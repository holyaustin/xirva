[{"id": "1904.00001", "submitter": "Hiroshi Kuwajima", "authors": "Hiroshi Kuwajima, Hirotoshi Yasuoka, Toshihiro Nakae", "title": "Engineering problems in machine learning systems", "comments": "20 pages, 4 figures, 4 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SE cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Fatal accidents are a major issue hindering the wide acceptance of\nsafety-critical systems that employ machine learning and deep learning models,\nsuch as automated driving vehicles. In order to use machine learning in a\nsafety-critical system, it is necessary to demonstrate the safety and security\nof the system through engineering processes. However, thus far, no such widely\naccepted engineering concepts or frameworks have been established for these\nsystems. The key to using a machine learning model in a deductively engineered\nsystem is decomposing the data-driven training of machine learning models into\nrequirement, design, and verification, particularly for machine learning models\nused in safety-critical systems. Simultaneously, open problems and relevant\ntechnical fields are not organized in a manner that enables researchers to\nselect a theme and work on it. In this study, we identify, classify, and\nexplore the open problems in engineering (safety-critical) machine learning\nsystems --- that is, in terms of requirement, design, and verification of\nmachine learning models and systems --- as well as discuss related works and\nresearch directions, using automated driving vehicles as an example. Our\nresults show that machine learning models are characterized by a lack of\nrequirements specification, lack of design specification, lack of\ninterpretability, and lack of robustness. We also perform a gap analysis on a\nconventional system quality standard SQuARE with the characteristics of machine\nlearning models to study quality models for machine learning systems. We find\nthat a lack of requirements specification and lack of robustness have the\ngreatest impact on conventional quality models.\n", "versions": [{"version": "v1", "created": "Mon, 1 Apr 2019 13:57:27 GMT"}, {"version": "v2", "created": "Thu, 22 Aug 2019 17:08:51 GMT"}], "update_date": "2019-08-23", "authors_parsed": [["Kuwajima", "Hiroshi", ""], ["Yasuoka", "Hirotoshi", ""], ["Nakae", "Toshihiro", ""]]}, {"id": "1904.00014", "submitter": "Daniel Muthukrishna", "authors": "Daniel Muthukrishna, Gautham Narayan, Kaisey S. Mandel, Rahul Biswas,\n  Ren\\'ee Hlo\\v{z}ek", "title": "RAPID: Early Classification of Explosive Transients using Deep Learning", "comments": "Accepted version. 28 pages, 16 figures, 2 tables, PASP Special Issue\n  on Methods for Time-Domain Astrophysics. Submitted: 13 December 2018,\n  Accepted: 26 March 2019", "journal-ref": "PASP 131, 118002 (2019)", "doi": "10.1088/1538-3873/ab1609", "report-no": null, "categories": "astro-ph.IM astro-ph.HE cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present RAPID (Real-time Automated Photometric IDentification), a novel\ntime-series classification tool capable of automatically identifying transients\nfrom within a day of the initial alert, to the full lifetime of a light curve.\nUsing a deep recurrent neural network with Gated Recurrent Units (GRUs), we\npresent the first method specifically designed to provide early classifications\nof astronomical time-series data, typing 12 different transient classes. Our\nclassifier can process light curves with any phase coverage, and it does not\nrely on deriving computationally expensive features from the data, making RAPID\nwell-suited for processing the millions of alerts that ongoing and upcoming\nwide-field surveys such as the Zwicky Transient Facility (ZTF), and the Large\nSynoptic Survey Telescope (LSST) will produce. The classification accuracy\nimproves over the lifetime of the transient as more photometric data becomes\navailable, and across the 12 transient classes, we obtain an average area under\nthe receiver operating characteristic curve of 0.95 and 0.98 at early and late\nepochs, respectively. We demonstrate RAPID's ability to effectively provide\nearly classifications of observed transients from the ZTF data stream. We have\nmade RAPID available as an open-source software package\n(https://astrorapid.readthedocs.io) for machine learning-based alert-brokers to\nuse for the autonomous and quick classification of several thousand light\ncurves within a few seconds.\n", "versions": [{"version": "v1", "created": "Fri, 29 Mar 2019 18:00:00 GMT"}, {"version": "v2", "created": "Mon, 7 Oct 2019 16:14:46 GMT"}], "update_date": "2019-10-08", "authors_parsed": [["Muthukrishna", "Daniel", ""], ["Narayan", "Gautham", ""], ["Mandel", "Kaisey S.", ""], ["Biswas", "Rahul", ""], ["Hlo\u017eek", "Ren\u00e9e", ""]]}, {"id": "1904.00035", "submitter": "Subramanya Nageshrao", "authors": "Subramanya Nageshrao, Eric Tseng and Dimitar Filev", "title": "Autonomous Highway Driving using Deep Reinforcement Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.LG cs.SY stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The operational space of an autonomous vehicle (AV) can be diverse and vary\nsignificantly. This may lead to a scenario that was not postulated in the\ndesign phase. Due to this, formulating a rule based decision maker for\nselecting maneuvers may not be ideal. Similarly, it may not be effective to\ndesign an a-priori cost function and then solve the optimal control problem in\nreal-time. In order to address these issues and to avoid peculiar behaviors\nwhen encountering unforeseen scenario, we propose a reinforcement learning (RL)\nbased method, where the ego car, i.e., an autonomous vehicle, learns to make\ndecisions by directly interacting with simulated traffic. The decision maker\nfor AV is implemented as a deep neural network providing an action choice for a\ngiven system state. In a critical application such as driving, an RL agent\nwithout explicit notion of safety may not converge or it may need extremely\nlarge number of samples before finding a reliable policy. To best address the\nissue, this paper incorporates reinforcement learning with an additional short\nhorizon safety check (SC). In a critical scenario, the safety check will also\nprovide an alternate safe action to the agent provided if it exists. This leads\nto two novel contributions. First, it generalizes the states that could lead to\nundesirable \"near-misses\" or \"collisions \". Second, inclusion of safety check\ncan provide a safe and stable training environment. This significantly enhances\nlearning efficiency without inhibiting meaningful exploration to ensure safe\nand optimal learned behavior. We demonstrate the performance of the developed\nalgorithm in highway driving scenario where the trained AV encounters varying\ntraffic density in a highway setting.\n", "versions": [{"version": "v1", "created": "Fri, 29 Mar 2019 18:15:24 GMT"}], "update_date": "2019-04-02", "authors_parsed": [["Nageshrao", "Subramanya", ""], ["Tseng", "Eric", ""], ["Filev", "Dimitar", ""]]}, {"id": "1904.00045", "submitter": "Collin Burns", "authors": "Collin Burns, Jesse Thomason, and Wesley Tansey", "title": "Interpreting Black Box Models via Hypothesis Testing", "comments": "FODS 2020", "journal-ref": null, "doi": "10.1145/3412815.3416889", "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In science and medicine, model interpretations may be reported as discoveries\nof natural phenomena or used to guide patient treatments. In such high-stakes\ntasks, false discoveries may lead investigators astray. These applications\nwould therefore benefit from control over the finite-sample error rate of\ninterpretations. We reframe black box model interpretability as a multiple\nhypothesis testing problem. The task is to discover \"important\" features by\ntesting whether the model prediction is significantly different from what would\nbe expected if the features were replaced with uninformative counterfactuals.\nWe propose two testing methods: one that provably controls the false discovery\nrate but which is not yet feasible for large-scale applications, and an\napproximate testing method which can be applied to real-world data sets. In\nsimulation, both tests have high power relative to existing interpretability\nmethods. When applied to state-of-the-art vision and language models, the\nframework selects features that intuitively explain model predictions. The\nresulting explanations have the additional advantage that they are themselves\neasy to interpret.\n", "versions": [{"version": "v1", "created": "Fri, 29 Mar 2019 18:47:58 GMT"}, {"version": "v2", "created": "Mon, 10 Jun 2019 03:18:23 GMT"}, {"version": "v3", "created": "Mon, 17 Aug 2020 17:28:57 GMT"}], "update_date": "2020-08-18", "authors_parsed": [["Burns", "Collin", ""], ["Thomason", "Jesse", ""], ["Tansey", "Wesley", ""]]}, {"id": "1904.00057", "submitter": "Andrea Idini", "authors": "Andrea Idini", "title": "Statistical learnability of nuclear masses", "comments": null, "journal-ref": "Phys. Rev. Research 2, 043363 (2020)", "doi": "10.1103/PhysRevResearch.2.043363", "report-no": null, "categories": "nucl-th cond-mat.dis-nn cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  After more than 80 years from the seminal work of Weizs\\\"acker and the liquid\ndrop model of the atomic nucleus, deviations from experiments of mass models\n($\\sim$ MeV) are orders of magnitude larger than experimental errors\n($\\lesssim$ keV). Predicting the mass of atomic nuclei with precision is\nextremely challenging. This is due to the non--trivial many--body interplay of\nprotons and neutrons in nuclei, and the complex nature of the nuclear strong\nforce. Statistical theory of learning will be used to provide bounds to the\nprediction errors of model trained with a finite data set. These bounds are\nvalidated with neural network calculations, and compared with state of the art\nmass models. Therefore, it will be argued that the nuclear structure models\ninvestigating ground state properties explore a system on the limit of the\nknowledgeable, as defined by the statistical theory of learning.\n", "versions": [{"version": "v1", "created": "Fri, 29 Mar 2019 19:08:12 GMT"}, {"version": "v2", "created": "Tue, 9 Apr 2019 11:47:09 GMT"}, {"version": "v3", "created": "Thu, 5 Sep 2019 16:20:41 GMT"}], "update_date": "2021-01-04", "authors_parsed": [["Idini", "Andrea", ""]]}, {"id": "1904.00070", "submitter": "Yi Hao", "authors": "Yi Hao, Alon Orlitsky, Ananda T. Suresh, Yihong Wu", "title": "Data Amplification: A Unified and Competitive Approach to Property\n  Estimation", "comments": "In NeurIPS 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Estimating properties of discrete distributions is a fundamental problem in\nstatistical learning. We design the first unified, linear-time, competitive,\nproperty estimator that for a wide class of properties and for all underlying\ndistributions uses just $2n$ samples to achieve the performance attained by the\nempirical estimator with $n\\sqrt{\\log n}$ samples. This provides off-the-shelf,\ndistribution-independent, \"amplification\" of the amount of data available\nrelative to common-practice estimators.\n  We illustrate the estimator's practical advantages by comparing it to\nexisting estimators for a wide variety of properties and distributions. In most\ncases, its performance with $n$ samples is even as good as that of the\nempirical estimator with $n\\log n$ samples, and for essentially all properties,\nits performance is comparable to that of the best existing estimator designed\nspecifically for that property.\n", "versions": [{"version": "v1", "created": "Fri, 29 Mar 2019 19:49:01 GMT"}], "update_date": "2019-04-02", "authors_parsed": [["Hao", "Yi", ""], ["Orlitsky", "Alon", ""], ["Suresh", "Ananda T.", ""], ["Wu", "Yihong", ""]]}, {"id": "1904.00093", "submitter": "Souvik Chakraborty", "authors": "Rajdip Nayek and Souvik Chakraborty and Sriram Narasimhan", "title": "A Gaussian process latent force model for joint input-state estimation\n  in linear structural systems", "comments": "Submitted to Mechanical Systems and Signal Processing", "journal-ref": null, "doi": "10.1016/j.ymssp.2019.03.048", "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The problem of combined state and input estimation of linear structural\nsystems based on measured responses and a priori knowledge of structural model\nis considered. A novel methodology using Gaussian process latent force models\nis proposed to tackle the problem in a stochastic setting. Gaussian process\nlatent force models (GPLFMs) are hybrid models that combine differential\nequations representing a physical system with data-driven non-parametric\nGaussian process models. In this work, the unknown input forces acting on a\nstructure are modelled as Gaussian processes with some chosen covariance\nfunctions which are combined with the mechanistic differential equation\nrepresenting the structure to construct a GPLFM. The GPLFM is then conveniently\nformulated as an augmented stochastic state-space model with additional states\nrepresenting the latent force components, and the joint input and state\ninference of the resulting model is implemented using Kalman filter. The\naugmented state-space model of GPLFM is shown as a generalization of the class\nof input-augmented state-space models, is proven observable, and is robust\ncompared to conventional augmented formulations in terms of numerical\nstability. The hyperparameters governing the covariance functions are estimated\nusing maximum likelihood optimization based on the observed data, thus\novercoming the need for manual tuning of the hyperparameters by\ntrial-and-error. To assess the performance of the proposed GPLFM method,\nseveral cases of state and input estimation are demonstrated using numerical\nsimulations on a 10-dof shear building and a 76-storey ASCE benchmark office\ntower. Results obtained indicate the superior performance of the proposed\napproach over conventional Kalman filter based approaches.\n", "versions": [{"version": "v1", "created": "Fri, 29 Mar 2019 21:29:54 GMT"}, {"version": "v2", "created": "Tue, 2 Apr 2019 01:21:50 GMT"}], "update_date": "2019-05-22", "authors_parsed": [["Nayek", "Rajdip", ""], ["Chakraborty", "Souvik", ""], ["Narasimhan", "Sriram", ""]]}, {"id": "1904.00110", "submitter": "Erion \\c{C}ano", "authors": "Erion \\c{C}ano and Ond\\v{r}ej Bojar", "title": "Keyphrase Generation: A Text Summarization Struggle", "comments": "7 pages, 3 tables. Published in proceedings of 2019 Annual Conference\n  of the North American Chapter of the Association for Computational\n  Linguistics. Identical to the previous version", "journal-ref": null, "doi": "10.18653/v1/N19-1070", "report-no": null, "categories": "cs.CL cs.IR cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Authors' keyphrases assigned to scientific articles are essential for\nrecognizing content and topic aspects. Most of the proposed supervised and\nunsupervised methods for keyphrase generation are unable to produce terms that\nare valuable but do not appear in the text. In this paper, we explore the\npossibility of considering the keyphrase string as an abstractive summary of\nthe title and the abstract. First, we collect, process and release a large\ndataset of scientific paper metadata that contains 2.2 million records. Then we\nexperiment with popular text summarization neural architectures. Despite using\nadvanced deep learning models, large quantities of data and many days of\ncomputation, our systematic evaluation on four test datasets reveals that the\nexplored text summarization methods could not produce better keyphrases than\nthe simpler unsupervised methods, or the existing supervised ones.\n", "versions": [{"version": "v1", "created": "Fri, 29 Mar 2019 22:43:26 GMT"}, {"version": "v2", "created": "Wed, 3 Apr 2019 19:54:28 GMT"}], "update_date": "2019-08-22", "authors_parsed": [["\u00c7ano", "Erion", ""], ["Bojar", "Ond\u0159ej", ""]]}, {"id": "1904.00132", "submitter": "Chenyang Huang", "authors": "Chenyang Huang, Amine Trabelsi, Osmar R. Za\\\"iane", "title": "ANA at SemEval-2019 Task 3: Contextual Emotion detection in\n  Conversations through hierarchical LSTMs and BERT", "comments": "Accepted at the SemEval-2019 International Workshop on Semantic\n  Evaluation", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.IR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper describes the system submitted by ANA Team for the SemEval-2019\nTask 3: EmoContext. We propose a novel Hierarchical LSTMs for Contextual\nEmotion Detection (HRLCE) model. It classifies the emotion of an utterance\ngiven its conversational context. The results show that, in this task, our\nHRCLE outperforms the most recent state-of-the-art text classification\nframework: BERT. We combine the results generated by BERT and HRCLE to achieve\nan overall score of 0.7709 which ranked 5th on the final leader board of the\ncompetition among 165 Teams.\n", "versions": [{"version": "v1", "created": "Sat, 30 Mar 2019 01:51:24 GMT"}, {"version": "v2", "created": "Fri, 31 May 2019 20:43:22 GMT"}], "update_date": "2019-06-04", "authors_parsed": [["Huang", "Chenyang", ""], ["Trabelsi", "Amine", ""], ["Za\u00efane", "Osmar R.", ""]]}, {"id": "1904.00138", "submitter": "Chen Hao", "authors": "K.S. Rajput, S. Wibowo, C. Hao, M. Majmudar", "title": "On Arrhythmia Detection by Deep Learning and Multidimensional\n  Representation", "comments": "draft paper; prepared for journal", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG eess.SP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  An electrocardiogram (ECG) is a time-series signal that is represented by\none-dimensional (1-D) data. Higher dimensional representation contains more\ninformation that is accessible for feature extraction. Hidden variables such as\nfrequency relation and morphology of segment is not directly accessible in the\ntime domain. In this paper, 1-D time series data is converted into\nmulti-dimensional representation in the form of multichannel 2-D images.\nFollowing that, deep learning was used to train a deep neural network based\nclassifier to detect arrhythmias. The results of simulation on testing database\ndemonstrate the effectiveness of the proposed methodology by showing an\noutstanding classification performance compared to other existing methods and\nhand-crafted annotations made by certified cardiologists.\n", "versions": [{"version": "v1", "created": "Sat, 30 Mar 2019 02:50:23 GMT"}, {"version": "v2", "created": "Tue, 2 Apr 2019 04:52:45 GMT"}, {"version": "v3", "created": "Wed, 3 Apr 2019 10:51:52 GMT"}, {"version": "v4", "created": "Thu, 11 Apr 2019 08:27:51 GMT"}], "update_date": "2019-04-12", "authors_parsed": [["Rajput", "K. S.", ""], ["Wibowo", "S.", ""], ["Hao", "C.", ""], ["Majmudar", "M.", ""]]}, {"id": "1904.00150", "submitter": "Gaurav Verma", "authors": "Gaurav Verma, Eeshan Gunesh Dhekane, Tanaya Guha", "title": "Learning Affective Correspondence between Music and Image", "comments": "5 pages, International Conference on Acoustics, Speech and Signal\n  Processing (ICASSP) 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.MM cs.LG cs.SD eess.AS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce the problem of learning affective correspondence between audio\n(music) and visual data (images). For this task, a music clip and an image are\nconsidered similar (having true correspondence) if they have similar emotion\ncontent. In order to estimate this crossmodal, emotion-centric similarity, we\npropose a deep neural network architecture that learns to project the data from\nthe two modalities to a common representation space, and performs a binary\nclassification task of predicting the affective correspondence (true or false).\nTo facilitate the current study, we construct a large scale database containing\nmore than $3,500$ music clips and $85,000$ images with three emotion classes\n(positive, neutral, negative). The proposed approach achieves $61.67\\%$\naccuracy for the affective correspondence prediction task on this database,\noutperforming two relevant and competitive baselines. We also demonstrate that\nour network learns modality-specific representations of emotion (without\nexplicitly being trained with emotion labels), which are useful for emotion\nrecognition in individual modalities.\n", "versions": [{"version": "v1", "created": "Sat, 30 Mar 2019 05:17:27 GMT"}, {"version": "v2", "created": "Wed, 17 Apr 2019 03:27:35 GMT"}], "update_date": "2019-04-18", "authors_parsed": [["Verma", "Gaurav", ""], ["Dhekane", "Eeshan Gunesh", ""], ["Guha", "Tanaya", ""]]}, {"id": "1904.00152", "submitter": "Chieh-Hsin Lai", "authors": "Chieh-Hsin Lai, Dongmian Zou, and Gilad Lerman", "title": "Robust Subspace Recovery Layer for Unsupervised Anomaly Detection", "comments": "This work is on the ICLR 2020 conference", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a neural network for unsupervised anomaly detection with a novel\nrobust subspace recovery layer (RSR layer). This layer seeks to extract the\nunderlying subspace from a latent representation of the given data and removes\noutliers that lie away from this subspace. It is used within an autoencoder.\nThe encoder maps the data into a latent space, from which the RSR layer\nextracts the subspace. The decoder then smoothly maps back the underlying\nsubspace to a \"manifold\" close to the original inliers. Inliers and outliers\nare distinguished according to the distances between the original and mapped\npositions (small for inliers and large for outliers). Extensive numerical\nexperiments with both image and document datasets demonstrate state-of-the-art\nprecision and recall.\n", "versions": [{"version": "v1", "created": "Sat, 30 Mar 2019 05:30:54 GMT"}, {"version": "v2", "created": "Tue, 24 Dec 2019 22:44:25 GMT"}], "update_date": "2019-12-30", "authors_parsed": [["Lai", "Chieh-Hsin", ""], ["Zou", "Dongmian", ""], ["Lerman", "Gilad", ""]]}, {"id": "1904.00160", "submitter": "Satoshi Yamane", "authors": "Tetsuto Takano, Satoshi Yamane", "title": "Machine translation considering context information using\n  Encoder-Decoder model", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In the task of machine translation, context information is one of the\nimportant factor. But considering the context information model dose not\nproposed. The paper propose a new model which can integrate context information\nand make translation. In this paper, we create a new model based Encoder\nDecoder model. When translating current sentence, the model integrates output\nfrom preceding encoder with current encoder. The model can consider context\ninformation and the result score is higher than existing model.\n", "versions": [{"version": "v1", "created": "Sat, 30 Mar 2019 07:13:38 GMT"}], "update_date": "2019-04-02", "authors_parsed": [["Takano", "Tetsuto", ""], ["Yamane", "Satoshi", ""]]}, {"id": "1904.00170", "submitter": "Jingcai Guo", "authors": "Jingcai Guo, Song Guo", "title": "Adaptive Adjustment with Semantic Feature Space for Zero-Shot\n  Recognition", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In most recent years, zero-shot recognition (ZSR) has gained increasing\nattention in machine learning and image processing fields. It aims at\nrecognizing unseen class instances with knowledge transferred from seen\nclasses. This is typically achieved by exploiting a pre-defined semantic\nfeature space (FS), i.e., semantic attributes or word vectors, as a bridge to\ntransfer knowledge between seen and unseen classes. However, due to the absence\nof unseen classes during training, the conventional ZSR easily suffers from\ndomain shift and hubness problems. In this paper, we propose a novel ZSR\nlearning framework that can handle these two issues well by adaptively\nadjusting semantic FS. To the best of our knowledge, our work is the first to\nconsider the adaptive adjustment of semantic FS in ZSR. Moreover, our solution\ncan be formulated to a more efficient framework that significantly boosts the\ntraining. Extensive experiments show the remarkable performance improvement of\nour model compared with other existing methods.\n", "versions": [{"version": "v1", "created": "Sat, 30 Mar 2019 08:39:03 GMT"}], "update_date": "2019-04-02", "authors_parsed": [["Guo", "Jingcai", ""], ["Guo", "Song", ""]]}, {"id": "1904.00172", "submitter": "Jingcai Guo", "authors": "Jingcai Guo, Song Guo", "title": "EE-AE: An Exclusivity Enhanced Unsupervised Feature Learning Approach", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Unsupervised learning is becoming more and more important recently. As one of\nits key components, the autoencoder (AE) aims to learn a latent feature\nrepresentation of data which is more robust and discriminative. However, most\nAE based methods only focus on the reconstruction within the encoder-decoder\nphase, which ignores the inherent relation of data, i.e., statistical and\ngeometrical dependence, and easily causes overfitting. In order to deal with\nthis issue, we propose an Exclusivity Enhanced (EE) unsupervised feature\nlearning approach to improve the conventional AE. To the best of our knowledge,\nour research is the first to utilize such exclusivity concept to cooperate with\nfeature extraction within AE. Moreover, in this paper we also make some\nimprovements to the stacked AE structure especially for the connection of\ndifferent layers from decoders, this could be regarded as a weight\ninitialization trial. The experimental results show that our proposed approach\ncan achieve remarkable performance compared with other related methods.\n", "versions": [{"version": "v1", "created": "Sat, 30 Mar 2019 08:46:23 GMT"}], "update_date": "2019-04-02", "authors_parsed": [["Guo", "Jingcai", ""], ["Guo", "Song", ""]]}, {"id": "1904.00173", "submitter": "Daniil Ryabko", "authors": "Daniil Ryabko", "title": "Asymptotic nonparametric statistical analysis of stationary time series", "comments": "This is the author's version of the homonymous volume published by\n  Springer. The final authenticated version is available online at:\n  https://doi.org/10.1007/978-3-030-12564-6 Further updates and corrections may\n  be made here", "journal-ref": null, "doi": "10.1007/978-3-030-12564-6", "report-no": null, "categories": "math.ST cs.IT cs.LG math.IT stat.ML stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Stationarity is a very general, qualitative assumption, that can be assessed\non the basis of application specifics. It is thus a rather attractive\nassumption to base statistical analysis on, especially for problems for which\nless general qualitative assumptions, such as independence or finite memory,\nclearly fail. However, it has long been considered too general to allow for\nstatistical inference to be made. One of the reasons for this is that rates of\nconvergence, even of frequencies to the mean, are not available under this\nassumption alone. Recently, it has been shown that, while some natural and\nsimple problems such as homogeneity, are indeed provably impossible to solve if\none only assumes that the data is stationary (or stationary ergodic), many\nothers can be solved using rather simple and intuitive algorithms. The latter\nproblems include clustering and change point estimation. In this volume I\nsummarize these results. The emphasis is on asymptotic consistency, since this\nthe strongest property one can obtain assuming stationarity alone. While for\nmost of the problems for which a solution is found this solution is\nalgorithmically realizable, the main objective in this area of research, the\nobjective which is only partially attained, is to understand what is possible\nand what is not possible to do for stationary time series. The considered\nproblems include homogeneity testing, clustering with respect to distribution,\nclustering with respect to independence, change-point estimation, identity\ntesting, and the general question of composite hypotheses testing. For the\nlatter problem, a topological criterion for the existence of a consistent test\nis presented. In addition, several open questions are discussed.\n", "versions": [{"version": "v1", "created": "Sat, 30 Mar 2019 08:47:46 GMT"}], "update_date": "2019-04-02", "authors_parsed": [["Ryabko", "Daniil", ""]]}, {"id": "1904.00176", "submitter": "Zhipeng Wang", "authors": "Zhipeng Wang and David W. Scott", "title": "Nonparametric Density Estimation for High-Dimensional Data - Algorithms\n  and Applications", "comments": null, "journal-ref": "Wiley Interdisciplinary Reviews: Computational Statistics, 2019", "doi": "10.1002/wics.1461", "report-no": null, "categories": "stat.ML cs.LG stat.CO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Density Estimation is one of the central areas of statistics whose purpose is\nto estimate the probability density function underlying the observed data. It\nserves as a building block for many tasks in statistical inference,\nvisualization, and machine learning. Density Estimation is widely adopted in\nthe domain of unsupervised learning especially for the application of\nclustering. As big data become pervasive in almost every area of data sciences,\nanalyzing high-dimensional data that have many features and variables appears\nto be a major focus in both academia and industry. High-dimensional data pose\nchallenges not only from the theoretical aspects of statistical inference, but\nalso from the algorithmic/computational considerations of machine learning and\ndata analytics. This paper reviews a collection of selected nonparametric\ndensity estimation algorithms for high-dimensional data, some of them are\nrecently published and provide interesting mathematical insights. The important\napplication domain of nonparametric density estimation, such as { modal\nclustering}, are also included in this paper. Several research directions\nrelated to density estimation and high-dimensional data analysis are suggested\nby the authors.\n", "versions": [{"version": "v1", "created": "Sat, 30 Mar 2019 09:08:45 GMT"}], "update_date": "2019-04-02", "authors_parsed": [["Wang", "Zhipeng", ""], ["Scott", "David W.", ""]]}, {"id": "1904.00197", "submitter": "Suraj Tripathi", "authors": "Abhay Kumar, Nishant Jain, Chirag Singh, Suraj Tripathi", "title": "Exploiting SIFT Descriptor for Rotation Invariant Convolutional Neural\n  Network", "comments": "Accepted in IEEE INDICON 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper presents a novel approach to exploit the distinctive invariant\nfeatures in convolutional neural network. The proposed CNN model uses Scale\nInvariant Feature Transform (SIFT) descriptor instead of the max-pooling layer.\nMax-pooling layer discards the pose, i.e., translational and rotational\nrelationship between the low-level features, and hence unable to capture the\nspatial hierarchies between low and high level features. The SIFT descriptor\nlayer captures the orientation and the spatial relationship of the features\nextracted by convolutional layer. The proposed SIFT Descriptor CNN therefore\ncombines the feature extraction capabilities of CNN model and rotation\ninvariance of SIFT descriptor. Experimental results on the MNIST and\nfashionMNIST datasets indicates reasonable improvements over conventional\nmethods available in literature.\n", "versions": [{"version": "v1", "created": "Sat, 30 Mar 2019 11:00:21 GMT"}], "update_date": "2019-04-02", "authors_parsed": [["Kumar", "Abhay", ""], ["Jain", "Nishant", ""], ["Singh", "Chirag", ""], ["Tripathi", "Suraj", ""]]}, {"id": "1904.00231", "submitter": "Junjie Wang", "authors": "Junjie Wang, Qichao Zhang, Dongbin Zhao, Yaran Chen", "title": "Lane Change Decision-making through Deep Reinforcement Learning with\n  Rule-based Constraints", "comments": "6 pages, 5 figures, accepted at 2019 International Joint Conference\n  on Neural Networks(IJCNN)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.AI cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Autonomous driving decision-making is a great challenge due to the complexity\nand uncertainty of the traffic environment. Combined with the rule-based\nconstraints, a Deep Q-Network (DQN) based method is applied for autonomous\ndriving lane change decision-making task in this study. Through the combination\nof high-level lateral decision-making and low-level rule-based trajectory\nmodification, a safe and efficient lane change behavior can be achieved. With\nthe setting of our state representation and reward function, the trained agent\nis able to take appropriate actions in a real-world-like simulator. The\ngenerated policy is evaluated on the simulator for 10 times, and the results\ndemonstrate that the proposed rule-based DQN method outperforms the rule-based\napproach and the DQN method.\n", "versions": [{"version": "v1", "created": "Sat, 30 Mar 2019 15:16:39 GMT"}, {"version": "v2", "created": "Tue, 2 Apr 2019 01:26:22 GMT"}], "update_date": "2019-04-03", "authors_parsed": [["Wang", "Junjie", ""], ["Zhang", "Qichao", ""], ["Zhao", "Dongbin", ""], ["Chen", "Yaran", ""]]}, {"id": "1904.00242", "submitter": "Yuan Zhou", "authors": "Yingkai Li and Yining Wang and Yuan Zhou", "title": "Nearly Minimax-Optimal Regret for Linearly Parameterized Bandits", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the linear contextual bandit problem with finite action sets. When\nthe problem dimension is $d$, the time horizon is $T$, and there are $n \\leq\n2^{d/2}$ candidate actions per time period, we (1) show that the minimax\nexpected regret is $\\Omega(\\sqrt{dT (\\log T) (\\log n)})$ for every algorithm,\nand (2) introduce a Variable-Confidence-Level (VCL) SupLinUCB algorithm whose\nregret matches the lower bound up to iterated logarithmic factors. Our\nalgorithmic result saves two $\\sqrt{\\log T}$ factors from previous analysis,\nand our information-theoretical lower bound also improves previous results by\none $\\sqrt{\\log T}$ factor, revealing a regret scaling quite different from\nclassical multi-armed bandits in which no logarithmic $T$ term is present in\nminimax regret. Our proof techniques include variable confidence levels and a\ncareful analysis of layer sizes of SupLinUCB on the upper bound side, and\ndelicately constructed adversarial sequences showing the tightness of\nelliptical potential lemmas on the lower bound side.\n", "versions": [{"version": "v1", "created": "Sat, 30 Mar 2019 16:16:23 GMT"}, {"version": "v2", "created": "Tue, 18 Aug 2020 22:51:34 GMT"}], "update_date": "2020-08-20", "authors_parsed": [["Li", "Yingkai", ""], ["Wang", "Yining", ""], ["Zhou", "Yuan", ""]]}, {"id": "1904.00243", "submitter": "Hugo Caselles-Dupr\\'e", "authors": "Hugo Caselles-Dupr\\'e, Michael Garcia-Ortiz, David Filliat", "title": "Symmetry-Based Disentangled Representation Learning requires Interaction\n  with Environments", "comments": "33rd Conference on Neural Information Processing Systems (NeurIPS\n  2019), Vancouver, Canada", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Finding a generally accepted formal definition of a disentangled\nrepresentation in the context of an agent behaving in an environment is an\nimportant challenge towards the construction of data-efficient autonomous\nagents. Higgins et al. recently proposed Symmetry-Based Disentangled\nRepresentation Learning, a definition based on a characterization of symmetries\nin the environment using group theory. We build on their work and make\nobservations, theoretical and empirical, that lead us to argue that\nSymmetry-Based Disentangled Representation Learning cannot only be based on\nstatic observations: agents should interact with the environment to discover\nits symmetries. Our experiments can be reproduced in Colab and the code is\navailable on GitHub.\n", "versions": [{"version": "v1", "created": "Sat, 30 Mar 2019 16:21:20 GMT"}, {"version": "v2", "created": "Thu, 11 Jul 2019 09:33:39 GMT"}, {"version": "v3", "created": "Thu, 19 Sep 2019 12:05:02 GMT"}], "update_date": "2019-09-20", "authors_parsed": [["Caselles-Dupr\u00e9", "Hugo", ""], ["Garcia-Ortiz", "Michael", ""], ["Filliat", "David", ""]]}, {"id": "1904.00275", "submitter": "Mei-Yun Chen", "authors": "Mei-Yun Chen, Ya-Bo Huang, Sheng-Ping Chang and Ming Ouhyoung", "title": "Prediction Model for Semitransparent Watercolor Pigment Mixtures Using\n  Deep Learning with a Dataset of Transmittance and Reflectance", "comments": "26 pages and 25 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.GR stat.ML", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Learning color mixing is difficult for novice painters. In order to support\nnovice painters in learning color mixing, we propose a prediction model for\nsemitransparent pigment mixtures and use its prediction results to create a\nSmart Palette system. Such a system is constructed by first building a\nwatercolor dataset with two types of color mixing data, indicated by\ntransmittance and reflectance: incrementation of the same primary pigment and a\nmixture of two different pigments. Next, we apply the collected data to a deep\nneural network to train a model for predicting the results of semitransparent\npigment mixtures. Finally, we constructed a Smart Palette that provides\neasily-followable instructions on mixing a target color with two primary\npigments in real life: when users pick a pixel, an RGB color, from an image,\nthe system returns its mixing recipe which indicates the two primary pigments\nbeing used and their quantities.\n", "versions": [{"version": "v1", "created": "Sat, 30 Mar 2019 19:27:33 GMT"}], "update_date": "2019-04-02", "authors_parsed": [["Chen", "Mei-Yun", ""], ["Huang", "Ya-Bo", ""], ["Chang", "Sheng-Ping", ""], ["Ouhyoung", "Ming", ""]]}, {"id": "1904.00284", "submitter": "Chieh Hubert Lin", "authors": "Chieh Hubert Lin, Chia-Che Chang, Yu-Sheng Chen, Da-Cheng Juan, Wei\n  Wei, Hwann-Tzong Chen", "title": "COCO-GAN: Generation by Parts via Conditional Coordinating", "comments": "Accepted to ICCV'19 (oral). All images are compressed due to size\n  limit, please access the full-resolution version via Google Drive:\n  http://bit.ly/COCO-GAN-full", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Humans can only interact with part of the surrounding environment due to\nbiological restrictions. Therefore, we learn to reason the spatial\nrelationships across a series of observations to piece together the surrounding\nenvironment. Inspired by such behavior and the fact that machines also have\ncomputational constraints, we propose \\underline{CO}nditional\n\\underline{CO}ordinate GAN (COCO-GAN) of which the generator generates images\nby parts based on their spatial coordinates as the condition. On the other\nhand, the discriminator learns to justify realism across multiple assembled\npatches by global coherence, local appearance, and edge-crossing continuity.\nDespite the full images are never generated during training, we show that\nCOCO-GAN can produce \\textbf{state-of-the-art-quality} full images during\ninference. We further demonstrate a variety of novel applications enabled by\nteaching the network to be aware of coordinates. First, we perform\nextrapolation to the learned coordinate manifold and generate off-the-boundary\npatches. Combining with the originally generated full image, COCO-GAN can\nproduce images that are larger than training samples, which we called\n\"beyond-boundary generation\". We then showcase panorama generation within a\ncylindrical coordinate system that inherently preserves horizontally cyclic\ntopology. On the computation side, COCO-GAN has a built-in divide-and-conquer\nparadigm that reduces memory requisition during training and inference,\nprovides high-parallelism, and can generate parts of images on-demand.\n", "versions": [{"version": "v1", "created": "Sat, 30 Mar 2019 20:37:24 GMT"}, {"version": "v2", "created": "Tue, 16 Apr 2019 15:55:44 GMT"}, {"version": "v3", "created": "Mon, 5 Aug 2019 05:58:45 GMT"}, {"version": "v4", "created": "Sun, 5 Jan 2020 06:28:59 GMT"}], "update_date": "2020-01-07", "authors_parsed": [["Lin", "Chieh Hubert", ""], ["Chang", "Chia-Che", ""], ["Chen", "Yu-Sheng", ""], ["Juan", "Da-Cheng", ""], ["Wei", "Wei", ""], ["Chen", "Hwann-Tzong", ""]]}, {"id": "1904.00310", "submitter": "Xilai Li", "authors": "Xilai Li, Yingbo Zhou, Tianfu Wu, Richard Socher, Caiming Xiong", "title": "Learn to Grow: A Continual Structure Learning Framework for Overcoming\n  Catastrophic Forgetting", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Addressing catastrophic forgetting is one of the key challenges in continual\nlearning where machine learning systems are trained with sequential or\nstreaming tasks. Despite recent remarkable progress in state-of-the-art deep\nlearning, deep neural networks (DNNs) are still plagued with the catastrophic\nforgetting problem. This paper presents a conceptually simple yet general and\neffective framework for handling catastrophic forgetting in continual learning\nwith DNNs. The proposed method consists of two components: a neural structure\noptimization component and a parameter learning and/or fine-tuning component.\nBy separating the explicit neural structure learning and the parameter\nestimation, not only is the proposed method capable of evolving neural\nstructures in an intuitively meaningful way, but also shows strong capabilities\nof alleviating catastrophic forgetting in experiments. Furthermore, the\nproposed method outperforms all other baselines on the permuted MNIST dataset,\nthe split CIFAR100 dataset and the Visual Domain Decathlon dataset in continual\nlearning setting.\n", "versions": [{"version": "v1", "created": "Sun, 31 Mar 2019 00:35:36 GMT"}, {"version": "v2", "created": "Tue, 2 Apr 2019 03:35:25 GMT"}, {"version": "v3", "created": "Tue, 21 May 2019 16:36:25 GMT"}], "update_date": "2019-05-22", "authors_parsed": [["Li", "Xilai", ""], ["Zhou", "Yingbo", ""], ["Wu", "Tianfu", ""], ["Socher", "Richard", ""], ["Xiong", "Caiming", ""]]}, {"id": "1904.00314", "submitter": "Seokho Kang", "authors": "Elman Mansimov, Omar Mahmood, Seokho Kang, Kyunghyun Cho", "title": "Molecular geometry prediction using a deep generative graph neural\n  network", "comments": "15 pages, 6 figures", "journal-ref": "Scientific Reports 9: 20381, 2019", "doi": "10.1038/s41598-019-56773-5", "report-no": null, "categories": "cs.LG physics.comp-ph stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A molecule's geometry, also known as conformation, is one of a molecule's\nmost important properties, determining the reactions it participates in, the\nbonds it forms, and the interactions it has with other molecules. Conventional\nconformation generation methods minimize hand-designed molecular force field\nenergy functions that are often not well correlated with the true energy\nfunction of a molecule observed in nature. They generate geometrically diverse\nsets of conformations, some of which are very similar to the lowest-energy\nconformations and others of which are very different. In this paper, we propose\na conditional deep generative graph neural network that learns an energy\nfunction by directly learning to generate molecular conformations that are\nenergetically favorable and more likely to be observed experimentally in\ndata-driven manner. On three large-scale datasets containing small molecules,\nwe show that our method generates a set of conformations that on average is far\nmore likely to be close to the corresponding reference conformations than are\nthose obtained from conventional force field methods. Our method maintains\ngeometrical diversity by generating conformations that are not too similar to\neach other, and is also computationally faster. We also show that our method\ncan be used to provide initial coordinates for conventional force field\nmethods. On one of the evaluated datasets we show that this combination allows\nus to combine the best of both methods, yielding generated conformations that\nare on average close to reference conformations with some very similar to\nreference conformations.\n", "versions": [{"version": "v1", "created": "Sun, 31 Mar 2019 01:06:22 GMT"}, {"version": "v2", "created": "Tue, 17 Dec 2019 00:53:28 GMT"}], "update_date": "2020-01-01", "authors_parsed": [["Mansimov", "Elman", ""], ["Mahmood", "Omar", ""], ["Kang", "Seokho", ""], ["Cho", "Kyunghyun", ""]]}, {"id": "1904.00324", "submitter": "Grigori Fursin", "authors": "Grigori Fursin", "title": "SysML'19 demo: customizable and reusable Collective Knowledge pipelines\n  to automate and reproduce machine learning experiments", "comments": "Accepted demo at the Conference on Systems and Machine Learning\n  (SysML'19)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Reproducing, comparing and reusing results from machine learning and systems\npapers is a very tedious, ad hoc and time-consuming process. I will demonstrate\nhow to automate this process using open-source, portable, customizable and\nCLI-based Collective Knowledge workflows and pipelines developed by the\ncommunity. I will help participants run several real-world non-virtualized CK\nworkflows from the SysML'19 conference, companies (General Motors, Arm) and\nMLPerf benchmark to automate benchmarking and co-design of efficient\nsoftware/hardware stacks for machine learning workloads. I hope that our\napproach will help authors reduce their effort when sharing reusable and\nextensible research artifacts while enabling artifact evaluators to\nautomatically validate experimental results from published papers in a standard\nand portable way.\n", "versions": [{"version": "v1", "created": "Sun, 31 Mar 2019 02:39:33 GMT"}], "update_date": "2019-04-02", "authors_parsed": [["Fursin", "Grigori", ""]]}, {"id": "1904.00326", "submitter": "Chengsheng Mao", "authors": "Chengsheng Mao, Liang Yao, Yuan Luo", "title": "MedGCN: Graph Convolutional Networks for Multiple Medical Tasks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Laboratory testing and medication prescription are two of the most important\nroutines in daily clinical practice. Developing an artificial intelligence\nsystem that can automatically make lab test imputations and medication\nrecommendations can save cost on potentially redundant lab tests and inform\nphysicians in more effective prescription. We present an intelligent model that\ncan automatically recommend the patients' medications based on their incomplete\nlab tests, and can even accurately estimate the lab values that have not been\ntaken. We model the complex relations between multiple types of medical\nentities with their inherent features in a heterogeneous graph. Then we learn a\ndistributed representation for each entity in the graph based on graph\nconvolutional networks to make the representations integrate information from\nmultiple types of entities. Since the entity representations incorporate\nmultiple types of medical information, they can be used for multiple medical\ntasks. In our experiments, we construct a graph to associate patients,\nencounters, lab tests and medications, and conduct the two tasks: medication\nrecommendation and lab test imputation. The experimental results demonstrate\nthat our model can outperform the state-of-the-art models in both tasks.\n", "versions": [{"version": "v1", "created": "Sun, 31 Mar 2019 02:48:50 GMT"}], "update_date": "2019-04-02", "authors_parsed": [["Mao", "Chengsheng", ""], ["Yao", "Liang", ""], ["Luo", "Yuan", ""]]}, {"id": "1904.00327", "submitter": "Chuang Ye", "authors": "Chuang Ye, M. Cenk Gursoy, and Senem Velipasalar", "title": "Power Control for Wireless VBR Video Streaming: From Optimization to\n  Reinforcement Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IT cs.LG math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we investigate the problem of power control for streaming\nvariable bit rate (VBR) videos over wireless links. A system model involving a\ntransmitter (e.g., a base station) that sends VBR video data to a receiver\n(e.g., a mobile user) equipped with a playout buffer is adopted, as used in\ndynamic adaptive streaming video applications. In this setting, we analyze\npower control policies considering the following two objectives: 1) the\nminimization of the transmit power consumption, and 2) the minimization of the\ntransmission completion time of the communication session. In order to play the\nvideo without interruptions, the power control policy should also satisfy the\nrequirement that the VBR video data is delivered to the mobile user without\ncausing playout buffer underflow or overflows. A directional water-filling\nalgorithm, which provides a simple and concise interpretation of the necessary\noptimality conditions, is identified as the optimal offline policy. Following\nthis, two online policies are proposed for power control based on channel side\ninformation (CSI) prediction within a short time window. Dynamic programming is\nemployed to implement the optimal offline and the initial online power control\npolicies that minimize the transmit power consumption in the communication\nsession. Subsequently, reinforcement learning (RL) based approach is employed\nfor the second online power control policy. Via simulation results, we show\nthat the optimal offline power control policy that minimizes the overall power\nconsumption leads to substantial energy savings compared to the strategy of\nminimizing the time duration of video streaming. We also demonstrate that the\nRL algorithm performs better than the dynamic programming based online grouped\nwater-filling (GWF) strategy unless the channel is highly correlated.\n", "versions": [{"version": "v1", "created": "Sun, 31 Mar 2019 02:57:19 GMT"}], "update_date": "2019-04-02", "authors_parsed": [["Ye", "Chuang", ""], ["Gursoy", "M. Cenk", ""], ["Velipasalar", "Senem", ""]]}, {"id": "1904.00346", "submitter": "Xijun Wang", "authors": "Xijun Wang, Meina Kan, Shiguang Shan, Xilin Chen", "title": "Fully Learnable Group Convolution for Acceleration of Deep Neural\n  Networks", "comments": "Accepted by CVPR 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Benefitted from its great success on many tasks, deep learning is\nincreasingly used on low-computational-cost devices, e.g. smartphone, embedded\ndevices, etc. To reduce the high computational and memory cost, in this work,\nwe propose a fully learnable group convolution module (FLGC for short) which is\nquite efficient and can be embedded into any deep neural networks for\nacceleration. Specifically, our proposed method automatically learns the group\nstructure in the training stage in a fully end-to-end manner, leading to a\nbetter structure than the existing pre-defined, two-steps, or iterative\nstrategies. Moreover, our method can be further combined with depthwise\nseparable convolution, resulting in 5 times acceleration than the vanilla\nResnet50 on single CPU. An additional advantage is that in our FLGC the number\nof groups can be set as any value, but not necessarily 2^k as in most existing\nmethods, meaning better tradeoff between accuracy and speed. As evaluated in\nour experiments, our method achieves better performance than existing learnable\ngroup convolution and standard group convolution when using the same number of\ngroups.\n", "versions": [{"version": "v1", "created": "Sun, 31 Mar 2019 06:24:07 GMT"}], "update_date": "2019-04-02", "authors_parsed": [["Wang", "Xijun", ""], ["Kan", "Meina", ""], ["Shan", "Shiguang", ""], ["Chen", "Xilin", ""]]}, {"id": "1904.00350", "submitter": "Sungjoon Park", "authors": "Sungjoon Park, Donghyun Kim, Alice Oh", "title": "Conversation Model Fine-Tuning for Classifying Client Utterances in\n  Counseling Dialogues", "comments": "9 pages, 2 figures, NAACL 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The recent surge of text-based online counseling applications enables us to\ncollect and analyze interactions between counselors and clients. A dataset of\nthose interactions can be used to learn to automatically classify the client\nutterances into categories that help counselors in diagnosing client status and\npredicting counseling outcome. With proper anonymization, we collect\ncounselor-client dialogues, define meaningful categories of client utterances\nwith professional counselors, and develop a novel neural network model for\nclassifying the client utterances. The central idea of our model, ConvMFiT, is\na pre-trained conversation model which consists of a general language model\nbuilt from an out-of-domain corpus and two role-specific language models built\nfrom unlabeled in-domain dialogues. The classification result shows that\nConvMFiT outperforms state-of-the-art comparison models. Further, the attention\nweights in the learned model confirm that the model finds expected linguistic\npatterns for each category.\n", "versions": [{"version": "v1", "created": "Sun, 31 Mar 2019 07:30:47 GMT"}], "update_date": "2019-04-02", "authors_parsed": [["Park", "Sungjoon", ""], ["Kim", "Donghyun", ""], ["Oh", "Alice", ""]]}, {"id": "1904.00368", "submitter": "Soheil Mehrabkhani", "authors": "Soheil Mehrabkhani", "title": "Fourier Transform Approach to Machine Learning I: Fourier Regression", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a supervised learning algorithm for machine learning applications.\nContrary to the model developing in the classical methods, which treat\ntraining, validation, and test as separate steps, in the presented approach,\nthere is a unified training and evaluating procedure based on an iterative band\nfiltering by the use of a fast Fourier transform. The presented approach does\nnot apply the method of least squares, thus, basically typical ill-conditioned\nmatrices do not occur at all. The optimal model results from the convergence of\nthe performance metric, which automatically prevents the usual underfitting and\noverfitting problems. The algorithm capability is investigated for noisy data,\nand the obtained result demonstrates a reliable and powerful machine learning\napproach beyond the typical limits of the classical methods.\n", "versions": [{"version": "v1", "created": "Sun, 31 Mar 2019 09:41:28 GMT"}, {"version": "v2", "created": "Tue, 2 Apr 2019 09:24:18 GMT"}, {"version": "v3", "created": "Sun, 22 Sep 2019 09:22:34 GMT"}], "update_date": "2019-09-24", "authors_parsed": [["Mehrabkhani", "Soheil", ""]]}, {"id": "1904.00370", "submitter": "Sayna Ebrahimi", "authors": "Samarth Sinha, Sayna Ebrahimi, Trevor Darrell", "title": "Variational Adversarial Active Learning", "comments": "First two authors contributed equally, listed alphabetically.\n  Accepted as Oral at ICCV 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Active learning aims to develop label-efficient algorithms by sampling the\nmost representative queries to be labeled by an oracle. We describe a\npool-based semi-supervised active learning algorithm that implicitly learns\nthis sampling mechanism in an adversarial manner. Unlike conventional active\nlearning algorithms, our approach is task agnostic, i.e., it does not depend on\nthe performance of the task for which we are trying to acquire labeled data.\nOur method learns a latent space using a variational autoencoder (VAE) and an\nadversarial network trained to discriminate between unlabeled and labeled data.\nThe mini-max game between the VAE and the adversarial network is played such\nthat while the VAE tries to trick the adversarial network into predicting that\nall data points are from the labeled pool, the adversarial network learns how\nto discriminate between dissimilarities in the latent space. We extensively\nevaluate our method on various image classification and semantic segmentation\nbenchmark datasets and establish a new state of the art on\n$\\text{CIFAR10/100}$, $\\text{Caltech-256}$, $\\text{ImageNet}$,\n$\\text{Cityscapes}$, and $\\text{BDD100K}$. Our results demonstrate that our\nadversarial approach learns an effective low dimensional latent space in\nlarge-scale settings and provides for a computationally efficient sampling\nmethod. Our code is available at https://github.com/sinhasam/vaal.\n", "versions": [{"version": "v1", "created": "Sun, 31 Mar 2019 09:54:17 GMT"}, {"version": "v2", "created": "Fri, 16 Aug 2019 18:48:22 GMT"}, {"version": "v3", "created": "Mon, 28 Oct 2019 18:03:08 GMT"}], "update_date": "2019-10-30", "authors_parsed": [["Sinha", "Samarth", ""], ["Ebrahimi", "Sayna", ""], ["Darrell", "Trevor", ""]]}, {"id": "1904.00374", "submitter": "Ben Day", "authors": "Enxhell Luzhnica, Ben Day and Pietro Lio'", "title": "Clique pooling for graph classification", "comments": "Under review as a workshop paper at RLGM 2019 @ ICML", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a novel graph pooling operation using cliques as the unit pool. As\nthis approach is purely topological, rather than featural, it is more readily\ninterpretable, a better analogue to image coarsening than filtering or pruning\ntechniques, and entirely nonparametric. The operation is implemented within\ngraph convolution network (GCN) and GraphSAGE architectures and tested against\nstandard graph classification benchmarks. In addition, we explore the backwards\ncompatibility of the pooling to regular graphs, demonstrating competitive\nperformance when replacing two-by-two pooling in standard convolutional neural\nnetworks (CNNs) with our mechanism.\n", "versions": [{"version": "v1", "created": "Sun, 31 Mar 2019 10:17:50 GMT"}, {"version": "v2", "created": "Tue, 9 Apr 2019 13:19:11 GMT"}], "update_date": "2019-04-10", "authors_parsed": [["Luzhnica", "Enxhell", ""], ["Day", "Ben", ""], ["Lio'", "Pietro", ""]]}, {"id": "1904.00377", "submitter": "Mones Raslan", "authors": "Gitta Kutyniok, Philipp Petersen, Mones Raslan, Reinhold Schneider", "title": "A Theoretical Analysis of Deep Neural Networks and Parametric PDEs", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.NA cs.LG cs.NA math.FA stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We derive upper bounds on the complexity of ReLU neural networks\napproximating the solution maps of parametric partial differential equations.\nIn particular, without any knowledge of its concrete shape, we use the inherent\nlow-dimensionality of the solution manifold to obtain approximation rates which\nare significantly superior to those provided by classical neural network\napproximation results. Concretely, we use the existence of a small reduced\nbasis to construct, for a large variety of parametric partial differential\nequations, neural networks that yield approximations of the parametric solution\nmaps in such a way that the sizes of these networks essentially only depend on\nthe size of the reduced basis.\n", "versions": [{"version": "v1", "created": "Sun, 31 Mar 2019 10:51:16 GMT"}, {"version": "v2", "created": "Mon, 1 Jul 2019 12:14:13 GMT"}, {"version": "v3", "created": "Thu, 14 May 2020 12:34:55 GMT"}], "update_date": "2020-05-15", "authors_parsed": [["Kutyniok", "Gitta", ""], ["Petersen", "Philipp", ""], ["Raslan", "Mones", ""], ["Schneider", "Reinhold", ""]]}, {"id": "1904.00435", "submitter": "Huyan Huang", "authors": "Huyan Huang, Yipeng Liu, Ce Zhu", "title": "Robust Low-Rank Tensor Ring Completion", "comments": null, "journal-ref": null, "doi": "10.1109/TCI.2020.3006718", "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Low-rank tensor completion recovers missing entries based on different tensor\ndecompositions. Due to its outstanding performance in exploiting some\nhigher-order data structure, low rank tensor ring has been applied in tensor\ncompletion. To further deal with its sensitivity to sparse component as it does\nin tensor principle component analysis, we propose robust tensor ring\ncompletion (RTRC), which separates latent low-rank tensor component from sparse\ncomponent with limited number of measurements. The low rank tensor component is\nconstrained by the weighted sum of nuclear norms of its balanced unfoldings,\nwhile the sparse component is regularized by its l1 norm. We analyze the RTRC\nmodel and gives the exact recovery guarantee. The alternating direction method\nof multipliers is used to divide the problem into several sub-problems with\nfast solutions. In numerical experiments, we verify the recovery condition of\nthe proposed method on synthetic data, and show the proposed method outperforms\nthe state-of-the-art ones in terms of both accuracy and computational\ncomplexity in a number of real-world data based tasks, i.e., light-field image\nrecovery, shadow removal in face images, and background extraction in color\nvideo.\n", "versions": [{"version": "v1", "created": "Sun, 31 Mar 2019 15:33:13 GMT"}, {"version": "v2", "created": "Wed, 17 Apr 2019 01:49:21 GMT"}, {"version": "v3", "created": "Thu, 23 Apr 2020 08:25:00 GMT"}], "update_date": "2020-07-14", "authors_parsed": [["Huang", "Huyan", ""], ["Liu", "Yipeng", ""], ["Zhu", "Ce", ""]]}, {"id": "1904.00438", "submitter": "George Adam", "authors": "George Adam, Jonathan Lorraine", "title": "Understanding Neural Architecture Search Techniques", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Automatic methods for generating state-of-the-art neural network\narchitectures without human experts have generated significant attention\nrecently. This is because of the potential to remove human experts from the\ndesign loop which can reduce costs and decrease time to model deployment.\nNeural architecture search (NAS) techniques have improved significantly in\ntheir computational efficiency since the original NAS was proposed. This\nreduction in computation is enabled via weight sharing such as in Efficient\nNeural Architecture Search (ENAS). However, recently a body of work confirms\nour discovery that ENAS does not do significantly better than random search\nwith weight sharing, contradicting the initial claims of the authors. We\nprovide an explanation for this phenomenon by investigating the\ninterpretability of the ENAS controller's hidden state. We find models sampled\nfrom identical controller hidden states have no correlation with various graph\nsimilarity metrics, so no notion of structural similarity is learned. This\nfailure mode implies the RNN controller does not condition on past architecture\nchoices. Lastly, we propose a solution to this failure mode by forcing the\ncontroller's hidden state to encode pasts decisions by training it with a\nmemory buffer of previously sampled architectures. Doing this improves hidden\nstate interpretability by increasing the correlation between controller hidden\nstates and graph similarity metrics.\n", "versions": [{"version": "v1", "created": "Sun, 31 Mar 2019 15:48:49 GMT"}, {"version": "v2", "created": "Thu, 21 Nov 2019 17:49:27 GMT"}], "update_date": "2019-11-22", "authors_parsed": [["Adam", "George", ""], ["Lorraine", "Jonathan", ""]]}, {"id": "1904.00442", "submitter": "Diogo Pernes", "authors": "Diogo Pernes and Jaime S. Cardoso", "title": "SpaMHMM: Sparse Mixture of Hidden Markov Models for Graph Connected\n  Entities", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a framework to model the distribution of sequential data coming\nfrom a set of entities connected in a graph with a known topology. The method\nis based on a mixture of shared hidden Markov models (HMMs), which are jointly\ntrained in order to exploit the knowledge of the graph structure and in such a\nway that the obtained mixtures tend to be sparse. Experiments in different\napplication domains demonstrate the effectiveness and versatility of the\nmethod.\n", "versions": [{"version": "v1", "created": "Sun, 31 Mar 2019 16:18:56 GMT"}], "update_date": "2019-04-02", "authors_parsed": [["Pernes", "Diogo", ""], ["Cardoso", "Jaime S.", ""]]}, {"id": "1904.00445", "submitter": "Nicholas Heller", "authors": "Nicholas Heller, Niranjan Sathianathen, Arveen Kalapara, Edward\n  Walczak, Keenan Moore, Heather Kaluzniak, Joel Rosenberg, Paul Blake, Zachary\n  Rengel, Makinna Oestreich, Joshua Dean, Michael Tradewell, Aneri Shah, Resha\n  Tejpaul, Zachary Edgerton, Matthew Peterson, Shaneabbas Raza, Subodh Regmi,\n  Nikolaos Papanikolopoulos, and Christopher Weight", "title": "The KiTS19 Challenge Data: 300 Kidney Tumor Cases with Clinical Context,\n  CT Semantic Segmentations, and Surgical Outcomes", "comments": "13 pages, 2 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.QM cs.LG stat.ML", "license": "http://creativecommons.org/publicdomain/zero/1.0/", "abstract": "  The morphometry of a kidney tumor revealed by contrast-enhanced Computed\nTomography (CT) imaging is an important factor in clinical decision making\nsurrounding the lesion's diagnosis and treatment. Quantitative study of the\nrelationship between kidney tumor morphology and clinical outcomes is difficult\ndue to data scarcity and the laborious nature of manually quantifying imaging\npredictors. Automatic semantic segmentation of kidneys and kidney tumors is a\npromising tool towards automatically quantifying a wide array of morphometric\nfeatures, but no sizeable annotated dataset is currently available to train\nmodels for this task. We present the KiTS19 challenge dataset: A collection of\nmulti-phase CT imaging, segmentation masks, and comprehensive clinical outcomes\nfor 300 patients who underwent nephrectomy for kidney tumors at our center\nbetween 2010 and 2018. 210 (70%) of these patients were selected at random as\nthe training set for the 2019 MICCAI KiTS Kidney Tumor Segmentation Challenge\nand have been released publicly. With the presence of clinical context and\nsurgical outcomes, this data can serve not only for benchmarking semantic\nsegmentation models, but also for developing and studying biomarkers which make\nuse of the imaging and semantic segmentation masks.\n", "versions": [{"version": "v1", "created": "Sun, 31 Mar 2019 16:56:10 GMT"}, {"version": "v2", "created": "Sun, 15 Mar 2020 14:06:45 GMT"}], "update_date": "2020-03-17", "authors_parsed": [["Heller", "Nicholas", ""], ["Sathianathen", "Niranjan", ""], ["Kalapara", "Arveen", ""], ["Walczak", "Edward", ""], ["Moore", "Keenan", ""], ["Kaluzniak", "Heather", ""], ["Rosenberg", "Joel", ""], ["Blake", "Paul", ""], ["Rengel", "Zachary", ""], ["Oestreich", "Makinna", ""], ["Dean", "Joshua", ""], ["Tradewell", "Michael", ""], ["Shah", "Aneri", ""], ["Tejpaul", "Resha", ""], ["Edgerton", "Zachary", ""], ["Peterson", "Matthew", ""], ["Raza", "Shaneabbas", ""], ["Regmi", "Subodh", ""], ["Papanikolopoulos", "Nikolaos", ""], ["Weight", "Christopher", ""]]}, {"id": "1904.00469", "submitter": "Luca Ambrogioni", "authors": "Luca Ambrogioni and Marcel A. J. van Gerven", "title": "Perturbative estimation of stochastic gradients", "comments": "Needs improvements, the experiments are too limited", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we introduce a family of stochastic gradient estimation\ntechniques based of the perturbative expansion around the mean of the sampling\ndistribution. We characterize the bias and variance of the resulting\nTaylor-corrected estimators using the Lagrange error formula. Furthermore, we\nintroduce a family of variance reduction techniques that can be applied to\nother gradient estimators. Finally, we show that these new perturbative methods\ncan be extended to discrete functions using analytic continuation. Using this\ntechnique, we derive a new gradient descent method for training stochastic\nnetworks with binary weights. In our experiments, we show that the perturbative\ncorrection improves the convergence of stochastic variational inference both in\nthe continuous and in the discrete case.\n", "versions": [{"version": "v1", "created": "Sun, 31 Mar 2019 20:00:50 GMT"}, {"version": "v2", "created": "Fri, 5 Apr 2019 09:09:48 GMT"}, {"version": "v3", "created": "Mon, 8 Apr 2019 11:30:54 GMT"}, {"version": "v4", "created": "Fri, 15 Nov 2019 08:35:16 GMT"}], "update_date": "2019-11-18", "authors_parsed": [["Ambrogioni", "Luca", ""], ["van Gerven", "Marcel A. J.", ""]]}, {"id": "1904.00479", "submitter": "Will Wei Sun", "authors": "Botao Hao, Boxiang Wang, Pengyuan Wang, Jingfei Zhang, Jian Yang, Will\n  Wei Sun", "title": "Sparse Tensor Additive Regression", "comments": "Accepted by Journal of Machine Learning Research", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Tensors are becoming prevalent in modern applications such as medical imaging\nand digital marketing. In this paper, we propose a sparse tensor additive\nregression (STAR) that models a scalar response as a flexible nonparametric\nfunction of tensor covariates. The proposed model effectively exploits the\nsparse and low-rank structures in the tensor additive regression. We formulate\nthe parameter estimation as a non-convex optimization problem, and propose an\nefficient penalized alternating minimization algorithm. We establish a\nnon-asymptotic error bound for the estimator obtained from each iteration of\nthe proposed algorithm, which reveals an interplay between the optimization\nerror and the statistical rate of convergence. We demonstrate the efficacy of\nSTAR through extensive comparative simulation studies, and an application to\nthe click-through-rate prediction in online advertising.\n", "versions": [{"version": "v1", "created": "Sun, 31 Mar 2019 20:45:50 GMT"}, {"version": "v2", "created": "Mon, 16 Sep 2019 13:58:39 GMT"}, {"version": "v3", "created": "Fri, 5 Mar 2021 16:31:58 GMT"}], "update_date": "2021-03-08", "authors_parsed": [["Hao", "Botao", ""], ["Wang", "Boxiang", ""], ["Wang", "Pengyuan", ""], ["Zhang", "Jingfei", ""], ["Yang", "Jian", ""], ["Sun", "Will Wei", ""]]}, {"id": "1904.00507", "submitter": "Soumyabrata Pal", "authors": "Arya Mazumdar, Soumyabrata Pal", "title": "Semisupervised Clustering by Queries and Locally Encodable Source Coding", "comments": "16 pages, 11 figures. Some of the results of this paper have appeared\n  in the proceedings of the 2017 Conference on Neural Information Processing\n  Systems (NeurIPS 2017)", "journal-ref": "IEEE Transactions on Information Theory, 2020", "doi": null, "report-no": null, "categories": "stat.ML cs.IT cs.LG math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Source coding is the canonical problem of data compression in information\ntheory. In a locally encodable source coding, each compressed bit depends on\nonly few bits of the input. In this paper, we show that a recently popular\nmodel of semi-supervised clustering is equivalent to locally encodable source\ncoding. In this model, the task is to perform multiclass labeling of unlabeled\nelements. At the beginning, we can ask in parallel a set of simple queries to\nan oracle who provides (possibly erroneous) binary answers to the queries. The\nqueries cannot involve more than two (or a fixed constant number of) elements.\nNow the labeling of all the elements (or clustering) must be performed based on\nthe noisy query answers. The goal is to recover all the correct labelings while\nminimizing the number of such queries. The equivalence to locally encodable\nsource codes leads us to find lower bounds on the number of queries required in\na variety of scenarios. We provide querying schemes based on pairwise `same\ncluster' queries - and pairwise AND queries and show provable performance\nguarantees for each of the schemes.\n", "versions": [{"version": "v1", "created": "Sun, 31 Mar 2019 23:16:45 GMT"}, {"version": "v2", "created": "Mon, 9 Nov 2020 08:40:23 GMT"}], "update_date": "2020-11-10", "authors_parsed": [["Mazumdar", "Arya", ""], ["Pal", "Soumyabrata", ""]]}, {"id": "1904.00511", "submitter": "Xinlei Pan", "authors": "Xinlei Pan, Daniel Seita, Yang Gao, John Canny", "title": "Risk Averse Robust Adversarial Reinforcement Learning", "comments": "ICRA 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.RO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep reinforcement learning has recently made significant progress in solving\ncomputer games and robotic control tasks. A known problem, though, is that\npolicies overfit to the training environment and may not avoid rare,\ncatastrophic events such as automotive accidents. A classical technique for\nimproving the robustness of reinforcement learning algorithms is to train on a\nset of randomized environments, but this approach only guards against common\nsituations. Recently, robust adversarial reinforcement learning (RARL) was\ndeveloped, which allows efficient applications of random and systematic\nperturbations by a trained adversary. A limitation of RARL is that only the\nexpected control objective is optimized; there is no explicit modeling or\noptimization of risk. Thus the agents do not consider the probability of\ncatastrophic events (i.e., those inducing abnormally large negative reward),\nexcept through their effect on the expected objective. In this paper we\nintroduce risk-averse robust adversarial reinforcement learning (RARARL), using\na risk-averse protagonist and a risk-seeking adversary. We test our approach on\na self-driving vehicle controller. We use an ensemble of policy networks to\nmodel risk as the variance of value functions. We show through experiments that\na risk-averse agent is better equipped to handle a risk-seeking adversary, and\nexperiences substantially fewer crashes compared to agents trained without an\nadversary.\n", "versions": [{"version": "v1", "created": "Sun, 31 Mar 2019 23:46:26 GMT"}], "update_date": "2019-04-02", "authors_parsed": [["Pan", "Xinlei", ""], ["Seita", "Daniel", ""], ["Gao", "Yang", ""], ["Canny", "John", ""]]}, {"id": "1904.00516", "submitter": "Subbayya Sastry Pidaparthy", "authors": "Soumyajit Mitra and P S Sastry", "title": "Summarizing Event Sequences with Serial Episodes: A Statistical Model\n  and an Application", "comments": "12 pages. Under review for IEEE TKDE", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we address the problem of discovering a small set of frequent\nserial episodes from sequential data so as to adequately characterize or\nsummarize the data. We discuss an algorithm based on the Minimum Description\nLength (MDL) principle and the algorithm is a slight modification of an earlier\nmethod, called CSC-2. We present a novel generative model for sequence data\ncontaining prominent pairs of serial episodes and, using this, provide some\nstatistical justification for the algorithm. We believe this is the first\ninstance of such a statistical justification for an MDL based algorithm for\nsummarizing event sequence data. We then present a novel application of this\ndata mining algorithm in text classification. By considering text documents as\ntemporal sequences of words, the data mining algorithm can find a set of\ncharacteristic episodes for all the training data as a whole. The words that\nare part of these characteristic episodes could then be considered the only\nrelevant words for the dictionary thus resulting in a considerably reduced\nfeature vector dimension. We show, through simulation experiments using\nbenchmark data sets, that the discovered frequent episodes can be used to\nachieve more than four-fold reduction in dictionary size without losing any\nclassification accuracy.\n", "versions": [{"version": "v1", "created": "Mon, 1 Apr 2019 00:29:15 GMT"}], "update_date": "2019-04-02", "authors_parsed": [["Mitra", "Soumyajit", ""], ["Sastry", "P S", ""]]}, {"id": "1904.00542", "submitter": "Ramy Baly", "authors": "Ramy Baly (MIT Computer Science and Artificial Intelligence\n  Laboratory, MA, USA) and Georgi Karadzhov (SiteGround Hosting EOOD, Bulgaria)\n  and Abdelrhman Saleh (Harvard University, MA, USA) and James Glass (MIT\n  Computer Science and Artificial Intelligence Laboratory, MA, USA) and Preslav\n  Nakov (Qatar Computing Research Institute, HBKU, Qatar)", "title": "Multi-Task Ordinal Regression for Jointly Predicting the Trustworthiness\n  and the Leading Political Ideology of News Media", "comments": "Fact-checking, political ideology, news media, NAACL-2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In the context of fake news, bias, and propaganda, we study two important but\nrelatively under-explored problems: (i) trustworthiness estimation (on a\n3-point scale) and (ii) political ideology detection (left/right bias on a\n7-point scale) of entire news outlets, as opposed to evaluating individual\narticles. In particular, we propose a multi-task ordinal regression framework\nthat models the two problems jointly. This is motivated by the observation that\nhyper-partisanship is often linked to low trustworthiness, e.g., appealing to\nemotions rather than sticking to the facts, while center media tend to be\ngenerally more impartial and trustworthy. We further use several auxiliary\ntasks, modeling centrality, hyperpartisanship, as well as left-vs.-right bias\non a coarse-grained scale. The evaluation results show sizable performance\ngains by the joint models over models that target the problems in isolation.\n", "versions": [{"version": "v1", "created": "Mon, 1 Apr 2019 02:54:54 GMT"}], "update_date": "2019-04-02", "authors_parsed": [["Baly", "Ramy", "", "MIT Computer Science and Artificial Intelligence\n  Laboratory, MA, USA"], ["Karadzhov", "Georgi", "", "SiteGround Hosting EOOD, Bulgaria"], ["Saleh", "Abdelrhman", "", "Harvard University, MA, USA"], ["Glass", "James", "", "MIT\n  Computer Science and Artificial Intelligence Laboratory, MA, USA"], ["Nakov", "Preslav", "", "Qatar Computing Research Institute, HBKU, Qatar"]]}, {"id": "1904.00548", "submitter": "Yaniv Shulman", "authors": "Yaniv Shulman", "title": "Unsupervised Contextual Anomaly Detection using Joint Deep Variational\n  Generative Models", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A method for unsupervised contextual anomaly detection is proposed using a\ncross-linked pair of Variational Auto-Encoders for assigning a normality score\nto an observation. The method enables a distinct separation of contextual from\nbehavioral attributes and is robust to the presence of anomalous or novel\ncontextual attributes. The method can be trained with data sets that contain\nanomalies without any special pre-processing.\n", "versions": [{"version": "v1", "created": "Mon, 1 Apr 2019 03:39:01 GMT"}], "update_date": "2019-04-02", "authors_parsed": [["Shulman", "Yaniv", ""]]}, {"id": "1904.00561", "submitter": "Matthew Britton", "authors": "Matthew Britton", "title": "VINE: Visualizing Statistical Interactions in Black Box Models", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by-sa/4.0/", "abstract": "  As machine learning becomes more pervasive, there is an urgent need for\ninterpretable explanations of predictive models. Prior work has developed\neffective methods for visualizing global model behavior, as well as generating\nlocal (instance-specific) explanations. However, relatively little work has\naddressed regional explanations - how groups of similar instances behave in a\ncomplex model, and the related issue of visualizing statistical feature\ninteractions. The lack of utilities available for these analytical needs\nhinders the development of models that are mission-critical, transparent, and\nalign with social goals. We present VINE (Visual INteraction Effects), a novel\nalgorithm to extract and visualize statistical interaction effects in black box\nmodels. We also present a novel evaluation metric for visualizations in the\ninterpretable ML space.\n", "versions": [{"version": "v1", "created": "Mon, 1 Apr 2019 04:42:07 GMT"}], "update_date": "2019-04-02", "authors_parsed": [["Britton", "Matthew", ""]]}, {"id": "1904.00562", "submitter": "Wanli Wang", "authors": "Jinguang Sun, Wanli Wang, Xian Wei, Li Fang, Xiaoliang Tang, Yusheng\n  Xu, Hui Yu and Wei Yao", "title": "Deep Clustering With Intra-class Distance Constraint for Hyperspectral\n  Images", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG eess.IV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The high dimensionality of hyperspectral images often results in the\ndegradation of clustering performance. Due to the powerful ability of deep\nfeature extraction and non-linear feature representation, the clustering\nalgorithm based on deep learning has become a hot research topic in the field\nof hyperspectral remote sensing. However, most deep clustering algorithms for\nhyperspectral images utilize deep neural networks as feature extractor without\nconsidering prior knowledge constraints that are suitable for clustering. To\nsolve this problem, we propose an intra-class distance constrained deep\nclustering algorithm for high-dimensional hyperspectral images. The proposed\nalgorithm constrains the feature mapping procedure of the auto-encoder network\nby intra-class distance so that raw images are transformed from the original\nhigh-dimensional space to the low-dimensional feature space that is more\nconducive to clustering. Furthermore, the related learning process is treated\nas a joint optimization problem of deep feature extraction and clustering.\nExperimental results demonstrate the intense competitiveness of the proposed\nalgorithm in comparison with state-of-the-art clustering methods of\nhyperspectral images.\n", "versions": [{"version": "v1", "created": "Mon, 1 Apr 2019 04:42:18 GMT"}], "update_date": "2019-04-02", "authors_parsed": [["Sun", "Jinguang", ""], ["Wang", "Wanli", ""], ["Wei", "Xian", ""], ["Fang", "Li", ""], ["Tang", "Xiaoliang", ""], ["Xu", "Yusheng", ""], ["Yu", "Hui", ""], ["Yao", "Wei", ""]]}, {"id": "1904.00575", "submitter": "Cheng Cheng", "authors": "Wenqian Jiang, Cheng Cheng, Beitong Zhou, Guijun Ma and Ye Yuan", "title": "A Novel GAN-based Fault Diagnosis Approach for Imbalanced Industrial\n  Time Series", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper proposes a novel fault diagnosis approach based on generative\nadversarial networks (GAN) for imbalanced industrial time series where normal\nsamples are much larger than failure cases. We combine a well-designed feature\nextractor with GAN to help train the whole network. Aimed at obtaining data\ndistribution and hidden pattern in both original distinguishing features and\nlatent space, the encoder-decoder-encoder three-sub-network is employed in GAN,\nbased on Deep Convolution Generative Adversarial Networks (DCGAN) but without\nTanh activation layer and only trained on normal samples. In order to verify\nthe validity and feasibility of our approach, we test it on rolling bearing\ndata from Case Western Reserve University and further verify it on data\ncollected from our laboratory. The results show that our proposed approach can\nachieve excellent performance in detecting faulty by outputting much larger\nevaluation scores.\n", "versions": [{"version": "v1", "created": "Mon, 1 Apr 2019 06:11:44 GMT"}], "update_date": "2019-04-02", "authors_parsed": [["Jiang", "Wenqian", ""], ["Cheng", "Cheng", ""], ["Zhou", "Beitong", ""], ["Ma", "Guijun", ""], ["Yuan", "Ye", ""]]}, {"id": "1904.00577", "submitter": "Weilin Zhou", "authors": "Weilin Zhou, Frederic Precioso", "title": "Adaptive Bayesian Linear Regression for Automated Machine Learning", "comments": "Added references;Corrected typos.Revised argument,results unchanged", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  To solve a machine learning problem, one typically needs to perform data\npreprocessing, modeling, and hyperparameter tuning, which is known as model\nselection and hyperparameter optimization.The goal of automated machine\nlearning (AutoML) is to design methods that can automatically perform model\nselection and hyperparameter optimization without human interventions for a\ngiven dataset. In this paper, we propose a meta-learning method that can search\nfor a high-performance machine learning pipeline from the predefined set of\ncandidate pipelines for supervised classification datasets in an efficient way\nby leveraging meta-data collected from previous experiments. More specifically,\nour method combines an adaptive Bayesian regression model with a neural network\nbasis function and the acquisition function from Bayesian optimization. The\nadaptive Bayesian regression model is able to capture knowledge from previous\nmeta-data and thus make predictions of the performances of machine learning\npipelines on a new dataset. The acquisition function is then used to guide the\nsearch of possible pipelines based on the predictions.The experiments\ndemonstrate that our approach can quickly identify high-performance pipelines\nfor a range of test datasets and outperforms the baseline methods.\n", "versions": [{"version": "v1", "created": "Mon, 1 Apr 2019 06:21:31 GMT"}, {"version": "v2", "created": "Thu, 18 Apr 2019 03:47:00 GMT"}], "update_date": "2019-04-19", "authors_parsed": [["Zhou", "Weilin", ""], ["Precioso", "Frederic", ""]]}, {"id": "1904.00583", "submitter": "Xiaolie Li", "authors": "Jing Chi, Xiaolei Li, Haozhong Wang, Dazhi Gao, Peter Gerstoft", "title": "Sound source ranging using a feed-forward neural network with\n  fitting-based early stopping", "comments": null, "journal-ref": null, "doi": "10.1121/1.5126115", "report-no": null, "categories": "cs.LG cs.SD eess.SP physics.comp-ph stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  When a feed-forward neural network (FNN) is trained for source ranging in an\nocean waveguide, it is difficult evaluating the range accuracy of the FNN on\nunlabeled test data. A fitting-based early stopping (FEAST) method is\nintroduced to evaluate the range error of the FNN on test data where the\ndistance of source is unknown. Based on FEAST, when the evaluated range error\nof the FNN reaches the minimum on test data, stopping training, which will help\nto improve the ranging accuracy of the FNN on the test data. The FEAST is\ndemonstrated on simulated and experimental data.\n", "versions": [{"version": "v1", "created": "Mon, 1 Apr 2019 06:36:33 GMT"}], "update_date": "2019-10-23", "authors_parsed": [["Chi", "Jing", ""], ["Li", "Xiaolei", ""], ["Wang", "Haozhong", ""], ["Gao", "Dazhi", ""], ["Gerstoft", "Peter", ""]]}, {"id": "1904.00601", "submitter": "Mohit Sharma", "authors": "Mohit K.Sharma, Alessio Zappone, Mohamad Assaad, Merouane Debbah,\n  Spyridon Vassilaras", "title": "Distributed Power Control for Large Energy Harvesting Networks: A\n  Multi-Agent Deep Reinforcement Learning Approach", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.IT math.IT stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we develop a multi-agent reinforcement learning (MARL)\nframework to obtain online power control policies for a large energy harvesting\n(EH) multiple access channel, when only causal information about the EH process\nand wireless channel is available. In the proposed framework, we model the\nonline power control problem as a discrete-time mean-field game (MFG), and\nanalytically show that the MFG has a unique stationary solution. Next, we\nleverage the fictitious play property of the mean-field games, and the deep\nreinforcement learning technique to learn the stationary solution of the game,\nin a completely distributed fashion. We analytically show that the proposed\nprocedure converges to the unique stationary solution of the MFG. This, in\nturn, ensures that the optimal policies can be learned in a completely\ndistributed fashion. In order to benchmark the performance of the distributed\npolicies, we also develop a deep neural network (DNN) based centralized as well\nas distributed online power control schemes. Our simulation results show the\nefficacy of the proposed power control policies. In particular, the DNN based\ncentralized power control policies provide a very good performance for large EH\nnetworks for which the design of optimal policies is intractable using the\nconventional methods such as Markov decision processes. Further, performance of\nboth the distributed policies is close to the throughput achieved by the\ncentralized policies.\n", "versions": [{"version": "v1", "created": "Mon, 1 Apr 2019 07:16:51 GMT"}, {"version": "v2", "created": "Tue, 22 Oct 2019 08:00:54 GMT"}], "update_date": "2019-10-23", "authors_parsed": [["Sharma", "Mohit K.", ""], ["Zappone", "Alessio", ""], ["Assaad", "Mohamad", ""], ["Debbah", "Merouane", ""], ["Vassilaras", "Spyridon", ""]]}, {"id": "1904.00623", "submitter": "Yu-Jung Heo", "authors": "Yu-Jung Heo, Kyoung-Woon On, Seongho Choi, Jaeseo Lim, Jinah Kim,\n  Jeh-Kwang Ryu, Byung-Chull Bae and Byoung-Tak Zhang", "title": "Constructing Hierarchical Q&A Datasets for Video Story Understanding", "comments": "Accepted to AAAI 2019 Spring Symposium Series : Story-Enabled\n  Intelligence", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.CV cs.LG cs.MM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Video understanding is emerging as a new paradigm for studying human-like AI.\nQuestion-and-Answering (Q&A) is used as a general benchmark to measure the\nlevel of intelligence for video understanding. While several previous studies\nhave suggested datasets for video Q&A tasks, they did not really incorporate\nstory-level understanding, resulting in highly-biased and lack of variance in\ndegree of question difficulty. In this paper, we propose a hierarchical method\nfor building Q&A datasets, i.e. hierarchical difficulty levels. We introduce\nthree criteria for video story understanding, i.e. memory capacity, logical\ncomplexity, and DIKW (Data-Information-Knowledge-Wisdom) pyramid. We discuss\nhow three-dimensional map constructed from these criteria can be used as a\nmetric for evaluating the levels of intelligence relating to video story\nunderstanding.\n", "versions": [{"version": "v1", "created": "Mon, 1 Apr 2019 08:05:19 GMT"}], "update_date": "2019-04-02", "authors_parsed": [["Heo", "Yu-Jung", ""], ["On", "Kyoung-Woon", ""], ["Choi", "Seongho", ""], ["Lim", "Jaeseo", ""], ["Kim", "Jinah", ""], ["Ryu", "Jeh-Kwang", ""], ["Bae", "Byung-Chull", ""], ["Zhang", "Byoung-Tak", ""]]}, {"id": "1904.00641", "submitter": "Kan Wu", "authors": "Kan Wu, Guanbin Li, Haofeng Li, Jianjun Zhang, Yizhou Yu", "title": "Harvesting Visual Objects from Internet Images via Deep Learning Based\n  Objectness Assessment", "comments": "Accepted by ACM Transactions on Multimedia Computing, Communications\n  and Applications", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The collection of internet images has been growing in an astonishing speed.\nIt is undoubted that these images contain rich visual information that can be\nuseful in many applications, such as visual media creation and data-driven\nimage synthesis. In this paper, we focus on the methodologies for building a\nvisual object database from a collection of internet images. Such database is\nbuilt to contain a large number of high-quality visual objects that can help\nwith various data-driven image applications. Our method is based on dense\nproposal generation and objectness-based re-ranking. A novel deep convolutional\nneural network is designed for the inference of proposal objectness, the\nprobability of a proposal containing optimally-located foreground object. In\nour work, the objectness is quantitatively measured in regard of completeness\nand fullness, reflecting two complementary features of an optimal proposal: a\ncomplete foreground and relatively small background. Our experiments indicate\nthat object proposals re-ranked according to the output of our network\ngenerally achieve higher performance than those produced by other\nstate-of-the-art methods. As a concrete example, a database of over 1.2 million\nvisual objects has been built using the proposed method, and has been\nsuccessfully used in various data-driven image applications.\n", "versions": [{"version": "v1", "created": "Mon, 1 Apr 2019 08:56:00 GMT"}], "update_date": "2019-04-02", "authors_parsed": [["Wu", "Kan", ""], ["Li", "Guanbin", ""], ["Li", "Haofeng", ""], ["Zhang", "Jianjun", ""], ["Yu", "Yizhou", ""]]}, {"id": "1904.00655", "submitter": "Pankaj Malhotra", "authors": "Priyanka Gupta, Pankaj Malhotra, Jyoti Narwariya, Lovekesh Vig, Gautam\n  Shroff", "title": "Transfer Learning for Clinical Time Series Analysis using Deep Neural\n  Networks", "comments": "Updated version of this work appeared in Journal of Healthcare\n  Informatics Research, Vol. 4, 2020. arXiv admin note: text overlap with\n  arXiv:1807.01705", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep neural networks have shown promising results for various clinical\nprediction tasks. However, training deep networks such as those based on\nRecurrent Neural Networks (RNNs) requires large labeled data, significant\nhyper-parameter tuning effort and expertise, and high computational resources.\nIn this work, we investigate as to what extent can transfer learning address\nthese issues when using deep RNNs to model multivariate clinical time series.\nWe consider two scenarios for transfer learning using RNNs: i)\ndomain-adaptation, i.e., leveraging a deep RNN - namely, TimeNet - pre-trained\nfor feature extraction on time series from diverse domains, and adapting it for\nfeature extraction and subsequent target tasks in healthcare domain, ii)\ntask-adaptation, i.e., pre-training a deep RNN - namely, HealthNet - on diverse\ntasks in healthcare domain, and adapting it to new target tasks in the same\ndomain. We evaluate the above approaches on publicly available MIMIC-III\nbenchmark dataset, and demonstrate that (a) computationally-efficient linear\nmodels trained using features extracted via pre-trained RNNs outperform or, in\nthe worst case, perform as well as deep RNNs and statistical hand-crafted\nfeatures based models trained specifically for target task; (b) models obtained\nby adapting pre-trained models for target tasks are significantly more robust\nto the size of labeled data compared to task-specific RNNs, while also being\ncomputationally efficient. We, therefore, conclude that pre-trained deep models\nlike TimeNet and HealthNet allow leveraging the advantages of deep learning for\nclinical time series analysis tasks, while also minimize dependence on\nhand-crafted features, deal robustly with scarce labeled training data\nscenarios without overfitting, as well as reduce dependence on expertise and\nresources required to train deep networks from scratch.\n", "versions": [{"version": "v1", "created": "Mon, 1 Apr 2019 09:31:34 GMT"}, {"version": "v2", "created": "Thu, 4 Mar 2021 13:11:04 GMT"}], "update_date": "2021-03-05", "authors_parsed": [["Gupta", "Priyanka", ""], ["Malhotra", "Pankaj", ""], ["Narwariya", "Jyoti", ""], ["Vig", "Lovekesh", ""], ["Shroff", "Gautam", ""]]}, {"id": "1904.00670", "submitter": "Borislav Ikonomov", "authors": "Borislav Ikonomov, Michael U. Gutmann", "title": "Robust Optimisation Monte Carlo", "comments": "8 pages + 6 page appendix; v2: made clarifications, added a second\n  possible algorithm implementation and its results; v3: small clarifications,\n  to be published in AISTATS 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG stat.CO stat.ME", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper is on Bayesian inference for parametric statistical models that\nare defined by a stochastic simulator which specifies how data is generated.\nExact sampling is then possible but evaluating the likelihood function is\ntypically prohibitively expensive. Approximate Bayesian Computation (ABC) is a\nframework to perform approximate inference in such situations. While basic ABC\nalgorithms are widely applicable, they are notoriously slow and much research\nhas focused on increasing their efficiency. Optimisation Monte Carlo (OMC) has\nrecently been proposed as an efficient and embarrassingly parallel method that\nleverages optimisation to accelerate the inference. In this paper, we\ndemonstrate an important previously unrecognised failure mode of OMC: It\ngenerates strongly overconfident approximations by collapsing regions of\nsimilar or near-constant likelihood into a single point. We propose an\nefficient, robust generalisation of OMC that corrects this. It makes fewer\nassumptions, retains the main benefits of OMC, and can be performed either as\npost-processing to OMC or as a stand-alone computation. We demonstrate the\neffectiveness of the proposed Robust OMC on toy examples and tasks in\ninverse-graphics where we perform Bayesian inference with a complex image\nrenderer.\n", "versions": [{"version": "v1", "created": "Mon, 1 Apr 2019 09:50:41 GMT"}, {"version": "v2", "created": "Wed, 20 Nov 2019 15:54:56 GMT"}, {"version": "v3", "created": "Fri, 28 Feb 2020 13:45:56 GMT"}], "update_date": "2020-03-02", "authors_parsed": [["Ikonomov", "Borislav", ""], ["Gutmann", "Michael U.", ""]]}, {"id": "1904.00687", "submitter": "Gilad Yehudai", "authors": "Gilad Yehudai and Ohad Shamir", "title": "On the Power and Limitations of Random Features for Understanding Neural\n  Networks", "comments": "Comparison to previous version: Fixed a bug in the proof of Theorem\n  4.1. Changed the polynomial dependency of ||w^*|| in Theorem 4.1 from d^2 to\n  d^3 and of |b^*| from O(d^3) to O(d^4)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recently, a spate of papers have provided positive theoretical results for\ntraining over-parameterized neural networks (where the network size is larger\nthan what is needed to achieve low error). The key insight is that with\nsufficient over-parameterization, gradient-based methods will implicitly leave\nsome components of the network relatively unchanged, so the optimization\ndynamics will behave as if those components are essentially fixed at their\ninitial random values. In fact, fixing these explicitly leads to the well-known\napproach of learning with random features. In other words, these techniques\nimply that we can successfully learn with neural networks, whenever we can\nsuccessfully learn with random features. In this paper, we first review these\ntechniques, providing a simple and self-contained analysis for one-hidden-layer\nnetworks. We then argue that despite the impressive positive results, random\nfeature approaches are also inherently limited in what they can explain. In\nparticular, we rigorously show that random features cannot be used to learn\neven a single ReLU neuron with standard Gaussian inputs, unless the network\nsize (or magnitude of the weights) is exponentially large. Since a single\nneuron is learnable with gradient-based methods, we conclude that we are still\nfar from a satisfying general explanation for the empirical success of neural\nnetworks.\n", "versions": [{"version": "v1", "created": "Mon, 1 Apr 2019 10:21:24 GMT"}, {"version": "v2", "created": "Thu, 13 Jun 2019 16:40:26 GMT"}, {"version": "v3", "created": "Wed, 4 Mar 2020 08:13:41 GMT"}], "update_date": "2020-03-05", "authors_parsed": [["Yehudai", "Gilad", ""], ["Shamir", "Ohad", ""]]}, {"id": "1904.00689", "submitter": "Olga Taran", "authors": "Olga Taran, Shideh Rezaeifar, Taras Holotyak, Slava Voloshynovskiy", "title": "Defending against adversarial attacks by randomized diversification", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The vulnerability of machine learning systems to adversarial attacks\nquestions their usage in many applications. In this paper, we propose a\nrandomized diversification as a defense strategy. We introduce a multi-channel\narchitecture in a gray-box scenario, which assumes that the architecture of the\nclassifier and the training data set are known to the attacker. The attacker\ndoes not only have access to a secret key and to the internal states of the\nsystem at the test time. The defender processes an input in multiple channels.\nEach channel introduces its own randomization in a special transform domain\nbased on a secret key shared between the training and testing stages. Such a\ntransform based randomization with a shared key preserves the gradients in\nkey-defined sub-spaces for the defender but it prevents gradient back\npropagation and the creation of various bypass systems for the attacker. An\nadditional benefit of multi-channel randomization is the aggregation that fuses\nsoft-outputs from all channels, thus increasing the reliability of the final\nscore. The sharing of a secret key creates an information advantage to the\ndefender. Experimental evaluation demonstrates an increased robustness of the\nproposed method to a number of known state-of-the-art attacks.\n", "versions": [{"version": "v1", "created": "Mon, 1 Apr 2019 10:27:33 GMT"}], "update_date": "2019-04-02", "authors_parsed": [["Taran", "Olga", ""], ["Rezaeifar", "Shideh", ""], ["Holotyak", "Taras", ""], ["Voloshynovskiy", "Slava", ""]]}, {"id": "1904.00690", "submitter": "Abdelrahim Ahmad", "authors": "Abdelrahim Kasem Ahmad, Assef Jafar and Kadan Aljoumaa", "title": "Customer churn prediction in telecom using machine learning and social\n  network analysis in big data platform", "comments": "24 pages, 14 figures. PDF https://rdcu.be/budKg", "journal-ref": "Journal of Big Data 2019 6:28", "doi": "10.1186/s40537-019-0191-6", "report-no": null, "categories": "cs.CY cs.DC cs.LG cs.SI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Customer churn is a major problem and one of the most important concerns for\nlarge companies. Due to the direct effect on the revenues of the companies,\nespecially in the telecom field, companies are seeking to develop means to\npredict potential customer to churn. Therefore, finding factors that increase\ncustomer churn is important to take necessary actions to reduce this churn. The\nmain contribution of our work is to develop a churn prediction model which\nassists telecom operators to predict customers who are most likely subject to\nchurn. The model developed in this work uses machine learning techniques on big\ndata platform and builds a new way of features' engineering and selection. In\norder to measure the performance of the model, the Area Under Curve (AUC)\nstandard measure is adopted, and the AUC value obtained is 93.3%. Another main\ncontribution is to use customer social network in the prediction model by\nextracting Social Network Analysis (SNA) features. The use of SNA enhanced the\nperformance of the model from 84 to 93.3% against AUC standard. The model was\nprepared and tested through Spark environment by working on a large dataset\ncreated by transforming big raw data provided by SyriaTel telecom company. The\ndataset contained all customers' information over 9 months, and was used to\ntrain, test, and evaluate the system at SyriaTel. The model experimented four\nalgorithms: Decision Tree, Random Forest, Gradient Boosted Machine Tree \"GBM\"\nand Extreme Gradient Boosting \"XGBOOST\". However, the best results were\nobtained by applying XGBOOST algorithm. This algorithm was used for\nclassification in this churn predictive model.\n", "versions": [{"version": "v1", "created": "Mon, 1 Apr 2019 10:30:04 GMT"}], "update_date": "2019-04-04", "authors_parsed": [["Ahmad", "Abdelrahim Kasem", ""], ["Jafar", "Assef", ""], ["Aljoumaa", "Kadan", ""]]}, {"id": "1904.00714", "submitter": "Evgeny Krivosheev", "authors": "Evgeny Krivosheev, Fabio Casati, Marcos Baez, Boualem Benatallah", "title": "Combining Crowd and Machines for Multi-predicate Item Screening", "comments": "Please cite the CSCW2018 version of this\n  paper:@article{krivosheev2018combining, title={Combining Crowd and Machines\n  for Multi-predicate Item Screening}, author={Krivosheev, Evgeny and Casati,\n  Fabio and Baez, Marcos and Benatallah, Boualem}, journal={Proceedings of the\n  ACM on Human-Computer Interaction}, volume={2}, number={CSCW}, pages={97},\n  year={2018}, publisher={ACM} }", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper discusses how crowd and machine classifiers can be efficiently\ncombined to screen items that satisfy a set of predicates. We show that this is\na recurring problem in many domains, present machine-human (hybrid) algorithms\nthat screen items efficiently and estimate the gain over human-only or\nmachine-only screening in terms of performance and cost. We further show how,\ngiven a new classification problem and a set of classifiers of unknown accuracy\nfor the problem at hand, we can identify how to manage the cost-accuracy trade\noff by progressively determining if we should spend budget to obtain test data\n(to assess the accuracy of the given classifiers), or to train an ensemble of\nclassifiers, or whether we should leverage the existing machine classifiers\nwith the crowd, and in this case how to efficiently combine them based on their\nestimated characteristics to obtain the classification. We demonstrate that the\ntechniques we propose obtain significant cost/accuracy improvements with\nrespect to the leading classification algorithms.\n", "versions": [{"version": "v1", "created": "Mon, 1 Apr 2019 12:02:55 GMT"}], "update_date": "2019-04-02", "authors_parsed": [["Krivosheev", "Evgeny", ""], ["Casati", "Fabio", ""], ["Baez", "Marcos", ""], ["Benatallah", "Boualem", ""]]}, {"id": "1904.00720", "submitter": "Ziyu Yao", "authors": "Ziyu Yao, Jayavardhan Reddy Peddamail, Huan Sun", "title": "CoaCor: Code Annotation for Code Retrieval with Reinforcement Learning", "comments": "10 pages, 2 figures. Accepted by The Web Conference (WWW) 2019", "journal-ref": null, "doi": "10.1145/3308558.3313632", "report-no": null, "categories": "cs.SE cs.CL cs.IR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  To accelerate software development, much research has been performed to help\npeople understand and reuse the huge amount of available code resources. Two\nimportant tasks have been widely studied: code retrieval, which aims to\nretrieve code snippets relevant to a given natural language query from a code\nbase, and code annotation, where the goal is to annotate a code snippet with a\nnatural language description. Despite their advancement in recent years, the\ntwo tasks are mostly explored separately. In this work, we investigate a novel\nperspective of Code annotation for Code retrieval (hence called `CoaCor'),\nwhere a code annotation model is trained to generate a natural language\nannotation that can represent the semantic meaning of a given code snippet and\ncan be leveraged by a code retrieval model to better distinguish relevant code\nsnippets from others. To this end, we propose an effective framework based on\nreinforcement learning, which explicitly encourages the code annotation model\nto generate annotations that can be used for the retrieval task. Through\nextensive experiments, we show that code annotations generated by our framework\nare much more detailed and more useful for code retrieval, and they can further\nimprove the performance of existing code retrieval models significantly.\n", "versions": [{"version": "v1", "created": "Wed, 13 Mar 2019 19:22:22 GMT"}], "update_date": "2019-04-02", "authors_parsed": [["Yao", "Ziyu", ""], ["Peddamail", "Jayavardhan Reddy", ""], ["Sun", "Huan", ""]]}, {"id": "1904.00724", "submitter": "Joseph Suarez", "authors": "Joseph Suarez", "title": "GAN You Do the GAN GAN?", "comments": "3 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Generative Adversarial Networks (GANs) have become a dominant class of\ngenerative models. In recent years, GAN variants have yielded especially\nimpressive results in the synthesis of a variety of forms of data. Examples\ninclude compelling natural and artistic images, textures, musical sequences,\nand 3D object files. However, one obvious synthesis candidate is missing. In\nthis work, we answer one of deep learning's most pressing questions: GAN you do\nthe GAN GAN? That is, is it possible to train a GAN to model a distribution of\nGANs? We release the full source code for this project under the MIT license.\n", "versions": [{"version": "v1", "created": "Mon, 1 Apr 2019 12:19:28 GMT"}], "update_date": "2019-04-02", "authors_parsed": [["Suarez", "Joseph", ""]]}, {"id": "1904.00735", "submitter": "Mark Stamp", "authors": "Neeraj Chavan, Fabio Di Troia, Mark Stamp", "title": "A Comparative Analysis of Android Malware", "comments": "3rd International Workshop on Formal Methods for Security Engineering\n  (ForSE 2019), in conjunction with the 5th International Conference on\n  Information Systems Security and Privacy (ICISSP 2019), Prague, Czech\n  Republic, February 23-25, 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we present a comparative analysis of benign and malicious\nAndroid applications, based on static features. In particular, we focus our\nattention on the permissions requested by an application. We consider both\nbinary classification of malware versus benign, as well as the multiclass\nproblem, where we classify malware samples into their respective families. Our\nexperiments are based on substantial malware datasets and we employ a wide\nvariety of machine learning techniques, including decision trees and random\nforests, support vector machines, logistic model trees, AdaBoost, and\nartificial neural networks. We find that permissions are a strong feature and\nthat by careful feature engineering, we can significantly reduce the number of\nfeatures needed for highly accurate detection and classification.\n", "versions": [{"version": "v1", "created": "Mon, 21 Jan 2019 02:05:55 GMT"}], "update_date": "2019-04-02", "authors_parsed": [["Chavan", "Neeraj", ""], ["Di Troia", "Fabio", ""], ["Stamp", "Mark", ""]]}, {"id": "1904.00736", "submitter": "Abdelmonim Naway", "authors": "Abdelmonim Naway and Yuancheng LI", "title": "Using Deep Neural Network for Android Malware Detection", "comments": "9 pages, 5 figures, 6 Tables", "journal-ref": "International Journal of advanced studies in Computer Science and\n  Engineering (IJASCSE) VOLUME 7 ISSUE 12, 2018, pg. 9-18", "doi": null, "report-no": null, "categories": "cs.CR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The pervasiveness of the Android operating system, with the availability of\napplications almost for everything, is readily accessible in the official\nGoogle play store or a dozen alternative third-party markets. Additionally, the\nvital role of smartphones in modern life leads to store significant information\non devices, not only personal information but also corporate information, which\nattract malware developers to develop applications that can infiltrate user's\ndevices to steal information and perform harmful tasks. This accompanied with\nthe limitation of currently defenses techniques such as ineffective screening\nin Google play store, weak or no screening in third-party markets. Antiviruses\nsoftware that still relies on a signature-based database that is effective only\nin identifying known malware. To contrive with malicious applications that are\nincreased in volume and sophistication, we propose an Android malware detection\nsystem that applies deep learning technique to face the threats of Android\nmalware. Extensive experiments on a real-world dataset contain benign and\nmalicious applications uncovered that the proposed system reaches an accuracy\nof 95.31%.\n", "versions": [{"version": "v1", "created": "Wed, 16 Jan 2019 10:10:04 GMT"}], "update_date": "2019-04-02", "authors_parsed": [["Naway", "Abdelmonim", ""], ["LI", "Yuancheng", ""]]}, {"id": "1904.00737", "submitter": "Onn Shehory", "authors": "Eitan Farchi, Onn Shehory, Guy Barash", "title": "Defending via strategic ML selection", "comments": "EDSMLS 2019 @ AAAI workshop", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The results of a learning process depend on the input data. There are cases\nin which an adversary can strategically tamper with the input data to affect\nthe outcome of the learning process. While some datasets are difficult to\nattack, many others are susceptible to manipulation. A resourceful attacker can\ntamper with large portions of the dataset and affect them. An attacker can\nadditionally strategically focus on a preferred subset of the attributes in the\ndataset to maximize the effectiveness of the attack and minimize the resources\nallocated to data manipulation. In light of this vulnerability, we introduce a\nsolution according to which the defender implements an array of learners, and\ntheir activation is performed strategically. The defender computes the (game\ntheoretic) strategy space and accordingly applies a dominant strategy where\npossible, and a Nash-stable strategy otherwise. In this paper we provide the\ndetails of this approach. We analyze Nash equilibrium in such a strategic\nlearning environment, and demonstrate our solution by specific examples.\n", "versions": [{"version": "v1", "created": "Wed, 16 Jan 2019 13:19:11 GMT"}], "update_date": "2019-04-02", "authors_parsed": [["Farchi", "Eitan", ""], ["Shehory", "Onn", ""], ["Barash", "Guy", ""]]}, {"id": "1904.00739", "submitter": "Kevin Meng", "authors": "Kevin Meng, Yu Meng", "title": "Through-Wall Pose Imaging in Real-Time with a Many-to-Many\n  Encoder/Decoder Paradigm", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Overcoming the visual barrier and developing \"see-through vision\" has been\none of mankind's long-standing dreams. Unlike visible light, Radio Frequency\n(RF) signals penetrate opaque obstructions and reflect highly off humans. This\npaper establishes a deep-learning model that can be trained to reconstruct\ncontinuous video of a 15-point human skeleton even through visual occlusion.\nThe training process adopts a student/teacher learning procedure inspired by\nthe Feynman learning technique, in which video frames and RF data are first\ncollected simultaneously using a co-located setup containing an optical camera\nand an RF antenna array transceiver. Next, the video frames are processed with\na computer-vision-based gait analysis \"teacher\" module to generate ground-truth\nhuman skeletons for each frame. Then, the same type of skeleton is predicted\nfrom corresponding RF data using a \"student\" deep-learning model consisting of\na Residual Convolutional Neural Network (CNN), Region Proposal Network (RPN),\nand Recurrent Neural Network with Long-Short Term Memory (LSTM) that 1)\nextracts spatial features from RF images, 2) detects all people present in a\nscene, and 3) aggregates information over many time-steps, respectively. The\nmodel is shown to both accurately and completely predict the pose of humans\nbehind visual obstruction solely using RF signals. Primary academic\ncontributions include the novel many-to-many imaging methodology, unique\nintegration of RPN and LSTM networks, and original training pipeline.\n", "versions": [{"version": "v1", "created": "Fri, 15 Mar 2019 19:05:05 GMT"}, {"version": "v2", "created": "Sun, 20 Oct 2019 05:52:38 GMT"}], "update_date": "2019-10-22", "authors_parsed": [["Meng", "Kevin", ""], ["Meng", "Yu", ""]]}, {"id": "1904.00741", "submitter": "Benjamin Chamberlain", "authors": "Elaine M. Bettaney, Stephen R. Hardwick, Odysseas Zisimopoulos,\n  Benjamin Paul Chamberlain", "title": "Fashion Outfit Generation for E-commerce", "comments": "9 pages, 9 figures, 4 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Combining items of clothing into an outfit is a major task in fashion retail.\nRecommending sets of items that are compatible with a particular seed item is\nuseful for providing users with guidance and inspiration, but is currently a\nmanual process that requires expert stylists and is therefore not scalable or\neasy to personalise. We use a multilayer neural network fed by visual and\ntextual features to learn embeddings of items in a latent style space such that\ncompatible items of different types are embedded close to one another. We train\nour model using the ASOS outfits dataset, which consists of a large number of\noutfits created by professional stylists and which we release to the research\ncommunity. Our model shows strong performance in an offline outfit\ncompatibility prediction task. We use our model to generate outfits and for the\nfirst time in this field perform an AB test, comparing our generated outfits to\nthose produced by a baseline model which matches appropriate product types but\nuses no information on style. Users approved of outfits generated by our model\n21% and 34% more frequently than those generated by the baseline model for\nwomenswear and menswear respectively.\n", "versions": [{"version": "v1", "created": "Mon, 18 Mar 2019 11:19:34 GMT"}], "update_date": "2019-04-02", "authors_parsed": [["Bettaney", "Elaine M.", ""], ["Hardwick", "Stephen R.", ""], ["Zisimopoulos", "Odysseas", ""], ["Chamberlain", "Benjamin Paul", ""]]}, {"id": "1904.00747", "submitter": "Amir Rastar", "authors": "Amir Rastar", "title": "A Novel Pixel-Averaging Technique for Extracting Training Data from a\n  Single Image, Used in ML-Based Image Enlargement", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Size of the training dataset is an important factor in the performance of a\nmachine learning algorithms and tools used in medical image processing are not\nexceptions. Machine learning tools normally require a decent amount of training\ndata before they could efficiently predict a target. For image processing and\ncomputer vision, the number of images determines the validity and reliability\nof the training set. Medical images in some cases, suffer from poor quality and\ninadequate quantity required for a suitable training set. The proposed\nalgorithm in this research obviates the need for large or even small image\ndatasets used in machine learning based image enlargement techniques by\nextracting the required data from a single image. The extracted data was then\nintroduced to a decision tree regressor for upscaling greyscale medical images\nat different zoom levels. Results from the algorithm are relatively acceptable\ncompared to third-party applications and promising for future research. This\ntechnique could be tailored to the requirements of other machine learning tools\nand the results may be improved by further tweaking of the tools\nhyperparameters.\n", "versions": [{"version": "v1", "created": "Mon, 25 Mar 2019 18:48:36 GMT"}], "update_date": "2019-04-02", "authors_parsed": [["Rastar", "Amir", ""]]}, {"id": "1904.00759", "submitter": "Juncheng Li", "authors": "Juncheng Li, Frank R. Schmidt, J. Zico Kolter", "title": "Adversarial camera stickers: A physical camera-based attack on deep\n  learning systems", "comments": null, "journal-ref": "Proceedings of the 36th International Conference on Machine\n  Learning, PMLR 97:3896-3904, 2019", "doi": null, "report-no": null, "categories": "cs.CV cs.CR cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent work has documented the susceptibility of deep learning systems to\nadversarial examples, but most such attacks directly manipulate the digital\ninput to a classifier. Although a smaller line of work considers physical\nadversarial attacks, in all cases these involve manipulating the object of\ninterest, e.g., putting a physical sticker on an object to misclassify it, or\nmanufacturing an object specifically intended to be misclassified. In this\nwork, we consider an alternative question: is it possible to fool deep\nclassifiers, over all perceived objects of a certain type, by physically\nmanipulating the camera itself? We show that by placing a carefully crafted and\nmainly-translucent sticker over the lens of a camera, one can create universal\nperturbations of the observed images that are inconspicuous, yet misclassify\ntarget objects as a different (targeted) class. To accomplish this, we propose\nan iterative procedure for both updating the attack perturbation (to make it\nadversarial for a given classifier), and the threat model itself (to ensure it\nis physically realizable). For example, we show that we can achieve\nphysically-realizable attacks that fool ImageNet classifiers in a targeted\nfashion 49.6% of the time. This presents a new class of physically-realizable\nthreat models to consider in the context of adversarially robust machine\nlearning. Our demo video can be viewed at: https://youtu.be/wUVmL33Fx54\n", "versions": [{"version": "v1", "created": "Thu, 21 Mar 2019 23:33:12 GMT"}, {"version": "v2", "created": "Tue, 2 Apr 2019 01:46:23 GMT"}, {"version": "v3", "created": "Wed, 3 Apr 2019 17:31:40 GMT"}, {"version": "v4", "created": "Sat, 8 Jun 2019 19:23:56 GMT"}], "update_date": "2019-06-11", "authors_parsed": [["Li", "Juncheng", ""], ["Schmidt", "Frank R.", ""], ["Kolter", "J. Zico", ""]]}, {"id": "1904.00760", "submitter": "Wieland Brendel", "authors": "Wieland Brendel and Matthias Bethge", "title": "Approximating CNNs with Bag-of-local-Features models works surprisingly\n  well on ImageNet", "comments": "Published as a conference paper at the Seventh International\n  Conference on Learning Representations (ICLR 2019)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep Neural Networks (DNNs) excel on many complex perceptual tasks but it has\nproven notoriously difficult to understand how they reach their decisions. We\nhere introduce a high-performance DNN architecture on ImageNet whose decisions\nare considerably easier to explain. Our model, a simple variant of the\nResNet-50 architecture called BagNet, classifies an image based on the\noccurrences of small local image features without taking into account their\nspatial ordering. This strategy is closely related to the bag-of-feature (BoF)\nmodels popular before the onset of deep learning and reaches a surprisingly\nhigh accuracy on ImageNet (87.6% top-5 for 33 x 33 px features and Alexnet\nperformance for 17 x 17 px features). The constraint on local features makes it\nstraight-forward to analyse how exactly each part of the image influences the\nclassification. Furthermore, the BagNets behave similar to state-of-the art\ndeep neural networks such as VGG-16, ResNet-152 or DenseNet-169 in terms of\nfeature sensitivity, error distribution and interactions between image parts.\nThis suggests that the improvements of DNNs over previous bag-of-feature\nclassifiers in the last few years is mostly achieved by better fine-tuning\nrather than by qualitatively different decision strategies.\n", "versions": [{"version": "v1", "created": "Wed, 20 Mar 2019 16:37:17 GMT"}], "update_date": "2019-04-02", "authors_parsed": [["Brendel", "Wieland", ""], ["Bethge", "Matthias", ""]]}, {"id": "1904.00761", "submitter": "Casper Hansen", "authors": "Christian Hansen, Casper Hansen, Stephen Alstrup, Jakob Grue Simonsen,\n  Christina Lioma", "title": "Neural Speed Reading with Structural-Jump-LSTM", "comments": "10 pages", "journal-ref": "7th International Conference on Learning Representations (ICLR)\n  2019", "doi": null, "report-no": null, "categories": "cs.CL cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recurrent neural networks (RNNs) can model natural language by sequentially\n'reading' input tokens and outputting a distributed representation of each\ntoken. Due to the sequential nature of RNNs, inference time is linearly\ndependent on the input length, and all inputs are read regardless of their\nimportance. Efforts to speed up this inference, known as 'neural speed\nreading', either ignore or skim over part of the input. We present\nStructural-Jump-LSTM: the first neural speed reading model to both skip and\njump text during inference. The model consists of a standard LSTM and two\nagents: one capable of skipping single words when reading, and one capable of\nexploiting punctuation structure (sub-sentence separators (,:), sentence end\nsymbols (.!?), or end of text markers) to jump ahead after reading a word. A\ncomprehensive experimental evaluation of our model against all five\nstate-of-the-art neural reading models shows that Structural-Jump-LSTM achieves\nthe best overall floating point operations (FLOP) reduction (hence is faster),\nwhile keeping the same accuracy or even improving it compared to a vanilla LSTM\nthat reads the whole text.\n", "versions": [{"version": "v1", "created": "Wed, 20 Mar 2019 12:01:46 GMT"}, {"version": "v2", "created": "Tue, 2 Apr 2019 08:59:34 GMT"}], "update_date": "2019-04-03", "authors_parsed": [["Hansen", "Christian", ""], ["Hansen", "Casper", ""], ["Alstrup", "Stephen", ""], ["Simonsen", "Jakob Grue", ""], ["Lioma", "Christina", ""]]}, {"id": "1904.00762", "submitter": "Subba Reddy Oota", "authors": "Subba Reddy Oota, Adithya Avvaru, Mounika Marreddy, Radhika Mamidi", "title": "Affect in Tweets Using Experts Model", "comments": "10 pages, 6 figures, The 32nd Pacific Asia Conference on Language,\n  Information and Computation (PACLIC 32)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.CL cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Estimating the intensity of emotion has gained significance as modern textual\ninputs in potential applications like social media, e-retail markets,\npsychology, advertisements etc., carry a lot of emotions, feelings, expressions\nalong with its meaning. However, the approaches of traditional sentiment\nanalysis primarily focuses on classifying the sentiment in general (positive or\nnegative) or at an aspect level(very positive, low negative, etc.) and cannot\nexploit the intensity information. Moreover, automatically identifying emotions\nlike anger, fear, joy, sadness, disgust etc., from text introduces challenging\nscenarios where single tweet may contain multiple emotions with different\nintensities and some emotions may even co-occur in some of the tweets. In this\npaper, we propose an architecture, Experts Model, inspired from the standard\nMixture of Experts (MoE) model. The key idea here is each expert learns\ndifferent sets of features from the feature vector which helps in better\nemotion detection from the tweet. We compared the results of our Experts Model\nwith both baseline results and top five performers of SemEval-2018 Task-1,\nAffect in Tweets (AIT). The experimental results show that our proposed\napproach deals with the emotion detection problem and stands at top-5 results.\n", "versions": [{"version": "v1", "created": "Wed, 20 Mar 2019 11:10:29 GMT"}], "update_date": "2019-04-02", "authors_parsed": [["Oota", "Subba Reddy", ""], ["Avvaru", "Adithya", ""], ["Marreddy", "Mounika", ""], ["Mamidi", "Radhika", ""]]}, {"id": "1904.00763", "submitter": "Samy Blusseau", "authors": "Bastien Ponchon (CMM, LTCI), Santiago Velasco-Forero (CMM), Samy\n  Blusseau (CMM), Jesus Angulo (CMM), Isabelle Bloch (LTCI)", "title": "Part-based approximations for morphological operators using asymmetric\n  auto-encoders", "comments": null, "journal-ref": "International Symposium on Mathematical Morphology, Jul 2019,\n  Saarbr{\\\"u}cken, Germany", "doi": null, "report-no": null, "categories": "cs.CV cs.LG math.ST stat.ML stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper addresses the issue of building a part-based representation of a\ndataset of images. More precisely, we look for a non-negative, sparse\ndecomposition of the images on a reduced set of atoms, in order to unveil a\nmorphological and interpretable structure of the data. Additionally, we want\nthis decomposition to be computed online for any new sample that is not part of\nthe initial dataset. Therefore, our solution relies on a sparse, non-negative\nauto-encoder where the encoder is deep (for accuracy) and the decoder shallow\n(for interpretability). This method compares favorably to the state-of-the-art\nonline methods on two datasets (MNIST and Fashion MNIST), according to\nclassical metrics and to a new one we introduce, based on the invariance of the\nrepresentation to morphological dilation.\n", "versions": [{"version": "v1", "created": "Wed, 20 Mar 2019 08:16:48 GMT"}, {"version": "v2", "created": "Wed, 3 Apr 2019 12:03:34 GMT"}], "update_date": "2019-04-04", "authors_parsed": [["Ponchon", "Bastien", "", "CMM, LTCI"], ["Velasco-Forero", "Santiago", "", "CMM"], ["Blusseau", "Samy", "", "CMM"], ["Angulo", "Jesus", "", "CMM"], ["Bloch", "Isabelle", "", "LTCI"]]}, {"id": "1904.00764", "submitter": "Hazrat Ali", "authors": "Mohammad Farhad Bulbul, Saiful Islam, Hazrat Ali", "title": "3D human action analysis and recognition through GLAC descriptor on 2D\n  motion and static posture images", "comments": "Multimed Tools Appl (2019)", "journal-ref": null, "doi": "10.1007/s11042-019-7365-2", "report-no": null, "categories": "cs.CV cs.LG eess.IV stat.ML", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  In this paper, we present an approach for identification of actions within\ndepth action videos. First, we process the video to get motion history images\n(MHIs) and static history images (SHIs) corresponding to an action video based\non the use of 3D Motion Trail Model (3DMTM). We then characterize the action\nvideo by extracting the Gradient Local Auto-Correlations (GLAC) features from\nthe SHIs and the MHIs. The two sets of features i.e., GLAC features from MHIs\nand GLAC features from SHIs are concatenated to obtain a representation vector\nfor action. Finally, we perform the classification on all the action samples by\nusing the l2-regularized Collaborative Representation Classifier (l2-CRC) to\nrecognize different human actions in an effective way. We perform evaluation of\nthe proposed method on three action datasets, MSR-Action3D, DHA and UTD-MHAD.\nThrough experimental results, we observe that the proposed method performs\nsuperior to other approaches.\n", "versions": [{"version": "v1", "created": "Tue, 19 Mar 2019 17:52:16 GMT"}], "update_date": "2019-04-02", "authors_parsed": [["Bulbul", "Mohammad Farhad", ""], ["Islam", "Saiful", ""], ["Ali", "Hazrat", ""]]}, {"id": "1904.00768", "submitter": "Pranav Shenoy K P", "authors": "Yongqing Sun, Pranav Shenoy K P, Jun Shimamura, Atsushi Sagata", "title": "Concatenated Feature Pyramid Network for Instance Segmentation", "comments": "5 pages, 6 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Low level features like edges and textures play an important role in\naccurately localizing instances in neural networks. In this paper, we propose\nan architecture which improves feature pyramid networks commonly used instance\nsegmentation networks by incorporating low level features in all layers of the\npyramid in an optimal and efficient way. Specifically, we introduce a new layer\nwhich learns new correlations from feature maps of multiple feature pyramid\nlevels holistically and enhances the semantic information of the feature\npyramid to improve accuracy. Our architecture is simple to implement in\ninstance segmentation or object detection frameworks to boost accuracy. Using\nthis method in Mask RCNN, our model achieves consistent improvement in\nprecision on COCO Dataset with the computational overhead compared to the\noriginal feature pyramid network.\n", "versions": [{"version": "v1", "created": "Sat, 16 Mar 2019 07:44:10 GMT"}], "update_date": "2019-04-02", "authors_parsed": [["Sun", "Yongqing", ""], ["P", "Pranav Shenoy K", ""], ["Shimamura", "Jun", ""], ["Sagata", "Atsushi", ""]]}, {"id": "1904.00770", "submitter": "Daniel Salles Civitarese", "authors": "Reinaldo Mozart Silva, Lais Baroni, Rodrigo S. Ferreira, Daniel\n  Civitarese, Daniela Szwarcman, Emilio Vital Brazil", "title": "Netherlands Dataset: A New Public Dataset for Machine Learning in\n  Seismic Interpretation", "comments": "5 pages, 5 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV physics.geo-ph stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Machine learning and, more specifically, deep learning algorithms have seen\nremarkable growth in their popularity and usefulness in the last years. This is\narguably due to three main factors: powerful computers, new techniques to train\ndeeper networks and larger datasets. Although the first two are readily\navailable in modern computers and ML libraries, the last one remains a\nchallenge for many domains. It is a fact that big data is a reality in almost\nall fields nowadays, and geosciences are not an exception. However, to achieve\nthe success of general-purpose applications such as ImageNet - for which there\nare +14 million labeled images for 1000 target classes - we not only need more\ndata, we need more high-quality labeled data. When it comes to the Oil&Gas\nindustry, confidentiality issues hamper even more the sharing of datasets. In\nthis work, we present the Netherlands interpretation dataset, a contribution to\nthe development of machine learning in seismic interpretation. The Netherlands\nF3 dataset acquisition was carried out in the North Sea, Netherlands offshore.\nThe data is publicly available and contains pos-stack data, 8 horizons and well\nlogs of 4 wells. For the purposes of our machine learning tasks, the original\ndataset was reinterpreted, generating 9 horizons separating different seismic\nfacies intervals. The interpreted horizons were used to generate approximatelly\n190,000 labeled images for inlines and crosslines. Finally, we present two deep\nlearning applications in which the proposed dataset was employed and produced\ncompelling results.\n", "versions": [{"version": "v1", "created": "Tue, 26 Mar 2019 13:12:14 GMT"}], "update_date": "2019-04-02", "authors_parsed": [["Silva", "Reinaldo Mozart", ""], ["Baroni", "Lais", ""], ["Ferreira", "Rodrigo S.", ""], ["Civitarese", "Daniel", ""], ["Szwarcman", "Daniela", ""], ["Brazil", "Emilio Vital", ""]]}, {"id": "1904.00775", "submitter": "Ramchalam Kinattinkara Ramakrishnan Mr", "authors": "Ramchalam Kinattinkara Ramakrishnan, Shangling Jui and Vahid Patrovi\n  Nia", "title": "Deep Demosaicing for Edge Implementation", "comments": "Accepted in the 16th International Conference of Image Analysis and\n  Recognition (ICIAR 2019)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Most digital cameras use sensors coated with a Color Filter Array (CFA) to\ncapture channel components at every pixel location, resulting in a mosaic image\nthat does not contain pixel values in all channels. Current research on\nreconstructing these missing channels, also known as demosaicing, introduces\nmany artifacts, such as zipper effect and false color. Many deep learning\ndemosaicing techniques outperform other classical techniques in reducing the\nimpact of artifacts. However, most of these models tend to be\nover-parametrized. Consequently, edge implementation of the state-of-the-art\ndeep learning-based demosaicing algorithms on low-end edge devices is a major\nchallenge. We provide an exhaustive search of deep neural network architectures\nand obtain a pareto front of Color Peak Signal to Noise Ratio (CPSNR) as the\nperformance criterion versus the number of parameters as the model complexity\nthat beats the state-of-the-art. Architectures on the pareto front can then be\nused to choose the best architecture for a variety of resource constraints.\nSimple architecture search methods such as exhaustive search and grid search\nrequire some conditions of the loss function to converge to the optimum. We\nclarify these conditions in a brief theoretical study.\n", "versions": [{"version": "v1", "created": "Tue, 26 Mar 2019 15:04:17 GMT"}, {"version": "v2", "created": "Fri, 12 Apr 2019 19:30:39 GMT"}, {"version": "v3", "created": "Thu, 23 May 2019 15:20:54 GMT"}], "update_date": "2019-05-24", "authors_parsed": [["Ramakrishnan", "Ramchalam Kinattinkara", ""], ["Jui", "Shangling", ""], ["Nia", "Vahid Patrovi", ""]]}, {"id": "1904.00783", "submitter": "Md. Abu Bakr Siddique", "authors": "Shadman Sakib, Zahidun Ashrafi, Md. Abu Bakr Siddique", "title": "Implementation of Fruits Recognition Classifier using Convolutional\n  Neural Network Algorithm for Observation of Accuracies for Various Hidden\n  Layers", "comments": "4 Pages, 5 Figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Fruit recognition using Deep Convolutional Neural Network (CNN) is one of the\nmost promising applications in computer vision. In recent times, deep learning\nbased classifications are making it possible to recognize fruits from images.\nHowever, fruit recognition is still a problem for the stacked fruits on\nweighing scale because of the complexity and similarity. In this paper, a fruit\nrecognition system using CNN is proposed. The proposed method uses deep\nlearning techniques for the classification. We have used Fruits-360 dataset for\nthe evaluation purpose. From the dataset, we have established a dataset which\ncontains 17,823 images from 25 different categories. The images are divided\ninto training and test dataset. Moreover, for the classification accuracies, we\nhave used various combinations of hidden layer and epochs for different cases\nand made a comparison between them. The overall performance losses of the\nnetwork for different cases also observed. Finally, we have achieved the best\ntest accuracy of 100% and a training accuracy of 99.79%.\n", "versions": [{"version": "v1", "created": "Mon, 1 Apr 2019 13:03:33 GMT"}, {"version": "v2", "created": "Fri, 12 Apr 2019 03:20:33 GMT"}, {"version": "v3", "created": "Tue, 23 Apr 2019 10:55:38 GMT"}, {"version": "v4", "created": "Tue, 11 Jun 2019 06:40:49 GMT"}, {"version": "v5", "created": "Thu, 16 Jan 2020 02:35:33 GMT"}, {"version": "v6", "created": "Sat, 25 Jan 2020 12:10:41 GMT"}], "update_date": "2020-01-28", "authors_parsed": [["Sakib", "Shadman", ""], ["Ashrafi", "Zahidun", ""], ["Siddique", "Md. Abu Bakr", ""]]}, {"id": "1904.00784", "submitter": "Sai Krishna Rallabandi", "authors": "Sunayana Sitaram, Khyathi Raghavi Chandu, Sai Krishna Rallabandi and\n  Alan W Black", "title": "A Survey of Code-switched Speech and Language Processing", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Code-switching, the alternation of languages within a conversation or\nutterance, is a common communicative phenomenon that occurs in multilingual\ncommunities across the world. This survey reviews computational approaches for\ncode-switched Speech and Natural Language Processing. We motivate why\nprocessing code-switched text and speech is essential for building intelligent\nagents and systems that interact with users in multilingual communities. As\ncode-switching data and resources are scarce, we list what is available in\nvarious code-switched language pairs with the language processing tasks they\ncan be used for. We review code-switching research in various Speech and NLP\napplications, including language processing tools and end-to-end systems. We\nconclude with future directions and open problems in the field.\n", "versions": [{"version": "v1", "created": "Mon, 25 Mar 2019 14:36:50 GMT"}, {"version": "v2", "created": "Tue, 2 Apr 2019 14:18:31 GMT"}, {"version": "v3", "created": "Wed, 22 Jul 2020 23:55:01 GMT"}], "update_date": "2020-07-24", "authors_parsed": [["Sitaram", "Sunayana", ""], ["Chandu", "Khyathi Raghavi", ""], ["Rallabandi", "Sai Krishna", ""], ["Black", "Alan W", ""]]}, {"id": "1904.00788", "submitter": "Soheil Esmaeilzadeh", "authors": "Soheil Esmaeilzadeh, Gao Xian Peh, Angela Xu", "title": "Neural Abstractive Text Summarization and Fake News Detection", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this work, we study abstractive text summarization by exploring different\nmodels such as LSTM-encoder-decoder with attention, pointer-generator networks,\ncoverage mechanisms, and transformers. Upon extensive and careful\nhyperparameter tuning we compare the proposed architectures against each other\nfor the abstractive text summarization task. Finally, as an extension of our\nwork, we apply our text summarization model as a feature extractor for a fake\nnews detection task where the news articles prior to classification will be\nsummarized and the results are compared against the classification using only\nthe original news text.\n  keywords: LSTM, encoder-deconder, abstractive text summarization,\npointer-generator, coverage mechanism, transformers, fake news detection\n", "versions": [{"version": "v1", "created": "Sun, 24 Mar 2019 07:27:51 GMT"}, {"version": "v2", "created": "Thu, 12 Dec 2019 07:46:43 GMT"}], "update_date": "2019-12-13", "authors_parsed": [["Esmaeilzadeh", "Soheil", ""], ["Peh", "Gao Xian", ""], ["Xu", "Angela", ""]]}, {"id": "1904.00791", "submitter": "Lin Zhang", "authors": "Lin Zhang, Petko Bogdanov", "title": "DSL: Discriminative Subgraph Learning via Sparse Self-Representation", "comments": "9 pages", "journal-ref": "SIAM International Conference on Data Mining(SDM) 2019", "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The goal in network state prediction (NSP) is to classify the global state\n(label) associated with features embedded in a graph. This graph structure\nencoding feature relationships is the key distinctive aspect of NSP compared to\nclassical supervised learning. NSP arises in various applications: gene\nexpression samples embedded in a protein-protein interaction (PPI) network,\ntemporal snapshots of infrastructure or sensor networks, and fMRI coherence\nnetwork samples from multiple subjects to name a few. Instances from these\ndomains are typically ``wide'' (more features than samples), and thus, feature\nsub-selection is required for robust and generalizable prediction. How to best\nemploy the network structure in order to learn succinct connected subgraphs\nencompassing the most discriminative features becomes a central challenge in\nNSP. Prior work employs connected subgraph sampling or graph smoothing within\noptimization frameworks, resulting in either large variance of quality or weak\ncontrol over the connectivity of selected subgraphs.\n  In this work we propose an optimization framework for discriminative subgraph\nlearning (DSL) which simultaneously enforces (i) sparsity, (ii) connectivity\nand (iii) high discriminative power of the resulting subgraphs of features. Our\noptimization algorithm is a single-step solution for the NSP and the associated\nfeature selection problem. It is rooted in the rich literature on\nmaximal-margin optimization, spectral graph methods and sparse subspace\nself-representation. DSL simultaneously ensures solution interpretability and\nsuperior predictive power (up to 16% improvement in challenging instances\ncompared to baselines), with execution times up to an hour for large instances.\n", "versions": [{"version": "v1", "created": "Sun, 24 Mar 2019 16:52:54 GMT"}], "update_date": "2019-04-02", "authors_parsed": [["Zhang", "Lin", ""], ["Bogdanov", "Petko", ""]]}, {"id": "1904.00805", "submitter": "Ben Gelman", "authors": "Jessica Moore, Ben Gelman, David Slater", "title": "A Convolutional Neural Network for Language-Agnostic Source Code\n  Summarization", "comments": "ENASE 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Descriptive comments play a crucial role in the software engineering process.\nThey decrease development time, enable better bug detection, and facilitate the\nreuse of previously written code. However, comments are commonly the last of a\nsoftware developer's priorities and are thus either insufficient or missing\nentirely. Automatic source code summarization may therefore have the ability to\nsignificantly improve the software development process. We introduce a novel\nencoder-decoder model that summarizes source code, effectively writing a\ncomment to describe the code's functionality. We make two primary innovations\nbeyond current source code summarization models. First, our encoder is fully\nlanguage-agnostic and requires no complex input preprocessing. Second, our\ndecoder has an open vocabulary, enabling it to predict any word, even ones not\nseen in training. We demonstrate results comparable to state-of-the-art methods\non a single-language data set and provide the first results on a data set\nconsisting of multiple programming languages.\n", "versions": [{"version": "v1", "created": "Fri, 29 Mar 2019 15:53:28 GMT"}], "update_date": "2019-04-02", "authors_parsed": [["Moore", "Jessica", ""], ["Gelman", "Ben", ""], ["Slater", "David", ""]]}, {"id": "1904.00815", "submitter": "Chollette Olisah Dr", "authors": "Chollette C. Olisah, Lyndon Smith", "title": "Understanding Unconventional Preprocessors in Deep Convolutional Neural\n  Networks for Face Identification", "comments": "9 pages, 4 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep networks have achieved huge successes in application domains like object\nand face recognition. The performance gain is attributed to different facets of\nthe network architecture such as: depth of the convolutional layers, activation\nfunction, pooling, batch normalization, forward and back propagation and many\nmore. However, very little emphasis is made on the preprocessors. Therefore, in\nthis paper, the network's preprocessing module is varied across different\npreprocessing approaches while keeping constant other facets of the network\narchitecture, to investigate the contribution preprocessing makes to the\nnetwork. Commonly used preprocessors are the data augmentation and\nnormalization and are termed conventional preprocessors. Others are termed the\nunconventional preprocessors, they are: color space converters; HSV, CIE L*a*b*\nand YCBCR, grey-level resolution preprocessors; full-based and plane-based\nimage quantization, illumination normalization and insensitive feature\npreprocessing using: histogram equalization (HE), local contrast normalization\n(LN) and complete face structural pattern (CFSP). To achieve fixed network\nparameters, CNNs with transfer learning is employed. Knowledge from the\nhigh-level feature vectors of the Inception-V3 network is transferred to\noffline preprocessed LFW target data; and features trained using the SoftMax\nclassifier for face identification. The experiments show that the\ndiscriminative capability of the deep networks can be improved by preprocessing\nRGB data with HE, full-based and plane-based quantization, rgbGELog, and YCBCR,\npreprocessors before feeding it to CNNs. However, for best performance, the\nright setup of preprocessed data with augmentation and/or normalization is\nrequired. The plane-based image quantization is found to increase the\nhomogeneity of neighborhood pixels and utilizes reduced bit depth for better\nstorage efficiency.\n", "versions": [{"version": "v1", "created": "Wed, 27 Mar 2019 13:05:55 GMT"}, {"version": "v2", "created": "Thu, 2 May 2019 10:54:14 GMT"}], "update_date": "2019-05-03", "authors_parsed": [["Olisah", "Chollette C.", ""], ["Smith", "Lyndon", ""]]}, {"id": "1904.00816", "submitter": "Kuo Teng Ding", "authors": "Yi-Lun Pan, Min-Jhih Huang, Kuo-Teng Ding, Ja-Ling Wu, Jyh-Shing Jang", "title": "k-Same-Siamese-GAN: k-Same Algorithm with Generative Adversarial Network\n  for Facial Image De-identification with Hyperparameter Tuning and Mixed\n  Precision Training", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  For a data holder, such as a hospital or a government entity, who has a\nprivately held collection of personal data, in which the revealing and/or\nprocessing of the personal identifiable data is restricted and prohibited by\nlaw. Then, \"how can we ensure the data holder does conceal the identity of each\nindividual in the imagery of personal data while still preserving certain\nuseful aspects of the data after de-identification?\" becomes a challenge issue.\nIn this work, we propose an approach towards high-resolution facial image\nde-identification, called k-Same-Siamese-GAN, which leverages the\nk-Same-Anonymity mechanism, the Generative Adversarial Network, and the\nhyperparameter tuning methods. Moreover, to speed up model training and reduce\nmemory consumption, the mixed precision training technique is also applied to\nmake kSS-GAN provide guarantees regarding privacy protection on close-form\nidentities and be trained much more efficiently as well. Finally, to validate\nits applicability, the proposed work has been applied to actual datasets - RafD\nand CelebA for performance testing. Besides protecting privacy of\nhigh-resolution facial images, the proposed system is also justified for its\nability in automating parameter tuning and breaking through the limitation of\nthe number of adjustable parameters.\n", "versions": [{"version": "v1", "created": "Wed, 27 Mar 2019 14:27:07 GMT"}, {"version": "v2", "created": "Tue, 17 Sep 2019 05:24:19 GMT"}], "update_date": "2019-09-18", "authors_parsed": [["Pan", "Yi-Lun", ""], ["Huang", "Min-Jhih", ""], ["Ding", "Kuo-Teng", ""], ["Wu", "Ja-Ling", ""], ["Jang", "Jyh-Shing", ""]]}, {"id": "1904.00864", "submitter": "Kyung-Su Kim", "authors": "Kyung-Su Kim, Sae-Young Chung", "title": "Tree Search Network for Sparse Regression", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG eess.SP stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the classical sparse regression problem of recovering a sparse\nsignal $x_0$ given a measurement vector $y = \\Phi x_0+w$. We propose a tree\nsearch algorithm driven by the deep neural network for sparse regression (TSN).\nTSN improves the signal reconstruction performance of the deep neural network\ndesigned for sparse regression by performing a tree search with pruning. It is\nobserved in both noiseless and noisy cases, TSN recovers synthetic and real\nsignals with lower complexity than a conventional tree search and is superior\nto existing algorithms by a large margin for various types of the sensing\nmatrix $\\Phi$, widely used in sparse regression.\n", "versions": [{"version": "v1", "created": "Mon, 1 Apr 2019 14:05:41 GMT"}], "update_date": "2019-04-02", "authors_parsed": [["Kim", "Kyung-Su", ""], ["Chung", "Sae-Young", ""]]}, {"id": "1904.00865", "submitter": "Benjamin Guedj", "authors": "Benjamin Guedj and Juliette Rengot", "title": "Non-linear aggregation of filters to improve image denoising", "comments": "To appear at Computing Conference 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.CV cs.LG eess.IV", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  We introduce a novel aggregation method to efficiently perform image\ndenoising. Preliminary filters are aggregated in a non-linear fashion, using a\nnew metric of pixel proximity based on how the pool of filters reaches a\nconsensus. We provide a theoretical bound to support our aggregation scheme,\nits numerical performance is illustrated and we show that the aggregate\nsignificantly outperforms each of the preliminary filters.\n", "versions": [{"version": "v1", "created": "Mon, 1 Apr 2019 14:10:21 GMT"}, {"version": "v2", "created": "Tue, 1 Oct 2019 18:54:55 GMT"}, {"version": "v3", "created": "Tue, 23 Jun 2020 15:43:09 GMT"}], "update_date": "2020-06-24", "authors_parsed": [["Guedj", "Benjamin", ""], ["Rengot", "Juliette", ""]]}, {"id": "1904.00876", "submitter": "Yawei Luo", "authors": "Yawei Luo, Ping Liu, Tao Guan, Junqing Yu, Yi Yang", "title": "Significance-aware Information Bottleneck for Domain Adaptive Semantic\n  Segmentation", "comments": "12 pages, 9 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  For unsupervised domain adaptation problems, the strategy of aligning the two\ndomains in latent feature space through adversarial learning has achieved much\nprogress in image classification, but usually fails in semantic segmentation\ntasks in which the latent representations are overcomplex. In this work, we\nequip the adversarial network with a \"significance-aware information bottleneck\n(SIB)\", to address the above problem. The new network structure, called SIBAN,\nenables a significance-aware feature purification before the adversarial\nadaptation, which eases the feature alignment and stabilizes the adversarial\ntraining course. In two domain adaptation tasks, i.e., GTA5 -> Cityscapes and\nSYNTHIA -> Cityscapes, we validate that the proposed method can yield leading\nresults compared with other feature-space alternatives. Moreover, SIBAN can\neven match the state-of-the-art output-space methods in segmentation accuracy,\nwhile the latter are often considered to be better choices for domain adaptive\nsegmentation task.\n", "versions": [{"version": "v1", "created": "Mon, 1 Apr 2019 14:19:28 GMT"}], "update_date": "2019-04-02", "authors_parsed": [["Luo", "Yawei", ""], ["Liu", "Ping", ""], ["Guan", "Tao", ""], ["Yu", "Junqing", ""], ["Yang", "Yi", ""]]}, {"id": "1904.00887", "submitter": "Aamir Mustafa", "authors": "Aamir Mustafa, Salman Khan, Munawar Hayat, Roland Goecke, Jianbing\n  Shen, Ling Shao", "title": "Adversarial Defense by Restricting the Hidden Space of Deep Neural\n  Networks", "comments": "Accepted at ICCV 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep neural networks are vulnerable to adversarial attacks, which can fool\nthem by adding minuscule perturbations to the input images. The robustness of\nexisting defenses suffers greatly under white-box attack settings, where an\nadversary has full knowledge about the network and can iterate several times to\nfind strong perturbations. We observe that the main reason for the existence of\nsuch perturbations is the close proximity of different class samples in the\nlearned feature space. This allows model decisions to be totally changed by\nadding an imperceptible perturbation in the inputs. To counter this, we propose\nto class-wise disentangle the intermediate feature representations of deep\nnetworks. Specifically, we force the features for each class to lie inside a\nconvex polytope that is maximally separated from the polytopes of other\nclasses. In this manner, the network is forced to learn distinct and distant\ndecision regions for each class. We observe that this simple constraint on the\nfeatures greatly enhances the robustness of learned models, even against the\nstrongest white-box attacks, without degrading the classification performance\non clean images. We report extensive evaluations in both black-box and\nwhite-box attack scenarios and show significant gains in comparison to\nstate-of-the art defenses.\n", "versions": [{"version": "v1", "created": "Mon, 1 Apr 2019 14:42:38 GMT"}, {"version": "v2", "created": "Tue, 2 Apr 2019 13:19:07 GMT"}, {"version": "v3", "created": "Sun, 7 Apr 2019 06:10:01 GMT"}, {"version": "v4", "created": "Sun, 28 Jul 2019 08:53:05 GMT"}], "update_date": "2019-07-30", "authors_parsed": [["Mustafa", "Aamir", ""], ["Khan", "Salman", ""], ["Hayat", "Munawar", ""], ["Goecke", "Roland", ""], ["Shen", "Jianbing", ""], ["Shao", "Ling", ""]]}, {"id": "1904.00904", "submitter": "Martin Hangaard Hansen", "authors": "Martin Hangaard Hansen, Jos\\'e A. Garrido Torres, Paul C. Jennings,\n  Ziyun Wang, Jacob R. Boes, Osman G. Mamun, Thomas Bligaard", "title": "An Atomistic Machine Learning Package for Surface Science and Catalysis", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "physics.chem-ph cs.LG physics.comp-ph physics.data-an", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present work flows and a software module for machine learning model\nbuilding in surface science and heterogeneous catalysis. This includes\nfingerprinting atomic structures from 3D structure and/or connectivity\ninformation, it includes descriptor selection methods and benchmarks, and it\nincludes active learning frameworks for atomic structure optimization,\nacceleration of screening studies and for exploration of the structure space of\nnano particles, which are all atomic structure problems relevant for surface\nscience and heterogeneous catalysis. Our overall goal is to provide a\nrepository to ease machine learning model building for catalysis, to advance\nthe models beyond the chemical intuition of the user and to increase autonomy\nfor exploration of chemical space.\n", "versions": [{"version": "v1", "created": "Mon, 1 Apr 2019 15:09:08 GMT"}], "update_date": "2019-04-02", "authors_parsed": [["Hansen", "Martin Hangaard", ""], ["Torres", "Jos\u00e9 A. Garrido", ""], ["Jennings", "Paul C.", ""], ["Wang", "Ziyun", ""], ["Boes", "Jacob R.", ""], ["Mamun", "Osman G.", ""], ["Bligaard", "Thomas", ""]]}, {"id": "1904.00923", "submitter": "Matthew Wicker", "authors": "Matthew Wicker, Marta Kwiatkowska", "title": "Robustness of 3D Deep Learning in an Adversarial Setting", "comments": "10 pages, 8 figures, 1 table", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.CR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Understanding the spatial arrangement and nature of real-world objects is of\nparamount importance to many complex engineering tasks, including autonomous\nnavigation. Deep learning has revolutionized state-of-the-art performance for\ntasks in 3D environments; however, relatively little is known about the\nrobustness of these approaches in an adversarial setting. The lack of\ncomprehensive analysis makes it difficult to justify deployment of 3D deep\nlearning models in real-world, safety-critical applications. In this work, we\ndevelop an algorithm for analysis of pointwise robustness of neural networks\nthat operate on 3D data. We show that current approaches presented for\nunderstanding the resilience of state-of-the-art models vastly overestimate\ntheir robustness. We then use our algorithm to evaluate an array of\nstate-of-the-art models in order to demonstrate their vulnerability to\nocclusion attacks. We show that, in the worst case, these networks can be\nreduced to 0% classification accuracy after the occlusion of at most 6.5% of\nthe occupied input space.\n", "versions": [{"version": "v1", "created": "Mon, 1 Apr 2019 15:51:12 GMT"}], "update_date": "2019-04-02", "authors_parsed": [["Wicker", "Matthew", ""], ["Kwiatkowska", "Marta", ""]]}, {"id": "1904.00935", "submitter": "Vadim Markovtsev", "authors": "Vadim Markovtsev, Waren Long, Hugo Mougard, Konstantin Slavnov, Egor\n  Bulychev", "title": "STYLE-ANALYZER: fixing code style inconsistencies with interpretable\n  unsupervised algorithms", "comments": "10 pages; Mining Software Repositories 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.SE stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Source code reviews are manual, time-consuming, and expensive. Human\ninvolvement should be focused on analyzing the most relevant aspects of the\nprogram, such as logic and maintainability, rather than amending style, syntax,\nor formatting defects. Some tools with linting capabilities can format code\nautomatically and report various stylistic violations for supported programming\nlanguages. They are based on rules written by domain experts, hence, their\nconfiguration is often tedious, and it is impractical for the given set of\nrules to cover all possible corner cases. Some machine learning-based solutions\nexist, but they remain uninterpretable black boxes. This paper introduces\nSTYLE-ANALYZER, a new open source tool to automatically fix code formatting\nviolations using the decision tree forest model which adapts to each codebase\nand is fully unsupervised. STYLE-ANALYZER is built on top of our novel assisted\ncode review framework, Lookout. It accurately mines the formatting style of\neach analyzed Git repository and expresses the found format patterns with\ncompact human-readable rules. STYLE-ANALYZER can then suggest style\ninconsistency fixes in the form of code review comments. We evaluate the output\nquality and practical relevance of STYLE-ANALYZER by demonstrating that it can\nreproduce the original style with high precision, measured on 19 popular\nJavaScript projects, and by showing that it yields promising results in fixing\nreal style mistakes. STYLE-ANALYZER includes a web application to visualize how\nthe rules are triggered. We release STYLE-ANALYZER as a reusable and extendable\nopen source software package on GitHub for the benefit of the community.\n", "versions": [{"version": "v1", "created": "Mon, 1 Apr 2019 16:15:38 GMT"}], "update_date": "2019-04-02", "authors_parsed": [["Markovtsev", "Vadim", ""], ["Long", "Waren", ""], ["Mougard", "Hugo", ""], ["Slavnov", "Konstantin", ""], ["Bulychev", "Egor", ""]]}, {"id": "1904.00937", "submitter": "Can Jozef Saul", "authors": "Can Jozef Saul, Deniz Yagmur Urey, Can Doruk Taktakoglu", "title": "Early Diagnosis of Pneumonia with Deep Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Pneumonia has been one of the fatal diseases and has the potential to result\nin severe consequences within a short period of time, due to the flow of fluid\nin lungs, which leads to drowning. If not acted upon by drugs at the right\ntime, pneumonia may result in death of individuals. Therefore, the early\ndiagnosis is a key factor along the progress of the disease. This paper focuses\non the biological progress of pneumonia and its detection by x-ray imaging,\noverviews the studies conducted on enhancing the level of diagnosis, and\npresents the methodology and results of an automation of xray images based on\nvarious parameters in order to detect the disease at very early stages. In this\nstudy we propose our deep learning architecture for the classification task,\nwhich is trained with modified images, through multiple steps of preprocessing.\nOur classification method uses convolutional neural networks and residual\nnetwork architecture for classifying the images. Our findings yield an accuracy\nof 78.73%, surpassing the previously top scoring accuracy of 76.8%.\n", "versions": [{"version": "v1", "created": "Mon, 1 Apr 2019 16:18:35 GMT"}], "update_date": "2019-04-02", "authors_parsed": [["Saul", "Can Jozef", ""], ["Urey", "Deniz Yagmur", ""], ["Taktakoglu", "Can Doruk", ""]]}, {"id": "1904.00938", "submitter": "Erwei Wang", "authors": "Erwei Wang, James J. Davis, Peter Y. K. Cheung, George A.\n  Constantinides", "title": "LUTNet: Rethinking Inference in FPGA Soft Logic", "comments": "Accepted manuscript uploaded 01/04/19. DOA 03/03/19", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Research has shown that deep neural networks contain significant redundancy,\nand that high classification accuracies can be achieved even when weights and\nactivations are quantised down to binary values. Network binarisation on FPGAs\ngreatly increases area efficiency by replacing resource-hungry multipliers with\nlightweight XNOR gates. However, an FPGA's fundamental building block, the\nK-LUT, is capable of implementing far more than an XNOR: it can perform any\nK-input Boolean operation. Inspired by this observation, we propose LUTNet, an\nend-to-end hardware-software framework for the construction of area-efficient\nFPGA-based neural network accelerators using the native LUTs as inference\noperators. We demonstrate that the exploitation of LUT flexibility allows for\nfar heavier pruning than possible in prior works, resulting in significant area\nsavings while achieving comparable accuracy. Against the state-of-the-art\nbinarised neural network implementation, we achieve twice the area efficiency\nfor several standard network models when inferencing popular datasets. We also\ndemonstrate that even greater energy efficiency improvements are obtainable.\n", "versions": [{"version": "v1", "created": "Mon, 1 Apr 2019 16:20:05 GMT"}], "update_date": "2019-04-02", "authors_parsed": [["Wang", "Erwei", ""], ["Davis", "James J.", ""], ["Cheung", "Peter Y. K.", ""], ["Constantinides", "George A.", ""]]}, {"id": "1904.00942", "submitter": "Wouter Van Amsterdam", "authors": "Wouter A.C. van Amsterdam, Marinus J.C. Eijkemans", "title": "Controlling for Biasing Signals in Images for Prognostic Models:\n  Survival Predictions for Lung Cancer with Deep Learning", "comments": "Initial version presented at AAAI-WHY spring symposium, 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep learning has shown remarkable results for image analysis and is expected\nto aid individual treatment decisions in health care. To achieve this, deep\nlearning methods need to be promoted from the level of mere associations to\nbeing able to answer causal questions. We present a scenario with real-world\nmedical images (CT-scans of lung cancers) and simulated outcome data. Through\nthe sampling scheme, the images contain two distinct factors of variation that\nrepresent a collider and a prognostic factor. We show that when this collider\ncan be quantified, unbiased individual prognosis predictions are attainable\nwith deep learning. This is achieved by (1) setting a dual task for the network\nto predict both the outcome and the collider and (2) enforcing independence of\nthe activation distributions of the last layer with ordinary least squares. Our\nmethod provides an example of combining deep learning and structural causal\nmodels for unbiased individual prognosis predictions.\n", "versions": [{"version": "v1", "created": "Mon, 1 Apr 2019 16:24:14 GMT"}], "update_date": "2019-04-02", "authors_parsed": [["van Amsterdam", "Wouter A. C.", ""], ["Eijkemans", "Marinus J. C.", ""]]}, {"id": "1904.00943", "submitter": "Weiming Feng", "authors": "Weiming Feng, Thomas P. Hayes, Yitong Yin", "title": "Distributed Metropolis Sampler with Optimal Parallelism", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The Metropolis-Hastings algorithm is a fundamental Markov chain Monte Carlo\n(MCMC) method for sampling and inference. With the advent of Big Data,\ndistributed and parallel variants of MCMC methods are attracting increased\nattention. In this paper, we give a distributed algorithm that can correctly\nsimulate sequential single-site Metropolis chains without any bias in a fully\nasynchronous message-passing model. Furthermore, if a natural Lipschitz\ncondition is satisfied by the Metropolis filters, our algorithm can simulate\n$N$-step Metropolis chains within $O(N/n+\\log n)$ rounds of asynchronous\ncommunications, where $n$ is the number of variables. For sequential\nsingle-site dynamics, whose mixing requires $\\Omega(n\\log n)$ steps, this\nachieves an optimal linear speedup. For several well-studied important\ngraphical models, including proper graph coloring, hardcore model, and Ising\nmodel, our condition for linear speedup is weaker than the respective\nuniqueness (mixing) conditions.\n  The novel idea in our algorithm is to resolve updates in advance: the local\nMetropolis filters can often be executed correctly before the full information\nabout neighboring spins is available. This achieves optimal parallelism without\nintroducing any bias.\n", "versions": [{"version": "v1", "created": "Mon, 1 Apr 2019 16:26:44 GMT"}, {"version": "v2", "created": "Sun, 14 Jul 2019 05:16:58 GMT"}], "update_date": "2019-07-16", "authors_parsed": [["Feng", "Weiming", ""], ["Hayes", "Thomas P.", ""], ["Yin", "Yitong", ""]]}, {"id": "1904.00956", "submitter": "Russell Mendonca", "authors": "Russell Mendonca, Abhishek Gupta, Rosen Kralev, Pieter Abbeel, Sergey\n  Levine, Chelsea Finn", "title": "Guided Meta-Policy Search", "comments": "Published at Neurips 2019. Website :\n  https://sites.google.com/berkeley.edu/guided-metapolicy-search", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.RO stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Reinforcement learning (RL) algorithms have demonstrated promising results on\ncomplex tasks, yet often require impractical numbers of samples since they\nlearn from scratch. Meta-RL aims to address this challenge by leveraging\nexperience from previous tasks so as to more quickly solve new tasks. However,\nin practice, these algorithms generally also require large amounts of on-policy\nexperience during the meta-training process, making them impractical for use in\nmany problems. To this end, we propose to learn a reinforcement learning\nprocedure in a federated way, where individual off-policy learners can solve\nthe individual meta-training tasks, and then consolidate these solutions into a\nsingle meta-learner. Since the central meta-learner learns by imitating the\nsolutions to the individual tasks, it can accommodate either the standard\nmeta-RL problem setting or a hybrid setting where some or all tasks are\nprovided with example demonstrations. The former results in an approach that\ncan leverage policies learned for previous tasks without significant amounts of\non-policy data during meta-training, whereas the latter is particularly useful\nin cases where demonstrations are easy for a person to provide. Across a number\nof continuous control meta-RL problems, we demonstrate significant improvements\nin meta-RL sample efficiency in comparison to prior work as well as the ability\nto scale to domains with visual observations.\n", "versions": [{"version": "v1", "created": "Mon, 1 Apr 2019 16:47:28 GMT"}, {"version": "v2", "created": "Tue, 27 Oct 2020 09:27:41 GMT"}], "update_date": "2020-10-28", "authors_parsed": [["Mendonca", "Russell", ""], ["Gupta", "Abhishek", ""], ["Kralev", "Rosen", ""], ["Abbeel", "Pieter", ""], ["Levine", "Sergey", ""], ["Finn", "Chelsea", ""]]}, {"id": "1904.00962", "submitter": "Yang You", "authors": "Yang You and Jing Li and Sashank Reddi and Jonathan Hseu and Sanjiv\n  Kumar and Srinadh Bhojanapalli and Xiaodan Song and James Demmel and Kurt\n  Keutzer and Cho-Jui Hsieh", "title": "Large Batch Optimization for Deep Learning: Training BERT in 76 minutes", "comments": "Published as a conference paper at ICLR 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CL stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Training large deep neural networks on massive datasets is computationally\nvery challenging. There has been recent surge in interest in using large batch\nstochastic optimization methods to tackle this issue. The most prominent\nalgorithm in this line of research is LARS, which by employing layerwise\nadaptive learning rates trains ResNet on ImageNet in a few minutes. However,\nLARS performs poorly for attention models like BERT, indicating that its\nperformance gains are not consistent across tasks. In this paper, we first\nstudy a principled layerwise adaptation strategy to accelerate training of deep\nneural networks using large mini-batches. Using this strategy, we develop a new\nlayerwise adaptive large batch optimization technique called LAMB; we then\nprovide convergence analysis of LAMB as well as LARS, showing convergence to a\nstationary point in general nonconvex settings. Our empirical results\ndemonstrate the superior performance of LAMB across various tasks such as BERT\nand ResNet-50 training with very little hyperparameter tuning. In particular,\nfor BERT training, our optimizer enables use of very large batch sizes of 32868\nwithout any degradation of performance. By increasing the batch size to the\nmemory limit of a TPUv3 Pod, BERT training time can be reduced from 3 days to\njust 76 minutes (Table 1). The LAMB implementation is available at\nhttps://github.com/tensorflow/addons/blob/master/tensorflow_addons/optimizers/lamb.py\n", "versions": [{"version": "v1", "created": "Mon, 1 Apr 2019 16:53:35 GMT"}, {"version": "v2", "created": "Thu, 23 May 2019 06:20:00 GMT"}, {"version": "v3", "created": "Fri, 24 May 2019 17:09:47 GMT"}, {"version": "v4", "created": "Wed, 25 Sep 2019 16:07:11 GMT"}, {"version": "v5", "created": "Fri, 3 Jan 2020 06:53:00 GMT"}], "update_date": "2020-01-06", "authors_parsed": [["You", "Yang", ""], ["Li", "Jing", ""], ["Reddi", "Sashank", ""], ["Hseu", "Jonathan", ""], ["Kumar", "Sanjiv", ""], ["Bhojanapalli", "Srinadh", ""], ["Song", "Xiaodan", ""], ["Demmel", "James", ""], ["Keutzer", "Kurt", ""], ["Hsieh", "Cho-Jui", ""]]}, {"id": "1904.00977", "submitter": "Ibai Roman", "authors": "Ibai Roman, Alexander Mendiburu, Roberto Santana and Jose A. Lozano", "title": "Sentiment analysis with genetically evolved Gaussian kernels", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by-sa/4.0/", "abstract": "  Sentiment analysis consists of evaluating opinions or statements from the\nanalysis of text. Among the methods used to estimate the degree in which a text\nexpresses a given sentiment, are those based on Gaussian Processes. However,\ntraditional Gaussian Processes methods use a predefined kernel with\nhyperparameters that can be tuned but whose structure can not be adapted. In\nthis paper, we propose the application of Genetic Programming for evolving\nGaussian Process kernels that are more precise for sentiment analysis. We use\nuse a very flexible representation of kernels combined with a multi-objective\napproach that simultaneously considers two quality metrics and the\ncomputational time spent by the kernels. Our results show that the algorithm\ncan outperform Gaussian Processes with traditional kernels for some of the\nsentiment analysis tasks considered.\n", "versions": [{"version": "v1", "created": "Mon, 1 Apr 2019 17:28:35 GMT"}, {"version": "v2", "created": "Mon, 14 Oct 2019 08:48:49 GMT"}], "update_date": "2019-10-15", "authors_parsed": [["Roman", "Ibai", ""], ["Mendiburu", "Alexander", ""], ["Santana", "Roberto", ""], ["Lozano", "Jose A.", ""]]}, {"id": "1904.01002", "submitter": "Dongrui Wu", "authors": "Xiao Zhang and Dongrui Wu", "title": "On the Vulnerability of CNN Classifiers in EEG-Based BCIs", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep learning has been successfully used in numerous applications because of\nits outstanding performance and the ability to avoid manual feature\nengineering. One such application is electroencephalogram (EEG) based\nbrain-computer interface (BCI), where multiple convolutional neural network\n(CNN) models have been proposed for EEG classification. However, it has been\nfound that deep learning models can be easily fooled with adversarial examples,\nwhich are normal examples with small deliberate perturbations. This paper\nproposes an unsupervised fast gradient sign method (UFGSM) to attack three\npopular CNN classifiers in BCIs, and demonstrates its effectiveness. We also\nverify the transferability of adversarial examples in BCIs, which means we can\nperform attacks even without knowing the architecture and parameters of the\ntarget models, or the datasets they were trained on. To our knowledge, this is\nthe first study on the vulnerability of CNN classifiers in EEG-based BCIs, and\nhopefully will trigger more attention on the security of BCI systems.\n", "versions": [{"version": "v1", "created": "Sun, 31 Mar 2019 06:27:08 GMT"}], "update_date": "2019-04-03", "authors_parsed": [["Zhang", "Xiao", ""], ["Wu", "Dongrui", ""]]}, {"id": "1904.01014", "submitter": "Joshua Peeples", "authors": "Joshua Peeples, Matthew Cook, Daniel Suen, Alina Zare, and James\n  Keller", "title": "Comparison of Possibilistic Fuzzy Local Information C-Means and\n  Possibilistic K-Nearest Neighbors for Synthetic Aperture Sonar Image\n  Segmentation", "comments": null, "journal-ref": "Proc. SPIE 110120, Detection and Sensing of Mines, Explosive\n  Objects, and Obscured Targets XXIV (10 May 2019)", "doi": null, "report-no": null, "categories": "eess.IV cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Synthetic aperture sonar (SAS) imagery can generate high resolution images of\nthe seafloor. Thus, segmentation algorithms can be used to partition the images\ninto different seafloor environments. In this paper, we compare two\npossibilistic segmentation approaches. Possibilistic approaches allow for the\nability to detect novel or outlier environments as well as well known classes.\nThe Possibilistic Fuzzy Local Information C-Means (PFLICM) algorithm has been\npreviously applied to segment SAS imagery. Additionally, the Possibilistic\nK-Nearest Neighbors (PKNN) algorithm has been used in other domains such as\nlandmine detection and hyperspectral imagery. In this paper, we compare the\nsegmentation performance of a semi-supervised approach using PFLICM and a\nsupervised method using Possibilistic K-NN. We include final segmentation\nresults on multiple SAS images and a quantitative assessment of each algorithm.\n", "versions": [{"version": "v1", "created": "Mon, 1 Apr 2019 16:18:28 GMT"}], "update_date": "2021-01-05", "authors_parsed": [["Peeples", "Joshua", ""], ["Cook", "Matthew", ""], ["Suen", "Daniel", ""], ["Zare", "Alina", ""], ["Keller", "James", ""]]}, {"id": "1904.01033", "submitter": "Maximilian Igl", "authors": "Maximilian Igl, Andrew Gambardella, Jinke He, Nantas Nardelli, N.\n  Siddharth, Wendelin B\\\"ohmer, Shimon Whiteson", "title": "Multitask Soft Option Learning", "comments": "Published at UAI 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present Multitask Soft Option Learning(MSOL), a hierarchical multitask\nframework based on Planning as Inference. MSOL extends the concept of options,\nusing separate variational posteriors for each task, regularized by a shared\nprior. This ''soft'' version of options avoids several instabilities during\ntraining in a multitask setting, and provides a natural way to learn both\nintra-option policies and their terminations. Furthermore, it allows\nfine-tuning of options for new tasks without forgetting their learned policies,\nleading to faster training without reducing the expressiveness of the\nhierarchical policy. We demonstrate empirically that MSOL significantly\noutperforms both hierarchical and flat transfer-learning baselines.\n", "versions": [{"version": "v1", "created": "Mon, 1 Apr 2019 18:01:34 GMT"}, {"version": "v2", "created": "Mon, 20 Jan 2020 13:53:11 GMT"}, {"version": "v3", "created": "Sun, 21 Jun 2020 10:36:45 GMT"}], "update_date": "2020-06-23", "authors_parsed": [["Igl", "Maximilian", ""], ["Gambardella", "Andrew", ""], ["He", "Jinke", ""], ["Nardelli", "Nantas", ""], ["Siddharth", "N.", ""], ["B\u00f6hmer", "Wendelin", ""], ["Whiteson", "Shimon", ""]]}, {"id": "1904.01047", "submitter": "Karun Adusumilli", "authors": "Karun Adusumilli, Friedrich Geiecke, Claudio Schilter", "title": "Dynamically optimal treatment allocation using Reinforcement Learning", "comments": "67 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "econ.EM cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Devising guidance on how to assign individuals to treatment is an important\ngoal in empirical research. In practice, individuals often arrive sequentially,\nand the planner faces various constraints such as limited budget/capacity, or\nborrowing constraints, or the need to place people in a queue. For instance, a\ngovernmental body may receive a budget outlay at the beginning of a year, and\nit may need to decide how best to allocate resources within the year to\nindividuals who arrive sequentially. In this and other examples involving\ninter-temporal trade-offs, previous work on devising optimal policy rules in a\nstatic context is either not applicable, or sub-optimal. Here we show how one\ncan use offline observational data to estimate an optimal policy rule that\nmaximizes expected welfare in this dynamic context. We allow the class of\npolicy rules to be restricted for legal, ethical or incentive compatibility\nreasons. The problem is equivalent to one of optimal control under a\nconstrained policy class, and we exploit recent developments in Reinforcement\nLearning (RL) to propose an algorithm to solve this. The algorithm is easily\nimplementable with speedups achieved through multiple RL agents learning in\nparallel processes. We also characterize the statistical regret from using our\nestimated policy rule by casting the evolution of the value function under each\npolicy in a Partial Differential Equation (PDE) form and using the theory of\nviscosity solutions to PDEs. We find that the policy regret decays at a\n$n^{-1/2}$ rate in most examples; this is the same rate as in the static case.\n", "versions": [{"version": "v1", "created": "Mon, 1 Apr 2019 18:18:16 GMT"}, {"version": "v2", "created": "Tue, 30 Jul 2019 08:11:51 GMT"}, {"version": "v3", "created": "Mon, 31 Aug 2020 03:30:30 GMT"}], "update_date": "2020-09-01", "authors_parsed": [["Adusumilli", "Karun", ""], ["Geiecke", "Friedrich", ""], ["Schilter", "Claudio", ""]]}, {"id": "1904.01049", "submitter": "Ben Letham", "authors": "Benjamin Letham, Eytan Bakshy", "title": "Bayesian Optimization for Policy Search via Online-Offline\n  Experimentation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Online field experiments are the gold-standard way of evaluating changes to\nreal-world interactive machine learning systems. Yet our ability to explore\ncomplex, multi-dimensional policy spaces - such as those found in\nrecommendation and ranking problems - is often constrained by the limited\nnumber of experiments that can be run simultaneously. To alleviate these\nconstraints, we augment online experiments with an offline simulator and apply\nmulti-task Bayesian optimization to tune live machine learning systems. We\ndescribe practical issues that arise in these types of applications, including\nbiases that arise from using a simulator and assumptions for the multi-task\nkernel. We measure empirical learning curves which show substantial gains from\nincluding data from biased offline experiments, and show how these learning\ncurves are consistent with theoretical results for multi-task Gaussian process\ngeneralization. We find that improved kernel inference is a significant driver\nof multi-task generalization. Finally, we show several examples of Bayesian\noptimization efficiently tuning a live machine learning system by combining\noffline and online experiments.\n", "versions": [{"version": "v1", "created": "Mon, 1 Apr 2019 18:19:11 GMT"}, {"version": "v2", "created": "Mon, 29 Apr 2019 16:38:06 GMT"}], "update_date": "2019-04-30", "authors_parsed": [["Letham", "Benjamin", ""], ["Bakshy", "Eytan", ""]]}, {"id": "1904.01059", "submitter": "Marco Romanelli", "authors": "Marco Romanelli and Konstantinos Chatzikokolakis and Catuscia\n  Palamidessi", "title": "Optimal Obfuscation Mechanisms via Machine Learning", "comments": "Preprint version of a paper that will appear on the Proceedings of\n  the IEEE 33rd Computer Security Foundations Symposium, CSF 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the problem of obfuscating sensitive information while preserving\nutility, and we propose a machine learning approach inspired by the generative\nadversarial networks paradigm. The idea is to set up two nets: the generator,\nthat tries to produce an optimal obfuscation mechanism to protect the data, and\nthe classifier, that tries to de-obfuscate the data. By letting the two nets\ncompete against each other, the mechanism improves its degree of protection,\nuntil an equilibrium is reached. We apply our method to the case of location\nprivacy, and we perform experiments on synthetic data and on real data from the\nGowalla dataset. We evaluate the privacy of the mechanism not only by its\ncapacity to defeat the classifier, but also in terms of the Bayes error, which\nrepresents the strongest possible adversary. We compare the privacy-utility\ntradeoff of our method to that of the planar Laplace mechanism used in\ngeo-indistinguishability, showing favorable results. Like the Laplace\nmechanism, our system can be deployed at the user end for protecting his\nlocation.\n", "versions": [{"version": "v1", "created": "Mon, 1 Apr 2019 18:33:54 GMT"}, {"version": "v2", "created": "Sat, 9 May 2020 19:16:51 GMT"}, {"version": "v3", "created": "Tue, 12 May 2020 10:36:22 GMT"}, {"version": "v4", "created": "Sat, 10 Oct 2020 16:55:29 GMT"}, {"version": "v5", "created": "Sun, 25 Oct 2020 17:18:12 GMT"}], "update_date": "2020-10-27", "authors_parsed": [["Romanelli", "Marco", ""], ["Chatzikokolakis", "Konstantinos", ""], ["Palamidessi", "Catuscia", ""]]}, {"id": "1904.01067", "submitter": "Yang Zhang", "authors": "Ahmed Salem and Apratim Bhattacharya and Michael Backes and Mario\n  Fritz and Yang Zhang", "title": "Updates-Leak: Data Set Inference and Reconstruction Attacks in Online\n  Learning", "comments": "USENIX Security 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Machine learning (ML) has progressed rapidly during the past decade and the\nmajor factor that drives such development is the unprecedented large-scale\ndata. As data generation is a continuous process, this leads to ML model owners\nupdating their models frequently with newly-collected data in an online\nlearning scenario. In consequence, if an ML model is queried with the same set\nof data samples at two different points in time, it will provide different\nresults.\n  In this paper, we investigate whether the change in the output of a black-box\nML model before and after being updated can leak information of the dataset\nused to perform the update, namely the updating set. This constitutes a new\nattack surface against black-box ML models and such information leakage may\ncompromise the intellectual property and data privacy of the ML model owner. We\npropose four attacks following an encoder-decoder formulation, which allows\ninferring diverse information of the updating set. Our new attacks are\nfacilitated by state-of-the-art deep learning techniques. In particular, we\npropose a hybrid generative model (CBM-GAN) that is based on generative\nadversarial networks (GANs) but includes a reconstructive loss that allows\nreconstructing accurate samples. Our experiments show that the proposed attacks\nachieve strong performance.\n", "versions": [{"version": "v1", "created": "Mon, 1 Apr 2019 19:08:49 GMT"}, {"version": "v2", "created": "Sat, 30 Nov 2019 14:53:28 GMT"}], "update_date": "2019-12-03", "authors_parsed": [["Salem", "Ahmed", ""], ["Bhattacharya", "Apratim", ""], ["Backes", "Michael", ""], ["Fritz", "Mario", ""], ["Zhang", "Yang", ""]]}, {"id": "1904.01068", "submitter": "Erdem B{\\i}y{\\i}k", "authors": "Erdem B{\\i}y{\\i}k, Jonathan Margoliash, Shahrouz Ryan Alimo, Dorsa\n  Sadigh", "title": "Efficient and Safe Exploration in Deterministic Markov Decision\n  Processes with Unknown Transition Models", "comments": "Proceedings of the American Control Conference (ACC), July 2019. The\n  first two authors have equal contribution", "journal-ref": null, "doi": "10.23919/ACC.2019.8815276", "report-no": null, "categories": "cs.RO cs.AI cs.LG cs.SY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a safe exploration algorithm for deterministic Markov Decision\nProcesses with unknown transition models. Our algorithm guarantees safety by\nleveraging Lipschitz-continuity to ensure that no unsafe states are visited\nduring exploration. Unlike many other existing techniques, the provided safety\nguarantee is deterministic. Our algorithm is optimized to reduce the number of\nactions needed for exploring the safe space. We demonstrate the performance of\nour algorithm in comparison with baseline methods in simulation on navigation\ntasks.\n", "versions": [{"version": "v1", "created": "Mon, 1 Apr 2019 19:09:08 GMT"}], "update_date": "2020-06-05", "authors_parsed": [["B\u0131y\u0131k", "Erdem", ""], ["Margoliash", "Jonathan", ""], ["Alimo", "Shahrouz Ryan", ""], ["Sadigh", "Dorsa", ""]]}, {"id": "1904.01070", "submitter": "Peyman Hosseinzadeh Kassani", "authors": "Peyman Hosseinzadeh Kassani, Alexej Gossmann, and Yu-Ping Wang", "title": "Multimodal Sparse Classifier for Adolescent Brain Age Prediction", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.NE q-bio.NC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The study of healthy brain development helps to better understand the brain\ntransformation and brain connectivity patterns which happen during childhood to\nadulthood. This study presents a sparse machine learning solution across\nwhole-brain functional connectivity (FC) measures of three sets of data,\nderived from resting state functional magnetic resonance imaging (rs-fMRI) and\ntask fMRI data, including a working memory n-back task (nb-fMRI) and an emotion\nidentification task (em-fMRI). These multi-modal image data are collected on a\nsample of adolescents from the Philadelphia Neurodevelopmental Cohort (PNC) for\nthe prediction of brain ages. Due to extremely large variable-to-instance ratio\nof PNC data, a high dimensional matrix with several irrelevant and highly\ncorrelated features is generated and hence a pattern learning approach is\nnecessary to extract significant features. We propose a sparse learner based on\nthe residual errors along the estimation of an inverse problem for the extreme\nlearning machine (ELM) neural network. The purpose of the approach is to\novercome the overlearning problem through pruning of several redundant features\nand their corresponding output weights. The proposed multimodal sparse ELM\nclassifier based on residual errors (RES-ELM) is highly competitive in terms of\nthe classification accuracy compared to its counterparts such as conventional\nELM, and sparse Bayesian learning ELM.\n", "versions": [{"version": "v1", "created": "Mon, 1 Apr 2019 19:13:07 GMT"}], "update_date": "2019-04-03", "authors_parsed": [["Kassani", "Peyman Hosseinzadeh", ""], ["Gossmann", "Alexej", ""], ["Wang", "Yu-Ping", ""]]}, {"id": "1904.01080", "submitter": "Lee Clement", "authors": "Lee Clement, Mona Gridseth, Justin Tomasi and Jonathan Kelly", "title": "Learning Matchable Image Transformations for Long-term Metric Visual\n  Localization", "comments": "In IEEE Robotics and Automation Letters (RA-L) and presented at the\n  IEEE International Conference on Robotics and Automation (ICRA'20), Paris,\n  France, May 31-June 4, 2020", "journal-ref": null, "doi": "10.1109/LRA.2020.2967659", "report-no": null, "categories": "cs.CV cs.LG cs.RO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Long-term metric self-localization is an essential capability of autonomous\nmobile robots, but remains challenging for vision-based systems due to\nappearance changes caused by lighting, weather, or seasonal variations. While\nexperience-based mapping has proven to be an effective technique for bridging\nthe `appearance gap,' the number of experiences required for reliable metric\nlocalization over days or months can be very large, and methods for reducing\nthe necessary number of experiences are needed for this approach to scale.\nTaking inspiration from color constancy theory, we learn a nonlinear\nRGB-to-grayscale mapping that explicitly maximizes the number of inlier feature\nmatches for images captured under different lighting and weather conditions,\nand use it as a pre-processing step in a conventional single-experience\nlocalization pipeline to improve its robustness to appearance change. We train\nthis mapping by approximating the target non-differentiable localization\npipeline with a deep neural network, and find that incorporating a learned\nlow-dimensional context feature can further improve cross-appearance feature\nmatching. Using synthetic and real-world datasets, we demonstrate substantial\nimprovements in localization performance across day-night cycles, enabling\ncontinuous metric localization over a 30-hour period using a single mapping\nexperience, and allowing experience-based localization to scale to long\ndeployments with dramatically reduced data requirements.\n", "versions": [{"version": "v1", "created": "Mon, 1 Apr 2019 19:38:56 GMT"}, {"version": "v2", "created": "Sun, 8 Dec 2019 17:06:19 GMT"}, {"version": "v3", "created": "Mon, 13 Jan 2020 03:53:09 GMT"}, {"version": "v4", "created": "Thu, 27 Feb 2020 20:23:40 GMT"}], "update_date": "2020-03-02", "authors_parsed": [["Clement", "Lee", ""], ["Gridseth", "Mona", ""], ["Tomasi", "Justin", ""], ["Kelly", "Jonathan", ""]]}, {"id": "1904.01083", "submitter": "Ardavan Bidgoli", "authors": "Ardavan Bidgoli, Pedro Veloso", "title": "DeepCloud. The Application of a Data-driven, Generative Model in Design", "comments": null, "journal-ref": "ACADIA 2018: Recalibration. On imprecision and infidelity.\n  Proceedings of the 38th Annual Conference of the Association for Computer\n  Aided Design in Architecture (ACADIA) ISBN 978-0-692-17729-7, Mexico City,\n  2018, pp. 176-185", "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Generative systems have a significant potential to synthesize innovative\ndesign alternatives. Still, most of the common systems that have been adopted\nin design require the designer to explicitly define the specifications of the\nprocedures and in some cases the design space. In contrast, a generative system\ncould potentially learn both aspects through processing a database of existing\nsolutions without the supervision of the designer. To explore this possibility,\nwe review recent advancements of generative models in machine learning and\ncurrent applications of learning techniques in design. Then, we describe the\ndevelopment of a data-driven generative system titled DeepCloud. It combines an\nautoencoder architecture for point clouds with a web-based interface and analog\ninput devices to provide an intuitive experience for data-driven generation of\ndesign alternatives. We delineate the implementation of two prototypes of\nDeepCloud, their contributions, and potentials for generative design.\n", "versions": [{"version": "v1", "created": "Mon, 1 Apr 2019 19:45:45 GMT"}], "update_date": "2019-04-03", "authors_parsed": [["Bidgoli", "Ardavan", ""], ["Veloso", "Pedro", ""]]}, {"id": "1904.01098", "submitter": "Yunsheng Bai", "authors": "Yunsheng Bai, Hao Ding, Yang Qiao, Agustin Marinovic, Ken Gu, Ting\n  Chen, Yizhou Sun, Wei Wang", "title": "Unsupervised Inductive Graph-Level Representation Learning via\n  Graph-Graph Proximity", "comments": "IJCAI 2019 camera ready version with supplementary material", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce a novel approach to graph-level representation learning, which\nis to embed an entire graph into a vector space where the embeddings of two\ngraphs preserve their graph-graph proximity. Our approach, UGRAPHEMB, is a\ngeneral framework that provides a novel means to performing graph-level\nembedding in a completely unsupervised and inductive manner. The learned neural\nnetwork can be considered as a function that receives any graph as input,\neither seen or unseen in the training set, and transforms it into an embedding.\nA novel graph-level embedding generation mechanism called Multi-Scale Node\nAttention (MSNA), is proposed. Experiments on five real graph datasets show\nthat UGRAPHEMB achieves competitive accuracy in the tasks of graph\nclassification, similarity ranking, and graph visualization.\n", "versions": [{"version": "v1", "created": "Mon, 1 Apr 2019 20:33:27 GMT"}, {"version": "v2", "created": "Sun, 2 Jun 2019 22:41:29 GMT"}], "update_date": "2019-06-04", "authors_parsed": [["Bai", "Yunsheng", ""], ["Ding", "Hao", ""], ["Qiao", "Yang", ""], ["Marinovic", "Agustin", ""], ["Gu", "Ken", ""], ["Chen", "Ting", ""], ["Sun", "Yizhou", ""], ["Wang", "Wei", ""]]}, {"id": "1904.01112", "submitter": "Florian Knoll", "authors": "Florian Knoll, Kerstin Hammernik, Chi Zhang, Steen Moeller, Thomas\n  Pock, Daniel K. Sodickson, Mehmet Akcakaya", "title": "Deep Learning Methods for Parallel Magnetic Resonance Image\n  Reconstruction", "comments": "14 pages, 7 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.SP cs.CV cs.LG eess.IV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Following the success of deep learning in a wide range of applications,\nneural network-based machine learning techniques have received interest as a\nmeans of accelerating magnetic resonance imaging (MRI). A number of ideas\ninspired by deep learning techniques from computer vision and image processing\nhave been successfully applied to non-linear image reconstruction in the spirit\nof compressed sensing for both low dose computed tomography and accelerated\nMRI. The additional integration of multi-coil information to recover missing\nk-space lines in the MRI reconstruction process, is still studied less\nfrequently, even though it is the de-facto standard for currently used\naccelerated MR acquisitions. This manuscript provides an overview of the recent\nmachine learning approaches that have been proposed specifically for improving\nparallel imaging. A general background introduction to parallel MRI is given\nthat is structured around the classical view of image space and k-space based\nmethods. Both linear and non-linear methods are covered, followed by a\ndiscussion of recent efforts to further improve parallel imaging using machine\nlearning, and specifically using artificial neural networks. Image-domain based\ntechniques that introduce improved regularizers are covered as well as k-space\nbased methods, where the focus is on better interpolation strategies using\nneural networks. Issues and open problems are discussed as well as recent\nefforts for producing open datasets and benchmarks for the community.\n", "versions": [{"version": "v1", "created": "Mon, 1 Apr 2019 21:23:23 GMT"}], "update_date": "2019-04-03", "authors_parsed": [["Knoll", "Florian", ""], ["Hammernik", "Kerstin", ""], ["Zhang", "Chi", ""], ["Moeller", "Steen", ""], ["Pock", "Thomas", ""], ["Sodickson", "Daniel K.", ""], ["Akcakaya", "Mehmet", ""]]}, {"id": "1904.01120", "submitter": "Cheng-I Lai", "authors": "Cheng-I Lai, Nanxin Chen, Jes\\'us Villalba, Najim Dehak", "title": "ASSERT: Anti-Spoofing with Squeeze-Excitation and Residual neTworks", "comments": "Submitted to Interspeech 2019, Graz, Austria", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG cs.SD eess.AS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present JHU's system submission to the ASVspoof 2019 Challenge:\nAnti-Spoofing with Squeeze-Excitation and Residual neTworks (ASSERT).\nAnti-spoofing has gathered more and more attention since the inauguration of\nthe ASVspoof Challenges, and ASVspoof 2019 dedicates to address attacks from\nall three major types: text-to-speech, voice conversion, and replay. Built upon\nprevious research work on Deep Neural Network (DNN), ASSERT is a pipeline for\nDNN-based approach to anti-spoofing. ASSERT has four components: feature\nengineering, DNN models, network optimization and system combination, where the\nDNN models are variants of squeeze-excitation and residual networks. We\nconducted an ablation study of the effectiveness of each component on the\nASVspoof 2019 corpus, and experimental results showed that ASSERT obtained more\nthan 93% and 17% relative improvements over the baseline systems in the two\nsub-challenges in ASVspooof 2019, ranking ASSERT one of the top performing\nsystems. Code and pretrained models will be made publicly available.\n", "versions": [{"version": "v1", "created": "Mon, 1 Apr 2019 21:47:00 GMT"}], "update_date": "2019-04-03", "authors_parsed": [["Lai", "Cheng-I", ""], ["Chen", "Nanxin", ""], ["Villalba", "Jes\u00fas", ""], ["Dehak", "Najim", ""]]}, {"id": "1904.01121", "submitter": "Sharon Zhou", "authors": "Sharon Zhou, Mitchell L. Gordon, Ranjay Krishna, Austin Narcomey, Li\n  Fei-Fei, Michael S. Bernstein", "title": "HYPE: A Benchmark for Human eYe Perceptual Evaluation of Generative\n  Models", "comments": "https://hype.stanford.edu", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.HC cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Generative models often use human evaluations to measure the perceived\nquality of their outputs. Automated metrics are noisy indirect proxies, because\nthey rely on heuristics or pretrained embeddings. However, up until now, direct\nhuman evaluation strategies have been ad-hoc, neither standardized nor\nvalidated. Our work establishes a gold standard human benchmark for generative\nrealism. We construct Human eYe Perceptual Evaluation (HYPE) a human benchmark\nthat is (1) grounded in psychophysics research in perception, (2) reliable\nacross different sets of randomly sampled outputs from a model, (3) able to\nproduce separable model performances, and (4) efficient in cost and time. We\nintroduce two variants: one that measures visual perception under adaptive time\nconstraints to determine the threshold at which a model's outputs appear real\n(e.g. 250ms), and the other a less expensive variant that measures human error\nrate on fake and real images sans time constraints. We test HYPE across six\nstate-of-the-art generative adversarial networks and two sampling techniques on\nconditional and unconditional image generation using four datasets: CelebA,\nFFHQ, CIFAR-10, and ImageNet. We find that HYPE can track model improvements\nacross training epochs, and we confirm via bootstrap sampling that HYPE\nrankings are consistent and replicable.\n", "versions": [{"version": "v1", "created": "Mon, 1 Apr 2019 21:48:41 GMT"}, {"version": "v2", "created": "Wed, 24 Apr 2019 03:58:24 GMT"}, {"version": "v3", "created": "Fri, 24 May 2019 05:35:31 GMT"}, {"version": "v4", "created": "Thu, 31 Oct 2019 23:43:11 GMT"}], "update_date": "2019-11-04", "authors_parsed": [["Zhou", "Sharon", ""], ["Gordon", "Mitchell L.", ""], ["Krishna", "Ranjay", ""], ["Narcomey", "Austin", ""], ["Fei-Fei", "Li", ""], ["Bernstein", "Michael S.", ""]]}, {"id": "1904.01125", "submitter": "Melissa Aczon", "authors": "Eugene Laksana, Melissa Aczon, Long Ho, Cameron Carlin, David\n  Ledbetter, Randall Wetzel", "title": "The Impact of Extraneous Variables on the Performance of Recurrent\n  Neural Network Models in Clinical Tasks", "comments": "9 pages (2 in appendix), 2 figures, 5 tables (2 in appendix)", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Electronic Medical Records (EMR) are a rich source of patient information,\nincluding measurements reflecting physiologic signs and administered therapies.\nIdentifying which variables are useful in predicting clinical outcomes can be\nchallenging. Advanced algorithms such as deep neural networks were designed to\nprocess high-dimensional inputs containing variables in their measured form,\nthus bypass separate feature selection or engineering steps. We investigated\nthe effect of extraneous input variables on the predictive performance of\nRecurrent Neural Networks (RNN) by including in the input vector extraneous\nvariables randomly drawn from theoretical and empirical distributions. RNN\nmodels using different input vectors (EMR variables; EMR and extraneous\nvariables; extraneous variables only) were trained to predict three clinical\noutcomes: in-ICU mortality, 72-hour ICU re-admission, and 30-day ICU-free days.\nThe measured degradations of the RNN's predictive performance with the addition\nof extraneous variables to EMR variables were negligible.\n", "versions": [{"version": "v1", "created": "Mon, 1 Apr 2019 21:58:20 GMT"}], "update_date": "2019-04-03", "authors_parsed": [["Laksana", "Eugene", ""], ["Aczon", "Melissa", ""], ["Ho", "Long", ""], ["Carlin", "Cameron", ""], ["Ledbetter", "David", ""], ["Wetzel", "Randall", ""]]}, {"id": "1904.01126", "submitter": "Rakshit Agrawal", "authors": "Jack W. Stokes, Rakshit Agrawal, Geoff McDonald, Matthew Hausknecht", "title": "ScriptNet: Neural Static Analysis for Malicious JavaScript Detection", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Malicious scripts are an important computer infection threat vector in the\nwild. For web-scale processing, static analysis offers substantial computing\nefficiencies. We propose the ScriptNet system for neural malicious JavaScript\ndetection which is based on static analysis. We use the Convoluted Partitioning\nof Long Sequences (CPoLS) model, which processes Javascript files as byte\nsequences. Lower layers capture the sequential nature of these byte sequences\nwhile higher layers classify the resulting embedding as malicious or benign.\nUnlike previously proposed solutions, our model variants are trained in an\nend-to-end fashion allowing discriminative training even for the sequential\nprocessing layers. Evaluating this model on a large corpus of 212,408\nJavaScript files indicates that the best performing CPoLS model offers a 97.20%\ntrue positive rate (TPR) for the first 60K byte subsequence at a false positive\nrate (FPR) of 0.50%. The best performing CPoLS model significantly outperform\nseveral baseline models.\n", "versions": [{"version": "v1", "created": "Mon, 1 Apr 2019 22:00:57 GMT"}], "update_date": "2019-04-03", "authors_parsed": [["Stokes", "Jack W.", ""], ["Agrawal", "Rakshit", ""], ["McDonald", "Geoff", ""], ["Hausknecht", "Matthew", ""]]}, {"id": "1904.01127", "submitter": "Pedro M. Ferreira", "authors": "Nuno Dion\\'isio, Fernando Alves, Pedro M. Ferreira, Alysson Bessani", "title": "Cyberthreat Detection from Twitter using Deep Neural Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR cs.SI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  To be prepared against cyberattacks, most organizations resort to security\ninformation and event management systems to monitor their infrastructures.\nThese systems depend on the timeliness and relevance of the latest updates,\npatches and threats provided by cyberthreat intelligence feeds. Open source\nintelligence platforms, namely social media networks such as Twitter, are\ncapable of aggregating a vast amount of cybersecurity-related sources. To\nprocess such information streams, we require scalable and efficient tools\ncapable of identifying and summarizing relevant information for specified\nassets. This paper presents the processing pipeline of a novel tool that uses\ndeep neural networks to process cybersecurity information received from\nTwitter. A convolutional neural network identifies tweets containing\nsecurity-related information relevant to assets in an IT infrastructure. Then,\na bidirectional long short-term memory network extracts named entities from\nthese tweets to form a security alert or to fill an indicator of compromise.\nThe proposed pipeline achieves an average 94% true positive rate and 91% true\nnegative rate for the classification task and an average F1-score of 92% for\nthe named entity recognition task, across three case study infrastructures.\n", "versions": [{"version": "v1", "created": "Mon, 1 Apr 2019 22:04:29 GMT"}], "update_date": "2019-04-03", "authors_parsed": [["Dion\u00edsio", "Nuno", ""], ["Alves", "Fernando", ""], ["Ferreira", "Pedro M.", ""], ["Bessani", "Alysson", ""]]}, {"id": "1904.01138", "submitter": "Lifu Tu", "authors": "Lifu Tu, Kevin Gimpel", "title": "Benchmarking Approximate Inference Methods for Neural Structured\n  Prediction", "comments": "NAACL2019 camera-ready version", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Exact structured inference with neural network scoring functions is\ncomputationally challenging but several methods have been proposed for\napproximating inference. One approach is to perform gradient descent with\nrespect to the output structure directly (Belanger and McCallum, 2016). Another\napproach, proposed recently, is to train a neural network (an \"inference\nnetwork\") to perform inference (Tu and Gimpel, 2018). In this paper, we compare\nthese two families of inference methods on three sequence labeling datasets. We\nchoose sequence labeling because it permits us to use exact inference as a\nbenchmark in terms of speed, accuracy, and search error. Across datasets, we\ndemonstrate that inference networks achieve a better speed/accuracy/search\nerror trade-off than gradient descent, while also being faster than exact\ninference at similar accuracy levels. We find further benefit by combining\ninference networks and gradient descent, using the former to provide a warm\nstart for the latter.\n", "versions": [{"version": "v1", "created": "Mon, 1 Apr 2019 23:08:05 GMT"}, {"version": "v2", "created": "Sat, 6 Jul 2019 23:05:09 GMT"}], "update_date": "2019-07-09", "authors_parsed": [["Tu", "Lifu", ""], ["Gimpel", "Kevin", ""]]}, {"id": "1904.01139", "submitter": "Yannick Schroecker", "authors": "Yannick Schroecker, Mel Vecerik, Jonathan Scholz", "title": "Generative predecessor models for sample-efficient imitation learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose Generative Predecessor Models for Imitation Learning (GPRIL), a\nnovel imitation learning algorithm that matches the state-action distribution\nto the distribution observed in expert demonstrations, using generative models\nto reason probabilistically about alternative histories of demonstrated states.\nWe show that this approach allows an agent to learn robust policies using only\na small number of expert demonstrations and self-supervised interactions with\nthe environment. We derive this approach from first principles and compare it\nempirically to a state-of-the-art imitation learning method, showing that it\noutperforms or matches its performance on two simulated robot manipulation\ntasks and demonstrate significantly higher sample efficiency by applying the\nalgorithm on a real robot.\n", "versions": [{"version": "v1", "created": "Mon, 1 Apr 2019 23:13:24 GMT"}], "update_date": "2019-04-03", "authors_parsed": [["Schroecker", "Yannick", ""], ["Vecerik", "Mel", ""], ["Scholz", "Jonathan", ""]]}, {"id": "1904.01156", "submitter": "Nikos Kargas", "authors": "Nikos Kargas, Nicholas D. Sidiropoulos", "title": "Learning Mixtures of Smooth Product Distributions: Identifiability and\n  Algorithm", "comments": "accepted to appear in AISTATS 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.SP cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the problem of learning a mixture model of non-parametric product\ndistributions. The problem of learning a mixture model is that of finding the\ncomponent distributions along with the mixing weights using observed samples\ngenerated from the mixture. The problem is well-studied in the parametric\nsetting, i.e., when the component distributions are members of a parametric\nfamily -- such as Gaussian distributions. In this work, we focus on\nmultivariate mixtures of non-parametric product distributions and propose a\ntwo-stage approach which recovers the component distributions of the mixture\nunder a smoothness condition. Our approach builds upon the identifiability\nproperties of the canonical polyadic (low-rank) decomposition of tensors, in\ntandem with Fourier and Shannon-Nyquist sampling staples from signal\nprocessing. We demonstrate the effectiveness of the approach on synthetic and\nreal datasets.\n", "versions": [{"version": "v1", "created": "Tue, 2 Apr 2019 00:34:26 GMT"}], "update_date": "2019-04-03", "authors_parsed": [["Kargas", "Nikos", ""], ["Sidiropoulos", "Nicholas D.", ""]]}, {"id": "1904.01178", "submitter": "Shahinur Alam", "authors": "Shahinur Alam, Mohammed Yeasin", "title": "Person Identification with Visual Summary for a Safe Access to a Smart\n  Home", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  SafeAccess is an integrated system designed to provide easier and safer\naccess to a smart home for people with or without disabilities. The system is\ndesigned to enhance safety and promote the independence of people with\ndisability (i.e., visually impaired). The key functionality of the system\nincludes the detection and identification of human and generating contextual\nvisual summary from the real-time video streams obtained from the cameras\nplaced in strategic locations around the house. In addition, the system\nclassifies human into groups (i.e. friends/families/caregiver versus\nintruders/burglars/unknown). These features allow the user to grant/deny remote\naccess to the premises or ability to call emergency services. In this paper, we\nfocus on designing a prototype system for the smart home and building a robust\nrecognition engine that meets the system criteria and addresses speed,\naccuracy, deployment and environmental challenges under a wide variety of\npractical and real-life situations. To interact with the system, we implemented\na dialog enabled interface to create a personalized profile using face images\nor video of friend/families/caregiver. To improve computational efficiency, we\napply change detection to filter out frames and use Faster-RCNN to detect the\nhuman presence and extract faces using Multitask Cascaded Convolutional\nNetworks (MTCNN). Subsequently, we apply LBP/FaceNet to identify a person and\ngroups by matching extracted faces with the profile. SafeAccess sends a visual\nsummary to the users with an MMS containing a person's name if any match found\nor as \"Unknown\", scene image, facial description, and contextual information.\nSafeAccess identifies friends/families/caregiver versus intruders/unknown with\nan average F-score 0.97 and generates a visual summary from 10 classes with an\naverage accuracy of 98.01%.\n", "versions": [{"version": "v1", "created": "Tue, 2 Apr 2019 02:25:31 GMT"}, {"version": "v2", "created": "Thu, 18 Apr 2019 23:24:00 GMT"}], "update_date": "2019-04-22", "authors_parsed": [["Alam", "Shahinur", ""], ["Yeasin", "Mohammed", ""]]}, {"id": "1904.01184", "submitter": "Zhiming Zhou", "authors": "Zhiming Zhou, Jian Shen, Yuxuan Song, Weinan Zhang, Yong Yu", "title": "Towards Efficient and Unbiased Implementation of Lipschitz Continuity in\n  GANs", "comments": "Submitted to IJCAI 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Lipschitz continuity recently becomes popular in generative adversarial\nnetworks (GANs). It was observed that the Lipschitz regularized discriminator\nleads to improved training stability and sample quality. The mainstream\nimplementations of Lipschitz continuity include gradient penalty and spectral\nnormalization. In this paper, we demonstrate that gradient penalty introduces\nundesired bias, while spectral normalization might be over restrictive. We\naccordingly propose a new method which is efficient and unbiased. Our\nexperiments verify our analysis and show that the proposed method is able to\nachieve successful training in various situations where gradient penalty and\nspectral normalization fail.\n", "versions": [{"version": "v1", "created": "Tue, 2 Apr 2019 02:57:19 GMT"}], "update_date": "2019-04-03", "authors_parsed": [["Zhou", "Zhiming", ""], ["Shen", "Jian", ""], ["Song", "Yuxuan", ""], ["Zhang", "Weinan", ""], ["Yu", "Yong", ""]]}, {"id": "1904.01186", "submitter": "Hanting Chen", "authors": "Hanting Chen, Yunhe Wang, Chang Xu, Zhaohui Yang, Chuanjian Liu, Boxin\n  Shi, Chunjing Xu, Chao Xu, Qi Tian", "title": "Data-Free Learning of Student Networks", "comments": null, "journal-ref": "ICCV 2019", "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Learning portable neural networks is very essential for computer vision for\nthe purpose that pre-trained heavy deep models can be well applied on edge\ndevices such as mobile phones and micro sensors. Most existing deep neural\nnetwork compression and speed-up methods are very effective for training\ncompact deep models, when we can directly access the training dataset. However,\ntraining data for the given deep network are often unavailable due to some\npractice problems (e.g. privacy, legal issue, and transmission), and the\narchitecture of the given network are also unknown except some interfaces. To\nthis end, we propose a novel framework for training efficient deep neural\nnetworks by exploiting generative adversarial networks (GANs). To be specific,\nthe pre-trained teacher networks are regarded as a fixed discriminator and the\ngenerator is utilized for derivating training samples which can obtain the\nmaximum response on the discriminator. Then, an efficient network with smaller\nmodel size and computational complexity is trained using the generated data and\nthe teacher network, simultaneously. Efficient student networks learned using\nthe proposed Data-Free Learning (DAFL) method achieve 92.22% and 74.47%\naccuracies using ResNet-18 without any training data on the CIFAR-10 and\nCIFAR-100 datasets, respectively. Meanwhile, our student network obtains an\n80.56% accuracy on the CelebA benchmark.\n", "versions": [{"version": "v1", "created": "Tue, 2 Apr 2019 03:00:06 GMT"}, {"version": "v2", "created": "Wed, 29 May 2019 06:50:22 GMT"}, {"version": "v3", "created": "Thu, 5 Sep 2019 06:54:30 GMT"}, {"version": "v4", "created": "Tue, 31 Dec 2019 06:58:35 GMT"}], "update_date": "2020-01-01", "authors_parsed": [["Chen", "Hanting", ""], ["Wang", "Yunhe", ""], ["Xu", "Chang", ""], ["Yang", "Zhaohui", ""], ["Liu", "Chuanjian", ""], ["Shi", "Boxin", ""], ["Xu", "Chunjing", ""], ["Xu", "Chao", ""], ["Tian", "Qi", ""]]}, {"id": "1904.01191", "submitter": "Zaheer Abbas", "authors": "Yi Wan, Zaheer Abbas, Adam White, Martha White and Richard S. Sutton", "title": "Planning with Expectation Models", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Distribution and sample models are two popular model choices in model-based\nreinforcement learning (MBRL). However, learning these models can be\nintractable, particularly when the state and action spaces are large.\nExpectation models, on the other hand, are relatively easier to learn due to\ntheir compactness and have also been widely used for deterministic\nenvironments. For stochastic environments, it is not obvious how expectation\nmodels can be used for planning as they only partially characterize a\ndistribution. In this paper, we propose a sound way of using approximate\nexpectation models for MBRL. In particular, we 1) show that planning with an\nexpectation model is equivalent to planning with a distribution model if the\nstate value function is linear in state features, 2) analyze two common\nparametrization choices for approximating the expectation: linear and\nnon-linear expectation models, 3) propose a sound model-based policy evaluation\nalgorithm and present its convergence results, and 4) empirically demonstrate\nthe effectiveness of the proposed planning algorithm.\n", "versions": [{"version": "v1", "created": "Tue, 2 Apr 2019 03:25:25 GMT"}, {"version": "v2", "created": "Wed, 3 Apr 2019 04:48:48 GMT"}, {"version": "v3", "created": "Fri, 6 Dec 2019 04:33:31 GMT"}, {"version": "v4", "created": "Wed, 29 Jul 2020 22:40:04 GMT"}], "update_date": "2020-07-31", "authors_parsed": [["Wan", "Yi", ""], ["Abbas", "Zaheer", ""], ["White", "Adam", ""], ["White", "Martha", ""], ["Sutton", "Richard S.", ""]]}, {"id": "1904.01198", "submitter": "Poojan Oza", "authors": "Poojan Oza and Vishal M Patel", "title": "C2AE: Class Conditioned Auto-Encoder for Open-set Recognition", "comments": "CVPR2019 (Oral)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Models trained for classification often assume that all testing classes are\nknown while training. As a result, when presented with an unknown class during\ntesting, such closed-set assumption forces the model to classify it as one of\nthe known classes. However, in a real world scenario, classification models are\nlikely to encounter such examples. Hence, identifying those examples as unknown\nbecomes critical to model performance. A potential solution to overcome this\nproblem lies in a class of learning problems known as open-set recognition. It\nrefers to the problem of identifying the unknown classes during testing, while\nmaintaining performance on the known classes. In this paper, we propose an\nopen-set recognition algorithm using class conditioned auto-encoders with novel\ntraining and testing methodology. In contrast to previous methods, training\nprocedure is divided in two sub-tasks, 1. closed-set classification and, 2.\nopen-set identification (i.e. identifying a class as known or unknown). Encoder\nlearns the first task following the closed-set classification training\npipeline, whereas decoder learns the second task by reconstructing conditioned\non class identity. Furthermore, we model reconstruction errors using the\nExtreme Value Theory of statistical modeling to find the threshold for\nidentifying known/unknown class samples. Experiments performed on multiple\nimage classification datasets show proposed method performs significantly\nbetter than state of the art.\n", "versions": [{"version": "v1", "created": "Tue, 2 Apr 2019 03:47:39 GMT"}], "update_date": "2019-04-03", "authors_parsed": [["Oza", "Poojan", ""], ["Patel", "Vishal M", ""]]}, {"id": "1904.01200", "submitter": "Jesus Tordesillas Torres", "authors": "Jesus Tordesillas, Juncal Arbelaiz", "title": "Personalized Cancer Chemotherapy Schedule: a numerical comparison of\n  performance and robustness in model-based and model-free scheduling\n  methodologies", "comments": "Minor changes", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Reinforcement learning algorithms are gaining popularity in fields in which\noptimal scheduling is important, and oncology is not an exception. The complex\nand uncertain dynamics of cancer limit the performance of traditional\nmodel-based scheduling strategies like Optimal Control. Motivated by the recent\nsuccess of model-free Deep Reinforcement Learning (DRL) in challenging control\ntasks and in the design of medical treatments, we use Deep Q-Network (DQN) and\nDeep Deterministic Policy Gradient (DDPG) to design a personalized cancer\nchemotherapy schedule. We show that both of them succeed in the task and\noutperform the Optimal Control solution in the presence of uncertainty.\nFurthermore, we show that DDPG can exterminate cancer more efficiently than DQN\npresumably due to its continuous action space. Finally, we provide some insight\nregarding the amount of samples required for the training.\n", "versions": [{"version": "v1", "created": "Tue, 2 Apr 2019 03:52:08 GMT"}, {"version": "v2", "created": "Sat, 6 Apr 2019 15:56:55 GMT"}, {"version": "v3", "created": "Mon, 2 Sep 2019 21:53:06 GMT"}], "update_date": "2019-09-04", "authors_parsed": [["Tordesillas", "Jesus", ""], ["Arbelaiz", "Juncal", ""]]}, {"id": "1904.01201", "submitter": "Manolis Savva", "authors": "Manolis Savva, Abhishek Kadian, Oleksandr Maksymets, Yili Zhao, Erik\n  Wijmans, Bhavana Jain, Julian Straub, Jia Liu, Vladlen Koltun, Jitendra\n  Malik, Devi Parikh, Dhruv Batra", "title": "Habitat: A Platform for Embodied AI Research", "comments": "ICCV 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.CL cs.LG cs.RO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present Habitat, a platform for research in embodied artificial\nintelligence (AI). Habitat enables training embodied agents (virtual robots) in\nhighly efficient photorealistic 3D simulation. Specifically, Habitat consists\nof: (i) Habitat-Sim: a flexible, high-performance 3D simulator with\nconfigurable agents, sensors, and generic 3D dataset handling. Habitat-Sim is\nfast -- when rendering a scene from Matterport3D, it achieves several thousand\nframes per second (fps) running single-threaded, and can reach over 10,000 fps\nmulti-process on a single GPU. (ii) Habitat-API: a modular high-level library\nfor end-to-end development of embodied AI algorithms -- defining tasks (e.g.,\nnavigation, instruction following, question answering), configuring, training,\nand benchmarking embodied agents.\n  These large-scale engineering contributions enable us to answer scientific\nquestions requiring experiments that were till now impracticable or 'merely'\nimpractical. Specifically, in the context of point-goal navigation: (1) we\nrevisit the comparison between learning and SLAM approaches from two recent\nworks and find evidence for the opposite conclusion -- that learning\noutperforms SLAM if scaled to an order of magnitude more experience than\nprevious investigations, and (2) we conduct the first cross-dataset\ngeneralization experiments {train, test} x {Matterport3D, Gibson} for multiple\nsensors {blind, RGB, RGBD, D} and find that only agents with depth (D) sensors\ngeneralize across datasets. We hope that our open-source platform and these\nfindings will advance research in embodied AI.\n", "versions": [{"version": "v1", "created": "Tue, 2 Apr 2019 03:52:27 GMT"}, {"version": "v2", "created": "Mon, 25 Nov 2019 01:39:04 GMT"}], "update_date": "2019-11-26", "authors_parsed": [["Savva", "Manolis", ""], ["Kadian", "Abhishek", ""], ["Maksymets", "Oleksandr", ""], ["Zhao", "Yili", ""], ["Wijmans", "Erik", ""], ["Jain", "Bhavana", ""], ["Straub", "Julian", ""], ["Liu", "Jia", ""], ["Koltun", "Vladlen", ""], ["Malik", "Jitendra", ""], ["Parikh", "Devi", ""], ["Batra", "Dhruv", ""]]}, {"id": "1904.01205", "submitter": "Rosalind Wang", "authors": "Mike Li, X. Rosalind Wang", "title": "Peak Alignment of Gas Chromatography-Mass Spectrometry Data with Deep\n  Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present ChromAlignNet, a deep learning model for alignment of peaks in Gas\nChromatography-Mass Spectrometry (GC-MS) data. In GC-MS data, a compound's\nretention time (RT) may not stay fixed across multiple chromatograms. To use\nGC-MS data for biomarker discovery requires alignment of identical analyte's RT\nfrom different samples. Current methods of alignment are all based on a set of\nformal, mathematical rules. We present a solution to GC-MS alignment using deep\nlearning neural networks, which are more adept at complex, fuzzy data sets. We\ntested our model on several GC-MS data sets of various complexities and\nanalysed the alignment results quantitatively. We show the model has very good\nperformance (AUC $\\sim 1$ for simple data sets and AUC $\\sim 0.85$ for very\ncomplex data sets). Further, our model easily outperforms existing algorithms\non complex data sets. Compared with existing methods, ChromAlignNet is very\neasy to use as it requires no user input of reference chromatograms and\nparameters. This method can easily be adapted to other similar data such as\nthose from liquid chromatography. The source code is written in Python and\navailable online.\n", "versions": [{"version": "v1", "created": "Tue, 2 Apr 2019 04:16:45 GMT"}, {"version": "v2", "created": "Wed, 7 Aug 2019 06:31:27 GMT"}, {"version": "v3", "created": "Tue, 20 Aug 2019 01:21:59 GMT"}], "update_date": "2019-08-21", "authors_parsed": [["Li", "Mike", ""], ["Wang", "X. Rosalind", ""]]}, {"id": "1904.01209", "submitter": "Connie Kou", "authors": "Cuong Phuc Ngo, Amadeus Aristo Winarto, Connie Kou Khor Li, Sojeong\n  Park, Farhan Akram, Hwee Kuan Lee", "title": "Fence GAN: Towards Better Anomaly Detection", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Anomaly detection is a classical problem where the aim is to detect anomalous\ndata that do not belong to the normal data distribution. Current\nstate-of-the-art methods for anomaly detection on complex high-dimensional data\nare based on the generative adversarial network (GAN). However, the traditional\nGAN loss is not directly aligned with the anomaly detection objective: it\nencourages the distribution of the generated samples to overlap with the real\ndata and so the resulting discriminator has been found to be ineffective as an\nanomaly detector. In this paper, we propose simple modifications to the GAN\nloss such that the generated samples lie at the boundary of the real data\ndistribution. With our modified GAN loss, our anomaly detection method, called\nFence GAN (FGAN), directly uses the discriminator score as an anomaly\nthreshold. Our experimental results using the MNIST, CIFAR10 and KDD99 datasets\nshow that Fence GAN yields the best anomaly classification accuracy compared to\nstate-of-the-art methods.\n", "versions": [{"version": "v1", "created": "Tue, 2 Apr 2019 04:36:15 GMT"}], "update_date": "2019-04-03", "authors_parsed": [["Ngo", "Cuong Phuc", ""], ["Winarto", "Amadeus Aristo", ""], ["Li", "Connie Kou Khor", ""], ["Park", "Sojeong", ""], ["Akram", "Farhan", ""], ["Lee", "Hwee Kuan", ""]]}, {"id": "1904.01214", "submitter": "Dong Eui Chang", "authors": "Chang Sik Lee, Dong Eui Chang", "title": "Enhancement of Energy-Based Swing-Up Controller via Entropy Search", "comments": "6 pages, 2019 Asian Control Conference", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.SY math.OC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  An energy based approach for stabilizing a mechanical system has offered a\nsimple yet powerful control scheme. However, since it does not impose such\nstrong constraints on parameter space of the controller, finding appropriate\nparameter values for an optimal controller is known to be hard. This paper\nintends to generate an optimal energy-based controller for swinging up a rotary\ninverted pendulum, also known as the Furuta pendulum, by applying the Bayesian\noptimization called Entropy Search. Simulations and experiments show that the\noptimal controller has an improved performance compared to a nominal controller\nfor various initial conditions.\n", "versions": [{"version": "v1", "created": "Tue, 2 Apr 2019 04:56:09 GMT"}, {"version": "v2", "created": "Wed, 3 Apr 2019 16:31:45 GMT"}], "update_date": "2019-04-04", "authors_parsed": [["Lee", "Chang Sik", ""], ["Chang", "Dong Eui", ""]]}, {"id": "1904.01269", "submitter": "Volodya Grancharov", "authors": "Stefano Imoscopi, Volodya Grancharov, Sigurdur Sverrisson, Erlendur\n  Karlsson, Harald Pobloth", "title": "Experiments on Open-Set Speaker Identification with Discriminatively\n  Trained Neural Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.SD eess.AS stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper presents a study on discriminative artificial neural network\nclassifiers in the context of open-set speaker identification. Both 2-class and\nmulti-class architectures are tested against the conventional Gaussian mixture\nmodel based classifier on enrolled speaker sets of different sizes. The\nperformance evaluation shows that the multi-class neural network system has\nsuperior performance for large population sizes.\n", "versions": [{"version": "v1", "created": "Tue, 2 Apr 2019 07:59:49 GMT"}], "update_date": "2019-04-03", "authors_parsed": [["Imoscopi", "Stefano", ""], ["Grancharov", "Volodya", ""], ["Sverrisson", "Sigurdur", ""], ["Karlsson", "Erlendur", ""], ["Pobloth", "Harald", ""]]}, {"id": "1904.01277", "submitter": "Alasdair Newson", "authors": "Sa\\\"id Ladjal, Alasdair Newson, Chi-Hieu Pham", "title": "A PCA-like Autoencoder", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  An autoencoder is a neural network which data projects to and from a lower\ndimensional latent space, where this data is easier to understand and model.\nThe autoencoder consists of two sub-networks, the encoder and the decoder,\nwhich carry out these transformations. The neural network is trained such that\nthe output is as close to the input as possible, the data having gone through\nan information bottleneck : the latent space. This tool bears significant\nressemblance to Principal Component Analysis (PCA), with two main differences.\nFirstly, the autoencoder is a non-linear transformation, contrary to PCA, which\nmakes the autoencoder more flexible and powerful. Secondly, the axes found by a\nPCA are orthogonal, and are ordered in terms of the amount of variability which\nthe data presents along these axes. This makes the interpretability of the PCA\nmuch greater than that of the autoencoder, which does not have these\nattributes. Ideally, then, we would like an autoencoder whose latent space\nconsists of independent components, ordered by decreasing importance to the\ndata. In this paper, we propose an algorithm to create such a network. We\ncreate an iterative algorithm which progressively increases the size of the\nlatent space, learning a new dimension at each step. Secondly, we propose a\ncovariance loss term to add to the standard autoencoder loss function, as well\nas a normalisation layer just before the latent space, which encourages the\nlatent space components to be statistically independent. We demonstrate the\nresults of this autoencoder on simple geometric shapes, and find that the\nalgorithm indeed finds a meaningful representation in the latent space. This\nmeans that subsequent interpolation in the latent space has meaning with\nrespect to the geometric properties of the images.\n", "versions": [{"version": "v1", "created": "Tue, 2 Apr 2019 08:27:52 GMT"}], "update_date": "2019-04-03", "authors_parsed": [["Ladjal", "Sa\u00efd", ""], ["Newson", "Alasdair", ""], ["Pham", "Chi-Hieu", ""]]}, {"id": "1904.01324", "submitter": "Saurabh Sharma", "authors": "Saurabh Sharma, Pavan Teja Varigonda, Prashast Bindal, Abhishek\n  Sharma, Arjun Jain", "title": "Monocular 3D Human Pose Estimation by Generation and Ordinal Ranking", "comments": "In Proceedings of the 2019 IEEE International Conference on Computer\n  Vision (ICCV)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Monocular 3D human-pose estimation from static images is a challenging\nproblem, due to the curse of dimensionality and the ill-posed nature of lifting\n2D-to-3D. In this paper, we propose a Deep Conditional Variational Autoencoder\nbased model that synthesizes diverse anatomically plausible 3D-pose samples\nconditioned on the estimated 2D-pose. We show that CVAE-based 3D-pose sample\nset is consistent with the 2D-pose and helps tackling the inherent ambiguity in\n2D-to-3D lifting. We propose two strategies for obtaining the final 3D pose-\n(a) depth-ordering/ordinal relations to score and weight-average the candidate\n3D-poses, referred to as OrdinalScore, and (b) with supervision from an Oracle.\nWe report close to state of-the-art results on two benchmark datasets using\nOrdinalScore, and state-of-the-art results using the Oracle. We also show that\nour pipeline yields competitive results without paired image-to-3D annotations.\nThe training and evaluation code is available at\nhttps://github.com/ssfootball04/generative_pose.\n", "versions": [{"version": "v1", "created": "Tue, 2 Apr 2019 10:35:14 GMT"}, {"version": "v2", "created": "Wed, 21 Aug 2019 08:19:13 GMT"}], "update_date": "2019-08-22", "authors_parsed": [["Sharma", "Saurabh", ""], ["Varigonda", "Pavan Teja", ""], ["Bindal", "Prashast", ""], ["Sharma", "Abhishek", ""], ["Jain", "Arjun", ""]]}, {"id": "1904.01334", "submitter": "Konstantin Posch", "authors": "Konstantin Posch, J\\\"urgen Pilz", "title": "Correlated Parameters to Accurately Measure Uncertainty in Deep Neural\n  Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this article a novel approach for training deep neural networks using\nBayesian techniques is presented. The Bayesian methodology allows for an easy\nevaluation of model uncertainty and additionally is robust to overfitting.\nThese are commonly the two main problems classical, i.e. non-Bayesian,\narchitectures have to struggle with. The proposed approach applies variational\ninference in order to approximate the intractable posterior distribution. In\nparticular, the variational distribution is defined as product of multiple\nmultivariate normal distributions with tridiagonal covariance matrices. Each\nsingle normal distribution belongs either to the weights, or to the biases\ncorresponding to one network layer. The layer-wise a posteriori variances are\ndefined based on the corresponding expectation values and further the\ncorrelations are assumed to be identical. Therefore, only a few additional\nparameters need to be optimized compared to non-Bayesian settings. The novel\napproach is successfully evaluated on basis of the popular benchmark datasets\nMNIST and CIFAR-10.\n", "versions": [{"version": "v1", "created": "Tue, 2 Apr 2019 11:06:50 GMT"}], "update_date": "2019-04-03", "authors_parsed": [["Posch", "Konstantin", ""], ["Pilz", "J\u00fcrgen", ""]]}, {"id": "1904.01340", "submitter": "Lukas Drude", "authors": "Lukas Drude, Daniel Hasenklever, Reinhold Haeb-Umbach", "title": "Unsupervised training of a deep clustering model for multichannel blind\n  source separation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG eess.SP stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a training scheme to train neural network-based source separation\nalgorithms from scratch when parallel clean data is unavailable. In particular,\nwe demonstrate that an unsupervised spatial clustering algorithm is sufficient\nto guide the training of a deep clustering system. We argue that previous work\non deep clustering requires strong supervision and elaborate on why this is a\nlimitation. We demonstrate that (a) the single-channel deep clustering system\ntrained according to the proposed scheme alone is able to achieve a similar\nperformance as the multi-channel teacher in terms of word error rates and (b)\ninitializing the spatial clustering approach with the deep clustering result\nyields a relative word error rate reduction of 26 % over the unsupervised\nteacher.\n", "versions": [{"version": "v1", "created": "Tue, 2 Apr 2019 11:25:27 GMT"}], "update_date": "2019-04-03", "authors_parsed": [["Drude", "Lukas", ""], ["Hasenklever", "Daniel", ""], ["Haeb-Umbach", "Reinhold", ""]]}, {"id": "1904.01341", "submitter": "Vinod Kumar Kurmi", "authors": "Vinod Kumar Kurmi and Vinay P. Namboodiri", "title": "Looking back at Labels: A Class based Domain Adaptation Technique", "comments": "IJCNN 2019 Accepted", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  In this paper, we solve the problem of adapting classifiers across domains.\nWe consider the problem of domain adaptation for multi-class classification\nwhere we are provided a labeled set of examples in a source dataset and we are\nprovided a target dataset with no supervision. In this setting, we propose an\nadversarial discriminator based approach. While the approach based on\nadversarial discriminator has been previously proposed; in this paper, we\npresent an informed adversarial discriminator. Our observation relies on the\nanalysis that shows that if the discriminator has access to all the information\navailable including the class structure present in the source dataset, then it\ncan guide the transformation of features of the target set of classes to a more\nstructure adapted space. Using this formulation, we obtain state-of-the-art\nresults for the standard evaluation on benchmark datasets. We further provide\ndetailed analysis which shows that using all the labeled information results in\nan improved domain adaptation.\n", "versions": [{"version": "v1", "created": "Tue, 2 Apr 2019 11:28:19 GMT"}], "update_date": "2019-04-03", "authors_parsed": [["Kurmi", "Vinod Kumar", ""], ["Namboodiri", "Vinay P.", ""]]}, {"id": "1904.01352", "submitter": "Yuyang Zhou", "authors": "Yuyang Zhou, Guang Cheng, Shanqing Jiang, Mian Dai", "title": "Building an Efficient Intrusion Detection System Based on Feature\n  Selection and Ensemble Classifier", "comments": "To be published in Computer Networks at\n  https://doi.org/10.1016/j.comnet.2020.107247", "journal-ref": null, "doi": "10.1016/j.comnet.2020.107247", "report-no": null, "categories": "cs.CR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Intrusion detection system (IDS) is one of extensively used techniques in a\nnetwork topology to safeguard the integrity and availability of sensitive\nassets in the protected systems. Although many supervised and unsupervised\nlearning approaches from the field of machine learning have been used to\nincrease the efficacy of IDSs, it is still a problem for existing intrusion\ndetection algorithms to achieve good performance. First, lots of redundant and\nirrelevant data in high-dimensional datasets interfere with the classification\nprocess of an IDS. Second, an individual classifier may not perform well in the\ndetection of each type of attacks. Third, many models are built for stale\ndatasets, making them less adaptable for novel attacks. Thus, we propose a new\nintrusion detection framework in this paper, and this framework is based on the\nfeature selection and ensemble learning techniques. In the first step, a\nheuristic algorithm called CFS-BA is proposed for dimensionality reduction,\nwhich selects the optimal subset based on the correlation between features.\nThen, we introduce an ensemble approach that combines C4.5, Random Forest (RF),\nand Forest by Penalizing Attributes (Forest PA) algorithms. Finally, voting\ntechnique is used to combine the probability distributions of the base learners\nfor attack recognition. The experimental results, using NSL-KDD, AWID, and\nCIC-IDS2017 datasets, reveal that the proposed CFS-BA-Ensemble method is able\nto exhibit better performance than other related and state of the art\napproaches under several metrics.\n", "versions": [{"version": "v1", "created": "Tue, 2 Apr 2019 11:45:41 GMT"}, {"version": "v2", "created": "Thu, 19 Sep 2019 07:46:19 GMT"}, {"version": "v3", "created": "Mon, 30 Mar 2020 03:17:56 GMT"}, {"version": "v4", "created": "Thu, 2 Apr 2020 10:17:25 GMT"}], "update_date": "2020-04-03", "authors_parsed": [["Zhou", "Yuyang", ""], ["Cheng", "Guang", ""], ["Jiang", "Shanqing", ""], ["Dai", "Mian", ""]]}, {"id": "1904.01367", "submitter": "Fengxiang He", "authors": "Fengxiang He, Tongliang Liu, and Dacheng Tao", "title": "Why ResNet Works? Residuals Generalize", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Residual connections significantly boost the performance of deep neural\nnetworks. However, there are few theoretical results that address the influence\nof residuals on the hypothesis complexity and the generalization ability of\ndeep neural networks. This paper studies the influence of residual connections\non the hypothesis complexity of the neural network in terms of the covering\nnumber of its hypothesis space. We prove that the upper bound of the covering\nnumber is the same as chain-like neural networks, if the total numbers of the\nweight matrices and nonlinearities are fixed, no matter whether they are in the\nresiduals or not. This result demonstrates that residual connections may not\nincrease the hypothesis complexity of the neural network compared with the\nchain-like counterpart. Based on the upper bound of the covering number, we\nthen obtain an $\\mathcal O(1 / \\sqrt{N})$ margin-based multi-class\ngeneralization bound for ResNet, as an exemplary case of any deep neural\nnetwork with residual connections. Generalization guarantees for similar\nstate-of-the-art neural network architectures, such as DenseNet and ResNeXt,\nare straight-forward. From our generalization bound, a practical implementation\nis summarized: to approach a good generalization ability, we need to use\nregularization terms to control the magnitude of the norms of weight matrices\nnot to increase too much, which justifies the standard technique of weight\ndecay.\n", "versions": [{"version": "v1", "created": "Tue, 2 Apr 2019 12:20:33 GMT"}], "update_date": "2019-04-03", "authors_parsed": [["He", "Fengxiang", ""], ["Liu", "Tongliang", ""], ["Tao", "Dacheng", ""]]}, {"id": "1904.01376", "submitter": "Jindong Wang", "authors": "Jindong Wang, Yiqiang Chen, Han Yu, Meiyu Huang, Qiang Yang", "title": "Easy Transfer Learning By Exploiting Intra-domain Structures", "comments": "Camera-ready version of IEEE International Conference on Multimedia\n  and Expo (ICME) 2019; code available at\n  http://transferlearning.xyz/code/traditional/EasyTL", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Transfer learning aims at transferring knowledge from a well-labeled domain\nto a similar but different domain with limited or no labels. Unfortunately,\nexisting learning-based methods often involve intensive model selection and\nhyperparameter tuning to obtain good results. Moreover, cross-validation is not\npossible for tuning hyperparameters since there are often no labels in the\ntarget domain. This would restrict wide applicability of transfer learning\nespecially in computationally-constraint devices such as wearables. In this\npaper, we propose a practically Easy Transfer Learning (EasyTL) approach which\nrequires no model selection and hyperparameter tuning, while achieving\ncompetitive performance. By exploiting intra-domain structures, EasyTL is able\nto learn both non-parametric transfer features and classifiers. Extensive\nexperiments demonstrate that, compared to state-of-the-art traditional and deep\nmethods, EasyTL satisfies the Occam's Razor principle: it is extremely easy to\nimplement and use while achieving comparable or better performance in\nclassification accuracy and much better computational efficiency. Additionally,\nit is shown that EasyTL can increase the performance of existing transfer\nfeature learning methods.\n", "versions": [{"version": "v1", "created": "Tue, 2 Apr 2019 12:43:53 GMT"}, {"version": "v2", "created": "Wed, 10 Apr 2019 02:44:33 GMT"}], "update_date": "2019-04-11", "authors_parsed": [["Wang", "Jindong", ""], ["Chen", "Yiqiang", ""], ["Yu", "Han", ""], ["Huang", "Meiyu", ""], ["Yang", "Qiang", ""]]}, {"id": "1904.01385", "submitter": "James Bagrow", "authors": "Andrew J. Becker and James P. Bagrow", "title": "UAFS: Uncertainty-Aware Feature Selection for Problems with Missing Data", "comments": "Withdrawn due to errors in theoretical derivations", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG physics.data-an stat.ME", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Missing data are a concern in many real world data sets and imputation\nmethods are often needed to estimate the values of missing data, but data sets\nwith excessive missingness and high dimensionality challenge most approaches to\nimputation. Here we show that appropriate feature selection can be an effective\npreprocessing step for imputation, allowing for more accurate imputation and\nsubsequent model predictions. The key feature of this preprocessing is that it\nincorporates uncertainty: by accounting for uncertainty due to missingness when\nselecting features we can reduce the degree of missingness while also limiting\nthe number of uninformative features being used to make predictive models. We\nintroduce a method to perform uncertainty-aware feature selection (UAFS),\nprovide a theoretical motivation, and test UAFS on both real and synthetic\nproblems, demonstrating that across a variety of data sets and levels of\nmissingness we can improve the accuracy of imputations. Improved imputation due\nto UAFS also results in improved prediction accuracy when performing supervised\nlearning using these imputed data sets. Our UAFS method is general and can be\nfruitfully coupled with a variety of imputation methods.\n", "versions": [{"version": "v1", "created": "Tue, 2 Apr 2019 13:02:18 GMT"}, {"version": "v2", "created": "Sat, 27 Jun 2020 21:22:07 GMT"}, {"version": "v3", "created": "Tue, 20 Apr 2021 18:33:16 GMT"}], "update_date": "2021-04-22", "authors_parsed": [["Becker", "Andrew J.", ""], ["Bagrow", "James P.", ""]]}, {"id": "1904.01390", "submitter": "Shiv Ram Dubey", "authors": "Sai Prasanna Teja Reddy, Surya Teja Karri, Shiv Ram Dubey, Snehasis\n  Mukherjee", "title": "Spontaneous Facial Micro-Expression Recognition using 3D Spatiotemporal\n  Convolutional Neural Networks", "comments": "Accepted in 2019 International Joint Conference on Neural Networks\n  (IJCNN)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.LG cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Facial expression recognition in videos is an active area of research in\ncomputer vision. However, fake facial expressions are difficult to be\nrecognized even by humans. On the other hand, facial micro-expressions\ngenerally represent the actual emotion of a person, as it is a spontaneous\nreaction expressed through human face. Despite of a few attempts made for\nrecognizing micro-expressions, still the problem is far from being a solved\nproblem, which is depicted by the poor rate of accuracy shown by the\nstate-of-the-art methods. A few CNN based approaches are found in the\nliterature to recognize micro-facial expressions from still images. Whereas, a\nspontaneous micro-expression video contains multiple frames that have to be\nprocessed together to encode both spatial and temporal information. This paper\nproposes two 3D-CNN methods: MicroExpSTCNN and MicroExpFuseNet, for spontaneous\nfacial micro-expression recognition by exploiting the spatiotemporal\ninformation in CNN framework. The MicroExpSTCNN considers the full spatial\ninformation, whereas the MicroExpFuseNet is based on the 3D-CNN feature fusion\nof the eyes and mouth regions. The experiments are performed over CAS(ME)^2 and\nSMIC micro-expression databases. The proposed MicroExpSTCNN model outperforms\nthe state-of-the-art methods.\n", "versions": [{"version": "v1", "created": "Wed, 27 Mar 2019 13:45:49 GMT"}], "update_date": "2019-04-03", "authors_parsed": [["Reddy", "Sai Prasanna Teja", ""], ["Karri", "Surya Teja", ""], ["Dubey", "Shiv Ram", ""], ["Mukherjee", "Snehasis", ""]]}, {"id": "1904.01399", "submitter": "Huan Long", "authors": "Yuting Jia, Haiwen Wang, Shuo Shao, Huan Long, Yunsong Zhou, Xinbing\n  Wang", "title": "On Geometric Structure of Activation Spaces in Neural Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we investigate the geometric structure of activation spaces of\nfully connected layers in neural networks and then show applications of this\nstudy. We propose an efficient approximation algorithm to characterize the\nconvex hull of massive points in high dimensional space. Based on this new\nalgorithm, four common geometric properties shared by the activation spaces are\nconcluded, which gives a rather clear description of the activation spaces. We\nthen propose an alternative classification method grounding on the geometric\nstructure description, which works better than neural networks alone.\nSurprisingly, this data classification method can be an indicator of\noverfitting in neural networks. We believe our work reveals several critical\nintrinsic properties of modern neural networks and further gives a new metric\nfor evaluating them.\n", "versions": [{"version": "v1", "created": "Tue, 2 Apr 2019 13:19:53 GMT"}], "update_date": "2019-04-03", "authors_parsed": [["Jia", "Yuting", ""], ["Wang", "Haiwen", ""], ["Shao", "Shuo", ""], ["Long", "Huan", ""], ["Zhou", "Yunsong", ""], ["Wang", "Xinbing", ""]]}, {"id": "1904.01401", "submitter": "David Saltiel", "authors": "Eric Benhamou, David Saltiel, Sebastien Verel, Fabien Teytaud", "title": "BCMA-ES: A Bayesian approach to CMA-ES", "comments": "10 pages, 9 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://creativecommons.org/publicdomain/zero/1.0/", "abstract": "  This paper introduces a novel theoretically sound approach for the celebrated\nCMA-ES algorithm. Assuming the parameters of the multi variate normal\ndistribution for the minimum follow a conjugate prior distribution, we derive\ntheir optimal update at each iteration step. Not only provides this Bayesian\nframework a justification for the update of the CMA-ES algorithm but it also\ngives two new versions of CMA-ES either assuming normal-Wishart or\nnormal-Inverse Wishart priors, depending whether we parametrize the likelihood\nby its covariance or precision matrix. We support our theoretical findings by\nnumerical experiments that show fast convergence of these modified versions of\nCMA-ES.\n", "versions": [{"version": "v1", "created": "Tue, 2 Apr 2019 13:28:49 GMT"}], "update_date": "2019-04-03", "authors_parsed": [["Benhamou", "Eric", ""], ["Saltiel", "David", ""], ["Verel", "Sebastien", ""], ["Teytaud", "Fabien", ""]]}, {"id": "1904.01451", "submitter": "Michael A. Hedderich", "authors": "Michael A. Hedderich, Andrew Yates, Dietrich Klakow and Gerard de Melo", "title": "Using Multi-Sense Vector Embeddings for Reverse Dictionaries", "comments": "Accepted as long paper at the 13th International Conference on\n  Computational Semantics (IWCS 2019)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Popular word embedding methods such as word2vec and GloVe assign a single\nvector representation to each word, even if a word has multiple distinct\nmeanings. Multi-sense embeddings instead provide different vectors for each\nsense of a word. However, they typically cannot serve as a drop-in replacement\nfor conventional single-sense embeddings, because the correct sense vector\nneeds to be selected for each word. In this work, we study the effect of\nmulti-sense embeddings on the task of reverse dictionaries. We propose a\ntechnique to easily integrate them into an existing neural network architecture\nusing an attention mechanism. Our experiments demonstrate that large\nimprovements can be obtained when employing multi-sense embeddings both in the\ninput sequence as well as for the target representation. An analysis of the\nsense distributions and of the learned attention is provided as well.\n", "versions": [{"version": "v1", "created": "Tue, 2 Apr 2019 14:17:19 GMT"}], "update_date": "2019-04-03", "authors_parsed": [["Hedderich", "Michael A.", ""], ["Yates", "Andrew", ""], ["Klakow", "Dietrich", ""], ["de Melo", "Gerard", ""]]}, {"id": "1904.01460", "submitter": "Basheer Qolomany", "authors": "Basheer Qolomany, Ala Al-Fuqaha, Ajay Gupta, Driss Benhaddou, Safaa\n  Alwajidi, Junaid Qadir, Alvis C. Fong", "title": "Leveraging Machine Learning and Big Data for Smart Buildings: A\n  Comprehensive Survey", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Future buildings will offer new convenience, comfort, and efficiency\npossibilities to their residents. Changes will occur to the way people live as\ntechnology involves into people's lives and information processing is fully\nintegrated into their daily living activities and objects. The future\nexpectation of smart buildings includes making the residents' experience as\neasy and comfortable as possible. The massive streaming data generated and\ncaptured by smart building appliances and devices contains valuable information\nthat needs to be mined to facilitate timely actions and better decision making.\nMachine learning and big data analytics will undoubtedly play a critical role\nto enable the delivery of such smart services. In this paper, we survey the\narea of smart building with a special focus on the role of techniques from\nmachine learning and big data analytics. This survey also reviews the current\ntrends and challenges faced in the development of smart building services.\n", "versions": [{"version": "v1", "created": "Mon, 1 Apr 2019 16:29:51 GMT"}, {"version": "v2", "created": "Sun, 19 May 2019 15:39:31 GMT"}], "update_date": "2019-05-21", "authors_parsed": [["Qolomany", "Basheer", ""], ["Al-Fuqaha", "Ala", ""], ["Gupta", "Ajay", ""], ["Benhaddou", "Driss", ""], ["Alwajidi", "Safaa", ""], ["Qadir", "Junaid", ""], ["Fong", "Alvis C.", ""]]}, {"id": "1904.01466", "submitter": "David Saltiel", "authors": "Eric Benhamou, David Saltiel, Beatrice Guez, Nicolas Paris", "title": "BCMA-ES II: revisiting Bayesian CMA-ES", "comments": "10 pages, 15 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper revisits the Bayesian CMA-ES and provides updates for normal\nWishart. It emphasizes the difference between a normal and normal inverse\nWishart prior. After some computation, we prove that the only difference relies\nsurprisingly in the expected covariance. We prove that the expected covariance\nshould be lower in the normal Wishart prior model because of the convexity of\nthe inverse. We present a mixture model that generalizes both normal Wishart\nand normal inverse Wishart model. We finally present various numerical\nexperiments to compare both methods as well as the generalized method.\n", "versions": [{"version": "v1", "created": "Tue, 2 Apr 2019 14:39:17 GMT"}, {"version": "v2", "created": "Tue, 9 Apr 2019 08:03:02 GMT"}], "update_date": "2019-04-10", "authors_parsed": [["Benhamou", "Eric", ""], ["Saltiel", "David", ""], ["Guez", "Beatrice", ""], ["Paris", "Nicolas", ""]]}, {"id": "1904.01490", "submitter": "Jelena Bradic", "authors": "Davide Viviano and Jelena Bradic", "title": "Synthetic learner: model-free inference on treatments over time", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ME cs.LG econ.EM stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Understanding of the effect of a particular treatment or a policy pertains to\nmany areas of interest -- ranging from political economics, marketing to\nhealth-care and personalized treatment studies. In this paper, we develop a\nnon-parametric, model-free test for detecting the effects of treatment over\ntime that extends widely used Synthetic Control tests. The test is built on\ncounterfactual predictions arising from many learning algorithms. In the\nNeyman-Rubin potential outcome framework with possible carry-over effects, we\nshow that the proposed test is asymptotically consistent for stationary, beta\nmixing processes. We do not assume that class of learners captures the correct\nmodel necessarily. We also discuss estimates of the average treatment effect,\nand we provide regret bounds on the predictive performance. To the best of our\nknowledge, this is the first set of results that allow for example any Random\nForest to be useful for provably valid statistical inference in the Synthetic\nControl setting. In experiments, we show that our Synthetic Learner is\nsubstantially more powerful than classical methods based on Synthetic Control\nor Difference-in-Differences, especially in the presence of non-linear outcome\nmodels.\n", "versions": [{"version": "v1", "created": "Tue, 2 Apr 2019 15:28:21 GMT"}], "update_date": "2019-04-03", "authors_parsed": [["Viviano", "Davide", ""], ["Bradic", "Jelena", ""]]}, {"id": "1904.01500", "submitter": "Robert Schwarzenberg", "authors": "Robert Schwarzenberg, Lisa Raithel, David Harbecke", "title": "Neural Vector Conceptualization for Word Vector Space Interpretation", "comments": "NAACL-HLT 2019 Workshop on Evaluating Vector Space Representations\n  for NLP (RepEval)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Distributed word vector spaces are considered hard to interpret which hinders\nthe understanding of natural language processing (NLP) models. In this work, we\nintroduce a new method to interpret arbitrary samples from a word vector space.\nTo this end, we train a neural model to conceptualize word vectors, which means\nthat it activates higher order concepts it recognizes in a given vector.\nContrary to prior approaches, our model operates in the original vector space\nand is capable of learning non-linear relations between word vectors and\nconcepts. Furthermore, we show that it produces considerably less entropic\nconcept activation profiles than the popular cosine similarity.\n", "versions": [{"version": "v1", "created": "Tue, 2 Apr 2019 15:39:27 GMT"}], "update_date": "2019-04-03", "authors_parsed": [["Schwarzenberg", "Robert", ""], ["Raithel", "Lisa", ""], ["Harbecke", "David", ""]]}, {"id": "1904.01508", "submitter": "Stavros Shiaeles Dr", "authors": "Michael Siracusano, Stavros Shiaeles, Bogdan Ghita", "title": "Detection of LDDoS Attacks Based on TCP Connection Parameters", "comments": null, "journal-ref": null, "doi": "10.1109/GIIS.2018.8635701", "report-no": null, "categories": "cs.NI cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Low-rate application layer distributed denial of service (LDDoS) attacks are\nboth powerful and stealthy. They force vulnerable webservers to open all\navailable connections to the adversary, denying resources to real users.\nMitigation advice focuses on solutions that potentially degrade quality of\nservice for legitimate connections. Furthermore, without accurate detection\nmechanisms, distributed attacks can bypass these defences. A methodology for\ndetection of LDDoS attacks, based on characteristics of malicious TCP flows, is\nproposed within this paper. Research will be conducted using combinations of\ntwo datasets: one generated from a simulated network, the other from the\npublically available CIC DoS dataset. Both contain the attacks slowread,\nslowheaders and slowbody, alongside legitimate web browsing. TCP flow features\nare extracted from all connections. Experimentation was carried out using six\nsupervised AI algorithms to categorise attack from legitimate flows. Decision\ntrees and k-NN accurately classified up to 99.99% of flows, with exceptionally\nlow false positive and false negative rates, demonstrating the potential of AI\nin LDDoS detection.\n", "versions": [{"version": "v1", "created": "Tue, 12 Mar 2019 16:56:17 GMT"}], "update_date": "2019-04-03", "authors_parsed": [["Siracusano", "Michael", ""], ["Shiaeles", "Stavros", ""], ["Ghita", "Bogdan", ""]]}, {"id": "1904.01509", "submitter": "Jian Xue", "authors": "Yanfu Yan, Ke Lu, Jian Xue, Pengcheng Gao, Jiayi Lyu", "title": "FEAFA: A Well-Annotated Dataset for Facial Expression Analysis and 3D\n  Facial Animation", "comments": "9 pages, 7 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV cs.GR eess.IV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Facial expression analysis based on machine learning requires large number of\nwell-annotated data to reflect different changes in facial motion. Publicly\navailable datasets truly help to accelerate research in this area by providing\na benchmark resource, but all of these datasets, to the best of our knowledge,\nare limited to rough annotations for action units, including only their\nabsence, presence, or a five-level intensity according to the Facial Action\nCoding System. To meet the need for videos labeled in great detail, we present\na well-annotated dataset named FEAFA for Facial Expression Analysis and 3D\nFacial Animation. One hundred and twenty-two participants, including children,\nyoung adults and elderly people, were recorded in real-world conditions. In\naddition, 99,356 frames were manually labeled using Expression Quantitative\nTool developed by us to quantify 9 symmetrical FACS action units, 10\nasymmetrical (unilateral) FACS action units, 2 symmetrical FACS action\ndescriptors and 2 asymmetrical FACS action descriptors, and each action unit or\naction descriptor is well-annotated with a floating point number between 0 and\n1. To provide a baseline for use in future research, a benchmark for the\nregression of action unit values based on Convolutional Neural Networks are\npresented. We also demonstrate the potential of our FEAFA dataset for 3D facial\nanimation. Almost all state-of-the-art algorithms for facial animation are\nachieved based on 3D face reconstruction. We hence propose a novel method that\ndrives virtual characters only based on action unit value regression of the 2D\nvideo frames of source actors.\n", "versions": [{"version": "v1", "created": "Tue, 2 Apr 2019 15:50:11 GMT"}], "update_date": "2019-04-03", "authors_parsed": [["Yan", "Yanfu", ""], ["Lu", "Ke", ""], ["Xue", "Jian", ""], ["Gao", "Pengcheng", ""], ["Lyu", "Jiayi", ""]]}, {"id": "1904.01514", "submitter": "Niccol\\`o Dal Santo", "authors": "Niccol\\`o Dal Santo, Simone Deparis and Luca Pegolotti", "title": "Data driven approximation of parametrized PDEs by Reduced Basis and\n  Neural Networks", "comments": null, "journal-ref": null, "doi": "10.1016/j.jcp.2020.109550", "report-no": null, "categories": "cs.NA cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We are interested in the approximation of partial differential equations with\na data-driven approach based on the reduced basis method and machine learning.\nWe suppose that the phenomenon of interest can be modeled by a parametrized\npartial differential equation, but that the value of the physical parameters is\nunknown or difficult to be directly measured. Our method allows to estimate\nfields of interest, for instance temperature of a sample of material or\nvelocity of a fluid, given data at a handful of points in the domain. We\npropose to accomplish this task with a neural network embedding a reduced basis\nsolver as exotic activation function in the last layer. The reduced basis\nsolver accounts for the underlying physical phenomenonon and it is constructed\nfrom snapshots obtained from randomly selected values of the physical\nparameters during an expensive offline phase. The same full order solutions are\nthen employed for the training of the neural network. As a matter of fact, the\nchosen architecture resembles an asymmetric autoencoder in which the decoder is\nthe reduced basis solver and as such it does not contain trainable parameters.\nThe resulting latent space of our autoencoder includes parameter-dependent\nquantities feeding the reduced basis solver, which -- depending on the\nconsidered partial differential equation -- are the values of the physical\nparameters themselves or the affine decomposition coefficients of the\ndifferential operators.\n", "versions": [{"version": "v1", "created": "Tue, 2 Apr 2019 15:54:15 GMT"}, {"version": "v2", "created": "Sat, 29 Jun 2019 08:25:30 GMT"}], "update_date": "2020-06-24", "authors_parsed": [["Santo", "Niccol\u00f2 Dal", ""], ["Deparis", "Simone", ""], ["Pegolotti", "Luca", ""]]}, {"id": "1904.01517", "submitter": "Benjamin Fehrman", "authors": "Benjamin Fehrman, Benjamin Gess, Arnulf Jentzen", "title": "Convergence rates for the stochastic gradient descent method for\n  non-convex objective functions", "comments": "59 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.NA cs.LG cs.NA math.PR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We prove the local convergence to minima and estimates on the rate of\nconvergence for the stochastic gradient descent method in the case of not\nnecessarily globally convex nor contracting objective functions. In particular,\nthe results are applicable to simple objective functions arising in machine\nlearning.\n", "versions": [{"version": "v1", "created": "Tue, 2 Apr 2019 15:55:32 GMT"}, {"version": "v2", "created": "Fri, 26 Jul 2019 17:34:04 GMT"}], "update_date": "2019-07-29", "authors_parsed": [["Fehrman", "Benjamin", ""], ["Gess", "Benjamin", ""], ["Jentzen", "Arnulf", ""]]}, {"id": "1904.01537", "submitter": "Soumi Maiti", "authors": "Soumi Maiti and Michael I Mandel", "title": "Speech denoising by parametric resynthesis", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.AS cs.LG cs.SD", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This work proposes the use of clean speech vocoder parameters as the target\nfor a neural network performing speech enhancement. These parameters have been\ndesigned for text-to-speech synthesis so that they both produce high-quality\nresyntheses and also are straightforward to model with neural networks, but\nhave not been utilized in speech enhancement until now. In comparison to a\nmatched text-to-speech system that is given the ground truth transcripts of the\nnoisy speech, our model is able to produce more natural speech because it has\naccess to the true prosody in the noisy speech. In comparison to two denoising\nsystems, the oracle Wiener mask and a DNN-based mask predictor, our model\nequals the oracle Wiener mask in subjective quality and intelligibility and\nsurpasses the realistic system. A vocoder-based upper bound shows that there is\nstill room for improvement with this approach beyond the oracle Wiener mask. We\ntest speaker-dependence with two speakers and show that a single model can be\nused for multiple speakers.\n", "versions": [{"version": "v1", "created": "Tue, 2 Apr 2019 16:50:46 GMT"}], "update_date": "2019-04-03", "authors_parsed": [["Maiti", "Soumi", ""], ["Mandel", "Michael I", ""]]}, {"id": "1904.01548", "submitter": "Dan Schwartz", "authors": "Dan Schwartz and Tom Mitchell", "title": "Understanding language-elicited EEG data by predicting it from a\n  fine-tuned language model", "comments": "To appear in Proceedings of the 2019 Conference of the North American\n  Chapter of the Association for Computational Linguistics", "journal-ref": null, "doi": "10.18653/v1/N19-1005", "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Electroencephalography (EEG) recordings of brain activity taken while\nparticipants read or listen to language are widely used within the cognitive\nneuroscience and psycholinguistics communities as a tool to study language\ncomprehension. Several time-locked stereotyped EEG responses to\nword-presentations -- known collectively as event-related potentials (ERPs) --\nare thought to be markers for semantic or syntactic processes that take place\nduring comprehension. However, the characterization of each individual ERP in\nterms of what features of a stream of language trigger the response remains\ncontroversial. Improving this characterization would make ERPs a more useful\ntool for studying language comprehension. We take a step towards better\nunderstanding the ERPs by fine-tuning a language model to predict them. This\nnew approach to analysis shows for the first time that all of the ERPs are\npredictable from embeddings of a stream of language. Prior work has only found\ntwo of the ERPs to be predictable. In addition to this analysis, we examine\nwhich ERPs benefit from sharing parameters during joint training. We find that\ntwo pairs of ERPs previously identified in the literature as being related to\neach other benefit from joint training, while several other pairs of ERPs that\nbenefit from joint training are suggestive of potential relationships.\nExtensions of this analysis that further examine what kinds of information in\nthe model embeddings relate to each ERP have the potential to elucidate the\nprocesses involved in human language comprehension.\n", "versions": [{"version": "v1", "created": "Tue, 2 Apr 2019 17:02:19 GMT"}], "update_date": "2019-11-05", "authors_parsed": [["Schwartz", "Dan", ""], ["Mitchell", "Tom", ""]]}, {"id": "1904.01554", "submitter": "Ali Payani", "authors": "Ali Payani and Faramarz Fekri", "title": "Learning Algorithms via Neural Logic Networks", "comments": "Under Review in ICLM2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a novel learning paradigm for Deep Neural Networks (DNN) by using\nBoolean logic algebra. We first present the basic differentiable operators of a\nBoolean system such as conjunction, disjunction and exclusive-OR and show how\nthese elementary operators can be combined in a simple and meaningful way to\nform Neural Logic Networks (NLNs). We examine the effectiveness of the proposed\nNLN framework in learning Boolean functions and discrete-algorithmic tasks. We\ndemonstrate that, in contrast to the implicit learning in MLP approach, the\nproposed neural logic networks can learn the logical functions explicitly that\ncan be verified and interpreted by human. In particular, we propose a new\nframework for learning the inductive logic programming (ILP) problems by\nexploiting the explicit representational power of NLN. We show the proposed\nneural ILP solver is capable of feats such as predicate invention and recursion\nand can outperform the current state of the art neural ILP solvers using a\nvariety of benchmark tasks such as decimal addition and multiplication, and\nsorting on ordered list.\n", "versions": [{"version": "v1", "created": "Tue, 2 Apr 2019 17:17:02 GMT"}], "update_date": "2019-04-10", "authors_parsed": [["Payani", "Ali", ""], ["Fekri", "Faramarz", ""]]}, {"id": "1904.01555", "submitter": "Amir Ziai", "authors": "Amir Ziai", "title": "Active Learning for Network Intrusion Detection", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Network operators are generally aware of common attack vectors that they\ndefend against. For most networks the vast majority of traffic is legitimate.\nHowever new attack vectors are continually designed and attempted by bad actors\nwhich bypass detection and go unnoticed due to low volume. One strategy for\nfinding such activity is to look for anomalous behavior. Investigating\nanomalous behavior requires significant time and resources. Collecting a large\nnumber of labeled examples for training supervised models is both prohibitively\nexpensive and subject to obsoletion as new attacks surface. A purely\nunsupervised methodology is ideal; however, research has shown that even a very\nsmall number of labeled examples can significantly improve the quality of\nanomaly detection. A methodology that minimizes the number of required labels\nwhile maximizing the quality of detection is desirable. False positives in this\ncontext result in wasted effort or blockage of legitimate traffic and false\nnegatives translate to undetected attacks. We propose a general active learning\nframework and experiment with different choices of learners and sampling\nstrategies.\n", "versions": [{"version": "v1", "created": "Tue, 2 Apr 2019 17:22:39 GMT"}], "update_date": "2019-04-03", "authors_parsed": [["Ziai", "Amir", ""]]}, {"id": "1904.01557", "submitter": "David Saxton", "authors": "David Saxton, Edward Grefenstette, Felix Hill, Pushmeet Kohli", "title": "Analysing Mathematical Reasoning Abilities of Neural Models", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Mathematical reasoning---a core ability within human intelligence---presents\nsome unique challenges as a domain: we do not come to understand and solve\nmathematical problems primarily on the back of experience and evidence, but on\nthe basis of inferring, learning, and exploiting laws, axioms, and symbol\nmanipulation rules. In this paper, we present a new challenge for the\nevaluation (and eventually the design) of neural architectures and similar\nsystem, developing a task suite of mathematics problems involving sequential\nquestions and answers in a free-form textual input/output format. The\nstructured nature of the mathematics domain, covering arithmetic, algebra,\nprobability and calculus, enables the construction of training and test splits\ndesigned to clearly illuminate the capabilities and failure-modes of different\narchitectures, as well as evaluate their ability to compose and relate\nknowledge and learned processes. Having described the data generation process\nand its potential future expansions, we conduct a comprehensive analysis of\nmodels from two broad classes of the most powerful sequence-to-sequence\narchitectures and find notable differences in their ability to resolve\nmathematical problems and generalize their knowledge.\n", "versions": [{"version": "v1", "created": "Tue, 2 Apr 2019 17:26:41 GMT"}], "update_date": "2019-04-03", "authors_parsed": [["Saxton", "David", ""], ["Grefenstette", "Edward", ""], ["Hill", "Felix", ""], ["Kohli", "Pushmeet", ""]]}, {"id": "1904.01561", "submitter": "Kevin Yang", "authors": "Kevin Yang, Kyle Swanson, Wengong Jin, Connor Coley, Philipp Eiden,\n  Hua Gao, Angel Guzman-Perez, Timothy Hopper, Brian Kelley, Miriam Mathea,\n  Andrew Palmer, Volker Settels, Tommi Jaakkola, Klavs Jensen, Regina Barzilay", "title": "Analyzing Learned Molecular Representations for Property Prediction", "comments": null, "journal-ref": "Journal of chemical information and modeling 59.8 (2019):\n  3370-3388", "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Advancements in neural machinery have led to a wide range of algorithmic\nsolutions for molecular property prediction. Two classes of models in\nparticular have yielded promising results: neural networks applied to computed\nmolecular fingerprints or expert-crafted descriptors, and graph convolutional\nneural networks that construct a learned molecular representation by operating\non the graph structure of the molecule. However, recent literature has yet to\nclearly determine which of these two methods is superior when generalizing to\nnew chemical space. Furthermore, prior research has rarely examined these new\nmodels in industry research settings in comparison to existing employed models.\nIn this paper, we benchmark models extensively on 19 public and 16 proprietary\nindustrial datasets spanning a wide variety of chemical endpoints. In addition,\nwe introduce a graph convolutional model that consistently matches or\noutperforms models using fixed molecular descriptors as well as previous graph\nneural architectures on both public and proprietary datasets. Our empirical\nfindings indicate that while approaches based on these representations have yet\nto reach the level of experimental reproducibility, our proposed model\nnevertheless offers significant improvements over models currently used in\nindustrial workflows.\n", "versions": [{"version": "v1", "created": "Tue, 2 Apr 2019 17:35:27 GMT"}, {"version": "v2", "created": "Tue, 18 Jun 2019 18:13:11 GMT"}, {"version": "v3", "created": "Fri, 12 Jul 2019 23:11:43 GMT"}, {"version": "v4", "created": "Tue, 30 Jul 2019 17:36:39 GMT"}, {"version": "v5", "created": "Wed, 20 Nov 2019 19:51:07 GMT"}], "update_date": "2019-11-22", "authors_parsed": [["Yang", "Kevin", ""], ["Swanson", "Kyle", ""], ["Jin", "Wengong", ""], ["Coley", "Connor", ""], ["Eiden", "Philipp", ""], ["Gao", "Hua", ""], ["Guzman-Perez", "Angel", ""], ["Hopper", "Timothy", ""], ["Kelley", "Brian", ""], ["Mathea", "Miriam", ""], ["Palmer", "Andrew", ""], ["Settels", "Volker", ""], ["Jaakkola", "Tommi", ""], ["Jensen", "Klavs", ""], ["Barzilay", "Regina", ""]]}, {"id": "1904.01569", "submitter": "Saining Xie", "authors": "Saining Xie, Alexander Kirillov, Ross Girshick, Kaiming He", "title": "Exploring Randomly Wired Neural Networks for Image Recognition", "comments": "Technical report", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Neural networks for image recognition have evolved through extensive manual\ndesign from simple chain-like models to structures with multiple wiring paths.\nThe success of ResNets and DenseNets is due in large part to their innovative\nwiring plans. Now, neural architecture search (NAS) studies are exploring the\njoint optimization of wiring and operation types, however, the space of\npossible wirings is constrained and still driven by manual design despite being\nsearched. In this paper, we explore a more diverse set of connectivity patterns\nthrough the lens of randomly wired neural networks. To do this, we first define\nthe concept of a stochastic network generator that encapsulates the entire\nnetwork generation process. Encapsulation provides a unified view of NAS and\nrandomly wired networks. Then, we use three classical random graph models to\ngenerate randomly wired graphs for networks. The results are surprising:\nseveral variants of these random generators yield network instances that have\ncompetitive accuracy on the ImageNet benchmark. These results suggest that new\nefforts focusing on designing better network generators may lead to new\nbreakthroughs by exploring less constrained search spaces with more room for\nnovel design.\n", "versions": [{"version": "v1", "created": "Tue, 2 Apr 2019 17:57:16 GMT"}, {"version": "v2", "created": "Mon, 8 Apr 2019 17:50:26 GMT"}], "update_date": "2019-04-09", "authors_parsed": [["Xie", "Saining", ""], ["Kirillov", "Alexander", ""], ["Girshick", "Ross", ""], ["He", "Kaiming", ""]]}, {"id": "1904.01574", "submitter": "Andreas Kofler", "authors": "Andreas Kofler, Marc Dewey, Tobias Schaeffter, Christian Wald, and\n  Christoph Kolbitsch", "title": "Spatio-Temporal Deep Learning-Based Undersampling Artefact Reduction for\n  2D Radial Cine MRI with Limited Data", "comments": "To be published in IEEE Transactions on Medical Imaging", "journal-ref": null, "doi": "10.1109/TMI.2019.2930318", "report-no": null, "categories": "eess.IV cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this work we reduce undersampling artefacts in two-dimensional ($2D$)\ngolden-angle radial cine cardiac MRI by applying a modified version of the\nU-net. We train the network on $2D$ spatio-temporal slices which are previously\nextracted from the image sequences. We compare our approach to two $2D$ and a\n$3D$ Deep Learning-based post processing methods and to three iterative\nreconstruction methods for dynamic cardiac MRI. Our method outperforms the $2D$\nspatially trained U-net and the $2D$ spatio-temporal U-net. Compared to the\n$3D$ spatio-temporal U-net, our method delivers comparable results, but with\nshorter training times and less training data. Compared to the Compressed\nSensing-based methods $kt$-FOCUSS and a total variation regularised\nreconstruction approach, our method improves image quality with respect to all\nreported metrics. Further, it achieves competitive results when compared to an\niterative reconstruction method based on adaptive regularization with\nDictionary Learning and total variation, while only requiring a small fraction\nof the computational time. A persistent homology analysis demonstrates that the\ndata manifold of the spatio-temporal domain has a lower complexity than the\nspatial domain and therefore, the learning of a projection-like mapping is\nfacilitated. Even when trained on only one single subject without\ndata-augmentation, our approach yields results which are similar to the ones\nobtained on a large training dataset. This makes the method particularly\nsuitable for training a network on limited training data. Finally, in contrast\nto the spatial $2D$ U-net, our proposed method is shown to be naturally robust\nwith respect to image rotation in image space and almost achieves\nrotation-equivariance where neither data-augmentation nor a particular network\ndesign are required.\n", "versions": [{"version": "v1", "created": "Mon, 1 Apr 2019 20:16:42 GMT"}, {"version": "v2", "created": "Tue, 13 Aug 2019 13:18:45 GMT"}], "update_date": "2019-08-14", "authors_parsed": [["Kofler", "Andreas", ""], ["Dewey", "Marc", ""], ["Schaeffter", "Tobias", ""], ["Wald", "Christian", ""], ["Kolbitsch", "Christoph", ""]]}, {"id": "1904.01575", "submitter": "Cheng-I Lai", "authors": "Cheng-I Lai", "title": "Contrastive Predictive Coding Based Feature for Automatic Speaker\n  Verification", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG cs.SD eess.AS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This thesis describes our ongoing work on Contrastive Predictive Coding (CPC)\nfeatures for speaker verification. CPC is a recently proposed representation\nlearning framework based on predictive coding and noise contrastive estimation.\nWe focus on incorporating CPC features into the standard automatic speaker\nverification systems, and we present our methods, experiments, and analysis.\nThis thesis also details necessary background knowledge in past and recent work\non automatic speaker verification systems, conventional speech features, and\nthe motivation and techniques behind CPC.\n", "versions": [{"version": "v1", "created": "Mon, 1 Apr 2019 23:54:08 GMT"}], "update_date": "2019-04-04", "authors_parsed": [["Lai", "Cheng-I", ""]]}, {"id": "1904.01576", "submitter": "Anirban Bhattacharjee", "authors": "Anirban Bhattacharjee, Ajay Dev Chhokra, Zhuangwei Kang, Hongyang Sun,\n  Aniruddha Gokhale, Gabor Karsai", "title": "BARISTA: Efficient and Scalable Serverless Serving System for Deep\n  Learning Prediction Services", "comments": null, "journal-ref": null, "doi": "10.1109/IC2E.2019.00-10", "report-no": null, "categories": "cs.DC cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Pre-trained deep learning models are increasingly being used to offer a\nvariety of compute-intensive predictive analytics services such as fitness\ntracking, speech and image recognition. The stateless and highly parallelizable\nnature of deep learning models makes them well-suited for serverless computing\nparadigm. However, making effective resource management decisions for these\nservices is a hard problem due to the dynamic workloads and diverse set of\navailable resource configurations that have their deployment and management\ncosts. To address these challenges, we present a distributed and scalable\ndeep-learning prediction serving system called Barista and make the following\ncontributions. First, we present a fast and effective methodology for\nforecasting workloads by identifying various trends. Second, we formulate an\noptimization problem to minimize the total cost incurred while ensuring bounded\nprediction latency with reasonable accuracy. Third, we propose an efficient\nheuristic to identify suitable compute resource configurations. Fourth, we\npropose an intelligent agent to allocate and manage the compute resources by\nhorizontal and vertical scaling to maintain the required prediction latency.\nFinally, using representative real-world workloads for urban transportation\nservice, we demonstrate and validate the capabilities of Barista.\n", "versions": [{"version": "v1", "created": "Tue, 2 Apr 2019 01:46:38 GMT"}, {"version": "v2", "created": "Thu, 11 Apr 2019 16:00:14 GMT"}], "update_date": "2019-12-30", "authors_parsed": [["Bhattacharjee", "Anirban", ""], ["Chhokra", "Ajay Dev", ""], ["Kang", "Zhuangwei", ""], ["Sun", "Hongyang", ""], ["Gokhale", "Aniruddha", ""], ["Karsai", "Gabor", ""]]}, {"id": "1904.01578", "submitter": "Lukas Drude", "authors": "Lukas Drude, Jahn Heymann, Reinhold Haeb-Umbach", "title": "Unsupervised training of neural mask-based beamforming", "comments": "Correction to Eq. 11: Hermite symbol was on the wrong variable.\n  Replaces y with the normalized version", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SD cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present an unsupervised training approach for a neural network-based mask\nestimator in an acoustic beamforming application. The network is trained to\nmaximize a likelihood criterion derived from a spatial mixture model of the\nobservations. It is trained from scratch without requiring any parallel data\nconsisting of degraded input and clean training targets. Thus, training can be\ncarried out on real recordings of noisy speech rather than simulated ones. In\ncontrast to previous work on unsupervised training of neural mask estimators,\nour approach avoids the need for a possibly pre-trained teacher model entirely.\nWe demonstrate the effectiveness of our approach by speech recognition\nexperiments on two different datasets: one mainly deteriorated by noise (CHiME\n4) and one by reverberation (REVERB). The results show that the performance of\nthe proposed system is on par with a supervised system using oracle target\nmasks for training and with a system trained using a model-based teacher.\n", "versions": [{"version": "v1", "created": "Tue, 2 Apr 2019 12:10:23 GMT"}, {"version": "v2", "created": "Mon, 8 Apr 2019 12:00:46 GMT"}], "update_date": "2019-04-09", "authors_parsed": [["Drude", "Lukas", ""], ["Heymann", "Jahn", ""], ["Haeb-Umbach", "Reinhold", ""]]}, {"id": "1904.01612", "submitter": "Yanwu Xu", "authors": "Yanwu Xu, Mingming Gong, Junxiang Chen, Tongliang Liu, Kun Zhang, and\n  Kayhan Batmanghelich", "title": "Generative-Discriminative Complementary Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Majority of state-of-the-art deep learning methods are discriminative\napproaches, which model the conditional distribution of labels given inputs\nfeatures. The success of such approaches heavily depends on high-quality\nlabeled instances, which are not easy to obtain, especially as the number of\ncandidate classes increases. In this paper, we study the complementary learning\nproblem. Unlike ordinary labels, complementary labels are easy to obtain\nbecause an annotator only needs to provide a yes/no answer to a randomly chosen\ncandidate class for each instance. We propose a generative-discriminative\ncomplementary learning method that estimates the ordinary labels by modeling\nboth the conditional (discriminative) and instance (generative) distributions.\nOur method, we call Complementary Conditional GAN (CCGAN), improves the\naccuracy of predicting ordinary labels and can generate high-quality instances\nin spite of weak supervision. In addition to the extensive empirical studies,\nwe also theoretically show that our model can retrieve the true conditional\ndistribution from the complementarily-labeled data.\n", "versions": [{"version": "v1", "created": "Tue, 2 Apr 2019 18:37:13 GMT"}, {"version": "v2", "created": "Sun, 7 Apr 2019 14:57:36 GMT"}, {"version": "v3", "created": "Tue, 16 Apr 2019 16:58:20 GMT"}, {"version": "v4", "created": "Wed, 11 Sep 2019 20:23:21 GMT"}], "update_date": "2019-09-13", "authors_parsed": [["Xu", "Yanwu", ""], ["Gong", "Mingming", ""], ["Chen", "Junxiang", ""], ["Liu", "Tongliang", ""], ["Zhang", "Kun", ""], ["Batmanghelich", "Kayhan", ""]]}, {"id": "1904.01624", "submitter": "Sree Hari Krishnan Parthasarathi", "authors": "Sree Hari Krishnan Parthasarathi and Nikko Strom", "title": "Lessons from Building Acoustic Models with a Million Hours of Speech", "comments": "\"Copyright 2019 IEEE. Personal use of this material is permitted.\n  Permission from IEEE must be obtained for all other uses, in any current or\n  future media, including reprinting/republishing this material for advertising\n  or promotional purposes, creating new collective works, for resale or\n  redistribution to servers or lists, or reuse of any copyrighted component of\n  this work in other works.\"", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.SD eess.AS stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This is a report of our lessons learned building acoustic models from 1\nMillion hours of unlabeled speech, while labeled speech is restricted to 7,000\nhours. We employ student/teacher training on unlabeled data, helping scale out\ntarget generation in comparison to confidence model based methods, which\nrequire a decoder and a confidence model. To optimize storage and to\nparallelize target generation, we store high valued logits from the teacher\nmodel. Introducing the notion of scheduled learning, we interleave learning on\nunlabeled and labeled data. To scale distributed training across a large number\nof GPUs, we use BMUF with 64 GPUs, while performing sequence training only on\nlabeled data with gradient threshold compression SGD using 16 GPUs. Our\nexperiments show that extremely large amounts of data are indeed useful; with\nlittle hyper-parameter tuning, we obtain relative WER improvements in the 10 to\n20% range, with higher gains in noisier conditions.\n", "versions": [{"version": "v1", "created": "Tue, 2 Apr 2019 18:58:41 GMT"}], "update_date": "2019-04-04", "authors_parsed": [["Parthasarathi", "Sree Hari Krishnan", ""], ["Strom", "Nikko", ""]]}, {"id": "1904.01631", "submitter": "Anthony Hsu", "authors": "Anthony Hsu, Keqiu Hu, Jonathan Hung, Arun Suresh, Zhe Zhang", "title": "TonY: An Orchestrator for Distributed Machine Learning Jobs", "comments": "2 pages, to be published in OpML '19", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Training machine learning (ML) models on large datasets requires considerable\ncomputing power. To speed up training, it is typical to distribute training\nacross several machines, often with specialized hardware like GPUs or TPUs.\nManaging a distributed training job is complex and requires dealing with\nresource contention, distributed configurations, monitoring, and fault\ntolerance. In this paper, we describe TonY, an open-source orchestrator for\ndistributed ML jobs built at LinkedIn to address these challenges.\n", "versions": [{"version": "v1", "created": "Sun, 24 Mar 2019 00:18:21 GMT"}], "update_date": "2019-04-04", "authors_parsed": [["Hsu", "Anthony", ""], ["Hu", "Keqiu", ""], ["Hung", "Jonathan", ""], ["Suresh", "Arun", ""], ["Zhang", "Zhe", ""]]}, {"id": "1904.01643", "submitter": "Karel Mundnich", "authors": "Karel Mundnich and Brandon M. Booth and Benjamin Girault and Shrikanth\n  Narayanan", "title": "Generating Labels for Regression of Subjective Constructs using Triplet\n  Embeddings", "comments": "9 pages, 5 figures, accepted journal paper", "journal-ref": "Pattern Recognition Letters Volume 128, 2019, Pages 385-392", "doi": "10.1016/j.patrec.2019.10.003", "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Human annotations serve an important role in computational models where the\ntarget constructs under study are hidden, such as dimensions of affect. This is\nespecially relevant in machine learning, where subjective labels derived from\nrelated observable signals (e.g., audio, video, text) are needed to support\nmodel training and testing. Current research trends focus on correcting\nartifacts and biases introduced by annotators during the annotation process\nwhile fusing them into a single annotation. In this work, we propose a novel\nannotation approach using triplet embeddings. By lifting the absolute\nannotation process to relative annotations where the annotator compares\nindividual target constructs in triplets, we leverage the accuracy of\ncomparisons over absolute ratings by human annotators. We then build a\n1-dimensional embedding in Euclidean space that is indexed in time and serves\nas a label for regression. In this setting, the annotation fusion occurs\nnaturally as a union of sets of sampled triplet comparisons among different\nannotators. We show that by using our proposed sampling method to find an\nembedding, we are able to accurately represent synthetic hidden constructs in\ntime under noisy sampling conditions. We further validate this approach using\nhuman annotations collected from Mechanical Turk and show that we can recover\nthe underlying structure of the hidden construct up to bias and scaling\nfactors.\n", "versions": [{"version": "v1", "created": "Tue, 2 Apr 2019 19:53:37 GMT"}, {"version": "v2", "created": "Tue, 18 Feb 2020 17:09:06 GMT"}], "update_date": "2020-02-19", "authors_parsed": [["Mundnich", "Karel", ""], ["Booth", "Brandon M.", ""], ["Girault", "Benjamin", ""], ["Narayanan", "Shrikanth", ""]]}, {"id": "1904.01648", "submitter": "Chiwoo Park", "authors": "Chiwoo Park, Peihua Qiu, Jennifer Carpena-N\\'u\\~nez, Rahul Rao,\n  Michael Susner and Benji Maruyama", "title": "Sequential Adaptive Design for Jump Regression Estimation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Selecting input variables or design points for statistical models has been of\ngreat interest in adaptive design and active learning. Motivated by two\nscientific examples, this paper presents a strategy of selecting the design\npoints for a regression model when the underlying regression function is\ndiscontinuous. The first example we undertook was for the purpose of\naccelerating imaging speed in a high resolution material imaging; the second\nwas use of sequential design for the purpose of mapping a chemical phase\ndiagram. In both examples, the underlying regression functions have\ndiscontinuities, so many of the existing design optimization approaches cannot\nbe applied because they mostly assume a continuous regression function.\nAlthough some existing adaptive design strategies developed from treed\nregression models can handle the discontinuities, the Bayesian approaches come\nwith computationally expensive Markov Chain Monte Carlo techniques for\nposterior inferences and subsequent design point selections, which is not\nappropriate for the first motivating example that requires computation at least\nfaster than the original imaging speed. In addition, the treed models are based\non the domain partitioning that are inefficient when the discontinuities occurs\nover complex sub-domain boundaries. We propose a simple and effective adaptive\ndesign strategy for a regression analysis with discontinuities: some\nstatistical properties with a fixed design will be presented first, and then\nthese properties will be used to propose a new criterion of selecting the\ndesign points for the regression analysis. Sequential design with the new\ncriterion will be presented with comprehensive simulated examples, and its\napplication to the two motivating examples will be presented.\n", "versions": [{"version": "v1", "created": "Tue, 2 Apr 2019 20:14:47 GMT"}, {"version": "v2", "created": "Tue, 14 Apr 2020 13:01:09 GMT"}, {"version": "v3", "created": "Thu, 22 Oct 2020 19:00:31 GMT"}, {"version": "v4", "created": "Wed, 10 Feb 2021 20:22:36 GMT"}], "update_date": "2021-02-12", "authors_parsed": [["Park", "Chiwoo", ""], ["Qiu", "Peihua", ""], ["Carpena-N\u00fa\u00f1ez", "Jennifer", ""], ["Rao", "Rahul", ""], ["Susner", "Michael", ""], ["Maruyama", "Benji", ""]]}, {"id": "1904.01670", "submitter": "Daniel Jakubovitz", "authors": "Daniel Jakubovitz, Miguel R. D. Rodrigues, Raja Giryes", "title": "Lautum Regularization for Semi-supervised Transfer Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Transfer learning is a very important tool in deep learning as it allows\npropagating information from one \"source dataset\" to another \"target dataset\",\nespecially in the case of a small number of training examples in the latter.\nYet, discrepancies between the underlying distributions of the source and\ntarget data are commonplace and are known to have a substantial impact on\nalgorithm performance. In this work we suggest a novel information theoretic\napproach for the analysis of the performance of deep neural networks in the\ncontext of transfer learning. We focus on the task of semi-supervised transfer\nlearning, in which unlabeled samples from the target dataset are available\nduring the network training on the source dataset. Our theory suggests that one\nmay improve the transferability of a deep neural network by imposing a Lautum\ninformation based regularization that relates the network weights to the target\ndata. We demonstrate the effectiveness of the proposed approach in various\ntransfer learning experiments.\n", "versions": [{"version": "v1", "created": "Tue, 2 Apr 2019 21:18:45 GMT"}, {"version": "v2", "created": "Wed, 21 Aug 2019 21:16:06 GMT"}, {"version": "v3", "created": "Thu, 23 Jan 2020 12:05:11 GMT"}], "update_date": "2020-01-24", "authors_parsed": [["Jakubovitz", "Daniel", ""], ["Rodrigues", "Miguel R. D.", ""], ["Giryes", "Raja", ""]]}, {"id": "1904.01677", "submitter": "Josef Urban", "authors": "Jan Jakub\\r{u}v and Josef Urban", "title": "Hammering Mizar by Learning Clause Guidance", "comments": "arXiv admin note: substantial text overlap with arXiv:1903.03182", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We describe a very large improvement of existing hammer-style proof\nautomation over large ITP libraries by combining learning and theorem proving.\nIn particular, we have integrated state-of-the-art machine learners into the E\nautomated theorem prover, and developed methods that allow learning and\nefficient internal guidance of E over the whole Mizar library. The resulting\ntrained system improves the real-time performance of E on the Mizar library by\n70% in a single-strategy setting.\n", "versions": [{"version": "v1", "created": "Tue, 2 Apr 2019 21:36:40 GMT"}], "update_date": "2019-04-04", "authors_parsed": [["Jakub\u016fv", "Jan", ""], ["Urban", "Josef", ""]]}, {"id": "1904.01681", "submitter": "Emilien Dupont", "authors": "Emilien Dupont, Arnaud Doucet, Yee Whye Teh", "title": "Augmented Neural ODEs", "comments": "NeurIPS camera ready, additional experiments, additional datasets,\n  discussion on relation to other models", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We show that Neural Ordinary Differential Equations (ODEs) learn\nrepresentations that preserve the topology of the input space and prove that\nthis implies the existence of functions Neural ODEs cannot represent. To\naddress these limitations, we introduce Augmented Neural ODEs which, in\naddition to being more expressive models, are empirically more stable,\ngeneralize better and have a lower computational cost than Neural ODEs.\n", "versions": [{"version": "v1", "created": "Tue, 2 Apr 2019 21:50:34 GMT"}, {"version": "v2", "created": "Wed, 22 May 2019 10:32:32 GMT"}, {"version": "v3", "created": "Sat, 26 Oct 2019 15:37:14 GMT"}], "update_date": "2019-10-29", "authors_parsed": [["Dupont", "Emilien", ""], ["Doucet", "Arnaud", ""], ["Teh", "Yee Whye", ""]]}, {"id": "1904.01685", "submitter": "Jeremy Nixon", "authors": "Jeremy Nixon, Mike Dusenberry, Ghassen Jerfel, Timothy Nguyen,\n  Jeremiah Liu, Linchuan Zhang, Dustin Tran", "title": "Measuring Calibration in Deep Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Overconfidence and underconfidence in machine learning classifiers is\nmeasured by calibration: the degree to which the probabilities predicted for\neach class match the accuracy of the classifier on that prediction.\n  How one measures calibration remains a challenge: expected calibration error,\nthe most popular metric, has numerous flaws which we outline, and there is no\nclear empirical understanding of how its choices affect conclusions in\npractice, and what recommendations there are to counteract its flaws.\n  In this paper, we perform a comprehensive empirical study of choices in\ncalibration measures including measuring all probabilities rather than just the\nmaximum prediction, thresholding probability values, class conditionality,\nnumber of bins, bins that are adaptive to the datapoint density, and the norm\nused to compare accuracies to confidences. To analyze the sensitivity of\ncalibration measures, we study the impact of optimizing directly for each\nvariant with recalibration techniques. Across MNIST, Fashion MNIST,\nCIFAR-10/100, and ImageNet, we find that conclusions on the rank ordering of\nrecalibration methods is drastically impacted by the choice of calibration\nmeasure. We find that conditioning on the class leads to more effective\ncalibration evaluations, and that using the L2 norm rather than the L1 norm\nimproves both optimization for calibration metrics and the rank correlation\nmeasuring metric consistency. Adaptive binning schemes lead to more stablity of\nmetric rank ordering when the number of bins vary, and is also recommended. We\nopen source a library for the use of our calibration measures.\n", "versions": [{"version": "v1", "created": "Tue, 2 Apr 2019 22:10:44 GMT"}, {"version": "v2", "created": "Fri, 7 Aug 2020 18:34:21 GMT"}], "update_date": "2020-08-11", "authors_parsed": [["Nixon", "Jeremy", ""], ["Dusenberry", "Mike", ""], ["Jerfel", "Ghassen", ""], ["Nguyen", "Timothy", ""], ["Liu", "Jeremiah", ""], ["Zhang", "Linchuan", ""], ["Tran", "Dustin", ""]]}, {"id": "1904.01691", "submitter": "Sangkug Lym", "authors": "Sangkug Lym, Donghyuk Lee, Mike O'Connor, Niladrish Chatterjee, Mattan\n  Erez", "title": "DeLTA: GPU Performance Model for Deep Learning Applications with\n  In-depth Memory System Traffic Analysis", "comments": null, "journal-ref": null, "doi": "10.1109/ISPASS.2019.00041", "report-no": null, "categories": "cs.DC cs.LG", "license": "http://creativecommons.org/licenses/by-sa/4.0/", "abstract": "  Training convolutional neural networks (CNNs) requires intense compute\nthroughput and high memory bandwidth. Especially, convolution layers account\nfor the majority of the execution time of CNN training, and GPUs are commonly\nused to accelerate these layer workloads. GPU design optimization for efficient\nCNN training acceleration requires the accurate modeling of how their\nperformance improves when computing and memory resources are increased. We\npresent DeLTA, the first analytical model that accurately estimates the traffic\nat each GPU memory hierarchy level, while accounting for the complex reuse\npatterns of a parallel convolution algorithm. We demonstrate that our model is\nboth accurate and robust for different CNNs and GPU architectures. We then show\nhow this model can be used to carefully balance the scaling of different GPU\nresources for efficient CNN performance improvement.\n", "versions": [{"version": "v1", "created": "Tue, 2 Apr 2019 22:30:06 GMT"}], "update_date": "2020-04-28", "authors_parsed": [["Lym", "Sangkug", ""], ["Lee", "Donghyuk", ""], ["O'Connor", "Mike", ""], ["Chatterjee", "Niladrish", ""], ["Erez", "Mattan", ""]]}, {"id": "1904.01720", "submitter": "Marko Vasic", "authors": "Marko Vasic, Aditya Kanade, Petros Maniatis, David Bieber, Rishabh\n  Singh", "title": "Neural Program Repair by Jointly Learning to Localize and Repair", "comments": "ICLR 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Due to its potential to improve programmer productivity and software quality,\nautomated program repair has been an active topic of research. Newer techniques\nharness neural networks to learn directly from examples of buggy programs and\ntheir fixes. In this work, we consider a recently identified class of bugs\ncalled variable-misuse bugs. The state-of-the-art solution for variable misuse\nenumerates potential fixes for all possible bug locations in a program, before\nselecting the best prediction. We show that it is beneficial to train a model\nthat jointly and directly localizes and repairs variable-misuse bugs. We\npresent multi-headed pointer networks for this purpose, with one head each for\nlocalization and repair. The experimental results show that the joint model\nsignificantly outperforms an enumerative solution that uses a pointer based\nmodel for repair alone.\n", "versions": [{"version": "v1", "created": "Wed, 3 Apr 2019 00:57:25 GMT"}], "update_date": "2019-04-04", "authors_parsed": [["Vasic", "Marko", ""], ["Kanade", "Aditya", ""], ["Maniatis", "Petros", ""], ["Bieber", "David", ""], ["Singh", "Rishabh", ""]]}, {"id": "1904.01723", "submitter": "Haozhen Zhao", "authors": "Fusheng Wei, Han Qin, Shi Ye, Haozhen Zhao", "title": "Empirical Study of Deep Learning for Text Classification in Legal\n  Document Review", "comments": "2018 IEEE International Conference on Big Data (Big Data)", "journal-ref": null, "doi": "10.1109/BigData.2018.8622157", "report-no": null, "categories": "cs.IR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Predictive coding has been widely used in legal matters to find relevant or\nprivileged documents in large sets of electronically stored information. It\nsaves the time and cost significantly. Logistic Regression (LR) and Support\nVector Machines (SVM) are two popular machine learning algorithms used in\npredictive coding. Recently, deep learning received a lot of attentions in many\nindustries. This paper reports our preliminary studies in using deep learning\nin legal document review. Specifically, we conducted experiments to compare\ndeep learning results with results obtained using a SVM algorithm on the four\ndatasets of real legal matters. Our results showed that CNN performed better\nwith larger volume of training dataset and should be a fit method in the text\nclassification in legal industry.\n", "versions": [{"version": "v1", "created": "Wed, 3 Apr 2019 01:00:41 GMT"}], "update_date": "2019-04-04", "authors_parsed": [["Wei", "Fusheng", ""], ["Qin", "Han", ""], ["Ye", "Shi", ""], ["Zhao", "Haozhen", ""]]}, {"id": "1904.01727", "submitter": "Anirban Bhattacharjee", "authors": "Anirban Bhattacharjee, Yogesh Barve, Shweta Khare, Shunxing Bao,\n  Aniruddha Gokhale and Thomas Damiano", "title": "Stratum: A Serverless Framework for Lifecycle Management of Machine\n  Learning based Data Analytics Tasks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SE cs.DC cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  With the proliferation of machine learning (ML) libraries and frameworks, and\nthe programming languages that they use, along with operations of data loading,\ntransformation, preparation and mining, ML model development is becoming a\ndaunting task. Furthermore, with a plethora of cloud-based ML model development\nplatforms, heterogeneity in hardware, increased focus on exploiting edge\ncomputing resources for low-latency prediction serving and often a lack of a\ncomplete understanding of resources required to execute ML workflows\nefficiently, ML model deployment demands expertise for managing the lifecycle\nof ML workflows efficiently and with minimal cost. To address these challenges,\nwe propose an end-to-end data analytics, a serverless platform called Stratum.\nStratum can deploy, schedule and dynamically manage data ingestion tools, live\nstreaming apps, batch analytics tools, ML-as-a-service (for inference jobs),\nand visualization tools across the cloud-fog-edge spectrum. This paper\ndescribes the Stratum architecture highlighting the problems it resolves.\n", "versions": [{"version": "v1", "created": "Wed, 3 Apr 2019 01:07:04 GMT"}], "update_date": "2019-04-04", "authors_parsed": [["Bhattacharjee", "Anirban", ""], ["Barve", "Yogesh", ""], ["Khare", "Shweta", ""], ["Bao", "Shunxing", ""], ["Gokhale", "Aniruddha", ""], ["Damiano", "Thomas", ""]]}, {"id": "1904.01740", "submitter": "Javier Hernandez-Ortega", "authors": "Javier Hernandez-Ortega, Javier Galbally, Julian Fierrez, Rudolf\n  Haraksim, Laurent Beslay", "title": "FaceQnet: Quality Assessment for Face Recognition based on Deep Learning", "comments": "Preprint version of a paper accepted at ICB 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG eess.IV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we develop a Quality Assessment approach for face recognition\nbased on deep learning. The method consists of a Convolutional Neural Network,\nFaceQnet, that is used to predict the suitability of a specific input image for\nface recognition purposes. The training of FaceQnet is done using the VGGFace2\ndatabase. We employ the BioLab-ICAO framework for labeling the VGGFace2 images\nwith quality information related to their ICAO compliance level. The\ngroundtruth quality labels are obtained using FaceNet to generate comparison\nscores. We employ the groundtruth data to fine-tune a ResNet-based CNN, making\nit capable of returning a numerical quality measure for each input image.\nFinally, we verify if the FaceQnet scores are suitable to predict the expected\nperformance when employing a specific image for face recognition with a COTS\nface recognition system. Several conclusions can be drawn from this work, most\nnotably: 1) we managed to employ an existing ICAO compliance framework and a\npretrained CNN to automatically label data with quality information, 2) we\ntrained FaceQnet for quality estimation by fine-tuning a pre-trained face\nrecognition network (ResNet-50), and 3) we have shown that the predictions from\nFaceQnet are highly correlated with the face recognition accuracy of a\nstate-of-the-art commercial system not used during development. FaceQnet is\npublicly available in GitHub.\n", "versions": [{"version": "v1", "created": "Wed, 3 Apr 2019 02:12:31 GMT"}, {"version": "v2", "created": "Thu, 4 Apr 2019 07:05:42 GMT"}], "update_date": "2019-04-05", "authors_parsed": [["Hernandez-Ortega", "Javier", ""], ["Galbally", "Javier", ""], ["Fierrez", "Julian", ""], ["Haraksim", "Rudolf", ""], ["Beslay", "Laurent", ""]]}, {"id": "1904.01747", "submitter": "Dacheng Tao", "authors": "Ya Li, Xinmei Tian, Tongliang Liu, Dacheng Tao", "title": "On Better Exploring and Exploiting Task Relationships in Multi-Task\n  Learning: Joint Model and Feature Learning", "comments": null, "journal-ref": null, "doi": "10.1109/TNNLS.2017.2690683", "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Multitask learning (MTL) aims to learn multiple tasks simultaneously through\nthe interdependence between different tasks. The way to measure the relatedness\nbetween tasks is always a popular issue. There are mainly two ways to measure\nrelatedness between tasks: common parameters sharing and common features\nsharing across different tasks. However, these two types of relatedness are\nmainly learned independently, leading to a loss of information. In this paper,\nwe propose a new strategy to measure the relatedness that jointly learns shared\nparameters and shared feature representations. The objective of our proposed\nmethod is to transform the features from different tasks into a common feature\nspace in which the tasks are closely related and the shared parameters can be\nbetter optimized. We give a detailed introduction to our proposed multitask\nlearning method. Additionally, an alternating algorithm is introduced to\noptimize the nonconvex objection. A theoretical bound is given to demonstrate\nthat the relatedness between tasks can be better measured by our proposed\nmultitask learning algorithm. We conduct various experiments to verify the\nsuperiority of the proposed joint model and feature a multitask learning\nmethod.\n", "versions": [{"version": "v1", "created": "Wed, 3 Apr 2019 03:14:20 GMT"}], "update_date": "2019-04-04", "authors_parsed": [["Li", "Ya", ""], ["Tian", "Xinmei", ""], ["Liu", "Tongliang", ""], ["Tao", "Dacheng", ""]]}, {"id": "1904.01750", "submitter": "Cheng Tang", "authors": "Cheng Tang", "title": "Exponentially convergent stochastic k-PCA without variance reduction", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present Matrix Krasulina, an algorithm for online k-PCA, by generalizing\nthe classic Krasulina's method (Krasulina, 1969) from vector to matrix case. We\nshow, both theoretically and empirically, that the algorithm naturally adapts\nto data low-rankness and converges exponentially fast to the ground-truth\nprincipal subspace. Notably, our result suggests that despite various recent\nefforts to accelerate the convergence of stochastic-gradient based methods by\nadding a O(n)-time variance reduction step, for the k-PCA problem, a truly\nonline SGD variant suffices to achieve exponential convergence on intrinsically\nlow-rank data.\n", "versions": [{"version": "v1", "created": "Wed, 3 Apr 2019 03:31:50 GMT"}], "update_date": "2019-04-04", "authors_parsed": [["Tang", "Cheng", ""]]}, {"id": "1904.01763", "submitter": "Yanjun Han", "authors": "Zijun Gao, Yanjun Han, Zhimei Ren, Zhengqing Zhou", "title": "Batched Multi-armed Bandits Problem", "comments": "To appear in NeurIPS 2019 as an oral presentation", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.IT cs.LG math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we study the multi-armed bandit problem in the batched setting\nwhere the employed policy must split data into a small number of batches. While\nthe minimax regret for the two-armed stochastic bandits has been completely\ncharacterized in \\cite{perchet2016batched}, the effect of the number of arms on\nthe regret for the multi-armed case is still open. Moreover, the question\nwhether adaptively chosen batch sizes will help to reduce the regret also\nremains underexplored. In this paper, we propose the BaSE (batched successive\nelimination) policy to achieve the rate-optimal regrets (within logarithmic\nfactors) for batched multi-armed bandits, with matching lower bounds even if\nthe batch sizes are determined in an adaptive manner.\n", "versions": [{"version": "v1", "created": "Wed, 3 Apr 2019 04:31:43 GMT"}, {"version": "v2", "created": "Thu, 12 Sep 2019 03:08:14 GMT"}, {"version": "v3", "created": "Sat, 26 Oct 2019 21:28:48 GMT"}], "update_date": "2019-10-29", "authors_parsed": [["Gao", "Zijun", ""], ["Han", "Yanjun", ""], ["Ren", "Zhimei", ""], ["Zhou", "Zhengqing", ""]]}, {"id": "1904.01775", "submitter": "Krishna Somandepalli", "authors": "Krishna Somandepalli, Naveen Kumar, Ruchir Travadi, Shrikanth\n  Narayanan", "title": "Multimodal Representation Learning using Deep Multiset Canonical\n  Correlation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG eess.SP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose Deep Multiset Canonical Correlation Analysis (dMCCA) as an\nextension to representation learning using CCA when the underlying signal is\nobserved across multiple (more than two) modalities. We use deep learning\nframework to learn non-linear transformations from different modalities to a\nshared subspace such that the representations maximize the ratio of between-\nand within-modality covariance of the observations. Unlike linear discriminant\nanalysis, we do not need class information to learn these representations, and\nwe show that this model can be trained for complex data using mini-batches.\nUsing synthetic data experiments, we show that dMCCA can effectively recover\nthe common signal across the different modalities corrupted by multiplicative\nand additive noise. We also analyze the sensitivity of our model to recover the\ncorrelated components with respect to mini-batch size and dimension of the\nembeddings. Performance evaluation on noisy handwritten datasets shows that our\nmodel outperforms other CCA-based approaches and is comparable to deep neural\nnetwork models trained end-to-end on this dataset.\n", "versions": [{"version": "v1", "created": "Wed, 3 Apr 2019 05:30:30 GMT"}], "update_date": "2019-04-04", "authors_parsed": [["Somandepalli", "Krishna", ""], ["Kumar", "Naveen", ""], ["Travadi", "Ruchir", ""], ["Narayanan", "Shrikanth", ""]]}, {"id": "1904.01777", "submitter": "Heng Wang", "authors": "Heng Wang, Mingzhi Mao", "title": "Defeats GAN: A Simpler Model Outperforms in Knowledge Representation\n  Learning", "comments": "5 pages, 1 figure, has been accepted as a conference paper of the 3rd\n  IEEE International Conference on Computational Intelligence and Applications\n  (ICCIA 2018)", "journal-ref": "Proceedings of the 3rd IEEE International Conference on\n  Computational Intelligence and Applications (ICCIA 2018)", "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The goal of knowledge representation learning is to embed entities and\nrelations into a low-dimensional, continuous vector space. How to push a model\nto its limit and obtain better results is of great significance in knowledge\ngraph's applications. We propose a simple and elegant method, Trans-DLR, whose\nmain idea is dynamic learning rate control during training. Our method achieves\nremarkable improvement, compared with recent GAN-based method. Moreover, we\nintroduce a new negative sampling trick which corrupts not only entities, but\nalso relations, in different probabilities. We also develop an efficient way,\nwhich fully utilizes multiprocessing and parallel computing, to speed up\nevaluation of the model in link prediction tasks. Experiments show that our\nmethod is effective.\n", "versions": [{"version": "v1", "created": "Wed, 3 Apr 2019 05:42:14 GMT"}], "update_date": "2019-04-04", "authors_parsed": [["Wang", "Heng", ""], ["Mao", "Mingzhi", ""]]}, {"id": "1904.01790", "submitter": "Daichi Nishio", "authors": "Daichi Nishio and Satoshi Yamane", "title": "Random Projection in Neural Episodic Control", "comments": "16 pages, 5 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  End-to-end deep reinforcement learning has enabled agents to learn with\nlittle preprocessing by humans. However, it is still difficult to learn stably\nand efficiently because the learning method usually uses a nonlinear function\napproximation. Neural Episodic Control (NEC), which has been proposed in order\nto improve sample efficiency, is able to learn stably by estimating action\nvalues using a non-parametric method. In this paper, we propose an architecture\nthat incorporates random projection into NEC to train with more stability. In\naddition, we verify the effectiveness of our architecture by Atari's five\ngames. The main idea is to reduce the number of parameters that have to learn\nby replacing neural networks with random projection in order to reduce\ndimensions while keeping the learning end-to-end.\n", "versions": [{"version": "v1", "created": "Wed, 3 Apr 2019 06:17:33 GMT"}, {"version": "v2", "created": "Sun, 14 Apr 2019 10:05:35 GMT"}], "update_date": "2019-04-16", "authors_parsed": [["Nishio", "Daichi", ""], ["Yamane", "Satoshi", ""]]}, {"id": "1904.01793", "submitter": "Michael P. Kim", "authors": "Michael P. Kim and Aleksandra Korolova and Guy N. Rothblum and Gal\n  Yona", "title": "Preference-Informed Fairness", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CY cs.DS stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study notions of fairness in decision-making systems when individuals have\ndiverse preferences over the possible outcomes of the decisions. Our starting\npoint is the seminal work of Dwork et al. which introduced a notion of\nindividual fairness (IF): given a task-specific similarity metric, every pair\nof individuals who are similarly qualified according to the metric should\nreceive similar outcomes. We show that when individuals have diverse\npreferences over outcomes, requiring IF may unintentionally lead to\nless-preferred outcomes for the very individuals that IF aims to protect. A\nnatural alternative to IF is the classic notion of fair division, envy-freeness\n(EF): no individual should prefer another individual's outcome over their own.\nAlthough EF allows for solutions where all individuals receive a\nhighly-preferred outcome, EF may also be overly-restrictive. For instance, if\nmany individuals agree on the best outcome, then if any individual receives\nthis outcome, they all must receive it, regardless of each individual's\nunderlying qualifications for the outcome.\n  We introduce and study a new notion of preference-informed individual\nfairness (PIIF) that is a relaxation of both individual fairness and\nenvy-freeness. At a high-level, PIIF requires that outcomes satisfy IF-style\nconstraints, but allows for deviations provided they are in line with\nindividuals' preferences. We show that PIIF can permit outcomes that are more\nfavorable to individuals than any IF solution, while providing considerably\nmore flexibility to the decision-maker than EF. In addition, we show how to\nefficiently optimize any convex objective over the outcomes subject to PIIF for\na rich class of individual preferences. Finally, we demonstrate the broad\napplicability of the PIIF framework by extending our definitions and algorithms\nto the multiple-task targeted advertising setting introduced by Dwork and\nIlvento.\n", "versions": [{"version": "v1", "created": "Wed, 3 Apr 2019 06:29:30 GMT"}, {"version": "v2", "created": "Tue, 10 Sep 2019 18:07:36 GMT"}], "update_date": "2019-09-12", "authors_parsed": [["Kim", "Michael P.", ""], ["Korolova", "Aleksandra", ""], ["Rothblum", "Guy N.", ""], ["Yona", "Gal", ""]]}, {"id": "1904.01806", "submitter": "Edward Beeching", "authors": "Edward Beeching and Christian Wolf and Jilles Dibangoye and Olivier\n  Simonin", "title": "Deep Reinforcement Learning on a Budget: 3D Control and Reasoning\n  Without a Supercomputer", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  An important goal of research in Deep Reinforcement Learning in mobile\nrobotics is to train agents capable of solving complex tasks, which require a\nhigh level of scene understanding and reasoning from an egocentric perspective.\nWhen trained from simulations, optimal environments should satisfy a currently\nunobtainable combination of high-fidelity photographic observations, massive\namounts of different environment configurations and fast simulation speeds. In\nthis paper we argue that research on training agents capable of complex\nreasoning can be simplified by decoupling from the requirement of high fidelity\nphotographic observations. We present a suite of tasks requiring complex\nreasoning and exploration in continuous, partially observable 3D environments.\nThe objective is to provide challenging scenarios and a robust baseline agent\narchitecture that can be trained on mid-range consumer hardware in under 24h.\nOur scenarios combine two key advantages: (i) they are based on a simple but\nhighly efficient 3D environment (ViZDoom) which allows high speed simulation\n(12000fps); (ii) the scenarios provide the user with a range of difficulty\nsettings, in order to identify the limitations of current state of the art\nalgorithms and network architectures. We aim to increase accessibility to the\nfield of Deep-RL by providing baselines for challenging scenarios where new\nideas can be iterated on quickly. We argue that the community should be able to\naddress challenging problems in reasoning of mobile agents without the need for\na large compute infrastructure.\n", "versions": [{"version": "v1", "created": "Wed, 3 Apr 2019 07:15:46 GMT"}], "update_date": "2019-04-04", "authors_parsed": [["Beeching", "Edward", ""], ["Wolf", "Christian", ""], ["Dibangoye", "Jilles", ""], ["Simonin", "Olivier", ""]]}, {"id": "1904.01814", "submitter": "Shao-Bo Lin", "authors": "Charles K. Chui, Shao-Bo Lin, Ding-Xuan Zhou", "title": "Deep Neural Networks for Rotation-Invariance Approximation and Learning", "comments": "34 pages, 1 figure", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Based on the tree architecture, the objective of this paper is to design deep\nneural networks with two or more hidden layers (called deep nets) for\nrealization of radial functions so as to enable rotational invariance for\nnear-optimal function approximation in an arbitrarily high dimensional\nEuclidian space. It is shown that deep nets have much better performance than\nshallow nets (with only one hidden layer) in terms of approximation accuracy\nand learning capabilities. In particular, for learning radial functions, it is\nshown that near-optimal rate can be achieved by deep nets but not by shallow\nnets. Our results illustrate the necessity of depth in neural network design\nfor realization of rotation-invariance target functions.\n", "versions": [{"version": "v1", "created": "Wed, 3 Apr 2019 07:40:40 GMT"}], "update_date": "2019-04-04", "authors_parsed": [["Chui", "Charles K.", ""], ["Lin", "Shao-Bo", ""], ["Zhou", "Ding-Xuan", ""]]}, {"id": "1904.01821", "submitter": "Kyung-Su Kim", "authors": "Kyung-Su Kim, Sae-Young Chung", "title": "Fourier Phase Retrieval with Extended Support Estimation via Deep Neural\n  Network", "comments": null, "journal-ref": null, "doi": "10.1109/LSP.2019.2935814", "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the problem of sparse phase retrieval from Fourier transform\nmagnitudes to recover the $k$-sparse signal vector and its support\n$\\mathcal{T}$. We exploit extended support estimate $\\mathcal{E}$ with size\nlarger than $k$ satisfying $\\mathcal{E} \\supseteq \\mathcal{T}$ and obtained by\na trained deep neural network (DNN). To make the DNN learnable, it provides\n$\\mathcal{E}$ as the union of equivalent solutions of $\\mathcal{T}$ by\nutilizing modulo Fourier invariances. Set $\\mathcal{E}$ can be estimated with\nshort running time via the DNN, and support $\\mathcal{T}$ can be determined\nfrom the DNN output rather than from the full index set by applying hard\nthresholding to $\\mathcal{E}$. Thus, the DNN-based extended support estimation\nimproves the reconstruction performance of the signal with a low complexity\nburden dependent on $k$. Numerical results verify that the proposed scheme has\na superior performance with lower complexity compared to local search-based\ngreedy sparse phase retrieval and a state-of-the-art variant of the Fienup\nmethod.\n", "versions": [{"version": "v1", "created": "Wed, 3 Apr 2019 07:55:22 GMT"}, {"version": "v2", "created": "Tue, 4 Jun 2019 08:27:44 GMT"}, {"version": "v3", "created": "Tue, 13 Aug 2019 04:52:40 GMT"}], "update_date": "2019-10-02", "authors_parsed": [["Kim", "Kyung-Su", ""], ["Chung", "Sae-Young", ""]]}, {"id": "1904.01831", "submitter": "Cai Shaofeng", "authors": "Shaofeng Cai, Gang Chen, Beng Chin Ooi, Jinyang Gao", "title": "Model Slicing for Supporting Complex Analytics with Elastic Inference\n  Cost and Resource Constraints", "comments": "14 pages, 8 figures", "journal-ref": null, "doi": "10.14778/3364324.3364325", "report-no": null, "categories": "cs.LG cs.DB cs.PF", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep learning models have been used to support analytics beyond simple\naggregation, where deeper and wider models have been shown to yield great\nresults. These models consume a huge amount of memory and computational\noperations. However, most of the large-scale industrial applications are often\ncomputational budget constrained. In practice, the peak workload of inference\nservice could be 10x higher than the average cases, with the presence of\nunpredictable extreme cases. Lots of computational resources could be wasted\nduring off-peak hours and the system may crash when the workload exceeds system\ncapacity. How to support deep learning services with a dynamic workload\ncost-efficiently remains a challenging problem. In this paper, we address the\nchallenge with a general and novel training scheme called model slicing, which\nenables deep learning models to provide predictions within the prescribed\ncomputational resource budget dynamically. Model slicing could be viewed as an\nelastic computation solution without requiring more computational resources.\nSuccinctly, each layer in the model is divided into groups of a contiguous\nblock of basic components (i.e. neurons in dense layers and channels in\nconvolutional layers), and then partially ordered relation is introduced to\nthese groups by enforcing that groups participated in each forward pass always\nstarts from the first group to the dynamically-determined rightmost group.\nTrained by dynamically indexing the rightmost group with a single parameter\nslice rate, the network is engendered to build up group-wise and residual\nrepresentation. Then during inference, a sub-model with fewer groups can be\nreadily deployed for efficiency whose computation is roughly quadratic to the\nwidth controlled by the slice rate. Extensive experiments show that models\ntrained with model slicing can effectively support on-demand workload with\nelastic inference cost.\n", "versions": [{"version": "v1", "created": "Wed, 3 Apr 2019 08:16:24 GMT"}, {"version": "v2", "created": "Tue, 8 Oct 2019 08:49:08 GMT"}, {"version": "v3", "created": "Wed, 21 Apr 2021 07:06:20 GMT"}], "update_date": "2021-04-22", "authors_parsed": [["Cai", "Shaofeng", ""], ["Chen", "Gang", ""], ["Ooi", "Beng Chin", ""], ["Gao", "Jinyang", ""]]}, {"id": "1904.01855", "submitter": "Navid Azizan Ruhi", "authors": "Navid Azizan and Babak Hassibi", "title": "A Stochastic Interpretation of Stochastic Mirror Descent: Risk-Sensitive\n  Optimality", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.OC cs.LG cs.SY stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Stochastic mirror descent (SMD) is a fairly new family of algorithms that has\nrecently found a wide range of applications in optimization, machine learning,\nand control. It can be considered a generalization of the classical stochastic\ngradient algorithm (SGD), where instead of updating the weight vector along the\nnegative direction of the stochastic gradient, the update is performed in a\n\"mirror domain\" defined by the gradient of a (strictly convex) potential\nfunction. This potential function, and the mirror domain it yields, provides\nconsiderable flexibility in the algorithm compared to SGD. While many\nproperties of SMD have already been obtained in the literature, in this paper\nwe exhibit a new interpretation of SMD, namely that it is a risk-sensitive\noptimal estimator when the unknown weight vector and additive noise are\nnon-Gaussian and belong to the exponential family of distributions. The\nanalysis also suggests a modified version of SMD, which we refer to as\nsymmetric SMD (SSMD). The proofs rely on some simple properties of Bregman\ndivergence, which allow us to extend results from quadratics and Gaussians to\ncertain convex functions and exponential families in a rather seamless way.\n", "versions": [{"version": "v1", "created": "Wed, 3 Apr 2019 08:57:18 GMT"}], "update_date": "2019-04-04", "authors_parsed": [["Azizan", "Navid", ""], ["Hassibi", "Babak", ""]]}, {"id": "1904.01866", "submitter": "Byeongho Heo", "authors": "Byeongho Heo, Jeesoo Kim, Sangdoo Yun, Hyojin Park, Nojun Kwak, Jin\n  Young Choi", "title": "A Comprehensive Overhaul of Feature Distillation", "comments": "Accepted at ICCV 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We investigate the design aspects of feature distillation methods achieving\nnetwork compression and propose a novel feature distillation method in which\nthe distillation loss is designed to make a synergy among various aspects:\nteacher transform, student transform, distillation feature position and\ndistance function. Our proposed distillation loss includes a feature transform\nwith a newly designed margin ReLU, a new distillation feature position, and a\npartial L2 distance function to skip redundant information giving adverse\neffects to the compression of student. In ImageNet, our proposed method\nachieves 21.65% of top-1 error with ResNet50, which outperforms the performance\nof the teacher network, ResNet152. Our proposed method is evaluated on various\ntasks such as image classification, object detection and semantic segmentation\nand achieves a significant performance improvement in all tasks. The code is\navailable at https://sites.google.com/view/byeongho-heo/overhaul\n", "versions": [{"version": "v1", "created": "Wed, 3 Apr 2019 09:17:59 GMT"}, {"version": "v2", "created": "Fri, 9 Aug 2019 05:07:09 GMT"}], "update_date": "2019-08-12", "authors_parsed": [["Heo", "Byeongho", ""], ["Kim", "Jeesoo", ""], ["Yun", "Sangdoo", ""], ["Park", "Hyojin", ""], ["Kwak", "Nojun", ""], ["Choi", "Jin Young", ""]]}, {"id": "1904.01934", "submitter": "Fengqi You", "authors": "Chao Ning, Fengqi You", "title": "Optimization under Uncertainty in the Era of Big Data and Deep Learning:\n  When Machine Learning Meets Mathematical Programming", "comments": null, "journal-ref": "Comput. Chem. Eng., Volume 125, 9 June 2019, Pages 434-448", "doi": "10.1016/j.compchemeng.2019.03.034", "report-no": null, "categories": "cs.LG math.OC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper reviews recent advances in the field of optimization under\nuncertainty via a modern data lens, highlights key research challenges and\npromise of data-driven optimization that organically integrates machine\nlearning and mathematical programming for decision-making under uncertainty,\nand identifies potential research opportunities. A brief review of classical\nmathematical programming techniques for hedging against uncertainty is first\npresented, along with their wide spectrum of applications in Process Systems\nEngineering. A comprehensive review and classification of the relevant\npublications on data-driven distributionally robust optimization, data-driven\nchance constrained program, data-driven robust optimization, and data-driven\nscenario-based optimization is then presented. This paper also identifies\nfertile avenues for future research that focuses on a closed-loop data-driven\noptimization framework, which allows the feedback from mathematical programming\nto machine learning, as well as scenario-based optimization leveraging the\npower of deep learning techniques. Perspectives on online learning-based\ndata-driven multistage optimization with a learning-while-optimizing scheme is\npresented.\n", "versions": [{"version": "v1", "created": "Wed, 3 Apr 2019 11:54:22 GMT"}], "update_date": "2019-04-16", "authors_parsed": [["Ning", "Chao", ""], ["You", "Fengqi", ""]]}, {"id": "1904.01949", "submitter": "Antonio H. Ribeiro", "authors": "Ant\\^onio H. Ribeiro, Manoel Horta Ribeiro, Gabriela M.M. Paix\\~ao,\n  Derick M. Oliveira, Paulo R. Gomes, J\\'essica A. Canazart, Milton P. S.\n  Ferreira, Carl R. Andersson, Peter W. Macfarlane, Wagner Meira Jr., Thomas B.\n  Sch\\\"on, Antonio Luiz P. Ribeiro", "title": "Automatic diagnosis of the 12-lead ECG using a deep neural network", "comments": "A preliminary version of this work titled: \"Automatic Diagnosis of\n  Short-Duration 12-Lead ECG using a Deep Convolutional Network \" was presented\n  in the Machine Learning for Health Workshop at NeurIPS 2018 and was made\n  available under a different identifier: arXiv:1811.12194. The current version\n  subsumes all previous versions", "journal-ref": "Nature Communications 11, article number: 1760 (2020)", "doi": "10.1038/s41467-020-15432-4", "report-no": null, "categories": "cs.LG eess.SP stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The role of automatic electrocardiogram (ECG) analysis in clinical practice\nis limited by the accuracy of existing models. Deep Neural Networks (DNNs) are\nmodels composed of stacked transformations that learn tasks by examples. This\ntechnology has recently achieved striking success in a variety of task and\nthere are great expectations on how it might improve clinical practice. Here we\npresent a DNN model trained in a dataset with more than 2 million labeled exams\nanalyzed by the Telehealth Network of Minas Gerais and collected under the\nscope of the CODE (Clinical Outcomes in Digital Electrocardiology) study. The\nDNN outperform cardiology resident medical doctors in recognizing 6 types of\nabnormalities in 12-lead ECG recordings, with F1 scores above 80% and\nspecificity over 99%. These results indicate ECG analysis based on DNNs,\npreviously studied in a single-lead setup, generalizes well to 12-lead exams,\ntaking the technology closer to the standard clinical practice.\n", "versions": [{"version": "v1", "created": "Tue, 2 Apr 2019 03:20:08 GMT"}, {"version": "v2", "created": "Tue, 14 Apr 2020 16:07:33 GMT"}], "update_date": "2020-04-15", "authors_parsed": [["Ribeiro", "Ant\u00f4nio H.", ""], ["Ribeiro", "Manoel Horta", ""], ["Paix\u00e3o", "Gabriela M. M.", ""], ["Oliveira", "Derick M.", ""], ["Gomes", "Paulo R.", ""], ["Canazart", "J\u00e9ssica A.", ""], ["Ferreira", "Milton P. S.", ""], ["Andersson", "Carl R.", ""], ["Macfarlane", "Peter W.", ""], ["Meira", "Wagner", "Jr."], ["Sch\u00f6n", "Thomas B.", ""], ["Ribeiro", "Antonio Luiz P.", ""]]}, {"id": "1904.01957", "submitter": "Paul Todorov", "authors": "Paul Todorov", "title": "A Game of Dice: Machine Learning and the Question Concerning Art", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We review some practical and philosophical questions raised by the use of\nmachine learning in creative practice. Beyond the obvious problems regarding\nplagiarism and authorship, we argue that the novelty in AI Art relies mostly on\na narrow machine learning contribution : manifold approximation. Nevertheless,\nthis contribution creates a radical shift in the way we have to consider this\nmovement. Is this omnipotent tool a blessing or a curse for the artists?\n", "versions": [{"version": "v1", "created": "Tue, 2 Apr 2019 09:37:44 GMT"}], "update_date": "2019-04-04", "authors_parsed": [["Todorov", "Paul", ""]]}, {"id": "1904.01962", "submitter": "Konstantinos Skianis", "authors": "Konstantinos Skianis, Giannis Nikolentzos, Stratis Limnios, Michalis\n  Vazirgiannis", "title": "Rep the Set: Neural Networks for Learning Set Representations", "comments": "AISTATS 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In several domains, data objects can be decomposed into sets of simpler\nobjects. It is then natural to represent each object as the set of its\ncomponents or parts. Many conventional machine learning algorithms are unable\nto process this kind of representations, since sets may vary in cardinality and\nelements lack a meaningful ordering. In this paper, we present a new neural\nnetwork architecture, called RepSet, that can handle examples that are\nrepresented as sets of vectors. The proposed model computes the correspondences\nbetween an input set and some hidden sets by solving a series of network flow\nproblems. This representation is then fed to a standard neural network\narchitecture to produce the output. The architecture allows end-to-end\ngradient-based learning. We demonstrate RepSet on classification tasks,\nincluding text categorization, and graph classification, and we show that the\nproposed neural network achieves performance better or comparable to\nstate-of-the-art algorithms.\n", "versions": [{"version": "v1", "created": "Wed, 3 Apr 2019 12:25:54 GMT"}, {"version": "v2", "created": "Fri, 28 Feb 2020 19:19:12 GMT"}], "update_date": "2020-03-03", "authors_parsed": [["Skianis", "Konstantinos", ""], ["Nikolentzos", "Giannis", ""], ["Limnios", "Stratis", ""], ["Vazirgiannis", "Michalis", ""]]}, {"id": "1904.01975", "submitter": "Zhengping Che", "authors": "Zhengping Che, Guangyu Li, Tracy Li, Bo Jiang, Xuefeng Shi, Xinsheng\n  Zhang, Ying Lu, Guobin Wu, Yan Liu, Jieping Ye", "title": "D$^2$-City: A Large-Scale Dashcam Video Dataset of Diverse Traffic\n  Scenarios", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Driving datasets accelerate the development of intelligent driving and\nrelated computer vision technologies, while substantial and detailed\nannotations serve as fuels and powers to boost the efficacy of such datasets to\nimprove learning-based models. We propose D$^2$-City, a large-scale\ncomprehensive collection of dashcam videos collected by vehicles on DiDi's\nplatform. D$^2$-City contains more than 10000 video clips which deeply reflect\nthe diversity and complexity of real-world traffic scenarios in China. We also\nprovide bounding boxes and tracking annotations of 12 classes of objects in all\nframes of 1000 videos and detection annotations on keyframes for the remainder\nof the videos. Compared with existing datasets, D$^2$-City features data in\nvarying weather, road, and traffic conditions and a huge amount of elaborate\ndetection and tracking annotations. By bringing a diverse set of challenging\ncases to the community, we expect the D$^2$-City dataset will advance the\nperception and related areas of intelligent driving.\n", "versions": [{"version": "v1", "created": "Wed, 3 Apr 2019 12:40:08 GMT"}, {"version": "v2", "created": "Mon, 3 Jun 2019 06:42:25 GMT"}], "update_date": "2019-06-04", "authors_parsed": [["Che", "Zhengping", ""], ["Li", "Guangyu", ""], ["Li", "Tracy", ""], ["Jiang", "Bo", ""], ["Shi", "Xuefeng", ""], ["Zhang", "Xinsheng", ""], ["Lu", "Ying", ""], ["Wu", "Guobin", ""], ["Liu", "Yan", ""], ["Ye", "Jieping", ""]]}, {"id": "1904.01989", "submitter": "Manuel Mager", "authors": "Manuel Mager, \\\"Ozlem \\c{C}etino\\u{g}lu, Katharina Kann", "title": "Subword-Level Language Identification for Intra-Word Code-Switching", "comments": "NAACL-HLT 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://creativecommons.org/licenses/by-sa/4.0/", "abstract": "  Language identification for code-switching (CS), the phenomenon of\nalternating between two or more languages in conversations, has traditionally\nbeen approached under the assumption of a single language per token. However,\nif at least one language is morphologically rich, a large number of words can\nbe composed of morphemes from more than one language (intra-word CS). In this\npaper, we extend the language identification task to the subword-level, such\nthat it includes splitting mixed words while tagging each part with a language\nID. We further propose a model for this task, which is based on a segmental\nrecurrent neural network. In experiments on a new Spanish--Wixarika dataset and\non an adapted German--Turkish dataset, our proposed model performs slightly\nbetter than or roughly on par with our best baseline, respectively. Considering\nonly mixed words, however, it strongly outperforms all baselines.\n", "versions": [{"version": "v1", "created": "Wed, 3 Apr 2019 13:08:12 GMT"}], "update_date": "2019-04-04", "authors_parsed": [["Mager", "Manuel", ""], ["\u00c7etino\u011flu", "\u00d6zlem", ""], ["Kann", "Katharina", ""]]}, {"id": "1904.01990", "submitter": "Zhun Zhong", "authors": "Zhun Zhong, Liang Zheng, Zhiming Luo, Shaozi Li, Yi Yang", "title": "Invariance Matters: Exemplar Memory for Domain Adaptive Person\n  Re-identification", "comments": "To appear in CVPR 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper considers the domain adaptive person re-identification (re-ID)\nproblem: learning a re-ID model from a labeled source domain and an unlabeled\ntarget domain. Conventional methods are mainly to reduce feature distribution\ngap between the source and target domains. However, these studies largely\nneglect the intra-domain variations in the target domain, which contain\ncritical factors influencing the testing performance on the target domain. In\nthis work, we comprehensively investigate into the intra-domain variations of\nthe target domain and propose to generalize the re-ID model w.r.t three types\nof the underlying invariance, i.e., exemplar-invariance, camera-invariance and\nneighborhood-invariance. To achieve this goal, an exemplar memory is introduced\nto store features of the target domain and accommodate the three invariance\nproperties. The memory allows us to enforce the invariance constraints over\nglobal training batch without significantly increasing computation cost.\nExperiment demonstrates that the three invariance properties and the proposed\nmemory are indispensable towards an effective domain adaptation system. Results\non three re-ID domains show that our domain adaptation accuracy outperforms the\nstate of the art by a large margin. Code is available at:\nhttps://github.com/zhunzhong07/ECN\n", "versions": [{"version": "v1", "created": "Wed, 3 Apr 2019 13:11:59 GMT"}], "update_date": "2019-04-04", "authors_parsed": [["Zhong", "Zhun", ""], ["Zheng", "Liang", ""], ["Luo", "Zhiming", ""], ["Li", "Shaozi", ""], ["Yang", "Yi", ""]]}, {"id": "1904.02016", "submitter": "Guy W Cole", "authors": "Guy W. Cole and Sinead A. Williamson", "title": "Stochastic Blockmodels with Edge Information", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SI cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Stochastic blockmodels allow us to represent networks in terms of a latent\ncommunity structure, often yielding intuitions about the underlying social\nstructure. Typically, this structure is inferred based only on a binary network\nrepresenting the presence or absence of interactions between nodes, which\nlimits the amount of information that can be extracted from the data. In\npractice, many interaction networks contain much more information about the\nrelationship between two nodes. For example, in an email network, the volume of\ncommunication between two users and the content of that communication can give\nus information about both the strength and the nature of their relationship.\n  In this paper, we propose the Topic Blockmodel, a stochastic blockmodel that\nuses a count-based topic model to capture the interaction modalities within and\nbetween latent communities. By explicitly incorporating information sent\nbetween nodes in our network representation, we are able to address questions\nof interest in real-world situations, such as predicting recipients for an\nemail message or inferring the content of an unopened email. Further, by\nconsidering topics associated with a pair of communities, we are better able to\ninterpret the nature of each community and the manner in which it interacts\nwith other communities.\n", "versions": [{"version": "v1", "created": "Wed, 3 Apr 2019 14:12:40 GMT"}], "update_date": "2019-04-04", "authors_parsed": [["Cole", "Guy W.", ""], ["Williamson", "Sinead A.", ""]]}, {"id": "1904.02020", "submitter": "Zita Marinho", "authors": "Afonso Mendes and Shashi Narayan and Sebasti\\~ao Miranda and Zita\n  Marinho and Andr\\'e F. T. Martins and Shay B. Cohen", "title": "Jointly Extracting and Compressing Documents with Summary State\n  Representations", "comments": null, "journal-ref": "NAACL 2019", "doi": null, "report-no": null, "categories": "cs.IR cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a new neural model for text summarization that first extracts\nsentences from a document and then compresses them. The proposed model offers a\nbalance that sidesteps the difficulties in abstractive methods while generating\nmore concise summaries than extractive methods. In addition, our model\ndynamically determines the length of the output summary based on the gold\nsummaries it observes during training and does not require length constraints\ntypical to extractive summarization. The model achieves state-of-the-art\nresults on the CNN/DailyMail and Newsroom datasets, improving over current\nextractive and abstractive methods. Human evaluations demonstrate that our\nmodel generates concise and informative summaries. We also make available a new\ndataset of oracle compressive summaries derived automatically from the\nCNN/DailyMail reference summaries.\n", "versions": [{"version": "v1", "created": "Wed, 3 Apr 2019 14:24:04 GMT"}, {"version": "v2", "created": "Fri, 5 Apr 2019 16:09:19 GMT"}], "update_date": "2019-04-08", "authors_parsed": [["Mendes", "Afonso", ""], ["Narayan", "Shashi", ""], ["Miranda", "Sebasti\u00e3o", ""], ["Marinho", "Zita", ""], ["Martins", "Andr\u00e9 F. T.", ""], ["Cohen", "Shay B.", ""]]}, {"id": "1904.02021", "submitter": "James Smith", "authors": "James Smith, Cameron Taylor, Seth Baer, and Constantine Dovrolis", "title": "Unsupervised Progressive Learning and the STAM Architecture", "comments": "Accepted by the 2021 International Joint Conference on Artificial\n  Intelligence (IJCAI 2021)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG q-bio.NC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We first pose the Unsupervised Progressive Learning (UPL) problem: an online\nrepresentation learning problem in which the learner observes a non-stationary\nand unlabeled data stream, learning a growing number of features that persist\nover time even though the data is not stored or replayed. To solve the UPL\nproblem we propose the Self-Taught Associative Memory (STAM) architecture.\nLayered hierarchies of STAM modules learn based on a combination of online\nclustering, novelty detection, forgetting outliers, and storing only\nprototypical features rather than specific examples. We evaluate STAM\nrepresentations using clustering and classification tasks. While there are no\nexisting learning scenarios that are directly comparable to UPL, we compare the\nSTAM architecture with two recent continual learning models, Memory Aware\nSynapses (MAS) and Gradient Episodic Memories (GEM), after adapting them in the\nUPL setting.\n", "versions": [{"version": "v1", "created": "Wed, 3 Apr 2019 14:25:08 GMT"}, {"version": "v2", "created": "Sun, 29 Sep 2019 18:02:19 GMT"}, {"version": "v3", "created": "Thu, 3 Oct 2019 13:43:48 GMT"}, {"version": "v4", "created": "Tue, 18 Feb 2020 05:16:25 GMT"}, {"version": "v5", "created": "Wed, 10 Jun 2020 22:00:27 GMT"}, {"version": "v6", "created": "Thu, 13 May 2021 17:55:25 GMT"}], "update_date": "2021-05-14", "authors_parsed": [["Smith", "James", ""], ["Taylor", "Cameron", ""], ["Baer", "Seth", ""], ["Dovrolis", "Constantine", ""]]}, {"id": "1904.02033", "submitter": "Ilya Razenshteyn", "authors": "Hao Chen and Ilaria Chillotti and Yihe Dong and Oxana Poburinnaya and\n  Ilya Razenshteyn and M. Sadegh Riazi", "title": "SANNS: Scaling Up Secure Approximate k-Nearest Neighbors Search", "comments": "18 pages, to appear at USENIX Security Symposium 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.CR cs.DB cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The $k$-Nearest Neighbor Search ($k$-NNS) is the backbone of several\ncloud-based services such as recommender systems, face recognition, and\ndatabase search on text and images. In these services, the client sends the\nquery to the cloud server and receives the response in which case the query and\nresponse are revealed to the service provider. Such data disclosures are\nunacceptable in several scenarios due to the sensitivity of data and/or privacy\nlaws.\n  In this paper, we introduce SANNS, a system for secure $k$-NNS that keeps\nclient's query and the search result confidential. SANNS comprises two\nprotocols: an optimized linear scan and a protocol based on a novel sublinear\ntime clustering-based algorithm. We prove the security of both protocols in the\nstandard semi-honest model. The protocols are built upon several\nstate-of-the-art cryptographic primitives such as lattice-based additively\nhomomorphic encryption, distributed oblivious RAM, and garbled circuits. We\nprovide several contributions to each of these primitives which are applicable\nto other secure computation tasks. Both of our protocols rely on a new circuit\nfor the approximate top-$k$ selection from $n$ numbers that is built from $O(n\n+ k^2)$ comparators.\n  We have implemented our proposed system and performed extensive experimental\nresults on four datasets in two different computation environments,\ndemonstrating more than $18-31\\times$ faster response time compared to\noptimally implemented protocols from the prior work. Moreover, SANNS is the\nfirst work that scales to the database of 10 million entries, pushing the limit\nby more than two orders of magnitude.\n", "versions": [{"version": "v1", "created": "Wed, 3 Apr 2019 14:38:11 GMT"}, {"version": "v2", "created": "Mon, 17 Jun 2019 08:53:48 GMT"}, {"version": "v3", "created": "Mon, 8 Jul 2019 15:41:33 GMT"}, {"version": "v4", "created": "Wed, 20 Nov 2019 08:15:50 GMT"}, {"version": "v5", "created": "Sun, 8 Mar 2020 23:59:18 GMT"}], "update_date": "2020-03-10", "authors_parsed": [["Chen", "Hao", ""], ["Chillotti", "Ilaria", ""], ["Dong", "Yihe", ""], ["Poburinnaya", "Oxana", ""], ["Razenshteyn", "Ilya", ""], ["Riazi", "M. Sadegh", ""]]}, {"id": "1904.02063", "submitter": "Jeremias Knoblauch", "authors": "Jeremias Knoblauch, Jack Jewson, Theodoros Damoulas", "title": "Generalized Variational Inference: Three arguments for deriving new\n  Posteriors", "comments": "103 pages, 23 figures (comprehensive revision of previous version)", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We advocate an optimization-centric view on and introduce a novel\ngeneralization of Bayesian inference. Our inspiration is the representation of\nBayes' rule as infinite-dimensional optimization problem (Csiszar, 1975;\nDonsker and Varadhan; 1975, Zellner; 1988). First, we use it to prove an\noptimality result of standard Variational Inference (VI): Under the proposed\nview, the standard Evidence Lower Bound (ELBO) maximizing VI posterior is\npreferable to alternative approximations of the Bayesian posterior. Next, we\nargue for generalizing standard Bayesian inference. The need for this arises in\nsituations of severe misalignment between reality and three assumptions\nunderlying standard Bayesian inference: (1) Well-specified priors, (2)\nwell-specified likelihoods, (3) the availability of infinite computing power.\nOur generalization addresses these shortcomings with three arguments and is\ncalled the Rule of Three (RoT). We derive it axiomatically and recover existing\nposteriors as special cases, including the Bayesian posterior and its\napproximation by standard VI. In contrast, approximations based on alternative\nELBO-like objectives violate the axioms. Finally, we study a special case of\nthe RoT that we call Generalized Variational Inference (GVI). GVI posteriors\nare a large and tractable family of belief distributions specified by three\narguments: A loss, a divergence and a variational family. GVI posteriors have\nappealing properties, including consistency and an interpretation as\napproximate ELBO. The last part of the paper explores some attractive\napplications of GVI in popular machine learning models, including robustness\nand more appropriate marginals. After deriving black box inference schemes for\nGVI posteriors, their predictive performance is investigated on Bayesian Neural\nNetworks and Deep Gaussian Processes, where GVI can comprehensively improve\nupon existing methods.\n", "versions": [{"version": "v1", "created": "Wed, 3 Apr 2019 15:31:46 GMT"}, {"version": "v2", "created": "Thu, 4 Apr 2019 10:48:21 GMT"}, {"version": "v3", "created": "Tue, 21 May 2019 01:53:32 GMT"}, {"version": "v4", "created": "Thu, 12 Dec 2019 15:02:50 GMT"}], "update_date": "2019-12-13", "authors_parsed": [["Knoblauch", "Jeremias", ""], ["Jewson", "Jack", ""], ["Damoulas", "Theodoros", ""]]}, {"id": "1904.02064", "submitter": "Byoungwook Jang", "authors": "Byoungwook Jang, Alfred Hero", "title": "Minimum Volume Topic Modeling", "comments": "Accepted in AISTATS 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.IR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a new topic modeling procedure that takes advantage of the fact\nthat the Latent Dirichlet Allocation (LDA) log likelihood function is\nasymptotically equivalent to the logarithm of the volume of the topic simplex.\nThis allows topic modeling to be reformulated as finding the probability\nsimplex that minimizes its volume and encloses the documents that are\nrepresented as distributions over words. A convex relaxation of the minimum\nvolume topic model optimization is proposed, and it is shown that the relaxed\nproblem has the same global minimum as the original problem under the\nseparability assumption and the sufficiently scattered assumption introduced by\nArora et al. (2013) and Huang et al. (2016). A locally convergent alternating\ndirection method of multipliers (ADMM) approach is introduced for solving the\nrelaxed minimum volume problem. Numerical experiments illustrate the benefits\nof our approach in terms of computation time and topic recovery performance.\n", "versions": [{"version": "v1", "created": "Wed, 3 Apr 2019 15:34:20 GMT"}], "update_date": "2019-04-04", "authors_parsed": [["Jang", "Byoungwook", ""], ["Hero", "Alfred", ""]]}, {"id": "1904.02072", "submitter": "Pedro M. Ferreira", "authors": "Fernando Alves, Aur\\'elien Bettini, Pedro M. Ferreira, Alysson Bessani", "title": "Processing Tweets for Cybersecurity Threat Awareness", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Receiving timely and relevant security information is crucial for maintaining\na high-security level on an IT infrastructure. This information can be\nextracted from Open Source Intelligence published daily by users, security\norganisations, and researchers. In particular, Twitter has become an\ninformation hub for obtaining cutting-edge information about many subjects,\nincluding cybersecurity. This work proposes SYNAPSE, a Twitter-based streaming\nthreat monitor that generates a continuously updated summary of the threat\nlandscape related to a monitored infrastructure. Its tweet-processing pipeline\nis composed of filtering, feature extraction, binary classification, an\ninnovative clustering strategy, and generation of Indicators of Compromise\n(IoCs). A quantitative evaluation considering all tweets from 80 accounts over\nmore than 8 months (over 195.000 tweets), shows that our approach timely and\nsuccessfully finds the majority of security-related tweets concerning an\nexample IT infrastructure (true positive rate above 90%), incorrectly selects a\nsmall number of tweets as relevant (false positive rate under 10%), and\nsummarises the results to very few IoCs per day. A qualitative evaluation of\nthe IoCs generated by SYNAPSE demonstrates their relevance (based on the CVSS\nscore and the availability of patches or exploits), and timeliness (based on\nthreat disclosure dates from NVD).\n", "versions": [{"version": "v1", "created": "Wed, 3 Apr 2019 16:04:16 GMT"}], "update_date": "2019-04-04", "authors_parsed": [["Alves", "Fernando", ""], ["Bettini", "Aur\u00e9lien", ""], ["Ferreira", "Pedro M.", ""], ["Bessani", "Alysson", ""]]}, {"id": "1904.02098", "submitter": "Linying Zhang", "authors": "Linying Zhang, Yixin Wang, Anna Ostropolets, Jami J. Mulgrave, David\n  M. Blei, George Hripcsak", "title": "The Medical Deconfounder: Assessing Treatment Effects with Electronic\n  Health Records", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The treatment effects of medications play a key role in guiding medical\nprescriptions. They are usually assessed with randomized controlled trials\n(RCTs), which are expensive. Recently, large-scale electronic health records\n(EHRs) have become available, opening up new opportunities for more\ncost-effective assessments. However, assessing a treatment effect from EHRs is\nchallenging: it is biased by unobserved confounders, unmeasured variables that\naffect both patients' medical prescription and their outcome, e.g. the\npatients' social economic status. To adjust for unobserved confounders, we\ndevelop the medical deconfounder, a machine learning algorithm that unbiasedly\nestimates treatment effects from EHRs. The medical deconfounder first\nconstructs a substitute confounder by modeling which medications were\nprescribed to each patient; this substitute confounder is guaranteed to capture\nall multi-medication confounders, observed or unobserved (arXiv:1805.06826). It\nthen uses this substitute confounder to adjust for the confounding bias in the\nanalysis. We validate the medical deconfounder on two simulated and two real\nmedical data sets. Compared to classical approaches, the medical deconfounder\nproduces closer-to-truth treatment effect estimates; it also identifies\neffective medications that are more consistent with the findings in the medical\nliterature.\n", "versions": [{"version": "v1", "created": "Wed, 3 Apr 2019 16:49:32 GMT"}, {"version": "v2", "created": "Sat, 17 Aug 2019 15:21:08 GMT"}], "update_date": "2019-08-20", "authors_parsed": [["Zhang", "Linying", ""], ["Wang", "Yixin", ""], ["Ostropolets", "Anna", ""], ["Mulgrave", "Jami J.", ""], ["Blei", "David M.", ""], ["Hripcsak", "George", ""]]}, {"id": "1904.02099", "submitter": "Daniel Kondratyuk", "authors": "Dan Kondratyuk and Milan Straka", "title": "75 Languages, 1 Model: Parsing Universal Dependencies Universally", "comments": "Accepted for publication at EMNLP 2019. 17 pages, 6 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present UDify, a multilingual multi-task model capable of accurately\npredicting universal part-of-speech, morphological features, lemmas, and\ndependency trees simultaneously for all 124 Universal Dependencies treebanks\nacross 75 languages. By leveraging a multilingual BERT self-attention model\npretrained on 104 languages, we found that fine-tuning it on all datasets\nconcatenated together with simple softmax classifiers for each UD task can\nresult in state-of-the-art UPOS, UFeats, Lemmas, UAS, and LAS scores, without\nrequiring any recurrent or language-specific components. We evaluate UDify for\nmultilingual learning, showing that low-resource languages benefit the most\nfrom cross-linguistic annotations. We also evaluate for zero-shot learning,\nwith results suggesting that multilingual training provides strong UD\npredictions even for languages that neither UDify nor BERT have ever been\ntrained on. Code for UDify is available at\nhttps://github.com/hyperparticle/udify.\n", "versions": [{"version": "v1", "created": "Wed, 3 Apr 2019 16:52:55 GMT"}, {"version": "v2", "created": "Fri, 5 Apr 2019 04:14:25 GMT"}, {"version": "v3", "created": "Sun, 25 Aug 2019 23:19:00 GMT"}], "update_date": "2019-08-27", "authors_parsed": [["Kondratyuk", "Dan", ""], ["Straka", "Milan", ""]]}, {"id": "1904.02101", "submitter": "Mateusz Staniak", "authors": "Mateusz Staniak and Przemyslaw Biecek", "title": "The Landscape of R Packages for Automated Exploratory Data Analysis", "comments": null, "journal-ref": null, "doi": "10.32614/RJ-2019-033", "report-no": null, "categories": "stat.CO cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  The increasing availability of large but noisy data sets with a large number\nof heterogeneous variables leads to the increasing interest in the automation\nof common tasks for data analysis. The most time-consuming part of this process\nis the Exploratory Data Analysis, crucial for better domain understanding, data\ncleaning, data validation, and feature engineering.\n  There is a growing number of libraries that attempt to automate some of the\ntypical Exploratory Data Analysis tasks to make the search for new insights\neasier and faster. In this paper, we present a systematic review of existing\ntools for Automated Exploratory Data Analysis (autoEDA). We explore the\nfeatures of twelve popular R packages to identify the parts of analysis that\ncan be effectively automated with the current tools and to point out new\ndirections for further autoEDA development.\n", "versions": [{"version": "v1", "created": "Wed, 27 Mar 2019 09:49:33 GMT"}, {"version": "v2", "created": "Mon, 29 Jul 2019 19:38:14 GMT"}, {"version": "v3", "created": "Wed, 18 Sep 2019 08:27:29 GMT"}], "update_date": "2019-09-19", "authors_parsed": [["Staniak", "Mateusz", ""], ["Biecek", "Przemyslaw", ""]]}, {"id": "1904.02113", "submitter": "Loic Landrieu", "authors": "Loic Landrieu, Mohamed Boussaha", "title": "Point Cloud Oversegmentation with Graph-Structured Deep Metric Learning", "comments": "CVPR2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a new supervized learning framework for oversegmenting 3D point\nclouds into superpoints. We cast this problem as learning deep embeddings of\nthe local geometry and radiometry of 3D points, such that the border of objects\npresents high contrasts. The embeddings are computed using a lightweight neural\nnetwork operating on the points' local neighborhood. Finally, we formulate\npoint cloud oversegmentation as a graph partition problem with respect to the\nlearned embeddings.\n  This new approach allows us to set a new state-of-the-art in point cloud\noversegmentation by a significant margin, on a dense indoor dataset (S3DIS) and\na sparse outdoor one (vKITTI). Our best solution requires over five times fewer\nsuperpoints to reach similar performance than previously published methods on\nS3DIS. Furthermore, we show that our framework can be used to improve\nsuperpoint-based semantic segmentation algorithms, setting a new\nstate-of-the-art for this task as well.\n", "versions": [{"version": "v1", "created": "Wed, 3 Apr 2019 17:18:26 GMT"}], "update_date": "2019-04-04", "authors_parsed": [["Landrieu", "Loic", ""], ["Boussaha", "Mohamed", ""]]}, {"id": "1904.02122", "submitter": "Sanjay Sahay", "authors": "Ashu Sharma and Sanjay K. Sahay", "title": "Group-wise classification approach to improve Android malicious apps\n  detection accuracy", "comments": "9 pages, 20 Figures", "journal-ref": "International Journal of Network Security, Vol. 21, No. 3, pp.\n  409-417, 2019", "doi": null, "report-no": null, "categories": "cs.CR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In the fast-growing smart devices, Android is the most popular OS, and due to\nits attractive features, mobility, ease of use, these devices hold sensitive\ninformation such as personal data, browsing history, shopping history,\nfinancial details, etc. Therefore, any security gap in these devices means that\nthe information stored or accessing the smart devices are at high risk of being\nbreached by the malware. These malware are continuously growing and are also\nused for military espionage, disrupting the industry, power grids, etc. To\ndetect these malware, traditional signature matching techniques are widely\nused. However, such strategies are not capable to detect the advanced Android\nmalicious apps because malware developer uses several obfuscation techniques.\nHence, researchers are continuously addressing the security issues in the\nAndroid based smart devices. Therefore, in this paper using Drebin benchmark\nmalware dataset we experimentally demonstrate how to improve the detection\naccuracy by analyzing the apps after grouping the collected data based on the\npermissions and achieved 97.15% overall average accuracy. Our results\noutperform the accuracy obtained without grouping data (79.27%, 2017), Arp, et\nal. (94%, 2014), Annamalai et al. (84.29%, 2016), Bahman Rashidi et al. (82%,\n2017)) and Ali Feizollah, et al. (95.5%, 2017). The analysis also shows that\namong the groups, Microphone group detection accuracy is least while Calendar\ngroup apps are detected with the highest accuracy, and with the highest\naccuracy, and for the best performance, one shall take 80-100 features.\n", "versions": [{"version": "v1", "created": "Wed, 3 Apr 2019 17:33:11 GMT"}], "update_date": "2019-04-04", "authors_parsed": [["Sharma", "Ashu", ""], ["Sahay", "Sanjay K.", ""]]}, {"id": "1904.02144", "submitter": "Jianbo Chen", "authors": "Jianbo Chen, Michael I. Jordan, Martin J. Wainwright", "title": "HopSkipJumpAttack: A Query-Efficient Decision-Based Attack", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR math.OC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The goal of a decision-based adversarial attack on a trained model is to\ngenerate adversarial examples based solely on observing output labels returned\nby the targeted model. We develop HopSkipJumpAttack, a family of algorithms\nbased on a novel estimate of the gradient direction using binary information at\nthe decision boundary. The proposed family includes both untargeted and\ntargeted attacks optimized for $\\ell_2$ and $\\ell_\\infty$ similarity metrics\nrespectively. Theoretical analysis is provided for the proposed algorithms and\nthe gradient direction estimate. Experiments show HopSkipJumpAttack requires\nsignificantly fewer model queries than Boundary Attack. It also achieves\ncompetitive performance in attacking several widely-used defense mechanisms.\n(HopSkipJumpAttack was named Boundary Attack++ in a previous version of the\npreprint.)\n", "versions": [{"version": "v1", "created": "Wed, 3 Apr 2019 17:59:33 GMT"}, {"version": "v2", "created": "Mon, 3 Jun 2019 10:24:22 GMT"}, {"version": "v3", "created": "Mon, 10 Jun 2019 06:36:02 GMT"}, {"version": "v4", "created": "Tue, 17 Sep 2019 04:39:24 GMT"}, {"version": "v5", "created": "Tue, 28 Apr 2020 01:20:45 GMT"}], "update_date": "2020-04-29", "authors_parsed": [["Chen", "Jianbo", ""], ["Jordan", "Michael I.", ""], ["Wainwright", "Martin J.", ""]]}, {"id": "1904.02147", "submitter": "Thai Son Nguyen", "authors": "Thai-Son Nguyen, Sebastian Stueker, Alex Waibel", "title": "Learning Shared Encoding Representation for End-to-End Speech\n  Recognition Models", "comments": "arXiv admin note: substantial text overlap with arXiv:1902.01951", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.AS cs.LG cs.SD", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this work, we learn a shared encoding representation for a multi-task\nneural network model optimized with connectionist temporal classification (CTC)\nand conventional framewise cross-entropy training criteria. Our experiments\nshow that the multi-task training not only tackles the complexity of optimizing\nCTC models such as acoustic-to-word but also results in significant improvement\ncompared to the plain-task training with an optimal setup. Furthermore, we\npropose to use the encoding representation learned by the multi-task network to\ninitialize the encoder of attention-based models. Thereby, we train a deep\nattention-based end-to-end model with 10 long short-term memory (LSTM) layers\nof encoder which produces 12.2\\% and 22.6\\% word-error-rate on Switchboard and\nCallHome subsets of the Hub5 2000 evaluation.\n", "versions": [{"version": "v1", "created": "Sun, 31 Mar 2019 20:46:13 GMT"}], "update_date": "2019-04-04", "authors_parsed": [["Nguyen", "Thai-Son", ""], ["Stueker", "Sebastian", ""], ["Waibel", "Alex", ""]]}, {"id": "1904.02165", "submitter": "Xiao-Ming Zhang", "authors": "Xiao-Ming Zhang and Man-Hong Yung", "title": "Low-Depth Optical Neural Networks", "comments": "16 pages, 6 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "physics.optics cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Optical neural network (ONN) is emerging as an attractive proposal for\nmachine-learning applications, enabling high-speed computation with low-energy\nconsumption. However, there are several challenges in applying ONN for\nindustrial applications, including the realization of activation functions and\nmaintaining stability. In particular, the stability of ONNs decrease with the\ncircuit depth, limiting the scalability of the ONNs for practical uses. Here we\ndemonstrate how to compress the circuit depth of ONN to scale only\nlogarithmically, leading to an exponential gain in terms of noise robustness.\nOur low-depth (LD) ONN is based on an architecture, called Optical CompuTing Of\ndot-Product UnitS (OCTOPUS), which can also be applied individually as a linear\nperceptron for solving classification problems. Using the standard data set of\nLetter Recognition, we present numerical evidence showing that LD-ONN can\nexhibit a significant gain in noise robustness, compared with a previous ONN\nproposal based on singular-value decomposition [Nature Photonics 11, 441\n(2017)].\n", "versions": [{"version": "v1", "created": "Wed, 3 Apr 2019 18:00:01 GMT"}, {"version": "v2", "created": "Sat, 18 May 2019 12:09:39 GMT"}], "update_date": "2019-05-21", "authors_parsed": [["Zhang", "Xiao-Ming", ""], ["Yung", "Man-Hong", ""]]}, {"id": "1904.02200", "submitter": "Lei Yu", "authors": "Lei Yu and Ling Liu and Calton Pu and Mehmet Emre Gursoy and Stacey\n  Truex", "title": "Differentially Private Model Publishing for Deep Learning", "comments": null, "journal-ref": "Proceedings of the 40th IEEE Symposium on Security and Privacy\n  (Oakland), 2019", "doi": "10.1109/SP.2019.00019", "report-no": null, "categories": "cs.CR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep learning techniques based on neural networks have shown significant\nsuccess in a wide range of AI tasks. Large-scale training datasets are one of\nthe critical factors for their success. However, when the training datasets are\ncrowdsourced from individuals and contain sensitive information, the model\nparameters may encode private information and bear the risks of privacy\nleakage. The recent growing trend of the sharing and publishing of pre-trained\nmodels further aggravates such privacy risks. To tackle this problem, we\npropose a differentially private approach for training neural networks. Our\napproach includes several new techniques for optimizing both privacy loss and\nmodel accuracy. We employ a generalization of differential privacy called\nconcentrated differential privacy(CDP), with both a formal and refined privacy\nloss analysis on two different data batching methods. We implement a dynamic\nprivacy budget allocator over the course of training to improve model accuracy.\nExtensive experiments demonstrate that our approach effectively improves\nprivacy loss accounting, training efficiency and model quality under a given\nprivacy budget.\n", "versions": [{"version": "v1", "created": "Wed, 3 Apr 2019 18:54:43 GMT"}, {"version": "v2", "created": "Tue, 9 Apr 2019 02:31:19 GMT"}, {"version": "v3", "created": "Sun, 5 May 2019 00:00:17 GMT"}, {"version": "v4", "created": "Wed, 11 Sep 2019 21:19:29 GMT"}, {"version": "v5", "created": "Thu, 19 Dec 2019 22:50:52 GMT"}], "update_date": "2019-12-23", "authors_parsed": [["Yu", "Lei", ""], ["Liu", "Ling", ""], ["Pu", "Calton", ""], ["Gursoy", "Mehmet Emre", ""], ["Truex", "Stacey", ""]]}, {"id": "1904.02205", "submitter": "David Hartmann", "authors": "David Hartmann, Michael Wand", "title": "Progressive Stochastic Binarization of Deep Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A plethora of recent research has focused on improving the memory footprint\nand inference speed of deep networks by reducing the complexity of (i)\nnumerical representations (for example, by deterministic or stochastic\nquantization) and (ii) arithmetic operations (for example, by binarization of\nweights).\n  We propose a stochastic binarization scheme for deep networks that allows for\nefficient inference on hardware by restricting itself to additions of small\nintegers and fixed shifts. Unlike previous approaches, the underlying\nrandomized approximation is progressive, thus permitting an adaptive control of\nthe accuracy of each operation at run-time. In a low-precision setting, we\nmatch the accuracy of previous binarized approaches. Our representation is\nunbiased - it approaches continuous computation with increasing sample size. In\na high-precision regime, the computational costs are competitive with previous\nquantization schemes. Progressive stochastic binarization also permits\nlocalized, dynamic accuracy control within a single network, thereby providing\na new tool for adaptively focusing computational attention.\n  We evaluate our method on networks of various architectures, already\npretrained on ImageNet. With representational costs comparable to previous\nschemes, we obtain accuracies close to the original floating point\nimplementation. This includes pruned networks, except the known special case of\ncertain types of separated convolutions. By focusing computational attention\nusing progressive sampling, we reduce inference costs on ImageNet further by a\nfactor of up to 33% (before network pruning).\n", "versions": [{"version": "v1", "created": "Wed, 3 Apr 2019 19:09:35 GMT"}], "update_date": "2019-04-05", "authors_parsed": [["Hartmann", "David", ""], ["Wand", "Michael", ""]]}, {"id": "1904.02206", "submitter": "Gabriel de la Cruz Jr", "authors": "Gabriel V. de la Cruz Jr. and Yunshu Du and Matthew E. Taylor", "title": "Jointly Pre-training with Supervised, Autoencoder, and Value Losses for\n  Deep Reinforcement Learning", "comments": "Accepted in Adaptive and Learning Agents (ALA) Workshop at AAMAS", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep Reinforcement Learning (DRL) algorithms are known to be data\ninefficient. One reason is that a DRL agent learns both the feature and the\npolicy tabula rasa. Integrating prior knowledge into DRL algorithms is one way\nto improve learning efficiency since it helps to build helpful representations.\nIn this work, we consider incorporating human knowledge to accelerate the\nasynchronous advantage actor-critic (A3C) algorithm by pre-training a small\namount of non-expert human demonstrations. We leverage the supervised\nautoencoder framework and propose a novel pre-training strategy that jointly\ntrains a weighted supervised classification loss, an unsupervised\nreconstruction loss, and an expected return loss. The resulting pre-trained\nmodel learns more useful features compared to independently training in\nsupervised or unsupervised fashion. Our pre-training method drastically\nimproved the learning performance of the A3C agent in Atari games of Pong and\nMsPacman, exceeding the performance of the state-of-the-art algorithms at a\nmuch smaller number of game interactions. Our method is light-weight and easy\nto implement in a single machine. For reproducibility, our code is available at\ngithub.com/gabrieledcjr/DeepRL/tree/A3C-ALA2019\n", "versions": [{"version": "v1", "created": "Wed, 3 Apr 2019 19:14:15 GMT"}], "update_date": "2019-04-05", "authors_parsed": [["Cruz", "Gabriel V. de la", "Jr."], ["Du", "Yunshu", ""], ["Taylor", "Matthew E.", ""]]}, {"id": "1904.02210", "submitter": "Oliver Adams", "authors": "Oliver Adams, Matthew Wiesner, Shinji Watanabe, David Yarowsky", "title": "Massively Multilingual Adversarial Speech Recognition", "comments": "Accepted at NAACL-HLT 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We report on adaptation of multilingual end-to-end speech recognition models\ntrained on as many as 100 languages. Our findings shed light on the relative\nimportance of similarity between the target and pretraining languages along the\ndimensions of phonetics, phonology, language family, geographical location, and\northography. In this context, experiments demonstrate the effectiveness of two\nadditional pretraining objectives in encouraging language-independent encoder\nrepresentations: a context-independent phoneme objective paired with a\nlanguage-adversarial classification objective.\n", "versions": [{"version": "v1", "created": "Wed, 3 Apr 2019 19:28:53 GMT"}], "update_date": "2019-04-05", "authors_parsed": [["Adams", "Oliver", ""], ["Wiesner", "Matthew", ""], ["Watanabe", "Shinji", ""], ["Yarowsky", "David", ""]]}, {"id": "1904.02214", "submitter": "Brian Coyle", "authors": "Brian Coyle, Daniel Mills, Vincent Danos and Elham Kashefi", "title": "The Born Supremacy: Quantum Advantage and Training of an Ising Born\n  Machine", "comments": "18 pages + supplementary material, 11 figures. Implementation at\n  https://github.com/BrianCoyle/IsingBornMachine v4 : Close to journal\n  published version - significant text structure change, split into main text &\n  appendices. See v2 for unsplit version", "journal-ref": "npj Quantum Inf 6, 60 (2020)", "doi": "10.1038/s41534-020-00288-9", "report-no": null, "categories": "quant-ph cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The search for an application of near-term quantum devices is widespread.\nQuantum Machine Learning is touted as a potential utilisation of such devices,\nparticularly those which are out of the reach of the simulation capabilities of\nclassical computers. In this work, we propose a generative Quantum Machine\nLearning Model, called the Ising Born Machine (IBM), which we show cannot, in\nthe worst case, and up to suitable notions of error, be simulated efficiently\nby a classical device. We also show this holds for all the circuit families\nencountered during training. In particular, we explore quantum circuit learning\nusing non-universal circuits derived from Ising Model Hamiltonians, which are\nimplementable on near term quantum devices.\n  We propose two novel training methods for the IBM by utilising the Stein\nDiscrepancy and the Sinkhorn Divergence cost functions. We show numerically,\nboth using a simulator within Rigetti's Forest platform and on the Aspen-1 16Q\nchip, that the cost functions we suggest outperform the more commonly used\nMaximum Mean Discrepancy (MMD) for differentiable training. We also propose an\nimprovement to the MMD by proposing a novel utilisation of quantum kernels\nwhich we demonstrate provides improvements over its classical counterpart. We\ndiscuss the potential of these methods to learn `hard' quantum distributions, a\nfeat which would demonstrate the advantage of quantum over classical computers,\nand provide the first formal definitions for what we call `Quantum Learning\nSupremacy'. Finally, we propose a novel view on the area of quantum circuit\ncompilation by using the IBM to `mimic' target quantum circuits using classical\noutput data only.\n", "versions": [{"version": "v1", "created": "Wed, 3 Apr 2019 19:35:07 GMT"}, {"version": "v2", "created": "Mon, 12 Aug 2019 08:16:59 GMT"}, {"version": "v3", "created": "Wed, 13 Jan 2021 11:35:58 GMT"}, {"version": "v4", "created": "Tue, 27 Apr 2021 13:10:32 GMT"}], "update_date": "2021-04-28", "authors_parsed": [["Coyle", "Brian", ""], ["Mills", "Daniel", ""], ["Danos", "Vincent", ""], ["Kashefi", "Elham", ""]]}, {"id": "1904.02217", "submitter": "Peter Weiderer", "authors": "Peter Weiderer and Ana Maria Tom\\'e and Elmar Wolfgang Lang", "title": "Decomposing Temperature Time Series with Non-Negative Matrix\n  Factorization", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV physics.app-ph stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  During the fabrication of casting parts sensor data is typically\nautomatically recorded and accumulated for process monitoring and defect\ndiagnosis. As casting is a thermal process with many interacting process\nparameters, root cause analysis tends to be tedious and ineffective. We show\nhow a decomposition based on non-negative matrix factorization (NMF), which is\nguided by a knowledge-based initialization strategy, is able to extract\nphysical meaningful sources from temperature time series collected during a\nthermal manufacturing process. The approach assumes the time series to be\ngenerated by a superposition of several simultaneously acting component\nprocesses. NMF is able to reverse the superposition and to identify the hidden\ncomponent processes. The latter can be linked to ongoing physical phenomena and\nprocess variables, which cannot be monitored directly. Our approach provides\nnew insights into the underlying physics and offers a tool, which can assist in\ndiagnosing defect causes. We demonstrate our method by applying it to real\nworld data, collected in a foundry during the series production of casting\nparts for the automobile industry.\n", "versions": [{"version": "v1", "created": "Wed, 3 Apr 2019 19:46:56 GMT"}], "update_date": "2019-04-05", "authors_parsed": [["Weiderer", "Peter", ""], ["Tom\u00e9", "Ana Maria", ""], ["Lang", "Elmar Wolfgang", ""]]}, {"id": "1904.02239", "submitter": "Valentin Khrulkov", "authors": "Valentin Khrulkov, Leyla Mirvakhabova, Evgeniya Ustinova, Ivan\n  Oseledets, Victor Lempitsky", "title": "Hyperbolic Image Embeddings", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Computer vision tasks such as image classification, image retrieval and\nfew-shot learning are currently dominated by Euclidean and spherical\nembeddings, so that the final decisions about class belongings or the degree of\nsimilarity are made using linear hyperplanes, Euclidean distances, or spherical\ngeodesic distances (cosine similarity). In this work, we demonstrate that in\nmany practical scenarios hyperbolic embeddings provide a better alternative.\n", "versions": [{"version": "v1", "created": "Wed, 3 Apr 2019 21:10:12 GMT"}, {"version": "v2", "created": "Mon, 30 Mar 2020 20:35:39 GMT"}], "update_date": "2020-04-01", "authors_parsed": [["Khrulkov", "Valentin", ""], ["Mirvakhabova", "Leyla", ""], ["Ustinova", "Evgeniya", ""], ["Oseledets", "Ivan", ""], ["Lempitsky", "Victor", ""]]}, {"id": "1904.02243", "submitter": "Emily Storey", "authors": "Emily E Storey, Amr S. Helmy", "title": "Optimized Preprocessing and Machine Learning for Quantitative Raman\n  Spectroscopy in Biology", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.SP cs.LG q-bio.QM stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Raman spectroscopy's capability to provide meaningful composition predictions\nis heavily reliant on a pre-processing step to remove insignificant spectral\nvariation. This is crucial in biofluid analysis. Widespread adoption of\ndiagnostics using Raman requires a robust model which can withstand routine\nspectra discrepancies due to unavoidable variations such as age, diet, and\nmedical background. A wealth of pre-processing methods are available, and it is\noften up to trial-and-error or user experience to select the method which gives\nthe best results. This process can be incredibly time consuming and\ninconsistent for multiple operators.\n  In this study we detail a method to analyze the statistical variability\nwithin a set of training spectra and determine suitability to form a robust\nmodel. This allows us to selectively qualify or exclude a pre-processing\nmethod, predetermine robustness, and simultaneously identify the number of\ncomponents which will form the best predictive model. We demonstrate the\nability of this technique to improve predictive models of two artificial\nbiological fluids.\n  Raman spectroscopy is ideal for noninvasive, nondestructive analysis. Routine\nhealth monitoring which maximizes comfort is increasingly crucial, particularly\nin epidemic-level diabetes diagnoses. High variability in spectra of biological\nsamples can hinder Raman's adoption for these methods. Our technique allows the\ndecision of optimal pre-treatment method to be determined for the operator;\nmodel performance is no longer a function of user experience. We foresee this\nstatistical technique being an instrumental element to widening the adoption of\nRaman as a monitoring tool in a field of biofluid analysis.\n", "versions": [{"version": "v1", "created": "Wed, 3 Apr 2019 21:24:38 GMT"}], "update_date": "2019-04-05", "authors_parsed": [["Storey", "Emily E", ""], ["Helmy", "Amr S.", ""]]}, {"id": "1904.02254", "submitter": "Jesper S\\\"oren Dramsch", "authors": "Jesper S\\\"oren Dramsch, Gustavo Corte, Hamed Amini, Colin MacBeth,\n  Mikael L\\\"uthje", "title": "Including Physics in Deep Learning -- An example from 4D seismic\n  pressure saturation inversion", "comments": "5 pages, 5 figures, workshop, extended abstract, EAGE 2019 Workshop\n  Programme, European Association of Geoscientists and Engineers", "journal-ref": null, "doi": "10.3997/2214-4609.201901967", "report-no": null, "categories": "physics.geo-ph cs.LG physics.data-an", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Geoscience data often have to rely on strong priors in the face of\nuncertainty. Additionally, we often try to detect or model anomalous sparse\ndata that can appear as an outlier in machine learning models. These are\nclassic examples of imbalanced learning. Approaching these problems can benefit\nfrom including prior information from physics models or transforming data to a\nbeneficial domain. We show an example of including physical information in the\narchitecture of a neural network as prior information. We go on to present\nnoise injection at training time to successfully transfer the network from\nsynthetic data to field data.\n", "versions": [{"version": "v1", "created": "Wed, 3 Apr 2019 22:14:08 GMT"}], "update_date": "2019-07-05", "authors_parsed": [["Dramsch", "Jesper S\u00f6ren", ""], ["Corte", "Gustavo", ""], ["Amini", "Hamed", ""], ["MacBeth", "Colin", ""], ["L\u00fcthje", "Mikael", ""]]}, {"id": "1904.02266", "submitter": "Maani Ghaffari Jadidi", "authors": "Maani Ghaffari, William Clark, Anthony Bloch, Ryan M. Eustice, Jessy\n  W. Grizzle", "title": "Continuous Direct Sparse Visual Odometry from RGB-D Images", "comments": "9 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.AI cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper reports on a novel formulation and evaluation of visual odometry\nfrom RGB-D images. Assuming a static scene, the developed theoretical framework\ngeneralizes the widely used direct energy formulation (photometric error\nminimization) technique for obtaining a rigid body transformation that aligns\ntwo overlapping RGB-D images to a continuous formulation. The continuity is\nachieved through functional treatment of the problem and representing the\nprocess models over RGB-D images in a reproducing kernel Hilbert space;\nconsequently, the registration is not limited to the specific image resolution\nand the framework is fully analytical with a closed-form derivation of the\ngradient. We solve the problem by maximizing the inner product between two\nfunctions defined over RGB-D images, while the continuous action of the rigid\nbody motion Lie group is captured through the integration of the flow in the\ncorresponding Lie algebra. Energy-based approaches have been extremely\nsuccessful and the developed framework in this paper shares many of their\ndesired properties such as the parallel structure on both CPUs and GPUs,\nsparsity, semi-dense tracking, avoiding explicit data association which is\ncomputationally expensive, and possible extensions to the simultaneous\nlocalization and mapping frameworks. The evaluations on experimental data and\ncomparison with the equivalent energy-based formulation of the problem confirm\nthe effectiveness of the proposed technique, especially, when the lack of\nstructure and texture in the environment is evident.\n", "versions": [{"version": "v1", "created": "Wed, 3 Apr 2019 23:25:01 GMT"}, {"version": "v2", "created": "Tue, 21 May 2019 03:08:07 GMT"}, {"version": "v3", "created": "Fri, 23 Aug 2019 23:21:18 GMT"}], "update_date": "2019-08-27", "authors_parsed": [["Ghaffari", "Maani", ""], ["Clark", "William", ""], ["Bloch", "Anthony", ""], ["Eustice", "Ryan M.", ""], ["Grizzle", "Jessy W.", ""]]}, {"id": "1904.02276", "submitter": "Tongyang Li", "authors": "Tongyang Li, Shouvanik Chakrabarti, Xiaodi Wu", "title": "Sublinear quantum algorithms for training linear and kernel-based\n  classifiers", "comments": "31 pages, 1 figure", "journal-ref": "Proceedings of the 36th International Conference on Machine\n  Learning (ICML 2019), PMLR 97:3815-3824, 2019", "doi": null, "report-no": null, "categories": "quant-ph cs.DS cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We investigate quantum algorithms for classification, a fundamental problem\nin machine learning, with provable guarantees. Given $n$ $d$-dimensional data\npoints, the state-of-the-art (and optimal) classical algorithm for training\nclassifiers with constant margin runs in $\\tilde{O}(n+d)$ time. We design\nsublinear quantum algorithms for the same task running in $\\tilde{O}(\\sqrt{n}\n+\\sqrt{d})$ time, a quadratic improvement in both $n$ and $d$. Moreover, our\nalgorithms use the standard quantization of the classical input and generate\nthe same classical output, suggesting minimal overheads when used as\nsubroutines for end-to-end applications. We also demonstrate a tight lower\nbound (up to poly-log factors) and discuss the possibility of implementation on\nnear-term quantum machines. As a side result, we also give sublinear quantum\nalgorithms for approximating the equilibria of $n$-dimensional matrix zero-sum\ngames with optimal complexity $\\tilde{\\Theta}(\\sqrt{n})$.\n", "versions": [{"version": "v1", "created": "Thu, 4 Apr 2019 00:00:59 GMT"}], "update_date": "2019-05-28", "authors_parsed": [["Li", "Tongyang", ""], ["Chakrabarti", "Shouvanik", ""], ["Wu", "Xiaodi", ""]]}, {"id": "1904.02278", "submitter": "Fengwen Chen", "authors": "Fengwen Chen, Shirui Pan, Jing Jiang, Huan Huo, Guodong Long", "title": "DAGCN: Dual Attention Graph Convolutional Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Graph convolutional networks (GCNs) have recently become one of the most\npowerful tools for graph analytics tasks in numerous applications, ranging from\nsocial networks and natural language processing to bioinformatics and\nchemoinformatics, thanks to their ability to capture the complex relationships\nbetween concepts. At present, the vast majority of GCNs use a neighborhood\naggregation framework to learn a continuous and compact vector, then performing\na pooling operation to generalize graph embedding for the classification task.\nThese approaches have two disadvantages in the graph classification task:\n(1)when only the largest sub-graph structure ($k$-hop neighbor) is used for\nneighborhood aggregation, a large amount of early-stage information is lost\nduring the graph convolution step; (2) simple average/sum pooling or max\npooling utilized, which loses the characteristics of each node and the topology\nbetween nodes. In this paper, we propose a novel framework called, dual\nattention graph convolutional networks (DAGCN) to address these problems. DAGCN\nautomatically learns the importance of neighbors at different hops using a\nnovel attention graph convolution layer, and then employs a second attention\ncomponent, a self-attention pooling layer, to generalize the graph\nrepresentation from the various aspects of a matrix graph embedding. The dual\nattention network is trained in an end-to-end manner for the graph\nclassification task. We compare our model with state-of-the-art graph kernels\nand other deep learning methods. The experimental results show that our\nframework not only outperforms other baselines but also achieves a better rate\nof convergence.\n", "versions": [{"version": "v1", "created": "Thu, 4 Apr 2019 00:04:57 GMT"}], "update_date": "2019-04-05", "authors_parsed": [["Chen", "Fengwen", ""], ["Pan", "Shirui", ""], ["Jiang", "Jing", ""], ["Huo", "Huan", ""], ["Long", "Guodong", ""]]}, {"id": "1904.02293", "submitter": "Akshay Budhkar", "authors": "Akshay Budhkar, Krishnapriya Vishnubhotla, Safwan Hossain, Frank\n  Rudzicz", "title": "Generative Adversarial Networks for text using word2vec intermediaries", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Generative adversarial networks (GANs) have shown considerable success,\nespecially in the realistic generation of images. In this work, we apply\nsimilar techniques for the generation of text. We propose a novel approach to\nhandle the discrete nature of text, during training, using word embeddings. Our\nmethod is agnostic to vocabulary size and achieves competitive results relative\nto methods with various discrete gradient estimators.\n", "versions": [{"version": "v1", "created": "Thu, 4 Apr 2019 01:17:29 GMT"}], "update_date": "2019-04-05", "authors_parsed": [["Budhkar", "Akshay", ""], ["Vishnubhotla", "Krishnapriya", ""], ["Hossain", "Safwan", ""], ["Rudzicz", "Frank", ""]]}, {"id": "1904.02301", "submitter": "Dacheng Tao", "authors": "Meng Liu, Chang Xu, Yong Luo, Chao Xu, Yonggang Wen and Dacheng Tao", "title": "Cost-Sensitive Feature Selection by Optimizing F-Measures", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Feature selection is beneficial for improving the performance of general\nmachine learning tasks by extracting an informative subset from the\nhigh-dimensional features. Conventional feature selection methods usually\nignore the class imbalance problem, thus the selected features will be biased\ntowards the majority class. Considering that F-measure is a more reasonable\nperformance measure than accuracy for imbalanced data, this paper presents an\neffective feature selection algorithm that explores the class imbalance issue\nby optimizing F-measures. Since F-measure optimization can be decomposed into a\nseries of cost-sensitive classification problems, we investigate the\ncost-sensitive feature selection by generating and assigning different costs to\neach class with rigorous theory guidance. After solving a series of\ncost-sensitive feature selection problems, features corresponding to the best\nF-measure will be selected. In this way, the selected features will fully\nrepresent the properties of all classes. Experimental results on popular\nbenchmarks and challenging real-world data sets demonstrate the significance of\ncost-sensitive feature selection for the imbalanced data setting and validate\nthe effectiveness of the proposed method.\n", "versions": [{"version": "v1", "created": "Thu, 4 Apr 2019 01:36:04 GMT"}], "update_date": "2019-04-05", "authors_parsed": [["Liu", "Meng", ""], ["Xu", "Chang", ""], ["Luo", "Yong", ""], ["Xu", "Chao", ""], ["Wen", "Yonggang", ""], ["Tao", "Dacheng", ""]]}, {"id": "1904.02303", "submitter": "Jeremias Knoblauch", "authors": "Jeremias Knoblauch", "title": "Robust Deep Gaussian Processes", "comments": "11 pages, 4 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This report provides an in-depth overview over the implications and novelty\nGeneralized Variational Inference (GVI) (Knoblauch et al., 2019) brings to Deep\nGaussian Processes (DGPs) (Damianou & Lawrence, 2013). Specifically, robustness\nto model misspecification as well as principled alternatives for uncertainty\nquantification are motivated with an information-geometric view. These\nmodifications have clear interpretations and can be implemented in less than\n100 lines of Python code. Most importantly, the corresponding empirical results\nshow that DGPs can greatly benefit from the presented enhancements.\n", "versions": [{"version": "v1", "created": "Thu, 4 Apr 2019 01:37:54 GMT"}, {"version": "v2", "created": "Tue, 21 May 2019 02:05:44 GMT"}], "update_date": "2019-05-22", "authors_parsed": [["Knoblauch", "Jeremias", ""]]}, {"id": "1904.02309", "submitter": "Roozbeh Farhoodi", "authors": "Roozbeh Farhoodi, Khashayar Filom, Ilenna Simone Jones, Konrad Paul\n  Kording", "title": "On functions computed on trees", "comments": "52 pages, 10 figures. The final version. To appear in Neural\n  Computation. May vary slightly from published version", "journal-ref": "Neural Computation 31 (2019), no. 11, 2075--2137", "doi": "10.1162/neco_a_01231", "report-no": null, "categories": "cs.LG math.CO q-bio.NC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Any function can be constructed using a hierarchy of simpler functions\nthrough compositions. Such a hierarchy can be characterized by a binary rooted\ntree. Each node of this tree is associated with a function which takes as\ninputs two numbers from its children and produces one output. Since thinking\nabout functions in terms of computation graphs is getting popular we may want\nto know which functions can be implemented on a given tree. Here, we describe a\nset of necessary constraints in the form of a system of non-linear partial\ndifferential equations that must be satisfied. Moreover, we prove that these\nconditions are sufficient in both contexts of analytic and bit-valued\nfunctions. In the latter case, we explicitly enumerate discrete functions and\nobserve that there are relatively few. Our point of view allows us to compare\ndifferent neural network architectures in regard to their function spaces. Our\nwork connects the structure of computation graphs with the functions they can\nimplement and has potential applications to neuroscience and computer science.\n", "versions": [{"version": "v1", "created": "Thu, 4 Apr 2019 02:15:35 GMT"}, {"version": "v2", "created": "Mon, 29 Jul 2019 00:59:32 GMT"}, {"version": "v3", "created": "Tue, 30 Jul 2019 17:57:50 GMT"}, {"version": "v4", "created": "Tue, 22 Oct 2019 17:47:17 GMT"}], "update_date": "2019-10-23", "authors_parsed": [["Farhoodi", "Roozbeh", ""], ["Filom", "Khashayar", ""], ["Jones", "Ilenna Simone", ""], ["Kording", "Konrad Paul", ""]]}, {"id": "1904.02311", "submitter": "Jonathan Siegel", "authors": "Jonathan W. Siegel, Jinchao Xu", "title": "Approximation Rates for Neural Networks with General Activation\n  Functions", "comments": null, "journal-ref": "Neural Networks (2020)", "doi": null, "report-no": null, "categories": "math.CA cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We prove some new results concerning the approximation rate of neural\nnetworks with general activation functions. Our first result concerns the rate\nof approximation of a two layer neural network with a polynomially-decaying\nnon-sigmoidal activation function. We extend the dimension independent\napproximation rates previously obtained to this new class of activation\nfunctions. Our second result gives a weaker, but still dimension independent,\napproximation rate for a larger class of activation functions, removing the\npolynomial decay assumption. This result applies to any bounded, integrable\nactivation function. Finally, we show that a stratified sampling approach can\nbe used to improve the approximation rate for polynomially decaying activation\nfunctions under mild additional assumptions.\n", "versions": [{"version": "v1", "created": "Thu, 4 Apr 2019 02:18:08 GMT"}, {"version": "v2", "created": "Sat, 12 Oct 2019 02:16:53 GMT"}, {"version": "v3", "created": "Mon, 24 Feb 2020 16:26:19 GMT"}, {"version": "v4", "created": "Fri, 8 May 2020 23:11:03 GMT"}, {"version": "v5", "created": "Fri, 22 May 2020 20:33:00 GMT"}, {"version": "v6", "created": "Sun, 1 Nov 2020 15:41:47 GMT"}, {"version": "v7", "created": "Sun, 3 Jan 2021 16:33:36 GMT"}], "update_date": "2021-01-05", "authors_parsed": [["Siegel", "Jonathan W.", ""], ["Xu", "Jinchao", ""]]}, {"id": "1904.02319", "submitter": "Rogerio Bonatti", "authors": "Rogerio Bonatti, Cherie Ho, Wenshan Wang, Sanjiban Choudhury,\n  Sebastian Scherer", "title": "Towards a Robust Aerial Cinematography Platform: Localizing and Tracking\n  Moving Targets in Unstructured Environments", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The use of drones for aerial cinematography has revolutionized several\napplications and industries that require live and dynamic camera viewpoints\nsuch as entertainment, sports, and security. However, safely controlling a\ndrone while filming a moving target usually requires multiple expert human\noperators; hence the need for an autonomous cinematographer. Current approaches\nhave severe real-life limitations such as requiring fully scripted scenes,\nhigh-precision motion-capture systems or GPS tags to localize targets, and\nprior maps of the environment to avoid obstacles and plan for occlusion.\n  In this work, we overcome such limitations and propose a complete system for\naerial cinematography that combines: (1) a vision-based algorithm for target\nlocalization; (2) a real-time incremental 3D signed-distance map algorithm for\nocclusion and safety computation; and (3) a real-time camera motion planner\nthat optimizes smoothness, collisions, occlusions and artistic guidelines. We\nevaluate robustness and real-time performance in series of field experiments\nand simulations by tracking dynamic targets moving through unknown,\nunstructured environments. Finally, we verify that despite removing previous\nlimitations, our system achieves state-of-the-art performance. Videos of the\nsystem in action can be seen at https://youtu.be/ZE9MnCVmumc\n", "versions": [{"version": "v1", "created": "Thu, 4 Apr 2019 02:37:05 GMT"}, {"version": "v2", "created": "Mon, 29 Jul 2019 03:29:55 GMT"}], "update_date": "2019-07-30", "authors_parsed": [["Bonatti", "Rogerio", ""], ["Ho", "Cherie", ""], ["Wang", "Wenshan", ""], ["Choudhury", "Sanjiban", ""], ["Scherer", "Sebastian", ""]]}, {"id": "1904.02323", "submitter": "Fred Hohman", "authors": "Fred Hohman, Haekyu Park, Caleb Robinson, Duen Horng Chau", "title": "Summit: Scaling Deep Learning Interpretability by Visualizing Activation\n  and Attribution Summarizations", "comments": "Published in IEEE Transactions on Visualization and Computer Graphics\n  2020, and presented at IEEE VAST 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.HC cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep learning is increasingly used in decision-making tasks. However,\nunderstanding how neural networks produce final predictions remains a\nfundamental challenge. Existing work on interpreting neural network predictions\nfor images often focuses on explaining predictions for single images or\nneurons. As predictions are often computed from millions of weights that are\noptimized over millions of images, such explanations can easily miss a bigger\npicture. We present Summit, an interactive system that scalably and\nsystematically summarizes and visualizes what features a deep learning model\nhas learned and how those features interact to make predictions. Summit\nintroduces two new scalable summarization techniques: (1) activation\naggregation discovers important neurons, and (2) neuron-influence aggregation\nidentifies relationships among such neurons. Summit combines these techniques\nto create the novel attribution graph that reveals and summarizes crucial\nneuron associations and substructures that contribute to a model's outcomes.\nSummit scales to large data, such as the ImageNet dataset with 1.2M images, and\nleverages neural network feature visualization and dataset examples to help\nusers distill large, complex neural network models into compact, interactive\nvisualizations. We present neural network exploration scenarios where Summit\nhelps us discover multiple surprising insights into a prevalent, large-scale\nimage classifier's learned representations and informs future neural network\narchitecture design. The Summit visualization runs in modern web browsers and\nis open-sourced.\n", "versions": [{"version": "v1", "created": "Thu, 4 Apr 2019 03:00:40 GMT"}, {"version": "v2", "created": "Tue, 9 Apr 2019 14:42:39 GMT"}, {"version": "v3", "created": "Mon, 2 Sep 2019 19:42:14 GMT"}], "update_date": "2019-09-04", "authors_parsed": [["Hohman", "Fred", ""], ["Park", "Haekyu", ""], ["Robinson", "Caleb", ""], ["Chau", "Duen Horng", ""]]}, {"id": "1904.02338", "submitter": "Maruan Al-Shedivat", "authors": "Maruan Al-Shedivat and Ankur P. Parikh", "title": "Consistency by Agreement in Zero-shot Neural Machine Translation", "comments": "NAACL 2019 (14 pages, 5 figures)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CL cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Generalization and reliability of multilingual translation often highly\ndepend on the amount of available parallel data for each language pair of\ninterest. In this paper, we focus on zero-shot generalization---a challenging\nsetup that tests models on translation directions they have not been optimized\nfor at training time. To solve the problem, we (i) reformulate multilingual\ntranslation as probabilistic inference, (ii) define the notion of zero-shot\nconsistency and show why standard training often results in models unsuitable\nfor zero-shot tasks, and (iii) introduce a consistent agreement-based training\nmethod that encourages the model to produce equivalent translations of parallel\nsentences in auxiliary languages. We test our multilingual NMT models on\nmultiple public zero-shot translation benchmarks (IWSLT17, UN corpus, Europarl)\nand show that agreement-based learning often results in 2-3 BLEU zero-shot\nimprovement over strong baselines without any loss in performance on supervised\ntranslation directions.\n", "versions": [{"version": "v1", "created": "Thu, 4 Apr 2019 03:49:05 GMT"}, {"version": "v2", "created": "Wed, 10 Apr 2019 04:00:03 GMT"}], "update_date": "2019-04-11", "authors_parsed": [["Al-Shedivat", "Maruan", ""], ["Parikh", "Ankur P.", ""]]}, {"id": "1904.02343", "submitter": "Chunting Zhou", "authors": "Chunting Zhou, Xuezhe Ma, Di Wang, Graham Neubig", "title": "Density Matching for Bilingual Word Embedding", "comments": "Accepted by NAACL-HLT 2019", "journal-ref": "NAACL 2019", "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent approaches to cross-lingual word embedding have generally been based\non linear transformations between the sets of embedding vectors in the two\nlanguages. In this paper, we propose an approach that instead expresses the two\nmonolingual embedding spaces as probability densities defined by a Gaussian\nmixture model, and matches the two densities using a method called normalizing\nflow. The method requires no explicit supervision, and can be learned with only\na seed dictionary of words that have identical strings. We argue that this\nformulation has several intuitively attractive properties, particularly with\nthe respect to improving robustness and generalization to mappings between\ndifficult language pairs or word pairs. On a benchmark data set of bilingual\nlexicon induction and cross-lingual word similarity, our approach can achieve\ncompetitive or superior performance compared to state-of-the-art published\nresults, with particularly strong results being found on etymologically distant\nand/or morphologically rich languages.\n", "versions": [{"version": "v1", "created": "Thu, 4 Apr 2019 04:36:11 GMT"}, {"version": "v2", "created": "Sat, 13 Apr 2019 03:47:04 GMT"}, {"version": "v3", "created": "Tue, 30 Apr 2019 21:08:13 GMT"}], "update_date": "2019-10-08", "authors_parsed": [["Zhou", "Chunting", ""], ["Ma", "Xuezhe", ""], ["Wang", "Di", ""], ["Neubig", "Graham", ""]]}, {"id": "1904.02345", "submitter": "Ayman Elgharabawy", "authors": "Ayman Elgharabawy", "title": "Preference Neural Network", "comments": "The current content is inappropriate and requires to be\n  comprehensively reviewed again", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper proposes a preference neural network (PNN) to address the problem\nof indifference preferences orders with new activation function. PNN also\nsolves the Multi-label ranking problem, where labels may have indifference\npreference orders or subgroups are equally ranked. PNN follows a multi-layer\nfeedforward architecture with fully connected neurons. Each neuron contains a\nnovel smooth stairstep activation function based on the number of preference\norders. PNN inputs represent data features and output neurons represent label\nindexes. The proposed PNN is evaluated using new preference mining dataset that\ncontains repeated label values which have not experimented before. PNN\noutperforms five previously proposed methods for strict label ranking in terms\nof accurate results with high computational efficiency.\n", "versions": [{"version": "v1", "created": "Thu, 4 Apr 2019 04:47:02 GMT"}, {"version": "v2", "created": "Tue, 9 Jun 2020 03:13:53 GMT"}], "update_date": "2020-06-11", "authors_parsed": [["Elgharabawy", "Ayman", ""]]}, {"id": "1904.02361", "submitter": "Mehran Khodabandeh", "authors": "Mehran Khodabandeh, Arash Vahdat, Mani Ranjbar, William G. Macready", "title": "A Robust Learning Approach to Domain Adaptive Object Detection", "comments": "Accepted to ICCV 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Domain shift is unavoidable in real-world applications of object detection.\nFor example, in self-driving cars, the target domain consists of unconstrained\nroad environments which cannot all possibly be observed in training data.\nSimilarly, in surveillance applications sufficiently representative training\ndata may be lacking due to privacy regulations. In this paper, we address the\ndomain adaptation problem from the perspective of robust learning and show that\nthe problem may be formulated as training with noisy labels. We propose a\nrobust object detection framework that is resilient to noise in bounding box\nclass labels, locations and size annotations. To adapt to the domain shift, the\nmodel is trained on the target domain using a set of noisy object bounding\nboxes that are obtained by a detection model trained only in the source domain.\nWe evaluate the accuracy of our approach in various source/target domain pairs\nand demonstrate that the model significantly improves the state-of-the-art on\nmultiple domain adaptation scenarios on the SIM10K, Cityscapes and KITTI\ndatasets.\n", "versions": [{"version": "v1", "created": "Thu, 4 Apr 2019 05:50:10 GMT"}, {"version": "v2", "created": "Sun, 11 Aug 2019 05:24:59 GMT"}, {"version": "v3", "created": "Mon, 18 Nov 2019 05:43:00 GMT"}], "update_date": "2019-11-19", "authors_parsed": [["Khodabandeh", "Mehran", ""], ["Vahdat", "Arash", ""], ["Ranjbar", "Mani", ""], ["Macready", "William G.", ""]]}, {"id": "1904.02383", "submitter": "Chanshin Park", "authors": "Chanshin Park, Daniel K. Tettey, and Han-Shin Jo", "title": "Artificial Neural Network Modeling for Path Loss Prediction in Urban\n  Environments", "comments": "5 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Although various linear log-distance path loss models have been developed,\nadvanced models are requiring to more accurately and flexibly represent the\npath loss for complex environments such as the urban area. This letter proposes\nan artificial neural network (ANN) based multi-dimensional regression framework\nfor path loss modeling in urban environments at 3 to 6 GHz frequency band. ANN\nis used to learn the path loss structure from the measured path loss data which\nis a function of distance and frequency. The effect of the network architecture\nparameter (activation function, the number of hidden layers and nodes) on the\nprediction accuracy are analyzed. We observe that the proposed model is more\naccurate and flexible compared to the conventional linear model.\n", "versions": [{"version": "v1", "created": "Thu, 4 Apr 2019 07:16:28 GMT"}], "update_date": "2019-04-05", "authors_parsed": [["Park", "Chanshin", ""], ["Tettey", "Daniel K.", ""], ["Jo", "Han-Shin", ""]]}, {"id": "1904.02390", "submitter": "Jiachen Li", "authors": "Jiachen Li and Hengbo Ma and Masayoshi Tomizuka", "title": "Interaction-aware Multi-agent Tracking and Probabilistic Behavior\n  Prediction via Adversarial Learning", "comments": "Accepted by 2019 International Conference on Robotics and Automation\n  (ICRA)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In order to enable high-quality decision making and motion planning of\nintelligent systems such as robotics and autonomous vehicles, accurate\nprobabilistic predictions for surrounding interactive objects is a crucial\nprerequisite. Although many research studies have been devoted to making\npredictions on a single entity, it remains an open challenge to forecast future\nbehaviors for multiple interactive agents simultaneously. In this work, we take\nadvantage of the Generative Adversarial Network (GAN) due to its capability of\ndistribution learning and propose a generic multi-agent probabilistic\nprediction and tracking framework which takes the interactions among multiple\nentities into account, in which all the entities are treated as a whole.\nHowever, since GAN is very hard to train, we make an empirical research and\npresent the relationship between training performance and hyperparameter values\nwith a numerical case study. The results imply that the proposed model can\ncapture both the mean, variance and multi-modalities of the groundtruth\ndistribution. Moreover, we apply the proposed approach to a real-world task of\nvehicle behavior prediction to demonstrate its effectiveness and accuracy. The\nresults illustrate that the proposed model trained by adversarial learning can\nachieve a better prediction performance than other state-of-the-art models\ntrained by traditional supervised learning which maximizes the data likelihood.\nThe well-trained model can also be utilized as an implicit proposal\ndistribution for particle filtered based Bayesian state estimation.\n", "versions": [{"version": "v1", "created": "Thu, 4 Apr 2019 07:41:07 GMT"}], "update_date": "2019-04-05", "authors_parsed": [["Li", "Jiachen", ""], ["Ma", "Hengbo", ""], ["Tomizuka", "Masayoshi", ""]]}, {"id": "1904.02399", "submitter": "Prince Zizhuang Wang", "authors": "Prince Zizhuang Wang, William Yang Wang", "title": "Riemannian Normalizing Flow on Variational Wasserstein Autoencoder for\n  Text Modeling", "comments": "NAACL 2019 (oral)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recurrent Variational Autoencoder has been widely used for language modeling\nand text generation tasks. These models often face a difficult optimization\nproblem, also known as the Kullback-Leibler (KL) term vanishing issue, where\nthe posterior easily collapses to the prior, and the model will ignore latent\ncodes in generative tasks. To address this problem, we introduce an improved\nWasserstein Variational Autoencoder (WAE) with Riemannian Normalizing Flow\n(RNF) for text modeling. The RNF transforms a latent variable into a space that\nrespects the geometric characteristics of input space, which makes posterior\nimpossible to collapse to the non-informative prior. The Wasserstein objective\nminimizes the distance between the marginal distribution and the prior directly\nand therefore does not force the posterior to match the prior. Empirical\nexperiments show that our model avoids KL vanishing over a range of datasets\nand has better performances in tasks such as language modeling, likelihood\napproximation, and text generation. Through a series of experiments and\nanalysis over latent space, we show that our model learns latent distributions\nthat respect latent space geometry and is able to generate sentences that are\nmore diverse.\n", "versions": [{"version": "v1", "created": "Thu, 4 Apr 2019 08:13:42 GMT"}, {"version": "v2", "created": "Sun, 7 Apr 2019 00:36:11 GMT"}, {"version": "v3", "created": "Mon, 15 Apr 2019 03:06:29 GMT"}, {"version": "v4", "created": "Mon, 22 Apr 2019 21:19:28 GMT"}], "update_date": "2019-04-24", "authors_parsed": [["Wang", "Prince Zizhuang", ""], ["Wang", "William Yang", ""]]}, {"id": "1904.02405", "submitter": "Yoav Chai", "authors": "Yotam Gil, Yoav Chai, Or Gorodissky and Jonathan Berant", "title": "White-to-Black: Efficient Distillation of Black-Box Adversarial Attacks", "comments": "Accepted to NAACL-HLT 2019 as conference paper", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Adversarial examples are important for understanding the behavior of neural\nmodels, and can improve their robustness through adversarial training. Recent\nwork in natural language processing generated adversarial examples by assuming\nwhite-box access to the attacked model, and optimizing the input directly\nagainst it (Ebrahimi et al., 2018). In this work, we show that the knowledge\nimplicit in the optimization procedure can be distilled into another more\nefficient neural network. We train a model to emulate the behavior of a\nwhite-box attack and show that it generalizes well across examples. Moreover,\nit reduces adversarial example generation time by 19x-39x. We also show that\nour approach transfers to a black-box setting, by attacking The Google\nPerspective API and exposing its vulnerability. Our attack flips the\nAPI-predicted label in 42\\% of the generated examples, while humans maintain\nhigh-accuracy in predicting the gold label.\n", "versions": [{"version": "v1", "created": "Thu, 4 Apr 2019 08:31:15 GMT"}], "update_date": "2019-04-05", "authors_parsed": [["Gil", "Yotam", ""], ["Chai", "Yoav", ""], ["Gorodissky", "Or", ""], ["Berant", "Jonathan", ""]]}, {"id": "1904.02420", "submitter": "Quentin Jodelet", "authors": "Quentin Jodelet, Vincent Gripon and Masafumi Hagiwara", "title": "Transfer Learning with Sparse Associative Memories", "comments": "Presented at the 28th International Conference on Artificial Neural\n  Networks (ICANN 2019)", "journal-ref": "Artificial Neural Networks and Machine Learning - ICANN 2019:\n  Theoretical Neural Computation. ICANN 2019. Lecture Notes in Computer\n  Science, vol 11727. Springer, Cham", "doi": "10.1007/978-3-030-30487-4_39", "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we introduce a novel layer designed to be used as the output\nof pre-trained neural networks in the context of classification. Based on\nAssociative Memories, this layer can help design Deep Neural Networks which\nsupport incremental learning and that can be (partially) trained in real time\non embedded devices. Experiments on the ImageNet dataset and other different\ndomain specific datasets show that it is possible to design more flexible and\nfaster-to-train Neural Networks at the cost of a slight decrease in accuracy.\n", "versions": [{"version": "v1", "created": "Thu, 4 Apr 2019 09:16:30 GMT"}, {"version": "v2", "created": "Sun, 30 Jun 2019 14:20:08 GMT"}, {"version": "v3", "created": "Thu, 19 Sep 2019 12:30:09 GMT"}], "update_date": "2019-09-20", "authors_parsed": [["Jodelet", "Quentin", ""], ["Gripon", "Vincent", ""], ["Hagiwara", "Masafumi", ""]]}, {"id": "1904.02426", "submitter": "Hongyu Chen", "authors": "Hongyu Chen, Li Jiang", "title": "Efficient GAN-based method for cyber-intrusion detection", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Ubiquitous anomalies endanger the security of our system constantly. They may\nbring irreversible damages to the system and cause leakage of privacy. Thus, it\nis of vital importance to promptly detect these anomalies. Traditional\nsupervised methods such as Decision Trees and Support Vector Machine (SVM) are\nused to classify normality and abnormality. However, in some case the abnormal\nstatus are largely rarer than normal status, which leads to decision bias of\nthese methods. Generative adversarial network (GAN) has been proposed to handle\nthe case. With its strong generative ability, it only needs to learn the\ndistribution of normal status, and identify the abnormal status through the gap\nbetween it and the learned distribution. Nevertheless, existing GAN-based\nmodels are not suitable to process data with discrete values, leading to\nimmense degradation of detection performance. To cope with the discrete\nfeatures, in this paper, we propose an efficient GAN-based model with\nspecifically-designed loss function. Experiment results show that our model\noutperforms state-of-the-art models on discrete dataset and remarkably reduce\nthe overhead.\n", "versions": [{"version": "v1", "created": "Thu, 4 Apr 2019 09:30:40 GMT"}, {"version": "v2", "created": "Wed, 24 Jul 2019 11:10:18 GMT"}], "update_date": "2019-07-25", "authors_parsed": [["Chen", "Hongyu", ""], ["Jiang", "Li", ""]]}, {"id": "1904.02435", "submitter": "Kai Olav Ellefsen", "authors": "Kai Olav Ellefsen and Jim Torresen", "title": "Self-Adapting Goals Allow Transfer of Predictive Models to New Tasks", "comments": "Accepted for publication in the proceedings of the 2019 Symposium of\n  the Norwegian AI Society", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A long-standing challenge in Reinforcement Learning is enabling agents to\nlearn a model of their environment which can be transferred to solve other\nproblems in a world with the same underlying rules. One reason this is\ndifficult is the challenge of learning accurate models of an environment. If\nsuch a model is inaccurate, the agent's plans and actions will likely be\nsub-optimal, and likely lead to the wrong outcomes. Recent progress in\nmodel-based reinforcement learning has improved the ability for agents to learn\nand use predictive models. In this paper, we extend a recent deep learning\narchitecture which learns a predictive model of the environment that aims to\npredict only the value of a few key measurements, which are be indicative of an\nagent's performance. Predicting only a few measurements rather than the entire\nfuture state of an environment makes it more feasible to learn a valuable\npredictive model. We extend this predictive model with a small, evolving neural\nnetwork that suggests the best goals to pursue in the current state. We\ndemonstrate that this allows the predictive model to transfer to new scenarios\nwhere goals are different, and that the adaptive goals can even adjust agent\nbehavior on-line, changing its strategy to fit the current context.\n", "versions": [{"version": "v1", "created": "Thu, 4 Apr 2019 09:52:18 GMT"}, {"version": "v2", "created": "Wed, 15 May 2019 11:36:20 GMT"}], "update_date": "2019-05-16", "authors_parsed": [["Ellefsen", "Kai Olav", ""], ["Torresen", "Jim", ""]]}, {"id": "1904.02436", "submitter": "Richard McKinley", "authors": "Richard McKinley, Michael Rebsamen, Raphael Meier, Mauricio Reyes,\n  Christian Rummel, Roland Wiest", "title": "Few-shot brain segmentation from weakly labeled data with deep\n  heteroscedastic multi-task networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG eess.IV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In applications of supervised learning applied to medical image segmentation,\nthe need for large amounts of labeled data typically goes unquestioned. In\nparticular, in the case of brain anatomy segmentation, hundreds or thousands of\nweakly-labeled volumes are often used as training data. In this paper, we first\nobserve that for many brain structures, a small number of training examples,\n(n=9), weakly labeled using Freesurfer 6.0, plus simple data augmentation,\nsuffice as training data to achieve high performance, achieving an overall mean\nDice coefficient of $0.84 \\pm 0.12$ compared to Freesurfer over 28 brain\nstructures in T1-weighted images of $\\approx 4000$ 9-10 year-olds from the\nAdolescent Brain Cognitive Development study. We then examine two varieties of\nheteroscedastic network as a method for improving classification results. An\nexisting proposal by Kendall and Gal, which uses Monte-Carlo inference to learn\nto predict the variance of each prediction, yields an overall mean Dice of\n$0.85 \\pm 0.14$ and showed statistically significant improvements over 25 brain\nstructures. Meanwhile a novel heteroscedastic network which directly learns the\nprobability that an example has been mislabeled yielded an overall mean Dice of\n$0.87 \\pm 0.11$ and showed statistically significant improvements over all but\none of the brain structures considered. The loss function associated to this\nnetwork can be interpreted as performing a form of learned label smoothing,\nwhere labels are only smoothed where they are judged to be uncertain.\n", "versions": [{"version": "v1", "created": "Thu, 4 Apr 2019 09:56:02 GMT"}], "update_date": "2019-04-05", "authors_parsed": [["McKinley", "Richard", ""], ["Rebsamen", "Michael", ""], ["Meier", "Raphael", ""], ["Reyes", "Mauricio", ""], ["Rummel", "Christian", ""], ["Wiest", "Roland", ""]]}, {"id": "1904.02441", "submitter": "Sanjay Sahay", "authors": "Hemant Rathore, Swati Agarwal, Sanjay K. Sahay and Mohit Sewak", "title": "Malware Detection using Machine Learning and Deep Learning", "comments": "11 Pages and 3 Figures", "journal-ref": "Springer, LNCS, Vol. 11297, pp. 402-411, International Conference\n  on Big Data Analytics, 2018", "doi": "10.1007/978-3-030-04780-1_28", "report-no": null, "categories": "cs.CR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Research shows that over the last decade, malware has been growing\nexponentially, causing substantial financial losses to various organizations.\nDifferent anti-malware companies have been proposing solutions to defend\nattacks from these malware. The velocity, volume, and the complexity of malware\nare posing new challenges to the anti-malware community. Current\nstate-of-the-art research shows that recently, researchers and anti-virus\norganizations started applying machine learning and deep learning methods for\nmalware analysis and detection. We have used opcode frequency as a feature\nvector and applied unsupervised learning in addition to supervised learning for\nmalware classification. The focus of this tutorial is to present our work on\ndetecting malware with 1) various machine learning algorithms and 2) deep\nlearning models. Our results show that the Random Forest outperforms Deep\nNeural Network with opcode frequency as a feature. Also in feature reduction,\nDeep Auto-Encoders are overkill for the dataset, and elementary function like\nVariance Threshold perform better than others. In addition to the proposed\nmethodologies, we will also discuss the additional issues and the unique\nchallenges in the domain, open research problems, limitations, and future\ndirections.\n", "versions": [{"version": "v1", "created": "Thu, 4 Apr 2019 10:01:26 GMT"}], "update_date": "2019-04-05", "authors_parsed": [["Rathore", "Hemant", ""], ["Agarwal", "Swati", ""], ["Sahay", "Sanjay K.", ""], ["Sewak", "Mohit", ""]]}, {"id": "1904.02478", "submitter": "Jacopo Castellini", "authors": "Jacopo Castellini", "title": "Learning Numeracy: Binary Arithmetic with Neural Turing Machines", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  One of the main problems encountered so far with recurrent neural networks is\nthat they struggle to retain long-time information dependencies in their\nrecurrent connections. Neural Turing Machines (NTMs) attempt to mitigate this\nissue by providing the neural network with an external portion of memory, in\nwhich information can be stored and manipulated later on. The whole mechanism\nis differentiable end-to-end, allowing the network to learn how to utilise this\nlong-term memory via stochastic gradient descent. This allows NTMs to infer\nsimple algorithms directly from data sequences. Nonetheless, the model can be\nhard to train due to a large number of parameters and interacting components\nand little related work is present. In this work we use NTMs to learn and\ngeneralise two arithmetical tasks: binary addition and multiplication. These\ntasks are two fundamental algorithmic examples in computer science, and are a\nlot more challenging than the previously explored ones, with which we aim to\nshed some light on the real capabilities on this neural model.\n", "versions": [{"version": "v1", "created": "Thu, 4 Apr 2019 11:00:11 GMT"}, {"version": "v2", "created": "Fri, 6 Sep 2019 12:10:29 GMT"}], "update_date": "2019-09-09", "authors_parsed": [["Castellini", "Jacopo", ""]]}, {"id": "1904.02495", "submitter": "Joani Mitro", "authors": "John Mitros and Brian Mac Namee", "title": "A Categorisation of Post-hoc Explanations for Predictive Models", "comments": "5 pages, 3 figures, AAAI 2019 Spring Symposia (#SSS19)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The ubiquity of machine learning based predictive models in modern society\nnaturally leads people to ask how trustworthy those models are? In predictive\nmodeling, it is quite common to induce a trade-off between accuracy and\ninterpretability. For instance, doctors would like to know how effective some\ntreatment will be for a patient or why the model suggested a particular\nmedication for a patient exhibiting those symptoms? We acknowledge that the\nnecessity for interpretability is a consequence of an incomplete formalisation\nof the problem, or more precisely of multiple meanings adhered to a particular\nconcept. For certain problems, it is not enough to get the answer (what), the\nmodel also has to provide an explanation of how it came to that conclusion\n(why), because a correct prediction, only partially solves the original\nproblem. In this article we extend existing categorisation of techniques to aid\nmodel interpretability and test this categorisation.\n", "versions": [{"version": "v1", "created": "Thu, 4 Apr 2019 11:34:05 GMT"}], "update_date": "2019-04-05", "authors_parsed": [["Mitros", "John", ""], ["Mac Namee", "Brian", ""]]}, {"id": "1904.02505", "submitter": "Guillaume Dehaene P.", "authors": "Guillaume P. Dehaene", "title": "A deterministic and computable Bernstein-von Mises theorem", "comments": "The first version contained an incorrect claim in section 5.1 : in\n  general the KL divergence does not bound the difference of the moments", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST cs.LG stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Bernstein-von Mises results (BvM) establish that the Laplace approximation is\nasymptotically correct in the large-data limit. However, these results are\ninappropriate for computational purposes since they only hold over most, and\nnot all, datasets and involve hard-to-estimate constants. In this article, I\npresent a new BvM theorem which bounds the Kullback-Leibler (KL) divergence\nbetween a fixed log-concave density $f\\left(\\boldsymbol{\\theta}\\right)$ and its\nLaplace approximation. The bound goes to $0$ as the higher-derivatives of\n$f\\left(\\boldsymbol{\\theta}\\right)$ tend to $0$ and\n$f\\left(\\boldsymbol{\\theta}\\right)$ becomes increasingly Gaussian. The\nclassical BvM theorem in the IID large-data asymptote is recovered as a\ncorollary.\n  Critically, this theorem further suggests a number of computable\napproximations of the KL divergence with the most promising being: \\[\nKL\\left(g_{LAP},f\\right)\\approx\\frac{1}{2}\\text{Var}_{\\boldsymbol{\\theta}\\sim\ng\\left(\\boldsymbol{\\theta}\\right)}\\left(\\log\\left[f\\left(\\boldsymbol{\\theta}\\right)\\right]-\\log\\left[g_{LAP}\\left(\\boldsymbol{\\theta}\\right)\\right]\\right)\n\\] An empirical investigation of these bounds in the logistic classification\nmodel reveals that these approximations are great surrogates for the KL\ndivergence. This result, and future results of a similar nature, could provide\na path towards rigorously controlling the error due to the Laplace\napproximation and more modern approximation methods.\n", "versions": [{"version": "v1", "created": "Thu, 4 Apr 2019 12:06:34 GMT"}, {"version": "v2", "created": "Tue, 30 Apr 2019 12:56:40 GMT"}], "update_date": "2019-05-01", "authors_parsed": [["Dehaene", "Guillaume P.", ""]]}, {"id": "1904.02514", "submitter": "Tom Vander Aa", "authors": "Tom Vander Aa, Imen Chakroun, Thomas J. Ashby, Jaak Simm, Adam Arany,\n  Yves Moreau, Thanh Le Van, Jos\\'e Felipe Golib Dzib, J\\\"org Wegner, Vladimir\n  Chupakhin, Hugo Ceulemans, Roel Wuyts and Wilfried Verachtert", "title": "SMURFF: a High-Performance Framework for Matrix Factorization", "comments": "European Commission Project: EPEEC - European joint Effort toward a\n  Highly Productive Programming Environment for Heterogeneous Exascale\n  Computing (EC-H2020-80151)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Bayesian Matrix Factorization (BMF) is a powerful technique for recommender\nsystems because it produces good results and is relatively robust against\noverfitting. Yet BMF is more computationally intensive and thus more\nchallenging to implement for large datasets. In this work we present SMURFF a\nhigh-performance feature-rich framework to compose and construct different\nBayesian matrix-factorization methods. The framework has been successfully used\nin to do large scale runs of compound-activity prediction. SMURFF is available\nas open-source and can be used both on a supercomputer and on a desktop or\nlaptop machine. Documentation and several examples are provided as Jupyter\nnotebooks using SMURFF's high-level Python API.\n", "versions": [{"version": "v1", "created": "Thu, 4 Apr 2019 12:36:36 GMT"}, {"version": "v2", "created": "Tue, 25 Jun 2019 11:40:15 GMT"}, {"version": "v3", "created": "Mon, 29 Jul 2019 14:02:48 GMT"}], "update_date": "2019-07-30", "authors_parsed": [["Aa", "Tom Vander", ""], ["Chakroun", "Imen", ""], ["Ashby", "Thomas J.", ""], ["Simm", "Jaak", ""], ["Arany", "Adam", ""], ["Moreau", "Yves", ""], ["Van", "Thanh Le", ""], ["Dzib", "Jos\u00e9 Felipe Golib", ""], ["Wegner", "J\u00f6rg", ""], ["Chupakhin", "Vladimir", ""], ["Ceulemans", "Hugo", ""], ["Wuyts", "Roel", ""], ["Verachtert", "Wilfried", ""]]}, {"id": "1904.02526", "submitter": "Eric Heim", "authors": "Eric Heim", "title": "Constrained Generative Adversarial Networks for Interactive Image\n  Generation", "comments": "To Appear in the Proceedings of the 2019 Conference on Computer\n  Vision and Pattern Recognition", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.GR cs.CV cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Generative Adversarial Networks (GANs) have received a great deal of\nattention due in part to recent success in generating original, high-quality\nsamples from visual domains. However, most current methods only allow for users\nto guide this image generation process through limited interactions. In this\nwork we develop a novel GAN framework that allows humans to be \"in-the-loop\" of\nthe image generation process. Our technique iteratively accepts relative\nconstraints of the form \"Generate an image more like image A than image B\".\nAfter each constraint is given, the user is presented with new outputs from the\nGAN, informing the next round of feedback. This feedback is used to constrain\nthe output of the GAN with respect to an underlying semantic space that can be\ndesigned to model a variety of different notions of similarity (e.g. classes,\nattributes, object relationships, color, etc.). In our experiments, we show\nthat our GAN framework is able to generate images that are of comparable\nquality to equivalent unsupervised GANs while satisfying a large number of the\nconstraints provided by users, effectively changing a GAN into one that allows\nusers interactive control over image generation without sacrificing image\nquality.\n", "versions": [{"version": "v1", "created": "Wed, 3 Apr 2019 17:59:41 GMT"}], "update_date": "2019-04-05", "authors_parsed": [["Heim", "Eric", ""]]}, {"id": "1904.02547", "submitter": "Lisa Beinborn", "authors": "Lisa Beinborn, Samira Abnar, Rochelle Choenni", "title": "Robust Evaluation of Language-Brain Encoding Experiments", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Language-brain encoding experiments evaluate the ability of language models\nto predict brain responses elicited by language stimuli. The evaluation\nscenarios for this task have not yet been standardized which makes it difficult\nto compare and interpret results. We perform a series of evaluation experiments\nwith a consistent encoding setup and compute the results for multiple fMRI\ndatasets. In addition, we test the sensitivity of the evaluation measures to\nrandomized data and analyze the effect of voxel selection methods. Our\nexperimental framework is publicly available to make modelling decisions more\ntransparent and support reproducibility for future comparisons.\n", "versions": [{"version": "v1", "created": "Thu, 4 Apr 2019 13:34:18 GMT"}], "update_date": "2019-04-05", "authors_parsed": [["Beinborn", "Lisa", ""], ["Abnar", "Samira", ""], ["Choenni", "Rochelle", ""]]}, {"id": "1904.02579", "submitter": "Rogerio Bonatti", "authors": "Mirko Gschwindt, Efe Camci, Rogerio Bonatti, Wenshan Wang, Erdal\n  Kayacan, Sebastian Scherer", "title": "Can a Robot Become a Movie Director? Learning Artistic Principles for\n  Aerial Cinematography", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.AI cs.HC cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Aerial filming is constantly gaining importance due to the recent advances in\ndrone technology. It invites many intriguing, unsolved problems at the\nintersection of aesthetical and scientific challenges. In this work, we propose\na deep reinforcement learning agent which supervises motion planning of a\nfilming drone by making desirable shot mode selections based on aesthetical\nvalues of video shots. Unlike most of the current state-of-the-art approaches\nthat require explicit guidance by a human expert, our drone learns how to make\nfavorable viewpoint selections by experience. We propose a learning scheme that\nexploits aesthetical features of retrospective shots in order to extract a\ndesirable policy for better prospective shots. We train our agent in realistic\nAirSim simulations using both a hand-crafted reward function as well as reward\nfrom direct human input. We then deploy the same agent on a real DJI M210 drone\nin order to test the generalization capability of our approach to real world\nconditions. To evaluate the success of our approach in the end, we conduct a\ncomprehensive user study in which participants rate the shot quality of our\nmethods. Videos of the system in action can be seen at\nhttps://youtu.be/qmVw6mfyEmw.\n", "versions": [{"version": "v1", "created": "Thu, 4 Apr 2019 14:30:09 GMT"}, {"version": "v2", "created": "Tue, 15 Oct 2019 15:45:57 GMT"}], "update_date": "2019-10-16", "authors_parsed": [["Gschwindt", "Mirko", ""], ["Camci", "Efe", ""], ["Bonatti", "Rogerio", ""], ["Wang", "Wenshan", ""], ["Kayacan", "Erdal", ""], ["Scherer", "Sebastian", ""]]}, {"id": "1904.02580", "submitter": "Jianhao Peng", "authors": "Abhishek Agarwal, Jianhao Peng and Olgica Milenkovic", "title": "Online Convex Matrix Factorization with Representative Regions", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Matrix factorization (MF) is a versatile learning method that has found wide\napplications in various data-driven disciplines. Still, many MF algorithms do\nnot adequately scale with the size of available datasets and/or lack\ninterpretability. To improve the computational efficiency of the method, an\nonline (streaming) MF algorithm was proposed in Mairal et al. [2010]. To enable\ndata interpretability, a constrained version of MF, termed convex MF, was\nintroduced in Ding et al. [2010]. In the latter work, the basis vectors are\nrequired to lie in the convex hull of the data samples, thereby ensuring that\nevery basis can be interpreted as a weighted combination of data samples. No\ncurrent algorithmic solutions for online convex MF are known as it is\nchallenging to find adequate convex bases without having access to the complete\ndataset. We address both problems by proposing the first online convex MF\nalgorithm that maintains a collection of constant-size sets of representative\ndata samples needed for interpreting each of the basis (Ding et al. [2010]) and\nhas the same almost sure convergence guarantees as the online learning\nalgorithm of Mairal et al. [2010]. Our proof techniques combine random\ncoordinate descent algorithms with specialized quasi-martingale convergence\nanalysis. Experiments on synthetic and real world datasets show significant\ncomputational savings of the proposed online convex MF method compared to\nclassical convex MF. Since the proposed method maintains small representative\nsets of data samples needed for convex interpretations, it is related to a body\nof work in theoretical computer science, pertaining to generating point sets\n(Blum et al. [2016]), and in computer vision, pertaining to archetypal analysis\n(Mei et al. [2018]). Nevertheless, it differs from these lines of work both in\nterms of the objective and algorithmic implementations.\n", "versions": [{"version": "v1", "created": "Thu, 4 Apr 2019 14:32:19 GMT"}, {"version": "v2", "created": "Wed, 29 May 2019 06:48:21 GMT"}], "update_date": "2019-05-30", "authors_parsed": [["Agarwal", "Abhishek", ""], ["Peng", "Jianhao", ""], ["Milenkovic", "Olgica", ""]]}, {"id": "1904.02632", "submitter": "Raphael Gontijo Lopes", "authors": "Raphael Gontijo Lopes, David Ha, Douglas Eck, Jonathon Shlens", "title": "A Learned Representation for Scalable Vector Graphics", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Dramatic advances in generative models have resulted in near photographic\nquality for artificially rendered faces, animals and other objects in the\nnatural world. In spite of such advances, a higher level understanding of\nvision and imagery does not arise from exhaustively modeling an object, but\ninstead identifying higher-level attributes that best summarize the aspects of\nan object. In this work we attempt to model the drawing process of fonts by\nbuilding sequential generative models of vector graphics. This model has the\nbenefit of providing a scale-invariant representation for imagery whose latent\nrepresentation may be systematically manipulated and exploited to perform style\npropagation. We demonstrate these results on a large dataset of fonts and\nhighlight how such a model captures the statistical dependencies and richness\nof this dataset. We envision that our model can find use as a tool for graphic\ndesigners to facilitate font design.\n", "versions": [{"version": "v1", "created": "Thu, 4 Apr 2019 16:04:03 GMT"}], "update_date": "2019-04-05", "authors_parsed": [["Lopes", "Raphael Gontijo", ""], ["Ha", "David", ""], ["Eck", "Douglas", ""], ["Shlens", "Jonathon", ""]]}, {"id": "1904.02642", "submitter": "Michael Volpp", "authors": "Michael Volpp, Lukas P. Fr\\\"ohlich, Kirsten Fischer, Andreas Doerr,\n  Stefan Falkner, Frank Hutter, Christian Daniel", "title": "Meta-Learning Acquisition Functions for Transfer Learning in Bayesian\n  Optimization", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Transferring knowledge across tasks to improve data-efficiency is one of the\nopen key challenges in the field of global black-box optimization. Readily\navailable algorithms are typically designed to be universal optimizers and,\ntherefore, often suboptimal for specific tasks. We propose a novel transfer\nlearning method to obtain customized optimizers within the well-established\nframework of Bayesian optimization, allowing our algorithm to utilize the\nproven generalization capabilities of Gaussian processes. Using reinforcement\nlearning to meta-train an acquisition function (AF) on a set of related tasks,\nthe proposed method learns to extract implicit structural information and to\nexploit it for improved data-efficiency. We present experiments on a\nsimulation-to-real transfer task as well as on several synthetic functions and\non two hyperparameter search problems. The results show that our algorithm (1)\nautomatically identifies structural properties of objective functions from\navailable source tasks or simulations, (2) performs favourably in settings with\nboth scarse and abundant source data, and (3) falls back to the performance\nlevel of general AFs if no particular structure is present.\n", "versions": [{"version": "v1", "created": "Thu, 4 Apr 2019 16:27:06 GMT"}, {"version": "v2", "created": "Tue, 9 Apr 2019 15:29:46 GMT"}, {"version": "v3", "created": "Tue, 28 May 2019 13:05:14 GMT"}, {"version": "v4", "created": "Fri, 27 Sep 2019 09:58:29 GMT"}, {"version": "v5", "created": "Fri, 14 Feb 2020 13:24:57 GMT"}], "update_date": "2020-02-17", "authors_parsed": [["Volpp", "Michael", ""], ["Fr\u00f6hlich", "Lukas P.", ""], ["Fischer", "Kirsten", ""], ["Doerr", "Andreas", ""], ["Falkner", "Stefan", ""], ["Hutter", "Frank", ""], ["Daniel", "Christian", ""]]}, {"id": "1904.02653", "submitter": "Daniel T Chang", "authors": "Daniel T. Chang", "title": "Tiered Latent Representations and Latent Spaces for Molecular Graphs", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Molecular graphs generally contain subgraphs (known as groups) that are\nidentifiable and significant in composition, functionality, geometry, etc. Flat\nlatent representations (node embeddings or graph embeddings) fail to represent,\nand support the use of, groups. Fully hierarchical latent representations, on\nthe other hand, are difficult to learn and, even if learned, may be too complex\nto use or interpret. We propose tiered latent representations and latent spaces\nfor molecular graphs as a simple way to explicitly represent and utilize\ngroups, which consist of the atom (node) tier, the group tier and the molecule\n(graph) tier. Specifically, we propose an architecture for learning tiered\nlatent representations and latent spaces using graph autoencoders, graph neural\nnetworks, differentiable group pooling and the membership matrix. We discuss\nits various components, major challenges and related work, for both a\ndeterministic and a probabilistic model. We also briefly discuss the usage and\nexploration of tiered latent spaces. The tiered approach is applicable to other\ntypes of structured graphs similar in nature to molecular graphs.\n", "versions": [{"version": "v1", "created": "Thu, 21 Mar 2019 16:58:53 GMT"}], "update_date": "2019-04-05", "authors_parsed": [["Chang", "Daniel T.", ""]]}, {"id": "1904.02654", "submitter": "Jindong Wang", "authors": "Chaohui Yu, Jindong Wang, Yiqiang Chen, Zijing Wu", "title": "Accelerating Deep Unsupervised Domain Adaptation with Transfer Channel\n  Pruning", "comments": "Accepted by International Joint Conference on Neural Networks (IJCNN)\n  2019; 8 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep unsupervised domain adaptation (UDA) has recently received increasing\nattention from researchers. However, existing methods are computationally\nintensive due to the computation cost of Convolutional Neural Networks (CNN)\nadopted by most work. To date, there is no effective network compression method\nfor accelerating these models. In this paper, we propose a unified Transfer\nChannel Pruning (TCP) approach for accelerating UDA models. TCP is capable of\ncompressing the deep UDA model by pruning less important channels while\nsimultaneously learning transferable features by reducing the cross-domain\ndistribution divergence. Therefore, it reduces the impact of negative transfer\nand maintains competitive performance on the target task. To the best of our\nknowledge, TCP is the first approach that aims at accelerating deep UDA models.\nTCP is validated on two benchmark datasets-Office-31 and ImageCLEF-DA with two\ncommon backbone networks-VGG16 and ResNet50. Experimental results demonstrate\nthat TCP achieves comparable or better classification accuracy than other\ncomparison methods while significantly reducing the computational cost. To be\nmore specific, in VGG16, we get even higher accuracy after pruning 26% floating\npoint operations (FLOPs); in ResNet50, we also get higher accuracy on half of\nthe tasks after pruning 12% FLOPs. We hope that TCP will open a new door for\nfuture research on accelerating transfer learning models.\n", "versions": [{"version": "v1", "created": "Mon, 25 Mar 2019 07:32:30 GMT"}], "update_date": "2019-04-05", "authors_parsed": [["Yu", "Chaohui", ""], ["Wang", "Jindong", ""], ["Chen", "Yiqiang", ""], ["Wu", "Zijing", ""]]}, {"id": "1904.02655", "submitter": "Noelia Oses Fern\\'andez", "authors": "Noelia Oses, Aritz Legarretaetxebarria, Marco Quartulli, Igor\n  Garc\\'ia, Mikel Serrano", "title": "Determining input variable ranges in Industry 4.0: A heuristic for\n  estimating the domain of a real-valued function or trained regression model\n  given an output range", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Industrial process control systems try to keep an output variable within a\ngiven tolerance around a target value. PID control systems have been widely\nused in industry to control input variables in order to reach this goal.\nHowever, this kind of Transfer Function based approach cannot be extended to\ncomplex processes where input data might be non-numeric, high dimensional,\nsparse, etc. In such cases, there is still a need for determining the subspace\nof input data that produces an output within a given range. This paper presents\na non-stochastic heuristic to determine input values for a mathematical\nfunction or trained regression model given an output range. The proposed method\ncreates a synthetic training data set of input combinations with a class label\nthat indicates whether the output is within the given target range or not.\nThen, a decision tree classifier is used to determine the subspace of input\ndata of interest. This method is more general than a traditional controller as\nthe target range for the output does not have to be centered around a reference\nvalue and it can be applied given a regression model of the output variable,\nwhich may have categorical variables as inputs and may be high dimensional,\nsparse... The proposed heuristic is validated with a proof of concept on a real\nuse case where the quality of a lamination factory is established to identify\nthe suitable subspace of production variable values.\n", "versions": [{"version": "v1", "created": "Wed, 3 Apr 2019 11:23:56 GMT"}], "update_date": "2019-04-05", "authors_parsed": [["Oses", "Noelia", ""], ["Legarretaetxebarria", "Aritz", ""], ["Quartulli", "Marco", ""], ["Garc\u00eda", "Igor", ""], ["Serrano", "Mikel", ""]]}, {"id": "1904.02664", "submitter": "Branislav Kveton", "authors": "Chih-Wei Hsu, Branislav Kveton, Ofer Meshi, Martin Mladenov, and Csaba\n  Szepesvari", "title": "Empirical Bayes Regret Minimization", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Most bandit algorithm designs are purely theoretical. Therefore, they have\nstrong regret guarantees, but also are often too conservative in practice. In\nthis work, we pioneer the idea of algorithm design by minimizing the empirical\nBayes regret, the average regret over problem instances sampled from a known\ndistribution. We focus on a tractable instance of this problem, the confidence\ninterval and posterior width tuning, and propose an efficient algorithm for\nsolving it. The tuning algorithm is analyzed and evaluated in multi-armed,\nlinear, and generalized linear bandits. We report several-fold reductions in\nBayes regret for state-of-the-art bandit algorithms, simply by optimizing over\na small sample from a distribution.\n", "versions": [{"version": "v1", "created": "Thu, 4 Apr 2019 17:00:02 GMT"}, {"version": "v2", "created": "Fri, 21 Jun 2019 05:14:06 GMT"}, {"version": "v3", "created": "Thu, 10 Oct 2019 06:18:52 GMT"}, {"version": "v4", "created": "Wed, 10 Jun 2020 18:47:04 GMT"}], "update_date": "2020-06-12", "authors_parsed": [["Hsu", "Chih-Wei", ""], ["Kveton", "Branislav", ""], ["Meshi", "Ofer", ""], ["Mladenov", "Martin", ""], ["Szepesvari", "Csaba", ""]]}, {"id": "1904.02666", "submitter": "Akbar Dehghani", "authors": "Akbar Dehghani, Tristan Glatard, Emad Shihab", "title": "Subject Cross Validation in Human Activity Recognition", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  K-fold Cross Validation is commonly used to evaluate classifiers and tune\ntheir hyperparameters. However, it assumes that data points are Independent and\nIdentically Distributed (i.i.d.) so that samples used in the training and test\nsets can be selected randomly and uniformly. In Human Activity Recognition\ndatasets, we note that the samples produced by the same subjects are likely to\nbe correlated due to diverse factors. Hence, k-fold cross validation may\noverestimate the performance of activity recognizers, in particular when\noverlapping sliding windows are used. In this paper, we investigate the effect\nof Subject Cross Validation on the performance of Human Activity Recognition,\nboth with non-overlapping and with overlapping sliding windows. Results show\nthat k-fold cross validation artificially increases the performance of\nrecognizers by about 10%, and even by 16% when overlapping windows are used. In\naddition, we do not observe any performance gain from the use of overlapping\nwindows. We conclude that Human Activity Recognition systems should be\nevaluated by Subject Cross Validation, and that overlapping windows are not\nworth their extra computational cost.\n", "versions": [{"version": "v1", "created": "Thu, 4 Apr 2019 17:02:12 GMT"}, {"version": "v2", "created": "Tue, 9 Apr 2019 17:55:48 GMT"}], "update_date": "2019-04-10", "authors_parsed": [["Dehghani", "Akbar", ""], ["Glatard", "Tristan", ""], ["Shihab", "Emad", ""]]}, {"id": "1904.02679", "submitter": "Jesse Vig", "authors": "Jesse Vig", "title": "Visualizing Attention in Transformer-Based Language Representation\n  Models", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.HC cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present an open-source tool for visualizing multi-head self-attention in\nTransformer-based language representation models. The tool extends earlier work\nby visualizing attention at three levels of granularity: the attention-head\nlevel, the model level, and the neuron level. We describe how each of these\nviews can help to interpret the model, and we demonstrate the tool on the BERT\nmodel and the OpenAI GPT-2 model. We also present three use cases for analyzing\nGPT-2: detecting model bias, identifying recurring patterns, and linking\nneurons to model behavior.\n", "versions": [{"version": "v1", "created": "Thu, 4 Apr 2019 17:32:49 GMT"}, {"version": "v2", "created": "Thu, 11 Apr 2019 16:00:53 GMT"}], "update_date": "2019-06-12", "authors_parsed": [["Vig", "Jesse", ""]]}, {"id": "1904.02688", "submitter": "Ralph Abboud", "authors": "Ralph Abboud, Ismail Ilkan Ceylan, Thomas Lukasiewicz", "title": "Learning to Reason: Leveraging Neural Networks for Approximate DNF\n  Counting", "comments": "To appear in Proceedings of the Thirty-Fourth AAAI Conference on\n  Artificial Intelligence (AAAI-20). Code and data available at:\n  https://github.com/ralphabb/NeuralDNF/", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Weighted model counting (WMC) has emerged as a prevalent approach for\nprobabilistic inference. In its most general form, WMC is #P-hard. Weighted DNF\ncounting (weighted #DNF) is a special case, where approximations with\nprobabilistic guarantees are obtained in O(nm), where n denotes the number of\nvariables, and m the number of clauses of the input DNF, but this is not\nscalable in practice. In this paper, we propose a neural model counting\napproach for weighted #DNF that combines approximate model counting with deep\nlearning, and accurately approximates model counts in linear time when width is\nbounded. We conduct experiments to validate our method, and show that our model\nlearns and generalizes very well to large-scale #DNF instances.\n", "versions": [{"version": "v1", "created": "Thu, 4 Apr 2019 17:45:45 GMT"}, {"version": "v2", "created": "Fri, 24 May 2019 17:27:08 GMT"}, {"version": "v3", "created": "Fri, 6 Sep 2019 20:27:13 GMT"}, {"version": "v4", "created": "Thu, 21 Nov 2019 18:03:23 GMT"}, {"version": "v5", "created": "Wed, 29 Jan 2020 21:39:41 GMT"}], "update_date": "2020-01-31", "authors_parsed": [["Abboud", "Ralph", ""], ["Ceylan", "Ismail Ilkan", ""], ["Lukasiewicz", "Thomas", ""]]}, {"id": "1904.02698", "submitter": "Jean Kossaifi", "authors": "Jean Kossaifi, Adrian Bulat, Georgios Tzimiropoulos and Maja Pantic", "title": "T-Net: Parametrizing Fully Convolutional Nets with a Single High-Order\n  Tensor", "comments": "CVPR 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent findings indicate that over-parametrization, while crucial for\nsuccessfully training deep neural networks, also introduces large amounts of\nredundancy. Tensor methods have the potential to efficiently parametrize\nover-complete representations by leveraging this redundancy. In this paper, we\npropose to fully parametrize Convolutional Neural Networks (CNNs) with a single\nhigh-order, low-rank tensor. Previous works on network tensorization have\nfocused on parametrizing individual layers (convolutional or fully connected)\nonly, and perform the tensorization layer-by-layer separately. In contrast, we\npropose to jointly capture the full structure of a neural network by\nparametrizing it with a single high-order tensor, the modes of which represent\neach of the architectural design parameters of the network (e.g. number of\nconvolutional blocks, depth, number of stacks, input features, etc). This\nparametrization allows to regularize the whole network and drastically reduce\nthe number of parameters. Our model is end-to-end trainable and the low-rank\nstructure imposed on the weight tensor acts as an implicit regularization. We\nstudy the case of networks with rich structure, namely Fully Convolutional\nNetworks (FCNs), which we propose to parametrize with a single 8th-order\ntensor. We show that our approach can achieve superior performance with small\ncompression rates, and attain high compression rates with negligible drop in\naccuracy for the challenging task of human pose estimation.\n", "versions": [{"version": "v1", "created": "Thu, 4 Apr 2019 17:55:37 GMT"}], "update_date": "2019-04-05", "authors_parsed": [["Kossaifi", "Jean", ""], ["Bulat", "Adrian", ""], ["Tzimiropoulos", "Georgios", ""], ["Pantic", "Maja", ""]]}, {"id": "1904.02749", "submitter": "Lei Yang", "authors": "Lei Yang, Xiaohang Zhan, Dapeng Chen, Junjie Yan, Chen Change Loy,\n  Dahua Lin", "title": "Learning to Cluster Faces on an Affinity Graph", "comments": "8 pages, 8 figures, CVPR 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Face recognition sees remarkable progress in recent years, and its\nperformance has reached a very high level. Taking it to a next level requires\nsubstantially larger data, which would involve prohibitive annotation cost.\nHence, exploiting unlabeled data becomes an appealing alternative. Recent works\nhave shown that clustering unlabeled faces is a promising approach, often\nleading to notable performance gains. Yet, how to effectively cluster,\nespecially on a large-scale (i.e. million-level or above) dataset, remains an\nopen question. A key challenge lies in the complex variations of cluster\npatterns, which make it difficult for conventional clustering methods to meet\nthe needed accuracy. This work explores a novel approach, namely, learning to\ncluster instead of relying on hand-crafted criteria. Specifically, we propose a\nframework based on graph convolutional network, which combines a detection and\na segmentation module to pinpoint face clusters. Experiments show that our\nmethod yields significantly more accurate face clusters, which, as a result,\nalso lead to further performance gain in face recognition.\n", "versions": [{"version": "v1", "created": "Thu, 4 Apr 2019 19:01:35 GMT"}, {"version": "v2", "created": "Sun, 5 May 2019 08:41:15 GMT"}], "update_date": "2019-05-07", "authors_parsed": [["Yang", "Lei", ""], ["Zhan", "Xiaohang", ""], ["Chen", "Dapeng", ""], ["Yan", "Junjie", ""], ["Loy", "Chen Change", ""], ["Lin", "Dahua", ""]]}, {"id": "1904.02756", "submitter": "Amir Hertz", "authors": "Amir Hertz, Sharon Fogel, Rana Hanocka, Raja Giryes, Daniel Cohen-Or", "title": "Blind Visual Motif Removal from a Single Image", "comments": "CVPR 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.GR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Many images shared over the web include overlaid objects, or visual motifs,\nsuch as text, symbols or drawings, which add a description or decoration to the\nimage. For example, decorative text that specifies where the image was taken,\nrepeatedly appears across a variety of different images. Often, the reoccurring\nvisual motif, is semantically similar, yet, differs in location, style and\ncontent (e.g. text placement, font and letters). This work proposes a deep\nlearning based technique for blind removal of such objects. In the blind\nsetting, the location and exact geometry of the motif are unknown. Our approach\nsimultaneously estimates which pixels contain the visual motif, and synthesizes\nthe underlying latent image. It is applied to a single input image, without any\nuser assistance in specifying the location of the motif, achieving\nstate-of-the-art results for blind removal of both opaque and semi-transparent\nvisual motifs.\n", "versions": [{"version": "v1", "created": "Thu, 4 Apr 2019 19:17:05 GMT"}], "update_date": "2019-04-08", "authors_parsed": [["Hertz", "Amir", ""], ["Fogel", "Sharon", ""], ["Hanocka", "Rana", ""], ["Giryes", "Raja", ""], ["Cohen-Or", "Daniel", ""]]}, {"id": "1904.02762", "submitter": "Cicero Nogueira dos Santos", "authors": "Cicero Nogueira dos Santos, Youssef Mroueh, Inkit Padhi, Pierre Dognin", "title": "Learning Implicit Generative Models by Matching Perceptual Features", "comments": "16 pages", "journal-ref": "ICCV 2019", "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Perceptual features (PFs) have been used with great success in tasks such as\ntransfer learning, style transfer, and super-resolution. However, the efficacy\nof PFs as key source of information for learning generative models is not well\nstudied. We investigate here the use of PFs in the context of learning implicit\ngenerative models through moment matching (MM). More specifically, we propose a\nnew effective MM approach that learns implicit generative models by performing\nmean and covariance matching of features extracted from pretrained ConvNets.\nOur proposed approach improves upon existing MM methods by: (1) breaking away\nfrom the problematic min/max game of adversarial learning; (2) avoiding online\nlearning of kernel functions; and (3) being efficient with respect to both\nnumber of used moments and required minibatch size. Our experimental results\ndemonstrate that, due to the expressiveness of PFs from pretrained deep\nConvNets, our method achieves state-of-the-art results for challenging\nbenchmarks.\n", "versions": [{"version": "v1", "created": "Thu, 4 Apr 2019 19:34:23 GMT"}], "update_date": "2019-08-01", "authors_parsed": [["Santos", "Cicero Nogueira dos", ""], ["Mroueh", "Youssef", ""], ["Padhi", "Inkit", ""], ["Dognin", "Pierre", ""]]}, {"id": "1904.02765", "submitter": "Andrew Patterson", "authors": "Andrew Patterson, Arun Lakshmanan and Naira Hovakimyan", "title": "Intent-Aware Probabilistic Trajectory Estimation for Collision\n  Prediction with Uncertainty Quantification", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.LG cs.SY math.OC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Collision prediction in a dynamic and unknown environment relies on knowledge\nof how the environment is changing. Many collision prediction methods rely on\ndeterministic knowledge of how obstacles are moving in the environment.\nHowever, complete deterministic knowledge of the obstacles' motion is often\nunavailable. This work proposes a Gaussian process based prediction method that\nreplaces the assumption of deterministic knowledge of each obstacle's future\nbehavior with probabilistic knowledge, to allow a larger class of obstacles to\nbe considered. The method solely relies on position and velocity measurements\nto predict collisions with dynamic obstacles. We show that the uncertainty\nregion for obstacle positions can be expressed in terms of a combination of\npolynomials generated with Gaussian process regression. To control the growth\nof uncertainty over arbitrary time horizons, a probabilistic obstacle intention\nis assumed as a distribution over obstacle positions and velocities, which can\nbe naturally included in the Gaussian process framework. Our approach is\ndemonstrated in two case studies in which (i), an obstacle overtakes the agent\nand (ii), an obstacle crosses the agent's path perpendicularly. In these\nsimulations we show that the collision can be predicted despite having limited\nknowledge of the obstacle's behavior.\n", "versions": [{"version": "v1", "created": "Thu, 4 Apr 2019 19:43:14 GMT"}], "update_date": "2019-04-08", "authors_parsed": [["Patterson", "Andrew", ""], ["Lakshmanan", "Arun", ""], ["Hovakimyan", "Naira", ""]]}, {"id": "1904.02773", "submitter": "Yuheng Bu", "authors": "Craig Wilson, Yuheng Bu and Venugopal Veeravalli", "title": "Adaptive Sequential Machine Learning", "comments": "arXiv admin note: text overlap with arXiv:1509.07422", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A framework previously introduced in [3] for solving a sequence of stochastic\noptimization problems with bounded changes in the minimizers is extended and\napplied to machine learning problems such as regression and classification. The\nstochastic optimization problems arising in these machine learning problems is\nsolved using algorithms such as stochastic gradient descent (SGD). A method\nbased on estimates of the change in the minimizers and properties of the\noptimization algorithm is introduced for adaptively selecting the number of\nsamples at each time step to ensure that the excess risk, i.e., the expected\ngap between the loss achieved by the approximate minimizer produced by the\noptimization algorithm and the exact minimizer, does not exceed a target level.\nA bound is developed to show that the estimate of the change in the minimizers\nis non-trivial provided that the excess risk is small enough. Extensions\nrelevant to the machine learning setting are considered, including a cost-based\napproach to select the number of samples with a cost budget over a fixed\nhorizon, and an approach to applying cross-validation for model selection.\nFinally, experiments with synthetic and real data are used to validate the\nalgorithms.\n", "versions": [{"version": "v1", "created": "Thu, 4 Apr 2019 20:03:46 GMT"}], "update_date": "2019-04-08", "authors_parsed": [["Wilson", "Craig", ""], ["Bu", "Yuheng", ""], ["Veeravalli", "Venugopal", ""]]}, {"id": "1904.02790", "submitter": "Nishant Prateek", "authors": "Nishant Prateek, Mateusz {\\L}ajszczak, Roberto Barra-Chicote, Thomas\n  Drugman, Jaime Lorenzo-Trueba, Thomas Merritt, Srikanth Ronanki, Trevor Wood", "title": "In Other News: A Bi-style Text-to-speech Model for Synthesizing\n  Newscaster Voice with Limited Data", "comments": "Accepted at NAACL-HLT 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG eess.AS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Neural text-to-speech synthesis (NTTS) models have shown significant progress\nin generating high-quality speech, however they require a large quantity of\ntraining data. This makes creating models for multiple styles expensive and\ntime-consuming. In this paper different styles of speech are analysed based on\nprosodic variations, from this a model is proposed to synthesise speech in the\nstyle of a newscaster, with just a few hours of supplementary data. We pose the\nproblem of synthesising in a target style using limited data as that of\ncreating a bi-style model that can synthesise both neutral-style and\nnewscaster-style speech via a one-hot vector which factorises the two styles.\nWe also propose conditioning the model on contextual word embeddings, and\nextensively evaluate it against neutral NTTS, and neutral concatenative-based\nsynthesis. This model closes the gap in perceived style-appropriateness between\nnatural recordings for newscaster-style of speech, and neutral speech synthesis\nby approximately two-thirds.\n", "versions": [{"version": "v1", "created": "Thu, 4 Apr 2019 20:59:20 GMT"}], "update_date": "2019-04-08", "authors_parsed": [["Prateek", "Nishant", ""], ["\u0141ajszczak", "Mateusz", ""], ["Barra-Chicote", "Roberto", ""], ["Drugman", "Thomas", ""], ["Lorenzo-Trueba", "Jaime", ""], ["Merritt", "Thomas", ""], ["Ronanki", "Srikanth", ""], ["Wood", "Trevor", ""]]}, {"id": "1904.02793", "submitter": "Ashutosh Modi", "authors": "Pierre Colombo and Wojciech Witon and Ashutosh Modi and James Kennedy\n  and Mubbasir Kapadia", "title": "Affect-Driven Dialog Generation", "comments": "8+2 Pages, Accepted at NAACL 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The majority of current systems for end-to-end dialog generation focus on\nresponse quality without an explicit control over the affective content of the\nresponses. In this paper, we present an affect-driven dialog system, which\ngenerates emotional responses in a controlled manner using a continuous\nrepresentation of emotions. The system achieves this by modeling emotions at a\nword and sequence level using: (1) a vector representation of the desired\nemotion, (2) an affect regularizer, which penalizes neutral words, and (3) an\naffect sampling method, which forces the neural network to generate diverse\nwords that are emotionally relevant. During inference, we use a reranking\nprocedure that aims to extract the most emotionally relevant responses using a\nhuman-in-the-loop optimization process. We study the performance of our system\nin terms of both quantitative (BLEU score and response diversity), and\nqualitative (emotional appropriateness) measures.\n", "versions": [{"version": "v1", "created": "Thu, 4 Apr 2019 21:05:13 GMT"}], "update_date": "2019-04-08", "authors_parsed": [["Colombo", "Pierre", ""], ["Witon", "Wojciech", ""], ["Modi", "Ashutosh", ""], ["Kennedy", "James", ""], ["Kapadia", "Mubbasir", ""]]}, {"id": "1904.02815", "submitter": "Ashutosh Modi", "authors": "Pooja Chitkara, Ashutosh Modi, Pravalika Avvaru, Sepehr Janghorbani,\n  Mubbasir Kapadia", "title": "Topic Spotting using Hierarchical Networks with Self Attention", "comments": "5+2 Pages, Accepted at NAACL 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Success of deep learning techniques have renewed the interest in development\nof dialogue systems. However, current systems struggle to have consistent long\nterm conversations with the users and fail to build rapport. Topic spotting,\nthe task of automatically inferring the topic of a conversation, has been shown\nto be helpful in making a dialog system more engaging and efficient. We propose\na hierarchical model with self attention for topic spotting. Experiments on the\nSwitchboard corpus show the superior performance of our model over previously\nproposed techniques for topic spotting and deep models for text classification.\nAdditionally, in contrast to offline processing of dialog, we also analyze the\nperformance of our model in a more realistic setting i.e. in an online setting\nwhere the topic is identified in real time as the dialog progresses. Results\nshow that our model is able to generalize even with limited information in the\nonline setting.\n", "versions": [{"version": "v1", "created": "Thu, 4 Apr 2019 22:54:57 GMT"}], "update_date": "2019-04-08", "authors_parsed": [["Chitkara", "Pooja", ""], ["Modi", "Ashutosh", ""], ["Avvaru", "Pravalika", ""], ["Janghorbani", "Sepehr", ""], ["Kapadia", "Mubbasir", ""]]}, {"id": "1904.02816", "submitter": "Saiprasad Ravishankar", "authors": "Saiprasad Ravishankar, Jong Chul Ye, and Jeffrey A. Fessler", "title": "Image Reconstruction: From Sparsity to Data-adaptive Methods and Machine\n  Learning", "comments": "To appear in the Proceedings of the IEEE, Special Issue on Biomedical\n  Imaging and Analysis in the Age of Sparsity, Big Data, and Deep Learning", "journal-ref": null, "doi": "10.1109/JPROC.2019.2936204", "report-no": null, "categories": "eess.IV cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The field of medical image reconstruction has seen roughly four types of\nmethods. The first type tended to be analytical methods, such as filtered\nback-projection (FBP) for X-ray computed tomography (CT) and the inverse\nFourier transform for magnetic resonance imaging (MRI), based on simple\nmathematical models for the imaging systems. These methods are typically fast,\nbut have suboptimal properties such as poor resolution-noise trade-off for CT.\nA second type is iterative reconstruction methods based on more complete models\nfor the imaging system physics and, where appropriate, models for the sensor\nstatistics. These iterative methods improved image quality by reducing noise\nand artifacts. The FDA-approved methods among these have been based on\nrelatively simple regularization models. A third type of methods has been\ndesigned to accommodate modified data acquisition methods, such as reduced\nsampling in MRI and CT to reduce scan time or radiation dose. These methods\ntypically involve mathematical image models involving assumptions such as\nsparsity or low-rank. A fourth type of methods replaces mathematically designed\nmodels of signals and systems with data-driven or adaptive models inspired by\nthe field of machine learning. This paper focuses on the two most recent trends\nin medical image reconstruction: methods based on sparsity or low-rank models,\nand data-driven methods based on machine learning techniques.\n", "versions": [{"version": "v1", "created": "Thu, 4 Apr 2019 23:04:10 GMT"}, {"version": "v2", "created": "Wed, 26 Jun 2019 03:14:57 GMT"}, {"version": "v3", "created": "Fri, 16 Aug 2019 03:07:55 GMT"}], "update_date": "2019-08-19", "authors_parsed": [["Ravishankar", "Saiprasad", ""], ["Ye", "Jong Chul", ""], ["Fessler", "Jeffrey A.", ""]]}, {"id": "1904.02817", "submitter": "Xiaochuang Han", "authors": "Xiaochuang Han and Jacob Eisenstein", "title": "Unsupervised Domain Adaptation of Contextualized Embeddings for Sequence\n  Labeling", "comments": "EMNLP 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.DL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Contextualized word embeddings such as ELMo and BERT provide a foundation for\nstrong performance across a wide range of natural language processing tasks by\npretraining on large corpora of unlabeled text. However, the applicability of\nthis approach is unknown when the target domain varies substantially from the\npretraining corpus. We are specifically interested in the scenario in which\nlabeled data is available in only a canonical source domain such as newstext,\nand the target domain is distinct from both the labeled and pretraining texts.\nTo address this scenario, we propose domain-adaptive fine-tuning, in which the\ncontextualized embeddings are adapted by masked language modeling on text from\nthe target domain. We test this approach on sequence labeling in two\nchallenging domains: Early Modern English and Twitter. Both domains differ\nsubstantially from existing pretraining corpora, and domain-adaptive\nfine-tuning yields substantial improvements over strong BERT baselines, with\nparticularly impressive results on out-of-vocabulary words. We conclude that\ndomain-adaptive fine-tuning offers a simple and effective approach for the\nunsupervised adaptation of sequence labeling to difficult new domains.\n", "versions": [{"version": "v1", "created": "Thu, 4 Apr 2019 23:05:45 GMT"}, {"version": "v2", "created": "Thu, 5 Sep 2019 00:18:25 GMT"}], "update_date": "2019-09-06", "authors_parsed": [["Han", "Xiaochuang", ""], ["Eisenstein", "Jacob", ""]]}, {"id": "1904.02818", "submitter": "David Bieber", "authors": "Rui Zhao, David Bieber, Kevin Swersky, Daniel Tarlow", "title": "Neural Networks for Modeling Source Code Edits", "comments": "Deanonymized version of ICLR 2019 submission", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CL cs.SE stat.ML", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Programming languages are emerging as a challenging and interesting domain\nfor machine learning. A core task, which has received significant attention in\nrecent years, is building generative models of source code. However, to our\nknowledge, previous generative models have always been framed in terms of\ngenerating static snapshots of code. In this work, we instead treat source code\nas a dynamic object and tackle the problem of modeling the edits that software\ndevelopers make to source code files. This requires extracting intent from\nprevious edits and leveraging it to generate subsequent edits. We develop\nseveral neural networks and use synthetic data to test their ability to learn\nchallenging edit patterns that require strong generalization. We then collect\nand train our models on a large-scale dataset of Google source code, consisting\nof millions of fine-grained edits from thousands of Python developers. From the\nmodeling perspective, our main conclusion is that a new composition of\nattentional and pointer network components provides the best overall\nperformance and scalability. From the application perspective, our results\nprovide preliminary evidence of the feasibility of developing tools that learn\nto predict future edits.\n", "versions": [{"version": "v1", "created": "Thu, 4 Apr 2019 23:06:09 GMT"}], "update_date": "2019-04-08", "authors_parsed": [["Zhao", "Rui", ""], ["Bieber", "David", ""], ["Swersky", "Kevin", ""], ["Tarlow", "Daniel", ""]]}, {"id": "1904.02826", "submitter": "Oliver Maclaren", "authors": "Oliver J. Maclaren and Ruanui Nicholson", "title": "What can be estimated? Identifiability, estimability, causal inference\n  and ill-posed inverse problems", "comments": "41 pages, 5 figures. Fixed typos, added references, added examples.\n  New examples (updated again) introduce explicit 'view' and 'undo' operations\n  to complement 'do' operation as part of the translation between structural\n  causal models and our abstract statistical formalism", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST cs.LG stat.ML stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider basic conceptual questions concerning the relationship between\nstatistical estimation and causal inference. Firstly, we show how to translate\ncausal inference problems into an abstract statistical formalism without\nrequiring any structure beyond an arbitrarily-indexed family of probability\nmodels. The formalism is simple but can incorporate a variety of causal\nmodelling frameworks, including 'structural causal models', but also models\nexpressed in terms of, e.g., differential equations. We focus primarily on the\nstructural/graphical causal modelling literature, however. Secondly, we\nconsider the extent to which causal and statistical concerns can be cleanly\nseparated, examining the fundamental question: 'What can be estimated from\ndata?'. We call this the problem of estimability. We approach this by analysing\na standard formal definition of 'can be estimated' commonly adopted in the\ncausal inference literature -- identifiability -- in our abstract statistical\nformalism. We use elementary category theory to show that identifiability\nimplies the existence of a Fisher-consistent estimator, but also show that this\nestimator may be discontinuous, and thus unstable, in general. This difficulty\narises because the causal inference problem is, in general, an ill-posed\ninverse problem. Inverse problems have three conditions which must be satisfied\nto be considered well-posed: existence, uniqueness, and stability of solutions.\nHere identifiability corresponds to the question of uniqueness; in contrast, we\ntake estimability to mean satisfaction of all three conditions, i.e.\nwell-posedness. Lack of stability implies that naive translation of a causally\nidentifiable quantity into an achievable statistical estimation target may\nprove impossible. Our article is primarily expository and aimed at unifying\nideas from multiple fields, though we provide new constructions and proofs.\n", "versions": [{"version": "v1", "created": "Thu, 4 Apr 2019 23:46:44 GMT"}, {"version": "v2", "created": "Thu, 11 Apr 2019 06:36:23 GMT"}, {"version": "v3", "created": "Mon, 20 Jul 2020 04:54:06 GMT"}, {"version": "v4", "created": "Tue, 21 Jul 2020 01:48:09 GMT"}], "update_date": "2020-07-22", "authors_parsed": [["Maclaren", "Oliver J.", ""], ["Nicholson", "Ruanui", ""]]}, {"id": "1904.02838", "submitter": "Md Shahriar Iqbal", "authors": "Md Shahriar Iqbal, Lars Kotthoff, Pooyan Jamshidi", "title": "Transfer Learning for Performance Modeling of Deep Neural Network\n  Systems", "comments": "2 pages, 2 figures, USENIX Conference on Operational Machine\n  Learning, 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Modern deep neural network (DNN) systems are highly configurable with large a\nnumber of options that significantly affect their non-functional behavior, for\nexample inference time and energy consumption. Performance models allow to\nunderstand and predict the effects of such configuration options on system\nbehavior, but are costly to build because of large configuration spaces.\nPerformance models from one environment cannot be transferred directly to\nanother; usually models are rebuilt from scratch for different environments,\nfor example different hardware. Recently, transfer learning methods have been\napplied to reuse knowledge from performance models trained in one environment\nin another. In this paper, we perform an empirical study to understand the\neffectiveness of different transfer learning strategies for building\nperformance models of DNN systems. Our results show that transferring\ninformation on the most influential configuration options and their\ninteractions is an effective way of reducing the cost to build performance\nmodels in new environments.\n", "versions": [{"version": "v1", "created": "Thu, 4 Apr 2019 14:16:37 GMT"}], "update_date": "2019-04-08", "authors_parsed": [["Iqbal", "Md Shahriar", ""], ["Kotthoff", "Lars", ""], ["Jamshidi", "Pooyan", ""]]}, {"id": "1904.02839", "submitter": "Alexander Hoyle", "authors": "Alexander Hoyle, Lawrence Wolf-Sonkin, Hanna Wallach, Ryan Cotterell\n  and Isabelle Augenstein", "title": "Combining Sentiment Lexica with a Multi-View Variational Autoencoder", "comments": "To appear in NAACL-HLT 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  When assigning quantitative labels to a dataset, different methodologies may\nrely on different scales. In particular, when assigning polarities to words in\na sentiment lexicon, annotators may use binary, categorical, or continuous\nlabels. Naturally, it is of interest to unify these labels from disparate\nscales to both achieve maximal coverage over words and to create a single, more\nrobust sentiment lexicon while retaining scale coherence. We introduce a\ngenerative model of sentiment lexica to combine disparate scales into a common\nlatent representation. We realize this model with a novel multi-view\nvariational autoencoder (VAE), called SentiVAE. We evaluate our approach via a\ndownstream text classification task involving nine English-Language sentiment\nanalysis datasets; our representation outperforms six individual sentiment\nlexica, as well as a straightforward combination thereof.\n", "versions": [{"version": "v1", "created": "Fri, 5 Apr 2019 01:03:31 GMT"}], "update_date": "2019-04-08", "authors_parsed": [["Hoyle", "Alexander", ""], ["Wolf-Sonkin", "Lawrence", ""], ["Wallach", "Hanna", ""], ["Cotterell", "Ryan", ""], ["Augenstein", "Isabelle", ""]]}, {"id": "1904.02841", "submitter": "Fatemeh Sheikholeslami", "authors": "Fatemeh Sheikholeslami, Swayambhoo Jain, and Georgios B. Giannakis", "title": "Minimum Uncertainty Based Detection of Adversaries in Deep Neural\n  Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Despite their unprecedented performance in various domains, utilization of\nDeep Neural Networks (DNNs) in safety-critical environments is severely limited\nin the presence of even small adversarial perturbations. The present work\ndevelops a randomized approach to detecting such perturbations based on minimum\nuncertainty metrics that rely on sampling at the hidden layers during the DNN\ninference stage. Inspired by Bayesian approaches to uncertainty estimation, the\nsampling probabilities are designed for effective detection of the\nadversarially corrupted inputs. Being modular, the novel detector of\nadversaries can be conveniently employed by any pre-trained DNN at no extra\ntraining overhead. Selecting which units to sample per hidden layer entails\nquantifying the amount of DNN output uncertainty, where the overall uncertainty\nis expressed in terms of its layer-wise components - what also promotes\nscalability. Sampling probabilities are then sought by minimizing uncertainty\nmeasures layer-by-layer, leading to a novel convex optimization problem that\nadmits an exact solver with superlinear convergence rate. By simplifying the\nobjective function, low-complexity approximate solvers are also developed. In\naddition to valuable insights, these approximations link the novel approach\nwith state-of-the-art randomized adversarial detectors. The effectiveness of\nthe novel detectors in the context of competing alternatives is highlighted\nthrough extensive tests for various types of adversarial attacks with variable\nlevels of strength.\n", "versions": [{"version": "v1", "created": "Fri, 5 Apr 2019 01:23:10 GMT"}, {"version": "v2", "created": "Thu, 15 Oct 2020 23:18:33 GMT"}], "update_date": "2020-10-19", "authors_parsed": [["Sheikholeslami", "Fatemeh", ""], ["Jain", "Swayambhoo", ""], ["Giannakis", "Georgios B.", ""]]}, {"id": "1904.02843", "submitter": "Jong Chul Ye", "authors": "Shujaat Khan, Jaeyoung Huh, Jong Chul Ye", "title": "Deep Learning-based Universal Beamformer for Ultrasound Imaging", "comments": "Accepted for MICCAI 2019. arXiv admin note: substantial text overlap\n  with arXiv:1901.01706", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.IV cs.CV cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In ultrasound (US) imaging, individual channel RF measurements are\nback-propagated and accumulated to form an image after applying specific\ndelays. While this time reversal is usually implemented using a hardware- or\nsoftware-based delay-and-sum (DAS) beamformer, the performance of DAS decreases\nrapidly in situations where data acquisition is not ideal. Herein, for the\nfirst time, we demonstrate that a single data-driven adaptive beamformer\ndesigned as a deep neural network can generate high quality images robustly for\nvarious detector channel configurations and subsampling rates. The proposed\ndeep beamformer is evaluated for two distinct acquisition schemes: focused\nultrasound imaging and planewave imaging. Experimental results showed that the\nproposed deep beamformer exhibit significant performance gain for both focused\nand planar imaging schemes, in terms of contrast-to-noise ratio and structural\nsimilarity.\n", "versions": [{"version": "v1", "created": "Fri, 5 Apr 2019 01:40:52 GMT"}, {"version": "v2", "created": "Mon, 15 Jul 2019 14:07:27 GMT"}], "update_date": "2019-07-17", "authors_parsed": [["Khan", "Shujaat", ""], ["Huh", "Jaeyoung", ""], ["Ye", "Jong Chul", ""]]}, {"id": "1904.02851", "submitter": "Aamodh Suresh", "authors": "Aamodh Suresh and Sonia Martinez", "title": "Planning under non-rational perception of uncertain spatial costs", "comments": "12 pages and 10 figures. This revision adds more explanation and\n  clearer figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.AI cs.LG cs.SY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This work investigates the design of risk-perception-aware motion-planning\nstrategies that incorporate non-rational perception of risks associated with\nuncertain spatial costs. Our proposed method employs the Cumulative Prospect\nTheory (CPT) to generate a perceived risk map over a given environment.\nCPT-like perceived risks and path-length metrics are then combined to define a\ncost function that is compliant with the requirements of asymptotic optimality\nof sampling-based motion planners (RRT*). The modeling power of CPT is\nillustrated in theory and in simulation, along with a comparison to other risk\nperception models like Conditional Value at Risk (CVaR). Theoretically, we\ndefine a notion of expressiveness for a risk perception model and show that\nCPT's is higher than that of CVaR and expected risk. We then show that this\nexpressiveness translates to our path planning setting, where we observe that a\nplanner equipped with CPT together with a simultaneous perturbation stochastic\napproximation (SPSA) method can better approximate arbitrary paths in an\nenvironment. Additionally, we show in simulation that our planner captures a\nrich set of meaningful paths, representative of different risk perceptions in a\ncustom environment. We then compare the performance of our planner with T-RRT*\n(a planner for continuous cost spaces) and Risk-RRT* (a risk-aware planner for\ndynamic human obstacles) through simulations in cluttered and dynamic\nenvironments respectively, showing the advantage of our proposed planner.\n", "versions": [{"version": "v1", "created": "Fri, 5 Apr 2019 02:42:24 GMT"}, {"version": "v2", "created": "Tue, 25 Feb 2020 03:14:50 GMT"}, {"version": "v3", "created": "Tue, 2 Jun 2020 03:00:21 GMT"}, {"version": "v4", "created": "Tue, 20 Oct 2020 20:32:34 GMT"}], "update_date": "2020-10-22", "authors_parsed": [["Suresh", "Aamodh", ""], ["Martinez", "Sonia", ""]]}, {"id": "1904.02868", "submitter": "Amirata Ghorbani", "authors": "Amirata Ghorbani and James Zou", "title": "Data Shapley: Equitable Valuation of Data for Machine Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  As data becomes the fuel driving technological and economic growth, a\nfundamental challenge is how to quantify the value of data in algorithmic\npredictions and decisions. For example, in healthcare and consumer markets, it\nhas been suggested that individuals should be compensated for the data that\nthey generate, but it is not clear what is an equitable valuation for\nindividual data. In this work, we develop a principled framework to address\ndata valuation in the context of supervised machine learning. Given a learning\nalgorithm trained on $n$ data points to produce a predictor, we propose data\nShapley as a metric to quantify the value of each training datum to the\npredictor performance. Data Shapley value uniquely satisfies several natural\nproperties of equitable data valuation. We develop Monte Carlo and\ngradient-based methods to efficiently estimate data Shapley values in practical\nsettings where complex learning algorithms, including neural networks, are\ntrained on large datasets. In addition to being equitable, extensive\nexperiments across biomedical, image and synthetic data demonstrate that data\nShapley has several other benefits: 1) it is more powerful than the popular\nleave-one-out or leverage score in providing insight on what data is more\nvaluable for a given learning task; 2) low Shapley value data effectively\ncapture outliers and corruptions; 3) high Shapley value data inform what type\nof new data to acquire to improve the predictor.\n", "versions": [{"version": "v1", "created": "Fri, 5 Apr 2019 04:54:10 GMT"}, {"version": "v2", "created": "Mon, 10 Jun 2019 08:10:40 GMT"}], "update_date": "2019-06-11", "authors_parsed": [["Ghorbani", "Amirata", ""], ["Zou", "James", ""]]}, {"id": "1904.02872", "submitter": "Jong Chul Ye", "authors": "Boah Kim and Jong Chul Ye", "title": "Mumford-Shah Loss Functional for Image Segmentation with Deep Learning", "comments": "Accepted for IEEE Transactions on Image Processing", "journal-ref": null, "doi": "10.1109/TIP.2019.2941265", "report-no": null, "categories": "cs.CV cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent state-of-the-art image segmentation algorithms are mostly based on\ndeep neural networks, thanks to their high performance and fast computation\ntime. However, these methods are usually trained in a supervised manner, which\nrequires large number of high quality ground-truth segmentation masks. On the\nother hand, classical image segmentation approaches such as level-set methods\nare formulated in a self-supervised manner by minimizing energy functions such\nas Mumford-Shah functional, so they are still useful to help generation of\nsegmentation masks without labels. Unfortunately, these algorithms are usually\ncomputationally expensive and often have limitation in semantic segmentation.\nIn this paper, we propose a novel loss function based on Mumford-Shah\nfunctional that can be used in deep-learning based image segmentation without\nor with small labeled data. This loss function is based on the observation that\nthe softmax layer of deep neural networks has striking similarity to the\ncharacteristic function in the Mumford-Shah functional. We show that the new\nloss function enables semi-supervised and unsupervised segmentation. In\naddition, our loss function can be also used as a regularized function to\nenhance supervised semantic segmentation algorithms. Experimental results on\nmultiple datasets demonstrate the effectiveness of the proposed method.\n", "versions": [{"version": "v1", "created": "Fri, 5 Apr 2019 05:17:18 GMT"}, {"version": "v2", "created": "Mon, 9 Sep 2019 09:14:39 GMT"}], "update_date": "2020-01-08", "authors_parsed": [["Kim", "Boah", ""], ["Ye", "Jong Chul", ""]]}, {"id": "1904.02873", "submitter": "Ga Wu", "authors": "Ga Wu, Buser Say and Scott Sanner", "title": "Scalable Planning with Deep Neural Network Learned Transition Models", "comments": "36 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In many real-world planning problems with factored, mixed discrete and\ncontinuous state and action spaces such as Reservoir Control, Heating\nVentilation, and Air Conditioning, and Navigation domains, it is difficult to\nobtain a model of the complex nonlinear dynamics that govern state evolution.\nHowever, the ubiquity of modern sensors allows us to collect large quantities\nof data from each of these complex systems and build accurate, nonlinear deep\nneural network models of their state transitions. But there remains one major\nproblem for the task of control -- how can we plan with deep network learned\ntransition models without resorting to Monte Carlo Tree Search and other\nblack-box transition model techniques that ignore model structure and do not\neasily extend to mixed discrete and continuous domains? In this paper, we\nintroduce two types of nonlinear planning methods that can leverage deep neural\nnetwork learned transition models: Hybrid Deep MILP Planner (HD-MILP-Plan) and\nTensorflow Planner (TF-Plan). In HD-MILP-Plan, we make the critical observation\nthat the Rectified Linear Unit transfer function for deep networks not only\nallows faster convergence of model learning, but also permits a direct\ncompilation of the deep network transition model to a Mixed-Integer Linear\nProgram encoding. Further, we identify deep network specific optimizations for\nHD-MILP-Plan that improve performance over a base encoding and show that we can\nplan optimally with respect to the learned deep networks. In TF-Plan, we take\nadvantage of the efficiency of auto-differentiation tools and GPU-based\ncomputation where we encode a subclass of purely continuous planning problems\nas Recurrent Neural Networks and directly optimize the actions through\nbackpropagation. We compare both planners and show that TF-Plan is able to\napproximate the optimal plans found by HD-MILP-Plan in less computation time...\n", "versions": [{"version": "v1", "created": "Fri, 5 Apr 2019 05:21:46 GMT"}, {"version": "v2", "created": "Thu, 30 May 2019 17:02:55 GMT"}, {"version": "v3", "created": "Mon, 3 Jun 2019 16:18:49 GMT"}, {"version": "v4", "created": "Tue, 14 Jul 2020 05:24:47 GMT"}, {"version": "v5", "created": "Wed, 15 Jul 2020 02:21:48 GMT"}], "update_date": "2020-07-16", "authors_parsed": [["Wu", "Ga", ""], ["Say", "Buser", ""], ["Sanner", "Scott", ""]]}, {"id": "1904.02874", "submitter": "Sneha Chaudhari", "authors": "Sneha Chaudhari, Varun Mithal, Gungor Polatkan, Rohan Ramanath", "title": "An Attentive Survey of Attention Models", "comments": "accepted to Transactions on Intelligent Systems and Technology(TIST);\n  33 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Attention Model has now become an important concept in neural networks that\nhas been researched within diverse application domains. This survey provides a\nstructured and comprehensive overview of the developments in modeling\nattention. In particular, we propose a taxonomy which groups existing\ntechniques into coherent categories. We review salient neural architectures in\nwhich attention has been incorporated, and discuss applications in which\nmodeling attention has shown a significant impact. We also describe how\nattention has been used to improve the interpretability of neural networks.\nFinally, we discuss some future research directions in attention. We hope this\nsurvey will provide a succinct introduction to attention models and guide\npractitioners while developing approaches for their applications.\n", "versions": [{"version": "v1", "created": "Fri, 5 Apr 2019 05:26:59 GMT"}, {"version": "v2", "created": "Tue, 15 Dec 2020 23:58:46 GMT"}, {"version": "v3", "created": "Mon, 12 Jul 2021 12:03:52 GMT"}], "update_date": "2021-07-13", "authors_parsed": [["Chaudhari", "Sneha", ""], ["Mithal", "Varun", ""], ["Polatkan", "Gungor", ""], ["Ramanath", "Rohan", ""]]}, {"id": "1904.02877", "submitter": "Dimitrios Stamoulis", "authors": "Dimitrios Stamoulis, Ruizhou Ding, Di Wang, Dimitrios Lymberopoulos,\n  Bodhi Priyantha, Jie Liu, Diana Marculescu", "title": "Single-Path NAS: Designing Hardware-Efficient ConvNets in less than 4\n  Hours", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Can we automatically design a Convolutional Network (ConvNet) with the\nhighest image classification accuracy under the runtime constraint of a mobile\ndevice? Neural architecture search (NAS) has revolutionized the design of\nhardware-efficient ConvNets by automating this process. However, the NAS\nproblem remains challenging due to the combinatorially large design space,\ncausing a significant searching time (at least 200 GPU-hours). To alleviate\nthis complexity, we propose Single-Path NAS, a novel differentiable NAS method\nfor designing hardware-efficient ConvNets in less than 4 hours. Our\ncontributions are as follows: 1. Single-path search space: Compared to previous\ndifferentiable NAS methods, Single-Path NAS uses one single-path\nover-parameterized ConvNet to encode all architectural decisions with shared\nconvolutional kernel parameters, hence drastically decreasing the number of\ntrainable parameters and the search cost down to few epochs. 2.\nHardware-efficient ImageNet classification: Single-Path NAS achieves 74.96%\ntop-1 accuracy on ImageNet with 79ms latency on a Pixel 1 phone, which is\nstate-of-the-art accuracy compared to NAS methods with similar constraints\n(<80ms). 3. NAS efficiency: Single-Path NAS search cost is only 8 epochs (30\nTPU-hours), which is up to 5,000x faster compared to prior work. 4.\nReproducibility: Unlike all recent mobile-efficient NAS methods which only\nrelease pretrained models, we open-source our entire codebase at:\nhttps://github.com/dstamoulis/single-path-nas.\n", "versions": [{"version": "v1", "created": "Fri, 5 Apr 2019 05:49:41 GMT"}], "update_date": "2019-04-08", "authors_parsed": [["Stamoulis", "Dimitrios", ""], ["Ding", "Ruizhou", ""], ["Wang", "Di", ""], ["Lymberopoulos", "Dimitrios", ""], ["Priyantha", "Bodhi", ""], ["Liu", "Jie", ""], ["Marculescu", "Diana", ""]]}, {"id": "1904.02884", "submitter": "Yinpeng Dong", "authors": "Yinpeng Dong, Tianyu Pang, Hang Su, Jun Zhu", "title": "Evading Defenses to Transferable Adversarial Examples by\n  Translation-Invariant Attacks", "comments": "CVPR 2019 (Oral)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.CR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep neural networks are vulnerable to adversarial examples, which can\nmislead classifiers by adding imperceptible perturbations. An intriguing\nproperty of adversarial examples is their good transferability, making\nblack-box attacks feasible in real-world applications. Due to the threat of\nadversarial attacks, many methods have been proposed to improve the robustness.\nSeveral state-of-the-art defenses are shown to be robust against transferable\nadversarial examples. In this paper, we propose a translation-invariant attack\nmethod to generate more transferable adversarial examples against the defense\nmodels. By optimizing a perturbation over an ensemble of translated images, the\ngenerated adversarial example is less sensitive to the white-box model being\nattacked and has better transferability. To improve the efficiency of attacks,\nwe further show that our method can be implemented by convolving the gradient\nat the untranslated image with a pre-defined kernel. Our method is generally\napplicable to any gradient-based attack method. Extensive experiments on the\nImageNet dataset validate the effectiveness of the proposed method. Our best\nattack fools eight state-of-the-art defenses at an 82% success rate on average\nbased only on the transferability, demonstrating the insecurity of the current\ndefense techniques.\n", "versions": [{"version": "v1", "created": "Fri, 5 Apr 2019 06:15:51 GMT"}], "update_date": "2019-04-08", "authors_parsed": [["Dong", "Yinpeng", ""], ["Pang", "Tianyu", ""], ["Su", "Hang", ""], ["Zhu", "Jun", ""]]}, {"id": "1904.02892", "submitter": "Kou Tanaka", "authors": "Kou Tanaka, Hirokazu Kameoka, Takuhiro Kaneko, Nobukatsu Hojo", "title": "WaveCycleGAN2: Time-domain Neural Post-filter for Speech Waveform\n  Generation", "comments": "Submitted to INTERSPEECH2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SD cs.LG eess.AS stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  WaveCycleGAN has recently been proposed to bridge the gap between natural and\nsynthesized speech waveforms in statistical parametric speech synthesis and\nprovides fast inference with a moving average model rather than an\nautoregressive model and high-quality speech synthesis with the adversarial\ntraining. However, the human ear can still distinguish the processed speech\nwaveforms from natural ones. One possible cause of this distinguishability is\nthe aliasing observed in the processed speech waveform via down/up-sampling\nmodules. To solve the aliasing and provide higher quality speech synthesis, we\npropose WaveCycleGAN2, which 1) uses generators without down/up-sampling\nmodules and 2) combines discriminators of the waveform domain and acoustic\nparameter domain. The results show that the proposed method 1) alleviates the\naliasing well, 2) is useful for both speech waveforms generated by\nanalysis-and-synthesis and statistical parametric speech synthesis, and 3)\nachieves a mean opinion score comparable to those of natural speech and speech\nsynthesized by WaveNet (open WaveNet) and WaveGlow while processing speech\nsamples at a rate of more than 150 kHz on an NVIDIA Tesla P100.\n", "versions": [{"version": "v1", "created": "Fri, 5 Apr 2019 06:53:37 GMT"}, {"version": "v2", "created": "Tue, 9 Apr 2019 01:15:27 GMT"}], "update_date": "2019-04-10", "authors_parsed": [["Tanaka", "Kou", ""], ["Kameoka", "Hirokazu", ""], ["Kaneko", "Takuhiro", ""], ["Hojo", "Nobukatsu", ""]]}, {"id": "1904.02910", "submitter": "Jong Chul Ye", "authors": "Sungjun Lim, Sang-Eun Lee, Sunghoe Chang, Jong Chul Ye", "title": "Blind Deconvolution Microscopy Using Cycle Consistent CNN with Explicit\n  PSF Layer", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deconvolution microscopy has been extensively used to improve the resolution\nof the widefield fluorescent microscopy. Conventional approaches, which usually\nrequire the point spread function (PSF) measurement or blind estimation, are\nhowever computationally expensive. Recently, CNN based approaches have been\nexplored as a fast and high performance alternative. In this paper, we present\na novel unsupervised deep neural network for blind deconvolution based on cycle\nconsistency and PSF modeling layers. In contrast to the recent CNN approaches\nfor similar problem, the explicit PSF modeling layers improve the robustness of\nthe algorithm. Experimental results confirm the efficacy of the algorithm.\n", "versions": [{"version": "v1", "created": "Fri, 5 Apr 2019 07:43:34 GMT"}], "update_date": "2019-04-08", "authors_parsed": [["Lim", "Sungjun", ""], ["Lee", "Sang-Eun", ""], ["Chang", "Sunghoe", ""], ["Ye", "Jong Chul", ""]]}, {"id": "1904.02921", "submitter": "Igor Koval", "authors": "Igor Koval (ARAMIS, CMAP, ICM), St\\'ephanie Allassonni\\`ere (CRC -\n  UMR-S 1138), Stanley Durrleman (ICM, ARAMIS)", "title": "Simulation of virtual cohorts increases predictive accuracy of cognitive\n  decline in MCI subjects", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ME cs.LG stat.AP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The ability to predict the progression of biomarkers, notably in NDD, is\nlimited by the size of the longitudinal data sets, in terms of number of\npatients, number of visits per patients and total follow-up time. To this end,\nwe introduce a data augmentation technique that is able to reproduce the\nvariability seen in a longitudinal training data set and simulate continuous\nbiomarkers trajectories for any number of virtual patients. Thanks to this\nsimulation framework, we propose to transform the training set into a simulated\ndata set with more patients, more time-points per patient and longer follow-up\nduration. We illustrate this approach on the prediction of the MMSE of MCI\nsubjects of the ADNI data set. We show that it allows to reach predictions with\nerrors comparable to the noise in the data, estimated in test/retest studies,\nachieving a improvement of 37% of the mean absolute error compared to the same\nnon-augmented model.\n", "versions": [{"version": "v1", "created": "Fri, 5 Apr 2019 08:01:39 GMT"}], "update_date": "2019-04-08", "authors_parsed": [["Koval", "Igor", "", "ARAMIS, CMAP, ICM"], ["Allassonni\u00e8re", "St\u00e9phanie", "", "CRC -\n  UMR-S 1138"], ["Durrleman", "Stanley", "", "ICM, ARAMIS"]]}, {"id": "1904.02926", "submitter": "Youngser Park", "authors": "Congyuan Yang, Carey E. Priebe, Youngser Park, David J. Marchette", "title": "Simultaneous Dimensionality and Complexity Model Selection for Spectral\n  Graph Clustering", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Our problem of interest is to cluster vertices of a graph by identifying\nunderlying community structure. Among various vertex clustering approaches,\nspectral clustering is one of the most popular methods because it is easy to\nimplement while often outperforming more traditional clustering algorithms.\nHowever, there are two inherent model selection problems in spectral\nclustering, namely estimating both the embedding dimension and number of\nclusters. This paper attempts to address the issue by establishing a novel\nmodel selection framework specifically for vertex clustering on graphs under a\nstochastic block model. The first contribution is a probabilistic model which\napproximates the distribution of the extended spectral embedding of a graph.\nThe model is constructed based on a theoretical result of asymptotic normality\nof the informative part of the embedding, and on a simulation result providing\na conjecture for the limiting behavior of the redundant part of the embedding.\nThe second contribution is a simultaneous model selection framework. In\ncontrast with the traditional approaches, our model selection procedure\nestimates embedding dimension and number of clusters simultaneously. Based on\nour conjectured distributional model, a theorem on the consistency of the\nestimates of model parameters is presented, providing support for the validity\nof our method. Algorithms for our simultaneous model selection for vertex\nclustering are proposed, demonstrating superior performance in simulation\nexperiments. We illustrate our method via application to a collection of brain\ngraphs.\n", "versions": [{"version": "v1", "created": "Fri, 5 Apr 2019 08:12:17 GMT"}, {"version": "v2", "created": "Wed, 13 Nov 2019 01:23:28 GMT"}, {"version": "v3", "created": "Fri, 15 May 2020 17:22:04 GMT"}, {"version": "v4", "created": "Tue, 22 Sep 2020 13:47:17 GMT"}], "update_date": "2020-09-23", "authors_parsed": [["Yang", "Congyuan", ""], ["Priebe", "Carey E.", ""], ["Park", "Youngser", ""], ["Marchette", "David J.", ""]]}, {"id": "1904.02931", "submitter": "Takamasa Okudono", "authors": "Takamasa Okudono, Masaki Waga, Taro Sekiyama, Ichiro Hasuo", "title": "Weighted Automata Extraction from Recurrent Neural Networks via\n  Regression on State Spaces", "comments": "AAAI 2020. We are preparing to distribute the implementation", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a method to extract a weighted finite automaton (WFA) from a\nrecurrent neural network (RNN). Our algorithm is based on the WFA learning\nalgorithm by Balle and Mohri, which is in turn an extension of Angluin's\nclassic \\lstar algorithm. Our technical novelty is in the use of\n\\emph{regression} methods for the so-called equivalence queries, thus\nexploiting the internal state space of an RNN to prioritize counterexample\ncandidates. This way we achieve a quantitative/weighted extension of the recent\nwork by Weiss, Goldberg and Yahav that extracts DFAs. We experimentally\nevaluate the accuracy, expressivity and efficiency of the extracted WFAs.\n", "versions": [{"version": "v1", "created": "Fri, 5 Apr 2019 08:21:45 GMT"}, {"version": "v2", "created": "Mon, 8 Apr 2019 05:33:58 GMT"}, {"version": "v3", "created": "Wed, 20 Nov 2019 07:23:23 GMT"}], "update_date": "2019-11-21", "authors_parsed": [["Okudono", "Takamasa", ""], ["Waga", "Masaki", ""], ["Sekiyama", "Taro", ""], ["Hasuo", "Ichiro", ""]]}, {"id": "1904.02958", "submitter": "Hyenkyun Woo", "authors": "Hyenkyun Woo", "title": "Logitron: Perceptron-augmented classification model based on an extended\n  logistic loss function", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.IT math.IT stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Classification is the most important process in data analysis. However, due\nto the inherent non-convex and non-smooth structure of the zero-one loss\nfunction of the classification model, various convex surrogate loss functions\nsuch as hinge loss, squared hinge loss, logistic loss, and exponential loss are\nintroduced. These loss functions have been used for decades in diverse\nclassification models, such as SVM (support vector machine) with hinge loss,\nlogistic regression with logistic loss, and Adaboost with exponential loss and\nso on. In this work, we present a Perceptron-augmented convex classification\nframework, {\\it Logitron}. The loss function of it is a smoothly stitched\nfunction of the extended logistic loss with the famous Perceptron loss\nfunction. The extended logistic loss function is a parameterized function\nestablished based on the extended logarithmic function and the extended\nexponential function. The main advantage of the proposed Logitron\nclassification model is that it shows the connection between SVM and logistic\nregression via polynomial parameterization of the loss function. In more\ndetails, depending on the choice of parameters, we have the Hinge-Logitron\nwhich has the generalized $k$-th order hinge-loss with an additional $k$-th\nroot stabilization function and the Logistic-Logitron which has a logistic-like\nloss function with relatively large $|k|$. Interestingly, even $k=-1$,\nHinge-Logitron satisfies the classification-calibration condition and shows\nreasonable classification performance with low computational cost. The\nnumerical experiment in the linear classifier framework demonstrates that\nHinge-Logitron with $k=4$ (the fourth-order SVM with the fourth root\nstabilization function) outperforms logistic regression, SVM, and other\nLogitron models in terms of classification accuracy.\n", "versions": [{"version": "v1", "created": "Fri, 5 Apr 2019 09:39:57 GMT"}], "update_date": "2019-04-08", "authors_parsed": [["Woo", "Hyenkyun", ""]]}, {"id": "1904.02971", "submitter": "Henri Riihim\\\"aki", "authors": "Henri Riihim\\\"aki, Wojciech Chach\\'olski, Jakob Theorell, Jan Hillert,\n  Ryan Ramanujam", "title": "A topological data analysis based classification method for multiple\n  measurements", "comments": "8 pages, 7 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG math.AT stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Machine learning models for repeated measurements are limited. Using\ntopological data analysis (TDA), we present a classifier for repeated\nmeasurements which samples from the data space and builds a network graph based\non the data topology. When applying this to two case studies, accuracy exceeds\nalternative models with additional benefits such as reporting data subsets with\nhigh purity along with feature values. For 300 examples of 3 tree species, the\naccuracy reached 80% after 30 datapoints, which was improved to 90% after\nincreased sampling to 400 datapoints. Using data from 100 examples of each of 6\npoint processes, the classifier achieved 96.8% accuracy. In both datasets, the\nTDA classifier outperformed an alternative model. This algorithm and software\ncan be beneficial for repeated measurement data common in biological sciences,\nas both an accurate classifier and a feature selection tool.\n", "versions": [{"version": "v1", "created": "Fri, 5 Apr 2019 10:06:55 GMT"}], "update_date": "2019-04-08", "authors_parsed": [["Riihim\u00e4ki", "Henri", ""], ["Chach\u00f3lski", "Wojciech", ""], ["Theorell", "Jakob", ""], ["Hillert", "Jan", ""], ["Ramanujam", "Ryan", ""]]}, {"id": "1904.02990", "submitter": "Soeren Laue", "authors": "Soeren Laue", "title": "On the Equivalence of Forward Mode Automatic Differentiation and\n  Symbolic Differentiation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SC cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We show that forward mode automatic differentiation and symbolic\ndifferentiation are equivalent in the sense that they both perform the same\noperations when computing derivatives. This is in stark contrast to the common\nclaim that they are substantially different. The difference is often\nillustrated by claiming that symbolic differentiation suffers from \"expression\nswell\" whereas automatic differentiation does not. Here, we show that this\nstatement is not true. \"Expression swell\" refers to the phenomenon of a much\nlarger representation of the derivative as opposed to the representation of the\noriginal function.\n", "versions": [{"version": "v1", "created": "Fri, 5 Apr 2019 11:05:55 GMT"}, {"version": "v2", "created": "Fri, 3 May 2019 14:01:19 GMT"}, {"version": "v3", "created": "Mon, 20 Jul 2020 12:47:47 GMT"}], "update_date": "2020-07-21", "authors_parsed": [["Laue", "Soeren", ""]]}, {"id": "1904.03000", "submitter": "Yaser Souri", "authors": "Johann Sawatzky, Yaser Souri, Christian Grund, Juergen Gall", "title": "What Object Should I Use? - Task Driven Object Detection", "comments": "CVPR 2019. The first two authors contributed equally, ordered\n  alphabetically", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG cs.RO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  When humans have to solve everyday tasks, they simply pick the objects that\nare most suitable. While the question which object should one use for a\nspecific task sounds trivial for humans, it is very difficult to answer for\nrobots or other autonomous systems. This issue, however, is not addressed by\ncurrent benchmarks for object detection that focus on detecting object\ncategories. We therefore introduce the COCO-Tasks dataset which comprises about\n40,000 images where the most suitable objects for 14 tasks have been annotated.\nWe furthermore propose an approach that detects the most suitable objects for a\ngiven task. The approach builds on a Gated Graph Neural Network to exploit the\nappearance of each object as well as the global context of all present objects\nin the scene. In our experiments, we show that the proposed approach\noutperforms other approaches that are evaluated on the dataset like\nclassification or ranking approaches.\n", "versions": [{"version": "v1", "created": "Fri, 5 Apr 2019 11:36:07 GMT"}], "update_date": "2019-04-08", "authors_parsed": [["Sawatzky", "Johann", ""], ["Souri", "Yaser", ""], ["Grund", "Christian", ""], ["Gall", "Juergen", ""]]}, {"id": "1904.03014", "submitter": "Yu Cheng", "authors": "Duo Wang, Yu Cheng, Mo Yu, Xiaoxiao Guo, Tao Zhang", "title": "A Hybrid Approach with Optimization and Metric-based Meta-Learner for\n  Few-Shot Learning", "comments": "Accepted to Neurocomputing journal, code will be released soon. arXiv\n  admin note: text overlap with arXiv:1901.09890", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Few-shot learning aims to learn classifiers for new classes with only a few\ntraining examples per class. Most existing few-shot learning approaches belong\nto either metric-based meta-learning or optimization-based meta-learning\ncategory, both of which have achieved successes in the simplified \"$k$-shot\n$N$-way\" image classification settings. Specifically, the optimization-based\napproaches train a meta-learner to predict the parameters of the task-specific\nclassifiers. The task-specific classifiers are required to be\nhomogeneous-structured to ease the parameter prediction, so the meta-learning\napproaches could only handle few-shot learning problems where the tasks share a\nuniform number of classes. The metric-based approaches learn one task-invariant\nmetric for all the tasks. Even though the metric-learning approaches allow\ndifferent numbers of classes, they require the tasks all coming from a similar\ndomain such that there exists a uniform metric that could work across tasks. In\nthis work, we propose a hybrid meta-learning model called Meta-Metric-Learner\nwhich combines the merits of both optimization- and metric-based approaches.\nOur meta-metric-learning approach consists of two components, a task-specific\nmetric-based learner as a base model, and a meta-learner that learns and\nspecifies the base model. Thus our model is able to handle flexible numbers of\nclasses as well as generate more generalized metrics for classification across\ntasks. We test our approach in the standard \"$k$-shot $N$-way\" few-shot\nlearning setting following previous works and a new realistic few-shot setting\nwith flexible class numbers in both single-source form and multi-source forms.\nExperiments show that our approach can obtain superior performance in all\nsettings.\n", "versions": [{"version": "v1", "created": "Thu, 4 Apr 2019 07:31:34 GMT"}, {"version": "v2", "created": "Tue, 27 Aug 2019 01:35:22 GMT"}], "update_date": "2019-08-28", "authors_parsed": [["Wang", "Duo", ""], ["Cheng", "Yu", ""], ["Yu", "Mo", ""], ["Guo", "Xiaoxiao", ""], ["Zhang", "Tao", ""]]}, {"id": "1904.03026", "submitter": "Rok Cestnik", "authors": "Rok Cestnik and Markus Abel", "title": "Inferring the dynamics of oscillatory systems using recurrent neural\n  networks", "comments": "9 pages, 7 figures", "journal-ref": "Chaos 29, 063128 (2019); https://doi.org/10.1063/1.5096918", "doi": "10.1063/1.5096918", "report-no": null, "categories": "nlin.AO cs.LG physics.soc-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We investigate the predictive power of recurrent neural networks for\noscillatory systems not only on the attractor, but in its vicinity as well. For\nthis we consider systems perturbed by an external force. This allows us to not\nmerely predict the time evolution of the system, but also study its dynamical\nproperties, such as bifurcations, dynamical response curves, characteristic\nexponents etc. It is shown that they can be effectively estimated even in some\nregions of the state space where no input data were given. We consider several\ndifferent oscillatory examples, including self-sustained, excitatory,\ntime-delay and chaotic systems. Furthermore, with a statistical analysis we\nassess the amount of training data required for effective inference for two\ncommon recurrent neural network cells, the long short-term memory and the gated\nrecurrent unit.\n", "versions": [{"version": "v1", "created": "Thu, 4 Apr 2019 15:21:48 GMT"}, {"version": "v2", "created": "Sun, 30 Jun 2019 11:09:51 GMT"}], "update_date": "2019-07-02", "authors_parsed": [["Cestnik", "Rok", ""], ["Abel", "Markus", ""]]}, {"id": "1904.03061", "submitter": "Zimin Chen", "authors": "Zimin Chen and Martin Monperrus", "title": "A Literature Study of Embeddings on Source Code", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.PL cs.SE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Natural language processing has improved tremendously after the success of\nword embedding techniques such as word2vec. Recently, the same idea has been\napplied on source code with encouraging results. In this survey, we aim to\ncollect and discuss the usage of word embedding techniques on programs and\nsource code. The articles in this survey have been collected by asking authors\nof related work and with an extensive search on Google Scholar. Each article is\ncategorized into five categories: 1. embedding of tokens 2. embedding of\nfunctions or methods 3. embedding of sequences or sets of method calls 4.\nembedding of binary code 5. other embeddings. We also provide links to\nexperimental data and show some remarkable visualization of code embeddings. In\nsummary, word embedding has been successfully applied on different\ngranularities of source code. With access to countless open-source\nrepositories, we see a great potential of applying other data-driven natural\nlanguage processing techniques on source code in the future.\n", "versions": [{"version": "v1", "created": "Fri, 5 Apr 2019 13:37:42 GMT"}], "update_date": "2019-04-08", "authors_parsed": [["Chen", "Zimin", ""], ["Monperrus", "Martin", ""]]}, {"id": "1904.03063", "submitter": "Edwin D. Simpson", "authors": "Edwin Simpson, Steven Reece, Stephen J. Roberts", "title": "Bayesian Heatmaps: Probabilistic Classification with Multiple Unreliable\n  Information Sources", "comments": null, "journal-ref": "Joint European Conference on Machine Learning and Knowledge\n  Discovery in Databases (2017), pp. 109-125, Springer, Cham", "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Unstructured data from diverse sources, such as social media and aerial\nimagery, can provide valuable up-to-date information for intelligent situation\nassessment. Mining these different information sources could bring major\nbenefits to applications such as situation awareness in disaster zones and\nmapping the spread of diseases. Such applications depend on classifying the\nsituation across a region of interest, which can be depicted as a spatial\n\"heatmap\". Annotating unstructured data using crowdsourcing or automated\nclassifiers produces individual classifications at sparse locations that\ntypically contain many errors. We propose a novel Bayesian approach that models\nthe relevance, error rates and bias of each information source, enabling us to\nlearn a spatial Gaussian Process classifier by aggregating data from multiple\nsources with varying reliability and relevance. Our method does not require\ngold-labelled data and can make predictions at any location in an area of\ninterest given only sparse observations. We show empirically that our approach\ncan handle noisy and biased data sources, and that simultaneously inferring\nreliability and transferring information between neighbouring reports leads to\nmore accurate predictions. We demonstrate our method on two real-world problems\nfrom disaster response, showing how our approach reduces the amount of\ncrowdsourced data required and can be used to generate valuable heatmap\nvisualisations from SMS messages and satellite images.\n", "versions": [{"version": "v1", "created": "Fri, 5 Apr 2019 13:39:42 GMT"}], "update_date": "2019-04-08", "authors_parsed": [["Simpson", "Edwin", ""], ["Reece", "Steven", ""], ["Roberts", "Stephen J.", ""]]}, {"id": "1904.03081", "submitter": "Thomas M\\\"ollenhoff", "authors": "Michael Moeller, Thomas M\\\"ollenhoff, Daniel Cremers", "title": "Controlling Neural Networks via Energy Dissipation", "comments": "Published as a conference paper at ICCV 2019, Seoul", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The last decade has shown a tremendous success in solving various computer\nvision problems with the help of deep learning techniques. Lately, many works\nhave demonstrated that learning-based approaches with suitable network\narchitectures even exhibit superior performance for the solution of (ill-posed)\nimage reconstruction problems such as deblurring, super-resolution, or medical\nimage reconstruction. The drawback of purely learning-based methods, however,\nis that they cannot provide provable guarantees for the trained network to\nfollow a given data formation process during inference. In this work we propose\nenergy dissipating networks that iteratively compute a descent direction with\nrespect to a given cost function or energy at the currently estimated\nreconstruction. Therefore, an adaptive step size rule such as a line-search,\nalong with a suitable number of iterations can guarantee the reconstruction to\nfollow a given data formation model encoded in the energy to arbitrary\nprecision, and hence control the model's behavior even during test time. We\nprove that under standard assumptions, descent using the direction predicted by\nthe network converges (linearly) to the global minimum of the energy. We\nillustrate the effectiveness of the proposed approach in experiments on single\nimage super resolution and computed tomography (CT) reconstruction, and further\nillustrate extensions to convex feasibility problems.\n", "versions": [{"version": "v1", "created": "Fri, 5 Apr 2019 14:13:55 GMT"}, {"version": "v2", "created": "Tue, 20 Aug 2019 11:54:46 GMT"}], "update_date": "2019-08-21", "authors_parsed": [["Moeller", "Michael", ""], ["M\u00f6llenhoff", "Thomas", ""], ["Cremers", "Daniel", ""]]}, {"id": "1904.03084", "submitter": "Lukas Schmelzeisen", "authors": "Ipek Baris and Lukas Schmelzeisen and Steffen Staab", "title": "CLEARumor at SemEval-2019 Task 7: ConvoLving ELMo Against Rumors", "comments": "5 pages, 2 figures, 3 tables. Accepted for publication at\n  SemEval@NAACL-HLT 2019", "journal-ref": "SemEval@NAACL-HLT (2019) 1105-1109", "doi": "10.18653/v1/S19-2193", "report-no": null, "categories": "cs.CL cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper describes our submission to SemEval-2019 Task 7: RumourEval:\nDetermining Rumor Veracity and Support for Rumors. We participated in both\nsubtasks. The goal of subtask A is to classify the type of interaction between\na rumorous social media post and a reply post as support, query, deny, or\ncomment. The goal of subtask B is to predict the veracity of a given rumor. For\nsubtask A, we implement a CNN-based neural architecture using ELMo embeddings\nof post text combined with auxiliary features and achieve a F1-score of 44.6%.\nFor subtask B, we employ a MLP neural network leveraging our estimates for\nsubtask A and achieve a F1-score of 30.1% (second place in the competition). We\nprovide results and analysis of our system performance and present ablation\nexperiments.\n", "versions": [{"version": "v1", "created": "Fri, 5 Apr 2019 14:25:25 GMT"}], "update_date": "2020-11-30", "authors_parsed": [["Baris", "Ipek", ""], ["Schmelzeisen", "Lukas", ""], ["Staab", "Steffen", ""]]}, {"id": "1904.03090", "submitter": "Lucas Benigni", "authors": "Lucas Benigni, Sandrine P\\'ech\\'e", "title": "Eigenvalue distribution of nonlinear models of random matrices", "comments": "36 pages, 19 figures. Paper shortened (the behavior of the largest\n  eigenvalue is removed and postponed to another article after noticing an\n  error)", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.PR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper is concerned with the asymptotic empirical eigenvalue distribution\nof a non linear random matrix ensemble. More precisely we consider $M=\n\\frac{1}{m} YY^*$ with $Y=f(WX)$ where $W$ and $X$ are random rectangular\nmatrices with i.i.d. centered entries. The function $f$ is applied pointwise\nand can be seen as an activation function in (random) neural networks. We\ncompute the asymptotic empirical distribution of this ensemble in the case\nwhere $W$ and $X$ have sub-Gaussian tails and $f$ is real analytic. This\nextends a previous result where the case of Gaussian matrices $W$ and $X$ is\nconsidered. We also investigate the same questions in the multi-layer case,\nregarding neural network applications.\n", "versions": [{"version": "v1", "created": "Fri, 5 Apr 2019 14:39:35 GMT"}, {"version": "v2", "created": "Thu, 25 Apr 2019 12:31:47 GMT"}, {"version": "v3", "created": "Mon, 13 Jul 2020 21:36:37 GMT"}], "update_date": "2020-07-15", "authors_parsed": [["Benigni", "Lucas", ""], ["P\u00e9ch\u00e9", "Sandrine", ""]]}, {"id": "1904.03116", "submitter": "Yaser Souri", "authors": "Yaser Souri, Mohsen Fayyaz, Luca Minciullo, Gianpiero Francesca,\n  Juergen Gall", "title": "Fast Weakly Supervised Action Segmentation Using Mutual Consistency", "comments": "Accepted for publication at TPAMI (IEEE Transactions on Pattern\n  Analysis and Machine Intelligence) in 2021. First two authors contributed\n  equally", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Action segmentation is the task of predicting the actions for each frame of a\nvideo. As obtaining the full annotation of videos for action segmentation is\nexpensive, weakly supervised approaches that can learn only from transcripts\nare appealing. In this paper, we propose a novel end-to-end approach for weakly\nsupervised action segmentation based on a two-branch neural network. The two\nbranches of our network predict two redundant but different representations for\naction segmentation and we propose a novel mutual consistency (MuCon) loss that\nenforces the consistency of the two redundant representations. Using the MuCon\nloss together with a loss for transcript prediction, our proposed approach\nachieves the accuracy of state-of-the-art approaches while being $14$ times\nfaster to train and $20$ times faster during inference. The MuCon loss proves\nbeneficial even in the fully supervised setting.\n", "versions": [{"version": "v1", "created": "Fri, 5 Apr 2019 15:19:35 GMT"}, {"version": "v2", "created": "Tue, 3 Dec 2019 11:55:42 GMT"}, {"version": "v3", "created": "Mon, 16 Mar 2020 16:44:09 GMT"}, {"version": "v4", "created": "Thu, 10 Jun 2021 21:31:13 GMT"}], "update_date": "2021-06-14", "authors_parsed": [["Souri", "Yaser", ""], ["Fayyaz", "Mohsen", ""], ["Minciullo", "Luca", ""], ["Francesca", "Gianpiero", ""], ["Gall", "Juergen", ""]]}, {"id": "1904.03136", "submitter": "Cheng Mao", "authors": "Jan-Christian H\\\"utter, Cheng Mao, Philippe Rigollet and Elina Robeva", "title": "Estimation of Monge Matrices", "comments": "42 pages, 3 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST cs.IT cs.LG math.IT stat.ML stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Monge matrices and their permuted versions known as pre-Monge matrices\nnaturally appear in many domains across science and engineering. While the rich\nstructural properties of such matrices have long been leveraged for algorithmic\npurposes, little is known about their impact on statistical estimation. In this\nwork, we propose to view this structure as a shape constraint and study the\nproblem of estimating a Monge matrix subject to additive random noise. More\nspecifically, we establish the minimax rates of estimation of Monge and\npre-Monge matrices. In the case of pre-Monge matrices, the minimax-optimal\nleast-squares estimator is not efficiently computable, and we propose two\nefficient estimators and establish their rates of convergence. Our theoretical\nfindings are supported by numerical experiments.\n", "versions": [{"version": "v1", "created": "Fri, 5 Apr 2019 16:01:52 GMT"}], "update_date": "2019-04-08", "authors_parsed": [["H\u00fctter", "Jan-Christian", ""], ["Mao", "Cheng", ""], ["Rigollet", "Philippe", ""], ["Robeva", "Elina", ""]]}, {"id": "1904.03137", "submitter": "Oleksiy Ostapenko", "authors": "Oleksiy Ostapenko, Mihai Puscas, Tassilo Klein, Patrick J\\\"ahnichen,\n  Moin Nabi", "title": "Learning to Remember: A Synaptic Plasticity Driven Framework for\n  Continual Learning", "comments": "CVPR 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Models trained in the context of continual learning (CL) should be able to\nlearn from a stream of data over an undefined period of time. The main\nchallenges herein are: 1) maintaining old knowledge while simultaneously\nbenefiting from it when learning new tasks, and 2) guaranteeing model\nscalability with a growing amount of data to learn from. In order to tackle\nthese challenges, we introduce Dynamic Generative Memory (DGM) - a synaptic\nplasticity driven framework for continual learning. DGM relies on conditional\ngenerative adversarial networks with learnable connection plasticity realized\nwith neural masking. Specifically, we evaluate two variants of neural masking:\napplied to (i) layer activations and (ii) to connection weights directly.\nFurthermore, we propose a dynamic network expansion mechanism that ensures\nsufficient model capacity to accommodate for continually incoming tasks. The\namount of added capacity is determined dynamically from the learned binary\nmask. We evaluate DGM in the continual class-incremental setup on visual\nclassification tasks.\n", "versions": [{"version": "v1", "created": "Fri, 5 Apr 2019 16:02:15 GMT"}, {"version": "v2", "created": "Tue, 28 May 2019 07:23:22 GMT"}, {"version": "v3", "created": "Wed, 12 Jun 2019 16:28:09 GMT"}, {"version": "v4", "created": "Mon, 2 Dec 2019 14:46:07 GMT"}], "update_date": "2019-12-03", "authors_parsed": [["Ostapenko", "Oleksiy", ""], ["Puscas", "Mihai", ""], ["Klein", "Tassilo", ""], ["J\u00e4hnichen", "Patrick", ""], ["Nabi", "Moin", ""]]}, {"id": "1904.03170", "submitter": "Maoying Qiao", "authors": "Maoying Qiao, Wei Bian, Richard Yida Xu, Dacheng Tao", "title": "Diversified Hidden Markov Models for Sequential Labeling", "comments": "14 pages, 12 figures", "journal-ref": "IEEE Transactions on Knowledge and Data Engineering, 27 (2015)\n  2947 - 2960", "doi": "10.1109/TKDE.2015.2433262", "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Labeling of sequential data is a prevalent meta-problem for a wide range of\nreal world applications. While the first-order Hidden Markov Models (HMM)\nprovides a fundamental approach for unsupervised sequential labeling, the basic\nmodel does not show satisfying performance when it is directly applied to real\nworld problems, such as part-of-speech tagging (PoS tagging) and optical\ncharacter recognition (OCR). Aiming at improving performance, important\nextensions of HMM have been proposed in the literatures. One of the common key\nfeatures in these extensions is the incorporation of proper prior information.\nIn this paper, we propose a new extension of HMM, termed diversified Hidden\nMarkov Models (dHMM), which utilizes a diversity-encouraging prior over the\nstate-transition probabilities and thus facilitates more dynamic sequential\nlabellings. Specifically, the diversity is modeled by a continuous\ndeterminantal point process prior, which we apply to both unsupervised and\nsupervised scenarios. Learning and inference algorithms for dHMM are derived.\nEmpirical evaluations on benchmark datasets for unsupervised PoS tagging and\nsupervised OCR confirmed the effectiveness of dHMM, with competitive\nperformance to the state-of-the-art.\n", "versions": [{"version": "v1", "created": "Fri, 5 Apr 2019 17:37:40 GMT"}], "update_date": "2019-04-08", "authors_parsed": [["Qiao", "Maoying", ""], ["Bian", "Wei", ""], ["Xu", "Richard Yida", ""], ["Tao", "Dacheng", ""]]}, {"id": "1904.03172", "submitter": "Alexander Shvets", "authors": "Alexander Shvets", "title": "Improving Scientific Article Visibility by Neural Title Simplification", "comments": "Contribution to the Proceedings of the 8th International Workshop on\n  Bibliometric-enhanced Information Retrieval (BIR 2019) as part of the 41th\n  European Conference on Information Retrieval (ECIR 2019), Cologne, Germany,\n  April 14, 2019. CEUR Workshop Proceedings, CEUR-WS.org 2019. Keywords:\n  Scientific Text Summarization, Machine Translation, Recommender Systems,\n  Personalized Simplification", "journal-ref": "Proceedings of the 8th International Workshop on\n  Bibliometric-enhanced Information Retrieval (BIR) co-located with ECIR 2019,\n  Cologne, Germany (pp. 140-147)", "doi": null, "report-no": null, "categories": "cs.IR cs.CL cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  The rapidly growing amount of data that scientific content providers should\ndeliver to a user makes them create effective recommendation tools. A title of\nan article is often the only shown element to attract people's attention. We\noffer an approach to automatic generating titles with various levels of\ninformativeness to benefit from different categories of users. Statistics from\nResearchGate used to bias train datasets and specially designed post-processing\nstep applied to neural sequence-to-sequence models allow reaching the desired\nvariety of simplified titles to gain a trade-off between the attractiveness and\ntransparency of recommendation.\n", "versions": [{"version": "v1", "created": "Fri, 5 Apr 2019 17:44:12 GMT"}], "update_date": "2020-08-27", "authors_parsed": [["Shvets", "Alexander", ""]]}, {"id": "1904.03177", "submitter": "Jessica Hamrick", "authors": "Victor Bapst, Alvaro Sanchez-Gonzalez, Carl Doersch, Kimberly L.\n  Stachenfeld, Pushmeet Kohli, Peter W. Battaglia, Jessica B. Hamrick", "title": "Structured agents for physical construction", "comments": "ICML 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Physical construction---the ability to compose objects, subject to physical\ndynamics, to serve some function---is fundamental to human intelligence. We\nintroduce a suite of challenging physical construction tasks inspired by how\nchildren play with blocks, such as matching a target configuration, stacking\nblocks to connect objects together, and creating shelter-like structures over\ntarget objects. We examine how a range of deep reinforcement learning agents\nfare on these challenges, and introduce several new approaches which provide\nsuperior performance. Our results show that agents which use structured\nrepresentations (e.g., objects and scene graphs) and structured policies (e.g.,\nobject-centric actions) outperform those which use less structured\nrepresentations, and generalize better beyond their training when asked to\nreason about larger scenes. Model-based agents which use Monte-Carlo Tree\nSearch also outperform strictly model-free agents in our most challenging\nconstruction problems. We conclude that approaches which combine structured\nrepresentations and reasoning with powerful learning are a key path toward\nagents that possess rich intuitive physics, scene understanding, and planning.\n", "versions": [{"version": "v1", "created": "Fri, 5 Apr 2019 17:52:35 GMT"}, {"version": "v2", "created": "Mon, 13 May 2019 11:51:04 GMT"}], "update_date": "2019-05-14", "authors_parsed": [["Bapst", "Victor", ""], ["Sanchez-Gonzalez", "Alvaro", ""], ["Doersch", "Carl", ""], ["Stachenfeld", "Kimberly L.", ""], ["Kohli", "Pushmeet", ""], ["Battaglia", "Peter W.", ""], ["Hamrick", "Jessica B.", ""]]}, {"id": "1904.03178", "submitter": "Joseph Early", "authors": "Joseph Early", "title": "Reducing catastrophic forgetting when evolving neural networks", "comments": "14 pages, 5 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A key stepping stone in the development of an artificial general intelligence\n(a machine that can perform any task), is the production of agents that can\nperform multiple tasks at once instead of just one. Unfortunately, canonical\nmethods are very prone to catastrophic forgetting (CF) - the act of overwriting\nprevious knowledge about a task when learning a new task. Recent efforts have\ndeveloped techniques for overcoming CF in learning systems, but no attempt has\nbeen made to apply these new techniques to evolutionary systems. This research\npresents a novel technique, weight protection, for reducing CF in evolutionary\nsystems by adapting a method from learning systems. It is used in conjunction\nwith other evolutionary approaches for overcoming CF and is shown to be\neffective at alleviating CF when applied to a suite of reinforcement learning\ntasks. It is speculated that this work could indicate the potential for a wider\napplication of existing learning-based approaches to evolutionary systems and\nthat evolutionary techniques may be competitive with or better than learning\nsystems when it comes to reducing CF.\n", "versions": [{"version": "v1", "created": "Fri, 5 Apr 2019 17:57:29 GMT"}], "update_date": "2019-04-08", "authors_parsed": [["Early", "Joseph", ""]]}, {"id": "1904.03182", "submitter": "Valentin Peretroukhin", "authors": "Valentin Peretroukhin, Brandon Wagstaff, Matthew Giamou and Jonathan\n  Kelly", "title": "Probabilistic Regression of Rotations using Quaternion Averaging and a\n  Deep Multi-Headed Network", "comments": "A shortened version of this work appears in the Proceedings of the\n  IEEE Conference on Computer Vision and Pattern Recognition (CVPR'19) Workshop\n  on Uncertainty and Robustness in Deep Visual Learning, Long Beach,\n  California, USA, Jun. 16-20 2019, pp. 83-86", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG cs.RO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Accurate estimates of rotation are crucial to vision-based motion estimation\nin augmented reality and robotics. In this work, we present a method to extract\nprobabilistic estimates of rotation from deep regression models. First, we\nbuild on prior work and argue that a multi-headed network structure we name\nHydraNet provides better calibrated uncertainty estimates than methods that\nrely on stochastic forward passes. Second, we extend HydraNet to targets that\nbelong to the rotation group, SO(3), by regressing unit quaternions and using\nthe tools of rotation averaging and uncertainty injection onto the manifold to\nproduce three-dimensional covariances. Finally, we present results and analysis\non a synthetic dataset, learn consistent orientation estimates on the 7-Scenes\ndataset, and show how we can use our learned covariances to fuse deep estimates\nof relative orientation with classical stereo visual odometry to improve\nlocalization on the KITTI dataset.\n", "versions": [{"version": "v1", "created": "Mon, 1 Apr 2019 19:39:09 GMT"}, {"version": "v2", "created": "Fri, 8 May 2020 16:27:56 GMT"}], "update_date": "2020-05-11", "authors_parsed": [["Peretroukhin", "Valentin", ""], ["Wagstaff", "Brandon", ""], ["Giamou", "Matthew", ""], ["Kelly", "Jonathan", ""]]}, {"id": "1904.03240", "submitter": "Yu-An Chung", "authors": "Yu-An Chung and Wei-Ning Hsu and Hao Tang and James Glass", "title": "An Unsupervised Autoregressive Model for Speech Representation Learning", "comments": "Accepted to Interspeech 2019. Code available at:\n  https://github.com/iamyuanchung/Autoregressive-Predictive-Coding", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG cs.SD eess.AS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper proposes a novel unsupervised autoregressive neural model for\nlearning generic speech representations. In contrast to other speech\nrepresentation learning methods that aim to remove noise or speaker\nvariabilities, ours is designed to preserve information for a wide range of\ndownstream tasks. In addition, the proposed model does not require any phonetic\nor word boundary labels, allowing the model to benefit from large quantities of\nunlabeled data. Speech representations learned by our model significantly\nimprove performance on both phone classification and speaker verification over\nthe surface features and other supervised and unsupervised approaches. Further\nanalysis shows that different levels of speech information are captured by our\nmodel at different layers. In particular, the lower layers tend to be more\ndiscriminative for speakers, while the upper layers provide more phonetic\ncontent.\n", "versions": [{"version": "v1", "created": "Fri, 5 Apr 2019 19:04:19 GMT"}, {"version": "v2", "created": "Wed, 19 Jun 2019 03:27:39 GMT"}], "update_date": "2019-06-20", "authors_parsed": [["Chung", "Yu-An", ""], ["Hsu", "Wei-Ning", ""], ["Tang", "Hao", ""], ["Glass", "James", ""]]}, {"id": "1904.03241", "submitter": "Markus N Rabe", "authors": "Kshitij Bansal, Sarah M. Loos, Markus N. Rabe, Christian Szegedy, and\n  Stewart Wilcox", "title": "HOList: An Environment for Machine Learning of Higher-Order Theorem\n  Proving", "comments": "Accepted at ICML 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present an environment, benchmark, and deep learning driven automated\ntheorem prover for higher-order logic. Higher-order interactive theorem provers\nenable the formalization of arbitrary mathematical theories and thereby present\nan interesting, open-ended challenge for deep learning. We provide an\nopen-source framework based on the HOL Light theorem prover that can be used as\na reinforcement learning environment. HOL Light comes with a broad coverage of\nbasic mathematical theorems on calculus and the formal proof of the Kepler\nconjecture, from which we derive a challenging benchmark for automated\nreasoning. We also present a deep reinforcement learning driven automated\ntheorem prover, DeepHOL, with strong initial results on this benchmark.\n", "versions": [{"version": "v1", "created": "Fri, 5 Apr 2019 19:04:33 GMT"}, {"version": "v2", "created": "Fri, 24 May 2019 00:08:20 GMT"}, {"version": "v3", "created": "Fri, 1 Nov 2019 20:16:27 GMT"}], "update_date": "2019-11-05", "authors_parsed": [["Bansal", "Kshitij", ""], ["Loos", "Sarah M.", ""], ["Rabe", "Markus N.", ""], ["Szegedy", "Christian", ""], ["Wilcox", "Stewart", ""]]}, {"id": "1904.03246", "submitter": "Xin Zhang", "authors": "Xin Zhang and Zhengyuan Zhu", "title": "Spatial CUSUM for Signal Region Detection", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ME cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Detecting weak clustered signal in spatial data is important but challenging\nin applications such as medical image and epidemiology. A more efficient\ndetection algorithm can provide more precise early warning, and effectively\nreduce the decision risk and cost. To date, many methods have been developed to\ndetect signals with spatial structures. However, most of the existing methods\nare either too conservative for weak signals or computationally too intensive.\nIn this paper, we consider a novel method named Spatial CUSUM (SCUSUM), which\nemploys the idea of the CUSUM procedure and false discovery rate controlling.\nWe develop theoretical properties of the method which indicates that\nasymptotically SCUSUM can reach high classification accuracy. In the simulation\nstudy, we demonstrate that SCUSUM is sensitive to weak spatial signals. This\nnew method is applied to a real fMRI dataset as illustration, and more\nirregular weak spatial signals are detected in the images compared to some\nexisting methods, including the conventional FDR, FDR$_L$ and scan statistics.\n", "versions": [{"version": "v1", "created": "Fri, 5 Apr 2019 19:25:11 GMT"}], "update_date": "2019-04-09", "authors_parsed": [["Zhang", "Xin", ""], ["Zhu", "Zhengyuan", ""]]}, {"id": "1904.03257", "submitter": "Alexander Ratner", "authors": "Alexander Ratner, Dan Alistarh, Gustavo Alonso, David G. Andersen,\n  Peter Bailis, Sarah Bird, Nicholas Carlini, Bryan Catanzaro, Jennifer Chayes,\n  Eric Chung, Bill Dally, Jeff Dean, Inderjit S. Dhillon, Alexandros Dimakis,\n  Pradeep Dubey, Charles Elkan, Grigori Fursin, Gregory R. Ganger, Lise Getoor,\n  Phillip B. Gibbons, Garth A. Gibson, Joseph E. Gonzalez, Justin Gottschlich,\n  Song Han, Kim Hazelwood, Furong Huang, Martin Jaggi, Kevin Jamieson, Michael\n  I. Jordan, Gauri Joshi, Rania Khalaf, Jason Knight, Jakub Kone\\v{c}n\\'y, Tim\n  Kraska, Arun Kumar, Anastasios Kyrillidis, Aparna Lakshmiratan, Jing Li,\n  Samuel Madden, H. Brendan McMahan, Erik Meijer, Ioannis Mitliagkas, Rajat\n  Monga, Derek Murray, Kunle Olukotun, Dimitris Papailiopoulos, Gennady\n  Pekhimenko, Theodoros Rekatsinas, Afshin Rostamizadeh, Christopher R\\'e,\n  Christopher De Sa, Hanie Sedghi, Siddhartha Sen, Virginia Smith, Alex Smola,\n  Dawn Song, Evan Sparks, Ion Stoica, Vivienne Sze, Madeleine Udell, Joaquin\n  Vanschoren, Shivaram Venkataraman, Rashmi Vinayak, Markus Weimer, Andrew\n  Gordon Wilson, Eric Xing, Matei Zaharia, Ce Zhang, Ameet Talwalkar", "title": "MLSys: The New Frontier of Machine Learning Systems", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.DB cs.DC cs.SE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Machine learning (ML) techniques are enjoying rapidly increasing adoption.\nHowever, designing and implementing the systems that support ML models in\nreal-world deployments remains a significant obstacle, in large part due to the\nradically different development and deployment profile of modern ML methods,\nand the range of practical concerns that come with broader adoption. We propose\nto foster a new systems machine learning research community at the intersection\nof the traditional systems and ML communities, focused on topics such as\nhardware systems for ML, software systems for ML, and ML optimized for metrics\nbeyond predictive accuracy. To do this, we describe a new conference, MLSys,\nthat explicitly targets research at the intersection of systems and machine\nlearning with a program committee split evenly between experts in systems and\nML, and an explicit focus on topics at the intersection of the two.\n", "versions": [{"version": "v1", "created": "Fri, 29 Mar 2019 12:43:36 GMT"}, {"version": "v2", "created": "Wed, 1 May 2019 04:55:56 GMT"}, {"version": "v3", "created": "Sun, 1 Dec 2019 20:27:06 GMT"}], "update_date": "2019-12-03", "authors_parsed": [["Ratner", "Alexander", ""], ["Alistarh", "Dan", ""], ["Alonso", "Gustavo", ""], ["Andersen", "David G.", ""], ["Bailis", "Peter", ""], ["Bird", "Sarah", ""], ["Carlini", "Nicholas", ""], ["Catanzaro", "Bryan", ""], ["Chayes", "Jennifer", ""], ["Chung", "Eric", ""], ["Dally", "Bill", ""], ["Dean", "Jeff", ""], ["Dhillon", "Inderjit S.", ""], ["Dimakis", "Alexandros", ""], ["Dubey", "Pradeep", ""], ["Elkan", "Charles", ""], ["Fursin", "Grigori", ""], ["Ganger", "Gregory R.", ""], ["Getoor", "Lise", ""], ["Gibbons", "Phillip B.", ""], ["Gibson", "Garth A.", ""], ["Gonzalez", "Joseph E.", ""], ["Gottschlich", "Justin", ""], ["Han", "Song", ""], ["Hazelwood", "Kim", ""], ["Huang", "Furong", ""], ["Jaggi", "Martin", ""], ["Jamieson", "Kevin", ""], ["Jordan", "Michael I.", ""], ["Joshi", "Gauri", ""], ["Khalaf", "Rania", ""], ["Knight", "Jason", ""], ["Kone\u010dn\u00fd", "Jakub", ""], ["Kraska", "Tim", ""], ["Kumar", "Arun", ""], ["Kyrillidis", "Anastasios", ""], ["Lakshmiratan", "Aparna", ""], ["Li", "Jing", ""], ["Madden", "Samuel", ""], ["McMahan", "H. Brendan", ""], ["Meijer", "Erik", ""], ["Mitliagkas", "Ioannis", ""], ["Monga", "Rajat", ""], ["Murray", "Derek", ""], ["Olukotun", "Kunle", ""], ["Papailiopoulos", "Dimitris", ""], ["Pekhimenko", "Gennady", ""], ["Rekatsinas", "Theodoros", ""], ["Rostamizadeh", "Afshin", ""], ["R\u00e9", "Christopher", ""], ["De Sa", "Christopher", ""], ["Sedghi", "Hanie", ""], ["Sen", "Siddhartha", ""], ["Smith", "Virginia", ""], ["Smola", "Alex", ""], ["Song", "Dawn", ""], ["Sparks", "Evan", ""], ["Stoica", "Ion", ""], ["Sze", "Vivienne", ""], ["Udell", "Madeleine", ""], ["Vanschoren", "Joaquin", ""], ["Venkataraman", "Shivaram", ""], ["Vinayak", "Rashmi", ""], ["Weimer", "Markus", ""], ["Wilson", "Andrew Gordon", ""], ["Xing", "Eric", ""], ["Zaharia", "Matei", ""], ["Zhang", "Ce", ""], ["Talwalkar", "Ameet", ""]]}, {"id": "1904.03259", "submitter": "Stephen Odaibo", "authors": "Stephen G. Odaibo", "title": "Is 'Unsupervised Learning' a Misconceived Term?", "comments": "9 pages, 3 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Is all of machine learning supervised to some degree? The field of machine\nlearning has traditionally been categorized pedagogically into\n$supervised~vs~unsupervised~learning$; where supervised learning has typically\nreferred to learning from labeled data, while unsupervised learning has\ntypically referred to learning from unlabeled data. In this paper, we assert\nthat all machine learning is in fact supervised to some degree, and that the\nscope of supervision is necessarily commensurate to the scope of learning\npotential. In particular, we argue that clustering algorithms such as k-means,\nand dimensionality reduction algorithms such as principal component analysis,\nvariational autoencoders, and deep belief networks are each internally\nsupervised by the data itself to learn their respective representations of its\nfeatures. Furthermore, these algorithms are not capable of external inference\nuntil their respective outputs (clusters, principal components, or\nrepresentation codes) have been identified and externally labeled in effect. As\nsuch, they do not suffice as examples of unsupervised learning. We propose that\nthe categorization `supervised vs unsupervised learning' be dispensed with, and\ninstead, learning algorithms be categorized as either\n$internally~or~externally~supervised$ (or both). We believe this change in\nperspective will yield new fundamental insights into the structure and\ncharacter of data and of learning algorithms.\n", "versions": [{"version": "v1", "created": "Fri, 5 Apr 2019 20:05:46 GMT"}], "update_date": "2019-04-09", "authors_parsed": [["Odaibo", "Stephen G.", ""]]}, {"id": "1904.03272", "submitter": "Brendan Ames", "authors": "Polina Bombina, Brendan Ames", "title": "Convex optimization for the densest subgraph and densest submatrix\n  problems", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.OC cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the densest $k$-subgraph problem, which seeks to identify the\n$k$-node subgraph of a given input graph with maximum number of edges. This\nproblem is well-known to be NP-hard, by reduction to the maximum clique\nproblem. We propose a new convex relaxation for the densest $k$-subgraph\nproblem, based on a nuclear norm relaxation of a low-rank plus sparse\ndecomposition of the adjacency matrices of $k$-node subgraphs to partially\naddress this intractability. We establish that the densest $k$-subgraph can be\nrecovered with high probability from the optimal solution of this convex\nrelaxation if the input graph is randomly sampled from a distribution of random\ngraphs constructed to contain an especially dense $k$-node subgraph with high\nprobability. Specifically, the relaxation is exact when the edges of the input\ngraph are added independently at random, with edges within a particular\n$k$-node subgraph added with higher probability than other edges in the graph.\nWe provide a sufficient condition on the size of this subgraph $k$ and the\nexpected density under which the optimal solution of the proposed relaxation\nrecovers this $k$-node subgraph with high probability. Further, we propose a\nfirst-order method for solving this relaxation based on the alternating\ndirection method of multipliers, and empirically confirm our predicted recovery\nthresholds using simulations involving randomly generated graphs, as well as\ngraphs drawn from social and collaborative networks.\n", "versions": [{"version": "v1", "created": "Fri, 5 Apr 2019 20:47:07 GMT"}], "update_date": "2019-04-09", "authors_parsed": [["Bombina", "Polina", ""], ["Ames", "Brendan", ""]]}, {"id": "1904.03273", "submitter": "Nazanin Mehrasa", "authors": "Nazanin Mehrasa, Akash Abdu Jyothi, Thibaut Durand, Jiawei He, Leonid\n  Sigal, Greg Mori", "title": "A Variational Auto-Encoder Model for Stochastic Point Processes", "comments": "CVPR 19", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a novel probabilistic generative model for action sequences. The\nmodel is termed the Action Point Process VAE (APP-VAE), a variational\nauto-encoder that can capture the distribution over the times and categories of\naction sequences. Modeling the variety of possible action sequences is a\nchallenge, which we show can be addressed via the APP-VAE's use of latent\nrepresentations and non-linear functions to parameterize distributions over\nwhich event is likely to occur next in a sequence and at what time. We\nempirically validate the efficacy of APP-VAE for modeling action sequences on\nthe MultiTHUMOS and Breakfast datasets.\n", "versions": [{"version": "v1", "created": "Fri, 5 Apr 2019 20:49:16 GMT"}], "update_date": "2019-04-09", "authors_parsed": [["Mehrasa", "Nazanin", ""], ["Jyothi", "Akash Abdu", ""], ["Durand", "Thibaut", ""], ["He", "Jiawei", ""], ["Sigal", "Leonid", ""], ["Mori", "Greg", ""]]}, {"id": "1904.03275", "submitter": "Tyler Maunu", "authors": "Tyler Maunu, Gilad Lerman", "title": "Robust Subspace Recovery with Adversarial Outliers", "comments": "21 pages, 1 table", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG math.OC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the problem of robust subspace recovery (RSR) in the presence of\nadversarial outliers. That is, we seek a subspace that contains a large portion\nof a dataset when some fraction of the data points are arbitrarily corrupted.\nWe first examine a theoretical estimator that is intractable to calculate and\nuse it to derive information-theoretic bounds of exact recovery. We then\npropose two tractable estimators: a variant of RANSAC and a simple relaxation\nof the theoretical estimator. The two estimators are fast to compute and\nachieve state-of-the-art theoretical performance in a noiseless RSR setting\nwith adversarial outliers. The former estimator achieves better theoretical\nguarantees in the noiseless case, while the latter estimator is robust to small\nnoise, and its guarantees significantly improve with non-adversarial models of\noutliers. We give a complete comparison of guarantees for the adversarial RSR\nproblem, as well as a short discussion on the estimation of affine subspaces.\n", "versions": [{"version": "v1", "created": "Fri, 5 Apr 2019 21:00:04 GMT"}], "update_date": "2019-04-09", "authors_parsed": [["Maunu", "Tyler", ""], ["Lerman", "Gilad", ""]]}, {"id": "1904.03276", "submitter": "Hexiang Hu", "authors": "Hexiang Hu, Liyu Chen, Boqing Gong, Fei Sha", "title": "Synthesized Policies for Transfer and Adaptation across Tasks and\n  Environments", "comments": "presented at NeurIPS 2018 as a Spotlight", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  The ability to transfer in reinforcement learning is key towards building an\nagent of general artificial intelligence. In this paper, we consider the\nproblem of learning to simultaneously transfer across both environments (ENV)\nand tasks (TASK), probably more importantly, by learning from only sparse (ENV,\nTASK) pairs out of all the possible combinations. We propose a novel\ncompositional neural network architecture which depicts a meta rule for\ncomposing policies from the environment and task embeddings. Notably, one of\nthe main challenges is to learn the embeddings jointly with the meta rule. We\nfurther propose new training methods to disentangle the embeddings, making them\nboth distinctive signatures of the environments and tasks and effective\nbuilding blocks for composing the policies. Experiments on GridWorld and Thor,\nof which the agent takes as input an egocentric view, show that our approach\ngives rise to high success rates on all the (ENV, TASK) pairs after learning\nfrom only 40% of them.\n", "versions": [{"version": "v1", "created": "Fri, 5 Apr 2019 21:00:07 GMT"}, {"version": "v2", "created": "Wed, 26 May 2021 22:23:51 GMT"}], "update_date": "2021-05-28", "authors_parsed": [["Hu", "Hexiang", ""], ["Chen", "Liyu", ""], ["Gong", "Boqing", ""], ["Sha", "Fei", ""]]}, {"id": "1904.03288", "submitter": "Jason Li", "authors": "Jason Li, Vitaly Lavrukhin, Boris Ginsburg, Ryan Leary, Oleksii\n  Kuchaiev, Jonathan M. Cohen, Huyen Nguyen, Ravi Teja Gadde", "title": "Jasper: An End-to-End Convolutional Neural Acoustic Model", "comments": "Accepted to INTERSPEECH 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.AS cs.CL cs.LG cs.SD", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we report state-of-the-art results on LibriSpeech among\nend-to-end speech recognition models without any external training data. Our\nmodel, Jasper, uses only 1D convolutions, batch normalization, ReLU, dropout,\nand residual connections. To improve training, we further introduce a new\nlayer-wise optimizer called NovoGrad. Through experiments, we demonstrate that\nthe proposed deep architecture performs as well or better than more complex\nchoices. Our deepest Jasper variant uses 54 convolutional layers. With this\narchitecture, we achieve 2.95% WER using a beam-search decoder with an external\nneural language model and 3.86% WER with a greedy decoder on LibriSpeech\ntest-clean. We also report competitive results on the Wall Street Journal and\nthe Hub5'00 conversational evaluation datasets.\n", "versions": [{"version": "v1", "created": "Fri, 5 Apr 2019 21:35:44 GMT"}, {"version": "v2", "created": "Thu, 27 Jun 2019 20:13:21 GMT"}, {"version": "v3", "created": "Tue, 27 Aug 2019 00:02:28 GMT"}], "update_date": "2019-08-28", "authors_parsed": [["Li", "Jason", ""], ["Lavrukhin", "Vitaly", ""], ["Ginsburg", "Boris", ""], ["Leary", "Ryan", ""], ["Kuchaiev", "Oleksii", ""], ["Cohen", "Jonathan M.", ""], ["Nguyen", "Huyen", ""], ["Gadde", "Ravi Teja", ""]]}, {"id": "1904.03292", "submitter": "Alessandro Achille", "authors": "Alessandro Achille, Giovanni Paolini, Glen Mbeng, Stefano Soatto", "title": "The Information Complexity of Learning Tasks, their Structure and their\n  Distance", "comments": null, "journal-ref": null, "doi": null, "report-no": "UCLA CSD180003", "categories": "cs.LG cs.IT math.IT stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce an asymmetric distance in the space of learning tasks, and a\nframework to compute their complexity. These concepts are foundational for the\npractice of transfer learning, whereby a parametric model is pre-trained for a\ntask, and then fine-tuned for another. The framework we develop is\nnon-asymptotic, captures the finite nature of the training dataset, and allows\ndistinguishing learning from memorization. It encompasses, as special cases,\nclassical notions from Kolmogorov complexity, Shannon, and Fisher Information.\nHowever, unlike some of those frameworks, it can be applied to large-scale\nmodels and real-world datasets. Our framework is the first to measure\ncomplexity in a way that accounts for the effect of the optimization scheme,\nwhich is critical in Deep Learning.\n", "versions": [{"version": "v1", "created": "Fri, 5 Apr 2019 21:46:27 GMT"}, {"version": "v2", "created": "Tue, 14 Jul 2020 15:50:02 GMT"}], "update_date": "2020-07-15", "authors_parsed": [["Achille", "Alessandro", ""], ["Paolini", "Giovanni", ""], ["Mbeng", "Glen", ""], ["Soatto", "Stefano", ""]]}, {"id": "1904.03293", "submitter": "Chao Tao", "authors": "Chao Tao, Qin Zhang, Yuan Zhou", "title": "Collaborative Learning with Limited Interaction: Tight Bounds for\n  Distributed Exploration in Multi-Armed Bandits", "comments": "33 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.IT math.IT stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Best arm identification (or, pure exploration) in multi-armed bandits is a\nfundamental problem in machine learning. In this paper we study the distributed\nversion of this problem where we have multiple agents, and they want to learn\nthe best arm collaboratively. We want to quantify the power of collaboration\nunder limited interaction (or, communication steps), as interaction is\nexpensive in many settings. We measure the running time of a distributed\nalgorithm as the speedup over the best centralized algorithm where there is\nonly one agent. We give almost tight round-speedup tradeoffs for this problem,\nalong which we develop several new techniques for proving lower bounds on the\nnumber of communication steps under time or confidence constraints.\n", "versions": [{"version": "v1", "created": "Fri, 5 Apr 2019 21:48:19 GMT"}, {"version": "v2", "created": "Fri, 30 Aug 2019 01:16:26 GMT"}], "update_date": "2019-09-02", "authors_parsed": [["Tao", "Chao", ""], ["Zhang", "Qin", ""], ["Zhou", "Yuan", ""]]}, {"id": "1904.03295", "submitter": "Ishan Durugkar", "authors": "Ishan Durugkar, Matthew Hausknecht, Adith Swaminathan, Patrick\n  MacAlpine", "title": "Multi-Preference Actor Critic", "comments": "NeurIPS Workshop on Deep RL, 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Policy gradient algorithms typically combine discounted future rewards with\nan estimated value function, to compute the direction and magnitude of\nparameter updates. However, for most Reinforcement Learning tasks, humans can\nprovide additional insight to constrain the policy learning. We introduce a\ngeneral method to incorporate multiple different feedback channels into a\nsingle policy gradient loss. In our formulation, the Multi-Preference Actor\nCritic (M-PAC), these different types of feedback are implemented as\nconstraints on the policy. We use a Lagrangian relaxation to satisfy these\nconstraints using gradient descent while learning a policy that maximizes\nrewards. Experiments in Atari and Pendulum verify that constraints are being\nrespected and can accelerate the learning process.\n", "versions": [{"version": "v1", "created": "Fri, 5 Apr 2019 21:50:50 GMT"}], "update_date": "2019-04-09", "authors_parsed": [["Durugkar", "Ishan", ""], ["Hausknecht", "Matthew", ""], ["Swaminathan", "Adith", ""], ["MacAlpine", "Patrick", ""]]}, {"id": "1904.03335", "submitter": "Nicolas Garcia Trillos", "authors": "Nicolas Garcia Trillos, Daniel Sanz-Alonso, Ruiyi Yang", "title": "Local Regularization of Noisy Point Clouds: Improved Global Geometric\n  Estimates and Data Analysis", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Several data analysis techniques employ similarity relationships between data\npoints to uncover the intrinsic dimension and geometric structure of the\nunderlying data-generating mechanism. In this paper we work under the model\nassumption that the data is made of random perturbations of feature vectors\nlying on a low-dimensional manifold. We study two questions: how to define the\nsimilarity relationship over noisy data points, and what is the resulting\nimpact of the choice of similarity in the extraction of global geometric\ninformation from the underlying manifold. We provide concrete mathematical\nevidence that using a local regularization of the noisy data to define the\nsimilarity improves the approximation of the hidden Euclidean distance between\nunperturbed points. Furthermore, graph-based objects constructed with the\nlocally regularized similarity function satisfy better error bounds in their\nrecovery of global geometric ones. Our theory is supported by numerical\nexperiments that demonstrate that the gain in geometric understanding\nfacilitated by local regularization translates into a gain in classification\naccuracy in simulated and real data.\n", "versions": [{"version": "v1", "created": "Sat, 6 Apr 2019 01:52:05 GMT"}], "update_date": "2019-04-09", "authors_parsed": [["Trillos", "Nicolas Garcia", ""], ["Sanz-Alonso", "Daniel", ""], ["Yang", "Ruiyi", ""]]}, {"id": "1904.03348", "submitter": "Abram Magner", "authors": "Abram Magner and Wojciech Szpankowski", "title": "Toward Universal Testing of Dynamic Network Models", "comments": "Accepted to the 31st International Conference on Algorithmic Learning\n  Theory", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG cs.SI math.PR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Numerous networks in the real world change over time, in the sense that nodes\nand edges enter and leave the networks. Various dynamic random graph models\nhave been proposed to explain the macroscopic properties of these systems and\nto provide a foundation for statistical inferences and predictions. It is of\ninterest to have a rigorous way to determine how well these models match\nobserved networks. We thus ask the following goodness of fit question: given a\nsequence of observations/snapshots of a growing random graph, along with a\ncandidate model M, can we determine whether the snapshots came from M or from\nsome arbitrary alternative model that is well-separated from M in some natural\nmetric? We formulate this problem precisely and boil it down to goodness of fit\ntesting for graph-valued, infinite-state Markov processes and exhibit and\nanalyze a universal test based on non-stationary sampling for a natural class\nof models.\n", "versions": [{"version": "v1", "created": "Sat, 6 Apr 2019 03:08:53 GMT"}, {"version": "v2", "created": "Thu, 13 Feb 2020 18:12:10 GMT"}], "update_date": "2020-02-14", "authors_parsed": [["Magner", "Abram", ""], ["Szpankowski", "Wojciech", ""]]}, {"id": "1904.03365", "submitter": "Yuan Gong", "authors": "Yuan Gong, Jian Yang, Jacob Huber, Mitchell MacKnight and Christian\n  Poellabauer", "title": "ReMASC: Realistic Replay Attack Corpus for Voice Controlled Systems", "comments": "To appear in Interspeech 2019. Data set available at\n  https://github.com/YuanGongND/ReMASC", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.LG cs.SD eess.AS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper introduces a new database of voice recordings with the goal of\nsupporting research on vulnerabilities and protection of voice-controlled\nsystems (VCSs). In contrast to prior efforts, the proposed database contains\nboth genuine voice commands and replayed recordings of such commands, collected\nin realistic VCSs usage scenarios and using modern voice assistant development\nkits. Specifically, the database contains recordings from four systems (each\nwith a different microphone array) in a variety of environmental conditions\nwith different forms of background noise and relative positions between speaker\nand device. To the best of our knowledge, this is the first publicly available\ndatabase that has been specifically designed for the protection of\nstate-of-the-art voice-controlled systems against various replay attacks in\nvarious conditions and environments.\n", "versions": [{"version": "v1", "created": "Sat, 6 Apr 2019 05:42:18 GMT"}, {"version": "v2", "created": "Tue, 2 Jul 2019 04:42:17 GMT"}], "update_date": "2019-07-03", "authors_parsed": [["Gong", "Yuan", ""], ["Yang", "Jian", ""], ["Huber", "Jacob", ""], ["MacKnight", "Mitchell", ""], ["Poellabauer", "Christian", ""]]}, {"id": "1904.03367", "submitter": "Anthony Manchin Mr.", "authors": "Anthony Manchin, Ehsan Abbasnejad, Anton van den Hengel", "title": "Reinforcement Learning with Attention that Works: A Self-Supervised\n  Approach", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Attention models have had a significant positive impact on deep learning\nacross a range of tasks. However previous attempts at integrating attention\nwith reinforcement learning have failed to produce significant improvements. We\npropose the first combination of self attention and reinforcement learning that\nis capable of producing significant improvements, including new state of the\nart results in the Arcade Learning Environment. Unlike the selective attention\nmodels used in previous attempts, which constrain the attention via\npreconceived notions of importance, our implementation utilises the Markovian\nproperties inherent in the state input. Our method produces a faithful\nvisualisation of the policy, focusing on the behaviour of the agent. Our\nexperiments demonstrate that the trained policies use multiple simultaneous\nfoci of attention, and are able to modulate attention over time to deal with\nsituations of partial observability.\n", "versions": [{"version": "v1", "created": "Sat, 6 Apr 2019 05:42:43 GMT"}], "update_date": "2019-04-09", "authors_parsed": [["Manchin", "Anthony", ""], ["Abbasnejad", "Ehsan", ""], ["Hengel", "Anton van den", ""]]}, {"id": "1904.03371", "submitter": "Ehsan Kamalloo", "authors": "Nouha Dziri, Ehsan Kamalloo, Kory W. Mathewson and Osmar Zaiane", "title": "Evaluating Coherence in Dialogue Systems using Entailment", "comments": "5 pages, 2 figures; NAACL-HLT 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Evaluating open-domain dialogue systems is difficult due to the diversity of\npossible correct answers. Automatic metrics such as BLEU correlate weakly with\nhuman annotations, resulting in a significant bias across different models and\ndatasets. Some researchers resort to human judgment experimentation for\nassessing response quality, which is expensive, time consuming, and not\nscalable. Moreover, judges tend to evaluate a small number of dialogues,\nmeaning that minor differences in evaluation configuration may lead to\ndissimilar results. In this paper, we present interpretable metrics for\nevaluating topic coherence by making use of distributed sentence\nrepresentations. Furthermore, we introduce calculable approximations of human\njudgment based on conversational coherence by adopting state-of-the-art\nentailment techniques. Results show that our metrics can be used as a surrogate\nfor human judgment, making it easy to evaluate dialogue systems on large-scale\ndatasets and allowing an unbiased estimate for the quality of the responses.\n", "versions": [{"version": "v1", "created": "Sat, 6 Apr 2019 06:06:11 GMT"}, {"version": "v2", "created": "Wed, 1 Apr 2020 01:19:52 GMT"}], "update_date": "2020-04-02", "authors_parsed": [["Dziri", "Nouha", ""], ["Kamalloo", "Ehsan", ""], ["Mathewson", "Kory W.", ""], ["Zaiane", "Osmar", ""]]}, {"id": "1904.03375", "submitter": "Jiancheng Yang", "authors": "Jiancheng Yang, Qiang Zhang, Bingbing Ni, Linguo Li, Jinxian Liu,\n  Mengdie Zhou, Qi Tian", "title": "Modeling Point Clouds with Self-Attention and Gumbel Subset Sampling", "comments": "CVPR'2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Geometric deep learning is increasingly important thanks to the popularity of\n3D sensors. Inspired by the recent advances in NLP domain, the self-attention\ntransformer is introduced to consume the point clouds. We develop Point\nAttention Transformers (PATs), using a parameter-efficient Group Shuffle\nAttention (GSA) to replace the costly Multi-Head Attention. We demonstrate its\nability to process size-varying inputs, and prove its permutation equivariance.\nBesides, prior work uses heuristics dependence on the input data (e.g.,\nFurthest Point Sampling) to hierarchically select subsets of input points.\nThereby, we for the first time propose an end-to-end learnable and\ntask-agnostic sampling operation, named Gumbel Subset Sampling (GSS), to select\na representative subset of input points. Equipped with Gumbel-Softmax, it\nproduces a \"soft\" continuous subset in training phase, and a \"hard\" discrete\nsubset in test phase. By selecting representative subsets in a hierarchical\nfashion, the networks learn a stronger representation of the input sets with\nlower computation cost. Experiments on classification and segmentation\nbenchmarks show the effectiveness and efficiency of our methods. Furthermore,\nwe propose a novel application, to process event camera stream as point clouds,\nand achieve a state-of-the-art performance on DVS128 Gesture Dataset.\n", "versions": [{"version": "v1", "created": "Sat, 6 Apr 2019 06:25:41 GMT"}], "update_date": "2019-04-09", "authors_parsed": [["Yang", "Jiancheng", ""], ["Zhang", "Qiang", ""], ["Ni", "Bingbing", ""], ["Li", "Linguo", ""], ["Liu", "Jinxian", ""], ["Zhou", "Mengdie", ""], ["Tian", "Qi", ""]]}, {"id": "1904.03391", "submitter": "Hazrat Ali", "authors": "Sulaiman Khan, Hazrat Ali, Zahid Ullah, Nasru Minallah, Shahid\n  Maqsood, Abdul Hafeez", "title": "KNN and ANN-based Recognition of Handwritten Pashto Letters using Zoning\n  Features", "comments": "(IJACSA) International Journal of Advanced Computer Science and\n  Applications,", "journal-ref": "International Journal of Advanced Computer Science and\n  Applications (IJACSA), 9(10), June 2018", "doi": "10.14569/IJACSA.2018.091070", "report-no": null, "categories": "cs.CV cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  This paper presents a recognition system for handwritten Pashto letters.\nHowever, handwritten character recognition is a challenging task. These letters\nnot only differ in shape and style but also vary among individuals. The\nrecognition becomes further daunting due to the lack of standard datasets for\ninscribed Pashto letters. In this work, we have designed a database of moderate\nsize, which encompasses a total of 4488 images, stemming from 102\ndistinguishing samples for each of the 44 letters in Pashto. The recognition\nframework uses zoning feature extractor followed by K-Nearest Neighbour (KNN)\nand Neural Network (NN) classifiers for classifying individual letter. Based on\nthe evaluation of the proposed system, an overall classification accuracy of\napproximately 70.05% is achieved by using KNN while 72% is achieved by using\nNN.\n", "versions": [{"version": "v1", "created": "Sat, 6 Apr 2019 09:10:55 GMT"}, {"version": "v2", "created": "Sat, 8 Jun 2019 15:49:26 GMT"}], "update_date": "2019-06-11", "authors_parsed": [["Khan", "Sulaiman", ""], ["Ali", "Hazrat", ""], ["Ullah", "Zahid", ""], ["Minallah", "Nasru", ""], ["Maqsood", "Shahid", ""], ["Hafeez", "Abdul", ""]]}, {"id": "1904.03392", "submitter": "Cai Shaofeng", "authors": "Shaofeng Cai, Yao Shu, Gang Chen, Beng Chin Ooi, Wei Wang, Meihui\n  Zhang", "title": "Effective and Efficient Dropout for Deep Convolutional Neural Networks", "comments": "12 pages, 10 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Convolutional Neural networks (CNNs) based applications have become\nubiquitous, where proper regularization is greatly needed. To prevent large\nneural network models from overfitting, dropout has been widely used as an\nefficient regularization technique in practice. However, many recent works show\nthat the standard dropout is ineffective or even detrimental to the training of\nCNNs. In this paper, we revisit this issue and examine various dropout variants\nin an attempt to improve existing dropout-based regularization techniques for\nCNNs. We attribute the failure of standard dropout to the conflict between the\nstochasticity of dropout and its following Batch Normalization (BN), and\npropose to reduce the conflict by placing dropout operations right before the\nconvolutional operation instead of BN, or totally address this issue by\nreplacing BN with Group Normalization (GN). We further introduce a structurally\nmore suited dropout variant Drop-Conv2d, which provides more efficient and\neffective regularization for deep CNNs. These dropout variants can be readily\nintegrated into the building blocks of CNNs and implemented in existing deep\nlearning platforms. Extensive experiments on benchmark datasets including\nCIFAR, SVHN and ImageNet are conducted to compare the existing building blocks\nand the proposed ones with dropout training. Results show that our building\nblocks improve over state-of-the-art CNNs significantly, which is mainly due to\nthe better regularization and implicit model ensemble effect.\n", "versions": [{"version": "v1", "created": "Sat, 6 Apr 2019 09:17:51 GMT"}, {"version": "v2", "created": "Mon, 22 Apr 2019 15:08:27 GMT"}, {"version": "v3", "created": "Thu, 24 Oct 2019 04:17:42 GMT"}, {"version": "v4", "created": "Wed, 17 Jun 2020 14:28:54 GMT"}, {"version": "v5", "created": "Tue, 28 Jul 2020 17:30:11 GMT"}], "update_date": "2020-07-29", "authors_parsed": [["Cai", "Shaofeng", ""], ["Shu", "Yao", ""], ["Chen", "Gang", ""], ["Ooi", "Beng Chin", ""], ["Wang", "Wei", ""], ["Zhang", "Meihui", ""]]}, {"id": "1904.03416", "submitter": "Santiago Pascual de la Puente", "authors": "Santiago Pascual, Mirco Ravanelli, Joan Serr\\`a, Antonio Bonafonte,\n  Yoshua Bengio", "title": "Learning Problem-agnostic Speech Representations from Multiple\n  Self-supervised Tasks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.SD eess.AS stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Learning good representations without supervision is still an open issue in\nmachine learning, and is particularly challenging for speech signals, which are\noften characterized by long sequences with a complex hierarchical structure.\nSome recent works, however, have shown that it is possible to derive useful\nspeech representations by employing a self-supervised encoder-discriminator\napproach. This paper proposes an improved self-supervised method, where a\nsingle neural encoder is followed by multiple workers that jointly solve\ndifferent self-supervised tasks. The needed consensus across different tasks\nnaturally imposes meaningful constraints to the encoder, contributing to\ndiscover general representations and to minimize the risk of learning\nsuperficial ones. Experiments show that the proposed approach can learn\ntransferable, robust, and problem-agnostic features that carry on relevant\ninformation from the speech signal, such as speaker identity, phonemes, and\neven higher-level features such as emotional cues. In addition, a number of\ndesign choices make the encoder easily exportable, facilitating its direct\nusage or adaptation to different problems.\n", "versions": [{"version": "v1", "created": "Sat, 6 Apr 2019 10:51:25 GMT"}], "update_date": "2019-04-09", "authors_parsed": [["Pascual", "Santiago", ""], ["Ravanelli", "Mirco", ""], ["Serr\u00e0", "Joan", ""], ["Bonafonte", "Antonio", ""], ["Bengio", "Yoshua", ""]]}, {"id": "1904.03418", "submitter": "Santiago Pascual de la Puente", "authors": "Santiago Pascual, Joan Serr\\`a, Antonio Bonafonte", "title": "Towards Generalized Speech Enhancement with Generative Adversarial\n  Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SD cs.LG eess.AS", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  The speech enhancement task usually consists of removing additive noise or\nreverberation that partially mask spoken utterances, affecting their\nintelligibility. However, little attention is drawn to other, perhaps more\naggressive signal distortions like clipping, chunk elimination, or\nfrequency-band removal. Such distortions can have a large impact not only on\nintelligibility, but also on naturalness or even speaker identity, and require\nof careful signal reconstruction. In this work, we give full consideration to\nthis generalized speech enhancement task, and show it can be tackled with a\ntime-domain generative adversarial network (GAN). In particular, we extend a\nprevious GAN-based speech enhancement system to deal with mixtures of four\ntypes of aggressive distortions. Firstly, we propose the addition of an\nadversarial acoustic regression loss that promotes a richer feature extraction\nat the discriminator. Secondly, we also make use of a two-step adversarial\ntraining schedule, acting as a warm up-and-fine-tune sequence. Both objective\nand subjective evaluations show that these two additions bring improved speech\nreconstructions that better match the original speaker identity and\nnaturalness.\n", "versions": [{"version": "v1", "created": "Sat, 6 Apr 2019 10:58:17 GMT"}], "update_date": "2019-04-09", "authors_parsed": [["Pascual", "Santiago", ""], ["Serr\u00e0", "Joan", ""], ["Bonafonte", "Antonio", ""]]}, {"id": "1904.03423", "submitter": "Tomasz Kajdanowicz", "authors": "Piotr Bielak, Kamil Tagowski, Maciej Falkiewicz, Tomasz Kajdanowicz,\n  Nitesh V. Chawla", "title": "FILDNE: A Framework for Incremental Learning of Dynamic Networks\n  Embeddings", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG cs.SI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Representation learning on graphs has emerged as a powerful mechanism to\nautomate feature vector generation for downstream machine learning tasks. The\nadvances in representation on graphs have centered on both homogeneous and\nheterogeneous graphs, where the latter presenting the challenges associated\nwith multi-typed nodes and/or edges. In this paper, we consider the additional\nchallenge of evolving graphs. We ask the question of whether the advances in\nrepresentation learning for static graphs can be leveraged for dynamic graphs\nand how? It is important to be able to incorporate those advances to maximize\nthe utility and generalization of methods. To that end, we propose the\nFramework for Incremental Learning of Dynamic Networks Embedding (FILDNE),\nwhich can utilize any existing static representation learning method for\nlearning node embeddings, while keeping the computational costs low. FILDNE\nintegrates the feature vectors computed using the standard methods over\ndifferent timesteps into a single representation by developing a convex\ncombination function and alignment mechanism. Experimental results on several\ndownstream tasks, over seven real-world data sets, show that FILDNE is able to\nreduce memory and computational time costs while providing competitive quality\nmeasure gains with respect to the contemporary methods for representation\nlearning on dynamic graphs.\n", "versions": [{"version": "v1", "created": "Sat, 6 Apr 2019 11:46:54 GMT"}, {"version": "v2", "created": "Thu, 19 Nov 2020 22:21:52 GMT"}], "update_date": "2020-11-23", "authors_parsed": [["Bielak", "Piotr", ""], ["Tagowski", "Kamil", ""], ["Falkiewicz", "Maciej", ""], ["Kajdanowicz", "Tomasz", ""], ["Chawla", "Nitesh V.", ""]]}, {"id": "1904.03438", "submitter": "Konrad Zolna", "authors": "Konrad Zolna, Negar Rostamzadeh, Yoshua Bengio, Sungjin Ahn, Pedro O.\n  Pinheiro", "title": "Reinforced Imitation in Heterogeneous Action Space", "comments": "The extended version of the work \"Reinforced Imitation Learning from\n  Observations\" presented on the NeurIPS workshop \"Imitation Learning and its\n  Challenges in Robotics\"", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Imitation learning is an effective alternative approach to learn a policy\nwhen the reward function is sparse. In this paper, we consider a challenging\nsetting where an agent and an expert use different actions from each other. We\nassume that the agent has access to a sparse reward function and state-only\nexpert observations. We propose a method which gradually balances between the\nimitation learning cost and the reinforcement learning objective. In addition,\nthis method adapts the agent's policy based on either mimicking expert behavior\nor maximizing sparse reward. We show, through navigation scenarios, that (i) an\nagent is able to efficiently leverage sparse rewards to outperform standard\nstate-only imitation learning, (ii) it can learn a policy even when its actions\nare different from the expert, and (iii) the performance of the agent is not\nbounded by that of the expert, due to the optimized usage of sparse rewards.\n", "versions": [{"version": "v1", "created": "Sat, 6 Apr 2019 13:07:12 GMT"}, {"version": "v2", "created": "Mon, 26 Aug 2019 15:26:06 GMT"}], "update_date": "2019-08-27", "authors_parsed": [["Zolna", "Konrad", ""], ["Rostamzadeh", "Negar", ""], ["Bengio", "Yoshua", ""], ["Ahn", "Sungjin", ""], ["Pinheiro", "Pedro O.", ""]]}, {"id": "1904.03441", "submitter": "Lei Huang", "authors": "Lei Huang, Yi Zhou, Fan Zhu, Li Liu and Ling Shao", "title": "Iterative Normalization: Beyond Standardization towards Efficient\n  Whitening", "comments": "Accepted to CVPR 2019. The Code is available at\n  https://github.com/huangleiBuaa/IterNorm", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Batch Normalization (BN) is ubiquitously employed for accelerating neural\nnetwork training and improving the generalization capability by performing\nstandardization within mini-batches. Decorrelated Batch Normalization (DBN)\nfurther boosts the above effectiveness by whitening. However, DBN relies\nheavily on either a large batch size, or eigen-decomposition that suffers from\npoor efficiency on GPUs. We propose Iterative Normalization (IterNorm), which\nemploys Newton's iterations for much more efficient whitening, while\nsimultaneously avoiding the eigen-decomposition. Furthermore, we develop a\ncomprehensive study to show IterNorm has better trade-off between optimization\nand generalization, with theoretical and experimental support. To this end, we\nexclusively introduce Stochastic Normalization Disturbance (SND), which\nmeasures the inherent stochastic uncertainty of samples when applied to\nnormalization operations. With the support of SND, we provide natural\nexplanations to several phenomena from the perspective of optimization, e.g.,\nwhy group-wise whitening of DBN generally outperforms full-whitening and why\nthe accuracy of BN degenerates with reduced batch sizes. We demonstrate the\nconsistently improved performance of IterNorm with extensive experiments on\nCIFAR-10 and ImageNet over BN and DBN.\n", "versions": [{"version": "v1", "created": "Sat, 6 Apr 2019 13:10:20 GMT"}], "update_date": "2019-04-09", "authors_parsed": [["Huang", "Lei", ""], ["Zhou", "Yi", ""], ["Zhu", "Fan", ""], ["Liu", "Li", ""], ["Shao", "Ling", ""]]}, {"id": "1904.03445", "submitter": "{\\L}ukasz Struski", "authors": "{\\L}ukasz Struski, Jacek Tabor, Igor Podolak, Aleksandra Nowak,\n  Krzysztof Maziarz", "title": "Realism Index: Interpolation in Generative Models With Arbitrary Prior", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In order to perform plausible interpolations in the latent space of a\ngenerative model, we need a measure that credibly reflects if a point in an\ninterpolation is close to the data manifold being modelled, i.e. if it is\nconvincing. In this paper, we introduce a realism index of a point, which can\nbe constructed from an arbitrary prior density, or based on FID score approach\nin case a prior is not available. We propose a numerically efficient algorithm\nthat directly maximises the realism index of an interpolation which, as we\ntheoretically prove, leads to a search of a geodesic with respect to the\ncorresponding Riemann structure. We show that we obtain better interpolations\nthen the classical linear ones, in particular when either the prior density is\nnot convex shaped, or when the soap bubble effect appears.\n", "versions": [{"version": "v1", "created": "Sat, 6 Apr 2019 13:47:48 GMT"}, {"version": "v2", "created": "Thu, 26 Sep 2019 19:27:18 GMT"}], "update_date": "2019-09-30", "authors_parsed": [["Struski", "\u0141ukasz", ""], ["Tabor", "Jacek", ""], ["Podolak", "Igor", ""], ["Nowak", "Aleksandra", ""], ["Maziarz", "Krzysztof", ""]]}, {"id": "1904.03446", "submitter": "Hao Sun", "authors": "Hao Sun, Xu Tan, Jun-Wei Gan, Hongzhi Liu, Sheng Zhao, Tao Qin and\n  Tie-Yan Liu", "title": "Token-Level Ensemble Distillation for Grapheme-to-Phoneme Conversion", "comments": "5 pages, accepted by interspeech 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG cs.SD eess.AS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Grapheme-to-phoneme (G2P) conversion is an important task in automatic speech\nrecognition and text-to-speech systems. Recently, G2P conversion is viewed as a\nsequence to sequence task and modeled by RNN or CNN based encoder-decoder\nframework. However, previous works do not consider the practical issues when\ndeploying G2P model in the production system, such as how to leverage\nadditional unlabeled data to boost the accuracy, as well as reduce model size\nfor online deployment. In this work, we propose token-level ensemble\ndistillation for G2P conversion, which can (1) boost the accuracy by distilling\nthe knowledge from additional unlabeled data, and (2) reduce the model size but\nmaintain the high accuracy, both of which are very practical and helpful in the\nonline production system. We use token-level knowledge distillation, which\nresults in better accuracy than the sequence-level counterpart. What is more,\nwe adopt the Transformer instead of RNN or CNN based models to further boost\nthe accuracy of G2P conversion. Experiments on the publicly available CMUDict\ndataset and an internal English dataset demonstrate the effectiveness of our\nproposed method. Particularly, our method achieves 19.88% WER on CMUDict\ndataset, outperforming the previous works by more than 4.22% WER, and setting\nthe new state-of-the-art results.\n", "versions": [{"version": "v1", "created": "Sat, 6 Apr 2019 13:49:16 GMT"}, {"version": "v2", "created": "Tue, 25 Jun 2019 08:14:58 GMT"}, {"version": "v3", "created": "Mon, 12 Aug 2019 02:59:46 GMT"}], "update_date": "2019-08-13", "authors_parsed": [["Sun", "Hao", ""], ["Tan", "Xu", ""], ["Gan", "Jun-Wei", ""], ["Liu", "Hongzhi", ""], ["Zhao", "Sheng", ""], ["Qin", "Tao", ""], ["Liu", "Tie-Yan", ""]]}, {"id": "1904.03461", "submitter": "Erik Wijmans", "authors": "Erik Wijmans, Samyak Datta, Oleksandr Maksymets, Abhishek Das, Georgia\n  Gkioxari, Stefan Lee, Irfan Essa, Devi Parikh, Dhruv Batra", "title": "Embodied Question Answering in Photorealistic Environments with Point\n  Cloud Perception", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  To help bridge the gap between internet vision-style problems and the goal of\nvision for embodied perception we instantiate a large-scale navigation task --\nEmbodied Question Answering [1] in photo-realistic environments (Matterport\n3D). We thoroughly study navigation policies that utilize 3D point clouds, RGB\nimages, or their combination. Our analysis of these models reveals several key\nfindings. We find that two seemingly naive navigation baselines, forward-only\nand random, are strong navigators and challenging to outperform, due to the\nspecific choice of the evaluation setting presented by [1]. We find a novel\nloss-weighting scheme we call Inflection Weighting to be important when\ntraining recurrent models for navigation with behavior cloning and are able to\nout perform the baselines with this technique. We find that point clouds\nprovide a richer signal than RGB images for learning obstacle avoidance,\nmotivating the use (and continued study) of 3D deep learning models for\nembodied navigation.\n", "versions": [{"version": "v1", "created": "Sat, 6 Apr 2019 14:50:11 GMT"}], "update_date": "2019-04-09", "authors_parsed": [["Wijmans", "Erik", ""], ["Datta", "Samyak", ""], ["Maksymets", "Oleksandr", ""], ["Das", "Abhishek", ""], ["Gkioxari", "Georgia", ""], ["Lee", "Stefan", ""], ["Essa", "Irfan", ""], ["Parikh", "Devi", ""], ["Batra", "Dhruv", ""]]}, {"id": "1904.03491", "submitter": "Rahul-Vigneswaran K", "authors": "Rahul-Vigneswaran K, Prabaharan Poornachandran and Soman KP", "title": "A Compendium on Network and Host based Intrusion Detection Systems", "comments": "8 pages, Accepted for ICDSMLA 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR cs.NE cs.NI stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  The techniques of deep learning have become the state of the art methodology\nfor executing complicated tasks from various domains of computer vision,\nnatural language processing, and several other areas. Due to its rapid\ndevelopment and promising benchmarks in those fields, researchers started\nexperimenting with this technique to perform in the area of, especially in\nintrusion detection related tasks. Deep learning is a subset and a natural\nextension of classical Machine learning and an evolved model of neural\nnetworks. This paper contemplates and discusses all the methodologies related\nto the leading edge Deep learning and Neural network models purposing to the\narena of Intrusion Detection Systems.\n", "versions": [{"version": "v1", "created": "Sat, 6 Apr 2019 16:45:42 GMT"}], "update_date": "2019-04-09", "authors_parsed": [["K", "Rahul-Vigneswaran", ""], ["Poornachandran", "Prabaharan", ""], ["KP", "Soman", ""]]}, {"id": "1904.03493", "submitter": "Xin Wang", "authors": "Xin Wang, Jiawei Wu, Junkun Chen, Lei Li, Yuan-Fang Wang, William Yang\n  Wang", "title": "VATEX: A Large-Scale, High-Quality Multilingual Dataset for\n  Video-and-Language Research", "comments": "ICCV 2019 Oral. 17 pages, 14 figures, 6 tables (updated the VATEX\n  website link: vatex-challenge.org)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a new large-scale multilingual video description dataset, VATEX,\nwhich contains over 41,250 videos and 825,000 captions in both English and\nChinese. Among the captions, there are over 206,000 English-Chinese parallel\ntranslation pairs. Compared to the widely-used MSR-VTT dataset, VATEX is\nmultilingual, larger, linguistically complex, and more diverse in terms of both\nvideo and natural language descriptions. We also introduce two tasks for\nvideo-and-language research based on VATEX: (1) Multilingual Video Captioning,\naimed at describing a video in various languages with a compact unified\ncaptioning model, and (2) Video-guided Machine Translation, to translate a\nsource language description into the target language using the video\ninformation as additional spatiotemporal context. Extensive experiments on the\nVATEX dataset show that, first, the unified multilingual model can not only\nproduce both English and Chinese descriptions for a video more efficiently, but\nalso offer improved performance over the monolingual models. Furthermore, we\ndemonstrate that the spatiotemporal video context can be effectively utilized\nto align source and target languages and thus assist machine translation. In\nthe end, we discuss the potentials of using VATEX for other video-and-language\nresearch.\n", "versions": [{"version": "v1", "created": "Sat, 6 Apr 2019 16:50:31 GMT"}, {"version": "v2", "created": "Thu, 22 Aug 2019 06:29:53 GMT"}, {"version": "v3", "created": "Wed, 17 Jun 2020 16:47:55 GMT"}], "update_date": "2020-06-18", "authors_parsed": [["Wang", "Xin", ""], ["Wu", "Jiawei", ""], ["Chen", "Junkun", ""], ["Li", "Lei", ""], ["Wang", "Yuan-Fang", ""], ["Wang", "William Yang", ""]]}, {"id": "1904.03508", "submitter": "Hwann-Tzong Chen", "authors": "Chih-Yao Chiu, Hwann-Tzong Chen, Tyng-Luh Liu", "title": "C2S2: Cost-aware Channel Sparse Selection for Progressive Network\n  Pruning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper describes a channel-selection approach for simplifying deep neural\nnetworks. Specifically, we propose a new type of generic network layer, called\npruning layer, to seamlessly augment a given pre-trained model for compression.\nEach pruning layer, comprising $1 \\times 1$ depth-wise kernels, is represented\nwith a dual format: one is real-valued and the other is binary. The former\nenables a two-phase optimization process of network pruning to operate with an\nend-to-end differentiable network, and the latter yields the mask information\nfor channel selection. Our method progressively performs the pruning task\nlayer-wise, and achieves channel selection according to a sparsity criterion to\nfavor pruning more channels. We also develop a cost-aware mechanism to prevent\nthe compression from sacrificing the expected network performance. Our results\nfor compressing several benchmark deep networks on image classification and\nsemantic segmentation are comparable to those by state-of-the-art.\n", "versions": [{"version": "v1", "created": "Sat, 6 Apr 2019 18:40:06 GMT"}], "update_date": "2019-04-09", "authors_parsed": [["Chiu", "Chih-Yao", ""], ["Chen", "Hwann-Tzong", ""], ["Liu", "Tyng-Luh", ""]]}, {"id": "1904.03513", "submitter": "Ramy Baly", "authors": "Abdelrhman Saleh (1), Ramy Baly (2), Alberto Barr\\'on-Cede\\~no (3),\n  Giovanni Da San Martino (3), Mitra Mohtarami (2), Preslav Nakov (3) and James\n  Glass (2) ((1) Harvard University, MA, USA, (2) MIT Computer Science and\n  Artificial Intelligence Laboratory, MA, USA, (3) Qatar Computing Research\n  Institute, HBKU, Qatar)", "title": "Team QCRI-MIT at SemEval-2019 Task 4: Propaganda Analysis Meets\n  Hyperpartisan News Detection", "comments": "Hyperpartisanship, propaganda, news media, fake news, SemEval-2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.CL cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we describe our submission to SemEval-2019 Task 4 on\nHyperpartisan News Detection. Our system relies on a variety of engineered\nfeatures originally used to detect propaganda. This is based on the assumption\nthat biased messages are propagandistic in the sense that they promote a\nparticular political cause or viewpoint. We trained a logistic regression model\nwith features ranging from simple bag-of-words to vocabulary richness and text\nreadability features. Our system achieved 72.9% accuracy on the test data that\nis annotated manually and 60.8% on the test data that is annotated with distant\nsupervision. Additional experiments showed that significant performance\nimprovements can be achieved with better feature pre-processing.\n", "versions": [{"version": "v1", "created": "Sat, 6 Apr 2019 19:04:29 GMT"}], "update_date": "2019-04-09", "authors_parsed": [["Saleh", "Abdelrhman", ""], ["Baly", "Ramy", ""], ["Barr\u00f3n-Cede\u00f1o", "Alberto", ""], ["Martino", "Giovanni Da San", ""], ["Mohtarami", "Mitra", ""], ["Nakov", "Preslav", ""], ["Glass", "James", ""]]}, {"id": "1904.03515", "submitter": "Micha{\\l} Zaj\\k{a}c", "authors": "Micha{\\l} Zaj\\k{a}c, Konrad Zolna, Stanis{\\l}aw Jastrz\\k{e}bski", "title": "Split Batch Normalization: Improving Semi-Supervised Learning under\n  Domain Shift", "comments": "Under review for ECML PKDD 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent work has shown that using unlabeled data in semi-supervised learning\nis not always beneficial and can even hurt generalization, especially when\nthere is a class mismatch between the unlabeled and labeled examples. We\ninvestigate this phenomenon for image classification on the CIFAR-10 and the\nImageNet datasets, and with many other forms of domain shifts applied (e.g.\nsalt-and-pepper noise). Our main contribution is Split Batch Normalization\n(Split-BN), a technique to improve SSL when the additional unlabeled data comes\nfrom a shifted distribution. We achieve it by using separate batch\nnormalization statistics for unlabeled examples. Due to its simplicity, we\nrecommend it as a standard practice. Finally, we analyse how domain shift\naffects the SSL training process. In particular, we find that during training\nthe statistics of hidden activations in late layers become markedly different\nbetween the unlabeled and the labeled examples.\n", "versions": [{"version": "v1", "created": "Sat, 6 Apr 2019 19:10:05 GMT"}], "update_date": "2019-10-07", "authors_parsed": [["Zaj\u0105c", "Micha\u0142", ""], ["Zolna", "Konrad", ""], ["Jastrz\u0119bski", "Stanis\u0142aw", ""]]}, {"id": "1904.03516", "submitter": "Hwann-Tzong Chen", "authors": "Songhao Jia, Ding-Jie Chen, Hwann-Tzong Chen", "title": "Instance-Level Meta Normalization", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper presents a normalization mechanism called Instance-Level Meta\nNormalization (ILM~Norm) to address a learning-to-normalize problem. ILM~Norm\nlearns to predict the normalization parameters via both the feature\nfeed-forward and the gradient back-propagation paths. ILM~Norm provides a meta\nnormalization mechanism and has several good properties. It can be easily\nplugged into existing instance-level normalization schemes such as Instance\nNormalization, Layer Normalization, or Group Normalization. ILM~Norm normalizes\neach instance individually and therefore maintains high performance even when\nsmall mini-batch is used. The experimental results show that ILM~Norm well\nadapts to different network architectures and tasks, and it consistently\nimproves the performance of the original models. The code is available at\nurl{https://github.com/Gasoonjia/ILM-Norm.\n", "versions": [{"version": "v1", "created": "Sat, 6 Apr 2019 19:37:18 GMT"}], "update_date": "2019-04-09", "authors_parsed": [["Jia", "Songhao", ""], ["Chen", "Ding-Jie", ""], ["Chen", "Hwann-Tzong", ""]]}, {"id": "1904.03522", "submitter": "Roee Levy Leshem", "authors": "Roee Levy Leshem, Raja Giryes", "title": "Taco-VC: A Single Speaker Tacotron based Voice Conversion with Limited\n  Data", "comments": "Accepted to EUSIPCO 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SD cs.LG eess.AS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper introduces Taco-VC, a novel architecture for voice conversion\nbased on Tacotron synthesizer, which is a sequence-to-sequence with attention\nmodel. The training of multi-speaker voice conversion systems requires a large\nnumber of resources, both in training and corpus size. Taco-VC is implemented\nusing a single speaker Tacotron synthesizer based on Phonetic PosteriorGrams\n(PPGs) and a single speaker WaveNet vocoder conditioned on mel spectrograms. To\nenhance the converted speech quality, and to overcome over-smoothing, the\noutputs of Tacotron are passed through a novel speechenhancement network, which\nis composed of a combination of the phoneme recognition and Tacotron networks.\nOur system is trained just with a single speaker corpus and adapts to new\nspeakers using only a few minutes of training data. Using mid-size public\ndatasets, our method outperforms the baseline in the VCC 2018 SPOKE\nnon-parallel voice conversion task and achieves competitive results compared to\nmulti-speaker networks trained on large private datasets.\n", "versions": [{"version": "v1", "created": "Sat, 6 Apr 2019 20:19:07 GMT"}, {"version": "v2", "created": "Tue, 16 Apr 2019 09:39:02 GMT"}, {"version": "v3", "created": "Sat, 26 Oct 2019 08:53:29 GMT"}, {"version": "v4", "created": "Fri, 19 Jun 2020 07:18:11 GMT"}], "update_date": "2020-06-22", "authors_parsed": [["Leshem", "Roee Levy", ""], ["Giryes", "Raja", ""]]}, {"id": "1904.03535", "submitter": "Nikolaos Tziortziotis", "authors": "Nikolaos Tziortziotis, Christos Dimitrakakis, Michalis Vazirgiannis", "title": "Randomised Bayesian Least-Squares Policy Iteration", "comments": "European Workshop on Reinforcement Learning 14, October 2018, Lille,\n  France", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce Bayesian least-squares policy iteration (BLSPI), an off-policy,\nmodel-free, policy iteration algorithm that uses the Bayesian least-squares\ntemporal-difference (BLSTD) learning algorithm to evaluate policies. An online\nvariant of BLSPI has been also proposed, called randomised BLSPI (RBLSPI), that\nimproves its policy based on an incomplete policy evaluation step. In online\nsetting, the exploration-exploitation dilemma should be addressed as we try to\ndiscover the optimal policy by using samples collected by ourselves. RBLSPI\nexploits the advantage of BLSTD to quantify our uncertainty about the value\nfunction. Inspired by Thompson sampling, RBLSPI first samples a value function\nfrom a posterior distribution over value functions, and then selects actions\nbased on the sampled value function. The effectiveness and the exploration\nabilities of RBLSPI are demonstrated experimentally in several environments.\n", "versions": [{"version": "v1", "created": "Sat, 6 Apr 2019 21:50:24 GMT"}], "update_date": "2019-04-09", "authors_parsed": [["Tziortziotis", "Nikolaos", ""], ["Dimitrakakis", "Christos", ""], ["Vazirgiannis", "Michalis", ""]]}, {"id": "1904.03537", "submitter": "Mahesh Chandra Mukkamala", "authors": "Mahesh Chandra Mukkamala, Peter Ochs, Thomas Pock, Shoham Sabach", "title": "Convex-Concave Backtracking for Inertial Bregman Proximal Gradient\n  Algorithms in Non-Convex Optimization", "comments": "29 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.OC cs.CV cs.LG cs.NA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Backtracking line-search is an old yet powerful strategy for finding a better\nstep sizes to be used in proximal gradient algorithms. The main principle is to\nlocally find a simple convex upper bound of the objective function, which in\nturn controls the step size that is used. In case of inertial proximal gradient\nalgorithms, the situation becomes much more difficult and usually leads to very\nrestrictive rules on the extrapolation parameter. In this paper, we show that\nthe extrapolation parameter can be controlled by locally finding also a simple\nconcave lower bound of the objective function. This gives rise to a double\nconvex-concave backtracking procedure which allows for an adaptive choice of\nboth the step size and extrapolation parameters. We apply this procedure to the\nclass of inertial Bregman proximal gradient methods, and prove that any\nsequence generated by these algorithms converges globally to a critical point\nof the function at hand. Numerical experiments on a number of challenging\nnon-convex problems in image processing and machine learning were conducted and\nshow the power of combining inertial step and double backtracking strategy in\nachieving improved performances.\n", "versions": [{"version": "v1", "created": "Sat, 6 Apr 2019 21:59:02 GMT"}, {"version": "v2", "created": "Tue, 5 Nov 2019 11:16:22 GMT"}], "update_date": "2019-11-06", "authors_parsed": [["Mukkamala", "Mahesh Chandra", ""], ["Ochs", "Peter", ""], ["Pock", "Thomas", ""], ["Sabach", "Shoham", ""]]}, {"id": "1904.03542", "submitter": "Yizheng Chen", "authors": "Yizheng Chen, Shiqi Wang, Dongdong She, Suman Jana", "title": "On Training Robust PDF Malware Classifiers", "comments": "USENIX Security 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Although state-of-the-art PDF malware classifiers can be trained with almost\nperfect test accuracy (99%) and extremely low false positive rate (under 0.1%),\nit has been shown that even a simple adversary can evade them. A practically\nuseful malware classifier must be robust against evasion attacks. However,\nachieving such robustness is an extremely challenging task.\n  In this paper, we take the first steps towards training robust PDF malware\nclassifiers with verifiable robustness properties. For instance, a robustness\nproperty can enforce that no matter how many pages from benign documents are\ninserted into a PDF malware, the classifier must still classify it as\nmalicious. We demonstrate how the worst-case behavior of a malware classifier\nwith respect to specific robustness properties can be formally verified.\nFurthermore, we find that training classifiers that satisfy formally verified\nrobustness properties can increase the evasion cost of unbounded (i.e., not\nbounded by the robustness properties) attackers by eliminating simple evasion\nattacks.\n  Specifically, we propose a new distance metric that operates on the PDF tree\nstructure and specify two classes of robustness properties including subtree\ninsertions and deletions. We utilize state-of-the-art verifiably robust\ntraining method to build robust PDF malware classifiers. Our results show that,\nwe can achieve 92.27% average verified robust accuracy over three properties,\nwhile maintaining 99.74% accuracy and 0.56% false positive rate. With simple\nrobustness properties, our robust model maintains 7% higher robust accuracy\nthan all the baseline models against unrestricted whitebox attacks. Moreover,\nthe state-of-the-art and new adaptive evolutionary attackers need up to 10\ntimes larger $L_0$ feature distance and 21 times more PDF basic mutations\n(e.g., inserting and deleting objects) to evade our robust model than the\nbaselines.\n", "versions": [{"version": "v1", "created": "Sat, 6 Apr 2019 22:43:26 GMT"}, {"version": "v2", "created": "Tue, 3 Dec 2019 13:59:59 GMT"}], "update_date": "2019-12-04", "authors_parsed": [["Chen", "Yizheng", ""], ["Wang", "Shiqi", ""], ["She", "Dongdong", ""], ["Jana", "Suman", ""]]}, {"id": "1904.03543", "submitter": "Huy Phan", "authors": "Huy Phan and Oliver Y. Ch\\'en and Lam Pham and Philipp Koch and\n  Maarten De Vos and Ian McLoughlin and Alfred Mertins", "title": "Spatio-Temporal Attention Pooling for Audio Scene Classification", "comments": "To appear at the 20th Annual Conference of the International Speech\n  Communication Association (INTERSPEECH 2019)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SD cs.LG eess.AS stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Acoustic scenes are rich and redundant in their content. In this work, we\npresent a spatio-temporal attention pooling layer coupled with a convolutional\nrecurrent neural network to learn from patterns that are discriminative while\nsuppressing those that are irrelevant for acoustic scene classification. The\nconvolutional layers in this network learn invariant features from\ntime-frequency input. The bidirectional recurrent layers are then able to\nencode the temporal dynamics of the resulting convolutional features.\nAfterwards, a two-dimensional attention mask is formed via the outer product of\nthe spatial and temporal attention vectors learned from two designated\nattention layers to weigh and pool the recurrent output into a final feature\nvector for classification. The network is trained with between-class examples\ngenerated from between-class data augmentation. Experiments demonstrate that\nthe proposed method not only outperforms a strong convolutional neural network\nbaseline but also sets new state-of-the-art performance on the LITIS Rouen\ndataset.\n", "versions": [{"version": "v1", "created": "Sat, 6 Apr 2019 22:49:20 GMT"}, {"version": "v2", "created": "Fri, 28 Jun 2019 12:32:52 GMT"}], "update_date": "2019-07-01", "authors_parsed": [["Phan", "Huy", ""], ["Ch\u00e9n", "Oliver Y.", ""], ["Pham", "Lam", ""], ["Koch", "Philipp", ""], ["De Vos", "Maarten", ""], ["McLoughlin", "Ian", ""], ["Mertins", "Alfred", ""]]}, {"id": "1904.03548", "submitter": "Roger  Fan", "authors": "Roger Fan, Byoungwook Jang, Yuekai Sun, Shuheng Zhou", "title": "Precision Matrix Estimation with Noisy and Missing Data", "comments": "27 pages, 14 figures, to appear in The 22nd International Conference\n  on Artificial Intelligence and Statistics (AISTATS 2019)", "journal-ref": null, "doi": null, "report-no": "Technical Report 545, Department of Statistics, University of\n  Michigan", "categories": "stat.ML cs.LG stat.ME", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Estimating conditional dependence graphs and precision matrices are some of\nthe most common problems in modern statistics and machine learning. When data\nare fully observed, penalized maximum likelihood-type estimators have become\nstandard tools for estimating graphical models under sparsity conditions.\nExtensions of these methods to more complex settings where data are\ncontaminated with additive or multiplicative noise have been developed in\nrecent years. In these settings, however, the relative performance of different\nmethods is not well understood and algorithmic gaps still exist. In particular,\nin high-dimensional settings these methods require using non-positive\nsemidefinite matrices as inputs, presenting novel optimization challenges. We\ndevelop an alternating direction method of multipliers (ADMM) algorithm for\nthese problems, providing a feasible algorithm to estimate precision matrices\nwith indefinite input and potentially nonconvex penalties. We compare this\nmethod with existing alternative solutions and empirically characterize the\ntradeoffs between them. Finally, we use this method to explore the networks\namong US senators estimated from voting records data.\n", "versions": [{"version": "v1", "created": "Sun, 7 Apr 2019 00:05:57 GMT"}], "update_date": "2019-04-09", "authors_parsed": [["Fan", "Roger", ""], ["Jang", "Byoungwook", ""], ["Sun", "Yuekai", ""], ["Zhou", "Shuheng", ""]]}, {"id": "1904.03549", "submitter": "Jie Gui", "authors": "Jie Gui, Tongliang Liu, Zhenan Sun, Dacheng Tao, and Tieniu Tan", "title": "Supervised Discrete Hashing with Relaxation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Data-dependent hashing has recently attracted attention due to being able to\nsupport efficient retrieval and storage of high-dimensional data such as\ndocuments, images, and videos. In this paper, we propose a novel learning-based\nhashing method called \"Supervised Discrete Hashing with Relaxation\" (SDHR)\nbased on \"Supervised Discrete Hashing\" (SDH). SDH uses ordinary least squares\nregression and traditional zero-one matrix encoding of class label information\nas the regression target (code words), thus fixing the regression target. In\nSDHR, the regression target is instead optimized. The optimized regression\ntarget matrix satisfies a large margin constraint for correct classification of\neach example. Compared with SDH, which uses the traditional zero-one matrix,\nSDHR utilizes the learned regression target matrix and, therefore, more\naccurately measures the classification error of the regression model and is\nmore flexible. As expected, SDHR generally outperforms SDH. Experimental\nresults on two large-scale image datasets (CIFAR-10 and MNIST) and a\nlarge-scale and challenging face dataset (FRGC) demonstrate the effectiveness\nand efficiency of SDHR.\n", "versions": [{"version": "v1", "created": "Sun, 7 Apr 2019 00:09:19 GMT"}], "update_date": "2019-04-09", "authors_parsed": [["Gui", "Jie", ""], ["Liu", "Tongliang", ""], ["Sun", "Zhenan", ""], ["Tao", "Dacheng", ""], ["Tan", "Tieniu", ""]]}, {"id": "1904.03556", "submitter": "Jie Gui", "authors": "Jie Gui, Tongliang Liu, Zhenan Sun, Dacheng Tao, and Tieniu Tan", "title": "Fast Supervised Discrete Hashing", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Learning-based hashing algorithms are ``hot topics\" because they can greatly\nincrease the scale at which existing methods operate. In this paper, we propose\na new learning-based hashing method called ``fast supervised discrete hashing\"\n(FSDH) based on ``supervised discrete hashing\" (SDH). Regressing the training\nexamples (or hash code) to the corresponding class labels is widely used in\nordinary least squares regression. Rather than adopting this method, FSDH uses\na very simple yet effective regression of the class labels of training examples\nto the corresponding hash code to accelerate the algorithm. To the best of our\nknowledge, this strategy has not previously been used for hashing. Traditional\nSDH decomposes the optimization into three sub-problems, with the most critical\nsub-problem - discrete optimization for binary hash codes - solved using\niterative discrete cyclic coordinate descent (DCC), which is time-consuming.\nHowever, FSDH has a closed-form solution and only requires a single rather than\niterative hash code-solving step, which is highly efficient. Furthermore, FSDH\nis usually faster than SDH for solving the projection matrix for least squares\nregression, making FSDH generally faster than SDH. For example, our results\nshow that FSDH is about 12-times faster than SDH when the number of hashing\nbits is 128 on the CIFAR-10 data base, and FSDH is about 151-times faster than\nFastHash when the number of hashing bits is 64 on the MNIST data-base. Our\nexperimental results show that FSDH is not only fast, but also outperforms\nother comparative methods.\n", "versions": [{"version": "v1", "created": "Sun, 7 Apr 2019 00:35:54 GMT"}], "update_date": "2019-04-09", "authors_parsed": [["Gui", "Jie", ""], ["Liu", "Tongliang", ""], ["Sun", "Zhenan", ""], ["Tao", "Dacheng", ""], ["Tan", "Tieniu", ""]]}, {"id": "1904.03564", "submitter": "Matthew Joseph", "authors": "Matthew Joseph, Jieming Mao, Seth Neel, Aaron Roth", "title": "The Role of Interactivity in Local Differential Privacy", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the power of interactivity in local differential privacy. First, we\nfocus on the difference between fully interactive and sequentially interactive\nprotocols. Sequentially interactive protocols may query users adaptively in\nsequence, but they cannot return to previously queried users. The vast majority\nof existing lower bounds for local differential privacy apply only to\nsequentially interactive protocols, and before this paper it was not known\nwhether fully interactive protocols were more powerful. We resolve this\nquestion. First, we classify locally private protocols by their\ncompositionality, the multiplicative factor $k \\geq 1$ by which the sum of a\nprotocol's single-round privacy parameters exceeds its overall privacy\nguarantee. We then show how to efficiently transform any fully interactive\n$k$-compositional protocol into an equivalent sequentially interactive protocol\nwith an $O(k)$ blowup in sample complexity. Next, we show that our reduction is\ntight by exhibiting a family of problems such that for any $k$, there is a\nfully interactive $k$-compositional protocol which solves the problem, while no\nsequentially interactive protocol can solve the problem without at least an\n$\\tilde \\Omega(k)$ factor more examples. We then turn our attention to\nhypothesis testing problems. We show that for a large class of compound\nhypothesis testing problems --- which include all simple hypothesis testing\nproblems as a special case --- a simple noninteractive test is optimal among\nthe class of all (possibly fully interactive) tests.\n", "versions": [{"version": "v1", "created": "Sun, 7 Apr 2019 01:47:04 GMT"}, {"version": "v2", "created": "Fri, 8 Nov 2019 14:29:49 GMT"}], "update_date": "2019-11-11", "authors_parsed": [["Joseph", "Matthew", ""], ["Mao", "Jieming", ""], ["Neel", "Seth", ""], ["Roth", "Aaron", ""]]}, {"id": "1904.03582", "submitter": "Xiu-Shen Wei", "authors": "Zhao-Min Chen, Xiu-Shen Wei, Peng Wang, Yanwen Guo", "title": "Multi-Label Image Recognition with Graph Convolutional Networks", "comments": "To appear at CVPR 2019 (Source codes have been released on\n  https://github.com/chenzhaomin123/ML_GCN)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The task of multi-label image recognition is to predict a set of object\nlabels that present in an image. As objects normally co-occur in an image, it\nis desirable to model the label dependencies to improve the recognition\nperformance. To capture and explore such important dependencies, we propose a\nmulti-label classification model based on Graph Convolutional Network (GCN).\nThe model builds a directed graph over the object labels, where each node\n(label) is represented by word embeddings of a label, and GCN is learned to map\nthis label graph into a set of inter-dependent object classifiers. These\nclassifiers are applied to the image descriptors extracted by another sub-net,\nenabling the whole network to be end-to-end trainable. Furthermore, we propose\na novel re-weighted scheme to create an effective label correlation matrix to\nguide information propagation among the nodes in GCN. Experiments on two\nmulti-label image recognition datasets show that our approach obviously\noutperforms other existing state-of-the-art methods. In addition, visualization\nanalyses reveal that the classifiers learned by our model maintain meaningful\nsemantic topology.\n", "versions": [{"version": "v1", "created": "Sun, 7 Apr 2019 04:36:50 GMT"}], "update_date": "2019-04-09", "authors_parsed": [["Chen", "Zhao-Min", ""], ["Wei", "Xiu-Shen", ""], ["Wang", "Peng", ""], ["Guo", "Yanwen", ""]]}, {"id": "1904.03584", "submitter": "Art Munson", "authors": "M. Arthur Munson and Jason Kichen and Dustin Hillard and Ashley Fidler\n  and Peiter Zatko", "title": "Reframing Threat Detection: Inside esINSIDER", "comments": "38 pages, 10 figures", "journal-ref": null, "doi": null, "report-no": "ES2019-001", "categories": "cs.CR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We describe the motivation and design for esINSIDER, an automated tool that\ndetects potential persistent and insider threats in a network. esINSIDER\naggregates clues from log data, over extended time periods, and proposes a\nsmall number of cases for human experts to review. The proposed cases package\ntogether related information so the analyst can see a bigger picture of what is\nhappening, and their evidence includes internal network activity resembling\nreconnaissance and data collection.\n  The core ideas are to 1) detect fundamental campaign behaviors by following\ndata movements over extended time periods, 2) link together behaviors\nassociated with different meta-goals, and 3) use machine learning to understand\nwhat activities are expected and consistent for each individual network. We\ncall this approach campaign analytics because it focuses on the threat actor's\ncampaign goals and the intrinsic steps to achieve them. Linking different\ncampaign behaviors (internal reconnaissance, collection, exfiltration) reduces\nfalse positives from business-as-usual activities and creates opportunities to\ndetect threats before a large exfiltration occurs. Machine learning makes it\npractical to deploy this approach by reducing the amount of tuning needed.\n", "versions": [{"version": "v1", "created": "Sun, 7 Apr 2019 05:20:02 GMT"}], "update_date": "2019-04-09", "authors_parsed": [["Munson", "M. Arthur", ""], ["Kichen", "Jason", ""], ["Hillard", "Dustin", ""], ["Fidler", "Ashley", ""], ["Zatko", "Peiter", ""]]}, {"id": "1904.03590", "submitter": "Phuong Tran", "authors": "Tran Thi Phuong and Le Trieu Phong", "title": "On the Convergence Proof of AMSGrad and a New Version", "comments": "Update publication information", "journal-ref": "IEEE Access, Volume 7, Issue 1, Pages 61706-61716, 2019", "doi": "10.1109/ACCESS.2019.2916341", "report-no": null, "categories": "cs.LG math.OC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The adaptive moment estimation algorithm Adam (Kingma and Ba) is a popular\noptimizer in the training of deep neural networks. However, Reddi et al. have\nrecently shown that the convergence proof of Adam is problematic and proposed a\nvariant of Adam called AMSGrad as a fix. In this paper, we show that the\nconvergence proof of AMSGrad is also problematic. Concretely, the problem in\nthe convergence proof of AMSGrad is in handling the hyper-parameters, treating\nthem as equal while they are not. This is also the neglected issue in the\nconvergence proof of Adam. We provide an explicit counter-example of a simple\nconvex optimization setting to show this neglected issue. Depending on\nmanipulating the hyper-parameters, we present various fixes for this issue. We\nprovide a new convergence proof for AMSGrad as the first fix. We also propose a\nnew version of AMSGrad called AdamX as another fix. Our experiments on the\nbenchmark dataset also support our theoretical results.\n", "versions": [{"version": "v1", "created": "Sun, 7 Apr 2019 06:10:04 GMT"}, {"version": "v2", "created": "Sun, 21 Apr 2019 02:33:09 GMT"}, {"version": "v3", "created": "Fri, 24 May 2019 02:08:06 GMT"}, {"version": "v4", "created": "Thu, 31 Oct 2019 00:06:04 GMT"}], "update_date": "2019-11-01", "authors_parsed": [["Phuong", "Tran Thi", ""], ["Phong", "Le Trieu", ""]]}, {"id": "1904.03595", "submitter": "Youssef Tamaazousti", "authors": "Sara Meftah, Youssef Tamaazousti, Nasredine Semmar, Hassane Essafi,\n  Fatiha Sadat", "title": "Joint Learning of Pre-Trained and Random Units for Domain Adaptation in\n  Part-of-Speech Tagging", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Fine-tuning neural networks is widely used to transfer valuable knowledge\nfrom high-resource to low-resource domains. In a standard fine-tuning scheme,\nsource and target problems are trained using the same architecture. Although\ncapable of adapting to new domains, pre-trained units struggle with learning\nuncommon target-specific patterns. In this paper, we propose to augment the\ntarget-network with normalised, weighted and randomly initialised units that\nbeget a better adaptation while maintaining the valuable source knowledge. Our\nexperiments on POS tagging of social media texts (Tweets domain) demonstrate\nthat our method achieves state-of-the-art performances on 3 commonly used\ndatasets.\n", "versions": [{"version": "v1", "created": "Sun, 7 Apr 2019 06:46:36 GMT"}], "update_date": "2019-04-09", "authors_parsed": [["Meftah", "Sara", ""], ["Tamaazousti", "Youssef", ""], ["Semmar", "Nasredine", ""], ["Essafi", "Hassane", ""], ["Sadat", "Fatiha", ""]]}, {"id": "1904.03602", "submitter": "Amit Daniely", "authors": "Amit Daniely and Yishay Mansour", "title": "Competitive ratio versus regret minimization: achieving the best of both\n  worlds", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.DS stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider online algorithms under both the competitive ratio criteria and\nthe regret minimization one. Our main goal is to build a unified methodology\nthat would be able to guarantee both criteria simultaneously.\n  For a general class of online algorithms, namely any Metrical Task System\n(MTS), we show that one can simultaneously guarantee the best known competitive\nratio and a natural regret bound. For the paging problem we further show an\nefficient online algorithm (polynomial in the number of pages) with this\nguarantee.\n  To this end, we extend an existing regret minimization algorithm\n(specifically, Kapralov and Panigrahy) to handle movement cost (the cost of\nswitching between states of the online system). We then show how to use the\nextended regret minimization algorithm to combine multiple online algorithms.\nOur end result is an online algorithm that can combine a \"base\" online\nalgorithm, having a guaranteed competitive ratio, with a range of online\nalgorithms that guarantee a small regret over any interval of time. The\ncombined algorithm guarantees both that the competitive ratio matches that of\nthe base algorithm and a low regret over any time interval.\n  As a by product, we obtain an expert algorithm with close to optimal regret\nbound on every time interval, even in the presence of switching costs. This\nresult is of independent interest.\n", "versions": [{"version": "v1", "created": "Sun, 7 Apr 2019 08:09:42 GMT"}], "update_date": "2019-04-09", "authors_parsed": [["Daniely", "Amit", ""], ["Mansour", "Yishay", ""]]}, {"id": "1904.03616", "submitter": "Beibin Li", "authors": "Beibin Li, Sachin Mehta, Deepali Aneja, Claire Foster, Pamela Ventola,\n  Frederick Shic, Linda Shapiro", "title": "A Facial Affect Analysis System for Autism Spectrum Disorder", "comments": "5 pages (including 1 page for reference), 3 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.HC cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we introduce an end-to-end machine learning-based system for\nclassifying autism spectrum disorder (ASD) using facial attributes such as\nexpressions, action units, arousal, and valence. Our system classifies ASD\nusing representations of different facial attributes from convolutional neural\nnetworks, which are trained on images in the wild. Our experimental results\nshow that different facial attributes used in our system are statistically\nsignificant and improve sensitivity, specificity, and F1 score of ASD\nclassification by a large margin. In particular, the addition of different\nfacial attributes improves the performance of ASD classification by about 7%\nwhich achieves a F1 score of 76%.\n", "versions": [{"version": "v1", "created": "Sun, 7 Apr 2019 10:08:35 GMT"}], "update_date": "2019-04-09", "authors_parsed": [["Li", "Beibin", ""], ["Mehta", "Sachin", ""], ["Aneja", "Deepali", ""], ["Foster", "Claire", ""], ["Ventola", "Pamela", ""], ["Shic", "Frederick", ""], ["Shapiro", "Linda", ""]]}, {"id": "1904.03617", "submitter": "Lantian Li Mr.", "authors": "Yang Zhang and Lantian Li and Dong Wang", "title": "VAE-based regularization for deep speaker embedding", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SD cs.LG eess.AS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep speaker embedding has achieved state-of-the-art performance in speaker\nrecognition. A potential problem of these embedded vectors (called `x-vectors')\nare not Gaussian, causing performance degradation with the famous PLDA back-end\nscoring. In this paper, we propose a regularization approach based on\nVariational Auto-Encoder (VAE). This model transforms x-vectors to a latent\nspace where mapped latent codes are more Gaussian, hence more suitable for PLDA\nscoring.\n", "versions": [{"version": "v1", "created": "Sun, 7 Apr 2019 10:11:58 GMT"}], "update_date": "2019-04-09", "authors_parsed": [["Zhang", "Yang", ""], ["Li", "Lantian", ""], ["Wang", "Dong", ""]]}, {"id": "1904.03620", "submitter": "Varshaneya V", "authors": "Varshaneya V, S Balasubramanian and Vineeth N Balasubramanian", "title": "Teaching GANs to Sketch in Vector Format", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.GR cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Sketching is more fundamental to human cognition than speech. Deep Neural\nNetworks (DNNs) have achieved the state-of-the-art in speech-related tasks but\nhave not made significant development in generating stroke-based sketches a.k.a\nsketches in vector format. Though there are Variational Auto Encoders (VAEs)\nfor generating sketches in vector format, there is no Generative Adversarial\nNetwork (GAN) architecture for the same. In this paper, we propose a standalone\nGAN architecture SkeGAN and a VAE-GAN architecture VASkeGAN, for sketch\ngeneration in vector format. SkeGAN is a stochastic policy in Reinforcement\nLearning (RL), capable of generating both multidimensional continuous and\ndiscrete outputs. VASkeGAN hybridizes a VAE and a GAN, in order to couple the\nefficient representation of data by VAE with the powerful generating\ncapabilities of a GAN, to produce visually appealing sketches. We also propose\na new metric called the Ske-score which quantifies the quality of vector\nsketches. We have validated that SkeGAN and VASkeGAN generate visually\nappealing sketches by using Human Turing Test and Ske-score.\n", "versions": [{"version": "v1", "created": "Sun, 7 Apr 2019 10:23:47 GMT"}], "update_date": "2019-04-09", "authors_parsed": [["V", "Varshaneya", ""], ["Balasubramanian", "S", ""], ["Balasubramanian", "Vineeth N", ""]]}, {"id": "1904.03626", "submitter": "Guy Hacohen", "authors": "Guy Hacohen and Daphna Weinshall", "title": "On The Power of Curriculum Learning in Training Deep Networks", "comments": "In proceedings, ICML 2019", "journal-ref": "Proc. ICML, 2019", "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Training neural networks is traditionally done by providing a sequence of\nrandom mini-batches sampled uniformly from the entire training data. In this\nwork, we analyze the effect of curriculum learning, which involves the\nnon-uniform sampling of mini-batches, on the training of deep networks, and\nspecifically CNNs trained for image recognition. To employ curriculum learning,\nthe training algorithm must resolve 2 problems: (i) sort the training examples\nby difficulty; (ii) compute a series of mini-batches that exhibit an increasing\nlevel of difficulty. We address challenge (i) using two methods: transfer\nlearning from some competitive ``teacher\" network, and bootstrapping. In our\nempirical evaluation, both methods show similar benefits in terms of increased\nlearning speed and improved final performance on test data. We address\nchallenge (ii) by investigating different pacing functions to guide the\nsampling. The empirical investigation includes a variety of network\narchitectures, using images from CIFAR-10, CIFAR-100 and subsets of ImageNet.\nWe conclude with a novel theoretical analysis of curriculum learning, where we\nshow how it effectively modifies the optimization landscape. We then define the\nconcept of an ideal curriculum, and show that under mild conditions it does not\nchange the corresponding global minimum of the optimization function.\n", "versions": [{"version": "v1", "created": "Sun, 7 Apr 2019 11:36:35 GMT"}, {"version": "v2", "created": "Mon, 27 May 2019 15:06:37 GMT"}, {"version": "v3", "created": "Wed, 29 May 2019 16:26:35 GMT"}], "update_date": "2020-12-03", "authors_parsed": [["Hacohen", "Guy", ""], ["Weinshall", "Daphna", ""]]}, {"id": "1904.03646", "submitter": "Thomas Anthony", "authors": "Thomas Anthony and Robert Nishihara and Philipp Moritz and Tim\n  Salimans and John Schulman", "title": "Policy Gradient Search: Online Planning and Expert Iteration without\n  Search Trees", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Monte Carlo Tree Search (MCTS) algorithms perform simulation-based search to\nimprove policies online. During search, the simulation policy is adapted to\nexplore the most promising lines of play. MCTS has been used by\nstate-of-the-art programs for many problems, however a disadvantage to MCTS is\nthat it estimates the values of states with Monte Carlo averages, stored in a\nsearch tree; this does not scale to games with very high branching factors. We\npropose an alternative simulation-based search method, Policy Gradient Search\n(PGS), which adapts a neural network simulation policy online via policy\ngradient updates, avoiding the need for a search tree. In Hex, PGS achieves\ncomparable performance to MCTS, and an agent trained using Expert Iteration\nwith PGS was able defeat MoHex 2.0, the strongest open-source Hex agent, in 9x9\nHex.\n", "versions": [{"version": "v1", "created": "Sun, 7 Apr 2019 13:00:21 GMT"}], "update_date": "2019-04-09", "authors_parsed": [["Anthony", "Thomas", ""], ["Nishihara", "Robert", ""], ["Moritz", "Philipp", ""], ["Salimans", "Tim", ""], ["Schulman", "John", ""]]}, {"id": "1904.03647", "submitter": "Rico Krueger", "authors": "Prateek Bansal, Rico Krueger, Michel Bierlaire, Ricardo A. Daziano,\n  Taha H. Rashidi", "title": "Bayesian Estimation of Mixed Multinomial Logit Models: Advances and\n  Simulation-Based Evaluations", "comments": null, "journal-ref": "Transportation Research Part B: Methodological, Volume 131,\n  January 2020, Pages 124-142", "doi": "10.1016/j.trb.2019.12.001", "report-no": null, "categories": "stat.ML cs.LG econ.EM stat.ME", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Variational Bayes (VB) methods have emerged as a fast and\ncomputationally-efficient alternative to Markov chain Monte Carlo (MCMC)\nmethods for scalable Bayesian estimation of mixed multinomial logit (MMNL)\nmodels. It has been established that VB is substantially faster than MCMC at\npractically no compromises in predictive accuracy. In this paper, we address\ntwo critical gaps concerning the usage and understanding of VB for MMNL. First,\nextant VB methods are limited to utility specifications involving only\nindividual-specific taste parameters. Second, the finite-sample properties of\nVB estimators and the relative performance of VB, MCMC and maximum simulated\nlikelihood estimation (MSLE) are not known. To address the former, this study\nextends several VB methods for MMNL to admit utility specifications including\nboth fixed and random utility parameters. To address the latter, we conduct an\nextensive simulation-based evaluation to benchmark the extended VB methods\nagainst MCMC and MSLE in terms of estimation times, parameter recovery and\npredictive accuracy. The results suggest that all VB variants with the\nexception of the ones relying on an alternative variational lower bound\nconstructed with the help of the modified Jensen's inequality perform as well\nas MCMC and MSLE at prediction and parameter recovery. In particular, VB with\nnonconjugate variational message passing and the delta-method (VB-NCVMP-Delta)\nis up to 16 times faster than MCMC and MSLE. Thus, VB-NCVMP-Delta can be an\nattractive alternative to MCMC and MSLE for fast, scalable and accurate\nestimation of MMNL models.\n", "versions": [{"version": "v1", "created": "Sun, 7 Apr 2019 13:03:56 GMT"}, {"version": "v2", "created": "Fri, 12 Apr 2019 15:48:39 GMT"}, {"version": "v3", "created": "Thu, 15 Aug 2019 07:12:09 GMT"}, {"version": "v4", "created": "Thu, 12 Dec 2019 14:38:22 GMT"}], "update_date": "2019-12-13", "authors_parsed": [["Bansal", "Prateek", ""], ["Krueger", "Rico", ""], ["Bierlaire", "Michel", ""], ["Daziano", "Ricardo A.", ""], ["Rashidi", "Taha H.", ""]]}, {"id": "1904.03665", "submitter": "Dieter B\\\"uchler", "authors": "Dieter B\\\"uchler, Roberto Calandra, Jan Peters", "title": "Learning to Control Highly Accelerated Ballistic Movements on Muscular\n  Robots", "comments": "12 pages, preprint submitted to Journal of Robotics and Autonomous\n  Systems", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.LG cs.SY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  High-speed and high-acceleration movements are inherently hard to control.\nApplying learning to the control of such motions on anthropomorphic robot arms\ncan improve the accuracy of the control but might damage the system. The\ninherent exploration of learning approaches can lead to instabilities and the\nrobot reaching joint limits at high speeds. Having hardware that enables safe\nexploration of high-speed and high-acceleration movements is therefore\ndesirable. To address this issue, we propose to use robots actuated by\nPneumatic Artificial Muscles (PAMs). In this paper, we present a four degrees\nof freedom (DoFs) robot arm that reaches high joint angle accelerations of up\nto 28000 deg/s^2 while avoiding dangerous joint limits thanks to the\nantagonistic actuation and limits on the air pressure ranges. With this robot\narm, we are able to tune control parameters using Bayesian optimization\ndirectly on the hardware without additional safety considerations. The achieved\ntracking performance on a fast trajectory exceeds previous results on\ncomparable PAM-driven robots. We also show that our system can be controlled\nwell on slow trajectories with PID controllers due to careful construction\nconsiderations such as minimal bending of cables, lightweight kinematics and\nminimal contact between PAMs and PAMs with the links. Finally, we propose a\nnovel technique to control the the co-contraction of antagonistic muscle pairs.\nExperimental results illustrate that choosing the optimal co-contraction level\nis vital to reach better tracking performance. Through the use of PAM-driven\nrobots and learning, we do a small step towards the future development of\nrobots capable of more human-like motions.\n", "versions": [{"version": "v1", "created": "Sun, 7 Apr 2019 15:00:31 GMT"}], "update_date": "2019-04-09", "authors_parsed": [["B\u00fcchler", "Dieter", ""], ["Calandra", "Roberto", ""], ["Peters", "Jan", ""]]}, {"id": "1904.03670", "submitter": "Loren Lugosch", "authors": "Loren Lugosch, Mirco Ravanelli, Patrick Ignoto, Vikrant Singh Tomar,\n  Yoshua Bengio", "title": "Speech Model Pre-training for End-to-End Spoken Language Understanding", "comments": "Accepted to Interspeech 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.AS cs.CL cs.LG cs.SD", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Whereas conventional spoken language understanding (SLU) systems map speech\nto text, and then text to intent, end-to-end SLU systems map speech directly to\nintent through a single trainable model. Achieving high accuracy with these\nend-to-end models without a large amount of training data is difficult. We\npropose a method to reduce the data requirements of end-to-end SLU in which the\nmodel is first pre-trained to predict words and phonemes, thus learning good\nfeatures for SLU. We introduce a new SLU dataset, Fluent Speech Commands, and\nshow that our method improves performance both when the full dataset is used\nfor training and when only a small subset is used. We also describe preliminary\nexperiments to gauge the model's ability to generalize to new phrases not heard\nduring training.\n", "versions": [{"version": "v1", "created": "Sun, 7 Apr 2019 15:24:32 GMT"}, {"version": "v2", "created": "Thu, 25 Jul 2019 17:56:23 GMT"}], "update_date": "2019-07-26", "authors_parsed": [["Lugosch", "Loren", ""], ["Ravanelli", "Mirco", ""], ["Ignoto", "Patrick", ""], ["Tomar", "Vikrant Singh", ""], ["Bengio", "Yoshua", ""]]}, {"id": "1904.03673", "submitter": "Kenji Kawaguchi", "authors": "Kenji Kawaguchi, Jiaoyang Huang, Leslie Pack Kaelbling", "title": "Every Local Minimum Value is the Global Minimum Value of Induced Model\n  in Non-convex Machine Learning", "comments": "Neural computation, MIT press", "journal-ref": "Neural computation, volume 31, pages 2293-2323, MIT press, 2019", "doi": "10.1162/neco_a_01234", "report-no": null, "categories": "stat.ML cs.LG cs.NE math.OC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  For nonconvex optimization in machine learning, this article proves that\nevery local minimum achieves the globally optimal value of the perturbable\ngradient basis model at any differentiable point. As a result, nonconvex\nmachine learning is theoretically as supported as convex machine learning with\na handcrafted basis in terms of the loss at differentiable local minima, except\nin the case when a preference is given to the handcrafted basis over the\nperturbable gradient basis. The proofs of these results are derived under mild\nassumptions. Accordingly, the proven results are directly applicable to many\nmachine learning models, including practical deep neural networks, without any\nmodification of practical methods. Furthermore, as special cases of our general\nresults, this article improves or complements several state-of-the-art\ntheoretical results on deep neural networks, deep residual networks, and\noverparameterized deep neural networks with a unified proof technique and novel\ngeometric insights. A special case of our results also contributes to the\ntheoretical foundation of representation learning.\n", "versions": [{"version": "v1", "created": "Sun, 7 Apr 2019 15:43:59 GMT"}, {"version": "v2", "created": "Thu, 1 Aug 2019 06:00:53 GMT"}, {"version": "v3", "created": "Fri, 15 Nov 2019 23:04:15 GMT"}], "update_date": "2019-11-19", "authors_parsed": [["Kawaguchi", "Kenji", ""], ["Huang", "Jiaoyang", ""], ["Kaelbling", "Leslie Pack", ""]]}, {"id": "1904.03677", "submitter": "Shing Chan", "authors": "Shing Chan and Ahmed H. Elsheikh", "title": "Parametrization of stochastic inputs using generative adversarial\n  networks with application in geology", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG physics.comp-ph stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We investigate artificial neural networks as a parametrization tool for\nstochastic inputs in numerical simulations. We address parametrization from the\npoint of view of emulating the data generating process, instead of explicitly\nconstructing a parametric form to preserve predefined statistics of the data.\nThis is done by training a neural network to generate samples from the data\ndistribution using a recent deep learning technique called generative\nadversarial networks. By emulating the data generating process, the relevant\nstatistics of the data are replicated. The method is assessed in subsurface\nflow problems, where effective parametrization of underground properties such\nas permeability is important due to the high dimensionality and presence of\nhigh spatial correlations. We experiment with realizations of binary\nchannelized subsurface permeability and perform uncertainty quantification and\nparameter estimation. Results show that the parametrization using generative\nadversarial networks is very effective in preserving visual realism as well as\nhigh order statistics of the flow responses, while achieving a dimensionality\nreduction of two orders of magnitude.\n", "versions": [{"version": "v1", "created": "Sun, 7 Apr 2019 16:04:56 GMT"}, {"version": "v2", "created": "Tue, 9 Apr 2019 08:41:26 GMT"}], "update_date": "2019-04-10", "authors_parsed": [["Chan", "Shing", ""], ["Elsheikh", "Ahmed H.", ""]]}, {"id": "1904.03688", "submitter": "Farhood Rismanchian", "authors": "Farhood Rismanchian and Karim Rahimian", "title": "Proposing a Localized Relevance Vector Machine for Pattern\n  Classification", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Relevance vector machine (RVM) can be seen as a probabilistic version of\nsupport vector machines which is able to produce sparse solutions by linearly\nweighting a small number of basis functions instead using all of them.\nRegardless of a few merits of RVM such as giving probabilistic predictions and\nrelax of parameter tuning, it has poor prediction for test instances that are\nfar away from the relevance vectors. As a solution, we propose a new\ncombination of RVM and k-nearest neighbor (k-NN) rule which resolves this issue\nwith regionally dealing with every test instance. In our settings, we obtain\nthe relevance vectors for each test instance in the local area given by k-NN\nrule. In this way, relevance vectors are closer and more relevant to the test\ninstance which results in a more accurate model. This can be seen as a\npiece-wise learner which locally classifies test instances. The model is hence\ncalled localized relevance vector machine (LRVM). The LRVM is examined on\nseveral datasets of the University of California, Irvine (UCI) repository.\nResults supported by statistical tests indicate that the performance of LRVM is\ncompetitive as compared with a few state-of-the-art classifiers.\n", "versions": [{"version": "v1", "created": "Sun, 7 Apr 2019 17:00:42 GMT"}], "update_date": "2019-04-09", "authors_parsed": [["Rismanchian", "Farhood", ""], ["Rahimian", "Karim", ""]]}, {"id": "1904.03743", "submitter": "Hassan Hafez Kolahi", "authors": "Hassan Hafez-Kolahi, Shohreh Kasaei", "title": "Information Bottleneck and its Applications in Deep Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.IT math.IT stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Information Theory (IT) has been used in Machine Learning (ML) from early\ndays of this field. In the last decade, advances in Deep Neural Networks (DNNs)\nhave led to surprising improvements in many applications of ML. The result has\nbeen a paradigm shift in the community toward revisiting previous ideas and\napplications in this new framework. Ideas from IT are no exception. One of the\nideas which is being revisited by many researchers in this new era, is\nInformation Bottleneck (IB); a formulation of information extraction based on\nIT. The IB is promising in both analyzing and improving DNNs. The goal of this\nsurvey is to review the IB concept and demonstrate its applications in deep\nlearning. The information theoretic nature of IB, makes it also a good\ncandidate in showing the more general concept of how IT can be used in ML. Two\nimportant concepts are highlighted in this narrative on the subject, i) the\nconcise and universal view that IT provides on seemingly unrelated methods of\nML, demonstrated by explaining how IB relates to minimal sufficient statistics,\nstochastic gradient descent, and variational auto-encoders, and ii) the common\ntechnical mistakes and problems caused by applying ideas from IT, which is\ndiscussed by a careful study of some recent methods suffering from them.\n", "versions": [{"version": "v1", "created": "Sun, 7 Apr 2019 21:09:30 GMT"}], "update_date": "2019-04-09", "authors_parsed": [["Hafez-Kolahi", "Hassan", ""], ["Kasaei", "Shohreh", ""]]}, {"id": "1904.03751", "submitter": "Matthias M\\\"uller", "authors": "Guohao Li, Matthias M\\\"uller, Ali Thabet, Bernard Ghanem", "title": "DeepGCNs: Can GCNs Go as Deep as CNNs?", "comments": "First two authors contributed equally. Accepted to ICCV'19 as oral\n  presentation", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Convolutional Neural Networks (CNNs) achieve impressive performance in a wide\nvariety of fields. Their success benefited from a massive boost when very deep\nCNN models were able to be reliably trained. Despite their merits, CNNs fail to\nproperly address problems with non-Euclidean data. To overcome this challenge,\nGraph Convolutional Networks (GCNs) build graphs to represent non-Euclidean\ndata, borrow concepts from CNNs, and apply them in training. GCNs show\npromising results, but they are usually limited to very shallow models due to\nthe vanishing gradient problem. As a result, most state-of-the-art GCN models\nare no deeper than 3 or 4 layers. In this work, we present new ways to\nsuccessfully train very deep GCNs. We do this by borrowing concepts from CNNs,\nspecifically residual/dense connections and dilated convolutions, and adapting\nthem to GCN architectures. Extensive experiments show the positive effect of\nthese deep GCN frameworks. Finally, we use these new concepts to build a very\ndeep 56-layer GCN, and show how it significantly boosts performance (+3.7% mIoU\nover state-of-the-art) in the task of point cloud semantic segmentation. We\nbelieve that the community can greatly benefit from this work, as it opens up\nmany opportunities for advancing GCN-based research.\n", "versions": [{"version": "v1", "created": "Sun, 7 Apr 2019 21:49:26 GMT"}, {"version": "v2", "created": "Mon, 19 Aug 2019 12:53:49 GMT"}], "update_date": "2019-08-20", "authors_parsed": [["Li", "Guohao", ""], ["M\u00fcller", "Matthias", ""], ["Thabet", "Ali", ""], ["Ghanem", "Bernard", ""]]}, {"id": "1904.03758", "submitter": "Kwonjoon Lee", "authors": "Kwonjoon Lee, Subhransu Maji, Avinash Ravichandran, Stefano Soatto", "title": "Meta-Learning with Differentiable Convex Optimization", "comments": "Accepted to CVPR 2019 (Oral)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Many meta-learning approaches for few-shot learning rely on simple base\nlearners such as nearest-neighbor classifiers. However, even in the few-shot\nregime, discriminatively trained linear predictors can offer better\ngeneralization. We propose to use these predictors as base learners to learn\nrepresentations for few-shot learning and show they offer better tradeoffs\nbetween feature size and performance across a range of few-shot recognition\nbenchmarks. Our objective is to learn feature embeddings that generalize well\nunder a linear classification rule for novel categories. To efficiently solve\nthe objective, we exploit two properties of linear classifiers: implicit\ndifferentiation of the optimality conditions of the convex problem and the dual\nformulation of the optimization problem. This allows us to use high-dimensional\nembeddings with improved generalization at a modest increase in computational\noverhead. Our approach, named MetaOptNet, achieves state-of-the-art performance\non miniImageNet, tieredImageNet, CIFAR-FS, and FC100 few-shot learning\nbenchmarks. Our code is available at https://github.com/kjunelee/MetaOptNet.\n", "versions": [{"version": "v1", "created": "Sun, 7 Apr 2019 22:23:42 GMT"}, {"version": "v2", "created": "Tue, 23 Apr 2019 17:59:19 GMT"}], "update_date": "2019-04-24", "authors_parsed": [["Lee", "Kwonjoon", ""], ["Maji", "Subhransu", ""], ["Ravichandran", "Avinash", ""], ["Soatto", "Stefano", ""]]}, {"id": "1904.03779", "submitter": "Chengkun Zhang", "authors": "Chengkun Zhang. Junbin Gao, Stephen Lu", "title": "Cluster Developing 1-Bit Matrix Completion", "comments": "16 Pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Matrix completion has a long-time history of usage as the core technique of\nrecommender systems. In particular, 1-bit matrix completion, which considers\nthe prediction as a ``Recommended'' or ``Not Recommended'' question, has proved\nits significance and validity in the field. However, while customers and\nproducts aggregate into interacted clusters, state-of-the-art model-based 1-bit\nrecommender systems do not take the consideration of grouping bias. To tackle\nthe gap, this paper introduced Group-Specific 1-bit Matrix Completion (GS1MC)\nby first-time consolidating group-specific effects into 1-bit recommender\nsystems under the low-rank latent variable framework. Additionally, to empower\nGS1MC even when grouping information is unobtainable, Cluster Developing Matrix\nCompletion (CDMC) was proposed by integrating the sparse subspace clustering\ntechnique into GS1MC. Namely, CDMC allows clustering users/items and to\nleverage their group effects into matrix completion at the same time.\nExperiments on synthetic and real-world data show that GS1MC outperforms the\ncurrent 1-bit matrix completion methods. Meanwhile, it is compelling that CDMC\ncan successfully capture items' genre features only based on sparse binary\nuser-item interactive data. Notably, GS1MC provides a new insight to\nincorporate and evaluate the efficacy of clustering methods while CDMC can be\nserved as a new tool to explore unrevealed social behavior or market\nphenomenon.\n", "versions": [{"version": "v1", "created": "Sun, 7 Apr 2019 23:50:34 GMT"}], "update_date": "2019-04-09", "authors_parsed": [["Gao", "Chengkun Zhang. Junbin", ""], ["Lu", "Stephen", ""]]}, {"id": "1904.03787", "submitter": "Chaitanya Prasad Narisetty", "authors": "Chaitanya Narisetty, and Tatsuya Komatsu and Reishi Kondo", "title": "Bayesian Non-Parametric Multi-Source Modelling Based Determined Blind\n  Source Separation", "comments": "5 pages, 2 figures. Accepted at ICASSP 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SD cs.LG eess.AS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper proposes a determined blind source separation method using\nBayesian non-parametric modelling of sources. Conventionally source signals are\nseparated from a given set of mixture signals by modelling them using\nnon-negative matrix factorization (NMF). However in NMF, a latent variable\nsignifying model complexity must be appropriately specified to avoid\nover-fitting or under-fitting. As real-world sources can be of varying and\nunknown complexities, we propose a Bayesian non-parametric framework which is\ninvariant to such latent variables. We show that our proposed method adapts to\ndifferent source complexities, while conventional methods require parameter\ntuning for optimal separation.\n", "versions": [{"version": "v1", "created": "Mon, 8 Apr 2019 00:39:30 GMT"}], "update_date": "2019-04-09", "authors_parsed": [["Narisetty", "Chaitanya", ""], ["Komatsu", "Tatsuya", ""], ["Kondo", "Reishi", ""]]}, {"id": "1904.03796", "submitter": "Hu Ding", "authors": "Hu Ding", "title": "Minimum Enclosing Ball Revisited: Stability and Sub-linear Time\n  Algorithms", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CG cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we revisit the Minimum Enclosing Ball (MEB) problem and its\nrobust version, MEB with outliers, in Euclidean space $\\mathbb{R}^d$. Though\nthe problem has been extensively studied before, most of the existing\nalgorithms need at least linear time (in the number of input points $n$ and the\ndimensionality $d$) to achieve a $(1+\\epsilon)$-approximation. Motivated by\nsome recent developments on beyond worst-case analysis, we introduce the notion\nof stability for MEB (with outliers), which is natural and easy to understand.\nRoughly speaking, an instance of MEB is stable, if the radius of the resulting\nball cannot be significantly reduced by removing a small fraction of the input\npoints. Under the stability assumption, we present two sampling algorithms for\ncomputing approximate MEB with sample complexities independent of the number of\ninput points $n$. In particular, the second algorithm has the sample complexity\neven independent of the dimensionality $d$. Further, we extend the idea to\nachieve a sub-linear time approximation algorithm for the MEB with outliers\nproblem. Note that most existing sub-linear time algorithms for the problems of\nMEB and MEB with outliers usually result in bi-criteria approximations, where\nthe \"bi-criteria\" means that the solution has to allow the approximations on\nthe radius and the number of covered points. Differently, all the algorithms\nproposed in this paper yield single-criterion approximations (with respect to\nradius). We expect that our proposed notion of stability and techniques will be\napplicable to design sub-linear time algorithms for other optimization\nproblems.\n", "versions": [{"version": "v1", "created": "Mon, 8 Apr 2019 01:39:23 GMT"}, {"version": "v2", "created": "Sun, 14 Jul 2019 03:23:20 GMT"}, {"version": "v3", "created": "Fri, 1 May 2020 01:19:59 GMT"}], "update_date": "2020-05-04", "authors_parsed": [["Ding", "Hu", ""]]}, {"id": "1904.03807", "submitter": "Chunsheng Liu", "authors": "Chunsheng Liu", "title": "Binary matrix completion with nonconvex regularizers", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Many practical problems involve the recovery of a binary matrix from partial\ninformation, which makes the binary matrix completion (BMC) technique received\nincreasing attention in machine learning. In particular, we consider a special\ncase of BMC problem, in which only a subset of positive elements can be\nobserved. In recent years, convex regularization based methods are the\nmainstream approaches for this task. However, the applications of nonconvex\nsurrogates in standard matrix completion have demonstrated better empirical\nperformance. Accordingly, we propose a novel BMC model with nonconvex\nregularizers and provide the recovery guarantee for the model. Furthermore, for\nsolving the resultant nonconvex optimization problem, we improve the popular\nproximal algorithm with acceleration strategies. It can be guaranteed that the\nconvergence rate of the algorithm is in the order of ${1/T}$, where $T$ is the\nnumber of iterations. Extensive experiments conducted on both synthetic and\nreal-world data sets demonstrate the superiority of the proposed approach over\nother competing methods.\n", "versions": [{"version": "v1", "created": "Mon, 8 Apr 2019 02:52:57 GMT"}], "update_date": "2019-04-09", "authors_parsed": [["Liu", "Chunsheng", ""]]}, {"id": "1904.03814", "submitter": "Sungjoo Ha", "authors": "Seungwoo Choi, Seokjun Seo, Beomjun Shin, Hyeongmin Byun, Martin\n  Kersner, Beomsu Kim, Dongyoung Kim, Sungjoo Ha", "title": "Temporal Convolution for Real-time Keyword Spotting on Mobile Devices", "comments": "In INTERSPEECH 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SD cs.LG cs.NE eess.AS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Keyword spotting (KWS) plays a critical role in enabling speech-based user\ninteractions on smart devices. Recent developments in the field of deep\nlearning have led to wide adoption of convolutional neural networks (CNNs) in\nKWS systems due to their exceptional accuracy and robustness. The main\nchallenge faced by KWS systems is the trade-off between high accuracy and low\nlatency. Unfortunately, there has been little quantitative analysis of the\nactual latency of KWS models on mobile devices. This is especially concerning\nsince conventional convolution-based KWS approaches are known to require a\nlarge number of operations to attain an adequate level of performance. In this\npaper, we propose a temporal convolution for real-time KWS on mobile devices.\nUnlike most of the 2D convolution-based KWS approaches that require a deep\narchitecture to fully capture both low- and high-frequency domains, we exploit\ntemporal convolutions with a compact ResNet architecture. In Google Speech\nCommand Dataset, we achieve more than \\textbf{385x} speedup on Google Pixel 1\nand surpass the accuracy compared to the state-of-the-art model. In addition,\nwe release the implementation of the proposed and the baseline models including\nan end-to-end pipeline for training models and evaluating them on mobile\ndevices.\n", "versions": [{"version": "v1", "created": "Mon, 8 Apr 2019 03:21:11 GMT"}, {"version": "v2", "created": "Mon, 18 Nov 2019 06:16:42 GMT"}], "update_date": "2019-11-19", "authors_parsed": [["Choi", "Seungwoo", ""], ["Seo", "Seokjun", ""], ["Shin", "Beomjun", ""], ["Byun", "Hyeongmin", ""], ["Kersner", "Martin", ""], ["Kim", "Beomsu", ""], ["Kim", "Dongyoung", ""], ["Ha", "Sungjoo", ""]]}, {"id": "1904.03816", "submitter": "Sungjoo Ha", "authors": "Seokjun Seo, Seungwoo Choi, Martin Kersner, Beomjun Shin, Hyungsuk\n  Yoon, Hyeongmin Byun, Sungjoo Ha", "title": "Towards Real-Time Automatic Portrait Matting on Mobile Devices", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.LG cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We tackle the problem of automatic portrait matting on mobile devices. The\nproposed model is aimed at attaining real-time inference on mobile devices with\nminimal degradation of model performance. Our model MMNet, based on\nmulti-branch dilated convolution with linear bottleneck blocks, outperforms the\nstate-of-the-art model and is orders of magnitude faster. The model can be\naccelerated four times to attain 30 FPS on Xiaomi Mi 5 device with moderate\nincrease in the gradient error. Under the same conditions, our model has an\norder of magnitude less number of parameters and is faster than Mobile\nDeepLabv3 while maintaining comparable performance. The accompanied\nimplementation can be found at \\url{https://github.com/hyperconnect/MMNet}.\n", "versions": [{"version": "v1", "created": "Mon, 8 Apr 2019 03:21:25 GMT"}], "update_date": "2019-04-09", "authors_parsed": [["Seo", "Seokjun", ""], ["Choi", "Seungwoo", ""], ["Kersner", "Martin", ""], ["Shin", "Beomjun", ""], ["Yoon", "Hyungsuk", ""], ["Byun", "Hyeongmin", ""], ["Ha", "Sungjoo", ""]]}, {"id": "1904.03819", "submitter": "Zhiheng Huang", "authors": "Zhiheng Huang and Bing Xiang", "title": "WeNet: Weighted Networks for Recurrent Network Architecture Search", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In recent years, there has been increasing demand for automatic architecture\nsearch in deep learning. Numerous approaches have been proposed and led to\nstate-of-the-art results in various applications, including image\nclassification and language modeling. In this paper, we propose a novel way of\narchitecture search by means of weighted networks (WeNet), which consist of a\nnumber of networks, with each assigned a weight. These weights are updated with\nback-propagation to reflect the importance of different networks. Such weighted\nnetworks bear similarity to mixture of experts. We conduct experiments on Penn\nTreebank and WikiText-2. We show that the proposed WeNet can find recurrent\narchitectures which result in state-of-the-art performance.\n", "versions": [{"version": "v1", "created": "Mon, 8 Apr 2019 03:35:07 GMT"}], "update_date": "2019-04-09", "authors_parsed": [["Huang", "Zhiheng", ""], ["Xiang", "Bing", ""]]}, {"id": "1904.03821", "submitter": "Inseok Oh", "authors": "Inseok Oh, Seungeun Rho, Sangbin Moon, Seongho Son, Hyoil Lee, and\n  Jinyun Chung", "title": "Creating Pro-Level AI for a Real-Time Fighting Game Using Deep\n  Reinforcement Learning", "comments": "8 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Reinforcement learning combined with deep neural networks has performed\nremarkably well in many genres of games recently. It has surpassed human-level\nperformance in fixed game environments and turn-based two player board games.\nHowever, to the best of our knowledge, current research has yet to produce a\nresult that has surpassed human-level performance in modern complex fighting\ngames. This is due to the inherent difficulties with real-time fighting games,\nincluding: vast action spaces, action dependencies, and imperfect information.\nWe overcame these challenges and made 1v1 battle AI agents for the commercial\ngame \"Blade & Soul\". The trained agents competed against five professional\ngamers and achieved a win rate of 62%. This paper presents a practical\nreinforcement learning method that includes a novel self-play curriculum and\ndata skipping techniques. Through the curriculum, three different styles of\nagents were created by reward shaping and were trained against each other.\nAdditionally, this paper suggests data skipping techniques that could increase\ndata efficiency and facilitate explorations in vast spaces. Since our method\ncan be generally applied to all two-player competitive games with vast action\nspaces, we anticipate its application to game development including level\ndesign and automated balancing.\n", "versions": [{"version": "v1", "created": "Mon, 8 Apr 2019 03:46:24 GMT"}, {"version": "v2", "created": "Mon, 23 Sep 2019 02:01:56 GMT"}, {"version": "v3", "created": "Fri, 31 Jan 2020 08:21:56 GMT"}], "update_date": "2020-02-03", "authors_parsed": [["Oh", "Inseok", ""], ["Rho", "Seungeun", ""], ["Moon", "Sangbin", ""], ["Son", "Seongho", ""], ["Lee", "Hyoil", ""], ["Chung", "Jinyun", ""]]}, {"id": "1904.03834", "submitter": "Alexander Greaves-Tunnell", "authors": "Alexander Greaves-Tunnell and Zaid Harchaoui", "title": "A Statistical Investigation of Long Memory in Language and Music", "comments": "29 pages; expanded supplement, added details in background and\n  methods per reviewer feedback, included additional references", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG cs.SD eess.AS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Representation and learning of long-range dependencies is a central challenge\nconfronted in modern applications of machine learning to sequence data. Yet\ndespite the prominence of this issue, the basic problem of measuring long-range\ndependence, either in a given data source or as represented in a trained deep\nmodel, remains largely limited to heuristic tools. We contribute a statistical\nframework for investigating long-range dependence in current applications of\ndeep sequence modeling, drawing on the well-developed theory of long memory\nstochastic processes. This framework yields testable implications concerning\nthe relationship between long memory in real-world data and its learned\nrepresentation in a deep learning architecture, which are explored through a\nsemiparametric framework adapted to the high-dimensional setting.\n", "versions": [{"version": "v1", "created": "Mon, 8 Apr 2019 04:36:14 GMT"}, {"version": "v2", "created": "Fri, 7 Jun 2019 01:15:36 GMT"}], "update_date": "2019-06-10", "authors_parsed": [["Greaves-Tunnell", "Alexander", ""], ["Harchaoui", "Zaid", ""]]}, {"id": "1904.03837", "submitter": "Xiaohan Ding", "authors": "Xiaohan Ding, Guiguang Ding, Yuchen Guo, Jungong Han", "title": "Centripetal SGD for Pruning Very Deep Convolutional Networks with\n  Complicated Structure", "comments": "CVPR 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The redundancy is widely recognized in Convolutional Neural Networks (CNNs),\nwhich enables to remove unimportant filters from convolutional layers so as to\nslim the network with acceptable performance drop. Inspired by the linear and\ncombinational properties of convolution, we seek to make some filters\nincreasingly close and eventually identical for network slimming. To this end,\nwe propose Centripetal SGD (C-SGD), a novel optimization method, which can\ntrain several filters to collapse into a single point in the parameter\nhyperspace. When the training is completed, the removal of the identical\nfilters can trim the network with NO performance loss, thus no finetuning is\nneeded. By doing so, we have partly solved an open problem of constrained\nfilter pruning on CNNs with complicated structure, where some layers must be\npruned following others. Our experimental results on CIFAR-10 and ImageNet have\njustified the effectiveness of C-SGD-based filter pruning. Moreover, we have\nprovided empirical evidences for the assumption that the redundancy in deep\nneural networks helps the convergence of training by showing that a redundant\nCNN trained using C-SGD outperforms a normally trained counterpart with the\nequivalent width.\n", "versions": [{"version": "v1", "created": "Mon, 8 Apr 2019 04:48:02 GMT"}], "update_date": "2019-04-09", "authors_parsed": [["Ding", "Xiaohan", ""], ["Ding", "Guiguang", ""], ["Guo", "Yuchen", ""], ["Han", "Jungong", ""]]}, {"id": "1904.03851", "submitter": "Chao Huang", "authors": "Chao Huang, Haojie Liu, Tong Chen, Qiu Shen, and Zhan Ma", "title": "Extreme Image Coding via Multiscale Autoencoders With Generative\n  Adversarial Optimization", "comments": "Accepted to IEEE VCIP 2019 as an oral presentation", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.IV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a MultiScale AutoEncoder(MSAE) based extreme image compression\nframework to offer visually pleasing reconstruction at a very low bitrate. Our\nmethod leverages the \"priors\" at different resolution scale to improve the\ncompression efficiency, and also employs the generative adversarial\nnetwork(GAN) with multiscale discriminators to perform the end-to-end trainable\nrate-distortion optimization. We compare the perceptual quality of our\nreconstructions with traditional compression algorithms using High-Efficiency\nVideo Coding(HEVC) based Intra Profile and JPEG2000 on the public Cityscapes\nand ADE20K datasets, demonstrating the significant subjective quality\nimprovement.\n", "versions": [{"version": "v1", "created": "Mon, 8 Apr 2019 05:52:00 GMT"}, {"version": "v2", "created": "Fri, 3 Jan 2020 17:32:15 GMT"}], "update_date": "2020-01-06", "authors_parsed": [["Huang", "Chao", ""], ["Liu", "Haojie", ""], ["Chen", "Tong", ""], ["Shen", "Qiu", ""], ["Ma", "Zhan", ""]]}, {"id": "1904.03858", "submitter": "Alexander Wein", "authors": "Alexander S. Wein, Ahmed El Alaoui, Cristopher Moore", "title": "The Kikuchi Hierarchy and Tensor PCA", "comments": "42 pages. This version adds results on odd-order tensor PCA and\n  even-arity XOR refutation", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cond-mat.stat-mech cs.LG math.ST stat.ML stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  For the tensor PCA (principal component analysis) problem, we propose a new\nhierarchy of increasingly powerful algorithms with increasing runtime. Our\nhierarchy is analogous to the sum-of-squares (SOS) hierarchy but is instead\ninspired by statistical physics and related algorithms such as belief\npropagation and AMP (approximate message passing). Our level-$\\ell$ algorithm\ncan be thought of as a linearized message-passing algorithm that keeps track of\n$\\ell$-wise dependencies among the hidden variables. Specifically, our\nalgorithms are spectral methods based on the Kikuchi Hessian, which generalizes\nthe well-studied Bethe Hessian to the higher-order Kikuchi free energies.\n  It is known that AMP, the flagship algorithm of statistical physics, has\nsubstantially worse performance than SOS for tensor PCA. In this work we\n'redeem' the statistical physics approach by showing that our hierarchy gives a\npolynomial-time algorithm matching the performance of SOS. Our hierarchy also\nyields a continuum of subexponential-time algorithms, and we prove that these\nachieve the same (conjecturally optimal) tradeoff between runtime and\nstatistical power as SOS. Our proofs are much simpler than prior work, and also\napply to the related problem of refuting random $k$-XOR formulas. The results\nwe present here apply to tensor PCA for tensors of all orders, and to $k$-XOR\nwhen $k$ is even.\n  Our methods suggest a new avenue for systematically obtaining optimal\nalgorithms for Bayesian inference problems, and our results constitute a step\ntoward unifying the statistical physics and sum-of-squares approaches to\nalgorithm design.\n", "versions": [{"version": "v1", "created": "Mon, 8 Apr 2019 06:26:35 GMT"}, {"version": "v2", "created": "Tue, 1 Oct 2019 14:35:50 GMT"}], "update_date": "2019-10-02", "authors_parsed": [["Wein", "Alexander S.", ""], ["Alaoui", "Ahmed El", ""], ["Moore", "Cristopher", ""]]}, {"id": "1904.03866", "submitter": "Abhimanyu Das", "authors": "Abhimanyu Das, Sreenivas Gollapudi, Ravi Kumar, Rina Panigrahy", "title": "On the Learnability of Deep Random Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we study the learnability of deep random networks from both\ntheoretical and practical points of view. On the theoretical front, we show\nthat the learnability of random deep networks with sign activation drops\nexponentially with its depth. On the practical front, we find that the\nlearnability drops sharply with depth even with the state-of-the-art training\nmethods, suggesting that our stylized theoretical results are closer to\nreality.\n", "versions": [{"version": "v1", "created": "Mon, 8 Apr 2019 07:02:06 GMT"}], "update_date": "2019-04-09", "authors_parsed": [["Das", "Abhimanyu", ""], ["Gollapudi", "Sreenivas", ""], ["Kumar", "Ravi", ""], ["Panigrahy", "Rina", ""]]}, {"id": "1904.03867", "submitter": "Christoph Molnar", "authors": "Christoph Molnar, Giuseppe Casalicchio, Bernd Bischl", "title": "Quantifying Model Complexity via Functional Decomposition for Better\n  Post-Hoc Interpretability", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Post-hoc model-agnostic interpretation methods such as partial dependence\nplots can be employed to interpret complex machine learning models. While these\ninterpretation methods can be applied regardless of model complexity, they can\nproduce misleading and verbose results if the model is too complex, especially\nw.r.t. feature interactions. To quantify the complexity of arbitrary machine\nlearning models, we propose model-agnostic complexity measures based on\nfunctional decomposition: number of features used, interaction strength and\nmain effect complexity. We show that post-hoc interpretation of models that\nminimize the three measures is more reliable and compact. Furthermore, we\ndemonstrate the application of these measures in a multi-objective optimization\napproach which simultaneously minimizes loss and complexity.\n", "versions": [{"version": "v1", "created": "Mon, 8 Apr 2019 07:02:14 GMT"}, {"version": "v2", "created": "Mon, 23 Sep 2019 12:04:16 GMT"}], "update_date": "2019-09-24", "authors_parsed": [["Molnar", "Christoph", ""], ["Casalicchio", "Giuseppe", ""], ["Bischl", "Bernd", ""]]}, {"id": "1904.03876", "submitter": "Lucas Ondel", "authors": "Lucas Ondel, Hari Krishna Vydana, Luk\\'a\\v{s} Burget, Jan\n  \\v{C}ernock\\'y", "title": "Bayesian Subspace Hidden Markov Model for Acoustic Unit Discovery", "comments": "Accepted to Interspeech 2019 * corrected typos * Recalculated the\n  segmentation using +-2 frames tolerance to comply with other publications", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.SD eess.AS stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This work tackles the problem of learning a set of language specific acoustic\nunits from unlabeled speech recordings given a set of labeled recordings from\nother languages. Our approach may be described by the following two steps\nprocedure: first the model learns the notion of acoustic units from the\nlabelled data and then the model uses its knowledge to find new acoustic units\non the target language. We implement this process with the Bayesian Subspace\nHidden Markov Model (SHMM), a model akin to the Subspace Gaussian Mixture Model\n(SGMM) where each low dimensional embedding represents an acoustic unit rather\nthan just a HMM's state. The subspace is trained on 3 languages from the\nGlobalPhone corpus (German, Polish and Spanish) and the AUs are discovered on\nthe TIMIT corpus. Results, measured in equivalent Phone Error Rate, show that\nthis approach significantly outperforms previous HMM based acoustic units\ndiscovery systems and compares favorably with the Variational Auto Encoder-HMM.\n", "versions": [{"version": "v1", "created": "Mon, 8 Apr 2019 07:48:36 GMT"}, {"version": "v2", "created": "Tue, 2 Jul 2019 14:35:26 GMT"}], "update_date": "2019-07-03", "authors_parsed": [["Ondel", "Lucas", ""], ["Vydana", "Hari Krishna", ""], ["Burget", "Luk\u00e1\u0161", ""], ["\u010cernock\u00fd", "Jan", ""]]}, {"id": "1904.03885", "submitter": "Peratham Wiriyathammabhum Mr.", "authors": "Peratham Wiriyathammabhum, Abhinav Shrivastava, Vlad I. Morariu, Larry\n  S. Davis", "title": "Referring to Objects in Videos using Spatio-Temporal Identifying\n  Descriptions", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper presents a new task, the grounding of spatio-temporal identifying\ndescriptions in videos. Previous work suggests potential bias in existing\ndatasets and emphasizes the need for a new data creation schema to better model\nlinguistic structure. We introduce a new data collection scheme based on\ngrammatical constraints for surface realization to enable us to investigate the\nproblem of grounding spatio-temporal identifying descriptions in videos. We\nthen propose a two-stream modular attention network that learns and grounds\nspatio-temporal identifying descriptions based on appearance and motion. We\nshow that motion modules help to ground motion-related words and also help to\nlearn in appearance modules because modular neural networks resolve task\ninterference between modules. Finally, we propose a future challenge and a need\nfor a robust system arising from replacing ground truth visual annotations with\nautomatic video object detector and temporal event localization.\n", "versions": [{"version": "v1", "created": "Mon, 8 Apr 2019 08:28:54 GMT"}], "update_date": "2019-04-09", "authors_parsed": [["Wiriyathammabhum", "Peratham", ""], ["Shrivastava", "Abhinav", ""], ["Morariu", "Vlad I.", ""], ["Davis", "Larry S.", ""]]}, {"id": "1904.03892", "submitter": "Taibou Birgui Sekou", "authors": "Taibou Birgui Sekou and Moncef Hidane and Julien Olivier and Hubert\n  Cardot", "title": "From Patch to Image Segmentation using Fully Convolutional Networks --\n  Application to Retinal Images", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep learning based models, generally, require a large number of samples for\nappropriate training, a requirement that is difficult to satisfy in the medical\nfield. This issue can usually be avoided with a proper initialization of the\nweights. On the task of medical image segmentation in general, two techniques\nare oftentimes employed to tackle the training of a deep network $f_T$. The\nfirst one consists in reusing some weights of a network $f_S$ pre-trained on a\nlarge scale database ($e.g.$ ImageNet). This procedure, also known as\n$transfer$ $learning$, happens to reduce the flexibility when it comes to new\nnetwork design since $f_T$ is constrained to match some parts of $f_S$. The\nsecond commonly used technique consists in working on image patches to benefit\nfrom the large number of available patches. This paper brings together these\ntwo techniques and propose to train $arbitrarily$ $designed$ $networks$ that\nsegment an image in one forward pass, with a focus on relatively small\ndatabases. An experimental work have been carried out on the tasks of retinal\nblood vessel segmentation and the optic disc one, using four publicly available\ndatabases. Furthermore, three types of network are considered, going from a\nvery light weighted network to a densely connected one. The final results show\nthe efficiency of the proposed framework along with state of the art results on\nall the databases.\n", "versions": [{"version": "v1", "created": "Mon, 8 Apr 2019 08:59:12 GMT"}, {"version": "v2", "created": "Tue, 18 Jun 2019 11:14:20 GMT"}], "update_date": "2019-06-19", "authors_parsed": [["Sekou", "Taibou Birgui", ""], ["Hidane", "Moncef", ""], ["Olivier", "Julien", ""], ["Cardot", "Hubert", ""]]}, {"id": "1904.03898", "submitter": "Jue Wang", "authors": "Jue Wang, Ke Chen, Lidan Shou, Sai Wu and Sharad Mehrotra", "title": "Semi-Supervised Few-Shot Learning for Dual Question-Answer Extraction", "comments": "7 pages, 5 figures, submission to IJCAI19", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper addresses the problem of key phrase extraction from sentences.\nExisting state-of-the-art supervised methods require large amounts of annotated\ndata to achieve good performance and generalization. Collecting labeled data\nis, however, often expensive. In this paper, we redefine the problem as\nquestion-answer extraction, and present SAMIE: Self-Asking Model for\nInformation Ixtraction, a semi-supervised model which dually learns to ask and\nto answer questions by itself. Briefly, given a sentence $s$ and an answer $a$,\nthe model needs to choose the most appropriate question $\\hat q$; meanwhile,\nfor the given sentence $s$ and same question $\\hat q$ selected in the previous\nstep, the model will predict an answer $\\hat a$. The model can support few-shot\nlearning with very limited supervision. It can also be used to perform\nclustering analysis when no supervision is provided. Experimental results show\nthat the proposed method outperforms typical supervised methods especially when\ngiven little labeled data.\n", "versions": [{"version": "v1", "created": "Mon, 8 Apr 2019 09:07:30 GMT"}], "update_date": "2019-04-09", "authors_parsed": [["Wang", "Jue", ""], ["Chen", "Ke", ""], ["Shou", "Lidan", ""], ["Wu", "Sai", ""], ["Mehrotra", "Sharad", ""]]}, {"id": "1904.03901", "submitter": "Yong Luo", "authors": "Yong Luo, Tongliang Liu, Dacheng Tao, Chao Xu", "title": "Multi-View Matrix Completion for Multi-Label Image Classification", "comments": null, "journal-ref": "IEEE Transactions on Image Processing (Volume: 24, Issue: 8, Aug.\n  2015)", "doi": "10.1109/TIP.2015.2421309", "report-no": null, "categories": "stat.ML cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  There is growing interest in multi-label image classification due to its\ncritical role in web-based image analytics-based applications, such as\nlarge-scale image retrieval and browsing. Matrix completion has recently been\nintroduced as a method for transductive (semi-supervised) multi-label\nclassification, and has several distinct advantages, including robustness to\nmissing data and background noise in both feature and label space. However, it\nis limited by only considering data represented by a single-view feature, which\ncannot precisely characterize images containing several semantic concepts. To\nutilize multiple features taken from different views, we have to concatenate\nthe different features as a long vector. But this concatenation is prone to\nover-fitting and often leads to very high time complexity in MC based image\nclassification. Therefore, we propose to weightedly combine the MC outputs of\ndifferent views, and present the multi-view matrix completion (MVMC) framework\nfor transductive multi-label image classification. To learn the view\ncombination weights effectively, we apply a cross validation strategy on the\nlabeled set. In the learning process, we adopt the average precision (AP) loss,\nwhich is particular suitable for multi-label image classification. A least\nsquares loss formulation is also presented for the sake of efficiency, and the\nrobustness of the algorithm based on the AP loss compared with the other losses\nis investigated. Experimental evaluation on two real world datasets (PASCAL\nVOC' 07 and MIR Flickr) demonstrate the effectiveness of MVMC for transductive\n(semi-supervised) multi-label image classification, and show that MVMC can\nexploit complementary properties of different features and output-consistent\nlabels for improved multi-label image classification.\n", "versions": [{"version": "v1", "created": "Mon, 8 Apr 2019 09:17:56 GMT"}], "update_date": "2019-04-09", "authors_parsed": [["Luo", "Yong", ""], ["Liu", "Tongliang", ""], ["Tao", "Dacheng", ""], ["Xu", "Chao", ""]]}, {"id": "1904.03908", "submitter": "Shabab Bazrafkan", "authors": "Shabab Bazrafkan, Vincent Van Nieuwenhove, Joris Soons, Jan De\n  Beenhouwer, and Jan Sijbers", "title": "Deep Learning Based Computed Tomography Whys and Wherefores", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.IV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This is an article about the Computed Tomography (CT) and how Deep Learning\ninfluences CT reconstruction pipeline, especially in low dose scenarios.\n", "versions": [{"version": "v1", "created": "Mon, 8 Apr 2019 09:32:54 GMT"}], "update_date": "2019-04-09", "authors_parsed": [["Bazrafkan", "Shabab", ""], ["Van Nieuwenhove", "Vincent", ""], ["Soons", "Joris", ""], ["De Beenhouwer", "Jan", ""], ["Sijbers", "Jan", ""]]}, {"id": "1904.03909", "submitter": "Mikhail Langovoy", "authors": "Mikhail A. Langovoy", "title": "Generalized active learning and design of statistical experiments for\n  manifold-valued data", "comments": "To appear in the Proceedings of the 62-nd World Statistics Congress\n  (2019)", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Characterizing the appearance of real-world surfaces is a fundamental problem\nin multidimensional reflectometry, computer vision and computer graphics. For\nmany applications, appearance is sufficiently well characterized by the\nbidirectional reflectance distribution function (BRDF). We treat BRDF\nmeasurements as samples of points from high-dimensional non-linear non-convex\nmanifolds. BRDF manifolds form an infinite-dimensional space, but typically the\navailable measurements are very scarce for complicated problems such as BRDF\nestimation. Therefore, an efficient learning strategy is crucial when\nperforming the measurements.\n  In this paper, we build the foundation of a mathematical framework that\nallows to develop and apply new techniques within statistical design of\nexperiments and generalized proactive learning, in order to establish more\nefficient sampling and measurement strategies for BRDF data manifolds.\n", "versions": [{"version": "v1", "created": "Mon, 8 Apr 2019 09:35:13 GMT"}], "update_date": "2019-04-09", "authors_parsed": [["Langovoy", "Mikhail A.", ""]]}, {"id": "1904.03911", "submitter": "Soumyadeep Ghosh", "authors": "Soumyadeep Ghosh, Richa Singh, Mayank Vatsa", "title": "On Learning Density Aware Embeddings", "comments": "Accepted in IEEE CVPR 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Deep metric learning algorithms have been utilized to learn discriminative\nand generalizable models which are effective for classifying unseen classes. In\nthis paper, a novel noise tolerant deep metric learning algorithm is proposed.\nThe proposed method, termed as Density Aware Metric Learning, enforces the\nmodel to learn embeddings that are pulled towards the most dense region of the\nclusters for each class. It is achieved by iteratively shifting the estimate of\nthe center towards the dense region of the cluster thereby leading to faster\nconvergence and higher generalizability. In addition to this, the approach is\nrobust to noisy samples in the training data, often present as outliers.\nDetailed experiments and analysis on two challenging cross-modal face\nrecognition databases and two popular object recognition databases exhibit the\nefficacy of the proposed approach. It has superior convergence, requires lesser\ntraining time, and yields better accuracies than several popular deep metric\nlearning methods.\n", "versions": [{"version": "v1", "created": "Mon, 8 Apr 2019 09:35:23 GMT"}], "update_date": "2019-04-09", "authors_parsed": [["Ghosh", "Soumyadeep", ""], ["Singh", "Richa", ""], ["Vatsa", "Mayank", ""]]}, {"id": "1904.03920", "submitter": "Pierre Alquier", "authors": "Badr-Eddine Ch\\'erief-Abdellatif, Pierre Alquier, Mohammad Emtiyaz\n  Khan", "title": "A Generalization Bound for Online Variational Inference", "comments": "Published in the proceedings of ACML 2019", "journal-ref": "Proceedings in Machine Learning Research, 2019, vol. 101, pp.\n  662-677", "doi": null, "report-no": null, "categories": "stat.ML cs.LG math.ST stat.CO stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Bayesian inference provides an attractive online-learning framework to\nanalyze sequential data, and offers generalization guarantees which hold even\nwith model mismatch and adversaries. Unfortunately, exact Bayesian inference is\nrarely feasible in practice and approximation methods are usually employed, but\ndo such methods preserve the generalization properties of Bayesian inference ?\nIn this paper, we show that this is indeed the case for some variational\ninference (VI) algorithms. We consider a few existing online, tempered VI\nalgorithms, as well as a new algorithm, and derive their generalization bounds.\nOur theoretical result relies on the convexity of the variational objective,\nbut we argue that the result should hold more generally and present empirical\nevidence in support of this. Our work in this paper presents theoretical\njustifications in favor of online algorithms relying on approximate Bayesian\nmethods.\n", "versions": [{"version": "v1", "created": "Mon, 8 Apr 2019 09:53:25 GMT"}, {"version": "v2", "created": "Tue, 10 Dec 2019 07:32:41 GMT"}], "update_date": "2020-08-03", "authors_parsed": [["Ch\u00e9rief-Abdellatif", "Badr-Eddine", ""], ["Alquier", "Pierre", ""], ["Khan", "Mohammad Emtiyaz", ""]]}, {"id": "1904.03921", "submitter": "Yong Luo", "authors": "Yong Luo, Dacheng Tao, Chang Xu, Chao Xu, Hong Liu, Yonggang Wen", "title": "Multi-view Vector-valued Manifold Regularization for Multi-label Image\n  Classification", "comments": null, "journal-ref": "IEEE Transactions on Neural Networks and Learning Systems (Volume:\n  24, Issue: 5, May 2013)", "doi": "10.1109/TNNLS.2013.2238682", "report-no": null, "categories": "stat.ML cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In computer vision, image datasets used for classification are naturally\nassociated with multiple labels and comprised of multiple views, because each\nimage may contain several objects (e.g. pedestrian, bicycle and tree) and is\nproperly characterized by multiple visual features (e.g. color, texture and\nshape). Currently available tools ignore either the label relationship or the\nview complementary. Motivated by the success of the vector-valued function that\nconstructs matrix-valued kernels to explore the multi-label structure in the\noutput space, we introduce multi-view vector-valued manifold regularization\n(MV$\\mathbf{^3}$MR) to integrate multiple features. MV$\\mathbf{^3}$MR exploits\nthe complementary property of different features and discovers the intrinsic\nlocal geometry of the compact support shared by different features under the\ntheme of manifold regularization. We conducted extensive experiments on two\nchallenging, but popular datasets, PASCAL VOC' 07 (VOC) and MIR Flickr (MIR),\nand validated the effectiveness of the proposed MV$\\mathbf{^3}$MR for image\nclassification.\n", "versions": [{"version": "v1", "created": "Mon, 8 Apr 2019 09:57:18 GMT"}], "update_date": "2019-04-09", "authors_parsed": [["Luo", "Yong", ""], ["Tao", "Dacheng", ""], ["Xu", "Chang", ""], ["Xu", "Chao", ""], ["Liu", "Hong", ""], ["Wen", "Yonggang", ""]]}, {"id": "1904.03936", "submitter": "Bharath Bhushan Damodaran", "authors": "Kilian Fatras, Bharath Bhushan Damodaran, Sylvain Lobry, R\\'emi\n  Flamary, Devis Tuia, Nicolas Courty", "title": "Wasserstein Adversarial Regularization (WAR) on label noise", "comments": "In Press, IEEE Transactions on Pattern Analysis and Machine\n  Intelligence (PAMI)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Noisy labels often occur in vision datasets, especially when they are\nobtained from crowdsourcing or Web scraping. We propose a new regularization\nmethod, which enables learning robust classifiers in presence of noisy data. To\nachieve this goal, we propose a new adversarial regularization scheme based on\nthe Wasserstein distance. Using this distance allows taking into account\nspecific relations between classes by leveraging the geometric properties of\nthe labels space. Our Wasserstein Adversarial Regularization (WAR) encodes a\nselective regularization, which promotes smoothness of the classifier between\nsome classes, while preserving sufficient complexity of the decision boundary\nbetween others. We first discuss how and why adversarial regularization can be\nused in the context of label noise and then show the effectiveness of our\nmethod on five datasets corrupted with noisy labels: in both benchmarks and\nreal datasets, WAR outperforms the state-of-the-art competitors.\n", "versions": [{"version": "v1", "created": "Mon, 8 Apr 2019 10:28:12 GMT"}, {"version": "v2", "created": "Thu, 26 Sep 2019 16:21:53 GMT"}, {"version": "v3", "created": "Tue, 29 Jun 2021 07:45:32 GMT"}], "update_date": "2021-06-30", "authors_parsed": [["Fatras", "Kilian", ""], ["Damodaran", "Bharath Bhushan", ""], ["Lobry", "Sylvain", ""], ["Flamary", "R\u00e9mi", ""], ["Tuia", "Devis", ""], ["Courty", "Nicolas", ""]]}, {"id": "1904.03943", "submitter": "Quay Au", "authors": "Quay Au, Daniel Schalk, Giuseppe Casalicchio, Ramona Schoedel, Clemens\n  Stachl, Bernd Bischl", "title": "Component-Wise Boosting of Targets for Multi-Output Prediction", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Multi-output prediction deals with the prediction of several targets of\npossibly diverse types. One way to address this problem is the so called\nproblem transformation method. This method is often used in multi-label\nlearning, but can also be used for multi-output prediction due to its\ngenerality and simplicity. In this paper, we introduce an algorithm that uses\nthe problem transformation method for multi-output prediction, while\nsimultaneously learning the dependencies between target variables in a sparse\nand interpretable manner. In a first step, predictions are obtained for each\ntarget individually. Target dependencies are then learned via a component-wise\nboosting approach. We compare our new method with similar approaches in a\nbenchmark using multi-label, multivariate regression and mixed-type datasets.\n", "versions": [{"version": "v1", "created": "Mon, 8 Apr 2019 10:48:56 GMT"}], "update_date": "2019-04-09", "authors_parsed": [["Au", "Quay", ""], ["Schalk", "Daniel", ""], ["Casalicchio", "Giuseppe", ""], ["Schoedel", "Ramona", ""], ["Stachl", "Clemens", ""], ["Bischl", "Bernd", ""]]}, {"id": "1904.03949", "submitter": "Alessandro Bianchi", "authors": "Alessandro Bianchi, Moreno Raimondo Vendra, Pavlos Protopapas, Marco\n  Brambilla", "title": "Improving Image Classification Robustness through Selective CNN-Filters\n  Fine-Tuning", "comments": "arXiv admin note: text overlap with arXiv:1705.02406 by other authors", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Image quality plays a big role in CNN-based image classification performance.\nFine-tuning the network with distorted samples may be too costly for large\nnetworks. To solve this issue, we propose a transfer learning approach\noptimized to keep into account that in each layer of a CNN some filters are\nmore susceptible to image distortion than others. Our method identifies the\nmost susceptible filters and applies retraining only to the filters that show\nthe highest activation maps distance between clean and distorted images.\nFilters are ranked using the Borda count election method and then only the most\naffected filters are fine-tuned. This significantly reduces the number of\nparameters to retrain. We evaluate this approach on the CIFAR-10 and CIFAR-100\ndatasets, testing it on two different models and two different types of\ndistortion. Results show that the proposed transfer learning technique recovers\nmost of the lost performance due to input data distortion, at a considerably\nfaster pace with respect to existing methods, thanks to the reduced number of\nparameters to fine-tune. When few noisy samples are provided for training, our\nfilter-level fine tuning performs particularly well, also outperforming state\nof the art layer-level transfer learning approaches.\n", "versions": [{"version": "v1", "created": "Mon, 8 Apr 2019 11:02:05 GMT"}], "update_date": "2019-06-04", "authors_parsed": [["Bianchi", "Alessandro", ""], ["Vendra", "Moreno Raimondo", ""], ["Protopapas", "Pavlos", ""], ["Brambilla", "Marco", ""]]}, {"id": "1904.03953", "submitter": "Zhongheng Li", "authors": "Fei Wang, Zhongheng Li, Fang He, Rong Wang, Weizhong Yu, Feiping Nie", "title": "Feature Learning Viewpoint of AdaBoost and a New Algorithm", "comments": null, "journal-ref": "IEEE Access, vol. 7, pp. 149890-149899, 2019", "doi": "10.1109/ACCESS.2019.2947359", "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The AdaBoost algorithm has the superiority of resisting overfitting.\nUnderstanding the mysteries of this phenomena is a very fascinating fundamental\ntheoretical problem. Many studies are devoted to explaining it from statistical\nview and margin theory. In this paper, we illustrate it from feature learning\nviewpoint, and propose the AdaBoost+SVM algorithm, which can explain the\nresistant to overfitting of AdaBoost directly and easily to understand.\nFirstly, we adopt the AdaBoost algorithm to learn the base classifiers. Then,\ninstead of directly weighted combination the base classifiers, we regard them\nas features and input them to SVM classifier. With this, the new coefficient\nand bias can be obtained, which can be used to construct the final classifier.\nWe explain the rationality of this and illustrate the theorem that when the\ndimension of these features increases, the performance of SVM would not be\nworse, which can explain the resistant to overfitting of AdaBoost.\n", "versions": [{"version": "v1", "created": "Mon, 8 Apr 2019 11:07:50 GMT"}], "update_date": "2020-07-30", "authors_parsed": [["Wang", "Fei", ""], ["Li", "Zhongheng", ""], ["He", "Fang", ""], ["Wang", "Rong", ""], ["Yu", "Weizhong", ""], ["Nie", "Feiping", ""]]}, {"id": "1904.03959", "submitter": "Christian Alexander Scholbeck", "authors": "Christian A. Scholbeck, Christoph Molnar, Christian Heumann, Bernd\n  Bischl, Giuseppe Casalicchio", "title": "Sampling, Intervention, Prediction, Aggregation: A Generalized Framework\n  for Model-Agnostic Interpretations", "comments": null, "journal-ref": null, "doi": "10.1007/978-3-030-43823-4_18", "report-no": "Cellier P., Driessens K. (eds) Machine Learning and Knowledge\n  Discovery in Databases. ECML PKDD 2019. Communications in Computer and\n  Information Science, vol 1167. Springer, Cham", "categories": "cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Model-agnostic interpretation techniques allow us to explain the behavior of\nany predictive model. Due to different notations and terminology, it is\ndifficult to see how they are related. A unified view on these methods has been\nmissing. We present the generalized SIPA (sampling, intervention, prediction,\naggregation) framework of work stages for model-agnostic interpretations and\ndemonstrate how several prominent methods for feature effects can be embedded\ninto the proposed framework. Furthermore, we extend the framework to feature\nimportance computations by pointing out how variance-based and\nperformance-based importance measures are based on the same work stages. The\nSIPA framework reduces the diverse set of model-agnostic techniques to a single\nmethodology and establishes a common terminology to discuss them in future\nwork.\n", "versions": [{"version": "v1", "created": "Mon, 8 Apr 2019 11:20:04 GMT"}, {"version": "v2", "created": "Wed, 31 Jul 2019 06:53:18 GMT"}, {"version": "v3", "created": "Fri, 9 Aug 2019 14:06:54 GMT"}, {"version": "v4", "created": "Thu, 13 Feb 2020 11:08:54 GMT"}], "update_date": "2020-04-01", "authors_parsed": [["Scholbeck", "Christian A.", ""], ["Molnar", "Christoph", ""], ["Heumann", "Christian", ""], ["Bischl", "Bernd", ""], ["Casalicchio", "Giuseppe", ""]]}, {"id": "1904.03969", "submitter": "Isabelle Augenstein", "authors": "Mareike Hartmann and Tallulah Jansen and Isabelle Augenstein and\n  Anders S{\\o}gaard", "title": "Issue Framing in Online Discussion Fora", "comments": "To appear in NAACL-HLT 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In online discussion fora, speakers often make arguments for or against\nsomething, say birth control, by highlighting certain aspects of the topic. In\nsocial science, this is referred to as issue framing. In this paper, we\nintroduce a new issue frame annotated corpus of online discussions. We explore\nto what extent models trained to detect issue frames in newswire and social\nmedia can be transferred to the domain of discussion fora, using a combination\nof multi-task and adversarial training, assuming only unlabeled training data\nin the target domain.\n", "versions": [{"version": "v1", "created": "Mon, 8 Apr 2019 11:36:53 GMT"}, {"version": "v2", "created": "Tue, 9 Apr 2019 07:58:22 GMT"}], "update_date": "2019-04-10", "authors_parsed": [["Hartmann", "Mareike", ""], ["Jansen", "Tallulah", ""], ["Augenstein", "Isabelle", ""], ["S\u00f8gaard", "Anders", ""]]}, {"id": "1904.03971", "submitter": "Ehsan Montahaei", "authors": "Ehsan Montahaei, Danial Alihosseini and Mahdieh Soleymani Baghshah", "title": "Jointly Measuring Diversity and Quality in Text Generation Models", "comments": "Accepted by NAACL 2019 workshop (NeuralGen 2019)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CL stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Text generation is an important Natural Language Processing task with various\napplications. Although several metrics have already been introduced to evaluate\nthe text generation methods, each of them has its own shortcomings. The most\nwidely used metrics such as BLEU only consider the quality of generated\nsentences and neglect their diversity. For example, repeatedly generation of\nonly one high quality sentence would result in a high BLEU score. On the other\nhand, the more recent metric introduced to evaluate the diversity of generated\ntexts known as Self-BLEU ignores the quality of generated texts. In this paper,\nwe propose metrics to evaluate both the quality and diversity simultaneously by\napproximating the distance of the learned generative model and the real data\ndistribution. For this purpose, we first introduce a metric that approximates\nthis distance using n-gram based measures. Then, a feature-based measure which\nis based on a recent highly deep model trained on a large text corpus called\nBERT is introduced. Finally, for oracle training mode in which the generator's\ndensity can also be calculated, we propose to use the distance measures between\nthe corresponding explicit distributions. Eventually, the most popular and\nrecent text generation models are evaluated using both the existing and the\nproposed metrics and the preferences of the proposed metrics are determined.\n", "versions": [{"version": "v1", "created": "Mon, 8 Apr 2019 11:44:41 GMT"}, {"version": "v2", "created": "Mon, 20 May 2019 21:14:54 GMT"}], "update_date": "2019-05-22", "authors_parsed": [["Montahaei", "Ehsan", ""], ["Alihosseini", "Danial", ""], ["Baghshah", "Mahdieh Soleymani", ""]]}, {"id": "1904.03976", "submitter": "Lauri Juvela", "authors": "Lauri Juvela, Bajibabu Bollepalli, Junichi Yamagishi, Paavo Alku", "title": "GELP: GAN-Excited Linear Prediction for Speech Synthesis from\n  Mel-spectrogram", "comments": "Interspeech 2019 accepted version", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.AS cs.LG cs.SD", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent advances in neural network -based text-to-speech have reached human\nlevel naturalness in synthetic speech. The present sequence-to-sequence models\ncan directly map text to mel-spectrogram acoustic features, which are\nconvenient for modeling, but present additional challenges for vocoding (i.e.,\nwaveform generation from the acoustic features). High-quality synthesis can be\nachieved with neural vocoders, such as WaveNet, but such autoregressive models\nsuffer from slow sequential inference. Meanwhile, their existing parallel\ninference counterparts are difficult to train and require increasingly large\nmodel sizes. In this paper, we propose an alternative training strategy for a\nparallel neural vocoder utilizing generative adversarial networks, and\nintegrate a linear predictive synthesis filter into the model. Results show\nthat the proposed model achieves significant improvement in inference speed,\nwhile outperforming a WaveNet in copy-synthesis quality.\n", "versions": [{"version": "v1", "created": "Mon, 8 Apr 2019 11:58:00 GMT"}, {"version": "v2", "created": "Wed, 10 Apr 2019 12:44:57 GMT"}, {"version": "v3", "created": "Wed, 26 Jun 2019 14:25:15 GMT"}], "update_date": "2019-06-27", "authors_parsed": [["Juvela", "Lauri", ""], ["Bollepalli", "Bajibabu", ""], ["Yamagishi", "Junichi", ""], ["Alku", "Paavo", ""]]}, {"id": "1904.03987", "submitter": "Ivan Ramirez", "authors": "Iv\\'an Ram\\'irez Morales, Daniel Rivero Cebri\\'an, Enrique Fern\\'andez\n  Blanco, Alejandro Pazos Sierra", "title": "Early warning in egg production curves from commercial hens: A SVM\n  approach", "comments": null, "journal-ref": "Early warning in egg production curves from commercial hens: A SVM\n  approach, Computers and Electronics in Agriculture, Volume 121, 2016, Pages\n  169-179, ISSN 0168-1699, https://doi.org/10.1016/j.compag.2015.12.009", "doi": "10.1016/j.compag.2015.12.009", "report-no": null, "categories": "stat.AP cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Artificial Intelligence allows the improvement of our daily life, for\ninstance, speech and handwritten text recognition, real time translation and\nweather forecasting are common used applications. In the livestock sector,\nmachine learning algorithms have the potential for early detection and warning\nof problems, which represents a significant milestone in the poultry industry.\nProduction problems generate economic loss that could be avoided by acting in a\ntimely manner. In the current study, training and testing of support vector\nmachines are addressed, for an early detection of problems in the production\ncurve of commercial eggs, using farm's egg production data of 478,919 laying\nhens grouped in 24 flocks. Experiments using support vector machines with a 5\nk-fold cross-validation were performed at different previous time intervals, to\nalert with up to 5 days of forecasting interval, whether a flock will\nexperience a problem in production curve. Performance metrics such as accuracy,\nspecificity, sensitivity, and positive predictive value were evaluated,\nreaching 0-day values of 0.9874, 0.9876, 0.9783 and 0.6518 respectively on\nunseen data (test-set). The optimal forecasting interval was from zero to three\ndays, performance metrics decreases as the forecasting interval is increased.\nIt should be emphasized that this technique was able to issue an alert a day in\nadvance, achieving an accuracy of 0.9854, a specificity of 0.9865, a\nsensitivity of 0.9333 and a positive predictive value of 0.6135. This novel\napplication embedded in a computer system of poultry management is able to\nprovide significant improvements in early detection and warning of problems\nrelated to the production curve.\n", "versions": [{"version": "v1", "created": "Mon, 8 Apr 2019 12:16:06 GMT"}], "update_date": "2019-04-09", "authors_parsed": [["Morales", "Iv\u00e1n Ram\u00edrez", ""], ["Cebri\u00e1n", "Daniel Rivero", ""], ["Blanco", "Enrique Fern\u00e1ndez", ""], ["Sierra", "Alejandro Pazos", ""]]}, {"id": "1904.03990", "submitter": "Bart Theeten", "authors": "Bart Theeten, Frederik Vandeputte, Tom Van Cutsem", "title": "Import2vec - Learning Embeddings for Software Libraries", "comments": "MSR19 Conference 11 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SE cs.IR cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the problem of developing suitable learning representations\n(embeddings) for library packages that capture semantic similarity among\nlibraries. Such representations are known to improve the performance of\ndownstream learning tasks (e.g. classification) or applications such as\ncontextual search and analogical reasoning.\n  We apply word embedding techniques from natural language processing (NLP) to\ntrain embeddings for library packages (\"library vectors\"). Library vectors\nrepresent libraries by similar context of use as determined by import\nstatements present in source code. Experimental results obtained from training\nsuch embeddings on three large open source software corpora reveals that\nlibrary vectors capture semantically meaningful relationships among software\nlibraries, such as the relationship between frameworks and their plug-ins and\nlibraries commonly used together within ecosystems such as big data\ninfrastructure projects (in Java), front-end and back-end web development\nframeworks (in JavaScript) and data science toolkits (in Python).\n", "versions": [{"version": "v1", "created": "Wed, 27 Mar 2019 14:36:19 GMT"}], "update_date": "2019-04-09", "authors_parsed": [["Theeten", "Bart", ""], ["Vandeputte", "Frederik", ""], ["Van Cutsem", "Tom", ""]]}, {"id": "1904.04017", "submitter": "Frank Nielsen", "authors": "Frank Nielsen", "title": "On a generalization of the Jensen-Shannon divergence and the\n  JS-symmetrization of distances relying on abstract means", "comments": "30 pages", "journal-ref": "Entropy 2019, 21(5), 485", "doi": "10.3390/e21050485", "report-no": null, "categories": "cs.IT cs.LG math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The Jensen-Shannon divergence is a renown bounded symmetrization of the\nunbounded Kullback-Leibler divergence which measures the total Kullback-Leibler\ndivergence to the average mixture distribution. However the Jensen-Shannon\ndivergence between Gaussian distributions is not available in closed-form. To\nbypass this problem, we present a generalization of the Jensen-Shannon (JS)\ndivergence using abstract means which yields closed-form expressions when the\nmean is chosen according to the parametric family of distributions. More\ngenerally, we define the JS-symmetrizations of any distance using generalized\nstatistical mixtures derived from abstract means. In particular, we first show\nthat the geometric mean is well-suited for exponential families, and report two\nclosed-form formula for (i) the geometric Jensen-Shannon divergence between\nprobability densities of the same exponential family, and (ii) the geometric\nJS-symmetrization of the reverse Kullback-Leibler divergence. As a second\nillustrating example, we show that the harmonic mean is well-suited for the\nscale Cauchy distributions, and report a closed-form formula for the harmonic\nJensen-Shannon divergence between scale Cauchy distributions. We also define\ngeneralized Jensen-Shannon divergences between matrices (e.g., quantum\nJensen-Shannon divergences) and consider clustering with respect to these novel\nJensen-Shannon divergences.\n", "versions": [{"version": "v1", "created": "Mon, 8 Apr 2019 12:47:18 GMT"}, {"version": "v2", "created": "Tue, 30 Apr 2019 16:37:29 GMT"}, {"version": "v3", "created": "Thu, 10 Dec 2020 06:28:31 GMT"}], "update_date": "2020-12-11", "authors_parsed": [["Nielsen", "Frank", ""]]}, {"id": "1904.04019", "submitter": "Giosu\\'e Lo Bosco", "authors": "Mattia Antonino Di Gangi, Giosu\\'e Lo Bosco, Giovanni Pilato", "title": "Effectiveness of Data-Driven Induction of Semantic Spaces and\n  Traditional Classifiers for Sarcasm Detection", "comments": "37 pages, 7 figures, version 4", "journal-ref": "Natural Language Engineering, 25(2), 257-285 (2019)", "doi": "10.1017/S1351324919000019", "report-no": null, "categories": "cs.CL cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Irony and sarcasm are two complex linguistic phenomena that are widely used\nin everyday language and especially over the social media, but they represent\ntwo serious issues for automated text understanding. Many labeled corpora have\nbeen extracted from several sources to accomplish this task, and it seems that\nsarcasm is conveyed in different ways for different domains. Nonetheless, very\nlittle work has been done for comparing different methods among the available\ncorpora. Furthermore, usually, each author collects and uses their own datasets\nto evaluate his own method. In this paper, we show that sarcasm detection can\nbe tackled by applying classical machine learning algorithms to input texts\nsub-symbolically represented in a Latent Semantic space. The main consequence\nis that our studies establish both reference datasets and baselines for the\nsarcasm detection problem that could serve the scientific community to test\nnewly proposed methods.\n", "versions": [{"version": "v1", "created": "Tue, 2 Apr 2019 15:49:02 GMT"}, {"version": "v2", "created": "Tue, 9 Apr 2019 10:20:39 GMT"}, {"version": "v3", "created": "Mon, 15 Apr 2019 09:17:12 GMT"}, {"version": "v4", "created": "Fri, 6 Dec 2019 16:45:25 GMT"}], "update_date": "2019-12-09", "authors_parsed": [["Di Gangi", "Mattia Antonino", ""], ["Bosco", "Giosu\u00e9 Lo", ""], ["Pilato", "Giovanni", ""]]}, {"id": "1904.04021", "submitter": "Tung Nguyen Thanh", "authors": "Tasnim Mohiuddin, Thanh-Tung Nguyen and Shafiq Joty", "title": "Adaptation of Hierarchical Structured Models for Speech Act Recognition\n  in Asynchronous Conversation", "comments": "To appear in NAACL 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We address the problem of speech act recognition (SAR) in asynchronous\nconversations (forums, emails). Unlike synchronous conversations (e.g.,\nmeetings, phone), asynchronous domains lack large labeled datasets to train an\neffective SAR model. In this paper, we propose methods to effectively leverage\nabundant unlabeled conversational data and the available labeled data from\nsynchronous domains. We carry out our research in three main steps. First, we\nintroduce a neural architecture based on hierarchical LSTMs and conditional\nrandom fields (CRF) for SAR, and show that our method outperforms existing\nmethods when trained on in-domain data only. Second, we improve our initial SAR\nmodels by semi-supervised learning in the form of pretrained word embeddings\nlearned from a large unlabeled conversational corpus. Finally, we employ\nadversarial training to improve the results further by leveraging the labeled\ndata from synchronous domains and by explicitly modeling the distributional\nshift in two domains.\n", "versions": [{"version": "v1", "created": "Mon, 1 Apr 2019 04:57:25 GMT"}], "update_date": "2019-04-09", "authors_parsed": [["Mohiuddin", "Tasnim", ""], ["Nguyen", "Thanh-Tung", ""], ["Joty", "Shafiq", ""]]}, {"id": "1904.04025", "submitter": "Yannis Flet-Berliac", "authors": "Yannis Flet-Berliac, Philippe Preux", "title": "Only Relevant Information Matters: Filtering Out Noisy Samples to Boost\n  RL", "comments": "Accepted at IJCAI 2020", "journal-ref": null, "doi": "10.24963/ijcai.2020/376", "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In reinforcement learning, policy gradient algorithms optimize the policy\ndirectly and rely on sampling efficiently an environment. Nevertheless, while\nmost sampling procedures are based on direct policy sampling, self-performance\nmeasures could be used to improve such sampling prior to each policy update.\nFollowing this line of thought, we introduce SAUNA, a method where\nnon-informative transitions are rejected from the gradient update. The level of\ninformation is estimated according to the fraction of variance explained by the\nvalue function: a measure of the discrepancy between V and the empirical\nreturns. In this work, we use this metric to select samples that are useful to\nlearn from, and we demonstrate that this selection can significantly improve\nthe performance of policy gradient methods. In this paper: (a) We define\nSAUNA's metric and introduce its method to filter transitions. (b) We conduct\nexperiments on a set of benchmark continuous control problems. SAUNA\nsignificantly improves performance. (c) We investigate how SAUNA reliably\nselects samples with the most positive impact on learning and study its\nimprovement on both performance and sample efficiency.\n", "versions": [{"version": "v1", "created": "Mon, 8 Apr 2019 12:53:12 GMT"}, {"version": "v2", "created": "Wed, 10 Apr 2019 10:57:34 GMT"}, {"version": "v3", "created": "Wed, 25 Sep 2019 14:16:56 GMT"}, {"version": "v4", "created": "Wed, 13 May 2020 09:45:42 GMT"}, {"version": "v5", "created": "Fri, 20 Nov 2020 16:04:51 GMT"}], "update_date": "2020-11-23", "authors_parsed": [["Flet-Berliac", "Yannis", ""], ["Preux", "Philippe", ""]]}, {"id": "1904.04047", "submitter": "Thomas Manzini", "authors": "Thomas Manzini, Yao Chong Lim, Yulia Tsvetkov, Alan W Black", "title": "Black is to Criminal as Caucasian is to Police: Detecting and Removing\n  Multiclass Bias in Word Embeddings", "comments": "Accepted as a conference paper at NAACL. 5 Pages excluding\n  references, additional page for appendix", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Online texts -- across genres, registers, domains, and styles -- are riddled\nwith human stereotypes, expressed in overt or subtle ways. Word embeddings,\ntrained on these texts, perpetuate and amplify these stereotypes, and propagate\nbiases to machine learning models that use word embeddings as features. In this\nwork, we propose a method to debias word embeddings in multiclass settings such\nas race and religion, extending the work of (Bolukbasi et al., 2016) from the\nbinary setting, such as binary gender. Next, we propose a novel methodology for\nthe evaluation of multiclass debiasing. We demonstrate that our multiclass\ndebiasing is robust and maintains the efficacy in standard NLP tasks.\n", "versions": [{"version": "v1", "created": "Wed, 3 Apr 2019 22:17:27 GMT"}, {"version": "v2", "created": "Mon, 13 May 2019 16:59:50 GMT"}, {"version": "v3", "created": "Tue, 2 Jul 2019 01:16:15 GMT"}], "update_date": "2019-07-03", "authors_parsed": [["Manzini", "Thomas", ""], ["Lim", "Yao Chong", ""], ["Tsvetkov", "Yulia", ""], ["Black", "Alan W", ""]]}, {"id": "1904.04049", "submitter": "Wenbo Zhao", "authors": "Wenbo Zhao, Tagyoung Chung, Anuj Goyal, Angeliki Metallinou", "title": "Simple Question Answering with Subgraph Ranking and Joint-Scoring", "comments": "Accepted by The 2019 Annual Conference of the North American Chapter\n  of the Association for Computational Linguistics (NAACL-HLT 2019). 11 pages,\n  1 figure", "journal-ref": null, "doi": "10.18653/v1/N19-1029", "report-no": null, "categories": "cs.CL cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Knowledge graph based simple question answering (KBSQA) is a major area of\nresearch within question answering. Although only dealing with simple\nquestions, i.e., questions that can be answered through a single knowledge base\n(KB) fact, this task is neither simple nor close to being solved. Targeting on\nthe two main steps, subgraph selection and fact selection, the research\ncommunity has developed sophisticated approaches. However, the importance of\nsubgraph ranking and leveraging the subject--relation dependency of a KB fact\nhave not been sufficiently explored. Motivated by this, we present a unified\nframework to describe and analyze existing approaches. Using this framework as\na starting point, we focus on two aspects: improving subgraph selection through\na novel ranking method and leveraging the subject--relation dependency by\nproposing a joint scoring CNN model with a novel loss function that enforces\nthe well-order of scores. Our methods achieve a new state of the art (85.44% in\naccuracy) on the SimpleQuestions dataset.\n", "versions": [{"version": "v1", "created": "Thu, 4 Apr 2019 02:20:50 GMT"}], "update_date": "2020-02-13", "authors_parsed": [["Zhao", "Wenbo", ""], ["Chung", "Tagyoung", ""], ["Goyal", "Anuj", ""], ["Metallinou", "Angeliki", ""]]}, {"id": "1904.04055", "submitter": "Jan Koco\\'n", "authors": "Jan Koco\\'n, Micha{\\l} Gawor", "title": "Evaluating KGR10 Polish word embeddings in the recognition of temporal\n  expressions using BiLSTM-CRF", "comments": "Presented at TFML 2019 (Theoretical Foundations of Machine Learning)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The article introduces a new set of Polish word embeddings, built using KGR10\ncorpus, which contains more than 4 billion words. These embeddings are\nevaluated in the problem of recognition of temporal expressions (timexes) for\nthe Polish language. We described the process of KGR10 corpus creation and a\nnew approach to the recognition problem using Bidirectional Long-Short Term\nMemory (BiLSTM) network with additional CRF layer, where specific embeddings\nare essential. We presented experiments and conclusions drawn from them.\n", "versions": [{"version": "v1", "created": "Wed, 3 Apr 2019 14:47:30 GMT"}], "update_date": "2019-04-09", "authors_parsed": [["Koco\u0144", "Jan", ""], ["Gawor", "Micha\u0142", ""]]}, {"id": "1904.04057", "submitter": "Hang Zou", "authors": "Hang Zou, Chao Zhang and Samson Lasaulce", "title": "Task Oriented Channel State Information Quantization", "comments": "2 pages, 2 figures", "journal-ref": "IEEE 2018 International Symposium on Personal, Indoor and Mobile\n  Radio Communications (PIMRC'18)", "doi": "10.1109/PIMRC.2018.8580826", "report-no": null, "categories": "cs.IT cs.LG math.IT stat.ML", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  In this paper, we propose a new perspective for quantizing a signal and more\nspecifically the channel state information (CSI). The proposed point of view is\nfully relevant for a receiver which has to send a quantized version of the\nchannel state to the transmitter. Roughly, the key idea is that the receiver\nsends the right amount of information to the transmitter so that the latter be\nable to take its (resource allocation) decision. More formally, the decision\ntask of the transmitter is to maximize an utility function u(x;g) with respect\nto x (e.g., a power allocation vector) given the knowledge of a quantized\nversion of the function parameters g. We exhibit a special case of an\nenergy-efficient power control (PC) problem for which the optimal task oriented\nCSI quantizer (TOCQ) can be found analytically. For more general utility\nfunctions, we propose to use neural networks (NN) based learning. Simulations\nshow that the compression rate obtained by adapting the feedback information\nrate to the function to be optimized may be significantly increased.\n", "versions": [{"version": "v1", "created": "Tue, 2 Apr 2019 14:52:51 GMT"}], "update_date": "2019-04-09", "authors_parsed": [["Zou", "Hang", ""], ["Zhang", "Chao", ""], ["Lasaulce", "Samson", ""]]}, {"id": "1904.04058", "submitter": "Ramakrishna Tipireddy", "authors": "Ramakrishna Tipireddy, Paris Perdikaris, Panos Stinis and Alexandre\n  Tartakovsky", "title": "A comparative study of physics-informed neural network models for\n  learning unknown dynamics and constitutive relations", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.NA math.DS math.NA physics.comp-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We investigate the use of discrete and continuous versions of\nphysics-informed neural network methods for learning unknown dynamics or\nconstitutive relations of a dynamical system. For the case of unknown dynamics,\nwe represent all the dynamics with a deep neural network (DNN). When the\ndynamics of the system are known up to the specification of constitutive\nrelations (that can depend on the state of the system), we represent these\nconstitutive relations with a DNN. The discrete versions combine classical\nmultistep discretization methods for dynamical systems with neural network\nbased machine learning methods. On the other hand, the continuous versions\nutilize deep neural networks to minimize the residual function for the\ncontinuous governing equations. We use the case of a fedbatch bioreactor system\nto study the effectiveness of these approaches and discuss conditions for their\napplicability. Our results indicate that the accuracy of the trained neural\nnetwork models is much higher for the cases where we only have to learn a\nconstitutive relation instead of the whole dynamics. This finding corroborates\nthe well-known fact from scientific computing that building as much structural\ninformation is available into an algorithm can enhance its efficiency and/or\naccuracy.\n", "versions": [{"version": "v1", "created": "Tue, 2 Apr 2019 23:52:29 GMT"}], "update_date": "2019-04-11", "authors_parsed": [["Tipireddy", "Ramakrishna", ""], ["Perdikaris", "Paris", ""], ["Stinis", "Panos", ""], ["Tartakovsky", "Alexandre", ""]]}, {"id": "1904.04061", "submitter": "Yong Luo", "authors": "Yong Luo, Yonggang Wen, Tongliang Liu, Dacheng Tao", "title": "Transferring Knowledge Fragments for Learning Distance Metric from A\n  Heterogeneous Domain", "comments": null, "journal-ref": "IEEE Transactions on Pattern Analysis and Machine Intelligence\n  (Volume: 41, Issue: 4, April 1 2019)", "doi": "10.1109/TPAMI.2018.2824309", "report-no": null, "categories": "stat.ML cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The goal of transfer learning is to improve the performance of target\nlearning task by leveraging information (or transferring knowledge) from other\nrelated tasks. In this paper, we examine the problem of transfer distance\nmetric learning (DML), which usually aims to mitigate the label information\ndeficiency issue in the target DML. Most of the current Transfer DML (TDML)\nmethods are not applicable to the scenario where data are drawn from\nheterogeneous domains. Some existing heterogeneous transfer learning (HTL)\napproaches can learn target distance metric by usually transforming the samples\nof source and target domain into a common subspace. However, these approaches\nlack flexibility in real-world applications, and the learned transformations\nare often restricted to be linear. This motivates us to develop a general\nflexible heterogeneous TDML (HTDML) framework. In particular, any\n(linear/nonlinear) DML algorithms can be employed to learn the source metric\nbeforehand. Then the pre-learned source metric is represented as a set of\nknowledge fragments to help target metric learning. We show how generalization\nerror in the target domain could be reduced using the proposed transfer\nstrategy, and develop novel algorithm to learn either linear or nonlinear\ntarget metric. Extensive experiments on various applications demonstrate the\neffectiveness of the proposed method.\n", "versions": [{"version": "v1", "created": "Mon, 8 Apr 2019 13:44:22 GMT"}], "update_date": "2019-04-09", "authors_parsed": [["Luo", "Yong", ""], ["Wen", "Yonggang", ""], ["Liu", "Tongliang", ""], ["Tao", "Dacheng", ""]]}, {"id": "1904.04081", "submitter": "Yong Luo", "authors": "Yong Luo, Yonggang Wen, Dacheng Tao", "title": "Heterogeneous Multi-task Metric Learning across Multiple Domains", "comments": null, "journal-ref": "IEEE Transactions on Neural Networks and Learning Systems (Volume:\n  29, Issue: 9, Sept. 2018)", "doi": "10.1109/TNNLS.2017.2750321", "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Distance metric learning (DML) plays a crucial role in diverse machine\nlearning algorithms and applications. When the labeled information in target\ndomain is limited, transfer metric learning (TML) helps to learn the metric by\nleveraging the sufficient information from other related domains. Multi-task\nmetric learning (MTML), which can be regarded as a special case of TML,\nperforms transfer across all related domains. Current TML tools usually assume\nthat the same feature representation is exploited for different domains.\nHowever, in real-world applications, data may be drawn from heterogeneous\ndomains. Heterogeneous transfer learning approaches can be adopted to remedy\nthis drawback by deriving a metric from the learned transformation across\ndifferent domains. But they are often limited in that only two domains can be\nhandled. To appropriately handle multiple domains, we develop a novel\nheterogeneous multi-task metric learning (HMTML) framework. In HMTML, the\nmetrics of all different domains are learned together. The transformations\nderived from the metrics are utilized to induce a common subspace, and the\nhigh-order covariance among the predictive structures of these domains is\nmaximized in this subspace. There do exist a few heterogeneous transfer\nlearning approaches that deal with multiple domains, but the high-order\nstatistics (correlation information), which can only be exploited by\nsimultaneously examining all domains, is ignored in these approaches. Compared\nwith them, the proposed HMTML can effectively explore such high-order\ninformation, thus obtaining more reliable feature transformations and metrics.\nEffectiveness of our method is validated by the extensive and intensive\nexperiments on text categorization, scene classification, and social image\nannotation.\n", "versions": [{"version": "v1", "created": "Mon, 8 Apr 2019 13:59:36 GMT"}], "update_date": "2019-04-09", "authors_parsed": [["Luo", "Yong", ""], ["Wen", "Yonggang", ""], ["Tao", "Dacheng", ""]]}, {"id": "1904.04088", "submitter": "Yong Luo", "authors": "Yong Luo, Yonggang Wen, Dacheng Tao, Jie Gui, Chao Xu", "title": "Large Margin Multi-modal Multi-task Feature Extraction for Image\n  Classification", "comments": null, "journal-ref": "IEEE Transactions on Image Processing (Volume: 25, Issue: 1, Jan.\n  2016)", "doi": "10.1109/TIP.2015.2495116", "report-no": null, "categories": "stat.ML cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The features used in many image analysis-based applications are frequently of\nvery high dimension. Feature extraction offers several advantages in\nhigh-dimensional cases, and many recent studies have used multi-task feature\nextraction approaches, which often outperform single-task feature extraction\napproaches. However, most of these methods are limited in that they only\nconsider data represented by a single type of feature, even though features\nusually represent images from multiple modalities. We therefore propose a novel\nlarge margin multi-modal multi-task feature extraction (LM3FE) framework for\nhandling multi-modal features for image classification. In particular, LM3FE\nsimultaneously learns the feature extraction matrix for each modality and the\nmodality combination coefficients. In this way, LM3FE not only handles\ncorrelated and noisy features, but also utilizes the complementarity of\ndifferent modalities to further help reduce feature redundancy in each\nmodality. The large margin principle employed also helps to extract strongly\npredictive features so that they are more suitable for prediction (e.g.,\nclassification). An alternating algorithm is developed for problem optimization\nand each sub-problem can be efficiently solved. Experiments on two challenging\nreal-world image datasets demonstrate the effectiveness and superiority of the\nproposed method.\n", "versions": [{"version": "v1", "created": "Mon, 8 Apr 2019 14:14:19 GMT"}], "update_date": "2019-04-09", "authors_parsed": [["Luo", "Yong", ""], ["Wen", "Yonggang", ""], ["Tao", "Dacheng", ""], ["Gui", "Jie", ""], ["Xu", "Chao", ""]]}, {"id": "1904.04096", "submitter": "Fatma Nasoz", "authors": "Nishit Shrestha and Fatma Nasoz", "title": "Deep Learning Sentiment Analysis of Amazon.com Reviews and Ratings", "comments": "15 pages, 10 figures, 3 tables, journal article", "journal-ref": "International Journal on Soft Computing, Artificial Intelligence\n  and Applications (IJSCAI), Vol.8, No.1, February 2019", "doi": "10.5121/ijscai.2019.8101", "report-no": null, "categories": "cs.IR cs.CL cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Our study employs sentiment analysis to evaluate the compatibility of\nAmazon.com reviews with their corresponding ratings. Sentiment analysis is the\ntask of identifying and classifying the sentiment expressed in a piece of text\nas being positive or negative. On e-commerce websites such as Amazon.com,\nconsumers can submit their reviews along with a specific polarity rating. In\nsome instances, there is a mismatch between the review and the rating. To\nidentify the reviews with mismatched ratings we performed sentiment analysis\nusing deep learning on Amazon.com product review data. Product reviews were\nconverted to vectors using paragraph vector, which then was used to train a\nrecurrent neural network with gated recurrent unit. Our model incorporated both\nsemantic relationship of review text and product information. We also developed\na web service application that predicts the rating score for a submitted review\nusing the trained model and if there is a mismatch between predicted rating\nscore and submitted rating score, it provides feedback to the reviewer.\n", "versions": [{"version": "v1", "created": "Thu, 4 Apr 2019 21:34:45 GMT"}], "update_date": "2019-04-09", "authors_parsed": [["Shrestha", "Nishit", ""], ["Nasoz", "Fatma", ""]]}, {"id": "1904.04116", "submitter": "Tasnim Mohiuddin", "authors": "Tasnim Mohiuddin and Shafiq Joty", "title": "Revisiting Adversarial Autoencoder for Unsupervised Word Translation\n  with Cycle Consistency and Improved Training", "comments": "Published in NAACL-HLT 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Adversarial training has shown impressive success in learning bilingual\ndictionary without any parallel data by mapping monolingual embeddings to a\nshared space. However, recent work has shown superior performance for\nnon-adversarial methods in more challenging language pairs. In this work, we\nrevisit adversarial autoencoder for unsupervised word translation and propose\ntwo novel extensions to it that yield more stable training and improved\nresults. Our method includes regularization terms to enforce cycle consistency\nand input reconstruction, and puts the target encoders as an adversary against\nthe corresponding discriminator. Extensive experimentations with European,\nnon-European and low-resource languages show that our method is more robust and\nachieves better performance than recently proposed adversarial and\nnon-adversarial approaches.\n", "versions": [{"version": "v1", "created": "Thu, 4 Apr 2019 12:46:07 GMT"}], "update_date": "2019-04-09", "authors_parsed": [["Mohiuddin", "Tasnim", ""], ["Joty", "Shafiq", ""]]}, {"id": "1904.04123", "submitter": "Asaf Noy", "authors": "Asaf Noy, Niv Nayman, Tal Ridnik, Nadav Zamir, Sivan Doveh, Itamar\n  Friedman, Raja Giryes, and Lihi Zelnik-Manor", "title": "ASAP: Architecture Search, Anneal and Prune", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Automatic methods for Neural Architecture Search (NAS) have been shown to\nproduce state-of-the-art network models. Yet, their main drawback is the\ncomputational complexity of the search process. As some primal methods\noptimized over a discrete search space, thousands of days of GPU were required\nfor convergence. A recent approach is based on constructing a differentiable\nsearch space that enables gradient-based optimization, which reduces the search\ntime to a few days. While successful, it still includes some noncontinuous\nsteps, e.g., the pruning of many weak connections at once. In this paper, we\npropose a differentiable search space that allows the annealing of architecture\nweights, while gradually pruning inferior operations. In this way, the search\nconverges to a single output network in a continuous manner. Experiments on\nseveral vision datasets demonstrate the effectiveness of our method with\nrespect to the search cost and accuracy of the achieved model. Specifically,\nwith $0.2$ GPU search days we achieve an error rate of $1.68\\%$ on CIFAR-10.\n", "versions": [{"version": "v1", "created": "Mon, 8 Apr 2019 15:16:16 GMT"}, {"version": "v2", "created": "Thu, 10 Oct 2019 08:59:52 GMT"}], "update_date": "2019-10-11", "authors_parsed": [["Noy", "Asaf", ""], ["Nayman", "Niv", ""], ["Ridnik", "Tal", ""], ["Zamir", "Nadav", ""], ["Doveh", "Sivan", ""], ["Friedman", "Itamar", ""], ["Giryes", "Raja", ""], ["Zelnik-Manor", "Lihi", ""]]}, {"id": "1904.04137", "submitter": "Hamed Sadeghi", "authors": "Mathieu Ravaut, Hamed Sadeghi, Kin Kwan Leung, Maksims Volkovs, Laura\n  C. Rosella", "title": "Diabetes Mellitus Forecasting Using Population Health Data in Ontario,\n  Canada", "comments": "18 pages, 3 figures, 8 Tables, Submitted to 2019 ML for Healthcare\n  conference", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.AP cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Leveraging health administrative data (HAD) datasets for predicting the risk\nof chronic diseases including diabetes has gained a lot of attention in the\nmachine learning community recently. In this paper, we use the largest health\nrecords datasets of patients in Ontario,Canada. Provided by the Institute of\nClinical Evaluative Sciences (ICES), this database is age, gender and\nethnicity-diverse. The datasets include demographics, lab measurements,drug\nbenefits, healthcare system interactions, ambulatory and hospitalizations\nrecords. We perform one of the first large-scale machine learning studies with\nthis data to study the task of predicting diabetes in a range of 1-10 years\nahead, which requires no additional screening of individuals.In the best setup,\nwe reach a test AUC of 80.3 with a single-model trained on an observation\nwindow of 5 years with a one-year buffer using all datasets. A subset of top 15\nfeatures alone (out of a total of 963) could provide a test AUC of 79.1. In\nthis paper, we provide extensive machine learning model performance and feature\ncontribution analysis, which enables us to narrow down to the most important\nfeatures useful for diabetes forecasting. Examples include chronic conditions\nsuch as asthma and hypertension, lab results, diagnostic codes in insurance\nclaims, age and geographical information.\n", "versions": [{"version": "v1", "created": "Mon, 8 Apr 2019 15:46:38 GMT"}], "update_date": "2019-04-09", "authors_parsed": [["Ravaut", "Mathieu", ""], ["Sadeghi", "Hamed", ""], ["Leung", "Kin Kwan", ""], ["Volkovs", "Maksims", ""], ["Rosella", "Laura C.", ""]]}, {"id": "1904.04153", "submitter": "Han Guo", "authors": "Han Guo, Ramakanth Pasunuru, Mohit Bansal", "title": "AutoSeM: Automatic Task Selection and Mixing in Multi-Task Learning", "comments": "NAACL 2019 (12 pages)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Multi-task learning (MTL) has achieved success over a wide range of problems,\nwhere the goal is to improve the performance of a primary task using a set of\nrelevant auxiliary tasks. However, when the usefulness of the auxiliary tasks\nw.r.t. the primary task is not known a priori, the success of MTL models\ndepends on the correct choice of these auxiliary tasks and also a balanced\nmixing ratio of these tasks during alternate training. These two problems could\nbe resolved via manual intuition or hyper-parameter tuning over all\ncombinatorial task choices, but this introduces inductive bias or is not\nscalable when the number of candidate auxiliary tasks is very large. To address\nthese issues, we present AutoSeM, a two-stage MTL pipeline, where the first\nstage automatically selects the most useful auxiliary tasks via a\nBeta-Bernoulli multi-armed bandit with Thompson Sampling, and the second stage\nlearns the training mixing ratio of these selected auxiliary tasks via a\nGaussian Process based Bayesian optimization framework. We conduct several MTL\nexperiments on the GLUE language understanding tasks, and show that our AutoSeM\nframework can successfully find relevant auxiliary tasks and automatically\nlearn their mixing ratio, achieving significant performance boosts on several\nprimary tasks. Finally, we present ablations for each stage of AutoSeM and\nanalyze the learned auxiliary task choices.\n", "versions": [{"version": "v1", "created": "Mon, 8 Apr 2019 16:05:43 GMT"}], "update_date": "2019-04-09", "authors_parsed": [["Guo", "Han", ""], ["Pasunuru", "Ramakanth", ""], ["Bansal", "Mohit", ""]]}, {"id": "1904.04154", "submitter": "Robert Baldock", "authors": "Robert J. N. Baldock, Nicola Marzari", "title": "Bayesian Neural Networks at Finite Temperature", "comments": "11 pages, 4 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cond-mat.dis-nn cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We recapitulate the Bayesian formulation of neural network based classifiers\nand show that, while sampling from the posterior does indeed lead to better\ngeneralisation than is obtained by standard optimisation of the cost function,\neven better performance can in general be achieved by sampling finite\ntemperature ($T$) distributions derived from the posterior. Taking the example\nof two different deep (3 hidden layers) classifiers for MNIST data, we find\nquite different $T$ values to be appropriate in each case. In particular, for a\ntypical neural network classifier a clear minimum of the test error is observed\nat $T>0$. This suggests an early stopping criterion for full batch simulated\nannealing: cool until the average validation error starts to increase, then\nrevert to the parameters with the lowest validation error. As $T$ is increased\nclassifiers transition from accurate classifiers to classifiers that have\nhigher training error than assigning equal probability to each class. Efficient\nstudies of these temperature-induced effects are enabled using a\nreplica-exchange Hamiltonian Monte Carlo simulation technique. Finally, we show\nhow thermodynamic integration can be used to perform model selection for deep\nneural networks. Similar to the Laplace approximation, this approach assumes\nthat the posterior is dominated by a single mode. Crucially, however, no\nassumption is made about the shape of that mode and it is not required to\nprecisely compute and invert the Hessian.\n", "versions": [{"version": "v1", "created": "Mon, 8 Apr 2019 16:06:13 GMT"}], "update_date": "2019-04-09", "authors_parsed": [["Baldock", "Robert J. N.", ""], ["Marzari", "Nicola", ""]]}, {"id": "1904.04156", "submitter": "Saugat Bhattacharyya", "authors": "Monalisa Pal, Sanghamitra Bandyopadhyay and Saugat Bhattacharyya", "title": "A Many Objective Optimization Approach for Transfer Learning in EEG\n  Classification", "comments": "Pre-submission work", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.SP cs.HC cs.LG cs.NE", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  In Brain-Computer Interfacing (BCI), due to inter-subject non-stationarities\nof electroencephalogram (EEG), classifiers are trained and tested using EEG\nfrom the same subject. When physical disabilities bottleneck the natural\nmodality of performing a task, acquisition of ample training data is difficult\nwhich practically obstructs classifier training. Previous works have tackled\nthis problem by generalizing the feature space amongst multiple subjects\nincluding the test subject. This work aims at knowledge transfer to classify\nEEG of the target subject using a classifier trained with the EEG of another\nunit source subject. A many-objective optimization framework is proposed where\noptimal weights are obtained for projecting features in another dimension such\nthat single source-trained target EEG classification performance is maximized\nwith the modified features. To validate the approach, motor imagery tasks from\nthe BCI Competition III Dataset IVa are classified using power spectral density\nbased features and linear support vector machine. Several performance metrics,\nimprovement in accuracy, sensitivity to the dimension of the projected space,\nassess the efficacy of the proposed approach. Addressing single-source training\npromotes independent living of differently-abled individuals by reducing\nassistance from others. The proposed approach eliminates the requirement of EEG\nfrom multiple source subjects and is applicable to any existing feature\nextractors and classifiers. Source code is available at\nhttp://worksupplements.droppages.com/tlbci.html.\n", "versions": [{"version": "v1", "created": "Thu, 4 Apr 2019 13:28:24 GMT"}], "update_date": "2019-04-09", "authors_parsed": [["Pal", "Monalisa", ""], ["Bandyopadhyay", "Sanghamitra", ""], ["Bhattacharyya", "Saugat", ""]]}, {"id": "1904.04161", "submitter": "Jayaraman J. Thiagarajan", "authors": "Vivek Sivaraman Narayanaswamy, Sameeksha Katoch, Jayaraman J.\n  Thiagarajan, Huan Song and Andreas Spanias", "title": "Audio Source Separation via Multi-Scale Learning with Dilated Dense\n  U-Nets", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.SD eess.AS stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Modern audio source separation techniques rely on optimizing sequence model\narchitectures such as, 1D-CNNs, on mixture recordings to generalize well to\nunseen mixtures. Specifically, recent focus is on time-domain based\narchitectures such as Wave-U-Net which exploit temporal context by extracting\nmulti-scale features. However, the optimality of the feature extraction process\nin these architectures has not been well investigated. In this paper, we\nexamine and recommend critical architectural changes that forge an optimal\nmulti-scale feature extraction process. To this end, we replace regular $1-$D\nconvolutions with adaptive dilated convolutions that have innate capability of\ncapturing increased context by using large temporal receptive fields. We also\ninvestigate the impact of dense connections on the extraction process that\nencourage feature reuse and better gradient flow. The dense connections between\nthe downsampling and upsampling paths of a U-Net architecture capture\nmulti-resolution information leading to improved temporal modelling. We\nevaluate the proposed approaches on the MUSDB test dataset. In addition to\nproviding an improved performance over the state-of-the-art, we also provide\ninsights on the impact of different architectural choices on complex\ndata-driven solutions for source separation.\n", "versions": [{"version": "v1", "created": "Mon, 8 Apr 2019 16:13:16 GMT"}], "update_date": "2019-04-09", "authors_parsed": [["Narayanaswamy", "Vivek Sivaraman", ""], ["Katoch", "Sameeksha", ""], ["Thiagarajan", "Jayaraman J.", ""], ["Song", "Huan", ""], ["Spanias", "Andreas", ""]]}, {"id": "1904.04174", "submitter": "John Lawson", "authors": "Rod Burns, John Lawson, Duncan McBain and Daniel Soutar", "title": "Accelerated Neural Networks on OpenCL Devices Using SYCL-DNN", "comments": "4 pages, 3 figures. In International Workshop on OpenCL (IWOCL '19),\n  May 13-15, 2019, Boston", "journal-ref": null, "doi": "10.1145/3318170.3318183", "report-no": null, "categories": "cs.LG cs.DC cs.PF", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Over the past few years machine learning has seen a renewed explosion of\ninterest, following a number of studies showing the effectiveness of neural\nnetworks in a range of tasks which had previously been considered incredibly\nhard. Neural networks' effectiveness in the fields of image recognition and\nnatural language processing stems primarily from the vast amounts of data\navailable to companies and researchers, coupled with the huge amounts of\ncompute power available in modern accelerators such as GPUs, FPGAs and ASICs.\nThere are a number of approaches available to developers for utilizing GPGPU\ntechnologies such as SYCL, OpenCL and CUDA, however many applications require\nthe same low level mathematical routines. Libraries dedicated to accelerating\nthese common routines allow developers to easily make full use of the available\nhardware without requiring low level knowledge of the hardware themselves,\nhowever such libraries are often provided by hardware manufacturers for\nspecific hardware such as cuDNN for Nvidia hardware or MIOpen for AMD hardware.\n  SYCL-DNN is a new open-source library dedicated to providing accelerated\nroutines for neural network operations which are hardware and vendor agnostic.\nBuilt on top of the SYCL open standard and written entirely in standard C++,\nSYCL-DNN allows a user to easily accelerate neural network code for a wide\nrange of hardware using a modern C++ interface. The library is tested on AMD's\nOpenCL for GPU, Intel's OpenCL for CPU and GPU, ARM's OpenCL for Mali GPUs as\nwell as ComputeAorta's OpenCL for R-Car CV engine and host CPU. In this talk we\nwill present performance figures for SYCL-DNN on this range of hardware, and\ndiscuss how high performance was achieved on such a varied set of accelerators\nwith such different hardware features.\n", "versions": [{"version": "v1", "created": "Mon, 8 Apr 2019 16:29:40 GMT"}], "update_date": "2019-04-09", "authors_parsed": [["Burns", "Rod", ""], ["Lawson", "John", ""], ["McBain", "Duncan", ""], ["Soutar", "Daniel", ""]]}, {"id": "1904.04195", "submitter": "Hao Tan", "authors": "Hao Tan, Licheng Yu, Mohit Bansal", "title": "Learning to Navigate Unseen Environments: Back Translation with\n  Environmental Dropout", "comments": "NAACL 2019 (12 pages)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A grand goal in AI is to build a robot that can accurately navigate based on\nnatural language instructions, which requires the agent to perceive the scene,\nunderstand and ground language, and act in the real-world environment. One key\nchallenge here is to learn to navigate in new environments that are unseen\nduring training. Most of the existing approaches perform dramatically worse in\nunseen environments as compared to seen ones. In this paper, we present a\ngeneralizable navigational agent. Our agent is trained in two stages. The first\nstage is training via mixed imitation and reinforcement learning, combining the\nbenefits from both off-policy and on-policy optimization. The second stage is\nfine-tuning via newly-introduced 'unseen' triplets (environment, path,\ninstruction). To generate these unseen triplets, we propose a simple but\neffective 'environmental dropout' method to mimic unseen environments, which\novercomes the problem of limited seen environment variability. Next, we apply\nsemi-supervised learning (via back-translation) on these dropped-out\nenvironments to generate new paths and instructions. Empirically, we show that\nour agent is substantially better at generalizability when fine-tuned with\nthese triplets, outperforming the state-of-art approaches by a large margin on\nthe private unseen test set of the Room-to-Room task, and achieving the top\nrank on the leaderboard.\n", "versions": [{"version": "v1", "created": "Mon, 8 Apr 2019 17:14:52 GMT"}], "update_date": "2019-04-09", "authors_parsed": [["Tan", "Hao", ""], ["Yu", "Licheng", ""], ["Bansal", "Mohit", ""]]}, {"id": "1904.04204", "submitter": "Fahrettin Ay", "authors": "F. Ay, G. \\.Ince, M. E. Kama\\c{s}ak, K. Y. Ek\\c{s}i", "title": "Classification of pulsars with Dirichlet process Gaussian mixture model", "comments": "Accepted by MNRAS (14 January 2020). 11 pages, 4 figures, 7 tables", "journal-ref": null, "doi": "10.1093/mnras/staa154", "report-no": null, "categories": "astro-ph.HE cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Young isolated neutron stars (INS) most commonly manifest themselves as\nrotationally powered pulsars (RPPs) which involve conventional radio pulsars as\nwell as gamma-ray pulsars (GRPs) and rotating radio transients (RRATs). Some\nother young INS families manifest themselves as anomalous X-ray pulsars (AXPs)\nand soft gamma-ray repeaters (SGRs) which are commonly accepted as magnetars,\ni.e. magnetically powered neutron stars with decaying superstrong fields. Yet\nsome other young INS are identified as central compact objects (CCOs) and X-ray\ndim isolated neutron stars (XDINSs) which are cooling objects powered by their\nthermal energy. Older pulsars, as a result of a previous long episode of\naccretion from a companion, manifest themselves as millisecond pulsars and more\ncommonly appear in binary systems. We use Dirichlet process Gaussian mixture\nmodel (DPGMM), an unsupervised machine learning algorithm, for analyzing the\ndistribution of these pulsar families in the parameter space of period and\nperiod derivative. We compare the average values of the characteristic age,\nmagnetic dipole field strength, surface temperature and transverse velocity of\nall discovered clusters. We verify that DPGMM is robust and provides hints for\ninferring relations between different classes of pulsars. We discuss the\nimplications of our findings for the magneto-thermal spin evolution models and\nfallback discs.\n", "versions": [{"version": "v1", "created": "Mon, 8 Apr 2019 17:23:35 GMT"}, {"version": "v2", "created": "Wed, 15 Jan 2020 19:42:04 GMT"}], "update_date": "2020-01-22", "authors_parsed": [["Ay", "F.", ""], ["\u0130nce", "G.", ""], ["Kama\u015fak", "M. E.", ""], ["Ek\u015fi", "K. Y.", ""]]}, {"id": "1904.04206", "submitter": "Shervin Minaee", "authors": "Shervin Minaee, Elham Azimi, AmirAli Abdolrashidi", "title": "Deep-Sentiment: Sentiment Analysis Using Ensemble of CNN and Bi-LSTM\n  Models", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.IR cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  With the popularity of social networks, and e-commerce websites, sentiment\nanalysis has become a more active area of research in the past few years. On a\nhigh level, sentiment analysis tries to understand the public opinion about a\nspecific product or topic, or trends from reviews or tweets. Sentiment analysis\nplays an important role in better understanding customer/user opinion, and also\nextracting social/political trends. There has been a lot of previous works for\nsentiment analysis, some based on hand-engineering relevant textual features,\nand others based on different neural network architectures. In this work, we\npresent a model based on an ensemble of long-short-term-memory (LSTM), and\nconvolutional neural network (CNN), one to capture the temporal information of\nthe data, and the other one to extract the local structure thereof. Through\nexperimental results, we show that using this ensemble model we can outperform\nboth individual models. We are also able to achieve a very high accuracy rate\ncompared to the previous works.\n", "versions": [{"version": "v1", "created": "Mon, 8 Apr 2019 17:26:20 GMT"}], "update_date": "2019-04-14", "authors_parsed": [["Minaee", "Shervin", ""], ["Azimi", "Elham", ""], ["Abdolrashidi", "AmirAli", ""]]}, {"id": "1904.04221", "submitter": "Mohammad Esmaeilpour", "authors": "Mohammad Esmaeilpour, Patrick Cardinal, Alessandro Lameiras Koerich", "title": "Unsupervised Feature Learning for Environmental Sound Classification\n  Using Weighted Cycle-Consistent Generative Adversarial Network", "comments": "Paper Accepted for Publication in Elsevier Applied Soft Computing", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.SD eess.AS stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we propose a novel environmental sound classification approach\nincorporating unsupervised feature learning from codebook via spherical\n$K$-Means++ algorithm and a new architecture for high-level data augmentation.\nThe audio signal is transformed into a 2D representation using a discrete\nwavelet transform (DWT). The DWT spectrograms are then augmented by a novel\narchitecture for cycle-consistent generative adversarial network. This\nhigh-level augmentation bootstraps generated spectrograms in both intra and\ninter class manners by translating structural features from sample to sample. A\ncodebook is built by coding the DWT spectrograms with the speeded-up robust\nfeature detector (SURF) and the K-Means++ algorithm. The Random Forest is our\nfinal learning algorithm which learns the environmental sound classification\ntask from the clustered codewords in the codebook. Experimental results in four\nbenchmarking environmental sound datasets (ESC-10, ESC-50, UrbanSound8k, and\nDCASE-2017) have shown that the proposed classification approach outperforms\nthe state-of-the-art classifiers in the scope, including advanced and dense\nconvolutional neural networks such as AlexNet and GoogLeNet, improving the\nclassification rate between 3.51% and 14.34%, depending on the dataset.\n", "versions": [{"version": "v1", "created": "Mon, 8 Apr 2019 17:44:14 GMT"}, {"version": "v2", "created": "Mon, 25 Nov 2019 17:43:32 GMT"}], "update_date": "2019-11-26", "authors_parsed": [["Esmaeilpour", "Mohammad", ""], ["Cardinal", "Patrick", ""], ["Koerich", "Alessandro Lameiras", ""]]}, {"id": "1904.04238", "submitter": "Lu Bai", "authors": "Lu Bail, Lixin Cui, Yuhang Jiao, Luca Rossi, Edwin R. Hancock", "title": "Learning Backtrackless Aligned-Spatial Graph Convolutional Networks for\n  Graph Classification", "comments": "This is an extension work for journals based on the previous work of\n  arXiv:1904.04238v1", "journal-ref": "IEEE Transactions on Pattern Analysis and Machine Intelligence,\n  2020", "doi": "10.1109/TPAMI.2020.3011866", "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we develop a novel Backtrackless Aligned-Spatial Graph\nConvolutional Network (BASGCN) model to learn effective features for graph\nclassification. Our idea is to transform arbitrary-sized graphs into\nfixed-sized backtrackless aligned grid structures and define a new spatial\ngraph convolution operation associated with the grid structures. We show that\nthe proposed BASGCN model not only reduces the problems of information loss and\nimprecise information representation arising in existing spatially-based Graph\nConvolutional Network (GCN) models, but also bridges the theoretical gap\nbetween traditional Convolutional Neural Network (CNN) models and\nspatially-based GCN models. Furthermore, the proposed BASGCN model can both\nadaptively discriminate the importance between specified vertices during the\nconvolution process and reduce the notorious tottering problem of existing\nspatially-based GCNs related to the Weisfeiler-Lehman algorithm, explaining the\neffectiveness of the proposed model. Experiments on standard graph datasets\ndemonstrate the effectiveness of the proposed model.\n", "versions": [{"version": "v1", "created": "Sat, 6 Apr 2019 09:50:54 GMT"}, {"version": "v2", "created": "Sun, 17 Nov 2019 17:18:09 GMT"}], "update_date": "2020-09-08", "authors_parsed": [["Bail", "Lu", ""], ["Cui", "Lixin", ""], ["Jiao", "Yuhang", ""], ["Rossi", "Luca", ""], ["Hancock", "Edwin R.", ""]]}, {"id": "1904.04272", "submitter": "Martin Engilberge", "authors": "Martin Engilberge, Louis Chevallier, Patrick P\\'erez, Matthieu Cord", "title": "SoDeep: a Sorting Deep net to learn ranking loss surrogates", "comments": "Accepted to CVPR 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV cs.IR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Several tasks in machine learning are evaluated using non-differentiable\nmetrics such as mean average precision or Spearman correlation. However, their\nnon-differentiability prevents from using them as objective functions in a\nlearning framework. Surrogate and relaxation methods exist but tend to be\nspecific to a given metric.\n  In the present work, we introduce a new method to learn approximations of\nsuch non-differentiable objective functions. Our approach is based on a deep\narchitecture that approximates the sorting of arbitrary sets of scores. It is\ntrained virtually for free using synthetic data. This sorting deep (SoDeep) net\ncan then be combined in a plug-and-play manner with existing deep\narchitectures. We demonstrate the interest of our approach in three different\ntasks that require ranking: Cross-modal text-image retrieval, multi-label image\nclassification and visual memorability ranking. Our approach yields very\ncompetitive results on these three tasks, which validates the merit and the\nflexibility of SoDeep as a proxy for sorting operation in ranking-based losses.\n", "versions": [{"version": "v1", "created": "Mon, 8 Apr 2019 18:02:43 GMT"}], "update_date": "2019-04-10", "authors_parsed": [["Engilberge", "Martin", ""], ["Chevallier", "Louis", ""], ["P\u00e9rez", "Patrick", ""], ["Cord", "Matthieu", ""]]}, {"id": "1904.04276", "submitter": "Lin Liu L", "authors": "Lin Liu, Rajarshi Mukherjee, James M. Robins", "title": "On nearly assumption-free tests of nominal confidence interval coverage\n  for causal parameters estimated by machine learning", "comments": "Significant updates from the previous version. In press in\n  Statistical Science", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG math.ST stat.ME stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  For many causal effect parameters of interest, doubly robust machine learning\n(DRML) estimators $\\hat{\\psi}_{1}$ are the state-of-the-art, incorporating the\ngood prediction performance of machine learning; the decreased bias of doubly\nrobust estimators; and the analytic tractability and bias reduction of sample\nsplitting with cross fitting. Nonetheless, even in the absence of confounding\nby unmeasured factors, the nominal $(1 - \\alpha)$ Wald confidence interval\n$\\hat{\\psi}_{1} \\pm z_{\\alpha / 2} \\widehat{\\mathsf{se}} [\\hat{\\psi}_{1}]$ may\nstill undercover even in large samples, because the bias of $\\hat{\\psi}_{1}$\nmay be of the same or even larger order than its standard error of order\n$n^{-1/2}$.\n  In this paper, we introduce essentially assumption-free tests that (i) can\nfalsify the null hypothesis that the bias of $\\hat{\\psi}_{1}$ is of smaller\norder than its standard error, (ii) can provide an upper confidence bound on\nthe true coverage of the Wald interval, and (iii) are valid under the null\nunder no smoothness/sparsity assumptions on the nuisance parameters. The tests,\nwhich we refer to as \\underline{A}ssumption \\underline{F}ree\n\\underline{E}mpirical \\underline{C}overage \\underline{T}ests (AFECTs), are\nbased on a U-statistic that estimates part of the bias of $\\hat{\\psi}_{1}$.\n", "versions": [{"version": "v1", "created": "Mon, 8 Apr 2019 18:09:45 GMT"}, {"version": "v2", "created": "Sun, 12 Jul 2020 12:47:27 GMT"}], "update_date": "2020-07-14", "authors_parsed": [["Liu", "Lin", ""], ["Mukherjee", "Rajarshi", ""], ["Robins", "James M.", ""]]}, {"id": "1904.04281", "submitter": "Tolga Birdal", "authors": "Haowen Deng and Tolga Birdal and Slobodan Ilic", "title": "3D Local Features for Direct Pairwise Registration", "comments": "To appear in CVPR 2019. 16 pages, identical to the camera ready\n  submission", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.LG cs.RO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a novel, data driven approach for solving the problem of\nregistration of two point cloud scans. Our approach is direct in the sense that\na single pair of corresponding local patches already provides the necessary\ntransformation cue for the global registration. To achieve that, we first endow\nthe state of the art PPF-FoldNet auto-encoder (AE) with a pose-variant sibling,\nwhere the discrepancy between the two leads to pose-specific descriptors. Based\nupon this, we introduce RelativeNet, a relative pose estimation network to\nassign correspondence-specific orientations to the keypoints, eliminating any\nlocal reference frame computations. Finally, we devise a simple yet effective\nhypothesize-and-verify algorithm to quickly use the predictions and align two\npoint sets. Our extensive quantitative and qualitative experiments suggests\nthat our approach outperforms the state of the art in challenging real datasets\nof pairwise registration and that augmenting the keypoints with local pose\ninformation leads to better generalization and a dramatic speed-up.\n", "versions": [{"version": "v1", "created": "Mon, 8 Apr 2019 18:17:36 GMT"}], "update_date": "2019-04-10", "authors_parsed": [["Deng", "Haowen", ""], ["Birdal", "Tolga", ""], ["Ilic", "Slobodan", ""]]}, {"id": "1904.04309", "submitter": "Marcin Sendera", "authors": "Marcin Sendera", "title": "Data adaptation in HANDY economy-ideology model", "comments": "172 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The concept of mathematical modeling is widespread across almost all of the\nfields of contemporary science and engineering. Because of the existing\nnecessity of predictions the behavior of natural phenomena, the researchers\ndevelop more and more complex models. However, despite their ability to better\nforecasting, the problem of an appropriate fitting ground truth data to those,\nhigh-dimensional and nonlinear models seems to be inevitable. In order to deal\nwith this demanding problem the entire discipline of data assimilation has been\ndeveloped. Basing on the Human and Nature Dynamics (HANDY) model, we have\npresented a detailed and comprehensive comparison of Approximate Bayesian\nComputation (classic data assimilation method) and a novelty approach of\nSupermodeling. Furthermore, with the usage of Sensitivity Analysis, we have\nproposed the methodology to reduce the number of coupling coefficients between\nsubmodels and as a consequence to increase the speed of the Supermodel\nconverging. In addition, we have demonstrated that usage of Approximate\nBayesian Computation method with the knowledge about parameters' sensitivities\ncould result with satisfactory estimation of the initial parameters. However,\nwe have also presented the mentioned methodology as unable to achieve similar\npredictions to Approximate Bayesian Computation. Finally, we have proved that\nSupermodeling with synchronization via the most sensitive variable could effect\nwith the better forecasting for chaotic as well as more stable systems than the\nApproximate Bayesian Computation. What is more, we have proposed the adequate\nmethodologies.\n", "versions": [{"version": "v1", "created": "Mon, 8 Apr 2019 19:19:59 GMT"}], "update_date": "2019-04-10", "authors_parsed": [["Sendera", "Marcin", ""]]}, {"id": "1904.04317", "submitter": "Yan Luo", "authors": "Yan Luo, Yongkang Wong, Mohan Kankanhalli, and Qi Zhao", "title": "$\\mathcal{G}$-softmax: Improving Intra-class Compactness and Inter-class\n  Separability of Features", "comments": "15 pages, published in TNNLS", "journal-ref": "IEEE Transactions on Neural Networks and Learning Systems in 2019", "doi": "10.1109/TNNLS.2019.2909737", "report-no": null, "categories": "cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Intra-class compactness and inter-class separability are crucial indicators\nto measure the effectiveness of a model to produce discriminative features,\nwhere intra-class compactness indicates how close the features with the same\nlabel are to each other and inter-class separability indicates how far away the\nfeatures with different labels are. In this work, we investigate intra-class\ncompactness and inter-class separability of features learned by convolutional\nnetworks and propose a Gaussian-based softmax ($\\mathcal{G}$-softmax) function\nthat can effectively improve intra-class compactness and inter-class\nseparability. The proposed function is simple to implement and can easily\nreplace the softmax function. We evaluate the proposed $\\mathcal{G}$-softmax\nfunction on classification datasets (i.e., CIFAR-10, CIFAR-100, and Tiny\nImageNet) and on multi-label classification datasets (i.e., MS COCO and\nNUS-WIDE). The experimental results show that the proposed\n$\\mathcal{G}$-softmax function improves the state-of-the-art models across all\nevaluated datasets. In addition, analysis of the intra-class compactness and\ninter-class separability demonstrates the advantages of the proposed function\nover the softmax function, which is consistent with the performance\nimprovement. More importantly, we observe that high intra-class compactness and\ninter-class separability are linearly correlated to average precision on MS\nCOCO and NUS-WIDE. This implies that improvement of intra-class compactness and\ninter-class separability would lead to improvement of average precision.\n", "versions": [{"version": "v1", "created": "Mon, 8 Apr 2019 19:31:25 GMT"}, {"version": "v2", "created": "Mon, 15 Jul 2019 15:21:07 GMT"}], "update_date": "2019-07-16", "authors_parsed": [["Luo", "Yan", ""], ["Wong", "Yongkang", ""], ["Kankanhalli", "Mohan", ""], ["Zhao", "Qi", ""]]}, {"id": "1904.04326", "submitter": "Lei Wu", "authors": "Weinan E, Chao Ma, Lei Wu", "title": "A Comparative Analysis of the Optimization and Generalization Property\n  of Two-layer Neural Network and Random Feature Models Under Gradient Descent\n  Dynamics", "comments": "Published version", "journal-ref": "Science China Mathematics (2020)", "doi": "10.1007/s11425-019-1628-5", "report-no": null, "categories": "cs.LG math.OC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A fairly comprehensive analysis is presented for the gradient descent\ndynamics for training two-layer neural network models in the situation when the\nparameters in both layers are updated. General initialization schemes as well\nas general regimes for the network width and training data size are considered.\nIn the over-parametrized regime, it is shown that gradient descent dynamics can\nachieve zero training loss exponentially fast regardless of the quality of the\nlabels. In addition, it is proved that throughout the training process the\nfunctions represented by the neural network model are uniformly close to that\nof a kernel method. For general values of the network width and training data\nsize, sharp estimates of the generalization error is established for target\nfunctions in the appropriate reproducing kernel Hilbert space.\n", "versions": [{"version": "v1", "created": "Mon, 8 Apr 2019 19:43:09 GMT"}, {"version": "v2", "created": "Fri, 21 Feb 2020 04:48:07 GMT"}], "update_date": "2020-02-27", "authors_parsed": [["E", "Weinan", ""], ["Ma", "Chao", ""], ["Wu", "Lei", ""]]}, {"id": "1904.04329", "submitter": "Xiaowei Jia", "authors": "Xiaowei Jia, Ankush Khandelwal, Vipin Kumar", "title": "Automated Monitoring Cropland Using Remote Sensing Data: Challenges and\n  Opportunities for Machine Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper provides an overview of how recent advances in machine learning\nand the availability of data from earth observing satellites can dramatically\nimprove our ability to automatically map croplands over long period and over\nlarge regions. It discusses three applications in the domain of crop monitoring\nwhere ML approaches are beginning to show great promise. For each application,\nit highlights machine learning challenges, proposed approaches, and recent\nresults. The paper concludes with discussion of major challenges that need to\nbe addressed before ML approaches will reach their full potential for this\nproblem of great societal relevance.\n", "versions": [{"version": "v1", "created": "Mon, 8 Apr 2019 19:54:27 GMT"}], "update_date": "2019-04-10", "authors_parsed": [["Jia", "Xiaowei", ""], ["Khandelwal", "Ankush", ""], ["Kumar", "Vipin", ""]]}, {"id": "1904.04334", "submitter": "Shahbaz Rezaei", "authors": "Shahbaz Rezaei and Xin Liu", "title": "A Target-Agnostic Attack on Deep Models: Exploiting Security\n  Vulnerabilities of Transfer Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Due to insufficient training data and the high computational cost to train a\ndeep neural network from scratch, transfer learning has been extensively used\nin many deep-neural-network-based applications. A commonly used transfer\nlearning approach involves taking a part of a pre-trained model, adding a few\nlayers at the end, and re-training the new layers with a small dataset. This\napproach, while efficient and widely used, imposes a security vulnerability\nbecause the pre-trained model used in transfer learning is usually publicly\navailable, including to potential attackers. In this paper, we show that\nwithout any additional knowledge other than the pre-trained model, an attacker\ncan launch an effective and efficient brute force attack that can craft\ninstances of input to trigger each target class with high confidence. We assume\nthat the attacker has no access to any target-specific information, including\nsamples from target classes, re-trained model, and probabilities assigned by\nSoftmax to each class, and thus making the attack target-agnostic. These\nassumptions render all previous attack models inapplicable, to the best of our\nknowledge. To evaluate the proposed attack, we perform a set of experiments on\nface recognition and speech recognition tasks and show the effectiveness of the\nattack. Our work reveals a fundamental security weakness of the Softmax layer\nwhen used in transfer learning settings.\n", "versions": [{"version": "v1", "created": "Mon, 8 Apr 2019 20:03:28 GMT"}, {"version": "v2", "created": "Tue, 24 Sep 2019 02:18:10 GMT"}, {"version": "v3", "created": "Wed, 29 Jan 2020 06:51:13 GMT"}], "update_date": "2020-01-30", "authors_parsed": [["Rezaei", "Shahbaz", ""], ["Liu", "Xin", ""]]}, {"id": "1904.04339", "submitter": "Heda Song", "authors": "Heda Song, Mercedes Torres Torres, Ender \\\"Ozcan, Isaac Triguero", "title": "L2AE-D: Learning to Aggregate Embeddings for Few-shot Learning with\n  Meta-level Dropout", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Few-shot learning focuses on learning a new visual concept with very limited\nlabelled examples. A successful approach to tackle this problem is to compare\nthe similarity between examples in a learned metric space based on\nconvolutional neural networks. However, existing methods typically suffer from\nmeta-level overfitting due to the limited amount of training tasks and do not\nnormally consider the importance of the convolutional features of different\nexamples within the same channel. To address these limitations, we make the\nfollowing two contributions: (a) We propose a novel meta-learning approach for\naggregating useful convolutional features and suppressing noisy ones based on a\nchannel-wise attention mechanism to improve class representations. The proposed\nmodel does not require fine-tuning and can be trained in an end-to-end manner.\nThe main novelty lies in incorporating a shared weight generation module that\nlearns to assign different weights to the feature maps of different examples\nwithin the same channel. (b) We also introduce a simple meta-level dropout\ntechnique that reduces meta-level overfitting in several few-shot learning\napproaches. In our experiments, we find that this simple technique\nsignificantly improves the performance of the proposed method as well as\nvarious state-of-the-art meta-learning algorithms. Applying our method to\nfew-shot image recognition using Omniglot and miniImageNet datasets shows that\nit is capable of delivering a state-of-the-art classification performance.\n", "versions": [{"version": "v1", "created": "Mon, 8 Apr 2019 20:11:39 GMT"}], "update_date": "2019-04-10", "authors_parsed": [["Song", "Heda", ""], ["Torres", "Mercedes Torres", ""], ["\u00d6zcan", "Ender", ""], ["Triguero", "Isaac", ""]]}, {"id": "1904.04352", "submitter": "Pramit Saha", "authors": "Pramit Saha and Sidney Fels", "title": "Hierarchical Deep Feature Learning For Decoding Imagined Speech From EEG", "comments": "Accepted in AAAI 2019 under Student Abstract and Poster Program", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG eess.IV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a mixed deep neural network strategy, incorporating parallel\ncombination of Convolutional (CNN) and Recurrent Neural Networks (RNN),\ncascaded with deep autoencoders and fully connected layers towards automatic\nidentification of imagined speech from EEG. Instead of utilizing raw EEG\nchannel data, we compute the joint variability of the channels in the form of a\ncovariance matrix that provide spatio-temporal representations of EEG. The\nnetworks are trained hierarchically and the extracted features are passed onto\nthe next network hierarchy until the final classification. Using a publicly\navailable EEG based speech imagery database we demonstrate around 23.45%\nimprovement of accuracy over the baseline method. Our approach demonstrates the\npromise of a mixed DNN approach for complex spatial-temporal classification\nproblems.\n", "versions": [{"version": "v1", "created": "Mon, 8 Apr 2019 20:56:15 GMT"}], "update_date": "2019-04-10", "authors_parsed": [["Saha", "Pramit", ""], ["Fels", "Sidney", ""]]}, {"id": "1904.04354", "submitter": "Neslisah Torosdagli", "authors": "Neslisah Torosdagli, Mary McIntosh, Denise K. Liberton, Payal Verma,\n  Murat Sincan, Wade W. Han, Janice S. Lee, and Ulas Bagci", "title": "Relational Reasoning Network (RRN) for Anatomical Landmarking", "comments": "10 pages, 6 Figures, 3 Tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Accurately identifying anatomical landmarks is a crucial step in deformation\nanalysis and surgical planning for craniomaxillofacial (CMF) bones. Available\nmethods require segmentation of the object of interest for precise landmarking.\nUnlike those, our purpose in this study is to perform anatomical landmarking\nusing the inherent relation of CMF bones without explicitly segmenting them. We\npropose a new deep network architecture, called relational reasoning network\n(RRN), to accurately learn the local and the global relations of the landmarks.\nSpecifically, we are interested in learning landmarks in CMF region: mandible,\nmaxilla, and nasal bones. The proposed RRN works in an end-to-end manner,\nutilizing learned relations of the landmarks based on dense-block units and\nwithout the need for segmentation. For a given a few landmarks as input, the\nproposed system accurately and efficiently localizes the remaining landmarks on\nthe aforementioned bones. For a comprehensive evaluation of RRN, we used\ncone-beam computed tomography (CBCT) scans of 250 patients. The proposed system\nidentifies the landmark locations very accurately even when there are severe\npathologies or deformations in the bones. The proposed RRN has also revealed\nunique relationships among the landmarks that help us infer several reasoning\nabout informativeness of the landmark points. RRN is invariant to order of\nlandmarks and it allowed us to discover the optimal configurations (number and\nlocation) for landmarks to be localized within the object of interest\n(mandible) or nearby objects (maxilla and nasal). To the best of our knowledge,\nthis is the first of its kind algorithm finding anatomical relations of the\nobjects using deep learning.\n", "versions": [{"version": "v1", "created": "Mon, 8 Apr 2019 20:58:47 GMT"}], "update_date": "2019-04-10", "authors_parsed": [["Torosdagli", "Neslisah", ""], ["McIntosh", "Mary", ""], ["Liberton", "Denise K.", ""], ["Verma", "Payal", ""], ["Sincan", "Murat", ""], ["Han", "Wade W.", ""], ["Lee", "Janice S.", ""], ["Bagci", "Ulas", ""]]}, {"id": "1904.04358", "submitter": "Pramit Saha", "authors": "Pramit Saha, Muhammad Abdul-Mageed and Sidney Fels", "title": "Deep Learning the EEG Manifold for Phonological Categorization from\n  Active Thoughts", "comments": "Accepted for publication in IEEE ICASSP 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CL cs.SD eess.AS stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Speech-related Brain Computer Interfaces (BCI) aim primarily at finding an\nalternative vocal communication pathway for people with speaking disabilities.\nAs a step towards full decoding of imagined speech from active thoughts, we\npresent a BCI system for subject-independent classification of phonological\ncategories exploiting a novel deep learning based hierarchical feature\nextraction scheme. To better capture the complex representation of\nhigh-dimensional electroencephalography (EEG) data, we compute the joint\nvariability of EEG electrodes into a channel cross-covariance matrix. We then\nextract the spatio-temporal information encoded within the matrix using a mixed\ndeep neural network strategy. Our model framework is composed of a\nconvolutional neural network (CNN), a long-short term network (LSTM), and a\ndeep autoencoder. We train the individual networks hierarchically, feeding\ntheir combined outputs in a final gradient boosting classification step. Our\nbest models achieve an average accuracy of 77.9% across five different binary\nclassification tasks, providing a significant 22.5% improvement over previous\nmethods. As we also show visually, our work demonstrates that the speech\nimagery EEG possesses significant discriminative information about the intended\narticulatory movements responsible for natural speech synthesis.\n", "versions": [{"version": "v1", "created": "Mon, 8 Apr 2019 21:11:40 GMT"}], "update_date": "2019-04-10", "authors_parsed": [["Saha", "Pramit", ""], ["Abdul-Mageed", "Muhammad", ""], ["Fels", "Sidney", ""]]}, {"id": "1904.04360", "submitter": "Andras Hajdu Dr.", "authors": "Attila Tiba, Andras Hajdu, Gyorgy Terdik, Henrietta Toman", "title": "Optimizing Majority Voting Based Systems Under a Resource Constraint for\n  Multiclass Problems", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Ensemble-based approaches are very effective in various fields in raising the\naccuracy of its individual members, when some voting rule is applied for\naggregating the individual decisions. In this paper, we investigate how to find\nand characterize the ensembles having the highest accuracy if the total cost of\nthe ensemble members is bounded. This question leads to Knapsack problem with\nnon-linear and non-separable objective function in binary and multiclass\nclassification if the majority voting is chosen for the aggregation. As the\nconventional solving methods cannot be applied for this task, a novel\nstochastic approach was introduced in the binary case where the energy function\nis discussed as the joint probability function of the member accuracy. We show\nsome theoretical results with respect to the expected ensemble accuracy and its\nvariance in the multiclass classification problem which can help us to solve\nthe Knapsack problem.\n", "versions": [{"version": "v1", "created": "Mon, 8 Apr 2019 21:16:47 GMT"}], "update_date": "2019-04-10", "authors_parsed": [["Tiba", "Attila", ""], ["Hajdu", "Andras", ""], ["Terdik", "Gyorgy", ""], ["Toman", "Henrietta", ""]]}, {"id": "1904.04364", "submitter": "Hiromitsu Nishizaki", "authors": "Masaki Okawa, Takuya Saito, Naoki Sawada, Hiromitsu Nishizaki", "title": "Audio Classification of Bit-Representation Waveform", "comments": "Accepted at INTERSPEECH2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.AS cs.CL cs.LG cs.SD", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This study investigated the waveform representation for audio signal\nclassification. Recently, many studies on audio waveform classification such as\nacoustic event detection and music genre classification have been published.\nMost studies on audio waveform classification have proposed the use of a deep\nlearning (neural network) framework. Generally, a frequency analysis method\nsuch as Fourier transform is applied to extract the frequency or spectral\ninformation from the input audio waveform before inputting the raw audio\nwaveform into the neural network. In contrast to these previous studies, in\nthis paper, we propose a novel waveform representation method, in which audio\nwaveforms are represented as a bit sequence, for audio classification. In our\nexperiment, we compare the proposed bit representation waveform, which is\ndirectly given to a neural network, to other representations of audio waveforms\nsuch as a raw audio waveform and a power spectrum with two classification\ntasks: one is an acoustic event classification task and the other is a\nsound/music classification task. The experimental results showed that the bit\nrepresentation waveform achieved the best classification performance for both\nthe tasks.\n", "versions": [{"version": "v1", "created": "Mon, 8 Apr 2019 21:24:31 GMT"}, {"version": "v2", "created": "Wed, 18 Sep 2019 14:22:59 GMT"}], "update_date": "2019-09-19", "authors_parsed": [["Okawa", "Masaki", ""], ["Saito", "Takuya", ""], ["Sawada", "Naoki", ""], ["Nishizaki", "Hiromitsu", ""]]}, {"id": "1904.04365", "submitter": "Jared Fernandez", "authors": "Michael Chen, Mike D'Arcy, Alisa Liu, Jared Fernandez, Doug Downey", "title": "CODAH: An Adversarially Authored Question-Answer Dataset for Common\n  Sense", "comments": "8 pages, Appeared in RepEval 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Commonsense reasoning is a critical AI capability, but it is difficult to\nconstruct challenging datasets that test common sense. Recent neural question\nanswering systems, based on large pre-trained models of language, have already\nachieved near-human-level performance on commonsense knowledge benchmarks.\nThese systems do not possess human-level common sense, but are able to exploit\nlimitations of the datasets to achieve human-level scores.\n  We introduce the CODAH dataset, an adversarially-constructed evaluation\ndataset for testing common sense. CODAH forms a challenging extension to the\nrecently-proposed SWAG dataset, which tests commonsense knowledge using\nsentence-completion questions that describe situations observed in video. To\nproduce a more difficult dataset, we introduce a novel procedure for question\nacquisition in which workers author questions designed to target weaknesses of\nstate-of-the-art neural question answering systems. Workers are rewarded for\nsubmissions that models fail to answer correctly both before and after\nfine-tuning (in cross-validation). We create 2.8k questions via this procedure\nand evaluate the performance of multiple state-of-the-art question answering\nsystems on our dataset. We observe a significant gap between human performance,\nwhich is 95.3%, and the performance of the best baseline accuracy of 67.5% by\nthe BERT-Large model.\n", "versions": [{"version": "v1", "created": "Mon, 8 Apr 2019 21:25:50 GMT"}, {"version": "v2", "created": "Fri, 12 Apr 2019 23:26:27 GMT"}, {"version": "v3", "created": "Thu, 6 Jun 2019 19:27:18 GMT"}, {"version": "v4", "created": "Fri, 26 Jul 2019 06:16:45 GMT"}], "update_date": "2019-07-29", "authors_parsed": [["Chen", "Michael", ""], ["D'Arcy", "Mike", ""], ["Liu", "Alisa", ""], ["Fernandez", "Jared", ""], ["Downey", "Doug", ""]]}, {"id": "1904.04370", "submitter": "Abby Stylianou", "authors": "Hong Xuan, Abby Stylianou and Robert Pless", "title": "Improved Embeddings with Easy Positive Triplet Mining", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep metric learning seeks to define an embedding where semantically similar\nimages are embedded to nearby locations, and semantically dissimilar images are\nembedded to distant locations. Substantial work has focused on loss functions\nand strategies to learn these embeddings by pushing images from the same class\nas close together in the embedding space as possible. In this paper, we propose\nan alternative, loosened embedding strategy that requires the embedding\nfunction only map each training image to the most similar examples from the\nsame class, an approach we call \"Easy Positive\" mining. We provide a collection\nof experiments and visualizations that highlight that this Easy Positive mining\nleads to embeddings that are more flexible and generalize better to new unseen\ndata. This simple mining strategy yields recall performance that exceeds state\nof the art approaches (including those with complicated loss functions and\nensemble methods) on image retrieval datasets including CUB, Stanford Online\nProducts, In-Shop Clothes and Hotels-50K.\n", "versions": [{"version": "v1", "created": "Mon, 8 Apr 2019 21:41:28 GMT"}, {"version": "v2", "created": "Wed, 18 Mar 2020 18:58:28 GMT"}], "update_date": "2020-03-20", "authors_parsed": [["Xuan", "Hong", ""], ["Stylianou", "Abby", ""], ["Pless", "Robert", ""]]}, {"id": "1904.04381", "submitter": "Jiaxuan You", "authors": "Jiaxuan You, Yichen Wang, Aditya Pal, Pong Eksombatchai, Chuck\n  Rosenberg, Jure Leskovec", "title": "Hierarchical Temporal Convolutional Networks for Dynamic Recommender\n  Systems", "comments": "Accepted by the Web Conference 2019 (WWW 2019) as a full paper", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SI cs.IR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recommender systems that can learn from cross-session data to dynamically\npredict the next item a user will choose are crucial for online platforms.\nHowever, existing approaches often use out-of-the-box sequence models which are\nlimited by speed and memory consumption, are often infeasible for production\nenvironments, and usually do not incorporate cross-session information, which\nis crucial for effective recommendations. Here we propose Hierarchical Temporal\nConvolutional Networks (HierTCN), a hierarchical deep learning architecture\nthat makes dynamic recommendations based on users' sequential multi-session\ninteractions with items. HierTCN is designed for web-scale systems with\nbillions of items and hundreds of millions of users. It consists of two levels\nof models: The high-level model uses Recurrent Neural Networks (RNN) to\naggregate users' evolving long-term interests across different sessions, while\nthe low-level model is implemented with Temporal Convolutional Networks (TCN),\nutilizing both the long-term interests and the short-term interactions within\nsessions to predict the next interaction. We conduct extensive experiments on a\npublic XING dataset and a large-scale Pinterest dataset that contains 6 million\nusers with 1.6 billion interactions. We show that HierTCN is 2.5x faster than\nRNN-based models and uses 90% less data memory compared to TCN-based models. We\nfurther develop an effective data caching scheme and a queue-based mini-batch\ngenerator, enabling our model to be trained within 24 hours on a single GPU.\nOur model consistently outperforms state-of-the-art dynamic recommendation\nmethods, with up to 18% improvement in recall and 10% in mean reciprocal rank.\n", "versions": [{"version": "v1", "created": "Mon, 8 Apr 2019 22:15:44 GMT"}, {"version": "v2", "created": "Wed, 10 Apr 2019 17:15:17 GMT"}], "update_date": "2019-04-14", "authors_parsed": [["You", "Jiaxuan", ""], ["Wang", "Yichen", ""], ["Pal", "Aditya", ""], ["Eksombatchai", "Pong", ""], ["Rosenberg", "Chuck", ""], ["Leskovec", "Jure", ""]]}, {"id": "1904.04399", "submitter": "Forrest Huang", "authors": "Forrest Huang and John F. Canny", "title": "Sketchforme: Composing Sketched Scenes from Text Descriptions for\n  Interactive Applications", "comments": "10 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.HC cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Sketching and natural languages are effective communication media for\ninteractive applications. We introduce Sketchforme, the first\nneural-network-based system that can generate sketches based on text\ndescriptions specified by users. Sketchforme is capable of gaining high-level\nand low-level understanding of multi-object sketched scenes without being\ntrained on sketched scene datasets annotated with text descriptions. The\nsketches composed by Sketchforme are expressive and realistic: we show in our\nuser study that these sketches convey descriptions better than human-generated\nsketches in multiple cases, and 36.5% of those sketches are considered to be\nhuman-generated. We develop multiple interactive applications using these\ngenerated sketches, and show that Sketchforme can significantly improve\nlanguage learning applications and support intelligent language-based sketching\nassistants.\n", "versions": [{"version": "v1", "created": "Mon, 8 Apr 2019 23:56:34 GMT"}], "update_date": "2019-04-10", "authors_parsed": [["Huang", "Forrest", ""], ["Canny", "John F.", ""]]}, {"id": "1904.04403", "submitter": "Nikolaj Tatti", "authors": "Nikolaj Tatti", "title": "Discovering Bands from Graphs", "comments": null, "journal-ref": null, "doi": "10.1007/s10618-014-0359-9", "report-no": null, "categories": "cs.DS cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Discovering the underlying structure of a given graph is one of the\nfundamental goals in graph mining. Given a graph, we can often order vertices\nin a way that neighboring vertices have a higher probability of being connected\nto each other. This implies that the edges form a band around the diagonal in\nthe adjacency matrix. Such structure may rise for example if the graph was\ncreated over time: each vertex had an active time interval during which the\nvertex was connected with other active vertices.\n  The goal of this paper is to model this phenomenon. To this end, we formulate\nan optimization problem: given a graph and an integer $K$, we want to order\ngraph vertices and partition the ordered adjacency matrix into $K$ bands such\nthat bands closer to the diagonal are more dense. We measure the goodness of a\nsegmentation using the log-likelihood of a log-linear model, a flexible family\nof distributions containing many standard distributions. We divide the problem\ninto two subproblems: finding the order and finding the bands. We show that\ndiscovering bands can be done in polynomial time with isotonic regression, and\nwe also introduce a heuristic iterative approach. For discovering the order we\nuse Fiedler order accompanied with a simple combinatorial refinement. We\ndemonstrate empirically that our heuristic works well in practice.\n", "versions": [{"version": "v1", "created": "Tue, 9 Apr 2019 00:11:27 GMT"}], "update_date": "2019-04-10", "authors_parsed": [["Tatti", "Nikolaj", ""]]}, {"id": "1904.04404", "submitter": "Jianwei Yang", "authors": "Jianwei Yang, Zhile Ren, Mingze Xu, Xinlei Chen, David Crandall, Devi\n  Parikh, Dhruv Batra", "title": "Embodied Visual Recognition", "comments": "14 pages, 13 figures, technical report", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.LG cs.RO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Passive visual systems typically fail to recognize objects in the amodal\nsetting where they are heavily occluded. In contrast, humans and other embodied\nagents have the ability to move in the environment, and actively control the\nviewing angle to better understand object shapes and semantics. In this work,\nwe introduce the task of Embodied Visual Recognition (EVR): An agent is\ninstantiated in a 3D environment close to an occluded target object, and is\nfree to move in the environment to perform object classification, amodal object\nlocalization, and amodal object segmentation. To address this, we develop a new\nmodel called Embodied Mask R-CNN, for agents to learn to move strategically to\nimprove their visual recognition abilities. We conduct experiments using the\nHouse3D environment. Experimental results show that: 1) agents with embodiment\n(movement) achieve better visual recognition performance than passive ones; 2)\nin order to improve visual recognition abilities, agents can learn strategical\nmoving paths that are different from shortest paths.\n", "versions": [{"version": "v1", "created": "Tue, 9 Apr 2019 00:33:17 GMT"}], "update_date": "2019-04-10", "authors_parsed": [["Yang", "Jianwei", ""], ["Ren", "Zhile", ""], ["Xu", "Mingze", ""], ["Chen", "Xinlei", ""], ["Crandall", "David", ""], ["Parikh", "Devi", ""], ["Batra", "Dhruv", ""]]}, {"id": "1904.04419", "submitter": "Tingfung Lau", "authors": "Tingfung Lau, Nathan Ng, Julian Gingold, Nina Desai, Julian McAuley,\n  Zachary C. Lipton", "title": "Embryo staging with weakly-supervised region selection and\n  dynamically-decoded predictions", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  To optimize clinical outcomes, fertility clinics must strategically select\nwhich embryos to transfer. Common selection heuristics are formulas expressed\nin terms of the durations required to reach various developmental milestones,\nquantities historically annotated manually by experienced embryologists based\non time-lapse EmbryoScope videos. We propose a new method for automatic embryo\nstaging that exploits several sources of structure in this time-lapse data.\nFirst, noting that in each image the embryo occupies a small subregion, we\njointly train a region proposal network with the downstream classifier to\nisolate the embryo. Notably, because we lack ground-truth bounding boxes, our\nwe weakly supervise the region proposal network optimizing its parameters via\nreinforcement learning to improve the downstream classifier's loss. Moreover,\nnoting that embryos reaching the blastocyst stage progress monotonically\nthrough earlier stages, we develop a dynamic-programming-based decoder that\npost-processes our predictions to select the most likely monotonic sequence of\ndevelopmental stages. Our methods outperform vanilla residual networks and\nrival the best numbers in contemporary papers, as measured by both per-frame\naccuracy and transition prediction error, despite operating on smaller data\nthan many.\n", "versions": [{"version": "v1", "created": "Tue, 9 Apr 2019 02:03:08 GMT"}], "update_date": "2019-04-10", "authors_parsed": [["Lau", "Tingfung", ""], ["Ng", "Nathan", ""], ["Gingold", "Julian", ""], ["Desai", "Nina", ""], ["McAuley", "Julian", ""], ["Lipton", "Zachary C.", ""]]}, {"id": "1904.04430", "submitter": "Xiaoyu Chen", "authors": "Xiaoyu Chen, Shugong Xu, Xudong Chen, Shan Cao, Shunqing Zhang, Yanzan\n  Sun", "title": "Passive TCP Identification for Wired and WirelessNetworks: A Long-Short\n  Term Memory Approach", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Transmission control protocol (TCP) congestion control is one of the key\ntechniques to improve network performance. TCP congestion control algorithm\nidentification (TCP identification) can be used to significantly improve\nnetwork efficiency. Existing TCP identification methods can only be applied to\nlimited number of TCP congestion control algorithms and focus on wired\nnetworks. In this paper, we proposed a machine learning based passive TCP\nidentification method for wired and wireless networks. After comparing among\nthree typical machine learning models, we concluded that the 4-layers Long\nShort Term Memory (LSTM) model achieves the best identification accuracy. Our\napproach achieves better than 98% accuracy in wired and wireless networks and\nworks for newly proposed TCP congestion control algorithms.\n", "versions": [{"version": "v1", "created": "Tue, 9 Apr 2019 02:35:31 GMT"}], "update_date": "2019-04-10", "authors_parsed": [["Chen", "Xiaoyu", ""], ["Xu", "Shugong", ""], ["Chen", "Xudong", ""], ["Cao", "Shan", ""], ["Zhang", "Shunqing", ""], ["Sun", "Yanzan", ""]]}, {"id": "1904.04432", "submitter": "Yang Li", "authors": "Yang Li, Shihao Ji", "title": "$L_0$-ARM: Network Sparsification via Stochastic Binary Optimization", "comments": "Published as a conference paper at ECML 2019", "journal-ref": null, "doi": "10.1007/978-3-030-46147-8_26", "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider network sparsification as an $L_0$-norm regularized binary\noptimization problem, where each unit of a neural network (e.g., weight,\nneuron, or channel, etc.) is attached with a stochastic binary gate, whose\nparameters are jointly optimized with original network parameters. The\nAugment-Reinforce-Merge (ARM), a recently proposed unbiased gradient estimator,\nis investigated for this binary optimization problem. Compared to the hard\nconcrete gradient estimator from Louizos et al., ARM demonstrates superior\nperformance of pruning network architectures while retaining almost the same\naccuracies of baseline methods. Similar to the hard concrete estimator, ARM\nalso enables conditional computation during model training but with improved\neffectiveness due to the exact binary stochasticity. Thanks to the flexibility\nof ARM, many smooth or non-smooth parametric functions, such as scaled sigmoid\nor hard sigmoid, can be used to parameterize this binary optimization problem\nand the unbiasness of the ARM estimator is retained, while the hard concrete\nestimator has to rely on the hard sigmoid function to achieve conditional\ncomputation and thus accelerated training. Extensive experiments on multiple\npublic datasets demonstrate state-of-the-art pruning rates with almost the same\naccuracies of baseline methods. The resulting algorithm $L_0$-ARM sparsifies\nthe Wide-ResNet models on CIFAR-10 and CIFAR-100 while the hard concrete\nestimator cannot. The code is public available at\nhttps://github.com/leo-yangli/l0-arm.\n", "versions": [{"version": "v1", "created": "Tue, 9 Apr 2019 02:43:31 GMT"}, {"version": "v2", "created": "Sat, 7 Sep 2019 18:08:27 GMT"}, {"version": "v3", "created": "Wed, 11 Sep 2019 13:38:21 GMT"}], "update_date": "2021-07-02", "authors_parsed": [["Li", "Yang", ""], ["Ji", "Shihao", ""]]}, {"id": "1904.04433", "submitter": "Yinpeng Dong", "authors": "Yinpeng Dong, Hang Su, Baoyuan Wu, Zhifeng Li, Wei Liu, Tong Zhang,\n  Jun Zhu", "title": "Efficient Decision-based Black-box Adversarial Attacks on Face\n  Recognition", "comments": "CVPR 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.CR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Face recognition has obtained remarkable progress in recent years due to the\ngreat improvement of deep convolutional neural networks (CNNs). However, deep\nCNNs are vulnerable to adversarial examples, which can cause fateful\nconsequences in real-world face recognition applications with\nsecurity-sensitive purposes. Adversarial attacks are widely studied as they can\nidentify the vulnerability of the models before they are deployed. In this\npaper, we evaluate the robustness of state-of-the-art face recognition models\nin the decision-based black-box attack setting, where the attackers have no\naccess to the model parameters and gradients, but can only acquire hard-label\npredictions by sending queries to the target model. This attack setting is more\npractical in real-world face recognition systems. To improve the efficiency of\nprevious methods, we propose an evolutionary attack algorithm, which can model\nthe local geometries of the search directions and reduce the dimension of the\nsearch space. Extensive experiments demonstrate the effectiveness of the\nproposed method that induces a minimum perturbation to an input face image with\nfewer queries. We also apply the proposed method to attack a real-world face\nrecognition system successfully.\n", "versions": [{"version": "v1", "created": "Tue, 9 Apr 2019 02:45:35 GMT"}], "update_date": "2019-04-10", "authors_parsed": [["Dong", "Yinpeng", ""], ["Su", "Hang", ""], ["Wu", "Baoyuan", ""], ["Li", "Zhifeng", ""], ["Liu", "Wei", ""], ["Zhang", "Tong", ""], ["Zhu", "Jun", ""]]}, {"id": "1904.04447", "submitter": "Bin Liu", "authors": "Bin Liu, Ruiming Tang, Yingzhi Chen, Jinkai Yu, Huifeng Guo, Yuzhou\n  Zhang", "title": "Feature Generation by Convolutional Neural Network for Click-Through\n  Rate Prediction", "comments": null, "journal-ref": "TheWebConf 2019", "doi": "10.1145/3308558.3313497", "report-no": null, "categories": "cs.IR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Click-Through Rate prediction is an important task in recommender systems,\nwhich aims to estimate the probability of a user to click on a given item.\nRecently, many deep models have been proposed to learn low-order and high-order\nfeature interactions from original features. However, since useful interactions\nare always sparse, it is difficult for DNN to learn them effectively under a\nlarge number of parameters. In real scenarios, artificial features are able to\nimprove the performance of deep models (such as Wide & Deep Learning), but\nfeature engineering is expensive and requires domain knowledge, making it\nimpractical in different scenarios. Therefore, it is necessary to augment\nfeature space automatically. In this paper, We propose a novel Feature\nGeneration by Convolutional Neural Network (FGCNN) model with two components:\nFeature Generation and Deep Classifier. Feature Generation leverages the\nstrength of CNN to generate local patterns and recombine them to generate new\nfeatures. Deep Classifier adopts the structure of IPNN to learn interactions\nfrom the augmented feature space. Experimental results on three large-scale\ndatasets show that FGCNN significantly outperforms nine state-of-the-art\nmodels. Moreover, when applying some state-of-the-art models as Deep\nClassifier, better performance is always achieved, showing the great\ncompatibility of our FGCNN model. This work explores a novel direction for CTR\npredictions: it is quite useful to reduce the learning difficulties of DNN by\nautomatically identifying important features.\n", "versions": [{"version": "v1", "created": "Tue, 9 Apr 2019 03:27:06 GMT"}], "update_date": "2019-04-30", "authors_parsed": [["Liu", "Bin", ""], ["Tang", "Ruiming", ""], ["Chen", "Yingzhi", ""], ["Yu", "Jinkai", ""], ["Guo", "Huifeng", ""], ["Zhang", "Yuzhou", ""]]}, {"id": "1904.04458", "submitter": "Angli Liu", "authors": "Angli Liu, Jingfei Du, Veselin Stoyanov", "title": "Knowledge-Augmented Language Model and its Application to Unsupervised\n  Named-Entity Recognition", "comments": "NAACL 2019; updated to cite Zhou et al. (2018) EMNLP as a piece of\n  related work", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Traditional language models are unable to efficiently model entity names\nobserved in text. All but the most popular named entities appear infrequently\nin text providing insufficient context. Recent efforts have recognized that\ncontext can be generalized between entity names that share the same type (e.g.,\n\\emph{person} or \\emph{location}) and have equipped language models with access\nto an external knowledge base (KB). Our Knowledge-Augmented Language Model\n(KALM) continues this line of work by augmenting a traditional model with a KB.\nUnlike previous methods, however, we train with an end-to-end predictive\nobjective optimizing the perplexity of text. We do not require any additional\ninformation such as named entity tags. In addition to improving language\nmodeling performance, KALM learns to recognize named entities in an entirely\nunsupervised way by using entity type information latent in the model. On a\nNamed Entity Recognition (NER) task, KALM achieves performance comparable with\nstate-of-the-art supervised models. Our work demonstrates that named entities\n(and possibly other types of world knowledge) can be modeled successfully using\npredictive learning and training on large corpora of text without any\nadditional information.\n", "versions": [{"version": "v1", "created": "Tue, 9 Apr 2019 04:09:45 GMT"}, {"version": "v2", "created": "Mon, 24 Jun 2019 07:48:21 GMT"}], "update_date": "2019-06-25", "authors_parsed": [["Liu", "Angli", ""], ["Du", "Jingfei", ""], ["Stoyanov", "Veselin", ""]]}, {"id": "1904.04460", "submitter": "Zeyuan Wang", "authors": "Zeyuan Wang, Josiah Poon, Shiding Sun, Simon Poon", "title": "Attention-based Multi-instance Neural Network for Medical Diagnosis from\n  Incomplete and Low Quality Data", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  One way to extract patterns from clinical records is to consider each patient\nrecord as a bag with various number of instances in the form of symptoms.\nMedical diagnosis is to discover informative ones first and then map them to\none or more diseases. In many cases, patients are represented as vectors in\nsome feature space and a classifier is applied after to generate diagnosis\nresults. However, in many real-world cases, data is often of low-quality due to\na variety of reasons, such as data consistency, integrity, completeness,\naccuracy, etc. In this paper, we propose a novel approach, attention based\nmulti-instance neural network (AMI-Net), to make the single disease\nclassification only based on the existing and valid information in the\nreal-world outpatient records. In the context of a patient, it takes a bag of\ninstances as input and output the bag label directly in end-to-end way.\nEmbedding layer is adopted at the beginning, mapping instances into an\nembedding space which represents the individual patient condition. The\ncorrelations among instances and their importance for the final classification\nare captured by multi-head attention transformer, instance-level multi-instance\npooling and bag-level multi-instance pooling. The proposed approach was test on\ntwo non-standardized and highly imbalanced datasets, one in the Traditional\nChinese Medicine (TCM) domain and the other in the Western Medicine (WM)\ndomain. Our preliminary results show that the proposed approach outperforms all\nbaselines results by a significant margin.\n", "versions": [{"version": "v1", "created": "Tue, 9 Apr 2019 04:21:52 GMT"}], "update_date": "2019-04-10", "authors_parsed": [["Wang", "Zeyuan", ""], ["Poon", "Josiah", ""], ["Sun", "Shiding", ""], ["Poon", "Simon", ""]]}, {"id": "1904.04478", "submitter": "Raghav Singhal", "authors": "Raghav Singhal, Xintian Han, Saad Lahlou, Rajesh Ranganath", "title": "Kernelized Complete Conditional Stein Discrepancy", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Much of machine learning relies on comparing distributions with discrepancy\nmeasures. Stein's method creates discrepancy measures between two distributions\nthat require only the unnormalized density of one and samples from the other.\nStein discrepancies can be combined with kernels to define kernelized Stein\ndiscrepancies (KSDs). While kernels make Stein discrepancies tractable, they\npose several challenges in high dimensions. We introduce kernelized complete\nconditional Stein discrepancies (KCC-SDs). Complete conditionals turn a\nmultivariate distribution into multiple univariate distributions. We show that\nKCC-SDs distinguish distributions. To show the efficacy of KCC-SDs in\ndistinguishing distributions, we introduce a goodness-of-fit test using\nKCC-SDs. We empirically show that KCC-SDs have higher power over baselines and\nuse KCC-SDs to assess sample quality in Markov chain Monte Carlo.\n", "versions": [{"version": "v1", "created": "Tue, 9 Apr 2019 06:06:23 GMT"}, {"version": "v2", "created": "Sat, 13 Apr 2019 07:09:09 GMT"}, {"version": "v3", "created": "Tue, 21 Jan 2020 03:21:14 GMT"}, {"version": "v4", "created": "Sat, 18 Jul 2020 03:06:14 GMT"}], "update_date": "2020-07-21", "authors_parsed": [["Singhal", "Raghav", ""], ["Han", "Xintian", ""], ["Lahlou", "Saad", ""], ["Ranganath", "Rajesh", ""]]}, {"id": "1904.04480", "submitter": "Lihua Lei", "authors": "Lihua Lei and Michael I. Jordan", "title": "On the Adaptivity of Stochastic Gradient-Based Optimization", "comments": "Accepted by SIAM Journal on Optimization; 54 pages", "journal-ref": null, "doi": "10.1137/19M1256919", "report-no": null, "categories": "math.OC cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Stochastic-gradient-based optimization has been a core enabling methodology\nin applications to large-scale problems in machine learning and related areas.\nDespite the progress, the gap between theory and practice remains significant,\nwith theoreticians pursuing mathematical optimality at a cost of obtaining\nspecialized procedures in different regimes (e.g., modulus of strong convexity,\nmagnitude of target accuracy, signal-to-noise ratio), and with practitioners\nnot readily able to know which regime is appropriate to their problem, and\nseeking broadly applicable algorithms that are reasonably close to optimality.\nTo bridge these perspectives it is necessary to study algorithms that are\nadaptive to different regimes. We present the stochastically controlled\nstochastic gradient (SCSG) method for composite convex finite-sum optimization\nproblems and show that SCSG is adaptive to both strong convexity and target\naccuracy. The adaptivity is achieved by batch variance reduction with adaptive\nbatch sizes and a novel technique, which we referred to as geometrization,\nwhich sets the length of each epoch as a geometric random variable. The\nalgorithm achieves strictly better theoretical complexity than other existing\nadaptive algorithms, while the tuning parameters of the algorithm only depend\non the smoothness parameter of the objective.\n", "versions": [{"version": "v1", "created": "Tue, 9 Apr 2019 06:07:55 GMT"}, {"version": "v2", "created": "Thu, 16 May 2019 03:57:08 GMT"}, {"version": "v3", "created": "Thu, 31 Dec 2020 18:57:20 GMT"}], "update_date": "2021-01-01", "authors_parsed": [["Lei", "Lihua", ""], ["Jordan", "Michael I.", ""]]}, {"id": "1904.04516", "submitter": "Matthias Rottmann", "authors": "Matthias Rottmann and Marius Schubert", "title": "Uncertainty Measures and Prediction Quality Rating for the Semantic\n  Segmentation of Nested Multi Resolution Street Scene Images", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In the semantic segmentation of street scenes the reliability of the\nprediction and therefore uncertainty measures are of highest interest. We\npresent a method that generates for each input image a hierarchy of nested\ncrops around the image center and presents these, all re-scaled to the same\nsize, to a neural network for semantic segmentation. The resulting softmax\noutputs are then post processed such that we can investigate mean and variance\nover all image crops as well as mean and variance of uncertainty heat maps\nobtained from pixel-wise uncertainty measures, like the entropy, applied to\neach crop's softmax output. In our tests, we use the publicly available\nDeepLabv3+ MobilenetV2 network (trained on the Cityscapes dataset) and\ndemonstrate that the incorporation of crops improves the quality of the\nprediction and that we obtain more reliable uncertainty measures. These are\nthen aggregated over predicted segments for either classifying between IoU=0\nand IoU>0 (meta classification) or predicting the IoU via linear regression\n(meta regression). The latter yields reliable performance estimates for\nsegmentation networks, in particular useful in the absence of ground truth. For\nthe task of meta classification we obtain a classification accuracy of\n$81.93\\%$ and an AUROC of $89.89\\%$. For meta regression we obtain an $R^2$\nvalue of $84.77\\%$. These results yield significant improvements compared to\nother approaches.\n", "versions": [{"version": "v1", "created": "Tue, 9 Apr 2019 08:14:09 GMT"}], "update_date": "2019-04-10", "authors_parsed": [["Rottmann", "Matthias", ""], ["Schubert", "Marius", ""]]}, {"id": "1904.04520", "submitter": "Mara Graziani Miss", "authors": "Mara Graziani, Vincent Andrearczyk and Henning M\\\"uller", "title": "Regression Concept Vectors for Bidirectional Explanations in\n  Histopathology", "comments": "9 pages, 3 figures, 3 tables", "journal-ref": "Understanding and Interpreting Machine Learning in Medical Image\n  Computing Applications: First International Workshops, Proceedings. Vol.\n  11038. Springer, 2018", "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Explanations for deep neural network predictions in terms of domain-related\nconcepts can be valuable in medical applications, where justifications are\nimportant for confidence in the decision-making. In this work, we propose a\nmethodology to exploit continuous concept measures as Regression Concept\nVectors (RCVs) in the activation space of a layer. The directional derivative\nof the decision function along the RCVs represents the network sensitivity to\nincreasing values of a given concept measure. When applied to breast cancer\ngrading, nuclei texture emerges as a relevant concept in the detection of tumor\ntissue in breast lymph node samples. We evaluate score robustness and\nconsistency by statistical analysis.\n", "versions": [{"version": "v1", "created": "Tue, 9 Apr 2019 08:26:02 GMT"}], "update_date": "2019-04-10", "authors_parsed": [["Graziani", "Mara", ""], ["Andrearczyk", "Vincent", ""], ["M\u00fcller", "Henning", ""]]}, {"id": "1904.04562", "submitter": "Eunwoo Kim", "authors": "Eunwoo Kim, Chanho Ahn, Philip H.S. Torr, Songhwai Oh", "title": "Deep Virtual Networks for Memory Efficient Inference of Multiple Tasks", "comments": "CVPR 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep networks consume a large amount of memory by their nature. A natural\nquestion arises can we reduce that memory requirement whilst maintaining\nperformance. In particular, in this work we address the problem of memory\nefficient learning for multiple tasks. To this end, we propose a novel network\narchitecture producing multiple networks of different configurations, termed\ndeep virtual networks (DVNs), for different tasks. Each DVN is specialized for\na single task and structured hierarchically. The hierarchical structure, which\ncontains multiple levels of hierarchy corresponding to different numbers of\nparameters, enables multiple inference for different memory budgets. The\nbuilding block of a deep virtual network is based on a disjoint collection of\nparameters of a network, which we call a unit. The lowest level of hierarchy in\na deep virtual network is a unit, and higher levels of hierarchy contain lower\nlevels' units and other additional units. Given a budget on the number of\nparameters, a different level of a deep virtual network can be chosen to\nperform the task. A unit can be shared by different DVNs, allowing multiple\nDVNs in a single network. In addition, shared units provide assistance to the\ntarget task with additional knowledge learned from another tasks. This\ncooperative configuration of DVNs makes it possible to handle different tasks\nin a memory-aware manner. Our experiments show that the proposed method\noutperforms existing approaches for multiple tasks. Notably, ours is more\nefficient than others as it allows memory-aware inference for all tasks.\n", "versions": [{"version": "v1", "created": "Tue, 9 Apr 2019 09:34:07 GMT"}], "update_date": "2019-04-10", "authors_parsed": [["Kim", "Eunwoo", ""], ["Ahn", "Chanho", ""], ["Torr", "Philip H. S.", ""], ["Oh", "Songhwai", ""]]}, {"id": "1904.04564", "submitter": "Art\\\"ur Manukyan", "authors": "Art\\\"ur Manukyan and Elvan Ceyhan", "title": "Classification of Imbalanced Data with a Geometric Digraph Family", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We use a geometric digraph family called class cover catch digraphs (CCCDs)\nto tackle the class imbalance problem in statistical classification. CCCDs\nprovide graph theoretic solutions to the class cover problem and have been\nemployed in classification. We assess the classification performance of CCCD\nclassifiers by extensive Monte Carlo simulations, comparing them with other\nclassifiers commonly used in the literature. In particular, we show that CCCD\nclassifiers perform relatively well when one class is more frequent than the\nother in a two-class setting, an example of the class imbalance problem. We\nalso point out the relationship between class imbalance and class overlapping\nproblems, and their influence on the performance of CCCD classifiers and other\nclassification methods as well as some state-of-the-art algorithms which are\nrobust to class imbalance by construction. Experiments on both simulated and\nreal data sets indicate that CCCD classifiers are robust to the class imbalance\nproblem. CCCDs substantially undersample from the majority class while\npreserving the information on the discarded points during the undersampling\nprocess. Many state-of-the-art methods, however, keep this information by means\nof ensemble classifiers, but CCCDs yield only a single classifier with the same\nproperty, making it both appealing and fast.\n", "versions": [{"version": "v1", "created": "Tue, 9 Apr 2019 09:45:24 GMT"}], "update_date": "2019-04-10", "authors_parsed": [["Manukyan", "Art\u00fcr", ""], ["Ceyhan", "Elvan", ""]]}, {"id": "1904.04573", "submitter": "Guillaume Staerman", "authors": "Guillaume Staerman, Pavlo Mozharovskyi, Stephan Cl\\'emen\\c{c}on,\n  Florence d'Alch\\'e-Buc", "title": "Functional Isolation Forest", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  For the purpose of monitoring the behavior of complex infrastructures (e.g.\naircrafts, transport or energy networks), high-rate sensors are deployed to\ncapture multivariate data, generally unlabeled, in quasi continuous-time to\ndetect quickly the occurrence of anomalies that may jeopardize the smooth\noperation of the system of interest. The statistical analysis of such massive\ndata of functional nature raises many challenging methodological questions. The\nprimary goal of this paper is to extend the popular Isolation Forest (IF)\napproach to Anomaly Detection, originally dedicated to finite dimensional\nobservations, to functional data. The major difficulty lies in the wide variety\nof topological structures that may equip a space of functions and the great\nvariety of patterns that may characterize abnormal curves. We address the issue\nof (randomly) splitting the functional space in a flexible manner in order to\nisolate progressively any trajectory from the others, a key ingredient to the\nefficiency of the algorithm. Beyond a detailed description of the algorithm,\ncomputational complexity and stability issues are investigated at length. From\nthe scoring function measuring the degree of abnormality of an observation\nprovided by the proposed variant of the IF algorithm, a Functional Statistical\nDepth function is defined and discussed as well as a multivariate functional\nextension. Numerical experiments provide strong empirical evidence of the\naccuracy of the extension proposed.\n", "versions": [{"version": "v1", "created": "Tue, 9 Apr 2019 10:04:18 GMT"}, {"version": "v2", "created": "Thu, 18 Jul 2019 07:30:09 GMT"}, {"version": "v3", "created": "Wed, 9 Oct 2019 16:06:43 GMT"}], "update_date": "2019-10-10", "authors_parsed": [["Staerman", "Guillaume", ""], ["Mozharovskyi", "Pavlo", ""], ["Cl\u00e9men\u00e7on", "Stephan", ""], ["d'Alch\u00e9-Buc", "Florence", ""]]}, {"id": "1904.04612", "submitter": "Mike Papadakis", "authors": "Salah Ghamizi, Maxime Cordy, Mike Papadakis, Yves Le Traon", "title": "Automated Search for Configurations of Deep Neural Network Architectures", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep Neural Networks (DNNs) are intensively used to solve a wide variety of\ncomplex problems. Although powerful, such systems require manual configuration\nand tuning. To this end, we view DNNs as configurable systems and propose an\nend-to-end framework that allows the configuration, evaluation and automated\nsearch for DNN architectures. Therefore, our contribution is threefold. First,\nwe model the variability of DNN architectures with a Feature Model (FM) that\ngeneralizes over existing architectures. Each valid configuration of the FM\ncorresponds to a valid DNN model that can be built and trained. Second, we\nimplement, on top of Tensorflow, an automated procedure to deploy, train and\nevaluate the performance of a configured model. Third, we propose a method to\nsearch for configurations and demonstrate that it leads to good DNN models. We\nevaluate our method by applying it on image classification tasks (MNIST,\nCIFAR-10) and show that, with limited amount of computation and training, our\nmethod can identify high-performing architectures (with high accuracy). We also\ndemonstrate that we outperform existing state-of-the-art architectures\nhandcrafted by ML researchers. Our FM and framework have been released %and are\npublicly available to support replication and future research.\n", "versions": [{"version": "v1", "created": "Tue, 9 Apr 2019 11:56:28 GMT"}], "update_date": "2019-04-10", "authors_parsed": [["Ghamizi", "Salah", ""], ["Cordy", "Maxime", ""], ["Papadakis", "Mike", ""], ["Traon", "Yves Le", ""]]}, {"id": "1904.04621", "submitter": "Abdullah Hamdi", "authors": "Abdullah Hamdi, Bernard Ghanem", "title": "Towards Analyzing Semantic Robustness of Deep Neural Networks", "comments": "Presented at European conference on computer vision (ECCV 2020)\n  Workshop on Adversarial Robustness in the Real World (\n  https://eccv20-adv-workshop.github.io/ ) [best paper award]. The code is\n  available at https://github.com/ajhamdi/semantic-robustness", "journal-ref": "ECCV 2020 Workshops", "doi": "10.1007/978-3-030-66415-2_2", "report-no": "10", "categories": "cs.CV cs.CR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Despite the impressive performance of Deep Neural Networks (DNNs) on various\nvision tasks, they still exhibit erroneous high sensitivity toward semantic\nprimitives (e.g. object pose). We propose a theoretically grounded analysis for\nDNN robustness in the semantic space. We qualitatively analyze different DNNs'\nsemantic robustness by visualizing the DNN global behavior as semantic maps and\nobserve interesting behavior of some DNNs. Since generating these semantic maps\ndoes not scale well with the dimensionality of the semantic space, we develop a\nbottom-up approach to detect robust regions of DNNs. To achieve this, we\nformalize the problem of finding robust semantic regions of the network as\noptimizing integral bounds and we develop expressions for update directions of\nthe region bounds. We use our developed formulations to quantitatively evaluate\nthe semantic robustness of different popular network architectures. We show\nthrough extensive experimentation that several networks, while trained on the\nsame dataset and enjoying comparable accuracy, do not necessarily perform\nsimilarly in semantic robustness. For example, InceptionV3 is more accurate\ndespite being less semantically robust than ResNet50. We hope that this tool\nwill serve as a milestone towards understanding the semantic robustness of\nDNNs.\n", "versions": [{"version": "v1", "created": "Tue, 9 Apr 2019 12:26:55 GMT"}, {"version": "v2", "created": "Sun, 22 Sep 2019 18:59:10 GMT"}, {"version": "v3", "created": "Sun, 16 Aug 2020 20:06:36 GMT"}, {"version": "v4", "created": "Tue, 8 Sep 2020 15:53:55 GMT"}], "update_date": "2021-01-19", "authors_parsed": [["Hamdi", "Abdullah", ""], ["Ghanem", "Bernard", ""]]}, {"id": "1904.04631", "submitter": "Takuhiro Kaneko", "authors": "Takuhiro Kaneko, Hirokazu Kameoka, Kou Tanaka, Nobukatsu Hojo", "title": "CycleGAN-VC2: Improved CycleGAN-based Non-parallel Voice Conversion", "comments": "Accepted to ICASSP 2019. Project page:\n  http://www.kecl.ntt.co.jp/people/kaneko.takuhiro/projects/cyclegan-vc2/index.html", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SD cs.LG eess.AS stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Non-parallel voice conversion (VC) is a technique for learning the mapping\nfrom source to target speech without relying on parallel data. This is an\nimportant task, but it has been challenging due to the disadvantages of the\ntraining conditions. Recently, CycleGAN-VC has provided a breakthrough and\nperformed comparably to a parallel VC method without relying on any extra data,\nmodules, or time alignment procedures. However, there is still a large gap\nbetween the real target and converted speech, and bridging this gap remains a\nchallenge. To reduce this gap, we propose CycleGAN-VC2, which is an improved\nversion of CycleGAN-VC incorporating three new techniques: an improved\nobjective (two-step adversarial losses), improved generator (2-1-2D CNN), and\nimproved discriminator (PatchGAN). We evaluated our method on a non-parallel VC\ntask and analyzed the effect of each technique in detail. An objective\nevaluation showed that these techniques help bring the converted feature\nsequence closer to the target in terms of both global and local structures,\nwhich we assess by using Mel-cepstral distortion and modulation spectra\ndistance, respectively. A subjective evaluation showed that CycleGAN-VC2\noutperforms CycleGAN-VC in terms of naturalness and similarity for every\nspeaker pair, including intra-gender and inter-gender pairs.\n", "versions": [{"version": "v1", "created": "Tue, 9 Apr 2019 12:55:35 GMT"}], "update_date": "2019-04-10", "authors_parsed": [["Kaneko", "Takuhiro", ""], ["Kameoka", "Hirokazu", ""], ["Tanaka", "Kou", ""], ["Hojo", "Nobukatsu", ""]]}, {"id": "1904.04645", "submitter": "Thiago Jose Marques Moura", "authors": "Thiago J. M. Moura, George D. C. Cavalcanti, and Luiz S. Oliveira", "title": "Evaluating Competence Measures for Dynamic Regressor Selection", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Dynamic regressor selection (DRS) systems work by selecting the most\ncompetent regressors from an ensemble to estimate the target value of a given\ntest pattern. This competence is usually quantified using the performance of\nthe regressors in local regions of the feature space around the test pattern.\nHowever, choosing the best measure to calculate the level of competence\ncorrectly is not straightforward. The literature of dynamic classifier\nselection presents a wide variety of competence measures, which cannot be used\nor adapted for DRS. In this paper, we review eight measures used with\nregression problems, and adapt them to test the performance of the DRS\nalgorithms found in the literature. Such measures are extracted from a local\nregion of the feature space around the test pattern, called region of\ncompetence, therefore competence measures.To better compare the competence\nmeasures, we perform a set of comprehensive experiments of 15 regression\ndatasets. Three DRS systems were compared against individual regressor and\nstatic systems that use the Mean and the Median to combine the outputs of the\nregressors from the ensemble. The DRS systems were assessed varying the\ncompetence measures. Our results show that DRS systems outperform individual\nregressors and static systems but the choice of the competence measure is\nproblem-dependent.\n", "versions": [{"version": "v1", "created": "Tue, 9 Apr 2019 13:18:12 GMT"}], "update_date": "2019-08-27", "authors_parsed": [["Moura", "Thiago J. M.", ""], ["Cavalcanti", "George D. C.", ""], ["Oliveira", "Luiz S.", ""]]}, {"id": "1904.04668", "submitter": "Reza Moradinezhad", "authors": "J. Ghasemi, R. Moradinezhad, M. A. Hosseini", "title": "Kinematic Synthesis of Parallel Manipulator via Neural Network Approach", "comments": null, "journal-ref": "IJE TRANSACTIONS C: Aspects Vol. 30, No. 9 (September 2017)\n  1319-1325", "doi": null, "report-no": null, "categories": "cs.RO cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this research, Artificial Neural Networks (ANNs) have been used as a\npowerful tool to solve the inverse kinematic equations of a parallel robot. For\nthis purpose, we have developed the kinematic equations of a Tricept parallel\nkinematic mechanism with two rotational and one translational degrees of\nfreedom (DoF). Using the analytical method, the inverse kinematic equations are\nsolved for specific trajectory, and used as inputs for the applied ANNs. The\nresults of both applied networks (Multi-Layer Perceptron and Redial Basis\nFunction) satisfied the required performance in solving complex inverse\nkinematics with proper accuracy and speed.\n", "versions": [{"version": "v1", "created": "Mon, 8 Apr 2019 03:48:57 GMT"}], "update_date": "2019-04-10", "authors_parsed": [["Ghasemi", "J.", ""], ["Moradinezhad", "R.", ""], ["Hosseini", "M. A.", ""]]}, {"id": "1904.04671", "submitter": "Selim Arikan", "authors": "Selim Arikan, Kiran Varanasi, Didier Stricker", "title": "Surface Defect Classification in Real-Time Using Convolutional Neural\n  Networks", "comments": "Supplementary material will follow", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.IV cs.CV cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Surface inspection systems are an important application domain for computer\nvision, as they are used for defect detection and classification in the\nmanufacturing industry. Existing systems use hand-crafted features which\nrequire extensive domain knowledge to create. Even though Convolutional neural\nnetworks (CNNs) have proven successful in many large-scale challenges,\nindustrial inspection systems have yet barely realized their potential due to\ntwo significant challenges: real-time processing speed requirements and\nspecialized narrow domain-specific datasets which are sometimes limited in\nsize. In this paper, we propose CNN models that are specifically designed to\nhandle capacity and real-time speed requirements of surface inspection systems.\nTo train and evaluate our network models, we created a surface image dataset\ncontaining more than 22000 labeled images with many types of surface materials\nand achieved 98.0% accuracy in binary defect classification. To solve the class\nimbalance problem in our datasets, we introduce neural data augmentation\nmethods which are also applicable to similar domains that suffer from the same\nproblem. Our results show that deep learning based methods are feasible to be\nused in surface inspection systems and outperform traditional methods in\naccuracy and inference time by considerable margins.\n", "versions": [{"version": "v1", "created": "Sun, 7 Apr 2019 21:22:38 GMT"}], "update_date": "2019-04-10", "authors_parsed": [["Arikan", "Selim", ""], ["Varanasi", "Kiran", ""], ["Stricker", "Didier", ""]]}, {"id": "1904.04676", "submitter": "Nicola De Cao", "authors": "Nicola De Cao, Ivan Titov and Wilker Aziz", "title": "Block Neural Autoregressive Flow", "comments": "12 pages, 3 figures, 3 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Normalising flows (NFS) map two density functions via a differentiable\nbijection whose Jacobian determinant can be computed efficiently. Recently, as\nan alternative to hand-crafted bijections, Huang et al. (2018) proposed neural\nautoregressive flow (NAF) which is a universal approximator for density\nfunctions. Their flow is a neural network (NN) whose parameters are predicted\nby another NN. The latter grows quadratically with the size of the former and\nthus an efficient technique for parametrization is needed. We propose block\nneural autoregressive flow (B-NAF), a much more compact universal approximator\nof density functions, where we model a bijection directly using a single\nfeed-forward network. Invertibility is ensured by carefully designing each\naffine transformation with block matrices that make the flow autoregressive and\n(strictly) monotone. We compare B-NAF to NAF and other established flows on\ndensity estimation and approximate inference for latent variable models. Our\nproposed flow is competitive across datasets while using orders of magnitude\nfewer parameters.\n", "versions": [{"version": "v1", "created": "Tue, 9 Apr 2019 13:54:55 GMT"}], "update_date": "2019-04-10", "authors_parsed": [["De Cao", "Nicola", ""], ["Titov", "Ivan", ""], ["Aziz", "Wilker", ""]]}, {"id": "1904.04685", "submitter": "Elisa Riccietti", "authors": "Henri Calandra, Serge Gratton, Elisa Riccietti, Xavier Vasseur", "title": "On the approximation of the solution of partial differential equations\n  by artificial neural networks trained by a multilevel Levenberg-Marquardt\n  method", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.NA cs.LG math.OC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper is concerned with the approximation of the solution of partial\ndifferential equations by means of artificial neural networks. Here a\nfeedforward neural network is used to approximate the solution of the partial\ndifferential equation. The learning problem is formulated as a least squares\nproblem, choosing the residual of the partial differential equation as a loss\nfunction, whereas a multilevel Levenberg-Marquardt method is employed as a\ntraining method. This setting allows us to get further insight into the\npotential of multilevel methods. Indeed, when the least squares problem arises\nfrom the training of artificial neural networks, the variables subject to\noptimization are not related by any geometrical constraints and the standard\ninterpolation and restriction operators cannot be employed any longer. A\nheuristic, inspired by algebraic multigrid methods, is then proposed to\nconstruct the multilevel transfer operators. Numerical experiments show\nencouraging results related to the efficiency of the new multilevel\noptimization method for the training of artificial neural networks, compared to\nthe standard corresponding one-level procedure.\n", "versions": [{"version": "v1", "created": "Tue, 9 Apr 2019 14:10:26 GMT"}], "update_date": "2019-04-10", "authors_parsed": [["Calandra", "Henri", ""], ["Gratton", "Serge", ""], ["Riccietti", "Elisa", ""], ["Vasseur", "Xavier", ""]]}, {"id": "1904.04691", "submitter": "Muhammad Usman Ghani", "authors": "Muhammad Usman Ghani, W. Clem Karl", "title": "Fast Enhanced CT Metal Artifact Reduction using Data Domain Deep\n  Learning", "comments": "Accepted for publication in IEEE Transactions on Computational\n  Imaging", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Filtered back projection (FBP) is the most widely used method for image\nreconstruction in X-ray computed tomography (CT) scanners. The presence of\nhyper-dense materials in a scene, such as metals, can strongly attenuate\nX-rays, producing severe streaking artifacts in the reconstruction. These metal\nartifacts can greatly limit subsequent object delineation and information\nextraction from the images, restricting their diagnostic value. This problem is\nparticularly acute in the security domain, where there is great heterogeneity\nin the objects that can appear in a scene, highly accurate decisions must be\nmade quickly. The standard practical approaches to reducing metal artifacts in\nCT imagery are either simplistic non-adaptive interpolation-based projection\ndata completion methods or direct image post-processing methods. These standard\napproaches have had limited success. Motivated primarily by security\napplications, we present a new deep-learning-based metal artifact reduction\n(MAR) approach that tackles the problem in the projection data domain. We treat\nthe projection data corresponding to metal objects as missing data and train an\nadversarial deep network to complete the missing data in the projection domain.\nThe subsequent complete projection data is then used with FBP to reconstruct\nimage intended to be free of artifacts. This new approach results in an\nend-to-end MAR algorithm that is computationally efficient so practical and\nfits well into existing CT workflows allowing easy adoption in existing\nscanners. Training deep networks can be challenging, and another contribution\nof our work is to demonstrate that training data generated using an accurate\nX-ray simulation can be used to successfully train the deep network when\ncombined with transfer learning using limited real data sets. We demonstrate\nthe effectiveness and potential of our algorithm on simulated and real\nexamples.\n", "versions": [{"version": "v1", "created": "Tue, 9 Apr 2019 14:13:41 GMT"}, {"version": "v2", "created": "Wed, 10 Apr 2019 01:11:12 GMT"}, {"version": "v3", "created": "Thu, 1 Aug 2019 16:16:35 GMT"}], "update_date": "2019-08-02", "authors_parsed": [["Ghani", "Muhammad Usman", ""], ["Karl", "W. Clem", ""]]}, {"id": "1904.04700", "submitter": "Edouard Leurent", "authors": "Edouard Leurent and Odalric-Ambrym Maillard", "title": "Practical Open-Loop Optimistic Planning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the problem of online planning in a Markov Decision Process when\ngiven only access to a generative model, restricted to open-loop policies -\ni.e. sequences of actions - and under budget constraint. In this setting, the\nOpen-Loop Optimistic Planning (OLOP) algorithm enjoys good theoretical\nguarantees but is overly conservative in practice, as we show in numerical\nexperiments. We propose a modified version of the algorithm with tighter\nupper-confidence bounds, KLOLOP, that leads to better practical performances\nwhile retaining the sample complexity bound. Finally, we propose an efficient\nimplementation that significantly improves the time complexity of both\nalgorithms.\n", "versions": [{"version": "v1", "created": "Tue, 9 Apr 2019 14:29:53 GMT"}], "update_date": "2019-04-10", "authors_parsed": [["Leurent", "Edouard", ""], ["Maillard", "Odalric-Ambrym", ""]]}, {"id": "1904.04706", "submitter": "Chih-Hong Cheng", "authors": "Chih-Hong Cheng, Chung-Hao Huang, Thomas Brunner, Vahid Hashemi", "title": "Towards Safety Verification of Direct Perception Neural Networks", "comments": "Revised text (2nd version). The research work is conducted during the\n  first author's service at the fortiss research institute and is supported by\n  the following projects: \"Audi Verifiable AI\" from Audi AG, Germany and\n  \"Dependable AI for automotive systems\" from DENSO Corporation, Japan", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SE cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the problem of safety verification of direct perception neural\nnetworks, where camera images are used as inputs to produce high-level features\nfor autonomous vehicles to make control decisions. Formal verification of\ndirect perception neural networks is extremely challenging, as it is difficult\nto formulate the specification that requires characterizing input as\nconstraints, while the number of neurons in such a network can reach millions.\nWe approach the specification problem by learning an input property\ncharacterizer which carefully extends a direct perception neural network at\nclose-to-output layers, and address the scalability problem by a novel\nassume-guarantee based verification approach. The presented workflow is used to\nunderstand a direct perception neural network (developed by Audi) which\ncomputes the next waypoint and orientation for autonomous vehicles to follow.\n", "versions": [{"version": "v1", "created": "Tue, 9 Apr 2019 14:40:32 GMT"}, {"version": "v2", "created": "Thu, 21 Nov 2019 09:04:07 GMT"}], "update_date": "2019-11-22", "authors_parsed": [["Cheng", "Chih-Hong", ""], ["Huang", "Chung-Hao", ""], ["Brunner", "Thomas", ""], ["Hashemi", "Vahid", ""]]}, {"id": "1904.04717", "submitter": "Ahmet Iscen", "authors": "Ahmet Iscen and Giorgos Tolias and Yannis Avrithis and Ondrej Chum", "title": "Label Propagation for Deep Semi-supervised Learning", "comments": "Accepted to CVPR 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Semi-supervised learning is becoming increasingly important because it can\ncombine data carefully labeled by humans with abundant unlabeled data to train\ndeep neural networks. Classic methods on semi-supervised learning that have\nfocused on transductive learning have not been fully exploited in the inductive\nframework followed by modern deep learning. The same holds for the manifold\nassumption---that similar examples should get the same prediction. In this\nwork, we employ a transductive label propagation method that is based on the\nmanifold assumption to make predictions on the entire dataset and use these\npredictions to generate pseudo-labels for the unlabeled data and train a deep\nneural network. At the core of the transductive method lies a nearest neighbor\ngraph of the dataset that we create based on the embeddings of the same\nnetwork.Therefore our learning process iterates between these two steps. We\nimprove performance on several datasets especially in the few labels regime and\nshow that our work is complementary to current state of the art.\n", "versions": [{"version": "v1", "created": "Tue, 9 Apr 2019 14:55:48 GMT"}], "update_date": "2019-09-20", "authors_parsed": [["Iscen", "Ahmet", ""], ["Tolias", "Giorgos", ""], ["Avrithis", "Yannis", ""], ["Chum", "Ondrej", ""]]}, {"id": "1904.04732", "submitter": "Daniel Russo", "authors": "Daniel Russo", "title": "A Note on the Equivalence of Upper Confidence Bounds and Gittins Indices\n  for Patient Agents", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This note gives a short, self-contained, proof of a sharp connection between\nGittins indices and Bayesian upper confidence bound algorithms. I consider a\nGaussian multi-armed bandit problem with discount factor $\\gamma$. The Gittins\nindex of an arm is shown to equal the $\\gamma$-quantile of the posterior\ndistribution of the arm's mean plus an error term that vanishes as $\\gamma\\to\n1$. In this sense, for sufficiently patient agents, a Gittins index measures\nthe highest plausible mean-reward of an arm in a manner equivalent to an upper\nconfidence bound.\n", "versions": [{"version": "v1", "created": "Tue, 9 Apr 2019 15:30:52 GMT"}], "update_date": "2019-04-10", "authors_parsed": [["Russo", "Daniel", ""]]}, {"id": "1904.04733", "submitter": "Marco Dinarelli", "authors": "Marco Dinarelli, Lo\\\"ic Grobol", "title": "Seq2Biseq: Bidirectional Output-wise Recurrent Neural Networks for\n  Sequence Modelling", "comments": "Slightly improved version of the paper accepted to the CICling 2019\n  conference", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  During the last couple of years, Recurrent Neural Networks (RNN) have reached\nstate-of-the-art performances on most of the sequence modelling problems. In\nparticular, the \"sequence to sequence\" model and the neural CRF have proved to\nbe very effective in this domain. In this article, we propose a new RNN\narchitecture for sequence labelling, leveraging gated recurrent layers to take\narbitrarily long contexts into account, and using two decoders operating\nforward and backward. We compare several variants of the proposed solution and\ntheir performances to the state-of-the-art. Most of our results are better than\nthe state-of-the-art or very close to it and thanks to the use of recent\ntechnologies, our architecture can scale on corpora larger than those used in\nthis work.\n", "versions": [{"version": "v1", "created": "Tue, 9 Apr 2019 15:33:59 GMT"}, {"version": "v2", "created": "Thu, 11 Apr 2019 22:44:10 GMT"}, {"version": "v3", "created": "Tue, 16 Apr 2019 09:26:52 GMT"}], "update_date": "2019-04-17", "authors_parsed": [["Dinarelli", "Marco", ""], ["Grobol", "Lo\u00efc", ""]]}, {"id": "1904.04734", "submitter": "Maximilian Alber", "authors": "Maximilian Alber", "title": "Software and application patterns for explanation methods", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep neural networks successfully pervaded many applications domains and are\nincreasingly used in critical decision processes. Understanding their workings\nis desirable or even required to further foster their potential as well as to\naccess sensitive domains like medical applications or autonomous driving. One\nkey to this broader usage of explaining frameworks is the accessibility and\nunderstanding of respective software. In this work we introduce software and\napplication patterns for explanation techniques that aim to explain individual\npredictions of neural networks. We discuss how to code well-known algorithms\nefficiently within deep learning software frameworks and describe how to embed\nalgorithms in downstream implementations. Building on this we show how\nexplanation methods can be used in applications to understand predictions for\nmiss-classified samples, to compare algorithms or networks, and to examine the\nfocus of networks. Furthermore, we review available open-source packages and\ndiscuss challenges posed by complex and evolving neural network structures to\nexplanation algorithm development and implementations.\n", "versions": [{"version": "v1", "created": "Tue, 9 Apr 2019 15:34:40 GMT"}], "update_date": "2019-04-10", "authors_parsed": [["Alber", "Maximilian", ""]]}, {"id": "1904.04742", "submitter": "Ahmad Rashid", "authors": "Ahmad Rashid, Alan Do-Omri, Md. Akmal Haidar, Qun Liu and Mehdi\n  Rezagholizadeh", "title": "Bilingual-GAN: A Step Towards Parallel Text Generation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Latent space based GAN methods and attention based sequence to sequence\nmodels have achieved impressive results in text generation and unsupervised\nmachine translation respectively. Leveraging the two domains, we propose an\nadversarial latent space based model capable of generating parallel sentences\nin two languages concurrently and translating bidirectionally. The bilingual\ngeneration goal is achieved by sampling from the latent space that is shared\nbetween both languages. First two denoising autoencoders are trained, with\nshared encoders and back-translation to enforce a shared latent state between\nthe two languages. The decoder is shared for the two translation directions.\nNext, a GAN is trained to generate synthetic \"code\" mimicking the languages'\nshared latent space. This code is then fed into the decoder to generate text in\neither language. We perform our experiments on Europarl and Multi30k datasets,\non the English-French language pair, and document our performance using both\nsupervised and unsupervised machine translation.\n", "versions": [{"version": "v1", "created": "Tue, 9 Apr 2019 15:42:08 GMT"}, {"version": "v2", "created": "Tue, 14 May 2019 19:57:24 GMT"}], "update_date": "2019-05-16", "authors_parsed": [["Rashid", "Ahmad", ""], ["Do-Omri", "Alan", ""], ["Haidar", "Md. Akmal", ""], ["Liu", "Qun", ""], ["Rezagholizadeh", "Mehdi", ""]]}, {"id": "1904.04747", "submitter": "Rafael Rodrigues", "authors": "Rafael Rodrigues and Antonio M. G. Pinheiro", "title": "Segmentation of Skeletal Muscle in Thigh Dixon MRI Based on Texture\n  Analysis", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Segmentation of skeletal muscles in Magnetic Resonance Images (MRI) is\nessential for the study of muscle physiology and diagnosis of muscular\npathologies. However, manual segmentation of large MRI volumes is a\ntime-consuming task. The state-of-the-art on algorithms for muscle segmentation\nin MRI is still not very extensive and is somewhat database-dependent. In this\npaper, an automated segmentation method based on AdaBoost classification of\nlocal texture features is presented. The texture descriptor consists of the\nHistogram of Oriented Gradients (HOG), Wavelet-based features, and a set of\nstatistical measures computed from both the original and the Laplacian of\nGaussian filtering of the grayscale MRI. The classifier performance suggests\nthat texture analysis may be a helpful tool for designing a generalized and\nautomated MRI muscle segmentation framework. Furthermore, an atlas-based\napproach to individual muscle segmentation is also described in this paper. The\natlas is obtained by overlaying the muscle segmentation ground truth, provided\nby a radiologist, after image alignment using an appropriate affine\ntransformation. Then, it is used to define the muscle labels upon the AdaBoost\nbinary segmentation. The developed atlas method provides reasonable results\nwhen an accurate muscle tissue segmentation was obtained.\n", "versions": [{"version": "v1", "created": "Tue, 9 Apr 2019 15:56:06 GMT"}], "update_date": "2019-04-10", "authors_parsed": [["Rodrigues", "Rafael", ""], ["Pinheiro", "Antonio M. G.", ""]]}, {"id": "1904.04751", "submitter": "Aibek Alanov", "authors": "Aibek Alanov, Max Kochurov, Denis Volkhonskiy, Daniil Yashkov, Evgeny\n  Burnaev, Dmitry Vetrov", "title": "User-Controllable Multi-Texture Synthesis with Generative Adversarial\n  Networks", "comments": "8 pages paper, 17 pages supplementary material", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a novel multi-texture synthesis model based on generative\nadversarial networks (GANs) with a user-controllable mechanism. The user\ncontrol ability allows to explicitly specify the texture which should be\ngenerated by the model. This property follows from using an encoder part which\nlearns a latent representation for each texture from the dataset. To ensure a\ndataset coverage, we use an adversarial loss function that penalizes for\nincorrect reproductions of a given texture. In experiments, we show that our\nmodel can learn descriptive texture manifolds for large datasets and from raw\ndata such as a collection of high-resolution photos. Moreover, we apply our\nmethod to produce 3D textures and show that it outperforms existing baselines.\n", "versions": [{"version": "v1", "created": "Tue, 9 Apr 2019 15:59:16 GMT"}, {"version": "v2", "created": "Wed, 24 Apr 2019 12:07:22 GMT"}], "update_date": "2019-04-25", "authors_parsed": [["Alanov", "Aibek", ""], ["Kochurov", "Max", ""], ["Volkhonskiy", "Denis", ""], ["Yashkov", "Daniil", ""], ["Burnaev", "Evgeny", ""], ["Vetrov", "Dmitry", ""]]}, {"id": "1904.04754", "submitter": "Enrique Fernandez-Blanco", "authors": "Enrique Fernandez-Blanco, Daniel Rivero, Marcos Gestal, Carlos\n  Fernandez-Lozano, Norberto Ezquerra, Cristian R. Munteanu, Julian Dorado", "title": "A Hybrid Evolutionary System for Automated Artificial Neural Networks\n  Generation and Simplification in Biomedical Applications", "comments": "48 pages, 9 figures, 17 tables", "journal-ref": "Current Bioinformatics, Volume 10, Number 5, 2015, pp. 672-691(20)", "doi": "10.2174/1574893610666151008012923", "report-no": null, "categories": "cs.LG cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Data mining and data classification over biomedical data are two of the most\nimportant research fields in computer science. Among the great diversity of\ntechniques that can be used for this purpose, Artifical Neural Networks (ANNs)\nis one of the most suited. One of the main problems in the development of this\ntechnique is the slow performance of the full process. Traditionally, in this\ndevelopment process, human experts are needed to experiment with different\narchitectural procedures until they find the one that presents the correct\nresults for solving a specific problem. However, many studies have emerged in\nwhich different ANN developmental techniques, more or less automated, are\ndescribed. In this paper, the authors have focused on developing a new\ntechnique to perform this process over biomedical data. The new technique is\ndescribed in which two Evolutionary Computation (EC) techniques are mixed to\nautomatically develop ANNs. These techniques are Genetic Algorithms and Genetic\nProgramming. The work goes further, and the system described here allows to\nobtain simplified networks with a low number of neurons to resolve the\nproblems. The system is compared with the already existent system which also\nuses EC over a set of well-known problems. The conclusions reached from these\ncomparisons indicate that this new system produces very good results, which in\nthe worst case are at least comparable to existing techniques and in many cases\nare substantially better.\n", "versions": [{"version": "v1", "created": "Tue, 9 Apr 2019 16:07:48 GMT"}], "update_date": "2019-04-10", "authors_parsed": [["Fernandez-Blanco", "Enrique", ""], ["Rivero", "Daniel", ""], ["Gestal", "Marcos", ""], ["Fernandez-Lozano", "Carlos", ""], ["Ezquerra", "Norberto", ""], ["Munteanu", "Cristian R.", ""], ["Dorado", "Julian", ""]]}, {"id": "1904.04755", "submitter": "Satyen Kale", "authors": "Dylan J. Foster and Spencer Greenberg and Satyen Kale and Haipeng Luo\n  and Mehryar Mohri and Karthik Sridharan", "title": "Hypothesis Set Stability and Generalization", "comments": "Published in NeurIPS 2019. This version is equivalent to the\n  camera-ready version but also includes the supplementary material", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a study of generalization for data-dependent hypothesis sets. We\ngive a general learning guarantee for data-dependent hypothesis sets based on a\nnotion of transductive Rademacher complexity. Our main result is a\ngeneralization bound for data-dependent hypothesis sets expressed in terms of a\nnotion of hypothesis set stability and a notion of Rademacher complexity for\ndata-dependent hypothesis sets that we introduce. This bound admits as special\ncases both standard Rademacher complexity bounds and algorithm-dependent\nuniform stability bounds. We also illustrate the use of these learning bounds\nin the analysis of several scenarios.\n", "versions": [{"version": "v1", "created": "Tue, 9 Apr 2019 16:08:25 GMT"}, {"version": "v2", "created": "Wed, 17 Apr 2019 02:46:07 GMT"}, {"version": "v3", "created": "Mon, 5 Oct 2020 14:38:37 GMT"}], "update_date": "2020-10-06", "authors_parsed": [["Foster", "Dylan J.", ""], ["Greenberg", "Spencer", ""], ["Kale", "Satyen", ""], ["Luo", "Haipeng", ""], ["Mohri", "Mehryar", ""], ["Sridharan", "Karthik", ""]]}, {"id": "1904.04762", "submitter": "Bhairav Mehta", "authors": "Bhairav Mehta, Manfred Diaz, Florian Golemo, Christopher J. Pal, Liam\n  Paull", "title": "Active Domain Randomization", "comments": "Code available at\n  https://github.com/montrealrobotics/active-domainrand", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.RO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Domain randomization is a popular technique for improving domain transfer,\noften used in a zero-shot setting when the target domain is unknown or cannot\neasily be used for training. In this work, we empirically examine the effects\nof domain randomization on agent generalization. Our experiments show that\ndomain randomization may lead to suboptimal, high-variance policies, which we\nattribute to the uniform sampling of environment parameters. We propose Active\nDomain Randomization, a novel algorithm that learns a parameter sampling\nstrategy. Our method looks for the most informative environment variations\nwithin the given randomization ranges by leveraging the discrepancies of policy\nrollouts in randomized and reference environment instances. We find that\ntraining more frequently on these instances leads to better overall agent\ngeneralization. Our experiments across various physics-based simulated and\nreal-robot tasks show that this enhancement leads to more robust, consistent\npolicies.\n", "versions": [{"version": "v1", "created": "Tue, 9 Apr 2019 16:15:39 GMT"}, {"version": "v2", "created": "Wed, 10 Jul 2019 20:20:10 GMT"}], "update_date": "2019-07-12", "authors_parsed": [["Mehta", "Bhairav", ""], ["Diaz", "Manfred", ""], ["Golemo", "Florian", ""], ["Pal", "Christopher J.", ""], ["Paull", "Liam", ""]]}, {"id": "1904.04764", "submitter": "Haohan Guo", "authors": "Haohan Guo, Frank K. Soong, Lei He, Lei Xie", "title": "Exploiting Syntactic Features in a Parsed Tree to Improve End-to-End TTS", "comments": "Submitted to Interspeech 2019, Graz, Austria", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG cs.SD", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The end-to-end TTS, which can predict speech directly from a given sequence\nof graphemes or phonemes, has shown improved performance over the conventional\nTTS. However, its predicting capability is still limited by the\nacoustic/phonetic coverage of the training data, usually constrained by the\ntraining set size. To further improve the TTS quality in pronunciation, prosody\nand perceived naturalness, we propose to exploit the information embedded in a\nsyntactically parsed tree where the inter-phrase/word information of a sentence\nis organized in a multilevel tree structure. Specifically, two key features:\nphrase structure and relations between adjacent words are investigated.\nExperimental results in subjective listening, measured on three test sets, show\nthat the proposed approach is effective to improve the pronunciation clarity,\nprosody and naturalness of the synthesized speech of the baseline system.\n", "versions": [{"version": "v1", "created": "Tue, 9 Apr 2019 16:20:52 GMT"}], "update_date": "2019-04-10", "authors_parsed": [["Guo", "Haohan", ""], ["Soong", "Frank K.", ""], ["He", "Lei", ""], ["Xie", "Lei", ""]]}, {"id": "1904.04765", "submitter": "Song Fang", "authors": "Song Fang, Mikael Skoglund, Karl Henrik Johansson, Hideaki Ishii,\n  Quanyan Zhu", "title": "Generic Variance Bounds on Estimation and Prediction Errors in Time\n  Series Analysis: An Entropy Perspective", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IT cs.LG eess.SP math.IT math.ST stat.ML stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we obtain generic bounds on the variances of estimation and\nprediction errors in time series analysis via an information-theoretic\napproach. It is seen in general that the error bounds are determined by the\nconditional entropy of the data point to be estimated or predicted given the\nside information or past observations. Additionally, we discover that in order\nto achieve the prediction error bounds asymptotically, the necessary and\nsufficient condition is that the \"innovation\" is asymptotically white Gaussian.\nWhen restricted to Gaussian processes and 1-step prediction, our bounds are\nshown to reduce to the Kolmogorov-Szeg\\\"o formula and Wiener-Masani formula\nknown from linear prediction theory.\n", "versions": [{"version": "v1", "created": "Tue, 9 Apr 2019 16:22:14 GMT"}, {"version": "v2", "created": "Mon, 15 Apr 2019 09:17:02 GMT"}, {"version": "v3", "created": "Tue, 3 Sep 2019 15:57:47 GMT"}, {"version": "v4", "created": "Fri, 11 Oct 2019 23:12:57 GMT"}, {"version": "v5", "created": "Tue, 11 May 2021 14:48:31 GMT"}], "update_date": "2021-05-12", "authors_parsed": [["Fang", "Song", ""], ["Skoglund", "Mikael", ""], ["Johansson", "Karl Henrik", ""], ["Ishii", "Hideaki", ""], ["Zhu", "Quanyan", ""]]}, {"id": "1904.04772", "submitter": "James Oldfield", "authors": "James Oldfield, Yannis Panagakis, Mihalis A. Nicolaou", "title": "Adversarial Learning of Disentangled and Generalizable Representations\n  for Visual Attributes", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recently, a multitude of methods for image-to-image translation have\ndemonstrated impressive results on problems such as multi-domain or\nmulti-attribute transfer. The vast majority of such works leverages the\nstrengths of adversarial learning and deep convolutional autoencoders to\nachieve realistic results by well-capturing the target data distribution.\nNevertheless, the most prominent representatives of this class of methods do\nnot facilitate semantic structure in the latent space, and usually rely on\nbinary domain labels for test-time transfer. This leads to rigid models, unable\nto capture the variance of each domain label. In this light, we propose a novel\nadversarial learning method that (i) facilitates the emergence of latent\nstructure by semantically disentangling sources of variation, and (ii)\nencourages learning generalizable, continuous, and transferable latent codes\nthat enable flexible attribute mixing. This is achieved by introducing a novel\nloss function that encourages representations to result in uniformly\ndistributed class posteriors for disentangled attributes. In tandem with an\nalgorithm for inducing generalizable properties, the resulting representations\ncan be utilized for a variety of tasks such as intensity-preserving\nmulti-attribute image translation and synthesis, without requiring labelled\ntest data. We demonstrate the merits of the proposed method by a set of\nqualitative and quantitative experiments on popular databases such as MultiPIE,\nRaFD, and BU-3DFE, where our method outperforms other, state-of-the-art methods\nin tasks such as intensity-preserving multi-attribute transfer and synthesis.\n", "versions": [{"version": "v1", "created": "Tue, 9 Apr 2019 16:35:21 GMT"}, {"version": "v2", "created": "Thu, 18 Apr 2019 08:44:45 GMT"}, {"version": "v3", "created": "Sat, 30 Jan 2021 14:16:30 GMT"}], "update_date": "2021-02-02", "authors_parsed": [["Oldfield", "James", ""], ["Panagakis", "Yannis", ""], ["Nicolaou", "Mihalis A.", ""]]}, {"id": "1904.04775", "submitter": "Haohan Guo", "authors": "Haohan Guo, Frank K. Soong, Lei He, Lei Xie", "title": "A New GAN-based End-to-End TTS Training Algorithm", "comments": "Submitted to Interspeech 2019, Graz, Austria", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG cs.SD", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  End-to-end, autoregressive model-based TTS has shown significant performance\nimprovements over the conventional one. However, the autoregressive module\ntraining is affected by the exposure bias, or the mismatch between the\ndifferent distributions of real and predicted data. While real data is\navailable in training, but in testing, only predicted data is available to feed\nthe autoregressive module. By introducing both real and generated data\nsequences in training, we can alleviate the effects of the exposure bias. We\npropose to use Generative Adversarial Network (GAN) along with the key idea of\nProfessor Forcing in training. A discriminator in GAN is jointly trained to\nequalize the difference between real and predicted data. In AB subjective\nlistening test, the results show that the new approach is preferred over the\nstandard transfer learning with a CMOS improvement of 0.1. Sentence level\nintelligibility tests show significant improvement in a pathological test set.\nThe GAN-trained new model is also more stable than the baseline to produce\nbetter alignments for the Tacotron output.\n", "versions": [{"version": "v1", "created": "Tue, 9 Apr 2019 16:37:35 GMT"}], "update_date": "2019-04-10", "authors_parsed": [["Guo", "Haohan", ""], ["Soong", "Frank K.", ""], ["He", "Lei", ""], ["Xie", "Lei", ""]]}, {"id": "1904.04776", "submitter": "Tianyang Zhao", "authors": "Tianyang Zhao, Yifei Xu, Mathew Monfort, Wongun Choi, Chris Baker,\n  Yibiao Zhao, Yizhou Wang, Ying Nian Wu", "title": "Multi-Agent Tensor Fusion for Contextual Trajectory Prediction", "comments": "Presented in CVPR 19:\n  http://openaccess.thecvf.com/content_CVPR_2019/html/Zhao_Multi-Agent_Tensor_Fusion_for_Contextual_Trajectory_Prediction_CVPR_2019_paper.html\n  ; Architecture details available:\n  https://github.com/programmingLearner/MATF-architecture-details", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Accurate prediction of others' trajectories is essential for autonomous\ndriving. Trajectory prediction is challenging because it requires reasoning\nabout agents' past movements, social interactions among varying numbers and\nkinds of agents, constraints from the scene context, and the stochasticity of\nhuman behavior. Our approach models these interactions and constraints jointly\nwithin a novel Multi-Agent Tensor Fusion (MATF) network. Specifically, the\nmodel encodes multiple agents' past trajectories and the scene context into a\nMulti-Agent Tensor, then applies convolutional fusion to capture multiagent\ninteractions while retaining the spatial structure of agents and the scene\ncontext. The model decodes recurrently to multiple agents' future trajectories,\nusing adversarial loss to learn stochastic predictions. Experiments on both\nhighway driving and pedestrian crowd datasets show that the model achieves\nstate-of-the-art prediction accuracy.\n", "versions": [{"version": "v1", "created": "Tue, 9 Apr 2019 16:38:11 GMT"}, {"version": "v2", "created": "Sun, 28 Jul 2019 13:38:00 GMT"}], "update_date": "2019-07-30", "authors_parsed": [["Zhao", "Tianyang", ""], ["Xu", "Yifei", ""], ["Monfort", "Mathew", ""], ["Choi", "Wongun", ""], ["Baker", "Chris", ""], ["Zhao", "Yibiao", ""], ["Wang", "Yizhou", ""], ["Wu", "Ying Nian", ""]]}, {"id": "1904.04780", "submitter": "Sheng Liu", "authors": "Sheng Liu, Mark Cheng, Hayley Brooks, Wayne Mackey, David J. Heeger,\n  Esteban G. Tabak, Carlos Fernandez-Granda", "title": "Time-Series Analysis via Low-Rank Matrix Factorization Applied to\n  Infant-Sleep Data", "comments": "Machine Learning for Health (ML4H) at NeurIPS 2019 - Extended\n  Abstract", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a nonparametric model for time series with missing data based on\nlow-rank matrix factorization. The model expresses each instance in a set of\ntime series as a linear combination of a small number of shared basis\nfunctions. Constraining the functions and the corresponding coefficients to be\nnonnegative yields an interpretable low-dimensional representation of the data.\nA time-smoothing regularization term ensures that the model captures meaningful\ntrends in the data, instead of overfitting short-term fluctuations. The\nlow-dimensional representation makes it possible to detect outliers and cluster\nthe time series according to the interpretable features extracted by the model,\nand also to perform forecasting via kernel regression. We apply our methodology\nto a large real-world dataset of infant-sleep data gathered by caregivers with\na mobile-phone app. Our analysis automatically extracts daily-sleep patterns\nconsistent with the existing literature. This allows us to compute\nsleep-development trends for the cohort, which characterize the emergence of\ncircadian sleep and different napping habits. We apply our methodology to\ndetect anomalous individuals, to cluster the cohort into groups with different\nsleeping tendencies, and to obtain improved predictions of future sleep\nbehavior.\n", "versions": [{"version": "v1", "created": "Tue, 9 Apr 2019 16:51:01 GMT"}, {"version": "v2", "created": "Wed, 10 Apr 2019 01:55:14 GMT"}, {"version": "v3", "created": "Wed, 6 Nov 2019 21:40:41 GMT"}], "update_date": "2019-11-11", "authors_parsed": [["Liu", "Sheng", ""], ["Cheng", "Mark", ""], ["Brooks", "Hayley", ""], ["Mackey", "Wayne", ""], ["Heeger", "David J.", ""], ["Tabak", "Esteban G.", ""], ["Fernandez-Granda", "Carlos", ""]]}, {"id": "1904.04789", "submitter": "Felix Voigtlaender", "authors": "Felix Voigtlaender, Philipp Petersen", "title": "Approximation in $L^p(\\mu)$ with deep ReLU neural networks", "comments": "Accepted for presentation at SampTA 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.FA cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We discuss the expressive power of neural networks which use the non-smooth\nReLU activation function $\\varrho(x) = \\max\\{0,x\\}$ by analyzing the\napproximation theoretic properties of such networks. The existing results\nmainly fall into two categories: approximation using ReLU networks with a fixed\ndepth, or using ReLU networks whose depth increases with the approximation\naccuracy. After reviewing these findings, we show that the results concerning\nnetworks with fixed depth--- which up to now only consider approximation in\n$L^p(\\lambda)$ for the Lebesgue measure $\\lambda$--- can be generalized to\napproximation in $L^p(\\mu)$, for any finite Borel measure $\\mu$. In particular,\nthe generalized results apply in the usual setting of statistical learning\ntheory, where one is interested in approximation in $L^2(\\mathbb{P})$, with the\nprobability measure $\\mathbb{P}$ describing the distribution of the data.\n", "versions": [{"version": "v1", "created": "Tue, 9 Apr 2019 17:08:58 GMT"}], "update_date": "2019-04-10", "authors_parsed": [["Voigtlaender", "Felix", ""], ["Petersen", "Philipp", ""]]}, {"id": "1904.04802", "submitter": "Daniel Park", "authors": "Daniel Park, Haidar Khan, B\\\"ulent Yener", "title": "Generation & Evaluation of Adversarial Examples for Malware Obfuscation", "comments": "Preprint", "journal-ref": null, "doi": "10.1109/ICMLA.2019.00210", "report-no": null, "categories": "cs.CR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  There has been an increased interest in the application of convolutional\nneural networks for image based malware classification, but the susceptibility\nof neural networks to adversarial examples allows malicious actors to evade\nclassifiers. Adversarial examples are usually generated by adding small\nperturbations to the input that are unrecognizable to humans, but the same\napproach is not effective with malware. In general, these perturbations cause\nchanges in the byte sequences that change the initial functionality or result\nin un-executable binaries. We present a generative model for executable\nadversarial malware examples using obfuscation that achieves a high\nmisclassification rate, up to 100% and 98% in white-box and black-box settings\nrespectively, and demonstrates transferability. We further evaluate the\neffectiveness of the proposed method by reporting insignificant change in the\nevasion rate of our adversarial examples against popular defense strategies.\n", "versions": [{"version": "v1", "created": "Tue, 9 Apr 2019 17:27:58 GMT"}, {"version": "v2", "created": "Tue, 30 Jul 2019 17:30:31 GMT"}, {"version": "v3", "created": "Wed, 16 Oct 2019 02:06:58 GMT"}], "update_date": "2020-06-24", "authors_parsed": [["Park", "Daniel", ""], ["Khan", "Haidar", ""], ["Yener", "B\u00fclent", ""]]}, {"id": "1904.04805", "submitter": "Jacques Kaiser", "authors": "Jacques Kaiser, Alexander Friedrich, J. Camilo Vasquez Tieck, Daniel\n  Reichard, Arne Roennau, Emre Neftci, R\\\"udiger Dillmann", "title": "Embodied Neuromorphic Vision with Event-Driven Random Backpropagation", "comments": "v2: title update, better plots and wordings. 8 pages, 9 figures, 1\n  table, video: https://neurorobotics-files.net/index.php/s/sBQzWFrBPoH9Dx7", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Spike-based communication between biological neurons is sparse and\nunreliable. This enables the brain to process visual information from the eyes\nefficiently. Taking inspiration from biology, artificial spiking neural\nnetworks coupled with silicon retinas attempt to model these computations.\nRecent findings in machine learning allowed the derivation of a family of\npowerful synaptic plasticity rules approximating backpropagation for spiking\nnetworks. Are these rules capable of processing real-world visual sensory data?\nIn this paper, we evaluate the performance of Event-Driven Random\nBack-Propagation (eRBP) at learning representations from event streams provided\nby a Dynamic Vision Sensor (DVS). First, we show that eRBP matches\nstate-of-the-art performance on the DvsGesture dataset with the addition of a\nsimple covert attention mechanism. By remapping visual receptive fields\nrelatively to the center of the motion, this attention mechanism provides\ntranslation invariance at low computational cost compared to convolutions.\nSecond, we successfully integrate eRBP in a real robotic setup, where a robotic\narm grasps objects according to detected visual affordances. In this setup,\nvisual information is actively sensed by a DVS mounted on a robotic head\nperforming microsaccadic eye movements. We show that our method classifies\naffordances within 100ms after microsaccade onset, which is comparable to human\nperformance reported in behavioral study. Our results suggest that advances in\nneuromorphic technology and plasticity rules enable the development of\nautonomous robots operating at high speed and low energy consumption.\n", "versions": [{"version": "v1", "created": "Tue, 9 Apr 2019 17:35:24 GMT"}, {"version": "v2", "created": "Mon, 6 May 2019 12:56:48 GMT"}], "update_date": "2019-05-07", "authors_parsed": [["Kaiser", "Jacques", ""], ["Friedrich", "Alexander", ""], ["Tieck", "J. Camilo Vasquez", ""], ["Reichard", "Daniel", ""], ["Roennau", "Arne", ""], ["Neftci", "Emre", ""], ["Dillmann", "R\u00fcdiger", ""]]}, {"id": "1904.04817", "submitter": "Logan Courtney", "authors": "Logan Courtney, Ramavarapu Sreenivas", "title": "Learning from Videos with Deep Convolutional LSTM Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper explores the use of convolution LSTMs to simultaneously learn\nspatial- and temporal-information in videos. A deep network of convolutional\nLSTMs allows the model to access the entire range of temporal information at\nall spatial scales of the data. We describe our experiments involving\nconvolution LSTMs for lipreading that demonstrate the model is capable of\nselectively choosing which spatiotemporal scales are most relevant for a\nparticular dataset. The proposed deep architecture also holds promise in other\napplications where spatiotemporal features play a vital role without having to\nspecifically cater the design of the network for the particular spatiotemporal\nfeatures existent within the problem. For the Lip Reading in the Wild (LRW)\ndataset, our model slightly outperforms the previous state of the art (83.4%\nvs. 83.0%) and sets the new state of the art at 85.2% when the model is\npretrained on the Lip Reading Sentences (LRS2) dataset.\n", "versions": [{"version": "v1", "created": "Tue, 9 Apr 2019 17:57:17 GMT"}], "update_date": "2019-04-10", "authors_parsed": [["Courtney", "Logan", ""], ["Sreenivas", "Ramavarapu", ""]]}, {"id": "1904.04849", "submitter": "Matthias Fey", "authors": "Matthias Fey", "title": "Just Jump: Dynamic Neighborhood Aggregation in Graph Neural Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a dynamic neighborhood aggregation (DNA) procedure guided by\n(multi-head) attention for representation learning on graphs. In contrast to\ncurrent graph neural networks which follow a simple neighborhood aggregation\nscheme, our DNA procedure allows for a selective and node-adaptive aggregation\nof neighboring embeddings of potentially differing locality. In order to avoid\noverfitting, we propose to control the channel-wise connections between input\nand output by making use of grouped linear projections. In a number of\ntransductive node-classification experiments, we demonstrate the effectiveness\nof our approach.\n", "versions": [{"version": "v1", "created": "Tue, 9 Apr 2019 18:02:54 GMT"}, {"version": "v2", "created": "Mon, 15 Apr 2019 17:10:23 GMT"}], "update_date": "2019-04-16", "authors_parsed": [["Fey", "Matthias", ""]]}, {"id": "1904.04861", "submitter": "Todd Huster", "authors": "Jeremy E.J. Cohen, Todd Huster, Ra Cohen", "title": "Universal Lipschitz Approximation in Bounded Depth Neural Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Adversarial attacks against machine learning models are a rather hefty\nobstacle to our increasing reliance on these models. Due to this, provably\nrobust (certified) machine learning models are a major topic of interest.\nLipschitz continuous models present a promising approach to solving this\nproblem. By leveraging the expressive power of a variant of neural networks\nwhich maintain low Lipschitz constants, we prove that three layer neural\nnetworks using the FullSort activation function are Universal Lipschitz\nfunction Approximators (ULAs). This both explains experimental results and\npaves the way for the creation of better certified models going forward. We\nconclude by presenting experimental results that suggest that ULAs are a not\njust a novelty, but a competitive approach to providing certified classifiers,\nusing these results to motivate several potential topics of further research.\n", "versions": [{"version": "v1", "created": "Tue, 9 Apr 2019 18:39:43 GMT"}], "update_date": "2019-04-11", "authors_parsed": [["Cohen", "Jeremy E. J.", ""], ["Huster", "Todd", ""], ["Cohen", "Ra", ""]]}, {"id": "1904.04862", "submitter": "Mojan Javaheripi", "authors": "Mojan Javaheripi, Bita Darvish Rouhani, Farinaz Koushanfar", "title": "SWNet: Small-World Neural Networks and Rapid Convergence", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Training large and highly accurate deep learning (DL) models is\ncomputationally costly. This cost is in great part due to the excessive number\nof trained parameters, which are well-known to be redundant and compressible\nfor the execution phase. This paper proposes a novel transformation which\nchanges the topology of the DL architecture such that it reaches an optimal\ncross-layer connectivity. This transformation leverages our important\nobservation that for a set level of accuracy, convergence is fastest when\nnetwork topology reaches the boundary of a Small-World Network. Small-world\ngraphs are known to possess a specific connectivity structure that enables\nenhanced signal propagation among nodes. Our small-world models, called SWNets,\nprovide several intriguing benefits: they facilitate data (gradient) flow\nwithin the network, enable feature-map reuse by adding long-range connections\nand accommodate various network architectures/datasets. Compared to densely\nconnected networks (e.g., DenseNets), SWNets require a substantially fewer\nnumber of training parameters while maintaining a similar level of\nclassification accuracy. We evaluate our networks on various DL model\narchitectures and image classification datasets, namely, CIFAR10, CIFAR100, and\nILSVRC (ImageNet). Our experiments demonstrate an average of ~2.1x improvement\nin convergence speed to the desired accuracy\n", "versions": [{"version": "v1", "created": "Tue, 9 Apr 2019 18:41:26 GMT"}], "update_date": "2019-04-11", "authors_parsed": [["Javaheripi", "Mojan", ""], ["Rouhani", "Bita Darvish", ""], ["Koushanfar", "Farinaz", ""]]}, {"id": "1904.04866", "submitter": "Denis Newman-Griffis", "authors": "Brendan Whitaker, Denis Newman-Griffis, Aparajita Haldar, Hakan\n  Ferhatosmanoglu, Eric Fosler-Lussier", "title": "Characterizing the impact of geometric properties of word embeddings on\n  task performance", "comments": "Appearing in the Third Workshop on Evaluating Vector Space\n  Representations for NLP (RepEval 2019). 7 pages + references", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Analysis of word embedding properties to inform their use in downstream NLP\ntasks has largely been studied by assessing nearest neighbors. However,\ngeometric properties of the continuous feature space contribute directly to the\nuse of embedding features in downstream models, and are largely unexplored. We\nconsider four properties of word embedding geometry, namely: position relative\nto the origin, distribution of features in the vector space, global pairwise\ndistances, and local pairwise distances. We define a sequence of\ntransformations to generate new embeddings that expose subsets of these\nproperties to downstream models and evaluate change in task performance to\nunderstand the contribution of each property to NLP models. We transform\npublicly available pretrained embeddings from three popular toolkits (word2vec,\nGloVe, and FastText) and evaluate on a variety of intrinsic tasks, which model\nlinguistic information in the vector space, and extrinsic tasks, which use\nvectors as input to machine learning models. We find that intrinsic evaluations\nare highly sensitive to absolute position, while extrinsic tasks rely primarily\non local similarity. Our findings suggest that future embedding models and\npost-processing techniques should focus primarily on similarity to nearby\npoints in vector space.\n", "versions": [{"version": "v1", "created": "Tue, 9 Apr 2019 18:53:00 GMT"}], "update_date": "2019-04-11", "authors_parsed": [["Whitaker", "Brendan", ""], ["Newman-Griffis", "Denis", ""], ["Haldar", "Aparajita", ""], ["Ferhatosmanoglu", "Hakan", ""], ["Fosler-Lussier", "Eric", ""]]}, {"id": "1904.04912", "submitter": "Bryan Lim", "authors": "Bryan Lim, Stefan Zohren, Stephen Roberts", "title": "Enhancing Time Series Momentum Strategies Using Deep Neural Networks", "comments": null, "journal-ref": "The Journal of Financial Data Science, Fall 2019", "doi": null, "report-no": null, "categories": "stat.ML cs.LG q-fin.TR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  While time series momentum is a well-studied phenomenon in finance, common\nstrategies require the explicit definition of both a trend estimator and a\nposition sizing rule. In this paper, we introduce Deep Momentum Networks -- a\nhybrid approach which injects deep learning based trading rules into the\nvolatility scaling framework of time series momentum. The model also\nsimultaneously learns both trend estimation and position sizing in a\ndata-driven manner, with networks directly trained by optimising the Sharpe\nratio of the signal. Backtesting on a portfolio of 88 continuous futures\ncontracts, we demonstrate that the Sharpe-optimised LSTM improved traditional\nmethods by more than two times in the absence of transactions costs, and\ncontinue outperforming when considering transaction costs up to 2-3 basis\npoints. To account for more illiquid assets, we also propose a turnover\nregularisation term which trains the network to factor in costs at run-time.\n", "versions": [{"version": "v1", "created": "Tue, 9 Apr 2019 21:06:55 GMT"}, {"version": "v2", "created": "Sun, 17 Nov 2019 21:16:45 GMT"}, {"version": "v3", "created": "Sun, 27 Sep 2020 14:23:03 GMT"}], "update_date": "2020-09-29", "authors_parsed": [["Lim", "Bryan", ""], ["Zohren", "Stefan", ""], ["Roberts", "Stephen", ""]]}, {"id": "1904.04917", "submitter": "Tal Kachman", "authors": "Tal Kachman, Michal Moshkovitz, Michal Rosen-Zvi", "title": "Novel Uncertainty Framework for Deep Learning Ensembles", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://creativecommons.org/publicdomain/zero/1.0/", "abstract": "  Deep neural networks have become the default choice for many of the machine\nlearning tasks such as classification and regression. Dropout, a method\ncommonly used to improve the convergence of deep neural networks, generates an\nensemble of thinned networks with extensive weight sharing. Recent studies that\ndropout can be viewed as an approximate variational inference in Gaussian\nprocesses, and used as a practical tool to obtain uncertainty estimates of the\nnetwork. We propose a novel statistical mechanics based framework to dropout\nand use this framework to propose a new generic algorithm that focuses on\nestimates of the variance of the loss as measured by the ensemble of thinned\nnetworks. Our approach can be applied to a wide range of deep neural network\narchitectures and machine learning tasks. In classification, this algorithm\nallows the generation of a don't-know answer to be generated, which can\nincrease the reliability of the classifier. Empirically we demonstrate\nstate-of-the-art AUC results on publicly available benchmarks.\n", "versions": [{"version": "v1", "created": "Tue, 9 Apr 2019 21:31:08 GMT"}], "update_date": "2019-04-11", "authors_parsed": [["Kachman", "Tal", ""], ["Moshkovitz", "Michal", ""], ["Rosen-Zvi", "Michal", ""]]}, {"id": "1904.04940", "submitter": "Maria Bampa", "authors": "Maria Bampa", "title": "Handling temporality of clinical events with application to Adverse Drug\n  Event detection in Electronic Health Records: A scoping review", "comments": "4 pages, 1 figure", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The increased adoption of Electronic Health Records(EHRs) has brought changes\nto the way the patient care is carried out. The rich heterogeneous and temporal\ndata space stored in EHRs can be leveraged by machine learning models to\ncapture the underlying information and make clinically relevant predictions.\nThis can be exploited to support public health activities such as\npharmacovigilance and specifically mitigate the public health issue of Adverse\nDrug Events(ADEs). The aim of this article is, therefore, to investigate the\nvarious ways of handling temporal data for the purpose of detecting ADEs. Based\non a review of the existing literature, 11 articles from the last 10 years were\nchosen to be studied. According to the literature retrieved the main methods\nwere found to fall into 5 different approaches: based on temporal abstraction,\ngraph-based, learning weights and data tables containing time series of\ndifferent length. To that end, EHRs are a valuable source that has led current\nresearch to the automatic detection of ADEs. Yet there still exists a great\ndeal of challenges that concerns the exploitation of the heterogeneous, data\ntypes with temporal information included in EHRs for predicting ADEs.\n", "versions": [{"version": "v1", "created": "Tue, 9 Apr 2019 22:46:20 GMT"}], "update_date": "2019-04-11", "authors_parsed": [["Bampa", "Maria", ""]]}, {"id": "1904.04956", "submitter": "Wei Zhang", "authors": "Wei Zhang, Xiaodong Cui, Ulrich Finkler, Brian Kingsbury, George Saon,\n  David Kung, Michael Picheny", "title": "Distributed Deep Learning Strategies For Automatic Speech Recognition", "comments": "Published in ICASSP'19", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SD cs.CL cs.LG eess.AS stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we propose and investigate a variety of distributed deep\nlearning strategies for automatic speech recognition (ASR) and evaluate them\nwith a state-of-the-art Long short-term memory (LSTM) acoustic model on the\n2000-hour Switchboard (SWB2000), which is one of the most widely used datasets\nfor ASR performance benchmark. We first investigate what are the proper\nhyper-parameters (e.g., learning rate) to enable the training with sufficiently\nlarge batch size without impairing the model accuracy. We then implement\nvarious distributed strategies, including Synchronous (SYNC), Asynchronous\nDecentralized Parallel SGD (ADPSGD) and the hybrid of the two HYBRID, to study\ntheir runtime/accuracy trade-off. We show that we can train the LSTM model\nusing ADPSGD in 14 hours with 16 NVIDIA P100 GPUs to reach a 7.6% WER on the\nHub5- 2000 Switchboard (SWB) test set and a 13.1% WER on the CallHome (CH) test\nset. Furthermore, we can train the model using HYBRID in 11.5 hours with 32\nNVIDIA V100 GPUs without loss in accuracy.\n", "versions": [{"version": "v1", "created": "Wed, 10 Apr 2019 01:00:26 GMT"}], "update_date": "2019-04-11", "authors_parsed": [["Zhang", "Wei", ""], ["Cui", "Xiaodong", ""], ["Finkler", "Ulrich", ""], ["Kingsbury", "Brian", ""], ["Saon", "George", ""], ["Kung", "David", ""], ["Picheny", "Michael", ""]]}, {"id": "1904.04957", "submitter": "Tristan Hascoet", "authors": "Tristan Hascoet, Yasuo Ariki and Tetsuya Takiguchi", "title": "On zero-shot recognition of generic objects", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Many recent advances in computer vision are the result of a healthy\ncompetition among researchers on high quality, task-specific, benchmarks. After\na decade of active research, zero-shot learning (ZSL) models accuracy on the\nImagenet benchmark remains far too low to be considered for practical object\nrecognition applications. In this paper, we argue that the main reason behind\nthis apparent lack of progress is the poor quality of this benchmark. We\nhighlight major structural flaws of the current benchmark and analyze different\nfactors impacting the accuracy of ZSL models. We show that the actual\nclassification accuracy of existing ZSL models is significantly higher than was\npreviously thought as we account for these flaws. We then introduce the notion\nof structural bias specific to ZSL datasets. We discuss how the presence of\nthis new form of bias allows for a trivial solution to the standard benchmark\nand conclude on the need for a new benchmark. We then detail the semi-automated\nconstruction of a new benchmark to address these flaws.\n", "versions": [{"version": "v1", "created": "Wed, 10 Apr 2019 01:04:35 GMT"}], "update_date": "2019-04-11", "authors_parsed": [["Hascoet", "Tristan", ""], ["Ariki", "Yasuo", ""], ["Takiguchi", "Tetsuya", ""]]}, {"id": "1904.04969", "submitter": "Yu Cao", "authors": "Yu Cao, Meng Fang, Dacheng Tao", "title": "BAG: Bi-directional Attention Entity Graph Convolutional Network for\n  Multi-hop Reasoning Question Answering", "comments": "5 pages, 1 figure, accepted short paper on NAACL-HLT 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Multi-hop reasoning question answering requires deep comprehension of\nrelationships between various documents and queries. We propose a\nBi-directional Attention Entity Graph Convolutional Network (BAG), leveraging\nrelationships between nodes in an entity graph and attention information\nbetween a query and the entity graph, to solve this task. Graph convolutional\nnetworks are used to obtain a relation-aware representation of nodes for entity\ngraphs built from documents with multi-level features. Bidirectional attention\nis then applied on graphs and queries to generate a query-aware nodes\nrepresentation, which will be used for the final prediction. Experimental\nevaluation shows BAG achieves state-of-the-art accuracy performance on the\nQAngaroo WIKIHOP dataset.\n", "versions": [{"version": "v1", "created": "Wed, 10 Apr 2019 01:40:08 GMT"}], "update_date": "2019-04-11", "authors_parsed": [["Cao", "Yu", ""], ["Fang", "Meng", ""], ["Tao", "Dacheng", ""]]}, {"id": "1904.04971", "submitter": "Jiquan Ngiam", "authors": "Brandon Yang, Gabriel Bender, Quoc V. Le, Jiquan Ngiam", "title": "CondConv: Conditionally Parameterized Convolutions for Efficient\n  Inference", "comments": null, "journal-ref": "NeurIPS 2019", "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Convolutional layers are one of the basic building blocks of modern deep\nneural networks. One fundamental assumption is that convolutional kernels\nshould be shared for all examples in a dataset. We propose conditionally\nparameterized convolutions (CondConv), which learn specialized convolutional\nkernels for each example. Replacing normal convolutions with CondConv enables\nus to increase the size and capacity of a network, while maintaining efficient\ninference. We demonstrate that scaling networks with CondConv improves the\nperformance and inference cost trade-off of several existing convolutional\nneural network architectures on both classification and detection tasks. On\nImageNet classification, our CondConv approach applied to EfficientNet-B0\nachieves state-of-the-art performance of 78.3% accuracy with only 413M\nmultiply-adds. Code and checkpoints for the CondConv Tensorflow layer and\nCondConv-EfficientNet models are available at:\nhttps://github.com/tensorflow/tpu/tree/master/models/official/efficientnet/condconv.\n", "versions": [{"version": "v1", "created": "Wed, 10 Apr 2019 01:46:48 GMT"}, {"version": "v2", "created": "Tue, 22 Oct 2019 17:58:56 GMT"}, {"version": "v3", "created": "Fri, 4 Sep 2020 00:53:44 GMT"}], "update_date": "2020-09-07", "authors_parsed": [["Yang", "Brandon", ""], ["Bender", "Gabriel", ""], ["Le", "Quoc V.", ""], ["Ngiam", "Jiquan", ""]]}, {"id": "1904.04973", "submitter": "Yoshiharu Sato", "authors": "Yoshiharu Sato", "title": "Model-Free Reinforcement Learning for Financial Portfolios: A Brief\n  Survey", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "q-fin.PM cs.AI cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Financial portfolio management is one of the problems that are most\nfrequently encountered in the investment industry. Nevertheless, it is not\nwidely recognized that both Kelly Criterion and Risk Parity collapse into Mean\nVariance under some conditions, which implies that a universal solution to the\nportfolio optimization problem could potentially exist. In fact, the process of\nsequential computation of optimal component weights that maximize the\nportfolio's expected return subject to a certain risk budget can be\nreformulated as a discrete-time Markov Decision Process (MDP) and hence as a\nstochastic optimal control, where the system being controlled is a portfolio\nconsisting of multiple investment components, and the control is its component\nweights. Consequently, the problem could be solved using model-free\nReinforcement Learning (RL) without knowing specific component dynamics. By\nexamining existing methods of both value-based and policy-based model-free RL\nfor the portfolio optimization problem, we identify some of the key unresolved\nquestions and difficulties facing today's portfolio managers of applying\nmodel-free RL to their investment portfolios.\n", "versions": [{"version": "v1", "created": "Wed, 10 Apr 2019 01:48:52 GMT"}, {"version": "v2", "created": "Fri, 3 May 2019 09:29:20 GMT"}], "update_date": "2019-06-11", "authors_parsed": [["Sato", "Yoshiharu", ""]]}, {"id": "1904.04978", "submitter": "Dawei Du", "authors": "Congcong Li, Dawei Du, Libo Zhang, Tiejian Luo, Yanjun Wu, Qi Tian,\n  Longyin Wen, Siwei Lyu", "title": "Data Priming Network for Automatic Check-Out", "comments": "Accepted to ACM MM 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Automatic Check-Out (ACO) receives increased interests in recent years. An\nimportant component of the ACO system is the visual item counting, which\nrecognizes the categories and counts of the items chosen by the customers.\nHowever, the training of such a system is challenged by the domain adaptation\nproblem, in which the training data are images from isolated items while the\ntesting images are for collections of items. Existing methods solve this\nproblem with data augmentation using synthesized images, but the image\nsynthesis leads to unreal images that affect the training process. In this\npaper, we propose a new data priming method to solve the domain adaptation\nproblem. Specifically, we first use pre-augmentation data priming, in which we\nremove distracting background from the training images using the coarse-to-fine\nstrategy and select images with realistic view angles by the pose pruning\nmethod. In the post-augmentation step, we train a data priming network using\ndetection and counting collaborative learning, and select more reliable images\nfrom testing data to fine-tune the final visual item tallying network.\nExperiments on the large scale Retail Product Checkout (RPC) dataset\ndemonstrate the superiority of the proposed method, i.e., we achieve 80.51%\ncheckout accuracy compared with 56.68% of the baseline methods. The source\ncodes can be found in https://isrc.iscas.ac.cn/gitlab/research/acm-mm-2019-ACO.\n", "versions": [{"version": "v1", "created": "Wed, 10 Apr 2019 02:12:48 GMT"}, {"version": "v2", "created": "Thu, 1 Aug 2019 17:12:56 GMT"}, {"version": "v3", "created": "Wed, 7 Aug 2019 03:04:32 GMT"}], "update_date": "2019-08-08", "authors_parsed": [["Li", "Congcong", ""], ["Du", "Dawei", ""], ["Zhang", "Libo", ""], ["Luo", "Tiejian", ""], ["Wu", "Yanjun", ""], ["Tian", "Qi", ""], ["Wen", "Longyin", ""], ["Lyu", "Siwei", ""]]}, {"id": "1904.04990", "submitter": "Zhenxing Xu", "authors": "Zhenxing Xu, Jingyuan Chou, Xi Sheryl Zhang, Yuan Luo, Tamara Isakova,\n  Prakash Adekkanattu, Jessica S. Ancker, Guoqian Jiang, Richard C. Kiefer,\n  Jennifer A. Pacheco, Luke V. Rasmussen, Jyotishman Pathak, Fei Wang", "title": "Identifying Sub-Phenotypes of Acute Kidney Injury using Structured and\n  Unstructured Electronic Health Record Data with Memory Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Acute Kidney Injury (AKI) is a common clinical syndrome characterized by the\nrapid loss of kidney excretory function, which aggravates the clinical severity\nof other diseases in a large number of hospitalized patients. Accurate early\nprediction of AKI can enable in-time interventions and treatments. However, AKI\nis highly heterogeneous, thus identification of AKI sub-phenotypes can lead to\nan improved understanding of the disease pathophysiology and development of\nmore targeted clinical interventions. This study used a memory network-based\ndeep learning approach to discover AKI sub-phenotypes using structured and\nunstructured electronic health record (EHR) data of patients before AKI\ndiagnosis. We leveraged a real world critical care EHR corpus including 37,486\nICU stays. Our approach identified three distinct sub-phenotypes: sub-phenotype\nI is with an average age of 63.03$ \\pm 17.25 $ years, and is characterized by\nmild loss of kidney excretory function (Serum Creatinine (SCr) $1.55\\pm 0.34$\nmg/dL, estimated Glomerular Filtration Rate Test (eGFR) $107.65\\pm 54.98$\nmL/min/1.73$m^2$). These patients are more likely to develop stage I AKI.\nSub-phenotype II is with average age 66.81$ \\pm 10.43 $ years, and was\ncharacterized by severe loss of kidney excretory function (SCr $1.96\\pm 0.49$\nmg/dL, eGFR $82.19\\pm 55.92$ mL/min/1.73$m^2$). These patients are more likely\nto develop stage III AKI. Sub-phenotype III is with average age 65.07$ \\pm\n11.32 $ years, and was characterized moderate loss of kidney excretory function\nand thus more likely to develop stage II AKI (SCr $1.69\\pm 0.32$ mg/dL, eGFR\n$93.97\\pm 56.53$ mL/min/1.73$m^2$). Both SCr and eGFR are significantly\ndifferent across the three sub-phenotypes with statistical testing plus postdoc\nanalysis, and the conclusion still holds after age adjustment.\n", "versions": [{"version": "v1", "created": "Wed, 10 Apr 2019 03:22:34 GMT"}, {"version": "v2", "created": "Sun, 22 Dec 2019 17:00:52 GMT"}], "update_date": "2019-12-24", "authors_parsed": [["Xu", "Zhenxing", ""], ["Chou", "Jingyuan", ""], ["Zhang", "Xi Sheryl", ""], ["Luo", "Yuan", ""], ["Isakova", "Tamara", ""], ["Adekkanattu", "Prakash", ""], ["Ancker", "Jessica S.", ""], ["Jiang", "Guoqian", ""], ["Kiefer", "Richard C.", ""], ["Pacheco", "Jennifer A.", ""], ["Rasmussen", "Luke V.", ""], ["Pathak", "Jyotishman", ""], ["Wang", "Fei", ""]]}, {"id": "1904.04994", "submitter": "Mert Ozer", "authors": "Mert Ozer, Anna Sapienza, Andr\\'es Abeliuk, Goran Muric, Emilio\n  Ferrara", "title": "Discovering patterns of online popularity from time series", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.SI stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  How is popularity gained online? Is being successful strictly related to\nrapidly becoming viral in an online platform or is it possible to acquire\npopularity in a steady and disciplined fashion? What are other temporal\ncharacteristics that can unveil the popularity of online content? To answer\nthese questions, we leverage a multi-faceted temporal analysis of the evolution\nof popular online contents. Here, we present dipm-SC: a multi-dimensional\nshape-based time-series clustering algorithm with a heuristic to find the\noptimal number of clusters. First, we validate the accuracy of our algorithm on\nsynthetic datasets generated from benchmark time series models. Second, we show\nthat dipm-SC can uncover meaningful clusters of popularity behaviors in a\nreal-world Twitter dataset. By clustering the multidimensional time-series of\nthe popularity of contents coupled with other domain-specific dimensions, we\nuncover two main patterns of popularity: bursty and steady temporal behaviors.\nMoreover, we find that the way popularity is gained over time has no\nsignificant impact on the final cumulative popularity.\n", "versions": [{"version": "v1", "created": "Wed, 10 Apr 2019 03:47:49 GMT"}], "update_date": "2019-04-11", "authors_parsed": [["Ozer", "Mert", ""], ["Sapienza", "Anna", ""], ["Abeliuk", "Andr\u00e9s", ""], ["Muric", "Goran", ""], ["Ferrara", "Emilio", ""]]}, {"id": "1904.04998", "submitter": "Ariel Gordon", "authors": "Ariel Gordon, Hanhan Li, Rico Jonschkowski, Anelia Angelova", "title": "Depth from Videos in the Wild: Unsupervised Monocular Depth Learning\n  from Unknown Cameras", "comments": null, "journal-ref": "The IEEE International Conference on Computer Vision (ICCV), 2019,\n  pp. 8977-8986", "doi": null, "report-no": null, "categories": "cs.CV cs.GR cs.LG cs.RO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a novel method for simultaneous learning of depth, egomotion,\nobject motion, and camera intrinsics from monocular videos, using only\nconsistency across neighboring video frames as supervision signal. Similarly to\nprior work, our method learns by applying differentiable warping to frames and\ncomparing the result to adjacent ones, but it provides several improvements: We\naddress occlusions geometrically and differentiably, directly using the depth\nmaps as predicted during training. We introduce randomized layer normalization,\na novel powerful regularizer, and we account for object motion relative to the\nscene. To the best of our knowledge, our work is the first to learn the camera\nintrinsic parameters, including lens distortion, from video in an unsupervised\nmanner, thereby allowing us to extract accurate depth and motion from arbitrary\nvideos of unknown origin at scale. We evaluate our results on the Cityscapes,\nKITTI and EuRoC datasets, establishing new state of the art on depth prediction\nand odometry, and demonstrate qualitatively that depth prediction can be\nlearned from a collection of YouTube videos.\n", "versions": [{"version": "v1", "created": "Wed, 10 Apr 2019 04:16:30 GMT"}], "update_date": "2019-10-31", "authors_parsed": [["Gordon", "Ariel", ""], ["Li", "Hanhan", ""], ["Jonschkowski", "Rico", ""], ["Angelova", "Anelia", ""]]}, {"id": "1904.05003", "submitter": "Wenbing Huang", "authors": "Jia Li, Yu Rong, Hong Cheng, Helen Meng, Wenbing Huang, Junzhou Huang", "title": "Semi-Supervised Graph Classification: A Hierarchical Graph Perspective", "comments": "12 pages, WWW-2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Node classification and graph classification are two graph learning problems\nthat predict the class label of a node and the class label of a graph\nrespectively. A node of a graph usually represents a real-world entity, e.g., a\nuser in a social network, or a protein in a protein-protein interaction\nnetwork. In this work, we consider a more challenging but practically useful\nsetting, in which a node itself is a graph instance. This leads to a\nhierarchical graph perspective which arises in many domains such as social\nnetwork, biological network and document collection. For example, in a social\nnetwork, a group of people with shared interests forms a user group, whereas a\nnumber of user groups are interconnected via interactions or common members. We\nstudy the node classification problem in the hierarchical graph where a `node'\nis a graph instance, e.g., a user group in the above example. As labels are\nusually limited in real-world data, we design two novel semi-supervised\nsolutions named \\underline{SE}mi-supervised gr\\underline{A}ph\nc\\underline{L}assification via \\underline{C}autious/\\underline{A}ctive\n\\underline{I}teration (or SEAL-C/AI in short). SEAL-C/AI adopt an iterative\nframework that takes turns to build or update two classifiers, one working at\nthe graph instance level and the other at the hierarchical graph level. To\nsimplify the representation of the hierarchical graph, we propose a novel\nsupervised, self-attentive graph embedding method called SAGE, which embeds\ngraph instances of arbitrary size into fixed-length vectors. Through\nexperiments on synthetic data and Tencent QQ group data, we demonstrate that\nSEAL-C/AI not only outperform competing methods by a significant margin in\nterms of accuracy/Macro-F1, but also generate meaningful interpretations of the\nlearned representations.\n", "versions": [{"version": "v1", "created": "Wed, 10 Apr 2019 04:53:20 GMT"}], "update_date": "2019-04-11", "authors_parsed": [["Li", "Jia", ""], ["Rong", "Yu", ""], ["Cheng", "Hong", ""], ["Meng", "Helen", ""], ["Huang", "Wenbing", ""], ["Huang", "Junzhou", ""]]}, {"id": "1904.05033", "submitter": "Prakhar Gupta", "authors": "Prakhar Gupta, Matteo Pagliardini and Martin Jaggi", "title": "Better Word Embeddings by Disentangling Contextual n-Gram Information", "comments": "NAACL 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.IR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Pre-trained word vectors are ubiquitous in Natural Language Processing\napplications. In this paper, we show how training word embeddings jointly with\nbigram and even trigram embeddings, results in improved unigram embeddings. We\nclaim that training word embeddings along with higher n-gram embeddings helps\nin the removal of the contextual information from the unigrams, resulting in\nbetter stand-alone word embeddings. We empirically show the validity of our\nhypothesis by outperforming other competing word representation models by a\nsignificant margin on a wide variety of tasks. We make our models publicly\navailable.\n", "versions": [{"version": "v1", "created": "Wed, 10 Apr 2019 07:44:06 GMT"}], "update_date": "2019-04-11", "authors_parsed": [["Gupta", "Prakhar", ""], ["Pagliardini", "Matteo", ""], ["Jaggi", "Martin", ""]]}, {"id": "1904.05044", "submitter": "Jiwoon Ahn", "authors": "Jiwoon Ahn, Sunghyun Cho, Suha Kwak", "title": "Weakly Supervised Learning of Instance Segmentation with Inter-pixel\n  Relations", "comments": "Accepted to CVPR 2019 (Oral)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper presents a novel approach for learning instance segmentation with\nimage-level class labels as supervision. Our approach generates pseudo instance\nsegmentation labels of training images, which are used to train a fully\nsupervised model. For generating the pseudo labels, we first identify confident\nseed areas of object classes from attention maps of an image classification\nmodel, and propagate them to discover the entire instance areas with accurate\nboundaries. To this end, we propose IRNet, which estimates rough areas of\nindividual instances and detects boundaries between different object classes.\nIt thus enables to assign instance labels to the seeds and to propagate them\nwithin the boundaries so that the entire areas of instances can be estimated\naccurately. Furthermore, IRNet is trained with inter-pixel relations on the\nattention maps, thus no extra supervision is required. Our method with IRNet\nachieves an outstanding performance on the PASCAL VOC 2012 dataset, surpassing\nnot only previous state-of-the-art trained with the same level of supervision,\nbut also some of previous models relying on stronger supervision.\n", "versions": [{"version": "v1", "created": "Wed, 10 Apr 2019 08:02:35 GMT"}, {"version": "v2", "created": "Thu, 9 May 2019 13:29:08 GMT"}, {"version": "v3", "created": "Fri, 10 May 2019 01:46:17 GMT"}], "update_date": "2019-05-13", "authors_parsed": [["Ahn", "Jiwoon", ""], ["Cho", "Sunghyun", ""], ["Kwak", "Suha", ""]]}, {"id": "1904.05046", "submitter": "Quanming Yao", "authors": "Yaqing Wang and Quanming Yao and James Kwok and Lionel M. Ni", "title": "Generalizing from a Few Examples: A Survey on Few-Shot Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Machine learning has been highly successful in data-intensive applications\nbut is often hampered when the data set is small. Recently, Few-Shot Learning\n(FSL) is proposed to tackle this problem. Using prior knowledge, FSL can\nrapidly generalize to new tasks containing only a few samples with supervised\ninformation. In this paper, we conduct a thorough survey to fully understand\nFSL. Starting from a formal definition of FSL, we distinguish FSL from several\nrelevant machine learning problems. We then point out that the core issue in\nFSL is that the empirical risk minimized is unreliable. Based on how prior\nknowledge can be used to handle this core issue, we categorize FSL methods from\nthree perspectives: (i) data, which uses prior knowledge to augment the\nsupervised experience; (ii) model, which uses prior knowledge to reduce the\nsize of the hypothesis space; and (iii) algorithm, which uses prior knowledge\nto alter the search for the best hypothesis in the given hypothesis space. With\nthis taxonomy, we review and discuss the pros and cons of each category.\nPromising directions, in the aspects of the FSL problem setups, techniques,\napplications and theories, are also proposed to provide insights for future\nresearch.\n", "versions": [{"version": "v1", "created": "Wed, 10 Apr 2019 08:05:48 GMT"}, {"version": "v2", "created": "Mon, 13 May 2019 16:13:24 GMT"}, {"version": "v3", "created": "Sun, 29 Mar 2020 16:47:41 GMT"}], "update_date": "2020-03-31", "authors_parsed": [["Wang", "Yaqing", ""], ["Yao", "Quanming", ""], ["Kwok", "James", ""], ["Ni", "Lionel M.", ""]]}, {"id": "1904.05052", "submitter": "Enrique Fernandez-Blanco", "authors": "Carlos Fernandez-Lozano, Ruben F. Cuinas, Jose A. Seoane, Enrique\n  Fernandez-Blanco, Julian Dorado, Cristian R. Munteanu", "title": "Classification of signaling proteins based on molecular star graph\n  descriptors using Machine Learning models", "comments": "19 pages, 6 figures, 3 tables", "journal-ref": "Journal of theoretical biology 384 (2015): 50-58", "doi": "10.1016/j.jtbi.2015.07.038", "report-no": null, "categories": "q-bio.QM cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Signaling proteins are an important topic in drug development due to the\nincreased importance of finding fast, accurate and cheap methods to evaluate\nnew molecular targets involved in specific diseases. The complexity of the\nprotein structure hinders the direct association of the signaling activity with\nthe molecular structure. Therefore, the proposed solution involves the use of\nprotein star graphs for the peptide sequence information encoding into specific\ntopological indices calculated with S2SNet tool. The Quantitative\nStructure-Activity Relationship classification model obtained with Machine\nLearning techniques is able to predict new signaling peptides. The best\nclassification model is the first signaling prediction model, which is based on\neleven descriptors and it was obtained using the Support Vector Machines -\nRecursive Feature Elimination (SVM-RFE) technique with the Laplacian kernel\n(RFE-LAP) and an AUROC of 0.961. Testing a set of 3114 proteins of unknown\nfunction from the PDB database assessed the prediction performance of the\nmodel. Important signaling pathways are presented for three UniprotIDs (34\nPDBs) with a signaling prediction greater than 98.0%.\n", "versions": [{"version": "v1", "created": "Wed, 10 Apr 2019 08:22:35 GMT"}], "update_date": "2019-04-11", "authors_parsed": [["Fernandez-Lozano", "Carlos", ""], ["Cuinas", "Ruben F.", ""], ["Seoane", "Jose A.", ""], ["Fernandez-Blanco", "Enrique", ""], ["Dorado", "Julian", ""], ["Munteanu", "Cristian R.", ""]]}, {"id": "1904.05054", "submitter": "Mehmet Saygin Seyfioglu", "authors": "Semih Yagcioglu, Mehmet Saygin Seyfioglu, Begum Citamak, Batuhan\n  Bardak, Seren Guldamlasioglu, Azmi Yuksel, Emin Islam Tatli", "title": "Detecting Cybersecurity Events from Noisy Short Text", "comments": "Accepted February 2019 to North American Chapter of the Association\n  for Computational Linguistics (NAACL) 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.CR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  It is very critical to analyze messages shared over social networks for cyber\nthreat intelligence and cyber-crime prevention. In this study, we propose a\nmethod that leverages both domain-specific word embeddings and task-specific\nfeatures to detect cyber security events from tweets. Our model employs a\nconvolutional neural network (CNN) and a long short-term memory (LSTM)\nrecurrent neural network which takes word level meta-embeddings as inputs and\nincorporates contextual embeddings to classify noisy short text. We collected a\nnew dataset of cyber security related tweets from Twitter and manually\nannotated a subset of 2K of them. We experimented with this dataset and\nconcluded that the proposed model outperforms both traditional and neural\nbaselines. The results suggest that our method works well for detecting cyber\nsecurity events from noisy short text.\n", "versions": [{"version": "v1", "created": "Wed, 10 Apr 2019 08:23:31 GMT"}, {"version": "v2", "created": "Sun, 2 Jun 2019 18:38:51 GMT"}], "update_date": "2019-06-04", "authors_parsed": [["Yagcioglu", "Semih", ""], ["Seyfioglu", "Mehmet Saygin", ""], ["Citamak", "Begum", ""], ["Bardak", "Batuhan", ""], ["Guldamlasioglu", "Seren", ""], ["Yuksel", "Azmi", ""], ["Tatli", "Emin Islam", ""]]}, {"id": "1904.05061", "submitter": "Soroor Malekmohamadi", "authors": "Soroor Malekmohammadi Faradonbeh, Faramarz Safi-Esfahani", "title": "A review on Neural Turing Machine", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  One of the major objectives of Artificial Intelligence is to design learning\nalgorithms that are executed on a general purposes computational machines such\nas human brain. Neural Turing Machine (NTM) is a step towards realizing such a\ncomputational machine. The attempt is made here to run a systematic review on\nNeural Turing Machine. First, the mind-map and taxonomy of machine learning,\nneural networks, and Turing machine are introduced. Next, NTM is inspected in\nterms of concepts, structure, variety of versions, implemented tasks,\ncomparisons, etc. Finally, the paper discusses on issues and ends up with\nseveral future works.\n", "versions": [{"version": "v1", "created": "Wed, 10 Apr 2019 08:36:46 GMT"}, {"version": "v2", "created": "Sun, 15 Nov 2020 10:15:53 GMT"}], "update_date": "2020-11-17", "authors_parsed": [["Faradonbeh", "Soroor Malekmohammadi", ""], ["Safi-Esfahani", "Faramarz", ""]]}, {"id": "1904.05068", "submitter": "Wonpyo Park", "authors": "Wonpyo Park, Dongju Kim, Yan Lu, Minsu Cho", "title": "Relational Knowledge Distillation", "comments": "Accepted to CVPR 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Knowledge distillation aims at transferring knowledge acquired in one model\n(a teacher) to another model (a student) that is typically smaller. Previous\napproaches can be expressed as a form of training the student to mimic output\nactivations of individual data examples represented by the teacher. We\nintroduce a novel approach, dubbed relational knowledge distillation (RKD),\nthat transfers mutual relations of data examples instead. For concrete\nrealizations of RKD, we propose distance-wise and angle-wise distillation\nlosses that penalize structural differences in relations. Experiments conducted\non different tasks show that the proposed method improves educated student\nmodels with a significant margin. In particular for metric learning, it allows\nstudents to outperform their teachers' performance, achieving the state of the\narts on standard benchmark datasets.\n", "versions": [{"version": "v1", "created": "Wed, 10 Apr 2019 08:52:14 GMT"}, {"version": "v2", "created": "Wed, 1 May 2019 09:36:42 GMT"}], "update_date": "2019-05-02", "authors_parsed": [["Park", "Wonpyo", ""], ["Kim", "Dongju", ""], ["Lu", "Yan", ""], ["Cho", "Minsu", ""]]}, {"id": "1904.05073", "submitter": "Prateek Verma", "authors": "Prateek Verma, Chris Chafe, Jonathan Berger", "title": "Neuralogram: A Deep Neural Network Based Representation for Audio\n  Signals", "comments": "Submitted to DAFx 2019, the 22nd International Conference on Digital\n  Audio Effects, Birmingham, United Kingdom", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SD cs.LG cs.MM eess.AS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose the Neuralogram -- a deep neural network based representation for\nunderstanding audio signals which, as the name suggests, transforms an audio\nsignal to a dense, compact representation based upon embeddings learned via a\nneural architecture. Through a series of probing signals, we show how our\nrepresentation can encapsulate pitch, timbre and rhythm-based information, and\nother attributes. This representation suggests a method for revealing\nmeaningful relationships in arbitrarily long audio signals that are not readily\nrepresented by existing algorithms. This has the potential for numerous\napplications in audio understanding, music recommendation, meta-data extraction\nto name a few.\n", "versions": [{"version": "v1", "created": "Wed, 10 Apr 2019 09:04:18 GMT"}], "update_date": "2019-04-11", "authors_parsed": [["Verma", "Prateek", ""], ["Chafe", "Chris", ""], ["Berger", "Jonathan", ""]]}, {"id": "1904.05086", "submitter": "Helena Cuesta", "authors": "Helena Cuesta, Emilia G\\'omez, Pritish Chandna", "title": "A Framework for Multi-f0 Modeling in SATB Choir Recordings", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SD cs.LG cs.MM eess.AS", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Fundamental frequency (f0) modeling is an important but relatively unexplored\naspect of choir singing. Performance evaluation as well as auditory analysis of\nsinging, whether individually or in a choir, often depend on extracting f0\ncontours for the singing voice. However, due to the large number of singers,\nsinging at a similar frequency range, extracting the exact individual pitch\ncontours from choir recordings is a challenging task. In this paper, we address\nthis task and develop a methodology for modeling pitch contours of SATB choir\nrecordings. A typical SATB choir consists of four parts, each covering a\ndistinct range of pitches and often with multiple singers each. We first\nevaluate some state-of-the-art multi-f0 estimation systems for the particular\ncase of choirs with a single singer per part, and observe that the pitch of\nindividual singers can be estimated to a relatively high degree of accuracy. We\nobserve, however, that the scenario of multiple singers for each choir part\n(i.e. unison singing) is far more challenging. In this work we propose a\nmethodology based on combining a multi-f0 estimation methodology based on deep\nlearning followed by a set of traditional DSP techniques to model f0 and its\ndispersion instead of a single f0 trajectory for each choir part. We present\nand discuss our observations and test our framework with different singer\nconfigurations.\n", "versions": [{"version": "v1", "created": "Wed, 10 Apr 2019 09:35:50 GMT"}], "update_date": "2019-04-11", "authors_parsed": [["Cuesta", "Helena", ""], ["G\u00f3mez", "Emilia", ""], ["Chandna", "Pritish", ""]]}, {"id": "1904.05098", "submitter": "Marco Frasca", "authors": "Marco Frasca, Giuliano Grossi, Giorgio Valentini", "title": "Multitask Hopfield Networks", "comments": "16 pages, 1 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Multitask algorithms typically use task similarity information as a bias to\nspeed up and improve the performance of learning processes. Tasks are learned\njointly, sharing information across them, in order to construct models more\naccurate than those learned separately over single tasks. In this contribution,\nwe present the first multitask model, to our knowledge, based on Hopfield\nNetworks (HNs), named HoMTask. We show that by appropriately building a unique\nHN embedding all tasks, a more robust and effective classification model can be\nlearned. HoMTask is a transductive semi-supervised parametric HN, that\nminimizes an energy function extended to all nodes and to all tasks under\nstudy. We provide theoretical evidence that the optimal parameters\nautomatically estimated by HoMTask make coherent the model itself with the\nprior knowledge (connection weights and node labels). The convergence\nproperties of HNs are preserved, and the fixed point reached by the network\ndynamics gives rise to the prediction of unlabeled nodes. The proposed model\nimproves the classification abilities of singletask HNs on a preliminary\nbenchmark comparison, and achieves competitive performance with\nstate-of-the-art semi-supervised graph-based algorithms.\n", "versions": [{"version": "v1", "created": "Wed, 10 Apr 2019 10:25:19 GMT"}], "update_date": "2019-04-11", "authors_parsed": [["Frasca", "Marco", ""], ["Grossi", "Giuliano", ""], ["Valentini", "Giorgio", ""]]}, {"id": "1904.05100", "submitter": "Yuan Xie", "authors": "Shu Changyong and Li Peng and Xie Yuan and Qu Yanyun and Dai Longquan\n  and Ma Lizhuang", "title": "Knowledge Squeezed Adversarial Network Compression", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep network compression has been achieved notable progress via knowledge\ndistillation, where a teacher-student learning manner is adopted by using\npredetermined loss. Recently, more focuses have been transferred to employ the\nadversarial training to minimize the discrepancy between distributions of\noutput from two networks. However, they always emphasize on result-oriented\nlearning while neglecting the scheme of process-oriented learning, leading to\nthe loss of rich information contained in the whole network pipeline. Inspired\nby the assumption that, the small network can not perfectly mimic a large one\ndue to the huge gap of network scale, we propose a knowledge transfer method,\ninvolving effective intermediate supervision, under the adversarial training\nframework to learn the student network. To achieve powerful but highly compact\nintermediate information representation, the squeezed knowledge is realized by\ntask-driven attention mechanism. Then, the transferred knowledge from teacher\nnetwork could accommodate the size of student network. As a result, the\nproposed method integrates merits from both process-oriented and\nresult-oriented learning. Extensive experimental results on three typical\nbenchmark datasets, i.e., CIFAR-10, CIFAR-100, and ImageNet, demonstrate that\nour method achieves highly superior performances against other state-of-the-art\nmethods.\n", "versions": [{"version": "v1", "created": "Wed, 10 Apr 2019 10:42:33 GMT"}, {"version": "v2", "created": "Thu, 25 Apr 2019 07:58:47 GMT"}], "update_date": "2019-04-26", "authors_parsed": [["Changyong", "Shu", ""], ["Peng", "Li", ""], ["Yuan", "Xie", ""], ["Yanyun", "Qu", ""], ["Longquan", "Dai", ""], ["Lizhuang", "Ma", ""]]}, {"id": "1904.05106", "submitter": "Andreas Bytyn", "authors": "Andreas Bytyn, Rainer Leupers and Gerd Ascheid", "title": "An Application-Specific VLIW Processor with Vector Instruction Set for\n  CNN Acceleration", "comments": "Accepted for publication in the proceedings of the 2019 IEEE\n  International Symposium on Circuits and Systems (ISCAS)", "journal-ref": null, "doi": "10.1109/ISCAS.2019.8702357", "report-no": null, "categories": "cs.AR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In recent years, neural networks have surpassed classical algorithms in areas\nsuch as object recognition, e.g. in the well-known ImageNet challenge. As a\nresult, great effort is being put into developing fast and efficient\naccelerators, especially for Convolutional Neural Networks (CNNs). In this work\nwe present ConvAix, a fully C-programmable processor, which -- contrary to many\nexisting architectures -- does not rely on a hard-wired array of\nmultiply-and-accumulate (MAC) units. Instead it maps computations onto\nindependent vector lanes making use of a carefully designed vector instruction\nset. The presented processor is targeted towards latency-sensitive applications\nand is capable of executing up to 192 MAC operations per cycle. ConvAix\noperates at a target clock frequency of 400 MHz in 28nm CMOS, thereby offering\nstate-of-the-art performance with proper flexibility within its target domain.\nSimulation results for several 2D convolutional layers from well known CNNs\n(AlexNet, VGG-16) show an average ALU utilization of 72.5% using vector\ninstructions with 16 bit fixed-point arithmetic. Compared to other well-known\ndesigns which are less flexible, ConvAix offers competitive energy efficiency\nof up to 497 GOP/s/W while even surpassing them in terms of area efficiency and\nprocessing speed.\n", "versions": [{"version": "v1", "created": "Wed, 10 Apr 2019 10:59:07 GMT"}], "update_date": "2019-07-18", "authors_parsed": [["Bytyn", "Andreas", ""], ["Leupers", "Rainer", ""], ["Ascheid", "Gerd", ""]]}, {"id": "1904.05126", "submitter": "Nikita Araslanov", "authors": "Nikita Araslanov, Constantin Rothkopf, Stefan Roth", "title": "Actor-Critic Instance Segmentation", "comments": "To appear at CVPR 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Most approaches to visual scene analysis have emphasised parallel processing\nof the image elements. However, one area in which the sequential nature of\nvision is apparent, is that of segmenting multiple, potentially similar and\npartially occluded objects in a scene. In this work, we revisit the recurrent\nformulation of this challenging problem in the context of reinforcement\nlearning. Motivated by the limitations of the global max-matching assignment of\nthe ground-truth segments to the recurrent states, we develop an actor-critic\napproach in which the actor recurrently predicts one instance mask at a time\nand utilises the gradient from a concurrently trained critic network. We\nformulate the state, action, and the reward such as to let the critic model\nlong-term effects of the current prediction and incorporate this information\ninto the gradient signal. Furthermore, to enable effective exploration in the\ninherently high-dimensional action space of instance masks, we learn a compact\nrepresentation using a conditional variational auto-encoder. We show that our\nactor-critic model consistently provides accuracy benefits over the recurrent\nbaseline on standard instance segmentation benchmarks.\n", "versions": [{"version": "v1", "created": "Wed, 10 Apr 2019 12:08:13 GMT"}], "update_date": "2019-04-11", "authors_parsed": [["Araslanov", "Nikita", ""], ["Rothkopf", "Constantin", ""], ["Roth", "Stefan", ""]]}, {"id": "1904.05146", "submitter": "Micha\\\"el Defferrard", "authors": "Micha\\\"el Defferrard, Nathana\\\"el Perraudin, Tomasz Kacprzak, Raphael\n  Sgier", "title": "DeepSphere: towards an equivariant graph-based spherical CNN", "comments": "published at the ICLR 2019 Workshop on Representation Learning on\n  Graphs and Manifolds. arXiv admin note: text overlap with arXiv:1810.12186", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Spherical data is found in many applications. By modeling the discretized\nsphere as a graph, we can accommodate non-uniformly distributed, partial, and\nchanging samplings. Moreover, graph convolutions are computationally more\nefficient than spherical convolutions. As equivariance is desired to exploit\nrotational symmetries, we discuss how to approach rotation equivariance using\nthe graph neural network introduced in Defferrard et al. (2016). Experiments\nshow good performance on rotation-invariant learning problems. Code and\nexamples are available at https://github.com/SwissDataScienceCenter/DeepSphere\n", "versions": [{"version": "v1", "created": "Mon, 8 Apr 2019 18:01:04 GMT"}], "update_date": "2019-04-11", "authors_parsed": [["Defferrard", "Micha\u00ebl", ""], ["Perraudin", "Nathana\u00ebl", ""], ["Kacprzak", "Tomasz", ""], ["Sgier", "Raphael", ""]]}, {"id": "1904.05154", "submitter": "Heinrich Dinkel", "authors": "Heinrich Dinkel, Mengyue Wu and Kai Yu", "title": "Text-based depression detection on sparse data", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CL cs.HC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Previous text-based depression detection is commonly based on large\nuser-generated data. Sparse scenarios like clinical conversations are less\ninvestigated. This work proposes a text-based multi-task BGRU network with\npretrained word embeddings to model patients' responses during clinical\ninterviews. Our main approach uses a novel multi-task loss function, aiming at\nmodeling both depression severity and binary health state. We independently\ninvestigate word- and sentence-level word-embeddings as well as the use of\nlarge-data pretraining for depression detection. To strengthen our findings, we\nreport mean-averaged results for a multitude of independent runs on sparse\ndata. First, we show that pretraining is helpful for word-level text-based\ndepression detection. Second, our results demonstrate that sentence-level\nword-embeddings should be mostly preferred over word-level ones. While the\nchoice of pooling function is less crucial, mean and attention pooling should\nbe preferred over last-timestep pooling. Our method outputs depression presence\nresults as well as predicted severity score, culminating a macro F1 score of\n0.84 and MAE of 3.48 on the DAIC-WOZ development set.\n", "versions": [{"version": "v1", "created": "Mon, 8 Apr 2019 03:47:15 GMT"}, {"version": "v2", "created": "Thu, 30 May 2019 08:58:17 GMT"}, {"version": "v3", "created": "Wed, 8 Jul 2020 05:23:15 GMT"}], "update_date": "2020-07-09", "authors_parsed": [["Dinkel", "Heinrich", ""], ["Wu", "Mengyue", ""], ["Yu", "Kai", ""]]}, {"id": "1904.05158", "submitter": "Kyongmin Yeo", "authors": "Kyongmin Yeo", "title": "Short note on the behavior of recurrent neural network for noisy\n  dynamical system", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.LG physics.comp-ph physics.data-an", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The behavior of recurrent neural network for the data-driven simulation of\nnoisy dynamical systems is studied by training a set of Long Short-Term Memory\nNetworks (LSTM) on the Mackey-Glass time series with a wide range of noise\nlevel. It is found that, as the training noise becomes larger, LSTM learns to\ndepend more on its autonomous dynamics than the noisy input data. As a result,\nLSTM trained on noisy data becomes less susceptible to the perturbation in the\ndata, but has a longer relaxation timescale. On the other hand, when trained on\nnoiseless data, LSTM becomes extremely sensitive to a small perturbation, but\nis able to adjusts to the changes in the input data.\n", "versions": [{"version": "v1", "created": "Fri, 5 Apr 2019 21:17:32 GMT"}], "update_date": "2019-04-11", "authors_parsed": [["Yeo", "Kyongmin", ""]]}, {"id": "1904.05160", "submitter": "Ziwei Liu", "authors": "Ziwei Liu, Zhongqi Miao, Xiaohang Zhan, Jiayun Wang, Boqing Gong,\n  Stella X. Yu", "title": "Large-Scale Long-Tailed Recognition in an Open World", "comments": "To appear in CVPR 2019 as an oral presentation. Code, datasets and\n  models are available at https://liuziwei7.github.io/projects/LongTail.html", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Real world data often have a long-tailed and open-ended distribution. A\npractical recognition system must classify among majority and minority classes,\ngeneralize from a few known instances, and acknowledge novelty upon a never\nseen instance. We define Open Long-Tailed Recognition (OLTR) as learning from\nsuch naturally distributed data and optimizing the classification accuracy over\na balanced test set which include head, tail, and open classes. OLTR must\nhandle imbalanced classification, few-shot learning, and open-set recognition\nin one integrated algorithm, whereas existing classification approaches focus\nonly on one aspect and deliver poorly over the entire class spectrum. The key\nchallenges are how to share visual knowledge between head and tail classes and\nhow to reduce confusion between tail and open classes. We develop an integrated\nOLTR algorithm that maps an image to a feature space such that visual concepts\ncan easily relate to each other based on a learned metric that respects the\nclosed-world classification while acknowledging the novelty of the open world.\nOur so-called dynamic meta-embedding combines a direct image feature and an\nassociated memory feature, with the feature norm indicating the familiarity to\nknown classes. On three large-scale OLTR datasets we curate from object-centric\nImageNet, scene-centric Places, and face-centric MS1M data, our method\nconsistently outperforms the state-of-the-art. Our code, datasets, and models\nenable future OLTR research and are publicly available at\nhttps://liuziwei7.github.io/projects/LongTail.html.\n", "versions": [{"version": "v1", "created": "Wed, 10 Apr 2019 13:09:42 GMT"}, {"version": "v2", "created": "Tue, 16 Apr 2019 14:17:39 GMT"}], "update_date": "2019-04-17", "authors_parsed": [["Liu", "Ziwei", ""], ["Miao", "Zhongqi", ""], ["Zhan", "Xiaohang", ""], ["Wang", "Jiayun", ""], ["Gong", "Boqing", ""], ["Yu", "Stella X.", ""]]}, {"id": "1904.05163", "submitter": "Luca Magri", "authors": "Tullio Traverso, Luca Magri", "title": "Data assimilation in a nonlinear time-delayed dynamical system", "comments": "13 pages, 4 figures", "journal-ref": "Computational Science - ICCS 2019. ICCS 2019. Lecture Notes in\n  Computer Science, vol 11539. Springer, Cham", "doi": "10.1007/978-3-030-22747-0_12", "report-no": null, "categories": "cs.CE cs.LG physics.data-an physics.flu-dyn", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  When the heat released by a flame is sufficiently in phase with the acoustic\npressure, a self-excited thermoacoustic oscillation can arise. These nonlinear\noscillations are one of the biggest challenges faced in the design of safe and\nreliable gas turbines and rocket motors. In the worst-case scenario,\nuncontrolled thermoacoustic oscillations can shake an engine apart.\nReduced-order thermoacoustic models, which are nonlinear and time-delayed, can\nonly qualitatively predict thermoacoustic oscillations. To make reduced-order\nmodels quantitatively predictive, we develop a data assimilation framework for\nstate estimation. We numerically estimate the most likely nonlinear state of a\nGalerkin-discretized time delayed model of a horizontal Rijke tube, which is a\nprototypical combustor. Data assimilation is an optimal blending of\nobservations with previous state estimates (background) to produce optimal\ninitial conditions. A cost functional is defined to measure the statistical\ndistance between the model output and the measurements from experiments; and\nthe distance between the initial conditions and the background knowledge. Its\nminimum corresponds to the optimal state, which is computed by Lagrangian\noptimization with the aid of adjoint equations. We study the influence of the\nnumber of Galerkin modes, which are the natural acoustic modes of the duct,\nwith which the model is discretized. We show that decomposing the measured\npressure signal in a finite number of modes is an effective way to enhance\nstate estimation, especially when nonlinear modal interactions occur during the\nassimilation window. This work represents the first application of data\nassimilation to nonlinear thermoacoustics, which opens up new possibilities for\nreal-time calibration of reduced-order models with experimental measurements.\n", "versions": [{"version": "v1", "created": "Tue, 9 Apr 2019 10:12:55 GMT"}], "update_date": "2019-06-28", "authors_parsed": [["Traverso", "Tullio", ""], ["Magri", "Luca", ""]]}, {"id": "1904.05168", "submitter": "Xiaobo Qu", "authors": "Xiaobo Qu, Yihui Huang, Hengfa Lu, Tianyu Qiu, Di Guo, Tatiana Agback,\n  Vladislav Orekhov, Zhong Chen", "title": "Accelerated Nuclear Magnetic Resonance Spectroscopy with Deep Learning", "comments": "23 pages, 23 figures, 3 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "physics.med-ph cs.AI cs.LG math.SP physics.bio-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Nuclear magnetic resonance (NMR) spectroscopy serves as an indispensable tool\nin chemistry and biology but often suffers from long experimental time. We\npresent a proof-of-concept of application of deep learning and neural network\nfor high-quality, reliable, and very fast NMR spectra reconstruction from\nlimited experimental data. We show that the neural network training can be\nachieved using solely synthetic NMR signal, which lifts the prohibiting demand\nfor a large volume of realistic training data usually required in the deep\nlearning approach.\n", "versions": [{"version": "v1", "created": "Tue, 9 Apr 2019 16:10:34 GMT"}, {"version": "v2", "created": "Tue, 14 May 2019 04:49:32 GMT"}], "update_date": "2019-05-15", "authors_parsed": [["Qu", "Xiaobo", ""], ["Huang", "Yihui", ""], ["Lu", "Hengfa", ""], ["Qiu", "Tianyu", ""], ["Guo", "Di", ""], ["Agback", "Tatiana", ""], ["Orekhov", "Vladislav", ""], ["Chen", "Zhong", ""]]}, {"id": "1904.05172", "submitter": "Trevor Karn", "authors": "Trevor K. Karn, Steven Petrone, Christopher Griffin", "title": "Modeling a Hidden Dynamical System Using Energy Minimization and Kernel\n  Density Estimates", "comments": "16 pages, 8 figures, 3 tables Added additional experiments and\n  corrected notation", "journal-ref": "Phys. Rev. E 100, 042137 (2019)", "doi": "10.1103/PhysRevE.100.042137", "report-no": null, "categories": "cs.LG cs.NA math.DS math.NA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we develop a kernel density estimation (KDE) approach to\nmodeling and forecasting recurrent trajectories on a compact manifold. For the\npurposes of this paper, a trajectory is a sequence of coordinates in a phase\nspace defined by an underlying hidden dynamical system. Our work is inspired by\nearlier work on the use of KDE to detect shipping anomalies using high-density,\nhigh-quality automated information system (AIS) data as well as our own earlier\nwork in trajectory modeling. We focus specifically on the sparse, noisy\ntrajectory reconstruction problem in which the data are (i) sparsely sampled\nand (ii) subject to an imperfect observer that introduces noise. Under certain\nregularity assumptions, we show that the constructed estimator minimizes a\nspecific energy function defined over the trajectory as the number of samples\nobtained grows.\n", "versions": [{"version": "v1", "created": "Mon, 8 Apr 2019 22:48:46 GMT"}, {"version": "v2", "created": "Tue, 30 Jul 2019 15:06:40 GMT"}], "update_date": "2019-11-06", "authors_parsed": [["Karn", "Trevor K.", ""], ["Petrone", "Steven", ""], ["Griffin", "Christopher", ""]]}, {"id": "1904.05181", "submitter": "Linxi Jiang", "authors": "Linxi Jiang, Xingjun Ma, Shaoxiang Chen, James Bailey, Yu-Gang Jiang", "title": "Black-box Adversarial Attacks on Video Recognition Models", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR cs.CV cs.MM stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep neural networks (DNNs) are known for their vulnerability to adversarial\nexamples. These are examples that have undergone small, carefully crafted\nperturbations, and which can easily fool a DNN into making misclassifications\nat test time. Thus far, the field of adversarial research has mainly focused on\nimage models, under either a white-box setting, where an adversary has full\naccess to model parameters, or a black-box setting where an adversary can only\nquery the target model for probabilities or labels. Whilst several white-box\nattacks have been proposed for video models, black-box video attacks are still\nunexplored. To close this gap, we propose the first black-box video attack\nframework, called V-BAD. V-BAD utilizes tentative perturbations transferred\nfrom image models, and partition-based rectifications found by the NES on\npartitions (patches) of tentative perturbations, to obtain good adversarial\ngradient estimates with fewer queries to the target model. V-BAD is equivalent\nto estimating the projection of an adversarial gradient on a selected subspace.\nUsing three benchmark video datasets, we demonstrate that V-BAD can craft both\nuntargeted and targeted attacks to fool two state-of-the-art deep video\nrecognition models. For the targeted attack, it achieves $>$93\\% success rate\nusing only an average of $3.4 \\sim 8.4 \\times 10^4$ queries, a similar number\nof queries to state-of-the-art black-box image attacks. This is despite the\nfact that videos often have two orders of magnitude higher dimensionality than\nstatic images. We believe that V-BAD is a promising new tool to evaluate and\nimprove the robustness of video recognition models to black-box adversarial\nattacks.\n", "versions": [{"version": "v1", "created": "Wed, 10 Apr 2019 13:41:02 GMT"}, {"version": "v2", "created": "Fri, 28 Jun 2019 06:22:54 GMT"}], "update_date": "2019-07-01", "authors_parsed": [["Jiang", "Linxi", ""], ["Ma", "Xingjun", ""], ["Chen", "Shaoxiang", ""], ["Bailey", "James", ""], ["Jiang", "Yu-Gang", ""]]}, {"id": "1904.05204", "submitter": "Hongwei Song", "authors": "Hongwei Song, Jiqing Han, Shiwen Deng, Zhihao Du", "title": "Acoustic Scene Classification by Implicitly Identifying Distinct Sound\n  Events", "comments": "code URL typo, code is available at\n  https://github.com/hackerekcah/distinct-events-asc.git", "journal-ref": "Proc. Interspeech 2019, 3860-3864", "doi": "10.21437/Interspeech.2019-2231", "report-no": null, "categories": "cs.SD cs.LG eess.AS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we propose a new strategy for acoustic scene classification\n(ASC) , namely recognizing acoustic scenes through identifying distinct sound\nevents. This differs from existing strategies, which focus on characterizing\nglobal acoustical distributions of audio or the temporal evolution of\nshort-term audio features, without analysis down to the level of sound events.\nTo identify distinct sound events for each scene, we formulate ASC in a\nmulti-instance learning (MIL) framework, where each audio recording is mapped\ninto a bag-of-instances representation. Here, instances can be seen as\nhigh-level representations for sound events inside a scene. We also propose a\nMIL neural networks model, which implicitly identifies distinct instances\n(i.e., sound events). Furthermore, we propose two specially designed modules\nthat model the multi-temporal scale and multi-modal natures of the sound events\nrespectively. The experiments were conducted on the official development set of\nthe DCASE2018 Task1 Subtask B, and our best-performing model improves over the\nofficial baseline by 9.4% (68.3% vs 58.9%) in terms of classification accuracy.\nThis study indicates that recognizing acoustic scenes by identifying distinct\nsound events is effective and paves the way for future studies that combine\nthis strategy with previous ones.\n", "versions": [{"version": "v1", "created": "Wed, 10 Apr 2019 14:19:34 GMT"}, {"version": "v2", "created": "Sat, 27 Apr 2019 02:49:09 GMT"}], "update_date": "2019-10-23", "authors_parsed": [["Song", "Hongwei", ""], ["Han", "Jiqing", ""], ["Deng", "Shiwen", ""], ["Du", "Zhihao", ""]]}, {"id": "1904.05207", "submitter": "Arno Solin", "authors": "Arno Solin and Manon Kok", "title": "Know Your Boundaries: Constraining Gaussian Processes by Variational\n  Harmonic Features", "comments": "Appearing in Proceedings of AISTATS 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Gaussian processes (GPs) provide a powerful framework for extrapolation,\ninterpolation, and noise removal in regression and classification. This paper\nconsiders constraining GPs to arbitrarily-shaped domains with boundary\nconditions. We solve a Fourier-like generalised harmonic feature representation\nof the GP prior in the domain of interest, which both constrains the GP and\nattains a low-rank representation that is used for speeding up inference. The\nmethod scales as $\\mathcal{O}(nm^2)$ in prediction and $\\mathcal{O}(m^3)$ in\nhyperparameter learning for regression, where $n$ is the number of data points\nand $m$ the number of features. Furthermore, we make use of the variational\napproach to allow the method to deal with non-Gaussian likelihoods. The\nexperiments cover both simulated and empirical data in which the boundary\nconditions allow for inclusion of additional physical information.\n", "versions": [{"version": "v1", "created": "Wed, 10 Apr 2019 14:24:26 GMT"}], "update_date": "2019-04-11", "authors_parsed": [["Solin", "Arno", ""], ["Kok", "Manon", ""]]}, {"id": "1904.05233", "submitter": "Alexey Romanov", "authors": "Alexey Romanov, Maria De-Arteaga, Hanna Wallach, Jennifer Chayes,\n  Christian Borgs, Alexandra Chouldechova, Sahin Geyik, Krishnaram Kenthapadi,\n  Anna Rumshisky, Adam Tauman Kalai", "title": "What's in a Name? Reducing Bias in Bios without Access to Protected\n  Attributes", "comments": "Accepted at NAACL 2019; Best Thematic Paper", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CL stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  There is a growing body of work that proposes methods for mitigating bias in\nmachine learning systems. These methods typically rely on access to protected\nattributes such as race, gender, or age. However, this raises two significant\nchallenges: (1) protected attributes may not be available or it may not be\nlegal to use them, and (2) it is often desirable to simultaneously consider\nmultiple protected attributes, as well as their intersections. In the context\nof mitigating bias in occupation classification, we propose a method for\ndiscouraging correlation between the predicted probability of an individual's\ntrue occupation and a word embedding of their name. This method leverages the\nsocietal biases that are encoded in word embeddings, eliminating the need for\naccess to protected attributes. Crucially, it only requires access to\nindividuals' names at training time and not at deployment time. We evaluate two\nvariations of our proposed method using a large-scale dataset of online\nbiographies. We find that both variations simultaneously reduce race and gender\nbiases, with almost no reduction in the classifier's overall true positive\nrate.\n", "versions": [{"version": "v1", "created": "Wed, 10 Apr 2019 15:10:37 GMT"}], "update_date": "2019-04-11", "authors_parsed": [["Romanov", "Alexey", ""], ["De-Arteaga", "Maria", ""], ["Wallach", "Hanna", ""], ["Chayes", "Jennifer", ""], ["Borgs", "Christian", ""], ["Chouldechova", "Alexandra", ""], ["Geyik", "Sahin", ""], ["Kenthapadi", "Krishnaram", ""], ["Rumshisky", "Anna", ""], ["Kalai", "Adam Tauman", ""]]}, {"id": "1904.05247", "submitter": "Linus W. Dietz", "authors": "Rinita Roy and Linus W. Dietz", "title": "A Model for Using Physiological Conditions for Proactive Tourist\n  Recommendations", "comments": null, "journal-ref": "ABIS '2019 Proceedings of the 23rd International Workshop on\n  Personalization and Recommendation on the Web and Beyond", "doi": "10.1145/3345002.3349289", "report-no": null, "categories": "cs.HC cs.IR cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Mobile proactive tourist recommender systems can support tourists by\nrecommending the best choice depending on different contexts related to herself\nand the environment. In this paper, we propose to utilize wearable sensors to\ngather health information about a tourist and use them for recommending tourist\nactivities. We discuss a range of wearable devices, sensors to infer\nphysiological conditions of the users, and exemplify the feasibility using a\npopular self-quantification mobile app. Our main contribution then comprises a\ndata model to derive relations between the parameters measured by the wearable\nsensors, such as heart rate, body temperature, blood pressure, and use them to\ninfer the physiological condition of a user. This model can then be used to\nderive classes of tourist activities that determine which items should be\nrecommended.\n", "versions": [{"version": "v1", "created": "Wed, 10 Apr 2019 15:37:28 GMT"}], "update_date": "2019-12-17", "authors_parsed": [["Roy", "Rinita", ""], ["Dietz", "Linus W.", ""]]}, {"id": "1904.05250", "submitter": "Antonino Furnari", "authors": "Antonino Furnari, Sebastiano Battiato, Kristen Grauman, Giovanni Maria\n  Farinella", "title": "Next-Active-Object prediction from Egocentric Videos", "comments": null, "journal-ref": "Journal of Visual Communication and Image Representation, Volume\n  49, 2017, Pages 401-411, ISSN 1047-3203", "doi": "10.1016/j.jvcir.2017.10.004", "report-no": null, "categories": "cs.CV cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Although First Person Vision systems can sense the environment from the\nuser's perspective, they are generally unable to predict his intentions and\ngoals. Since human activities can be decomposed in terms of atomic actions and\ninteractions with objects, intelligent wearable systems would benefit from the\nability to anticipate user-object interactions. Even if this task is not\ntrivial, the First Person Vision paradigm can provide important cues to address\nthis challenge. We propose to exploit the dynamics of the scene to recognize\nnext-active-objects before an object interaction begins. We train a classifier\nto discriminate trajectories leading to an object activation from all others\nand forecast next-active-objects by analyzing fixed-length trajectory segments\nwithin a temporal sliding window. The proposed method compares favorably with\nrespect to several baselines on the Activity of Daily Living (ADL) egocentric\ndataset comprising 10 hours of videos acquired by 20 subjects while performing\nunconstrained interactions with several objects.\n", "versions": [{"version": "v1", "created": "Wed, 10 Apr 2019 15:39:19 GMT"}], "update_date": "2019-04-11", "authors_parsed": [["Furnari", "Antonino", ""], ["Battiato", "Sebastiano", ""], ["Grauman", "Kristen", ""], ["Farinella", "Giovanni Maria", ""]]}, {"id": "1904.05254", "submitter": "Hristo Inouzhe Valdes", "authors": "Eustasio del Barrio, Hristo Inouzhe, Jean-Michel Loubes", "title": "Attraction-Repulsion clustering with applications to fairness", "comments": "29 pages, 9 figures, 5 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In the framework of fair learning, we consider clustering methods that avoid\nor limit the influence of a set of protected attributes, $S$, (race, sex, etc)\nover the resulting clusters, with the goal of producing a {\\it fair\nclustering}. For this, we introduce perturbations to the Euclidean distance\nthat take into account $S$ in a way that resembles attraction-repulsion in\ncharged particles in Physics and results in dissimilarities with an easy\ninterpretation. Cluster analysis based on these dissimilarities penalizes\nhomogeneity of the clusters in the attributes $S$, and leads to an improvement\nin fairness. We illustrate the use of our procedures with both synthetic and\nreal data. Our procedures are implemented in an R package freely available at\nhttps://github.com/HristoInouzhe/AttractionRepulsionClustering.\n", "versions": [{"version": "v1", "created": "Wed, 10 Apr 2019 15:52:11 GMT"}, {"version": "v2", "created": "Fri, 21 Jun 2019 11:57:58 GMT"}, {"version": "v3", "created": "Wed, 29 Apr 2020 12:34:49 GMT"}], "update_date": "2020-04-30", "authors_parsed": [["del Barrio", "Eustasio", ""], ["Inouzhe", "Hristo", ""], ["Loubes", "Jean-Michel", ""]]}, {"id": "1904.05263", "submitter": "Lei Wu", "authors": "Weinan E, Chao Ma, Qingcan Wang, Lei Wu", "title": "Analysis of the Gradient Descent Algorithm for a Deep Neural Network\n  Model with Skip-connections", "comments": "29 pages, 4 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG math.OC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The behavior of the gradient descent (GD) algorithm is analyzed for a deep\nneural network model with skip-connections. It is proved that in the\nover-parametrized regime, for a suitable initialization, with high probability\nGD can find a global minimum exponentially fast. Generalization error estimates\nalong the GD path are also established. As a consequence, it is shown that when\nthe target function is in the reproducing kernel Hilbert space (RKHS) with a\nkernel defined by the initialization, there exist generalizable early-stopping\nsolutions along the GD path. In addition, it is also shown that the GD path is\nuniformly close to the functions given by the related random feature model.\nConsequently, in this \"implicit regularization\" setting, the deep neural\nnetwork model deteriorates to a random feature model. Our results hold for\nneural networks of any width larger than the input dimension.\n", "versions": [{"version": "v1", "created": "Wed, 10 Apr 2019 16:05:17 GMT"}, {"version": "v2", "created": "Thu, 11 Apr 2019 01:22:36 GMT"}, {"version": "v3", "created": "Sun, 14 Apr 2019 17:08:40 GMT"}], "update_date": "2019-04-16", "authors_parsed": [["E", "Weinan", ""], ["Ma", "Chao", ""], ["Wang", "Qingcan", ""], ["Wu", "Lei", ""]]}, {"id": "1904.05268", "submitter": "Iiris Sundin", "authors": "Iiris Sundin, Peter Schulam, Eero Siivola, Aki Vehtari, Suchi Saria,\n  Samuel Kaski", "title": "Active Learning for Decision-Making from Imbalanced Observational Data", "comments": "Published in Proceedings of the 36th International Conference on\n  Machine Learning (ICML) 2019. 15 pages (10 paper + 5 supplementary), 7\n  figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Machine learning can help personalized decision support by learning models to\npredict individual treatment effects (ITE). This work studies the reliability\nof prediction-based decision-making in a task of deciding which action $a$ to\ntake for a target unit after observing its covariates $\\tilde{x}$ and predicted\noutcomes $\\hat{p}(\\tilde{y} \\mid \\tilde{x}, a)$. An example case is\npersonalized medicine and the decision of which treatment to give to a patient.\nA common problem when learning these models from observational data is\nimbalance, that is, difference in treated/control covariate distributions,\nwhich is known to increase the upper bound of the expected ITE estimation\nerror. We propose to assess the decision-making reliability by estimating the\nITE model's Type S error rate, which is the probability of the model inferring\nthe sign of the treatment effect wrong. Furthermore, we use the estimated\nreliability as a criterion for active learning, in order to collect new\n(possibly expensive) observations, instead of making a forced choice based on\nunreliable predictions. We demonstrate the effectiveness of this\ndecision-making aware active learning in two decision-making tasks: in\nsimulated data with binary outcomes and in a medical dataset with synthetic and\ncontinuous treatment outcomes.\n", "versions": [{"version": "v1", "created": "Wed, 10 Apr 2019 16:10:32 GMT"}, {"version": "v2", "created": "Thu, 6 Jun 2019 12:21:44 GMT"}], "update_date": "2019-06-07", "authors_parsed": [["Sundin", "Iiris", ""], ["Schulam", "Peter", ""], ["Siivola", "Eero", ""], ["Vehtari", "Aki", ""], ["Saria", "Suchi", ""], ["Kaski", "Samuel", ""]]}, {"id": "1904.05290", "submitter": "Junhwa Hur", "authors": "Junhwa Hur and Stefan Roth", "title": "Iterative Residual Refinement for Joint Optical Flow and Occlusion\n  Estimation", "comments": "To appear in CVPR 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep learning approaches to optical flow estimation have seen rapid progress\nover the recent years. One common trait of many networks is that they refine an\ninitial flow estimate either through multiple stages or across the levels of a\ncoarse-to-fine representation. While leading to more accurate results, the\ndownside of this is an increased number of parameters. Taking inspiration from\nboth classical energy minimization approaches as well as residual networks, we\npropose an iterative residual refinement (IRR) scheme based on weight sharing\nthat can be combined with several backbone networks. It reduces the number of\nparameters, improves the accuracy, or even achieves both. Moreover, we show\nthat integrating occlusion prediction and bi-directional flow estimation into\nour IRR scheme can further boost the accuracy. Our full network achieves\nstate-of-the-art results for both optical flow and occlusion estimation across\nseveral standard datasets.\n", "versions": [{"version": "v1", "created": "Wed, 10 Apr 2019 16:50:38 GMT"}], "update_date": "2019-04-11", "authors_parsed": [["Hur", "Junhwa", ""], ["Roth", "Stefan", ""]]}, {"id": "1904.05308", "submitter": "Davy Weissenbacher", "authors": "Davy Weissenbacher, Abeed Sarker, Ari Klein, Karen O'Connor, Arjun\n  Magge Ranganatha, Graciela Gonzalez-Hernandez", "title": "Deep Neural Networks Ensemble for Detecting Medication Mentions in\n  Tweets", "comments": "This is a pre-copy-editing, author-produced PDF of an article\n  accepted for publication in JAMIA following peer review. The definitive\n  publisher-authenticated version is \"D. Weissenbacher, A. Sarker, A. Klein, K.\n  O'Connor, A. Magge, G. Gonzalez-Hernandez, Deep neural networks ensemble for\n  detecting medication mentions in tweets, Journal of the American Medical\n  Informatics Association, ocz156, 2019\"", "journal-ref": "Journal of the American Medical Informatics Association, ocz156,\n  2019", "doi": "10.1093/jamia/ocz156", "report-no": null, "categories": "cs.CL cs.IR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Objective: After years of research, Twitter posts are now recognized as an\nimportant source of patient-generated data, providing unique insights into\npopulation health. A fundamental step to incorporating Twitter data in\npharmacoepidemiological research is to automatically recognize medication\nmentions in tweets. Given that lexical searches for medication names may fail\ndue to misspellings or ambiguity with common words, we propose a more advanced\nmethod to recognize them. Methods: We present Kusuri, an Ensemble Learning\nclassifier, able to identify tweets mentioning drug products and dietary\nsupplements. Kusuri (\"medication\" in Japanese) is composed of two modules.\nFirst, four different classifiers (lexicon-based, spelling-variant-based,\npattern-based and one based on a weakly-trained neural network) are applied in\nparallel to discover tweets potentially containing medication names. Second, an\nensemble of deep neural networks encoding morphological, semantical and\nlong-range dependencies of important words in the tweets discovered is used to\nmake the final decision. Results: On a balanced (50-50) corpus of 15,005\ntweets, Kusuri demonstrated performances close to human annotators with 93.7%\nF1-score, the best score achieved thus far on this corpus. On a corpus made of\nall tweets posted by 113 Twitter users (98,959 tweets, with only 0.26%\nmentioning medications), Kusuri obtained 76.3% F1-score. There is not a prior\ndrug extraction system that compares running on such an extremely unbalanced\ndataset. Conclusion: The system identifies tweets mentioning drug names with\nperformance high enough to ensure its usefulness and ready to be integrated in\nlarger natural language processing systems.\n", "versions": [{"version": "v1", "created": "Wed, 10 Apr 2019 17:18:17 GMT"}, {"version": "v2", "created": "Mon, 30 Sep 2019 16:34:33 GMT"}], "update_date": "2019-10-01", "authors_parsed": [["Weissenbacher", "Davy", ""], ["Sarker", "Abeed", ""], ["Klein", "Ari", ""], ["O'Connor", "Karen", ""], ["Ranganatha", "Arjun Magge", ""], ["Gonzalez-Hernandez", "Graciela", ""]]}, {"id": "1904.05325", "submitter": "Shameem Puthiya Parambath Mr.", "authors": "Shameem A Puthiya Parambath, Nishant Vijayakumar, Sanjay Chawla", "title": "Risk Aware Ranking for Top-$k$ Recommendations", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SI cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Given an incomplete ratings data over a set of users and items, the\npreference completion problem aims to estimate a personalized total preference\norder over a subset of the items. In practical settings, a ranked list of\ntop-$k$ items from the estimated preference order is recommended to the end\nuser in the decreasing order of preference for final consumption. We analyze\nthis model and observe that such a ranking model results in suboptimal\nperformance when the payoff associated with the recommended items is different.\nWe propose a novel and very efficient algorithm for the preference ranking\nconsidering the uncertainty regarding the payoffs of the items. Once the\npreference scores for the users are obtained using any preference learning\nalgorithm, we show that ranking the items using a risk seeking utility function\nresults in the best ranking performance.\n", "versions": [{"version": "v1", "created": "Sun, 17 Mar 2019 08:01:26 GMT"}, {"version": "v2", "created": "Fri, 12 Apr 2019 19:34:36 GMT"}], "update_date": "2019-04-16", "authors_parsed": [["Parambath", "Shameem A Puthiya", ""], ["Vijayakumar", "Nishant", ""], ["Chawla", "Sanjay", ""]]}, {"id": "1904.05330", "submitter": "Arash Ali Amini", "authors": "Marina S. Paez, Arash A. Amini and Lizhen Lin", "title": "Hierarchical Stochastic Block Model for Community Detection in Multiplex\n  Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SI cs.LG stat.ME stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Multiplex networks have become increasingly more prevalent in many fields,\nand have emerged as a powerful tool for modeling the complexity of real\nnetworks. There is a critical need for developing inference models for\nmultiplex networks that can take into account potential dependencies across\ndifferent layers, particularly when the aim is community detection. We add to a\nlimited literature by proposing a novel and efficient Bayesian model for\ncommunity detection in multiplex networks. A key feature of our approach is the\nability to model varying communities at different network layers. In contrast,\nmany existing models assume the same communities for all layers. Moreover, our\nmodel automatically picks up the necessary number of communities at each layer\n(as validated by real data examples). This is appealing, since deciding the\nnumber of communities is a challenging aspect of community detection, and\nespecially so in the multiplex setting, if one allows the communities to change\nacross layers. Borrowing ideas from hierarchical Bayesian modeling, we use a\nhierarchical Dirichlet prior to model community labels across layers, allowing\ndependency in their structure. Given the community labels, a stochastic block\nmodel (SBM) is assumed for each layer. We develop an efficient slice sampler\nfor sampling the posterior distribution of the community labels as well as the\nlink probabilities between communities. In doing so, we address some unique\nchallenges posed by coupling the complex likelihood of SBM with the\nhierarchical nature of the prior on the labels. An extensive empirical\nvalidation is performed on simulated and real data, demonstrating the superior\nperformance of the model over single-layer alternatives, as well as the ability\nto uncover interesting structures in real networks.\n", "versions": [{"version": "v1", "created": "Sat, 30 Mar 2019 02:01:09 GMT"}], "update_date": "2019-04-11", "authors_parsed": [["Paez", "Marina S.", ""], ["Amini", "Arash A.", ""], ["Lin", "Lizhen", ""]]}, {"id": "1904.05332", "submitter": "Guilherme Gomes", "authors": "Guilherme Gomes, Vinayak Rao, Jennifer Neville", "title": "Community detection over a heterogeneous population of non-aligned\n  networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SI cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Clustering and community detection with multiple graphs have typically\nfocused on aligned graphs, where there is a mapping between nodes across the\ngraphs (e.g., multi-view, multi-layer, temporal graphs). However, there are\nnumerous application areas with multiple graphs that are only partially\naligned, or even unaligned. These graphs are often drawn from the same\npopulation, with communities of potentially different sizes that exhibit\nsimilar structure. In this paper, we develop a joint stochastic blockmodel\n(Joint SBM) to estimate shared communities across sets of heterogeneous\nnon-aligned graphs. We derive an efficient spectral clustering approach to\nlearn the parameters of the joint SBM. We evaluate the model on both synthetic\nand real-world datasets and show that the joint model is able to exploit\ncross-graph information to better estimate the communities compared to learning\nseparate SBMs on each individual graph.\n", "versions": [{"version": "v1", "created": "Thu, 4 Apr 2019 13:30:05 GMT"}], "update_date": "2019-04-11", "authors_parsed": [["Gomes", "Guilherme", ""], ["Rao", "Vinayak", ""], ["Neville", "Jennifer", ""]]}, {"id": "1904.05333", "submitter": "Francesco Sanna Passino", "authors": "Francesco Sanna Passino and Nicholas A. Heard", "title": "Bayesian estimation of the latent dimension and communities in\n  stochastic blockmodels", "comments": null, "journal-ref": "Statistics and Computing 30(5), 1291-1307 (2020)", "doi": "10.1007/s11222-020-09946-6", "report-no": null, "categories": "cs.SI cs.LG stat.AP stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Spectral embedding of adjacency or Laplacian matrices of undirected graphs is\na common technique for representing a network in a lower dimensional latent\nspace, with optimal theoretical guarantees. The embedding can be used to\nestimate the community structure of the network, with strong consistency\nresults in the stochastic blockmodel framework. One of the main practical\nlimitations of standard algorithms for community detection from spectral\nembeddings is that the number of communities and the latent dimension of the\nembedding must be specified in advance. In this article, a novel Bayesian model\nfor simultaneous and automatic selection of the appropriate dimension of the\nlatent space and the number of blocks is proposed. Extensions to directed and\nbipartite graphs are discussed. The model is tested on simulated and real world\nnetwork data, showing promising performance for recovering latent community\nstructure.\n", "versions": [{"version": "v1", "created": "Sat, 6 Apr 2019 08:22:15 GMT"}, {"version": "v2", "created": "Sat, 13 Apr 2019 09:55:51 GMT"}, {"version": "v3", "created": "Thu, 28 May 2020 08:54:28 GMT"}], "update_date": "2021-07-22", "authors_parsed": [["Passino", "Francesco Sanna", ""], ["Heard", "Nicholas A.", ""]]}, {"id": "1904.05335", "submitter": "Maoying Qiao", "authors": "Maoying Qiao, Jun Yu, Wei Bian, Qiang Li, Dacheng Tao", "title": "Adapting Stochastic Block Models to Power-Law Degree Distributions", "comments": "13 pages, 13 figures", "journal-ref": "IEEE Transactions on Cybernetics, 49 (2019) 626-637", "doi": "10.1109/TCYB.2017.2783325", "report-no": null, "categories": "cs.SI cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Stochastic block models (SBMs) have been playing an important role in\nmodeling clusters or community structures of network data. But, it is incapable\nof handling several complex features ubiquitously exhibited in real-world\nnetworks, one of which is the power-law degree characteristic. To this end, we\npropose a new variant of SBM, termed power-law degree SBM (PLD-SBM), by\nintroducing degree decay variables to explicitly encode the varying degree\ndistribution over all nodes. With an exponential prior, it is proved that\nPLD-SBM approximately preserves the scale-free feature in real networks. In\naddition, from the inference of variational E-Step, PLD-SBM is indeed to\ncorrect the bias inherited in SBM with the introduced degree decay factors.\nFurthermore, experiments conducted on both synthetic networks and two\nreal-world datasets including Adolescent Health Data and the political blogs\nnetwork verify the effectiveness of the proposed model in terms of cluster\nprediction accuracies.\n", "versions": [{"version": "v1", "created": "Fri, 5 Apr 2019 15:49:06 GMT"}], "update_date": "2019-04-11", "authors_parsed": [["Qiao", "Maoying", ""], ["Yu", "Jun", ""], ["Bian", "Wei", ""], ["Li", "Qiang", ""], ["Tao", "Dacheng", ""]]}, {"id": "1904.05338", "submitter": "Amin Jalali", "authors": "Amin Jalali, Adel Javanmard and Maryam Fazel", "title": "New Computational and Statistical Aspects of Regularized Regression with\n  Application to Rare Feature Selection and Aggregation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG math.OC math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Prior knowledge on properties of a target model often come as discrete or\ncombinatorial descriptions. This work provides a unified computational\nframework for defining norms that promote such structures. More specifically,\nwe develop associated tools for optimization involving such norms given only\nthe orthogonal projection oracle onto the non-convex set of desired models. As\nan example, we study a norm, which we term the doubly-sparse norm, for\npromoting vectors with few nonzero entries taking only a few distinct values.\nWe further discuss how the K-means algorithm can serve as the underlying\nprojection oracle in this case and how it can be efficiently represented as a\nquadratically constrained quadratic program. Our motivation for the study of\nthis norm is regularized regression in the presence of rare features which\nposes a challenge to various methods within high-dimensional statistics, and in\nmachine learning in general. The proposed estimation procedure is designed to\nperform automatic feature selection and aggregation for which we develop\nstatistical bounds. The bounds are general and offer a statistical framework\nfor norm-based regularization. The bounds rely on novel geometric quantities on\nwhich we attempt to elaborate as well.\n", "versions": [{"version": "v1", "created": "Wed, 10 Apr 2019 17:44:25 GMT"}], "update_date": "2019-04-11", "authors_parsed": [["Jalali", "Amin", ""], ["Javanmard", "Adel", ""], ["Fazel", "Maryam", ""]]}, {"id": "1904.05342", "submitter": "Kexin Huang", "authors": "Kexin Huang, Jaan Altosaar, Rajesh Ranganath", "title": "ClinicalBERT: Modeling Clinical Notes and Predicting Hospital\n  Readmission", "comments": "CHIL 2020 Workshop", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Clinical notes contain information about patients that goes beyond structured\ndata like lab values and medications. However, clinical notes have been\nunderused relative to structured data, because notes are high-dimensional and\nsparse. This work develops and evaluates representations of clinical notes\nusing bidirectional transformers (ClinicalBERT). ClinicalBERT uncovers\nhigh-quality relationships between medical concepts as judged by humans.\nClinicalBert outperforms baselines on 30-day hospital readmission prediction\nusing both discharge summaries and the first few days of notes in the intensive\ncare unit. Code and model parameters are available.\n", "versions": [{"version": "v1", "created": "Wed, 10 Apr 2019 17:53:13 GMT"}, {"version": "v2", "created": "Thu, 11 Apr 2019 16:51:52 GMT"}, {"version": "v3", "created": "Sun, 29 Nov 2020 03:40:45 GMT"}], "update_date": "2020-12-01", "authors_parsed": [["Huang", "Kexin", ""], ["Altosaar", "Jaan", ""], ["Ranganath", "Rajesh", ""]]}, {"id": "1904.05347", "submitter": "Mehdi Goli", "authors": "John Lawson, Mehdi Goli, Duncan McBain, Daniel Soutar, Louis Sugy", "title": "Cross-Platform Performance Portability Using Highly Parametrized SYCL\n  Kernels", "comments": "11 pages, 9 figures, 4 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.PF cs.DC cs.LG cs.MS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Over recent years heterogeneous systems have become more prevalent across HPC\nsystems, with over 100 supercomputers in the TOP500 incorporating GPUs or other\naccelerators. These hardware platforms have different performance\ncharacteristics and optimization requirements. In order to make the most of\nmultiple accelerators a developer has to provide implementations of their\nalgorithms tuned for each device. Hardware vendors provide libraries targeting\ntheir devices specifically, which provide good performance but frequently have\ndifferent API designs, hampering portability.\n  The SYCL programming model allows users to write heterogeneous programs using\ncompletely standard C++, and so developers have access to the power of C++\ntemplates when developing compute kernels. In this paper we show that by\nwriting highly parameterized kernels for matrix multiplies and convolutions we\nachieve performance competitive with vendor implementations across different\narchitectures. Furthermore, tuning for new devices amounts to choosing the\ncombinations of kernel parameters that perform best on the hardware.\n", "versions": [{"version": "v1", "created": "Wed, 10 Apr 2019 17:58:23 GMT"}], "update_date": "2019-04-11", "authors_parsed": [["Lawson", "John", ""], ["Goli", "Mehdi", ""], ["McBain", "Duncan", ""], ["Soutar", "Daniel", ""], ["Sugy", "Louis", ""]]}, {"id": "1904.05351", "submitter": "Yunchao He", "authors": "Yunchao He, Haitong Zhang, Yujun Wang", "title": "RawNet: Fast End-to-End Neural Vocoder", "comments": "Submitted to Interspeech 2019, Graz, Austria", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.AS cs.LG cs.SD stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Neural networks based vocoders have recently demonstrated the powerful\nability to synthesize high quality speech. These models usually generate\nsamples by conditioning on some spectrum features, such as Mel-spectrum.\nHowever, these features are extracted by using speech analysis module including\nsome processing based on the human knowledge. In this work, we proposed RawNet,\na truly end-to-end neural vocoder, which use a coder network to learn the\nhigher representation of signal, and an autoregressive voder network to\ngenerate speech sample by sample. The coder and voder together act like an\nauto-encoder network, and could be jointly trained directly on raw waveform\nwithout any human-designed features. The experiments on the Copy-Synthesis\ntasks show that RawNet can achieve the comparative synthesized speech quality\nwith LPCNet, with a smaller model architecture and faster speech generation at\nthe inference step.\n", "versions": [{"version": "v1", "created": "Wed, 10 Apr 2019 10:25:25 GMT"}], "update_date": "2019-04-12", "authors_parsed": [["He", "Yunchao", ""], ["Zhang", "Haitong", ""], ["Wang", "Yujun", ""]]}, {"id": "1904.05373", "submitter": "Hang Su", "authors": "Hang Su, Varun Jampani, Deqing Sun, Orazio Gallo, Erik Learned-Miller,\n  and Jan Kautz", "title": "Pixel-Adaptive Convolutional Neural Networks", "comments": "CVPR 2019. Video introduction: https://youtu.be/gsQZbHuR64o", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.GR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Convolutions are the fundamental building block of CNNs. The fact that their\nweights are spatially shared is one of the main reasons for their widespread\nuse, but it also is a major limitation, as it makes convolutions content\nagnostic. We propose a pixel-adaptive convolution (PAC) operation, a simple yet\neffective modification of standard convolutions, in which the filter weights\nare multiplied with a spatially-varying kernel that depends on learnable, local\npixel features. PAC is a generalization of several popular filtering techniques\nand thus can be used for a wide range of use cases. Specifically, we\ndemonstrate state-of-the-art performance when PAC is used for deep joint image\nupsampling. PAC also offers an effective alternative to fully-connected CRF\n(Full-CRF), called PAC-CRF, which performs competitively, while being\nconsiderably faster. In addition, we also demonstrate that PAC can be used as a\ndrop-in replacement for convolution layers in pre-trained networks, resulting\nin consistent performance improvements.\n", "versions": [{"version": "v1", "created": "Wed, 10 Apr 2019 18:02:54 GMT"}], "update_date": "2019-04-12", "authors_parsed": [["Su", "Hang", ""], ["Jampani", "Varun", ""], ["Sun", "Deqing", ""], ["Gallo", "Orazio", ""], ["Learned-Miller", "Erik", ""], ["Kautz", "Jan", ""]]}, {"id": "1904.05375", "submitter": "Daniel Moyer", "authors": "Daniel Moyer, Greg Ver Steeg, Chantal M. W. Tax, Paul M. Thompson", "title": "Scanner Invariant Representations for Diffusion MRI Harmonization", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.QM cs.LG eess.IV stat.AP stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Purpose: In the present work we describe the correction of diffusion-weighted\nMRI for site and scanner biases using a novel method based on invariant\nrepresentation.\n  Theory and Methods: Pooled imaging data from multiple sources are subject to\nvariation between the sources. Correcting for these biases has become very\nimportant as imaging studies increase in size and multi-site cases become more\ncommon. We propose learning an intermediate representation invariant to\nsite/protocol variables, a technique adapted from information theory-based\nalgorithmic fairness; by leveraging the data processing inequality, such a\nrepresentation can then be used to create an image reconstruction that is\nuninformative of its original source, yet still faithful to underlying\nstructures. To implement this, we use a deep learning method based on\nvariational auto-encoders (VAE) to construct scanner invariant encodings of the\nimaging data.\n  Results: To evaluate our method, we use training data from the 2018 MICCAI\nComputational Diffusion MRI (CDMRI) Challenge Harmonization dataset. Our\nproposed method shows improvements on independent test data relative to a\nrecently published baseline method on each subtask, mapping data from three\ndifferent scanning contexts to and from one separate target scanning context.\n  Conclusion: As imaging studies continue to grow, the use of pooled multi-site\nimaging will similarly increase. Invariant representation presents a strong\ncandidate for the harmonization of these data.\n", "versions": [{"version": "v1", "created": "Wed, 10 Apr 2019 18:10:19 GMT"}, {"version": "v2", "created": "Fri, 31 Jan 2020 19:11:39 GMT"}], "update_date": "2020-02-04", "authors_parsed": [["Moyer", "Daniel", ""], ["Steeg", "Greg Ver", ""], ["Tax", "Chantal M. W.", ""], ["Thompson", "Paul M.", ""]]}, {"id": "1904.05381", "submitter": "Xudong Sun", "authors": "Xudong Sun, Jiali Lin, Bernd Bischl", "title": "ReinBo: Machine Learning pipeline search and configuration with Bayesian\n  Optimization embedded Reinforcement Learning", "comments": null, "journal-ref": "ECML PKDD 2019: Machine Learning and Knowledge Discovery in\n  Databases pp 68-84", "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Machine learning pipeline potentially consists of several stages of\noperations like data preprocessing, feature engineering and machine learning\nmodel training. Each operation has a set of hyper-parameters, which can become\nirrelevant for the pipeline when the operation is not selected. This gives rise\nto a hierarchical conditional hyper-parameter space. To optimize this mixed\ncontinuous and discrete conditional hierarchical hyper-parameter space, we\npropose an efficient pipeline search and configuration algorithm which combines\nthe power of Reinforcement Learning and Bayesian Optimization. Empirical\nresults show that our method performs favorably compared to state of the art\nmethods like Auto-sklearn , TPOT, Tree Parzen Window, and Random Search.\n", "versions": [{"version": "v1", "created": "Wed, 10 Apr 2019 18:26:16 GMT"}], "update_date": "2021-05-04", "authors_parsed": [["Sun", "Xudong", ""], ["Lin", "Jiali", ""], ["Bischl", "Bernd", ""]]}, {"id": "1904.05384", "submitter": "Adamantios Ntakaris Mr", "authors": "Adamantios Ntakaris, Giorgio Mirone, Juho Kanniainen, Moncef Gabbouj,\n  Alexandros Iosifidis", "title": "Feature Engineering for Mid-Price Prediction with Deep Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "q-fin.ST cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Mid-price movement prediction based on limit order book (LOB) data is a\nchallenging task due to the complexity and dynamics of the LOB. So far, there\nhave been very limited attempts for extracting relevant features based on LOB\ndata. In this paper, we address this problem by designing a new set of\nhandcrafted features and performing an extensive experimental evaluation on\nboth liquid and illiquid stocks. More specifically, we implement a new set of\neconometrical features that capture statistical properties of the underlying\nsecurities for the task of mid-price prediction. Moreover, we develop a new\nexperimental protocol for online learning that treats the task as a\nmulti-objective optimization problem and predicts i) the direction of the next\nprice movement and ii) the number of order book events that occur until the\nchange takes place. In order to predict the mid-price movement, the features\nare fed into nine different deep learning models based on multi-layer\nperceptrons (MLP), convolutional neural networks (CNN) and long short-term\nmemory (LSTM) neural networks. The performance of the proposed method is then\nevaluated on liquid and illiquid stocks, which are based on TotalView-ITCH US\nand Nordic stocks, respectively. For some stocks, results suggest that the\ncorrect choice of a feature set and a model can lead to the successful\nprediction of how long it takes to have a stock price movement.\n", "versions": [{"version": "v1", "created": "Wed, 10 Apr 2019 18:40:20 GMT"}, {"version": "v2", "created": "Mon, 15 Apr 2019 12:08:54 GMT"}, {"version": "v3", "created": "Fri, 7 Jun 2019 19:07:22 GMT"}], "update_date": "2019-06-11", "authors_parsed": [["Ntakaris", "Adamantios", ""], ["Mirone", "Giorgio", ""], ["Kanniainen", "Juho", ""], ["Gabbouj", "Moncef", ""], ["Iosifidis", "Alexandros", ""]]}, {"id": "1904.05391", "submitter": "Mohamed Akrout", "authors": "Mohamed Akrout, Collin Wilson, Peter C. Humphreys, Timothy Lillicrap,\n  Douglas Tweed", "title": "Deep Learning without Weight Transport", "comments": "Accepted for the Conference on Neural Information Processing Systems\n  (NeurIPS) 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Current algorithms for deep learning probably cannot run in the brain because\nthey rely on weight transport, where forward-path neurons transmit their\nsynaptic weights to a feedback path, in a way that is likely impossible\nbiologically. An algorithm called feedback alignment achieves deep learning\nwithout weight transport by using random feedback weights, but it performs\npoorly on hard visual-recognition tasks. Here we describe two mechanisms - a\nneural circuit called a weight mirror and a modification of an algorithm\nproposed by Kolen and Pollack in 1994 - both of which let the feedback path\nlearn appropriate synaptic weights quickly and accurately even in large\nnetworks, without weight transport or complex wiring.Tested on the ImageNet\nvisual-recognition task, these mechanisms outperform both feedback alignment\nand the newer sign-symmetry method, and nearly match backprop, the standard\nalgorithm of deep learning, which uses weight transport.\n", "versions": [{"version": "v1", "created": "Wed, 10 Apr 2019 18:55:59 GMT"}, {"version": "v2", "created": "Tue, 16 Apr 2019 19:54:05 GMT"}, {"version": "v3", "created": "Fri, 31 May 2019 18:54:57 GMT"}, {"version": "v4", "created": "Sun, 27 Oct 2019 22:30:52 GMT"}, {"version": "v5", "created": "Thu, 9 Jan 2020 21:36:57 GMT"}], "update_date": "2020-01-13", "authors_parsed": [["Akrout", "Mohamed", ""], ["Wilson", "Collin", ""], ["Humphreys", "Peter C.", ""], ["Lillicrap", "Timothy", ""], ["Tweed", "Douglas", ""]]}, {"id": "1904.05394", "submitter": "Marco Huber", "authors": "Nina Schaaf, Marco F. Huber, and Johannes Maucher", "title": "Enhancing Decision Tree based Interpretation of Deep Neural Networks\n  through L1-Orthogonal Regularization", "comments": "8 pages, 18th IEEE International Conference on Machine Learning and\n  Applications (ICMLA) 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  One obstacle that so far prevents the introduction of machine learning models\nprimarily in critical areas is the lack of explainability. In this work, a\npracticable approach of gaining explainability of deep artificial neural\nnetworks (NN) using an interpretable surrogate model based on decision trees is\npresented. Simply fitting a decision tree to a trained NN usually leads to\nunsatisfactory results in terms of accuracy and fidelity. Using L1-orthogonal\nregularization during training, however, preserves the accuracy of the NN,\nwhile it can be closely approximated by small decision trees. Tests with\ndifferent data sets confirm that L1-orthogonal regularization yields models of\nlower complexity and at the same time higher fidelity compared to other\nregularizers.\n", "versions": [{"version": "v1", "created": "Wed, 10 Apr 2019 19:11:47 GMT"}, {"version": "v2", "created": "Thu, 3 Oct 2019 19:57:24 GMT"}], "update_date": "2019-10-07", "authors_parsed": [["Schaaf", "Nina", ""], ["Huber", "Marco F.", ""], ["Maucher", "Johannes", ""]]}, {"id": "1904.05404", "submitter": "Shuai Liao", "authors": "Shuai Liao, Efstratios Gavves, Cees G. M. Snoek", "title": "Spherical Regression: Learning Viewpoints, Surface Normals and 3D\n  Rotations on n-Spheres", "comments": "CVPR 2019 camera ready", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Many computer vision challenges require continuous outputs, but tend to be\nsolved by discrete classification. The reason is classification's natural\ncontainment within a probability $n$-simplex, as defined by the popular softmax\nactivation function. Regular regression lacks such a closed geometry, leading\nto unstable training and convergence to suboptimal local minima. Starting from\nthis insight we revisit regression in convolutional neural networks. We observe\nmany continuous output problems in computer vision are naturally contained in\nclosed geometrical manifolds, like the Euler angles in viewpoint estimation or\nthe normals in surface normal estimation. A natural framework for posing such\ncontinuous output problems are $n$-spheres, which are naturally closed\ngeometric manifolds defined in the $\\mathbb{R}^{(n+1)}$ space. By introducing a\nspherical exponential mapping on $n$-spheres at the regression output, we\nobtain well-behaved gradients, leading to stable training. We show how our\nspherical regression can be utilized for several computer vision challenges,\nspecifically viewpoint estimation, surface normal estimation and 3D rotation\nestimation. For all these problems our experiments demonstrate the benefit of\nspherical regression. All paper resources are available at\nhttps://github.com/leoshine/Spherical_Regression.\n", "versions": [{"version": "v1", "created": "Wed, 10 Apr 2019 19:33:59 GMT"}], "update_date": "2019-04-12", "authors_parsed": [["Liao", "Shuai", ""], ["Gavves", "Efstratios", ""], ["Snoek", "Cees G. M.", ""]]}, {"id": "1904.05406", "submitter": "Steffen Borgwardt", "authors": "Steffen Borgwardt and Charles Viss", "title": "Constructing Clustering Transformations", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.OC cs.LG math.CO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Clustering is one of the fundamental tasks in data analytics and machine\nlearning. In many situations, different clusterings of the same data set become\nrelevant. For example, different algorithms for the same clustering task may\nreturn dramatically different solutions. We are interested in applications in\nwhich one clustering has to be transformed into another; e.g., when a gradual\ntransition from an old solution to a new one is required. In this paper, we\ndevise methods for constructing such a transition based on linear programming\nand network theory. We use a so-called clustering-difference graph to model the\ndesired transformation and provide methods for decomposing the graph into a\nsequence of elementary moves that accomplishes the transformation. These moves\nare equivalent to the edge directions, or circuits, of the underlying partition\npolytopes. Therefore, in addition to a conceptually new metric for measuring\nthe distance between clusterings, we provide new bounds on the circuit diameter\nof these partition polytopes.\n", "versions": [{"version": "v1", "created": "Wed, 10 Apr 2019 19:44:34 GMT"}, {"version": "v2", "created": "Thu, 2 Apr 2020 18:14:17 GMT"}], "update_date": "2020-04-06", "authors_parsed": [["Borgwardt", "Steffen", ""], ["Viss", "Charles", ""]]}, {"id": "1904.05411", "submitter": "Ilia Sucholutsky", "authors": "Ilia Sucholutsky, Apurva Narayan, Matthias Schonlau, Sebastian\n  Fischmeister", "title": "Deep Learning for System Trace Restoration", "comments": "Pre-print (accepted to IJCNN 2019)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Most real-world datasets, and particularly those collected from physical\nsystems, are full of noise, packet loss, and other imperfections. However, most\nspecification mining, anomaly detection and other such algorithms assume, or\neven require, perfect data quality to function properly. Such algorithms may\nwork in lab conditions when given clean, controlled data, but will fail in the\nfield when given imperfect data. We propose a method for accurately\nreconstructing discrete temporal or sequential system traces affected by data\nloss, using Long Short-Term Memory Networks (LSTMs). The model works by\nlearning to predict the next event in a sequence of events, and uses its own\noutput as an input to continue predicting future events. As a result, this\nmethod can be used for data restoration even with streamed data. Such a method\ncan reconstruct even long sequence of missing events, and can also help\nvalidate and improve data quality for noisy data. The output of the model will\nbe a close reconstruction of the true data, and can be fed to algorithms that\nrely on clean data. We demonstrate our method by reconstructing automotive CAN\ntraces consisting of long sequences of discrete events. We show that given even\nsmall parts of a CAN trace, our LSTM model can predict future events with an\naccuracy of almost 90%, and can successfully reconstruct large portions of the\noriginal trace, greatly outperforming a Markov Model benchmark. We separately\nfeed the original, lossy, and reconstructed traces into a specification mining\nframework to perform downstream analysis of the effect of our method on\nstate-of-the-art models that use these traces for understanding the behavior of\ncomplex systems.\n", "versions": [{"version": "v1", "created": "Wed, 10 Apr 2019 19:53:20 GMT"}], "update_date": "2019-04-12", "authors_parsed": [["Sucholutsky", "Ilia", ""], ["Narayan", "Apurva", ""], ["Schonlau", "Matthias", ""], ["Fischmeister", "Sebastian", ""]]}, {"id": "1904.05417", "submitter": "Leah Bar", "authors": "Leah Bar and Nir Sochen", "title": "Unsupervised Deep Learning Algorithm for PDE-based Forward and Inverse\n  Problems", "comments": "15 pages, 11 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a neural network-based algorithm for solving forward and inverse\nproblems for partial differential equations in unsupervised fashion. The\nsolution is approximated by a deep neural network which is the minimizer of a\ncost function, and satisfies the PDE, boundary conditions, and additional\nregularizations. The method is mesh free and can be easily applied to an\narbitrary regular domain. We focus on 2D second order elliptical system with\nnon-constant coefficients, with application to Electrical Impedance Tomography.\n", "versions": [{"version": "v1", "created": "Wed, 10 Apr 2019 20:01:48 GMT"}], "update_date": "2019-04-12", "authors_parsed": [["Bar", "Leah", ""], ["Sochen", "Nir", ""]]}, {"id": "1904.05419", "submitter": "Will Epperson", "authors": "\\'Angel Alexander Cabrera, Will Epperson, Fred Hohman, Minsuk Kahng,\n  Jamie Morgenstern, Duen Horng Chau", "title": "FairVis: Visual Analytics for Discovering Intersectional Bias in Machine\n  Learning", "comments": "Accepted as a VAST conference paper to IEEE VIS'19", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The growing capability and accessibility of machine learning has led to its\napplication to many real-world domains and data about people. Despite the\nbenefits algorithmic systems may bring, models can reflect, inject, or\nexacerbate implicit and explicit societal biases into their outputs,\ndisadvantaging certain demographic subgroups. Discovering which biases a\nmachine learning model has introduced is a great challenge, due to the numerous\ndefinitions of fairness and the large number of potentially impacted subgroups.\nWe present FairVis, a mixed-initiative visual analytics system that integrates\na novel subgroup discovery technique for users to audit the fairness of machine\nlearning models. Through FairVis, users can apply domain knowledge to generate\nand investigate known subgroups, and explore suggested and similar subgroups.\nFairVis' coordinated views enable users to explore a high-level overview of\nsubgroup performance and subsequently drill down into detailed investigation of\nspecific subgroups. We show how FairVis helps to discover biases in two real\ndatasets used in predicting income and recidivism. As a visual analytics system\ndevoted to discovering bias in machine learning, FairVis demonstrates how\ninteractive visualization may help data scientists and the general public\nunderstand and create more equitable algorithmic systems.\n", "versions": [{"version": "v1", "created": "Wed, 10 Apr 2019 20:07:35 GMT"}, {"version": "v2", "created": "Wed, 31 Jul 2019 01:34:48 GMT"}, {"version": "v3", "created": "Thu, 1 Aug 2019 20:30:36 GMT"}, {"version": "v4", "created": "Sun, 1 Sep 2019 19:54:28 GMT"}], "update_date": "2019-09-04", "authors_parsed": [["Cabrera", "\u00c1ngel Alexander", ""], ["Epperson", "Will", ""], ["Hohman", "Fred", ""], ["Kahng", "Minsuk", ""], ["Morgenstern", "Jamie", ""], ["Chau", "Duen Horng", ""]]}, {"id": "1904.05421", "submitter": "Romain Aza\\\"is", "authors": "Romain Aza\\\"is and Florian Ingels", "title": "The Weight Function in the Subtree Kernel is Decisive", "comments": "36 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Tree data are ubiquitous because they model a large variety of situations,\ne.g., the architecture of plants, the secondary structure of RNA, or the\nhierarchy of XML files. Nevertheless, the analysis of these non-Euclidean data\nis difficult per se. In this paper, we focus on the subtree kernel that is a\nconvolution kernel for tree data introduced by Vishwanathan and Smola in the\nearly 2000's. More precisely, we investigate the influence of the weight\nfunction from a theoretical perspective and in real data applications. We\nestablish on a 2-classes stochastic model that the performance of the subtree\nkernel is improved when the weight of leaves vanishes, which motivates the\ndefinition of a new weight function, learned from the data and not fixed by the\nuser as usually done. To this end, we define a unified framework for computing\nthe subtree kernel from ordered or unordered trees, that is particularly\nsuitable for tuning parameters. We show through eight real data classification\nproblems the great efficiency of our approach, in particular for small\ndatasets, which also states the high importance of the weight function.\nFinally, a visualization tool of the significant features is derived.\n", "versions": [{"version": "v1", "created": "Wed, 10 Apr 2019 20:11:13 GMT"}, {"version": "v2", "created": "Thu, 21 Nov 2019 13:40:51 GMT"}, {"version": "v3", "created": "Tue, 25 Feb 2020 08:55:07 GMT"}, {"version": "v4", "created": "Wed, 15 Apr 2020 14:14:42 GMT"}], "update_date": "2020-04-16", "authors_parsed": [["Aza\u00efs", "Romain", ""], ["Ingels", "Florian", ""]]}, {"id": "1904.05426", "submitter": "Ronald Cardenas Acosta", "authors": "Ronald Cardenas, Ying Lin, Heng Ji, Jonathan May", "title": "A Grounded Unsupervised Universal Part-of-Speech Tagger for Low-Resource\n  Languages", "comments": "NAACL-HLT 2019, 12 pages, code available at\n  https://github.com/isi-nlp/universal-cipher-pos-tagging", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Unsupervised part of speech (POS) tagging is often framed as a clustering\nproblem, but practical taggers need to \\textit{ground} their clusters as well.\nGrounding generally requires reference labeled data, a luxury a low-resource\nlanguage might not have. In this work, we describe an approach for low-resource\nunsupervised POS tagging that yields fully grounded output and requires no\nlabeled training data. We find the classic method of Brown et al. (1992)\nclusters well in our use case and employ a decipherment-based approach to\ngrounding. This approach presumes a sequence of cluster IDs is a `ciphertext'\nand seeks a POS tag-to-cluster ID mapping that will reveal the POS sequence. We\nshow intrinsically that, despite the difficulty of the task, we obtain\nreasonable performance across a variety of languages. We also show\nextrinsically that incorporating our POS tagger into a name tagger leads to\nstate-of-the-art tagging performance in Sinhalese and Kinyarwanda, two\nlanguages with nearly no labeled POS data available. We further demonstrate our\ntagger's utility by incorporating it into a true `zero-resource' variant of the\nMalopa (Ammar et al., 2016) dependency parser model that removes the current\nreliance on multilingual resources and gold POS tags for new languages.\nExperiments show that including our tagger makes up much of the accuracy lost\nwhen gold POS tags are unavailable.\n", "versions": [{"version": "v1", "created": "Wed, 10 Apr 2019 20:22:31 GMT"}], "update_date": "2019-04-12", "authors_parsed": [["Cardenas", "Ronald", ""], ["Lin", "Ying", ""], ["Ji", "Heng", ""], ["May", "Jonathan", ""]]}, {"id": "1904.05440", "submitter": "Ashutosh Modi", "authors": "Yeyao Zhang, Eleftheria Tsipidi, Sasha Schriber, Mubbasir Kapadia,\n  Markus Gross, Ashutosh Modi", "title": "Generating Animations from Screenplays", "comments": "9+1+6 Pages, Accepted at StarSEM 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.GR cs.IR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Automatically generating animation from natural language text finds\napplication in a number of areas e.g. movie script writing, instructional\nvideos, and public safety. However, translating natural language text into\nanimation is a challenging task. Existing text-to-animation systems can handle\nonly very simple sentences, which limits their applications. In this paper, we\ndevelop a text-to-animation system which is capable of handling complex\nsentences. We achieve this by introducing a text simplification step into the\nprocess. Building on an existing animation generation system for screenwriting,\nwe create a robust NLP pipeline to extract information from screenplays and map\nthem to the system's knowledge base. We develop a set of linguistic\ntransformation rules that simplify complex sentences. Information extracted\nfrom the simplified sentences is used to generate a rough storyboard and video\ndepicting the text. Our sentence simplification module outperforms existing\nsystems in terms of BLEU and SARI metrics.We further evaluated our system via a\nuser study: 68 % participants believe that our system generates reasonable\nanimation from input screenplays.\n", "versions": [{"version": "v1", "created": "Wed, 10 Apr 2019 21:04:54 GMT"}], "update_date": "2019-04-12", "authors_parsed": [["Zhang", "Yeyao", ""], ["Tsipidi", "Eleftheria", ""], ["Schriber", "Sasha", ""], ["Kapadia", "Mubbasir", ""], ["Gross", "Markus", ""], ["Modi", "Ashutosh", ""]]}, {"id": "1904.05453", "submitter": "Yifei Xu", "authors": "Yifei Xu, Jianwen Xie, Tianyang Zhao, Chris Baker, Yibiao Zhao, and\n  Ying Nian Wu", "title": "Energy-Based Continuous Inverse Optimal Control", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The problem of continuous optimal control (over finite time horizon) is to\nminimize a given cost function over the sequence of continuous control\nvariables. The problem of continuous inverse optimal control is to learn the\nunknown cost function from expert demonstrations. In this article, we study\nthis fundamental problem in the framework of energy-based model, where the\nobserved expert trajectories are assumed to be random samples from a\nprobability density function defined as the exponential of the negative cost\nfunction up to a normalizing constant. The parameters of the cost function are\nlearned by maximum likelihood via an \"analysis by synthesis\" scheme, which\niterates the following two steps: (1) Synthesis step: sample the synthesized\ntrajectories from the current probability density using the Langevin dynamics\nvia back-propagation through time. (2) Analysis step: update the model\nparameters based on the statistical difference between the synthesized\ntrajectories and the observed trajectories. Given the fact that an efficient\noptimization algorithm is usually available for an optimal control problem, we\nalso consider a convenient approximation of the above learning method, where we\nreplace the sampling in the synthesis step by optimization. To make the\nsampling or optimization more efficient, we propose to train the energy-based\nmodel simultaneously with a top-down trajectory generator via cooperative\nlearning, where the trajectory generator is used to fast initialize the\nsampling step or optimization step of the energy-based model. We demonstrate\nthe proposed methods on autonomous driving tasks, and show that it can learn\nsuitable cost functions for optimal control.\n", "versions": [{"version": "v1", "created": "Wed, 10 Apr 2019 21:41:39 GMT"}, {"version": "v2", "created": "Thu, 12 Sep 2019 18:55:12 GMT"}, {"version": "v3", "created": "Wed, 22 Jan 2020 22:17:59 GMT"}, {"version": "v4", "created": "Sun, 1 Nov 2020 05:16:36 GMT"}, {"version": "v5", "created": "Fri, 22 Jan 2021 00:17:44 GMT"}], "update_date": "2021-01-25", "authors_parsed": [["Xu", "Yifei", ""], ["Xie", "Jianwen", ""], ["Zhao", "Tianyang", ""], ["Baker", "Chris", ""], ["Zhao", "Yibiao", ""], ["Wu", "Ying Nian", ""]]}, {"id": "1904.05460", "submitter": "Shane Barratt", "authors": "Shane Barratt and Stephen Boyd", "title": "Least Squares Auto-Tuning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.OC cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Least squares is by far the simplest and most commonly applied computational\nmethod in many fields. In almost all applications, the least squares objective\nis rarely the true objective. We account for this discrepancy by parametrizing\nthe least squares problem and automatically adjusting these parameters using an\noptimization algorithm. We apply our method, which we call least squares\nauto-tuning, to data fitting.\n", "versions": [{"version": "v1", "created": "Wed, 10 Apr 2019 21:53:33 GMT"}], "update_date": "2019-04-12", "authors_parsed": [["Barratt", "Shane", ""], ["Boyd", "Stephen", ""]]}, {"id": "1904.05488", "submitter": "Sean Tao", "authors": "Sean Tao", "title": "Deep Neural Network Ensembles", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Current deep neural networks suffer from two problems; first, they are hard\nto interpret, and second, they suffer from overfitting. There have been many\nattempts to define interpretability in neural networks, but they typically lack\ncausality or generality. A myriad of regularization techniques have been\ndeveloped to prevent overfitting, and this has driven deep learning to become\nthe hot topic it is today; however, while most regularization techniques are\njustified empirically and even intuitively, there is not much underlying\ntheory. This paper argues that to extract the features used in neural networks\nto make decisions, it's important to look at the paths between clusters\nexisting in the hidden spaces of neural networks. These features are of\nparticular interest because they reflect the true decision making process of\nthe neural network. This analysis is then furthered to present an ensemble\nalgorithm for arbitrary neural networks which has guarantees for test accuracy.\nFinally, a discussion detailing the aforementioned guarantees is introduced and\nthe implications to neural networks, including an intuitive explanation for all\ncurrent regularization methods, are presented. The ensemble algorithm has\ngenerated state-of-the-art results for Wide-ResNets on CIFAR-10 (top 5 for all\nmodels) and has improved test accuracy for all models it has been applied to.\n", "versions": [{"version": "v1", "created": "Thu, 11 Apr 2019 00:52:47 GMT"}, {"version": "v2", "created": "Tue, 13 Aug 2019 20:48:02 GMT"}], "update_date": "2019-08-15", "authors_parsed": [["Tao", "Sean", ""]]}, {"id": "1904.05506", "submitter": "Sorami Hisamoto", "authors": "Sorami Hisamoto, Matt Post, Kevin Duh", "title": "Membership Inference Attacks on Sequence-to-Sequence Models: Is My Data\n  In Your Machine Translation System?", "comments": null, "journal-ref": "Tansactions of the Association for Computational Linguistics\n  (TACL) Volume 8, 2020 p.49-63", "doi": "10.1162/tacl_a_00299", "report-no": null, "categories": "cs.LG cs.CL stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Data privacy is an important issue for \"machine learning as a service\"\nproviders. We focus on the problem of membership inference attacks: given a\ndata sample and black-box access to a model's API, determine whether the sample\nexisted in the model's training data. Our contribution is an investigation of\nthis problem in the context of sequence-to-sequence models, which are important\nin applications such as machine translation and video captioning. We define the\nmembership inference problem for sequence generation, provide an open dataset\nbased on state-of-the-art machine translation models, and report initial\nresults on whether these models leak private information against several kinds\nof membership inference attacks.\n", "versions": [{"version": "v1", "created": "Thu, 11 Apr 2019 02:53:21 GMT"}, {"version": "v2", "created": "Mon, 16 Mar 2020 10:27:24 GMT"}], "update_date": "2020-03-17", "authors_parsed": [["Hisamoto", "Sorami", ""], ["Post", "Matt", ""], ["Duh", "Kevin", ""]]}, {"id": "1904.05510", "submitter": "Shiva Kasiviswanathan", "authors": "Shiva Prasad Kasiviswanathan and Mark Rudelson", "title": "Restricted Isometry Property under High Correlations", "comments": "30 pages, fixed minor typos", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.DS stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Matrices satisfying the Restricted Isometry Property (RIP) play an important\nrole in the areas of compressed sensing and statistical learning. RIP matrices\nwith optimal parameters are mainly obtained via probabilistic arguments, as\nexplicit constructions seem hard. It is therefore interesting to ask whether a\nfixed matrix can be incorporated into a construction of restricted isometries.\nIn this paper, we construct a new broad ensemble of random matrices with\ndependent entries that satisfy the restricted isometry property. Our\nconstruction starts with a fixed (deterministic) matrix $X$ satisfying some\nsimple stable rank condition, and we show that the matrix $XR$, where $R$ is a\nrandom matrix drawn from various popular probabilistic models (including,\nsubgaussian, sparse, low-randomness, satisfying convex concentration property),\nsatisfies the RIP with high probability. These theorems have various\napplications in signal recovery, random matrix theory, dimensionality\nreduction, etc. Additionally, motivated by an application for understanding the\neffectiveness of word vector embeddings popular in natural language processing\nand machine learning applications, we investigate the RIP of the matrix\n$XR^{(l)}$ where $R^{(l)}$ is formed by taking all possible (disregarding\norder) $l$-way entrywise products of the columns of a random matrix $R$.\n", "versions": [{"version": "v1", "created": "Thu, 11 Apr 2019 03:14:48 GMT"}, {"version": "v2", "created": "Thu, 31 Oct 2019 17:34:19 GMT"}], "update_date": "2019-11-01", "authors_parsed": [["Kasiviswanathan", "Shiva Prasad", ""], ["Rudelson", "Mark", ""]]}, {"id": "1904.05514", "submitter": "Vishnu Naresh Boddeti", "authors": "Proteek Chandan Roy and Vishnu Naresh Boddeti", "title": "Mitigating Information Leakage in Image Representations: A Maximum\n  Entropy Approach", "comments": "Accepted for oral presentation at CVPR 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Image recognition systems have demonstrated tremendous progress over the past\nfew decades thanks, in part, to our ability of learning compact and robust\nrepresentations of images. As we witness the wide spread adoption of these\nsystems, it is imperative to consider the problem of unintended leakage of\ninformation from an image representation, which might compromise the privacy of\nthe data owner. This paper investigates the problem of learning an image\nrepresentation that minimizes such leakage of user information. We formulate\nthe problem as an adversarial non-zero sum game of finding a good embedding\nfunction with two competing goals: to retain as much task dependent\ndiscriminative image information as possible, while simultaneously minimizing\nthe amount of information, as measured by entropy, about other sensitive\nattributes of the user. We analyze the stability and convergence dynamics of\nthe proposed formulation using tools from non-linear systems theory and compare\nto that of the corresponding adversarial zero-sum game formulation that\noptimizes likelihood as a measure of information content. Numerical experiments\non UCI, Extended Yale B, CIFAR-10 and CIFAR-100 datasets indicate that our\nproposed approach is able to learn image representations that exhibit high task\nperformance while mitigating leakage of predefined sensitive information.\n", "versions": [{"version": "v1", "created": "Thu, 11 Apr 2019 03:34:27 GMT"}], "update_date": "2019-04-12", "authors_parsed": [["Roy", "Proteek Chandan", ""], ["Boddeti", "Vishnu Naresh", ""]]}, {"id": "1904.05521", "submitter": "Hao Wu", "authors": "Hao Wu, Jiayuan Mao, Yufeng Zhang, Yuning Jiang, Lei Li, Weiwei Sun,\n  Wei-Ying Ma", "title": "UniVSE: Robust Visual Semantic Embeddings via Structured Semantic\n  Representations", "comments": "v1 is the full version which is accepted by CVPR 2019. v2 is the\n  short version accepted by NAACL 2019 SpLU-RoboNLP workshop (in non-archival\n  proceedings)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose Unified Visual-Semantic Embeddings (UniVSE) for learning a joint\nspace of visual and textual concepts. The space unifies the concepts at\ndifferent levels, including objects, attributes, relations, and full scenes. A\ncontrastive learning approach is proposed for the fine-grained alignment from\nonly image-caption pairs. Moreover, we present an effective approach for\nenforcing the coverage of semantic components that appear in the sentence. We\ndemonstrate the robustness of Unified VSE in defending text-domain adversarial\nattacks on cross-modal retrieval tasks. Such robustness also empowers the use\nof visual cues to resolve word dependencies in novel sentences.\n", "versions": [{"version": "v1", "created": "Thu, 11 Apr 2019 04:04:06 GMT"}, {"version": "v2", "created": "Sun, 28 Apr 2019 03:21:28 GMT"}], "update_date": "2019-04-30", "authors_parsed": [["Wu", "Hao", ""], ["Mao", "Jiayuan", ""], ["Zhang", "Yufeng", ""], ["Jiang", "Yuning", ""], ["Li", "Lei", ""], ["Sun", "Weiwei", ""], ["Ma", "Wei-Ying", ""]]}, {"id": "1904.05526", "submitter": "Cong Ma", "authors": "Jianqing Fan, Cong Ma, Yiqiao Zhong", "title": "A Selective Overview of Deep Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG math.ST stat.ME stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep learning has arguably achieved tremendous success in recent years. In\nsimple words, deep learning uses the composition of many nonlinear functions to\nmodel the complex dependency between input features and labels. While neural\nnetworks have a long history, recent advances have greatly improved their\nperformance in computer vision, natural language processing, etc. From the\nstatistical and scientific perspective, it is natural to ask: What is deep\nlearning? What are the new characteristics of deep learning, compared with\nclassical methods? What are the theoretical foundations of deep learning? To\nanswer these questions, we introduce common neural network models (e.g.,\nconvolutional neural nets, recurrent neural nets, generative adversarial nets)\nand training techniques (e.g., stochastic gradient descent, dropout, batch\nnormalization) from a statistical point of view. Along the way, we highlight\nnew characteristics of deep learning (including depth and over-parametrization)\nand explain their practical and theoretical benefits. We also sample recent\nresults on theories of deep learning, many of which are only suggestive. While\na complete understanding of deep learning remains elusive, we hope that our\nperspectives and discussions serve as a stimulus for new statistical research.\n", "versions": [{"version": "v1", "created": "Wed, 10 Apr 2019 17:53:15 GMT"}, {"version": "v2", "created": "Mon, 15 Apr 2019 13:59:45 GMT"}], "update_date": "2019-04-16", "authors_parsed": [["Fan", "Jianqing", ""], ["Ma", "Cong", ""], ["Zhong", "Yiqiao", ""]]}, {"id": "1904.05530", "submitter": "Xiang Ren", "authors": "Woojeong Jin, Meng Qu, Xisen Jin, Xiang Ren", "title": "Recurrent Event Network: Autoregressive Structure Inference over\n  Temporal Knowledge Graphs", "comments": "15 pages, 8 figures, accepted at as full paper in EMNLP 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CL stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Knowledge graph reasoning is a critical task in natural language processing.\nThe task becomes more challenging on temporal knowledge graphs, where each fact\nis associated with a timestamp. Most existing methods focus on reasoning at\npast timestamps and they are not able to predict facts happening in the future.\nThis paper proposes Recurrent Event Network (RE-NET), a novel autoregressive\narchitecture for predicting future interactions. The occurrence of a fact\n(event) is modeled as a probability distribution conditioned on temporal\nsequences of past knowledge graphs. Specifically, our RE-NET employs a\nrecurrent event encoder to encode past facts and uses a neighborhood aggregator\nto model the connection of facts at the same timestamp. Future facts can then\nbe inferred in a sequential manner based on the two modules. We evaluate our\nproposed method via link prediction at future times on five public datasets.\nThrough extensive experiments, we demonstrate the strength of RENET, especially\non multi-step inference over future timestamps, and achieve state-of-the-art\nperformance on all five datasets. Code and data can be found at\nhttps://github.com/INK-USC/RE-Net.\n", "versions": [{"version": "v1", "created": "Thu, 11 Apr 2019 04:45:42 GMT"}, {"version": "v2", "created": "Tue, 4 Jun 2019 19:06:37 GMT"}, {"version": "v3", "created": "Tue, 8 Oct 2019 03:32:40 GMT"}, {"version": "v4", "created": "Tue, 6 Oct 2020 18:40:59 GMT"}], "update_date": "2020-10-08", "authors_parsed": [["Jin", "Woojeong", ""], ["Qu", "Meng", ""], ["Jin", "Xisen", ""], ["Ren", "Xiang", ""]]}, {"id": "1904.05538", "submitter": "Annie Xie", "authors": "Annie Xie, Frederik Ebert, Sergey Levine, Chelsea Finn", "title": "Improvisation through Physical Understanding: Using Novel Objects as\n  Tools with Visual Foresight", "comments": "Videos available at https://sites.google.com/view/gvf-tool", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Machine learning techniques have enabled robots to learn narrow, yet complex\ntasks and also perform broad, yet simple skills with a wide variety of objects.\nHowever, learning a model that can both perform complex tasks and generalize to\npreviously unseen objects and goals remains a significant challenge. We study\nthis challenge in the context of \"improvisational\" tool use: a robot is\npresented with novel objects and a user-specified goal (e.g., sweep some\nclutter into the dustpan), and must figure out, using only raw image\nobservations, how to accomplish the goal using the available objects as tools.\nWe approach this problem by training a model with both a visual and physical\nunderstanding of multi-object interactions, and develop a sampling-based\noptimizer that can leverage these interactions to accomplish tasks. We do so by\ncombining diverse demonstration data with self-supervised interaction data,\naiming to leverage the interaction data to build generalizable models and the\ndemonstration data to guide the model-based RL planner to solve complex tasks.\nOur experiments show that our approach can solve a variety of complex tool use\ntasks from raw pixel inputs, outperforming both imitation learning and\nself-supervised learning individually. Furthermore, we show that the robot can\nperceive and use novel objects as tools, including objects that are not\nconventional tools, while also choosing dynamically to use or not use tools\ndepending on whether or not they are required.\n", "versions": [{"version": "v1", "created": "Thu, 11 Apr 2019 05:20:57 GMT"}], "update_date": "2019-04-12", "authors_parsed": [["Xie", "Annie", ""], ["Ebert", "Frederik", ""], ["Levine", "Sergey", ""], ["Finn", "Chelsea", ""]]}, {"id": "1904.05548", "submitter": "Zilong Zheng", "authors": "Zilong Zheng, Wenguan Wang, Siyuan Qi, Song-Chun Zhu", "title": "Reasoning Visual Dialogs with Structural and Partial Observations", "comments": "CVPR 2019 Oral paper", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a novel model to address the task of Visual Dialog which exhibits\ncomplex dialog structures. To obtain a reasonable answer based on the current\nquestion and the dialog history, the underlying semantic dependencies between\ndialog entities are essential. In this paper, we explicitly formalize this task\nas inference in a graphical model with partially observed nodes and unknown\ngraph structures (relations in dialog). The given dialog entities are viewed as\nthe observed nodes. The answer to a given question is represented by a node\nwith missing value. We first introduce an Expectation Maximization algorithm to\ninfer both the underlying dialog structures and the missing node values\n(desired answers). Based on this, we proceed to propose a differentiable graph\nneural network (GNN) solution that approximates this process. Experiment\nresults on the VisDial and VisDial-Q datasets show that our model outperforms\ncomparative methods. It is also observed that our method can infer the\nunderlying dialog structure for better dialog reasoning.\n", "versions": [{"version": "v1", "created": "Thu, 11 Apr 2019 06:46:15 GMT"}, {"version": "v2", "created": "Tue, 28 May 2019 23:40:33 GMT"}], "update_date": "2019-05-30", "authors_parsed": [["Zheng", "Zilong", ""], ["Wang", "Wenguan", ""], ["Qi", "Siyuan", ""], ["Zhu", "Song-Chun", ""]]}, {"id": "1904.05576", "submitter": "Galina Lavrentyeva", "authors": "Galina Lavrentyeva, Sergey Novoselov, Andzhukaev Tseren, Marina\n  Volkova, Artem Gorlanov, Alexandr Kozlov", "title": "STC Antispoofing Systems for the ASVspoof2019 Challenge", "comments": "Submitted to Interspeech 2019, Graz, Austria", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SD cs.CL cs.CR cs.LG eess.AS stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper describes the Speech Technology Center (STC) antispoofing systems\nsubmitted to the ASVspoof 2019 challenge. The ASVspoof2019 is the extended\nversion of the previous challenges and includes 2 evaluation conditions:\nlogical access use-case scenario with speech synthesis and voice conversion\nattack types and physical access use-case scenario with replay attacks. During\nthe challenge we developed anti-spoofing solutions for both scenarios. The\nproposed systems are implemented using deep learning approach and are based on\ndifferent types of acoustic features. We enhanced Light CNN architecture\npreviously considered by the authors for replay attacks detection and which\nperformed high spoofing detection quality during the ASVspoof2017 challenge. In\nparticular here we investigate the efficiency of angular margin based softmax\nactivation for training robust deep Light CNN classifier to solve the\nmentioned-above tasks. Submitted systems achieved EER of 1.86% in logical\naccess scenario and 0.54% in physical access scenario on the evaluation part of\nthe Challenge corpora. High performance obtained for the unknown types of\nspoofing attacks demonstrates the stability of the offered approach in both\nevaluation conditions.\n", "versions": [{"version": "v1", "created": "Thu, 11 Apr 2019 08:37:43 GMT"}], "update_date": "2019-04-12", "authors_parsed": [["Lavrentyeva", "Galina", ""], ["Novoselov", "Sergey", ""], ["Tseren", "Andzhukaev", ""], ["Volkova", "Marina", ""], ["Gorlanov", "Artem", ""], ["Kozlov", "Alexandr", ""]]}, {"id": "1904.05606", "submitter": "Pavel Kral", "authors": "Ji\\v{r}\\'i Mart\\'inek, Pavel Kr\\'al, Ladislav Lenc, Christophe\n  Cerisara", "title": "Multi-lingual Dialogue Act Recognition with Deep Learning Methods", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper deals with multi-lingual dialogue act (DA) recognition. The\nproposed approaches are based on deep neural networks and use word2vec\nembeddings for word representation. Two multi-lingual models are proposed for\nthis task. The first approach uses one general model trained on the embeddings\nfrom all available languages. The second method trains the model on a single\npivot language and a linear transformation method is used to project other\nlanguages onto the pivot language. The popular convolutional neural network and\nLSTM architectures with different set-ups are used as classifiers. To the best\nof our knowledge this is the first attempt at multi-lingual DA recognition\nusing neural networks. The multi-lingual models are validated experimentally on\ntwo languages from the Verbmobil corpus.\n", "versions": [{"version": "v1", "created": "Thu, 11 Apr 2019 09:55:41 GMT"}], "update_date": "2019-04-12", "authors_parsed": [["Mart\u00ednek", "Ji\u0159\u00ed", ""], ["Kr\u00e1l", "Pavel", ""], ["Lenc", "Ladislav", ""], ["Cerisara", "Christophe", ""]]}, {"id": "1904.05619", "submitter": "Sarod Yatawatta", "authors": "Sarod Yatawatta, Lukas De Clercq, Hanno Spreeuw, Faruk Diblen", "title": "A Stochastic LBFGS Algorithm for Radio Interferometric Calibration", "comments": "Draft, final version in IEEE Data Science Workshop 2019 proceedings", "journal-ref": null, "doi": null, "report-no": null, "categories": "astro-ph.IM cs.LG math.OC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a stochastic, limited-memory Broyden Fletcher Goldfarb Shanno\n(LBFGS) algorithm that is suitable for handling very large amounts of data. A\ndirect application of this algorithm is radio interferometric calibration of\nraw data at fine time and frequency resolution. Almost all existing radio\ninterferometric calibration algorithms assume that it is possible to fit the\ndataset being calibrated into memory. Therefore, the raw data is averaged in\ntime and frequency to reduce its size by many orders of magnitude before\ncalibration is performed. However, this averaging is detrimental for the\ndetection of some signals of interest that have narrow bandwidth and time\nduration such as fast radio bursts (FRBs). Using the proposed algorithm, it is\npossible to calibrate data at such a fine resolution that they cannot be\nentirely loaded into memory, thus preserving such signals. As an additional\ndemonstration, we use the proposed algorithm for training deep neural networks\nand compare the performance against the mainstream first order optimization\nalgorithms that are used in deep learning.\n", "versions": [{"version": "v1", "created": "Thu, 11 Apr 2019 10:50:33 GMT"}, {"version": "v2", "created": "Sat, 13 Apr 2019 12:47:55 GMT"}], "update_date": "2019-04-16", "authors_parsed": [["Yatawatta", "Sarod", ""], ["De Clercq", "Lukas", ""], ["Spreeuw", "Hanno", ""], ["Diblen", "Faruk", ""]]}, {"id": "1904.05626", "submitter": "Conor Durkan", "authors": "Charlie Nash, Conor Durkan", "title": "Autoregressive Energy Machines", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Neural density estimators are flexible families of parametric models which\nhave seen widespread use in unsupervised machine learning in recent years.\nMaximum-likelihood training typically dictates that these models be constrained\nto specify an explicit density. However, this limitation can be overcome by\ninstead using a neural network to specify an energy function, or unnormalized\ndensity, which can subsequently be normalized to obtain a valid distribution.\nThe challenge with this approach lies in accurately estimating the normalizing\nconstant of the high-dimensional energy function. We propose the Autoregressive\nEnergy Machine, an energy-based model which simultaneously learns an\nunnormalized density and computes an importance-sampling estimate of the\nnormalizing constant for each conditional in an autoregressive decomposition.\nThe Autoregressive Energy Machine achieves state-of-the-art performance on a\nsuite of density-estimation tasks.\n", "versions": [{"version": "v1", "created": "Thu, 11 Apr 2019 11:11:01 GMT"}], "update_date": "2019-04-12", "authors_parsed": [["Nash", "Charlie", ""], ["Durkan", "Conor", ""]]}, {"id": "1904.05633", "submitter": "Charanjeet Singh", "authors": "Charanjeet, Anuj Sharma", "title": "Modified online Newton step based on element wise multiplication", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The second order method as Newton Step is a suitable technique in Online\nLearning to guarantee regret bound. The large data is a challenge in Newton\nmethod to store second order matrices as hessian. In this paper, we have\nproposed an modified online Newton step that store first and second order\nmatrices of dimension m (classes) by d (features). we have used element wise\narithmetic operation to retain matrices size same. The modified second order\nmatrix size results in faster computations. Also, the mistake rate is at par\nwith respect to popular methods in literature. The experiments outcome indicate\nthat proposed method could be helpful to handle large multi class datasets in\ncommon desktop machines using second order method as Newton step.\n", "versions": [{"version": "v1", "created": "Thu, 11 Apr 2019 11:26:41 GMT"}, {"version": "v2", "created": "Tue, 16 Apr 2019 03:35:55 GMT"}], "update_date": "2019-04-17", "authors_parsed": [["Charanjeet", "", ""], ["Sharma", "Anuj", ""]]}, {"id": "1904.05657", "submitter": "Brynjulf Owren", "authors": "Martin Benning and Elena Celledoni and Matthias J. Ehrhardt and\n  Brynjulf Owren and Carola-Bibiane Sch\\\"onlieb", "title": "Deep learning as optimal control problems: models and numerical methods", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.OC cs.LG cs.NA math.NA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider recent work of Haber and Ruthotto 2017 and Chang et al. 2018,\nwhere deep learning neural networks have been interpreted as discretisations of\nan optimal control problem subject to an ordinary differential equation\nconstraint. We review the first order conditions for optimality, and the\nconditions ensuring optimality after discretisation. This leads to a class of\nalgorithms for solving the discrete optimal control problem which guarantee\nthat the corresponding discrete necessary conditions for optimality are\nfulfilled. The differential equation setting lends itself to learning\nadditional parameters such as the time discretisation. We explore this\nextension alongside natural constraints (e.g. time steps lie in a simplex). We\ncompare these deep learning algorithms numerically in terms of induced flow and\ngeneralisation ability.\n", "versions": [{"version": "v1", "created": "Thu, 11 Apr 2019 12:15:00 GMT"}, {"version": "v2", "created": "Sun, 22 Sep 2019 17:28:02 GMT"}, {"version": "v3", "created": "Mon, 30 Sep 2019 21:33:06 GMT"}], "update_date": "2019-10-02", "authors_parsed": [["Benning", "Martin", ""], ["Celledoni", "Elena", ""], ["Ehrhardt", "Matthias J.", ""], ["Owren", "Brynjulf", ""], ["Sch\u00f6nlieb", "Carola-Bibiane", ""]]}, {"id": "1904.05658", "submitter": "Minseop Park", "authors": "Minseop Park, Jungtaek Kim, Saehoon Kim, Yanbin Liu, and Seungjin Choi", "title": "MxML: Mixture of Meta-Learners for Few-Shot Classification", "comments": "12 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A meta-model is trained on a distribution of similar tasks such that it\nlearns an algorithm that can quickly adapt to a novel task with only a handful\nof labeled examples. Most of current meta-learning methods assume that the\nmeta-training set consists of relevant tasks sampled from a single\ndistribution. In practice, however, a new task is often out of the task\ndistribution, yielding a performance degradation. One way to tackle this\nproblem is to construct an ensemble of meta-learners such that each\nmeta-learner is trained on different task distribution. In this paper we\npresent a method for constructing a mixture of meta-learners (MxML), where\nmixing parameters are determined by the weight prediction network (WPN)\noptimized to improve the few-shot classification performance. Experiments on\nvarious datasets demonstrate that MxML significantly outperforms\nstate-of-the-art meta-learners, or their naive ensemble in the case of\nout-of-distribution as well as in-distribution tasks.\n", "versions": [{"version": "v1", "created": "Thu, 11 Apr 2019 12:16:19 GMT"}], "update_date": "2019-04-12", "authors_parsed": [["Park", "Minseop", ""], ["Kim", "Jungtaek", ""], ["Kim", "Saehoon", ""], ["Liu", "Yanbin", ""], ["Choi", "Seungjin", ""]]}, {"id": "1904.05661", "submitter": "Paulo Hubert", "authors": "Paulo Hubert and Linilson Padovese", "title": "A machine learning approach for underwater gas leakage detection", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Underwater gas reservoirs are used in many situations. In particular, Carbon\nCapture and Storage (CCS) facilities that are currently being developed intend\nto store greenhouse gases inside geological formations in the deep sea. In\nthese formations, however, the gas might percolate, leaking back to the water\nand eventually to the atmosphere. The early detection of such leaks is\ntherefore tantamount to any underwater CCS project. In this work, we propose to\nuse Passive Acoustic Monitoring (PAM) and a machine learning approach to design\nefficient detectors that can signal the presence of a leakage. We use data\nobtained from simulation experiments off the Brazilian shore, and show that the\ndetection based on classification algorithms achieve good performance. We also\npropose a smoothing strategy based on Hidden Markov Models in order to\nincorporate previous knowledge about the probabilities of leakage occurrences.\n", "versions": [{"version": "v1", "created": "Thu, 11 Apr 2019 12:27:08 GMT"}], "update_date": "2019-04-12", "authors_parsed": [["Hubert", "Paulo", ""], ["Padovese", "Linilson", ""]]}, {"id": "1904.05674", "submitter": "Nikos Athanasiou", "authors": "Eleftheria Briakou, Nikos Athanasiou, Alexandros Potamianos", "title": "Cross-topic distributional semantic representations via unsupervised\n  mappings", "comments": "NAACL-HLT 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In traditional Distributional Semantic Models (DSMs) the multiple senses of a\npolysemous word are conflated into a single vector space representation. In\nthis work, we propose a DSM that learns multiple distributional representations\nof a word based on different topics. First, a separate DSM is trained for each\ntopic and then each of the topic-based DSMs is aligned to a common vector\nspace. Our unsupervised mapping approach is motivated by the hypothesis that\nwords preserving their relative distances in different topic semantic\nsub-spaces constitute robust \\textit{semantic anchors} that define the mappings\nbetween them. Aligned cross-topic representations achieve state-of-the-art\nresults for the task of contextual word similarity. Furthermore, evaluation on\nNLP downstream tasks shows that multiple topic-based embeddings outperform\nsingle-prototype models.\n", "versions": [{"version": "v1", "created": "Thu, 11 Apr 2019 13:09:57 GMT"}], "update_date": "2019-04-12", "authors_parsed": [["Briakou", "Eleftheria", ""], ["Athanasiou", "Nikos", ""], ["Potamianos", "Alexandros", ""]]}, {"id": "1904.05724", "submitter": "Hanan Hindy", "authors": "Hanan Hindy, David Brosset, Ethan Bayne, Amar Seeam and Xavier\n  Bellekens", "title": "Improving SIEM for Critical SCADA Water Infrastructures Using Machine\n  Learning", "comments": "17 pages, 8 figures, 4 tables. In the proceeding of International\n  Workshop on the Security of Industrial Control Systems and Cyber-Physical\n  Systems CyberICPS, In Conjunction With ESORICS 2018", "journal-ref": "Computer Security. SECPRE 2018, CyberICPS 2018. Lecture Notes in\n  Computer Science, vol 11387. Springer, Cham", "doi": "10.1007/978-3-030-12786-2_1", "report-no": null, "categories": "cs.CR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Network Control Systems (NAC) have been used in many industrial processes.\nThey aim to reduce the human factor burden and efficiently handle the complex\nprocess and communication of those systems. Supervisory control and data\nacquisition (SCADA) systems are used in industrial, infrastructure and facility\nprocesses (e.g. manufacturing, fabrication, oil and water pipelines, building\nventilation, etc.) Like other Internet of Things (IoT) implementations, SCADA\nsystems are vulnerable to cyber-attacks, therefore, a robust anomaly detection\nis a major requirement. However, having an accurate anomaly detection system is\nnot an easy task, due to the difficulty to differentiate between cyber-attacks\nand system internal failures (e.g. hardware failures). In this paper, we\npresent a model that detects anomaly events in a water system controlled by\nSCADA. Six Machine Learning techniques have been used in building and\nevaluating the model. The model classifies different anomaly events including\nhardware failures (e.g. sensor failures), sabotage and cyber-attacks (e.g. DoS\nand Spoofing). Unlike other detection systems, our proposed work focuses on\nnotifying the operator when an anomaly occurs with a probability of the event\noccurring. This additional information helps in accelerating the mitigation\nprocess. The model is trained and tested using a real-world dataset.\n", "versions": [{"version": "v1", "created": "Wed, 6 Mar 2019 12:59:01 GMT"}], "update_date": "2019-04-12", "authors_parsed": [["Hindy", "Hanan", ""], ["Brosset", "David", ""], ["Bayne", "Ethan", ""], ["Seeam", "Amar", ""], ["Bellekens", "Xavier", ""]]}, {"id": "1904.05732", "submitter": "Eric Weber", "authors": "Chinmay Hegde, Fritz Keinert, Eric S. Weber", "title": "A Kaczmarz Algorithm for Solving Tree Based Distributed Systems of\n  Equations", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.NA cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  The Kaczmarz algorithm is an iterative method for solving systems of linear\nequations. We introduce a modified Kaczmarz algorithm for solving systems of\nlinear equations in a distributed environment, i.e. the equations within the\nsystem are distributed over multiple nodes within a network. The modification\nwe introduce is designed for a network with a tree structure that allows for\npassage of solution estimates between the nodes in the network. We prove that\nthe modified algorithm converges under no additional assumptions on the\nequations. We demonstrate that the algorithm converges to the solution, or the\nsolution of minimal norm, when the system is consistent. We also demonstrate\nthat in the case of an inconsistent system of equations, the modified relaxed\nKaczmarz algorithm converges to a weighted least squares solution as the\nrelaxation parameter approaches $0$.\n", "versions": [{"version": "v1", "created": "Thu, 11 Apr 2019 14:43:24 GMT"}], "update_date": "2019-04-12", "authors_parsed": [["Hegde", "Chinmay", ""], ["Keinert", "Fritz", ""], ["Weber", "Eric S.", ""]]}, {"id": "1904.05734", "submitter": "Hadi Abdullah", "authors": "Hadi Abdullah, Washington Garcia, Christian Peeters, Patrick Traynor,\n  Kevin R. B. Butler and Joseph Wilson", "title": "Practical Hidden Voice Attacks against Speech and Speaker Recognition\n  Systems", "comments": null, "journal-ref": "The Network and Distributed System Security Symposium (NDSS) 2019", "doi": null, "report-no": null, "categories": "cs.CR cs.LG cs.SD eess.AS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Voice Processing Systems (VPSes), now widely deployed, have been made\nsignificantly more accurate through the application of recent advances in\nmachine learning. However, adversarial machine learning has similarly advanced\nand has been used to demonstrate that VPSes are vulnerable to the injection of\nhidden commands - audio obscured by noise that is correctly recognized by a VPS\nbut not by human beings. Such attacks, though, are often highly dependent on\nwhite-box knowledge of a specific machine learning model and limited to\nspecific microphones and speakers, making their use across different acoustic\nhardware platforms (and thus their practicality) limited. In this paper, we\nbreak these dependencies and make hidden command attacks more practical through\nmodel-agnostic (blackbox) attacks, which exploit knowledge of the signal\nprocessing algorithms commonly used by VPSes to generate the data fed into\nmachine learning systems. Specifically, we exploit the fact that multiple\nsource audio samples have similar feature vectors when transformed by acoustic\nfeature extraction algorithms (e.g., FFTs). We develop four classes of\nperturbations that create unintelligible audio and test them against 12 machine\nlearning models, including 7 proprietary models (e.g., Google Speech API, Bing\nSpeech API, IBM Speech API, Azure Speaker API, etc), and demonstrate successful\nattacks against all targets. Moreover, we successfully use our maliciously\ngenerated audio samples in multiple hardware configurations, demonstrating\neffectiveness across both models and real systems. In so doing, we demonstrate\nthat domain-specific knowledge of audio signal processing represents a\npractical means of generating successful hidden voice command attacks.\n", "versions": [{"version": "v1", "created": "Mon, 18 Mar 2019 20:10:13 GMT"}], "update_date": "2019-04-12", "authors_parsed": [["Abdullah", "Hadi", ""], ["Garcia", "Washington", ""], ["Peeters", "Christian", ""], ["Traynor", "Patrick", ""], ["Butler", "Kevin R. B.", ""], ["Wilson", "Joseph", ""]]}, {"id": "1904.05735", "submitter": "Ekram Hossain", "authors": "Fatima Hussain, Rasheed Hussain, Syed Ali Hassan, and Ekram Hossain", "title": "Machine Learning in IoT Security: Current Solutions and Future\n  Challenges", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The future Internet of Things (IoT) will have a deep economical, commercial\nand social impact on our lives. The participating nodes in IoT networks are\nusually resource-constrained, which makes them luring targets for cyber\nattacks. In this regard, extensive efforts have been made to address the\nsecurity and privacy issues in IoT networks primarily through traditional\ncryptographic approaches. However, the unique characteristics of IoT nodes\nrender the existing solutions insufficient to encompass the entire security\nspectrum of the IoT networks. This is, at least in part, because of the\nresource constraints, heterogeneity, massive real-time data generated by the\nIoT devices, and the extensively dynamic behavior of the networks. Therefore,\nMachine Learning (ML) and Deep Learning (DL) techniques, which are able to\nprovide embedded intelligence in the IoT devices and networks, are leveraged to\ncope with different security problems. In this paper, we systematically review\nthe security requirements, attack vectors, and the current security solutions\nfor the IoT networks. We then shed light on the gaps in these security\nsolutions that call for ML and DL approaches. We also discuss in detail the\nexisting ML and DL solutions for addressing different security problems in IoT\nnetworks. At last, based on the detailed investigation of the existing\nsolutions in the literature, we discuss the future research directions for ML-\nand DL-based IoT security.\n", "versions": [{"version": "v1", "created": "Thu, 14 Mar 2019 02:46:58 GMT"}], "update_date": "2019-04-12", "authors_parsed": [["Hussain", "Fatima", ""], ["Hussain", "Rasheed", ""], ["Hassan", "Syed Ali", ""], ["Hossain", "Ekram", ""]]}, {"id": "1904.05738", "submitter": "Farzam Fanitabasi", "authors": "Farzam Fanitabasi", "title": "TG-PSM: Tunable Greedy Packet Sequence Morphing Based on Trace\n  Clustering", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Common privacy enhancing technologies fail to effectively hide certain\nstatistical aspects of encrypted traffic, namely individual packets length,\npackets direction and, packets timing. Recent researches have shown that using\nsuch attributes, an adversary is able to extract various information from the\nencrypted traffic such as the visited website and used protocol. Such attacks\nare called traffic analysis. Proposed countermeasures attempt to change the\ndistribution of such features. however, either they fail to effectively reduce\nattacker's accuracy or do so while enforcing high bandwidth overhead and timing\ndelay. In this paper, through the use of a predefined set of clustered traces\nof websites and a greedy packet morphing algorithm, we introduce a website\nfingerprinting countermeasure called TG-PSM. Firstly, this method clusters\nwebsites based on their behavior in different phases of loading. Secondly, it\nfinds a suitable target site for any visiting website based on user indicated\nimportance degree; thus providing dynamic tunability. Thirdly, this method\nmorphs the given website to the target website using a greedy algorithm\nconsidering the distance and the resulted overhead. Our evaluations show that\nTG-PSM outperforms previous countermeasures regarding attacker accuracy\nreduction and enforced bandwidth, e.g., reducing bandwidth overhead over 40%\nwhile maintaining attacker's accuracy.\n", "versions": [{"version": "v1", "created": "Mon, 1 Apr 2019 12:29:44 GMT"}], "update_date": "2019-04-12", "authors_parsed": [["Fanitabasi", "Farzam", ""]]}, {"id": "1904.05742", "submitter": "Ju-Chieh Chou", "authors": "Ju-chieh Chou, Cheng-chieh Yeh, Hung-yi Lee", "title": "One-shot Voice Conversion by Separating Speaker and Content\n  Representations with Instance Normalization", "comments": "Interspeech 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.SD eess.AS stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recently, voice conversion (VC) without parallel data has been successfully\nadapted to multi-target scenario in which a single model is trained to convert\nthe input voice to many different speakers. However, such model suffers from\nthe limitation that it can only convert the voice to the speakers in the\ntraining data, which narrows down the applicable scenario of VC. In this paper,\nwe proposed a novel one-shot VC approach which is able to perform VC by only an\nexample utterance from source and target speaker respectively, and the source\nand target speaker do not even need to be seen during training. This is\nachieved by disentangling speaker and content representations with instance\nnormalization (IN). Objective and subjective evaluation shows that our model is\nable to generate the voice similar to target speaker. In addition to the\nperformance measurement, we also demonstrate that this model is able to learn\nmeaningful speaker representations without any supervision.\n", "versions": [{"version": "v1", "created": "Wed, 10 Apr 2019 16:22:18 GMT"}, {"version": "v2", "created": "Tue, 16 Apr 2019 14:40:52 GMT"}, {"version": "v3", "created": "Sat, 29 Jun 2019 13:42:03 GMT"}, {"version": "v4", "created": "Thu, 22 Aug 2019 17:18:16 GMT"}], "update_date": "2019-08-23", "authors_parsed": [["Chou", "Ju-chieh", ""], ["Yeh", "Cheng-chieh", ""], ["Lee", "Hung-yi", ""]]}, {"id": "1904.05746", "submitter": "Pramit Saha", "authors": "Pramit Saha, Muhammad Abdul-Mageed, Sidney Fels", "title": "SPEAK YOUR MIND! Towards Imagined Speech Recognition With Hierarchical\n  Deep Learning", "comments": "Under review in INTERSPEECH 2019. arXiv admin note: text overlap with\n  arXiv:1904.04358", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CL cs.SD eess.AS stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Speech-related Brain Computer Interface (BCI) technologies provide effective\nvocal communication strategies for controlling devices through speech commands\ninterpreted from brain signals. In order to infer imagined speech from active\nthoughts, we propose a novel hierarchical deep learning BCI system for\nsubject-independent classification of 11 speech tokens including phonemes and\nwords. Our novel approach exploits predicted articulatory information of six\nphonological categories (e.g., nasal, bilabial) as an intermediate step for\nclassifying the phonemes and words, thereby finding discriminative signal\nresponsible for natural speech synthesis. The proposed network is composed of\nhierarchical combination of spatial and temporal CNN cascaded with a deep\nautoencoder. Our best models on the KARA database achieve an average accuracy\nof 83.42% across the six different binary phonological classification tasks,\nand 53.36% for the individual token identification task, significantly\noutperforming our baselines. Ultimately, our work suggests the possible\nexistence of a brain imagery footprint for the underlying articulatory movement\nrelated to different sounds that can be used to aid imagined speech decoding.\n", "versions": [{"version": "v1", "created": "Mon, 8 Apr 2019 21:41:54 GMT"}], "update_date": "2019-04-12", "authors_parsed": [["Saha", "Pramit", ""], ["Abdul-Mageed", "Muhammad", ""], ["Fels", "Sidney", ""]]}, {"id": "1904.05747", "submitter": "Yonghong Huang Ph.D.", "authors": "Yonghong Huang, Utkarsh Verma, Celeste Fralick, Gabriel Infante-Lopez,\n  Brajesh Kumarz, Carl Woodward", "title": "Malware Evasion Attack and Defense", "comments": "Accepted by IEEE DSN-DSML2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Machine learning (ML) classifiers are vulnerable to adversarial examples. An\nadversarial example is an input sample which is slightly modified to induce\nmisclassification in an ML classifier. In this work, we investigate white-box\nand grey-box evasion attacks to an ML-based malware detector and conduct\nperformance evaluations in a real-world setting. We compare the defense\napproaches in mitigating the attacks. We propose a framework for deploying\ngrey-box and black-box attacks to malware detection systems.\n", "versions": [{"version": "v1", "created": "Sun, 7 Apr 2019 22:31:53 GMT"}, {"version": "v2", "created": "Tue, 16 Apr 2019 16:55:54 GMT"}], "update_date": "2019-04-17", "authors_parsed": [["Huang", "Yonghong", ""], ["Verma", "Utkarsh", ""], ["Fralick", "Celeste", ""], ["Infante-Lopez", "Gabriel", ""], ["Kumarz", "Brajesh", ""], ["Woodward", "Carl", ""]]}, {"id": "1904.05759", "submitter": "Pablo Hernandez-Leal", "authors": "Bilal Kartal, Pablo Hernandez-Leal, Chao Gao, and Matthew E. Taylor", "title": "Safer Deep RL with Shallow MCTS: A Case Study in Pommerman", "comments": "Adaptive Learning Agents (ALA) Workshop at AAMAS 2019. arXiv admin\n  note: substantial text overlap with arXiv:1812.00045", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.MA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Safe reinforcement learning has many variants and it is still an open\nresearch problem. Here, we focus on how to use action guidance by means of a\nnon-expert demonstrator to avoid catastrophic events in a domain with sparse,\ndelayed, and deceptive rewards: the recently-proposed multi-agent benchmark of\nPommerman. This domain is very challenging for reinforcement learning (RL) ---\npast work has shown that model-free RL algorithms fail to achieve significant\nlearning. In this paper, we shed light into the reasons behind this failure by\nexemplifying and analyzing the high rate of catastrophic events (i.e.,\nsuicides) that happen under random exploration in this domain. While model-free\nrandom exploration is typically futile, we propose a new framework where even a\nnon-expert simulated demonstrator, e.g., planning algorithms such as Monte\nCarlo tree search with small number of rollouts, can be integrated to\nasynchronous distributed deep reinforcement learning methods. Compared to\nvanilla deep RL algorithms, our proposed methods both learn faster and converge\nto better policies on a two-player mini version of the Pommerman game.\n", "versions": [{"version": "v1", "created": "Wed, 10 Apr 2019 14:34:40 GMT"}], "update_date": "2019-04-12", "authors_parsed": [["Kartal", "Bilal", ""], ["Hernandez-Leal", "Pablo", ""], ["Gao", "Chao", ""], ["Taylor", "Matthew E.", ""]]}, {"id": "1904.05760", "submitter": "Tinkle Chugh", "authors": "Tinkle Chugh", "title": "Scalarizing Functions in Bayesian Multiobjective Optimization", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Scalarizing functions have been widely used to convert a multiobjective\noptimization problem into a single objective optimization problem. However,\ntheir use in solving (computationally) expensive multi- and many-objective\noptimization problems in Bayesian multiobjective optimization is scarce.\nScalarizing functions can play a crucial role on the quality and number of\nevaluations required when doing the optimization. In this article, we study and\nreview 15 different scalarizing functions in the framework of Bayesian\nmultiobjective optimization and build Gaussian process models (as surrogates,\nmetamodels or emulators) on them. We use expected improvement as infill\ncriterion (or acquisition function) to update the models. In particular, we\ncompare different scalarizing functions and analyze their performance on\nseveral benchmark problems with different number of objectives to be optimized.\nThe review and experiments on different functions provide useful insights when\nusing and selecting a scalarizing function when using a Bayesian multiobjective\noptimization method.\n", "versions": [{"version": "v1", "created": "Thu, 11 Apr 2019 15:17:38 GMT"}], "update_date": "2019-04-12", "authors_parsed": [["Chugh", "Tinkle", ""]]}, {"id": "1904.05773", "submitter": "Kamran Kowsari", "authors": "Kamran Kowsari, Rasoul Sali, Marium N. Khan, William Adorno, S. Asad\n  Ali, Sean R. Moore, Beatrice C. Amadi, Paul Kelly, Sana Syed, Donald E. Brown", "title": "Diagnosis of Celiac Disease and Environmental Enteropathy on Biopsy\n  Images Using Color Balancing on Convolutional Neural Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.IV cs.CV cs.LG q-bio.QM stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Celiac Disease (CD) and Environmental Enteropathy (EE) are common causes of\nmalnutrition and adversely impact normal childhood development. CD is an\nautoimmune disorder that is prevalent worldwide and is caused by an increased\nsensitivity to gluten. Gluten exposure destructs the small intestinal\nepithelial barrier, resulting in nutrient mal-absorption and childhood\nunder-nutrition. EE also results in barrier dysfunction but is thought to be\ncaused by an increased vulnerability to infections. EE has been implicated as\nthe predominant cause of under-nutrition, oral vaccine failure, and impaired\ncognitive development in low-and-middle-income countries. Both conditions\nrequire a tissue biopsy for diagnosis, and a major challenge of interpreting\nclinical biopsy images to differentiate between these gastrointestinal diseases\nis striking histopathologic overlap between them. In the current study, we\npropose a convolutional neural network (CNN) to classify duodenal biopsy images\nfrom subjects with CD, EE, and healthy controls. We evaluated the performance\nof our proposed model using a large cohort containing 1000 biopsy images. Our\nevaluations show that the proposed model achieves an area under ROC of 0.99,\n1.00, and 0.97 for CD, EE, and healthy controls, respectively. These results\ndemonstrate the discriminative power of the proposed model in duodenal biopsies\nclassification.\n", "versions": [{"version": "v1", "created": "Wed, 10 Apr 2019 15:24:32 GMT"}, {"version": "v2", "created": "Wed, 24 Apr 2019 02:34:20 GMT"}, {"version": "v3", "created": "Thu, 13 Jun 2019 19:22:31 GMT"}, {"version": "v4", "created": "Fri, 4 Oct 2019 16:22:32 GMT"}, {"version": "v5", "created": "Wed, 9 Oct 2019 16:24:12 GMT"}], "update_date": "2020-12-08", "authors_parsed": [["Kowsari", "Kamran", ""], ["Sali", "Rasoul", ""], ["Khan", "Marium N.", ""], ["Adorno", "William", ""], ["Ali", "S. Asad", ""], ["Moore", "Sean R.", ""], ["Amadi", "Beatrice C.", ""], ["Kelly", "Paul", ""], ["Syed", "Sana", ""], ["Brown", "Donald E.", ""]]}, {"id": "1904.05777", "submitter": "Mirko Pieropan", "authors": "Alfredo Braunstein, Anna Paola Muntoni, Andrea Pagnani and Mirko\n  Pieropan", "title": "Compressed sensing reconstruction using Expectation Propagation", "comments": "20 pages, 6 figures", "journal-ref": null, "doi": "10.1088/1751-8121/ab3065", "report-no": null, "categories": "stat.ML cond-mat.dis-nn cond-mat.stat-mech cs.LG physics.comp-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Many interesting problems in fields ranging from telecommunications to\ncomputational biology can be formalized in terms of large underdetermined\nsystems of linear equations with additional constraints or regularizers. One of\nthe most studied ones, the Compressed Sensing problem (CS), consists in finding\nthe solution with the smallest number of non-zero components of a given system\nof linear equations $\\boldsymbol y = \\mathbf{F} \\boldsymbol{w}$ for known\nmeasurement vector $\\boldsymbol{y}$ and sensing matrix $\\mathbf{F}$. Here, we\nwill address the compressed sensing problem within a Bayesian inference\nframework where the sparsity constraint is remapped into a singular prior\ndistribution (called Spike-and-Slab or Bernoulli-Gauss). Solution to the\nproblem is attempted through the computation of marginal distributions via\nExpectation Propagation (EP), an iterative computational scheme originally\ndeveloped in Statistical Physics. We will show that this strategy is\ncomparatively more accurate than the alternatives in solving instances of CS\ngenerated from statistically correlated measurement matrices. For computational\nstrategies based on the Bayesian framework such as variants of Belief\nPropagation, this is to be expected, as they implicitly rely on the hypothesis\nof statistical independence among the entries of the sensing matrix. Perhaps\nsurprisingly, the method outperforms uniformly also all the other\nstate-of-the-art methods in our tests.\n", "versions": [{"version": "v1", "created": "Wed, 10 Apr 2019 15:45:32 GMT"}, {"version": "v2", "created": "Sat, 3 Aug 2019 22:20:39 GMT"}], "update_date": "2019-08-06", "authors_parsed": [["Braunstein", "Alfredo", ""], ["Muntoni", "Anna Paola", ""], ["Pagnani", "Andrea", ""], ["Pieropan", "Mirko", ""]]}, {"id": "1904.05801", "submitter": "Mingsheng Long", "authors": "Yuchen Zhang, Tianle Liu, Mingsheng Long, Michael I. Jordan", "title": "Bridging Theory and Algorithm for Domain Adaptation", "comments": "Proceedings of the 36th International Conference on Machine Learning,\n  Long Beach, California, PMLR 97, 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper addresses the problem of unsupervised domain adaption from\ntheoretical and algorithmic perspectives. Existing domain adaptation theories\nnaturally imply minimax optimization algorithms, which connect well with the\ndomain adaptation methods based on adversarial learning. However, several\ndisconnections still exist and form the gap between theory and algorithm. We\nextend previous theories (Mansour et al., 2009c; Ben-David et al., 2010) to\nmulticlass classification in domain adaptation, where classifiers based on the\nscoring functions and margin loss are standard choices in algorithm design. We\nintroduce Margin Disparity Discrepancy, a novel measurement with rigorous\ngeneralization bounds, tailored to the distribution comparison with the\nasymmetric margin loss, and to the minimax optimization for easier training.\nOur theory can be seamlessly transformed into an adversarial learning algorithm\nfor domain adaptation, successfully bridging the gap between theory and\nalgorithm. A series of empirical studies show that our algorithm achieves the\nstate of the art accuracies on challenging domain adaptation tasks.\n", "versions": [{"version": "v1", "created": "Thu, 11 Apr 2019 16:00:10 GMT"}, {"version": "v2", "created": "Mon, 22 Jul 2019 18:18:17 GMT"}], "update_date": "2019-07-24", "authors_parsed": [["Zhang", "Yuchen", ""], ["Liu", "Tianle", ""], ["Long", "Mingsheng", ""], ["Jordan", "Michael I.", ""]]}, {"id": "1904.05811", "submitter": "Dan Busbridge", "authors": "Dan Busbridge, Dane Sherburn, Pietro Cavallo and Nils Y. Hammerla", "title": "Relational Graph Attention Networks", "comments": "10 pages + 8 pages of appendices. Layer implementation available at\n  https://github.com/Babylonpartners/rgat/", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We investigate Relational Graph Attention Networks, a class of models that\nextends non-relational graph attention mechanisms to incorporate relational\ninformation, opening up these methods to a wider variety of problems. A\nthorough evaluation of these models is performed, and comparisons are made\nagainst established benchmarks. To provide a meaningful comparison, we retrain\nRelational Graph Convolutional Networks, the spectral counterpart of Relational\nGraph Attention Networks, and evaluate them under the same conditions. We find\nthat Relational Graph Attention Networks perform worse than anticipated,\nalthough some configurations are marginally beneficial for modelling molecular\nproperties. We provide insights as to why this may be, and suggest both\nmodifications to evaluation strategies, as well as directions to investigate\nfor future work.\n", "versions": [{"version": "v1", "created": "Thu, 11 Apr 2019 16:11:36 GMT"}], "update_date": "2019-04-12", "authors_parsed": [["Busbridge", "Dan", ""], ["Sherburn", "Dane", ""], ["Cavallo", "Pietro", ""], ["Hammerla", "Nils Y.", ""]]}, {"id": "1904.05814", "submitter": "Tolga Birdal", "authors": "Tolga Birdal and Umut \\c{S}im\\c{s}ekli", "title": "Probabilistic Permutation Synchronization using the Riemannian Structure\n  of the Birkhoff Polytope", "comments": "To appear as oral presentation at CVPR 2019. 20 pages including the\n  supplementary material", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.GR cs.LG cs.NA cs.RO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present an entirely new geometric and probabilistic approach to\nsynchronization of correspondences across multiple sets of objects or images.\nIn particular, we present two algorithms: (1) Birkhoff-Riemannian L-BFGS for\noptimizing the relaxed version of the combinatorially intractable cycle\nconsistency loss in a principled manner, (2) Birkhoff-Riemannian Langevin Monte\nCarlo for generating samples on the Birkhoff Polytope and estimating the\nconfidence of the found solutions. To this end, we first introduce the very\nrecently developed Riemannian geometry of the Birkhoff Polytope. Next, we\nintroduce a new probabilistic synchronization model in the form of a Markov\nRandom Field (MRF). Finally, based on the first order retraction operators, we\nformulate our problem as simulating a stochastic differential equation and\ndevise new integrators. We show on both synthetic and real datasets that we\nachieve high quality multi-graph matching results with faster convergence and\nreliable confidence/uncertainty estimates.\n", "versions": [{"version": "v1", "created": "Thu, 11 Apr 2019 16:12:50 GMT"}], "update_date": "2019-04-12", "authors_parsed": [["Birdal", "Tolga", ""], ["\u015eim\u015fekli", "Umut", ""]]}, {"id": "1904.05815", "submitter": "MArk Hoogendoorn", "authors": "Mark Hoogendoorn, Ward van Breda, and Jeroen Ruwaard", "title": "GP-HD: Using Genetic Programming to Generate Dynamical Systems Models\n  for Health Care", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The huge wealth of data in the health domain can be exploited to create\nmodels that predict development of health states over time. Temporal learning\nalgorithms are well suited to learn relationships between health states and\nmake predictions about their future developments. However, these algorithms:\n(1) either focus on learning one generic model for all patients, providing\ngeneral insights but often with limited predictive performance, or (2) learn\nindividualized models from which it is hard to derive generic concepts. In this\npaper, we present a middle ground, namely parameterized dynamical systems\nmodels that are generated from data using a Genetic Programming (GP) framework.\nA fitness function suitable for the health domain is exploited. An evaluation\nof the approach in the mental health domain shows that performance of the model\ngenerated by the GP is on par with a dynamical systems model developed based on\ndomain knowledge, significantly outperforms a generic Long Term Short Term\nMemory (LSTM) model and in some cases also outperforms an individualized LSTM\nmodel.\n", "versions": [{"version": "v1", "created": "Thu, 11 Apr 2019 16:13:22 GMT"}], "update_date": "2019-04-12", "authors_parsed": [["Hoogendoorn", "Mark", ""], ["van Breda", "Ward", ""], ["Ruwaard", "Jeroen", ""]]}, {"id": "1904.05822", "submitter": "Rahul Garg", "authors": "Rahul Garg, Neal Wadhwa, Sameer Ansari, Jonathan T. Barron", "title": "Learning Single Camera Depth Estimation using Dual-Pixels", "comments": "Accepted to ICCV 2019 (oral)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep learning techniques have enabled rapid progress in monocular depth\nestimation, but their quality is limited by the ill-posed nature of the problem\nand the scarcity of high quality datasets. We estimate depth from a single\ncamera by leveraging the dual-pixel auto-focus hardware that is increasingly\ncommon on modern camera sensors. Classic stereo algorithms and prior\nlearning-based depth estimation techniques under-perform when applied on this\ndual-pixel data, the former due to too-strong assumptions about RGB image\nmatching, and the latter due to not leveraging the understanding of optics of\ndual-pixel image formation. To allow learning based methods to work well on\ndual-pixel imagery, we identify an inherent ambiguity in the depth estimated\nfrom dual-pixel cues, and develop an approach to estimate depth up to this\nambiguity. Using our approach, existing monocular depth estimation techniques\ncan be effectively applied to dual-pixel data, and much smaller models can be\nconstructed that still infer high quality depth. To demonstrate this, we\ncapture a large dataset of in-the-wild 5-viewpoint RGB images paired with\ncorresponding dual-pixel data, and show how view supervision with this data can\nbe used to learn depth up to the unknown ambiguities. On our new task, our\nmodel is 30% more accurate than any prior work on learning-based monocular or\nstereoscopic depth estimation.\n", "versions": [{"version": "v1", "created": "Thu, 11 Apr 2019 16:25:43 GMT"}, {"version": "v2", "created": "Fri, 12 Apr 2019 01:19:03 GMT"}, {"version": "v3", "created": "Wed, 14 Aug 2019 17:52:05 GMT"}], "update_date": "2019-08-15", "authors_parsed": [["Garg", "Rahul", ""], ["Wadhwa", "Neal", ""], ["Ansari", "Sameer", ""], ["Barron", "Jonathan T.", ""]]}, {"id": "1904.05829", "submitter": "Kechen Qin", "authors": "Kechen Qin, Cheng Li, Virgil Pavlu, Javed A. Aslam", "title": "Adapting RNN Sequence Prediction Model to Multi-label Set Prediction", "comments": "Accepted to NAACL 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present an adaptation of RNN sequence models to the problem of multi-label\nclassification for text, where the target is a set of labels, not a sequence.\nPrevious such RNN models define probabilities for sequences but not for sets;\nattempts to obtain a set probability are after-thoughts of the network design,\nincluding pre-specifying the label order, or relating the sequence probability\nto the set probability in ad hoc ways.\n  Our formulation is derived from a principled notion of set probability, as\nthe sum of probabilities of corresponding permutation sequences for the set. We\nprovide a new training objective that maximizes this set probability, and a new\nprediction objective that finds the most probable set on a test document. These\nnew objectives are theoretically appealing because they give the RNN model\nfreedom to discover the best label order, which often is the natural one (but\ndifferent among documents).\n  We develop efficient procedures to tackle the computation difficulties\ninvolved in training and prediction. Experiments on benchmark datasets\ndemonstrate that we outperform state-of-the-art methods for this task.\n", "versions": [{"version": "v1", "created": "Thu, 11 Apr 2019 16:33:54 GMT"}], "update_date": "2019-04-12", "authors_parsed": [["Qin", "Kechen", ""], ["Li", "Cheng", ""], ["Pavlu", "Virgil", ""], ["Aslam", "Javed A.", ""]]}, {"id": "1904.05835", "submitter": "Zhenwen Dai", "authors": "Sungsoo Ahn, Shell Xu Hu, Andreas Damianou, Neil D. Lawrence, Zhenwen\n  Dai", "title": "Variational Information Distillation for Knowledge Transfer", "comments": "To appear at CVPR 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Transferring knowledge from a teacher neural network pretrained on the same\nor a similar task to a student neural network can significantly improve the\nperformance of the student neural network. Existing knowledge transfer\napproaches match the activations or the corresponding hand-crafted features of\nthe teacher and the student networks. We propose an information-theoretic\nframework for knowledge transfer which formulates knowledge transfer as\nmaximizing the mutual information between the teacher and the student networks.\nWe compare our method with existing knowledge transfer methods on both\nknowledge distillation and transfer learning tasks and show that our method\nconsistently outperforms existing methods. We further demonstrate the strength\nof our method on knowledge transfer across heterogeneous network architectures\nby transferring knowledge from a convolutional neural network (CNN) to a\nmulti-layer perceptron (MLP) on CIFAR-10. The resulting MLP significantly\noutperforms the-state-of-the-art methods and it achieves similar performance to\nthe CNN with a single convolutional layer.\n", "versions": [{"version": "v1", "created": "Thu, 11 Apr 2019 16:39:19 GMT"}], "update_date": "2019-04-12", "authors_parsed": [["Ahn", "Sungsoo", ""], ["Hu", "Shell Xu", ""], ["Damianou", "Andreas", ""], ["Lawrence", "Neil D.", ""], ["Dai", "Zhenwen", ""]]}, {"id": "1904.05856", "submitter": "Joseph Gaudio", "authors": "Joseph E. Gaudio, Travis E. Gibson, Anuradha M. Annaswamy, Michael A.\n  Bolender, Eugene Lavretsky", "title": "Connections Between Adaptive Control and Optimization in Machine\n  Learning", "comments": "18 pages", "journal-ref": null, "doi": "10.1109/CDC40024.2019.9029197", "report-no": null, "categories": "math.OC cs.LG cs.SY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper demonstrates many immediate connections between adaptive control\nand optimization methods commonly employed in machine learning. Starting from\ncommon output error formulations, similarities in update law modifications are\nexamined. Concepts in stability, performance, and learning, common to both\nfields are then discussed. Building on the similarities in update laws and\ncommon concepts, new intersections and opportunities for improved algorithm\nanalysis are provided. In particular, a specific problem related to higher\norder learning is solved through insights obtained from these intersections.\n", "versions": [{"version": "v1", "created": "Thu, 11 Apr 2019 17:23:41 GMT"}], "update_date": "2020-04-17", "authors_parsed": [["Gaudio", "Joseph E.", ""], ["Gibson", "Travis E.", ""], ["Annaswamy", "Anuradha M.", ""], ["Bolender", "Michael A.", ""], ["Lavretsky", "Eugene", ""]]}, {"id": "1904.05869", "submitter": "Oleh Rybkin", "authors": "Karl Pertsch, Oleh Rybkin, Jingyun Yang, Shenghao Zhou, Konstantinos\n  G. Derpanis, Kostas Daniilidis, Joseph Lim, Andrew Jaegle", "title": "Keyframing the Future: Keyframe Discovery for Visual Prediction and\n  Planning", "comments": "Conference on Learning for Dynamics and Control, 2020. Website:\n  https://sites.google.com/view/keyin/home", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Temporal observations such as videos contain essential information about the\ndynamics of the underlying scene, but they are often interleaved with\ninessential, predictable details. One way of dealing with this problem is by\nfocusing on the most informative moments in a sequence. We propose a model that\nlearns to discover these important events and the times when they occur and\nuses them to represent the full sequence. We do so using a hierarchical\nKeyframe-Inpainter (KeyIn) model that first generates a video's keyframes and\nthen inpaints the rest by generating the frames at the intervening times. We\npropose a fully differentiable formulation to efficiently learn this procedure.\nWe show that KeyIn finds informative keyframes in several datasets with\ndifferent dynamics and visual properties. KeyIn outperforms other recent\nhierarchical predictive models for planning. For more details, please see the\nproject website at \\url{https://sites.google.com/view/keyin}.\n", "versions": [{"version": "v1", "created": "Thu, 11 Apr 2019 17:55:09 GMT"}, {"version": "v2", "created": "Fri, 8 May 2020 00:53:23 GMT"}], "update_date": "2020-05-11", "authors_parsed": [["Pertsch", "Karl", ""], ["Rybkin", "Oleh", ""], ["Yang", "Jingyun", ""], ["Zhou", "Shenghao", ""], ["Derpanis", "Konstantinos G.", ""], ["Daniilidis", "Kostas", ""], ["Lim", "Joseph", ""], ["Jaegle", "Andrew", ""]]}, {"id": "1904.05873", "submitter": "Jifeng Dai", "authors": "Xizhou Zhu, Dazhi Cheng, Zheng Zhang, Stephen Lin, Jifeng Dai", "title": "An Empirical Study of Spatial Attention Mechanisms in Deep Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Attention mechanisms have become a popular component in deep neural networks,\nyet there has been little examination of how different influencing factors and\nmethods for computing attention from these factors affect performance. Toward a\nbetter general understanding of attention mechanisms, we present an empirical\nstudy that ablates various spatial attention elements within a generalized\nattention formulation, encompassing the dominant Transformer attention as well\nas the prevalent deformable convolution and dynamic convolution modules.\nConducted on a variety of applications, the study yields significant findings\nabout spatial attention in deep networks, some of which run counter to\nconventional understanding. For example, we find that the query and key content\ncomparison in Transformer attention is negligible for self-attention, but vital\nfor encoder-decoder attention. A proper combination of deformable convolution\nwith key content only saliency achieves the best accuracy-efficiency tradeoff\nin self-attention. Our results suggest that there exists much room for\nimprovement in the design of attention mechanisms.\n", "versions": [{"version": "v1", "created": "Thu, 11 Apr 2019 17:58:37 GMT"}], "update_date": "2019-04-15", "authors_parsed": [["Zhu", "Xizhou", ""], ["Cheng", "Dazhi", ""], ["Zhang", "Zheng", ""], ["Lin", "Stephen", ""], ["Dai", "Jifeng", ""]]}, {"id": "1904.05876", "submitter": "Idan Schwartz", "authors": "Idan Schwartz, Alexander Schwing and Tamir Hazan", "title": "A Simple Baseline for Audio-Visual Scene-Aware Dialog", "comments": "Accepted to CVPR 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.CL cs.LG cs.SD eess.AS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The recently proposed audio-visual scene-aware dialog task paves the way to a\nmore data-driven way of learning virtual assistants, smart speakers and car\nnavigation systems. However, very little is known to date about how to\neffectively extract meaningful information from a plethora of sensors that\npound the computational engine of those devices. Therefore, in this paper, we\nprovide and carefully analyze a simple baseline for audio-visual scene-aware\ndialog which is trained end-to-end. Our method differentiates in a data-driven\nmanner useful signals from distracting ones using an attention mechanism. We\nevaluate the proposed approach on the recently introduced and challenging\naudio-visual scene-aware dataset, and demonstrate the key features that permit\nto outperform the current state-of-the-art by more than 20\\% on CIDEr.\n", "versions": [{"version": "v1", "created": "Thu, 11 Apr 2019 17:59:51 GMT"}], "update_date": "2019-04-12", "authors_parsed": [["Schwartz", "Idan", ""], ["Schwing", "Alexander", ""], ["Hazan", "Tamir", ""]]}, {"id": "1904.05877", "submitter": "Yuan-Ting Hu", "authors": "Ishan Deshpande, Yuan-Ting Hu, Ruoyu Sun, Ayis Pyrros, Nasir Siddiqui,\n  Sanmi Koyejo, Zhizhen Zhao, David Forsyth, Alexander Schwing", "title": "Max-Sliced Wasserstein Distance and its use for GANs", "comments": "Accepted to CVPR 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Generative adversarial nets (GANs) and variational auto-encoders have\nsignificantly improved our distribution modeling capabilities, showing promise\nfor dataset augmentation, image-to-image translation and feature learning.\nHowever, to model high-dimensional distributions, sequential training and\nstacked architectures are common, increasing the number of tunable\nhyper-parameters as well as the training time. Nonetheless, the sample\ncomplexity of the distance metrics remains one of the factors affecting GAN\ntraining. We first show that the recently proposed sliced Wasserstein distance\nhas compelling sample complexity properties when compared to the Wasserstein\ndistance. To further improve the sliced Wasserstein distance we then analyze\nits `projection complexity' and develop the max-sliced Wasserstein distance\nwhich enjoys compelling sample complexity while reducing projection complexity,\nalbeit necessitating a max estimation. We finally illustrate that the proposed\ndistance trains GANs on high-dimensional images up to a resolution of 256x256\neasily.\n", "versions": [{"version": "v1", "created": "Thu, 11 Apr 2019 17:59:57 GMT"}], "update_date": "2019-04-12", "authors_parsed": [["Deshpande", "Ishan", ""], ["Hu", "Yuan-Ting", ""], ["Sun", "Ruoyu", ""], ["Pyrros", "Ayis", ""], ["Siddiqui", "Nasir", ""], ["Koyejo", "Sanmi", ""], ["Zhao", "Zhizhen", ""], ["Forsyth", "David", ""], ["Schwing", "Alexander", ""]]}, {"id": "1904.05878", "submitter": "Iou-Jen Liu", "authors": "Iou-Jen Liu and Jian Peng and Alexander G. Schwing", "title": "Knowledge Flow: Improve Upon Your Teachers", "comments": "Accepted to ICLR 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A zoo of deep nets is available these days for almost any given task, and it\nis increasingly unclear which net to start with when addressing a new task, or\nwhich net to use as an initialization for fine-tuning a new model. To address\nthis issue, in this paper, we develop knowledge flow which moves 'knowledge'\nfrom multiple deep nets, referred to as teachers, to a new deep net model,\ncalled the student. The structure of the teachers and the student can differ\narbitrarily and they can be trained on entirely different tasks with different\noutput spaces too. Upon training with knowledge flow the student is independent\nof the teachers. We demonstrate our approach on a variety of supervised and\nreinforcement learning tasks, outperforming fine-tuning and other 'knowledge\nexchange' methods.\n", "versions": [{"version": "v1", "created": "Thu, 11 Apr 2019 17:59:57 GMT"}], "update_date": "2019-04-12", "authors_parsed": [["Liu", "Iou-Jen", ""], ["Peng", "Jian", ""], ["Schwing", "Alexander G.", ""]]}, {"id": "1904.05880", "submitter": "Idan Schwartz", "authors": "Idan Schwartz and Seunghak Yu and Tamir Hazan and Alexander Schwing", "title": "Factor Graph Attention", "comments": "Accepted to CVPR 2019; revised version includes bottom-up features", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.CL cs.IR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Dialog is an effective way to exchange information, but subtle details and\nnuances are extremely important. While significant progress has paved a path to\naddress visual dialog with algorithms, details and nuances remain a challenge.\nAttention mechanisms have demonstrated compelling results to extract details in\nvisual question answering and also provide a convincing framework for visual\ndialog due to their interpretability and effectiveness. However, the many data\nutilities that accompany visual dialog challenge existing attention techniques.\nWe address this issue and develop a general attention mechanism for visual\ndialog which operates on any number of data utilities. To this end, we design a\nfactor graph based attention mechanism which combines any number of utility\nrepresentations. We illustrate the applicability of the proposed approach on\nthe challenging and recently introduced VisDial datasets, outperforming recent\nstate-of-the-art methods by 1.1% for VisDial0.9 and by 2% for VisDial1.0 on\nMRR. Our ensemble model improved the MRR score on VisDial1.0 by more than 6%.\n", "versions": [{"version": "v1", "created": "Thu, 11 Apr 2019 17:59:58 GMT"}, {"version": "v2", "created": "Sat, 3 Aug 2019 20:05:12 GMT"}, {"version": "v3", "created": "Sat, 7 Mar 2020 23:35:13 GMT"}], "update_date": "2020-03-10", "authors_parsed": [["Schwartz", "Idan", ""], ["Yu", "Seunghak", ""], ["Hazan", "Tamir", ""], ["Schwing", "Alexander", ""]]}, {"id": "1904.05902", "submitter": "Dmitry Yudin", "authors": "Adriano Macarone Palmieri, Egor Kovlakov, Federico Bianchi, Dmitry\n  Yudin, Stanislav Straupe, Jacob Biamonte, Sergei Kulik", "title": "Experimental neural network enhanced quantum tomography", "comments": "11 pages, 3+6 figures; All data and source code are available online;\n  RevTeX", "journal-ref": "npj Quantum Information 6:20 (2020)", "doi": "10.1038/s41534-020-0248-6", "report-no": null, "categories": "quant-ph cond-mat.dis-nn cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Quantum tomography is currently ubiquitous for testing any implementation of\na quantum information processing device. Various sophisticated procedures for\nstate and process reconstruction from measured data are well developed and\nbenefit from precise knowledge of the model describing state preparation and\nthe measurement apparatus. However, physical models suffer from intrinsic\nlimitations as actual measurement operators and trial states cannot be known\nprecisely. This scenario inevitably leads to state-preparation-and-measurement\n(SPAM) errors degrading reconstruction performance. Here we develop and\nexperimentally implement a machine learning based protocol reducing SPAM\nerrors. We trained a supervised neural network to filter the experimental data\nand hence uncovered salient patterns that characterize the measurement\nprobabilities for the original state and the ideal experimental apparatus free\nfrom SPAM errors. We compared the neural network state reconstruction protocol\nwith a protocol treating SPAM errors by process tomography, as well as to a\nSPAM-agnostic protocol with idealized measurements. The average reconstruction\nfidelity is shown to be enhanced by 10\\% and 27\\%, respectively. The presented\nmethods apply to the vast range of quantum experiments which rely on\ntomography.\n", "versions": [{"version": "v1", "created": "Thu, 11 Apr 2019 18:00:13 GMT"}, {"version": "v2", "created": "Wed, 24 Apr 2019 12:47:48 GMT"}], "update_date": "2020-03-06", "authors_parsed": [["Palmieri", "Adriano Macarone", ""], ["Kovlakov", "Egor", ""], ["Bianchi", "Federico", ""], ["Yudin", "Dmitry", ""], ["Straupe", "Stanislav", ""], ["Biamonte", "Jacob", ""], ["Kulik", "Sergei", ""]]}, {"id": "1904.05937", "submitter": "Bingyu Wang", "authors": "Bingyu Wang, Li Chen, Wei Sun, Kechen Qin, Kefeng Li and Hui Zhou", "title": "Ranking-Based Autoencoder for Extreme Multi-label Classification", "comments": "Accepted by NAACL-HLT 2019 as a long paper", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Extreme Multi-label classification (XML) is an important yet challenging\nmachine learning task, that assigns to each instance its most relevant\ncandidate labels from an extremely large label collection, where the numbers of\nlabels, features and instances could be thousands or millions. XML is more and\nmore on demand in the Internet industries, accompanied with the increasing\nbusiness scale / scope and data accumulation. The extremely large label\ncollections yield challenges such as computational complexity, inter-label\ndependency and noisy labeling. Many methods have been proposed to tackle these\nchallenges, based on different mathematical formulations. In this paper, we\npropose a deep learning XML method, with a word-vector-based self-attention,\nfollowed by a ranking-based AutoEncoder architecture. The proposed method has\nthree major advantages: 1) the autoencoder simultaneously considers the\ninter-label dependencies and the feature-label dependencies, by projecting\nlabels and features onto a common embedding space; 2) the ranking loss not only\nimproves the training efficiency and accuracy but also can be extended to\nhandle noisy labeled data; 3) the efficient attention mechanism improves\nfeature representation by highlighting feature importance. Experimental results\non benchmark datasets show the proposed method is competitive to\nstate-of-the-art methods.\n", "versions": [{"version": "v1", "created": "Thu, 11 Apr 2019 19:47:01 GMT"}], "update_date": "2019-04-15", "authors_parsed": [["Wang", "Bingyu", ""], ["Chen", "Li", ""], ["Sun", "Wei", ""], ["Qin", "Kechen", ""], ["Li", "Kefeng", ""], ["Zhou", "Hui", ""]]}, {"id": "1904.05945", "submitter": "Huy Phan", "authors": "Huy Phan and Oliver Y. Ch\\'en and Philipp Koch and Alfred Mertins and\n  Maarten De Vos", "title": "Deep Transfer Learning for Single-Channel Automatic Sleep Staging with\n  Channel Mismatch", "comments": "Accepted for 27th European Signal Processing Conference (EUSIPCO\n  2019)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Many sleep studies suffer from the problem of insufficient data to fully\nutilize deep neural networks as different labs use different recordings set\nups, leading to the need of training automated algorithms on rather small\ndatabases, whereas large annotated databases are around but cannot be directly\nincluded into these studies for data compensation due to channel mismatch. This\nwork presents a deep transfer learning approach to overcome the channel\nmismatch problem and transfer knowledge from a large dataset to a small cohort\nto study automatic sleep staging with single-channel input. We employ the\nstate-of-the-art SeqSleepNet and train the network in the source domain, i.e.\nthe large dataset. Afterwards, the pretrained network is finetuned in the\ntarget domain, i.e. the small cohort, to complete knowledge transfer. We study\ntwo transfer learning scenarios with slight and heavy channel mismatch between\nthe source and target domains. We also investigate whether, and if so, how\nfinetuning entirely or partially the pretrained network would affect the\nperformance of sleep staging on the target domain. Using the Montreal Archive\nof Sleep Studies (MASS) database consisting of 200 subjects as the source\ndomain and the Sleep-EDF Expanded database consisting of 20 subjects as the\ntarget domain in this study, our experimental results show significant\nperformance improvement on sleep staging achieved with the proposed deep\ntransfer learning approach. Furthermore, these results also reveal the\nessential of finetuning the feature-learning parts of the pretrained network to\nbe able to bypass the channel mismatch problem.\n", "versions": [{"version": "v1", "created": "Thu, 11 Apr 2019 20:18:02 GMT"}, {"version": "v2", "created": "Tue, 18 Jun 2019 12:11:41 GMT"}], "update_date": "2019-06-19", "authors_parsed": [["Phan", "Huy", ""], ["Ch\u00e9n", "Oliver Y.", ""], ["Koch", "Philipp", ""], ["Mertins", "Alfred", ""], ["De Vos", "Maarten", ""]]}, {"id": "1904.05948", "submitter": "Qingyu Zhao", "authors": "Qingyu Zhao, Ehsan Adeli, Nicolas Honnorat, Tuo Leng, Kilian M. Pohl", "title": "Variational AutoEncoder For Regression: Application to Brain Aging\n  Analysis", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  While unsupervised variational autoencoders (VAE) have become a powerful tool\nin neuroimage analysis, their application to supervised learning is\nunder-explored. We aim to close this gap by proposing a unified probabilistic\nmodel for learning the latent space of imaging data and performing supervised\nregression. Based on recent advances in learning disentangled representations,\nthe novel generative process explicitly models the conditional distribution of\nlatent representations with respect to the regression target variable.\nPerforming a variational inference procedure on this model leads to joint\nregularization between the VAE and a neural-network regressor. In predicting\nthe age of 245 subjects from their structural Magnetic Resonance (MR) images,\nour model is more accurate than state-of-the-art methods when applied to either\nregion-of-interest (ROI) measurements or raw 3D volume images. More\nimportantly, unlike simple feed-forward neural-networks, disentanglement of age\nin latent representations allows for intuitive interpretation of the structural\ndevelopmental patterns of the human brain.\n", "versions": [{"version": "v1", "created": "Thu, 11 Apr 2019 20:39:29 GMT"}, {"version": "v2", "created": "Thu, 11 Jul 2019 18:14:47 GMT"}], "update_date": "2019-07-15", "authors_parsed": [["Zhao", "Qingyu", ""], ["Adeli", "Ehsan", ""], ["Honnorat", "Nicolas", ""], ["Leng", "Tuo", ""], ["Pohl", "Kilian M.", ""]]}, {"id": "1904.05961", "submitter": "Hanlin Lu", "authors": "Hanlin Lu, Ming-Ju Li, Ting He, Shiqiang Wang, Vijaykrishnan Narayanan\n  and Kevin S Chan", "title": "Robust Coreset Construction for Distributed Machine Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.DS stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Coreset, which is a summary of the original dataset in the form of a small\nweighted set in the same sample space, provides a promising approach to enable\nmachine learning over distributed data. Although viewed as a proxy of the\noriginal dataset, each coreset is only designed to approximate the cost\nfunction of a specific machine learning problem, and thus different coresets\nare often required to solve different machine learning problems, increasing the\ncommunication overhead. We resolve this dilemma by developing robust coreset\nconstruction algorithms that can support a variety of machine learning\nproblems. Motivated by empirical evidence that suitably-weighted k-clustering\ncenters provide a robust coreset, we harden the observation by establishing\ntheoretical conditions under which the coreset provides a guaranteed\napproximation for a broad range of machine learning problems, and developing\nboth centralized and distributed algorithms to generate coresets satisfying the\nconditions. The robustness of the proposed algorithms is verified through\nextensive experiments on diverse datasets with respect to both supervised and\nunsupervised learning problems.\n", "versions": [{"version": "v1", "created": "Thu, 11 Apr 2019 21:39:10 GMT"}, {"version": "v2", "created": "Thu, 10 Oct 2019 02:02:03 GMT"}, {"version": "v3", "created": "Mon, 22 Jun 2020 20:11:43 GMT"}], "update_date": "2020-06-24", "authors_parsed": [["Lu", "Hanlin", ""], ["Li", "Ming-Ju", ""], ["He", "Ting", ""], ["Wang", "Shiqiang", ""], ["Narayanan", "Vijaykrishnan", ""], ["Chan", "Kevin S", ""]]}, {"id": "1904.05981", "submitter": "Yizhe Zhu", "authors": "Soumik Pal, Yizhe Zhu", "title": "Community detection in the sparse hypergraph stochastic block model", "comments": "44 pages, 5 figures", "journal-ref": null, "doi": "10.1002/rsa.21006", "report-no": null, "categories": "math.PR cs.LG cs.SI math.CO stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the community detection problem in sparse random hypergraphs.\nAngelini et al. (2015) conjectured the existence of a sharp threshold on model\nparameters for community detection in sparse hypergraphs generated by a\nhypergraph stochastic block model. We solve the positive part of the conjecture\nfor the case of two blocks: above the threshold, there is a spectral algorithm\nwhich asymptotically almost surely constructs a partition of the hypergraph\ncorrelated with the true partition. Our method is a generalization to random\nhypergraphs of the method developed by Massouli\\'{e} (2014) for sparse random\ngraphs.\n", "versions": [{"version": "v1", "created": "Thu, 11 Apr 2019 23:23:21 GMT"}, {"version": "v2", "created": "Thu, 30 May 2019 00:23:04 GMT"}, {"version": "v3", "created": "Sat, 25 Jul 2020 23:54:37 GMT"}, {"version": "v4", "created": "Tue, 22 Dec 2020 07:40:27 GMT"}, {"version": "v5", "created": "Mon, 22 Feb 2021 21:46:48 GMT"}, {"version": "v6", "created": "Thu, 8 Jul 2021 04:33:17 GMT"}], "update_date": "2021-07-09", "authors_parsed": [["Pal", "Soumik", ""], ["Zhu", "Yizhe", ""]]}, {"id": "1904.05982", "submitter": "Jon Hoffman", "authors": "Jon Hoffman", "title": "Cramnet: Layer-wise Deep Neural Network Compression with Knowledge\n  Transfer from a Teacher Network", "comments": "Thesis for Masters degree", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Neural Networks accomplish amazing things, but they suffer from computational\nand memory bottlenecks that restrict their usage. Nowhere can this be better\nseen than in the mobile space, where specialized hardware is being created just\nto satisfy the demand for neural networks. Previous studies have shown that\nneural networks have vastly more connections than they actually need to do\ntheir work. This thesis develops a method that can compress networks to less\nthan 10% of memory and less than 25% of computational power, without loss of\naccuracy, and without creating sparse networks that require special code to\nrun.\n", "versions": [{"version": "v1", "created": "Thu, 11 Apr 2019 23:28:05 GMT"}], "update_date": "2019-04-15", "authors_parsed": [["Hoffman", "Jon", ""]]}, {"id": "1904.05985", "submitter": "Chu Wang", "authors": "Chu Wang, Lei Tang, Shujun Bian, Da Zhang, Zuohua Zhang, Yongning Wu", "title": "Reference Product Search", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.IR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  For a product of interest, we propose a search method to surface a set of\nreference products. The reference products can be used as candidates to support\ndownstream modeling tasks and business applications. The search method consists\nof product representation learning and fingerprint-type vector searching. The\nproduct catalog information is transformed into a high-quality embedding of low\ndimensions via a novel attention auto-encoder neural network, and the embedding\nis further coupled with a binary encoding vector for fast retrieval. We conduct\nextensive experiments to evaluate the proposed method, and compare it with peer\nservices to demonstrate its advantage in terms of search return rate and\nprecision.\n", "versions": [{"version": "v1", "created": "Thu, 11 Apr 2019 23:47:01 GMT"}], "update_date": "2019-04-15", "authors_parsed": [["Wang", "Chu", ""], ["Tang", "Lei", ""], ["Bian", "Shujun", ""], ["Zhang", "Da", ""], ["Zhang", "Zuohua", ""], ["Wu", "Yongning", ""]]}, {"id": "1904.06022", "submitter": "Gaurav Sahu", "authors": "Gaurav Sahu", "title": "Multimodal Speech Emotion Recognition and Ambiguity Resolution", "comments": "9 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CL stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Identifying emotion from speech is a non-trivial task pertaining to the\nambiguous definition of emotion itself. In this work, we adopt a\nfeature-engineering based approach to tackle the task of speech emotion\nrecognition. Formalizing our problem as a multi-class classification problem,\nwe compare the performance of two categories of models. For both, we extract\neight hand-crafted features from the audio signal. In the first approach, the\nextracted features are used to train six traditional machine learning\nclassifiers, whereas the second approach is based on deep learning wherein a\nbaseline feed-forward neural network and an LSTM-based classifier are trained\nover the same features. In order to resolve ambiguity in communication, we also\ninclude features from the text domain. We report accuracy, f-score, precision,\nand recall for the different experiment settings we evaluated our models in.\nOverall, we show that lighter machine learning based models trained over a few\nhand-crafted features are able to achieve performance comparable to the current\ndeep learning based state-of-the-art method for emotion recognition.\n", "versions": [{"version": "v1", "created": "Fri, 12 Apr 2019 03:22:13 GMT"}], "update_date": "2019-04-15", "authors_parsed": [["Sahu", "Gaurav", ""]]}, {"id": "1904.06025", "submitter": "Yeping Hu", "authors": "Yeping Hu, Alireza Nakhaei, Masayoshi Tomizuka, and Kikuo Fujimura", "title": "Interaction-aware Decision Making with Adaptive Strategies under Merging\n  Scenarios", "comments": "Best Paper Finalist of IROS 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.RO stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In order to drive safely and efficiently under merging scenarios, autonomous\nvehicles should be aware of their surroundings and make decisions by\ninteracting with other road participants. Moreover, different strategies should\nbe made when the autonomous vehicle is interacting with drivers having\ndifferent level of cooperativeness. Whether the vehicle is on the merge-lane or\nmain-lane will also influence the driving maneuvers since drivers will behave\ndifferently when they have the right-of-way than otherwise. Many traditional\nmethods have been proposed to solve decision making problems under merging\nscenarios. However, these works either are incapable of modeling complicated\ninteractions or require implementing hand-designed rules which cannot properly\nhandle the uncertainties in real-world scenarios. In this paper, we proposed an\ninteraction-aware decision making with adaptive strategies (IDAS) approach that\ncan let the autonomous vehicle negotiate the road with other drivers by\nleveraging their cooperativeness under merging scenarios. A single policy is\nlearned under the multi-agent reinforcement learning (MARL) setting via the\ncurriculum learning strategy, which enables the agent to automatically infer\nother drivers' various behaviors and make decisions strategically. A masking\nmechanism is also proposed to prevent the agent from exploring states that\nviolate common sense of human judgment and increase the learning efficiency. An\nexemplar merging scenario was used to implement and examine the proposed\nmethod.\n", "versions": [{"version": "v1", "created": "Fri, 12 Apr 2019 04:01:18 GMT"}, {"version": "v2", "created": "Fri, 21 Feb 2020 18:00:23 GMT"}], "update_date": "2020-02-24", "authors_parsed": [["Hu", "Yeping", ""], ["Nakhaei", "Alireza", ""], ["Tomizuka", "Masayoshi", ""], ["Fujimura", "Kikuo", ""]]}, {"id": "1904.06031", "submitter": "Saurabh Singh", "authors": "Saurabh Singh, Abhinav Shrivastava", "title": "EvalNorm: Estimating Batch Normalization Statistics for Evaluation", "comments": "Accepted at ICCV 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Batch normalization (BN) has been very effective for deep learning and is\nwidely used. However, when training with small minibatches, models using BN\nexhibit a significant degradation in performance. In this paper we study this\npeculiar behavior of BN to gain a better understanding of the problem, and\nidentify a cause. We propose 'EvalNorm' to address the issue by estimating\ncorrected normalization statistics to use for BN during evaluation. EvalNorm\nsupports online estimation of the corrected statistics while the model is being\ntrained, and does not affect the training scheme of the model. As a result,\nEvalNorm can also be used with existing pre-trained models allowing them to\nbenefit from our method. EvalNorm yields large gains for models trained with\nsmaller batches. Our experiments show that EvalNorm performs 6.18% (absolute)\nbetter than vanilla BN for a batchsize of 2 on ImageNet validation set and from\n1.5 to 7.0 points (absolute) gain on the COCO object detection benchmark across\na variety of setups.\n", "versions": [{"version": "v1", "created": "Fri, 12 Apr 2019 04:54:56 GMT"}, {"version": "v2", "created": "Tue, 13 Aug 2019 22:17:03 GMT"}], "update_date": "2019-08-15", "authors_parsed": [["Singh", "Saurabh", ""], ["Shrivastava", "Abhinav", ""]]}, {"id": "1904.06034", "submitter": "Tomoharu Iwata", "authors": "Tomoharu Iwata, Yuki Yamanaka", "title": "Supervised Anomaly Detection based on Deep Autoregressive Density\n  Estimators", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a supervised anomaly detection method based on neural density\nestimators, where the negative log likelihood is used for the anomaly score.\nDensity estimators have been widely used for unsupervised anomaly detection. By\nthe recent advance of deep learning, the density estimation performance has\nbeen greatly improved. However, the neural density estimators cannot exploit\nanomaly label information, which would be valuable for improving the anomaly\ndetection performance. The proposed method effectively utilizes the anomaly\nlabel information by training the neural density estimator so that the\nlikelihood of normal instances is maximized and the likelihood of anomalous\ninstances is lower than that of the normal instances. We employ an\nautoregressive model for the neural density estimator, which enables us to\ncalculate the likelihood exactly. With the experiments using 16 datasets, we\ndemonstrate that the proposed method improves the anomaly detection performance\nwith a few labeled anomalous instances, and achieves better performance than\nexisting unsupervised and supervised anomaly detection methods.\n", "versions": [{"version": "v1", "created": "Fri, 12 Apr 2019 05:03:53 GMT"}], "update_date": "2019-04-15", "authors_parsed": [["Iwata", "Tomoharu", ""], ["Yamanaka", "Yuki", ""]]}, {"id": "1904.06037", "submitter": "Ye Jia", "authors": "Ye Jia, Ron J. Weiss, Fadi Biadsy, Wolfgang Macherey, Melvin Johnson,\n  Zhifeng Chen, Yonghui Wu", "title": "Direct speech-to-speech translation with a sequence-to-sequence model", "comments": "Accepted to Interspeech 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG cs.SD eess.AS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present an attention-based sequence-to-sequence neural network which can\ndirectly translate speech from one language into speech in another language,\nwithout relying on an intermediate text representation. The network is trained\nend-to-end, learning to map speech spectrograms into target spectrograms in\nanother language, corresponding to the translated content (in a different\ncanonical voice). We further demonstrate the ability to synthesize translated\nspeech using the voice of the source speaker. We conduct experiments on two\nSpanish-to-English speech translation datasets, and find that the proposed\nmodel slightly underperforms a baseline cascade of a direct speech-to-text\ntranslation model and a text-to-speech synthesis model, demonstrating the\nfeasibility of the approach on this very challenging task.\n", "versions": [{"version": "v1", "created": "Fri, 12 Apr 2019 05:15:31 GMT"}, {"version": "v2", "created": "Tue, 25 Jun 2019 21:34:10 GMT"}], "update_date": "2019-06-27", "authors_parsed": [["Jia", "Ye", ""], ["Weiss", "Ron J.", ""], ["Biadsy", "Fadi", ""], ["Macherey", "Wolfgang", ""], ["Johnson", "Melvin", ""], ["Chen", "Zhifeng", ""], ["Wu", "Yonghui", ""]]}, {"id": "1904.06039", "submitter": "Guiying Huang", "authors": "Huang Victoria, Chen Gang, Fu Qiang", "title": "Effective Scheduling Function Design in SDN through Deep Reinforcement\n  Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.NI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent research on Software-Defined Networking (SDN) strongly promotes the\nadoption of distributed controller architectures. To achieve high network\nperformance, designing a scheduling function (SF) to properly dispatch requests\nfrom each switch to suitable controllers becomes critical. However, existing\nliterature tends to design the SF targeted at specific network settings. In\nthis paper, a reinforcement-learning-based (RL) approach is proposed with the\naim to automatically learn a general, effective, and efficient SF. In\nparticular, a new dispatching system is introduced in which the SF is\nrepresented as a neural network that determines the priority of each\ncontroller. Based on the priorities, a controller is selected using our\nproposed probability selection scheme to balance the trade-off between\nexploration and exploitation during learning. In order to train a general SF,\nwe first formulate the scheduling function design problem as an RL problem.\nThen a new training approach is developed based on a state-of-the-art deep RL\nalgorithm. Our simulation results show that our RL approach can rapidly design\n(or learn) SFs with optimal performance. Apart from that, the trained SF can\ngeneralize well and outperforms commonly used scheduling heuristics under\nvarious network settings.\n", "versions": [{"version": "v1", "created": "Fri, 12 Apr 2019 05:23:24 GMT"}], "update_date": "2019-04-15", "authors_parsed": [["Victoria", "Huang", ""], ["Gang", "Chen", ""], ["Qiang", "Fu", ""]]}, {"id": "1904.06049", "submitter": "Chun Hsien Yu", "authors": "Chun-Hsien Yu, Chun-Nan Chou, Emily Chang", "title": "Distributed Layer-Partitioned Training for Privacy-Preserved Deep\n  Learning", "comments": "accepted by IEEE MIPR'19 - short paper", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep Learning techniques have achieved remarkable results in many domains.\nOften, training deep learning models requires large datasets, which may require\nsensitive information to be uploaded to the cloud to accelerate training. To\nadequately protect sensitive information, we propose distributed\nlayer-partitioned training with step-wise activation functions for\nprivacy-preserving deep learning. Experimental results attest our method to be\nsimple and effective.\n", "versions": [{"version": "v1", "created": "Fri, 12 Apr 2019 06:08:57 GMT"}], "update_date": "2019-04-15", "authors_parsed": [["Yu", "Chun-Hsien", ""], ["Chou", "Chun-Nan", ""], ["Chang", "Emily", ""]]}, {"id": "1904.06062", "submitter": "Jayakorn Vongkulbhisal", "authors": "Jayakorn Vongkulbhisal, Phongtharin Vinayavekhin, Marco\n  Visentini-Scarzanella", "title": "Unifying Heterogeneous Classifiers with Distillation", "comments": "Accepted to CVPR 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we study the problem of unifying knowledge from a set of\nclassifiers with different architectures and target classes into a single\nclassifier, given only a generic set of unlabelled data. We call this problem\nUnifying Heterogeneous Classifiers (UHC). This problem is motivated by\nscenarios where data is collected from multiple sources, but the sources cannot\nshare their data, e.g., due to privacy concerns, and only privately trained\nmodels can be shared. In addition, each source may not be able to gather data\nto train all classes due to data availability at each source, and may not be\nable to train the same classification model due to different computational\nresources. To tackle this problem, we propose a generalisation of knowledge\ndistillation to merge HCs. We derive a probabilistic relation between the\noutputs of HCs and the probability over all classes. Based on this relation, we\npropose two classes of methods based on cross-entropy minimisation and matrix\nfactorisation, which allow us to estimate soft labels over all classes from\nunlabelled samples and use them in lieu of ground truth labels to train a\nunified classifier. Our extensive experiments on ImageNet, LSUN, and Places365\ndatasets show that our approaches significantly outperform a naive extension of\ndistillation and can achieve almost the same accuracy as classifiers that are\ntrained in a centralised, supervised manner.\n", "versions": [{"version": "v1", "created": "Fri, 12 Apr 2019 06:51:41 GMT"}], "update_date": "2019-04-15", "authors_parsed": [["Vongkulbhisal", "Jayakorn", ""], ["Vinayavekhin", "Phongtharin", ""], ["Visentini-Scarzanella", "Marco", ""]]}, {"id": "1904.06093", "submitter": "Sergey Novoselov", "authors": "Sergey Novoselov, Aleksei Gusev, Artem Ivanov, Timur Pekhovsky, Andrey\n  Shulipa, Galina Lavrentyeva, Vladimir Volokhov, Alexandr Kozlov", "title": "STC Speaker Recognition Systems for the VOiCES From a Distance Challenge", "comments": "Submitted to Interspeech 2019, Graz, Austria", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SD cs.CL cs.LG eess.AS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper presents the Speech Technology Center (STC) speaker recognition\n(SR) systems submitted to the VOiCES From a Distance challenge 2019. The\nchallenge's SR task is focused on the problem of speaker recognition in single\nchannel distant/far-field audio under noisy conditions. In this work we\ninvestigate different deep neural networks architectures for speaker embedding\nextraction to solve the task. We show that deep networks with residual frame\nlevel connections outperform more shallow architectures. Simple energy based\nspeech activity detector (SAD) and automatic speech recognition (ASR) based SAD\nare investigated in this work. We also address the problem of data preparation\nfor robust embedding extractors training. The reverberation for the data\naugmentation was performed using automatic room impulse response generator. In\nour systems we used discriminatively trained cosine similarity metric learning\nmodel as embedding backend. Scores normalization procedure was applied for each\nindividual subsystem we used. Our final submitted systems were based on the\nfusion of different subsystems. The results obtained on the VOiCES development\nand evaluation sets demonstrate effectiveness and robustness of the proposed\nsystems when dealing with distant/far-field audio under noisy conditions.\n", "versions": [{"version": "v1", "created": "Fri, 12 Apr 2019 08:23:26 GMT"}], "update_date": "2019-04-15", "authors_parsed": [["Novoselov", "Sergey", ""], ["Gusev", "Aleksei", ""], ["Ivanov", "Artem", ""], ["Pekhovsky", "Timur", ""], ["Shulipa", "Andrey", ""], ["Lavrentyeva", "Galina", ""], ["Volokhov", "Vladimir", ""], ["Kozlov", "Alexandr", ""]]}, {"id": "1904.06100", "submitter": "Ismini Lourentzou", "authors": "Ismini Lourentzou, Kabir Manghnani, ChengXiang Zhai", "title": "Adapting Sequence to Sequence models for Text Normalization in Social\n  Media", "comments": "Accepted at the 13th International AAAI Conference on Web and Social\n  Media (ICWSM 2019)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Social media offer an abundant source of valuable raw data, however informal\nwriting can quickly become a bottleneck for many natural language processing\n(NLP) tasks. Off-the-shelf tools are usually trained on formal text and cannot\nexplicitly handle noise found in short online posts. Moreover, the variety of\nfrequently occurring linguistic variations presents several challenges, even\nfor humans who might not be able to comprehend the meaning of such posts,\nespecially when they contain slang and abbreviations. Text Normalization aims\nto transform online user-generated text to a canonical form. Current text\nnormalization systems rely on string or phonetic similarity and classification\nmodels that work on a local fashion. We argue that processing contextual\ninformation is crucial for this task and introduce a social media text\nnormalization hybrid word-character attention-based encoder-decoder model that\ncan serve as a pre-processing step for NLP applications to adapt to noisy text\nin social media. Our character-based component is trained on synthetic\nadversarial examples that are designed to capture errors commonly found in\nonline user-generated text. Experiments show that our model surpasses neural\narchitectures designed for text normalization and achieves comparable\nperformance with state-of-the-art related work.\n", "versions": [{"version": "v1", "created": "Fri, 12 Apr 2019 08:45:43 GMT"}], "update_date": "2019-04-15", "authors_parsed": [["Lourentzou", "Ismini", ""], ["Manghnani", "Kabir", ""], ["Zhai", "ChengXiang", ""]]}, {"id": "1904.06127", "submitter": "Alastair Gregory", "authors": "Alastair Gregory, Din-Houn Lau, Alex Tessier and Pan Zhang", "title": "A streaming feature-based compression method for data from instrumented\n  infrastructure", "comments": "22 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.AP stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  An increasing amount of civil engineering applications are utilising data\nacquired from infrastructure instrumented with sensing devices. This data has\nan important role in monitoring the response of these structures to excitation,\nand evaluating structural health. In this paper we seek to monitor\npedestrian-events (such as a person walking) on a footbridge using strain and\nacceleration data. The rate of this data acquisition and the number of sensing\ndevices make the storage and analysis of this data a computational challenge.\nWe introduce a streaming method to compress the sensor data, whilst preserving\nkey patterns and features (unique to different sensor types) corresponding to\npedestrian-events. Numerical demonstrations of the methodology on data obtained\nfrom strain sensors and accelerometers on the pedestrian footbridge are\nprovided to show the trade-off between compression and accuracy during and\nin-between periods of pedestrian-events.\n", "versions": [{"version": "v1", "created": "Fri, 12 Apr 2019 09:36:40 GMT"}], "update_date": "2019-04-15", "authors_parsed": [["Gregory", "Alastair", ""], ["Lau", "Din-Houn", ""], ["Tessier", "Alex", ""], ["Zhang", "Pan", ""]]}, {"id": "1904.06145", "submitter": "Ari Heljakka", "authors": "Ari Heljakka, Arno Solin, Juho Kannala", "title": "Towards Photographic Image Manipulation with Balanced Growing of\n  Generative Autoencoders", "comments": "WACV 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a generative autoencoder that provides fast encoding, faithful\nreconstructions (eg. retaining the identity of a face), sharp\ngenerated/reconstructed samples in high resolutions, and a well-structured\nlatent space that supports semantic manipulation of the inputs. There are no\ncurrent autoencoder or GAN models that satisfactorily achieve all of these. We\nbuild on the progressively growing autoencoder model PIONEER, for which we\ncompletely alter the training dynamics based on a careful analysis of recently\nintroduced normalization schemes. We show significantly improved visual and\nquantitative results for face identity conservation in CelebAHQ. Our model\nachieves state-of-the-art disentanglement of latent space, both quantitatively\nand via realistic image attribute manipulations. On the LSUN Bedrooms dataset,\nwe improve the disentanglement performance of the vanilla PIONEER, despite\nhaving a simpler model. Overall, our results indicate that the PIONEER networks\nprovide a way towards photorealistic face manipulation.\n", "versions": [{"version": "v1", "created": "Fri, 12 Apr 2019 10:31:45 GMT"}, {"version": "v2", "created": "Thu, 20 Feb 2020 18:36:05 GMT"}], "update_date": "2020-02-21", "authors_parsed": [["Heljakka", "Ari", ""], ["Solin", "Arno", ""], ["Kannala", "Juho", ""]]}, {"id": "1904.06151", "submitter": "Maxim Panov", "authors": "Marina Gomtsyan, Nikita Mokrov, Maxim Panov and Yury Yanovich", "title": "Geometry-Aware Maximum Likelihood Estimation of Intrinsic Dimension", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG stat.ME", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The existing approaches to intrinsic dimension estimation usually are not\nreliable when the data are nonlinearly embedded in the high dimensional space.\nIn this work, we show that the explicit accounting to geometric properties of\nunknown support leads to the polynomial correction to the standard maximum\nlikelihood estimate of intrinsic dimension for flat manifolds. The proposed\nalgorithm (GeoMLE) realizes the correction by regression of standard MLEs based\non distances to nearest neighbors for different sizes of neighborhoods.\nMoreover, the proposed approach also efficiently handles the case of nonuniform\nsampling of the manifold. We perform numerous experiments on different\nsynthetic and real-world datasets. The results show that our algorithm achieves\nstate-of-the-art performance, while also being computationally efficient and\nrobust to noise in the data.\n", "versions": [{"version": "v1", "created": "Fri, 12 Apr 2019 10:44:22 GMT"}], "update_date": "2019-04-15", "authors_parsed": [["Gomtsyan", "Marina", ""], ["Mokrov", "Nikita", ""], ["Panov", "Maxim", ""], ["Yanovich", "Yury", ""]]}, {"id": "1904.06157", "submitter": "Stylianos Ioannis Mimilakis", "authors": "Stylianos Ioannis Mimilakis, Konstantinos Drossos, Estefan\\'ia Cano,\n  Gerald Schuller", "title": "Examining the Mapping Functions of Denoising Autoencoders in Singing\n  Voice Separation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.AS cs.LG cs.SD", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The goal of this work is to investigate what singing voice separation\napproaches based on neural networks learn from the data. We examine the mapping\nfunctions of neural networks based on the denoising autoencoder (DAE) model\nthat are conditioned on the mixture magnitude spectra. To approximate the\nmapping functions, we propose an algorithm inspired by the knowledge\ndistillation, denoted the neural couplings algorithm (NCA). The NCA yields a\nmatrix that expresses the mapping of the mixture to the target source magnitude\ninformation. Using the NCA, we examine the mapping functions of three\nfundamental DAE-based models in music source separation; one with single-layer\nencoder and decoder, one with multi-layer encoder and single-layer decoder, and\none using skip-filtering connections (SF) with a single-layer encoding and\ndecoding. We first train these models with realistic data to estimate the\nsinging voice magnitude spectra from the corresponding mixture. We then use the\noptimized models and test spectral data as input to the NCA. Our experimental\nfindings show that approaches based on the DAE model learn scalar filtering\noperators, exhibiting a predominant diagonal structure in their corresponding\nmapping functions, limiting the exploitation of inter-frequency structure of\nmusic data. In contrast, skip-filtering connections are shown to assist the DAE\nmodel in learning filtering operators that exploit richer inter-frequency\nstructures.\n", "versions": [{"version": "v1", "created": "Fri, 12 Apr 2019 11:22:43 GMT"}, {"version": "v2", "created": "Sun, 20 Oct 2019 14:41:05 GMT"}], "update_date": "2019-10-22", "authors_parsed": [["Mimilakis", "Stylianos Ioannis", ""], ["Drossos", "Konstantinos", ""], ["Cano", "Estefan\u00eda", ""], ["Schuller", "Gerald", ""]]}, {"id": "1904.06186", "submitter": "Yatie Xiao", "authors": "Yatie Xiao, Chi-Man Pun", "title": "Generating Minimal Adversarial Perturbations with Integrated Adaptive\n  Gradients", "comments": "8 pages, 7 figures. arXiv admin note: text overlap with\n  arXiv:1902.01220 The formula in Algorithm 1 lacks important representations", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep neural networks are easily fooled high confidence predictions for\nadversarial samples\n", "versions": [{"version": "v1", "created": "Fri, 12 Apr 2019 12:24:25 GMT"}, {"version": "v2", "created": "Tue, 14 May 2019 07:16:55 GMT"}, {"version": "v3", "created": "Mon, 20 May 2019 01:33:58 GMT"}], "update_date": "2019-05-21", "authors_parsed": [["Xiao", "Yatie", ""], ["Pun", "Chi-Man", ""]]}, {"id": "1904.06187", "submitter": "Jingcai Guo", "authors": "Shiheng Ma, Jingcai Guo, Song Guo, Minyi Guo", "title": "Position-Aware Convolutional Networks for Traffic Prediction", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Forecasting the future traffic flow distribution in an area is an important\nissue for traffic management in an intelligent transportation system. The key\nchallenge of traffic prediction is to capture spatial and temporal relations\nbetween future traffic flows and historical traffic due to highly dynamical\npatterns of human activities. Most existing methods explore such relations by\nfusing spatial and temporal features extracted from multi-source data. However,\nthey neglect position information which helps distinguish patterns on different\npositions. In this paper, we propose a position-aware neural network that\nintegrates data features and position information. Our approach employs the\ninception backbone network to capture rich features of traffic distribution on\nthe whole area. The novelty lies in that under the backbone network, we apply\nposition embedding technique used in neural language processing to represent\nposition information as embedding vectors which are learned during the\ntraining. With these embedding vectors, we design position-aware convolution\nwhich allows different kernels to process features of different positions.\nExtensive experiments on two real-world datasets show that our approach\noutperforms previous methods even with fewer data sources.\n", "versions": [{"version": "v1", "created": "Fri, 12 Apr 2019 12:25:14 GMT"}], "update_date": "2019-04-15", "authors_parsed": [["Ma", "Shiheng", ""], ["Guo", "Jingcai", ""], ["Guo", "Song", ""], ["Guo", "Minyi", ""]]}, {"id": "1904.06194", "submitter": "Ze-Feng Gao", "authors": "Ze-Feng Gao, Song Cheng, Rong-Qiang He, Z. Y. Xie, Hui-Hai Zhao,\n  Zhong-Yi Lu, Tao Xiang", "title": "Compressing deep neural networks by matrix product operators", "comments": "8+9 pages, 3+7 figures, 2+11 tables", "journal-ref": "Phys. Rev. Research 2, 023300 (2020)", "doi": "10.1103/PhysRevResearch.2.023300", "report-no": null, "categories": "cs.LG cs.CV cs.NE physics.comp-ph quant-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A deep neural network is a parametrization of a multilayer mapping of signals\nin terms of many alternatively arranged linear and nonlinear transformations.\nThe linear transformations, which are generally used in the fully connected as\nwell as convolutional layers, contain most of the variational parameters that\nare trained and stored. Compressing a deep neural network to reduce its number\nof variational parameters but not its prediction power is an important but\nchallenging problem toward the establishment of an optimized scheme in training\nefficiently these parameters and in lowering the risk of overfitting. Here we\nshow that this problem can be effectively solved by representing linear\ntransformations with matrix product operators (MPOs), which is a tensor network\noriginally proposed in physics to characterize the short-range entanglement in\none-dimensional quantum states. We have tested this approach in five typical\nneural networks, including FC2, LeNet-5, VGG, ResNet, and DenseNet on two\nwidely used data sets, namely, MNIST and CIFAR-10, and found that this MPO\nrepresentation indeed sets up a faithful and efficient mapping between input\nand output signals, which can keep or even improve the prediction accuracy with\na dramatically reduced number of parameters. Our method greatly simplifies the\nrepresentations in deep learning, and opens a possible route toward\nestablishing a framework of modern neural networks which might be simpler and\ncheaper, but more efficient.\n", "versions": [{"version": "v1", "created": "Thu, 11 Apr 2019 17:59:00 GMT"}, {"version": "v2", "created": "Wed, 10 Jun 2020 03:26:01 GMT"}], "update_date": "2020-07-01", "authors_parsed": [["Gao", "Ze-Feng", ""], ["Cheng", "Song", ""], ["He", "Rong-Qiang", ""], ["Xie", "Z. Y.", ""], ["Zhao", "Hui-Hai", ""], ["Lu", "Zhong-Yi", ""], ["Xiang", "Tao", ""]]}, {"id": "1904.06197", "submitter": "Andrea Mendizabal", "authors": "Andrea Mendizabal, Pablo M\\'arquez-Neila, St\\'ephane Cotin", "title": "Simulation of hyperelastic materials in real-time using Deep Learning", "comments": null, "journal-ref": "Medical Image Analysis, Volume 59, January 2020, 101569", "doi": "10.1016/j.media.2019.101569", "report-no": null, "categories": "cs.CE cs.LG physics.comp-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The finite element method (FEM) is among the most commonly used numerical\nmethods for solving engineering problems. Due to its computational cost,\nvarious ideas have been introduced to reduce computation times, such as domain\ndecomposition, parallel computing, adaptive meshing, and model order reduction.\nIn this paper we present U-Mesh: a data-driven method based on a U-Net\narchitecture that approximates the non-linear relation between a contact force\nand the displacement field computed by a FEM algorithm. We show that deep\nlearning, one of the latest machine learning methods based on artificial neural\nnetworks, can enhance computational mechanics through its ability to encode\nhighly non-linear models in a compact form. Our method is applied to two\nbenchmark examples: a cantilever beam and an L-shape subject to moving punctual\nloads. A comparison between our method and proper orthogonal decomposition\n(POD) is done through the paper. The results show that U-Mesh can perform very\nfast simulations on various geometries, mesh resolutions and number of input\nforces with very small errors.\n", "versions": [{"version": "v1", "created": "Wed, 10 Apr 2019 17:30:28 GMT"}, {"version": "v2", "created": "Wed, 6 Nov 2019 14:04:58 GMT"}], "update_date": "2019-11-07", "authors_parsed": [["Mendizabal", "Andrea", ""], ["M\u00e1rquez-Neila", "Pablo", ""], ["Cotin", "St\u00e9phane", ""]]}, {"id": "1904.06211", "submitter": "Jo\\~ao Henrique Corr\\^ea", "authors": "Jo\\~ao Henrique Corr\\^ea, Patrick Marques Ciarelli, Moises R. N.\n  Ribeiro and Rodolfo da Silva Villaca", "title": "On Machine Learning DoS Attack Identification from Cloud Computing\n  Telemetry", "comments": "Abstract submit for LANCOMM 2019\n  (http://sbrc2019.sbc.org.br/en/lancomm-student-workshop-2019/)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.LG cs.NI stat.ML", "license": "http://creativecommons.org/licenses/by-sa/4.0/", "abstract": "  The detection of Denial of Service (DoS) attacks remains a challenge for the\ncloud environment, affecting a massive number of services and applications\nhosted by such virtualized infrastructures. Typically, in the literature, the\ndetection of DoS attacks is performed solely by analyzing the traffic of\npackets in the network. This work advocates for the use of telemetry from the\ncloud to detect DoS attacks using Machine Learning algorithms. Our hypothesis\nis based on richness of such native data collection services, with metrics from\nboth physical and virtual hosts. Our preliminary results demonstrate that DoS\ncan be identified accurately with k-Nearest Neighbors (kNN) and decision tree\n(CART).\n", "versions": [{"version": "v1", "created": "Thu, 11 Apr 2019 12:41:12 GMT"}], "update_date": "2019-04-15", "authors_parsed": [["Corr\u00eaa", "Jo\u00e3o Henrique", ""], ["Ciarelli", "Patrick Marques", ""], ["Ribeiro", "Moises R. N.", ""], ["Villaca", "Rodolfo da Silva", ""]]}, {"id": "1904.06215", "submitter": "Adrien Bitton", "authors": "Adrien Bitton, Philippe Esling, Antoine Caillon, Martin Fouilleul", "title": "Assisted Sound Sample Generation with Musical Conditioning in\n  Adversarial Auto-Encoders", "comments": "this article has been accepted for presentation to the 22nd\n  International Conference on Digital Audio Effects (DAFx 2019) ; we provide\n  additional content on this companion repository\n  https://github.com/acids-ircam/Expressive_WAE_FADER", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SD cs.LG eess.AS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Generative models have thrived in computer vision, enabling unprecedented\nimage processes. Yet the results in audio remain less advanced. Our project\ntargets real-time sound synthesis from a reduced set of high-level parameters,\nincluding semantic controls that can be adapted to different sound libraries\nand specific tags. These generative variables should allow expressive\nmodulations of target musical qualities and continuously mix into new styles.\nTo this extent we train AEs on an orchestral database of individual note\nsamples, along with their intrinsic attributes: note class, timbre domain and\nextended playing techniques. We condition the decoder for control over the\nrendered note attributes and use latent adversarial training for learning\nexpressive style parameters that can ultimately be mixed. We evaluate both\ngenerative performances and latent representation. Our ablation study\ndemonstrates the effectiveness of the musical conditioning mechanisms. The\nproposed model generates notes as magnitude spectrograms from any probabilistic\nlatent code samples, with expressive control of orchestral timbres and playing\nstyles. Its training data subsets can directly be visualized in the 3D latent\nrepresentation. Waveform rendering can be done offline with GLA. In order to\nallow real-time interactions, we fine-tune the decoder with a pretrained MCNN\nand embed the full waveform generation pipeline in a plugin. Moreover the\nencoder could be used to process new input samples, after manipulating their\nlatent attribute representation, the decoder can generate sample variations as\nan audio effect would. Our solution remains rather fast to train, it can\ndirectly be applied to other sound domains, including an user's libraries with\ncustom sound tags that could be mapped to specific generative controls. As a\nresult, it fosters creativity and intuitive audio style experimentations.\n", "versions": [{"version": "v1", "created": "Fri, 12 Apr 2019 13:02:17 GMT"}, {"version": "v2", "created": "Sat, 22 Jun 2019 13:53:50 GMT"}], "update_date": "2019-06-25", "authors_parsed": [["Bitton", "Adrien", ""], ["Esling", "Philippe", ""], ["Caillon", "Antoine", ""], ["Fouilleul", "Martin", ""]]}, {"id": "1904.06250", "submitter": "Jiaqi Guan", "authors": "Jiaqi Guan, Ye Yuan, Kris M. Kitani, Nicholas Rhinehart", "title": "Generative Hybrid Representations for Activity Forecasting with\n  No-Regret Learning", "comments": "Oral presentation at CVPR 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Automatically reasoning about future human behaviors is a difficult problem\nbut has significant practical applications to assistive systems. Part of this\ndifficulty stems from learning systems' inability to represent all kinds of\nbehaviors. Some behaviors, such as motion, are best described with continuous\nrepresentations, whereas others, such as picking up a cup, are best described\nwith discrete representations. Furthermore, human behavior is generally not\nfixed: people can change their habits and routines. This suggests these systems\nmust be able to learn and adapt continuously. In this work, we develop an\nefficient deep generative model to jointly forecast a person's future discrete\nactions and continuous motions. On a large-scale egocentric dataset,\nEPIC-KITCHENS, we observe our method generates high-quality and diverse samples\nwhile exhibiting better generalization than related generative models. Finally,\nwe propose a variant to continually learn our model from streaming data,\nobserve its practical effectiveness, and theoretically justify its learning\nefficiency.\n", "versions": [{"version": "v1", "created": "Fri, 12 Apr 2019 14:22:37 GMT"}, {"version": "v2", "created": "Fri, 3 Apr 2020 18:27:39 GMT"}], "update_date": "2020-04-07", "authors_parsed": [["Guan", "Jiaqi", ""], ["Yuan", "Ye", ""], ["Kitani", "Kris M.", ""], ["Rhinehart", "Nicholas", ""]]}, {"id": "1904.06253", "submitter": "Nicolas Couellan", "authors": "Nicolas Couellan", "title": "The coupling effect of Lipschitz regularization in deep neural networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We investigate robustness of deep feed-forward neural networks when input\ndata are subject to random uncertainties. More specifically, we consider\nregularization of the network by its Lipschitz constant and emphasize its role.\nWe highlight the fact that this regularization is not only a way to control the\nmagnitude of the weights but has also a coupling effect on the network weights\naccross the layers. We claim and show evidence on a dataset that this coupling\neffect brings a tradeoff between robustness and expressiveness of the network.\nThis suggests that Lipschitz regularization should be carefully implemented so\nas to maintain coupling accross layers.\n", "versions": [{"version": "v1", "created": "Fri, 12 Apr 2019 14:36:21 GMT"}], "update_date": "2019-04-15", "authors_parsed": [["Couellan", "Nicolas", ""]]}, {"id": "1904.06254", "submitter": "Jingcai Guo", "authors": "Jingcai Guo, Song Guo", "title": "AMS-SFE: Towards an Alignment of Manifold Structures via Semantic\n  Feature Expansion for Zero-shot Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Zero-shot learning (ZSL) aims at recognizing unseen classes with knowledge\ntransferred from seen classes. This is typically achieved by exploiting a\nsemantic feature space (FS) shared by both seen and unseen classes, i.e.,\nattributes or word vectors, as the bridge. However, due to the mutually\ndisjoint of training (seen) and testing (unseen) data, existing ZSL methods\neasily and commonly suffer from the domain shift problem. To address this\nissue, we propose a novel model called AMS-SFE. It considers the Alignment of\nManifold Structures by Semantic Feature Expansion. Specifically, we build up an\nautoencoder based model to expand the semantic features and joint with an\nalignment to an embedded manifold extracted from the visual FS of data. It is\nthe first attempt to align these two FSs by way of expanding semantic features.\nExtensive experiments show the remarkable performance improvement of our model\ncompared with other existing methods.\n", "versions": [{"version": "v1", "created": "Fri, 12 Apr 2019 14:38:03 GMT"}], "update_date": "2019-04-15", "authors_parsed": [["Guo", "Jingcai", ""], ["Guo", "Song", ""]]}, {"id": "1904.06258", "submitter": "Saeed Ghoorchian", "authors": "Saeed Ghoorchian, Setareh Maghsudi", "title": "Multi-Armed Bandit for Energy-Efficient and Delay-Sensitive Edge\n  Computing in Dynamic Networks with Uncertainty", "comments": "30 pages, 7 figures", "journal-ref": null, "doi": "10.1109/TCCN.2020.3012445", "report-no": null, "categories": "cs.LG eess.SP stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In the edge computing paradigm, mobile devices offload the computational\ntasks to an edge server by routing the required data over the wireless network.\nThe full potential of edge computing becomes realized only if a smart device\nselects the most appropriate server in terms of the latency and energy\nconsumption, among many available ones. The server selection problem is\nchallenging due to the randomness of the environment and lack of prior\ninformation about the environment. Therefore, a smart device, which\nsequentially chooses a server under uncertainty, aims to improve its decision\nbased on the historical time and energy consumption. The problem becomes more\ncomplicated in a dynamic environment, where key variables might undergo abrupt\nchanges. To deal with the aforementioned problem, we first analyze the required\ntime and energy to data transmission and processing. We then use the analysis\nto cast the problem as a budget-limited multi-armed bandit problem, where each\narm is associated with a reward and cost, with time-variant statistical\ncharacteristics. We propose a policy to solve the formulated problem and prove\na regret bound. The numerical results demonstrate the superiority of the\nproposed method compared to a number of existing solutions.\n", "versions": [{"version": "v1", "created": "Fri, 12 Apr 2019 14:46:20 GMT"}, {"version": "v2", "created": "Mon, 2 Dec 2019 17:53:24 GMT"}], "update_date": "2020-08-25", "authors_parsed": [["Ghoorchian", "Saeed", ""], ["Maghsudi", "Setareh", ""]]}, {"id": "1904.06260", "submitter": "Eric Benhamou", "authors": "Eric Benhamou", "title": "Similarities between policy gradient methods (PGM) in Reinforcement\n  learning (RL) and supervised learning (SL)", "comments": "6 pages, 1 figure", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Reinforcement learning (RL) is about sequential decision making and is\ntraditionally opposed to supervised learning (SL) and unsupervised learning\n(USL). In RL, given the current state, the agent makes a decision that may\ninfluence the next state as opposed to SL (and USL) where, the next state\nremains the same, regardless of the decisions taken, either in batch or online\nlearning. Although this difference is fundamental between SL and RL, there are\nconnections that have been overlooked. In particular, we prove in this paper\nthat gradient policy method can be cast as a supervised learning problem where\ntrue label are replaced with discounted rewards. We provide a new proof of\npolicy gradient methods (PGM) that emphasizes the tight link with the cross\nentropy and supervised learning. We provide a simple experiment where we\ninterchange label and pseudo rewards. We conclude that other relationships with\nSL could be made if we modify the reward functions wisely.\n", "versions": [{"version": "v1", "created": "Fri, 12 Apr 2019 14:49:28 GMT"}, {"version": "v2", "created": "Tue, 23 Apr 2019 07:39:36 GMT"}, {"version": "v3", "created": "Thu, 2 May 2019 17:44:44 GMT"}], "update_date": "2019-05-03", "authors_parsed": [["Benhamou", "Eric", ""]]}, {"id": "1904.06264", "submitter": "Francesco Tonolini", "authors": "Francesco Tonolini, Jack Radford, Alex Turpin, Daniele Faccio,\n  Roderick Murray-Smith", "title": "Variational Inference for Computational Imaging Inverse Problems", "comments": "29+15 Pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Machine learning methods for computational imaging require uncertainty\nestimation to be reliable in real settings. While Bayesian models offer a\ncomputationally tractable way of recovering uncertainty, they need large data\nvolumes to be trained, which in imaging applications implicates prohibitively\nexpensive collections with specific imaging instruments. This paper introduces\na novel framework to train variational inference for inverse problems\nexploiting in combination few experimentally collected data, domain expertise\nand existing image data sets. In such a way, Bayesian machine learning models\ncan solve imaging inverse problems with minimal data collection efforts.\nExtensive simulated experiments show the advantages of the proposed framework.\nThe approach is then applied to two real experimental optics settings:\nholographic image reconstruction and imaging through highly scattering media.\nIn both settings, state of the art reconstructions are achieved with little\ncollection of training data.\n", "versions": [{"version": "v1", "created": "Fri, 12 Apr 2019 15:10:57 GMT"}, {"version": "v2", "created": "Tue, 21 Jan 2020 12:43:52 GMT"}, {"version": "v3", "created": "Fri, 21 Aug 2020 15:18:09 GMT"}], "update_date": "2020-08-24", "authors_parsed": [["Tonolini", "Francesco", ""], ["Radford", "Jack", ""], ["Turpin", "Alex", ""], ["Faccio", "Daniele", ""], ["Murray-Smith", "Roderick", ""]]}, {"id": "1904.06269", "submitter": "Daniel Saunders", "authors": "Daniel J. Saunders, Devdhar Patel, Hananel Hazan, Hava T. Siegelmann,\n  Robert Kozma", "title": "Locally Connected Spiking Neural Networks for Unsupervised Feature\n  Learning", "comments": "22 pages, 7 figures, and 4 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In recent years, Spiking Neural Networks (SNNs) have demonstrated great\nsuccesses in completing various Machine Learning tasks. We introduce a method\nfor learning image features by \\textit{locally connected layers} in SNNs using\nspike-timing-dependent plasticity (STDP) rule. In our approach, sub-networks\ncompete via competitive inhibitory interactions to learn features from\ndifferent locations of the input space. These \\textit{Locally-Connected SNNs}\n(LC-SNNs) manifest key topological features of the spatial interaction of\nbiological neurons. We explore biologically inspired n-gram classification\napproach allowing parallel processing over various patches of the the image\nspace. We report the classification accuracy of simple two-layer LC-SNNs on two\nimage datasets, which match the state-of-art performance and are the first\nresults to date. LC-SNNs have the advantage of fast convergence to a dataset\nrepresentation, and they require fewer learnable parameters than other SNN\napproaches with unsupervised learning. Robustness tests demonstrate that\nLC-SNNs exhibit graceful degradation of performance despite the random deletion\nof large amounts of synapses and neurons.\n", "versions": [{"version": "v1", "created": "Fri, 12 Apr 2019 15:20:37 GMT"}], "update_date": "2019-04-15", "authors_parsed": [["Saunders", "Daniel J.", ""], ["Patel", "Devdhar", ""], ["Hazan", "Hananel", ""], ["Siegelmann", "Hava T.", ""], ["Kozma", "Robert", ""]]}, {"id": "1904.06288", "submitter": "Arnak Dalalyan S.", "authors": "Arnak S. Dalalyan and Philip Thompson", "title": "Outlier-robust estimation of a sparse linear model using\n  $\\ell_1$-penalized Huber's $M$-estimator", "comments": "This is a follow up paper of arXiv:1805.08020", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST cs.LG stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the problem of estimating a $p$-dimensional $s$-sparse vector in a\nlinear model with Gaussian design and additive noise. In the case where the\nlabels are contaminated by at most $o$ adversarial outliers, we prove that the\n$\\ell_1$-penalized Huber's $M$-estimator based on $n$ samples attains the\noptimal rate of convergence $(s/n)^{1/2} + (o/n)$, up to a logarithmic factor.\nFor more general design matrices, our results highlight the importance of two\nproperties: the transfer principle and the incoherence property. These\nproperties with suitable constants are shown to yield the optimal rates, up to\nlog-factors, of robust estimation with adversarial contamination.\n", "versions": [{"version": "v1", "created": "Fri, 12 Apr 2019 15:52:04 GMT"}, {"version": "v2", "created": "Wed, 22 May 2019 14:54:33 GMT"}, {"version": "v3", "created": "Tue, 19 Nov 2019 15:52:50 GMT"}], "update_date": "2019-11-20", "authors_parsed": [["Dalalyan", "Arnak S.", ""], ["Thompson", "Philip", ""]]}, {"id": "1904.06292", "submitter": "George Kesidis", "authors": "David J. Miller, Zhen Xiang, and George Kesidis", "title": "Adversarial Learning in Statistical Classification: A Comprehensive\n  Review of Defenses Against Attacks", "comments": null, "journal-ref": "Proceedings of the IEEE, March. 2020", "doi": null, "report-no": null, "categories": "cs.LG cs.CR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  There is great potential for damage from adversarial learning (AL) attacks on\nmachine-learning based systems. In this paper, we provide a contemporary survey\nof AL, focused particularly on defenses against attacks on statistical\nclassifiers. After introducing relevant terminology and the goals and range of\npossible knowledge of both attackers and defenders, we survey recent work on\ntest-time evasion (TTE), data poisoning (DP), and reverse engineering (RE)\nattacks and particularly defenses against same. In so doing, we distinguish\nrobust classification from anomaly detection (AD), unsupervised from\nsupervised, and statistical hypothesis-based defenses from ones that do not\nhave an explicit null (no attack) hypothesis; we identify the hyperparameters a\nparticular method requires, its computational complexity, as well as the\nperformance measures on which it was evaluated and the obtained quality. We\nthen dig deeper, providing novel insights that challenge conventional AL wisdom\nand that target unresolved issues, including: 1) robust classification versus\nAD as a defense strategy; 2) the belief that attack success increases with\nattack strength, which ignores susceptibility to AD; 3) small perturbations for\ntest-time evasion attacks: a fallacy or a requirement?; 4) validity of the\nuniversal assumption that a TTE attacker knows the ground-truth class for the\nexample to be attacked; 5) black, grey, or white box attacks as the standard\nfor defense evaluation; 6) susceptibility of query-based RE to an AD defense.\nWe also discuss attacks on the privacy of training data. We then present\nbenchmark comparisons of several defenses against TTE, RE, and backdoor DP\nattacks on images. The paper concludes with a discussion of future work.\n", "versions": [{"version": "v1", "created": "Fri, 12 Apr 2019 16:05:21 GMT"}, {"version": "v2", "created": "Mon, 13 May 2019 17:15:49 GMT"}, {"version": "v3", "created": "Mon, 2 Dec 2019 22:49:28 GMT"}], "update_date": "2020-03-11", "authors_parsed": [["Miller", "David J.", ""], ["Xiang", "Zhen", ""], ["Kesidis", "George", ""]]}, {"id": "1904.06307", "submitter": "Shikui Tu", "authors": "Wenjing Huang, Shikui Tu and Lei Xu", "title": "Revisit Lmser and its further development based on convolutional layers", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Proposed in 1991, Least Mean Square Error Reconstruction for self-organizing\nnetwork, shortly Lmser, was a further development of the traditional\nauto-encoder (AE) by folding the architecture with respect to the central\ncoding layer and thus leading to the features of symmetric weights and neurons,\nas well as jointly supervised and unsupervised learning. However, its\nadvantages were only demonstrated in a one-hidden-layer implementation due to\nthe lack of computing resources and big data at that time. In this paper, we\nrevisit Lmser from the perspective of deep learning, develop Lmser network\nbased on multiple convolutional layers, which is more suitable for\nimage-related tasks, and confirm several Lmser functions with preliminary\ndemonstrations on image recognition, reconstruction, association recall, and so\non. Experiments demonstrate that Lmser indeed works as indicated in the\noriginal paper, and it has promising performance in various applications.\n", "versions": [{"version": "v1", "created": "Fri, 12 Apr 2019 16:26:04 GMT"}], "update_date": "2019-04-15", "authors_parsed": [["Huang", "Wenjing", ""], ["Tu", "Shikui", ""], ["Xu", "Lei", ""]]}, {"id": "1904.06309", "submitter": "Yuanhao Wang", "authors": "Yuanhao Wang, Jiachen Hu, Xiaoyu Chen, Liwei Wang", "title": "Distributed Bandit Learning: Near-Optimal Regret with Efficient\n  Communication", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the problem of regret minimization for distributed bandits learning,\nin which $M$ agents work collaboratively to minimize their total regret under\nthe coordination of a central server. Our goal is to design communication\nprotocols with near-optimal regret and little communication cost, which is\nmeasured by the total amount of transmitted data. For distributed multi-armed\nbandits, we propose a protocol with near-optimal regret and only $O(M\\log(MK))$\ncommunication cost, where $K$ is the number of arms. The communication cost is\nindependent of the time horizon $T$, has only logarithmic dependence on the\nnumber of arms, and matches the lower bound except for a logarithmic factor.\nFor distributed $d$-dimensional linear bandits, we propose a protocol that\nachieves near-optimal regret and has communication cost of order\n$\\tilde{O}(Md)$, which has only logarithmic dependence on $T$.\n", "versions": [{"version": "v1", "created": "Fri, 12 Apr 2019 16:32:17 GMT"}, {"version": "v2", "created": "Wed, 29 May 2019 02:05:10 GMT"}], "update_date": "2019-05-30", "authors_parsed": [["Wang", "Yuanhao", ""], ["Hu", "Jiachen", ""], ["Chen", "Xiaoyu", ""], ["Wang", "Liwei", ""]]}, {"id": "1904.06312", "submitter": "Kaleigh Clary", "authors": "Kaleigh Clary, Emma Tosch, John Foley, and David Jensen", "title": "Let's Play Again: Variability of Deep Reinforcement Learning Agents in\n  Atari Environments", "comments": "NeurIPS 2018 Critiquing and Correcting Trends Workshop", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Reproducibility in reinforcement learning is challenging: uncontrolled\nstochasticity from many sources, such as the learning algorithm, the learned\npolicy, and the environment itself have led researchers to report the\nperformance of learned agents using aggregate metrics of performance over\nmultiple random seeds for a single environment. Unfortunately, there are still\npernicious sources of variability in reinforcement learning agents that make\nreporting common summary statistics an unsound metric for performance. Our\nexperiments demonstrate the variability of common agents used in the popular\nOpenAI Baselines repository. We make the case for reporting post-training agent\nperformance as a distribution, rather than a point estimate.\n", "versions": [{"version": "v1", "created": "Fri, 12 Apr 2019 16:37:52 GMT"}], "update_date": "2019-04-15", "authors_parsed": [["Clary", "Kaleigh", ""], ["Tosch", "Emma", ""], ["Foley", "John", ""], ["Jensen", "David", ""]]}, {"id": "1904.06314", "submitter": "Florent Avellaneda", "authors": "Florent Avellaneda", "title": "Learning Optimal Decision Trees from Large Datasets", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Inferring a decision tree from a given dataset is one of the classic problems\nin machine learning. This problem consists of buildings, from a labelled\ndataset, a tree such that each node corresponds to a class and a path between\nthe tree root and a leaf corresponds to a conjunction of features to be\nsatisfied in this class. Following the principle of parsimony, we want to infer\na minimal tree consistent with the dataset. Unfortunately, inferring an optimal\ndecision tree is known to be NP-complete for several definitions of optimality.\nHence, the majority of existing approaches relies on heuristics, and as for the\nfew exact inference approaches, they do not work on large data sets. In this\npaper, we propose a novel approach for inferring a decision tree of a minimum\ndepth based on the incremental generation of Boolean formula. The experimental\nresults indicate that it scales sufficiently well and the time it takes to run\ngrows slowly with the size of dataset.\n", "versions": [{"version": "v1", "created": "Fri, 12 Apr 2019 16:44:10 GMT"}], "update_date": "2019-04-15", "authors_parsed": [["Avellaneda", "Florent", ""]]}, {"id": "1904.06316", "submitter": "Felix Opolka", "authors": "Felix L. Opolka, Aaron Solomon, C\\u{a}t\\u{a}lina Cangea, Petar\n  Veli\\v{c}kovi\\'c, Pietro Li\\`o, R Devon Hjelm", "title": "Spatio-Temporal Deep Graph Infomax", "comments": "6 pages, 2 figures, Representation Learning on Graphs and Manifolds\n  Workshop of the International Conference on Learning Representations (ICLR)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Spatio-temporal graphs such as traffic networks or gene regulatory systems\npresent challenges for the existing deep learning methods due to the complexity\nof structural changes over time. To address these issues, we introduce\nSpatio-Temporal Deep Graph Infomax (STDGI)---a fully unsupervised node\nrepresentation learning approach based on mutual information maximization that\nexploits both the temporal and spatial dynamics of the graph. Our model tackles\nthe challenging task of node-level regression by training embeddings to\nmaximize the mutual information between patches of the graph, at any given time\nstep, and between features of the central nodes of patches, in the future. We\ndemonstrate through experiments and qualitative studies that the learned\nrepresentations can successfully encode relevant information about the input\ngraph and improve the predictive performance of spatio-temporal auto-regressive\nforecasting models.\n", "versions": [{"version": "v1", "created": "Fri, 12 Apr 2019 16:47:30 GMT"}], "update_date": "2019-04-15", "authors_parsed": [["Opolka", "Felix L.", ""], ["Solomon", "Aaron", ""], ["Cangea", "C\u0103t\u0103lina", ""], ["Veli\u010dkovi\u0107", "Petar", ""], ["Li\u00f2", "Pietro", ""], ["Hjelm", "R Devon", ""]]}, {"id": "1904.06330", "submitter": "Isidro Cortes-Ciriano PhD", "authors": "Isidro Cortes-Ciriano and Andreas Bender", "title": "Reliable Prediction Errors for Deep Neural Networks Using Test-Time\n  Dropout", "comments": null, "journal-ref": null, "doi": "10.1021/acs.jcim.9b00297", "report-no": null, "categories": "cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  While the use of deep learning in drug discovery is gaining increasing\nattention, the lack of methods to compute reliable errors in prediction for\nNeural Networks prevents their application to guide decision making in domains\nwhere identifying unreliable predictions is essential, e.g. precision medicine.\nHere, we present a framework to compute reliable errors in prediction for\nNeural Networks using Test-Time Dropout and Conformal Prediction. Specifically,\nthe algorithm consists of training a single Neural Network using dropout, and\nthen applying it N times to both the validation and test sets, also employing\ndropout in this step. Therefore, for each instance in the validation and test\nsets an ensemble of predictions were generated. The residuals and absolute\nerrors in prediction for the validation set were then used to compute\nprediction errors for test set instances using Conformal Prediction. We show\nusing 24 bioactivity data sets from ChEMBL 23 that dropout Conformal Predictors\nare valid (i.e., the fraction of instances whose true value lies within the\npredicted interval strongly correlates with the confidence level) and\nefficient, as the predicted confidence intervals span a narrower set of values\nthan those computed with Conformal Predictors generated using Random Forest\n(RF) models. Lastly, we show in retrospective virtual screening experiments\nthat dropout and RF-based Conformal Predictors lead to comparable retrieval\nrates of active compounds. Overall, we propose a computationally efficient\nframework (as only N extra forward passes are required in addition to training\na single network) to harness Test-Time Dropout and the Conformal Prediction\nframework, and to thereby generate reliable prediction errors for deep Neural\nNetworks.\n", "versions": [{"version": "v1", "created": "Fri, 12 Apr 2019 17:18:08 GMT"}], "update_date": "2019-06-25", "authors_parsed": [["Cortes-Ciriano", "Isidro", ""], ["Bender", "Andreas", ""]]}, {"id": "1904.06345", "submitter": "Adrian Bulat", "authors": "Adrian Bulat and Jean Kossaifi and Georgios Tzimiropoulos and Maja\n  Pantic", "title": "Incremental multi-domain learning with network latent tensor\n  factorization", "comments": "AAAI20", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The prominence of deep learning, large amount of annotated data and\nincreasingly powerful hardware made it possible to reach remarkable performance\nfor supervised classification tasks, in many cases saturating the training\nsets. However the resulting models are specialized to a single very specific\ntask and domain. Adapting the learned classification to new domains is a hard\nproblem due to at least three reasons: (1) the new domains and the tasks might\nbe drastically different; (2) there might be very limited amount of annotated\ndata on the new domain and (3) full training of a new model for each new task\nis prohibitive in terms of computation and memory, due to the sheer number of\nparameters of deep CNNs. In this paper, we present a method to learn\nnew-domains and tasks incrementally, building on prior knowledge from already\nlearned tasks and without catastrophic forgetting. We do so by jointly\nparametrizing weights across layers using low-rank Tucker structure. The core\nis task agnostic while a set of task specific factors are learnt on each new\ndomain. We show that leveraging tensor structure enables better performance\nthan simply using matrix operations. Joint tensor modelling also naturally\nleverages correlations across different layers. Compared with previous methods\nwhich have focused on adapting each layer separately, our approach results in\nmore compact representations for each new task/domain. We apply the proposed\nmethod to the 10 datasets of the Visual Decathlon Challenge and show that our\nmethod offers on average about 7.5x reduction in number of parameters and\ncompetitive performance in terms of both classification accuracy and Decathlon\nscore.\n", "versions": [{"version": "v1", "created": "Fri, 12 Apr 2019 17:57:05 GMT"}, {"version": "v2", "created": "Fri, 22 Nov 2019 14:04:15 GMT"}], "update_date": "2019-11-25", "authors_parsed": [["Bulat", "Adrian", ""], ["Kossaifi", "Jean", ""], ["Tzimiropoulos", "Georgios", ""], ["Pantic", "Maja", ""]]}, {"id": "1904.06366", "submitter": "Ranjan Maitra", "authors": "Yifan Zhu and Fan Dai and Ranjan Maitra", "title": "Fully Three-dimensional Radial Visualization", "comments": "7 pages, 5 figures, 1 table", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We develop methodology for three-dimensional (3D) radial visualization\n(RadViz) of multidimensional datasets. Our tool is called RadViz3D and extends\nthe classical two-dimensional (2D) RadViz that visualizes multivariate data in\nthe 2D plane by mapping every observation to a point inside the unit circle. We\nshow that distributing anchor points uniformly on the 3D unit sphere provides\nthe best visualization with minimal artificial visual correlation for data with\nuncorrelated variables. However, anchor points can be placed exactly\nequi-distant from each other only for the five Platonic solids. We provide\nequi-distant anchor points for these five settings, and approximately\nequi-distant anchor points via a Fibonacci grid for the other cases. Our\nmethodology, implemented in the R package $radviz3d$, makes fully 3D RadViz\npossible and is shown to improve clarity of this nonlinear display technique on\nsimulated and real datasets.\n", "versions": [{"version": "v1", "created": "Sat, 6 Apr 2019 21:24:39 GMT"}, {"version": "v2", "created": "Sun, 28 Mar 2021 02:15:07 GMT"}, {"version": "v3", "created": "Mon, 28 Jun 2021 13:59:02 GMT"}], "update_date": "2021-06-29", "authors_parsed": [["Zhu", "Yifan", ""], ["Dai", "Fan", ""], ["Maitra", "Ranjan", ""]]}, {"id": "1904.06387", "submitter": "Daniel Brown", "authors": "Daniel S. Brown, Wonjoon Goo, Prabhat Nagarajan, Scott Niekum", "title": "Extrapolating Beyond Suboptimal Demonstrations via Inverse Reinforcement\n  Learning from Observations", "comments": "In proceedings of Thirty-sixth International Conference on Machine\n  Learning (ICML 2019)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A critical flaw of existing inverse reinforcement learning (IRL) methods is\ntheir inability to significantly outperform the demonstrator. This is because\nIRL typically seeks a reward function that makes the demonstrator appear\nnear-optimal, rather than inferring the underlying intentions of the\ndemonstrator that may have been poorly executed in practice. In this paper, we\nintroduce a novel reward-learning-from-observation algorithm, Trajectory-ranked\nReward EXtrapolation (T-REX), that extrapolates beyond a set of (approximately)\nranked demonstrations in order to infer high-quality reward functions from a\nset of potentially poor demonstrations. When combined with deep reinforcement\nlearning, T-REX outperforms state-of-the-art imitation learning and IRL methods\non multiple Atari and MuJoCo benchmark tasks and achieves performance that is\noften more than twice the performance of the best demonstration. We also\ndemonstrate that T-REX is robust to ranking noise and can accurately\nextrapolate intention by simply watching a learner noisily improve at a task\nover time.\n", "versions": [{"version": "v1", "created": "Fri, 12 Apr 2019 19:34:43 GMT"}, {"version": "v2", "created": "Tue, 14 May 2019 13:48:50 GMT"}, {"version": "v3", "created": "Sat, 1 Jun 2019 22:39:47 GMT"}, {"version": "v4", "created": "Tue, 18 Jun 2019 17:46:49 GMT"}, {"version": "v5", "created": "Tue, 9 Jul 2019 03:51:47 GMT"}], "update_date": "2019-07-10", "authors_parsed": [["Brown", "Daniel S.", ""], ["Goo", "Wonjoon", ""], ["Nagarajan", "Prabhat", ""], ["Niekum", "Scott", ""]]}, {"id": "1904.06395", "submitter": "Luis Lastras", "authors": "Luis A. Lastras", "title": "Information Theoretic Lower Bounds on Negative Log Likelihood", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.IT math.IT stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this article we use rate-distortion theory, a branch of information theory\ndevoted to the problem of lossy compression, to shed light on an important\nproblem in latent variable modeling of data: is there room to improve the\nmodel? One way to address this question is to find an upper bound on the\nprobability (equivalently a lower bound on the negative log likelihood) that\nthe model can assign to some data as one varies the prior and/or the likelihood\nfunction in a latent variable model. The core of our contribution is to\nformally show that the problem of optimizing priors in latent variable models\nis exactly an instance of the variational optimization problem that information\ntheorists solve when computing rate-distortion functions, and then to use this\nto derive a lower bound on negative log likelihood. Moreover, we will show that\nif changing the prior can improve the log likelihood, then there is a way to\nchange the likelihood function instead and attain the same log likelihood, and\nthus rate-distortion theory is of relevance to both optimizing priors as well\nas optimizing likelihood functions. We will experimentally argue for the\nusefulness of quantities derived from rate-distortion theory in latent variable\nmodeling by applying them to a problem in image modeling.\n", "versions": [{"version": "v1", "created": "Fri, 12 Apr 2019 20:03:33 GMT"}], "update_date": "2019-04-17", "authors_parsed": [["Lastras", "Luis A.", ""]]}, {"id": "1904.06396", "submitter": "Valentin De Bortoli", "authors": "De Bortoli Valentin, Desolneux Agn\\`es, Galerne Bruno, Leclaire Arthur", "title": "Macrocanonical Models for Texture Synthesis", "comments": "Accepted to Scale Space and Variational Methods in Computer Vision\n  2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this article we consider macrocanonical models for texture synthesis. In\nthese models samples are generated given an input texture image and a set of\nfeatures which should be matched in expectation. It is known that if the images\nare quantized, macrocanonical models are given by Gibbs measures, using the\nmaximum entropy principle. We study conditions under which this result extends\nto real-valued images. If these conditions hold, finding a macrocanonical model\namounts to minimizing a convex function and sampling from an associated Gibbs\nmeasure. We analyze an algorithm which alternates between sampling and\nminimizing. We present experiments with neural network features and study the\ndrawbacks and advantages of using this sampling scheme.\n", "versions": [{"version": "v1", "created": "Fri, 12 Apr 2019 20:08:39 GMT"}], "update_date": "2019-04-16", "authors_parsed": [["Valentin", "De Bortoli", ""], ["Agn\u00e8s", "Desolneux", ""], ["Bruno", "Galerne", ""], ["Arthur", "Leclaire", ""]]}, {"id": "1904.06400", "submitter": "Jianguo Chen", "authors": "Jianguo Chen, Kenli Li, Qingying Deng, Keqin Li, Philip S. Yu", "title": "Distributed Deep Learning Model for Intelligent Video Surveillance\n  Systems with Edge Computing", "comments": "IEEE Transactions on Industrial Informatics. 2019", "journal-ref": null, "doi": "10.1109/TII.2019.2909473", "report-no": null, "categories": "cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we propose a Distributed Intelligent Video Surveillance (DIVS)\nsystem using Deep Learning (DL) algorithms and deploy it in an edge computing\nenvironment. We establish a multi-layer edge computing architecture and a\ndistributed DL training model for the DIVS system. The DIVS system can migrate\ncomputing workloads from the network center to network edges to reduce huge\nnetwork communication overhead and provide low-latency and accurate video\nanalysis solutions. We implement the proposed DIVS system and address the\nproblems of parallel training, model synchronization, and workload balancing.\nTask-level parallel and model-level parallel training methods are proposed to\nfurther accelerate the video analysis process. In addition, we propose a model\nparameter updating method to achieve model synchronization of the global DL\nmodel in a distributed EC environment. Moreover, a dynamic data migration\napproach is proposed to address the imbalance of workload and computational\npower of edge nodes. Experimental results showed that the EC architecture can\nprovide elastic and scalable computing power, and the proposed DIVS system can\nefficiently handle video surveillance and analysis tasks.\n", "versions": [{"version": "v1", "created": "Fri, 12 Apr 2019 20:17:05 GMT"}], "update_date": "2019-11-26", "authors_parsed": [["Chen", "Jianguo", ""], ["Li", "Kenli", ""], ["Deng", "Qingying", ""], ["Li", "Keqin", ""], ["Yu", "Philip S.", ""]]}, {"id": "1904.06442", "submitter": "Qiyao Wang", "authors": "Qiyao Wang, Shuai Zheng, Ahmed Farahat, Susumu Serita, Chetan Gupta", "title": "Remaining Useful Life Estimation Using Functional Data Analysis", "comments": "Accepted by IEEE International Conference on Prognostics and Health\n  Management 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Remaining Useful Life (RUL) of an equipment or one of its components is\ndefined as the time left until the equipment or component reaches its end of\nuseful life. Accurate RUL estimation is exceptionally beneficial to Predictive\nMaintenance, and Prognostics and Health Management (PHM). Data driven\napproaches which leverage the power of algorithms for RUL estimation using\nsensor and operational time series data are gaining popularity. Existing\nalgorithms, such as linear regression, Convolutional Neural Network (CNN),\nHidden Markov Models (HMMs), and Long Short-Term Memory (LSTM), have their own\nlimitations for the RUL estimation task. In this work, we propose a novel\nFunctional Data Analysis (FDA) method called functional Multilayer Perceptron\n(functional MLP) for RUL estimation. Functional MLP treats time series data\nfrom multiple equipment as a sample of random continuous processes over time.\nFDA explicitly incorporates both the correlations within the same equipment and\nthe random variations across different equipment's sensor time series into the\nmodel. FDA also has the benefit of allowing the relationship between RUL and\nsensor variables to vary over time. We implement functional MLP on the\nbenchmark NASA C-MAPSS data and evaluate the performance using two\npopularly-used metrics. Results show the superiority of our algorithm over all\nthe other state-of-the-art methods.\n", "versions": [{"version": "v1", "created": "Fri, 12 Apr 2019 22:48:49 GMT"}], "update_date": "2019-04-16", "authors_parsed": [["Wang", "Qiyao", ""], ["Zheng", "Shuai", ""], ["Farahat", "Ahmed", ""], ["Serita", "Susumu", ""], ["Gupta", "Chetan", ""]]}, {"id": "1904.06449", "submitter": "Ryan Rossi", "authors": "John Boaz Lee, Giang Nguyen, Ryan A. Rossi, Nesreen K. Ahmed, Eunyee\n  Koh, and Sungchul Kim", "title": "Dynamic Node Embeddings from Edge Streams", "comments": "IEEE Transactions on Emerging Topics in Computational Intelligence\n  (TETIC)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.SI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Networks evolve continuously over time with the addition, deletion, and\nchanging of links and nodes. Such temporal networks (or edge streams) consist\nof a sequence of timestamped edges and are seemingly ubiquitous. Despite the\nimportance of accurately modeling the temporal information, most embedding\nmethods ignore it entirely or approximate the temporal network using a sequence\nof static snapshot graphs. In this work, we propose using the notion of\ntemporal walks for learning dynamic embeddings from temporal networks. Temporal\nwalks capture the temporally valid interactions (e.g., flow of information,\nspread of disease) in the dynamic network in a lossless fashion. Based on the\nnotion of temporal walks, we describe a general class of embeddings called\ncontinuous-time dynamic network embeddings (CTDNEs) that completely avoid the\nissues and problems that arise when approximating the temporal network as a\nsequence of static snapshot graphs. Unlike previous work, CTDNEs learn dynamic\nnode embeddings directly from the temporal network at the finest temporal\ngranularity and thus use only temporally valid information. As such CTDNEs\nnaturally support online learning of the node embeddings in a streaming\nreal-time fashion. Finally, the experiments demonstrate the effectiveness of\nthis class of embedding methods that leverage temporal walks as it achieves an\naverage gain in AUC of 11.9% across all methods and graphs.\n", "versions": [{"version": "v1", "created": "Fri, 12 Apr 2019 23:44:25 GMT"}, {"version": "v2", "created": "Fri, 17 Jul 2020 15:44:02 GMT"}], "update_date": "2020-07-20", "authors_parsed": [["Lee", "John Boaz", ""], ["Nguyen", "Giang", ""], ["Rossi", "Ryan A.", ""], ["Ahmed", "Nesreen K.", ""], ["Koh", "Eunyee", ""], ["Kim", "Sungchul", ""]]}, {"id": "1904.06483", "submitter": "Daniel Pfeifer", "authors": "Daniel Pfeifer and Jochen L. Leidner", "title": "Topic Grouper: An Agglomerative Clustering Approach to Topic Modeling", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce Topic Grouper as a complementary approach in the field of\nprobabilistic topic modeling. Topic Grouper creates a disjunctive partitioning\nof the training vocabulary in a stepwise manner such that resulting partitions\nrepresent topics. It is governed by a simple generative model, where the\nlikelihood to generate the training documents via topics is optimized. The\nalgorithm starts with one-word topics and joins two topics at every step. It\ntherefore generates a solution for every desired number of topics ranging\nbetween the size of the training vocabulary and one. The process represents an\nagglomerative clustering that corresponds to a binary tree of topics. A\nresulting tree may act as a containment hierarchy, typically with more general\ntopics towards the root of tree and more specific topics towards the leaves.\nTopic Grouper is not governed by a background distribution such as the\nDirichlet and avoids hyper parameter optimizations.\n  We show that Topic Grouper has reasonable predictive power and also a\nreasonable theoretical and practical complexity. Topic Grouper can deal well\nwith stop words and function words and tends to push them into their own\ntopics. Also, it can handle topic distributions, where some topics are more\nfrequent than others. We present typical examples of computed topics from\nevaluation datasets, where topics appear conclusive and coherent. In this\ncontext, the fact that each word belongs to exactly one topic is not a major\nlimitation; in some scenarios this can even be a genuine advantage, e.g.~a\nrelated shopping basket analysis may aid in optimizing groupings of articles in\nsales catalogs.\n", "versions": [{"version": "v1", "created": "Sat, 13 Apr 2019 05:06:18 GMT"}], "update_date": "2019-04-16", "authors_parsed": [["Pfeifer", "Daniel", ""], ["Leidner", "Jochen L.", ""]]}, {"id": "1904.06491", "submitter": "Chandan Gautam", "authors": "Chandan Gautam, Aruna Tiwari, M. Tanveer", "title": "Graph-Embedded Multi-layer Kernel Extreme Learning Machine for One-class\n  Classification or (Graph-Embedded Multi-layer Kernel Ridge Regression for\n  One-class Classification)", "comments": "arXiv admin note: substantial text overlap with arXiv:1805.07808", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A brain can detect outlier just by using only normal samples. Similarly,\none-class classification (OCC) also uses only normal samples to train the model\nand trained model can be used for outlier detection. In this paper, a\nmulti-layer architecture for OCC is proposed by stacking various Graph-Embedded\nKernel Ridge Regression (KRR) based Auto-Encoders in a hierarchical fashion.\nThese Auto-Encoders are formulated under two types of Graph-Embedding, namely,\nlocal and global variance-based embedding. This Graph-Embedding explores the\nrelationship between samples and multi-layers of Auto-Encoder project the input\nfeatures into new feature space. The last layer of this proposed architecture\nis Graph-Embedded regression-based one-class classifier. The Auto-Encoders use\nan unsupervised approach of learning and the final layer uses semi-supervised\n(trained by only positive samples and obtained closed-form solution) approach\nto learning. The proposed method is experimentally evaluated on 21 publicly\navailable benchmark datasets. Experimental results verify the effectiveness of\nthe proposed one-class classifiers over 11 existing state-of-the-art\nkernel-based one-class classifiers. Friedman test is also performed to verify\nthe statistical significance of the claim of the superiority of the proposed\none-class classifiers over the existing state-of-the-art methods. By using two\ntypes of Graph-Embedding, 4 variants of Graph-Embedded multi-layer KRR-based\none-class classifier has been presented in this paper. All 4 variants performed\nbetter than the existing one-class classifiers in terms of various discussed\ncriteria in this paper. Hence, it can be a viable alternative for OCC task. In\nthe future, various other types of Auto-Encoders can be explored within\nproposed architecture.\n", "versions": [{"version": "v1", "created": "Sat, 13 Apr 2019 06:37:34 GMT"}], "update_date": "2019-04-16", "authors_parsed": [["Gautam", "Chandan", ""], ["Tiwari", "Aruna", ""], ["Tanveer", "M.", ""]]}, {"id": "1904.06501", "submitter": "Badong Chen", "authors": "Badong Chen, Xin Wang, Yingsong Li, Jose C. Principe", "title": "Maximum Correntropy Criterion with Variable Center", "comments": "5 pages, 1 figure", "journal-ref": null, "doi": "10.1109/LSP.2019.2925692", "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Correntropy is a local similarity measure defined in kernel space and the\nmaximum correntropy criterion (MCC) has been successfully applied in many areas\nof signal processing and machine learning in recent years. The kernel function\nin correntropy is usually restricted to the Gaussian function with center\nlocated at zero. However, zero-mean Gaussian function may not be a good choice\nfor many practical applications. In this study, we propose an extended version\nof correntropy, whose center can locate at any position. Accordingly, we\npropose a new optimization criterion called maximum correntropy criterion with\nvariable center (MCC-VC). We also propose an efficient approach to optimize the\nkernel width and center location in MCC-VC. Simulation results of regression\nwith linear in parameters (LIP) models confirm the desirable performance of the\nnew method.\n", "versions": [{"version": "v1", "created": "Sat, 13 Apr 2019 07:49:54 GMT"}], "update_date": "2019-07-24", "authors_parsed": [["Chen", "Badong", ""], ["Wang", "Xin", ""], ["Li", "Yingsong", ""], ["Principe", "Jose C.", ""]]}, {"id": "1904.06508", "submitter": "Tao Tu", "authors": "Tao Tu, Yuan-Jui Chen, Cheng-chieh Yeh, Hung-yi Lee", "title": "End-to-end Text-to-speech for Low-resource Languages by Cross-Lingual\n  Transfer Learning", "comments": "Accepted to Interspeech 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG cs.SD eess.AS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  End-to-end text-to-speech (TTS) has shown great success on large quantities\nof paired text plus speech data. However, laborious data collection remains\ndifficult for at least 95% of the languages over the world, which hinders the\ndevelopment of TTS in different languages. In this paper, we aim to build TTS\nsystems for such low-resource (target) languages where only very limited paired\ndata are available. We show such TTS can be effectively constructed by\ntransferring knowledge from a high-resource (source) language. Since the model\ntrained on source language cannot be directly applied to target language due to\ninput space mismatch, we propose a method to learn a mapping between source and\ntarget linguistic symbols. Benefiting from this learned mapping, pronunciation\ninformation can be preserved throughout the transferring procedure. Preliminary\nexperiments show that we only need around 15 minutes of paired data to obtain a\nrelatively good TTS system. Furthermore, analytic studies demonstrated that the\nautomatically discovered mapping correlate well with the phonetic expertise.\n", "versions": [{"version": "v1", "created": "Sat, 13 Apr 2019 08:51:11 GMT"}, {"version": "v2", "created": "Tue, 2 Jul 2019 07:43:40 GMT"}], "update_date": "2019-07-03", "authors_parsed": [["Tu", "Tao", ""], ["Chen", "Yuan-Jui", ""], ["Yeh", "Cheng-chieh", ""], ["Lee", "Hung-yi", ""]]}, {"id": "1904.06513", "submitter": "Baogui Xin", "authors": "Baogui Xin and Wei Peng", "title": "An Integrated Autoencoder-Based Filter for Sparse Big Data", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a novel filter for sparse big data, called an integrated\nautoencoder (IAE), which utilizes auxiliary information to mitigate data\nsparsity. The proposed model achieves an appropriate balance between prediction\naccuracy, convergence speed, and complexity. We implement experiments on a GPS\ntrajectory dataset, and the results demonstrate that the IAE is more accurate\nand robust than some state-of-the-art methods.\n", "versions": [{"version": "v1", "created": "Sat, 13 Apr 2019 09:53:27 GMT"}, {"version": "v2", "created": "Fri, 14 Jun 2019 00:30:27 GMT"}], "update_date": "2019-06-17", "authors_parsed": [["Xin", "Baogui", ""], ["Peng", "Wei", ""]]}, {"id": "1904.06517", "submitter": "Marta Stepniewska-Dziubinska", "authors": "Marta M. Stepniewska-Dziubinska, Piotr Zielenkiewicz and Pawel\n  Siedlecki", "title": "Improving detection of protein-ligand binding sites with 3D segmentation", "comments": null, "journal-ref": "Sci Rep 10, 5035 (2020)", "doi": "10.1038/s41598-020-61860-z", "report-no": null, "categories": "q-bio.BM cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In recent years machine learning (ML) took bio- and cheminformatics fields by\nstorm, providing new solutions for a vast repertoire of problems related to\nprotein sequence, structure, and interactions analysis. ML techniques, deep\nneural networks especially, were proven more effective than classical models\nfor tasks like predicting binding affinity for molecular complex. In this work\nwe investigated the earlier stage of drug discovery process - finding druggable\npockets on protein surface, that can be later used to design active molecules.\nFor this purpose we developed a 3D fully convolutional neural network capable\nof binding site segmentation. Our solution has high prediction accuracy and\nprovides intuitive representations of the results, which makes it easy to\nincorporate into drug discovery projects. The model's source code, together\nwith scripts for most common use-cases is freely available at\nhttp://gitlab.com/cheminfIBB/kalasanty\n", "versions": [{"version": "v1", "created": "Sat, 13 Apr 2019 10:10:55 GMT"}, {"version": "v2", "created": "Sat, 28 Mar 2020 13:26:25 GMT"}], "update_date": "2020-03-31", "authors_parsed": [["Stepniewska-Dziubinska", "Marta M.", ""], ["Zielenkiewicz", "Piotr", ""], ["Siedlecki", "Pawel", ""]]}, {"id": "1904.06539", "submitter": "Yong-Lu Li", "authors": "Yong-Lu Li, Liang Xu, Xinpeng Liu, Xijie Huang, Yue Xu, Mingyang Chen,\n  Ze Ma, Shiyi Wang, Hao-Shu Fang, Cewu Lu", "title": "HAKE: Human Activity Knowledge Engine", "comments": "Work in progress. Project website: http://hake-mvig.cn", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Human activity understanding is crucial for building automatic intelligent\nsystem. With the help of deep learning, activity understanding has made huge\nprogress recently. But some challenges such as imbalanced data distribution,\naction ambiguity, complex visual patterns still remain. To address these and\npromote the activity understanding, we build a large-scale Human Activity\nKnowledge Engine (HAKE) based on the human body part states. Upon existing\nactivity datasets, we annotate the part states of all the active persons in all\nimages, thus establish the relationship between instance activity and body part\nstates. Furthermore, we propose a HAKE based part state recognition model with\na knowledge extractor named Activity2Vec and a corresponding part state based\nreasoning network. With HAKE, our method can alleviate the learning difficulty\nbrought by the long-tail data distribution, and bring in interpretability. Now\nour HAKE has more than 7 M+ part state annotations and is still under\nconstruction. We first validate our approach on a part of HAKE in this\npreliminary paper, where we show 7.2 mAP performance improvement on\nHuman-Object Interaction recognition, and 12.38 mAP improvement on the one-shot\nsubsets.\n", "versions": [{"version": "v1", "created": "Sat, 13 Apr 2019 12:56:17 GMT"}, {"version": "v2", "created": "Wed, 8 May 2019 17:18:11 GMT"}, {"version": "v3", "created": "Fri, 19 Jul 2019 16:00:12 GMT"}, {"version": "v4", "created": "Sat, 3 Aug 2019 07:47:43 GMT"}, {"version": "v5", "created": "Tue, 6 Aug 2019 12:47:41 GMT"}], "update_date": "2019-08-07", "authors_parsed": [["Li", "Yong-Lu", ""], ["Xu", "Liang", ""], ["Liu", "Xinpeng", ""], ["Huang", "Xijie", ""], ["Xu", "Yue", ""], ["Chen", "Mingyang", ""], ["Ma", "Ze", ""], ["Wang", "Shiyi", ""], ["Fang", "Hao-Shu", ""], ["Lu", "Cewu", ""]]}, {"id": "1904.06546", "submitter": "Bowen Zhao", "authors": "Bowen Zhao, Xi Xiao, Wanpeng Zhang, Bin Zhang, Shutao Xia", "title": "Self-Paced Probabilistic Principal Component Analysis for Data with\n  Outliers", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Principal Component Analysis (PCA) is a popular tool for dimensionality\nreduction and feature extraction in data analysis. There is a probabilistic\nversion of PCA, known as Probabilistic PCA (PPCA). However, standard PCA and\nPPCA are not robust, as they are sensitive to outliers. To alleviate this\nproblem, this paper introduces the Self-Paced Learning mechanism into PPCA, and\nproposes a novel method called Self-Paced Probabilistic Principal Component\nAnalysis (SP-PPCA). Furthermore, we design the corresponding optimization\nalgorithm based on the alternative search strategy and the\nexpectation-maximization algorithm. SP-PPCA looks for optimal projection\nvectors and filters out outliers iteratively. Experiments on both synthetic\nproblems and real-world datasets clearly demonstrate that SP-PPCA is able to\nreduce or eliminate the impact of outliers.\n", "versions": [{"version": "v1", "created": "Sat, 13 Apr 2019 13:32:30 GMT"}], "update_date": "2019-04-16", "authors_parsed": [["Zhao", "Bowen", ""], ["Xiao", "Xi", ""], ["Zhang", "Wanpeng", ""], ["Zhang", "Bin", ""], ["Xia", "Shutao", ""]]}, {"id": "1904.06578", "submitter": "S. Mohammad H. Hashemi", "authors": "S. Mohammad H. Hashemi, Demetri Psaltis", "title": "Deep-learning PDEs with unlabeled data and hardwiring physics laws", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "physics.comp-ph cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Providing fast and accurate solutions to partial differential equations is a\nproblem of continuous interest to the fields of applied mathematics and\nphysics. With the recent advances in machine learning, the adoption learning\ntechniques in this domain is being eagerly pursued. We build upon earlier works\non linear and homogeneous PDEs, and develop convolutional deep neural networks\nthat can accurately solve nonlinear and non-homogeneous equations without the\nneed for labeled data. The architecture of these networks is readily accessible\nfor scientific disciplines who deal with PDEs and know the basics of deep\nlearning.\n", "versions": [{"version": "v1", "created": "Sat, 13 Apr 2019 17:58:26 GMT"}], "update_date": "2019-04-16", "authors_parsed": [["Hashemi", "S. Mohammad H.", ""], ["Psaltis", "Demetri", ""]]}, {"id": "1904.06580", "submitter": "Anurag Ajay", "authors": "Anurag Ajay, Maria Bauza, Jiajun Wu, Nima Fazeli, Joshua B. Tenenbaum,\n  Alberto Rodriguez, Leslie P. Kaelbling", "title": "Combining Physical Simulators and Object-Based Networks for Control", "comments": "ICRA 2019; Project page: http://sain.csail.mit.edu", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Physics engines play an important role in robot planning and control;\nhowever, many real-world control problems involve complex contact dynamics that\ncannot be characterized analytically. Most physics engines therefore employ .\napproximations that lead to a loss in precision. In this paper, we propose a\nhybrid dynamics model, simulator-augmented interaction networks (SAIN),\ncombining a physics engine with an object-based neural network for dynamics\nmodeling. Compared with existing models that are purely analytical or purely\ndata-driven, our hybrid model captures the dynamics of interacting objects in a\nmore accurate and data-efficient manner.Experiments both in simulation and on a\nreal robot suggest that it also leads to better performance when used in\ncomplex control tasks. Finally, we show that our model generalizes to novel\nenvironments with varying object shapes and materials.\n", "versions": [{"version": "v1", "created": "Sat, 13 Apr 2019 18:08:11 GMT"}], "update_date": "2019-04-16", "authors_parsed": [["Ajay", "Anurag", ""], ["Bauza", "Maria", ""], ["Wu", "Jiajun", ""], ["Fazeli", "Nima", ""], ["Tenenbaum", "Joshua B.", ""], ["Rodriguez", "Alberto", ""], ["Kaelbling", "Leslie P.", ""]]}, {"id": "1904.06590", "submitter": "Eliya Nachmani", "authors": "Eliya Nachmani, Lior Wolf", "title": "Unsupervised Singing Voice Conversion", "comments": "Accepted to Interspeech 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.SD eess.AS stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a deep learning method for singing voice conversion. The proposed\nnetwork is not conditioned on the text or on the notes, and it directly\nconverts the audio of one singer to the voice of another. Training is performed\nwithout any form of supervision: no lyrics or any kind of phonetic features, no\nnotes, and no matching samples between singers. The proposed network employs a\nsingle CNN encoder for all singers, a single WaveNet decoder, and a classifier\nthat enforces the latent representation to be singer-agnostic. Each singer is\nrepresented by one embedding vector, which the decoder is conditioned on. In\norder to deal with relatively small datasets, we propose a new data\naugmentation scheme, as well as new training losses and protocols that are\nbased on backtranslation. Our evaluation presents evidence that the conversion\nproduces natural signing voices that are highly recognizable as the target\nsinger.\n", "versions": [{"version": "v1", "created": "Sat, 13 Apr 2019 20:07:58 GMT"}, {"version": "v2", "created": "Wed, 26 Jun 2019 14:56:38 GMT"}, {"version": "v3", "created": "Wed, 25 Sep 2019 14:39:49 GMT"}], "update_date": "2019-09-26", "authors_parsed": [["Nachmani", "Eliya", ""], ["Wolf", "Lior", ""]]}, {"id": "1904.06593", "submitter": "Guoliang Kang", "authors": "Guoliang Kang, Jun Li, Dacheng Tao", "title": "Shakeout: A New Approach to Regularized Deep Neural Network Training", "comments": "Appears at T-PAMI 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent years have witnessed the success of deep neural networks in dealing\nwith a plenty of practical problems. Dropout has played an essential role in\nmany successful deep neural networks, by inducing regularization in the model\ntraining. In this paper, we present a new regularized training approach:\nShakeout. Instead of randomly discarding units as Dropout does at the training\nstage, Shakeout randomly chooses to enhance or reverse each unit's contribution\nto the next layer. This minor modification of Dropout has the statistical\ntrait: the regularizer induced by Shakeout adaptively combines $L_0$, $L_1$ and\n$L_2$ regularization terms. Our classification experiments with representative\ndeep architectures on image datasets MNIST, CIFAR-10 and ImageNet show that\nShakeout deals with over-fitting effectively and outperforms Dropout. We\nempirically demonstrate that Shakeout leads to sparser weights under both\nunsupervised and supervised settings. Shakeout also leads to the grouping\neffect of the input units in a layer. Considering the weights in reflecting the\nimportance of connections, Shakeout is superior to Dropout, which is valuable\nfor the deep model compression. Moreover, we demonstrate that Shakeout can\neffectively reduce the instability of the training process of the deep\narchitecture.\n", "versions": [{"version": "v1", "created": "Sat, 13 Apr 2019 21:38:16 GMT"}], "update_date": "2019-04-16", "authors_parsed": [["Kang", "Guoliang", ""], ["Li", "Jun", ""], ["Tao", "Dacheng", ""]]}, {"id": "1904.06618", "submitter": "Md Kamrul Hasan", "authors": "Md Kamrul Hasan, Wasifur Rahman, Amir Zadeh, Jianyuan Zhong, Md\n  Iftekhar Tanveer, Louis-Philippe Morency, Mohammed (Ehsan) Hoque", "title": "UR-FUNNY: A Multimodal Language Dataset for Understanding Humor", "comments": null, "journal-ref": "EMNLP-IJCNLP, 2019, 2046-2056", "doi": "10.18653/v1/D19-1211", "report-no": null, "categories": "cs.LG cs.CL stat.ML", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Humor is a unique and creative communicative behavior displayed during social\ninteractions. It is produced in a multimodal manner, through the usage of words\n(text), gestures (vision) and prosodic cues (acoustic). Understanding humor\nfrom these three modalities falls within boundaries of multimodal language; a\nrecent research trend in natural language processing that models natural\nlanguage as it happens in face-to-face communication. Although humor detection\nis an established research area in NLP, in a multimodal context it is an\nunderstudied area. This paper presents a diverse multimodal dataset, called\nUR-FUNNY, to open the door to understanding multimodal language used in\nexpressing humor. The dataset and accompanying studies, present a framework in\nmultimodal humor detection for the natural language processing community.\nUR-FUNNY is publicly available for research.\n", "versions": [{"version": "v1", "created": "Sun, 14 Apr 2019 03:15:38 GMT"}], "update_date": "2020-07-02", "authors_parsed": [["Hasan", "Md Kamrul", "", "Ehsan"], ["Rahman", "Wasifur", "", "Ehsan"], ["Zadeh", "Amir", "", "Ehsan"], ["Zhong", "Jianyuan", "", "Ehsan"], ["Tanveer", "Md Iftekhar", "", "Ehsan"], ["Morency", "Louis-Philippe", "", "Ehsan"], ["Mohammed", "", "", "Ehsan"], ["Hoque", "", ""]]}, {"id": "1904.06632", "submitter": "Mansoor Sheikh", "authors": "M Sheikh, A.C.C. Coolen", "title": "Analysis of overfitting in the regularized Cox model", "comments": null, "journal-ref": null, "doi": "10.1088/1751-8121/ab375c", "report-no": null, "categories": "stat.ME cond-mat.dis-nn cs.LG math.ST stat.ML stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The Cox proportional hazards model is ubiquitous in the analysis of\ntime-to-event data. However, when the data dimension p is comparable to the\nsample size $N$, maximum likelihood estimates for its regression parameters are\nknown to be biased or break down entirely due to overfitting. This prompted the\nintroduction of the so-called regularized Cox model. In this paper we use the\nreplica method from statistical physics to investigate the relationship between\nthe true and inferred regression parameters in regularized multivariate Cox\nregression with L2 regularization, in the regime where both p and N are large\nbut with p/N ~ O(1). We thereby generalize a recent study from maximum\nlikelihood to maximum a posteriori inference. We also establish a relationship\nbetween the optimal regularization parameter and p/N, allowing for\nstraightforward overfitting corrections in time-to-event analysis.\n", "versions": [{"version": "v1", "created": "Sun, 14 Apr 2019 05:48:02 GMT"}, {"version": "v2", "created": "Thu, 25 Jul 2019 12:15:10 GMT"}], "update_date": "2020-01-08", "authors_parsed": [["Sheikh", "M", ""], ["Coolen", "A. C. C.", ""]]}, {"id": "1904.06633", "submitter": "Abhishek Joshi", "authors": "Abhishek Joshi, Vinay P. Namboodiri", "title": "Unsupervised Synthesis of Anomalies in Videos: Transforming the Normal", "comments": "Accepted in IJCNN 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Abnormal activity recognition requires detection of occurrence of anomalous\nevents that suffer from a severe imbalance in data. In a video, normal is used\nto describe activities that conform to usual events while the irregular events\nwhich do not conform to the normal are referred to as abnormal. It is far more\ncommon to observe normal data than to obtain abnormal data in visual\nsurveillance. In this paper, we propose an approach where we can obtain\nabnormal data by transforming normal data. This is a challenging task that is\nsolved through a multi-stage pipeline approach. We utilize a number of\ntechniques from unsupervised segmentation in order to synthesize new samples of\ndata that are transformed from an existing set of normal examples. Further,\nthis synthesis approach has useful applications as a data augmentation\ntechnique. An incrementally trained Bayesian convolutional neural network (CNN)\nis used to carefully select the set of abnormal samples that can be added.\nFinally through this synthesis approach we obtain a comparable set of abnormal\nsamples that can be used for training the CNN for the classification of normal\nvs abnormal samples. We show that this method generalizes to multiple settings\nby evaluating it on two real world datasets and achieves improved performance\nover other probabilistic techniques that have been used in the past for this\ntask.\n", "versions": [{"version": "v1", "created": "Sun, 14 Apr 2019 05:49:43 GMT"}], "update_date": "2019-04-16", "authors_parsed": [["Joshi", "Abhishek", ""], ["Namboodiri", "Vinay P.", ""]]}, {"id": "1904.06646", "submitter": "Zahra Zohrevand", "authors": "Zahra Zohrevand, Uwe Gl\\\"asser", "title": "Should I Raise The Red Flag? A comprehensive survey of anomaly scoring\n  methods toward mitigating false alarms", "comments": "arXiv admin note: text overlap with arXiv:1802.04431,\n  arXiv:1503.01158 by other authors", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Nowadays, advanced intrusion detection systems (IDSs) rely on a combination\nof anomaly detection and signature-based methods. An IDS gathers observations,\nanalyzes behavioral patterns, and reports suspicious events for further\ninvestigation. A notorious issue anomaly detection systems (ADSs) and IDSs face\nis the possibility of high false alarms, which even state-of-the-art systems\nhave not overcome. This is especially a problem with large and complex systems.\nThe number of non-critical alarms can easily overwhelm administrators and\nincrease the likelihood of ignoring future alerts. Mitigation strategies thus\naim to avoid raising `too many' false alarms without missing potentially\ndangerous situations. There are two major categories of false alarm-mitigation\nstrategies: (1) methods that are customized to enhance the quality of anomaly\nscoring; (2) approaches acting as filtering methods in contexts that aim to\ndecrease false alarm rates. These methods have been widely utilized by many\nscholars. Herein, we review and compare the existing techniques for false alarm\nmitigation in ADSs. We also examine the use of promising techniques in\nsignature-based IDS and other relevant contexts, such as commercial security\ninformation and event management tools, which are promising for ADSs. We\nconclude by highlighting promising directions for future research.\n", "versions": [{"version": "v1", "created": "Sun, 14 Apr 2019 07:36:08 GMT"}, {"version": "v2", "created": "Sun, 30 Aug 2020 19:35:13 GMT"}], "update_date": "2020-09-01", "authors_parsed": [["Zohrevand", "Zahra", ""], ["Gl\u00e4sser", "Uwe", ""]]}, {"id": "1904.06656", "submitter": "Na Zhang", "authors": "Na Zhang, Xuefeng Guan, Jun Cao, Xinglei Wang, Huayi Wu", "title": "A Hybrid Traffic Speed Forecasting Approach Integrating Wavelet\n  Transform and Motif-based Graph Convolutional Recurrent Neural Network", "comments": "7 pages, IJCAI19", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG eess.SP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Traffic forecasting is crucial for urban traffic management and guidance.\nHowever, existing methods rarely exploit the time-frequency properties of\ntraffic speed observations, and often neglect the propagation of traffic flows\nfrom upstream to downstream road segments. In this paper, we propose a hybrid\napproach that learns the spatio-temporal dependency in traffic flows and\npredicts short-term traffic speeds on a road network. Specifically, we employ\nwavelet transform to decompose raw traffic data into several components with\ndifferent frequency sub-bands. A Motif-based Graph Convolutional Recurrent\nNeural Network (Motif-GCRNN) and Auto-Regressive Moving Average (ARMA) are used\nto train and predict low-frequency components and high-frequency components,\nrespectively. In the Motif-GCRNN framework, we integrate Graph Convolutional\nNetworks (GCNs) with local sub-graph structures - Motifs - to capture the\nspatial correlations among road segments, and apply Long Short-Term Memory\n(LSTM) to extract the short-term and periodic patterns in traffic speeds.\nExperiments on a traffic dataset collected in Chengdu, China, demonstrate that\nthe proposed hybrid method outperforms six state-of-art prediction methods.\n", "versions": [{"version": "v1", "created": "Sun, 14 Apr 2019 08:40:58 GMT"}], "update_date": "2019-04-16", "authors_parsed": [["Zhang", "Na", ""], ["Guan", "Xuefeng", ""], ["Cao", "Jun", ""], ["Wang", "Xinglei", ""], ["Wu", "Huayi", ""]]}, {"id": "1904.06685", "submitter": "Zengmao Wang PhD", "authors": "Bo Du, Zengmao Wang, Lefei Zhang, Liangpei Zhang, Wei Liu, Jialie\n  Shen, Dacheng Tao", "title": "Exploring Representativeness and Informativeness for Active Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  How can we find a general way to choose the most suitable samples for\ntraining a classifier? Even with very limited prior information? Active\nlearning, which can be regarded as an iterative optimization procedure, plays a\nkey role to construct a refined training set to improve the classification\nperformance in a variety of applications, such as text analysis, image\nrecognition, social network modeling, etc.\n  Although combining representativeness and informativeness of samples has been\nproven promising for active sampling, state-of-the-art methods perform well\nunder certain data structures. Then can we find a way to fuse the two active\nsampling criteria without any assumption on data? This paper proposes a general\nactive learning framework that effectively fuses the two criteria. Inspired by\na two-sample discrepancy problem, triple measures are elaborately designed to\nguarantee that the query samples not only possess the representativeness of the\nunlabeled data but also reveal the diversity of the labeled data. Any\nappropriate similarity measure can be employed to construct the triple\nmeasures. Meanwhile, an uncertain measure is leveraged to generate the\ninformativeness criterion, which can be carried out in different ways.\n  Rooted in this framework, a practical active learning algorithm is proposed,\nwhich exploits a radial basis function together with the estimated\nprobabilities to construct the triple measures and a modified\nBest-versus-Second-Best strategy to construct the uncertain measure,\nrespectively. Experimental results on benchmark datasets demonstrate that our\nalgorithm consistently achieves superior performance over the state-of-the-art\nactive learning algorithms.\n", "versions": [{"version": "v1", "created": "Sun, 14 Apr 2019 12:18:42 GMT"}], "update_date": "2019-04-16", "authors_parsed": [["Du", "Bo", ""], ["Wang", "Zengmao", ""], ["Zhang", "Lefei", ""], ["Zhang", "Liangpei", ""], ["Liu", "Wei", ""], ["Shen", "Jialie", ""], ["Tao", "Dacheng", ""]]}, {"id": "1904.06689", "submitter": "Zengmao Wang PhD", "authors": "Bo Du, Zengmao Wang, Lefei Zhang, Liangpei Zhang, Dacheng Tao", "title": "Robust and Discriminative Labeling for Multi-label Active Learning Based\n  on Maximum Correntropy Criterion", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Multi-label learning draws great interests in many real world applications.\nIt is a highly costly task to assign many labels by the oracle for one\ninstance. Meanwhile, it is also hard to build a good model without diagnosing\ndiscriminative labels. Can we reduce the label costs and improve the ability to\ntrain a good model for multi-label learning simultaneously?\n  Active learning addresses the less training samples problem by querying the\nmost valuable samples to achieve a better performance with little costs. In\nmulti-label active learning, some researches have been done for querying the\nrelevant labels with less training samples or querying all labels without\ndiagnosing the discriminative information. They all cannot effectively handle\nthe outlier labels for the measurement of uncertainty. Since Maximum\nCorrentropy Criterion (MCC) provides a robust analysis for outliers in many\nmachine learning and data mining algorithms, in this paper, we derive a robust\nmulti-label active learning algorithm based on MCC by merging uncertainty and\nrepresentativeness, and propose an efficient alternating optimization method to\nsolve it. With MCC, our method can eliminate the influence of outlier labels\nthat are not discriminative to measure the uncertainty. To make further\nimprovement on the ability of information measurement, we merge uncertainty and\nrepresentativeness with the prediction labels of unknown data. It can not only\nenhance the uncertainty but also improve the similarity measurement of\nmulti-label data with labels information. Experiments on benchmark multi-label\ndata sets have shown a superior performance than the state-of-the-art methods.\n", "versions": [{"version": "v1", "created": "Sun, 14 Apr 2019 12:53:57 GMT"}], "update_date": "2019-04-16", "authors_parsed": [["Du", "Bo", ""], ["Wang", "Zengmao", ""], ["Zhang", "Lefei", ""], ["Zhang", "Liangpei", ""], ["Tao", "Dacheng", ""]]}, {"id": "1904.06690", "submitter": "Fei Sun", "authors": "Fei Sun, Jun Liu, Jian Wu, Changhua Pei, Xiao Lin, Wenwu Ou, and Peng\n  Jiang", "title": "BERT4Rec: Sequential Recommendation with Bidirectional Encoder\n  Representations from Transformer", "comments": "To appear in CIKM 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Modeling users' dynamic and evolving preferences from their historical\nbehaviors is challenging and crucial for recommendation systems. Previous\nmethods employ sequential neural networks (e.g., Recurrent Neural Network) to\nencode users' historical interactions from left to right into hidden\nrepresentations for making recommendations. Although these methods achieve\nsatisfactory results, they often assume a rigidly ordered sequence which is not\nalways practical. We argue that such left-to-right unidirectional architectures\nrestrict the power of the historical sequence representations. For this\npurpose, we introduce a Bidirectional Encoder Representations from Transformers\nfor sequential Recommendation (BERT4Rec). However, jointly conditioning on both\nleft and right context in deep bidirectional model would make the training\nbecome trivial since each item can indirectly \"see the target item\". To address\nthis problem, we train the bidirectional model using the Cloze task, predicting\nthe masked items in the sequence by jointly conditioning on their left and\nright context. Comparing with predicting the next item at each position in a\nsequence, the Cloze task can produce more samples to train a more powerful\nbidirectional model. Extensive experiments on four benchmark datasets show that\nour model outperforms various state-of-the-art sequential models consistently.\n", "versions": [{"version": "v1", "created": "Sun, 14 Apr 2019 13:01:46 GMT"}, {"version": "v2", "created": "Wed, 21 Aug 2019 07:36:44 GMT"}], "update_date": "2019-08-22", "authors_parsed": [["Sun", "Fei", ""], ["Liu", "Jun", ""], ["Wu", "Jian", ""], ["Pei", "Changhua", ""], ["Lin", "Xiao", ""], ["Ou", "Wenwu", ""], ["Jiang", "Peng", ""]]}, {"id": "1904.06703", "submitter": "Benjamin Beyret", "authors": "Benjamin Beyret, Ali Shafti, A. Aldo Faisal", "title": "Dot-to-Dot: Explainable Hierarchical Reinforcement Learning for Robotic\n  Manipulation", "comments": null, "journal-ref": null, "doi": "10.1109/IROS40897.2019.8968488", "report-no": null, "categories": "cs.LG cs.AI cs.RO stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Robotic systems are ever more capable of automation and fulfilment of complex\ntasks, particularly with reliance on recent advances in intelligent systems,\ndeep learning and artificial intelligence. However, as robots and humans come\ncloser in their interactions, the matter of interpretability, or explainability\nof robot decision-making processes for the human grows in importance. A\nsuccessful interaction and collaboration will only take place through mutual\nunderstanding of underlying representations of the environment and the task at\nhand. This is currently a challenge in deep learning systems. We present a\nhierarchical deep reinforcement learning system, consisting of a low-level\nagent handling the large actions/states space of a robotic system efficiently,\nby following the directives of a high-level agent which is learning the\nhigh-level dynamics of the environment and task. This high-level agent forms a\nrepresentation of the world and task at hand that is interpretable for a human\noperator. The method, which we call Dot-to-Dot, is tested on a MuJoCo-based\nmodel of the Fetch Robotics Manipulator, as well as a Shadow Hand, to test its\nperformance. Results show efficient learning of complex actions/states spaces\nby the low-level agent, and an interpretable representation of the task and\ndecision-making process learned by the high-level agent.\n", "versions": [{"version": "v1", "created": "Sun, 14 Apr 2019 14:54:14 GMT"}, {"version": "v2", "created": "Sun, 11 Aug 2019 06:37:15 GMT"}], "update_date": "2020-02-13", "authors_parsed": [["Beyret", "Benjamin", ""], ["Shafti", "Ali", ""], ["Faisal", "A. Aldo", ""]]}, {"id": "1904.06707", "submitter": "Timo Schick", "authors": "Timo Schick, Hinrich Sch\\\"utze", "title": "Rare Words: A Major Problem for Contextualized Embeddings And How to Fix\n  it by Attentive Mimicking", "comments": "To appear at AAAI 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Pretraining deep neural network architectures with a language modeling\nobjective has brought large improvements for many natural language processing\ntasks. Exemplified by BERT, a recently proposed such architecture, we\ndemonstrate that despite being trained on huge amounts of data, deep language\nmodels still struggle to understand rare words. To fix this problem, we adapt\nAttentive Mimicking, a method that was designed to explicitly learn embeddings\nfor rare words, to deep language models. In order to make this possible, we\nintroduce one-token approximation, a procedure that enables us to use Attentive\nMimicking even when the underlying language model uses subword-based\ntokenization, i.e., it does not assign embeddings to all words. To evaluate our\nmethod, we create a novel dataset that tests the ability of language models to\ncapture semantic properties of words without any task-specific fine-tuning.\nUsing this dataset, we show that adding our adapted version of Attentive\nMimicking to BERT does indeed substantially improve its understanding of rare\nwords.\n", "versions": [{"version": "v1", "created": "Sun, 14 Apr 2019 15:26:52 GMT"}, {"version": "v2", "created": "Sat, 20 Apr 2019 11:24:37 GMT"}, {"version": "v3", "created": "Sun, 17 Nov 2019 07:46:56 GMT"}, {"version": "v4", "created": "Wed, 4 Dec 2019 14:26:08 GMT"}], "update_date": "2019-12-05", "authors_parsed": [["Schick", "Timo", ""], ["Sch\u00fctze", "Hinrich", ""]]}, {"id": "1904.06738", "submitter": "Chiranjib Bhattacharyya", "authors": "Chiranjib Bhattacharyya and Ravindran Kannan", "title": "Finding a latent k-simplex in O(k . nnz(data)) time via Subset Smoothing", "comments": "Added more discussion of special cases. The assumptions are also\n  modified", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.DS stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we show that a large class of Latent variable models, such as\nMixed Membership Stochastic Block(MMSB) Models, Topic Models, and Adversarial\nClustering, can be unified through a geometric perspective, replacing model\nspecific assumptions and algorithms for individual models. The geometric\nperspective leads to the formulation: \\emph{find a latent $k-$ polytope $K$ in\n${\\bf R}^d$ given $n$ data points, each obtained by perturbing a latent point\nin $K$}. This problem does not seem to have been considered in the literature.\nThe most important contribution of this paper is to show that the latent\n$k-$polytope problem admits an efficient algorithm under deterministic\nassumptions which naturally hold in Latent variable models considered in this\npaper. ur algorithm runs in time $O^*(k\\; \\mbox{nnz})$ matching the best\nrunning time of algorithms in special cases considered here and is better when\nthe data is sparse, as is the case in applications. An important novelty of the\nalgorithm is the introduction of \\emph{subset smoothed polytope}, $K'$, the\nconvex hull of the ${n\\choose \\delta n}$ points obtained by averaging all\n$\\delta n$ subsets of the data points, for a given $\\delta \\in (0,1)$. We show\nthat $K$ and $K'$ are close in Hausdroff distance. Among the consequences of\nour algorithm are the following: (a) MMSB Models and Topic Models: the first\nquasi-input-sparsity time algorithm for parameter estimation for $k \\in\nO^*(1)$, (b) Adversarial Clustering: In $k-$means, if, an adversary is allowed\nto move many data points from each cluster an arbitrary amount towards the\nconvex hull of the centers of other clusters, our algorithm still estimates\ncluster centers well.\n", "versions": [{"version": "v1", "created": "Sun, 14 Apr 2019 18:29:13 GMT"}, {"version": "v2", "created": "Fri, 19 Apr 2019 23:30:28 GMT"}, {"version": "v3", "created": "Tue, 16 Jul 2019 16:41:12 GMT"}, {"version": "v4", "created": "Sun, 5 Jan 2020 06:51:19 GMT"}], "update_date": "2020-01-07", "authors_parsed": [["Bhattacharyya", "Chiranjib", ""], ["Kannan", "Ravindran", ""]]}, {"id": "1904.06744", "submitter": "Won-Yong Shin", "authors": "Adeel Malik, Joongheon Kim, Kwang Soon Kim, Won-Yong Shin", "title": "A Personalized Preference Learning Framework for Caching in Mobile\n  Networks", "comments": "21 pages, 10 figures, 1 table, to appear in the IEEE Transactions on\n  Mobile Computing", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI cs.IR cs.IT cs.LG cs.MM math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper comprehensively studies a content-centric mobile network based on\na preference learning framework, where each mobile user is equipped with a\nfinite-size cache. We consider a practical scenario where each user requests a\ncontent file according to its own preferences, which is motivated by the\nexistence of heterogeneity in file preferences among different users. Under our\nmodel, we consider a single-hop-based device-to-device (D2D) content delivery\nprotocol and characterize the average hit ratio for the following two file\npreference cases: the personalized file preferences and the common file\npreferences. By assuming that the model parameters such as user activity\nlevels, user file preferences, and file popularity are unknown and thus need to\nbe inferred, we present a collaborative filtering (CF)-based approach to learn\nthese parameters. Then, we reformulate the hit ratio maximization problems into\na submodular function maximization and propose two computationally efficient\nalgorithms including a greedy approach to efficiently solve the cache\nallocation problems. We analyze the computational complexity of each algorithm.\nMoreover, we analyze the corresponding level of the approximation that our\ngreedy algorithm can achieve compared to the optimal solution. Using a\nreal-world dataset, we demonstrate that the proposed framework employing the\npersonalized file preferences brings substantial gains over its counterpart for\nvarious system parameters.\n", "versions": [{"version": "v1", "created": "Mon, 15 Apr 2019 05:54:53 GMT"}, {"version": "v2", "created": "Wed, 19 Feb 2020 16:22:14 GMT"}, {"version": "v3", "created": "Thu, 20 Feb 2020 05:43:21 GMT"}], "update_date": "2020-02-21", "authors_parsed": [["Malik", "Adeel", ""], ["Kim", "Joongheon", ""], ["Kim", "Kwang Soon", ""], ["Shin", "Won-Yong", ""]]}, {"id": "1904.06762", "submitter": "Tryphon Georgiou", "authors": "Yongxin Chen, Tryphon T. Georgiou, and Allen R. Tannenbaum", "title": "Probabilistic Kernel Support Vector Machines", "comments": "6 pages, 6 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.SY eess.SY stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a probabilistic enhancement of standard kernel Support Vector\nMachines for binary classification, in order to address the case when, along\nwith given data sets, a description of uncertainty (e.g., error bounds) may be\navailable on each datum. In the present paper, we specifically consider\nGaussian distributions to model uncertainty. Thereby, our data consist of pairs\n$(x_i,\\Sigma_i)$, $i\\in\\{1,\\ldots,N\\}$, along with an indicator\n$y_i\\in\\{-1,1\\}$ to declare membership in one of two categories for each pair.\nThese pairs may be viewed to represent the mean and covariance, respectively,\nof random vectors $\\xi_i$ taking values in a suitable linear space (typically\n$\\mathbb R^n$). Thus, our setting may also be viewed as a modification of\nSupport Vector Machines to classify distributions, albeit, at present, only\nGaussian ones. We outline the formalism that allows computing suitable\nclassifiers via a natural modification of the standard \"kernel trick.\" The main\ncontribution of this work is to point out a suitable kernel function for\napplying Support Vector techniques to the setting of uncertain data for which a\ndetailed uncertainty description is also available (herein, \"Gaussian points\").\n", "versions": [{"version": "v1", "created": "Sun, 14 Apr 2019 21:25:25 GMT"}, {"version": "v2", "created": "Wed, 18 Mar 2020 16:13:27 GMT"}], "update_date": "2020-03-19", "authors_parsed": [["Chen", "Yongxin", ""], ["Georgiou", "Tryphon T.", ""], ["Tannenbaum", "Allen R.", ""]]}, {"id": "1904.06765", "submitter": "Alexander Fabisch", "authors": "Alexander Fabisch", "title": "A Comparison of Policy Search in Joint Space and Cartesian Space for\n  Refinement of Skills", "comments": null, "journal-ref": null, "doi": "10.1007/978-3-030-19648-6_35", "report-no": null, "categories": "cs.RO cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Imitation learning is a way to teach robots skills that are demonstrated by\nhumans. Transfering skills between these different kinematic structures seems\nto be straightforward in Cartesian space. Because of the correspondence\nproblem, however, the result will most likely not be identical. This is why\nrefinement is required, for example, by policy search. Policy search in\nCartesian space is prone to reachability problems when using conventional\ninverse kinematic solvers. We propose a configurable approximate inverse\nkinematic solver and show that it can accelerate the refinement process\nconsiderably. We also compare empirically refinement in Cartesian space and\nrefinement in joint space.\n", "versions": [{"version": "v1", "created": "Sun, 14 Apr 2019 21:41:28 GMT"}], "update_date": "2019-06-11", "authors_parsed": [["Fabisch", "Alexander", ""]]}, {"id": "1904.06786", "submitter": "Sarah Bechtle", "authors": "Sarah Bechtle, Yixin Lin, Akshara Rai, Ludovic Righetti, Franziska\n  Meier", "title": "Curious iLQR: Resolving Uncertainty in Model-based RL", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Curiosity as a means to explore during reinforcement learning problems has\nrecently become very popular. However, very little progress has been made in\nutilizing curiosity for learning control. In this work, we propose a\nmodel-based reinforcement learning (MBRL) framework that combines Bayesian\nmodeling of the system dynamics with curious iLQR, an iterative LQR approach\nthat considers model uncertainty. During trajectory optimization the curious\niLQR attempts to minimize both the task-dependent cost and the uncertainty in\nthe dynamics model. We demonstrate the approach on reaching tasks with 7-DoF\nmanipulators in simulation and on a real robot. Our experiments show that MBRL\nwith curious iLQR reaches desired end-effector targets more reliably and with\nless system rollouts when learning a new task from scratch, and that the\nlearned model generalizes better to new reaching tasks.\n", "versions": [{"version": "v1", "created": "Mon, 15 Apr 2019 00:02:27 GMT"}, {"version": "v2", "created": "Tue, 8 Oct 2019 00:34:22 GMT"}], "update_date": "2019-10-09", "authors_parsed": [["Bechtle", "Sarah", ""], ["Lin", "Yixin", ""], ["Rai", "Akshara", ""], ["Righetti", "Ludovic", ""], ["Meier", "Franziska", ""]]}, {"id": "1904.06788", "submitter": "Seyyid Emre Sofuoglu", "authors": "Seyyid Emre Sofuoglu, Selin Aviyente", "title": "Multi-Branch Tensor Network Structure for Tensor-Train Discriminant\n  Analysis", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.SP cs.LG eess.IV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Higher-order data with high dimensionality arise in a diverse set of\napplication areas such as computer vision, video analytics and medical imaging.\nTensors provide a natural tool for representing these types of data. Although\nthere has been a lot of work in the area of tensor decomposition and low-rank\ntensor approximation, extensions to supervised learning, feature extraction and\nclassification are still limited. Moreover, most of the existing supervised\ntensor learning approaches are based on the orthogonal Tucker model. However,\nthis model has some limitations for large tensors including high memory and\ncomputational costs. In this paper, we introduce a supervised learning approach\nfor tensor classification based on the tensor-train model. In particular, we\nintroduce a multi-branch tensor network structure for efficient implementation\nof tensor-train discriminant analysis (TTDA). The proposed approach takes\nadvantage of the flexibility of the tensor train structure to implement various\ncomputationally efficient versions of TTDA. This approach is then evaluated on\nimage and video classification tasks with respect to computation time, storage\ncost and classification accuracy and is compared to both vector and tensor\nbased discriminant analysis methods.\n", "versions": [{"version": "v1", "created": "Mon, 15 Apr 2019 00:40:06 GMT"}, {"version": "v2", "created": "Mon, 3 Aug 2020 14:32:18 GMT"}], "update_date": "2020-08-04", "authors_parsed": [["Sofuoglu", "Seyyid Emre", ""], ["Aviyente", "Selin", ""]]}, {"id": "1904.06807", "submitter": "Hao Tang", "authors": "Hao Tang, Dan Xu, Nicu Sebe, Yanzhi Wang, Jason J. Corso, Yan Yan", "title": "Multi-Channel Attention Selection GAN with Cascaded Semantic Guidance\n  for Cross-View Image Translation", "comments": "20 pages, 16 figures, accepted to CVPR 2019 as an oral paper", "journal-ref": "CVPR 2019", "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.LG cs.MM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Cross-view image translation is challenging because it involves images with\ndrastically different views and severe deformation. In this paper, we propose a\nnovel approach named Multi-Channel Attention SelectionGAN (SelectionGAN) that\nmakes it possible to generate images of natural scenes in arbitrary viewpoints,\nbased on an image of the scene and a novel semantic map. The proposed\nSelectionGAN explicitly utilizes the semantic information and consists of two\nstages. In the first stage, the condition image and the target semantic map are\nfed into a cycled semantic-guided generation network to produce initial coarse\nresults. In the second stage, we refine the initial results by using a\nmulti-channel attention selection mechanism. Moreover, uncertainty maps\nautomatically learned from attentions are used to guide the pixel loss for\nbetter network optimization. Extensive experiments on Dayton, CVUSA and Ego2Top\ndatasets show that our model is able to generate significantly better results\nthan the state-of-the-art methods. The source code, data and trained models are\navailable at https://github.com/Ha0Tang/SelectionGAN.\n", "versions": [{"version": "v1", "created": "Mon, 15 Apr 2019 02:04:15 GMT"}, {"version": "v2", "created": "Tue, 16 Apr 2019 20:36:07 GMT"}], "update_date": "2019-04-18", "authors_parsed": [["Tang", "Hao", ""], ["Xu", "Dan", ""], ["Sebe", "Nicu", ""], ["Wang", "Yanzhi", ""], ["Corso", "Jason J.", ""], ["Yan", "Yan", ""]]}, {"id": "1904.06823", "submitter": "Feng Xiao", "authors": "Feng Xiao, Dapeng Zhang, Gang Kou, Lu Li", "title": "Learning Spatiotemporal Features of Ride-sourcing Services with Fusion\n  Convolutional Network", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  To collectively forecast the demand for ride-sourcing services in all regions\nof a city, the deep learning approaches have been applied with commendable\nresults. However, the local statistical differences throughout the geographical\nlayout of the city make the spatial stationarity assumption of the convolution\ninvalid, which limits the performance of CNNs on the demand forecasting task.\nIn this paper, we propose a novel deep learning framework called LC-ST-FCN\n(locally connected spatiotemporal fully-convolutional neural network) to\naddress the unique challenges of the region-level demand forecasting problem\nwithin one end-to-end architecture (E2E). We first employ the 3D convolutional\nlayers to fuse the spatial and temporal information existed in the input and\nthen feed the spatiotemporal features extracted by the 3D convolutional layers\nto the subsequent 2D convolutional layers. Afterward, the prediction value of\neach region is obtained by the locally connected convolutional layers which\nrelax the parameter sharing scheme. We evaluate the proposed model on a real\ndataset from a ride-sourcing service platform (DiDiChuxing) and observe\nsignificant improvements compared with a bunch of baseline models. Besides, we\nalso illustrate the effectiveness of our proposed model by visualizing how\ndifferent types of convolutional layers transform their input and capture\nuseful features. The visualization results show that fully convolutional\narchitecture enables the model to better localize the related regions. And the\nlocally connected layers play an important role in dealing with the local\nstatistical differences and activating useful regions.\n", "versions": [{"version": "v1", "created": "Mon, 15 Apr 2019 03:10:45 GMT"}, {"version": "v2", "created": "Fri, 24 Apr 2020 08:48:30 GMT"}], "update_date": "2020-04-27", "authors_parsed": [["Xiao", "Feng", ""], ["Zhang", "Dapeng", ""], ["Kou", "Gang", ""], ["Li", "Lu", ""]]}, {"id": "1904.06834", "submitter": "Kartik Goyal", "authors": "Kartik Goyal, Chris Dyer and Taylor Berg-Kirkpatrick", "title": "An Empirical Investigation of Global and Local Normalization for\n  Recurrent Neural Sequence Models Using a Continuous Relaxation to Beam Search", "comments": "Long paper at NAACL 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CL stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Globally normalized neural sequence models are considered superior to their\nlocally normalized equivalents because they may ameliorate the effects of label\nbias. However, when considering high-capacity neural parametrizations that\ncondition on the whole input sequence, both model classes are theoretically\nequivalent in terms of the distributions they are capable of representing.\nThus, the practical advantage of global normalization in the context of modern\nneural methods remains unclear. In this paper, we attempt to shed light on this\nproblem through an empirical study. We extend an approach for search-aware\ntraining via a continuous relaxation of beam search (Goyal et al., 2017b) in\norder to enable training of globally normalized recurrent sequence models\nthrough simple backpropagation. We then use this technique to conduct an\nempirical study of the interaction between global normalization, high-capacity\nencoders, and search-aware optimization. We observe that in the context of\ninexact search, globally normalized neural models are still more effective than\ntheir locally normalized counterparts. Further, since our training approach is\nsensitive to warm-starting with pre-trained models, we also propose a novel\ninitialization strategy based on self-normalization for pre-training globally\nnormalized models. We perform analysis of our approach on two tasks: CCG\nsupertagging and Machine Translation, and demonstrate the importance of global\nnormalization under different conditions while using search-aware training.\n", "versions": [{"version": "v1", "created": "Mon, 15 Apr 2019 04:17:13 GMT"}], "update_date": "2019-04-16", "authors_parsed": [["Goyal", "Kartik", ""], ["Dyer", "Chris", ""], ["Berg-Kirkpatrick", "Taylor", ""]]}, {"id": "1904.06861", "submitter": "Junlong Gao", "authors": "Junlong Gao, Shiqi Wang, Shanshe Wang, Siwei Ma, Wen Gao", "title": "Self-critical n-step Training for Image Captioning", "comments": "CVPR2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Existing methods for image captioning are usually trained by cross entropy\nloss, which leads to exposure bias and the inconsistency between the optimizing\nfunction and evaluation metrics. Recently it has been shown that these two\nissues can be addressed by incorporating techniques from reinforcement\nlearning, where one of the popular techniques is the advantage actor-critic\nalgorithm that calculates per-token advantage by estimating state value with a\nparametrized estimator at the cost of introducing estimation bias. In this\npaper, we estimate state value without using a parametrized value estimator.\nWith the properties of image captioning, namely, the deterministic state\ntransition function and the sparse reward, state value is equivalent to its\npreceding state-action value, and we reformulate advantage function by simply\nreplacing the former with the latter. Moreover, the reformulated advantage is\nextended to n-step, which can generally increase the absolute value of the mean\nof reformulated advantage while lowering variance. Then two kinds of rollout\nare adopted to estimate state-action value, which we call self-critical n-step\ntraining. Empirically we find that our method can obtain better performance\ncompared to the state-of-the-art methods that use the sequence level advantage\nand parametrized estimator respectively on the widely used MSCOCO benchmark.\n", "versions": [{"version": "v1", "created": "Mon, 15 Apr 2019 05:47:23 GMT"}], "update_date": "2019-04-16", "authors_parsed": [["Gao", "Junlong", ""], ["Wang", "Shiqi", ""], ["Wang", "Shanshe", ""], ["Ma", "Siwei", ""], ["Gao", "Wen", ""]]}, {"id": "1904.06866", "submitter": "Ori Plonsky", "authors": "Ori Plonsky, Reut Apel, Eyal Ert, Moshe Tennenholtz, David Bourgin,\n  Joshua C. Peterson, Daniel Reichman, Thomas L. Griffiths, Stuart J. Russell,\n  Evan C. Carter, James F. Cavanagh, Ido Erev", "title": "Predicting human decisions with behavioral theories and machine learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.GT cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Behavioral decision theories aim to explain human behavior. Can they help\npredict it? An open tournament for prediction of human choices in fundamental\neconomic decision tasks is presented. The results suggest that integration of\ncertain behavioral theories as features in machine learning systems provides\nthe best predictions. Surprisingly, the most useful theories for prediction\nbuild on basic properties of human and animal learning and are very different\nfrom mainstream decision theories that focus on deviations from rational\nchoice. Moreover, we find that theoretical features should be based not only on\nqualitative behavioral insights (e.g. loss aversion), but also on quantitative\nbehavioral foresights generated by functional descriptive models (e.g. Prospect\nTheory). Our analysis prescribes a recipe for derivation of explainable, useful\npredictions of human decisions.\n", "versions": [{"version": "v1", "created": "Mon, 15 Apr 2019 06:12:44 GMT"}], "update_date": "2019-04-16", "authors_parsed": [["Plonsky", "Ori", ""], ["Apel", "Reut", ""], ["Ert", "Eyal", ""], ["Tennenholtz", "Moshe", ""], ["Bourgin", "David", ""], ["Peterson", "Joshua C.", ""], ["Reichman", "Daniel", ""], ["Griffiths", "Thomas L.", ""], ["Russell", "Stuart J.", ""], ["Carter", "Evan C.", ""], ["Cavanagh", "James F.", ""], ["Erev", "Ido", ""]]}, {"id": "1904.06868", "submitter": "Kazuhiro Nakamura", "authors": "Kazuhiro Nakamura, Kei Hashimoto, Keiichiro Oura, Yoshihiko Nankaku,\n  Keiichi Tokuda", "title": "Singing voice synthesis based on convolutional neural networks", "comments": "Singing voice samples (Japanese, English, Chinese):\n  https://www.techno-speech.com/news-20181214a-en", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.AS cs.LG cs.SD", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The present paper describes a singing voice synthesis based on convolutional\nneural networks (CNNs). Singing voice synthesis systems based on deep neural\nnetworks (DNNs) are currently being proposed and are improving the naturalness\nof synthesized singing voices. In these systems, the relationship between\nmusical score feature sequences and acoustic feature sequences extracted from\nsinging voices is modeled by DNNs. Then, an acoustic feature sequence of an\narbitrary musical score is output in units of frames by the trained DNNs, and a\nnatural trajectory of a singing voice is obtained by using a parameter\ngeneration algorithm. As singing voices contain rich expression, a powerful\ntechnique to model them accurately is required. In the proposed technique,\nlong-term dependencies of singing voices are modeled by CNNs. An acoustic\nfeature sequence is generated in units of segments that consist of long-term\nframes, and a natural trajectory is obtained without the parameter generation\nalgorithm. Experimental results in a subjective listening test show that the\nproposed architecture can synthesize natural sounding singing voices.\n", "versions": [{"version": "v1", "created": "Mon, 15 Apr 2019 06:23:44 GMT"}, {"version": "v2", "created": "Tue, 25 Jun 2019 06:54:03 GMT"}], "update_date": "2019-06-26", "authors_parsed": [["Nakamura", "Kazuhiro", ""], ["Hashimoto", "Kei", ""], ["Oura", "Keiichiro", ""], ["Nankaku", "Yoshihiko", ""], ["Tokuda", "Keiichi", ""]]}, {"id": "1904.06887", "submitter": "Minsung Hyun", "authors": "Minsung Hyun, Junyoung Choi and Nojun Kwak", "title": "Disentangling Options with Hellinger Distance Regularizer", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In reinforcement learning (RL), temporal abstraction still remains as an\nimportant and unsolved problem. The options framework provided clues to\ntemporal abstraction in the RL, and the option-critic architecture elegantly\nsolved the two problems of finding options and learning RL agents in an\nend-to-end manner. However, it is necessary to examine whether the options\nlearned through this method play a mutually exclusive role. In this paper, we\npropose a Hellinger distance regularizer, a method for disentangling options.\nIn addition, we will shed light on various indicators from the statistical\npoint of view to compare with the options learned through the existing\noption-critic architecture.\n", "versions": [{"version": "v1", "created": "Mon, 15 Apr 2019 07:43:17 GMT"}], "update_date": "2019-04-16", "authors_parsed": [["Hyun", "Minsung", ""], ["Choi", "Junyoung", ""], ["Kwak", "Nojun", ""]]}, {"id": "1904.06895", "submitter": "Markku Hinkka", "authors": "Markku Hinkka, Teemu Lehto and Keijo Heljanko", "title": "Exploiting Event Log Event Attributes in RNN Based Prediction", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In predictive process analytics, current and historical process data in event\nlogs is used to predict the future, e.g., to predict the next activity or how\nlong a process will still require to complete. Recurrent neural networks (RNN)\nand its subclasses have been demonstrated to be well suited for creating\nprediction models. Thus far, event attributes have not been fully utilized in\nthese models. The biggest challenge in exploiting them in prediction models is\nthe potentially large amount of event attributes and attribute values. We\npresent a novel clustering technique that allows for trade-offs between\nprediction accuracy and the time needed for model training and prediction. As\nan additional finding, we also find that this clustering method combined with\nhaving raw event attribute values in some cases provides even better prediction\naccuracy at the cost of additional time required for training and prediction.\n", "versions": [{"version": "v1", "created": "Mon, 15 Apr 2019 07:58:30 GMT"}, {"version": "v2", "created": "Thu, 20 Jun 2019 08:19:29 GMT"}, {"version": "v3", "created": "Wed, 15 Jan 2020 07:18:43 GMT"}], "update_date": "2020-01-16", "authors_parsed": [["Hinkka", "Markku", ""], ["Lehto", "Teemu", ""], ["Heljanko", "Keijo", ""]]}, {"id": "1904.06913", "submitter": "Yiftach Ginger", "authors": "Yiftach Ginger, Dov Danon, Hadar Averbuch-Elor, Daniel Cohen-Or", "title": "Implicit Pairs for Boosting Unpaired Image-to-Image Translation", "comments": null, "journal-ref": null, "doi": "10.1016/j.visinf.2020.10.001", "report-no": null, "categories": "cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In image-to-image translation the goal is to learn a mapping from one image\ndomain to another. In the case of supervised approaches the mapping is learned\nfrom paired samples. However, collecting large sets of image pairs is often\neither prohibitively expensive or not possible. As a result, in recent years\nmore attention has been given to techniques that learn the mapping from\nunpaired sets.\n  In our work, we show that injecting implicit pairs into unpaired sets\nstrengthens the mapping between the two domains, improves the compatibility of\ntheir distributions, and leads to performance boosting of unsupervised\ntechniques by over 14% across several measurements.\n  The competence of the implicit pairs is further displayed with the use of\npseudo-pairs, i.e., paired samples which only approximate a real pair. We\ndemonstrate the effect of the approximated implicit samples on image-to-image\ntranslation problems, where such pseudo-pairs may be synthesized in one\ndirection, but not in the other. We further show that pseudo-pairs are\nsignificantly more effective as implicit pairs in an unpaired setting, than\ndirectly using them explicitly in a paired setting.\n", "versions": [{"version": "v1", "created": "Mon, 15 Apr 2019 08:52:25 GMT"}, {"version": "v2", "created": "Tue, 25 Feb 2020 13:10:09 GMT"}, {"version": "v3", "created": "Sun, 28 Jun 2020 13:54:32 GMT"}, {"version": "v4", "created": "Thu, 3 Dec 2020 17:37:23 GMT"}], "update_date": "2020-12-04", "authors_parsed": [["Ginger", "Yiftach", ""], ["Danon", "Dov", ""], ["Averbuch-Elor", "Hadar", ""], ["Cohen-Or", "Daniel", ""]]}, {"id": "1904.06915", "submitter": "Yao Yang Leow", "authors": "Yao Yang Leow, Thomas Laurent, Xavier Bresson", "title": "GraphTSNE: A Visualization Technique for Graph-Structured Data", "comments": "Published as a workshop paper at ICLR 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present GraphTSNE, a novel visualization technique for graph-structured\ndata based on t-SNE. The growing interest in graph-structured data increases\nthe importance of gaining human insight into such datasets by means of\nvisualization. Among the most popular visualization techniques, classical t-SNE\nis not suitable on such datasets because it has no mechanism to make use of\ninformation from the graph structure. On the other hand, visualization\ntechniques which operate on graphs, such as Laplacian Eigenmaps and tsNET, have\nno mechanism to make use of information from node features. Our proposed method\nGraphTSNE produces visualizations which account for both graph structure and\nnode features. It is based on scalable and unsupervised training of a graph\nconvolutional network on a modified t-SNE loss. By assembling a suite of\nevaluation metrics, we demonstrate that our method produces desirable\nvisualizations on three benchmark datasets.\n", "versions": [{"version": "v1", "created": "Mon, 15 Apr 2019 09:11:17 GMT"}, {"version": "v2", "created": "Sun, 21 Apr 2019 05:36:53 GMT"}, {"version": "v3", "created": "Tue, 23 Apr 2019 13:10:07 GMT"}], "update_date": "2019-04-24", "authors_parsed": [["Leow", "Yao Yang", ""], ["Laurent", "Thomas", ""], ["Bresson", "Xavier", ""]]}, {"id": "1904.06950", "submitter": "Mayukh Das", "authors": "Mayukh Das, Yang Yu, Devendra Singh Dhami, Gautam Kunapuli, Sriraam\n  Natarajan", "title": "Human-Guided Learning of Column Networks: Augmenting Deep Learning with\n  Advice", "comments": "Under Review at 'Machine Learning Journal' (MLJ)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recently, deep models have been successfully applied in several applications,\nespecially with low-level representations. However, sparse, noisy samples and\nstructured domains (with multiple objects and interactions) are some of the\nopen challenges in most deep models. Column Networks, a deep architecture, can\nsuccinctly capture such domain structure and interactions, but may still be\nprone to sub-optimal learning from sparse and noisy samples. Inspired by the\nsuccess of human-advice guided learning in AI, especially in data-scarce\ndomains, we propose Knowledge-augmented Column Networks that leverage human\nadvice/knowledge for better learning with noisy/sparse samples. Our experiments\ndemonstrate that our approach leads to either superior overall performance or\nfaster convergence (i.e., both effective and efficient).\n", "versions": [{"version": "v1", "created": "Mon, 15 Apr 2019 10:23:10 GMT"}], "update_date": "2019-04-16", "authors_parsed": [["Das", "Mayukh", ""], ["Yu", "Yang", ""], ["Dhami", "Devendra Singh", ""], ["Kunapuli", "Gautam", ""], ["Natarajan", "Sriraam", ""]]}, {"id": "1904.06952", "submitter": "Eran Treister", "authors": "Jonathan Ephrath, Lars Ruthotto, Eldad Haber, Eran Treister", "title": "LeanResNet: A Low-cost Yet Effective Convolutional Residual Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Convolutional Neural Networks (CNNs) filter the input data using spatial\nconvolution operators with compact stencils. Commonly, the convolution\noperators couple features from all channels, which leads to immense\ncomputational cost in the training of and prediction with CNNs. To improve the\nefficiency of CNNs, we introduce lean convolution operators that reduce the\nnumber of parameters and computational complexity, and can be used in a wide\nrange of existing CNNs. Here, we exemplify their use in residual networks\n(ResNets), which have been very reliable for a few years now and analyzed\nintensively. In our experiments on three image classification problems, the\nproposed LeanResNet yields results that are comparable to other recently\nproposed reduced architectures using similar number of parameters.\n", "versions": [{"version": "v1", "created": "Mon, 15 Apr 2019 10:28:42 GMT"}, {"version": "v2", "created": "Thu, 16 May 2019 13:11:43 GMT"}], "update_date": "2019-05-17", "authors_parsed": [["Ephrath", "Jonathan", ""], ["Ruthotto", "Lars", ""], ["Haber", "Eldad", ""], ["Treister", "Eran", ""]]}, {"id": "1904.06960", "submitter": "Mischa Schmidt", "authors": "Mischa Schmidt, Shahd Safarani, Julia Gastinger, Tobias Jacobs,\n  Sebastien Nicolas, Anett Sch\\\"ulke", "title": "On the Performance of Differential Evolution for Hyperparameter Tuning", "comments": "2019 International Joint Conference on Neural Networks (IJCNN)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Automated hyperparameter tuning aspires to facilitate the application of\nmachine learning for non-experts. In the literature, different optimization\napproaches are applied for that purpose. This paper investigates the\nperformance of Differential Evolution for tuning hyperparameters of supervised\nlearning algorithms for classification tasks. This empirical study involves a\nrange of different machine learning algorithms and datasets with various\ncharacteristics to compare the performance of Differential Evolution with\nSequential Model-based Algorithm Configuration (SMAC), a reference Bayesian\nOptimization approach. The results indicate that Differential Evolution\noutperforms SMAC for most datasets when tuning a given machine learning\nalgorithm - particularly when breaking ties in a first-to-report fashion. Only\nfor the tightest of computational budgets SMAC performs better. On small\ndatasets, Differential Evolution outperforms SMAC by 19% (37% after\ntie-breaking). In a second experiment across a range of representative datasets\ntaken from the literature, Differential Evolution scores 15% (23% after\ntie-breaking) more wins than SMAC.\n", "versions": [{"version": "v1", "created": "Mon, 15 Apr 2019 10:58:14 GMT"}], "update_date": "2019-04-16", "authors_parsed": [["Schmidt", "Mischa", ""], ["Safarani", "Shahd", ""], ["Gastinger", "Julia", ""], ["Jacobs", "Tobias", ""], ["Nicolas", "Sebastien", ""], ["Sch\u00fclke", "Anett", ""]]}, {"id": "1904.06963", "submitter": "Soham De", "authors": "Karthik A. Sankararaman, Soham De, Zheng Xu, W. Ronny Huang, Tom\n  Goldstein", "title": "The Impact of Neural Network Overparameterization on Gradient Confusion\n  and Stochastic Gradient Descent", "comments": "ICML 2020 camera-ready version", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper studies how neural network architecture affects the speed of\ntraining. We introduce a simple concept called gradient confusion to help\nformally analyze this. When gradient confusion is high, stochastic gradients\nproduced by different data samples may be negatively correlated, slowing down\nconvergence. But when gradient confusion is low, data samples interact\nharmoniously, and training proceeds quickly. Through theoretical and\nexperimental results, we demonstrate how the neural network architecture\naffects gradient confusion, and thus the efficiency of training. Our results\nshow that, for popular initialization techniques, increasing the width of\nneural networks leads to lower gradient confusion, and thus faster model\ntraining. On the other hand, increasing the depth of neural networks has the\nopposite effect. Our results indicate that alternate initialization techniques\nor networks using both batch normalization and skip connections help reduce the\ntraining burden of very deep networks.\n", "versions": [{"version": "v1", "created": "Mon, 15 Apr 2019 11:02:22 GMT"}, {"version": "v2", "created": "Sat, 8 Jun 2019 14:55:41 GMT"}, {"version": "v3", "created": "Wed, 16 Oct 2019 20:49:48 GMT"}, {"version": "v4", "created": "Wed, 26 Feb 2020 15:08:50 GMT"}, {"version": "v5", "created": "Mon, 6 Jul 2020 21:36:19 GMT"}], "update_date": "2020-07-08", "authors_parsed": [["Sankararaman", "Karthik A.", ""], ["De", "Soham", ""], ["Xu", "Zheng", ""], ["Huang", "W. Ronny", ""], ["Goldstein", "Tom", ""]]}, {"id": "1904.06968", "submitter": "Sergiy Vorobyov A.", "authors": "F.G. Veshki and S.A. Vorobyov", "title": "A Fast Dictionary Learning Method for Coupled Feature Space Learning", "comments": "12 pages, 3 figures, 1 algorithm", "journal-ref": "IEEE Signal Processing Letters, vol. 26, no. 10, pp. 1441-1445,\n  Oct. 2019", "doi": null, "report-no": null, "categories": "cs.LG cs.IT math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this letter, we propose a novel computationally efficient coupled\ndictionary learning method that enforces pairwise correlation between the atoms\nof dictionaries learned to represent the underlying feature spaces of two\ndifferent representations of the same signals, e.g., representations in\ndifferent modalities or representations of the same signals measured with\ndifferent qualities. The jointly learned correlated feature spaces represented\nby coupled dictionaries are used in sparse representation based classification,\nrecognition and reconstruction tasks. The presented experimental results show\nthat the proposed coupled dictionary learning method has a significantly lower\ncomputational cost. Moreover, the visual presentation of jointly learned\ndictionaries shows that the pairwise correlations between the corresponding\natoms are ensured.\n", "versions": [{"version": "v1", "created": "Mon, 15 Apr 2019 11:16:51 GMT"}], "update_date": "2019-09-24", "authors_parsed": [["Veshki", "F. G.", ""], ["Vorobyov", "S. A.", ""]]}, {"id": "1904.06969", "submitter": "Nikolay Burlutskiy", "authors": "Nikolay Burlutskiy, Nicolas Pinchaud, Feng Gu, Daniel H\\\"agg, Mats\n  Andersson, Lars Bj\\\"ork, Kristian Eur\\'en, Cristina Svensson, Lena Kajland\n  Wil\\'en, Martin Hedlund", "title": "Segmenting Potentially Cancerous Areas in Prostate Biopsies using\n  Semi-Automatically Annotated Data", "comments": "Accepted as oral presentation at Medical Imaging with Deep Learning\n  (MIDL) 2019, July, London, England", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Gleason grading specified in ISUP 2014 is the clinical standard in staging\nprostate cancer and the most important part of the treatment decision. However,\nthe grading is subjective and suffers from high intra and inter-user\nvariability. To improve the consistency and objectivity in the grading, we\nintroduced glandular tissue WithOut Basal cells (WOB) as the ground truth. The\npresence of basal cells is the most accepted biomarker for benign glandular\ntissue and the absence of basal cells is a strong indicator of acinar prostatic\nadenocarcinoma, the most common form of prostate cancer. Glandular tissue can\nobjectively be assessed as WOB or not WOB by using specific immunostaining for\nglandular tissue (Cytokeratin 8/18) and for basal cells (Cytokeratin 5/6 +\np63). Even more, WOB allowed us to develop a semi-automated data generation\npipeline to speed up the tremendously time consuming and expensive process of\nannotating whole slide images by pathologists. We generated 295 prostatectomy\nimages exhaustively annotated with WOB. Then we used our Deep Learning\nFramework, which achieved the $2^{nd}$ best reported score in Camelyon17\nChallenge, to train networks for segmenting WOB in needle biopsies. Evaluation\nof the model on 63 needle biopsies showed promising results which were improved\nfurther by finetuning the model on 118 biopsies annotated with WOB, achieving\nF1-score of 0.80 and Precision-Recall AUC of 0.89 at the pixel-level. Then we\ncompared the performance of the model against 17 biopsies annotated\nindependently by 3 pathologists using only H\\&E staining. The comparison\ndemonstrated that the model performed on a par with the pathologists. Finally,\nthe model detected and accurately outlined existing WOB areas in two biopsies\nincorrectly annotated as totally WOB-free biopsies by three pathologists and in\none biopsy by two pathologists.\n", "versions": [{"version": "v1", "created": "Mon, 15 Apr 2019 11:18:27 GMT"}], "update_date": "2019-04-16", "authors_parsed": [["Burlutskiy", "Nikolay", ""], ["Pinchaud", "Nicolas", ""], ["Gu", "Feng", ""], ["H\u00e4gg", "Daniel", ""], ["Andersson", "Mats", ""], ["Bj\u00f6rk", "Lars", ""], ["Eur\u00e9n", "Kristian", ""], ["Svensson", "Cristina", ""], ["Wil\u00e9n", "Lena Kajland", ""], ["Hedlund", "Martin", ""]]}, {"id": "1904.06972", "submitter": "Faizal Hafiz", "authors": "Faizal Hafiz and Akshya Swain and Chirag Naik and Nitish Patel", "title": "Efficient Feature Selection of Power Quality Events using Two\n  Dimensional (2D) Particle Swarms", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A novel two-dimensional (2D) learning framework has been proposed to address\nthe feature selection problem in Power Quality (PQ) events. Unlike the existing\nfeature selection approaches, the proposed 2D learning explicitly incorporates\nthe information about the subset cardinality (i.e., the number of features) as\nan additional learning dimension to effectively guide the search process. The\nefficacy of this approach has been demonstrated considering fourteen distinct\nclasses of PQ events which conform to the IEEE Standard 1159. The search\nperformance of the 2D learning approach has been compared to the other six\nwell-known feature selection wrappers by considering two induction algorithms:\nNaive Bayes (NB) and k-Nearest Neighbors (k-NN). Further, the robustness of the\nselected/reduced feature subsets has been investigated considering seven\ndifferent levels of noise. The results of this investigation convincingly\ndemonstrate that the proposed 2D learning can identify significantly better and\nrobust feature subsets for PQ events.\n", "versions": [{"version": "v1", "created": "Mon, 15 Apr 2019 11:32:58 GMT"}], "update_date": "2019-04-16", "authors_parsed": [["Hafiz", "Faizal", ""], ["Swain", "Akshya", ""], ["Naik", "Chirag", ""], ["Patel", "Nitish", ""]]}, {"id": "1904.06979", "submitter": "C\\'edric Colas", "authors": "C\\'edric Colas, Olivier Sigaud, Pierre-Yves Oudeyer", "title": "A Hitchhiker's Guide to Statistical Comparisons of Reinforcement\n  Learning Algorithms", "comments": "8 pages + supplementary material", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ME cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Consistently checking the statistical significance of experimental results is\nthe first mandatory step towards reproducible science. This paper presents a\nhitchhiker's guide to rigorous comparisons of reinforcement learning\nalgorithms. After introducing the concepts of statistical testing, we review\nthe relevant statistical tests and compare them empirically in terms of false\npositive rate and statistical power as a function of the sample size (number of\nseeds) and effect size. We further investigate the robustness of these tests to\nviolations of the most common hypotheses (normal distributions, same\ndistributions, equal variances). Beside simulations, we compare empirical\ndistributions obtained by running Soft-Actor Critic and Twin-Delayed Deep\nDeterministic Policy Gradient on Half-Cheetah. We conclude by providing\nguidelines and code to perform rigorous comparisons of RL algorithm\nperformances.\n", "versions": [{"version": "v1", "created": "Mon, 15 Apr 2019 12:00:29 GMT"}], "update_date": "2019-04-16", "authors_parsed": [["Colas", "C\u00e9dric", ""], ["Sigaud", "Olivier", ""], ["Oudeyer", "Pierre-Yves", ""]]}, {"id": "1904.06984", "submitter": "Itay Safran", "authors": "Itay Safran, Ronen Eldan, Ohad Shamir", "title": "Depth Separations in Neural Networks: What is Actually Being Separated?", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Existing depth separation results for constant-depth networks essentially\nshow that certain radial functions in $\\mathbb{R}^d$, which can be easily\napproximated with depth $3$ networks, cannot be approximated by depth $2$\nnetworks, even up to constant accuracy, unless their size is exponential in\n$d$. However, the functions used to demonstrate this are rapidly oscillating,\nwith a Lipschitz parameter scaling polynomially with the dimension $d$ (or\nequivalently, by scaling the function, the hardness result applies to\n$\\mathcal{O}(1)$-Lipschitz functions only when the target accuracy $\\epsilon$\nis at most $\\text{poly}(1/d)$). In this paper, we study whether such depth\nseparations might still hold in the natural setting of\n$\\mathcal{O}(1)$-Lipschitz radial functions, when $\\epsilon$ does not scale\nwith $d$. Perhaps surprisingly, we show that the answer is negative: In\ncontrast to the intuition suggested by previous work, it \\emph{is} possible to\napproximate $\\mathcal{O}(1)$-Lipschitz radial functions with depth $2$, size\n$\\text{poly}(d)$ networks, for every constant $\\epsilon$. We complement it by\nshowing that approximating such functions is also possible with depth $2$, size\n$\\text{poly}(1/\\epsilon)$ networks, for every constant $d$. Finally, we show\nthat it is not possible to have polynomial dependence in both $d,1/\\epsilon$\nsimultaneously. Overall, our results indicate that in order to show depth\nseparations for expressing $\\mathcal{O}(1)$-Lipschitz functions with constant\naccuracy -- if at all possible -- one would need fundamentally different\ntechniques than existing ones in the literature.\n", "versions": [{"version": "v1", "created": "Mon, 15 Apr 2019 12:07:38 GMT"}, {"version": "v2", "created": "Sun, 26 May 2019 11:22:43 GMT"}, {"version": "v3", "created": "Wed, 2 Jun 2021 16:35:17 GMT"}], "update_date": "2021-06-03", "authors_parsed": [["Safran", "Itay", ""], ["Eldan", "Ronen", ""], ["Shamir", "Ohad", ""]]}, {"id": "1904.06991", "submitter": "Samuli Laine", "authors": "Tuomas Kynk\\\"a\\\"anniemi, Tero Karras, Samuli Laine, Jaakko Lehtinen,\n  Timo Aila", "title": "Improved Precision and Recall Metric for Assessing Generative Models", "comments": "NeurIPS 2019 final version", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The ability to automatically estimate the quality and coverage of the samples\nproduced by a generative model is a vital requirement for driving algorithm\nresearch. We present an evaluation metric that can separately and reliably\nmeasure both of these aspects in image generation tasks by forming explicit,\nnon-parametric representations of the manifolds of real and generated data. We\ndemonstrate the effectiveness of our metric in StyleGAN and BigGAN by providing\nseveral illustrative examples where existing metrics yield uninformative or\ncontradictory results. Furthermore, we analyze multiple design variants of\nStyleGAN to better understand the relationships between the model architecture,\ntraining methods, and the properties of the resulting sample distribution. In\nthe process, we identify new variants that improve the state-of-the-art. We\nalso perform the first principled analysis of truncation methods and identify\nan improved method. Finally, we extend our metric to estimate the perceptual\nquality of individual samples, and use this to study latent space\ninterpolations.\n", "versions": [{"version": "v1", "created": "Mon, 15 Apr 2019 12:20:32 GMT"}, {"version": "v2", "created": "Wed, 5 Jun 2019 13:03:04 GMT"}, {"version": "v3", "created": "Wed, 30 Oct 2019 12:33:29 GMT"}], "update_date": "2019-10-31", "authors_parsed": [["Kynk\u00e4\u00e4nniemi", "Tuomas", ""], ["Karras", "Tero", ""], ["Laine", "Samuli", ""], ["Lehtinen", "Jaakko", ""], ["Aila", "Timo", ""]]}, {"id": "1904.07032", "submitter": "Sushravya Raghunath", "authors": "Sushravya Raghunath, Alvaro E. Ulloa Cerna, Linyuan Jing, David P.\n  vanMaanen, Joshua Stough, Dustin N. Hartzel, Joseph B. Leader, H. Lester\n  Kirchner, Christopher W. Good, Aalpen A. Patel, Brian P. Delisle, Amro\n  Alsaid, Dominik Beer, Christopher M. Haggerty, Brandon K. Fornwalt", "title": "Deep neural networks can predict mortality from 12-lead\n  electrocardiogram voltage data", "comments": "An updated version of this paper is now published with Nature\n  Medicine (2020)", "journal-ref": null, "doi": "10.1038/s41591-020-0870-z", "report-no": null, "categories": "q-bio.QM cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The electrocardiogram (ECG) is a widely-used medical test, typically\nconsisting of 12 voltage versus time traces collected from surface recordings\nover the heart. Here we hypothesize that a deep neural network can predict an\nimportant future clinical event (one-year all-cause mortality) from ECG\nvoltage-time traces. We show good performance for predicting one-year mortality\nwith an average AUC of 0.85 from a model cross-validated on 1,775,926 12-lead\nresting ECGs, that were collected over a 34-year period in a large regional\nhealth system. Even within the large subset of ECGs interpreted as 'normal' by\na physician (n=297,548), the model performance to predict one-year mortality\nremained high (AUC=0.84), and Cox Proportional Hazard model revealed a hazard\nratio of 6.6 (p<0.005) for the two predicted groups (dead vs alive one year\nafter ECG) over a 30-year follow-up period. A blinded survey of three\ncardiologists suggested that the patterns captured by the model were generally\nnot visually apparent to cardiologists even after being shown 240 paired\nexamples of labeled true positives (dead) and true negatives (alive). In\nsummary, deep learning can add significant prognostic information to the\ninterpretation of 12-lead resting ECGs, even in cases that are interpreted as\n'normal' by physicians.\n", "versions": [{"version": "v1", "created": "Mon, 15 Apr 2019 13:28:35 GMT"}, {"version": "v2", "created": "Fri, 3 May 2019 17:08:02 GMT"}, {"version": "v3", "created": "Mon, 11 May 2020 18:21:11 GMT"}], "update_date": "2020-05-13", "authors_parsed": [["Raghunath", "Sushravya", ""], ["Cerna", "Alvaro E. Ulloa", ""], ["Jing", "Linyuan", ""], ["vanMaanen", "David P.", ""], ["Stough", "Joshua", ""], ["Hartzel", "Dustin N.", ""], ["Leader", "Joseph B.", ""], ["Kirchner", "H. Lester", ""], ["Good", "Christopher W.", ""], ["Patel", "Aalpen A.", ""], ["Delisle", "Brian P.", ""], ["Alsaid", "Amro", ""], ["Beer", "Dominik", ""], ["Haggerty", "Christopher M.", ""], ["Fornwalt", "Brandon K.", ""]]}, {"id": "1904.07077", "submitter": "Cunxi Yu", "authors": "Cunxi Yu and Zhiru Zhang", "title": "Painting on Placement: Forecasting Routing Congestion using Conditional\n  Generative Adversarial Nets", "comments": "6 pages, 9 figures, to appear at DAC'19", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Physical design process commonly consumes hours to days for large designs,\nand routing is known as the most critical step. Demands for accurate routing\nquality prediction raise to a new level to accelerate hardware innovation with\nadvanced technology nodes. This work presents an approach that forecasts the\ndensity of all routing channels over the entire floorplan, with features\ncollected up to placement, using conditional GANs. Specifically, forecasting\nthe routing congestion is constructed as an image translation (colorization)\nproblem. The proposed approach is applied to a) placement exploration for\nminimum congestion, b) constrained placement exploration and c) forecasting\ncongestion in real-time during incremental placement, using eight designs\ntargeting a fixed FPGA architecture.\n", "versions": [{"version": "v1", "created": "Mon, 15 Apr 2019 14:35:14 GMT"}], "update_date": "2019-04-16", "authors_parsed": [["Yu", "Cunxi", ""], ["Zhang", "Zhiru", ""]]}, {"id": "1904.07092", "submitter": "Christian Joppi", "authors": "Marco Godi, Christian Joppi, Andrea Giachetti, Marco Cristani", "title": "SIMCO: SIMilarity-based object COunting", "comments": "Accepted at ICPR 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present SIMCO, the first agnostic multi-class object counting approach.\nSIMCO starts by detecting foreground objects through a novel Mask RCNN-based\narchitecture trained beforehand (just once) on a brand-new synthetic 2D shape\ndataset, InShape; the idea is to highlight every object resembling a primitive\n2D shape (circle, square, rectangle, etc.). Each object detected is described\nby a low-dimensional embedding, obtained from a novel similarity-based head\nbranch; this latter implements a triplet loss, encouraging similar objects\n(same 2D shape + color and scale) to map close. Subsequently, SIMCO uses this\nembedding for clustering, so that different types of objects can emerge and be\ncounted, making SIMCO the very first multi-class unsupervised counter.\nExperiments show that SIMCO provides state-of-the-art scores on counting\nbenchmarks and that it can also help in many challenging image understanding\ntasks.\n", "versions": [{"version": "v1", "created": "Mon, 15 Apr 2019 14:52:31 GMT"}, {"version": "v2", "created": "Tue, 13 Oct 2020 08:16:53 GMT"}], "update_date": "2020-10-14", "authors_parsed": [["Godi", "Marco", ""], ["Joppi", "Christian", ""], ["Giachetti", "Andrea", ""], ["Cristani", "Marco", ""]]}, {"id": "1904.07153", "submitter": "Marcel Hirt", "authors": "Marcel Hirt, Petros Dellaportas, Alain Durmus", "title": "Copula-like Variational Inference", "comments": "33rd Conference on Neural Information Processing Systems (NeurIPS\n  2019), Vancouver, Canada", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper considers a new family of variational distributions motivated by\nSklar's theorem. This family is based on new copula-like densities on the\nhypercube with non-uniform marginals which can be sampled efficiently, i.e.\nwith a complexity linear in the dimension of state space. Then, the proposed\nvariational densities that we suggest can be seen as arising from these\ncopula-like densities used as base distributions on the hypercube with Gaussian\nquantile functions and sparse rotation matrices as normalizing flows. The\nlatter correspond to a rotation of the marginals with complexity $\\mathcal{O}(d\n\\log d)$. We provide some empirical evidence that such a variational family can\nalso approximate non-Gaussian posteriors and can be beneficial compared to\nGaussian approximations. Our method performs largely comparably to\nstate-of-the-art variational approximations on standard regression and\nclassification benchmarks for Bayesian Neural Networks.\n", "versions": [{"version": "v1", "created": "Mon, 15 Apr 2019 16:08:32 GMT"}, {"version": "v2", "created": "Sun, 22 Dec 2019 13:01:15 GMT"}], "update_date": "2019-12-24", "authors_parsed": [["Hirt", "Marcel", ""], ["Dellaportas", "Petros", ""], ["Durmus", "Alain", ""]]}, {"id": "1904.07154", "submitter": "Jaehun Kim", "authors": "Jaehun Kim, Juli\\'an Urbano, Cynthia C. S. Liem, Alan Hanjalic", "title": "Are Nearby Neighbors Relatives?: Testing Deep Music Embeddings", "comments": "this work was accepted for publication in the \"Frontiers in Applied\n  Mathematics and Statistics (Deep Learning: Status, Applications and\n  Algorithms)\"", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.SD eess.AS stat.ML", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Deep neural networks have frequently been used to directly learn\nrepresentations useful for a given task from raw input data. In terms of\noverall performance metrics, machine learning solutions employing deep\nrepresentations frequently have been reported to greatly outperform those using\nhand-crafted feature representations. At the same time, they may pick up on\naspects that are predominant in the data, yet not actually meaningful or\ninterpretable. In this paper, we therefore propose a systematic way to test the\ntrustworthiness of deep music representations, considering musical semantics.\nThe underlying assumption is that in case a deep representation is to be\ntrusted, distance consistency between known related points should be maintained\nboth in the input audio space and corresponding latent deep space. We generate\nknown related points through semantically meaningful transformations, both\nconsidering imperceptible and graver transformations. Then, we examine within-\nand between-space distance consistencies, both considering audio space and\nlatent embedded space, the latter either being a result of a conventional\nfeature extractor or a deep encoder. We illustrate how our method, as a\ncomplement to task-specific performance, provides interpretable insight into\nwhat a network may have captured from training data signals.\n", "versions": [{"version": "v1", "created": "Mon, 15 Apr 2019 16:08:41 GMT"}, {"version": "v2", "created": "Tue, 15 Oct 2019 21:42:36 GMT"}, {"version": "v3", "created": "Thu, 17 Oct 2019 23:34:04 GMT"}], "update_date": "2019-10-21", "authors_parsed": [["Kim", "Jaehun", ""], ["Urbano", "Juli\u00e1n", ""], ["Liem", "Cynthia C. S.", ""], ["Hanjalic", "Alan", ""]]}, {"id": "1904.07163", "submitter": "Jalal Mirakhorli", "authors": "Jalal Mirakhorli, Hamidreza Amindavar, Mojgan Mirakhorli", "title": "Graph-Based Method for Anomaly Prediction in Brain Network", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.IV cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Resting-state functional MRI (rs-fMRI) in functional neuroimaging techniques\nhave improved in brain disorders, dysfunction studies via mapping the topology\nof the brain connections, i.e. connectopic mapping. Since, there are the slight\ndifferences between healthy and unhealthy brain regions and functions,\ninvestigation into the complex topology of functional and structural brain\nnetworks in human is a complicated task with the growth of evaluation criteria.\nIrregular graph deep learning applications have widely spread to understanding\nhuman cognitive functions that are linked to gene expression and related\ndistributed spatial patterns, because the neuronal networks of the brain can\nhold dynamically a variety of brain solutions with different activity patterns\nand functional connectivity, these applications might also be involved with\nboth node-centric and graph-centric tasks. In this paper, we performed a novel\napproach of individual generative model and high order graph analysis for the\nregion of interest recognition areas of the brain which do not have a normal\nconnection during applying certain tasks. Here, we proposed a high order\nframework of Graph Auto-Encoder (GAE) with a hypersphere distributer for\nfunctional data analysis in brain imaging studies that is underlying\nnon-Euclidean structure in the learning of strong non-rigid graphs among large\nscale data. In addition, we distinguished the possible modes of correlations in\nabnormal brain connections. Our finding will show the degree of correlation\nbetween the affected regions and their simultaneous occurrence over time that\ncan be used to diagnose brain diseases or revealing the ability of the nervous\nsystem to modify in brain topology at all angles, brain plasticity, according\nto input stimuli.\n", "versions": [{"version": "v1", "created": "Mon, 15 Apr 2019 16:22:08 GMT"}, {"version": "v2", "created": "Wed, 17 Apr 2019 05:30:51 GMT"}, {"version": "v3", "created": "Tue, 23 Apr 2019 10:34:06 GMT"}, {"version": "v4", "created": "Tue, 7 May 2019 10:33:25 GMT"}, {"version": "v5", "created": "Fri, 24 May 2019 09:57:47 GMT"}, {"version": "v6", "created": "Mon, 24 Jun 2019 08:58:49 GMT"}, {"version": "v7", "created": "Wed, 17 Jul 2019 07:10:21 GMT"}], "update_date": "2019-07-18", "authors_parsed": [["Mirakhorli", "Jalal", ""], ["Amindavar", "Hamidreza", ""], ["Mirakhorli", "Mojgan", ""]]}, {"id": "1904.07174", "submitter": "Ilias Zadik", "authors": "David Gamarnik and Ilias Zadik", "title": "The Landscape of the Planted Clique Problem: Dense subgraphs and the\n  Overlap Gap Property", "comments": "70 pages, 3 Figures. Added Figure 1 (phase diagram), and a new result\n  proving that the OGP implies the failure of an MCMC family to recover the\n  planted clique", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST cs.DS cs.LG math.OC math.PR stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we study the computational-statistical gap of the planted\nclique problem, where a clique of size $k$ is planted in an Erdos Renyi graph\n$G(n,\\frac{1}{2})$ resulting in a graph $G\\left(n,\\frac{1}{2},k\\right)$. The\ngoal is to recover the planted clique vertices by observing\n$G\\left(n,\\frac{1}{2},k\\right)$ . It is known that the clique can be recovered\nas long as $k \\geq \\left(2+\\epsilon\\right)\\log n $ for any $\\epsilon>0$, but no\npolynomial-time algorithm is known for this task unless $k=\\Omega\\left(\\sqrt{n}\n\\right)$. Following a statistical-physics inspired point of view as an attempt\nto understand this computational-statistical gap, we study the landscape of the\n\"sufficiently dense\" subgraphs of $G$ and their overlap with the planted\nclique.\n  Using the first moment method, we study the densest subgraph problems for\nsubgraphs with fixed, but arbitrary, overlap size with the planted clique, and\nprovide evidence of a phase transition for the presence of Overlap Gap Property\n(OGP) at $k=\\Theta\\left(\\sqrt{n}\\right)$. OGP is a concept introduced\noriginally in spin glass theory and known to suggest algorithmic hardness when\nit appears. We establish the presence of OGP when $k$ is a small positive power\nof $n$ by using a conditional second moment method. As our main technical tool,\nwe establish the first, to the best of our knowledge, concentration results for\nthe $K$-densest subgraph problem for the Erdos-Renyi model\n$G\\left(n,\\frac{1}{2}\\right)$ when $K=n^{0.5-\\epsilon}$ for arbitrary\n$\\epsilon>0$. Finally, to study the OGP we employ a certain form of\noverparametrization, which is conceptually aligned with a large body of recent\nwork in learning theory and optimization.\n", "versions": [{"version": "v1", "created": "Mon, 15 Apr 2019 16:44:00 GMT"}, {"version": "v2", "created": "Mon, 30 Dec 2019 10:56:26 GMT"}], "update_date": "2020-01-01", "authors_parsed": [["Gamarnik", "David", ""], ["Zadik", "Ilias", ""]]}, {"id": "1904.07199", "submitter": "Rob Brekelmans", "authors": "Rob Brekelmans, Daniel Moyer, Aram Galstyan, Greg Ver Steeg", "title": "Exact Rate-Distortion in Autoencoders via Echo Noise", "comments": "NeurIPS 2019; updated Gaussian baseline results, added\n  disentanglement", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.IT math.IT stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Compression is at the heart of effective representation learning. However,\nlossy compression is typically achieved through simple parametric models like\nGaussian noise to preserve analytic tractability, and the limitations this\nimposes on learning are largely unexplored. Further, the Gaussian prior\nassumptions in models such as variational autoencoders (VAEs) provide only an\nupper bound on the compression rate in general. We introduce a new noise\nchannel, \\emph{Echo noise}, that admits a simple, exact expression for mutual\ninformation for arbitrary input distributions. The noise is constructed in a\ndata-driven fashion that does not require restrictive distributional\nassumptions. With its complex encoding mechanism and exact rate regularization,\nEcho leads to improved bounds on log-likelihood and dominates $\\beta$-VAEs\nacross the achievable range of rate-distortion trade-offs. Further, we show\nthat Echo noise can outperform flow-based methods without the need to train\nadditional distributional transformations.\n", "versions": [{"version": "v1", "created": "Mon, 15 Apr 2019 17:22:42 GMT"}, {"version": "v2", "created": "Sun, 2 Jun 2019 03:21:25 GMT"}, {"version": "v3", "created": "Thu, 14 Nov 2019 05:41:55 GMT"}], "update_date": "2019-11-15", "authors_parsed": [["Brekelmans", "Rob", ""], ["Moyer", "Daniel", ""], ["Galstyan", "Aram", ""], ["Steeg", "Greg Ver", ""]]}, {"id": "1904.07200", "submitter": "Tim Dockhorn", "authors": "Tim Dockhorn", "title": "A Discussion on Solving Partial Differential Equations using Neural\n  Networks", "comments": "9 pages, 2 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG math.NA stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Can neural networks learn to solve partial differential equations (PDEs)? We\ninvestigate this question for two (systems of) PDEs, namely, the Poisson\nequation and the steady Navier--Stokes equations. The contributions of this\npaper are five-fold. (1) Numerical experiments show that small neural networks\n(< 500 learnable parameters) are able to accurately learn complex solutions for\nsystems of partial differential equations. (2) It investigates the influence of\nrandom weight initialization on the quality of the neural network approximate\nsolution and demonstrates how one can take advantage of this non-determinism\nusing ensemble learning. (3) It investigates the suitability of the loss\nfunction used in this work. (4) It studies the benefits and drawbacks of\nsolving (systems of) PDEs with neural networks compared to classical numerical\nmethods. (5) It proposes an exhaustive list of possible directions of future\nwork.\n", "versions": [{"version": "v1", "created": "Mon, 15 Apr 2019 17:23:58 GMT"}], "update_date": "2019-04-16", "authors_parsed": [["Dockhorn", "Tim", ""]]}, {"id": "1904.07204", "submitter": "Adarsh Subbaswamy", "authors": "Suchi Saria and Adarsh Subbaswamy", "title": "Tutorial: Safe and Reliable Machine Learning", "comments": "Overview of the \"Safe and Reliable Machine Learning\" tutorial given\n  at the 2019 ACM Conference on Fairness, Accountability, and Transparency\n  (FAT* 2019)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This document serves as a brief overview of the \"Safe and Reliable Machine\nLearning\" tutorial given at the 2019 ACM Conference on Fairness,\nAccountability, and Transparency (FAT* 2019). The talk slides can be found\nhere: https://bit.ly/2Gfsukp, while a video of the talk is available here:\nhttps://youtu.be/FGLOCkC4KmE, and a complete list of references for the\ntutorial here: https://bit.ly/2GdLPme.\n", "versions": [{"version": "v1", "created": "Mon, 15 Apr 2019 17:28:50 GMT"}], "update_date": "2019-04-16", "authors_parsed": [["Saria", "Suchi", ""], ["Subbaswamy", "Adarsh", ""]]}, {"id": "1904.07235", "submitter": "Guillermo Gallego", "authors": "Guillermo Gallego, Mathias Gehrig, Davide Scaramuzza", "title": "Focus Is All You Need: Loss Functions For Event-based Vision", "comments": "29 pages, 19 figures, 4 tables", "journal-ref": "IEEE Conference on Computer Vision and Pattern Recognition (CVPR),\n  Long Beach, 2019", "doi": null, "report-no": null, "categories": "cs.CV cs.LG cs.RO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Event cameras are novel vision sensors that output pixel-level brightness\nchanges (\"events\") instead of traditional video frames. These asynchronous\nsensors offer several advantages over traditional cameras, such as, high\ntemporal resolution, very high dynamic range, and no motion blur. To unlock the\npotential of such sensors, motion compensation methods have been recently\nproposed. We present a collection and taxonomy of twenty two objective\nfunctions to analyze event alignment in motion compensation approaches (Fig.\n1). We call them Focus Loss Functions since they have strong connections with\nfunctions used in traditional shape-from-focus applications. The proposed loss\nfunctions allow bringing mature computer vision tools to the realm of event\ncameras. We compare the accuracy and runtime performance of all loss functions\non a publicly available dataset, and conclude that the variance, the gradient\nand the Laplacian magnitudes are among the best loss functions. The\napplicability of the loss functions is shown on multiple tasks: rotational\nmotion, depth and optical flow estimation. The proposed focus loss functions\nallow to unlock the outstanding properties of event cameras.\n", "versions": [{"version": "v1", "created": "Mon, 15 Apr 2019 15:40:56 GMT"}], "update_date": "2019-04-17", "authors_parsed": [["Gallego", "Guillermo", ""], ["Gehrig", "Mathias", ""], ["Scaramuzza", "Davide", ""]]}, {"id": "1904.07272", "submitter": "Aleksandrs Slivkins", "authors": "Aleksandrs Slivkins", "title": "Introduction to Multi-Armed Bandits", "comments": "Published with Foundations and Trends(R) in Machine Learning,\n  November 2019. The present version is a revision of the \"Foundations and\n  Trends\" publication. It contains numerous edits for presentation and accuracy\n  (based in part on readers' feedback), updated and expanded literature\n  reviews, and some new exercises", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.DS stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Multi-armed bandits a simple but very powerful framework for algorithms that\nmake decisions over time under uncertainty. An enormous body of work has\naccumulated over the years, covered in several books and surveys. This book\nprovides a more introductory, textbook-like treatment of the subject. Each\nchapter tackles a particular line of work, providing a self-contained,\nteachable technical introduction and a brief review of the further\ndevelopments; many of the chapters conclude with exercises.\n  The book is structured as follows. The first four chapters are on IID\nrewards, from the basic model to impossibility results to Bayesian priors to\nLipschitz rewards. The next three chapters cover adversarial rewards, from the\nfull-feedback version to adversarial bandits to extensions with linear rewards\nand combinatorially structured actions. Chapter 8 is on contextual bandits, a\nmiddle ground between IID and adversarial bandits in which the change in reward\ndistributions is completely explained by observable contexts. The last three\nchapters cover connections to economics, from learning in repeated games to\nbandits with supply/budget constraints to exploration in the presence of\nincentives. The appendix provides sufficient background on concentration and\nKL-divergence.\n  The chapters on \"bandits with similarity information\", \"bandits with\nknapsacks\" and \"bandits and agents\" can also be consumed as standalone surveys\non the respective topics.\n", "versions": [{"version": "v1", "created": "Mon, 15 Apr 2019 18:17:01 GMT"}, {"version": "v2", "created": "Mon, 29 Apr 2019 20:45:01 GMT"}, {"version": "v3", "created": "Tue, 25 Jun 2019 14:39:03 GMT"}, {"version": "v4", "created": "Sun, 15 Sep 2019 02:06:22 GMT"}, {"version": "v5", "created": "Mon, 30 Sep 2019 00:15:42 GMT"}, {"version": "v6", "created": "Sat, 26 Jun 2021 20:15:32 GMT"}], "update_date": "2021-06-29", "authors_parsed": [["Slivkins", "Aleksandrs", ""]]}, {"id": "1904.07293", "submitter": "Md. Akmal Haidar", "authors": "Md. Akmal Haidar, Mehdi Rezagholizadeh, Alan Do-Omri, Ahmad Rashid", "title": "Latent Code and Text-based Generative Adversarial Networks for Soft-text\n  Generation", "comments": null, "journal-ref": "2019 Annual Conference of the North American Chapter of the\n  Association for Computational Linguistics", "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Text generation with generative adversarial networks (GANs) can be divided\ninto the text-based and code-based categories according to the type of signals\nused for discrimination. In this work, we introduce a novel text-based approach\ncalled Soft-GAN to effectively exploit GAN setup for text generation. We\ndemonstrate how autoencoders (AEs) can be used for providing a continuous\nrepresentation of sentences, which we will refer to as soft-text. This soft\nrepresentation will be used in GAN discrimination to synthesize similar\nsoft-texts. We also propose hybrid latent code and text-based GAN (LATEXT-GAN)\napproaches with one or more discriminators, in which a combination of the\nlatent code and the soft-text is used for GAN discriminations. We perform a\nnumber of subjective and objective experiments on two well-known datasets (SNLI\nand Image COCO) to validate our techniques. We discuss the results using\nseveral evaluation metrics and show that the proposed techniques outperform the\ntraditional GAN-based text-generation methods.\n", "versions": [{"version": "v1", "created": "Mon, 15 Apr 2019 19:07:49 GMT"}, {"version": "v2", "created": "Tue, 23 Apr 2019 15:05:41 GMT"}], "update_date": "2019-04-24", "authors_parsed": [["Haidar", "Md. Akmal", ""], ["Rezagholizadeh", "Mehdi", ""], ["Do-Omri", "Alan", ""], ["Rashid", "Ahmad", ""]]}, {"id": "1904.07294", "submitter": "Jalal Abdulbaqi", "authors": "Jalal Abdulbaqi, Yue Gu, and Ivan Marsic", "title": "RHR-Net: A Residual Hourglass Recurrent Neural Network for Speech\n  Enhancement", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.AS cs.LG cs.SD eess.SP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Most current speech enhancement models use spectrogram features that require\nan expensive transformation and result in phase information loss. Previous work\nhas overcome these issues by using convolutional networks to learn long-range\ntemporal correlations across high-resolution waveforms. These models, however,\nare limited by memory-intensive dilated convolution and aliasing artifacts from\nupsampling. We introduce an end-to-end fully-recurrent hourglass-shaped neural\nnetwork architecture with residual connections for waveform-based\nsingle-channel speech enhancement. Our model can efficiently capture long-range\ntemporal dependencies by reducing the features resolution without information\nloss. Experimental results show that our model outperforms state-of-the-art\napproaches in six evaluation metrics.\n", "versions": [{"version": "v1", "created": "Mon, 15 Apr 2019 19:17:28 GMT"}], "update_date": "2019-04-17", "authors_parsed": [["Abdulbaqi", "Jalal", ""], ["Gu", "Yue", ""], ["Marsic", "Ivan", ""]]}, {"id": "1904.07302", "submitter": "Hassan Ismail Fawaz", "authors": "Hassan Ismail Fawaz, Germain Forestier, Jonathan Weber, Fran\\c{c}ois\n  Petitjean, Lhassane Idoumghar, Pierre-Alain Muller", "title": "Automatic alignment of surgical videos using kinematic data", "comments": "Accepted at AIME 2019", "journal-ref": null, "doi": "10.1007/978-3-030-21642-9_14", "report-no": null, "categories": "cs.CV cs.AI cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Over the past one hundred years, the classic teaching methodology of \"see\none, do one, teach one\" has governed the surgical education systems worldwide.\nWith the advent of Operation Room 2.0, recording video, kinematic and many\nother types of data during the surgery became an easy task, thus allowing\nartificial intelligence systems to be deployed and used in surgical and medical\npractice. Recently, surgical videos has been shown to provide a structure for\npeer coaching enabling novice trainees to learn from experienced surgeons by\nreplaying those videos. However, the high inter-operator variability in\nsurgical gesture duration and execution renders learning from comparing novice\nto expert surgical videos a very difficult task. In this paper, we propose a\nnovel technique to align multiple videos based on the alignment of their\ncorresponding kinematic multivariate time series data. By leveraging the\nDynamic Time Warping measure, our algorithm synchronizes a set of videos in\norder to show the same gesture being performed at different speed. We believe\nthat the proposed approach is a valuable addition to the existing learning\ntools for surgery.\n", "versions": [{"version": "v1", "created": "Wed, 3 Apr 2019 16:46:08 GMT"}, {"version": "v2", "created": "Fri, 26 Apr 2019 12:27:13 GMT"}], "update_date": "2019-07-23", "authors_parsed": [["Fawaz", "Hassan Ismail", ""], ["Forestier", "Germain", ""], ["Weber", "Jonathan", ""], ["Petitjean", "Fran\u00e7ois", ""], ["Idoumghar", "Lhassane", ""], ["Muller", "Pierre-Alain", ""]]}, {"id": "1904.07303", "submitter": "Runhua Xu", "authors": "Runhua Xu, James B.D. Joshi and Chao Li", "title": "CryptoNN: Training Neural Networks over Encrypted Data", "comments": "ePrint", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.LG", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Emerging neural networks based machine learning techniques such as deep\nlearning and its variants have shown tremendous potential in many application\ndomains. However, they raise serious privacy concerns due to the risk of\nleakage of highly privacy-sensitive data when data collected from users is used\nto train neural network models to support predictive tasks. To tackle such\nserious privacy concerns, several privacy-preserving approaches have been\nproposed in the literature that use either secure multi-party computation (SMC)\nor homomorphic encryption (HE) as the underlying mechanisms. However, neither\nof these cryptographic approaches provides an efficient solution towards\nconstructing a privacy-preserving machine learning model, as well as supporting\nboth the training and inference phases. To tackle the above issue, we propose a\nCryptoNN framework that supports training a neural network model over encrypted\ndata by using the emerging functional encryption scheme instead of SMC or HE.\nWe also construct a functional encryption scheme for basic arithmetic\ncomputation to support the requirement of the proposed CryptoNN framework. We\npresent performance evaluation and security analysis of the underlying crypto\nscheme and show through our experiments that CryptoNN achieves accuracy that is\nsimilar to those of the baseline neural network models on the MNIST dataset.\n", "versions": [{"version": "v1", "created": "Mon, 15 Apr 2019 19:43:00 GMT"}, {"version": "v2", "created": "Fri, 26 Apr 2019 13:46:58 GMT"}], "update_date": "2019-04-29", "authors_parsed": [["Xu", "Runhua", ""], ["Joshi", "James B. D.", ""], ["Li", "Chao", ""]]}, {"id": "1904.07305", "submitter": "Aruni RoyChowdhury", "authors": "Aruni RoyChowdhury, Prithvijit Chakrabarty, Ashish Singh, SouYoung\n  Jin, Huaizu Jiang, Liangliang Cao and Erik Learned-Miller", "title": "Automatic adaptation of object detectors to new domains using\n  self-training", "comments": "Accepted at CVPR 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This work addresses the unsupervised adaptation of an existing object\ndetector to a new target domain. We assume that a large number of unlabeled\nvideos from this domain are readily available. We automatically obtain labels\non the target data by using high-confidence detections from the existing\ndetector, augmented with hard (misclassified) examples acquired by exploiting\ntemporal cues using a tracker. These automatically-obtained labels are then\nused for re-training the original model. A modified knowledge distillation loss\nis proposed, and we investigate several ways of assigning soft-labels to the\ntraining examples from the target domain. Our approach is empirically evaluated\non challenging face and pedestrian detection tasks: a face detector trained on\nWIDER-Face, which consists of high-quality images crawled from the web, is\nadapted to a large-scale surveillance data set; a pedestrian detector trained\non clear, daytime images from the BDD-100K driving data set is adapted to all\nother scenarios such as rainy, foggy, night-time. Our results demonstrate the\nusefulness of incorporating hard examples obtained from tracking, the advantage\nof using soft-labels via distillation loss versus hard-labels, and show\npromising performance as a simple method for unsupervised domain adaptation of\nobject detectors, with minimal dependence on hyper-parameters.\n", "versions": [{"version": "v1", "created": "Mon, 15 Apr 2019 19:46:18 GMT"}], "update_date": "2019-04-17", "authors_parsed": [["RoyChowdhury", "Aruni", ""], ["Chakrabarty", "Prithvijit", ""], ["Singh", "Ashish", ""], ["Jin", "SouYoung", ""], ["Jiang", "Huaizu", ""], ["Cao", "Liangliang", ""], ["Learned-Miller", "Erik", ""]]}, {"id": "1904.07319", "submitter": "Mengyuan Yan", "authors": "Mengyuan Yan, Adrian Li, Mrinal Kalakrishnan, Peter Pastor", "title": "Learning Probabilistic Multi-Modal Actor Models for Vision-Based Robotic\n  Grasping", "comments": null, "journal-ref": "The 2019 International Conference on Robotics and Automation\n  (ICRA)", "doi": null, "report-no": null, "categories": "cs.RO cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Many previous works approach vision-based robotic grasping by training a\nvalue network that evaluates grasp proposals. These approaches require an\noptimization process at run-time to infer the best action from the value\nnetwork. As a result, the inference time grows exponentially as the dimension\nof action space increases. We propose an alternative method, by directly\ntraining a neural density model to approximate the conditional distribution of\nsuccessful grasp poses from the input images. We construct a neural network\nthat combines Gaussian mixture and normalizing flows, which is able to\nrepresent multi-modal, complex probability distributions. We demonstrate on\nboth simulation and real robot that the proposed actor model achieves similar\nperformance compared to the value network using the Cross-Entropy Method (CEM)\nfor inference, on top-down grasping with a 4 dimensional action space. Our\nactor model reduces the inference time by 3 times compared to the\nstate-of-the-art CEM method. We believe that actor models will play an\nimportant role when scaling up these approaches to higher dimensional action\nspaces.\n", "versions": [{"version": "v1", "created": "Mon, 15 Apr 2019 20:23:52 GMT"}], "update_date": "2019-04-17", "authors_parsed": [["Yan", "Mengyuan", ""], ["Li", "Adrian", ""], ["Kalakrishnan", "Mrinal", ""], ["Pastor", "Peter", ""]]}, {"id": "1904.07320", "submitter": "Fang Su", "authors": "Fang Su, Hai-Yang Shang, Jing-Yan Wang", "title": "Low-Rank Deep Convolutional Neural Network for Multi-Task Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we propose a novel multi-task learning method based on the\ndeep convolutional network. The proposed deep network has four convolutional\nlayers, three max-pooling layers, and two parallel fully connected layers. To\nadjust the deep network to multi-task learning problem, we propose to learn a\nlow-rank deep network so that the relation among different tasks can be\nexplored. We proposed to minimize the number of independent parameter rows of\none fully connected layer to explore the relations among different tasks, which\nis measured by the nuclear norm of the parameter of one fully connected layer,\nand seek a low-rank parameter matrix. Meanwhile, we also propose to regularize\nanother fully connected layer by sparsity penalty, so that the useful features\nlearned by the lower layers can be selected. The learning problem is solved by\nan iterative algorithm based on gradient descent and back-propagation\nalgorithms. The proposed algorithm is evaluated over benchmark data sets of\nmultiple face attribute prediction, multi-task natural language processing, and\njoint economics index predictions. The evaluation results show the advantage of\nthe low-rank deep CNN model over multi-task problems.\n", "versions": [{"version": "v1", "created": "Fri, 12 Apr 2019 14:20:01 GMT"}], "update_date": "2019-04-17", "authors_parsed": [["Su", "Fang", ""], ["Shang", "Hai-Yang", ""], ["Wang", "Jing-Yan", ""]]}, {"id": "1904.07328", "submitter": "Niki Gitinabard", "authors": "Niki Gitinabard, Yiqiao Xu, Sarah Heckman, Tiffany Barnes, Collin F.\n  Lynch", "title": "How Widely Can Prediction Models be Generalized? Performance Prediction\n  in Blended Courses", "comments": null, "journal-ref": "IEEE TLT, Special Issue on Early Prediction 2019", "doi": "10.1109/TLT.2019.2911832", "report-no": null, "categories": "cs.CY cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Blended courses that mix in-person instruction with online platforms are\nincreasingly popular in secondary education. These tools record a rich amount\nof data on students' study habits and social interactions. Prior research has\nshown that these metrics are correlated with students' performance in face to\nface classes. However, predictive models for blended courses are still limited\nand have not yet succeeded at early prediction or cross-class predictions even\nfor repeated offerings of the same course.\n  In this work, we use data from two offerings of two different undergraduate\ncourses to train and evaluate predictive models on student performance based\nupon persistent student characteristics including study habits and social\ninteractions. We analyze the performance of these models on the same offering,\non different offerings of the same course, and across courses to see how well\nthey generalize. We also evaluate the models on different segments of the\ncourses to determine how early reliable predictions can be made. This work\ntells us in part how much data is required to make robust predictions and how\ncross-class data may be used, or not, to boost model performance. The results\nof this study will help us better understand how similar the study habits,\nsocial activities, and the teamwork styles are across semesters for students in\neach performance category. These trained models also provide an avenue to\nimprove our existing support platforms to better support struggling students\nearly in the semester with the goal of providing timely intervention.\n", "versions": [{"version": "v1", "created": "Mon, 15 Apr 2019 20:50:46 GMT"}, {"version": "v2", "created": "Fri, 21 Jun 2019 18:25:31 GMT"}], "update_date": "2019-06-25", "authors_parsed": [["Gitinabard", "Niki", ""], ["Xu", "Yiqiao", ""], ["Heckman", "Sarah", ""], ["Barnes", "Tiffany", ""], ["Lynch", "Collin F.", ""]]}, {"id": "1904.07342", "submitter": "Allison Koenecke", "authors": "Allison Koenecke and Jordi Feliu-Fab\\`a", "title": "Learning Twitter User Sentiments on Climate Change with Limited Labeled\n  Data", "comments": null, "journal-ref": null, "doi": "10.36190/2020.22", "report-no": null, "categories": "cs.CL cs.LG", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  While it is well-documented that climate change accepters and deniers have\nbecome increasingly polarized in the United States over time, there has been no\nlarge-scale examination of whether these individuals are prone to changing\ntheir opinions as a result of natural external occurrences. On the\nsub-population of Twitter users, we examine whether climate change sentiment\nchanges in response to five separate natural disasters occurring in the U.S. in\n2018. We begin by showing that relevant tweets can be classified with over 75%\naccuracy as either accepting or denying climate change when using our\nmethodology to compensate for limited labeled data; results are robust across\nseveral machine learning models and yield geographic-level results in line with\nprior research. We then apply RNNs to conduct a cohort-level analysis showing\nthat the 2018 hurricanes yielded a statistically significant increase in\naverage tweet sentiment affirming climate change. However, this effect does not\nhold for the 2018 blizzard and wildfires studied, implying that Twitter users'\nopinions on climate change are fairly ingrained on this subset of natural\ndisasters.\n", "versions": [{"version": "v1", "created": "Mon, 15 Apr 2019 21:51:21 GMT"}], "update_date": "2020-06-09", "authors_parsed": [["Koenecke", "Allison", ""], ["Feliu-Fab\u00e0", "Jordi", ""]]}, {"id": "1904.07346", "submitter": "Markus Wulfmeier", "authors": "Markus Wulfmeier", "title": "Efficient Supervision for Robot Learning via Imitation, Simulation, and\n  Adaptation", "comments": "Dissertation Summary", "journal-ref": null, "doi": "10.1007/s13218-019-00587-0", "report-no": null, "categories": "cs.LG cs.AI cs.RO stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent successes in machine learning have led to a shift in the design of\nautonomous systems, improving performance on existing tasks and rendering new\napplications possible. Data-focused approaches gain relevance across diverse,\nintricate applications when developing data collection and curation pipelines\nbecomes more effective than manual behaviour design. The following work aims at\nincreasing the efficiency of this pipeline in two principal ways: by utilising\nmore powerful sources of informative data and by extracting additional\ninformation from existing data. In particular, we target three orthogonal\nfronts: imitation learning, domain adaptation, and transfer from simulation.\n", "versions": [{"version": "v1", "created": "Mon, 15 Apr 2019 22:19:25 GMT"}], "update_date": "2019-04-17", "authors_parsed": [["Wulfmeier", "Markus", ""]]}, {"id": "1904.07370", "submitter": "Alesia Chernikova", "authors": "Alesia Chernikova, Alina Oprea, Cristina Nita-Rotaru, BaekGyu Kim", "title": "Are Self-Driving Cars Secure? Evasion Attacks against Deep Neural\n  Networks for Steering Angle Prediction", "comments": "Preprint of the work accepted for publication at the IEEE Workshop on\n  the Internet of Safe Things, San Francisco, CA, USA, May 23, 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep Neural Networks (DNNs) have tremendous potential in advancing the vision\nfor self-driving cars. However, the security of DNN models in this context\nleads to major safety implications and needs to be better understood. We\nconsider the case study of steering angle prediction from camera images, using\nthe dataset from the 2014 Udacity challenge. We demonstrate for the first time\nadversarial testing-time attacks for this application for both classification\nand regression settings. We show that minor modifications to the camera image\n(an L2 distance of 0.82 for one of the considered models) result in\nmis-classification of an image to any class of attacker's choice. Furthermore,\nour regression attack results in a significant increase in Mean Square Error\n(MSE) by a factor of 69 in the worst case.\n", "versions": [{"version": "v1", "created": "Mon, 15 Apr 2019 23:52:09 GMT"}], "update_date": "2019-04-17", "authors_parsed": [["Chernikova", "Alesia", ""], ["Oprea", "Alina", ""], ["Nita-Rotaru", "Cristina", ""], ["Kim", "BaekGyu", ""]]}, {"id": "1904.07380", "submitter": "Alireza Shamsoshoara", "authors": "Alireza Shamsoshoara, Mehrdad Khaledi, Fatemeh Afghah, Abolfazl Razi,\n  Jonathan Ashdown, Kurt Turck", "title": "A Solution for Dynamic Spectrum Management in Mission-Critical UAV\n  Networks", "comments": "10 Pages, 5 Figures, 2 Tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI cs.AI cs.LG cs.MA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we study the problem of spectrum scarcity in a network of\nunmanned aerial vehicles (UAVs) during mission-critical applications such as\ndisaster monitoring and public safety missions, where the pre-allocated\nspectrum is not sufficient to offer a high data transmission rate for real-time\nvideo-streaming. In such scenarios, the UAV network can lease part of the\nspectrum of a terrestrial licensed network in exchange for providing relaying\nservice. In order to optimize the performance of the UAV network and prolong\nits lifetime, some of the UAVs will function as a relay for the primary network\nwhile the rest of the UAVs carry out their sensing tasks. Here, we propose a\nteam reinforcement learning algorithm performed by the UAV's controller unit to\ndetermine the optimum allocation of sensing and relaying tasks among the UAVs\nas well as their relocation strategy at each time. We analyze the convergence\nof our algorithm and present simulation results to evaluate the system\nthroughput in different scenarios.\n", "versions": [{"version": "v1", "created": "Tue, 16 Apr 2019 00:28:01 GMT"}], "update_date": "2019-04-17", "authors_parsed": [["Shamsoshoara", "Alireza", ""], ["Khaledi", "Mehrdad", ""], ["Afghah", "Fatemeh", ""], ["Razi", "Abolfazl", ""], ["Ashdown", "Jonathan", ""], ["Turck", "Kurt", ""]]}, {"id": "1904.07387", "submitter": "Po-Yu Kao", "authors": "Po-Yu Kao, Angela Zhang, Michael Goebel, Jefferson W. Chen, B.S.\n  Manjunath", "title": "Predicting Fluid Intelligence of Children using T1-weighted MR Images\n  and a StackNet", "comments": "8 pages, 2 figures, 3 tables, Accepted by MICCAI ABCD-NP Challenge\n  2019; Added NDA", "journal-ref": null, "doi": "10.1007/978-3-030-31901-4_2", "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  In this work, we utilize T1-weighted MR images and StackNet to predict fluid\nintelligence in adolescents. Our framework includes feature extraction, feature\nnormalization, feature denoising, feature selection, training a StackNet, and\npredicting fluid intelligence. The extracted feature is the distribution of\ndifferent brain tissues in different brain parcellation regions. The proposed\nStackNet consists of three layers and 11 models. Each layer uses the\npredictions from all previous layers including the input layer. The proposed\nStackNet is tested on a public benchmark Adolescent Brain Cognitive Development\nNeurocognitive Prediction Challenge 2019 and achieves a mean squared error of\n82.42 on the combined training and validation set with 10-fold\ncross-validation. In addition, the proposed StackNet also achieves a mean\nsquared error of 94.25 on the testing data. The source code is available on\nGitHub.\n", "versions": [{"version": "v1", "created": "Tue, 16 Apr 2019 01:04:20 GMT"}, {"version": "v2", "created": "Tue, 7 May 2019 02:31:27 GMT"}, {"version": "v3", "created": "Tue, 12 May 2020 02:25:31 GMT"}], "update_date": "2020-05-13", "authors_parsed": [["Kao", "Po-Yu", ""], ["Zhang", "Angela", ""], ["Goebel", "Michael", ""], ["Chen", "Jefferson W.", ""], ["Manjunath", "B. S.", ""]]}, {"id": "1904.07392", "submitter": "Golnaz Ghiasi", "authors": "Golnaz Ghiasi, Tsung-Yi Lin, Ruoming Pang, Quoc V. Le", "title": "NAS-FPN: Learning Scalable Feature Pyramid Architecture for Object\n  Detection", "comments": "Accepted at CVPR 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Current state-of-the-art convolutional architectures for object detection are\nmanually designed. Here we aim to learn a better architecture of feature\npyramid network for object detection. We adopt Neural Architecture Search and\ndiscover a new feature pyramid architecture in a novel scalable search space\ncovering all cross-scale connections. The discovered architecture, named\nNAS-FPN, consists of a combination of top-down and bottom-up connections to\nfuse features across scales. NAS-FPN, combined with various backbone models in\nthe RetinaNet framework, achieves better accuracy and latency tradeoff compared\nto state-of-the-art object detection models. NAS-FPN improves mobile detection\naccuracy by 2 AP compared to state-of-the-art SSDLite with MobileNetV2 model in\n[32] and achieves 48.3 AP which surpasses Mask R-CNN [10] detection accuracy\nwith less computation time.\n", "versions": [{"version": "v1", "created": "Tue, 16 Apr 2019 01:32:33 GMT"}], "update_date": "2019-04-17", "authors_parsed": [["Ghiasi", "Golnaz", ""], ["Lin", "Tsung-Yi", ""], ["Pang", "Ruoming", ""], ["Le", "Quoc V.", ""]]}, {"id": "1904.07396", "submitter": "Saeed Anwar", "authors": "Saeed Anwar and Nick Barnes", "title": "Real Image Denoising with Feature Attention", "comments": "Accepted in ICCV (Oral), 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Deep convolutional neural networks perform better on images containing\nspatially invariant noise (synthetic noise); however, their performance is\nlimited on real-noisy photographs and requires multiple stage network modeling.\nTo advance the practicability of denoising algorithms, this paper proposes a\nnovel single-stage blind real image denoising network (RIDNet) by employing a\nmodular architecture. We use a residual on the residual structure to ease the\nflow of low-frequency information and apply feature attention to exploit the\nchannel dependencies. Furthermore, the evaluation in terms of quantitative\nmetrics and visual quality on three synthetic and four real noisy datasets\nagainst 19 state-of-the-art algorithms demonstrate the superiority of our\nRIDNet.\n", "versions": [{"version": "v1", "created": "Tue, 16 Apr 2019 01:55:08 GMT"}, {"version": "v2", "created": "Mon, 23 Mar 2020 04:57:08 GMT"}], "update_date": "2020-03-24", "authors_parsed": [["Anwar", "Saeed", ""], ["Barnes", "Nick", ""]]}, {"id": "1904.07402", "submitter": "Quanquan Shao", "authors": "Quanquan Shao, Jie Hu, Weiming Wang, Yi Fang, Wenhai Liu, Jin Qi, Jin\n  Ma", "title": "Suction Grasp Region Prediction using Self-supervised Learning for\n  Object Picking in Dense Clutter", "comments": "6 pages, 7 figures, conference", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.CV cs.LG", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  This paper focuses on robotic picking tasks in cluttered scenario. Because of\nthe diversity of poses, types of stack and complicated background in bin\npicking situation, it is much difficult to recognize and estimate their pose\nbefore grasping them. Here, this paper combines Resnet with U-net structure, a\nspecial framework of Convolution Neural Networks (CNN), to predict picking\nregion without recognition and pose estimation. And it makes robotic picking\nsystem learn picking skills from scratch. At the same time, we train the\nnetwork end to end with online samples. In the end of this paper, several\nexperiments are conducted to demonstrate the performance of our methods.\n", "versions": [{"version": "v1", "created": "Tue, 16 Apr 2019 02:03:57 GMT"}, {"version": "v2", "created": "Wed, 24 Apr 2019 09:01:33 GMT"}], "update_date": "2019-04-25", "authors_parsed": [["Shao", "Quanquan", ""], ["Hu", "Jie", ""], ["Wang", "Weiming", ""], ["Fang", "Yi", ""], ["Liu", "Wenhai", ""], ["Qi", "Jin", ""], ["Ma", "Jin", ""]]}, {"id": "1904.07404", "submitter": "Changxi Liu", "authors": "Changxi Liu, Hailong Yang, Rujun Sun, Zhongzhi Luan, Lin Gan, Guangwen\n  Yang, Depei Qian", "title": "swTVM: Exploring the Automated Compilation for Deep Learning on Sunway\n  Architecture", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.PL stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The flourish of deep learning frameworks and hardware platforms has been\ndemanding an efficient compiler that can shield the diversity in both software\nand hardware in order to provide application portability. Among the exiting\ndeep learning compilers, TVM is well known for its efficiency in code\ngeneration and optimization across diverse hardware devices. In the meanwhile,\nthe Sunway many-core processor renders itself as a competitive candidate for\nits attractive computational power in both scientific and deep learning\napplications. This paper combines the trends in these two directions.\nSpecifically, we propose swTVM that extends the original TVM to support\nahead-of-time compilation for architecture requiring cross-compilation such as\nSunway. In addition, we leverage the architecture features during the\ncompilation such as core group for massive parallelism, DMA for high bandwidth\nmemory transfer and local device memory for data locality, in order to generate\nefficient code for deep learning application on Sunway. The experimental\nresults show the ability of swTVM to automatically generate code for various\ndeep neural network models on Sunway. The performance of automatically\ngenerated code for AlexNet and VGG-19 by swTVM achieves 6.71x and 2.45x speedup\non average than hand-optimized OpenACC implementations on convolution and fully\nconnected layers respectively. This work is the first attempt from the compiler\nperspective to bridge the gap of deep learning and high performance\narchitecture particularly with productivity and efficiency in mind. We would\nlike to open source the implementation so that more people can embrace the\npower of deep learning compiler and Sunway many-core processor.\n", "versions": [{"version": "v1", "created": "Tue, 16 Apr 2019 02:13:05 GMT"}, {"version": "v2", "created": "Thu, 18 Apr 2019 13:09:43 GMT"}], "update_date": "2019-04-19", "authors_parsed": [["Liu", "Changxi", ""], ["Yang", "Hailong", ""], ["Sun", "Rujun", ""], ["Luan", "Zhongzhi", ""], ["Gan", "Lin", ""], ["Yang", "Guangwen", ""], ["Qian", "Depei", ""]]}, {"id": "1904.07409", "submitter": "Satoshi Takabe", "authors": "Satoshi Takabe, Tadashi Wadayama, Yonina C. Eldar", "title": "Complex Trainable ISTA for Linear and Nonlinear Inverse Problems", "comments": "6 pages, 3 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IT cs.LG math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Complex-field signal recovery problems from noisy linear/nonlinear\nmeasurements appear in many areas of signal processing and wireless\ncommunications. In this paper, we propose a trainable iterative signal recovery\nalgorithm named complex-field TISTA (C-TISTA) which treats complex-field\nnonlinear inverse problems. C-TISTA is based on the concept of deep unfolding\nand consists of a gradient descent step with the Wirtinger derivatives followed\nby a shrinkage step with a trainable complex-valued shrinkage function.\nImportantly, it contains a small number of trainable parameters so that its\ntraining process can be executed efficiently. Numerical results indicate that\nC-TISTA shows remarkable signal recovery performance compared with existing\nalgorithms.\n", "versions": [{"version": "v1", "created": "Tue, 16 Apr 2019 02:23:26 GMT"}, {"version": "v2", "created": "Thu, 17 Oct 2019 11:53:57 GMT"}], "update_date": "2019-10-18", "authors_parsed": [["Takabe", "Satoshi", ""], ["Wadayama", "Tadashi", ""], ["Eldar", "Yonina C.", ""]]}, {"id": "1904.07435", "submitter": "Agastya Kalra", "authors": "Agastya Kalra, Ben Peterson", "title": "Photofeeler-D3: A Neural Network with Voter Modeling for Dating Photo\n  Impression Prediction", "comments": "10 pages, 3 figures, 5 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In just a few years, online dating has become the dominant way that young\npeople meet to date, making the deceptively error-prone task of picking good\ndating profile photos vital to a generation's ability to form romantic\nconnections. Until now, artificial intelligence approaches to Dating Photo\nImpression Prediction (DPIP) have been very inaccurate, unadaptable to\nreal-world application, and have only taken into account a subject's physical\nattractiveness. To that effect, we propose Photofeeler-D3 - the first\nconvolutional neural network as accurate as 10 human votes for how smart,\ntrustworthy, and attractive the subject appears in highly variable dating\nphotos. Our \"attractive\" output is also applicable to Facial Beauty Prediction\n(FBP), making Photofeeler-D3 state-of-the-art for both DPIP and FBP. We achieve\nthis by leveraging Photofeeler's Dating Dataset (PDD) with over 1 million\nimages and tens of millions of votes, our novel technique of voter modeling,\nand cutting-edge computer vision techniques.\n", "versions": [{"version": "v1", "created": "Tue, 16 Apr 2019 03:44:08 GMT"}, {"version": "v2", "created": "Tue, 30 Apr 2019 18:00:48 GMT"}, {"version": "v3", "created": "Fri, 10 May 2019 17:38:08 GMT"}], "update_date": "2019-05-13", "authors_parsed": [["Kalra", "Agastya", ""], ["Peterson", "Ben", ""]]}, {"id": "1904.07451", "submitter": "Yash Goyal", "authors": "Yash Goyal and Ziyan Wu and Jan Ernst and Dhruv Batra and Devi Parikh\n  and Stefan Lee", "title": "Counterfactual Visual Explanations", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this work, we develop a technique to produce counterfactual visual\nexplanations. Given a 'query' image $I$ for which a vision system predicts\nclass $c$, a counterfactual visual explanation identifies how $I$ could change\nsuch that the system would output a different specified class $c'$. To do this,\nwe select a 'distractor' image $I'$ that the system predicts as class $c'$ and\nidentify spatial regions in $I$ and $I'$ such that replacing the identified\nregion in $I$ with the identified region in $I'$ would push the system towards\nclassifying $I$ as $c'$. We apply our approach to multiple image classification\ndatasets generating qualitative results showcasing the interpretability and\ndiscriminativeness of our counterfactual explanations. To explore the\neffectiveness of our explanations in teaching humans, we present machine\nteaching experiments for the task of fine-grained bird classification. We find\nthat users trained to distinguish bird species fare better when given access to\ncounterfactual explanations in addition to training examples.\n", "versions": [{"version": "v1", "created": "Tue, 16 Apr 2019 04:16:11 GMT"}, {"version": "v2", "created": "Tue, 11 Jun 2019 16:49:55 GMT"}], "update_date": "2019-06-12", "authors_parsed": [["Goyal", "Yash", ""], ["Wu", "Ziyan", ""], ["Ernst", "Jan", ""], ["Batra", "Dhruv", ""], ["Parikh", "Devi", ""], ["Lee", "Stefan", ""]]}, {"id": "1904.07453", "submitter": "Mari Ganesh Kumar", "authors": "Mari Ganesh Kumar, Suvidha Rupesh Kumar, Saranya M, B. Bharathi, Hema\n  A. Murthy", "title": "Spoof detection using time-delay shallow neural network and feature\n  switching", "comments": null, "journal-ref": "2019 IEEE Automatic Speech Recognition and Understanding Workshop\n  (ASRU), 1011--1017", "doi": "10.1109/ASRU46091.2019.9003824", "report-no": null, "categories": "eess.AS cs.CR cs.LG cs.SD", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Detecting spoofed utterances is a fundamental problem in voice-based\nbiometrics. Spoofing can be performed either by logical accesses like speech\nsynthesis, voice conversion or by physical accesses such as replaying the\npre-recorded utterance. Inspired by the state-of-the-art \\emph{x}-vector based\nspeaker verification approach, this paper proposes a time-delay shallow neural\nnetwork (TD-SNN) for spoof detection for both logical and physical access. The\nnovelty of the proposed TD-SNN system vis-a-vis conventional DNN systems is\nthat it can handle variable length utterances during testing. Performance of\nthe proposed TD-SNN systems and the baseline Gaussian mixture models (GMMs) is\nanalyzed on the ASV-spoof-2019 dataset. The performance of the systems is\nmeasured in terms of the minimum normalized tandem detection cost function\n(min-t-DCF). When studied with individual features, the TD-SNN system\nconsistently outperforms the GMM system for physical access. For logical\naccess, GMM surpasses TD-SNN systems for certain individual features. When\ncombined with the decision-level feature switching (DLFS) paradigm, the best\nTD-SNN system outperforms the best baseline GMM system on evaluation data with\na relative improvement of 48.03\\% and 49.47\\% for both logical and physical\naccess, respectively.\n", "versions": [{"version": "v1", "created": "Tue, 16 Apr 2019 04:22:26 GMT"}, {"version": "v2", "created": "Thu, 23 Jan 2020 09:25:59 GMT"}], "update_date": "2020-07-28", "authors_parsed": [["Kumar", "Mari Ganesh", ""], ["Kumar", "Suvidha Rupesh", ""], ["M", "Saranya", ""], ["Bharathi", "B.", ""], ["Murthy", "Hema A.", ""]]}, {"id": "1904.07457", "submitter": "Zezhou Cheng", "authors": "Zezhou Cheng, Matheus Gadelha, Subhransu Maji, Daniel Sheldon", "title": "A Bayesian Perspective on the Deep Image Prior", "comments": "CVPR 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The deep image prior was recently introduced as a prior for natural images.\nIt represents images as the output of a convolutional network with random\ninputs. For \"inference\", gradient descent is performed to adjust network\nparameters to make the output match observations. This approach yields good\nperformance on a range of image reconstruction tasks. We show that the deep\nimage prior is asymptotically equivalent to a stationary Gaussian process prior\nin the limit as the number of channels in each layer of the network goes to\ninfinity, and derive the corresponding kernel. This informs a Bayesian approach\nto inference. We show that by conducting posterior inference using stochastic\ngradient Langevin we avoid the need for early stopping, which is a drawback of\nthe current approach, and improve results for denoising and impainting tasks.\nWe illustrate these intuitions on a number of 1D and 2D signal reconstruction\ntasks.\n", "versions": [{"version": "v1", "created": "Tue, 16 Apr 2019 04:39:29 GMT"}], "update_date": "2019-04-17", "authors_parsed": [["Cheng", "Zezhou", ""], ["Gadelha", "Matheus", ""], ["Maji", "Subhransu", ""], ["Sheldon", "Daniel", ""]]}, {"id": "1904.07462", "submitter": "Nhat Ho", "authors": "Nhat Ho and Tianyi Lin and Michael I. Jordan", "title": "On Structured Filtering-Clustering: Global Error Bound and Optimal\n  First-Order Algorithms", "comments": "The first two authors contributed equally to this work. This version\n  greatly improves and expands the results in the previous version", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG stat.CO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In recent years, the filtering-clustering problems have been a central topic\nin statistics and machine learning, especially the $\\ell_1$-trend filtering and\n$\\ell_2$-convex clustering problems. In practice, such structured problems are\ntypically solved by first-order algorithms despite the extremely\nill-conditioned structures of difference operator matrices. Inspired by the\ndesire to analyze the convergence rates of these algorithms, we show that for a\nlarge class of filtering-clustering problems, a \\textit{global error bound}\ncondition is satisfied for the dual filtering-clustering problems when a\ncertain regularization is chosen. Based on this result, we show that many\nfirst-order algorithms attain the \\textit{optimal rate of convergence} in\ndifferent settings. In particular, we establish a generalized dual gradient\nascent (GDGA) algorithmic framework with several subroutines. In deterministic\nsetting when the subroutine is accelerated gradient descent (AGD), the\nresulting algorithm attains the linear convergence. This linear convergence\nalso holds for the finite-sum setting in which the subroutine is the Katyusha\nalgorithm. We also demonstrate that the GDGA with stochastic gradient descent\n(SGD) subroutine attains the optimal rate of convergence up to the logarithmic\nfactor, shedding the light to the possibility of solving the\nfiltering-clustering problems efficiently in online setting. Experiments\nconducted on $\\ell_1$-trend filtering problems illustrate the favorable\nperformance of our algorithms over other competing algorithms.\n", "versions": [{"version": "v1", "created": "Tue, 16 Apr 2019 04:54:47 GMT"}, {"version": "v2", "created": "Mon, 5 Aug 2019 00:13:20 GMT"}], "update_date": "2019-08-06", "authors_parsed": [["Ho", "Nhat", ""], ["Lin", "Tianyi", ""], ["Jordan", "Michael I.", ""]]}, {"id": "1904.07464", "submitter": "Yeqi Liu", "authors": "Yeqi Liu, Chuanyang Gong, Ling Yang, Yingyi Chen", "title": "DSTP-RNN: a dual-stage two-phase attention-based recurrent neural\n  networks for long-term and multivariate time series prediction", "comments": "6 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Long-term prediction of multivariate time series is still an important but\nchallenging problem. The key to solve this problem is to capture the spatial\ncorrelations at the same time, the spatio-temporal relationships at different\ntimes and the long-term dependence of the temporal relationships between\ndifferent series. Attention-based recurrent neural networks (RNN) can\neffectively represent the dynamic spatio-temporal relationships between\nexogenous series and target series, but it only performs well in one-step time\nprediction and short-term time prediction. In this paper, inspired by human\nattention mechanism including the dual-stage two-phase (DSTP) model and the\ninfluence mechanism of target information and non-target information, we\npropose DSTP-based RNN (DSTP-RNN) and DSTP-RNN-2 respectively for long-term\ntime series prediction. Specifically, we first propose the DSTP-based structure\nto enhance the spatial correlations between exogenous series. The first phase\nproduces violent but decentralized response weight, while the second phase\nleads to stationary and concentrated response weight. Secondly, we employ\nmultiple attentions on target series to boost the long-term dependence.\nFinally, we study the performance of deep spatial attention mechanism and\nprovide experiment and interpretation. Our methods outperform nine baseline\nmethods on four datasets in the fields of energy, finance, environment and\nmedicine, respectively.\n", "versions": [{"version": "v1", "created": "Tue, 16 Apr 2019 05:03:45 GMT"}], "update_date": "2019-04-17", "authors_parsed": [["Liu", "Yeqi", ""], ["Gong", "Chuanyang", ""], ["Yang", "Ling", ""], ["Chen", "Yingyi", ""]]}, {"id": "1904.07478", "submitter": "Rebecca Simpson", "authors": "Becks Simpson, Francis Dutil, Yoshua Bengio and Joseph Paul Cohen", "title": "GradMask: Reduce Overfitting by Regularizing Saliency", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG eess.IV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  With too few samples or too many model parameters, overfitting can inhibit\nthe ability to generalise predictions to new data. Within medical imaging, this\ncan occur when features are incorrectly assigned importance such as distinct\nhospital specific artifacts, leading to poor performance on a new dataset from\na different institution without those features, which is undesirable. Most\nregularization methods do not explicitly penalize the incorrect association of\nthese features to the target class and hence fail to address this issue. We\npropose a regularization method, GradMask, which penalizes saliency maps\ninferred from the classifier gradients when they are not consistent with the\nlesion segmentation. This prevents non-tumor related features to contribute to\nthe classification of unhealthy samples. We demonstrate that this method can\nimprove test accuracy between 1-3% compared to the baseline without GradMask,\nshowing that it has an impact on reducing overfitting.\n", "versions": [{"version": "v1", "created": "Tue, 16 Apr 2019 05:57:50 GMT"}], "update_date": "2019-07-31", "authors_parsed": [["Simpson", "Becks", ""], ["Dutil", "Francis", ""], ["Bengio", "Yoshua", ""], ["Cohen", "Joseph Paul", ""]]}, {"id": "1904.07482", "submitter": "Guangxiang Zhu", "authors": "Guangxiang Zhu, Jianhao Wang, Zhizhou Ren, Zichuan Lin, and Chongjie\n  Zhang", "title": "Object-Oriented Dynamics Learning through Multi-Level Abstraction", "comments": "Accepted to the Thirthy-Fourth AAAI Conference On Artificial\n  Intelligence (AAAI), 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Object-based approaches for learning action-conditioned dynamics has\ndemonstrated promise for generalization and interpretability. However, existing\napproaches suffer from structural limitations and optimization difficulties for\ncommon environments with multiple dynamic objects. In this paper, we present a\nnovel self-supervised learning framework, called Multi-level Abstraction\nObject-oriented Predictor (MAOP), which employs a three-level learning\narchitecture that enables efficient object-based dynamics learning from raw\nvisual observations. We also design a spatial-temporal relational reasoning\nmechanism for MAOP to support instance-level dynamics learning and handle\npartial observability. Our results show that MAOP significantly outperforms\nprevious methods in terms of sample efficiency and generalization over novel\nenvironments for learning environment models. We also demonstrate that learned\ndynamics models enable efficient planning in unseen environments, comparable to\ntrue environment models. In addition, MAOP learns semantically and visually\ninterpretable disentangled representations.\n", "versions": [{"version": "v1", "created": "Tue, 16 Apr 2019 06:01:17 GMT"}, {"version": "v2", "created": "Sat, 25 May 2019 03:46:55 GMT"}, {"version": "v3", "created": "Sat, 30 Nov 2019 10:29:10 GMT"}, {"version": "v4", "created": "Thu, 5 Dec 2019 06:05:28 GMT"}], "update_date": "2019-12-06", "authors_parsed": [["Zhu", "Guangxiang", ""], ["Wang", "Jianhao", ""], ["Ren", "Zhizhou", ""], ["Lin", "Zichuan", ""], ["Zhang", "Chongjie", ""]]}, {"id": "1904.07496", "submitter": "Chong Peng", "authors": "Chong Peng, Qiang Cheng", "title": "Discriminative Ridge Machine: A Classifier for High-Dimensional Data or\n  Imbalanced Data", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce a discriminative regression approach to supervised\nclassification in this paper. It estimates a representation model while\naccounting for discriminativeness between classes, thereby enabling accurate\nderivation of categorical information. This new type of regression models\nextends existing models such as ridge, lasso, and group lasso through\nexplicitly incorporating discriminative information. As a special case we focus\non a quadratic model that admits a closed-form analytical solution. The\ncorresponding classifier is called discriminative regression machine (DRM).\nThree iterative algorithms are further established for the DRM to enhance the\nefficiency and scalability for real applications. Our approach and the\nalgorithms are applicable to general types of data including images,\nhigh-dimensional data, and imbalanced data. We compare the DRM with currently\nstate-of-the-art classifiers. Our extensive experimental results show superior\nperformance of the DRM and confirm the effectiveness of the proposed approach.\n", "versions": [{"version": "v1", "created": "Tue, 16 Apr 2019 07:07:01 GMT"}, {"version": "v2", "created": "Mon, 30 Dec 2019 17:54:33 GMT"}], "update_date": "2020-01-01", "authors_parsed": [["Peng", "Chong", ""], ["Cheng", "Qiang", ""]]}, {"id": "1904.07497", "submitter": "Chong Peng", "authors": "Chong Peng, Chenglizhao Chen, Zhao Kang, Jianbo Li, Qiang Cheng", "title": "RES-PCA: A Scalable Approach to Recovering Low-rank Matrices", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Robust principal component analysis (RPCA) has drawn significant attentions\ndue to its powerful capability in recovering low-rank matrices as well as\nsuccessful appplications in various real world problems. The current\nstate-of-the-art algorithms usually need to solve singular value decomposition\nof large matrices, which generally has at least a quadratic or even cubic\ncomplexity. This drawback has limited the application of RPCA in solving real\nworld problems. To combat this drawback, in this paper we propose a new type of\nRPCA method, RES-PCA, which is linearly efficient and scalable in both data\nsize and dimension. For comparison purpose, AltProj, an existing scalable\napproach to RPCA requires the precise knowlwdge of the true rank; otherwise, it\nmay fail to recover low-rank matrices. By contrast, our method works with or\nwithout knowing the true rank; even when both methods work, our method is\nfaster. Extensive experiments have been performed and testified to the\neffectiveness of proposed method quantitatively and in visual quality, which\nsuggests that our method is suitable to be employed as a light-weight, scalable\ncomponent for RPCA in any application pipelines.\n", "versions": [{"version": "v1", "created": "Tue, 16 Apr 2019 07:07:44 GMT"}], "update_date": "2019-04-17", "authors_parsed": [["Peng", "Chong", ""], ["Chen", "Chenglizhao", ""], ["Kang", "Zhao", ""], ["Li", "Jianbo", ""], ["Cheng", "Qiang", ""]]}, {"id": "1904.07511", "submitter": "Lingchen Huang", "authors": "Lingchen Huang, Huazi Zhang, Rong Li, Yiqun Ge, Jun Wang", "title": "Reinforcement Learning for Nested Polar Code Construction", "comments": "8 pages, 10 figures, propose a multi-stage genetic algorithm", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IT cs.LG math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we model nested polar code construction as a Markov decision\nprocess (MDP), and tackle it with advanced reinforcement learning (RL)\ntechniques. First, an MDP environment with state, action, and reward is defined\nin the context of polar coding. Specifically, a state represents the\nconstruction of an $(N,K)$ polar code, an action specifies its reduction to an\n$(N,K-1)$ subcode, and reward is the decoding performance. A neural network\narchitecture consisting of both policy and value networks is proposed to\ngenerate actions based on the observed states, aiming at maximizing the overall\nrewards. A loss function is defined to trade off between exploitation and\nexploration. To further improve learning efficiency and quality, an `integrated\nlearning' paradigm is proposed. It first employs a genetic algorithm to\ngenerate a population of (sub-)optimal polar codes for each $(N,K)$, and then\nuses them as prior knowledge to refine the policy in RL. Such a paradigm is\nshown to accelerate the training process, and converge at better performances.\nSimulation results show that the proposed learning-based polar constructions\nachieve comparable, or even better, performances than the state of the art\nunder successive cancellation list (SCL) decoders. Last but not least, this is\nachieved without exploiting any expert knowledge from polar coding theory in\nthe learning algorithms.\n", "versions": [{"version": "v1", "created": "Tue, 16 Apr 2019 07:47:51 GMT"}, {"version": "v2", "created": "Sat, 9 Nov 2019 03:05:15 GMT"}], "update_date": "2019-11-12", "authors_parsed": [["Huang", "Lingchen", ""], ["Zhang", "Huazi", ""], ["Li", "Rong", ""], ["Ge", "Yiqun", ""], ["Wang", "Jun", ""]]}, {"id": "1904.07516", "submitter": "Siyu Chen", "authors": "Zhijian Luo, Siyu Chen, Yuntao Qian", "title": "A Deep Optimization Approach for Image Deconvolution", "comments": "12 pages, 16 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In blind image deconvolution, priors are often leveraged to constrain the\nsolution space, so as to alleviate the under-determinacy. Priors which are\ntrained separately from the task of deconvolution tend to be instable, or\nineffective. We propose the Golf Optimizer, a novel but simple form of network\nthat learns deep priors from data with better propagation behavior. Like\nplaying golf, our method first estimates an aggressive propagation towards\noptimum using one network, and recurrently applies a residual CNN to learn the\ngradient of prior for delicate correction on restoration. Experiments show that\nour network achieves competitive performance on GoPro dataset, and our model is\nextremely lightweight compared with the state-of-art works.\n", "versions": [{"version": "v1", "created": "Tue, 16 Apr 2019 07:52:45 GMT"}], "update_date": "2019-04-17", "authors_parsed": [["Luo", "Zhijian", ""], ["Chen", "Siyu", ""], ["Qian", "Yuntao", ""]]}, {"id": "1904.07535", "submitter": "Shun Zheng", "authors": "Shun Zheng, Wei Cao, Wei Xu, Jiang Bian", "title": "Doc2EDAG: An End-to-End Document-level Framework for Chinese Financial\n  Event Extraction", "comments": "Accepted by EMNLP 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Most existing event extraction (EE) methods merely extract event arguments\nwithin the sentence scope. However, such sentence-level EE methods struggle to\nhandle soaring amounts of documents from emerging applications, such as\nfinance, legislation, health, etc., where event arguments always scatter across\ndifferent sentences, and even multiple such event mentions frequently co-exist\nin the same document. To address these challenges, we propose a novel\nend-to-end model, Doc2EDAG, which can generate an entity-based directed acyclic\ngraph to fulfill the document-level EE (DEE) effectively. Moreover, we\nreformalize a DEE task with the no-trigger-words design to ease the\ndocument-level event labeling. To demonstrate the effectiveness of Doc2EDAG, we\nbuild a large-scale real-world dataset consisting of Chinese financial\nannouncements with the challenges mentioned above. Extensive experiments with\ncomprehensive analyses illustrate the superiority of Doc2EDAG over\nstate-of-the-art methods. Data and codes can be found at\nhttps://github.com/dolphin-zs/Doc2EDAG.\n", "versions": [{"version": "v1", "created": "Tue, 16 Apr 2019 08:39:06 GMT"}, {"version": "v2", "created": "Mon, 23 Sep 2019 03:14:54 GMT"}], "update_date": "2019-09-24", "authors_parsed": [["Zheng", "Shun", ""], ["Cao", "Wei", ""], ["Xu", "Wei", ""], ["Bian", "Jiang", ""]]}, {"id": "1904.07556", "submitter": "Herman Kamper", "authors": "Ryan Eloff, Andr\\'e Nortje, Benjamin van Niekerk, Avashna Govender,\n  Leanne Nortje, Arnu Pretorius, Elan van Biljon, Ewald van der Westhuizen,\n  Lisa van Staden, Herman Kamper", "title": "Unsupervised acoustic unit discovery for speech synthesis using discrete\n  latent-variable neural networks", "comments": "Interspeech 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG cs.SD eess.AS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  For our submission to the ZeroSpeech 2019 challenge, we apply discrete\nlatent-variable neural networks to unlabelled speech and use the discovered\nunits for speech synthesis. Unsupervised discrete subword modelling could be\nuseful for studies of phonetic category learning in infants or in low-resource\nspeech technology requiring symbolic input. We use an autoencoder (AE)\narchitecture with intermediate discretisation. We decouple acoustic unit\ndiscovery from speaker modelling by conditioning the AE's decoder on the\ntraining speaker identity. At test time, unit discovery is performed on speech\nfrom an unseen speaker, followed by unit decoding conditioned on a known target\nspeaker to obtain reconstructed filterbanks. This output is fed to a neural\nvocoder to synthesise speech in the target speaker's voice. For discretisation,\ncategorical variational autoencoders (CatVAEs), vector-quantised VAEs (VQ-VAEs)\nand straight-through estimation are compared at different compression levels on\ntwo languages. Our final model uses convolutional encoding, VQ-VAE\ndiscretisation, deconvolutional decoding and an FFTNet vocoder. We show that\ndecoupled speaker conditioning intrinsically improves discrete acoustic\nrepresentations, yielding competitive synthesis quality compared to the\nchallenge baseline.\n", "versions": [{"version": "v1", "created": "Tue, 16 Apr 2019 09:38:01 GMT"}, {"version": "v2", "created": "Fri, 28 Jun 2019 12:04:07 GMT"}], "update_date": "2019-07-01", "authors_parsed": [["Eloff", "Ryan", ""], ["Nortje", "Andr\u00e9", ""], ["van Niekerk", "Benjamin", ""], ["Govender", "Avashna", ""], ["Nortje", "Leanne", ""], ["Pretorius", "Arnu", ""], ["van Biljon", "Elan", ""], ["van der Westhuizen", "Ewald", ""], ["van Staden", "Lisa", ""], ["Kamper", "Herman", ""]]}, {"id": "1904.07568", "submitter": "Minghao Yin", "authors": "Minghao Yin, Xiu Li, Yongbing Zhang, Shiqi Wang", "title": "On the Mathematical Understanding of ResNet with Feynman Path Integral", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG hep-th stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we aim to understand Residual Network (ResNet) in a\nscientifically sound way by providing a bridge between ResNet and Feynman path\nintegral. In particular, we prove that the effect of residual block is\nequivalent to partial differential equation, and the ResNet transforming\nprocess can be equivalently converted to Feynman path integral. These\nconclusions greatly help us mathematically understand the advantage of ResNet\nin addressing the gradient vanishing issue. More importantly, our analyses\noffer a path integral view of ResNet, and demonstrate that the output of\ncertain network can be obtained by adding contributions of all paths. Moreover,\nthe contribution of each path is proportional to e^{-S}, where S is the action\ngiven by time integral of Lagrangian L. This lays the solid foundation in the\nunderstanding of ResNet, and provides insights in the future design of\nconvolutional neural network architecture. Based on these results, we have\ndesigned the network using partial differential operators, which further\nvalidates our theoritical analyses.\n", "versions": [{"version": "v1", "created": "Tue, 16 Apr 2019 09:59:18 GMT"}], "update_date": "2019-04-17", "authors_parsed": [["Yin", "Minghao", ""], ["Li", "Xiu", ""], ["Zhang", "Yongbing", ""], ["Wang", "Shiqi", ""]]}, {"id": "1904.07577", "submitter": "Taban Eslami", "authors": "Taban Eslami, Vahid Mirjalili, Alvis Fong, Angela Laird and Fahad\n  Saeed", "title": "ASD-DiagNet: A hybrid learning approach for detection of Autism Spectrum\n  Disorder using fMRI data", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG eess.IV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Mental disorders such as Autism Spectrum Disorders (ASD) are heterogeneous\ndisorders that are notoriously difficult to diagnose, especially in children.\nThe current psychiatric diagnostic process is based purely on the behavioural\nobservation of symptomology (DSM-5/ICD-10) and may be prone to over-prescribing\nof drugs due to misdiagnosis. In order to move the field towards more\nquantitative fashion, we need advanced and scalable machine learning\ninfrastructure that will allow us to identify reliable biomarkers of mental\nhealth disorders. In this paper, we propose a framework called ASD-DiagNet for\nclassifying subjects with ASD from healthy subjects by using only fMRI data. We\ndesigned and implemented a joint learning procedure using an autoencoder and a\nsingle layer perceptron which results in improved quality of extracted features\nand optimized parameters for the model. Further, we designed and implemented a\ndata augmentation strategy, based on linear interpolation on available feature\nvectors, that allows us to produce synthetic datasets needed for training of\nmachine learning models. The proposed approach is evaluated on a public dataset\nprovided by Autism Brain Imaging Data Exchange including 1035 subjects coming\nfrom 17 different brain imaging centers. Our machine learning model outperforms\nother state of the art methods from 13 imaging centers with increase in\nclassification accuracy up to 20% with maximum accuracy of 80%. The machine\nlearning technique presented in this paper, in addition to yielding better\nquality, gives enormous advantages in terms of execution time (40 minutes vs. 6\nhours on other methods). The implemented code is available as GPL license on\nGitHub portal of our lab (https://github.com/pcdslab/ASD-DiagNet).\n", "versions": [{"version": "v1", "created": "Tue, 16 Apr 2019 10:19:58 GMT"}], "update_date": "2019-04-17", "authors_parsed": [["Eslami", "Taban", ""], ["Mirjalili", "Vahid", ""], ["Fong", "Alvis", ""], ["Laird", "Angela", ""], ["Saeed", "Fahad", ""]]}, {"id": "1904.07594", "submitter": "Fabien Lauer", "authors": "Fabien Lauer (ABC)", "title": "Risk Bounds for Learning Multiple Components with Permutation-Invariant\n  Losses", "comments": null, "journal-ref": "23rd International Conference on Artificial Intelligence and\n  Statistics (AISTATS), 2020, Palermo, Italy", "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper proposes a simple approach to derive efficient error bounds for\nlearning multiple components with sparsity-inducing regularization. We show\nthat for such regularization schemes, known decompositions of the Rademacher\ncomplexity over the components can be used in a more efficient manner to result\nin tighter bounds without too much effort. We give examples of application to\nswitching regression and center-based clustering/vector quantization. Then, the\ncomplete workflow is illustrated on the problem of subspace clustering, for\nwhich decomposition results were not previously available. For all these\nproblems, the proposed approach yields risk bounds with mild dependencies on\nthe number of components and completely removes this dependence for nonconvex\nregularization schemes that could not be handled by previous methods.\n", "versions": [{"version": "v1", "created": "Tue, 16 Apr 2019 11:08:23 GMT"}, {"version": "v2", "created": "Thu, 23 Jan 2020 15:32:57 GMT"}], "update_date": "2020-01-24", "authors_parsed": [["Lauer", "Fabien", "", "ABC"]]}, {"id": "1904.07612", "submitter": "Michael Michelashvili", "authors": "Michael Michelashvili, Lior Wolf", "title": "Speech Denoising by Accumulating Per-Frequency Modeling Fluctuations", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SD cs.LG eess.AS stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We present a method for audio denoising that combines processing done in both\nthe time domain and the time-frequency domain. Given a noisy audio clip, the\nmethod trains a deep neural network to fit this signal. Since the fitting is\nonly partly successful and is able to better capture the underlying clean\nsignal than the noise, the output of the network helps to disentangle the clean\naudio from the rest of the signal. This is done by accumulating a fitting score\nper time-frequency bin and applying the time-frequency domain filtering based\non the obtained scores. The method is completely unsupervised and only trains\non the specific audio clip that is being denoised. Our experiments demonstrate\nfavorable performance in comparison to the literature methods. Our code and\nsamples are available at github.com/mosheman5/DNP and as supplementary. Index\nTerms: Audio denoising; Unsupervised learning\n", "versions": [{"version": "v1", "created": "Tue, 16 Apr 2019 12:06:58 GMT"}, {"version": "v2", "created": "Tue, 12 Nov 2019 09:43:44 GMT"}, {"version": "v3", "created": "Mon, 8 Jun 2020 20:38:08 GMT"}], "update_date": "2020-06-11", "authors_parsed": [["Michelashvili", "Michael", ""], ["Wolf", "Lior", ""]]}, {"id": "1904.07629", "submitter": "Zhaoning Li", "authors": "Zhaoning Li, Qi Li, Xiaotian Zou, Jiangtao Ren", "title": "Causality Extraction based on Self-Attentive BiLSTM-CRF with Transferred\n  Embeddings", "comments": "39 pages, 11 figures, 6 tables", "journal-ref": "Neurocomputing, Volume 423, 2021, Pages 207-219", "doi": "10.1016/j.neucom.2020.08.078", "report-no": null, "categories": "cs.CL cs.IR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Causality extraction from natural language texts is a challenging open\nproblem in artificial intelligence. Existing methods utilize patterns,\nconstraints, and machine learning techniques to extract causality, heavily\ndepending on domain knowledge and requiring considerable human effort and time\nfor feature engineering. In this paper, we formulate causality extraction as a\nsequence labeling problem based on a novel causality tagging scheme. On this\nbasis, we propose a neural causality extractor with the BiLSTM-CRF model as the\nbackbone, named SCITE (Self-attentive BiLSTM-CRF wIth Transferred Embeddings),\nwhich can directly extract cause and effect without extracting candidate causal\npairs and identifying their relations separately. To address the problem of\ndata insufficiency, we transfer contextual string embeddings, also known as\nFlair embeddings, which are trained on a large corpus in our task. In addition,\nto improve the performance of causality extraction, we introduce a multihead\nself-attention mechanism into SCITE to learn the dependencies between causal\nwords. We evaluate our method on a public dataset, and experimental results\ndemonstrate that our method achieves significant and consistent improvement\ncompared to baselines.\n", "versions": [{"version": "v1", "created": "Tue, 16 Apr 2019 12:54:00 GMT"}, {"version": "v2", "created": "Sat, 20 Apr 2019 19:00:21 GMT"}, {"version": "v3", "created": "Mon, 29 Apr 2019 13:59:57 GMT"}, {"version": "v4", "created": "Tue, 29 Oct 2019 07:14:23 GMT"}, {"version": "v5", "created": "Wed, 17 Jun 2020 16:28:53 GMT"}, {"version": "v6", "created": "Sun, 8 Nov 2020 13:30:15 GMT"}], "update_date": "2020-11-10", "authors_parsed": [["Li", "Zhaoning", ""], ["Li", "Qi", ""], ["Zou", "Xiaotian", ""], ["Ren", "Jiangtao", ""]]}, {"id": "1904.07633", "submitter": "Oguzhan Gencoglu", "authors": "Oguzhan Gencoglu, Mark van Gils, Esin Guldogan, Chamin Morikawa,\n  Mehmet S\\\"uzen, Mathias Gruber, Jussi Leinonen, Heikki Huttunen", "title": "HARK Side of Deep Learning -- From Grad Student Descent to Automated\n  Machine Learning", "comments": "13 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent advancements in machine learning research, i.e., deep learning,\nintroduced methods that excel conventional algorithms as well as humans in\nseveral complex tasks, ranging from detection of objects in images and speech\nrecognition to playing difficult strategic games. However, the current\nmethodology of machine learning research and consequently, implementations of\nthe real-world applications of such algorithms, seems to have a recurring\nHARKing (Hypothesizing After the Results are Known) issue. In this work, we\nelaborate on the algorithmic, economic and social reasons and consequences of\nthis phenomenon. We present examples from current common practices of\nconducting machine learning research (e.g. avoidance of reporting negative\nresults) and failure of generalization ability of the proposed algorithms and\ndatasets in actual real-life usage. Furthermore, a potential future trajectory\nof machine learning research and development from the perspective of\naccountable, unbiased, ethical and privacy-aware algorithmic decision making is\ndiscussed. We would like to emphasize that with this discussion we neither\nclaim to provide an exhaustive argumentation nor blame any specific institution\nor individual on the raised issues. This is simply a discussion put forth by\nus, insiders of the machine learning field, reflecting on us.\n", "versions": [{"version": "v1", "created": "Tue, 16 Apr 2019 13:02:01 GMT"}], "update_date": "2019-04-17", "authors_parsed": [["Gencoglu", "Oguzhan", ""], ["van Gils", "Mark", ""], ["Guldogan", "Esin", ""], ["Morikawa", "Chamin", ""], ["S\u00fczen", "Mehmet", ""], ["Gruber", "Mathias", ""], ["Leinonen", "Jussi", ""], ["Huttunen", "Heikki", ""]]}, {"id": "1904.07637", "submitter": "Aur\\'elien Decelle", "authors": "Aur\\'elien Decelle and Victor Martin-Mayor and Beatriz Seoane", "title": "Learning a Local Symmetry with Neural-Networks", "comments": "4 pages, 4 figures + appendices", "journal-ref": "Phys. Rev. E 100, 050102 (2019)", "doi": "10.1103/PhysRevE.100.050102", "report-no": null, "categories": "cond-mat.dis-nn cond-mat.stat-mech cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We explore the capacity of neural networks to detect a symmetry with complex\nlocal and non-local patterns : the gauge symmetry Z 2 . This symmetry is\npresent in physical problems from topological transitions to QCD, and controls\nthe computational hardness of instances of spin-glasses. Here, we show how to\ndesign a neural network, and a dataset, able to learn this symmetry and to find\ncompressed latent representations of the gauge orbits. Our method pays special\nattention to system-wrapping loops, the so-called Polyakov loops, known to be\nparticularly relevant for computational complexity.\n", "versions": [{"version": "v1", "created": "Tue, 16 Apr 2019 13:11:04 GMT"}, {"version": "v2", "created": "Fri, 7 Jun 2019 15:11:20 GMT"}], "update_date": "2019-11-13", "authors_parsed": [["Decelle", "Aur\u00e9lien", ""], ["Martin-Mayor", "Victor", ""], ["Seoane", "Beatriz", ""]]}, {"id": "1904.07640", "submitter": "Alison Callahan", "authors": "Alison Callahan, Jason A Fries, Christopher R\\'e, James I Huddleston\n  III, Nicholas J Giori, Scott Delp, Nigam H Shah", "title": "Medical device surveillance with electronic health records", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Post-market medical device surveillance is a challenge facing manufacturers,\nregulatory agencies, and health care providers. Electronic health records are\nvaluable sources of real world evidence to assess device safety and track\ndevice-related patient outcomes over time. However, distilling this evidence\nremains challenging, as information is fractured across clinical notes and\nstructured records. Modern machine learning methods for machine reading promise\nto unlock increasingly complex information from text, but face barriers due to\ntheir reliance on large and expensive hand-labeled training sets. To address\nthese challenges, we developed and validated state-of-the-art deep learning\nmethods that identify patient outcomes from clinical notes without requiring\nhand-labeled training data. Using hip replacements as a test case, our methods\naccurately extracted implant details and reports of complications and pain from\nelectronic health records with up to 96.3% precision, 98.5% recall, and 97.4%\nF1, improved classification performance by 12.7- 53.0% over rule-based methods,\nand detected over 6 times as many complication events compared to using\nstructured data alone. Using these events to assess complication-free\nsurvivorship of different implant systems, we found significant variation\nbetween implants, including for risk of revision surgery, which could not be\ndetected using coded data alone. Patients with revision surgeries had more hip\npain mentions in the post-hip replacement, pre-revision period compared to\npatients with no evidence of revision surgery (mean hip pain mentions 4.97 vs.\n3.23; t = 5.14; p < 0.001). Some implant models were associated with higher or\nlower rates of hip pain mentions. Our methods complement existing surveillance\nmechanisms by requiring orders of magnitude less hand-labeled training data,\noffering a scalable solution for national medical device surveillance.\n", "versions": [{"version": "v1", "created": "Wed, 3 Apr 2019 18:48:20 GMT"}], "update_date": "2019-04-17", "authors_parsed": [["Callahan", "Alison", ""], ["Fries", "Jason A", ""], ["R\u00e9", "Christopher", ""], ["Huddleston", "James I", "III"], ["Giori", "Nicholas J", ""], ["Delp", "Scott", ""], ["Shah", "Nigam H", ""]]}, {"id": "1904.07656", "submitter": "Syed Qureshi", "authors": "Syed Arbaaz Qureshi, Mohammed Hasanuzzaman, Sriparna Saha, Ga\\\"el Dias", "title": "The Verbal and Non Verbal Signals of Depression -- Combining Acoustics,\n  Text and Visuals for Estimating Depression Level", "comments": "10 pages including references, 2 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Depression is a serious medical condition that is suffered by a large number\nof people around the world. It significantly affects the way one feels, causing\na persistent lowering of mood. In this paper, we propose a novel\nattention-based deep neural network which facilitates the fusion of various\nmodalities. We use this network to regress the depression level. Acoustic, text\nand visual modalities have been used to train our proposed network. Various\nexperiments have been carried out on the benchmark dataset, namely, Distress\nAnalysis Interview Corpus - a Wizard of Oz (DAIC-WOZ). From the results, we\nempirically justify that the fusion of all three modalities helps in giving the\nmost accurate estimation of depression level. Our proposed approach outperforms\nthe state-of-the-art by 7.17% on root mean squared error (RMSE) and 8.08% on\nmean absolute error (MAE).\n", "versions": [{"version": "v1", "created": "Tue, 2 Apr 2019 21:18:00 GMT"}], "update_date": "2019-04-17", "authors_parsed": [["Qureshi", "Syed Arbaaz", ""], ["Hasanuzzaman", "Mohammed", ""], ["Saha", "Sriparna", ""], ["Dias", "Ga\u00ebl", ""]]}, {"id": "1904.07686", "submitter": "Anahid Naghibzadeh-Jalali", "authors": "Anahid Jalali, Clemens Heistracher, Alexander Schindler, Bernhard\n  Haslhofer, Tanja Nemeth, Robert Glawar, Wilfried Sihn and Peter De Boer", "title": "Predicting Time-to-Failure of Plasma Etching Equipment using Machine\n  Learning", "comments": "8 pages, 10 figures, accepted in IEEEE/PHM 2019 Conference", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Predicting unscheduled breakdowns of plasma etching equipment can reduce\nmaintenance costs and production losses in the semiconductor industry. However,\nplasma etching is a complex procedure and it is hard to capture all relevant\nequipment properties and behaviors in a single physical model. Machine learning\noffers an alternative for predicting upcoming machine failures based on\nrelevant data points. In this paper, we describe three different machine\nlearning tasks that can be used for that purpose: (i) predicting\nTime-To-Failure (TTF), (ii) predicting health state, and (iii) predicting TTF\nintervals of an equipment. Our results show that trained machine learning\nmodels can outperform benchmarks resembling human judgments in all three tasks.\nThis suggests that machine learning offers a viable alternative to currently\ndeployed plasma etching equipment maintenance strategies and decision making\nprocesses.\n", "versions": [{"version": "v1", "created": "Tue, 16 Apr 2019 14:07:17 GMT"}], "update_date": "2019-04-17", "authors_parsed": [["Jalali", "Anahid", ""], ["Heistracher", "Clemens", ""], ["Schindler", "Alexander", ""], ["Haslhofer", "Bernhard", ""], ["Nemeth", "Tanja", ""], ["Glawar", "Robert", ""], ["Sihn", "Wilfried", ""], ["De Boer", "Peter", ""]]}, {"id": "1904.07687", "submitter": "Andrei Damian I", "authors": "Andrei Damian, Laurentiu Piciu, Sergiu Turlea, Nicolae Tapus", "title": "Advanced Customer Activity Prediction based on Deep Hierarchic\n  Encoder-Decoders", "comments": "2019 22nd International Conference on Control Systems and Computer\n  Science (CSCS)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Product recommender systems and customer profiling techniques have always\nbeen a priority in online retail. Recent machine learning research advances and\nalso wide availability of massive parallel numerical computing has enabled\nvarious approaches and directions of recommender systems advancement. Worth to\nmention is the fact that in past years multiple traditional \"offline\" retail\nbusiness are gearing more and more towards employing inferential and even\npredictive analytics both to stock-related problems such as predictive\nreplenishment but also to enrich customer interaction experience. One of the\nmost important areas of recommender systems research and development is that of\nDeep Learning based models which employ representational learning to model\nconsumer behavioral patterns. Current state of the art in Deep Learning based\nrecommender systems uses multiple approaches ranging from already classical\nmethods such as the ones based on learning product representation vector, to\nrecurrent analysis of customer transactional time-series and up to generative\nmodels based on adversarial training. Each of these methods has multiple\nadvantages and inherent weaknesses such as inability of understanding the\nactual user-journey, ability to propose only single product recommendation or\ntop-k product recommendations without prediction of actual next-best-offer. In\nour work we will present a new and innovative architectural approach of\napplying state-of-the-art hierarchical multi-module encoder-decoder\narchitecture in order to solve several of current state-of-the-art recommender\nsystems issues. Our approach will also produce by-products such as product\nneed-based segmentation and customer behavioral segmentation - all in an\nend-to-end trainable approach. Finally, we will present a couple methods that\nsolve known retail & distribution pain-points based on the proposed\narchitecture.\n", "versions": [{"version": "v1", "created": "Thu, 11 Apr 2019 18:15:33 GMT"}, {"version": "v2", "created": "Wed, 15 May 2019 05:22:36 GMT"}, {"version": "v3", "created": "Thu, 16 May 2019 14:20:25 GMT"}, {"version": "v4", "created": "Fri, 21 Jun 2019 17:03:21 GMT"}], "update_date": "2019-06-24", "authors_parsed": [["Damian", "Andrei", ""], ["Piciu", "Laurentiu", ""], ["Turlea", "Sergiu", ""], ["Tapus", "Nicolae", ""]]}, {"id": "1904.07688", "submitter": "Prateek Bansal", "authors": "Prateek Bansal, Rico Krueger, Michel Bierlaire, Ricardo A. Daziano,\n  Taha H. Rashidi", "title": "P\\'olygamma Data Augmentation to address Non-conjugacy in the Bayesian\n  Estimation of Mixed Multinomial Logit Models", "comments": "arXiv admin note: text overlap with arXiv:1904.03647", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG econ.EM stat.AP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The standard Gibbs sampler of Mixed Multinomial Logit (MMNL) models involves\nsampling from conditional densities of utility parameters using\nMetropolis-Hastings (MH) algorithm due to unavailability of conjugate prior for\nlogit kernel. To address this non-conjugacy concern, we propose the application\nof P\\'olygamma data augmentation (PG-DA) technique for the MMNL estimation. The\nposterior estimates of the augmented and the default Gibbs sampler are similar\nfor two-alternative scenario (binary choice), but we encounter empirical\nidentification issues in the case of more alternatives ($J \\geq 3$).\n", "versions": [{"version": "v1", "created": "Sat, 13 Apr 2019 16:38:18 GMT"}], "update_date": "2019-04-17", "authors_parsed": [["Bansal", "Prateek", ""], ["Krueger", "Rico", ""], ["Bierlaire", "Michel", ""], ["Daziano", "Ricardo A.", ""], ["Rashidi", "Taha H.", ""]]}, {"id": "1904.07698", "submitter": "Fahad Sohrab", "authors": "Fahad Sohrab, Jenni Raitoharju, Alexandros Iosifidis, Moncef Gabbouj", "title": "Multimodal Subspace Support Vector Data Description", "comments": "26 pages manuscript (6 tables, 2 figures), 24 pages supplementary\n  material (27 tables, 10 figures). The manuscript and supplementary material\n  are combined as a single .pdf (50 pages) file", "journal-ref": "Pattern Recognition, 2020", "doi": "10.1016/j.patcog.2020.107648", "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we propose a novel method for projecting data from multiple\nmodalities to a new subspace optimized for one-class classification. The\nproposed method iteratively transforms the data from the original feature space\nof each modality to a new common feature space along with finding a joint\ncompact description of data coming from all the modalities. For data in each\nmodality, we define a separate transformation to map the data from the\ncorresponding feature space to the new optimized subspace by exploiting the\navailable information from the class of interest only. We also propose\ndifferent regularization strategies for the proposed method and provide both\nlinear and non-linear formulations. The proposed Multimodal Subspace Support\nVector Data Description outperforms all the competing methods using data from a\nsingle modality or fusing data from all modalities in four out of five\ndatasets.\n", "versions": [{"version": "v1", "created": "Tue, 16 Apr 2019 14:16:09 GMT"}, {"version": "v2", "created": "Mon, 14 Sep 2020 13:31:50 GMT"}], "update_date": "2020-09-15", "authors_parsed": [["Sohrab", "Fahad", ""], ["Raitoharju", "Jenni", ""], ["Iosifidis", "Alexandros", ""], ["Gabbouj", "Moncef", ""]]}, {"id": "1904.07701", "submitter": "Alessandra Cabassi", "authors": "Alessandra Cabassi, Paul D. W. Kirk", "title": "Multiple kernel learning for integrative consensus clustering of 'omic\n  datasets", "comments": "Manuscript: 18 pages, 6 figures. Supplement: 29 pages, 19 figures.\n  This version contains additional simulation studies and comparisons to other\n  methods. For associated R code, see https://CRAN.R-project.org/package=klic\n  and https://github.com/acabassi/klic-pancancer-analysis", "journal-ref": null, "doi": "10.1093/bioinformatics/btaa593", "report-no": null, "categories": "stat.ML cs.LG stat.AP stat.ME", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Diverse applications - particularly in tumour subtyping - have demonstrated\nthe importance of integrative clustering techniques for combining information\nfrom multiple data sources. Cluster-Of-Clusters Analysis (COCA) is one such\napproach that has been widely applied in the context of tumour subtyping.\nHowever, the properties of COCA have never been systematically explored, and\nits robustness to the inclusion of noisy datasets, or datasets that define\nconflicting clustering structures, is unclear. We rigorously benchmark COCA,\nand present Kernel Learning Integrative Clustering (KLIC) as an alternative\nstrategy. KLIC frames the challenge of combining clustering structures as a\nmultiple kernel learning problem, in which different datasets each provide a\nweighted contribution to the final clustering. This allows the contribution of\nnoisy datasets to be down-weighted relative to more informative datasets. We\ncompare the performances of KLIC and COCA in a variety of situations through\nsimulation studies. We also present the output of KLIC and COCA in real data\napplications to cancer subtyping and transcriptional module discovery. R\npackages \"klic\" and \"coca\" are available on the Comprehensive R Archive\nNetwork.\n", "versions": [{"version": "v1", "created": "Mon, 15 Apr 2019 12:33:32 GMT"}, {"version": "v2", "created": "Wed, 26 Feb 2020 16:15:23 GMT"}, {"version": "v3", "created": "Mon, 27 Apr 2020 09:35:40 GMT"}, {"version": "v4", "created": "Mon, 18 May 2020 18:12:07 GMT"}], "update_date": "2020-08-05", "authors_parsed": [["Cabassi", "Alessandra", ""], ["Kirk", "Paul D. W.", ""]]}, {"id": "1904.07704", "submitter": "Tzeviya Sylvia Fuchs", "authors": "Yael Segal, Tzeviya Sylvia Fuchs, Joseph Keshet", "title": "SpeechYOLO: Detection and Localization of Speech Objects", "comments": null, "journal-ref": "Interspeech 2019, pp. 4210-4214", "doi": null, "report-no": null, "categories": "eess.AS cs.LG cs.SD stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we propose to apply object detection methods from the vision\ndomain on the speech recognition domain, by treating audio fragments as\nobjects. More specifically, we present SpeechYOLO, which is inspired by the\nYOLO algorithm for object detection in images. The goal of SpeechYOLO is to\nlocalize boundaries of utterances within the input signal, and to correctly\nclassify them. Our system is composed of a convolutional neural network, with a\nsimple least-mean-squares loss function. We evaluated the system on several\nkeyword spotting tasks, that include corpora of read speech and spontaneous\nspeech. Our system compares favorably with other algorithms trained for both\nlocalization and classification.\n", "versions": [{"version": "v1", "created": "Sun, 14 Apr 2019 15:47:14 GMT"}, {"version": "v2", "created": "Sun, 30 Jun 2019 09:14:46 GMT"}], "update_date": "2019-09-26", "authors_parsed": [["Segal", "Yael", ""], ["Fuchs", "Tzeviya Sylvia", ""], ["Keshet", "Joseph", ""]]}, {"id": "1904.07705", "submitter": "Rafael Vasquez", "authors": "Rafael Vasquez, Bilal Farooq", "title": "Multi-Objective Autonomous Braking System using Naturalistic Dataset", "comments": "Accepted in the proceedings of IEEE ITSC2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A deep reinforcement learning based multi-objective autonomous braking system\nis presented. The design of the system is formulated in a continuous action\nspace and seeks to maximize both pedestrian safety and perception as well as\npassenger comfort. The vehicle agent is trained against a large naturalistic\ndataset containing pedestrian road-crossing trials in which respondents walked\nacross a road under various traffic conditions within an interactive virtual\nreality environment. The policy for brake control is learned through computer\nsimulation using two reinforcement learning methods i.e. Proximal Policy\nOptimization and Deep Deterministic Policy Gradient and the efficiency of each\nare compared. Results show that the system is able to reduce the negative\ninfluence on passenger comfort by half while maintaining safe braking\noperation.\n", "versions": [{"version": "v1", "created": "Mon, 15 Apr 2019 16:07:45 GMT"}, {"version": "v2", "created": "Mon, 1 Jul 2019 15:27:28 GMT"}], "update_date": "2019-07-02", "authors_parsed": [["Vasquez", "Rafael", ""], ["Farooq", "Bilal", ""]]}, {"id": "1904.07734", "submitter": "Gido van de Ven", "authors": "Gido M. van de Ven, Andreas S. Tolias", "title": "Three scenarios for continual learning", "comments": "Extended version of work presented at the NeurIPS Continual Learning\n  workshop (2018); 18 pages, 5 figures, 6 tables. Related to arXiv:1809.10635", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Standard artificial neural networks suffer from the well-known issue of\ncatastrophic forgetting, making continual or lifelong learning difficult for\nmachine learning. In recent years, numerous methods have been proposed for\ncontinual learning, but due to differences in evaluation protocols it is\ndifficult to directly compare their performance. To enable more structured\ncomparisons, we describe three continual learning scenarios based on whether at\ntest time task identity is provided and--in case it is not--whether it must be\ninferred. Any sequence of well-defined tasks can be performed according to each\nscenario. Using the split and permuted MNIST task protocols, for each scenario\nwe carry out an extensive comparison of recently proposed continual learning\nmethods. We demonstrate substantial differences between the three scenarios in\nterms of difficulty and in terms of how efficient different methods are. In\nparticular, when task identity must be inferred (i.e., class incremental\nlearning), we find that regularization-based approaches (e.g., elastic weight\nconsolidation) fail and that replaying representations of previous experiences\nseems required for solving this scenario.\n", "versions": [{"version": "v1", "created": "Mon, 15 Apr 2019 12:22:36 GMT"}], "update_date": "2019-04-18", "authors_parsed": [["van de Ven", "Gido M.", ""], ["Tolias", "Andreas S.", ""]]}, {"id": "1904.07754", "submitter": "Danny Rorabaugh", "authors": "Danny Rorabaugh, Mario Guevara, Ricardo Llamas, Joy Kitson, Rodrigo\n  Vargas, Michela Taufer", "title": "SOMOSPIE: A modular SOil MOisture SPatial Inference Engine based on data\n  driven decisions", "comments": "10 pages, 11 figures, 1 table", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The current availability of soil moisture data over large areas comes from\nsatellite remote sensing technologies (i.e., radar-based systems), but these\ndata have coarse resolution and often exhibit large spatial information gaps.\nWhere data are too coarse or sparse for a given need (e.g., precision\nagriculture), one can leverage machine-learning techniques coupled with other\nsources of environmental information (e.g., topography) to generate gap-free\ninformation and at a finer spatial resolution (i.e., increased granularity). To\nthis end, we develop a spatial inference engine consisting of modular stages\nfor processing spatial environmental data, generating predictions with\nmachine-learning techniques, and analyzing these predictions. We demonstrate\nthe functionality of this approach and the effects of data processing choices\nvia multiple prediction maps over a United States ecological region with a\nhighly diverse soil moisture profile (i.e., the Middle Atlantic Coastal\nPlains). The relevance of our work derives from a pressing need to improve the\nspatial representation of soil moisture for applications in environmental\nsciences (e.g., ecological niche modeling, carbon monitoring systems, and other\nEarth system models) and precision agriculture (e.g., optimizing irrigation\npractices and other land management decisions).\n", "versions": [{"version": "v1", "created": "Tue, 16 Apr 2019 15:14:56 GMT"}, {"version": "v2", "created": "Mon, 20 May 2019 21:35:19 GMT"}], "update_date": "2019-05-22", "authors_parsed": [["Rorabaugh", "Danny", ""], ["Guevara", "Mario", ""], ["Llamas", "Ricardo", ""], ["Kitson", "Joy", ""], ["Vargas", "Rodrigo", ""], ["Taufer", "Michela", ""]]}, {"id": "1904.07773", "submitter": "Junhao Wen", "authors": "Junhao Wen, Elina Thibeau-Sutre, Mauricio Diaz-Melo, Jorge\n  Samper-Gonzalez, Alexandre Routier, Simona Bottani, Didier Dormont, Stanley\n  Durrleman, Ninon Burgos and Olivier Colliot", "title": "Convolutional Neural Networks for Classification of Alzheimer's Disease:\n  Overview and Reproducible Evaluation", "comments": null, "journal-ref": "Medical Image Analysis, p.101694. 2020", "doi": "10.1016/j.media.2020.101694", "report-no": null, "categories": "cs.LG eess.IV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Over 30 papers have proposed to use convolutional neural network (CNN) for AD\nclassification from anatomical MRI. However, the classification performance is\ndifficult to compare across studies due to variations in components such as\nparticipant selection, image preprocessing or validation procedure. Moreover,\nthese studies are hardly reproducible because their frameworks are not publicly\naccessible and because implementation details are lacking. Lastly, some of\nthese papers may report a biased performance due to inadequate or unclear\nvalidation or model selection procedures. In the present work, we aim to\naddress these limitations through three main contributions. First, we performed\na systematic literature review and found that more than half of the surveyed\npapers may have suffered from data leakage. Our second contribution is the\nextension of our open-source framework for classification of AD using CNN and\nT1-weighted MRI. Finally, we used this framework to rigorously compare\ndifferent CNN architectures. The data was split into training/validation/test\nsets at the very beginning and only the training/validation sets were used for\nmodel selection. To avoid any overfitting, the test sets were left untouched\nuntil the end of the peer-review process. Overall, the different 3D approaches\n(3D-subject, 3D-ROI, 3D-patch) achieved similar performances while that of the\n2D slice approach was lower. Of note, the different CNN approaches did not\nperform better than a SVM with voxel-based features. The different approaches\ngeneralized well to similar populations but not to datasets with different\ninclusion criteria or demographical characteristics.\n", "versions": [{"version": "v1", "created": "Tue, 16 Apr 2019 15:46:06 GMT"}, {"version": "v2", "created": "Wed, 16 Oct 2019 15:25:01 GMT"}, {"version": "v3", "created": "Thu, 17 Oct 2019 00:35:50 GMT"}, {"version": "v4", "created": "Mon, 23 Mar 2020 17:52:55 GMT"}, {"version": "v5", "created": "Mon, 4 May 2020 15:16:23 GMT"}, {"version": "v6", "created": "Mon, 1 Jun 2020 01:39:56 GMT"}], "update_date": "2020-06-02", "authors_parsed": [["Wen", "Junhao", ""], ["Thibeau-Sutre", "Elina", ""], ["Diaz-Melo", "Mauricio", ""], ["Samper-Gonzalez", "Jorge", ""], ["Routier", "Alexandre", ""], ["Bottani", "Simona", ""], ["Dormont", "Didier", ""], ["Durrleman", "Stanley", ""], ["Burgos", "Ninon", ""], ["Colliot", "Olivier", ""]]}, {"id": "1904.07774", "submitter": "Basura Fernando", "authors": "Basura Fernando and Cheston Tan Yin Chet and Hakan Bilen", "title": "Weakly Supervised Gaussian Networks for Action Detection", "comments": "Accepted in WACV 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Detecting temporal extents of human actions in videos is a challenging\ncomputer vision problem that requires detailed manual supervision including\nframe-level labels. This expensive annotation process limits deploying action\ndetectors to a limited number of categories. We propose a novel method, called\nWSGN, that learns to detect actions from \\emph{weak supervision}, using only\nvideo-level labels. WSGN learns to exploit both video-specific and dataset-wide\nstatistics to predict relevance of each frame to an action category. This\nstrategy leads to significant gains in action detection for two standard\nbenchmarks THUMOS14 and Charades. Our method obtains excellent results compared\nto state-of-the-art methods that uses similar features and loss functions on\nTHUMOS14 dataset. Similarly, our weakly supervised method is only 0.3% mAP\nbehind a state-of-the-art supervised method on challenging Charades dataset for\naction localization.\n", "versions": [{"version": "v1", "created": "Tue, 16 Apr 2019 15:48:36 GMT"}, {"version": "v2", "created": "Tue, 6 Aug 2019 03:09:52 GMT"}, {"version": "v3", "created": "Thu, 2 Jan 2020 03:59:18 GMT"}, {"version": "v4", "created": "Mon, 6 Jan 2020 02:46:05 GMT"}], "update_date": "2020-01-07", "authors_parsed": [["Fernando", "Basura", ""], ["Chet", "Cheston Tan Yin", ""], ["Bilen", "Hakan", ""]]}, {"id": "1904.07785", "submitter": "Bingbing Xu", "authors": "Bingbing Xu, Huawei Shen, Qi Cao, Yunqi Qiu, Xueqi Cheng", "title": "Graph Wavelet Neural Network", "comments": null, "journal-ref": "ICLR(2019)", "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present graph wavelet neural network (GWNN), a novel graph convolutional\nneural network (CNN), leveraging graph wavelet transform to address the\nshortcomings of previous spectral graph CNN methods that depend on graph\nFourier transform. Different from graph Fourier transform, graph wavelet\ntransform can be obtained via a fast algorithm without requiring matrix\neigendecomposition with high computational cost. Moreover, graph wavelets are\nsparse and localized in vertex domain, offering high efficiency and good\ninterpretability for graph convolution. The proposed GWNN significantly\noutperforms previous spectral graph CNNs in the task of graph-based\nsemi-supervised classification on three benchmark datasets: Cora, Citeseer and\nPubmed.\n", "versions": [{"version": "v1", "created": "Fri, 12 Apr 2019 08:20:08 GMT"}], "update_date": "2019-04-17", "authors_parsed": [["Xu", "Bingbing", ""], ["Shen", "Huawei", ""], ["Cao", "Qi", ""], ["Qiu", "Yunqi", ""], ["Cheng", "Xueqi", ""]]}, {"id": "1904.07787", "submitter": "Yoram Louzoun", "authors": "Idan Benami, Keren Cohen, Oved Nagar, Yoram Louzoun", "title": "Topological based classification of paper domains using graph\n  convolutional networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SI cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The main approaches for node classification in graphs are information\npropagation and the association of the class of the node with external\ninformation. State of the art methods merge these approaches through Graph\nConvolutional Networks. We here use the association of topological features of\nthe nodes with their class to predict this class. Moreover, combining\ntopological information with information propagation improves classification\naccuracy on the standard CiteSeer and Cora paper classification task.\nTopological features and information propagation produce results almost as good\nas text-based classification, without no textual or content information. We\npropose to represent the topology and information propagation through a GCN\nwith the neighboring training node classification as an input and the current\nnode classification as output. Such a formalism outperforms state of the art\nmethods.\n", "versions": [{"version": "v1", "created": "Wed, 10 Apr 2019 14:04:11 GMT"}], "update_date": "2019-04-17", "authors_parsed": [["Benami", "Idan", ""], ["Cohen", "Keren", ""], ["Nagar", "Oved", ""], ["Louzoun", "Yoram", ""]]}, {"id": "1904.07793", "submitter": "Xiaosen Wang", "authors": "Xiaosen Wang, Kun He, Chuanbiao Song, Liwei Wang, John E. Hopcroft", "title": "AT-GAN: An Adversarial Generator Model for Non-constrained Adversarial\n  Examples", "comments": "15 pages, 6 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.CR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Despite the rapid development of adversarial machine learning, most\nadversarial attack and defense researches mainly focus on the\nperturbation-based adversarial examples, which is constrained by the input\nimages. In comparison with existing works, we propose non-constrained\nadversarial examples, which are generated entirely from scratch without any\nconstraint on the input. Unlike perturbation-based attacks, or the so-called\nunrestricted adversarial attack which is still constrained by the input noise,\nwe aim to learn the distribution of adversarial examples to generate\nnon-constrained but semantically meaningful adversarial examples. Following\nthis spirit, we propose a novel attack framework called AT-GAN (Adversarial\nTransfer on Generative Adversarial Net). Specifically, we first develop a\nnormal GAN model to learn the distribution of benign data, and then transfer\nthe pre-trained GAN model to estimate the distribution of adversarial examples\nfor the target model. In this way, AT-GAN can learn the distribution of\nadversarial examples that is very close to the distribution of real data. To\nour knowledge, this is the first work of building an adversarial generator\nmodel that could produce adversarial examples directly from any input noise.\nExtensive experiments and visualizations show that the proposed AT-GAN can very\nefficiently generate diverse adversarial examples that are more realistic to\nhuman perception. In addition, AT-GAN yields higher attack success rates\nagainst adversarially trained models under white-box attack setting and\nexhibits moderate transferability against black-box models.\n", "versions": [{"version": "v1", "created": "Tue, 16 Apr 2019 16:26:19 GMT"}, {"version": "v2", "created": "Wed, 17 Apr 2019 02:19:07 GMT"}, {"version": "v3", "created": "Tue, 21 May 2019 15:26:32 GMT"}, {"version": "v4", "created": "Fri, 7 Feb 2020 18:11:58 GMT"}], "update_date": "2020-02-10", "authors_parsed": [["Wang", "Xiaosen", ""], ["He", "Kun", ""], ["Song", "Chuanbiao", ""], ["Wang", "Liwei", ""], ["Hopcroft", "John E.", ""]]}, {"id": "1904.07802", "submitter": "Quentin Debard", "authors": "Quentin Debard, Jilles Steeve Dibangoye, St\\'ephane Canu, Christian\n  Wolf", "title": "Learning 3D Navigation Protocols on Touch Interfaces with Cooperative\n  Multi-Agent Reinforcement Learning", "comments": "17 pages, 8 figures. Accepted at The European Conference on Machine\n  Learning and Principles and Practice of Knowledge Discovery in Databases 2019\n  (ECMLPKDD 2019)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.HC", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Using touch devices to navigate in virtual 3D environments such as computer\nassisted design (CAD) models or geographical information systems (GIS) is\ninherently difficult for humans, as the 3D operations have to be performed by\nthe user on a 2D touch surface. This ill-posed problem is classically solved\nwith a fixed and handcrafted interaction protocol, which must be learned by the\nuser. We propose to automatically learn a new interaction protocol allowing to\nmap a 2D user input to 3D actions in virtual environments using reinforcement\nlearning (RL). A fundamental problem of RL methods is the vast amount of\ninteractions often required, which are difficult to come by when humans are\ninvolved. To overcome this limitation, we make use of two collaborative agents.\nThe first agent models the human by learning to perform the 2D finger\ntrajectories. The second agent acts as the interaction protocol, interpreting\nand translating to 3D operations the 2D finger trajectories from the first\nagent. We restrict the learned 2D trajectories to be similar to a training set\nof collected human gestures by first performing state representation learning,\nprior to reinforcement learning. This state representation learning is\naddressed by projecting the gestures into a latent space learned by a\nvariational auto encoder (VAE).\n", "versions": [{"version": "v1", "created": "Tue, 16 Apr 2019 16:33:04 GMT"}, {"version": "v2", "created": "Tue, 27 Aug 2019 20:44:46 GMT"}], "update_date": "2019-08-29", "authors_parsed": [["Debard", "Quentin", ""], ["Dibangoye", "Jilles Steeve", ""], ["Canu", "St\u00e9phane", ""], ["Wolf", "Christian", ""]]}, {"id": "1904.07817", "submitter": "Manuel Gra\\~na", "authors": "Borja Fernandez-Gauna, Manuel Gra\\~na and Roland S. Zimmermann", "title": "Simion Zoo: A Workbench for Distributed Experimentation with\n  Reinforcement Learning for Continuous Control Tasks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present Simion Zoo, a Reinforcement Learning (RL) workbench that provides\na complete set of tools to design, run, and analyze the results,both\nstatistically and visually, of RL control applications. The main features that\nset apart Simion Zoo from similar software packages are its easy-to-use GUI,\nits support for distributed execution including deployment over graphics\nprocessing units (GPUs) , and the possibility to explore concurrently the RL\nmetaparameter space, which is key to successful RL experimentation.\n", "versions": [{"version": "v1", "created": "Tue, 16 Apr 2019 16:48:23 GMT"}], "update_date": "2019-04-17", "authors_parsed": [["Fernandez-Gauna", "Borja", ""], ["Gra\u00f1a", "Manuel", ""], ["Zimmermann", "Roland S.", ""]]}, {"id": "1904.07834", "submitter": "Jonathan De Matos", "authors": "Jonathan de Matos, Alceu de S. Britto Jr., Luiz E. S. Oliveira,\n  Alessandro L. Koerich", "title": "Double Transfer Learning for Breast Cancer Histopathologic Image\n  Classification", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This work proposes a classification approach for breast cancer\nhistopathologic images (HI) that uses transfer learning to extract features\nfrom HI using an Inception-v3 CNN pre-trained with ImageNet dataset. We also\nuse transfer learning on training a support vector machine (SVM) classifier on\na tissue labeled colorectal cancer dataset aiming to filter the patches from a\nbreast cancer HI and remove the irrelevant ones. We show that removing\nirrelevant patches before training a second SVM classifier, improves the\naccuracy for classifying malign and benign tumors on breast cancer images. We\nare able to improve the classification accuracy in 3.7% using the feature\nextraction transfer learning and an additional 0.7% using the irrelevant patch\nelimination. The proposed approach outperforms the state-of-the-art in three\nout of the four magnification factors of the breast cancer dataset.\n", "versions": [{"version": "v1", "created": "Tue, 16 Apr 2019 17:26:34 GMT"}], "update_date": "2019-04-17", "authors_parsed": [["de Matos", "Jonathan", ""], ["Britto", "Alceu de S.", "Jr."], ["Oliveira", "Luiz E. S.", ""], ["Koerich", "Alessandro L.", ""]]}, {"id": "1904.07845", "submitter": "Gene-Ping Yang", "authors": "Gene-Ping Yang, Chao-I Tuan, Hung-Yi Lee, Lin-shan Lee", "title": "Improved Speech Separation with Time-and-Frequency Cross-domain Joint\n  Embedding and Clustering", "comments": "Submitted to Interspeech 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SD cs.LG eess.AS stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Speech separation has been very successful with deep learning techniques.\nSubstantial effort has been reported based on approaches over spectrogram,\nwhich is well known as the standard time-and-frequency cross-domain\nrepresentation for speech signals. It is highly correlated to the phonetic\nstructure of speech, or \"how the speech sounds\" when perceived by human, but\nprimarily frequency domain features carrying temporal behaviour. Very\nimpressive work achieving speech separation over time domain was reported\nrecently, probably because waveforms in time domain may describe the different\nrealizations of speech in a more precise way than spectrogram. In this paper,\nwe propose a framework properly integrating the above two directions, hoping to\nachieve both purposes. We construct a time-and-frequency feature map by\nconcatenating the 1-dim convolution encoded feature map (for time domain) and\nthe spectrogram (for frequency domain), which was then processed by an\nembedding network and clustering approaches very similar to those used in time\nand frequency domain prior works. In this way, the information in the time and\nfrequency domains, as well as the interactions between them, can be jointly\nconsidered during embedding and clustering. Very encouraging results\n(state-of-the-art to our knowledge) were obtained with WSJ0-2mix dataset in\npreliminary experiments.\n", "versions": [{"version": "v1", "created": "Tue, 16 Apr 2019 17:48:59 GMT"}], "update_date": "2019-04-17", "authors_parsed": [["Yang", "Gene-Ping", ""], ["Tuan", "Chao-I", ""], ["Lee", "Hung-Yi", ""], ["Lee", "Lin-shan", ""]]}, {"id": "1904.07846", "submitter": "Debidatta Dwibedi", "authors": "Debidatta Dwibedi, Yusuf Aytar, Jonathan Tompson, Pierre Sermanet,\n  Andrew Zisserman", "title": "Temporal Cycle-Consistency Learning", "comments": "Accepted at CVPR 2019. Project webpage:\n  https://sites.google.com/view/temporal-cycle-consistency", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce a self-supervised representation learning method based on the\ntask of temporal alignment between videos. The method trains a network using\ntemporal cycle consistency (TCC), a differentiable cycle-consistency loss that\ncan be used to find correspondences across time in multiple videos. The\nresulting per-frame embeddings can be used to align videos by simply matching\nframes using the nearest-neighbors in the learned embedding space.\n  To evaluate the power of the embeddings, we densely label the Pouring and\nPenn Action video datasets for action phases. We show that (i) the learned\nembeddings enable few-shot classification of these action phases, significantly\nreducing the supervised training requirements; and (ii) TCC is complementary to\nother methods of self-supervised learning in videos, such as Shuffle and Learn\nand Time-Contrastive Networks. The embeddings are also used for a number of\napplications based on alignment (dense temporal correspondence) between video\npairs, including transfer of metadata of synchronized modalities between videos\n(sounds, temporal semantic labels), synchronized playback of multiple videos,\nand anomaly detection. Project webpage:\nhttps://sites.google.com/view/temporal-cycle-consistency .\n", "versions": [{"version": "v1", "created": "Tue, 16 Apr 2019 17:49:50 GMT"}], "update_date": "2019-04-17", "authors_parsed": [["Dwibedi", "Debidatta", ""], ["Aytar", "Yusuf", ""], ["Tompson", "Jonathan", ""], ["Sermanet", "Pierre", ""], ["Zisserman", "Andrew", ""]]}, {"id": "1904.07848", "submitter": "Jong-Chyi Su", "authors": "Jong-Chyi Su, Yi-Hsuan Tsai, Kihyuk Sohn, Buyu Liu, Subhransu Maji,\n  Manmohan Chandraker", "title": "Active Adversarial Domain Adaptation", "comments": "WACV 2020 Camera Ready Version", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose an active learning approach for transferring representations\nacross domains. Our approach, active adversarial domain adaptation (AADA),\nexplores a duality between two related problems: adversarial domain alignment\nand importance sampling for adapting models across domains. The former uses a\ndomain discriminative model to align domains, while the latter utilizes it to\nweigh samples to account for distribution shifts. Specifically, our importance\nweight promotes samples with large uncertainty in classification and diversity\nfrom labeled examples, thus serves as a sample selection scheme for active\nlearning. We show that these two views can be unified in one framework for\ndomain adaptation and transfer learning when the source domain has many labeled\nexamples while the target domain does not. AADA provides significant\nimprovements over fine-tuning based approaches and other sampling methods when\nthe two domains are closely related. Results on challenging domain adaptation\ntasks, e.g., object detection, demonstrate that the advantage over baseline\napproaches is retained even after hundreds of examples being actively\nannotated.\n", "versions": [{"version": "v1", "created": "Tue, 16 Apr 2019 17:52:54 GMT"}, {"version": "v2", "created": "Mon, 9 Mar 2020 19:19:09 GMT"}], "update_date": "2020-03-11", "authors_parsed": [["Su", "Jong-Chyi", ""], ["Tsai", "Yi-Hsuan", ""], ["Sohn", "Kihyuk", ""], ["Liu", "Buyu", ""], ["Maji", "Subhransu", ""], ["Chandraker", "Manmohan", ""]]}, {"id": "1904.07852", "submitter": "Adrian Bulat", "authors": "Adrian Bulat and Jean Kossaifi and Georgios Tzimiropoulos and Maja\n  Pantic", "title": "Matrix and tensor decompositions for training binary neural networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper is on improving the training of binary neural networks in which\nboth activations and weights are binary. While prior methods for neural network\nbinarization binarize each filter independently, we propose to instead\nparametrize the weight tensor of each layer using matrix or tensor\ndecomposition. The binarization process is then performed using this latent\nparametrization, via a quantization function (e.g. sign function) applied to\nthe reconstructed weights. A key feature of our method is that while the\nreconstruction is binarized, the computation in the latent factorized space is\ndone in the real domain. This has several advantages: (i) the latent\nfactorization enforces a coupling of the filters before binarization, which\nsignificantly improves the accuracy of the trained models. (ii) while at\ntraining time, the binary weights of each convolutional layer are parametrized\nusing real-valued matrix or tensor decomposition, during inference we simply\nuse the reconstructed (binary) weights. As a result, our method does not\nsacrifice any advantage of binary networks in terms of model compression and\nspeeding-up inference. As a further contribution, instead of computing the\nbinary weight scaling factors analytically, as in prior work, we propose to\nlearn them discriminatively via back-propagation. Finally, we show that our\napproach significantly outperforms existing methods when tested on the\nchallenging tasks of (a) human pose estimation (more than 4% improvements) and\n(b) ImageNet classification (up to 5% performance gains).\n", "versions": [{"version": "v1", "created": "Tue, 16 Apr 2019 17:57:27 GMT"}], "update_date": "2019-04-17", "authors_parsed": [["Bulat", "Adrian", ""], ["Kossaifi", "Jean", ""], ["Tzimiropoulos", "Georgios", ""], ["Pantic", "Maja", ""]]}, {"id": "1904.07854", "submitter": "Avi Singh", "authors": "Avi Singh, Larry Yang, Kristian Hartikainen, Chelsea Finn, Sergey\n  Levine", "title": "End-to-End Robotic Reinforcement Learning without Reward Engineering", "comments": "Accepted to RSS 2019. 14 pages and 13 figures including references\n  and appendix. Website: https://sites.google.com/view/reward-learning-rl/home", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV cs.RO stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The combination of deep neural network models and reinforcement learning\nalgorithms can make it possible to learn policies for robotic behaviors that\ndirectly read in raw sensory inputs, such as camera images, effectively\nsubsuming both estimation and control into one model. However, real-world\napplications of reinforcement learning must specify the goal of the task by\nmeans of a manually programmed reward function, which in practice requires\neither designing the very same perception pipeline that end-to-end\nreinforcement learning promises to avoid, or else instrumenting the environment\nwith additional sensors to determine if the task has been performed\nsuccessfully. In this paper, we propose an approach for removing the need for\nmanual engineering of reward specifications by enabling a robot to learn from a\nmodest number of examples of successful outcomes, followed by actively\nsolicited queries, where the robot shows the user a state and asks for a label\nto determine whether that state represents successful completion of the task.\nWhile requesting labels for every single state would amount to asking the user\nto manually provide the reward signal, our method requires labels for only a\ntiny fraction of the states seen during training, making it an efficient and\npractical approach for learning skills without manually engineered rewards. We\nevaluate our method on real-world robotic manipulation tasks where the\nobservations consist of images viewed by the robot's camera. In our\nexperiments, our method effectively learns to arrange objects, place books, and\ndrape cloth, directly from images and without any manually specified reward\nfunctions, and with only 1-4 hours of interaction with the real world.\n", "versions": [{"version": "v1", "created": "Tue, 16 Apr 2019 17:59:23 GMT"}, {"version": "v2", "created": "Thu, 16 May 2019 00:00:22 GMT"}], "update_date": "2019-05-17", "authors_parsed": [["Singh", "Avi", ""], ["Yang", "Larry", ""], ["Hartikainen", "Kristian", ""], ["Finn", "Chelsea", ""], ["Levine", "Sergey", ""]]}, {"id": "1904.07864", "submitter": "Arman Roohi", "authors": "Arman Roohi, Shaahin Angizi, Deliang Fan, and Ronald F DeMara", "title": "Processing-In-Memory Acceleration of Convolutional Neural Networks for\n  Energy-Efficiency, and Power-Intermittency Resilience", "comments": "6 pages, 10 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AR cs.ET", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Herein, a bit-wise Convolutional Neural Network (CNN) in-memory accelerator\nis implemented using Spin-Orbit Torque Magnetic Random Access Memory (SOT-MRAM)\ncomputational sub-arrays. It utilizes a novel AND-Accumulation method capable\nof significantly-reduced energy consumption within convolutional layers and\nperforms various low bit-width CNN inference operations entirely within MRAM.\nPower-intermittence resiliency is also enhanced by retaining the partial state\ninformation needed to maintain computational forward-progress, which is\nadvantageous for battery-less IoT nodes. Simulation results indicate\n$\\sim$5.4$\\times$ higher energy-efficiency and 9$\\times$ speedup over\nReRAM-based acceleration, or roughly $\\sim$9.7$\\times$ higher energy-efficiency\nand 13.5$\\times$ speedup over recent CMOS-only approaches, while maintaining\ninference accuracy comparable to baseline designs.\n", "versions": [{"version": "v1", "created": "Tue, 16 Apr 2019 16:22:16 GMT"}], "update_date": "2019-04-18", "authors_parsed": [["Roohi", "Arman", ""], ["Angizi", "Shaahin", ""], ["Fan", "Deliang", ""], ["DeMara", "Ronald F", ""]]}, {"id": "1904.07900", "submitter": "Jonathan De Matos", "authors": "Jonathan de Matos, Alceu de Souza Britto Jr., Luiz E. S. Oliveira,\n  Alessandro L. Koerich", "title": "Histopathologic Image Processing: A Review", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Histopathologic Images (HI) are the gold standard for evaluation of some\ntumors. However, the analysis of such images is challenging even for\nexperienced pathologists, resulting in problems of inter and intra observer.\nBesides that, the analysis is time and resource consuming. One of the ways to\naccelerate such an analysis is by using Computer Aided Diagnosis systems. In\nthis work we present a literature review about the computing techniques to\nprocess HI, including shallow and deep methods. We cover the most common tasks\nfor processing HI such as segmentation, feature extraction, unsupervised\nlearning and supervised learning. A dataset section show some datasets found\nduring the literature review. We also bring a study case of breast cancer\nclassification using a mix of deep and shallow machine learning methods. The\nproposed method obtained an accuracy of 91% in the best case, outperforming the\ncompared baseline of the dataset.\n", "versions": [{"version": "v1", "created": "Tue, 16 Apr 2019 18:04:24 GMT"}], "update_date": "2019-04-18", "authors_parsed": [["de Matos", "Jonathan", ""], ["Britto", "Alceu de Souza", "Jr."], ["Oliveira", "Luiz E. S.", ""], ["Koerich", "Alessandro L.", ""]]}, {"id": "1904.07916", "submitter": "Abdullah Hamdi", "authors": "Abdullah Hamdi, Bernard Ghanem", "title": "IAN: Combining Generative Adversarial Networks for Imaginative Face\n  Generation", "comments": "preprint", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Generative Adversarial Networks (GANs) have gained momentum for their ability\nto model image distributions. They learn to emulate the training set and that\nenables sampling from that domain and using the knowledge learned for useful\napplications. Several methods proposed enhancing GANs, including regularizing\nthe loss with some feature matching. We seek to push GANs beyond the data in\nthe training and try to explore unseen territory in the image manifold. We\nfirst propose a new regularizer for GAN based on K-nearest neighbor (K-NN)\nselective feature matching to a target set Y in high-level feature space,\nduring the adversarial training of GAN on the base set X, and we call this\nnovel model K-GAN. We show that minimizing the added term follows from\ncross-entropy minimization between the distributions of GAN and the set Y.\nThen, We introduce a cascaded framework for GANs that try to address the task\nof imagining a new distribution that combines the base set X and target set Y\nby cascading sampling GANs with translation GANs, and we dub the cascade of\nsuch GANs as the Imaginative Adversarial Network (IAN). We conduct an objective\nand subjective evaluation for different IAN setups in the addressed task and\nshow some useful applications for these IANs, like manifold traversing and\ncreative face generation for characters' design in movies or video games.\n", "versions": [{"version": "v1", "created": "Tue, 16 Apr 2019 18:45:33 GMT"}], "update_date": "2019-04-18", "authors_parsed": [["Hamdi", "Abdullah", ""], ["Ghanem", "Bernard", ""]]}, {"id": "1904.07935", "submitter": "Gordon Moon", "authors": "Gordon E. Moon, Aravind Sukumaran-Rajam, Srinivasan Parthasarathy and\n  P. Sadayappan", "title": "PL-NMF: Parallel Locality-Optimized Non-negative Matrix Factorization", "comments": "11 pages, 5 tables, 9 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.DC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Non-negative Matrix Factorization (NMF) is a key kernel for unsupervised\ndimension reduction used in a wide range of applications, including topic\nmodeling, recommender systems and bioinformatics. Due to the compute-intensive\nnature of applications that must perform repeated NMF, several parallel\nimplementations have been developed in the past. However, existing parallel NMF\nalgorithms have not addressed data locality optimizations, which are critical\nfor high performance since data movement costs greatly exceed the cost of\narithmetic/logic operations on current computer systems. In this paper, we\ndevise a parallel NMF algorithm based on the HALS (Hierarchical Alternating\nLeast Squares) scheme that incorporates algorithmic transformations to enhance\ndata locality. Efficient realizations of the algorithm on multi-core CPUs and\nGPUs are developed, demonstrating significant performance improvement over\nexisting state-of-the-art parallel NMF algorithms.\n", "versions": [{"version": "v1", "created": "Tue, 16 Apr 2019 19:18:37 GMT"}], "update_date": "2019-04-18", "authors_parsed": [["Moon", "Gordon E.", ""], ["Sukumaran-Rajam", "Aravind", ""], ["Parthasarathy", "Srinivasan", ""], ["Sadayappan", "P.", ""]]}, {"id": "1904.07944", "submitter": "Chris Donahue", "authors": "Paarth Neekhara, Chris Donahue, Miller Puckette, Shlomo Dubnov, Julian\n  McAuley", "title": "Expediting TTS Synthesis with Adversarial Vocoding", "comments": "Published as a conference paper at INTERSPEECH 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SD cs.LG eess.AS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent approaches in text-to-speech (TTS) synthesis employ neural network\nstrategies to vocode perceptually-informed spectrogram representations directly\ninto listenable waveforms. Such vocoding procedures create a computational\nbottleneck in modern TTS pipelines. We propose an alternative approach which\nutilizes generative adversarial networks (GANs) to learn mappings from\nperceptually-informed spectrograms to simple magnitude spectrograms which can\nbe heuristically vocoded. Through a user study, we show that our approach\nsignificantly outperforms na\\\"ive vocoding strategies while being hundreds of\ntimes faster than neural network vocoders used in state-of-the-art TTS systems.\nWe also show that our method can be used to achieve state-of-the-art results in\nunsupervised synthesis of individual words of speech.\n", "versions": [{"version": "v1", "created": "Tue, 16 Apr 2019 19:42:43 GMT"}, {"version": "v2", "created": "Fri, 26 Jul 2019 03:36:52 GMT"}], "update_date": "2019-07-29", "authors_parsed": [["Neekhara", "Paarth", ""], ["Donahue", "Chris", ""], ["Puckette", "Miller", ""], ["Dubnov", "Shlomo", ""], ["McAuley", "Julian", ""]]}, {"id": "1904.07961", "submitter": "Liang Wang", "authors": "Liang Wang, Peiqiu Huang, Kezhi Wang, Guopeng Zhang, Lei Zhang, Nauman\n  Aslam, and Kun Yang", "title": "RL-Based User Association and Resource Allocation for Multi-UAV enabled\n  MEC", "comments": "This paper was accepted by IWCMC 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, multi-unmanned aerial vehicle (UAV) enabled mobile edge\ncomputing (MEC), i.e., UAVE is studied, where several UAVs are deployed as\nflying MEC platform to provide computing resource to ground user equipments\n(UEs). Compared to the traditional fixed location MEC, UAV enabled MEC (i.e.,\nUAVE) is particular useful in case of temporary events, emergency situations\nand on-demand services, due to its high flexibility, low cost and easy\ndeployment features. However, operation of UAVE faces several challenges, two\nof which are how to achieve both 1) the association between multiple UEs and\nUAVs and 2) the resource allocation from UAVs to UEs, while minimizing the\nenergy consumption for all the UEs. To address this, we formulate the above\nproblem into a mixed integer nonlinear programming (MINLP), which is difficult\nto be solved in general, especially in the large-scale scenario. We then\npropose a Reinforcement Learning (RL)-based user Association and resource\nAllocation (RLAA) algorithm to tackle this problem efficiently and effectively.\nNumerical results show that the proposed RLAA can achieve the optimal\nperformance with comparison to the exhaustive search in small scale, and have\nconsiderable performance gain over other typical algorithms in large-scale\ncases.\n", "versions": [{"version": "v1", "created": "Mon, 8 Apr 2019 20:15:39 GMT"}], "update_date": "2019-04-18", "authors_parsed": [["Wang", "Liang", ""], ["Huang", "Peiqiu", ""], ["Wang", "Kezhi", ""], ["Zhang", "Guopeng", ""], ["Zhang", "Lei", ""], ["Aslam", "Nauman", ""], ["Yang", "Kun", ""]]}, {"id": "1904.07964", "submitter": "Wentai Zhang", "authors": "Wentai Zhang, Zhangsihao Yang, Haoliang Jiang, Suyash Nigam, Soji\n  Yamakawa, Tomotake Furuhata, Kenji Shimada, Levent Burak Kara", "title": "3D Shape Synthesis for Conceptual Design and Optimization Using\n  Variational Autoencoders", "comments": "Preprint accepted by ASME IDETC/CIE 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CG cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a data-driven 3D shape design method that can learn a generative\nmodel from a corpus of existing designs, and use this model to produce a wide\nrange of new designs. The approach learns an encoding of the samples in the\ntraining corpus using an unsupervised variational autoencoder-decoder\narchitecture, without the need for an explicit parametric representation of the\noriginal designs. To facilitate the generation of smooth final surfaces, we\ndevelop a 3D shape representation based on a distance transformation of the\noriginal 3D data, rather than using the commonly utilized binary voxel\nrepresentation. Once established, the generator maps the latent space\nrepresentations to the high-dimensional distance transformation fields, which\nare then automatically surfaced to produce 3D representations amenable to\nphysics simulations or other objective function evaluation modules. We\ndemonstrate our approach for the computational design of gliders that are\noptimized to attain prescribed performance scores. Our results show that when\ncombined with genetic optimization, the proposed approach can generate a rich\nset of candidate concept designs that achieve prescribed functional goals, even\nwhen the original dataset has only a few or no solutions that achieve these\ngoals.\n", "versions": [{"version": "v1", "created": "Tue, 16 Apr 2019 20:26:53 GMT"}], "update_date": "2019-04-18", "authors_parsed": [["Zhang", "Wentai", ""], ["Yang", "Zhangsihao", ""], ["Jiang", "Haoliang", ""], ["Nigam", "Suyash", ""], ["Yamakawa", "Soji", ""], ["Furuhata", "Tomotake", ""], ["Shimada", "Kenji", ""], ["Kara", "Levent Burak", ""]]}, {"id": "1904.07965", "submitter": "Fabrizio Sebastiani", "authors": "Andrea Esuli, Alejandro Moreo, Fabrizio Sebastiani", "title": "Cross-Lingual Sentiment Quantification", "comments": "Identical to previous version, but for the abstract, which is now\n  identical to the one in the published version", "journal-ref": "Published in IEEE Intelligent Systems 35(3):106-114, 2020. The\n  present version is identical to the published one but for formatting", "doi": "10.1109/MIS.2020.2979203", "report-no": null, "categories": "cs.LG cs.IR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  \\emph{Sentiment Quantification} (i.e., the task of estimating the relative\nfrequency of sentiment-related classes -- such as \\textsf{Positive} and\n\\textsf{Negative} -- in a set of unlabelled documents) is an important topic in\nsentiment analysis, as the study of sentiment-related quantities and trends\nacross a population is often of higher interest than the analysis of individual\ninstances. In this work we propose a method for \\emph{Cross-Lingual Sentiment\nQuantification}, the task of performing sentiment quantification when training\ndocuments are available for a source language $\\mathcal{S}$ but not for the\ntarget language $\\mathcal{T}$ for which sentiment quantification needs to be\nperformed. Cross-lingual sentiment quantification (and cross-lingual\n\\emph{text} quantification in general) has never been discussed before in the\nliterature; we establish baseline results for the binary case by combining\nstate-of-the-art quantification methods with methods capable of generating\ncross-lingual vectorial representations of the source and target documents\ninvolved. We present experimental results obtained on publicly available\ndatasets for cross-lingual sentiment classification; the results show that the\npresented methods can perform cross-lingual sentiment quantification with a\nsurprising level of accuracy.\n", "versions": [{"version": "v1", "created": "Tue, 16 Apr 2019 20:32:02 GMT"}, {"version": "v2", "created": "Tue, 7 Jul 2020 13:50:58 GMT"}], "update_date": "2020-07-08", "authors_parsed": [["Esuli", "Andrea", ""], ["Moreo", "Alejandro", ""], ["Sebastiani", "Fabrizio", ""]]}, {"id": "1904.07969", "submitter": "Lana Sinapayen", "authors": "Lana Sinapayen, Atsushi Noda", "title": "DNN Architecture for High Performance Prediction on Natural Videos Loses\n  Submodule's Ability to Learn Discrete-World Dataset", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Is cognition a collection of loosely connected functions tuned to different\ntasks, or can there be a general learning algorithm? If such an hypothetical\ngeneral algorithm did exist, tuned to our world, could it adapt seamlessly to a\nworld with different laws of nature? We consider the theory that predictive\ncoding is such a general rule, and falsify it for one specific neural\narchitecture known for high-performance predictions on natural videos and\nreplication of human visual illusions: PredNet. Our results show that PredNet's\nhigh performance generalizes without retraining on a completely different\nnatural video dataset. Yet PredNet cannot be trained to reach even mediocre\naccuracy on an artificial video dataset created with the rules of the Game of\nLife (GoL). We also find that a submodule of PredNet, a Convolutional Neural\nNetwork trained alone, reaches perfect accuracy on the GoL while being mediocre\nfor natural videos, showing that PredNet's architecture itself is responsible\nfor both the high performance on natural videos and the loss of performance on\nthe GoL. Just as humans cannot predict the dynamics of the GoL, our results\nsuggest that there might be a trade-off between high performance on sensory\ninputs with different sets of rules.\n", "versions": [{"version": "v1", "created": "Tue, 16 Apr 2019 20:35:09 GMT"}], "update_date": "2019-04-18", "authors_parsed": [["Sinapayen", "Lana", ""], ["Noda", "Atsushi", ""]]}, {"id": "1904.07974", "submitter": "Nikolaj Tatti", "authors": "Nikolaj Tatti", "title": "Discovering Episodes with Compact Minimal Windows", "comments": null, "journal-ref": null, "doi": "10.1007/s10618-013-0327-9", "report-no": null, "categories": "cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Discovering the most interesting patterns is the key problem in the field of\npattern mining. While ranking or selecting patterns is well-studied for\nitemsets it is surprisingly under-researched for other, more complex, pattern\ntypes.\n  In this paper we propose a new quality measure for episodes. An episode is\nessentially a set of events with possible restrictions on the order of events.\nWe say that an episode is significant if its occurrence is abnormally compact,\nthat is, only few gap events occur between the actual episode events, when\ncompared to the expected length according to the independence model. We can\napply this measure as a post-pruning step by first discovering frequent\nepisodes and then rank them according to this measure.\n  In order to compute the score we will need to compute the mean and the\nvariance according to the independence model. As a main technical contribution\nwe introduce a technique that allows us to compute these values. Such a task is\nsurprisingly complex and in order to solve it we develop intricate finite state\nmachines that allow us to compute the needed statistics. We also show that\nasymptotically our score can be interpreted as a P-value. In our experiments we\ndemonstrate that despite its intricacy our ranking is fast: we can rank tens of\nthousands episodes in seconds. Our experiments with text data demonstrate that\nour measure ranks interpretable episodes high.\n", "versions": [{"version": "v1", "created": "Mon, 15 Apr 2019 01:38:29 GMT"}], "update_date": "2019-04-18", "authors_parsed": [["Tatti", "Nikolaj", ""]]}, {"id": "1904.07976", "submitter": "Asim Darwaish", "authors": "Asim Darwaish, Farid Na\\\"it-Abdesselam, Ashfaq Khokhar", "title": "Detection and Prediction of Cardiac Anomalies Using Wireless Body\n  Sensors and Bayesian Belief Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Intricating cardiac complexities are the primary factor associated with\nhealthcare costs and the highest cause of death rate in the world. However,\npreventive measures like the early detection of cardiac anomalies can prevent\nsevere cardiovascular arrests of varying complexities and can impose a\nsubstantial impact on healthcare cost. Encountering such scenarios usually the\nelectrocardiogram (ECG or EKG) is the first diagnostic choice of a medical\npractitioner or clinical staff to measure the electrical and muscular fitness\nof an individual heart. This paper presents a system which is capable of\nreading the recorded ECG and predict the cardiac anomalies without the\nintervention of a human expert. The paper purpose an algorithm which read and\nperform analysis on electrocardiogram datasets. The proposed architecture uses\nthe Discrete Wavelet Transform (DWT) at first place to perform preprocessing of\nECG data followed by undecimated Wavelet transform (UWT) to extract nine\nrelevant features which are of high interest to a cardiologist. The\nprobabilistic mode named Bayesian Network Classifier is trained using the\nextracted nine parameters on UCL arrhythmia dataset. The proposed system\nclassifies a recorded heartbeat into four classes using Bayesian Network\nclassifier and Tukey's box analysis. The four classes for the prediction of a\nheartbeat are (a) Normal Beat, (b) Premature Ventricular Contraction (PVC) (c)\nPremature Atrial Contraction (PAC) and (d) Myocardial Infarction. The results\nof experimental setup depict that the proposed system has achieved an average\naccuracy of 96.6 for PAC\\% 92.8\\% for MI and 87\\% for PVC, with an average\nerror rate of 3.3\\% for PAC, 6\\% for MI and 12.5\\% for PVC on real\nelectrocardiogram datasets including Physionet and European ST-T Database\n(EDB).\n", "versions": [{"version": "v1", "created": "Tue, 16 Apr 2019 20:44:43 GMT"}], "update_date": "2019-04-18", "authors_parsed": [["Darwaish", "Asim", ""], ["Na\u00eft-Abdesselam", "Farid", ""], ["Khokhar", "Ashfaq", ""]]}, {"id": "1904.07980", "submitter": "George Adam", "authors": "George Adam, Petr Smirnov, Benjamin Haibe-Kains, Anna Goldenberg", "title": "Reducing Adversarial Example Transferability Using Gradient\n  Regularization", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep learning algorithms have increasingly been shown to lack robustness to\nsimple adversarial examples (AdvX). An equally troubling observation is that\nthese adversarial examples transfer between different architectures trained on\ndifferent datasets. We investigate the transferability of adversarial examples\nbetween models using the angle between the input-output Jacobians of different\nmodels. To demonstrate the relevance of this approach, we perform case studies\nthat involve jointly training pairs of models. These case studies empirically\njustify the theoretical intuitions for why the angle between gradients is a\nfundamental quantity in AdvX transferability. Furthermore, we consider the\nasymmetry of AdvX transferability between two models of the same architecture\nand explain it in terms of differences in gradient norms between the models.\nLastly, we provide a simple modification to existing training setups that\nreduces transferability of adversarial examples between pairs of models.\n", "versions": [{"version": "v1", "created": "Tue, 16 Apr 2019 20:49:49 GMT"}], "update_date": "2019-04-18", "authors_parsed": [["Adam", "George", ""], ["Smirnov", "Petr", ""], ["Haibe-Kains", "Benjamin", ""], ["Goldenberg", "Anna", ""]]}, {"id": "1904.07990", "submitter": "Gunnar R\\\"atsch", "authors": "Stephanie L. Hyland and Martin Faltys and Matthias H\\\"user and Xinrui\n  Lyu and Thomas Gumbsch and Crist\\'obal Esteban and Christian Bock and Max\n  Horn and Michael Moor and Bastian Rieck and Marc Zimmermann and Dean Bodenham\n  and Karsten Borgwardt and Gunnar R\\\"atsch and Tobias M. Merz", "title": "Machine learning for early prediction of circulatory failure in the\n  intensive care unit", "comments": "5 main figures, 1 main table, 13 supplementary figures, 5\n  supplementary tables; 250ppi images", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.AP stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Intensive care clinicians are presented with large quantities of patient\ninformation and measurements from a multitude of monitoring systems. The\nlimited ability of humans to process such complex information hinders\nphysicians to readily recognize and act on early signs of patient\ndeterioration. We used machine learning to develop an early warning system for\ncirculatory failure based on a high-resolution ICU database with 240 patient\nyears of data. This automatic system predicts 90.0% of circulatory failure\nevents (prevalence 3.1%), with 81.8% identified more than two hours in advance,\nresulting in an area under the receiver operating characteristic curve of 94.0%\nand area under the precision-recall curve of 63.0%. The model was externally\nvalidated in a large independent patient cohort.\n", "versions": [{"version": "v1", "created": "Tue, 16 Apr 2019 21:18:17 GMT"}, {"version": "v2", "created": "Fri, 19 Apr 2019 16:02:18 GMT"}], "update_date": "2019-04-22", "authors_parsed": [["Hyland", "Stephanie L.", ""], ["Faltys", "Martin", ""], ["H\u00fcser", "Matthias", ""], ["Lyu", "Xinrui", ""], ["Gumbsch", "Thomas", ""], ["Esteban", "Crist\u00f3bal", ""], ["Bock", "Christian", ""], ["Horn", "Max", ""], ["Moor", "Michael", ""], ["Rieck", "Bastian", ""], ["Zimmermann", "Marc", ""], ["Bodenham", "Dean", ""], ["Borgwardt", "Karsten", ""], ["R\u00e4tsch", "Gunnar", ""], ["Merz", "Tobias M.", ""]]}, {"id": "1904.07998", "submitter": "Yue Zhao", "authors": "Colin Wan, Zheng Li, Alicia Guo, Yue Zhao", "title": "SynC: A Unified Framework for Generating Synthetic Population with\n  Gaussian Copula", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Synthetic population generation is the process of combining multiple\nsocioeconomic and demographic datasets from different sources and/or\ngranularity levels, and downscaling them to an individual level. Although it is\na fundamental step for many data science tasks, an efficient and standard\nframework is absent. In this study, we propose a multi-stage framework called\nSynC (Synthetic Population via Gaussian Copula) to fill the gap. SynC first\nremoves potential outliers in the data and then fits the filtered data with a\nGaussian copula model to correctly capture dependencies and marginal\ndistributions of sampled survey data. Finally, SynC leverages predictive models\nto merge datasets into one and then scales them accordingly to match the\nmarginal constraints. We make three key contributions in this work: 1) propose\na novel framework for generating individual level data from aggregated data\nsources by combining state-of-the-art machine learning and statistical\ntechniques, 2) demonstrate its value as a feature engineering tool, as well as\nan alternative to data collection in situations where gathering is difficult\nthrough two real-world datasets, 3) release an easy-to-use framework\nimplementation for reproducibility, and 4) ensure the methodology is scalable\nat the production level and can easily incorporate new data.\n", "versions": [{"version": "v1", "created": "Tue, 16 Apr 2019 22:10:19 GMT"}, {"version": "v2", "created": "Mon, 11 Nov 2019 01:48:59 GMT"}], "update_date": "2019-11-12", "authors_parsed": [["Wan", "Colin", ""], ["Li", "Zheng", ""], ["Guo", "Alicia", ""], ["Zhao", "Yue", ""]]}, {"id": "1904.08030", "submitter": "Chao Li", "authors": "Chao Li, Zhiyuan Liu, Mengmeng Wu, Yuchi Xu, Pipei Huang, Huan Zhao,\n  Guoliang Kang, Qiwei Chen, Wei Li, Dik Lun Lee", "title": "Multi-Interest Network with Dynamic Routing for Recommendation at Tmall", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Industrial recommender systems usually consist of the matching stage and the\nranking stage, in order to handle the billion-scale of users and items. The\nmatching stage retrieves candidate items relevant to user interests, while the\nranking stage sorts candidate items by user interests. Thus, the most critical\nability is to model and represent user interests for either stage. Most of the\nexisting deep learning-based models represent one user as a single vector which\nis insufficient to capture the varying nature of user's interests. In this\npaper, we approach this problem from a different view, to represent one user\nwith multiple vectors encoding the different aspects of the user's interests.\nWe propose the Multi-Interest Network with Dynamic routing (MIND) for dealing\nwith user's diverse interests in the matching stage. Specifically, we design a\nmulti-interest extractor layer based on capsule routing mechanism, which is\napplicable for clustering historical behaviors and extracting diverse\ninterests. Furthermore, we develop a technique named label-aware attention to\nhelp learn a user representation with multiple vectors. Through extensive\nexperiments on several public benchmarks and one large-scale industrial dataset\nfrom Tmall, we demonstrate that MIND can achieve superior performance than\nstate-of-the-art methods for recommendation. Currently, MIND has been deployed\nfor handling major online traffic at the homepage on Mobile Tmall App.\n", "versions": [{"version": "v1", "created": "Wed, 17 Apr 2019 00:39:24 GMT"}], "update_date": "2019-04-18", "authors_parsed": [["Li", "Chao", ""], ["Liu", "Zhiyuan", ""], ["Wu", "Mengmeng", ""], ["Xu", "Yuchi", ""], ["Huang", "Pipei", ""], ["Zhao", "Huan", ""], ["Kang", "Guoliang", ""], ["Chen", "Qiwei", ""], ["Li", "Wei", ""], ["Lee", "Dik Lun", ""]]}, {"id": "1904.08031", "submitter": "Jiabin Xue", "authors": "Jiabin Xue, Jiqing Han, Tieran Zheng, Jiaxing Guo and Boyong Wu", "title": "Hard Sample Mining for the Improved Retraining of Automatic Speech\n  Recognition", "comments": "Submitted to Interspeech 2019;", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SD cs.LG eess.AS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  It is an effective way that improves the performance of the existing\nAutomatic Speech Recognition (ASR) systems by retraining with more and more new\ntraining data in the target domain. Recently, Deep Neural Network (DNN) has\nbecome a successful model in the ASR field. In the training process of the DNN\nbased methods, a back propagation of error between the transcription and the\ncorresponding annotated text is used to update and optimize the parameters.\nThus, the parameters are more influenced by the training samples with a big\npropagation error than the samples with a small one. In this paper, we define\nthe samples with significant error as the hard samples and try to improve the\nperformance of the ASR system by adding many of them. Unfortunately, the hard\nsamples are sparse in the training data of the target domain, and manually\nlabel them is expensive. Therefore, we propose a hard samples mining method\nbased on an enhanced deep multiple instance learning, which can find the hard\nsamples from unlabeled training data by using a small subset of the dataset\nwith manual labeling in the target domain. We applied our method to an End2End\nASR task and obtained the best performance.\n", "versions": [{"version": "v1", "created": "Wed, 17 Apr 2019 00:39:35 GMT"}], "update_date": "2019-04-18", "authors_parsed": [["Xue", "Jiabin", ""], ["Han", "Jiqing", ""], ["Zheng", "Tieran", ""], ["Guo", "Jiaxing", ""], ["Wu", "Boyong", ""]]}, {"id": "1904.08034", "submitter": "Brenden Lake", "authors": "Brenden M. Lake and Steven T. Piantadosi", "title": "People infer recursive visual concepts from just a few examples", "comments": "In press at \"Computational Brain & Behavior\"", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV q-bio.NC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Machine learning has made major advances in categorizing objects in images,\nyet the best algorithms miss important aspects of how people learn and think\nabout categories. People can learn richer concepts from fewer examples,\nincluding causal models that explain how members of a category are formed.\nHere, we explore the limits of this human ability to infer causal \"programs\" --\nlatent generating processes with nontrivial algorithmic properties -- from one,\ntwo, or three visual examples. People were asked to extrapolate the programs in\nseveral ways, for both classifying and generating new examples. As a theory of\nthese inductive abilities, we present a Bayesian program learning model that\nsearches the space of programs for the best explanation of the observations.\nAlthough variable, people's judgments are broadly consistent with the model and\ninconsistent with several alternatives, including a pre-trained deep neural\nnetwork for object recognition, indicating that people can learn and reason\nwith rich algorithmic abstractions from sparse input data.\n", "versions": [{"version": "v1", "created": "Wed, 17 Apr 2019 00:45:05 GMT"}, {"version": "v2", "created": "Mon, 29 Jul 2019 15:26:40 GMT"}], "update_date": "2019-07-30", "authors_parsed": [["Lake", "Brenden M.", ""], ["Piantadosi", "Steven T.", ""]]}, {"id": "1904.08035", "submitter": "Binxuan Huang", "authors": "Binxuan Huang, Kathleen M. Carley", "title": "Residual or Gate? Towards Deeper Graph Neural Networks for Inductive\n  Graph Representation Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.SI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we study the problem of node representation learning with\ngraph neural networks. We present a graph neural network class named recurrent\ngraph neural network (RGNN), that address the shortcomings of prior methods. By\nusing recurrent units to capture the long-term dependency across layers, our\nmethods can successfully identify important information during recursive\nneighborhood expansion. In our experiments, we show that our model class\nachieves state-of-the-art results on three benchmarks: the Pubmed, Reddit, and\nPPI network datasets. Our in-depth analyses also demonstrate that incorporating\nrecurrent units is a simple yet effective method to prevent noisy information\nin graphs, which enables a deeper graph neural network.\n", "versions": [{"version": "v1", "created": "Wed, 17 Apr 2019 00:46:20 GMT"}, {"version": "v2", "created": "Tue, 7 May 2019 02:38:19 GMT"}, {"version": "v3", "created": "Mon, 26 Aug 2019 17:45:11 GMT"}], "update_date": "2019-08-27", "authors_parsed": [["Huang", "Binxuan", ""], ["Carley", "Kathleen M.", ""]]}, {"id": "1904.08039", "submitter": "Jiabin Xue", "authors": "Jiabin Xue, Jiqing Han, Tieran Zheng, Xiang Gao and Jiaxing Guo", "title": "A Multi-Task Learning Framework for Overcoming the Catastrophic\n  Forgetting in Automatic Speech Recognition", "comments": "Submitted to Interspeech 2019;", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SD cs.LG eess.AS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recently, data-driven based Automatic Speech Recognition (ASR) systems have\nachieved state-of-the-art results. And transfer learning is often used when\nthose existing systems are adapted to the target domain, e.g., fine-tuning,\nretraining. However, in the processes, the system parameters may well deviate\ntoo much from the previously learned parameters. Thus, it is difficult for the\nsystem training process to learn knowledge from target domains meanwhile not\nforgetting knowledge from the previous learning process, which is called as\ncatastrophic forgetting (CF). In this paper, we attempt to solve the CF problem\nwith the lifelong learning and propose a novel multi-task learning (MTL)\ntraining framework for ASR. It considers reserving original knowledge and\nlearning new knowledge as two independent tasks, respectively. On the one hand,\nwe constrain the new parameters not to deviate too far from the original\nparameters and punish the new system when forgetting original knowledge. On the\nother hand, we force the new system to solve new knowledge quickly. Then, a MTL\nmechanism is employed to get the balance between the two tasks. We applied our\nmethod to an End2End ASR task and obtained the best performance in both target\nand original datasets.\n", "versions": [{"version": "v1", "created": "Wed, 17 Apr 2019 00:55:04 GMT"}], "update_date": "2019-04-18", "authors_parsed": [["Xue", "Jiabin", ""], ["Han", "Jiqing", ""], ["Zheng", "Tieran", ""], ["Gao", "Xiang", ""], ["Guo", "Jiaxing", ""]]}, {"id": "1904.08049", "submitter": "Yanjun  Qi Dr.", "authors": "Jack Lanchantin, Arshdeep Sekhon and Yanjun Qi", "title": "Neural Message Passing for Multi-Label Classification", "comments": "19pages. We provide our code and datasets at\n  https://github.com/QData/LaMP", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.IR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Multi-label classification (MLC) is the task of assigning a set of target\nlabels for a given sample. Modeling the combinatorial label interactions in MLC\nhas been a long-haul challenge. We propose Label Message Passing (LaMP) Neural\nNetworks to efficiently model the joint prediction of multiple labels. LaMP\ntreats labels as nodes on a label-interaction graph and computes the hidden\nrepresentation of each label node conditioned on the input using\nattention-based neural message passing. Attention enables LaMP to assign\ndifferent importance to neighbor nodes per label, learning how labels interact\n(implicitly). The proposed models are simple, accurate, interpretable,\nstructure-agnostic, and applicable for predicting dense labels since LaMP is\nincredibly parallelizable. We validate the benefits of LaMP on seven real-world\nMLC datasets, covering a broad spectrum of input/output types and outperforming\nthe state-of-the-art results. Notably, LaMP enables intuitive interpretation of\nhow classifying each label depends on the elements of a sample and at the same\ntime rely on its interaction with other labels. We provide our code and\ndatasets at https://github.com/QData/LaMP\n", "versions": [{"version": "v1", "created": "Wed, 17 Apr 2019 01:58:17 GMT"}], "update_date": "2019-04-18", "authors_parsed": [["Lanchantin", "Jack", ""], ["Sekhon", "Arshdeep", ""], ["Qi", "Yanjun", ""]]}, {"id": "1904.08050", "submitter": "Najeeb Khan", "authors": "Najeeb Khan and Ian Stavness", "title": "Sparseout: Controlling Sparsity in Deep Networks", "comments": "Code: https://github.com/najeebkhan/sparseout", "journal-ref": null, "doi": "10.1007/978-3-030-18305-9_24", "report-no": null, "categories": "cs.LG cs.NE stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Dropout is commonly used to help reduce overfitting in deep neural networks.\nSparsity is a potentially important property of neural networks, but is not\nexplicitly controlled by Dropout-based regularization. In this work, we propose\nSparseout a simple and efficient variant of Dropout that can be used to control\nthe sparsity of the activations in a neural network. We theoretically prove\nthat Sparseout is equivalent to an $L_q$ penalty on the features of a\ngeneralized linear model and that Dropout is a special case of Sparseout for\nneural networks. We empirically demonstrate that Sparseout is computationally\ninexpensive and is able to control the desired level of sparsity in the\nactivations. We evaluated Sparseout on image classification and language\nmodelling tasks to see the effect of sparsity on these tasks. We found that\nsparsity of the activations is favorable for language modelling performance\nwhile image classification benefits from denser activations. Sparseout provides\na way to investigate sparsity in state-of-the-art deep learning models. Source\ncode for Sparseout could be found at\n\\url{https://github.com/najeebkhan/sparseout}.\n", "versions": [{"version": "v1", "created": "Wed, 17 Apr 2019 02:10:25 GMT"}], "update_date": "2019-04-18", "authors_parsed": [["Khan", "Najeeb", ""], ["Stavness", "Ian", ""]]}, {"id": "1904.08051", "submitter": "Qi Zhang", "authors": "Qi Zhang, Siliang Tang, Xiang Ren, Fei Wu, Shiliang Pu, Yueting Zhuang", "title": "Posterior-regularized REINFORCE for Instance Selection in Distant\n  Supervision", "comments": "Five pages", "journal-ref": "naacl 2019", "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper provides a new way to improve the efficiency of the REINFORCE\ntraining process. We apply it to the task of instance selection in distant\nsupervision. Modeling the instance selection in one bag as a sequential\ndecision process, a reinforcement learning agent is trained to determine\nwhether an instance is valuable or not and construct a new bag with less noisy\ninstances. However unbiased methods, such as REINFORCE, could usually take much\ntime to train. This paper adopts posterior regularization (PR) to integrate\nsome domain-specific rules in instance selection using REINFORCE. As the\nexperiment results show, this method remarkably improves the performance of the\nrelation classifier trained on cleaned distant supervision dataset as well as\nthe efficiency of the REINFORCE training.\n", "versions": [{"version": "v1", "created": "Wed, 17 Apr 2019 02:21:51 GMT"}], "update_date": "2019-04-18", "authors_parsed": [["Zhang", "Qi", ""], ["Tang", "Siliang", ""], ["Ren", "Xiang", ""], ["Wu", "Fei", ""], ["Pu", "Shiliang", ""], ["Zhuang", "Yueting", ""]]}, {"id": "1904.08061", "submitter": "Jia Li", "authors": "Jia Li, Xiao Sun, Xing Wei, Changliang Li, Jianhua Tao", "title": "Reinforcement Learning Based Emotional Editing Constraint Conversation\n  Generation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In recent years, the generation of conversation content based on deep neural\nnetworks has attracted many researchers. However, traditional neural language\nmodels tend to generate general replies, lacking logical and emotional factors.\nThis paper proposes a conversation content generation model that combines\nreinforcement learning with emotional editing constraints to generate more\nmeaningful and customizable emotional replies. The model divides the replies\ninto three clauses based on pre-generated keywords and uses the emotional\neditor to further optimize the final reply. The model combines multi-task\nlearning with multiple indicator rewards to comprehensively optimize the\nquality of replies. Experiments shows that our model can not only improve the\nfluency of the replies, but also significantly enhance the logical relevance\nand emotional relevance of the replies.\n", "versions": [{"version": "v1", "created": "Wed, 17 Apr 2019 03:01:16 GMT"}], "update_date": "2019-04-18", "authors_parsed": [["Li", "Jia", ""], ["Sun", "Xiao", ""], ["Wei", "Xing", ""], ["Li", "Changliang", ""], ["Tao", "Jianhua", ""]]}, {"id": "1904.08064", "submitter": "Feng Li", "authors": "Xixi Li, Yanfei Kang, Feng Li", "title": "Forecasting with time series imaging", "comments": null, "journal-ref": "Expert Systems with Applications (2020)", "doi": "10.1016/j.eswa.2020.113680", "report-no": null, "categories": "stat.ML cs.CV cs.LG stat.CO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Feature-based time series representations have attracted substantial\nattention in a wide range of time series analysis methods. Recently, the use of\ntime series features for forecast model averaging has been an emerging research\nfocus in the forecasting community. Nonetheless, most of the existing\napproaches depend on the manual choice of an appropriate set of features.\nExploiting machine learning methods to extract features from time series\nautomatically becomes crucial in state-of-the-art time series analysis. In this\npaper, we introduce an automated approach to extract time series features based\non time series imaging. We first transform time series into recurrence plots,\nfrom which local features can be extracted using computer vision algorithms.\nThe extracted features are used for forecast model averaging. Our experiments\nshow that forecasting based on automatically extracted features, with less\nhuman intervention and a more comprehensive view of the raw time series data,\nyields highly comparable performances with the best methods in the largest\nforecasting competition dataset (M4) and outperforms the top methods in the\nTourism forecasting competition dataset.\n", "versions": [{"version": "v1", "created": "Wed, 17 Apr 2019 03:18:45 GMT"}, {"version": "v2", "created": "Fri, 13 Mar 2020 03:33:57 GMT"}, {"version": "v3", "created": "Fri, 5 Jun 2020 03:13:12 GMT"}], "update_date": "2020-07-21", "authors_parsed": [["Li", "Xixi", ""], ["Kang", "Yanfei", ""], ["Li", "Feng", ""]]}, {"id": "1904.08067", "submitter": "Kamran Kowsari", "authors": "Kamran Kowsari, Kiana Jafari Meimandi, Mojtaba Heidarysafa, Sanjana\n  Mendu, Laura E. Barnes, Donald E. Brown", "title": "Text Classification Algorithms: A Survey", "comments": null, "journal-ref": null, "doi": "10.3390/info10040150", "report-no": null, "categories": "cs.LG cs.AI cs.CL cs.IR stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  In recent years, there has been an exponential growth in the number of\ncomplex documents and texts that require a deeper understanding of machine\nlearning methods to be able to accurately classify texts in many applications.\nMany machine learning approaches have achieved surpassing results in natural\nlanguage processing. The success of these learning algorithms relies on their\ncapacity to understand complex models and non-linear relationships within data.\nHowever, finding suitable structures, architectures, and techniques for text\nclassification is a challenge for researchers. In this paper, a brief overview\nof text classification algorithms is discussed. This overview covers different\ntext feature extractions, dimensionality reduction methods, existing algorithms\nand techniques, and evaluations methods. Finally, the limitations of each\ntechnique and their application in the real-world problem are discussed.\n", "versions": [{"version": "v1", "created": "Wed, 17 Apr 2019 03:29:05 GMT"}, {"version": "v2", "created": "Tue, 23 Apr 2019 01:20:53 GMT"}, {"version": "v3", "created": "Thu, 25 Apr 2019 18:28:33 GMT"}, {"version": "v4", "created": "Tue, 25 Jun 2019 22:51:18 GMT"}, {"version": "v5", "created": "Wed, 20 May 2020 16:27:00 GMT"}], "update_date": "2020-05-21", "authors_parsed": [["Kowsari", "Kamran", ""], ["Meimandi", "Kiana Jafari", ""], ["Heidarysafa", "Mojtaba", ""], ["Mendu", "Sanjana", ""], ["Barnes", "Laura E.", ""], ["Brown", "Donald E.", ""]]}, {"id": "1904.08082", "submitter": "InYeop Lee", "authors": "Junhyun Lee, Inyeop Lee, Jaewoo Kang", "title": "Self-Attention Graph Pooling", "comments": "10 pages, 3 figures, 4 tables. Accepted to ICML 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Advanced methods of applying deep learning to structured data such as graphs\nhave been proposed in recent years. In particular, studies have focused on\ngeneralizing convolutional neural networks to graph data, which includes\nredefining the convolution and the downsampling (pooling) operations for\ngraphs. The method of generalizing the convolution operation to graphs has been\nproven to improve performance and is widely used. However, the method of\napplying downsampling to graphs is still difficult to perform and has room for\nimprovement. In this paper, we propose a graph pooling method based on\nself-attention. Self-attention using graph convolution allows our pooling\nmethod to consider both node features and graph topology. To ensure a fair\ncomparison, the same training procedures and model architectures were used for\nthe existing pooling methods and our method. The experimental results\ndemonstrate that our method achieves superior graph classification performance\non the benchmark datasets using a reasonable number of parameters.\n", "versions": [{"version": "v1", "created": "Wed, 17 Apr 2019 05:02:24 GMT"}, {"version": "v2", "created": "Thu, 18 Apr 2019 01:38:18 GMT"}, {"version": "v3", "created": "Wed, 24 Apr 2019 06:55:43 GMT"}, {"version": "v4", "created": "Thu, 13 Jun 2019 05:54:07 GMT"}], "update_date": "2019-06-14", "authors_parsed": [["Lee", "Junhyun", ""], ["Lee", "Inyeop", ""], ["Kang", "Jaewoo", ""]]}, {"id": "1904.08084", "submitter": "Sheryl Brahnam", "authors": "L. Nanni, S. Brahnam, S. Ghidoni, and G. Maguolo", "title": "General Purpose (GenP) Bioimage Ensemble of Handcrafted and Learned\n  Features with Data Augmentation", "comments": "27 pages, 1 figure, 5 tables, manuscript", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Bioimage classification plays a crucial role in many biological problems. In\nthis work, we present a new General Purpose (GenP) ensemble that boosts\nperformance by combining local features, dense sampling features, and deep\nlearning approaches. First, we introduce three new methods for data\naugmentation based on PCA/DCT; second, we show that different data augmentation\napproaches can boost the performance of an ensemble of CNNs; and, finally, we\npropose a set of handcrafted/learned descriptors that are highly generalizable.\nEach handcrafted descriptor is used to train a different Support Vector Machine\n(SVM), and the different SVMs are combined with the ensemble of CNNs. Our\nmethod is evaluated on a diverse set of bioimage classification problems.\nResults demonstrate that the proposed GenP bioimage ensemble obtains\nstate-of-the-art performance without any ad-hoc dataset tuning of parameters\n(thus avoiding the risk of overfitting/overtraining).\n", "versions": [{"version": "v1", "created": "Wed, 17 Apr 2019 05:11:55 GMT"}, {"version": "v2", "created": "Tue, 6 Oct 2020 06:02:29 GMT"}, {"version": "v3", "created": "Thu, 22 Apr 2021 05:51:58 GMT"}, {"version": "v4", "created": "Tue, 6 Jul 2021 05:31:12 GMT"}], "update_date": "2021-07-07", "authors_parsed": [["Nanni", "L.", ""], ["Brahnam", "S.", ""], ["Ghidoni", "S.", ""], ["Maguolo", "G.", ""]]}, {"id": "1904.08089", "submitter": "Yuxian Qiu", "authors": "Yuxian Qiu, Jingwen Leng, Cong Guo, Quan Chen, Chao Li, Minyi Guo and\n  Yuhao Zhu", "title": "Adversarial Defense Through Network Profiling Based Path Extraction", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recently, researchers have started decomposing deep neural network models\naccording to their semantics or functions. Recent work has shown the\neffectiveness of decomposed functional blocks for defending adversarial\nattacks, which add small input perturbation to the input image to fool the DNN\nmodels. This work proposes a profiling-based method to decompose the DNN models\nto different functional blocks, which lead to the effective path as a new\napproach to exploring DNNs' internal organization. Specifically, the per-image\neffective path can be aggregated to the class-level effective path, through\nwhich we observe that adversarial images activate effective path different from\nnormal images. We propose an effective path similarity-based method to detect\nadversarial images with an interpretable model, which achieve better accuracy\nand broader applicability than the state-of-the-art technique.\n", "versions": [{"version": "v1", "created": "Wed, 17 Apr 2019 05:51:24 GMT"}, {"version": "v2", "created": "Thu, 9 May 2019 04:40:40 GMT"}], "update_date": "2019-05-10", "authors_parsed": [["Qiu", "Yuxian", ""], ["Leng", "Jingwen", ""], ["Guo", "Cong", ""], ["Chen", "Quan", ""], ["Li", "Chao", ""], ["Guo", "Minyi", ""], ["Zhu", "Yuhao", ""]]}, {"id": "1904.08092", "submitter": "Siddharth Srivastava", "authors": "Siddharth Srivastava, Sumit Soman, Astha Rai", "title": "An Online Learning Approach for Dengue Fever Classification", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper introduces a novel approach for dengue fever classification based\non online learning paradigms. The proposed approach is suitable for practical\nimplementation as it enables learning using only a few training samples. With\ntime, the proposed approach is capable of learning incrementally from the data\ncollected without need for retraining the model or redeployment of the\nprediction engine. Additionally, we also provide a comprehensive evaluation of\nmachine learning methods for prediction of dengue fever. The input to the\nproposed pipeline comprises of recorded patient symptoms and diagnostic\ninvestigations. Offline classifier models have been employed to obtain baseline\nscores to establish that the feature set is optimal for classification of\ndengue. The primary benefit of the online detection model presented in the\npaper is that it has been established to effectively identify patients with\nhigh likelihood of dengue disease, and experiments on scalability in terms of\nnumber of training and test samples validate the use of the proposed model.\n", "versions": [{"version": "v1", "created": "Wed, 17 Apr 2019 05:57:52 GMT"}], "update_date": "2019-04-18", "authors_parsed": [["Srivastava", "Siddharth", ""], ["Soman", "Sumit", ""], ["Rai", "Astha", ""]]}, {"id": "1904.08095", "submitter": "Vinoj Yasanga Jayasundara Magalle Hewa Mr.", "authors": "Vinoj Jayasundara, Sandaru Jayasekara, Hirunima Jayasekara, Jathushan\n  Rajasegaran, Suranga Seneviratne, Ranga Rodrigo", "title": "TextCaps : Handwritten Character Recognition with Very Small Datasets", "comments": null, "journal-ref": "In 2019 IEEE Winter Conference on Applications of Computer Vision\n  (WACV) (pp. 254-262). IEEE 2019", "doi": "10.1109/WACV.2019.00033", "report-no": null, "categories": "cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Many localized languages struggle to reap the benefits of recent advancements\nin character recognition systems due to the lack of substantial amount of\nlabeled training data. This is due to the difficulty in generating large\namounts of labeled data for such languages and inability of deep learning\ntechniques to properly learn from small number of training samples. We solve\nthis problem by introducing a technique of generating new training samples from\nthe existing samples, with realistic augmentations which reflect actual\nvariations that are present in human hand writing, by adding random controlled\nnoise to their corresponding instantiation parameters. Our results with a mere\n200 training samples per class surpass existing character recognition results\nin the EMNIST-letter dataset while achieving the existing results in the three\ndatasets: EMNIST-balanced, EMNIST-digits, and MNIST. We also develop a strategy\nto effectively use a combination of loss functions to improve reconstructions.\nOur system is useful in character recognition for localized languages that lack\nmuch labeled training data and even in other related more general contexts such\nas object recognition.\n", "versions": [{"version": "v1", "created": "Wed, 17 Apr 2019 06:09:59 GMT"}], "update_date": "2020-08-10", "authors_parsed": [["Jayasundara", "Vinoj", ""], ["Jayasekara", "Sandaru", ""], ["Jayasekara", "Hirunima", ""], ["Rajasegaran", "Jathushan", ""], ["Seneviratne", "Suranga", ""], ["Rodrigo", "Ranga", ""]]}, {"id": "1904.08098", "submitter": "Dacheng Tao", "authors": "Qiang Li, Bo Xie, Jane You, Wei Bian, Dacheng Tao", "title": "Correlated Logistic Model With Elastic Net Regularization for Multilabel\n  Image Classification", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we present correlated logistic (CorrLog) model for multilabel\nimage classification. CorrLog extends conventional logistic regression model\ninto multilabel cases, via explicitly modeling the pairwise correlation between\nlabels. In addition, we propose to learn the model parameters of CorrLog with\nelastic net regularization, which helps exploit the sparsity in feature\nselection and label correlations and thus further boost the performance of\nmultilabel classification. CorrLog can be efficiently learned, though\napproximately, by regularized maximum pseudo likelihood estimation, and it\nenjoys a satisfying generalization bound that is independent of the number of\nlabels. CorrLog performs competitively for multilabel image classification on\nbenchmark data sets MULAN scene, MIT outdoor scene, PASCAL VOC 2007, and PASCAL\nVOC 2012, compared with the state-of-the-art multilabel classification\nalgorithms.\n", "versions": [{"version": "v1", "created": "Wed, 17 Apr 2019 06:16:59 GMT"}], "update_date": "2019-04-18", "authors_parsed": [["Li", "Qiang", ""], ["Xie", "Bo", ""], ["You", "Jane", ""], ["Bian", "Wei", ""], ["Tao", "Dacheng", ""]]}, {"id": "1904.08102", "submitter": "Kevin Yang", "authors": "Kevin K. Yang, Yuxin Chen, Alycia Lee, Yisong Yue", "title": "Batched Stochastic Bayesian Optimization via Combinatorial Constraints\n  Design", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG q-bio.QM stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In many high-throughput experimental design settings, such as those common in\nbiochemical engineering, batched queries are more cost effective than\none-by-one sequential queries. Furthermore, it is often not possible to\ndirectly choose items to query. Instead, the experimenter specifies a set of\nconstraints that generates a library of possible items, which are then selected\nstochastically. Motivated by these considerations, we investigate \\emph{Batched\nStochastic Bayesian Optimization} (BSBO), a novel Bayesian optimization scheme\nfor choosing the constraints in order to guide exploration towards items with\ngreater utility. We focus on \\emph{site-saturation mutagenesis}, a prototypical\nsetting of BSBO in biochemical engineering, and propose a natural objective\nfunction for this problem. Importantly, we show that our objective function can\nbe efficiently decomposed as a difference of submodular functions (DS), which\nallows us to employ DS optimization tools to greedily identify sets of\nconstraints that increase the likelihood of finding items with high utility.\nOur experimental results show that our algorithm outperforms common heuristics\non both synthetic and two real protein datasets.\n", "versions": [{"version": "v1", "created": "Wed, 17 Apr 2019 06:30:58 GMT"}], "update_date": "2019-04-18", "authors_parsed": [["Yang", "Kevin K.", ""], ["Chen", "Yuxin", ""], ["Lee", "Alycia", ""], ["Yue", "Yisong", ""]]}, {"id": "1904.08104", "submitter": "Jee-Weon Jung", "authors": "Jee-weon Jung, Hee-Soo Heo, Ju-ho Kim, Hye-jin Shim, Ha-Jin Yu", "title": "RawNet: Advanced end-to-end deep neural network using raw waveforms for\n  text-independent speaker verification", "comments": "Accepted for oral presentation at Interspeech 2019, code available at\n  http://github.com/Jungjee/RawNet", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.AS cs.LG cs.SD", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recently, direct modeling of raw waveforms using deep neural networks has\nbeen widely studied for a number of tasks in audio domains. In speaker\nverification, however, utilization of raw waveforms is in its preliminary\nphase, requiring further investigation. In this study, we explore end-to-end\ndeep neural networks that input raw waveforms to improve various aspects:\nfront-end speaker embedding extraction including model architecture,\npre-training scheme, additional objective functions, and back-end\nclassification. Adjustment of model architecture using a pre-training scheme\ncan extract speaker embeddings, giving a significant improvement in\nperformance. Additional objective functions simplify the process of extracting\nspeaker embeddings by merging conventional two-phase processes: extracting\nutterance-level features such as i-vectors or x-vectors and the feature\nenhancement phase, e.g., linear discriminant analysis. Effective back-end\nclassification models that suit the proposed speaker embedding are also\nexplored. We propose an end-to-end system that comprises two deep neural\nnetworks, one front-end for utterance-level speaker embedding extraction and\nthe other for back-end classification. Experiments conducted on the VoxCeleb1\ndataset demonstrate that the proposed model achieves state-of-the-art\nperformance among systems without data augmentation. The proposed system is\nalso comparable to the state-of-the-art x-vector system that adopts data\naugmentation.\n", "versions": [{"version": "v1", "created": "Wed, 17 Apr 2019 06:37:22 GMT"}, {"version": "v2", "created": "Wed, 17 Jul 2019 03:52:16 GMT"}], "update_date": "2019-07-18", "authors_parsed": [["Jung", "Jee-weon", ""], ["Heo", "Hee-Soo", ""], ["Kim", "Ju-ho", ""], ["Shim", "Hye-jin", ""], ["Yu", "Ha-Jin", ""]]}, {"id": "1904.08117", "submitter": "Hua Wei", "authors": "Hua Wei, Guanjie Zheng, Vikash Gayah, Zhenhui Li", "title": "A Survey on Traffic Signal Control Methods", "comments": "32 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Traffic signal control is an important and challenging real-world problem,\nwhich aims to minimize the travel time of vehicles by coordinating their\nmovements at the road intersections. Current traffic signal control systems in\nuse still rely heavily on oversimplified information and rule-based methods,\nalthough we now have richer data, more computing power and advanced methods to\ndrive the development of intelligent transportation. With the growing interest\nin intelligent transportation using machine learning methods like reinforcement\nlearning, this survey covers the widely acknowledged transportation approaches\nand a comprehensive list of recent literature on reinforcement for traffic\nsignal control. We hope this survey can foster interdisciplinary research on\nthis important topic.\n", "versions": [{"version": "v1", "created": "Wed, 17 Apr 2019 08:07:29 GMT"}, {"version": "v2", "created": "Mon, 1 Jul 2019 22:23:49 GMT"}, {"version": "v3", "created": "Thu, 16 Jan 2020 16:29:35 GMT"}], "update_date": "2020-01-17", "authors_parsed": [["Wei", "Hua", ""], ["Zheng", "Guanjie", ""], ["Gayah", "Vikash", ""], ["Li", "Zhenhui", ""]]}, {"id": "1904.08129", "submitter": "Yuji Kanagawa", "authors": "Yuji Kanagawa and Tomoyuki Kaneko", "title": "Rogue-Gym: A New Challenge for Generalization in Reinforcement Learning", "comments": "8 pages, 14 figures, 4 tables, accepted to IEEE COG 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we propose Rogue-Gym, a simple and classic style roguelike\ngame built for evaluating generalization in reinforcement learning (RL).\nCombined with the recent progress of deep neural networks, RL has successfully\ntrained human-level agents without human knowledge in many games such as those\nfor Atari 2600. However, it has been pointed out that agents trained with RL\nmethods often overfit the training environment, and they work poorly in\nslightly different environments. To investigate this problem, some research\nenvironments with procedural content generation have been proposed. Following\nthese studies, we propose the use of roguelikes as a benchmark for evaluating\nthe generalization ability of RL agents. In our Rogue-Gym, agents need to\nexplore dungeons that are structured differently each time they start a new\ngame. Thanks to the very diverse structures of the dungeons, we believe that\nthe generalization benchmark of Rogue-Gym is sufficiently fair. In our\nexperiments, we evaluate a standard reinforcement learning method, PPO, with\nand without enhancements for generalization. The results show that some\nenhancements believed to be effective fail to mitigate the overfitting in\nRogue-Gym, although others slightly improve the generalization ability.\n", "versions": [{"version": "v1", "created": "Wed, 17 Apr 2019 08:31:06 GMT"}, {"version": "v2", "created": "Sat, 1 Jun 2019 03:39:07 GMT"}], "update_date": "2019-06-04", "authors_parsed": [["Kanagawa", "Yuji", ""], ["Kaneko", "Tomoyuki", ""]]}, {"id": "1904.08144", "submitter": "Jaechang Lim", "authors": "Jaechang Lim, Seongok Ryu, Kyubyong Park, Yo Joong Choe, Jiyeon Ham,\n  and Woo Youn Kim", "title": "Predicting drug-target interaction using 3D structure-embedded graph\n  representations from graph neural networks", "comments": "20 pages, 2 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Accurate prediction of drug-target interaction (DTI) is essential for in\nsilico drug design. For the purpose, we propose a novel approach for predicting\nDTI using a GNN that directly incorporates the 3D structure of a protein-ligand\ncomplex. We also apply a distance-aware graph attention algorithm with gate\naugmentation to increase the performance of our model. As a result, our model\nshows better performance than docking and other deep learning methods for both\nvirtual screening and pose prediction. In addition, our model can reproduce the\nnatural population distribution of active molecules and inactive molecules.\n", "versions": [{"version": "v1", "created": "Wed, 17 Apr 2019 09:03:54 GMT"}], "update_date": "2019-04-18", "authors_parsed": [["Lim", "Jaechang", ""], ["Ryu", "Seongok", ""], ["Park", "Kyubyong", ""], ["Choe", "Yo Joong", ""], ["Ham", "Jiyeon", ""], ["Kim", "Woo Youn", ""]]}, {"id": "1904.08149", "submitter": "Ozan \\c{C}atal", "authors": "Ozan \\c{C}atal, Johannes Nauta, Tim Verbelen, Pieter Simoens and Bart\n  Dhoedt", "title": "Bayesian policy selection using active inference", "comments": "ICLR 2019 Workshop on Structure & priors in reinforcement learning", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.NE", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Learning to take actions based on observations is a core requirement for\nartificial agents to be able to be successful and robust at their task.\nReinforcement Learning (RL) is a well-known technique for learning such\npolicies. However, current RL algorithms often have to deal with reward\nshaping, have difficulties generalizing to other environments and are most\noften sample inefficient. In this paper, we explore active inference and the\nfree energy principle, a normative theory from neuroscience that explains how\nself-organizing biological systems operate by maintaining a model of the world\nand casting action selection as an inference problem. We apply this concept to\na typical problem known to the RL community, the mountain car problem, and show\nhow active inference encompasses both RL and learning from demonstrations.\n", "versions": [{"version": "v1", "created": "Wed, 17 Apr 2019 09:18:07 GMT"}, {"version": "v2", "created": "Thu, 25 Apr 2019 14:28:32 GMT"}], "update_date": "2019-04-26", "authors_parsed": [["\u00c7atal", "Ozan", ""], ["Nauta", "Johannes", ""], ["Verbelen", "Tim", ""], ["Simoens", "Pieter", ""], ["Dhoedt", "Bart", ""]]}, {"id": "1904.08155", "submitter": "Dominique Vaufreydaz", "authors": "Justin Le Louedec (PERVASIVE), Thomas Guntz (PERVASIVE), James Crowley\n  (PERVASIVE), Dominique Vaufreydaz (PERVASIVE)", "title": "Deep learning investigation for chess player attention prediction using\n  eye-tracking and game data", "comments": null, "journal-ref": "ACM Symposium On Eye Tracking Research & Applications (ETRA 2019),\n  Jun 2019, Denver, United States.", "doi": "10.1145/3314111.3319827", "report-no": null, "categories": "stat.ML cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This article reports on an investigation of the use of convolutional neural\nnetworks to predict the visual attention of chess players. The visual attention\nmodel described in this article has been created to generate saliency maps that\ncapture hierarchical and spatial features of chessboard, in order to predict\nthe probability fixation for individual pixels Using a skip-layer architecture\nof an autoencoder, with a unified decoder, we are able to use multiscale\nfeatures to predict saliency of part of the board at different scales, showing\nmultiple relations between pieces. We have used scan path and fixation data\nfrom players engaged in solving chess problems, to compute 6600 saliency maps\nassociated to the corresponding chess piece configurations. This corpus is\ncompleted with synthetically generated data from actual games gathered from an\nonline chess platform. Experiments realized using both scan-paths from chess\nplayers and the CAT2000 saliency dataset of natural images, highlights several\nresults. Deep features, pretrained on natural images, were found to be helpful\nin training visual attention prediction for chess. The proposed neural network\narchitecture is able to generate meaningful saliency maps on unseen chess\nconfigurations with good scores on standard metrics. This work provides a\nbaseline for future work on visual attention prediction in similar contexts.\n", "versions": [{"version": "v1", "created": "Wed, 17 Apr 2019 09:31:37 GMT"}], "update_date": "2019-04-21", "authors_parsed": [["Louedec", "Justin Le", "", "PERVASIVE"], ["Guntz", "Thomas", "", "PERVASIVE"], ["Crowley", "James", "", "PERVASIVE"], ["Vaufreydaz", "Dominique", "", "PERVASIVE"]]}, {"id": "1904.08157", "submitter": "Tianshu Lyu", "authors": "Tianshu Lyu, Fei Sun, Peng Jiang, Wenwu Ou, Yan Zhang", "title": "Compositional Network Embedding", "comments": "Accepted By RecSys 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.SI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Network embedding has proved extremely useful in a variety of network\nanalysis tasks such as node classification, link prediction, and network\nvisualization. Almost all the existing network embedding methods learn to map\nthe node IDs to their corresponding node embeddings. This design principle,\nhowever, hinders the existing methods from being applied in real cases. Node ID\nis not generalizable and, thus, the existing methods have to pay great effort\nin cold-start problem. The heterogeneous network usually requires extra work to\nencode node types, as node type is not able to be identified by node ID. Node\nID carries rare information, resulting in the criticism that the existing\nmethods are not robust to noise.\n  To address this issue, we introduce Compositional Network Embedding, a\ngeneral inductive network representation learning framework that generates node\nembeddings by combining node features based on the principle of\ncompositionally. Instead of directly optimizing an embedding lookup based on\narbitrary node IDs, we learn a composition function that infers node embeddings\nby combining the corresponding node attribute embeddings through a graph-based\nloss. For evaluation, we conduct the experiments on link prediction under four\ndifferent settings. The results verified the effectiveness and generalization\nability of compositional network embeddings, especially on unseen nodes.\n", "versions": [{"version": "v1", "created": "Wed, 17 Apr 2019 09:39:43 GMT"}, {"version": "v2", "created": "Thu, 18 Apr 2019 02:24:31 GMT"}, {"version": "v3", "created": "Tue, 13 Aug 2019 01:25:16 GMT"}], "update_date": "2019-08-14", "authors_parsed": [["Lyu", "Tianshu", ""], ["Sun", "Fei", ""], ["Jiang", "Peng", ""], ["Ou", "Wenwu", ""], ["Zhang", "Yan", ""]]}, {"id": "1904.08159", "submitter": "Daniel Koguciuk M.Sc.Eng.", "authors": "Daniel Koguciuk and {\\L}ukasz Chechli\\'nski and Tarek El-Gaaly", "title": "3D Object Recognition with Ensemble Learning --- A Study of Point\n  Cloud-Based Deep Learning Models", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.LG cs.RO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this study, we present an analysis of model-based ensemble learning for 3D\npoint-cloud object classification and detection. An ensemble of multiple model\ninstances is known to outperform a single model instance, but there is little\nstudy of the topic of ensemble learning for 3D point clouds. First, an ensemble\nof multiple model instances trained on the same part of the\n$\\textit{ModelNet40}$ dataset was tested for seven deep learning, point\ncloud-based classification algorithms: $\\textit{PointNet}$,\n$\\textit{PointNet++}$, $\\textit{SO-Net}$, $\\textit{KCNet}$,\n$\\textit{DeepSets}$, $\\textit{DGCNN}$, and $\\textit{PointCNN}$. Second, the\nensemble of different architectures was tested. Results of our experiments show\nthat the tested ensemble learning methods improve over state-of-the-art on the\n$\\textit{ModelNet40}$ dataset, from $92.65\\%$ to $93.64\\%$ for the ensemble of\nsingle architecture instances, $94.03\\%$ for two different architectures, and\n$94.15\\%$ for five different architectures. We show that the ensemble of two\nmodels with different architectures can be as effective as the ensemble of 10\nmodels with the same architecture. Third, a study on classic bagging i.e. with\ndifferent subsets used for training multiple model instances) was tested and\nsources of ensemble accuracy growth were investigated for best-performing\narchitecture, i.e. $\\textit{SO-Net}$. We also investigate the ensemble learning\nof $\\textit{Frustum PointNet}$ approach in the task of 3D object detection,\nincreasing the average precision of 3D box detection on the $\\textit{KITTI}$\ndataset from $63.1\\%$ to $66.5\\%$ using only three model instances. We measure\nthe inference time of all 3D classification architectures on a $\\textit{Nvidia\nJetson TX2}$, a common embedded computer for mobile robots, to allude to the\nuse of these models in real-life applications.\n", "versions": [{"version": "v1", "created": "Wed, 17 Apr 2019 09:51:12 GMT"}, {"version": "v2", "created": "Wed, 22 May 2019 22:46:23 GMT"}], "update_date": "2019-05-24", "authors_parsed": [["Koguciuk", "Daniel", ""], ["Chechli\u0144ski", "\u0141ukasz", ""], ["El-Gaaly", "Tarek", ""]]}, {"id": "1904.08194", "submitter": "Tom Pelsmaeker", "authors": "Tom Pelsmaeker, Wilker Aziz", "title": "Effective Estimation of Deep Generative Language Models", "comments": "Published in ACL 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Advances in variational inference enable parameterisation of probabilistic\nmodels by deep neural networks. This combines the statistical transparency of\nthe probabilistic modelling framework with the representational power of deep\nlearning. Yet, due to a problem known as posterior collapse, it is difficult to\nestimate such models in the context of language modelling effectively. We\nconcentrate on one such model, the variational auto-encoder, which we argue is\nan important building block in hierarchical probabilistic models of language.\nThis paper contributes a sober view of the problem, a survey of techniques to\naddress it, novel techniques, and extensions to the model. To establish a\nranking of techniques, we perform a systematic comparison using Bayesian\noptimisation and find that many techniques perform reasonably similar, given\nenough resources. Still, a favourite can be named based on convenience. We also\nmake several empirical observations and recommendations of best practices that\nshould help researchers interested in this exciting field.\n", "versions": [{"version": "v1", "created": "Wed, 17 Apr 2019 11:24:58 GMT"}, {"version": "v2", "created": "Thu, 19 Sep 2019 14:57:41 GMT"}, {"version": "v3", "created": "Fri, 1 May 2020 18:21:17 GMT"}], "update_date": "2020-05-05", "authors_parsed": [["Pelsmaeker", "Tom", ""], ["Aziz", "Wilker", ""]]}, {"id": "1904.08205", "submitter": "L\\'eonard Torossian", "authors": "L\\'eonard Torossian, Aur\\'elien Garivier, Victor Picheny", "title": "X-Armed Bandits: Optimizing Quantiles, CVaR and Other Risks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose and analyze StoROO, an algorithm for risk optimization on\nstochastic black-box functions derived from StoOO. Motivated by risk-averse\ndecision making fields like agriculture, medicine, biology or finance, we do\nnot focus on the mean payoff but on generic functionals of the return\ndistribution. We provide a generic regret analysis of StoROO and illustrate its\napplicability with two examples: the optimization of quantiles and CVaR.\nInspired by the bandit literature and black-box mean optimizers, StoROO relies\non the possibility to construct confidence intervals for the targeted\nfunctional based on random-size samples. We detail their construction in the\ncase of quantiles, providing tight bounds based on Kullback-Leibler divergence.\nWe finally present numerical experiments that show a dramatic impact of tight\nbounds for the optimization of quantiles and CVaR.\n", "versions": [{"version": "v1", "created": "Wed, 17 Apr 2019 11:52:11 GMT"}, {"version": "v2", "created": "Tue, 22 Oct 2019 08:33:59 GMT"}, {"version": "v3", "created": "Wed, 4 Mar 2020 16:48:34 GMT"}], "update_date": "2020-03-05", "authors_parsed": [["Torossian", "L\u00e9onard", ""], ["Garivier", "Aur\u00e9lien", ""], ["Picheny", "Victor", ""]]}, {"id": "1904.08208", "submitter": "Rodrigo Caye Daudt", "authors": "Rodrigo Caye Daudt, Bertrand Le Saux, Alexandre Boulch, Yann Gousseau", "title": "Guided Anisotropic Diffusion and Iterative Learning for Weakly\n  Supervised Change Detection", "comments": "Accepted at CVPR 2019 Workshops", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Large scale datasets created from user labels or openly available data have\nbecome crucial to provide training data for large scale learning algorithms.\nWhile these datasets are easier to acquire, the data are frequently noisy and\nunreliable, which is motivating research on weakly supervised learning\ntechniques. In this paper we propose an iterative learning method that extracts\nthe useful information from a large scale change detection dataset generated\nfrom open vector data to train a fully convolutional network which surpasses\nthe performance obtained by naive supervised learning. We also propose the\nguided anisotropic diffusion algorithm, which improves semantic segmentation\nresults using the input images as guides to perform edge preserving filtering,\nand is used in conjunction with the iterative training method to improve\nresults.\n", "versions": [{"version": "v1", "created": "Wed, 17 Apr 2019 11:53:52 GMT"}], "update_date": "2019-04-18", "authors_parsed": [["Daudt", "Rodrigo Caye", ""], ["Saux", "Bertrand Le", ""], ["Boulch", "Alexandre", ""], ["Gousseau", "Yann", ""]]}, {"id": "1904.08249", "submitter": "Rohit Babbar", "authors": "Sujay Khandagale, Han Xiao, Rohit Babbar", "title": "Bonsai -- Diverse and Shallow Trees for Extreme Multi-label\n  Classification", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Extreme multi-label classification (XMC) refers to supervised multi-label\nlearning involving hundreds of thousand or even millions of labels. In this\npaper, we develop a suite of algorithms, called Bonsai, which generalizes the\nnotion of label representation in XMC, and partitions the labels in the\nrepresentation space to learn shallow trees. We show three concrete\nrealizations of this label representation space including : (i) the input space\nwhich is spanned by the input features, (ii) the output space spanned by label\nvectors based on their co-occurrence with other labels, and (iii) the joint\nspace by combining the input and output representations. Furthermore, the\nconstraint-free multi-way partitions learnt iteratively in these spaces lead to\nshallow trees. By combining the effect of shallow trees and generalized label\nrepresentation, Bonsai achieves the best of both worlds - fast training which\nis comparable to state-of-the-art tree-based methods in XMC, and much better\nprediction accuracy, particularly on tail-labels. On a benchmark Amazon-3M\ndataset with 3 million labels, \\bonsai outperforms a state-of-the-art\none-vs-rest method in terms of prediction accuracy, while being approximately\n200 times faster to train. The code for Bonsai is available at\n\\url{https://github.com/xmc-aalto/bonsai}\n", "versions": [{"version": "v1", "created": "Wed, 17 Apr 2019 12:57:09 GMT"}, {"version": "v2", "created": "Sat, 10 Aug 2019 15:08:30 GMT"}], "update_date": "2019-08-13", "authors_parsed": [["Khandagale", "Sujay", ""], ["Xiao", "Han", ""], ["Babbar", "Rohit", ""]]}, {"id": "1904.08254", "submitter": "Changhee Han", "authors": "Leonardo Rundo, Changhee Han, Yudai Nagano, Jin Zhang, Ryuichiro\n  Hataya, Carmelo Militello, Andrea Tangherloni, Marco S. Nobile, Claudio\n  Ferretti, Daniela Besozzi, Maria Carla Gilardi, Salvatore Vitabile, Giancarlo\n  Mauri, Hideki Nakayama, Paolo Cazzaniga", "title": "USE-Net: incorporating Squeeze-and-Excitation blocks into U-Net for\n  prostate zonal segmentation of multi-institutional MRI datasets", "comments": "44 pages, 6 figures, Accepted to Neurocomputing, Co-first authors:\n  Leonardo Rundo and Changhee Han", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Prostate cancer is the most common malignant tumors in men but prostate\nMagnetic Resonance Imaging (MRI) analysis remains challenging. Besides whole\nprostate gland segmentation, the capability to differentiate between the blurry\nboundary of the Central Gland (CG) and Peripheral Zone (PZ) can lead to\ndifferential diagnosis, since tumor's frequency and severity differ in these\nregions. To tackle the prostate zonal segmentation task, we propose a novel\nConvolutional Neural Network (CNN), called USE-Net, which incorporates\nSqueeze-and-Excitation (SE) blocks into U-Net. Especially, the SE blocks are\nadded after every Encoder (Enc USE-Net) or Encoder-Decoder block (Enc-Dec\nUSE-Net). This study evaluates the generalization ability of CNN-based\narchitectures on three T2-weighted MRI datasets, each one consisting of a\ndifferent number of patients and heterogeneous image characteristics, collected\nby different institutions. The following mixed scheme is used for\ntraining/testing: (i) training on either each individual dataset or multiple\nprostate MRI datasets and (ii) testing on all three datasets with all possible\ntraining/testing combinations. USE-Net is compared against three\nstate-of-the-art CNN-based architectures (i.e., U-Net, pix2pix, and Mixed-Scale\nDense Network), along with a semi-automatic continuous max-flow model. The\nresults show that training on the union of the datasets generally outperforms\ntraining on each dataset separately, allowing for both intra-/cross-dataset\ngeneralization. Enc USE-Net shows good overall generalization under any\ntraining condition, while Enc-Dec USE-Net remarkably outperforms the other\nmethods when trained on all datasets. These findings reveal that the SE blocks'\nadaptive feature recalibration provides excellent cross-dataset generalization\nwhen testing is performed on samples of the datasets used during training.\n", "versions": [{"version": "v1", "created": "Wed, 17 Apr 2019 13:02:30 GMT"}, {"version": "v2", "created": "Wed, 17 Jul 2019 04:10:46 GMT"}], "update_date": "2019-07-18", "authors_parsed": [["Rundo", "Leonardo", ""], ["Han", "Changhee", ""], ["Nagano", "Yudai", ""], ["Zhang", "Jin", ""], ["Hataya", "Ryuichiro", ""], ["Militello", "Carmelo", ""], ["Tangherloni", "Andrea", ""], ["Nobile", "Marco S.", ""], ["Ferretti", "Claudio", ""], ["Besozzi", "Daniela", ""], ["Gilardi", "Maria Carla", ""], ["Vitabile", "Salvatore", ""], ["Mauri", "Giancarlo", ""], ["Nakayama", "Hideki", ""], ["Cazzaniga", "Paolo", ""]]}, {"id": "1904.08269", "submitter": "Yaoming Cai", "authors": "Yaoming Cai, Xiaobo Liu, and Zhihua Cai", "title": "BS-Nets: An End-to-End Framework For Band Selection of Hyperspectral\n  Image", "comments": "The paper has been submitted to IEEE TGRS", "journal-ref": null, "doi": "10.1109/TGRS.2019.2951433", "report-no": null, "categories": "cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Hyperspectral image (HSI) consists of hundreds of continuous narrow bands\nwith high spectral correlation, which would lead to the so-called Hughes\nphenomenon and the high computational cost in processing. Band selection has\nbeen proven effective in avoiding such problems by removing the redundant\nbands. However, many of existing band selection methods separately estimate the\nsignificance for every single band and cannot fully consider the nonlinear and\nglobal interaction between spectral bands. In this paper, by assuming that a\ncomplete HSI can be reconstructed from its few informative bands, we propose a\ngeneral band selection framework, Band Selection Network (termed as BS-Net).\nThe framework consists of a band attention module (BAM), which aims to\nexplicitly model the nonlinear inter-dependencies between spectral bands, and a\nreconstruction network (RecNet), which is used to restore the original HSI cube\nfrom the learned informative bands, resulting in a flexible architecture. The\nresulting framework is end-to-end trainable, making it easier to train from\nscratch and to combine with existing networks. We implement two BS-Nets\nrespectively using fully connected networks (BS-Net-FC) and convolutional\nneural networks (BS-Net-Conv), and compare the results with many existing band\nselection approaches for three real hyperspectral images, demonstrating that\nthe proposed BS-Nets can accurately select informative band subset with less\nredundancy and achieve significantly better classification performance with an\nacceptable time cost.\n", "versions": [{"version": "v1", "created": "Wed, 17 Apr 2019 13:41:38 GMT"}], "update_date": "2019-11-22", "authors_parsed": [["Cai", "Yaoming", ""], ["Liu", "Xiaobo", ""], ["Cai", "Zhihua", ""]]}, {"id": "1904.08338", "submitter": "Chandan Gautam", "authors": "Chandan Gautam, Aruna Tiwari, M. Tanveer", "title": "OCKELM+: Kernel Extreme Learning Machine based One-class Classification\n  using Privileged Information (or KOC+: Kernel Ridge Regression or Least\n  Square SVM with zero bias based One-class Classification using Privileged\n  Information)", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Kernel method-based one-class classifier is mainly used for outlier or\nnovelty detection. In this letter, kernel ridge regression (KRR) based\none-class classifier (KOC) has been extended for learning using privileged\ninformation (LUPI). LUPI-based KOC method is referred to as KOC+. This\nprivileged information is available as a feature with the dataset but only for\ntraining (not for testing). KOC+ utilizes the privileged information\ndifferently compared to normal feature information by using a so-called\ncorrection function. Privileged information helps KOC+ in achieving better\ngeneralization performance which is exhibited in this letter by testing the\nclassifiers with and without privileged information. Existing and proposed\nclassifiers are evaluated on the datasets from UCI machine learning repository\nand also on MNIST dataset. Moreover, experimental results evince the advantage\nof KOC+ over KOC and support vector machine (SVM) based one-class classifiers.\n", "versions": [{"version": "v1", "created": "Sat, 13 Apr 2019 08:07:52 GMT"}], "update_date": "2019-04-18", "authors_parsed": [["Gautam", "Chandan", ""], ["Tiwari", "Aruna", ""], ["Tanveer", "M.", ""]]}, {"id": "1904.08352", "submitter": "Chen-Chou Lo", "authors": "Chen-Chou Lo, Szu-Wei Fu, Wen-Chin Huang, Xin Wang, Junichi Yamagishi,\n  Yu Tsao, Hsin-Min Wang", "title": "MOSNet: Deep Learning based Objective Assessment for Voice Conversion", "comments": "Accepted to Interspeech2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SD cs.LG eess.AS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Existing objective evaluation metrics for voice conversion (VC) are not\nalways correlated with human perception. Therefore, training VC models with\nsuch criteria may not effectively improve naturalness and similarity of\nconverted speech. In this paper, we propose deep learning-based assessment\nmodels to predict human ratings of converted speech. We adopt the convolutional\nand recurrent neural network models to build a mean opinion score (MOS)\npredictor, termed as MOSNet. The proposed models are tested on large-scale\nlistening test results of the Voice Conversion Challenge (VCC) 2018.\nExperimental results show that the predicted scores of the proposed MOSNet are\nhighly correlated with human MOS ratings at the system level while being fairly\ncorrelated with human MOS ratings at the utterance level. Meanwhile, we have\nmodified MOSNet to predict the similarity scores, and the preliminary results\nshow that the predicted scores are also fairly correlated with human ratings.\nThese results confirm that the proposed models could be used as a computational\nevaluator to measure the MOS of VC systems to reduce the need for expensive\nhuman rating.\n", "versions": [{"version": "v1", "created": "Wed, 17 Apr 2019 16:38:31 GMT"}, {"version": "v2", "created": "Fri, 26 Apr 2019 09:56:16 GMT"}, {"version": "v3", "created": "Wed, 14 Jul 2021 07:32:49 GMT"}], "update_date": "2021-07-15", "authors_parsed": [["Lo", "Chen-Chou", ""], ["Fu", "Szu-Wei", ""], ["Huang", "Wen-Chin", ""], ["Wang", "Xin", ""], ["Yamagishi", "Junichi", ""], ["Tsao", "Yu", ""], ["Wang", "Hsin-Min", ""]]}, {"id": "1904.08353", "submitter": "Filipe Rodrigues", "authors": "Filipe Rodrigues and Carlos Lima Azevedo", "title": "Towards Robust Deep Reinforcement Learning for Traffic Signal Control:\n  Demand Surges, Incidents and Sensor Failures", "comments": "8 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG cs.SY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Reinforcement learning (RL) constitutes a promising solution for alleviating\nthe problem of traffic congestion. In particular, deep RL algorithms have been\nshown to produce adaptive traffic signal controllers that outperform\nconventional systems. However, in order to be reliable in highly dynamic urban\nareas, such controllers need to be robust with the respect to a series of\nexogenous sources of uncertainty. In this paper, we develop an open-source\ncallback-based framework for promoting the flexible evaluation of different\ndeep RL configurations under a traffic simulation environment. With this\nframework, we investigate how deep RL-based adaptive traffic controllers\nperform under different scenarios, namely under demand surges caused by special\nevents, capacity reductions from incidents and sensor failures. We extract\nseveral key insights for the development of robust deep RL algorithms for\ntraffic control and propose concrete designs to mitigate the impact of the\nconsidered exogenous uncertainties.\n", "versions": [{"version": "v1", "created": "Wed, 17 Apr 2019 16:39:22 GMT"}, {"version": "v2", "created": "Mon, 22 Jul 2019 13:23:48 GMT"}], "update_date": "2019-07-23", "authors_parsed": [["Rodrigues", "Filipe", ""], ["Azevedo", "Carlos Lima", ""]]}, {"id": "1904.08361", "submitter": "Dileep Kalathil", "authors": "Ran Wang, Karthikeya Parunandi, Dan Yu, Dileep Kalathil, Suman\n  Chakravorty", "title": "Decoupled Data Based Approach for Learning to Control Nonlinear\n  Dynamical Systems", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.RO cs.SY stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper addresses the problem of learning the optimal control policy for a\nnonlinear stochastic dynamical system with continuous state space, continuous\naction space and unknown dynamics. This class of problems are typically\naddressed in stochastic adaptive control and reinforcement learning literature\nusing model-based and model-free approaches respectively. Both methods rely on\nsolving a dynamic programming problem, either directly or indirectly, for\nfinding the optimal closed loop control policy. The inherent `curse of\ndimensionality' associated with dynamic programming method makes these\napproaches also computationally difficult.\n  This paper proposes a novel decoupled data-based control (D2C) algorithm that\naddresses this problem using a decoupled, `open loop - closed loop', approach.\nFirst, an open-loop deterministic trajectory optimization problem is solved\nusing a black-box simulation model of the dynamical system. Then, a closed loop\ncontrol is developed around this open loop trajectory by linearization of the\ndynamics about this nominal trajectory. By virtue of linearization, a linear\nquadratic regulator based algorithm can be used for this closed loop control.\nWe show that the performance of D2C algorithm is approximately optimal.\nMoreover, simulation performance suggests significant reduction in training\ntime compared to other state of the art algorithms.\n", "versions": [{"version": "v1", "created": "Wed, 17 Apr 2019 16:58:18 GMT"}], "update_date": "2019-04-18", "authors_parsed": [["Wang", "Ran", ""], ["Parunandi", "Karthikeya", ""], ["Yu", "Dan", ""], ["Kalathil", "Dileep", ""], ["Chakravorty", "Suman", ""]]}, {"id": "1904.08368", "submitter": "Jared Roesch", "authors": "Jared Roesch, Steven Lyubomirsky, Marisa Kirisame, Logan Weber, Josh\n  Pollock, Luis Vega, Ziheng Jiang, Tianqi Chen, Thierry Moreau, Zachary\n  Tatlock", "title": "Relay: A High-Level Compiler for Deep Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.PL stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Frameworks for writing, compiling, and optimizing deep learning (DL) models\nhave recently enabled progress in areas like computer vision and natural\nlanguage processing. Extending these frameworks to accommodate the rapidly\ndiversifying landscape of DL models and hardware platforms presents challenging\ntradeoffs between expressivity, composability, and portability. We present\nRelay, a new compiler framework for DL. Relay's functional, statically typed\nintermediate representation (IR) unifies and generalizes existing DL IRs to\nexpress state-of-the-art models. The introduction of Relay's expressive IR\nrequires careful design of domain-specific optimizations, addressed via Relay's\nextension mechanisms. Using these extension mechanisms, Relay supports a\nunified compiler that can target a variety of hardware platforms. Our\nevaluation demonstrates Relay's competitive performance for a broad class of\nmodels and devices (CPUs, GPUs, and emerging accelerators). Relay's design\ndemonstrates how a unified IR can provide expressivity, composability, and\nportability without compromising performance.\n", "versions": [{"version": "v1", "created": "Wed, 17 Apr 2019 17:08:23 GMT"}, {"version": "v2", "created": "Sat, 24 Aug 2019 23:30:04 GMT"}], "update_date": "2019-08-27", "authors_parsed": [["Roesch", "Jared", ""], ["Lyubomirsky", "Steven", ""], ["Kirisame", "Marisa", ""], ["Weber", "Logan", ""], ["Pollock", "Josh", ""], ["Vega", "Luis", ""], ["Jiang", "Ziheng", ""], ["Chen", "Tianqi", ""], ["Moreau", "Thierry", ""], ["Tatlock", "Zachary", ""]]}, {"id": "1904.08375", "submitter": "Rodrigo Nogueira", "authors": "Rodrigo Nogueira, Wei Yang, Jimmy Lin, Kyunghyun Cho", "title": "Document Expansion by Query Prediction", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  One technique to improve the retrieval effectiveness of a search engine is to\nexpand documents with terms that are related or representative of the\ndocuments' content.From the perspective of a question answering system, this\nmight comprise questions the document can potentially answer. Following this\nobservation, we propose a simple method that predicts which queries will be\nissued for a given document and then expands it with those predictions with a\nvanilla sequence-to-sequence model, trained using datasets consisting of pairs\nof query and relevant documents. By combining our method with a\nhighly-effective re-ranking component, we achieve the state of the art in two\nretrieval tasks. In a latency-critical regime, retrieval results alone (without\nre-ranking) approach the effectiveness of more computationally expensive neural\nre-rankers but are much faster.\n", "versions": [{"version": "v1", "created": "Wed, 17 Apr 2019 17:20:14 GMT"}, {"version": "v2", "created": "Wed, 25 Sep 2019 00:40:54 GMT"}], "update_date": "2019-09-26", "authors_parsed": [["Nogueira", "Rodrigo", ""], ["Yang", "Wei", ""], ["Lin", "Jimmy", ""], ["Cho", "Kyunghyun", ""]]}, {"id": "1904.08378", "submitter": "Benjamin Krause", "authors": "Ben Krause, Emmanuel Kahembwe, Iain Murray, Steve Renals", "title": "Dynamic Evaluation of Transformer Language Models", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This research note combines two methods that have recently improved the state\nof the art in language modeling: Transformers and dynamic evaluation.\nTransformers use stacked layers of self-attention that allow them to capture\nlong range dependencies in sequential data. Dynamic evaluation fits models to\nthe recent sequence history, allowing them to assign higher probabilities to\nre-occurring sequential patterns. By applying dynamic evaluation to\nTransformer-XL models, we improve the state of the art on enwik8 from 0.99 to\n0.94 bits/char, text8 from 1.08 to 1.04 bits/char, and WikiText-103 from 18.3\nto 16.4 perplexity points.\n", "versions": [{"version": "v1", "created": "Wed, 17 Apr 2019 17:26:01 GMT"}], "update_date": "2019-04-18", "authors_parsed": [["Krause", "Ben", ""], ["Kahembwe", "Emmanuel", ""], ["Murray", "Iain", ""], ["Renals", "Steve", ""]]}, {"id": "1904.08379", "submitter": "Oran Gafni", "authors": "Oran Gafni, Lior Wolf, Yaniv Taigman", "title": "Vid2Game: Controllable Characters Extracted from Real-World Videos", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV cs.GR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We are given a video of a person performing a certain activity, from which we\nextract a controllable model. The model generates novel image sequences of that\nperson, according to arbitrary user-defined control signals, typically marking\nthe displacement of the moving body. The generated video can have an arbitrary\nbackground, and effectively capture both the dynamics and appearance of the\nperson.\n  The method is based on two networks. The first network maps a current pose,\nand a single-instance control signal to the next pose. The second network maps\nthe current pose, the new pose, and a given background, to an output frame.\nBoth networks include multiple novelties that enable high-quality performance.\nThis is demonstrated on multiple characters extracted from various videos of\ndancers and athletes.\n", "versions": [{"version": "v1", "created": "Wed, 17 Apr 2019 17:26:14 GMT"}], "update_date": "2019-04-18", "authors_parsed": [["Gafni", "Oran", ""], ["Wolf", "Lior", ""], ["Taigman", "Yaniv", ""]]}, {"id": "1904.08386", "submitter": "Shufan Wang", "authors": "Shufan Wang, Mohit Iyyer", "title": "Casting Light on Invisible Cities: Computationally Engaging with\n  Literary Criticism", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CL stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Literary critics often attempt to uncover meaning in a single work of\nliterature through careful reading and analysis. Applying natural language\nprocessing methods to aid in such literary analyses remains a challenge in\ndigital humanities. While most previous work focuses on \"distant reading\" by\nalgorithmically discovering high-level patterns from large collections of\nliterary works, here we sharpen the focus of our methods to a single literary\ntheory about Italo Calvino's postmodern novel Invisible Cities, which consists\nof 55 short descriptions of imaginary cities. Calvino has provided a\nclassification of these cities into eleven thematic groups, but literary\nscholars disagree as to how trustworthy his categorization is. Due to the\nunique structure of this novel, we can computationally weigh in on this debate:\nwe leverage pretrained contextualized representations to embed each city's\ndescription and use unsupervised methods to cluster these embeddings.\nAdditionally, we compare results of our computational approach to similarity\njudgments generated by human readers. Our work is a first step towards\nincorporating natural language processing into literary criticism.\n", "versions": [{"version": "v1", "created": "Wed, 17 Apr 2019 17:37:33 GMT"}], "update_date": "2019-04-18", "authors_parsed": [["Wang", "Shufan", ""], ["Iyyer", "Mohit", ""]]}, {"id": "1904.08397", "submitter": "Wolfgang Konen K", "authors": "Samineh Bagheri and Wolfgang Konen and Thomas B\\\"ack", "title": "SACOBRA with Online Whitening for Solving Optimization Problems with\n  High Conditioning", "comments": "20 pages, 10 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG math.OC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Real-world optimization problems often have expensive objective functions in\nterms of cost and time. It is desirable to find near-optimal solutions with\nvery few function evaluations. Surrogate-assisted optimizers tend to reduce the\nrequired number of function evaluations by replacing the real function with an\nefficient mathematical model built on few evaluated points. Problems with a\nhigh condition number are a challenge for many surrogate-assisted optimizers\nincluding SACOBRA. To address such problems we propose a new online whitening\noperating in the black-box optimization paradigm. We show on a set of\nhigh-conditioning functions that online whitening tackles SACOBRA's early\nstagnation issue and reduces the optimization error by a factor between 10 to\n1e12 as compared to the plain SACOBRA, though it imposes many extra function\nevaluations. Covariance matrix adaptation evolution strategy (CMA-ES) has for\nvery high numbers of function evaluations even lower errors, whereas SACOBRA\nperforms better in the expensive setting (less than 1e03 function evaluations).\nIf we count all parallelizable function evaluations (population evaluation in\nCMA-ES, online whitening in our approach) as one iteration, then both\nalgorithms have comparable strength even on the long run. This holds for\nproblems with dimension D <= 20.\n", "versions": [{"version": "v1", "created": "Wed, 17 Apr 2019 17:53:42 GMT"}], "update_date": "2019-04-18", "authors_parsed": [["Bagheri", "Samineh", ""], ["Konen", "Wolfgang", ""], ["B\u00e4ck", "Thomas", ""]]}, {"id": "1904.08405", "submitter": "Guillermo Gallego", "authors": "Guillermo Gallego, Tobi Delbruck, Garrick Orchard, Chiara Bartolozzi,\n  Brian Taba, Andrea Censi, Stefan Leutenegger, Andrew Davison, Joerg Conradt,\n  Kostas Daniilidis, Davide Scaramuzza", "title": "Event-based Vision: A Survey", "comments": null, "journal-ref": "IEEE Transactions on Pattern Analysis and Machine Intelligence,\n  2020", "doi": "10.1109/TPAMI.2020.3008413", "report-no": null, "categories": "cs.CV cs.AI cs.LG cs.RO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Event cameras are bio-inspired sensors that differ from conventional frame\ncameras: Instead of capturing images at a fixed rate, they asynchronously\nmeasure per-pixel brightness changes, and output a stream of events that encode\nthe time, location and sign of the brightness changes. Event cameras offer\nattractive properties compared to traditional cameras: high temporal resolution\n(in the order of microseconds), very high dynamic range (140 dB vs. 60 dB), low\npower consumption, and high pixel bandwidth (on the order of kHz) resulting in\nreduced motion blur. Hence, event cameras have a large potential for robotics\nand computer vision in challenging scenarios for traditional cameras, such as\nlow-latency, high speed, and high dynamic range. However, novel methods are\nrequired to process the unconventional output of these sensors in order to\nunlock their potential. This paper provides a comprehensive overview of the\nemerging field of event-based vision, with a focus on the applications and the\nalgorithms developed to unlock the outstanding properties of event cameras. We\npresent event cameras from their working principle, the actual sensors that are\navailable and the tasks that they have been used for, from low-level vision\n(feature detection and tracking, optic flow, etc.) to high-level vision\n(reconstruction, segmentation, recognition). We also discuss the techniques\ndeveloped to process events, including learning-based techniques, as well as\nspecialized processors for these novel sensors, such as spiking neural\nnetworks. Additionally, we highlight the challenges that remain to be tackled\nand the opportunities that lie ahead in the search for a more efficient,\nbio-inspired way for machines to perceive and interact with the world.\n", "versions": [{"version": "v1", "created": "Wed, 17 Apr 2019 17:59:34 GMT"}, {"version": "v2", "created": "Wed, 26 Feb 2020 18:52:38 GMT"}, {"version": "v3", "created": "Sat, 8 Aug 2020 10:55:56 GMT"}], "update_date": "2020-08-11", "authors_parsed": [["Gallego", "Guillermo", ""], ["Delbruck", "Tobi", ""], ["Orchard", "Garrick", ""], ["Bartolozzi", "Chiara", ""], ["Taba", "Brian", ""], ["Censi", "Andrea", ""], ["Leutenegger", "Stefan", ""], ["Davison", "Andrew", ""], ["Conradt", "Joerg", ""], ["Daniilidis", "Kostas", ""], ["Scaramuzza", "Davide", ""]]}, {"id": "1904.08408", "submitter": "Benjamin Deguerre", "authors": "Benjamin Deguerre, Cl\\'ement Chatelain, Gilles Gasso", "title": "Fast object detection in compressed JPEG Images", "comments": null, "journal-ref": null, "doi": "10.1109/ITSC.2019.8916937", "report-no": null, "categories": "cs.CV cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Object detection in still images has drawn a lot of attention over past few\nyears, and with the advent of Deep Learning impressive performances have been\nachieved with numerous industrial applications. Most of these deep learning\nmodels rely on RGB images to localize and identify objects in the image.\nHowever in some application scenarii, images are compressed either for storage\nsavings or fast transmission. Therefore a time consuming image decompression\nstep is compulsory in order to apply the aforementioned deep models. To\nalleviate this drawback, we propose a fast deep architecture for object\ndetection in JPEG images, one of the most widespread compression format. We\ntrain a neural network to detect objects based on the blockwise DCT (discrete\ncosine transform) coefficients {issued from} the JPEG compression algorithm. We\nmodify the well-known Single Shot multibox Detector (SSD) by replacing its\nfirst layers with one convolutional layer dedicated to process the DCT inputs.\nExperimental evaluations on PASCAL VOC and industrial dataset comprising images\nof road traffic surveillance show that the model is about $2\\times$ faster than\nregular SSD with promising detection performances. To the best of our\nknowledge, this paper is the first to address detection in compressed JPEG\nimages.\n", "versions": [{"version": "v1", "created": "Tue, 16 Apr 2019 22:10:53 GMT"}], "update_date": "2020-06-23", "authors_parsed": [["Deguerre", "Benjamin", ""], ["Chatelain", "Cl\u00e9ment", ""], ["Gasso", "Gilles", ""]]}, {"id": "1904.08410", "submitter": "Reiichiro Nakano", "authors": "Reiichiro Nakano", "title": "Neural Painters: A learned differentiable constraint for generating\n  brushstroke paintings", "comments": "Added more references and acknowledgments", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We explore neural painters, a generative model for brushstrokes learned from\na real non-differentiable and non-deterministic painting program. We show that\nwhen training an agent to \"paint\" images using brushstrokes, using a\ndifferentiable neural painter leads to much faster convergence. We propose a\nmethod for encouraging this agent to follow human-like strokes when\nreconstructing digits. We also explore the use of a neural painter as a\ndifferentiable image parameterization. By directly optimizing brushstrokes to\nactivate neurons in a pre-trained convolutional network, we can directly\nvisualize ImageNet categories and generate \"ideal\" paintings of each class.\nFinally, we present a new concept called intrinsic style transfer. By\nminimizing only the content loss from neural style transfer, we allow the\nartistic medium, in this case, brushstrokes, to naturally dictate the resulting\nstyle.\n", "versions": [{"version": "v1", "created": "Wed, 17 Apr 2019 03:03:49 GMT"}, {"version": "v2", "created": "Mon, 22 Apr 2019 17:14:53 GMT"}], "update_date": "2019-04-23", "authors_parsed": [["Nakano", "Reiichiro", ""]]}, {"id": "1904.08414", "submitter": "Andreas Danzer", "authors": "Andreas Danzer, Thomas Griebel, Martin Bach, and Klaus Dietmayer", "title": "2D Car Detection in Radar Data with PointNets", "comments": null, "journal-ref": "IEEE Intelligent Transportation Systems Conference (ITSC),\n  Auckland, New Zealand, 2019, pp. 61-66", "doi": "10.1109/ITSC.2019.8917000", "report-no": null, "categories": "cs.CV cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  For many automated driving functions, a highly accurate perception of the\nvehicle environment is a crucial prerequisite. Modern high-resolution radar\nsensors generate multiple radar targets per object, which makes these sensors\nparticularly suitable for the 2D object detection task. This work presents an\napproach to detect 2D objects solely depending on sparse radar data using\nPointNets. In literature, only methods are presented so far which perform\neither object classification or bounding box estimation for objects. In\ncontrast, this method facilitates a classification together with a bounding box\nestimation of objects using a single radar sensor. To this end, PointNets are\nadjusted for radar data performing 2D object classification with segmentation,\nand 2D bounding box regression in order to estimate an amodal 2D bounding box.\nThe algorithm is evaluated using an automatically created dataset which consist\nof various realistic driving maneuvers. The results show the great potential of\nobject detection in high-resolution radar data using PointNets.\n", "versions": [{"version": "v1", "created": "Wed, 17 Apr 2019 09:27:56 GMT"}, {"version": "v2", "created": "Fri, 12 Jul 2019 11:39:44 GMT"}, {"version": "v3", "created": "Mon, 2 Dec 2019 10:54:34 GMT"}], "update_date": "2019-12-03", "authors_parsed": [["Danzer", "Andreas", ""], ["Griebel", "Thomas", ""], ["Bach", "Martin", ""], ["Dietmayer", "Klaus", ""]]}, {"id": "1904.08421", "submitter": "Lambert Schomaker", "authors": "Lambert Schomaker", "title": "A large-scale field test on word-image classification in large\n  historical document collections using a traditional and two deep-learning\n  methods", "comments": "Field test of a large operational image search system, comparing BOVW\n  and end-to-end CNN", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This technical report describes a practical field test on word-image\nclassification in a very large collection of more than 300 diverse handwritten\nhistorical manuscripts, with 1.6 million unique labeled images and more than 11\nmillion images used in testing. Results indicate that several deep-learning\ntests completely failed (mean accuracy 83%). In the tests with more than 1000\noutput units (lexical words) in one-hot encoding for classification,\nperformance steeply drops to almost zero percent accuracy, even with a modest\nsize of the pre-final (i.e., penultimate) layer (150 units). A traditional\nfeature method (BOVW) displays a consistent performance over numbers of classes\nand numbers of training examples (mean accuracy 87%). Additional tests using\nnearest mean on the output of the pre-final layer of an Inception V3 network,\nfor each book, only yielded mediocre results (mean accuracy 49\\%), but was not\nsensitive to high numbers of classes. Notably, this experiment was only\npossible on the basis of labels that were harvested on the basis of a\ntraditional method which already works starting from a single labeled image per\nclass. It is expected that the performance of the failed deep learning tests\ncan be repaired, but only on the basis of human handcrafting (sic) of network\narchitecture and hyperparameters. When the failed problematic books are not\nconsidered, end-to-end CNN training yields about 95% accuracy. This average is\ndominated by a large subset of Chinese characters, performances for other\nscript styles being lower.\n", "versions": [{"version": "v1", "created": "Wed, 17 Apr 2019 16:03:14 GMT"}], "update_date": "2019-04-19", "authors_parsed": [["Schomaker", "Lambert", ""]]}, {"id": "1904.08444", "submitter": "Ji Lin", "authors": "Ji Lin, Chuang Gan, Song Han", "title": "Defensive Quantization: When Efficiency Meets Robustness", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Neural network quantization is becoming an industry standard to efficiently\ndeploy deep learning models on hardware platforms, such as CPU, GPU, TPU, and\nFPGAs. However, we observe that the conventional quantization approaches are\nvulnerable to adversarial attacks. This paper aims to raise people's awareness\nabout the security of the quantized models, and we designed a novel\nquantization methodology to jointly optimize the efficiency and robustness of\ndeep learning models. We first conduct an empirical study to show that vanilla\nquantization suffers more from adversarial attacks. We observe that the\ninferior robustness comes from the error amplification effect, where the\nquantization operation further enlarges the distance caused by amplified noise.\nThen we propose a novel Defensive Quantization (DQ) method by controlling the\nLipschitz constant of the network during quantization, such that the magnitude\nof the adversarial noise remains non-expansive during inference. Extensive\nexperiments on CIFAR-10 and SVHN datasets demonstrate that our new quantization\nmethod can defend neural networks against adversarial examples, and even\nachieves superior robustness than their full-precision counterparts while\nmaintaining the same hardware efficiency as vanilla quantization approaches. As\na by-product, DQ can also improve the accuracy of quantized models without\nadversarial attack.\n", "versions": [{"version": "v1", "created": "Wed, 17 Apr 2019 18:23:24 GMT"}], "update_date": "2019-04-19", "authors_parsed": [["Lin", "Ji", ""], ["Gan", "Chuang", ""], ["Han", "Song", ""]]}, {"id": "1904.08452", "submitter": "Zhenyu Tang", "authors": "Zhenyu Tang, John D. Kanu, Kevin Hogan, Dinesh Manocha", "title": "Regression and Classification for Direction-of-Arrival Estimation with\n  Convolutional Recurrent Neural Networks", "comments": null, "journal-ref": "Proc. Interspeech 2019, 654-658", "doi": "10.21437/Interspeech.2019-1111", "report-no": null, "categories": "cs.SD cs.LG eess.AS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a novel learning-based approach to estimate the\ndirection-of-arrival (DOA) of a sound source using a convolutional recurrent\nneural network (CRNN) trained via regression on synthetic data and Cartesian\nlabels. We also describe an improved method to generate synthetic data to train\nthe neural network using state-of-the-art sound propagation algorithms that\nmodel specular as well as diffuse reflections of sound. We compare our model\nagainst three other CRNNs trained using different formulations of the same\nproblem: classification on categorical labels, and regression on spherical\ncoordinate labels. In practice, our model achieves up to 43% decrease in\nangular error over prior methods. The use of diffuse reflection results in 34%\nand 41% reduction in angular prediction errors on LOCATA and SOFA datasets,\nrespectively, over prior methods based on image-source methods. Our method\nresults in an additional 3% error reduction over prior schemes that use\nclassification based networks, and we use 36% fewer network parameters.\n", "versions": [{"version": "v1", "created": "Wed, 17 Apr 2019 18:49:12 GMT"}, {"version": "v2", "created": "Fri, 19 Apr 2019 19:54:02 GMT"}, {"version": "v3", "created": "Wed, 10 Jul 2019 03:48:07 GMT"}], "update_date": "2020-02-11", "authors_parsed": [["Tang", "Zhenyu", ""], ["Kanu", "John D.", ""], ["Hogan", "Kevin", ""], ["Manocha", "Dinesh", ""]]}, {"id": "1904.08459", "submitter": "Hieu Nguyen", "authors": "Hieu Quang Nguyen, Abdul Hasib Rahimyar, Xiaodi Wang", "title": "Stock Forecasting using M-Band Wavelet-Based SVR and RNN-LSTMs Models", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "q-fin.CP cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The task of predicting future stock values has always been one that is\nheavily desired albeit very difficult. This difficulty arises from stocks with\nnon-stationary behavior, and without any explicit form. Hence, predictions are\nbest made through analysis of financial stock data. To handle big data sets,\ncurrent convention involves the use of the Moving Average. However, by\nutilizing the Wavelet Transform in place of the Moving Average to denoise stock\nsignals, financial data can be smoothened and more accurately broken down. This\nnewly transformed, denoised, and more stable stock data can be followed up by\nnon-parametric statistical methods, such as Support Vector Regression (SVR) and\nRecurrent Neural Network (RNN) based Long Short-Term Memory (LSTM) networks to\npredict future stock prices. Through the implementation of these methods, one\nis left with a more accurate stock forecast, and in turn, increased profits.\n", "versions": [{"version": "v1", "created": "Wed, 17 Apr 2019 19:10:10 GMT"}], "update_date": "2019-04-19", "authors_parsed": [["Nguyen", "Hieu Quang", ""], ["Rahimyar", "Abdul Hasib", ""], ["Wang", "Xiaodi", ""]]}, {"id": "1904.08473", "submitter": "Yao Liu", "authors": "Yao Liu, Adith Swaminathan, Alekh Agarwal, Emma Brunskill", "title": "Off-Policy Policy Gradient with State Distribution Correction", "comments": "to appear at UAI 18; camera-ready version", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the problem of off-policy policy optimization in Markov decision\nprocesses, and develop a novel off-policy policy gradient method. Prior\noff-policy policy gradient approaches have generally ignored the mismatch\nbetween the distribution of states visited under the behavior policy used to\ncollect data, and what would be the distribution of states under the learned\npolicy. Here we build on recent progress for estimating the ratio of the state\ndistributions under behavior and evaluation policies for policy evaluation, and\npresent an off-policy policy gradient optimization technique that can account\nfor this mismatch in distributions. We present an illustrative example of why\nthis is important and a theoretical convergence guarantee for our approach.\nEmpirically, we compare our method in simulations to several strong baselines\nwhich do not correct for this mismatch, significantly improving in the quality\nof the policy discovered.\n", "versions": [{"version": "v1", "created": "Wed, 17 Apr 2019 19:46:02 GMT"}, {"version": "v2", "created": "Sat, 6 Jul 2019 05:30:14 GMT"}], "update_date": "2019-07-09", "authors_parsed": [["Liu", "Yao", ""], ["Swaminathan", "Adith", ""], ["Agarwal", "Alekh", ""], ["Brunskill", "Emma", ""]]}, {"id": "1904.08477", "submitter": "Negin Musavi", "authors": "Negin Musavi", "title": "A Game Theoretical Framework for the Evaluation of Unmanned Aircraft\n  Systems Airspace Integration Concepts", "comments": "This thesis is submitted in partial fulfillment of the requirements\n  for the degree of Master of Science in Mechanical Engineering in the Graduate\n  School of Engineering and Science of Bilkent University.\n  http://repository.bilkent.edu.tr/handle/11693/33526", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Predicting the outcomes of integrating Unmanned Aerial Systems (UAS) into the\nNational Aerospace (NAS) is a complex problem which is required to be addressed\nby simulation studies before allowing the routine access of UAS into the NAS.\nThis thesis focuses on providing 2D and 3D simulation frameworks using a game\ntheoretical methodology to evaluate integration concepts in scenarios where\nmanned and unmanned air vehicles co-exist. The fundamental gap in the\nliterature is that the models of interaction between manned and unmanned\nvehicles are insufficient: a) they assume that pilot behavior is known a priori\nand b) they disregard decision making processes. The contribution of this work\nis to propose a modeling framework, in which, human pilot reactions are modeled\nusing reinforcement learning and a game theoretical concept called level-k\nreasoning to fill this gap. The level-k reasoning concept is based on the\nassumption that humans have various levels of decision making. Reinforcement\nlearning is a mathematical learning method that is rooted in human learning. In\nthis work, a classical and an approximate reinforcement learning (Neural Fitted\nQ Iteration) methods are used to model time-extended decisions of pilots with\n2D and 3D maneuvers. An analysis of UAS integration is conducted using example\nscenarios in the presence of manned aircraft and fully autonomous UAS equipped\nwith sense and avoid algorithms.\n", "versions": [{"version": "v1", "created": "Wed, 17 Apr 2019 19:58:45 GMT"}], "update_date": "2019-04-19", "authors_parsed": [["Musavi", "Negin", ""]]}, {"id": "1904.08479", "submitter": "Yaoyao Liu", "authors": "Yaoyao Liu, Bernt Schiele, Qianru Sun", "title": "An Ensemble of Epoch-wise Empirical Bayes for Few-shot Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Few-shot learning aims to train efficient predictive models with a few\nexamples. The lack of training data leads to poor models that perform\nhigh-variance or low-confidence predictions. In this paper, we propose to\nmeta-learn the ensemble of epoch-wise empirical Bayes models (E3BM) to achieve\nrobust predictions. \"Epoch-wise\" means that each training epoch has a Bayes\nmodel whose parameters are specifically learned and deployed. \"Empirical\" means\nthat the hyperparameters, e.g., used for learning and ensembling the epoch-wise\nmodels, are generated by hyperprior learners conditional on task-specific data.\nWe introduce four kinds of hyperprior learners by considering inductive vs.\ntransductive, and epoch-dependent vs. epoch-independent, in the paradigm of\nmeta-learning. We conduct extensive experiments for five-class few-shot tasks\non three challenging benchmarks: miniImageNet, tieredImageNet, and FC100, and\nachieve top performance using the epoch-dependent transductive hyperprior\nlearner, which captures the richest information. Our ablation study shows that\nboth \"epoch-wise ensemble\" and \"empirical\" encourage high efficiency and\nrobustness in the model performance.\n", "versions": [{"version": "v1", "created": "Wed, 17 Apr 2019 20:02:24 GMT"}, {"version": "v2", "created": "Thu, 12 Sep 2019 15:04:44 GMT"}, {"version": "v3", "created": "Wed, 11 Dec 2019 11:51:59 GMT"}, {"version": "v4", "created": "Mon, 23 Dec 2019 14:06:29 GMT"}, {"version": "v5", "created": "Mon, 16 Mar 2020 07:54:13 GMT"}, {"version": "v6", "created": "Fri, 17 Jul 2020 09:31:15 GMT"}], "update_date": "2020-07-20", "authors_parsed": [["Liu", "Yaoyao", ""], ["Schiele", "Bernt", ""], ["Sun", "Qianru", ""]]}, {"id": "1904.08483", "submitter": "Zhenzhou Wang", "authors": "Zhenzhou Wang", "title": "Deep learning for image segmentation: veritable or overhyped?", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep learning has achieved great success as a powerful classification tool\nand also made great progress in sematic segmentation. As a result, many\nresearchers also believe that deep learning is the most powerful tool for pixel\nlevel image segmentation. Could deep learning achieve the same pixel level\naccuracy as traditional image segmentation techniques by mapping the features\nof the object into a non-linear function? This paper gives a short survey of\nthe accuracies achieved by deep learning so far in image classification and\nimage segmentation. Compared to the high accuracies achieved by deep learning\nin classifying limited categories in international vision challenges, the image\nsegmentation accuracies achieved by deep learning in the same challenges are\nonly about eighty percent. On the contrary, the image segmentation accuracies\nachieved in international biomedical challenges are close to ninty five\npercent. Why the difference is so big? Since the accuracies of the competitors\nmethods are only evaluated based on their submitted results instead of\nreproducing the results by submitting the source codes or the software, are the\nachieved accuracies verifiable or overhyped? We are going to find it out by\nanalyzing the working principle of deep learning. Finally, we compared the\naccuracies of state of the art deep learning methods with a threshold selection\nmethod quantitatively. Experimental results showed that the threshold selection\nmethod could achieve significantly higher accuracy than deep learning methods\nin image segmentation.\n", "versions": [{"version": "v1", "created": "Tue, 16 Apr 2019 01:43:40 GMT"}, {"version": "v2", "created": "Thu, 6 Jun 2019 09:06:50 GMT"}, {"version": "v3", "created": "Thu, 23 Jul 2020 07:33:26 GMT"}], "update_date": "2020-07-24", "authors_parsed": [["Wang", "Zhenzhou", ""]]}, {"id": "1904.08484", "submitter": "Robin Yancey", "authors": "Robin Elizabeth Yancey, Norman Matloff, Paul Thompson", "title": "Multi-linear Faster RCNN with ELA for Image Tampering Detection", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.CR cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  With technological advances leading to an increase in mechanisms for image\ntampering, fraud detection methods must continue to be upgraded to match their\nsophistication. One problem with current methods is that they require prior\nknowledge of the method of forgery in order to determine which features to\nextract from the image to localize the region of interest. When a machine\nlearning algorithm is used to learn different types of tampering from a large\nset of various image types, with a large enough database we can easily classify\nwhich images are tampered (by training on the entire image feature map for each\nimage). However, we still are left with the question of which features to train\non, and how to localize the manipulation. To solve this, object detection\nnetworks such as Faster R-CNN, which combine an RPN (Region Proposal Network)\nwith a CNN, have recently been adapted to fraud detection by utilizing their\nability to propose bounding boxes for objects of interest to localize the\ntampering artifacts. By making use of the computational powers of today's GPUs\nthis method also achieves a fast run-time and higher accuracy than the top\ncurrent methods such as noise analysis, ELA (Error Level Analysis), or CFA\n(Color Filter Array). In this work, a multi-linear Faster RCNN network will be\napplied similarly but with the second stream having an input of the ELA JPEG\ncompression level mask. This is shown to provide even higher accuracy by adding\ntraining features from the segmented image map to the network.\n", "versions": [{"version": "v1", "created": "Sun, 7 Apr 2019 19:39:17 GMT"}, {"version": "v2", "created": "Thu, 20 Jun 2019 17:37:44 GMT"}], "update_date": "2019-06-21", "authors_parsed": [["Yancey", "Robin Elizabeth", ""], ["Matloff", "Norman", ""], ["Thompson", "Paul", ""]]}, {"id": "1904.08486", "submitter": "Martin Mundt", "authors": "Martin Mundt, Sagnik Majumder, Sreenivas Murali, Panagiotis Panetsos,\n  Visvanathan Ramesh", "title": "Meta-learning Convolutional Neural Architectures for Multi-target\n  Concrete Defect Classification with the COncrete DEfect BRidge IMage Dataset", "comments": "Accepted for publication at CVPR 2019. Version includes supplementary\n  material", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recognition of defects in concrete infrastructure, especially in bridges, is\na costly and time consuming crucial first step in the assessment of the\nstructural integrity. Large variation in appearance of the concrete material,\nchanging illumination and weather conditions, a variety of possible surface\nmarkings as well as the possibility for different types of defects to overlap,\nmake it a challenging real-world task. In this work we introduce the novel\nCOncrete DEfect BRidge IMage dataset (CODEBRIM) for multi-target classification\nof five commonly appearing concrete defects. We investigate and compare two\nreinforcement learning based meta-learning approaches, MetaQNN and efficient\nneural architecture search, to find suitable convolutional neural network\narchitectures for this challenging multi-class multi-target task. We show that\nlearned architectures have fewer overall parameters in addition to yielding\nbetter multi-target accuracy in comparison to popular neural architectures from\nthe literature evaluated in the context of our application.\n", "versions": [{"version": "v1", "created": "Tue, 2 Apr 2019 13:08:33 GMT"}], "update_date": "2019-04-19", "authors_parsed": [["Mundt", "Martin", ""], ["Majumder", "Sagnik", ""], ["Murali", "Sreenivas", ""], ["Panetsos", "Panagiotis", ""], ["Ramesh", "Visvanathan", ""]]}, {"id": "1904.08487", "submitter": "Zihao Liu", "authors": "Zihao Liu, Xiaowei Xu, Tao Liu, Qi Liu, Yanzhi Wang, Yiyu Shi, Wujie\n  Wen, Meiping Huang, Haiyun Yuan, Jian Zhuang", "title": "Machine Vision Guided 3D Medical Image Compression for Efficient\n  Transmission and Accurate Segmentation in the Clouds", "comments": "IEEE Computer Society Conference on Computer Vision and Pattern\n  Recognition(CVPR), Long Beach, CA, 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Cloud based medical image analysis has become popular recently due to the\nhigh computation complexities of various deep neural network (DNN) based\nframeworks and the increasingly large volume of medical images that need to be\nprocessed. It has been demonstrated that for medical images the transmission\nfrom local to clouds is much more expensive than the computation in the clouds\nitself. Towards this, 3D image compression techniques have been widely applied\nto reduce the data traffic. However, most of the existing image compression\ntechniques are developed around human vision, i.e., they are designed to\nminimize distortions that can be perceived by human eyes. In this paper we will\nuse deep learning based medical image segmentation as a vehicle and demonstrate\nthat interestingly, machine and human view the compression quality differently.\nMedical images compressed with good quality w.r.t. human vision may result in\ninferior segmentation accuracy. We then design a machine vision oriented 3D\nimage compression framework tailored for segmentation using DNNs. Our method\nautomatically extracts and retains image features that are most important to\nthe segmentation. Comprehensive experiments on widely adopted segmentation\nframeworks with HVSMR 2016 challenge dataset show that our method can achieve\nsignificantly higher segmentation accuracy at the same compression rate, or\nmuch better compression rate under the same segmentation accuracy, when\ncompared with the existing JPEG 2000 method. To the best of the authors'\nknowledge, this is the first machine vision guided medical image compression\nframework for segmentation in the clouds.\n", "versions": [{"version": "v1", "created": "Tue, 9 Apr 2019 13:34:25 GMT"}], "update_date": "2019-04-19", "authors_parsed": [["Liu", "Zihao", ""], ["Xu", "Xiaowei", ""], ["Liu", "Tao", ""], ["Liu", "Qi", ""], ["Wang", "Yanzhi", ""], ["Shi", "Yiyu", ""], ["Wen", "Wujie", ""], ["Huang", "Meiping", ""], ["Yuan", "Haiyun", ""], ["Zhuang", "Jian", ""]]}, {"id": "1904.08489", "submitter": "Ameya Joshi", "authors": "Ameya Joshi, Amitangshu Mukherjee, Soumik Sarkar, Chinmay Hegde", "title": "Semantic Adversarial Attacks: Parametric Transformations That Fool Deep\n  Classifiers", "comments": "Accepted to International Conference on Computer Vision, (ICCV) 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep neural networks have been shown to exhibit an intriguing vulnerability\nto adversarial input images corrupted with imperceptible perturbations.\nHowever, the majority of adversarial attacks assume global, fine-grained\ncontrol over the image pixel space. In this paper, we consider a different\nsetting: what happens if the adversary could only alter specific attributes of\nthe input image? These would generate inputs that might be perceptibly\ndifferent, but still natural-looking and enough to fool a classifier. We\npropose a novel approach to generate such `semantic' adversarial examples by\noptimizing a particular adversarial loss over the range-space of a parametric\nconditional generative model. We demonstrate implementations of our attacks on\nbinary classifiers trained on face images, and show that such natural-looking\nsemantic adversarial examples exist. We evaluate the effectiveness of our\nattack on synthetic and real data, and present detailed comparisons with\nexisting attack methods. We supplement our empirical results with theoretical\nbounds that demonstrate the existence of such parametric adversarial examples.\n", "versions": [{"version": "v1", "created": "Wed, 17 Apr 2019 20:39:17 GMT"}, {"version": "v2", "created": "Thu, 15 Aug 2019 19:56:17 GMT"}], "update_date": "2019-08-19", "authors_parsed": [["Joshi", "Ameya", ""], ["Mukherjee", "Amitangshu", ""], ["Sarkar", "Soumik", ""], ["Hegde", "Chinmay", ""]]}, {"id": "1904.08491", "submitter": "Shadi Albarqouni Ph.D.", "authors": "Mhd Hasan Sarhan, Abouzar Eslami, Nassir Navab, Shadi Albarqouni", "title": "Learning Interpretable Disentangled Representations using Adversarial\n  VAEs", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Learning Interpretable representation in medical applications is becoming\nessential for adopting data-driven models into clinical practice. It has been\nrecently shown that learning a disentangled feature representation is important\nfor a more compact and explainable representation of the data. In this paper,\nwe introduce a novel adversarial variational autoencoder with a total\ncorrelation constraint to enforce independence on the latent representation\nwhile preserving the reconstruction fidelity. Our proposed method is validated\non a publicly available dataset showing that the learned disentangled\nrepresentation is not only interpretable, but also superior to the\nstate-of-the-art methods. We report a relative improvement of 81.50% in terms\nof disentanglement, 11.60% in clustering, and 2% in supervised classification\nwith a few amounts of labeled data.\n", "versions": [{"version": "v1", "created": "Wed, 17 Apr 2019 20:43:51 GMT"}], "update_date": "2019-04-19", "authors_parsed": [["Sarhan", "Mhd Hasan", ""], ["Eslami", "Abouzar", ""], ["Navab", "Nassir", ""], ["Albarqouni", "Shadi", ""]]}, {"id": "1904.08495", "submitter": "Behzad Ghazanfari", "authors": "Behzad Ghazanfari, Fatemeh Afghah, Kayvan Najarian, Sajad Mousavi,\n  Jonathan Gryak, James Todd", "title": "An Unsupervised Feature Learning Approach to Reduce False Alarm Rate in\n  ICUs", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The high rate of false alarms in intensive care units (ICUs) is one of the\ntop challenges of using medical technology in hospitals. These false alarms are\noften caused by patients' movements, detachment of monitoring sensors, or\ndifferent sources of noise and interference that impact the collected signals\nfrom different monitoring devices. In this paper, we propose a novel set of\nhigh-level features based on unsupervised feature learning technique in order\nto effectively capture the characteristics of different arrhythmia in\nelectrocardiogram (ECG) signal and differentiate them from irregularity in\nsignals due to different sources of signal disturbances. This unsupervised\nfeature learning technique, first extracts a set of low-level features from all\nexisting heart cycles of a patient, and then clusters these segments for each\nindividual patient to provide a set of prominent high-level features. The\nobjective of the clustering phase is to enable the classification method to\ndifferentiate between the high-level features extracted from normal and\nabnormal cycles (i.e., either due to arrhythmia or different sources of\ndistortions in signal) in order to put more attention to the features extracted\nfrom abnormal portion of the signal that contribute to the alarm. The\nperformance of this method is evaluated using the 2015 PhysioNet/Computing in\nCardiology Challenge dataset for reducing false arrhythmia alarms in the ICUs.\nAs confirmed by the experimental results, the proposed method offers a\nconsiderable performance in terms of accuracy, sensitivity and specificity of\nalarm detection only using a few high-level features that are extracted from\none single lead ECG signal.\n", "versions": [{"version": "v1", "created": "Wed, 17 Apr 2019 20:49:29 GMT"}], "update_date": "2019-04-19", "authors_parsed": [["Ghazanfari", "Behzad", ""], ["Afghah", "Fatemeh", ""], ["Najarian", "Kayvan", ""], ["Mousavi", "Sajad", ""], ["Gryak", "Jonathan", ""], ["Todd", "James", ""]]}, {"id": "1904.08496", "submitter": "Loc Tran H", "authors": "Loc Hoang Tran, Linh Hoang Tran", "title": "Tensor Sparse PCA and Face Recognition: A Novel Approach", "comments": "It has some errors in the experimental section", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Face recognition is the important field in machine learning and pattern\nrecognition research area. It has a lot of applications in military, finance,\npublic security, to name a few. In this paper, the combination of the tensor\nsparse PCA with the nearest-neighbor method (and with the kernel ridge\nregression method) will be proposed and applied to the face dataset.\nExperimental results show that the combination of the tensor sparse PCA with\nany classification system does not always reach the best accuracy performance\nmeasures. However, the accuracy of the combination of the sparse PCA method and\none specific classification system is always better than the accuracy of the\ncombination of the PCA method and one specific classification system and is\nalways better than the accuracy of the classification system itself.\n", "versions": [{"version": "v1", "created": "Fri, 12 Apr 2019 03:43:57 GMT"}, {"version": "v2", "created": "Thu, 5 Mar 2020 08:22:03 GMT"}, {"version": "v3", "created": "Sat, 7 Mar 2020 03:14:49 GMT"}, {"version": "v4", "created": "Tue, 11 Aug 2020 08:08:48 GMT"}], "update_date": "2020-08-12", "authors_parsed": [["Tran", "Loc Hoang", ""], ["Tran", "Linh Hoang", ""]]}, {"id": "1904.08497", "submitter": "Pedro Ribeiro Mendes J\\'unior", "authors": "Pedro Ribeiro Mendes J\\'unior, Luca Bondi, Paolo Bestagini, Stefano\n  Tubaro, Anderson Rocha", "title": "An In-Depth Study on Open-Set Camera Model Identification", "comments": "Published through IEEE Access journal", "journal-ref": null, "doi": "10.1109/ACCESS.2019.2921436", "report-no": null, "categories": "cs.CV cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Camera model identification refers to the problem of linking a picture to the\ncamera model used to shoot it. As this might be an enabling factor in different\nforensic applications to single out possible suspects (e.g., detecting the\nauthor of child abuse or terrorist propaganda material), many accurate camera\nmodel attribution methods have been developed in the literature. One of their\nmain drawbacks, however, is the typical closed-set assumption of the problem.\nThis means that an investigated photograph is always assigned to one camera\nmodel within a set of known ones present during investigation, i.e., training\ntime, and the fact that the picture can come from a completely unrelated camera\nmodel during actual testing is usually ignored. Under realistic conditions, it\nis not possible to assume that every picture under analysis belongs to one of\nthe available camera models. To deal with this issue, in this paper, we present\nthe first in-depth study on the possibility of solving the camera model\nidentification problem in open-set scenarios. Given a photograph, we aim at\ndetecting whether it comes from one of the known camera models of interest or\nfrom an unknown one. We compare different feature extraction algorithms and\nclassifiers specially targeting open-set recognition. We also evaluate possible\nopen-set training protocols that can be applied along with any open-set\nclassifier, observing that a simple of those alternatives obtains best results.\nThorough testing on independent datasets shows that it is possible to leverage\na recently proposed convolutional neural network as feature extractor paired\nwith a properly trained open-set classifier aiming at solving the open-set\ncamera model attribution problem even to small-scale image patches, improving\nover state-of-the-art available solutions.\n", "versions": [{"version": "v1", "created": "Thu, 11 Apr 2019 14:48:55 GMT"}, {"version": "v2", "created": "Wed, 13 Nov 2019 19:53:21 GMT"}], "update_date": "2019-11-15", "authors_parsed": [["J\u00fanior", "Pedro Ribeiro Mendes", ""], ["Bondi", "Luca", ""], ["Bestagini", "Paolo", ""], ["Tubaro", "Stefano", ""], ["Rocha", "Anderson", ""]]}, {"id": "1904.08500", "submitter": "Jingfan Wang", "authors": "Jingfan Wang, Lyne P. Tchapmi, Arvind P. Ravikumara, Mike McGuire,\n  Clay S. Bell, Daniel Zimmerle, Silvio Savarese, Adam R. Brandt", "title": "Machine Vision for Natural Gas Methane Emissions Detection Using an\n  Infrared Camera", "comments": "This paper was submitted to Applied Energy", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG eess.IV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  It is crucial to reduce natural gas methane emissions, which can potentially\noffset the climate benefits of replacing coal with gas. Optical gas imaging\n(OGI) is a widely-used method to detect methane leaks, but is labor-intensive\nand cannot provide leak detection results without operators' judgment. In this\npaper, we develop a computer vision approach to OGI-based leak detection using\nconvolutional neural networks (CNN) trained on methane leak images to enable\nautomatic detection. First, we collect ~1 M frames of labeled video of methane\nleaks from different leaking equipment for building CNN model, covering a wide\nrange of leak sizes (5.3-2051.6 gCH4/h) and imaging distances (4.6-15.6 m).\nSecond, we examine different background subtraction methods to extract the\nmethane plume in the foreground. Third, we then test three CNN model variants,\ncollectively called GasNet, to detect plumes in videos taken at other pieces of\nleaking equipment. We assess the ability of GasNet to perform leak detection by\ncomparing it to a baseline method that uses optical-flow based change detection\nalgorithm. We explore the sensitivity of results to the CNN structure, with a\nmoderate-complexity variant performing best across distances. We find that the\ndetection accuracy can reach as high as 99%, the overall detection accuracy can\nexceed 95% for a case across all leak sizes and imaging distances. Binary\ndetection accuracy exceeds 97% for large leaks (~710 gCH4/h) imaged closely\n(~5-7 m). At closer imaging distances (~5-10 m), CNN-based models have greater\nthan 94% accuracy across all leak sizes. At farthest distances (~13-16 m),\nperformance degrades rapidly, but it can achieve above 95% accuracy to detect\nlarge leaks (>950 gCH4/h). The GasNet-based computer vision approach could be\ndeployed in OGI surveys to allow automatic vigilance of methane leak detection\nwith high detection accuracy in the real world.\n", "versions": [{"version": "v1", "created": "Mon, 1 Apr 2019 05:38:59 GMT"}], "update_date": "2019-04-19", "authors_parsed": [["Wang", "Jingfan", ""], ["Tchapmi", "Lyne P.", ""], ["Ravikumara", "Arvind P.", ""], ["McGuire", "Mike", ""], ["Bell", "Clay S.", ""], ["Zimmerle", "Daniel", ""], ["Savarese", "Silvio", ""], ["Brandt", "Adam R.", ""]]}, {"id": "1904.08502", "submitter": "Davis Wertheimer", "authors": "Davis Wertheimer and Bharath Hariharan", "title": "Few-Shot Learning with Localization in Realistic Settings", "comments": "Appearing in CVPR 2019; added references in covariance pooling\n  sections, added link to code in supplementary", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Traditional recognition methods typically require large,\nartificially-balanced training classes, while few-shot learning methods are\ntested on artificially small ones. In contrast to both extremes, real world\nrecognition problems exhibit heavy-tailed class distributions, with cluttered\nscenes and a mix of coarse and fine-grained class distinctions. We show that\nprior methods designed for few-shot learning do not work out of the box in\nthese challenging conditions, based on a new \"meta-iNat\" benchmark. We\nintroduce three parameter-free improvements: (a) better training procedures\nbased on adapting cross-validation to meta-learning, (b) novel architectures\nthat localize objects using limited bounding box annotations before\nclassification, and (c) simple parameter-free expansions of the feature space\nbased on bilinear pooling. Together, these improvements double the accuracy of\nstate-of-the-art models on meta-iNat while generalizing to prior benchmarks,\ncomplex neural architectures, and settings with substantial domain shift.\n", "versions": [{"version": "v1", "created": "Tue, 9 Apr 2019 20:20:38 GMT"}, {"version": "v2", "created": "Mon, 1 Jul 2019 18:12:02 GMT"}], "update_date": "2019-07-03", "authors_parsed": [["Wertheimer", "Davis", ""], ["Hariharan", "Bharath", ""]]}, {"id": "1904.08503", "submitter": "Assaf Arbelle", "authors": "Assaf Arbelle, Eliav Elul and Tammy Riklin Raviv", "title": "QANet -- Quality Assurance Network for Image Segmentation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce a novel Deep Learning framework, which quantitatively estimates\nimage segmentation quality without the need for human inspection or labeling.\nWe refer to this method as a Quality Assurance Network -- QANet. Specifically,\ngiven an image and a `proposed' corresponding segmentation, obtained by any\nmethod including manual annotation, the QANet solves a regression problem in\norder to estimate a predefined quality measure with respect to the unknown\nground truth. The QANet is by no means yet another segmentation method.\nInstead, it performs a multi-level, multi-feature comparison of an\nimage-segmentation pair based on a unique network architecture, called the\nRibCage.\n  To demonstrate the strength of the QANet, we addressed the evaluation of\ninstance segmentation using two different datasets from different domains,\nnamely, high throughput live cell microscopy images from the Cell Segmentation\nBenchmark and natural images of plants from the Leaf Segmentation Challenge.\nWhile synthesized segmentations were used to train the QANet, it was tested on\nsegmentations obtained by publicly available methods that participated in the\ndifferent challenges. We show that the QANet accurately estimates the scores of\nthe evaluated segmentations with respect to the hidden ground truth, as\npublished by the challenges' organizers.\n  The code is available at: TBD.\n", "versions": [{"version": "v1", "created": "Tue, 9 Apr 2019 08:38:57 GMT"}, {"version": "v2", "created": "Tue, 23 Apr 2019 12:57:36 GMT"}, {"version": "v3", "created": "Wed, 3 Jul 2019 08:39:52 GMT"}, {"version": "v4", "created": "Wed, 18 Sep 2019 08:43:24 GMT"}, {"version": "v5", "created": "Tue, 5 Nov 2019 19:09:56 GMT"}], "update_date": "2019-11-07", "authors_parsed": [["Arbelle", "Assaf", ""], ["Elul", "Eliav", ""], ["Raviv", "Tammy Riklin", ""]]}, {"id": "1904.08504", "submitter": "Takashi Matsubara", "authors": "Kenta Hama, Takashi Matsubara, Kuniaki Uehara, Jianfei Cai", "title": "Exploring Uncertainty Measures for Image-Caption Embedding-and-Retrieval\n  Task", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.CL cs.LG cs.MM stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  With the wide development of black-box machine learning algorithms,\nparticularly deep neural network (DNN), the practical demand for the\nreliability assessment is rapidly rising. On the basis of the concept that\n`Bayesian deep learning knows what it does not know,' the uncertainty of DNN\noutputs has been investigated as a reliability measure for the classification\nand regression tasks. However, in the image-caption retrieval task, well-known\nsamples are not always easy-to-retrieve samples. This study investigates two\naspects of image-caption embedding-and-retrieval systems. On one hand, we\nquantify feature uncertainty by considering image-caption embedding as a\nregression task, and use it for model averaging, which can improve the\nretrieval performance. On the other hand, we further quantify posterior\nuncertainty by considering the retrieval as a classification task, and use it\nas a reliability measure, which can greatly improve the retrieval performance\nby rejecting uncertain queries. The consistent performance of two uncertainty\nmeasures is observed with different datasets (MS COCO and Flickr30k), different\ndeep learning architectures (dropout and batch normalization), and different\nsimilarity functions.\n", "versions": [{"version": "v1", "created": "Tue, 9 Apr 2019 12:19:09 GMT"}], "update_date": "2019-04-19", "authors_parsed": [["Hama", "Kenta", ""], ["Matsubara", "Takashi", ""], ["Uehara", "Kuniaki", ""], ["Cai", "Jianfei", ""]]}, {"id": "1904.08505", "submitter": "Clebeson Santos Msc", "authors": "Clebeson Canuto dos Santos, Jorge Leonid Aching Samatelo, Raquel\n  Frizera Vassallo", "title": "Dynamic Gesture Recognition by Using CNNs and Star RGB: a Temporal\n  Information Condensation", "comments": "19 pages, 12 figures, submitted to Neurocomputing Journal", "journal-ref": null, "doi": "10.1016/j.neucom.2020.03.038", "report-no": null, "categories": "cs.CV cs.HC cs.LG cs.RO", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Due to the advance of technologies, machines are increasingly present in\npeople's daily lives. Thus, there has been more and more effort to develop\ninterfaces, such as dynamic gestures, that provide an intuitive way of\ninteraction. Currently, the most common trend is to use multimodal data, as\ndepth and skeleton information, to enable dynamic gesture recognition. However,\nusing only color information would be more interesting, since RGB cameras are\nusually available in almost every public place, and could be used for gesture\nrecognition without the need of installing other equipment. The main problem\nwith such approach is the difficulty of representing spatio-temporal\ninformation using just color. With this in mind, we propose a technique capable\nof condensing a dynamic gesture, shown in a video, in just one RGB image. We\ncall this technique star RGB. This image is then passed to a classifier formed\nby two Resnet CNNs, a soft-attention ensemble, and a fully connected layer,\nwhich indicates the class of the gesture present in the input video.\nExperiments were carried out using both Montalbano and GRIT datasets. For\nMontalbano dataset, the proposed approach achieved an accuracy of 94.58%. Such\nresult reaches the state-of-the-art when considering this dataset and only\ncolor information. Regarding the GRIT dataset, our proposal achieves more than\n98% of accuracy, recall, precision, and F1-score, outperforming the reference\napproach by more than 6%.\n", "versions": [{"version": "v1", "created": "Wed, 10 Apr 2019 00:39:32 GMT"}, {"version": "v2", "created": "Sun, 8 Sep 2019 15:57:22 GMT"}], "update_date": "2020-06-19", "authors_parsed": [["Santos", "Clebeson Canuto dos", ""], ["Samatelo", "Jorge Leonid Aching", ""], ["Vassallo", "Raquel Frizera", ""]]}, {"id": "1904.08514", "submitter": "Rui Qiao", "authors": "Rui Qiao, Ngoc Hieu Tran, Lei Xin, Baozhen Shan, Ming Li, Ali Ghodsi", "title": "DeepNovoV2: Better de novo peptide sequencing with deep learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG q-bio.BM stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Personalized cancer vaccines are envisioned as the next generation rational\ncancer immunotherapy. The key step in developing personalized therapeutic\ncancer vaccines is to identify tumor-specific neoantigens that are on the\nsurface of tumor cells. A promising method for this is through de novo peptide\nsequencing from mass spectrometry data. In this paper we introduce DeepNovoV2,\nthe state-of-the-art model for peptide sequencing. In DeepNovoV2, a spectrum is\ndirectly represented as a set of (m/z, intensity) pairs, therefore it does not\nsuffer from the accuracy-speed/memory trade-off problem. The model combines an\norder invariant network structure (T-Net) and recurrent neural networks and\nprovides a complete end-to-end training and prediction framework to sequence\npatterns of peptides. Our experiments on a wide variety of data from different\nspecies show that DeepNovoV2 outperforms previous state-of-the-art methods,\nachieving 13.01-23.95\\% higher accuracy at the peptide level.\n", "versions": [{"version": "v1", "created": "Wed, 17 Apr 2019 21:50:03 GMT"}, {"version": "v2", "created": "Wed, 22 May 2019 15:49:15 GMT"}], "update_date": "2019-05-23", "authors_parsed": [["Qiao", "Rui", ""], ["Tran", "Ngoc Hieu", ""], ["Xin", "Lei", ""], ["Shan", "Baozhen", ""], ["Li", "Ming", ""], ["Ghodsi", "Ali", ""]]}, {"id": "1904.08516", "submitter": "Guanxiong Liu", "authors": "Guanxiong Liu, Issa Khalil, Abdallah Khreishah", "title": "ZK-GanDef: A GAN based Zero Knowledge Adversarial Training Defense for\n  Neural Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Neural Network classifiers have been used successfully in a wide range of\napplications. However, their underlying assumption of attack free environment\nhas been defied by adversarial examples. Researchers tried to develop defenses;\nhowever, existing approaches are still far from providing effective solutions\nto this evolving problem. In this paper, we design a generative adversarial net\n(GAN) based zero knowledge adversarial training defense, dubbed ZK-GanDef,\nwhich does not consume adversarial examples during training. Therefore,\nZK-GanDef is not only efficient in training but also adaptive to new\nadversarial examples. This advantage comes at the cost of small degradation in\ntest accuracy compared to full knowledge approaches. Our experiments show that\nZK-GanDef enhances test accuracy on adversarial examples by up-to 49.17%\ncompared to zero knowledge approaches. More importantly, its test accuracy is\nclose to that of the state-of-the-art full knowledge approaches (maximum\ndegradation of 8.46%), while taking much less training time.\n", "versions": [{"version": "v1", "created": "Wed, 17 Apr 2019 21:52:20 GMT"}], "update_date": "2019-04-19", "authors_parsed": [["Liu", "Guanxiong", ""], ["Khalil", "Issa", ""], ["Khreishah", "Abdallah", ""]]}, {"id": "1904.08528", "submitter": "Reazul Hasan Russel", "authors": "Reazul H. Russel and Tianyi Gu and Marek Petrik", "title": "Robust Exploration with Tight Bayesian Plausibility Sets", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Optimism about the poorly understood states and actions is the main driving\nforce of exploration for many provably-efficient reinforcement learning\nalgorithms. We propose optimism in the face of sensible value functions (OFVF)-\na novel data-driven Bayesian algorithm to constructing Plausibility sets for\nMDPs to explore robustly minimizing the worst case exploration cost. The method\ncomputes policies with tighter optimistic estimates for exploration by\nintroducing two new ideas. First, it is based on Bayesian posterior\ndistributions rather than distribution-free bounds. Second, OFVF does not\nconstruct plausibility sets as simple confidence intervals. Confidence\nintervals as plausibility sets are a sufficient but not a necessary condition.\nOFVF uses the structure of the value function to optimize the location and\nshape of the plausibility set to guarantee upper bounds directly without\nnecessarily enforcing the requirement for the set to be a confidence interval.\nOFVF proceeds in an episodic manner, where the duration of the episode is fixed\nand known. Our algorithm is inherently Bayesian and can leverage prior\ninformation. Our theoretical analysis shows the robustness of OFVF, and the\nempirical results demonstrate its practical promise.\n", "versions": [{"version": "v1", "created": "Wed, 17 Apr 2019 22:54:50 GMT"}], "update_date": "2019-04-19", "authors_parsed": [["Russel", "Reazul H.", ""], ["Gu", "Tianyi", ""], ["Petrik", "Marek", ""]]}, {"id": "1904.08534", "submitter": "Joseph Paul Cohen", "authors": "Hadrien Bertrand, Mohammad Hashir and Joseph Paul Cohen", "title": "Do Lateral Views Help Automated Chest X-ray Predictions?", "comments": "3 pages and 1 figure. Under review as extended abstract at MIDL 2019\n  [arXiv:1907.08612]", "journal-ref": null, "doi": null, "report-no": "MIDL/2019/ExtendedAbstract/ryeLXFe494", "categories": "cs.CV cs.LG eess.IV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Most convolutional neural networks in chest radiology use only the frontal\nposteroanterior (PA) view to make a prediction. However the lateral view is\nknown to help the diagnosis of certain diseases and conditions. The recently\nreleased PadChest dataset contains paired PA and lateral views, allowing us to\nstudy for which diseases and conditions the performance of a neural network\nimproves when provided a lateral x-ray view as opposed to a frontal\nposteroanterior (PA) view. Using a simple DenseNet model, we find that using\nthe lateral view increases the AUC of 8 of the 56 labels in our data and\nachieves the same performance as the PA view for 21 of the labels. We find that\nusing the PA and lateral views jointly doesn't trivially lead to an increase in\nperformance but suggest further investigation.\n", "versions": [{"version": "v1", "created": "Wed, 17 Apr 2019 23:26:21 GMT"}, {"version": "v2", "created": "Thu, 25 Jul 2019 12:56:18 GMT"}], "update_date": "2019-07-27", "authors_parsed": [["Bertrand", "Hadrien", ""], ["Hashir", "Mohammad", ""], ["Cohen", "Joseph Paul", ""]]}, {"id": "1904.08540", "submitter": "Christian Parkinson", "authors": "Christian Parkinson, Kevin Huynh, Deanna Needell", "title": "Matrix Completion With Selective Sampling", "comments": "4 pages, 4 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Matrix completion is a classical problem in data science wherein one attempts\nto reconstruct a low-rank matrix while only observing some subset of the\nentries. Previous authors have phrased this problem as a nuclear norm\nminimization problem. Almost all previous work assumes no explicit structure of\nthe matrix and uses uniform sampling to decide the observed entries. We suggest\nmethods for selective sampling in the case where we have some knowledge about\nthe structure of the matrix and are allowed to design the observation set.\n", "versions": [{"version": "v1", "created": "Wed, 17 Apr 2019 23:57:19 GMT"}], "update_date": "2019-04-19", "authors_parsed": [["Parkinson", "Christian", ""], ["Huynh", "Kevin", ""], ["Needell", "Deanna", ""]]}, {"id": "1904.08544", "submitter": "Vatsal Sharan", "authors": "Vatsal Sharan, Aaron Sidford, Gregory Valiant", "title": "Memory-Sample Tradeoffs for Linear Regression with Small Error", "comments": "A few minor edits over previous version", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the problem of performing linear regression over a stream of\n$d$-dimensional examples, and show that any algorithm that uses a subquadratic\namount of memory exhibits a slower rate of convergence than can be achieved\nwithout memory constraints. Specifically, consider a sequence of labeled\nexamples $(a_1,b_1), (a_2,b_2)\\ldots,$ with $a_i$ drawn independently from a\n$d$-dimensional isotropic Gaussian, and where $b_i = \\langle a_i, x\\rangle +\n\\eta_i,$ for a fixed $x \\in \\mathbb{R}^d$ with $\\|x\\|_2 = 1$ and with\nindependent noise $\\eta_i$ drawn uniformly from the interval\n$[-2^{-d/5},2^{-d/5}].$ We show that any algorithm with at most $d^2/4$ bits of\nmemory requires at least $\\Omega(d \\log \\log \\frac{1}{\\epsilon})$ samples to\napproximate $x$ to $\\ell_2$ error $\\epsilon$ with probability of success at\nleast $2/3$, for $\\epsilon$ sufficiently small as a function of $d$. In\ncontrast, for such $\\epsilon$, $x$ can be recovered to error $\\epsilon$ with\nprobability $1-o(1)$ with memory $O\\left(d^2 \\log(1/\\epsilon)\\right)$ using $d$\nexamples. This represents the first nontrivial lower bounds for regression with\nsuper-linear memory, and may open the door for strong memory/sample tradeoffs\nfor continuous optimization.\n", "versions": [{"version": "v1", "created": "Thu, 18 Apr 2019 00:24:17 GMT"}, {"version": "v2", "created": "Sat, 10 Oct 2020 04:20:20 GMT"}], "update_date": "2020-10-13", "authors_parsed": [["Sharan", "Vatsal", ""], ["Sidford", "Aaron", ""], ["Valiant", "Gregory", ""]]}, {"id": "1904.08547", "submitter": "Qiaoyu Tan", "authors": "Qiaoyu Tan, Ninghao Liu, Xia Hu", "title": "Deep Representation Learning for Social Network Analysis", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SI cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Social network analysis is an important problem in data mining. A fundamental\nstep for analyzing social networks is to encode network data into\nlow-dimensional representations, i.e., network embeddings, so that the network\ntopology structure and other attribute information can be effectively\npreserved. Network representation leaning facilitates further applications such\nas classification, link prediction, anomaly detection and clustering. In\naddition, techniques based on deep neural networks have attracted great\ninterests over the past a few years. In this survey, we conduct a comprehensive\nreview of current literature in network representation learning utilizing\nneural network models. First, we introduce the basic models for learning node\nrepresentations in homogeneous networks. Meanwhile, we will also introduce some\nextensions of the base models in tackling more complex scenarios, such as\nanalyzing attributed networks, heterogeneous networks and dynamic networks.\nThen, we introduce the techniques for embedding subgraphs. After that, we\npresent the applications of network representation learning. At the end, we\ndiscuss some promising research directions for future work.\n", "versions": [{"version": "v1", "created": "Thu, 18 Apr 2019 00:42:11 GMT"}], "update_date": "2019-04-19", "authors_parsed": [["Tan", "Qiaoyu", ""], ["Liu", "Ninghao", ""], ["Hu", "Xia", ""]]}, {"id": "1904.08548", "submitter": "Michael Minyi Zhang", "authors": "Sinead A. Williamson, Michael Minyi Zhang, Paul Damien", "title": "A New Class of Time Dependent Latent Factor Models with Applications", "comments": null, "journal-ref": "Journal of Machine Learning Research 21(27):1-24, 2020", "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In many applications, observed data are influenced by some combination of\nlatent causes. For example, suppose sensors are placed inside a building to\nrecord responses such as temperature, humidity, power consumption and noise\nlevels. These random, observed responses are typically affected by many\nunobserved, latent factors (or features) within the building such as the number\nof individuals, the turning on and off of electrical devices, power surges,\netc. These latent factors are usually present for a contiguous period of time\nbefore disappearing; further, multiple factors could be present at a time. This\npaper develops new probabilistic methodology and inference methods for random\nobject generation influenced by latent features exhibiting temporal\npersistence. Every datum is associated with subsets of a potentially infinite\nnumber of hidden, persistent features that account for temporal dynamics in an\nobservation. The ensuing class of dynamic models constructed by adapting the\nIndian Buffet Process --- a probability measure on the space of random,\nunbounded binary matrices --- finds use in a variety of applications arising in\noperations, signal processing, biomedicine, marketing, image analysis, etc.\nIllustrations using synthetic and real data are provided.\n", "versions": [{"version": "v1", "created": "Thu, 18 Apr 2019 00:43:00 GMT"}], "update_date": "2020-07-16", "authors_parsed": [["Williamson", "Sinead A.", ""], ["Zhang", "Michael Minyi", ""], ["Damien", "Paul", ""]]}, {"id": "1904.08554", "submitter": "Shawn Shan", "authors": "Shawn Shan, Emily Wenger, Bolun Wang, Bo Li, Haitao Zheng, Ben Y. Zhao", "title": "Gotta Catch 'Em All: Using Honeypots to Catch Adversarial Attacks on\n  Neural Networks", "comments": null, "journal-ref": "Proceedings of the 2020 ACM SIGSAC Conference on Computer and\n  Communications Security", "doi": "10.1145/3372297.3417231", "report-no": null, "categories": "cs.LG cs.CR stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Deep neural networks (DNN) are known to be vulnerable to adversarial attacks.\nNumerous efforts either try to patch weaknesses in trained models, or try to\nmake it difficult or costly to compute adversarial examples that exploit them.\nIn our work, we explore a new \"honeypot\" approach to protect DNN models. We\nintentionally inject trapdoors, honeypot weaknesses in the classification\nmanifold that attract attackers searching for adversarial examples. Attackers'\noptimization algorithms gravitate towards trapdoors, leading them to produce\nattacks similar to trapdoors in the feature space. Our defense then identifies\nattacks by comparing neuron activation signatures of inputs to those of\ntrapdoors. In this paper, we introduce trapdoors and describe an implementation\nof a trapdoor-enabled defense. First, we analytically prove that trapdoors\nshape the computation of adversarial attacks so that attack inputs will have\nfeature representations very similar to those of trapdoors. Second, we\nexperimentally show that trapdoor-protected models can detect, with high\naccuracy, adversarial examples generated by state-of-the-art attacks (PGD,\noptimization-based CW, Elastic Net, BPDA), with negligible impact on normal\nclassification. These results generalize across classification domains,\nincluding image, facial, and traffic-sign recognition. We also present\nsignificant results measuring trapdoors' robustness against customized adaptive\nattacks (countermeasures).\n", "versions": [{"version": "v1", "created": "Thu, 18 Apr 2019 01:17:23 GMT"}, {"version": "v2", "created": "Mon, 9 Sep 2019 17:31:04 GMT"}, {"version": "v3", "created": "Mon, 4 Nov 2019 01:38:59 GMT"}, {"version": "v4", "created": "Sat, 22 Feb 2020 17:42:21 GMT"}, {"version": "v5", "created": "Wed, 25 Mar 2020 14:43:21 GMT"}, {"version": "v6", "created": "Mon, 28 Sep 2020 04:32:23 GMT"}], "update_date": "2020-12-01", "authors_parsed": [["Shan", "Shawn", ""], ["Wenger", "Emily", ""], ["Wang", "Bolun", ""], ["Li", "Bo", ""], ["Zheng", "Haitao", ""], ["Zhao", "Ben Y.", ""]]}, {"id": "1904.08558", "submitter": "Ying Wang", "authors": "Ying Wang, Xiao Xu, Tao Jin, Xiang Li, Guotong Xie, Jianmin Wang", "title": "Inpatient2Vec: Medical Representation Learning for Inpatients", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Representation learning (RL) plays an important role in extracting proper\nrepresentations from complex medical data for various analyzing tasks, such as\npatient grouping, clinical endpoint prediction and medication recommendation.\nMedical data can be divided into two typical categories, outpatient and\ninpatient, that have different data characteristics. However, few of existing\nRL methods are specially designed for inpatients data, which have strong\ntemporal relations and consistent diagnosis. In addition, for unordered medical\nactivity set, existing medical RL methods utilize a simple pooling strategy,\nwhich would result in indistinguishable contributions among the activities for\nlearning. In this work, weproposeInpatient2Vec, anovelmodel for learning three\nkinds of representations for inpatient, including medical activity, hospital\nday and diagnosis. A multi-layer self-attention mechanism with two training\ntasks is designed to capture the inpatient data characteristics and process the\nunordered set. Using a real-world dataset, we demonstrate that the proposed\napproach outperforms the competitive baselines on semantic similarity\nmeasurement and clinical events prediction tasks.\n", "versions": [{"version": "v1", "created": "Thu, 18 Apr 2019 01:32:24 GMT"}, {"version": "v2", "created": "Mon, 14 Oct 2019 07:14:53 GMT"}], "update_date": "2019-10-15", "authors_parsed": [["Wang", "Ying", ""], ["Xu", "Xiao", ""], ["Jin", "Tao", ""], ["Li", "Xiang", ""], ["Xie", "Guotong", ""], ["Wang", "Jianmin", ""]]}, {"id": "1904.08559", "submitter": "Vishnu Raj", "authors": "Vishnu Raj, Sheetal Kalyani", "title": "Design of Communication Systems using Deep Learning: A Variational\n  Inference Perspective", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IT cs.LG math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent research in the design of end to end communication system using deep\nlearning has produced models which can outperform traditional communication\nschemes. Most of these architectures leveraged autoencoders to design the\nencoder at the transmitter and decoder at the receiver and train them jointly\nby modeling transmit symbols as latent codes from the encoder. However, in\ncommunication systems, the receiver has to work with noise corrupted versions\nof transmit symbols. Traditional autoencoders are not designed to work with\nlatent codes corrupted with noise. In this work, we provide a framework to\ndesign end to end communication systems which accounts for the existence of\nnoise corrupted transmit symbols. The proposed method uses deep neural\narchitecture. An objective function for optimizing these models is derived\nbased on the concepts of variational inference. Further, domain knowledge such\nas channel type can be systematically integrated into the objective. Through\nnumerical simulation, the proposed method is shown to consistently produce\nmodels with better packing density and achieving it faster in multiple popular\nchannel models as compared to the previous works leveraging deep learning\nmodels.\n", "versions": [{"version": "v1", "created": "Thu, 18 Apr 2019 01:41:13 GMT"}, {"version": "v2", "created": "Fri, 2 Aug 2019 01:22:10 GMT"}, {"version": "v3", "created": "Sat, 25 Jan 2020 01:43:10 GMT"}], "update_date": "2020-01-28", "authors_parsed": [["Raj", "Vishnu", ""], ["Kalyani", "Sheetal", ""]]}, {"id": "1904.08575", "submitter": "Mihai Cucuringu", "authors": "Mihai Cucuringu, Peter Davies, Aldo Glielmo, and Hemant Tyagi", "title": "SPONGE: A generalized eigenproblem for clustering signed networks", "comments": "33 pages, 18 figures", "journal-ref": "AISTATS 2019", "doi": null, "report-no": null, "categories": "stat.ML cs.LG math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce a principled and theoretically sound spectral method for $k$-way\nclustering in signed graphs, where the affinity measure between nodes takes\neither positive or negative values. Our approach is motivated by social balance\ntheory, where the task of clustering aims to decompose the network into\ndisjoint groups, such that individuals within the same group are connected by\nas many positive edges as possible, while individuals from different groups are\nconnected by as many negative edges as possible. Our algorithm relies on a\ngeneralized eigenproblem formulation inspired by recent work on constrained\nclustering. We provide theoretical guarantees for our approach in the setting\nof a signed stochastic block model, by leveraging tools from matrix\nperturbation theory and random matrix theory. An extensive set of numerical\nexperiments on both synthetic and real data shows that our approach compares\nfavorably with state-of-the-art methods for signed clustering, especially for\nlarge number of clusters and sparse measurement graphs.\n", "versions": [{"version": "v1", "created": "Thu, 18 Apr 2019 02:55:22 GMT"}, {"version": "v2", "created": "Sun, 19 May 2019 12:22:00 GMT"}], "update_date": "2019-05-21", "authors_parsed": [["Cucuringu", "Mihai", ""], ["Davies", "Peter", ""], ["Glielmo", "Aldo", ""], ["Tyagi", "Hemant", ""]]}, {"id": "1904.08576", "submitter": "Mohsen Bayati", "authors": "Nima Hamidi and Mohsen Bayati", "title": "On Low-rank Trace Regression under General Sampling Distribution", "comments": "32 pages, 1 figure", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.IT math.IT stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A growing number of modern statistical learning problems involve estimating a\nlarge number of parameters from a (smaller) number of noisy observations. In a\nsubset of these problems (matrix completion, matrix compressed sensing, and\nmulti-task learning) the unknown parameters form a high-dimensional matrix B*,\nand two popular approaches for the estimation are convex relaxation of\nrank-penalized regression or non-convex optimization. It is also known that\nthese estimators satisfy near optimal error bounds under assumptions on rank,\ncoherence, or spikiness of the unknown matrix.\n  In this paper, we introduce a unifying technique for analyzing all of these\nproblems via both estimators that leads to short proofs for the existing\nresults as well as new results. Specifically, first we introduce a general\nnotion of spikiness for B* and consider a general family of estimators and\nprove non-asymptotic error bounds for the their estimation error. Our approach\nrelies on a generic recipe to prove restricted strong convexity for the\nsampling operator of the trace regression. Second, and most notably, we prove\nsimilar error bounds when the regularization parameter is chosen via K-fold\ncross-validation. This result is significant in that existing theory on\ncross-validated estimators do not apply to our setting since our estimators are\nnot known to satisfy their required notion of stability. Third, we study\napplications of our general results to four subproblems of (1) matrix\ncompletion, (2) multi-task learning, (3) compressed sensing with Gaussian\nensembles, and (4) compressed sensing with factored measurements. For (1), (3),\nand (4) we recover matching error bounds as those found in the literature, and\nfor (2) we obtain (to the best of our knowledge) the first such error bound. We\nalso demonstrate how our frameworks applies to the exact recovery problem in\n(3) and (4).\n", "versions": [{"version": "v1", "created": "Thu, 18 Apr 2019 02:56:00 GMT"}, {"version": "v2", "created": "Thu, 29 Aug 2019 04:28:00 GMT"}], "update_date": "2019-08-30", "authors_parsed": [["Hamidi", "Nima", ""], ["Bayati", "Mohsen", ""]]}, {"id": "1904.08582", "submitter": "Rui Fan", "authors": "Rui Fan, Mohammud Junaid Bocus, Yilong Zhu, Jianhao Jiao, Li Wang,\n  Fulong Ma, Shanshan Cheng, Ming Liu", "title": "Road Crack Detection Using Deep Convolutional Neural Network and\n  Adaptive Thresholding", "comments": "6 pages, 8 figures, 2019 IEEE Intelligent Vehicles Symposium", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG eess.IV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Crack is one of the most common road distresses which may pose road safety\nhazards. Generally, crack detection is performed by either certified inspectors\nor structural engineers. This task is, however, time-consuming, subjective and\nlabor-intensive. In this paper, we propose a novel road crack detection\nalgorithm based on deep learning and adaptive image segmentation. Firstly, a\ndeep convolutional neural network is trained to determine whether an image\ncontains cracks or not. The images containing cracks are then smoothed using\nbilateral filtering, which greatly minimizes the number of noisy pixels.\nFinally, we utilize an adaptive thresholding method to extract the cracks from\nroad surface. The experimental results illustrate that our network can classify\nimages with an accuracy of 99.92%, and the cracks can be successfully extracted\nfrom the images using our proposed thresholding algorithm.\n", "versions": [{"version": "v1", "created": "Thu, 18 Apr 2019 03:38:52 GMT"}], "update_date": "2019-04-19", "authors_parsed": [["Fan", "Rui", ""], ["Bocus", "Mohammud Junaid", ""], ["Zhu", "Yilong", ""], ["Jiao", "Jianhao", ""], ["Wang", "Li", ""], ["Ma", "Fulong", ""], ["Cheng", "Shanshan", ""], ["Liu", "Ming", ""]]}, {"id": "1904.08594", "submitter": "Sriram Ravula", "authors": "Sriram Ravula, Alexandros G. Dimakis", "title": "One-dimensional Deep Image Prior for Time Series Inverse Problems", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We extend the Deep Image Prior (DIP) framework to one-dimensional signals.\nDIP is using a randomly initialized convolutional neural network (CNN) to solve\nlinear inverse problems by optimizing over weights to fit the observed\nmeasurements. Our main finding is that properly tuned one-dimensional\nconvolutional architectures provide an excellent Deep Image Prior for various\ntypes of temporal signals including audio, biological signals, and sensor\nmeasurements. We show that our network can be used in a variety of recovery\ntasks including missing value imputation, blind denoising, and compressed\nsensing from random Gaussian projections. The key challenge is how to avoid\noverfitting by carefully tuning early stopping, total variation, and weight\ndecay regularization. Our method requires up to 4 times fewer measurements than\nLasso and outperforms NLM-VAMP for random Gaussian measurements on audio\nsignals, has similar imputation performance to a Kalman state-space model on a\nvariety of data, and outperforms wavelet filtering in removing additive noise\nfrom air-quality sensor readings.\n", "versions": [{"version": "v1", "created": "Thu, 18 Apr 2019 05:29:54 GMT"}], "update_date": "2019-04-19", "authors_parsed": [["Ravula", "Sriram", ""], ["Dimakis", "Alexandros G.", ""]]}, {"id": "1904.08598", "submitter": "Tatjana Chavdarova", "authors": "Tatjana Chavdarova, Gauthier Gidel, Fran\\c{c}ois Fleuret and Simon\n  Lacoste-Julien", "title": "Reducing Noise in GAN Training with Variance Reduced Extragradient", "comments": "latest NeurIPS'19 version", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG math.OC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the effect of the stochastic gradient noise on the training of\ngenerative adversarial networks (GANs) and show that it can prevent the\nconvergence of standard game optimization methods, while the batch version\nconverges. We address this issue with a novel stochastic variance-reduced\nextragradient (SVRE) optimization algorithm, which for a large class of games\nimproves upon the previous convergence rates proposed in the literature. We\nobserve empirically that SVRE performs similarly to a batch method on MNIST\nwhile being computationally cheaper, and that SVRE yields more stable GAN\ntraining on standard datasets.\n", "versions": [{"version": "v1", "created": "Thu, 18 Apr 2019 06:02:24 GMT"}, {"version": "v2", "created": "Wed, 12 Jun 2019 21:37:18 GMT"}, {"version": "v3", "created": "Thu, 25 Jun 2020 18:40:55 GMT"}], "update_date": "2020-06-29", "authors_parsed": [["Chavdarova", "Tatjana", ""], ["Gidel", "Gauthier", ""], ["Fleuret", "Fran\u00e7ois", ""], ["Lacoste-Julien", "Simon", ""]]}, {"id": "1904.08613", "submitter": "Kazi Nazmul Haque", "authors": "Kazi Nazmul Haque, Siddique Latif, and Rajib Rana", "title": "Disentangled Representation Learning with Information Maximizing\n  Autoencoder", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Learning disentangled representation from any unlabelled data is a\nnon-trivial problem. In this paper we propose Information Maximising\nAutoencoder (InfoAE) where the encoder learns powerful disentangled\nrepresentation through maximizing the mutual information between the\nrepresentation and given information in an unsupervised fashion. We have\nevaluated our model on MNIST dataset and achieved 98.9 ($\\pm .1$) $\\%$ test\naccuracy while using complete unsupervised training.\n", "versions": [{"version": "v1", "created": "Thu, 18 Apr 2019 07:25:19 GMT"}], "update_date": "2019-04-19", "authors_parsed": [["Haque", "Kazi Nazmul", ""], ["Latif", "Siddique", ""], ["Rana", "Rajib", ""]]}, {"id": "1904.08621", "submitter": "Guangliang Li", "authors": "Guangliang Li, Randy Gomez, Keisuke Nakamura, Jinying Lin, Qilei\n  Zhang, Bo He", "title": "Improving Interactive Reinforcement Agent Planning with Human\n  Demonstration", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.HC cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  TAMER has proven to be a powerful interactive reinforcement learning method\nfor allowing ordinary people to teach and personalize autonomous agents'\nbehavior by providing evaluative feedback. However, a TAMER agent planning with\nUCT---a Monte Carlo Tree Search strategy, can only update states along its path\nand might induce high learning cost especially for a physical robot. In this\npaper, we propose to drive the agent's exploration along the optimal path and\nreduce the learning cost by initializing the agent's reward function via\ninverse reinforcement learning from demonstration. We test our proposed method\nin the RL benchmark domain---Grid World---with different discounts on human\nreward. Our results show that learning from demonstration can allow a TAMER\nagent to learn a roughly optimal policy up to the deepest search and encourage\nthe agent to explore along the optimal path. In addition, we find that learning\nfrom demonstration can improve the learning efficiency by reducing total\nfeedback, the number of incorrect actions and increasing the ratio of correct\nactions to obtain an optimal policy, allowing a TAMER agent to converge faster.\n", "versions": [{"version": "v1", "created": "Thu, 18 Apr 2019 07:45:36 GMT"}], "update_date": "2019-04-19", "authors_parsed": [["Li", "Guangliang", ""], ["Gomez", "Randy", ""], ["Nakamura", "Keisuke", ""], ["Lin", "Jinying", ""], ["Zhang", "Qilei", ""], ["He", "Bo", ""]]}, {"id": "1904.08623", "submitter": "Xie De", "authors": "Xianglong Liu, Lei Huang, Cheng Deng, Bo Lang, Dacheng Tao", "title": "Query-Adaptive Hash Code Ranking for Large-Scale Multi-View Visual\n  Search", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Hash based nearest neighbor search has become attractive in many\napplications. However, the quantization in hashing usually degenerates the\ndiscriminative power when using Hamming distance ranking. Besides, for\nlarge-scale visual search, existing hashing methods cannot directly support the\nefficient search over the data with multiple sources, and while the literature\nhas shown that adaptively incorporating complementary information from diverse\nsources or views can significantly boost the search performance. To address the\nproblems, this paper proposes a novel and generic approach to building multiple\nhash tables with multiple views and generating fine-grained ranking results at\nbitwise and tablewise levels. For each hash table, a query-adaptive bitwise\nweighting is introduced to alleviate the quantization loss by simultaneously\nexploiting the quality of hash functions and their complement for nearest\nneighbor search. From the tablewise aspect, multiple hash tables are built for\ndifferent data views as a joint index, over which a query-specific rank fusion\nis proposed to rerank all results from the bitwise ranking by diffusing in a\ngraph. Comprehensive experiments on image search over three well-known\nbenchmarks show that the proposed method achieves up to 17.11% and 20.28%\nperformance gains on single and multiple table search over state-of-the-art\nmethods.\n", "versions": [{"version": "v1", "created": "Thu, 18 Apr 2019 07:49:26 GMT"}], "update_date": "2019-04-19", "authors_parsed": [["Liu", "Xianglong", ""], ["Huang", "Lei", ""], ["Deng", "Cheng", ""], ["Lang", "Bo", ""], ["Tao", "Dacheng", ""]]}, {"id": "1904.08658", "submitter": "Danilo Vasconcellos  Vargas", "authors": "Vinicius V. Melo, Danilo Vasconcellos Vargas, Wolfgang Banzhaf", "title": "Batch Tournament Selection for Genetic Programming", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Lexicase selection achieves very good solution quality by introducing ordered\ntest cases. However, the computational complexity of lexicase selection can\nprohibit its use in many applications. In this paper, we introduce Batch\nTournament Selection (BTS), a hybrid of tournament and lexicase selection which\nis approximately one order of magnitude faster than lexicase selection while\nachieving a competitive quality of solutions. Tests on a number of regression\ndatasets show that BTS compares well with lexicase selection in terms of mean\nabsolute error while having a speed-up of up to 25 times. Surprisingly, BTS and\nlexicase selection have almost no difference in both diversity and performance.\nThis reveals that batches and ordered test cases are completely different\nmechanisms which share the same general principle fostering the specialization\nof individuals. This work introduces an efficient algorithm that sheds light\nonto the main principles behind the success of lexicase, potentially opening up\na new range of possibilities for algorithms to come.\n", "versions": [{"version": "v1", "created": "Thu, 18 Apr 2019 09:53:20 GMT"}], "update_date": "2019-04-19", "authors_parsed": [["Melo", "Vinicius V.", ""], ["Vargas", "Danilo Vasconcellos", ""], ["Banzhaf", "Wolfgang", ""]]}, {"id": "1904.08693", "submitter": "Niki Kilbertus", "authors": "Timothy D. Gebhard, Niki Kilbertus, Ian Harry, Bernhard Sch\\\"olkopf", "title": "Convolutional neural networks: a magic bullet for gravitational-wave\n  detection?", "comments": "First two authors contributed equally; appeared at Phys. Rev. D", "journal-ref": "Phys. Rev. D 100, 063015 (2019)", "doi": "10.1103/PhysRevD.100.063015", "report-no": null, "categories": "astro-ph.IM astro-ph.HE cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In the last few years, machine learning techniques, in particular\nconvolutional neural networks, have been investigated as a method to replace or\ncomplement traditional matched filtering techniques that are used to detect the\ngravitational-wave signature of merging black holes. However, to date, these\nmethods have not yet been successfully applied to the analysis of long\nstretches of data recorded by the Advanced LIGO and Virgo gravitational-wave\nobservatories. In this work, we critically examine the use of convolutional\nneural networks as a tool to search for merging black holes. We identify the\nstrengths and limitations of this approach, highlight some common pitfalls in\ntranslating between machine learning and gravitational-wave astronomy, and\ndiscuss the interdisciplinary challenges. In particular, we explain in detail\nwhy convolutional neural networks alone cannot be used to claim a statistically\nsignificant gravitational-wave detection. However, we demonstrate how they can\nstill be used to rapidly flag the times of potential signals in the data for a\nmore detailed follow-up. Our convolutional neural network architecture as well\nas the proposed performance metrics are better suited for this task than a\nstandard binary classifications scheme. A detailed evaluation of our approach\non Advanced LIGO data demonstrates the potential of such systems as trigger\ngenerators. Finally, we sound a note of caution by constructing adversarial\nexamples, which showcase interesting \"failure modes\" of our model, where inputs\nwith no visible resemblance to real gravitational-wave signals are identified\nas such by the network with high confidence.\n", "versions": [{"version": "v1", "created": "Thu, 18 Apr 2019 11:13:43 GMT"}, {"version": "v2", "created": "Fri, 6 Sep 2019 07:39:52 GMT"}], "update_date": "2019-10-02", "authors_parsed": [["Gebhard", "Timothy D.", ""], ["Kilbertus", "Niki", ""], ["Harry", "Ian", ""], ["Sch\u00f6lkopf", "Bernhard", ""]]}, {"id": "1904.08741", "submitter": "Nikolaj Tatti", "authors": "Nikolaj Tatti, Boris Cule", "title": "Mining Closed Episodes with Simultaneous Events", "comments": null, "journal-ref": null, "doi": "10.1145/2020408.2020589", "report-no": null, "categories": "cs.DB cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Sequential pattern discovery is a well-studied field in data mining. Episodes\nare sequential patterns describing events that often occur in the vicinity of\neach other. Episodes can impose restrictions to the order of the events, which\nmakes them a versatile technique for describing complex patterns in the\nsequence. Most of the research on episodes deals with special cases such as\nserial, parallel, and injective episodes, while discovering general episodes is\nunderstudied.\n  In this paper we extend the definition of an episode in order to be able to\nrepresent cases where events often occur simultaneously. We present an\nefficient and novel miner for discovering frequent and closed general episodes.\nSuch a task presents unique challenges. Firstly, we cannot define closure based\non frequency. We solve this by computing a more conservative closure that we\nuse to reduce the search space and discover the closed episodes as a\npostprocessing step. Secondly, episodes are traditionally presented as directed\nacyclic graphs. We argue that this representation has drawbacks leading to\nredundancy in the output. We solve these drawbacks by defining a subset\nrelationship in such a way that allows us to remove the redundant episodes. We\ndemonstrate the efficiency of our algorithm and the need for using closed\nepisodes empirically on synthetic and real-world datasets.\n", "versions": [{"version": "v1", "created": "Tue, 16 Apr 2019 22:53:04 GMT"}], "update_date": "2019-04-19", "authors_parsed": [["Tatti", "Nikolaj", ""], ["Cule", "Boris", ""]]}, {"id": "1904.08745", "submitter": "An-Phi Nguyen", "authors": "Guillaume Jaume, An-phi Nguyen, Mar\\'ia Rodr\\'iguez Mart\\'inez,\n  Jean-Philippe Thiran, Maria Gabrani", "title": "edGNN: a Simple and Powerful GNN for Directed Labeled Graphs", "comments": "Representation Learning on Graphs and Manifolds @ ICLR19", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The ability of a graph neural network (GNN) to leverage both the graph\ntopology and graph labels is fundamental to building discriminative node and\ngraph embeddings. Building on previous work, we theoretically show that edGNN,\nour model for directed labeled graphs, is as powerful as the Weisfeiler-Lehman\nalgorithm for graph isomorphism. Our experiments support our theoretical\nfindings, confirming that graph neural networks can be used effectively for\ninference problems on directed graphs with both node and edge labels. Code\navailable at https://github.com/guillaumejaume/edGNN.\n", "versions": [{"version": "v1", "created": "Thu, 18 Apr 2019 13:04:56 GMT"}, {"version": "v2", "created": "Wed, 4 Dec 2019 12:03:18 GMT"}], "update_date": "2019-12-05", "authors_parsed": [["Jaume", "Guillaume", ""], ["Nguyen", "An-phi", ""], ["Mart\u00ednez", "Mar\u00eda Rodr\u00edguez", ""], ["Thiran", "Jean-Philippe", ""], ["Gabrani", "Maria", ""]]}, {"id": "1904.08764", "submitter": "Jaakko Sahlsten", "authors": "Jaakko Sahlsten, Joel Jaskari, Jyri Kivinen, Lauri Turunen, Esa\n  Jaanio, Kustaa Hietala and Kimmo Kaski", "title": "Deep Learning Fundus Image Analysis for Diabetic Retinopathy and Macular\n  Edema Grading", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.IV cs.CV cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Diabetes is a globally prevalent disease that can cause visible microvascular\ncomplications such as diabetic retinopathy and macular edema in the human eye\nretina, the images of which are today used for manual disease screening. This\nlabor-intensive task could greatly benefit from automatic detection using deep\nlearning technique. Here we present a deep learning system that identifies\nreferable diabetic retinopathy comparably or better than presented in the\nprevious studies, although we use only a small fraction of images (<1/4) in\ntraining but are aided with higher image resolutions. We also provide novel\nresults for five different screening and clinical grading systems for diabetic\nretinopathy and macular edema classification, including results for accurately\nclassifying images according to clinical five-grade diabetic retinopathy and\nfour-grade diabetic macular edema scales. These results suggest, that a deep\nlearning system could increase the cost-effectiveness of screening while\nattaining higher than recommended performance, and that the system could be\napplied in clinical examinations requiring finer grading.\n", "versions": [{"version": "v1", "created": "Tue, 16 Apr 2019 08:00:40 GMT"}], "update_date": "2019-04-19", "authors_parsed": [["Sahlsten", "Jaakko", ""], ["Jaskari", "Joel", ""], ["Kivinen", "Jyri", ""], ["Turunen", "Lauri", ""], ["Jaanio", "Esa", ""], ["Hietala", "Kustaa", ""], ["Kaski", "Kimmo", ""]]}, {"id": "1904.08775", "submitter": "Siddharth Srivastava", "authors": "Prashant Anand, Ajeet Kumar Singh, Siddharth Srivastava, Brejesh Lall", "title": "Few Shot Speaker Recognition using Deep Neural Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.AS cs.LG cs.SD", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The recent advances in deep learning are mostly driven by availability of\nlarge amount of training data. However, availability of such data is not always\npossible for specific tasks such as speaker recognition where collection of\nlarge amount of data is not possible in practical scenarios. Therefore, in this\npaper, we propose to identify speakers by learning from only a few training\nexamples. To achieve this, we use a deep neural network with prototypical loss\nwhere the input to the network is a spectrogram. For output, we project the\nclass feature vectors into a common embedding space, followed by\nclassification. Further, we show the effectiveness of capsule net in a few shot\nlearning setting. To this end, we utilize an auto-encoder to learn generalized\nfeature embeddings from class-specific embeddings obtained from capsule\nnetwork. We provide exhaustive experiments on publicly available datasets and\ncompetitive baselines, demonstrating the superiority and generalization ability\nof the proposed few shot learning pipelines.\n", "versions": [{"version": "v1", "created": "Wed, 17 Apr 2019 09:25:02 GMT"}], "update_date": "2019-04-19", "authors_parsed": [["Anand", "Prashant", ""], ["Singh", "Ajeet Kumar", ""], ["Srivastava", "Siddharth", ""], ["Lall", "Brejesh", ""]]}, {"id": "1904.08779", "submitter": "Daniel Park", "authors": "Daniel S. Park, William Chan, Yu Zhang, Chung-Cheng Chiu, Barret Zoph,\n  Ekin D. Cubuk, Quoc V. Le", "title": "SpecAugment: A Simple Data Augmentation Method for Automatic Speech\n  Recognition", "comments": "5 pages, 3 figures, 6 tables; v3: references added", "journal-ref": "Proc. Interspeech 2019, 2613-2617", "doi": "10.21437/Interspeech.2019-2680", "report-no": null, "categories": "eess.AS cs.CL cs.LG cs.SD stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present SpecAugment, a simple data augmentation method for speech\nrecognition. SpecAugment is applied directly to the feature inputs of a neural\nnetwork (i.e., filter bank coefficients). The augmentation policy consists of\nwarping the features, masking blocks of frequency channels, and masking blocks\nof time steps. We apply SpecAugment on Listen, Attend and Spell networks for\nend-to-end speech recognition tasks. We achieve state-of-the-art performance on\nthe LibriSpeech 960h and Swichboard 300h tasks, outperforming all prior work.\nOn LibriSpeech, we achieve 6.8% WER on test-other without the use of a language\nmodel, and 5.8% WER with shallow fusion with a language model. This compares to\nthe previous state-of-the-art hybrid system of 7.5% WER. For Switchboard, we\nachieve 7.2%/14.6% on the Switchboard/CallHome portion of the Hub5'00 test set\nwithout the use of a language model, and 6.8%/14.1% with shallow fusion, which\ncompares to the previous state-of-the-art hybrid system at 8.3%/17.3% WER.\n", "versions": [{"version": "v1", "created": "Thu, 18 Apr 2019 17:53:38 GMT"}, {"version": "v2", "created": "Tue, 23 Jul 2019 21:56:06 GMT"}, {"version": "v3", "created": "Tue, 3 Dec 2019 18:19:07 GMT"}], "update_date": "2019-12-04", "authors_parsed": [["Park", "Daniel S.", ""], ["Chan", "William", ""], ["Zhang", "Yu", ""], ["Chiu", "Chung-Cheng", ""], ["Zoph", "Barret", ""], ["Cubuk", "Ekin D.", ""], ["Le", "Quoc V.", ""]]}, {"id": "1904.08783", "submitter": "Marta R. Costa-juss\\`a", "authors": "Christine Basta, Marta R. Costa-juss\\`a, Noe Casas", "title": "Evaluating the Underlying Gender Bias in Contextualized Word Embeddings", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Gender bias is highly impacting natural language processing applications.\nWord embeddings have clearly been proven both to keep and amplify gender biases\nthat are present in current data sources. Recently, contextualized word\nembeddings have enhanced previous word embedding techniques by computing word\nvector representations dependent on the sentence they appear in.\n  In this paper, we study the impact of this conceptual change in the word\nembedding computation in relation with gender bias. Our analysis includes\ndifferent measures previously applied in the literature to standard word\nembeddings. Our findings suggest that contextualized word embeddings are less\nbiased than standard ones even when the latter are debiased.\n", "versions": [{"version": "v1", "created": "Thu, 18 Apr 2019 13:47:00 GMT"}], "update_date": "2019-04-19", "authors_parsed": [["Basta", "Christine", ""], ["Costa-juss\u00e0", "Marta R.", ""], ["Casas", "Noe", ""]]}, {"id": "1904.08784", "submitter": "Tianyu Shi", "authors": "Chenyang Xi, Tianyu Shi, Yuankai Wu, Lijun Sun", "title": "Efficient Motion Planning for Automated Lane Change based on Imitation\n  Learning and Mixed-Integer Optimization", "comments": "Accepted by IEEE ITSC 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Intelligent motion planning is one of the core components in automated\nvehicles, which has received extensive interests. Traditional motion planning\nmethods suffer from several drawbacks in terms of optimality, efficiency and\ngeneralization capability. Sampling based methods cannot guarantee the\noptimality of the generated trajectories. Whereas the optimization-based\nmethods are not able to perform motion planning in real-time, and limited by\nthe simplified formalization. In this work, we propose a learning-based\napproach to handle those shortcomings. Mixed Integer Quadratic Problem based\noptimization (MIQP) is used to generate the optimal lane-change trajectories\nwhich served as the training dataset for learning-based action generation\nalgorithms. A hierarchical supervised learning model is devised to make the\nfast lane-change decision. Numerous experiments have been conducted to evaluate\nthe optimality, efficiency, and generalization capability of the proposed\napproach. The experimental results indicate that the proposed model outperforms\nseveral commonly used motion planning baselines.\n", "versions": [{"version": "v1", "created": "Thu, 18 Apr 2019 13:47:17 GMT"}, {"version": "v2", "created": "Sun, 1 Sep 2019 11:48:35 GMT"}, {"version": "v3", "created": "Sat, 7 Mar 2020 14:29:52 GMT"}, {"version": "v4", "created": "Fri, 8 May 2020 21:26:02 GMT"}], "update_date": "2020-05-12", "authors_parsed": [["Xi", "Chenyang", ""], ["Shi", "Tianyu", ""], ["Wu", "Yuankai", ""], ["Sun", "Lijun", ""]]}, {"id": "1904.08796", "submitter": "Eric Eaton", "authors": "Julia E. Reid, Eric Eaton", "title": "Artificial Intelligence for Pediatric Ophthalmology", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "physics.med-ph cs.CV cs.LG eess.IV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  PURPOSE OF REVIEW: Despite the impressive results of recent artificial\nintelligence (AI) applications to general ophthalmology, comparatively less\nprogress has been made toward solving problems in pediatric ophthalmology using\nsimilar techniques. This article discusses the unique needs of pediatric\nophthalmology patients and how AI techniques can address these challenges,\nsurveys recent applications of AI to pediatric ophthalmology, and discusses\nfuture directions in the field.\n  RECENT FINDINGS: The most significant advances involve the automated\ndetection of retinopathy of prematurity (ROP), yielding results that rival\nexperts. Machine learning (ML) has also been successfully applied to the\nclassification of pediatric cataracts, prediction of post-operative\ncomplications following cataract surgery, detection of strabismus and\nrefractive error, prediction of future high myopia, and diagnosis of reading\ndisability via eye tracking. In addition, ML techniques have been used for the\nstudy of visual development, vessel segmentation in pediatric fundus images,\nand ophthalmic image synthesis.\n  SUMMARY: AI applications could significantly benefit clinical care for\npediatric ophthalmology patients by optimizing disease detection and grading,\nbroadening access to care, furthering scientific discovery, and improving\nclinical efficiency. These methods need to match or surpass physician\nperformance in clinical trials before deployment with patients. Due to\nwidespread use of closed-access data sets and software implementations, it is\ndifficult to directly compare the performance of these approaches, and\nreproducibility is poor. Open-access data sets and software implementations\ncould alleviate these issues, and encourage further AI applications to\npediatric ophthalmology.\n  KEYWORDS: pediatric ophthalmology, machine learning, artificial intelligence,\ndeep learning\n", "versions": [{"version": "v1", "created": "Sat, 6 Apr 2019 01:47:47 GMT"}], "update_date": "2019-04-19", "authors_parsed": [["Reid", "Julia E.", ""], ["Eaton", "Eric", ""]]}, {"id": "1904.08800", "submitter": "Carlton Shepherd", "authors": "Pradip Mainali, Carlton Shepherd and Fabien A. P. Petitcolas", "title": "Privacy-Enhancing Context Authentication from Location-Sensitive Data", "comments": "Accepted at the 2nd ACM International Workshop on Behavioral\n  Authentication for System Security (BASS 2019)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper proposes a new privacy-enhancing, context-aware user\nauthentication system, ConSec, which uses a transformation of general\nlocation-sensitive data, such as GPS location, barometric altitude and noise\nlevels, collected from the user's device, into a representation based on\nlocality-sensitive hashing (LSH). The resulting hashes provide a dimensionality\nreduction of the underlying data, which we leverage to model users' behaviour\nfor authentication using machine learning. We present how ConSec supports\nlearning from categorical and numerical data, while addressing a number of\non-device and network-based threats. ConSec is implemented subsequently for the\nAndroid platform and evaluated using data collected from 35 users, which is\nfollowed by a security and privacy analysis. We demonstrate that LSH presents a\nuseful approach for context authentication from location-sensitive data without\ndirectly utilising plain measurements.\n", "versions": [{"version": "v1", "created": "Thu, 18 Apr 2019 14:21:05 GMT"}, {"version": "v2", "created": "Wed, 10 Jul 2019 11:04:40 GMT"}], "update_date": "2019-10-01", "authors_parsed": [["Mainali", "Pradip", ""], ["Shepherd", "Carlton", ""], ["Petitcolas", "Fabien A. P.", ""]]}, {"id": "1904.08801", "submitter": "Matthias M\\\"uller", "authors": "Matthias M\\\"uller, Guohao Li, Vincent Casser, Neil Smith, Dominik L.\n  Michels, Bernard Ghanem", "title": "Learning a Controller Fusion Network by Online Trajectory Filtering for\n  Vision-based UAV Racing", "comments": "Accepted at CVPRW'19: UAVision 2019. First two authors contributed\n  equally. Based on the initial work of arXiv:1803.01129 which was eventually\n  split into two separate projects", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Autonomous UAV racing has recently emerged as an interesting research\nproblem. The dream is to beat humans in this new fast-paced sport. A common\napproach is to learn an end-to-end policy that directly predicts controls from\nraw images by imitating an expert. However, such a policy is limited by the\nexpert it imitates and scaling to other environments and vehicle dynamics is\ndifficult. One approach to overcome the drawbacks of an end-to-end policy is to\ntrain a network only on the perception task and handle control with a PID or\nMPC controller. However, a single controller must be extensively tuned and\ncannot usually cover the whole state space. In this paper, we propose learning\nan optimized controller using a DNN that fuses multiple controllers. The\nnetwork learns a robust controller with online trajectory filtering, which\nsuppresses noisy trajectories and imperfections of individual controllers. The\nresult is a network that is able to learn a good fusion of filtered\ntrajectories from different controllers leading to significant improvements in\noverall performance. We compare our trained network to controllers it has\nlearned from, end-to-end baselines and human pilots in a realistic simulation;\nour network beats all baselines in extensive experiments and approaches the\nperformance of a professional human pilot. A video summarizing this work is\navailable at https://youtu.be/hGKlE5X9Z5U\n", "versions": [{"version": "v1", "created": "Thu, 18 Apr 2019 14:23:33 GMT"}], "update_date": "2019-04-19", "authors_parsed": [["M\u00fcller", "Matthias", ""], ["Li", "Guohao", ""], ["Casser", "Vincent", ""], ["Smith", "Neil", ""], ["Michels", "Dominik L.", ""], ["Ghanem", "Bernard", ""]]}, {"id": "1904.08809", "submitter": "Dario  Izzo", "authors": "Dario Izzo, Ekin \\\"Ozt\\\"urk, Marcus M\\\"artens", "title": "Interplanetary Transfers via Deep Representations of the Optimal Policy\n  and/or of the Value Function", "comments": null, "journal-ref": null, "doi": "10.1145/3319619.3326834", "report-no": null, "categories": "cs.NE cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A number of applications to interplanetary trajectories have been recently\nproposed based on deep networks. These approaches often rely on the\navailability of a large number of optimal trajectories to learn from. In this\npaper we introduce a new method to quickly create millions of optimal\nspacecraft trajectories from a single nominal trajectory. Apart from the\ngeneration of the nominal trajectory, no additional optimal control problems\nneed to be solved as all the trajectories, by construction, satisfy\nPontryagin's minimum principle and the relevant transversality conditions. We\nthen consider deep feed forward neural networks and benchmark three learning\nmethods on the created dataset: policy imitation, value function learning and\nvalue function gradient learning. Our results are shown for the case of the\ninterplanetary trajectory optimization problem of reaching Venus orbit, with\nthe nominal trajectory starting from the Earth. We find that both policy\nimitation and value function gradient learning are able to learn the optimal\nstate feedback, while in the case of value function learning the optimal policy\nis not captured, only the final value of the optimal propellant mass is.\n", "versions": [{"version": "v1", "created": "Thu, 18 Apr 2019 14:33:34 GMT"}], "update_date": "2019-12-18", "authors_parsed": [["Izzo", "Dario", ""], ["\u00d6zt\u00fcrk", "Ekin", ""], ["M\u00e4rtens", "Marcus", ""]]}, {"id": "1904.08827", "submitter": "Bahareh Tolooshams", "authors": "Bahareh Tolooshams, Sourav Dey, Demba Ba", "title": "Deep Residual Autoencoders for Expectation Maximization-inspired\n  Dictionary Learning", "comments": null, "journal-ref": "in IEEE Transactions on Neural Networks and Learning Systems, pp.\n  1-15, 2020", "doi": "10.1109/TNNLS.2020.3005348", "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce a neural-network architecture, termed the constrained recurrent\nsparse autoencoder (CRsAE), that solves convolutional dictionary learning\nproblems, thus establishing a link between dictionary learning and neural\nnetworks. Specifically, we leverage the interpretation of the\nalternating-minimization algorithm for dictionary learning as an approximate\nExpectation-Maximization algorithm to develop autoencoders that enable the\nsimultaneous training of the dictionary and regularization parameter (ReLU\nbias). The forward pass of the encoder approximates the sufficient statistics\nof the E-step as the solution to a sparse coding problem, using an iterative\nproximal gradient algorithm called FISTA. The encoder can be interpreted either\nas a recurrent neural network or as a deep residual network, with two-sided\nReLU non-linearities in both cases. The M-step is implemented via a two-stage\nback-propagation. The first stage relies on a linear decoder applied to the\nencoder and a norm-squared loss. It parallels the dictionary update step in\ndictionary learning. The second stage updates the regularization parameter by\napplying a loss function to the encoder that includes a prior on the parameter\nmotivated by Bayesian statistics. We demonstrate in an image-denoising task\nthat CRsAE learns Gabor-like filters, and that the EM-inspired approach for\nlearning biases is superior to the conventional approach. In an application to\nrecordings of electrical activity from the brain, we demonstrate that CRsAE\nlearns realistic spike templates and speeds up the process of identifying spike\ntimes by 900x compared to algorithms based on convex optimization.\n", "versions": [{"version": "v1", "created": "Thu, 18 Apr 2019 15:08:10 GMT"}, {"version": "v2", "created": "Fri, 20 Mar 2020 15:33:31 GMT"}, {"version": "v3", "created": "Sun, 18 Oct 2020 16:17:46 GMT"}], "update_date": "2020-10-20", "authors_parsed": [["Tolooshams", "Bahareh", ""], ["Dey", "Sourav", ""], ["Ba", "Demba", ""]]}, {"id": "1904.08831", "submitter": "Matthew A. Wright", "authors": "Matthew A. Wright, Simon F. G. Ehlers, Roberto Horowitz", "title": "Neural-Attention-Based Deep Learning Architectures for Modeling Traffic\n  Dynamics on Lane Graphs", "comments": "To appear at 2019 IEEE Conference on Intelligent Transportation\n  Systems", "journal-ref": null, "doi": "10.1109/ITSC.2019.8917174", "report-no": null, "categories": "cs.LG cs.SY stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep neural networks can be powerful tools, but require careful\napplication-specific design to ensure that the most informative relationships\nin the data are learnable. In this paper, we apply deep neural networks to the\nnonlinear spatiotemporal physics problem of vehicle traffic dynamics. We\nconsider problems of estimating macroscopic quantities (e.g., the queue at an\nintersection) at a lane level. First-principles modeling at the lane scale has\nbeen a challenge due to complexities in modeling social behaviors like lane\nchanges, and those behaviors' resultant macro-scale effects. Following domain\nknowledge that upstream/downstream lanes and neighboring lanes affect each\nothers' traffic flows in distinct ways, we apply a form of neural attention\nthat allows the neural network layers to aggregate information from different\nlanes in different manners. Using a microscopic traffic simulator as a testbed,\nwe obtain results showing that an attentional neural network model can use\ninformation from nearby lanes to improve predictions, and, that explicitly\nencoding the lane-to-lane relationship types significantly improves\nperformance. We also demonstrate the transfer of our learned neural network to\na more complex road network, discuss how its performance degradation may be\nattributable to new traffic behaviors induced by increased topological\ncomplexity, and motivate learning dynamics models from many road network\ntopologies.\n", "versions": [{"version": "v1", "created": "Thu, 18 Apr 2019 15:14:10 GMT"}, {"version": "v2", "created": "Tue, 23 Apr 2019 20:43:43 GMT"}, {"version": "v3", "created": "Sun, 14 Jul 2019 19:03:37 GMT"}], "update_date": "2019-12-04", "authors_parsed": [["Wright", "Matthew A.", ""], ["Ehlers", "Simon F. G.", ""], ["Horowitz", "Roberto", ""]]}, {"id": "1904.08842", "submitter": "Ruihan Yang", "authors": "Ruihan Yang, Tianyao Chen, Yiyi Zhang and Gus Xia", "title": "Inspecting and Interacting with Meaningful Music Representations using\n  VAE", "comments": "Accepted for poster at the International Conference on New Interfaces\n  for Musical Expression (NIME), June 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SD cs.HC cs.IR cs.LG eess.AS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Variational Autoencoders(VAEs) have already achieved great results on image\ngeneration and recently made promising progress on music generation. However,\nthe generation process is still quite difficult to control in the sense that\nthe learned latent representations lack meaningful music semantics. It would be\nmuch more useful if people can modify certain music features, such as rhythm\nand pitch contour, via latent representations to test different composition\nideas. In this paper, we propose a new method to inspect the pitch and rhythm\ninterpretations of the latent representations and we name it disentanglement by\naugmentation. Based on the interpretable representations, an intuitive\ngraphical user interface is designed for users to better direct the music\ncreation process by manipulating the pitch contours and rhythmic complexity.\n", "versions": [{"version": "v1", "created": "Thu, 18 Apr 2019 15:22:33 GMT"}], "update_date": "2019-04-19", "authors_parsed": [["Yang", "Ruihan", ""], ["Chen", "Tianyao", ""], ["Zhang", "Yiyi", ""], ["Xia", "Gus", ""]]}, {"id": "1904.08875", "submitter": "Lauri Himanen", "authors": "Lauri Himanen, Marc O. J. J\\\"ager, Eiaki V. Morooka, Filippo Federici\n  Canova, Yashasvi S. Ranawat, David Z. Gao, Patrick Rinke, Adam S. Foster", "title": "DScribe: Library of Descriptors for Machine Learning in Materials\n  Science", "comments": null, "journal-ref": null, "doi": "10.1016/j.cpc.2019.106949", "report-no": null, "categories": "cond-mat.mtrl-sci cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  DScribe is a software package for machine learning that provides popular\nfeature transformations (\"descriptors\") for atomistic materials simulations.\nDScribe accelerates the application of machine learning for atomistic property\nprediction by providing user-friendly, off-the-shelf descriptor\nimplementations. The package currently contains implementations for Coulomb\nmatrix, Ewald sum matrix, sine matrix, Many-body Tensor Representation (MBTR),\nAtom-centered Symmetry Function (ACSF) and Smooth Overlap of Atomic Positions\n(SOAP). Usage of the package is illustrated for two different applications:\nformation energy prediction for solids and ionic charge prediction for atoms in\norganic molecules. The package is freely available under the open-source Apache\nLicense 2.0.\n", "versions": [{"version": "v1", "created": "Thu, 18 Apr 2019 16:29:07 GMT"}], "update_date": "2019-12-02", "authors_parsed": [["Himanen", "Lauri", ""], ["J\u00e4ger", "Marc O. J.", ""], ["Morooka", "Eiaki V.", ""], ["Canova", "Filippo Federici", ""], ["Ranawat", "Yashasvi S.", ""], ["Gao", "David Z.", ""], ["Rinke", "Patrick", ""], ["Foster", "Adam S.", ""]]}, {"id": "1904.08915", "submitter": "Steven Kearnes", "authors": "Steven Kearnes, Li Li, Patrick Riley", "title": "Decoding Molecular Graph Embeddings with Reinforcement Learning", "comments": "Presented at the ICML 2019 Workshop on Learning and Reasoning with\n  Graph-Structured Data. Copyright 2019 by the author(s)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present RL-VAE, a graph-to-graph variational autoencoder that uses\nreinforcement learning to decode molecular graphs from latent embeddings.\nMethods have been described previously for graph-to-graph autoencoding, but\nthese approaches require sophisticated decoders that increase the complexity of\ntraining and evaluation (such as requiring parallel encoders and decoders or\nnon-trivial graph matching). Here, we repurpose a simple graph generator to\nenable efficient decoding and generation of molecular graphs.\n", "versions": [{"version": "v1", "created": "Thu, 18 Apr 2019 17:50:57 GMT"}, {"version": "v2", "created": "Tue, 4 Jun 2019 23:31:26 GMT"}], "update_date": "2019-06-06", "authors_parsed": [["Kearnes", "Steven", ""], ["Li", "Li", ""], ["Riley", "Patrick", ""]]}, {"id": "1904.08920", "submitter": "Amanpreet Singh", "authors": "Amanpreet Singh, Vivek Natarajan, Meet Shah, Yu Jiang, Xinlei Chen,\n  Dhruv Batra, Devi Parikh, Marcus Rohrbach", "title": "Towards VQA Models That Can Read", "comments": "CVPR 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Studies have shown that a dominant class of questions asked by visually\nimpaired users on images of their surroundings involves reading text in the\nimage. But today's VQA models can not read! Our paper takes a first step\ntowards addressing this problem. First, we introduce a new \"TextVQA\" dataset to\nfacilitate progress on this important problem. Existing datasets either have a\nsmall proportion of questions about text (e.g., the VQA dataset) or are too\nsmall (e.g., the VizWiz dataset). TextVQA contains 45,336 questions on 28,408\nimages that require reasoning about text to answer. Second, we introduce a\nnovel model architecture that reads text in the image, reasons about it in the\ncontext of the image and the question, and predicts an answer which might be a\ndeduction based on the text and the image or composed of the strings found in\nthe image. Consequently, we call our approach Look, Read, Reason & Answer\n(LoRRA). We show that LoRRA outperforms existing state-of-the-art VQA models on\nour TextVQA dataset. We find that the gap between human performance and machine\nperformance is significantly larger on TextVQA than on VQA 2.0, suggesting that\nTextVQA is well-suited to benchmark progress along directions complementary to\nVQA 2.0.\n", "versions": [{"version": "v1", "created": "Thu, 18 Apr 2019 17:55:37 GMT"}, {"version": "v2", "created": "Mon, 13 May 2019 23:28:48 GMT"}], "update_date": "2019-05-15", "authors_parsed": [["Singh", "Amanpreet", ""], ["Natarajan", "Vivek", ""], ["Shah", "Meet", ""], ["Jiang", "Yu", ""], ["Chen", "Xinlei", ""], ["Batra", "Dhruv", ""], ["Parikh", "Devi", ""], ["Rohrbach", "Marcus", ""]]}, {"id": "1904.08930", "submitter": "Joie Yeahuay Wu", "authors": "Surya Teja Devarakonda and Joie Yeahuay Wu and Yi Ren Fung and\n  Madalina Fiterau", "title": "FLARe: Forecasting by Learning Anticipated Representations", "comments": null, "journal-ref": null, "doi": null, "report-no": "PMLR 106:53-65", "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Computational models that forecast the progression of Alzheimer's disease at\nthe patient level are extremely useful tools for identifying high risk cohorts\nfor early intervention and treatment planning. The state-of-the-art work in\nthis area proposes models that forecast by using latent representations\nextracted from the longitudinal data across multiple modalities, including\nvolumetric information extracted from medical scans and demographic info. These\nmodels incorporate the time horizon, which is the amount of time between the\nlast recorded visit and the future visit, by directly concatenating a\nrepresentation of it to the data latent representation. In this paper, we\npresent a model which generates a sequence of latent representations of the\npatient status across the time horizon, providing more informative modeling of\nthe temporal relationships between the patient's history and future visits. Our\nproposed model outperforms the baseline in terms of forecasting accuracy and F1\nscore with the added benefit of robustly handling missing visits.\n", "versions": [{"version": "v1", "created": "Wed, 17 Apr 2019 18:04:38 GMT"}, {"version": "v2", "created": "Fri, 27 Dec 2019 04:12:07 GMT"}], "update_date": "2019-12-30", "authors_parsed": [["Devarakonda", "Surya Teja", ""], ["Wu", "Joie Yeahuay", ""], ["Fung", "Yi Ren", ""], ["Fiterau", "Madalina", ""]]}, {"id": "1904.08933", "submitter": "Ali Yazdizadeh", "authors": "Ali Yazdizadeh, Zachary Patterson, Bilal Farooq", "title": "Ensemble Convolutional Neural Networks for Mode Inference in Smartphone\n  Travel Survey", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We develop ensemble Convolutional Neural Networks (CNNs) to classify the\ntransportation mode of trip data collected as part of a large-scale smartphone\ntravel survey in Montreal, Canada. Our proposed ensemble library is composed of\na series of CNN models with different hyper-parameter values and CNN\narchitectures. In our final model, we combine the output of CNN models using\n\"average voting\", \"majority voting\" and \"optimal weights\" methods. Furthermore,\nwe exploit the ensemble library by deploying a Random Forest model as a\nmeta-learner. The ensemble method with random forest as meta-learner shows an\naccuracy of 91.8% which surpasses the other three ensemble combination methods,\nas well as other comparable models reported in the literature. The \"majority\nvoting\" and \"optimal weights\" combination methods result in prediction accuracy\nrates around 89%, while \"average voting\" is able to achieve an accuracy of only\n85%.\n", "versions": [{"version": "v1", "created": "Thu, 18 Apr 2019 00:24:21 GMT"}], "update_date": "2019-04-22", "authors_parsed": [["Yazdizadeh", "Ali", ""], ["Patterson", "Zachary", ""], ["Farooq", "Bilal", ""]]}, {"id": "1904.08935", "submitter": "Alan Gee", "authors": "Alan H. Gee, Diego Garcia-Olano, Joydeep Ghosh, and David Paydarfar", "title": "Explaining Deep Classification of Time-Series Data with Learned\n  Prototypes", "comments": "The first two authors contributed equally. Accepted May 20, Presented\n  Jun 14, 2019 at the ICML Time-series Workshop in Long Beach, CA, USA.\n  Accepted June 15, Presented Aug 11, 2019 at the IJCAI Workshop on Knowledge\n  Discovery in Healthcare Data in Macao, China. Formal proceedings available in\n  the CEUR Workshop Proceedings (http://ceur-ws.org/Vol-2429/)", "journal-ref": "Proceedings of the 4th International Workshop on Knowledge\n  Discovery in Healthcare Data, co-located with the 28th International Joint\n  Conference on Artificial Intelligence (IJCAI 2019)", "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The emergence of deep learning networks raises a need for explainable AI so\nthat users and domain experts can be confident applying them to high-risk\ndecisions. In this paper, we leverage data from the latent space induced by\ndeep learning models to learn stereotypical representations or \"prototypes\"\nduring training to elucidate the algorithmic decision-making process. We study\nhow leveraging prototypes effect classification decisions of two dimensional\ntime-series data in a few different settings: (1) electrocardiogram (ECG)\nwaveforms to detect clinical bradycardia, a slowing of heart rate, in preterm\ninfants, (2) respiration waveforms to detect apnea of prematurity, and (3)\naudio waveforms to classify spoken digits. We improve upon existing models by\noptimizing for increased prototype diversity and robustness, visualize how\nthese prototypes in the latent space are used by the model to distinguish\nclasses, and show that prototypes are capable of learning features on two\ndimensional time-series data to produce explainable insights during\nclassification tasks. We show that the prototypes are capable of learning\nreal-world features - bradycardia in ECG, apnea in respiration, and\narticulation in speech - as well as features within sub-classes. Our novel work\nleverages learned prototypical framework on two dimensional time-series data to\nproduce explainable insights during classification tasks.\n", "versions": [{"version": "v1", "created": "Thu, 18 Apr 2019 07:14:45 GMT"}, {"version": "v2", "created": "Thu, 1 Aug 2019 04:48:06 GMT"}, {"version": "v3", "created": "Thu, 5 Sep 2019 02:47:22 GMT"}], "update_date": "2019-09-10", "authors_parsed": [["Gee", "Alan H.", ""], ["Garcia-Olano", "Diego", ""], ["Ghosh", "Joydeep", ""], ["Paydarfar", "David", ""]]}, {"id": "1904.08936", "submitter": "Anupiya Nugaliyadde Mr", "authors": "Anupiya Nugaliyadde, Kok Wai Wong, Ferdous Sohel and Hong Xie", "title": "Language Modeling through Long Term Memory Network", "comments": "The paper is accepted to be published in IJCNN 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recurrent Neural Networks (RNN), Long Short-Term Memory Networks (LSTM), and\nMemory Networks which contain memory are popularly used to learn patterns in\nsequential data. Sequential data has long sequences that hold relationships.\nRNN can handle long sequences but suffers from the vanishing and exploding\ngradient problems. While LSTM and other memory networks address this problem,\nthey are not capable of handling long sequences (50 or more data points long\nsequence patterns). Language modelling requiring learning from longer sequences\nare affected by the need for more information in memory. This paper introduces\nLong Term Memory network (LTM), which can tackle the exploding and vanishing\ngradient problems and handles long sequences without forgetting. LTM is\ndesigned to scale data in the memory and gives a higher weight to the input in\nthe sequence. LTM avoid overfitting by scaling the cell state after achieving\nthe optimal results. The LTM is tested on Penn treebank dataset, and Text8\ndataset and LTM achieves test perplexities of 83 and 82 respectively. 650 LTM\ncells achieved a test perplexity of 67 for Penn treebank, and 600 cells\nachieved a test perplexity of 77 for Text8. LTM achieves state of the art\nresults by only using ten hidden LTM cells for both datasets.\n", "versions": [{"version": "v1", "created": "Thu, 18 Apr 2019 09:19:25 GMT"}], "update_date": "2019-04-22", "authors_parsed": [["Nugaliyadde", "Anupiya", ""], ["Wong", "Kok Wai", ""], ["Sohel", "Ferdous", ""], ["Xie", "Hong", ""]]}, {"id": "1904.08939", "submitter": "Anh Nguyen", "authors": "Anh Nguyen and Jason Yosinski and Jeff Clune", "title": "Understanding Neural Networks via Feature Visualization: A survey", "comments": "A book chapter in an Interpretable ML book\n  (http://www.interpretable-ml.org/book/)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A neuroscience method to understanding the brain is to find and study the\npreferred stimuli that highly activate an individual cell or groups of cells.\nRecent advances in machine learning enable a family of methods to synthesize\npreferred stimuli that cause a neuron in an artificial or biological brain to\nfire strongly. Those methods are known as Activation Maximization (AM) or\nFeature Visualization via Optimization. In this chapter, we (1) review existing\nAM techniques in the literature; (2) discuss a probabilistic interpretation for\nAM; and (3) review the applications of AM in debugging and explaining networks.\n", "versions": [{"version": "v1", "created": "Thu, 18 Apr 2019 15:46:26 GMT"}], "update_date": "2019-04-22", "authors_parsed": [["Nguyen", "Anh", ""], ["Yosinski", "Jason", ""], ["Clune", "Jeff", ""]]}, {"id": "1904.08962", "submitter": "Kesav Kaza", "authors": "Kesav Kaza and Rahul Meshram and Varun Mehta and S.N.Merchant", "title": "Constrained Restless Bandits for Dynamic Scheduling in Cyber-Physical\n  Systems", "comments": "14 pages, 2 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SY cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper studies a class of constrained restless multi-armed bandits\n(CRMAB). The constraints are in the form of time varying set of actions (set of\navailable arms). This variation can be either stochastic or semi-deterministic.\nGiven a set of arms, a fixed number of them can be chosen to be played in each\ndecision interval. The play of each arm yields a state dependent reward. The\ncurrent states of arms are partially observable through binary feedback signals\nfrom arms that are played. The current availability of arms is fully\nobservable. The objective is to maximize long term cumulative reward. The\nuncertainty about future availability of arms along with partial state\ninformation makes this objective challenging. Applications for CRMAB abound in\nthe domain of cyber-physical systems. First, this optimization problem is\nanalyzed using Whittle's index policy. To this end, a constrained restless\nsingle-armed bandit is studied. It is shown to admit a threshold-type optimal\npolicy and is also indexable. An algorithm to compute Whittle's index is\npresented. An alternate solution method with lower complexity is also presented\nin the form of an online rollout policy. Further, upper bounds on the value\nfunction are derived in order to estimate the degree of sub-optimality of\nvarious solutions. The simulation study compares the performance of Whittle's\nindex, online rollout, myopic and modified Whittle's index policies.\n", "versions": [{"version": "v1", "created": "Thu, 18 Apr 2019 18:15:52 GMT"}, {"version": "v2", "created": "Sun, 22 Sep 2019 10:00:18 GMT"}, {"version": "v3", "created": "Thu, 7 May 2020 13:08:08 GMT"}, {"version": "v4", "created": "Mon, 12 Jul 2021 18:39:58 GMT"}], "update_date": "2021-07-14", "authors_parsed": [["Kaza", "Kesav", ""], ["Meshram", "Rahul", ""], ["Mehta", "Varun", ""], ["Merchant", "S. N.", ""]]}, {"id": "1904.08983", "submitter": "Adam Polyak", "authors": "Adam Polyak, Lior Wolf, Yaniv Taigman", "title": "TTS Skins: Speaker Conversion via ASR", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SD cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a fully convolutional wav-to-wav network for converting between\nspeakers' voices, without relying on text. Our network is based on an\nencoder-decoder architecture, where the encoder is pre-trained for the task of\nAutomatic Speech Recognition, and a multi-speaker waveform decoder is trained\nto reconstruct the original signal in an autoregressive manner. We train the\nnetwork on narrated audiobooks, and demonstrate multi-voice TTS in those\nvoices, by converting the voice of a TTS robot.\n", "versions": [{"version": "v1", "created": "Thu, 18 Apr 2019 19:35:24 GMT"}, {"version": "v2", "created": "Sun, 26 Jul 2020 11:18:14 GMT"}], "update_date": "2020-07-28", "authors_parsed": [["Polyak", "Adam", ""], ["Wolf", "Lior", ""], ["Taigman", "Yaniv", ""]]}, {"id": "1904.08990", "submitter": "Sajjad Abdoli", "authors": "Sajjad Abdoli, Patrick Cardinal, Alessandro Lameiras Koerich", "title": "End-to-End Environmental Sound Classification using a 1D Convolutional\n  Neural Network", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SD cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we present an end-to-end approach for environmental sound\nclassification based on a 1D Convolution Neural Network (CNN) that learns a\nrepresentation directly from the audio signal. Several convolutional layers are\nused to capture the signal's fine time structure and learn diverse filters that\nare relevant to the classification task. The proposed approach can deal with\naudio signals of any length as it splits the signal into overlapped frames\nusing a sliding window. Different architectures considering several input sizes\nare evaluated, including the initialization of the first convolutional layer\nwith a Gammatone filterbank that models the human auditory filter response in\nthe cochlea. The performance of the proposed end-to-end approach in classifying\nenvironmental sounds was assessed on the UrbanSound8k dataset and the\nexperimental results have shown that it achieves 89% of mean accuracy.\nTherefore, the propose approach outperforms most of the state-of-the-art\napproaches that use handcrafted features or 2D representations as input.\nFurthermore, the proposed approach has a small number of parameters compared to\nother architectures found in the literature, which reduces the amount of data\nrequired for training.\n", "versions": [{"version": "v1", "created": "Thu, 18 Apr 2019 20:07:03 GMT"}], "update_date": "2019-04-22", "authors_parsed": [["Abdoli", "Sajjad", ""], ["Cardinal", "Patrick", ""], ["Koerich", "Alessandro Lameiras", ""]]}, {"id": "1904.08991", "submitter": "Marios Mattheakis M", "authors": "M. Mattheakis, P. Protopapas, D. Sondak, M. Di Giovanni, E. Kaxiras", "title": "Physical Symmetries Embedded in Neural Networks", "comments": "This is the same manuscript with version 1 (arXiv:1904.08991v1) which\n  accidentally was replaced 16 pages, 8 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "physics.comp-ph cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Neural networks are a central technique in machine learning. Recent years\nhave seen a wave of interest in applying neural networks to physical systems\nfor which the governing dynamics are known and expressed through differential\nequations. Two fundamental challenges facing the development of neural networks\nin physics applications is their lack of interpretability and their\nphysics-agnostic design. The focus of the present work is to embed physical\nconstraints into the structure of the neural network to address the second\nfundamental challenge. By constraining tunable parameters (such as weights and\nbiases) and adding special layers to the network, the desired constraints are\nguaranteed to be satisfied without the need for explicit regularization terms.\nThis is demonstrated on upervised and unsupervised networks for two basic\nsymmetries: even/odd symmetry of a function and energy conservation. In the\nsupervised case, the network with embedded constraints is shown to perform well\non regression problems while simultaneously obeying the desired constraints\nwhereas a traditional network fits the data but violates the underlying\nconstraints. Finally, a new unsupervised neural network is proposed that\nguarantees energy conservation through an embedded symplectic structure. The\nsymplectic neural network is used to solve a system of energy-conserving\ndifferential equations and out-performs an unsupervised, non-symplectic neural\nnetwork.\n", "versions": [{"version": "v1", "created": "Thu, 18 Apr 2019 20:07:04 GMT"}, {"version": "v2", "created": "Mon, 27 Jan 2020 21:08:34 GMT"}, {"version": "v3", "created": "Wed, 29 Jan 2020 21:44:39 GMT"}], "update_date": "2020-01-31", "authors_parsed": [["Mattheakis", "M.", ""], ["Protopapas", "P.", ""], ["Sondak", "D.", ""], ["Di Giovanni", "M.", ""], ["Kaxiras", "E.", ""]]}, {"id": "1904.08992", "submitter": "Jacob Farinholt", "authors": "Samuel S. Mendelson, Robert W. Strand, Guy B. Oldaker IV, Jacob M.\n  Farinholt", "title": "Quantum-Assisted Clustering Algorithms for NISQ-Era Devices", "comments": "12 pages, 11 figures, 2 tables, 1 Appendix. Latest Version: Evaluated\n  runtimes, edited content for readability, included further discussions", "journal-ref": null, "doi": null, "report-no": null, "categories": "quant-ph cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In the NISQ-era of quantum computing, we should not expect to see quantum\ndevices that provide an exponential improvement in runtime for practical\nproblems, due to the lack of error correction and small number of qubits\navailable. Nevertheless, these devices should be able to provide other\nperformance improvements, particularly when combined with existing classical\nmachines. In this article, we develop several hybrid quantum-classical\nclustering algorithms that can be employed as subroutines on small, NISQ-era\ndevices. These new hybrid algorithms require a number of qubits that is at most\nlogarithmic in the size of the data, provide performance improvement and/or\nruntime improvement over their classical counterparts, and do not require a\nblack-box oracle. Consequently, we are able to provide a promising near-term\napplication of NISQ-era devices.\n", "versions": [{"version": "v1", "created": "Thu, 18 Apr 2019 20:07:55 GMT"}, {"version": "v2", "created": "Mon, 29 Apr 2019 17:31:51 GMT"}, {"version": "v3", "created": "Thu, 27 Jun 2019 18:59:31 GMT"}], "update_date": "2019-07-02", "authors_parsed": [["Mendelson", "Samuel S.", ""], ["Strand", "Robert W.", ""], ["Oldaker", "Guy B.", "IV"], ["Farinholt", "Jacob M.", ""]]}, {"id": "1904.08993", "submitter": "Andrew Cropper", "authors": "Andrew Cropper", "title": "Playgol: learning programs through play", "comments": "IJCAI 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Children learn though play. We introduce the analogous idea of learning\nprograms through play. In this approach, a program induction system (the\nlearner) is given a set of tasks and initial background knowledge. Before\nsolving the tasks, the learner enters an unsupervised playing stage where it\ncreates its own tasks to solve, tries to solve them, and saves any solutions\n(programs) to the background knowledge. After the playing stage is finished,\nthe learner enters the supervised building stage where it tries to solve the\nuser-supplied tasks and can reuse solutions learnt whilst playing. The idea is\nthat playing allows the learner to discover reusable general programs on its\nown which can then help solve the user-supplied tasks. We claim that playing\ncan improve learning performance. We show that playing can reduce the textual\ncomplexity of target concepts which in turn reduces the sample complexity of a\nlearner. We implement our idea in Playgol, a new inductive logic programming\nsystem. We experimentally test our claim on two domains: robot planning and\nreal-world string transformations. Our experimental results suggest that\nplaying can substantially improve learning performance. We think that the idea\nof playing (or, more verbosely, unsupervised bootstrapping for supervised\nprogram induction) is an important contribution to the problem of developing\nprogram induction approaches that self-discover BK.\n", "versions": [{"version": "v1", "created": "Thu, 18 Apr 2019 20:14:02 GMT"}, {"version": "v2", "created": "Mon, 20 May 2019 15:24:51 GMT"}], "update_date": "2019-05-21", "authors_parsed": [["Cropper", "Andrew", ""]]}, {"id": "1904.08994", "submitter": "Lilian Weng", "authors": "Lilian Weng", "title": "From GAN to WGAN", "comments": "12 pages, 9 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper explains the math behind a generative adversarial network (GAN)\nmodel and why it is hard to be trained. Wasserstein GAN is intended to improve\nGANs' training by adopting a smooth metric for measuring the distance between\ntwo probability distributions.\n", "versions": [{"version": "v1", "created": "Thu, 18 Apr 2019 20:15:08 GMT"}], "update_date": "2019-04-22", "authors_parsed": [["Weng", "Lilian", ""]]}, {"id": "1904.09007", "submitter": "Nico Engel", "authors": "Nico Engel, Stefan Hoermann, Markus Horn, Vasileios Belagiannis, Klaus\n  Dietmayer", "title": "DeepLocalization: Landmark-based Self-Localization with Deep Neural\n  Networks", "comments": "Accepted for publication by the IEEE Intelligent Transportation\n  Systems Conference (ITSC 2019), Auckland, New Zealand", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.CV cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We address the problem of vehicle self-localization from multi-modal sensor\ninformation and a reference map. The map is generated off-line by extracting\nlandmarks from the vehicle's field of view, while the measurements are\ncollected similarly on the fly. Our goal is to determine the autonomous\nvehicle's pose from the landmark measurements and map landmarks. To learn this\nmapping, we propose DeepLocalization, a deep neural network that regresses the\nvehicle's translation and rotation parameters from unordered and dynamic input\nlandmarks. The proposed network architecture is robust to changes of the\ndynamic environment and can cope with a small number of extracted landmarks.\nDuring the training process we rely on synthetically generated ground-truth. In\nour experiments, we evaluate two inference approaches in real-world scenarios.\nWe show that DeepLocalization can be combined with regular GPS signals and\nfiltering algorithms such as the extended Kalman filter. Our approach achieves\nstate-of-the-art accuracy and is about ten times faster than the related work.\n", "versions": [{"version": "v1", "created": "Thu, 18 Apr 2019 20:41:10 GMT"}, {"version": "v2", "created": "Fri, 19 Jul 2019 09:24:45 GMT"}], "update_date": "2019-07-22", "authors_parsed": [["Engel", "Nico", ""], ["Hoermann", "Stefan", ""], ["Horn", "Markus", ""], ["Belagiannis", "Vasileios", ""], ["Dietmayer", "Klaus", ""]]}, {"id": "1904.09014", "submitter": "Travis Dick", "authors": "Maria-Florina Balcan, Travis Dick, Wesley Pegden", "title": "Semi-bandit Optimization in the Dispersed Setting", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The goal of data-driven algorithm design is to obtain high-performing\nalgorithms for specific application domains using machine learning and data.\nAcross many fields in AI, science, and engineering, practitioners will often\nfix a family of parameterized algorithms and then optimize those parameters to\nobtain good performance on example instances from the application domain. In\nthe online setting, we must choose algorithm parameters for each instance as\nthey arrive, and our goal is to be competitive with the best fixed algorithm in\nhindsight.\n  There are two major challenges in online data-driven algorithm design. First,\nit can be computationally expensive to evaluate the loss functions that map\nalgorithm parameters to performance, which often require the learner to run a\ncombinatorial algorithm to measure its performance. Second, the losses can be\nextremely volatile and have sharp discontinuities. However, we show that in\nmany applications, evaluating the loss function for one algorithm choice can\nsometimes reveal the loss for a range of similar algorithms, essentially for\nfree. We develop online optimization algorithms capable of using this kind of\nextra information by working in the semi-bandit feedback setting. Our\nalgorithms achieve regret bounds that are essentially as good as algorithms\nunder full-information feedback and are significantly more computationally\nefficient. We apply our semi-bandit results to obtain the first provable\nguarantees for data-driven algorithm design for linkage-based clustering and we\nimprove the best regret bounds for designing greedy knapsack algorithms.\n", "versions": [{"version": "v1", "created": "Thu, 18 Apr 2019 21:13:31 GMT"}, {"version": "v2", "created": "Tue, 9 Jul 2019 21:38:28 GMT"}, {"version": "v3", "created": "Mon, 21 Dec 2020 17:11:56 GMT"}], "update_date": "2020-12-22", "authors_parsed": [["Balcan", "Maria-Florina", ""], ["Dick", "Travis", ""], ["Pegden", "Wesley", ""]]}, {"id": "1904.09019", "submitter": "Ferran Alet", "authors": "Ferran Alet, Adarsh K. Jeewajee, Maria Bauza, Alberto Rodriguez, Tomas\n  Lozano-Perez, Leslie Pack Kaelbling", "title": "Graph Element Networks: adaptive, structured computation and memory", "comments": "Accepted to ICML 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We explore the use of graph neural networks (GNNs) to model spatial processes\nin which there is no a priori graphical structure. Similar to finite element\nanalysis, we assign nodes of a GNN to spatial locations and use a computational\nprocess defined on the graph to model the relationship between an initial\nfunction defined over a space and a resulting function in the same space. We\nuse GNNs as a computational substrate, and show that the locations of the nodes\nin space as well as their connectivity can be optimized to focus on the most\ncomplex parts of the space. Moreover, this representational strategy allows the\nlearned input-output relationship to generalize over the size of the underlying\nspace and run the same model at different levels of precision, trading\ncomputation for accuracy. We demonstrate this method on a traditional PDE\nproblem, a physical prediction problem from robotics, and learning to predict\nscene images from novel viewpoints.\n", "versions": [{"version": "v1", "created": "Thu, 18 Apr 2019 21:29:02 GMT"}, {"version": "v2", "created": "Fri, 3 May 2019 06:27:38 GMT"}, {"version": "v3", "created": "Mon, 13 May 2019 19:41:04 GMT"}, {"version": "v4", "created": "Wed, 19 Jun 2019 21:00:38 GMT"}, {"version": "v5", "created": "Sun, 17 Nov 2019 16:08:04 GMT"}], "update_date": "2019-11-19", "authors_parsed": [["Alet", "Ferran", ""], ["Jeewajee", "Adarsh K.", ""], ["Bauza", "Maria", ""], ["Rodriguez", "Alberto", ""], ["Lozano-Perez", "Tomas", ""], ["Kaelbling", "Leslie Pack", ""]]}, {"id": "1904.09023", "submitter": "Alex Kearney", "authors": "Alex Kearney, Oliver Oxton", "title": "Making Meaning: Semiotics Within Predictive Knowledge Architectures", "comments": "Accepted to RLDM 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Within Reinforcement Learning, there is a fledgling approach to\nconceptualizing the environment in terms of predictions. Central to this\npredictive approach is the assertion that it is possible to construct\nontologies in terms of predictions about sensation, behaviour, and time---to\ncategorize the world into entities which express all aspects of the world using\nonly predictions. This construction of ontologies is integral to predictive\napproaches to machine knowledge where objects are described exclusively in\nterms of how they are perceived. In this paper, we ground the Pericean model of\nsemiotics in terms of Reinforcement Learning Methods, describing Peirce's Three\nCategories in the notation of General Value Functions. Using the Peircean model\nof semiotics, we demonstrate that predictions alone are insufficient to\nconstruct an ontology; however, we identify predictions as being integral to\nthe meaning-making process. Moreover, we discuss how predictive knowledge\nprovides a particularly stable foundation for semiosis\\textemdash the process\nof making meaning\\textemdash and suggest a possible avenue of research to\ndesign algorithmic methods which construct semantics and meaning using\npredictions.\n", "versions": [{"version": "v1", "created": "Thu, 18 Apr 2019 22:12:01 GMT"}], "update_date": "2019-04-22", "authors_parsed": [["Kearney", "Alex", ""], ["Oxton", "Oliver", ""]]}, {"id": "1904.09024", "submitter": "Alex Kearney", "authors": "Alex Kearney, Patrick M. Pilarski", "title": "When is a Prediction Knowledge?", "comments": "Accepted to RLDM 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Within Reinforcement Learning, there is a growing collection of research\nwhich aims to express all of an agent's knowledge of the world through\npredictions about sensation, behaviour, and time. This work can be seen not\nonly as a collection of architectural proposals, but also as the beginnings of\na theory of machine knowledge in reinforcement learning. Recent work has\nexpanded what can be expressed using predictions, and developed applications\nwhich use predictions to inform decision-making on a variety of synthetic and\nreal-world problems. While promising, we here suggest that the notion of\npredictions as knowledge in reinforcement learning is as yet underdeveloped:\nsome work explicitly refers to predictions as knowledge, what the requirements\nare for considering a prediction to be knowledge have yet to be well explored.\nThis specification of the necessary and sufficient conditions of knowledge is\nimportant; even if claims about the nature of knowledge are left implicit in\ntechnical proposals, the underlying assumptions of such claims have\nconsequences for the systems we design. These consequences manifest in both the\nway we choose to structure predictive knowledge architectures, and how we\nevaluate them. In this paper, we take a first step to formalizing predictive\nknowledge by discussing the relationship of predictive knowledge learning\nmethods to existing theories of knowledge in epistemology. Specifically, we\nexplore the relationships between Generalized Value Functions and epistemic\nnotions of Justification and Truth.\n", "versions": [{"version": "v1", "created": "Thu, 18 Apr 2019 22:12:49 GMT"}], "update_date": "2019-04-22", "authors_parsed": [["Kearney", "Alex", ""], ["Pilarski", "Patrick M.", ""]]}, {"id": "1904.09029", "submitter": "Spyros Chatzivasileiadis", "authors": "Jos\\'e-Mar\\'ia Hidalgo-Arteaga, Fiodar Hancharou, Florian Thams,\n  Spyros Chatzivasileiadis", "title": "Deep Learning for Power System Security Assessment", "comments": "Accepted at IEEE Powertech 2019, Milan, Italy", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Security assessment is among the most fundamental functions of power system\noperator. The sheer complexity of power systems exceeding a few buses, however,\nmakes it an extremely computationally demanding task. The emergence of deep\nlearning methods that are able to handle immense amounts of data, and infer\nvaluable information appears as a promising alternative. This paper has two\nmain contributions. First, inspired by the remarkable performance of\nconvolutional neural networks for image processing, we represent for the first\ntime power system snapshots as 2-dimensional images, thus taking advantage of\nthe wide range of deep learning methods available for image processing. Second,\nwe train deep neural networks on a large database for the NESTA 162-bus system\nto assess both N-1 security and small-signal stability. We find that our\napproach is over 255 times faster than a standard small-signal stability\nassessment, and it can correctly determine unsafe points with over 99%\naccuracy.\n", "versions": [{"version": "v1", "created": "Sun, 31 Mar 2019 20:07:44 GMT"}], "update_date": "2019-04-22", "authors_parsed": [["Hidalgo-Arteaga", "Jos\u00e9-Mar\u00eda", ""], ["Hancharou", "Fiodar", ""], ["Thams", "Florian", ""], ["Chatzivasileiadis", "Spyros", ""]]}, {"id": "1904.09031", "submitter": "Yuwei Zhang", "authors": "Yuwei Zhang, Xin Wu, Chenyang Gu, Yueqi Xie", "title": "Predict Future Sales using Ensembled Random Forests", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This is a method report for the Kaggle data competition 'Predict future\nsales'. In this paper, we propose a rather simple approach to future sales\npredicting based on feature engineering, Random Forest Regressor and ensemble\nlearning. Its performance turned out to exceed many of the conventional methods\nand get final score 0.88186, representing root mean squared error. As of this\nwriting, our model ranked 5th on the leaderboard. (till 8.5.2018)\n", "versions": [{"version": "v1", "created": "Wed, 17 Apr 2019 07:55:35 GMT"}], "update_date": "2019-04-22", "authors_parsed": [["Zhang", "Yuwei", ""], ["Wu", "Xin", ""], ["Gu", "Chenyang", ""], ["Xie", "Yueqi", ""]]}, {"id": "1904.09035", "submitter": "Bin Wang", "authors": "Bin Wang, Yanan Sun, Bing Xue and Mengjie Zhang", "title": "Evolving Deep Neural Networks by Multi-objective Particle Swarm\n  Optimization for Image Classification", "comments": "conditionally accepted by gecco2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In recent years, convolutional neural networks (CNNs) have become deeper in\norder to achieve better classification accuracy in image classification.\nHowever, it is difficult to deploy the state-of-the-art deep CNNs for\nindustrial use due to the difficulty of manually fine-tuning the\nhyperparameters and the trade-off between classification accuracy and\ncomputational cost. This paper proposes a novel multi-objective optimization\nmethod for evolving state-of-the-art deep CNNs in real-life applications, which\nautomatically evolves the non-dominant solutions at the Pareto front. Three\nmajor contributions are made: Firstly, a new encoding strategy is designed to\nencode one of the best state-of-the-art CNNs; With the classification accuracy\nand the number of floating point operations as the two objectives, a\nmulti-objective particle swarm optimization method is developed to evolve the\nnon-dominant solutions; Last but not least, a new infrastructure is designed to\nboost the experiments by concurrently running the experiments on multiple GPUs\nacross multiple machines, and a Python library is developed and released to\nmanage the infrastructure. The experimental results demonstrate that the\nnon-dominant solutions found by the proposed algorithm form a clear Pareto\nfront, and the proposed infrastructure is able to almost linearly reduce the\nrunning time.\n", "versions": [{"version": "v1", "created": "Thu, 21 Mar 2019 02:55:14 GMT"}, {"version": "v2", "created": "Mon, 22 Apr 2019 04:07:17 GMT"}], "update_date": "2019-04-23", "authors_parsed": [["Wang", "Bin", ""], ["Sun", "Yanan", ""], ["Xue", "Bing", ""], ["Zhang", "Mengjie", ""]]}, {"id": "1904.09037", "submitter": "Chu Wang", "authors": "Chu Wang and Lei Tang and Yang Lu and Shujun Bian and Hirohisa Fujita\n  and Da Zhang and Zuohua Zhang and Yongning Wu", "title": "ProductNet: a Collection of High-Quality Datasets for Product\n  Representation Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CL cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  ProductNet is a collection of high-quality product datasets for better\nproduct understanding. Motivated by ImageNet, ProductNet aims at supporting\nproduct representation learning by curating product datasets of high quality\nwith properly chosen taxonomy. In this paper, the two goals of building\nhigh-quality product datasets and learning product representation support each\nother in an iterative fashion: the product embedding is obtained via a\nmulti-modal deep neural network (master model) designed to leverage product\nimage and catalog information; and in return, the embedding is utilized via\nactive learning (local model) to vastly accelerate the annotation process. For\nthe labeled data, the proposed master model yields high categorization accuracy\n(94.7% top-1 accuracy for 1240 classes), which can be used as search indices,\npartition keys, and input features for machine learning models. The product\nembedding, as well as the fined-tuned master model for a specific business\ntask, can also be used for various transfer learning tasks.\n", "versions": [{"version": "v1", "created": "Thu, 18 Apr 2019 23:17:07 GMT"}], "update_date": "2019-04-22", "authors_parsed": [["Wang", "Chu", ""], ["Tang", "Lei", ""], ["Lu", "Yang", ""], ["Bian", "Shujun", ""], ["Fujita", "Hirohisa", ""], ["Zhang", "Da", ""], ["Zhang", "Zuohua", ""], ["Wu", "Yongning", ""]]}, {"id": "1904.09044", "submitter": "Subhashis Hazarika", "authors": "Subhashis Hazarika, Haoyu Li, Ko-Chih Wang, Han-Wei Shen and\n  Ching-Shan Chou", "title": "NNVA: Neural Network Assisted Visual Analysis of Yeast Cell Polarization\n  Simulation", "comments": "Published at IEEE Transactions on Visualization and Computer Graphics", "journal-ref": null, "doi": "10.1109/TVCG.2019.2934591", "report-no": null, "categories": "cs.HC cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Complex computational models are often designed to simulate real-world\nphysical phenomena in many scientific disciplines. However, these simulation\nmodels tend to be computationally very expensive and involve a large number of\nsimulation input parameters which need to be analyzed and properly calibrated\nbefore the models can be applied for real scientific studies. We propose a\nvisual analysis system to facilitate interactive exploratory analysis of\nhigh-dimensional input parameter space for a complex yeast cell polarization\nsimulation. The proposed system can assist the computational biologists, who\ndesigned the simulation model, to visually calibrate the input parameters by\nmodifying the parameter values and immediately visualizing the predicted\nsimulation outcome without having the need to run the original expensive\nsimulation for every instance. Our proposed visual analysis system is driven by\na trained neural network-based surrogate model as the backend analysis\nframework. Surrogate models are widely used in the field of simulation sciences\nto efficiently analyze computationally expensive simulation models. In this\nwork, we demonstrate the advantage of using neural networks as surrogate models\nfor visual analysis by incorporating some of the recent advances in the field\nof uncertainty quantification, interpretability and explainability of neural\nnetwork-based models. We utilize the trained network to perform interactive\nparameter sensitivity analysis of the original simulation at multiple\nlevels-of-detail as well as recommend optimal parameter configurations using\nthe activation maximization framework of neural networks. We also facilitate\ndetail analysis of the trained network to extract useful insights about the\nsimulation model, learned by the network, during the training process.\n", "versions": [{"version": "v1", "created": "Fri, 19 Apr 2019 00:36:27 GMT"}, {"version": "v2", "created": "Wed, 31 Jul 2019 03:21:57 GMT"}, {"version": "v3", "created": "Wed, 16 Oct 2019 20:41:28 GMT"}], "update_date": "2019-10-18", "authors_parsed": [["Hazarika", "Subhashis", ""], ["Li", "Haoyu", ""], ["Wang", "Ko-Chih", ""], ["Shen", "Han-Wei", ""], ["Chou", "Ching-Shan", ""]]}, {"id": "1904.09056", "submitter": "Sudeep Salgia", "authors": "Boshuang Huang, Sudeep Salgia, Qing Zhao", "title": "Disagreement-based Active Learning in Online Settings", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study online active learning for classifying streaming instances within\nthe framework of statistical learning theory. At each time, the learner either\nqueries the label of the current instance or predicts the label based on past\nseen examples. The objective is to minimize the number of queries while\nconstraining the number of prediction errors over a horizon of length $T$. We\ndevelop a disagreement-based online learning algorithm for a general hypothesis\nspace and under the Tsybakov noise. We show that the proposed algorithm has a\nlabel complexity of $O(dT^{\\frac{2-2\\alpha}{2-\\alpha}}\\log^2 T)$ under a\nconstraint of bounded regret in terms of classification errors, where $d$ is\nthe VC dimension of the hypothesis space and $\\alpha$ is the Tsybakov noise\nparameter. We further establish a matching (up to a poly-logarithmic factor)\nlower bound, demonstrating the order optimality of the proposed algorithm. We\naddress the tradeoff between label complexity and regret and show that the\nalgorithm can be modified to operate at a different point on the tradeoff\ncurve.\n", "versions": [{"version": "v1", "created": "Fri, 19 Apr 2019 03:08:34 GMT"}, {"version": "v2", "created": "Wed, 24 Apr 2019 19:35:03 GMT"}, {"version": "v3", "created": "Wed, 9 Oct 2019 20:07:56 GMT"}, {"version": "v4", "created": "Fri, 7 Feb 2020 20:54:04 GMT"}, {"version": "v5", "created": "Mon, 16 Nov 2020 15:29:56 GMT"}], "update_date": "2020-11-17", "authors_parsed": [["Huang", "Boshuang", ""], ["Salgia", "Sudeep", ""], ["Zhao", "Qing", ""]]}, {"id": "1904.09061", "submitter": "Jingwei Liu", "authors": "Jingwei Liu", "title": "Random Fragments Classification of Microbial Marker Clades with\n  Multi-class SVM and N-Best Algorithm", "comments": "17 pages, 59 figurea", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.QM cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Microbial clades modeling is a challenging problem in biology based on\nmicroarray genome sequences, especially in new species gene isolates discovery\nand category. Marker family genome sequences play important roles in describing\nspecific microbial clades within species, a framework of support vector machine\n(SVM) based microbial species classification with N-best algorithm is\nconstructed to classify the centroid marker genome fragments randomly generated\nfrom marker genome sequences on MetaRef. A time series feature extraction\nmethod is proposed by segmenting the centroid gene sequences and mapping into\ndifferent dimensional spaces. Two ways of data splitting are investigated\naccording to random splitting fragments along genome sequence (DI) , or\nseparating genome sequences into two parts (DII).Two strategies of fragments\nrecognition tasks, dimension-by-dimension and sequence--by--sequence, are\ninvestigated. The k-mer size selection, overlap of segmentation and effects of\nrandom split percents are also discussed. Experiments on 12390 maker genome\nsequences belonging to marker families of 17 species from MetaRef show that,\nboth for DI and DII in dimension-by-dimension and sequence-by-sequence\nrecognition, the recognition accuracy rates can achieve above 28\\% in top-1\ncandidate, and above 91\\% in top-10 candidate both on training and testing sets\noverall.\n", "versions": [{"version": "v1", "created": "Fri, 19 Apr 2019 03:21:48 GMT"}], "update_date": "2019-04-22", "authors_parsed": [["Liu", "Jingwei", ""]]}, {"id": "1904.09067", "submitter": "Michael Cogswell", "authors": "Michael Cogswell, Jiasen Lu, Stefan Lee, Devi Parikh, Dhruv Batra", "title": "Emergence of Compositional Language with Deep Generational Transmission", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CL stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent work has studied the emergence of language among deep reinforcement\nlearning agents that must collaborate to solve a task. Of particular interest\nare the factors that cause language to be compositional -- i.e., express\nmeaning by combining words which themselves have meaning. Evolutionary\nlinguists have found that in addition to structural priors like those already\nstudied in deep learning, the dynamics of transmitting language from generation\nto generation contribute significantly to the emergence of compositionality. In\nthis paper, we introduce these cultural evolutionary dynamics into language\nemergence by periodically replacing agents in a population to create a\nknowledge gap, implicitly inducing cultural transmission of language. We show\nthat this implicit cultural transmission encourages the resulting languages to\nexhibit better compositional generalization.\n", "versions": [{"version": "v1", "created": "Fri, 19 Apr 2019 04:09:12 GMT"}, {"version": "v2", "created": "Wed, 27 May 2020 19:54:23 GMT"}], "update_date": "2020-05-29", "authors_parsed": [["Cogswell", "Michael", ""], ["Lu", "Jiasen", ""], ["Lee", "Stefan", ""], ["Parikh", "Devi", ""], ["Batra", "Dhruv", ""]]}, {"id": "1904.09078", "submitter": "Jun-Ho Choi", "authors": "Jun-Ho Choi, Jong-Seok Lee", "title": "EmbraceNet: A robust deep learning architecture for multimodal\n  classification", "comments": "Code available at https://github.com/idearibosome/embracenet", "journal-ref": "Information Fusion 51 (2019) 259-270", "doi": "10.1016/j.inffus.2019.02.010", "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Classification using multimodal data arises in many machine learning\napplications. It is crucial not only to model cross-modal relationship\neffectively but also to ensure robustness against loss of part of data or\nmodalities. In this paper, we propose a novel deep learning-based multimodal\nfusion architecture for classification tasks, which guarantees compatibility\nwith any kind of learning models, deals with cross-modal information carefully,\nand prevents performance degradation due to partial absence of data. We employ\ntwo datasets for multimodal classification tasks, build models based on our\narchitecture and other state-of-the-art models, and analyze their performance\non various situations. The results show that our architecture outperforms the\nother multimodal fusion architectures when some parts of data are not\navailable.\n", "versions": [{"version": "v1", "created": "Fri, 19 Apr 2019 04:46:29 GMT"}], "update_date": "2019-04-22", "authors_parsed": [["Choi", "Jun-Ho", ""], ["Lee", "Jong-Seok", ""]]}, {"id": "1904.09080", "submitter": "Paul Valiant", "authors": "Guy Blanc, Neha Gupta, Gregory Valiant, Paul Valiant", "title": "Implicit regularization for deep neural networks driven by an\n  Ornstein-Uhlenbeck like process", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider networks, trained via stochastic gradient descent to minimize\n$\\ell_2$ loss, with the training labels perturbed by independent noise at each\niteration. We characterize the behavior of the training dynamics near any\nparameter vector that achieves zero training error, in terms of an implicit\nregularization term corresponding to the sum over the data points, of the\nsquared $\\ell_2$ norm of the gradient of the model with respect to the\nparameter vector, evaluated at each data point. This holds for networks of any\nconnectivity, width, depth, and choice of activation function. We interpret\nthis implicit regularization term for three simple settings: matrix sensing,\ntwo layer ReLU networks trained on one-dimensional data, and two layer networks\nwith sigmoid activations trained on a single datapoint. For these settings, we\nshow why this new and general implicit regularization effect drives the\nnetworks towards \"simple\" models.\n", "versions": [{"version": "v1", "created": "Fri, 19 Apr 2019 04:58:36 GMT"}, {"version": "v2", "created": "Wed, 22 Jul 2020 17:59:18 GMT"}], "update_date": "2020-07-23", "authors_parsed": [["Blanc", "Guy", ""], ["Gupta", "Neha", ""], ["Valiant", "Gregory", ""], ["Valiant", "Paul", ""]]}, {"id": "1904.09081", "submitter": "Yingtian Zou", "authors": "Yingtian Zou, Jiashi Feng", "title": "Hierarchical Meta Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Meta learning is a promising solution to few-shot learning problems. However,\nexisting meta learning methods are restricted to the scenarios where training\nand application tasks share the same out-put structure. To obtain a meta model\napplicable to the tasks with new structures, it is required to collect new\ntraining data and repeat the time-consuming meta training procedure. This makes\nthem inefficient or even inapplicable in learning to solve heterogeneous\nfew-shot learning tasks. We thus develop a novel and principled\nHierarchicalMeta Learning (HML) method. Different from existing methods that\nonly focus on optimizing the adaptability of a meta model to similar tasks, HML\nalso explicitly optimizes its generalizability across heterogeneous tasks. To\nthis end, HML first factorizes a set of similar training tasks into\nheterogeneous ones and trains the meta model over them at two levels to\nmaximize adaptation and generalization performance respectively. The resultant\nmodel can then directly generalize to new tasks. Extensive experiments on\nfew-shot classification and regression problems clearly demonstrate the\nsuperiority of HML over fine-tuning and state-of-the-art meta learning\napproaches in terms of generalization across heterogeneous tasks.\n", "versions": [{"version": "v1", "created": "Fri, 19 Apr 2019 05:12:57 GMT"}], "update_date": "2019-04-22", "authors_parsed": [["Zou", "Yingtian", ""], ["Feng", "Jiashi", ""]]}, {"id": "1904.09090", "submitter": "Shayan Hassantabar", "authors": "Shayan Hassantabar, Zeyu Wang, Niraj K. Jha", "title": "SCANN: Synthesis of Compact and Accurate Neural Networks", "comments": "13 pages, 8 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Deep neural networks (DNNs) have become the driving force behind recent\nartificial intelligence (AI) research. An important problem with implementing a\nneural network is the design of its architecture. Typically, such an\narchitecture is obtained manually by exploring its hyperparameter space and\nkept fixed during training. This approach is time-consuming and inefficient.\nAnother issue is that modern neural networks often contain millions of\nparameters, whereas many applications and devices require small inference\nmodels. However, efforts to migrate DNNs to such devices typically entail a\nsignificant loss of classification accuracy. To address these challenges, we\npropose a two-step neural network synthesis methodology, called DR+SCANN, that\ncombines two complementary approaches to design compact and accurate DNNs. At\nthe core of our framework is the SCANN methodology that uses three basic\narchitecture-changing operations, namely connection growth, neuron growth, and\nconnection pruning, to synthesize feed-forward architectures with arbitrary\nstructure. SCANN encapsulates three synthesis methodologies that apply a\nrepeated grow-and-prune paradigm to three architectural starting points.\nDR+SCANN combines the SCANN methodology with dataset dimensionality reduction\nto alleviate the curse of dimensionality. We demonstrate the efficacy of SCANN\nand DR+SCANN on various image and non-image datasets. We evaluate SCANN on\nMNIST and ImageNet benchmarks. In addition, we also evaluate the efficacy of\nusing dimensionality reduction alongside SCANN (DR+SCANN) on nine small to\nmedium-size datasets. We also show that our synthesis methodology yields neural\nnetworks that are much better at navigating the accuracy vs. energy efficiency\nspace. This would enable neural network-based inference even on\nInternet-of-Things sensors.\n", "versions": [{"version": "v1", "created": "Fri, 19 Apr 2019 06:26:03 GMT"}, {"version": "v2", "created": "Mon, 29 Mar 2021 03:02:43 GMT"}], "update_date": "2021-03-30", "authors_parsed": [["Hassantabar", "Shayan", ""], ["Wang", "Zeyu", ""], ["Jha", "Niraj K.", ""]]}, {"id": "1904.09096", "submitter": "Ricardo Pio Monti", "authors": "Ricardo Pio Monti, Kun Zhang, Aapo Hyvarinen", "title": "Causal Discovery with General Non-Linear Relationships Using Non-Linear\n  ICA", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the problem of inferring causal relationships between two or more\npassively observed variables. While the problem of such causal discovery has\nbeen extensively studied especially in the bivariate setting, the majority of\ncurrent methods assume a linear causal relationship, and the few methods which\nconsider non-linear dependencies usually make the assumption of additive noise.\nHere, we propose a framework through which we can perform causal discovery in\nthe presence of general non-linear relationships. The proposed method is based\non recent progress in non-linear independent component analysis and exploits\nthe non-stationarity of observations in order to recover the underlying sources\nor latent disturbances. We show rigorously that in the case of bivariate causal\ndiscovery, such non-linear ICA can be used to infer the causal direction via a\nseries of independence tests. We further propose an alternative measure of\ncausal direction based on asymptotic approximations to the likelihood ratio, as\nwell as an extension to multivariate causal discovery. We demonstrate the\ncapabilities of the proposed method via a series of simulation studies and\nconclude with an application to neuroimaging data.\n", "versions": [{"version": "v1", "created": "Fri, 19 Apr 2019 06:44:53 GMT"}], "update_date": "2019-04-22", "authors_parsed": [["Monti", "Ricardo Pio", ""], ["Zhang", "Kun", ""], ["Hyvarinen", "Aapo", ""]]}, {"id": "1904.09098", "submitter": "Ashutosh Pednekar", "authors": "Ashutosh Mahesh Pednekar", "title": "Optimal initialization of K-means using Particle Swarm Optimization", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper proposes the use of an optimization algorithm, namely PSO to\ndecide the initial centroids in K-means, to eventually get better accuracy. The\nvectorized notation of the optimal centroids can be thought of as entities in\nan optimization space, where the accuracy of K-means over a random subset of\nthe data could act as a fitness measure. The resultant optimal vector can be\nused as the initial centroids for K-means.\n", "versions": [{"version": "v1", "created": "Fri, 19 Apr 2019 06:59:10 GMT"}], "update_date": "2019-04-22", "authors_parsed": [["Pednekar", "Ashutosh Mahesh", ""]]}, {"id": "1904.09105", "submitter": "Yiwen Guo", "authors": "Yiwen Guo, Ming Lu, Wangmeng Zuo, Changshui Zhang, Yurong Chen", "title": "Deep Likelihood Network for Image Restoration with Multiple Degradation\n  Levels", "comments": "Accepted by IEEE Transactions on Image Processing; 13 pages, 6\n  figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Convolutional neural networks have been proven effective in a variety of\nimage restoration tasks. Most state-of-the-art solutions, however, are trained\nusing images with a single particular degradation level, and their performance\ndeteriorates drastically when applied to other degradation settings. In this\npaper, we propose deep likelihood network (DL-Net), aiming at generalizing\noff-the-shelf image restoration networks to succeed over a spectrum of\ndegradation levels. We slightly modify an off-the-shelf network by appending a\nsimple recursive module, which is derived from a fidelity term, for\ndisentangling the computation for multiple degradation levels. Extensive\nexperimental results on image inpainting, interpolation, and super-resolution\nshow the effectiveness of our DL-Net.\n", "versions": [{"version": "v1", "created": "Fri, 19 Apr 2019 07:45:28 GMT"}, {"version": "v2", "created": "Mon, 11 Nov 2019 06:25:48 GMT"}, {"version": "v3", "created": "Tue, 19 Nov 2019 01:39:20 GMT"}, {"version": "v4", "created": "Sun, 10 Jan 2021 02:07:26 GMT"}], "update_date": "2021-01-12", "authors_parsed": [["Guo", "Yiwen", ""], ["Lu", "Ming", ""], ["Zuo", "Wangmeng", ""], ["Zhang", "Changshui", ""], ["Chen", "Yurong", ""]]}, {"id": "1904.09109", "submitter": "Hye Won Chung", "authors": "Youngjae Min and Hye Won Chung", "title": "Shallow Neural Network can Perfectly Classify an Object following\n  Separable Probability Distribution", "comments": "5 pages. To be presented at the 2019 IEEE International Symposium on\n  Information Theory (ISIT)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.IT math.IT stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Guiding the design of neural networks is of great importance to save enormous\nresources consumed on empirical decisions of architectural parameters. This\npaper constructs shallow sigmoid-type neural networks that achieve 100%\naccuracy in classification for datasets following a linear separability\ncondition. The separability condition in this work is more relaxed than the\nwidely used linear separability. Moreover, the constructed neural network\nguarantees perfect classification for any datasets sampled from a separable\nprobability distribution. This generalization capability comes from the\nsaturation of sigmoid function that exploits small margins near the boundaries\nof intervals formed by the separable probability distribution.\n", "versions": [{"version": "v1", "created": "Fri, 19 Apr 2019 08:00:11 GMT"}], "update_date": "2019-04-22", "authors_parsed": [["Min", "Youngjae", ""], ["Chung", "Hye Won", ""]]}, {"id": "1904.09117", "submitter": "Pengpeng Liu", "authors": "Pengpeng Liu, Michael Lyu, Irwin King, Jia Xu", "title": "SelFlow: Self-Supervised Learning of Optical Flow", "comments": "Published at the Conference on Computer Vision and Pattern\n  Recognition (CVPR 2019)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a self-supervised learning approach for optical flow. Our method\ndistills reliable flow estimations from non-occluded pixels, and uses these\npredictions as ground truth to learn optical flow for hallucinated occlusions.\nWe further design a simple CNN to utilize temporal information from multiple\nframes for better flow estimation. These two principles lead to an approach\nthat yields the best performance for unsupervised optical flow learning on the\nchallenging benchmarks including MPI Sintel, KITTI 2012 and 2015. More notably,\nour self-supervised pre-trained model provides an excellent initialization for\nsupervised fine-tuning. Our fine-tuned models achieve state-of-the-art results\non all three datasets. At the time of writing, we achieve EPE=4.26 on the\nSintel benchmark, outperforming all submitted methods.\n", "versions": [{"version": "v1", "created": "Fri, 19 Apr 2019 08:21:16 GMT"}], "update_date": "2019-04-22", "authors_parsed": [["Liu", "Pengpeng", ""], ["Lyu", "Michael", ""], ["King", "Irwin", ""], ["Xu", "Jia", ""]]}, {"id": "1904.09122", "submitter": "Soufian Jebbara", "authors": "Soufian Jebbara and Philipp Cimiano", "title": "Zero-Shot Cross-Lingual Opinion Target Extraction", "comments": "Proceedings of the 2019 Conference of the North American Chapter of\n  the Association for Computational Linguistics: Human Language Technologies", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Aspect-based sentiment analysis involves the recognition of so called opinion\ntarget expressions (OTEs). To automatically extract OTEs, supervised learning\nalgorithms are usually employed which are trained on manually annotated\ncorpora. The creation of these corpora is labor-intensive and sufficiently\nlarge datasets are therefore usually only available for a very narrow selection\nof languages and domains. In this work, we address the lack of available\nannotated data for specific languages by proposing a zero-shot cross-lingual\napproach for the extraction of opinion target expressions. We leverage\nmultilingual word embeddings that share a common vector space across various\nlanguages and incorporate these into a convolutional neural network\narchitecture for OTE extraction. Our experiments with 5 languages give\npromising results: We can successfully train a model on annotated data of a\nsource language and perform accurate prediction on a target language without\never using any annotated samples in that target language. Depending on the\nsource and target language pairs, we reach performances in a zero-shot regime\nof up to 77% of a model trained on target language data. Furthermore, we can\nincrease this performance up to 87% of a baseline model trained on target\nlanguage data by performing cross-lingual learning from multiple source\nlanguages.\n", "versions": [{"version": "v1", "created": "Fri, 19 Apr 2019 08:59:13 GMT"}], "update_date": "2019-04-22", "authors_parsed": [["Jebbara", "Soufian", ""], ["Cimiano", "Philipp", ""]]}, {"id": "1904.09135", "submitter": "Claus Aranha", "authors": "Fabio Henrique Kiyoiti dos Santos Tanaka, Claus Aranha", "title": "Data Augmentation Using GANs", "comments": "Submitted for ACML 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we propose the use of Generative Adversarial Networks (GAN) to\ngenerate artificial training data for machine learning tasks. The generation of\nartificial training data can be extremely useful in situations such as\nimbalanced data sets, performing a role similar to SMOTE or ADASYN. It is also\nuseful when the data contains sensitive information, and it is desirable to\navoid using the original data set as much as possible (example: medical data).\nWe test our proposal on benchmark data sets using different network\narchitectures, and show that a Decision Tree (DT) classifier trained using the\ntraining data generated by the GAN reached the same, (and surprisingly\nsometimes better), accuracy and recall than a DT trained on the original data\nset.\n", "versions": [{"version": "v1", "created": "Fri, 19 Apr 2019 10:05:33 GMT"}], "update_date": "2019-04-22", "authors_parsed": [["Tanaka", "Fabio Henrique Kiyoiti dos Santos", ""], ["Aranha", "Claus", ""]]}, {"id": "1904.09140", "submitter": "Dennis Ludl", "authors": "Dennis Ludl, Thomas Gulde and Crist\\'obal Curio", "title": "Simple yet efficient real-time pose-based action recognition", "comments": "Submitted to IEEE Intelligent Transportation Systems Conference\n  (ITSC) 2019. Code will be available soon at\n  https://github.com/noboevbo/ehpi_action_recognition", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recognizing human actions is a core challenge for autonomous systems as they\ndirectly share the same space with humans. Systems must be able to recognize\nand assess human actions in real-time. In order to train corresponding\ndata-driven algorithms, a significant amount of annotated training data is\nrequired. We demonstrated a pipeline to detect humans, estimate their pose,\ntrack them over time and recognize their actions in real-time with standard\nmonocular camera sensors. For action recognition, we encode the human pose into\na new data format called Encoded Human Pose Image (EHPI) that can then be\nclassified using standard methods from the computer vision community. With this\nsimple procedure we achieve competitive state-of-the-art performance in\npose-based action detection and can ensure real-time performance. In addition,\nwe show a use case in the context of autonomous driving to demonstrate how such\na system can be trained to recognize human actions using simulation data.\n", "versions": [{"version": "v1", "created": "Fri, 19 Apr 2019 10:36:28 GMT"}], "update_date": "2019-04-22", "authors_parsed": [["Ludl", "Dennis", ""], ["Gulde", "Thomas", ""], ["Curio", "Crist\u00f3bal", ""]]}, {"id": "1904.09149", "submitter": "Baoyun Peng", "authors": "Xiao Jin, Baoyun Peng, Yichao Wu, Yu Liu, Jiaheng Liu, Ding Liang,\n  Junjie Yan, Xiaolin Hu", "title": "Knowledge Distillation via Route Constrained Optimization", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Distillation-based learning boosts the performance of the miniaturized neural\nnetwork based on the hypothesis that the representation of a teacher model can\nbe used as structured and relatively weak supervision, and thus would be easily\nlearned by a miniaturized model. However, we find that the representation of a\nconverged heavy model is still a strong constraint for training a small student\nmodel, which leads to a high lower bound of congruence loss. In this work,\ninspired by curriculum learning we consider the knowledge distillation from the\nperspective of curriculum learning by routing. Instead of supervising the\nstudent model with a converged teacher model, we supervised it with some anchor\npoints selected from the route in parameter space that the teacher model passed\nby, as we called route constrained optimization (RCO). We experimentally\ndemonstrate this simple operation greatly reduces the lower bound of congruence\nloss for knowledge distillation, hint and mimicking learning. On close-set\nclassification tasks like CIFAR100 and ImageNet, RCO improves knowledge\ndistillation by 2.14% and 1.5% respectively. For the sake of evaluating the\ngeneralization, we also test RCO on the open-set face recognition task\nMegaFace.\n", "versions": [{"version": "v1", "created": "Fri, 19 Apr 2019 11:24:20 GMT"}], "update_date": "2019-04-22", "authors_parsed": [["Jin", "Xiao", ""], ["Peng", "Baoyun", ""], ["Wu", "Yichao", ""], ["Liu", "Yu", ""], ["Liu", "Jiaheng", ""], ["Liang", "Ding", ""], ["Yan", "Junjie", ""], ["Hu", "Xiaolin", ""]]}, {"id": "1904.09162", "submitter": "Tong Mu", "authors": "Tong Mu, Karan Goel, Emma Brunskill", "title": "PLOTS: Procedure Learning from Observations using Subtask Structure", "comments": "To appear in the proceedings of AAMAS 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.MA stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In many cases an intelligent agent may want to learn how to mimic a single\nobserved demonstrated trajectory. In this work we consider how to perform such\nprocedural learning from observation, which could help to enable agents to\nbetter use the enormous set of video data on observation sequences. Our\napproach exploits the properties of this setting to incrementally build an open\nloop action plan that can yield the desired subsequence, and can be used in\nboth Markov and partially observable Markov domains. In addition, procedures\ncommonly involve repeated extended temporal action subsequences. Our method\noptimistically explores actions to leverage potential repeated structure in the\nprocedure. In comparing to some state-of-the-art approaches we find that our\nexplicit procedural learning from observation method is about 100 times faster\nthan policy-gradient based approaches that learn a stochastic policy and is\nfaster than model based approaches as well. We also find that performing\noptimistic action selection yields substantial speed ups when latent dynamical\nstructure is present.\n", "versions": [{"version": "v1", "created": "Wed, 17 Apr 2019 20:57:11 GMT"}], "update_date": "2019-04-22", "authors_parsed": [["Mu", "Tong", ""], ["Goel", "Karan", ""], ["Brunskill", "Emma", ""]]}, {"id": "1904.09163", "submitter": "David Sigtermans", "authors": "David Sigtermans", "title": "Transfer Entropy: where Shannon meets Turing", "comments": "4 pages, 1 figure", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IT cs.LG math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Transfer entropy is capable of capturing nonlinear source-destination\nrelations between multi-variate time series. It is a measure of association\nbetween source data that are transformed into destination data via a set of\nlinear transformations between their probability mass functions. The resulting\ntensor formalism is used to show that in specific cases, e.g., in the case the\nsystem consists of three stochastic processes, bivariate analysis suffices to\ndistinguish true relations from false relations. This allows us to determine\nthe causal structure as far as encoded in the probability mass functions of\nnoisy data. The tensor formalism was also used to derive the Data Processing\nInequality for transfer entropy.\n", "versions": [{"version": "v1", "created": "Fri, 19 Apr 2019 12:24:44 GMT"}, {"version": "v2", "created": "Fri, 17 May 2019 17:56:03 GMT"}, {"version": "v3", "created": "Sat, 25 May 2019 14:11:24 GMT"}], "update_date": "2019-05-28", "authors_parsed": [["Sigtermans", "David", ""]]}, {"id": "1904.09187", "submitter": "Tianlin Liu", "authors": "Tianlin Liu, Lyle Ungar, Jo\\~ao Sedoc", "title": "Continual Learning for Sentence Representations Using Conceptors", "comments": "Accepted by NAACL-2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Distributed representations of sentences have become ubiquitous in natural\nlanguage processing tasks. In this paper, we consider a continual learning\nscenario for sentence representations: Given a sequence of corpora, we aim to\noptimize the sentence encoder with respect to the new corpus while maintaining\nits accuracy on the old corpora. To address this problem, we propose to\ninitialize sentence encoders with the help of corpus-independent features, and\nthen sequentially update sentence encoders using Boolean operations of\nconceptor matrices to learn corpus-dependent features. We evaluate our approach\non semantic textual similarity tasks and show that our proposed sentence\nencoder can continually learn features from new corpora while retaining its\ncompetence on previously encountered corpora.\n", "versions": [{"version": "v1", "created": "Thu, 18 Apr 2019 06:37:15 GMT"}], "update_date": "2019-04-22", "authors_parsed": [["Liu", "Tianlin", ""], ["Ungar", "Lyle", ""], ["Sedoc", "Jo\u00e3o", ""]]}, {"id": "1904.09211", "submitter": "Philippe Lacaille", "authors": "Philippe Lacaille", "title": "Analyzing the benefits of communication channels between deep learning\n  models", "comments": "77 pages, 7 figures, Master's Thesis", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  As artificial intelligence systems spread to more diverse and larger tasks in\nmany domains, the machine learning algorithms, and in particular the deep\nlearning models and the databases required to train them are getting bigger\nthemselves. Some algorithms do allow for some scaling of large computations by\nleveraging data parallelism. However, they often require a large amount of data\nto be exchanged in order to ensure the shared knowledge throughout the compute\nnodes is accurate.\n  In this work, the effect of different levels of communications between deep\nlearning models is studied, in particular how it affects performance. The first\napproach studied looks at decentralizing the numerous computations that are\ndone in parallel in training procedures such as synchronous and asynchronous\nstochastic gradient descent. In this setting, a simplified communication that\nconsists of exchanging low bandwidth outputs between compute nodes can be\nbeneficial. In the following chapter, the communication protocol is slightly\nmodified to further include training instructions. Indeed, this is studied in a\nsimplified setup where a pre-trained model, analogous to a teacher, can\ncustomize a randomly initialized model's training procedure to accelerate\nlearning. Finally, a communication channel where two deep learning models can\nexchange a purposefully crafted language is explored while allowing for\ndifferent ways of optimizing that language.\n", "versions": [{"version": "v1", "created": "Fri, 19 Apr 2019 14:33:57 GMT"}], "update_date": "2019-04-22", "authors_parsed": [["Lacaille", "Philippe", ""]]}, {"id": "1904.09212", "submitter": "Khalil Elkhalil", "authors": "Khalil Elkhalil, Abla Kammoun, Xiangliang Zhang, Mohamed-Slim Alouini,\n  Tareq Al-Naffouri", "title": "Risk Convergence of Centered Kernel Ridge Regression with Large\n  Dimensional Data", "comments": "Submitted to IEEE Transactions on Signal Processing", "journal-ref": null, "doi": "10.1109/TSP.2020.2975939", "report-no": null, "categories": "stat.ML cs.LG", "license": "http://creativecommons.org/publicdomain/zero/1.0/", "abstract": "  This paper carries out a large dimensional analysis of a variation of kernel\nridge regression that we call \\emph{centered kernel ridge regression} (CKRR),\nalso known in the literature as kernel ridge regression with offset. This\nmodified technique is obtained by accounting for the bias in the regression\nproblem resulting in the old kernel ridge regression but with \\emph{centered}\nkernels. The analysis is carried out under the assumption that the data is\ndrawn from a Gaussian distribution and heavily relies on tools from random\nmatrix theory (RMT). Under the regime in which the data dimension and the\ntraining size grow infinitely large with fixed ratio and under some mild\nassumptions controlling the data statistics, we show that both the empirical\nand the prediction risks converge to a deterministic quantities that describe\nin closed form fashion the performance of CKRR in terms of the data statistics\nand dimensions. Inspired by this theoretical result, we subsequently build a\nconsistent estimator of the prediction risk based on the training data which\nallows to optimally tune the design parameters. A key insight of the proposed\nanalysis is the fact that asymptotically a large class of kernels achieve the\nsame minimum prediction risk. This insight is validated with both synthetic and\nreal data.\n", "versions": [{"version": "v1", "created": "Fri, 19 Apr 2019 14:35:39 GMT"}], "update_date": "2020-04-22", "authors_parsed": [["Elkhalil", "Khalil", ""], ["Kammoun", "Abla", ""], ["Zhang", "Xiangliang", ""], ["Alouini", "Mohamed-Slim", ""], ["Al-Naffouri", "Tareq", ""]]}, {"id": "1904.09228", "submitter": "Jasper C.H. Lee", "authors": "Jasper C.H. Lee, Paul Valiant", "title": "Uncertainty about Uncertainty: Optimal Adaptive Algorithms for\n  Estimating Mixtures of Unknown Coins", "comments": "Full paper updated to reflect the new result in our SODA 2021\n  proceedings version: our new sample complexity lower bound includes\n  dependence on the failure probability, and hence is simultaneously tight in\n  all of the problem parameters up to a constant multiplicative factor", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.DS stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Given a mixture between two populations of coins, \"positive\" coins that each\nhave -- unknown and potentially different -- bias $\\geq\\frac{1}{2}+\\Delta$ and\n\"negative\" coins with bias $\\leq\\frac{1}{2}-\\Delta$, we consider the task of\nestimating the fraction $\\rho$ of positive coins to within additive error\n$\\epsilon$. We achieve an upper and lower bound of\n$\\Theta(\\frac{\\rho}{\\epsilon^2\\Delta^2}\\log\\frac{1}{\\delta})$ samples for a\n$1-\\delta$ probability of success, where crucially, our lower bound applies to\nall fully-adaptive algorithms. Thus, our sample complexity bounds have tight\ndependence for every relevant problem parameter. A crucial component of our\nlower bound proof is a decomposition lemma (see Lemmas 17 and 18) showing how\nto assemble partially-adaptive bounds into a fully-adaptive bound, which may be\nof independent interest: though we invoke it for the special case of Bernoulli\nrandom variables (coins), it applies to general distributions. We present\nsimulation results to demonstrate the practical efficacy of our approach for\nrealistic problem parameters for crowdsourcing applications, focusing on the\n\"rare events\" regime where $\\rho$ is small. The fine-grained adaptive flavor of\nboth our algorithm and lower bound contrasts with much previous work in\ndistributional testing and learning.\n", "versions": [{"version": "v1", "created": "Fri, 19 Apr 2019 15:22:04 GMT"}, {"version": "v2", "created": "Tue, 18 Aug 2020 04:29:50 GMT"}, {"version": "v3", "created": "Fri, 5 Feb 2021 05:07:48 GMT"}], "update_date": "2021-02-08", "authors_parsed": [["Lee", "Jasper C. H.", ""], ["Valiant", "Paul", ""]]}, {"id": "1904.09231", "submitter": "Nikolaj Tatti", "authors": "Nikolaj Tatti, Boris Cule", "title": "Mining Closed Strict Episodes", "comments": "Journal version. The previous version is the conference version", "journal-ref": null, "doi": "10.1007/s10618-011-0232-z", "report-no": null, "categories": "cs.DB cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Discovering patterns in a sequence is an important aspect of data mining. One\npopular choice of such patterns are episodes, patterns in sequential data\ndescribing events that often occur in the vicinity of each other. Episodes also\nenforce in which order the events are allowed to occur.\n  In this work we introduce a technique for discovering closed episodes.\nAdopting existing approaches for discovering traditional patterns, such as\nclosed itemsets, to episodes is not straightforward. First of all, we cannot\ndefine a unique closure based on frequency because an episode may have several\nclosed superepisodes. Moreover, to define a closedness concept for episodes we\nneed a subset relationship between episodes, which is not trivial to define.\n  We approach these problems by introducing strict episodes. We argue that this\nclass is general enough, and at the same time we are able to define a natural\nsubset relationship within it and use it efficiently. In order to mine closed\nepisodes we define an auxiliary closure operator. We show that this closure\nsatisfies the needed properties so that we can use the existing framework for\nmining closed patterns. Discovering the true closed episodes can be done as a\npost-processing step. We combine these observations into an efficient mining\nalgorithm and demonstrate empirically its performance in practice.\n", "versions": [{"version": "v1", "created": "Sun, 14 Apr 2019 00:24:47 GMT"}, {"version": "v2", "created": "Wed, 24 Apr 2019 23:19:21 GMT"}], "update_date": "2019-04-26", "authors_parsed": [["Tatti", "Nikolaj", ""], ["Cule", "Boris", ""]]}, {"id": "1904.09235", "submitter": "Eyke H\\\"ullermeier", "authors": "Vu-Linh Nguyen and Eyke H\\\"ullermeier", "title": "Reliable Multi-label Classification: Prediction with Partial Abstention", "comments": "19 pages, 12 figures", "journal-ref": "Proceedings AAAI-20, Thirty-Fourth AAAI Conference on Artificial\n  Intelligence, New York, USA, 2020", "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In contrast to conventional (single-label) classification, the setting of\nmultilabel classification (MLC) allows an instance to belong to several classes\nsimultaneously. Thus, instead of selecting a single class label, predictions\ntake the form of a subset of all labels. In this paper, we study an extension\nof the setting of MLC, in which the learner is allowed to partially abstain\nfrom a prediction, that is, to deliver predictions on some but not necessarily\nall class labels. We propose a formalization of MLC with abstention in terms of\na generalized loss minimization problem and present first results for the case\nof the Hamming loss, rank loss, and F-measure, both theoretical and\nexperimental.\n", "versions": [{"version": "v1", "created": "Fri, 19 Apr 2019 15:33:06 GMT"}, {"version": "v2", "created": "Fri, 24 Jan 2020 08:49:16 GMT"}], "update_date": "2020-01-27", "authors_parsed": [["Nguyen", "Vu-Linh", ""], ["H\u00fcllermeier", "Eyke", ""]]}, {"id": "1904.09237", "submitter": "Sashank J. Reddi", "authors": "Sashank J. Reddi, Satyen Kale, Sanjiv Kumar", "title": "On the Convergence of Adam and Beyond", "comments": "Appeared in ICLR 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG math.OC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Several recently proposed stochastic optimization methods that have been\nsuccessfully used in training deep networks such as RMSProp, Adam, Adadelta,\nNadam are based on using gradient updates scaled by square roots of exponential\nmoving averages of squared past gradients. In many applications, e.g. learning\nwith large output spaces, it has been empirically observed that these\nalgorithms fail to converge to an optimal solution (or a critical point in\nnonconvex settings). We show that one cause for such failures is the\nexponential moving average used in the algorithms. We provide an explicit\nexample of a simple convex optimization setting where Adam does not converge to\nthe optimal solution, and describe the precise problems with the previous\nanalysis of Adam algorithm. Our analysis suggests that the convergence issues\ncan be fixed by endowing such algorithms with `long-term memory' of past\ngradients, and propose new variants of the Adam algorithm which not only fix\nthe convergence issues but often also lead to improved empirical performance.\n", "versions": [{"version": "v1", "created": "Fri, 19 Apr 2019 16:21:38 GMT"}], "update_date": "2019-04-22", "authors_parsed": [["Reddi", "Sashank J.", ""], ["Kale", "Satyen", ""], ["Kumar", "Sanjiv", ""]]}, {"id": "1904.09265", "submitter": "Zhize Li", "authors": "Zhize Li", "title": "SSRGD: Simple Stochastic Recursive Gradient Descent for Escaping Saddle\n  Points", "comments": "44 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.DS math.OC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We analyze stochastic gradient algorithms for optimizing nonconvex problems.\nIn particular, our goal is to find local minima (second-order stationary\npoints) instead of just finding first-order stationary points which may be some\nbad unstable saddle points. We show that a simple perturbed version of\nstochastic recursive gradient descent algorithm (called SSRGD) can find an\n$(\\epsilon,\\delta)$-second-order stationary point with\n$\\widetilde{O}(\\sqrt{n}/\\epsilon^2 + \\sqrt{n}/\\delta^4 + n/\\delta^3)$\nstochastic gradient complexity for nonconvex finite-sum problems. As a\nby-product, SSRGD finds an $\\epsilon$-first-order stationary point with\n$O(n+\\sqrt{n}/\\epsilon^2)$ stochastic gradients. These results are almost\noptimal since Fang et al. [2018] provided a lower bound\n$\\Omega(\\sqrt{n}/\\epsilon^2)$ for finding even just an $\\epsilon$-first-order\nstationary point. We emphasize that SSRGD algorithm for finding second-order\nstationary points is as simple as for finding first-order stationary points\njust by adding a uniform perturbation sometimes, while all other algorithms for\nfinding second-order stationary points with similar gradient complexity need to\ncombine with a negative-curvature search subroutine (e.g., Neon2 [Allen-Zhu and\nLi, 2018]). Moreover, the simple SSRGD algorithm gets a simpler analysis.\nBesides, we also extend our results from nonconvex finite-sum problems to\nnonconvex online (expectation) problems, and prove the corresponding\nconvergence results.\n", "versions": [{"version": "v1", "created": "Fri, 19 Apr 2019 16:59:46 GMT"}, {"version": "v2", "created": "Thu, 20 Jun 2019 19:56:33 GMT"}], "update_date": "2019-06-24", "authors_parsed": [["Li", "Zhize", ""]]}, {"id": "1904.09273", "submitter": "David Johnson", "authors": "G\\\"orkem Pa\\c{c}ac{\\i}, David Johnson, Steve McKeever, Andreas Hamfelt", "title": "\"Why did you do that?\": Explaining black box models with Inductive\n  Synthesis", "comments": "12 pages, 1 figure, accepted for publication at the Solving Problems\n  with Uncertainties workshop as part of ICCS 2019, Faro, Portugal, June 12-14", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  By their nature, the composition of black box models is opaque. This makes\nthe ability to generate explanations for the response to stimuli challenging.\nThe importance of explaining black box models has become increasingly important\ngiven the prevalence of AI and ML systems and the need to build legal and\nregulatory frameworks around them. Such explanations can also increase trust in\nthese uncertain systems. In our paper we present RICE, a method for generating\nexplanations of the behaviour of black box models by (1) probing a model to\nextract model output examples using sensitivity analysis; (2) applying\nCNPInduce, a method for inductive logic program synthesis, to generate logic\nprograms based on critical input-output pairs; and (3) interpreting the target\nprogram as a human-readable explanation. We demonstrate the application of our\nmethod by generating explanations of an artificial neural network trained to\nfollow simple traffic rules in a hypothetical self-driving car simulation. We\nconclude with a discussion on the scalability and usability of our approach and\nits potential applications to explanation-critical scenarios.\n", "versions": [{"version": "v1", "created": "Wed, 17 Apr 2019 10:44:10 GMT"}], "update_date": "2019-04-22", "authors_parsed": [["Pa\u00e7ac\u0131", "G\u00f6rkem", ""], ["Johnson", "David", ""], ["McKeever", "Steve", ""], ["Hamfelt", "Andreas", ""]]}, {"id": "1904.09274", "submitter": "Yunbin Deng", "authors": "Yunbin Deng", "title": "Deep Learning on Mobile Devices - A Review", "comments": "comments from the machine learning community are very welcome", "journal-ref": "SPIE Defense + Commercial Sensing, Invited Paper. April 2019,\n  Baltimore, MD", "doi": "10.13140/RG.2.2.15012.12167", "report-no": null, "categories": "cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent breakthroughs in deep learning and artificial intelligence\ntechnologies have enabled numerous mobile applications. While traditional\ncomputation paradigms rely on mobile sensing and cloud computing, deep learning\nimplemented on mobile devices provides several advantages. These advantages\ninclude low communication bandwidth, small cloud computing resource cost, quick\nresponse time, and improved data privacy. Research and development of deep\nlearning on mobile and embedded devices has recently attracted much attention.\nThis paper provides a timely review of this fast-paced field to give the\nresearcher, engineer, practitioner, and graduate student a quick grasp on the\nrecent advancements of deep learning on mobile devices. In this paper, we\ndiscuss hardware architectures for mobile deep learning, including Field\nProgrammable Gate Arrays, Application Specific Integrated Circuit, and recent\nmobile Graphic Processing Units. We present Size, Weight, Area and Power\nconsiderations and their relation to algorithm optimizations, such as\nquantization, pruning, compression, and approximations that simplify\ncomputation while retaining performance accuracy. We cover existing systems and\ngive a state-of-the-industry review of TensorFlow, MXNet, Mobile AI Compute\nEngine, and Paddle-mobile deep learning platform. We discuss resources for\nmobile deep learning practitioners, including tools, libraries, models, and\nperformance benchmarks. We present applications of various mobile sensing\nmodalities to industries, ranging from robotics, healthcare and multi-media,\nbiometrics to autonomous drive and defense. We address the key deep learning\nchallenges to overcome, including low quality data, and small\ntraining/adaptation data sets. In addition, the review provides numerous\ncitations and links to existing code bases implementing various technologies.\n", "versions": [{"version": "v1", "created": "Thu, 21 Mar 2019 00:41:20 GMT"}], "update_date": "2019-04-22", "authors_parsed": [["Deng", "Yunbin", ""]]}, {"id": "1904.09290", "submitter": "Peng Zhang", "authors": "Peng Zhang, Fuhao Zou, Zhiwen Wu, Nengli Dai, Skarpness Mark, Michael\n  Fu, Juan Zhao, Kai Li", "title": "FeatherNets: Convolutional Neural Networks as Light as Feather for Face\n  Anti-spoofing", "comments": "10 pages;6 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.LG", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Face Anti-spoofing gains increased attentions recently in both academic and\nindustrial fields. With the emergence of various CNN based solutions, the\nmulti-modal(RGB, depth and IR) methods based CNN showed better performance than\nsingle modal classifiers. However, there is a need for improving the\nperformance and reducing the complexity. Therefore, an extreme light network\narchitecture(FeatherNet A/B) is proposed with a streaming module which fixes\nthe weakness of Global Average Pooling and uses less parameters. Our single\nFeatherNet trained by depth image only, provides a higher baseline with 0.00168\nACER, 0.35M parameters and 83M FLOPS. Furthermore, a novel fusion procedure\nwith ``ensemble + cascade'' structure is presented to satisfy the performance\npreferred use cases. Meanwhile, the MMFD dataset is collected to provide more\nattacks and diversity to gain better generalization. We use the fusion method\nin the Face Anti-spoofing Attack Detection Challenge@CVPR2019 and got the\nresult of 0.0013(ACER), 0.999(TPR@FPR=10e-2), 0.998(TPR@FPR=10e-3) and\n0.9814(TPR@FPR=10e-4).\n", "versions": [{"version": "v1", "created": "Mon, 22 Apr 2019 05:04:36 GMT"}], "update_date": "2019-04-23", "authors_parsed": [["Zhang", "Peng", ""], ["Zou", "Fuhao", ""], ["Wu", "Zhiwen", ""], ["Dai", "Nengli", ""], ["Mark", "Skarpness", ""], ["Fu", "Michael", ""], ["Zhao", "Juan", ""], ["Li", "Kai", ""]]}, {"id": "1904.09317", "submitter": "Christopher Kanan", "authors": "Kushal Kafle, Robik Shrestha, Christopher Kanan", "title": "Challenges and Prospects in Vision and Language Research", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CL cs.CV cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Language grounded image understanding tasks have often been proposed as a\nmethod for evaluating progress in artificial intelligence. Ideally, these tasks\nshould test a plethora of capabilities that integrate computer vision,\nreasoning, and natural language understanding. However, rather than behaving as\nvisual Turing tests, recent studies have demonstrated state-of-the-art systems\nare achieving good performance through flaws in datasets and evaluation\nprocedures. We review the current state of affairs and outline a path forward.\n", "versions": [{"version": "v1", "created": "Fri, 19 Apr 2019 19:04:12 GMT"}, {"version": "v2", "created": "Fri, 24 May 2019 22:10:33 GMT"}], "update_date": "2019-05-28", "authors_parsed": [["Kafle", "Kushal", ""], ["Shrestha", "Robik", ""], ["Kanan", "Christopher", ""]]}, {"id": "1904.09324", "submitter": "Omer Levy", "authors": "Marjan Ghazvininejad, Omer Levy, Yinhan Liu, Luke Zettlemoyer", "title": "Mask-Predict: Parallel Decoding of Conditional Masked Language Models", "comments": "EMNLP 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Most machine translation systems generate text autoregressively from left to\nright. We, instead, use a masked language modeling objective to train a model\nto predict any subset of the target words, conditioned on both the input text\nand a partially masked target translation. This approach allows for efficient\niterative decoding, where we first predict all of the target words\nnon-autoregressively, and then repeatedly mask out and regenerate the subset of\nwords that the model is least confident about. By applying this strategy for a\nconstant number of iterations, our model improves state-of-the-art performance\nlevels for non-autoregressive and parallel decoding translation models by over\n4 BLEU on average. It is also able to reach within about 1 BLEU point of a\ntypical left-to-right transformer model, while decoding significantly faster.\n", "versions": [{"version": "v1", "created": "Fri, 19 Apr 2019 19:53:01 GMT"}, {"version": "v2", "created": "Wed, 4 Sep 2019 16:31:39 GMT"}], "update_date": "2019-09-05", "authors_parsed": [["Ghazvininejad", "Marjan", ""], ["Levy", "Omer", ""], ["Liu", "Yinhan", ""], ["Zettlemoyer", "Luke", ""]]}, {"id": "1904.09331", "submitter": "Xiang Ren", "authors": "Qinyuan Ye, Liyuan Liu, Maosen Zhang, Xiang Ren", "title": "Looking Beyond Label Noise: Shifted Label Distribution Matters in\n  Distantly Supervised Relation Extraction", "comments": "13 pages: 10 pages paper, 3 pages appendix. Appears at EMNLP 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In recent years there is a surge of interest in applying distant supervision\n(DS) to automatically generate training data for relation extraction (RE). In\nthis paper, we study the problem what limits the performance of DS-trained\nneural models, conduct thorough analyses, and identify a factor that can\ninfluence the performance greatly, shifted label distribution. Specifically, we\nfound this problem commonly exists in real-world DS datasets, and without\nspecial handing, typical DS-RE models cannot automatically adapt to this shift,\nthus achieving deteriorated performance. To further validate our intuition, we\ndevelop a simple yet effective adaptation method for DS-trained models, bias\nadjustment, which updates models learned over the source domain (i.e., DS\ntraining set) with a label distribution estimated on the target domain (i.e.,\ntest set). Experiments demonstrate that bias adjustment achieves consistent\nperformance gains on DS-trained models, especially on neural models, with an up\nto 23% relative F1 improvement, which verifies our assumptions. Our code and\ndata can be found at\n\\url{https://github.com/INK-USC/shifted-label-distribution}.\n", "versions": [{"version": "v1", "created": "Fri, 19 Apr 2019 20:23:27 GMT"}, {"version": "v2", "created": "Tue, 10 Sep 2019 01:00:12 GMT"}], "update_date": "2019-09-11", "authors_parsed": [["Ye", "Qinyuan", ""], ["Liu", "Liyuan", ""], ["Zhang", "Maosen", ""], ["Ren", "Xiang", ""]]}, {"id": "1904.09339", "submitter": "Reza Mohammadi", "authors": "Reza Mohammadi, Matthew Pratola, Maurits Kaptein", "title": "Continuous-Time Birth-Death MCMC for Bayesian Regression Tree Models", "comments": "Published at http://jmlr.org/papers/v21/19-307 in the Journal of\n  Machine Learning Research (https://www.jmlr.org)", "journal-ref": "Journal of Machine Learning Research 2020, Vol. 21, No. 201, 1-26", "doi": null, "report-no": null, "categories": "stat.ML cs.LG stat.CO stat.ME", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Decision trees are flexible models that are well suited for many statistical\nregression problems. In a Bayesian framework for regression trees, Markov Chain\nMonte Carlo (MCMC) search algorithms are required to generate samples of tree\nmodels according to their posterior probabilities. The critical component of\nsuch an MCMC algorithm is to construct good Metropolis-Hastings steps for\nupdating the tree topology. However, such algorithms frequently suffering from\nlocal mode stickiness and poor mixing. As a result, the algorithms are slow to\nconverge. Hitherto, authors have primarily used discrete-time birth/death\nmechanisms for Bayesian (sums of) regression tree models to explore the model\nspace. These algorithms are efficient only if the acceptance rate is high which\nis not always the case. Here we overcome this issue by developing a new search\nalgorithm which is based on a continuous-time birth-death Markov process. This\nsearch algorithm explores the model space by jumping between parameter spaces\ncorresponding to different tree structures. In the proposed algorithm, the\nmoves between models are always accepted which can dramatically improve the\nconvergence and mixing properties of the MCMC algorithm. We provide theoretical\nsupport of the algorithm for Bayesian regression tree models and demonstrate\nits performance.\n", "versions": [{"version": "v1", "created": "Fri, 19 Apr 2019 20:37:05 GMT"}, {"version": "v2", "created": "Mon, 26 Oct 2020 11:55:32 GMT"}], "update_date": "2020-10-27", "authors_parsed": [["Mohammadi", "Reza", ""], ["Pratola", "Matthew", ""], ["Kaptein", "Maurits", ""]]}, {"id": "1904.09354", "submitter": "Christopher Harshaw", "authors": "Christopher Harshaw and Moran Feldman and Justin Ward and Amin Karbasi", "title": "Submodular Maximization Beyond Non-negativity: Guarantees, Fast\n  Algorithms, and Applications", "comments": "submitted to ICML 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.LG math.OC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  It is generally believed that submodular functions -- and the more general\nclass of $\\gamma$-weakly submodular functions -- may only be optimized under\nthe non-negativity assumption $f(S) \\geq 0$. In this paper, we show that once\nthe function is expressed as the difference $f = g - c$, where $g$ is monotone,\nnon-negative, and $\\gamma$-weakly submodular and $c$ is non-negative modular,\nthen strong approximation guarantees may be obtained. We present an algorithm\nfor maximizing $g - c$ under a $k$-cardinality constraint which produces a\nrandom feasible set $S$ such that $\\mathbb{E} \\left[ g(S) - c(S) \\right] \\geq\n(1 - e^{-\\gamma} - \\epsilon) g(OPT) - c(OPT)$, whose running time is $O\n(\\frac{n}{\\epsilon} \\log^2 \\frac{1}{\\epsilon})$, i.e., independent of $k$. We\nextend these results to the unconstrained setting by describing an algorithm\nwith the same approximation guarantees and faster $O(\\frac{n}{\\epsilon}\n\\log\\frac{1}{\\epsilon})$ runtime. The main techniques underlying our algorithms\nare two-fold: the use of a surrogate objective which varies the relative\nimportance between $g$ and $c$ throughout the algorithm, and a geometric sweep\nover possible $\\gamma$ values. Our algorithmic guarantees are complemented by a\nhardness result showing that no polynomial-time algorithm which accesses $g$\nthrough a value oracle can do better. We empirically demonstrate the success of\nour algorithms by applying them to experimental design on the Boston Housing\ndataset and directed vertex cover on the Email EU dataset.\n", "versions": [{"version": "v1", "created": "Fri, 19 Apr 2019 22:00:09 GMT"}], "update_date": "2019-04-23", "authors_parsed": [["Harshaw", "Christopher", ""], ["Feldman", "Moran", ""], ["Ward", "Justin", ""], ["Karbasi", "Amin", ""]]}, {"id": "1904.09357", "submitter": "Thiago Andrade", "authors": "Thiago Andrade and Jo\\~ao Gama", "title": "Identifying Points of Interest and Similar Individuals from Raw GPS Data", "comments": "Conference paper at Mobility IoT 2018 -\n  http://mobilityiot2018.eai-conferences.org/full-program/", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Smartphones and portable devices have become ubiquitous and part of\neveryone's life. Due to the fact of its portability, these devices are perfect\nto record individuals' traces and life-logging generating vast amounts of data\nat low costs. These data is emerging as a new source for studies in human\nmobility patterns raising the number of research projects and techniques aiming\nto analyze and retrieve useful information from it. The aim of this paper is to\nexplore GPS raw data from different individuals in a community and apply data\nmining algorithms to identify meaningful places in a region and describe user's\nprofiles and its similarities. We evaluate the proposed method with a\nreal-world dataset. The experimental results show that the steps performed to\nidentify points of interest (POIs) and further the similarity between the users\nare quite satisfactory serving as a supplement for urban planning and social\nnetworks.\n", "versions": [{"version": "v1", "created": "Fri, 19 Apr 2019 22:24:47 GMT"}], "update_date": "2019-04-23", "authors_parsed": [["Andrade", "Thiago", ""], ["Gama", "Jo\u00e3o", ""]]}, {"id": "1904.09365", "submitter": "Jiawei Zhang", "authors": "Jiawei Zhang", "title": "Derivative-Free Global Optimization Algorithms: Bayesian Method and\n  Lipschitzian Approaches", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we will provide an introduction to the derivative-free\noptimization algorithms which can be potentially applied to train deep learning\nmodels. Existing deep learning model training is mostly based on the back\npropagation algorithm, which updates the model variables layers by layers with\nthe gradient descent algorithm or its variants. However, the objective\nfunctions of deep learning models to be optimized are usually non-convex and\nthe gradient descent algorithms based on the first-order derivative can get\nstuck into the local optima very easily. To resolve such a problem, various\nlocal or global optimization algorithms have been proposed, which can help\nimprove the training of deep learning models greatly. The representative\nexamples include the Bayesian methods, Shubert-Piyavskii algorithm, Direct,\nLIPO, MCS, GA, SCE, DE, PSO, ES, CMA-ES, hill climbing and simulated annealing,\netc. One part of these algorithms will be introduced in this paper (including\nthe Bayesian method and Lipschitzian approaches, e.g., Shubert-Piyavskii\nalgorithm, Direct, LIPO and MCS), and the remaining algorithms (including the\npopulation based optimization algorithms, e.g., GA, SCE, DE, PSO, ES and\nCMA-ES, and random search algorithms, e.g., hill climbing and simulated\nannealing) will be introduced in the follow-up paper [18] in detail.\n", "versions": [{"version": "v1", "created": "Fri, 19 Apr 2019 23:14:01 GMT"}], "update_date": "2019-04-23", "authors_parsed": [["Zhang", "Jiawei", ""]]}, {"id": "1904.09368", "submitter": "Jiawei Zhang", "authors": "Jiawei Zhang", "title": "Derivative-Free Global Optimization Algorithms: Population based Methods\n  and Random Search Approaches", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we will provide an introduction to the derivative-free\noptimization algorithms which can be potentially applied to train deep learning\nmodels. Existing deep learning model training is mostly based on the back\npropagation algorithm, which updates the model variables layers by layers with\nthe gradient descent algorithm or its variants. However, the objective\nfunctions of deep learning models to be optimized are usually non-convex and\nthe gradient descent algorithms based on the first-order derivative can get\nstuck into the local optima very easily. To resolve such a problem, various\nlocal or global optimization algorithms have been proposed, which can help\nimprove the training of deep learning models greatly. The representative\nexamples include the Bayesian methods, Shubert-Piyavskii algorithm, Direct,\nLIPO, MCS, GA, SCE, DE, PSO, ES, CMA-ES, hill climbing and simulated annealing,\netc. This is a follow-up paper of [18], and we will introduce the population\nbased optimization algorithms, e.g., GA, SCE, DE, PSO, ES and CMA-ES, and\nrandom search algorithms, e.g., hill climbing and simulated annealing, in this\npaper. For the introduction to the other derivative-free optimization\nalgorithms, please refer to [18] for more information.\n", "versions": [{"version": "v1", "created": "Fri, 19 Apr 2019 23:22:49 GMT"}], "update_date": "2019-04-23", "authors_parsed": [["Zhang", "Jiawei", ""]]}, {"id": "1904.09369", "submitter": "Hakan Gokcesu", "authors": "Hakan Gokcesu and Suleyman S. Kozat", "title": "Minimax Optimal Online Stochastic Learning for Sequences of Convex\n  Functions under Sub-Gradient Observation Failures", "comments": "25 pages, 6 figures, preprint, single column", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG math.OC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study online convex optimization under stochastic sub-gradient observation\nfaults, where we introduce adaptive algorithms with minimax optimal regret\nguarantees. We specifically study scenarios where our sub-gradient observations\ncan be noisy or even completely missing in a stochastic manner. To this end, we\npropose algorithms based on sub-gradient descent method, which achieve tight\nminimax optimal regret bounds. When necessary, these algorithms utilize\nproperties of the underlying stochastic settings to optimize their learning\nrates (step sizes). These optimizations are the main factor in providing the\nminimax optimal performance guarantees, especially when observations are\nstochastically missing. However, in real world scenarios, these properties of\nthe underlying stochastic settings may not be revealed to the optimizer. For\nsuch a scenario, we propose a blind algorithm that estimates these properties\nempirically in a generally applicable manner. Through extensive experiments, we\nshow that this empirical approach is a natural combination of regular\nstochastic gradient descent and the minimax optimal algorithms (which work best\nfor randomized and adversarial function sequences, respectively).\n", "versions": [{"version": "v1", "created": "Fri, 19 Apr 2019 23:24:38 GMT"}], "update_date": "2019-04-23", "authors_parsed": [["Gokcesu", "Hakan", ""], ["Kozat", "Suleyman S.", ""]]}, {"id": "1904.09370", "submitter": "Oggi Rudovic", "authors": "Ognjen Rudovic, Yuria Utsumi, Ricardo Guerrero, Kelly Peterson, Daniel\n  Rueckert, Rosalind W. Picard", "title": "Meta-Weighted Gaussian Process Experts for Personalized Forecasting of\n  AD Cognitive Changes", "comments": null, "journal-ref": "Machine Learning for Healthcare Conference (ML4HC2019)", "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce a novel personalized Gaussian Process Experts (pGPE) model for\npredicting per-subject ADAS-Cog13 cognitive scores -- a significant predictor\nof Alzheimer's Disease (AD) in the cognitive domain -- over the future 6, 12,\n18, and 24 months. We start by training a population-level model using\nmulti-modal data from previously seen subjects using a base Gaussian Process\n(GP) regression. Then, we personalize this model by adapting the base GP\nsequentially over time to a new (target) subject using domain adaptive GPs, and\nalso by training subject-specific GP. While we show that these models achieve\nimproved performance when selectively applied to the forecasting task (one\nperforms better than the other on different subjects/visits), the average\nperformance per model is suboptimal. To this end, we used the notion of meta\nlearning in the proposed pGPE to design a regression-based weighting of these\nexpert models, where the expert weights are optimized for each subject and\nhis/her future visit. The results on a cohort of subjects from the ADNI dataset\nshow that this newly introduced personalized weighting of the expert models\nleads to large improvements in accurately forecasting future ADAS-Cog13 scores\nand their fine-grained changes associated with the AD progression. This\napproach has potential to help identify at-risk patients early and improve the\nconstruction of clinical trials for AD.\n", "versions": [{"version": "v1", "created": "Fri, 19 Apr 2019 23:28:11 GMT"}], "update_date": "2019-06-11", "authors_parsed": [["Rudovic", "Ognjen", ""], ["Utsumi", "Yuria", ""], ["Guerrero", "Ricardo", ""], ["Peterson", "Kelly", ""], ["Rueckert", "Daniel", ""], ["Picard", "Rosalind W.", ""]]}, {"id": "1904.09378", "submitter": "Mathieu Carri\\`ere", "authors": "Mathieu Carri\\`ere and Fr\\'ed\\'eric Chazal and Yuichi Ike and Th\\'eo\n  Lacombe and Martin Royer and Yuhei Umeda", "title": "PersLay: A Neural Network Layer for Persistence Diagrams and New Graph\n  Topological Signatures", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.CG cs.LG math.AT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Persistence diagrams, the most common descriptors of Topological Data\nAnalysis, encode topological properties of data and have already proved pivotal\nin many different applications of data science. However, since the (metric)\nspace of persistence diagrams is not Hilbert, they end up being difficult\ninputs for most Machine Learning techniques. To address this concern, several\nvectorization methods have been put forward that embed persistence diagrams\ninto either finite-dimensional Euclidean space or (implicit) infinite\ndimensional Hilbert space with kernels. In this work, we focus on persistence\ndiagrams built on top of graphs. Relying on extended persistence theory and the\nso-called heat kernel signature, we show how graphs can be encoded by\n(extended) persistence diagrams in a provably stable way. We then propose a\ngeneral and versatile framework for learning vectorizations of persistence\ndiagrams, which encompasses most of the vectorization techniques used in the\nliterature. We finally showcase the experimental strength of our setup by\nachieving competitive scores on classification tasks on real-life graph\ndatasets.\n", "versions": [{"version": "v1", "created": "Sat, 20 Apr 2019 00:21:59 GMT"}, {"version": "v2", "created": "Wed, 5 Jun 2019 02:14:57 GMT"}, {"version": "v3", "created": "Thu, 17 Oct 2019 23:16:02 GMT"}, {"version": "v4", "created": "Mon, 9 Mar 2020 03:15:26 GMT"}], "update_date": "2020-03-10", "authors_parsed": [["Carri\u00e8re", "Mathieu", ""], ["Chazal", "Fr\u00e9d\u00e9ric", ""], ["Ike", "Yuichi", ""], ["Lacombe", "Th\u00e9o", ""], ["Royer", "Martin", ""], ["Umeda", "Yuhei", ""]]}, {"id": "1904.09380", "submitter": "Harsh Trivedi", "authors": "Harsh Trivedi, Heeyoung Kwon, Tushar Khot, Ashish Sabharwal, Niranjan\n  Balasubramanian", "title": "Repurposing Entailment for Multi-Hop Question Answering Tasks", "comments": "Accepted at NAACL'19", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Question Answering (QA) naturally reduces to an entailment problem, namely,\nverifying whether some text entails the answer to a question. However, for\nmulti-hop QA tasks, which require reasoning with multiple sentences, it remains\nunclear how best to utilize entailment models pre-trained on large scale\ndatasets such as SNLI, which are based on sentence pairs. We introduce Multee,\na general architecture that can effectively use entailment models for multi-hop\nQA tasks. Multee uses (i) a local module that helps locate important sentences,\nthereby avoiding distracting information, and (ii) a global module that\naggregates information by effectively incorporating importance weights.\nImportantly, we show that both modules can use entailment functions pre-trained\non a large scale NLI datasets. We evaluate performance on MultiRC and\nOpenBookQA, two multihop QA datasets. When using an entailment function\npre-trained on NLI datasets, Multee outperforms QA models trained only on the\ntarget QA datasets and the OpenAI transformer models. The code is available at\nhttps://github.com/StonyBrookNLP/multee.\n", "versions": [{"version": "v1", "created": "Sat, 20 Apr 2019 00:30:26 GMT"}], "update_date": "2019-04-23", "authors_parsed": [["Trivedi", "Harsh", ""], ["Kwon", "Heeyoung", ""], ["Khot", "Tushar", ""], ["Sabharwal", "Ashish", ""], ["Balasubramanian", "Niranjan", ""]]}, {"id": "1904.09390", "submitter": "Tae Hyung Kim", "authors": "Tae Hyung Kim, Pratyush Garg, Justin P. Haldar", "title": "LORAKI: Autocalibrated Recurrent Neural Networks for Autoregressive MRI\n  Reconstruction in k-Space", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.IV cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose and evaluate a new MRI reconstruction method named LORAKI that\ntrains an autocalibrated scan-specific recurrent neural network (RNN) to\nrecover missing k-space data. Methods like GRAPPA, SPIRiT, and AC-LORAKS assume\nthat k-space data has shift-invariant autoregressive structure, and that the\nscan-specific autoregression relationships needed to recover missing samples\ncan be learned from fully-sampled autocalibration (ACS) data. Recently, the\nstructure of the linear GRAPPA method has been translated into a nonlinear deep\nlearning method named RAKI. RAKI uses ACS data to train an artificial neural\nnetwork to interpolate missing k-space samples, and often outperforms GRAPPA.\nIn this work, we apply a similar principle to translate the linear AC-LORAKS\nmethod (simultaneously incorporating support, phase, and parallel imaging\nconstraints) into a nonlinear deep learning method named LORAKI. Since\nAC-LORAKS is iterative and convolutional, LORAKI takes the form of a\nconvolutional RNN. This new architecture admits a wide range of sampling\npatterns, and even calibrationless patterns are possible if synthetic ACS data\nis generated. The performance of LORAKI was evaluated with retrospectively\nundersampled brain datasets, with comparisons against other related\nreconstruction methods. Results suggest that LORAKI can provide improved\nreconstruction compared to other scan-specific autocalibrated reconstruction\nmethods like GRAPPA, RAKI, and AC-LORAKS. LORAKI offers a new deep-learning\napproach to MRI reconstruction based on RNNs in k-space, and enables improved\nimage quality and enhanced sampling flexibility.\n", "versions": [{"version": "v1", "created": "Sat, 20 Apr 2019 03:02:34 GMT"}, {"version": "v2", "created": "Wed, 24 Apr 2019 01:16:06 GMT"}], "update_date": "2019-04-25", "authors_parsed": [["Kim", "Tae Hyung", ""], ["Garg", "Pratyush", ""], ["Haldar", "Justin P.", ""]]}, {"id": "1904.09399", "submitter": "Ali Sadeghian", "authors": "Xiaofeng Zhou, Ali Sadeghian, Daisy Zhe Wang", "title": "Mining Rules Incrementally over Large Knowledge Bases", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DB cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Multiple web-scale Knowledge Bases, e.g., Freebase, YAGO, NELL, have been\nconstructed using semi-supervised or unsupervised information extraction\ntechniques and many of them, despite their large sizes, are continuously\ngrowing. Much research effort has been put into mining inference rules from\nknowledge bases. To address the task of rule mining over evolving web-scale\nknowledge bases, we propose a parallel incremental rule mining framework. Our\napproach is able to efficiently mine rules based on the relational model and\napply updates to large knowledge bases; we propose an alternative metric that\nreduces computation complexity without compromising quality; we apply multiple\noptimization techniques that reduce runtime by more than 2 orders of magnitude.\nExperiments show that our approach efficiently scales to web-scale knowledge\nbases and saves over 90% time compared to the state-of-the-art batch rule\nmining system. We also apply our optimization techniques to the batch rule\nmining algorithm, reducing runtime by more than half compared to the\nstate-of-the-art. To the best of our knowledge, our incremental rule mining\nsystem is the first that handles updates to web-scale knowledge bases.\n", "versions": [{"version": "v1", "created": "Sat, 20 Apr 2019 04:09:01 GMT"}], "update_date": "2019-04-23", "authors_parsed": [["Zhou", "Xiaofeng", ""], ["Sadeghian", "Ali", ""], ["Wang", "Daisy Zhe", ""]]}, {"id": "1904.09404", "submitter": "Saied Mahdian", "authors": "Branislav Kveton, Saied Mahdian, S. Muthukrishnan, Zheng Wen, Yikun\n  Xian", "title": "Waterfall Bandits: Learning to Sell Ads Online", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A popular approach to selling online advertising is by a waterfall, where a\npublisher makes sequential price offers to ad networks for an inventory, and\nchooses the winner in that order. The publisher picks the order and prices to\nmaximize her revenue. A traditional solution is to learn the demand model and\nthen subsequently solve the optimization problem for the given demand model.\nThis will incur a linear regret. We design an online learning algorithm for\nsolving this problem, which interleaves learning and optimization, and prove\nthat this algorithm has sublinear regret. We evaluate the algorithm on both\nsynthetic and real-world data, and show that it quickly learns high quality\npricing strategies. This is the first principled study of learning a waterfall\ndesign online by sequential experimentation.\n", "versions": [{"version": "v1", "created": "Sat, 20 Apr 2019 05:11:56 GMT"}], "update_date": "2019-04-23", "authors_parsed": [["Kveton", "Branislav", ""], ["Mahdian", "Saied", ""], ["Muthukrishnan", "S.", ""], ["Wen", "Zheng", ""], ["Xian", "Yikun", ""]]}, {"id": "1904.09408", "submitter": "Chenguang Wang", "authors": "Chenguang Wang, Mu Li, Alexander J. Smola", "title": "Language Models with Transformers", "comments": "12 pages, 7 tables, 4 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The Transformer architecture is superior to RNN-based models in computational\nefficiency. Recently, GPT and BERT demonstrate the efficacy of Transformer\nmodels on various NLP tasks using pre-trained language models on large-scale\ncorpora. Surprisingly, these Transformer architectures are suboptimal for\nlanguage model itself. Neither self-attention nor the positional encoding in\nthe Transformer is able to efficiently incorporate the word-level sequential\ncontext crucial to language modeling.\n  In this paper, we explore effective Transformer architectures for language\nmodel, including adding additional LSTM layers to better capture the sequential\ncontext while still keeping the computation efficient. We propose Coordinate\nArchitecture Search (CAS) to find an effective architecture through iterative\nrefinement of the model. Experimental results on the PTB, WikiText-2, and\nWikiText-103 show that CAS achieves perplexities between 20.42 and 34.11 on all\nproblems, i.e. on average an improvement of 12.0 perplexity units compared to\nstate-of-the-art LSTMs. The source code is publicly available.\n", "versions": [{"version": "v1", "created": "Sat, 20 Apr 2019 06:43:14 GMT"}, {"version": "v2", "created": "Thu, 17 Oct 2019 04:25:15 GMT"}], "update_date": "2019-10-18", "authors_parsed": [["Wang", "Chenguang", ""], ["Li", "Mu", ""], ["Smola", "Alexander J.", ""]]}, {"id": "1904.09415", "submitter": "Xiao Chen", "authors": "Xiao Chen, Thomas Navidi, Stefano Ermon, Ram Rajagopal", "title": "Distributed generation of privacy preserving data with user\n  customization", "comments": "accepted in ICLR 2019 SafeML workshop", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CY stat.ML", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Distributed devices such as mobile phones can produce and store large amounts\nof data that can enhance machine learning models; however, this data may\ncontain private information specific to the data owner that prevents the\nrelease of the data. We wish to reduce the correlation between user-specific\nprivate information and data while maintaining the useful information. Rather\nthan learning a large model to achieve privatization from end to end, we\nintroduce a decoupling of the creation of a latent representation and the\nprivatization of data that allows user-specific privatization to occur in a\ndistributed setting with limited computation and minimal disturbance on the\nutility of the data. We leverage a Variational Autoencoder (VAE) to create a\ncompact latent representation of the data; however, the VAE remains fixed for\nall devices and all possible private labels. We then train a small generative\nfilter to perturb the latent representation based on individual preferences\nregarding the private and utility information. The small filter is trained by\nutilizing a GAN-type robust optimization that can take place on a distributed\ndevice. We conduct experiments on three popular datasets: MNIST, UCI-Adult, and\nCelebA, and give a thorough evaluation including visualizing the geometry of\nthe latent embeddings and estimating the empirical mutual information to show\nthe effectiveness of our approach.\n", "versions": [{"version": "v1", "created": "Sat, 20 Apr 2019 07:58:37 GMT"}], "update_date": "2019-04-23", "authors_parsed": [["Chen", "Xiao", ""], ["Navidi", "Thomas", ""], ["Ermon", "Stefano", ""], ["Rajagopal", "Ram", ""]]}, {"id": "1904.09425", "submitter": "Shilian Zheng", "authors": "Shichuan Chen, Shilian Zheng, Lifeng Yang, and Xiaoniu Yang", "title": "Deep Learning for Large-Scale Real-World ACARS and ADS-B Radio Signal\n  Classification", "comments": "Accepted by IEEE Access", "journal-ref": null, "doi": "10.1109/ACCESS.2019.2925569", "report-no": null, "categories": "cs.LG eess.SP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Radio signal classification has a very wide range of applications in the\nfield of wireless communications and electromagnetic spectrum management. In\nrecent years, deep learning has been used to solve the problem of radio signal\nclassification and has achieved good results. However, the radio signal data\ncurrently used is very limited in scale. In order to verify the performance of\nthe deep learning-based radio signal classification on real-world radio signal\ndata, in this paper we conduct experiments on large-scale real-world ACARS and\nADS-B signal data with sample sizes of 900,000 and 13,000,000, respectively,\nand with categories of 3,143 and 5,157 respectively. We use the same\nInception-Residual neural network model structure for ACARS signal\nclassification and ADS-B signal classification to verify the ability of a\nsingle basic deep neural network model structure to process different types of\nradio signals, i.e., communication bursts in ACARS and pulse bursts in ADS-B.\nWe build an experimental system for radio signal deep learning experiments.\nExperimental results show that the signal classification accuracy of ACARS and\nADS-B is 98.1% and 96.3%, respectively. When the signal-to-noise ratio (with\ninjected additive white Gaussian noise) is greater than 9 dB, the\nclassification accuracy is greater than 92%. These experimental results\nvalidate the ability of deep learning to classify large-scale real-world radio\nsignals. The results of the transfer learning experiment show that the model\ntrained on large-scale ADS-B datasets is more conducive to the learning and\ntraining of new tasks than the model trained on small-scale datasets.\n", "versions": [{"version": "v1", "created": "Sat, 20 Apr 2019 10:04:34 GMT"}, {"version": "v2", "created": "Sat, 22 Jun 2019 06:55:45 GMT"}, {"version": "v3", "created": "Wed, 26 Jun 2019 07:44:40 GMT"}], "update_date": "2019-06-27", "authors_parsed": [["Chen", "Shichuan", ""], ["Zheng", "Shilian", ""], ["Yang", "Lifeng", ""], ["Yang", "Xiaoniu", ""]]}, {"id": "1904.09433", "submitter": "Mohammad Shojafar", "authors": "Rahim Taheri, Reza Javidan, Mohammad Shojafar, Vinod P and Mauro Conti", "title": "Can Machine Learning Model with Static Features be Fooled: an\n  Adversarial Machine Learning Approach", "comments": "20 pages, 6 figures, 5 tables", "journal-ref": "Cluster Computing 2020", "doi": null, "report-no": null, "categories": "cs.CR cs.AI cs.CC cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  The widespread adoption of smartphones dramatically increases the risk of\nattacks and the spread of mobile malware, especially on the Android platform.\nMachine learning-based solutions have been already used as a tool to supersede\nsignature-based anti-malware systems. However, malware authors leverage\nfeatures from malicious and legitimate samples to estimate statistical\ndifference in-order to create adversarial examples. Hence, to evaluate the\nvulnerability of machine learning algorithms in malware detection, we propose\nfive different attack scenarios to perturb malicious applications (apps). By\ndoing this, the classification algorithm inappropriately fits the discriminant\nfunction on the set of data points, eventually yielding a higher\nmisclassification rate. Further, to distinguish the adversarial examples from\nbenign samples, we propose two defense mechanisms to counter attacks. To\nvalidate our attacks and solutions, we test our model on three different\nbenchmark datasets. We also test our methods using various classifier\nalgorithms and compare them with the state-of-the-art data poisoning method\nusing the Jacobian matrix. Promising results show that generated adversarial\nsamples can evade detection with a very high probability. Additionally, evasive\nvariants generated by our attack models when used to harden the developed\nanti-malware system improves the detection rate up to 50% when using the\nGenerative Adversarial Network (GAN) method.\n", "versions": [{"version": "v1", "created": "Sat, 20 Apr 2019 11:17:51 GMT"}, {"version": "v2", "created": "Sat, 29 Feb 2020 07:44:14 GMT"}], "update_date": "2020-03-03", "authors_parsed": [["Taheri", "Rahim", ""], ["Javidan", "Reza", ""], ["Shojafar", "Mohammad", ""], ["P", "Vinod", ""], ["Conti", "Mauro", ""]]}, {"id": "1904.09448", "submitter": "Vinod Kumar Chauhan", "authors": "Vinod Kumar Chauhan, Anuj Sharma, Kalpana Dahiya", "title": "LIBS2ML: A Library for Scalable Second Order Machine Learning Algorithms", "comments": "5 page JMLR library format, 4 figures. Library available as open\n  source for download at: https://github.com/jmdvinodjmd/LIBS2ML", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  LIBS2ML is a library based on scalable second order learning algorithms for\nsolving large-scale problems, i.e., big data problems in machine learning.\nLIBS2ML has been developed using MEX files, i.e., C++ with MATLAB/Octave\ninterface to take the advantage of both the worlds, i.e., faster learning using\nC++ and easy I/O using MATLAB. Most of the available libraries are either in\nMATLAB/Python/R which are very slow and not suitable for large-scale learning,\nor are in C/C++ which does not have easy ways to take input and display\nresults. So LIBS2ML is completely unique due to its focus on the scalable\nsecond order methods, the hot research topic, and being based on MEX files.\nThus it provides researchers a comprehensive environment to evaluate their\nideas and it also provides machine learning practitioners an effective tool to\ndeal with the large-scale learning problems. LIBS2ML is an open-source, highly\nefficient, extensible, scalable, readable, portable and easy to use library.\nThe library can be downloaded from the URL:\n\\url{https://github.com/jmdvinodjmd/LIBS2ML}.\n", "versions": [{"version": "v1", "created": "Sat, 20 Apr 2019 14:41:05 GMT"}], "update_date": "2019-04-23", "authors_parsed": [["Chauhan", "Vinod Kumar", ""], ["Sharma", "Anuj", ""], ["Dahiya", "Kalpana", ""]]}, {"id": "1904.09483", "submitter": "Peng Li", "authors": "Peng Li, Xi Rao, Jennifer Blase, Yue Zhang, Xu Chu, Ce Zhang", "title": "CleanML: A Study for Evaluating the Impact of Data Cleaning on ML\n  Classification Tasks", "comments": "published in ICDE 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DB cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Data quality affects machine learning (ML) model performances, and data\nscientists spend considerable amount of time on data cleaning before model\ntraining. However, to date, there does not exist a rigorous study on how\nexactly cleaning affects ML -- ML community usually focuses on developing ML\nalgorithms that are robust to some particular noise types of certain\ndistributions, while database (DB) community has been mostly studying the\nproblem of data cleaning alone without considering how data is consumed by\ndownstream ML analytics. We propose a CleanML study that systematically\ninvestigates the impact of data cleaning on ML classification tasks. The\nopen-source and extensible CleanML study currently includes 14 real-world\ndatasets with real errors, five common error types, seven different ML models,\nand multiple cleaning algorithms for each error type (including both commonly\nused algorithms in practice as well as state-of-the-art solutions in academic\nliterature). We control the randomness in ML experiments using statistical\nhypothesis testing, and we also control false discovery rate in our experiments\nusing the Benjamini-Yekutieli (BY) procedure. We analyze the results in a\nsystematic way to derive many interesting and nontrivial observations. We also\nput forward multiple research directions for researchers.\n", "versions": [{"version": "v1", "created": "Sat, 20 Apr 2019 19:12:03 GMT"}, {"version": "v2", "created": "Fri, 26 Apr 2019 00:17:24 GMT"}, {"version": "v3", "created": "Mon, 5 Apr 2021 23:35:41 GMT"}], "update_date": "2021-04-07", "authors_parsed": [["Li", "Peng", ""], ["Rao", "Xi", ""], ["Blase", "Jennifer", ""], ["Zhang", "Yue", ""], ["Chu", "Xu", ""], ["Zhang", "Ce", ""]]}, {"id": "1904.09489", "submitter": "Joel Ruben Antony Moniz", "authors": "Joel Ruben Antony Moniz, Barun Patra, Sarthak Garg", "title": "Compression and Localization in Reinforcement Learning for ATARI Games", "comments": "NeurIPS 2018 Deep Reinforcement Learning Workshop", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep neural networks have become commonplace in the domain of reinforcement\nlearning, but are often expensive in terms of the number of parameters needed.\nWhile compressing deep neural networks has of late assumed great importance to\novercome this drawback, little work has been done to address this problem in\nthe context of reinforcement learning agents. This work aims at making first\nsteps towards model compression in an RL agent. In particular, we compress\nnetworks to drastically reduce the number of parameters in them (to sizes less\nthan 3% of their original size), further facilitated by applying a global max\npool after the final convolution layer, and propose using Actor-Mimic in the\ncontext of compression. Finally, we show that this global max-pool allows for\nweakly supervised object localization, improving the ability to identify the\nagent's points of focus.\n", "versions": [{"version": "v1", "created": "Sat, 20 Apr 2019 19:42:50 GMT"}], "update_date": "2019-04-23", "authors_parsed": [["Moniz", "Joel Ruben Antony", ""], ["Patra", "Barun", ""], ["Garg", "Sarthak", ""]]}, {"id": "1904.09491", "submitter": "Guokan Shang", "authors": "Guokan Shang (1 and 2), Antoine Jean-Pierre Tixier (1), Michalis\n  Vazirgiannis (1 and 3), Jean-Pierre Lorr\\'e (2) ((1) \\'Ecole Polytechnique,\n  (2) Linagora, (3) AUEB)", "title": "Energy-based Self-attentive Learning of Abstractive Communities for\n  Spoken Language Understanding", "comments": "Update baselines", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Abstractive community detection is an important spoken language understanding\ntask, whose goal is to group utterances in a conversation according to whether\nthey can be jointly summarized by a common abstractive sentence. This paper\nprovides a novel approach to this task. We first introduce a neural contextual\nutterance encoder featuring three types of self-attention mechanisms. We then\ntrain it using the siamese and triplet energy-based meta-architectures.\nExperiments on the AMI corpus show that our system outperforms multiple\nenergy-based and non-energy based baselines from the state-of-the-art. Code and\ndata are publicly available.\n", "versions": [{"version": "v1", "created": "Sat, 20 Apr 2019 20:01:52 GMT"}, {"version": "v2", "created": "Fri, 8 Nov 2019 02:18:29 GMT"}], "update_date": "2019-11-11", "authors_parsed": [["Shang", "Guokan", "", "1 and 2"], ["Tixier", "Antoine Jean-Pierre", "", "1 and 3"], ["Vazirgiannis", "Michalis", "", "1 and 3"], ["Lorr\u00e9", "Jean-Pierre", ""]]}, {"id": "1904.09503", "submitter": "Jianyu Chen", "authors": "Jianyu Chen, Bodi Yuan, Masayoshi Tomizuka", "title": "Model-free Deep Reinforcement Learning for Urban Autonomous Driving", "comments": "7 pages, 6 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CV cs.RO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Urban autonomous driving decision making is challenging due to complex road\ngeometry and multi-agent interactions. Current decision making methods are\nmostly manually designing the driving policy, which might result in sub-optimal\nsolutions and is expensive to develop, generalize and maintain at scale. On the\nother hand, with reinforcement learning (RL), a policy can be learned and\nimproved automatically without any manual designs. However, current RL methods\ngenerally do not work well on complex urban scenarios. In this paper, we\npropose a framework to enable model-free deep reinforcement learning in\nchallenging urban autonomous driving scenarios. We design a specific input\nrepresentation and use visual encoding to capture the low-dimensional latent\nstates. Several state-of-the-art model-free deep RL algorithms are implemented\ninto our framework, with several tricks to improve their performance. We\nevaluate our method in a challenging roundabout task with dense surrounding\nvehicles in a high-definition driving simulator. The result shows that our\nmethod can solve the task well and is significantly better than the baseline.\n", "versions": [{"version": "v1", "created": "Sat, 20 Apr 2019 22:02:45 GMT"}, {"version": "v2", "created": "Mon, 21 Oct 2019 21:11:58 GMT"}], "update_date": "2019-10-23", "authors_parsed": [["Chen", "Jianyu", ""], ["Yuan", "Bodi", ""], ["Tomizuka", "Masayoshi", ""]]}, {"id": "1904.09533", "submitter": "Daniel Stoller", "authors": "Saumitra Mishra, Daniel Stoller, Emmanouil Benetos, Bob L. Sturm,\n  Simon Dixon", "title": "GAN-based Generation and Automatic Selection of Explanations for Neural\n  Networks", "comments": "8 pages plus references and appendix. Accepted at the ICLR 2019\n  Workshop \"Safe Machine Learning: Specification, Robustness and Assurance\".\n  Camera-ready version. v2: Corrected page header", "journal-ref": "SafeML Workshop at the International Conference on Learning\n  Representations (ICLR) 2019", "doi": null, "report-no": null, "categories": "cs.LG cs.SD eess.AS stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  One way to interpret trained deep neural networks (DNNs) is by inspecting\ncharacteristics that neurons in the model respond to, such as by iteratively\noptimising the model input (e.g., an image) to maximally activate specific\nneurons. However, this requires a careful selection of hyper-parameters to\ngenerate interpretable examples for each neuron of interest, and current\nmethods rely on a manual, qualitative evaluation of each setting, which is\nprohibitively slow. We introduce a new metric that uses Fr\\'echet Inception\nDistance (FID) to encourage similarity between model activations for real and\ngenerated data. This provides an efficient way to evaluate a set of generated\nexamples for each setting of hyper-parameters. We also propose a novel\nGAN-based method for generating explanations that enables an efficient search\nthrough the input space and imposes a strong prior favouring realistic outputs.\nWe apply our approach to a classification model trained to predict whether a\nmusic audio recording contains singing voice. Our results suggest that this\nproposed metric successfully selects hyper-parameters leading to interpretable\nexamples, avoiding the need for manual evaluation. Moreover, we see that\nexamples synthesised to maximise or minimise the predicted probability of\nsinging voice presence exhibit vocal or non-vocal characteristics,\nrespectively, suggesting that our approach is able to generate suitable\nexplanations for understanding concepts learned by a neural network.\n", "versions": [{"version": "v1", "created": "Sun, 21 Apr 2019 02:54:33 GMT"}, {"version": "v2", "created": "Sat, 27 Apr 2019 09:31:26 GMT"}], "update_date": "2019-07-02", "authors_parsed": [["Mishra", "Saumitra", ""], ["Stoller", "Daniel", ""], ["Benetos", "Emmanouil", ""], ["Sturm", "Bob L.", ""], ["Dixon", "Simon", ""]]}, {"id": "1904.09537", "submitter": "Haitian Sun", "authors": "Haitian Sun, Tania Bedrax-Weiss, William W. Cohen", "title": "PullNet: Open Domain Question Answering with Iterative Retrieval on\n  Knowledge Bases and Text", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider open-domain queston answering (QA) where answers are drawn from\neither a corpus, a knowledge base (KB), or a combination of both of these. We\nfocus on a setting in which a corpus is supplemented with a large but\nincomplete KB, and on questions that require non-trivial (e.g., ``multi-hop'')\nreasoning. We describe PullNet, an integrated framework for (1) learning what\nto retrieve (from the KB and/or corpus) and (2) reasoning with this\nheterogeneous information to find the best answer. PullNet uses an {iterative}\nprocess to construct a question-specific subgraph that contains information\nrelevant to the question. In each iteration, a graph convolutional network\n(graph CNN) is used to identify subgraph nodes that should be expanded using\nretrieval (or ``pull'') operations on the corpus and/or KB. After the subgraph\nis complete, a similar graph CNN is used to extract the answer from the\nsubgraph. This retrieve-and-reason process allows us to answer multi-hop\nquestions using large KBs and corpora. PullNet is weakly supervised, requiring\nquestion-answer pairs but not gold inference paths. Experimentally PullNet\nimproves over the prior state-of-the art, and in the setting where a corpus is\nused with incomplete KB these improvements are often dramatic. PullNet is also\noften superior to prior systems in a KB-only setting or a text-only setting.\n", "versions": [{"version": "v1", "created": "Sun, 21 Apr 2019 03:49:09 GMT"}], "update_date": "2019-04-23", "authors_parsed": [["Sun", "Haitian", ""], ["Bedrax-Weiss", "Tania", ""], ["Cohen", "William W.", ""]]}, {"id": "1904.09559", "submitter": "Feng Yin", "authors": "Feng Yin, Lishuo Pan, Xinwei He, Tianshi Chen, Sergios Theodoridis,\n  Zhi-Quan (Tom) Luo", "title": "Linear Multiple Low-Rank Kernel Based Stationary Gaussian Processes\n  Regression for Time Series", "comments": "15 pages, 5 figures, submitted", "journal-ref": null, "doi": "10.1109/TSP.2020.3023008", "report-no": null, "categories": "cs.LG eess.SP stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Gaussian processes (GP) for machine learning have been studied systematically\nover the past two decades and they are by now widely used in a number of\ndiverse applications. However, GP kernel design and the associated\nhyper-parameter optimization are still hard and to a large extend open\nproblems. In this paper, we consider the task of GP regression for time series\nmodeling and analysis. The underlying stationary kernel can be approximated\narbitrarily close by a new proposed grid spectral mixture (GSM) kernel, which\nturns out to be a linear combination of low-rank sub-kernels. In the case where\na large number of the sub-kernels are used, either the Nystr\\\"{o}m or the\nrandom Fourier feature approximations can be adopted to deal efficiently with\nthe computational demands. The unknown GP hyper-parameters consist of the\nnon-negative weights of all sub-kernels as well as the noise variance; their\nestimation is performed via the maximum-likelihood (ML) estimation framework.\nTwo efficient numerical optimization methods for solving the unknown\nhyper-parameters are derived, including a sequential majorization-minimization\n(MM) method and a non-linearly constrained alternating direction of multiplier\nmethod (ADMM). The MM matches perfectly with the proven low-rank property of\nthe proposed GSM sub-kernels and turns out to be a part of efficiency, stable,\nand efficient solver, while the ADMM has the potential to generate better local\nminimum in terms of the test MSE. Experimental results, based on various\nclassic time series data sets, corroborate that the proposed GSM kernel-based\nGP regression model outperforms several salient competitors of similar kind in\nterms of prediction mean-squared-error and numerical stability.\n", "versions": [{"version": "v1", "created": "Sun, 21 Apr 2019 07:37:19 GMT"}], "update_date": "2020-10-28", "authors_parsed": [["Yin", "Feng", "", "Tom"], ["Pan", "Lishuo", "", "Tom"], ["He", "Xinwei", "", "Tom"], ["Chen", "Tianshi", "", "Tom"], ["Theodoridis", "Sergios", "", "Tom"], ["Zhi-Quan", "", "", "Tom"], ["Luo", "", ""]]}, {"id": "1904.09585", "submitter": "Serhii Havrylov", "authors": "Zhifeng Hu, Serhii Havrylov, Ivan Titov, Shay B. Cohen", "title": "Obfuscation for Privacy-preserving Syntactic Parsing", "comments": "Accepted to IWPT 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The goal of homomorphic encryption is to encrypt data such that another party\ncan operate on it without being explicitly exposed to the content of the\noriginal data. We introduce an idea for a privacy-preserving transformation on\nnatural language data, inspired by homomorphic encryption. Our primary tool is\n{\\em obfuscation}, relying on the properties of natural language. Specifically,\na given English text is obfuscated using a neural model that aims to preserve\nthe syntactic relationships of the original sentence so that the obfuscated\nsentence can be parsed instead of the original one. The model works at the word\nlevel, and learns to obfuscate each word separately by changing it into a new\nword that has a similar syntactic role. The text obfuscated by our model leads\nto better performance on three syntactic parsers (two dependency and one\nconstituency parsers) in comparison to an upper-bound random substitution\nbaseline. More specifically, the results demonstrate that as more terms are\nobfuscated (by their part of speech), the substitution upper bound\nsignificantly degrades, while the neural model maintains a relatively high\nperforming parser. All of this is done without much sacrifice of privacy\ncompared to the random substitution upper bound. We also further analyze the\nresults, and discover that the substituted words have similar syntactic\nproperties, but different semantic content, compared to the original words.\n", "versions": [{"version": "v1", "created": "Sun, 21 Apr 2019 12:09:39 GMT"}, {"version": "v2", "created": "Wed, 27 May 2020 09:38:58 GMT"}], "update_date": "2020-05-28", "authors_parsed": [["Hu", "Zhifeng", ""], ["Havrylov", "Serhii", ""], ["Titov", "Ivan", ""], ["Cohen", "Shay B.", ""]]}, {"id": "1904.09602", "submitter": "Min-Hsiu Hsieh", "authors": "Yuxuan Du and Min-Hsiu Hsieh and Dacheng Tao", "title": "Efficient Online Quantum Generative Adversarial Learning Algorithms with\n  Applications", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "quant-ph cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The exploration of quantum algorithms that possess quantum advantages is a\ncentral topic in quantum computation and quantum information processing. One\npotential candidate in this area is quantum generative adversarial learning\n(QuGAL), which conceptually has exponential advantages over classical\nadversarial networks. However, the corresponding learning algorithm remains\nobscured. In this paper, we propose the first quantum generative adversarial\nlearning algorithm-- the quantum multiplicative matrix weight algorithm\n(QMMW)-- which enables the efficient processing of fundamental tasks. The\ncomputational complexity of QMMW is polynomially proportional to the number of\ntraining rounds and logarithmically proportional to the input size. The core\nconcept of the proposed algorithm combines QuGAL with online learning. We\nexploit the implementation of QuGAL with parameterized quantum circuits, and\nnumerical experiments for the task of entanglement test for pure state are\nprovided to support our claims.\n", "versions": [{"version": "v1", "created": "Sun, 21 Apr 2019 13:55:13 GMT"}], "update_date": "2019-04-23", "authors_parsed": [["Du", "Yuxuan", ""], ["Hsieh", "Min-Hsiu", ""], ["Tao", "Dacheng", ""]]}, {"id": "1904.09605", "submitter": "Zongqing Lu", "authors": "Jiechuan Jiang and Zongqing Lu", "title": "Generative Exploration and Exploitation", "comments": "AAAI'20", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Sparse reward is one of the biggest challenges in reinforcement learning\n(RL). In this paper, we propose a novel method called Generative Exploration\nand Exploitation (GENE) to overcome sparse reward. GENE automatically generates\nstart states to encourage the agent to explore the environment and to exploit\nreceived reward signals. GENE can adaptively tradeoff between exploration and\nexploitation according to the varying distributions of states experienced by\nthe agent as the learning progresses. GENE relies on no prior knowledge about\nthe environment and can be combined with any RL algorithm, no matter on-policy\nor off-policy, single-agent or multi-agent. Empirically, we demonstrate that\nGENE significantly outperforms existing methods in three tasks with only binary\nrewards, including Maze, Maze Ant, and Cooperative Navigation. Ablation studies\nverify the emergence of progressive exploration and automatic reversing.\n", "versions": [{"version": "v1", "created": "Sun, 21 Apr 2019 14:15:24 GMT"}, {"version": "v2", "created": "Wed, 20 Nov 2019 11:56:23 GMT"}], "update_date": "2019-11-21", "authors_parsed": [["Jiang", "Jiechuan", ""], ["Lu", "Zongqing", ""]]}, {"id": "1904.09609", "submitter": "Ranjan Maitra", "authors": "Nicholas S. Berry and Ranjan Maitra", "title": "TiK-means: $K$-means clustering for skewed groups", "comments": "15 pages, 6 figures, to appear in Statistical Analysis and Data\n  Mining - The ASA Data Science Journal", "journal-ref": "Statistical Analysis and Data Mining -- The ASA Data Science\n  Journal, 2019, volume 12, number 3, pages 223-233", "doi": "10.1002/sam11416", "report-no": null, "categories": "stat.ML astro-ph.HE cs.CV cs.LG stat.AP stat.ME", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The $K$-means algorithm is extended to allow for partitioning of skewed\ngroups. Our algorithm is called TiK-Means and contributes a $K$-means type\nalgorithm that assigns observations to groups while estimating their\nskewness-transformation parameters. The resulting groups and transformation\nreveal general-structured clusters that can be explained by inverting the\nestimated transformation. Further, a modification of the jump statistic chooses\nthe number of groups. Our algorithm is evaluated on simulated and real-life\ndatasets and then applied to a long-standing astronomical dispute regarding the\ndistinct kinds of gamma ray bursts.\n", "versions": [{"version": "v1", "created": "Sun, 21 Apr 2019 14:32:42 GMT"}], "update_date": "2019-05-21", "authors_parsed": [["Berry", "Nicholas S.", ""], ["Maitra", "Ranjan", ""]]}, {"id": "1904.09612", "submitter": "Qian Yang", "authors": "Qian Yang, Aaron Steinfeld, John Zimmerman", "title": "Unremarkable AI: Fitting Intelligent Decision Support into Critical,\n  Clinical Decision-Making Processes", "comments": null, "journal-ref": "CHI Conference on Human Factors in Computing Systems Proceedings\n  2019 (CHI'19)", "doi": "10.1145/3290605.3300468", "report-no": null, "categories": "cs.HC cs.AI cs.CY cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Clinical decision support tools (DST) promise improved healthcare outcomes by\noffering data-driven insights. While effective in lab settings, almost all DSTs\nhave failed in practice. Empirical research diagnosed poor contextual fit as\nthe cause. This paper describes the design and field evaluation of a radically\nnew form of DST. It automatically generates slides for clinicians' decision\nmeetings with subtly embedded machine prognostics. This design took inspiration\nfrom the notion of \"Unremarkable Computing\", that by augmenting the users'\nroutines technology/AI can have significant importance for the users yet remain\nunobtrusive. Our field evaluation suggests clinicians are more likely to\nencounter and embrace such a DST. Drawing on their responses, we discuss the\nimportance and intricacies of finding the right level of unremarkableness in\nDST design, and share lessons learned in prototyping critical AI systems as a\nsituated experience.\n", "versions": [{"version": "v1", "created": "Sun, 21 Apr 2019 14:57:44 GMT"}], "update_date": "2019-04-23", "authors_parsed": [["Yang", "Qian", ""], ["Steinfeld", "Aaron", ""], ["Zimmerman", "John", ""]]}, {"id": "1904.09615", "submitter": "Cosimo Izzo", "authors": "Cosimo Izzo", "title": "Explaining a prediction in some nonlinear models", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this article we will analyse how to compute the contribution of each input\nvalue to its aggregate output in some nonlinear models. Regression and\nclassification applications, together with related algorithms for deep neural\nnetworks are presented. The proposed approach merges two methods currently\npresent in the literature: integrated gradient and deep Taylor decomposition.\nCompared to DeepLIFT and Deep SHAP, it provides a natural choice of the\nreference point peculiar to the model at use.\n", "versions": [{"version": "v1", "created": "Sun, 21 Apr 2019 15:23:52 GMT"}, {"version": "v2", "created": "Mon, 13 May 2019 14:00:55 GMT"}, {"version": "v3", "created": "Sat, 22 Jun 2019 19:09:19 GMT"}], "update_date": "2019-06-25", "authors_parsed": [["Izzo", "Cosimo", ""]]}, {"id": "1904.09626", "submitter": "Sungyeon Kim", "authors": "Sungyeon Kim, Minkyo Seo, Ivan Laptev, Minsu Cho, Suha Kwak", "title": "Deep Metric Learning Beyond Binary Supervision", "comments": "Accepted to CVPR 2019 (Oral)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Metric Learning for visual similarity has mostly adopted binary supervision\nindicating whether a pair of images are of the same class or not. Such a binary\nindicator covers only a limited subset of image relations, and is not\nsufficient to represent semantic similarity between images described by\ncontinuous and/or structured labels such as object poses, image captions, and\nscene graphs. Motivated by this, we present a novel method for deep metric\nlearning using continuous labels. First, we propose a new triplet loss that\nallows distance ratios in the label space to be preserved in the learned metric\nspace. The proposed loss thus enables our model to learn the degree of\nsimilarity rather than just the order. Furthermore, we design a triplet mining\nstrategy adapted to metric learning with continuous labels. We address three\ndifferent image retrieval tasks with continuous labels in terms of human poses,\nroom layouts and image captions, and demonstrate the superior performance of\nour approach compared to previous methods.\n", "versions": [{"version": "v1", "created": "Sun, 21 Apr 2019 17:02:56 GMT"}], "update_date": "2019-04-23", "authors_parsed": [["Kim", "Sungyeon", ""], ["Seo", "Minkyo", ""], ["Laptev", "Ivan", ""], ["Cho", "Minsu", ""], ["Kwak", "Suha", ""]]}, {"id": "1904.09631", "submitter": "Vidyasagar Sadhu", "authors": "Vidyasagar Sadhu, Saman Zonouz, Vincent Sritapan, Dario Pompili", "title": "HCFContext: Smartphone Context Inference via Sequential History-based\n  Collaborative Filtering", "comments": "Mobile context, collaborative filtering, privacy-preserving,\n  personalized model, sensors, location, prediction, hidden markov models,\n  google now, apple siri, cortana, alexa", "journal-ref": "IEEE International Conference on Pervasive Computing and\n  Communications (PerCom), Kyoto, Japan, 2019, pp. 1-9", "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Mobile context determination is an important step for many context aware\nservices such as location-based services, enterprise policy enforcement,\nbuilding or room occupancy detection for power or HVAC operation, etc.\nEspecially in enterprise scenarios where policies (e.g., attending a\nconfidential meeting only when the user is in \"Location X\") are defined based\non mobile context, it is paramount to verify the accuracy of the mobile\ncontext. To this end, two stochastic models based on the theory of Hidden\nMarkov Models (HMMs) to obtain mobile context are proposed-personalized model\n(HPContext) and collaborative filtering model (HCFContext). The former predicts\nthe current context using sequential history of the user's past context\nobservations, the latter enhances HPContext with collaborative filtering\nfeatures, which enables it to predict the current context of the primary user\nbased on the context observations of users related to the primary user, e.g.,\nsame team colleagues in company, gym friends, family members, etc. Each of the\nproposed models can also be used to enhance or complement the context obtained\nfrom sensors. Furthermore, since privacy is a concern in collaborative\nfiltering, a privacy-preserving method is proposed to derive HCFContext model\nparameters based on the concepts of homomorphic encryption. Finally, these\nmodels are thoroughly validated on a real-life dataset.\n", "versions": [{"version": "v1", "created": "Sun, 21 Apr 2019 17:09:35 GMT"}, {"version": "v2", "created": "Mon, 29 Apr 2019 02:59:14 GMT"}], "update_date": "2019-04-30", "authors_parsed": [["Sadhu", "Vidyasagar", ""], ["Zonouz", "Saman", ""], ["Sritapan", "Vincent", ""], ["Pompili", "Dario", ""]]}, {"id": "1904.09632", "submitter": "Jeremiah Zhe Liu", "authors": "Jeremiah Zhe Liu", "title": "Gaussian Process Regression and Classification under Mathematical\n  Constraints with Learning Guarantees", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST cs.LG stat.ME stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce constrained Gaussian process (CGP), a Gaussian process model for\nrandom functions that allows easy placement of mathematical constrains (e.g.,\nnon-negativity, monotonicity, etc) on its sample functions. CGP comes with\nclosed-form probability density function (PDF), and has the attractive feature\nthat its posterior distributions for regression and classification are again\nCGPs with closed-form expressions. Furthermore, we show that CGP inherents the\noptimal theoretical properties of the Gaussian process, e.g. rates of posterior\ncontraction, due to the fact that CGP is an Gaussian process with a more\nefficient model space.\n", "versions": [{"version": "v1", "created": "Sun, 21 Apr 2019 17:19:47 GMT"}], "update_date": "2019-04-23", "authors_parsed": [["Liu", "Jeremiah Zhe", ""]]}, {"id": "1904.09633", "submitter": "Devinder Kumar", "authors": "Devinder Kumar, Ibrahim Ben-Daya, Kanav Vats, Jeffery Feng, Graham\n  Taylor and, Alexander Wong", "title": "Beyond Explainability: Leveraging Interpretability for Improved\n  Adversarial Learning", "comments": "CVPR 2019 XAI Workshop accepted", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this study, we propose the leveraging of interpretability for tasks beyond\npurely the purpose of explainability. In particular, this study puts forward a\nnovel strategy for leveraging gradient-based interpretability in the realm of\nadversarial examples, where we use insights gained to aid adversarial learning.\nMore specifically, we introduce the concept of spatially constrained one-pixel\nadversarial perturbations, where we guide the learning of such adversarial\nperturbations towards more susceptible areas identified via gradient-based\ninterpretability. Experimental results using different benchmark datasets show\nthat such a spatially constrained one-pixel adversarial perturbation strategy\ncan noticeably improve the speed of convergence as well as produce successful\nattacks that were also visually difficult to perceive, thus illustrating an\neffective use of interpretability methods for tasks outside of the purpose of\npurely explainability.\n", "versions": [{"version": "v1", "created": "Sun, 21 Apr 2019 17:32:03 GMT"}], "update_date": "2019-04-23", "authors_parsed": [["Kumar", "Devinder", ""], ["Ben-Daya", "Ibrahim", ""], ["Vats", "Kanav", ""], ["Feng", "Jeffery", ""], ["and", "Graham Taylor", ""], ["Wong", "Alexander", ""]]}, {"id": "1904.09635", "submitter": "Yingjie Fei", "authors": "Yingjie Fei and Yudong Chen", "title": "Achieving the Bayes Error Rate in Synchronization and Block Models by\n  SDP, Robustly", "comments": "Partial preliminary results to appear in the Conference on Learning\n  Theory (COLT) 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST cs.IT cs.LG math.IT math.OC stat.ML stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the statistical performance of semidefinite programming (SDP)\nrelaxations for clustering under random graph models. Under the\n$\\mathbb{Z}_{2}$ Synchronization model, Censored Block Model and Stochastic\nBlock Model, we show that SDP achieves an error rate of the form \\[\n\\exp\\Big[-\\big(1-o(1)\\big)\\bar{n} I^* \\Big]. \\] Here $\\bar{n}$ is an\nappropriate multiple of the number of nodes and $I^*$ is an\ninformation-theoretic measure of the signal-to-noise ratio. We provide matching\nlower bounds on the Bayes error for each model and therefore demonstrate that\nthe SDP approach is Bayes optimal. As a corollary, our results imply that SDP\nachieves the optimal exact recovery threshold under each model. Furthermore, we\nshow that SDP is robust: the above bound remains valid under semirandom\nversions of the models in which the observed graph is modified by a monotone\nadversary. Our proof is based on a novel primal-dual analysis of SDP under a\nunified framework for all three models, and the analysis shows that SDP tightly\napproximates a joint majority voting procedure.\n", "versions": [{"version": "v1", "created": "Sun, 21 Apr 2019 17:44:48 GMT"}], "update_date": "2019-04-23", "authors_parsed": [["Fei", "Yingjie", ""], ["Chen", "Yudong", ""]]}, {"id": "1904.09639", "submitter": "Mustafa Hajij", "authors": "Yunhao Zhang, Haowen Liu, Paul Rosen, Mustafa Hajij", "title": "Mesh Learning Using Persistent Homology on the Laplacian Eigenfunctions", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We use persistent homology along with the eigenfunctions of the Laplacian to\nstudy similarity amongst triangulated 2-manifolds. Our method relies on\nstudying the lower-star filtration induced by the eigenfunctions of the\nLaplacian. This gives us a shape descriptor that inherits the rich information\nencoded in the eigenfunctions of the Laplacian. Moreover, the similarity\nbetween these descriptors can be easily computed using tools that are readily\navailable in Topological Data Analysis. We provide experiments to illustrate\nthe effectiveness of the proposed method.\n", "versions": [{"version": "v1", "created": "Sun, 21 Apr 2019 18:18:40 GMT"}, {"version": "v2", "created": "Tue, 23 Apr 2019 22:12:39 GMT"}], "update_date": "2019-04-25", "authors_parsed": [["Zhang", "Yunhao", ""], ["Liu", "Haowen", ""], ["Rosen", "Paul", ""], ["Hajij", "Mustafa", ""]]}, {"id": "1904.09644", "submitter": "Seulki Lee", "authors": "Seulki Lee, Bashima Islam, Yubo Luo, Shahriar Nirjon", "title": "Intermittent Learning: On-Device Machine Learning on Intermittently\n  Powered System", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper introduces intermittent learning - the goal of which is to enable\nenergy harvested computing platforms capable of executing certain classes of\nmachine learning tasks effectively and efficiently. We identify unique\nchallenges to intermittent learning relating to the data and application\nsemantics of machine learning tasks, and to address these challenges, we devise\n1) an algorithm that determines a sequence of actions to achieve the desired\nlearning objective under tight energy constraints, and 2) propose three\nheuristics that help an intermittent learner decide whether to learn or discard\ntraining examples at run-time which increases the energy efficiency of the\nsystem. We implement and evaluate three intermittent learning applications that\nlearn the 1) air quality, 2) human presence, and 3) vibration using solar, RF,\nand kinetic energy harvesters, respectively. We demonstrate that the proposed\nframework improves the energy efficiency of a learner by up to 100% and cuts\ndown the number of learning examples by up to 50% when compared to\nstate-of-the-art intermittent computing systems that do not implement the\nproposed intermittent learning framework.\n", "versions": [{"version": "v1", "created": "Sun, 21 Apr 2019 19:00:43 GMT"}, {"version": "v2", "created": "Sun, 15 Dec 2019 19:55:45 GMT"}], "update_date": "2019-12-17", "authors_parsed": [["Lee", "Seulki", ""], ["Islam", "Bashima", ""], ["Luo", "Yubo", ""], ["Nirjon", "Shahriar", ""]]}, {"id": "1904.09651", "submitter": "Hritik Bansal", "authors": "Ujjwal Gupta, Hritik Bansal, Deepak Joshi", "title": "An improved sex specific and age dependent classification model for\n  Parkinson's diagnosis using handwriting measurement", "comments": "Journal of Computer Methods and Programs in Biomedicine(Accepted on\n  27 December 2019)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG eess.SP q-bio.NC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Accurate diagnosis is crucial for preventing the progression of Parkinson's,\nas well as improving the quality of life with individuals with Parkinson's\ndisease. In this paper, we develop a sex-specific and age-dependent\nclassification method to diagnose the Parkinson's disease using the online\nhandwriting recorded from individuals with\nParkinson's(n=37;m/f-19/18;age-69.3+-10.9years) and healthy\ncontrols(n=38;m/f-20/18;age-62.4+-11.3 years).The sex specific and age\ndependent classifier was observed significantly outperforming the generalized\nclassifier. An improved accuracy of 83.75%(SD+1.63) with female specific\nclassifier, and 79.55%(SD=1.58) with old age dependent classifier was observed\nin comparison to 75.76%(SD=1.17) accuracy with the generalized classifier.\nFinally, combining the age and sex information proved to be encouraging in\nclassification. We performed a rigorous analysis to observe the dominance of\nsex specific and age dependent features for Parkinson's detection and ranked\nthem using the support vector machine(SVM) ranking method. Distinct set of\nfeatures were observed to be dominating for higher classification accuracy in\ndifferent category of classification.\n", "versions": [{"version": "v1", "created": "Sun, 21 Apr 2019 19:36:26 GMT"}, {"version": "v2", "created": "Tue, 23 Apr 2019 11:48:47 GMT"}, {"version": "v3", "created": "Fri, 26 Apr 2019 07:49:10 GMT"}, {"version": "v4", "created": "Tue, 13 Aug 2019 11:32:50 GMT"}, {"version": "v5", "created": "Sun, 15 Dec 2019 13:02:21 GMT"}, {"version": "v6", "created": "Mon, 30 Dec 2019 14:54:26 GMT"}], "update_date": "2020-01-01", "authors_parsed": [["Gupta", "Ujjwal", ""], ["Bansal", "Hritik", ""], ["Joshi", "Deepak", ""]]}, {"id": "1904.09656", "submitter": "Satyasaran Changdar PhD", "authors": "Satyasaran Changdar and Snehangshu Bhattacharjee", "title": "Solution of Definite Integrals using Functional Link Artificial Neural\n  Networks", "comments": "14 pages, 7 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.NA", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  This paper discusses a new method to solve definite integrals using\nartificial neural networks. The objective is to build a neural network that\nwould be a novel alternative to pre-established numerical methods and with the\nhelp of a learning algorithm, be able to solve definite integrals, by\nminimising a well constructed error function. The proposed algorithm, with\nrespect to existing numerical methods, is effective and precise and well-suited\nfor purposes which require integration of higher order polynomials. The\nobservations have been recorded and illustrated in tabular and graphical form.\n", "versions": [{"version": "v1", "created": "Sun, 21 Apr 2019 20:52:18 GMT"}], "update_date": "2019-04-23", "authors_parsed": [["Changdar", "Satyasaran", ""], ["Bhattacharjee", "Snehangshu", ""]]}, {"id": "1904.09671", "submitter": "Rami Al-Rfou", "authors": "Rami Al-Rfou and Dustin Zelle and Bryan Perozzi", "title": "DDGK: Learning Graph Representations for Deep Divergence Graph Kernels", "comments": "www '19", "journal-ref": "Proceedings of the 2019 World Wide Web Conference (WWW '19), May\n  13--17, 2019, San Francisco, CA, USA", "doi": "10.1145/3308558.3313668", "report-no": null, "categories": "cs.LG cs.IR cs.SI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Can neural networks learn to compare graphs without feature engineering? In\nthis paper, we show that it is possible to learn representations for graph\nsimilarity with neither domain knowledge nor supervision (i.e.\\ feature\nengineering or labeled graphs). We propose Deep Divergence Graph Kernels, an\nunsupervised method for learning representations over graphs that encodes a\nrelaxed notion of graph isomorphism. Our method consists of three parts. First,\nwe learn an encoder for each anchor graph to capture its structure. Second, for\neach pair of graphs, we train a cross-graph attention network which uses the\nnode representations of an anchor graph to reconstruct another graph. This\napproach, which we call isomorphism attention, captures how well the\nrepresentations of one graph can encode another. We use the attention-augmented\nencoder's predictions to define a divergence score for each pair of graphs.\nFinally, we construct an embedding space for all graphs using these pair-wise\ndivergence scores.\n  Unlike previous work, much of which relies on 1) supervision, 2) domain\nspecific knowledge (e.g. a reliance on Weisfeiler-Lehman kernels), and 3) known\nnode alignment, our unsupervised method jointly learns node representations,\ngraph representations, and an attention-based alignment between graphs.\n  Our experimental results show that Deep Divergence Graph Kernels can learn an\nunsupervised alignment between graphs, and that the learned representations\nachieve competitive results when used as features on a number of challenging\ngraph classification tasks. Furthermore, we illustrate how the learned\nattention allows insight into the the alignment of sub-structures across\ngraphs.\n", "versions": [{"version": "v1", "created": "Sun, 21 Apr 2019 22:45:04 GMT"}], "update_date": "2019-04-23", "authors_parsed": [["Al-Rfou", "Rami", ""], ["Zelle", "Dustin", ""], ["Perozzi", "Bryan", ""]]}, {"id": "1904.09708", "submitter": "Jacob Russin", "authors": "Jake Russin, Jason Jo, Randall C. O'Reilly, Yoshua Bengio", "title": "Compositional generalization in a deep seq2seq model by separating\n  syntax and semantics", "comments": "18 pages, 15 figures, preprint version of submission to NeurIPS 2019,\n  under review", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CL stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Standard methods in deep learning for natural language processing fail to\ncapture the compositional structure of human language that allows for\nsystematic generalization outside of the training distribution. However, human\nlearners readily generalize in this way, e.g. by applying known grammatical\nrules to novel words. Inspired by work in neuroscience suggesting separate\nbrain systems for syntactic and semantic processing, we implement a\nmodification to standard approaches in neural machine translation, imposing an\nanalogous separation. The novel model, which we call Syntactic Attention,\nsubstantially outperforms standard methods in deep learning on the SCAN\ndataset, a compositional generalization task, without any hand-engineered\nfeatures or additional supervision. Our work suggests that separating syntactic\nfrom semantic learning may be a useful heuristic for capturing compositional\nstructure.\n", "versions": [{"version": "v1", "created": "Mon, 22 Apr 2019 03:12:09 GMT"}, {"version": "v2", "created": "Fri, 26 Apr 2019 16:05:35 GMT"}, {"version": "v3", "created": "Thu, 23 May 2019 20:59:12 GMT"}], "update_date": "2019-05-27", "authors_parsed": [["Russin", "Jake", ""], ["Jo", "Jason", ""], ["O'Reilly", "Randall C.", ""], ["Bengio", "Yoshua", ""]]}, {"id": "1904.09712", "submitter": "Qiuwei Li", "authors": "Qiuwei Li, Zhihui Zhu, Gongguo Tang, Michael B. Wakin", "title": "Provable Bregman-divergence based Methods for Nonconvex and\n  Non-Lipschitz Problems", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.OC cs.IT cs.LG math.IT stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The (global) Lipschitz smoothness condition is crucial in establishing the\nconvergence theory for most optimization methods. Unfortunately, most machine\nlearning and signal processing problems are not Lipschitz smooth. This\nmotivates us to generalize the concept of Lipschitz smoothness condition to the\nrelative smoothness condition, which is satisfied by any finite-order\npolynomial objective function. Further, this work develops new\nBregman-divergence based algorithms that are guaranteed to converge to a\nsecond-order stationary point for any relatively smooth problem. In addition,\nthe proposed optimization methods cover both the proximal alternating\nminimization and the proximal alternating linearized minimization when we\nspecialize the Bregman divergence to the Euclidian distance. Therefore, this\nwork not only develops guaranteed optimization methods for non-Lipschitz smooth\nproblems but also solves an open problem of showing the second-order\nconvergence guarantees for these alternating minimization methods.\n", "versions": [{"version": "v1", "created": "Mon, 22 Apr 2019 03:53:56 GMT"}], "update_date": "2019-04-23", "authors_parsed": [["Li", "Qiuwei", ""], ["Zhu", "Zhihui", ""], ["Tang", "Gongguo", ""], ["Wakin", "Michael B.", ""]]}, {"id": "1904.09743", "submitter": "Yu-Feng Li", "authors": "Lan-Zhe Guo, Yu-Feng Li, Ming Li, Jin-Feng Yi, Bo-Wen Zhou, Zhi-Hua\n  Zhou", "title": "Reliable Weakly Supervised Learning: Maximize Gain and Maintain Safeness", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Weakly supervised data are widespread and have attracted much attention.\nHowever, since label quality is often difficult to guarantee, sometimes the use\nof weakly supervised data will lead to unsatisfactory performance, i.e.,\nperformance degradation or poor performance gains. Moreover, it is usually not\nfeasible to manually increase the label quality, which results in weakly\nsupervised learning being somewhat difficult to rely on. In view of this\ncrucial issue, this paper proposes a simple and novel weakly supervised\nlearning framework. We guide the optimization of label quality through a small\namount of validation data, and to ensure the safeness of performance while\nmaximizing performance gain. As validation set is a good approximation for\ndescribing generalization risk, it can effectively avoid the unsatisfactory\nperformance caused by incorrect data distribution assumptions. We formalize\nthis underlying consideration into a novel Bi-Level optimization and give an\neffective solution. Extensive experimental results verify that the new\nframework achieves impressive performance on weakly supervised learning with a\nsmall amount of validation data.\n", "versions": [{"version": "v1", "created": "Mon, 22 Apr 2019 06:50:39 GMT"}], "update_date": "2019-04-23", "authors_parsed": [["Guo", "Lan-Zhe", ""], ["Li", "Yu-Feng", ""], ["Li", "Ming", ""], ["Yi", "Jin-Feng", ""], ["Zhou", "Bo-Wen", ""], ["Zhou", "Zhi-Hua", ""]]}, {"id": "1904.09764", "submitter": "Jiahui Huang", "authors": "Jiahui Huang, Kshitij Dwivedi, Gemma Roig", "title": "Deep Anchored Convolutional Neural Networks", "comments": "This paper is accepted to 2019 IEEE/CVF Conference on Computer Vision\n  and Pattern Recognition Workshops (CVPRW)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Convolutional Neural Networks (CNNs) have been proven to be extremely\nsuccessful at solving computer vision tasks. State-of-the-art methods favor\nsuch deep network architectures for its accuracy performance, with the cost of\nhaving massive number of parameters and high weights redundancy. Previous works\nhave studied how to prune such CNNs weights. In this paper, we go to another\nextreme and analyze the performance of a network stacked with a single\nconvolution kernel across layers, as well as other weights sharing techniques.\nWe name it Deep Anchored Convolutional Neural Network (DACNN). Sharing the same\nkernel weights across layers allows to reduce the model size tremendously, more\nprecisely, the network is compressed in memory by a factor of L, where L is the\ndesired depth of the network, disregarding the fully connected layer for\nprediction. The number of parameters in DACNN barely increases as the network\ngrows deeper, which allows us to build deep DACNNs without any concern about\nmemory costs. We also introduce a partial shared weights network (DACNN-mix) as\nwell as an easy-plug-in module, coined regulators, to boost the performance of\nour architecture. We validated our idea on 3 datasets: CIFAR-10, CIFAR-100 and\nSVHN. Our results show that we can save massive amounts of memory with our\nmodel, while maintaining a high accuracy performance.\n", "versions": [{"version": "v1", "created": "Mon, 22 Apr 2019 08:07:00 GMT"}], "update_date": "2019-04-23", "authors_parsed": [["Huang", "Jiahui", ""], ["Dwivedi", "Kshitij", ""], ["Roig", "Gemma", ""]]}, {"id": "1904.09765", "submitter": "Pradeep Rengaswamy", "authors": "Pradeep Rengaswamy, Gurunath Reddy M and Krothapalli Sreenivasa Rao", "title": "hf0: A hybrid pitch extraction method for multimodal voice", "comments": "Pitch Extraction, F0 extraction, harmonic signals, speech, monophonic\n  songs, Convolutional Neural Network, 5 pages, 5 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SD cs.LG eess.AS stat.ML", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Pitch or fundamental frequency (f0) extraction is a fundamental problem\nstudied extensively for its potential applications in speech and clinical\napplications. In literature, explicit mode specific (modal speech or singing\nvoice or emotional/ expressive speech or noisy speech) signal processing and\ndeep learning f0 extraction methods that exploit the quasi periodic nature of\nthe signal in time, harmonic property in spectral or combined form to extract\nthe pitch is developed. Hence, there is no single unified method which can\nreliably extract the pitch from various modes of the acoustic signal. In this\nwork, we propose a hybrid f0 extraction method which seamlessly extracts the\npitch across modes of speech production with very high accuracy required for\nmany applications. The proposed hybrid model exploits the advantages of deep\nlearning and signal processing methods to minimize the pitch detection error\nand adopts to various modes of acoustic signal. Specifically, we propose an\nordinal regression convolutional neural networks to map the periodicity rich\ninput representation to obtain the nominal pitch classes which drastically\nreduces the number of classes required for pitch detection unlike other deep\nlearning approaches. Further, the accurate f0 is estimated from the nominal\npitch class labels by filtering and autocorrelation. We show that the proposed\nmethod generalizes to the unseen modes of voice production and various noises\nfor large scale datasets. Also, the proposed hybrid model significantly reduces\nthe learning parameters required to train the deep model compared to other\nmethods. Furthermore,the evaluation measures showed that the proposed method is\nsignificantly better than the state-of-the-art signal processing and deep\nlearning approaches.\n", "versions": [{"version": "v1", "created": "Mon, 22 Apr 2019 08:08:12 GMT"}], "update_date": "2019-04-23", "authors_parsed": [["Rengaswamy", "Pradeep", ""], ["M", "Gurunath Reddy", ""], ["Rao", "Krothapalli Sreenivasa", ""]]}, {"id": "1904.09770", "submitter": "Erik Nijkamp", "authors": "Erik Nijkamp, Mitch Hill, Song-Chun Zhu, Ying Nian Wu", "title": "Learning Non-Convergent Non-Persistent Short-Run MCMC Toward\n  Energy-Based Model", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper studies a curious phenomenon in learning energy-based model (EBM)\nusing MCMC. In each learning iteration, we generate synthesized examples by\nrunning a non-convergent, non-mixing, and non-persistent short-run MCMC toward\nthe current model, always starting from the same initial distribution such as\nuniform noise distribution, and always running a fixed number of MCMC steps.\nAfter generating synthesized examples, we then update the model parameters\naccording to the maximum likelihood learning gradient, as if the synthesized\nexamples are fair samples from the current model. We treat this non-convergent\nshort-run MCMC as a learned generator model or a flow model. We provide\narguments for treating the learned non-convergent short-run MCMC as a valid\nmodel. We show that the learned short-run MCMC is capable of generating\nrealistic images. More interestingly, unlike traditional EBM or MCMC, the\nlearned short-run MCMC is capable of reconstructing observed images and\ninterpolating between images, like generator or flow models. The code can be\nfound in the Appendix.\n", "versions": [{"version": "v1", "created": "Mon, 22 Apr 2019 08:48:52 GMT"}, {"version": "v2", "created": "Sat, 18 May 2019 02:47:13 GMT"}, {"version": "v3", "created": "Mon, 27 May 2019 00:16:34 GMT"}, {"version": "v4", "created": "Mon, 25 Nov 2019 22:54:43 GMT"}], "update_date": "2019-11-27", "authors_parsed": [["Nijkamp", "Erik", ""], ["Hill", "Mitch", ""], ["Zhu", "Song-Chun", ""], ["Wu", "Ying Nian", ""]]}, {"id": "1904.09775", "submitter": "Babak Barazandeh", "authors": "Babak Barazandeh, Meisam Razaviyayn and Maziar Sanjabi", "title": "Training generative networks using random discriminators", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In recent years, Generative Adversarial Networks (GANs) have drawn a lot of\nattentions for learning the underlying distribution of data in various\napplications. Despite their wide applicability, training GANs is notoriously\ndifficult. This difficulty is due to the min-max nature of the resulting\noptimization problem and the lack of proper tools of solving general\n(non-convex, non-concave) min-max optimization problems. In this paper, we try\nto alleviate this problem by proposing a new generative network that relies on\nthe use of random discriminators instead of adversarial design. This design\nhelps us to avoid the min-max formulation and leads to an optimization problem\nthat is stable and could be solved efficiently. The performance of the proposed\nmethod is evaluated using handwritten digits (MNIST) and Fashion products\n(Fashion-MNIST) data sets. While the resulting images are not as sharp as\nadversarial training, the use of random discriminator leads to a much faster\nalgorithm as compared to the adversarial counterpart. This observation, at the\nminimum, illustrates the potential of the random discriminator approach for\nwarm-start in training GANs.\n", "versions": [{"version": "v1", "created": "Mon, 22 Apr 2019 08:53:18 GMT"}], "update_date": "2019-04-23", "authors_parsed": [["Barazandeh", "Babak", ""], ["Razaviyayn", "Meisam", ""], ["Sanjabi", "Maziar", ""]]}, {"id": "1904.09792", "submitter": "Sandeep Kumar", "authors": "Sandeep Kumar, Jiaxi Ying, Jos\\'e Vin\\'icius de M. Cardoso, and Daniel\n  Palomar", "title": "A Unified Framework for Structured Graph Learning via Spectral\n  Constraints", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG cs.SI math.OC", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Graph learning from data represents a canonical problem that has received\nsubstantial attention in the literature. However, insufficient work has been\ndone in incorporating prior structural knowledge onto the learning of\nunderlying graphical models from data. Learning a graph with a specific\nstructure is essential for interpretability and identification of the\nrelationships among data. Useful structured graphs include the multi-component\ngraph, bipartite graph, connected graph, sparse graph, and regular graph. In\ngeneral, structured graph learning is an NP-hard combinatorial problem,\ntherefore, designing a general tractable optimization method is extremely\nchallenging. In this paper, we introduce a unified graph learning framework\nlying at the integration of Gaussian graphical models and spectral graph\ntheory. To impose a particular structure on a graph, we first show how to\nformulate the combinatorial constraints as an analytical property of the graph\nmatrix. Then we develop an optimization framework that leverages graph learning\nwith specific structures via spectral constraints on graph matrices. The\nproposed algorithms are provably convergent, computationally efficient, and\npractically amenable for numerous graph-based tasks. Extensive numerical\nexperiments with both synthetic and real data sets illustrate the effectiveness\nof the proposed algorithms. The code for all the simulations is made available\nas an open source repository.\n", "versions": [{"version": "v1", "created": "Mon, 22 Apr 2019 10:19:58 GMT"}], "update_date": "2019-04-23", "authors_parsed": [["Kumar", "Sandeep", ""], ["Ying", "Jiaxi", ""], ["Cardoso", "Jos\u00e9 Vin\u00edcius de M.", ""], ["Palomar", "Daniel", ""]]}, {"id": "1904.09816", "submitter": "Sungrae Park", "authors": "Sungrae Park, Kyungwoo Song, Mingi Ji, Wonsung Lee, Il-Chul Moon", "title": "Adversarial Dropout for Recurrent Neural Networks", "comments": "published in AAAI19", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Successful application processing sequential data, such as text and speech,\nrequires an improved generalization performance of recurrent neural networks\n(RNNs). Dropout techniques for RNNs were introduced to respond to these\ndemands, but we conjecture that the dropout on RNNs could have been improved by\nadopting the adversarial concept. This paper investigates ways to improve the\ndropout for RNNs by utilizing intentionally generated dropout masks.\nSpecifically, the guided dropout used in this research is called as adversarial\ndropout, which adversarially disconnects neurons that are dominantly used to\npredict correct targets over time. Our analysis showed that our regularizer,\nwhich consists of a gap between the original and the reconfigured RNNs, was the\nupper bound of the gap between the training and the inference phases of the\nrandom dropout. We demonstrated that minimizing our regularizer improved the\neffectiveness of the dropout for RNNs on sequential MNIST tasks,\nsemi-supervised text classification tasks, and language modeling tasks.\n", "versions": [{"version": "v1", "created": "Mon, 22 Apr 2019 12:16:08 GMT"}], "update_date": "2019-04-23", "authors_parsed": [["Park", "Sungrae", ""], ["Song", "Kyungwoo", ""], ["Ji", "Mingi", ""], ["Lee", "Wonsung", ""], ["Moon", "Il-Chul", ""]]}, {"id": "1904.09841", "submitter": "Cameron Musco", "authors": "Cameron Musco and Christopher Musco and David P. Woodruff", "title": "Simple Heuristics Yield Provable Algorithms for Masked Low-Rank\n  Approximation", "comments": "ITCS 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.LG cs.NA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In $masked\\ low-rank\\ approximation$, one is given $A \\in \\mathbb{R}^{n\n\\times n}$ and binary mask matrix $W \\in \\{0,1\\}^{n \\times n}$. The goal is to\nfind a rank-$k$ matrix $L$ for which: $$cost(L) = \\sum_{i=1}^{n} \\sum_{j =\n1}^{n} W_{i,j} \\cdot (A_{i,j} - L_{i,j} )^2 \\leq OPT + \\epsilon \\|A\\|_F^2 ,$$\nwhere $OPT = \\min_{rank-k\\ \\hat{L}} cost(\\hat L)$ and $\\epsilon$ is a given\nerror parameter. Depending on the choice of $W$, this problem captures factor\nanalysis, low-rank plus diagonal decomposition, robust PCA, low-rank matrix\ncompletion, low-rank plus block matrix approximation, and many problems. Many\nof these problems are NP-hard, and while some algorithms with provable\nguarantees are known, they either 1) run in time $n^{\\Omega(k^2/\\epsilon)}$ or\n2) make strong assumptions, e.g., that $A$ is incoherent or that $W$ is random.\n  In this work, we show that a common polynomial time heuristic, which simply\nsets $A$ to $0$ where $W$ is $0$, and then finds a standard low-rank\napproximation, yields bicriteria approximation guarantees for this problem. In\nparticular, for rank $k' > k$ depending on the $public\\ coin\\ partition\\\nnumber$ of $W$, the heuristic outputs rank-$k'$ $L$ with cost$(L) \\leq OPT +\n\\epsilon \\|A\\|_F^2$. This partition number is in turn bounded by the\n$randomized\\ communication\\ complexity$ of $W$, when interpreted as a\ntwo-player communication matrix. For many important examples of masked low-rank\napproximation, including all those listed above, this result yields bicriteria\napproximation guarantees with $k' = k \\cdot poly(\\log n/\\epsilon)$.\n  Further, we show that different models of communication yield algorithms for\nnatural variants of masked low-rank approximation. For example, multi-player\nnumber-in-hand communication complexity connects to masked tensor decomposition\nand non-deterministic communication complexity to masked Boolean low-rank\nfactorization.\n", "versions": [{"version": "v1", "created": "Mon, 22 Apr 2019 13:01:07 GMT"}, {"version": "v2", "created": "Sat, 1 Feb 2020 14:55:26 GMT"}, {"version": "v3", "created": "Fri, 17 Apr 2020 17:33:07 GMT"}, {"version": "v4", "created": "Mon, 30 Nov 2020 05:32:14 GMT"}], "update_date": "2020-12-01", "authors_parsed": [["Musco", "Cameron", ""], ["Musco", "Christopher", ""], ["Woodruff", "David P.", ""]]}, {"id": "1904.09858", "submitter": "Hlynur Dav\\'i{\\dh} Hlynsson", "authors": "Hlynur Dav\\'i{\\dh} Hlynsson, Laurenz Wiskott", "title": "Learning gradient-based ICA by neurally estimating mutual information", "comments": "6 Pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Several methods of estimating the mutual information of random variables have\nbeen developed in recent years. They can prove valuable for novel approaches to\nlearning statistically independent features. In this paper, we use one of these\nmethods, a mutual information neural estimation (MINE) network, to present a\nproof-of-concept of how a neural network can perform linear ICA. We minimize\nthe mutual information, as estimated by a MINE network, between the output\nunits of a differentiable encoder network. This is done by simple alternate\noptimization of the two networks. The method is shown to get a qualitatively\nequal solution to FastICA on blind-source-separation of noisy sources.\n", "versions": [{"version": "v1", "created": "Mon, 22 Apr 2019 13:26:13 GMT"}], "update_date": "2019-04-23", "authors_parsed": [["Hlynsson", "Hlynur Dav\u00ed\u00f0", ""], ["Wiskott", "Laurenz", ""]]}, {"id": "1904.09872", "submitter": "Evgenii Zheltonozhskii", "authors": "Yochai Zur, Chaim Baskin, Evgenii Zheltonozhskii, Brian Chmiel, Itay\n  Evron, Alex M. Bronstein and Avi Mendelson", "title": "Towards Learning of Filter-Level Heterogeneous Compression of\n  Convolutional Neural Networks", "comments": "Accepted to ICML Workshop on AutoML 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG cs.NE", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Recently, deep learning has become a de facto standard in machine learning\nwith convolutional neural networks (CNNs) demonstrating spectacular success on\na wide variety of tasks. However, CNNs are typically very demanding\ncomputationally at inference time. One of the ways to alleviate this burden on\ncertain hardware platforms is quantization relying on the use of low-precision\narithmetic representation for the weights and the activations. Another popular\nmethod is the pruning of the number of filters in each layer. While mainstream\ndeep learning methods train the neural networks weights while keeping the\nnetwork architecture fixed, the emerging neural architecture search (NAS)\ntechniques make the latter also amenable to training. In this paper, we\nformulate optimal arithmetic bit length allocation and neural network pruning\nas a NAS problem, searching for the configurations satisfying a computational\ncomplexity budget while maximizing the accuracy. We use a differentiable search\nmethod based on the continuous relaxation of the search space proposed by Liu\net al. (arXiv:1806.09055). We show, by grid search, that heterogeneous\nquantized networks suffer from a high variance which renders the benefit of the\nsearch questionable. For pruning, improvement over homogeneous cases is\npossible, but it is still challenging to find those configurations with the\nproposed method. The code is publicly available at\nhttps://github.com/yochaiz/Slimmable and https://github.com/yochaiz/darts-UNIQ\n", "versions": [{"version": "v1", "created": "Mon, 22 Apr 2019 13:43:34 GMT"}, {"version": "v2", "created": "Mon, 29 Apr 2019 09:24:07 GMT"}, {"version": "v3", "created": "Sun, 9 Jun 2019 10:40:41 GMT"}, {"version": "v4", "created": "Thu, 26 Sep 2019 14:45:46 GMT"}], "update_date": "2019-09-27", "authors_parsed": [["Zur", "Yochai", ""], ["Baskin", "Chaim", ""], ["Zheltonozhskii", "Evgenii", ""], ["Chmiel", "Brian", ""], ["Evron", "Itay", ""], ["Bronstein", "Alex M.", ""], ["Mendelson", "Avi", ""]]}, {"id": "1904.09896", "submitter": "Carlton Shepherd", "authors": "Pradip Mainali and Carlton Shepherd", "title": "Privacy-Enhancing Fall Detection from Remote Sensor Data Using\n  Multi-Party Computation", "comments": "Accepted for publication in the Proceedings of the 14th International\n  Conference on Availability, Reliability and Security (ARES '19)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Motion-based fall detection systems are concerned with detecting falls from\nvulnerable users, which is typically performed by classifying measurements from\na body-worn inertial measurement unit (IMU) using machine learning. Such\nsystems, however, necessitate the collection of high-resolution measurements\nthat may violate users' privacy, such as revealing their gait, activities of\ndaily living (ADLs), and relative position using dead reckoning. In this paper,\nwe investigate the application of multi-party computation (MPC) to IMU-based\nfall detection for protecting device measurement confidentiality. Our system is\nevaluated in a cloud-based setting that precludes parties from learning the\nunderlying data using multiple, disparate cloud instances deployed in three\ngeographical configurations. Using a publicly-available dataset, we demonstrate\nthat MPC-based fall detection from IMU measurements is practical while\nachieving state-of-the-art error rates. In the best case, our system executes\nin 365.2 milliseconds, which falls well within the required time window for\non-device data acquisition (750ms).\n", "versions": [{"version": "v1", "created": "Mon, 22 Apr 2019 14:28:46 GMT"}, {"version": "v2", "created": "Thu, 20 Jun 2019 07:45:02 GMT"}], "update_date": "2019-06-21", "authors_parsed": [["Mainali", "Pradip", ""], ["Shepherd", "Carlton", ""]]}, {"id": "1904.09901", "submitter": "Adam Van Etten", "authors": "Adam Van Etten", "title": "City-scale Road Extraction from Satellite Imagery", "comments": "6 pages, 9 figures, 5 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Automated road network extraction from remote sensing imagery remains a\nsignificant challenge despite its importance in a broad array of applications.\nTo this end, we leverage recent open source advances and the high quality\nSpaceNet dataset to explore road network extraction at scale, an approach we\ncall City-scale Road Extraction from Satellite Imagery (CRESI). Specifically,\nwe create an algorithm to extract road networks directly from imagery over\ncity-scale regions, which can subsequently be used for routing purposes. We\nquantify the performance of our algorithm with the APLS and TOPO\ngraph-theoretic metrics over a diverse 608 square kilometer test area covering\nfour cities. We find an aggregate score of APLS = 0.73, and a TOPO score of\n0.58 (a significant improvement over existing methods). Inference speed is 160\nsquare kilometers per hour on modest hardware. Finally, we demonstrate that one\ncan use the extracted road network for any number of applications, such as\noptimized routing.\n", "versions": [{"version": "v1", "created": "Mon, 22 Apr 2019 14:36:57 GMT"}, {"version": "v2", "created": "Mon, 22 Jul 2019 16:00:47 GMT"}], "update_date": "2019-07-23", "authors_parsed": [["Van Etten", "Adam", ""]]}, {"id": "1904.09942", "submitter": "Michael P. Kim", "authors": "Sumegha Garg and Michael P. Kim and Omer Reingold", "title": "Tracking and Improving Information in the Service of Fairness", "comments": "Appeared at EC 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  As algorithmic prediction systems have become widespread, fears that these\nsystems may inadvertently discriminate against members of underrepresented\npopulations have grown. With the goal of understanding fundamental principles\nthat underpin the growing number of approaches to mitigating algorithmic\ndiscrimination, we investigate the role of information in fair prediction. A\ncommon strategy for decision-making uses a predictor to assign individuals a\nrisk score; then, individuals are selected or rejected on the basis of this\nscore. In this work, we study a formal framework for measuring the information\ncontent of predictors. Central to this framework is the notion of a refinement,\nfirst studied by Degroot and Fienberg. Intuitively, a refinement of a predictor\n$z$ increases the overall informativeness of the predictions without losing the\ninformation already contained in $z$. We show that increasing information\ncontent through refinements improves the downstream selection rules across a\nwide range of fairness measures (e.g. true positive rates, false positive\nrates, selection rates). In turn, refinements provide a simple but effective\ntool for reducing disparity in treatment and impact without sacrificing the\nutility of the predictions. Our results suggest that in many applications, the\nperceived \"cost of fairness\" results from an information disparity across\npopulations, and thus, may be avoided with improved information.\n", "versions": [{"version": "v1", "created": "Mon, 22 Apr 2019 16:35:24 GMT"}, {"version": "v2", "created": "Thu, 1 Aug 2019 16:39:16 GMT"}], "update_date": "2019-08-02", "authors_parsed": [["Garg", "Sumegha", ""], ["Kim", "Michael P.", ""], ["Reingold", "Omer", ""]]}, {"id": "1904.09948", "submitter": "Naresh Manwani", "authors": "Kulin Shah, P. S. Sastry, Naresh Manwani", "title": "PLUME: Polyhedral Learning Using Mixture of Experts", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we propose a novel mixture of expert architecture for learning\npolyhedral classifiers. We learn the parameters of the classifierusing an\nexpectation maximization algorithm. Wederive the generalization bounds of the\nproposedapproach. Through an extensive simulation study, we show that the\nproposed method performs comparably to other state-of-the-art approaches.\n", "versions": [{"version": "v1", "created": "Mon, 22 Apr 2019 16:50:04 GMT"}], "update_date": "2019-04-23", "authors_parsed": [["Shah", "Kulin", ""], ["Sastry", "P. S.", ""], ["Manwani", "Naresh", ""]]}, {"id": "1904.09959", "submitter": "Greg Anderson", "authors": "Greg Anderson, Shankara Pailoor, Isil Dillig, Swarat Chaudhuri", "title": "Optimization and Abstraction: A Synergistic Approach for Analyzing\n  Neural Network Robustness", "comments": null, "journal-ref": null, "doi": "10.1145/3314221.3314614", "report-no": null, "categories": "cs.PL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In recent years, the notion of local robustness (or robustness for short) has\nemerged as a desirable property of deep neural networks. Intuitively,\nrobustness means that small perturbations to an input do not cause the network\nto perform misclassifications. In this paper, we present a novel algorithm for\nverifying robustness properties of neural networks. Our method synergistically\ncombines gradient-based optimization methods for counterexample search with\nabstraction-based proof search to obtain a sound and ({\\delta}-)complete\ndecision procedure. Our method also employs a data-driven approach to learn a\nverification policy that guides abstract interpretation during proof search. We\nhave implemented the proposed approach in a tool called Charon and\nexperimentally evaluated it on hundreds of benchmarks. Our experiments show\nthat the proposed approach significantly outperforms three state-of-the-art\ntools, namely AI^2 , Reluplex, and Reluval.\n", "versions": [{"version": "v1", "created": "Mon, 22 Apr 2019 17:21:52 GMT"}, {"version": "v2", "created": "Wed, 1 May 2019 15:25:46 GMT"}], "update_date": "2019-05-02", "authors_parsed": [["Anderson", "Greg", ""], ["Pailoor", "Shankara", ""], ["Dillig", "Isil", ""], ["Chaudhuri", "Swarat", ""]]}, {"id": "1904.09980", "submitter": "Kyle Mott", "authors": "Kyle Mott", "title": "Estimating Forces of Robotic Pouring Using a LSTM RNN", "comments": "6 Pages, 14 Figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In machine learning, it is very important for a robot to be able to estimate\ndynamics from sequences of input data. This problem can be solved using a\nrecurrent neural network. In this paper, we will discuss the preprocessing of\n10 states of the dataset, then the use of a LSTM recurrent neural network to\nestimate one output state (dynamics) from the other 9 input states. We will\ndiscuss the architecture of the recurrent neural network, the data collection\nand preprocessing, the loss function, the results of the test data, and the\ndiscussion of changes that could improve the network. The results of this paper\nwill be used for artificial intelligence research and identify the capabilities\nof a LSTM recurrent neural network architecture to estimate dynamics of a\nsystem.\n", "versions": [{"version": "v1", "created": "Sun, 21 Apr 2019 23:35:24 GMT"}, {"version": "v2", "created": "Thu, 2 May 2019 02:59:06 GMT"}], "update_date": "2019-05-03", "authors_parsed": [["Mott", "Kyle", ""]]}, {"id": "1904.09981", "submitter": "Yang Gao", "authors": "Yang Gao, Hong Yang, Peng Zhang, Chuan Zhou, Yue Hu", "title": "GraphNAS: Graph Neural Architecture Search with Reinforcement Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Graph Neural Networks (GNNs) have been popularly used for analyzing\nnon-Euclidean data such as social network data and biological data. Despite\ntheir success, the design of graph neural networks requires a lot of manual\nwork and domain knowledge. In this paper, we propose a Graph Neural\nArchitecture Search method (GraphNAS for short) that enables automatic search\nof the best graph neural architecture based on reinforcement learning.\nSpecifically, GraphNAS first uses a recurrent network to generate\nvariable-length strings that describe the architectures of graph neural\nnetworks, and then trains the recurrent network with reinforcement learning to\nmaximize the expected accuracy of the generated architectures on a validation\ndata set. Extensive experimental results on node classification tasks in both\ntransductive and inductive learning settings demonstrate that GraphNAS can\nachieve consistently better performance on the Cora, Citeseer, Pubmed citation\nnetwork, and protein-protein interaction network. On node classification tasks,\nGraphNAS can design a novel network architecture that rivals the best\nhuman-invented architecture in terms of test set accuracy.\n", "versions": [{"version": "v1", "created": "Mon, 22 Apr 2019 07:13:10 GMT"}, {"version": "v2", "created": "Tue, 20 Aug 2019 03:00:40 GMT"}], "update_date": "2020-11-03", "authors_parsed": [["Gao", "Yang", ""], ["Yang", "Hong", ""], ["Zhang", "Peng", ""], ["Zhou", "Chuan", ""], ["Hu", "Yue", ""]]}, {"id": "1904.10020", "submitter": "Damek Davis", "authors": "Vasileios Charisopoulos, Yudong Chen, Damek Davis, Mateo D\\'iaz, Lijun\n  Ding, Dmitriy Drusvyatskiy", "title": "Low-rank matrix recovery with composite optimization: good conditioning\n  and rapid convergence", "comments": "80 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.OC cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The task of recovering a low-rank matrix from its noisy linear measurements\nplays a central role in computational science. Smooth formulations of the\nproblem often exhibit an undesirable phenomenon: the condition number,\nclassically defined, scales poorly with the dimension of the ambient space. In\ncontrast, we here show that in a variety of concrete circumstances, nonsmooth\npenalty formulations do not suffer from the same type of ill-conditioning.\nConsequently, standard algorithms for nonsmooth optimization, such as\nsubgradient and prox-linear methods, converge at a rapid dimension-independent\nrate when initialized within constant relative error of the solution. Moreover,\nnonsmooth formulations are naturally robust against outliers. Our framework\nsubsumes such important computational tasks as phase retrieval, blind\ndeconvolution, quadratic sensing, matrix completion, and robust PCA. Numerical\nexperiments on these problems illustrate the benefits of the proposed approach.\n", "versions": [{"version": "v1", "created": "Mon, 22 Apr 2019 18:36:56 GMT"}], "update_date": "2019-04-24", "authors_parsed": [["Charisopoulos", "Vasileios", ""], ["Chen", "Yudong", ""], ["Davis", "Damek", ""], ["D\u00edaz", "Mateo", ""], ["Ding", "Lijun", ""], ["Drusvyatskiy", "Dmitriy", ""]]}, {"id": "1904.10030", "submitter": "Davood Karimi", "authors": "Davood Karimi and Septimiu E. Salcudean", "title": "Reducing the Hausdorff Distance in Medical Image Segmentation with\n  Convolutional Neural Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.IV cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The Hausdorff Distance (HD) is widely used in evaluating medical image\nsegmentation methods. However, existing segmentation methods do not attempt to\nreduce HD directly. In this paper, we present novel loss functions for training\nconvolutional neural network (CNN)-based segmentation methods with the goal of\nreducing HD directly. We propose three methods to estimate HD from the\nsegmentation probability map produced by a CNN. One method makes use of the\ndistance transform of the segmentation boundary. Another method is based on\napplying morphological erosion on the difference between the true and estimated\nsegmentation maps. The third method works by applying circular/spherical\nconvolution kernels of different radii on the segmentation probability maps.\nBased on these three methods for estimating HD, we suggest three loss functions\nthat can be used for training to reduce HD. We use these loss functions to\ntrain CNNs for segmentation of the prostate, liver, and pancreas in ultrasound,\nmagnetic resonance, and computed tomography images and compare the results with\ncommonly-used loss functions. Our results show that the proposed loss functions\ncan lead to approximately 18-45 % reduction in HD without degrading other\nsegmentation performance criteria such as the Dice similarity coefficient. The\nproposed loss functions can be used for training medical image segmentation\nmethods in order to reduce the large segmentation errors.\n", "versions": [{"version": "v1", "created": "Mon, 22 Apr 2019 18:55:05 GMT"}], "update_date": "2019-04-24", "authors_parsed": [["Karimi", "Davood", ""], ["Salcudean", "Septimiu E.", ""]]}, {"id": "1904.10037", "submitter": "Chun-Liang Li", "authors": "Chun-Liang Li, Tomas Simon, Jason Saragih, Barnab\\'as P\\'oczos, Yaser\n  Sheikh", "title": "LBS Autoencoder: Self-supervised Fitting of Articulated Meshes to Point\n  Clouds", "comments": "In the Proceedings of IEEE Conference on Computer Vision and Pattern\n  Recognition (CVPR 2019)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present LBS-AE; a self-supervised autoencoding algorithm for fitting\narticulated mesh models to point clouds. As input, we take a sequence of point\nclouds to be registered as well as an artist-rigged mesh, i.e. a template mesh\nequipped with a linear-blend skinning (LBS) deformation space parameterized by\na skeleton hierarchy. As output, we learn an LBS-based autoencoder that\nproduces registered meshes from the input point clouds. To bridge the gap\nbetween the artist-defined geometry and the captured point clouds, our\nautoencoder models pose-dependent deviations from the template geometry. During\ntraining, instead of using explicit correspondences, such as key points or pose\nsupervision, our method leverages LBS deformations to bootstrap the learning\nprocess. To avoid poor local minima from erroneous point-to-point\ncorrespondences, we utilize a structured Chamfer distance based on\npart-segmentations, which are learned concurrently using self-supervision. We\ndemonstrate qualitative results on real captured hands, and report quantitative\nevaluations on the FAUST benchmark for body registration. Our method achieves\nperformance that is superior to other unsupervised approaches and comparable to\nmethods using supervised examples.\n", "versions": [{"version": "v1", "created": "Mon, 22 Apr 2019 19:12:18 GMT"}], "update_date": "2019-04-24", "authors_parsed": [["Li", "Chun-Liang", ""], ["Simon", "Tomas", ""], ["Saragih", "Jason", ""], ["P\u00f3czos", "Barnab\u00e1s", ""], ["Sheikh", "Yaser", ""]]}, {"id": "1904.10040", "submitter": "Djallel Bouneffouf", "authors": "Djallel Bouneffouf and Irina Rish", "title": "A Survey on Practical Applications of Multi-Armed and Contextual Bandits", "comments": "under review by IJCAI 2019 Survey", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In recent years, multi-armed bandit (MAB) framework has attracted a lot of\nattention in various applications, from recommender systems and information\nretrieval to healthcare and finance, due to its stellar performance combined\nwith certain attractive properties, such as learning from less feedback. The\nmulti-armed bandit field is currently flourishing, as novel problem settings\nand algorithms motivated by various practical applications are being\nintroduced, building on top of the classical bandit problem. This article aims\nto provide a comprehensive review of top recent developments in multiple\nreal-life applications of the multi-armed bandit. Specifically, we introduce a\ntaxonomy of common MAB-based applications and summarize state-of-art for each\nof those domains. Furthermore, we identify important current trends and provide\nnew perspectives pertaining to the future of this exciting and fast-growing\nfield.\n", "versions": [{"version": "v1", "created": "Tue, 2 Apr 2019 14:17:40 GMT"}], "update_date": "2019-04-24", "authors_parsed": [["Bouneffouf", "Djallel", ""], ["Rish", "Irina", ""]]}, {"id": "1904.10059", "submitter": "Hafiz Imtiaz", "authors": "Hafiz Imtiaz, Jafar Mohammadi, Anand D. Sarwate", "title": "Distributed Differentially Private Computation of Functions with\n  Correlated Noise", "comments": "The manuscript is partially subsumed by arXiv:1910.12913", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Many applications of machine learning, such as human health research, involve\nprocessing private or sensitive information. Privacy concerns may impose\nsignificant hurdles to collaboration in scenarios where there are multiple\nsites holding data and the goal is to estimate properties jointly across all\ndatasets. Differentially private decentralized algorithms can provide strong\nprivacy guarantees. However, the accuracy of the joint estimates may be poor\nwhen the datasets at each site are small. This paper proposes a new framework,\nCorrelation Assisted Private Estimation (CAPE), for designing\nprivacy-preserving decentralized algorithms with better accuracy guarantees in\nan honest-but-curious model. CAPE can be used in conjunction with the\nfunctional mechanism for statistical and machine learning optimization\nproblems. A tighter characterization of the functional mechanism is provided\nthat allows CAPE to achieve the same performance as a centralized algorithm in\nthe decentralized setting using all datasets. Empirical results on regression\nand neural network problems for both synthetic and real datasets show that\ndifferentially private methods can be competitive with non-private algorithms\nin many scenarios of interest.\n", "versions": [{"version": "v1", "created": "Mon, 22 Apr 2019 20:38:09 GMT"}, {"version": "v2", "created": "Fri, 3 May 2019 19:08:54 GMT"}, {"version": "v3", "created": "Tue, 23 Feb 2021 02:41:21 GMT"}], "update_date": "2021-02-24", "authors_parsed": [["Imtiaz", "Hafiz", ""], ["Mohammadi", "Jafar", ""], ["Sarwate", "Anand D.", ""]]}, {"id": "1904.10066", "submitter": "Marcus Scheunemann", "authors": "Marcus M. Scheunemann and Sander G. van Dijk and Rebecca Miko and\n  Daniel Barry and George M. Evans and Alessandra Rossi and Daniel Polani", "title": "Bold Hearts Team Description for RoboCup 2019 (Humanoid Kid Size League)", "comments": "Technical report", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.AI cs.CV cs.LG cs.SE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We participated in the RoboCup 2018 competition in Montreal with our newly\ndeveloped BoldBot based on the Darwin-OP and mostly self-printed custom parts.\nThis paper is about the lessons learnt from that competition and further\ndevelopments for the RoboCup 2019 competition. Firstly, we briefly introduce\nthe team along with an overview of past achievements. We then present a simple,\nstandalone 2D simulator we use for simplifying the entry for new members with\nmaking basic RoboCup concepts quickly accessible. We describe our approach for\nsemantic-segmentation for our vision used in the 2018 competition, which\nreplaced the lookup-table (LUT) implementation we had before. We also discuss\nthe extra structural support we plan to add to the printed parts of the BoldBot\nand our transition to ROS 2 as our new middleware. Lastly, we will present a\ncollection of open-source contributions of our team.\n", "versions": [{"version": "v1", "created": "Mon, 22 Apr 2019 21:10:25 GMT"}], "update_date": "2019-04-24", "authors_parsed": [["Scheunemann", "Marcus M.", ""], ["van Dijk", "Sander G.", ""], ["Miko", "Rebecca", ""], ["Barry", "Daniel", ""], ["Evans", "George M.", ""], ["Rossi", "Alessandra", ""], ["Polani", "Daniel", ""]]}, {"id": "1904.10076", "submitter": "Keren Gu", "authors": "Keren Gu, Brandon Yang, Jiquan Ngiam, Quoc Le, Jonathon Shlens", "title": "Using Videos to Evaluate Image Model Robustness", "comments": "Video Robustness Dataset included in directory", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Human visual systems are robust to a wide range of image transformations that\nare challenging for artificial networks. We present the first study of image\nmodel robustness to the minute transformations found across video frames, which\nwe term \"natural robustness\". Compared to previous studies on adversarial\nexamples and synthetic distortions, natural robustness captures a more diverse\nset of common image transformations that occur in the natural environment. Our\nstudy across a dozen model architectures shows that more accurate models are\nmore robust to natural transformations, and that robustness to synthetic color\ndistortions is a good proxy for natural robustness. In examining brittleness in\nvideos, we find that majority of the brittleness found in videos lies outside\nthe typical definition of adversarial examples (99.9\\%). Finally, we\ninvestigate training techniques to reduce brittleness and find that no single\ntechnique systematically improves natural robustness across twelve tested\narchitectures.\n", "versions": [{"version": "v1", "created": "Mon, 22 Apr 2019 22:13:22 GMT"}, {"version": "v2", "created": "Wed, 24 Apr 2019 16:58:54 GMT"}, {"version": "v3", "created": "Thu, 29 Aug 2019 23:18:47 GMT"}], "update_date": "2019-09-02", "authors_parsed": [["Gu", "Keren", ""], ["Yang", "Brandon", ""], ["Ngiam", "Jiquan", ""], ["Le", "Quoc", ""], ["Shlens", "Jonathon", ""]]}, {"id": "1904.10079", "submitter": "William Guss", "authors": "William H. Guss, Cayden Codel, Katja Hofmann, Brandon Houghton, Noboru\n  Kuno, Stephanie Milani, Sharada Mohanty, Diego Perez Liebana, Ruslan\n  Salakhutdinov, Nicholay Topin, Manuela Veloso, Phillip Wang", "title": "The MineRL 2019 Competition on Sample Efficient Reinforcement Learning\n  using Human Priors", "comments": "accepted at NeurIPS 2019, 28 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Though deep reinforcement learning has led to breakthroughs in many difficult\ndomains, these successes have required an ever-increasing number of samples. As\nstate-of-the-art reinforcement learning (RL) systems require an exponentially\nincreasing number of samples, their development is restricted to a continually\nshrinking segment of the AI community. Likewise, many of these systems cannot\nbe applied to real-world problems, where environment samples are expensive.\nResolution of these limitations requires new, sample-efficient methods. To\nfacilitate research in this direction, we introduce the MineRL Competition on\nSample Efficient Reinforcement Learning using Human Priors.\n  The primary goal of the competition is to foster the development of\nalgorithms which can efficiently leverage human demonstrations to drastically\nreduce the number of samples needed to solve complex, hierarchical, and sparse\nenvironments. To that end, we introduce: (1) the Minecraft ObtainDiamond task,\na sequential decision making environment requiring long-term planning,\nhierarchical control, and efficient exploration methods; and (2) the MineRL-v0\ndataset, a large-scale collection of over 60 million state-action pairs of\nhuman demonstrations that can be resimulated into embodied trajectories with\narbitrary modifications to game state and visuals.\n  Participants will compete to develop systems which solve the ObtainDiamond\ntask with a limited number of samples from the environment simulator, Malmo.\nThe competition is structured into two rounds in which competitors are provided\nseveral paired versions of the dataset and environment with different game\ntextures. At the end of each round, competitors will submit containerized\nversions of their learning algorithms and they will then be trained/evaluated\nfrom scratch on a hold-out dataset-environment pair for a total of 4-days on a\nprespecified hardware platform.\n", "versions": [{"version": "v1", "created": "Mon, 22 Apr 2019 22:18:37 GMT"}, {"version": "v2", "created": "Mon, 29 Jul 2019 18:24:24 GMT"}, {"version": "v3", "created": "Tue, 19 Jan 2021 07:47:28 GMT"}], "update_date": "2021-01-20", "authors_parsed": [["Guss", "William H.", ""], ["Codel", "Cayden", ""], ["Hofmann", "Katja", ""], ["Houghton", "Brandon", ""], ["Kuno", "Noboru", ""], ["Milani", "Stephanie", ""], ["Mohanty", "Sharada", ""], ["Liebana", "Diego Perez", ""], ["Salakhutdinov", "Ruslan", ""], ["Topin", "Nicholay", ""], ["Veloso", "Manuela", ""], ["Wang", "Phillip", ""]]}, {"id": "1904.10090", "submitter": "Erwan Lecarpentier", "authors": "Erwan Lecarpentier and Emmanuel Rachelson", "title": "Non-Stationary Markov Decision Processes, a Worst-Case Approach using\n  Model-Based Reinforcement Learning, Extended version", "comments": "Published at NeurIPS 2019, 17 pages, 3 figures", "journal-ref": "year: 2019; page range: 7214--7223", "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This work tackles the problem of robust zero-shot planning in non-stationary\nstochastic environments. We study Markov Decision Processes (MDPs) evolving\nover time and consider Model-Based Reinforcement Learning algorithms in this\nsetting. We make two hypotheses: 1) the environment evolves continuously with a\nbounded evolution rate; 2) a current model is known at each decision epoch but\nnot its evolution. Our contribution can be presented in four points. 1) we\ndefine a specific class of MDPs that we call Non-Stationary MDPs (NSMDPs). We\nintroduce the notion of regular evolution by making an hypothesis of\nLipschitz-Continuity on the transition and reward functions w.r.t. time; 2) we\nconsider a planning agent using the current model of the environment but\nunaware of its future evolution. This leads us to consider a worst-case method\nwhere the environment is seen as an adversarial agent; 3) following this\napproach, we propose the Risk-Averse Tree-Search (RATS) algorithm, a zero-shot\nModel-Based method similar to Minimax search; 4) we illustrate the benefits\nbrought by RATS empirically and compare its performance with reference\nModel-Based algorithms.\n", "versions": [{"version": "v1", "created": "Mon, 22 Apr 2019 23:19:03 GMT"}, {"version": "v2", "created": "Fri, 24 May 2019 09:39:01 GMT"}, {"version": "v3", "created": "Fri, 10 Jan 2020 16:43:46 GMT"}, {"version": "v4", "created": "Wed, 15 Jan 2020 16:32:47 GMT"}], "update_date": "2020-01-16", "authors_parsed": [["Lecarpentier", "Erwan", ""], ["Rachelson", "Emmanuel", ""]]}, {"id": "1904.10098", "submitter": "Jie Chen", "authors": "Yue Yu, Jie Chen, Tian Gao, Mo Yu", "title": "DAG-GNN: DAG Structure Learning with Graph Neural Networks", "comments": "ICML2019. Code is available at\n  https://github.com/fishmoon1234/DAG-GNN", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Learning a faithful directed acyclic graph (DAG) from samples of a joint\ndistribution is a challenging combinatorial problem, owing to the intractable\nsearch space superexponential in the number of graph nodes. A recent\nbreakthrough formulates the problem as a continuous optimization with a\nstructural constraint that ensures acyclicity (Zheng et al., 2018). The authors\napply the approach to the linear structural equation model (SEM) and the\nleast-squares loss function that are statistically well justified but\nnevertheless limited. Motivated by the widespread success of deep learning that\nis capable of capturing complex nonlinear mappings, in this work we propose a\ndeep generative model and apply a variant of the structural constraint to learn\nthe DAG. At the heart of the generative model is a variational autoencoder\nparameterized by a novel graph neural network architecture, which we coin\nDAG-GNN. In addition to the richer capacity, an advantage of the proposed model\nis that it naturally handles discrete variables as well as vector-valued ones.\nWe demonstrate that on synthetic data sets, the proposed method learns more\naccurate graphs for nonlinearly generated samples; and on benchmark data sets\nwith discrete variables, the learned graphs are reasonably close to the global\noptima. The code is available at \\url{https://github.com/fishmoon1234/DAG-GNN}.\n", "versions": [{"version": "v1", "created": "Mon, 22 Apr 2019 23:58:49 GMT"}], "update_date": "2019-04-24", "authors_parsed": [["Yu", "Yue", ""], ["Chen", "Jie", ""], ["Gao", "Tian", ""], ["Yu", "Mo", ""]]}, {"id": "1904.10100", "submitter": "Weifeng Liu", "authors": "Weifeng Liu and Dacheng Tao", "title": "Multiview Hessian Regularization for Image Annotation", "comments": null, "journal-ref": "IEEE Transactions on Image Processing, vol. 22, no. 7, pp. 2676 -\n  2687, 2013", "doi": "10.1109/TIP.2013.2255302", "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The rapid development of computer hardware and Internet technology makes\nlarge scale data dependent models computationally tractable, and opens a bright\navenue for annotating images through innovative machine learning algorithms.\nSemi-supervised learning (SSL) has consequently received intensive attention in\nrecent years and has been successfully deployed in image annotation. One\nrepresentative work in SSL is Laplacian regularization (LR), which smoothes the\nconditional distribution for classification along the manifold encoded in the\ngraph Laplacian, however, it has been observed that LR biases the\nclassification function towards a constant function which possibly results in\npoor generalization. In addition, LR is developed to handle uniformly\ndistributed data (or single view data), although instances or objects, such as\nimages and videos, are usually represented by multiview features, such as\ncolor, shape and texture. In this paper, we present multiview Hessian\nregularization (mHR) to address the above two problems in LR-based image\nannotation. In particular, mHR optimally combines multiple Hessian\nregularizations, each of which is obtained from a particular view of instances,\nand steers the classification function which varies linearly along the data\nmanifold. We apply mHR to kernel least squares and support vector machines as\ntwo examples for image annotation. Extensive experiments on the PASCAL VOC'07\ndataset validate the effectiveness of mHR by comparing it with baseline\nalgorithms, including LR and HR.\n", "versions": [{"version": "v1", "created": "Tue, 23 Apr 2019 00:08:43 GMT"}], "update_date": "2019-04-24", "authors_parsed": [["Liu", "Weifeng", ""], ["Tao", "Dacheng", ""]]}, {"id": "1904.10112", "submitter": "Yan Yan", "authors": "Yan Yan, Yi Xu, Qihang Lin, Lijun Zhang, Tianbao Yang", "title": "Stochastic Primal-Dual Algorithms with Faster Convergence than\n  $O(1/\\sqrt{T})$ for Problems without Bilinear Structure", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG math.OC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Previous studies on stochastic primal-dual algorithms for solving min-max\nproblems with faster convergence heavily rely on the bilinear structure of the\nproblem, which restricts their applicability to a narrowed range of problems.\nThe main contribution of this paper is the design and analysis of new\nstochastic primal-dual algorithms that use a mixture of stochastic gradient\nupdates and a logarithmic number of deterministic dual updates for solving a\nfamily of convex-concave problems with no bilinear structure assumed. Faster\nconvergence rates than $O(1/\\sqrt{T})$ with $T$ being the number of stochastic\ngradient updates are established under some mild conditions of involved\nfunctions on the primal and the dual variable. For example, for a family of\nproblems that enjoy a weak strong convexity in terms of the primal variable and\nhas a strongly concave function of the dual variable, the convergence rate of\nthe proposed algorithm is $O(1/T)$. We also investigate the effectiveness of\nthe proposed algorithms for learning robust models and empirical AUC\nmaximization.\n", "versions": [{"version": "v1", "created": "Tue, 23 Apr 2019 01:04:12 GMT"}, {"version": "v2", "created": "Wed, 18 Dec 2019 21:40:26 GMT"}], "update_date": "2019-12-20", "authors_parsed": [["Yan", "Yan", ""], ["Xu", "Yi", ""], ["Lin", "Qihang", ""], ["Zhang", "Lijun", ""], ["Yang", "Tianbao", ""]]}, {"id": "1904.10120", "submitter": "Nathan Srebro", "authors": "Hubert Eichner and Tomer Koren and H. Brendan McMahan and Nathan\n  Srebro and Kunal Talwar", "title": "Semi-Cyclic Stochastic Gradient Descent", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider convex SGD updates with a block-cyclic structure, i.e. where each\ncycle consists of a small number of blocks, each with many samples from a\npossibly different, block-specific, distribution. This situation arises, e.g.,\nin Federated Learning where the mobile devices available for updates at\ndifferent times during the day have different characteristics. We show that\nsuch block-cyclic structure can significantly deteriorate the performance of\nSGD, but propose a simple approach that allows prediction with the same\nperformance guarantees as for i.i.d., non-cyclic, sampling.\n", "versions": [{"version": "v1", "created": "Tue, 23 Apr 2019 02:17:15 GMT"}], "update_date": "2019-04-24", "authors_parsed": [["Eichner", "Hubert", ""], ["Koren", "Tomer", ""], ["McMahan", "H. Brendan", ""], ["Srebro", "Nathan", ""], ["Talwar", "Kunal", ""]]}, {"id": "1904.10122", "submitter": "James Freitag", "authors": "Hunter Chase and James Freitag", "title": "Bounds in Query Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG math.LO stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce new combinatorial quantities for concept classes, and prove\nlower and upper bounds for learning complexity in several models of query\nlearning in terms of various combinatorial quantities. Our approach is flexible\nand powerful enough to enough to give new and very short proofs of the\nefficient learnability of several prominent examples (e.g. regular languages\nand regular $\\omega$-languages), in some cases also producing new bounds on the\nnumber of queries. In the setting of equivalence plus membership queries, we\ngive an algorithm which learns a class in polynomially many queries whenever\nany such algorithm exists.\n  We also study equivalence query learning in a randomized model, producing new\nbounds on the expected number of queries required to learn an arbitrary\nconcept. Many of the techniques and notions of dimension draw inspiration from\nor are related to notions from model theory, and these connections are\nexplained. We also use techniques from query learning to mildly improve a\nresult of Laskowski regarding compression schemes.\n", "versions": [{"version": "v1", "created": "Tue, 23 Apr 2019 02:39:53 GMT"}], "update_date": "2019-04-24", "authors_parsed": [["Chase", "Hunter", ""], ["Freitag", "James", ""]]}, {"id": "1904.10130", "submitter": "John Brandt", "authors": "John Brandt", "title": "Spatio-temporal crop classification of low-resolution satellite imagery\n  with capsule layers and distributed attention", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Land use classification of low resolution spatial imagery is one of the most\nextensively researched fields in remote sensing. Despite significant\nadvancements in satellite technology, high resolution imagery lacks global\ncoverage and can be prohibitively expensive to procure for extended time\nperiods. Accurately classifying land use change without high resolution imagery\noffers the potential to monitor vital aspects of global development agenda\nincluding climate smart agriculture, drought resistant crops, and sustainable\nland management. Utilizing a combination of capsule layers and long-short term\nmemory layers with distributed attention, the present paper achieves\nstate-of-the-art accuracy on temporal crop type classification at a 30x30m\nresolution with Sentinel 2 imagery.\n", "versions": [{"version": "v1", "created": "Tue, 23 Apr 2019 03:05:31 GMT"}], "update_date": "2019-04-24", "authors_parsed": [["Brandt", "John", ""]]}, {"id": "1904.10142", "submitter": "Sanjay Sahay", "authors": "Hemant Rathore, Sanjay K. Sahay, Palash Chaturvedi and Mohit Sewak", "title": "Android Malicious Application Classification Using Clustering", "comments": "Springer, AISC, Volume 941, pp. 659-667, ISDA, 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Android malware have been growing at an exponential pace and becomes a\nserious threat to mobile users. It appears that most of the anti-malware still\nrelies on the signature-based detection system which is generally slow and\noften not able to detect advanced obfuscated malware. Hence time-to-time\nvarious authors have proposed different machine learning solutions to identify\nsophisticated malware. However, it appears that detection accuracy can be\nimproved by using the clustering method. Therefore in this paper, we propose a\nnovel scalable and effective clustering method to improve the detection\naccuracy of the malicious android application and obtained a better overall\naccuracy (98.34%) by random forest classifier compared to regular method, i.e.,\ntaking the data altogether to detect the malware. However, as far as true\npositive and true negative are concerned, by clustering method, true positive\nis best obtained by decision tree (97.59%) and true negative by support vector\nmachine (99.96%) which is the almost same result obtained by the random forest\ntrue positive (97.30%) and true negative (99.38%) respectively. The reason that\noverall accuracy of random forest is high because the true positive of support\nvector machine and true negative of the decision tree is significantly less\nthan the random forest.\n", "versions": [{"version": "v1", "created": "Sun, 21 Apr 2019 10:59:11 GMT"}], "update_date": "2019-04-24", "authors_parsed": [["Rathore", "Hemant", ""], ["Sahay", "Sanjay K.", ""], ["Chaturvedi", "Palash", ""], ["Sewak", "Mohit", ""]]}, {"id": "1904.10146", "submitter": "Xiang Gao", "authors": "Xiang Gao, Wei Hu, Zongming Guo", "title": "Exploring Structure-Adaptive Graph Learning for Robust Semi-Supervised\n  Classification", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Graph Convolutional Neural Networks (GCNNs) are generalizations of CNNs to\ngraph-structured data, in which convolution is guided by the graph topology. In\nmany cases where graphs are unavailable, existing methods manually construct\ngraphs or learn task-driven adaptive graphs. In this paper, we propose Graph\nLearning Neural Networks (GLNNs), which exploit the optimization of graphs (the\nadjacency matrix in particular) from both data and tasks. Leveraging on\nspectral graph theory, we propose the objective of graph learning from a\nsparsity constraint, properties of a valid adjacency matrix as well as a graph\nLaplacian regularizer via maximum a posteriori estimation. The optimization\nobjective is then integrated into the loss function of the GCNN, which adapts\nthe graph topology to not only labels of a specific task but also the input\ndata. Experimental results show that our proposed GLNN outperforms\nstate-of-the-art approaches over widely adopted social network datasets and\ncitation network datasets for semi-supervised classification.\n", "versions": [{"version": "v1", "created": "Tue, 23 Apr 2019 04:17:41 GMT"}, {"version": "v2", "created": "Mon, 16 Sep 2019 05:49:39 GMT"}], "update_date": "2019-09-17", "authors_parsed": [["Gao", "Xiang", ""], ["Hu", "Wei", ""], ["Guo", "Zongming", ""]]}, {"id": "1904.10154", "submitter": "Ronald Chang", "authors": "Shing-Jiuan Liu, Ronald Y. Chang, Feng-Tsun Chien", "title": "Analysis and Visualization of Deep Neural Networks in Device-Free Wi-Fi\n  Indoor Localization", "comments": "Accepted for publication in IEEE Access", "journal-ref": "IEEE Access, vol. 7, pp. 69379-69392, June 2019", "doi": "10.1109/ACCESS.2019.2918714", "report-no": null, "categories": "cs.NI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Device-free Wi-Fi indoor localization has received significant attention as a\nkey enabling technology for many Internet of Things (IoT) applications. Machine\nlearning-based location estimators, such as the deep neural network (DNN),\ncarry proven potential in achieving high-precision localization performance by\nautomatically learning discriminative features from the noisy wireless signal\nmeasurements. However, the inner workings of DNNs are not transparent and not\nadequately understood especially in the indoor localization application. In\nthis paper, we provide quantitative and visual explanations for the DNN\nlearning process as well as the critical features that DNN has learned during\nthe process. Toward this end, we propose to use several visualization\ntechniques, including: 1) dimensionality reduction visualization, to project\nthe high-dimensional feature space to the 2D space to facilitate visualization\nand interpretation, and 2) visual analytics and information visualization, to\nquantify relative contributions of each feature with the proposed feature\nmanipulation procedures. The results provide insightful views and plausible\nexplanations of the DNN in device-free Wi-Fi indoor localization using channel\nstate information (CSI) fingerprints.\n", "versions": [{"version": "v1", "created": "Tue, 23 Apr 2019 05:22:09 GMT"}, {"version": "v2", "created": "Wed, 22 May 2019 11:55:53 GMT"}], "update_date": "2021-01-29", "authors_parsed": [["Liu", "Shing-Jiuan", ""], ["Chang", "Ronald Y.", ""], ["Chien", "Feng-Tsun", ""]]}, {"id": "1904.10155", "submitter": "Lai Tian", "authors": "Lai Tian, Feiping Nie, Xuelong Li", "title": "Learning Feature Sparse Principal Components", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  This paper presents new algorithms to solve the feature-sparsity constrained\nPCA problem (FSPCA), which performs feature selection and PCA simultaneously.\nExisting optimization methods for FSPCA require data distribution assumptions\nand are lack of global convergence guarantee. Though the general FSPCA problem\nis NP-hard, we show that, for a low-rank covariance, FSPCA can be solved\nglobally (Algorithm 1). Then, we propose another strategy (Algorithm 2) to\nsolve FSPCA for the general covariance by iteratively building a carefully\ndesigned proxy. We prove theoretical guarantees on approximation and\nconvergence for the new algorithms. Experimental results show the promising\nperformance of the new algorithms compared with the state-of-the-arts on both\nsynthetic and real-world datasets.\n", "versions": [{"version": "v1", "created": "Tue, 23 Apr 2019 05:25:02 GMT"}, {"version": "v2", "created": "Sun, 26 May 2019 02:55:26 GMT"}], "update_date": "2019-05-28", "authors_parsed": [["Tian", "Lai", ""], ["Nie", "Feiping", ""], ["Li", "Xuelong", ""]]}, {"id": "1904.10165", "submitter": "Tao Li", "authors": "Tao Li, Jinwen Ma", "title": "T-SVD Based Non-convex Tensor Completion and Robust Principal Component\n  Analysis", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Tensor completion and robust principal component analysis have been widely\nused in machine learning while the key problem relies on the minimization of a\ntensor rank that is very challenging. A common way to tackle this difficulty is\nto approximate the tensor rank with the $\\ell_1-$norm of singular values based\non its Tensor Singular Value Decomposition (T-SVD). Besides, the sparsity of a\ntensor is also measured by its $\\ell_1-$norm. However, the $\\ell_1$ penalty is\nessentially biased and thus the result will deviate. In order to sidestep the\nbias, we propose a novel non-convex tensor rank surrogate function and a novel\nnon-convex sparsity measure. In this new setting by using the concavity instead\nof the convexity, a majorization minimization algorithm is further designed for\ntensor completion and robust principal component analysis. Furthermore, we\nanalyze its theoretical properties. Finally, the experiments on natural and\nhyperspectral images demonstrate the efficacy and efficiency of our proposed\nmethod.\n", "versions": [{"version": "v1", "created": "Tue, 23 Apr 2019 06:09:27 GMT"}, {"version": "v2", "created": "Tue, 25 May 2021 06:08:52 GMT"}], "update_date": "2021-05-26", "authors_parsed": [["Li", "Tao", ""], ["Ma", "Jinwen", ""]]}, {"id": "1904.10171", "submitter": "Tianyu Shi", "authors": "Tianyu Shi, Pin Wang, Xuxin Cheng, Ching-Yao Chan, Ding Huang", "title": "Driving Decision and Control for Autonomous Lane Change based on Deep\n  Reinforcement Learning", "comments": "This Paper has been submitted to ITSC 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We apply Deep Q-network (DQN) with the consideration of safety during the\ntask for deciding whether to conduct the maneuver. Furthermore, we design two\nsimilar Deep Q learning frameworks with quadratic approximator for deciding how\nto select a comfortable gap and just follow the preceding vehicle. Finally, a\npolynomial lane change trajectory is generated and Pure Pursuit Control is\nimplemented for path tracking. We demonstrate the effectiveness of this\nframework in simulation, from both the decision-making and control layers. The\nproposed architecture also has the potential to be extended to other autonomous\ndriving scenarios.\n", "versions": [{"version": "v1", "created": "Tue, 23 Apr 2019 06:27:18 GMT"}, {"version": "v2", "created": "Tue, 30 Jul 2019 07:18:11 GMT"}], "update_date": "2019-07-31", "authors_parsed": [["Shi", "Tianyu", ""], ["Wang", "Pin", ""], ["Cheng", "Xuxin", ""], ["Chan", "Ching-Yao", ""], ["Huang", "Ding", ""]]}, {"id": "1904.10237", "submitter": "Eita Nakamura", "authors": "Eita Nakamura, Yasuyuki Saito, Kazuyoshi Yoshii", "title": "Statistical Learning and Estimation of Piano Fingering", "comments": "30 pages, 8 figures, tex style changed, minor modifications", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.SD eess.AS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Automatic estimation of piano fingering is important for understanding the\ncomputational process of music performance and applicable to performance\nassistance and education systems. While a natural way to formulate the quality\nof fingerings is to construct models of the constraints/costs of performance,\nit is generally difficult to find appropriate parameter values for these\nmodels. Here we study an alternative data-driven approach based on statistical\nmodeling in which the appropriateness of a given fingering is described by\nprobabilities. Specifically, we construct two types of hidden Markov models\n(HMMs) and their higher-order extensions. We also study deep neural network\n(DNN)-based methods for comparison. Using a newly released dataset of fingering\nannotations, we conduct systematic evaluations of these models as well as a\nrepresentative constraint-based method. We find that the methods based on\nhigh-order HMMs outperform the other methods in terms of estimation accuracies.\nWe also quantitatively study individual difference of fingering and propose\nevaluation measures that can be used with multiple ground truth data. We\nconclude that the HMM-based methods are currently state of the art and generate\nacceptable fingerings in most parts and that they have certain limitations such\nas ignorance of phrase boundaries and interdependence of the two hands.\n", "versions": [{"version": "v1", "created": "Tue, 23 Apr 2019 10:25:31 GMT"}, {"version": "v2", "created": "Wed, 1 Jan 2020 14:43:48 GMT"}], "update_date": "2020-01-03", "authors_parsed": [["Nakamura", "Eita", ""], ["Saito", "Yasuyuki", ""], ["Yoshii", "Kazuyoshi", ""]]}, {"id": "1904.10255", "submitter": "Ahmed Imtiaz Humayun", "authors": "Ahmed Imtiaz Humayun, Asif Shahriyar Sushmit, Taufiq Hasan and\n  Mohammed Imamul Hassan Bhuiyan", "title": "End-to-end Sleep Staging with Raw Single Channel EEG using Deep Residual\n  ConvNets", "comments": "5 pages, 3 Figures, Appendix, IEEE BHI 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV eess.SP stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Humans approximately spend a third of their life sleeping, which makes\nmonitoring sleep an integral part of well-being. In this paper, a 34-layer deep\nresidual ConvNet architecture for end-to-end sleep staging is proposed. The\nnetwork takes raw single channel electroencephalogram (Fpz-Cz) signal as input\nand yields hypnogram annotations for each 30s segments as output. Experiments\nare carried out for two different scoring standards (5 and 6 stage\nclassification) on the expanded PhysioNet Sleep-EDF dataset, which contains\nmulti-source data from hospital and household polysomnography setups. The\nperformance of the proposed network is compared with that of the\nstate-of-the-art algorithms in patient independent validation tasks. The\nexperimental results demonstrate the superiority of the proposed network\ncompared to the best existing method, providing a relative improvement in\nepoch-wise average accuracy of 6.8% and 6.3% on the household data and\nmulti-source data, respectively. Codes are made publicly available on Github.\n", "versions": [{"version": "v1", "created": "Tue, 23 Apr 2019 11:32:46 GMT"}], "update_date": "2019-04-24", "authors_parsed": [["Humayun", "Ahmed Imtiaz", ""], ["Sushmit", "Asif Shahriyar", ""], ["Hasan", "Taufiq", ""], ["Bhuiyan", "Mohammed Imamul Hassan", ""]]}, {"id": "1904.10261", "submitter": "Aleksander Lukashou", "authors": "Aleksander Lukashou", "title": "Improving benchmarks for autonomous vehicles testing using synthetically\n  generated images", "comments": "4 pages, 38 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV cs.RO stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Nowadays autonomous technologies are a very heavily explored area and\nparticularly computer vision as the main component of vehicle perception. The\nquality of the whole vision system based on neural networks relies on the\ndataset it was trained on. It is extremely difficult to find traffic sign\ndatasets from most of the counties of the world. Meaning autonomous vehicle\nfrom the USA will not be able to drive though Lithuania recognizing all road\nsigns on the way. In this paper, we propose a solution on how to update model\nusing a small dataset from the country vehicle will be used in. It is important\nto mention that is not panacea, rather small upgrade which can boost autonomous\ncar development in countries with limited data access. We achieved about 10\npercent quality raise and expect even better results during future experiments.\n", "versions": [{"version": "v1", "created": "Tue, 23 Apr 2019 11:59:36 GMT"}], "update_date": "2019-04-24", "authors_parsed": [["Lukashou", "Aleksander", ""]]}, {"id": "1904.10272", "submitter": "ZhaoCheng Liu", "authors": "Zhaocheng Liu and Guangxue Yin", "title": "CPM-sensitive AUC for CTR prediction", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The prediction of click-through rate (CTR) is crucial for industrial\napplications, such as online advertising. AUC is a commonly used evaluation\nindicator for CTR models. For advertising platforms, online performance is\ngenerally evaluated by CPM. However, in practice, AUC often improves in offline\nevaluation, but online CPM does not. As a result, a huge waste of precious\nonline traffic and human costs has been caused. This is because there is a gap\nbetween offline AUC and online CPM. AUC can only reflect the order on CTR, but\nit does not reflect the order of CTR*Bid. Moreover, the bids of different\nadvertisements are different, so the loss of income caused by different\nreverse-order pair is also different. For this reason, we propose the\nCPM-sensitive AUC (csAUC) to solve all these problems. We also give the csAUC\ncalculation method based on dynamic programming. It can fully support the\ncalculation of csAUC on large-scale data in real-world applications.\n", "versions": [{"version": "v1", "created": "Tue, 23 Apr 2019 12:25:10 GMT"}], "update_date": "2019-04-24", "authors_parsed": [["Liu", "Zhaocheng", ""], ["Yin", "Guangxue", ""]]}, {"id": "1904.10273", "submitter": "Sainath Adapa", "authors": "Sainath Adapa", "title": "Sequential modeling of Sessions using Recurrent Neural Networks for Skip\n  Prediction", "comments": "4 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recommender systems play an essential role in music streaming services,\nprominently in the form of personalized playlists. Exploring the user\ninteractions within these listening sessions can be beneficial to understanding\nthe user preferences in the context of a single session. In the 'Spotify\nSequential Skip Prediction Challenge', WSDM, and Spotify are challenging people\nto understand the way users sequentially interact with music. We describe our\nsolution approach in this paper and also state proposals for further\nimprovements to the model. The proposed model initially generates a fixed\nvector representation of the session, and this additional information is\nincorporated into an Encoder-Decoder style architecture. This method achieved\nthe seventh position in the competition, with a mean average accuracy of 0.604\non the test set. The solution code is available at\nhttps://github.com/sainathadapa/spotify-sequential-skip-prediction.\n", "versions": [{"version": "v1", "created": "Tue, 23 Apr 2019 12:26:24 GMT"}], "update_date": "2019-04-24", "authors_parsed": [["Adapa", "Sainath", ""]]}, {"id": "1904.10281", "submitter": "Shuai Zhang", "authors": "Shuai Zhang and Yi Tay and Lina Yao and Qi Liu", "title": "Quaternion Knowledge Graph Embeddings", "comments": "Accepted by NeurIPS 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CL stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this work, we move beyond the traditional complex-valued representations,\nintroducing more expressive hypercomplex representations to model entities and\nrelations for knowledge graph embeddings. More specifically, quaternion\nembeddings, hypercomplex-valued embeddings with three imaginary components, are\nutilized to represent entities. Relations are modelled as rotations in the\nquaternion space. The advantages of the proposed approach are: (1) Latent\ninter-dependencies (between all components) are aptly captured with Hamilton\nproduct, encouraging a more compact interaction between entities and relations;\n(2) Quaternions enable expressive rotation in four-dimensional space and have\nmore degree of freedom than rotation in complex plane; (3) The proposed\nframework is a generalization of ComplEx on hypercomplex space while offering\nbetter geometrical interpretations, concurrently satisfying the key desiderata\nof relational representation learning (i.e., modeling symmetry, anti-symmetry\nand inversion). Experimental results demonstrate that our method achieves\nstate-of-the-art performance on four well-established knowledge graph\ncompletion benchmarks.\n", "versions": [{"version": "v1", "created": "Tue, 23 Apr 2019 12:36:59 GMT"}, {"version": "v2", "created": "Sat, 25 May 2019 06:11:16 GMT"}, {"version": "v3", "created": "Thu, 31 Oct 2019 12:45:00 GMT"}], "update_date": "2019-11-01", "authors_parsed": [["Zhang", "Shuai", ""], ["Tay", "Yi", ""], ["Yao", "Lina", ""], ["Liu", "Qi", ""]]}, {"id": "1904.10294", "submitter": "Zihao Wang", "authors": "Zihao Wang, Datong Zhou, Yong Zhang, Hao Wu, Chenglong Bao", "title": "Wasserstein-Fisher-Rao Document Distance", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CL stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  As a fundamental problem of natural language processing, it is important to\nmeasure the distance between different documents. Among the existing methods,\nthe Word Mover's Distance (WMD) has shown remarkable success in document\nsemantic matching for its clear physical insight as a parameter-free model.\nHowever, WMD is essentially based on the classical Wasserstein metric, thus it\noften fails to robustly represent the semantic similarity between texts of\ndifferent lengths. In this paper, we apply the newly developed\nWasserstein-Fisher-Rao (WFR) metric from unbalanced optimal transport theory to\nmeasure the distance between different documents. The proposed WFR document\ndistance maintains the great interpretability and simplicity as WMD. We\ndemonstrate that the WFR document distance has significant advantages when\ncomparing the texts of different lengths. In addition, an accelerated Sinkhorn\nbased algorithm with GPU implementation has been developed for the fast\ncomputation of WFR distances. The KNN classification results on eight datasets\nhave shown its clear improvement over WMD.\n", "versions": [{"version": "v1", "created": "Tue, 23 Apr 2019 13:11:40 GMT"}, {"version": "v2", "created": "Thu, 11 Jul 2019 08:55:21 GMT"}], "update_date": "2019-07-12", "authors_parsed": [["Wang", "Zihao", ""], ["Zhou", "Datong", ""], ["Zhang", "Yong", ""], ["Wu", "Hao", ""], ["Bao", "Chenglong", ""]]}, {"id": "1904.10337", "submitter": "Mile Sikic", "authors": "Neven Miculini\\'c, Marko Ratkovi\\'c, Mile \\v{S}iki\\'c", "title": "MinCall - MinION end2end convolutional deep learning basecaller", "comments": "2nd international workshop on deep learning for precision medicine,\n  ECML-PKDD 2017", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.GN cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The Oxford Nanopore Technologies's MinION is the first portable DNA\nsequencing device. It is capable of producing long reads, over 100 kBp were\nreported. However, it has significantly higher error rate than other methods.\nIn this study, we present MinCall, an end2end basecaller model for the MinION.\nThe model is based on deep learning and uses convolutional neural networks\n(CNN) in its implementation. For extra performance, it uses cutting edge deep\nlearning techniques and architectures, batch normalization and Connectionist\nTemporal Classification (CTC) loss. The best performing deep learning model\nachieves 91.4% median match rate on E. Coli dataset using R9 pore chemistry and\n1D reads.\n", "versions": [{"version": "v1", "created": "Mon, 22 Apr 2019 16:37:00 GMT"}], "update_date": "2019-04-24", "authors_parsed": [["Miculini\u0107", "Neven", ""], ["Ratkovi\u0107", "Marko", ""], ["\u0160iki\u0107", "Mile", ""]]}, {"id": "1904.10353", "submitter": "Mile Sikic", "authors": "Tomislav \\v{S}ebrek, Jan Tomljanovi\\'c, Josip Krapac, Mile \\v{S}iki\\'c", "title": "Read classification using semi-supervised deep learning", "comments": "2nd International Workshop on Deep Learning for Precision Medicine,\n  ECML-PKDD, 2017, Skopje, Nothern Macedonia", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG q-bio.GN stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we propose a semi-supervised deep learning method for\ndetecting the specific types of reads that impede the de novo genome assembly\nprocess. Instead of dealing directly with sequenced reads, we analyze their\ncoverage graphs converted to 1D-signals. We noticed that specific signal\npatterns occur in each relevant class of reads. Semi-supervised approach is\nchosen because manually labelling the data is a very slow and tedious process,\nso our goal was to facilitate the assembly process with as little labeled data\nas possible. We tested two models to learn patterns in the coverage graphs:\nM1+M2 and semi-GAN. We evaluated the performance of each model based on a\nmanually labeled dataset that comprises various reads from multiple reference\ngenomes with respect to the number of labeled examples that were used during\nthe training process. In addition, we embedded our detection in the assembly\nprocess which improved the quality of assemblies.\n", "versions": [{"version": "v1", "created": "Tue, 23 Apr 2019 14:25:42 GMT"}], "update_date": "2019-04-24", "authors_parsed": [["\u0160ebrek", "Tomislav", ""], ["Tomljanovi\u0107", "Jan", ""], ["Krapac", "Josip", ""], ["\u0160iki\u0107", "Mile", ""]]}, {"id": "1904.10359", "submitter": "Moa Johansson", "authors": "Moa Johansson, Marie Korneliusson, Nickey Lizbat Lawrence", "title": "Identifying cross country skiing techniques using power meters in ski\n  poles", "comments": "Presented at the Norwegian Artificial Intelligence Symposium 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Power meters are becoming a widely used tool for measuring training and\nracing effort in cycling, and are now spreading also to other sports. This\nmeans that increasing volumes of data can be collected from athletes, with the\naim of helping coaches and athletes analyse and understanding training load,\nracing efforts, technique etc. In this project, we have collaborated with\nSkisens AB, a company producing handles for cross country ski poles equipped\nwith power meters. We have conducted a pilot study in the use of machine\nlearning techniques on data from Skisens poles to identify which \"gear\" a skier\nis using (double poling or gears 2-4 in skating), based only on the sensor data\nfrom the ski poles. The dataset for this pilot study contained labelled\ntime-series data from three individual skiers using four different gears\nrecorded in varied locations and varied terrain. We systematically evaluated a\nnumber of machine learning techniques based on neural networks with best\nresults obtained by a LSTM network (accuracy of 95% correctly classified\nstrokes), when a subset of data from all three skiers was used for training. As\nexpected, accuracy dropped to 78% when the model was trained on data from only\ntwo skiers and tested on the third. To achieve better generalisation to\nindividuals not appearing in the training set more data is required, which is\nongoing work.\n", "versions": [{"version": "v1", "created": "Tue, 23 Apr 2019 14:43:10 GMT"}, {"version": "v2", "created": "Mon, 27 May 2019 13:27:28 GMT"}], "update_date": "2019-05-28", "authors_parsed": [["Johansson", "Moa", ""], ["Korneliusson", "Marie", ""], ["Lawrence", "Nickey Lizbat", ""]]}, {"id": "1904.10367", "submitter": "Gabriel de Souza Pereira Moreira", "authors": "Gabriel de Souza Pereira Moreira, Dietmar Jannach, Adilson Marques da\n  Cunha", "title": "Contextual Hybrid Session-based News Recommendation with Recurrent\n  Neural Networks", "comments": "20 pgs. Published at IEEE Access, Volume 7, 2019.\n  https://ieeexplore.ieee.org/document/8908688", "journal-ref": "IEEE Access 7 (2019): 169185-169203", "doi": "10.1109/ACCESS.2019.2954957", "report-no": null, "categories": "cs.IR cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recommender systems help users deal with information overload by providing\ntailored item suggestions to them. The recommendation of news is often\nconsidered to be challenging, since the relevance of an article for a user can\ndepend on a variety of factors, including the user's short-term reading\ninterests, the reader's context, or the recency or popularity of an article.\nPrevious work has shown that the use of Recurrent Neural Networks is promising\nfor the next-in-session prediction task, but has certain limitations when only\nrecorded item click sequences are used as input. In this work, we present a\ncontextual hybrid, deep learning based approach for session-based news\nrecommendation that is able to leverage a variety of information types. We\nevaluated our approach on two public datasets, using a temporal evaluation\nprotocol that simulates the dynamics of a news portal in a realistic way. Our\nresults confirm the benefits of considering additional types of information,\nincluding article popularity and recency, in the proposed way, resulting in\nsignificantly higher recommendation accuracy and catalog coverage than other\nsession-based algorithms. Additional experiments show that the proposed\nparameterizable loss function used in our method also allows us to balance two\nusually conflicting quality factors, accuracy and novelty.\n  Keywords: Artificial Neural Networks, Context-Aware Recommender Systems,\nHybrid Recommender Systems, News Recommender Systems, Session-based\nRecommendation\n", "versions": [{"version": "v1", "created": "Mon, 15 Apr 2019 21:47:43 GMT"}, {"version": "v2", "created": "Sun, 8 Dec 2019 16:56:09 GMT"}], "update_date": "2019-12-10", "authors_parsed": [["Moreira", "Gabriel de Souza Pereira", ""], ["Jannach", "Dietmar", ""], ["da Cunha", "Adilson Marques", ""]]}, {"id": "1904.10370", "submitter": "Jose Rodrigues Jr", "authors": "Jose F Rodrigues Jr, Larisa Florea, Maria C F de Oliveira, Dermot\n  Diamond, Osvaldo N Oliveira Jr", "title": "A survey on Big Data and Machine Learning for Chemistry", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "physics.chem-ph cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Herein we review aspects of leading-edge research and innovation in chemistry\nwhich exploits big data and machine learning (ML), two computer science fields\nthat combine to yield machine intelligence. ML can accelerate the solution of\nintricate chemical problems and even solve problems that otherwise would not be\ntractable. But the potential benefits of ML come at the cost of big data\nproduction; that is, the algorithms, in order to learn, demand large volumes of\ndata of various natures and from different sources, from materials properties\nto sensor data. In the survey, we propose a roadmap for future developments,\nwith emphasis on materials discovery and chemical sensing, and within the\ncontext of the Internet of Things (IoT), both prominent research fields for ML\nin the context of big data. In addition to providing an overview of recent\nadvances, we elaborate upon the conceptual and practical limitations of big\ndata and ML applied to chemistry, outlining processes, discussing pitfalls, and\nreviewing cases of success and failure.\n", "versions": [{"version": "v1", "created": "Tue, 23 Apr 2019 15:11:45 GMT"}], "update_date": "2019-04-24", "authors_parsed": [["Rodrigues", "Jose F", "Jr"], ["Florea", "Larisa", ""], ["de Oliveira", "Maria C F", ""], ["Diamond", "Dermot", ""], ["Oliveira", "Osvaldo N", "Jr"]]}, {"id": "1904.10387", "submitter": "C\\'edric B\\'eny", "authors": "C\\'edric B\\'eny", "title": "Learning relevant features for statistical inference", "comments": "Changes resulting from ICLR2020 submission and review. The\n  presentation now accounts for the close connection to previous work on deep\n  CCA", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG quant-ph stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Given two views of data, we consider the problem of finding the features of\none view which can be most faithfully inferred from the other. We find that\nthese are also the most correlated variables in the sense of deep canonical\ncorrelation analysis (DCCA). Moreover, we show that these variables can be used\nto construct a non-parametric representation of the implied joint probability\ndistribution, which can be thought of as a classical version of the Schmidt\ndecomposition of quantum states. This representation can be used to compute the\nexpectations of functions over one view of data conditioned on the other, such\nas Bayesian estimators and their standard deviations. We test the approach\nusing inference on occluded MNIST images, and show that our representation\ncontains multiple modes. Surprisingly, when applied to supervised learning (one\ndataset consists of labels), this approach automatically provides\nregularization and faster convergence compared to the cross-entropy objective.\nWe also explore using this approach to discover salient independent variables\nof a single dataset.\n", "versions": [{"version": "v1", "created": "Tue, 23 Apr 2019 15:29:04 GMT"}, {"version": "v2", "created": "Mon, 6 May 2019 03:27:20 GMT"}, {"version": "v3", "created": "Sun, 2 Jun 2019 02:56:39 GMT"}, {"version": "v4", "created": "Tue, 24 Mar 2020 13:47:56 GMT"}], "update_date": "2020-03-25", "authors_parsed": [["B\u00e9ny", "C\u00e9dric", ""]]}, {"id": "1904.10396", "submitter": "Adam Santoro", "authors": "Adam Santoro, Felix Hill, David Barrett, David Raposo, Matthew\n  Botvinick, Timothy Lillicrap", "title": "Is coding a relevant metaphor for building AI? A commentary on \"Is\n  coding a relevant metaphor for the brain?\", by Romain Brette", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.NC cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Brette contends that the neural coding metaphor is an invalid basis for\ntheories of what the brain does. Here, we argue that it is an insufficient\nguide for building an artificial intelligence that learns to accomplish short-\nand long-term goals in a complex, changing environment.\n", "versions": [{"version": "v1", "created": "Thu, 18 Apr 2019 14:58:52 GMT"}], "update_date": "2019-04-24", "authors_parsed": [["Santoro", "Adam", ""], ["Hill", "Felix", ""], ["Barrett", "David", ""], ["Raposo", "David", ""], ["Botvinick", "Matthew", ""], ["Lillicrap", "Timothy", ""]]}, {"id": "1904.10400", "submitter": "Abeegithan Jeyasothy", "authors": "Abeegithan Jeyasothy, Savitha Ramasamy, Suresh Sundaram", "title": "Efficient single input-output layer spiking neural classifier with\n  time-varying weight model", "comments": "8 pages, 2 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper presents a supervised learning algorithm, namely, the Synaptic\nEfficacy Function with Meta-neuron based learning algorithm (SEF-M) for a\nspiking neural network with a time-varying weight model. For a given pattern,\nSEF-M uses the learning algorithm derived from meta-neuron based learning\nalgorithm to determine the change in weights corresponding to each presynaptic\nspike times. The changes in weights modulate the amplitude of a Gaussian\nfunction centred at the same presynaptic spike times. The sum of amplitude\nmodulated Gaussian functions represents the synaptic efficacy functions (or\ntime-varying weight models). The performance of SEF-M is evaluated against\nstate-of-the-art spiking neural network learning algorithms on 10 benchmark\ndatasets from UCI machine learning repository. Performance studies show\nsuperior generalization ability of SEF-M. An ablation study on time-varying\nweight model is conducted using JAFFE dataset. The results of the ablation\nstudy indicate that using a time-varying weight model instead of single weight\nmodel improves the classification accuracy by 14%. Thus, it can be inferred\nthat a single input-output layer spiking neural network with time-varying\nweight model is computationally more efficient than a multi-layer spiking\nneural network with long-term or short-term weight model.\n", "versions": [{"version": "v1", "created": "Thu, 21 Mar 2019 06:49:01 GMT"}], "update_date": "2019-04-24", "authors_parsed": [["Jeyasothy", "Abeegithan", ""], ["Ramasamy", "Savitha", ""], ["Sundaram", "Suresh", ""]]}, {"id": "1904.10416", "submitter": "Haozhe Zhang", "authors": "Haozhe Zhang, Dan Nettleton, Zhengyuan Zhu", "title": "Regression-Enhanced Random Forests", "comments": "12 pages, 5 figures", "journal-ref": "In JSM Proceedings (2017), Section on Statistical Learning and\n  Data Science, Alexandria, VA: American Statistical Association. 636 -- 647", "doi": null, "report-no": null, "categories": "stat.ML cs.LG stat.ME", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Random forest (RF) methodology is one of the most popular machine learning\ntechniques for prediction problems. In this article, we discuss some cases\nwhere random forests may suffer and propose a novel generalized RF method,\nnamely regression-enhanced random forests (RERFs), that can improve on RFs by\nborrowing the strength of penalized parametric regression. The algorithm for\nconstructing RERFs and selecting its tuning parameters is described. Both\nsimulation study and real data examples show that RERFs have better predictive\nperformance than RFs in important situations often encountered in practice.\nMoreover, RERFs may incorporate known relationships between the response and\nthe predictors, and may give reliable predictions in extrapolation problems\nwhere predictions are required at points out of the domain of the training\ndataset. Strategies analogous to those described here can be used to improve\nother machine learning methods via combination with penalized parametric\nregression techniques.\n", "versions": [{"version": "v1", "created": "Tue, 23 Apr 2019 16:45:07 GMT"}], "update_date": "2019-04-24", "authors_parsed": [["Zhang", "Haozhe", ""], ["Nettleton", "Dan", ""], ["Zhu", "Zhengyuan", ""]]}, {"id": "1904.10446", "submitter": "Jason Chou", "authors": "Jason Chou, Gautam Hathi", "title": "Generated Loss, Augmented Training, and Multiscale VAE", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The variational autoencoder (VAE) framework remains a popular option for\ntraining unsupervised generative models, especially for discrete data where\ngenerative adversarial networks (GANs) require workaround to create gradient\nfor the generator. In our work modeling US postal addresses, we show that our\ndiscrete VAE with tree recursive architecture demonstrates limited capability\nof capturing field correlations within structured data, even after overcoming\nthe challenge of posterior collapse with scheduled sampling and tuning of the\nKL-divergence weight $\\beta$. Worse, VAE seems to have difficulty mapping its\ngenerated samples to the latent space, as their VAE loss lags behind or even\nincreases during the training process. Motivated by this observation, we show\nthat augmenting training data with generated variants (augmented training) and\ntraining a VAE with multiple values of $\\beta$ simultaneously (multiscale VAE)\nboth improve the generation quality of VAE. Despite their differences in\nmotivation and emphasis, we show that augmented training and multiscale VAE are\nactually connected and have similar effects on the model.\n", "versions": [{"version": "v1", "created": "Tue, 23 Apr 2019 17:53:59 GMT"}], "update_date": "2019-04-24", "authors_parsed": [["Chou", "Jason", ""], ["Hathi", "Gautam", ""]]}, {"id": "1904.10450", "submitter": "Lijiang Guo", "authors": "Lijiang Guo", "title": "Latent Variable Algorithms for Multimodal Learning and Sensor Fusion", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.SD eess.AS stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Multimodal learning has been lacking principled ways of combining information\nfrom different modalities and learning a low-dimensional manifold of meaningful\nrepresentations. We study multimodal learning and sensor fusion from a latent\nvariable perspective. We first present a regularized recurrent attention filter\nfor sensor fusion. This algorithm can dynamically combine information from\ndifferent types of sensors in a sequential decision making task. Each sensor is\nbonded with a modular neural network to maximize utility of its own\ninformation. A gating modular neural network dynamically generates a set of\nmixing weights for outputs from sensor networks by balancing utility of all\nsensors' information. We design a co-learning mechanism to encourage\nco-adaption and independent learning of each sensor at the same time, and\npropose a regularization based co-learning method. In the second part, we focus\non recovering the manifold of latent representation. We propose a co-learning\napproach using probabilistic graphical model which imposes a structural prior\non the generative model: multimodal variational RNN (MVRNN) model, and derive a\nvariational lower bound for its objective functions. In the third part, we\nextend the siamese structure to sensor fusion for robust acoustic event\ndetection. We perform experiments to investigate the latent representations\nthat are extracted; works will be done in the following months. Our experiments\nshow that the recurrent attention filter can dynamically combine different\nsensor inputs according to the information carried in the inputs. We consider\nMVRNN can identify latent representations that are useful for many downstream\ntasks such as speech synthesis, activity recognition, and control and planning.\nBoth algorithms are general frameworks which can be applied to other tasks\nwhere different types of sensors are jointly used for decision making.\n", "versions": [{"version": "v1", "created": "Tue, 23 Apr 2019 17:58:19 GMT"}], "update_date": "2019-04-24", "authors_parsed": [["Guo", "Lijiang", ""]]}, {"id": "1904.10500", "submitter": "Eda Okur", "authors": "Eda Okur, Shachi H Kumar, Saurav Sahay, Asli Arslan Esme, Lama Nachman", "title": "Natural Language Interactions in Autonomous Vehicles: Intent Detection\n  and Slot Filling from Passenger Utterances", "comments": "Accepted and presented as a full paper at 20th International\n  Conference on Computational Linguistics and Intelligent Text Processing\n  (CICLing 2019), April 7-13, 2019, La Rochelle, France", "journal-ref": "Springer LNCS Proceedings for CICLing 2019", "doi": null, "report-no": null, "categories": "cs.CL cs.HC cs.LG cs.SD eess.AS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Understanding passenger intents and extracting relevant slots are important\nbuilding blocks towards developing contextual dialogue systems for natural\ninteractions in autonomous vehicles (AV). In this work, we explored AMIE\n(Automated-vehicle Multi-modal In-cabin Experience), the in-cabin agent\nresponsible for handling certain passenger-vehicle interactions. When the\npassengers give instructions to AMIE, the agent should parse such commands\nproperly and trigger the appropriate functionality of the AV system. In our\ncurrent explorations, we focused on AMIE scenarios describing usages around\nsetting or changing the destination and route, updating driving behavior or\nspeed, finishing the trip and other use-cases to support various natural\ncommands. We collected a multi-modal in-cabin dataset with multi-turn dialogues\nbetween the passengers and AMIE using a Wizard-of-Oz scheme via a realistic\nscavenger hunt game activity. After exploring various recent Recurrent Neural\nNetworks (RNN) based techniques, we introduced our own hierarchical joint\nmodels to recognize passenger intents along with relevant slots associated with\nthe action to be performed in AV scenarios. Our experimental results\noutperformed certain competitive baselines and achieved overall F1 scores of\n0.91 for utterance-level intent detection and 0.96 for slot filling tasks. In\naddition, we conducted initial speech-to-text explorations by comparing\nintent/slot models trained and tested on human transcriptions versus noisy\nAutomatic Speech Recognition (ASR) outputs. Finally, we compared the results\nwith single passenger rides versus the rides with multiple passengers.\n", "versions": [{"version": "v1", "created": "Tue, 23 Apr 2019 19:13:51 GMT"}], "update_date": "2019-04-25", "authors_parsed": [["Okur", "Eda", ""], ["Kumar", "Shachi H", ""], ["Sahay", "Saurav", ""], ["Esme", "Asli Arslan", ""], ["Nachman", "Lama", ""]]}, {"id": "1904.10504", "submitter": "Li Chen", "authors": "Li Chen", "title": "Understanding the efficacy, reliability and resiliency of computer\n  vision techniques for malware detection and future research directions", "comments": "Report", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  My research lies in the intersection of security and machine learning. This\noverview summarizes one component of my research: combining computer vision\nwith malware exploit detection for enhanced security solutions. I will present\nthe perspectives of efficacy, reliability and resiliency to formulate threat\ndetection as computer vision problems and develop state-of-the-art image-based\nmalware classification. Representing malware binary as images provides a direct\nvisualization of data samples, reduces the efforts for feature extraction, and\nconsumes the whole binary for holistic structural analysis. Employing transfer\nlearning of deep neural networks effective for large scale image classification\nto malware classification demonstrates superior classification efficacy\ncompared with classical machine learning algorithms. To enhance reliability of\nthese vision-based malware detectors, interpretation frameworks can be\nconstructed on the malware visual representations and useful for extracting\nfaithful explanation, so that security practitioners have confidence in the\nmodel before deployment. In cyber-security applications, we should always\nassume that a malware writer constantly modifies code to bypass detection.\nAddressing the resiliency of the malware detectors is equivalently important as\nefficacy and reliability. Via understanding the attack surfaces of machine\nlearning models used for malware detection, we can greatly improve the\nrobustness of the algorithms to combat malware adversaries in the wild. Finally\nI will discuss future research directions worth pursuing in this research\ncommunity.\n", "versions": [{"version": "v1", "created": "Wed, 3 Apr 2019 18:34:20 GMT"}], "update_date": "2019-04-25", "authors_parsed": [["Chen", "Li", ""]]}, {"id": "1904.10509", "submitter": "Rewon Child", "authors": "Rewon Child, Scott Gray, Alec Radford, and Ilya Sutskever", "title": "Generating Long Sequences with Sparse Transformers", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Transformers are powerful sequence models, but require time and memory that\ngrows quadratically with the sequence length. In this paper we introduce sparse\nfactorizations of the attention matrix which reduce this to $O(n \\sqrt{n})$. We\nalso introduce a) a variation on architecture and initialization to train\ndeeper networks, b) the recomputation of attention matrices to save memory, and\nc) fast attention kernels for training. We call networks with these changes\nSparse Transformers, and show they can model sequences tens of thousands of\ntimesteps long using hundreds of layers. We use the same architecture to model\nimages, audio, and text from raw bytes, setting a new state of the art for\ndensity modeling of Enwik8, CIFAR-10, and ImageNet-64. We generate\nunconditional samples that demonstrate global coherence and great diversity,\nand show it is possible in principle to use self-attention to model sequences\nof length one million or more.\n", "versions": [{"version": "v1", "created": "Tue, 23 Apr 2019 19:29:47 GMT"}], "update_date": "2019-04-25", "authors_parsed": [["Child", "Rewon", ""], ["Gray", "Scott", ""], ["Radford", "Alec", ""], ["Sutskever", "Ilya", ""]]}, {"id": "1904.10522", "submitter": "Hyunsu Cho", "authors": "Theodore Vasiloudis, Hyunsu Cho, Henrik Bostr\\\"om", "title": "Block-distributed Gradient Boosted Trees", "comments": "SIGIR 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.IR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The Gradient Boosted Tree (GBT) algorithm is one of the most popular machine\nlearning algorithms used in production, for tasks that include Click-Through\nRate (CTR) prediction and learning-to-rank. To deal with the massive datasets\navailable today, many distributed GBT methods have been proposed. However, they\nall assume a row-distributed dataset, addressing scalability only with respect\nto the number of data points and not the number of features, and increasing\ncommunication cost for high-dimensional data. In order to allow for scalability\nacross both the data point and feature dimensions, and reduce communication\ncost, we propose block-distributed GBTs. We achieve communication efficiency by\nmaking full use of the data sparsity and adapting the Quickscorer algorithm to\nthe block-distributed setting. We evaluate our approach using datasets with\nmillions of features, and demonstrate that we are able to achieve multiple\norders of magnitude reduction in communication cost for sparse data, with no\nloss in accuracy, while providing a more scalable design. As a result, we are\nable to reduce the training time for high-dimensional data, and allow more\ncost-effective scale-out without the need for expensive network communication.\n", "versions": [{"version": "v1", "created": "Tue, 23 Apr 2019 20:10:36 GMT"}, {"version": "v2", "created": "Tue, 28 May 2019 19:32:35 GMT"}], "update_date": "2019-05-30", "authors_parsed": [["Vasiloudis", "Theodore", ""], ["Cho", "Hyunsu", ""], ["Bostr\u00f6m", "Henrik", ""]]}, {"id": "1904.10523", "submitter": "Shuaiqiang Liu", "authors": "Shuaiqiang Liu, Anastasia Borovykh, Lech A. Grzelak and Cornelis W.\n  Oosterlee", "title": "A neural network-based framework for financial model calibration", "comments": "34 pages, 9 figures, 11 tables", "journal-ref": "J.Math.Industry 9, 9 (2019)", "doi": "10.1186/s13362-019-0066-7", "report-no": null, "categories": "q-fin.CP cs.LG q-fin.MF", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A data-driven approach called CaNN (Calibration Neural Network) is proposed\nto calibrate financial asset price models using an Artificial Neural Network\n(ANN). Determining optimal values of the model parameters is formulated as\ntraining hidden neurons within a machine learning framework, based on available\nfinancial option prices. The framework consists of two parts: a forward pass in\nwhich we train the weights of the ANN off-line, valuing options under many\ndifferent asset model parameter settings; and a backward pass, in which we\nevaluate the trained ANN-solver on-line, aiming to find the weights of the\nneurons in the input layer. The rapid on-line learning of implied volatility by\nANNs, in combination with the use of an adapted parallel global optimization\nmethod, tackles the computation bottleneck and provides a fast and reliable\ntechnique for calibrating model parameters while avoiding, as much as possible,\ngetting stuck in local minima. Numerical experiments confirm that this\nmachine-learning framework can be employed to calibrate parameters of\nhigh-dimensional stochastic volatility models efficiently and accurately.\n", "versions": [{"version": "v1", "created": "Tue, 23 Apr 2019 20:12:18 GMT"}], "update_date": "2020-02-03", "authors_parsed": [["Liu", "Shuaiqiang", ""], ["Borovykh", "Anastasia", ""], ["Grzelak", "Lech A.", ""], ["Oosterlee", "Cornelis W.", ""]]}, {"id": "1904.10551", "submitter": "Arjun Pakrashi", "authors": "Arjun Pakrashi, Brian Mac Namee", "title": "CascadeML: An Automatic Neural Network Architecture Evolution and\n  Training Algorithm for Multi-label Classification", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Multi-label classification is an approach which allows a datapoint to be\nlabelled with more than one class at the same time. A common but trivial\napproach is to train individual binary classifiers per label, but the\nperformance can be improved by considering associations within the labels. Like\nwith any machine learning algorithm, hyperparameter tuning is important to\ntrain a good multi-label classifier model. The task of selecting the best\nhyperparameter settings for an algorithm is an optimisation problem. Very\nlimited work has been done on automatic hyperparameter tuning and AutoML in the\nmulti-label domain. This paper attempts to fill this gap by proposing a neural\nnetwork algorithm, CascadeML, to train multi-label neural network based on\ncascade neural networks. This method requires minimal or no hyperparameter\ntuning and also considers pairwise label associations. The cascade algorithm\ngrows the network architecture incrementally in a two phase process as it\nlearns the weights using adaptive first order gradient algorithm, therefore\nomitting the requirement of preselecting the number of hidden layers, nodes and\nthe learning rate. The method was tested on 10 multi-label datasets and\ncompared with other multi-label classification algorithms. Results show that\nCascadeML performs very well without hyperparameter tuning.\n", "versions": [{"version": "v1", "created": "Tue, 23 Apr 2019 22:05:51 GMT"}], "update_date": "2019-04-25", "authors_parsed": [["Pakrashi", "Arjun", ""], ["Mac Namee", "Brian", ""]]}, {"id": "1904.10552", "submitter": "Arjun Pakrashi", "authors": "Arjun Pakrashi, Brian Mac Namee", "title": "ML-KFHE: Multi-label ensemble classification algorithm exploiting sensor\n  fusion properties of the Kalman filter", "comments": "The paper is under consideration at Information Fusion, Elsevier", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Despite the success of ensemble classification methods in multi-class\nclassification problems, ensemble methods based on approaches other than\nbagging have not been widely explored for multi-label classification problems.\nThe Kalman Filter-based Heuristic Ensemble (KFHE) is a recent ensemble method\nthat exploits the sensor fusion properties of the Kalman filter to combine\nseveral classifier models, and that has been shown to be very effective. This\nwork proposes a multi-label version of KFHE, ML-KFHE, demonstrating the\neffectiveness of the KFHE method on multi-label datasets. Two variants are\nintroduced based on the underlying component classifier algorithm,\nML-KFHE-HOMER, and ML-KFHE-CC which uses HOMER and Classifier Chain (CC) as the\nunderlying multi-label algorithms respectively. ML-KFHE-HOMER and ML-KFHE-CC\nsequentially trains multiple HOMER and CC multi-label classifiers and\naggregates their outputs using the sensor fusion properties of the Kalman\nfilter. Experiments and detailed analysis performed on thirteen multi-label\ndatasets and eight other algorithms, including state-of-the-art ensemble\nmethods, show that for both versions, the ML-KFHE framework improves the\nensembling process significantly with respect to bagging based combinations of\nHOMER and CC, thus demonstrating the effectiveness of ML-KFHE. Also, the\nML-KFHE-HOMER variant was found to perform consistently and significantly\nbetter than existing multi-label methods including existing approaches based on\nensembles.\n", "versions": [{"version": "v1", "created": "Tue, 23 Apr 2019 22:10:50 GMT"}, {"version": "v2", "created": "Mon, 11 Nov 2019 20:56:54 GMT"}, {"version": "v3", "created": "Wed, 10 Mar 2021 15:49:56 GMT"}], "update_date": "2021-03-11", "authors_parsed": [["Pakrashi", "Arjun", ""], ["Mac Namee", "Brian", ""]]}, {"id": "1904.10554", "submitter": "Sebastian Jaimungal", "authors": "Philippe Casgrain, Brian Ning, Sebastian Jaimungal", "title": "Deep Q-Learning for Nash Equilibria: Nash-DQN", "comments": "16 pages, 4 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.GT q-fin.CP stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Model-free learning for multi-agent stochastic games is an active area of\nresearch. Existing reinforcement learning algorithms, however, are often\nrestricted to zero-sum games, and are applicable only in small state-action\nspaces or other simplified settings. Here, we develop a new data efficient\nDeep-Q-learning methodology for model-free learning of Nash equilibria for\ngeneral-sum stochastic games. The algorithm uses a local linear-quadratic\nexpansion of the stochastic game, which leads to analytically solvable optimal\nactions. The expansion is parametrized by deep neural networks to give it\nsufficient flexibility to learn the environment without the need to experience\nall state-action pairs. We study symmetry properties of the algorithm stemming\nfrom label-invariant stochastic games and as a proof of concept, apply our\nalgorithm to learning optimal trading strategies in competitive electronic\nmarkets.\n", "versions": [{"version": "v1", "created": "Tue, 23 Apr 2019 22:18:59 GMT"}], "update_date": "2019-04-25", "authors_parsed": [["Casgrain", "Philippe", ""], ["Ning", "Brian", ""], ["Jaimungal", "Sebastian", ""]]}, {"id": "1904.10573", "submitter": "Max Wilson", "authors": "Max Wilson, Thomas Vandal, Tad Hogg, Eleanor Rieffel", "title": "Quantum-assisted associative adversarial network: Applying quantum\n  annealing in deep learning", "comments": null, "journal-ref": "Quantum Machine Intelligence 3:19 (2021)", "doi": "10.1007/s42484-021-00047-9", "report-no": null, "categories": "cs.LG quant-ph stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present an algorithm for learning a latent variable generative model via\ngenerative adversarial learning where the canonical uniform noise input is\nreplaced by samples from a graphical model. This graphical model is learned by\na Boltzmann machine which learns low-dimensional feature representation of data\nextracted by the discriminator. A quantum annealer, the D-Wave 2000Q, is used\nto sample from this model. This algorithm joins a growing family of algorithms\nthat use a quantum annealing subroutine in deep learning, and provides a\nframework to test the advantages of quantum-assisted learning in GANs. Fully\nconnected, symmetric bipartite and Chimera graph topologies are compared on a\nreduced stochastically binarized MNIST dataset, for both classical and quantum\nannealing sampling methods. The quantum-assisted associative adversarial\nnetwork successfully learns a generative model of the MNIST dataset for all\ntopologies, and is also applied to the LSUN dataset bedrooms class for the\nChimera topology. Evaluated using the Fr\\'{e}chet inception distance and\ninception score, the quantum and classical versions of the algorithm are found\nto have equivalent performance for learning an implicit generative model of the\nMNIST dataset.\n", "versions": [{"version": "v1", "created": "Tue, 23 Apr 2019 23:57:40 GMT"}], "update_date": "2021-07-05", "authors_parsed": [["Wilson", "Max", ""], ["Vandal", "Thomas", ""], ["Hogg", "Tad", ""], ["Rieffel", "Eleanor", ""]]}, {"id": "1904.10574", "submitter": "Hasan Manzour", "authors": "Hasan Manzour, Simge K\\\"u\\c{c}\\\"ukyavuz, Ali Shojaie", "title": "Integer Programming for Learning Directed Acyclic Graphs from Continuous\n  Data", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.DM stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Learning directed acyclic graphs (DAGs) from data is a challenging task both\nin theory and in practice, because the number of possible DAGs scales\nsuperexponentially with the number of nodes. In this paper, we study the\nproblem of learning an optimal DAG from continuous observational data. We cast\nthis problem in the form of a mathematical programming model which can\nnaturally incorporate a super-structure in order to reduce the set of possible\ncandidate DAGs. We use the penalized negative log-likelihood score function\nwith both $\\ell_0$ and $\\ell_1$ regularizations and propose a new mixed-integer\nquadratic optimization (MIQO) model, referred to as a layered network (LN)\nformulation. The LN formulation is a compact model, which enjoys as tight an\noptimal continuous relaxation value as the stronger but larger formulations\nunder a mild condition. Computational results indicate that the proposed\nformulation outperforms existing mathematical formulations and scales better\nthan available algorithms that can solve the same problem with only $\\ell_1$\nregularization. In particular, the LN formulation clearly outperforms existing\nmethods in terms of computational time needed to find an optimal DAG in the\npresence of a sparse super-structure.\n", "versions": [{"version": "v1", "created": "Tue, 23 Apr 2019 23:58:40 GMT"}], "update_date": "2019-04-25", "authors_parsed": [["Manzour", "Hasan", ""], ["K\u00fc\u00e7\u00fckyavuz", "Simge", ""], ["Shojaie", "Ali", ""]]}, {"id": "1904.10583", "submitter": "Thomas Uriot Tu", "authors": "Thomas Uriot", "title": "Kernel Mean Embedding of Instance-wise Predictions in Multiple Instance\n  Regression", "comments": "KDD 2019, FEED Workshop", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we propose an extension to an existing algorithm\n(instance-MIR) which tackles the multiple instance regression (MIR) problem,\nalso known as distribution regression. The MIR setting arises when the data is\na collection of bags, where each bag consists of several instances which\ncorrespond to the same and unique real-valued label. The goal of a MIR\nalgorithm is to find a mapping from the instances of an unseen bag to its\ntarget value. The instance-MIR algorithm treats all the instances separately\nand maps each instance to a label. The final bag label is then taken as the\nmean or the median of the predictions for that given bag. While it is\nconceptually simple, taking a single statistic to summarize the distribution of\nthe labels in each bag is a limitation. In spite of this performance\nbottleneck, the instance-MIR algorithm has been shown to be competitive when\ncompared to the current state-of-the-art methods. We address the aforementioned\nissue by computing the kernel mean embeddings of the distributions of the\npredicted labels, for each bag, and learn a regressor from these embeddings to\nthe bag label. We test our algorithm (instance-kme-MIR) on five real world\ndatasets and obtain better results than the baseline instance-MIR across all\nthe datasets, while achieving state-of-the-art results on two of the datasets.\n", "versions": [{"version": "v1", "created": "Wed, 24 Apr 2019 00:24:55 GMT"}, {"version": "v2", "created": "Sun, 18 Aug 2019 16:37:47 GMT"}], "update_date": "2019-08-20", "authors_parsed": [["Uriot", "Thomas", ""]]}, {"id": "1904.10584", "submitter": "Sree Hari Krishnan Parthasarathi", "authors": "Sree Hari Krishnan Parthasarathi, Nitin Sivakrishnan, Pranav Ladkat,\n  Nikko Strom", "title": "Realizing Petabyte Scale Acoustic Modeling", "comments": "2156-3357 \\copyright 2019 IEEE. Personal use is permitted, but\n  republication/redistribution requires IEEE permission. See\n  http://www.ieee.org/publications standards/publications/rights/index.html for\n  more information", "journal-ref": null, "doi": "10.1109/JETCAS.2019.2912353", "report-no": null, "categories": "cs.SD cs.LG eess.AS stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Large scale machine learning (ML) systems such as the Alexa automatic speech\nrecognition (ASR) system continue to improve with increasing amounts of\nmanually transcribed training data. Instead of scaling manual transcription to\nimpractical levels, we utilize semi-supervised learning (SSL) to learn acoustic\nmodels (AM) from the vast firehose of untranscribed audio data. Learning an AM\nfrom 1 Million hours of audio presents unique ML and system design challenges.\nWe present the design and evaluation of a highly scalable and resource\nefficient SSL system for AM. Employing the student/teacher learning paradigm,\nwe focus on the student learning subsystem: a scalable and robust data pipeline\nthat generates features and targets from raw audio, and an efficient model\npipeline, including the distributed trainer, that builds a student model. Our\nevaluations show that, even without extensive hyper-parameter tuning, we obtain\nrelative accuracy improvements in the 10 to 20$\\%$ range, with higher gains in\nnoisier conditions. The end-to-end processing time of this SSL system was 12\ndays, and several components in this system can trivially scale linearly with\nmore compute resources.\n", "versions": [{"version": "v1", "created": "Wed, 24 Apr 2019 00:39:25 GMT"}], "update_date": "2019-04-25", "authors_parsed": [["Parthasarathi", "Sree Hari Krishnan", ""], ["Sivakrishnan", "Nitin", ""], ["Ladkat", "Pranav", ""], ["Strom", "Nikko", ""]]}, {"id": "1904.10597", "submitter": "Xiaohu Zhang", "authors": "Ruisheng Diao, Zhiwei Wang, Di Shi, Qianyun Chang, Jiajun Duan, Xiaohu\n  Zhang", "title": "Autonomous Voltage Control for Grid Operation Using Deep Reinforcement\n  Learning", "comments": "To be published (Accepted) in: Proceedings of the Power and Energy\n  Society General Meeting (PESGM), Atlanta, GA, 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SY cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Modern power grids are experiencing grand challenges caused by the stochastic\nand dynamic nature of growing renewable energy and demand response. Traditional\ntheoretical assumptions and operational rules may be violated, which are\ndifficult to be adapted by existing control systems due to the lack of\ncomputational power and accurate grid models for use in real time, leading to\ngrowing concerns in the secure and economic operation of the power grid.\nExisting operational control actions are typically determined offline, which\nare less optimized. This paper presents a novel paradigm, Grid Mind, for\nautonomous grid operational controls using deep reinforcement learning. The\nproposed AI agent for voltage control can learn its control policy through\ninteractions with massive offline simulations, and adapts its behavior to new\nchanges including not only load/generation variations but also topological\nchanges. A properly trained agent is tested on the IEEE 14-bus system with tens\nof thousands of scenarios, and promising performance is demonstrated in\napplying autonomous voltage controls for secure grid operation.\n", "versions": [{"version": "v1", "created": "Wed, 24 Apr 2019 01:34:04 GMT"}], "update_date": "2019-04-25", "authors_parsed": [["Diao", "Ruisheng", ""], ["Wang", "Zhiwei", ""], ["Shi", "Di", ""], ["Chang", "Qianyun", ""], ["Duan", "Jiajun", ""], ["Zhang", "Xiaohu", ""]]}, {"id": "1904.10604", "submitter": "Xulei Yang", "authors": "Xuetong Niu, Li Wang, Xulei Yang", "title": "A Comparison Study of Credit Card Fraud Detection: Supervised versus\n  Unsupervised", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Credit card has become popular mode of payment for both online and offline\npurchase, which leads to increasing daily fraud transactions. An Efficient\nfraud detection methodology is therefore essential to maintain the reliability\nof the payment system. In this study, we perform a comparison study of credit\ncard fraud detection by using various supervised and unsupervised approaches.\nSpecifically, 6 supervised classification models, i.e., Logistic Regression\n(LR), K-Nearest Neighbors (KNN), Support Vector Machines (SVM), Decision Tree\n(DT), Random Forest (RF), Extreme Gradient Boosting (XGB), as well as 4\nunsupervised anomaly detection models, i.e., One-Class SVM (OCSVM),\nAuto-Encoder (AE), Restricted Boltzmann Machine (RBM), and Generative\nAdversarial Networks (GAN), are explored in this study. We train all these\nmodels on a public credit card transaction dataset from Kaggle website, which\ncontains 492 frauds out of 284,807 transactions. The labels of the transactions\nare used for supervised learning models only. The performance of each model is\nevaluated through 5-fold cross validation in terms of Area Under the Receiver\nOperating Curves (AUROC). Within supervised approaches, XGB and RF obtain the\nbest performance with AUROC = 0.989 and AUROC = 0.988, respectively. While for\nunsupervised approaches, RBM achieves the best performance with AUROC = 0.961,\nfollowed by GAN with AUROC = 0.954. The experimental results show that\nsupervised models perform slightly better than unsupervised models in this\nstudy. Anyway, unsupervised approaches are still promising for credit card\nfraud transaction detection due to the insufficient annotation and the data\nimbalance issue in real-world applications.\n", "versions": [{"version": "v1", "created": "Wed, 24 Apr 2019 01:59:27 GMT"}], "update_date": "2019-04-25", "authors_parsed": [["Niu", "Xuetong", ""], ["Wang", "Li", ""], ["Yang", "Xulei", ""]]}, {"id": "1904.10616", "submitter": "Song Han", "authors": "Song Han, Han Cai, Ligeng Zhu, Ji Lin, Kuan Wang, Zhijian Liu, Yujun\n  Lin", "title": "Design Automation for Efficient Deep Learning Computing", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Efficient deep learning computing requires algorithm and hardware co-design\nto enable specialization: we usually need to change the algorithm to reduce\nmemory footprint and improve energy efficiency. However, the extra degree of\nfreedom from the algorithm makes the design space much larger: it's not only\nabout designing the hardware but also about how to tweak the algorithm to best\nfit the hardware. Human engineers can hardly exhaust the design space by\nheuristics. It's labor consuming and sub-optimal. We propose design automation\ntechniques for efficient neural networks. We investigate automatically\ndesigning specialized fast models, auto channel pruning, and auto\nmixed-precision quantization. We demonstrate such learning-based, automated\ndesign achieves superior performance and efficiency than rule-based human\ndesign. Moreover, we shorten the design cycle by 200x than previous work, so\nthat we can afford to design specialized neural network models for different\nhardware platforms.\n", "versions": [{"version": "v1", "created": "Wed, 24 Apr 2019 02:45:44 GMT"}], "update_date": "2019-04-25", "authors_parsed": [["Han", "Song", ""], ["Cai", "Han", ""], ["Zhu", "Ligeng", ""], ["Lin", "Ji", ""], ["Wang", "Kuan", ""], ["Liu", "Zhijian", ""], ["Lin", "Yujun", ""]]}, {"id": "1904.10619", "submitter": "Hongzhu Li", "authors": "Hongzhu Li, Weiqiang Wang", "title": "Reinterpreting CTC training as iterative fitting", "comments": "to be published in Pattern Recognition", "journal-ref": null, "doi": "10.1016/j.patcog.2020.107392", "report-no": null, "categories": "cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The connectionist temporal classification (CTC) enables end-to-end sequence\nlearning by maximizing the probability of correctly recognizing sequences\nduring training. The outputs of a CTC-trained model tend to form a series of\nspikes separated by strongly predicted blanks, know as the spiky problem. To\nfigure out the reason for it, we reinterpret the CTC training process as an\niterative fitting task that is based on frame-wise cross-entropy loss. It\noffers us an intuitive way to compare target probabilities with model outputs\nfor each iteration, and explain how the model outputs gradually turns spiky.\nInspired by it, we put forward two ways to modify the CTC training. The\nexperiments demonstrate that our method can well solve the spiky problem and\nmoreover, lead to faster convergence over various training settings. Beside\nthis, the reinterpretation of CTC, as a brand new perspective, may be\npotentially useful in other situations. The code is publicly available at\nhttps://github.com/hzli-ucas/caffe/tree/ctc.\n", "versions": [{"version": "v1", "created": "Wed, 24 Apr 2019 02:50:29 GMT"}, {"version": "v2", "created": "Tue, 7 Jul 2020 09:18:11 GMT"}], "update_date": "2020-07-08", "authors_parsed": [["Li", "Hongzhu", ""], ["Wang", "Weiqiang", ""]]}, {"id": "1904.10631", "submitter": "Nimit Sohoni", "authors": "Nimit Sharad Sohoni and Christopher Richard Aberger and Megan\n  Leszczynski and Jian Zhang and Christopher R\\'e", "title": "Low-Memory Neural Network Training: A Technical Report", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Memory is increasingly often the bottleneck when training neural network\nmodels. Despite this, techniques to lower the overall memory requirements of\ntraining have been less widely studied compared to the extensive literature on\nreducing the memory requirements of inference. In this paper we study a\nfundamental question: How much memory is actually needed to train a neural\nnetwork? To answer this question, we profile the overall memory usage of\ntraining on two representative deep learning benchmarks -- the WideResNet model\nfor image classification and the DynamicConv Transformer model for machine\ntranslation -- and comprehensively evaluate four standard techniques for\nreducing the training memory requirements: (1) imposing sparsity on the model,\n(2) using low precision, (3) microbatching, and (4) gradient checkpointing. We\nexplore how each of these techniques in isolation affects both the peak memory\nusage of training and the quality of the end model, and explore the memory,\naccuracy, and computation tradeoffs incurred when combining these techniques.\nUsing appropriate combinations of these techniques, we show that it is possible\nto the reduce the memory required to train a WideResNet-28-2 on CIFAR-10 by up\nto 60.7x with a 0.4% loss in accuracy, and reduce the memory required to train\na DynamicConv model on IWSLT'14 German to English translation by up to 8.7x\nwith a BLEU score drop of 0.15.\n", "versions": [{"version": "v1", "created": "Wed, 24 Apr 2019 03:44:58 GMT"}], "update_date": "2019-04-25", "authors_parsed": [["Sohoni", "Nimit Sharad", ""], ["Aberger", "Christopher Richard", ""], ["Leszczynski", "Megan", ""], ["Zhang", "Jian", ""], ["R\u00e9", "Christopher", ""]]}, {"id": "1904.10632", "submitter": "Nikolaj Tatti", "authors": "Nikolaj Tatti", "title": "Maximum Entropy Based Significance of Itemsets", "comments": "Journal version. The previous version is the conference paper", "journal-ref": null, "doi": "10.1007/s10115-008-0128-4", "report-no": null, "categories": "cs.LG cs.DB stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the problem of defining the significance of an itemset. We say\nthat the itemset is significant if we are surprised by its frequency when\ncompared to the frequencies of its sub-itemsets. In other words, we estimate\nthe frequency of the itemset from the frequencies of its sub-itemsets and\ncompute the deviation between the real value and the estimate. For the\nestimation we use Maximum Entropy and for measuring the deviation we use\nKullback-Leibler divergence.\n  A major advantage compared to the previous methods is that we are able to use\nricher models whereas the previous approaches only measure the deviation from\nthe independence model.\n  We show that our measure of significance goes to zero for derivable itemsets\nand that we can use the rank as a statistical test. Our empirical results\ndemonstrate that for our real datasets the independence assumption is too\nstrong but applying more flexible models leads to good results.\n", "versions": [{"version": "v1", "created": "Wed, 24 Apr 2019 03:46:23 GMT"}, {"version": "v2", "created": "Sat, 27 Apr 2019 01:44:29 GMT"}], "update_date": "2019-04-30", "authors_parsed": [["Tatti", "Nikolaj", ""]]}, {"id": "1904.10642", "submitter": "Kaichun Hu", "authors": "Kai-Chun Hu, Chen-Huan Pi, Ting Han Wei, I-Chen Wu, Stone Cheng,\n  Yi-Wei Dai, Wei-Yuan Ye", "title": "Towards Combining On-Off-Policy Methods for Real-World Applications", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we point out a fundamental property of the objective in\nreinforcement learning, with which we can reformulate the policy gradient\nobjective into a perceptron-like loss function, removing the need to\ndistinguish between on and off policy training. Namely, we posit that it is\nsufficient to only update a policy $\\pi$ for cases that satisfy the condition\n$A(\\frac{\\pi}{\\mu}-1)\\leq0$, where $A$ is the advantage, and $\\mu$ is another\npolicy. Furthermore, we show via theoretic derivation that a perceptron-like\nloss function matches the clipped surrogate objective for PPO. With our new\nformulation, the policies $\\pi$ and $\\mu$ can be arbitrarily apart in theory,\neffectively enabling off-policy training. To examine our derivations, we can\ncombine the on-policy PPO clipped surrogate (which we show to be equivalent\nwith one instance of the new reformation) with the off-policy IMPALA method. We\nfirst verify the combined method on the OpenAI Gym pendulum toy problem. Next,\nwe use our method to train a quadrotor position controller in a simulator. Our\ntrained policy is efficient and lightweight enough to perform in a low cost\nmicro-controller at a minimum update rate of 500 Hz. For the quadrotor, we show\ntwo experiments to verify our method and demonstrate performance: 1) hovering\nat a fixed position, and 2) tracking along a specific trajectory. In\npreliminary trials, we are also able to apply the method to a real-world\nquadrotor.\n", "versions": [{"version": "v1", "created": "Wed, 24 Apr 2019 05:07:49 GMT"}], "update_date": "2019-04-25", "authors_parsed": [["Hu", "Kai-Chun", ""], ["Pi", "Chen-Huan", ""], ["Wei", "Ting Han", ""], ["Wu", "I-Chen", ""], ["Cheng", "Stone", ""], ["Dai", "Yi-Wei", ""], ["Ye", "Wei-Yuan", ""]]}, {"id": "1904.10644", "submitter": "Yu Chen", "authors": "Yu Chen and Tom Diethe and Neil Lawrence", "title": "Facilitating Bayesian Continual Learning by Natural Gradients and Stein\n  Gradients", "comments": null, "journal-ref": "Continual Learning Workshop of 32nd Conference on Neural\n  Information Processing Systems (NeurIPS 2018)", "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Continual learning aims to enable machine learning models to learn a general\nsolution space for past and future tasks in a sequential manner. Conventional\nmodels tend to forget the knowledge of previous tasks while learning a new\ntask, a phenomenon known as catastrophic forgetting. When using Bayesian models\nin continual learning, knowledge from previous tasks can be retained in two\nways: 1). posterior distributions over the parameters, containing the knowledge\ngained from inference in previous tasks, which then serve as the priors for the\nfollowing task; 2). coresets, containing knowledge of data distributions of\nprevious tasks. Here, we show that Bayesian continual learning can be\nfacilitated in terms of these two means through the use of natural gradients\nand Stein gradients respectively.\n", "versions": [{"version": "v1", "created": "Wed, 24 Apr 2019 05:18:32 GMT"}], "update_date": "2019-04-25", "authors_parsed": [["Chen", "Yu", ""], ["Diethe", "Tom", ""], ["Lawrence", "Neil", ""]]}, {"id": "1904.10653", "submitter": "Xu Zhu", "authors": "Xu Zhu", "title": "Stochastic Lipschitz Q-Learning", "comments": "The papers have been removed and we refer the readers to\n  arXiv:1901.09277. arXiv admin note: author list truncated", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI math.OC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In an episodic Markov Decision Process (MDP) problem, an online algorithm\nchooses from a set of actions in a sequence of $H$ trials, where $H$ is the\nepisode length, in order to maximize the total payoff of the chosen actions.\nQ-learning, as the most popular model-free reinforcement learning (RL)\nalgorithm, directly parameterizes and updates value functions without\nexplicitly modeling the environment. Recently, [Jin et al. 2018] studies the\nsample complexity of Q-learning with finite states and actions. Their algorithm\nachieves nearly optimal regret, which shows that Q-learning can be made sample\nefficient. However, MDPs with large discrete states and actions [Silver et al.\n2016] or continuous spaces [Mnih et al. 2013] cannot learn efficiently in this\nway. Hence, it is critical to develop new algorithms to solve this dilemma with\nprovable guarantee on the sample complexity. With this motivation, we propose a\nnovel algorithm that works for MDPs with a more general setting, which has\ninfinitely many states and actions and assumes that the payoff function and\ntransition kernel are Lipschitz continuous. We also provide corresponding\ntheory justification for our algorithm. It achieves the regret\n$\\tilde{\\mathcal{O}}(K^{\\frac{d+1}{d+2}}\\sqrt{H^3}),$ where $K$ denotes the\nnumber of episodes and $d$ denotes the dimension of the joint space. To the\nbest of our knowledge, this is the first analysis in the model-free setting\nwhose established regret matches the lower bound up to a logarithmic factor.\n", "versions": [{"version": "v1", "created": "Wed, 24 Apr 2019 06:25:42 GMT"}, {"version": "v2", "created": "Wed, 15 May 2019 00:50:11 GMT"}], "update_date": "2019-07-11", "authors_parsed": [["Zhu", "Xu", ""]]}, {"id": "1904.10674", "submitter": "Nicolas Audebert", "authors": "Nicolas Audebert (OBELIX), Bertrand Saux, S\\'ebastien Lef\\`evre\n  (OBELIX)", "title": "Deep Learning for Classification of Hyperspectral Data: A Comparative\n  Review", "comments": null, "journal-ref": null, "doi": "10.1109/MGRS.2019.2912563", "report-no": null, "categories": "cs.LG cs.CV cs.NE eess.IV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In recent years, deep learning techniques revolutionized the way remote\nsensing data are processed. Classification of hyperspectral data is no\nexception to the rule, but has intrinsic specificities which make application\nof deep learning less straightforward than with other optical data. This\narticle presents a state of the art of previous machine learning approaches,\nreviews the various deep learning approaches currently proposed for\nhyperspectral classification, and identifies the problems and difficulties\nwhich arise to implement deep neural networks for this task. In particular, the\nissues of spatial and spectral resolution, data volume, and transfer of models\nfrom multimedia images to hyperspectral data are addressed. Additionally, a\ncomparative study of various families of network architectures is provided and\na software toolbox is publicly released to allow experimenting with these\nmethods. 1 This article is intended for both data scientists with interest in\nhyperspectral data and remote sensing experts eager to apply deep learning\ntechniques to their own dataset.\n", "versions": [{"version": "v1", "created": "Wed, 24 Apr 2019 07:56:37 GMT"}], "update_date": "2019-04-25", "authors_parsed": [["Audebert", "Nicolas", "", "OBELIX"], ["Saux", "Bertrand", "", "OBELIX"], ["Lef\u00e8vre", "S\u00e9bastien", "", "OBELIX"]]}, {"id": "1904.10678", "submitter": "Konstantinos Drossos", "authors": "Konstantinos Drossos and Paul Magron and Tuomas Virtanen", "title": "Unsupervised Adversarial Domain Adaptation Based On The Wasserstein\n  Distance For Acoustic Scene Classification", "comments": "Updated indices at Eq 6", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SD cs.LG eess.AS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A challenging problem in deep learning-based machine listening field is the\ndegradation of the performance when using data from unseen conditions. In this\npaper we focus on the acoustic scene classification (ASC) task and propose an\nadversarial deep learning method to allow adapting an acoustic scene\nclassification system to deal with a new acoustic channel resulting from data\ncaptured with a different recording device. We build upon the theoretical model\nof H{\\Delta}H-distance and previous adversarial discriminative deep learning\nmethod for ASC unsupervised domain adaptation, and we present an adversarial\ntraining based method using the Wasserstein distance. We improve the\nstate-of-the-art mean accuracy on the data from the unseen conditions from 32%\nto 45%, using the TUT Acoustic Scenes dataset.\n", "versions": [{"version": "v1", "created": "Wed, 24 Apr 2019 08:01:38 GMT"}, {"version": "v2", "created": "Wed, 6 Nov 2019 11:56:01 GMT"}], "update_date": "2019-11-07", "authors_parsed": [["Drossos", "Konstantinos", ""], ["Magron", "Paul", ""], ["Virtanen", "Tuomas", ""]]}, {"id": "1904.10679", "submitter": "M{\\aa}ns Magnusson", "authors": "M\\r{a}ns Magnusson, Michael Riis Andersen, Johan Jonasson, Aki Vehtari", "title": "Bayesian leave-one-out cross-validation for large data", "comments": "Accepted to ICML 2019. This version is the submitted paper", "journal-ref": "Thirty-sixth International Conference on Machine Learning, PMLR\n  97:4244-4253, 2019", "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://creativecommons.org/publicdomain/zero/1.0/", "abstract": "  Model inference, such as model comparison, model checking, and model\nselection, is an important part of model development. Leave-one-out\ncross-validation (LOO) is a general approach for assessing the generalizability\nof a model, but unfortunately, LOO does not scale well to large datasets. We\npropose a combination of using approximate inference techniques and\nprobability-proportional-to-size-sampling (PPS) for fast LOO model evaluation\nfor large datasets. We provide both theoretical and empirical results showing\ngood properties for large data.\n", "versions": [{"version": "v1", "created": "Wed, 24 Apr 2019 08:04:00 GMT"}], "update_date": "2020-08-12", "authors_parsed": [["Magnusson", "M\u00e5ns", ""], ["Andersen", "Michael Riis", ""], ["Jonasson", "Johan", ""], ["Vehtari", "Aki", ""]]}, {"id": "1904.10683", "submitter": "Peng Xu", "authors": "Peng Xu, Zhaohong Deng, Chen Cui, Te Zhang, Kup-Sze Choi, Gu Suhang,\n  Jun Wang, ShiTong Wang", "title": "Concise Fuzzy System Modeling Integrating Soft Subspace Clustering and\n  Sparse Learning", "comments": null, "journal-ref": null, "doi": "10.1109/TFUZZ.2019.2895572", "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The superior interpretability and uncertainty modeling ability of\nTakagi-Sugeno-Kang fuzzy system (TSK FS) make it possible to describe complex\nnonlinear systems intuitively and efficiently. However, classical TSK FS\nusually adopts the whole feature space of the data for model construction,\nwhich can result in lengthy rules for high-dimensional data and lead to\ndegeneration in interpretability. Furthermore, for highly nonlinear modeling\ntask, it is usually necessary to use a large number of rules which further\nweakens the clarity and interpretability of TSK FS. To address these issues, a\nconcise zero-order TSK FS construction method, called ESSC-SL-CTSK-FS, is\nproposed in this paper by integrating the techniques of enhanced soft subspace\nclustering (ESSC) and sparse learning (SL). In this method, ESSC is used to\ngenerate the antecedents and various sparse subspace for different fuzzy rules,\nwhereas SL is used to optimize the consequent parameters of the fuzzy rules,\nbased on which the number of fuzzy rules can be effectively reduced. Finally,\nthe proposed ESSC-SL-CTSK-FS method is used to construct con-cise zero-order\nTSK FS that can explain the scenes in high-dimensional data modeling more\nclearly and easily. Experiments are conducted on various real-world datasets to\nconfirm the advantages.\n", "versions": [{"version": "v1", "created": "Wed, 24 Apr 2019 08:11:45 GMT"}], "update_date": "2019-04-25", "authors_parsed": [["Xu", "Peng", ""], ["Deng", "Zhaohong", ""], ["Cui", "Chen", ""], ["Zhang", "Te", ""], ["Choi", "Kup-Sze", ""], ["Suhang", "Gu", ""], ["Wang", "Jun", ""], ["Wang", "ShiTong", ""]]}, {"id": "1904.10689", "submitter": "Saurav Basu", "authors": "Saurav Basu, Koyel Mukherjee, Shrihari Vasudevan", "title": "Layer Dynamics of Linearised Neural Nets", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Despite the phenomenal success of deep learning in recent years, there\nremains a gap in understanding the fundamental mechanics of neural nets. More\nresearch is focussed on handcrafting complex and larger networks, and the\ndesign decisions are often ad-hoc and based on intuition. Some recent research\nhas aimed to demystify the learning dynamics in neural nets by attempting to\nbuild a theory from first principles, such as characterising the non-linear\ndynamics of specialised \\textit{linear} deep neural nets (such as orthogonal\nnetworks). In this work, we expand and derive properties of learning dynamics\nrespected by general multi-layer linear neural nets. Although an\nover-parameterisation of a single layer linear network, linear multi-layer\nneural nets offer interesting insights that explain how learning dynamics\nproceed in small pockets of the data space. We show in particular that multiple\nlayers in linear nets grow at approximately the same rate, and there are\ndistinct phases of learning with markedly different layer growth. We then apply\na linearisation process to a general RelU neural net and show how nonlinearity\nbreaks down the growth symmetry observed in liner neural nets. Overall, our\nwork can be viewed as an initial step in building a theory for understanding\nthe effect of layer design on the learning dynamics from first principles.\n", "versions": [{"version": "v1", "created": "Wed, 24 Apr 2019 08:29:43 GMT"}], "update_date": "2019-04-25", "authors_parsed": [["Basu", "Saurav", ""], ["Mukherjee", "Koyel", ""], ["Vasudevan", "Shrihari", ""]]}, {"id": "1904.10717", "submitter": "James Thorne", "authors": "James Thorne, Andreas Vlachos, Christos Christodoulopoulos, Arpit\n  Mittal", "title": "Generating Token-Level Explanations for Natural Language Inference", "comments": "Accepted at NAACL2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CL stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The task of Natural Language Inference (NLI) is widely modeled as supervised\nsentence pair classification. While there has been a lot of work recently on\ngenerating explanations of the predictions of classifiers on a single piece of\ntext, there have been no attempts to generate explanations of classifiers\noperating on pairs of sentences. In this paper, we show that it is possible to\ngenerate token-level explanations for NLI without the need for training data\nexplicitly annotated for this purpose. We use a simple LSTM architecture and\nevaluate both LIME and Anchor explanations for this task. We compare these to a\nMultiple Instance Learning (MIL) method that uses thresholded attention make\ntoken-level predictions. The approach we present in this paper is a novel\nextension of zero-shot single-sentence tagging to sentence pairs for NLI. We\nconduct our experiments on the well-studied SNLI dataset that was recently\naugmented with manually annotation of the tokens that explain the entailment\nrelation. We find that our white-box MIL-based method, while orders of\nmagnitude faster, does not reach the same accuracy as the black-box methods.\n", "versions": [{"version": "v1", "created": "Wed, 24 Apr 2019 09:41:14 GMT"}], "update_date": "2019-04-25", "authors_parsed": [["Thorne", "James", ""], ["Vlachos", "Andreas", ""], ["Christodoulopoulos", "Christos", ""], ["Mittal", "Arpit", ""]]}, {"id": "1904.10729", "submitter": "Zhengyao Jiang", "authors": "Zhengyao Jiang, Shan Luo", "title": "Neural Logic Reinforcement Learning", "comments": "Accpeted by ICML2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep reinforcement learning (DRL) has achieved significant breakthroughs in\nvarious tasks. However, most DRL algorithms suffer a problem of generalizing\nthe learned policy which makes the learning performance largely affected even\nby minor modifications of the training environment. Except that, the use of\ndeep neural networks makes the learned policies hard to be interpretable. To\naddress these two challenges, we propose a novel algorithm named Neural Logic\nReinforcement Learning (NLRL) to represent the policies in reinforcement\nlearning by first-order logic. NLRL is based on policy gradient methods and\ndifferentiable inductive logic programming that have demonstrated significant\nadvantages in terms of interpretability and generalisability in supervised\ntasks. Extensive experiments conducted on cliff-walking and blocks manipulation\ntasks demonstrate that NLRL can induce interpretable policies achieving\nnear-optimal performance while demonstrating good generalisability to\nenvironments of different initial states and problem sizes.\n", "versions": [{"version": "v1", "created": "Wed, 24 Apr 2019 10:24:35 GMT"}, {"version": "v2", "created": "Wed, 10 Jul 2019 03:45:15 GMT"}], "update_date": "2019-07-11", "authors_parsed": [["Jiang", "Zhengyao", ""], ["Luo", "Shan", ""]]}, {"id": "1904.10743", "submitter": "Jiyu Chen", "authors": "Jiyu Chen, Karin Verspoor, Zenan Zhai", "title": "A bag-of-concepts model improves relation extraction in a narrow\n  knowledge domain with limited data", "comments": "To appear in Proceedings of the Student Research Workshop at the\n  North American Association for Computational Linguistics (NAACL) meeting 2019", "journal-ref": "In Proceedings of the Student Research Workshop at North American\n  Association for Computational Linguistics (NAACL) 2019", "doi": null, "report-no": null, "categories": "cs.LG cs.CL cs.IR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper focuses on a traditional relation extraction task in the context\nof limited annotated data and a narrow knowledge domain. We explore this task\nwith a clinical corpus consisting of 200 breast cancer follow-up treatment\nletters in which 16 distinct types of relations are annotated. We experiment\nwith an approach to extracting typed relations called window-bounded\nco-occurrence (WBC), which uses an adjustable context window around entity\nmentions of a relevant type, and compare its performance with a more typical\nintra-sentential co-occurrence baseline. We further introduce a new\nbag-of-concepts (BoC) approach to feature engineering based on the\nstate-of-the-art word embeddings and word synonyms. We demonstrate the\ncompetitiveness of BoC by comparing with methods of higher complexity, and\nexplore its effectiveness on this small dataset.\n", "versions": [{"version": "v1", "created": "Wed, 24 Apr 2019 11:06:54 GMT"}], "update_date": "2019-04-25", "authors_parsed": [["Chen", "Jiyu", ""], ["Verspoor", "Karin", ""], ["Zhai", "Zenan", ""]]}, {"id": "1904.10748", "submitter": "Kaito Fujii", "authors": "Kaito Fujii, Shinsaku Sakaue", "title": "Beyond Adaptive Submodularity: Approximation Guarantees of Greedy Policy\n  with Adaptive Submodularity Ratio", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.DS stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a new concept named adaptive submodularity ratio to study the\ngreedy policy for sequential decision making. While the greedy policy is known\nto perform well for a wide variety of adaptive stochastic optimization problems\nin practice, its theoretical properties have been analyzed only for a limited\nclass of problems. We narrow the gap between theory and practice by using\nadaptive submodularity ratio, which enables us to prove approximation\nguarantees of the greedy policy for a substantially wider class of problems.\nExamples of newly analyzed problems include important applications such as\nadaptive influence maximization and adaptive feature selection. Our adaptive\nsubmodularity ratio also provides bounds of adaptivity gaps. Experiments\nconfirm that the greedy policy performs well with the applications being\nconsidered compared to standard heuristics.\n", "versions": [{"version": "v1", "created": "Wed, 24 Apr 2019 11:18:47 GMT"}], "update_date": "2019-04-25", "authors_parsed": [["Fujii", "Kaito", ""], ["Sakaue", "Shinsaku", ""]]}, {"id": "1904.10753", "submitter": "Aysun Urhan", "authors": "Aysun Urhan, Burak Alakent", "title": "An Exploratory Analysis of Biased Learners in Soft-Sensing Frames", "comments": "Preprint", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Data driven soft sensor design has recently gained immense popularity, due to\nadvances in sensory devices, and a growing interest in data mining. While\npartial least squares (PLS) is traditionally used in the process literature for\ndesigning soft sensors, the statistical literature has focused on sparse\nlearners, such as Lasso and relevance vector machine (RVM), to solve the high\ndimensional data problem. In the current study, predictive performances of\nthree regression techniques, PLS, Lasso and RVM were assessed and compared\nunder various offline and online soft sensing scenarios applied on datasets\nfrom five real industrial plants, and a simulated process. In offline learning,\npredictions of RVM and Lasso were found to be superior to those of PLS when a\nlarge number of time-lagged predictors were used. Online prediction results\ngave a slightly more complicated picture. It was found that the minimum\nprediction error achieved by PLS under moving window (MW), or just-in-time\nlearning scheme was decreased up to ~5-10% using Lasso, or RVM. However, when a\nsmall MW size was used, or the optimum number of PLS components was as low as\n~1, prediction performance of PLS surpassed RVM, which was found to yield\noccasional unstable predictions. PLS and Lasso models constructed via online\nparameter tuning generally did not yield better predictions compared to those\nconstructed via offline tuning. We present evidence to suggest that retaining a\nlarge portion of the available process measurement data in the predictor\nmatrix, instead of preselecting variables, would be more advantageous for\nsparse learners in increasing prediction accuracy. As a result, Lasso is\nrecommended as a better substitute for PLS in soft sensors; while performance\nof RVM should be validated before online application.\n", "versions": [{"version": "v1", "created": "Wed, 24 Apr 2019 11:45:23 GMT"}], "update_date": "2019-04-25", "authors_parsed": [["Urhan", "Aysun", ""], ["Alakent", "Burak", ""]]}, {"id": "1904.10761", "submitter": "Steven Whang", "authors": "Ki Hyun Tae, Yuji Roh, Young Hun Oh, Hyunsu Kim, Steven Euijong Whang", "title": "Data Cleaning for Accurate, Fair, and Robust Models: A Big Data - AI\n  Integration Approach", "comments": "4 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DB cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The wide use of machine learning is fundamentally changing the software\ndevelopment paradigm (a.k.a. Software 2.0) where data becomes a first-class\ncitizen, on par with code. As machine learning is used in sensitive\napplications, it becomes imperative that the trained model is accurate, fair,\nand robust to attacks. While many techniques have been proposed to improve the\nmodel training process (in-processing approach) or the trained model itself\n(post-processing), we argue that the most effective method is to clean the root\ncause of error: the data the model is trained on (pre-processing).\nHistorically, there are at least three research communities that have been\nseparately studying this problem: data management, machine learning (model\nfairness), and security. Although a significant amount of research has been\ndone by each community, ultimately the same datasets must be preprocessed, and\nthere is little understanding how the techniques relate to each other and can\npossibly be integrated. We contend that it is time to extend the notion of data\ncleaning for modern machine learning needs. We identify dependencies among the\ndata preprocessing techniques and propose MLClean, a unified data cleaning\nframework that integrates the techniques and helps train accurate and fair\nmodels. This work is part of a broader trend of Big data -- Artificial\nIntelligence (AI) integration.\n", "versions": [{"version": "v1", "created": "Mon, 22 Apr 2019 23:57:07 GMT"}], "update_date": "2019-04-25", "authors_parsed": [["Tae", "Ki Hyun", ""], ["Roh", "Yuji", ""], ["Oh", "Young Hun", ""], ["Kim", "Hyunsu", ""], ["Whang", "Steven Euijong", ""]]}, {"id": "1904.10762", "submitter": "Linsen Dong", "authors": "Linsen Dong, Guanyu Gao, Xinyi Zhang, Liangyu Chen, and Yonggang Wen", "title": "Baconian: A Unified Open-source Framework for Model-Based Reinforcement\n  Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Model-Based Reinforcement Learning (MBRL) is one category of Reinforcement\nLearning (RL) algorithms which can improve sampling efficiency by modeling and\napproximating system dynamics. It has been widely adopted in the research of\nrobotics, autonomous driving, etc. Despite its popularity, there still lacks\nsome sophisticated and reusable open-source frameworks to facilitate MBRL\nresearch and experiments. To fill this gap, we develop a flexible and\nmodularized framework, Baconian, which allows researchers to easily implement a\nMBRL testbed by customizing or building upon our provided modules and\nalgorithms. Our framework can free users from re-implementing popular MBRL\nalgorithms from scratch thus greatly save users' efforts on MBRL experiments.\n", "versions": [{"version": "v1", "created": "Tue, 23 Apr 2019 05:35:50 GMT"}, {"version": "v2", "created": "Sun, 24 May 2020 10:55:55 GMT"}, {"version": "v3", "created": "Mon, 15 Mar 2021 15:47:28 GMT"}, {"version": "v4", "created": "Tue, 16 Mar 2021 03:40:36 GMT"}], "update_date": "2021-03-17", "authors_parsed": [["Dong", "Linsen", ""], ["Gao", "Guanyu", ""], ["Zhang", "Xinyi", ""], ["Chen", "Liangyu", ""], ["Wen", "Yonggang", ""]]}, {"id": "1904.10778", "submitter": "Abhishek Gupta", "authors": "Abhishek Gupta and Hao Chen and Jianzong Pi and Gaurav Tendolkar", "title": "Some Limit Properties of Markov Chains Induced by Stochastic Recursive\n  Algorithms", "comments": "Accepted in SIMODS, 37 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.SY math.OC math.PR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recursive stochastic algorithms have gained significant attention in the\nrecent past due to data driven applications. Examples include stochastic\ngradient descent for solving large-scale optimization problems and empirical\ndynamic programming algorithms for solving Markov decision problems. These\nrecursive stochastic algorithms approximate certain contraction operators and\ncan be viewed within the framework of iterated random operators. Accordingly,\nwe consider iterated random operators over a Polish space that simulate\niterated contraction operator over that Polish space. Assume that the iterated\nrandom operators are indexed by certain batch sizes such that as batch sizes\ngrow to infinity, each realization of the random operator converges (in some\nsense) to the contraction operator it is simulating. We show that starting from\nthe same initial condition, the distribution of the random sequence generated\nby the iterated random operators converges weakly to the trajectory generated\nby the contraction operator. We further show that under certain conditions, the\ntime average of the random sequence converges to the spatial mean of the\ninvariant distribution. We then apply these results to logistic regression,\nempirical value iteration, and empirical Q value iteration for finite state\nfinite action MDPs to illustrate the general theory develop here.\n", "versions": [{"version": "v1", "created": "Wed, 24 Apr 2019 12:51:46 GMT"}, {"version": "v2", "created": "Thu, 23 Jul 2020 20:35:37 GMT"}], "update_date": "2020-07-27", "authors_parsed": [["Gupta", "Abhishek", ""], ["Chen", "Hao", ""], ["Pi", "Jianzong", ""], ["Tendolkar", "Gaurav", ""]]}, {"id": "1904.10784", "submitter": "David Rohde", "authors": "David Rohde, Stephen Bonner", "title": "Latent Variable Session-Based Recommendation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Session based recommendation provides an attractive alternative to the\ntraditional feature engineering approach to recommendation. Feature engineering\napproaches require hand tuned features of the users history to be created to\nproduce a context vector. In contrast a session based approach is able to\ndynamically model the users state as they act. We present a probabilistic\nframework for session based recommendation. A latent variable for the user\nstate is updated as the user views more items and we learn more about their\ninterests. The latent variable model is conceptually simple and elegant; yet\nrequires sophisticated computational technique to approximate the integral over\nthe latent variable. We provide computational solutions using both the\nre-parameterization trick and also using the Bouchard bound for the softmax\nfunction, we further explore employing a variational auto-encoder and a\nvariational Expectation-Maximization algorithm for tightening the variational\nbound. The model performs well against a number of baselines. The intuitive\nnature of the model allows an elegant formulation combining correlations\nbetween items and their popularity and that sheds light on other popular\nrecommendation methods. An attractive feature of the latent variable approach\nis that, as the user continues to act, the posterior on the user's state\ntightens reflecting the recommender system's increased knowledge about that\nuser.\n", "versions": [{"version": "v1", "created": "Wed, 24 Apr 2019 13:10:38 GMT"}, {"version": "v2", "created": "Wed, 19 Jun 2019 15:21:49 GMT"}, {"version": "v3", "created": "Tue, 17 Sep 2019 16:41:29 GMT"}], "update_date": "2019-09-18", "authors_parsed": [["Rohde", "David", ""], ["Bonner", "Stephen", ""]]}, {"id": "1904.10788", "submitter": "Seunghyun Yoon", "authors": "Seunghyun Yoon, Seokhyun Byun, Subhadeep Dey, Kyomin Jung", "title": "Speech Emotion Recognition Using Multi-hop Attention Mechanism", "comments": "5 pages, Accepted as a conference paper at ICASSP 2019 (oral\n  presentation)", "journal-ref": null, "doi": "10.1109/ICASSP.2019.8683483", "report-no": null, "categories": "eess.AS cs.AI cs.CL cs.LG cs.SD", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we are interested in exploiting textual and acoustic data of\nan utterance for the speech emotion classification task. The baseline approach\nmodels the information from audio and text independently using two deep neural\nnetworks (DNNs). The outputs from both the DNNs are then fused for\nclassification. As opposed to using knowledge from both the modalities\nseparately, we propose a framework to exploit acoustic information in tandem\nwith lexical data. The proposed framework uses two bi-directional long\nshort-term memory (BLSTM) for obtaining hidden representations of the\nutterance. Furthermore, we propose an attention mechanism, referred to as the\nmulti-hop, which is trained to automatically infer the correlation between the\nmodalities. The multi-hop attention first computes the relevant segments of the\ntextual data corresponding to the audio signal. The relevant textual data is\nthen applied to attend parts of the audio signal. To evaluate the performance\nof the proposed system, experiments are performed in the IEMOCAP dataset.\nExperimental results show that the proposed technique outperforms the\nstate-of-the-art system by 6.5% relative improvement in terms of weighted\naccuracy.\n", "versions": [{"version": "v1", "created": "Tue, 23 Apr 2019 13:09:21 GMT"}, {"version": "v2", "created": "Thu, 9 May 2019 13:34:00 GMT"}], "update_date": "2019-12-02", "authors_parsed": [["Yoon", "Seunghyun", ""], ["Byun", "Seokhyun", ""], ["Dey", "Subhadeep", ""], ["Jung", "Kyomin", ""]]}, {"id": "1904.10797", "submitter": "Julius Walln\\\"ofer", "authors": "Julius Walln\\\"ofer, Alexey A. Melnikov, Wolfgang D\\\"ur, and Hans J.\n  Briegel", "title": "Machine learning for long-distance quantum communication", "comments": "13+7 pages, 6+3 figures, 1+3 tables; v2: significantly extended scope\n  and updated figures", "journal-ref": "PRX Quantum 1, 010301 (2020)", "doi": "10.1103/PRXQuantum.1.010301", "report-no": null, "categories": "quant-ph cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Machine learning can help us in solving problems in the context big data\nanalysis and classification, as well as in playing complex games such as Go.\nBut can it also be used to find novel protocols and algorithms for applications\nsuch as large-scale quantum communication? Here we show that machine learning\ncan be used to identify central quantum protocols, including teleportation,\nentanglement purification and the quantum repeater. These schemes are of\nimportance in long-distance quantum communication, and their discovery has\nshaped the field of quantum information processing. However, the usefulness of\nlearning agents goes beyond the mere re-production of known protocols; the same\napproach allows one to find improved solutions to long-distance communication\nproblems, in particular when dealing with asymmetric situations where channel\nnoise and segment distance are non-uniform. Our findings are based on the use\nof projective simulation, a model of a learning agent that combines\nreinforcement learning and decision making in a physically motivated framework.\nThe learning agent is provided with a universal gate set, and the desired task\nis specified via a reward scheme. From a technical perspective, the learning\nagent has to deal with stochastic environments and reactions. We utilize an\nidea reminiscent of hierarchical skill acquisition, where solutions to\nsub-problems are learned and re-used in the overall scheme. This is of\nparticular importance in the development of long-distance communication\nschemes, and opens the way for using machine learning in the design and\nimplementation of quantum networks.\n", "versions": [{"version": "v1", "created": "Wed, 24 Apr 2019 13:20:55 GMT"}, {"version": "v2", "created": "Thu, 17 Sep 2020 12:22:43 GMT"}], "update_date": "2020-09-18", "authors_parsed": [["Walln\u00f6fer", "Julius", ""], ["Melnikov", "Alexey A.", ""], ["D\u00fcr", "Wolfgang", ""], ["Briegel", "Hans J.", ""]]}, {"id": "1904.10814", "submitter": "Marian Boguna", "authors": "Guillermo Garc\\'ia-P\\'erez, Antoine Allard, M. \\'Angeles Serrano,\n  Mari\\'an Bogu\\~n\\'a", "title": "Mercator: uncovering faithful hyperbolic embeddings of complex networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "physics.soc-ph cs.LG cs.SI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce Mercator, a reliable embedding method to map real complex\nnetworks into their hyperbolic latent geometry. The method assumes that the\nstructure of networks is well described by the Popularity$\\times$Similarity\n$\\mathbb{S}^1/\\mathbb{H}^2$ static geometric network model, which can\naccommodate arbitrary degree distributions and reproduces many pivotal\nproperties of real networks, including self-similarity patterns. The algorithm\nmixes machine learning and maximum likelihood approaches to infer the\ncoordinates of the nodes in the underlying hyperbolic disk with the best\nmatching between the observed network topology and the geometric model. In its\nfast mode, Mercator uses a model-adjusted machine learning technique performing\ndimensional reduction to produce a fast and accurate map, whose quality already\noutperform other embedding algorithms in the literature. In the refined\nMercator mode, the fast-mode embedding result is taken as an initial condition\nin a Maximum Likelihood estimation, which significantly improves the quality of\nthe final embedding. Apart from its accuracy as an embedding tool, Mercator has\nthe clear advantage of systematically inferring not only node orderings, or\nangular positions, but also the hidden degrees and global model parameters, and\nhas the ability to embed networks with arbitrary degree distributions. Overall,\nour results suggest that mixing machine learning and maximum likelihood\ntechniques in a model-dependent framework can boost the meaningful mapping of\ncomplex networks.\n", "versions": [{"version": "v1", "created": "Wed, 24 Apr 2019 13:39:17 GMT"}], "update_date": "2019-04-25", "authors_parsed": [["Garc\u00eda-P\u00e9rez", "Guillermo", ""], ["Allard", "Antoine", ""], ["Serrano", "M. \u00c1ngeles", ""], ["Bogu\u00f1\u00e1", "Mari\u00e1n", ""]]}, {"id": "1904.10824", "submitter": "Chongyang Wang", "authors": "Chongyang Wang, Min Peng, Temitayo A. Olugbade, Nicholas D. Lane,\n  Amanda C. De C. Williams, Nadia Bianchi-Berthouze", "title": "Learning Bodily and Temporal Attention in Protective Movement Behavior\n  Detection", "comments": "7 pages, 3 figures, 2 tables, code available, accepted in ACII 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  For people with chronic pain, the assessment of protective behavior during\nphysical functioning is essential to understand their subjective pain-related\nexperiences (e.g., fear and anxiety toward pain and injury) and how they deal\nwith such experiences (avoidance or reliance on specific body joints), with the\nultimate goal of guiding intervention. Advances in deep learning (DL) can\nenable the development of such intervention. Using the EmoPain MoCap dataset,\nwe investigate how attention-based DL architectures can be used to improve the\ndetection of protective behavior by capturing the most informative temporal and\nbody configurational cues characterizing specific movements and the strategies\nused to perform them. We propose an end-to-end deep learning architecture named\nBodyAttentionNet (BANet). BANet is designed to learn temporal and bodily parts\nthat are more informative to the detection of protective behavior. The approach\naddresses the variety of ways people execute a movement (including healthy\npeople) independently of the type of movement analyzed. Through extensive\ncomparison experiments with other state-of-the-art machine learning techniques\nused with motion capture data, we show statistically significant improvements\nachieved by using these attention mechanisms. In addition, the BANet\narchitecture requires a much lower number of parameters than the state of the\nart for comparable if not higher performances.\n", "versions": [{"version": "v1", "created": "Wed, 24 Apr 2019 14:00:05 GMT"}, {"version": "v2", "created": "Thu, 11 Jul 2019 10:32:44 GMT"}, {"version": "v3", "created": "Wed, 17 Jul 2019 12:21:26 GMT"}], "update_date": "2019-07-18", "authors_parsed": [["Wang", "Chongyang", ""], ["Peng", "Min", ""], ["Olugbade", "Temitayo A.", ""], ["Lane", "Nicholas D.", ""], ["Williams", "Amanda C. De C.", ""], ["Bianchi-Berthouze", "Nadia", ""]]}, {"id": "1904.10829", "submitter": "Jann Goschenhofer", "authors": "Jann Goschenhofer, Franz MJ Pfister, Kamer Ali Yuksel, Bernd Bischl,\n  Urban Fietzek, Janek Thomas", "title": "Wearable-based Parkinson's Disease Severity Monitoring using Deep\n  Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.AP stat.ML", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  One major challenge in the medication of Parkinson's disease is that the\nseverity of the disease, reflected in the patients' motor state, cannot be\nmeasured using accessible biomarkers. Therefore, we develop and examine a\nvariety of statistical models to detect the motor state of such patients based\non sensor data from a wearable device. We find that deep learning models\nconsistently outperform a classical machine learning model applied on\nhand-crafted features in this time series classification task. Furthermore, our\nresults suggest that treating this problem as a regression instead of an\nordinal regression or a classification task is most appropriate. For consistent\nmodel evaluation and training, we adopt the leave-one-subject-out validation\nscheme to the training of deep learning models. We also employ a\nclass-weighting scheme to successfully mitigate the problem of high multi-class\nimbalances in this domain. In addition, we propose a customized performance\nmeasure that reflects the requirements of the involved medical staff on the\nmodel. To solve the problem of limited availability of high quality training\ndata, we propose a transfer learning technique which helps to improve model\nperformance substantially. Our results suggest that deep learning techniques\noffer a high potential to autonomously detect motor states of patients with\nParkinson's disease.\n", "versions": [{"version": "v1", "created": "Wed, 24 Apr 2019 14:05:34 GMT"}], "update_date": "2019-04-26", "authors_parsed": [["Goschenhofer", "Jann", ""], ["Pfister", "Franz MJ", ""], ["Yuksel", "Kamer Ali", ""], ["Bischl", "Bernd", ""], ["Fietzek", "Urban", ""], ["Thomas", "Janek", ""]]}, {"id": "1904.10863", "submitter": "Artjom Zern", "authors": "Artjom Zern, Matthias Zisler, Stefania Petra, Christoph Schn\\\"orr", "title": "Unsupervised Assignment Flow: Label Learning on Feature Manifolds by\n  Spatially Regularized Geometric Assignment", "comments": "34 pages, 13 figures, published in Journal of Mathematical Imaging\n  and Vision (JMIV)", "journal-ref": null, "doi": "10.1007/s10851-019-00935-7", "report-no": null, "categories": "cs.LG cs.CV math.OC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper introduces the unsupervised assignment flow that couples the\nassignment flow for supervised image labeling with Riemannian gradient flows\nfor label evolution on feature manifolds. The latter component of the approach\nencompasses extensions of state-of-the-art clustering approaches to\nmanifold-valued data. Coupling label evolution with the spatially regularized\nassignment flow induces a sparsifying effect that enables to learn compact\nlabel dictionaries in an unsupervised manner. Our approach alleviates the\nrequirement for supervised labeling to have proper labels at hand, because an\ninitial set of labels can evolve and adapt to better values while being\nassigned to given data. The separation between feature and assignment manifolds\nenables the flexible application which is demonstrated for three scenarios with\nmanifold-valued features. Experiments demonstrate a beneficial effect in both\ndirections: adaptivity of labels improves image labeling, and steering label\nevolution by spatially regularized assignments leads to proper labels, because\nthe assignment flow for supervised labeling is exactly used without any\napproximation for label learning.\n", "versions": [{"version": "v1", "created": "Wed, 24 Apr 2019 15:08:01 GMT"}, {"version": "v2", "created": "Thu, 12 Sep 2019 13:58:53 GMT"}, {"version": "v3", "created": "Mon, 16 Dec 2019 15:44:49 GMT"}], "update_date": "2019-12-17", "authors_parsed": [["Zern", "Artjom", ""], ["Zisler", "Matthias", ""], ["Petra", "Stefania", ""], ["Schn\u00f6rr", "Christoph", ""]]}, {"id": "1904.10869", "submitter": "Swapnil Nitin Shah", "authors": "Swapnil Nitin Shah", "title": "Variational approach to unsupervised learning", "comments": "5 pages, 2 figures", "journal-ref": null, "doi": "10.1088/2399-6528/ab3029", "report-no": null, "categories": "cond-mat.dis-nn cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep belief networks are used extensively for unsupervised stochastic\nlearning on large datasets. Compared to other deep learning approaches their\nlayer-by-layer learning makes them highly scalable. Unfortunately, the\nprinciples by which they achieve efficient learning are not well understood.\nNumerous attempts have been made to explain their efficiency and applicability\nto a wide class of learning problems in terms of principles drawn from\ncognitive psychology, statistics, information theory, and more recently\nphysics, but quite often these imported principles lack strong scientific\nfoundation. Here we demonstrate how one can arrive at convolutional deep belief\nnetworks as potential solution to unsupervised learning problems without making\nassumptions about the underlying framework. To do this, we exploit the notion\nof symmetry that is fundamental in machine learning, physics and other fields,\nutilizing the particular form of the functional renormalization group in\nphysics.\n", "versions": [{"version": "v1", "created": "Wed, 24 Apr 2019 15:23:54 GMT"}], "update_date": "2019-07-15", "authors_parsed": [["Shah", "Swapnil Nitin", ""]]}, {"id": "1904.10873", "submitter": "Yanwei  Fu", "authors": "Yanwei Fu, Donghao Li, Xinwei Sun, Shun Zhang, Yizhou Wang, Yuan Yao", "title": "$S^{2}$-LBI: Stochastic Split Linearized Bregman Iterations for\n  Parsimonious Deep Learning", "comments": "technical report", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper proposes a novel Stochastic Split Linearized Bregman Iteration\n($S^{2}$-LBI) algorithm to efficiently train the deep network. The $S^{2}$-LBI\nintroduces an iterative regularization path with structural sparsity. Our\n$S^{2}$-LBI combines the computational efficiency of the LBI, and model\nselection consistency in learning the structural sparsity. The computed\nsolution path intrinsically enables us to enlarge or simplify a network, which\ntheoretically, is benefited from the dynamics property of our $S^{2}$-LBI\nalgorithm. The experimental results validate our $S^{2}$-LBI on MNIST and\nCIFAR-10 dataset. For example, in MNIST, we can either boost a network with\nonly 1.5K parameters (1 convolutional layer of 5 filters, and 1 FC layer),\nachieves 98.40\\% recognition accuracy; or we simplify $82.5\\%$ of parameters in\nLeNet-5 network, and still achieves the 98.47\\% recognition accuracy. In\naddition, we also have the learning results on ImageNet, which will be added in\nthe next version of our report.\n", "versions": [{"version": "v1", "created": "Wed, 24 Apr 2019 15:31:55 GMT"}], "update_date": "2019-04-25", "authors_parsed": [["Fu", "Yanwei", ""], ["Li", "Donghao", ""], ["Sun", "Xinwei", ""], ["Zhang", "Shun", ""], ["Wang", "Yizhou", ""], ["Yao", "Yuan", ""]]}, {"id": "1904.10890", "submitter": "Roel Henckaerts", "authors": "Roel Henckaerts, Marie-Pier C\\^ot\\'e, Katrien Antonio, Roel Verbelen", "title": "Boosting insights in insurance tariff plans with tree-based machine\n  learning methods", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.AP cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Pricing actuaries typically operate within the framework of generalized\nlinear models (GLMs). With the upswing of data analytics, our study puts focus\non machine learning methods to develop full tariff plans built from both the\nfrequency and severity of claims. We adapt the loss functions used in the\nalgorithms such that the specific characteristics of insurance data are\ncarefully incorporated: highly unbalanced count data with excess zeros and\nvarying exposure on the frequency side combined with scarce, but potentially\nlong-tailed data on the severity side. A key requirement is the need for\ntransparent and interpretable pricing models which are easily explainable to\nall stakeholders. We therefore focus on machine learning with decision trees:\nstarting from simple regression trees, we work towards more advanced ensembles\nsuch as random forests and boosted trees. We show how to choose the optimal\ntuning parameters for these models in an elaborate cross-validation scheme, we\npresent visualization tools to obtain insights from the resulting models and\nthe economic value of these new modeling approaches is evaluated. Boosted trees\noutperform the classical GLMs, allowing the insurer to form profitable\nportfolios and to guard against potential adverse risk selection.\n", "versions": [{"version": "v1", "created": "Fri, 12 Apr 2019 12:36:49 GMT"}, {"version": "v2", "created": "Wed, 7 Aug 2019 09:23:52 GMT"}, {"version": "v3", "created": "Mon, 2 Mar 2020 22:03:03 GMT"}], "update_date": "2020-03-04", "authors_parsed": [["Henckaerts", "Roel", ""], ["C\u00f4t\u00e9", "Marie-Pier", ""], ["Antonio", "Katrien", ""], ["Verbelen", "Roel", ""]]}, {"id": "1904.10900", "submitter": "Qing Zhou", "authors": "Jiaying Gu and Qing Zhou", "title": "Learning big Gaussian Bayesian networks: partition, estimation, and\n  fusion", "comments": "26 pages, 2 figures, and 5 tables", "journal-ref": "Journal of Machine Learning Research, 21(158): 1-31, 2020", "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Structure learning of Bayesian networks has always been a challenging\nproblem. Nowadays, massive-size networks with thousands or more of nodes but\nfewer samples frequently appear in many areas. We develop a divide-and-conquer\nframework, called partition-estimation-fusion (PEF), for structure learning of\nsuch big networks. The proposed method first partitions nodes into clusters,\nthen learns a subgraph on each cluster of nodes, and finally fuses all learned\nsubgraphs into one Bayesian network. The PEF method is designed in a flexible\nway so that any structure learning method may be used in the second step to\nlearn a subgraph structure as either a DAG or a CPDAG. In the clustering step,\nwe adapt the hierarchical clustering method to automatically choose a proper\nnumber of clusters. In the fusion step, we propose a novel hybrid method that\nsequentially add edges between subgraphs. Extensive numerical experiments\ndemonstrate the competitive performance of our PEF method, in terms of both\nspeed and accuracy compared to existing methods. Our method can improve the\naccuracy of structure learning by 20% or more, while reducing running time up\nto two orders-of-magnitude.\n", "versions": [{"version": "v1", "created": "Wed, 24 Apr 2019 16:08:53 GMT"}], "update_date": "2020-09-24", "authors_parsed": [["Gu", "Jiaying", ""], ["Zhou", "Qing", ""]]}, {"id": "1904.10904", "submitter": "Peter Watson", "authors": "Peter A. G. Watson", "title": "Applying machine learning to improve simulations of a chaotic dynamical\n  system using empirical error correction", "comments": "26p, 7 figures To be published in Journal of Advances in Modeling\n  Earth Systems", "journal-ref": null, "doi": "10.1029/2018MS001597", "report-no": null, "categories": "physics.ao-ph cs.LG nlin.CD stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Dynamical weather and climate prediction models underpin many studies of the\nEarth system and hold the promise of being able to make robust projections of\nfuture climate change based on physical laws. However, simulations from these\nmodels still show many differences compared with observations. Machine learning\nhas been applied to solve certain prediction problems with great success, and\nrecently it's been proposed that this could replace the role of\nphysically-derived dynamical weather and climate models to give better quality\nsimulations. Here, instead, a framework using machine learning together with\nphysically-derived models is tested, in which it is learnt how to correct the\nerrors of the latter from timestep to timestep. This maintains the physical\nunderstanding built into the models, whilst allowing performance improvements,\nand also requires much simpler algorithms and less training data. This is\ntested in the context of simulating the chaotic Lorenz '96 system, and it is\nshown that the approach yields models that are stable and that give both\nimproved skill in initialised predictions and better long-term climate\nstatistics. Improvements in long-term statistics are smaller than for single\ntime-step tendencies, however, indicating that it would be valuable to develop\nmethods that target improvements on longer time scales. Future strategies for\nthe development of this approach and possible applications to making progress\non important scientific problems are discussed.\n", "versions": [{"version": "v1", "created": "Wed, 24 Apr 2019 16:17:46 GMT"}], "update_date": "2019-09-04", "authors_parsed": [["Watson", "Peter A. G.", ""]]}, {"id": "1904.10921", "submitter": "Jaedeok Kim", "authors": "Jaedeok Kim, Chiyoun Park, Hyun-Joo Jung, Yoonsuck Choe", "title": "Plug-in, Trainable Gate for Streamlining Arbitrary Neural Networks", "comments": "Accepted to AAAI 2020 (Poster)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Architecture optimization, which is a technique for finding an efficient\nneural network that meets certain requirements, generally reduces to a set of\nmultiple-choice selection problems among alternative sub-structures or\nparameters. The discrete nature of the selection problem, however, makes this\noptimization difficult. To tackle this problem we introduce a novel concept of\na trainable gate function. The trainable gate function, which confers a\ndifferentiable property to discretevalued variables, allows us to directly\noptimize loss functions that include non-differentiable discrete values such as\n0-1 selection. The proposed trainable gate can be applied to pruning. Pruning\ncan be carried out simply by appending the proposed trainable gate functions to\neach intermediate output tensor followed by fine-tuning the overall model,\nusing any gradient-based training methods. So the proposed method can jointly\noptimize the selection of the pruned channels while fine-tuning the weights of\nthe pruned model at the same time. Our experimental results demonstrate that\nthe proposed method efficiently optimizes arbitrary neural networks in various\ntasks such as image classification, style transfer, optical flow estimation,\nand neural machine translation.\n", "versions": [{"version": "v1", "created": "Wed, 24 Apr 2019 16:57:20 GMT"}, {"version": "v2", "created": "Thu, 14 Nov 2019 15:11:45 GMT"}], "update_date": "2019-11-15", "authors_parsed": [["Kim", "Jaedeok", ""], ["Park", "Chiyoun", ""], ["Jung", "Hyun-Joo", ""], ["Choe", "Yoonsuck", ""]]}, {"id": "1904.10922", "submitter": "Michela Paganini", "authors": "Jessica Zosa Forde and Michela Paganini", "title": "The Scientific Method in the Science of Machine Learning", "comments": "4 pages + 1 appendix. Presented at the ICLR 2019 Debugging Machine\n  Learning Models workshop", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In the quest to align deep learning with the sciences to address calls for\nrigor, safety, and interpretability in machine learning systems, this\ncontribution identifies key missing pieces: the stages of hypothesis\nformulation and testing, as well as statistical and systematic uncertainty\nestimation -- core tenets of the scientific method. This position paper\ndiscusses the ways in which contemporary science is conducted in other domains\nand identifies potentially useful practices. We present a case study from\nphysics and describe how this field has promoted rigor through specific\nmethodological practices, and provide recommendations on how machine learning\nresearchers can adopt these practices into the research ecosystem. We argue\nthat both domain-driven experiments and application-agnostic questions of the\ninner workings of fundamental building blocks of machine learning models ought\nto be examined with the tools of the scientific method, to ensure we not only\nunderstand effect, but also begin to understand cause, which is the raison\nd'\\^{e}tre of science.\n", "versions": [{"version": "v1", "created": "Wed, 24 Apr 2019 17:01:43 GMT"}], "update_date": "2019-04-25", "authors_parsed": [["Forde", "Jessica Zosa", ""], ["Paganini", "Michela", ""]]}, {"id": "1904.10926", "submitter": "Malte Schilling", "authors": "Malte Schilling", "title": "Setup of a Recurrent Neural Network as a Body Model for Solving Inverse\n  and Forward Kinematics as well as Dynamics for a Redundant Manipulator", "comments": "Pre-print (accepted to IJCNN 2019)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  An internal model of the own body can be assumed a fundamental and\nevolutionary-early representation as it is present throughout the animal\nkingdom. Such functional models are, on the one hand, required in motor\ncontrol, for example solving the inverse kinematic or dynamic task in\ngoal-directed movements or a forward task in ballistic movements. On the other\nhand, such models are recruited in cognitive tasks as are planning ahead or\nobservation of actions of a conspecific. Here, we present a functional internal\nbody model that is based on the Mean of Multiple Computations principle. For\nthe first time such a model is completely realized in a recurrent neural\nnetwork as necessary normalization steps are integrated into the neural model\nitself. Secondly, a dynamic extension is applied to the model. It is shown how\nthe neural network solves a series of inverse tasks. Furthermore, emerging\nrepresentation in transformational layers are analyzed that show a form of\nprototypical population-coding as found in place or direction cells.\n", "versions": [{"version": "v1", "created": "Fri, 12 Apr 2019 19:31:52 GMT"}], "update_date": "2019-04-25", "authors_parsed": [["Schilling", "Malte", ""]]}, {"id": "1904.10927", "submitter": "Tamara Radivilova A", "authors": "Lyudmyla Kirichenko and Tamara Radivilova and Illya Zinkevich", "title": "Forecasting Weakly Correlated Time Series in Tasks of Electronic\n  Commerce", "comments": "4 pages, 4 figures, 1 table", "journal-ref": "2017 12th International Scientific and Technical Conference on\n  Computer Sciences and Information Technologies (CSIT)", "doi": "10.1109/STC-CSIT.2017.8098793", "report-no": null, "categories": "cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Forecasting of weakly correlated time series of conversion rate by methods of\nexponential smoothing, neural network and decision tree on the example of\nconversion percent series for an electronic store is considered in the paper.\nThe advantages and disadvantages of each method are considered.\n", "versions": [{"version": "v1", "created": "Tue, 16 Apr 2019 11:41:34 GMT"}], "update_date": "2019-04-25", "authors_parsed": [["Kirichenko", "Lyudmyla", ""], ["Radivilova", "Tamara", ""], ["Zinkevich", "Illya", ""]]}, {"id": "1904.10931", "submitter": "Alex Fedorov", "authors": "Alex Fedorov, R Devon Hjelm, Anees Abrol, Zening Fu, Yuhui Du, Sergey\n  Plis, Vince D. Calhoun", "title": "Prediction of Progression to Alzheimer's disease with Deep InfoMax", "comments": "Accepted to 2019 IEEE Biomedical and Health Informatics (BHI) as a\n  conference paper", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.NE stat.ML", "license": "http://creativecommons.org/licenses/by-sa/4.0/", "abstract": "  Arguably, unsupervised learning plays a crucial role in the majority of\nalgorithms for processing brain imaging. A recently introduced unsupervised\napproach Deep InfoMax (DIM) is a promising tool for exploring brain structure\nin a flexible non-linear way. In this paper, we investigate the use of variants\nof DIM in a setting of progression to Alzheimer's disease in comparison with\nsupervised AlexNet and ResNet inspired convolutional neural networks. As a\nbenchmark, we use a classification task between four groups: patients with\nstable, and progressive mild cognitive impairment (MCI), with Alzheimer's\ndisease, and healthy controls. Our dataset is comprised of 828 subjects from\nthe Alzheimer's Disease Neuroimaging Initiative (ADNI) database. Our\nexperiments highlight encouraging evidence of the high potential utility of DIM\nin future neuroimaging studies.\n", "versions": [{"version": "v1", "created": "Wed, 24 Apr 2019 17:10:11 GMT"}, {"version": "v2", "created": "Tue, 30 Apr 2019 16:01:34 GMT"}, {"version": "v3", "created": "Wed, 1 May 2019 02:13:22 GMT"}], "update_date": "2019-05-02", "authors_parsed": [["Fedorov", "Alex", ""], ["Hjelm", "R Devon", ""], ["Abrol", "Anees", ""], ["Fu", "Zening", ""], ["Du", "Yuhui", ""], ["Plis", "Sergey", ""], ["Calhoun", "Vince D.", ""]]}, {"id": "1904.10932", "submitter": "Mikel Malagon", "authors": "Mikel Malagon and Josu Ceberio", "title": "Evolving Neural Networks in Reinforcement Learning by means of UMDAc", "comments": "10 pages, 6 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.LG", "license": "http://creativecommons.org/licenses/by-sa/4.0/", "abstract": "  Neural networks are gaining popularity in the reinforcement learning field\ndue to the vast number of successfully solved complex benchmark problems. In\nfact, artificial intelligence algorithms are, in some cases, able to overcome\nhuman professionals. Usually, neural networks have more than a couple of hidden\nlayers, and thus, they involve a large quantity of parameters that need to be\noptimized. Commonly, numeric approaches are used to optimize the inner\nparameters of neural networks, such as the stochastic gradient descent.\nHowever, these techniques tend to be computationally very expensive, and for\nsome tasks, where effectiveness is crucial, high computational costs are not\nacceptable. Along these research lines, in this paper we propose to optimize\nthe parameters of neural networks by means of estimation of distribution\nalgorithms. More precisely, the univariate marginal distribution algorithm is\nused for evolving neural networks in various reinforcement learning tasks. For\nthe sake of validating our idea, we run the proposed algorithm on four OpenAI\nGym benchmark problems. In addition, the obtained results were compared with a\nstandard genetic algorithm. Revealing, that optimizing with UMDAc provides\nbetter results than the genetic algorithm in most of the cases.\n", "versions": [{"version": "v1", "created": "Wed, 24 Apr 2019 17:12:42 GMT"}], "update_date": "2019-04-25", "authors_parsed": [["Malagon", "Mikel", ""], ["Ceberio", "Josu", ""]]}, {"id": "1904.10937", "submitter": "Jason Chou", "authors": "Jason Chou", "title": "Generated Loss and Augmented Training of MNIST VAE", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The variational autoencoder (VAE) framework is a popular option for training\nunsupervised generative models, featuring ease of training and latent\nrepresentation of data. The objective function of VAE does not guarantee to\nachieve the latter, however, and failure to do so leads to a frequent failure\nmode called posterior collapse. Even in successful cases, VAEs often result in\nlow-precision reconstructions and generated samples. The introduction of the\nKL-divergence weight $\\beta$ can help steer the model clear of posterior\ncollapse, but its tuning is often a trial-and-error process with no guiding\nmetrics. Here we test the idea of using the total VAE loss of generated samples\n(generated loss) as the proxy metric for generation quality, the related\nhypothesis that VAE reconstruction from the mean latent vector tends to be a\nmore typical example of its class than the original, and the idea of exploiting\nthis property by augmenting training data with generated variants (augmented\ntraining). The results are mixed, but repeated encoding and decoding indeed\nresult in qualitatively and quantitatively more typical examples from both\nconvolutional and fully-connected MNIST VAEs, suggesting that it may be an\ninherent property of the VAE framework.\n", "versions": [{"version": "v1", "created": "Wed, 24 Apr 2019 17:22:07 GMT"}], "update_date": "2019-04-25", "authors_parsed": [["Chou", "Jason", ""]]}, {"id": "1904.10944", "submitter": "Maria Bauza", "authors": "Maria Bauza, Oleguer Canal and Alberto Rodriguez", "title": "Tactile Mapping and Localization from High-Resolution Tactile Imprints", "comments": "ICRA 2019, 7 pages, 7 figures. Website:\n  http://web.mit.edu/mcube/research/tactile_localization.html Video:\n  https://youtu.be/uMkspjmDbqs", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This work studies the problem of shape reconstruction and object localization\nusing a vision-based tactile sensor, GelSlim. The main contributions are the\nrecovery of local shapes from contact, an approach to reconstruct the tactile\nshape of objects from tactile imprints, and an accurate method for object\nlocalization of previously reconstructed objects. The algorithms can be applied\nto a large variety of 3D objects and provide accurate tactile feedback for\nin-hand manipulation. Results show that by exploiting the dense tactile\ninformation we can reconstruct the shape of objects with high accuracy and do\non-line object identification and localization, opening the door to reactive\nmanipulation guided by tactile sensing. We provide videos and supplemental\ninformation in the project's website\nhttp://web.mit.edu/mcube/research/tactile_localization.html.\n", "versions": [{"version": "v1", "created": "Wed, 24 Apr 2019 17:41:23 GMT"}, {"version": "v2", "created": "Thu, 11 Jul 2019 15:54:52 GMT"}], "update_date": "2019-07-12", "authors_parsed": [["Bauza", "Maria", ""], ["Canal", "Oleguer", ""], ["Rodriguez", "Alberto", ""]]}, {"id": "1904.10945", "submitter": "Donghwan Lee", "authors": "Donghwan Lee, Niao He", "title": "Target-Based Temporal Difference Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.SY math.OC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The use of target networks has been a popular and key component of recent\ndeep Q-learning algorithms for reinforcement learning, yet little is known from\nthe theory side. In this work, we introduce a new family of target-based\ntemporal difference (TD) learning algorithms and provide theoretical analysis\non their convergences. In contrast to the standard TD-learning, target-based TD\nalgorithms maintain two separate learning parameters-the target variable and\nonline variable. Particularly, we introduce three members in the family, called\nthe averaging TD, double TD, and periodic TD, where the target variable is\nupdated through an averaging, symmetric, or periodic fashion, mirroring those\ntechniques used in deep Q-learning practice.\n  We establish asymptotic convergence analyses for both averaging TD and double\nTD and a finite sample analysis for periodic TD. In addition, we also provide\nsome simulation results showing potentially superior convergence of these\ntarget-based TD algorithms compared to the standard TD-learning. While this\nwork focuses on linear function approximation and policy evaluation setting, we\nconsider this as a meaningful step towards the theoretical understanding of\ndeep Q-learning variants with target networks.\n", "versions": [{"version": "v1", "created": "Wed, 24 Apr 2019 17:41:58 GMT"}, {"version": "v2", "created": "Tue, 3 Sep 2019 01:25:31 GMT"}, {"version": "v3", "created": "Fri, 20 Sep 2019 20:23:44 GMT"}], "update_date": "2019-09-24", "authors_parsed": [["Lee", "Donghwan", ""], ["He", "Niao", ""]]}, {"id": "1904.10951", "submitter": "Madeleine Udell", "authors": "Yiming Sun, Yang Guo, Charlene Luo, Joel Tropp, Madeleine Udell", "title": "Low-Rank Tucker Approximation of a Tensor From Streaming Data", "comments": "Appendix includes supplement from published version", "journal-ref": "SIAM Journal on Mathematics of Data Science 2.4 (2020): 1123-1150", "doi": null, "report-no": null, "categories": "math.NA cs.LG cs.NA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper describes a new algorithm for computing a low-Tucker-rank\napproximation of a tensor. The method applies a randomized linear map to the\ntensor to obtain a sketch that captures the important directions within each\nmode, as well as the interactions among the modes. The sketch can be extracted\nfrom streaming or distributed data or with a single pass over the tensor, and\nit uses storage proportional to the degrees of freedom in the output Tucker\napproximation. The algorithm does not require a second pass over the tensor,\nalthough it can exploit another view to compute a superior approximation. The\npaper provides a rigorous theoretical guarantee on the approximation error.\nExtensive numerical experiments show that that the algorithm produces useful\nresults that improve on the state of the art for streaming Tucker\ndecomposition.\n", "versions": [{"version": "v1", "created": "Wed, 24 Apr 2019 17:51:57 GMT"}, {"version": "v2", "created": "Fri, 30 Apr 2021 21:16:14 GMT"}], "update_date": "2021-05-04", "authors_parsed": [["Sun", "Yiming", ""], ["Guo", "Yang", ""], ["Luo", "Charlene", ""], ["Tropp", "Joel", ""], ["Udell", "Madeleine", ""]]}, {"id": "1904.10959", "submitter": "Samuel Asante Gyamerah", "authors": "Samuel Asante Gyamerah, Philip Ngare, Dennis Ikpe", "title": "Crop yield probability density forecasting via quantile random forest\n  and Epanechnikov Kernel function", "comments": "22 pages, 11 figures", "journal-ref": "Agricultural and Forest Meteorology, 280:107808 (2020)", "doi": "10.1016/j.ecolmodel.2014.01.030", "report-no": null, "categories": "stat.AP cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  A reliable and accurate forecasting model for crop yields is of crucial\nimportance for efficient decision-making process in the agricultural sector.\nHowever, due to weather extremes and uncertainties, most forecasting models for\ncrop yield are not reliable and accurate. For measuring the uncertainty and\nobtaining further information of future crop yields, a probability density\nforecasting model based on quantile random forest and Epanechnikov kernel\nfunction (QRF-SJ) is proposed. The nonlinear structure of random forest is\napplied to change the quantile regression model for building the probabilistic\nforecasting model. Epanechnikov kernel function and solve-the equation plug-in\napproach of Sheather and Jones are used in the kernel density estimation. A\ncase study using the annual crop yield of groundnut and millet in Ghana is\npresented to illustrate the efficiency and robustness of the proposed\ntechnique. The values of the prediction interval coverage probability and\nprediction interval normalized average width for the two crops show that the\nconstructed prediction intervals capture the observed yields with high coverage\nprobability. The probability density curves show that QRF-SJ method has a very\nhigh ability to forecast quality prediction intervals with a higher coverage\nprobability. The feature importance gave a score of the importance of each\nweather variable in building the quantile regression forest model. The farmer\nand other stakeholders are able to realize the specific weather variable that\naffect the yield of a selected crop through feature importance. The proposed\nmethod and its application on crop yield dataset are the first of its kind in\nliterature.\n", "versions": [{"version": "v1", "created": "Tue, 23 Apr 2019 22:55:08 GMT"}, {"version": "v2", "created": "Sat, 19 Oct 2019 17:07:07 GMT"}], "update_date": "2019-10-25", "authors_parsed": [["Gyamerah", "Samuel Asante", ""], ["Ngare", "Philip", ""], ["Ikpe", "Dennis", ""]]}, {"id": "1904.10990", "submitter": "Mohammad Esmaeilpour", "authors": "Mohammad Esmaeilpour, Patrick Cardinal, Alessandro Lameiras Koerich", "title": "A Robust Approach for Securing Audio Classification Against Adversarial\n  Attacks", "comments": "Paper Accepted for Publication in IEEE Transactions on Information\n  Forensics and Security", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR cs.SD eess.AS stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Adversarial audio attacks can be considered as a small perturbation\nunperceptive to human ears that is intentionally added to the audio signal and\ncauses a machine learning model to make mistakes. This poses a security concern\nabout the safety of machine learning models since the adversarial attacks can\nfool such models toward the wrong predictions. In this paper we first review\nsome strong adversarial attacks that may affect both audio signals and their 2D\nrepresentations and evaluate the resiliency of the most common machine learning\nmodel, namely deep learning models and support vector machines (SVM) trained on\n2D audio representations such as short time Fourier transform (STFT), discrete\nwavelet transform (DWT) and cross recurrent plot (CRP) against several\nstate-of-the-art adversarial attacks. Next, we propose a novel approach based\non pre-processed DWT representation of audio signals and SVM to secure audio\nsystems against adversarial attacks. The proposed architecture has several\npreprocessing modules for generating and enhancing spectrograms including\ndimension reduction and smoothing. We extract features from small patches of\nthe spectrograms using speeded up robust feature (SURF) algorithm which are\nfurther used to generate a codebook using the K-Means++ algorithm. Finally,\ncodewords are used to train a SVM on the codebook of the SURF-generated\nvectors. All these steps yield to a novel approach for audio classification\nthat provides a good trade-off between accuracy and resilience. Experimental\nresults on three environmental sound datasets show the competitive performance\nof proposed approach compared to the deep neural networks both in terms of\naccuracy and robustness against strong adversarial attacks.\n", "versions": [{"version": "v1", "created": "Wed, 24 Apr 2019 18:07:52 GMT"}, {"version": "v2", "created": "Mon, 25 Nov 2019 17:32:06 GMT"}], "update_date": "2019-11-26", "authors_parsed": [["Esmaeilpour", "Mohammad", ""], ["Cardinal", "Patrick", ""], ["Koerich", "Alessandro Lameiras", ""]]}, {"id": "1904.10996", "submitter": "Zheng Ma", "authors": "Zheng Ma, Ming Li, Yuguang Wang", "title": "PAN: Path Integral Based Convolution for Deep Graph Neural Networks", "comments": null, "journal-ref": "ICML 2019 Workshop on Learning and Reasoning with Graph-Structured\n  Representations (Oral)", "doi": null, "report-no": null, "categories": "cs.LG cond-mat.dis-nn cond-mat.stat-mech cs.SI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Convolution operations designed for graph-structured data usually utilize the\ngraph Laplacian, which can be seen as message passing between the adjacent\nneighbors through a generic random walk. In this paper, we propose PAN, a new\ngraph convolution framework that involves every path linking the message sender\nand receiver with learnable weights depending on the path length, which\ncorresponds to the maximal entropy random walk. PAN generalizes the graph\nLaplacian to a new transition matrix we call \\emph{maximal entropy transition}\n(MET) matrix derived from a path integral formalism. Most previous graph\nconvolutional network architectures can be adapted to our framework, and many\nvariations and derivatives based on the path integral idea can be developed.\nExperimental results show that the path integral based graph neural networks\nhave great learnability and fast convergence rate, and achieve state-of-the-art\nperformance on benchmark tasks.\n", "versions": [{"version": "v1", "created": "Wed, 24 Apr 2019 18:20:15 GMT"}], "update_date": "2019-07-22", "authors_parsed": [["Ma", "Zheng", ""], ["Li", "Ming", ""], ["Wang", "Yuguang", ""]]}, {"id": "1904.11005", "submitter": "Modar Alfadly", "authors": "Modar Alfadly, Adel Bibi and Bernard Ghanem", "title": "Analytical Moment Regularizer for Gaussian Robust Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Despite the impressive performance of deep neural networks (DNNs) on numerous\nvision tasks, they still exhibit yet-to-understand uncouth behaviours. One\npuzzling behaviour is the subtle sensitive reaction of DNNs to various noise\nattacks. Such a nuisance has strengthened the line of research around\ndeveloping and training noise-robust networks. In this work, we propose a new\ntraining regularizer that aims to minimize the probabilistic expected training\nloss of a DNN subject to a generic Gaussian input. We provide an efficient and\nsimple approach to approximate such a regularizer for arbitrary deep networks.\nThis is done by leveraging the analytic expression of the output mean of a\nshallow neural network; avoiding the need for the memory and computationally\nexpensive data augmentation. We conduct extensive experiments on LeNet and\nAlexNet on various datasets including MNIST, CIFAR10, and CIFAR100\ndemonstrating the effectiveness of our proposed regularizer. In particular, we\nshow that networks that are trained with the proposed regularizer benefit from\na boost in robustness equivalent to performing 3-21 folds of data augmentation.\n", "versions": [{"version": "v1", "created": "Wed, 24 Apr 2019 18:37:36 GMT"}], "update_date": "2019-04-26", "authors_parsed": [["Alfadly", "Modar", ""], ["Bibi", "Adel", ""], ["Ghanem", "Bernard", ""]]}, {"id": "1904.11042", "submitter": "Rey Wiyatno", "authors": "Rey Reza Wiyatno, Anqi Xu", "title": "Physical Adversarial Textures that Fool Visual Object Tracking", "comments": "Accepted to the International Conference on Computer Vision (ICCV)\n  2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a system for generating inconspicuous-looking textures that, when\ndisplayed in the physical world as digital or printed posters, cause visual\nobject tracking systems to become confused. For instance, as a target being\ntracked by a robot's camera moves in front of such a poster, our generated\ntexture makes the tracker lock onto it and allows the target to evade. This\nwork aims to fool seldom-targeted regression tasks, and in particular compares\ndiverse optimization strategies: non-targeted, targeted, and a new family of\nguided adversarial losses. While we use the Expectation Over Transformation\n(EOT) algorithm to generate physical adversaries that fool tracking models when\nimaged under diverse conditions, we compare the impacts of different\nconditioning variables, including viewpoint, lighting, and appearances, to find\npractical attack setups with high resulting adversarial strength and\nconvergence speed. We further showcase textures optimized solely using\nsimulated scenes can confuse real-world tracking systems.\n", "versions": [{"version": "v1", "created": "Wed, 24 Apr 2019 19:56:57 GMT"}, {"version": "v2", "created": "Sun, 15 Sep 2019 20:12:35 GMT"}], "update_date": "2019-09-17", "authors_parsed": [["Wiyatno", "Rey Reza", ""], ["Xu", "Anqi", ""]]}, {"id": "1904.11061", "submitter": "Matthew England Dr", "authors": "Matthew England and Dorian Florescu", "title": "Comparing machine learning models to choose the variable ordering for\n  cylindrical algebraic decomposition", "comments": "Accepted into CICM 2019", "journal-ref": "In: C. Kaliszyk, E. Brady, A. Kohlhase and C.C. Sacerdoti eds.,\n  Intelligent Computer Mathematics (Proceedings of CICM 2019), pp. 93-108,\n  (Lecture Notes in Computer Science, 11617). Springer International\n  Publishing, 2019", "doi": "10.1007/978-3-030-23250-4_7", "report-no": null, "categories": "cs.SC cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  There has been recent interest in the use of machine learning (ML) approaches\nwithin mathematical software to make choices that impact on the computing\nperformance without affecting the mathematical correctness of the result. We\naddress the problem of selecting the variable ordering for cylindrical\nalgebraic decomposition (CAD), an important algorithm in Symbolic Computation.\nPrior work to apply ML on this problem implemented a Support Vector Machine\n(SVM) to select between three existing human-made heuristics, which did better\nthan anyone heuristic alone. The present work extends to have ML select the\nvariable ordering directly, and to try a wider variety of ML techniques.\n  We experimented with the NLSAT dataset and the Regular Chains Library CAD\nfunction for Maple 2018. For each problem, the variable ordering leading to the\nshortest computing time was selected as the target class for ML. Features were\ngenerated from the polynomial input and used to train the following ML models:\nk-nearest neighbours (KNN) classifier, multi-layer perceptron (MLP), decision\ntree (DT) and SVM, as implemented in the Python scikit-learn package. We also\ncompared these with the two leading human constructed heuristics for the\nproblem: Brown's heuristic and sotd. On this dataset all of the ML approaches\noutperformed the human made heuristics, some by a large margin.\n", "versions": [{"version": "v1", "created": "Wed, 24 Apr 2019 20:42:59 GMT"}, {"version": "v2", "created": "Wed, 5 Jun 2019 09:48:25 GMT"}], "update_date": "2019-07-17", "authors_parsed": [["England", "Matthew", ""], ["Florescu", "Dorian", ""]]}, {"id": "1904.11082", "submitter": "Xinlei Pan", "authors": "Xinlei Pan, Weiyao Wang, Xiaoshuai Zhang, Bo Li, Jinfeng Yi, Dawn Song", "title": "How You Act Tells a Lot: Privacy-Leakage Attack on Deep Reinforcement\n  Learning", "comments": "The first three authors contributed equally. Accepted by AAMAS 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Machine learning has been widely applied to various applications, some of\nwhich involve training with privacy-sensitive data. A modest number of data\nbreaches have been studied, including credit card information in natural\nlanguage data and identities from face dataset. However, most of these studies\nfocus on supervised learning models. As deep reinforcement learning (DRL) has\nbeen deployed in a number of real-world systems, such as indoor robot\nnavigation, whether trained DRL policies can leak private information requires\nin-depth study. To explore such privacy breaches in general, we mainly propose\ntwo methods: environment dynamics search via genetic algorithm and candidate\ninference based on shadow policies. We conduct extensive experiments to\ndemonstrate such privacy vulnerabilities in DRL under various settings. We\nleverage the proposed algorithms to infer floor plans from some trained Grid\nWorld navigation DRL agents with LiDAR perception. The proposed algorithm can\ncorrectly infer most of the floor plans and reaches an average recovery rate of\n95.83% using policy gradient trained agents. In addition, we are able to\nrecover the robot configuration in continuous control environments and an\nautonomous driving simulator with high accuracy. To the best of our knowledge,\nthis is the first work to investigate privacy leakage in DRL settings and we\nshow that DRL-based agents do potentially leak privacy-sensitive information\nfrom the trained policies.\n", "versions": [{"version": "v1", "created": "Wed, 24 Apr 2019 21:41:04 GMT"}], "update_date": "2019-04-26", "authors_parsed": [["Pan", "Xinlei", ""], ["Wang", "Weiyao", ""], ["Zhang", "Xiaoshuai", ""], ["Li", "Bo", ""], ["Yi", "Jinfeng", ""], ["Song", "Dawn", ""]]}, {"id": "1904.11088", "submitter": "Muhan Zhang", "authors": "Muhan Zhang, Shali Jiang, Zhicheng Cui, Roman Garnett, Yixin Chen", "title": "D-VAE: A Variational Autoencoder for Directed Acyclic Graphs", "comments": "Accepted by 33rd Conference on Neural Information Processing Systems\n  (NeurIPS 2019)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Graph structured data are abundant in the real world. Among different graph\ntypes, directed acyclic graphs (DAGs) are of particular interest to machine\nlearning researchers, as many machine learning models are realized as\ncomputations on DAGs, including neural networks and Bayesian networks. In this\npaper, we study deep generative models for DAGs, and propose a novel DAG\nvariational autoencoder (D-VAE). To encode DAGs into the latent space, we\nleverage graph neural networks. We propose an asynchronous message passing\nscheme that allows encoding the computations on DAGs, rather than using\nexisting simultaneous message passing schemes to encode local graph structures.\nWe demonstrate the effectiveness of our proposed DVAE through two tasks: neural\narchitecture search and Bayesian network structure learning. Experiments show\nthat our model not only generates novel and valid DAGs, but also produces a\nsmooth latent space that facilitates searching for DAGs with better performance\nthrough Bayesian optimization.\n", "versions": [{"version": "v1", "created": "Wed, 24 Apr 2019 22:22:57 GMT"}, {"version": "v2", "created": "Thu, 9 May 2019 21:52:21 GMT"}, {"version": "v3", "created": "Thu, 30 May 2019 17:51:04 GMT"}, {"version": "v4", "created": "Tue, 29 Oct 2019 04:28:17 GMT"}], "update_date": "2019-10-30", "authors_parsed": [["Zhang", "Muhan", ""], ["Jiang", "Shali", ""], ["Cui", "Zhicheng", ""], ["Garnett", "Roman", ""], ["Chen", "Yixin", ""]]}, {"id": "1904.11093", "submitter": "Mahdi Abavisani", "authors": "Mahdi Abavisani and Vishal M. Patel", "title": "Deep Sparse Representation-based Classification", "comments": null, "journal-ref": "IEEE Signal Processing Letters, 2019", "doi": "10.1109/LSP.2019.2913022", "report-no": null, "categories": "cs.CV cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a transductive deep learning-based formulation for the sparse\nrepresentation-based classification (SRC) method. The proposed network consists\nof a convolutional autoencoder along with a fully-connected layer. The role of\nthe autoencoder network is to learn robust deep features for classification. On\nthe other hand, the fully-connected layer, which is placed in between the\nencoder and the decoder networks, is responsible for finding the sparse\nrepresentation. The estimated sparse codes are then used for classification.\nVarious experiments on three different datasets show that the proposed network\nleads to sparse representations that give better classification results than\nstate-of-the-art SRC methods. The source code is available at:\ngithub.com/mahdiabavisani/DSRC.\n", "versions": [{"version": "v1", "created": "Wed, 24 Apr 2019 22:52:18 GMT"}], "update_date": "2019-05-22", "authors_parsed": [["Abavisani", "Mahdi", ""], ["Patel", "Vishal M.", ""]]}, {"id": "1904.11094", "submitter": "Mariem Ben Fadhel", "authors": "Mariem Ben Fadhel, Kofi Nyarko", "title": "GAN Augmented Text Anomaly Detection with Sequences of Deep Statistics", "comments": "5 pages, 53rd Annual Conference on Information Sciences and Systems,\n  CISS 2019", "journal-ref": null, "doi": "10.1109/CISS.2019.8693024", "report-no": null, "categories": "cs.LG cs.CR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Anomaly detection is the process of finding data points that deviate from a\nbaseline. In a real-life setting, anomalies are usually unknown or extremely\nrare. Moreover, the detection must be accomplished in a timely manner or the\nrisk of corrupting the system might grow exponentially. In this work, we\npropose a two level framework for detecting anomalies in sequences of discrete\nelements. First, we assess whether we can obtain enough information from the\nstatistics collected from the discriminator's layers to discriminate between\nout of distribution and in distribution samples. We then build an unsupervised\nanomaly detection module based on these statistics. As to augment the data and\nkeep track of classes of known data, we lean toward a semi-supervised\nadversarial learning applied to discrete elements.\n", "versions": [{"version": "v1", "created": "Wed, 24 Apr 2019 23:06:36 GMT"}], "update_date": "2019-04-26", "authors_parsed": [["Fadhel", "Mariem Ben", ""], ["Nyarko", "Kofi", ""]]}, {"id": "1904.11095", "submitter": "Minsu Cho", "authors": "Minsu Cho and Chinmay Hegde", "title": "Reducing The Search Space For Hyperparameter Optimization Using Group\n  Sparsity", "comments": "Published at ICASSP 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a new algorithm for hyperparameter selection in machine learning\nalgorithms. The algorithm is a novel modification of Harmonica, a spectral\nhyperparameter selection approach using sparse recovery methods. In particular,\nwe show that a special encoding of hyperparameter space enables a natural\ngroup-sparse recovery formulation, which when coupled with HyperBand (a\nmulti-armed bandit strategy) leads to improvement over existing hyperparameter\noptimization methods such as Successive Halving and Random Search. Experimental\nresults on image datasets such as CIFAR-10 confirm the benefits of our\napproach.\n", "versions": [{"version": "v1", "created": "Wed, 24 Apr 2019 23:09:54 GMT"}], "update_date": "2019-04-26", "authors_parsed": [["Cho", "Minsu", ""], ["Hegde", "Chinmay", ""]]}, {"id": "1904.11099", "submitter": "Daniel Huang", "authors": "Daniel Huang", "title": "On Learning to Prove", "comments": "Preprint", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we consider the problem of learning a first-order theorem\nprover that uses a representation of beliefs in mathematical claims to\nconstruct proofs. The inspiration for doing so comes from the practices of\nhuman mathematicians where \"plausible reasoning\" is applied in addition to\ndeductive reasoning to find proofs.\n  Towards this end, we introduce a representation of beliefs that assigns\nprobabilities to the exhaustive and mutually exclusive first-order\npossibilities found in Hintikka's theory of distributive normal forms. The\nrepresentation supports Bayesian update, induces a distribution on statements\nthat does not enforce that logically equivalent statements are assigned the\nsame probability, and suggests an embedding of statements into an associated\nHilbert space.\n  We then examine conjecturing as model selection and an alternating-turn game\nof determining consistency. The game is amenable (in principle) to self-play\ntraining to learn beliefs and derive a prover that is complete when logical\nomniscience is attained and sound when beliefs are reasonable. The\nrepresentation has super-exponential space requirements as a function of\nquantifier depth so the ideas in this paper should be taken as theoretical. We\nwill comment on how abstractions can be used to control the space requirements\nat the cost of completeness.\n", "versions": [{"version": "v1", "created": "Wed, 24 Apr 2019 23:54:59 GMT"}, {"version": "v2", "created": "Fri, 26 Apr 2019 16:55:51 GMT"}, {"version": "v3", "created": "Fri, 28 Jun 2019 05:57:10 GMT"}], "update_date": "2019-07-01", "authors_parsed": [["Huang", "Daniel", ""]]}, {"id": "1904.11102", "submitter": "Ahmed Qureshi", "authors": "Mayur J. Bency, Ahmed H. Qureshi, Michael C. Yip", "title": "Neural Path Planning: Fixed Time, Near-Optimal Path Generation via\n  Oracle Imitation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Fast and efficient path generation is critical for robots operating in\ncomplex environments. This motion planning problem is often performed in a\nrobot's actuation or configuration space, where popular pathfinding methods\nsuch as A*, RRT*, get exponentially more computationally expensive to execute\nas the dimensionality increases or the spaces become more cluttered and\ncomplex. On the other hand, if one were to save the entire set of paths\nconnecting all pair of locations in the configuration space a priori, one would\nrun out of memory very quickly. In this work, we introduce a novel way of\nproducing fast and optimal motion plans for static environments by using a\nstepping neural network approach, called OracleNet. OracleNet uses Recurrent\nNeural Networks to determine end-to-end trajectories in an iterative manner\nthat implicitly generates optimal motion plans with minimal loss in performance\nin a compact form. The algorithm is straightforward in implementation while\nconsistently generating near-optimal paths in a single, iterative, end-to-end\nroll-out. In practice, OracleNet generally has fixed-time execution regardless\nof the configuration space complexity while outperforming popular pathfinding\nalgorithms in complex environments and higher dimensions\n", "versions": [{"version": "v1", "created": "Thu, 25 Apr 2019 00:05:24 GMT"}], "update_date": "2019-04-26", "authors_parsed": [["Bency", "Mayur J.", ""], ["Qureshi", "Ahmed H.", ""], ["Yip", "Michael C.", ""]]}, {"id": "1904.11115", "submitter": "Daniel Lopez-Martinez", "authors": "Daniel Lopez-Martinez and Patrick Eschenfeldt and Sassan Ostvar and\n  Myles Ingram and Chin Hur and Rosalind Picard", "title": "Deep Reinforcement Learning for Optimal Critical Care Pain Management\n  with Morphine using Dueling Double-Deep Q Networks", "comments": "2019 41st Annual International Conference of the IEEE Engineering in\n  Medicine & Biology Society (EMBC)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Opioids are the preferred medications for the treatment of pain in the\nintensive care unit. While undertreatment leads to unrelieved pain and poor\nclinical outcomes, excessive use of opioids puts patients at risk of\nexperiencing multiple adverse effects. In this work, we present a sequential\ndecision making framework for opioid dosing based on deep reinforcement\nlearning. It provides real-time clinically interpretable dosing\nrecommendations, personalized according to each patient's evolving pain and\nphysiological condition. We focus on morphine, one of the most commonly\nprescribed opioids. To train and evaluate the model, we used retrospective data\nfrom the publicly available MIMIC-3 database. Our results demonstrate that\nreinforcement learning may be used to aid decision making in the intensive care\nsetting by providing personalized pain management interventions.\n", "versions": [{"version": "v1", "created": "Thu, 25 Apr 2019 01:26:24 GMT"}], "update_date": "2019-04-26", "authors_parsed": [["Lopez-Martinez", "Daniel", ""], ["Eschenfeldt", "Patrick", ""], ["Ostvar", "Sassan", ""], ["Ingram", "Myles", ""], ["Hur", "Chin", ""], ["Picard", "Rosalind", ""]]}, {"id": "1904.11119", "submitter": "Konstantinos Sotiropoulos", "authors": "Konstantinos Sotiropoulos, John W. Byers, Polyvios Pratikakis,\n  Charalampos E. Tsourakakis", "title": "TwitterMancer: Predicting Interactions on Twitter Accurately", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SI cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  This paper investigates the interplay between different types of user\ninteractions on Twitter, with respect to predicting missing or unseen\ninteractions. For example, given a set of retweet interactions between Twitter\nusers, how accurately can we predict reply interactions? Is it more difficult\nto predict retweet or quote interactions between a pair of accounts? Also, how\nimportant is time locality, and which features of interaction patterns are most\nimportant to enable accurate prediction of specific Twitter interactions? Our\nempirical study of Twitter interactions contributes initial answers to these\nquestions.\n  We have crawled an extensive dataset of Greek-speaking Twitter accounts and\ntheir follow, quote, retweet, reply interactions over a period of a month.\n  We find we can accurately predict many interactions of Twitter users.\nInterestingly, the most predictive features vary with the user profiles, and\nare not the same across all users.\n  For example, for a pair of users that interact with a large number of other\nTwitter users, we find that certain \"higher-dimensional\" triads, i.e., triads\nthat involve multiple types of interactions, are very informative, whereas for\nless active Twitter users, certain in-degrees and out-degrees play a major\nrole. Finally, we provide various other insights on Twitter user behavior.\n  Our code and data are available at https://github.com/twittermancer/.\n  Keywords: Graph mining, machine learning, social media, social networks\n", "versions": [{"version": "v1", "created": "Thu, 25 Apr 2019 01:41:21 GMT"}], "update_date": "2019-04-26", "authors_parsed": [["Sotiropoulos", "Konstantinos", ""], ["Byers", "John W.", ""], ["Pratikakis", "Polyvios", ""], ["Tsourakakis", "Charalampos E.", ""]]}, {"id": "1904.11121", "submitter": "Dimitrije Jankov", "authors": "Dimitrije Jankov, Shangyu Luo, Binhang Yuan, Zhuhua Cai, Jia Zou,\n  Chris Jermaine, Zekai J. Gao", "title": "Declarative Recursive Computation on an RDBMS, or, Why You Should Use a\n  Database For Distributed Machine Learning", "comments": null, "journal-ref": null, "doi": "10.14778/3317315.3317323", "report-no": null, "categories": "cs.DB cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A number of popular systems, most notably Google's TensorFlow, have been\nimplemented from the ground up to support machine learning tasks. We consider\nhow to make a very small set of changes to a modern relational database\nmanagement system (RDBMS) to make it suitable for distributed learning\ncomputations. Changes include adding better support for recursion, and\noptimization and execution of very large compute plans. We also show that there\nare key advantages to using an RDBMS as a machine learning platform. In\nparticular, learning based on a database management system allows for trivial\nscaling to large data sets and especially large models, where different\ncomputational units operate on different parts of a model that may be too large\nto fit into RAM.\n", "versions": [{"version": "v1", "created": "Thu, 25 Apr 2019 01:50:52 GMT"}], "update_date": "2019-04-26", "authors_parsed": [["Jankov", "Dimitrije", ""], ["Luo", "Shangyu", ""], ["Yuan", "Binhang", ""], ["Cai", "Zhuhua", ""], ["Zou", "Jia", ""], ["Jermaine", "Chris", ""], ["Gao", "Zekai J.", ""]]}, {"id": "1904.11131", "submitter": "Xu Zhu", "authors": "Xu Zhu", "title": "Lipschitz Bandit Optimization with Improved Efficiency", "comments": "The papers have been removed and we refer the readers to\n  arXiv:1901.09277. arXiv admin note: author list truncated", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI math.OC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the Lipschitz bandit optimization problem with an emphasis on\npractical efficiency. Although there is rich literature on regret analysis of\nthis type of problem, e.g., [Kleinberg et al. 2008, Bubeck et al. 2011,\nSlivkins 2014], their proposed algorithms suffer from serious practical\nproblems including extreme time complexity and dependence on oracle\nimplementations. With this motivation, we propose a novel algorithm with an\nUpper Confidence Bound (UCB) exploration, namely Tree UCB-Hoeffding, using\nadaptive partitions. Our partitioning scheme is easy to implement and does not\nrequire any oracle settings. With a tree-based search strategy, the total\ncomputational cost can be improved to $\\mathcal{O}(T\\log T)$ for the first $T$\niterations. In addition, our algorithm achieves the regret lower bound up to a\nlogarithmic factor.\n", "versions": [{"version": "v1", "created": "Thu, 25 Apr 2019 02:38:33 GMT"}, {"version": "v2", "created": "Wed, 15 May 2019 00:49:54 GMT"}], "update_date": "2019-07-11", "authors_parsed": [["Zhu", "Xu", ""]]}, {"id": "1904.11132", "submitter": "Chapman Siu", "authors": "Chapman Siu", "title": "TreeGrad: Transferring Tree Ensembles to Neural Networks", "comments": "Technical Report on Implementation of Deep Neural Decision Forests\n  Algorithm. To accompany implementation here:\n  https://github.com/chappers/TreeGrad. Update: Please cite as: Siu, C. (2019).\n  \"Transferring Tree Ensembles to Neural Networks\". International Conference on\n  Neural Information Processing. Springer, 2019. arXiv admin note: text overlap\n  with arXiv:1909.11790", "journal-ref": null, "doi": "10.1007/978-3-030-36711-4_39", "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Gradient Boosting Decision Tree (GBDT) are popular machine learning\nalgorithms with implementations such as LightGBM and in popular machine\nlearning toolkits like Scikit-Learn. Many implementations can only produce\ntrees in an offline manner and in a greedy manner. We explore ways to convert\nexisting GBDT implementations to known neural network architectures with\nminimal performance loss in order to allow decision splits to be updated in an\nonline manner and provide extensions to allow splits points to be altered as a\nneural architecture search problem. We provide learning bounds for our neural\nnetwork.\n", "versions": [{"version": "v1", "created": "Thu, 25 Apr 2019 02:54:32 GMT"}, {"version": "v2", "created": "Wed, 25 Sep 2019 21:44:05 GMT"}, {"version": "v3", "created": "Mon, 9 Dec 2019 12:28:48 GMT"}], "update_date": "2020-02-06", "authors_parsed": [["Siu", "Chapman", ""]]}, {"id": "1904.11134", "submitter": "Nikolaj Tatti", "authors": "Michael Mampaey, Jilles Vreeken, Nikolaj Tatti", "title": "Summarizing Data Succinctly with the Most Informative Itemsets", "comments": "Journal version. The previous version is the conference version", "journal-ref": null, "doi": "10.1145/2382577.2382580", "report-no": null, "categories": "cs.DS cs.DB cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Knowledge discovery from data is an inherently iterative process. That is,\nwhat we know about the data greatly determines our expectations, and therefore,\nwhat results we would find interesting and/or surprising. Given new knowledge\nabout the data, our expectations will change. Hence, in order to avoid\nredundant results, knowledge discovery algorithms ideally should follow such an\niterative updating procedure.\n  With this in mind, we introduce a well-founded approach for succinctly\nsummarizing data with the most informative itemsets; using a probabilistic\nmaximum entropy model, we iteratively find the itemset that provides us the\nmost novel information--that is, for which the frequency in the data surprises\nus the most---and in turn we update our model accordingly. As we use the\nMaximum Entropy principle to obtain unbiased probabilistic models, and only\ninclude those itemsets that are most informative with regard to the current\nmodel, the summaries we construct are guaranteed to be both descriptive and\nnon-redundant.\n  The algorithm that we present, called MTV, can either discover the top-$k$\nmost informative itemsets, or we can employ either the Bayesian Information\nCriterion (BIC) or the Minimum Description Length (MDL) principle to\nautomatically identify the set of itemsets that together summarize the data\nwell. In other words, our method will `tell you what you need to know' about\nthe data. Importantly, it is a one-phase algorithm: rather than picking\nitemsets from a user-provided candidate set, itemsets and their supports are\nmined on-the-fly. To further its applicability, we provide an efficient method\nto compute the maximum entropy distribution using Quick Inclusion-Exclusion.\n  Experiments on our method, using synthetic, benchmark, and real data, show\nthat the discovered summaries are succinct, and correctly identify the key\npatterns in the data.\n", "versions": [{"version": "v1", "created": "Thu, 25 Apr 2019 02:59:53 GMT"}, {"version": "v2", "created": "Sat, 27 Apr 2019 01:16:11 GMT"}], "update_date": "2019-04-30", "authors_parsed": [["Mampaey", "Michael", ""], ["Vreeken", "Jilles", ""], ["Tatti", "Nikolaj", ""]]}, {"id": "1904.11138", "submitter": "XiaoBin Li", "authors": "XiaoBin Li, WeiQiang Wang", "title": "Learning Discriminative Features Via Weights-biased Softmax Loss", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Loss functions play a key role in training superior deep neural networks. In\nconvolutional neural networks (CNNs), the popular cross entropy loss together\nwith softmax does not explicitly guarantee minimization of intra-class variance\nor maximization of inter-class variance. In the early studies, there is no\ntheoretical analysis and experiments explicitly indicating how to choose the\nnumber of units in fully connected layer. To help CNNs learn features more fast\nand discriminative, there are two contributions in this paper. First, we\ndetermine the minimum number of units in FC layer by rigorous theoretical\nanalysis and extensive experiment, which reduces CNNs' parameter memory and\ntraining time. Second, we propose a negative-focused weights-biased softmax\n(W-Softmax) loss to help CNNs learn more discriminative features. The proposed\nW-Softmax loss not only theoretically formulates the intraclass compactness and\ninter-class separability, but also can avoid overfitting by enlarging decision\nmargins. Moreover, the size of decision margins can be flexibly controlled by\nadjusting a hyperparameter $\\alpha$. Extensive experimental results on several\nbenchmark datasets show the superiority of W-Softmax in image classification\ntasks.\n", "versions": [{"version": "v1", "created": "Thu, 25 Apr 2019 03:24:53 GMT"}], "update_date": "2019-04-26", "authors_parsed": [["Li", "XiaoBin", ""], ["Wang", "WeiQiang", ""]]}, {"id": "1904.11145", "submitter": "Ali Habibnia", "authors": "Ali Habibnia (1) and Esfandiar Maasoumi (2) ((1) Virginia Tech, (2)\n  Emory University)", "title": "Forecasting in Big Data Environments: an Adaptable and Automated\n  Shrinkage Estimation of Neural Networks (AAShNet)", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "econ.EM cs.LG q-fin.ST stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper considers improved forecasting in possibly nonlinear dynamic\nsettings, with high-dimension predictors (\"big data\" environments). To overcome\nthe curse of dimensionality and manage data and model complexity, we examine\nshrinkage estimation of a back-propagation algorithm of a deep neural net with\nskip-layer connections. We expressly include both linear and nonlinear\ncomponents. This is a high-dimensional learning approach including both\nsparsity L1 and smoothness L2 penalties, allowing high-dimensionality and\nnonlinearity to be accommodated in one step. This approach selects significant\npredictors as well as the topology of the neural network. We estimate optimal\nvalues of shrinkage hyperparameters by incorporating a gradient-based\noptimization technique resulting in robust predictions with improved\nreproducibility. The latter has been an issue in some approaches. This is\nstatistically interpretable and unravels some network structure, commonly left\nto a black box. An additional advantage is that the nonlinear part tends to get\npruned if the underlying process is linear. In an application to forecasting\nequity returns, the proposed approach captures nonlinear dynamics between\nequities to enhance forecast performance. It offers an appreciable improvement\nover current univariate and multivariate models by RMSE and actual portfolio\nperformance.\n", "versions": [{"version": "v1", "created": "Thu, 25 Apr 2019 03:43:02 GMT"}], "update_date": "2019-04-26", "authors_parsed": [["Habibnia", "Ali", ""], ["Maasoumi", "Esfandiar", ""]]}, {"id": "1904.11148", "submitter": "Yuzhou Liu", "authors": "Yuzhou Liu and DeLiang Wang", "title": "Divide and Conquer: A Deep CASA Approach to Talker-independent Monaural\n  Speaker Separation", "comments": "10 pages, 5 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SD cs.LG eess.AS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We address talker-independent monaural speaker separation from the\nperspectives of deep learning and computational auditory scene analysis (CASA).\nSpecifically, we decompose the multi-speaker separation task into the stages of\nsimultaneous grouping and sequential grouping. Simultaneous grouping is first\nperformed in each time frame by separating the spectra of different speakers\nwith a permutation-invariantly trained neural network. In the second stage, the\nframe-level separated spectra are sequentially grouped to different speakers by\na clustering network. The proposed deep CASA approach optimizes frame-level\nseparation and speaker tracking in turn, and produces excellent results for\nboth objectives. Experimental results on the benchmark WSJ0-2mix database show\nthat the new approach achieves the state-of-the-art results with a modest model\nsize.\n", "versions": [{"version": "v1", "created": "Thu, 25 Apr 2019 03:57:11 GMT"}], "update_date": "2019-04-26", "authors_parsed": [["Liu", "Yuzhou", ""], ["Wang", "DeLiang", ""]]}, {"id": "1904.11157", "submitter": "Rohit Jena", "authors": "Rohit Jena", "title": "Out of the Box: A combined approach for handling occlusion in Human Pose\n  Estimation", "comments": "11 pages, 12 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Human Pose estimation is a challenging problem, especially in the case of 3D\npose estimation from 2D images due to many different factors like occlusion,\ndepth ambiguities, intertwining of people, and in general crowds. 2D\nmulti-person human pose estimation in the wild also suffers from the same\nproblems - occlusion, ambiguities, and disentanglement of people's body parts.\nBeing a fundamental problem with loads of applications, including but not\nlimited to surveillance, economical motion capture for video games and movies,\nand physiotherapy, this is an interesting problem to be solved both from a\npractical perspective and from an intellectual perspective as well. Although\nthere are cases where no pose estimation can ever predict with 100% accuracy\n(cases where even humans would fail), there are several algorithms that have\nbrought new state-of-the-art performance in human pose estimation in the wild.\nWe look at a few algorithms with different approaches and also formulate our\nown approach to tackle a consistently bugging problem, i.e. occlusions.\n", "versions": [{"version": "v1", "created": "Thu, 25 Apr 2019 05:10:18 GMT"}], "update_date": "2019-04-26", "authors_parsed": [["Jena", "Rohit", ""]]}, {"id": "1904.11163", "submitter": "Ravi Kumar Thakur", "authors": "Ravi Kumar Thakur and Snehasis Mukherjee", "title": "A Conditional Adversarial Network for Scene Flow Estimation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG cs.RO eess.IV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The problem of Scene flow estimation in depth videos has been attracting\nattention of researchers of robot vision, due to its potential application in\nvarious areas of robotics. The conventional scene flow methods are difficult to\nuse in reallife applications due to their long computational overhead. We\npropose a conditional adversarial network SceneFlowGAN for scene flow\nestimation. The proposed SceneFlowGAN uses loss function at two ends: both\ngenerator and descriptor ends. The proposed network is the first attempt to\nestimate scene flow using generative adversarial networks, and is able to\nestimate both the optical flow and disparity from the input stereo images\nsimultaneously. The proposed method is experimented on a large RGB-D benchmark\nsceneflow dataset.\n", "versions": [{"version": "v1", "created": "Thu, 25 Apr 2019 06:03:06 GMT"}], "update_date": "2019-04-26", "authors_parsed": [["Thakur", "Ravi Kumar", ""], ["Mukherjee", "Snehasis", ""]]}, {"id": "1904.11203", "submitter": "Tom Vander Aa", "authors": "Imen Chakroun, Tom Vander Aa and Tom Ashby", "title": "Reviewing Data Access Patterns and Computational Redundancy for Machine\n  Learning Algorithms", "comments": "European Commission Project: EPEEC - European joint Effort toward a\n  Highly Productive Programming Environment for Heterogeneous Exascale\n  Computing (EC-H2020-80151) An extended version of this paper titled\n  \"Guidelines for enhancing data locality in selected machine learning\n  algorithms\" has been published in the journal \"Intelligent Data Analysis\"", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Machine learning (ML) is probably the first and foremost used technique to\ndeal with the size and complexity of the new generation of data. In this paper,\nwe analyze one of the means to increase the performances of ML algorithms which\nis exploiting data locality. Data locality and access patterns are often at the\nheart of performance issues in computing systems due to the use of certain\nhardware techniques to improve performance. Altering the access patterns to\nincrease locality can dramatically increase performance of a given algorithm.\nBesides, repeated data access can be seen as redundancy in data movement.\nSimilarly, there can also be redundancy in the repetition of calculations. This\nwork also identifies some of the opportunities for avoiding these redundancies\nby directly reusing computation results. We document the possibilities of such\nreuse in some selected machine learning algorithms and give initial indicative\nresults from our first experiments on data access improvement and algorithm\nredesign.\n", "versions": [{"version": "v1", "created": "Thu, 25 Apr 2019 08:26:19 GMT"}, {"version": "v2", "created": "Mon, 29 Jul 2019 14:01:36 GMT"}, {"version": "v3", "created": "Thu, 9 Jan 2020 13:57:20 GMT"}], "update_date": "2020-01-10", "authors_parsed": [["Chakroun", "Imen", ""], ["Aa", "Tom Vander", ""], ["Ashby", "Tom", ""]]}, {"id": "1904.11223", "submitter": "Matteo Manica", "authors": "Matteo Manica, Ali Oskooei, Jannis Born, Vigneshwari Subramanian,\n  Julio S\\'aez-Rodr\\'iguez, Mar\\'ia Rodr\\'iguez Mart\\'inez", "title": "Towards Explainable Anticancer Compound Sensitivity Prediction via\n  Multimodal Attention-based Convolutional Encoders", "comments": "11 pages, 5 figures, 1 table, Workshop on Computational Biology at\n  the International Conference on Machine Learning (ICML), Long Beach, CA, 2019", "journal-ref": "Mol. Pharmaceutics 2019", "doi": "10.1021/acs.molpharmaceut.9b00520", "report-no": null, "categories": "cs.LG cs.AI q-bio.QM stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In line with recent advances in neural drug design and sensitivity\nprediction, we propose a novel architecture for interpretable prediction of\nanticancer compound sensitivity using a multimodal attention-based\nconvolutional encoder. Our model is based on the three key pillars of drug\nsensitivity: compounds' structure in the form of a SMILES sequence, gene\nexpression profiles of tumors and prior knowledge on intracellular interactions\nfrom protein-protein interaction networks. We demonstrate that our multiscale\nconvolutional attention-based (MCA) encoder significantly outperforms a\nbaseline model trained on Morgan fingerprints, a selection of encoders based on\nSMILES as well as previously reported state of the art for multimodal drug\nsensitivity prediction (R2 = 0.86 and RMSE = 0.89). Moreover, the\nexplainability of our approach is demonstrated by a thorough analysis of the\nattention weights. We show that the attended genes significantly enrich\napoptotic processes and that the drug attention is strongly correlated with a\nstandard chemical structure similarity index. Finally, we report a case study\nof two receptor tyrosine kinase (RTK) inhibitors acting on a leukemia cell\nline, showcasing the ability of the model to focus on informative genes and\nsubmolecular regions of the two compounds. The demonstrated generalizability\nand the interpretability of our model testify its potential for in-silico\nprediction of anticancer compound efficacy on unseen cancer cells, positioning\nit as a valid solution for the development of personalized therapies as well as\nfor the evaluation of candidate compounds in de novo drug design.\n", "versions": [{"version": "v1", "created": "Thu, 25 Apr 2019 09:14:52 GMT"}, {"version": "v2", "created": "Wed, 22 May 2019 20:03:13 GMT"}, {"version": "v3", "created": "Sun, 14 Jul 2019 14:00:55 GMT"}], "update_date": "2019-11-07", "authors_parsed": [["Manica", "Matteo", ""], ["Oskooei", "Ali", ""], ["Born", "Jannis", ""], ["Subramanian", "Vigneshwari", ""], ["S\u00e1ez-Rodr\u00edguez", "Julio", ""], ["Mart\u00ednez", "Mar\u00eda Rodr\u00edguez", ""]]}, {"id": "1904.11228", "submitter": "Lei Zhu", "authors": "Xiao Dong, Lei Zhu, Xuemeng Song, Jingjing Li, Zhiyong Cheng", "title": "Adaptive Collaborative Similarity Learning for Unsupervised Multi-view\n  Feature Selection", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  In this paper, we investigate the research problem of unsupervised multi-view\nfeature selection. Conventional solutions first simply combine multiple\npre-constructed view-specific similarity structures into a collaborative\nsimilarity structure, and then perform the subsequent feature selection. These\ntwo processes are separate and independent. The collaborative similarity\nstructure remains fixed during feature selection. Further, the simple\nundirected view combination may adversely reduce the reliability of the\nultimate similarity structure for feature selection, as the view-specific\nsimilarity structures generally involve noises and outlying entries. To\nalleviate these problems, we propose an adaptive collaborative similarity\nlearning (ACSL) for multi-view feature selection. We propose to dynamically\nlearn the collaborative similarity structure, and further integrate it with the\nultimate feature selection into a unified framework. Moreover, a reasonable\nrank constraint is devised to adaptively learn an ideal collaborative\nsimilarity structure with proper similarity combination weights and desirable\nneighbor assignment, both of which could positively facilitate the feature\nselection. An effective solution guaranteed with the proved convergence is\nderived to iteratively tackle the formulated optimization problem. Experiments\ndemonstrate the superiority of the proposed approach.\n", "versions": [{"version": "v1", "created": "Thu, 25 Apr 2019 09:21:31 GMT"}], "update_date": "2019-04-26", "authors_parsed": [["Dong", "Xiao", ""], ["Zhu", "Lei", ""], ["Song", "Xuemeng", ""], ["Li", "Jingjing", ""], ["Cheng", "Zhiyong", ""]]}, {"id": "1904.11266", "submitter": "Lei Zhu", "authors": "Yudong Han, Lei Zhu, Zhiyong Cheng, Jingjing Li, Xiaobai Liu", "title": "Discrete Optimal Graph Clustering", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.IR stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Graph based clustering is one of the major clustering methods. Most of it\nwork in three separate steps: similarity graph construction, clustering label\nrelaxing and label discretization with k-means. Such common practice has three\ndisadvantages: 1) the predefined similarity graph is often fixed and may not be\noptimal for the subsequent clustering. 2) the relaxing process of cluster\nlabels may cause significant information loss. 3) label discretization may\ndeviate from the real clustering result since k-means is sensitive to the\ninitialization of cluster centroids. To tackle these problems, in this paper,\nwe propose an effective discrete optimal graph clustering (DOGC) framework. A\nstructured similarity graph that is theoretically optimal for clustering\nperformance is adaptively learned with a guidance of reasonable rank\nconstraint. Besides, to avoid the information loss, we explicitly enforce a\ndiscrete transformation on the intermediate continuous label, which derives a\ntractable optimization problem with discrete solution. Further, to compensate\nthe unreliability of the learned labels and enhance the clustering accuracy, we\ndesign an adaptive robust module that learns prediction function for the unseen\ndata based on the learned discrete cluster labels. Finally, an iterative\noptimization strategy guaranteed with convergence is developed to directly\nsolve the clustering results. Extensive experiments conducted on both real and\nsynthetic datasets demonstrate the superiority of our proposed methods compared\nwith several state-of-the-art clustering approaches.\n", "versions": [{"version": "v1", "created": "Thu, 25 Apr 2019 11:31:29 GMT"}], "update_date": "2019-04-26", "authors_parsed": [["Han", "Yudong", ""], ["Zhu", "Lei", ""], ["Cheng", "Zhiyong", ""], ["Li", "Jingjing", ""], ["Liu", "Xiaobai", ""]]}, {"id": "1904.11272", "submitter": "Guanzhi Wang", "authors": "Qiao Gu, Guanzhi Wang, Mang Tik Chiu, Yu-Wing Tai, Chi-Keung Tang", "title": "LADN: Local Adversarial Disentangling Network for Facial Makeup and\n  De-Makeup", "comments": "Qiao and Guanzhi have equal contribution. Accepted to ICCV 2019.\n  Project website: https://georgegu1997.github.io/LADN-project-page/", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a local adversarial disentangling network (LADN) for facial makeup\nand de-makeup. Central to our method are multiple and overlapping local\nadversarial discriminators in a content-style disentangling network for\nachieving local detail transfer between facial images, with the use of\nasymmetric loss functions for dramatic makeup styles with high-frequency\ndetails. Existing techniques do not demonstrate or fail to transfer\nhigh-frequency details in a global adversarial setting, or train a single local\ndiscriminator only to ensure image structure consistency and thus work only for\nrelatively simple styles. Unlike others, our proposed local adversarial\ndiscriminators can distinguish whether the generated local image details are\nconsistent with the corresponding regions in the given reference image in\ncross-image style transfer in an unsupervised setting. Incorporating these\ntechnical contributions, we achieve not only state-of-the-art results on\nconventional styles but also novel results involving complex and dramatic\nstyles with high-frequency details covering large areas across multiple facial\nfeatures. A carefully designed dataset of unpaired before and after makeup\nimages is released.\n", "versions": [{"version": "v1", "created": "Thu, 25 Apr 2019 11:52:06 GMT"}, {"version": "v2", "created": "Fri, 9 Aug 2019 07:31:36 GMT"}], "update_date": "2019-08-12", "authors_parsed": [["Gu", "Qiao", ""], ["Wang", "Guanzhi", ""], ["Chiu", "Mang Tik", ""], ["Tai", "Yu-Wing", ""], ["Tang", "Chi-Keung", ""]]}, {"id": "1904.11296", "submitter": "Sarah Itani", "authors": "Sarah Itani and Dorina Thanou", "title": "Combining Anatomical and Functional Networks for Neuropathology\n  Identification: A Case Study on Autism Spectrum Disorder", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.IV cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  While the prevalence of Autism Spectrum Disorder (ASD) is increasing,\nresearch continues in an effort to identify common etiological and\npathophysiological bases. In this regard, modern machine learning and network\nscience pave the way for a better understanding of the neuropathology and the\ndevelopment of diagnosis aid systems. The present work addresses the\nclassification of neurotypical and ASD subjects by combining knowledge about\nboth the structure and the functional activity of the brain. In particular, we\nmodel the brain structure as a graph, and the resting-state functional MRI\n(rs-fMRI) signals as values that live on the nodes of that graph. We then\nborrow tools from the emerging field of Graph Signal Processing (GSP) to build\nfeatures related to the frequency content of these signals. In order to make\nthese features highly discriminative, we apply an extension of the\nFukunaga-Koontz transform. Finally, we use these new markers to train a\ndecision tree, an interpretable classification scheme, which results in a final\ndiagnosis aid model. Interestingly, the resulting decision tree outperforms\nstate-of-the-art methods on the publicly available Autism Brain Imaging Data\nExchange (ABIDE) collection. Moreover, the analysis of the predictive markers\nreveals the influence of the frontal and temporal lobes in the diagnosis of the\ndisorder, which is in line with previous findings in the literature of\nneuroscience. Our results indicate that exploiting jointly structural and\nfunctional information of the brain can reveal important information about the\ncomplexity of the neuropathology.\n", "versions": [{"version": "v1", "created": "Thu, 25 Apr 2019 12:37:01 GMT"}, {"version": "v2", "created": "Wed, 5 Aug 2020 12:47:52 GMT"}], "update_date": "2020-08-06", "authors_parsed": [["Itani", "Sarah", ""], ["Thanou", "Dorina", ""]]}, {"id": "1904.11301", "submitter": "\\c{C}a\\u{g}atay I\\c{s}il", "authors": "\\c{C}a\\u{g}atay I\\c{s}{\\i}l, Figen S. Oktem, Aykut Ko\\c{c}", "title": "Deep Iterative Reconstruction for Phase Retrieval", "comments": "14 pages, 8 figures, published in Applied Optics (Vol. 58, Issue 20,\n  pp. 5422-5431 (2019))", "journal-ref": "\\c{C}a\\u{g}atay I\\c{s}{\\i}l, Figen S. Oktem, and Aykut Ko\\c{c},\n  \"Deep iterative reconstruction for phase retrieval,\" Appl. Opt. 58, 5422-5431\n  (2019)", "doi": "10.1364/AO.58.005422", "report-no": null, "categories": "eess.IV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Classical phase retrieval problem is the recovery of a constrained image from\nthe magnitude of its Fourier transform. Although there are several well-known\nphase retrieval algorithms including the hybrid input-output (HIO) method, the\nreconstruction performance is generally sensitive to initialization and\nmeasurement noise. Recently, deep neural networks (DNNs) have been shown to\nprovide state-of-the-art performance in solving several inverse problems such\nas denoising, deconvolution, and superresolution. In this work, we develop a\nphase retrieval algorithm that utilizes two DNNs together with the model-based\nHIO method. First, a DNN is trained to remove the HIO artifacts and is used\niteratively with the HIO method to improve the reconstructions. After this\niterative phase, a second DNN is trained to remove the remaining artifacts.\nNumerical results demonstrate the effectiveness of ourapproach, which has\nlittle additional computational cost compared to the HIO method. Our approach\nnot only achieves state-of-the-art reconstruction performance but also is more\nrobust to different initialization and noise levels.\n", "versions": [{"version": "v1", "created": "Thu, 25 Apr 2019 12:48:06 GMT"}, {"version": "v2", "created": "Mon, 19 Aug 2019 13:31:10 GMT"}], "update_date": "2019-08-20", "authors_parsed": [["I\u015f\u0131l", "\u00c7a\u011fatay", ""], ["Oktem", "Figen S.", ""], ["Ko\u00e7", "Aykut", ""]]}, {"id": "1904.11316", "submitter": "Yiming Ying", "authors": "Wei Shen, Zhenhuan Yang, Yiming Ying and Xiaoming Yuan", "title": "Stability and Optimization Error of Stochastic Gradient Descent for\n  Pairwise Learning", "comments": "35 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG math.ST stat.ML stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we study the stability and its trade-off with optimization\nerror for stochastic gradient descent (SGD) algorithms in the pairwise learning\nsetting. Pairwise learning refers to a learning task which involves a loss\nfunction depending on pairs of instances among which notable examples are\nbipartite ranking, metric learning, area under ROC (AUC) maximization and\nminimum error entropy (MEE) principle. Our contribution is twofold. Firstly, we\nestablish the stability results of SGD for pairwise learning in the convex,\nstrongly convex and non-convex settings, from which generalization bounds can\nbe naturally derived. Secondly, we establish the trade-off between stability\nand optimization error of SGD algorithms for pairwise learning. This is\nachieved by lower-bounding the sum of stability and optimization error by the\nminimax statistical error over a prescribed class of pairwise loss functions.\nFrom this fundamental trade-off, we obtain lower bounds for the optimization\nerror of SGD algorithms and the excess expected risk over a class of pairwise\nlosses. In addition, we illustrate our stability results by giving some\nspecific examples of AUC maximization, metric learning and MEE.\n", "versions": [{"version": "v1", "created": "Thu, 25 Apr 2019 13:07:37 GMT"}, {"version": "v2", "created": "Fri, 26 Apr 2019 14:39:35 GMT"}], "update_date": "2019-04-29", "authors_parsed": [["Shen", "Wei", ""], ["Yang", "Zhenhuan", ""], ["Ying", "Yiming", ""], ["Yuan", "Xiaoming", ""]]}, {"id": "1904.11325", "submitter": "Aymeric Dieuleveut", "authors": "Kumar Kshitij Patel and Aymeric Dieuleveut", "title": "Communication trade-offs for synchronized distributed SGD with large\n  step size", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG math.OC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Synchronous mini-batch SGD is state-of-the-art for large-scale distributed\nmachine learning. However, in practice, its convergence is bottlenecked by slow\ncommunication rounds between worker nodes. A natural solution to reduce\ncommunication is to use the \\emph{`local-SGD'} model in which the workers train\ntheir model independently and synchronize every once in a while. This algorithm\nimproves the computation-communication trade-off but its convergence is not\nunderstood very well. We propose a non-asymptotic error analysis, which enables\ncomparison to \\emph{one-shot averaging} i.e., a single communication round\namong independent workers, and \\emph{mini-batch averaging} i.e., communicating\nat every step. We also provide adaptive lower bounds on the communication\nfrequency for large step-sizes ($ t^{-\\alpha} $, $ \\alpha\\in (1/2 , 1 ) $) and\nshow that \\emph{Local-SGD} reduces communication by a factor of\n$O\\Big(\\frac{\\sqrt{T}}{P^{3/2}}\\Big)$, with $T$ the total number of gradients\nand $P$ machines.\n", "versions": [{"version": "v1", "created": "Thu, 25 Apr 2019 13:27:30 GMT"}], "update_date": "2019-04-26", "authors_parsed": [["Patel", "Kumar Kshitij", ""], ["Dieuleveut", "Aymeric", ""]]}, {"id": "1904.11352", "submitter": "Paola Favati", "authors": "Paola Favati, Grazia Lotti, Ornella Menchi and Francesco Romani", "title": "Construction of the similarity matrix for the spectral clustering\n  method: numerical experiments", "comments": "Submitted to Journal of Computational and Applied Mathematics", "journal-ref": null, "doi": null, "report-no": "Technical Report IIT TR-09/2017", "categories": "math.NA cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Spectral clustering is a powerful method for finding structure in a dataset\nthrough the eigenvectors of a similarity matrix. It often outperforms\ntraditional clustering algorithms such as $k$-means when the structure of the\nindividual clusters is highly non-convex. Its accuracy depends on how the\nsimilarity between pairs of data points is defined. Two important items\ncontribute to the construction of the similarity matrix: the sparsity of the\nunderlying weighted graph, which depends mainly on the distances among data\npoints, and the similarity function. When a Gaussian similarity function is\nused, the choice of the scale parameter $\\sigma$ can be critical. In this paper\nwe examine both items, the sparsity and the selection of suitable $\\sigma$'s,\nbased either directly on the graph associated to the dataset or on the minimal\nspanning tree (MST) of the graph. An extensive numerical experimentation on\nartificial and real-world datasets has been carried out to compare the\nperformances of the methods.\n", "versions": [{"version": "v1", "created": "Wed, 24 Apr 2019 07:51:59 GMT"}], "update_date": "2019-04-26", "authors_parsed": [["Favati", "Paola", ""], ["Lotti", "Grazia", ""], ["Menchi", "Ornella", ""], ["Romani", "Francesco", ""]]}, {"id": "1904.11366", "submitter": "Yu Ye", "authors": "Yu Ye, Ming Xiao, Mikael Skoglund", "title": "Decentralized Multi-Task Learning Based on Extreme Learning Machines", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In multi-task learning (MTL), related tasks learn jointly to improve\ngeneralization performance. To exploit the high learning speed of extreme\nlearning machines (ELMs), we apply the ELM framework to the MTL problem, where\nthe output weights of ELMs for all the tasks are learned collaboratively. We\nfirst present the ELM based MTL problem in the centralized setting, which is\nsolved by the proposed MTL-ELM algorithm. Due to the fact that many data sets\nof different tasks are geo-distributed, decentralized machine learning is\nstudied. We formulate the decentralized MTL problem based on ELM as majorized\nmulti-block optimization with coupled bi-convex objective functions. To solve\nthe problem, we propose the DMTL-ELM algorithm, which is a hybrid Jacobian and\nGauss-Seidel Proximal multi-block alternating direction method of multipliers\n(ADMM). Further, to reduce the computation load of DMTL-ELM, DMTL-ELM with\nfirst-order approximation (FO-DMTL-ELM) is presented. Theoretical analysis\nshows that the convergence to the stationary point of DMTL-ELM and FO-DMTL-ELM\ncan be guaranteed conditionally. Through simulations, we demonstrate the\nconvergence of proposed MTL-ELM, DMTL-ELM, and FO-DMTL-ELM algorithms, and also\nshow that they can outperform existing MTL methods. Moreover, by adjusting the\ndimension of hidden feature space, there exists a trade-off between\ncommunication load and learning accuracy for DMTL-ELM.\n", "versions": [{"version": "v1", "created": "Thu, 25 Apr 2019 14:19:02 GMT"}], "update_date": "2019-04-26", "authors_parsed": [["Ye", "Yu", ""], ["Xiao", "Ming", ""], ["Skoglund", "Mikael", ""]]}, {"id": "1904.11367", "submitter": "Abeegithan Jeyasothy", "authors": "Abeegithan Jeyasothy, Suresh Sundaram, Savitha Ramasamy, Narasimhan\n  Sundararajan", "title": "A novel method for extracting interpretable knowledge from a spiking\n  neural classifier with time-varying synaptic weights", "comments": "16 pages, 6 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper presents a novel method for information interpretability in an\nMC-SEFRON classifier. To develop a method to extract knowledge stored in a\ntrained classifier, first, the binary-class SEFRON classifier developed earlier\nis extended to handle multi-class problems. MC-SEFRON uses the population\nencoding scheme to encode the real-valued input data into spike patterns.\nMC-SEFRON is trained using the same supervised learning rule used in the\nSEFRON. After training, the proposed method extracts the knowledge for a given\nclass stored in the classifier by mapping the weighted postsynaptic potential\nin the time domain to the feature domain as Feature Strength Functions (FSFs).\nA set of FSFs corresponding to each output class represents the extracted\nknowledge from the classifier. This knowledge encoding method is derived to\nmaintain consistency between the classification in the time domain and the\nfeature domain. The correctness of the FSF is quantitatively measured by using\nFSF directly for classification tasks. For a given input, each FSF is sampled\nat the input value to obtain the corresponding feature strength value (FSV).\nThen the aggregated FSVs obtained for each class are used to determine the\noutput class labels during classification. FSVs are also used to interpret the\npredictions during the classification task. Using ten UCI datasets and the\nMNIST dataset, the knowledge extraction method, interpretation and the\nreliability of the FSF are demonstrated. Based on the studies, it can be seen\nthat on an average, the difference in the classification accuracies using the\nFSF directly and those obtained by MC-SEFRON is only around 0.9% & 0.1\\% for\nthe UCI datasets and the MNIST dataset respectively. This clearly shows that\nthe knowledge represented by the FSFs has acceptable reliability and the\ninterpretability of classification using the classifier's knowledge has been\njustified.\n", "versions": [{"version": "v1", "created": "Thu, 28 Feb 2019 09:49:42 GMT"}], "update_date": "2019-04-26", "authors_parsed": [["Jeyasothy", "Abeegithan", ""], ["Sundaram", "Suresh", ""], ["Ramasamy", "Savitha", ""], ["Sundararajan", "Narasimhan", ""]]}, {"id": "1904.11392", "submitter": "Haoran Wang", "authors": "Haoran Wang, Xun Yu Zhou", "title": "Continuous-Time Mean-Variance Portfolio Selection: A Reinforcement\n  Learning Framework", "comments": "39 pages, 5 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-fin.PM cs.CE cs.LG math.OC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We approach the continuous-time mean-variance (MV) portfolio selection with\nreinforcement learning (RL). The problem is to achieve the best tradeoff\nbetween exploration and exploitation, and is formulated as an\nentropy-regularized, relaxed stochastic control problem. We prove that the\noptimal feedback policy for this problem must be Gaussian, with time-decaying\nvariance. We then establish connections between the entropy-regularized MV and\nthe classical MV, including the solvability equivalence and the convergence as\nexploration weighting parameter decays to zero. Finally, we prove a policy\nimprovement theorem, based on which we devise an implementable RL algorithm. We\nfind that our algorithm outperforms both an adaptive control based method and a\ndeep neural networks based algorithm by a large margin in our simulations.\n", "versions": [{"version": "v1", "created": "Thu, 25 Apr 2019 14:47:15 GMT"}, {"version": "v2", "created": "Sun, 5 May 2019 00:25:27 GMT"}], "update_date": "2019-05-07", "authors_parsed": [["Wang", "Haoran", ""], ["Zhou", "Xun Yu", ""]]}, {"id": "1904.11401", "submitter": "Nadejda Drenska", "authors": "Nadejda Drenska and Robert V. Kohn", "title": "Prediction with Expert Advice: a PDE Perspective", "comments": "30 pages", "journal-ref": null, "doi": "10.1007/s00332-019-09570-3", "report-no": null, "categories": "math.AP cs.GT cs.LG math.OC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This work addresses a classic problem of online prediction with expert\nadvice. We assume an adversarial opponent, and we consider both the\nfinite-horizon and random-stopping versions of this zero-sum, two-person game.\nFocusing on an appropriate continuum limit and using methods from optimal\ncontrol, we characterize the value of the game as the viscosity solution of a\ncertain nonlinear partial differential equation. The analysis also reveals the\npredictor's and the opponent's minimax optimal strategies. Our work provides,\nin particular, a continuum perspective on recent work of Gravin, Peres, and\nSivan (Proc SODA 2016). Our techniques are similar to those of Kohn and Serfaty\n(Comm Pure Appl Math 2010), where scaling limits of some two-person games led\nto elliptic or parabolic PDEs.\n", "versions": [{"version": "v1", "created": "Thu, 25 Apr 2019 15:20:16 GMT"}], "update_date": "2019-09-04", "authors_parsed": [["Drenska", "Nadejda", ""], ["Kohn", "Robert V.", ""]]}, {"id": "1904.11416", "submitter": "Nicholas Sanders", "authors": "Nicholas D. Sanders, Richard M. Everson, Jonathan E. Fieldsend, Alma\n  A. M. Rahat", "title": "A Bayesian Approach for the Robust Optimisation of Expensive-To-Evaluate\n  Functions", "comments": "Submitted to IEEE Transactions on Evolutionary Computation. 11 pages,\n  8 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Many expensive black-box optimisation problems are sensitive to their inputs.\nIn these problems it makes more sense to locate a region of good designs, than\na single, possible fragile, optimal design.\n  Expensive black-box functions can be optimised effectively with Bayesian\noptimisation, where a Gaussian process is a popular choice as a prior over the\nexpensive function. We propose a method for robust optimisation using Bayesian\noptimisation to find a region of design space in which the expensive function's\nperformance is insensitive to the inputs whilst retaining a good quality. This\nis achieved by sampling realisations from a Gaussian process modelling the\nexpensive function and evaluating the improvement for each realisation. The\nexpectation of these improvements can be optimised cheaply with an evolutionary\nalgorithm to determine the next location at which to evaluate the expensive\nfunction. We describe an efficient process to locate the optimum expected\nimprovement. We show empirically that evaluating the expensive function at the\nlocation in the candidate sweet spot about which the model is most uncertain or\nat random yield the best convergence in contrast to exploitative schemes.\n  We illustrate our method on six test functions in two, five, and ten\ndimensions, and demonstrate that it is able to outperform a state-of-the-art\napproach from the literature.\n", "versions": [{"version": "v1", "created": "Thu, 25 Apr 2019 15:43:37 GMT"}, {"version": "v2", "created": "Thu, 9 May 2019 16:55:14 GMT"}], "update_date": "2019-05-10", "authors_parsed": [["Sanders", "Nicholas D.", ""], ["Everson", "Richard M.", ""], ["Fieldsend", "Jonathan E.", ""], ["Rahat", "Alma A. M.", ""]]}, {"id": "1904.11419", "submitter": "Jie Chen", "authors": "Rao Fu, Jie Chen, Shutian Zeng, Yiping Zhuang, Agus Sudjianto", "title": "Time Series Simulation by Conditional Generative Adversarial Net", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG eess.IV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Generative Adversarial Net (GAN) has been proven to be a powerful machine\nlearning tool in image data analysis and generation. In this paper, we propose\nto use Conditional Generative Adversarial Net (CGAN) to learn and simulate time\nseries data. The conditions can be both categorical and continuous variables\ncontaining different kinds of auxiliary information. Our simulation studies\nshow that CGAN is able to learn different kinds of normal and heavy tail\ndistributions, as well as dependent structures of different time series and it\ncan further generate conditional predictive distributions consistent with the\ntraining data distributions. We also provide an in-depth discussion on the\nrationale of GAN and the neural network as hierarchical splines to draw a clear\nconnection with the existing statistical method for distribution generation. In\npractice, CGAN has a wide range of applications in the market risk and\ncounterparty risk analysis: it can be applied to learn the historical data and\ngenerate scenarios for the calculation of Value-at-Risk (VaR) and Expected\nShortfall (ES) and predict the movement of the market risk factors. We present\na real data analysis including a backtesting to demonstrate CGAN is able to\noutperform the Historic Simulation, a popular method in market risk analysis\nfor the calculation of VaR. CGAN can also be applied in the economic time\nseries modeling and forecasting, and an example of hypothetical shock analysis\nfor economic models and the generation of potential CCAR scenarios by CGAN is\ngiven at the end of the paper.\n", "versions": [{"version": "v1", "created": "Thu, 25 Apr 2019 15:49:23 GMT"}], "update_date": "2019-04-26", "authors_parsed": [["Fu", "Rao", ""], ["Chen", "Jie", ""], ["Zeng", "Shutian", ""], ["Zhuang", "Yiping", ""], ["Sudjianto", "Agus", ""]]}, {"id": "1904.11439", "submitter": "Mingde Zhao", "authors": "Mingde Zhao, Sitao Luan, Ian Porada, Xiao-Wen Chang, and Doina Precup", "title": "META-Learning State-based Eligibility Traces for More Sample-Efficient\n  Policy Evaluation", "comments": "Accepted by AAMAS 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Temporal-Difference (TD) learning is a standard and very successful\nreinforcement learning approach, at the core of both algorithms that learn the\nvalue of a given policy, as well as algorithms which learn how to improve\npolicies. TD-learning with eligibility traces provides a way to boost sample\nefficiency by temporal credit assignment, i.e. deciding which portion of a\nreward should be assigned to predecessor states that occurred at different\nprevious times, controlled by a parameter $\\lambda$. However, tuning this\nparameter can be time-consuming, and not tuning it can lead to inefficient\nlearning. For better sample efficiency of TD-learning, we propose a\nmeta-learning method for adjusting the eligibility trace parameter, in a\nstate-dependent manner. The adaptation is achieved with the help of auxiliary\nlearners that learn distributional information about the update targets online,\nincurring roughly the same computational complexity per step as the usual value\nlearner. Our approach can be used both in on-policy and off-policy learning. We\nprove that, under some assumptions, the proposed method improves the overall\nquality of the update targets, by minimizing the overall target error. This\nmethod can be viewed as a plugin to assist prediction with function\napproximation by meta-learning feature (observation)-based $\\lambda$ online, or\neven in the control case to assist policy improvement. Our empirical evaluation\ndemonstrates significant performance improvements, as well as improved\nrobustness of the proposed algorithm to learning rate variation.\n", "versions": [{"version": "v1", "created": "Thu, 25 Apr 2019 16:32:21 GMT"}, {"version": "v2", "created": "Sat, 25 May 2019 22:49:24 GMT"}, {"version": "v3", "created": "Fri, 21 Jun 2019 01:52:16 GMT"}, {"version": "v4", "created": "Fri, 18 Oct 2019 03:19:57 GMT"}, {"version": "v5", "created": "Thu, 27 Feb 2020 03:49:03 GMT"}, {"version": "v6", "created": "Sat, 16 May 2020 18:15:11 GMT"}], "update_date": "2020-05-19", "authors_parsed": [["Zhao", "Mingde", ""], ["Luan", "Sitao", ""], ["Porada", "Ian", ""], ["Chang", "Xiao-Wen", ""], ["Precup", "Doina", ""]]}, {"id": "1904.11455", "submitter": "Tom Schaul", "authors": "Tom Schaul, Diana Borsa, Joseph Modayil, Razvan Pascanu", "title": "Ray Interference: a Source of Plateaus in Deep Reinforcement Learning", "comments": "Full version of RLDM abstract", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Rather than proposing a new method, this paper investigates an issue present\nin existing learning algorithms. We study the learning dynamics of\nreinforcement learning (RL), specifically a characteristic coupling between\nlearning and data generation that arises because RL agents control their future\ndata distribution. In the presence of function approximation, this coupling can\nlead to a problematic type of 'ray interference', characterized by learning\ndynamics that sequentially traverse a number of performance plateaus,\neffectively constraining the agent to learn one thing at a time even when\nlearning in parallel is better. We establish the conditions under which ray\ninterference occurs, show its relation to saddle points and obtain the exact\nlearning dynamics in a restricted setting. We characterize a number of its\nproperties and discuss possible remedies.\n", "versions": [{"version": "v1", "created": "Thu, 25 Apr 2019 16:54:02 GMT"}], "update_date": "2019-04-26", "authors_parsed": [["Schaul", "Tom", ""], ["Borsa", "Diana", ""], ["Modayil", "Joseph", ""], ["Pascanu", "Razvan", ""]]}, {"id": "1904.11466", "submitter": "Ankit Laddha", "authors": "Gregory P. Meyer, Jake Charland, Darshan Hegde, Ankit Laddha, Carlos\n  Vallespi-Gonzalez", "title": "Sensor Fusion for Joint 3D Object Detection and Semantic Segmentation", "comments": "Accepted for publication at CVPR Workshop on Autonomous Driving 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG cs.RO", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  In this paper, we present an extension to LaserNet, an efficient and\nstate-of-the-art LiDAR based 3D object detector. We propose a method for fusing\nimage data with the LiDAR data and show that this sensor fusion method improves\nthe detection performance of the model especially at long ranges. The addition\nof image data is straightforward and does not require image labels.\nFurthermore, we expand the capabilities of the model to perform 3D semantic\nsegmentation in addition to 3D object detection. On a large benchmark dataset,\nwe demonstrate our approach achieves state-of-the-art performance on both\nobject detection and semantic segmentation while maintaining a low runtime.\n", "versions": [{"version": "v1", "created": "Thu, 25 Apr 2019 17:20:31 GMT"}], "update_date": "2019-04-26", "authors_parsed": [["Meyer", "Gregory P.", ""], ["Charland", "Jake", ""], ["Hegde", "Darshan", ""], ["Laddha", "Ankit", ""], ["Vallespi-Gonzalez", "Carlos", ""]]}, {"id": "1904.11475", "submitter": "Ilya Gusev", "authors": "Ilya Gusev", "title": "Importance of Copying Mechanism for News Headline Generation", "comments": null, "journal-ref": "Computational Linguistics and Intellectual Technologies, Papers\n  from the Annual International Conference \"Dialogue\" (2019) Issue 18, 229-236", "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  News headline generation is an essential problem of text summarization\nbecause it is constrained, well-defined, and is still hard to solve. Models\nwith a limited vocabulary can not solve it well, as new named entities can\nappear regularly in the news and these entities often should be in the\nheadline. News articles in morphologically rich languages such as Russian\nrequire model modifications due to a large number of possible word forms. This\nstudy aims to validate that models with a possibility of copying words from the\noriginal article performs better than models without such an option. The\nproposed model achieves a mean ROUGE score of 23 on the provided test dataset,\nwhich is 8 points greater than the result of a similar model without a copying\nmechanism. Moreover, the resulting model performs better than any known model\non the new dataset of Russian news.\n", "versions": [{"version": "v1", "created": "Thu, 25 Apr 2019 17:39:01 GMT"}], "update_date": "2020-05-06", "authors_parsed": [["Gusev", "Ilya", ""]]}, {"id": "1904.11483", "submitter": "Maxime Bouton", "authors": "Maxime Bouton, Alireza Nakhaei, Kikuo Fujimura, Mykel J. Kochenderfer", "title": "Safe Reinforcement Learning with Scene Decomposition for Navigating\n  Complex Urban Environments", "comments": "8 pages; 7 figures", "journal-ref": "IEEE Intelligent Vehicles Symposium (IV), 2019", "doi": null, "report-no": null, "categories": "cs.RO cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Navigating urban environments represents a complex task for automated\nvehicles. They must reach their goal safely and efficiently while considering a\nmultitude of traffic participants. We propose a modular decision making\nalgorithm to autonomously navigate intersections, addressing challenges of\nexisting rule-based and reinforcement learning (RL) approaches. We first\npresent a safe RL algorithm relying on a model-checker to ensure safety\nguarantees. To make the decision strategy robust to perception errors and\nocclusions, we introduce a belief update technique using a learning based\napproach. Finally, we use a scene decomposition approach to scale our algorithm\nto environments with multiple traffic participants. We empirically demonstrate\nthat our algorithm outperforms rule-based methods and reinforcement learning\ntechniques on a complex intersection scenario.\n", "versions": [{"version": "v1", "created": "Thu, 25 Apr 2019 17:52:28 GMT"}], "update_date": "2019-04-26", "authors_parsed": [["Bouton", "Maxime", ""], ["Nakhaei", "Alireza", ""], ["Fujimura", "Kikuo", ""], ["Kochenderfer", "Mykel J.", ""]]}, {"id": "1904.11486", "submitter": "Richard Zhang", "authors": "Richard Zhang", "title": "Making Convolutional Networks Shift-Invariant Again", "comments": "Accepted to ICML 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Modern convolutional networks are not shift-invariant, as small input shifts\nor translations can cause drastic changes in the output. Commonly used\ndownsampling methods, such as max-pooling, strided-convolution, and\naverage-pooling, ignore the sampling theorem. The well-known signal processing\nfix is anti-aliasing by low-pass filtering before downsampling. However, simply\ninserting this module into deep networks degrades performance; as a result, it\nis seldomly used today. We show that when integrated correctly, it is\ncompatible with existing architectural components, such as max-pooling and\nstrided-convolution. We observe \\textit{increased accuracy} in ImageNet\nclassification, across several commonly-used architectures, such as ResNet,\nDenseNet, and MobileNet, indicating effective regularization. Furthermore, we\nobserve \\textit{better generalization}, in terms of stability and robustness to\ninput corruptions. Our results demonstrate that this classical signal\nprocessing technique has been undeservingly overlooked in modern deep networks.\nCode and anti-aliased versions of popular networks are available at\nhttps://richzhang.github.io/antialiased-cnns/ .\n", "versions": [{"version": "v1", "created": "Thu, 25 Apr 2019 17:56:21 GMT"}, {"version": "v2", "created": "Sun, 9 Jun 2019 00:27:38 GMT"}], "update_date": "2019-06-11", "authors_parsed": [["Zhang", "Richard", ""]]}, {"id": "1904.11491", "submitter": "Han Hu", "authors": "Han Hu and Zheng Zhang and Zhenda Xie and Stephen Lin", "title": "Local Relation Networks for Image Recognition", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The convolution layer has been the dominant feature extractor in computer\nvision for years. However, the spatial aggregation in convolution is basically\na pattern matching process that applies fixed filters which are inefficient at\nmodeling visual elements with varying spatial distributions. This paper\npresents a new image feature extractor, called the local relation layer, that\nadaptively determines aggregation weights based on the compositional\nrelationship of local pixel pairs. With this relational approach, it can\ncomposite visual elements into higher-level entities in a more efficient manner\nthat benefits semantic inference. A network built with local relation layers,\ncalled the Local Relation Network (LR-Net), is found to provide greater\nmodeling capacity than its counterpart built with regular convolution on\nlarge-scale recognition tasks such as ImageNet classification.\n", "versions": [{"version": "v1", "created": "Thu, 25 Apr 2019 17:59:35 GMT"}], "update_date": "2019-04-26", "authors_parsed": [["Hu", "Han", ""], ["Zhang", "Zheng", ""], ["Xie", "Zhenda", ""], ["Lin", "Stephen", ""]]}, {"id": "1904.11492", "submitter": "Yue Cao", "authors": "Yue Cao and Jiarui Xu and Stephen Lin and Fangyun Wei and Han Hu", "title": "GCNet: Non-local Networks Meet Squeeze-Excitation Networks and Beyond", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The Non-Local Network (NLNet) presents a pioneering approach for capturing\nlong-range dependencies, via aggregating query-specific global context to each\nquery position. However, through a rigorous empirical analysis, we have found\nthat the global contexts modeled by non-local network are almost the same for\ndifferent query positions within an image. In this paper, we take advantage of\nthis finding to create a simplified network based on a query-independent\nformulation, which maintains the accuracy of NLNet but with significantly less\ncomputation. We further observe that this simplified design shares similar\nstructure with Squeeze-Excitation Network (SENet). Hence we unify them into a\nthree-step general framework for global context modeling. Within the general\nframework, we design a better instantiation, called the global context (GC)\nblock, which is lightweight and can effectively model the global context. The\nlightweight property allows us to apply it for multiple layers in a backbone\nnetwork to construct a global context network (GCNet), which generally\noutperforms both simplified NLNet and SENet on major benchmarks for various\nrecognition tasks. The code and configurations are released at\nhttps://github.com/xvjiarui/GCNet.\n", "versions": [{"version": "v1", "created": "Thu, 25 Apr 2019 17:59:42 GMT"}], "update_date": "2019-04-26", "authors_parsed": [["Cao", "Yue", ""], ["Xu", "Jiarui", ""], ["Lin", "Stephen", ""], ["Wei", "Fangyun", ""], ["Hu", "Han", ""]]}, {"id": "1904.11532", "submitter": "Yi-Chun Chen", "authors": "Yi-Chun Chen, Velibor V. Mi\\v{s}i\\'c", "title": "Decision Forest: A Nonparametric Approach to Modeling Irrational Choice", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG math.OC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Customer behavior is often assumed to follow weak rationality, which implies\nthat adding a product to an assortment will not increase the choice probability\nof another product in that assortment. However, an increasing amount of\nresearch has revealed that customers are not necessarily rational when making\ndecisions. In this paper, we propose a new nonparametric choice model that\nrelaxes this assumption and can model a wider range of customer behavior, such\nas decoy effects between products. In this model, each customer type is\nassociated with a binary decision tree, which represents a decision process for\nmaking a purchase based on checking for the existence of specific products in\nthe assortment. Together with a probability distribution over customer types,\nwe show that the resulting model -- a decision forest -- is able to represent\nany customer choice model, including models that are inconsistent with weak\nrationality. We theoretically characterize the depth of the forest needed to\nfit a data set of historical assortments and prove that with high probability,\na forest whose depth scales logarithmically in the number of assortments is\nsufficient to fit most data sets. We also propose two practical algorithms --\none based on column generation and one based on random sampling -- for\nestimating such models from data. Using synthetic data and real transaction\ndata exhibiting non-rational behavior, we show that the model outperforms both\nrational and non-rational benchmark models in out-of-sample predictive ability.\n", "versions": [{"version": "v1", "created": "Thu, 25 Apr 2019 18:41:29 GMT"}, {"version": "v2", "created": "Tue, 9 Jun 2020 09:47:18 GMT"}], "update_date": "2020-06-11", "authors_parsed": [["Chen", "Yi-Chun", ""], ["Mi\u0161i\u0107", "Velibor V.", ""]]}, {"id": "1904.11538", "submitter": "Shuhang Chen", "authors": "Shuhang Chen, Adithya M. Devraj, Ana Bu\\v{s}i\\'c, Sean P. Meyn", "title": "Zap Q-Learning for Optimal Stopping Time Problems", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SY cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The objective in this paper is to obtain fast converging reinforcement\nlearning algorithms to approximate solutions to the problem of discounted cost\noptimal stopping in an irreducible, uniformly ergodic Markov chain, evolving on\na compact subset of $\\mathbb{R}^n$. We build on the dynamic programming\napproach taken by Tsitsikilis and Van Roy, wherein they propose a Q-learning\nalgorithm to estimate the optimal state-action value function, which then\ndefines an optimal stopping rule. We provide insights as to why the convergence\nrate of this algorithm can be slow, and propose a fast-converging alternative,\nthe \"Zap-Q-learning\" algorithm, designed to achieve optimal rate of\nconvergence. For the first time, we prove the convergence of the Zap-Q-learning\nalgorithm under the assumption of linear function approximation setting. We use\nODE analysis for the proof, and the optimal asymptotic variance property of the\nalgorithm is reflected via fast convergence in a finance example.\n", "versions": [{"version": "v1", "created": "Thu, 25 Apr 2019 18:57:49 GMT"}, {"version": "v2", "created": "Wed, 1 May 2019 18:39:03 GMT"}, {"version": "v3", "created": "Mon, 30 Sep 2019 16:37:22 GMT"}], "update_date": "2019-10-01", "authors_parsed": [["Chen", "Shuhang", ""], ["Devraj", "Adithya M.", ""], ["Bu\u0161i\u0107", "Ana", ""], ["Meyn", "Sean P.", ""]]}, {"id": "1904.11546", "submitter": "Mugdim Bublin", "authors": "Mugdim Bublin", "title": "Machine Learning For Distributed Acoustic Sensors, Classic versus Image\n  and Deep Neural Networks Approach", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.SD eess.AS stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Distributed Acoustic Sensing (DAS) using fiber optic cables is a promising\nnew technology for pipeline monitoring and protection. In this work, we applied\nand compared two approaches for event detection using DAS: Classic machine\nlearning approach and the approach based on image processing and deep learning.\nAlthough with both approaches acceptable performance can be achieved, the\npreliminary results show that image based deep learning is more promising\napproach, offering six times lower event detection delay and twelve times lower\nexecution time.\n", "versions": [{"version": "v1", "created": "Thu, 25 Apr 2019 19:18:31 GMT"}], "update_date": "2019-04-29", "authors_parsed": [["Bublin", "Mugdim", ""]]}, {"id": "1904.11547", "submitter": "Feiyang Pan", "authors": "Feiyang Pan, Shuokai Li, Xiang Ao, Pingzhong Tang, Qing He", "title": "Warm Up Cold-start Advertisements: Improving CTR Predictions via\n  Learning to Learn ID Embeddings", "comments": "Accepted at SIGIR 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.IR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Click-through rate (CTR) prediction has been one of the most central problems\nin computational advertising. Lately, embedding techniques that produce\nlow-dimensional representations of ad IDs drastically improve CTR prediction\naccuracies. However, such learning techniques are data demanding and work\npoorly on new ads with little logging data, which is known as the cold-start\nproblem.\n  In this paper, we aim to improve CTR predictions during both the cold-start\nphase and the warm-up phase when a new ad is added to the candidate pool. We\npropose Meta-Embedding, a meta-learning-based approach that learns to generate\ndesirable initial embeddings for new ad IDs. The proposed method trains an\nembedding generator for new ad IDs by making use of previously learned ads\nthrough gradient-based meta-learning. In other words, our method learns how to\nlearn better embeddings. When a new ad comes, the trained generator initializes\nthe embedding of its ID by feeding its contents and attributes. Next, the\ngenerated embedding can speed up the model fitting during the warm-up phase\nwhen a few labeled examples are available, compared to the existing\ninitialization methods.\n  Experimental results on three real-world datasets showed that Meta-Embedding\ncan significantly improve both the cold-start and warm-up performances for six\nexisting CTR prediction models, ranging from lightweight models such as\nFactorization Machines to complicated deep models such as PNN and DeepFM. All\nof the above apply to conversion rate (CVR) predictions as well.\n", "versions": [{"version": "v1", "created": "Thu, 25 Apr 2019 19:26:42 GMT"}], "update_date": "2019-04-29", "authors_parsed": [["Pan", "Feiyang", ""], ["Li", "Shuokai", ""], ["Ao", "Xiang", ""], ["Tang", "Pingzhong", ""], ["He", "Qing", ""]]}, {"id": "1904.11576", "submitter": "Zulfiqar Ali Z.ali", "authors": "Zulifqar Ali, Ijaz Hussain, Muhammad Faisal, Hafiza Mamona Nazir,\n  Tajammal Hussain, Muhammad Yousaf Shad, Alaa Mohamd Shoukry, Showkat Hussain\n  Gani", "title": "Forecasting Drought Using Multilayer Perceptron Artificial Neural\n  Network Model", "comments": null, "journal-ref": null, "doi": "10.1155/2017/5681308", "report-no": null, "categories": "physics.ao-ph cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  These days human beings are facing many environmental challenges due to\nfrequently occurring drought hazards. It may have an effect on the countrys\nenvironment, the community, and industries. Several adverse impacts of drought\nhazard are continued in Pakistan, including other hazards. However, early\nmeasurement and detection of drought can provide guidance to water resources\nmanagement for employing drought mitigation policies. In this paper, we used a\nmultilayer perceptron neural network (MLPNN) algorithm for drought forecasting.\nWe applied and tested MLPNN algorithm on monthly time series data of\nStandardized Precipitation Evapotranspiration Index (SPEI) for seventeen\nclimatological stations located in Northern Area and KPK (Pakistan). We found\nthat MLPNN has potential capability for SPEI drought forecasting based on\nperformance measures (i.e., Mean Average Error (MAE), the coefficient of\ncorrelation R, and Root Mean Square Error (RMSE). Water resources and\nmanagement planner can take necessary action in advance (e.g., in water\nscarcity areas) by using MLPNN model as part of their decision making.\n", "versions": [{"version": "v1", "created": "Wed, 17 Apr 2019 08:25:02 GMT"}], "update_date": "2019-04-29", "authors_parsed": [["Ali", "Zulifqar", ""], ["Hussain", "Ijaz", ""], ["Faisal", "Muhammad", ""], ["Nazir", "Hafiza Mamona", ""], ["Hussain", "Tajammal", ""], ["Shad", "Muhammad Yousaf", ""], ["Shoukry", "Alaa Mohamd", ""], ["Gani", "Showkat Hussain", ""]]}, {"id": "1904.11577", "submitter": "Bahram Mohammadi", "authors": "Bahram Mohammadi and Mohammad Sabokrou", "title": "End-to-End Adversarial Learning for Intrusion Detection in Computer\n  Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper presents a simple yet efficient method for an anomaly-based\nIntrusion Detection System (IDS). In reality, IDSs can be defined as a\none-class classification system, where the normal traffic is the target class.\nThe high diversity of network attacks in addition to the need for\ngeneralization, motivate us to propose a semi-supervised method. Inspired by\nthe successes of Generative Adversarial Networks (GANs) for training deep\nmodels in semi-unsupervised setting, we have proposed an end-to-end deep\narchitecture for IDS. The proposed architecture is composed of two deep\nnetworks, each of which trained by competing with each other to understand the\nunderlying concept of the normal traffic class. The key idea of this paper is\nto compensate the lack of anomalous traffic by approximately obtain them from\nnormal flows. In this case, our method is not biased towards the available\nintrusions in the training set leading to more accurate detection. The proposed\nmethod has been evaluated on NSL-KDD dataset. The results confirm that our\nmethod outperforms the other state-of-the-art approaches.\n", "versions": [{"version": "v1", "created": "Thu, 25 Apr 2019 20:40:05 GMT"}], "update_date": "2019-04-29", "authors_parsed": [["Mohammadi", "Bahram", ""], ["Sabokrou", "Mohammad", ""]]}, {"id": "1904.11608", "submitter": "Yao Ma", "authors": "Yao Ma, Alex Olshevsky, Venkatesh Saligrama, Csaba Szepesvari", "title": "Gradient Descent for Sparse Rank-One Matrix Completion for Crowd-Sourced\n  Aggregation of Sparsely Interacting Workers", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.HC cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider worker skill estimation for the single-coin Dawid-Skene\ncrowdsourcing model. In practice, skill-estimation is challenging because\nworker assignments are sparse and irregular due to the arbitrary and\nuncontrolled availability of workers. We formulate skill estimation as a\nrank-one correlation-matrix completion problem, where the observed components\ncorrespond to observed label correlations between workers. We show that the\ncorrelation matrix can be successfully recovered and skills are identifiable if\nand only if the sampling matrix (observed components) does not have a bipartite\nconnected component. We then propose a projected gradient descent scheme and\nshow that skill estimates converge to the desired global optima for such\nsampling matrices. Our proof is original and the results are surprising in\nlight of the fact that even the weighted rank-one matrix factorization problem\nis NP-hard in general. Next, we derive sample complexity bounds in terms of\nspectral properties of the signless Laplacian of the sampling matrix. Our\nproposed scheme achieves state-of-art performance on a number of real-world\ndatasets.\n", "versions": [{"version": "v1", "created": "Thu, 25 Apr 2019 22:09:58 GMT"}, {"version": "v2", "created": "Thu, 23 Jul 2020 10:01:19 GMT"}], "update_date": "2020-07-24", "authors_parsed": [["Ma", "Yao", ""], ["Olshevsky", "Alex", ""], ["Saligrama", "Venkatesh", ""], ["Szepesvari", "Csaba", ""]]}, {"id": "1904.11620", "submitter": "Kyongsik Yun", "authors": "Kyongsik Yun, Kevin Yu, Joseph Osborne, Sarah Eldin, Luan Nguyen,\n  Alexander Huyen, Thomas Lu", "title": "Improved visible to IR image transformation using synthetic data\n  augmentation with cycle-consistent adversarial networks", "comments": "8 pages, 6 figures, SPIE", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.IV cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Infrared (IR) images are essential to improve the visibility of dark or\ncamouflaged objects. Object recognition and segmentation based on a neural\nnetwork using IR images provide more accuracy and insight than color visible\nimages. But the bottleneck is the amount of relevant IR images for training. It\nis difficult to collect real-world IR images for special purposes, including\nspace exploration, military and fire-fighting applications. To solve this\nproblem, we created color visible and IR images using a Unity-based 3D game\neditor. These synthetically generated color visible and IR images were used to\ntrain cycle consistent adversarial networks (CycleGAN) to convert visible\nimages to IR images. CycleGAN has the advantage that it does not require\nprecisely matching visible and IR pairs for transformation training. In this\nstudy, we discovered that additional synthetic data can help improve CycleGAN\nperformance. Neural network training using real data (N = 20) performed more\naccurate transformations than training using real (N = 10) and synthetic (N =\n10) data combinations. The result indicates that the synthetic data cannot\nexceed the quality of the real data. Neural network training using real (N =\n10) and synthetic (N = 100) data combinations showed almost the same\nperformance as training using real data (N = 20). At least 10 times more\nsynthetic data than real data is required to achieve the same performance. In\nsummary, CycleGAN is used with synthetic data to improve the IR image\nconversion performance of visible images.\n", "versions": [{"version": "v1", "created": "Thu, 25 Apr 2019 23:12:52 GMT"}], "update_date": "2019-04-29", "authors_parsed": [["Yun", "Kyongsik", ""], ["Yu", "Kevin", ""], ["Osborne", "Joseph", ""], ["Eldin", "Sarah", ""], ["Nguyen", "Luan", ""], ["Huyen", "Alexander", ""], ["Lu", "Thomas", ""]]}, {"id": "1904.11637", "submitter": "Christopher McCord", "authors": "Dimitris Bertsimas and Christopher McCord", "title": "From Predictions to Prescriptions in Multistage Optimization Problems", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we introduce a framework for solving finite-horizon multistage\noptimization problems under uncertainty in the presence of auxiliary data. We\nassume the joint distribution of the uncertain quantities is unknown, but noisy\nobservations, along with observations of auxiliary covariates, are available.\nWe utilize effective predictive methods from machine learning (ML), including\n$k$-nearest neighbors regression ($k$NN), classification and regression trees\n(CART), and random forests (RF), to develop specific methods that are\napplicable to a wide variety of problems. We demonstrate that our solution\nmethods are asymptotically optimal under mild conditions. Additionally, we\nestablish finite sample guarantees for the optimality of our method with $k$NN\nweight functions. Finally, we demonstrate the practicality of our approach with\ncomputational examples. We see a significant decrease in cost by taking into\naccount the auxiliary data in the multistage setting.\n", "versions": [{"version": "v1", "created": "Fri, 26 Apr 2019 01:21:20 GMT"}], "update_date": "2019-04-29", "authors_parsed": [["Bertsimas", "Dimitris", ""], ["McCord", "Christopher", ""]]}, {"id": "1904.11643", "submitter": "Toan Minh Tran Mr", "authors": "Toan Tran, Thanh-Toan Do, Ian Reid, Gustavo Carneiro", "title": "Bayesian Generative Active Deep Learning", "comments": "Accepted to ICML 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep learning models have demonstrated outstanding performance in several\nproblems, but their training process tends to require immense amounts of\ncomputational and human resources for training and labeling, constraining the\ntypes of problems that can be tackled. Therefore, the design of effective\ntraining methods that require small labeled training sets is an important\nresearch direction that will allow a more effective use of resources.Among\ncurrent approaches designed to address this issue, two are particularly\ninteresting: data augmentation and active learning. Data augmentation achieves\nthis goal by artificially generating new training points, while active learning\nrelies on the selection of the \"most informative\" subset of unlabeled training\nsamples to be labelled by an oracle. Although successful in practice, data\naugmentation can waste computational resources because it indiscriminately\ngenerates samples that are not guaranteed to be informative, and active\nlearning selects a small subset of informative samples (from a large\nun-annotated set) that may be insufficient for the training process. In this\npaper, we propose a Bayesian generative active deep learning approach that\ncombines active learning with data augmentation -- we provide theoretical and\nempirical evidence (MNIST, CIFAR-$\\{10,100\\}$, and SVHN) that our approach has\nmore efficient training and better classification results than data\naugmentation and active learning.\n", "versions": [{"version": "v1", "created": "Fri, 26 Apr 2019 01:55:04 GMT"}], "update_date": "2019-04-29", "authors_parsed": [["Tran", "Toan", ""], ["Do", "Thanh-Toan", ""], ["Reid", "Ian", ""], ["Carneiro", "Gustavo", ""]]}, {"id": "1904.11649", "submitter": "Alessandro Lameiras Koerich", "authors": "Alexandre Reeberg Mello, Jonathan de Matos, Marcelo R. Stemmer, Alceu\n  de Souza Britto Jr., Alessandro Lameiras Koerich", "title": "A Novel Orthogonal Direction Mesh Adaptive Direct Search Approach for\n  SVM Hyperparameter Tuning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we propose the use of a black-box optimization method called\ndeterministic Mesh Adaptive Direct Search (MADS) algorithm with orthogonal\ndirections (Ortho-MADS) for the selection of hyperparameters of Support Vector\nMachines with a Gaussian kernel. Different from most of the methods in the\nliterature that exploit the properties of the data or attempt to minimize the\naccuracy of a validation dataset over the first quadrant of (C, gamma), the\nOrtho-MADS provides convergence proof. We present the MADS, followed by the\nOrtho-MADS, the dynamic stopping criterion defined by the MADS mesh size and\ntwo different search strategies (Nelder-Mead and Variable Neighborhood Search)\nthat contribute to a competitive convergence rate as well as a mechanism to\nescape from undesired local minima. We have investigated the practical\nselection of hyperparameters for the Support Vector Machine with a Gaussian\nkernel, i.e., properly choose the hyperparameters gamma (bandwidth) and C\n(trade-off) on several benchmark datasets. The experimental results have shown\nthat the proposed approach for hyperparameter tuning consistently finds\ncomparable or better solutions, when using a common configuration, than other\nmethods. We have also evaluated the accuracy and the number of function\nevaluations of the Ortho-MADS with the Nelder-Mead search strategy and the\nVariable Neighborhood Search strategy using the mesh size as a stopping\ncriterion, and we have achieved accuracy that no other method for\nhyperparameters optimization could reach.\n", "versions": [{"version": "v1", "created": "Fri, 26 Apr 2019 02:09:35 GMT"}], "update_date": "2019-04-29", "authors_parsed": [["Mello", "Alexandre Reeberg", ""], ["de Matos", "Jonathan", ""], ["Stemmer", "Marcelo R.", ""], ["Britto", "Alceu de Souza", "Jr."], ["Koerich", "Alessandro Lameiras", ""]]}, {"id": "1904.11652", "submitter": "Bum Chul Kwon", "authors": "Bum Chul Kwon, Vibha Anand, Kristen A Severson, Soumya Ghosh, Zhaonan\n  Sun, Brigitte I Frohnert, Markus Lundgren, Kenney Ng", "title": "DPVis: Visual Analytics with Hidden Markov Models for Disease\n  Progression Pathways", "comments": "to appear at IEEE Transactions on Visualization and Computer Graphics", "journal-ref": null, "doi": "10.1109/TVCG.2020.2985689", "report-no": null, "categories": "cs.LG cs.HC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Clinical researchers use disease progression models to understand patient\nstatus and characterize progression patterns from longitudinal health records.\nOne approach for disease progression modeling is to describe patient status\nusing a small number of states that represent distinctive distributions over a\nset of observed measures. Hidden Markov models (HMMs) and its variants are a\nclass of models that both discover these states and make inferences of health\nstates for patients. Despite the advantages of using the algorithms for\ndiscovering interesting patterns, it still remains challenging for medical\nexperts to interpret model outputs, understand complex modeling parameters, and\nclinically make sense of the patterns. To tackle these problems, we conducted a\ndesign study with clinical scientists, statisticians, and visualization\nexperts, with the goal to investigate disease progression pathways of chronic\ndiseases, namely type 1 diabetes (T1D), Huntington's disease, Parkinson's\ndisease, and chronic obstructive pulmonary disease (COPD). As a result, we\nintroduce DPVis which seamlessly integrates model parameters and outcomes of\nHMMs into interpretable and interactive visualizations. In this study, we\ndemonstrate that DPVis is successful in evaluating disease progression models,\nvisually summarizing disease states, interactively exploring disease\nprogression patterns, and building, analyzing, and comparing clinically\nrelevant patient subgroups.\n", "versions": [{"version": "v1", "created": "Fri, 26 Apr 2019 02:30:32 GMT"}, {"version": "v2", "created": "Thu, 9 Apr 2020 16:26:43 GMT"}], "update_date": "2020-04-10", "authors_parsed": [["Kwon", "Bum Chul", ""], ["Anand", "Vibha", ""], ["Severson", "Kristen A", ""], ["Ghosh", "Soumya", ""], ["Sun", "Zhaonan", ""], ["Frohnert", "Brigitte I", ""], ["Lundgren", "Markus", ""], ["Ng", "Kenney", ""]]}, {"id": "1904.11681", "submitter": "Lijun Zhang", "authors": "Lijun Zhang, Tie-Yan Liu, Zhi-Hua Zhou", "title": "Adaptive Regret of Convex and Smooth Functions", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We investigate online convex optimization in changing environments, and\nchoose the adaptive regret as the performance measure. The goal is to achieve a\nsmall regret over every interval so that the comparator is allowed to change\nover time. Different from previous works that only utilize the convexity\ncondition, this paper further exploits smoothness to improve the adaptive\nregret. To this end, we develop novel adaptive algorithms for convex and smooth\nfunctions, and establish problem-dependent regret bounds over any interval. Our\nregret bounds are comparable to existing results in the worst case, and become\nmuch tighter when the comparator has a small loss.\n", "versions": [{"version": "v1", "created": "Fri, 26 Apr 2019 06:01:55 GMT"}, {"version": "v2", "created": "Thu, 9 May 2019 07:31:06 GMT"}, {"version": "v3", "created": "Sat, 15 Jun 2019 07:38:05 GMT"}], "update_date": "2019-06-18", "authors_parsed": [["Zhang", "Lijun", ""], ["Liu", "Tie-Yan", ""], ["Zhou", "Zhi-Hua", ""]]}, {"id": "1904.11682", "submitter": "Yongqi Zhang", "authors": "Yongqi Zhang and Quanming Yao and Wenyuan Dai and Lei Chen", "title": "AutoSF: Searching Scoring Functions for Knowledge Graph Embedding", "comments": "accepted by ICDE 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Scoring functions (SFs), which measure the plausibility of triplets in\nknowledge graph (KG), have become the crux of KG embedding. Lots of SFs, which\ntarget at capturing different kinds of relations in KGs, have been designed by\nhumans in recent years. However, as relations can exhibit complex patterns that\nare hard to infer before training, none of them can consistently perform better\nthan others on existing benchmark data sets. In this paper, inspired by the\nrecent success of automated machine learning (AutoML), we propose to\nautomatically design SFs (AutoSF) for distinct KGs by the AutoML techniques.\nHowever, it is non-trivial to explore domain-specific information here to make\nAutoSF efficient and effective. We firstly identify a unified representation\nover popularly used SFs, which helps to set up a search space for AutoSF. Then,\nwe propose a greedy algorithm to search in such a space efficiently. The\nalgorithm is further sped up by a filter and a predictor, which can avoid\nrepeatedly training SFs with same expressive ability and help removing bad\ncandidates during the search before model training. Finally, we perform\nextensive experiments on benchmark data sets. Results on link prediction and\ntriplets classification show that the searched SFs by AutoSF, are KG dependent,\nnew to the literature, and outperform the state-of-the-art SFs designed by\nhumans.\n", "versions": [{"version": "v1", "created": "Fri, 26 Apr 2019 06:04:10 GMT"}, {"version": "v2", "created": "Mon, 3 Jun 2019 17:21:46 GMT"}, {"version": "v3", "created": "Fri, 28 Feb 2020 09:45:17 GMT"}], "update_date": "2020-03-02", "authors_parsed": [["Zhang", "Yongqi", ""], ["Yao", "Quanming", ""], ["Dai", "Wenyuan", ""], ["Chen", "Lei", ""]]}, {"id": "1904.11685", "submitter": "Kai Wang", "authors": "Xiang Wang and Kai Wang and Shiguo Lian", "title": "A Survey on Face Data Augmentation", "comments": "26 pages, 22 figures. Neural Comput & Applic (2020)", "journal-ref": null, "doi": "10.1007/s00521-020-04748-3", "report-no": null, "categories": "cs.CV cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The quality and size of training set have great impact on the results of deep\nlearning-based face related tasks. However, collecting and labeling adequate\nsamples with high quality and balanced distributions still remains a laborious\nand expensive work, and various data augmentation techniques have thus been\nwidely used to enrich the training dataset. In this paper, we systematically\nreview the existing works of face data augmentation from the perspectives of\nthe transformation types and methods, with the state-of-the-art approaches\ninvolved. Among all these approaches, we put the emphasis on the deep\nlearning-based works, especially the generative adversarial networks which have\nbeen recognized as more powerful and effective tools in recent years. We\npresent their principles, discuss the results and show their applications as\nwell as limitations. Different evaluation metrics for evaluating these\napproaches are also introduced. We point out the challenges and opportunities\nin the field of face data augmentation, and provide brief yet insightful\ndiscussions.\n", "versions": [{"version": "v1", "created": "Fri, 26 Apr 2019 06:23:35 GMT"}], "update_date": "2020-04-06", "authors_parsed": [["Wang", "Xiang", ""], ["Wang", "Kai", ""], ["Lian", "Shiguo", ""]]}, {"id": "1904.11686", "submitter": "Yuanming Shi", "authors": "Khaled B. Letaief, Wei Chen, Yuanming Shi, Jun Zhang, Ying-Jun Angela\n  Zhang", "title": "The Roadmap to 6G -- AI Empowered Wireless Networks", "comments": "This work has been submitted to the IEEE for possible publication.\n  Copyright may be transferred without notice, after which this version may no\n  longer be accessible", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The recent upsurge of diversified mobile applications, especially those\nsupported by Artificial Intelligence (AI), is spurring heated discussions on\nthe future evolution of wireless communications. While 5G is being deployed\naround the world, efforts from industry and academia have started to look\nbeyond 5G and conceptualize 6G. We envision 6G to undergo an unprecedented\ntransformation that will make it substantially different from the previous\ngenerations of wireless cellular systems. In particular, 6G will go beyond\nmobile Internet and will be required to support ubiquitous AI services from the\ncore to the end devices of the network. Meanwhile, AI will play a critical role\nin designing and optimizing 6G architectures, protocols, and operations. In\nthis article, we discuss potential technologies for 6G to enable mobile AI\napplications, as well as AI-enabled methodologies for 6G network design and\noptimization. Key trends in the evolution to 6G will also be discussed.\n", "versions": [{"version": "v1", "created": "Fri, 26 Apr 2019 06:27:27 GMT"}, {"version": "v2", "created": "Fri, 19 Jul 2019 06:21:06 GMT"}], "update_date": "2019-07-22", "authors_parsed": [["Letaief", "Khaled B.", ""], ["Chen", "Wei", ""], ["Shi", "Yuanming", ""], ["Zhang", "Jun", ""], ["Zhang", "Ying-Jun Angela", ""]]}, {"id": "1904.11694", "submitter": "Jiayuan Mao", "authors": "Honghua Dong, Jiayuan Mao, Tian Lin, Chong Wang, Lihong Li, Denny Zhou", "title": "Neural Logic Machines", "comments": "ICLR 2019. Project page:\n  https://sites.google.com/view/neural-logic-machines", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose the Neural Logic Machine (NLM), a neural-symbolic architecture for\nboth inductive learning and logic reasoning. NLMs exploit the power of both\nneural networks---as function approximators, and logic programming---as a\nsymbolic processor for objects with properties, relations, logic connectives,\nand quantifiers. After being trained on small-scale tasks (such as sorting\nshort arrays), NLMs can recover lifted rules, and generalize to large-scale\ntasks (such as sorting longer arrays). In our experiments, NLMs achieve perfect\ngeneralization in a number of tasks, from relational reasoning tasks on the\nfamily tree and general graphs, to decision making tasks including sorting\narrays, finding shortest paths, and playing the blocks world. Most of these\ntasks are hard to accomplish for neural networks or inductive logic programming\nalone.\n", "versions": [{"version": "v1", "created": "Fri, 26 Apr 2019 06:52:53 GMT"}], "update_date": "2019-04-29", "authors_parsed": [["Dong", "Honghua", ""], ["Mao", "Jiayuan", ""], ["Lin", "Tian", ""], ["Wang", "Chong", ""], ["Li", "Lihong", ""], ["Zhou", "Denny", ""]]}, {"id": "1904.11701", "submitter": "Martin L\\\"angkvist", "authors": "Martin L\\\"angkvist and Jonas Widell and Per Thunberg and Amy Loutfi\n  and Mats Lid\\'en", "title": "Interactive user interface based on Convolutional Auto-encoders for\n  annotating CT-scans", "comments": "12 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.HC cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  High resolution computed tomography (HRCT) is the most important imaging\nmodality for interstitial lung diseases, where the radiologists are interested\nin identifying certain patterns, and their volumetric and regional\ndistribution. The use of machine learning can assist the radiologists with both\nthese tasks by performing semantic segmentation. In this paper, we propose an\ninteractive annotation-tool for semantic segmentation that assists the\nradiologist in labeling CT scans. The annotation tool is evaluated by six\nradiologists and radiology residents classifying healthy lung and reticular\npattern i HRCT images. The usability of the system is evaluated with a System\nUsability Score (SUS) and interaction information from the readers that used\nthe tool for annotating the CT volumes. It was discovered that the experienced\nusability and how the users interactied with the system differed between the\nusers. A higher SUS-score was given by users that prioritized learning speed\nover model accuracy and spent less time with manual labeling and instead\nutilized the suggestions provided by the GUI. An analysis of the annotation\nvariations between the readers show substantial agreement (Cohen's kappa=0.69)\nfor classification of healthy and affected lung parenchyma in pulmonary\nfibrosis. The inter-reader variation is a challenge for the definition of\nground truth.\n", "versions": [{"version": "v1", "created": "Fri, 26 Apr 2019 07:45:48 GMT"}], "update_date": "2019-04-29", "authors_parsed": [["L\u00e4ngkvist", "Martin", ""], ["Widell", "Jonas", ""], ["Thunberg", "Per", ""], ["Loutfi", "Amy", ""], ["Lid\u00e9n", "Mats", ""]]}, {"id": "1904.11711", "submitter": "Davood Zabihzadeh", "authors": "Sumia Abdulhussien Razooqi Al-Obaidi, Davood Zabihzadeh, and Hamideh\n  Hajiabadi", "title": "Robust Metric Learning based on the Rescaled Hinge Loss", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Distance/Similarity learning is a fundamental problem in machine learning.\nFor example, kNN classifier or clustering methods are based on a\ndistance/similarity measure. Metric learning algorithms enhance the efficiency\nof these methods by learning an optimal distance function from data. Most\nmetric learning methods need training information in the form of pair or\ntriplet sets. Nowadays, this training information often is obtained from the\nInternet via crowdsourcing methods. Therefore, this information may contain\nlabel noise or outliers leading to the poor performance of the learned metric.\nIt is even possible that the learned metric functions perform worse than the\ngeneral metrics such as Euclidean distance. To address this challenge, this\npaper presents a new robust metric learning method based on the Rescaled Hinge\nloss. This loss function is a general case of the popular Hinge loss and\ninitially introduced in (Xu et al. 2017) to develop a new robust SVM algorithm.\nIn this paper, we formulate the metric learning problem using the Rescaled\nHinge loss function and then develop an efficient algorithm based on HQ\n(Half-Quadratic) to solve the problem. Experimental results on a variety of\nboth real and synthetic datasets confirm that our new robust algorithm\nconsiderably outperforms state-of-the-art metric learning methods in the\npresence of label noise and outliers.\n", "versions": [{"version": "v1", "created": "Fri, 26 Apr 2019 08:20:59 GMT"}, {"version": "v2", "created": "Wed, 22 Jan 2020 14:36:54 GMT"}], "update_date": "2020-01-23", "authors_parsed": [["Al-Obaidi", "Sumia Abdulhussien Razooqi", ""], ["Zabihzadeh", "Davood", ""], ["Hajiabadi", "Hamideh", ""]]}, {"id": "1904.11717", "submitter": "Takuya Shimada", "authors": "Takuya Shimada, Han Bao, Issei Sato, Masashi Sugiyama", "title": "Classification from Pairwise Similarities/Dissimilarities and Unlabeled\n  Data via Empirical Risk Minimization", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Pairwise similarities and dissimilarities between data points might be easier\nto obtain than fully labeled data in real-world classification problems, e.g.,\nin privacy-aware situations. To handle such pairwise information, an empirical\nrisk minimization approach has been proposed, giving an unbiased estimator of\nthe classification risk that can be computed only from pairwise similarities\nand unlabeled data. However, this direction cannot handle pairwise\ndissimilarities so far. On the other hand, semi-supervised clustering is one of\nthe methods which can use both similarities and dissimilarities. Nevertheless,\nthey typically require strong geometrical assumptions on the data distribution\nsuch as the manifold assumption, which may deteriorate the performance. In this\npaper, we derive an unbiased risk estimator which can handle all of\nsimilarities/dissimilarities and unlabeled data. We theoretically establish\nestimation error bounds and experimentally demonstrate the practical usefulness\nof our empirical risk minimization method.\n", "versions": [{"version": "v1", "created": "Fri, 26 Apr 2019 08:43:53 GMT"}], "update_date": "2019-04-29", "authors_parsed": [["Shimada", "Takuya", ""], ["Bao", "Han", ""], ["Sato", "Issei", ""], ["Sugiyama", "Masashi", ""]]}, {"id": "1904.11727", "submitter": "Kyungwoo Song", "authors": "Kyungwoo Song, Wonsung Lee, Il-Chul Moon", "title": "Neural Ideal Point Estimation Network", "comments": null, "journal-ref": "AAAI 2018", "doi": null, "report-no": null, "categories": "cs.SI cs.CY cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Understanding politics is challenging because the politics take the influence\nfrom everything. Even we limit ourselves to the political context in the\nlegislative processes; we need a better understanding of latent factors, such\nas legislators, bills, their ideal points, and their relations. From the\nmodeling perspective, this is difficult 1) because these observations lie in a\nhigh dimension that requires learning on low dimensional representations, and\n2) because these observations require complex probabilistic modeling with\nlatent variables to reflect the causalities. This paper presents a new model to\nreflect and understand this political setting, NIPEN, including factors\nmentioned above in the legislation. We propose two versions of NIPEN: one is a\nhybrid model of deep learning and probabilistic graphical model, and the other\nmodel is a neural tensor model. Our result indicates that NIPEN successfully\nlearns the manifold of the legislative bill texts, and NIPEN utilizes the\nlearned low-dimensional latent variables to increase the prediction performance\nof legislators' votings. Additionally, by virtue of being a domain-rich\nprobabilistic model, NIPEN shows the hidden strength of the legislators' trust\nnetwork and their various characteristics on casting votes.\n", "versions": [{"version": "v1", "created": "Fri, 26 Apr 2019 09:08:34 GMT"}], "update_date": "2019-04-29", "authors_parsed": [["Song", "Kyungwoo", ""], ["Lee", "Wonsung", ""], ["Moon", "Il-Chul", ""]]}, {"id": "1904.11738", "submitter": "Chun Kit Yeung", "authors": "Chun-Kit Yeung", "title": "Deep-IRT: Make Deep Learning Based Knowledge Tracing Explainable Using\n  Item Response Theory", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep learning based knowledge tracing model has been shown to outperform\ntraditional knowledge tracing model without the need for human-engineered\nfeatures, yet its parameters and representations have long been criticized for\nnot being explainable. In this paper, we propose Deep-IRT which is a synthesis\nof the item response theory (IRT) model and a knowledge tracing model that is\nbased on the deep neural network architecture called dynamic key-value memory\nnetwork (DKVMN) to make deep learning based knowledge tracing explainable.\nSpecifically, we use the DKVMN model to process the student's learning\ntrajectory and estimate the student ability level and the item difficulty level\nover time. Then, we use the IRT model to estimate the probability that a\nstudent will answer an item correctly using the estimated student ability and\nthe item difficulty. Experiments show that the Deep-IRT model retains the\nperformance of the DKVMN model, while it provides a direct psychological\ninterpretation of both students and items.\n", "versions": [{"version": "v1", "created": "Fri, 26 Apr 2019 09:38:37 GMT"}], "update_date": "2019-04-29", "authors_parsed": [["Yeung", "Chun-Kit", ""]]}, {"id": "1904.11740", "submitter": "Gemma Roig", "authors": "Kshitij Dwivedi, Gemma Roig", "title": "Representation Similarity Analysis for Efficient Task taxonomy &\n  Transfer Learning", "comments": "Accepted at CVPR 2019. Code available at\n  https://github.com/kshitijd20/RSA-CVPR19-release", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Transfer learning is widely used in deep neural network models when there are\nfew labeled examples available. The common approach is to take a pre-trained\nnetwork in a similar task and finetune the model parameters. This is usually\ndone blindly without a pre-selection from a set of pre-trained models, or by\nfinetuning a set of models trained on different tasks and selecting the best\nperforming one by cross-validation. We address this problem by proposing an\napproach to assess the relationship between visual tasks and their\ntask-specific models. Our method uses Representation Similarity Analysis (RSA),\nwhich is commonly used to find a correlation between neuronal responses from\nbrain data and models. With RSA we obtain a similarity score among tasks by\ncomputing correlations between models trained on different tasks. Our method is\nefficient as it requires only pre-trained models, and a few images with no\nfurther training. We demonstrate the effectiveness and efficiency of our method\nfor generating task taxonomy on Taskonomy dataset. We next evaluate the\nrelationship of RSA with the transfer learning performance on Taskonomy tasks\nand a new task: Pascal VOC semantic segmentation. Our results reveal that\nmodels trained on tasks with higher similarity score show higher transfer\nlearning performance. Surprisingly, the best transfer learning result for\nPascal VOC semantic segmentation is not obtained from the pre-trained model on\nsemantic segmentation, probably due to the domain differences, and our method\nsuccessfully selects the high performing models.\n", "versions": [{"version": "v1", "created": "Fri, 26 Apr 2019 09:43:11 GMT"}], "update_date": "2019-04-29", "authors_parsed": [["Dwivedi", "Kshitij", ""], ["Roig", "Gemma", ""]]}, {"id": "1904.11757", "submitter": "Jan-Hendrik Lorenz", "authors": "Jan-Hendrik Lorenz, Julian Nickerl", "title": "The Potential of Restarts for ProbSAT", "comments": "Eurocast 2019", "journal-ref": null, "doi": "10.1007/978-3-030-45093-9_43", "report-no": null, "categories": "cs.DS cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This work analyses the potential of restarts for probSAT, a quite successful\nalgorithm for k-SAT, by estimating its runtime distributions on random 3-SAT\ninstances that are close to the phase transition. We estimate an optimal\nrestart time from empirical data, reaching a potential speedup factor of 1.39.\nCalculating restart times from fitted probability distributions reduces this\nfactor to a maximum of 1.30. A spin-off result is that the Weibull distribution\napproximates the runtime distribution for over 93% of the used instances well.\nA machine learning pipeline is presented to compute a restart time for a\nfixed-cutoff strategy to exploit this potential. The main components of the\npipeline are a random forest for determining the distribution type and a neural\nnetwork for the distribution's parameters. ProbSAT performs statistically\nsignificantly better than Luby's restart strategy and the policy without\nrestarts when using the presented approach. The structure is particularly\nadvantageous on hard problems.\n", "versions": [{"version": "v1", "created": "Fri, 26 Apr 2019 10:51:11 GMT"}], "update_date": "2020-05-11", "authors_parsed": [["Lorenz", "Jan-Hendrik", ""], ["Nickerl", "Julian", ""]]}, {"id": "1904.11761", "submitter": "Robert Pinsler", "authors": "Robert Pinsler, Peter Karkus, Andras Kupcsik, David Hsu, Wee Sun Lee", "title": "Factored Contextual Policy Search with Bayesian Optimization", "comments": "To appear in ICRA 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Scarce data is a major challenge to scaling robot learning to truly complex\ntasks, as we need to generalize locally learned policies over different task\ncontexts. Contextual policy search offers data-efficient learning and\ngeneralization by explicitly conditioning the policy on a parametric context\nspace. In this paper, we further structure the contextual policy\nrepresentation. We propose to factor contexts into two components: target\ncontexts that describe the task objectives, e.g. target position for throwing a\nball; and environment contexts that characterize the environment, e.g. initial\nposition or mass of the ball. Our key observation is that experience can be\ndirectly generalized over target contexts. We show that this can be easily\nexploited in contextual policy search algorithms. In particular, we apply\nfactorization to a Bayesian optimization approach to contextual policy search\nboth in sampling-based and active learning settings. Our simulation results\nshow faster learning and better generalization in various robotic domains. See\nour supplementary video: https://youtu.be/MNTbBAOufDY.\n", "versions": [{"version": "v1", "created": "Fri, 26 Apr 2019 11:04:26 GMT"}], "update_date": "2019-04-29", "authors_parsed": [["Pinsler", "Robert", ""], ["Karkus", "Peter", ""], ["Kupcsik", "Andras", ""], ["Hsu", "David", ""], ["Lee", "Wee Sun", ""]]}, {"id": "1904.11786", "submitter": "Zhepu Xu", "authors": "Qun Yang, Zhepu Xu, Saravanan Gurupackiam, Ping Wang", "title": "A Method for Expressing and Displaying the Vehicle Behavior Distribution\n  in Maintenance Work Zones", "comments": "14 pages, 12 figures, 1 table", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.OH cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Maintenance work zones on the road network have impacts on the normal\ntravelling of vehicles, which increase the risk of traffic accidents. The\ntraffic characteristic analysis in maintenance work zones is a basis for\nmaintenance work zone related research such as layout design, traffic control\nand safety assessment. Due to the difficulty in vehicle microscopic behaviour\ndata acquisition, traditional traffic characteristic analysis mainly focuses on\nmacroscopic characteristics. With the development of data acquisition\ntechnology, it becomes much easier to obtain a large amount of microscopic\nbehaviour data nowadays, which lays a good foundation for analysing the traffic\ncharacteristics from a new point of view. This paper puts forward a method for\nexpressing and displaying the vehicle behaviour distribution in maintenance\nwork zones. Using portable vehicle microscopic behaviour data acquisition\ndevices, lots of data can be obtained. Based on this data, an endpoint\ndetection technology is used to automatically extract the segments in behaviour\ndata with violent fluctuations, which are segments where vehicles take\nbehaviours such as acceleration or turning. Using the support vector machine\nclassification method, the specific types of behaviours of the segments\nextracted can be identified, and together with a data combination method, a\ntotal of ten types of behaviours can be identified. Then the kernel density\nanalysis is used to cluster different types of behaviours of all passing\nvehicles to show the distribution on maps. By this method, how vehicles travel\nthrough maintenance work zones, and how different vehicle behaviours distribute\nin maintenance work zones can be displayed intuitively on maps, which is a\nnovel traffic characteristic and can shed light to maintenance work zone\nrelated researches such as safety assessment and design method.\n", "versions": [{"version": "v1", "created": "Thu, 25 Apr 2019 10:41:38 GMT"}], "update_date": "2019-04-29", "authors_parsed": [["Yang", "Qun", ""], ["Xu", "Zhepu", ""], ["Gurupackiam", "Saravanan", ""], ["Wang", "Ping", ""]]}, {"id": "1904.11798", "submitter": "Sara Morsy", "authors": "Sara Morsy and George Karypis", "title": "Will this Course Increase or Decrease Your GPA? Towards Grade-aware\n  Course Recommendation", "comments": "Under revision for Journal of Educational Data Mining (JEDM)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In order to help undergraduate students towards successfully completing their\ndegrees, developing tools that can assist students during the course selection\nprocess is a significant task in the education domain. The optimal set of\ncourses for each student should include courses that help him/her graduate in a\ntimely fashion and for which he/she is well-prepared for so as to get a good\ngrade in. To this end, we propose two different grade-aware course\nrecommendation approaches to recommend to each student his/her optimal set of\ncourses. The first approach ranks the courses by using an objective function\nthat differentiates between courses that are expected to increase or decrease a\nstudent's GPA. The second approach combines the grades predicted by grade\nprediction methods with the rankings produced by course recommendation methods\nto improve the final course rankings. To obtain the course rankings in the\nfirst approach, we adapt two widely-used representation learning techniques to\nlearn the optimal temporal ordering between courses. Our experiments on a large\ndataset obtained from the University of Minnesota that includes students from\n23 different majors show that the grade-aware course recommendation methods can\ndo better on recommending more courses in which the students are expected to\nperform well and recommending fewer courses in which they are expected not to\nperform well in than grade-unaware course recommendation methods.\n", "versions": [{"version": "v1", "created": "Mon, 22 Apr 2019 21:27:42 GMT"}], "update_date": "2019-04-29", "authors_parsed": [["Morsy", "Sara", ""], ["Karypis", "George", ""]]}, {"id": "1904.11799", "submitter": "Mohit Sharma", "authors": "Mohit Sharma, Jiayu Zhou, Junling Hu, George Karypis", "title": "Feature-based factorized Bilinear Similarity Model for Cold-Start Top-n\n  Item Recommendation", "comments": "9 pages, Proceedings of the 2015 SIAM International Conference on\n  Data Mining", "journal-ref": null, "doi": "10.1137/1.9781611974010.22", "report-no": null, "categories": "cs.IR cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recommending new items to existing users has remained a challenging problem\ndue to absence of user's past preferences for these items. The user\npersonalized non-collaborative methods based on item features can be used to\naddress this item cold-start problem. These methods rely on similarities\nbetween the target item and user's previous preferred items. While computing\nsimilarities based on item features, these methods overlook the interactions\namong the features of the items and consider them independently. Modeling\ninteractions among features can be helpful as some features, when considered\ntogether, provide a stronger signal on the relevance of an item when compared\nto case where features are considered independently. To address this important\nissue, in this work we introduce the Feature-based factorized Bilinear\nSimilarity Model (FBSM), which learns factorized bilinear similarity model for\nTOP-n recommendation of new items, given the information about items preferred\nby users in past as well as the features of these items. We carry out extensive\nempirical evaluations on benchmark datasets, and we find that the proposed FBSM\napproach improves upon traditional non-collaborative methods in terms of\nrecommendation performance. Moreover, the proposed approach also learns\ninsightful interactions among item features from data, which lead to deep\nunderstanding on how these interactions contribute to personalized\nrecommendation.\n", "versions": [{"version": "v1", "created": "Mon, 22 Apr 2019 05:10:48 GMT"}], "update_date": "2019-04-29", "authors_parsed": [["Sharma", "Mohit", ""], ["Zhou", "Jiayu", ""], ["Hu", "Junling", ""], ["Karypis", "George", ""]]}, {"id": "1904.11800", "submitter": "Mohit Sharma", "authors": "Mohit Sharma, and George Karypis", "title": "Adaptive Matrix Completion for the Users and the Items in Tail", "comments": "7 pages, 3 figures, ACM WWW'19", "journal-ref": null, "doi": "10.1145/3308558.3313736", "report-no": null, "categories": "cs.IR cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recommender systems are widely used to recommend the most appealing items to\nusers. These recommendations can be generated by applying collaborative\nfiltering methods. The low-rank matrix completion method is the\nstate-of-the-art collaborative filtering method. In this work, we show that the\nskewed distribution of ratings in the user-item rating matrix of real-world\ndatasets affects the accuracy of matrix-completion-based approaches. Also, we\nshow that the number of ratings that an item or a user has positively\ncorrelates with the ability of low-rank matrix-completion-based approaches to\npredict the ratings for the item or the user accurately. Furthermore, we use\nthese insights to develop four matrix completion-based approaches, i.e.,\nFrequency Adaptive Rating Prediction (FARP), Truncated Matrix Factorization\n(TMF), Truncated Matrix Factorization with Dropout (TMF + Dropout) and Inverse\nFrequency Weighted Matrix Factorization (IFWMF), that outperforms traditional\nmatrix-completion-based approaches for the users and the items with few ratings\nin the user-item rating matrix.\n", "versions": [{"version": "v1", "created": "Mon, 22 Apr 2019 04:55:10 GMT"}, {"version": "v2", "created": "Sun, 5 Jan 2020 00:58:20 GMT"}], "update_date": "2020-01-07", "authors_parsed": [["Sharma", "Mohit", ""], ["Karypis", "George", ""]]}, {"id": "1904.11803", "submitter": "Francesco Ranzato", "authors": "Francesco Ranzato and Marco Zanella", "title": "Robustness Verification of Support Vector Machines", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the problem of formally verifying the robustness to adversarial\nexamples of support vector machines (SVMs), a major machine learning model for\nclassification and regression tasks. Following a recent stream of works on\nformal robustness verification of (deep) neural networks, our approach relies\non a sound abstract version of a given SVM classifier to be used for checking\nits robustness. This methodology is parametric on a given numerical abstraction\nof real values and, analogously to the case of neural networks, needs neither\nabstract least upper bounds nor widening operators on this abstraction. The\nstandard interval domain provides a simple instantiation of our abstraction\ntechnique, which is enhanced with the domain of reduced affine forms, which is\nan efficient abstraction of the zonotope abstract domain. This robustness\nverification technique has been fully implemented and experimentally evaluated\non SVMs based on linear and nonlinear (polynomial and radial basis function)\nkernels, which have been trained on the popular MNIST dataset of images and on\nthe recent and more challenging Fashion-MNIST dataset. The experimental results\nof our prototype SVM robustness verifier appear to be encouraging: this\nautomated verification is fast, scalable and shows significantly high\npercentages of provable robustness on the test set of MNIST, in particular\ncompared to the analogous provable robustness of neural networks.\n", "versions": [{"version": "v1", "created": "Fri, 26 Apr 2019 12:38:11 GMT"}], "update_date": "2019-04-29", "authors_parsed": [["Ranzato", "Francesco", ""], ["Zanella", "Marco", ""]]}, {"id": "1904.11816", "submitter": "Alexandre Salle", "authors": "Alexandre Salle, Marcelo Prates", "title": "Think Again Networks and the Delta Loss", "comments": "redacted experiments on language modeling due to evaluation error", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This short paper introduces an abstraction called Think Again Networks\n(ThinkNet) which can be applied to any state-dependent function (such as a\nrecurrent neural network).\n", "versions": [{"version": "v1", "created": "Fri, 26 Apr 2019 12:57:25 GMT"}, {"version": "v2", "created": "Tue, 30 Apr 2019 20:31:59 GMT"}], "update_date": "2019-05-02", "authors_parsed": [["Salle", "Alexandre", ""], ["Prates", "Marcelo", ""]]}, {"id": "1904.11829", "submitter": "Leila Arras", "authors": "Leila Arras, Ahmed Osman, Klaus-Robert M\\\"uller, Wojciech Samek", "title": "Evaluating Recurrent Neural Network Explanations", "comments": "14 pages, accepted for ACL'19 Workshop BlackboxNLP: Analyzing and\n  Interpreting Neural Networks for NLP", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recently, several methods have been proposed to explain the predictions of\nrecurrent neural networks (RNNs), in particular of LSTMs. The goal of these\nmethods is to understand the network's decisions by assigning to each input\nvariable, e.g., a word, a relevance indicating to which extent it contributed\nto a particular prediction. In previous works, some of these methods were not\nyet compared to one another, or were evaluated only qualitatively. We close\nthis gap by systematically and quantitatively comparing these methods in\ndifferent settings, namely (1) a toy arithmetic task which we use as a sanity\ncheck, (2) a five-class sentiment prediction of movie reviews, and besides (3)\nwe explore the usefulness of word relevances to build sentence-level\nrepresentations. Lastly, using the method that performed best in our\nexperiments, we show how specific linguistic phenomena such as the negation in\nsentiment analysis reflect in terms of relevance patterns, and how the\nrelevance visualization can help to understand the misclassification of\nindividual samples.\n", "versions": [{"version": "v1", "created": "Fri, 26 Apr 2019 13:08:43 GMT"}, {"version": "v2", "created": "Mon, 29 Apr 2019 07:49:19 GMT"}, {"version": "v3", "created": "Tue, 4 Jun 2019 13:52:09 GMT"}], "update_date": "2019-06-05", "authors_parsed": [["Arras", "Leila", ""], ["Osman", "Ahmed", ""], ["M\u00fcller", "Klaus-Robert", ""], ["Samek", "Wojciech", ""]]}, {"id": "1904.11830", "submitter": "Chunguang Li", "authors": "Xiaokun Pu, Chunguang Li", "title": "Online Learning Algorithms for Quaternion ARMA Model", "comments": "17 pages, 2 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we address the problem of adaptive learning for autoregressive\nmoving average (ARMA) model in the quaternion domain. By transforming the\noriginal learning problem into a full information optimization task without\nexplicit noise terms, and then solving the optimization problem using the\ngradient descent and the Newton analogues, we obtain two online learning\nalgorithms for the quaternion ARMA. Furthermore, regret bound analysis\naccounting for the specific properties of quaternion algebra is presented,\nwhich proves that the performance of the online algorithms asymptotically\napproaches that of the best quaternion ARMA model in hindsight.\n", "versions": [{"version": "v1", "created": "Fri, 26 Apr 2019 13:10:14 GMT"}], "update_date": "2019-04-29", "authors_parsed": [["Pu", "Xiaokun", ""], ["Li", "Chunguang", ""]]}, {"id": "1904.11834", "submitter": "Artur Souza", "authors": "Artur Souza, Leonardo B. Oliveira, Sabine Hollatz, Matt Feldman, Kunle\n  Olukotun, James M. Holton, Aina E. Cohen, Luigi Nardi", "title": "DeepFreak: Learning Crystallography Diffraction Patterns with Automated\n  Machine Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Serial crystallography is the field of science that studies the structure and\nproperties of crystals via diffraction patterns. In this paper, we introduce a\nnew serial crystallography dataset comprised of real and synthetic images; the\nsynthetic images are generated through the use of a simulator that is both\nscalable and accurate. The resulting dataset is called DiffraNet, and it is\ncomposed of 25,457 512x512 grayscale labeled images. We explore several\ncomputer vision approaches for classification on DiffraNet such as standard\nfeature extraction algorithms associated with Random Forests and Support Vector\nMachines but also an end-to-end CNN topology dubbed DeepFreak tailored to work\non this new dataset. All implementations are publicly available and have been\nfine-tuned using off-the-shelf AutoML optimization tools for a fair comparison.\nOur best model achieves 98.5% accuracy on synthetic images and 94.51% accuracy\non real images. We believe that the DiffraNet dataset and its classification\nmethods will have in the long term a positive impact in accelerating\ndiscoveries in many disciplines, including chemistry, geology, biology,\nmaterials science, metallurgy, and physics.\n", "versions": [{"version": "v1", "created": "Fri, 26 Apr 2019 13:12:40 GMT"}, {"version": "v2", "created": "Fri, 3 May 2019 15:11:32 GMT"}], "update_date": "2019-05-06", "authors_parsed": [["Souza", "Artur", ""], ["Oliveira", "Leonardo B.", ""], ["Hollatz", "Sabine", ""], ["Feldman", "Matt", ""], ["Olukotun", "Kunle", ""], ["Holton", "James M.", ""], ["Cohen", "Aina E.", ""], ["Nardi", "Luigi", ""]]}, {"id": "1904.11838", "submitter": "Marco Roberti", "authors": "Marco Roberti, Giovanni Bonetta, Rossella Cancelliere, Patrick\n  Gallinari", "title": "Copy mechanism and tailored training for character-based data-to-text\n  generation", "comments": "ECML-PKDD 2019 (Camera ready version)", "journal-ref": null, "doi": "10.1007/978-3-030-46147-8_39", "report-no": null, "categories": "cs.LG cs.CL cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In the last few years, many different methods have been focusing on using\ndeep recurrent neural networks for natural language generation. The most widely\nused sequence-to-sequence neural methods are word-based: as such, they need a\npre-processing step called delexicalization (conversely, relexicalization) to\ndeal with uncommon or unknown words. These forms of processing, however, give\nrise to models that depend on the vocabulary used and are not completely\nneural.\n  In this work, we present an end-to-end sequence-to-sequence model with\nattention mechanism which reads and generates at a character level, no longer\nrequiring delexicalization, tokenization, nor even lowercasing. Moreover, since\ncharacters constitute the common \"building blocks\" of every text, it also\nallows a more general approach to text generation, enabling the possibility to\nexploit transfer learning for training. These skills are obtained thanks to two\nmajor features: (i) the possibility to alternate between the standard\ngeneration mechanism and a copy one, which allows to directly copy input facts\nto produce outputs, and (ii) the use of an original training pipeline that\nfurther improves the quality of the generated texts.\n  We also introduce a new dataset called E2E+, designed to highlight the\ncopying capabilities of character-based models, that is a modified version of\nthe well-known E2E dataset used in the E2E Challenge. We tested our model\naccording to five broadly accepted metrics (including the widely used BLEU),\nshowing that it yields competitive performance with respect to both\ncharacter-based and word-based approaches.\n", "versions": [{"version": "v1", "created": "Fri, 26 Apr 2019 13:33:56 GMT"}, {"version": "v2", "created": "Fri, 28 Jun 2019 11:38:07 GMT"}, {"version": "v3", "created": "Tue, 2 Jul 2019 15:35:14 GMT"}, {"version": "v4", "created": "Mon, 11 May 2020 12:48:10 GMT"}], "update_date": "2020-05-12", "authors_parsed": [["Roberti", "Marco", ""], ["Bonetta", "Giovanni", ""], ["Cancelliere", "Rossella", ""], ["Gallinari", "Patrick", ""]]}, {"id": "1904.11857", "submitter": "Manie Tadayon", "authors": "Manie Tadayon, Greg Pottie", "title": "Predicting Student Performance in an Educational Game Using a Hidden\n  Markov Model", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.CY cs.LG stat.AP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Contributions: Prior studies on education have mostly followed the model of\nthe cross sectional study, namely, examining the pretest and the posttest\nscores. This paper shows that students' knowledge throughout the intervention\ncan be estimated by time series analysis using a hidden Markov model.\nBackground: Analyzing time series and the interaction between the students and\nthe game data can result in valuable information that cannot be gained by only\ncross sectional studies of the exams. Research Questions: Can a hidden Markov\nmodel be used to analyze the educational games? Can a hidden Markov model be\nused to make a prediction of the students' performance? Methodology: The study\nwas conducted on (N=854) students who played the Save Patch game. Students were\ndivided into class 1 and class 2. Class 1 students are those who scored lower\nin the test than class 2 students. The analysis is done by choosing various\nfeatures of the game as the observations. Findings: The state trajectories can\npredict the students' performance accurately for both class 1 and class 2.\n", "versions": [{"version": "v1", "created": "Wed, 24 Apr 2019 06:55:50 GMT"}], "update_date": "2019-05-02", "authors_parsed": [["Tadayon", "Manie", ""], ["Pottie", "Greg", ""]]}, {"id": "1904.11858", "submitter": "Sara Morsy", "authors": "Sara Morsy and George Karypis", "title": "Sparse Neural Attentive Knowledge-based Models for Grade Prediction", "comments": "accepted for publication in EDM 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Grade prediction for future courses not yet taken by students is important as\nit can help them and their advisers during the process of course selection as\nwell as for designing personalized degree plans and modifying them based on\ntheir performance. One of the successful approaches for accurately predicting a\nstudent's grades in future courses is Cumulative Knowledge-based Regression\nModels (CKRM). CKRM learns shallow linear models that predict a student's\ngrades as the similarity between his/her knowledge state and the target course.\nA student's knowledge state is built by linearly accumulating the learned\nprovided knowledge components of the courses he/she has taken in the past,\nweighted by his/her grades in them. However, not all the prior courses\ncontribute equally to the target course. In this paper, we propose a novel\nNeural Attentive Knowledge-based model (NAK) that learns the importance of each\nhistorical course in predicting the grade of a target course. Compared to CKRM\nand other competing approaches, our experiments on a large real-world dataset\nconsisting of $\\sim$1.5 grades show the effectiveness of the proposed NAK model\nin accurately predicting the students' grades. Moreover, the attention weights\nlearned by the model can be helpful in better designing their degree plans.\n", "versions": [{"version": "v1", "created": "Mon, 22 Apr 2019 21:16:17 GMT"}], "update_date": "2019-04-29", "authors_parsed": [["Morsy", "Sara", ""], ["Karypis", "George", ""]]}, {"id": "1904.11874", "submitter": "Silvija Kokalj-Filipovic", "authors": "Silvija Kokalj-Filipovic, Rob Miller, Joshua Morman", "title": "AutoEncoders for Training Compact Deep Learning RF Classifiers for\n  Wireless Protocols", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI cs.LG eess.SP stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We show that compact fully connected (FC) deep learning networks trained to\nclassify wireless protocols using a hierarchy of multiple denoising\nautoencoders (AEs) outperform reference FC networks trained in a typical way,\ni.e., with a stochastic gradient based optimization of a given FC architecture.\nNot only is the complexity of such FC network, measured in number of trainable\nparameters and scalar multiplications, much lower than the reference FC and\nresidual models, its accuracy also outperforms both models for nearly all\ntested SNR values (0 dB to 50dB). Such AE-trained networks are suited for\nin-situ protocol inference performed by simple mobile devices based on noisy\nsignal measurements. Training is based on the data transmitted by real devices,\nand collected in a controlled environment, and systematically augmented by a\npolicy-based data synthesis process by adding to the signal any subset of\nimpairments commonly seen in a wireless receiver.\n", "versions": [{"version": "v1", "created": "Sat, 13 Apr 2019 00:13:01 GMT"}], "update_date": "2019-04-29", "authors_parsed": [["Kokalj-Filipovic", "Silvija", ""], ["Miller", "Rob", ""], ["Morman", "Joshua", ""]]}, {"id": "1904.11875", "submitter": "Ellen Vitercik", "authors": "Daniel Alabi, Adam Tauman Kalai, Katrina Ligett, Cameron Musco,\n  Christos Tzamos, and Ellen Vitercik", "title": "Learning to Prune: Speeding up Repeated Computations", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  It is common to encounter situations where one must solve a sequence of\nsimilar computational problems. Running a standard algorithm with worst-case\nruntime guarantees on each instance will fail to take advantage of valuable\nstructure shared across the problem instances. For example, when a commuter\ndrives from work to home, there are typically only a handful of routes that\nwill ever be the shortest path. A naive algorithm that does not exploit this\ncommon structure may spend most of its time checking roads that will never be\nin the shortest path. More generally, we can often ignore large swaths of the\nsearch space that will likely never contain an optimal solution.\n  We present an algorithm that learns to maximally prune the search space on\nrepeated computations, thereby reducing runtime while provably outputting the\ncorrect solution each period with high probability. Our algorithm employs a\nsimple explore-exploit technique resembling those used in online algorithms,\nthough our setting is quite different. We prove that, with respect to our model\nof pruning search spaces, our approach is optimal up to constant factors.\nFinally, we illustrate the applicability of our model and algorithm to three\nclassic problems: shortest-path routing, string search, and linear programming.\nWe present experiments confirming that our simple algorithm is effective at\nsignificantly reducing the runtime of solving repeated computations.\n", "versions": [{"version": "v1", "created": "Fri, 26 Apr 2019 14:52:03 GMT"}], "update_date": "2019-04-29", "authors_parsed": [["Alabi", "Daniel", ""], ["Kalai", "Adam Tauman", ""], ["Ligett", "Katrina", ""], ["Musco", "Cameron", ""], ["Tzamos", "Christos", ""], ["Vitercik", "Ellen", ""]]}, {"id": "1904.11876", "submitter": "Jakub Tomczak", "authors": "Jakub M. Tomczak and Romain Lepert and Auke Wiggers", "title": "Simulating Execution Time of Tensor Programs using Graph Neural Networks", "comments": "All authors contributed equally. Accepted as a workshop paper at\n  Representation Learning on Graphs and Manifolds @ ICLR 2019. Fixed values in\n  Table 1", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Optimizing the execution time of tensor program, e.g., a convolution,\ninvolves finding its optimal configuration. Searching the configuration space\nexhaustively is typically infeasible in practice. In line with recent research\nusing TVM, we propose to learn a surrogate model to overcome this issue. The\nmodel is trained on an acyclic graph called an abstract syntax tree, and\nutilizes a graph convolutional network to exploit structure in the graph. We\nclaim that a learnable graph-based data processing is a strong competitor to\nheuristic-based feature extraction. We present a new dataset of graphs\ncorresponding to configurations and their execution time for various tensor\nprograms. We provide baselines for a runtime prediction task.\n", "versions": [{"version": "v1", "created": "Fri, 26 Apr 2019 14:53:30 GMT"}, {"version": "v2", "created": "Mon, 24 Jun 2019 11:49:49 GMT"}, {"version": "v3", "created": "Wed, 27 Nov 2019 14:38:08 GMT"}], "update_date": "2019-11-28", "authors_parsed": [["Tomczak", "Jakub M.", ""], ["Lepert", "Romain", ""], ["Wiggers", "Auke", ""]]}, {"id": "1904.11882", "submitter": "Dwj Sukeshkumar Sheth Mr", "authors": "Dwij Sukeshkumar Sheth, Shantanu Singh, Prakhar S Mathur, Vydeki D", "title": "Smart Laptop Bag with Machine Learning for Activity Recognition", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.OH cs.LG eess.SP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In todays world of smart living, the smart laptop bag, presented in this\npaper, provides a better solution to keep track of our precious possessions and\nmonitoring them in real time. As the world moves towards a much tech-savvy\ndirection, the novel laptop bag discussed here facilitates the user to perform\nlocation tracking, ambiance monitoring, user-state monitoring etc. in one\ndevice. The innovative design uses cloud computing and machine learning\nalgorithms to monitor the health of the user and many parameters of the bag.\nThe emergency alert system in this bag could be trained to send appropriate\nnotifications to emergency contacts of the user, in case of abnormal health\nconditions or theft of the bag. The experimental smart laptop bag uses deep\nneural network, which was trained and tested over the various parameters from\nthe bag and produces above 95% accurate results.\n", "versions": [{"version": "v1", "created": "Sun, 14 Apr 2019 06:29:29 GMT"}], "update_date": "2019-04-29", "authors_parsed": [["Sheth", "Dwij Sukeshkumar", ""], ["Singh", "Shantanu", ""], ["Mathur", "Prakhar S", ""], ["D", "Vydeki", ""]]}, {"id": "1904.11883", "submitter": "Bo Jiang", "authors": "Bo Jiang and Ziyan Zhang and Jin Tang and Bin Luo", "title": "Graph Optimized Convolutional Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Graph Convolutional Networks (GCNs) have been widely studied for graph data\nrepresentation and learning tasks. Existing GCNs generally use a fixed single\ngraph which may lead to weak suboptimal for data representation/learning and\nare also hard to deal with multiple graphs. To address these issues, we propose\na novel Graph Optimized Convolutional Network (GOCN) for graph data\nrepresentation and learning. Our GOCN is motivated based on our\nre-interpretation of graph convolution from a regularization/optimization\nframework. The core idea of GOCN is to formulate graph optimization and graph\nconvolutional representation into a unified framework and thus conducts both of\nthem cooperatively to boost their respective performance in GCN learning\nscheme. Moreover, based on the proposed unified graph optimization-convolution\nframework, we propose a novel Multiple Graph Optimized Convolutional Network\n(M-GOCN) to naturally address the data with multiple graphs. Experimental\nresults demonstrate the effectiveness and benefit of the proposed GOCN and\nM-GOCN.\n", "versions": [{"version": "v1", "created": "Fri, 26 Apr 2019 15:05:45 GMT"}], "update_date": "2019-04-29", "authors_parsed": [["Jiang", "Bo", ""], ["Zhang", "Ziyan", ""], ["Tang", "Jin", ""], ["Luo", "Bin", ""]]}, {"id": "1904.11898", "submitter": "Keuntaek Lee", "authors": "Keuntaek Lee, Gabriel Nakajima An, Viacheslav Zakharov, Evangelos A.\n  Theodorou", "title": "Perceptual Attention-based Predictive Control", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.CV cs.LG cs.SY", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  In this paper, we present a novel information processing architecture for\nsafe deep learning-based visual navigation of autonomous systems. The proposed\ninformation processing architecture is used to support a perceptual\nattention-based predictive control algorithm that leverages model predictive\ncontrol (MPC), convolutional neural networks (CNNs), and uncertainty\nquantification methods. The novelty of our approach lies in using MPC to learn\nhow to place attention on relevant areas of the visual input, which ultimately\nallows the system to more rapidly detect unsafe conditions. We accomplish this\nby using MPC to learn to select regions of interest in the input image, which\nare used to output control actions as well as estimates of epistemic and\naleatoric uncertainty in the attention-aware visual input. We use these\nuncertainty estimates to quantify the safety of our network controller under\nthe current navigation condition. The proposed architecture and algorithm is\ntested on a 1:5 scale terrestrial vehicle. Experimental results show that the\nproposed algorithm outperforms previous approaches on early detection of unsafe\nconditions, such as when novel obstacles are present in the navigation\nenvironment. The proposed architecture is the first step towards using deep\nlearning-based perceptual control policies in safety-critical domains.\n", "versions": [{"version": "v1", "created": "Fri, 26 Apr 2019 15:38:37 GMT"}, {"version": "v2", "created": "Wed, 16 Oct 2019 01:05:22 GMT"}], "update_date": "2019-10-17", "authors_parsed": [["Lee", "Keuntaek", ""], ["An", "Gabriel Nakajima", ""], ["Zakharov", "Viacheslav", ""], ["Theodorou", "Evangelos A.", ""]]}, {"id": "1904.11914", "submitter": "Saeedreza Shehnepoor", "authors": "Mohammad Adiban, Bagher BabaAli, Saeedreza Shehnepoor", "title": "Statistical feature embedding for heart sound classification", "comments": null, "journal-ref": "Journal of Electrical Engineering, 70(4), 259-272 (2019)", "doi": "10.2478/jee-2019-0056", "report-no": null, "categories": "cs.LG cs.SD eess.AS stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Cardiovascular Disease (CVD) is considered as one of the principal causes of\ndeath in the world. Over recent years, this field of study has attracted\nresearchers' attention to investigate heart sounds' patterns for disease\ndiagnostics. In this study, an approach is proposed for normal/abnormal heart\nsound classification on the Physionet challenge 2016 dataset. For the first\ntime, a fixed-length feature vector; called i-vector; is extracted from each\nheart sound using Mel Frequency Cepstral Coefficient (MFCC) features.\nAfterwards, Principal Component Analysis (PCA) transform and Variational\nAutoencoder (VAE) are applied on the i-vector to achieve dimension reduction.\nEventually, the reduced size vector is fed to Gaussian Mixture Models (GMMs)\nand Support Vector Machine (SVM) for classification purpose. Experimental\nresults demonstrate the proposed method could achieve a performance improvement\nof 16% based on Modified Accuracy (MAcc) compared with the baseline system on\nthe Physoinet dataset.\n", "versions": [{"version": "v1", "created": "Fri, 26 Apr 2019 16:07:18 GMT"}, {"version": "v2", "created": "Tue, 23 Jul 2019 10:31:29 GMT"}, {"version": "v3", "created": "Mon, 9 Nov 2020 06:43:56 GMT"}], "update_date": "2020-11-10", "authors_parsed": [["Adiban", "Mohammad", ""], ["BabaAli", "Bagher", ""], ["Shehnepoor", "Saeedreza", ""]]}, {"id": "1904.11943", "submitter": "Guandao Yang", "authors": "Guandao Yang, Tianyi Zhang, Polina Kirichenko, Junwen Bai, Andrew\n  Gordon Wilson, Christopher De Sa", "title": "SWALP : Stochastic Weight Averaging in Low-Precision Training", "comments": "Published at ICML 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Low precision operations can provide scalability, memory savings,\nportability, and energy efficiency. This paper proposes SWALP, an approach to\nlow precision training that averages low-precision SGD iterates with a modified\nlearning rate schedule. SWALP is easy to implement and can match the\nperformance of full-precision SGD even with all numbers quantized down to 8\nbits, including the gradient accumulators. Additionally, we show that SWALP\nconverges arbitrarily close to the optimal solution for quadratic objectives,\nand to a noise ball asymptotically smaller than low precision SGD in strongly\nconvex settings.\n", "versions": [{"version": "v1", "created": "Fri, 26 Apr 2019 17:22:06 GMT"}, {"version": "v2", "created": "Mon, 20 May 2019 16:00:08 GMT"}], "update_date": "2019-05-21", "authors_parsed": [["Yang", "Guandao", ""], ["Zhang", "Tianyi", ""], ["Kirichenko", "Polina", ""], ["Bai", "Junwen", ""], ["Wilson", "Andrew Gordon", ""], ["De Sa", "Christopher", ""]]}, {"id": "1904.11949", "submitter": "Nunzio Alexandro Letizia Mr", "authors": "Andrea M. Tonello, Nunzio A. Letizia, Davide Righini and Francesco\n  Marcuzzi", "title": "Machine Learning Tips and Tricks for Power Line Communications", "comments": "Accepted for publication in IEEE Access. 19 pages, 15 figures, 142\n  references. Added Sec. II-C", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.SP cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A great deal of attention has been recently given to Machine Learning (ML)\ntechniques in many different application fields. This paper provides a vision\nof what ML can do in Power Line Communications (PLC). We firstly and briefly\ndescribe classical formulations of ML, and distinguish deterministic from\nstatistical learning models with relevance to communications. We then discuss\nML applications in PLC for each layer, namely, for characterization and\nmodeling, for the development of physical layer algorithms, for media access\ncontrol and networking. Finally, other applications of PLC that can benefit\nfrom the usage of ML, as grid diagnostics, are analyzed. Illustrative numerical\nexamples are reported to serve the purpose of validating the ideas and motivate\nfuture research endeavors in this stimulating signal/data processing field.\n", "versions": [{"version": "v1", "created": "Wed, 24 Apr 2019 15:07:31 GMT"}, {"version": "v2", "created": "Thu, 6 Jun 2019 07:53:51 GMT"}], "update_date": "2019-06-07", "authors_parsed": [["Tonello", "Andrea M.", ""], ["Letizia", "Nunzio A.", ""], ["Righini", "Davide", ""], ["Marcuzzi", "Francesco", ""]]}, {"id": "1904.11950", "submitter": "Chuanqi Tan", "authors": "Chuanqi Tan, Fuchun Sun, Tao Kong, Bin Fang and Wenchang Zhang", "title": "Attention-based Transfer Learning for Brain-computer Interface", "comments": "In Proceedings of IEEE International Conference on Acoustics, Speech\n  and Signal Processing (ICASSP) 2019, 12 - 17 May, 2019, Brighton, UK", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.SP cs.AI cs.HC cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Different functional areas of the human brain play different roles in brain\nactivity, which has not been paid sufficient research attention in the\nbrain-computer interface (BCI) field. This paper presents a new approach for\nelectroencephalography (EEG) classification that applies attention-based\ntransfer learning. Our approach considers the importance of different brain\nfunctional areas to improve the accuracy of EEG classification, and provides an\nadditional way to automatically identify brain functional areas associated with\nnew activities without the involvement of a medical professional. We\ndemonstrate empirically that our approach out-performs state-of-the-art\napproaches in the task of EEG classification, and the results of visualization\nindicate that our approach can detect brain functional areas related to a\ncertain task.\n", "versions": [{"version": "v1", "created": "Thu, 25 Apr 2019 06:10:09 GMT"}], "update_date": "2019-04-29", "authors_parsed": [["Tan", "Chuanqi", ""], ["Sun", "Fuchun", ""], ["Kong", "Tao", ""], ["Fang", "Bin", ""], ["Zhang", "Wenchang", ""]]}, {"id": "1904.11955", "submitter": "Simon Du", "authors": "Sanjeev Arora, Simon S. Du, Wei Hu, Zhiyuan Li, Ruslan Salakhutdinov,\n  Ruosong Wang", "title": "On Exact Computation with an Infinitely Wide Neural Net", "comments": "In NeurIPS 2019. Code available: https://github.com/ruosongwang/cntk", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  How well does a classic deep net architecture like AlexNet or VGG19 classify\non a standard dataset such as CIFAR-10 when its width --- namely, number of\nchannels in convolutional layers, and number of nodes in fully-connected\ninternal layers --- is allowed to increase to infinity? Such questions have\ncome to the forefront in the quest to theoretically understand deep learning\nand its mysteries about optimization and generalization. They also connect deep\nlearning to notions such as Gaussian processes and kernels. A recent paper\n[Jacot et al., 2018] introduced the Neural Tangent Kernel (NTK) which captures\nthe behavior of fully-connected deep nets in the infinite width limit trained\nby gradient descent; this object was implicit in some other recent papers. An\nattraction of such ideas is that a pure kernel-based method is used to capture\nthe power of a fully-trained deep net of infinite width.\n  The current paper gives the first efficient exact algorithm for computing the\nextension of NTK to convolutional neural nets, which we call Convolutional NTK\n(CNTK), as well as an efficient GPU implementation of this algorithm. This\nresults in a significant new benchmark for the performance of a pure\nkernel-based method on CIFAR-10, being $10\\%$ higher than the methods reported\nin [Novak et al., 2019], and only $6\\%$ lower than the performance of the\ncorresponding finite deep net architecture (once batch normalization, etc. are\nturned off). Theoretically, we also give the first non-asymptotic proof showing\nthat a fully-trained sufficiently wide net is indeed equivalent to the kernel\nregression predictor using NTK.\n", "versions": [{"version": "v1", "created": "Fri, 26 Apr 2019 17:29:37 GMT"}, {"version": "v2", "created": "Mon, 4 Nov 2019 15:10:47 GMT"}], "update_date": "2019-11-05", "authors_parsed": [["Arora", "Sanjeev", ""], ["Du", "Simon S.", ""], ["Hu", "Wei", ""], ["Li", "Zhiyuan", ""], ["Salakhutdinov", "Ruslan", ""], ["Wang", "Ruosong", ""]]}, {"id": "1904.11968", "submitter": "David Wehr", "authors": "David Wehr, Halley Fede, Eleanor Pence, Bo Zhang, Guilherme Ferreira,\n  John Walczyk, Joseph Hughes", "title": "Learning Semantic Vector Representations of Source Code via a Siamese\n  Neural Network", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.PL cs.SE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The abundance of open-source code, coupled with the success of recent\nadvances in deep learning for natural language processing, has given rise to a\npromising new application of machine learning to source code. In this work, we\nexplore the use of a Siamese recurrent neural network model on Python source\ncode to create vectors which capture the semantics of code. We evaluate the\nquality of embeddings by identifying which problem from a programming\ncompetition the code solves. Our model significantly outperforms a\nbag-of-tokens embedding, providing promising results for improving code\nembeddings that can be used in future software engineering tasks.\n", "versions": [{"version": "v1", "created": "Fri, 26 Apr 2019 17:52:06 GMT"}], "update_date": "2019-04-29", "authors_parsed": [["Wehr", "David", ""], ["Fede", "Halley", ""], ["Pence", "Eleanor", ""], ["Zhang", "Bo", ""], ["Ferreira", "Guilherme", ""], ["Walczyk", "John", ""], ["Hughes", "Joseph", ""]]}, {"id": "1904.12004", "submitter": "Chenglong Wang", "authors": "Chenglong Wang, Rudy Bunel, Krishnamurthy Dvijotham, Po-Sen Huang,\n  Edward Grefenstette, Pushmeet Kohli", "title": "Knowing When to Stop: Evaluation and Verification of Conformity to\n  Output-size Specifications", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Models such as Sequence-to-Sequence and Image-to-Sequence are widely used in\nreal world applications. While the ability of these neural architectures to\nproduce variable-length outputs makes them extremely effective for problems\nlike Machine Translation and Image Captioning, it also leaves them vulnerable\nto failures of the form where the model produces outputs of undesirable length.\nThis behavior can have severe consequences such as usage of increased\ncomputation and induce faults in downstream modules that expect outputs of a\ncertain length. Motivated by the need to have a better understanding of the\nfailures of these models, this paper proposes and studies the novel output-size\nmodulation problem and makes two key technical contributions. First, to\nevaluate model robustness, we develop an easy-to-compute differentiable proxy\nobjective that can be used with gradient-based algorithms to find\noutput-lengthening inputs. Second and more importantly, we develop a\nverification approach that can formally verify whether a network always\nproduces outputs within a certain length. Experimental results on Machine\nTranslation and Image Captioning show that our output-lengthening approach can\nproduce outputs that are 50 times longer than the input, while our verification\napproach can, given a model and input domain, prove that the output length is\nbelow a certain size.\n", "versions": [{"version": "v1", "created": "Fri, 26 Apr 2019 18:12:56 GMT"}], "update_date": "2019-04-30", "authors_parsed": [["Wang", "Chenglong", ""], ["Bunel", "Rudy", ""], ["Dvijotham", "Krishnamurthy", ""], ["Huang", "Po-Sen", ""], ["Grefenstette", "Edward", ""], ["Kohli", "Pushmeet", ""]]}, {"id": "1904.12017", "submitter": "Jonathan Tuck", "authors": "Jonathan Tuck, Shane Barratt, Stephen Boyd", "title": "A Distributed Method for Fitting Laplacian Regularized Stratified Models", "comments": "37 pages, 6 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG math.OC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Stratified models are models that depend in an arbitrary way on a set of\nselected categorical features, and depend linearly on the other features. In a\nbasic and traditional formulation a separate model is fit for each value of the\ncategorical feature, using only the data that has the specific categorical\nvalue. To this formulation we add Laplacian regularization, which encourages\nthe model parameters for neighboring categorical values to be similar.\nLaplacian regularization allows us to specify one or more weighted graphs on\nthe stratification feature values. For example, stratifying over the days of\nthe week, we can specify that the Sunday model parameter should be close to the\nSaturday and Monday model parameters. The regularization improves the\nperformance of the model over the traditional stratified model, since the model\nfor each value of the categorical `borrows strength' from its neighbors. In\nparticular, it produces a model even for categorical values that did not appear\nin the training data set.\n  We propose an efficient distributed method for fitting stratified models,\nbased on the alternating direction method of multipliers (ADMM). When the\nfitting loss functions are convex, the stratified model fitting problem is\nconvex, and our method computes the global minimizer of the loss plus\nregularization; in other cases it computes a local minimizer. The method is\nvery efficient, and naturally scales to large data sets or numbers of\nstratified feature values. We illustrate our method with a variety of examples.\n", "versions": [{"version": "v1", "created": "Fri, 26 Apr 2019 19:05:59 GMT"}, {"version": "v2", "created": "Thu, 27 Jun 2019 22:39:16 GMT"}, {"version": "v3", "created": "Sun, 10 Nov 2019 20:22:18 GMT"}], "update_date": "2019-11-12", "authors_parsed": [["Tuck", "Jonathan", ""], ["Barratt", "Shane", ""], ["Boyd", "Stephen", ""]]}, {"id": "1904.12043", "submitter": "Haibin Lin", "authors": "Haibin Lin, Hang Zhang, Yifei Ma, Tong He, Zhi Zhang, Sheng Zha, Mu Li", "title": "Dynamic Mini-batch SGD for Elastic Distributed Training: Learning in the\n  Limbo of Resources", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV cs.DC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  With an increasing demand for training powers for deep learning algorithms\nand the rapid growth of computation resources in data centers, it is desirable\nto dynamically schedule different distributed deep learning tasks to maximize\nresource utilization and reduce cost. In this process, different tasks may\nreceive varying numbers of machines at different time, a setting we call\nelastic distributed training. Despite the recent successes in large mini-batch\ndistributed training, these methods are rarely tested in elastic distributed\ntraining environments and suffer degraded performance in our experiments, when\nwe adjust the learning rate linearly immediately with respect to the batch\nsize. One difficulty we observe is that the noise in the stochastic momentum\nestimation is accumulated over time and will have delayed effects when the\nbatch size changes. We therefore propose to smoothly adjust the learning rate\nover time to alleviate the influence of the noisy momentum estimation. Our\nexperiments on image classification, object detection and semantic segmentation\nhave demonstrated that our proposed Dynamic SGD method achieves stabilized\nperformance when varying the number of GPUs from 8 to 128. We also provide\ntheoretical understanding on the optimality of linear learning rate scheduling\nand the effects of stochastic momentum.\n", "versions": [{"version": "v1", "created": "Fri, 26 Apr 2019 20:45:28 GMT"}, {"version": "v2", "created": "Thu, 2 May 2019 06:48:24 GMT"}], "update_date": "2019-05-03", "authors_parsed": [["Lin", "Haibin", ""], ["Zhang", "Hang", ""], ["Ma", "Yifei", ""], ["He", "Tong", ""], ["Zhang", "Zhi", ""], ["Zha", "Sheng", ""], ["Li", "Mu", ""]]}, {"id": "1904.12052", "submitter": "Hengtong Zhang", "authors": "Hengtong Zhang, Tianhang Zheng, Jing Gao, Chenglin Miao, Lu Su,\n  Yaliang Li, Kui Ren", "title": "Data Poisoning Attack against Knowledge Graph Embedding", "comments": "Fix typos and version conflicts", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Knowledge graph embedding (KGE) is a technique for learning continuous\nembeddings for entities and relations in the knowledge graph.Due to its benefit\nto a variety of downstream tasks such as knowledge graph completion, question\nanswering and recommendation, KGE has gained significant attention recently.\nDespite its effectiveness in a benign environment, KGE' robustness to\nadversarial attacks is not well-studied. Existing attack methods on graph data\ncannot be directly applied to attack the embeddings of knowledge graph due to\nits heterogeneity. To fill this gap, we propose a collection of data poisoning\nattack strategies, which can effectively manipulate the plausibility of\narbitrary targeted facts in a knowledge graph by adding or deleting facts on\nthe graph. The effectiveness and efficiency of the proposed attack strategies\nare verified by extensive evaluations on two widely-used benchmarks.\n", "versions": [{"version": "v1", "created": "Fri, 26 Apr 2019 21:12:19 GMT"}, {"version": "v2", "created": "Mon, 24 Jun 2019 04:06:02 GMT"}], "update_date": "2019-06-25", "authors_parsed": [["Zhang", "Hengtong", ""], ["Zheng", "Tianhang", ""], ["Gao", "Jing", ""], ["Miao", "Chenglin", ""], ["Su", "Lu", ""], ["Li", "Yaliang", ""], ["Ren", "Kui", ""]]}, {"id": "1904.12053", "submitter": "Shivam Garg", "authors": "Brian Axelrod, Shivam Garg, Vatsal Sharan, Gregory Valiant", "title": "Sample Amplification: Increasing Dataset Size even when Learning is\n  Impossible", "comments": "Added discussion about potential applications", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG math.ST stat.ML stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Given data drawn from an unknown distribution, $D$, to what extent is it\npossible to ``amplify'' this dataset and output an even larger set of samples\nthat appear to have been drawn from $D$? We formalize this question as follows:\nan $(n,m)$ $\\text{amplification procedure}$ takes as input $n$ independent\ndraws from an unknown distribution $D$, and outputs a set of $m > n$\n``samples''. An amplification procedure is valid if no algorithm can\ndistinguish the set of $m$ samples produced by the amplifier from a set of $m$\nindependent draws from $D$, with probability greater than $2/3$. Perhaps\nsurprisingly, in many settings, a valid amplification procedure exists, even\nwhen the size of the input dataset, $n$, is significantly less than what would\nbe necessary to learn $D$ to non-trivial accuracy. Specifically we consider two\nfundamental settings: the case where $D$ is an arbitrary discrete distribution\nsupported on $\\le k$ elements, and the case where $D$ is a $d$-dimensional\nGaussian with unknown mean, and fixed covariance. In the first case, we show\nthat an $\\left(n, n + \\Theta(\\frac{n}{\\sqrt{k}})\\right)$ amplifier exists. In\nparticular, given $n=O(\\sqrt{k})$ samples from $D$, one can output a set of\n$m=n+1$ datapoints, whose total variation distance from the distribution of $m$\ni.i.d. draws from $D$ is a small constant, despite the fact that one would need\nquadratically more data, $n=\\Theta(k)$, to learn $D$ up to small constant total\nvariation distance. In the Gaussian case, we show that an\n$\\left(n,n+\\Theta(\\frac{n}{\\sqrt{d}} )\\right)$ amplifier exists, even though\nlearning the distribution to small constant total variation distance requires\n$\\Theta(d)$ samples. In both the discrete and Gaussian settings, we show that\nthese results are tight, to constant factors. Beyond these results, we\nformalize a number of curious directions for future research along this vein.\n", "versions": [{"version": "v1", "created": "Fri, 26 Apr 2019 21:42:44 GMT"}, {"version": "v2", "created": "Tue, 3 Dec 2019 01:40:28 GMT"}], "update_date": "2019-12-04", "authors_parsed": [["Axelrod", "Brian", ""], ["Garg", "Shivam", ""], ["Sharan", "Vatsal", ""], ["Valiant", "Gregory", ""]]}, {"id": "1904.12054", "submitter": "Marc Z\\\"oller", "authors": "Marc-Andr\\'e Z\\\"oller and Marco F. Huber", "title": "Benchmark and Survey of Automated Machine Learning Frameworks", "comments": "Revised version accepted for publication at Journal of Artificial\n  Intelligence Research (JAIR)", "journal-ref": "Journal of Artificial Intelligence Research 70 (2021) 409-472", "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Machine learning (ML) has become a vital part in many aspects of our daily\nlife. However, building well performing machine learning applications requires\nhighly specialized data scientists and domain experts. Automated machine\nlearning (AutoML) aims to reduce the demand for data scientists by enabling\ndomain experts to build machine learning applications automatically without\nextensive knowledge of statistics and machine learning. This paper is a\ncombination of a survey on current AutoML methods and a benchmark of popular\nAutoML frameworks on real data sets. Driven by the selected frameworks for\nevaluation, we summarize and review important AutoML techniques and methods\nconcerning every step in building an ML pipeline. The selected AutoML\nframeworks are evaluated on 137 data sets from established AutoML benchmark\nsuits.\n", "versions": [{"version": "v1", "created": "Fri, 26 Apr 2019 21:42:56 GMT"}, {"version": "v2", "created": "Wed, 8 Jan 2020 11:19:24 GMT"}, {"version": "v3", "created": "Sun, 30 Aug 2020 09:49:10 GMT"}, {"version": "v4", "created": "Thu, 14 Jan 2021 15:09:26 GMT"}, {"version": "v5", "created": "Tue, 26 Jan 2021 15:52:33 GMT"}], "update_date": "2021-01-27", "authors_parsed": [["Z\u00f6ller", "Marc-Andr\u00e9", ""], ["Huber", "Marco F.", ""]]}, {"id": "1904.12058", "submitter": "Muhan Zhang", "authors": "Muhan Zhang, Yixin Chen", "title": "Inductive Matrix Completion Based on Graph Neural Networks", "comments": "Accepted as a spotlight presentation at ICLR-2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose an inductive matrix completion model without using side\ninformation. By factorizing the (rating) matrix into the product of\nlow-dimensional latent embeddings of rows (users) and columns (items), a\nmajority of existing matrix completion methods are transductive, since the\nlearned embeddings cannot generalize to unseen rows/columns or to new matrices.\nTo make matrix completion inductive, most previous works use content (side\ninformation), such as user's age or movie's genre, to make predictions.\nHowever, high-quality content is not always available, and can be hard to\nextract. Under the extreme setting where not any side information is available\nother than the matrix to complete, can we still learn an inductive matrix\ncompletion model? In this paper, we propose an Inductive Graph-based Matrix\nCompletion (IGMC) model to address this problem. IGMC trains a graph neural\nnetwork (GNN) based purely on 1-hop subgraphs around (user, item) pairs\ngenerated from the rating matrix and maps these subgraphs to their\ncorresponding ratings. It achieves highly competitive performance with\nstate-of-the-art transductive baselines. In addition, IGMC is inductive -- it\ncan generalize to users/items unseen during the training (given that their\ninteractions exist), and can even transfer to new tasks. Our transfer learning\nexperiments show that a model trained out of the MovieLens dataset can be\ndirectly used to predict Douban movie ratings with surprisingly good\nperformance. Our work demonstrates that: 1) it is possible to train inductive\nmatrix completion models without using side information while achieving similar\nor better performances than state-of-the-art transductive methods; 2) local\ngraph patterns around a (user, item) pair are effective predictors of the\nrating this user gives to the item; and 3) Long-range dependencies might not be\nnecessary for modeling recommender systems.\n", "versions": [{"version": "v1", "created": "Fri, 26 Apr 2019 21:58:46 GMT"}, {"version": "v2", "created": "Sun, 6 Oct 2019 03:08:54 GMT"}, {"version": "v3", "created": "Sun, 16 Feb 2020 04:27:14 GMT"}], "update_date": "2020-02-18", "authors_parsed": [["Zhang", "Muhan", ""], ["Chen", "Yixin", ""]]}, {"id": "1904.12072", "submitter": "Gurtej Kanwar", "authors": "M. S. Albergo, G. Kanwar, P. E. Shanahan", "title": "Flow-based generative models for Markov chain Monte Carlo in lattice\n  field theory", "comments": "13 pages, 7 figures; corrected normalization conventions in eqns. 20\n  and 23", "journal-ref": "Phys. Rev. D 100, 034515 (2019)", "doi": "10.1103/PhysRevD.100.034515", "report-no": "MIT-CTP/5114", "categories": "hep-lat cond-mat.dis-nn cond-mat.stat-mech cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A Markov chain update scheme using a machine-learned flow-based generative\nmodel is proposed for Monte Carlo sampling in lattice field theories. The\ngenerative model may be optimized (trained) to produce samples from a\ndistribution approximating the desired Boltzmann distribution determined by the\nlattice action of the theory being studied. Training the model systematically\nimproves autocorrelation times in the Markov chain, even in regions of\nparameter space where standard Markov chain Monte Carlo algorithms exhibit\ncritical slowing down in producing decorrelated updates. Moreover, the model\nmay be trained without existing samples from the desired distribution. The\nalgorithm is compared with HMC and local Metropolis sampling for $\\phi^4$\ntheory in two dimensions.\n", "versions": [{"version": "v1", "created": "Fri, 26 Apr 2019 23:30:09 GMT"}, {"version": "v2", "created": "Wed, 31 Jul 2019 14:44:25 GMT"}, {"version": "v3", "created": "Mon, 9 Sep 2019 17:53:37 GMT"}], "update_date": "2019-09-10", "authors_parsed": [["Albergo", "M. S.", ""], ["Kanwar", "G.", ""], ["Shanahan", "P. E.", ""]]}, {"id": "1904.12083", "submitter": "Bo Dai", "authors": "Bo Dai, Zhen Liu, Hanjun Dai, Niao He, Arthur Gretton, Le Song, Dale\n  Schuurmans", "title": "Exponential Family Estimation via Adversarial Dynamics Embedding", "comments": "Appearing in NeurIPS 2019 Vancouver, Canada; a preliminary version\n  published in NeurIPS2018 Bayesian Deep Learning Workshop", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.CO stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present an efficient algorithm for maximum likelihood estimation (MLE) of\nexponential family models, with a general parametrization of the energy\nfunction that includes neural networks. We exploit the primal-dual view of the\nMLE with a kinetics augmented model to obtain an estimate associated with an\nadversarial dual sampler. To represent this sampler, we introduce a novel\nneural architecture, dynamics embedding, that generalizes Hamiltonian\nMonte-Carlo (HMC). The proposed approach inherits the flexibility of HMC while\nenabling tractable entropy estimation for the augmented model. By learning both\na dual sampler and the primal model simultaneously, and sharing parameters\nbetween them, we obviate the requirement to design a separate sampling\nprocedure once the model has been trained, leading to more effective learning.\nWe show that many existing estimators, such as contrastive divergence,\npseudo/composite-likelihood, score matching, minimum Stein discrepancy\nestimator, non-local contrastive objectives, noise-contrastive estimation, and\nminimum probability flow, are special cases of the proposed approach, each\nexpressed by a different (fixed) dual sampler. An empirical investigation shows\nthat adapting the sampler during MLE can significantly improve on\nstate-of-the-art estimators.\n", "versions": [{"version": "v1", "created": "Sat, 27 Apr 2019 01:20:21 GMT"}, {"version": "v2", "created": "Sun, 1 Dec 2019 06:36:27 GMT"}, {"version": "v3", "created": "Mon, 30 Mar 2020 20:20:43 GMT"}], "update_date": "2020-04-01", "authors_parsed": [["Dai", "Bo", ""], ["Liu", "Zhen", ""], ["Dai", "Hanjun", ""], ["He", "Niao", ""], ["Gretton", "Arthur", ""], ["Song", "Le", ""], ["Schuurmans", "Dale", ""]]}, {"id": "1904.12084", "submitter": "Zhanfu Yang", "authors": "Zhanfu Yang, Fei Wang, Ziliang Chen, Guannan Wei, Tiark Rompf", "title": "Graph Neural Reasoning for 2-Quantified Boolean Formula Solvers", "comments": "5 Pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we investigate the feasibility of learning GNN (Graph Neural\nNetwork) based solvers and GNN-based heuristics for specified QBF (Quantified\nBoolean Formula) problems. We design and evaluate several GNN architectures for\n2QBF formulae, and conjecture that GNN has limitations in learning 2QBF\nsolvers. Then we show how to learn a heuristic CEGAR 2QBF solver. We further\nexplore generalizing GNN-based heuristics to larger unseen instances, and\nuncover some interesting challenges. In summary, this paper provides a\ncomprehensive surveying view of applying GNN-embeddings to specified QBF\nsolvers, and aims to offer guidance in applying ML to more complicated symbolic\nreasoning problems.\n", "versions": [{"version": "v1", "created": "Sat, 27 Apr 2019 01:30:50 GMT"}], "update_date": "2019-04-30", "authors_parsed": [["Yang", "Zhanfu", ""], ["Wang", "Fei", ""], ["Chen", "Ziliang", ""], ["Wei", "Guannan", ""], ["Rompf", "Tiark", ""]]}, {"id": "1904.12098", "submitter": "Jordan Henkel", "authors": "Jordan Henkel, Shuvendu K. Lahiri, Ben Liblit, Thomas Reps", "title": "Enabling Open-World Specification Mining via Unsupervised Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SE cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Many programming tasks require using both domain-specific code and\nwell-established patterns (such as routines concerned with file IO). Together,\nseveral small patterns combine to create complex interactions. This compounding\neffect, mixed with domain-specific idiosyncrasies, creates a challenging\nenvironment for fully automatic specification inference. Mining specifications\nin this environment, without the aid of rule templates, user-directed feedback,\nor predefined API surfaces, is a major challenge. We call this challenge\nOpen-World Specification Mining.\n  In this paper, we present a framework for mining specifications and usage\npatterns in an Open-World setting. We design this framework to be\nminer-agnostic and instead focus on disentangling complex and noisy API\ninteractions. To evaluate our framework, we introduce a benchmark of 71\nclusters extracted from five open-source projects. Using this dataset, we show\nthat interesting clusters can be recovered, in a fully automatic way, by\nleveraging unsupervised learning in the form of word embeddings. Once clusters\nhave been recovered, the challenge of Open-World Specification Mining is\nsimplified and any trace-based mining technique can be applied. In addition, we\nprovide a comprehensive evaluation of three word-vector learners to showcase\nthe value of sub-word information for embeddings learned in the\nsoftware-engineering domain.\n", "versions": [{"version": "v1", "created": "Sat, 27 Apr 2019 03:16:07 GMT"}], "update_date": "2019-04-30", "authors_parsed": [["Henkel", "Jordan", ""], ["Lahiri", "Shuvendu K.", ""], ["Liblit", "Ben", ""], ["Reps", "Thomas", ""]]}, {"id": "1904.12118", "submitter": "Gopi Sanghani Dr.", "authors": "Gopi Sanghani, Ketan Kotecha", "title": "Incremental personalized E-mail spam filter using novel TFDCR feature\n  selection with dynamic feature update", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Communication through e-mails remains to be highly formalized, conventional\nand indispensable method for the exchange of information over the Internet. An\never-increasing ratio and adversary nature of spam e-mails have posed a great\nmany challenges such as uneven class distribution, unequal error cost, frequent\nchange of content and personalized context-sensitive discrimination. In this\nresearch, we propose a novel and distinctive approach to develop an incremental\npersonalized e-mail spam filter. The proposed work is described using three\nsignificant contributions. First, we applied a novel term frequency difference\nand category ratio based feature selection function TFDCR to select the most\ndiscriminating features irrespective of the number of samples in each class.\nSecond, an incremental learning model is used which enables the classifier to\nupdate the discriminant function dynamically. Third, a heuristic function\ncalled selectionRankWeight is introduced to upgrade the existing feature set\nthat determines new features carrying strong discriminating ability from an\nincoming set of e-mails. Three public e-mail datasets possessing different\ncharacteristics are used to evaluate the filter performance. Experiments are\nconducted to compare the feature selection efficiency of TFDCR and to observe\nthe filter performance under both the batch and the incremental learning mode.\nThe results demonstrate the superiority of TFDCR as the most effective f eature\nselection function. The incremental learning model incorporating dynamic\nfeature update function overcomes the problem of drifting concepts. The\nproposed filter validates its efficiency and feasibility by substantially\nimproving the classification accuracy and reducing the false positive error of\nmisclassifying legitimate e-mail as spam.\n", "versions": [{"version": "v1", "created": "Sat, 27 Apr 2019 07:00:18 GMT"}], "update_date": "2019-04-30", "authors_parsed": [["Sanghani", "Gopi", ""], ["Kotecha", "Ketan", ""]]}, {"id": "1904.12138", "submitter": "Nidhi Rastogi", "authors": "Nidhi Rastogi", "title": "Exploring Information Centrality for Intrusion Detection in Large\n  Networks", "comments": "14 pages, 4 figures, 18th Annual Security Conference", "journal-ref": "In Proceedings of the Annual Information Institute Conference,\n  March 26-28, 2018. Las Vegas, USA. ISBN: 978-1-935160-19-9", "doi": null, "report-no": null, "categories": "cs.CR cs.LG cs.SI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Modern networked systems are constantly under threat from systemic attacks.\nThere has been a massive upsurge in the number of devices connected to a\nnetwork as well as the associated traffic volume. This has intensified the need\nto better understand all possible attack vectors during system design and\nimplementation. Further, it has increased the need to mine large data sets,\nanalyzing which has become a daunting task. It is critical to scale monitoring\ninfrastructures to match this need, but a difficult goal for the small and\nmedium organization. Hence, there is a need to propose novel approaches that\naddress the big data problem in security. Information Centrality (IC) labels\nnetwork nodes with better vantage points for detecting network-based anomalies\nas central nodes and uses them for detecting a category of attacks called\nsystemic attacks. The main idea is that since these central nodes already see a\nlot of information flowing through the network, they are in a good position to\ndetect anomalies before other nodes. This research first dives into the\nimportance of using graphs in understanding the topology and information flow.\nWe then introduce the usage of information centrality, a centrality-based\nindex, to reduce data collection in existing communication networks. Using\nIC-identified central nodes can accelerate outlier detection when armed with a\nsuitable anomaly detection technique. We also come up with a more efficient way\nto compute Information centrality for large networks. Finally, we demonstrate\nthat central nodes detect anomalous behavior much faster than other non-central\nnodes, given the anomalous behavior is systemic in nature.\n", "versions": [{"version": "v1", "created": "Sat, 27 Apr 2019 10:05:46 GMT"}, {"version": "v2", "created": "Fri, 12 Jun 2020 04:04:32 GMT"}], "update_date": "2020-06-15", "authors_parsed": [["Rastogi", "Nidhi", ""]]}, {"id": "1904.12165", "submitter": "Lluis Castrejon", "authors": "Lluis Castrejon, Nicolas Ballas, Aaron Courville", "title": "Improved Conditional VRNNs for Video Prediction", "comments": "Project page: https://sites.google.com/view/videovrnn", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Predicting future frames for a video sequence is a challenging generative\nmodeling task. Promising approaches include probabilistic latent variable\nmodels such as the Variational Auto-Encoder. While VAEs can handle uncertainty\nand model multiple possible future outcomes, they have a tendency to produce\nblurry predictions. In this work we argue that this is a sign of underfitting.\nTo address this issue, we propose to increase the expressiveness of the latent\ndistributions and to use higher capacity likelihood models. Our approach relies\non a hierarchy of latent variables, which defines a family of flexible prior\nand posterior distributions in order to better model the probability of future\nsequences. We validate our proposal through a series of ablation experiments\nand compare our approach to current state-of-the-art latent variable models.\nOur method performs favorably under several metrics in three different\ndatasets.\n", "versions": [{"version": "v1", "created": "Sat, 27 Apr 2019 15:07:12 GMT"}], "update_date": "2019-04-30", "authors_parsed": [["Castrejon", "Lluis", ""], ["Ballas", "Nicolas", ""], ["Courville", "Aaron", ""]]}, {"id": "1904.12171", "submitter": "Zhi-Hua Zhou", "authors": "Bo-Jian Hou and Lijun Zhang and Zhi-Hua Zhou", "title": "Prediction with Unpredictable Feature Evolution", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Learning with feature evolution studies the scenario where the features of\nthe data streams can evolve, i.e., old features vanish and new features emerge.\nIts goal is to keep the model always performing well even when the features\nhappen to evolve. To tackle this problem, canonical methods assume that the old\nfeatures will vanish simultaneously and the new features themselves will emerge\nsimultaneously as well. They also assume there is an overlapping period where\nold and new features both exist when the feature space starts to change.\nHowever, in reality, the feature evolution could be unpredictable, which means\nthe features can vanish or emerge arbitrarily, causing the overlapping period\nincomplete. In this paper, we propose a novel paradigm: Prediction with\nUnpredictable Feature Evolution (PUFE) where the feature evolution is\nunpredictable. To address this problem, we fill the incomplete overlapping\nperiod and formulate it as a new matrix completion problem. We give a\ntheoretical bound on the least number of observed entries to make the\noverlapping period intact. With this intact overlapping period, we leverage an\nensemble method to take the advantage of both the old and new feature spaces\nwithout manually deciding which base models should be incorporated. Theoretical\nand experimental results validate that our method can always follow the best\nbase models and thus realize the goal of learning with feature evolution.\n", "versions": [{"version": "v1", "created": "Sat, 27 Apr 2019 16:08:24 GMT"}, {"version": "v2", "created": "Sat, 12 Jun 2021 08:24:40 GMT"}], "update_date": "2021-06-15", "authors_parsed": [["Hou", "Bo-Jian", ""], ["Zhang", "Lijun", ""], ["Zhou", "Zhi-Hua", ""]]}, {"id": "1904.12191", "submitter": "Andrea Montanari", "authors": "Behrooz Ghorbani, Song Mei, Theodor Misiakiewicz, Andrea Montanari", "title": "Linearized two-layers neural networks in high dimension", "comments": "65 pages; 17 pdf figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST cs.LG stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the problem of learning an unknown function $f_{\\star}$ on the\n$d$-dimensional sphere with respect to the square loss, given i.i.d. samples\n$\\{(y_i,{\\boldsymbol x}_i)\\}_{i\\le n}$ where ${\\boldsymbol x}_i$ is a feature\nvector uniformly distributed on the sphere and $y_i=f_{\\star}({\\boldsymbol\nx}_i)+\\varepsilon_i$. We study two popular classes of models that can be\nregarded as linearizations of two-layers neural networks around a random\ninitialization: the random features model of Rahimi-Recht (RF); the neural\ntangent kernel model of Jacot-Gabriel-Hongler (NT). Both these approaches can\nalso be regarded as randomized approximations of kernel ridge regression (with\nrespect to different kernels), and enjoy universal approximation properties\nwhen the number of neurons $N$ diverges, for a fixed dimension $d$.\n  We consider two specific regimes: the approximation-limited regime, in which\n$n=\\infty$ while $d$ and $N$ are large but finite; and the sample size-limited\nregime in which $N=\\infty$ while $d$ and $n$ are large but finite. In the first\nregime we prove that if $d^{\\ell + \\delta} \\le N\\le d^{\\ell+1-\\delta}$ for\nsmall $\\delta > 0$, then \\RF\\, effectively fits a degree-$\\ell$ polynomial in\nthe raw features, and \\NT\\, fits a degree-$(\\ell+1)$ polynomial. In the second\nregime, both RF and NT reduce to kernel methods with rotationally invariant\nkernels. We prove that, if the number of samples is $d^{\\ell + \\delta} \\le n\n\\le d^{\\ell +1-\\delta}$, then kernel methods can fit at most a a degree-$\\ell$\npolynomial in the raw features. This lower bound is achieved by kernel ridge\nregression. Optimal prediction error is achieved for vanishing ridge\nregularization.\n", "versions": [{"version": "v1", "created": "Sat, 27 Apr 2019 18:42:02 GMT"}, {"version": "v2", "created": "Wed, 12 Jun 2019 18:19:55 GMT"}, {"version": "v3", "created": "Mon, 17 Feb 2020 01:27:56 GMT"}], "update_date": "2020-02-18", "authors_parsed": [["Ghorbani", "Behrooz", ""], ["Mei", "Song", ""], ["Misiakiewicz", "Theodor", ""], ["Montanari", "Andrea", ""]]}, {"id": "1904.12200", "submitter": "Anmol Sharma", "authors": "Anmol Sharma, Ghassan Hamarneh", "title": "Missing MRI Pulse Sequence Synthesis using Multi-Modal Generative\n  Adversarial Network", "comments": "Accepted for publication in IEEE Transactions on Medical Imaging", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.IV cs.AI cs.CV cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Magnetic resonance imaging (MRI) is being increasingly utilized to assess,\ndiagnose, and plan treatment for a variety of diseases. The ability to\nvisualize tissue in varied contrasts in the form of MR pulse sequences in a\nsingle scan provides valuable insights to physicians, as well as enabling\nautomated systems performing downstream analysis. However many issues like\nprohibitive scan time, image corruption, different acquisition protocols, or\nallergies to certain contrast materials may hinder the process of acquiring\nmultiple sequences for a patient. This poses challenges to both physicians and\nautomated systems since complementary information provided by the missing\nsequences is lost. In this paper, we propose a variant of generative\nadversarial network (GAN) capable of leveraging redundant information contained\nwithin multiple available sequences in order to generate one or more missing\nsequences for a patient scan. The proposed network is designed as a\nmulti-input, multi-output network which combines information from all the\navailable pulse sequences, implicitly infers which sequences are missing, and\nsynthesizes the missing ones in a single forward pass. We demonstrate and\nvalidate our method on two brain MRI datasets each with four sequences, and\nshow the applicability of the proposed method in simultaneously synthesizing\nall missing sequences in any possible scenario where either one, two, or three\nof the four sequences may be missing. We compare our approach with competing\nunimodal and multi-modal methods, and show that we outperform both\nquantitatively and qualitatively.\n", "versions": [{"version": "v1", "created": "Sat, 27 Apr 2019 20:15:15 GMT"}, {"version": "v2", "created": "Fri, 23 Aug 2019 19:08:43 GMT"}, {"version": "v3", "created": "Wed, 2 Oct 2019 00:20:13 GMT"}], "update_date": "2019-10-03", "authors_parsed": [["Sharma", "Anmol", ""], ["Hamarneh", "Ghassan", ""]]}, {"id": "1904.12206", "submitter": "Mohammad Taha Bahadori", "authors": "Mohammad Taha Bahadori, Zachary Chase Lipton", "title": "Temporal-Clustering Invariance in Irregular Healthcare Time Series", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG q-bio.QM stat.ML", "license": "http://creativecommons.org/licenses/by-sa/4.0/", "abstract": "  Electronic records contain sequences of events, some of which take place all\nat once in a single visit, and others that are dispersed over multiple visits,\neach with a different timestamp. We postulate that fine temporal detail, e.g.,\nwhether a series of blood tests are completed at once or in rapid succession\nshould not alter predictions based on this data. Motivated by this intuition,\nwe propose models for analyzing sequences of multivariate clinical time series\ndata that are invariant to this temporal clustering. We propose an efficient\ndata augmentation technique that exploits the postulated temporal-clustering\ninvariance to regularize deep neural networks optimized for several clinical\nprediction tasks. We introduce two techniques to temporally coarsen\n(downsample) irregular time series: (i) grouping the data points based on\nregularly-spaced timestamps; and (ii) clustering them, yielding\nirregularly-paced timestamps. Moreover, we propose a MultiResolution Ensemble\n(MRE) model, improving predictive accuracy by ensembling predictions based on\ninputs sequences transformed by different coarsening operators. Our experiments\nshow that MRE improves the mAP on the benchmark mortality prediction task from\n51.53% to 53.92%.\n", "versions": [{"version": "v1", "created": "Sat, 27 Apr 2019 20:30:26 GMT"}], "update_date": "2019-04-30", "authors_parsed": [["Bahadori", "Mohammad Taha", ""], ["Lipton", "Zachary Chase", ""]]}, {"id": "1904.12211", "submitter": "Mojtaba Nayyeri", "authors": "Mojtaba Nayyeri, Sahar Vahdati, Jens Lehmann, Hamed Shariat Yazdi", "title": "Soft Marginal TransE for Scholarly Knowledge Graph Completion", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.IR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Knowledge graphs (KGs), i.e. representation of information as a semantic\ngraph, provide a significant test bed for many tasks including question\nanswering, recommendation, and link prediction. Various amount of scholarly\nmetadata have been made vailable as knowledge graphs from the diversity of data\nproviders and agents. However, these high-quantities of data remain far from\nquality criteria in terms of completeness while growing at a rapid pace. Most\nof the attempts in completing such KGs are following traditional data\ndigitization, harvesting and collaborative curation approaches. Whereas,\nadvanced AI-related approaches such as embedding models - specifically designed\nfor such tasks - are usually evaluated for standard benchmarks such as Freebase\nand Wordnet. The tailored nature of such datasets prevents those approaches to\nshed the lights on more accurate discoveries. Application of such models on\ndomain-specific KGs takes advantage of enriched meta-data and provides accurate\nresults where the underlying domain can enormously benefit. In this work, the\nTransE embedding model is reconciled for a specific link prediction task on\nscholarly metadata. The results show a significant shift in the accuracy and\nperformance evaluation of the model on a dataset with scholarly metadata. The\nnewly proposed version of TransE obtains 99.9% for link prediction task while\noriginal TransE gets 95%. In terms of accuracy and Hit@10, TransE outperforms\nother embedding models such as ComplEx, TransH and TransR experimented over\nscholarly knowledge graphs\n", "versions": [{"version": "v1", "created": "Sat, 27 Apr 2019 20:40:03 GMT"}], "update_date": "2019-04-30", "authors_parsed": [["Nayyeri", "Mojtaba", ""], ["Vahdati", "Sahar", ""], ["Lehmann", "Jens", ""], ["Yazdi", "Hamed Shariat", ""]]}, {"id": "1904.12218", "submitter": "Giannis Nikolentzos", "authors": "Giannis Nikolentzos and Giannis Siglidis and Michalis Vazirgiannis", "title": "Graph Kernels: A Survey", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Graph kernels have attracted a lot of attention during the last decade, and\nhave evolved into a rapidly developing branch of learning on structured data.\nDuring the past 20 years, the considerable research activity that occurred in\nthe field resulted in the development of dozens of graph kernels, each focusing\non specific structural properties of graphs. Graph kernels have proven\nsuccessful in a wide range of domains, ranging from social networks to\nbioinformatics. The goal of this survey is to provide a unifying view of the\nliterature on graph kernels. In particular, we present a comprehensive overview\nof a wide range of graph kernels. Furthermore, we perform an experimental\nevaluation of several of those kernels on publicly available datasets, and\nprovide a comparative study. Finally, we discuss key applications of graph\nkernels, and outline some challenges that remain to be addressed.\n", "versions": [{"version": "v1", "created": "Sat, 27 Apr 2019 22:20:40 GMT"}], "update_date": "2019-04-30", "authors_parsed": [["Nikolentzos", "Giannis", ""], ["Siglidis", "Giannis", ""], ["Vazirgiannis", "Michalis", ""]]}, {"id": "1904.12220", "submitter": "Sachin Vernekar", "authors": "Sachin Vernekar, Ashish Gaurav, Taylor Denouden, Buu Phan, Vahdat\n  Abdelzad, Rick Salay, Krzysztof Czarnecki", "title": "Analysis of Confident-Classifiers for Out-of-distribution Detection", "comments": "SafeML 2019 ICLR workshop paper", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Discriminatively trained neural classifiers can be trusted, only when the\ninput data comes from the training distribution (in-distribution). Therefore,\ndetecting out-of-distribution (OOD) samples is very important to avoid\nclassification errors. In the context of OOD detection for image\nclassification, one of the recent approaches proposes training a classifier\ncalled \"confident-classifier\" by minimizing the standard cross-entropy loss on\nin-distribution samples and minimizing the KL divergence between the predictive\ndistribution of OOD samples in the low-density regions of in-distribution and\nthe uniform distribution (maximizing the entropy of the outputs). Thus, the\nsamples could be detected as OOD if they have low confidence or high entropy.\nIn this paper, we analyze this setting both theoretically and experimentally.\nWe conclude that the resulting confident-classifier still yields arbitrarily\nhigh confidence for OOD samples far away from the in-distribution. We instead\nsuggest training a classifier by adding an explicit \"reject\" class for OOD\nsamples.\n", "versions": [{"version": "v1", "created": "Sat, 27 Apr 2019 22:33:34 GMT"}], "update_date": "2019-04-30", "authors_parsed": [["Vernekar", "Sachin", ""], ["Gaurav", "Ashish", ""], ["Denouden", "Taylor", ""], ["Phan", "Buu", ""], ["Abdelzad", "Vahdat", ""], ["Salay", "Rick", ""], ["Czarnecki", "Krzysztof", ""]]}, {"id": "1904.12222", "submitter": "Hema Venkata Krishna Giri Narra", "authors": "Krishna Giri Narra, Zhifeng Lin, Ganesh Ananthanarayanan, Salman\n  Avestimehr, Murali Annavaram", "title": "Collage Inference: Using Coded Redundancy for Low Variance Distributed\n  Image Classification", "comments": "10 pages, Under submission", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.DC cs.IT cs.LG math.IT stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  MLaaS (ML-as-a-Service) offerings by cloud computing platforms are becoming\nincreasingly popular. Hosting pre-trained machine learning models in the cloud\nenables elastic scalability as the demand grows. But providing low latency and\nreducing the latency variance is a key requirement. Variance is harder to\ncontrol in a cloud deployment due to uncertainties in resource allocations\nacross many virtual instances. We propose the collage inference technique which\nuses a novel convolutional neural network model, collage-cnn, to provide\nlow-cost redundancy. A collage-cnn model takes a collage image formed by\ncombining multiple images and performs multi-image classification in one shot,\nalbeit at slightly lower accuracy. We augment a collection of traditional\nsingle image classifier models with a single collage-cnn classifier which acts\nas their low-cost redundant backup. Collage-cnn provides backup classification\nresults if any single image classification requests experience slowdown.\nDeploying the collage-cnn models in the cloud, we demonstrate that the 99th\npercentile tail latency of inference can be reduced by 1.2x to 2x compared to\nreplication based approaches while providing high accuracy. Variation in\ninference latency can be reduced by 1.8x to 15x.\n", "versions": [{"version": "v1", "created": "Sat, 27 Apr 2019 22:56:10 GMT"}, {"version": "v2", "created": "Tue, 10 Sep 2019 17:25:42 GMT"}], "update_date": "2019-09-11", "authors_parsed": [["Narra", "Krishna Giri", ""], ["Lin", "Zhifeng", ""], ["Ananthanarayanan", "Ganesh", ""], ["Avestimehr", "Salman", ""], ["Annavaram", "Murali", ""]]}, {"id": "1904.12225", "submitter": "Oh-Hyun Kwon", "authors": "Oh-Hyun Kwon and Kwan-Liu Ma", "title": "A Deep Generative Model for Graph Layout", "comments": "To appear in IEEE Transactions on Visualization and Computer\n  Graphics. In Proc. IEEE VIS 2019 (InfoVis)", "journal-ref": null, "doi": "10.1109/TVCG.2019.2934396", "report-no": null, "categories": "cs.SI cs.GR cs.HC cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Different layouts can characterize different aspects of the same graph.\nFinding a \"good\" layout of a graph is thus an important task for graph\nvisualization. In practice, users often visualize a graph in multiple layouts\nby using different methods and varying parameter settings until they find a\nlayout that best suits the purpose of the visualization. However, this\ntrial-and-error process is often haphazard and time-consuming. To provide users\nwith an intuitive way to navigate the layout design space, we present a\ntechnique to systematically visualize a graph in diverse layouts using deep\ngenerative models. We design an encoder-decoder architecture to learn a model\nfrom a collection of example layouts, where the encoder represents training\nexamples in a latent space and the decoder produces layouts from the latent\nspace. In particular, we train the model to construct a two-dimensional latent\nspace for users to easily explore and generate various layouts. We demonstrate\nour approach through quantitative and qualitative evaluations of the generated\nlayouts. The results of our evaluations show that our model is capable of\nlearning and generalizing abstract concepts of graph layouts, not just\nmemorizing the training examples. In summary, this paper presents a\nfundamentally new approach to graph visualization where a machine learning\nmodel learns to visualize a graph from examples without manually-defined\nheuristics.\n", "versions": [{"version": "v1", "created": "Sat, 27 Apr 2019 23:19:49 GMT"}, {"version": "v2", "created": "Sat, 13 Jul 2019 23:44:11 GMT"}, {"version": "v3", "created": "Sat, 27 Jul 2019 21:45:55 GMT"}, {"version": "v4", "created": "Tue, 30 Jul 2019 02:57:51 GMT"}, {"version": "v5", "created": "Thu, 29 Aug 2019 00:33:59 GMT"}, {"version": "v6", "created": "Mon, 2 Sep 2019 07:04:25 GMT"}, {"version": "v7", "created": "Tue, 15 Oct 2019 17:22:25 GMT"}], "update_date": "2019-10-16", "authors_parsed": [["Kwon", "Oh-Hyun", ""], ["Ma", "Kwan-Liu", ""]]}, {"id": "1904.12232", "submitter": "Hanchen Xu", "authors": "Hanchen Xu and Xiao Li and Xiangyu Zhang and Junbo Zhang", "title": "Arbitrage of Energy Storage in Electricity Markets with Deep\n  Reinforcement Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG math.OC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this letter, we address the problem of controlling energy storage systems\n(ESSs) for arbitrage in real-time electricity markets under price uncertainty.\nWe first formulate this problem as a Markov decision process, and then develop\na deep reinforcement learning based algorithm to learn a stochastic control\npolicy that maps a set of available information processed by a recurrent neural\nnetwork to ESSs' charging/discharging actions. Finally, we verify the\neffectiveness of our algorithm using real-time electricity prices from PJM.\n", "versions": [{"version": "v1", "created": "Sun, 28 Apr 2019 00:08:07 GMT"}, {"version": "v2", "created": "Sat, 4 May 2019 05:18:04 GMT"}], "update_date": "2019-05-07", "authors_parsed": [["Xu", "Hanchen", ""], ["Li", "Xiao", ""], ["Zhang", "Xiangyu", ""], ["Zhang", "Junbo", ""]]}, {"id": "1904.12233", "submitter": "Sebastien Bubeck", "authors": "S\\'ebastien Bubeck, Yuanzhi Li, Yuval Peres, Mark Sellke", "title": "Non-Stochastic Multi-Player Multi-Armed Bandits: Optimal Rate With\n  Collision Information, Sublinear Without", "comments": "27 pages, v2 adds a pseudorandom generator construction to remove the\n  shared randomness assumption in the $\\sqrt{T}$-regret result (Section 3.9)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.MA stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the non-stochastic version of the (cooperative) multi-player\nmulti-armed bandit problem. The model assumes no communication at all between\nthe players, and furthermore when two (or more) players select the same action\nthis results in a maximal loss. We prove the first $\\sqrt{T}$-type regret\nguarantee for this problem, under the feedback model where collisions are\nannounced to the colliding players. Such a bound was not known even for the\nsimpler stochastic version. We also prove the first sublinear guarantee for the\nfeedback model where collision information is not available, namely\n$T^{1-\\frac{1}{2m}}$ where $m$ is the number of players.\n", "versions": [{"version": "v1", "created": "Sun, 28 Apr 2019 00:21:04 GMT"}, {"version": "v2", "created": "Wed, 1 May 2019 19:05:21 GMT"}], "update_date": "2019-05-03", "authors_parsed": [["Bubeck", "S\u00e9bastien", ""], ["Li", "Yuanzhi", ""], ["Peres", "Yuval", ""], ["Sellke", "Mark", ""]]}, {"id": "1904.12234", "submitter": "Francisco Avila-Camacho J", "authors": "Jose de Jesus Rubio, Jose Alberto Hernandez-Aguilar, Francisco Jacob\n  Avila-Camacho, Juan Manuel Stein-Carrillo, Adolfo Melendez-Ramirez", "title": "Sistema Sensor para el Monitoreo Ambiental Basado en Redes Neuronales", "comments": "11 pages, in Spanish", "journal-ref": "Ingenier\\'ia Investigaci\\'on y Tecnolog\\'ia,volumen XVII (n\\'umero\n  2), abril-junio 2016: 211-222", "doi": "10.1016/J.RIIT.2016.06.006", "report-no": null, "categories": "cs.LG cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In the tasks of environmental monitoring is of great importance to have\ncompact and portable systems able to identify environmental contaminants that\nfacilitate tasks related to waste management and environmental restoration. In\nthis paper, a prototype sensor is described to identify contaminants in the\nenvironment. This prototype is made with an array of tin oxide SnO2 gas sensors\nused to identify chemical vapors, a step of data acquisition implemented with\nARM (Advanced RISC Machine) low-cost platform (Arduino) and a neural network\nable to identify environmental contaminants automatically. The neural network\nis used to identify the composition of contaminant census. In the computer\nsystem, the heavy computational load is presented only in the training process,\nonce the neural network has been trained, the operation is to spread the data\nacross the network with a much lighter computational load, which consists\nmainly of a vector-matrix multiplication and a search table that holds the\nactivation function to quickly identify unknown samples.\n", "versions": [{"version": "v1", "created": "Sun, 28 Apr 2019 00:23:11 GMT"}], "update_date": "2019-04-30", "authors_parsed": [["Rubio", "Jose de Jesus", ""], ["Hernandez-Aguilar", "Jose Alberto", ""], ["Avila-Camacho", "Francisco Jacob", ""], ["Stein-Carrillo", "Juan Manuel", ""], ["Melendez-Ramirez", "Adolfo", ""]]}, {"id": "1904.12255", "submitter": "Suhit Kodgule", "authors": "Suhit Kodgule, Alberto Candela and David Wettergreen", "title": "Non-myopic Planetary Exploration Combining In Situ and Remote\n  Measurements", "comments": "Preprint. Under review for IROS 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.AI cs.LG", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Remote sensing can provide crucial information for planetary rovers. However,\nthey must validate these orbital observations with in situ measurements.\nTypically, this involves validating hyperspectral data using a spectrometer\non-board the field robot. In order to achieve this, the robot must visit\nsampling locations that jointly improve a model of the environment while\nsatisfying sampling constraints. However, current planners follow sub-optimal\ngreedy strategies that are not scalable to larger regions. We demonstrate how\nthe problem can be effectively defined in an MDP framework and propose a\nplanning algorithm based on Monte Carlo Tree Search, which is devoid of the\ncommon drawbacks of existing planners and also provides superior performance.\nWe evaluate our approach using hyperspectral imagery of a well-studied geologic\nsite in Cuprite, Nevada.\n", "versions": [{"version": "v1", "created": "Sun, 28 Apr 2019 03:59:01 GMT"}], "update_date": "2019-04-30", "authors_parsed": [["Kodgule", "Suhit", ""], ["Candela", "Alberto", ""], ["Wettergreen", "David", ""]]}, {"id": "1904.12286", "submitter": "Koby Bibas", "authors": "Koby Bibas, Yaniv Fogel and Meir Feder", "title": "Deep pNML: Predictive Normalized Maximum Likelihood for Deep Neural\n  Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The Predictive Normalized Maximum Likelihood (pNML) scheme has been recently\nsuggested for universal learning in the individual setting, where both the\ntraining and test samples are individual data. The goal of universal learning\nis to compete with a ``genie'' or reference learner that knows the data values,\nbut is restricted to use a learner from a given model class. The pNML minimizes\nthe associated regret for any possible value of the unknown label. Furthermore,\nits min-max regret can serve as a pointwise measure of learnability for the\nspecific training and data sample. In this work we examine the pNML and its\nassociated learnability measure for the Deep Neural Network (DNN) model class.\nAs shown, the pNML outperforms the commonly used Empirical Risk Minimization\n(ERM) approach and provides robustness against adversarial attacks. Together\nwith its learnability measure it can detect out of distribution test examples,\nbe tolerant to noisy labels and serve as a confidence measure for the ERM.\nFinally, we extend the pNML to a ``twice universal'' solution, that provides\nuniversality for model class selection and generates a learner competing with\nthe best one from all model classes.\n", "versions": [{"version": "v1", "created": "Sun, 28 Apr 2019 09:35:50 GMT"}, {"version": "v2", "created": "Wed, 8 Jan 2020 12:46:19 GMT"}], "update_date": "2020-01-09", "authors_parsed": [["Bibas", "Koby", ""], ["Fogel", "Yaniv", ""], ["Feder", "Meir", ""]]}, {"id": "1904.12294", "submitter": "Kai Wang", "authors": "Kai Wang and Fuyuan Shi and Wenqi Wang and Yibing Nan and Shiguo Lian", "title": "Synthetic Data Generation and Adaption for Object Detection in Smart\n  Vending Machines", "comments": "9 pages, 9 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.GR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper presents an improved scheme for the generation and adaption of\nsynthetic images for the training of deep Convolutional Neural Networks(CNNs)\nto perform the object detection task in smart vending machines. While\ngenerating synthetic data has proved to be effective for complementing the\ntraining data in supervised learning methods, challenges still exist for\ngenerating virtual images which are similar to those of the complex real scenes\nand minimizing redundant training data. To solve these problems, we consider\nthe simulation of cluttered objects placed in a virtual scene and the\nwide-angle camera with distortions used to capture the whole scene in the data\ngeneration process, and post-processed the generated images with a\nelaborately-designed generative network to make them more similar to the real\nimages. Various experiments have been conducted to prove the efficiency of\nusing the generated virtual images to enhance the detection precision on\nexisting datasets with limited real training data and the generalization\nability of applying the trained network to datasets collected in new\nenvironment.\n", "versions": [{"version": "v1", "created": "Sun, 28 Apr 2019 10:16:04 GMT"}], "update_date": "2019-04-30", "authors_parsed": [["Wang", "Kai", ""], ["Shi", "Fuyuan", ""], ["Wang", "Wenqi", ""], ["Nan", "Yibing", ""], ["Lian", "Shiguo", ""]]}, {"id": "1904.12303", "submitter": "Ke Han", "authors": "Jun Song, Ke Han", "title": "Deep-MAPS: Machine Learning based Mobile Air Pollution Sensing", "comments": "10 pages, 4 figures, 1 table", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Mobile and ubiquitous sensing of urban air quality has received increased\nattention as an economically and operationally viable means to survey\natmospheric environment with high spatial-temporal resolution. This paper\nproposes a machine learning based mobile air pollution sensing framework,\ncalled Deep-MAPS, and demonstrates its scientific and financial values in the\nfollowing aspects. (1) Based on a network of fixed and mobile air quality\nsensors, we perform spatial inference of PM2.5 concentrations in Beijing (3,025\nkm2, 19 Jun-16 Jul 2018) for a spatial-temporal resolution of 1km-by-1km and 1\nhour, with over 85% accuracy. (2) We leverage urban big data to generate\ninsights regarding the potential cause of pollution, which facilitates\nevidence-based sustainable urban management. (3) To achieve such\nspatial-temporal coverage and accuracy, Deep-MAPS can save up to 90% hardware\ninvestment, compared with ubiquitous sensing that relies primarily on fixed\nsensors.\n", "versions": [{"version": "v1", "created": "Sun, 28 Apr 2019 11:07:24 GMT"}, {"version": "v2", "created": "Sun, 1 Mar 2020 08:26:21 GMT"}], "update_date": "2020-03-03", "authors_parsed": [["Song", "Jun", ""], ["Han", "Ke", ""]]}, {"id": "1904.12320", "submitter": "Laurent Bou\\'e", "authors": "Laurent Bou\\'e", "title": "Real numbers, data science and chaos: How to fit any dataset with a\n  single parameter", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.DM cs.GL cs.IR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We show how any dataset of any modality (time-series, images, sound...) can\nbe approximated by a well-behaved (continuous, differentiable...) scalar\nfunction with a single real-valued parameter. Building upon elementary concepts\nfrom chaos theory, we adopt a pedagogical approach demonstrating how to adjust\nthis parameter in order to achieve arbitrary precision fit to all samples of\nthe data. Targeting an audience of data scientists with a taste for the curious\nand unusual, the results presented here expand on previous similar observations\nregarding expressiveness power and generalization of machine learning models.\n", "versions": [{"version": "v1", "created": "Sun, 28 Apr 2019 13:29:49 GMT"}], "update_date": "2019-04-30", "authors_parsed": [["Bou\u00e9", "Laurent", ""]]}, {"id": "1904.12331", "submitter": "Pritam Anand South Asian University", "authors": "Pritam Anand, Reshma Rastogi (nee Khemchandani), Suresh Chandra", "title": "Support Vector Regression via a Combined Reward Cum Penalty Loss\n  Function", "comments": "For any assistance , reader can contact on email with Pritam Anand.\n  Email id - ltpritamanand@gmail.com. The valuable opinion/comments on the work\n  are welcomed. Looking for collaboration especially for speeding up the\n  solution of optimization problems", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we introduce a novel combined reward cum penalty loss function\nto handle the regression problem. The proposed combined reward cum penalty loss\nfunction penalizes the data points which lie outside the $\\epsilon$-tube of the\nregressor and also assigns reward for the data points which lie inside of the\n$\\epsilon$-tube of the regressor. The combined reward cum penalty loss function\nbased regression (RP-$\\epsilon$-SVR) model has several interesting properties\nwhich are investigated in this paper and are also supported with the\nexperimental results.\n", "versions": [{"version": "v1", "created": "Sun, 28 Apr 2019 14:50:19 GMT"}, {"version": "v2", "created": "Sun, 3 May 2020 17:34:24 GMT"}], "update_date": "2020-05-05", "authors_parsed": [["Anand", "Pritam", "", "nee Khemchandani"], ["Rastogi", "Reshma", "", "nee Khemchandani"], ["Chandra", "Suresh", ""]]}, {"id": "1904.12335", "submitter": "Cyrille W. Combettes", "authors": "Cyrille W. Combettes and Sebastian Pokutta", "title": "Blended Matching Pursuit", "comments": "30 pages and 15 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.OC cs.CC cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Matching pursuit algorithms are an important class of algorithms in signal\nprocessing and machine learning. We present a blended matching pursuit\nalgorithm, combining coordinate descent-like steps with stronger gradient\ndescent steps, for minimizing a smooth convex function over a linear space\nspanned by a set of atoms. We derive sublinear to linear convergence rates\naccording to the smoothness and sharpness orders of the function and\ndemonstrate computational superiority of our approach. In particular, we derive\nlinear rates for a wide class of non-strongly convex functions, and we\ndemonstrate in experiments that our algorithm enjoys very fast rates of\nconvergence and wall-clock speed while maintaining a sparsity of iterates very\ncomparable to that of the (much slower) orthogonal matching pursuit.\n", "versions": [{"version": "v1", "created": "Sun, 28 Apr 2019 15:28:13 GMT"}, {"version": "v2", "created": "Mon, 10 Jun 2019 15:46:33 GMT"}, {"version": "v3", "created": "Tue, 19 Nov 2019 20:33:13 GMT"}], "update_date": "2019-11-21", "authors_parsed": [["Combettes", "Cyrille W.", ""], ["Pokutta", "Sebastian", ""]]}, {"id": "1904.12336", "submitter": "Zinan Liu", "authors": "Zinan Liu, Kai Ploeger, Svenja Stark, Elmar Rueckert and Jan Peters", "title": "Learning walk and trot from the same objective using different types of\n  exploration", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.RO stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In quadruped gait learning, policy search methods that scale high dimensional\ncontinuous action spaces are commonly used. In most approaches, it is necessary\nto introduce prior knowledge on the gaits to limit the highly non-convex search\nspace of the policies. In this work, we propose a new approach to encode the\nsymmetry properties of the desired gaits, on the initial covariance of the\nGaussian search distribution, allowing for strategic exploration. Using\nepisode-based likelihood ratio policy gradient and relative entropy policy\nsearch, we learned the gaits walk and trot on a simulated quadruped. Comparing\nthese gaits to random gaits learned by initialized diagonal covariance matrix,\nwe show that the performance can be significantly enhanced.\n", "versions": [{"version": "v1", "created": "Sun, 28 Apr 2019 15:44:24 GMT"}], "update_date": "2019-04-30", "authors_parsed": [["Liu", "Zinan", ""], ["Ploeger", "Kai", ""], ["Stark", "Svenja", ""], ["Rueckert", "Elmar", ""], ["Peters", "Jan", ""]]}, {"id": "1904.12347", "submitter": "Xingchao Peng", "authors": "Xingchao Peng, Zijun Huang, Ximeng Sun, Kate Saenko", "title": "Domain Agnostic Learning with Disentangled Representations", "comments": null, "journal-ref": "Proceedings of the 36th International Conference on Machine\n  Learning, Long Beach, California, PMLR 97, 2019", "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Unsupervised model transfer has the potential to greatly improve the\ngeneralizability of deep models to novel domains. Yet the current literature\nassumes that the separation of target data into distinct domains is known as a\npriori. In this paper, we propose the task of Domain-Agnostic Learning (DAL):\nHow to transfer knowledge from a labeled source domain to unlabeled data from\narbitrary target domains? To tackle this problem, we devise a novel Deep\nAdversarial Disentangled Autoencoder (DADA) capable of disentangling\ndomain-specific features from class identity. We demonstrate experimentally\nthat when the target domain labels are unknown, DADA leads to state-of-the-art\nperformance on several image classification datasets.\n", "versions": [{"version": "v1", "created": "Sun, 28 Apr 2019 17:07:10 GMT"}], "update_date": "2019-04-30", "authors_parsed": [["Peng", "Xingchao", ""], ["Huang", "Zijun", ""], ["Sun", "Ximeng", ""], ["Saenko", "Kate", ""]]}, {"id": "1904.12354", "submitter": "Aydin Teyhouee", "authors": "Aydin Teyhouee and Nathaniel D. Osgood", "title": "Cough Detection Using Hidden Markov Models", "comments": "SBP-BRiMS 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SD cs.LG eess.AS stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Respiratory infections and chronic respiratory diseases impose a heavy health\nburden worldwide. Coughing is one of the most common symptoms of many such\ninfections, and can be indicative of flare-ups of chronic respiratory diseases.\nWhether at a clinical or public health level, the capacity to identify bouts of\ncoughing can aid understanding of population and individual health status.\nDeveloping health monitoring models in the context of respiratory diseases and\nalso seasonal diseases with symptoms such as cough has the potential to improve\nquality of life, help clinicians and public health authorities with their\ndecisions and decrease the cost of health services. In this paper, we\ninvestigated the ability to which a simple machine learning approach in the\nform of Hidden Markov Models (HMMs) could be used to classify different states\nof coughing using univariate (with a single energy band as the input feature)\nand multivariate (with a multiple energy band as the input features) binned\ntime series using both of cough data. We further used the model to distinguish\ncough events from other events and environmental noise. Our Hidden Markov\nalgorithm achieved 92% AUR (Area Under Receiver Operating Characteristic Curve)\nin classifying coughing events in noisy environments. Moreover, comparison of\nunivariate with multivariate HMMs suggest a high accuracy of multivariate HMMs\nfor cough event classifications.\n", "versions": [{"version": "v1", "created": "Sun, 28 Apr 2019 17:47:31 GMT"}], "update_date": "2019-04-30", "authors_parsed": [["Teyhouee", "Aydin", ""], ["Osgood", "Nathaniel D.", ""]]}, {"id": "1904.12355", "submitter": "Shunhao Oh", "authors": "Shunhao Oh, Anuja Meetoo Appavoo, Seth Gilbert", "title": "Periodic Bandits and Wireless Network Selection", "comments": "46th International Colloquium on Automata, Languages and Programming\n  (ICALP 2019), Track C", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Bandit-style algorithms have been studied extensively in stochastic and\nadversarial settings. Such algorithms have been shown to be useful in\nmultiplayer settings, e.g. to solve the wireless network selection problem,\nwhich can be formulated as an adversarial bandit problem. A leading bandit\nalgorithm for the adversarial setting is EXP3. However, network behavior is\noften repetitive, where user density and network behavior follow regular\npatterns. Bandit algorithms, like EXP3, fail to provide good guarantees for\nperiodic behaviors. A major reason is that these algorithms compete against\nfixed-action policies, which is ineffective in a periodic setting.\n  In this paper, we define a periodic bandit setting, and periodic regret as a\nbetter performance measure for this type of setting. Instead of comparing an\nalgorithm's performance to fixed-action policies, we aim to be competitive with\npolicies that play arms under some set of possible periodic patterns $F$ (for\nexample, all possible periodic functions with periods $1,2,\\cdots,P$). We\npropose Periodic EXP4, a computationally efficient variant of the EXP4\nalgorithm for periodic settings. With $K$ arms, $T$ time steps, and where each\nperiodic pattern in $F$ is of length at most $P$, we show that the periodic\nregret obtained by Periodic EXP4 is at most $O\\big(\\sqrt{PKT \\log K + KT \\log\n|F|}\\big)$. We also prove a lower bound of $\\Omega\\big(\\sqrt{PKT + KT\n\\frac{\\log |F|}{\\log K}} \\big)$ for the periodic setting, showing that this is\noptimal within log-factors. As an example, we focus on the wireless network\nselection problem. Through simulation, we show that Periodic EXP4 learns the\nperiodic pattern over time, adapts to changes in a dynamic environment, and far\noutperforms EXP3.\n", "versions": [{"version": "v1", "created": "Sun, 28 Apr 2019 17:51:17 GMT"}], "update_date": "2019-04-30", "authors_parsed": [["Oh", "Shunhao", ""], ["Appavoo", "Anuja Meetoo", ""], ["Gilbert", "Seth", ""]]}, {"id": "1904.12360", "submitter": "Qing Zhou", "authors": "Qiaoling Ye, Arash A. Amini, and Qing Zhou", "title": "Optimizing regularized Cholesky score for order-based learning of\n  Bayesian networks", "comments": "15 pages, 7 figures, 5 tables", "journal-ref": "IEEE Transactions on Pattern Analysis and Machine Intelligence\n  (2020)", "doi": "10.1109/TPAMI.2020.2990820", "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Bayesian networks are a class of popular graphical models that encode causal\nand conditional independence relations among variables by directed acyclic\ngraphs (DAGs). We propose a novel structure learning method, annealing on\nregularized Cholesky score (ARCS), to search over topological sorts, or\npermutations of nodes, for a high-scoring Bayesian network. Our scoring\nfunction is derived from regularizing Gaussian DAG likelihood, and its\noptimization gives an alternative formulation of the sparse Cholesky\nfactorization problem from a statistical viewpoint, which is of independent\ninterest. We combine global simulated annealing over permutations with a fast\nproximal gradient algorithm, operating on triangular matrices of edge\ncoefficients, to compute the score of any permutation. Combined, the two\napproaches allow us to quickly and effectively search over the space of DAGs\nwithout the need to verify the acyclicity constraint or to enumerate possible\nparent sets given a candidate topological sort. The annealing aspect of the\noptimization is able to consistently improve the accuracy of DAGs learned by\nlocal search algorithms. In addition, we develop several techniques to\nfacilitate the structure learning, including pre-annealing data-driven tuning\nparameter selection and post-annealing constraint-based structure refinement.\nThrough extensive numerical comparisons, we show that ARCS achieves substantial\nimprovements over existing methods, demonstrating its great potential to learn\nBayesian networks from both observational and experimental data.\n", "versions": [{"version": "v1", "created": "Sun, 28 Apr 2019 18:24:15 GMT"}], "update_date": "2020-05-04", "authors_parsed": [["Ye", "Qiaoling", ""], ["Amini", "Arash A.", ""], ["Zhou", "Qing", ""]]}, {"id": "1904.12368", "submitter": "Ting-Wu Chin", "authors": "Ting-Wu Chin and Ruizhou Ding and Cha Zhang and Diana Marculescu", "title": "Towards Efficient Model Compression via Learned Global Ranking", "comments": "CVPR 2020 Oral", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Pruning convolutional filters has demonstrated its effectiveness in\ncompressing ConvNets. Prior art in filter pruning requires users to specify a\ntarget model complexity (e.g., model size or FLOP count) for the resulting\narchitecture. However, determining a target model complexity can be difficult\nfor optimizing various embodied AI applications such as autonomous robots,\ndrones, and user-facing applications. First, both the accuracy and the speed of\nConvNets can affect the performance of the application. Second, the performance\nof the application can be hard to assess without evaluating ConvNets during\ninference. As a consequence, finding a sweet-spot between the accuracy and\nspeed via filter pruning, which needs to be done in a trial-and-error fashion,\ncan be time-consuming. This work takes a first step toward making this process\nmore efficient by altering the goal of model compression to producing a set of\nConvNets with various accuracy and latency trade-offs instead of producing one\nConvNet targeting some pre-defined latency constraint. To this end, we propose\nto learn a global ranking of the filters across different layers of the\nConvNet, which is used to obtain a set of ConvNet architectures that have\ndifferent accuracy/latency trade-offs by pruning the bottom-ranked filters. Our\nproposed algorithm, LeGR, is shown to be 2x to 3x faster than prior work while\nhaving comparable or better performance when targeting seven pruned ResNet-56\nwith different accuracy/FLOPs profiles on the CIFAR-100 dataset. Additionally,\nwe have evaluated LeGR on ImageNet and Bird-200 with ResNet-50 and MobileNetV2\nto demonstrate its effectiveness. Code available at\nhttps://github.com/cmu-enyac/LeGR.\n", "versions": [{"version": "v1", "created": "Sun, 28 Apr 2019 18:51:26 GMT"}, {"version": "v2", "created": "Sat, 14 Mar 2020 05:53:58 GMT"}], "update_date": "2020-03-17", "authors_parsed": [["Chin", "Ting-Wu", ""], ["Ding", "Ruizhou", ""], ["Zhang", "Cha", ""], ["Marculescu", "Diana", ""]]}, {"id": "1904.12369", "submitter": "Elynn Chen", "authors": "Krishna Balasubramanian, Elynn Y. Chen, Jianqing Fan, Xiang Wu", "title": "Low-Rank Principal Eigenmatrix Analysis", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG stat.ME", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Sparse PCA is a widely used technique for high-dimensional data analysis. In\nthis paper, we propose a new method called low-rank principal eigenmatrix\nanalysis. Different from sparse PCA, the dominant eigenvectors are allowed to\nbe dense but are assumed to have a low-rank structure when matricized\nappropriately. Such a structure arises naturally in several practical cases:\nIndeed the top eigenvector of a circulant matrix, when matricized appropriately\nis a rank-1 matrix. We propose a matricized rank-truncated power method that\ncould be efficiently implemented and establish its computational and\nstatistical properties. Extensive experiments on several synthetic data sets\ndemonstrate the competitive empirical performance of our method.\n", "versions": [{"version": "v1", "created": "Sun, 28 Apr 2019 18:51:39 GMT"}], "update_date": "2019-04-30", "authors_parsed": [["Balasubramanian", "Krishna", ""], ["Chen", "Elynn Y.", ""], ["Fan", "Jianqing", ""], ["Wu", "Xiang", ""]]}, {"id": "1904.12374", "submitter": "Masha Itkina", "authors": "Masha Itkina, Katherine Driggs-Campbell, and Mykel J. Kochenderfer", "title": "Dynamic Environment Prediction in Urban Scenes using Recurrent\n  Representation Learning", "comments": "8 pages, updated final draft, accepted into Intelligent\n  Transportation Systems Conference (ITSC) 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG cs.RO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A key challenge for autonomous driving is safe trajectory planning in\ncluttered, urban environments with dynamic obstacles, such as pedestrians,\nbicyclists, and other vehicles. A reliable prediction of the future\nenvironment, including the behavior of dynamic agents, would allow planning\nalgorithms to proactively generate a trajectory in response to a rapidly\nchanging environment. We present a novel framework that predicts the future\noccupancy state of the local environment surrounding an autonomous agent by\nlearning a motion model from occupancy grid data using a neural network. We\ntake advantage of the temporal structure of the grid data by utilizing a\nconvolutional long-short term memory network in the form of the PredNet\narchitecture. This method is validated on the KITTI dataset and demonstrates\nhigher accuracy and better predictive power than baseline methods.\n", "versions": [{"version": "v1", "created": "Sun, 28 Apr 2019 19:41:59 GMT"}, {"version": "v2", "created": "Sun, 18 Aug 2019 20:24:45 GMT"}], "update_date": "2019-08-20", "authors_parsed": [["Itkina", "Masha", ""], ["Driggs-Campbell", "Katherine", ""], ["Kochenderfer", "Mykel J.", ""]]}, {"id": "1904.12380", "submitter": "Tomasz Patejko", "authors": "Jacek Czaja (1), Michal Gallus (1), Tomasz Patejko (1), Jian Tang (2)\n  ((1) Intel Corporation, (2) Baidu)", "title": "Softmax Optimizations for Intel Xeon Processor-based Platforms", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.MS cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Softmax is popular normalization method used in machine learning. Deep\nlearning solutions like Transformer or BERT use the softmax function\nintensively, so it is worthwhile to optimize its performance. This article\npresents our methodology of optimization and its results applied to softmax. By\npresenting this methodology, we hope to increase an interest in deep learning\noptimizations for CPUs. We believe that the optimization process presented here\ncould be transferred to other deep learning frameworks such as TensorFlow or\nPyTorch.\n", "versions": [{"version": "v1", "created": "Sun, 28 Apr 2019 20:19:22 GMT"}, {"version": "v2", "created": "Mon, 27 May 2019 08:33:00 GMT"}], "update_date": "2019-05-28", "authors_parsed": [["Czaja", "Jacek", "", "Intel Corporation"], ["Gallus", "Michal", "", "Intel Corporation"], ["Patejko", "Tomasz", "", "Intel Corporation"], ["Tang", "Jian", "", "Baidu"]]}, {"id": "1904.12383", "submitter": "Seyedeh Neelufar Payrovnaziri", "authors": "Seyedeh Neelufar Payrovnaziri, Laura A. Barrett, Daniel Bis, Jiang\n  Bian, Zhe He", "title": "Enhancing Prediction Models for One-Year Mortality in Patients with\n  Acute Myocardial Infarction and Post Myocardial Infarction Syndrome", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Predicting the risk of mortality for patients with acute myocardial\ninfarction (AMI) using electronic health records (EHRs) data can help identify\nrisky patients who might need more tailored care. In our previous work, we\nbuilt computational models to predict one-year mortality of patients admitted\nto an intensive care unit (ICU) with AMI or post myocardial infarction\nsyndrome. Our prior work only used the structured clinical data from MIMIC-III,\na publicly available ICU clinical database. In this study, we enhanced our work\nby adding the word embedding features from free-text discharge summaries. Using\na richer set of features resulted in significant improvement in the performance\nof our deep learning models. The average accuracy of our deep learning models\nwas 92.89% and the average F-measure was 0.928. We further reported the impact\nof different combinations of features extracted from structured and/or\nunstructured data on the performance of the deep learning models.\n", "versions": [{"version": "v1", "created": "Sun, 28 Apr 2019 20:45:04 GMT"}], "update_date": "2019-04-30", "authors_parsed": [["Payrovnaziri", "Seyedeh Neelufar", ""], ["Barrett", "Laura A.", ""], ["Bis", "Daniel", ""], ["Bian", "Jiang", ""], ["He", "Zhe", ""]]}, {"id": "1904.12385", "submitter": "Deniz Gunduz", "authors": "Deniz Gunduz, Paul de Kerret, Nicholas D. Sidiropoulos, David Gesbert,\n  Chandra Murthy, Mihaela van der Schaar", "title": "Machine Learning in the Air", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IT cs.AI cs.LG cs.NI math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Thanks to the recent advances in processing speed and data acquisition and\nstorage, machine learning (ML) is penetrating every facet of our lives, and\ntransforming research in many areas in a fundamental manner. Wireless\ncommunications is another success story -- ubiquitous in our lives, from\nhandheld devices to wearables, smart homes, and automobiles. While recent years\nhave seen a flurry of research activity in exploiting ML tools for various\nwireless communication problems, the impact of these techniques in practical\ncommunication systems and standards is yet to be seen. In this paper, we review\nsome of the major promises and challenges of ML in wireless communication\nsystems, focusing mainly on the physical layer. We present some of the most\nstriking recent accomplishments that ML techniques have achieved with respect\nto classical approaches, and point to promising research directions where ML is\nlikely to make the biggest impact in the near future. We also highlight the\ncomplementary problem of designing physical layer techniques to enable\ndistributed ML at the wireless network edge, which further emphasizes the need\nto understand and connect ML with fundamental concepts in wireless\ncommunications.\n", "versions": [{"version": "v1", "created": "Sun, 28 Apr 2019 21:21:48 GMT"}], "update_date": "2019-04-30", "authors_parsed": [["Gunduz", "Deniz", ""], ["de Kerret", "Paul", ""], ["Sidiropoulos", "Nicholas D.", ""], ["Gesbert", "David", ""], ["Murthy", "Chandra", ""], ["van der Schaar", "Mihaela", ""]]}, {"id": "1904.12386", "submitter": "Maximilian Du", "authors": "Maximilian Du", "title": "Application of Autoencoder-Assisted Recurrent Neural Networks to Prevent\n  Cases of Sudden Infant Death Syndrome", "comments": "4 pages, 7 figures", "journal-ref": null, "doi": "10.13140/RG.2.2.28868.48002", "report-no": null, "categories": "cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  This project develops and trains a Recurrent Neural Network (RNN) that\nmonitors sleeping infants from an auxiliary microphone for cases of Sudden\nInfant Death Syndrome (SIDS), manifested in sudden or gradual respiratory\narrest. To minimize invasiveness and maximize economic viability, an electret\nmicrophone, and parabolic concentrator, paired with a specially designed and\ntuned amplifier circuit, was used as a very sensitive audio monitoring device,\nwhich fed data to the RNN model. This RNN was trained and operated in the\nfrequency domain, where the respiratory activity is most unique from noise. In\nboth training and operation, a Fourier transform and an autoencoder compression\nwere applied to the raw audio, and this transformed audio data was fed into the\nmodel in 1/8 second time steps. In operation, this model flagged each perceived\nbreath, and the time between breaths was analyzed through a statistical T-test\nfor slope, which detected dangerous trends. The entire model achieved 92.5%\naccuracy on continuous data and had an 11.25-second response rate on data that\nemulated total respiratory arrest. Because of the compatibility of the trained\nmodel with many off-the-shelf devices like Android phones and Raspberry Pi's,\nfree-standing processing hardware deployment is a very feasible future goal.\n", "versions": [{"version": "v1", "created": "Sun, 28 Apr 2019 21:27:31 GMT"}, {"version": "v2", "created": "Mon, 5 Aug 2019 02:11:52 GMT"}], "update_date": "2019-08-06", "authors_parsed": [["Du", "Maximilian", ""]]}, {"id": "1904.12387", "submitter": "Fady Medhat", "authors": "Fady Medhat, Mahnaz Mohammadi, Sardar Jaf, Chris G. Willcocks, Toby P.\n  Breckon, Peter Matthews, Andrew Stephen McGough, Georgios Theodoropoulos and\n  Boguslaw Obara", "title": "TMIXT: A process flow for Transcribing MIXed handwritten and\n  machine-printed Text", "comments": "big data, unstructured data, Optical Character Recognition (OCR),\n  Handwritten Text Recognition (HTR), machine-printed text recognition, IAM\n  handwriting database, TMIXT", "journal-ref": "IEEE International Conference on Big Data (Big Data) 2018", "doi": "10.1109/BigData.2018.8622136", "report-no": null, "categories": "cs.LG cs.CV cs.IR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Handling large corpuses of documents is of significant importance in many\nfields, no more so than in the areas of crime investigation and defence, where\nan organisation may be presented with a large volume of scanned documents which\nneed to be processed in a finite time. However, this problem is exacerbated\nboth by the volume, in terms of scanned documents and the complexity of the\npages, which need to be processed. Often containing many different elements,\nwhich each need to be processed and understood. Text recognition, which is a\nprimary task of this process, is usually dependent upon the type of text, being\neither handwritten or machine-printed. Accordingly, the recognition involves\nprior classification of the text category, before deciding on the recognition\nmethod to be applied. This poses a more challenging task if a document contains\nboth handwritten and machine-printed text. In this work, we present a generic\nprocess flow for text recognition in scanned documents containing mixed\nhandwritten and machine-printed text without the need to classify text in\nadvance. We realize the proposed process flow using several open-source image\nprocessing and text recognition packages1. The evaluation is performed using a\nspecially developed variant, presented in this work, of the IAM handwriting\ndatabase, where we achieve an average transcription accuracy of nearly 80% for\npages containing both printed and handwritten text.\n", "versions": [{"version": "v1", "created": "Sun, 28 Apr 2019 21:46:39 GMT"}], "update_date": "2019-04-30", "authors_parsed": [["Medhat", "Fady", ""], ["Mohammadi", "Mahnaz", ""], ["Jaf", "Sardar", ""], ["Willcocks", "Chris G.", ""], ["Breckon", "Toby P.", ""], ["Matthews", "Peter", ""], ["McGough", "Andrew Stephen", ""], ["Theodoropoulos", "Georgios", ""], ["Obara", "Boguslaw", ""]]}, {"id": "1904.12399", "submitter": "Zhong Meng", "authors": "Zhong Meng, Jinyu Li, Yong Zhao, Yifan Gong", "title": "Conditional Teacher-Student Learning", "comments": "5 pages, 1 figure, ICASSP 2019", "journal-ref": "2019 IEEE International Conference on Acoustics, Speech and Signal\n  Processing (ICASSP), Brighton, UK", "doi": "10.1109/ICASSP.2019.8683438", "report-no": null, "categories": "cs.LG cs.CL cs.SD eess.AS stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The teacher-student (T/S) learning has been shown to be effective for a\nvariety of problems such as domain adaptation and model compression. One\nshortcoming of the T/S learning is that a teacher model, not always perfect,\nsporadically produces wrong guidance in form of posterior probabilities that\nmisleads the student model towards a suboptimal performance. To overcome this\nproblem, we propose a conditional T/S learning scheme, in which a \"smart\"\nstudent model selectively chooses to learn from either the teacher model or the\nground truth labels conditioned on whether the teacher can correctly predict\nthe ground truth. Unlike a naive linear combination of the two knowledge\nsources, the conditional learning is exclusively engaged with the teacher model\nwhen the teacher model's prediction is correct, and otherwise backs off to the\nground truth. Thus, the student model is able to learn effectively from the\nteacher and even potentially surpass the teacher. We examine the proposed\nlearning scheme on two tasks: domain adaptation on CHiME-3 dataset and speaker\nadaptation on Microsoft short message dictation dataset. The proposed method\nachieves 9.8% and 12.8% relative word error rate reductions, respectively, over\nT/S learning for environment adaptation and speaker-independent model for\nspeaker adaptation.\n", "versions": [{"version": "v1", "created": "Sun, 28 Apr 2019 23:43:20 GMT"}], "update_date": "2019-04-30", "authors_parsed": [["Meng", "Zhong", ""], ["Li", "Jinyu", ""], ["Zhao", "Yong", ""], ["Gong", "Yifan", ""]]}, {"id": "1904.12400", "submitter": "Zhong Meng", "authors": "Zhong Meng, Jinyu Li, Yifan Gong", "title": "Attentive Adversarial Learning for Domain-Invariant Training", "comments": "5 pages, 1 figure, ICASSP 2019", "journal-ref": "2019 IEEE International Conference on Acoustics, Speech and Signal\n  Processing (ICASSP), Brighton, United Kingdom", "doi": "10.1109/ICASSP.2019.8683486", "report-no": null, "categories": "cs.LG cs.CL cs.SD eess.AS stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Adversarial domain-invariant training (ADIT) proves to be effective in\nsuppressing the effects of domain variability in acoustic modeling and has led\nto improved performance in automatic speech recognition (ASR). In ADIT, an\nauxiliary domain classifier takes in equally-weighted deep features from a deep\nneural network (DNN) acoustic model and is trained to improve their\ndomain-invariance by optimizing an adversarial loss function. In this work, we\npropose an attentive ADIT (AADIT) in which we advance the domain classifier\nwith an attention mechanism to automatically weight the input deep features\naccording to their importance in domain classification. With this attentive\nre-weighting, AADIT can focus on the domain normalization of phonetic\ncomponents that are more susceptible to domain variability and generates deep\nfeatures with improved domain-invariance and senone-discriminativity over ADIT.\nMost importantly, the attention block serves only as an external component to\nthe DNN acoustic model and is not involved in ASR, so AADIT can be used to\nimprove the acoustic modeling with any DNN architectures. More generally, the\nsame methodology can improve any adversarial learning system with an auxiliary\ndiscriminator. Evaluated on CHiME-3 dataset, the AADIT achieves 13.6% and 9.3%\nrelative WER improvements, respectively, over a multi-conditional model and a\nstrong ADIT baseline.\n", "versions": [{"version": "v1", "created": "Sun, 28 Apr 2019 23:44:29 GMT"}], "update_date": "2019-04-30", "authors_parsed": [["Meng", "Zhong", ""], ["Li", "Jinyu", ""], ["Gong", "Yifan", ""]]}, {"id": "1904.12406", "submitter": "Zhong Meng", "authors": "Zhong Meng, Yong Zhao, Jinyu Li, Yifan Gong", "title": "Adversarial Speaker Verification", "comments": "5 pages, 1 figure, ICASSP 2019", "journal-ref": "2019 IEEE International Conference on Acoustics, Speech and Signal\n  Processing (ICASSP), Brighton, United Kingdom", "doi": "10.1109/ICASSP.2019.8682488", "report-no": null, "categories": "cs.SD cs.CL cs.LG eess.AS stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The use of deep networks to extract embeddings for speaker recognition has\nproven successfully. However, such embeddings are susceptible to performance\ndegradation due to the mismatches among the training, enrollment, and test\nconditions. In this work, we propose an adversarial speaker verification (ASV)\nscheme to learn the condition-invariant deep embedding via adversarial\nmulti-task training. In ASV, a speaker classification network and a condition\nidentification network are jointly optimized to minimize the speaker\nclassification loss and simultaneously mini-maximize the condition loss. The\ntarget labels of the condition network can be categorical (environment types)\nand continuous (SNR values). We further propose multi-factorial ASV to\nsimultaneously suppress multiple factors that constitute the condition\nvariability. Evaluated on a Microsoft Cortana text-dependent speaker\nverification task, the ASV achieves 8.8% and 14.5% relative improvements in\nequal error rates (EER) for known and unknown conditions, respectively.\n", "versions": [{"version": "v1", "created": "Mon, 29 Apr 2019 00:37:27 GMT"}], "update_date": "2019-04-30", "authors_parsed": [["Meng", "Zhong", ""], ["Zhao", "Yong", ""], ["Li", "Jinyu", ""], ["Gong", "Yifan", ""]]}, {"id": "1904.12407", "submitter": "Zhong Meng", "authors": "Zhong Meng, Jinyu Li, Yifan Gong", "title": "Adversarial Speaker Adaptation", "comments": "5 pages, 2 figures, ICASSP 2019", "journal-ref": "2019 IEEE International Conference on Acoustics, Speech and Signal\n  Processing (ICASSP), Brighton, United Kingdom", "doi": "10.1109/ICASSP.2019.8682510", "report-no": null, "categories": "cs.LG cs.CL cs.SD eess.AS stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a novel adversarial speaker adaptation (ASA) scheme, in which\nadversarial learning is applied to regularize the distribution of deep hidden\nfeatures in a speaker-dependent (SD) deep neural network (DNN) acoustic model\nto be close to that of a fixed speaker-independent (SI) DNN acoustic model\nduring adaptation. An additional discriminator network is introduced to\ndistinguish the deep features generated by the SD model from those produced by\nthe SI model. In ASA, with a fixed SI model as the reference, an SD model is\njointly optimized with the discriminator network to minimize the senone\nclassification loss, and simultaneously to mini-maximize the SI/SD\ndiscrimination loss on the adaptation data. With ASA, a senone-discriminative\ndeep feature is learned in the SD model with a similar distribution to that of\nthe SI model. With such a regularized and adapted deep feature, the SD model\ncan perform improved automatic speech recognition on the target speaker's\nspeech. Evaluated on the Microsoft short message dictation dataset, ASA\nachieves 14.4% and 7.9% relative word error rate improvements for supervised\nand unsupervised adaptation, respectively, over an SI model trained from 2600\nhours data, with 200 adaptation utterances per speaker.\n", "versions": [{"version": "v1", "created": "Mon, 29 Apr 2019 00:38:16 GMT"}], "update_date": "2019-04-30", "authors_parsed": [["Meng", "Zhong", ""], ["Li", "Jinyu", ""], ["Gong", "Yifan", ""]]}, {"id": "1904.12413", "submitter": "Reza Asadi Mr", "authors": "Reza Asadi, Amelia Regan", "title": "A convolution recurrent autoencoder for spatio-temporal missing data\n  imputation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  When sensors collect spatio-temporal data in a large geographical area, the\nexistence of missing data cannot be escaped. Missing data negatively impacts\nthe performance of data analysis and machine learning algorithms. In this\npaper, we study deep autoencoders for missing data imputation in\nspatio-temporal problems. We propose a convolution bidirectional-LSTM for\ncapturing spatial and temporal patterns. Moreover, we analyze an autoencoder's\nlatent feature representation in spatio-temporal data and illustrate its\nperformance for missing data imputation. Traffic flow data are used for\nevaluation of our models. The result shows that the proposed convolution\nrecurrent neural network outperforms state-of-the-art methods.\n", "versions": [{"version": "v1", "created": "Mon, 29 Apr 2019 01:12:28 GMT"}], "update_date": "2019-04-30", "authors_parsed": [["Asadi", "Reza", ""], ["Regan", "Amelia", ""]]}, {"id": "1904.12426", "submitter": "Taesik Na", "authors": "Taesik Na, Minah Lee, Burhan A. Mudassar, Priyabrata Saha, Jong Hwan\n  Ko, Saibal Mukhopadhyay", "title": "Mixture of Pre-processing Experts Model for Noise Robust Deep Learning\n  on Resource Constrained Platforms", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep learning on an edge device requires energy efficient operation due to\never diminishing power budget. Intentional low quality data during the data\nacquisition for longer battery life, and natural noise from the low cost sensor\ndegrade the quality of target output which hinders adoption of deep learning on\nan edge device. To overcome these problems, we propose simple yet efficient\nmixture of pre-processing experts (MoPE) model to handle various image\ndistortions including low resolution and noisy images. We also propose to use\nadversarially trained auto encoder as a pre-processing expert for the noisy\nimages. We evaluate our proposed method for various machine learning tasks\nincluding object detection on MS-COCO 2014 dataset, multiple object tracking\nproblem on MOT-Challenge dataset, and human activity classification on UCF 101\ndataset. Experimental results show that the proposed method achieves better\ndetection, tracking and activity classification accuracies under noise without\nsacrificing accuracies for the clean images. The overheads of our proposed MoPE\nare 0.67% and 0.17% in terms of memory and computation compared to the baseline\nobject detection network.\n", "versions": [{"version": "v1", "created": "Mon, 29 Apr 2019 02:26:06 GMT"}], "update_date": "2019-04-30", "authors_parsed": [["Na", "Taesik", ""], ["Lee", "Minah", ""], ["Mudassar", "Burhan A.", ""], ["Saha", "Priyabrata", ""], ["Ko", "Jong Hwan", ""], ["Mukhopadhyay", "Saibal", ""]]}, {"id": "1904.12437", "submitter": "Cheng Li", "authors": "Cheng Li, Abdul Dakkak, Jinjun Xiong, Wen-mei Hwu", "title": "Challenges and Pitfalls of Machine Learning Evaluation and Benchmarking", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.SE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  An increasingly complex and diverse collection of Machine Learning (ML)\nmodels as well as hardware/software stacks, collectively referred to as \"ML\nartifacts\", are being proposed - leading to a diverse landscape of ML. These ML\ninnovations proposed have outpaced researchers' ability to analyze, study and\nadapt them. This is exacerbated by the complicated and sometimes\nnon-reproducible procedures for ML evaluation. A common practice of sharing ML\nartifacts is through repositories where artifact authors post ad-hoc code and\nsome documentation, but often fail to reveal critical information for others to\nreproduce their results. This results in users' inability to compare with\nartifact authors' claims or adapt the model to his/her own use. This paper\ndiscusses common challenges and pitfalls of ML evaluation and benchmarking,\nwhich can be used as a guideline for ML model authors when sharing ML\nartifacts, and for system developers when benchmarking or designing ML systems.\n", "versions": [{"version": "v1", "created": "Mon, 29 Apr 2019 03:35:15 GMT"}, {"version": "v2", "created": "Tue, 25 Jun 2019 09:28:49 GMT"}], "update_date": "2019-06-26", "authors_parsed": [["Li", "Cheng", ""], ["Dakkak", "Abdul", ""], ["Xiong", "Jinjun", ""], ["Hwu", "Wen-mei", ""]]}, {"id": "1904.12443", "submitter": "Dheeraj Nagaraj", "authors": "Prateek Jain, Dheeraj Nagaraj and Praneeth Netrapalli", "title": "Making the Last Iterate of SGD Information Theoretically Optimal", "comments": "3 figures, Accepted for presentation at COLT 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.OC cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Stochastic gradient descent (SGD) is one of the most widely used algorithms\nfor large scale optimization problems. While classical theoretical analysis of\nSGD for convex problems studies (suffix) \\emph{averages} of iterates and\nobtains information theoretically optimal bounds on suboptimality, the\n\\emph{last point} of SGD is, by far, the most preferred choice in practice. The\nbest known results for last point of SGD \\cite{shamir2013stochastic} however,\nare suboptimal compared to information theoretic lower bounds by a $\\log T$\nfactor, where $T$ is the number of iterations. \\cite{harvey2018tight} shows\nthat in fact, this additional $\\log T$ factor is tight for standard step size\nsequences of $\\OTheta{\\frac{1}{\\sqrt{t}}}$ and $\\OTheta{\\frac{1}{t}}$ for\nnon-strongly convex and strongly convex settings, respectively. Similarly, even\nfor subgradient descent (GD) when applied to non-smooth, convex functions, the\nbest known step-size sequences still lead to $O(\\log T)$-suboptimal convergence\nrates (on the final iterate). The main contribution of this work is to design\nnew step size sequences that enjoy information theoretically optimal bounds on\nthe suboptimality of \\emph{last point} of SGD as well as GD. We achieve this by\ndesigning a modification scheme, that converts one sequence of step sizes to\nanother so that the last point of SGD/GD with modified sequence has the same\nsuboptimality guarantees as the average of SGD/GD with original sequence. We\nalso show that our result holds with high-probability. We validate our results\nthrough simulations which demonstrate that the new step size sequence indeed\nimproves the final iterate significantly compared to the standard step size\nsequences.\n", "versions": [{"version": "v1", "created": "Mon, 29 Apr 2019 04:33:53 GMT"}, {"version": "v2", "created": "Wed, 29 May 2019 16:47:01 GMT"}], "update_date": "2019-05-30", "authors_parsed": [["Jain", "Prateek", ""], ["Nagaraj", "Dheeraj", ""], ["Netrapalli", "Praneeth", ""]]}, {"id": "1904.12445", "submitter": "Junyu Cao", "authors": "Junyu Cao, Wei Sun", "title": "Dynamic Learning with Frequent New Product Launches: A Sequential\n  Multinomial Logit Bandit Problem", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Motivated by the phenomenon that companies introduce new products to keep\nabreast with customers' rapidly changing tastes, we consider a novel online\nlearning setting where a profit-maximizing seller needs to learn customers'\npreferences through offering recommendations, which may contain existing\nproducts and new products that are launched in the middle of a selling period.\nWe propose a sequential multinomial logit (SMNL) model to characterize\ncustomers' behavior when product recommendations are presented in tiers. For\nthe offline version with known customers' preferences, we propose a\npolynomial-time algorithm and characterize the properties of the optimal tiered\nproduct recommendation. For the online problem, we propose a learning algorithm\nand quantify its regret bound. Moreover, we extend the setting to incorporate a\nconstraint which ensures every new product is learned to a given accuracy. Our\nresults demonstrate the tier structure can be used to mitigate the risks\nassociated with learning new products.\n", "versions": [{"version": "v1", "created": "Mon, 29 Apr 2019 04:44:31 GMT"}], "update_date": "2019-04-30", "authors_parsed": [["Cao", "Junyu", ""], ["Sun", "Wei", ""]]}, {"id": "1904.12465", "submitter": "David Zimmermann", "authors": "David Zimmermann", "title": "Asymmetric Impurity Functions, Class Weighting, and Optimal Splits for\n  Binary Classification Trees", "comments": "18 pages, 2 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We investigate how asymmetrizing an impurity function affects the choice of\noptimal node splits when growing a decision tree for binary classification. In\nparticular, we relax the usual axioms of an impurity function and show how\nskewing an impurity function biases the optimal splits to isolate points of a\nparticular class when splitting a node. We give a rigorous definition of this\nnotion, then give a necessary and sufficient condition for such a bias to hold.\nWe also show that the technique of class weighting is equivalent to applying a\nspecific transformation to the impurity function, and tie all these notions\ntogether for a class of impurity functions that includes the entropy and Gini\nimpurity. We also briefly discuss cost-insensitive impurity functions and give\na characterization of such functions.\n", "versions": [{"version": "v1", "created": "Mon, 29 Apr 2019 06:34:37 GMT"}], "update_date": "2019-04-30", "authors_parsed": [["Zimmermann", "David", ""]]}, {"id": "1904.12470", "submitter": "Asher Wilk", "authors": "Asher Wilk", "title": "Teaching AI, Ethics, Law and Policy", "comments": "15 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.AI cs.LG cs.SE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The cyberspace and development of intelligent systems using Artificial\nIntelligence (AI) creates new challenges to computer professionals, data\nscientists, regulators and policy makers. For example, self-driving cars raise\nnew technical, ethical, legal and public policy issues. This paper proposes a\ncourse named Computers, Ethics, Law, and Public Policy, and suggests a\ncurriculum for such a course. This paper presents ethical, legal, and public\npolicy issues relevant to building and using intelligent systems.\n", "versions": [{"version": "v1", "created": "Mon, 29 Apr 2019 07:01:50 GMT"}, {"version": "v2", "created": "Fri, 24 May 2019 15:56:02 GMT"}, {"version": "v3", "created": "Tue, 18 Jun 2019 16:38:44 GMT"}, {"version": "v4", "created": "Wed, 10 Jul 2019 18:04:31 GMT"}, {"version": "v5", "created": "Fri, 30 Aug 2019 16:13:44 GMT"}], "update_date": "2019-09-02", "authors_parsed": [["Wilk", "Asher", ""]]}, {"id": "1904.12534", "submitter": "Sinisa Stekovic", "authors": "Sinisa Stekovic, Friedrich Fraundorfer, Vincent Lepetit", "title": "Casting Geometric Constraints in Semantic Segmentation as\n  Semi-Supervised Learning", "comments": "To be presented at WACV 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a simple yet effective method to learn to segment new indoor\nscenes from video frames: State-of-the-art methods trained on one dataset, even\nas large as the SUNRGB-D dataset, can perform poorly when applied to images\nthat are not part of the dataset, because of the dataset bias, a common\nphenomenon in computer vision. To make semantic segmentation more useful in\npractice, one can exploit geometric constraints. Our main contribution is to\nshow that these constraints can be cast conveniently as semi-supervised terms,\nwhich enforce the fact that the same class should be predicted for the\nprojections of the same 3D location in different images. This is interesting as\nwe can exploit general existing techniques developed for semi-supervised\nlearning to efficiently incorporate the constraints. We show that this approach\ncan efficiently and accurately learn to segment target sequences of ScanNet and\nour own target sequences using only annotations from SUNRGB-D, and geometric\nrelations between the video frames of target sequences.\n", "versions": [{"version": "v1", "created": "Mon, 29 Apr 2019 09:36:12 GMT"}, {"version": "v2", "created": "Tue, 30 Apr 2019 11:15:12 GMT"}, {"version": "v3", "created": "Wed, 8 Jan 2020 08:54:00 GMT"}], "update_date": "2020-01-09", "authors_parsed": [["Stekovic", "Sinisa", ""], ["Fraundorfer", "Friedrich", ""], ["Lepetit", "Vincent", ""]]}, {"id": "1904.12535", "submitter": "Ping Li", "authors": "Mingming Sun, Xu Li, Xin Wang, Miao Fan, Yue Feng, Ping Li", "title": "Logician: A Unified End-to-End Neural Approach for Open-Domain\n  Information Extraction", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.DB cs.IR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we consider the problem of open information extraction (OIE)\nfor extracting entity and relation level intermediate structures from sentences\nin open-domain. We focus on four types of valuable intermediate structures\n(Relation, Attribute, Description, and Concept), and propose a unified\nknowledge expression form, SAOKE, to express them. We publicly release a data\nset which contains more than forty thousand sentences and the corresponding\nfacts in the SAOKE format labeled by crowd-sourcing. To our knowledge, this is\nthe largest publicly available human labeled data set for open information\nextraction tasks. Using this labeled SAOKE data set, we train an end-to-end\nneural model using the sequenceto-sequence paradigm, called Logician, to\ntransform sentences into facts. For each sentence, different to existing\nalgorithms which generally focus on extracting each single fact without\nconcerning other possible facts, Logician performs a global optimization over\nall possible involved facts, in which facts not only compete with each other to\nattract the attention of words, but also cooperate to share words. An\nexperimental study on various types of open domain relation extraction tasks\nreveals the consistent superiority of Logician to other states-of-the-art\nalgorithms. The experiments verify the reasonableness of SAOKE format, the\nvaluableness of SAOKE data set, the effectiveness of the proposed Logician\nmodel, and the feasibility of the methodology to apply end-to-end learning\nparadigm on supervised data sets for the challenging tasks of open information\nextraction.\n", "versions": [{"version": "v1", "created": "Mon, 29 Apr 2019 09:37:31 GMT"}], "update_date": "2019-04-30", "authors_parsed": [["Sun", "Mingming", ""], ["Li", "Xu", ""], ["Wang", "Xin", ""], ["Fan", "Miao", ""], ["Feng", "Yue", ""], ["Li", "Ping", ""]]}, {"id": "1904.12543", "submitter": "Kei Akuzawa", "authors": "Kei Akuzawa, Yusuke Iwasawa, Yutaka Matsuo", "title": "Adversarial Invariant Feature Learning with Accuracy Constraint for\n  Domain Generalization", "comments": "accepted for ECMLPKDD 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Learning domain-invariant representation is a dominant approach for domain\ngeneralization (DG), where we need to build a classifier that is robust toward\ndomain shifts. However, previous domain-invariance-based methods overlooked the\nunderlying dependency of classes on domains, which is responsible for the\ntrade-off between classification accuracy and domain invariance. Because the\nprimary purpose of DG is to classify unseen domains rather than the invariance\nitself, the improvement of the invariance can negatively affect DG performance\nunder this trade-off. To overcome the problem, this study first expands the\nanalysis of the trade-off by Xie et. al., and provides the notion of\naccuracy-constrained domain invariance, which means the maximum domain\ninvariance within a range that does not interfere with accuracy. We then\npropose a novel method adversarial feature learning with accuracy constraint\n(AFLAC), which explicitly leads to that invariance on adversarial training.\nEmpirical validations show that the performance of AFLAC is superior to that of\ndomain-invariance-based methods on both synthetic and three real-world\ndatasets, supporting the importance of considering the dependency and the\nefficacy of the proposed method.\n", "versions": [{"version": "v1", "created": "Mon, 29 Apr 2019 09:52:36 GMT"}, {"version": "v2", "created": "Tue, 18 Jun 2019 05:54:15 GMT"}, {"version": "v3", "created": "Mon, 2 Mar 2020 11:24:01 GMT"}], "update_date": "2020-03-03", "authors_parsed": [["Akuzawa", "Kei", ""], ["Iwasawa", "Yusuke", ""], ["Matsuo", "Yutaka", ""]]}, {"id": "1904.12546", "submitter": "Pankaj Malhotra", "authors": "Kathan Kashiparekh, Jyoti Narwariya, Pankaj Malhotra, Lovekesh Vig,\n  Gautam Shroff", "title": "ConvTimeNet: A Pre-trained Deep Convolutional Neural Network for Time\n  Series Classification", "comments": "Accepted at IJCNN 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Training deep neural networks often requires careful hyper-parameter tuning\nand significant computational resources. In this paper, we propose ConvTimeNet\n(CTN): an off-the-shelf deep convolutional neural network (CNN) trained on\ndiverse univariate time series classification (TSC) source tasks. Once trained,\nCTN can be easily adapted to new TSC target tasks via a small amount of\nfine-tuning using labeled instances from the target tasks. We note that the\nlength of convolutional filters is a key aspect when building a pre-trained\nmodel that can generalize to time series of different lengths across datasets.\nTo achieve this, we incorporate filters of multiple lengths in all\nconvolutional layers of CTN to capture temporal features at multiple time\nscales. We consider all 65 datasets with time series of lengths up to 512\npoints from the UCR TSC Benchmark for training and testing transferability of\nCTN: We train CTN on a randomly chosen subset of 24 datasets using a multi-head\napproach with a different softmax layer for each training dataset, and study\ngeneralizability and transferability of the learned filters on the remaining 41\nTSC datasets. We observe significant gains in classification accuracy as well\nas computational efficiency when using pre-trained CTN as a starting point for\nsubsequent task-specific fine-tuning compared to existing state-of-the-art TSC\napproaches. We also provide qualitative insights into the working of CTN by: i)\nanalyzing the activations and filters of first convolution layer suggesting the\nfilters in CTN are generically useful, ii) analyzing the impact of the design\ndecision to incorporate multiple length decisions, and iii) finding regions of\ntime series that affect the final classification decision via occlusion\nsensitivity analysis.\n", "versions": [{"version": "v1", "created": "Mon, 29 Apr 2019 10:12:17 GMT"}, {"version": "v2", "created": "Thu, 2 May 2019 05:32:20 GMT"}], "update_date": "2019-05-03", "authors_parsed": [["Kashiparekh", "Kathan", ""], ["Narwariya", "Jyoti", ""], ["Malhotra", "Pankaj", ""], ["Vig", "Lovekesh", ""], ["Shroff", "Gautam", ""]]}, {"id": "1904.12562", "submitter": "Evgenii Ofitserov", "authors": "Evgenii Ofitserov, Vasily Tsvetkov, Vadim Nazarov", "title": "Soft edit distance for differentiable comparison of symbolic sequences", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Edit distance, also known as Levenshtein distance, is an essential way to\ncompare two strings that proved to be particularly useful in the analysis of\ngenetic sequences and natural language processing. However, edit distance is a\ndiscrete function that is known to be hard to optimize. This fact hampers the\nuse of this metric in Machine Learning. Even as simple algorithm as K-means\nfails to cluster a set of sequences using edit distance if they are of variable\nlength and abundance. In this paper we propose a novel metric - soft edit\ndistance (SED), which is a smooth approximation of edit distance. It is\ndifferentiable and therefore it is possible to optimize it with gradient\nmethods. Similar to original edit distance, SED as well as its derivatives can\nbe calculated with recurrent formulas at polynomial time. We prove usefulness\nof the proposed metric on synthetic datasets and clustering of biological\nsequences.\n", "versions": [{"version": "v1", "created": "Mon, 29 Apr 2019 11:31:54 GMT"}], "update_date": "2019-04-30", "authors_parsed": [["Ofitserov", "Evgenii", ""], ["Tsvetkov", "Vasily", ""], ["Nazarov", "Vadim", ""]]}, {"id": "1904.12574", "submitter": "Da Xu", "authors": "Da Xu, Chuanwei Ruan, Jason Cho, Evren Korpeoglu, Sushant Kumar,\n  Kannan Achan", "title": "Knowledge-aware Complementary Product Representation Learning", "comments": null, "journal-ref": null, "doi": "10.1145/3336191.3371854", "report-no": null, "categories": "cs.IR cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Learning product representations that reflect complementary relationship\nplays a central role in e-commerce recommender system. In the absence of the\nproduct relationships graph, which existing methods rely on, there is a need to\ndetect the complementary relationships directly from noisy and sparse customer\npurchase activities. Furthermore, unlike simple relationships such as\nsimilarity, complementariness is asymmetric and non-transitive. Standard usage\nof representation learning emphasizes on only one set of embedding, which is\nproblematic for modelling such properties of complementariness. We propose\nusing knowledge-aware learning with dual product embedding to solve the above\nchallenges. We encode contextual knowledge into product representation by\nmulti-task learning, to alleviate the sparsity issue. By explicitly modelling\nwith user bias terms, we separate the noise of customer-specific preferences\nfrom the complementariness. Furthermore, we adopt the dual embedding framework\nto capture the intrinsic properties of complementariness and provide geometric\ninterpretation motivated by the classic separating hyperplane theory. Finally,\nwe propose a Bayesian network structure that unifies all the components, which\nalso concludes several popular models as special cases. The proposed method\ncompares favourably to state-of-art methods, in downstream classification and\nrecommendation tasks. We also develop an implementation that scales efficiently\nto a dataset with millions of items and customers.\n", "versions": [{"version": "v1", "created": "Sat, 16 Mar 2019 03:01:12 GMT"}, {"version": "v2", "created": "Sun, 16 Jun 2019 19:46:18 GMT"}, {"version": "v3", "created": "Thu, 28 Nov 2019 21:09:31 GMT"}], "update_date": "2019-12-02", "authors_parsed": [["Xu", "Da", ""], ["Ruan", "Chuanwei", ""], ["Cho", "Jason", ""], ["Korpeoglu", "Evren", ""], ["Kumar", "Sushant", ""], ["Achan", "Kannan", ""]]}, {"id": "1904.12575", "submitter": "Hongwei Wang", "authors": "Hongwei Wang, Miao Zhao, Xing Xie, Wenjie Li, Minyi Guo", "title": "Knowledge Graph Convolutional Networks for Recommender Systems", "comments": "Proceedings of the 2019 World Wide Web Conference", "journal-ref": null, "doi": "10.1145/3308558.3313417", "report-no": null, "categories": "cs.IR cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  To alleviate sparsity and cold start problem of collaborative filtering based\nrecommender systems, researchers and engineers usually collect attributes of\nusers and items, and design delicate algorithms to exploit these additional\ninformation. In general, the attributes are not isolated but connected with\neach other, which forms a knowledge graph (KG). In this paper, we propose\nKnowledge Graph Convolutional Networks (KGCN), an end-to-end framework that\ncaptures inter-item relatedness effectively by mining their associated\nattributes on the KG. To automatically discover both high-order structure\ninformation and semantic information of the KG, we sample from the neighbors\nfor each entity in the KG as their receptive field, then combine neighborhood\ninformation with bias when calculating the representation of a given entity.\nThe receptive field can be extended to multiple hops away to model high-order\nproximity information and capture users' potential long-distance interests.\nMoreover, we implement the proposed KGCN in a minibatch fashion, which enables\nour model to operate on large datasets and KGs. We apply the proposed model to\nthree datasets about movie, book, and music recommendation, and experiment\nresults demonstrate that our approach outperforms strong recommender baselines.\n", "versions": [{"version": "v1", "created": "Mon, 18 Mar 2019 17:17:34 GMT"}], "update_date": "2019-04-30", "authors_parsed": [["Wang", "Hongwei", ""], ["Zhao", "Miao", ""], ["Xie", "Xing", ""], ["Li", "Wenjie", ""], ["Guo", "Minyi", ""]]}, {"id": "1904.12576", "submitter": "Armel Jacques Nzekon Nzeko'o", "authors": "Armel Jacques Nzekon Nzeko'o, Maurice Tchuente, Matthieu Latapy", "title": "Link Stream Graph for Temporal Recommendations", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.LG cs.SI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Several researches on recommender systems are based on explicit rating data,\nbut in many real world e-commerce platforms, ratings are not always available,\nand in those situations, recommender systems have to deal with implicit data\nsuch as users' purchase history, browsing history and streaming history. In\nthis context, classical bipartite user-item graphs (BIP) are widely used to\ncompute top-N recommendations. However, these graphs have some limitations,\nparticularly in terms of taking temporal dynamic into account. This is not good\nbecause users' preference change over time. To overcome this limit, the\nSession-based Temporal Graph (STG) was proposed by Xiang et al. to combine\nlong- and short-term preferences in a graph-based recommender system. But in\nthe STG, time is divided into slices and therefore considered discontinuously.\nThis approach loses details of the real temporal dynamics of user actions. To\naddress this challenge, we propose the Link Stream Graph (LSG) which is an\nextension of link stream representation proposed by Latapy et al. and which\nallows to model interactions between users and items by considering time\ncontinuously. Experiments conducted on four real world implicit datasets for\ntemporal recommendation, with 3 evaluation metrics, show that LSG is the best\nin 9 out of 12 cases compared to BIP and STG which are the most used\nstate-of-the-art recommender graphs.\n", "versions": [{"version": "v1", "created": "Wed, 27 Mar 2019 14:04:44 GMT"}], "update_date": "2019-04-30", "authors_parsed": [["Nzeko'o", "Armel Jacques Nzekon", ""], ["Tchuente", "Maurice", ""], ["Latapy", "Matthieu", ""]]}, {"id": "1904.12577", "submitter": "Martin Hole\\v{c}ek", "authors": "Martin Hole\\v{c}ek, Anton\\'in Hoskovec, Petr Baudi\\v{s}, Pavel Klinger", "title": "Table understanding in structured documents", "comments": "Changed from previous version based on icdar2019 feedback to include\n  6 pages, 2 figures. Slightly changed paper name and abstract to be less\n  misleading. Corrected grammar and shortened content heavily, corrected\n  misleading information and readability. Currently in review for icdar2019-wml\n  subconference/workshop", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Abstract--- Table detection and extraction has been studied in the context of\ndocuments like reports, where tables are clearly outlined and stand out from\nthe document structure visually. We study this topic in a rather more\nchallenging domain of layout-heavy business documents, particularly invoices.\nInvoices present the novel challenges of tables being often without outlines -\neither in the form of borders or surrounding text flow - with ragged columns\nand widely varying data content. We will also show, that we can extract\nspecific information from structurally different tables or table-like\nstructures with one model. We present a comprehensive representation of a page\nusing graph over word boxes, positional embeddings, trainable textual features\nand rephrase the table detection as a text box labeling problem. We will work\non our newly presented dataset of pro forma invoices, invoices and debit note\ndocuments using this representation and propose multiple baselines to solve\nthis labeling problem. We then propose a novel neural network model that\nachieves strong, practical results on the presented dataset and analyze the\nmodel performance and effects of graph convolutions and self-attention in\ndetail.\n", "versions": [{"version": "v1", "created": "Fri, 22 Mar 2019 15:08:04 GMT"}, {"version": "v2", "created": "Tue, 9 Jul 2019 14:38:06 GMT"}], "update_date": "2019-07-10", "authors_parsed": [["Hole\u010dek", "Martin", ""], ["Hoskovec", "Anton\u00edn", ""], ["Baudi\u0161", "Petr", ""], ["Klinger", "Pavel", ""]]}, {"id": "1904.12578", "submitter": "Ronghui You", "authors": "Ronghui You, Zihan Zhang, Suyang Dai and Shanfeng Zhu", "title": "HAXMLNet: Hierarchical Attention Network for Extreme Multi-Label Text\n  Classification", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Extreme multi-label text classification (XMTC) addresses the problem of\ntagging each text with the most relevant labels from an extreme-scale label\nset. Traditional methods use bag-of-words (BOW) representations without context\ninformation as their features. The state-ot-the-art deep learning-based method,\nAttentionXML, which uses a recurrent neural network (RNN) and the multi-label\nattention, can hardly deal with extreme-scale (hundreds of thousands labels)\nproblem. To address this, we propose our HAXMLNet, which uses an efficient and\neffective hierarchical structure with the multi-label attention. Experimental\nresults show that HAXMLNet reaches a competitive performance with other\nstate-of-the-art methods.\n", "versions": [{"version": "v1", "created": "Sun, 24 Mar 2019 08:09:15 GMT"}], "update_date": "2019-04-30", "authors_parsed": [["You", "Ronghui", ""], ["Zhang", "Zihan", ""], ["Dai", "Suyang", ""], ["Zhu", "Shanfeng", ""]]}, {"id": "1904.12579", "submitter": "Furao Shen", "authors": "Yi Yang, Baile Xu, Furao Shen, Jian Zhao", "title": "Operation-aware Neural Networks for User Response Prediction", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  User response prediction makes a crucial contribution to the rapid\ndevelopment of online advertising system and recommendation system. The\nimportance of learning feature interactions has been emphasized by many works.\nMany deep models are proposed to automatically learn high-order feature\ninteractions. Since most features in advertising system and recommendation\nsystem are high-dimensional sparse features, deep models usually learn a\nlow-dimensional distributed representation for each feature in the bottom\nlayer. Besides traditional fully-connected architectures, some new operations,\nsuch as convolutional operations and product operations, are proposed to learn\nfeature interactions better. In these models, the representation is shared\namong different operations. However, the best representation for different\noperations may be different. In this paper, we propose a new neural model named\nOperation-aware Neural Networks (ONN) which learns different representations\nfor different operations. Our experimental results on two large-scale\nreal-world ad click/conversion datasets demonstrate that ONN consistently\noutperforms the state-of-the-art models in both offline-training environment\nand online-training environment.\n", "versions": [{"version": "v1", "created": "Tue, 2 Apr 2019 15:04:52 GMT"}], "update_date": "2019-04-30", "authors_parsed": [["Yang", "Yi", ""], ["Xu", "Baile", ""], ["Shen", "Furao", ""], ["Zhao", "Jian", ""]]}, {"id": "1904.12580", "submitter": "Mahidhar Dwarampudi", "authors": "Dwarampudi Mahidhar Reddy, Dr. N V Subba Reddy, Dr. N V Subba Reddy", "title": "Twitter Sentiment Analysis using Distributed Word and Sentence\n  Representation", "comments": "8 pages, 5 figures, 6 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.CL cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  An important part of the information gathering and data analysis is to find\nout what people think about, either a product or an entity. Twitter is an\nopinion rich social networking site. The posts or tweets from this data can be\nused for mining people's opinions. The recent surge of activity in this area\ncan be attributed to the computational treatment of data, which made opinion\nextraction and sentiment analysis easier. This paper classifies tweets into\npositive and negative sentiments, but instead of using traditional methods or\npreprocessing text data here we use the distributed representations of words\nand sentences to classify the tweets. We use Long Short Term Memory (LSTM)\nNetworks, Convolutional Neural Networks (CNNs) and Artificial Neural Networks.\nThe first two are used on Distributed Representation of words while the latter\nis used on the distributed representation of sentences. This paper achieves\naccuracies as high as 81%. It also suggests the best and optimal ways for\ncreating distributed representations of words for sentiment analysis, out of\nthe available methods.\n", "versions": [{"version": "v1", "created": "Mon, 1 Apr 2019 17:46:54 GMT"}], "update_date": "2019-04-30", "authors_parsed": [["Reddy", "Dwarampudi Mahidhar", ""], ["Reddy", "Dr. N V Subba", ""], ["Reddy", "Dr. N V Subba", ""]]}, {"id": "1904.12584", "submitter": "Jiayuan Mao", "authors": "Jiayuan Mao, Chuang Gan, Pushmeet Kohli, Joshua B. Tenenbaum, Jiajun\n  Wu", "title": "The Neuro-Symbolic Concept Learner: Interpreting Scenes, Words, and\n  Sentences From Natural Supervision", "comments": "ICLR 2019 (Oral). Project page: http://nscl.csail.mit.edu/", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose the Neuro-Symbolic Concept Learner (NS-CL), a model that learns\nvisual concepts, words, and semantic parsing of sentences without explicit\nsupervision on any of them; instead, our model learns by simply looking at\nimages and reading paired questions and answers. Our model builds an\nobject-based scene representation and translates sentences into executable,\nsymbolic programs. To bridge the learning of two modules, we use a\nneuro-symbolic reasoning module that executes these programs on the latent\nscene representation. Analogical to human concept learning, the perception\nmodule learns visual concepts based on the language description of the object\nbeing referred to. Meanwhile, the learned visual concepts facilitate learning\nnew words and parsing new sentences. We use curriculum learning to guide the\nsearching over the large compositional space of images and language. Extensive\nexperiments demonstrate the accuracy and efficiency of our model on learning\nvisual concepts, word representations, and semantic parsing of sentences.\nFurther, our method allows easy generalization to new object attributes,\ncompositions, language concepts, scenes and questions, and even new program\ndomains. It also empowers applications including visual question answering and\nbidirectional image-text retrieval.\n", "versions": [{"version": "v1", "created": "Fri, 26 Apr 2019 06:50:54 GMT"}], "update_date": "2019-04-30", "authors_parsed": [["Mao", "Jiayuan", ""], ["Gan", "Chuang", ""], ["Kohli", "Pushmeet", ""], ["Tenenbaum", "Joshua B.", ""], ["Wu", "Jiajun", ""]]}, {"id": "1904.12587", "submitter": "Thomas K\\\"ollmer", "authors": "Thomas K\\\"ollmer and Jens Hasselbach and Patrick Aichroth", "title": "Text Classification Components for Detecting Descriptions and Names of\n  CAD models", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We apply text analysis approaches for a specialized search engine for 3D CAD\nmodels and associated products. The main goals are to distinguish between\nactual product descriptions and other text on a website, as well as to decide\nwhether a given text is or contains a product name.\n  For this we use paragraph vectors for text classification, a character-level\nlong short-term memory network (LSTM) for a single word classification and an\nLSTM tagger based on word embeddings for detecting product names within\nsentences. Despite the need to collect bigger datasets in our specific problem\ndomain, the first results are promising and partially fit for production use.\n", "versions": [{"version": "v1", "created": "Thu, 4 Apr 2019 15:41:26 GMT"}], "update_date": "2019-04-30", "authors_parsed": [["K\u00f6llmer", "Thomas", ""], ["Hasselbach", "Jens", ""], ["Aichroth", "Patrick", ""]]}, {"id": "1904.12604", "submitter": "Jingxuan Yang", "authors": "Jingxuan Yang, Jun Xu, Jianzhuo Tong, Sheng Gao, Jun Guo, Jirong Wen", "title": "Pre-training of Context-aware Item Representation for Next Basket\n  Recommendation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Next basket recommendation, which aims to predict the next a few items that a\nuser most probably purchases given his historical transactions, plays a vital\nrole in market basket analysis. From the viewpoint of item, an item could be\npurchased by different users together with different items, for different\nreasons. Therefore, an ideal recommender system should represent an item\nconsidering its transaction contexts. Existing state-of-the-art deep learning\nmethods usually adopt the static item representations, which are invariant\namong all of the transactions and thus cannot achieve the full potentials of\ndeep learning. Inspired by the pre-trained representations of BERT in natural\nlanguage processing, we propose to conduct context-aware item representation\nfor next basket recommendation, called Item Encoder Representations from\nTransformers (IERT). In the offline phase, IERT pre-trains deep item\nrepresentations conditioning on their transaction contexts. In the online\nrecommendation phase, the pre-trained model is further fine-tuned with an\nadditional output layer. The output contextualized item embeddings are used to\ncapture users' sequential behaviors and general tastes to conduct\nrecommendation. Experimental results on the Ta-Feng data set show that IERT\noutperforms the state-of-the-art baseline methods, which demonstrated the\neffectiveness of IERT in next basket representation.\n", "versions": [{"version": "v1", "created": "Sun, 14 Apr 2019 14:57:57 GMT"}], "update_date": "2019-04-30", "authors_parsed": [["Yang", "Jingxuan", ""], ["Xu", "Jun", ""], ["Tong", "Jianzhuo", ""], ["Gao", "Sheng", ""], ["Guo", "Jun", ""], ["Wen", "Jirong", ""]]}, {"id": "1904.12606", "submitter": "Dongxu Zhang", "authors": "Dongxu Zhang and Subhabrata Mukherjee and Colin Lockard and Xin Luna\n  Dong and Andrew McCallum", "title": "OpenKI: Integrating Open Information Extraction and Knowledge Bases with\n  Relation Inference", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we consider advancing web-scale knowledge extraction and\nalignment by integrating OpenIE extractions in the form of (subject, predicate,\nobject) triples with Knowledge Bases (KB). Traditional techniques from\nuniversal schema and from schema mapping fall in two extremes: either they\nperform instance-level inference relying on embedding for (subject, object)\npairs, thus cannot handle pairs absent in any existing triples; or they perform\npredicate-level mapping and completely ignore background evidence from\nindividual entities, thus cannot achieve satisfying quality. We propose OpenKI\nto handle sparsity of OpenIE extractions by performing instance-level\ninference: for each entity, we encode the rich information in its neighborhood\nin both KB and OpenIE extractions, and leverage this information in relation\ninference by exploring different methods of aggregation and attention. In order\nto handle unseen entities, our model is designed without creating\nentity-specific parameters. Extensive experiments show that this method not\nonly significantly improves state-of-the-art for conventional OpenIE\nextractions like ReVerb, but also boosts the performance on OpenIE from\nsemi-structured data, where new entity pairs are abundant and data are fairly\nsparse.\n", "versions": [{"version": "v1", "created": "Fri, 12 Apr 2019 14:05:38 GMT"}], "update_date": "2019-04-30", "authors_parsed": [["Zhang", "Dongxu", ""], ["Mukherjee", "Subhabrata", ""], ["Lockard", "Colin", ""], ["Dong", "Xin Luna", ""], ["McCallum", "Andrew", ""]]}, {"id": "1904.12608", "submitter": "J\\'an Dolinsk\\'y", "authors": "J\\'an Dolinsk\\'y, M\\'aria Starovsk\\'a, Robert T\\'oth", "title": "Automatic Model Building in GEFCom 2017 Qualifying Match", "comments": "10 pages, 3 figures, competition report", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG stat.ME", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The Tangent Works team participated in GEFCom 2017 to test its automatic\nmodel building strategy for time series known as Tangent Information Modeller\n(TIM). Model building using TIM combined with historical temperature shuffling\nresulted in winning the competition. This strategy involved one remaining\ndegree of freedom, a decision on using a trend variable. This paper describes\nour modelling efforts in the competition, and furthermore outlines a fully\nautomated scenario where the decision on using the trend variable is handled by\nTIM. The results show that such a setup would also win the competition.\n", "versions": [{"version": "v1", "created": "Fri, 12 Apr 2019 15:02:15 GMT"}], "update_date": "2019-04-30", "authors_parsed": [["Dolinsk\u00fd", "J\u00e1n", ""], ["Starovsk\u00e1", "M\u00e1ria", ""], ["T\u00f3th", "Robert", ""]]}, {"id": "1904.12615", "submitter": "Xinyu Li", "authors": "Xinyu Li, Wei Zhang, Tong Shen, Tao Mei", "title": "Everyone is a Cartoonist: Selfie Cartoonization with Attentive\n  Adversarial Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Selfie and cartoon are two popular artistic forms that are widely presented\nin our daily life. Despite the great progress in image translation/stylization,\nfew techniques focus specifically on selfie cartoonization, since cartoon\nimages usually contain artistic abstraction (e.g., large smoothing areas) and\nexaggeration (e.g., large/delicate eyebrows). In this paper, we address this\nproblem by proposing a selfie cartoonization Generative Adversarial Network\n(scGAN), which mainly uses an attentive adversarial network (AAN) to emphasize\nspecific facial regions and ignore low-level details. More specifically, we\nfirst design a cycle-like architecture to enable training with unpaired data.\nThen we design three losses from different aspects. A total variation loss is\nused to highlight important edges and contents in cartoon portraits. An\nattentive cycle loss is added to lay more emphasis on delicate facial areas\nsuch as eyes. In addition, a perceptual loss is included to eliminate artifacts\nand improve robustness of our method. Experimental results show that our method\nis capable of generating different cartoon styles and outperforms a number of\nstate-of-the-art methods.\n", "versions": [{"version": "v1", "created": "Sat, 20 Apr 2019 11:23:40 GMT"}], "update_date": "2019-04-30", "authors_parsed": [["Li", "Xinyu", ""], ["Zhang", "Wei", ""], ["Shen", "Tong", ""], ["Mei", "Tao", ""]]}, {"id": "1904.12617", "submitter": "Danielle Braun", "authors": "Yujia Bao, Zhengyi Deng, Yan Wang, Heeyoon Kim, Victor Diego Armengol,\n  Francisco Acevedo, Nofal Ouardaoui, Cathy Wang, Giovanni Parmigiani, Regina\n  Barzilay, Danielle Braun, Kevin S Hughes", "title": "Using Machine Learning and Natural Language Processing to Review and\n  Classify the Medical Literature on Cancer Susceptibility Genes", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  PURPOSE: The medical literature relevant to germline genetics is growing\nexponentially. Clinicians need tools monitoring and prioritizing the literature\nto understand the clinical implications of the pathogenic genetic variants. We\ndeveloped and evaluated two machine learning models to classify abstracts as\nrelevant to the penetrance (risk of cancer for germline mutation carriers) or\nprevalence of germline genetic mutations. METHODS: We conducted literature\nsearches in PubMed and retrieved paper titles and abstracts to create an\nannotated dataset for training and evaluating the two machine learning\nclassification models. Our first model is a support vector machine (SVM) which\nlearns a linear decision rule based on the bag-of-ngrams representation of each\ntitle and abstract. Our second model is a convolutional neural network (CNN)\nwhich learns a complex nonlinear decision rule based on the raw title and\nabstract. We evaluated the performance of the two models on the classification\nof papers as relevant to penetrance or prevalence. RESULTS: For penetrance\nclassification, we annotated 3740 paper titles and abstracts and used 60% for\ntraining the model, 20% for tuning the model, and 20% for evaluating the model.\nThe SVM model achieves 89.53% accuracy (percentage of papers that were\ncorrectly classified) while the CNN model achieves 88.95 % accuracy. For\nprevalence classification, we annotated 3753 paper titles and abstracts. The\nSVM model achieves 89.14% accuracy while the CNN model achieves 89.13 %\naccuracy. CONCLUSION: Our models achieve high accuracy in classifying abstracts\nas relevant to penetrance or prevalence. By facilitating literature review,\nthis tool could help clinicians and researchers keep abreast of the burgeoning\nknowledge of gene-cancer associations and keep the knowledge bases for clinical\ndecision support tools up to date.\n", "versions": [{"version": "v1", "created": "Wed, 24 Apr 2019 17:20:21 GMT"}], "update_date": "2019-04-30", "authors_parsed": [["Bao", "Yujia", ""], ["Deng", "Zhengyi", ""], ["Wang", "Yan", ""], ["Kim", "Heeyoon", ""], ["Armengol", "Victor Diego", ""], ["Acevedo", "Francisco", ""], ["Ouardaoui", "Nofal", ""], ["Wang", "Cathy", ""], ["Parmigiani", "Giovanni", ""], ["Barzilay", "Regina", ""], ["Braun", "Danielle", ""], ["Hughes", "Kevin S", ""]]}, {"id": "1904.12624", "submitter": "Apostol Vassilev", "authors": "Apostol Vassilev", "title": "BowTie - A deep learning feedforward neural network for sentiment\n  analysis", "comments": "12 pages, 7 figures, 4 tables", "journal-ref": null, "doi": "10.1007/978-3-030-37599-7_30", "report-no": null, "categories": "cs.IR cs.CL cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  How to model and encode the semantics of human-written text and select the\ntype of neural network to process it are not settled issues in sentiment\nanalysis. Accuracy and transferability are critical issues in machine learning\nin general. These properties are closely related to the loss estimates for the\ntrained model. I present a computationally-efficient and accurate feedforward\nneural network for sentiment prediction capable of maintaining low losses. When\ncoupled with an effective semantics model of the text, it provides highly\naccurate models with low losses. Experimental results on representative\nbenchmark datasets and comparisons to other methods show the advantages of the\nnew approach.\n", "versions": [{"version": "v1", "created": "Thu, 18 Apr 2019 13:38:57 GMT"}], "update_date": "2020-06-02", "authors_parsed": [["Vassilev", "Apostol", ""]]}, {"id": "1904.12627", "submitter": "Thomas Hollis", "authors": "Antoine Viscardi, Casey Juanxi Li, Thomas Hollis", "title": "Catch Me If You Can", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  As advances in signature recognition have reached a new plateau of\nperformance at around 2% error rate, it is interesting to investigate\nalternative approaches. The approach detailed in this paper looks at using\nVariational Auto-Encoders (VAEs) to learn a latent space representation of\ngenuine signatures. This is then used to pass unlabelled signatures such that\nonly the genuine ones will successfully be reconstructed by the VAE. This\nlatent space representation and the reconstruction loss is subsequently used by\nrandom forest and kNN classifiers for prediction. Subsequently, VAE\ndisentanglement and the possibility of posterior collapse are ascertained and\nanalysed. The final results suggest that while this method performs less well\nthan existing alternatives, further work may allow this to be used as part of\nan ensemble for future models.\n", "versions": [{"version": "v1", "created": "Thu, 18 Apr 2019 04:36:54 GMT"}], "update_date": "2019-04-30", "authors_parsed": [["Viscardi", "Antoine", ""], ["Li", "Casey Juanxi", ""], ["Hollis", "Thomas", ""]]}, {"id": "1904.12638", "submitter": "Eloi Zablocki", "authors": "Eloi Zablocki, Patrick Bordes, Benjamin Piwowarski, Laure Soulier,\n  Patrick Gallinari", "title": "Context-Aware Zero-Shot Learning for Object Recognition", "comments": "Accepted at ICML 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.CL cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Zero-Shot Learning (ZSL) aims at classifying unlabeled objects by leveraging\nauxiliary knowledge, such as semantic representations. A limitation of previous\napproaches is that only intrinsic properties of objects, e.g. their visual\nappearance, are taken into account while their context, e.g. the surrounding\nobjects in the image, is ignored. Following the intuitive principle that\nobjects tend to be found in certain contexts but not others, we propose a new\nand challenging approach, context-aware ZSL, that leverages semantic\nrepresentations in a new way to model the conditional likelihood of an object\nto appear in a given context. Finally, through extensive experiments conducted\non Visual Genome, we show that contextual information can substantially improve\nthe standard ZSL approach and is robust to unbalanced classes.\n", "versions": [{"version": "v1", "created": "Wed, 24 Apr 2019 08:50:05 GMT"}, {"version": "v2", "created": "Tue, 30 Apr 2019 11:39:52 GMT"}], "update_date": "2019-05-01", "authors_parsed": [["Zablocki", "Eloi", ""], ["Bordes", "Patrick", ""], ["Piwowarski", "Benjamin", ""], ["Soulier", "Laure", ""], ["Gallinari", "Patrick", ""]]}, {"id": "1904.12643", "submitter": "Mohit Sharma", "authors": "Mohit Sharma, F.Maxwell Harper, and George Karypis", "title": "Learning from Sets of Items in Recommender Systems", "comments": "27 pages, 17 figures, ACM TiiS (2019), DOI provided", "journal-ref": null, "doi": "10.1145/3326128", "report-no": null, "categories": "cs.IR cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Most of the existing recommender systems use the ratings provided by users on\nindividual items. An additional source of preference information is to use the\nratings that users provide on sets of items. The advantages of using\npreferences on sets are two-fold. First, a rating provided on a set conveys\nsome preference information about each of the set's items, which allows us to\nacquire a user's preferences for more items that the number of ratings that the\nuser provided. Second, due to privacy concerns, users may not be willing to\nreveal their preferences on individual items explicitly but may be willing to\nprovide a single rating to a set of items, since it provides some level of\ninformation hiding. This paper investigates two questions related to using\nset-level ratings in recommender systems. First, how users' item-level ratings\nrelate to their set-level ratings. Second, how collaborative filtering-based\nmodels for item-level rating prediction can take advantage of such set-level\nratings. We have collected set-level ratings from active users of Movielens on\nsets of movies that they have rated in the past. Our analysis of these ratings\nshows that though the majority of the users provide the average of the ratings\non a set's constituent items as the rating on the set, there exists a\nsignificant number of users that tend to consistently either under- or\nover-rate the sets. We have developed collaborative filtering-based methods to\nexplicitly model these user behaviors that can be used to recommend items to\nusers. Experiments on real data and on synthetic data that resembles the under-\nor over-rating behavior in the real data, demonstrate that these models can\nrecover the overall characteristics of the underlying data and predict the\nuser's ratings on individual items.\n", "versions": [{"version": "v1", "created": "Mon, 22 Apr 2019 04:42:12 GMT"}], "update_date": "2019-04-30", "authors_parsed": [["Sharma", "Mohit", ""], ["Harper", "F. Maxwell", ""], ["Karypis", "George", ""]]}, {"id": "1904.12653", "submitter": "Taylan \\c{S}ahin", "authors": "Taylan \\c{S}ahin, Ramin Khalili, Mate Boban, Adam Wolisz", "title": "Reinforcement Learning Scheduler for Vehicle-to-Vehicle Communications\n  Outside Coverage", "comments": "Article published in IEEE VNC 2018", "journal-ref": null, "doi": "10.1109/VNC.2018.8628366", "report-no": null, "categories": "cs.NI cs.IT cs.LG math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Radio resources in vehicle-to-vehicle (V2V) communication can be scheduled\neither by a centralized scheduler residing in the network (e.g., a base station\nin case of cellular systems) or a distributed scheduler, where the resources\nare autonomously selected by the vehicles. The former approach yields a\nconsiderably higher resource utilization in case the network coverage is\nuninterrupted. However, in case of intermittent or out-of-coverage, due to not\nhaving input from centralized scheduler, vehicles need to revert to distributed\nscheduling. Motivated by recent advances in reinforcement learning (RL), we\ninvestigate whether a centralized learning scheduler can be taught to\nefficiently pre-assign the resources to vehicles for out-of-coverage V2V\ncommunication. Specifically, we use the actor-critic RL algorithm to train the\ncentralized scheduler to provide non-interfering resources to vehicles before\nthey enter the out-of-coverage area. Our initial results show that a RL-based\nscheduler can achieve performance as good as or better than the state-of-art\ndistributed scheduler, often outperforming it. Furthermore, the learning\nprocess completes within a reasonable time (ranging from a few hundred to a few\nthousand epochs), thus making the RL-based scheduler a promising solution for\nV2V communications with intermittent network coverage.\n", "versions": [{"version": "v1", "created": "Mon, 29 Apr 2019 12:45:38 GMT"}], "update_date": "2019-04-30", "authors_parsed": [["\u015eahin", "Taylan", ""], ["Khalili", "Ramin", ""], ["Boban", "Mate", ""], ["Wolisz", "Adam", ""]]}, {"id": "1904.12654", "submitter": "Alberto Bailoni", "authors": "Steffen Wolf, Alberto Bailoni, Constantin Pape, Nasim Rahaman, Anna\n  Kreshuk, Ullrich K\\\"othe, Fred A. Hamprecht", "title": "The Mutex Watershed and its Objective: Efficient, Parameter-Free Graph\n  Partitioning", "comments": null, "journal-ref": "IEEE Transactions on Pattern Analysis and Machine Intelligence\n  (2020) 1-1", "doi": "10.1109/TPAMI.2020.2980827", "report-no": null, "categories": "cs.CV cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Image partitioning, or segmentation without semantics, is the task of\ndecomposing an image into distinct segments, or equivalently to detect closed\ncontours. Most prior work either requires seeds, one per segment; or a\nthreshold; or formulates the task as multicut / correlation clustering, an\nNP-hard problem. Here, we propose an efficient algorithm for graph\npartitioning, the \"Mutex Watershed''. Unlike seeded watershed, the algorithm\ncan accommodate not only attractive but also repulsive cues, allowing it to\nfind a previously unspecified number of segments without the need for explicit\nseeds or a tunable threshold. We also prove that this simple algorithm solves\nto global optimality an objective function that is intimately related to the\nmulticut / correlation clustering integer linear programming formulation. The\nalgorithm is deterministic, very simple to implement, and has empirically\nlinearithmic complexity. When presented with short-range attractive and\nlong-range repulsive cues from a deep neural network, the Mutex Watershed gives\nthe best results currently known for the competitive ISBI 2012 EM segmentation\nbenchmark.\n", "versions": [{"version": "v1", "created": "Thu, 25 Apr 2019 17:29:45 GMT"}, {"version": "v2", "created": "Mon, 19 Apr 2021 13:06:08 GMT"}], "update_date": "2021-04-20", "authors_parsed": [["Wolf", "Steffen", ""], ["Bailoni", "Alberto", ""], ["Pape", "Constantin", ""], ["Rahaman", "Nasim", ""], ["Kreshuk", "Anna", ""], ["K\u00f6the", "Ullrich", ""], ["Hamprecht", "Fred A.", ""]]}, {"id": "1904.12672", "submitter": "Kaifeng Yang", "authors": "Kaifeng Yang, Michael Emmerich, Andr\\'e Deutz, Thomas B\\\"ack", "title": "Efficient Computation of Expected Hypervolume Improvement Using Box\n  Decomposition Algorithms", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In the field of multi-objective optimization algorithms, multi-objective\nBayesian Global Optimization (MOBGO) is an important branch, in addition to\nevolutionary multi-objective optimization algorithms (EMOAs). MOBGO utilizes\nGaussian Process models learned from previous objective function evaluations to\ndecide the next evaluation site by maximizing or minimizing an infill\ncriterion. A common criterion in MOBGO is the Expected Hypervolume Improvement\n(EHVI), which shows a good performance on a wide range of problems, with\nrespect to exploration and exploitation. However, so far it has been a\nchallenge to calculate exact EHVI values efficiently. In this paper, an\nefficient algorithm for the computation of the exact EHVI for a generic case is\nproposed. This efficient algorithm is based on partitioning the integration\nvolume into a set of axis-parallel slices. Theoretically, the upper bound time\ncomplexities are improved from previously $O (n^2)$ and $O(n^3)$, for two- and\nthree-objective problems respectively, to $\\Theta(n\\log n)$, which is\nasymptotically optimal. This article generalizes the scheme in higher\ndimensional case by utilizing a new hyperbox decomposition technique, which was\nproposed by D{\\\"a}chert et al, EJOR, 2017. It also utilizes a generalization of\nthe multilayered integration scheme that scales linearly in the number of\nhyperboxes of the decomposition. The speed comparison shows that the proposed\nalgorithm in this paper significantly reduces computation time. Finally, this\ndecomposition technique is applied in the calculation of the Probability of\nImprovement (PoI).\n", "versions": [{"version": "v1", "created": "Fri, 26 Apr 2019 11:23:26 GMT"}, {"version": "v2", "created": "Thu, 13 Jun 2019 07:31:07 GMT"}], "update_date": "2019-06-14", "authors_parsed": [["Yang", "Kaifeng", ""], ["Emmerich", "Michael", ""], ["Deutz", "Andr\u00e9", ""], ["B\u00e4ck", "Thomas", ""]]}, {"id": "1904.12674", "submitter": "Kyungwoo Song", "authors": "Kyungwoo Song, Mingi Ji, Sungrae Park, Il-Chul Moon", "title": "Hierarchical Context enabled Recurrent Neural Network for Recommendation", "comments": null, "journal-ref": "AAAI 2019", "doi": null, "report-no": null, "categories": "cs.IR cs.LG cs.SI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A long user history inevitably reflects the transitions of personal interests\nover time. The analyses on the user history require the robust sequential model\nto anticipate the transitions and the decays of user interests. The user\nhistory is often modeled by various RNN structures, but the RNN structures in\nthe recommendation system still suffer from the long-term dependency and the\ninterest drifts. To resolve these challenges, we suggest HCRNN with three\nhierarchical contexts of the global, the local, and the temporary interests.\nThis structure is designed to withhold the global long-term interest of users,\nto reflect the local sub-sequence interests, and to attend the temporary\ninterests of each transition. Besides, we propose a hierarchical context-based\ngate structure to incorporate our \\textit{interest drift assumption}. As we\nsuggest a new RNN structure, we support HCRNN with a complementary\n\\textit{bi-channel attention} structure to utilize hierarchical context. We\nexperimented the suggested structure on the sequential recommendation tasks\nwith CiteULike, MovieLens, and LastFM, and our model showed the best\nperformances in the sequential recommendations.\n", "versions": [{"version": "v1", "created": "Fri, 26 Apr 2019 09:07:55 GMT"}], "update_date": "2019-04-30", "authors_parsed": [["Song", "Kyungwoo", ""], ["Ji", "Mingi", ""], ["Park", "Sungrae", ""], ["Moon", "Il-Chul", ""]]}, {"id": "1904.12682", "submitter": "Shunji Umetani", "authors": "Naoya Uematsu, Shunji Umetani, Yoshinobu Kawahara", "title": "An efficient branch-and-cut algorithm for approximately submodular\n  function maximization", "comments": "arXiv admin note: substantial text overlap with arXiv:1811.04177", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.LG math.OC", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  When approaching to problems in computer science, we often encounter\nsituations where a subset of a finite set maximizing some utility function\nneeds to be selected. Some of such utility functions are known to be\napproximately submodular. For the problem of maximizing an approximately\nsubmodular function (ASFM problem), a greedy algorithm quickly finds good\nfeasible solutions for many instances while guaranteeing\n($1-e^{-\\gamma}$)-approximation ratio for a given submodular ratio $\\gamma$.\nHowever, we still encounter its applications that ask more accurate or exactly\noptimal solutions within a reasonable computation time. In this paper, we\npresent an efficient branch-and-cut algorithm for the non-decreasing ASFM\nproblem based on its binary integer programming (BIP) formulation with an\nexponential number of constraints. To this end, we first derive a BIP\nformulation of the ASFM problem and then, develop an improved constraint\ngeneration algorithm that starts from a reduced BIP problem with a small subset\nof constraints and repeats solving the reduced BIP problem while adding a\npromising set of constraints at each iteration. Moreover, we incorporate it\ninto a branch-and-cut algorithm to attain good upper bounds while solving a\nsmaller number of nodes of a search tree. The computational results for three\ntypes of well-known benchmark instances show that our algorithm performs better\nthan the conventional exact algorithms.\n", "versions": [{"version": "v1", "created": "Fri, 26 Apr 2019 05:44:00 GMT"}], "update_date": "2019-04-30", "authors_parsed": [["Uematsu", "Naoya", ""], ["Umetani", "Shunji", ""], ["Kawahara", "Yoshinobu", ""]]}, {"id": "1904.12685", "submitter": "Ranwa Al Mallah", "authors": "Al Mallah Ranwa, Farooq Bilal, Quintero Alejandro", "title": "Distributed Classification of Urban Congestion Using VANET", "comments": "8 pages, transactions, 7 figures", "journal-ref": "IEEE Transactions on Intelligent Transportation Systems, 18(9),\n  2435-2442 (2017)", "doi": "10.1109/TITS.2016.2641903", "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Vehicular Ad-hoc NETworks (VANET) can efficiently detect traffic congestion,\nbut detection is not enough because congestion can be further classified as\nrecurrent and non-recurrent congestion (NRC). In particular, NRC in an urban\nnetwork is mainly caused by incidents, workzones, special events and adverse\nweather. We propose a framework for the real-time distributed classification of\ncongestion into its components on a heterogeneous urban road network using\nVANET. We present models built on an understanding of the spatial and temporal\ncausality measures and trained on synthetic data extended from a real case\nstudy of Cologne. Our performance evaluation shows a predictive accuracy of\n87.63\\% for the deterministic Classification Tree (CT), 88.83\\% for the Naive\nBayesian classifier (NB), 89.51\\% for Random Forest (RF) and 89.17\\% for the\nboosting technique. This framework can assist transportation agencies in\nreducing urban congestion by developing effective congestion mitigation\nstrategies knowing the root causes of congestion.\n", "versions": [{"version": "v1", "created": "Fri, 26 Apr 2019 17:08:01 GMT"}, {"version": "v2", "created": "Fri, 4 Dec 2020 17:05:12 GMT"}], "update_date": "2020-12-07", "authors_parsed": [["Ranwa", "Al Mallah", ""], ["Bilal", "Farooq", ""], ["Alejandro", "Quintero", ""]]}, {"id": "1904.12690", "submitter": "Ruairidh Battleday", "authors": "Ruairidh M. Battleday, Joshua C. Peterson, and Thomas L. Griffiths", "title": "Capturing human categorization of natural images at scale by combining\n  deep networks and cognitive models", "comments": "29 pages; 4 figures. arXiv admin note: text overlap with\n  arXiv:1711.04855", "journal-ref": null, "doi": "10.1038/s41467-020-18946-z", "report-no": null, "categories": "cs.CV cs.AI cs.LG q-bio.NC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Human categorization is one of the most important and successful targets of\ncognitive modeling in psychology, yet decades of development and assessment of\ncompeting models have been contingent on small sets of simple, artificial\nexperimental stimuli. Here we extend this modeling paradigm to the domain of\nnatural images, revealing the crucial role that stimulus representation plays\nin categorization and its implications for conclusions about how people form\ncategories. Applying psychological models of categorization to natural images\nrequired two significant advances. First, we conducted the first large-scale\nexperimental study of human categorization, involving over 500,000 human\ncategorization judgments of 10,000 natural images from ten non-overlapping\nobject categories. Second, we addressed the traditional bottleneck of\nrepresenting high-dimensional images in cognitive models by exploring the best\nof current supervised and unsupervised deep and shallow machine learning\nmethods. We find that selecting sufficiently expressive, data-driven\nrepresentations is crucial to capturing human categorization, and using these\nrepresentations allows simple models that represent categories with abstract\nprototypes to outperform the more complex memory-based exemplar accounts of\ncategorization that have dominated in studies using less naturalistic stimuli.\n", "versions": [{"version": "v1", "created": "Fri, 26 Apr 2019 15:47:59 GMT"}], "update_date": "2021-01-27", "authors_parsed": [["Battleday", "Ruairidh M.", ""], ["Peterson", "Joshua C.", ""], ["Griffiths", "Thomas L.", ""]]}, {"id": "1904.12691", "submitter": "Shangtong Zhang", "authors": "Shangtong Zhang, Shimon Whiteson", "title": "DAC: The Double Actor-Critic Architecture for Learning Options", "comments": "NeurIPS 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We reformulate the option framework as two parallel augmented MDPs. Under\nthis novel formulation, all policy optimization algorithms can be used off the\nshelf to learn intra-option policies, option termination conditions, and a\nmaster policy over options. We apply an actor-critic algorithm on each\naugmented MDP, yielding the Double Actor-Critic (DAC) architecture.\nFurthermore, we show that, when state-value functions are used as critics, one\ncritic can be expressed in terms of the other, and hence only one critic is\nnecessary. We conduct an empirical study on challenging robot simulation tasks.\nIn a transfer learning setting, DAC outperforms both its hierarchy-free\ncounterpart and previous gradient-based option learning algorithms.\n", "versions": [{"version": "v1", "created": "Mon, 29 Apr 2019 14:57:47 GMT"}, {"version": "v2", "created": "Tue, 30 Apr 2019 08:38:00 GMT"}, {"version": "v3", "created": "Mon, 6 May 2019 15:23:29 GMT"}, {"version": "v4", "created": "Thu, 16 May 2019 14:54:53 GMT"}, {"version": "v5", "created": "Mon, 9 Sep 2019 15:37:19 GMT"}, {"version": "v6", "created": "Tue, 10 Sep 2019 08:29:53 GMT"}, {"version": "v7", "created": "Wed, 11 Sep 2019 08:34:22 GMT"}], "update_date": "2019-09-12", "authors_parsed": [["Zhang", "Shangtong", ""], ["Whiteson", "Shimon", ""]]}, {"id": "1904.12694", "submitter": "Bo Kang", "authors": "Bo Kang, Jefrey Lijffijt, Tijl De Bie", "title": "ExplaiNE: An Approach for Explaining Network Embedding-based Link\n  Predictions", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Networks are powerful data structures, but are challenging to work with for\nconventional machine learning methods. Network Embedding (NE) methods attempt\nto resolve this by learning vector representations for the nodes, for\nsubsequent use in downstream machine learning tasks.\n  Link Prediction (LP) is one such downstream machine learning task that is an\nimportant use case and popular benchmark for NE methods. Unfortunately, while\nNE methods perform exceedingly well at this task, they are lacking in\ntransparency as compared to simpler LP approaches.\n  We introduce ExplaiNE, an approach to offer counterfactual explanations for\nNE-based LP methods, by identifying existing links in the network that explain\nthe predicted links. ExplaiNE is applicable to a broad class of NE algorithms.\nAn extensive empirical evaluation for the NE method `Conditional Network\nEmbedding' in particular demonstrates its accuracy and scalability.\n", "versions": [{"version": "v1", "created": "Mon, 22 Apr 2019 08:38:02 GMT"}], "update_date": "2019-04-30", "authors_parsed": [["Kang", "Bo", ""], ["Lijffijt", "Jefrey", ""], ["De Bie", "Tijl", ""]]}, {"id": "1904.12760", "submitter": "Xin Chen", "authors": "Xin Chen, Lingxi Xie, Jun Wu and Qi Tian", "title": "Progressive Differentiable Architecture Search: Bridging the Depth Gap\n  between Search and Evaluation", "comments": "10 pages, 3 figures, 3 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recently, differentiable search methods have made major progress in reducing\nthe computational costs of neural architecture search. However, these\napproaches often report lower accuracy in evaluating the searched architecture\nor transferring it to another dataset. This is arguably due to the large gap\nbetween the architecture depths in search and evaluation scenarios. In this\npaper, we present an efficient algorithm which allows the depth of searched\narchitectures to grow gradually during the training procedure. This brings two\nissues, namely, heavier computational overheads and weaker search stability,\nwhich we solve using search space approximation and regularization,\nrespectively. With a significantly reduced search time (~7 hours on a single\nGPU), our approach achieves state-of-the-art performance on both the proxy\ndataset (CIFAR10 or CIFAR100) and the target dataset (ImageNet). Code is\navailable at https://github.com/chenxin061/pdarts.\n", "versions": [{"version": "v1", "created": "Mon, 29 Apr 2019 14:59:28 GMT"}], "update_date": "2019-04-30", "authors_parsed": [["Chen", "Xin", ""], ["Xie", "Lingxi", ""], ["Wu", "Jun", ""], ["Tian", "Qi", ""]]}, {"id": "1904.12769", "submitter": "Sharath Adavanne", "authors": "Sharath Adavanne, Archontis Politis, Tuomas Virtanen", "title": "Localization, Detection and Tracking of Multiple Moving Sound Sources\n  with a Convolutional Recurrent Neural Network", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SD cs.LG eess.AS", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  This paper investigates the joint localization, detection, and tracking of\nsound events using a convolutional recurrent neural network (CRNN). We use a\nCRNN previously proposed for the localization and detection of stationary\nsources, and show that the recurrent layers enable the spatial tracking of\nmoving sources when trained with dynamic scenes. The tracking performance of\nthe CRNN is compared with a stand-alone tracking method that combines a\nmulti-source (DOA) estimator and a particle filter. Their respective\nperformance is evaluated in various acoustic conditions such as anechoic and\nreverberant scenarios, stationary and moving sources at several angular\nvelocities, and with a varying number of overlapping sources. The results show\nthat the CRNN manages to track multiple sources more consistently than the\nparametric method across acoustic scenarios, but at the cost of higher\nlocalization error.\n", "versions": [{"version": "v1", "created": "Mon, 29 Apr 2019 15:26:47 GMT"}], "update_date": "2019-04-30", "authors_parsed": [["Adavanne", "Sharath", ""], ["Politis", "Archontis", ""], ["Virtanen", "Tuomas", ""]]}, {"id": "1904.12770", "submitter": "Mohammed Amer", "authors": "Mohammed Amer, Tom\\'as Maul", "title": "A Review of Modularization Techniques in Artificial Neural Networks", "comments": "Artif Intell Rev (2019)", "journal-ref": null, "doi": "10.1007/s10462-019-09706-7", "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Artificial neural networks (ANNs) have achieved significant success in\ntackling classical and modern machine learning problems. As learning problems\ngrow in scale and complexity, and expand into multi-disciplinary territory, a\nmore modular approach for scaling ANNs will be needed. Modular neural networks\n(MNNs) are neural networks that embody the concepts and principles of\nmodularity. MNNs adopt a large number of different techniques for achieving\nmodularization. Previous surveys of modularization techniques are relatively\nscarce in their systematic analysis of MNNs, focusing mostly on empirical\ncomparisons and lacking an extensive taxonomical framework. In this review, we\naim to establish a solid taxonomy that captures the essential properties and\nrelationships of the different variants of MNNs. Based on an investigation of\nthe different levels at which modularization techniques act, we attempt to\nprovide a universal and systematic framework for theorists studying MNNs, also\ntrying along the way to emphasise the strengths and weaknesses of different\nmodularization approaches in order to highlight good practices for neural\nnetwork practitioners.\n", "versions": [{"version": "v1", "created": "Mon, 29 Apr 2019 15:28:14 GMT"}], "update_date": "2019-04-30", "authors_parsed": [["Amer", "Mohammed", ""], ["Maul", "Tom\u00e1s", ""]]}, {"id": "1904.12773", "submitter": "Zeyu Ding", "authors": "Zeyu Ding, Yuxin Wang, Danfeng Zhang, Daniel Kifer", "title": "Free Gap Information from the Differentially Private Sparse Vector and\n  Noisy Max Mechanisms", "comments": "16 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR cs.DB stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Noisy Max and Sparse Vector are selection algorithms for differential privacy\nand serve as building blocks for more complex algorithms. In this paper we show\nthat both algorithms can release additional information for free (i.e., at no\nadditional privacy cost). Noisy Max is used to return the approximate maximizer\namong a set of queries. We show that it can also release for free the noisy gap\nbetween the approximate maximizer and runner-up. This free information can\nimprove the accuracy of certain subsequent counting queries by up to 50%.\nSparse Vector is used to return a set of queries that are approximately larger\nthan a fixed threshold. We show that it can adaptively control its privacy\nbudget (use less budget for queries that are likely to be much larger than the\nthreshold) in order to increase the amount of queries it can process. These\nresults follow from a careful privacy analysis.\n", "versions": [{"version": "v1", "created": "Mon, 29 Apr 2019 15:31:13 GMT"}, {"version": "v2", "created": "Thu, 2 May 2019 02:30:23 GMT"}, {"version": "v3", "created": "Sun, 15 Sep 2019 16:34:49 GMT"}], "update_date": "2019-09-17", "authors_parsed": [["Ding", "Zeyu", ""], ["Wang", "Yuxin", ""], ["Zhang", "Danfeng", ""], ["Kifer", "Daniel", ""]]}, {"id": "1904.12774", "submitter": "Clemens Rosenbaum", "authors": "Clemens Rosenbaum, Ignacio Cases, Matthew Riemer, Tim Klinger", "title": "Routing Networks and the Challenges of Modular and Compositional\n  Computation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Compositionality is a key strategy for addressing combinatorial complexity\nand the curse of dimensionality. Recent work has shown that compositional\nsolutions can be learned and offer substantial gains across a variety of\ndomains, including multi-task learning, language modeling, visual question\nanswering, machine comprehension, and others. However, such models present\nunique challenges during training when both the module parameters and their\ncomposition must be learned jointly. In this paper, we identify several of\nthese issues and analyze their underlying causes. Our discussion focuses on\nrouting networks, a general approach to this problem, and examines empirically\nthe interplay of these challenges and a variety of design decisions. In\nparticular, we consider the effect of how the algorithm decides on module\ncomposition, how the algorithm updates the modules, and if the algorithm uses\nregularization.\n", "versions": [{"version": "v1", "created": "Mon, 29 Apr 2019 15:32:14 GMT"}], "update_date": "2019-04-30", "authors_parsed": [["Rosenbaum", "Clemens", ""], ["Cases", "Ignacio", ""], ["Riemer", "Matthew", ""], ["Klinger", "Tim", ""]]}, {"id": "1904.12787", "submitter": "Yujia Li", "authors": "Yujia Li, Chenjie Gu, Thomas Dullien, Oriol Vinyals, Pushmeet Kohli", "title": "Graph Matching Networks for Learning the Similarity of Graph Structured\n  Objects", "comments": "Accepted as a conference paper at ICML 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper addresses the challenging problem of retrieval and matching of\ngraph structured objects, and makes two key contributions. First, we\ndemonstrate how Graph Neural Networks (GNN), which have emerged as an effective\nmodel for various supervised prediction problems defined on structured data,\ncan be trained to produce embedding of graphs in vector spaces that enables\nefficient similarity reasoning. Second, we propose a novel Graph Matching\nNetwork model that, given a pair of graphs as input, computes a similarity\nscore between them by jointly reasoning on the pair through a new cross-graph\nattention-based matching mechanism. We demonstrate the effectiveness of our\nmodels on different domains including the challenging problem of\ncontrol-flow-graph based function similarity search that plays an important\nrole in the detection of vulnerabilities in software systems. The experimental\nanalysis demonstrates that our models are not only able to exploit structure in\nthe context of similarity learning but they can also outperform domain-specific\nbaseline systems that have been carefully hand-engineered for these problems.\n", "versions": [{"version": "v1", "created": "Mon, 29 Apr 2019 15:59:04 GMT"}, {"version": "v2", "created": "Sun, 12 May 2019 22:15:33 GMT"}], "update_date": "2019-05-14", "authors_parsed": [["Li", "Yujia", ""], ["Gu", "Chenjie", ""], ["Dullien", "Thomas", ""], ["Vinyals", "Oriol", ""], ["Kohli", "Pushmeet", ""]]}, {"id": "1904.12831", "submitter": "Ian Williamson", "authors": "Tyler W. Hughes, Ian A. D. Williamson, Momchil Minkov, Shanhui Fan", "title": "Wave Physics as an Analog Recurrent Neural Network", "comments": "13 pages, 6 figures", "journal-ref": "Science Advances, vol. 5, no. 12, p. eaay6946, Dec. 2019", "doi": "10.1126/sciadv.aay6946", "report-no": null, "categories": "physics.comp-ph cs.LG cs.NE physics.optics", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Analog machine learning hardware platforms promise to be faster and more\nenergy-efficient than their digital counterparts. Wave physics, as found in\nacoustics and optics, is a natural candidate for building analog processors for\ntime-varying signals. Here we identify a mapping between the dynamics of wave\nphysics, and the computation in recurrent neural networks. This mapping\nindicates that physical wave systems can be trained to learn complex features\nin temporal data, using standard training techniques for neural networks. As a\ndemonstration, we show that an inverse-designed inhomogeneous medium can\nperform vowel classification on raw audio signals as their waveforms scatter\nand propagate through it, achieving performance comparable to a standard\ndigital implementation of a recurrent neural network. These findings pave the\nway for a new class of analog machine learning platforms, capable of fast and\nefficient processing of information in its native domain.\n", "versions": [{"version": "v1", "created": "Mon, 29 Apr 2019 17:27:35 GMT"}, {"version": "v2", "created": "Fri, 20 Dec 2019 19:22:10 GMT"}], "update_date": "2019-12-24", "authors_parsed": [["Hughes", "Tyler W.", ""], ["Williamson", "Ian A. D.", ""], ["Minkov", "Momchil", ""], ["Fan", "Shanhui", ""]]}, {"id": "1904.12834", "submitter": "Bowei Chen", "authors": "Yu Zheng and Yongxin Yang and Bowei Chen", "title": "Incorporating prior financial domain knowledge into neural networks for\n  implied volatility surface prediction", "comments": "8 pages, SIGKDD 2021", "journal-ref": null, "doi": "10.1145/3447548.3467115", "report-no": null, "categories": "q-fin.CP cs.LG cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we develop a novel neural network model for predicting implied\nvolatility surface. Prior financial domain knowledge is taken into account. A\nnew activation function that incorporates volatility smile is proposed, which\nis used for the hidden nodes that process the underlying asset price. In\naddition, financial conditions, such as the absence of arbitrage, the\nboundaries and the asymptotic slope, are embedded into the loss function. This\nis one of the very first studies which discuss a methodological framework that\nincorporates prior financial domain knowledge into neural network architecture\ndesign and model training. The proposed model outperforms the benchmarked\nmodels with the option data on the S&P 500 index over 20 years. More\nimportantly, the domain knowledge is satisfied empirically, showing the model\nis consistent with the existing financial theories and conditions related to\nimplied volatility surface.\n", "versions": [{"version": "v1", "created": "Mon, 29 Apr 2019 17:35:41 GMT"}, {"version": "v2", "created": "Sun, 26 May 2019 21:13:58 GMT"}, {"version": "v3", "created": "Thu, 13 Jun 2019 22:32:10 GMT"}, {"version": "v4", "created": "Thu, 30 Jan 2020 23:43:33 GMT"}, {"version": "v5", "created": "Fri, 28 May 2021 14:26:23 GMT"}], "update_date": "2021-05-31", "authors_parsed": [["Zheng", "Yu", ""], ["Yang", "Yongxin", ""], ["Chen", "Bowei", ""]]}, {"id": "1904.12838", "submitter": "Rahul Kidambi", "authors": "Rong Ge, Sham M. Kakade, Rahul Kidambi and Praneeth Netrapalli", "title": "The Step Decay Schedule: A Near Optimal, Geometrically Decaying Learning\n  Rate Procedure For Least Squares", "comments": "Appears in the proceedings of the Conference on Neural Information\n  Processing Systems (NeurIPS), 2019. 28 pages, 4 tables, 1 Algorithm, 7\n  figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG math.OC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Minimax optimal convergence rates for classes of stochastic convex\noptimization problems are well characterized, where the majority of results\nutilize iterate averaged stochastic gradient descent (SGD) with polynomially\ndecaying step sizes. In contrast, SGD's final iterate behavior has received\nmuch less attention despite their widespread use in practice. Motivated by this\nobservation, this work provides a detailed study of the following question:\nwhat rate is achievable using the final iterate of SGD for the streaming least\nsquares regression problem with and without strong convexity?\n  First, this work shows that even if the time horizon T (i.e. the number of\niterations SGD is run for) is known in advance, SGD's final iterate behavior\nwith any polynomially decaying learning rate scheme is highly sub-optimal\ncompared to the minimax rate (by a condition number factor in the strongly\nconvex case and a factor of $\\sqrt{T}$ in the non-strongly convex case). In\ncontrast, this paper shows that Step Decay schedules, which cut the learning\nrate by a constant factor every constant number of epochs (i.e., the learning\nrate decays geometrically) offers significant improvements over any\npolynomially decaying step sizes. In particular, the final iterate behavior\nwith a step decay schedule is off the minimax rate by only $log$ factors (in\nthe condition number for strongly convex case, and in T for the non-strongly\nconvex case). Finally, in stark contrast to the known horizon case, this paper\nshows that the anytime (i.e. the limiting) behavior of SGD's final iterate is\npoor (in that it queries iterates with highly sub-optimal function value\ninfinitely often, i.e. in a limsup sense) irrespective of the stepsizes\nemployed. These results demonstrate the subtlety in establishing optimal\nlearning rate schemes (for the final iterate) for stochastic gradient\nprocedures in fixed time horizon settings.\n", "versions": [{"version": "v1", "created": "Mon, 29 Apr 2019 17:41:27 GMT"}, {"version": "v2", "created": "Tue, 29 Oct 2019 04:04:19 GMT"}], "update_date": "2019-10-30", "authors_parsed": [["Ge", "Rong", ""], ["Kakade", "Sham M.", ""], ["Kidambi", "Rahul", ""], ["Netrapalli", "Praneeth", ""]]}, {"id": "1904.12840", "submitter": "Giorgio Patrini", "authors": "Tim van Elsloo, Giorgio Patrini, Hamish Ivey-Law", "title": "SEALion: a Framework for Neural Network Inference on Encrypted Data", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present SEALion: an extensible framework for privacy-preserving machine\nlearning with homomorphic encryption. It allows one to learn deep neural\nnetworks that can be seamlessly utilized for prediction on encrypted data. The\nframework consists of two layers: the first is built upon TensorFlow and SEAL\nand exposes standard algebra and deep learning primitives; the second\nimplements a Keras-like syntax for training and inference with neural networks.\nGiven a required level of security, a user is abstracted from the details of\nthe encoding and the encryption scheme, allowing quick prototyping. We present\ntwo applications that exemplifying the extensibility of our proposal, which are\nalso of independent interest: i) improving efficiency of neural network\ninference by an activity sparsifier and ii) transfer learning by querying a\nserver-side Variational AutoEncoder that can handle encrypted data.\n", "versions": [{"version": "v1", "created": "Mon, 29 Apr 2019 17:42:25 GMT"}], "update_date": "2019-04-30", "authors_parsed": [["van Elsloo", "Tim", ""], ["Patrini", "Giorgio", ""], ["Ivey-Law", "Hamish", ""]]}, {"id": "1904.12843", "submitter": "Mahyar Najibi", "authors": "Ali Shafahi, Mahyar Najibi, Amin Ghiasi, Zheng Xu, John Dickerson,\n  Christoph Studer, Larry S. Davis, Gavin Taylor, Tom Goldstein", "title": "Adversarial Training for Free!", "comments": "Accepted to NeurIPS 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Adversarial training, in which a network is trained on adversarial examples,\nis one of the few defenses against adversarial attacks that withstands strong\nattacks. Unfortunately, the high cost of generating strong adversarial examples\nmakes standard adversarial training impractical on large-scale problems like\nImageNet. We present an algorithm that eliminates the overhead cost of\ngenerating adversarial examples by recycling the gradient information computed\nwhen updating model parameters. Our \"free\" adversarial training algorithm\nachieves comparable robustness to PGD adversarial training on the CIFAR-10 and\nCIFAR-100 datasets at negligible additional cost compared to natural training,\nand can be 7 to 30 times faster than other strong adversarial training methods.\nUsing a single workstation with 4 P100 GPUs and 2 days of runtime, we can train\na robust model for the large-scale ImageNet classification task that maintains\n40% accuracy against PGD attacks. The code is available at\nhttps://github.com/ashafahi/free_adv_train.\n", "versions": [{"version": "v1", "created": "Mon, 29 Apr 2019 17:50:32 GMT"}, {"version": "v2", "created": "Wed, 20 Nov 2019 21:26:19 GMT"}], "update_date": "2019-11-22", "authors_parsed": [["Shafahi", "Ali", ""], ["Najibi", "Mahyar", ""], ["Ghiasi", "Amin", ""], ["Xu", "Zheng", ""], ["Dickerson", "John", ""], ["Studer", "Christoph", ""], ["Davis", "Larry S.", ""], ["Taylor", "Gavin", ""], ["Goldstein", "Tom", ""]]}, {"id": "1904.12846", "submitter": "Atakan Okan", "authors": "Juan Zamudio-Fernandez, Atakan Okan, Francisco Villaescusa-Navarro,\n  Seda Bilaloglu, Asena Derin Cengiz, Siyu He, Laurence Perreault Levasseur,\n  Shirley Ho", "title": "HIGAN: Cosmic Neutral Hydrogen with Generative Adversarial Networks", "comments": "9 pages, 8 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "astro-ph.CO astro-ph.IM cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  One of the most promising ways to observe the Universe is by detecting the\n21cm emission from cosmic neutral hydrogen (HI) through radio-telescopes. Those\nobservations can shed light on fundamental astrophysical questions only if\naccurate theoretical predictions are available. In order to maximize the\nscientific return of these surveys, those predictions need to include different\nobservables and be precise on non-linear scales. Currently, one of the best\nways to achieve this is via cosmological hydrodynamic simulations; however, the\ncomputational cost of these simulations is high -- tens of millions of CPU\nhours. In this work, we use Wasserstein Generative Adversarial Networks (WGANs)\nto generate new high-resolution ($35~h^{-1}{\\rm kpc}$) 3D realizations of\ncosmic HI at $z=5$. We do so by sampling from a 100-dimension manifold, learned\nby the generator, that characterizes the fully non-linear abundance and\nclustering of cosmic HI from the state-of-the-art simulation IllustrisTNG. We\nshow that different statistical properties of the produced samples -- 1D PDF,\npower spectrum, bispectrum, and void size function -- match very well those of\nIllustrisTNG, and outperform state-of-the-art models such as Halo Occupation\nDistributions (HODs). Our WGAN samples reproduce the abundance of HI across 9\norders of magnitude, from the Ly$\\alpha$ forest to Damped Lyman Absorbers. WGAN\ncan produce new samples orders of magnitude faster than hydrodynamic\nsimulations.\n", "versions": [{"version": "v1", "created": "Mon, 29 Apr 2019 17:56:01 GMT"}], "update_date": "2019-04-30", "authors_parsed": [["Zamudio-Fernandez", "Juan", ""], ["Okan", "Atakan", ""], ["Villaescusa-Navarro", "Francisco", ""], ["Bilaloglu", "Seda", ""], ["Cengiz", "Asena Derin", ""], ["He", "Siyu", ""], ["Levasseur", "Laurence Perreault", ""], ["Ho", "Shirley", ""]]}, {"id": "1904.12847", "submitter": "Xiyang Hu", "authors": "Xiyang Hu, Cynthia Rudin, Margo Seltzer", "title": "Optimal Sparse Decision Trees", "comments": "33rd Conference on Neural Information Processing Systems (NeurIPS\n  2019), Vancouver, Canada", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Decision tree algorithms have been among the most popular algorithms for\ninterpretable (transparent) machine learning since the early 1980's. The\nproblem that has plagued decision tree algorithms since their inception is\ntheir lack of optimality, or lack of guarantees of closeness to optimality:\ndecision tree algorithms are often greedy or myopic, and sometimes produce\nunquestionably suboptimal models. Hardness of decision tree optimization is\nboth a theoretical and practical obstacle, and even careful mathematical\nprogramming approaches have not been able to solve these problems efficiently.\nThis work introduces the first practical algorithm for optimal decision trees\nfor binary variables. The algorithm is a co-design of analytical bounds that\nreduce the search space and modern systems techniques, including data\nstructures and a custom bit-vector library. Our experiments highlight\nadvantages in scalability, speed, and proof of optimality.\n", "versions": [{"version": "v1", "created": "Mon, 29 Apr 2019 17:56:34 GMT"}, {"version": "v2", "created": "Mon, 16 Dec 2019 04:40:34 GMT"}, {"version": "v3", "created": "Tue, 17 Dec 2019 01:23:37 GMT"}, {"version": "v4", "created": "Tue, 14 Jul 2020 22:42:16 GMT"}, {"version": "v5", "created": "Fri, 18 Sep 2020 00:51:41 GMT"}], "update_date": "2020-09-21", "authors_parsed": [["Hu", "Xiyang", ""], ["Rudin", "Cynthia", ""], ["Seltzer", "Margo", ""]]}, {"id": "1904.12848", "submitter": "Qizhe Xie", "authors": "Qizhe Xie, Zihang Dai, Eduard Hovy, Minh-Thang Luong, Quoc V. Le", "title": "Unsupervised Data Augmentation for Consistency Training", "comments": "NeurIPS 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CL cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Semi-supervised learning lately has shown much promise in improving deep\nlearning models when labeled data is scarce. Common among recent approaches is\nthe use of consistency training on a large amount of unlabeled data to\nconstrain model predictions to be invariant to input noise. In this work, we\npresent a new perspective on how to effectively noise unlabeled examples and\nargue that the quality of noising, specifically those produced by advanced data\naugmentation methods, plays a crucial role in semi-supervised learning. By\nsubstituting simple noising operations with advanced data augmentation methods\nsuch as RandAugment and back-translation, our method brings substantial\nimprovements across six language and three vision tasks under the same\nconsistency training framework. On the IMDb text classification dataset, with\nonly 20 labeled examples, our method achieves an error rate of 4.20,\noutperforming the state-of-the-art model trained on 25,000 labeled examples. On\na standard semi-supervised learning benchmark, CIFAR-10, our method outperforms\nall previous approaches and achieves an error rate of 5.43 with only 250\nexamples. Our method also combines well with transfer learning, e.g., when\nfinetuning from BERT, and yields improvements in high-data regime, such as\nImageNet, whether when there is only 10% labeled data or when a full labeled\nset with 1.3M extra unlabeled examples is used. Code is available at\nhttps://github.com/google-research/uda.\n", "versions": [{"version": "v1", "created": "Mon, 29 Apr 2019 17:56:59 GMT"}, {"version": "v2", "created": "Wed, 10 Jul 2019 17:53:48 GMT"}, {"version": "v3", "created": "Thu, 26 Sep 2019 15:32:11 GMT"}, {"version": "v4", "created": "Mon, 30 Sep 2019 15:40:40 GMT"}, {"version": "v5", "created": "Thu, 25 Jun 2020 17:58:43 GMT"}, {"version": "v6", "created": "Thu, 5 Nov 2020 15:11:02 GMT"}], "update_date": "2020-11-06", "authors_parsed": [["Xie", "Qizhe", ""], ["Dai", "Zihang", ""], ["Hovy", "Eduard", ""], ["Luong", "Minh-Thang", ""], ["Le", "Quoc V.", ""]]}, {"id": "1904.12856", "submitter": "Utkarsh Porwal", "authors": "Utkarsh Porwal", "title": "Learning Image Information for eCommerce Queries", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Computing similarity between a query and a document is fundamental in any\ninformation retrieval system. In search engines, computing query-document\nsimilarity is an essential step in both retrieval and ranking stages. In eBay\nsearch, document is an item and the query-item similarity can be computed by\ncomparing different facets of the query-item pair. Query text can be compared\nwith the text of the item title. Likewise, a category constraint applied on the\nquery can be compared with the listing category of the item. However, images\nare one signal that are usually present in the items but are not present in the\nquery. Images are one of the most intuitive signals used by users to determine\nthe relevance of the item given a query. Including this signal in estimating\nsimilarity between the query-item pair is likely to improve the relevance of\nthe search engine. We propose a novel way of deriving image information for\nqueries. We attempt to learn image information for queries from item images\ninstead of generating explicit image features or an image for queries. We use\ncanonical correlation analysis (CCA) to learn a new subspace where projecting\nthe original data will give us a new query and item representation. We\nhypothesize that this new query representation will also have image information\nabout the query. We estimate the query-item similarity using a vector space\nmodel and report the performance of the proposed method on eBay's search data.\nWe show 11.89\\% relevance improvement over the baseline using area under the\nreceiver operating characteristic curve (AUROC) as the evaluation metric. We\nalso show 3.1\\% relevance improvement over the baseline with area under the\nprecision recall curve (AUPRC) .\n", "versions": [{"version": "v1", "created": "Mon, 29 Apr 2019 23:48:31 GMT"}], "update_date": "2019-05-01", "authors_parsed": [["Porwal", "Utkarsh", ""]]}, {"id": "1904.12857", "submitter": "Quanming Yao", "authors": "Yuanfei Luo and Mengshuo Wang and Hao Zhou and Quanming Yao and WeiWei\n  Tu and Yuqiang Chen and Qiang Yang and Wenyuan Dai", "title": "AutoCross: Automatic Feature Crossing for Tabular Data in Real-World\n  Applications", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Feature crossing captures interactions among categorical features and is\nuseful to enhance learning from tabular data in real-world businesses. In this\npaper, we present AutoCross, an automatic feature crossing tool provided by\n4Paradigm to its customers, ranging from banks, hospitals, to Internet\ncorporations. By performing beam search in a tree-structured space, AutoCross\nenables efficient generation of high-order cross features, which is not yet\nvisited by existing works. Additionally, we propose successive mini-batch\ngradient descent and multi-granularity discretization to further improve\nefficiency and effectiveness, while ensuring simplicity so that no machine\nlearning expertise or tedious hyper-parameter tuning is required. Furthermore,\nthe algorithms are designed to reduce the computational, transmitting, and\nstorage costs involved in distributed computing. Experimental results on both\nbenchmark and real-world business datasets demonstrate the effectiveness and\nefficiency of AutoCross. It is shown that AutoCross can significantly enhance\nthe performance of both linear and deep models.\n", "versions": [{"version": "v1", "created": "Mon, 29 Apr 2019 13:05:23 GMT"}, {"version": "v2", "created": "Mon, 15 Jul 2019 13:55:58 GMT"}], "update_date": "2019-07-16", "authors_parsed": [["Luo", "Yuanfei", ""], ["Wang", "Mengshuo", ""], ["Zhou", "Hao", ""], ["Yao", "Quanming", ""], ["Tu", "WeiWei", ""], ["Chen", "Yuqiang", ""], ["Yang", "Qiang", ""], ["Dai", "Wenyuan", ""]]}, {"id": "1904.12887", "submitter": "Allison Koenecke", "authors": "Allison Koenecke and Amita Gajewar", "title": "Curriculum Learning in Deep Neural Networks for Financial Forecasting", "comments": null, "journal-ref": null, "doi": "10.1007/978-3-030-37720-5_2", "report-no": null, "categories": "cs.LG q-fin.GN stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  For any financial organization, computing accurate quarterly forecasts for\nvarious products is one of the most critical operations. As the granularity at\nwhich forecasts are needed increases, traditional statistical time series\nmodels may not scale well. We apply deep neural networks in the forecasting\ndomain by experimenting with techniques from Natural Language Processing\n(Encoder-Decoder LSTMs) and Computer Vision (Dilated CNNs), as well as\nincorporating transfer learning. A novel contribution of this paper is the\napplication of curriculum learning to neural network models built for time\nseries forecasting. We illustrate the performance of our models using\nMicrosoft's revenue data corresponding to Enterprise, and Small, Medium &\nCorporate products, spanning approximately 60 regions across the globe for 8\ndifferent business segments, and totaling in the order of tens of billions of\nUSD. We compare our models' performance to the ensemble model of traditional\nstatistics and machine learning techniques currently used by Microsoft Finance.\nWith this in-production model as a baseline, our experiments yield an\napproximately 30% improvement in overall accuracy on test data. We find that\nour curriculum learning LSTM-based model performs best, showing that it is\nreasonable to implement our proposed methods without overfitting on\nmedium-sized data.\n", "versions": [{"version": "v1", "created": "Mon, 29 Apr 2019 18:09:31 GMT"}, {"version": "v2", "created": "Wed, 24 Jul 2019 02:27:56 GMT"}], "update_date": "2020-01-28", "authors_parsed": [["Koenecke", "Allison", ""], ["Gajewar", "Amita", ""]]}, {"id": "1904.12901", "submitter": "Gabriel Dulac-Arnold", "authors": "Gabriel Dulac-Arnold, Daniel Mankowitz, Todd Hester", "title": "Challenges of Real-World Reinforcement Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.RO stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Reinforcement learning (RL) has proven its worth in a series of artificial\ndomains, and is beginning to show some successes in real-world scenarios.\nHowever, much of the research advances in RL are often hard to leverage in\nreal-world systems due to a series of assumptions that are rarely satisfied in\npractice. We present a set of nine unique challenges that must be addressed to\nproductionize RL to real world problems. For each of these challenges, we\nspecify the exact meaning of the challenge, present some approaches from the\nliterature, and specify some metrics for evaluating that challenge. An approach\nthat addresses all nine challenges would be applicable to a large number of\nreal world problems. We also present an example domain that has been modified\nto present these challenges as a testbed for practical RL research.\n", "versions": [{"version": "v1", "created": "Mon, 29 Apr 2019 18:40:15 GMT"}], "update_date": "2019-05-01", "authors_parsed": [["Dulac-Arnold", "Gabriel", ""], ["Mankowitz", "Daniel", ""], ["Hester", "Todd", ""]]}, {"id": "1904.12904", "submitter": "Nathan Wycoff", "authors": "Nathan Wycoff, Prasanna Balaprakash, Fangfang Xia", "title": "Neuromorphic Acceleration for Approximate Bayesian Inference on Neural\n  Networks via Permanent Dropout", "comments": "4 pages, 4 figures. Submitted to International Conference on\n  Neuromorphic Systems (ICONS) 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  As neural networks have begun performing increasingly critical tasks for\nsociety, ranging from driving cars to identifying candidates for drug\ndevelopment, the value of their ability to perform uncertainty quantification\n(UQ) in their predictions has risen commensurately. Permanent dropout, a\npopular method for neural network UQ, involves injecting stochasticity into the\ninference phase of the model and creating many predictions for each of the test\ndata. This shifts the computational and energy burden of deep neural networks\nfrom the training phase to the inference phase. Recent work has demonstrated\nnear-lossless conversion of classical deep neural networks to their spiking\ncounterparts. We use these results to demonstrate the feasibility of conducting\nthe inference phase with permanent dropout on spiking neural networks,\nmitigating the technique's computational and energy burden, which is essential\nfor its use at scale or on edge platforms. We demonstrate the proposed approach\nvia the Nengo spiking neural simulator on a combination drug therapy dataset\nfor cancer treatment, where UQ is critical. Our results indicate that the\nspiking approximation gives a predictive distribution practically\nindistinguishable from that given by the classical network.\n", "versions": [{"version": "v1", "created": "Mon, 29 Apr 2019 18:43:07 GMT"}], "update_date": "2019-05-01", "authors_parsed": [["Wycoff", "Nathan", ""], ["Balaprakash", "Prasanna", ""], ["Xia", "Fangfang", ""]]}, {"id": "1904.12926", "submitter": "Bowen Shi", "authors": "Bowen Shi, Ming Sun, Chieh-Chi Kao, Viktor Rozgic, Spyros Matsoukas,\n  Chao Wang", "title": "Semi-supervised Acoustic Event Detection based on tri-training", "comments": "5 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.AS cs.LG cs.SD", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper presents our work of training acoustic event detection (AED)\nmodels using unlabeled dataset. Recent acoustic event detectors are based on\nlarge-scale neural networks, which are typically trained with huge amounts of\nlabeled data. Labels for acoustic events are expensive to obtain, and relevant\nacoustic event audios can be limited, especially for rare events. In this paper\nwe leverage an Internet-scale unlabeled dataset with potential domain shift to\nimprove the detection of acoustic events. Based on the classic tri-training\napproach, our proposed method shows accuracy improvement over both the\nsupervised training baseline, and semisupervised self-training set-up, in all\npre-defined acoustic event detection tasks. As our approach relies on ensemble\nmodels, we further show the improvements can be distilled to a single model via\nknowledge distillation, with the resulting single student model maintaining\nhigh accuracy of teacher ensemble models.\n", "versions": [{"version": "v1", "created": "Mon, 29 Apr 2019 19:51:22 GMT"}], "update_date": "2019-05-01", "authors_parsed": [["Shi", "Bowen", ""], ["Sun", "Ming", ""], ["Kao", "Chieh-Chi", ""], ["Rozgic", "Viktor", ""], ["Matsoukas", "Spyros", ""], ["Wang", "Chao", ""]]}, {"id": "1904.12933", "submitter": "Murphy Yuezhen Niu", "authors": "Murphy Yuezhen Niu, Lior Horesh, Isaac Chuang", "title": "Recurrent Neural Networks in the Eye of Differential Equations", "comments": "25pages, 3 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG quant-ph stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  To understand the fundamental trade-offs between training stability, temporal\ndynamics and architectural complexity of recurrent neural networks~(RNNs), we\ndirectly analyze RNN architectures using numerical methods of ordinary\ndifferential equations~(ODEs). We define a general family of RNNs--the\nODERNNs--by relating the composition rules of RNNs to integration methods of\nODEs at discrete time steps. We show that the degree of RNN's functional\nnonlinearity $n$ and the range of its temporal memory $t$ can be mapped to the\ncorresponding stage of Runge-Kutta recursion and the order of time-derivative\nof the ODEs. We prove that popular RNN architectures, such as LSTM and URNN,\nfit into different orders of $n$-$t$-ODERNNs. This exact correspondence between\nRNN and ODE helps us to establish the sufficient conditions for RNN training\nstability and facilitates more flexible top-down designs of new RNN\narchitectures using large varieties of toolboxes from numerical integration of\nODEs. We provide such an example: Quantum-inspired Universal computing Neural\nNetwork~(QUNN), which reduces the required number of training parameters from\npolynomial in both data length and temporal memory length to only linear in\ntemporal memory length.\n", "versions": [{"version": "v1", "created": "Mon, 29 Apr 2019 20:16:20 GMT"}], "update_date": "2019-05-01", "authors_parsed": [["Niu", "Murphy Yuezhen", ""], ["Horesh", "Lior", ""], ["Chuang", "Isaac", ""]]}, {"id": "1904.12935", "submitter": "Jihun Oh", "authors": "Jihun Oh, Kyunghyun Cho, and Joan Bruna", "title": "Advancing GraphSAGE with A Data-Driven Node Sampling", "comments": "6 pages, 2 tables, ICLR 2019 workshop on Representation Learning on\n  Graphs and Manifolds", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  As an efficient and scalable graph neural network, GraphSAGE has enabled an\ninductive capability for inferring unseen nodes or graphs by aggregating\nsubsampled local neighborhoods and by learning in a mini-batch gradient descent\nfashion. The neighborhood sampling used in GraphSAGE is effective in order to\nimprove computing and memory efficiency when inferring a batch of target nodes\nwith diverse degrees in parallel. Despite this advantage, the default uniform\nsampling suffers from high variance in training and inference, leading to\nsub-optimum accuracy. We propose a new data-driven sampling approach to reason\nabout the real-valued importance of a neighborhood by a non-linear regressor,\nand to use the value as a criterion for subsampling neighborhoods. The\nregressor is learned using a value-based reinforcement learning. The implied\nimportance for each combination of vertex and neighborhood is inductively\nextracted from the negative classification loss output of GraphSAGE. As a\nresult, in an inductive node classification benchmark using three datasets, our\nmethod enhanced the baseline using the uniform sampling, outperforming recent\nvariants of a graph neural network in accuracy.\n", "versions": [{"version": "v1", "created": "Mon, 29 Apr 2019 20:22:03 GMT"}], "update_date": "2019-05-01", "authors_parsed": [["Oh", "Jihun", ""], ["Cho", "Kyunghyun", ""], ["Bruna", "Joan", ""]]}, {"id": "1904.12952", "submitter": "Cristian Alecsa", "authors": "Cristian Daniel Alecsa, Titus Pinta and Imre Boros", "title": "New optimization algorithms for neural network training using operator\n  splitting techniques", "comments": "21 pages, 6 tables, 7 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG math.OC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In the following paper we present a new type of optimization algorithms\nadapted for neural network training. These algorithms are based upon sequential\noperator splitting technique for some associated dynamical systems.\nFurthermore, we investigate through numerical simulations the empirical rate of\nconvergence of these iterative schemes toward a local minimum of the loss\nfunction, with some suitable choices of the underlying hyper-parameters. We\nvalidate the convergence of these optimizers using the results of the accuracy\nand of the loss function on the MNIST, MNIST-Fashion and CIFAR 10\nclassification datasets.\n", "versions": [{"version": "v1", "created": "Mon, 29 Apr 2019 21:29:47 GMT"}, {"version": "v2", "created": "Sat, 15 Jun 2019 13:27:21 GMT"}, {"version": "v3", "created": "Wed, 29 Jan 2020 18:10:21 GMT"}, {"version": "v4", "created": "Thu, 30 Jan 2020 08:33:48 GMT"}, {"version": "v5", "created": "Sat, 21 Mar 2020 14:02:42 GMT"}], "update_date": "2020-03-24", "authors_parsed": [["Alecsa", "Cristian Daniel", ""], ["Pinta", "Titus", ""], ["Boros", "Imre", ""]]}, {"id": "1904.12969", "submitter": "Gregory Rehm", "authors": "Gregory B. Rehm, Brooks T. Kuhn, Jimmy Nguyen, Nicholas R. Anderson,\n  Chen-Nee Chuah, Jason Y. Adams", "title": "Improving Mechanical Ventilator Clinical Decision Support Systems with A\n  Machine Learning Classifier for Determining Ventilator Mode", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Clinical decision support systems (CDSS) will play an in-creasing role in\nimproving the quality of medical care for critically ill patients. However, due\nto limitations in current informatics infrastructure, CDSS do not always have\ncom-plete information on state of supporting physiologic monitor-ing devices,\nwhich can limit the input data available to CDSS. This is especially true in\nthe use case of mechanical ventilation (MV), where current CDSS have no\nknowledge of critical ventilation settings, such as ventilation mode. To enable\nMV CDSS to make accurate recommendations related to ventilator mode, we\ndeveloped a highly performant ma-chine learning model that is able to perform\nper-breath clas-sification of 5 of the most widely used ventilation modes in\nthe USA with an average F1-score of 97.52%. We also show how our approach makes\nmethodologic improvements over previous work and that it is highly robust to\nmissing data caused by software/sensor error.\n", "versions": [{"version": "v1", "created": "Mon, 29 Apr 2019 21:59:03 GMT"}], "update_date": "2019-05-01", "authors_parsed": [["Rehm", "Gregory B.", ""], ["Kuhn", "Brooks T.", ""], ["Nguyen", "Jimmy", ""], ["Anderson", "Nicholas R.", ""], ["Chuah", "Chen-Nee", ""], ["Adams", "Jason Y.", ""]]}, {"id": "1904.12970", "submitter": "S\\'ebastien Bougleux", "authors": "Xuan Son Nguyen and Luc Brun and Olivier L\\'ezoray and S\\'ebastien\n  Bougleux", "title": "A neural network based on SPD manifold learning for skeleton-based hand\n  gesture recognition", "comments": "Accepted at CVPR 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG cs.NE", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  This paper proposes a new neural network based on SPD manifold learning for\nskeleton-based hand gesture recognition. Given the stream of hand's joint\npositions, our approach combines two aggregation processes on respectively\nspatial and temporal domains. The pipeline of our network architecture consists\nin three main stages. The first stage is based on a convolutional layer to\nincrease the discriminative power of learned features. The second stage relies\non different architectures for spatial and temporal Gaussian aggregation of\njoint features. The third stage learns a final SPD matrix from skeletal data. A\nnew type of layer is proposed for the third stage, based on a variant of\nstochastic gradient descent on Stiefel manifolds. The proposed network is\nvalidated on two challenging datasets and shows state-of-the-art accuracies on\nboth datasets.\n", "versions": [{"version": "v1", "created": "Mon, 29 Apr 2019 21:59:14 GMT"}], "update_date": "2019-05-01", "authors_parsed": [["Nguyen", "Xuan Son", ""], ["Brun", "Luc", ""], ["L\u00e9zoray", "Olivier", ""], ["Bougleux", "S\u00e9bastien", ""]]}, {"id": "1904.12973", "submitter": "Gunnar R\\\"atsch", "authors": "Stefan G. Stark, Stephanie L. Hyland, Melanie F. Pradier, Kjong\n  Lehmann, Andreas Wicki, Fernando Perez Cruz, Julia E. Vogt, Gunnar R\\\"atsch", "title": "Unsupervised Extraction of Phenotypes from Cancer Clinical Notes for\n  Association Studies", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CL stat.AP stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The recent adoption of Electronic Health Records (EHRs) by health care\nproviders has introduced an important source of data that provides detailed and\nhighly specific insights into patient phenotypes over large cohorts. These\ndatasets, in combination with machine learning and statistical approaches,\ngenerate new opportunities for research and clinical care. However, many\nmethods require the patient representations to be in structured formats, while\nthe information in the EHR is often locked in unstructured texts designed for\nhuman readability. In this work, we develop the methodology to automatically\nextract clinical features from clinical narratives from large EHR corpora\nwithout the need for prior knowledge. We consider medical terms and sentences\nappearing in clinical narratives as atomic information units. We propose an\nefficient clustering strategy suitable for the analysis of large text corpora\nand to utilize the clusters to represent information about the patient\ncompactly. To demonstrate the utility of our approach, we perform an\nassociation study of clinical features with somatic mutation profiles from\n4,007 cancer patients and their tumors. We apply the proposed algorithm to a\ndataset consisting of about 65 thousand documents with a total of about 3.2\nmillion sentences. We identify 341 significant statistical associations between\nthe presence of somatic mutations and clinical features. We annotated these\nassociations according to their novelty, and report several known associations.\nWe also propose 32 testable hypotheses where the underlying biological\nmechanism does not appear to be known but plausible. These results illustrate\nthat the automated discovery of clinical features is possible and the joint\nanalysis of clinical and genetic datasets can generate appealing new\nhypotheses.\n", "versions": [{"version": "v1", "created": "Mon, 29 Apr 2019 22:15:22 GMT"}, {"version": "v2", "created": "Fri, 3 May 2019 14:13:56 GMT"}], "update_date": "2019-05-06", "authors_parsed": [["Stark", "Stefan G.", ""], ["Hyland", "Stephanie L.", ""], ["Pradier", "Melanie F.", ""], ["Lehmann", "Kjong", ""], ["Wicki", "Andreas", ""], ["Cruz", "Fernando Perez", ""], ["Vogt", "Julia E.", ""], ["R\u00e4tsch", "Gunnar", ""]]}, {"id": "1904.12987", "submitter": "Jia Peng", "authors": "Peng Jia and Yifei Zhao and Gang Xue and Dongmei Cai", "title": "Optical Transient Object Classification in Wide Field Small Aperture\n  Telescopes with Neural Networks", "comments": "13 pages, 10 figures. Accepted by AJ and all the code can be\n  downloaded from aojp.lamost.org. Comments welcome", "journal-ref": null, "doi": "10.3847/1538-3881/ab1e52", "report-no": null, "categories": "astro-ph.IM cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Wide field small aperture telescopes are working horses for fast sky\nsurveying. Transient discovery is one of their main tasks. Classification of\ncandidate transient images between real sources and artifacts with high\naccuracy is an important step for transient discovery. In this paper, we\npropose two transient classification methods based on neural networks. The\nfirst method uses the convolutional neural network without pooling layers to\nclassify transient images with low sampling rate. The second method assumes\ntransient images as one dimensional signals and is based on recurrent neural\nnetworks with long short term memory and leaky ReLu activation function in each\ndetection layer. Testing with real observation data, we find that although\nthese two methods can both achieve more than 94% classification accuracy, they\nhave different classification properties for different targets. Based on this\nresult, we propose to use the ensemble learning method to further increase the\nclassification accuracy to more than 97%.\n", "versions": [{"version": "v1", "created": "Mon, 29 Apr 2019 23:16:05 GMT"}], "update_date": "2019-07-17", "authors_parsed": [["Jia", "Peng", ""], ["Zhao", "Yifei", ""], ["Xue", "Gang", ""], ["Cai", "Dongmei", ""]]}, {"id": "1904.12991", "submitter": "Yiming Sun", "authors": "Yujia Zhang, Kuangyan Song, Yiming Sun, Sarah Tan, Madeleine Udell", "title": "\"Why Should You Trust My Explanation?\" Understanding Uncertainty in LIME\n  Explanations", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Methods for interpreting machine learning black-box models increase the\noutcomes' transparency and in turn generates insight into the reliability and\nfairness of the algorithms. However, the interpretations themselves could\ncontain significant uncertainty that undermines the trust in the outcomes and\nraises concern about the model's reliability. Focusing on the method \"Local\nInterpretable Model-agnostic Explanations\" (LIME), we demonstrate the presence\nof two sources of uncertainty, namely the randomness in its sampling procedure\nand the variation of interpretation quality across different input data points.\nSuch uncertainty is present even in models with high training and test\naccuracy. We apply LIME to synthetic data and two public data sets, text\nclassification in 20 Newsgroup and recidivism risk-scoring in COMPAS, to\nsupport our argument.\n", "versions": [{"version": "v1", "created": "Mon, 29 Apr 2019 23:49:19 GMT"}, {"version": "v2", "created": "Tue, 4 Jun 2019 07:46:54 GMT"}], "update_date": "2019-06-05", "authors_parsed": [["Zhang", "Yujia", ""], ["Song", "Kuangyan", ""], ["Sun", "Yiming", ""], ["Tan", "Sarah", ""], ["Udell", "Madeleine", ""]]}, {"id": "1904.13000", "submitter": "Florian Tram\\`er", "authors": "Florian Tram\\`er and Dan Boneh", "title": "Adversarial Training and Robustness for Multiple Perturbations", "comments": "Accepted at NeurIPS 2019, 23 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Defenses against adversarial examples, such as adversarial training, are\ntypically tailored to a single perturbation type (e.g., small\n$\\ell_\\infty$-noise). For other perturbations, these defenses offer no\nguarantees and, at times, even increase the model's vulnerability. Our aim is\nto understand the reasons underlying this robustness trade-off, and to train\nmodels that are simultaneously robust to multiple perturbation types. We prove\nthat a trade-off in robustness to different types of $\\ell_p$-bounded and\nspatial perturbations must exist in a natural and simple statistical setting.\nWe corroborate our formal analysis by demonstrating similar robustness\ntrade-offs on MNIST and CIFAR10. Building upon new multi-perturbation\nadversarial training schemes, and a novel efficient attack for finding\n$\\ell_1$-bounded adversarial examples, we show that no model trained against\nmultiple attacks achieves robustness competitive with that of models trained on\neach attack individually. In particular, we uncover a pernicious\ngradient-masking phenomenon on MNIST, which causes adversarial training with\nfirst-order $\\ell_\\infty, \\ell_1$ and $\\ell_2$ adversaries to achieve merely\n$50\\%$ accuracy. Our results question the viability and computational\nscalability of extending adversarial robustness, and adversarial training, to\nmultiple perturbation types.\n", "versions": [{"version": "v1", "created": "Tue, 30 Apr 2019 00:22:29 GMT"}, {"version": "v2", "created": "Fri, 18 Oct 2019 01:53:18 GMT"}], "update_date": "2019-10-21", "authors_parsed": [["Tram\u00e8r", "Florian", ""], ["Boneh", "Dan", ""]]}, {"id": "1904.13001", "submitter": "Austin Slakey", "authors": "Austin Slakey, Daniel Salas, Yoni Schamroth", "title": "Encoding Categorical Variables with Conjugate Bayesian Models for WeWork\n  Lead Scoring Engine", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Applied Data Scientists throughout various industries are commonly faced with\nthe challenging task of encoding high-cardinality categorical features into\ndigestible inputs for machine learning algorithms. This paper describes a\nBayesian encoding technique developed for WeWork's lead scoring engine which\noutputs the probability of a person touring one of our office spaces based on\ninteraction, enrichment, and geospatial data. We present a paradigm for\nensemble modeling which mitigates the need to build complicated preprocessing\nand encoding schemes for categorical variables. In particular, domain-specific\nconjugate Bayesian models are employed as base learners for features in a\nstacked ensemble model. For each column of a categorical feature matrix we fit\na problem-specific prior distribution, for example, the Beta distribution for a\nbinary classification problem. In order to analytically derive the moments of\nthe posterior distribution, we update the prior with the conjugate likelihood\nof the corresponding target variable for each unique value of the given\ncategorical feature. This function of column and value encodes the categorical\nfeature matrix so that the final learner in the ensemble model ingests\nlow-dimensional numerical input. Experimental results on both curated and real\nworld datasets demonstrate impressive accuracy and computational efficiency on\na variety of problem archetypes. Particularly, for the lead scoring engine at\nWeWork -- where some categorical features have as many as 300,000 levels -- we\nhave seen an AUC improvement from 0.87 to 0.97 through implementing conjugate\nBayesian model encoding.\n", "versions": [{"version": "v1", "created": "Tue, 30 Apr 2019 00:24:06 GMT"}], "update_date": "2019-05-01", "authors_parsed": [["Slakey", "Austin", ""], ["Salas", "Daniel", ""], ["Schamroth", "Yoni", ""]]}, {"id": "1904.13007", "submitter": "Zhaofei Yu", "authors": "Yichen Zhang and Shanshan Jia and Yajing Zheng and Zhaofei Yu and\n  Yonghong Tian and Siwei Ma and Tiejun Huang and Jian K. Liu", "title": "Reconstruction of Natural Visual Scenes from Neural Spikes with Deep\n  Neural Networks", "comments": "35 pages, 10 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.NC cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Neural coding is one of the central questions in systems neuroscience for\nunderstanding how the brain processes stimulus from the environment, moreover,\nit is also a cornerstone for designing algorithms of brain-machine interface,\nwhere decoding incoming stimulus is highly demanded for better performance of\nphysical devices. Traditionally researchers have focused on functional magnetic\nresonance imaging (fMRI) data as the neural signals of interest for decoding\nvisual scenes. However, our visual perception operates in a fast time scale of\nmillisecond in terms of an event termed neural spike. There are few studies of\ndecoding by using spikes. Here we fulfill this aim by developing a novel\ndecoding framework based on deep neural networks, named spike-image decoder\n(SID), for reconstructing natural visual scenes, including static images and\ndynamic videos, from experimentally recorded spikes of a population of retinal\nganglion cells. The SID is an end-to-end decoder with one end as neural spikes\nand the other end as images, which can be trained directly such that visual\nscenes are reconstructed from spikes in a highly accurate fashion. Our SID also\noutperforms on the reconstruction of visual stimulus compared to existing fMRI\ndecoding models. In addition, with the aid of a spike encoder, we show that SID\ncan be generalized to arbitrary visual scenes by using the image datasets of\nMNIST, CIFAR10, and CIFAR100. Furthermore, with a pre-trained SID, one can\ndecode any dynamic videos to achieve real-time encoding and decoding of visual\nscenes by spikes. Altogether, our results shed new light on neuromorphic\ncomputing for artificial visual systems, such as event-based visual cameras and\nvisual neuroprostheses.\n", "versions": [{"version": "v1", "created": "Tue, 30 Apr 2019 01:15:24 GMT"}, {"version": "v2", "created": "Tue, 28 Jan 2020 13:04:24 GMT"}], "update_date": "2020-01-29", "authors_parsed": [["Zhang", "Yichen", ""], ["Jia", "Shanshan", ""], ["Zheng", "Yajing", ""], ["Yu", "Zhaofei", ""], ["Tian", "Yonghong", ""], ["Ma", "Siwei", ""], ["Huang", "Tiejun", ""], ["Liu", "Jian K.", ""]]}, {"id": "1904.13015", "submitter": "Sanghyun Yi", "authors": "Sanghyun Yi, Rahul Goel, Chandra Khatri, Alessandra Cervone, Tagyoung\n  Chung, Behnam Hedayatnia, Anu Venkatesh, Raefer Gabriel, Dilek Hakkani-Tur", "title": "Towards Coherent and Engaging Spoken Dialog Response Generation Using\n  Automatic Conversation Evaluators", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Encoder-decoder based neural architectures serve as the basis of\nstate-of-the-art approaches in end-to-end open domain dialog systems. Since\nmost of such systems are trained with a maximum likelihood~(MLE) objective they\nsuffer from issues such as lack of generalizability and the generic response\nproblem, i.e., a system response that can be an answer to a large number of\nuser utterances, e.g., \"Maybe, I don't know.\" Having explicit feedback on the\nrelevance and interestingness of a system response at each turn can be a useful\nsignal for mitigating such issues and improving system quality by selecting\nresponses from different approaches. Towards this goal, we present a system\nthat evaluates chatbot responses at each dialog turn for coherence and\nengagement. Our system provides explicit turn-level dialog quality feedback,\nwhich we show to be highly correlated with human evaluation. To show that\nincorporating this feedback in the neural response generation models improves\ndialog quality, we present two different and complementary mechanisms to\nincorporate explicit feedback into a neural response generation model:\nreranking and direct modification of the loss function during training. Our\nstudies show that a response generation model that incorporates these combined\nfeedback mechanisms produce more engaging and coherent responses in an\nopen-domain spoken dialog setting, significantly improving the response quality\nusing both automatic and human evaluation.\n", "versions": [{"version": "v1", "created": "Tue, 30 Apr 2019 02:03:05 GMT"}, {"version": "v2", "created": "Thu, 2 May 2019 18:50:50 GMT"}, {"version": "v3", "created": "Sat, 21 Sep 2019 18:24:42 GMT"}, {"version": "v4", "created": "Fri, 22 Nov 2019 03:06:41 GMT"}], "update_date": "2019-11-25", "authors_parsed": [["Yi", "Sanghyun", ""], ["Goel", "Rahul", ""], ["Khatri", "Chandra", ""], ["Cervone", "Alessandra", ""], ["Chung", "Tagyoung", ""], ["Hedayatnia", "Behnam", ""], ["Venkatesh", "Anu", ""], ["Gabriel", "Raefer", ""], ["Hakkani-Tur", "Dilek", ""]]}, {"id": "1904.13016", "submitter": "Xin Tong Thomson", "authors": "Xi Chen and Simon S. Du and Xin T. Tong", "title": "On Stationary-Point Hitting Time and Ergodicity of Stochastic Gradient\n  Langevin Dynamics", "comments": "41 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Stochastic gradient Langevin dynamics (SGLD) is a fundamental algorithm in\nstochastic optimization. Recent work by Zhang et al. [2017] presents an\nanalysis for the hitting time of SGLD for the first and second order stationary\npoints. The proof in Zhang et al. [2017] is a two-stage procedure through\nbounding the Cheeger's constant, which is rather complicated and leads to loose\nbounds. In this paper, using intuitions from stochastic differential equations,\nwe provide a direct analysis for the hitting times of SGLD to the first and\nsecond order stationary points. Our analysis is straightforward. It only relies\non basic linear algebra and probability theory tools. Our direct analysis also\nleads to tighter bounds comparing to Zhang et al. [2017] and shows the explicit\ndependence of the hitting time on different factors, including dimensionality,\nsmoothness, noise strength, and step size effects. Under suitable conditions,\nwe show that the hitting time of SGLD to first-order stationary points can be\ndimension-independent. Moreover, we apply our analysis to study several\nimportant online estimation problems in machine learning, including linear\nregression, matrix factorization, and online PCA.\n", "versions": [{"version": "v1", "created": "Tue, 30 Apr 2019 02:03:11 GMT"}, {"version": "v2", "created": "Wed, 29 May 2019 03:37:12 GMT"}, {"version": "v3", "created": "Sun, 13 Oct 2019 06:30:29 GMT"}, {"version": "v4", "created": "Sun, 15 Mar 2020 22:42:14 GMT"}], "update_date": "2020-03-17", "authors_parsed": [["Chen", "Xi", ""], ["Du", "Simon S.", ""], ["Tong", "Xin T.", ""]]}, {"id": "1904.13032", "submitter": "Ekram Hossain", "authors": "Kazi Ishfaq Ahmed and Ekram Hossain", "title": "A Deep Q-Learning Method for Downlink Power Allocation in Multi-Cell\n  Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI cs.LG eess.SP stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Optimal resource allocation is a fundamental challenge for dense and\nheterogeneous wireless networks with massive wireless connections. Because of\nthe non-convex nature of the optimization problem, it is computationally\ndemanding to obtain the optimal resource allocation. Recently, deep\nreinforcement learning (DRL) has emerged as a promising technique in solving\nnon-convex optimization problems. Unlike deep learning (DL), DRL does not\nrequire any optimal/ near-optimal training dataset which is either unavailable\nor computationally expensive in generating synthetic data. In this paper, we\npropose a novel centralized DRL based downlink power allocation scheme for a\nmulti-cell system intending to maximize the total network throughput.\nSpecifically, we apply a deep Q-learning (DQL) approach to achieve near-optimal\npower allocation policy. For benchmarking the proposed approach, we use a\nGenetic Algorithm (GA) to obtain near-optimal power allocation solution.\nSimulation results show that the proposed DRL-based power allocation scheme\nperforms better compared to the conventional power allocation schemes in a\nmulti-cell scenario.\n", "versions": [{"version": "v1", "created": "Tue, 30 Apr 2019 03:18:39 GMT"}], "update_date": "2019-05-01", "authors_parsed": [["Ahmed", "Kazi Ishfaq", ""], ["Hossain", "Ekram", ""]]}, {"id": "1904.13033", "submitter": "Harald Steck", "authors": "Harald Steck", "title": "Collaborative Filtering via High-Dimensional Regression", "comments": "10 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  While the SLIM approach obtained high ranking-accuracy in many experiments in\nthe literature, it is also known for its high computational cost of learning\nits parameters from data. For this reason, we focus in this paper on variants\nof high-dimensional regression problems that have closed-form solutions.\nMoreover, we motivate a re-scaling rather than a re-weighting approach for\ndealing with biases regarding item-popularities in the data. We also discuss\nproperties of the sparse solution, and outline a computationally efficient\napproximation. In experiments on three publicly available data sets, we\nobserved not only extremely reduced training times, but also significantly\nimproved ranking accuracy compared to SLIM. Surprisingly, various\nstate-of-the-art models, including deep non-linear autoencoders, were also\noutperformed on two of the three data sets in our experiments, in particular\nfor recommendations with highly personalized relevance.\n", "versions": [{"version": "v1", "created": "Tue, 30 Apr 2019 03:21:19 GMT"}], "update_date": "2019-05-01", "authors_parsed": [["Steck", "Harald", ""]]}, {"id": "1904.13036", "submitter": "Qi Wang", "authors": "Qi Wang, Fahong Zhang and Xuelong Li", "title": "Optimal Clustering Framework for Hyperspectral Band Selection", "comments": null, "journal-ref": "IEEE Trans. Geoscience and Remote Sensing, vol. 56, no. 10, pp.\n  5910-5922, 2018", "doi": "10.1109/TGRS.2018.2828161", "report-no": null, "categories": "eess.IV cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Band selection, by choosing a set of representative bands in hyperspectral\nimage (HSI), is an effective method to reduce the redundant information without\ncompromising the original contents. Recently, various unsupervised band\nselection methods have been proposed, but most of them are based on\napproximation algorithms which can only obtain suboptimal solutions toward a\nspecific objective function. This paper focuses on clustering-based band\nselection, and proposes a new framework to solve the above dilemma, claiming\nthe following contributions: 1) An optimal clustering framework (OCF), which\ncan obtain the optimal clustering result for a particular form of objective\nfunction under a reasonable constraint. 2) A rank on clusters strategy (RCS),\nwhich provides an effective criterion to select bands on existing clustering\nstructure. 3) An automatic method to determine the number of the required\nbands, which can better evaluate the distinctive information produced by\ncertain number of bands. In experiments, the proposed algorithm is compared to\nsome state-of-the-art competitors. According to the experimental results, the\nproposed algorithm is robust and significantly outperform the other methods on\nvarious data sets.\n", "versions": [{"version": "v1", "created": "Tue, 30 Apr 2019 03:26:44 GMT"}], "update_date": "2019-05-01", "authors_parsed": [["Wang", "Qi", ""], ["Zhang", "Fahong", ""], ["Li", "Xuelong", ""]]}, {"id": "1904.13041", "submitter": "Yifeng Jiang", "authors": "Yifeng Jiang, Tom Van Wouwe, Friedl De Groote, C. Karen Liu", "title": "Synthesis of Biologically Realistic Human Motion Using Joint Torque\n  Actuation", "comments": "SIGGRAPH 2019. 12 pages, 8 figures. Accompanying video:\n  https://youtu.be/3UxfF_BmDxY", "journal-ref": null, "doi": "10.1145/3306346.3322966", "report-no": null, "categories": "cs.GR cs.LG cs.RO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Using joint actuators to drive the skeletal movements is a common practice in\ncharacter animation, but the resultant torque patterns are often unnatural or\ninfeasible for real humans to achieve. On the other hand, physiologically-based\nmodels explicitly simulate muscles and tendons and thus produce more human-like\nmovements and torque patterns. This paper introduces a technique to transform\nan optimal control problem formulated in the muscle-actuation space to an\nequivalent problem in the joint-actuation space, such that the solutions to\nboth problems have the same optimal value. By solving the equivalent problem in\nthe joint-actuation space, we can generate human-like motions comparable to\nthose generated by musculotendon models, while retaining the benefit of simple\nmodeling and fast computation offered by joint-actuation models. Our method\ntransforms constant bounds on muscle activations to nonlinear, state-dependent\ntorque limits in the joint-actuation space. In addition, the metabolic energy\nfunction on muscle activations is transformed to a nonlinear function of joint\ntorques, joint configuration and joint velocity. Our technique can also benefit\npolicy optimization using deep reinforcement learning approach, by providing a\nmore anatomically realistic action space for the agent to explore during the\nlearning process. We take the advantage of the physiologically-based simulator,\nOpenSim, to provide training data for learning the torque limits and the\nmetabolic energy function. Once trained, the same torque limits and the energy\nfunction can be applied to drastically different motor tasks formulated as\neither trajectory optimization or policy learning. Codebase:\nhttps://github.com/jyf588/lrle and https://github.com/jyf588/lrle-rl-examples\n", "versions": [{"version": "v1", "created": "Tue, 30 Apr 2019 03:55:30 GMT"}, {"version": "v2", "created": "Thu, 22 Aug 2019 06:17:50 GMT"}], "update_date": "2019-08-23", "authors_parsed": [["Jiang", "Yifeng", ""], ["Van Wouwe", "Tom", ""], ["De Groote", "Friedl", ""], ["Liu", "C. Karen", ""]]}, {"id": "1904.13052", "submitter": "Haiping Huang", "authors": "Tianqi Hou, and K.Y. Michael Wong, and Haiping Huang", "title": "Minimal model of permutation symmetry in unsupervised learning", "comments": "36 pages, 110 equations, 5 figures; a complete picture about physical\n  laws of unsupervised learning in neural networks presented", "journal-ref": "2019 J. Phys. A: Math. Theor. 52 414001", "doi": "10.1088/1751-8121/ab3f3f", "report-no": null, "categories": "cond-mat.dis-nn cond-mat.stat-mech cs.LG q-bio.NC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Permutation of any two hidden units yields invariant properties in typical\ndeep generative neural networks. This permutation symmetry plays an important\nrole in understanding the computation performance of a broad class of neural\nnetworks with two or more hidden units. However, a theoretical study of the\npermutation symmetry is still lacking. Here, we propose a minimal model with\nonly two hidden units in a restricted Boltzmann machine, which aims to address\nhow the permutation symmetry affects the critical learning data size at which\nthe concept-formation (or spontaneous symmetry breaking in physics language)\nstarts, and moreover semi-rigorously prove a conjecture that the critical data\nsize is independent of the number of hidden units once this number is finite.\nRemarkably, we find that the embedded correlation between two receptive fields\nof hidden units reduces the critical data size. In particular, the\nweakly-correlated receptive fields have the benefit of significantly reducing\nthe minimal data size that triggers the transition, given less noisy data.\nInspired by the theory, we also propose an efficient fully-distributed\nalgorithm to infer the receptive fields of hidden units. Furthermore, our\nminimal model reveals that the permutation symmetry can also be spontaneously\nbroken following the spontaneous symmetry breaking. Overall, our results\ndemonstrate that the unsupervised learning is a progressive combination of\nspontaneous symmetry breaking and permutation symmetry breaking which are both\nspontaneous processes driven by data streams (observations). All these effects\ncan be analytically probed based on the minimal model, providing theoretical\ninsights towards understanding unsupervised learning in a more general context.\n", "versions": [{"version": "v1", "created": "Tue, 30 Apr 2019 05:08:14 GMT"}, {"version": "v2", "created": "Mon, 12 Aug 2019 01:31:58 GMT"}], "update_date": "2019-09-17", "authors_parsed": [["Hou", "Tianqi", ""], ["Wong", "K. Y. Michael", ""], ["Huang", "Haiping", ""]]}, {"id": "1904.13081", "submitter": "Bhaskar Mukhoty", "authors": "Bhaskar Pratim Mukhoty, Vikas Maurya, Sandeep Kumar Shukla", "title": "Sequence to sequence deep learning models for solar irradiation\n  forecasting", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The energy output a photo voltaic(PV) panel is a function of solar\nirradiation and weather parameters like temperature and wind speed etc. A\ngeneral measure for solar irradiation called Global Horizontal Irradiance\n(GHI), customarily reported in Watt/meter$^2$, is a generic indicator for this\nintermittent energy resource. An accurate prediction of GHI is necessary for\nreliable grid integration of the renewable as well as for power market trading.\nWhile some machine learning techniques are well introduced along with the\ntraditional time-series forecasting techniques, deep-learning techniques\nremains less explored for the task at hand. In this paper we give deep learning\nmodels suitable for sequence to sequence prediction of GHI. The deep learning\nmodels are reported for short-term forecasting $\\{1-24\\}$ hour along with the\nstate-of-the art techniques like Gradient Boosted Regression Trees(GBRT) and\nFeed Forward Neural Networks(FFNN).\n  We have checked that spatio-temporal features like wind direction, wind speed\nand GHI of neighboring location improves the prediction accuracy of the deep\nlearning models significantly. Among the various sequence-to-sequence\nencoder-decoder models LSTM performed superior, handling short-comings of the\nstate-of-the-art techniques.\n", "versions": [{"version": "v1", "created": "Tue, 30 Apr 2019 07:28:33 GMT"}], "update_date": "2019-05-01", "authors_parsed": [["Mukhoty", "Bhaskar Pratim", ""], ["Maurya", "Vikas", ""], ["Shukla", "Sandeep Kumar", ""]]}, {"id": "1904.13094", "submitter": "Francesco Crecchi", "authors": "Francesco Crecchi, Davide Bacciu and Battista Biggio", "title": "Detecting Adversarial Examples through Nonlinear Dimensionality\n  Reduction", "comments": "European Symposium on Artificial Neural Networks, Computational\n  Intelligence and Machine Learning (ESANN) 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep neural networks are vulnerable to adversarial examples, i.e.,\ncarefully-perturbed inputs aimed to mislead classification. This work proposes\na detection method based on combining non-linear dimensionality reduction and\ndensity estimation techniques. Our empirical findings show that the proposed\napproach is able to effectively detect adversarial examples crafted by\nnon-adaptive attackers, i.e., not specifically tuned to bypass the detection\nmethod. Given our promising results, we plan to extend our analysis to adaptive\nattackers in future work.\n", "versions": [{"version": "v1", "created": "Tue, 30 Apr 2019 07:59:52 GMT"}, {"version": "v2", "created": "Wed, 1 May 2019 17:30:58 GMT"}], "update_date": "2019-05-02", "authors_parsed": [["Crecchi", "Francesco", ""], ["Bacciu", "Davide", ""], ["Biggio", "Battista", ""]]}, {"id": "1904.13107", "submitter": "Yao Ma", "authors": "Yao Ma, Suhang Wang, Charu C. Aggarwal, Jiliang Tang", "title": "Graph Convolutional Networks with EigenPooling", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Graph neural networks, which generalize deep neural network models to graph\nstructured data, have attracted increasing attention in recent years. They\nusually learn node representations by transforming, propagating and aggregating\nnode features and have been proven to improve the performance of many graph\nrelated tasks such as node classification and link prediction. To apply graph\nneural networks for the graph classification task, approaches to generate the\n\\textit{graph representation} from node representations are demanded. A common\nway is to globally combine the node representations. However, rich structural\ninformation is overlooked. Thus a hierarchical pooling procedure is desired to\npreserve the graph structure during the graph representation learning. There\nare some recent works on hierarchically learning graph representation analogous\nto the pooling step in conventional convolutional neural (CNN) networks.\nHowever, the local structural information is still largely neglected during the\npooling process. In this paper, we introduce a pooling operator $\\pooling$\nbased on graph Fourier transform, which can utilize the node features and local\nstructures during the pooling process. We then design pooling layers based on\nthe pooling operator, which are further combined with traditional GCN\nconvolutional layers to form a graph neural network framework $\\m$ for graph\nclassification. Theoretical analysis is provided to understand $\\pooling$ from\nboth local and global perspectives. Experimental results of the graph\nclassification task on $6$ commonly used benchmarks demonstrate the\neffectiveness of the proposed framework.\n", "versions": [{"version": "v1", "created": "Tue, 30 Apr 2019 08:57:54 GMT"}, {"version": "v2", "created": "Sat, 18 May 2019 04:20:13 GMT"}], "update_date": "2019-05-21", "authors_parsed": [["Ma", "Yao", ""], ["Wang", "Suhang", ""], ["Aggarwal", "Charu C.", ""], ["Tang", "Jiliang", ""]]}, {"id": "1904.13111", "submitter": "Francesco Curia", "authors": "Francesco Curia", "title": "Restricted Boltzmann Machine Assignment Algorithm: Application to solve\n  many-to-one matching problems on weighted bipartite graph", "comments": "In this version is was update the thresholds determination", "journal-ref": "Annals of Data Science (April 2019)", "doi": null, "report-no": null, "categories": "math.OC cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  In this work an iterative algorithm based on unsupervised learning is\npresented, specifically on a Restricted Boltzmann Machine (RBM) to solve a\nperfect matching problem on a bipartite weighted graph. Iteratively is\ncalculated the weights $w_{ij}$ and the bias parameters $\\theta = ( a_i, b_j) $\nthat maximize the energy function and assignment element $i$ to element $j$. An\napplication of real problem is presented to show the potentiality of this\nalgorithm.\n", "versions": [{"version": "v1", "created": "Tue, 30 Apr 2019 09:06:55 GMT"}, {"version": "v2", "created": "Thu, 2 May 2019 12:28:31 GMT"}], "update_date": "2019-05-03", "authors_parsed": [["Curia", "Francesco", ""]]}, {"id": "1904.13113", "submitter": "Xu Yang", "authors": "Xu Yang, Cheng Deng, Feng Zheng, Junchi Yan, Wei Liu", "title": "Deep Spectral Clustering using Dual Autoencoder Network", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The clustering methods have recently absorbed even-increasing attention in\nlearning and vision. Deep clustering combines embedding and clustering together\nto obtain optimal embedding subspace for clustering, which can be more\neffective compared with conventional clustering methods. In this paper, we\npropose a joint learning framework for discriminative embedding and spectral\nclustering. We first devise a dual autoencoder network, which enforces the\nreconstruction constraint for the latent representations and their noisy\nversions, to embed the inputs into a latent space for clustering. As such the\nlearned latent representations can be more robust to noise. Then the mutual\ninformation estimation is utilized to provide more discriminative information\nfrom the inputs. Furthermore, a deep spectral clustering method is applied to\nembed the latent representations into the eigenspace and subsequently clusters\nthem, which can fully exploit the relationship between inputs to achieve\noptimal clustering results. Experimental results on benchmark datasets show\nthat our method can significantly outperform state-of-the-art clustering\napproaches.\n", "versions": [{"version": "v1", "created": "Tue, 30 Apr 2019 09:12:22 GMT"}], "update_date": "2019-05-01", "authors_parsed": [["Yang", "Xu", ""], ["Deng", "Cheng", ""], ["Zheng", "Feng", ""], ["Yan", "Junchi", ""], ["Liu", "Wei", ""]]}, {"id": "1904.13127", "submitter": "Brais Cancela", "authors": "Brais Cancela, Ver\\'onica Bol\\'on-Canedo, Amparo Alonso-Betanzos,\n  Jo\\~ao Gama", "title": "A scalable saliency-based Feature selection method with instance level\n  information", "comments": null, "journal-ref": null, "doi": "10.1016/j.knosys.2020.105885", "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Classic feature selection techniques remove those features that are either\nirrelevant or redundant, achieving a subset of relevant features that help to\nprovide a better knowledge extraction. This allows the creation of compact\nmodels that are easier to interpret. Most of these techniques work over the\nwhole dataset, but they are unable to provide the user with successful\ninformation when only instance information is needed. In short, given any\nexample, classic feature selection algorithms do not give any information about\nwhich the most relevant information is, regarding this sample. This work aims\nto overcome this handicap by developing a novel feature selection method,\ncalled Saliency-based Feature Selection (SFS), based in deep-learning saliency\ntechniques. Our experimental results will prove that this algorithm can be\nsuccessfully used not only in Neural Networks, but also under any given\narchitecture trained by using Gradient Descent techniques.\n", "versions": [{"version": "v1", "created": "Tue, 30 Apr 2019 09:54:13 GMT"}], "update_date": "2020-12-16", "authors_parsed": [["Cancela", "Brais", ""], ["Bol\u00f3n-Canedo", "Ver\u00f3nica", ""], ["Alonso-Betanzos", "Amparo", ""], ["Gama", "Jo\u00e3o", ""]]}, {"id": "1904.13142", "submitter": "Chien-Feng Liao", "authors": "Chien-Feng Liao, Yu Tsao, Xugang Lu, Hisashi Kawai", "title": "Incorporating Symbolic Sequential Modeling for Speech Enhancement", "comments": "Accepted to Interspeech 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.SD eess.AS stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In a noisy environment, a lossy speech signal can be automatically restored\nby a listener if he/she knows the language well. That is, with the built-in\nknowledge of a \"language model\", a listener may effectively suppress noise\ninterference and retrieve the target speech signals. Accordingly, we argue that\nfamiliarity with the underlying linguistic content of spoken utterances\nbenefits speech enhancement (SE) in noisy environments. In this study, in\naddition to the conventional modeling for learning the acoustic noisy-clean\nspeech mapping, an abstract symbolic sequential modeling is incorporated into\nthe SE framework. This symbolic sequential modeling can be regarded as a\n\"linguistic constraint\" in learning the acoustic noisy-clean speech mapping\nfunction. In this study, the symbolic sequences for acoustic signals are\nobtained as discrete representations with a Vector Quantized Variational\nAutoencoder algorithm. The obtained symbols are able to capture high-level\nphoneme-like content from speech signals. The experimental results demonstrate\nthat the proposed framework can obtain notable performance improvement in terms\nof perceptual evaluation of speech quality (PESQ) and short-time objective\nintelligibility (STOI) on the TIMIT dataset.\n", "versions": [{"version": "v1", "created": "Tue, 30 Apr 2019 10:31:22 GMT"}, {"version": "v2", "created": "Mon, 1 Jul 2019 15:04:02 GMT"}, {"version": "v3", "created": "Tue, 2 Jul 2019 02:38:05 GMT"}], "update_date": "2019-07-03", "authors_parsed": [["Liao", "Chien-Feng", ""], ["Tsao", "Yu", ""], ["Lu", "Xugang", ""], ["Kawai", "Hisashi", ""]]}, {"id": "1904.13148", "submitter": "Zhennan Wang", "authors": "Zhennan Wang, Wenbin Zou, Chen Xu", "title": "PR Product: A Substitute for Inner Product in Neural Networks", "comments": "ICCV2019 oral", "journal-ref": "Proceedings of the IEEE International Conference on Computer\n  Vision. 2019: 6013-6022", "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we analyze the inner product of weight vector w and data\nvector x in neural networks from the perspective of vector orthogonal\ndecomposition and prove that the direction gradient of w decreases with the\nangle between them close to 0 or {\\pi}. We propose the Projection and Rejection\nProduct (PR Product) to make the direction gradient of w independent of the\nangle and consistently larger than the one in standard inner product while\nkeeping the forward propagation identical. As a reliable substitute for\nstandard inner product, the PR Product can be applied into many existing deep\nlearning modules, so we develop the PR Product version of fully connected\nlayer, convolutional layer and LSTM layer. In static image classification, the\nexperiments on CIFAR10 and CIFAR100 datasets demonstrate that the PR Product\ncan robustly enhance the ability of various state-of-the-art classification\nnetworks. On the task of image captioning, even without any bells and whistles,\nour PR Product version of captioning model can compete or outperform the\nstate-of-the-art models on MS COCO dataset. Code has been made available\nat:https://github.com/wzn0828/PR_Product.\n", "versions": [{"version": "v1", "created": "Tue, 30 Apr 2019 10:43:38 GMT"}, {"version": "v2", "created": "Fri, 16 Aug 2019 11:37:06 GMT"}], "update_date": "2020-06-15", "authors_parsed": [["Wang", "Zhennan", ""], ["Zou", "Wenbin", ""], ["Xu", "Chen", ""]]}, {"id": "1904.13179", "submitter": "Shuhan Tan", "authors": "Shuhan Tan, Jiening Jiao, Wei-Shi Zheng", "title": "Weakly Supervised Open-set Domain Adaptation by Dual-domain\n  Collaboration", "comments": "CVPR 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In conventional domain adaptation, a critical assumption is that there exists\na fully labeled domain (source) that contains the same label space as another\nunlabeled or scarcely labeled domain (target). However, in the real world,\nthere often exist application scenarios in which both domains are partially\nlabeled and not all classes are shared between these two domains. Thus, it is\nmeaningful to let partially labeled domains learn from each other to classify\nall the unlabeled samples in each domain under an open-set setting. We consider\nthis problem as weakly supervised open-set domain adaptation. To address this\npractical setting, we propose the Collaborative Distribution Alignment (CDA)\nmethod, which performs knowledge transfer bilaterally and works collaboratively\nto classify unlabeled data and identify outlier samples. Extensive experiments\non the Office benchmark and an application on person reidentification show that\nour method achieves state-of-the-art performance.\n", "versions": [{"version": "v1", "created": "Tue, 30 Apr 2019 11:54:19 GMT"}], "update_date": "2019-05-01", "authors_parsed": [["Tan", "Shuhan", ""], ["Jiao", "Jiening", ""], ["Zheng", "Wei-Shi", ""]]}, {"id": "1904.13195", "submitter": "Maxime Cordy", "authors": "Wei Ma, Mike Papadakis, Anestis Tsakmalis, Maxime Cordy, Yves Le Traon", "title": "Test Selection for Deep Learning Systems", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.SE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Testing of deep learning models is challenging due to the excessive number\nand complexity of computations involved. As a result, test data selection is\nperformed manually and in an ad hoc way. This raises the question of how we can\nautomatically select candidate test data to test deep learning models. Recent\nresearch has focused on adapting test selection metrics from code-based\nsoftware testing (such as coverage) to deep learning. However, deep learning\nmodels have different attributes from code such as spread of computations\nacross the entire network reflecting training data properties, balance of\nneuron weights and redundancy (use of many more neurons than needed). Such\ndifferences make code-based metrics inappropriate to select data that can\nchallenge the models (can trigger misclassification). We thus propose a set of\ntest selection metrics based on the notion of model uncertainty (model\nconfidence on specific inputs). Intuitively, the more uncertain we are about a\ncandidate sample, the more likely it is that this sample triggers a\nmisclassification. Similarly, the samples for which we are the most uncertain,\nare the most informative and should be used to improve the model by retraining.\nWe evaluate these metrics on two widely-used image classification problems\ninvolving real and artificial (adversarial) data. We show that\nuncertainty-based metrics have a strong ability to select data that are\nmisclassified and lead to major improvement in classification accuracy during\nretraining: up to 80% more gain than random selection and other\nstate-of-the-art metrics on one dataset and up to 29% on the other.\n", "versions": [{"version": "v1", "created": "Tue, 30 Apr 2019 12:44:10 GMT"}], "update_date": "2019-05-01", "authors_parsed": [["Ma", "Wei", ""], ["Papadakis", "Mike", ""], ["Tsakmalis", "Anestis", ""], ["Cordy", "Maxime", ""], ["Traon", "Yves Le", ""]]}, {"id": "1904.13196", "submitter": "Marjan Alirezaie", "authors": "Marjan Alirezaie, Martin L\\\"angkvist, Michael Sioutis, Amy Loutfi", "title": "Semantic Referee: A Neural-Symbolic Framework for Enhancing Geospatial\n  Semantic Segmentation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.CV cs.LG cs.LO", "license": "http://creativecommons.org/publicdomain/zero/1.0/", "abstract": "  Understanding why machine learning algorithms may fail is usually the task of\nthe human expert that uses domain knowledge and contextual information to\ndiscover systematic shortcomings in either the data or the algorithm. In this\npaper, we propose a semantic referee, which is able to extract qualitative\nfeatures of the errors emerging from deep machine learning frameworks and\nsuggest corrections. The semantic referee relies on ontological reasoning about\nspatial knowledge in order to characterize errors in terms of their spatial\nrelations with the environment. Using semantics, the reasoner interacts with\nthe learning algorithm as a supervisor. In this paper, the proposed method of\nthe interaction between a neural network classifier and a semantic referee\nshows how to improve the performance of semantic segmentation for satellite\nimagery data.\n", "versions": [{"version": "v1", "created": "Tue, 30 Apr 2019 12:44:22 GMT"}], "update_date": "2019-05-01", "authors_parsed": [["Alirezaie", "Marjan", ""], ["L\u00e4ngkvist", "Martin", ""], ["Sioutis", "Michael", ""], ["Loutfi", "Amy", ""]]}, {"id": "1904.13197", "submitter": "James Bocinsky", "authors": "James Bocinsky, Connor McCurley, Daniel Shats, and Alina Zare", "title": "Investigation of Initialization Strategies for the Multiple Instance\n  Adaptive Cosine Estimator", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Sensors which use electromagnetic induction (EMI) to excite a response in\nconducting bodies have long been investigated for subsurface explosive hazard\ndetection. In particular, EMI sensors have been used to discriminate between\ndifferent types of objects, and to detect objects with low metal content. One\nsuccessful, previously investigated approach is the Multiple Instance Adaptive\nCosine Estimator (MI-ACE). In this paper, a number of new initialization\ntechniques for MI-ACE are proposed and evaluated using their respective\nperformance and speed. The cross validated learned signatures, as well as\nlearned background statistics, are used with Adaptive Cosine Estimator (ACE) to\ngenerate confidence maps, which are clustered into alarms. Alarms are scored\nagainst a ground truth and the initialization approaches are compared.\n", "versions": [{"version": "v1", "created": "Tue, 30 Apr 2019 12:45:18 GMT"}], "update_date": "2019-05-01", "authors_parsed": [["Bocinsky", "James", ""], ["McCurley", "Connor", ""], ["Shats", "Daniel", ""], ["Zare", "Alina", ""]]}, {"id": "1904.13204", "submitter": "Andrey Alekseev", "authors": "Andrey Alekseev and Anatoly Bobe", "title": "GaborNet: Gabor filters with learnable parameters in deep convolutional\n  neural networks", "comments": "10 pages, 6 figures, 3 tables, preprint", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG eess.IV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The article describes a system for image recognition using deep convolutional\nneural networks. Modified network architecture is proposed that focuses on\nimproving convergence and reducing training complexity. The filters in the\nfirst layer of the network are constrained to fit the Gabor function. The\nparameters of Gabor functions are learnable and are updated by standard\nbackpropagation techniques. The system was implemented on Python, tested on\nseveral datasets and outperformed the common convolutional networks.\n", "versions": [{"version": "v1", "created": "Tue, 30 Apr 2019 13:12:36 GMT"}], "update_date": "2019-05-01", "authors_parsed": [["Alekseev", "Andrey", ""], ["Bobe", "Anatoly", ""]]}, {"id": "1904.13215", "submitter": "Corina P\\u{a}s\\u{a}reanu", "authors": "Divya Gopinath, Hayes Converse, Corina S. Pasareanu and Ankur Taly", "title": "Property Inference for Deep Neural Networks", "comments": "Errata: This version updates the ASE'19 conference version by\n  correcting the definition of the three properties that were checked for\n  ACASXU", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.FL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present techniques for automatically inferring formal properties of\nfeed-forward neural networks. We observe that a significant part (if not all)\nof the logic of feed forward networks is captured in the activation status\n('on' or 'off') of its neurons. We propose to extract patterns based on neuron\ndecisions as preconditions that imply certain desirable output property e.g.,\nthe prediction being a certain class. We present techniques to extract input\nproperties, encoding convex predicates on the input space that imply given\noutput properties and layer properties, representing network properties\ncaptured in the hidden layers that imply the desired output behavior. We apply\nour techniques on networks for the MNIST and ACASXU applications. Our\nexperiments highlight the use of the inferred properties in a variety of tasks,\nsuch as explaining predictions, providing robustness guarantees, simplifying\nproofs, and network distillation.\n", "versions": [{"version": "v1", "created": "Mon, 29 Apr 2019 16:37:21 GMT"}, {"version": "v2", "created": "Fri, 13 Sep 2019 21:25:04 GMT"}, {"version": "v3", "created": "Thu, 10 Sep 2020 22:32:54 GMT"}], "update_date": "2020-09-14", "authors_parsed": [["Gopinath", "Divya", ""], ["Converse", "Hayes", ""], ["Pasareanu", "Corina S.", ""], ["Taly", "Ankur", ""]]}, {"id": "1904.13221", "submitter": "Emad Ul Haq Qazi", "authors": "Saeed Bamatraf, Muhammad Hussain, Emad-ul-Haq Qazi and Hatim Aboalsamh", "title": "Eigen Values Features for the Classification of Brain Signals\n  corresponding to 2D and 3D Educational Contents", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG eess.SP stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we have proposed a brain signal classification method, which\nuses eigenvalues of the covariance matrix as features to classify images\n(topomaps) created from the brain signals. The signals are recorded during the\nanswering of 2D and 3D questions. The system is used to classify the correct\nand incorrect answers for both 2D and 3D questions. Using the classification\ntechnique, the impacts of 2D and 3D multimedia educational contents on\nlearning, memory retention and recall will be compared. The subjects learn\nsimilar 2D and 3D educational contents. Afterwards, subjects are asked 20\nmultiple-choice questions (MCQs) associated with the contents after thirty\nminutes (Short-Term Memory) and two months (Long-Term Memory). Eigenvalues\nfeatures extracted from topomaps images are given to K-Nearest Neighbor (KNN)\nand Support Vector Machine (SVM) classifiers, in order to identify the states\nof the brain related to incorrect and correct answers. Excellent accuracies\nobtained by both classifiers and by applying statistical analysis on the\nresults, no significant difference is indicated between 2D and 3D multimedia\neducational contents on learning, memory retention and recall in both STM and\nLTM.\n", "versions": [{"version": "v1", "created": "Tue, 30 Apr 2019 13:32:00 GMT"}], "update_date": "2019-05-01", "authors_parsed": [["Bamatraf", "Saeed", ""], ["Hussain", "Muhammad", ""], ["Qazi", "Emad-ul-Haq", ""], ["Aboalsamh", "Hatim", ""]]}, {"id": "1904.13223", "submitter": "Morteza Haghir Chehreghani", "authors": "Morteza Haghir Chehreghani", "title": "Unsupervised Representation Learning with Minimax Distance Measures", "comments": "32 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We investigate the use of Minimax distances to extract in a nonparametric way\nthe features that capture the unknown underlying patterns and structures in the\ndata. We develop a general-purpose and computationally efficient framework to\nemploy Minimax distances with many machine learning methods that perform on\nnumerical data. We study both computing the pairwise Minimax distances for all\npairs of objects and as well as computing the Minimax distances of all the\nobjects to/from a fixed (test) object.\n  We first efficiently compute the pairwise Minimax distances between the\nobjects, using the equivalence of Minimax distances over a graph and over a\nminimum spanning tree constructed on that. Then, we perform an embedding of the\npairwise Minimax distances into a new vector space, such that their squared\nEuclidean distances in the new space equal to the pairwise Minimax distances in\nthe original space. We also study the case of having multiple pairwise Minimax\nmatrices, instead of a single one. Thereby, we propose an embedding via first\nsumming up the centered matrices and then performing an eigenvalue\ndecomposition to obtain the relevant features.\n  In the following, we study computing Minimax distances from a fixed (test)\nobject which can be used for instance in K-nearest neighbor search. Similar to\nthe case of all-pair pairwise Minimax distances, we develop an efficient and\ngeneral-purpose algorithm that is applicable with any arbitrary base distance\nmeasure. Moreover, we investigate in detail the edges selected by the Minimax\ndistances and thereby explore the ability of Minimax distances in detecting\noutlier objects.\n  Finally, for each setting, we perform several experiments to demonstrate the\neffectiveness of our framework.\n", "versions": [{"version": "v1", "created": "Sat, 27 Apr 2019 16:13:08 GMT"}, {"version": "v2", "created": "Fri, 10 Apr 2020 12:08:40 GMT"}], "update_date": "2020-04-13", "authors_parsed": [["Chehreghani", "Morteza Haghir", ""]]}, {"id": "1904.13228", "submitter": "Emad Ul Haq Qazi", "authors": "Emad-ul-Haq Qazi, Muhammad Hussain and Hatim Aboalsamh", "title": "An Efficient Intelligent System for the Classification of\n  Electroencephalography (EEG) Brain Signals using Nuclear Features for Human\n  Cognitive Tasks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG eess.SP stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Representation and classification of Electroencephalography (EEG) brain\nsignals are critical processes for their analysis in cognitive tasks.\nParticularly, extraction of discriminative features from raw EEG signals,\nwithout any pre-processing, is a challenging task. Motivated by nuclear norm,\nwe observed that there is a significant difference between the variances of EEG\nsignals captured from the same brain region when a subject performs different\ntasks. This observation lead us to use singular value decomposition for\ncomputing dominant variances of EEG signals captured from a certain brain\nregion while performing a certain task and use them as features (nuclear\nfeatures). A simple and efficient class means based minimum distance classifier\n(CMMDC) is enough to predict brain states. This approach results in the feature\nspace of significantly small dimension and gives equally good classification\nresults on clean as well as raw data. We validated the effectiveness and\nrobustness of the technique using four datasets of different tasks: fluid\nintelligence clean data (FICD), fluid intelligence raw data (FIRD), memory\nrecall task (MRT), and eyes open / eyes closed task (EOEC). For each task, we\nanalyzed EEG signals over six (06) different brain regions with 8, 16, 20, 18,\n18 and 100 electrodes. The nuclear features from frontal brain region gave the\n100% prediction accuracy. The discriminant analysis of the nuclear features has\nbeen conducted using intra-class and inter-class variations. Comparisons with\nthe state-of-the-art techniques showed the superiority of the proposed system.\n", "versions": [{"version": "v1", "created": "Tue, 30 Apr 2019 13:38:04 GMT"}], "update_date": "2019-05-01", "authors_parsed": [["Qazi", "Emad-ul-Haq", ""], ["Hussain", "Muhammad", ""], ["Aboalsamh", "Hatim", ""]]}, {"id": "1904.13233", "submitter": "Daniel Cunnington", "authors": "Daniel Cunnington, Graham White, Geeth de Mel", "title": "Synthetic Ground Truth Generation for Evaluating Generative Policy\n  Models", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Generative Policy-based Models aim to enable a coalition of systems, be they\ndevices or services to adapt according to contextual changes such as\nenvironmental factors, user preferences and different tasks whilst adhering to\nvarious constraints and regulations as directed by a managing party or the\ncollective vision of the coalition. Recent developments have proposed new\narchitectures to realize the potential of GPMs but as the complexity of systems\nand their associated requirements increases, there is an emerging requirement\nto have scenarios and associated datasets to realistically evaluate GPMs with\nrespect to the properties of the operating environment, be it the future\nbattlespace or an autonomous organization. In order to address this\nrequirement, in this paper, we present a method of applying an agile knowledge\nrepresentation framework to model requirements, both individualistic and\ncollective that enables synthetic generation of ground truth data such that\nadvanced GPMs can be evaluated robustly in complex environments. We also\nrelease conceptual models, annotated datasets, as well as means to extend the\ndata generation approach so that similar datasets can be developed for varying\ncomplexities and different situations.\n", "versions": [{"version": "v1", "created": "Fri, 26 Apr 2019 14:41:58 GMT"}], "update_date": "2019-05-01", "authors_parsed": [["Cunnington", "Daniel", ""], ["White", "Graham", ""], ["de Mel", "Geeth", ""]]}, {"id": "1904.13234", "submitter": "Emad Ul Haq Qazi", "authors": "Emad-ul-Haq Qazi, Muhammad Hussain, Hatim AboAlsamh, Ihsan Ullah", "title": "Automatic Emotion Recognition (AER) System based on Two-Level Ensemble\n  of Lightweight Deep CNN Models", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG eess.SP stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Emotions play a crucial role in human interaction, health care and security\ninvestigations and monitoring. Automatic emotion recognition (AER) using\nelectroencephalogram (EEG) signals is an effective method for decoding the real\nemotions, which are independent of body gestures, but it is a challenging\nproblem. Several automatic emotion recognition systems have been proposed,\nwhich are based on traditional hand-engineered approaches and their\nperformances are very poor. Motivated by the outstanding performance of deep\nlearning (DL) in many recognition tasks, we introduce an AER system (Deep-AER)\nbased on EEG brain signals using DL. A DL model involves a large number of\nlearnable parameters, and its training needs a large dataset of EEG signals,\nwhich is difficult to acquire for AER problem. To overcome this problem, we\nproposed a lightweight pyramidal one-dimensional convolutional neural network\n(LP-1D-CNN) model, which involves a small number of learnable parameters. Using\nLP-1D-CNN, we build a two level ensemble model. In the first level of the\nensemble, each channel is scanned incrementally by LP-1D-CNN to generate\npredictions, which are fused using majority vote. The second level of the\nensemble combines the predictions of all channels of an EEG signal using\nmajority vote for detecting the emotion state. We validated the effectiveness\nand robustness of Deep-AER using DEAP, a benchmark dataset for emotion\nrecognition research. The results indicate that FRONT plays dominant role in\nAER and over this region, Deep-AER achieved the accuracies of 98.43% and 97.65%\nfor two AER problems, i.e., high valence vs low valence (HV vs LV) and high\narousal vs low arousal (HA vs LA), respectively. The comparison reveals that\nDeep-AER outperforms the state-of-the-art systems with large margin. The\nDeep-AER system will be helpful in monitoring for health care and security\ninvestigations.\n", "versions": [{"version": "v1", "created": "Tue, 30 Apr 2019 13:43:14 GMT"}], "update_date": "2019-05-01", "authors_parsed": [["Qazi", "Emad-ul-Haq", ""], ["Hussain", "Muhammad", ""], ["AboAlsamh", "Hatim", ""], ["Ullah", "Ihsan", ""]]}, {"id": "1904.13236", "submitter": "Soheil Esmaeilzadeh", "authors": "Soheil Esmaeilzadeh, Amir Salehi, Gill Hetz, Feyisayo Olalotiti-lawal,\n  Hamed Darabi, David Castineira", "title": "A General Spatio-Temporal Clustering-Based Non-local Formulation for\n  Multiscale Modeling of Compartmentalized Reservoirs", "comments": null, "journal-ref": "Machine Learning Session, WRM 2019 Conference", "doi": "10.2118/195329-MS", "report-no": "SPE-195329-MS", "categories": "cs.LG stat.ME", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Representing the reservoir as a network of discrete compartments with\nneighbor and non-neighbor connections is a fast, yet accurate method for\nanalyzing oil and gas reservoirs. Automatic and rapid detection of coarse-scale\ncompartments with distinct static and dynamic properties is an integral part of\nsuch high-level reservoir analysis. In this work, we present a hybrid framework\nspecific to reservoir analysis for an automatic detection of clusters in space\nusing spatial and temporal field data, coupled with a physics-based multiscale\nmodeling approach. In this work a novel hybrid approach is presented in which\nwe couple a physics-based non-local modeling framework with data-driven\nclustering techniques to provide a fast and accurate multiscale modeling of\ncompartmentalized reservoirs. This research also adds to the literature by\npresenting a comprehensive work on spatio-temporal clustering for reservoir\nstudies applications that well considers the clustering complexities, the\nintrinsic sparse and noisy nature of the data, and the interpretability of the\noutcome.\n  Keywords: Artificial Intelligence; Machine Learning; Spatio-Temporal\nClustering; Physics-Based Data-Driven Formulation; Multiscale Modeling\n", "versions": [{"version": "v1", "created": "Sun, 28 Apr 2019 23:01:05 GMT"}], "update_date": "2019-11-21", "authors_parsed": [["Esmaeilzadeh", "Soheil", ""], ["Salehi", "Amir", ""], ["Hetz", "Gill", ""], ["Olalotiti-lawal", "Feyisayo", ""], ["Darabi", "Hamed", ""], ["Castineira", "David", ""]]}, {"id": "1904.13240", "submitter": "Prabal Chhibbar", "authors": "Prabal Chhibbar, Arpit Joshi", "title": "Generating protein sequences from antibiotic resistance genes data using\n  Generative Adversarial Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.GN cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We introduce a method to generate synthetic protein sequences which are\npredicted to be resistant to certain antibiotics. We did this using 6,023 genes\nthat were predicted to be resistant to antibiotics in the intestinal region of\nthe human gut and were fed as input to a Wasserstein generative adversarial\nnetwork (W-GAN) model a variant to the original generative adversarial model\nwhich has been known to perform efficiently when it comes to mimicking the\ndistribution of the real data in order to generate new data which is similar in\nstyle to the original data which was fed as the training data\n", "versions": [{"version": "v1", "created": "Sun, 28 Apr 2019 11:34:03 GMT"}], "update_date": "2019-05-01", "authors_parsed": [["Chhibbar", "Prabal", ""], ["Joshi", "Arpit", ""]]}, {"id": "1904.13241", "submitter": "Soheil Mehrabkhani", "authors": "Soheil Mehrabkhani", "title": "Fourier Transform Approach to Machine Learning II: Fourier Clustering", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a Fourier-based approach for optimization of several clustering\nalgorithms. Mathematically, clusters data can be described by a density\nfunction represented by the Dirac mixture distribution. The density function\ncan be smoothed by applying the Fourier transform and a Gaussian filter. The\ndetermination of the optimal standard deviation of the Gaussian filter will be\naccomplished by the use of a convergence criterion related to the correlation\nbetween the smoothed and the original density functions. In principle, the\noptimal smoothed density function exhibits local maxima, which correspond to\nthe cluster centroids. Thus, the complex task of finding the centroids of the\nclusters is simplified by the detection of the peaks of the smoothed density\nfunction. A multiple sliding windows procedure is used to detect the peaks. The\nremarkable accuracy of the proposed algorithm demonstrates its capability as a\nreliable general method for enhancement of the clustering performance, its\nglobal optimization and also removing the initialization problem in many\nclustering methods.\n", "versions": [{"version": "v1", "created": "Mon, 29 Apr 2019 03:12:32 GMT"}, {"version": "v2", "created": "Mon, 3 Jun 2019 16:10:03 GMT"}, {"version": "v3", "created": "Sun, 22 Sep 2019 09:37:07 GMT"}], "update_date": "2019-09-24", "authors_parsed": [["Mehrabkhani", "Soheil", ""]]}, {"id": "1904.13247", "submitter": "Durdane Kocacoban", "authors": "Durdane Kocacoban, James Cussens", "title": "Online Causal Structure Learning in the Presence of Latent Variables", "comments": "16 pages, 9 figures, 2 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present two online causal structure learning algorithms which can track\nchanges in a causal structure and process data in a dynamic real-time manner.\nStandard causal structure learning algorithms assume that causal structure does\nnot change during the data collection process, but in real-world scenarios, it\ndoes often change. Therefore, it is inappropriate to handle such changes with\nexisting batch-learning approaches, and instead, a structure should be learned\nin an online manner. The online causal structure learning algorithms we present\nhere can revise correlation values without reprocessing the entire dataset and\nuse an existing model to avoid relearning the causal links in the prior model,\nwhich still fit data. Proposed algorithms are tested on synthetic and\nreal-world datasets, the latter being a seasonally adjusted commodity price\nindex dataset for the U.S. The online causal structure learning algorithms\noutperformed standard FCI by a large margin in learning the changed causal\nstructure correctly and efficiently when latent variables were present.\n", "versions": [{"version": "v1", "created": "Tue, 30 Apr 2019 13:49:43 GMT"}, {"version": "v2", "created": "Sun, 14 Jul 2019 18:17:34 GMT"}], "update_date": "2019-07-16", "authors_parsed": [["Kocacoban", "Durdane", ""], ["Cussens", "James", ""]]}, {"id": "1904.13251", "submitter": "Leonard Heilig", "authors": "Leonard Heilig, Robert Stahlbock, Stefan Vo{\\ss}", "title": "From Digitalization to Data-Driven Decision Making in Container\n  Terminals", "comments": "20 pages, 5 figures, book chapter", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DB cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  With the new opportunities emerging from the current wave of digitalization,\nterminal planning and management need to be revisited by taking a data-driven\nperspective. Business analytics, as a practice of extracting insights from\noperational data, assists in reducing uncertainties using predictions and helps\nto identify and understand causes of inefficiencies, disruptions, and anomalies\nin intra- and inter-organizational terminal operations. Despite the growing\ncomplexity of data within and around container terminals, a lack of data-driven\napproaches in the context of container terminals can be identified. In this\nchapter, the concept of business analytics for supporting terminal planning and\nmanagement is introduced. The chapter specifically focuses on data mining\napproaches and provides a comprehensive overview on applications in container\nterminals and related research. As such, we aim to establish a data-driven\nperspective on terminal planning and management, complementing the traditional\noptimization perspective.\n", "versions": [{"version": "v1", "created": "Mon, 29 Apr 2019 14:37:28 GMT"}], "update_date": "2019-05-01", "authors_parsed": [["Heilig", "Leonard", ""], ["Stahlbock", "Robert", ""], ["Vo\u00df", "Stefan", ""]]}, {"id": "1904.13255", "submitter": "Kacper Kielak", "authors": "Kacper Kielak", "title": "Generative Adversarial Imagination for Sample Efficient Deep\n  Reinforcement Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Reinforcement learning has seen great advancements in the past five years.\nThe successful introduction of deep learning in place of more traditional\nmethods allowed reinforcement learning to scale to very complex domains\nachieving super-human performance in environments like the game of Go or\nnumerous video games. Despite great successes in multiple domains, these new\nmethods suffer from their own issues that make them often inapplicable to the\nreal world problems. Extreme lack of data efficiency, together with huge\nvariance and difficulty in enforcing safety constraints, is one of the three\nmost prominent issues in the field. Usually, millions of data points sampled\nfrom the environment are necessary for these algorithms to converge to\nacceptable policies.\n  This thesis proposes novel Generative Adversarial Imaginative Reinforcement\nLearning algorithm. It takes advantage of the recent introduction of highly\neffective generative adversarial models, and Markov property that underpins\nreinforcement learning setting, to model dynamics of the real environment\nwithin the internal imagination module. Rollouts from the imagination are then\nused to artificially simulate the real environment in a standard reinforcement\nlearning process to avoid, often expensive and dangerous, trial and error in\nthe real environment. Experimental results show that the proposed algorithm\nmore economically utilises experience from the real environment than the\ncurrent state-of-the-art Rainbow DQN algorithm, and thus makes an important\nstep towards sample efficient deep reinforcement learning.\n", "versions": [{"version": "v1", "created": "Tue, 30 Apr 2019 13:53:29 GMT"}, {"version": "v2", "created": "Mon, 10 Jun 2019 18:34:54 GMT"}], "update_date": "2019-06-12", "authors_parsed": [["Kielak", "Kacper", ""]]}, {"id": "1904.13262", "submitter": "Gauthier Gidel", "authors": "Gauthier Gidel, Francis Bach and Simon Lacoste-Julien", "title": "Implicit Regularization of Discrete Gradient Dynamics in Linear Neural\n  Networks", "comments": "19 pages, to appear in NeurIPS 2019 proceedings", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG math.OC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  When optimizing over-parameterized models, such as deep neural networks, a\nlarge set of parameters can achieve zero training error. In such cases, the\nchoice of the optimization algorithm and its respective hyper-parameters\nintroduces biases that will lead to convergence to specific minimizers of the\nobjective. Consequently, this choice can be considered as an implicit\nregularization for the training of over-parametrized models. In this work, we\npush this idea further by studying the discrete gradient dynamics of the\ntraining of a two-layer linear network with the least-squares loss. Using a\ntime rescaling, we show that, with a vanishing initialization and a small\nenough step size, this dynamics sequentially learns the solutions of a\nreduced-rank regression with a gradually increasing rank.\n", "versions": [{"version": "v1", "created": "Tue, 30 Apr 2019 14:06:05 GMT"}, {"version": "v2", "created": "Thu, 5 Dec 2019 17:02:21 GMT"}], "update_date": "2019-12-06", "authors_parsed": [["Gidel", "Gauthier", ""], ["Bach", "Francis", ""], ["Lacoste-Julien", "Simon", ""]]}, {"id": "1904.13264", "submitter": "Vitalii Zhelezniak", "authors": "Vitalii Zhelezniak, Aleksandar Savkov, April Shen, Francesco\n  Moramarco, Jack Flann, Nils Y. Hammerla", "title": "Don't Settle for Average, Go for the Max: Fuzzy Sets and Max-Pooled Word\n  Vectors", "comments": "Published as a conference paper at ICLR 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent literature suggests that averaged word vectors followed by simple\npost-processing outperform many deep learning methods on semantic textual\nsimilarity tasks. Furthermore, when averaged word vectors are trained\nsupervised on large corpora of paraphrases, they achieve state-of-the-art\nresults on standard STS benchmarks. Inspired by these insights, we push the\nlimits of word embeddings even further. We propose a novel fuzzy bag-of-words\n(FBoW) representation for text that contains all the words in the vocabulary\nsimultaneously but with different degrees of membership, which are derived from\nsimilarities between word vectors. We show that max-pooled word vectors are\nonly a special case of fuzzy BoW and should be compared via fuzzy Jaccard index\nrather than cosine similarity. Finally, we propose DynaMax, a completely\nunsupervised and non-parametric similarity measure that dynamically extracts\nand max-pools good features depending on the sentence pair. This method is both\nefficient and easy to implement, yet outperforms current baselines on STS tasks\nby a large margin and is even competitive with supervised word vectors trained\nto directly optimise cosine similarity.\n", "versions": [{"version": "v1", "created": "Tue, 30 Apr 2019 14:08:37 GMT"}], "update_date": "2019-05-01", "authors_parsed": [["Zhelezniak", "Vitalii", ""], ["Savkov", "Aleksandar", ""], ["Shen", "April", ""], ["Moramarco", "Francesco", ""], ["Flann", "Jack", ""], ["Hammerla", "Nils Y.", ""]]}, {"id": "1904.13270", "submitter": "Nico Lang", "authors": "Nico Lang, Konrad Schindler, Jan Dirk Wegner", "title": "Country-wide high-resolution vegetation height mapping with Sentinel-2", "comments": null, "journal-ref": "Remote Sensing of Environment 233 (2019) 111347", "doi": "10.1016/j.rse.2019.111347", "report-no": null, "categories": "eess.IV cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Sentinel-2 multi-spectral images collected over periods of several months\nwere used to estimate vegetation height for Gabon and Switzerland. A deep\nconvolutional neural network (CNN) was trained to extract suitable spectral and\ntextural features from reflectance images and to regress per-pixel vegetation\nheight. In Gabon, reference heights for training and validation were derived\nfrom airborne LiDAR measurements. In Switzerland, reference heights were taken\nfrom an existing canopy height model derived via photogrammetric surface\nreconstruction. The resulting maps have a mean absolute error (MAE) of 1.7 m in\nSwitzerland and 4.3 m in Gabon (a root mean square error (RMSE) of 3.4 m and\n5.6 m, respectively), and correctly estimate vegetation heights up to >50 m.\nThey also show good qualitative agreement with existing vegetation height maps.\nOur work demonstrates that, given a moderate amount of reference data (i.e.,\n2000 km$^2$ in Gabon and $\\approx$5800 km$^2$ in Switzerland), high-resolution\nvegetation height maps with 10 m ground sampling distance (GSD) can be derived\nat country scale from Sentinel-2 imagery.\n", "versions": [{"version": "v1", "created": "Tue, 30 Apr 2019 14:13:13 GMT"}, {"version": "v2", "created": "Wed, 14 Aug 2019 08:28:21 GMT"}], "update_date": "2019-08-15", "authors_parsed": [["Lang", "Nico", ""], ["Schindler", "Konrad", ""], ["Wegner", "Jan Dirk", ""]]}, {"id": "1904.13281", "submitter": "Jonathan Rubin", "authors": "Jonathan Rubin and S. Mazdak Abulnaga", "title": "CT-To-MR Conditional Generative Adversarial Networks for Ischemic Stroke\n  Lesion Segmentation", "comments": "Seventh IEEE International Conference on Healthcare Informatics (ICHI\n  2019)", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.IV cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Infarcted brain tissue resulting from acute stroke readily shows up as\nhyperintense regions within diffusion-weighted magnetic resonance imaging\n(DWI). It has also been proposed that computed tomography perfusion (CTP) could\nalternatively be used to triage stroke patients, given improvements in speed\nand availability, as well as reduced cost. However, CTP has a lower signal to\nnoise ratio compared to MR. In this work, we investigate whether a conditional\nmapping can be learned by a generative adversarial network to map CTP inputs to\ngenerated MR DWI that more clearly delineates hyperintense regions due to\nischemic stroke. We detail the architectures of the generator and discriminator\nand describe the training process used to perform image-to-image translation\nfrom multi-modal CT perfusion maps to diffusion weighted MR outputs. We\nevaluate the results both qualitatively by visual comparison of generated MR to\nground truth, as well as quantitatively by training fully convolutional neural\nnetworks that make use of generated MR data inputs to perform ischemic stroke\nlesion segmentation. Segmentation networks trained using generated CT-to-MR\ninputs result in at least some improvement on all metrics used for evaluation,\ncompared with networks that only use CT perfusion input.\n", "versions": [{"version": "v1", "created": "Tue, 30 Apr 2019 14:42:53 GMT"}], "update_date": "2019-05-01", "authors_parsed": [["Rubin", "Jonathan", ""], ["Abulnaga", "S. Mazdak", ""]]}, {"id": "1904.13285", "submitter": "Pablo Samuel Castro", "authors": "Pablo Samuel Castro", "title": "Performing Structured Improvisations with pre-trained Deep Learning\n  Models", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SD cs.LG eess.AS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The quality of outputs produced by deep generative models for music have seen\na dramatic improvement in the last few years. However, most deep learning\nmodels perform in \"offline\" mode, with few restrictions on the processing time.\nIntegrating these types of models into a live structured performance poses a\nchallenge because of the necessity to respect the beat and harmony. Further,\nthese deep models tend to be agnostic to the style of a performer, which often\nrenders them impractical for live performance. In this paper we propose a\nsystem which enables the integration of out-of-the-box generative models by\nleveraging the musician's creativity and expertise.\n", "versions": [{"version": "v1", "created": "Tue, 30 Apr 2019 14:50:12 GMT"}], "update_date": "2019-05-01", "authors_parsed": [["Castro", "Pablo Samuel", ""]]}, {"id": "1904.13304", "submitter": "Youngjin Kim", "authors": "Youngjin Kim", "title": "A supervised-learning-based strategy for optimal demand response of an\n  HVAC System", "comments": "12 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.SY eess.SP stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The large thermal capacity of buildings enables heating, ventilating, and\nair-conditioning (HVAC) systems to be exploited as demand response (DR)\nresources. Optimal DR of HVAC units is challenging, particularly for multi-zone\nbuildings, because this requires detailed physics-based models of zonal\ntemperature variations for HVAC system operation and building thermal\nconditions. This paper proposes a new strategy for optimal DR of an HVAC system\nin a multi-zone building, based on supervised learning (SL). Artificial neural\nnetworks (ANNs) are trained with data obtained under normal building operating\nconditions. The ANNs are replicated using piecewise linear equations, which are\nexplicitly integrated into an optimal scheduling problem for price-based DR.\nThe optimization problem is solved for various electricity prices and building\nthermal conditions. The solutions are further used to train a deep neural\nnetwork (DNN) to directly determine the optimal DR schedule, referred to here\nas supervised-learning-aided meta-prediction (SLAMP). Case studies are\nperformed using three different methods: explicit ANN replication (EAR), SLAMP,\nand physics-based modeling. The case study results verify the effectiveness of\nthe proposed SL-based strategy, in terms of both practical applicability and\ncomputational time, while also ensuring the thermal comfort of occupants and\ncost-effective operation of the HVAC system.\n", "versions": [{"version": "v1", "created": "Mon, 29 Apr 2019 04:37:50 GMT"}], "update_date": "2019-05-01", "authors_parsed": [["Kim", "Youngjin", ""]]}, {"id": "1904.13310", "submitter": "Hojjat Salehinejad", "authors": "Alex Labach, Hojjat Salehinejad, Shahrokh Valaee", "title": "Survey of Dropout Methods for Deep Neural Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Dropout methods are a family of stochastic techniques used in neural network\ntraining or inference that have generated significant research interest and are\nwidely used in practice. They have been successfully applied in neural network\nregularization, model compression, and in measuring the uncertainty of neural\nnetwork outputs. While original formulated for dense neural network layers,\nrecent advances have made dropout methods also applicable to convolutional and\nrecurrent neural network layers. This paper summarizes the history of dropout\nmethods, their various applications, and current areas of research interest.\nImportant proposed methods are described in additional detail.\n", "versions": [{"version": "v1", "created": "Thu, 25 Apr 2019 21:21:52 GMT"}, {"version": "v2", "created": "Fri, 25 Oct 2019 04:36:14 GMT"}], "update_date": "2020-06-09", "authors_parsed": [["Labach", "Alex", ""], ["Salehinejad", "Hojjat", ""], ["Valaee", "Shahrokh", ""]]}, {"id": "1904.13317", "submitter": "Alberto Dalla Libera", "authors": "Alberto Dalla Libera and Ruggero Carli", "title": "A data-efficient geometrically inspired polynomial kernel for robot\n  inverse dynamics", "comments": null, "journal-ref": "IEEE Robotics and Automation Letters, vol. 5, no. 1, pp. 24-31,\n  Jan. 2020", "doi": "10.1109/LRA.2019.2945240", "report-no": null, "categories": "cs.RO cs.LG cs.SY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we introduce a novel data-driven inverse dynamics estimator\nbased on Gaussian Process Regression. Driven by the fact that the inverse\ndynamics can be described as a polynomial function on a suitable input space,\nwe propose the use of a novel kernel, called Geometrically Inspired Polynomial\nKernel (GIP). The resulting estimator behaves similarly to model-based\napproaches as concerns data efficiency. Indeed, we proved that the GIP kernel\ndefines a finite-dimensional Reproducing Kernel Hilbert Space that contains the\ninverse dynamics function computed through the Rigid Body Dynamics. The\nproposed kernel is based on the recently introduced Multiplicative Polynomial\nKernel, a redefinition of the classical polynomial kernel equipped with a set\nof parameters that allows for a higher regularization. We tested the proposed\napproach in a simulated environment, and also in real experiments with a UR10\nrobot. The obtained results confirm that, compared to other data-driven\nestimators, the proposed approach is more data-efficient and exhibits better\ngeneralization properties. Instead, with respect to model-based estimators, our\napproach requires less prior information and is not affected by model bias.\n", "versions": [{"version": "v1", "created": "Tue, 30 Apr 2019 15:31:48 GMT"}, {"version": "v2", "created": "Sat, 25 May 2019 18:13:36 GMT"}, {"version": "v3", "created": "Tue, 28 May 2019 09:36:02 GMT"}, {"version": "v4", "created": "Tue, 12 Nov 2019 16:35:00 GMT"}], "update_date": "2020-01-28", "authors_parsed": [["Libera", "Alberto Dalla", ""], ["Carli", "Ruggero", ""]]}, {"id": "1904.13323", "submitter": "Kamen Brestnichki", "authors": "Francisco Vargas, Kamen Brestnichki, Nils Hammerla", "title": "Model Comparison for Semantic Grouping", "comments": "Proceedings of the 36th International Conference on Machine Learning", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CL stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce a probabilistic framework for quantifying the semantic\nsimilarity between two groups of embeddings. We formulate the task of semantic\nsimilarity as a model comparison task in which we contrast a generative model\nwhich jointly models two sentences versus one that does not. We illustrate how\nthis framework can be used for the Semantic Textual Similarity tasks using\nclear assumptions about how the embeddings of words are generated. We apply\nmodel comparison that utilises information criteria to address some of the\nshortcomings of Bayesian model comparison, whilst still penalising model\ncomplexity. We achieve competitive results by applying the proposed framework\nwith an appropriate choice of likelihood on the STS datasets.\n", "versions": [{"version": "v1", "created": "Tue, 30 Apr 2019 15:37:16 GMT"}, {"version": "v2", "created": "Wed, 1 May 2019 10:52:54 GMT"}], "update_date": "2019-05-02", "authors_parsed": [["Vargas", "Francisco", ""], ["Brestnichki", "Kamen", ""], ["Hammerla", "Nils", ""]]}, {"id": "1904.13335", "submitter": "Xin Du", "authors": "Xin Du, Lei Sun, Wouter Duivesteijn, Alexander Nikolaev, Mykola\n  Pechenizkiy", "title": "Adversarial Balancing-based Representation Learning for Causal Effect\n  Inference with Observational Data", "comments": null, "journal-ref": "Data Mining and Knowledge Discovery, (2021), 1-26", "doi": "10.1007/s10618-021-00759-3", "report-no": null, "categories": "cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Learning causal effects from observational data greatly benefits a variety of\ndomains such as health care, education and sociology. For instance, one could\nestimate the impact of a new drug on specific individuals to assist the clinic\nplan and improve the survival rate. In this paper, we focus on studying the\nproblem of estimating Conditional Average Treatment Effect (CATE) from\nobservational data. The challenges for this problem are two-fold: on the one\nhand, we have to derive a causal estimator to estimate the causal quantity from\nobservational data, where there exists confounding bias; on the other hand, we\nhave to deal with the identification of CATE when the distribution of\ncovariates in treatment and control groups are imbalanced. To overcome these\nchallenges, we propose a neural network framework called Adversarial\nBalancing-based representation learning for Causal Effect Inference (ABCEI),\nbased on the recent advances in representation learning. To ensure the\nidentification of CATE, ABCEI uses adversarial learning to balance the\ndistributions of covariates in treatment and control groups in the latent\nrepresentation space, without any assumption on the form of the treatment\nselection/assignment function. In addition, during the representation learning\nand balancing process, highly predictive information from the original\ncovariate space might be lost. ABCEI can tackle this information loss problem\nby preserving useful information for predicting causal effects under the\nregularization of a mutual information estimator. The experimental results show\nthat ABCEI is robust against treatment selection bias, and matches/outperforms\nthe state-of-the-art approaches. Our experiments show promising results on\nseveral datasets, representing different health care domains among others.\n", "versions": [{"version": "v1", "created": "Tue, 30 Apr 2019 16:02:49 GMT"}, {"version": "v2", "created": "Tue, 12 Nov 2019 11:59:03 GMT"}, {"version": "v3", "created": "Fri, 16 Oct 2020 21:52:08 GMT"}], "update_date": "2021-05-19", "authors_parsed": [["Du", "Xin", ""], ["Sun", "Lei", ""], ["Duivesteijn", "Wouter", ""], ["Nikolaev", "Alexander", ""], ["Pechenizkiy", "Mykola", ""]]}, {"id": "1904.13341", "submitter": "Rui Feng", "authors": "Rui Feng, Yang Yang, Yuehan Lyu, Chenhao Tan, Yizhou Sun and Chunping\n  Wang", "title": "Learning Fair Representations via an Adversarial Framework", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Fairness has become a central issue for our research community as\nclassification algorithms are adopted in societally critical domains such as\nrecidivism prediction and loan approval. In this work, we consider the\npotential bias based on protected attributes (e.g., race and gender), and\ntackle this problem by learning latent representations of individuals that are\nstatistically indistinguishable between protected groups while sufficiently\npreserving other information for classification. To do that, we develop a\nminimax adversarial framework with a generator to capture the data distribution\nand generate latent representations, and a critic to ensure that the\ndistributions across different protected groups are similar. Our framework\nprovides a theoretical guarantee with respect to statistical parity and\nindividual fairness. Empirical results on four real-world datasets also show\nthat the learned representation can effectively be used for classification\ntasks such as credit risk prediction while obstructing information related to\nprotected groups, especially when removing protected attributes is not\nsufficient for fair classification.\n", "versions": [{"version": "v1", "created": "Tue, 30 Apr 2019 16:12:19 GMT"}], "update_date": "2019-05-01", "authors_parsed": [["Feng", "Rui", ""], ["Yang", "Yang", ""], ["Lyu", "Yuehan", ""], ["Tan", "Chenhao", ""], ["Sun", "Yizhou", ""], ["Wang", "Chunping", ""]]}, {"id": "1904.13349", "submitter": "Maarten Sukel", "authors": "Maarten Sukel, Stevan Rudinac and Marcel Worring", "title": "Multimodal Classification of Urban Micro-Events", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we seek methods to effectively detect urban micro-events. Urban\nmicro-events are events which occur in cities, have limited geographical\ncoverage and typically affect only a small group of citizens. Because of their\nscale these are difficult to identify in most data sources. However, by using\ncitizen sensing to gather data, detecting them becomes feasible. The data\ngathered by citizen sensing is often multimodal and, as a consequence, the\ninformation required to detect urban micro-events is distributed over multiple\nmodalities. This makes it essential to have a classifier capable of combining\nthem. In this paper we explore several methods of creating such a classifier,\nincluding early, late, hybrid fusion and representation learning using\nmultimodal graphs. We evaluate performance on a real world dataset obtained\nfrom a live citizen reporting system. We show that a multimodal approach yields\nhigher performance than unimodal alternatives. Furthermore, we demonstrate that\nour hybrid combination of early and late fusion with multimodal embeddings\nperforms best in classification of urban micro-events.\n", "versions": [{"version": "v1", "created": "Tue, 30 Apr 2019 16:24:19 GMT"}], "update_date": "2019-05-01", "authors_parsed": [["Sukel", "Maarten", ""], ["Rudinac", "Stevan", ""], ["Worring", "Marcel", ""]]}, {"id": "1904.13353", "submitter": "Andre Kelm", "authors": "Andre Peter Kelm, Vijesh Soorya Rao and Udo Zoelzer", "title": "Object Contour and Edge Detection with RefineContourNet", "comments": "Keywords: Object Contour Detection, Edge Detection, Multi-Path\n  Refinement CNN", "journal-ref": null, "doi": "10.1007/978-3-030-29888-3_20", "report-no": null, "categories": "cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A ResNet-based multi-path refinement CNN is used for object contour\ndetection. For this task, we prioritise the effective utilization of the\nhigh-level abstraction capability of a ResNet, which leads to state-of-the-art\nresults for edge detection. Keeping our focus in mind, we fuse the high, mid\nand low-level features in that specific order, which differs from many other\napproaches. It uses the tensor with the highest-levelled features as the\nstarting point to combine it layer-by-layer with features of a lower\nabstraction level until it reaches the lowest level. We train this network on a\nmodified PASCAL VOC 2012 dataset for object contour detection and evaluate on a\nrefined PASCAL-val dataset reaching an excellent performance and an Optimal\nDataset Scale (ODS) of 0.752. Furthermore, by fine-training on the BSDS500\ndataset we reach state-of-the-art results for edge-detection with an ODS of\n0.824.\n", "versions": [{"version": "v1", "created": "Tue, 30 Apr 2019 16:34:27 GMT"}, {"version": "v2", "created": "Thu, 2 May 2019 15:19:10 GMT"}], "update_date": "2019-08-26", "authors_parsed": [["Kelm", "Andre Peter", ""], ["Rao", "Vijesh Soorya", ""], ["Zoelzer", "Udo", ""]]}, {"id": "1904.13358", "submitter": "Jeremiah Johnson", "authors": "Faisal Mahmood, Wenhao Xu, Nicholas J. Durr, Jeremiah W. Johnson, Alan\n  Yuille", "title": "Structured Prediction using cGANs with Fusion Discriminator", "comments": "13 pages, 5 figures, 3 tables", "journal-ref": "Workshop on Deep Generative Models for Structured Prediction at\n  ICLR 2019", "doi": null, "report-no": null, "categories": "cs.CV cs.LG eess.IV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose the fusion discriminator, a single unified framework for\nincorporating conditional information into a generative adversarial network\n(GAN) for a variety of distinct structured prediction tasks, including image\nsynthesis, semantic segmentation, and depth estimation. Much like commonly used\nconvolutional neural network -- conditional Markov random field (CNN-CRF)\nmodels, the proposed method is able to enforce higher-order consistency in the\nmodel, but without being limited to a very specific class of potentials. The\nmethod is conceptually simple and flexible, and our experimental results\ndemonstrate improvement on several diverse structured prediction tasks.\n", "versions": [{"version": "v1", "created": "Tue, 30 Apr 2019 16:42:55 GMT"}], "update_date": "2019-05-15", "authors_parsed": [["Mahmood", "Faisal", ""], ["Xu", "Wenhao", ""], ["Durr", "Nicholas J.", ""], ["Johnson", "Jeremiah W.", ""], ["Yuille", "Alan", ""]]}, {"id": "1904.13362", "submitter": "Yingjing Lu", "authors": "Yingjing Lu", "title": "The Level Weighted Structural Similarity Loss: A Step Away from the MSE", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The Mean Square Error (MSE) has shown its strength when applied in deep\ngenerative models such as Auto-Encoders to model reconstruction loss. However,\nin image domain especially, the limitation of MSE is obvious: it assumes pixel\nindependence and ignores spatial relationships of samples. This contradicts\nmost architectures of Auto-Encoders which use convolutional layers to extract\nspatial dependent features. We base on the structural similarity metric (SSIM)\nand propose a novel level weighted structural similarity (LWSSIM) loss for\nconvolutional Auto-Encoders. Experiments on common datasets on various\nAuto-Encoder variants show that our loss is able to outperform the MSE loss and\nthe Vanilla SSIM loss. We also provide reasons why our model is able to succeed\nin cases where the standard SSIM loss fails.\n", "versions": [{"version": "v1", "created": "Tue, 30 Apr 2019 16:45:35 GMT"}], "update_date": "2019-05-01", "authors_parsed": [["Lu", "Yingjing", ""]]}, {"id": "1904.13366", "submitter": "Nagdev Amruthnath", "authors": "Nagdev Amruthnath, Tarun Gupta", "title": "Factor Analysis in Fault Diagnostics Using Random Forest", "comments": null, "journal-ref": "Industrial Engineering & Management, 2019", "doi": "10.4172/2169-0316.1000278", "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Factor analysis or sometimes referred to as variable analysis has been\nextensively used in classification problems for identifying specific factors\nthat are significant to particular classes. This type of analysis has been\nwidely used in application such as customer segmentation, medical research,\nnetwork traffic, image, and video classification. Today, factor analysis is\nprominently being used in fault diagnosis of machines to identify the\nsignificant factors and to study the root cause of a specific machine fault.\nThe advantage of performing factor analysis in machine maintenance is to\nperform prescriptive analysis (helps answer what actions to take?) and\npreemptive analysis (helps answer how to eliminate the failure mode?). In this\npaper, a real case of an industrial rotating machine was considered where\nvibration and ambient temperature data was collected for monitoring the health\nof the machine. Gaussian mixture model-based clustering was used to cluster the\ndata into significant groups, and spectrum analysis was used to diagnose each\ncluster to a specific state of the machine. The significant features that\nattribute to a particular mode of the machine were identified by using the\nrandom forest classification model. The significant features for specific modes\nof the machine were used to conclude that the clusters generated are distinct\nand have a unique set of significant features.\n", "versions": [{"version": "v1", "created": "Tue, 30 Apr 2019 16:54:13 GMT"}], "update_date": "2019-05-01", "authors_parsed": [["Amruthnath", "Nagdev", ""], ["Gupta", "Tarun", ""]]}, {"id": "1904.13373", "submitter": "Swanand Kadhe", "authors": "Swanand Kadhe, O. Ozan Koyluoglu, Kannan Ramchandran", "title": "Gradient Coding Based on Block Designs for Mitigating Adversarial\n  Stragglers", "comments": "Shorter version accepted in 2019 IEEE International Symposium on\n  Information Theory (ISIT)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IT cs.DC cs.LG math.IT stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Distributed implementations of gradient-based methods, wherein a server\ndistributes gradient computations across worker machines, suffer from slow\nrunning machines, called 'stragglers'. Gradient coding is a coding-theoretic\nframework to mitigate stragglers by enabling the server to recover the gradient\nsum in the presence of stragglers. 'Approximate gradient codes' are variants of\ngradient codes that reduce computation and storage overhead per worker by\nallowing the server to approximately reconstruct the gradient sum.\n  In this work, our goal is to construct approximate gradient codes that are\nresilient to stragglers selected by a computationally unbounded adversary. Our\nmotivation for constructing codes to mitigate adversarial stragglers stems from\nthe challenge of tackling stragglers in massive-scale elastic and serverless\nsystems, wherein it is difficult to statistically model stragglers. Towards\nthis end, we propose a class of approximate gradient codes based on balanced\nincomplete block designs (BIBDs). We show that the approximation error for\nthese codes depends only on the number of stragglers, and thus, adversarial\nstraggler selection has no advantage over random selection. In addition, the\nproposed codes admit computationally efficient decoding at the server. Next, to\ncharacterize fundamental limits of adversarial straggling, we consider the\nnotion of 'adversarial threshold' -- the smallest number of workers that an\nadversary must straggle to inflict certain approximation error. We compute a\nlower bound on the adversarial threshold, and show that codes based on\nsymmetric BIBDs maximize this lower bound among a wide class of codes, making\nthem excellent candidates for mitigating adversarial stragglers.\n", "versions": [{"version": "v1", "created": "Tue, 30 Apr 2019 17:13:32 GMT"}], "update_date": "2019-05-01", "authors_parsed": [["Kadhe", "Swanand", ""], ["Koyluoglu", "O. Ozan", ""], ["Ramchandran", "Kannan", ""]]}, {"id": "1904.13377", "submitter": "Ngoc Quan Pham", "authors": "Ngoc-Quan Pham, Thai-Son Nguyen, Jan Niehues, Markus M\\\"uller,\n  Sebastian St\\\"uker, Alexander Waibel", "title": "Very Deep Self-Attention Networks for End-to-End Speech Recognition", "comments": "Submitted to INTERSPEECH 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG cs.SD eess.AS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recently, end-to-end sequence-to-sequence models for speech recognition have\ngained significant interest in the research community. While previous\narchitecture choices revolve around time-delay neural networks (TDNN) and long\nshort-term memory (LSTM) recurrent neural networks, we propose to use\nself-attention via the Transformer architecture as an alternative. Our analysis\nshows that deep Transformer networks with high learning capacity are able to\nexceed performance from previous end-to-end approaches and even match the\nconventional hybrid systems. Moreover, we trained very deep models with up to\n48 Transformer layers for both encoder and decoders combined with stochastic\nresidual connections, which greatly improve generalizability and training\nefficiency. The resulting models outperform all previous end-to-end ASR\napproaches on the Switchboard benchmark. An ensemble of these models achieve\n9.9% and 17.7% WER on Switchboard and CallHome test sets respectively. This\nfinding brings our end-to-end models to competitive levels with previous hybrid\nsystems. Further, with model ensembling the Transformers can outperform certain\nhybrid systems, which are more complicated in terms of both structure and\ntraining procedure.\n", "versions": [{"version": "v1", "created": "Tue, 30 Apr 2019 17:20:32 GMT"}, {"version": "v2", "created": "Fri, 3 May 2019 14:00:16 GMT"}], "update_date": "2019-05-06", "authors_parsed": [["Pham", "Ngoc-Quan", ""], ["Nguyen", "Thai-Son", ""], ["Niehues", "Jan", ""], ["M\u00fcller", "Markus", ""], ["St\u00fcker", "Sebastian", ""], ["Waibel", "Alexander", ""]]}, {"id": "1904.13386", "submitter": "Robert Bridges", "authors": "Robert A. Bridges, Anthony D. Gruber, Christopher Felder, Miki Verma,\n  Chelsey Hoff", "title": "Active Manifolds: A non-linear analogue to Active Subspaces", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present an approach to analyze $C^1(\\mathbb{R}^m)$ functions that\naddresses limitations present in the Active Subspaces (AS) method of\nConstantine et al.(2015; 2014). Under appropriate hypotheses, our Active\nManifolds (AM) method identifies a 1-D curve in the domain (the active\nmanifold) on which nearly all values of the unknown function are attained, and\nwhich can be exploited for approximation or analysis, especially when $m$ is\nlarge (high-dimensional input space). We provide theorems justifying our AM\ntechnique and an algorithm permitting functional approximation and sensitivity\nanalysis. Using accessible, low-dimensional functions as initial examples, we\nshow AM reduces approximation error by an order of magnitude compared to AS, at\nthe expense of more computation. Following this, we revisit the sensitivity\nanalysis by Glaws et al. (2017), who apply AS to analyze a magnetohydrodynamic\npower generator model, and compare the performance of AM on the same data. Our\nanalysis provides detailed information not captured by AS, exhibiting the\ninfluence of each parameter individually along an active manifold. Overall, AM\nrepresents a novel technique for analyzing functional models with benefits\nincluding: reducing $m$-dimensional analysis to a 1-D analogue, permitting more\naccurate regression than AS (at more computational expense), enabling more\ninformative sensitivity analysis, and granting accessible visualizations(2-D\nplots) of parameter sensitivity along the AM.\n", "versions": [{"version": "v1", "created": "Tue, 30 Apr 2019 17:39:55 GMT"}, {"version": "v2", "created": "Wed, 1 May 2019 15:54:01 GMT"}, {"version": "v3", "created": "Mon, 13 May 2019 13:54:12 GMT"}, {"version": "v4", "created": "Tue, 14 May 2019 13:49:37 GMT"}], "update_date": "2019-05-15", "authors_parsed": [["Bridges", "Robert A.", ""], ["Gruber", "Anthony D.", ""], ["Felder", "Christopher", ""], ["Verma", "Miki", ""], ["Hoff", "Chelsey", ""]]}, {"id": "1904.13387", "submitter": "Ali Yekkehkhany", "authors": "Ali Yekkehkhany, Ebrahim Arian, Mohammad Hajiesmaili, Rakesh Nagi", "title": "Risk-Averse Explore-Then-Commit Algorithms for Finite-Time Bandits", "comments": null, "journal-ref": "2019 IEEE 58th Conference on Decision and Control (CDC)", "doi": "10.1109/CDC40024.2019.9142286", "report-no": "https://ieeexplore.ieee.org/document/9142286", "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we study multi-armed bandit problems in explore-then-commit\nsetting. In our proposed explore-then-commit setting, the goal is to identify\nthe best arm after a pure experimentation (exploration) phase and exploit it\nonce or for a given finite number of times. We identify that although the arm\nwith the highest expected reward is the most desirable objective for infinite\nexploitations, it is not necessarily the one that is most probable to have the\nhighest reward in a single or finite-time exploitations. Alternatively, we\nadvocate the idea of risk-aversion where the objective is to compete against\nthe arm with the best risk-return trade-off. Then, we propose two algorithms\nwhose objectives are to select the arm that is most probable to reward the\nmost. Using a new notion of finite-time exploitation regret, we find an upper\nbound for the minimum number of experiments before commitment, to guarantee an\nupper bound for the regret. As compared to existing risk-averse bandit\nalgorithms, our algorithms do not rely on hyper-parameters, resulting in a more\nrobust behavior in practice, which is verified by the numerical evaluation.\n", "versions": [{"version": "v1", "created": "Tue, 30 Apr 2019 17:40:13 GMT"}, {"version": "v2", "created": "Wed, 8 May 2019 23:34:45 GMT"}, {"version": "v3", "created": "Wed, 11 Sep 2019 18:58:30 GMT"}], "update_date": "2020-12-16", "authors_parsed": [["Yekkehkhany", "Ali", ""], ["Arian", "Ebrahim", ""], ["Hajiesmaili", "Mohammad", ""], ["Nagi", "Rakesh", ""]]}, {"id": "1904.13389", "submitter": "Lin Chen", "authors": "MohammadHossein Bateni, Lin Chen, Hossein Esfandiari, Thomas Fu, Vahab\n  S. Mirrokni, Afshin Rostamizadeh", "title": "Categorical Feature Compression via Submodular Optimization", "comments": "Accepted to ICML 2019. Authors are listed in alphabetical order", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.DS cs.IT math.IT stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In the era of big data, learning from categorical features with very large\nvocabularies (e.g., 28 million for the Criteo click prediction dataset) has\nbecome a practical challenge for machine learning researchers and\npractitioners. We design a highly-scalable vocabulary compression algorithm\nthat seeks to maximize the mutual information between the compressed\ncategorical feature and the target binary labels and we furthermore show that\nits solution is guaranteed to be within a $1-1/e \\approx 63\\%$ factor of the\nglobal optimal solution. To achieve this, we introduce a novel\nre-parametrization of the mutual information objective, which we prove is\nsubmodular, and design a data structure to query the submodular function in\namortized $O(\\log n )$ time (where $n$ is the input vocabulary size). Our\ncomplete algorithm is shown to operate in $O(n \\log n )$ time. Additionally, we\ndesign a distributed implementation in which the query data structure is\ndecomposed across $O(k)$ machines such that each machine only requires $O(\\frac\nn k)$ space, while still preserving the approximation guarantee and using only\nlogarithmic rounds of computation. We also provide analysis of simple\nalternative heuristic compression methods to demonstrate they cannot achieve\nany approximation guarantee. Using the large-scale Criteo learning task, we\ndemonstrate better performance in retaining mutual information and also verify\ncompetitive learning performance compared to other baseline methods.\n", "versions": [{"version": "v1", "created": "Tue, 30 Apr 2019 17:45:13 GMT"}], "update_date": "2019-05-01", "authors_parsed": [["Bateni", "MohammadHossein", ""], ["Chen", "Lin", ""], ["Esfandiari", "Hossein", ""], ["Fu", "Thomas", ""], ["Mirrokni", "Vahab S.", ""], ["Rostamizadeh", "Afshin", ""]]}]