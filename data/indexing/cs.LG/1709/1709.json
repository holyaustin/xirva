[{"id": "1709.00025", "submitter": "Nasser Mohammadiha", "authors": "Nasser Mohammadiha, Paris Smaragdis, Ghazaleh Panahandeh, Simon Doclo", "title": "A State-Space Approach to Dynamic Nonnegative Matrix Factorization", "comments": null, "journal-ref": "IEEE Trans. Signal Process., vol. 63, no. 4, pp. 949--959, Dec.\n  2014", "doi": "10.1109/TSP.2014.2385655", "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Nonnegative matrix factorization (NMF) has been actively investigated and\nused in a wide range of problems in the past decade. A significant amount of\nattention has been given to develop NMF algorithms that are suitable to model\ntime series with strong temporal dependencies. In this paper, we propose a\nnovel state-space approach to perform dynamic NMF (D-NMF). In the proposed\nprobabilistic framework, the NMF coefficients act as the state variables and\ntheir dynamics are modeled using a multi-lag nonnegative vector autoregressive\n(N-VAR) model within the process equation. We use expectation maximization and\npropose a maximum-likelihood estimation framework to estimate the basis matrix\nand the N-VAR model parameters. Interestingly, the N-VAR model parameters are\nobtained by simply applying NMF. Moreover, we derive a maximum a posteriori\nestimate of the state variables (i.e., the NMF coefficients) that is based on a\nprediction step and an update step, similarly to the Kalman filter. We\nillustrate the benefits of the proposed approach using different numerical\nsimulations where D-NMF significantly outperforms its static counterpart.\nExperimental results for three different applications show that the proposed\napproach outperforms two state-of-the-art NMF approaches that exploit temporal\ndependencies, namely a nonnegative hidden Markov model and a frame stacking\napproach, while it requires less memory and computational power.\n", "versions": [{"version": "v1", "created": "Thu, 31 Aug 2017 18:12:52 GMT"}], "update_date": "2017-09-04", "authors_parsed": [["Mohammadiha", "Nasser", ""], ["Smaragdis", "Paris", ""], ["Panahandeh", "Ghazaleh", ""], ["Doclo", "Simon", ""]]}, {"id": "1709.00028", "submitter": "Falcon Dai", "authors": "Falcon Z. Dai and Zheng Cai", "title": "Glyph-aware Embedding of Chinese Characters", "comments": "Workshop on Subword and Character level models in NLP at EMNLP 2017.\n  Source code available", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Given the advantage and recent success of English character-level and\nsubword-unit models in several NLP tasks, we consider the equivalent modeling\nproblem for Chinese. Chinese script is logographic and many Chinese logograms\nare composed of common substructures that provide semantic, phonetic and\nsyntactic hints. In this work, we propose to explicitly incorporate the visual\nappearance of a character's glyph in its representation, resulting in a novel\nglyph-aware embedding of Chinese characters. Being inspired by the success of\nconvolutional neural networks in computer vision, we use them to incorporate\nthe spatio-structural patterns of Chinese glyphs as rendered in raw pixels. In\nthe context of two basic Chinese NLP tasks of language modeling and word\nsegmentation, the model learns to represent each character's task-relevant\nsemantic and syntactic information in the character-level embedding.\n", "versions": [{"version": "v1", "created": "Thu, 31 Aug 2017 18:19:08 GMT"}], "update_date": "2018-09-11", "authors_parsed": [["Dai", "Falcon Z.", ""], ["Cai", "Zheng", ""]]}, {"id": "1709.00029", "submitter": "Patrick Helber", "authors": "Patrick Helber, Benjamin Bischke, Andreas Dengel, Damian Borth", "title": "EuroSAT: A Novel Dataset and Deep Learning Benchmark for Land Use and\n  Land Cover Classification", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we address the challenge of land use and land cover\nclassification using Sentinel-2 satellite images. The Sentinel-2 satellite\nimages are openly and freely accessible provided in the Earth observation\nprogram Copernicus. We present a novel dataset based on Sentinel-2 satellite\nimages covering 13 spectral bands and consisting out of 10 classes with in\ntotal 27,000 labeled and geo-referenced images. We provide benchmarks for this\nnovel dataset with its spectral bands using state-of-the-art deep Convolutional\nNeural Network (CNNs). With the proposed novel dataset, we achieved an overall\nclassification accuracy of 98.57%. The resulting classification system opens a\ngate towards a number of Earth observation applications. We demonstrate how\nthis classification system can be used for detecting land use and land cover\nchanges and how it can assist in improving geographical maps. The\ngeo-referenced dataset EuroSAT is made publicly available at\nhttps://github.com/phelber/eurosat.\n", "versions": [{"version": "v1", "created": "Thu, 31 Aug 2017 18:19:10 GMT"}, {"version": "v2", "created": "Fri, 1 Feb 2019 09:51:18 GMT"}], "update_date": "2019-02-04", "authors_parsed": [["Helber", "Patrick", ""], ["Bischke", "Benjamin", ""], ["Dengel", "Andreas", ""], ["Borth", "Damian", ""]]}, {"id": "1709.00045", "submitter": "Battista Biggio", "authors": "Ambra Demontis, Paolo Russu, Battista Biggio, Giorgio Fumera, Fabio\n  Roli", "title": "On Security and Sparsity of Linear Classifiers for Adversarial Settings", "comments": null, "journal-ref": "IAPR Workshop S+SSPR 2016", "doi": "10.1007/978-3-319-49055-7_29", "report-no": null, "categories": "cs.LG cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Machine-learning techniques are widely used in security-related applications,\nlike spam and malware detection. However, in such settings, they have been\nshown to be vulnerable to adversarial attacks, including the deliberate\nmanipulation of data at test time to evade detection. In this work, we focus on\nthe vulnerability of linear classifiers to evasion attacks. This can be\nconsidered a relevant problem, as linear classifiers have been increasingly\nused in embedded systems and mobile devices for their low processing time and\nmemory requirements. We exploit recent findings in robust optimization to\ninvestigate the link between regularization and security of linear classifiers,\ndepending on the type of attack. We also analyze the relationship between the\nsparsity of feature weights, which is desirable for reducing processing cost,\nand the security of linear classifiers. We further propose a novel octagonal\nregularizer that allows us to achieve a proper trade-off between them. Finally,\nwe empirically show how this regularizer can improve classifier security and\nsparsity in real-world application examples including spam and malware\ndetection.\n", "versions": [{"version": "v1", "created": "Thu, 31 Aug 2017 19:11:56 GMT"}], "update_date": "2017-09-04", "authors_parsed": [["Demontis", "Ambra", ""], ["Russu", "Paolo", ""], ["Biggio", "Battista", ""], ["Fumera", "Giorgio", ""], ["Roli", "Fabio", ""]]}, {"id": "1709.00074", "submitter": "Tomer Galanti", "authors": "Tomer Galanti, Lior Wolf and Sagie Benaim", "title": "The Role of Minimal Complexity Functions in Unsupervised Learning of\n  Semantic Mappings", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We discuss the feasibility of the following learning problem: given unmatched\nsamples from two domains and nothing else, learn a mapping between the two,\nwhich preserves semantics. Due to the lack of paired samples and without any\ndefinition of the semantic information, the problem might seem ill-posed.\nSpecifically, in typical cases, it seems possible to build infinitely many\nalternative mappings from every target mapping. This apparent ambiguity stands\nin sharp contrast to the recent empirical success in solving this problem.\n  We identify the abstract notion of aligning two domains in a semantic way\nwith concrete terms of minimal relative complexity. A theoretical framework for\nmeasuring the complexity of compositions of functions is developed in order to\nshow that it is reasonable to expect the minimal complexity mapping to be\nunique. The measured complexity used is directly related to the depth of the\nneural networks being learned and a semantically aligned mapping could then be\ncaptured simply by learning using architectures that are not much bigger than\nthe minimal architecture.\n  Various predictions are made based on the hypothesis that semantic alignment\ncan be captured by the minimal mapping. These are verified extensively. In\naddition, a new mapping algorithm is proposed and shown to lead to better\nmapping results.\n", "versions": [{"version": "v1", "created": "Thu, 31 Aug 2017 20:42:12 GMT"}, {"version": "v2", "created": "Tue, 31 Oct 2017 11:46:56 GMT"}, {"version": "v3", "created": "Wed, 15 Jan 2020 08:46:42 GMT"}], "update_date": "2020-01-16", "authors_parsed": [["Galanti", "Tomer", ""], ["Wolf", "Lior", ""], ["Benaim", "Sagie", ""]]}, {"id": "1709.00106", "submitter": "Brendt Wohlberg", "authors": "Jialin Liu, Cristina Garcia-Cardona, Brendt Wohlberg, Wotao Yin", "title": "First and Second Order Methods for Online Convolutional Dictionary\n  Learning", "comments": null, "journal-ref": "SIAM J. Imaging Sci., 11(2), 1589-1628, 2018", "doi": "10.1137/17M1145689", "report-no": null, "categories": "cs.LG cs.CV eess.IV math.OC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Convolutional sparse representations are a form of sparse representation with\na structured, translation invariant dictionary. Most convolutional dictionary\nlearning algorithms to date operate in batch mode, requiring simultaneous\naccess to all training images during the learning process, which results in\nvery high memory usage and severely limits the training data that can be used.\nVery recently, however, a number of authors have considered the design of\nonline convolutional dictionary learning algorithms that offer far better\nscaling of memory and computational cost with training set size than batch\nmethods. This paper extends our prior work, improving a number of aspects of\nour previous algorithm; proposing an entirely new one, with better performance,\nand that supports the inclusion of a spatial mask for learning from incomplete\ndata; and providing a rigorous theoretical analysis of these methods.\n", "versions": [{"version": "v1", "created": "Thu, 31 Aug 2017 23:19:02 GMT"}, {"version": "v2", "created": "Sat, 10 Feb 2018 17:18:20 GMT"}, {"version": "v3", "created": "Sat, 16 Jun 2018 19:21:10 GMT"}], "update_date": "2018-06-19", "authors_parsed": [["Liu", "Jialin", ""], ["Garcia-Cardona", "Cristina", ""], ["Wohlberg", "Brendt", ""], ["Yin", "Wotao", ""]]}, {"id": "1709.00127", "submitter": "Nihar Shah", "authors": "Nihar B. Shah, Sivaraman Balakrishnan, Martin J. Wainwright", "title": "Low Permutation-rank Matrices: Structural Properties and Noisy\n  Completion", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.IT cs.LG math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the problem of noisy matrix completion, in which the goal is to\nreconstruct a structured matrix whose entries are partially observed in noise.\nStandard approaches to this underdetermined inverse problem are based on\nassuming that the underlying matrix has low rank, or is well-approximated by a\nlow rank matrix. In this paper, we propose a richer model based on what we term\nthe \"permutation-rank\" of a matrix. We first describe how the classical\nnon-negative rank model enforces restrictions that may be undesirable in\npractice, and how and these restrictions can be avoided by using the richer\npermutation-rank model. Second, we establish the minimax rates of estimation\nunder the new permutation-based model, and prove that surprisingly, the minimax\nrates are equivalent up to logarithmic factors to those for estimation under\nthe typical low rank model. Third, we analyze a computationally efficient\nsingular-value-thresholding algorithm, known to be optimal for the low-rank\nsetting, and show that it also simultaneously yields a consistent estimator for\nthe low-permutation rank setting. Finally, we present various structural\nresults characterizing the uniqueness of the permutation-rank decomposition,\nand characterizing convex approximations of the permutation-rank polytope.\n", "versions": [{"version": "v1", "created": "Fri, 1 Sep 2017 01:25:45 GMT"}], "update_date": "2017-09-04", "authors_parsed": [["Shah", "Nihar B.", ""], ["Balakrishnan", "Sivaraman", ""], ["Wainwright", "Martin J.", ""]]}, {"id": "1709.00139", "submitter": "Hansi Jiang", "authors": "Hansi Jiang, Haoyu Wang, Wenhao Hu, Deovrat Kakde and Arin Chaudhuri", "title": "Fast Incremental SVDD Learning Algorithm with the Gaussian Kernel", "comments": "18 pages, 1 table, 4 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Support vector data description (SVDD) is a machine learning technique that\nis used for single-class classification and outlier detection. The idea of SVDD\nis to find a set of support vectors that defines a boundary around data. When\ndealing with online or large data, existing batch SVDD methods have to be rerun\nin each iteration. We propose an incremental learning algorithm for SVDD that\nuses the Gaussian kernel. This algorithm builds on the observation that all\nsupport vectors on the boundary have the same distance to the center of sphere\nin a higher-dimensional feature space as mapped by the Gaussian kernel\nfunction. Each iteration involves only the existing support vectors and the new\ndata point. Moreover, the algorithm is based solely on matrix manipulations;\nthe support vectors and their corresponding Lagrange multiplier $\\alpha_i$'s\nare automatically selected and determined in each iteration. It can be seen\nthat the complexity of our algorithm in each iteration is only $O(k^2)$, where\n$k$ is the number of support vectors. Experimental results on some real data\nsets indicate that FISVDD demonstrates significant gains in efficiency with\nalmost no loss in either outlier detection accuracy or objective function\nvalue.\n", "versions": [{"version": "v1", "created": "Fri, 1 Sep 2017 02:47:05 GMT"}, {"version": "v2", "created": "Tue, 16 Jan 2018 18:20:36 GMT"}, {"version": "v3", "created": "Thu, 1 Feb 2018 23:37:31 GMT"}, {"version": "v4", "created": "Thu, 1 Nov 2018 22:13:35 GMT"}], "update_date": "2018-11-05", "authors_parsed": [["Jiang", "Hansi", ""], ["Wang", "Haoyu", ""], ["Hu", "Wenhao", ""], ["Kakde", "Deovrat", ""], ["Chaudhuri", "Arin", ""]]}, {"id": "1709.00149", "submitter": "Clayton Morrison", "authors": "Enrique Noriega-Atala, Marco A. Valenzuela-Escarcega, Clayton T.\n  Morrison, Mihai Surdeanu", "title": "Learning what to read: Focused machine reading", "comments": "6 pages, 1 figure, 1 algorithm, 2 tables, accepted to EMNLP 2017", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.CL cs.IR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent efforts in bioinformatics have achieved tremendous progress in the\nmachine reading of biomedical literature, and the assembly of the extracted\nbiochemical interactions into large-scale models such as protein signaling\npathways. However, batch machine reading of literature at today's scale (PubMed\nalone indexes over 1 million papers per year) is unfeasible due to both cost\nand processing overhead. In this work, we introduce a focused reading approach\nto guide the machine reading of biomedical literature towards what literature\nshould be read to answer a biomedical query as efficiently as possible. We\nintroduce a family of algorithms for focused reading, including an intuitive,\nstrong baseline, and a second approach which uses a reinforcement learning (RL)\nframework that learns when to explore (widen the search) or exploit (narrow\nit). We demonstrate that the RL approach is capable of answering more queries\nthan the baseline, while being more efficient, i.e., reading fewer documents.\n", "versions": [{"version": "v1", "created": "Fri, 1 Sep 2017 04:09:42 GMT"}], "update_date": "2017-09-04", "authors_parsed": [["Noriega-Atala", "Enrique", ""], ["Valenzuela-Escarcega", "Marco A.", ""], ["Morrison", "Clayton T.", ""], ["Surdeanu", "Mihai", ""]]}, {"id": "1709.00155", "submitter": "Lei Sha", "authors": "Lei Sha, Lili Mou, Tianyu Liu, Pascal Poupart, Sujian Li, Baobao\n  Chang, Zhifang Sui", "title": "Order-Planning Neural Text Generation From Structured Data", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.IR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Generating texts from structured data (e.g., a table) is important for\nvarious natural language processing tasks such as question answering and dialog\nsystems. In recent studies, researchers use neural language models and\nencoder-decoder frameworks for table-to-text generation. However, these neural\nnetwork-based approaches do not model the order of contents during text\ngeneration. When a human writes a summary based on a given table, he or she\nwould probably consider the content order before wording. In a biography, for\nexample, the nationality of a person is typically mentioned before occupation\nin a biography. In this paper, we propose an order-planning text generation\nmodel to capture the relationship between different fields and use such\nrelationship to make the generated text more fluent and smooth. We conducted\nexperiments on the WikiBio dataset and achieve significantly higher performance\nthan previous methods in terms of BLEU, ROUGE, and NIST scores.\n", "versions": [{"version": "v1", "created": "Fri, 1 Sep 2017 04:46:10 GMT"}], "update_date": "2017-09-04", "authors_parsed": [["Sha", "Lei", ""], ["Mou", "Lili", ""], ["Liu", "Tianyu", ""], ["Poupart", "Pascal", ""], ["Li", "Sujian", ""], ["Chang", "Baobao", ""], ["Sui", "Zhifang", ""]]}, {"id": "1709.00199", "submitter": "Lior Wolf", "authors": "Naama Hadad, Lior Wolf, Moni Shahar", "title": "A Two-Step Disentanglement Method", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We address the problem of disentanglement of factors that generate a given\ndata into those that are correlated with the labeling and those that are not.\nOur solution is simpler than previous solutions and employs adversarial\ntraining. First, the part of the data that is correlated with the labels is\nextracted by training a classifier. Then, the other part is extracted such that\nit enables the reconstruction of the original data but does not contain label\ninformation. The utility of the new method is demonstrated on visual datasets\nas well as on financial data. Our code is available at\nhttps://github.com/naamahadad/A-Two-Step-Disentanglement-Method\n", "versions": [{"version": "v1", "created": "Fri, 1 Sep 2017 08:45:43 GMT"}, {"version": "v2", "created": "Tue, 14 Jan 2020 16:19:44 GMT"}], "update_date": "2020-01-15", "authors_parsed": [["Hadad", "Naama", ""], ["Wolf", "Lior", ""], ["Shahar", "Moni", ""]]}, {"id": "1709.00228", "submitter": "Yang Cai", "authors": "Yang Cai, Constantinos Daskalakis", "title": "Learning Multi-item Auctions with (or without) Samples", "comments": "Appears in FOCS 2017", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.GT cs.DS cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We provide algorithms that learn simple auctions whose revenue is\napproximately optimal in multi-item multi-bidder settings, for a wide range of\nvaluations including unit-demand, additive, constrained additive, XOS, and\nsubadditive. We obtain our learning results in two settings. The first is the\ncommonly studied setting where sample access to the bidders' distributions over\nvaluations is given, for both regular distributions and arbitrary distributions\nwith bounded support. Our algorithms require polynomially many samples in the\nnumber of items and bidders. The second is a more general max-min learning\nsetting that we introduce, where we are given \"approximate distributions,\" and\nwe seek to compute an auction whose revenue is approximately optimal\nsimultaneously for all \"true distributions\" that are close to the given ones.\nThese results are more general in that they imply the sample-based results, and\nare also applicable in settings where we have no sample access to the\nunderlying distributions but have estimated them indirectly via market research\nor by observation of previously run, potentially non-truthful auctions.\n  Our results hold for valuation distributions satisfying the standard (and\nnecessary) independence-across-items property. They also generalize and improve\nupon recent works, which have provided algorithms that learn approximately\noptimal auctions in more restricted settings with additive, subadditive and\nunit-demand valuations using sample access to distributions. We generalize\nthese results to the complete unit-demand, additive, and XOS setting, to i.i.d.\nsubadditive bidders, and to the max-min setting.\n  Our results are enabled by new uniform convergence bounds for hypotheses\nclasses under product measures. Our bounds result in exponential savings in\nsample complexity compared to bounds derived by bounding the VC dimension, and\nare of independent interest.\n", "versions": [{"version": "v1", "created": "Fri, 1 Sep 2017 10:07:18 GMT"}], "update_date": "2017-09-04", "authors_parsed": [["Cai", "Yang", ""], ["Daskalakis", "Constantinos", ""]]}, {"id": "1709.00300", "submitter": "Yu Wang", "authors": "Yu Wang, Jixing Xu, Aohan Wu, Mantian Li, Yang He, Jinghe Hu, Weipeng\n  P. Yan", "title": "Telepath: Understanding Users from a Human Vision Perspective in\n  Large-Scale Recommender Systems", "comments": "8 pages, 11 figures, 1 table", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Designing an e-commerce recommender system that serves hundreds of millions\nof active users is a daunting challenge. From a human vision perspective,\nthere're two key factors that affect users' behaviors: items' attractiveness\nand their matching degree with users' interests. This paper proposes Telepath,\na vision-based bionic recommender system model, which understands users from\nsuch perspective. Telepath is a combination of a convolutional neural network\n(CNN), a recurrent neural network (RNN) and deep neural networks (DNNs). Its\nCNN subnetwork simulates the human vision system to extract key visual signals\nof items' attractiveness and generate corresponding activations. Its RNN and\nDNN subnetworks simulate cerebral cortex to understand users' interest based on\nthe activations generated from browsed items. In practice, the Telepath model\nhas been launched to JD's recommender system and advertising system. For one of\nthe major item recommendation blocks on the JD app, click-through rate (CTR),\ngross merchandise value (GMV) and orders have increased 1.59%, 8.16% and 8.71%\nrespectively. For several major ads publishers of JD demand-side platform, CTR,\nGMV and return on investment have increased 6.58%, 61.72% and 65.57%\nrespectively by the first launch, and further increased 2.95%, 41.75% and\n41.37% respectively by the second launch.\n", "versions": [{"version": "v1", "created": "Fri, 1 Sep 2017 13:29:36 GMT"}, {"version": "v2", "created": "Mon, 4 Sep 2017 16:06:57 GMT"}], "update_date": "2017-09-05", "authors_parsed": [["Wang", "Yu", ""], ["Xu", "Jixing", ""], ["Wu", "Aohan", ""], ["Li", "Mantian", ""], ["He", "Yang", ""], ["Hu", "Jinghe", ""], ["Yan", "Weipeng P.", ""]]}, {"id": "1709.00387", "submitter": "Suwon Shon", "authors": "Suwon Shon, Ahmed Ali and James Glass", "title": "MIT-QCRI Arabic Dialect Identification System for the 2017 Multi-Genre\n  Broadcast Challenge", "comments": "Submitted to the 2017 IEEE Automatic Speech Recognition and\n  Understanding Workshop (ASRU 2017)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG cs.SD", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In order to successfully annotate the Arabic speech con- tent found in\nopen-domain media broadcasts, it is essential to be able to process a diverse\nset of Arabic dialects. For the 2017 Multi-Genre Broadcast challenge (MGB-3)\nthere were two possible tasks: Arabic speech recognition, and Arabic Dialect\nIdentification (ADI). In this paper, we describe our efforts to create an ADI\nsystem for the MGB-3 challenge, with the goal of distinguishing amongst four\nmajor Arabic dialects, as well as Modern Standard Arabic. Our research fo-\ncused on dialect variability and domain mismatches between the training and\ntest domain. In order to achieve a robust ADI system, we explored both Siamese\nneural network models to learn similarity and dissimilarities among Arabic\ndialects, as well as i-vector post-processing to adapt domain mismatches. Both\nAcoustic and linguistic features were used for the final MGB-3 submissions,\nwith the best primary system achieving 75% accuracy on the official 10hr test\nset.\n", "versions": [{"version": "v1", "created": "Mon, 28 Aug 2017 14:20:02 GMT"}], "update_date": "2017-09-04", "authors_parsed": [["Shon", "Suwon", ""], ["Ali", "Ahmed", ""], ["Glass", "James", ""]]}, {"id": "1709.00440", "submitter": "Briland Hitaj", "authors": "Briland Hitaj, Paolo Gasti, Giuseppe Ateniese, Fernando Perez-Cruz", "title": "PassGAN: A Deep Learning Approach for Password Guessing", "comments": "This is an extended version of the paper which appeared in NeurIPS\n  2018 Workshop on Security in Machine Learning (SecML'18), see\n  https://github.com/secml2018/secml2018.github.io/raw/master/PASSGAN_SECML2018.pdf", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  State-of-the-art password guessing tools, such as HashCat and John the\nRipper, enable users to check billions of passwords per second against password\nhashes. In addition to performing straightforward dictionary attacks, these\ntools can expand password dictionaries using password generation rules, such as\nconcatenation of words (e.g., \"password123456\") and leet speak (e.g.,\n\"password\" becomes \"p4s5w0rd\"). Although these rules work well in practice,\nexpanding them to model further passwords is a laborious task that requires\nspecialized expertise. To address this issue, in this paper we introduce\nPassGAN, a novel approach that replaces human-generated password rules with\ntheory-grounded machine learning algorithms. Instead of relying on manual\npassword analysis, PassGAN uses a Generative Adversarial Network (GAN) to\nautonomously learn the distribution of real passwords from actual password\nleaks, and to generate high-quality password guesses. Our experiments show that\nthis approach is very promising. When we evaluated PassGAN on two large\npassword datasets, we were able to surpass rule-based and state-of-the-art\nmachine learning password guessing tools. However, in contrast with the other\ntools, PassGAN achieved this result without any a-priori knowledge on passwords\nor common password structures. Additionally, when we combined the output of\nPassGAN with the output of HashCat, we were able to match 51%-73% more\npasswords than with HashCat alone. This is remarkable, because it shows that\nPassGAN can autonomously extract a considerable number of password properties\nthat current state-of-the art rules do not encode.\n", "versions": [{"version": "v1", "created": "Fri, 1 Sep 2017 18:42:00 GMT"}, {"version": "v2", "created": "Fri, 9 Mar 2018 21:03:46 GMT"}, {"version": "v3", "created": "Thu, 14 Feb 2019 19:51:21 GMT"}], "update_date": "2019-02-18", "authors_parsed": [["Hitaj", "Briland", ""], ["Gasti", "Paolo", ""], ["Ateniese", "Giuseppe", ""], ["Perez-Cruz", "Fernando", ""]]}, {"id": "1709.00503", "submitter": "Cameron Allen", "authors": "Cameron Allen, Kavosh Asadi, Melrose Roderick, Abdel-rahman Mohamed,\n  George Konidaris, Michael Littman", "title": "Mean Actor Critic", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a new algorithm, Mean Actor-Critic (MAC), for discrete-action\ncontinuous-state reinforcement learning. MAC is a policy gradient algorithm\nthat uses the agent's explicit representation of all action values to estimate\nthe gradient of the policy, rather than using only the actions that were\nactually executed. We prove that this approach reduces variance in the policy\ngradient estimate relative to traditional actor-critic methods. We show\nempirical results on two control domains and on six Atari games, where MAC is\ncompetitive with state-of-the-art policy search algorithms.\n", "versions": [{"version": "v1", "created": "Fri, 1 Sep 2017 22:53:03 GMT"}, {"version": "v2", "created": "Tue, 22 May 2018 20:20:59 GMT"}], "update_date": "2018-05-24", "authors_parsed": [["Allen", "Cameron", ""], ["Asadi", "Kavosh", ""], ["Roderick", "Melrose", ""], ["Mohamed", "Abdel-rahman", ""], ["Konidaris", "George", ""], ["Littman", "Michael", ""]]}, {"id": "1709.00513", "submitter": "Zheng Xu", "authors": "Zheng Xu, Yen-Chang Hsu, Jiawei Huang", "title": "Training Shallow and Thin Networks for Acceleration via Knowledge\n  Distillation with Conditional Adversarial Networks", "comments": "Shorter version will appear at ICLR workshop 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  There is an increasing interest on accelerating neural networks for real-time\napplications. We study the student-teacher strategy, in which a small and fast\nstudent network is trained with the auxiliary information learned from a large\nand accurate teacher network. We propose to use conditional adversarial\nnetworks to learn the loss function to transfer knowledge from teacher to\nstudent. The proposed method is particularly effective for relatively small\nstudent networks. Moreover, experimental results show the effect of network\nsize when the modern networks are used as student. We empirically study the\ntrade-off between inference time and classification accuracy, and provide\nsuggestions on choosing a proper student network.\n", "versions": [{"version": "v1", "created": "Sat, 2 Sep 2017 01:03:08 GMT"}, {"version": "v2", "created": "Mon, 16 Apr 2018 18:42:13 GMT"}], "update_date": "2018-04-18", "authors_parsed": [["Xu", "Zheng", ""], ["Hsu", "Yen-Chang", ""], ["Huang", "Jiawei", ""]]}, {"id": "1709.00537", "submitter": "Jineng Ren", "authors": "Jineng Ren and Jarvis Haupt", "title": "Communication-efficient Algorithm for Distributed Sparse Learning via\n  Two-way Truncation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG math.OC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a communicationally and computationally efficient algorithm for\nhigh-dimensional distributed sparse learning. At each iteration, local machines\ncompute the gradient on local data and the master machine solves one shifted\n$l_1$ regularized minimization problem. The communication cost is reduced from\nconstant times of the dimension number for the state-of-the-art algorithm to\nconstant times of the sparsity number via Two-way Truncation procedure.\nTheoretically, we prove that the estimation error of the proposed algorithm\ndecreases exponentially and matches that of the centralized method under mild\nassumptions. Extensive experiments on both simulated data and real data verify\nthat the proposed algorithm is efficient and has performance comparable with\nthe centralized method on solving high-dimensional sparse learning problems.\n", "versions": [{"version": "v1", "created": "Sat, 2 Sep 2017 06:02:38 GMT"}, {"version": "v2", "created": "Sat, 9 Sep 2017 05:15:59 GMT"}], "update_date": "2017-09-12", "authors_parsed": [["Ren", "Jineng", ""], ["Haupt", "Jarvis", ""]]}, {"id": "1709.00541", "submitter": "Rustem Takhanov", "authors": "Rustem Takhanov and Zhenisbek Assylbekov", "title": "Patterns versus Characters in Subword-aware Neural Language Modeling", "comments": "10 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Words in some natural languages can have a composite structure. Elements of\nthis structure include the root (that could also be composite), prefixes and\nsuffixes with which various nuances and relations to other words can be\nexpressed. Thus, in order to build a proper word representation one must take\ninto account its internal structure. From a corpus of texts we extract a set of\nfrequent subwords and from the latter set we select patterns, i.e. subwords\nwhich encapsulate information on character $n$-gram regularities. The selection\nis made using the pattern-based Conditional Random Field model with $l_1$\nregularization. Further, for every word we construct a new sequence over an\nalphabet of patterns. The new alphabet's symbols confine a local statistical\ncontext stronger than the characters, therefore they allow better\nrepresentations in ${\\mathbb{R}}^n$ and are better building blocks for word\nrepresentation. In the task of subword-aware language modeling, pattern-based\nmodels outperform character-based analogues by 2-20 perplexity points. Also, a\nrecurrent neural network in which a word is represented as a sum of embeddings\nof its patterns is on par with a competitive and significantly more\nsophisticated character-based convolutional architecture.\n", "versions": [{"version": "v1", "created": "Sat, 2 Sep 2017 07:00:22 GMT"}], "update_date": "2017-09-05", "authors_parsed": [["Takhanov", "Rustem", ""], ["Assylbekov", "Zhenisbek", ""]]}, {"id": "1709.00572", "submitter": "C\\u{a}t\\u{a}lina Cangea", "authors": "C\\u{a}t\\u{a}lina Cangea, Petar Veli\\v{c}kovi\\'c, Pietro Li\\`o", "title": "XFlow: Cross-modal Deep Neural Networks for Audiovisual Classification", "comments": "Accepted at the IEEE ICDL-EPIROB 2017 Workshop on Computational\n  Models for Crossmodal Learning (CMCML), 4 pages, 6 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.AI cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In recent years, there have been numerous developments towards solving\nmultimodal tasks, aiming to learn a stronger representation than through a\nsingle modality. Certain aspects of the data can be particularly useful in this\ncase - for example, correlations in the space or time domain across modalities\n- but should be wisely exploited in order to benefit from their full predictive\npotential. We propose two deep learning architectures with multimodal\ncross-connections that allow for dataflow between several feature extractors\n(XFlow). Our models derive more interpretable features and achieve better\nperformances than models which do not exchange representations, usefully\nexploiting correlations between audio and visual data, which have a different\ndimensionality and are nontrivially exchangeable. Our work improves on existing\nmultimodal deep learning algorithms in two essential ways: (1) it presents a\nnovel method for performing cross-modality (before features are learned from\nindividual modalities) and (2) extends the previously proposed\ncross-connections which only transfer information between streams that process\ncompatible data. Illustrating some of the representations learned by the\nconnections, we analyse their contribution to the increase in discrimination\nability and reveal their compatibility with a lip-reading network intermediate\nrepresentation. We provide the research community with Digits, a new dataset\nconsisting of three data types extracted from videos of people saying the\ndigits 0-9. Results show that both cross-modal architectures outperform their\nbaselines (by up to 11.5%) when evaluated on the AVletters, CUAVE and Digits\ndatasets, achieving state-of-the-art results.\n", "versions": [{"version": "v1", "created": "Sat, 2 Sep 2017 12:43:59 GMT"}, {"version": "v2", "created": "Fri, 12 Apr 2019 21:43:42 GMT"}], "update_date": "2019-04-16", "authors_parsed": [["Cangea", "C\u0103t\u0103lina", ""], ["Veli\u010dkovi\u0107", "Petar", ""], ["Li\u00f2", "Pietro", ""]]}, {"id": "1709.00575", "submitter": "Marek Rei", "authors": "Marek Rei, Luana Bulat, Douwe Kiela, Ekaterina Shutova", "title": "Grasping the Finer Point: A Supervised Similarity Network for Metaphor\n  Detection", "comments": "EMNLP 2017", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The ubiquity of metaphor in our everyday communication makes it an important\nproblem for natural language understanding. Yet, the majority of metaphor\nprocessing systems to date rely on hand-engineered features and there is still\nno consensus in the field as to which features are optimal for this task. In\nthis paper, we present the first deep learning architecture designed to capture\nmetaphorical composition. Our results demonstrate that it outperforms the\nexisting approaches in the metaphor identification task.\n", "versions": [{"version": "v1", "created": "Sat, 2 Sep 2017 13:13:06 GMT"}], "update_date": "2017-09-05", "authors_parsed": [["Rei", "Marek", ""], ["Bulat", "Luana", ""], ["Kiela", "Douwe", ""], ["Shutova", "Ekaterina", ""]]}, {"id": "1709.00584", "submitter": "Mark Anastasio", "authors": "Brendan Kelly, Thomas P. Matthews, Mark A. Anastasio", "title": "Deep Learning-Guided Image Reconstruction from Incomplete Data", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  An approach to incorporate deep learning within an iterative image\nreconstruction framework to reconstruct images from severely incomplete\nmeasurement data is presented. Specifically, we utilize a convolutional neural\nnetwork (CNN) as a quasi-projection operator within a least squares\nminimization procedure. The CNN is trained to encode high level information\nabout the class of images being imaged; this information is utilized to\nmitigate artifacts in intermediate images produced by use of an iterative\nmethod. The structure of the method was inspired by the proximal gradient\ndescent method, where the proximal operator is replaced by a deep CNN and the\ngradient descent step is generalized by use of a linear reconstruction\noperator. It is demonstrated that this approach improves image quality for\nseveral cases of limited-view image reconstruction and that using a CNN in an\niterative method increases performance compared to conventional image\nreconstruction approaches. We test our method on several limited-view image\nreconstruction problems. Qualitative and quantitative results demonstrate\nstate-of-the-art performance.\n", "versions": [{"version": "v1", "created": "Sat, 2 Sep 2017 14:15:24 GMT"}], "update_date": "2017-09-05", "authors_parsed": [["Kelly", "Brendan", ""], ["Matthews", "Thomas P.", ""], ["Anastasio", "Mark A.", ""]]}, {"id": "1709.00599", "submitter": "Aryan Mokhtari", "authors": "Aryan Mokhtari and Alejandro Ribeiro", "title": "First-Order Adaptive Sample Size Methods to Reduce Complexity of\n  Empirical Risk Minimization", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG math.OC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper studies empirical risk minimization (ERM) problems for large-scale\ndatasets and incorporates the idea of adaptive sample size methods to improve\nthe guaranteed convergence bounds for first-order stochastic and deterministic\nmethods. In contrast to traditional methods that attempt to solve the ERM\nproblem corresponding to the full dataset directly, adaptive sample size\nschemes start with a small number of samples and solve the corresponding ERM\nproblem to its statistical accuracy. The sample size is then grown\ngeometrically -- e.g., scaling by a factor of two -- and use the solution of\nthe previous ERM as a warm start for the new ERM. Theoretical analyses show\nthat the use of adaptive sample size methods reduces the overall computational\ncost of achieving the statistical accuracy of the whole dataset for a broad\nrange of deterministic and stochastic first-order methods. The gains are\nspecific to the choice of method. When particularized to, e.g., accelerated\ngradient descent and stochastic variance reduce gradient, the computational\ncost advantage is a logarithm of the number of training samples. Numerical\nexperiments on various datasets confirm theoretical claims and showcase the\ngains of using the proposed adaptive sample size scheme.\n", "versions": [{"version": "v1", "created": "Sat, 2 Sep 2017 16:13:04 GMT"}], "update_date": "2017-09-05", "authors_parsed": [["Mokhtari", "Aryan", ""], ["Ribeiro", "Alejandro", ""]]}, {"id": "1709.00609", "submitter": "Battista Biggio", "authors": "Battista Biggio, Giorgio Fumera, Fabio Roli", "title": "Security Evaluation of Pattern Classifiers under Attack", "comments": null, "journal-ref": "IEEE Transactions on Knowledge and Data Engineering,\n  26(4):984-996, April 2014", "doi": "10.1109/TKDE.2013.57", "report-no": null, "categories": "cs.LG cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Pattern classification systems are commonly used in adversarial applications,\nlike biometric authentication, network intrusion detection, and spam filtering,\nin which data can be purposely manipulated by humans to undermine their\noperation. As this adversarial scenario is not taken into account by classical\ndesign methods, pattern classification systems may exhibit vulnerabilities,\nwhose exploitation may severely affect their performance, and consequently\nlimit their practical utility. Extending pattern classification theory and\ndesign methods to adversarial settings is thus a novel and very relevant\nresearch direction, which has not yet been pursued in a systematic way. In this\npaper, we address one of the main open issues: evaluating at design phase the\nsecurity of pattern classifiers, namely, the performance degradation under\npotential attacks they may incur during operation. We propose a framework for\nempirical evaluation of classifier security that formalizes and generalizes the\nmain ideas proposed in the literature, and give examples of its use in three\nreal applications. Reported results show that security evaluation can provide a\nmore complete understanding of the classifier's behavior in adversarial\nenvironments, and lead to better design choices.\n", "versions": [{"version": "v1", "created": "Sat, 2 Sep 2017 17:38:45 GMT"}], "update_date": "2017-09-05", "authors_parsed": [["Biggio", "Battista", ""], ["Fumera", "Giorgio", ""], ["Roli", "Fabio", ""]]}, {"id": "1709.00614", "submitter": "Xiao Fu", "authors": "Xiao Fu and Kejun Huang and Nicholas D. Sidiropoulos", "title": "On Identifiability of Nonnegative Matrix Factorization", "comments": null, "journal-ref": null, "doi": "10.1109/LSP.2018.2789405", "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this letter, we propose a new identification criterion that guarantees the\nrecovery of the low-rank latent factors in the nonnegative matrix factorization\n(NMF) model, under mild conditions. Specifically, using the proposed criterion,\nit suffices to identify the latent factors if the rows of one factor are\n\\emph{sufficiently scattered} over the nonnegative orthant, while no structural\nassumption is imposed on the other factor except being full-rank. This is by\nfar the mildest condition under which the latent factors are provably\nidentifiable from the NMF model.\n", "versions": [{"version": "v1", "created": "Sat, 2 Sep 2017 18:40:37 GMT"}], "update_date": "2018-03-14", "authors_parsed": [["Fu", "Xiao", ""], ["Huang", "Kejun", ""], ["Sidiropoulos", "Nicholas D.", ""]]}, {"id": "1709.00643", "submitter": "Qifeng Chen", "authors": "Qifeng Chen, Jia Xu, Vladlen Koltun", "title": "Fast Image Processing with Fully-Convolutional Networks", "comments": "Published at the International Conference on Computer Vision (ICCV\n  2017)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.GR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present an approach to accelerating a wide variety of image processing\noperators. Our approach uses a fully-convolutional network that is trained on\ninput-output pairs that demonstrate the operator's action. After training, the\noriginal operator need not be run at all. The trained network operates at full\nresolution and runs in constant time. We investigate the effect of network\narchitecture on approximation accuracy, runtime, and memory footprint, and\nidentify a specific architecture that balances these considerations. We\nevaluate the presented approach on ten advanced image processing operators,\nincluding multiple variational models, multiscale tone and detail manipulation,\nphotographic style transfer, nonlocal dehazing, and nonphotorealistic\nstylization. All operators are approximated by the same model. Experiments\ndemonstrate that the presented approach is significantly more accurate than\nprior approximation schemes. It increases approximation accuracy as measured by\nPSNR across the evaluated operators by 8.5 dB on the MIT-Adobe dataset (from\n27.5 to 36 dB) and reduces DSSIM by a multiplicative factor of 3 compared to\nthe most accurate prior approximation scheme, while being the fastest. We show\nthat our models generalize across datasets and across resolutions, and\ninvestigate a number of extensions of the presented approach. The results are\nshown in the supplementary video at https://youtu.be/eQyfHgLx8Dc\n", "versions": [{"version": "v1", "created": "Sat, 2 Sep 2017 22:38:13 GMT"}], "update_date": "2017-09-05", "authors_parsed": [["Chen", "Qifeng", ""], ["Xu", "Jia", ""], ["Koltun", "Vladlen", ""]]}, {"id": "1709.00653", "submitter": "Viet Ha-Thuc", "authors": "Viet Ha-Thuc, Yan Yan, Xianren Wu, Vijay Dialani, Abhishek Gupta,\n  Shakti Sinha", "title": "From Query-By-Keyword to Query-By-Example: LinkedIn Talent Search\n  Approach", "comments": null, "journal-ref": null, "doi": "10.1145/3132847.3132869", "report-no": null, "categories": "cs.IR cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  One key challenge in talent search is to translate complex criteria of a\nhiring position into a search query, while it is relatively easy for a searcher\nto list examples of suitable candidates for a given position. To improve search\nefficiency, we propose the next generation of talent search at LinkedIn, also\nreferred to as Search By Ideal Candidates. In this system, a searcher provides\none or several ideal candidates as the input to hire for a given position. The\nsystem then generates a query based on the ideal candidates and uses it to\nretrieve and rank results. Shifting from the traditional Query-By-Keyword to\nthis new Query-By-Example system poses a number of challenges: How to generate\na query that best describes the candidates? When moving to a completely\ndifferent paradigm, how does one leverage previous product logs to learn\nranking models and/or evaluate the new system with no existing usage logs?\nFinally, given the different nature between the two search paradigms, the\nranking features typically used for Query-By-Keyword systems might not be\noptimal for Query-By-Example. This paper describes our approach to solving\nthese challenges. We present experimental results confirming the effectiveness\nof the proposed solution, particularly on query building and search ranking\ntasks. As of writing this paper, the new system has been available to all\nLinkedIn members.\n", "versions": [{"version": "v1", "created": "Sun, 3 Sep 2017 02:02:08 GMT"}], "update_date": "2017-09-05", "authors_parsed": [["Ha-Thuc", "Viet", ""], ["Yan", "Yan", ""], ["Wu", "Xianren", ""], ["Dialani", "Vijay", ""], ["Gupta", "Abhishek", ""], ["Sinha", "Shakti", ""]]}, {"id": "1709.00668", "submitter": "Evangelos Papalexakis", "authors": "Ekta Gujral, Ravdeep Pasricha, Evangelos E. Papalexakis", "title": "SamBaTen: Sampling-based Batch Incremental Tensor Decomposition", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Tensor decompositions are invaluable tools in analyzing multimodal datasets.\nIn many real-world scenarios, such datasets are far from being static, to the\ncontrary they tend to grow over time. For instance, in an online social network\nsetting, as we observe new interactions over time, our dataset gets updated in\nits \"time\" mode. How can we maintain a valid and accurate tensor decomposition\nof such a dynamically evolving multimodal dataset, without having to re-compute\nthe entire decomposition after every single update? In this paper we introduce\nSaMbaTen, a Sampling-based Batch Incremental Tensor Decomposition algorithm,\nwhich incrementally maintains the decomposition given new updates to the tensor\ndataset. SaMbaTen is able to scale to datasets that the state-of-the-art in\nincremental tensor decomposition is unable to operate on, due to its ability to\neffectively summarize the existing tensor and the incoming updates, and perform\nall computations in the reduced summary space. We extensively evaluate SaMbaTen\nusing synthetic and real datasets. Indicatively, SaMbaTen achieves comparable\naccuracy to state-of-the-art incremental and non-incremental techniques, while\nbeing 25-30 times faster. Furthermore, SaMbaTen scales to very large sparse and\ndense dynamically evolving tensors of dimensions up to 100K x 100K x 100K where\nstate-of-the-art incremental approaches were not able to operate.\n", "versions": [{"version": "v1", "created": "Sun, 3 Sep 2017 06:05:07 GMT"}, {"version": "v2", "created": "Mon, 18 Sep 2017 20:42:33 GMT"}], "update_date": "2017-09-20", "authors_parsed": [["Gujral", "Ekta", ""], ["Pasricha", "Ravdeep", ""], ["Papalexakis", "Evangelos E.", ""]]}, {"id": "1709.00770", "submitter": "Muhammad Mahbubur Rahman", "authors": "Muhammad Mahbubur Rahman, Tim Finin", "title": "Understanding the Logical and Semantic Structure of Large Documents", "comments": "10 pages, 15 figures and 6 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.IR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Current language understanding approaches focus on small documents, such as\nnewswire articles, blog posts, product reviews and discussion forum entries.\nUnderstanding and extracting information from large documents like legal\nbriefs, proposals, technical manuals and research articles is still a\nchallenging task. We describe a framework that can analyze a large document and\nhelp people to know where a particular information is in that document. We aim\nto automatically identify and classify semantic sections of documents and\nassign consistent and human-understandable labels to similar sections across\ndocuments. A key contribution of our research is modeling the logical and\nsemantic structure of an electronic document. We apply machine learning\ntechniques, including deep learning, in our prototype system. We also make\navailable a dataset of information about a collection of scholarly articles\nfrom the arXiv eprints collection that includes a wide range of metadata for\neach article, including a table of contents, section labels, section\nsummarizations and more. We hope that this dataset will be a useful resource\nfor the machine learning and NLP communities in information retrieval,\ncontent-based question answering and language modeling.\n", "versions": [{"version": "v1", "created": "Sun, 3 Sep 2017 21:38:56 GMT"}], "update_date": "2017-09-05", "authors_parsed": [["Rahman", "Muhammad Mahbubur", ""], ["Finin", "Tim", ""]]}, {"id": "1709.00845", "submitter": "Yongsub  Lim", "authors": "Andre S. Yoon, Taehoon Lee, Yongsub Lim, Deokwoo Jung, Philgyun Kang,\n  Dongwon Kim, Keuntae Park, Yongjin Choi", "title": "Semi-supervised Learning with Deep Generative Models for Asset Failure\n  Prediction", "comments": "9 pages, 6 figures, 1 table, KDD17 Workshop on Machine Learning for\n  Prognostics and Health Management.August 13-17, 2017, Halifax, Nova Scotia -\n  Canada", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This work presents a novel semi-supervised learning approach for data-driven\nmodeling of asset failures when health status is only partially known in\nhistorical data. We combine a generative model parameterized by deep neural\nnetworks with non-linear embedding technique. It allows us to build prognostic\nmodels with the limited amount of health status information for the precise\nprediction of future asset reliability. The proposed method is evaluated on a\npublicly available dataset for remaining useful life (RUL) estimation, which\nshows significant improvement even when a fraction of the data with known\nhealth status is as sparse as 1% of the total. Our study suggests that the\nnon-linear embedding based on a deep generative model can efficiently\nregularize a complex model with deep architectures while achieving high\nprediction accuracy that is far less sensitive to the availability of health\nstatus information.\n", "versions": [{"version": "v1", "created": "Mon, 4 Sep 2017 07:42:57 GMT"}], "update_date": "2017-09-05", "authors_parsed": [["Yoon", "Andre S.", ""], ["Lee", "Taehoon", ""], ["Lim", "Yongsub", ""], ["Jung", "Deokwoo", ""], ["Kang", "Philgyun", ""], ["Kim", "Dongwon", ""], ["Park", "Keuntae", ""], ["Choi", "Yongjin", ""]]}, {"id": "1709.00911", "submitter": "Chih-Hong Cheng", "authors": "Chih-Hong Cheng, Frederik Diehl, Yassine Hamza, Gereon Hinz, Georg\n  N\\\"uhrenberg, Markus Rickert, Harald Ruess, Michael Troung-Le", "title": "Neural Networks for Safety-Critical Applications - Challenges,\n  Experiments and Perspectives", "comments": "Summary for activities conducted in the fortiss\n  Eigenforschungsprojekt \"TdpSW - Towards dependable and predictable SW for\n  ML-based autonomous systems\". All ANN-based motion predictors being formally\n  analyzed are available in the source file", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SE cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a methodology for designing dependable Artificial Neural Networks\n(ANN) by extending the concepts of understandability, correctness, and validity\nthat are crucial ingredients in existing certification standards. We apply the\nconcept in a concrete case study in designing a high-way ANN-based motion\npredictor to guarantee safety properties such as impossibility for the ego\nvehicle to suggest moving to the right lane if there exists another vehicle on\nits right.\n", "versions": [{"version": "v1", "created": "Mon, 4 Sep 2017 12:19:06 GMT"}], "update_date": "2017-09-05", "authors_parsed": [["Cheng", "Chih-Hong", ""], ["Diehl", "Frederik", ""], ["Hamza", "Yassine", ""], ["Hinz", "Gereon", ""], ["N\u00fchrenberg", "Georg", ""], ["Rickert", "Markus", ""], ["Ruess", "Harald", ""], ["Troung-Le", "Michael", ""]]}, {"id": "1709.00947", "submitter": "Pedro Saleiro", "authors": "Pedro Saleiro, Lu\\'is Sarmento, Eduarda Mendes Rodrigues, Carlos\n  Soares, Eug\\'enio Oliveira", "title": "Learning Word Embeddings from the Portuguese Twitter Stream: A Study of\n  some Practical Aspects", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper describes a preliminary study for producing and distributing a\nlarge-scale database of embeddings from the Portuguese Twitter stream. We start\nby experimenting with a relatively small sample and focusing on three\nchallenges: volume of training data, vocabulary size and intrinsic evaluation\nmetrics. Using a single GPU, we were able to scale up vocabulary size from 2048\nwords embedded and 500K training examples to 32768 words over 10M training\nexamples while keeping a stable validation loss and approximately linear trend\non training time per epoch. We also observed that using less than 50\\% of the\navailable training examples for each vocabulary size might result in\noverfitting. Results on intrinsic evaluation show promising performance for a\nvocabulary size of 32768 words. Nevertheless, intrinsic evaluation metrics\nsuffer from over-sensitivity to their corresponding cosine similarity\nthresholds, indicating that a wider range of metrics need to be developed to\ntrack progress.\n", "versions": [{"version": "v1", "created": "Mon, 4 Sep 2017 13:30:23 GMT"}], "update_date": "2017-09-05", "authors_parsed": [["Saleiro", "Pedro", ""], ["Sarmento", "Lu\u00eds", ""], ["Rodrigues", "Eduarda Mendes", ""], ["Soares", "Carlos", ""], ["Oliveira", "Eug\u00e9nio", ""]]}, {"id": "1709.01006", "submitter": "Josip Djolonga", "authors": "Josip Djolonga, Andreas Krause", "title": "Learning Implicit Generative Models Using Differentiable Graph Tests", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recently, there has been a growing interest in the problem of learning rich\nimplicit models - those from which we can sample, but can not evaluate their\ndensity. These models apply some parametric function, such as a deep network,\nto a base measure, and are learned end-to-end using stochastic optimization.\nOne strategy of devising a loss function is through the statistics of two\nsample tests - if we can fool a statistical test, the learned distribution\nshould be a good model of the true data. However, not all tests can easily fit\ninto this framework, as they might not be differentiable with respect to the\ndata points, and hence with respect to the parameters of the implicit model.\nMotivated by this problem, in this paper we show how two such classical tests,\nthe Friedman-Rafsky and k-nearest neighbour tests, can be effectively smoothed\nusing ideas from undirected graphical models - the matrix tree theorem and\ncardinality potentials. Moreover, as we show experimentally, smoothing can\nsignificantly increase the power of the test, which might of of independent\ninterest. Finally, we apply our method to learn implicit models.\n", "versions": [{"version": "v1", "created": "Mon, 4 Sep 2017 15:34:59 GMT"}], "update_date": "2017-09-05", "authors_parsed": [["Djolonga", "Josip", ""], ["Krause", "Andreas", ""]]}, {"id": "1709.01062", "submitter": "Mark Tygert", "authors": "Cinna Wu, Mark Tygert, and Yann LeCun", "title": "A hierarchical loss and its problems when classifying non-hierarchically", "comments": "19 pages, 4 figures, 7 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Failing to distinguish between a sheepdog and a skyscraper should be worse\nand penalized more than failing to distinguish between a sheepdog and a poodle;\nafter all, sheepdogs and poodles are both breeds of dogs. However, existing\nmetrics of failure (so-called \"loss\" or \"win\") used in textual or visual\nclassification/recognition via neural networks seldom leverage a-priori\ninformation, such as a sheepdog being more similar to a poodle than to a\nskyscraper. We define a metric that, inter alia, can penalize failure to\ndistinguish between a sheepdog and a skyscraper more than failure to\ndistinguish between a sheepdog and a poodle. Unlike previously employed\npossibilities, this metric is based on an ultrametric tree associated with any\ngiven tree organization into a semantically meaningful hierarchy of a\nclassifier's classes. An ultrametric tree is a tree with a so-called\nultrametric distance metric such that all leaves are at the same distance from\nthe root. Unfortunately, extensive numerical experiments indicate that the\nstandard practice of training neural networks via stochastic gradient descent\nwith random starting points often drives down the hierarchical loss nearly as\nmuch when minimizing the standard cross-entropy loss as when trying to minimize\nthe hierarchical loss directly. Thus, this hierarchical loss is unreliable as\nan objective for plain, randomly started stochastic gradient descent to\nminimize; the main value of the hierarchical loss may be merely as a meaningful\nmetric of success of a classifier.\n", "versions": [{"version": "v1", "created": "Fri, 1 Sep 2017 23:46:59 GMT"}, {"version": "v2", "created": "Mon, 9 Dec 2019 20:38:32 GMT"}], "update_date": "2019-12-11", "authors_parsed": [["Wu", "Cinna", ""], ["Tygert", "Mark", ""], ["LeCun", "Yann", ""]]}, {"id": "1709.01073", "submitter": "Narendhar Gugulothu", "authors": "Narendhar Gugulothu, Vishnu TV, Pankaj Malhotra, Lovekesh Vig, Puneet\n  Agarwal, Gautam Shroff", "title": "Predicting Remaining Useful Life using Time Series Embeddings based on\n  Recurrent Neural Networks", "comments": "Presented at 2nd ML for PHM Workshop at SIGKDD 2017, Halifax, Canada", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the problem of estimating the remaining useful life (RUL) of a\nsystem or a machine from sensor data. Many approaches for RUL estimation based\non sensor data make assumptions about how machines degrade. Additionally,\nsensor data from machines is noisy and often suffers from missing values in\nmany practical settings. We propose Embed-RUL: a novel approach for RUL\nestimation from sensor data that does not rely on any degradation-trend\nassumptions, is robust to noise, and handles missing values. Embed-RUL utilizes\na sequence-to-sequence model based on Recurrent Neural Networks (RNNs) to\ngenerate embeddings for multivariate time series subsequences. The embeddings\nfor normal and degraded machines tend to be different, and are therefore found\nto be useful for RUL estimation. We show that the embeddings capture the\noverall pattern in the time series while filtering out the noise, so that the\nembeddings of two machines with similar operational behavior are close to each\nother, even when their sensor readings have significant and varying levels of\nnoise content. We perform experiments on publicly available turbofan engine\ndataset and a proprietary real-world dataset, and demonstrate that Embed-RUL\noutperforms the previously reported state-of-the-art on several metrics.\n", "versions": [{"version": "v1", "created": "Mon, 4 Sep 2017 12:15:44 GMT"}, {"version": "v2", "created": "Fri, 6 Oct 2017 10:42:52 GMT"}], "update_date": "2017-10-09", "authors_parsed": [["Gugulothu", "Narendhar", ""], ["TV", "Vishnu", ""], ["Malhotra", "Pankaj", ""], ["Vig", "Lovekesh", ""], ["Agarwal", "Puneet", ""], ["Shroff", "Gautam", ""]]}, {"id": "1709.01076", "submitter": "Daniele Ramazzotti", "authors": "Daniele Ramazzotti and Alex Graudenzi and Luca De Sano and Marco\n  Antoniotti and Giulio Caravagna", "title": "Learning mutational graphs of individual tumour evolution from\n  single-cell and multi-region sequencing data", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.GN cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Background. A large number of algorithms is being developed to reconstruct\nevolutionary models of individual tumours from genome sequencing data. Most\nmethods can analyze multiple samples collected either through bulk multi-region\nsequencing experiments or the sequencing of individual cancer cells. However,\nrarely the same method can support both data types.\n  Results. We introduce TRaIT, a computational framework to infer mutational\ngraphs that model the accumulation of multiple types of somatic alterations\ndriving tumour evolution. Compared to other tools, TRaIT supports multi-region\nand single-cell sequencing data within the same statistical framework, and\ndelivers expressive models that capture many complex evolutionary phenomena.\nTRaIT improves accuracy, robustness to data-specific errors and computational\ncomplexity compared to competing methods.\n  Conclusions. We show that the application of TRaIT to single-cell and\nmulti-region cancer datasets can produce accurate and reliable models of\nsingle-tumour evolution, quantify the extent of intra-tumour heterogeneity and\ngenerate new testable experimental hypotheses.\n", "versions": [{"version": "v1", "created": "Mon, 4 Sep 2017 15:35:11 GMT"}, {"version": "v2", "created": "Fri, 22 Mar 2019 23:42:19 GMT"}], "update_date": "2019-03-26", "authors_parsed": [["Ramazzotti", "Daniele", ""], ["Graudenzi", "Alex", ""], ["De Sano", "Luca", ""], ["Antoniotti", "Marco", ""], ["Caravagna", "Giulio", ""]]}, {"id": "1709.01134", "submitter": "Asit Mishra", "authors": "Asit Mishra, Eriko Nurvitadhi, Jeffrey J Cook and Debbie Marr", "title": "WRPN: Wide Reduced-Precision Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG cs.NE", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  For computer vision applications, prior works have shown the efficacy of\nreducing numeric precision of model parameters (network weights) in deep neural\nnetworks. Activation maps, however, occupy a large memory footprint during both\nthe training and inference step when using mini-batches of inputs. One way to\nreduce this large memory footprint is to reduce the precision of activations.\nHowever, past works have shown that reducing the precision of activations hurts\nmodel accuracy. We study schemes to train networks from scratch using\nreduced-precision activations without hurting accuracy. We reduce the precision\nof activation maps (along with model parameters) and increase the number of\nfilter maps in a layer, and find that this scheme matches or surpasses the\naccuracy of the baseline full-precision network. As a result, one can\nsignificantly improve the execution efficiency (e.g. reduce dynamic memory\nfootprint, memory bandwidth and computational energy) and speed up the training\nand inference process with appropriate hardware support. We call our scheme\nWRPN - wide reduced-precision networks. We report results and show that WRPN\nscheme is better than previously reported accuracies on ILSVRC-12 dataset while\nbeing computationally less expensive compared to previously reported\nreduced-precision networks.\n", "versions": [{"version": "v1", "created": "Mon, 4 Sep 2017 19:56:48 GMT"}], "update_date": "2017-09-06", "authors_parsed": [["Mishra", "Asit", ""], ["Nurvitadhi", "Eriko", ""], ["Cook", "Jeffrey J", ""], ["Marr", "Debbie", ""]]}, {"id": "1709.01144", "submitter": "Pranay Dighe", "authors": "Pranay Dighe, Afsaneh Asaei, Herv\\'e Bourlard", "title": "Information Theoretic Analysis of DNN-HMM Acoustic Modeling", "comments": "Theoretical flaw, needs major revision", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SD cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose an information theoretic framework for quantitative assessment of\nacoustic modeling for hidden Markov model (HMM) based automatic speech\nrecognition (ASR). Acoustic modeling yields the probabilities of HMM sub-word\nstates for a short temporal window of speech acoustic features. We cast ASR as\na communication channel where the input sub-word probabilities convey the\ninformation about the output HMM state sequence. The quality of the acoustic\nmodel is thus quantified in terms of the information transmitted through this\nchannel. The process of inferring the most likely HMM state sequence from the\nsub-word probabilities is known as decoding. HMM based decoding assumes that an\nacoustic model yields accurate state-level probabilities and the data\ndistribution given the underlying hidden state is independent of any other\nstate in the sequence. We quantify 1) the acoustic model accuracy and 2) its\nrobustness to mismatch between data and the HMM conditional independence\nassumption in terms of some mutual information quantities. In this context,\nexploiting deep neural network (DNN) posterior probabilities leads to a simple\nand straightforward analysis framework to assess shortcomings of the acoustic\nmodel for HMM based decoding. This analysis enables us to evaluate the Gaussian\nmixture acoustic model (GMM) and the importance of many hidden layers in DNNs\nwithout any need of explicit speech recognition. In addition, it sheds light on\nthe contribution of low-dimensional models to enhance acoustic modeling for\nbetter compliance with the HMM based decoding requirements.\n", "versions": [{"version": "v1", "created": "Tue, 29 Aug 2017 10:03:05 GMT"}, {"version": "v2", "created": "Wed, 8 Nov 2017 15:52:53 GMT"}], "update_date": "2017-11-09", "authors_parsed": [["Dighe", "Pranay", ""], ["Asaei", "Afsaneh", ""], ["Bourlard", "Herv\u00e9", ""]]}, {"id": "1709.01147", "submitter": "Evangelos Papalexakis", "authors": "Ishmam Zabir, Evangelos E. Papalexakis", "title": "Balancing Interpretability and Predictive Accuracy for Unsupervised\n  Tensor Mining", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The PARAFAC tensor decomposition has enjoyed an increasing success in\nexploratory multi-aspect data mining scenarios. A major challenge remains the\nestimation of the number of latent factors (i.e., the rank) of the\ndecomposition, which yields high-quality, interpretable results. Previously, we\nhave proposed an automated tensor mining method which leverages a well-known\nquality heuristic from the field of Chemometrics, the Core Consistency\nDiagnostic (CORCONDIA), in order to automatically determine the rank for the\nPARAFAC decomposition. In this work we set out to explore the trade-off between\n1) the interpretability/quality of the results (as expressed by CORCONDIA), and\n2) the predictive accuracy of the results, in order to further improve the rank\nestimation quality. Our preliminary results indicate that striking a good\nbalance in that trade-off benefits rank estimation.\n", "versions": [{"version": "v1", "created": "Mon, 4 Sep 2017 20:34:43 GMT"}], "update_date": "2017-09-06", "authors_parsed": [["Zabir", "Ishmam", ""], ["Papalexakis", "Evangelos E.", ""]]}, {"id": "1709.01177", "submitter": "Antonio Sutera", "authors": "Antonio Sutera, C\\'elia Ch\\^atel, Gilles Louppe, Louis Wehenkel,\n  Pierre Geurts", "title": "Random Subspace with Trees for Feature Selection Under Memory\n  Constraints", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Dealing with datasets of very high dimension is a major challenge in machine\nlearning. In this paper, we consider the problem of feature selection in\napplications where the memory is not large enough to contain all features. In\nthis setting, we propose a novel tree-based feature selection approach that\nbuilds a sequence of randomized trees on small subsamples of variables mixing\nboth variables already identified as relevant by previous models and variables\nrandomly selected among the other variables. As our main contribution, we\nprovide an in-depth theoretical analysis of this method in infinite sample\nsetting. In particular, we study its soundness with respect to common\ndefinitions of feature relevance and its convergence speed under various\nvariable dependance scenarios. We also provide some preliminary empirical\nresults highlighting the potential of the approach.\n", "versions": [{"version": "v1", "created": "Mon, 4 Sep 2017 21:56:25 GMT"}, {"version": "v2", "created": "Wed, 6 Sep 2017 08:50:48 GMT"}], "update_date": "2017-09-07", "authors_parsed": [["Sutera", "Antonio", ""], ["Ch\u00e2tel", "C\u00e9lia", ""], ["Louppe", "Gilles", ""], ["Wehenkel", "Louis", ""], ["Geurts", "Pierre", ""]]}, {"id": "1709.01215", "submitter": "Chunyuan Li", "authors": "Chunyuan Li, Hao Liu, Changyou Chen, Yunchen Pu, Liqun Chen, Ricardo\n  Henao, Lawrence Carin", "title": "ALICE: Towards Understanding Adversarial Learning for Joint Distribution\n  Matching", "comments": "NIPS 2017 (22 pages); short version (9 pages):\n  http://people.duke.edu/~cl319/doc/papers/nips_2017_alice.pdf", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.AI cs.CV cs.LG cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We investigate the non-identifiability issues associated with bidirectional\nadversarial training for joint distribution matching. Within a framework of\nconditional entropy, we propose both adversarial and non-adversarial approaches\nto learn desirable matched joint distributions for unsupervised and supervised\ntasks. We unify a broad family of adversarial models as joint distribution\nmatching problems. Our approach stabilizes learning of unsupervised\nbidirectional adversarial learning methods. Further, we introduce an extension\nfor semi-supervised learning tasks. Theoretical results are validated in\nsynthetic data and real-world applications.\n", "versions": [{"version": "v1", "created": "Tue, 5 Sep 2017 02:18:06 GMT"}, {"version": "v2", "created": "Sun, 5 Nov 2017 03:58:52 GMT"}], "update_date": "2017-11-07", "authors_parsed": [["Li", "Chunyuan", ""], ["Liu", "Hao", ""], ["Chen", "Changyou", ""], ["Pu", "Yunchen", ""], ["Chen", "Liqun", ""], ["Henao", "Ricardo", ""], ["Carin", "Lawrence", ""]]}, {"id": "1709.01230", "submitter": "Yingzhen Yang", "authors": "Yingzhen Yang, Jiashi Feng, Nebojsa Jojic, Jianchao Yang, Thomas S.\n  Huang", "title": "On the Suboptimality of Proximal Gradient Descent for $\\ell^{0}$ Sparse\n  Approximation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.OC cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the proximal gradient descent (PGD) method for $\\ell^{0}$ sparse\napproximation problem as well as its accelerated optimization with randomized\nalgorithms in this paper. We first offer theoretical analysis of PGD showing\nthe bounded gap between the sub-optimal solution by PGD and the globally\noptimal solution for the $\\ell^{0}$ sparse approximation problem under\nconditions weaker than Restricted Isometry Property widely used in compressive\nsensing literature. Moreover, we propose randomized algorithms to accelerate\nthe optimization by PGD using randomized low rank matrix approximation\n(PGD-RMA) and randomized dimension reduction (PGD-RDR). Our randomized\nalgorithms substantially reduces the computation cost of the original PGD for\nthe $\\ell^{0}$ sparse approximation problem, and the resultant sub-optimal\nsolution still enjoys provable suboptimality, namely, the sub-optimal solution\nto the reduced problem still has bounded gap to the globally optimal solution\nto the original problem.\n", "versions": [{"version": "v1", "created": "Tue, 5 Sep 2017 04:06:19 GMT"}], "update_date": "2017-09-06", "authors_parsed": [["Yang", "Yingzhen", ""], ["Feng", "Jiashi", ""], ["Jojic", "Nebojsa", ""], ["Yang", "Jianchao", ""], ["Huang", "Thomas S.", ""]]}, {"id": "1709.01231", "submitter": "Yingzhen Yang", "authors": "Yingzhen Yang, Feng Liang, Nebojsa Jojic, Shuicheng Yan, Jiashi Feng,\n  Thomas S. Huang", "title": "Discriminative Similarity for Clustering and Semi-Supervised Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Similarity-based clustering and semi-supervised learning methods separate the\ndata into clusters or classes according to the pairwise similarity between the\ndata, and the pairwise similarity is crucial for their performance. In this\npaper, we propose a novel discriminative similarity learning framework which\nlearns discriminative similarity for either data clustering or semi-supervised\nlearning. The proposed framework learns classifier from each hypothetical\nlabeling, and searches for the optimal labeling by minimizing the\ngeneralization error of the learned classifiers associated with the\nhypothetical labeling. Kernel classifier is employed in our framework. By\ngeneralization analysis via Rademacher complexity, the generalization error\nbound for the kernel classifier learned from hypothetical labeling is expressed\nas the sum of pairwise similarity between the data from different classes,\nparameterized by the weights of the kernel classifier. Such pairwise similarity\nserves as the discriminative similarity for the purpose of clustering and\nsemi-supervised learning, and discriminative similarity with similar form can\nalso be induced by the integrated squared error bound for kernel density\nclassification. Based on the discriminative similarity induced by the kernel\nclassifier, we propose new clustering and semi-supervised learning methods.\n", "versions": [{"version": "v1", "created": "Tue, 5 Sep 2017 04:10:44 GMT"}], "update_date": "2017-09-06", "authors_parsed": [["Yang", "Yingzhen", ""], ["Liang", "Feng", ""], ["Jojic", "Nebojsa", ""], ["Yan", "Shuicheng", ""], ["Feng", "Jiashi", ""], ["Huang", "Thomas S.", ""]]}, {"id": "1709.01237", "submitter": "Hariprasad Kannan", "authors": "Hariprasad Kannan, Nikos Komodakis, Nikos Paragios", "title": "Newton-type Methods for Inference in Higher-Order Markov Random Fields", "comments": "10 pages, 3 figures, 3 tables, CVPR 2017", "journal-ref": "Poster at IEEE International Conference on Computer Vision and\n  Pattern Recognition 2017", "doi": null, "report-no": null, "categories": "cs.CV cs.LG cs.NA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Linear programming relaxations are central to {\\sc map} inference in discrete\nMarkov Random Fields. The ability to properly solve the Lagrangian dual is a\ncritical component of such methods. In this paper, we study the benefit of\nusing Newton-type methods to solve the Lagrangian dual of a smooth version of\nthe problem. We investigate their ability to achieve superior convergence\nbehavior and to better handle the ill-conditioned nature of the formulation, as\ncompared to first order methods. We show that it is indeed possible to\nefficiently apply a trust region Newton method for a broad range of {\\sc map}\ninference problems. In this paper we propose a provably convergent and\nefficient framework that includes (i) excellent compromise between\ncomputational complexity and precision concerning the Hessian matrix\nconstruction, (ii) a damping strategy that aids efficient optimization, (iii) a\ntruncation strategy coupled with a generic pre-conditioner for Conjugate\nGradients, (iv) efficient sum-product computation for sparse clique potentials.\nResults for higher-order Markov Random Fields demonstrate the potential of this\napproach.\n", "versions": [{"version": "v1", "created": "Tue, 5 Sep 2017 04:55:47 GMT"}], "update_date": "2017-09-06", "authors_parsed": [["Kannan", "Hariprasad", ""], ["Komodakis", "Nikos", ""], ["Paragios", "Nikos", ""]]}, {"id": "1709.01249", "submitter": "Pan Li", "authors": "Pan Li, Olgica Milenkovic", "title": "Inhomogeneous Hypergraph Clustering with Applications", "comments": "To appear in NIPS 2017", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Hypergraph partitioning is an important problem in machine learning, computer\nvision and network analytics. A widely used method for hypergraph partitioning\nrelies on minimizing a normalized sum of the costs of partitioning hyperedges\nacross clusters. Algorithmic solutions based on this approach assume that\ndifferent partitions of a hyperedge incur the same cost. However, this\nassumption fails to leverage the fact that different subsets of vertices within\nthe same hyperedge may have different structural importance. We hence propose a\nnew hypergraph clustering technique, termed inhomogeneous hypergraph\npartitioning, which assigns different costs to different hyperedge cuts. We\nprove that inhomogeneous partitioning produces a quadratic approximation to the\noptimal solution if the inhomogeneous costs satisfy submodularity constraints.\nMoreover, we demonstrate that inhomogenous partitioning offers significant\nperformance improvements in applications such as structure learning of\nrankings, subspace segmentation and motif clustering.\n", "versions": [{"version": "v1", "created": "Tue, 5 Sep 2017 06:11:26 GMT"}, {"version": "v2", "created": "Wed, 6 Sep 2017 02:49:07 GMT"}, {"version": "v3", "created": "Mon, 30 Oct 2017 19:39:25 GMT"}, {"version": "v4", "created": "Thu, 2 Nov 2017 18:48:40 GMT"}], "update_date": "2017-11-06", "authors_parsed": [["Li", "Pan", ""], ["Milenkovic", "Olgica", ""]]}, {"id": "1709.01268", "submitter": "Dat Thanh Tran", "authors": "Dat Thanh Tran, Martin Magris, Juho Kanniainen, Moncef Gabbouj,\n  Alexandros Iosifidis", "title": "Tensor Representation in High-Frequency Financial Data for Price Change\n  Prediction", "comments": "accepted in SSCI 2017, typos fixed", "journal-ref": "IEEE Symposium Series on Computational Intelligence (SSCI), 2017", "doi": "10.1109/SSCI.2017.8280812", "report-no": null, "categories": "cs.CE cs.LG cs.NA q-fin.TR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Nowadays, with the availability of massive amount of trade data collected,\nthe dynamics of the financial markets pose both a challenge and an opportunity\nfor high frequency traders. In order to take advantage of the rapid, subtle\nmovement of assets in High Frequency Trading (HFT), an automatic algorithm to\nanalyze and detect patterns of price change based on transaction records must\nbe available. The multichannel, time-series representation of financial data\nnaturally suggests tensor-based learning algorithms. In this work, we\ninvestigate the effectiveness of two multilinear methods for the mid-price\nprediction problem against other existing methods. The experiments in a large\nscale dataset which contains more than 4 millions limit orders show that by\nutilizing tensor representation, multilinear models outperform vector-based\napproaches and other competing ones.\n", "versions": [{"version": "v1", "created": "Tue, 5 Sep 2017 07:48:33 GMT"}, {"version": "v2", "created": "Tue, 26 Sep 2017 05:14:34 GMT"}, {"version": "v3", "created": "Mon, 2 Oct 2017 17:33:50 GMT"}, {"version": "v4", "created": "Tue, 28 Nov 2017 11:03:45 GMT"}], "update_date": "2018-07-06", "authors_parsed": [["Tran", "Dat Thanh", ""], ["Magris", "Martin", ""], ["Kanniainen", "Juho", ""], ["Gabbouj", "Moncef", ""], ["Iosifidis", "Alexandros", ""]]}, {"id": "1709.01298", "submitter": "Felipe Tobar", "authors": "Gabriel Parra and Felipe Tobar", "title": "Spectral Mixture Kernels for Multi-Output Gaussian Processes", "comments": "To appear in Advances in Neural Information Processing Systems 31\n  (NIPS 2017)", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Early approaches to multiple-output Gaussian processes (MOGPs) relied on\nlinear combinations of independent, latent, single-output Gaussian processes\n(GPs). This resulted in cross-covariance functions with limited parametric\ninterpretation, thus conflicting with the ability of single-output GPs to\nunderstand lengthscales, frequencies and magnitudes to name a few. On the\ncontrary, current approaches to MOGP are able to better interpret the\nrelationship between different channels by directly modelling the\ncross-covariances as a spectral mixture kernel with a phase shift. We extend\nthis rationale and propose a parametric family of complex-valued cross-spectral\ndensities and then build on Cram\\'er's Theorem (the multivariate version of\nBochner's Theorem) to provide a principled approach to design multivariate\ncovariance functions. The so-constructed kernels are able to model delays among\nchannels in addition to phase differences and are thus more expressive than\nprevious methods, while also providing full parametric interpretation of the\nrelationship across channels. The proposed method is first validated on\nsynthetic data and then compared to existing MOGP methods on two real-world\nexamples.\n", "versions": [{"version": "v1", "created": "Tue, 5 Sep 2017 09:20:19 GMT"}, {"version": "v2", "created": "Fri, 3 Nov 2017 22:44:09 GMT"}], "update_date": "2017-11-07", "authors_parsed": [["Parra", "Gabriel", ""], ["Tobar", "Felipe", ""]]}, {"id": "1709.01300", "submitter": "Daiki Suehiro", "authors": "Daiki Suehiro, Kohei Hatano, Eiji Takimoto, Shuji Yamamoto, Kenichi\n  Bannai, Akiko Takeda", "title": "Boosting the kernelized shapelets: Theory and algorithms for local\n  features", "comments": "16 pages, 1 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider binary classification problems using local features of objects.\nOne of motivating applications is time-series classification, where features\nreflecting some local closeness measure between a time series and a pattern\nsequence called shapelet are useful. Despite the empirical success of such\napproaches using local features, the generalization ability of resulting\nhypotheses is not fully understood and previous work relies on a bunch of\nheuristics. In this paper, we formulate a class of hypotheses using local\nfeatures, where the richness of features is controlled by kernels. We derive\ngeneralization bounds of sparse ensembles over the class which is exponentially\nbetter than a standard analysis in terms of the number of possible local\nfeatures. The resulting optimization problem is well suited to the boosting\napproach and the weak learning problem is formulated as a DC program, for which\npractical algorithms exist. In preliminary experiments on time-series data\nsets, our method achieves competitive accuracy with the state-of-the-art\nalgorithms with small parameter-tuning cost.\n", "versions": [{"version": "v1", "created": "Tue, 5 Sep 2017 09:27:01 GMT"}, {"version": "v2", "created": "Wed, 6 Sep 2017 01:54:43 GMT"}, {"version": "v3", "created": "Thu, 7 Sep 2017 01:39:36 GMT"}], "update_date": "2017-09-08", "authors_parsed": [["Suehiro", "Daiki", ""], ["Hatano", "Kohei", ""], ["Takimoto", "Eiji", ""], ["Yamamoto", "Shuji", ""], ["Bannai", "Kenichi", ""], ["Takeda", "Akiko", ""]]}, {"id": "1709.01402", "submitter": "Alexander Jung", "authors": "Alexandru Mara and Alexander Jung", "title": "Recovery Conditions and Sampling Strategies for Network Lasso", "comments": "nominated as student paper award finalist at Asilomar 2017. arXiv\n  admin note: substantial text overlap with arXiv:1704.02107", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The network Lasso is a recently proposed convex optimization method for\nmachine learning from massive network structured datasets, i.e., big data over\nnetworks. It is a variant of the well-known least absolute shrinkage and\nselection operator (Lasso), which is underlying many methods in learning and\nsignal processing involving sparse models. Highly scalable implementations of\nthe network Lasso can be obtained by state-of-the art proximal methods, e.g.,\nthe alternating direction method of multipliers (ADMM). By generalizing the\nconcept of the compatibility condition put forward by van de Geer and Buehlmann\nas a powerful tool for the analysis of plain Lasso, we derive a sufficient\ncondition, i.e., the network compatibility condition, on the underlying network\ntopology such that network Lasso accurately learns a clustered underlying graph\nsignal. This network compatibility condition relates the location of the\nsampled nodes with the clustering structure of the network. In particular, the\nNCC informs the choice of which nodes to sample, or in machine learning terms,\nwhich data points provide most information if labeled.\n", "versions": [{"version": "v1", "created": "Sun, 3 Sep 2017 13:05:30 GMT"}], "update_date": "2017-09-06", "authors_parsed": [["Mara", "Alexandru", ""], ["Jung", "Alexander", ""]]}, {"id": "1709.01412", "submitter": "Thomas Epelbaum", "authors": "Thomas Epelbaum", "title": "Deep learning: Technical introduction", "comments": "The content of this note can be found on GitHub:\n  https://github.com/tomepel/Technical_Book_DL . If you detect any typo, error,\n  or feel that I forgot to cite an important source, don't hesitate to email:\n  thomas.epelbaum@mediamobile.com. v2: minor typos corrected", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This note presents in a technical though hopefully pedagogical way the three\nmost common forms of neural network architectures: Feedforward, Convolutional\nand Recurrent. For each network, their fundamental building blocks are\ndetailed. The forward pass and the update rules for the backpropagation\nalgorithm are then derived in full.\n", "versions": [{"version": "v1", "created": "Tue, 5 Sep 2017 14:27:08 GMT"}, {"version": "v2", "created": "Mon, 11 Sep 2017 11:39:06 GMT"}], "update_date": "2017-09-12", "authors_parsed": [["Epelbaum", "Thomas", ""]]}, {"id": "1709.01421", "submitter": "Konstantin Sozykin", "authors": "Konstantin Sozykin, Stanislav Protasov, Adil Khan, Rasheed Hussain,\n  Jooyoung Lee", "title": "Multi-label Class-imbalanced Action Recognition in Hockey Videos via 3D\n  Convolutional Neural Networks", "comments": "Accepted to IEEE/ACIS SNPD 2018, 6 pages, 3 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Automatic analysis of the video is one of most complex problems in the fields\nof computer vision and machine learning. A significant part of this research\ndeals with (human) activity recognition (HAR) since humans, and the activities\nthat they perform, generate most of the video semantics. Video-based HAR has\napplications in various domains, but one of the most important and challenging\nis HAR in sports videos. Some of the major issues include high inter- and\nintra-class variations, large class imbalance, the presence of both group\nactions and single player actions, and recognizing simultaneous actions, i.e.,\nthe multi-label learning problem. Keeping in mind these challenges and the\nrecent success of CNNs in solving various computer vision problems, in this\nwork, we implement a 3D CNN based multi-label deep HAR system for multi-label\nclass-imbalanced action recognition in hockey videos. We test our system for\ntwo different scenarios: an ensemble of $k$ binary networks vs. a single\n$k$-output network, on a publicly available dataset. We also compare our\nresults with the system that was originally designed for the chosen dataset.\nExperimental results show that the proposed approach performs better than the\nexisting solution.\n", "versions": [{"version": "v1", "created": "Tue, 5 Sep 2017 14:44:20 GMT"}, {"version": "v2", "created": "Thu, 3 May 2018 15:23:28 GMT"}], "update_date": "2018-05-04", "authors_parsed": [["Sozykin", "Konstantin", ""], ["Protasov", "Stanislav", ""], ["Khan", "Adil", ""], ["Hussain", "Rasheed", ""], ["Lee", "Jooyoung", ""]]}, {"id": "1709.01423", "submitter": "Chandrasekaran Anirudh Bhardwaj", "authors": "Megha Mishra, Chandrasekaran Anirudh Bhardwaj, and Kalyani Desikan", "title": "A Maximal Heterogeneity Based Clustering Approach for Obtaining Samples", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Medical and social sciences demand sampling techniques which are robust,\nreliable, replicable and have the least dissimilarity between the samples\nobtained. Majority of the applications of sampling use randomized sampling,\nalbeit with stratification where applicable. The randomized technique is not\nconsistent, and may provide different samples each time, and the different\nsamples themselves may not be similar to each other. In this paper, we\nintroduce a novel non-statistical no-replacement sampling technique called\nWobbly Center Algorithm, which relies on building clusters iteratively based on\nmaximizing the heterogeneity inside each cluster. The algorithm works on the\nprinciple of stepwise building of clusters by finding the points with the\nmaximal distance from the cluster center. The obtained results are validated\nstatistically using Analysis of Variance tests by comparing the samples\nobtained to check if they are representative of each other. The obtained\nresults generated from running the Wobbly Center algorithm on benchmark\ndatasets when compared against other sampling algorithms indicate the\nsuperiority of the Wobbly Center Algorithm.\n", "versions": [{"version": "v1", "created": "Sat, 2 Sep 2017 17:26:15 GMT"}, {"version": "v2", "created": "Mon, 16 Oct 2017 06:19:42 GMT"}, {"version": "v3", "created": "Sun, 9 Dec 2018 01:18:38 GMT"}], "update_date": "2018-12-11", "authors_parsed": [["Mishra", "Megha", ""], ["Bhardwaj", "Chandrasekaran Anirudh", ""], ["Desikan", "Kalyani", ""]]}, {"id": "1709.01427", "submitter": "Alice Schoenauer Sebag", "authors": "Alice Schoenauer-Sebag, Marc Schoenauer and Mich\\`ele Sebag", "title": "Stochastic Gradient Descent: Going As Fast As Possible But Not Faster", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  When applied to training deep neural networks, stochastic gradient descent\n(SGD) often incurs steady progression phases, interrupted by catastrophic\nepisodes in which loss and gradient norm explode. A possible mitigation of such\nevents is to slow down the learning process. This paper presents a novel\napproach to control the SGD learning rate, that uses two statistical tests. The\nfirst one, aimed at fast learning, compares the momentum of the normalized\ngradient vectors to that of random unit vectors and accordingly gracefully\nincreases or decreases the learning rate. The second one is a change point\ndetection test, aimed at the detection of catastrophic learning episodes; upon\nits triggering the learning rate is instantly halved. Both abilities of\nspeeding up and slowing down the learning rate allows the proposed approach,\ncalled SALeRA, to learn as fast as possible but not faster. Experiments on\nstandard benchmarks show that SALeRA performs well in practice, and compares\nfavorably to the state of the art.\n", "versions": [{"version": "v1", "created": "Tue, 5 Sep 2017 14:50:55 GMT"}], "update_date": "2017-09-06", "authors_parsed": [["Schoenauer-Sebag", "Alice", ""], ["Schoenauer", "Marc", ""], ["Sebag", "Mich\u00e8le", ""]]}, {"id": "1709.01434", "submitter": "Manzil Zaheer", "authors": "Sashank J Reddi, Manzil Zaheer, Suvrit Sra, Barnabas Poczos, Francis\n  Bach, Ruslan Salakhutdinov, Alexander J Smola", "title": "A Generic Approach for Escaping Saddle points", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A central challenge to using first-order methods for optimizing nonconvex\nproblems is the presence of saddle points. First-order methods often get stuck\nat saddle points, greatly deteriorating their performance. Typically, to escape\nfrom saddles one has to use second-order methods. However, most works on\nsecond-order methods rely extensively on expensive Hessian-based computations,\nmaking them impractical in large-scale settings. To tackle this challenge, we\nintroduce a generic framework that minimizes Hessian based computations while\nat the same time provably converging to second-order critical points. Our\nframework carefully alternates between a first-order and a second-order\nsubroutine, using the latter only close to saddle points, and yields\nconvergence results competitive to the state-of-the-art. Empirical results\nsuggest that our strategy also enjoys a good practical performance.\n", "versions": [{"version": "v1", "created": "Tue, 5 Sep 2017 14:58:15 GMT"}], "update_date": "2017-09-06", "authors_parsed": [["Reddi", "Sashank J", ""], ["Zaheer", "Manzil", ""], ["Sra", "Suvrit", ""], ["Poczos", "Barnabas", ""], ["Bach", "Francis", ""], ["Salakhutdinov", "Ruslan", ""], ["Smola", "Alexander J", ""]]}, {"id": "1709.01439", "submitter": "Gustavo A Valencia-Zapata", "authors": "Gustavo A Valencia-Zapata, Daniel Mejia, Gerhard Klimeck, Michael\n  Zentner, and Okan Ersoy", "title": "A Statistical Approach to Increase Classification Accuracy in Supervised\n  Learning Algorithms", "comments": "7 pages, 9 figures, IPSI BgD Transactions", "journal-ref": "PSI BGD TRANSACTIONS ON INTERNET RESEARCH 13.2 (2017)", "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Probabilistic mixture models have been widely used for different machine\nlearning and pattern recognition tasks such as clustering, dimensionality\nreduction, and classification. In this paper, we focus on trying to solve the\nmost common challenges related to supervised learning algorithms by using\nmixture probability distribution functions. With this modeling strategy, we\nidentify sub-labels and generate synthetic data in order to reach better\nclassification accuracy. It means we focus on increasing the training data\nsynthetically to increase the classification accuracy.\n", "versions": [{"version": "v1", "created": "Tue, 5 Sep 2017 15:05:16 GMT"}], "update_date": "2020-04-08", "authors_parsed": [["Valencia-Zapata", "Gustavo A", ""], ["Mejia", "Daniel", ""], ["Klimeck", "Gerhard", ""], ["Zentner", "Michael", ""], ["Ersoy", "Okan", ""]]}, {"id": "1709.01471", "submitter": "Edward Raff", "authors": "Edward Raff, Jared Sylvester, Charles Nicholas", "title": "Learning the PE Header, Malware Detection with Minimal Domain Knowledge", "comments": null, "journal-ref": "Proceedings of the 10th ACM Workshop on Artificial Intelligence\n  and Security (2017) 121-132", "doi": "10.1145/3128572.3140442", "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Many efforts have been made to use various forms of domain knowledge in\nmalware detection. Currently there exist two common approaches to malware\ndetection without domain knowledge, namely byte n-grams and strings. In this\nwork we explore the feasibility of applying neural networks to malware\ndetection and feature learning. We do this by restricting ourselves to a\nminimal amount of domain knowledge in order to extract a portion of the\nPortable Executable (PE) header. By doing this we show that neural networks can\nlearn from raw bytes without explicit feature construction, and perform even\nbetter than a domain knowledge approach that parses the PE header into explicit\nfeatures.\n", "versions": [{"version": "v1", "created": "Tue, 5 Sep 2017 16:08:56 GMT"}, {"version": "v2", "created": "Sat, 11 Nov 2017 05:18:59 GMT"}], "update_date": "2017-11-15", "authors_parsed": [["Raff", "Edward", ""], ["Sylvester", "Jared", ""], ["Nicholas", "Charles", ""]]}, {"id": "1709.01476", "submitter": "Jan Zacharias", "authors": "Daniel Sonntag, Michael Barz, Jan Zacharias, Sven Stauden, Vahid\n  Rahmani, \\'Aron F\\'othi, Andr\\'as L\\H{o}rincz", "title": "Fine-tuning deep CNN models on specific MS COCO categories", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.LG", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Fine-tuning of a deep convolutional neural network (CNN) is often desired.\nThis paper provides an overview of our publicly available py-faster-rcnn-ft\nsoftware library that can be used to fine-tune the VGG_CNN_M_1024 model on\ncustom subsets of the Microsoft Common Objects in Context (MS COCO) dataset.\nFor example, we improved the procedure so that the user does not have to look\nfor suitable image files in the dataset by hand which can then be used in the\ndemo program. Our implementation randomly selects images that contain at least\none object of the categories on which the model is fine-tuned.\n", "versions": [{"version": "v1", "created": "Tue, 5 Sep 2017 16:22:28 GMT"}], "update_date": "2017-09-07", "authors_parsed": [["Sonntag", "Daniel", ""], ["Barz", "Michael", ""], ["Zacharias", "Jan", ""], ["Stauden", "Sven", ""], ["Rahmani", "Vahid", ""], ["F\u00f3thi", "\u00c1ron", ""], ["L\u0151rincz", "Andr\u00e1s", ""]]}, {"id": "1709.01509", "submitter": "Akshay Balsubramani", "authors": "Akshay Balsubramani", "title": "Linking Generative Adversarial Learning and Binary Classification", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this note, we point out a basic link between generative adversarial (GA)\ntraining and binary classification -- any powerful discriminator essentially\ncomputes an (f-)divergence between real and generated samples. The result,\nrepeatedly re-derived in decision theory, has implications for GA Networks\n(GANs), providing an alternative perspective on training f-GANs by designing\nthe discriminator loss function.\n", "versions": [{"version": "v1", "created": "Tue, 5 Sep 2017 17:55:59 GMT"}], "update_date": "2017-09-06", "authors_parsed": [["Balsubramani", "Akshay", ""]]}, {"id": "1709.01532", "submitter": "Wenjie Pei", "authors": "Wenjie Pei, Jie Yang, Zhu Sun, Jie Zhang, Alessandro Bozzon, David\n  M.J. Tax", "title": "Interacting Attention-gated Recurrent Networks for Recommendation", "comments": "Accepted by ACM International Conference on Information and Knowledge\n  Management (CIKM), 2017", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.AI cs.LG cs.SI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Capturing the temporal dynamics of user preferences over items is important\nfor recommendation. Existing methods mainly assume that all time steps in\nuser-item interaction history are equally relevant to recommendation, which\nhowever does not apply in real-world scenarios where user-item interactions can\noften happen accidentally. More importantly, they learn user and item dynamics\nseparately, thus failing to capture their joint effects on user-item\ninteractions. To better model user and item dynamics, we present the\nInteracting Attention-gated Recurrent Network (IARN) which adopts the attention\nmodel to measure the relevance of each time step. In particular, we propose a\nnovel attention scheme to learn the attention scores of user and item history\nin an interacting way, thus to account for the dependencies between user and\nitem dynamics in shaping user-item interactions. By doing so, IARN can\nselectively memorize different time steps of a user's history when predicting\nher preferences over different items. Our model can therefore provide\nmeaningful interpretations for recommendation results, which could be further\nenhanced by auxiliary features. Extensive validation on real-world datasets\nshows that IARN consistently outperforms state-of-the-art methods.\n", "versions": [{"version": "v1", "created": "Tue, 5 Sep 2017 18:01:39 GMT"}, {"version": "v2", "created": "Thu, 7 Sep 2017 10:08:44 GMT"}], "update_date": "2017-09-08", "authors_parsed": [["Pei", "Wenjie", ""], ["Yang", "Jie", ""], ["Sun", "Zhu", ""], ["Zhang", "Jie", ""], ["Bozzon", "Alessandro", ""], ["Tax", "David M. J.", ""]]}, {"id": "1709.01572", "submitter": "Hao Tang", "authors": "Hao Tang", "title": "Sequence Prediction with Neural Segmental Models", "comments": "Thesis", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG cs.SD", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Segments that span contiguous parts of inputs, such as phonemes in speech,\nnamed entities in sentences, actions in videos, occur frequently in sequence\nprediction problems. Segmental models, a class of models that explicitly\nhypothesizes segments, have allowed the exploration of rich segment features\nfor sequence prediction. However, segmental models suffer from slow decoding,\nhampering the use of computationally expensive features.\n  In this thesis, we introduce discriminative segmental cascades, a multi-pass\ninference framework that allows us to improve accuracy by adding higher-order\nfeatures and neural segmental features while maintaining efficiency. We also\nshow that instead of including more features to obtain better accuracy,\nsegmental cascades can be used to speed up training and decoding.\n  Segmental models, similarly to conventional speech recognizers, are typically\ntrained in multiple stages. In the first stage, a frame classifier is trained\nwith manual alignments, and then in the second stage, segmental models are\ntrained with manual alignments and the out- puts of the frame classifier.\nHowever, obtaining manual alignments are time-consuming and expensive. We\nexplore end-to-end training for segmental models with various loss functions,\nand show how end-to-end training with marginal log loss can eliminate the need\nfor detailed manual alignments.\n  We draw the connections between the marginal log loss and a popular\nend-to-end training approach called connectionist temporal classification. We\npresent a unifying framework for various end-to-end graph search-based models,\nsuch as hidden Markov models, connectionist temporal classification, and\nsegmental models. Finally, we discuss possible extensions of segmental models\nto large-vocabulary sequence prediction tasks.\n", "versions": [{"version": "v1", "created": "Tue, 5 Sep 2017 19:53:35 GMT"}, {"version": "v2", "created": "Tue, 12 Sep 2017 14:25:43 GMT"}, {"version": "v3", "created": "Wed, 13 Jun 2018 03:43:47 GMT"}], "update_date": "2018-06-14", "authors_parsed": [["Tang", "Hao", ""]]}, {"id": "1709.01584", "submitter": "Jill-J\\^enn Vie", "authors": "Jill-J\\^enn Vie, Florian Yger, Ryan Lahfa, Basile Clement, K\\'evin\n  Cocchi, Thomas Chalumeau and Hisashi Kashima", "title": "Using Posters to Recommend Anime and Mangas in a Cold-Start Scenario", "comments": "6 pages, 3 figures, 1 table, accepted at the MANPU 2017 workshop,\n  co-located with ICDAR 2017 in Kyoto on November 10, 2017", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Item cold-start is a classical issue in recommender systems that affects\nanime and manga recommendations as well. This problem can be framed as follows:\nhow to predict whether a user will like a manga that received few ratings from\nthe community? Content-based techniques can alleviate this issue but require\nextra information, that is usually expensive to gather. In this paper, we use a\ndeep learning technique, Illustration2Vec, to easily extract tag information\nfrom the manga and anime posters (e.g., sword, or ponytail). We propose BALSE\n(Blended Alternate Least Squares with Explanation), a new model for\ncollaborative filtering, that benefits from this extra information to recommend\nmangas. We show, using real data from an online manga recommender system called\nMangaki, that our model improves substantially the quality of recommendations,\nespecially for less-known manga, and is able to provide an interpretation of\nthe taste of the users.\n", "versions": [{"version": "v1", "created": "Sun, 3 Sep 2017 16:19:36 GMT"}, {"version": "v2", "created": "Thu, 7 Sep 2017 06:48:31 GMT"}], "update_date": "2017-09-08", "authors_parsed": [["Vie", "Jill-J\u00eann", ""], ["Yger", "Florian", ""], ["Lahfa", "Ryan", ""], ["Clement", "Basile", ""], ["Cocchi", "K\u00e9vin", ""], ["Chalumeau", "Thomas", ""], ["Kashima", "Hisashi", ""]]}, {"id": "1709.01604", "submitter": "Samuel Yeom", "authors": "Samuel Yeom, Irene Giacomelli, Matt Fredrikson, Somesh Jha", "title": "Privacy Risk in Machine Learning: Analyzing the Connection to\n  Overfitting", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Machine learning algorithms, when applied to sensitive data, pose a distinct\nthreat to privacy. A growing body of prior work demonstrates that models\nproduced by these algorithms may leak specific private information in the\ntraining data to an attacker, either through the models' structure or their\nobservable behavior. However, the underlying cause of this privacy risk is not\nwell understood beyond a handful of anecdotal accounts that suggest overfitting\nand influence might play a role.\n  This paper examines the effect that overfitting and influence have on the\nability of an attacker to learn information about the training data from\nmachine learning models, either through training set membership inference or\nattribute inference attacks. Using both formal and empirical analyses, we\nillustrate a clear relationship between these factors and the privacy risk that\narises in several popular machine learning algorithms. We find that overfitting\nis sufficient to allow an attacker to perform membership inference and, when\nthe target attribute meets certain conditions about its influence, attribute\ninference attacks. Interestingly, our formal analysis also shows that\noverfitting is not necessary for these attacks and begins to shed light on what\nother factors may be in play. Finally, we explore the connection between\nmembership inference and attribute inference, showing that there are deep\nconnections between the two that lead to effective new attacks.\n", "versions": [{"version": "v1", "created": "Tue, 5 Sep 2017 21:56:24 GMT"}, {"version": "v2", "created": "Thu, 7 Sep 2017 21:39:21 GMT"}, {"version": "v3", "created": "Thu, 1 Feb 2018 03:38:13 GMT"}, {"version": "v4", "created": "Fri, 2 Feb 2018 23:04:31 GMT"}, {"version": "v5", "created": "Fri, 4 May 2018 22:43:43 GMT"}], "update_date": "2018-05-08", "authors_parsed": [["Yeom", "Samuel", ""], ["Giacomelli", "Irene", ""], ["Fredrikson", "Matt", ""], ["Jha", "Somesh", ""]]}, {"id": "1709.01620", "submitter": "Jean-Pierre Briot", "authors": "Jean-Pierre Briot, Ga\\\"etan Hadjeres and Fran\\c{c}ois-David Pachet", "title": "Deep Learning Techniques for Music Generation -- A Survey", "comments": "209 pages. This paper is a simplified version of the book: J.-P.\n  Briot, G. Hadjeres and F.-D. Pachet, Deep Learning Techniques for Music\n  Generation, Computational Synthesis and Creative Systems, Springer, 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SD cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper is a survey and an analysis of different ways of using deep\nlearning (deep artificial neural networks) to generate musical content. We\npropose a methodology based on five dimensions for our analysis:\n  Objective - What musical content is to be generated? Examples are: melody,\npolyphony, accompaniment or counterpoint. - For what destination and for what\nuse? To be performed by a human(s) (in the case of a musical score), or by a\nmachine (in the case of an audio file).\n  Representation - What are the concepts to be manipulated? Examples are:\nwaveform, spectrogram, note, chord, meter and beat. - What format is to be\nused? Examples are: MIDI, piano roll or text. - How will the representation be\nencoded? Examples are: scalar, one-hot or many-hot.\n  Architecture - What type(s) of deep neural network is (are) to be used?\nExamples are: feedforward network, recurrent network, autoencoder or generative\nadversarial networks.\n  Challenge - What are the limitations and open challenges? Examples are:\nvariability, interactivity and creativity.\n  Strategy - How do we model and control the process of generation? Examples\nare: single-step feedforward, iterative feedforward, sampling or input\nmanipulation.\n  For each dimension, we conduct a comparative analysis of various models and\ntechniques and we propose some tentative multidimensional typology. This\ntypology is bottom-up, based on the analysis of many existing deep-learning\nbased systems for music generation selected from the relevant literature. These\nsystems are described and are used to exemplify the various choices of\nobjective, representation, architecture, challenge and strategy. The last\nsection includes some discussion and some prospects.\n", "versions": [{"version": "v1", "created": "Tue, 5 Sep 2017 23:12:01 GMT"}, {"version": "v2", "created": "Sat, 10 Nov 2018 17:02:35 GMT"}, {"version": "v3", "created": "Sat, 23 Mar 2019 20:05:32 GMT"}, {"version": "v4", "created": "Wed, 7 Aug 2019 19:25:30 GMT"}], "update_date": "2019-08-09", "authors_parsed": [["Briot", "Jean-Pierre", ""], ["Hadjeres", "Ga\u00ebtan", ""], ["Pachet", "Fran\u00e7ois-David", ""]]}, {"id": "1709.01643", "submitter": "Alexander Ratner", "authors": "Alexander J. Ratner, Henry R. Ehrenberg, Zeshan Hussain, Jared\n  Dunnmon, Christopher R\\'e", "title": "Learning to Compose Domain-Specific Transformations for Data\n  Augmentation", "comments": "To appear at Neural Information Processing Systems (NIPS) 2017", "journal-ref": "Advances in Neural Information Processing Systems 30, 2017,\n  3236--3246", "doi": null, "report-no": null, "categories": "stat.ML cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Data augmentation is a ubiquitous technique for increasing the size of\nlabeled training sets by leveraging task-specific data transformations that\npreserve class labels. While it is often easy for domain experts to specify\nindividual transformations, constructing and tuning the more sophisticated\ncompositions typically needed to achieve state-of-the-art results is a\ntime-consuming manual task in practice. We propose a method for automating this\nprocess by learning a generative sequence model over user-specified\ntransformation functions using a generative adversarial approach. Our method\ncan make use of arbitrary, non-deterministic transformation functions, is\nrobust to misspecified user input, and is trained on unlabeled data. The\nlearned transformation model can then be used to perform data augmentation for\nany end discriminative model. In our experiments, we show the efficacy of our\napproach on both image and text datasets, achieving improvements of 4.0\naccuracy points on CIFAR-10, 1.4 F1 points on the ACE relation extraction task,\nand 3.4 accuracy points when using domain-specific transformation operations on\na medical imaging dataset as compared to standard heuristic augmentation\napproaches.\n", "versions": [{"version": "v1", "created": "Wed, 6 Sep 2017 01:17:31 GMT"}, {"version": "v2", "created": "Sun, 17 Sep 2017 18:09:15 GMT"}, {"version": "v3", "created": "Sat, 30 Sep 2017 04:27:53 GMT"}], "update_date": "2018-12-10", "authors_parsed": [["Ratner", "Alexander J.", ""], ["Ehrenberg", "Henry R.", ""], ["Hussain", "Zeshan", ""], ["Dunnmon", "Jared", ""], ["R\u00e9", "Christopher", ""]]}, {"id": "1709.01648", "submitter": "Zhengping Che", "authors": "Zhengping Che, Yu Cheng, Shuangfei Zhai, Zhaonan Sun, Yan Liu", "title": "Boosting Deep Learning Risk Prediction with Generative Adversarial\n  Networks for Electronic Health Records", "comments": "To appear in ICDM 2017. This is the full version of paper with 8\n  pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The rapid growth of Electronic Health Records (EHRs), as well as the\naccompanied opportunities in Data-Driven Healthcare (DDH), has been attracting\nwidespread interests and attentions. Recent progress in the design and\napplications of deep learning methods has shown promising results and is\nforcing massive changes in healthcare academia and industry, but most of these\nmethods rely on massive labeled data. In this work, we propose a general deep\nlearning framework which is able to boost risk prediction performance with\nlimited EHR data. Our model takes a modified generative adversarial network\nnamely ehrGAN, which can provide plausible labeled EHR data by mimicking real\npatient records, to augment the training dataset in a semi-supervised learning\nmanner. We use this generative model together with a convolutional neural\nnetwork (CNN) based prediction model to improve the onset prediction\nperformance. Experiments on two real healthcare datasets demonstrate that our\nproposed framework produces realistic data samples and achieves significant\nimprovements on classification tasks with the generated data over several\nstat-of-the-art baselines.\n", "versions": [{"version": "v1", "created": "Wed, 6 Sep 2017 01:36:12 GMT"}], "update_date": "2017-09-07", "authors_parsed": [["Che", "Zhengping", ""], ["Cheng", "Yu", ""], ["Zhai", "Shuangfei", ""], ["Sun", "Zhaonan", ""], ["Liu", "Yan", ""]]}, {"id": "1709.01662", "submitter": "Jun Wang", "authors": "Zhao-Yu Han, Jun Wang, Heng Fan, Lei Wang and Pan Zhang", "title": "Unsupervised Generative Modeling Using Matrix Product States", "comments": "11 pages, 12 figures (not including the TNs) GitHub Page:\n  https://congzlwag.github.io/UnsupGenModbyMPS/", "journal-ref": "Phys. Rev. X 8, 031012 (2018)", "doi": "10.1103/PhysRevX.8.031012", "report-no": null, "categories": "cond-mat.stat-mech cs.LG quant-ph stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Generative modeling, which learns joint probability distribution from data\nand generates samples according to it, is an important task in machine learning\nand artificial intelligence. Inspired by probabilistic interpretation of\nquantum physics, we propose a generative model using matrix product states,\nwhich is a tensor network originally proposed for describing (particularly\none-dimensional) entangled quantum states. Our model enjoys efficient learning\nanalogous to the density matrix renormalization group method, which allows\ndynamically adjusting dimensions of the tensors and offers an efficient direct\nsampling approach for generative tasks. We apply our method to generative\nmodeling of several standard datasets including the Bars and Stripes, random\nbinary patterns and the MNIST handwritten digits to illustrate the abilities,\nfeatures and drawbacks of our model over popular generative models such as\nHopfield model, Boltzmann machines and generative adversarial networks. Our\nwork sheds light on many interesting directions of future exploration on the\ndevelopment of quantum-inspired algorithms for unsupervised machine learning,\nwhich are promisingly possible to be realized on quantum devices.\n", "versions": [{"version": "v1", "created": "Wed, 6 Sep 2017 03:18:33 GMT"}, {"version": "v2", "created": "Wed, 27 Sep 2017 08:45:44 GMT"}, {"version": "v3", "created": "Thu, 19 Jul 2018 03:03:42 GMT"}], "update_date": "2018-07-20", "authors_parsed": [["Han", "Zhao-Yu", ""], ["Wang", "Jun", ""], ["Fan", "Heng", ""], ["Wang", "Lei", ""], ["Zhang", "Pan", ""]]}, {"id": "1709.01672", "submitter": "Rahul  Singh", "authors": "Rahul Singh, P.R. Kumar, and Eytan Modiano", "title": "Throughput Optimal Decentralized Scheduling of Multi-Hop Networks with\n  End-to-End Deadline Constraints: II Wireless Networks with Interference", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI cs.LG cs.NE cs.SY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Consider a multihop wireless network serving multiple flows in which wireless\nlink interference constraints are described by a link interference graph. For\nsuch a network, we design routing-scheduling policies that maximize the\nend-to-end timely throughput of the network. Timely throughput of a flow $f$ is\ndefined as the average rate at which packets of flow $f$ reach their\ndestination node $d_f$ within their deadline.\n  Our policy has several surprising characteristics. Firstly, we show that the\noptimal routing-scheduling decision for an individual packet that is present at\na wireless node $i\\in V$ is solely a function of its location, and \"age\". Thus,\na wireless node $i$ does not require the knowledge of the \"global\" network\nstate in order to maximize the timely throughput. We notice that in comparison,\nunder the backpressure routing policy, a node $i$ requires only the knowledge\nof its neighbours queue lengths in order to guarantee maximal stability, and\nhence is decentralized. The key difference arises due to the fact that in our\nset-up the packets loose their utility once their \"age\" has crossed their\ndeadline, thus making the task of optimizing timely throughput much more\nchallenging than that of ensuring network stability. Of course, due to this key\ndifference, the decision process involved in maximizing the timely throughput\nis also much more complex than that involved in ensuring network-wide queue\nstabilization. In view of this, our results are somewhat surprising.\n", "versions": [{"version": "v1", "created": "Wed, 6 Sep 2017 04:56:43 GMT"}, {"version": "v2", "created": "Tue, 12 Sep 2017 03:58:18 GMT"}], "update_date": "2017-09-13", "authors_parsed": [["Singh", "Rahul", ""], ["Kumar", "P. R.", ""], ["Modiano", "Eytan", ""]]}, {"id": "1709.01674", "submitter": "Haizi Yu", "authors": "Haizi Yu, Tianxi Li, Lav R. Varshney", "title": "Probabilistic Rule Realization and Selection", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Abstraction and realization are bilateral processes that are key in deriving\nintelligence and creativity. In many domains, the two processes are approached\nthrough rules: high-level principles that reveal invariances within similar yet\ndiverse examples. Under a probabilistic setting for discrete input spaces, we\nfocus on the rule realization problem which generates input sample\ndistributions that follow the given rules. More ambitiously, we go beyond a\nmechanical realization that takes whatever is given, but instead ask for\nproactively selecting reasonable rules to realize. This goal is demanding in\npractice, since the initial rule set may not always be consistent and thus\nintelligent compromises are needed. We formulate both rule realization and\nselection as two strongly connected components within a single and symmetric\nbi-convex problem, and derive an efficient algorithm that works at large scale.\nTaking music compositional rules as the main example throughout the paper, we\ndemonstrate our model's efficiency in not only music realization (composition)\nbut also music interpretation and understanding (analysis).\n", "versions": [{"version": "v1", "created": "Wed, 6 Sep 2017 05:08:00 GMT"}, {"version": "v2", "created": "Thu, 26 Oct 2017 05:24:04 GMT"}, {"version": "v3", "created": "Fri, 9 Mar 2018 21:44:06 GMT"}], "update_date": "2018-03-13", "authors_parsed": [["Yu", "Haizi", ""], ["Li", "Tianxi", ""], ["Varshney", "Lav R.", ""]]}, {"id": "1709.01686", "submitter": "Surat Teerapittayanon", "authors": "Surat Teerapittayanon, Bradley McDanel, H.T. Kung", "title": "BranchyNet: Fast Inference via Early Exiting from Deep Neural Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep neural networks are state of the art methods for many learning tasks due\nto their ability to extract increasingly better features at each network layer.\nHowever, the improved performance of additional layers in a deep network comes\nat the cost of added latency and energy usage in feedforward inference. As\nnetworks continue to get deeper and larger, these costs become more prohibitive\nfor real-time and energy-sensitive applications. To address this issue, we\npresent BranchyNet, a novel deep network architecture that is augmented with\nadditional side branch classifiers. The architecture allows prediction results\nfor a large portion of test samples to exit the network early via these\nbranches when samples can already be inferred with high confidence. BranchyNet\nexploits the observation that features learned at an early layer of a network\nmay often be sufficient for the classification of many data points. For more\ndifficult samples, which are expected less frequently, BranchyNet will use\nfurther or all network layers to provide the best likelihood of correct\nprediction. We study the BranchyNet architecture using several well-known\nnetworks (LeNet, AlexNet, ResNet) and datasets (MNIST, CIFAR10) and show that\nit can both improve accuracy and significantly reduce the inference time of the\nnetwork.\n", "versions": [{"version": "v1", "created": "Wed, 6 Sep 2017 06:30:51 GMT"}], "update_date": "2017-09-07", "authors_parsed": [["Teerapittayanon", "Surat", ""], ["McDanel", "Bradley", ""], ["Kung", "H. T.", ""]]}, {"id": "1709.01703", "submitter": "Daniel Michelsanti", "authors": "Daniel Michelsanti and Zheng-Hua Tan", "title": "Conditional Generative Adversarial Networks for Speech Enhancement and\n  Noise-Robust Speaker Verification", "comments": "INTERSPEECH 2017 August 20-24, 2017, Stockholm, Sweden", "journal-ref": null, "doi": "10.21437/Interspeech.2017-1620", "report-no": null, "categories": "eess.AS cs.LG cs.SD eess.SP stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Improving speech system performance in noisy environments remains a\nchallenging task, and speech enhancement (SE) is one of the effective\ntechniques to solve the problem. Motivated by the promising results of\ngenerative adversarial networks (GANs) in a variety of image processing tasks,\nwe explore the potential of conditional GANs (cGANs) for SE, and in particular,\nwe make use of the image processing framework proposed by Isola et al. [1] to\nlearn a mapping from the spectrogram of noisy speech to an enhanced\ncounterpart. The SE cGAN consists of two networks, trained in an adversarial\nmanner: a generator that tries to enhance the input noisy spectrogram, and a\ndiscriminator that tries to distinguish between enhanced spectrograms provided\nby the generator and clean ones from the database using the noisy spectrogram\nas a condition. We evaluate the performance of the cGAN method in terms of\nperceptual evaluation of speech quality (PESQ), short-time objective\nintelligibility (STOI), and equal error rate (EER) of speaker verification (an\nexample application). Experimental results show that the cGAN method overall\noutperforms the classical short-time spectral amplitude minimum mean square\nerror (STSA-MMSE) SE algorithm, and is comparable to a deep neural\nnetwork-based SE approach (DNN-SE).\n", "versions": [{"version": "v1", "created": "Wed, 6 Sep 2017 07:51:18 GMT"}, {"version": "v2", "created": "Thu, 7 Sep 2017 06:07:30 GMT"}], "update_date": "2019-11-05", "authors_parsed": [["Michelsanti", "Daniel", ""], ["Tan", "Zheng-Hua", ""]]}, {"id": "1709.01716", "submitter": "Daniel Ting", "authors": "Daniel Ting and Eric Brochu", "title": "Optimal Sub-sampling with Influence Functions", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Sub-sampling is a common and often effective method to deal with the\ncomputational challenges of large datasets. However, for most statistical\nmodels, there is no well-motivated approach for drawing a non-uniform\nsubsample. We show that the concept of an asymptotically linear estimator and\nthe associated influence function leads to optimal sampling procedures for a\nwide class of popular models. Furthermore, for linear regression models which\nhave well-studied procedures for non-uniform sub-sampling, we show our optimal\ninfluence function based method outperforms previous approaches. We empirically\nshow the improved performance of our method on real datasets.\n", "versions": [{"version": "v1", "created": "Wed, 6 Sep 2017 08:32:50 GMT"}], "update_date": "2017-09-07", "authors_parsed": [["Ting", "Daniel", ""], ["Brochu", "Eric", ""]]}, {"id": "1709.01720", "submitter": "Eitam Sheetrit", "authors": "Eitam Sheetrit, Nir Nissim, Denis Klimov, Lior Fuchs, Yuval Elovici,\n  Yuval Shahar", "title": "Temporal Pattern Discovery for Accurate Sepsis Diagnosis in ICU Patients", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.AP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Sepsis is a condition caused by the body's overwhelming and life-threatening\nresponse to infection, which can lead to tissue damage, organ failure, and\nfinally death. Common signs and symptoms include fever, increased heart rate,\nincreased breathing rate, and confusion. Sepsis is difficult to predict,\ndiagnose, and treat. Patients who develop sepsis have an increased risk of\ncomplications and death and face higher health care costs and longer\nhospitalization. Today, sepsis is one of the leading causes of mortality among\npopulations in intensive care units (ICUs). In this paper, we look at the\nproblem of early detection of sepsis by using temporal data mining. We focus on\nthe use of knowledge-based temporal abstraction to create meaningful\ninterval-based abstractions, and on time-interval mining to discover frequent\ninterval-based patterns. We used 2,560 cases derived from the MIMIC-III\ndatabase. We found that the distribution of the temporal patterns whose\nfrequency is above 10% discovered in the records of septic patients during the\nlast 6 and 12 hours before onset of sepsis is significantly different from that\ndistribution within a similar period, during an equivalent time window during\nhospitalization, in the records of non-septic patients. This discovery is\nencouraging for the purpose of performing an early diagnosis of sepsis using\nthe discovered patterns as constructed features.\n", "versions": [{"version": "v1", "created": "Wed, 6 Sep 2017 08:42:25 GMT"}], "update_date": "2017-09-07", "authors_parsed": [["Sheetrit", "Eitam", ""], ["Nissim", "Nir", ""], ["Klimov", "Denis", ""], ["Fuchs", "Lior", ""], ["Elovici", "Yuval", ""], ["Shahar", "Yuval", ""]]}, {"id": "1709.01779", "submitter": "Filipe Rodrigues", "authors": "Filipe Rodrigues and Francisco Pereira", "title": "Deep learning from crowds", "comments": "10 pages, The Thirty-Second AAAI Conference on Artificial\n  Intelligence (AAAI), 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.CV cs.HC cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Over the last few years, deep learning has revolutionized the field of\nmachine learning by dramatically improving the state-of-the-art in various\ndomains. However, as the size of supervised artificial neural networks grows,\ntypically so does the need for larger labeled datasets. Recently, crowdsourcing\nhas established itself as an efficient and cost-effective solution for labeling\nlarge sets of data in a scalable manner, but it often requires aggregating\nlabels from multiple noisy contributors with different levels of expertise. In\nthis paper, we address the problem of learning deep neural networks from\ncrowds. We begin by describing an EM algorithm for jointly learning the\nparameters of the network and the reliabilities of the annotators. Then, a\nnovel general-purpose crowd layer is proposed, which allows us to train deep\nneural networks end-to-end, directly from the noisy labels of multiple\nannotators, using only backpropagation. We empirically show that the proposed\napproach is able to internally capture the reliability and biases of different\nannotators and achieve new state-of-the-art results for various crowdsourced\ndatasets across different settings, namely classification, regression and\nsequence labeling.\n", "versions": [{"version": "v1", "created": "Wed, 6 Sep 2017 11:41:19 GMT"}, {"version": "v2", "created": "Mon, 25 Dec 2017 12:30:12 GMT"}], "update_date": "2017-12-27", "authors_parsed": [["Rodrigues", "Filipe", ""], ["Pereira", "Francisco", ""]]}, {"id": "1709.01846", "submitter": "Yunchen Pu", "authors": "Liqun Chen, Shuyang Dai, Yunchen Pu, Chunyuan Li, Qinliang Su,\n  Lawrence Carin", "title": "Symmetric Variational Autoencoder and Connections to Adversarial\n  Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A new form of the variational autoencoder (VAE) is proposed, based on the\nsymmetric Kullback-Leibler divergence. It is demonstrated that learning of the\nresulting symmetric VAE (sVAE) has close connections to previously developed\nadversarial-learning methods. This relationship helps unify the previously\ndistinct techniques of VAE and adversarially learning, and provides insights\nthat allow us to ameliorate shortcomings with some previously developed\nadversarial methods. In addition to an analysis that motivates and explains the\nsVAE, an extensive set of experiments validate the utility of the approach.\n", "versions": [{"version": "v1", "created": "Wed, 6 Sep 2017 14:48:19 GMT"}, {"version": "v2", "created": "Thu, 19 Oct 2017 23:43:49 GMT"}], "update_date": "2017-10-23", "authors_parsed": [["Chen", "Liqun", ""], ["Dai", "Shuyang", ""], ["Pu", "Yunchen", ""], ["Li", "Chunyuan", ""], ["Su", "Qinliang", ""], ["Carin", "Lawrence", ""]]}, {"id": "1709.01860", "submitter": "Christopher Dienes", "authors": "Christopher Dienes", "title": "The low-rank hurdle model", "comments": "14 pages, 2 figures, 2 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A composite loss framework is proposed for low-rank modeling of data\nconsisting of interesting and common values, such as excess zeros or missing\nvalues. The methodology is motivated by the generalized low-rank framework and\nthe hurdle method which is commonly used to analyze zero-inflated counts. The\nmodel is demonstrated on a manufacturing data set and applied to the problem of\nmissing value imputation.\n", "versions": [{"version": "v1", "created": "Wed, 6 Sep 2017 15:41:11 GMT"}], "update_date": "2017-09-07", "authors_parsed": [["Dienes", "Christopher", ""]]}, {"id": "1709.01867", "submitter": "Soufiane Belharbi", "authors": "Soufiane Belharbi, Cl\\'ement Chatelain, Romain H\\'erault, S\\'ebastien\n  Adam", "title": "Neural Networks Regularization Through Class-wise Invariant\n  Representation Learning", "comments": "Submitted to ELSEVIER, 13 pages, 5 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Training deep neural networks is known to require a large number of training\nsamples. However, in many applications only few training samples are available.\nIn this work, we tackle the issue of training neural networks for\nclassification task when few training samples are available. We attempt to\nsolve this issue by proposing a new regularization term that constrains the\nhidden layers of a network to learn class-wise invariant representations. In\nour regularization framework, learning invariant representations is generalized\nto the class membership where samples with the same class should have the same\nrepresentation. Numerical experiments over MNIST and its variants showed that\nour proposal helps improving the generalization of neural network particularly\nwhen trained with few samples. We provide the source code of our framework\nhttps://github.com/sbelharbi/learning-class-invariant-features .\n", "versions": [{"version": "v1", "created": "Wed, 6 Sep 2017 15:53:16 GMT"}, {"version": "v2", "created": "Sun, 1 Oct 2017 12:45:37 GMT"}, {"version": "v3", "created": "Wed, 25 Oct 2017 18:17:15 GMT"}, {"version": "v4", "created": "Fri, 22 Dec 2017 14:11:44 GMT"}], "update_date": "2017-12-25", "authors_parsed": [["Belharbi", "Soufiane", ""], ["Chatelain", "Cl\u00e9ment", ""], ["H\u00e9rault", "Romain", ""], ["Adam", "S\u00e9bastien", ""]]}, {"id": "1709.01870", "submitter": "Sunrita Poddar", "authors": "Sunrita Poddar, Mathews Jacob", "title": "Clustering of Data with Missing Entries using Non-convex Fusion\n  Penalties", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The presence of missing entries in data often creates challenges for pattern\nrecognition algorithms. Traditional algorithms for clustering data assume that\nall the feature values are known for every data point. We propose a method to\ncluster data in the presence of missing information. Unlike conventional\nclustering techniques where every feature is known for each point, our\nalgorithm can handle cases where a few feature values are unknown for every\npoint. For this more challenging problem, we provide theoretical guarantees for\nclustering using a $\\ell_0$ fusion penalty based optimization problem.\nFurthermore, we propose an algorithm to solve a relaxation of this problem\nusing saturating non-convex fusion penalties. It is observed that this\nalgorithm produces solutions that degrade gradually with an increase in the\nfraction of missing feature values. We demonstrate the utility of the proposed\nmethod using a simulated dataset, the Wine dataset and also an under-sampled\ncardiac MRI dataset. It is shown that the proposed method is a promising\nclustering technique for datasets with large fractions of missing entries.\n", "versions": [{"version": "v1", "created": "Wed, 6 Sep 2017 15:59:57 GMT"}], "update_date": "2017-09-07", "authors_parsed": [["Poddar", "Sunrita", ""], ["Jacob", "Mathews", ""]]}, {"id": "1709.01888", "submitter": "Miriam Cha", "authors": "Miriam Cha, Youngjune Gwon, H.T. Kung", "title": "Language Modeling by Clustering with Word Embeddings for Text\n  Readability Assessment", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a clustering-based language model using word embeddings for text\nreadability prediction. Presumably, an Euclidean semantic space hypothesis\nholds true for word embeddings whose training is done by observing word\nco-occurrences. We argue that clustering with word embeddings in the metric\nspace should yield feature representations in a higher semantic space\nappropriate for text regression. Also, by representing features in terms of\nhistograms, our approach can naturally address documents of varying lengths. An\nempirical evaluation using the Common Core Standards corpus reveals that the\nfeatures formed on our clustering-based language model significantly improve\nthe previously known results for the same corpus in readability prediction. We\nalso evaluate the task of sentence matching based on semantic relatedness using\nthe Wiki-SimpleWiki corpus and find that our features lead to superior matching\nperformance.\n", "versions": [{"version": "v1", "created": "Tue, 5 Sep 2017 02:38:44 GMT"}], "update_date": "2017-09-07", "authors_parsed": [["Cha", "Miriam", ""], ["Gwon", "Youngjune", ""], ["Kung", "H. T.", ""]]}, {"id": "1709.01894", "submitter": "Mark van der Wilk", "authors": "Mark van der Wilk, Carl Edward Rasmussen, James Hensman", "title": "Convolutional Gaussian Processes", "comments": "To appear in Advances in Neural Information Processing Systems 30\n  (NIPS 2017)", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a practical way of introducing convolutional structure into\nGaussian processes, making them more suited to high-dimensional inputs like\nimages. The main contribution of our work is the construction of an\ninter-domain inducing point approximation that is well-tailored to the\nconvolutional kernel. This allows us to gain the generalisation benefit of a\nconvolutional kernel, together with fast but accurate posterior inference. We\ninvestigate several variations of the convolutional kernel, and apply it to\nMNIST and CIFAR-10, which have both been known to be challenging for Gaussian\nprocesses. We also show how the marginal likelihood can be used to find an\noptimal weighting between convolutional and RBF kernels to further improve\nperformance. We hope that this illustration of the usefulness of a marginal\nlikelihood will help automate discovering architectures in larger models.\n", "versions": [{"version": "v1", "created": "Wed, 6 Sep 2017 16:59:02 GMT"}], "update_date": "2017-09-07", "authors_parsed": [["van der Wilk", "Mark", ""], ["Rasmussen", "Carl Edward", ""], ["Hensman", "James", ""]]}, {"id": "1709.01919", "submitter": "Ming Yu", "authors": "Ming Yu, Varun Gupta, Mladen Kolar", "title": "Estimation of a Low-rank Topic-Based Model for Information Cascades", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG cs.SI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the problem of estimating the latent structure of a social\nnetwork based on the observed information diffusion events, or cascades, where\nthe observations for a given cascade consist of only the timestamps of\ninfection for infected nodes but not the source of the infection. Most of the\nexisting work on this problem has focused on estimating a diffusion matrix\nwithout any structural assumptions on it. In this paper, we propose a novel\nmodel based on the intuition that an information is more likely to propagate\namong two nodes if they are interested in similar topics which are also\nprominent in the information content. In particular, our model endows each node\nwith an influence vector (which measures how authoritative the node is on each\ntopic) and a receptivity vector (which measures how susceptible the node is for\neach topic). We show how this node-topic structure can be estimated from the\nobserved cascades, and prove the consistency of the estimator. Experiments on\nsynthetic and real data demonstrate the improved performance and better\ninterpretability of our model compared to existing state-of-the-art methods.\n", "versions": [{"version": "v1", "created": "Wed, 6 Sep 2017 17:56:45 GMT"}, {"version": "v2", "created": "Fri, 21 Jun 2019 03:48:01 GMT"}, {"version": "v3", "created": "Thu, 26 Mar 2020 01:04:36 GMT"}], "update_date": "2020-03-27", "authors_parsed": [["Yu", "Ming", ""], ["Gupta", "Varun", ""], ["Kolar", "Mladen", ""]]}, {"id": "1709.01922", "submitter": "Keunwoo Choi Mr", "authors": "Keunwoo Choi, Gy\\\"orgy Fazekas, Kyunghyun Cho and Mark Sandler", "title": "A Comparison of Audio Signal Preprocessing Methods for Deep Neural\n  Networks on Music Tagging", "comments": "5 pages. EUSIPCO 2018 camera-ready. arXiv:1706.02361 does not have\n  the overlapped part with this submission anymore", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SD cs.CV cs.IR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we empirically investigate the effect of audio preprocessing\non music tagging with deep neural networks. We perform comprehensive\nexperiments involving audio preprocessing using different time-frequency\nrepresentations, logarithmic magnitude compression, frequency weighting, and\nscaling. We show that many commonly used input preprocessing techniques are\nredundant except magnitude compression.\n", "versions": [{"version": "v1", "created": "Wed, 6 Sep 2017 12:44:01 GMT"}, {"version": "v2", "created": "Sun, 3 Jun 2018 13:12:55 GMT"}, {"version": "v3", "created": "Mon, 22 Feb 2021 13:21:38 GMT"}], "update_date": "2021-02-23", "authors_parsed": [["Choi", "Keunwoo", ""], ["Fazekas", "Gy\u00f6rgy", ""], ["Cho", "Kyunghyun", ""], ["Sandler", "Mark", ""]]}, {"id": "1709.01953", "submitter": "Behnam Neyshabur", "authors": "Behnam Neyshabur", "title": "Implicit Regularization in Deep Learning", "comments": "PhD Thesis", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In an attempt to better understand generalization in deep learning, we study\nseveral possible explanations. We show that implicit regularization induced by\nthe optimization method is playing a key role in generalization and success of\ndeep learning models. Motivated by this view, we study how different complexity\nmeasures can ensure generalization and explain how optimization algorithms can\nimplicitly regularize complexity measures. We empirically investigate the\nability of these measures to explain different observed phenomena in deep\nlearning. We further study the invariances in neural networks, suggest\ncomplexity measures and optimization algorithms that have similar invariances\nto those in neural networks and evaluate them on a number of learning tasks.\n", "versions": [{"version": "v1", "created": "Wed, 6 Sep 2017 18:12:04 GMT"}, {"version": "v2", "created": "Fri, 8 Sep 2017 03:27:06 GMT"}], "update_date": "2017-09-11", "authors_parsed": [["Neyshabur", "Behnam", ""]]}, {"id": "1709.01972", "submitter": "David W. Dreisigmeyer", "authors": "David W. Dreisigmeyer", "title": "A Quasi-isometric Embedding Algorithm", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.CG cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The Whitney embedding theorem gives an upper bound on the smallest embedding\ndimension of a manifold. If a data set lies on a manifold, a random projection\ninto this reduced dimension will retain the manifold structure. Here we present\nan algorithm to find a projection that distorts the data as little as possible.\n", "versions": [{"version": "v1", "created": "Wed, 6 Sep 2017 19:35:02 GMT"}, {"version": "v2", "created": "Thu, 14 Sep 2017 17:35:59 GMT"}, {"version": "v3", "created": "Fri, 3 Nov 2017 13:40:50 GMT"}], "update_date": "2017-11-06", "authors_parsed": [["Dreisigmeyer", "David W.", ""]]}, {"id": "1709.02012", "submitter": "Geoff Pleiss", "authors": "Geoff Pleiss, Manish Raghavan, Felix Wu, Jon Kleinberg, Kilian Q.\n  Weinberger", "title": "On Fairness and Calibration", "comments": "First two authors contributed equally. NIPS 2017", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CY stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The machine learning community has become increasingly concerned with the\npotential for bias and discrimination in predictive models. This has motivated\na growing line of work on what it means for a classification procedure to be\n\"fair.\" In this paper, we investigate the tension between minimizing error\ndisparity across different population groups while maintaining calibrated\nprobability estimates. We show that calibration is compatible only with a\nsingle error constraint (i.e. equal false-negatives rates across groups), and\nshow that any algorithm that satisfies this relaxation is no better than\nrandomizing a percentage of predictions for an existing classifier. These\nunsettling findings, which extend and generalize existing results, are\nempirically confirmed on several datasets.\n", "versions": [{"version": "v1", "created": "Wed, 6 Sep 2017 21:49:38 GMT"}, {"version": "v2", "created": "Fri, 3 Nov 2017 18:18:41 GMT"}], "update_date": "2017-11-07", "authors_parsed": [["Pleiss", "Geoff", ""], ["Raghavan", "Manish", ""], ["Wu", "Felix", ""], ["Kleinberg", "Jon", ""], ["Weinberger", "Kilian Q.", ""]]}, {"id": "1709.02023", "submitter": "Murat Kocaoglu", "authors": "Murat Kocaoglu, Christopher Snyder, Alexandros G. Dimakis, Sriram\n  Vishwanath", "title": "CausalGAN: Learning Causal Implicit Generative Models with Adversarial\n  Training", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.IT math.IT stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose an adversarial training procedure for learning a causal implicit\ngenerative model for a given causal graph. We show that adversarial training\ncan be used to learn a generative model with true observational and\ninterventional distributions if the generator architecture is consistent with\nthe given causal graph. We consider the application of generating faces based\non given binary labels where the dependency structure between the labels is\npreserved with a causal graph. This problem can be seen as learning a causal\nimplicit generative model for the image and labels. We devise a two-stage\nprocedure for this problem. First we train a causal implicit generative model\nover binary labels using a neural network consistent with a causal graph as the\ngenerator. We empirically show that WassersteinGAN can be used to output\ndiscrete labels. Later, we propose two new conditional GAN architectures, which\nwe call CausalGAN and CausalBEGAN. We show that the optimal generator of the\nCausalGAN, given the labels, samples from the image distributions conditioned\non these labels. The conditional GAN combined with a trained causal implicit\ngenerative model for the labels is then a causal implicit generative model over\nthe labels and the generated image. We show that the proposed architectures can\nbe used to sample from observational and interventional image distributions,\neven for interventions which do not naturally occur in the dataset.\n", "versions": [{"version": "v1", "created": "Wed, 6 Sep 2017 22:53:12 GMT"}, {"version": "v2", "created": "Thu, 14 Sep 2017 22:52:47 GMT"}], "update_date": "2017-09-18", "authors_parsed": [["Kocaoglu", "Murat", ""], ["Snyder", "Christopher", ""], ["Dimakis", "Alexandros G.", ""], ["Vishwanath", "Sriram", ""]]}, {"id": "1709.02066", "submitter": "Pin Wang", "authors": "Pin Wang, Ching-Yao Chan", "title": "Formulation of Deep Reinforcement Learning Architecture Toward\n  Autonomous Driving for On-Ramp Merge", "comments": "IEEE International Conference on Intelligent Transportation Systems,\n  Yokohama, Japan, 2017", "journal-ref": null, "doi": "10.1109/ITSC.2017.8317735", "report-no": null, "categories": "cs.LG cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Multiple automakers have in development or in production automated driving\nsystems (ADS) that offer freeway-pilot functions. This type of ADS is typically\nlimited to restricted-access freeways only, that is, the transition from manual\nto automated modes takes place only after the ramp merging process is completed\nmanually. One major challenge to extend the automation to ramp merging is that\nthe automated vehicle needs to incorporate and optimize long-term objectives\n(e.g. successful and smooth merge) when near-term actions must be safely\nexecuted. Moreover, the merging process involves interactions with other\nvehicles whose behaviors are sometimes hard to predict but may influence the\nmerging vehicle optimal actions. To tackle such a complicated control problem,\nwe propose to apply Deep Reinforcement Learning (DRL) techniques for finding an\noptimal driving policy by maximizing the long-term reward in an interactive\nenvironment. Specifically, we apply a Long Short-Term Memory (LSTM)\narchitecture to model the interactive environment, from which an internal state\ncontaining historical driving information is conveyed to a Deep Q-Network\n(DQN). The DQN is used to approximate the Q-function, which takes the internal\nstate as input and generates Q-values as output for action selection. With this\nDRL architecture, the historical impact of interactive environment on the\nlong-term reward can be captured and taken into account for deciding the\noptimal control policy. The proposed architecture has the potential to be\nextended and applied to other autonomous driving scenarios such as driving\nthrough a complex intersection or changing lanes under varying traffic flow\nconditions.\n", "versions": [{"version": "v1", "created": "Thu, 7 Sep 2017 04:50:29 GMT"}, {"version": "v2", "created": "Mon, 23 Apr 2018 21:20:06 GMT"}, {"version": "v3", "created": "Sat, 2 Feb 2019 02:04:20 GMT"}], "update_date": "2019-02-05", "authors_parsed": [["Wang", "Pin", ""], ["Chan", "Ching-Yao", ""]]}, {"id": "1709.02082", "submitter": "Romain Lopez", "authors": "Romain Lopez, Jeffrey Regier, Michael Cole, Michael Jordan and Nir\n  Yosef", "title": "A deep generative model for gene expression profiles from single-cell\n  RNA sequencing", "comments": "BayLearn2017, NIPS workshop MLCB 2017", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG q-bio.GN stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a probabilistic model for interpreting gene expression levels that\nare observed through single-cell RNA sequencing. In the model, each cell has a\nlow-dimensional latent representation. Additional latent variables account for\ntechnical effects that may erroneously set some observations of gene expression\nlevels to zero. Conditional distributions are specified by neural networks,\ngiving the proposed model enough flexibility to fit the data well. We use\nvariational inference and stochastic optimization to approximate the posterior\ndistribution. The inference procedure scales to over one million cells, whereas\ncompeting algorithms do not. Even for smaller datasets, for several tasks, the\nproposed procedure outperforms state-of-the-art methods like ZIFA and\nZINB-WaVE. We also extend our framework to account for batch effects and other\nconfounding factors, and propose a Bayesian hypothesis test for differential\nexpression that outperforms DESeq2.\n", "versions": [{"version": "v1", "created": "Thu, 7 Sep 2017 05:59:49 GMT"}, {"version": "v2", "created": "Tue, 17 Oct 2017 01:41:27 GMT"}, {"version": "v3", "created": "Wed, 18 Oct 2017 00:37:51 GMT"}, {"version": "v4", "created": "Tue, 16 Jan 2018 22:44:59 GMT"}], "update_date": "2018-01-18", "authors_parsed": [["Lopez", "Romain", ""], ["Regier", "Jeffrey", ""], ["Cole", "Michael", ""], ["Jordan", "Michael", ""], ["Yosef", "Nir", ""]]}, {"id": "1709.02087", "submitter": "Ilias Diakonikolas", "authors": "Ilias Diakonikolas, Daniel M. Kane, Alistair Stewart", "title": "Sharp Bounds for Generalized Uniformity Testing", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.IT cs.LG math.IT math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the problem of generalized uniformity testing \\cite{BC17} of a\ndiscrete probability distribution: Given samples from a probability\ndistribution $p$ over an {\\em unknown} discrete domain $\\mathbf{\\Omega}$, we\nwant to distinguish, with probability at least $2/3$, between the case that $p$\nis uniform on some {\\em subset} of $\\mathbf{\\Omega}$ versus $\\epsilon$-far, in\ntotal variation distance, from any such uniform distribution.\n  We establish tight bounds on the sample complexity of generalized uniformity\ntesting. In more detail, we present a computationally efficient tester whose\nsample complexity is optimal, up to constant factors, and a matching\ninformation-theoretic lower bound. Specifically, we show that the sample\ncomplexity of generalized uniformity testing is\n$\\Theta\\left(1/(\\epsilon^{4/3}\\|p\\|_3) + 1/(\\epsilon^{2} \\|p\\|_2) \\right)$.\n", "versions": [{"version": "v1", "created": "Thu, 7 Sep 2017 06:16:08 GMT"}], "update_date": "2017-09-08", "authors_parsed": [["Diakonikolas", "Ilias", ""], ["Kane", "Daniel M.", ""], ["Stewart", "Alistair", ""]]}, {"id": "1709.02123", "submitter": "Zhizhong Li", "authors": "Zhizhong Li and Dahua Lin", "title": "Integrating Specialized Classifiers Based on Continuous Time Markov\n  Chain", "comments": "Published at IJCAI-17, typo fixed", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Specialized classifiers, namely those dedicated to a subset of classes, are\noften adopted in real-world recognition systems. However, integrating such\nclassifiers is nontrivial. Existing methods, e.g. weighted average, usually\nimplicitly assume that all constituents of an ensemble cover the same set of\nclasses. Such methods can produce misleading predictions when used to combine\nspecialized classifiers. This work explores a novel approach. Instead of\ncombining predictions from individual classifiers directly, it first decomposes\nthe predictions into sets of pairwise preferences, treating them as transition\nchannels between classes, and thereon constructs a continuous-time Markov\nchain, and use the equilibrium distribution of this chain as the final\nprediction. This way allows us to form a coherent picture over all specialized\npredictions. On large public datasets, the proposed method obtains considerable\nimprovement compared to mainstream ensemble methods, especially when the\nclassifier coverage is highly unbalanced.\n", "versions": [{"version": "v1", "created": "Thu, 7 Sep 2017 07:56:30 GMT"}], "update_date": "2017-09-08", "authors_parsed": [["Li", "Zhizhong", ""], ["Lin", "Dahua", ""]]}, {"id": "1709.02169", "submitter": "Rafael Dos Santos De Oliveira", "authors": "Rafael Oliveira, Lionel Ott, Vitor Guizilini and Fabio Ramos", "title": "Bayesian Optimisation for Safe Navigation under Localisation Uncertainty", "comments": "To appear in the proceedings of the 18th International Symposium on\n  Robotics Research (ISRR 2017)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In outdoor environments, mobile robots are required to navigate through\nterrain with varying characteristics, some of which might significantly affect\nthe integrity of the platform. Ideally, the robot should be able to identify\nareas that are safe for navigation based on its own percepts about the\nenvironment while avoiding damage to itself. Bayesian optimisation (BO) has\nbeen successfully applied to the task of learning a model of terrain\ntraversability while guiding the robot through more traversable areas. An\nissue, however, is that localisation uncertainty can end up guiding the robot\nto unsafe areas and distort the model being learnt. In this paper, we address\nthis problem and present a novel method that allows BO to consider localisation\nuncertainty by applying a Gaussian process model for uncertain inputs as a\nprior. We evaluate the proposed method in simulation and in experiments with a\nreal robot navigating over rough terrain and compare it against standard BO\nmethods.\n", "versions": [{"version": "v1", "created": "Thu, 7 Sep 2017 10:17:52 GMT"}, {"version": "v2", "created": "Sat, 17 Feb 2018 02:46:33 GMT"}], "update_date": "2018-02-20", "authors_parsed": [["Oliveira", "Rafael", ""], ["Ott", "Lionel", ""], ["Guizilini", "Vitor", ""], ["Ramos", "Fabio", ""]]}, {"id": "1709.02194", "submitter": "Biswa Sengupta", "authors": "Alessandro Bay and Biswa Sengupta", "title": "Approximating meta-heuristics with homotopic recurrent neural networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.DM cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Much combinatorial optimisation problems constitute a non-polynomial (NP)\nhard optimisation problem, i.e., they can not be solved in polynomial time. One\nsuch problem is finding the shortest route between two nodes on a graph.\nMeta-heuristic algorithms such as $A^{*}$ along with mixed-integer programming\n(MIP) methods are often employed for these problems. Our work demonstrates that\nit is possible to approximate solutions generated by a meta-heuristic algorithm\nusing a deep recurrent neural network. We compare different methodologies based\non reinforcement learning (RL) and recurrent neural networks (RNN) to gauge\ntheir respective quality of approximation. We show the viability of recurrent\nneural network solutions on a graph that has over 300 nodes and argue that a\nsequence-to-sequence network rather than other recurrent networks has improved\napproximation quality. Additionally, we argue that homotopy continuation --\nthat increases chances of hitting an extremum -- further improves the estimate\ngenerated by a vanilla RNN.\n", "versions": [{"version": "v1", "created": "Thu, 7 Sep 2017 11:54:36 GMT"}], "update_date": "2017-09-08", "authors_parsed": [["Bay", "Alessandro", ""], ["Sengupta", "Biswa", ""]]}, {"id": "1709.02232", "submitter": "Andrey Lavrentyev", "authors": "Pavel Filonov, Fedor Kitashov, Andrey Lavrentyev", "title": "RNN-based Early Cyber-Attack Detection for the Tennessee Eastman Process", "comments": "ICML 2017 Time Series Workshop, Sydney, Australia, 2017", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  An RNN-based forecasting approach is used to early detect anomalies in\nindustrial multivariate time series data from a simulated Tennessee Eastman\nProcess (TEP) with many cyber-attacks. This work continues a previously\nproposed LSTM-based approach to the fault detection in simpler data. It is\nconsidered necessary to adapt the RNN network to deal with data containing\nstochastic, stationary, transitive and a rich variety of anomalous behaviours.\nThere is particular focus on early detection with special NAB-metric. A\ncomparison with the DPCA approach is provided. The generated data set is made\npublicly available.\n", "versions": [{"version": "v1", "created": "Thu, 7 Sep 2017 13:45:29 GMT"}], "update_date": "2017-09-08", "authors_parsed": [["Filonov", "Pavel", ""], ["Kitashov", "Fedor", ""], ["Lavrentyev", "Andrey", ""]]}, {"id": "1709.02236", "submitter": "Andrea Gigli", "authors": "Andrea Gigli, Arjan Gijsberts, Valentina Gregori, Matteo Cognolato,\n  Manfredo Atzori, Barbara Caputo", "title": "Visual Cues to Improve Myoelectric Control of Upper Limb Prostheses", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The instability of myoelectric signals over time complicates their use to\ncontrol highly articulated prostheses. To address this problem, studies have\ntried to combine surface electromyography with modalities that are less\naffected by the amputation and environment, such as accelerometry or gaze\ninformation. In the latter case, the hypothesis is that a subject looks at the\nobject he or she intends to manipulate and that knowing this object's\naffordances allows to constrain the set of possible grasps. In this paper, we\ndevelop an automated way to detect stable fixations and show that gaze\ninformation is indeed helpful in predicting hand movements. In our multimodal\napproach, we automatically detect stable gazes and segment an object of\ninterest around the subject's fixation in the visual frame. The patch extracted\naround this object is subsequently fed through an off-the-shelf deep\nconvolutional neural network to obtain a high level feature representation,\nwhich is then combined with traditional surface electromyography in the\nclassification stage. Tests have been performed on a dataset acquired from five\nintact subjects who performed ten types of grasps on various objects as well as\nin a functional setting. They show that the addition of gaze information\nincreases the classification accuracy considerably. Further analysis\ndemonstrates that this improvement is consistent for all grasps and\nconcentrated during the movement onset and offset.\n", "versions": [{"version": "v1", "created": "Tue, 29 Aug 2017 16:59:19 GMT"}], "update_date": "2017-09-08", "authors_parsed": [["Gigli", "Andrea", ""], ["Gijsberts", "Arjan", ""], ["Gregori", "Valentina", ""], ["Cognolato", "Matteo", ""], ["Atzori", "Manfredo", ""], ["Caputo", "Barbara", ""]]}, {"id": "1709.02249", "submitter": "Sungjoon Choi", "authors": "Sungjoon Choi, Kyungjae Lee, Sungbin Lim, Songhwai Oh", "title": "Uncertainty-Aware Learning from Demonstration using Mixture Density\n  Networks with Sampling-Free Variance Modeling", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.LG cs.RO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we propose an uncertainty-aware learning from demonstration\nmethod by presenting a novel uncertainty estimation method utilizing a mixture\ndensity network appropriate for modeling complex and noisy human behaviors. The\nproposed uncertainty acquisition can be done with a single forward path without\nMonte Carlo sampling and is suitable for real-time robotics applications. The\nproperties of the proposed uncertainty measure are analyzed through three\ndifferent synthetic examples, absence of data, heavy measurement noise, and\ncomposition of functions scenarios. We show that each case can be distinguished\nusing the proposed uncertainty measure and presented an uncertainty-aware\nlearn- ing from demonstration method of an autonomous driving using this\nproperty. The proposed uncertainty-aware learning from demonstration method\noutperforms other compared methods in terms of safety using a complex\nreal-world driving dataset.\n", "versions": [{"version": "v1", "created": "Sun, 3 Sep 2017 18:57:54 GMT"}, {"version": "v2", "created": "Fri, 8 Sep 2017 06:11:36 GMT"}], "update_date": "2018-12-21", "authors_parsed": [["Choi", "Sungjoon", ""], ["Lee", "Kyungjae", ""], ["Lim", "Sungbin", ""], ["Oh", "Songhwai", ""]]}, {"id": "1709.02251", "submitter": "Shizhe Chen", "authors": "Shizhe Chen, Qin Jin", "title": "Multi-modal Conditional Attention Fusion for Dimensional Emotion\n  Prediction", "comments": "Appeared at ACM Multimedia 2016", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG cs.MM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Continuous dimensional emotion prediction is a challenging task where the\nfusion of various modalities usually achieves state-of-the-art performance such\nas early fusion or late fusion. In this paper, we propose a novel multi-modal\nfusion strategy named conditional attention fusion, which can dynamically pay\nattention to different modalities at each time step. Long-short term memory\nrecurrent neural networks (LSTM-RNN) is applied as the basic uni-modality model\nto capture long time dependencies. The weights assigned to different modalities\nare automatically decided by the current input features and recent history\ninformation rather than being fixed at any kinds of situation. Our experimental\nresults on a benchmark dataset AVEC2015 show the effectiveness of our method\nwhich outperforms several common fusion strategies for valence prediction.\n", "versions": [{"version": "v1", "created": "Mon, 4 Sep 2017 12:05:47 GMT"}], "update_date": "2017-09-08", "authors_parsed": [["Chen", "Shizhe", ""], ["Jin", "Qin", ""]]}, {"id": "1709.02253", "submitter": "Faxian Cao", "authors": "Faxian Cao, Zhijing Yang, Jinchang Ren, Mengying Jiang, Wing-Kuen Ling", "title": "Linear vs Nonlinear Extreme Learning Machine for Spectral-Spatial\n  Classification of Hyperspectral Image", "comments": "13 pages,8 figures,3 tables,article", "journal-ref": "Sensors,17,2017,2603", "doi": "10.3390/s17112603", "report-no": null, "categories": "cs.CV cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  As a new machine learning approach, extreme learning machine (ELM) has\nreceived wide attentions due to its good performances. However, when directly\napplied to the hyperspectral image (HSI) classification, the recognition rate\nis too low. This is because ELM does not use the spatial information which is\nvery important for HSI classification. In view of this, this paper proposes a\nnew framework for spectral-spatial classification of HSI by combining ELM with\nloopy belief propagation (LBP). The original ELM is linear, and the nonlinear\nELMs (or Kernel ELMs) are the improvement of linear ELM (LELM). However, based\non lots of experiments and analysis, we found out that the LELM is a better\nchoice than nonlinear ELM for spectral-spatial classification of HSI.\nFurthermore, we exploit the marginal probability distribution that uses the\nwhole information in the HSI and learn such distribution using the LBP. The\nproposed method not only maintain the fast speed of ELM, but also greatly\nimproves the accuracy of classification. The experimental results in the\nwell-known HSI data sets, Indian Pines and Pavia University, demonstrate the\ngood performances of the proposed method.\n", "versions": [{"version": "v1", "created": "Tue, 5 Sep 2017 06:53:02 GMT"}, {"version": "v2", "created": "Thu, 12 Oct 2017 02:16:40 GMT"}], "update_date": "2017-11-17", "authors_parsed": [["Cao", "Faxian", ""], ["Yang", "Zhijing", ""], ["Ren", "Jinchang", ""], ["Jiang", "Mengying", ""], ["Ling", "Wing-Kuen", ""]]}, {"id": "1709.02255", "submitter": "Yipeng Hu", "authors": "Yipeng Hu, Eli Gibson, Tom Vercauteren, Hashim U. Ahmed, Mark\n  Emberton, Caroline M. Moore, J. Alison Noble, Dean C. Barratt", "title": "Intraoperative Organ Motion Models with an Ensemble of Conditional\n  Generative Adversarial Networks", "comments": "Accepted to MICCAI 2017", "journal-ref": null, "doi": "10.1007/978-3-319-66185-8_42", "report-no": null, "categories": "cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we describe how a patient-specific, ultrasound-probe-induced\nprostate motion model can be directly generated from a single preoperative MR\nimage. Our motion model allows for sampling from the conditional distribution\nof dense displacement fields, is encoded by a generative neural network\nconditioned on a medical image, and accepts random noise as additional input.\nThe generative network is trained by a minimax optimisation with a second\ndiscriminative neural network, tasked to distinguish generated samples from\ntraining motion data. In this work, we propose that 1) jointly optimising a\nthird conditioning neural network that pre-processes the input image, can\neffectively extract patient-specific features for conditioning; and 2)\ncombining multiple generative models trained separately with heuristically\npre-disjointed training data sets can adequately mitigate the problem of mode\ncollapse. Trained with diagnostic T2-weighted MR images from 143 real patients\nand 73,216 3D dense displacement fields from finite element simulations of\nintraoperative prostate motion due to transrectal ultrasound probe pressure,\nthe proposed models produced physically-plausible patient-specific motion of\nprostate glands. The ability to capture biomechanically simulated motion was\nevaluated using two errors representing generalisability and specificity of the\nmodel. The median values, calculated from a 10-fold cross-validation, were\n2.8+/-0.3 mm and 1.7+/-0.1 mm, respectively. We conclude that the introduced\napproach demonstrates the feasibility of applying state-of-the-art machine\nlearning algorithms to generate organ motion models from patient images, and\nshows significant promise for future research.\n", "versions": [{"version": "v1", "created": "Tue, 5 Sep 2017 21:14:39 GMT"}], "update_date": "2017-09-08", "authors_parsed": [["Hu", "Yipeng", ""], ["Gibson", "Eli", ""], ["Vercauteren", "Tom", ""], ["Ahmed", "Hashim U.", ""], ["Emberton", "Mark", ""], ["Moore", "Caroline M.", ""], ["Noble", "J. Alison", ""], ["Barratt", "Dean C.", ""]]}, {"id": "1709.02260", "submitter": "Surat Teerapittayanon", "authors": "Bradley McDanel, Surat Teerapittayanon, H.T. Kung", "title": "Embedded Binarized Neural Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study embedded Binarized Neural Networks (eBNNs) with the aim of allowing\ncurrent binarized neural networks (BNNs) in the literature to perform\nfeedforward inference efficiently on small embedded devices. We focus on\nminimizing the required memory footprint, given that these devices often have\nmemory as small as tens of kilobytes (KB). Beyond minimizing the memory\nrequired to store weights, as in a BNN, we show that it is essential to\nminimize the memory used for temporaries which hold intermediate results\nbetween layers in feedforward inference. To accomplish this, eBNN reorders the\ncomputation of inference while preserving the original BNN structure, and uses\njust a single floating-point temporary for the entire neural network. All\nintermediate results from a layer are stored as binary values, as opposed to\nfloating-points used in current BNN implementations, leading to a 32x reduction\nin required temporary space. We provide empirical evidence that our proposed\neBNN approach allows efficient inference (10s of ms) on devices with severely\nlimited memory (10s of KB). For example, eBNN achieves 95\\% accuracy on the\nMNIST dataset running on an Intel Curie with only 15 KB of usable memory with\nan inference runtime of under 50 ms per sample. To ease the development of\napplications in embedded contexts, we make our source code available that\nallows users to train and discover eBNN models for a learning task at hand,\nwhich fit within the memory constraint of the target device.\n", "versions": [{"version": "v1", "created": "Wed, 6 Sep 2017 06:45:33 GMT"}], "update_date": "2017-09-08", "authors_parsed": [["McDanel", "Bradley", ""], ["Teerapittayanon", "Surat", ""], ["Kung", "H. T.", ""]]}, {"id": "1709.02268", "submitter": "Giuseppe Jurman", "authors": "Diego Fioravanti, Ylenia Giarratano, Valerio Maggio, Claudio\n  Agostinelli, Marco Chierici, Giuseppe Jurman and Cesare Furlanello", "title": "Phylogenetic Convolutional Neural Networks in Metagenomics", "comments": "Presented at BMTL 2017, Naples", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.QM cs.LG cs.NE q-bio.GN", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Background: Convolutional Neural Networks can be effectively used only when\ndata are endowed with an intrinsic concept of neighbourhood in the input space,\nas is the case of pixels in images. We introduce here Ph-CNN, a novel deep\nlearning architecture for the classification of metagenomics data based on the\nConvolutional Neural Networks, with the patristic distance defined on the\nphylogenetic tree being used as the proximity measure. The patristic distance\nbetween variables is used together with a sparsified version of\nMultiDimensional Scaling to embed the phylogenetic tree in a Euclidean space.\nResults: Ph-CNN is tested with a domain adaptation approach on synthetic data\nand on a metagenomics collection of gut microbiota of 38 healthy subjects and\n222 Inflammatory Bowel Disease patients, divided in 6 subclasses.\nClassification performance is promising when compared to classical algorithms\nlike Support Vector Machines and Random Forest and a baseline fully connected\nneural network, e.g. the Multi-Layer Perceptron. Conclusion: Ph-CNN represents\na novel deep learning approach for the classification of metagenomics data.\nOperatively, the algorithm has been implemented as a custom Keras layer taking\ncare of passing to the following convolutional layer not only the data but also\nthe ranked list of neighbourhood of each sample, thus mimicking the case of\nimage data, transparently to the user. Keywords: Metagenomics; Deep learning;\nConvolutional Neural Networks; Phylogenetic trees\n", "versions": [{"version": "v1", "created": "Wed, 6 Sep 2017 12:59:14 GMT"}], "update_date": "2017-09-08", "authors_parsed": [["Fioravanti", "Diego", ""], ["Giarratano", "Ylenia", ""], ["Maggio", "Valerio", ""], ["Agostinelli", "Claudio", ""], ["Chierici", "Marco", ""], ["Jurman", "Giuseppe", ""], ["Furlanello", "Cesare", ""]]}, {"id": "1709.02291", "submitter": "Monika Doerfler", "authors": "Monika Doerfler, Thomas Grill, Roswitha Bammer, Arthur Flexer", "title": "Basic Filters for Convolutional Neural Networks Applied to Music:\n  Training or Design?", "comments": "Completely revised version; 21 pages, 4 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.IR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  When convolutional neural networks are used to tackle learning problems based\non music or, more generally, time series data, raw one-dimensional data are\ncommonly pre-processed to obtain spectrogram or mel-spectrogram coefficients,\nwhich are then used as input to the actual neural network. In this\ncontribution, we investigate, both theoretically and experimentally, the\ninfluence of this pre-processing step on the network's performance and pose the\nquestion, whether replacing it by applying adaptive or learned filters directly\nto the raw data, can improve learning success. The theoretical results show\nthat approximately reproducing mel-spectrogram coefficients by applying\nadaptive filters and subsequent time-averaging is in principle possible. We\nalso conducted extensive experimental work on the task of singing voice\ndetection in music. The results of these experiments show that for\nclassification based on Convolutional Neural Networks the features obtained\nfrom adaptive filter banks followed by time-averaging perform better than the\ncanonical Fourier-transform-based mel-spectrogram coefficients. Alternative\nadaptive approaches with center frequencies or time-averaging lengths learned\nfrom training data perform equally well.\n", "versions": [{"version": "v1", "created": "Thu, 7 Sep 2017 14:51:37 GMT"}, {"version": "v2", "created": "Thu, 14 Dec 2017 11:25:18 GMT"}, {"version": "v3", "created": "Wed, 19 Sep 2018 14:30:19 GMT"}], "update_date": "2018-09-20", "authors_parsed": [["Doerfler", "Monika", ""], ["Grill", "Thomas", ""], ["Bammer", "Roswitha", ""], ["Flexer", "Arthur", ""]]}, {"id": "1709.02314", "submitter": "Daniel O\\~noro-Rubio", "authors": "Daniel O\\~noro-Rubio, Mathias Niepert, Alberto Garc\\'ia-Dur\\'an,\n  Roberto Gonz\\'alez and Roberto J. L\\'opez-Sastre", "title": "Answering Visual-Relational Queries in Web-Extracted Knowledge Graphs", "comments": null, "journal-ref": "AKBC2019", "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A visual-relational knowledge graph (KG) is a multi-relational graph whose\nentities are associated with images. We explore novel machine learning\napproaches for answering visual-relational queries in web-extracted knowledge\ngraphs. To this end, we have created ImageGraph, a KG with 1,330 relation\ntypes, 14,870 entities, and 829,931 images crawled from the web. With\nvisual-relational KGs such as ImageGraph one can introduce novel probabilistic\nquery types in which images are treated as first-class citizens. Both the\nprediction of relations between unseen images as well as multi-relational image\nretrieval can be expressed with specific families of visual-relational queries.\nWe introduce novel combinations of convolutional networks and knowledge graph\nembedding methods to answer such queries. We also explore a zero-shot learning\nscenario where an image of an entirely new entity is linked with multiple\nrelations to entities of an existing KG. The resulting multi-relational\ngrounding of unseen entity images into a knowledge graph serves as a semantic\nentity representation. We conduct experiments to demonstrate that the proposed\nmethods can answer these visual-relational queries efficiently and accurately.\n", "versions": [{"version": "v1", "created": "Thu, 7 Sep 2017 15:31:54 GMT"}, {"version": "v2", "created": "Mon, 11 Sep 2017 16:41:07 GMT"}, {"version": "v3", "created": "Tue, 21 Nov 2017 10:38:13 GMT"}, {"version": "v4", "created": "Thu, 15 Mar 2018 09:44:51 GMT"}, {"version": "v5", "created": "Sat, 31 Mar 2018 08:37:45 GMT"}, {"version": "v6", "created": "Fri, 3 May 2019 10:09:09 GMT"}], "update_date": "2019-05-06", "authors_parsed": [["O\u00f1oro-Rubio", "Daniel", ""], ["Niepert", "Mathias", ""], ["Garc\u00eda-Dur\u00e1n", "Alberto", ""], ["Gonz\u00e1lez", "Roberto", ""], ["L\u00f3pez-Sastre", "Roberto J.", ""]]}, {"id": "1709.02327", "submitter": "Claudio Reggiani", "authors": "Claudio Reggiani, Yann-A\\\"el Le Borgne, Gianluca Bontempi", "title": "Feature selection in high-dimensional dataset using MapReduce", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper describes a distributed MapReduce implementation of the minimum\nRedundancy Maximum Relevance algorithm, a popular feature selection method in\nbioinformatics and network inference problems. The proposed approach handles\nboth tall/narrow and wide/short datasets. We further provide an open source\nimplementation based on Hadoop/Spark, and illustrate its scalability on\ndatasets involving millions of observations or features.\n", "versions": [{"version": "v1", "created": "Thu, 7 Sep 2017 16:05:51 GMT"}], "update_date": "2017-09-08", "authors_parsed": [["Reggiani", "Claudio", ""], ["Borgne", "Yann-A\u00ebl Le", ""], ["Bontempi", "Gianluca", ""]]}, {"id": "1709.02349", "submitter": "Iulian Vlad Serban", "authors": "Iulian V. Serban, Chinnadhurai Sankar, Mathieu Germain, Saizheng\n  Zhang, Zhouhan Lin, Sandeep Subramanian, Taesup Kim, Michael Pieper, Sarath\n  Chandar, Nan Rosemary Ke, Sai Rajeshwar, Alexandre de Brebisson, Jose M. R.\n  Sotelo, Dendi Suhubdy, Vincent Michalski, Alexandre Nguyen, Joelle Pineau,\n  Yoshua Bengio", "title": "A Deep Reinforcement Learning Chatbot", "comments": "40 pages, 9 figures, 11 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present MILABOT: a deep reinforcement learning chatbot developed by the\nMontreal Institute for Learning Algorithms (MILA) for the Amazon Alexa Prize\ncompetition. MILABOT is capable of conversing with humans on popular small talk\ntopics through both speech and text. The system consists of an ensemble of\nnatural language generation and retrieval models, including template-based\nmodels, bag-of-words models, sequence-to-sequence neural network and latent\nvariable neural network models. By applying reinforcement learning to\ncrowdsourced data and real-world user interactions, the system has been trained\nto select an appropriate response from the models in its ensemble. The system\nhas been evaluated through A/B testing with real-world users, where it\nperformed significantly better than many competing systems. Due to its machine\nlearning architecture, the system is likely to improve with additional data.\n", "versions": [{"version": "v1", "created": "Thu, 7 Sep 2017 16:51:09 GMT"}, {"version": "v2", "created": "Sun, 5 Nov 2017 21:02:57 GMT"}], "update_date": "2017-11-07", "authors_parsed": [["Serban", "Iulian V.", ""], ["Sankar", "Chinnadhurai", ""], ["Germain", "Mathieu", ""], ["Zhang", "Saizheng", ""], ["Lin", "Zhouhan", ""], ["Subramanian", "Sandeep", ""], ["Kim", "Taesup", ""], ["Pieper", "Michael", ""], ["Chandar", "Sarath", ""], ["Ke", "Nan Rosemary", ""], ["Rajeshwar", "Sai", ""], ["de Brebisson", "Alexandre", ""], ["Sotelo", "Jose M. R.", ""], ["Suhubdy", "Dendi", ""], ["Michalski", "Vincent", ""], ["Nguyen", "Alexandre", ""], ["Pineau", "Joelle", ""], ["Bengio", "Yoshua", ""]]}, {"id": "1709.02373", "submitter": "Salaheddin Alakkari", "authors": "Salaheddin Alakkari and John Dingliana", "title": "Adaptive PCA for Time-Varying Data", "comments": "Typos fixed, uncited references removed", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we present an online adaptive PCA algorithm that is able to\ncompute the full dimensional eigenspace per new time-step of sequential data.\nThe algorithm is based on a one-step update rule that considers all second\norder correlations between previous samples and the new time-step. Our\nalgorithm has O(n) complexity per new time-step in its deterministic mode and\nO(1) complexity per new time-step in its stochastic mode. We test our algorithm\non a number of time-varying datasets of different physical phenomena. Explained\nvariance curves indicate that our technique provides an excellent approximation\nto the original eigenspace computed using standard PCA in batch mode. In\naddition, our experiments show that the stochastic mode, despite its much lower\ncomputational complexity, converges to the same eigenspace computed using the\ndeterministic mode.\n", "versions": [{"version": "v1", "created": "Thu, 7 Sep 2017 17:49:47 GMT"}, {"version": "v2", "created": "Tue, 12 Sep 2017 15:55:44 GMT"}], "update_date": "2017-09-13", "authors_parsed": [["Alakkari", "Salaheddin", ""], ["Dingliana", "John", ""]]}, {"id": "1709.02418", "submitter": "Jacob Whitehill", "authors": "Jacob Whitehill", "title": "How Does Knowledge of the AUC Constrain the Set of Possible Ground-truth\n  Labelings?", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent work on privacy-preserving machine learning has considered how\ndata-mining competitions such as Kaggle could potentially be \"hacked\", either\nintentionally or inadvertently, by using information from an oracle that\nreports a classifier's accuracy on the test set. For binary classification\ntasks in particular, one of the most common accuracy metrics is the Area Under\nthe ROC Curve (AUC), and in this paper we explore the mathematical structure of\nhow the AUC is computed from an n-vector of real-valued \"guesses\" with respect\nto the ground-truth labels. We show how knowledge of a classifier's AUC on the\ntest set can constrain the set of possible ground-truth labelings, and we\nderive an algorithm both to compute the exact number of such labelings and to\nenumerate efficiently over them. Finally, we provide empirical evidence that,\nsurprisingly, the number of compatible labelings can actually decrease as n\ngrows, until a test set-dependent threshold is reached.\n", "versions": [{"version": "v1", "created": "Thu, 7 Sep 2017 19:30:57 GMT"}, {"version": "v2", "created": "Mon, 11 Sep 2017 15:11:28 GMT"}], "update_date": "2017-09-12", "authors_parsed": [["Whitehill", "Jacob", ""]]}, {"id": "1709.02432", "submitter": "Joseph Gomes", "authors": "Amir Barati Farimani, Joseph Gomes, and Vijay S. Pande", "title": "Deep Learning the Physics of Transport Phenomena", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG physics.comp-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We have developed a new data-driven paradigm for the rapid inference,\nmodeling and simulation of the physics of transport phenomena by deep learning.\nUsing conditional generative adversarial networks (cGAN), we train models for\nthe direct generation of solutions to steady state heat conduction and\nincompressible fluid flow purely on observation without knowledge of the\nunderlying governing equations. Rather than using iterative numerical methods\nto approximate the solution of the constitutive equations, cGANs learn to\ndirectly generate the solutions to these phenomena, given arbitrary boundary\nconditions and domain, with high test accuracy (MAE$<$1\\%) and state-of-the-art\ncomputational performance. The cGAN framework can be used to learn causal\nmodels directly from experimental observations where the underlying physical\nmodel is complex or unknown.\n", "versions": [{"version": "v1", "created": "Thu, 7 Sep 2017 19:57:26 GMT"}], "update_date": "2017-09-11", "authors_parsed": [["Farimani", "Amir Barati", ""], ["Gomes", "Joseph", ""], ["Pande", "Vijay S.", ""]]}, {"id": "1709.02435", "submitter": "Rick Salay", "authors": "Rick Salay, Rodrigo Queiroz, Krzysztof Czarnecki", "title": "An Analysis of ISO 26262: Using Machine Learning Safely in Automotive\n  Software", "comments": "6 pages, 3 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG cs.SE cs.SY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Machine learning (ML) plays an ever-increasing role in advanced automotive\nfunctionality for driver assistance and autonomous operation; however, its\nadequacy from the perspective of safety certification remains controversial. In\nthis paper, we analyze the impacts that the use of ML as an implementation\napproach has on ISO 26262 safety lifecycle and ask what could be done to\naddress them. We then provide a set of recommendations on how to adapt the\nstandard to accommodate ML.\n", "versions": [{"version": "v1", "created": "Thu, 7 Sep 2017 20:10:56 GMT"}], "update_date": "2017-09-11", "authors_parsed": [["Salay", "Rick", ""], ["Queiroz", "Rodrigo", ""], ["Czarnecki", "Krzysztof", ""]]}, {"id": "1709.02448", "submitter": "Hao Wu", "authors": "Hao Wu, Kristina Lerman", "title": "Network Vector: Distributed Representations of Networks with Global\n  Context", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a neural embedding algorithm called Network Vector, which learns\ndistributed representations of nodes and the entire networks simultaneously. By\nembedding networks in a low-dimensional space, the algorithm allows us to\ncompare networks in terms of structural similarity and to solve outstanding\npredictive problems. Unlike alternative approaches that focus on node level\nfeatures, we learn a continuous global vector that captures each node's global\ncontext by maximizing the predictive likelihood of random walk paths in the\nnetwork. Our algorithm is scalable to real world graphs with many nodes. We\nevaluate our algorithm on datasets from diverse domains, and compare it with\nstate-of-the-art techniques in node classification, role discovery and concept\nanalogy tasks. The empirical results show the effectiveness and the efficiency\nof our algorithm.\n", "versions": [{"version": "v1", "created": "Thu, 7 Sep 2017 20:51:27 GMT"}], "update_date": "2017-09-11", "authors_parsed": [["Wu", "Hao", ""], ["Lerman", "Kristina", ""]]}, {"id": "1709.02457", "submitter": "Ali Pesaranghader", "authors": "Ali Pesaranghader, Herna Viktor and Eric Paquet", "title": "Reservoir of Diverse Adaptive Learners and Stacking Fast Hoeffding Drift\n  Detection Methods for Evolving Data Streams", "comments": "42 pages, and 14 figures", "journal-ref": null, "doi": "10.1007/s10994-018-5719-z", "report-no": null, "categories": "stat.ML cs.DB cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The last decade has seen a surge of interest in adaptive learning algorithms\nfor data stream classification, with applications ranging from predicting ozone\nlevel peaks, learning stock market indicators, to detecting computer security\nviolations. In addition, a number of methods have been developed to detect\nconcept drifts in these streams. Consider a scenario where we have a number of\nclassifiers with diverse learning styles and different drift detectors.\nIntuitively, the current 'best' (classifier, detector) pair is application\ndependent and may change as a result of the stream evolution. Our research\nbuilds on this observation. We introduce the $\\mbox{Tornado}$ framework that\nimplements a reservoir of diverse classifiers, together with a variety of drift\ndetection algorithms. In our framework, all (classifier, detector) pairs\nproceed, in parallel, to construct models against the evolving data streams. At\nany point in time, we select the pair which currently yields the best\nperformance. We further incorporate two novel stacking-based drift detection\nmethods, namely the $\\mbox{FHDDMS}$ and $\\mbox{FHDDMS}_{add}$ approaches. The\nexperimental evaluation confirms that the current 'best' (classifier, detector)\npair is not only heavily dependent on the characteristics of the stream, but\nalso that this selection evolves as the stream flows. Further, our\n$\\mbox{FHDDMS}$ variants detect concept drifts accurately in a timely fashion\nwhile outperforming the state-of-the-art.\n", "versions": [{"version": "v1", "created": "Thu, 7 Sep 2017 21:19:24 GMT"}], "update_date": "2018-08-13", "authors_parsed": [["Pesaranghader", "Ali", ""], ["Viktor", "Herna", ""], ["Paquet", "Eric", ""]]}, {"id": "1709.02477", "submitter": "Bryan He", "authors": "Paroma Varma, Bryan He, Payal Bajaj, Imon Banerjee, Nishith Khandwala,\n  Daniel L. Rubin, Christopher R\\'e", "title": "Inferring Generative Model Structure with Static Analysis", "comments": "NIPS 2017", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Obtaining enough labeled data to robustly train complex discriminative models\nis a major bottleneck in the machine learning pipeline. A popular solution is\ncombining multiple sources of weak supervision using generative models. The\nstructure of these models affects training label quality, but is difficult to\nlearn without any ground truth labels. We instead rely on these weak\nsupervision sources having some structure by virtue of being encoded\nprogrammatically. We present Coral, a paradigm that infers generative model\nstructure by statically analyzing the code for these heuristics, thus reducing\nthe data required to learn structure significantly. We prove that Coral's\nsample complexity scales quasilinearly with the number of heuristics and number\nof relations found, improving over the standard sample complexity, which is\nexponential in $n$ for identifying $n^{\\textrm{th}}$ degree relations.\nExperimentally, Coral matches or outperforms traditional structure learning\napproaches by up to 3.81 F1 points. Using Coral to model dependencies instead\nof assuming independence results in better performance than a fully supervised\nmodel by 3.07 accuracy points when heuristics are used to label radiology data\nwithout ground truth labels.\n", "versions": [{"version": "v1", "created": "Thu, 7 Sep 2017 22:33:37 GMT"}], "update_date": "2017-09-11", "authors_parsed": [["Varma", "Paroma", ""], ["He", "Bryan", ""], ["Bajaj", "Payal", ""], ["Banerjee", "Imon", ""], ["Khandwala", "Nishith", ""], ["Rubin", "Daniel L.", ""], ["R\u00e9", "Christopher", ""]]}, {"id": "1709.02535", "submitter": "Shiro Yano", "authors": "Megumi Miyashita, Shiro Yano, Toshiyuki Kondo", "title": "Mirror Descent Search and its Acceleration", "comments": "Gold open access in Journal of Robotics and Autonomous Systems:\n  https://www.sciencedirect.com/science/article/pii/S0921889017307546", "journal-ref": null, "doi": "10.1016/j.robot.2018.04.009", "report-no": null, "categories": "cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In recent years, attention has been focused on the relationship between\nblack-box optimiza- tion problem and reinforcement learning problem. In this\nresearch, we propose the Mirror Descent Search (MDS) algorithm which is\napplicable both for black box optimization prob- lems and reinforcement\nlearning problems. Our method is based on the mirror descent method, which is a\ngeneral optimization algorithm. The contribution of this research is roughly\ntwofold. We propose two essential algorithms, called MDS and Accelerated Mirror\nDescent Search (AMDS), and two more approximate algorithms: Gaussian Mirror\nDescent Search (G-MDS) and Gaussian Accelerated Mirror Descent Search (G-AMDS).\nThis re- search shows that the advanced methods developed in the context of the\nmirror descent research can be applied to reinforcement learning problem. We\nalso clarify the relationship between an existing reinforcement learning\nalgorithm and our method. With two evaluation experiments, we show our proposed\nalgorithms converge faster than some state-of-the-art methods.\n", "versions": [{"version": "v1", "created": "Fri, 8 Sep 2017 04:43:48 GMT"}, {"version": "v2", "created": "Sat, 12 May 2018 09:04:21 GMT"}], "update_date": "2018-05-15", "authors_parsed": [["Miyashita", "Megumi", ""], ["Yano", "Shiro", ""], ["Kondo", "Toshiyuki", ""]]}, {"id": "1709.02538", "submitter": "Bita Darvish Rouhani", "authors": "Bita Darvish Rouhani, Mohammad Samragh, Mojan Javaheripi, Tara Javidi,\n  Farinaz Koushanfar", "title": "DeepFense: Online Accelerated Defense Against Adversarial Deep Learning", "comments": "Adding hardware acceleration for real-time execution of defender\n  modules", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent advances in adversarial Deep Learning (DL) have opened up a largely\nunexplored surface for malicious attacks jeopardizing the integrity of\nautonomous DL systems. With the wide-spread usage of DL in critical and\ntime-sensitive applications, including unmanned vehicles, drones, and video\nsurveillance systems, online detection of malicious inputs is of utmost\nimportance. We propose DeepFense, the first end-to-end automated framework that\nsimultaneously enables efficient and safe execution of DL models. DeepFense\nformalizes the goal of thwarting adversarial attacks as an optimization problem\nthat minimizes the rarely observed regions in the latent feature space spanned\nby a DL network. To solve the aforementioned minimization problem, a set of\ncomplementary but disjoint modular redundancies are trained to validate the\nlegitimacy of the input samples in parallel with the victim DL model. DeepFense\nleverages hardware/software/algorithm co-design and customized acceleration to\nachieve just-in-time performance in resource-constrained settings. The proposed\ncountermeasure is unsupervised, meaning that no adversarial sample is leveraged\nto train modular redundancies. We further provide an accompanying API to reduce\nthe non-recurring engineering cost and ensure automated adaptation to various\nplatforms. Extensive evaluations on FPGAs and GPUs demonstrate up to two orders\nof magnitude performance improvement while enabling online adversarial sample\ndetection.\n", "versions": [{"version": "v1", "created": "Fri, 8 Sep 2017 04:53:51 GMT"}, {"version": "v2", "created": "Fri, 22 Dec 2017 01:37:12 GMT"}, {"version": "v3", "created": "Sun, 1 Apr 2018 18:30:00 GMT"}, {"version": "v4", "created": "Tue, 21 Aug 2018 02:54:23 GMT"}], "update_date": "2018-08-22", "authors_parsed": [["Rouhani", "Bita Darvish", ""], ["Samragh", "Mohammad", ""], ["Javaheripi", "Mojan", ""], ["Javidi", "Tara", ""], ["Koushanfar", "Farinaz", ""]]}, {"id": "1709.02540", "submitter": "Zhou Lu", "authors": "Zhou Lu, Hongming Pu, Feicheng Wang, Zhiqiang Hu, Liwei Wang", "title": "The Expressive Power of Neural Networks: A View from the Width", "comments": "accepted by NIPS 2017 ( with some typos fixed)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The expressive power of neural networks is important for understanding deep\nlearning. Most existing works consider this problem from the view of the depth\nof a network. In this paper, we study how width affects the expressiveness of\nneural networks. Classical results state that depth-bounded (e.g. depth-$2$)\nnetworks with suitable activation functions are universal approximators. We\nshow a universal approximation theorem for width-bounded ReLU networks:\nwidth-$(n+4)$ ReLU networks, where $n$ is the input dimension, are universal\napproximators. Moreover, except for a measure zero set, all functions cannot be\napproximated by width-$n$ ReLU networks, which exhibits a phase transition.\nSeveral recent works demonstrate the benefits of depth by proving the\ndepth-efficiency of neural networks. That is, there are classes of deep\nnetworks which cannot be realized by any shallow network whose size is no more\nthan an exponential bound. Here we pose the dual question on the\nwidth-efficiency of ReLU networks: Are there wide networks that cannot be\nrealized by narrow networks whose size is not substantially larger? We show\nthat there exist classes of wide networks which cannot be realized by any\nnarrow network whose depth is no more than a polynomial bound. On the other\nhand, we demonstrate by extensive experiments that narrow networks whose size\nexceed the polynomial bound by a constant factor can approximate wide and\nshallow network with high accuracy. Our results provide more comprehensive\nevidence that depth is more effective than width for the expressiveness of ReLU\nnetworks.\n", "versions": [{"version": "v1", "created": "Fri, 8 Sep 2017 05:00:20 GMT"}, {"version": "v2", "created": "Thu, 28 Sep 2017 01:28:09 GMT"}, {"version": "v3", "created": "Wed, 1 Nov 2017 08:50:32 GMT"}], "update_date": "2017-11-02", "authors_parsed": [["Lu", "Zhou", ""], ["Pu", "Hongming", ""], ["Wang", "Feicheng", ""], ["Hu", "Zhiqiang", ""], ["Wang", "Liwei", ""]]}, {"id": "1709.02555", "submitter": "EPTCS", "authors": "Takumi Akazaki (1), Yoshihiro Kumazawa (1), Ichiro Hasuo (2) ((1)\n  University of Tokyo, (2) National Institute of Informatics)", "title": "Causality-Aided Falsification", "comments": "In Proceedings FVAV 2017, arXiv:1709.02126", "journal-ref": "EPTCS 257, 2017, pp. 3-18", "doi": "10.4204/EPTCS.257.2", "report-no": null, "categories": "cs.SY cs.AI cs.LG cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Falsification is drawing attention in quality assurance of heterogeneous\nsystems whose complexities are beyond most verification techniques'\nscalability. In this paper we introduce the idea of causality aid in\nfalsification: by providing a falsification solver -- that relies on stochastic\noptimization of a certain cost function -- with suitable causal information\nexpressed by a Bayesian network, search for a falsifying input value can be\nefficient. Our experiment results show the idea's viability.\n", "versions": [{"version": "v1", "created": "Fri, 8 Sep 2017 06:34:21 GMT"}], "update_date": "2017-09-11", "authors_parsed": [["Akazaki", "Takumi", ""], ["Kumazawa", "Yoshihiro", ""], ["Hasuo", "Ichiro", ""]]}, {"id": "1709.02576", "submitter": "Chang Min Hyun", "authors": "Chang Min Hyun, Hwa Pyung Kim, Sung Min Lee, Sungchul Lee and Jin Keun\n  Seo", "title": "Deep learning for undersampled MRI reconstruction", "comments": null, "journal-ref": null, "doi": "10.1088/1361-6560/aac71a", "report-no": null, "categories": "stat.ML cs.LG physics.med-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper presents a deep learning method for faster magnetic resonance\nimaging (MRI) by reducing k-space data with sub-Nyquist sampling strategies and\nprovides a rationale for why the proposed approach works well. Uniform\nsubsampling is used in the time-consuming phase-encoding direction to capture\nhigh-resolution image information, while permitting the image-folding problem\ndictated by the Poisson summation formula. To deal with the localization\nuncertainty due to image folding, very few low-frequency k-space data are\nadded. Training the deep learning net involves input and output images that are\npairs of Fourier transforms of the subsampled and fully sampled k-space data.\nNumerous experiments show the remarkable performance of the proposed method;\nonly 29% of k-space data can generate images of high quality as effectively as\nstandard MRI reconstruction with fully sampled data.\n", "versions": [{"version": "v1", "created": "Fri, 8 Sep 2017 07:35:58 GMT"}, {"version": "v2", "created": "Mon, 11 Sep 2017 00:38:47 GMT"}, {"version": "v3", "created": "Sun, 12 May 2019 12:47:06 GMT"}], "update_date": "2019-05-14", "authors_parsed": [["Hyun", "Chang Min", ""], ["Kim", "Hwa Pyung", ""], ["Lee", "Sung Min", ""], ["Lee", "Sungchul", ""], ["Seo", "Jin Keun", ""]]}, {"id": "1709.02605", "submitter": "Tri Dao", "authors": "Tri Dao, Christopher De Sa, Christopher R\\'e", "title": "Gaussian Quadrature for Kernel Features", "comments": "Neural Information Processing Systems (NIPS) 2017", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Kernel methods have recently attracted resurgent interest, showing\nperformance competitive with deep neural networks in tasks such as speech\nrecognition. The random Fourier features map is a technique commonly used to\nscale up kernel machines, but employing the randomized feature map means that\n$O(\\epsilon^{-2})$ samples are required to achieve an approximation error of at\nmost $\\epsilon$. We investigate some alternative schemes for constructing\nfeature maps that are deterministic, rather than random, by approximating the\nkernel in the frequency domain using Gaussian quadrature. We show that\ndeterministic feature maps can be constructed, for any $\\gamma > 0$, to achieve\nerror $\\epsilon$ with $O(e^{e^\\gamma} + \\epsilon^{-1/\\gamma})$ samples as\n$\\epsilon$ goes to 0. Our method works particularly well with sparse ANOVA\nkernels, which are inspired by the convolutional layer of CNNs. We validate our\nmethods on datasets in different domains, such as MNIST and TIMIT, showing that\ndeterministic features are faster to generate and achieve accuracy comparable\nto the state-of-the-art kernel methods based on random Fourier features.\n", "versions": [{"version": "v1", "created": "Fri, 8 Sep 2017 09:17:59 GMT"}, {"version": "v2", "created": "Sun, 5 Nov 2017 02:33:36 GMT"}, {"version": "v3", "created": "Wed, 31 Jan 2018 06:16:31 GMT"}], "update_date": "2018-02-01", "authors_parsed": [["Dao", "Tri", ""], ["De Sa", "Christopher", ""], ["R\u00e9", "Christopher", ""]]}, {"id": "1709.02656", "submitter": "Mahdi Jafari Siavoshani", "authors": "Mohammad Lotfollahi, Ramin Shirali Hossein Zade, Mahdi Jafari\n  Siavoshani, Mohammdsadegh Saberian", "title": "Deep Packet: A Novel Approach For Encrypted Traffic Classification Using\n  Deep Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Internet traffic classification has become more important with rapid growth\nof current Internet network and online applications. There have been numerous\nstudies on this topic which have led to many different approaches. Most of\nthese approaches use predefined features extracted by an expert in order to\nclassify network traffic. In contrast, in this study, we propose a \\emph{deep\nlearning} based approach which integrates both feature extraction and\nclassification phases into one system. Our proposed scheme, called \"Deep\nPacket,\" can handle both \\emph{traffic characterization} in which the network\ntraffic is categorized into major classes (\\eg, FTP and P2P) and application\nidentification in which end-user applications (\\eg, BitTorrent and Skype)\nidentification is desired. Contrary to most of the current methods, Deep Packet\ncan identify encrypted traffic and also distinguishes between VPN and non-VPN\nnetwork traffic. After an initial pre-processing phase on data, packets are fed\ninto Deep Packet framework that embeds stacked autoencoder and convolution\nneural network in order to classify network traffic. Deep packet with CNN as\nits classification model achieved recall of $0.98$ in application\nidentification task and $0.94$ in traffic categorization task. To the best of\nour knowledge, Deep Packet outperforms all of the proposed classification\nmethods on UNB ISCX VPN-nonVPN dataset.\n", "versions": [{"version": "v1", "created": "Fri, 8 Sep 2017 11:40:37 GMT"}, {"version": "v2", "created": "Sun, 24 Sep 2017 12:13:18 GMT"}, {"version": "v3", "created": "Wed, 4 Jul 2018 07:54:04 GMT"}], "update_date": "2018-07-05", "authors_parsed": [["Lotfollahi", "Mohammad", ""], ["Zade", "Ramin Shirali Hossein", ""], ["Siavoshani", "Mahdi Jafari", ""], ["Saberian", "Mohammdsadegh", ""]]}, {"id": "1709.02664", "submitter": "Kechao Cai", "authors": "Kechao Cai, Kun Chen, Longbo Huang, John C.S. Lui", "title": "Multi-level Feedback Web Links Selection Problem: Learning and\n  Optimization", "comments": "8 pages (with full proof), 4 figures, ICDM 2017 technical report", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Selecting the right web links for a website is important because appropriate\nlinks not only can provide high attractiveness but can also increase the\nwebsite's revenue. In this work, we first show that web links have an intrinsic\n\\emph{multi-level feedback structure}. For example, consider a $2$-level\nfeedback web link: the $1$st level feedback provides the Click-Through Rate\n(CTR) and the $2$nd level feedback provides the potential revenue, which\ncollectively produce the compound $2$-level revenue. We consider the\ncontext-free links selection problem of selecting links for a homepage so as to\nmaximize the total compound $2$-level revenue while keeping the total $1$st\nlevel feedback above a preset threshold. We further generalize the problem to\nlinks with $n~(n\\ge2)$-level feedback structure. The key challenge is that the\nlinks' multi-level feedback structures are unobservable unless the links are\nselected on the homepage. To our best knowledge, we are the first to model the\nlinks selection problem as a constrained multi-armed bandit problem and design\nan effective links selection algorithm by learning the links' multi-level\nstructure with provable \\emph{sub-linear} regret and violation bounds. We\nuncover the multi-level feedback structures of web links in two real-world\ndatasets. We also conduct extensive experiments on the datasets to compare our\nproposed \\textbf{LExp} algorithm with two state-of-the-art context-free bandit\nalgorithms and show that \\textbf{LExp} algorithm is the most effective in links\nselection while satisfying the constraint.\n", "versions": [{"version": "v1", "created": "Fri, 8 Sep 2017 11:55:00 GMT"}], "update_date": "2017-09-11", "authors_parsed": [["Cai", "Kechao", ""], ["Chen", "Kun", ""], ["Huang", "Longbo", ""], ["Lui", "John C. S.", ""]]}, {"id": "1709.02707", "submitter": "Weihao Kong", "authors": "Kevin Tian, Weihao Kong, Gregory Valiant", "title": "Learning Populations of Parameters", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Consider the following estimation problem: there are $n$ entities, each with\nan unknown parameter $p_i \\in [0,1]$, and we observe $n$ independent random\nvariables, $X_1,\\ldots,X_n$, with $X_i \\sim $ Binomial$(t, p_i)$. How\naccurately can one recover the \"histogram\" (i.e. cumulative density function)\nof the $p_i$'s? While the empirical estimates would recover the histogram to\nearth mover distance $\\Theta(\\frac{1}{\\sqrt{t}})$ (equivalently, $\\ell_1$\ndistance between the CDFs), we show that, provided $n$ is sufficiently large,\nwe can achieve error $O(\\frac{1}{t})$ which is information theoretically\noptimal. We also extend our results to the multi-dimensional parameter case,\ncapturing settings where each member of the population has multiple associated\nparameters. Beyond the theoretical results, we demonstrate that the recovery\nalgorithm performs well in practice on a variety of datasets, providing\nilluminating insights into several domains, including politics, sports\nanalytics, and variation in the gender ratio of offspring.\n", "versions": [{"version": "v1", "created": "Fri, 8 Sep 2017 13:53:26 GMT"}, {"version": "v2", "created": "Wed, 22 Nov 2017 06:07:44 GMT"}], "update_date": "2017-11-23", "authors_parsed": [["Tian", "Kevin", ""], ["Kong", "Weihao", ""], ["Valiant", "Gregory", ""]]}, {"id": "1709.02726", "submitter": "Pooria Joulani", "authors": "Pooria Joulani, Andr\\'as Gy\\\"orgy, Csaba Szepesv\\'ari", "title": "A Modular Analysis of Adaptive (Non-)Convex Optimization: Optimism,\n  Composite Objectives, and Variational Bounds", "comments": "Accepted to The 28th International Conference on Algorithmic Learning\n  Theory (ALT 2017). 40 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG math.OC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recently, much work has been done on extending the scope of online learning\nand incremental stochastic optimization algorithms. In this paper we contribute\nto this effort in two ways: First, based on a new regret decomposition and a\ngeneralization of Bregman divergences, we provide a self-contained, modular\nanalysis of the two workhorses of online learning: (general) adaptive versions\nof Mirror Descent (MD) and the Follow-the-Regularized-Leader (FTRL) algorithms.\nThe analysis is done with extra care so as not to introduce assumptions not\nneeded in the proofs and allows to combine, in a straightforward way, different\nalgorithmic ideas (e.g., adaptivity, optimism, implicit updates) and learning\nsettings (e.g., strongly convex or composite objectives). This way we are able\nto reprove, extend and refine a large body of the literature, while keeping the\nproofs concise. The second contribution is a byproduct of this careful\nanalysis: We present algorithms with improved variational bounds for smooth,\ncomposite objectives, including a new family of optimistic MD algorithms with\nonly one projection step per round. Furthermore, we provide a simple extension\nof adaptive regret bounds to practically relevant non-convex problem settings\nwith essentially no extra effort.\n", "versions": [{"version": "v1", "created": "Fri, 8 Sep 2017 14:54:44 GMT"}], "update_date": "2017-09-12", "authors_parsed": [["Joulani", "Pooria", ""], ["Gy\u00f6rgy", "Andr\u00e1s", ""], ["Szepesv\u00e1ri", "Csaba", ""]]}, {"id": "1709.02738", "submitter": "Panayotis Mertikopoulos", "authors": "Panayotis Mertikopoulos, Christos Papadimitriou and Georgios Piliouras", "title": "Cycles in adversarial regularized learning", "comments": "22 pages, 4 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.GT cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Regularized learning is a fundamental technique in online optimization,\nmachine learning and many other fields of computer science. A natural question\nthat arises in these settings is how regularized learning algorithms behave\nwhen faced against each other. We study a natural formulation of this problem\nby coupling regularized learning dynamics in zero-sum games. We show that the\nsystem's behavior is Poincar\\'e recurrent, implying that almost every\ntrajectory revisits any (arbitrarily small) neighborhood of its starting point\ninfinitely often. This cycling behavior is robust to the agents' choice of\nregularization mechanism (each agent could be using a different regularizer),\nto positive-affine transformations of the agents' utilities, and it also\npersists in the case of networked competition, i.e., for zero-sum polymatrix\ngames.\n", "versions": [{"version": "v1", "created": "Fri, 8 Sep 2017 15:16:54 GMT"}], "update_date": "2017-09-11", "authors_parsed": [["Mertikopoulos", "Panayotis", ""], ["Papadimitriou", "Christos", ""], ["Piliouras", "Georgios", ""]]}, {"id": "1709.02753", "submitter": "Aleksandra Korolova", "authors": "Jun Tang, Aleksandra Korolova, Xiaolong Bai, Xueqiang Wang, Xiaofeng\n  Wang", "title": "Privacy Loss in Apple's Implementation of Differential Privacy on MacOS\n  10.12", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.CY cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In June 2016, Apple announced that it will deploy differential privacy for\nsome user data collection in order to ensure privacy of user data, even from\nApple. The details of Apple's approach remained sparse. Although several\npatents have since appeared hinting at the algorithms that may be used to\nachieve differential privacy, they did not include a precise explanation of the\napproach taken to privacy parameter choice. Such choice and the overall\napproach to privacy budget use and management are key questions for\nunderstanding the privacy protections provided by any deployment of\ndifferential privacy.\n  In this work, through a combination of experiments, static and dynamic code\nanalysis of macOS Sierra (Version 10.12) implementation, we shed light on the\nchoices Apple made for privacy budget management. We discover and describe\nApple's set-up for differentially private data processing, including the\noverall data pipeline, the parameters used for differentially private\nperturbation of each piece of data, and the frequency with which such data is\nsent to Apple's servers.\n  We find that although Apple's deployment ensures that the (differential)\nprivacy loss per each datum submitted to its servers is $1$ or $2$, the overall\nprivacy loss permitted by the system is significantly higher, as high as $16$\nper day for the four initially announced applications of Emojis, New words,\nDeeplinks and Lookup Hints. Furthermore, Apple renews the privacy budget\navailable every day, which leads to a possible privacy loss of 16 times the\nnumber of days since user opt-in to differentially private data collection for\nthose four applications.\n  We advocate that in order to claim the full benefits of differentially\nprivate data collection, Apple must give full transparency of its\nimplementation, enable user choice in areas related to privacy loss, and set\nmeaningful defaults on the privacy loss permitted.\n", "versions": [{"version": "v1", "created": "Fri, 8 Sep 2017 16:00:14 GMT"}, {"version": "v2", "created": "Mon, 11 Sep 2017 05:18:29 GMT"}], "update_date": "2017-09-12", "authors_parsed": [["Tang", "Jun", ""], ["Korolova", "Aleksandra", ""], ["Bai", "Xiaolong", ""], ["Wang", "Xueqiang", ""], ["Wang", "Xiaofeng", ""]]}, {"id": "1709.02759", "submitter": "Pedro Almagro-Blanco", "authors": "Pedro Almagro-Blanco, Fernando Sancho-Caparrini", "title": "Semantic Preserving Embeddings for Generalized Graphs", "comments": "Multi-lingual Paper. Main language: English. Additional Language:\n  Spanish. 15 Figures. English: 28 pages. Spanish: 32 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A new approach to the study of Generalized Graphs as semantic data structures\nusing machine learning techniques is presented. We show how vector\nrepresentations maintaining semantic characteristics of the original data can\nbe obtained from a given graph using neural encoding architectures and\nconsidering the topological properties of the graph. Semantic features of these\nnew representations are tested by using some machine learning tasks and new\ndirections on efficient link discovery, entitity retrieval and long distance\nquery methodologies on large relational datasets are investigated using real\ndatasets.\n  ----\n  En este trabajo se presenta un nuevo enfoque en el contexto del aprendizaje\nautom\\'atico multi-relacional para el estudio de Grafos Generalizados. Se\nmuestra c\\'omo se pueden obtener representaciones vectoriales que mantienen\ncaracter\\'isticas sem\\'anticas del grafo original utilizando codificadores\nneuronales y considerando las propiedades topol\\'ogicas del grafo. Adem\\'as, se\neval\\'uan las caracter\\'isticas sem\\'anticas capturadas por estas nuevas\nrepresentaciones y se investigan nuevas metodolog\\'ias eficientes relacionadas\ncon Link Discovery, Entity Retrieval y consultas a larga distancia en grandes\nconjuntos de datos relacionales haciendo uso de bases de datos reales.\n", "versions": [{"version": "v1", "created": "Thu, 7 Sep 2017 10:58:37 GMT"}], "update_date": "2017-09-11", "authors_parsed": [["Almagro-Blanco", "Pedro", ""], ["Sancho-Caparrini", "Fernando", ""]]}, {"id": "1709.02797", "submitter": "Matti Herranen", "authors": "Heikki Arponen, Matti Herranen, Harri Valpola", "title": "On the exact relationship between the denoising function and the data\n  distribution", "comments": "4 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We prove an exact relationship between the optimal denoising function and the\ndata distribution in the case of additive Gaussian noise, showing that\ndenoising implicitly models the structure of data allowing it to be exploited\nin the unsupervised learning of representations. This result generalizes a\nknown relationship [2], which is valid only in the limit of small corruption\nnoise.\n", "versions": [{"version": "v1", "created": "Wed, 6 Sep 2017 07:26:59 GMT"}], "update_date": "2017-09-11", "authors_parsed": [["Arponen", "Heikki", ""], ["Herranen", "Matti", ""], ["Valpola", "Harri", ""]]}, {"id": "1709.02800", "submitter": "Hamed R. Bonab", "authors": "Hamed R. Bonab and Fazli Can", "title": "GOOWE: Geometrically Optimum and Online-Weighted Ensemble Classifier for\n  Evolving Data Streams", "comments": "33 Pages, Accepted for publication in The ACM Transactions on\n  Knowledge Discovery from Data (TKDD) in August 2017", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Designing adaptive classifiers for an evolving data stream is a challenging\ntask due to the data size and its dynamically changing nature. Combining\nindividual classifiers in an online setting, the ensemble approach, is a\nwell-known solution. It is possible that a subset of classifiers in the\nensemble outperforms others in a time-varying fashion. However, optimum weight\nassignment for component classifiers is a problem which is not yet fully\naddressed in online evolving environments. We propose a novel data stream\nensemble classifier, called Geometrically Optimum and Online-Weighted Ensemble\n(GOOWE), which assigns optimum weights to the component classifiers using a\nsliding window containing the most recent data instances. We map vote scores of\nindividual classifiers and true class labels into a spatial environment. Based\non the Euclidean distance between vote scores and ideal-points, and using the\nlinear least squares (LSQ) solution, we present a novel, dynamic, and online\nweighting approach. While LSQ is used for batch mode ensemble classifiers, it\nis the first time that we adapt and use it for online environments by providing\na spatial modeling of online ensembles. In order to show the robustness of the\nproposed algorithm, we use real-world datasets and synthetic data generators\nusing the MOA libraries. First, we analyze the impact of our weighting system\non prediction accuracy through two scenarios. Second, we compare GOOWE with 8\nstate-of-the-art ensemble classifiers in a comprehensive experimental\nenvironment. Our experiments show that GOOWE provides improved reactions to\ndifferent types of concept drift compared to our baselines. The statistical\ntests indicate a significant improvement in accuracy, with conservative time\nand memory requirements.\n", "versions": [{"version": "v1", "created": "Fri, 8 Sep 2017 00:58:40 GMT"}], "update_date": "2017-09-12", "authors_parsed": [["Bonab", "Hamed R.", ""], ["Can", "Fazli", ""]]}, {"id": "1709.02802", "submitter": "EPTCS", "authors": "Guy Katz (Stanford University), Clark Barrett (Stanford University),\n  David L. Dill (Stanford University), Kyle Julian (Stanford University), Mykel\n  J. Kochenderfer (Stanford University)", "title": "Towards Proving the Adversarial Robustness of Deep Neural Networks", "comments": "In Proceedings FVAV 2017, arXiv:1709.02126", "journal-ref": "EPTCS 257, 2017, pp. 19-26", "doi": "10.4204/EPTCS.257.3", "report-no": null, "categories": "cs.LG cs.CR cs.LO stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Autonomous vehicles are highly complex systems, required to function reliably\nin a wide variety of situations. Manually crafting software controllers for\nthese vehicles is difficult, but there has been some success in using deep\nneural networks generated using machine-learning. However, deep neural networks\nare opaque to human engineers, rendering their correctness very difficult to\nprove manually; and existing automated techniques, which were not designed to\noperate on neural networks, fail to scale to large systems. This paper focuses\non proving the adversarial robustness of deep neural networks, i.e. proving\nthat small perturbations to a correctly-classified input to the network cannot\ncause it to be misclassified. We describe some of our recent and ongoing work\non verifying the adversarial robustness of networks, and discuss some of the\nopen questions we have encountered and how they might be addressed.\n", "versions": [{"version": "v1", "created": "Fri, 8 Sep 2017 06:34:44 GMT"}], "update_date": "2017-09-12", "authors_parsed": [["Katz", "Guy", "", "Stanford University"], ["Barrett", "Clark", "", "Stanford University"], ["Dill", "David L.", "", "Stanford University"], ["Julian", "Kyle", "", "Stanford University"], ["Kochenderfer", "Mykel J.", "", "Stanford University"]]}, {"id": "1709.02840", "submitter": "Osvaldo Simeone", "authors": "Osvaldo Simeone", "title": "A Brief Introduction to Machine Learning for Engineers", "comments": "This is an expanded and improved version of the original posting.\n  Feedback is welcome", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.IT math.IT stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This monograph aims at providing an introduction to key concepts, algorithms,\nand theoretical results in machine learning. The treatment concentrates on\nprobabilistic models for supervised and unsupervised learning problems. It\nintroduces fundamental concepts and algorithms by building on first principles,\nwhile also exposing the reader to more advanced topics with extensive pointers\nto the literature, within a unified notation and mathematical framework. The\nmaterial is organized according to clearly defined categories, such as\ndiscriminative and generative models, frequentist and Bayesian approaches,\nexact and approximate inference, as well as directed and undirected models.\nThis monograph is meant as an entry point for researchers with a background in\nprobability and linear algebra.\n", "versions": [{"version": "v1", "created": "Fri, 8 Sep 2017 19:21:26 GMT"}, {"version": "v2", "created": "Sat, 7 Apr 2018 09:57:15 GMT"}, {"version": "v3", "created": "Thu, 17 May 2018 18:28:52 GMT"}], "update_date": "2018-05-21", "authors_parsed": [["Simeone", "Osvaldo", ""]]}, {"id": "1709.02878", "submitter": "Danijar Hafner", "authors": "Danijar Hafner, James Davidson, Vincent Vanhoucke", "title": "TensorFlow Agents: Efficient Batched Reinforcement Learning in\n  TensorFlow", "comments": "White paper, 7 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce TensorFlow Agents, an efficient infrastructure paradigm for\nbuilding parallel reinforcement learning algorithms in TensorFlow. We simulate\nmultiple environments in parallel, and group them to perform the neural network\ncomputation on a batch rather than individual observations. This allows the\nTensorFlow execution engine to parallelize computation, without the need for\nmanual synchronization. Environments are stepped in separate Python processes\nto progress them in parallel without interference of the global interpreter\nlock. As part of this project, we introduce BatchPPO, an efficient\nimplementation of the proximal policy optimization algorithm. By open sourcing\nTensorFlow Agents, we hope to provide a flexible starting point for future\nprojects that accelerates future research in the field.\n", "versions": [{"version": "v1", "created": "Fri, 8 Sep 2017 23:13:01 GMT"}, {"version": "v2", "created": "Wed, 31 Oct 2018 20:11:05 GMT"}], "update_date": "2018-11-02", "authors_parsed": [["Hafner", "Danijar", ""], ["Davidson", "James", ""], ["Vanhoucke", "Vincent", ""]]}, {"id": "1709.02888", "submitter": "Ricky Fok", "authors": "Ricky Fok, Aijun An, Xiaogang Wang", "title": "Optimization assisted MCMC", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.CO cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Markov Chain Monte Carlo (MCMC) sampling methods are widely used but often\nencounter either slow convergence or biased sampling when applied to multimodal\nhigh dimensional distributions. In this paper, we present a general framework\nof improving classical MCMC samplers by employing a global optimization method.\nThe global optimization method first reduces a high dimensional search to an\none dimensional geodesic to find a starting point close to a local mode. The\nsearch is accelerated and completed by using a local search method such as\nBFGS. We modify the target distribution by extracting a local Gaussian\ndistribution aound the found mode. The process is repeated to find all the\nmodes during sampling on the fly. We integrate the optimization algorithm into\nthe Wormhole Hamiltonian Monte Carlo (WHMC) method. Experimental results show\nthat, when applied to high dimensional, multimodal Gaussian mixture models and\nthe network sensor localization problem, the proposed method achieves much\nfaster convergence, with relative error from the mean improved by about an\norder of magnitude than WHMC in some cases.\n", "versions": [{"version": "v1", "created": "Sat, 9 Sep 2017 01:03:08 GMT"}], "update_date": "2017-09-12", "authors_parsed": [["Fok", "Ricky", ""], ["An", "Aijun", ""], ["Wang", "Xiaogang", ""]]}, {"id": "1709.02893", "submitter": "Brendt Wohlberg", "authors": "Cristina Garcia-Cardona and Brendt Wohlberg", "title": "Convolutional Dictionary Learning: A Comparative Review and New\n  Algorithms", "comments": "Corrected typos in Eq. (18) and (19)", "journal-ref": "IEEE Transactions on Computational Imaging, vol. 4, no. 3, pp.\n  366-381, Sep 2018", "doi": "10.1109/TCI.2018.2840334", "report-no": null, "categories": "cs.LG eess.IV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Convolutional sparse representations are a form of sparse representation with\na dictionary that has a structure that is equivalent to convolution with a set\nof linear filters. While effective algorithms have recently been developed for\nthe convolutional sparse coding problem, the corresponding dictionary learning\nproblem is substantially more challenging. Furthermore, although a number of\ndifferent approaches have been proposed, the absence of thorough comparisons\nbetween them makes it difficult to determine which of them represents the\ncurrent state of the art. The present work both addresses this deficiency and\nproposes some new approaches that outperform existing ones in certain contexts.\nA thorough set of performance comparisons indicates a very wide range of\nperformance differences among the existing and proposed methods, and clearly\nidentifies those that are the most effective.\n", "versions": [{"version": "v1", "created": "Sat, 9 Sep 2017 01:45:43 GMT"}, {"version": "v2", "created": "Sat, 19 May 2018 13:52:50 GMT"}, {"version": "v3", "created": "Wed, 13 Jun 2018 06:50:42 GMT"}, {"version": "v4", "created": "Mon, 6 Aug 2018 16:19:21 GMT"}, {"version": "v5", "created": "Wed, 5 Sep 2018 16:55:28 GMT"}], "update_date": "2018-09-06", "authors_parsed": [["Garcia-Cardona", "Cristina", ""], ["Wohlberg", "Brendt", ""]]}, {"id": "1709.02896", "submitter": "Yanwei Pang", "authors": "Yanwei Pang, Bo Zhou, and Feiping Nie", "title": "Simultaneously Learning Neighborship and Projection Matrix for\n  Supervised Dimensionality Reduction", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Explicitly or implicitly, most of dimensionality reduction methods need to\ndetermine which samples are neighbors and the similarity between the neighbors\nin the original highdimensional space. The projection matrix is then learned on\nthe assumption that the neighborhood information (e.g., the similarity) is\nknown and fixed prior to learning. However, it is difficult to precisely\nmeasure the intrinsic similarity of samples in high-dimensional space because\nof the curse of dimensionality. Consequently, the neighbors selected according\nto such similarity might and the projection matrix obtained according to such\nsimilarity and neighbors are not optimal in the sense of classification and\ngeneralization. To overcome the drawbacks, in this paper we propose to let the\nsimilarity and neighbors be variables and model them in low-dimensional space.\nBoth the optimal similarity and projection matrix are obtained by minimizing a\nunified objective function. Nonnegative and sum-to-one constraints on the\nsimilarity are adopted. Instead of empirically setting the regularization\nparameter, we treat it as a variable to be optimized. It is interesting that\nthe optimal regularization parameter is adaptive to the neighbors in\nlow-dimensional space and has intuitive meaning. Experimental results on the\nYALE B, COIL-100, and MNIST datasets demonstrate the effectiveness of the\nproposed method.\n", "versions": [{"version": "v1", "created": "Sat, 9 Sep 2017 02:44:18 GMT"}], "update_date": "2017-09-12", "authors_parsed": [["Pang", "Yanwei", ""], ["Zhou", "Bo", ""], ["Nie", "Feiping", ""]]}, {"id": "1709.02909", "submitter": "Tianbao Yang", "authors": "Tianbao Yang, Zhe Li, Lijun Zhang", "title": "A Simple Analysis for Exp-concave Empirical Minimization with Arbitrary\n  Convex Regularizer", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG math.OC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we present a simple analysis of {\\bf fast rates} with {\\it\nhigh probability} of {\\bf empirical minimization} for {\\it stochastic composite\noptimization} over a finite-dimensional bounded convex set with exponential\nconcave loss functions and an arbitrary convex regularization. To the best of\nour knowledge, this result is the first of its kind. As a byproduct, we can\ndirectly obtain the fast rate with {\\it high probability} for exponential\nconcave empirical risk minimization with and without any convex regularization,\nwhich not only extends existing results of empirical risk minimization but also\nprovides a unified framework for analyzing exponential concave empirical risk\nminimization with and without {\\it any} convex regularization. Our proof is\nvery simple only exploiting the covering number of a finite-dimensional bounded\nset and a concentration inequality of random vectors.\n", "versions": [{"version": "v1", "created": "Sat, 9 Sep 2017 04:44:14 GMT"}], "update_date": "2017-09-12", "authors_parsed": [["Yang", "Tianbao", ""], ["Li", "Zhe", ""], ["Zhang", "Lijun", ""]]}, {"id": "1709.02925", "submitter": "Hamed R. Bonab", "authors": "Hamed Bonab and Fazli Can", "title": "Less Is More: A Comprehensive Framework for the Number of Components of\n  Ensemble Classifiers", "comments": "This is an extended version of the work presented as a short paper at\n  the Conference on Information and Knowledge Management (CIKM), 2016", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The number of component classifiers chosen for an ensemble greatly impacts\nthe prediction ability. In this paper, we use a geometric framework for a\npriori determining the ensemble size, which is applicable to most of existing\nbatch and online ensemble classifiers. There are only a limited number of\nstudies on the ensemble size examining Majority Voting (MV) and Weighted\nMajority Voting (WMV). Almost all of them are designed for batch-mode, hardly\naddressing online environments. Big data dimensions and resource limitations,\nin terms of time and memory, make determination of ensemble size crucial,\nespecially for online environments. For the MV aggregation rule, our framework\nproves that the more strong components we add to the ensemble, the more\naccurate predictions we can achieve. For the WMV aggregation rule, our\nframework proves the existence of an ideal number of components, which is equal\nto the number of class labels, with the premise that components are completely\nindependent of each other and strong enough. While giving the exact definition\nfor a strong and independent classifier in the context of an ensemble is a\nchallenging task, our proposed geometric framework provides a theoretical\nexplanation of diversity and its impact on the accuracy of predictions. We\nconduct a series of experimental evaluations to show the practical value of our\ntheorems and existing challenges.\n", "versions": [{"version": "v1", "created": "Sat, 9 Sep 2017 07:52:58 GMT"}, {"version": "v2", "created": "Sat, 29 Sep 2018 23:48:02 GMT"}], "update_date": "2018-10-02", "authors_parsed": [["Bonab", "Hamed", ""], ["Can", "Fazli", ""]]}, {"id": "1709.02956", "submitter": "Masato Taki", "authors": "Masato Taki", "title": "Deep Residual Networks and Weight Initialization", "comments": "10 pages, 4 figures", "journal-ref": null, "doi": null, "report-no": "RIKEN-iTHEMS-Report-17", "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Residual Network (ResNet) is the state-of-the-art architecture that realizes\nsuccessful training of really deep neural network. It is also known that good\nweight initialization of neural network avoids problem of vanishing/exploding\ngradients. In this paper, simplified models of ResNets are analyzed. We argue\nthat goodness of ResNet is correlated with the fact that ResNets are relatively\ninsensitive to choice of initial weights. We also demonstrate how batch\nnormalization improves backpropagation of deep ResNets without tuning initial\nvalues of weights.\n", "versions": [{"version": "v1", "created": "Sat, 9 Sep 2017 14:23:50 GMT"}], "update_date": "2017-10-16", "authors_parsed": [["Taki", "Masato", ""]]}, {"id": "1709.02980", "submitter": "Shuochao Yao", "authors": "Shuochao Yao, Yiran Zhao, Huajie Shao, Aston Zhang, Chao Zhang, Shen\n  Li, Tarek Abdelzaher", "title": "RDeepSense: Reliable Deep Mobile Computing Models with Uncertainty\n  Estimations", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent advances in deep learning have led various applications to\nunprecedented achievements, which could potentially bring higher intelligence\nto a broad spectrum of mobile and ubiquitous applications. Although existing\nstudies have demonstrated the effectiveness and feasibility of running deep\nneural network inference operations on mobile and embedded devices, they\noverlooked the reliability of mobile computing models. Reliability measurements\nsuch as predictive uncertainty estimations are key factors for improving the\ndecision accuracy and user experience. In this work, we propose RDeepSense, the\nfirst deep learning model that provides well-calibrated uncertainty estimations\nfor resource-constrained mobile and embedded devices. RDeepSense enables the\npredictive uncertainty by adopting a tunable proper scoring rule as the\ntraining criterion and dropout as the implicit Bayesian approximation, which\ntheoretically proves its correctness.To reduce the computational complexity,\nRDeepSense employs efficient dropout and predictive distribution estimation\ninstead of model ensemble or sampling-based method for inference operations. We\nevaluate RDeepSense with four mobile sensing applications using Intel Edison\ndevices. Results show that RDeepSense can reduce around 90% of the energy\nconsumption while producing superior uncertainty estimations and preserving at\nleast the same model accuracy compared with other state-of-the-art methods.\n", "versions": [{"version": "v1", "created": "Sat, 9 Sep 2017 16:58:01 GMT"}], "update_date": "2017-09-12", "authors_parsed": [["Yao", "Shuochao", ""], ["Zhao", "Yiran", ""], ["Shao", "Huajie", ""], ["Zhang", "Aston", ""], ["Zhang", "Chao", ""], ["Li", "Shen", ""], ["Abdelzaher", "Tarek", ""]]}, {"id": "1709.03008", "submitter": "Patrick O. Glauner", "authors": "Patrick Glauner, Niklas Dahringer, Oleksandr Puhachov, Jorge Augusto\n  Meira, Petko Valtchev, Radu State, Diogo Duarte", "title": "Identifying Irregular Power Usage by Turning Predictions into\n  Holographic Spatial Visualizations", "comments": "Proceedings of the 17th IEEE International Conference on Data Mining\n  Workshops (ICDMW 2017)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.HC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Power grids are critical infrastructure assets that face non-technical losses\n(NTL) such as electricity theft or faulty meters. NTL may range up to 40% of\nthe total electricity distributed in emerging countries. Industrial NTL\ndetection systems are still largely based on expert knowledge when deciding\nwhether to carry out costly on-site inspections of customers. Electricity\nproviders are reluctant to move to large-scale deployments of automated systems\nthat learn NTL profiles from data due to the latter's propensity to suggest a\nlarge number of unnecessary inspections. In this paper, we propose a novel\nsystem that combines automated statistical decision making with expert\nknowledge. First, we propose a machine learning framework that classifies\ncustomers into NTL or non-NTL using a variety of features derived from the\ncustomers' consumption data. The methodology used is specifically tailored to\nthe level of noise in the data. Second, in order to allow human experts to feed\ntheir knowledge in the decision loop, we propose a method for visualizing\nprediction results at various granularity levels in a spatial hologram. Our\napproach allows domain experts to put the classification results into the\ncontext of the data and to incorporate their knowledge for making the final\ndecisions of which customers to inspect. This work has resulted in appreciable\nresults on a real-world data set of 3.6M customers. Our system is being\ndeployed in a commercial NTL detection software.\n", "versions": [{"version": "v1", "created": "Sat, 9 Sep 2017 21:27:06 GMT"}], "update_date": "2017-09-12", "authors_parsed": [["Glauner", "Patrick", ""], ["Dahringer", "Niklas", ""], ["Puhachov", "Oleksandr", ""], ["Meira", "Jorge Augusto", ""], ["Valtchev", "Petko", ""], ["State", "Radu", ""], ["Duarte", "Diogo", ""]]}, {"id": "1709.03019", "submitter": "Andrew Gardner", "authors": "Andrew Gardner and Jinko Kanno and Christian A. Duncan and Rastko R.\n  Selmic", "title": "Classifying Unordered Feature Sets with Convolutional Deep Averaging\n  Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Unordered feature sets are a nonstandard data structure that traditional\nneural networks are incapable of addressing in a principled manner. Providing a\nconcatenation of features in an arbitrary order may lead to the learning of\nspurious patterns or biases that do not actually exist. Another complication is\nintroduced if the number of features varies between each set. We propose\nconvolutional deep averaging networks (CDANs) for classifying and learning\nrepresentations of datasets whose instances comprise variable-size, unordered\nfeature sets. CDANs are efficient, permutation-invariant, and capable of\naccepting sets of arbitrary size. We emphasize the importance of nonlinear\nfeature embeddings for obtaining effective CDAN classifiers and illustrate\ntheir advantages in experiments versus linear embeddings and alternative\npermutation-invariant and -equivariant architectures.\n", "versions": [{"version": "v1", "created": "Sun, 10 Sep 2017 00:03:37 GMT"}], "update_date": "2017-09-12", "authors_parsed": [["Gardner", "Andrew", ""], ["Kanno", "Jinko", ""], ["Duncan", "Christian A.", ""], ["Selmic", "Rastko R.", ""]]}, {"id": "1709.03030", "submitter": "Xiaodong Feng", "authors": "Xiaodong Feng, Zhiwei Tang, Sen Wu", "title": "Robust Sparse Coding via Self-Paced Learning", "comments": "submitted to AAAI2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Sparse coding (SC) is attracting more and more attention due to its\ncomprehensive theoretical studies and its excellent performance in many signal\nprocessing applications. However, most existing sparse coding algorithms are\nnonconvex and are thus prone to becoming stuck into bad local minima,\nespecially when there are outliers and noisy data. To enhance the learning\nrobustness, in this paper, we propose a unified framework named Self-Paced\nSparse Coding (SPSC), which gradually include matrix elements into SC learning\nfrom easy to complex. We also generalize the self-paced learning schema into\ndifferent levels of dynamic selection on samples, features and elements\nrespectively. Experimental results on real-world data demonstrate the efficacy\nof the proposed algorithms.\n", "versions": [{"version": "v1", "created": "Sun, 10 Sep 2017 03:15:48 GMT"}], "update_date": "2017-09-12", "authors_parsed": [["Feng", "Xiaodong", ""], ["Tang", "Zhiwei", ""], ["Wu", "Sen", ""]]}, {"id": "1709.03036", "submitter": "Kevin McCurley", "authors": "Kedar Dhamdhere and Kevin S. McCurley and Mukund Sundararajan and\n  Ankur Taly", "title": "Abductive Matching in Question Answering", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study question-answering over semi-structured data. We introduce a new way\nto apply the technique of semantic parsing by applying machine learning only to\nprovide annotations that the system infers to be missing; all the other parsing\nlogic is in the form of manually authored rules. In effect, the machine\nlearning is used to provide non-syntactic matches, a step that is ill-suited to\nmanual rules. The advantage of this approach is in its debuggability and in its\ntransparency to the end-user. We demonstrate the effectiveness of the approach\nby achieving state-of-the-art performance of 40.42% accuracy on a standard\nbenchmark dataset over tables from Wikipedia.\n", "versions": [{"version": "v1", "created": "Sun, 10 Sep 2017 03:42:43 GMT"}], "update_date": "2017-09-12", "authors_parsed": [["Dhamdhere", "Kedar", ""], ["McCurley", "Kevin S.", ""], ["Sundararajan", "Mukund", ""], ["Taly", "Ankur", ""]]}, {"id": "1709.03082", "submitter": "Abien Fred Agarap", "authors": "Abien Fred Agarap", "title": "A Neural Network Architecture Combining Gated Recurrent Unit (GRU) and\n  Support Vector Machine (SVM) for Intrusion Detection in Network Traffic Data", "comments": "5 pages, 4 figures, 5 tables, accepted paper at the International\n  Conference on Machine Learning and Computing (ICMLC) 2018", "journal-ref": null, "doi": "10.1145/3195106.3195117", "report-no": null, "categories": "cs.NE cs.CR cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Gated Recurrent Unit (GRU) is a recently-developed variation of the long\nshort-term memory (LSTM) unit, both of which are types of recurrent neural\nnetwork (RNN). Through empirical evidence, both models have been proven to be\neffective in a wide variety of machine learning tasks such as natural language\nprocessing (Wen et al., 2015), speech recognition (Chorowski et al., 2015), and\ntext classification (Yang et al., 2016). Conventionally, like most neural\nnetworks, both of the aforementioned RNN variants employ the Softmax function\nas its final output layer for its prediction, and the cross-entropy function\nfor computing its loss. In this paper, we present an amendment to this norm by\nintroducing linear support vector machine (SVM) as the replacement for Softmax\nin the final output layer of a GRU model. Furthermore, the cross-entropy\nfunction shall be replaced with a margin-based function. While there have been\nsimilar studies (Alalshekmubarak & Smith, 2013; Tang, 2013), this proposal is\nprimarily intended for binary classification on intrusion detection using the\n2013 network traffic data from the honeypot systems of Kyoto University.\nResults show that the GRU-SVM model performs relatively higher than the\nconventional GRU-Softmax model. The proposed model reached a training accuracy\nof ~81.54% and a testing accuracy of ~84.15%, while the latter was able to\nreach a training accuracy of ~63.07% and a testing accuracy of ~70.75%. In\naddition, the juxtaposition of these two final output layers indicate that the\nSVM would outperform Softmax in prediction time - a theoretical implication\nwhich was supported by the actual training and testing time in the study.\n", "versions": [{"version": "v1", "created": "Sun, 10 Sep 2017 10:43:09 GMT"}, {"version": "v2", "created": "Thu, 14 Sep 2017 06:17:37 GMT"}, {"version": "v3", "created": "Thu, 5 Oct 2017 10:40:13 GMT"}, {"version": "v4", "created": "Sat, 7 Oct 2017 07:01:11 GMT"}, {"version": "v5", "created": "Wed, 25 Oct 2017 02:15:07 GMT"}, {"version": "v6", "created": "Thu, 28 Dec 2017 18:55:35 GMT"}, {"version": "v7", "created": "Sat, 10 Mar 2018 05:50:54 GMT"}, {"version": "v8", "created": "Thu, 7 Feb 2019 06:38:08 GMT"}], "update_date": "2019-02-08", "authors_parsed": [["Agarap", "Abien Fred", ""]]}, {"id": "1709.03093", "submitter": "Dan Garber", "authors": "Dan Garber", "title": "Efficient Online Linear Optimization with Approximation Algorithms", "comments": "Accepted to Conference on Neural Information Processing System (NIPS)\n  2017", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG math.OC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We revisit the problem of \\textit{online linear optimization} in case the set\nof feasible actions is accessible through an approximated linear optimization\noracle with a factor $\\alpha$ multiplicative approximation guarantee. This\nsetting is in particular interesting since it captures natural online\nextensions of well-studied \\textit{offline} linear optimization problems which\nare NP-hard, yet admit efficient approximation algorithms. The goal here is to\nminimize the $\\alpha$\\textit{-regret} which is the natural extension of the\nstandard \\textit{regret} in \\textit{online learning} to this setting.\n  We present new algorithms with significantly improved oracle complexity for\nboth the full information and bandit variants of the problem. Mainly, for both\nvariants, we present $\\alpha$-regret bounds of $O(T^{-1/3})$, were $T$ is the\nnumber of prediction rounds, using only $O(\\log{T})$ calls to the approximation\noracle per iteration, on average. These are the first results to obtain both\naverage oracle complexity of $O(\\log{T})$ (or even poly-logarithmic in $T$) and\n$\\alpha$-regret bound $O(T^{-c})$ for a constant $c>0$, for both variants.\n", "versions": [{"version": "v1", "created": "Sun, 10 Sep 2017 12:30:26 GMT"}], "update_date": "2017-09-12", "authors_parsed": [["Garber", "Dan", ""]]}, {"id": "1709.03126", "submitter": "Bowen Cheng", "authors": "Bowen Cheng, Zhangyang Wang, Zhaobin Zhang, Zhu Li, Ding Liu, Jianchao\n  Yang, Shuai Huang, Thomas S. Huang", "title": "Robust Emotion Recognition from Low Quality and Low Bit Rate Video: A\n  Deep Learning Approach", "comments": "Accepted by the Seventh International Conference on Affective\n  Computing and Intelligent Interaction (ACII2017)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Emotion recognition from facial expressions is tremendously useful,\nespecially when coupled with smart devices and wireless multimedia\napplications. However, the inadequate network bandwidth often limits the\nspatial resolution of the transmitted video, which will heavily degrade the\nrecognition reliability. We develop a novel framework to achieve robust emotion\nrecognition from low bit rate video. While video frames are downsampled at the\nencoder side, the decoder is embedded with a deep network model for joint\nsuper-resolution (SR) and recognition. Notably, we propose a novel max-mix\ntraining strategy, leading to a single \"One-for-All\" model that is remarkably\nrobust to a vast range of downsampling factors. That makes our framework well\nadapted for the varied bandwidths in real transmission scenarios, without\nhampering scalability or efficiency. The proposed framework is evaluated on the\nAVEC 2016 benchmark, and demonstrates significantly improved stand-alone\nrecognition performance, as well as rate-distortion (R-D) performance, than\neither directly recognizing from LR frames, or separating SR and recognition.\n", "versions": [{"version": "v1", "created": "Sun, 10 Sep 2017 16:31:56 GMT"}], "update_date": "2017-09-12", "authors_parsed": [["Cheng", "Bowen", ""], ["Wang", "Zhangyang", ""], ["Zhang", "Zhaobin", ""], ["Li", "Zhu", ""], ["Liu", "Ding", ""], ["Yang", "Jianchao", ""], ["Huang", "Shuai", ""], ["Huang", "Thomas S.", ""]]}, {"id": "1709.03153", "submitter": "Somil Bansal", "authors": "Somil Bansal, Roberto Calandra, Kurtland Chua, Sergey Levine, Claire\n  Tomlin", "title": "MBMF: Model-Based Priors for Model-Free Reinforcement Learning", "comments": "After we submitted the paper for consideration in CoRL 2017 we found\n  a paper published in the recent past with a similar method (see related work\n  for a discussion). Considering the similarities between the two papers, we\n  have decided to retract our paper from CoRL 2017", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.RO cs.SY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Reinforcement Learning is divided in two main paradigms: model-free and\nmodel-based. Each of these two paradigms has strengths and limitations, and has\nbeen successfully applied to real world domains that are appropriate to its\ncorresponding strengths. In this paper, we present a new approach aimed at\nbridging the gap between these two paradigms. We aim to take the best of the\ntwo paradigms and combine them in an approach that is at the same time\ndata-efficient and cost-savvy. We do so by learning a probabilistic dynamics\nmodel and leveraging it as a prior for the intertwined model-free optimization.\nAs a result, our approach can exploit the generality and structure of the\ndynamics model, but is also capable of ignoring its inevitable inaccuracies, by\ndirectly incorporating the evidence provided by the direct observation of the\ncost. Preliminary results demonstrate that our approach outperforms purely\nmodel-based and model-free approaches, as well as the approach of simply\nswitching from a model-based to a model-free setting.\n", "versions": [{"version": "v1", "created": "Sun, 10 Sep 2017 18:46:09 GMT"}, {"version": "v2", "created": "Tue, 17 Oct 2017 18:23:24 GMT"}], "update_date": "2017-10-19", "authors_parsed": [["Bansal", "Somil", ""], ["Calandra", "Roberto", ""], ["Chua", "Kurtland", ""], ["Levine", "Sergey", ""], ["Tomlin", "Claire", ""]]}, {"id": "1709.03159", "submitter": "Hardik Goel", "authors": "Hardik Goel, Igor Melnyk, Arindam Banerjee", "title": "R2N2: Residual Recurrent Neural Networks for Multivariate Time Series\n  Forecasting", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Multivariate time-series modeling and forecasting is an important problem\nwith numerous applications. Traditional approaches such as VAR (vector\nauto-regressive) models and more recent approaches such as RNNs (recurrent\nneural networks) are indispensable tools in modeling time-series data. In many\nmultivariate time series modeling problems, there is usually a significant\nlinear dependency component, for which VARs are suitable, and a nonlinear\ncomponent, for which RNNs are suitable. Modeling such times series with only\nVAR or only RNNs can lead to poor predictive performance or complex models with\nlarge training times. In this work, we propose a hybrid model called R2N2\n(Residual RNN), which first models the time series with a simple linear model\n(like VAR) and then models its residual errors using RNNs. R2N2s can be trained\nusing existing algorithms for VARs and RNNs. Through an extensive empirical\nevaluation on two real world datasets (aviation and climate domains), we show\nthat R2N2 is competitive, usually better than VAR or RNN, used alone. We also\nshow that R2N2 is faster to train as compared to an RNN, while requiring less\nnumber of hidden units.\n", "versions": [{"version": "v1", "created": "Sun, 10 Sep 2017 19:29:49 GMT"}], "update_date": "2017-09-12", "authors_parsed": [["Goel", "Hardik", ""], ["Melnyk", "Igor", ""], ["Banerjee", "Arindam", ""]]}, {"id": "1709.03162", "submitter": "I\\~nigo Urteaga", "authors": "I\\~nigo Urteaga and Chris H. Wiggins", "title": "Bayesian bandits: balancing the exploration-exploitation tradeoff via\n  double sampling", "comments": "The software used for this study is publicly available at\n  https://github.com/iurteaga/bandits", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG stat.CO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Reinforcement learning studies how to balance exploration and exploitation in\nreal-world systems, optimizing interactions with the world while simultaneously\nlearning how the world operates. One general class of algorithms for such\nlearning is the multi-armed bandit setting. Randomized probability matching,\nbased upon the Thompson sampling approach introduced in the 1930s, has recently\nbeen shown to perform well and to enjoy provable optimality properties. It\npermits generative, interpretable modeling in a Bayesian setting, where prior\nknowledge is incorporated, and the computed posteriors naturally capture the\nfull state of knowledge. In this work, we harness the information contained in\nthe Bayesian posterior and estimate its sufficient statistics via sampling. In\nseveral application domains, for example in health and medicine, each\ninteraction with the world can be expensive and invasive, whereas drawing\nsamples from the model is relatively inexpensive. Exploiting this viewpoint, we\ndevelop a double sampling technique driven by the uncertainty in the learning\nprocess: it favors exploitation when certain about the properties of each arm,\nexploring otherwise. The proposed algorithm does not make any distributional\nassumption and it is applicable to complex reward distributions, as long as\nBayesian posterior updates are computable. Utilizing the estimated posterior\nsufficient statistics, double sampling autonomously balances the\nexploration-exploitation tradeoff to make better informed decisions. We\nempirically show its reduced cumulative regret when compared to\nstate-of-the-art alternatives in representative bandit settings.\n", "versions": [{"version": "v1", "created": "Sun, 10 Sep 2017 19:58:34 GMT"}, {"version": "v2", "created": "Wed, 8 Aug 2018 20:20:27 GMT"}], "update_date": "2018-08-10", "authors_parsed": [["Urteaga", "I\u00f1igo", ""], ["Wiggins", "Chris H.", ""]]}, {"id": "1709.03163", "submitter": "I\\~nigo Urteaga", "authors": "I\\~nigo Urteaga and Chris H. Wiggins", "title": "Variational inference for the multi-armed contextual bandit", "comments": "The software used for this study is publicly available at\n  https://github.com/iurteaga/bandits", "journal-ref": "Proceedings of the Twenty-First International Conference on\n  Artificial Intelligence and Statistics, PMLR 84:698-706, 2018", "doi": null, "report-no": null, "categories": "stat.ML cs.LG stat.CO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In many biomedical, science, and engineering problems, one must sequentially\ndecide which action to take next so as to maximize rewards. One general class\nof algorithms for optimizing interactions with the world, while simultaneously\nlearning how the world operates, is the multi-armed bandit setting and, in\nparticular, the contextual bandit case. In this setting, for each executed\naction, one observes rewards that are dependent on a given 'context', available\nat each interaction with the world. The Thompson sampling algorithm has\nrecently been shown to enjoy provable optimality properties for this set of\nproblems, and to perform well in real-world settings. It facilitates generative\nand interpretable modeling of the problem at hand. Nevertheless, the design and\ncomplexity of the model limit its application, since one must both sample from\nthe distributions modeled and calculate their expected rewards. We here show\nhow these limitations can be overcome using variational inference to\napproximate complex models, applying to the reinforcement learning case\nadvances developed for the inference case in the machine learning community\nover the past two decades. We consider contextual multi-armed bandit\napplications where the true reward distribution is unknown and complex, which\nwe approximate with a mixture model whose parameters are inferred via\nvariational inference. We show how the proposed variational Thompson sampling\napproach is accurate in approximating the true distribution, and attains\nreduced regrets even with complex reward distributions. The proposed algorithm\nis valuable for practical scenarios where restrictive modeling assumptions are\nundesirable.\n", "versions": [{"version": "v1", "created": "Sun, 10 Sep 2017 19:58:44 GMT"}, {"version": "v2", "created": "Wed, 8 Aug 2018 20:16:40 GMT"}, {"version": "v3", "created": "Mon, 3 May 2021 20:40:32 GMT"}], "update_date": "2021-05-05", "authors_parsed": [["Urteaga", "I\u00f1igo", ""], ["Wiggins", "Chris H.", ""]]}, {"id": "1709.03183", "submitter": "Jiaming Xu", "authors": "Jiaming Xu", "title": "Rates of Convergence of Spectral Methods for Graphon Estimation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG cs.SI math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper studies the problem of estimating the grahpon model - the\nunderlying generating mechanism of a network. Graphon estimation arises in many\napplications such as predicting missing links in networks and learning user\npreferences in recommender systems. The graphon model deals with a random graph\nof $n$ vertices such that each pair of two vertices $i$ and $j$ are connected\nindependently with probability $\\rho \\times f(x_i,x_j)$, where $x_i$ is the\nunknown $d$-dimensional label of vertex $i$, $f$ is an unknown symmetric\nfunction, and $\\rho$ is a scaling parameter characterizing the graph sparsity.\nRecent studies have identified the minimax error rate of estimating the graphon\nfrom a single realization of the random graph. However, there exists a wide gap\nbetween the known error rates of computationally efficient estimation\nprocedures and the minimax optimal error rate.\n  Here we analyze a spectral method, namely universal singular value\nthresholding (USVT) algorithm, in the relatively sparse regime with the average\nvertex degree $n\\rho=\\Omega(\\log n)$. When $f$ belongs to H\\\"{o}lder or Sobolev\nspace with smoothness index $\\alpha$, we show the error rate of USVT is at most\n$(n\\rho)^{ -2 \\alpha / (2\\alpha+d)}$, approaching the minimax optimal error\nrate $\\log (n\\rho)/(n\\rho)$ for $d=1$ as $\\alpha$ increases. Furthermore, when\n$f$ is analytic, we show the error rate of USVT is at most $\\log^d\n(n\\rho)/(n\\rho)$. In the special case of stochastic block model with $k$\nblocks, the error rate of USVT is at most $k/(n\\rho)$, which is larger than the\nminimax optimal error rate by at most a multiplicative factor $k/\\log k$. This\ncoincides with the computational gap observed for community detection. A key\nstep of our analysis is to derive the eigenvalue decaying rate of the edge\nprobability matrix using piecewise polynomial approximations of the graphon\nfunction $f$.\n", "versions": [{"version": "v1", "created": "Sun, 10 Sep 2017 21:45:48 GMT"}], "update_date": "2017-09-12", "authors_parsed": [["Xu", "Jiaming", ""]]}, {"id": "1709.03202", "submitter": "Taewan Kim", "authors": "Taewan Kim, Joydeep Ghosh", "title": "Semi-Supervised Active Clustering with Weak Oracles", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Semi-supervised active clustering (SSAC) utilizes the knowledge of a domain\nexpert to cluster data points by interactively making pairwise \"same-cluster\"\nqueries. However, it is impractical to ask human oracles to answer every\npairwise query. In this paper, we study the influence of allowing \"not-sure\"\nanswers from a weak oracle and propose algorithms to efficiently handle\nuncertainties. Different types of model assumptions are analyzed to cover\nrealistic scenarios of oracle abstraction. In the first model, random-weak\noracle, an oracle randomly abstains with a certain probability. We also\nproposed two distance-weak oracle models which simulate the case of getting\nconfused based on the distance between two points in a pairwise query. For each\nweak oracle model, we show that a small query complexity is adequate for the\neffective $k$ means clustering with high probability. Sufficient conditions for\nthe guarantee include a $\\gamma$-margin property of the data, and an existence\nof a point close to each cluster center. Furthermore, we provide a sample\ncomplexity with a reduced effect of the cluster's margin and only a logarithmic\ndependency on the data dimension. Our results allow significantly less number\nof same-cluster queries if the margin of the clusters is tight, i.e. $\\gamma\n\\approx 1$. Experimental results on synthetic data show the effective\nperformance of our approach in overcoming uncertainties.\n", "versions": [{"version": "v1", "created": "Mon, 11 Sep 2017 00:44:17 GMT"}], "update_date": "2017-09-12", "authors_parsed": [["Kim", "Taewan", ""], ["Ghosh", "Joydeep", ""]]}, {"id": "1709.03221", "submitter": "Yuriy Brun", "authors": "Sainyam Galhotra, Yuriy Brun, Alexandra Meliou", "title": "Fairness Testing: Testing Software for Discrimination", "comments": "Sainyam Galhotra, Yuriy Brun, and Alexandra Meliou. 2017. Fairness\n  Testing: Testing Software for Discrimination. In Proceedings of 2017 11th\n  Joint Meeting of the European Software Engineering Conference and the ACM\n  SIGSOFT Symposium on the Foundations of Software Engineering (ESEC/FSE),\n  Paderborn, Germany, September 4-8, 2017 (ESEC/FSE'17).\n  https://doi.org/10.1145/3106237.3106277, ESEC/FSE, 2017", "journal-ref": null, "doi": "10.1145/3106237.3106277", "report-no": null, "categories": "cs.SE cs.AI cs.CY cs.DB cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper defines software fairness and discrimination and develops a\ntesting-based method for measuring if and how much software discriminates,\nfocusing on causality in discriminatory behavior. Evidence of software\ndiscrimination has been found in modern software systems that recommend\ncriminal sentences, grant access to financial products, and determine who is\nallowed to participate in promotions. Our approach, Themis, generates efficient\ntest suites to measure discrimination. Given a schema describing valid system\ninputs, Themis generates discrimination tests automatically and does not\nrequire an oracle. We evaluate Themis on 20 software systems, 12 of which come\nfrom prior work with explicit focus on avoiding discrimination. We find that\n(1) Themis is effective at discovering software discrimination, (2)\nstate-of-the-art techniques for removing discrimination from algorithms fail in\nmany situations, at times discriminating against as much as 98% of an input\nsubdomain, (3) Themis optimizations are effective at producing efficient test\nsuites for measuring discrimination, and (4) Themis is more efficient on\nsystems that exhibit more discrimination. We thus demonstrate that fairness\ntesting is a critical aspect of the software development cycle in domains with\npossible discrimination and provide initial tools for measuring software\ndiscrimination.\n", "versions": [{"version": "v1", "created": "Mon, 11 Sep 2017 02:45:22 GMT"}], "update_date": "2017-09-12", "authors_parsed": [["Galhotra", "Sainyam", ""], ["Brun", "Yuriy", ""], ["Meliou", "Alexandra", ""]]}, {"id": "1709.03239", "submitter": "Xuan Peng", "authors": "Xuan Peng, Xunzhang Gao, Xiang Li", "title": "On better training the infinite restricted Boltzmann machines", "comments": "Submitted to Machine Learning", "journal-ref": null, "doi": "10.1007/s10994-018-5696-2", "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The infinite restricted Boltzmann machine (iRBM) is an extension of the\nclassic RBM. It enjoys a good property of automatically deciding the size of\nthe hidden layer according to specific training data. With sufficient training,\nthe iRBM can achieve a competitive performance with that of the classic RBM.\nHowever, the convergence of learning the iRBM is slow, due to the fact that the\niRBM is sensitive to the ordering of its hidden units, the learned filters\nchange slowly from the left-most hidden unit to right. To break this dependency\nbetween neighboring hidden units and speed up the convergence of training, a\nnovel training strategy is proposed. The key idea of the proposed training\nstrategy is randomly regrouping the hidden units before each gradient descent\nstep. Potentially, a mixing of infinite many iRBMs with different permutations\nof the hidden units can be achieved by this learning method, which has a\nsimilar effect of preventing the model from over-fitting as the dropout. The\noriginal iRBM is also modified to be capable of carrying out discriminative\ntraining. To evaluate the impact of our method on convergence speed of learning\nand the model's generalization ability, several experiments have been performed\non the binarized MNIST and CalTech101 Silhouettes datasets. Experimental\nresults indicate that the proposed training strategy can greatly accelerate\nlearning and enhance generalization ability of iRBMs.\n", "versions": [{"version": "v1", "created": "Mon, 11 Sep 2017 04:41:06 GMT"}, {"version": "v2", "created": "Sat, 14 Oct 2017 19:05:55 GMT"}], "update_date": "2018-07-30", "authors_parsed": [["Peng", "Xuan", ""], ["Gao", "Xunzhang", ""], ["Li", "Xiang", ""]]}, {"id": "1709.03413", "submitter": "Eray Ozkural", "authors": "Eray \\\"Ozkural", "title": "Gigamachine: incremental machine learning on desktop computers", "comments": "This is the original submission for my AGI-2010 paper titled\n  Stochastic Grammar Based Incremental Machine Learning Using Scheme which may\n  be found on http://agi-conf.org/2010/wp-content/uploads/2009/06/paper_24.pdf\n  and presented a partial but general solution to the transfer learning problem\n  in AI. arXiv admin note: substantial text overlap with arXiv:1103.1003", "journal-ref": "Artificial General Intelligence 2010, p. 190", "doi": null, "report-no": null, "categories": "cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a concrete design for Solomonoff's incremental machine learning\nsystem suitable for desktop computers. We use R5RS Scheme and its standard\nlibrary with a few omissions as the reference machine. We introduce a Levin\nSearch variant based on a stochastic Context Free Grammar together with new\nupdate algorithms that use the same grammar as a guiding probability\ndistribution for incremental machine learning. The updates include adjusting\nproduction probabilities, re-using previous solutions, learning programming\nidioms and discovery of frequent subprograms. The issues of extending the a\npriori probability distribution and bootstrapping are discussed. We have\nimplemented a good portion of the proposed algorithms. Experiments with toy\nproblems show that the update algorithms work as expected.\n", "versions": [{"version": "v1", "created": "Fri, 8 Sep 2017 17:39:26 GMT"}], "update_date": "2017-09-12", "authors_parsed": [["\u00d6zkural", "Eray", ""]]}, {"id": "1709.03423", "submitter": "Andrej Junginger", "authors": "Thilo Strauss, Markus Hanselmann, Andrej Junginger, Holger Ulmer", "title": "Ensemble Methods as a Defense to Adversarial Perturbations Against Deep\n  Neural Networks", "comments": "10 pages, 2 figures, 4 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep learning has become the state of the art approach in many machine\nlearning problems such as classification. It has recently been shown that deep\nlearning is highly vulnerable to adversarial perturbations. Taking the camera\nsystems of self-driving cars as an example, small adversarial perturbations can\ncause the system to make errors in important tasks, such as classifying traffic\nsigns or detecting pedestrians. Hence, in order to use deep learning without\nsafety concerns a proper defense strategy is required. We propose to use\nensemble methods as a defense strategy against adversarial perturbations. We\nfind that an attack leading one model to misclassify does not imply the same\nfor other networks performing the same task. This makes ensemble methods an\nattractive defense strategy against adversarial attacks. We empirically show\nfor the MNIST and the CIFAR-10 data sets that ensemble methods not only improve\nthe accuracy of neural networks on test data but also increase their robustness\nagainst adversarial perturbations.\n", "versions": [{"version": "v1", "created": "Mon, 11 Sep 2017 15:01:03 GMT"}, {"version": "v2", "created": "Thu, 8 Feb 2018 08:48:03 GMT"}], "update_date": "2018-02-09", "authors_parsed": [["Strauss", "Thilo", ""], ["Hanselmann", "Markus", ""], ["Junginger", "Andrej", ""], ["Ulmer", "Holger", ""]]}, {"id": "1709.03441", "submitter": "Candice Schumann", "authors": "Candice Schumann, Samsara N. Counts, Jeffrey S. Foster and John P.\n  Dickerson", "title": "The Diverse Cohort Selection Problem", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  How should a firm allocate its limited interviewing resources to select the\noptimal cohort of new employees from a large set of job applicants? How should\nthat firm allocate cheap but noisy resume screenings and expensive but in-depth\nin-person interviews? We view this problem through the lens of combinatorial\npure exploration (CPE) in the multi-armed bandit setting, where a central\nlearning agent performs costly exploration of a set of arms before selecting a\nfinal subset with some combinatorial structure. We generalize a recent CPE\nalgorithm to the setting where arm pulls can have different costs and return\ndifferent levels of information. We then prove theoretical upper bounds for a\ngeneral class of arm-pulling strategies in this new setting. We apply our\ngeneral algorithm to a real-world problem with combinatorial structure:\nincorporating diversity into university admissions. We take real data from\nadmissions at one of the largest US-based computer science graduate programs\nand show that a simulation of our algorithm produces a cohort with hiring\noverall utility while spending comparable budget to the current admissions\nprocess at that university.\n", "versions": [{"version": "v1", "created": "Mon, 11 Sep 2017 15:38:49 GMT"}, {"version": "v2", "created": "Sun, 28 Jan 2018 14:57:22 GMT"}, {"version": "v3", "created": "Sun, 20 May 2018 18:06:27 GMT"}, {"version": "v4", "created": "Sun, 26 Aug 2018 22:52:50 GMT"}, {"version": "v5", "created": "Thu, 14 Mar 2019 17:11:55 GMT"}], "update_date": "2019-03-15", "authors_parsed": [["Schumann", "Candice", ""], ["Counts", "Samsara N.", ""], ["Foster", "Jeffrey S.", ""], ["Dickerson", "John P.", ""]]}, {"id": "1709.03450", "submitter": "Mario Amrehn", "authors": "Mario Amrehn, Sven Gaube, Mathias Unberath, Frank Schebesch, Tim Horz,\n  Maddalena Strumia, Stefan Steidl, Markus Kowarschik, Andreas Maier", "title": "UI-Net: Interactive Artificial Neural Networks for Iterative Image\n  Segmentation Based on a User Model", "comments": "This work is submitted to the 2017 Eurographics Workshop on Visual\n  Computing for Biology and Medicine", "journal-ref": "Eurographics Workshop on Visual Computing for Biology and Medicine\n  (2017) 143-147", "doi": "10.2312/vcbm.20171248", "report-no": null, "categories": "cs.CV cs.AI cs.LG cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  For complex segmentation tasks, fully automatic systems are inherently\nlimited in their achievable accuracy for extracting relevant objects.\nEspecially in cases where only few data sets need to be processed for a highly\naccurate result, semi-automatic segmentation techniques exhibit a clear benefit\nfor the user. One area of application is medical image processing during an\nintervention for a single patient. We propose a learning-based cooperative\nsegmentation approach which includes the computing entity as well as the user\ninto the task. Our system builds upon a state-of-the-art fully convolutional\nartificial neural network (FCN) as well as an active user model for training.\nDuring the segmentation process, a user of the trained system can iteratively\nadd additional hints in form of pictorial scribbles as seed points into the FCN\nsystem to achieve an interactive and precise segmentation result. The\nsegmentation quality of interactive FCNs is evaluated. Iterative FCN approaches\ncan yield superior results compared to networks without the user input channel\ncomponent, due to a consistent improvement in segmentation quality after each\ninteraction.\n", "versions": [{"version": "v1", "created": "Mon, 11 Sep 2017 15:50:24 GMT"}], "update_date": "2017-09-12", "authors_parsed": [["Amrehn", "Mario", ""], ["Gaube", "Sven", ""], ["Unberath", "Mathias", ""], ["Schebesch", "Frank", ""], ["Horz", "Tim", ""], ["Strumia", "Maddalena", ""], ["Steidl", "Stefan", ""], ["Kowarschik", "Markus", ""], ["Maier", "Andreas", ""]]}, {"id": "1709.03485", "submitter": "Eli Gibson", "authors": "Eli Gibson, Wenqi Li, Carole Sudre, Lucas Fidon, Dzhoshkun I. Shakir,\n  Guotai Wang, Zach Eaton-Rosen, Robert Gray, Tom Doel, Yipeng Hu, Tom Whyntie,\n  Parashkev Nachev, Marc Modat, Dean C. Barratt, S\\'ebastien Ourselin, M. Jorge\n  Cardoso and Tom Vercauteren", "title": "NiftyNet: a deep-learning platform for medical imaging", "comments": "Wenqi Li and Eli Gibson contributed equally to this work. M. Jorge\n  Cardoso and Tom Vercauteren contributed equally to this work. 26 pages, 6\n  figures; Update includes additional applications, updated author list and\n  formatting for journal submission", "journal-ref": null, "doi": "10.1016/j.cmpb.2018.01.025", "report-no": null, "categories": "cs.CV cs.LG cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Medical image analysis and computer-assisted intervention problems are\nincreasingly being addressed with deep-learning-based solutions. Established\ndeep-learning platforms are flexible but do not provide specific functionality\nfor medical image analysis and adapting them for this application requires\nsubstantial implementation effort. Thus, there has been substantial duplication\nof effort and incompatible infrastructure developed across many research\ngroups. This work presents the open-source NiftyNet platform for deep learning\nin medical imaging. The ambition of NiftyNet is to accelerate and simplify the\ndevelopment of these solutions, and to provide a common mechanism for\ndisseminating research outputs for the community to use, adapt and build upon.\n  NiftyNet provides a modular deep-learning pipeline for a range of medical\nimaging applications including segmentation, regression, image generation and\nrepresentation learning applications. Components of the NiftyNet pipeline\nincluding data loading, data augmentation, network architectures, loss\nfunctions and evaluation metrics are tailored to, and take advantage of, the\nidiosyncracies of medical image analysis and computer-assisted intervention.\nNiftyNet is built on TensorFlow and supports TensorBoard visualization of 2D\nand 3D images and computational graphs by default.\n  We present 3 illustrative medical image analysis applications built using\nNiftyNet: (1) segmentation of multiple abdominal organs from computed\ntomography; (2) image regression to predict computed tomography attenuation\nmaps from brain magnetic resonance images; and (3) generation of simulated\nultrasound images for specified anatomical poses.\n  NiftyNet enables researchers to rapidly develop and distribute deep learning\nsolutions for segmentation, regression, image generation and representation\nlearning applications, or extend the platform to new applications.\n", "versions": [{"version": "v1", "created": "Mon, 11 Sep 2017 17:42:10 GMT"}, {"version": "v2", "created": "Mon, 16 Oct 2017 13:46:31 GMT"}], "update_date": "2018-02-05", "authors_parsed": [["Gibson", "Eli", ""], ["Li", "Wenqi", ""], ["Sudre", "Carole", ""], ["Fidon", "Lucas", ""], ["Shakir", "Dzhoshkun I.", ""], ["Wang", "Guotai", ""], ["Eaton-Rosen", "Zach", ""], ["Gray", "Robert", ""], ["Doel", "Tom", ""], ["Hu", "Yipeng", ""], ["Whyntie", "Tom", ""], ["Nachev", "Parashkev", ""], ["Modat", "Marc", ""], ["Barratt", "Dean C.", ""], ["Ourselin", "S\u00e9bastien", ""], ["Cardoso", "M. Jorge", ""], ["Vercauteren", "Tom", ""]]}, {"id": "1709.03528", "submitter": "Shusen Wang", "authors": "Shusen Wang, Farbod Roosta-Khorasani, Peng Xu and Michael W. Mahoney", "title": "GIANT: Globally Improved Approximate Newton Method for Distributed\n  Optimization", "comments": "Fixed some typos. Improved writing", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.DC math.OC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  For distributed computing environment, we consider the empirical risk\nminimization problem and propose a distributed and communication-efficient\nNewton-type optimization method. At every iteration, each worker locally finds\nan Approximate NewTon (ANT) direction, which is sent to the main driver. The\nmain driver, then, averages all the ANT directions received from workers to\nform a {\\it Globally Improved ANT} (GIANT) direction. GIANT is highly\ncommunication efficient and naturally exploits the trade-offs between local\ncomputations and global communications in that more local computations result\nin fewer overall rounds of communications. Theoretically, we show that GIANT\nenjoys an improved convergence rate as compared with first-order methods and\nexisting distributed Newton-type methods. Further, and in sharp contrast with\nmany existing distributed Newton-type methods, as well as popular first-order\nmethods, a highly advantageous practical feature of GIANT is that it only\ninvolves one tuning parameter. We conduct large-scale experiments on a computer\ncluster and, empirically, demonstrate the superior performance of GIANT.\n", "versions": [{"version": "v1", "created": "Mon, 11 Sep 2017 18:17:18 GMT"}, {"version": "v2", "created": "Wed, 27 Sep 2017 17:47:15 GMT"}, {"version": "v3", "created": "Wed, 9 May 2018 21:45:02 GMT"}, {"version": "v4", "created": "Fri, 18 May 2018 21:05:37 GMT"}, {"version": "v5", "created": "Tue, 11 Sep 2018 15:12:01 GMT"}], "update_date": "2018-09-12", "authors_parsed": [["Wang", "Shusen", ""], ["Roosta-Khorasani", "Farbod", ""], ["Xu", "Peng", ""], ["Mahoney", "Michael W.", ""]]}, {"id": "1709.03545", "submitter": "Liu Weiyi", "authors": "Weiyi Liu, Hal Cooper, Min Hwan Oh, Sailung Yeung, Pin-Yu Chen,\n  Toyotaro Suzumura, Lingli Chen", "title": "Learning Graph Topological Features via GAN", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Inspired by the generation power of generative adversarial networks (GANs) in\nimage domains, we introduce a novel hierarchical architecture for learning\ncharacteristic topological features from a single arbitrary input graph via\nGANs. The hierarchical architecture consisting of multiple GANs preserves both\nlocal and global topological features and automatically partitions the input\ngraph into representative stages for feature learning. The stages facilitate\nreconstruction and can be used as indicators of the importance of the\nassociated topological structures. Experiments show that our method produces\nsubgraphs retaining a wide range of topological features, even in early\nreconstruction stages (unlike a single GAN, which cannot easily identify such\nfeatures, let alone reconstruct the original graph). This paper is firstline\nresearch on combining the use of GANs and graph topological analysis.\n", "versions": [{"version": "v1", "created": "Mon, 11 Sep 2017 18:57:03 GMT"}, {"version": "v2", "created": "Wed, 13 Sep 2017 18:02:41 GMT"}, {"version": "v3", "created": "Tue, 9 Apr 2019 03:40:07 GMT"}, {"version": "v4", "created": "Tue, 27 Aug 2019 21:54:52 GMT"}, {"version": "v5", "created": "Tue, 8 Oct 2019 22:16:43 GMT"}], "update_date": "2019-10-10", "authors_parsed": [["Liu", "Weiyi", ""], ["Cooper", "Hal", ""], ["Oh", "Min Hwan", ""], ["Yeung", "Sailung", ""], ["Chen", "Pin-Yu", ""], ["Suzumura", "Toyotaro", ""], ["Chen", "Lingli", ""]]}, {"id": "1709.03562", "submitter": "Andrea Li", "authors": "Andrea S. Li, Alistair E. W. Johnson, Roger G. Mark", "title": "False arrhythmia alarm reduction in the intensive care unit", "comments": "10 pages, 5 tables, 5 figures", "journal-ref": null, "doi": "10.5281/zenodo.889036", "report-no": null, "categories": "cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Research has shown that false alarms constitute more than 80% of the alarms\ntriggered in the intensive care unit (ICU). The high false arrhythmia alarm\nrate has severe implications such as disruption of patient care, caregiver\nalarm fatigue, and desensitization from clinical staff to real life-threatening\nalarms. A method to reduce the false alarm rate would therefore greatly benefit\npatients as well as nurses in their ability to provide care. We here develop\nand describe a robust false arrhythmia alarm reduction system for use in the\nICU. Building off of work previously described in the literature, we make use\nof signal processing and machine learning techniques to identify true and false\nalarms for five arrhythmia types. This baseline algorithm alone is able to\nperform remarkably well, with a sensitivity of 0.908, a specificity of 0.838,\nand a PhysioNet/CinC challenge score of 0.756. We additionally explore dynamic\ntime warping techniques on both the entire alarm signal as well as on a\nbeat-by-beat basis in an effort to improve performance of ventricular\ntachycardia, which has in the literature been one of the hardest arrhythmias to\nclassify. Such an algorithm with strong performance and efficiency could\npotentially be translated for use in the ICU to promote overall patient care\nand recovery.\n", "versions": [{"version": "v1", "created": "Mon, 11 Sep 2017 19:57:12 GMT"}], "update_date": "2017-09-13", "authors_parsed": [["Li", "Andrea S.", ""], ["Johnson", "Alistair E. W.", ""], ["Mark", "Roger G.", ""]]}, {"id": "1709.03573", "submitter": "Sattar Vakili", "authors": "Sattar Vakili, Qing Zhao, Chang Liu, Chen-Nee Chuah", "title": "Anomaly Detection in Hierarchical Data Streams under Unknown Models", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the problem of detecting a few targets among a large number of\nhierarchical data streams. The data streams are modeled as random processes\nwith unknown and potentially heavy-tailed distributions. The objective is an\nactive inference strategy that determines, sequentially, which data stream to\ncollect samples from in order to minimize the sample complexity under a\nreliability constraint. We propose an active inference strategy that induces a\nbiased random walk on the tree-structured hierarchy based on confidence bounds\nof sample statistics. We then establish its order optimality in terms of both\nthe size of the search space (i.e., the number of data streams) and the\nreliability requirement. The results find applications in hierarchical heavy\nhitter detection, noisy group testing, and adaptive sampling for active\nlearning, classification, and stochastic root finding.\n", "versions": [{"version": "v1", "created": "Mon, 11 Sep 2017 20:16:29 GMT"}], "update_date": "2017-09-13", "authors_parsed": [["Vakili", "Sattar", ""], ["Zhao", "Qing", ""], ["Liu", "Chang", ""], ["Chuah", "Chen-Nee", ""]]}, {"id": "1709.03582", "submitter": "Valentin Khrulkov", "authors": "Valentin Khrulkov and Ivan Oseledets", "title": "Art of singular vectors and universal adversarial perturbations", "comments": "Submitted to CVPR 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Vulnerability of Deep Neural Networks (DNNs) to adversarial attacks has been\nattracting a lot of attention in recent studies. It has been shown that for\nmany state of the art DNNs performing image classification there exist\nuniversal adversarial perturbations --- image-agnostic perturbations mere\naddition of which to natural images with high probability leads to their\nmisclassification. In this work we propose a new algorithm for constructing\nsuch universal perturbations. Our approach is based on computing the so-called\n$(p, q)$-singular vectors of the Jacobian matrices of hidden layers of a\nnetwork. Resulting perturbations present interesting visual patterns, and by\nusing only 64 images we were able to construct universal perturbations with\nmore than 60 \\% fooling rate on the dataset consisting of 50000 images. We also\ninvestigate a correlation between the maximal singular value of the Jacobian\nmatrix and the fooling rate of the corresponding singular vector, and show that\nthe constructed perturbations generalize across networks.\n", "versions": [{"version": "v1", "created": "Mon, 11 Sep 2017 20:22:37 GMT"}, {"version": "v2", "created": "Mon, 20 Nov 2017 03:09:07 GMT"}], "update_date": "2017-11-21", "authors_parsed": [["Khrulkov", "Valentin", ""], ["Oseledets", "Ivan", ""]]}, {"id": "1709.03625", "submitter": "AmirEmad Ghassami", "authors": "AmirEmad Ghassami, Saber Salehkaleybar, Negar Kiyavash, Elias\n  Bareinboim", "title": "Budgeted Experiment Design for Causal Structure Learning", "comments": null, "journal-ref": "35th International Conference on Machine Learning (ICML), PMLR\n  80:1719-1728, 2018", "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the problem of causal structure learning when the experimenter is\nlimited to perform at most $k$ non-adaptive experiments of size $1$. We\nformulate the problem of finding the best intervention target set as an\noptimization problem, which aims to maximize the average number of edges whose\ndirections are resolved. We prove that the corresponding objective function is\nsubmodular and a greedy algorithm suffices to achieve\n$(1-\\frac{1}{e})$-approximation of the optimal value. We further present an\naccelerated variant of the greedy algorithm, which can lead to orders of\nmagnitude performance speedup. We validate our proposed approach on synthetic\nand real graphs. The results show that compared to the purely observational\nsetting, our algorithm orients the majority of the edges through a considerably\nsmall number of interventions.\n", "versions": [{"version": "v1", "created": "Mon, 11 Sep 2017 23:43:30 GMT"}, {"version": "v2", "created": "Sun, 29 Jul 2018 21:56:06 GMT"}], "update_date": "2018-08-03", "authors_parsed": [["Ghassami", "AmirEmad", ""], ["Salehkaleybar", "Saber", ""], ["Kiyavash", "Negar", ""], ["Bareinboim", "Elias", ""]]}, {"id": "1709.03629", "submitter": "Carlos Eduardo Cancino-Chac\\'on", "authors": "Carlos Cancino-Chac\\'on, Maarten Grachten, David R. W. Sears, Gerhard\n  Widmer", "title": "What were you expecting? Using Expectancy Features to Predict Expressive\n  Performances of Classical Piano Music", "comments": "6 pages, 1 figure, 10th International Workshop on Machine Learning\n  and Music (MML 2017)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SD cs.IT cs.LG math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we present preliminary work examining the relationship between\nthe formation of expectations and the realization of musical performances,\npaying particular attention to expressive tempo and dynamics. To compute\nfeatures that reflect what a listener is expecting to hear, we employ a\ncomputational model of auditory expectation called the Information Dynamics of\nMusic model (IDyOM). We then explore how well these expectancy features -- when\ncombined with score descriptors using the Basis-Function modeling approach --\ncan predict expressive tempo and dynamics in a dataset of Mozart piano sonata\nperformances. Our results suggest that using expectancy features significantly\nimproves the predictions for tempo.\n", "versions": [{"version": "v1", "created": "Mon, 11 Sep 2017 23:56:37 GMT"}], "update_date": "2017-09-13", "authors_parsed": [["Cancino-Chac\u00f3n", "Carlos", ""], ["Grachten", "Maarten", ""], ["Sears", "David R. W.", ""], ["Widmer", "Gerhard", ""]]}, {"id": "1709.03645", "submitter": "Tao Yang", "authors": "Tao Yang, Paul Thompson, Sihai Zhao, Jieping Ye", "title": "Identifying Genetic Risk Factors via Sparse Group Lasso with Group Graph\n  Structure", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG q-bio.GN", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Genome-wide association studies (GWA studies or GWAS) investigate the\nrelationships between genetic variants such as single-nucleotide polymorphisms\n(SNPs) and individual traits. Recently, incorporating biological priors\ntogether with machine learning methods in GWA studies has attracted increasing\nattention. However, in real-world, nucleotide-level bio-priors have not been\nwell-studied to date. Alternatively, studies at gene-level, for example,\nprotein--protein interactions and pathways, are more rigorous and legitimate,\nand it is potentially beneficial to utilize such gene-level priors in GWAS. In\nthis paper, we proposed a novel two-level structured sparse model, called\nSparse Group Lasso with Group-level Graph structure (SGLGG), for GWAS. It can\nbe considered as a sparse group Lasso along with a group-level graph Lasso.\nEssentially, SGLGG penalizes the nucleotide-level sparsity as well as takes\nadvantages of gene-level priors (both gene groups and networks), to identifying\nphenotype-associated risk SNPs. We employ the alternating direction method of\nmultipliers algorithm to optimize the proposed model. Our experiments on the\nAlzheimer's Disease Neuroimaging Initiative whole genome sequence data and\nneuroimage data demonstrate the effectiveness of SGLGG. As a regression model,\nit is competitive to the state-of-the-arts sparse models; as a variable\nselection method, SGLGG is promising for identifying Alzheimer's\ndisease-related risk SNPs.\n", "versions": [{"version": "v1", "created": "Tue, 12 Sep 2017 01:34:50 GMT"}], "update_date": "2017-09-13", "authors_parsed": [["Yang", "Tao", ""], ["Thompson", "Paul", ""], ["Zhao", "Sihai", ""], ["Ye", "Jieping", ""]]}, {"id": "1709.03657", "submitter": "Taesup Moon", "authors": "Taesup Moon", "title": "A Denoising Loss Bound for Neural Network based Universal Discrete\n  Denoisers", "comments": "submitted to ICML 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.IT math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We obtain a denoising loss bound of the recently proposed neural network\nbased universal discrete denoiser, Neural DUDE, which can adaptively learn its\nparameters solely from the noise-corrupted data, by minimizing the\n\\emph{empirical estimated loss}. The resulting bound resembles the\ngeneralization error bound of the standard empirical risk minimizers (ERM) in\nsupervised learning, and we show that the well-known bias-variance tradeoff\nalso exists in our loss bound. The key tool we develop is the concentration of\nthe unbiased estimated loss on the true denoising loss, which is shown to hold\n\\emph{uniformly} for \\emph{all} bounded network parameters and \\emph{all}\nunderlying clean sequences. For proving our main results, we make a novel\napplication of the tools from the statistical learning theory. Finally, we show\nthat the hyperparameters of Neural DUDE can be chosen from a small validation\nset to significantly improve the denoising performance, as predicted by the\ntheoretical result of this paper.\n", "versions": [{"version": "v1", "created": "Tue, 12 Sep 2017 02:16:15 GMT"}, {"version": "v2", "created": "Sat, 24 Feb 2018 05:44:47 GMT"}], "update_date": "2018-02-27", "authors_parsed": [["Moon", "Taesup", ""]]}, {"id": "1709.03658", "submitter": "Szu-Wei Fu", "authors": "Szu-Wei Fu, Tao-Wei Wang, Yu Tsao, Xugang Lu, and Hisashi Kawai", "title": "End-to-End Waveform Utterance Enhancement for Direct Evaluation Metrics\n  Optimization by Fully Convolutional Neural Networks", "comments": "Accepted in IEEE Transactions on Audio, Speech and Language\n  Processing (TASLP)", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG cs.SD", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Speech enhancement model is used to map a noisy speech to a clean speech. In\nthe training stage, an objective function is often adopted to optimize the\nmodel parameters. However, in most studies, there is an inconsistency between\nthe model optimization criterion and the evaluation criterion on the enhanced\nspeech. For example, in measuring speech intelligibility, most of the\nevaluation metric is based on a short-time objective intelligibility (STOI)\nmeasure, while the frame based minimum mean square error (MMSE) between\nestimated and clean speech is widely used in optimizing the model. Due to the\ninconsistency, there is no guarantee that the trained model can provide optimal\nperformance in applications. In this study, we propose an end-to-end\nutterance-based speech enhancement framework using fully convolutional neural\nnetworks (FCN) to reduce the gap between the model optimization and evaluation\ncriterion. Because of the utterance-based optimization, temporal correlation\ninformation of long speech segments, or even at the entire utterance level, can\nbe considered when perception-based objective functions are used for the direct\noptimization. As an example, we implement the proposed FCN enhancement\nframework to optimize the STOI measure. Experimental results show that the STOI\nof test speech is better than conventional MMSE-optimized speech due to the\nconsistency between the training and evaluation target. Moreover, by\nintegrating the STOI in model optimization, the intelligibility of human\nsubjects and automatic speech recognition (ASR) system on the enhanced speech\nis also substantially improved compared to those generated by the MMSE\ncriterion.\n", "versions": [{"version": "v1", "created": "Tue, 12 Sep 2017 02:24:50 GMT"}, {"version": "v2", "created": "Thu, 15 Mar 2018 10:19:56 GMT"}], "update_date": "2018-03-16", "authors_parsed": [["Fu", "Szu-Wei", ""], ["Wang", "Tao-Wei", ""], ["Tsao", "Yu", ""], ["Lu", "Xugang", ""], ["Kawai", "Hisashi", ""]]}, {"id": "1709.03659", "submitter": "Guixiang Ma", "authors": "Guixiang Ma, Chun-Ta Lu, Lifang He, Philip S. Yu, Ann B. Ragin", "title": "Multi-view Graph Embedding with Hub Detection for Brain Network Analysis", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Multi-view graph embedding has become a widely studied problem in the area of\ngraph learning. Most of the existing works on multi-view graph embedding aim to\nfind a shared common node embedding across all the views of the graph by\ncombining the different views in a specific way. Hub detection, as another\nessential topic in graph mining has also drawn extensive attentions in recent\nyears, especially in the context of brain network analysis. Both the graph\nembedding and hub detection relate to the node clustering structure of graphs.\nThe multi-view graph embedding usually implies the node clustering structure of\nthe graph based on the multiple views, while the hubs are the boundary-spanning\nnodes across different node clusters in the graph and thus may potentially\ninfluence the clustering structure of the graph. However, none of the existing\nworks in multi-view graph embedding considered the hubs when learning the\nmulti-view embeddings. In this paper, we propose to incorporate the hub\ndetection task into the multi-view graph embedding framework so that the two\ntasks could benefit each other. Specifically, we propose an auto-weighted\nframework of Multi-view Graph Embedding with Hub Detection (MVGE-HD) for brain\nnetwork analysis. The MVGE-HD framework learns a unified graph embedding across\nall the views while reducing the potential influence of the hubs on blurring\nthe boundaries between node clusters in the graph, thus leading to a clear and\ndiscriminative node clustering structure for the graph. We apply MVGE-HD on two\nreal multi-view brain network datasets (i.e., HIV and Bipolar). The\nexperimental results demonstrate the superior performance of the proposed\nframework in brain network analysis for clinical investigation and application.\n", "versions": [{"version": "v1", "created": "Tue, 12 Sep 2017 02:32:36 GMT"}], "update_date": "2017-09-13", "authors_parsed": [["Ma", "Guixiang", ""], ["Lu", "Chun-Ta", ""], ["He", "Lifang", ""], ["Yu", "Philip S.", ""], ["Ragin", "Ann B.", ""]]}, {"id": "1709.03670", "submitter": "Kangwook Lee", "authors": "Kwangjun Ahn, Kangwook Lee, Changho Suh", "title": "Community Recovery in Hypergraphs", "comments": "25 pages, 7 figures. Submitted to IEEE Transacations on Information\n  Theory", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IT cs.LG math.IT stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Community recovery is a central problem that arises in a wide variety of\napplications such as network clustering, motion segmentation, face clustering\nand protein complex detection. The objective of the problem is to cluster data\npoints into distinct communities based on a set of measurements, each of which\nis associated with the values of a certain number of data points. While most of\nthe prior works focus on a setting in which the number of data points involved\nin a measurement is two, this work explores a generalized setting in which the\nnumber can be more than two. Motivated by applications particularly in machine\nlearning and channel coding, we consider two types of measurements: (1)\nhomogeneity measurement which indicates whether or not the associated data\npoints belong to the same community; (2) parity measurement which denotes the\nmodulo-2 sum of the values of the data points. Such measurements are possibly\ncorrupted by Bernoulli noise. We characterize the fundamental limits on the\nnumber of measurements required to reconstruct the communities for the\nconsidered models.\n", "versions": [{"version": "v1", "created": "Tue, 12 Sep 2017 03:08:33 GMT"}], "update_date": "2017-09-13", "authors_parsed": [["Ahn", "Kwangjun", ""], ["Lee", "Kangwook", ""], ["Suh", "Changho", ""]]}, {"id": "1709.03671", "submitter": "Nikos Pitsianis", "authors": "Nikos Pitsianis, Dimitris Floros, Alexandros-Stavros Iliopoulos,\n  Kostas Mylonakis, Nikos Sismanis and Xiaobai Sun", "title": "Rapid Near-Neighbor Interaction of High-dimensional Data via\n  Hierarchical Clustering", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Calculation of near-neighbor interactions among high dimensional, irregularly\ndistributed data points is a fundamental task to many graph-based or\nkernel-based machine learning algorithms and applications. Such calculations,\ninvolving large, sparse interaction matrices, expose the limitation of\nconventional data-and-computation reordering techniques for improving space and\ntime locality on modern computer memory hierarchies. We introduce a novel\nmethod for obtaining a matrix permutation that renders a desirable sparsity\nprofile. The method is distinguished by the guiding principle to obtain a\nprofile that is block-sparse with dense blocks. Our profile model and measure\ncapture the essential properties affecting space and time locality, and permit\nvariation in sparsity profile without imposing a restriction to a fixed\npattern. The second distinction lies in an efficient algorithm for obtaining a\ndesirable profile, via exploring and exploiting multi-scale cluster structure\nhidden in but intrinsic to the data. The algorithm accomplishes its task with\nkey components for lower-dimensional embedding with data-specific principal\nfeature axes, hierarchical data clustering, multi-level matrix compression\nstorage, and multi-level interaction computations. We provide experimental\nresults from case studies with two important data analysis algorithms. The\nresulting performance is remarkably comparable to the BLAS performance for the\nbest-case interaction governed by a regularly banded matrix with the same\nsparsity.\n", "versions": [{"version": "v1", "created": "Tue, 12 Sep 2017 03:11:50 GMT"}], "update_date": "2017-09-13", "authors_parsed": [["Pitsianis", "Nikos", ""], ["Floros", "Dimitris", ""], ["Iliopoulos", "Alexandros-Stavros", ""], ["Mylonakis", "Kostas", ""], ["Sismanis", "Nikos", ""], ["Sun", "Xiaobai", ""]]}, {"id": "1709.03683", "submitter": "Yan Zhao", "authors": "Yan Zhao, Xiao Fang, David Simchi-Levi", "title": "A Practically Competitive and Provably Consistent Algorithm for Uplift\n  Modeling", "comments": "Accepted by 2017 IEEE International Conference on Data Mining", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Randomized experiments have been critical tools of decision making for\ndecades. However, subjects can show significant heterogeneity in response to\ntreatments in many important applications. Therefore it is not enough to simply\nknow which treatment is optimal for the entire population. What we need is a\nmodel that correctly customize treatment assignment base on subject\ncharacteristics. The problem of constructing such models from randomized\nexperiments data is known as Uplift Modeling in the literature. Many algorithms\nhave been proposed for uplift modeling and some have generated promising\nresults on various data sets. Yet little is known about the theoretical\nproperties of these algorithms. In this paper, we propose a new tree-based\nensemble algorithm for uplift modeling. Experiments show that our algorithm can\nachieve competitive results on both synthetic and industry-provided data. In\naddition, by properly tuning the \"node size\" parameter, our algorithm is proved\nto be consistent under mild regularity conditions. This is the first consistent\nalgorithm for uplift modeling that we are aware of.\n", "versions": [{"version": "v1", "created": "Tue, 12 Sep 2017 03:49:57 GMT"}], "update_date": "2017-09-13", "authors_parsed": [["Zhao", "Yan", ""], ["Fang", "Xiao", ""], ["Simchi-Levi", "David", ""]]}, {"id": "1709.03714", "submitter": "Cheng Wang", "authors": "Cheng Wang", "title": "RRA: Recurrent Residual Attention for Sequence Learning", "comments": "9 pages, 7 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we propose a recurrent neural network (RNN) with residual\nattention (RRA) to learn long-range dependencies from sequential data. We\npropose to add residual connections across timesteps to RNN, which explicitly\nenhances the interaction between current state and hidden states that are\nseveral timesteps apart. This also allows training errors to be directly\nback-propagated through residual connections and effectively alleviates\ngradient vanishing problem. We further reformulate an attention mechanism over\nresidual connections. An attention gate is defined to summarize the individual\ncontribution from multiple previous hidden states in computing the current\nstate. We evaluate RRA on three tasks: the adding problem, pixel-by-pixel MNIST\nclassification and sentiment analysis on the IMDB dataset. Our experiments\ndemonstrate that RRA yields better performance, faster convergence and more\nstable training compared to a standard LSTM network. Furthermore, RRA shows\nhighly competitive performance to the state-of-the-art methods.\n", "versions": [{"version": "v1", "created": "Tue, 12 Sep 2017 07:39:43 GMT"}], "update_date": "2017-09-19", "authors_parsed": [["Wang", "Cheng", ""]]}, {"id": "1709.03726", "submitter": "Paolo Di Lorenzo", "authors": "Paolo Di Lorenzo, Paolo Banelli, Elvin Isufi, Sergio Barbarossa, Geert\n  Leus", "title": "Adaptive Graph Signal Processing: Algorithms and Optimal Sampling\n  Strategies", "comments": "Submitted to IEEE Transactions on Signal Processing, September 2017", "journal-ref": null, "doi": "10.1109/TSP.2018.2835384", "report-no": null, "categories": "cs.LG cs.SY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The goal of this paper is to propose novel strategies for adaptive learning\nof signals defined over graphs, which are observed over a (randomly\ntime-varying) subset of vertices. We recast two classical adaptive algorithms\nin the graph signal processing framework, namely, the least mean squares (LMS)\nand the recursive least squares (RLS) adaptive estimation strategies. For both\nmethods, a detailed mean-square analysis illustrates the effect of random\nsampling on the adaptive reconstruction capability and the steady-state\nperformance. Then, several probabilistic sampling strategies are proposed to\ndesign the sampling probability at each node in the graph, with the aim of\noptimizing the tradeoff between steady-state performance, graph sampling rate,\nand convergence rate of the adaptive algorithms. Finally, a distributed RLS\nstrategy is derived and is shown to be convergent to its centralized\ncounterpart. Numerical simulations carried out over both synthetic and real\ndata illustrate the good performance of the proposed sampling and\nreconstruction strategies for (possibly distributed) adaptive learning of\nsignals defined over graphs.\n", "versions": [{"version": "v1", "created": "Tue, 12 Sep 2017 08:06:22 GMT"}], "update_date": "2018-08-01", "authors_parsed": [["Di Lorenzo", "Paolo", ""], ["Banelli", "Paolo", ""], ["Isufi", "Elvin", ""], ["Barbarossa", "Sergio", ""], ["Leus", "Geert", ""]]}, {"id": "1709.03730", "submitter": "Huijun Wu", "authors": "Huijun Wu, Chen Wang, Jie Yin, Kai Lu, Liming Zhu", "title": "Interpreting Shared Deep Learning Models via Explicable Boundary Trees", "comments": "9 pages, 10 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.HC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Despite outperforming the human in many tasks, deep neural network models are\nalso criticized for the lack of transparency and interpretability in decision\nmaking. The opaqueness results in uncertainty and low confidence when deploying\nsuch a model in model sharing scenarios, when the model is developed by a third\nparty. For a supervised machine learning model, sharing training process\nincluding training data provides an effective way to gain trust and to better\nunderstand model predictions. However, it is not always possible to share all\ntraining data due to privacy and policy constraints. In this paper, we propose\na method to disclose a small set of training data that is just sufficient for\nusers to get the insight of a complicated model. The method constructs a\nboundary tree using selected training data and the tree is able to approximate\nthe complicated model with high fidelity. We show that traversing data points\nin the tree gives users significantly better understanding of the model and\npaves the way for trustworthy model sharing.\n", "versions": [{"version": "v1", "created": "Tue, 12 Sep 2017 08:13:24 GMT"}], "update_date": "2017-09-14", "authors_parsed": [["Wu", "Huijun", ""], ["Wang", "Chen", ""], ["Yin", "Jie", ""], ["Lu", "Kai", ""], ["Zhu", "Liming", ""]]}, {"id": "1709.03741", "submitter": "Junying Li", "authors": "Junying Li, Deng Cai, Xiaofei He", "title": "Learning Graph-Level Representation for Drug Discovery", "comments": "arXiv admin note: text overlap with arXiv:1703.00564,\n  arXiv:1611.03199 by other authors", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Predicating macroscopic influences of drugs on human body, like efficacy and\ntoxicity, is a central problem of small-molecule based drug discovery.\nMolecules can be represented as an undirected graph, and we can utilize graph\nconvolution networks to predication molecular properties. However, graph\nconvolutional networks and other graph neural networks all focus on learning\nnode-level representation rather than graph-level representation. Previous\nworks simply sum all feature vectors for all nodes in the graph to obtain the\ngraph feature vector for drug predication. In this paper, we introduce a dummy\nsuper node that is connected with all nodes in the graph by a directed edge as\nthe representation of the graph and modify the graph operation to help the\ndummy super node learn graph-level feature. Thus, we can handle graph-level\nclassification and regression in the same way as node-level classification and\nregression. In addition, we apply focal loss to address class imbalance in drug\ndatasets. The experiments on MoleculeNet show that our method can effectively\nimprove the performance of molecular properties predication.\n", "versions": [{"version": "v1", "created": "Tue, 12 Sep 2017 08:41:39 GMT"}, {"version": "v2", "created": "Sat, 16 Sep 2017 03:21:59 GMT"}], "update_date": "2017-09-19", "authors_parsed": [["Li", "Junying", ""], ["Cai", "Deng", ""], ["He", "Xiaofei", ""]]}, {"id": "1709.03749", "submitter": "Siavash Arjomand Bigdeli", "authors": "Siavash Arjomand Bigdeli, Meiguang Jin, Paolo Favaro, Matthias Zwicker", "title": "Deep Mean-Shift Priors for Image Restoration", "comments": "NIPS 2017", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we introduce a natural image prior that directly represents a\nGaussian-smoothed version of the natural image distribution. We include our\nprior in a formulation of image restoration as a Bayes estimator that also\nallows us to solve noise-blind image restoration problems. We show that the\ngradient of our prior corresponds to the mean-shift vector on the natural image\ndistribution. In addition, we learn the mean-shift vector field using denoising\nautoencoders, and use it in a gradient descent approach to perform Bayes risk\nminimization. We demonstrate competitive results for noise-blind deblurring,\nsuper-resolution, and demosaicing.\n", "versions": [{"version": "v1", "created": "Tue, 12 Sep 2017 09:11:24 GMT"}, {"version": "v2", "created": "Wed, 4 Oct 2017 13:13:53 GMT"}], "update_date": "2017-10-05", "authors_parsed": [["Bigdeli", "Siavash Arjomand", ""], ["Jin", "Meiguang", ""], ["Favaro", "Paolo", ""], ["Zwicker", "Matthias", ""]]}, {"id": "1709.03768", "submitter": "Dacheng Tao", "authors": "Jiacheng Cheng, Tongliang Liu, Kotagiri Ramamohanarao, Dacheng Tao", "title": "Learning with Bounded Instance- and Label-dependent Label Noise", "comments": "Published in the International Conference on Machine Learning (ICML),\n  2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Instance- and Label-dependent label Noise (ILN) widely exists in real-world\ndatasets but has been rarely studied. In this paper, we focus on Bounded\nInstance- and Label-dependent label Noise (BILN), a particular case of ILN\nwhere the label noise rates -- the probabilities that the true labels of\nexamples flip into the corrupted ones -- have upper bound less than $1$.\nSpecifically, we introduce the concept of distilled examples, i.e. examples\nwhose labels are identical with the labels assigned for them by the Bayes\noptimal classifier, and prove that under certain conditions classifiers learnt\non distilled examples will converge to the Bayes optimal classifier. Inspired\nby the idea of learning with distilled examples, we then propose a learning\nalgorithm with theoretical guarantees for its robustness to BILN. At last,\nempirical evaluations on both synthetic and real-world datasets show\neffectiveness of our algorithm in learning with BILN.\n", "versions": [{"version": "v1", "created": "Tue, 12 Sep 2017 09:59:59 GMT"}, {"version": "v2", "created": "Sun, 3 Mar 2019 23:18:29 GMT"}, {"version": "v3", "created": "Fri, 11 Dec 2020 03:38:12 GMT"}], "update_date": "2020-12-14", "authors_parsed": [["Cheng", "Jiacheng", ""], ["Liu", "Tongliang", ""], ["Ramamohanarao", "Kotagiri", ""], ["Tao", "Dacheng", ""]]}, {"id": "1709.03831", "submitter": "Tu Dinh Nguyen", "authors": "Tu Dinh Nguyen, Trung Le, Hung Vu, Dinh Phung", "title": "Dual Discriminator Generative Adversarial Nets", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose in this paper a novel approach to tackle the problem of mode\ncollapse encountered in generative adversarial network (GAN). Our idea is\nintuitive but proven to be very effective, especially in addressing some key\nlimitations of GAN. In essence, it combines the Kullback-Leibler (KL) and\nreverse KL divergences into a unified objective function, thus it exploits the\ncomplementary statistical properties from these divergences to effectively\ndiversify the estimated density in capturing multi-modes. We term our method\ndual discriminator generative adversarial nets (D2GAN) which, unlike GAN, has\ntwo discriminators; and together with a generator, it also has the analogy of a\nminimax game, wherein a discriminator rewards high scores for samples from data\ndistribution whilst another discriminator, conversely, favoring data from the\ngenerator, and the generator produces data to fool both two discriminators. We\ndevelop theoretical analysis to show that, given the maximal discriminators,\noptimizing the generator of D2GAN reduces to minimizing both KL and reverse KL\ndivergences between data distribution and the distribution induced from the\ndata generated by the generator, hence effectively avoiding the mode collapsing\nproblem. We conduct extensive experiments on synthetic and real-world\nlarge-scale datasets (MNIST, CIFAR-10, STL-10, ImageNet), where we have made\nour best effort to compare our D2GAN with the latest state-of-the-art GAN's\nvariants in comprehensive qualitative and quantitative evaluations. The\nexperimental results demonstrate the competitive and superior performance of\nour approach in generating good quality and diverse samples over baselines, and\nthe capability of our method to scale up to ImageNet database.\n", "versions": [{"version": "v1", "created": "Tue, 12 Sep 2017 13:28:48 GMT"}], "update_date": "2017-09-13", "authors_parsed": [["Nguyen", "Tu Dinh", ""], ["Le", "Trung", ""], ["Vu", "Hung", ""], ["Phung", "Dinh", ""]]}, {"id": "1709.03853", "submitter": "Nasser Mohammadiha", "authors": "Christopher Innocenti, Henrik Lind\\'en, Ghazaleh Panahandeh, Lennart\n  Svensson, Nasser Mohammadiha", "title": "Imitation Learning for Vision-based Lane Keeping Assistance", "comments": "International Conference on Intelligent Transportation Systems (ITSC)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper aims to investigate direct imitation learning from human drivers\nfor the task of lane keeping assistance in highway and country roads using\ngrayscale images from a single front view camera. The employed method utilizes\nconvolutional neural networks (CNN) to act as a policy that is driving a\nvehicle. The policy is successfully learned via imitation learning using\nreal-world data collected from human drivers and is evaluated in closed-loop\nsimulated environments, demonstrating good driving behaviour and a robustness\nfor domain changes. Evaluation is based on two proposed performance metrics\nmeasuring how well the vehicle is positioned in a lane and the smoothness of\nthe driven trajectory.\n", "versions": [{"version": "v1", "created": "Tue, 12 Sep 2017 14:06:32 GMT"}], "update_date": "2017-09-13", "authors_parsed": [["Innocenti", "Christopher", ""], ["Lind\u00e9n", "Henrik", ""], ["Panahandeh", "Ghazaleh", ""], ["Svensson", "Lennart", ""], ["Mohammadiha", "Nasser", ""]]}, {"id": "1709.03854", "submitter": "Ivan Olier", "authors": "Ivan Olier, Noureddin Sadawi, G. Richard Bickerton, Joaquin\n  Vanschoren, Crina Grosan, Larisa Soldatova and Ross D. King", "title": "Meta-QSAR: a large-scale application of meta-learning to drug design and\n  discovery", "comments": "33 pages and 15 figures. Manuscript accepted for publication in\n  Machine Learning Journal. This is the author's pre-print version", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We investigate the learning of quantitative structure activity relationships\n(QSARs) as a case-study of meta-learning. This application area is of the\nhighest societal importance, as it is a key step in the development of new\nmedicines. The standard QSAR learning problem is: given a target (usually a\nprotein) and a set of chemical compounds (small molecules) with associated\nbioactivities (e.g. inhibition of the target), learn a predictive mapping from\nmolecular representation to activity. Although almost every type of machine\nlearning method has been applied to QSAR learning there is no agreed single\nbest way of learning QSARs, and therefore the problem area is well-suited to\nmeta-learning. We first carried out the most comprehensive ever comparison of\nmachine learning methods for QSAR learning: 18 regression methods, 6 molecular\nrepresentations, applied to more than 2,700 QSAR problems. (These results have\nbeen made publicly available on OpenML and represent a valuable resource for\ntesting novel meta-learning methods.) We then investigated the utility of\nalgorithm selection for QSAR problems. We found that this meta-learning\napproach outperformed the best individual QSAR learning method (random forests\nusing a molecular fingerprint representation) by up to 13%, on average. We\nconclude that meta-learning outperforms base-learning methods for QSAR\nlearning, and as this investigation is one of the most extensive ever\ncomparisons of base and meta-learning methods ever made, it provides evidence\nfor the general effectiveness of meta-learning over base-learning.\n", "versions": [{"version": "v1", "created": "Tue, 12 Sep 2017 14:07:13 GMT"}], "update_date": "2017-09-13", "authors_parsed": [["Olier", "Ivan", ""], ["Sadawi", "Noureddin", ""], ["Bickerton", "G. Richard", ""], ["Vanschoren", "Joaquin", ""], ["Grosan", "Crina", ""], ["Soldatova", "Larisa", ""], ["King", "Ross D.", ""]]}, {"id": "1709.03871", "submitter": "Roi Livni", "authors": "Pravesh K. Kothari and Roi Livni", "title": "Agnostic Learning by Refuting", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The sample complexity of learning a Boolean-valued function class is\nprecisely characterized by its Rademacher complexity. This has little bearing,\nhowever, on the sample complexity of \\emph{efficient} agnostic learning.\n  We introduce \\emph{refutation complexity}, a natural computational analog of\nRademacher complexity of a Boolean concept class and show that it exactly\ncharacterizes the sample complexity of \\emph{efficient} agnostic learning.\nInformally, refutation complexity of a class $\\mathcal{C}$ is the minimum\nnumber of example-label pairs required to efficiently distinguish between the\ncase that the labels correlate with the evaluation of some member of\n$\\mathcal{C}$ (\\emph{structure}) and the case where the labels are i.i.d.\nRademacher random variables (\\emph{noise}). The easy direction of this\nrelationship was implicitly used in the recent framework for improper PAC\nlearning lower bounds of Daniely and co-authors via connections to the hardness\nof refuting random constraint satisfaction problems. Our work can be seen as\nmaking the relationship between agnostic learning and refutation implicit in\ntheir work into an explicit equivalence. In a recent, independent work, Salil\nVadhan discovered a similar relationship between refutation and PAC-learning in\nthe realizable (i.e. noiseless) case.\n", "versions": [{"version": "v1", "created": "Tue, 12 Sep 2017 14:43:58 GMT"}, {"version": "v2", "created": "Thu, 30 Nov 2017 16:47:17 GMT"}], "update_date": "2017-12-01", "authors_parsed": [["Kothari", "Pravesh K.", ""], ["Livni", "Roi", ""]]}, {"id": "1709.03891", "submitter": "Sijie He", "authors": "Jamal Golmohammadi, Imme Ebert-Uphoff, Sijie He, Yi Deng and Arindam\n  Banerjee", "title": "High-Dimensional Dependency Structure Learning for Physical Processes", "comments": "21 pages, 8 figures, International Conference on Data Mining 2017", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we consider the use of structure learning methods for\nprobabilistic graphical models to identify statistical dependencies in\nhigh-dimensional physical processes. Such processes are often synthetically\ncharacterized using PDEs (partial differential equations) and are observed in a\nvariety of natural phenomena, including geoscience data capturing atmospheric\nand hydrological phenomena. Classical structure learning approaches such as the\nPC algorithm and variants are challenging to apply due to their high\ncomputational and sample requirements. Modern approaches, often based on sparse\nregression and variants, do come with finite sample guarantees, but are usually\nhighly sensitive to the choice of hyper-parameters, e.g., parameter $\\lambda$\nfor sparsity inducing constraint or regularization. In this paper, we present\nACLIME-ADMM, an efficient two-step algorithm for adaptive structure learning,\nwhich estimates an edge specific parameter $\\lambda_{ij}$ in the first step,\nand uses these parameters to learn the structure in the second step. Both steps\nof our algorithm use (inexact) ADMM to solve suitable linear programs, and all\niterations can be done in closed form in an efficient block parallel manner. We\ncompare ACLIME-ADMM with baselines on both synthetic data simulated by partial\ndifferential equations (PDEs) that model advection-diffusion processes, and\nreal data (50 years) of daily global geopotential heights to study information\nflow in the atmosphere. ACLIME-ADMM is shown to be efficient, stable, and\ncompetitive, usually better than the baselines especially on difficult\nproblems. On real data, ACLIME-ADMM recovers the underlying structure of global\natmospheric circulation, including switches in wind directions at the equator\nand tropics entirely from the data.\n", "versions": [{"version": "v1", "created": "Tue, 12 Sep 2017 14:54:57 GMT"}], "update_date": "2017-09-13", "authors_parsed": [["Golmohammadi", "Jamal", ""], ["Ebert-Uphoff", "Imme", ""], ["He", "Sijie", ""], ["Deng", "Yi", ""], ["Banerjee", "Arindam", ""]]}, {"id": "1709.03919", "submitter": "Boyi Li", "authors": "Boyi Li and Xiulian Peng and Zhangyang Wang and Jizheng Xu and Dan\n  Feng", "title": "End-to-End United Video Dehazing and Detection", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The recent development of CNN-based image dehazing has revealed the\neffectiveness of end-to-end modeling. However, extending the idea to end-to-end\nvideo dehazing has not been explored yet. In this paper, we propose an\nEnd-to-End Video Dehazing Network (EVD-Net), to exploit the temporal\nconsistency between consecutive video frames. A thorough study has been\nconducted over a number of structure options, to identify the best temporal\nfusion strategy. Furthermore, we build an End-to-End United Video Dehazing and\nDetection Network(EVDD-Net), which concatenates and jointly trains EVD-Net with\na video object detection model. The resulting augmented end-to-end pipeline has\ndemonstrated much more stable and accurate detection results in hazy video.\n", "versions": [{"version": "v1", "created": "Tue, 12 Sep 2017 15:43:28 GMT"}], "update_date": "2017-09-13", "authors_parsed": [["Li", "Boyi", ""], ["Peng", "Xiulian", ""], ["Wang", "Zhangyang", ""], ["Xu", "Jizheng", ""], ["Feng", "Dan", ""]]}, {"id": "1709.03942", "submitter": "Yu Jing", "authors": "Song Wang, Yu Jing", "title": "Deep Reinforcement Learning with Surrogate Agent-Environment Interface", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  In this paper, we propose surrogate agent-environment interface (SAEI) in\nreinforcement learning. We also state that learning based on probability\nsurrogate agent-environment interface provides optimal policy of task\nagent-environment interface. We introduce surrogate probability action and\ndevelop the probability surrogate action deterministic policy gradient (PSADPG)\nalgorithm based on SAEI. This algorithm enables continuous control of discrete\naction. The experiments show PSADPG achieves the performance of DQN in certain\ntasks with the stochastic optimal policy nature in the initial training stage.\n", "versions": [{"version": "v1", "created": "Tue, 12 Sep 2017 16:35:09 GMT"}, {"version": "v2", "created": "Sat, 4 Nov 2017 06:16:10 GMT"}, {"version": "v3", "created": "Fri, 10 Nov 2017 14:46:16 GMT"}], "update_date": "2017-11-13", "authors_parsed": [["Wang", "Song", ""], ["Jing", "Yu", ""]]}, {"id": "1709.03943", "submitter": "Erik Bartos", "authors": "Kabin Kanjamapornkul, Richard Pin\\v{c}\\'ak, Sanphet Chunithpaisan,\n  Erik Barto\\v{s}", "title": "Support Spinor Machine", "comments": "18 pages, 12 figures, 6 tables", "journal-ref": "Digital Signal Processing 70 (2017) 59-72", "doi": "10.1016/j.dsp.2017.07.023", "report-no": null, "categories": "cs.LG eess.SP q-fin.ST stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We generalize a support vector machine to a support spinor machine by using\nthe mathematical structure of wedge product over vector machine in order to\nextend field from vector field to spinor field. The separated hyperplane is\nextended to Kolmogorov space in time series data which allow us to extend a\nstructure of support vector machine to a support tensor machine and a support\ntensor machine moduli space. Our performance test on support spinor machine is\ndone over one class classification of end point in physiology state of time\nseries data after empirical mode analysis and compared with support vector\nmachine test. We implement algorithm of support spinor machine by using\nHolo-Hilbert amplitude modulation for fully nonlinear and nonstationary time\nseries data analysis.\n", "versions": [{"version": "v1", "created": "Mon, 11 Sep 2017 07:23:57 GMT"}], "update_date": "2017-09-18", "authors_parsed": [["Kanjamapornkul", "Kabin", ""], ["Pin\u010d\u00e1k", "Richard", ""], ["Chunithpaisan", "Sanphet", ""], ["Barto\u0161", "Erik", ""]]}, {"id": "1709.03946", "submitter": "Nikhita Vedula", "authors": "Nikhita Vedula, Wei Sun, Hyunhwan Lee, Harsh Gupta, Mitsunori Ogihara,\n  Joseph Johnson, Gang Ren, Srinivasan Parthasarathy", "title": "Multimodal Content Analysis for Effective Advertisements on YouTube", "comments": "11 pages, 5 figures, ICDM 2017", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG cs.MM cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The rapid advances in e-commerce and Web 2.0 technologies have greatly\nincreased the impact of commercial advertisements on the general public. As a\nkey enabling technology, a multitude of recommender systems exists which\nanalyzes user features and browsing patterns to recommend appealing\nadvertisements to users. In this work, we seek to study the characteristics or\nattributes that characterize an effective advertisement and recommend a useful\nset of features to aid the designing and production processes of commercial\nadvertisements. We analyze the temporal patterns from multimedia content of\nadvertisement videos including auditory, visual and textual components, and\nstudy their individual roles and synergies in the success of an advertisement.\nThe objective of this work is then to measure the effectiveness of an\nadvertisement, and to recommend a useful set of features to advertisement\ndesigners to make it more successful and approachable to users. Our proposed\nframework employs the signal processing technique of cross modality feature\nlearning where data streams from different components are employed to train\nseparate neural network models and are then fused together to learn a shared\nrepresentation. Subsequently, a neural network model trained on this joint\nfeature embedding representation is utilized as a classifier to predict\nadvertisement effectiveness. We validate our approach using subjective ratings\nfrom a dedicated user study, the sentiment strength of online viewer comments,\nand a viewer opinion metric of the ratio of the Likes and Views received by\neach advertisement from an online platform.\n", "versions": [{"version": "v1", "created": "Tue, 12 Sep 2017 16:47:21 GMT"}], "update_date": "2017-09-13", "authors_parsed": [["Vedula", "Nikhita", ""], ["Sun", "Wei", ""], ["Lee", "Hyunhwan", ""], ["Gupta", "Harsh", ""], ["Ogihara", "Mitsunori", ""], ["Johnson", "Joseph", ""], ["Ren", "Gang", ""], ["Parthasarathy", "Srinivasan", ""]]}, {"id": "1709.03980", "submitter": "Wen Zhang", "authors": "Wen Zhang, Jiawei Hu, Yang Feng, Qun Liu", "title": "Refining Source Representations with Relation Networks for Neural\n  Machine Translation", "comments": "i am planned to improve my experiments and modified our paper", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Although neural machine translation (NMT) with the encoder-decoder framework\nhas achieved great success in recent times, it still suffers from some\ndrawbacks: RNNs tend to forget old information which is often useful and the\nencoder only operates through words without considering word relationship. To\nsolve these problems, we introduce a relation networks (RN) into NMT to refine\nthe encoding representations of the source. In our method, the RN first\naugments the representation of each source word with its neighbors and reasons\nall the possible pairwise relations between them. Then the source\nrepresentations and all the relations are fed to the attention module and the\ndecoder together, keeping the main encoder-decoder architecture unchanged.\nExperiments on two Chinese-to-English data sets in different scales both show\nthat our method can outperform the competitive baselines significantly.\n", "versions": [{"version": "v1", "created": "Tue, 12 Sep 2017 13:38:11 GMT"}, {"version": "v2", "created": "Wed, 8 Nov 2017 08:20:13 GMT"}, {"version": "v3", "created": "Fri, 25 May 2018 13:36:08 GMT"}], "update_date": "2018-05-28", "authors_parsed": [["Zhang", "Wen", ""], ["Hu", "Jiawei", ""], ["Feng", "Yang", ""], ["Liu", "Qun", ""]]}, {"id": "1709.04004", "submitter": "Xueying Guo", "authors": "Huasen Wu, Xueying Guo, Xin Liu", "title": "Adaptive Exploration-Exploitation Tradeoff for Opportunistic Bandits", "comments": "In Proceedings of the 35th International Conference on Machine\n  Learning (ICML), 2018, pp. 5306-5314, Stockholmsm\\\"assan, Stockholm Sweden,\n  ICML 2018. (PMLR 80:5306-5314)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we propose and study opportunistic bandits - a new variant of\nbandits where the regret of pulling a suboptimal arm varies under different\nenvironmental conditions, such as network load or produce price. When the\nload/price is low, so is the cost/regret of pulling a suboptimal arm (e.g.,\ntrying a suboptimal network configuration). Therefore, intuitively, we could\nexplore more when the load/price is low and exploit more when the load/price is\nhigh. Inspired by this intuition, we propose an Adaptive Upper-Confidence-Bound\n(AdaUCB) algorithm to adaptively balance the exploration-exploitation tradeoff\nfor opportunistic bandits. We prove that AdaUCB achieves $O(\\log T)$ regret\nwith a smaller coefficient than the traditional UCB algorithm. Furthermore,\nAdaUCB achieves $O(1)$ regret with respect to $T$ if the exploration cost is\nzero when the load level is below a certain threshold. Last, based on both\nsynthetic data and real-world traces, experimental results show that AdaUCB\nsignificantly outperforms other bandit algorithms, such as UCB and TS (Thompson\nSampling), under large load/price fluctuations.\n", "versions": [{"version": "v1", "created": "Tue, 12 Sep 2017 18:18:33 GMT"}, {"version": "v2", "created": "Fri, 30 Nov 2018 18:38:12 GMT"}], "update_date": "2018-12-03", "authors_parsed": [["Wu", "Huasen", ""], ["Guo", "Xueying", ""], ["Liu", "Xin", ""]]}, {"id": "1709.04054", "submitter": "Lars Eidnes", "authors": "Lars Eidnes, Arild N{\\o}kland", "title": "Shifting Mean Activation Towards Zero with Bipolar Activation Functions", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a simple extension to the ReLU-family of activation functions that\nallows them to shift the mean activation across a layer towards zero. Combined\nwith proper weight initialization, this alleviates the need for normalization\nlayers. We explore the training of deep vanilla recurrent neural networks\n(RNNs) with up to 144 layers, and show that bipolar activation functions help\nlearning in this setting. On the Penn Treebank and Text8 language modeling\ntasks we obtain competitive results, improving on the best reported results for\nnon-gated networks. In experiments with convolutional neural networks without\nbatch normalization, we find that bipolar activations produce a faster drop in\ntraining error, and results in a lower test error on the CIFAR-10\nclassification task.\n", "versions": [{"version": "v1", "created": "Tue, 12 Sep 2017 20:44:15 GMT"}, {"version": "v2", "created": "Mon, 18 Dec 2017 20:18:47 GMT"}, {"version": "v3", "created": "Thu, 15 Mar 2018 01:59:24 GMT"}], "update_date": "2018-03-16", "authors_parsed": [["Eidnes", "Lars", ""], ["N\u00f8kland", "Arild", ""]]}, {"id": "1709.04057", "submitter": "Eric Martin", "authors": "Eric Martin, Chris Cundy", "title": "Parallelizing Linear Recurrent Neural Nets Over Sequence Length", "comments": "9 pages. Published as a conference paper at ICLR 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recurrent neural networks (RNNs) are widely used to model sequential data but\ntheir non-linear dependencies between sequence elements prevent parallelizing\ntraining over sequence length. We show the training of RNNs with only linear\nsequential dependencies can be parallelized over the sequence length using the\nparallel scan algorithm, leading to rapid training on long sequences even with\nsmall minibatch size. We develop a parallel linear recurrence CUDA kernel and\nshow that it can be applied to immediately speed up training and inference of\nseveral state of the art RNN architectures by up to 9x. We abstract recent work\non linear RNNs into a new framework of linear surrogate RNNs and develop a\nlinear surrogate model for the long short-term memory unit, the GILR-LSTM, that\nutilizes parallel linear recurrence. We extend sequence learning to new\nextremely long sequence regimes that were previously out of reach by\nsuccessfully training a GILR-LSTM on a synthetic sequence classification task\nwith a one million timestep dependency.\n", "versions": [{"version": "v1", "created": "Tue, 12 Sep 2017 20:52:22 GMT"}, {"version": "v2", "created": "Thu, 22 Feb 2018 05:38:25 GMT"}], "update_date": "2018-02-23", "authors_parsed": [["Martin", "Eric", ""], ["Cundy", "Chris", ""]]}, {"id": "1709.04071", "submitter": "Yuyu Zhang", "authors": "Yuyu Zhang, Hanjun Dai, Zornitsa Kozareva, Alexander J. Smola, Le Song", "title": "Variational Reasoning for Question Answering with Knowledge Graph", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Knowledge graph (KG) is known to be helpful for the task of question\nanswering (QA), since it provides well-structured relational information\nbetween entities, and allows one to further infer indirect facts. However, it\nis challenging to build QA systems which can learn to reason over knowledge\ngraphs based on question-answer pairs alone. First, when people ask questions,\ntheir expressions are noisy (for example, typos in texts, or variations in\npronunciations), which is non-trivial for the QA system to match those\nmentioned entities to the knowledge graph. Second, many questions require\nmulti-hop logic reasoning over the knowledge graph to retrieve the answers. To\naddress these challenges, we propose a novel and unified deep learning\narchitecture, and an end-to-end variational learning algorithm which can handle\nnoise in questions, and learn multi-hop reasoning simultaneously. Our method\nachieves state-of-the-art performance on a recent benchmark dataset in the\nliterature. We also derive a series of new benchmark datasets, including\nquestions for multi-hop reasoning, questions paraphrased by neural translation\nmodel, and questions in human voice. Our method yields very promising results\non all these challenging datasets.\n", "versions": [{"version": "v1", "created": "Tue, 12 Sep 2017 22:27:34 GMT"}, {"version": "v2", "created": "Thu, 14 Sep 2017 06:24:24 GMT"}, {"version": "v3", "created": "Thu, 12 Oct 2017 23:18:47 GMT"}, {"version": "v4", "created": "Tue, 21 Nov 2017 00:33:53 GMT"}, {"version": "v5", "created": "Mon, 27 Nov 2017 21:58:40 GMT"}], "update_date": "2017-11-29", "authors_parsed": [["Zhang", "Yuyu", ""], ["Dai", "Hanjun", ""], ["Kozareva", "Zornitsa", ""], ["Smola", "Alexander J.", ""], ["Song", "Le", ""]]}, {"id": "1709.04073", "submitter": "Chandrashekar Lakshminarayanan", "authors": "Chandrashekar Lakshminarayanan and Csaba Szepesv\\'ari", "title": "Linear Stochastic Approximation: Constant Step-Size and Iterate\n  Averaging", "comments": "16 pages, 2 figures, was submitted to NIPS 2017", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.SY stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider $d$-dimensional linear stochastic approximation algorithms (LSAs)\nwith a constant step-size and the so called Polyak-Ruppert (PR) averaging of\niterates. LSAs are widely applied in machine learning and reinforcement\nlearning (RL), where the aim is to compute an appropriate $\\theta_{*} \\in\n\\mathbb{R}^d$ (that is an optimum or a fixed point) using noisy data and $O(d)$\nupdates per iteration. In this paper, we are motivated by the problem (in RL)\nof policy evaluation from experience replay using the \\emph{temporal\ndifference} (TD) class of learning algorithms that are also LSAs. For LSAs with\na constant step-size, and PR averaging, we provide bounds for the mean squared\nerror (MSE) after $t$ iterations. We assume that data is \\iid with finite\nvariance (underlying distribution being $P$) and that the expected dynamics is\nHurwitz. For a given LSA with PR averaging, and data distribution $P$\nsatisfying the said assumptions, we show that there exists a range of constant\nstep-sizes such that its MSE decays as $O(\\frac{1}{t})$.\n  We examine the conditions under which a constant step-size can be chosen\nuniformly for a class of data distributions $\\mathcal{P}$, and show that not\nall data distributions `admit' such a uniform constant step-size. We also\nsuggest a heuristic step-size tuning algorithm to choose a constant step-size\nof a given LSA for a given data distribution $P$. We compare our results with\nrelated work and also discuss the implication of our results in the context of\nTD algorithms that are LSAs.\n", "versions": [{"version": "v1", "created": "Tue, 12 Sep 2017 22:34:09 GMT"}], "update_date": "2017-09-14", "authors_parsed": [["Lakshminarayanan", "Chandrashekar", ""], ["Szepesv\u00e1ri", "Csaba", ""]]}, {"id": "1709.04083", "submitter": "Yunshu Du", "authors": "Gabriel V. de la Cruz Jr, Yunshu Du and Matthew E. Taylor", "title": "Pre-training Neural Networks with Human Demonstrations for Deep\n  Reinforcement Learning", "comments": "ALA 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep reinforcement learning (deep RL) has achieved superior performance in\ncomplex sequential tasks by using a deep neural network as its function\napproximator and by learning directly from raw images. A drawback of using raw\nimages is that deep RL must learn the state feature representation from the raw\nimages in addition to learning a policy. As a result, deep RL can require a\nprohibitively large amount of training time and data to reach reasonable\nperformance, making it difficult to use deep RL in real-world applications,\nespecially when data is expensive. In this work, we speed up training by\naddressing half of what deep RL is trying to solve --- learning features. Our\napproach is to learn some of the important features by pre-training deep RL\nnetwork's hidden layers via supervised learning using a small set of human\ndemonstrations. We empirically evaluate our approach using deep Q-network (DQN)\nand asynchronous advantage actor-critic (A3C) algorithms on the Atari 2600\ngames of Pong, Freeway, and Beamrider. Our results show that: 1) pre-training\nwith human demonstrations in a supervised learning manner is better at\ndiscovering features relative to pre-training naively in DQN, and 2)\ninitializing a deep RL network with a pre-trained model provides a significant\nimprovement in training time even when pre-training from a small number of\nhuman demonstrations.\n", "versions": [{"version": "v1", "created": "Tue, 12 Sep 2017 23:17:45 GMT"}, {"version": "v2", "created": "Sat, 6 Apr 2019 21:59:20 GMT"}], "update_date": "2019-04-09", "authors_parsed": [["Cruz", "Gabriel V. de la", "Jr"], ["Du", "Yunshu", ""], ["Taylor", "Matthew E.", ""]]}, {"id": "1709.04090", "submitter": "Yanjun  Qi Dr.", "authors": "Chandan Singh, Beilun Wang, Yanjun Qi", "title": "A Constrained, Weighted-L1 Minimization Approach for Joint Discovery of\n  Heterogeneous Neural Connectivity Graphs", "comments": "8 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.NC cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Determining functional brain connectivity is crucial to understanding the\nbrain and neural differences underlying disorders such as autism. Recent\nstudies have used Gaussian graphical models to learn brain connectivity via\nstatistical dependencies across brain regions from neuroimaging. However,\nprevious studies often fail to properly incorporate priors tailored to\nneuroscience, such as preferring shorter connections. To remedy this problem,\nthe paper here introduces a novel, weighted-$\\ell_1$, multi-task graphical\nmodel (W-SIMULE). This model elegantly incorporates a flexible prior, along\nwith a parallelizable formulation. Additionally, W-SIMULE extends the\noften-used Gaussian assumption, leading to considerable performance increases.\nHere, applications to fMRI data show that W-SIMULE succeeds in determining\nfunctional connectivity in terms of (1) log-likelihood, (2) finding edges that\ndifferentiate groups, and (3) classifying different groups based on their\nconnectivity, achieving 58.6\\% accuracy on the ABIDE dataset. Having\nestablished W-SIMULE's effectiveness, it links four key areas to autism, all of\nwhich are consistent with the literature. Due to its elegant domain adaptivity,\nW-SIMULE can be readily applied to various data types to effectively estimate\nconnectivity.\n", "versions": [{"version": "v1", "created": "Wed, 13 Sep 2017 00:05:20 GMT"}, {"version": "v2", "created": "Thu, 21 Sep 2017 15:18:23 GMT"}], "update_date": "2017-09-22", "authors_parsed": [["Singh", "Chandan", ""], ["Wang", "Beilun", ""], ["Qi", "Yanjun", ""]]}, {"id": "1709.04108", "submitter": "Ehsan Mohammady Ardehaly", "authors": "Ehsan Mohammady Ardehaly, Aron Culotta", "title": "Co-training for Demographic Classification Using Deep Learning from\n  Label Proportions", "comments": null, "journal-ref": null, "doi": "10.1109/ICDMW.2017.144", "report-no": null, "categories": "cs.CV cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep learning algorithms have recently produced state-of-the-art accuracy in\nmany classification tasks, but this success is typically dependent on access to\nmany annotated training examples. For domains without such data, an attractive\nalternative is to train models with light, or distant supervision. In this\npaper, we introduce a deep neural network for the Learning from Label\nProportion (LLP) setting, in which the training data consist of bags of\nunlabeled instances with associated label distributions for each bag. We\nintroduce a new regularization layer, Batch Averager, that can be appended to\nthe last layer of any deep neural network to convert it from supervised\nlearning to LLP. This layer can be implemented readily with existing deep\nlearning packages. To further support domains in which the data consist of two\nconditionally independent feature views (e.g. image and text), we propose a\nco-training algorithm that iteratively generates pseudo bags and refits the\ndeep LLP model to improve classification accuracy. We demonstrate our models on\ndemographic attribute classification (gender and race/ethnicity), which has\nmany applications in social media analysis, public health, and marketing. We\nconduct experiments to predict demographics of Twitter users based on their\ntweets and profile image, without requiring any user-level annotations for\ntraining. We find that the deep LLP approach outperforms baselines for both\ntext and image features separately. Additionally, we find that co-training\nalgorithm improves image and text classification by 4% and 8% absolute F1,\nrespectively. Finally, an ensemble of text and image classifiers further\nimproves the absolute F1 measure by 4% on average.\n", "versions": [{"version": "v1", "created": "Wed, 13 Sep 2017 02:06:19 GMT"}], "update_date": "2018-01-01", "authors_parsed": [["Ardehaly", "Ehsan Mohammady", ""], ["Culotta", "Aron", ""]]}, {"id": "1709.04109", "submitter": "Liyuan Liu", "authors": "Liyuan Liu, Jingbo Shang, Frank F. Xu, Xiang Ren, Huan Gui, Jian Peng,\n  Jiawei Han", "title": "Empower Sequence Labeling with Task-Aware Neural Language Model", "comments": "AAAI 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Linguistic sequence labeling is a general modeling approach that encompasses\na variety of problems, such as part-of-speech tagging and named entity\nrecognition. Recent advances in neural networks (NNs) make it possible to build\nreliable models without handcrafted features. However, in many cases, it is\nhard to obtain sufficient annotations to train these models. In this study, we\ndevelop a novel neural framework to extract abundant knowledge hidden in raw\ntexts to empower the sequence labeling task. Besides word-level knowledge\ncontained in pre-trained word embeddings, character-aware neural language\nmodels are incorporated to extract character-level knowledge. Transfer learning\ntechniques are further adopted to mediate different components and guide the\nlanguage model towards the key knowledge. Comparing to previous methods, these\ntask-specific knowledge allows us to adopt a more concise model and conduct\nmore efficient training. Different from most transfer learning methods, the\nproposed framework does not rely on any additional supervision. It extracts\nknowledge from self-contained order information of training sequences.\nExtensive experiments on benchmark datasets demonstrate the effectiveness of\nleveraging character-level knowledge and the efficiency of co-training. For\nexample, on the CoNLL03 NER task, model training completes in about 6 hours on\na single GPU, reaching F1 score of 91.71$\\pm$0.10 without using any extra\nannotation.\n", "versions": [{"version": "v1", "created": "Wed, 13 Sep 2017 02:13:25 GMT"}, {"version": "v2", "created": "Thu, 14 Sep 2017 03:39:38 GMT"}, {"version": "v3", "created": "Fri, 15 Sep 2017 06:51:06 GMT"}, {"version": "v4", "created": "Thu, 23 Nov 2017 23:12:40 GMT"}], "update_date": "2017-11-27", "authors_parsed": [["Liu", "Liyuan", ""], ["Shang", "Jingbo", ""], ["Xu", "Frank F.", ""], ["Ren", "Xiang", ""], ["Gui", "Huan", ""], ["Peng", "Jian", ""], ["Han", "Jiawei", ""]]}, {"id": "1709.04114", "submitter": "Pin-Yu Chen", "authors": "Pin-Yu Chen, Yash Sharma, Huan Zhang, Jinfeng Yi and Cho-Jui Hsieh", "title": "EAD: Elastic-Net Attacks to Deep Neural Networks via Adversarial\n  Examples", "comments": "To be published at AAAI 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.CR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent studies have highlighted the vulnerability of deep neural networks\n(DNNs) to adversarial examples - a visually indistinguishable adversarial image\ncan easily be crafted to cause a well-trained model to misclassify. Existing\nmethods for crafting adversarial examples are based on $L_2$ and $L_\\infty$\ndistortion metrics. However, despite the fact that $L_1$ distortion accounts\nfor the total variation and encourages sparsity in the perturbation, little has\nbeen developed for crafting $L_1$-based adversarial examples. In this paper, we\nformulate the process of attacking DNNs via adversarial examples as an\nelastic-net regularized optimization problem. Our elastic-net attacks to DNNs\n(EAD) feature $L_1$-oriented adversarial examples and include the\nstate-of-the-art $L_2$ attack as a special case. Experimental results on MNIST,\nCIFAR10 and ImageNet show that EAD can yield a distinct set of adversarial\nexamples with small $L_1$ distortion and attains similar attack performance to\nthe state-of-the-art methods in different attack scenarios. More importantly,\nEAD leads to improved attack transferability and complements adversarial\ntraining for DNNs, suggesting novel insights on leveraging $L_1$ distortion in\nadversarial machine learning and security implications of DNNs.\n", "versions": [{"version": "v1", "created": "Wed, 13 Sep 2017 02:40:59 GMT"}, {"version": "v2", "created": "Mon, 20 Nov 2017 19:59:47 GMT"}, {"version": "v3", "created": "Sat, 10 Feb 2018 04:49:12 GMT"}], "update_date": "2018-02-13", "authors_parsed": [["Chen", "Pin-Yu", ""], ["Sharma", "Yash", ""], ["Zhang", "Huan", ""], ["Yi", "Jinfeng", ""], ["Hsieh", "Cho-Jui", ""]]}, {"id": "1709.04129", "submitter": "Bokai Cao", "authors": "Bokai Cao, Mia Mao, Siim Viidu, Philip S. Yu", "title": "HitFraud: A Broad Learning Approach for Collective Fraud Detection in\n  Heterogeneous Information Networks", "comments": "ICDM 2017", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  On electronic game platforms, different payment transactions have different\nlevels of risk. Risk is generally higher for digital goods in e-commerce.\nHowever, it differs based on product and its popularity, the offer type\n(packaged game, virtual currency to a game or subscription service), storefront\nand geography. Existing fraud policies and models make decisions independently\nfor each transaction based on transaction attributes, payment velocities, user\ncharacteristics, and other relevant information. However, suspicious\ntransactions may still evade detection and hence we propose a broad learning\napproach leveraging a graph based perspective to uncover relationships among\nsuspicious transactions, i.e., inter-transaction dependency. Our focus is to\ndetect suspicious transactions by capturing common fraudulent behaviors that\nwould not be considered suspicious when being considered in isolation. In this\npaper, we present HitFraud that leverages heterogeneous information networks\nfor collective fraud detection by exploring correlated and fast evolving\nfraudulent behaviors. First, a heterogeneous information network is designed to\nlink entities of interest in the transaction database via different semantics.\nThen, graph based features are efficiently discovered from the network\nexploiting the concept of meta-paths, and decisions on frauds are made\ncollectively on test instances. Experiments on real-world payment transaction\ndata from Electronic Arts demonstrate that the prediction performance is\neffectively boosted by HitFraud with fast convergence where the computation of\nmeta-path based features is largely optimized. Notably, recall can be improved\nup to 7.93% and F-score 4.62% compared to baselines.\n", "versions": [{"version": "v1", "created": "Wed, 13 Sep 2017 04:02:30 GMT"}, {"version": "v2", "created": "Tue, 19 Sep 2017 19:52:25 GMT"}], "update_date": "2017-09-21", "authors_parsed": [["Cao", "Bokai", ""], ["Mao", "Mia", ""], ["Viidu", "Siim", ""], ["Yu", "Philip S.", ""]]}, {"id": "1709.04136", "submitter": "Lin Yang", "authors": "Lin Yang, Cheng Tan and Wing Shing Wong", "title": "Recursive Exponential Weighting for Online Non-convex Optimization", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we investigate the online non-convex optimization problem\nwhich generalizes the classic {online convex optimization problem by relaxing\nthe convexity assumption on the cost function.\n  For this type of problem, the classic exponential weighting online algorithm\nhas recently been shown to attain a sub-linear regret of $O(\\sqrt{T\\log T})$.\n  In this paper, we introduce a novel recursive structure to the online\nalgorithm to define a recursive exponential weighting algorithm that attains a\nregret of $O(\\sqrt{T})$, matching the well-known regret lower bound.\n  To the best of our knowledge, this is the first online algorithm with\nprovable $O(\\sqrt{T})$ regret for the online non-convex optimization problem.\n", "versions": [{"version": "v1", "created": "Wed, 13 Sep 2017 05:01:42 GMT"}], "update_date": "2017-09-14", "authors_parsed": [["Yang", "Lin", ""], ["Tan", "Cheng", ""], ["Wong", "Wing Shing", ""]]}, {"id": "1709.04212", "submitter": "Naoki Hayashi", "authors": "Naoki Hayashi and Sumio Watanabe", "title": "Asymptotic Bayesian Generalization Error in Latent Dirichlet Allocation\n  and Stochastic Matrix Factorization", "comments": "Containing 36 pages, 2 figures, and 1 table. To appear in SN Computer\n  Science", "journal-ref": "SN Computer Science volume 1, Article number: 69 (2020)", "doi": "10.1007/s42979-020-0071-3", "report-no": null, "categories": "math.ST cs.LG stat.ML stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Latent Dirichlet allocation (LDA) is useful in document analysis, image\nprocessing, and many information systems; however, its generalization\nperformance has been left unknown because it is a singular learning machine to\nwhich regular statistical theory can not be applied.\n  Stochastic matrix factorization (SMF) is a restricted matrix factorization in\nwhich matrix factors are stochastic; the column of the matrix is in a simplex.\nSMF is being applied to image recognition and text mining. We can understand\nSMF as a statistical model by which a stochastic matrix of given data is\nrepresented by a product of two stochastic matrices, whose generalization\nperformance has also been left unknown because of non-regularity.\n  In this paper, by using an algebraic and geometric method, we show the\nanalytic equivalence of LDA and SMF, both of which have the same real log\ncanonical threshold (RLCT), resulting in that they asymptotically have the same\nBayesian generalization error and the same log marginal likelihood. Moreover,\nwe derive the upper bound of the RLCT and prove that it is smaller than the\ndimension of the parameter divided by two, hence the Bayesian generalization\nerrors of them are smaller than those of regular statistical models.\n", "versions": [{"version": "v1", "created": "Wed, 13 Sep 2017 09:37:03 GMT"}, {"version": "v2", "created": "Thu, 12 Oct 2017 10:45:36 GMT"}, {"version": "v3", "created": "Mon, 4 Dec 2017 08:22:09 GMT"}, {"version": "v4", "created": "Wed, 6 Jun 2018 13:47:32 GMT"}, {"version": "v5", "created": "Sat, 23 Jun 2018 00:26:47 GMT"}, {"version": "v6", "created": "Mon, 14 Jan 2019 16:20:44 GMT"}, {"version": "v7", "created": "Fri, 22 Mar 2019 14:56:22 GMT"}, {"version": "v8", "created": "Thu, 30 Jan 2020 15:39:39 GMT"}], "update_date": "2020-02-21", "authors_parsed": [["Hayashi", "Naoki", ""], ["Watanabe", "Sumio", ""]]}, {"id": "1709.04271", "submitter": "Sam Toyer", "authors": "Sam Toyer, Felipe Trevizan, Sylvie Thi\\'ebaux, Lexing Xie", "title": "Action Schema Networks: Generalised Policies with Deep Learning", "comments": "Accepted to AAAI 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we introduce the Action Schema Network (ASNet): a neural\nnetwork architecture for learning generalised policies for probabilistic\nplanning problems. By mimicking the relational structure of planning problems,\nASNets are able to adopt a weight-sharing scheme which allows the network to be\napplied to any problem from a given planning domain. This allows the cost of\ntraining the network to be amortised over all problems in that domain. Further,\nwe propose a training method which balances exploration and supervised training\non small problems to produce a policy which remains robust when evaluated on\nlarger problems. In experiments, we show that ASNet's learning capability\nallows it to significantly outperform traditional non-learning planners in\nseveral challenging domains.\n", "versions": [{"version": "v1", "created": "Wed, 13 Sep 2017 12:15:52 GMT"}, {"version": "v2", "created": "Fri, 22 Dec 2017 07:59:26 GMT"}], "update_date": "2017-12-25", "authors_parsed": [["Toyer", "Sam", ""], ["Trevizan", "Felipe", ""], ["Thi\u00e9baux", "Sylvie", ""], ["Xie", "Lexing", ""]]}, {"id": "1709.04305", "submitter": "Tim Oates", "authors": "Zhiguang Wang, Chul Gwon, Tim Oates, Adam Iezzi", "title": "Automated Cloud Provisioning on AWS using Deep Reinforcement Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  As the use of cloud computing continues to rise, controlling cost becomes\nincreasingly important. Yet there is evidence that 30\\% - 45\\% of cloud spend\nis wasted. Existing tools for cloud provisioning typically rely on highly\ntrained human experts to specify what to monitor, thresholds for triggering\naction, and actions. In this paper we explore the use of reinforcement learning\n(RL) to acquire policies to balance performance and spend, allowing humans to\nspecify what they want as opposed to how to do it, minimizing the need for\ncloud expertise. Empirical results with tabular, deep, and dueling double deep\nQ-learning with the CloudSim simulator show the utility of RL and the relative\nmerits of the approaches. We also demonstrate effective policy transfer\nlearning from an extremely simple simulator to CloudSim, with the next step\nbeing transfer from CloudSim to an Amazon Web Services physical environment.\n", "versions": [{"version": "v1", "created": "Wed, 13 Sep 2017 13:06:43 GMT"}, {"version": "v2", "created": "Tue, 19 Sep 2017 14:45:59 GMT"}], "update_date": "2017-09-20", "authors_parsed": [["Wang", "Zhiguang", ""], ["Gwon", "Chul", ""], ["Oates", "Tim", ""], ["Iezzi", "Adam", ""]]}, {"id": "1709.04317", "submitter": "Mohammad Tarek Al Muallim M.Sc.", "authors": "Mohammad Tarek Al Muallim", "title": "Pattern Recognition using Artificial Immune System", "comments": "MSc Thesis, 126 pages, in Arabic", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this thesis, the uses of Artificial Immune Systems (AIS) in Machine\nlearning is studded. the thesis focus on some of immune inspired algorithms\nsuch as clonal selection algorithm and artificial immune network. The effect of\nchanging the algorithm parameter on its performance is studded. Then a new\nimmune inspired algorithm for unsupervised classification is proposed. The new\nalgorithm is based on clonal selection principle and named Unsupervised Clonal\nSelection Classification (UCSC). The new proposed algorithm is almost parameter\nfree. The algorithm parameters are data driven and it adjusts itself to make\nthe classification as fast as possible. The performance of UCSC is evaluated.\nThe experiments show that the proposed UCSC algorithm has a good performance\nand more reliable.\n", "versions": [{"version": "v1", "created": "Wed, 19 Apr 2017 07:09:47 GMT"}], "update_date": "2017-09-14", "authors_parsed": [["Muallim", "Mohammad Tarek Al", ""]]}, {"id": "1709.04380", "submitter": "Tianyu Li", "authors": "Tianyu Li, Guillaume Rabusseau, Doina Precup", "title": "Neural Network Based Nonlinear Weighted Finite Automata", "comments": "AISTATS 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.FL cs.AI cs.CL cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Weighted finite automata (WFA) can expressively model functions defined over\nstrings but are inherently linear models. Given the recent successes of\nnonlinear models in machine learning, it is natural to wonder whether\nex-tending WFA to the nonlinear setting would be beneficial. In this paper, we\npropose a novel model of neural network based nonlinearWFA model (NL-WFA) along\nwith a learning algorithm. Our learning algorithm is inspired by the spectral\nlearning algorithm for WFAand relies on a nonlinear decomposition of the\nso-called Hankel matrix, by means of an auto-encoder network. The expressive\npower of NL-WFA and the proposed learning algorithm are assessed on both\nsynthetic and real-world data, showing that NL-WFA can lead to smaller model\nsizes and infer complex grammatical structures from data.\n", "versions": [{"version": "v1", "created": "Wed, 13 Sep 2017 15:26:50 GMT"}, {"version": "v2", "created": "Thu, 21 Dec 2017 13:42:43 GMT"}], "update_date": "2017-12-22", "authors_parsed": [["Li", "Tianyu", ""], ["Rabusseau", "Guillaume", ""], ["Precup", "Doina", ""]]}, {"id": "1709.04384", "submitter": "Yu-Siang Huang", "authors": "Yu-Siang Huang, Szu-Yu Chou, Yi-Hsuan Yang", "title": "Generating Music Medleys via Playing Music Puzzle Games", "comments": "Accepted at AAAI 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG cs.SD", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Generating music medleys is about finding an optimal permutation of a given\nset of music clips. Toward this goal, we propose a self-supervised learning\ntask, called the music puzzle game, to train neural network models to learn the\nsequential patterns in music. In essence, such a game requires machines to\ncorrectly sort a few multisecond music fragments. In the training stage, we\nlearn the model by sampling multiple non-overlapping fragment pairs from the\nsame songs and seeking to predict whether a given pair is consecutive and is in\nthe correct chronological order. For testing, we design a number of puzzle\ngames with different difficulty levels, the most difficult one being music\nmedley, which requiring sorting fragments from different songs. On the basis of\nstate-of-the-art Siamese convolutional network, we propose an improved\narchitecture that learns to embed frame-level similarity scores computed from\nthe input fragment pairs to a common space, where fragment pairs in the correct\norder can be more easily identified. Our result shows that the resulting model,\ndubbed as the similarity embedding network (SEN), performs better than\ncompeting models across different games, including music jigsaw puzzle, music\nsequencing, and music medley. Example results can be found at our project\nwebsite, https://remyhuang.github.io/DJnet.\n", "versions": [{"version": "v1", "created": "Wed, 13 Sep 2017 15:33:07 GMT"}, {"version": "v2", "created": "Fri, 17 Nov 2017 03:52:58 GMT"}], "update_date": "2017-11-20", "authors_parsed": [["Huang", "Yu-Siang", ""], ["Chou", "Szu-Yu", ""], ["Yang", "Yi-Hsuan", ""]]}, {"id": "1709.04395", "submitter": "David W. Dreisigmeyer", "authors": "David W Dreisigmeyer", "title": "Tight Semi-Nonnegative Matrix Factorization", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The nonnegative matrix factorization is a widely used, flexible matrix\ndecomposition, finding applications in biology, image and signal processing and\ninformation retrieval, among other areas. Here we present a related matrix\nfactorization. A multi-objective optimization problem finds conical\ncombinations of templates that approximate a given data matrix. The templates\nare chosen so that as far as possible only the initial data set can be\nrepresented this way. However, the templates are not required to be nonnegative\nnor convex combinations of the original data.\n", "versions": [{"version": "v1", "created": "Wed, 13 Sep 2017 16:05:12 GMT"}, {"version": "v2", "created": "Fri, 3 Nov 2017 13:42:18 GMT"}, {"version": "v3", "created": "Mon, 11 Dec 2017 15:33:45 GMT"}], "update_date": "2017-12-12", "authors_parsed": [["Dreisigmeyer", "David W", ""]]}, {"id": "1709.04402", "submitter": "Tu  Nguyen", "authors": "Tu Ngoc Nguyen, Cheng Li, Claudia Nieder\\'ee", "title": "On Early-stage Debunking Rumors on Twitter: Leveraging the Wisdom of\n  Weak Learners", "comments": "The 9th International Conference on Social Informatics", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recently a lot of progress has been made in rumor modeling and rumor\ndetection for micro-blogging streams. However, existing automated methods do\nnot perform very well for early rumor detection, which is crucial in many\nsettings, e.g., in crisis situations. One reason for this is that aggregated\nrumor features such as propagation features, which work well on the long run,\nare - due to their accumulating characteristic - not very helpful in the early\nphase of a rumor. In this work, we present an approach for early rumor\ndetection, which leverages Convolutional Neural Networks for learning the\nhidden representations of individual rumor-related tweets to gain insights on\nthe credibility of each tweets. We then aggregate the predictions from the very\nbeginning of a rumor to obtain the overall event credits (so-called wisdom),\nand finally combine it with a time series based rumor classification model. Our\nextensive experiments show a clearly improved classification performance within\nthe critical very first hours of a rumor. For a better understanding, we also\nconduct an extensive feature evaluation that emphasized on the early stage and\nshows that the low-level credibility has best predictability at all phases of\nthe rumor lifetime.\n", "versions": [{"version": "v1", "created": "Wed, 13 Sep 2017 16:15:59 GMT"}], "update_date": "2017-09-14", "authors_parsed": [["Nguyen", "Tu Ngoc", ""], ["Li", "Cheng", ""], ["Nieder\u00e9e", "Claudia", ""]]}, {"id": "1709.04407", "submitter": "SiQi Zhou", "authors": "Siqi Zhou, Mohamed K. Helwa and Angela P. Schoellig", "title": "An Inversion-Based Learning Approach for Improving Impromptu Trajectory\n  Tracking of Robots with Non-Minimum Phase Dynamics", "comments": "Accepted for publication in the IEEE Robotics and Automation Letters\n  (RA-L), July 2018", "journal-ref": null, "doi": "10.1109/LRA.2018.2801471", "report-no": null, "categories": "cs.RO cs.LG cs.SY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper presents a learning-based approach for impromptu trajectory\ntracking for non-minimum phase systems, i.e., systems with unstable inverse\ndynamics. Inversion-based feedforward approaches are commonly used for\nimproving tracking performance; however, these approaches are not directly\napplicable to non-minimum phase systems due to their inherent instability. In\norder to resolve the instability issue, existing methods have assumed that the\nsystem model is known and used pre-actuation or inverse approximation\ntechniques. In this work, we propose an approach for learning a stable,\napproximate inverse of a non-minimum phase baseline system directly from its\ninput-output data. Through theoretical discussions, simulations, and\nexperiments on two different platforms, we show the stability of our proposed\napproach and its effectiveness for high-accuracy, impromptu tracking. Our\napproach also shows that including more information in the training, as is\ncommonly assumed to be useful, does not lead to better performance but may\ntrigger instability and impact the effectiveness of the overall approach.\n", "versions": [{"version": "v1", "created": "Wed, 13 Sep 2017 16:28:26 GMT"}, {"version": "v2", "created": "Wed, 7 Mar 2018 00:27:49 GMT"}], "update_date": "2018-03-08", "authors_parsed": [["Zhou", "Siqi", ""], ["Helwa", "Mohamed K.", ""], ["Schoellig", "Angela P.", ""]]}, {"id": "1709.04447", "submitter": "Arunesh Sinha", "authors": "Linh Nguyen, Sky Wang, Arunesh Sinha", "title": "A Learning and Masking Approach to Secure Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep Neural Networks (DNNs) have been shown to be vulnerable against\nadversarial examples, which are data points cleverly constructed to fool the\nclassifier. Such attacks can be devastating in practice, especially as DNNs are\nbeing applied to ever increasing critical tasks like image recognition in\nautonomous driving. In this paper, we introduce a new perspective on the\nproblem. We do so by first defining robustness of a classifier to adversarial\nexploitation. Next, we show that the problem of adversarial example generation\ncan be posed as learning problem. We also categorize attacks in literature into\nhigh and low perturbation attacks; well-known attacks like fast-gradient sign\nmethod (FGSM) and our attack produce higher perturbation adversarial examples\nwhile the more potent but computationally inefficient Carlini-Wagner (CW)\nattack is low perturbation. Next, we show that the dual approach of the attack\nlearning problem can be used as a defensive technique that is effective against\nhigh perturbation attacks. Finally, we show that a classifier masking method\nachieved by adding noise to the a neural network's logit output protects\nagainst low distortion attacks such as the CW attack. We also show that both\nour learning and masking defense can work simultaneously to protect against\nmultiple attacks. We demonstrate the efficacy of our techniques by\nexperimenting with the MNIST and CIFAR-10 datasets.\n", "versions": [{"version": "v1", "created": "Wed, 13 Sep 2017 17:44:35 GMT"}, {"version": "v2", "created": "Mon, 2 Oct 2017 23:08:36 GMT"}, {"version": "v3", "created": "Wed, 22 Nov 2017 04:52:45 GMT"}, {"version": "v4", "created": "Sat, 27 Jan 2018 04:08:56 GMT"}], "update_date": "2018-01-30", "authors_parsed": [["Nguyen", "Linh", ""], ["Wang", "Sky", ""], ["Sinha", "Arunesh", ""]]}, {"id": "1709.04511", "submitter": "Yaodong Yang Mr.", "authors": "Yaodong Yang, Lantao Yu, Yiwei Bai, Jun Wang, Weinan Zhang, Ying Wen,\n  Yong Yu", "title": "A Study of AI Population Dynamics with Million-agent Reinforcement\n  Learning", "comments": "Full version of the paper presented at AAMAS 2018 (International\n  Conference on Autonomous Agents and Multiagent Systems)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG cs.MA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We conduct an empirical study on discovering the ordered collective dynamics\nobtained by a population of intelligence agents, driven by million-agent\nreinforcement learning. Our intention is to put intelligent agents into a\nsimulated natural context and verify if the principles developed in the real\nworld could also be used in understanding an artificially-created intelligent\npopulation. To achieve this, we simulate a large-scale predator-prey world,\nwhere the laws of the world are designed by only the findings or logical\nequivalence that have been discovered in nature. We endow the agents with the\nintelligence based on deep reinforcement learning (DRL). In order to scale the\npopulation size up to millions agents, a large-scale DRL training platform with\nredesigned experience buffer is proposed. Our results show that the population\ndynamics of AI agents, driven only by each agent's individual self-interest,\nreveals an ordered pattern that is similar to the Lotka-Volterra model studied\nin population biology. We further discover the emergent behaviors of collective\nadaptations in studying how the agents' grouping behaviors will change with the\nenvironmental resources. Both of the two findings could be explained by the\nself-organization theory in nature.\n", "versions": [{"version": "v1", "created": "Wed, 13 Sep 2017 19:21:57 GMT"}, {"version": "v2", "created": "Sun, 17 Sep 2017 23:06:31 GMT"}, {"version": "v3", "created": "Thu, 5 Oct 2017 13:25:18 GMT"}, {"version": "v4", "created": "Mon, 14 May 2018 13:30:45 GMT"}], "update_date": "2018-05-15", "authors_parsed": [["Yang", "Yaodong", ""], ["Yu", "Lantao", ""], ["Bai", "Yiwei", ""], ["Wang", "Jun", ""], ["Zhang", "Weinan", ""], ["Wen", "Ying", ""], ["Yu", "Yong", ""]]}, {"id": "1709.04514", "submitter": "Emiliano De Cristofaro", "authors": "Gergely Acs, Luca Melis, Claude Castelluccia, and Emiliano De\n  Cristofaro", "title": "Differentially Private Mixture of Generative Neural Networks", "comments": "A shorter version of this paper appeared at the 17th IEEE\n  International Conference on Data Mining (ICDM 2017). This is the full\n  version, published in IEEE Transactions on Knowledge and Data Engineering\n  (TKDE)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Generative models are used in a wide range of applications building on large\namounts of contextually rich information. Due to possible privacy violations of\nthe individuals whose data is used to train these models, however, publishing\nor sharing generative models is not always viable. In this paper, we present a\nnovel technique for privately releasing generative models and entire\nhigh-dimensional datasets produced by these models. We model the generator\ndistribution of the training data with a mixture of $k$ generative neural\nnetworks. These are trained together and collectively learn the generator\ndistribution of a dataset. Data is divided into $k$ clusters, using a novel\ndifferentially private kernel $k$-means, then each cluster is given to separate\ngenerative neural networks, such as Restricted Boltzmann Machines or\nVariational Autoencoders, which are trained only on their own cluster using\ndifferentially private gradient descent. We evaluate our approach using the\nMNIST dataset, as well as call detail records and transit datasets, showing\nthat it produces realistic synthetic samples, which can also be used to\naccurately compute arbitrary number of counting queries.\n", "versions": [{"version": "v1", "created": "Wed, 13 Sep 2017 19:43:45 GMT"}, {"version": "v2", "created": "Wed, 20 Sep 2017 19:59:10 GMT"}, {"version": "v3", "created": "Sun, 19 Nov 2017 20:41:50 GMT"}, {"version": "v4", "created": "Fri, 13 Jul 2018 08:45:45 GMT"}], "update_date": "2018-07-16", "authors_parsed": [["Acs", "Gergely", ""], ["Melis", "Luca", ""], ["Castelluccia", "Claude", ""], ["De Cristofaro", "Emiliano", ""]]}, {"id": "1709.04546", "submitter": "Zijun Zhang", "authors": "Zijun Zhang, Lin Ma, Zongpeng Li, Chuan Wu", "title": "Normalized Direction-preserving Adam", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Adaptive optimization algorithms, such as Adam and RMSprop, have shown better\noptimization performance than stochastic gradient descent (SGD) in some\nscenarios. However, recent studies show that they often lead to worse\ngeneralization performance than SGD, especially for training deep neural\nnetworks (DNNs). In this work, we identify the reasons that Adam generalizes\nworse than SGD, and develop a variant of Adam to eliminate the generalization\ngap. The proposed method, normalized direction-preserving Adam (ND-Adam),\nenables more precise control of the direction and step size for updating weight\nvectors, leading to significantly improved generalization performance.\nFollowing a similar rationale, we further improve the generalization\nperformance in classification tasks by regularizing the softmax logits. By\nbridging the gap between SGD and Adam, we also hope to shed light on why\ncertain optimization algorithms generalize better than others.\n", "versions": [{"version": "v1", "created": "Wed, 13 Sep 2017 21:38:02 GMT"}, {"version": "v2", "created": "Tue, 18 Sep 2018 02:35:39 GMT"}], "update_date": "2018-09-19", "authors_parsed": [["Zhang", "Zijun", ""], ["Ma", "Lin", ""], ["Li", "Zongpeng", ""], ["Wu", "Chuan", ""]]}, {"id": "1709.04549", "submitter": "Allison Del Giorno", "authors": "Allison Del Giorno, J. Andrew Bagnell, Martial Hebert", "title": "Ignoring Distractors in the Absence of Labels: Optimal Linear Projection\n  to Remove False Positives During Anomaly Detection", "comments": "13 pages, 6 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In the anomaly detection setting, the native feature embedding can be a\ncrucial source of bias. We present a technique, Feature Omission using Context\nin Unsupervised Settings (FOCUS) to learn a feature mapping that is invariant\nto changes exemplified in training sets while retaining as much descriptive\npower as possible. While this method could apply to many unsupervised settings,\nwe focus on applications in anomaly detection, where little task-labeled data\nis available. Our algorithm requires only non-anomalous sets of data, and does\nnot require that the contexts in the training sets match the context of the\ntest set. By maximizing within-set variance and minimizing between-set\nvariance, we are able to identify and remove distracting features while\nretaining fidelity to the descriptiveness needed at test time. In the linear\ncase, our formulation reduces to a generalized eigenvalue problem that can be\nsolved quickly and applied to test sets outside the context of the training\nsets. This technique allows us to align technical definitions of anomaly\ndetection with human definitions through appropriate mappings of the feature\nspace. We demonstrate that this method is able to remove uninformative parts of\nthe feature space for the anomaly detection setting.\n", "versions": [{"version": "v1", "created": "Wed, 13 Sep 2017 21:53:10 GMT"}], "update_date": "2017-09-15", "authors_parsed": [["Del Giorno", "Allison", ""], ["Bagnell", "J. Andrew", ""], ["Hebert", "Martial", ""]]}, {"id": "1709.04553", "submitter": "Yingfei Wang", "authors": "Yingfei Wang, Warren Powell", "title": "MOLTE: a Modular Optimal Learning Testing Environment", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We address the relative paucity of empirical testing of learning algorithms\n(of any type) by introducing a new public-domain, Modular, Optimal Learning\nTesting Environment (MOLTE) for Bayesian ranking and selection problem,\nstochastic bandits or sequential experimental design problems. The Matlab-based\nsimulator allows the comparison of a number of learning policies (represented\nas a series of .m modules) in the context of a wide range of problems (each\nrepresented in its own .m module) which makes it easy to add new algorithms and\nnew test problems. State-of-the-art policies and various problem classes are\nprovided in the package. The choice of problems and policies is guided through\na spreadsheet-based interface. Different graphical metrics are included. MOLTE\nis designed to be compatible with parallel computing to scale up from local\ndesktop to clusters and clouds. We offer MOLTE as an easy-to-use tool for the\nresearch community that will make it possible to perform much more\ncomprehensive testing, spanning a broader selection of algorithms and test\nproblems. We demonstrate the capabilities of MOLTE through a series of\ncomparisons of policies on a starter library of test problems. We also address\nthe problem of tuning and constructing priors that have been largely overlooked\nin optimal learning literature. We envision MOLTE as a modest spur to provide\nresearchers an easy environment to study interesting questions involved in\noptimal learning.\n", "versions": [{"version": "v1", "created": "Wed, 13 Sep 2017 22:05:01 GMT"}], "update_date": "2017-09-15", "authors_parsed": [["Wang", "Yingfei", ""], ["Powell", "Warren", ""]]}, {"id": "1709.04555", "submitter": "Wengong Jin", "authors": "Wengong Jin, Connor W. Coley, Regina Barzilay, Tommi Jaakkola", "title": "Predicting Organic Reaction Outcomes with Weisfeiler-Lehman Network", "comments": "accepted by NIPS 2017", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The prediction of organic reaction outcomes is a fundamental problem in\ncomputational chemistry. Since a reaction may involve hundreds of atoms, fully\nexploring the space of possible transformations is intractable. The current\nsolution utilizes reaction templates to limit the space, but it suffers from\ncoverage and efficiency issues. In this paper, we propose a template-free\napproach to efficiently explore the space of product molecules by first\npinpointing the reaction center -- the set of nodes and edges where graph edits\noccur. Since only a small number of atoms contribute to reaction center, we can\ndirectly enumerate candidate products. The generated candidates are scored by a\nWeisfeiler-Lehman Difference Network that models high-order interactions\nbetween changes occurring at nodes across the molecule. Our framework\noutperforms the top-performing template-based approach with a 10\\% margin,\nwhile running orders of magnitude faster. Finally, we demonstrate that the\nmodel accuracy rivals the performance of domain experts.\n", "versions": [{"version": "v1", "created": "Wed, 13 Sep 2017 22:28:46 GMT"}, {"version": "v2", "created": "Mon, 4 Dec 2017 18:53:33 GMT"}, {"version": "v3", "created": "Fri, 29 Dec 2017 16:31:51 GMT"}], "update_date": "2018-01-01", "authors_parsed": [["Jin", "Wengong", ""], ["Coley", "Connor W.", ""], ["Barzilay", "Regina", ""], ["Jaakkola", "Tommi", ""]]}, {"id": "1709.04570", "submitter": "Yi Ouyang", "authors": "Yi Ouyang, Mukul Gagrani, Ashutosh Nayyar, Rahul Jain", "title": "Learning Unknown Markov Decision Processes: A Thompson Sampling Approach", "comments": "Accepted to NIPS 2017", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the problem of learning an unknown Markov Decision Process (MDP)\nthat is weakly communicating in the infinite horizon setting. We propose a\nThompson Sampling-based reinforcement learning algorithm with dynamic episodes\n(TSDE). At the beginning of each episode, the algorithm generates a sample from\nthe posterior distribution over the unknown model parameters. It then follows\nthe optimal stationary policy for the sampled model for the rest of the\nepisode. The duration of each episode is dynamically determined by two stopping\ncriteria. The first stopping criterion controls the growth rate of episode\nlength. The second stopping criterion happens when the number of visits to any\nstate-action pair is doubled. We establish $\\tilde O(HS\\sqrt{AT})$ bounds on\nexpected regret under a Bayesian setting, where $S$ and $A$ are the sizes of\nthe state and action spaces, $T$ is time, and $H$ is the bound of the span.\nThis regret bound matches the best available bound for weakly communicating\nMDPs. Numerical results show it to perform better than existing algorithms for\ninfinite horizon MDPs.\n", "versions": [{"version": "v1", "created": "Thu, 14 Sep 2017 00:16:14 GMT"}], "update_date": "2017-09-15", "authors_parsed": [["Ouyang", "Yi", ""], ["Gagrani", "Mukul", ""], ["Nayyar", "Ashutosh", ""], ["Jain", "Rahul", ""]]}, {"id": "1709.04596", "submitter": "Nesreen Ahmed", "authors": "Nesreen K. Ahmed, Ryan A. Rossi, Rong Zhou, John Boaz Lee, Xiangnan\n  Kong, Theodore L. Willke and Hoda Eldardiry", "title": "A Framework for Generalizing Graph-based Representation Learning Methods", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.AI cs.LG cs.SI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Random walks are at the heart of many existing deep learning algorithms for\ngraph data. However, such algorithms have many limitations that arise from the\nuse of random walks, e.g., the features resulting from these methods are unable\nto transfer to new nodes and graphs as they are tied to node identity. In this\nwork, we introduce the notion of attributed random walks which serves as a\nbasis for generalizing existing methods such as DeepWalk, node2vec, and many\nothers that leverage random walks. Our proposed framework enables these methods\nto be more widely applicable for both transductive and inductive learning as\nwell as for use on graphs with attributes (if available). This is achieved by\nlearning functions that generalize to new nodes and graphs. We show that our\nproposed framework is effective with an average AUC improvement of 16.1% while\nrequiring on average 853 times less space than existing methods on a variety of\ngraphs from several domains.\n", "versions": [{"version": "v1", "created": "Thu, 14 Sep 2017 02:37:52 GMT"}], "update_date": "2017-09-15", "authors_parsed": [["Ahmed", "Nesreen K.", ""], ["Rossi", "Ryan A.", ""], ["Zhou", "Rong", ""], ["Lee", "John Boaz", ""], ["Kong", "Xiangnan", ""], ["Willke", "Theodore L.", ""], ["Eldardiry", "Hoda", ""]]}, {"id": "1709.04620", "submitter": "Takashi Shinzato", "authors": "Daichi Tada, Hisashi Yamamoto and Takashi Shinzato", "title": "Random matrix approach for primal-dual portfolio optimization problems", "comments": "24 pages, 4 figures", "journal-ref": null, "doi": "10.7566/JPSJ.86.124804", "report-no": null, "categories": "q-fin.PM cond-mat.dis-nn cs.CE cs.LG math.OC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we revisit the portfolio optimization problems of the\nminimization/maximization of investment risk under constraints of budget and\ninvestment concentration (primal problem) and the maximization/minimization of\ninvestment concentration under constraints of budget and investment risk (dual\nproblem) for the case that the variances of the return rates of the assets are\nidentical. We analyze both optimization problems by using the Lagrange\nmultiplier method and the random matrix approach. Thereafter, we compare the\nresults obtained from our proposed approach with the results obtained in\nprevious work. Moreover, we use numerical experiments to validate the results\nobtained from the replica approach and the random matrix approach as methods\nfor analyzing both the primal and dual portfolio optimization problems.\n", "versions": [{"version": "v1", "created": "Thu, 14 Sep 2017 05:45:45 GMT"}, {"version": "v2", "created": "Wed, 20 Sep 2017 12:25:38 GMT"}], "update_date": "2018-01-17", "authors_parsed": [["Tada", "Daichi", ""], ["Yamamoto", "Hisashi", ""], ["Shinzato", "Takashi", ""]]}, {"id": "1709.04744", "submitter": "John Lipor", "authors": "John Lipor, David Hong, Yan Shuo Tan, and Laura Balzano", "title": "Subspace Clustering using Ensembles of $K$-Subspaces", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Subspace clustering is the unsupervised grouping of points lying near a union\nof low-dimensional linear subspaces. Algorithms based directly on geometric\nproperties of such data tend to either provide poor empirical performance, lack\ntheoretical guarantees, or depend heavily on their initialization. We present a\nnovel geometric approach to the subspace clustering problem that leverages\nensembles of the K-subspaces (KSS) algorithm via the evidence accumulation\nclustering framework. Our algorithm, referred to as ensemble K-subspaces\n(EKSS), forms a co-association matrix whose (i,j)th entry is the number of\ntimes points i and j are clustered together by several runs of KSS with random\ninitializations. We prove general recovery guarantees for any algorithm that\nforms an affinity matrix with entries close to a monotonic transformation of\npairwise absolute inner products. We then show that a specific instance of EKSS\nresults in an affinity matrix with entries of this form, and hence our proposed\nalgorithm can provably recover subspaces under similar conditions to\nstate-of-the-art algorithms. The finding is, to the best of our knowledge, the\nfirst recovery guarantee for evidence accumulation clustering and for KSS\nvariants. We show on synthetic data that our method performs well in the\ntraditionally challenging settings of subspaces with large intersection,\nsubspaces with small principal angles, and noisy data. Finally, we evaluate our\nalgorithm on six common benchmark datasets and show that unlike existing\nmethods, EKSS achieves excellent empirical performance when there are both a\nsmall and large number of points per subspace.\n", "versions": [{"version": "v1", "created": "Thu, 14 Sep 2017 12:55:56 GMT"}, {"version": "v2", "created": "Sun, 23 Sep 2018 22:18:48 GMT"}, {"version": "v3", "created": "Wed, 6 Jan 2021 23:39:59 GMT"}], "update_date": "2021-01-08", "authors_parsed": [["Lipor", "John", ""], ["Hong", "David", ""], ["Tan", "Yan Shuo", ""], ["Balzano", "Laura", ""]]}, {"id": "1709.04751", "submitter": "Florian Kraemer", "authors": "Florian Kraemer, Alexander Schaefer, Andreas Eitel, Johan Vertens,\n  Wolfram Burgard", "title": "From Plants to Landmarks: Time-invariant Plant Localization that uses\n  Deep Pose Regression in Agricultural Fields", "comments": "IROS 2017 AGROB Workshop", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Agricultural robots are expected to increase yields in a sustainable way and\nautomate precision tasks, such as weeding and plant monitoring. At the same\ntime, they move in a continuously changing, semi-structured field environment,\nin which features can hardly be found and reproduced at a later time.\nChallenges for Lidar and visual detection systems stem from the fact that\nplants can be very small, overlapping and have a steadily changing appearance.\nTherefore, a popular way to localize vehicles with high accuracy is based on\nex- pensive global navigation satellite systems and not on natural landmarks.\nThe contribution of this work is a novel image- based plant localization\ntechnique that uses the time-invariant stem emerging point as a reference. Our\napproach is based on a fully convolutional neural network that learns landmark\nlocalization from RGB and NIR image input in an end-to-end manner. The network\nperforms pose regression to generate a plant location likelihood map. Our\napproach allows us to cope with visual variances of plants both for different\nspecies and different growth stages. We achieve high localization accuracies as\nshown in detailed evaluations of a sugar beet cultivation phase. In experiments\nwith our BoniRob we demonstrate that detections can be robustly reproduced with\ncentimeter accuracy.\n", "versions": [{"version": "v1", "created": "Thu, 14 Sep 2017 13:03:51 GMT"}], "update_date": "2017-09-15", "authors_parsed": [["Kraemer", "Florian", ""], ["Schaefer", "Alexander", ""], ["Eitel", "Andreas", ""], ["Vertens", "Johan", ""], ["Burgard", "Wolfram", ""]]}, {"id": "1709.04762", "submitter": "Giacomo Spigler", "authors": "Giacomo Spigler", "title": "Denoising Autoencoders for Overgeneralization in Neural Networks", "comments": "9 pages, 5 figures, submitted", "journal-ref": null, "doi": "10.1109/TPAMI.2019.2909876", "report-no": null, "categories": "cs.AI cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Despite the recent developments that allowed neural networks to achieve\nimpressive performance on a variety of applications, these models are\nintrinsically affected by the problem of overgeneralization, due to their\npartitioning of the full input space into the fixed set of target classes used\nduring training. Thus it is possible for novel inputs belonging to categories\nunknown during training or even completely unrecognizable to humans to fool the\nsystem into classifying them as one of the known classes, even with a high\ndegree of confidence. Solving this problem may help improve the security of\nsuch systems in critical applications, and may further lead to applications in\nthe context of open set recognition and 1-class recognition. This paper\npresents a novel way to compute a confidence score using denoising autoencoders\nand shows that such confidence score can correctly identify the regions of the\ninput space close to the training distribution by approximately identifying its\nlocal maxima.\n", "versions": [{"version": "v1", "created": "Thu, 14 Sep 2017 13:12:03 GMT"}, {"version": "v2", "created": "Tue, 23 Oct 2018 11:09:10 GMT"}, {"version": "v3", "created": "Mon, 14 Jan 2019 22:35:13 GMT"}], "update_date": "2020-02-11", "authors_parsed": [["Spigler", "Giacomo", ""]]}, {"id": "1709.04764", "submitter": "Raif Rustamov", "authors": "Raif M. Rustamov and James T. Klosowski", "title": "Interpretable Graph-Based Semi-Supervised Learning via Flows", "comments": null, "journal-ref": "AAAI 2018", "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we consider the interpretability of the foundational\nLaplacian-based semi-supervised learning approaches on graphs. We introduce a\nnovel flow-based learning framework that subsumes the foundational approaches\nand additionally provides a detailed, transparent, and easily understood\nexpression of the learning process in terms of graph flows. As a result, one\ncan visualize and interactively explore the precise subgraph along which the\ninformation from labeled nodes flows to an unlabeled node of interest.\nSurprisingly, the proposed framework avoids trading accuracy for\ninterpretability, but in fact leads to improved prediction accuracy, which is\nsupported both by theoretical considerations and empirical results. The\nflow-based framework guarantees the maximum principle by construction and can\nhandle directed graphs in an out-of-the-box manner.\n", "versions": [{"version": "v1", "created": "Thu, 14 Sep 2017 13:13:52 GMT"}], "update_date": "2019-01-14", "authors_parsed": [["Rustamov", "Raif M.", ""], ["Klosowski", "James T.", ""]]}, {"id": "1709.04808", "submitter": "Yanjie Wang", "authors": "Yanjie Wang, Rainer Gemulla, Hui Li", "title": "On Multi-Relational Link Prediction with Bilinear Models", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study bilinear embedding models for the task of multi-relational link\nprediction and knowledge graph completion. Bilinear models belong to the most\nbasic models for this task, they are comparably efficient to train and use, and\nthey can provide good prediction performance. The main goal of this paper is to\nexplore the expressiveness of and the connections between various bilinear\nmodels proposed in the literature. In particular, a substantial number of\nmodels can be represented as bilinear models with certain additional\nconstraints enforced on the embeddings. We explore whether or not these\nconstraints lead to universal models, which can in principle represent every\nset of relations, and whether or not there are subsumption relationships\nbetween various models. We report results of an independent experimental study\nthat evaluates recent bilinear models in a common experimental setup. Finally,\nwe provide evidence that relation-level ensembles of multiple bilinear models\ncan achieve state-of-the art prediction performance.\n", "versions": [{"version": "v1", "created": "Thu, 14 Sep 2017 14:21:33 GMT"}], "update_date": "2017-09-15", "authors_parsed": [["Wang", "Yanjie", ""], ["Gemulla", "Rainer", ""], ["Li", "Hui", ""]]}, {"id": "1709.04836", "submitter": "Jiankang Deng", "authors": "Niannan Xue, Jiankang Deng, Yannis Panagakis, Stefanos Zafeiriou", "title": "Informed Non-convex Robust Principal Component Analysis with Features", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We revisit the problem of robust principal component analysis with features\nacting as prior side information. To this aim, a novel, elegant, non-convex\noptimization approach is proposed to decompose a given observation matrix into\na low-rank core and the corresponding sparse residual. Rigorous theoretical\nanalysis of the proposed algorithm results in exact recovery guarantees with\nlow computational complexity. Aptly designed synthetic experiments demonstrate\nthat our method is the first to wholly harness the power of non-convexity over\nconvexity in terms of both recoverability and speed. That is, the proposed\nnon-convex approach is more accurate and faster compared to the best available\nalgorithms for the problem under study. Two real-world applications, namely\nimage classification and face denoising further exemplify the practical\nsuperiority of the proposed method.\n", "versions": [{"version": "v1", "created": "Thu, 14 Sep 2017 15:06:21 GMT"}], "update_date": "2017-09-15", "authors_parsed": [["Xue", "Niannan", ""], ["Deng", "Jiankang", ""], ["Panagakis", "Yannis", ""], ["Zafeiriou", "Stefanos", ""]]}, {"id": "1709.04875", "submitter": "Haoteng Yin", "authors": "Bing Yu, Haoteng Yin, Zhanxing Zhu", "title": "Spatio-Temporal Graph Convolutional Networks: A Deep Learning Framework\n  for Traffic Forecasting", "comments": "Proceedings of the 27th International Joint Conference on Artificial\n  Intelligence", "journal-ref": null, "doi": "10.24963/ijcai.2018/505", "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Timely accurate traffic forecast is crucial for urban traffic control and\nguidance. Due to the high nonlinearity and complexity of traffic flow,\ntraditional methods cannot satisfy the requirements of mid-and-long term\nprediction tasks and often neglect spatial and temporal dependencies. In this\npaper, we propose a novel deep learning framework, Spatio-Temporal Graph\nConvolutional Networks (STGCN), to tackle the time series prediction problem in\ntraffic domain. Instead of applying regular convolutional and recurrent units,\nwe formulate the problem on graphs and build the model with complete\nconvolutional structures, which enable much faster training speed with fewer\nparameters. Experiments show that our model STGCN effectively captures\ncomprehensive spatio-temporal correlations through modeling multi-scale traffic\nnetworks and consistently outperforms state-of-the-art baselines on various\nreal-world traffic datasets.\n", "versions": [{"version": "v1", "created": "Thu, 14 Sep 2017 16:54:41 GMT"}, {"version": "v2", "created": "Mon, 25 Sep 2017 09:17:45 GMT"}, {"version": "v3", "created": "Thu, 1 Feb 2018 13:52:01 GMT"}, {"version": "v4", "created": "Thu, 12 Jul 2018 07:55:09 GMT"}], "update_date": "2018-07-13", "authors_parsed": [["Yu", "Bing", ""], ["Yin", "Haoteng", ""], ["Zhu", "Zhanxing", ""]]}, {"id": "1709.04889", "submitter": "Melkior Ornik", "authors": "Melkior Ornik, Arie Israel, Ufuk Topcu", "title": "Control-Oriented Learning on the Fly", "comments": "Extended version of M. Ornik, A. Israel, U. Topcu, \"Myopic Control of\n  Systems with Unknown Dynamics\". Detailed list of differences from that paper\n  given within the manuscript. Changes in v2 include a discussion of myopic\n  control in an LTL context and a correction of the bound for suboptimality of\n  the algorithm", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.OC cs.LG cs.RO cs.SY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper focuses on developing a strategy for control of systems whose\ndynamics are almost entirely unknown. This situation arises naturally in a\nscenario where a system undergoes a critical failure. In that case, it is\nimperative to retain the ability to satisfy basic control objectives in order\nto avert an imminent catastrophe. A prime example of such an objective is the\nreach-avoid problem, where a system needs to move to a certain state in a\nconstrained state space. To deal with limitations on our knowledge of system\ndynamics, we develop a theory of myopic control. The primary goal of myopic\ncontrol is to, at any given time, optimize the current direction of the system\ntrajectory, given solely the information obtained about the system until that\ntime. We propose an algorithm that uses small perturbations in the control\neffort to learn local dynamics while simultaneously ensuring that the system\nmoves in a direction that appears to be nearly optimal, and provide hard bounds\nfor its suboptimality. We additionally verify the usefulness of the algorithm\non a simulation of a damaged aircraft seeking to avoid a crash, as well as on\nan example of a Van der Pol oscillator.\n", "versions": [{"version": "v1", "created": "Thu, 14 Sep 2017 17:25:11 GMT"}, {"version": "v2", "created": "Sat, 14 Oct 2017 17:31:37 GMT"}], "update_date": "2017-10-17", "authors_parsed": [["Ornik", "Melkior", ""], ["Israel", "Arie", ""], ["Topcu", "Ufuk", ""]]}, {"id": "1709.04893", "submitter": "Jonas K\\\"ohler", "authors": "Taco Cohen, Mario Geiger, Jonas K\\\"ohler and Max Welling", "title": "Convolutional Networks for Spherical Signals", "comments": null, "journal-ref": "Principled Approaches to Deep Learning Workshop, ICML 2017", "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The success of convolutional networks in learning problems involving planar\nsignals such as images is due to their ability to exploit the translation\nsymmetry of the data distribution through weight sharing. Many areas of science\nand egineering deal with signals with other symmetries, such as rotation\ninvariant data on the sphere. Examples include climate and weather science,\nastrophysics, and chemistry. In this paper we present spherical convolutional\nnetworks. These networks use convolutions on the sphere and rotation group,\nwhich results in rotational weight sharing and rotation equivariance. Using a\nsynthetic spherical MNIST dataset, we show that spherical convolutional\nnetworks are very effective at dealing with rotationally invariant\nclassification problems.\n", "versions": [{"version": "v1", "created": "Thu, 14 Sep 2017 17:29:58 GMT"}, {"version": "v2", "created": "Fri, 15 Sep 2017 07:30:30 GMT"}], "update_date": "2019-04-23", "authors_parsed": [["Cohen", "Taco", ""], ["Geiger", "Mario", ""], ["K\u00f6hler", "Jonas", ""], ["Welling", "Max", ""]]}, {"id": "1709.04905", "submitter": "Chelsea Finn", "authors": "Chelsea Finn, Tianhe Yu, Tianhao Zhang, Pieter Abbeel, Sergey Levine", "title": "One-Shot Visual Imitation Learning via Meta-Learning", "comments": "Conference on Robot Learning, 2017 (to appear). First two authors\n  contributed equally. Video available at\n  https://sites.google.com/view/one-shot-imitation", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CV cs.RO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In order for a robot to be a generalist that can perform a wide range of\njobs, it must be able to acquire a wide variety of skills quickly and\nefficiently in complex unstructured environments. High-capacity models such as\ndeep neural networks can enable a robot to represent complex skills, but\nlearning each skill from scratch then becomes infeasible. In this work, we\npresent a meta-imitation learning method that enables a robot to learn how to\nlearn more efficiently, allowing it to acquire new skills from just a single\ndemonstration. Unlike prior methods for one-shot imitation, our method can\nscale to raw pixel inputs and requires data from significantly fewer prior\ntasks for effective learning of new skills. Our experiments on both simulated\nand real robot platforms demonstrate the ability to learn new tasks,\nend-to-end, from a single visual demonstration.\n", "versions": [{"version": "v1", "created": "Thu, 14 Sep 2017 17:50:18 GMT"}], "update_date": "2017-09-15", "authors_parsed": [["Finn", "Chelsea", ""], ["Yu", "Tianhe", ""], ["Zhang", "Tianhao", ""], ["Abbeel", "Pieter", ""], ["Levine", "Sergey", ""]]}, {"id": "1709.04909", "submitter": "Rakesh Radhakrishnan Menon", "authors": "Rakesh R Menon, Balaraman Ravindran", "title": "Shared Learning : Enhancing Reinforcement in $Q$-Ensembles", "comments": "Submitted to AAAI 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep Reinforcement Learning has been able to achieve amazing successes in a\nvariety of domains from video games to continuous control by trying to maximize\nthe cumulative reward. However, most of these successes rely on algorithms that\nrequire a large amount of data to train in order to obtain results on par with\nhuman-level performance. This is not feasible if we are to deploy these systems\non real world tasks and hence there has been an increased thrust in exploring\ndata efficient algorithms. To this end, we propose the Shared Learning\nframework aimed at making $Q$-ensemble algorithms data-efficient. For achieving\nthis, we look into some principles of transfer learning which aim to study the\nbenefits of information exchange across tasks in reinforcement learning and\nadapt transfer to learning our value function estimates in a novel manner. In\nthis paper, we consider the special case of transfer between the value function\nestimates in the $Q$-ensemble architecture of BootstrappedDQN. We further\nempirically demonstrate how our proposed framework can help in speeding up the\nlearning process in $Q$-ensembles with minimum computational overhead on a\nsuite of Atari 2600 Games.\n", "versions": [{"version": "v1", "created": "Thu, 14 Sep 2017 17:54:05 GMT"}], "update_date": "2017-09-15", "authors_parsed": [["Menon", "Rakesh R", ""], ["Ravindran", "Balaraman", ""]]}, {"id": "1709.04960", "submitter": "Paresh Nakhe", "authors": "Paresh Nakhe", "title": "Dynamic Pricing in Competitive Markets", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.GT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Dynamic pricing of goods in a competitive environment to maximize revenue is\na natural objective and has been a subject of research over the years. In this\npaper, we focus on a class of markets exhibiting the substitutes property with\nsellers having divisible and replenishable goods. Depending on the prices\nchosen, each seller observes a certain demand which is satisfied subject to the\nsupply constraint. The goal of the seller is to price her good dynamically so\nas to maximize her revenue. For the static market case, when the consumer\nutility satisfies the Constant Elasticity of Substitution (CES) property, we\ngive a $O(\\sqrt{T})$ regret bound on the maximum loss in revenue of a seller\nusing a modified version of the celebrated Online Gradient Descent Algorithm by\nZinkevich. For a more specialized set of consumer utilities satisfying the\niso-elasticity condition, we show that when each seller uses a\nregret-minimizing algorithm satisfying a certain technical property, the regret\nwith respect to $(1-\\alpha)$ times optimal revenue is bounded as $O(T^{1/4} /\n\\sqrt{\\alpha})$. We extend this result to markets with dynamic supplies and\nprove a corresponding dynamic regret bound, whose guarantee deteriorates\nsmoothly with the inherent instability of the market. As a side-result, we also\nextend the previously known convergence results of these algorithms in a\ngeneral game to the dynamic setting.\n", "versions": [{"version": "v1", "created": "Thu, 14 Sep 2017 20:06:22 GMT"}], "update_date": "2017-09-18", "authors_parsed": [["Nakhe", "Paresh", ""]]}, {"id": "1709.05006", "submitter": "Xiuyuan Cheng", "authors": "Xiuyuan Cheng, Alexander Cloninger and Ronald R. Coifman", "title": "Two-sample Statistics Based on Anisotropic Kernels", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG stat.AP stat.CO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The paper introduces a new kernel-based Maximum Mean Discrepancy (MMD)\nstatistic for measuring the distance between two distributions given\nfinitely-many multivariate samples. When the distributions are locally\nlow-dimensional, the proposed test can be made more powerful to distinguish\ncertain alternatives by incorporating local covariance matrices and\nconstructing an anisotropic kernel. The kernel matrix is asymmetric; it\ncomputes the affinity between $n$ data points and a set of $n_R$ reference\npoints, where $n_R$ can be drastically smaller than $n$. While the proposed\nstatistic can be viewed as a special class of Reproducing Kernel Hilbert Space\nMMD, the consistency of the test is proved, under mild assumptions of the\nkernel, as long as $\\|p-q\\| \\sqrt{n} \\to \\infty $, and a finite-sample lower\nbound of the testing power is obtained. Applications to flow cytometry and\ndiffusion MRI datasets are demonstrated, which motivate the proposed approach\nto compare distributions.\n", "versions": [{"version": "v1", "created": "Thu, 14 Sep 2017 23:06:19 GMT"}, {"version": "v2", "created": "Sat, 30 Sep 2017 15:39:36 GMT"}, {"version": "v3", "created": "Thu, 30 Aug 2018 21:56:28 GMT"}], "update_date": "2018-09-03", "authors_parsed": [["Cheng", "Xiuyuan", ""], ["Cloninger", "Alexander", ""], ["Coifman", "Ronald R.", ""]]}, {"id": "1709.05027", "submitter": "Wei Wen", "authors": "Wei Wen, Yuxiong He, Samyam Rajbhandari, Minjia Zhang, Wenhan Wang,\n  Fang Liu, Bin Hu, Yiran Chen, Hai Li", "title": "Learning Intrinsic Sparse Structures within Long Short-Term Memory", "comments": "Published in ICLR 2018 ( the Sixth International Conference on\n  Learning Representations)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CL cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Model compression is significant for the wide adoption of Recurrent Neural\nNetworks (RNNs) in both user devices possessing limited resources and business\nclusters requiring quick responses to large-scale service requests. This work\naims to learn structurally-sparse Long Short-Term Memory (LSTM) by reducing the\nsizes of basic structures within LSTM units, including input updates, gates,\nhidden states, cell states and outputs. Independently reducing the sizes of\nbasic structures can result in inconsistent dimensions among them, and\nconsequently, end up with invalid LSTM units. To overcome the problem, we\npropose Intrinsic Sparse Structures (ISS) in LSTMs. Removing a component of ISS\nwill simultaneously decrease the sizes of all basic structures by one and\nthereby always maintain the dimension consistency. By learning ISS within LSTM\nunits, the obtained LSTMs remain regular while having much smaller basic\nstructures. Based on group Lasso regularization, our method achieves 10.59x\nspeedup without losing any perplexity of a language modeling of Penn TreeBank\ndataset. It is also successfully evaluated through a compact model with only\n2.69M weights for machine Question Answering of SQuAD dataset. Our approach is\nsuccessfully extended to non- LSTM RNNs, like Recurrent Highway Networks\n(RHNs). Our source code is publicly available at\nhttps://github.com/wenwei202/iss-rnns\n", "versions": [{"version": "v1", "created": "Fri, 15 Sep 2017 01:10:23 GMT"}, {"version": "v2", "created": "Fri, 13 Oct 2017 17:23:05 GMT"}, {"version": "v3", "created": "Sat, 28 Oct 2017 15:49:22 GMT"}, {"version": "v4", "created": "Sun, 24 Dec 2017 19:24:23 GMT"}, {"version": "v5", "created": "Fri, 5 Jan 2018 16:23:10 GMT"}, {"version": "v6", "created": "Tue, 30 Jan 2018 04:42:43 GMT"}, {"version": "v7", "created": "Sun, 11 Feb 2018 16:36:32 GMT"}], "update_date": "2018-02-13", "authors_parsed": [["Wen", "Wei", ""], ["He", "Yuxiong", ""], ["Rajbhandari", "Samyam", ""], ["Zhang", "Minjia", ""], ["Wang", "Wenhan", ""], ["Liu", "Fang", ""], ["Hu", "Bin", ""], ["Chen", "Yiran", ""], ["Li", "Hai", ""]]}, {"id": "1709.05038", "submitter": "Yang Xian", "authors": "Yang Xian, Yingli Tian", "title": "Self-Guiding Multimodal LSTM - when we do not have a perfect training\n  dataset for image captioning", "comments": "The paper is under consideration at Computer Vision and Image\n  Understanding", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, a self-guiding multimodal LSTM (sg-LSTM) image captioning\nmodel is proposed to handle uncontrolled imbalanced real-world image-sentence\ndataset. We collect FlickrNYC dataset from Flickr as our testbed with 306,165\nimages and the original text descriptions uploaded by the users are utilized as\nthe ground truth for training. Descriptions in FlickrNYC dataset vary\ndramatically ranging from short term-descriptions to long\nparagraph-descriptions and can describe any visual aspects, or even refer to\nobjects that are not depicted. To deal with the imbalanced and noisy situation\nand to fully explore the dataset itself, we propose a novel guiding textual\nfeature extracted utilizing a multimodal LSTM (m-LSTM) model. Training of\nm-LSTM is based on the portion of data in which the image content and the\ncorresponding descriptions are strongly bonded. Afterwards, during the training\nof sg-LSTM on the rest training data, this guiding information serves as\nadditional input to the network along with the image representations and the\nground-truth descriptions. By integrating these input components into a\nmultimodal block, we aim to form a training scheme with the textual information\ntightly coupled with the image content. The experimental results demonstrate\nthat the proposed sg-LSTM model outperforms the traditional state-of-the-art\nmultimodal RNN captioning framework in successfully describing the key\ncomponents of the input images.\n", "versions": [{"version": "v1", "created": "Fri, 15 Sep 2017 02:53:16 GMT"}], "update_date": "2017-09-18", "authors_parsed": [["Xian", "Yang", ""], ["Tian", "Yingli", ""]]}, {"id": "1709.05047", "submitter": "Yang Li", "authors": "Yang Li, Quan Pan, Suhang Wang, Haiyun Peng, Tao Yang, Erik Cambria", "title": "Disentangled Variational Auto-Encoder for Semi-supervised Learning", "comments": "6 figures, 10 pages, Information Sciences 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Semi-supervised learning is attracting increasing attention due to the fact\nthat datasets of many domains lack enough labeled data. Variational\nAuto-Encoder (VAE), in particular, has demonstrated the benefits of\nsemi-supervised learning. The majority of existing semi-supervised VAEs utilize\na classifier to exploit label information, where the parameters of the\nclassifier are introduced to the VAE. Given the limited labeled data, learning\nthe parameters for the classifiers may not be an optimal solution for\nexploiting label information. Therefore, in this paper, we develop a novel\napproach for semi-supervised VAE without classifier. Specifically, we propose a\nnew model called Semi-supervised Disentangled VAE (SDVAE), which encodes the\ninput data into disentangled representation and non-interpretable\nrepresentation, then the category information is directly utilized to\nregularize the disentangled representation via the equality constraint. To\nfurther enhance the feature learning ability of the proposed VAE, we\nincorporate reinforcement learning to relieve the lack of data. The dynamic\nframework is capable of dealing with both image and text data with its\ncorresponding encoder and decoder networks. Extensive experiments on image and\ntext datasets demonstrate the effectiveness of the proposed framework.\n", "versions": [{"version": "v1", "created": "Fri, 15 Sep 2017 03:39:53 GMT"}, {"version": "v2", "created": "Sun, 2 Dec 2018 07:42:21 GMT"}], "update_date": "2018-12-04", "authors_parsed": [["Li", "Yang", ""], ["Pan", "Quan", ""], ["Wang", "Suhang", ""], ["Peng", "Haiyun", ""], ["Yang", "Tao", ""], ["Cambria", "Erik", ""]]}, {"id": "1709.05056", "submitter": "Marc Khoury", "authors": "Marc Khoury, Qian-Yi Zhou, Vladlen Koltun", "title": "Learning Compact Geometric Features", "comments": "International Conference on Computer Vision (ICCV), 2017", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.GR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present an approach to learning features that represent the local geometry\naround a point in an unstructured point cloud. Such features play a central\nrole in geometric registration, which supports diverse applications in robotics\nand 3D vision. Current state-of-the-art local features for unstructured point\nclouds have been manually crafted and none combines the desirable properties of\nprecision, compactness, and robustness. We show that features with these\nproperties can be learned from data, by optimizing deep networks that map\nhigh-dimensional histograms into low-dimensional Euclidean spaces. The\npresented approach yields a family of features, parameterized by dimension,\nthat are both more compact and more accurate than existing descriptors.\n", "versions": [{"version": "v1", "created": "Fri, 15 Sep 2017 04:44:28 GMT"}], "update_date": "2017-09-18", "authors_parsed": [["Khoury", "Marc", ""], ["Zhou", "Qian-Yi", ""], ["Koltun", "Vladlen", ""]]}, {"id": "1709.05069", "submitter": "S\\'ebastien Arnold", "authors": "S\\'ebastien M. R. Arnold and Chunming Wang", "title": "Accelerating SGD for Distributed Deep-Learning Using Approximated\n  Hessian Matrix", "comments": "ICLR17 Workshop Track", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce a novel method to compute a rank $m$ approximation of the\ninverse of the Hessian matrix in the distributed regime. By leveraging the\ndifferences in gradients and parameters of multiple Workers, we are able to\nefficiently implement a distributed approximation of the Newton-Raphson method.\nWe also present preliminary results which underline advantages and challenges\nof second-order methods for large stochastic optimization problems. In\nparticular, our work suggests that novel strategies for combining gradients\nprovide further information on the loss surface.\n", "versions": [{"version": "v1", "created": "Fri, 15 Sep 2017 06:27:49 GMT"}], "update_date": "2017-09-18", "authors_parsed": [["Arnold", "S\u00e9bastien M. R.", ""], ["Wang", "Chunming", ""]]}, {"id": "1709.05070", "submitter": "S\\'ebastien Arnold", "authors": "S\\'ebastien M. R. Arnold, Tsam Kiu Pun, Th\\'eo-Tim J. Denisart and\n  Francisco J. Valero-Cuevas", "title": "Shapechanger: Environments for Transfer Learning", "comments": "Presented at the SoCal 2017 Robotics Symposium", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.RO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present Shapechanger, a library for transfer reinforcement learning\nspecifically designed for robotic tasks. We consider three types of knowledge\ntransfer---from simulation to simulation, from simulation to real, and from\nreal to real---and a wide range of tasks with continuous states and actions.\nShapechanger is under active development and open-sourced at:\nhttps://github.com/seba-1511/shapechanger/.\n", "versions": [{"version": "v1", "created": "Fri, 15 Sep 2017 06:44:19 GMT"}], "update_date": "2017-09-18", "authors_parsed": [["Arnold", "S\u00e9bastien M. R.", ""], ["Pun", "Tsam Kiu", ""], ["Denisart", "Th\u00e9o-Tim J.", ""], ["Valero-Cuevas", "Francisco J.", ""]]}, {"id": "1709.05107", "submitter": "Ke Chen", "authors": "Qian Wang and Ke Chen", "title": "Multi-Label Zero-Shot Human Action Recognition via Joint Latent Ranking\n  Embedding", "comments": "27 pages, 10 figures and 7 tables. Technical report submitted to a\n  journal. More experimental results/references were added and typos were\n  corrected", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Human action recognition refers to automatic recognizing human actions from a\nvideo clip. In reality, there often exist multiple human actions in a video\nstream. Such a video stream is often weakly-annotated with a set of relevant\nhuman action labels at a global level rather than assigning each label to a\nspecific video episode corresponding to a single action, which leads to a\nmulti-label learning problem. Furthermore, there are many meaningful human\nactions in reality but it would be extremely difficult to collect/annotate\nvideo clips regarding all of various human actions, which leads to a zero-shot\nlearning scenario. To the best of our knowledge, there is no work that has\naddressed all the above issues together in human action recognition. In this\npaper, we formulate a real-world human action recognition task as a multi-label\nzero-shot learning problem and propose a framework to tackle this problem in a\nholistic way. Our framework holistically tackles the issue of unknown temporal\nboundaries between different actions for multi-label learning and exploits the\nside information regarding the semantic relationship between different human\nactions for knowledge transfer. Consequently, our framework leads to a joint\nlatent ranking embedding for multi-label zero-shot human action recognition. A\nnovel neural architecture of two component models and an alternate learning\nalgorithm are proposed to carry out the joint latent ranking embedding\nlearning. Thus, multi-label zero-shot recognition is done by measuring\nrelatedness scores of action labels to a test video clip in the joint latent\nvisual and semantic embedding spaces. We evaluate our framework with different\nsettings, including a novel data split scheme designed especially for\nevaluating multi-label zero-shot learning, on two datasets: Breakfast and\nCharades. The experimental results demonstrate the effectiveness of our\nframework.\n", "versions": [{"version": "v1", "created": "Fri, 15 Sep 2017 08:44:02 GMT"}, {"version": "v2", "created": "Sat, 29 Sep 2018 08:51:15 GMT"}, {"version": "v3", "created": "Wed, 6 Feb 2019 12:42:58 GMT"}], "update_date": "2019-02-07", "authors_parsed": [["Wang", "Qian", ""], ["Chen", "Ke", ""]]}, {"id": "1709.05156", "submitter": "Paresh Nakhe", "authors": "Paresh Nakhe, Rebecca Reiffenh\\\"auser", "title": "Trend Detection based Regret Minimization for Bandit Problems", "comments": null, "journal-ref": "2016 IEEE International Conference on Data Science and Advanced\n  Analytics (DSAA), Montreal, QC, 2016, pp. 263-271", "doi": "10.1109/DSAA.2016.35", "report-no": null, "categories": "cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study a variation of the classical multi-armed bandits problem. In this\nproblem, the learner has to make a sequence of decisions, picking from a fixed\nset of choices. In each round, she receives as feedback only the loss incurred\nfrom the chosen action. Conventionally, this problem has been studied when\nlosses of the actions are drawn from an unknown distribution or when they are\nadversarial. In this paper, we study this problem when the losses of the\nactions also satisfy certain structural properties, and especially, do show a\ntrend structure. When this is true, we show that using \\textit{trend\ndetection}, we can achieve regret of order $\\tilde{O} (N \\sqrt{TK})$ with\nrespect to a switching strategy for the version of the problem where a single\naction is chosen in each round and $\\tilde{O} (Nm \\sqrt{TK})$ when $m$ actions\nare chosen each round. This guarantee is a significant improvement over the\nconventional benchmark. Our approach can, as a framework, be applied in\ncombination with various well-known bandit algorithms, like Exp3. For both\nversions of the problem, we give regret guarantees also for the\n\\textit{anytime} setting, i.e. when the length of the choice-sequence is not\nknown in advance. Finally, we pinpoint the advantages of our method by\ncomparing it to some well-known other strategies.\n", "versions": [{"version": "v1", "created": "Fri, 15 Sep 2017 11:26:07 GMT"}], "update_date": "2017-09-18", "authors_parsed": [["Nakhe", "Paresh", ""], ["Reiffenh\u00e4user", "Rebecca", ""]]}, {"id": "1709.05206", "submitter": "Fazle Karim", "authors": "Fazle Karim, Somshubra Majumdar, Houshang Darabi and Shun Chen", "title": "LSTM Fully Convolutional Networks for Time Series Classification", "comments": "7 pages, 3 figures and 2 tables", "journal-ref": null, "doi": "10.1109/ACCESS.2017.2779939", "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Fully convolutional neural networks (FCN) have been shown to achieve\nstate-of-the-art performance on the task of classifying time series sequences.\nWe propose the augmentation of fully convolutional networks with long short\nterm memory recurrent neural network (LSTM RNN) sub-modules for time series\nclassification. Our proposed models significantly enhance the performance of\nfully convolutional networks with a nominal increase in model size and require\nminimal preprocessing of the dataset. The proposed Long Short Term Memory Fully\nConvolutional Network (LSTM-FCN) achieves state-of-the-art performance compared\nto others. We also explore the usage of attention mechanism to improve time\nseries classification with the Attention Long Short Term Memory Fully\nConvolutional Network (ALSTM-FCN). Utilization of the attention mechanism\nallows one to visualize the decision process of the LSTM cell. Furthermore, we\npropose fine-tuning as a method to enhance the performance of trained models.\nAn overall analysis of the performance of our model is provided and compared to\nother techniques.\n", "versions": [{"version": "v1", "created": "Fri, 8 Sep 2017 13:35:36 GMT"}], "update_date": "2018-03-20", "authors_parsed": [["Karim", "Fazle", ""], ["Majumdar", "Somshubra", ""], ["Darabi", "Houshang", ""], ["Chen", "Shun", ""]]}, {"id": "1709.05231", "submitter": "Argyris Kalogeratos", "authors": "Kevin Scaman, Argyris Kalogeratos, Luca Corinzia, Nicolas Vayatis", "title": "A Spectral Method for Activity Shaping in Continuous-Time Information\n  Cascades", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.AI cs.LG cs.SI math.OC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Information Cascades Model captures dynamical properties of user activity in\na social network. In this work, we develop a novel framework for activity\nshaping under the Continuous-Time Information Cascades Model which allows the\nadministrator for local control actions by allocating targeted resources that\ncan alter the spread of the process. Our framework employs the optimization of\nthe spectral radius of the Hazard matrix, a quantity that has been shown to\ndrive the maximum influence in a network, while enjoying a simple convex\nrelaxation when used to minimize the influence of the cascade. In addition,\nuse-cases such as quarantine and node immunization are discussed to highlight\nthe generality of the proposed activity shaping framework. Finally, we present\nthe NetShape influence minimization method which is compared favorably to\nbaseline and state-of-the-art approaches through simulations on real social\nnetworks.\n", "versions": [{"version": "v1", "created": "Fri, 15 Sep 2017 14:32:36 GMT"}], "update_date": "2017-09-18", "authors_parsed": [["Scaman", "Kevin", ""], ["Kalogeratos", "Argyris", ""], ["Corinzia", "Luca", ""], ["Vayatis", "Nicolas", ""]]}, {"id": "1709.05246", "submitter": "Baojian Zhou", "authors": "Feng Chen, Baojian Zhou, Adil Alim, Liang Zhao", "title": "A Generic Framework for Interesting Subspace Cluster Detection in\n  Multi-attributed Networks", "comments": "18 pages, Accepted by IEEE International Conference on Data Mining\n  (ICDM), 2017", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Detection of interesting (e.g., coherent or anomalous) clusters has been\nstudied extensively on plain or univariate networks, with various applications.\nRecently, algorithms have been extended to networks with multiple attributes\nfor each node in the real-world. In a multi-attributed network, often, a\ncluster of nodes is only interesting for a subset (subspace) of attributes, and\nthis type of clusters is called subspace clusters. However, in the current\nliterature, few methods are capable of detecting subspace clusters, which\ninvolves concurrent feature selection and network cluster detection. These\nrelevant methods are mostly heuristic-driven and customized for specific\napplication scenarios.\n  In this work, we present a generic and theoretical framework for detection of\ninteresting subspace clusters in large multi-attributed networks. Specifically,\nwe propose a subspace graph-structured matching pursuit algorithm, namely,\nSG-Pursuit, to address a broad class of such problems for different score\nfunctions (e.g., coherence or anomalous functions) and topology constraints\n(e.g., connected subgraphs and dense subgraphs). We prove that our algorithm 1)\nruns in nearly-linear time on the network size and the total number of\nattributes and 2) enjoys rigorous guarantees (geometrical convergence rate and\ntight error bound) analogous to those of the state-of-the-art algorithms for\nsparse feature selection problems and subgraph detection problems. As a case\nstudy, we specialize SG-Pursuit to optimize a number of well-known score\nfunctions for two typical tasks, including detection of coherent dense and\nanomalous connected subspace clusters in real-world networks. Empirical\nevidence demonstrates that our proposed generic algorithm SG-Pursuit performs\nsuperior over state-of-the-art methods that are designed specifically for these\ntwo tasks.\n", "versions": [{"version": "v1", "created": "Fri, 15 Sep 2017 14:58:49 GMT"}, {"version": "v2", "created": "Thu, 20 Sep 2018 15:09:11 GMT"}], "update_date": "2018-09-21", "authors_parsed": [["Chen", "Feng", ""], ["Zhou", "Baojian", ""], ["Alim", "Adil", ""], ["Zhao", "Liang", ""]]}, {"id": "1709.05254", "submitter": "Marco Schreyer", "authors": "Marco Schreyer, Timur Sattarov, Damian Borth, Andreas Dengel and Bernd\n  Reimer", "title": "Detection of Anomalies in Large Scale Accounting Data using Deep\n  Autoencoder Networks", "comments": "19 pages, 6 figures, 3 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Learning to detect fraud in large-scale accounting data is one of the\nlong-standing challenges in financial statement audits or fraud investigations.\nNowadays, the majority of applied techniques refer to handcrafted rules derived\nfrom known fraud scenarios. While fairly successful, these rules exhibit the\ndrawback that they often fail to generalize beyond known fraud scenarios and\nfraudsters gradually find ways to circumvent them. To overcome this\ndisadvantage and inspired by the recent success of deep learning we propose the\napplication of deep autoencoder neural networks to detect anomalous journal\nentries. We demonstrate that the trained network's reconstruction error\nobtainable for a journal entry and regularized by the entry's individual\nattribute probabilities can be interpreted as a highly adaptive anomaly\nassessment. Experiments on two real-world datasets of journal entries, show the\neffectiveness of the approach resulting in high f1-scores of 32.93 (dataset A)\nand 16.95 (dataset B) and less false positive alerts compared to state of the\nart baseline methods. Initial feedback received by chartered accountants and\nfraud examiners underpinned the quality of the approach in capturing highly\nrelevant accounting anomalies.\n", "versions": [{"version": "v1", "created": "Fri, 15 Sep 2017 15:07:29 GMT"}, {"version": "v2", "created": "Wed, 1 Aug 2018 15:47:52 GMT"}], "update_date": "2018-08-02", "authors_parsed": [["Schreyer", "Marco", ""], ["Sattarov", "Timur", ""], ["Borth", "Damian", ""], ["Dengel", "Andreas", ""], ["Reimer", "Bernd", ""]]}, {"id": "1709.05262", "submitter": "Vikas Garg", "authors": "Vikas K. Garg, Adam Kalai", "title": "Supervising Unsupervised Learning", "comments": "11 two column pages. arXiv admin note: substantial text overlap with\n  arXiv:1612.09030", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce a framework to leverage knowledge acquired from a repository of\n(heterogeneous) supervised datasets to new unsupervised datasets. Our\nperspective avoids the subjectivity inherent in unsupervised learning by\nreducing it to supervised learning, and provides a principled way to evaluate\nunsupervised algorithms. We demonstrate the versatility of our framework via\nsimple agnostic bounds on unsupervised problems. In the context of clustering,\nour approach helps choose the number of clusters and the clustering algorithm,\nremove the outliers, and provably circumvent the Kleinberg's impossibility\nresult. Experimental results across hundreds of problems demonstrate improved\nperformance on unsupervised data with simple algorithms, despite the fact that\nour problems come from heterogeneous domains. Additionally, our framework lets\nus leverage deep networks to learn common features from many such small\ndatasets, and perform zero shot learning.\n", "versions": [{"version": "v1", "created": "Thu, 14 Sep 2017 14:42:41 GMT"}, {"version": "v2", "created": "Fri, 16 Feb 2018 14:08:39 GMT"}], "update_date": "2018-02-19", "authors_parsed": [["Garg", "Vikas K.", ""], ["Kalai", "Adam", ""]]}, {"id": "1709.05289", "submitter": "Philipp Petersen", "authors": "Philipp Petersen, Felix Voigtlaender", "title": "Optimal approximation of piecewise smooth functions using deep ReLU\n  neural networks", "comments": "Generalized some estimates to $L^p$ norms for $0<p<\\infty$", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.FA cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the necessary and sufficient complexity of ReLU neural networks---in\nterms of depth and number of weights---which is required for approximating\nclassifier functions in $L^2$. As a model class, we consider the set\n$\\mathcal{E}^\\beta (\\mathbb R^d)$ of possibly discontinuous piecewise $C^\\beta$\nfunctions $f : [-1/2, 1/2]^d \\to \\mathbb R$, where the different smooth regions\nof $f$ are separated by $C^\\beta$ hypersurfaces. For dimension $d \\geq 2$,\nregularity $\\beta > 0$, and accuracy $\\varepsilon > 0$, we construct artificial\nneural networks with ReLU activation function that approximate functions from\n$\\mathcal{E}^\\beta(\\mathbb R^d)$ up to $L^2$ error of $\\varepsilon$. The\nconstructed networks have a fixed number of layers, depending only on $d$ and\n$\\beta$, and they have $O(\\varepsilon^{-2(d-1)/\\beta})$ many nonzero weights,\nwhich we prove to be optimal. In addition to the optimality in terms of the\nnumber of weights, we show that in order to achieve the optimal approximation\nrate, one needs ReLU networks of a certain depth. Precisely, for piecewise\n$C^\\beta(\\mathbb R^d)$ functions, this minimal depth is given---up to a\nmultiplicative constant---by $\\beta/d$. Up to a log factor, our constructed\nnetworks match this bound. This partly explains the benefits of depth for ReLU\nnetworks by showing that deep networks are necessary to achieve efficient\napproximation of (piecewise) smooth functions. Finally, we analyze\napproximation in high-dimensional spaces where the function $f$ to be\napproximated can be factorized into a smooth dimension reducing feature map\n$\\tau$ and classifier function $g$---defined on a low-dimensional feature\nspace---as $f = g \\circ \\tau$. We show that in this case the approximation rate\ndepends only on the dimension of the feature space and not the input dimension.\n", "versions": [{"version": "v1", "created": "Fri, 15 Sep 2017 16:14:39 GMT"}, {"version": "v2", "created": "Thu, 21 Sep 2017 14:42:27 GMT"}, {"version": "v3", "created": "Fri, 5 Jan 2018 14:35:54 GMT"}, {"version": "v4", "created": "Tue, 22 May 2018 11:24:29 GMT"}], "update_date": "2018-05-23", "authors_parsed": [["Petersen", "Philipp", ""], ["Voigtlaender", "Felix", ""]]}, {"id": "1709.05340", "submitter": "Saarthak Sarup", "authors": "Saarthak Sarup and Mingoo Seok", "title": "Dynamic Capacity Estimation in Hopfield Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Understanding the memory capacity of neural networks remains a challenging\nproblem in implementing artificial intelligence systems. In this paper, we\naddress the notion of capacity with respect to Hopfield networks and propose a\ndynamic approach to monitoring a network's capacity. We define our\nunderstanding of capacity as the maximum number of stored patterns which can be\nretrieved when probed by the stored patterns. Prior work in this area has\npresented static expressions dependent on neuron count $N$, forcing network\ndesigners to assume worst-case input characteristics for bias and correlation\nwhen setting the capacity of the network. Instead, our model operates\nsimultaneously with the learning Hopfield network and concludes on a capacity\nestimate based on the patterns which were stored. By continuously updating the\ncrosstalk associated with the stored patterns, our model guards the network\nfrom overwriting its memory traces and exceeding its capacity. We simulate our\nmodel using artificially generated random patterns, which can be set to a\ndesired bias and correlation, and observe capacity estimates between 93% and\n97% accurate. As a result, our model doubles the memory efficiency of Hopfield\nnetworks in comparison to the static and worst-case capacity estimate while\nminimizing the risk of lost patterns.\n", "versions": [{"version": "v1", "created": "Fri, 15 Sep 2017 01:48:20 GMT"}], "update_date": "2017-09-19", "authors_parsed": [["Sarup", "Saarthak", ""], ["Seok", "Mingoo", ""]]}, {"id": "1709.05342", "submitter": "Christopher M. Poskitt", "authors": "Jun Inoue, Yoriyuki Yamagata, Yuqi Chen, Christopher M. Poskitt, Jun\n  Sun", "title": "Anomaly Detection for a Water Treatment System Using Unsupervised\n  Machine Learning", "comments": null, "journal-ref": "Proc. IEEE International Conference on Data Mining Workshops\n  (ICDMW 2017): Data Mining for Cyberphysical and Industrial Systems (DMCIS\n  2017), pages 1058-1065. IEEE, 2017", "doi": "10.1109/ICDMW.2017.149", "report-no": null, "categories": "cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we propose and evaluate the application of unsupervised\nmachine learning to anomaly detection for a Cyber-Physical System (CPS). We\ncompare two methods: Deep Neural Networks (DNN) adapted to time series data\ngenerated by a CPS, and one-class Support Vector Machines (SVM). These methods\nare evaluated against data from the Secure Water Treatment (SWaT) testbed, a\nscaled-down but fully operational raw water purification plant. For both\nmethods, we first train detectors using a log generated by SWaT operating under\nnormal conditions. Then, we evaluate the performance of both methods using a\nlog generated by SWaT operating under 36 different attack scenarios. We find\nthat our DNN generates fewer false positives than our one-class SVM while our\nSVM detects slightly more anomalies. Overall, our DNN has a slightly better F\nmeasure than our SVM. We discuss the characteristics of the DNN and one-class\nSVM used in this experiment, and compare the advantages and disadvantages of\nthe two methods.\n", "versions": [{"version": "v1", "created": "Fri, 15 Sep 2017 17:12:34 GMT"}, {"version": "v2", "created": "Mon, 25 Sep 2017 05:38:55 GMT"}], "update_date": "2017-12-25", "authors_parsed": [["Inoue", "Jun", ""], ["Yamagata", "Yoriyuki", ""], ["Chen", "Yuqi", ""], ["Poskitt", "Christopher M.", ""], ["Sun", "Jun", ""]]}, {"id": "1709.05362", "submitter": "Nasser Mohammadiha", "authors": "Nasser Mohammadiha, Paris Smaragdis, Arne Leijon", "title": "Supervised and Unsupervised Speech Enhancement Using Nonnegative Matrix\n  Factorization", "comments": null, "journal-ref": "IEEE Trans. Audio, Speech and Language Process., vol. 21, no. 10,\n  Oct. 2013", "doi": "10.1109/TASL.2013.2270369", "report-no": null, "categories": "cs.SD cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Reducing the interference noise in a monaural noisy speech signal has been a\nchallenging task for many years. Compared to traditional unsupervised speech\nenhancement methods, e.g., Wiener filtering, supervised approaches, such as\nalgorithms based on hidden Markov models (HMM), lead to higher-quality enhanced\nspeech signals. However, the main practical difficulty of these approaches is\nthat for each noise type a model is required to be trained a priori. In this\npaper, we investigate a new class of supervised speech denoising algorithms\nusing nonnegative matrix factorization (NMF). We propose a novel speech\nenhancement method that is based on a Bayesian formulation of NMF (BNMF). To\ncircumvent the mismatch problem between the training and testing stages, we\npropose two solutions. First, we use an HMM in combination with BNMF (BNMF-HMM)\nto derive a minimum mean square error (MMSE) estimator for the speech signal\nwith no information about the underlying noise type. Second, we suggest a\nscheme to learn the required noise BNMF model online, which is then used to\ndevelop an unsupervised speech enhancement system. Extensive experiments are\ncarried out to investigate the performance of the proposed methods under\ndifferent conditions. Moreover, we compare the performance of the developed\nalgorithms with state-of-the-art speech enhancement schemes using various\nobjective measures. Our simulations show that the proposed BNMF-based methods\noutperform the competing algorithms substantially.\n", "versions": [{"version": "v1", "created": "Fri, 15 Sep 2017 18:34:52 GMT"}], "update_date": "2017-09-19", "authors_parsed": [["Mohammadiha", "Nasser", ""], ["Smaragdis", "Paris", ""], ["Leijon", "Arne", ""]]}, {"id": "1709.05379", "submitter": "Nasser Mohammadiha", "authors": "Ghazaleh Panahandeh, Erik Ek, Nasser Mohammadiha", "title": "Road Friction Estimation for Connected Vehicles using Supervised Machine\n  Learning", "comments": "Published at IV 2017", "journal-ref": null, "doi": "10.1109/IVS.2017.7995885", "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, the problem of road friction prediction from a fleet of\nconnected vehicles is investigated. A framework is proposed to predict the road\nfriction level using both historical friction data from the connected cars and\ndata from weather stations, and comparative results from different methods are\npresented. The problem is formulated as a classification task where the\navailable data is used to train three machine learning models including\nlogistic regression, support vector machine, and neural networks to predict the\nfriction class (slippery or non-slippery) in the future for specific road\nsegments. In addition to the friction values, which are measured by moving\nvehicles, additional parameters such as humidity, temperature, and rainfall are\nused to obtain a set of descriptive feature vectors as input to the\nclassification methods. The proposed prediction models are evaluated for\ndifferent prediction horizons (0 to 120 minutes in the future) where the\nevaluation shows that the neural networks method leads to more stable results\nin different conditions.\n", "versions": [{"version": "v1", "created": "Fri, 15 Sep 2017 19:52:18 GMT"}], "update_date": "2017-09-19", "authors_parsed": [["Panahandeh", "Ghazaleh", ""], ["Ek", "Erik", ""], ["Mohammadiha", "Nasser", ""]]}, {"id": "1709.05380", "submitter": "Brendan O'Donoghue", "authors": "Brendan O'Donoghue, Ian Osband, Remi Munos, Volodymyr Mnih", "title": "The Uncertainty Bellman Equation and Exploration", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG math.OC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the exploration/exploitation problem in reinforcement learning.\nFor exploitation, it is well known that the Bellman equation connects the value\nat any time-step to the expected value at subsequent time-steps. In this paper\nwe consider a similar \\textit{uncertainty} Bellman equation (UBE), which\nconnects the uncertainty at any time-step to the expected uncertainties at\nsubsequent time-steps, thereby extending the potential exploratory benefit of a\npolicy beyond individual time-steps. We prove that the unique fixed point of\nthe UBE yields an upper bound on the variance of the posterior distribution of\nthe Q-values induced by any policy. This bound can be much tighter than\ntraditional count-based bonuses that compound standard deviation rather than\nvariance. Importantly, and unlike several existing approaches to optimism, this\nmethod scales naturally to large systems with complex generalization.\nSubstituting our UBE-exploration strategy for $\\epsilon$-greedy improves DQN\nperformance on 51 out of 57 games in the Atari suite.\n", "versions": [{"version": "v1", "created": "Fri, 15 Sep 2017 19:55:58 GMT"}, {"version": "v2", "created": "Fri, 8 Jun 2018 11:47:43 GMT"}, {"version": "v3", "created": "Tue, 19 Jun 2018 15:42:36 GMT"}, {"version": "v4", "created": "Mon, 22 Oct 2018 15:25:04 GMT"}], "update_date": "2018-10-23", "authors_parsed": [["O'Donoghue", "Brendan", ""], ["Osband", "Ian", ""], ["Munos", "Remi", ""], ["Mnih", "Volodymyr", ""]]}, {"id": "1709.05412", "submitter": "Soheil Kolouri", "authors": "Mohammad Rostami, Soheil Kolouri, Kyungnam Kim, Eric Eaton", "title": "Multi-Agent Distributed Lifelong Learning for Collective Knowledge\n  Acquisition", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Lifelong machine learning methods acquire knowledge over a series of\nconsecutive tasks, continually building upon their experience. Current lifelong\nlearning algorithms rely upon a single learning agent that has centralized\naccess to all data. In this paper, we extend the idea of lifelong learning from\na single agent to a network of multiple agents that collectively learn a series\nof tasks. Each agent faces some (potentially unique) set of tasks; the key idea\nis that knowledge learned from these tasks may benefit other agents trying to\nlearn different (but related) tasks. Our Collective Lifelong Learning Algorithm\n(CoLLA) provides an efficient way for a network of agents to share their\nlearned knowledge in a distributed and decentralized manner, while preserving\nthe privacy of the locally observed data. Note that a decentralized scheme is a\nsubclass of distributed algorithms where a central server does not exist and in\naddition to data, computations are also distributed among the agents. We\nprovide theoretical guarantees for robust performance of the algorithm and\nempirically demonstrate that CoLLA outperforms existing approaches for\ndistributed multi-task learning on a variety of data sets.\n", "versions": [{"version": "v1", "created": "Fri, 15 Sep 2017 21:24:26 GMT"}, {"version": "v2", "created": "Tue, 20 Feb 2018 21:37:12 GMT"}], "update_date": "2018-02-22", "authors_parsed": [["Rostami", "Mohammad", ""], ["Kolouri", "Soheil", ""], ["Kim", "Kyungnam", ""], ["Eaton", "Eric", ""]]}, {"id": "1709.05418", "submitter": "Brian McWilliams", "authors": "Simon Kallweit and Thomas M\\\"uller and Brian McWilliams and Markus\n  Gross and Jan Nov\\'ak", "title": "Deep Scattering: Rendering Atmospheric Clouds with Radiance-Predicting\n  Neural Networks", "comments": "ACM Transactions on Graphics (Proceedings of SIGGRAPH Asia 2017)", "journal-ref": null, "doi": "10.1145/3130800.3130880", "report-no": null, "categories": "cs.LG cs.GR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a technique for efficiently synthesizing images of atmospheric\nclouds using a combination of Monte Carlo integration and neural networks. The\nintricacies of Lorenz-Mie scattering and the high albedo of cloud-forming\naerosols make rendering of clouds---e.g. the characteristic silverlining and\nthe \"whiteness\" of the inner body---challenging for methods based solely on\nMonte Carlo integration or diffusion theory. We approach the problem\ndifferently. Instead of simulating all light transport during rendering, we\npre-learn the spatial and directional distribution of radiant flux from tens of\ncloud exemplars. To render a new scene, we sample visible points of the cloud\nand, for each, extract a hierarchical 3D descriptor of the cloud geometry with\nrespect to the shading location and the light source. The descriptor is input\nto a deep neural network that predicts the radiance function for each shading\nconfiguration. We make the key observation that progressively feeding the\nhierarchical descriptor into the network enhances the network's ability to\nlearn faster and predict with high accuracy while using few coefficients. We\nalso employ a block design with residual connections to further improve\nperformance. A GPU implementation of our method synthesizes images of clouds\nthat are nearly indistinguishable from the reference solution within seconds\ninteractively. Our method thus represents a viable solution for applications\nsuch as cloud design and, thanks to its temporal stability, also for\nhigh-quality production of animated content.\n", "versions": [{"version": "v1", "created": "Fri, 15 Sep 2017 21:40:02 GMT"}], "update_date": "2017-09-19", "authors_parsed": [["Kallweit", "Simon", ""], ["M\u00fcller", "Thomas", ""], ["McWilliams", "Brian", ""], ["Gross", "Markus", ""], ["Nov\u00e1k", "Jan", ""]]}, {"id": "1709.05433", "submitter": "Zhiyun Ren", "authors": "Zhiyun Ren, Xia Ning, Huzefa Rangwala", "title": "Grade Prediction with Temporal Course-wise Influence", "comments": "8 pages, 5 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  There is a critical need to develop new educational technology applications\nthat analyze the data collected by universities to ensure that students\ngraduate in a timely fashion (4 to 6 years); and they are well prepared for\njobs in their respective fields of study. In this paper, we present a novel\napproach for analyzing historical educational records from a large, public\nuniversity to perform next-term grade prediction; i.e., to estimate the grades\nthat a student will get in a course that he/she will enroll in the next term.\nAccurate next-term grade prediction holds the promise for better student degree\nplanning, personalized advising and automated interventions to ensure that\nstudents stay on track in their chosen degree program and graduate on time. We\npresent a factorization-based approach called Matrix Factorization with\nTemporal Course-wise Influence that incorporates course-wise influence effects\nand temporal effects for grade prediction. In this model, students and courses\nare represented in a latent \"knowledge\" space. The grade of a student on a\ncourse is modeled as the similarity of their latent representation in the\n\"knowledge\" space. Course-wise influence is considered as an additional factor\nin the grade prediction. Our experimental results show that the proposed method\noutperforms several baseline approaches and infer meaningful patterns between\npairs of courses within academic programs.\n", "versions": [{"version": "v1", "created": "Fri, 15 Sep 2017 23:08:49 GMT"}], "update_date": "2017-09-19", "authors_parsed": [["Ren", "Zhiyun", ""], ["Ning", "Xia", ""], ["Rangwala", "Huzefa", ""]]}, {"id": "1709.05448", "submitter": "James Harrison", "authors": "Brian Ichter, James Harrison, Marco Pavone", "title": "Learning Sampling Distributions for Robot Motion Planning", "comments": "International Conference on Robotics and Automation (ICRA), 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A defining feature of sampling-based motion planning is the reliance on an\nimplicit representation of the state space, which is enabled by a set of\nprobing samples. Traditionally, these samples are drawn either\nprobabilistically or deterministically to uniformly cover the state space. Yet,\nthe motion of many robotic systems is often restricted to \"small\" regions of\nthe state space, due to, for example, differential constraints or\ncollision-avoidance constraints. To accelerate the planning process, it is thus\ndesirable to devise non-uniform sampling strategies that favor sampling in\nthose regions where an optimal solution might lie. This paper proposes a\nmethodology for non-uniform sampling, whereby a sampling distribution is\nlearned from demonstrations, and then used to bias sampling. The sampling\ndistribution is computed through a conditional variational autoencoder,\nallowing sample generation from the latent space conditioned on the specific\nplanning problem. This methodology is general, can be used in combination with\nany sampling-based planner, and can effectively exploit the underlying\nstructure of a planning problem while maintaining the theoretical guarantees of\nsampling-based approaches. Specifically, on several planning problems, the\nproposed methodology is shown to effectively learn representations for the\nrelevant regions of the state space, resulting in an order of magnitude\nimprovement in terms of success rate and convergence to the optimal cost.\n", "versions": [{"version": "v1", "created": "Sat, 16 Sep 2017 03:08:04 GMT"}, {"version": "v2", "created": "Thu, 1 Mar 2018 02:41:09 GMT"}, {"version": "v3", "created": "Tue, 12 Mar 2019 02:40:29 GMT"}], "update_date": "2019-03-13", "authors_parsed": [["Ichter", "Brian", ""], ["Harrison", "James", ""], ["Pavone", "Marco", ""]]}, {"id": "1709.05480", "submitter": "Yannis Papanikolaou", "authors": "Yannis Papanikolaou and Grigorios Tsoumakas", "title": "Subset Labeled LDA for Large-Scale Multi-Label Classification", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Labeled Latent Dirichlet Allocation (LLDA) is an extension of the standard\nunsupervised Latent Dirichlet Allocation (LDA) algorithm, to address\nmulti-label learning tasks. Previous work has shown it to perform in par with\nother state-of-the-art multi-label methods. Nonetheless, with increasing label\nsets sizes LLDA encounters scalability issues. In this work, we introduce\nSubset LLDA, a simple variant of the standard LLDA algorithm, that not only can\neffectively scale up to problems with hundreds of thousands of labels but also\nimproves over the LLDA state-of-the-art. We conduct extensive experiments on\neight data sets, with label sets sizes ranging from hundreds to hundreds of\nthousands, comparing our proposed algorithm with the previously proposed LLDA\nalgorithms (Prior--LDA, Dep--LDA), as well as the state of the art in extreme\nmulti-label classification. The results show a steady advantage of our method\nover the other LLDA algorithms and competitive results compared to the extreme\nmulti-label classification algorithms.\n", "versions": [{"version": "v1", "created": "Sat, 16 Sep 2017 08:35:12 GMT"}], "update_date": "2017-09-19", "authors_parsed": [["Papanikolaou", "Yannis", ""], ["Tsoumakas", "Grigorios", ""]]}, {"id": "1709.05506", "submitter": "Patrick Rubin-Delanchy Dr", "authors": "Patrick Rubin-Delanchy, Joshua Cape, Minh Tang and Carey E. Priebe", "title": "A statistical interpretation of spectral embedding: the generalised\n  random dot product graph", "comments": "30 pages; 10 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A generalisation of a latent position network model known as the random dot\nproduct graph is considered. We show that, whether the normalised Laplacian or\nadjacency matrix is used, the vector representations of nodes obtained by\nspectral embedding, using the largest eigenvalues by magnitude, provide\nstrongly consistent latent position estimates with asymptotically Gaussian\nerror, up to indefinite orthogonal transformation. The mixed membership and\nstandard stochastic block models constitute special cases where the latent\npositions live respectively inside or on the vertices of a simplex, crucially,\nwithout assuming the underlying block connectivity probability matrix is\npositive-definite. Estimation via spectral embedding can therefore be achieved\nby respectively estimating this simplicial support, or fitting a Gaussian\nmixture model. In the latter case, the use of $K$-means (with Euclidean\ndistance), as has been previously recommended, is suboptimal and for\nidentifiability reasons unsound. Indeed, Euclidean distances and angles are not\npreserved under indefinite orthogonal transformation, and we show stochastic\nblock model examples where such quantities vary appreciably. Empirical\nimprovements in link prediction (over the random dot product graph), as well as\nthe potential to uncover richer latent structure (than posited under the mixed\nmembership or standard stochastic block models) are demonstrated in a\ncyber-security example.\n", "versions": [{"version": "v1", "created": "Sat, 16 Sep 2017 12:30:40 GMT"}, {"version": "v2", "created": "Thu, 21 Sep 2017 12:58:52 GMT"}, {"version": "v3", "created": "Sun, 29 Jul 2018 19:02:30 GMT"}, {"version": "v4", "created": "Wed, 8 Jan 2020 16:27:46 GMT"}], "update_date": "2020-01-09", "authors_parsed": [["Rubin-Delanchy", "Patrick", ""], ["Cape", "Joshua", ""], ["Tang", "Minh", ""], ["Priebe", "Carey E.", ""]]}, {"id": "1709.05538", "submitter": "Wentao Zhu", "authors": "Wentao Zhu, Chaochun Liu, Wei Fan, Xiaohui Xie", "title": "DeepLung: 3D Deep Convolutional Nets for Automated Pulmonary Nodule\n  Detection and Classification", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG cs.NE", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  In this work, we present a fully automated lung CT cancer diagnosis system,\nDeepLung. DeepLung contains two parts, nodule detection and classification.\nConsidering the 3D nature of lung CT data, two 3D networks are designed for the\nnodule detection and classification respectively. Specifically, a 3D Faster\nR-CNN is designed for nodule detection with a U-net-like encoder-decoder\nstructure to effectively learn nodule features. For nodule classification,\ngradient boosting machine (GBM) with 3D dual path network (DPN) features is\nproposed. The nodule classification subnetwork is validated on a public dataset\nfrom LIDC-IDRI, on which it achieves better performance than state-of-the-art\napproaches, and surpasses the average performance of four experienced doctors.\nFor the DeepLung system, candidate nodules are detected first by the nodule\ndetection subnetwork, and nodule diagnosis is conducted by the classification\nsubnetwork. Extensive experimental results demonstrate the DeepLung is\ncomparable to the experienced doctors both for the nodule-level and\npatient-level diagnosis on the LIDC-IDRI dataset.\n", "versions": [{"version": "v1", "created": "Sat, 16 Sep 2017 16:18:22 GMT"}], "update_date": "2017-09-19", "authors_parsed": [["Zhu", "Wentao", ""], ["Liu", "Chaochun", ""], ["Fan", "Wei", ""], ["Xie", "Xiaohui", ""]]}, {"id": "1709.05545", "submitter": "Yangzi Guo", "authors": "Gitesh Dawer, Yangzi Guo, Adrian Barbu", "title": "Generating Compact Tree Ensembles via Annealing", "comments": "Comparison with Random Forest included in the results section", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Tree ensembles are flexible predictive models that can capture relevant\nvariables and to some extent their interactions in a compact and interpretable\nmanner. Most algorithms for obtaining tree ensembles are based on versions of\nboosting or Random Forest. Previous work showed that boosting algorithms\nexhibit a cyclic behavior of selecting the same tree again and again due to the\nway the loss is optimized. At the same time, Random Forest is not based on loss\noptimization and obtains a more complex and less interpretable model. In this\npaper we present a novel method for obtaining compact tree ensembles by growing\na large pool of trees in parallel with many independent boosting threads and\nthen selecting a small subset and updating their leaf weights by loss\noptimization. We allow for the trees in the initial pool to have different\ndepths which further helps with generalization. Experiments on real datasets\nshow that the obtained model has usually a smaller loss than boosting, which is\nalso reflected in a lower misclassification error on the test set.\n", "versions": [{"version": "v1", "created": "Sat, 16 Sep 2017 18:26:18 GMT"}, {"version": "v2", "created": "Tue, 17 Oct 2017 03:03:27 GMT"}, {"version": "v3", "created": "Mon, 5 Feb 2018 18:27:57 GMT"}, {"version": "v4", "created": "Thu, 20 Feb 2020 03:25:08 GMT"}], "update_date": "2020-02-21", "authors_parsed": [["Dawer", "Gitesh", ""], ["Guo", "Yangzi", ""], ["Barbu", "Adrian", ""]]}, {"id": "1709.05554", "submitter": "Yan Shu", "authors": "Davis Liang, Yan Shu", "title": "Deep Automated Multi-task Learning", "comments": "IJCNLP 2017", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Multi-task learning (MTL) has recently contributed to learning better\nrepresentations in service of various NLP tasks. MTL aims at improving the\nperformance of a primary task, by jointly training on a secondary task. This\npaper introduces automated tasks, which exploit the sequential nature of the\ninput data, as secondary tasks in an MTL model. We explore next word\nprediction, next character prediction, and missing word completion as potential\nautomated tasks. Our results show that training on a primary task in parallel\nwith a secondary automated task improves both the convergence speed and\naccuracy for the primary task. We suggest two methods for augmenting an\nexisting network with automated tasks and establish better performance in topic\nprediction, sentiment analysis, and hashtag recommendation. Finally, we show\nthat the MTL models can perform well on datasets that are small and colloquial\nby nature.\n", "versions": [{"version": "v1", "created": "Sat, 16 Sep 2017 19:04:54 GMT"}, {"version": "v2", "created": "Tue, 19 Sep 2017 19:05:39 GMT"}], "update_date": "2017-09-21", "authors_parsed": [["Liang", "Davis", ""], ["Shu", "Yan", ""]]}, {"id": "1709.05557", "submitter": "Nasser Mohammadiha", "authors": "Nasser Mohammadiha, Simon Doclo", "title": "Speech Dereverberation Using Nonnegative Convolutive Transfer Function\n  and Spectro temporal Modeling", "comments": null, "journal-ref": "IEEE Trans. Audio, Speech and Language Process., vol. 24, no. 2,\n  Feb. 2016", "doi": "10.1109/TASLP.2015.2501724", "report-no": null, "categories": "cs.SD cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper presents two single channel speech dereverberation methods to\nenhance the quality of speech signals that have been recorded in an enclosed\nspace. For both methods, the room acoustics are modeled using a nonnegative\napproximation of the convolutive transfer function (NCTF), and to additionally\nexploit the spectral properties of the speech signal, such as the low rank\nnature of the speech spectrogram, the speech spectrogram is modeled using\nnonnegative matrix factorization (NMF). Two methods are described to combine\nthe NCTF and NMF models. In the first method, referred to as the integrated\nmethod, a cost function is constructed by directly integrating the speech NMF\nmodel into the NCTF model, while in the second method, referred to as the\nweighted method, the NCTF and NMF based cost functions are weighted and summed.\nEfficient update rules are derived to solve both optimization problems. In\naddition, an extension of the integrated method is presented, which exploits\nthe temporal dependencies of the speech signal. Several experiments are\nperformed on reverberant speech signals with and without background noise,\nwhere the integrated method yields a considerably higher speech quality than\nthe baseline NCTF method and a state of the art spectral enhancement method.\nMoreover, the experimental results indicate that the weighted method can even\nlead to a better performance in terms of instrumental quality measures, but\nthat the optimal weighting parameter depends on the room acoustics and the\nutilized NMF model. Modeling the temporal dependencies in the integrated method\nwas found to be useful only for highly reverberant conditions.\n", "versions": [{"version": "v1", "created": "Sat, 16 Sep 2017 19:43:44 GMT"}], "update_date": "2017-09-19", "authors_parsed": [["Mohammadiha", "Nasser", ""], ["Doclo", "Simon", ""]]}, {"id": "1709.05559", "submitter": "Nasser Mohammadiha", "authors": "Nasser Mohammadiha, Arne Leijon", "title": "Nonnegative HMM for Babble Noise Derived from Speech HMM: Application to\n  Speech Enhancement", "comments": null, "journal-ref": "IEEE Trans. Audio, Speech and Language Process., vol. 21, no. 5,\n  pp. 998-1011, May 2013", "doi": "10.1109/TASL.2013.2243435", "report-no": null, "categories": "cs.SD cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deriving a good model for multitalker babble noise can facilitate different\nspeech processing algorithms, e.g. noise reduction, to reduce the so-called\ncocktail party difficulty. In the available systems, the fact that the babble\nwaveform is generated as a sum of N different speech waveforms is not exploited\nexplicitly. In this paper, first we develop a gamma hidden Markov model for\npower spectra of the speech signal, and then formulate it as a sparse\nnonnegative matrix factorization (NMF). Second, the sparse NMF is extended by\nrelaxing the sparsity constraint, and a novel model for babble noise (gamma\nnonnegative HMM) is proposed in which the babble basis matrix is the same as\nthe speech basis matrix, and only the activation factors (weights) of the basis\nvectors are different for the two signals over time. Finally, a noise reduction\nalgorithm is proposed using the derived speech and babble models. All of the\nstationary model parameters are estimated using the expectation-maximization\n(EM) algorithm, whereas the time-varying parameters, i.e. the gain parameters\nof speech and babble signals, are estimated using a recursive EM algorithm. The\nobjective and subjective listening evaluations show that the proposed babble\nmodel and the final noise reduction algorithm significantly outperform the\nconventional methods.\n", "versions": [{"version": "v1", "created": "Sat, 16 Sep 2017 19:56:05 GMT"}], "update_date": "2017-09-19", "authors_parsed": [["Mohammadiha", "Nasser", ""], ["Leijon", "Arne", ""]]}, {"id": "1709.05581", "submitter": "Sauhaarda Chowdhuri", "authors": "Sauhaarda Chowdhuri, Tushar Pankaj, Karl Zipser", "title": "MultiNet: Multi-Modal Multi-Task Learning for Autonomous Driving", "comments": "Published in IEEE WACV 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.RO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Autonomous driving requires operation in different behavioral modes ranging\nfrom lane following and intersection crossing to turning and stopping. However,\nmost existing deep learning approaches to autonomous driving do not consider\nthe behavioral mode in the training strategy. This paper describes a technique\nfor learning multiple distinct behavioral modes in a single deep neural network\nthrough the use of multi-modal multi-task learning. We study the effectiveness\nof this approach, denoted MultiNet, using self-driving model cars for driving\nin unstructured environments such as sidewalks and unpaved roads. Using labeled\ndata from over one hundred hours of driving our fleet of 1/10th scale model\ncars, we trained different neural networks to predict the steering angle and\ndriving speed of the vehicle in different behavioral modes. We show that in\neach case, MultiNet networks outperform networks trained on individual modes\nwhile using a fraction of the total number of parameters.\n", "versions": [{"version": "v1", "created": "Sat, 16 Sep 2017 23:16:44 GMT"}, {"version": "v2", "created": "Fri, 2 Mar 2018 01:39:52 GMT"}, {"version": "v3", "created": "Thu, 23 Aug 2018 05:07:47 GMT"}, {"version": "v4", "created": "Mon, 14 Jan 2019 02:50:11 GMT"}], "update_date": "2019-01-15", "authors_parsed": [["Chowdhuri", "Sauhaarda", ""], ["Pankaj", "Tushar", ""], ["Zipser", "Karl", ""]]}, {"id": "1709.05583", "submitter": "Xiaoyu Cao", "authors": "Xiaoyu Cao, Neil Zhenqiang Gong", "title": "Mitigating Evasion Attacks to Deep Neural Networks via Region-based\n  Classification", "comments": "33rd Annual Computer Security Applications Conference (ACSAC), 2017", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep neural networks (DNNs) have transformed several artificial intelligence\nresearch areas including computer vision, speech recognition, and natural\nlanguage processing. However, recent studies demonstrated that DNNs are\nvulnerable to adversarial manipulations at testing time. Specifically, suppose\nwe have a testing example, whose label can be correctly predicted by a DNN\nclassifier. An attacker can add a small carefully crafted noise to the testing\nexample such that the DNN classifier predicts an incorrect label, where the\ncrafted testing example is called adversarial example. Such attacks are called\nevasion attacks. Evasion attacks are one of the biggest challenges for\ndeploying DNNs in safety and security critical applications such as\nself-driving cars. In this work, we develop new methods to defend against\nevasion attacks. Our key observation is that adversarial examples are close to\nthe classification boundary. Therefore, we propose region-based classification\nto be robust to adversarial examples. For a benign/adversarial testing example,\nwe ensemble information in a hypercube centered at the example to predict its\nlabel. In contrast, traditional classifiers are point-based classification,\ni.e., given a testing example, the classifier predicts its label based on the\ntesting example alone. Our evaluation results on MNIST and CIFAR-10 datasets\ndemonstrate that our region-based classification can significantly mitigate\nevasion attacks without sacrificing classification accuracy on benign examples.\nSpecifically, our region-based classification achieves the same classification\naccuracy on testing benign examples as point-based classification, but our\nregion-based classification is significantly more robust than point-based\nclassification to various evasion attacks.\n", "versions": [{"version": "v1", "created": "Sun, 17 Sep 2017 00:18:42 GMT"}, {"version": "v2", "created": "Wed, 3 Jan 2018 06:45:33 GMT"}, {"version": "v3", "created": "Thu, 11 Jan 2018 20:58:56 GMT"}, {"version": "v4", "created": "Tue, 31 Dec 2019 14:36:29 GMT"}], "update_date": "2020-01-01", "authors_parsed": [["Cao", "Xiaoyu", ""], ["Gong", "Neil Zhenqiang", ""]]}, {"id": "1709.05584", "submitter": "William L Hamilton", "authors": "William L. Hamilton, Rex Ying, and Jure Leskovec", "title": "Representation Learning on Graphs: Methods and Applications", "comments": "Published in the IEEE Data Engineering Bulletin, September 2017;\n  version with minor corrections", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Machine learning on graphs is an important and ubiquitous task with\napplications ranging from drug design to friendship recommendation in social\nnetworks. The primary challenge in this domain is finding a way to represent,\nor encode, graph structure so that it can be easily exploited by machine\nlearning models. Traditionally, machine learning approaches relied on\nuser-defined heuristics to extract features encoding structural information\nabout a graph (e.g., degree statistics or kernel functions). However, recent\nyears have seen a surge in approaches that automatically learn to encode graph\nstructure into low-dimensional embeddings, using techniques based on deep\nlearning and nonlinear dimensionality reduction. Here we provide a conceptual\nreview of key advancements in this area of representation learning on graphs,\nincluding matrix factorization-based methods, random-walk based algorithms, and\ngraph neural networks. We review methods to embed individual nodes as well as\napproaches to embed entire (sub)graphs. In doing so, we develop a unified\nframework to describe these recent approaches, and we highlight a number of\nimportant applications and directions for future work.\n", "versions": [{"version": "v1", "created": "Sun, 17 Sep 2017 00:19:33 GMT"}, {"version": "v2", "created": "Wed, 27 Sep 2017 22:05:19 GMT"}, {"version": "v3", "created": "Tue, 10 Apr 2018 15:26:32 GMT"}], "update_date": "2018-04-11", "authors_parsed": [["Hamilton", "William L.", ""], ["Ying", "Rex", ""], ["Leskovec", "Jure", ""]]}, {"id": "1709.05602", "submitter": "Eric Lei", "authors": "Eric Lei, Kyle Miller, Michael R. Pinsky, Artur Dubrawski", "title": "Characterization of Hemodynamic Signal by Learning Multi-View\n  Relationships", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Multi-view data are increasingly prevalent in practice. It is often relevant\nto analyze the relationships between pairs of views by multi-view component\nanalysis techniques such as Canonical Correlation Analysis (CCA). However, data\nmay easily exhibit nonlinear relations, which CCA cannot reveal. We aim to\ninvestigate the usefulness of nonlinear multi-view relations to characterize\nmulti-view data in an explainable manner. To address this challenge, we propose\na method to characterize globally nonlinear multi-view relationships as a\nmixture of linear relationships. A clustering method, it identifies partitions\nof observations that exhibit the same relationships and learns those\nrelationships simultaneously. It defines cluster variables by multi-view rather\nthan spatial relationships, unlike almost all other clustering methods.\nFurthermore, we introduce a supervised classification method that builds on our\nclustering method by employing multi-view relationships as discriminative\nfactors. The value of these methods resides in their capability to find useful\nstructure in the data that single-view or current multi-view methods may\nstruggle to find. We demonstrate the potential utility of the proposed approach\nusing an application in clinical informatics to detect and characterize slow\nbleeding in patients whose central venous pressure (CVP) is monitored at the\nbedside. Presently, CVP is considered an insensitive measure of a subject's\nintravascular volume status or its change. However, we reason that features of\nCVP during inspiration and expiration should be informative in early\nidentification of emerging changes of patient status. We empirically show how\nthe proposed method can help discover and analyze multiple-to-multiple\ncorrelations, which could be nonlinear or vary throughout the population, by\nfinding explainable structure of operational interest to practitioners.\n", "versions": [{"version": "v1", "created": "Sun, 17 Sep 2017 03:12:27 GMT"}, {"version": "v2", "created": "Sun, 8 Dec 2019 22:34:06 GMT"}], "update_date": "2019-12-10", "authors_parsed": [["Lei", "Eric", ""], ["Miller", "Kyle", ""], ["Pinsky", "Michael R.", ""], ["Dubrawski", "Artur", ""]]}, {"id": "1709.05612", "submitter": "Luming Tang", "authors": "Luming Tang, Yexiang Xue, Di Chen, Carla P. Gomes", "title": "Multi-Entity Dependence Learning with Rich Context via Conditional\n  Variational Auto-encoder", "comments": "The first two authors contribute equally", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Multi-Entity Dependence Learning (MEDL) explores conditional correlations\namong multiple entities. The availability of rich contextual information\nrequires a nimble learning scheme that tightly integrates with deep neural\nnetworks and has the ability to capture correlation structures among\nexponentially many outcomes. We propose MEDL_CVAE, which encodes a conditional\nmultivariate distribution as a generating process. As a result, the variational\nlower bound of the joint likelihood can be optimized via a conditional\nvariational auto-encoder and trained end-to-end on GPUs. Our MEDL_CVAE was\nmotivated by two real-world applications in computational sustainability: one\nstudies the spatial correlation among multiple bird species using the eBird\ndata and the other models multi-dimensional landscape composition and human\nfootprint in the Amazon rainforest with satellite images. We show that\nMEDL_CVAE captures rich dependency structures, scales better than previous\nmethods, and further improves on the joint likelihood taking advantage of very\nlarge datasets that are beyond the capacity of previous methods.\n", "versions": [{"version": "v1", "created": "Sun, 17 Sep 2017 06:21:40 GMT"}], "update_date": "2017-09-19", "authors_parsed": [["Tang", "Luming", ""], ["Xue", "Yexiang", ""], ["Chen", "Di", ""], ["Gomes", "Carla P.", ""]]}, {"id": "1709.05666", "submitter": "Th\\'eo Trouillon", "authors": "Th\\'eo Trouillon, \\'Eric Gaussier, Christopher R. Dance, Guillaume\n  Bouchard", "title": "On Inductive Abilities of Latent Factor Models for Relational Learning", "comments": "30+3 pages, submitted to the Journal of Artificial Intelligence\n  Research", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Latent factor models are increasingly popular for modeling multi-relational\nknowledge graphs. By their vectorial nature, it is not only hard to interpret\nwhy this class of models works so well, but also to understand where they fail\nand how they might be improved. We conduct an experimental survey of\nstate-of-the-art models, not towards a purely comparative end, but as a means\nto get insight about their inductive abilities. To assess the strengths and\nweaknesses of each model, we create simple tasks that exhibit first, atomic\nproperties of binary relations, and then, common inter-relational inference\nthrough synthetic genealogies. Based on these experimental results, we propose\nnew research directions to improve on existing models.\n", "versions": [{"version": "v1", "created": "Sun, 17 Sep 2017 14:20:05 GMT"}], "update_date": "2017-09-19", "authors_parsed": [["Trouillon", "Th\u00e9o", ""], ["Gaussier", "\u00c9ric", ""], ["Dance", "Christopher R.", ""], ["Bouchard", "Guillaume", ""]]}, {"id": "1709.05672", "submitter": "Taesup Moon", "authors": "Sungmin Cha, Taesup Moon", "title": "Neural Affine Grayscale Image Denoising", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a new grayscale image denoiser, dubbed as Neural Affine Image\nDenoiser (Neural AIDE), which utilizes neural network in a novel way. Unlike\nother neural network based image denoising methods, which typically apply\nsimple supervised learning to learn a mapping from a noisy patch to a clean\npatch, we formulate to train a neural network to learn an \\emph{affine} mapping\nthat gets applied to a noisy pixel, based on its context. Our formulation\nenables both supervised training of the network from the labeled training\ndataset and adaptive fine-tuning of the network parameters using the given\nnoisy image subject to denoising. The key tool for devising Neural AIDE is to\ndevise an estimated loss function of the MSE of the affine mapping, solely\nbased on the noisy data. As a result, our algorithm can outperform most of the\nrecent state-of-the-art methods in the standard benchmark datasets. Moreover,\nour fine-tuning method can nicely overcome one of the drawbacks of the\npatch-level supervised learning methods in image denoising; namely, a\nsupervised trained model with a mismatched noise variance can be mostly\ncorrected as long as we have the matched noise variance during the fine-tuning\nstep.\n", "versions": [{"version": "v1", "created": "Sun, 17 Sep 2017 14:44:07 GMT"}], "update_date": "2017-09-19", "authors_parsed": [["Cha", "Sungmin", ""], ["Moon", "Taesup", ""]]}, {"id": "1709.05725", "submitter": "Saswat Padhi", "authors": "Saswat Padhi, Prateek Jain, Daniel Perelman, Oleksandr Polozov, Sumit\n  Gulwani, Todd Millstein", "title": "FlashProfile: A Framework for Synthesizing Data Profiles", "comments": "28 pages, SPLASH (OOPSLA) 2018", "journal-ref": "Proc. ACM Program. Lang. 2, OOPSLA, Article 150 (November 2018)\n  150:1-150:28", "doi": "10.1145/3276520", "report-no": null, "categories": "cs.LG", "license": "http://creativecommons.org/licenses/by-sa/4.0/", "abstract": "  We address the problem of learning a syntactic profile for a collection of\nstrings, i.e. a set of regex-like patterns that succinctly describe the\nsyntactic variations in the strings. Real-world datasets, typically curated\nfrom multiple sources, often contain data in various syntactic formats. Thus,\nany data processing task is preceded by the critical step of data format\nidentification. However, manual inspection of data to identify the different\nformats is infeasible in standard big-data scenarios.\n  Prior techniques are restricted to a small set of pre-defined patterns (e.g.\ndigits, letters, words, etc.), and provide no control over granularity of\nprofiles. We define syntactic profiling as a problem of clustering strings\nbased on syntactic similarity, followed by identifying patterns that succinctly\ndescribe each cluster. We present a technique for synthesizing such profiles\nover a given language of patterns, that also allows for interactive refinement\nby requesting a desired number of clusters.\n  Using a state-of-the-art inductive synthesis framework, PROSE, we have\nimplemented our technique as FlashProfile. Across $153$ tasks over $75$ large\nreal datasets, we observe a median profiling time of only $\\sim\\,0.7\\,$s.\nFurthermore, we show that access to syntactic profiles may allow for more\naccurate synthesis of programs, i.e. using fewer examples, in\nprogramming-by-example (PBE) workflows such as FlashFill.\n", "versions": [{"version": "v1", "created": "Sun, 17 Sep 2017 23:09:38 GMT"}, {"version": "v2", "created": "Tue, 16 Apr 2019 06:10:02 GMT"}], "update_date": "2019-04-17", "authors_parsed": [["Padhi", "Saswat", ""], ["Jain", "Prateek", ""], ["Perelman", "Daniel", ""], ["Polozov", "Oleksandr", ""], ["Gulwani", "Sumit", ""], ["Millstein", "Todd", ""]]}, {"id": "1709.05746", "submitter": "Fangyi Zhang", "authors": "Fangyi Zhang, J\\\"urgen Leitner, Zongyuan Ge, Michael Milford, Peter\n  Corke", "title": "Adversarial Discriminative Sim-to-real Transfer of Visuo-motor Policies", "comments": "Under review for the International Journal of Robotics Research", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.AI cs.CV cs.LG cs.SY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Various approaches have been proposed to learn visuo-motor policies for\nreal-world robotic applications. One solution is first learning in simulation\nthen transferring to the real world. In the transfer, most existing approaches\nneed real-world images with labels. However, the labelling process is often\nexpensive or even impractical in many robotic applications. In this paper, we\npropose an adversarial discriminative sim-to-real transfer approach to reduce\nthe cost of labelling real data. The effectiveness of the approach is\ndemonstrated with modular networks in a table-top object reaching task where a\n7 DoF arm is controlled in velocity mode to reach a blue cuboid in clutter\nthrough visual observations. The adversarial transfer approach reduced the\nlabelled real data requirement by 50%. Policies can be transferred to real\nenvironments with only 93 labelled and 186 unlabelled real images. The\ntransferred visuo-motor policies are robust to novel (not seen in training)\nobjects in clutter and even a moving target, achieving a 97.8% success rate and\n1.8 cm control accuracy.\n", "versions": [{"version": "v1", "created": "Mon, 18 Sep 2017 02:27:02 GMT"}, {"version": "v2", "created": "Thu, 31 May 2018 09:38:25 GMT"}], "update_date": "2018-06-01", "authors_parsed": [["Zhang", "Fangyi", ""], ["Leitner", "J\u00fcrgen", ""], ["Ge", "Zongyuan", ""], ["Milford", "Michael", ""], ["Corke", "Peter", ""]]}, {"id": "1709.05750", "submitter": "NhatHai Phan", "authors": "NhatHai Phan, Xintao Wu, Han Hu, Dejing Dou", "title": "Adaptive Laplace Mechanism: Differential Privacy Preservation in Deep\n  Learning", "comments": "IEEE ICDM 2017 - regular paper", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we focus on developing a novel mechanism to preserve\ndifferential privacy in deep neural networks, such that: (1) The privacy budget\nconsumption is totally independent of the number of training steps; (2) It has\nthe ability to adaptively inject noise into features based on the contribution\nof each to the output; and (3) It could be applied in a variety of different\ndeep neural networks. To achieve this, we figure out a way to perturb affine\ntransformations of neurons, and loss functions used in deep neural networks. In\naddition, our mechanism intentionally adds \"more noise\" into features which are\n\"less relevant\" to the model output, and vice-versa. Our theoretical analysis\nfurther derives the sensitivities and error bounds of our mechanism. Rigorous\nexperiments conducted on MNIST and CIFAR-10 datasets show that our mechanism is\nhighly effective and outperforms existing solutions.\n", "versions": [{"version": "v1", "created": "Mon, 18 Sep 2017 02:37:40 GMT"}, {"version": "v2", "created": "Mon, 23 Apr 2018 02:45:14 GMT"}], "update_date": "2018-04-24", "authors_parsed": [["Phan", "NhatHai", ""], ["Wu", "Xintao", ""], ["Hu", "Han", ""], ["Dou", "Dejing", ""]]}, {"id": "1709.05778", "submitter": "Bradford Heap", "authors": "Bradford Heap, Michael Bain, Wayne Wobcke, Alfred Krzywicki and\n  Susanne Schmeidl", "title": "Word Vector Enrichment of Low Frequency Words in the Bag-of-Words Model\n  for Short Text Multi-class Classification Problems", "comments": "8 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The bag-of-words model is a standard representation of text for many linear\nclassifier learners. In many problem domains, linear classifiers are preferred\nover more complex models due to their efficiency, robustness and\ninterpretability, and the bag-of-words text representation can capture\nsufficient information for linear classifiers to make highly accurate\npredictions. However in settings where there is a large vocabulary, large\nvariance in the frequency of terms in the training corpus, many classes and\nvery short text (e.g., single sentences or document titles) the bag-of-words\nrepresentation becomes extremely sparse, and this can reduce the accuracy of\nclassifiers. A particular issue in such settings is that short texts tend to\ncontain infrequently occurring or rare terms which lack class-conditional\nevidence. In this work we introduce a method for enriching the bag-of-words\nmodel by complementing such rare term information with related terms from both\ngeneral and domain-specific Word Vector models. By reducing sparseness in the\nbag-of-words models, our enrichment approach achieves improved classification\nover several baseline classifiers in a variety of text classification problems.\nOur approach is also efficient because it requires no change to the linear\nclassifier before or during training, since bag-of-words enrichment applies\nonly to text being classified.\n", "versions": [{"version": "v1", "created": "Mon, 18 Sep 2017 05:00:34 GMT"}], "update_date": "2017-09-19", "authors_parsed": [["Heap", "Bradford", ""], ["Bain", "Michael", ""], ["Wobcke", "Wayne", ""], ["Krzywicki", "Alfred", ""], ["Schmeidl", "Susanne", ""]]}, {"id": "1709.05804", "submitter": "Bingzhen Wei", "authors": "Bingzhen Wei, Xu Sun, Xuancheng Ren, Jingjing Xu", "title": "Minimal Effort Back Propagation for Convolutional Neural Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  As traditional neural network consumes a significant amount of computing\nresources during back propagation, \\citet{Sun2017mePropSB} propose a simple yet\neffective technique to alleviate this problem. In this technique, only a small\nsubset of the full gradients are computed to update the model parameters. In\nthis paper we extend this technique into the Convolutional Neural Network(CNN)\nto reduce calculation in back propagation, and the surprising results verify\nits validity in CNN: only 5\\% of the gradients are passed back but the model\nstill achieves the same effect as the traditional CNN, or even better. We also\nshow that the top-$k$ selection of gradients leads to a sparse calculation in\nback propagation, which may bring significant computational benefits for high\ncomputational complexity of convolution operation in CNN.\n", "versions": [{"version": "v1", "created": "Mon, 18 Sep 2017 08:07:40 GMT"}], "update_date": "2017-09-27", "authors_parsed": [["Wei", "Bingzhen", ""], ["Sun", "Xu", ""], ["Ren", "Xuancheng", ""], ["Xu", "Jingjing", ""]]}, {"id": "1709.05840", "submitter": "Iraklis Klampanos", "authors": "I. A. Klampanos, A. Davvetas, S. Andronopoulos, C. Pappas, A.\n  Ikonomopoulos and V. Karkaletsis", "title": "Autoencoder-Driven Weather Clustering for Source Estimation during\n  Nuclear Events", "comments": null, "journal-ref": null, "doi": "10.1016/j.envsoft.2018.01.014", "report-no": null, "categories": "cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Emergency response applications for nuclear or radiological events can be\nsignificantly improved via deep feature learning due to the hidden complexity\nof the data and models involved. In this paper we present a novel methodology\nfor rapid source estimation during radiological releases based on deep feature\nextraction and weather clustering. Atmospheric dispersions are then calculated\nbased on identified predominant weather patterns and are matched against\nsimulated incidents indicated by radiation readings on the ground. We evaluate\nthe accuracy of our methods over multiple years of weather reanalysis data in\nthe European region. We juxtapose these results with deep classification\nconvolution networks and discuss advantages and disadvantages.\n", "versions": [{"version": "v1", "created": "Mon, 18 Sep 2017 09:55:31 GMT"}, {"version": "v2", "created": "Sat, 13 Jan 2018 12:22:56 GMT"}], "update_date": "2018-04-02", "authors_parsed": [["Klampanos", "I. A.", ""], ["Davvetas", "A.", ""], ["Andronopoulos", "S.", ""], ["Pappas", "C.", ""], ["Ikonomopoulos", "A.", ""], ["Karkaletsis", "V.", ""]]}, {"id": "1709.05849", "submitter": "Andriy Temko Dr", "authors": "Alison O'Shea, Gordon Lightbody, Geraldine Boylan, Andriy Temko", "title": "Neonatal Seizure Detection using Convolutional Neural Networks", "comments": "IEEE International Workshop on Machine Learning for Signal Processing", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This study presents a novel end-to-end architecture that learns hierarchical\nrepresentations from raw EEG data using fully convolutional deep neural\nnetworks for the task of neonatal seizure detection. The deep neural network\nacts as both feature extractor and classifier, allowing for end-to-end\noptimization of the seizure detector. The designed system is evaluated on a\nlarge dataset of continuous unedited multi-channel neonatal EEG totaling 835\nhours and comprising of 1389 seizures. The proposed deep architecture, with\nsample-level filters, achieves an accuracy that is comparable to the\nstate-of-the-art SVM-based neonatal seizure detector, which operates on a set\nof carefully designed hand-crafted features. The fully convolutional\narchitecture allows for the localization of EEG waveforms and patterns that\nresult in high seizure probabilities for further clinical examination.\n", "versions": [{"version": "v1", "created": "Mon, 18 Sep 2017 10:30:43 GMT"}], "update_date": "2017-09-19", "authors_parsed": [["O'Shea", "Alison", ""], ["Lightbody", "Gordon", ""], ["Boylan", "Geraldine", ""], ["Temko", "Andriy", ""]]}, {"id": "1709.05861", "submitter": "Narotam Singh", "authors": "Narotam Singh (1), Nittin Singh (1), Abhinav Dhall (1) ((1) Indian\n  Institute of Technology Ropar)", "title": "Continuous Multimodal Emotion Recognition Approach for AVEC 2017", "comments": "4 pages, 3 figures, arXiv:1605.06778, arXiv:1512.03385", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG cs.MM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper reports the analysis of audio and visual features in predicting\nthe continuous emotion dimensions under the seventh Audio/Visual Emotion\nChallenge (AVEC 2017), which was done as part of a B.Tech. 2nd year internship\nproject. For visual features we used the HOG (Histogram of Gradients) features,\nFisher encodings of SIFT (Scale-Invariant Feature Transform) features based on\nGaussian mixture model (GMM) and some pretrained Convolutional Neural Network\nlayers as features; all these extracted for each video clip. For audio features\nwe used the Bag-of-audio-words (BoAW) representation of the LLDs (low-level\ndescriptors) generated by openXBOW provided by the organisers of the event.\nThen we trained fully connected neural network regression model on the dataset\nfor all these different modalities. We applied multimodal fusion on the output\nmodels to get the Concordance correlation coefficient on Development set as\nwell as Test set.\n", "versions": [{"version": "v1", "created": "Mon, 18 Sep 2017 11:01:43 GMT"}, {"version": "v2", "created": "Tue, 24 Oct 2017 12:08:09 GMT"}], "update_date": "2017-10-25", "authors_parsed": [["Singh", "Narotam", ""], ["Singh", "Nittin", ""], ["Dhall", "Abhinav", ""]]}, {"id": "1709.05865", "submitter": "Shubham Dham", "authors": "Shubham Dham, Anirudh Sharma, Abhinav Dhall", "title": "Depression Scale Recognition from Audio, Visual and Text Analysis", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG cs.MM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Depression is a major mental health disorder that is rapidly affecting lives\nworldwide. Depression not only impacts emotional but also physical and\npsychological state of the person. Its symptoms include lack of interest in\ndaily activities, feeling low, anxiety, frustration, loss of weight and even\nfeeling of self-hatred. This report describes work done by us for Audio Visual\nEmotion Challenge (AVEC) 2017 during our second year BTech summer internship.\nWith the increase in demand to detect depression automatically with the help of\nmachine learning algorithms, we present our multimodal feature extraction and\ndecision level fusion approach for the same. Features are extracted by\nprocessing on the provided Distress Analysis Interview Corpus-Wizard of Oz\n(DAIC-WOZ) database. Gaussian Mixture Model (GMM) clustering and Fisher vector\napproach were applied on the visual data; statistical descriptors on gaze,\npose; low level audio features and head pose and text features were also\nextracted. Classification is done on fused as well as independent features\nusing Support Vector Machine (SVM) and neural networks. The results obtained\nwere able to cross the provided baseline on validation data set by 17% on audio\nfeatures and 24.5% on video features.\n", "versions": [{"version": "v1", "created": "Mon, 18 Sep 2017 11:26:01 GMT"}], "update_date": "2017-09-19", "authors_parsed": [["Dham", "Shubham", ""], ["Sharma", "Anirudh", ""], ["Dhall", "Abhinav", ""]]}, {"id": "1709.05870", "submitter": "Jiaxin Shi", "authors": "Jiaxin Shi, Jianfei Chen, Jun Zhu, Shengyang Sun, Yucen Luo, Yihong\n  Gu, Yuhao Zhou", "title": "ZhuSuan: A Library for Bayesian Deep Learning", "comments": "The GitHub page is at https://github.com/thu-ml/zhusuan", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.AI cs.LG cs.NE stat.CO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we introduce ZhuSuan, a python probabilistic programming\nlibrary for Bayesian deep learning, which conjoins the complimentary advantages\nof Bayesian methods and deep learning. ZhuSuan is built upon Tensorflow. Unlike\nexisting deep learning libraries, which are mainly designed for deterministic\nneural networks and supervised tasks, ZhuSuan is featured for its deep root\ninto Bayesian inference, thus supporting various kinds of probabilistic models,\nincluding both the traditional hierarchical Bayesian models and recent deep\ngenerative models. We use running examples to illustrate the probabilistic\nprogramming on ZhuSuan, including Bayesian logistic regression, variational\nauto-encoders, deep sigmoid belief networks and Bayesian recurrent neural\nnetworks.\n", "versions": [{"version": "v1", "created": "Mon, 18 Sep 2017 11:30:08 GMT"}], "update_date": "2017-09-19", "authors_parsed": [["Shi", "Jiaxin", ""], ["Chen", "Jianfei", ""], ["Zhu", "Jun", ""], ["Sun", "Shengyang", ""], ["Luo", "Yucen", ""], ["Gu", "Yihong", ""], ["Zhou", "Yuhao", ""]]}, {"id": "1709.05929", "submitter": "Ken Chang", "authors": "Ken Chang, Niranjan Balachandar, Carson K Lam, Darvin Yi, James M\n  Brown, Andrew Beers, Bruce R Rosen, Daniel L Rubin, Jayashree Kalpathy-Cramer", "title": "Institutionally Distributed Deep Learning Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG physics.med-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep learning has become a promising approach for automated medical\ndiagnoses. When medical data samples are limited, collaboration among multiple\ninstitutions is necessary to achieve high algorithm performance. However,\nsharing patient data often has limitations due to technical, legal, or ethical\nconcerns. In such cases, sharing a deep learning model is a more attractive\nalternative. The best method of performing such a task is unclear, however. In\nthis study, we simulate the dissemination of learning deep learning network\nmodels across four institutions using various heuristics and compare the\nresults with a deep learning model trained on centrally hosted patient data.\nThe heuristics investigated include ensembling single institution models,\nsingle weight transfer, and cyclical weight transfer. We evaluated these\napproaches for image classification in three independent image collections\n(retinal fundus photos, mammography, and ImageNet). We find that cyclical\nweight transfer resulted in a performance (testing accuracy = 77.3%) that was\nclosest to that of centrally hosted patient data (testing accuracy = 78.7%). We\nalso found that there is an improvement in the performance of cyclical weight\ntransfer heuristic with high frequency of weight transfer.\n", "versions": [{"version": "v1", "created": "Sun, 10 Sep 2017 15:36:17 GMT"}], "update_date": "2017-09-19", "authors_parsed": [["Chang", "Ken", ""], ["Balachandar", "Niranjan", ""], ["Lam", "Carson K", ""], ["Yi", "Darvin", ""], ["Brown", "James M", ""], ["Beers", "Andrew", ""], ["Rosen", "Bruce R", ""], ["Rubin", "Daniel L", ""], ["Kalpathy-Cramer", "Jayashree", ""]]}, {"id": "1709.05963", "submitter": "Christian Beck", "authors": "Christian Beck, Weinan E, and Arnulf Jentzen", "title": "Machine learning approximation algorithms for high-dimensional fully\n  nonlinear partial differential equations and second-order backward stochastic\n  differential equations", "comments": "56 pages, 12 figures", "journal-ref": "J. Nonlinear Sci. 29, 1563-1619 (2019)", "doi": "10.1007/s00332-018-9525-3", "report-no": null, "categories": "math.NA cs.LG cs.NE math.PR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  High-dimensional partial differential equations (PDE) appear in a number of\nmodels from the financial industry, such as in derivative pricing models,\ncredit valuation adjustment (CVA) models, or portfolio optimization models. The\nPDEs in such applications are high-dimensional as the dimension corresponds to\nthe number of financial assets in a portfolio. Moreover, such PDEs are often\nfully nonlinear due to the need to incorporate certain nonlinear phenomena in\nthe model such as default risks, transaction costs, volatility uncertainty\n(Knightian uncertainty), or trading constraints in the model. Such\nhigh-dimensional fully nonlinear PDEs are exceedingly difficult to solve as the\ncomputational effort for standard approximation methods grows exponentially\nwith the dimension. In this work we propose a new method for solving\nhigh-dimensional fully nonlinear second-order PDEs. Our method can in\nparticular be used to sample from high-dimensional nonlinear expectations. The\nmethod is based on (i) a connection between fully nonlinear second-order PDEs\nand second-order backward stochastic differential equations (2BSDEs), (ii) a\nmerged formulation of the PDE and the 2BSDE problem, (iii) a temporal forward\ndiscretization of the 2BSDE and a spatial approximation via deep neural nets,\nand (iv) a stochastic gradient descent-type optimization procedure. Numerical\nresults obtained using ${\\rm T{\\small ENSOR}F{\\small LOW}}$ in ${\\rm P{\\small\nYTHON}}$ illustrate the efficiency and the accuracy of the method in the cases\nof a $100$-dimensional Black-Scholes-Barenblatt equation, a $100$-dimensional\nHamilton-Jacobi-Bellman equation, and a nonlinear expectation of a $ 100\n$-dimensional $ G $-Brownian motion.\n", "versions": [{"version": "v1", "created": "Mon, 18 Sep 2017 14:16:06 GMT"}], "update_date": "2020-07-15", "authors_parsed": [["Beck", "Christian", ""], ["E", "Weinan", ""], ["Jentzen", "Arnulf", ""]]}, {"id": "1709.05964", "submitter": "Hajin Shim", "authors": "Hajin Shim, Sung Ju Hwang, Eunho Yang", "title": "Why Pay More When You Can Pay Less: A Joint Learning Framework for\n  Active Feature Acquisition and Classification", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the problem of active feature acquisition, where we sequentially\nselect the subset of features in order to achieve the maximum prediction\nperformance in the most cost-effective way. In this work, we formulate this\nactive feature acquisition problem as a reinforcement learning problem, and\nprovide a novel framework for jointly learning both the RL agent and the\nclassifier (environment). We also introduce a more systematic way of encoding\nsubsets of features that can properly handle innate challenge with missing\nentries in active feature acquisition problems, that uses the orderless\nLSTM-based set encoding mechanism that readily fits in the joint learning\nframework. We evaluate our model on a carefully designed synthetic dataset for\nthe active feature acquisition as well as several real datasets such as\nelectric health record (EHR) datasets, on which it outperforms all baselines in\nterms of prediction performance as well feature acquisition cost.\n", "versions": [{"version": "v1", "created": "Mon, 18 Sep 2017 14:17:22 GMT"}], "update_date": "2017-09-19", "authors_parsed": [["Shim", "Hajin", ""], ["Hwang", "Sung Ju", ""], ["Yang", "Eunho", ""]]}, {"id": "1709.05976", "submitter": "Vivek Gupta", "authors": "Rahul Wadbude, Vivek Gupta, Piyush Rai, Nagarajan Natarajan, Harish\n  Karnick, Prateek Jain", "title": "Leveraging Distributional Semantics for Multi-Label Learning", "comments": "10 Pages, 0 Figures, Missing Result Joint Learning Included", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a novel and scalable label embedding framework for large-scale\nmulti-label learning a.k.a ExMLDS (Extreme Multi-Label Learning using\nDistributional Semantics). Our approach draws inspiration from ideas rooted in\ndistributional semantics, specifically the Skip Gram Negative Sampling (SGNS)\napproach, widely used to learn word embeddings for natural language processing\ntasks. Learning such embeddings can be reduced to a certain matrix\nfactorization. Our approach is novel in that it highlights interesting\nconnections between label embedding methods used for multi-label learning and\nparagraph/document embedding methods commonly used for learning representations\nof text data. The framework can also be easily extended to incorporate\nauxiliary information such as label-label correlations; this is crucial\nespecially when there are a lot of missing labels in the training data. We\ndemonstrate the effectiveness of our approach through an extensive set of\nexperiments on a variety of benchmark datasets, and show that the proposed\nlearning methods perform favorably compared to several baselines and\nstate-of-the-art methods for large-scale multi-label learning. To facilitate\nend-to-end learning, we develop a joint learning algorithm that can learn the\nembeddings as well as a regression model that predicts these embeddings given\ninput features, via efficient gradient-based methods.\n", "versions": [{"version": "v1", "created": "Mon, 18 Sep 2017 14:34:16 GMT"}, {"version": "v2", "created": "Thu, 9 Nov 2017 10:48:18 GMT"}, {"version": "v3", "created": "Fri, 10 Nov 2017 08:04:21 GMT"}], "update_date": "2017-11-13", "authors_parsed": [["Wadbude", "Rahul", ""], ["Gupta", "Vivek", ""], ["Rai", "Piyush", ""], ["Natarajan", "Nagarajan", ""], ["Karnick", "Harish", ""], ["Jain", "Prateek", ""]]}, {"id": "1709.06009", "submitter": "Marlos C. Machado", "authors": "Marlos C. Machado, Marc G. Bellemare, Erik Talvitie, Joel Veness,\n  Matthew Hausknecht, Michael Bowling", "title": "Revisiting the Arcade Learning Environment: Evaluation Protocols and\n  Open Problems for General Agents", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The Arcade Learning Environment (ALE) is an evaluation platform that poses\nthe challenge of building AI agents with general competency across dozens of\nAtari 2600 games. It supports a variety of different problem settings and it\nhas been receiving increasing attention from the scientific community, leading\nto some high-profile success stories such as the much publicized Deep\nQ-Networks (DQN). In this article we take a big picture look at how the ALE is\nbeing used by the research community. We show how diverse the evaluation\nmethodologies in the ALE have become with time, and highlight some key concerns\nwhen evaluating agents in the ALE. We use this discussion to present some\nmethodological best practices and provide new benchmark results using these\nbest practices. To further the progress in the field, we introduce a new\nversion of the ALE that supports multiple game modes and provides a form of\nstochasticity we call sticky actions. We conclude this big picture look by\nrevisiting challenges posed when the ALE was introduced, summarizing the\nstate-of-the-art in various problems and highlighting problems that remain\nopen.\n", "versions": [{"version": "v1", "created": "Mon, 18 Sep 2017 15:32:57 GMT"}, {"version": "v2", "created": "Fri, 1 Dec 2017 03:18:14 GMT"}], "update_date": "2017-12-04", "authors_parsed": [["Machado", "Marlos C.", ""], ["Bellemare", "Marc G.", ""], ["Talvitie", "Erik", ""], ["Veness", "Joel", ""], ["Hausknecht", "Matthew", ""], ["Bowling", "Michael", ""]]}, {"id": "1709.06010", "submitter": "Surbhi Goel", "authors": "Surbhi Goel and Adam Klivans", "title": "Learning Neural Networks with Two Nonlinear Layers in Polynomial Time", "comments": "Changed title, included new results", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We give a polynomial-time algorithm for learning neural networks with one\nlayer of sigmoids feeding into any Lipschitz, monotone activation function\n(e.g., sigmoid or ReLU). We make no assumptions on the structure of the\nnetwork, and the algorithm succeeds with respect to {\\em any} distribution on\nthe unit ball in $n$ dimensions (hidden weight vectors also have unit norm).\nThis is the first assumption-free, provably efficient algorithm for learning\nneural networks with two nonlinear layers.\n  Our algorithm-- {\\em Alphatron}-- is a simple, iterative update rule that\ncombines isotonic regression with kernel methods. It outputs a hypothesis that\nyields efficient oracle access to interpretable features. It also suggests a\nnew approach to Boolean learning problems via real-valued conditional-mean\nfunctions, sidestepping traditional hardness results from computational\nlearning theory.\n  Along these lines, we subsume and improve many longstanding results for PAC\nlearning Boolean functions to the more general, real-valued setting of {\\em\nprobabilistic concepts}, a model that (unlike PAC learning) requires non-i.i.d.\nnoise-tolerance.\n", "versions": [{"version": "v1", "created": "Mon, 18 Sep 2017 15:36:06 GMT"}, {"version": "v2", "created": "Mon, 23 Oct 2017 17:29:51 GMT"}, {"version": "v3", "created": "Tue, 24 Oct 2017 17:14:38 GMT"}, {"version": "v4", "created": "Fri, 20 Apr 2018 20:16:02 GMT"}], "update_date": "2018-04-24", "authors_parsed": [["Goel", "Surbhi", ""], ["Klivans", "Adam", ""]]}, {"id": "1709.06011", "submitter": "Maximilian Huettenrauch", "authors": "Maximilian H\\\"uttenrauch and Adrian \\v{S}o\\v{s}i\\'c and Gerhard\n  Neumann", "title": "Guided Deep Reinforcement Learning for Swarm Systems", "comments": "15 pages, 8 figures, accepted at the AAMAS 2017 Autonomous Robots and\n  Multirobot Systems (ARMS) Workshop", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.MA cs.AI cs.LG cs.SY stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we investigate how to learn to control a group of cooperative\nagents with limited sensing capabilities such as robot swarms. The agents have\nonly very basic sensor capabilities, yet in a group they can accomplish\nsophisticated tasks, such as distributed assembly or search and rescue tasks.\nLearning a policy for a group of agents is difficult due to distributed partial\nobservability of the state. Here, we follow a guided approach where a critic\nhas central access to the global state during learning, which simplifies the\npolicy evaluation problem from a reinforcement learning point of view. For\nexample, we can get the positions of all robots of the swarm using a camera\nimage of a scene. This camera image is only available to the critic and not to\nthe control policies of the robots. We follow an actor-critic approach, where\nthe actors base their decisions only on locally sensed information. In\ncontrast, the critic is learned based on the true global state. Our algorithm\nuses deep reinforcement learning to approximate both the Q-function and the\npolicy. The performance of the algorithm is evaluated on two tasks with simple\nsimulated 2D agents: 1) finding and maintaining a certain distance to each\nothers and 2) locating a target.\n", "versions": [{"version": "v1", "created": "Mon, 18 Sep 2017 15:37:45 GMT"}], "update_date": "2017-09-19", "authors_parsed": [["H\u00fcttenrauch", "Maximilian", ""], ["\u0160o\u0161i\u0107", "Adrian", ""], ["Neumann", "Gerhard", ""]]}, {"id": "1709.06030", "submitter": "Bhav Ashok", "authors": "Anubhav Ashok, Nicholas Rhinehart, Fares Beainy, Kris M. Kitani", "title": "N2N Learning: Network to Network Compression via Policy Gradient\n  Reinforcement Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  While bigger and deeper neural network architectures continue to advance the\nstate-of-the-art for many computer vision tasks, real-world adoption of these\nnetworks is impeded by hardware and speed constraints. Conventional model\ncompression methods attempt to address this problem by modifying the\narchitecture manually or using pre-defined heuristics. Since the space of all\nreduced architectures is very large, modifying the architecture of a deep\nneural network in this way is a difficult task. In this paper, we tackle this\nissue by introducing a principled method for learning reduced network\narchitectures in a data-driven way using reinforcement learning. Our approach\ntakes a larger `teacher' network as input and outputs a compressed `student'\nnetwork derived from the `teacher' network. In the first stage of our method, a\nrecurrent policy network aggressively removes layers from the large `teacher'\nmodel. In the second stage, another recurrent policy network carefully reduces\nthe size of each remaining layer. The resulting network is then evaluated to\nobtain a reward -- a score based on the accuracy and compression of the\nnetwork. Our approach uses this reward signal with policy gradients to train\nthe policies to find a locally optimal student network. Our experiments show\nthat we can achieve compression rates of more than 10x for models such as\nResNet-34 while maintaining similar performance to the input `teacher' network.\nWe also present a valuable transfer learning result which shows that policies\nwhich are pre-trained on smaller `teacher' networks can be used to rapidly\nspeed up training on larger `teacher' networks.\n", "versions": [{"version": "v1", "created": "Mon, 18 Sep 2017 16:26:53 GMT"}, {"version": "v2", "created": "Sun, 17 Dec 2017 11:46:06 GMT"}], "update_date": "2017-12-19", "authors_parsed": [["Ashok", "Anubhav", ""], ["Rhinehart", "Nicholas", ""], ["Beainy", "Fares", ""], ["Kitani", "Kris M.", ""]]}, {"id": "1709.06075", "submitter": "John Boaz Lee", "authors": "John Boaz Lee, Ryan Rossi, Xiangnan Kong", "title": "Deep Graph Attention Model", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Graph classification is a problem with practical applications in many\ndifferent domains. Most of the existing methods take the entire graph into\naccount when calculating graph features. In a graphlet-based approach, for\ninstance, the entire graph is processed to get the total count of different\ngraphlets or sub-graphs. In the real-world, however, graphs can be both large\nand noisy with discriminative patterns confined to certain regions in the graph\nonly. In this work, we study the problem of attentional processing for graph\nclassification. The use of attention allows us to focus on small but\ninformative parts of the graph, avoiding noise in the rest of the graph. We\npresent a novel RNN model, called the Graph Attention Model (GAM), that\nprocesses only a portion of the graph by adaptively selecting a sequence of\n\"interesting\" nodes. The model is equipped with an external memory component\nwhich allows it to integrate information gathered from different parts of the\ngraph. We demonstrate the effectiveness of the model through various\nexperiments.\n", "versions": [{"version": "v1", "created": "Fri, 15 Sep 2017 19:02:50 GMT"}], "update_date": "2017-09-20", "authors_parsed": [["Lee", "John Boaz", ""], ["Rossi", "Ryan", ""], ["Kong", "Xiangnan", ""]]}, {"id": "1709.06076", "submitter": "Hermes Senger", "authors": "Lucas Venezian Povoa and Cesar Marcondes and Hermes Senger", "title": "Modelling Energy Consumption based on Resource Utilization", "comments": "Submitted to Journal of Supercomputing on 14th June, 2017", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Power management is an expensive and important issue for large computational\ninfrastructures such as datacenters, large clusters, and computational grids.\nHowever, measuring energy consumption of scalable systems may be impractical\ndue to both cost and complexity for deploying power metering devices on a large\nnumber of machines. In this paper, we propose the use of information about\nresource utilization (e.g. processor, memory, disk operations, and network\ntraffic) as proxies for estimating power consumption. We employ machine\nlearning techniques to estimate power consumption using such information which\nare provided by common operating systems. Experiments with linear regression,\nregression tree, and multilayer perceptron on data from different hardware\nresulted into a model with 99.94\\% of accuracy and 6.32 watts of error in the\nbest case.\n", "versions": [{"version": "v1", "created": "Fri, 15 Sep 2017 19:17:02 GMT"}], "update_date": "2017-09-20", "authors_parsed": [["Povoa", "Lucas Venezian", ""], ["Marcondes", "Cesar", ""], ["Senger", "Hermes", ""]]}, {"id": "1709.06079", "submitter": "Lei Huang", "authors": "Lei Huang, Xianglong Liu, Bo Lang, Adams Wei Yu, Yongliang Wang, Bo Li", "title": "Orthogonal Weight Normalization: Solution to Optimization over Multiple\n  Dependent Stiefel Manifolds in Deep Neural Networks", "comments": "20 pages, Accepted by AAAI 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Orthogonal matrix has shown advantages in training Recurrent Neural Networks\n(RNNs), but such matrix is limited to be square for the hidden-to-hidden\ntransformation in RNNs. In this paper, we generalize such square orthogonal\nmatrix to orthogonal rectangular matrix and formulating this problem in\nfeed-forward Neural Networks (FNNs) as Optimization over Multiple Dependent\nStiefel Manifolds (OMDSM). We show that the rectangular orthogonal matrix can\nstabilize the distribution of network activations and regularize FNNs. We also\npropose a novel orthogonal weight normalization method to solve OMDSM.\nParticularly, it constructs orthogonal transformation over proxy parameters to\nensure the weight matrix is orthogonal and back-propagates gradient information\nthrough the transformation during training. To guarantee stability, we minimize\nthe distortions between proxy parameters and canonical weights over all\ntractable orthogonal transformations. In addition, we design an orthogonal\nlinear module (OLM) to learn orthogonal filter banks in practice, which can be\nused as an alternative to standard linear module. Extensive experiments\ndemonstrate that by simply substituting OLM for standard linear module without\nrevising any experimental protocols, our method largely improves the\nperformance of the state-of-the-art networks, including Inception and residual\nnetworks on CIFAR and ImageNet datasets. In particular, we have reduced the\ntest error of wide residual network on CIFAR-100 from 20.04% to 18.61% with\nsuch simple substitution. Our code is available online for result reproduction.\n", "versions": [{"version": "v1", "created": "Sat, 16 Sep 2017 09:56:55 GMT"}, {"version": "v2", "created": "Tue, 21 Nov 2017 16:39:59 GMT"}], "update_date": "2017-11-22", "authors_parsed": [["Huang", "Lei", ""], ["Liu", "Xianglong", ""], ["Lang", "Bo", ""], ["Yu", "Adams Wei", ""], ["Wang", "Yongliang", ""], ["Li", "Bo", ""]]}, {"id": "1709.06080", "submitter": "Maxim Naumov", "authors": "Maxim Naumov", "title": "Feedforward and Recurrent Neural Networks Backward Propagation and\n  Hessian in Matrix Form", "comments": "23 pages, 4 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI math.NA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we focus on the linear algebra theory behind feedforward (FNN)\nand recurrent (RNN) neural networks. We review backward propagation, including\nbackward propagation through time (BPTT). Also, we obtain a new exact\nexpression for Hessian, which represents second order effects. We show that for\n$t$ time steps the weight gradient can be expressed as a rank-$t$ matrix, while\nthe weight Hessian is as a sum of $t^{2}$ Kronecker products of rank-$1$ and\n$W^{T}AW$ matrices, for some matrix $A$ and weight matrix $W$. Also, we show\nthat for a mini-batch of size $r$, the weight update can be expressed as a\nrank-$rt$ matrix. Finally, we briefly comment on the eigenvalues of the Hessian\nmatrix.\n", "versions": [{"version": "v1", "created": "Sat, 16 Sep 2017 18:59:17 GMT"}], "update_date": "2017-09-20", "authors_parsed": [["Naumov", "Maxim", ""]]}, {"id": "1709.06109", "submitter": "Yining Wang", "authors": "Xi Chen, Yining Wang", "title": "A Note on a Tight Lower Bound for MNL-Bandit Assortment Selection Models", "comments": "Final version, 4 pages (double column)", "journal-ref": "Operations Research Letters 46(5):534-537, 2018", "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this short note we consider a dynamic assortment planning problem under\nthe capacitated multinomial logit (MNL) bandit model. We prove a tight lower\nbound on the accumulated regret that matches existing regret upper bounds for\nall parameters (time horizon $T$, number of items $N$ and maximum assortment\ncapacity $K$) up to logarithmic factors. Our results close an $O(\\sqrt{K})$ gap\nbetween upper and lower regret bounds from existing works.\n", "versions": [{"version": "v1", "created": "Mon, 18 Sep 2017 18:12:10 GMT"}, {"version": "v2", "created": "Thu, 9 Nov 2017 19:30:54 GMT"}, {"version": "v3", "created": "Fri, 28 Sep 2018 17:29:56 GMT"}], "update_date": "2018-10-01", "authors_parsed": [["Chen", "Xi", ""], ["Wang", "Yining", ""]]}, {"id": "1709.06123", "submitter": "Qinliang Su", "authors": "Qinliang Su, Xuejun Liao, Lawrence Carin", "title": "A Probabilistic Framework for Nonlinearities in Stochastic Neural\n  Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a probabilistic framework for nonlinearities, based on doubly\ntruncated Gaussian distributions. By setting the truncation points\nappropriately, we are able to generate various types of nonlinearities within a\nunified framework, including sigmoid, tanh and ReLU, the most commonly used\nnonlinearities in neural networks. The framework readily integrates into\nexisting stochastic neural networks (with hidden units characterized as random\nvariables), allowing one for the first time to learn the nonlinearities\nalongside model weights in these networks. Extensive experiments demonstrate\nthe performance improvements brought about by the proposed framework when\nintegrated with the restricted Boltzmann machine (RBM), temporal RBM and the\ntruncated Gaussian graphical model (TGGM).\n", "versions": [{"version": "v1", "created": "Mon, 18 Sep 2017 19:01:53 GMT"}], "update_date": "2017-09-20", "authors_parsed": [["Su", "Qinliang", ""], ["Liao", "Xuejun", ""], ["Carin", "Lawrence", ""]]}, {"id": "1709.06129", "submitter": "Simon Du", "authors": "Simon S. Du, Jason D. Lee, Yuandong Tian", "title": "When is a Convolutional Filter Easy To Learn?", "comments": "Published as a conference paper at ICLR 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CV math.OC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We analyze the convergence of (stochastic) gradient descent algorithm for\nlearning a convolutional filter with Rectified Linear Unit (ReLU) activation\nfunction. Our analysis does not rely on any specific form of the input\ndistribution and our proofs only use the definition of ReLU, in contrast with\nprevious works that are restricted to standard Gaussian input. We show that\n(stochastic) gradient descent with random initialization can learn the\nconvolutional filter in polynomial time and the convergence rate depends on the\nsmoothness of the input distribution and the closeness of patches. To the best\nof our knowledge, this is the first recovery guarantee of gradient-based\nalgorithms for convolutional filter on non-Gaussian input distributions. Our\ntheory also justifies the two-stage learning rate strategy in deep neural\nnetworks. While our focus is theoretical, we also present experiments that\nillustrate our theoretical findings.\n", "versions": [{"version": "v1", "created": "Mon, 18 Sep 2017 19:09:24 GMT"}, {"version": "v2", "created": "Wed, 28 Feb 2018 17:08:26 GMT"}], "update_date": "2018-03-01", "authors_parsed": [["Du", "Simon S.", ""], ["Lee", "Jason D.", ""], ["Tian", "Yuandong", ""]]}, {"id": "1709.06138", "submitter": "Rajat Sen", "authors": "Rajat Sen, Ananda Theertha Suresh, Karthikeyan Shanmugam, Alexandros\n  G. Dimakis and Sanjay Shakkottai", "title": "Model-Powered Conditional Independence Test", "comments": "19 Pages, 2 figures, Accepted for publication in NIPS 2017", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.AI cs.IT cs.LG math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the problem of non-parametric Conditional Independence testing\n(CI testing) for continuous random variables. Given i.i.d samples from the\njoint distribution $f(x,y,z)$ of continuous random vectors $X,Y$ and $Z,$ we\ndetermine whether $X \\perp Y | Z$. We approach this by converting the\nconditional independence test into a classification problem. This allows us to\nharness very powerful classifiers like gradient-boosted trees and deep neural\nnetworks. These models can handle complex probability distributions and allow\nus to perform significantly better compared to the prior state of the art, for\nhigh-dimensional CI testing. The main technical challenge in the classification\nproblem is the need for samples from the conditional product distribution\n$f^{CI}(x,y,z) = f(x|z)f(y|z)f(z)$ -- the joint distribution if and only if $X\n\\perp Y | Z.$ -- when given access only to i.i.d. samples from the true joint\ndistribution $f(x,y,z)$. To tackle this problem we propose a novel nearest\nneighbor bootstrap procedure and theoretically show that our generated samples\nare indeed close to $f^{CI}$ in terms of total variational distance. We then\ndevelop theoretical results regarding the generalization bounds for\nclassification for our problem, which translate into error bounds for CI\ntesting. We provide a novel analysis of Rademacher type classification bounds\nin the presence of non-i.i.d near-independent samples. We empirically validate\nthe performance of our algorithm on simulated and real datasets and show\nperformance gains over previous methods.\n", "versions": [{"version": "v1", "created": "Mon, 18 Sep 2017 19:56:07 GMT"}], "update_date": "2017-09-20", "authors_parsed": [["Sen", "Rajat", ""], ["Suresh", "Ananda Theertha", ""], ["Shanmugam", "Karthikeyan", ""], ["Dimakis", "Alexandros G.", ""], ["Shakkottai", "Sanjay", ""]]}, {"id": "1709.06161", "submitter": "Meng Li", "authors": "Meng Li, Liangzhen Lai, Naveen Suda, Vikas Chandra and David Z. Pan", "title": "PrivyNet: A Flexible Framework for Privacy-Preserving Deep Neural\n  Network Training", "comments": "20 pages, 25 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Massive data exist among user local platforms that usually cannot support\ndeep neural network (DNN) training due to computation and storage resource\nconstraints. Cloud-based training schemes provide beneficial services but\nsuffer from potential privacy risks due to excessive user data collection. To\nenable cloud-based DNN training while protecting the data privacy\nsimultaneously, we propose to leverage the intermediate representations of the\ndata, which is achieved by splitting the DNNs and deploying them separately\nonto local platforms and the cloud. The local neural network (NN) is used to\ngenerate the feature representations. To avoid local training and protect data\nprivacy, the local NN is derived from pre-trained NNs. The cloud NN is then\ntrained based on the extracted intermediate representations for the target\nlearning task. We validate the idea of DNN splitting by characterizing the\ndependency of privacy loss and classification accuracy on the local NN topology\nfor a convolutional NN (CNN) based image classification task. Based on the\ncharacterization, we further propose PrivyNet to determine the local NN\ntopology, which optimizes the accuracy of the target learning task under the\nconstraints on privacy loss, local computation, and storage. The efficiency and\neffectiveness of PrivyNet are demonstrated with the CIFAR-10 dataset.\n", "versions": [{"version": "v1", "created": "Mon, 18 Sep 2017 20:38:29 GMT"}, {"version": "v2", "created": "Thu, 26 Oct 2017 21:03:07 GMT"}, {"version": "v3", "created": "Fri, 12 Jan 2018 01:13:59 GMT"}], "update_date": "2018-01-15", "authors_parsed": [["Li", "Meng", ""], ["Lai", "Liangzhen", ""], ["Suda", "Naveen", ""], ["Chandra", "Vikas", ""], ["Pan", "David Z.", ""]]}, {"id": "1709.06182", "submitter": "Miltiadis Allamanis", "authors": "Miltiadis Allamanis, Earl T. Barr, Premkumar Devanbu, Charles Sutton", "title": "A Survey of Machine Learning for Big Code and Naturalness", "comments": "Website accompanying this survey paper can be found at\n  https://ml4code.github.io", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SE cs.LG cs.PL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Research at the intersection of machine learning, programming languages, and\nsoftware engineering has recently taken important steps in proposing learnable\nprobabilistic models of source code that exploit code's abundance of patterns.\nIn this article, we survey this work. We contrast programming languages against\nnatural languages and discuss how these similarities and differences drive the\ndesign of probabilistic models. We present a taxonomy based on the underlying\ndesign principles of each model and use it to navigate the literature. Then, we\nreview how researchers have adapted these models to application areas and\ndiscuss cross-cutting and application-specific challenges and opportunities.\n", "versions": [{"version": "v1", "created": "Mon, 18 Sep 2017 22:03:51 GMT"}, {"version": "v2", "created": "Sat, 5 May 2018 02:38:45 GMT"}], "update_date": "2018-05-08", "authors_parsed": [["Allamanis", "Miltiadis", ""], ["Barr", "Earl T.", ""], ["Devanbu", "Premkumar", ""], ["Sutton", "Charles", ""]]}, {"id": "1709.06183", "submitter": "Jiantao Jiao", "authors": "Jiantao Jiao and Yanjun Han", "title": "Bias Correction with Jackknife, Bootstrap, and Taylor Series", "comments": "to appear in IEEE Transactions on Information Theory", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST cs.IT cs.LG math.IT stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We analyze bias correction methods using jackknife, bootstrap, and Taylor\nseries. We focus on the binomial model, and consider the problem of bias\ncorrection for estimating $f(p)$, where $f \\in C[0,1]$ is arbitrary. We\ncharacterize the supremum norm of the bias of general jackknife and bootstrap\nestimators for any continuous functions, and demonstrate the in delete-$d$\njackknife, different values of $d$ may lead to drastically different behaviors\nin jackknife. We show that in the binomial model, iterating the bootstrap bias\ncorrection infinitely many times may lead to divergence of bias and variance,\nand demonstrate that the bias properties of the bootstrap bias corrected\nestimator after $r-1$ rounds are of the same order as that of the $r$-jackknife\nestimator if a bounded coefficients condition is satisfied.\n", "versions": [{"version": "v1", "created": "Mon, 18 Sep 2017 22:04:10 GMT"}, {"version": "v2", "created": "Wed, 5 Sep 2018 18:38:39 GMT"}, {"version": "v3", "created": "Tue, 14 Jan 2020 19:59:28 GMT"}, {"version": "v4", "created": "Tue, 16 Jun 2020 00:32:07 GMT"}], "update_date": "2020-06-17", "authors_parsed": [["Jiao", "Jiantao", ""], ["Han", "Yanjun", ""]]}, {"id": "1709.06201", "submitter": "Jaedeok Kim", "authors": "Jaedeok Kim, and Jingoo Seo", "title": "Human Understandable Explanation Extraction for Black-box Classification\n  Models Based on Matrix Factorization", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In recent years, a number of artificial intelligent services have been\ndeveloped such as defect detection system or diagnosis system for customer\nservices. Unfortunately, the core in these services is a black-box in which\nhuman cannot understand the underlying decision making logic, even though the\ninspection of the logic is crucial before launching a commercial service. Our\ngoal in this paper is to propose an analytic method of a model explanation that\nis applicable to general classification models. To this end, we introduce the\nconcept of a contribution matrix and an explanation embedding in a constraint\nspace by using a matrix factorization. We extract a rule-like model explanation\nfrom the contribution matrix with the help of the nonnegative matrix\nfactorization. To validate our method, the experiment results provide with open\ndatasets as well as an industry dataset of a LTE network diagnosis and the\nresults show our method extracts reasonable explanations.\n", "versions": [{"version": "v1", "created": "Mon, 18 Sep 2017 23:44:45 GMT"}], "update_date": "2017-09-20", "authors_parsed": [["Kim", "Jaedeok", ""], ["Seo", "Jingoo", ""]]}, {"id": "1709.06212", "submitter": "Weihao Gao", "authors": "Weihao Gao, Sreeram Kannan, Sewoong Oh, Pramod Viswanath", "title": "Estimating Mutual Information for Discrete-Continuous Mixtures", "comments": "25 pages, 3 figures. Part of this paper appears in the Conference on\n  Neural Information Processing Systems (NIPS), 2017", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IT cs.LG math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Estimating mutual information from observed samples is a basic primitive,\nuseful in several machine learning tasks including correlation mining,\ninformation bottleneck clustering, learning a Chow-Liu tree, and conditional\nindependence testing in (causal) graphical models. While mutual information is\na well-defined quantity in general probability spaces, existing estimators can\nonly handle two special cases of purely discrete or purely continuous pairs of\nrandom variables. The main challenge is that these methods first estimate the\n(differential) entropies of X, Y and the pair (X;Y) and add them up with\nappropriate signs to get an estimate of the mutual information. These\n3H-estimators cannot be applied in general mixture spaces, where entropy is not\nwell-defined. In this paper, we design a novel estimator for mutual information\nof discrete-continuous mixtures. We prove that the proposed estimator is\nconsistent. We provide numerical experiments suggesting superiority of the\nproposed estimator compared to other heuristics of adding small continuous\nnoise to all the samples and applying standard estimators tailored for purely\ncontinuous variables, and quantizing the samples and applying standard\nestimators tailored for purely discrete variables. This significantly widens\nthe applicability of mutual information estimation in real-world applications,\nwhere some variables are discrete, some continuous, and others are a mixture\nbetween continuous and discrete components.\n", "versions": [{"version": "v1", "created": "Tue, 19 Sep 2017 00:52:15 GMT"}, {"version": "v2", "created": "Wed, 7 Feb 2018 23:15:34 GMT"}, {"version": "v3", "created": "Tue, 9 Oct 2018 18:31:40 GMT"}], "update_date": "2018-10-11", "authors_parsed": [["Gao", "Weihao", ""], ["Kannan", "Sreeram", ""], ["Oh", "Sewoong", ""], ["Viswanath", "Pramod", ""]]}, {"id": "1709.06293", "submitter": "Kyungjae Lee", "authors": "Kyungjae Lee, Sungjoon Choi and Songhwai Oh", "title": "Sparse Markov Decision Processes with Causal Sparse Tsallis Entropy\n  Regularization for Reinforcement Learning", "comments": "15 pages, 9 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, a sparse Markov decision process (MDP) with novel causal\nsparse Tsallis entropy regularization is proposed.The proposed policy\nregularization induces a sparse and multi-modal optimal policy distribution of\na sparse MDP. The full mathematical analysis of the proposed sparse MDP is\nprovided.We first analyze the optimality condition of a sparse MDP. Then, we\npropose a sparse value iteration method which solves a sparse MDP and then\nprove the convergence and optimality of sparse value iteration using the Banach\nfixed point theorem. The proposed sparse MDP is compared to soft MDPs which\nutilize causal entropy regularization. We show that the performance error of a\nsparse MDP has a constant bound, while the error of a soft MDP increases\nlogarithmically with respect to the number of actions, where this performance\nerror is caused by the introduced regularization term. In experiments, we apply\nsparse MDPs to reinforcement learning problems. The proposed method outperforms\nexisting methods in terms of the convergence speed and performance.\n", "versions": [{"version": "v1", "created": "Tue, 19 Sep 2017 08:36:21 GMT"}, {"version": "v2", "created": "Thu, 21 Sep 2017 10:57:25 GMT"}, {"version": "v3", "created": "Fri, 13 Oct 2017 06:22:59 GMT"}], "update_date": "2017-10-16", "authors_parsed": [["Lee", "Kyungjae", ""], ["Choi", "Sungjoon", ""], ["Oh", "Songhwai", ""]]}, {"id": "1709.06298", "submitter": "Hao-Wen Dong", "authors": "Hao-Wen Dong, Wen-Yi Hsiao, Li-Chia Yang, Yi-Hsuan Yang", "title": "MuseGAN: Multi-track Sequential Generative Adversarial Networks for\n  Symbolic Music Generation and Accompaniment", "comments": "to appear at AAAI 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.AS cs.AI cs.LG cs.SD stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Generating music has a few notable differences from generating images and\nvideos. First, music is an art of time, necessitating a temporal model. Second,\nmusic is usually composed of multiple instruments/tracks with their own\ntemporal dynamics, but collectively they unfold over time interdependently.\nLastly, musical notes are often grouped into chords, arpeggios or melodies in\npolyphonic music, and thereby introducing a chronological ordering of notes is\nnot naturally suitable. In this paper, we propose three models for symbolic\nmulti-track music generation under the framework of generative adversarial\nnetworks (GANs). The three models, which differ in the underlying assumptions\nand accordingly the network architectures, are referred to as the jamming\nmodel, the composer model and the hybrid model. We trained the proposed models\non a dataset of over one hundred thousand bars of rock music and applied them\nto generate piano-rolls of five tracks: bass, drums, guitar, piano and strings.\nA few intra-track and inter-track objective metrics are also proposed to\nevaluate the generative results, in addition to a subjective user study. We\nshow that our models can generate coherent music of four bars right from\nscratch (i.e. without human inputs). We also extend our models to human-AI\ncooperative music generation: given a specific track composed by human, we can\ngenerate four additional tracks to accompany it. All code, the dataset and the\nrendered audio samples are available at https://salu133445.github.io/musegan/ .\n", "versions": [{"version": "v1", "created": "Tue, 19 Sep 2017 08:49:40 GMT"}, {"version": "v2", "created": "Fri, 24 Nov 2017 05:11:39 GMT"}], "update_date": "2020-08-06", "authors_parsed": [["Dong", "Hao-Wen", ""], ["Hsiao", "Wen-Yi", ""], ["Yang", "Li-Chia", ""], ["Yang", "Yi-Hsuan", ""]]}, {"id": "1709.06304", "submitter": "Ruohui Wang", "authors": "Ruohui Wang, Dahua Lin", "title": "Scalable Estimation of Dirichlet Process Mixture Models on Distributed\n  Data", "comments": "This paper is published on IJCAI 2017.\n  https://www.ijcai.org/proceedings/2017/646", "journal-ref": null, "doi": "10.24963/ijcai.2017/646", "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the estimation of Dirichlet Process Mixture Models (DPMMs) in\ndistributed environments, where data are distributed across multiple computing\nnodes. A key advantage of Bayesian nonparametric models such as DPMMs is that\nthey allow new components to be introduced on the fly as needed. This, however,\nposts an important challenge to distributed estimation -- how to handle new\ncomponents efficiently and consistently. To tackle this problem, we propose a\nnew estimation method, which allows new components to be created locally in\nindividual computing nodes. Components corresponding to the same cluster will\nbe identified and merged via a probabilistic consolidation scheme. In this way,\nwe can maintain the consistency of estimation with very low communication cost.\nExperiments on large real-world data sets show that the proposed method can\nachieve high scalability in distributed and asynchronous environments without\ncompromising the mixing performance.\n", "versions": [{"version": "v1", "created": "Tue, 19 Sep 2017 09:05:14 GMT"}], "update_date": "2017-09-20", "authors_parsed": [["Wang", "Ruohui", ""], ["Lin", "Dahua", ""]]}, {"id": "1709.06390", "submitter": "Minh Trung Le", "authors": "Trung Le, Khanh Nguyen, Tu Dinh Nguyen, Dinh Phung", "title": "Analogical-based Bayesian Optimization", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Some real-world problems revolve to solve the optimization problem\n\\max_{x\\in\\mathcal{X}}f\\left(x\\right) where f\\left(.\\right) is a black-box\nfunction and X might be the set of non-vectorial objects (e.g., distributions)\nwhere we can only define a symmetric and non-negative similarity score on it.\nThis setting requires a novel view for the standard framework of Bayesian\nOptimization that generalizes the core insightful spirit of this framework.\nWith this spirit, in this paper, we propose Analogical-based Bayesian\nOptimization that can maximize black-box function over a domain where only a\nsimilarity score can be defined. Our pathway is as follows: we first base on\nthe geometric view of Gaussian Processes (GP) to define the concept of\ninfluence level that allows us to analytically represent predictive means and\nvariances of GP posteriors and base on that view to enable replacing kernel\nsimilarity by a more genetic similarity score. Furthermore, we also propose two\nstrategies to find a batch of query points that can efficiently handle high\ndimensional data.\n", "versions": [{"version": "v1", "created": "Tue, 19 Sep 2017 13:06:39 GMT"}], "update_date": "2017-09-20", "authors_parsed": [["Le", "Trung", ""], ["Nguyen", "Khanh", ""], ["Nguyen", "Tu Dinh", ""], ["Phung", "Dinh", ""]]}, {"id": "1709.06404", "submitter": "Ga\\\"etan Hadjeres", "authors": "Ga\\\"etan Hadjeres and Frank Nielsen", "title": "Interactive Music Generation with Positional Constraints using\n  Anticipation-RNNs", "comments": "9 pages, 7 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recurrent Neural Networks (RNNS) are now widely used on sequence generation\ntasks due to their ability to learn long-range dependencies and to generate\nsequences of arbitrary length. However, their left-to-right generation\nprocedure only allows a limited control from a potential user which makes them\nunsuitable for interactive and creative usages such as interactive music\ngeneration. This paper introduces a novel architecture called Anticipation-RNN\nwhich possesses the assets of the RNN-based generative models while allowing to\nenforce user-defined positional constraints. We demonstrate its efficiency on\nthe task of generating melodies satisfying positional constraints in the style\nof the soprano parts of the J.S. Bach chorale harmonizations. Sampling using\nthe Anticipation-RNN is of the same order of complexity than sampling from the\ntraditional RNN model. This fast and interactive generation of musical\nsequences opens ways to devise real-time systems that could be used for\ncreative purposes.\n", "versions": [{"version": "v1", "created": "Tue, 19 Sep 2017 13:29:53 GMT"}], "update_date": "2017-09-20", "authors_parsed": [["Hadjeres", "Ga\u00ebtan", ""], ["Nielsen", "Frank", ""]]}, {"id": "1709.06429", "submitter": "Shaona Ghosh", "authors": "Shaona Ghosh, Per Ola Kristensson", "title": "Neural Networks for Text Correction and Completion in Keyboard Decoding", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Despite the ubiquity of mobile and wearable text messaging applications, the\nproblem of keyboard text decoding is not tackled sufficiently in the light of\nthe enormous success of the deep learning Recurrent Neural Network (RNN) and\nConvolutional Neural Networks (CNN) for natural language understanding. In\nparticular, considering that the keyboard decoders should operate on devices\nwith memory and processor resource constraints, makes it challenging to deploy\nindustrial scale deep neural network (DNN) models. This paper proposes a\nsequence-to-sequence neural attention network system for automatic text\ncorrection and completion. Given an erroneous sequence, our model encodes\ncharacter level hidden representations and then decodes the revised sequence\nthus enabling auto-correction and completion. We achieve this by a combination\nof character level CNN and gated recurrent unit (GRU) encoder along with and a\nword level gated recurrent unit (GRU) attention decoder. Unlike traditional\nlanguage models that learn from billions of words, our corpus size is only 12\nmillion words; an order of magnitude smaller. The memory footprint of our\nlearnt model for inference and prediction is also an order of magnitude smaller\nthan the conventional language model based text decoders. We report baseline\nperformance for neural keyboard decoders in such limited domain. Our models\nachieve a word level accuracy of $90\\%$ and a character error rate CER of\n$2.4\\%$ over the Twitter typo dataset. We present a novel dataset of noisy to\ncorrected mappings by inducing the noise distribution from the Twitter data\nover the OpenSubtitles 2009 dataset; on which our model predicts with a word\nlevel accuracy of $98\\%$ and sequence accuracy of $68.9\\%$. In our user study,\nour model achieved an average CER of $2.6\\%$ with the state-of-the-art\nnon-neural touch-screen keyboard decoder at CER of $1.6\\%$.\n", "versions": [{"version": "v1", "created": "Tue, 19 Sep 2017 13:52:28 GMT"}], "update_date": "2017-09-20", "authors_parsed": [["Ghosh", "Shaona", ""], ["Kristensson", "Per Ola", ""]]}, {"id": "1709.06444", "submitter": "Minh Trung Le", "authors": "Tung Pham, Trung Le, Hang Dang", "title": "Scalable Support Vector Clustering Using Budget", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Owing to its application in solving the difficult and diverse clustering or\noutlier detection problem, support-based clustering has recently drawn plenty\nof attention. Support-based clustering method always undergoes two phases:\nfinding the domain of novelty and performing clustering assignment. To find the\ndomain of novelty, the training time given by the current solvers is typically\nover-quadratic in the training size, and hence precluding the usage of\nsupport-based clustering method for large-scale datasets. In this paper, we\npropose applying Stochastic Gradient Descent (SGD) framework to the first phase\nof support-based clustering for finding the domain of novelty and a new\nstrategy to perform the clustering assignment. However, the direct application\nof SGD to the first phase of support-based clustering is vulnerable to the\ncurse of kernelization, that is, the model size linearly grows up with the data\nsize accumulated overtime. To address this issue, we invoke the budget approach\nwhich allows us to restrict the model size to a small budget. Our new strategy\nfor clustering assignment enables a fast computation by means of reducing the\ntask of clustering assignment on the full training set to the same task on a\nsignificantly smaller set. We also provide a rigorous theoretical analysis\nabout the convergence rate for the proposed method. Finally, we validate our\nproposed method on the well-known datasets for clustering to show that the\nproposed method offers a comparable clustering quality while simultaneously\nachieving significant speedup in comparison with the baselines.\n", "versions": [{"version": "v1", "created": "Tue, 19 Sep 2017 14:18:13 GMT"}], "update_date": "2017-09-20", "authors_parsed": [["Pham", "Tung", ""], ["Le", "Trung", ""], ["Dang", "Hang", ""]]}, {"id": "1709.06489", "submitter": "Louis Lello", "authors": "Louis Lello, Steven G. Avery, Laurent Tellier, Ana Vazquez, Gustavo de\n  los Campos, Stephen D.H. Hsu", "title": "Accurate Genomic Prediction Of Human Height", "comments": "17 pages, 10 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.GN cs.LG q-bio.QM stat.ML", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  We construct genomic predictors for heritable and extremely complex human\nquantitative traits (height, heel bone density, and educational attainment)\nusing modern methods in high dimensional statistics (i.e., machine learning).\nReplication tests show that these predictors capture, respectively, $\\sim$40,\n20, and 9 percent of total variance for the three traits. For example,\npredicted heights correlate $\\sim$0.65 with actual height; actual heights of\nmost individuals in validation samples are within a few cm of the prediction.\nThe variance captured for height is comparable to the estimated SNP\nheritability from GCTA (GREML) analysis, and seems to be close to its\nasymptotic value (i.e., as sample size goes to infinity), suggesting that we\nhave captured most of the heritability for the SNPs used. Thus, our results\nresolve the common SNP portion of the \"missing heritability\" problem -- i.e.,\nthe gap between prediction R-squared and SNP heritability. The $\\sim$20k\nactivated SNPs in our height predictor reveal the genetic architecture of human\nheight, at least for common SNPs. Our primary dataset is the UK Biobank cohort,\ncomprised of almost 500k individual genotypes with multiple phenotypes. We also\nuse other datasets and SNPs found in earlier GWAS for out-of-sample validation\nof our results.\n", "versions": [{"version": "v1", "created": "Tue, 19 Sep 2017 15:32:37 GMT"}], "update_date": "2017-09-20", "authors_parsed": [["Lello", "Louis", ""], ["Avery", "Steven G.", ""], ["Tellier", "Laurent", ""], ["Vazquez", "Ana", ""], ["Campos", "Gustavo de los", ""], ["Hsu", "Stephen D. H.", ""]]}, {"id": "1709.06493", "submitter": "Wei Zhang", "authors": "Wei Zhang, Bowen Zhou", "title": "Learning to update Auto-associative Memory in Recurrent Neural Networks\n  for Improving Sequence Memorization", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Learning to remember long sequences remains a challenging task for recurrent\nneural networks. Register memory and attention mechanisms were both proposed to\nresolve the issue with either high computational cost to retain memory\ndifferentiability, or by discounting the RNN representation learning towards\nencoding shorter local contexts than encouraging long sequence encoding.\nAssociative memory, which studies the compression of multiple patterns in a\nfixed size memory, were rarely considered in recent years. Although some recent\nwork tries to introduce associative memory in RNN and mimic the energy decay\nprocess in Hopfield nets, it inherits the shortcoming of rule-based memory\nupdates, and the memory capacity is limited. This paper proposes a method to\nlearn the memory update rule jointly with task objective to improve memory\ncapacity for remembering long sequences. Also, we propose an architecture that\nuses multiple such associative memory for more complex input encoding. We\nobserved some interesting facts when compared to other RNN architectures on\nsome well-studied sequence learning tasks.\n", "versions": [{"version": "v1", "created": "Tue, 19 Sep 2017 15:55:16 GMT"}, {"version": "v2", "created": "Fri, 29 Sep 2017 20:52:46 GMT"}, {"version": "v3", "created": "Tue, 3 Oct 2017 14:31:03 GMT"}], "update_date": "2017-10-04", "authors_parsed": [["Zhang", "Wei", ""], ["Zhou", "Bowen", ""]]}, {"id": "1709.06533", "submitter": "Christopher Grimm", "authors": "Christopher Grimm, Yuhang Song and Michael L. Littman", "title": "Summable Reparameterizations of Wasserstein Critics in the\n  One-Dimensional Setting", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Generative adversarial networks (GANs) are an exciting alternative to\nalgorithms for solving density estimation problems---using data to assess how\nlikely samples are to be drawn from the same distribution. Instead of\nexplicitly computing these probabilities, GANs learn a generator that can match\nthe given probabilistic source. This paper looks particularly at this matching\ncapability in the context of problems with one-dimensional outputs. We identify\na class of function decompositions with properties that make them well suited\nto the critic role in a leading approach to GANs known as Wasserstein GANs. We\nshow that Taylor and Fourier series decompositions belong to our class, provide\nexamples of these critics outperforming standard GAN approaches, and suggest\nhow they can be scaled to higher dimensional problems in the future.\n", "versions": [{"version": "v1", "created": "Tue, 19 Sep 2017 17:03:17 GMT"}], "update_date": "2017-09-20", "authors_parsed": [["Grimm", "Christopher", ""], ["Song", "Yuhang", ""], ["Littman", "Michael L.", ""]]}, {"id": "1709.06548", "submitter": "Zhe Gan", "authors": "Zhe Gan, Liqun Chen, Weiyao Wang, Yunchen Pu, Yizhe Zhang, Hao Liu,\n  Chunyuan Li, Lawrence Carin", "title": "Triangle Generative Adversarial Networks", "comments": "To appear in NIPS 2017", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A Triangle Generative Adversarial Network ($\\Delta$-GAN) is developed for\nsemi-supervised cross-domain joint distribution matching, where the training\ndata consists of samples from each domain, and supervision of domain\ncorrespondence is provided by only a few paired samples. $\\Delta$-GAN consists\nof four neural networks, two generators and two discriminators. The generators\nare designed to learn the two-way conditional distributions between the two\ndomains, while the discriminators implicitly define a ternary discriminative\nfunction, which is trained to distinguish real data pairs and two kinds of fake\ndata pairs. The generators and discriminators are trained together using\nadversarial learning. Under mild assumptions, in theory the joint distributions\ncharacterized by the two generators concentrate to the data distribution. In\nexperiments, three different kinds of domain pairs are considered, image-label,\nimage-image and image-attribute pairs. Experiments on semi-supervised image\nclassification, image-to-image translation and attribute-based image generation\ndemonstrate the superiority of the proposed approach.\n", "versions": [{"version": "v1", "created": "Tue, 19 Sep 2017 17:50:40 GMT"}, {"version": "v2", "created": "Sat, 18 Nov 2017 23:41:49 GMT"}], "update_date": "2017-11-21", "authors_parsed": [["Gan", "Zhe", ""], ["Chen", "Liqun", ""], ["Wang", "Weiyao", ""], ["Pu", "Yunchen", ""], ["Zhang", "Yizhe", ""], ["Liu", "Hao", ""], ["Li", "Chunyuan", ""], ["Carin", "Lawrence", ""]]}, {"id": "1709.06560", "submitter": "Peter Henderson", "authors": "Peter Henderson, Riashat Islam, Philip Bachman, Joelle Pineau, Doina\n  Precup, David Meger", "title": "Deep Reinforcement Learning that Matters", "comments": "Accepted to the Thirthy-Second AAAI Conference On Artificial\n  Intelligence (AAAI), 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In recent years, significant progress has been made in solving challenging\nproblems across various domains using deep reinforcement learning (RL).\nReproducing existing work and accurately judging the improvements offered by\nnovel methods is vital to sustaining this progress. Unfortunately, reproducing\nresults for state-of-the-art deep RL methods is seldom straightforward. In\nparticular, non-determinism in standard benchmark environments, combined with\nvariance intrinsic to the methods, can make reported results tough to\ninterpret. Without significance metrics and tighter standardization of\nexperimental reporting, it is difficult to determine whether improvements over\nthe prior state-of-the-art are meaningful. In this paper, we investigate\nchallenges posed by reproducibility, proper experimental techniques, and\nreporting procedures. We illustrate the variability in reported metrics and\nresults when comparing against common baselines and suggest guidelines to make\nfuture results in deep RL more reproducible. We aim to spur discussion about\nhow to ensure continued progress in the field by minimizing wasted effort\nstemming from results that are non-reproducible and easily misinterpreted.\n", "versions": [{"version": "v1", "created": "Tue, 19 Sep 2017 06:09:47 GMT"}, {"version": "v2", "created": "Fri, 24 Nov 2017 19:51:33 GMT"}, {"version": "v3", "created": "Wed, 30 Jan 2019 04:21:41 GMT"}], "update_date": "2019-01-31", "authors_parsed": [["Henderson", "Peter", ""], ["Islam", "Riashat", ""], ["Bachman", "Philip", ""], ["Pineau", "Joelle", ""], ["Precup", "Doina", ""], ["Meger", "David", ""]]}, {"id": "1709.06599", "submitter": "Junaid Qadir", "authors": "Muhammad Usama, Junaid Qadir, Aunn Raza, Hunain Arif, Kok-Lim Alvin\n  Yau, Yehia Elkhatib, Amir Hussain, Ala Al-Fuqaha", "title": "Unsupervised Machine Learning for Networking: Techniques, Applications\n  and Research Challenges", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  While machine learning and artificial intelligence have long been applied in\nnetworking research, the bulk of such works has focused on supervised learning.\nRecently there has been a rising trend of employing unsupervised machine\nlearning using unstructured raw network data to improve network performance and\nprovide services such as traffic engineering, anomaly detection, Internet\ntraffic classification, and quality of service optimization. The interest in\napplying unsupervised learning techniques in networking emerges from their\ngreat success in other fields such as computer vision, natural language\nprocessing, speech recognition, and optimal control (e.g., for developing\nautonomous self-driving cars). Unsupervised learning is interesting since it\ncan unconstrain us from the need of labeled data and manual handcrafted feature\nengineering thereby facilitating flexible, general, and automated methods of\nmachine learning. The focus of this survey paper is to provide an overview of\nthe applications of unsupervised learning in the domain of networking. We\nprovide a comprehensive survey highlighting the recent advancements in\nunsupervised learning techniques and describe their applications for various\nlearning tasks in the context of networking. We also provide a discussion on\nfuture directions and open research issues, while also identifying potential\npitfalls. While a few survey papers focusing on the applications of machine\nlearning in networking have previously been published, a survey of similar\nscope and breadth is missing in literature. Through this paper, we advance the\nstate of knowledge by carefully synthesizing the insights from these survey\npapers while also providing contemporary coverage of recent advances.\n", "versions": [{"version": "v1", "created": "Tue, 19 Sep 2017 18:37:42 GMT"}], "update_date": "2017-09-21", "authors_parsed": [["Usama", "Muhammad", ""], ["Qadir", "Junaid", ""], ["Raza", "Aunn", ""], ["Arif", "Hunain", ""], ["Yau", "Kok-Lim Alvin", ""], ["Elkhatib", "Yehia", ""], ["Hussain", "Amir", ""], ["Al-Fuqaha", "Ala", ""]]}, {"id": "1709.06614", "submitter": "Yuan Du", "authors": "Yuan Du, Li Du, Xuefeng Gu, Jieqiong Du, X. Shawn Wang, Boyu Hu,\n  Mingzhe Jiang, Xiaoliang Chen, Junjie Su, Subramanian S. Iyer, Mau-Chung\n  Frank Chang", "title": "An Analog Neural Network Computing Engine using CMOS-Compatible\n  Charge-Trap-Transistor (CTT)", "comments": "9 pages, 11 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.ET cs.AR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  An analog neural network computing engine based on CMOS-compatible\ncharge-trap transistor (CTT) is proposed in this paper. CTT devices are used as\nanalog multipliers. Compared to digital multipliers, CTT-based analog\nmultiplier shows significant area and power reduction. The proposed computing\nengine is composed of a scalable CTT multiplier array and energy efficient\nanalog-digital interfaces. Through implementing the sequential analog fabric\n(SAF), the engine mixed-signal interfaces are simplified and hardware overhead\nremains constant regardless of the size of the array. A proof-of-concept 784 by\n784 CTT computing engine is implemented using TSMC 28nm CMOS technology and\noccupied 0.68mm2. The simulated performance achieves 76.8 TOPS (8-bit) with 500\nMHz clock frequency and consumes 14.8 mW. As an example, we utilize this\ncomputing engine to address a classic pattern recognition problem --\nclassifying handwritten digits on MNIST database and obtained a performance\ncomparable to state-of-the-art fully connected neural networks using 8-bit\nfixed-point resolution.\n", "versions": [{"version": "v1", "created": "Tue, 19 Sep 2017 19:09:16 GMT"}, {"version": "v2", "created": "Wed, 20 Jun 2018 06:38:37 GMT"}, {"version": "v3", "created": "Wed, 8 Aug 2018 10:15:01 GMT"}, {"version": "v4", "created": "Thu, 9 Aug 2018 07:36:18 GMT"}], "update_date": "2018-08-10", "authors_parsed": [["Du", "Yuan", ""], ["Du", "Li", ""], ["Gu", "Xuefeng", ""], ["Du", "Jieqiong", ""], ["Wang", "X. Shawn", ""], ["Hu", "Boyu", ""], ["Jiang", "Mingzhe", ""], ["Chen", "Xiaoliang", ""], ["Su", "Junjie", ""], ["Iyer", "Subramanian S.", ""], ["Chang", "Mau-Chung Frank", ""]]}, {"id": "1709.06617", "submitter": "Ben London", "authors": "Ben London", "title": "A PAC-Bayesian Analysis of Randomized Learning with Application to\n  Stochastic Gradient Descent", "comments": "In Neural Information Processing Systems (NIPS) 2017. The latest\n  version specifies that the references to Kuzborskij & Lampert (2017) are for\n  v2 of their manuscript, which was posted to arXiv in March, 2017.\n  Importantly, Theorem 3 therein (a stability bound for convex losses) has a\n  different form than the final version", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the generalization error of randomized learning algorithms --\nfocusing on stochastic gradient descent (SGD) -- using a novel combination of\nPAC-Bayes and algorithmic stability. Importantly, our generalization bounds\nhold for all posterior distributions on an algorithm's random hyperparameters,\nincluding distributions that depend on the training data. This inspires an\nadaptive sampling algorithm for SGD that optimizes the posterior at runtime. We\nanalyze this algorithm in the context of our generalization bounds and evaluate\nit on a benchmark dataset. Our experiments demonstrate that adaptive sampling\ncan reduce empirical risk faster than uniform sampling while also improving\nout-of-sample accuracy.\n", "versions": [{"version": "v1", "created": "Tue, 19 Sep 2017 19:21:33 GMT"}, {"version": "v2", "created": "Thu, 9 Nov 2017 18:45:42 GMT"}, {"version": "v3", "created": "Sat, 2 Dec 2017 01:07:32 GMT"}, {"version": "v4", "created": "Wed, 31 Jan 2018 05:31:46 GMT"}, {"version": "v5", "created": "Sat, 20 Jun 2020 19:44:42 GMT"}], "update_date": "2020-06-23", "authors_parsed": [["London", "Ben", ""]]}, {"id": "1709.06620", "submitter": "Qiyang Li", "authors": "Qiyang Li, Xintong Du, Yizhou Huang, Quinlan Sykora, and Angela P.\n  Schoellig", "title": "Learning of Coordination Policies for Robotic Swarms", "comments": "8 pages, 11 figures, submitted to 2018 IEEE International Conference\n  on Robotics and Automation", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.AI cs.LG cs.MA cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Inspired by biological swarms, robotic swarms are envisioned to solve\nreal-world problems that are difficult for individual agents. Biological swarms\ncan achieve collective intelligence based on local interactions and simple\nrules; however, designing effective distributed policies for large-scale\nrobotic swarms to achieve a global objective can be challenging. Although it is\noften possible to design an optimal centralized strategy for smaller numbers of\nagents, those methods can fail as the number of agents increases. Motivated by\nthe growing success of machine learning, we develop a deep learning approach\nthat learns distributed coordination policies from centralized policies. In\ncontrast to traditional distributed control approaches, which are usually based\non human-designed policies for relatively simple tasks, this learning-based\napproach can be adapted to more difficult tasks. We demonstrate the efficacy of\nour proposed approach on two different tasks, the well-known rendezvous problem\nand a more difficult particle assignment problem. For the latter, no known\ndistributed policy exists. From extensive simulations, it is shown that the\nperformance of the learned coordination policies is comparable to the\ncentralized policies, surpassing state-of-the-art distributed policies.\nThereby, our proposed approach provides a promising alternative for real-world\ncoordination problems that would be otherwise computationally expensive to\nsolve or intangible to explore.\n", "versions": [{"version": "v1", "created": "Tue, 19 Sep 2017 19:26:20 GMT"}], "update_date": "2017-09-21", "authors_parsed": [["Li", "Qiyang", ""], ["Du", "Xintong", ""], ["Huang", "Yizhou", ""], ["Sykora", "Quinlan", ""], ["Schoellig", "Angela P.", ""]]}, {"id": "1709.06622", "submitter": "Chun-Nan Chou", "authors": "Shang-Xuan Zou, Chun-Yen Chen, Jui-Lin Wu, Chun-Nan Chou, Chia-Chin\n  Tsao, Kuan-Chieh Tung, Ting-Wei Lin, Cheng-Lung Sung, and Edward Y. Chang", "title": "Distributed Training Large-Scale Deep Architectures", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Scale of data and scale of computation infrastructures together enable the\ncurrent deep learning renaissance. However, training large-scale deep\narchitectures demands both algorithmic improvement and careful system\nconfiguration. In this paper, we focus on employing the system approach to\nspeed up large-scale training. Via lessons learned from our routine\nbenchmarking effort, we first identify bottlenecks and overheads that hinter\ndata parallelism. We then devise guidelines that help practitioners to\nconfigure an effective system and fine-tune parameters to achieve desired\nspeedup. Specifically, we develop a procedure for setting minibatch size and\nchoosing computation algorithms. We also derive lemmas for determining the\nquantity of key components such as the number of GPUs and parameter servers.\nExperiments and examples show that these guidelines help effectively speed up\nlarge-scale deep learning training.\n", "versions": [{"version": "v1", "created": "Thu, 10 Aug 2017 09:24:27 GMT"}], "update_date": "2017-09-21", "authors_parsed": [["Zou", "Shang-Xuan", ""], ["Chen", "Chun-Yen", ""], ["Wu", "Jui-Lin", ""], ["Chou", "Chun-Nan", ""], ["Tsao", "Chia-Chin", ""], ["Tung", "Kuan-Chieh", ""], ["Lin", "Ting-Wei", ""], ["Sung", "Cheng-Lung", ""], ["Chang", "Edward Y.", ""]]}, {"id": "1709.06636", "submitter": "Meng Qu", "authors": "Meng Qu, Jian Tang, Jingbo Shang, Xiang Ren, Ming Zhang, Jiawei Han", "title": "An Attention-based Collaboration Framework for Multi-View Network\n  Representation Learning", "comments": "CIKM 2017", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SI cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Learning distributed node representations in networks has been attracting\nincreasing attention recently due to its effectiveness in a variety of\napplications. Existing approaches usually study networks with a single type of\nproximity between nodes, which defines a single view of a network. However, in\nreality there usually exists multiple types of proximities between nodes,\nyielding networks with multiple views. This paper studies learning node\nrepresentations for networks with multiple views, which aims to infer robust\nnode representations across different views. We propose a multi-view\nrepresentation learning approach, which promotes the collaboration of different\nviews and lets them vote for the robust representations. During the voting\nprocess, an attention mechanism is introduced, which enables each node to focus\non the most informative views. Experimental results on real-world networks show\nthat the proposed approach outperforms existing state-of-the-art approaches for\nnetwork representation learning with a single view and other competitive\napproaches with multiple views.\n", "versions": [{"version": "v1", "created": "Tue, 19 Sep 2017 20:30:30 GMT"}], "update_date": "2017-09-21", "authors_parsed": [["Qu", "Meng", ""], ["Tang", "Jian", ""], ["Shang", "Jingbo", ""], ["Ren", "Xiang", ""], ["Zhang", "Ming", ""], ["Han", "Jiawei", ""]]}, {"id": "1709.06653", "submitter": "James P. Crutchfield", "authors": "Ryan G. James, Jeffrey Emenheiser, and James P. Crutchfield", "title": "Unique Information via Dependency Constraints", "comments": "15 pages, 7 figures, 2 tables, 3 appendices;\n  http://csc.ucdavis.edu/~cmg/compmech/pubs/idep.htm", "journal-ref": null, "doi": null, "report-no": null, "categories": "cond-mat.stat-mech cs.IT cs.LG math.IT math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The partial information decomposition (PID) is perhaps the leading proposal\nfor resolving information shared between a set of sources and a target into\nredundant, synergistic, and unique constituents. Unfortunately, the PID\nframework has been hindered by a lack of a generally agreed-upon, multivariate\nmethod of quantifying the constituents. Here, we take a step toward rectifying\nthis by developing a decomposition based on a new method that quantifies unique\ninformation. We first develop a broadly applicable method---the dependency\ndecomposition---that delineates how statistical dependencies influence the\nstructure of a joint distribution. The dependency decomposition then allows us\nto define a measure of the information about a target that can be uniquely\nattributed to a particular source as the least amount which the source-target\nstatistical dependency can influence the information shared between the sources\nand the target. The result is the first measure that satisfies the core axioms\nof the PID framework while not satisfying the Blackwell relation, which depends\non a particular interpretation of how the variables are related. This makes a\nkey step forward to a practical PID.\n", "versions": [{"version": "v1", "created": "Tue, 19 Sep 2017 21:36:28 GMT"}, {"version": "v2", "created": "Sun, 29 Apr 2018 20:22:28 GMT"}, {"version": "v3", "created": "Sat, 27 Oct 2018 17:48:17 GMT"}], "update_date": "2018-10-30", "authors_parsed": [["James", "Ryan G.", ""], ["Emenheiser", "Jeffrey", ""], ["Crutchfield", "James P.", ""]]}, {"id": "1709.06662", "submitter": "Nina Narodytska", "authors": "Nina Narodytska, Shiva Prasad Kasiviswanathan, Leonid Ryzhyk, Mooly\n  Sagiv, Toby Walsh", "title": "Verifying Properties of Binarized Deep Neural Networks", "comments": "10 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.AI cs.CR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Understanding properties of deep neural networks is an important challenge in\ndeep learning. In this paper, we take a step in this direction by proposing a\nrigorous way of verifying properties of a popular class of neural networks,\nBinarized Neural Networks, using the well-developed means of Boolean\nsatisfiability. Our main contribution is a construction that creates a\nrepresentation of a binarized neural network as a Boolean formula. Our encoding\nis the first exact Boolean representation of a deep neural network. Using this\nencoding, we leverage the power of modern SAT solvers along with a proposed\ncounterexample-guided search procedure to verify various properties of these\nnetworks. A particular focus will be on the critical property of robustness to\nadversarial perturbations. For this property, our experimental results\ndemonstrate that our approach scales to medium-size deep neural networks used\nin image classification tasks. To the best of our knowledge, this is the first\nwork on verifying properties of deep neural networks using an exact Boolean\nencoding of the network.\n", "versions": [{"version": "v1", "created": "Tue, 19 Sep 2017 22:21:49 GMT"}, {"version": "v2", "created": "Thu, 31 May 2018 18:30:06 GMT"}], "update_date": "2018-06-04", "authors_parsed": [["Narodytska", "Nina", ""], ["Kasiviswanathan", "Shiva Prasad", ""], ["Ryzhyk", "Leonid", ""], ["Sagiv", "Mooly", ""], ["Walsh", "Toby", ""]]}, {"id": "1709.06669", "submitter": "Abhay Harpale", "authors": "Abhay Harpale (1), Abhishek Srivastav (1) ((1) GE Global Research)", "title": "A textual transform of multivariate time-series for prognostics", "comments": "10 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Prognostics or early detection of incipient faults is an important industrial\nchallenge for condition-based and preventive maintenance. Physics-based\napproaches to modeling fault progression are infeasible due to multiple\ninteracting components, uncontrolled environmental factors and observability\nconstraints. Moreover, such approaches to prognostics do not generalize to new\ndomains. Consequently, domain-agnostic data-driven machine learning approaches\nto prognostics are desirable. Damage progression is a path-dependent process\nand explicitly modeling the temporal patterns is critical for accurate\nestimation of both the current damage state and its progression leading to\ntotal failure. In this paper, we present a novel data-driven approach to\nprognostics that employs a novel textual representation of multivariate\ntemporal sensor observations for predicting the future health state of the\nmonitored equipment early in its life. This representation enables us to\nutilize well-understood concepts from text-mining for modeling, prediction and\nunderstanding distress patterns in a domain agnostic way. The approach has been\ndeployed and successfully tested on large scale multivariate time-series data\nfrom commercial aircraft engines. We report experiments on well-known publicly\navailable benchmark datasets and simulation datasets. The proposed approach is\nshown to be superior in terms of prediction accuracy, lead time to prediction\nand interpretability.\n", "versions": [{"version": "v1", "created": "Tue, 19 Sep 2017 22:54:10 GMT"}], "update_date": "2017-09-21", "authors_parsed": [["Harpale", "Abhay", "", "GE Global Research"], ["Srivastav", "Abhishek", "", "GE Global Research"]]}, {"id": "1709.06671", "submitter": "Danushka Bollegala", "authors": "Danushka Bollegala, Kohei Hayashi and Ken-ichi Kawarabayashi", "title": "Think Globally, Embed Locally --- Locally Linear Meta-embedding of Words", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Distributed word embeddings have shown superior performances in numerous\nNatural Language Processing (NLP) tasks. However, their performances vary\nsignificantly across different tasks, implying that the word embeddings learnt\nby those methods capture complementary aspects of lexical semantics. Therefore,\nwe believe that it is important to combine the existing word embeddings to\nproduce more accurate and complete \\emph{meta-embeddings} of words. For this\npurpose, we propose an unsupervised locally linear meta-embedding learning\nmethod that takes pre-trained word embeddings as the input, and produces more\naccurate meta embeddings. Unlike previously proposed meta-embedding learning\nmethods that learn a global projection over all words in a vocabulary, our\nproposed method is sensitive to the differences in local neighbourhoods of the\nindividual source word embeddings. Moreover, we show that vector concatenation,\na previously proposed highly competitive baseline approach for integrating word\nembeddings, can be derived as a special case of the proposed method.\nExperimental results on semantic similarity, word analogy, relation\nclassification, and short-text classification tasks show that our\nmeta-embeddings to significantly outperform prior methods in several benchmark\ndatasets, establishing a new state of the art for meta-embeddings.\n", "versions": [{"version": "v1", "created": "Tue, 19 Sep 2017 22:58:02 GMT"}], "update_date": "2017-09-21", "authors_parsed": [["Bollegala", "Danushka", ""], ["Hayashi", "Kohei", ""], ["Kawarabayashi", "Ken-ichi", ""]]}, {"id": "1709.06673", "submitter": "Danushka Bollegala", "authors": "Huda Hakami and Danushka Bollegala and Hayashi Kohei", "title": "Why PairDiff works? -- A Mathematical Analysis of Bilinear Relational\n  Compositional Operators for Analogy Detection", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Representing the semantic relations that exist between two given words (or\nentities) is an important first step in a wide-range of NLP applications such\nas analogical reasoning, knowledge base completion and relational information\nretrieval. A simple, yet surprisingly accurate method for representing a\nrelation between two words is to compute the vector offset (\\PairDiff) between\ntheir corresponding word embeddings. Despite the empirical success, it remains\nunclear as to whether \\PairDiff is the best operator for obtaining a relational\nrepresentation from word embeddings. We conduct a theoretical analysis of\ngeneralised bilinear operators that can be used to measure the $\\ell_{2}$\nrelational distance between two word-pairs. We show that, if the word\nembeddings are standardised and uncorrelated, such an operator will be\nindependent of bilinear terms, and can be simplified to a linear form, where\n\\PairDiff is a special case. For numerous word embedding types, we empirically\nverify the uncorrelation assumption, demonstrating the general applicability of\nour theoretical result. Moreover, we experimentally discover \\PairDiff from the\nbilinear relation composition operator on several benchmark analogy datasets.\n", "versions": [{"version": "v1", "created": "Tue, 19 Sep 2017 23:09:15 GMT"}, {"version": "v2", "created": "Fri, 15 Dec 2017 15:41:23 GMT"}], "update_date": "2017-12-18", "authors_parsed": [["Hakami", "Huda", ""], ["Bollegala", "Danushka", ""], ["Kohei", "Hayashi", ""]]}, {"id": "1709.06680", "submitter": "Seungil You", "authors": "Seungil You, David Ding, Kevin Canini, Jan Pfeifer, Maya Gupta", "title": "Deep Lattice Networks and Partial Monotonic Functions", "comments": "9 pages, NIPS 2017", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  We propose learning deep models that are monotonic with respect to a\nuser-specified set of inputs by alternating layers of linear embeddings,\nensembles of lattices, and calibrators (piecewise linear functions), with\nappropriate constraints for monotonicity, and jointly training the resulting\nnetwork. We implement the layers and projections with new computational graph\nnodes in TensorFlow and use the ADAM optimizer and batched stochastic\ngradients. Experiments on benchmark and real-world datasets show that six-layer\nmonotonic deep lattice networks achieve state-of-the art performance for\nclassification and regression with monotonicity guarantees.\n", "versions": [{"version": "v1", "created": "Tue, 19 Sep 2017 23:48:39 GMT"}], "update_date": "2017-09-21", "authors_parsed": [["You", "Seungil", ""], ["Ding", "David", ""], ["Canini", "Kevin", ""], ["Pfeifer", "Jan", ""], ["Gupta", "Maya", ""]]}, {"id": "1709.06683", "submitter": "Peter Henderson", "authors": "Peter Henderson, Wei-Di Chang, Pierre-Luc Bacon, David Meger, Joelle\n  Pineau, Doina Precup", "title": "OptionGAN: Learning Joint Reward-Policy Options using Generative\n  Adversarial Inverse Reinforcement Learning", "comments": "Accepted to the Thirthy-Second AAAI Conference On Artificial\n  Intelligence (AAAI), 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Reinforcement learning has shown promise in learning policies that can solve\ncomplex problems. However, manually specifying a good reward function can be\ndifficult, especially for intricate tasks. Inverse reinforcement learning\noffers a useful paradigm to learn the underlying reward function directly from\nexpert demonstrations. Yet in reality, the corpus of demonstrations may contain\ntrajectories arising from a diverse set of underlying reward functions rather\nthan a single one. Thus, in inverse reinforcement learning, it is useful to\nconsider such a decomposition. The options framework in reinforcement learning\nis specifically designed to decompose policies in a similar light. We therefore\nextend the options framework and propose a method to simultaneously recover\nreward options in addition to policy options. We leverage adversarial methods\nto learn joint reward-policy options using only observed expert states. We show\nthat this approach works well in both simple and complex continuous control\ntasks and shows significant performance increases in one-shot transfer\nlearning.\n", "versions": [{"version": "v1", "created": "Wed, 20 Sep 2017 00:10:52 GMT"}, {"version": "v2", "created": "Fri, 24 Nov 2017 19:31:45 GMT"}], "update_date": "2017-11-28", "authors_parsed": [["Henderson", "Peter", ""], ["Chang", "Wei-Di", ""], ["Bacon", "Pierre-Luc", ""], ["Meger", "David", ""], ["Pineau", "Joelle", ""], ["Precup", "Doina", ""]]}, {"id": "1709.06709", "submitter": "Franziska Meier", "authors": "Franziska Meier, Daniel Kappler and Stefan Schaal", "title": "Online Learning of a Memory for Learning Rates", "comments": "accepted to ICRA 2018, code available:\n  https://github.com/fmeier/online-meta-learning ; video pitch available:\n  https://youtu.be/9PzQ25FPPOM", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The promise of learning to learn for robotics rests on the hope that by\nextracting some information about the learning process itself we can speed up\nsubsequent similar learning tasks. Here, we introduce a computationally\nefficient online meta-learning algorithm that builds and optimizes a memory\nmodel of the optimal learning rate landscape from previously observed gradient\nbehaviors. While performing task specific optimization, this memory of learning\nrates predicts how to scale currently observed gradients. After applying the\ngradient scaling our meta-learner updates its internal memory based on the\nobserved effect its prediction had. Our meta-learner can be combined with any\ngradient-based optimizer, learns on the fly and can be transferred to new\noptimization tasks. In our evaluations we show that our meta-learning algorithm\nspeeds up learning of MNIST classification and a variety of learning control\ntasks, either in batch or online learning settings.\n", "versions": [{"version": "v1", "created": "Wed, 20 Sep 2017 03:18:54 GMT"}, {"version": "v2", "created": "Fri, 23 Mar 2018 19:22:19 GMT"}], "update_date": "2018-03-28", "authors_parsed": [["Meier", "Franziska", ""], ["Kappler", "Daniel", ""], ["Schaal", "Stefan", ""]]}, {"id": "1709.06716", "submitter": "Abubakar Abid", "authors": "Abubakar Abid, Martin J. Zhang, Vivek K. Bagaria, James Zou", "title": "Contrastive Principal Component Analysis", "comments": "main body is 10 pages, 9 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a new technique called contrastive principal component analysis\n(cPCA) that is designed to discover low-dimensional structure that is unique to\na dataset, or enriched in one dataset relative to other data. The technique is\na generalization of standard PCA, for the setting where multiple datasets are\navailable -- e.g. a treatment and a control group, or a mixed versus a\nhomogeneous population -- and the goal is to explore patterns that are specific\nto one of the datasets. We conduct a wide variety of experiments in which cPCA\nidentifies important dataset-specific patterns that are missed by PCA,\ndemonstrating that it is useful for many applications: subgroup discovery,\nvisualizing trends, feature selection, denoising, and data-dependent\nstandardization. We provide geometrical interpretations of cPCA and show that\nit satisfies desirable theoretical guarantees. We also extend cPCA to nonlinear\nsettings in the form of kernel cPCA. We have released our code as a python\npackage and documentation is on Github.\n", "versions": [{"version": "v1", "created": "Wed, 20 Sep 2017 03:53:03 GMT"}, {"version": "v2", "created": "Wed, 22 Nov 2017 00:26:51 GMT"}], "update_date": "2017-11-23", "authors_parsed": [["Abid", "Abubakar", ""], ["Zhang", "Martin J.", ""], ["Bagaria", "Vivek K.", ""], ["Zou", "James", ""]]}, {"id": "1709.06853", "submitter": "Ciara Pike-Burke", "authors": "Ciara Pike-Burke, Shipra Agrawal, Csaba Szepesvari, Steffen\n  Grunewalder", "title": "Bandits with Delayed, Aggregated Anonymous Feedback", "comments": "ICML 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study a variant of the stochastic $K$-armed bandit problem, which we call\n\"bandits with delayed, aggregated anonymous feedback\". In this problem, when\nthe player pulls an arm, a reward is generated, however it is not immediately\nobserved. Instead, at the end of each round the player observes only the sum of\na number of previously generated rewards which happen to arrive in the given\nround. The rewards are stochastically delayed and due to the aggregated nature\nof the observations, the information of which arm led to a particular reward is\nlost. The question is what is the cost of the information loss due to this\ndelayed, aggregated anonymous feedback? Previous works have studied bandits\nwith stochastic, non-anonymous delays and found that the regret increases only\nby an additive factor relating to the expected delay. In this paper, we show\nthat this additive regret increase can be maintained in the harder delayed,\naggregated anonymous feedback setting when the expected delay (or a bound on\nit) is known. We provide an algorithm that matches the worst case regret of the\nnon-anonymous problem exactly when the delays are bounded, and up to\nlogarithmic factors or an additive variance term for unbounded delays.\n", "versions": [{"version": "v1", "created": "Wed, 20 Sep 2017 13:36:19 GMT"}, {"version": "v2", "created": "Thu, 15 Feb 2018 17:36:26 GMT"}, {"version": "v3", "created": "Wed, 13 Jun 2018 17:29:28 GMT"}], "update_date": "2018-06-14", "authors_parsed": [["Pike-Burke", "Ciara", ""], ["Agrawal", "Shipra", ""], ["Szepesvari", "Csaba", ""], ["Grunewalder", "Steffen", ""]]}, {"id": "1709.06895", "submitter": "Tao Hong", "authors": "Tao Hong, Xiao Li, Zhihui Zhu and Qiuwei Li", "title": "Optimized Structured Sparse Sensing Matrices for Compressive Sensing", "comments": "2 tables, 10 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.SP cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider designing a robust structured sparse sensing matrix consisting of\na sparse matrix with a few non-zero entries per row and a dense base matrix for\ncapturing signals efficiently We design the robust structured sparse sensing\nmatrix through minimizing the distance between the Gram matrix of the\nequivalent dictionary and the target Gram of matrix holding small mutual\ncoherence. Moreover, a regularization is added to enforce the robustness of the\noptimized structured sparse sensing matrix to the sparse representation error\n(SRE) of signals of interests. An alternating minimization algorithm with\nglobal sequence convergence is proposed for solving the corresponding\noptimization problem. Numerical experiments on synthetic data and natural\nimages show that the obtained structured sensing matrix results in a higher\nsignal reconstruction than a random dense sensing matrix.\n", "versions": [{"version": "v1", "created": "Tue, 19 Sep 2017 17:03:33 GMT"}, {"version": "v2", "created": "Fri, 8 Dec 2017 17:48:26 GMT"}, {"version": "v3", "created": "Tue, 5 Feb 2019 14:55:17 GMT"}], "update_date": "2019-02-06", "authors_parsed": [["Hong", "Tao", ""], ["Li", "Xiao", ""], ["Zhu", "Zhihui", ""], ["Li", "Qiuwei", ""]]}, {"id": "1709.06917", "submitter": "Konstantinos Chatzilygeroudis", "authors": "Konstantinos Chatzilygeroudis and Jean-Baptiste Mouret", "title": "Using Parameterized Black-Box Priors to Scale Up Model-Based Policy\n  Search for Robotics", "comments": "Accepted at ICRA 2018; 8 pages, 4 figures, 2 algorithms, 1 table;\n  Video at https://youtu.be/HFkZkhGGzTo ; Spotlight ICRA presentation at\n  https://youtu.be/_MZYDhfWeLc", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.AI cs.LG cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The most data-efficient algorithms for reinforcement learning in robotics are\nmodel-based policy search algorithms, which alternate between learning a\ndynamical model of the robot and optimizing a policy to maximize the expected\nreturn given the model and its uncertainties. Among the few proposed\napproaches, the recently introduced Black-DROPS algorithm exploits a black-box\noptimization algorithm to achieve both high data-efficiency and good\ncomputation times when several cores are used; nevertheless, like all\nmodel-based policy search approaches, Black-DROPS does not scale to high\ndimensional state/action spaces. In this paper, we introduce a new model\nlearning procedure in Black-DROPS that leverages parameterized black-box priors\nto (1) scale up to high-dimensional systems, and (2) be robust to large\ninaccuracies of the prior information. We demonstrate the effectiveness of our\napproach with the \"pendubot\" swing-up task in simulation and with a physical\nhexapod robot (48D state space, 18D action space) that has to walk forward as\nfast as possible. The results show that our new algorithm is more\ndata-efficient than previous model-based policy search algorithms (with and\nwithout priors) and that it can allow a physical 6-legged robot to learn new\ngaits in only 16 to 30 seconds of interaction time.\n", "versions": [{"version": "v1", "created": "Wed, 20 Sep 2017 15:03:47 GMT"}, {"version": "v2", "created": "Tue, 13 Mar 2018 16:39:40 GMT"}], "update_date": "2018-03-14", "authors_parsed": [["Chatzilygeroudis", "Konstantinos", ""], ["Mouret", "Jean-Baptiste", ""]]}, {"id": "1709.06919", "submitter": "Konstantinos Chatzilygeroudis", "authors": "R\\'emi Pautrat, Konstantinos Chatzilygeroudis and Jean-Baptiste Mouret", "title": "Bayesian Optimization with Automatic Prior Selection for Data-Efficient\n  Direct Policy Search", "comments": "Accepted at ICRA 2018; 8 pages, 4 figures, 1 algorithm; Video at\n  https://youtu.be/xo8mUIZTvNE ; Spotlight ICRA presentation\n  https://youtu.be/iiVaV-U6Kqo", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.AI cs.LG cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  One of the most interesting features of Bayesian optimization for direct\npolicy search is that it can leverage priors (e.g., from simulation or from\nprevious tasks) to accelerate learning on a robot. In this paper, we are\ninterested in situations for which several priors exist but we do not know in\nadvance which one fits best the current situation. We tackle this problem by\nintroducing a novel acquisition function, called Most Likely Expected\nImprovement (MLEI), that combines the likelihood of the priors and the expected\nimprovement. We evaluate this new acquisition function on a transfer learning\ntask for a 5-DOF planar arm and on a possibly damaged, 6-legged robot that has\nto learn to walk on flat ground and on stairs, with priors corresponding to\ndifferent stairs and different kinds of damages. Our results show that MLEI\neffectively identifies and exploits the priors, even when there is no obvious\nmatch between the current situations and the priors.\n", "versions": [{"version": "v1", "created": "Wed, 20 Sep 2017 15:04:50 GMT"}, {"version": "v2", "created": "Tue, 13 Mar 2018 16:45:49 GMT"}], "update_date": "2018-03-14", "authors_parsed": [["Pautrat", "R\u00e9mi", ""], ["Chatzilygeroudis", "Konstantinos", ""], ["Mouret", "Jean-Baptiste", ""]]}, {"id": "1709.06922", "submitter": "Afshin Oroojlooy Jadid", "authors": "Afshin Oroojlooyjadid, Lawrence Snyder, Martin Tak\\'a\\v{c}", "title": "Stock-out Prediction in Multi-echelon Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In multi-echelon inventory systems the performance of a given node is\naffected by events that occur at many other nodes and in many other time\nperiods. For example, a supply disruption upstream will have an effect on\ndownstream, customer-facing nodes several periods later as the disruption\n\"cascades\" through the system. There is very little research on stock-out\nprediction in single-echelon systems and (to the best of our knowledge) none on\nmulti-echelon systems. However, in real the world, it is clear that there is\nsignificant interest in techniques for this sort of stock-out prediction.\nTherefore, our research aims to fill this gap by using deep neural networks\n(DNN) to predict stock-outs in multi-echelon supply chains.\n", "versions": [{"version": "v1", "created": "Wed, 20 Sep 2017 15:11:53 GMT"}, {"version": "v2", "created": "Thu, 8 Mar 2018 14:17:01 GMT"}], "update_date": "2018-03-09", "authors_parsed": [["Oroojlooyjadid", "Afshin", ""], ["Snyder", "Lawrence", ""], ["Tak\u00e1\u010d", "Martin", ""]]}, {"id": "1709.06950", "submitter": "Damian Berger", "authors": "Damian L. Berger, Lucilla de Arcangelis, and Hans J. Herrmann", "title": "Spatial features of synaptic adaptation affecting learning performance", "comments": null, "journal-ref": "Scientific Reports 7, 11016 (2017)", "doi": "10.1038/s41598-017-11424-5", "report-no": null, "categories": "q-bio.NC cond-mat.dis-nn cs.LG cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent studies have proposed that the diffusion of messenger molecules, such\nas monoamines, can mediate the plastic adaptation of synapses in supervised\nlearning of neural networks. Based on these findings we developed a model for\nneural learning, where the signal for plastic adaptation is assumed to\npropagate through the extracellular space. We investigate the conditions\nallowing learning of Boolean rules in a neural network. Even fully excitatory\nnetworks show very good learning performances. Moreover, the investigation of\nthe plastic adaptation features optimizing the performance suggests that\nlearning is very sensitive to the extent of the plastic adaptation and the\nspatial range of synaptic connections.\n", "versions": [{"version": "v1", "created": "Wed, 20 Sep 2017 16:18:17 GMT"}], "update_date": "2017-09-21", "authors_parsed": [["Berger", "Damian L.", ""], ["de Arcangelis", "Lucilla", ""], ["Herrmann", "Hans J.", ""]]}, {"id": "1709.06994", "submitter": "Huan Wang", "authors": "Huan Wang, Qiming Zhang, Yuehai Wang, Haoji Hu", "title": "Structured Probabilistic Pruning for Convolutional Neural Network\n  Acceleration", "comments": "CNN model acceleration, 13 pages, 6 figures, accepted by Proceedings\n  of the British Machine Vision Conference (BMVC), 2018 oral", "journal-ref": "Proceedings of the British Machine Vision Conference (BMVC), 2018", "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we propose a novel progressive parameter pruning method for\nConvolutional Neural Network acceleration, named Structured Probabilistic\nPruning (SPP), which effectively prunes weights of convolutional layers in a\nprobabilistic manner. Unlike existing deterministic pruning approaches, where\nunimportant weights are permanently eliminated, SPP introduces a pruning\nprobability for each weight, and pruning is guided by sampling from the pruning\nprobabilities. A mechanism is designed to increase and decrease pruning\nprobabilities based on importance criteria in the training process. Experiments\nshow that, with 4x speedup, SPP can accelerate AlexNet with only 0.3% loss of\ntop-5 accuracy and VGG-16 with 0.8% loss of top-5 accuracy in ImageNet\nclassification. Moreover, SPP can be directly applied to accelerate\nmulti-branch CNN networks, such as ResNet, without specific adaptations. Our 2x\nspeedup ResNet-50 only suffers 0.8% loss of top-5 accuracy on ImageNet. We\nfurther show the effectiveness of SPP on transfer learning tasks.\n", "versions": [{"version": "v1", "created": "Wed, 20 Sep 2017 03:13:40 GMT"}, {"version": "v2", "created": "Tue, 28 Nov 2017 16:39:49 GMT"}, {"version": "v3", "created": "Mon, 10 Sep 2018 01:11:50 GMT"}], "update_date": "2018-09-13", "authors_parsed": [["Wang", "Huan", ""], ["Zhang", "Qiming", ""], ["Wang", "Yuehai", ""], ["Hu", "Haoji", ""]]}, {"id": "1709.07077", "submitter": "Yihui He", "authors": "Yihui He", "title": "Estimated Depth Map Helps Image Classification", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider image classification with estimated depth. This problem falls\ninto the domain of transfer learning, since we are using a model trained on a\nset of depth images to generate depth maps (additional features) for use in\nanother classification problem using another disjoint set of images. It's\nchallenging as no direct depth information is provided. Though depth estimation\nhas been well studied, none have attempted to aid image classification with\nestimated depth. Therefore, we present a way of transferring domain knowledge\non depth estimation to a separate image classification task over a disjoint set\nof train, and test data. We build a RGBD dataset based on RGB dataset and do\nimage classification on it. Then evaluation the performance of neural networks\non the RGBD dataset compared to the RGB dataset. From our experiments, the\nbenefit is significant with shallow and deep networks. It improves ResNet-20 by\n0.55% and ResNet-56 by 0.53%. Our code and dataset are available publicly.\n", "versions": [{"version": "v1", "created": "Wed, 20 Sep 2017 20:39:47 GMT"}], "update_date": "2017-09-22", "authors_parsed": [["He", "Yihui", ""]]}, {"id": "1709.07089", "submitter": "Alonso Marco", "authors": "Alonso Marco, Philipp Hennig, Stefan Schaal and Sebastian Trimpe", "title": "On the Design of LQR Kernels for Efficient Controller Learning", "comments": "8 pages, 5 figures, to appear in 56th IEEE Conference on Decision and\n  Control (CDC 2017)", "journal-ref": null, "doi": "10.1109/CDC.2017.8264429", "report-no": null, "categories": "cs.SY cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Finding optimal feedback controllers for nonlinear dynamic systems from data\nis hard. Recently, Bayesian optimization (BO) has been proposed as a powerful\nframework for direct controller tuning from experimental trials. For selecting\nthe next query point and finding the global optimum, BO relies on a\nprobabilistic description of the latent objective function, typically a\nGaussian process (GP). As is shown herein, GPs with a common kernel choice can,\nhowever, lead to poor learning outcomes on standard quadratic control problems.\nFor a first-order system, we construct two kernels that specifically leverage\nthe structure of the well-known Linear Quadratic Regulator (LQR), yet retain\nthe flexibility of Bayesian nonparametric learning. Simulations of uncertain\nlinear and nonlinear systems demonstrate that the LQR kernels yield superior\nlearning performance.\n", "versions": [{"version": "v1", "created": "Wed, 20 Sep 2017 21:36:45 GMT"}], "update_date": "2018-02-07", "authors_parsed": [["Marco", "Alonso", ""], ["Hennig", "Philipp", ""], ["Schaal", "Stefan", ""], ["Trimpe", "Sebastian", ""]]}, {"id": "1709.07093", "submitter": "Xingguo Li", "authors": "Jarvis Haupt and Xingguo Li and David P. Woodruff", "title": "Near Optimal Sketching of Low-Rank Tensor Regression", "comments": "36 pages, 2 figures, 2 tables, Accepted at NIPS 2017", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.DS stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the least squares regression problem \\begin{align*} \\min_{\\Theta \\in\n\\mathcal{S}_{\\odot D,R}} \\|A\\Theta-b\\|_2, \\end{align*} where\n$\\mathcal{S}_{\\odot D,R}$ is the set of $\\Theta$ for which $\\Theta =\n\\sum_{r=1}^{R} \\theta_1^{(r)} \\circ \\cdots \\circ \\theta_D^{(r)}$ for vectors\n$\\theta_d^{(r)} \\in \\mathbb{R}^{p_d}$ for all $r \\in [R]$ and $d \\in [D]$, and\n$\\circ$ denotes the outer product of vectors. That is, $\\Theta$ is a\nlow-dimensional, low-rank tensor. This is motivated by the fact that the number\nof parameters in $\\Theta$ is only $R \\cdot \\sum_{d=1}^D p_d$, which is\nsignificantly smaller than the $\\prod_{d=1}^{D} p_d$ number of parameters in\nordinary least squares regression. We consider the above CP decomposition model\nof tensors $\\Theta$, as well as the Tucker decomposition. For both models we\nshow how to apply data dimensionality reduction techniques based on {\\it\nsparse} random projections $\\Phi \\in \\mathbb{R}^{m \\times n}$, with $m \\ll n$,\nto reduce the problem to a much smaller problem $\\min_{\\Theta} \\|\\Phi A \\Theta\n- \\Phi b\\|_2$, for which if $\\Theta'$ is a near-optimum to the smaller problem,\nthen it is also a near optimum to the original problem. We obtain significantly\nsmaller dimension and sparsity in $\\Phi$ than is possible for ordinary least\nsquares regression, and we also provide a number of numerical simulations\nsupporting our theory.\n", "versions": [{"version": "v1", "created": "Wed, 20 Sep 2017 22:05:49 GMT"}], "update_date": "2017-09-22", "authors_parsed": [["Haupt", "Jarvis", ""], ["Li", "Xingguo", ""], ["Woodruff", "David P.", ""]]}, {"id": "1709.07109", "submitter": "Dinghan Shen", "authors": "Dinghan Shen, Yizhe Zhang, Ricardo Henao, Qinliang Su, Lawrence Carin", "title": "Deconvolutional Latent-Variable Model for Text Sequence Matching", "comments": "Accepted by AAAI-2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A latent-variable model is introduced for text matching, inferring sentence\nrepresentations by jointly optimizing generative and discriminative objectives.\nTo alleviate typical optimization challenges in latent-variable models for\ntext, we employ deconvolutional networks as the sequence decoder (generator),\nproviding learned latent codes with more semantic information and better\ngeneralization. Our model, trained in an unsupervised manner, yields stronger\nempirical predictive performance than a decoder based on Long Short-Term Memory\n(LSTM), with less parameters and considerably faster training. Further, we\napply it to text sequence-matching problems. The proposed model significantly\noutperforms several strong sentence-encoding baselines, especially in the\nsemi-supervised setting.\n", "versions": [{"version": "v1", "created": "Thu, 21 Sep 2017 00:23:55 GMT"}, {"version": "v2", "created": "Wed, 27 Sep 2017 01:07:34 GMT"}, {"version": "v3", "created": "Wed, 22 Nov 2017 02:18:24 GMT"}], "update_date": "2017-11-23", "authors_parsed": [["Shen", "Dinghan", ""], ["Zhang", "Yizhe", ""], ["Henao", "Ricardo", ""], ["Su", "Qinliang", ""], ["Carin", "Lawrence", ""]]}, {"id": "1709.07116", "submitter": "J\\\"org Bornschein", "authors": "J\\\"org Bornschein and Andriy Mnih and Daniel Zoran and Danilo J.\n  Rezende", "title": "Variational Memory Addressing in Generative Models", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Aiming to augment generative models with external memory, we interpret the\noutput of a memory module with stochastic addressing as a conditional mixture\ndistribution, where a read operation corresponds to sampling a discrete memory\naddress and retrieving the corresponding content from memory. This perspective\nallows us to apply variational inference to memory addressing, which enables\neffective training of the memory module by using the target information to\nguide memory lookups. Stochastic addressing is particularly well-suited for\ngenerative models as it naturally encourages multimodality which is a prominent\naspect of most high-dimensional datasets. Treating the chosen address as a\nlatent variable also allows us to quantify the amount of information gained\nwith a memory lookup and measure the contribution of the memory module to the\ngenerative process. To illustrate the advantages of this approach we\nincorporate it into a variational autoencoder and apply the resulting model to\nthe task of generative few-shot learning. The intuition behind this\narchitecture is that the memory module can pick a relevant template from memory\nand the continuous part of the model can concentrate on modeling remaining\nvariations. We demonstrate empirically that our model is able to identify and\naccess the relevant memory contents even with hundreds of unseen Omniglot\ncharacters in memory\n", "versions": [{"version": "v1", "created": "Thu, 21 Sep 2017 01:01:59 GMT"}], "update_date": "2017-09-22", "authors_parsed": [["Bornschein", "J\u00f6rg", ""], ["Mnih", "Andriy", ""], ["Zoran", "Daniel", ""], ["Rezende", "Danilo J.", ""]]}, {"id": "1709.07124", "submitter": "Scott Wisdom", "authors": "Scott Wisdom, Thomas Powers, James Pitton, Les Atlas", "title": "Deep Recurrent NMF for Speech Separation by Unfolding Iterative\n  Thresholding", "comments": "To be presented at WASPAA 2017", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SD cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we propose a novel recurrent neural network architecture for\nspeech separation. This architecture is constructed by unfolding the iterations\nof a sequential iterative soft-thresholding algorithm (ISTA) that solves the\noptimization problem for sparse nonnegative matrix factorization (NMF) of\nspectrograms. We name this network architecture deep recurrent NMF (DR-NMF).\nThe proposed DR-NMF network has three distinct advantages. First, DR-NMF\nprovides better interpretability than other deep architectures, since the\nweights correspond to NMF model parameters, even after training. This\ninterpretability also provides principled initializations that enable faster\ntraining and convergence to better solutions compared to conventional random\ninitialization. Second, like many deep networks, DR-NMF is an order of\nmagnitude faster at test time than NMF, since computation of the network output\nonly requires evaluating a few layers at each time step. Third, when a limited\namount of training data is available, DR-NMF exhibits stronger generalization\nand separation performance compared to sparse NMF and state-of-the-art\nlong-short term memory (LSTM) networks. When a large amount of training data is\navailable, DR-NMF achieves lower yet competitive separation performance\ncompared to LSTM networks.\n", "versions": [{"version": "v1", "created": "Thu, 21 Sep 2017 01:46:19 GMT"}], "update_date": "2017-09-22", "authors_parsed": [["Wisdom", "Scott", ""], ["Powers", "Thomas", ""], ["Pitton", "James", ""], ["Atlas", "Les", ""]]}, {"id": "1709.07149", "submitter": "Vidyadhar Upadhya", "authors": "Vidyadhar Upadhya, P. S. Sastry", "title": "Learning RBM with a DC programming Approach", "comments": "Accepted in ACML2017", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  By exploiting the property that the RBM log-likelihood function is the\ndifference of convex functions, we formulate a stochastic variant of the\ndifference of convex functions (DC) programming to minimize the negative\nlog-likelihood. Interestingly, the traditional contrastive divergence algorithm\nis a special case of the above formulation and the hyperparameters of the two\nalgorithms can be chosen such that the amount of computation per mini-batch is\nidentical. We show that for a given computational budget the proposed algorithm\nalmost always reaches a higher log-likelihood more rapidly, compared to the\nstandard contrastive divergence algorithm. Further, we modify this algorithm to\nuse the centered gradients and show that it is more efficient and effective\ncompared to the standard centered gradient algorithm on benchmark datasets.\n", "versions": [{"version": "v1", "created": "Thu, 21 Sep 2017 03:51:16 GMT"}, {"version": "v2", "created": "Thu, 5 Oct 2017 10:26:53 GMT"}], "update_date": "2017-10-06", "authors_parsed": [["Upadhya", "Vidyadhar", ""], ["Sastry", "P. S.", ""]]}, {"id": "1709.07150", "submitter": "Udayan Khurana", "authors": "Udayan Khurana and Horst Samulowitz and Deepak Turaga", "title": "Feature Engineering for Predictive Modeling using Reinforcement Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Feature engineering is a crucial step in the process of predictive modeling.\nIt involves the transformation of given feature space, typically using\nmathematical functions, with the objective of reducing the modeling error for a\ngiven target. However, there is no well-defined basis for performing effective\nfeature engineering. It involves domain knowledge, intuition, and most of all,\na lengthy process of trial and error. The human attention involved in\noverseeing this process significantly influences the cost of model generation.\nWe present a new framework to automate feature engineering. It is based on\nperformance driven exploration of a transformation graph, which systematically\nand compactly enumerates the space of given options. A highly efficient\nexploration strategy is derived through reinforcement learning on past\nexamples.\n", "versions": [{"version": "v1", "created": "Thu, 21 Sep 2017 04:04:43 GMT"}], "update_date": "2017-09-22", "authors_parsed": [["Khurana", "Udayan", ""], ["Samulowitz", "Horst", ""], ["Turaga", "Deepak", ""]]}, {"id": "1709.07172", "submitter": "Tong Yu", "authors": "Tong Yu, Branislav Kveton, Zheng Wen, Hung Bui, Ole J. Mengshoel", "title": "SpectralLeader: Online Spectral Learning for Single Topic Models", "comments": "17 pages, 2 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the problem of learning a latent variable model from a stream of\ndata. Latent variable models are popular in practice because they can explain\nobserved data in terms of unobserved concepts. These models have been\ntraditionally studied in the offline setting. In the online setting, on the\nother hand, the online EM is arguably the most popular algorithm for learning\nlatent variable models. Although the online EM is computationally efficient, it\ntypically converges to a local optimum. In this work, we develop a new online\nlearning algorithm for latent variable models, which we call SpectralLeader.\nSpectralLeader always converges to the global optimum, and we derive a\nsublinear upper bound on its $n$-step regret in the bag-of-words model. In both\nsynthetic and real-world experiments, we show that SpectralLeader performs\nsimilarly to or better than the online EM with tuned hyper-parameters.\n", "versions": [{"version": "v1", "created": "Thu, 21 Sep 2017 06:24:51 GMT"}, {"version": "v2", "created": "Sat, 10 Feb 2018 05:51:34 GMT"}, {"version": "v3", "created": "Fri, 16 Feb 2018 20:01:42 GMT"}, {"version": "v4", "created": "Thu, 26 Apr 2018 02:39:04 GMT"}], "update_date": "2018-04-27", "authors_parsed": [["Yu", "Tong", ""], ["Kveton", "Branislav", ""], ["Wen", "Zheng", ""], ["Bui", "Hung", ""], ["Mengshoel", "Ole J.", ""]]}, {"id": "1709.07200", "submitter": "Valentin Vielzeuf", "authors": "Valentin Vielzeuf, St\\'ephane Pateux, Fr\\'ed\\'eric Jurie", "title": "Temporal Multimodal Fusion for Video Emotion Classification in the Wild", "comments": null, "journal-ref": "ACM - ICMI 2017, Nov 2017, Glasgow, United Kingdom", "doi": null, "report-no": null, "categories": "cs.CV cs.LG cs.MM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper addresses the question of emotion classification. The task\nconsists in predicting emotion labels (taken among a set of possible labels)\nbest describing the emotions contained in short video clips. Building on a\nstandard framework -- lying in describing videos by audio and visual features\nused by a supervised classifier to infer the labels -- this paper investigates\nseveral novel directions. First of all, improved face descriptors based on 2D\nand 3D Convo-lutional Neural Networks are proposed. Second, the paper explores\nseveral fusion methods, temporal and multimodal, including a novel hierarchical\nmethod combining features and scores. In addition, we carefully reviewed the\ndifferent stages of the pipeline and designed a CNN architecture adapted to the\ntask; this is important as the size of the training set is small compared to\nthe difficulty of the problem, making generalization difficult. The so-obtained\nmodel ranked 4th at the 2017 Emotion in the Wild challenge with the accuracy of\n58.8 %.\n", "versions": [{"version": "v1", "created": "Thu, 21 Sep 2017 08:14:40 GMT"}], "update_date": "2017-09-22", "authors_parsed": [["Vielzeuf", "Valentin", ""], ["Pateux", "St\u00e9phane", ""], ["Jurie", "Fr\u00e9d\u00e9ric", ""]]}, {"id": "1709.07223", "submitter": "Roarke Horstmeyer", "authors": "Roarke Horstmeyer, Richard Y. Chen, Barbara Kappes and Benjamin\n  Judkewitz", "title": "Convolutional neural networks that teach microscopes how to image", "comments": "13 pages, 6 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.LG physics.optics", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep learning algorithms offer a powerful means to automatically analyze the\ncontent of medical images. However, many biological samples of interest are\nprimarily transparent to visible light and contain features that are difficult\nto resolve with a standard optical microscope. Here, we use a convolutional\nneural network (CNN) not only to classify images, but also to optimize the\nphysical layout of the imaging device itself. We increase the classification\naccuracy of a microscope's recorded images by merging an optical model of image\nformation into the pipeline of a CNN. The resulting network simultaneously\ndetermines an ideal illumination arrangement to highlight important sample\nfeatures during image acquisition, along with a set of convolutional weights to\nclassify the detected images post-capture. We demonstrate our joint\noptimization technique with an experimental microscope configuration that\nautomatically identifies malaria-infected cells with 5-10% higher accuracy than\nstandard and alternative microscope lighting designs.\n", "versions": [{"version": "v1", "created": "Thu, 21 Sep 2017 09:17:47 GMT"}], "update_date": "2017-09-22", "authors_parsed": [["Horstmeyer", "Roarke", ""], ["Chen", "Richard Y.", ""], ["Kappes", "Barbara", ""], ["Judkewitz", "Benjamin", ""]]}, {"id": "1709.07224", "submitter": "Maximilian H\\\"uttenrauch", "authors": "Maximilian H\\\"uttenrauch and Adrian \\v{S}o\\v{s}i\\'c and Gerhard\n  Neumann", "title": "Local Communication Protocols for Learning Complex Swarm Behaviors with\n  Deep Reinforcement Learning", "comments": "13 pages, 4 figures, version 2, accepted at ANTS 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.MA cs.AI cs.LG cs.SY stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Swarm systems constitute a challenging problem for reinforcement learning\n(RL) as the algorithm needs to learn decentralized control policies that can\ncope with limited local sensing and communication abilities of the agents.\nWhile it is often difficult to directly define the behavior of the agents,\nsimple communication protocols can be defined more easily using prior knowledge\nabout the given task. In this paper, we propose a number of simple\ncommunication protocols that can be exploited by deep reinforcement learning to\nfind decentralized control policies in a multi-robot swarm environment. The\nprotocols are based on histograms that encode the local neighborhood relations\nof the agents and can also transmit task-specific information, such as the\nshortest distance and direction to a desired target. In our framework, we use\nan adaptation of Trust Region Policy Optimization to learn complex\ncollaborative tasks, such as formation building and building a communication\nlink. We evaluate our findings in a simulated 2D-physics environment, and\ncompare the implications of different communication protocols.\n", "versions": [{"version": "v1", "created": "Thu, 21 Sep 2017 09:18:09 GMT"}, {"version": "v2", "created": "Wed, 18 Jul 2018 08:39:08 GMT"}], "update_date": "2018-07-19", "authors_parsed": [["H\u00fcttenrauch", "Maximilian", ""], ["\u0160o\u0161i\u0107", "Adrian", ""], ["Neumann", "Gerhard", ""]]}, {"id": "1709.07308", "submitter": "Charalampos Tsourakakis", "authors": "Charalampos E. Tsourakakis, Michael Mitzenmacher, Kasper Green Larsen,\n  Jaros{\\l}aw B{\\l}asiok, Ben Lawson, Preetum Nakkiran, Vasileios Nakos", "title": "Predicting Positive and Negative Links with Noisy Queries: Theory &\n  Practice", "comments": "arXiv admin note: text overlap with arXiv:1609.00750", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.DM cs.LG cs.SI math.CO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Social networks involve both positive and negative relationships, which can\nbe captured in signed graphs. The {\\em edge sign prediction problem} aims to\npredict whether an interaction between a pair of nodes will be positive or\nnegative. We provide theoretical results for this problem that motivate natural\nimprovements to recent heuristics.\n  The edge sign prediction problem is related to correlation clustering; a\npositive relationship means being in the same cluster. We consider the\nfollowing model for two clusters: we are allowed to query any pair of nodes\nwhether they belong to the same cluster or not, but the answer to the query is\ncorrupted with some probability $0<q<\\frac{1}{2}$. Let $\\delta=1-2q$ be the\nbias. We provide an algorithm that recovers all signs correctly with high\nprobability in the presence of noise with $O(\\frac{n\\log\nn}{\\delta^2}+\\frac{\\log^2 n}{\\delta^6})$ queries. This is the best known result\nfor this problem for all but tiny $\\delta$, improving on the recent work of\nMazumdar and Saha \\cite{mazumdar2017clustering}. We also provide an algorithm\nthat performs $O(\\frac{n\\log n}{\\delta^4})$ queries, and uses breadth first\nsearch as its main algorithmic primitive. While both the running time and the\nnumber of queries for this algorithm are sub-optimal, our result relies on\nnovel theoretical techniques, and naturally suggests the use of edge-disjoint\npaths as a feature for predicting signs in online social networks.\nCorrespondingly, we experiment with using edge disjoint $s-t$ paths of short\nlength as a feature for predicting the sign of edge $(s,t)$ in real-world\nsigned networks. Empirical findings suggest that the use of such paths improves\nthe classification accuracy, especially for pairs of nodes with no common\nneighbors.\n", "versions": [{"version": "v1", "created": "Tue, 19 Sep 2017 20:38:10 GMT"}, {"version": "v2", "created": "Tue, 7 Aug 2018 21:28:34 GMT"}, {"version": "v3", "created": "Sun, 6 Dec 2020 21:54:16 GMT"}], "update_date": "2020-12-08", "authors_parsed": [["Tsourakakis", "Charalampos E.", ""], ["Mitzenmacher", "Michael", ""], ["Larsen", "Kasper Green", ""], ["B\u0142asiok", "Jaros\u0142aw", ""], ["Lawson", "Ben", ""], ["Nakkiran", "Preetum", ""], ["Nakos", "Vasileios", ""]]}, {"id": "1709.07314", "submitter": "Ana Ozaki", "authors": "Boris Konev, Carsten Lutz, Ana Ozaki and Frank Wolter", "title": "Exact Learning of Lightweight Description Logic Ontologies", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the problem of learning description logic (DL) ontologies in Angluin\net al.'s framework of exact learning via queries. We admit membership queries\n(\"is a given subsumption entailed by the target ontology?\") and equivalence\nqueries (\"is a given ontology equivalent to the target ontology?\"). We present\nthree main results: (1) ontologies formulated in (two relevant versions of) the\ndescription logic DL-Lite can be learned with polynomially many queries of\npolynomial size; (2) this is not the case for ontologies formulated in the\ndescription logic EL, even when only acyclic ontologies are admitted; and (3)\nontologies formulated in a fragment of EL related to the web ontology language\nOWL 2 RL can be learned in polynomial time. We also show that neither\nmembership nor equivalence queries alone are sufficient in cases (1) and (3).\n", "versions": [{"version": "v1", "created": "Wed, 20 Sep 2017 10:25:25 GMT"}], "update_date": "2017-09-22", "authors_parsed": [["Konev", "Boris", ""], ["Lutz", "Carsten", ""], ["Ozaki", "Ana", ""], ["Wolter", "Frank", ""]]}, {"id": "1709.07359", "submitter": "Lucas C. Uzal", "authors": "Guillermo L. Grinblat, Lucas C. Uzal and Pablo M. Granitto", "title": "Class-Splitting Generative Adversarial Networks", "comments": "Under consideration at Pattern Recognition Letters", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Generative Adversarial Networks (GANs) produce systematically better quality\nsamples when class label information is provided., i.e. in the conditional GAN\nsetup. This is still observed for the recently proposed Wasserstein GAN\nformulation which stabilized adversarial training and allows considering high\ncapacity network architectures such as ResNet. In this work we show how to\nboost conditional GAN by augmenting available class labels. The new classes\ncome from clustering in the representation space learned by the same GAN model.\nThe proposed strategy is also feasible when no class information is available,\ni.e. in the unsupervised setup. Our generated samples reach state-of-the-art\nInception scores for CIFAR-10 and STL-10 datasets in both supervised and\nunsupervised setup.\n", "versions": [{"version": "v1", "created": "Thu, 21 Sep 2017 14:55:54 GMT"}, {"version": "v2", "created": "Thu, 17 May 2018 14:07:35 GMT"}], "update_date": "2018-05-18", "authors_parsed": [["Grinblat", "Guillermo L.", ""], ["Uzal", "Lucas C.", ""], ["Granitto", "Pablo M.", ""]]}, {"id": "1709.07377", "submitter": "Fernando Bacao", "authors": "Georgios Douzas and Fernando Bacao", "title": "Geometric SMOTE: Effective oversampling for imbalanced learning through\n  a geometric extension of SMOTE", "comments": "22 pages, 15 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Classification of imbalanced datasets is a challenging task for standard\nalgorithms. Although many methods exist to address this problem in different\nways, generating artificial data for the minority class is a more general\napproach compared to algorithmic modifications. SMOTE algorithm and its\nvariations generate synthetic samples along a line segment that joins minority\nclass instances. In this paper we propose Geometric SMOTE (G-SMOTE) as a\ngeneralization of the SMOTE data generation mechanism. G-SMOTE generates\nsynthetic samples in a geometric region of the input space, around each\nselected minority instance. While in the basic configuration this region is a\nhyper-sphere, G-SMOTE allows its deformation to a hyper-spheroid and finally to\na line segment, emulating, in the last case, the SMOTE mechanism. The\nperformance of G-SMOTE is compared against multiple standard oversampling\nalgorithms. We present empirical results that show a significant improvement in\nthe quality of the generated data when G-SMOTE is used as an oversampling\nalgorithm.\n", "versions": [{"version": "v1", "created": "Thu, 21 Sep 2017 15:33:33 GMT"}], "update_date": "2017-09-22", "authors_parsed": [["Douzas", "Georgios", ""], ["Bacao", "Fernando", ""]]}, {"id": "1709.07409", "submitter": "Lucas Lamata", "authors": "L. Lamata, U. Alvarez-Rodriguez, J. D. Mart\\'in-Guerrero, M. Sanz, E.\n  Solano", "title": "Quantum autoencoders via quantum adders with genetic algorithms", "comments": null, "journal-ref": "Quantum Sci. Technol. 4 (2019) 014007", "doi": "10.1088/2058-9565/aae22b", "report-no": null, "categories": "quant-ph cs.LG cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The quantum autoencoder is a recent paradigm in the field of quantum machine\nlearning, which may enable an enhanced use of resources in quantum\ntechnologies. To this end, quantum neural networks with less nodes in the inner\nthan in the outer layers were considered. Here, we propose a useful connection\nbetween approximate quantum adders and quantum autoencoders. Specifically, this\nlink allows us to employ optimized approximate quantum adders, obtained with\ngenetic algorithms, for the implementation of quantum autoencoders for a\nvariety of initial states. Furthermore, we can also directly optimize the\nquantum autoencoders via genetic algorithms. Our approach opens a different\npath for the design of quantum autoencoders in controllable quantum platforms.\n", "versions": [{"version": "v1", "created": "Thu, 21 Sep 2017 16:52:00 GMT"}, {"version": "v2", "created": "Wed, 17 Oct 2018 09:25:40 GMT"}], "update_date": "2018-10-18", "authors_parsed": [["Lamata", "L.", ""], ["Alvarez-Rodriguez", "U.", ""], ["Mart\u00edn-Guerrero", "J. D.", ""], ["Sanz", "M.", ""], ["Solano", "E.", ""]]}, {"id": "1709.07417", "submitter": "Irwan Bello", "authors": "Irwan Bello, Barret Zoph, Vijay Vasudevan, Quoc V. Le", "title": "Neural Optimizer Search with Reinforcement Learning", "comments": "ICML 2017 Conference paper", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present an approach to automate the process of discovering optimization\nmethods, with a focus on deep learning architectures. We train a Recurrent\nNeural Network controller to generate a string in a domain specific language\nthat describes a mathematical update equation based on a list of primitive\nfunctions, such as the gradient, running average of the gradient, etc. The\ncontroller is trained with Reinforcement Learning to maximize the performance\nof a model after a few epochs. On CIFAR-10, our method discovers several update\nrules that are better than many commonly used optimizers, such as Adam,\nRMSProp, or SGD with and without Momentum on a ConvNet model. We introduce two\nnew optimizers, named PowerSign and AddSign, which we show transfer well and\nimprove training on a variety of different tasks and architectures, including\nImageNet classification and Google's neural machine translation system.\n", "versions": [{"version": "v1", "created": "Thu, 21 Sep 2017 17:01:47 GMT"}, {"version": "v2", "created": "Fri, 22 Sep 2017 15:27:27 GMT"}], "update_date": "2017-09-25", "authors_parsed": [["Bello", "Irwan", ""], ["Zoph", "Barret", ""], ["Vasudevan", "Vijay", ""], ["Le", "Quoc V.", ""]]}, {"id": "1709.07433", "submitter": "Robert Bamler", "authors": "Robert Bamler, Cheng Zhang, Manfred Opper, Stephan Mandt", "title": "Perturbative Black Box Variational Inference", "comments": "In the proceedings of Advances in Neural Information Processing\n  Systems (NIPS 2017)", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Black box variational inference (BBVI) with reparameterization gradients\ntriggered the exploration of divergence measures other than the\nKullback-Leibler (KL) divergence, such as alpha divergences. In this paper, we\nview BBVI with generalized divergences as a form of estimating the marginal\nlikelihood via biased importance sampling. The choice of divergence determines\na bias-variance trade-off between the tightness of a bound on the marginal\nlikelihood (low bias) and the variance of its gradient estimators. Drawing on\nvariational perturbation theory of statistical physics, we use these insights\nto construct a family of new variational bounds. Enumerated by an odd integer\norder $K$, this family captures the standard KL bound for $K=1$, and converges\nto the exact marginal likelihood as $K\\to\\infty$. Compared to\nalpha-divergences, our reparameterization gradients have a lower variance. We\nshow in experiments on Gaussian Processes and Variational Autoencoders that the\nnew bounds are more mass covering, and that the resulting posterior covariances\nare closer to the true posterior and lead to higher likelihoods on held-out\ndata.\n", "versions": [{"version": "v1", "created": "Thu, 21 Sep 2017 17:50:10 GMT"}, {"version": "v2", "created": "Sat, 6 Jan 2018 22:22:31 GMT"}], "update_date": "2018-01-09", "authors_parsed": [["Bamler", "Robert", ""], ["Zhang", "Cheng", ""], ["Opper", "Manfred", ""], ["Mandt", "Stephan", ""]]}, {"id": "1709.07534", "submitter": "Arijit Biswas", "authors": "Arijit Biswas, Mukul Bhutani and Subhajit Sanyal", "title": "MRNet-Product2Vec: A Multi-task Recurrent Neural Network for Product\n  Embeddings", "comments": "Published in ECML-PKDD 2017 (Applied Data Science Track)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  E-commerce websites such as Amazon, Alibaba, Flipkart, and Walmart sell\nbillions of products. Machine learning (ML) algorithms involving products are\noften used to improve the customer experience and increase revenue, e.g.,\nproduct similarity, recommendation, and price estimation. The products are\nrequired to be represented as features before training an ML algorithm. In this\npaper, we propose an approach called MRNet-Product2Vec for creating generic\nembeddings of products within an e-commerce ecosystem. We learn a dense and\nlow-dimensional embedding where a diverse set of signals related to a product\nare explicitly injected into its representation. We train a Discriminative\nMulti-task Bidirectional Recurrent Neural Network (RNN), where the input is a\nproduct title fed through a Bidirectional RNN and at the output, product labels\ncorresponding to fifteen different tasks are predicted. The task set includes\nseveral intrinsic characteristics about a product such as price, weight, size,\ncolor, popularity, and material. We evaluate the proposed embedding\nquantitatively and qualitatively. We demonstrate that they are almost as good\nas sparse and extremely high-dimensional TF-IDF representation in spite of\nhaving less than 3% of the TF-IDF dimension. We also use a multimodal\nautoencoder for comparing products from different language-regions and show\npreliminary yet promising qualitative results.\n", "versions": [{"version": "v1", "created": "Thu, 21 Sep 2017 22:38:51 GMT"}], "update_date": "2017-09-25", "authors_parsed": [["Biswas", "Arijit", ""], ["Bhutani", "Mukul", ""], ["Sanyal", "Subhajit", ""]]}, {"id": "1709.07545", "submitter": "Tian Wang", "authors": "Tian Wang, Kyunghyun Cho", "title": "Attention-based Mixture Density Recurrent Networks for History-based\n  Recommendation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.IR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The goal of personalized history-based recommendation is to automatically\noutput a distribution over all the items given a sequence of previous purchases\nof a user. In this work, we present a novel approach that uses a recurrent\nnetwork for summarizing the history of purchases, continuous vectors\nrepresenting items for scalability, and a novel attention-based recurrent\nmixture density network, which outputs each component in a mixture\nsequentially, for modelling a multi-modal conditional distribution. We evaluate\nthe proposed approach on two publicly available datasets, MovieLens-20M and\nRecSys15. The experiments show that the proposed approach, which explicitly\nmodels the multi-modal nature of the predictive distribution, is able to\nimprove the performance over various baselines in terms of precision, recall\nand nDCG.\n", "versions": [{"version": "v1", "created": "Fri, 22 Sep 2017 00:16:35 GMT"}], "update_date": "2017-09-25", "authors_parsed": [["Wang", "Tian", ""], ["Cho", "Kyunghyun", ""]]}, {"id": "1709.07615", "submitter": "Katharina Eggensperger", "authors": "Katharina Eggensperger, Marius Lindauer and Frank Hutter", "title": "Neural Networks for Predicting Algorithm Runtime Distributions", "comments": null, "journal-ref": "International Joint Conference on Artificial Intelligence (2018),\n  1442--1448", "doi": "10.24963/ijcai.2018/200", "report-no": null, "categories": "cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Many state-of-the-art algorithms for solving hard combinatorial problems in\nartificial intelligence (AI) include elements of stochasticity that lead to\nhigh variations in runtime, even for a fixed problem instance. Knowledge about\nthe resulting runtime distributions (RTDs) of algorithms on given problem\ninstances can be exploited in various meta-algorithmic procedures, such as\nalgorithm selection, portfolios, and randomized restarts. Previous work has\nshown that machine learning can be used to individually predict mean, median\nand variance of RTDs. To establish a new state-of-the-art in predicting RTDs,\nwe demonstrate that the parameters of an RTD should be learned jointly and that\nneural networks can do this well by directly optimizing the likelihood of an\nRTD given runtime observations. In an empirical study involving five algorithms\nfor SAT solving and AI planning, we show that neural networks predict the true\nRTDs of unseen instances better than previous methods, and can even do so when\nonly few runtime observations are available per training instance.\n", "versions": [{"version": "v1", "created": "Fri, 22 Sep 2017 07:25:13 GMT"}, {"version": "v2", "created": "Tue, 24 Oct 2017 07:09:21 GMT"}, {"version": "v3", "created": "Wed, 9 May 2018 07:42:29 GMT"}], "update_date": "2018-07-10", "authors_parsed": [["Eggensperger", "Katharina", ""], ["Lindauer", "Marius", ""], ["Hutter", "Frank", ""]]}, {"id": "1709.07625", "submitter": "Daohong Xiang", "authors": "Andreas Christmann and Daohong Xiang and Ding-Xuan Zhou", "title": "Total stability of kernel methods", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Regularized empirical risk minimization using kernels and their corresponding\nreproducing kernel Hilbert spaces (RKHSs) plays an important role in machine\nlearning. However, the actually used kernel often depends on one or on a few\nhyperparameters or the kernel is even data dependent in a much more complicated\nmanner. Examples are Gaussian RBF kernels, kernel learning, and hierarchical\nGaussian kernels which were recently proposed for deep learning. Therefore, the\nactually used kernel is often computed by a grid search or in an iterative\nmanner and can often only be considered as an approximation to the \"ideal\" or\n\"optimal\" kernel. The paper gives conditions under which classical kernel based\nmethods based on a convex Lipschitz loss function and on a bounded and smooth\nkernel are stable, if the probability measure $P$, the regularization parameter\n$\\lambda$, and the kernel $k$ may slightly change in a simultaneous manner.\nSimilar results are also given for pairwise learning. Therefore, the topic of\nthis paper is somewhat more general than in classical robust statistics, where\nusually only the influence of small perturbations of the probability measure\n$P$ on the estimated function is considered.\n", "versions": [{"version": "v1", "created": "Fri, 22 Sep 2017 07:58:45 GMT"}], "update_date": "2017-09-25", "authors_parsed": [["Christmann", "Andreas", ""], ["Xiang", "Daohong", ""], ["Zhou", "Ding-Xuan", ""]]}, {"id": "1709.07626", "submitter": "Jagmohan Chauhan", "authors": "Jagmohan Chauhan, Suranga Seneviratne, Yining Hu, Archan Misra, Aruna\n  Seneviratne, Youngki Lee", "title": "BreathRNNet: Breathing Based Authentication on Resource-Constrained IoT\n  Devices using RNNs", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.LG cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recurrent neural networks (RNNs) have shown promising results in audio and\nspeech processing applications due to their strong capabilities in modelling\nsequential data. In many applications, RNNs tend to outperform conventional\nmodels based on GMM/UBMs and i-vectors. Increasing popularity of IoT devices\nmakes a strong case for implementing RNN based inferences for applications such\nas acoustics based authentication, voice commands, and edge analytics for smart\nhomes. Nonetheless, the feasibility and performance of RNN based inferences on\nresources-constrained IoT devices remain largely unexplored. In this paper, we\ninvestigate the feasibility of using RNNs for an end-to-end authentication\nsystem based on breathing acoustics. We evaluate the performance of RNN models\non three types of devices; smartphone, smartwatch, and Raspberry Pi and show\nthat unlike CNN models, RNN models can be easily ported onto\nresource-constrained devices without a significant loss in accuracy.\n", "versions": [{"version": "v1", "created": "Fri, 22 Sep 2017 08:06:38 GMT"}], "update_date": "2017-09-25", "authors_parsed": [["Chauhan", "Jagmohan", ""], ["Seneviratne", "Suranga", ""], ["Hu", "Yining", ""], ["Misra", "Archan", ""], ["Seneviratne", "Aruna", ""], ["Lee", "Youngki", ""]]}, {"id": "1709.07638", "submitter": "Syama Sundar Rangapuram", "authors": "Matthias Seeger, Syama Rangapuram, Yuyang Wang, David Salinas, Jan\n  Gasthaus, Tim Januschowski, Valentin Flunkert", "title": "Approximate Bayesian Inference in Linear State Space Models for\n  Intermittent Demand Forecasting at Scale", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a scalable and robust Bayesian inference method for linear state\nspace models. The method is applied to demand forecasting in the context of a\nlarge e-commerce platform, paying special attention to intermittent and bursty\ntarget statistics. Inference is approximated by the Newton-Raphson algorithm,\nreduced to linear-time Kalman smoothing, which allows us to operate on several\norders of magnitude larger problems than previous related work. In a study on\nlarge real-world sales datasets, our method outperforms competing approaches on\nfast and medium moving items.\n", "versions": [{"version": "v1", "created": "Fri, 22 Sep 2017 08:53:54 GMT"}], "update_date": "2017-09-25", "authors_parsed": [["Seeger", "Matthias", ""], ["Rangapuram", "Syama", ""], ["Wang", "Yuyang", ""], ["Salinas", "David", ""], ["Gasthaus", "Jan", ""], ["Januschowski", "Tim", ""], ["Flunkert", "Valentin", ""]]}, {"id": "1709.07772", "submitter": "Liang Wang", "authors": "Liang Wang, Ben Catterall and Richard Mortier", "title": "Probabilistic Synchronous Parallel", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Most machine learning and deep neural network algorithms rely on certain\niterative algorithms to optimise their utility/cost functions, e.g. Stochastic\nGradient Descent. In distributed learning, the networked nodes have to work\ncollaboratively to update the model parameters, and the way how they proceed is\nreferred to as synchronous parallel design (or barrier control). Synchronous\nparallel protocol is the building block of any distributed learning framework,\nand its design has direct impact on the performance and scalability of the\nsystem.\n  In this paper, we propose a new barrier control technique - Probabilistic\nSynchronous Parallel (PSP). Com- paring to the previous Bulk Synchronous\nParallel (BSP), Stale Synchronous Parallel (SSP), and (Asynchronous Parallel)\nASP, the proposed solution e ectively improves both the convergence speed and\nthe scalability of the SGD algorithm by introducing a sampling primitive into\nthe system. Moreover, we also show that the sampling primitive can be applied\natop of the existing barrier control mechanisms to derive fully distributed\nPSP-based synchronous parallel.\n  We not only provide a thorough theoretical analysis1 on the convergence of\nPSP-based SGD algorithm, but also implement a full-featured distributed\nlearning framework called Actor and perform intensive evaluation atop of it.\n", "versions": [{"version": "v1", "created": "Fri, 22 Sep 2017 14:22:39 GMT"}, {"version": "v2", "created": "Thu, 5 Oct 2017 15:40:22 GMT"}], "update_date": "2017-10-06", "authors_parsed": [["Wang", "Liang", ""], ["Catterall", "Ben", ""], ["Mortier", "Richard", ""]]}, {"id": "1709.07776", "submitter": "Zhourui Song", "authors": "Zhourui Song, Zhenyu Liu and Dongsheng Wang", "title": "Computation Error Analysis of Block Floating Point Arithmetic Oriented\n  Convolution Neural Network Accelerator Design", "comments": "Accepted by AAAI-2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The heavy burdens of computation and off-chip traffic impede deploying the\nlarge scale convolution neural network on embedded platforms. As CNN is\nattributed to the strong endurance to computation errors, employing block\nfloating point (BFP) arithmetics in CNN accelerators could save the hardware\ncost and data traffics efficiently, while maintaining the classification\naccuracy. In this paper, we verify the effects of word width definitions in BFP\nto the CNN performance without retraining. Several typical CNN models,\nincluding VGG16, ResNet-18, ResNet-50 and GoogLeNet, were tested in this paper.\nExperiments revealed that 8-bit mantissa, including sign bit, in BFP\nrepresentation merely induced less than 0.3% accuracy loss. In addition, we\ninvestigate the computational errors in theory and develop the noise-to-signal\nratio (NSR) upper bound, which provides the promising guidance for BFP based\nCNN engine design.\n", "versions": [{"version": "v1", "created": "Fri, 22 Sep 2017 14:28:39 GMT"}, {"version": "v2", "created": "Fri, 24 Nov 2017 07:22:14 GMT"}], "update_date": "2017-11-27", "authors_parsed": [["Song", "Zhourui", ""], ["Liu", "Zhenyu", ""], ["Wang", "Dongsheng", ""]]}, {"id": "1709.07796", "submitter": "Vincent Francois-Lavet", "authors": "Vincent Francois-Lavet, Guillaume Rabusseau, Joelle Pineau, Damien\n  Ernst, Raphael Fonteneau", "title": "On overfitting and asymptotic bias in batch reinforcement learning with\n  partial observability", "comments": "Accepted at the Journal of Artificial Intelligence Research (JAIR) -\n  31 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper provides an analysis of the tradeoff between asymptotic bias\n(suboptimality with unlimited data) and overfitting (additional suboptimality\ndue to limited data) in the context of reinforcement learning with partial\nobservability. Our theoretical analysis formally characterizes that while\npotentially increasing the asymptotic bias, a smaller state representation\ndecreases the risk of overfitting. This analysis relies on expressing the\nquality of a state representation by bounding L1 error terms of the associated\nbelief states. Theoretical results are empirically illustrated when the state\nrepresentation is a truncated history of observations, both on synthetic POMDPs\nand on a large-scale POMDP in the context of smartgrids, with real-world data.\nFinally, similarly to known results in the fully observable setting, we also\nbriefly discuss and empirically illustrate how using function approximators and\nadapting the discount factor may enhance the tradeoff between asymptotic bias\nand overfitting in the partially observable context.\n", "versions": [{"version": "v1", "created": "Fri, 22 Sep 2017 14:56:35 GMT"}, {"version": "v2", "created": "Wed, 6 Feb 2019 18:30:04 GMT"}], "update_date": "2019-02-07", "authors_parsed": [["Francois-Lavet", "Vincent", ""], ["Rabusseau", "Guillaume", ""], ["Pineau", "Joelle", ""], ["Ernst", "Damien", ""], ["Fonteneau", "Raphael", ""]]}, {"id": "1709.07814", "submitter": "Andros Tjandra", "authors": "Andros Tjandra, Sakriani Sakti, Satoshi Nakamura", "title": "Attention-based Wav2Text with Feature Transfer Learning", "comments": "Accepted at ASRU 2017", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG cs.SD", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Conventional automatic speech recognition (ASR) typically performs\nmulti-level pattern recognition tasks that map the acoustic speech waveform\ninto a hierarchy of speech units. But, it is widely known that information loss\nin the earlier stage can propagate through the later stages. After the\nresurgence of deep learning, interest has emerged in the possibility of\ndeveloping a purely end-to-end ASR system from the raw waveform to the\ntranscription without any predefined alignments and hand-engineered models.\nHowever, the successful attempts in end-to-end architecture still used\nspectral-based features, while the successful attempts in using raw waveform\nwere still based on the hybrid deep neural network - Hidden Markov model\n(DNN-HMM) framework. In this paper, we construct the first end-to-end\nattention-based encoder-decoder model to process directly from raw speech\nwaveform to the text transcription. We called the model as \"Attention-based\nWav2Text\". To assist the training process of the end-to-end model, we propose\nto utilize a feature transfer learning. Experimental results also reveal that\nthe proposed Attention-based Wav2Text model directly with raw waveform could\nachieve a better result in comparison with the attentional encoder-decoder\nmodel trained on standard front-end filterbank features.\n", "versions": [{"version": "v1", "created": "Fri, 22 Sep 2017 15:38:09 GMT"}], "update_date": "2017-09-25", "authors_parsed": [["Tjandra", "Andros", ""], ["Sakti", "Sakriani", ""], ["Nakamura", "Satoshi", ""]]}, {"id": "1709.07857", "submitter": "Alexander Irpan", "authors": "Konstantinos Bousmalis, Alex Irpan, Paul Wohlhart, Yunfei Bai, Matthew\n  Kelcey, Mrinal Kalakrishnan, Laura Downs, Julian Ibarz, Peter Pastor, Kurt\n  Konolige, Sergey Levine, Vincent Vanhoucke", "title": "Using Simulation and Domain Adaptation to Improve Efficiency of Deep\n  Robotic Grasping", "comments": "9 pages, 5 figures, 3 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CV cs.RO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Instrumenting and collecting annotated visual grasping datasets to train\nmodern machine learning algorithms can be extremely time-consuming and\nexpensive. An appealing alternative is to use off-the-shelf simulators to\nrender synthetic data for which ground-truth annotations are generated\nautomatically. Unfortunately, models trained purely on simulated data often\nfail to generalize to the real world. We study how randomized simulated\nenvironments and domain adaptation methods can be extended to train a grasping\nsystem to grasp novel objects from raw monocular RGB images. We extensively\nevaluate our approaches with a total of more than 25,000 physical test grasps,\nstudying a range of simulation conditions and domain adaptation methods,\nincluding a novel extension of pixel-level domain adaptation that we term the\nGraspGAN. We show that, by using synthetic data and domain adaptation, we are\nable to reduce the number of real-world samples needed to achieve a given level\nof performance by up to 50 times, using only randomly generated simulated\nobjects. We also show that by using only unlabeled real-world data and our\nGraspGAN methodology, we obtain real-world grasping performance without any\nreal-world labels that is similar to that achieved with 939,777 labeled\nreal-world samples.\n", "versions": [{"version": "v1", "created": "Fri, 22 Sep 2017 17:23:12 GMT"}, {"version": "v2", "created": "Mon, 25 Sep 2017 21:35:45 GMT"}], "update_date": "2017-09-27", "authors_parsed": [["Bousmalis", "Konstantinos", ""], ["Irpan", "Alex", ""], ["Wohlhart", "Paul", ""], ["Bai", "Yunfei", ""], ["Kelcey", "Matthew", ""], ["Kalakrishnan", "Mrinal", ""], ["Downs", "Laura", ""], ["Ibarz", "Julian", ""], ["Pastor", "Peter", ""], ["Konolige", "Kurt", ""], ["Levine", "Sergey", ""], ["Vanhoucke", "Vincent", ""]]}, {"id": "1709.07886", "submitter": "Congzheng Song", "authors": "Congzheng Song, Thomas Ristenpart, Vitaly Shmatikov", "title": "Machine Learning Models that Remember Too Much", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Machine learning (ML) is becoming a commodity. Numerous ML frameworks and\nservices are available to data holders who are not ML experts but want to train\npredictive models on their data. It is important that ML models trained on\nsensitive inputs (e.g., personal images or documents) not leak too much\ninformation about the training data.\n  We consider a malicious ML provider who supplies model-training code to the\ndata holder, does not observe the training, but then obtains white- or\nblack-box access to the resulting model. In this setting, we design and\nimplement practical algorithms, some of them very similar to standard ML\ntechniques such as regularization and data augmentation, that \"memorize\"\ninformation about the training dataset in the model yet the model is as\naccurate and predictive as a conventionally trained model. We then explain how\nthe adversary can extract memorized information from the model.\n  We evaluate our techniques on standard ML tasks for image classification\n(CIFAR10), face recognition (LFW and FaceScrub), and text analysis (20\nNewsgroups and IMDB). In all cases, we show how our algorithms create models\nthat have high predictive power yet allow accurate extraction of subsets of\ntheir training data.\n", "versions": [{"version": "v1", "created": "Fri, 22 Sep 2017 18:00:19 GMT"}], "update_date": "2017-09-28", "authors_parsed": [["Song", "Congzheng", ""], ["Ristenpart", "Thomas", ""], ["Shmatikov", "Vitaly", ""]]}, {"id": "1709.07899", "submitter": "Patrick Rodler", "authors": "Patrick Rodler", "title": "On the Discrimination Power and Effective Utilization of Active Learning\n  Measures in Version Space Search", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Active Learning (AL) methods have proven cost-saving against passive\nsupervised methods in many application domains. An active learner, aiming to\nfind some target hypothesis, formulates sequential queries to some oracle. The\nset of hypotheses consistent with the already answered queries is called\nversion space. Several query selection measures (QSMs) for determining the best\nquery to ask next have been proposed. Assuming binaryoutcome queries, we\nanalyze various QSMs wrt. to the discrimination power of their selected queries\nwithin the current version space. As a result, we derive superiority and\nequivalence relations between these QSMs and introduce improved versions of\nexisting QSMs to overcome identified issues. The obtained picture gives a hint\nabout which QSMs should preferably be used in pool-based AL scenarios.\nMoreover, we deduce properties optimal queries wrt. QSMs must satisfy. Based on\nthese, we demonstrate how efficient heuristic search methods for optimal\nqueries in query synthesis AL scenarios can be devised.\n", "versions": [{"version": "v1", "created": "Fri, 22 Sep 2017 18:30:32 GMT"}], "update_date": "2017-09-26", "authors_parsed": [["Rodler", "Patrick", ""]]}, {"id": "1709.07902", "submitter": "Wei-Ning Hsu", "authors": "Wei-Ning Hsu, Yu Zhang, and James Glass", "title": "Unsupervised Learning of Disentangled and Interpretable Representations\n  from Sequential Data", "comments": "Accepted to NIPS 2017", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CL cs.SD eess.AS stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a factorized hierarchical variational autoencoder, which learns\ndisentangled and interpretable representations from sequential data without\nsupervision. Specifically, we exploit the multi-scale nature of information in\nsequential data by formulating it explicitly within a factorized hierarchical\ngraphical model that imposes sequence-dependent priors and sequence-independent\npriors to different sets of latent variables. The model is evaluated on two\nspeech corpora to demonstrate, qualitatively, its ability to transform speakers\nor linguistic content by manipulating different sets of latent variables; and\nquantitatively, its ability to outperform an i-vector baseline for speaker\nverification and reduce the word error rate by as much as 35% in mismatched\ntrain/test scenarios for automatic speech recognition tasks.\n", "versions": [{"version": "v1", "created": "Fri, 22 Sep 2017 18:36:50 GMT"}], "update_date": "2017-09-26", "authors_parsed": [["Hsu", "Wei-Ning", ""], ["Zhang", "Yu", ""], ["Glass", "James", ""]]}, {"id": "1709.07903", "submitter": "Weitong Ruan", "authors": "Weitong Ruan and Eric L. Miller", "title": "Ensemble Multi-task Gaussian Process Regression with Multiple Latent\n  Processes", "comments": "main body: 9 pages, supplemental material: 7 pages. This version\n  corrected a few typos in previous version", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Multi-task/Multi-output learning seeks to exploit correlation among tasks to\nenhance performance over learning or solving each task independently. In this\npaper, we investigate this problem in the context of Gaussian Processes (GPs)\nand propose a new model which learns a mixture of latent processes by\ndecomposing the covariance matrix into a sum of structured hidden components\neach of which is controlled by a latent GP over input features and a \"weight\"\nover tasks. From this sum structure, we propose a parallelizable parameter\nlearning algorithm with a predetermined initialization for the \"weights\". We\nalso notice that an ensemble parameter learning approach using mini-batches of\ntraining data not only reduces the computation complexity of learning but also\nimproves the regression performance. We evaluate our model on two datasets, the\nsmaller Swiss Jura dataset and another relatively larger ATMS dataset from\nNOAA. Substantial improvements are observed compared with established\nalternatives.\n", "versions": [{"version": "v1", "created": "Fri, 22 Sep 2017 18:38:31 GMT"}, {"version": "v2", "created": "Wed, 27 Sep 2017 20:28:38 GMT"}, {"version": "v3", "created": "Wed, 9 May 2018 15:09:58 GMT"}], "update_date": "2018-05-10", "authors_parsed": [["Ruan", "Weitong", ""], ["Miller", "Eric L.", ""]]}, {"id": "1709.07911", "submitter": "Junhong Xu", "authors": "Junhong Xu, Shangyue Zhu, Hanqing Guo and Shaoen Wu", "title": "Avoidance of Manual Labeling in Robotic Autonomous Navigation Through\n  Multi-Sensory Semi-Supervised Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.RO", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Imitation learning holds the promise to address challenging robotic tasks\nsuch as autonomous navigation. It however requires a human supervisor to\noversee the training process and send correct control commands to robots\nwithout feedback, which is always prone to error and expensive. To minimize\nhuman involvement and avoid manual labeling of data in the robotic autonomous\nnavigation with imitation learning, this paper proposes a novel semi-supervised\nimitation learning solution based on a multi-sensory design. This solution\nincludes a suboptimal sensor policy based on sensor fusion to automatically\nlabel states encountered by a robot to avoid human supervision during training.\nIn addition, a recording policy is developed to throttle the adversarial affect\nof learning too much from the suboptimal sensor policy. This solution allows\nthe robot to learn a navigation policy in a self-supervised manner. With\nextensive experiments in indoor environments, this solution can achieve near\nhuman performance in most of the tasks and even surpasses human performance in\ncase of unexpected events such as hardware failures or human operation errors.\nTo best of our knowledge, this is the first work that synthesizes sensor fusion\nand imitation learning to enable robotic autonomous navigation in the real\nworld without human supervision.\n", "versions": [{"version": "v1", "created": "Fri, 22 Sep 2017 19:03:18 GMT"}, {"version": "v2", "created": "Tue, 26 Sep 2017 13:41:14 GMT"}, {"version": "v3", "created": "Mon, 9 Oct 2017 15:04:29 GMT"}, {"version": "v4", "created": "Tue, 20 Feb 2018 21:06:23 GMT"}], "update_date": "2018-02-22", "authors_parsed": [["Xu", "Junhong", ""], ["Zhu", "Shangyue", ""], ["Guo", "Hanqing", ""], ["Wu", "Shaoen", ""]]}, {"id": "1709.07943", "submitter": "Yue Wu", "authors": "Yue Wu and Youzuo Lin and Zheng Zhou and David Chas Bolton and Ji Liu\n  and Paul Johnson", "title": "Cascaded Region-based Densely Connected Network for Event Detection: A\n  Seismic Application", "comments": null, "journal-ref": null, "doi": "10.1109/TGRS.2018.2852302", "report-no": null, "categories": "cs.LG cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Automatic event detection from time series signals has wide applications,\nsuch as abnormal event detection in video surveillance and event detection in\ngeophysical data. Traditional detection methods detect events primarily by the\nuse of similarity and correlation in data. Those methods can be inefficient and\nyield low accuracy. In recent years, because of the significantly increased\ncomputational power, machine learning techniques have revolutionized many\nscience and engineering domains. In this study, we apply a deep-learning-based\nmethod to the detection of events from time series seismic signals. However, a\ndirect adaptation of the similar ideas from 2D object detection to our problem\nfaces two challenges. The first challenge is that the duration of earthquake\nevent varies significantly; The other is that the proposals generated are\ntemporally correlated. To address these challenges, we propose a novel cascaded\nregion-based convolutional neural network to capture earthquake events in\ndifferent sizes, while incorporating contextual information to enrich features\nfor each individual proposal. To achieve a better generalization performance,\nwe use densely connected blocks as the backbone of our network. Because of the\nfact that some positive events are not correctly annotated, we further\nformulate the detection problem as a learning-from-noise problem. To verify the\nperformance of our detection methods, we employ our methods to seismic data\ngenerated from a bi-axial \"earthquake machine\" located at Rock Mechanics\nLaboratory, and we acquire labels with the help of experts. Through our\nnumerical tests, we show that our novel detection techniques yield high\naccuracy. Therefore, our novel deep-learning-based detection methods can\npotentially be powerful tools for locating events from time series data in\nvarious applications.\n", "versions": [{"version": "v1", "created": "Tue, 12 Sep 2017 08:00:46 GMT"}, {"version": "v2", "created": "Wed, 29 Nov 2017 04:15:26 GMT"}], "update_date": "2018-09-26", "authors_parsed": [["Wu", "Yue", ""], ["Lin", "Youzuo", ""], ["Zhou", "Zheng", ""], ["Bolton", "David Chas", ""], ["Liu", "Ji", ""], ["Johnson", "Paul", ""]]}, {"id": "1709.07979", "submitter": "Wenhao Yu", "authors": "Wenhao Yu, C. Karen Liu, Greg Turk", "title": "Multi-task Learning with Gradient Guided Policy Specialization", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a method for efficient learning of control policies for multiple\nrelated robotic motor skills. Our approach consists of two stages, joint\ntraining and specialization training. During the joint training stage, a neural\nnetwork policy is trained with minimal information to disambiguate the motor\nskills. This forces the policy to learn a common representation of the\ndifferent tasks. Then, during the specialization training stage we selectively\nsplit the weights of the policy based on a per-weight metric that measures the\ndisagreement among the multiple tasks. By splitting part of the control policy,\nit can be further trained to specialize to each task. To update the control\npolicy during learning, we use Trust Region Policy Optimization with\nGeneralized Advantage Function (TRPOGAE). We propose a modification to the\ngradient update stage of TRPO to better accommodate multi-task learning\nscenarios. We evaluate our approach on three continuous motor skill learning\nproblems in simulation: 1) a locomotion task where three single legged robots\nwith considerable difference in shape and size are trained to hop forward, 2) a\nmanipulation task where three robot manipulators with different sizes and joint\ntypes are trained to reach different locations in 3D space, and 3) locomotion\nof a two-legged robot, whose range of motion of one leg is constrained in\ndifferent ways. We compare our training method to three baselines. The first\nbaseline uses only joint training for the policy, the second trains independent\npolicies for each task, and the last randomly selects weights to split. We show\nthat our approach learns more efficiently than each of the baseline methods.\n", "versions": [{"version": "v1", "created": "Sat, 23 Sep 2017 00:54:18 GMT"}, {"version": "v2", "created": "Wed, 11 Oct 2017 15:28:57 GMT"}, {"version": "v3", "created": "Fri, 2 Mar 2018 22:23:00 GMT"}], "update_date": "2018-03-06", "authors_parsed": [["Yu", "Wenhao", ""], ["Liu", "C. Karen", ""], ["Turk", "Greg", ""]]}, {"id": "1709.07984", "submitter": "Jorge Luis Rivero", "authors": "Jorge Rivero, Bernardete Ribeiro, Ning Chen, F\\'atima Silva Leite", "title": "A Grassmannian Approach to Zero-Shot Learning for Network Intrusion\n  Detection", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  One of the main problems in Network Intrusion Detection comes from constant\nrise of new attacks, so that not enough labeled examples are available for the\nnew classes of attacks. Traditional Machine Learning approaches hardly address\nsuch problem. This can be overcome with Zero-Shot Learning, a new approach in\nthe field of Computer Vision, which can be described in two stages: the\nAttribute Learning and the Inference Stage. The goal of this paper is to\npropose a new Inference Stage algorithm for Network Intrusion Detection. In\norder to attain this objective, we firstly put forward an experimental setup\nfor the evaluation of the Zero-Shot Learning in Network Intrusion Detection\nrelated tasks. Secondly, a decision tree based algorithm is applied to extract\nrules for generating the attributes in the AL stage. Finally, using a\nrepresentation of a Zero-Shot Class as a point in the Grassmann manifold, an\nexplicit formula for the shortest distance between points in that manifold can\nbe used to compute the geodesic distance between the Zero-Shot Classes which\nrepresent the new attacks and the Known Classes corresponding to the attack\ncategories. The experimental results in the datasets KDD Cup 99 and NSL-KDD\nshow that our approach with Zero-Shot Learning successfully addresses the\nNetwork Intrusion Detection problem.\n", "versions": [{"version": "v1", "created": "Sat, 23 Sep 2017 01:27:17 GMT"}], "update_date": "2017-09-26", "authors_parsed": [["Rivero", "Jorge", ""], ["Ribeiro", "Bernardete", ""], ["Chen", "Ning", ""], ["Leite", "F\u00e1tima Silva", ""]]}, {"id": "1709.08025", "submitter": "Yuanfang Chen", "authors": "Yuanfang Chen, Yan Zhang, Sabita Maharjan", "title": "Deep Learning for Secure Mobile Edge Computing", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.LG cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Mobile edge computing (MEC) is a promising approach for enabling\ncloud-computing capabilities at the edge of cellular networks. Nonetheless,\nsecurity is becoming an increasingly important issue in MEC-based applications.\nIn this paper, we propose a deep-learning-based model to detect security\nthreats. The model uses unsupervised learning to automate the detection\nprocess, and uses location information as an important feature to improve the\nperformance of detection. Our proposed model can be used to detect malicious\napplications at the edge of a cellular network, which is a serious security\nthreat. Extensive experiments are carried out with 10 different datasets, the\nresults of which illustrate that our deep-learning-based model achieves an\naverage gain of 6% accuracy compared with state-of-the-art machine learning\nalgorithms.\n", "versions": [{"version": "v1", "created": "Sat, 23 Sep 2017 08:59:49 GMT"}], "update_date": "2017-09-26", "authors_parsed": [["Chen", "Yuanfang", ""], ["Zhang", "Yan", ""], ["Maharjan", "Sabita", ""]]}, {"id": "1709.08041", "submitter": "Yuki Saito", "authors": "Yuki Saito, Shinnosuke Takamichi, Hiroshi Saruwatari", "title": "Statistical Parametric Speech Synthesis Incorporating Generative\n  Adversarial Networks", "comments": "Preprint manuscript of IEEE/ACM Transactions on Audio, Speech and\n  Language Processing", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SD cs.LG eess.AS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A method for statistical parametric speech synthesis incorporating generative\nadversarial networks (GANs) is proposed. Although powerful deep neural networks\n(DNNs) techniques can be applied to artificially synthesize speech waveform,\nthe synthetic speech quality is low compared with that of natural speech. One\nof the issues causing the quality degradation is an over-smoothing effect often\nobserved in the generated speech parameters. A GAN introduced in this paper\nconsists of two neural networks: a discriminator to distinguish natural and\ngenerated samples, and a generator to deceive the discriminator. In the\nproposed framework incorporating the GANs, the discriminator is trained to\ndistinguish natural and generated speech parameters, while the acoustic models\nare trained to minimize the weighted sum of the conventional minimum generation\nloss and an adversarial loss for deceiving the discriminator. Since the\nobjective of the GANs is to minimize the divergence (i.e., distribution\ndifference) between the natural and generated speech parameters, the proposed\nmethod effectively alleviates the over-smoothing effect on the generated speech\nparameters. We evaluated the effectiveness for text-to-speech and voice\nconversion, and found that the proposed method can generate more natural\nspectral parameters and $F_0$ than conventional minimum generation error\ntraining algorithm regardless its hyper-parameter settings. Furthermore, we\ninvestigated the effect of the divergence of various GANs, and found that a\nWasserstein GAN minimizing the Earth-Mover's distance works the best in terms\nof improving synthetic speech quality.\n", "versions": [{"version": "v1", "created": "Sat, 23 Sep 2017 12:10:32 GMT"}], "update_date": "2017-09-26", "authors_parsed": [["Saito", "Yuki", ""], ["Takamichi", "Shinnosuke", ""], ["Saruwatari", "Hiroshi", ""]]}, {"id": "1709.08055", "submitter": "Ben Fulcher", "authors": "Ben D. Fulcher", "title": "Feature-based time-series analysis", "comments": "28 pages, 9 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This work presents an introduction to feature-based time-series analysis. The\ntime series as a data type is first described, along with an overview of the\ninterdisciplinary time-series analysis literature. I then summarize the range\nof feature-based representations for time series that have been developed to\naid interpretable insights into time-series structure. Particular emphasis is\ngiven to emerging research that facilitates wide comparison of feature-based\nrepresentations that allow us to understand the properties of a time-series\ndataset that make it suited to a particular feature-based representation or\nanalysis algorithm. The future of time-series analysis is likely to embrace\napproaches that exploit machine learning methods to partially automate human\nlearning to aid understanding of the complex dynamical patterns in the time\nseries we measure from the world.\n", "versions": [{"version": "v1", "created": "Sat, 23 Sep 2017 13:33:53 GMT"}, {"version": "v2", "created": "Mon, 2 Oct 2017 00:29:48 GMT"}], "update_date": "2017-10-03", "authors_parsed": [["Fulcher", "Ben D.", ""]]}, {"id": "1709.08073", "submitter": "Petar Veli\\v{c}kovi\\'c", "authors": "Petar Veli\\v{c}kovi\\'c, Laurynas Karazija, Nicholas D. Lane, Sourav\n  Bhattacharya, Edgar Liberis, Pietro Li\\`o, Angela Chieh, Otmane Bellahsen,\n  Matthieu Vegreville", "title": "Cross-modal Recurrent Models for Weight Objective Prediction from\n  Multimodal Time-series Data", "comments": "To appear in NIPS ML4H 2017 and NIPS TSW 2017", "journal-ref": null, "doi": "10.1145/3240925.3240937", "report-no": null, "categories": "stat.ML cs.AI cs.LG q-bio.QM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We analyse multimodal time-series data corresponding to weight, sleep and\nsteps measurements. We focus on predicting whether a user will successfully\nachieve his/her weight objective. For this, we design several deep long\nshort-term memory (LSTM) architectures, including a novel cross-modal LSTM\n(X-LSTM), and demonstrate their superiority over baseline approaches. The\nX-LSTM improves parameter efficiency by processing each modality separately and\nallowing for information flow between them by way of recurrent\ncross-connections. We present a general hyperparameter optimisation technique\nfor X-LSTMs, which allows us to significantly improve on the LSTM and a prior\nstate-of-the-art cross-modal approach, using a comparable number of parameters.\nFinally, we visualise the model's predictions, revealing implications about\nlatent variables in this task.\n", "versions": [{"version": "v1", "created": "Sat, 23 Sep 2017 16:42:34 GMT"}, {"version": "v2", "created": "Wed, 29 Nov 2017 07:45:28 GMT"}], "update_date": "2018-09-13", "authors_parsed": [["Veli\u010dkovi\u0107", "Petar", ""], ["Karazija", "Laurynas", ""], ["Lane", "Nicholas D.", ""], ["Bhattacharya", "Sourav", ""], ["Liberis", "Edgar", ""], ["Li\u00f2", "Pietro", ""], ["Chieh", "Angela", ""], ["Bellahsen", "Otmane", ""], ["Vegreville", "Matthieu", ""]]}, {"id": "1709.08120", "submitter": "Maria Bauza", "authors": "Maria Bauza, Alberto Rodriguez", "title": "GP-SUM. Gaussian Processes Filtering of non-Gaussian Beliefs", "comments": "WAFR 2018, 16 pages, 7 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This work studies the problem of stochastic dynamic filtering and state\npropagation with complex beliefs. The main contribution is GP-SUM, a filtering\nalgorithm tailored to dynamic systems and observation models expressed as\nGaussian Processes (GP), and to states represented as a weighted sum of\nGaussians. The key attribute of GP-SUM is that it does not rely on\nlinearizations of the dynamic or observation models, or on unimodal Gaussian\napproximations of the belief, hence enables tracking complex state\ndistributions. The algorithm can be seen as a combination of a sampling-based\nfilter with a probabilistic Bayes filter. On the one hand, GP-SUM operates by\nsampling the state distribution and propagating each sample through the dynamic\nsystem and observation models. On the other hand, it achieves effective\nsampling and accurate probabilistic propagation by relying on the GP form of\nthe system, and the sum-of-Gaussian form of the belief. We show that GP-SUM\noutperforms several GP-Bayes and Particle Filters on a standard benchmark. We\nalso demonstrate its use in a pushing task, predicting with experimental\naccuracy the naturally occurring non-Gaussian distributions.\n", "versions": [{"version": "v1", "created": "Sat, 23 Sep 2017 21:41:38 GMT"}, {"version": "v2", "created": "Wed, 7 Feb 2018 14:52:45 GMT"}, {"version": "v3", "created": "Wed, 30 Jan 2019 23:28:07 GMT"}], "update_date": "2019-02-01", "authors_parsed": [["Bauza", "Maria", ""], ["Rodriguez", "Alberto", ""]]}, {"id": "1709.08126", "submitter": "Guido de Croon", "authors": "G.C.H.E. de Croon", "title": "Self-supervised learning: When is fusion of the primary and secondary\n  sensor cue useful?", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Self-supervised learning (SSL) is a reliable learning mechanism in which a\nrobot enhances its perceptual capabilities. Typically, in SSL a trusted,\nprimary sensor cue provides supervised training data to a secondary sensor cue.\nIn this article, a theoretical analysis is performed on the fusion of the\nprimary and secondary cue in a minimal model of SSL. A proof is provided that\ndetermines the specific conditions under which it is favorable to perform\nfusion. In short, it is favorable when (i) the prior on the target value is\nstrong or (ii) the secondary cue is sufficiently accurate. The theoretical\nfindings are validated with computational experiments. Subsequently, a\nreal-world case study is performed to investigate if fusion in SSL is also\nbeneficial when assumptions of the minimal model are not met. In particular, a\nflying robot learns to map pressure measurements to sonar height measurements\nand then fuses the two, resulting in better height estimation. Fusion is also\nbeneficial in the opposite case, when pressure is the primary cue. The analysis\nand results are encouraging to study SSL fusion also for other robots and\nsensors.\n", "versions": [{"version": "v1", "created": "Sat, 23 Sep 2017 23:21:26 GMT"}], "update_date": "2017-10-10", "authors_parsed": [["de Croon", "G. C. H. E.", ""]]}, {"id": "1709.08174", "submitter": "Hrushikesh Mhaskar", "authors": "Hrushikesh N. Mhaskar", "title": "Function approximation with zonal function networks with activation\n  functions analogous to the rectified linear unit functions", "comments": "18 pages, Title changed from the pervious version", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG math.NA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A zonal function (ZF) network on the $q$ dimensional sphere $\\mathbb{S}^q$ is\na network of the form $\\mathbf{x}\\mapsto \\sum_{k=1}^n\na_k\\phi(\\mathbf{x}\\cdot\\mathbf{x}_k)$ where $\\phi :[-1,1]\\to\\mathbf{R}$ is the\nactivation function, $\\mathbf{x}_k\\in\\mathbb{S}^q$ are the centers, and\n$a_k\\in\\mathbb{R}$. While the approximation properties of such networks are\nwell studied in the context of positive definite activation functions, recent\ninterest in deep and shallow networks motivate the study of activation\nfunctions of the form $\\phi(t)=|t|$, which are not positive definite. In this\npaper, we define an appropriate smoothess class and establish approximation\nproperties of such networks for functions in this class. The centers can be\nchosen independently of the target function, and the coefficients are linear\ncombinations of the training data. The constructions preserve rotational\nsymmetries.\n", "versions": [{"version": "v1", "created": "Sun, 24 Sep 2017 09:55:04 GMT"}, {"version": "v2", "created": "Sun, 8 Jul 2018 17:40:13 GMT"}], "update_date": "2018-07-10", "authors_parsed": [["Mhaskar", "Hrushikesh N.", ""]]}, {"id": "1709.08201", "submitter": "Siyuan Li", "authors": "Siyuan Li and Chongjie Zhang", "title": "An Optimal Online Method of Selecting Source Policies for Reinforcement\n  Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Transfer learning significantly accelerates the reinforcement learning\nprocess by exploiting relevant knowledge from previous experiences. The problem\nof optimally selecting source policies during the learning process is of great\nimportance yet challenging. There has been little theoretical analysis of this\nproblem. In this paper, we develop an optimal online method to select source\npolicies for reinforcement learning. This method formulates online source\npolicy selection as a multi-armed bandit problem and augments Q-learning with\npolicy reuse. We provide theoretical guarantees of the optimal selection\nprocess and convergence to the optimal policy. In addition, we conduct\nexperiments on a grid-based robot navigation domain to demonstrate its\nefficiency and robustness by comparing to the state-of-the-art transfer\nlearning method.\n", "versions": [{"version": "v1", "created": "Sun, 24 Sep 2017 14:17:14 GMT"}], "update_date": "2017-09-26", "authors_parsed": [["Li", "Siyuan", ""], ["Zhang", "Chongjie", ""]]}, {"id": "1709.08225", "submitter": "Stefanos Papanikolaou", "authors": "Stefanos Papanikolaou, Michail Tzimas, Andrew C.E. Reid and Stephen A.\n  Langer", "title": "Learning crystal plasticity using digital image correlation: Examples\n  from discrete dislocation dynamics", "comments": "35 pages, 31 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cond-mat.mtrl-sci cond-mat.mes-hall cond-mat.stat-mech cs.CE cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Digital image correlation (DIC) is a well-established, non-invasive technique\nfor tracking and quantifying the deformation of mechanical samples under\nstrain. While it provides an obvious way to observe incremental and aggregate\ndisplacement information, it seems likely that DIC data sets, which after all\nreflect the spatially-resolved response of a microstructure to loads, contain\nmuch richer information than has generally been extracted from them. In this\npaper, we demonstrate a machine-learning approach to quantifying the prior\ndeformation history of a crystalline sample based on its response to a\nsubsequent DIC test. This prior deformation history is encoded in the\nmicrostructure through the inhomogeneity of the dislocation microstructure, and\nin the spatial correlations of the dislocation patterns, which mediate the\nsystem's response to the DIC test load. Our domain consists of deformed\ncrystalline thin films generated by a discrete dislocation plasticity\nsimulation. We explore the range of applicability of machine learning (ML) for\ntypical experimental protocols, and as a function of possible size effects and\nstochasticity. Plasticity size effects may directly influence the data,\nrendering unsupervised techniques unable to distinguish different plasticity\nregimes.\n", "versions": [{"version": "v1", "created": "Sun, 24 Sep 2017 17:30:51 GMT"}, {"version": "v2", "created": "Sat, 13 Apr 2019 15:55:15 GMT"}], "update_date": "2019-04-16", "authors_parsed": [["Papanikolaou", "Stefanos", ""], ["Tzimas", "Michail", ""], ["Reid", "Andrew C. E.", ""], ["Langer", "Stephen A.", ""]]}, {"id": "1709.08267", "submitter": "Kamran Kowsari", "authors": "Kamran Kowsari, Donald E. Brown, Mojtaba Heidarysafa, Kiana Jafari\n  Meimandi, Matthew S. Gerber, Laura E. Barnes", "title": "HDLTex: Hierarchical Deep Learning for Text Classification", "comments": "ICMLA 2017", "journal-ref": null, "doi": "10.1109/ICMLA.2017.0-134", "report-no": null, "categories": "cs.LG cs.AI cs.CL cs.CV cs.IR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The continually increasing number of documents produced each year\nnecessitates ever improving information processing methods for searching,\nretrieving, and organizing text. Central to these information processing\nmethods is document classification, which has become an important application\nfor supervised learning. Recently the performance of these traditional\nclassifiers has degraded as the number of documents has increased. This is\nbecause along with this growth in the number of documents has come an increase\nin the number of categories. This paper approaches this problem differently\nfrom current document classification methods that view the problem as\nmulti-class classification. Instead we perform hierarchical classification\nusing an approach we call Hierarchical Deep Learning for Text classification\n(HDLTex). HDLTex employs stacks of deep learning architectures to provide\nspecialized understanding at each level of the document hierarchy.\n", "versions": [{"version": "v1", "created": "Sun, 24 Sep 2017 21:58:12 GMT"}, {"version": "v2", "created": "Fri, 6 Oct 2017 18:16:31 GMT"}], "update_date": "2018-03-29", "authors_parsed": [["Kowsari", "Kamran", ""], ["Brown", "Donald E.", ""], ["Heidarysafa", "Mojtaba", ""], ["Meimandi", "Kiana Jafari", ""], ["Gerber", "Matthew S.", ""], ["Barnes", "Laura E.", ""]]}, {"id": "1709.08274", "submitter": "Kaiyu Zheng", "authors": "Kaiyu Zheng, Andrzej Pronobis, Rajesh P. N. Rao", "title": "Learning Graph-Structured Sum-Product Networks for Probabilistic\n  Semantic Maps", "comments": "9 pages, 8 figures. AAAI Conference on Artificial Intelligence (AAAI\n  2018)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We introduce Graph-Structured Sum-Product Networks (GraphSPNs), a\nprobabilistic approach to structured prediction for problems where dependencies\nbetween latent variables are expressed in terms of arbitrary, dynamic graphs.\nWhile many approaches to structured prediction place strict constraints on the\ninteractions between inferred variables, many real-world problems can be only\ncharacterized using complex graph structures of varying size, often\ncontaminated with noise when obtained from real data. Here, we focus on one\nsuch problem in the domain of robotics. We demonstrate how GraphSPNs can be\nused to bolster inference about semantic, conceptual place descriptions using\nnoisy topological relations discovered by a robot exploring large-scale office\nspaces. Through experiments, we show that GraphSPNs consistently outperform the\ntraditional approach based on undirected graphical models, successfully\ndisambiguating information in global semantic maps built from uncertain, noisy\nlocal evidence. We further exploit the probabilistic nature of the model to\ninfer marginal distributions over semantic descriptions of as yet unexplored\nplaces and detect spatial environment configurations that are novel and\nincongruent with the known evidence.\n", "versions": [{"version": "v1", "created": "Sun, 24 Sep 2017 22:24:02 GMT"}, {"version": "v2", "created": "Wed, 22 Nov 2017 18:36:13 GMT"}], "update_date": "2017-11-23", "authors_parsed": [["Zheng", "Kaiyu", ""], ["Pronobis", "Andrzej", ""], ["Rao", "Rajesh P. N.", ""]]}, {"id": "1709.08292", "submitter": "Peter Henderson", "authors": "Florian Shkurti, Wei-Di Chang, Peter Henderson, Md Jahidul Islam, Juan\n  Camilo Gamboa Higuera, Jimmy Li, Travis Manderson, Anqi Xu, Gregory Dudek,\n  Junaed Sattar", "title": "Underwater Multi-Robot Convoying using Visual Tracking by Detection", "comments": "Accepted to IEEE/RSJ International Conference on Intelligent Robots\n  and Systems (IROS), 2017", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a robust multi-robot convoying approach that relies on visual\ndetection of the leading agent, thus enabling target following in unstructured\n3-D environments. Our method is based on the idea of tracking-by-detection,\nwhich interleaves efficient model-based object detection with temporal\nfiltering of image-based bounding box estimation. This approach has the\nimportant advantage of mitigating tracking drift (i.e. drifting away from the\ntarget object), which is a common symptom of model-free trackers and is\ndetrimental to sustained convoying in practice. To illustrate our solution, we\ncollected extensive footage of an underwater robot in ocean settings, and\nhand-annotated its location in each frame. Based on this dataset, we present an\nempirical comparison of multiple tracker variants, including the use of several\nconvolutional neural networks, both with and without recurrent connections, as\nwell as frequency-based model-free trackers. We also demonstrate the\npracticality of this tracking-by-detection strategy in real-world scenarios by\nsuccessfully controlling a legged underwater robot in five degrees of freedom\nto follow another robot's independent motion.\n", "versions": [{"version": "v1", "created": "Mon, 25 Sep 2017 01:55:00 GMT"}], "update_date": "2017-09-26", "authors_parsed": [["Shkurti", "Florian", ""], ["Chang", "Wei-Di", ""], ["Henderson", "Peter", ""], ["Islam", "Md Jahidul", ""], ["Higuera", "Juan Camilo Gamboa", ""], ["Li", "Jimmy", ""], ["Manderson", "Travis", ""], ["Xu", "Anqi", ""], ["Dudek", "Gregory", ""], ["Sattar", "Junaed", ""]]}, {"id": "1709.08294", "submitter": "Dinghan Shen", "authors": "Dinghan Shen, Martin Renqiang Min, Yitong Li, Lawrence Carin", "title": "Learning Context-Sensitive Convolutional Filters for Text Processing", "comments": "Accepted by EMNLP 2018 as a full paper", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Convolutional neural networks (CNNs) have recently emerged as a popular\nbuilding block for natural language processing (NLP). Despite their success,\nmost existing CNN models employed in NLP share the same learned (and static)\nset of filters for all input sentences. In this paper, we consider an approach\nof using a small meta network to learn context-sensitive convolutional filters\nfor text processing. The role of meta network is to abstract the contextual\ninformation of a sentence or document into a set of input-aware filters. We\nfurther generalize this framework to model sentence pairs, where a\nbidirectional filter generation mechanism is introduced to encapsulate\nco-dependent sentence representations. In our benchmarks on four different\ntasks, including ontology classification, sentiment analysis, answer sentence\nselection, and paraphrase identification, our proposed model, a modified CNN\nwith context-sensitive filters, consistently outperforms the standard CNN and\nattention-based CNN baselines. By visualizing the learned context-sensitive\nfilters, we further validate and rationalize the effectiveness of proposed\nframework.\n", "versions": [{"version": "v1", "created": "Mon, 25 Sep 2017 02:29:26 GMT"}, {"version": "v2", "created": "Wed, 29 Aug 2018 04:15:40 GMT"}, {"version": "v3", "created": "Thu, 30 Aug 2018 16:29:50 GMT"}], "update_date": "2018-08-31", "authors_parsed": [["Shen", "Dinghan", ""], ["Min", "Martin Renqiang", ""], ["Li", "Yitong", ""], ["Carin", "Lawrence", ""]]}, {"id": "1709.08426", "submitter": "Ji Xu", "authors": "Ji Xu and Guoyin Wang", "title": "Non-iterative Label Propagation in Optimal Leading Forest", "comments": "Claim the itelligence property by first uploading it to the preprint\n  platform. After carefullu revision of this initial draft, we would like to\n  submit it to a conference or journal", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Graph based semi-supervised learning (GSSL) has intuitive representation and\ncan be improved by exploiting the matrix calculation. However, it has to\nperform iterative optimization to achieve a preset objective, which usually\nleads to low efficiency. Another inconvenience lying in GSSL is that when new\ndata come, the graph construction and the optimization have to be conducted all\nover again. We propose a sound assumption, arguing that: the neighboring data\npoints are not in peer-to-peer relation, but in a partial-ordered relation\ninduced by the local density and distance between the data; and the label of a\ncenter can be regarded as the contribution of its followers. Starting from the\nassumption, we develop a highly efficient non-iterative label propagation\nalgorithm based on a novel data structure named as optimal leading forest\n(LaPOLeaF). The major weaknesses of the traditional GSSL are addressed by this\nstudy. We further scale LaPOLeaF to accommodate big data by utilizing block\ndistance matrix technique, parallel computing, and Locality-Sensitive Hashing\n(LSH). Experiments on large datasets have shown the promising results of the\nproposed methods.\n", "versions": [{"version": "v1", "created": "Mon, 25 Sep 2017 11:25:36 GMT"}, {"version": "v2", "created": "Tue, 12 Feb 2019 09:50:32 GMT"}], "update_date": "2019-02-13", "authors_parsed": [["Xu", "Ji", ""], ["Wang", "Guoyin", ""]]}, {"id": "1709.08430", "submitter": "Giuseppe Paolo Mr", "authors": "Giuseppe Paolo, Lei Tai and Ming Liu", "title": "Towards continuous control of flippers for a multi-terrain robot using\n  deep reinforcement learning", "comments": "12 pages, single column, submitted to International Journal of\n  Robotics and Automation (IJRA)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we focus on developing a control algorithm for multi-terrain\ntracked robots with flippers using a reinforcement learning (RL) approach. The\nwork is based on the deep deterministic policy gradient (DDPG) algorithm,\nproven to be very successful in simple simulation environments. The algorithm\nworks in an end-to-end fashion in order to control the continuous position of\nthe flippers. This end-to-end approach makes it easy to apply the controller to\na wide array of circumstances, but the huge flexibility comes to the cost of an\nincreased difficulty of solution. The complexity of the task is enlarged even\nmore by the fact that real multi-terrain robots move in partially observable\nenvironments. Notwithstanding these complications, being able to smoothly\ncontrol a multi-terrain robot can produce huge benefits in impaired people\ndaily lives or in search and rescue situations.\n", "versions": [{"version": "v1", "created": "Mon, 25 Sep 2017 11:29:34 GMT"}], "update_date": "2017-09-26", "authors_parsed": [["Paolo", "Giuseppe", ""], ["Tai", "Lei", ""], ["Liu", "Ming", ""]]}, {"id": "1709.08432", "submitter": "Lai Wei", "authors": "Xiaochen Chen, Lai Wei, Jiaxin Xu", "title": "House Price Prediction Using LSTM", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we use the house price data ranging from January 2004 to\nOctober 2016 to predict the average house price of November and December in\n2016 for each district in Beijing, Shanghai, Guangzhou and Shenzhen. We apply\nAutoregressive Integrated Moving Average model to generate the baseline while\nLSTM networks to build prediction model. These algorithms are compared in terms\nof Mean Squared Error. The result shows that the LSTM model has excellent\nproperties with respect to predict time series. Also, stateful LSTM networks\nand stack LSTM networks are employed to further study the improvement of\naccuracy of the house prediction model.\n", "versions": [{"version": "v1", "created": "Mon, 25 Sep 2017 11:31:50 GMT"}], "update_date": "2017-09-26", "authors_parsed": [["Chen", "Xiaochen", ""], ["Wei", "Lai", ""], ["Xu", "Jiaxin", ""]]}, {"id": "1709.08470", "submitter": "Yuan-Yen Tai", "authors": "Yuan-Yen Tai", "title": "An efficient clustering algorithm from the measure of local Gaussian\n  distribution", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DB cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, I will introduce a fast and novel clustering algorithm based\non Gaussian distribution and it can guarantee the separation of each cluster\ncentroid as a given parameter, $d_s$. The worst run time complexity of this\nalgorithm is approximately $\\sim$O$(T\\times N \\times \\log(N))$ where $T$ is the\niteration steps and $N$ is the number of features.\n", "versions": [{"version": "v1", "created": "Wed, 13 Sep 2017 15:39:03 GMT"}, {"version": "v2", "created": "Mon, 21 Oct 2019 14:07:45 GMT"}], "update_date": "2019-10-22", "authors_parsed": [["Tai", "Yuan-Yen", ""]]}, {"id": "1709.08480", "submitter": "Michele Mancini", "authors": "Michele Mancini, Gabriele Costante, Paolo Valigi and Thomas A.\n  Ciarfuglia", "title": "J-MOD$^{2}$: Joint Monocular Obstacle Detection and Depth Estimation", "comments": null, "journal-ref": "IEEE Robotics and Automation Letters, July 2018", "doi": "10.1109/LRA.2018.2800083", "report-no": null, "categories": "cs.LG cs.RO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this work, we propose an end-to-end deep architecture that jointly learns\nto detect obstacles and estimate their depth for MAV flight applications. Most\nof the existing approaches either rely on Visual SLAM systems or on depth\nestimation models to build 3D maps and detect obstacles. However, for the task\nof avoiding obstacles this level of complexity is not required. Recent works\nhave proposed multi task architectures to both perform scene understanding and\ndepth estimation. We follow their track and propose a specific architecture to\njointly estimate depth and obstacles, without the need to compute a global map,\nbut maintaining compatibility with a global SLAM system if needed. The network\narchitecture is devised to exploit the joint information of the obstacle\ndetection task, that produces more reliable bounding boxes, with the depth\nestimation one, increasing the robustness of both to scenario changes. We call\nthis architecture J-MOD$^{2}$. We test the effectiveness of our approach with\nexperiments on sequences with different appearance and focal lengths and\ncompare it to SotA multi task methods that jointly perform semantic\nsegmentation and depth estimation. In addition, we show the integration in a\nfull system using a set of simulated navigation experiments where a MAV\nexplores an unknown scenario and plans safe trajectories by using our detection\nmodel.\n", "versions": [{"version": "v1", "created": "Mon, 25 Sep 2017 13:37:01 GMT"}, {"version": "v2", "created": "Wed, 13 Dec 2017 14:28:11 GMT"}], "update_date": "2018-02-26", "authors_parsed": [["Mancini", "Michele", ""], ["Costante", "Gabriele", ""], ["Valigi", "Paolo", ""], ["Ciarfuglia", "Thomas A.", ""]]}, {"id": "1709.08519", "submitter": "Mikel Sanz", "authors": "F. A. C\\'ardenas-L\\'opez, M. Sanz, J. C. Retamal, E. Solano", "title": "Enhanced Quantum Synchronization via Quantum Machine Learning", "comments": null, "journal-ref": "Adv. Quantum Technol. 1800076 (2019)", "doi": "10.1002/qute.201800076", "report-no": null, "categories": "quant-ph cond-mat.mes-hall cs.AI cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the quantum synchronization between a pair of two-level systems\ninside two coupled cavities. By using a digital-analog decomposition of the\nmaster equation that rules the system dynamics, we show that this approach\nleads to quantum synchronization between both two-level systems. Moreover, we\ncan identify in this digital-analog block decomposition the fundamental\nelements of a quantum machine learning protocol, in which the agent and the\nenvironment (learning units) interact through a mediating system, namely, the\nregister. If we can additionally equip this algorithm with a classical feedback\nmechanism, which consists of projective measurements in the register,\nreinitialization of the register state and local conditional operations on the\nagent and environment subspace, a powerful and flexible quantum machine\nlearning protocol emerges. Indeed, numerical simulations show that this\nprotocol enhances the synchronization process, even when every subsystem\nexperience different loss/decoherence mechanisms, and give us the flexibility\nto choose the synchronization state. Finally, we propose an implementation\nbased on current technologies in superconducting circuits.\n", "versions": [{"version": "v1", "created": "Mon, 25 Sep 2017 14:40:11 GMT"}, {"version": "v2", "created": "Wed, 16 Jan 2019 11:21:39 GMT"}], "update_date": "2019-01-17", "authors_parsed": [["C\u00e1rdenas-L\u00f3pez", "F. A.", ""], ["Sanz", "M.", ""], ["Retamal", "J. C.", ""], ["Solano", "E.", ""]]}, {"id": "1709.08520", "submitter": "Nicholas Rhinehart", "authors": "Arun Venkatraman, Nicholas Rhinehart, Wen Sun, Lerrel Pinto, Martial\n  Hebert, Byron Boots, Kris M. Kitani, J. Andrew Bagnell", "title": "Predictive-State Decoders: Encoding the Future into Recurrent Networks", "comments": "NIPS 2017", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recurrent neural networks (RNNs) are a vital modeling technique that rely on\ninternal states learned indirectly by optimization of a supervised,\nunsupervised, or reinforcement training loss. RNNs are used to model dynamic\nprocesses that are characterized by underlying latent states whose form is\noften unknown, precluding its analytic representation inside an RNN. In the\nPredictive-State Representation (PSR) literature, latent state processes are\nmodeled by an internal state representation that directly models the\ndistribution of future observations, and most recent work in this area has\nrelied on explicitly representing and targeting sufficient statistics of this\nprobability distribution. We seek to combine the advantages of RNNs and PSRs by\naugmenting existing state-of-the-art recurrent neural networks with\nPredictive-State Decoders (PSDs), which add supervision to the network's\ninternal state representation to target predicting future observations.\nPredictive-State Decoders are simple to implement and easily incorporated into\nexisting training pipelines via additional loss regularization. We demonstrate\nthe effectiveness of PSDs with experimental results in three different domains:\nprobabilistic filtering, Imitation Learning, and Reinforcement Learning. In\neach, our method improves statistical performance of state-of-the-art recurrent\nbaselines and does so with fewer iterations and less data.\n", "versions": [{"version": "v1", "created": "Mon, 25 Sep 2017 14:40:18 GMT"}], "update_date": "2017-09-26", "authors_parsed": [["Venkatraman", "Arun", ""], ["Rhinehart", "Nicholas", ""], ["Sun", "Wen", ""], ["Pinto", "Lerrel", ""], ["Hebert", "Martial", ""], ["Boots", "Byron", ""], ["Kitani", "Kris M.", ""], ["Bagnell", "J. Andrew", ""]]}, {"id": "1709.08524", "submitter": "Alexander Shekhovtsov", "authors": "Boris Flach, Alexander Shekhovtsov, Ondrej Fikar", "title": "Generative learning for deep networks", "comments": "submitted to AAAI", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV cs.NE stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Learning, taking into account full distribution of the data, referred to as\ngenerative, is not feasible with deep neural networks (DNNs) because they model\nonly the conditional distribution of the outputs given the inputs. Current\nsolutions are either based on joint probability models facing difficult\nestimation problems or learn two separate networks, mapping inputs to outputs\n(recognition) and vice-versa (generation). We propose an intermediate approach.\nFirst, we show that forward computation in DNNs with logistic sigmoid\nactivations corresponds to a simplified approximate Bayesian inference in a\ndirected probabilistic multi-layer model. This connection allows to interpret\nDNN as a probabilistic model of the output and all hidden units given the\ninput. Second, we propose that in order for the recognition and generation\nnetworks to be more consistent with the joint model of the data, weights of the\nrecognition and generator network should be related by transposition. We\ndemonstrate in a tentative experiment that such a coupled pair can be learned\ngeneratively, modelling the full distribution of the data, and has enough\ncapacity to perform well in both recognition and generation.\n", "versions": [{"version": "v1", "created": "Mon, 25 Sep 2017 14:43:53 GMT"}], "update_date": "2017-09-26", "authors_parsed": [["Flach", "Boris", ""], ["Shekhovtsov", "Alexander", ""], ["Fikar", "Ondrej", ""]]}, {"id": "1709.08535", "submitter": "Tom Michoel", "authors": "Tom Michoel", "title": "Analytic solution and stationary phase approximation for the Bayesian\n  lasso and elastic net", "comments": "Switched to new NeurIPS style file; 11 pages, 3 figures + appendices\n  29 pages, 3 supplementary figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ME cs.LG math.ST q-bio.QM stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The lasso and elastic net linear regression models impose a\ndouble-exponential prior distribution on the model parameters to achieve\nregression shrinkage and variable selection, allowing the inference of robust\nmodels from large data sets. However, there has been limited success in\nderiving estimates for the full posterior distribution of regression\ncoefficients in these models, due to a need to evaluate analytically\nintractable partition function integrals. Here, the Fourier transform is used\nto express these integrals as complex-valued oscillatory integrals over\n\"regression frequencies\". This results in an analytic expansion and stationary\nphase approximation for the partition functions of the Bayesian lasso and\nelastic net, where the non-differentiability of the double-exponential prior\nhas so far eluded such an approach. Use of this approximation leads to highly\naccurate numerical estimates for the expectation values and marginal posterior\ndistributions of the regression coefficients, and allows for Bayesian inference\nof much higher dimensional models than previously possible.\n", "versions": [{"version": "v1", "created": "Mon, 25 Sep 2017 15:05:29 GMT"}, {"version": "v2", "created": "Mon, 15 Oct 2018 18:29:17 GMT"}, {"version": "v3", "created": "Wed, 28 Nov 2018 08:09:17 GMT"}], "update_date": "2018-11-29", "authors_parsed": [["Michoel", "Tom", ""]]}, {"id": "1709.08568", "submitter": "Yoshua Bengio", "authors": "Yoshua Bengio", "title": "The Consciousness Prior", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A new prior is proposed for learning representations of high-level concepts\nof the kind we manipulate with language. This prior can be combined with other\npriors in order to help disentangling abstract factors from each other. It is\ninspired by cognitive neuroscience theories of consciousness, seen as a\nbottleneck through which just a few elements, after having been selected by\nattention from a broader pool, are then broadcast and condition further\nprocessing, both in perception and decision-making. The set of recently\nselected elements one becomes aware of is seen as forming a low-dimensional\nconscious state. This conscious state is combining the few concepts\nconstituting a conscious thought, i.e., what one is immediately conscious of at\na particular moment. We claim that this architectural and\ninformation-processing constraint corresponds to assumptions about the joint\ndistribution between high-level concepts. To the extent that these assumptions\nare generally true (and the form of natural language seems consistent with\nthem), they can form a useful prior for representation learning. A\nlow-dimensional thought or conscious state is analogous to a sentence: it\ninvolves only a few variables and yet can make a statement with very high\nprobability of being true. This is consistent with a joint distribution (over\nhigh-level concepts) which has the form of a sparse factor graph, i.e., where\nthe dependencies captured by each factor of the factor graph involve only very\nfew variables while creating a strong dip in the overall energy function. The\nconsciousness prior also makes it natural to map conscious states to natural\nlanguage utterances or to express classical AI knowledge in a form similar to\nfacts and rules, albeit capturing uncertainty as well as efficient search\nmechanisms implemented by attention mechanisms.\n", "versions": [{"version": "v1", "created": "Mon, 25 Sep 2017 15:59:11 GMT"}, {"version": "v2", "created": "Mon, 2 Dec 2019 22:53:39 GMT"}], "update_date": "2019-12-04", "authors_parsed": [["Bengio", "Yoshua", ""]]}, {"id": "1709.08600", "submitter": "Maxim Grechkin", "authors": "Maxim Grechkin, Hoifung Poon, Bill Howe", "title": "EZLearn: Exploiting Organic Supervision in Large-Scale Data Annotation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Many real-world applications require automated data annotation, such as\nidentifying tissue origins based on gene expressions and classifying images\ninto semantic categories. Annotation classes are often numerous and subject to\nchanges over time, and annotating examples has become the major bottleneck for\nsupervised learning methods. In science and other high-value domains, large\nrepositories of data samples are often available, together with two sources of\norganic supervision: a lexicon for the annotation classes, and text\ndescriptions that accompany some data samples. Distant supervision has emerged\nas a promising paradigm for exploiting such indirect supervision by\nautomatically annotating examples where the text description contains a class\nmention in the lexicon. However, due to linguistic variations and ambiguities,\nsuch training data is inherently noisy, which limits the accuracy of this\napproach. In this paper, we introduce an auxiliary natural language processing\nsystem for the text modality, and incorporate co-training to reduce noise and\naugment signal in distant supervision. Without using any manually labeled data,\nour EZLearn system learned to accurately annotate data samples in functional\ngenomics and scientific figure comprehension, substantially outperforming\nstate-of-the-art supervised methods trained on tens of thousands of annotated\nexamples.\n", "versions": [{"version": "v1", "created": "Mon, 25 Sep 2017 17:10:46 GMT"}, {"version": "v2", "created": "Sat, 9 Dec 2017 16:16:57 GMT"}, {"version": "v3", "created": "Mon, 2 Jul 2018 00:03:11 GMT"}], "update_date": "2018-07-03", "authors_parsed": [["Grechkin", "Maxim", ""], ["Poon", "Hoifung", ""], ["Howe", "Bill", ""]]}, {"id": "1709.08607", "submitter": "Maxim Borisyak", "authors": "Maxim Borisyak, Fedor Ratnikov, Denis Derkach and Andrey Ustyuzhanin", "title": "Towards automation of data quality system for CERN CMS experiment", "comments": null, "journal-ref": null, "doi": "10.1088/1742-6596/898/9/092041", "report-no": null, "categories": "physics.data-an cs.AI cs.LG hep-ex", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Daily operation of a large-scale experiment is a challenging task,\nparticularly from perspectives of routine monitoring of quality for data being\ntaken. We describe an approach that uses Machine Learning for the automated\nsystem to monitor data quality, which is based on partial use of data qualified\nmanually by detector experts. The system automatically classifies marginal\ncases: both of good an bad data, and use human expert decision to classify\nremaining \"grey area\" cases.\n  This study uses collision data collected by the CMS experiment at LHC in\n2010. We demonstrate that proposed workflow is able to automatically process at\nleast 20\\% of samples without noticeable degradation of the result.\n", "versions": [{"version": "v1", "created": "Mon, 25 Sep 2017 17:24:15 GMT"}], "update_date": "2017-12-06", "authors_parsed": [["Borisyak", "Maxim", ""], ["Ratnikov", "Fedor", ""], ["Derkach", "Denis", ""], ["Ustyuzhanin", "Andrey", ""]]}, {"id": "1709.08624", "submitter": "Weinan Zhang", "authors": "Jiaxian Guo, Sidi Lu, Han Cai, Weinan Zhang, Yong Yu, Jun Wang", "title": "Long Text Generation via Adversarial Training with Leaked Information", "comments": "14 pages, AAAI 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Automatically generating coherent and semantically meaningful text has many\napplications in machine translation, dialogue systems, image captioning, etc.\nRecently, by combining with policy gradient, Generative Adversarial Nets (GAN)\nthat use a discriminative model to guide the training of the generative model\nas a reinforcement learning policy has shown promising results in text\ngeneration. However, the scalar guiding signal is only available after the\nentire text has been generated and lacks intermediate information about text\nstructure during the generative process. As such, it limits its success when\nthe length of the generated text samples is long (more than 20 words). In this\npaper, we propose a new framework, called LeakGAN, to address the problem for\nlong text generation. We allow the discriminative net to leak its own\nhigh-level extracted features to the generative net to further help the\nguidance. The generator incorporates such informative signals into all\ngeneration steps through an additional Manager module, which takes the\nextracted features of current generated words and outputs a latent vector to\nguide the Worker module for next-word generation. Our extensive experiments on\nsynthetic data and various real-world tasks with Turing test demonstrate that\nLeakGAN is highly effective in long text generation and also improves the\nperformance in short text generation scenarios. More importantly, without any\nsupervision, LeakGAN would be able to implicitly learn sentence structures only\nthrough the interaction between Manager and Worker.\n", "versions": [{"version": "v1", "created": "Sun, 24 Sep 2017 13:35:08 GMT"}, {"version": "v2", "created": "Fri, 8 Dec 2017 18:53:52 GMT"}], "update_date": "2017-12-11", "authors_parsed": [["Guo", "Jiaxian", ""], ["Lu", "Sidi", ""], ["Cai", "Han", ""], ["Zhang", "Weinan", ""], ["Yu", "Yong", ""], ["Wang", "Jun", ""]]}, {"id": "1709.08669", "submitter": "Konstantina Christakopoulou", "authors": "Konstantina Christakopoulou, Adam Tauman Kalai", "title": "Glass-Box Program Synthesis: A Machine Learning Approach", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recently proposed models which learn to write computer programs from data use\neither input/output examples or rich execution traces. Instead, we argue that a\nnovel alternative is to use a glass-box loss function, given as a program\nitself that can be directly inspected. Glass-box optimization covers a wide\nrange of problems, from computing the greatest common divisor of two integers,\nto learning-to-learn problems.\n  In this paper, we present an intelligent search system which learns, given\nthe partial program and the glass-box problem, the probabilities over the space\nof programs. We empirically demonstrate that our informed search procedure\nleads to significant improvements compared to brute-force program search, both\nin terms of accuracy and time. For our experiments we use rich context free\ngrammars inspired by number theory, text processing, and algebra. Our results\nshow that (i) performing 4 rounds of our framework typically solves about 70%\nof the target problems, (ii) our framework can improve itself even in domain\nagnostic scenarios, and (iii) it can solve problems that would be otherwise too\nslow to solve with brute-force search.\n", "versions": [{"version": "v1", "created": "Mon, 25 Sep 2017 18:43:56 GMT"}], "update_date": "2017-09-27", "authors_parsed": [["Christakopoulou", "Konstantina", ""], ["Kalai", "Adam Tauman", ""]]}, {"id": "1709.08694", "submitter": "Paulo Cavalin", "authors": "Luciano Barbosa, Paulo R. Cavalin, Victor Guimaraes and Matthias\n  Kormaksson", "title": "Methodology and Results for the Competition on Semantic Similarity\n  Evaluation and Entailment Recognition for PROPOR 2016", "comments": "Original submission in English, further translated to Portuguese and\n  publised at Linguamatica", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we present the methodology and the results obtained by our\nteams, dubbed Blue Man Group, in the ASSIN (from the Portuguese {\\it\nAvalia\\c{c}\\~ao de Similaridade Sem\\^antica e Infer\\^encia Textual})\ncompetition, held at PROPOR 2016\\footnote{International Conference on the\nComputational Processing of the Portuguese Language -\nhttp://propor2016.di.fc.ul.pt/}. Our team's strategy consisted of evaluating\nmethods based on semantic word vectors, following two distinct directions: 1)\nto make use of low-dimensional, compact, feature sets, and 2) deep\nlearning-based strategies dealing with high-dimensional feature vectors.\nEvaluation results demonstrated that the first strategy was more promising, so\nthat the results from the second strategy have been discarded. As a result, by\nconsidering the best run of each of the six teams, we have been able to achieve\nthe best accuracy and F1 values in entailment recognition, in the Brazilian\nPortuguese set, and the best F1 score overall. In the semantic similarity task,\nour team was ranked second in the Brazilian Portuguese set, and third\nconsidering both sets.\n", "versions": [{"version": "v1", "created": "Tue, 19 Sep 2017 18:02:51 GMT"}], "update_date": "2017-09-27", "authors_parsed": [["Barbosa", "Luciano", ""], ["Cavalin", "Paulo R.", ""], ["Guimaraes", "Victor", ""], ["Kormaksson", "Matthias", ""]]}, {"id": "1709.08728", "submitter": "Weiran Wang", "authors": "Weiran Wang, Nathan Srebro", "title": "Stochastic Nonconvex Optimization with Large Minibatches", "comments": "Accepted by the ALT 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study stochastic optimization of nonconvex loss functions, which are\ntypical objectives for training neural networks. We propose stochastic\napproximation algorithms which optimize a series of regularized, nonlinearized\nlosses on large minibatches of samples, using only first-order gradient\ninformation. Our algorithms provably converge to an approximate critical point\nof the expected objective with faster rates than minibatch stochastic gradient\ndescent, and facilitate better parallelization by allowing larger minibatches.\n", "versions": [{"version": "v1", "created": "Mon, 25 Sep 2017 21:20:32 GMT"}, {"version": "v2", "created": "Thu, 28 Sep 2017 14:46:13 GMT"}, {"version": "v3", "created": "Sun, 12 Nov 2017 19:50:07 GMT"}, {"version": "v4", "created": "Fri, 8 Mar 2019 22:54:46 GMT"}], "update_date": "2019-03-12", "authors_parsed": [["Wang", "Weiran", ""], ["Srebro", "Nathan", ""]]}, {"id": "1709.08730", "submitter": "Gustavo Daniel Sosa Cabrera", "authors": "Gustavo Sosa-Cabrera, Miguel Garc\\'ia-Torres, Santiago G\\'omez,\n  Christian Schaerer, Federico Divina", "title": "Understanding a Version of Multivariate Symmetric Uncertainty to assist\n  in Feature Selection", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we analyze the behavior of the multivariate symmetric\nuncertainty (MSU) measure through the use of statistical simulation techniques\nunder various mixes of informative and non-informative randomly generated\nfeatures. Experiments show how the number of attributes, their cardinalities,\nand the sample size affect the MSU. We discovered a condition that preserves\ngood quality in the MSU under different combinations of these three factors,\nproviding a new useful criterion to help drive the process of dimension\nreduction.\n", "versions": [{"version": "v1", "created": "Mon, 25 Sep 2017 21:41:20 GMT"}], "update_date": "2017-09-27", "authors_parsed": [["Sosa-Cabrera", "Gustavo", ""], ["Garc\u00eda-Torres", "Miguel", ""], ["G\u00f3mez", "Santiago", ""], ["Schaerer", "Christian", ""], ["Divina", "Federico", ""]]}, {"id": "1709.08802", "submitter": "Feng Xiao", "authors": "Wenwen Tu, Feng Xiao, Liping Fu, Guangyuan Pan", "title": "A Deep Learning Model for Traffic Flow State Classification Based on\n  Smart Phone Sensor Data", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This study proposes a Deep Belief Network model to classify traffic flow\nstates. The model is capable of processing massive, high-density, and\nnoise-contaminated data sets generated from smartphone sensors. The statistical\nfeatures of Vehicle acceleration, angular acceleration, and GPS speed data,\nrecorded by smartphone software, are analyzed, and then used as input for\ntraffic flow state classification. Data from a five-day experiment is used to\ntrain and test the proposed model. A total of 747,856 sets of data are\ngenerated and used for both traffic flow states classification and sensitivity\nanalysis of input variables. The result shows that the proposed Deep Belief\nNetwork model is superior to traditional machine learning methods in both\nclassification performance and computational efficiency.\n", "versions": [{"version": "v1", "created": "Tue, 26 Sep 2017 03:48:41 GMT"}], "update_date": "2017-09-27", "authors_parsed": [["Tu", "Wenwen", ""], ["Xiao", "Feng", ""], ["Fu", "Liping", ""], ["Pan", "Guangyuan", ""]]}, {"id": "1709.08830", "submitter": "Yu Cheng", "authors": "Devu Manikantan Shilay, Kin Gwn Lorey, Tianshu Weiz, Teems Lovetty,\n  and Yu Cheng", "title": "Catching Anomalous Distributed Photovoltaics: An Edge-based Multi-modal\n  Anomaly Detection", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SY cs.CR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A significant challenge in energy system cyber security is the current\ninability to detect cyber-physical attacks targeting and originating from\ndistributed grid-edge devices such as photovoltaics (PV) panels, smart flexible\nloads, and electric vehicles. We address this concern by designing and\ndeveloping a distributed, multi-modal anomaly detection approach that can sense\nthe health of the device and the electric power grid from the edge. This is\nrealized by exploiting unsupervised machine learning algorithms on multiple\nsources of time-series data, fusing these multiple local observations and\nflagging anomalies when a deviation from the normal behavior is observed.\n  We particularly focus on the cyber-physical threats to the distributed PVs\nthat has the potential to cause local disturbances or grid instabilities by\ncreating supply-demand mismatch, reverse power flow conditions etc. We use an\nopen source power system simulation tool called GridLAB-D, loaded with real\nsmart home and solar datasets to simulate the smart grid scenarios and to\nillustrate the impact of PV attacks on the power system. Various attacks\ntargeting PV panels that create voltage fluctuations, reverse power flow etc\nwere designed and performed. We observe that while individual unsupervised\nlearning algorithms such as OCSVMs, Corrupt RF and PCA surpasses in identifying\nparticular attack type, PCA with Convex Hull outperforms all algorithms in\nidentifying all designed attacks with a true positive rate of 83.64% and an\naccuracy of 95.78%. Our key insight is that due to the heterogeneous nature of\nthe distribution grid and the uncertainty in the type of the attack being\nlaunched, relying on single mode of information for defense can lead to\nincreased false alarms and missed detection rates as one can design attacks to\nhide within those uncertainties and remain stealthy.\n", "versions": [{"version": "v1", "created": "Tue, 26 Sep 2017 04:54:46 GMT"}], "update_date": "2017-09-27", "authors_parsed": [["Shilay", "Devu Manikantan", ""], ["Lorey", "Kin Gwn", ""], ["Weiz", "Tianshu", ""], ["Lovetty", "Teems", ""], ["Cheng", "Yu", ""]]}, {"id": "1709.08842", "submitter": "Jonas Langhabel", "authors": "Jonas Langhabel", "title": "Learning a Predictive Model for Music Using PULSE", "comments": "Master's Thesis", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.SD eess.AS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Predictive models for music are studied by researchers of algorithmic\ncomposition, the cognitive sciences and machine learning. They serve as base\nmodels for composition, can simulate human prediction and provide a\nmultidisciplinary application domain for learning algorithms. A particularly\nwell established and constantly advanced subtask is the prediction of\nmonophonic melodies. As melodies typically involve non-Markovian dependencies\ntheir prediction requires a capable learning algorithm. In this thesis, I apply\nthe recent feature discovery and learning method PULSE to the realm of symbolic\nmusic modeling. PULSE is comprised of a feature generating operation and\nL1-regularized optimization. These are used to iteratively expand and cull the\nfeature set, effectively exploring feature spaces that are too large for common\nfeature selection approaches. I design a general Python framework for PULSE,\npropose task-optimized feature generating operations and various\nmusic-theoretically motivated features that are evaluated on a standard corpus\nof monophonic folk and chorale melodies. The proposed method significantly\noutperforms comparable state-of-the-art models. I further discuss the free\nparameters of the learning algorithm and analyze the feature composition of the\nlearned models. The models learned by PULSE afford an easy inspection and are\nmusicologically interpreted for the first time.\n", "versions": [{"version": "v1", "created": "Tue, 26 Sep 2017 05:47:43 GMT"}], "update_date": "2017-10-04", "authors_parsed": [["Langhabel", "Jonas", ""]]}, {"id": "1709.08850", "submitter": "Emmanouil Antonios Platanios", "authors": "Emmanouil Antonios Platanios and Ashish Kapoor and Eric Horvitz", "title": "Active Learning amidst Logical Knowledge", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Structured prediction is ubiquitous in applications of machine learning such\nas knowledge extraction and natural language processing. Structure often can be\nformulated in terms of logical constraints. We consider the question of how to\nperform efficient active learning in the presence of logical constraints among\nvariables inferred by different classifiers. We propose several methods and\nprovide theoretical results that demonstrate the inappropriateness of employing\nuncertainty guided sampling, a commonly used active learning method.\nFurthermore, experiments on ten different datasets demonstrate that the methods\nsignificantly outperform alternatives in practice. The results are of practical\nsignificance in situations where labeled data is scarce.\n", "versions": [{"version": "v1", "created": "Tue, 26 Sep 2017 06:13:49 GMT"}], "update_date": "2017-09-27", "authors_parsed": [["Platanios", "Emmanouil Antonios", ""], ["Kapoor", "Ashish", ""], ["Horvitz", "Eric", ""]]}, {"id": "1709.08853", "submitter": "Xianggen Liu", "authors": "Zhengdong Lu and Xianggen Liu and Haotian Cui and Yukun Yan and Daqi\n  Zheng", "title": "Object-oriented Neural Programming (OONP) for Document Understanding", "comments": "accepted by ACL 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CL cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose Object-oriented Neural Programming (OONP), a framework for\nsemantically parsing documents in specific domains. Basically, OONP reads a\ndocument and parses it into a predesigned object-oriented data structure\n(referred to as ontology in this paper) that reflects the domain-specific\nsemantics of the document. An OONP parser models semantic parsing as a decision\nprocess: a neural net-based Reader sequentially goes through the document, and\nduring the process it builds and updates an intermediate ontology to summarize\nits partial understanding of the text it covers. OONP supports a rich family of\noperations (both symbolic and differentiable) for composing the ontology, and a\nbig variety of forms (both symbolic and differentiable) for representing the\nstate and the document. An OONP parser can be trained with supervision of\ndifferent forms and strength, including supervised learning (SL) ,\nreinforcement learning (RL) and hybrid of the two. Our experiments on both\nsynthetic and real-world document parsing tasks have shown that OONP can learn\nto handle fairly complicated ontology with training data of modest sizes.\n", "versions": [{"version": "v1", "created": "Tue, 26 Sep 2017 06:17:35 GMT"}, {"version": "v2", "created": "Thu, 28 Sep 2017 06:56:18 GMT"}, {"version": "v3", "created": "Tue, 3 Oct 2017 15:07:54 GMT"}, {"version": "v4", "created": "Sun, 8 Oct 2017 07:36:03 GMT"}, {"version": "v5", "created": "Thu, 19 Jul 2018 11:21:07 GMT"}, {"version": "v6", "created": "Wed, 25 Jul 2018 08:56:09 GMT"}], "update_date": "2018-07-26", "authors_parsed": [["Lu", "Zhengdong", ""], ["Liu", "Xianggen", ""], ["Cui", "Haotian", ""], ["Yan", "Yukun", ""], ["Zheng", "Daqi", ""]]}, {"id": "1709.08878", "submitter": "Kelvin Guu", "authors": "Kelvin Guu, Tatsunori B. Hashimoto, Yonatan Oren, Percy Liang", "title": "Generating Sentences by Editing Prototypes", "comments": "14 pages, Transactions of the Association for Computational\n  Linguistics (TACL), 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a new generative model of sentences that first samples a prototype\nsentence from the training corpus and then edits it into a new sentence.\nCompared to traditional models that generate from scratch either left-to-right\nor by first sampling a latent sentence vector, our prototype-then-edit model\nimproves perplexity on language modeling and generates higher quality outputs\naccording to human evaluation. Furthermore, the model gives rise to a latent\nedit vector that captures interpretable semantics such as sentence similarity\nand sentence-level analogies.\n", "versions": [{"version": "v1", "created": "Tue, 26 Sep 2017 08:11:33 GMT"}, {"version": "v2", "created": "Fri, 7 Sep 2018 04:57:15 GMT"}], "update_date": "2018-09-10", "authors_parsed": [["Guu", "Kelvin", ""], ["Hashimoto", "Tatsunori B.", ""], ["Oren", "Yonatan", ""], ["Liang", "Percy", ""]]}, {"id": "1709.08894", "submitter": "Henning Petzka", "authors": "Henning Petzka, Asja Fischer, Denis Lukovnicov", "title": "On the regularization of Wasserstein GANs", "comments": "Published as a conference paper at ICLR 2018. * Henning Petzka and\n  Asja Fischer contributed equally to this work (11 pages +13 pages appendix)", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Since their invention, generative adversarial networks (GANs) have become a\npopular approach for learning to model a distribution of real (unlabeled) data.\nConvergence problems during training are overcome by Wasserstein GANs which\nminimize the distance between the model and the empirical distribution in terms\nof a different metric, but thereby introduce a Lipschitz constraint into the\noptimization problem. A simple way to enforce the Lipschitz constraint on the\nclass of functions, which can be modeled by the neural network, is weight\nclipping. It was proposed that training can be improved by instead augmenting\nthe loss by a regularization term that penalizes the deviation of the gradient\nof the critic (as a function of the network's input) from one. We present\ntheoretical arguments why using a weaker regularization term enforcing the\nLipschitz constraint is preferable. These arguments are supported by\nexperimental results on toy data sets.\n", "versions": [{"version": "v1", "created": "Tue, 26 Sep 2017 08:53:41 GMT"}, {"version": "v2", "created": "Mon, 5 Mar 2018 13:55:14 GMT"}], "update_date": "2018-03-06", "authors_parsed": [["Petzka", "Henning", ""], ["Fischer", "Asja", ""], ["Lukovnicov", "Denis", ""]]}, {"id": "1709.09002", "submitter": "Daniel Larremore", "authors": "Caterina De Bacco, Daniel B. Larremore and Cristopher Moore", "title": "A physical model for efficient ranking in networks", "comments": "SpringRank implementations in Python, MATLAB, SAS/IML at\n  https://github.com/cdebacco/SpringRank", "journal-ref": null, "doi": null, "report-no": null, "categories": "physics.soc-ph cs.LG cs.SI physics.data-an", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a physically-inspired model and an efficient algorithm to infer\nhierarchical rankings of nodes in directed networks. It assigns real-valued\nranks to nodes rather than simply ordinal ranks, and it formalizes the\nassumption that interactions are more likely to occur between individuals with\nsimilar ranks. It provides a natural statistical significance test for the\ninferred hierarchy, and it can be used to perform inference tasks such as\npredicting the existence or direction of edges. The ranking is obtained by\nsolving a linear system of equations, which is sparse if the network is; thus\nthe resulting algorithm is extremely efficient and scalable. We illustrate\nthese findings by analyzing real and synthetic data, including datasets from\nanimal behavior, faculty hiring, social support networks, and sports\ntournaments. We show that our method often outperforms a variety of others, in\nboth speed and accuracy, in recovering the underlying ranks and predicting edge\ndirections.\n", "versions": [{"version": "v1", "created": "Sun, 3 Sep 2017 09:02:57 GMT"}, {"version": "v2", "created": "Wed, 27 Sep 2017 04:10:06 GMT"}, {"version": "v3", "created": "Wed, 20 Dec 2017 22:48:48 GMT"}, {"version": "v4", "created": "Wed, 13 Jun 2018 15:35:21 GMT"}], "update_date": "2018-06-14", "authors_parsed": [["De Bacco", "Caterina", ""], ["Larremore", "Daniel B.", ""], ["Moore", "Cristopher", ""]]}, {"id": "1709.09018", "submitter": "Zhi-Hua Zhou", "authors": "Ji Feng and Zhi-Hua Zhou", "title": "AutoEncoder by Forest", "comments": null, "journal-ref": "AAAI 2018", "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Auto-encoding is an important task which is typically realized by deep neural\nnetworks (DNNs) such as convolutional neural networks (CNN). In this paper, we\npropose EncoderForest (abbrv. eForest), the first tree ensemble based\nauto-encoder. We present a procedure for enabling forests to do backward\nreconstruction by utilizing the equivalent classes defined by decision paths of\nthe trees, and demonstrate its usage in both supervised and unsupervised\nsetting. Experiments show that, compared with DNN autoencoders, eForest is able\nto obtain lower reconstruction error with fast training speed, while the model\nitself is reusable and damage-tolerable.\n", "versions": [{"version": "v1", "created": "Tue, 26 Sep 2017 13:54:34 GMT"}], "update_date": "2020-07-07", "authors_parsed": [["Feng", "Ji", ""], ["Zhou", "Zhi-Hua", ""]]}, {"id": "1709.09069", "submitter": "Andreas Kirsch", "authors": "Andreas Kirsch", "title": "MDP environments for the OpenAI Gym", "comments": "6 pages, 2 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The OpenAI Gym provides researchers and enthusiasts with simple to use\nenvironments for reinforcement learning. Even the simplest environment have a\nlevel of complexity that can obfuscate the inner workings of RL approaches and\nmake debugging difficult. This whitepaper describes a Python framework that\nmakes it very easy to create simple Markov-Decision-Process environments\nprogrammatically by specifying state transitions and rewards of deterministic\nand non-deterministic MDPs in a domain-specific language in Python. It then\npresents results and visualizations created with this MDP framework.\n", "versions": [{"version": "v1", "created": "Tue, 26 Sep 2017 14:52:23 GMT"}], "update_date": "2017-09-27", "authors_parsed": [["Kirsch", "Andreas", ""]]}, {"id": "1709.09130", "submitter": "Souradeep Dutta", "authors": "Souradeep Dutta, Susmit Jha, Sriram Sanakaranarayanan, Ashish Tiwari", "title": "Output Range Analysis for Deep Neural Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep neural networks (NN) are extensively used for machine learning tasks\nsuch as image classification, perception and control of autonomous systems.\nIncreasingly, these deep NNs are also been deployed in high-assurance\napplications. Thus, there is a pressing need for developing techniques to\nverify neural networks to check whether certain user-expected properties are\nsatisfied. In this paper, we study a specific verification problem of computing\na guaranteed range for the output of a deep neural network given a set of\ninputs represented as a convex polyhedron. Range estimation is a key primitive\nfor verifying deep NNs. We present an efficient range estimation algorithm that\nuses a combination of local search and linear programming problems to\nefficiently find the maximum and minimum values taken by the outputs of the NN\nover the given input set. In contrast to recently proposed \"monolithic\"\noptimization approaches, we use local gradient descent to repeatedly find and\neliminate local minima of the function. The final global optimum is certified\nusing a mixed integer programming instance. We implement our approach and\ncompare it with Reluplex, a recently proposed solver for deep neural networks.\nWe demonstrate the effectiveness of the proposed approach for verification of\nNNs used in automated control as well as those used in classification.\n", "versions": [{"version": "v1", "created": "Tue, 26 Sep 2017 16:56:15 GMT"}], "update_date": "2017-09-27", "authors_parsed": [["Dutta", "Souradeep", ""], ["Jha", "Susmit", ""], ["Sanakaranarayanan", "Sriram", ""], ["Tiwari", "Ashish", ""]]}, {"id": "1709.09161", "submitter": "Emmanuel Dufourq Mr", "authors": "Emmanuel Dufourq, Bruce A. Bassett", "title": "EDEN: Evolutionary Deep Networks for Efficient Machine Learning", "comments": "7 pages, 3 figures, 3 tables and see video\n  https://vimeo.com/234510097", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG cs.NE", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Deep neural networks continue to show improved performance with increasing\ndepth, an encouraging trend that implies an explosion in the possible\npermutations of network architectures and hyperparameters for which there is\nlittle intuitive guidance. To address this increasing complexity, we propose\nEvolutionary DEep Networks (EDEN), a computationally efficient\nneuro-evolutionary algorithm which interfaces to any deep neural network\nplatform, such as TensorFlow. We show that EDEN evolves simple yet successful\narchitectures built from embedding, 1D and 2D convolutional, max pooling and\nfully connected layers along with their hyperparameters. Evaluation of EDEN\nacross seven image and sentiment classification datasets shows that it reliably\nfinds good networks -- and in three cases achieves state-of-the-art results --\neven on a single GPU, in just 6-24 hours. Our study provides a first attempt at\napplying neuro-evolution to the creation of 1D convolutional networks for\nsentiment analysis including the optimisation of the embedding layer.\n", "versions": [{"version": "v1", "created": "Tue, 26 Sep 2017 17:56:31 GMT"}], "update_date": "2017-09-27", "authors_parsed": [["Dufourq", "Emmanuel", ""], ["Bassett", "Bruce A.", ""]]}, {"id": "1709.09233", "submitter": "Dan Nguyen", "authors": "Dan Nguyen, Troy Long, Xun Jia, Weiguo Lu, Xuejun Gu, Zohaib Iqbal,\n  Steve Jiang", "title": "A feasibility study for predicting optimal radiation therapy dose\n  distributions of prostate cancer patients from patient anatomy using deep\n  learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "physics.med-ph cs.AI cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  With the advancement of treatment modalities in radiation therapy for cancer\npatients, outcomes have improved, but at the cost of increased treatment plan\ncomplexity and planning time. The accurate prediction of dose distributions\nwould alleviate this issue by guiding clinical plan optimization to save time\nand maintain high quality plans. We have modified a convolutional deep network\nmodel, U-net (originally designed for segmentation purposes), for predicting\ndose from patient image contours of the planning target volume (PTV) and organs\nat risk (OAR). We show that, as an example, we are able to accurately predict\nthe dose of intensity-modulated radiation therapy (IMRT) for prostate cancer\npatients, where the average Dice similarity coefficient is 0.91 when comparing\nthe predicted vs. true isodose volumes between 0% and 100% of the prescription\ndose. The average value of the absolute differences in [max, mean] dose is\nfound to be under 5% of the prescription dose, specifically for each structure\nis [1.80%, 1.03%](PTV), [1.94%, 4.22%](Bladder), [1.80%, 0.48%](Body), [3.87%,\n1.79%](L Femoral Head), [5.07%, 2.55%](R Femoral Head), and [1.26%,\n1.62%](Rectum) of the prescription dose. We thus managed to map a desired\nradiation dose distribution from a patient's PTV and OAR contours. As an\nadditional advantage, relatively little data was used in the techniques and\nmodels described in this paper.\n", "versions": [{"version": "v1", "created": "Tue, 26 Sep 2017 19:43:29 GMT"}, {"version": "v2", "created": "Mon, 26 Mar 2018 06:26:06 GMT"}, {"version": "v3", "created": "Wed, 23 May 2018 23:45:25 GMT"}, {"version": "v4", "created": "Thu, 29 Nov 2018 21:34:27 GMT"}], "update_date": "2018-12-03", "authors_parsed": [["Nguyen", "Dan", ""], ["Long", "Troy", ""], ["Jia", "Xun", ""], ["Lu", "Weiguo", ""], ["Gu", "Xuejun", ""], ["Iqbal", "Zohaib", ""], ["Jiang", "Steve", ""]]}, {"id": "1709.09268", "submitter": "Kamran Kowsari", "authors": "Kamran Kowsari, Nima Bari, Roman Vichr, Farhad A. Goodarzi", "title": "FSL-BM: Fuzzy Supervised Learning with Binary Meta-Feature for\n  Classification", "comments": "FICC2018", "journal-ref": null, "doi": "10.1007/978-3-030-03405-4_46", "report-no": null, "categories": "cs.LG cs.AI stat.AP stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper introduces a novel real-time Fuzzy Supervised Learning with Binary\nMeta-Feature (FSL-BM) for big data classification task. The study of real-time\nalgorithms addresses several major concerns, which are namely: accuracy, memory\nconsumption, and ability to stretch assumptions and time complexity. Attaining\na fast computational model providing fuzzy logic and supervised learning is one\nof the main challenges in the machine learning. In this research paper, we\npresent FSL-BM algorithm as an efficient solution of supervised learning with\nfuzzy logic processing using binary meta-feature representation using Hamming\nDistance and Hash function to relax assumptions. While many studies focused on\nreducing time complexity and increasing accuracy during the last decade, the\nnovel contribution of this proposed solution comes through integration of\nHamming Distance, Hash function, binary meta-features, binary classification to\nprovide real time supervised method. Hash Tables (HT) component gives a fast\naccess to existing indices; and therefore, the generation of new indices in a\nconstant time complexity, which supersedes existing fuzzy supervised algorithms\nwith better or comparable results. To summarize, the main contribution of this\ntechnique for real-time Fuzzy Supervised Learning is to represent hypothesis\nthrough binary input as meta-feature space and creating the Fuzzy Supervised\nHash table to train and validate model.\n", "versions": [{"version": "v1", "created": "Tue, 26 Sep 2017 21:52:41 GMT"}, {"version": "v2", "created": "Wed, 15 Nov 2017 23:34:10 GMT"}], "update_date": "2020-12-09", "authors_parsed": [["Kowsari", "Kamran", ""], ["Bari", "Nima", ""], ["Vichr", "Roman", ""], ["Goodarzi", "Farhad A.", ""]]}, {"id": "1709.09346", "submitter": "Nan Ding", "authors": "Nan Ding, Radu Soricut", "title": "Cold-Start Reinforcement Learning with Softmax Policy Gradient", "comments": "Conference on Neural Information Processing Systems 2017. Main paper\n  and supplementary material", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Policy-gradient approaches to reinforcement learning have two common and\nundesirable overhead procedures, namely warm-start training and sample variance\nreduction. In this paper, we describe a reinforcement learning method based on\na softmax value function that requires neither of these procedures. Our method\ncombines the advantages of policy-gradient methods with the efficiency and\nsimplicity of maximum-likelihood approaches. We apply this new cold-start\nreinforcement learning method in training sequence generation models for\nstructured output prediction problems. Empirical evidence validates this method\non automatic summarization and image captioning tasks.\n", "versions": [{"version": "v1", "created": "Wed, 27 Sep 2017 06:04:03 GMT"}, {"version": "v2", "created": "Fri, 13 Oct 2017 21:20:00 GMT"}], "update_date": "2017-10-17", "authors_parsed": [["Ding", "Nan", ""], ["Soricut", "Radu", ""]]}, {"id": "1709.09393", "submitter": "Shizhao Sun", "authors": "Shizhao Sun, Wei Chen, Jiang Bian, Xiaoguang Liu, Tie-Yan Liu", "title": "Slim-DP: A Light Communication Data Parallelism for DNN", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Data parallelism has emerged as a necessary technique to accelerate the\ntraining of deep neural networks (DNN). In a typical data parallelism approach,\nthe local workers push the latest updates of all the parameters to the\nparameter server and pull all merged parameters back periodically. However,\nwith the increasing size of DNN models and the large number of workers in\npractice, this typical data parallelism cannot achieve satisfactory training\nacceleration, since it usually suffers from the heavy communication cost due to\ntransferring huge amount of information between workers and the parameter\nserver. In-depth understanding on DNN has revealed that it is usually highly\nredundant, that deleting a considerable proportion of the parameters will not\nsignificantly decline the model performance. This redundancy property exposes a\ngreat opportunity to reduce the communication cost by only transferring the\ninformation of those significant parameters during the parallel training.\nHowever, if we only transfer information of temporally significant parameters\nof the latest snapshot, we may miss the parameters that are insignificant now\nbut have potential to become significant as the training process goes on. To\nthis end, we design an Explore-Exploit framework to dynamically choose the\nsubset to be communicated, which is comprised of the significant parameters in\nthe latest snapshot together with a random explored set of other parameters. We\npropose to measure the significance of the parameter by the combination of its\nmagnitude and gradient. Our experimental results demonstrate that our proposed\nSlim-DP can achieve better training acceleration than standard data parallelism\nand its communication-efficient version by saving communication time without\nloss of accuracy.\n", "versions": [{"version": "v1", "created": "Wed, 27 Sep 2017 08:58:40 GMT"}], "update_date": "2017-09-28", "authors_parsed": [["Sun", "Shizhao", ""], ["Chen", "Wei", ""], ["Bian", "Jiang", ""], ["Liu", "Xiaoguang", ""], ["Liu", "Tie-Yan", ""]]}, {"id": "1709.09480", "submitter": "Daniel Hein", "authors": "Daniel Hein, Stefan Depeweg, Michel Tokic, Steffen Udluft, Alexander\n  Hentschel, Thomas A. Runkler, Volkmar Sterzing", "title": "A Benchmark Environment Motivated by Industrial Control Problems", "comments": null, "journal-ref": "2017 IEEE Symposium Series on Computational Intelligence (SSCI)", "doi": "10.1109/SSCI.2017.8280935", "report-no": null, "categories": "cs.AI cs.LG cs.SY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In the research area of reinforcement learning (RL), frequently novel and\npromising methods are developed and introduced to the RL community. However,\nalthough many researchers are keen to apply their methods on real-world\nproblems, implementing such methods in real industry environments often is a\nfrustrating and tedious process. Generally, academic research groups have only\nlimited access to real industrial data and applications. For this reason, new\nmethods are usually developed, evaluated and compared by using artificial\nsoftware benchmarks. On one hand, these benchmarks are designed to provide\ninterpretable RL training scenarios and detailed insight into the learning\nprocess of the method on hand. On the other hand, they usually do not share\nmuch similarity with industrial real-world applications. For this reason we\nused our industry experience to design a benchmark which bridges the gap\nbetween freely available, documented, and motivated artificial benchmarks and\nproperties of real industrial problems. The resulting industrial benchmark (IB)\nhas been made publicly available to the RL community by publishing its Java and\nPython code, including an OpenAI Gym wrapper, on Github. In this paper we\nmotivate and describe in detail the IB's dynamics and identify prototypic\nexperimental settings that capture common situations in real-world industry\ncontrol problems.\n", "versions": [{"version": "v1", "created": "Wed, 27 Sep 2017 13:03:52 GMT"}, {"version": "v2", "created": "Tue, 6 Feb 2018 10:59:19 GMT"}], "update_date": "2018-02-07", "authors_parsed": [["Hein", "Daniel", ""], ["Depeweg", "Stefan", ""], ["Tokic", "Michel", ""], ["Udluft", "Steffen", ""], ["Hentschel", "Alexander", ""], ["Runkler", "Thomas A.", ""], ["Sterzing", "Volkmar", ""]]}, {"id": "1709.09578", "submitter": "Ivan Sosnovik", "authors": "Ivan Sosnovik, Ivan Oseledets", "title": "Neural networks for topology optimization", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG math.NA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this research, we propose a deep learning based approach for speeding up\nthe topology optimization methods. The problem we seek to solve is the layout\nproblem. The main novelty of this work is to state the problem as an image\nsegmentation task. We leverage the power of deep learning methods as the\nefficient pixel-wise image labeling technique to perform the topology\noptimization. We introduce convolutional encoder-decoder architecture and the\noverall approach of solving the above-described problem with high performance.\nThe conducted experiments demonstrate the significant acceleration of the\noptimization process. The proposed approach has excellent generalization\nproperties. We demonstrate the ability of the application of the proposed model\nto other problems. The successful results, as well as the drawbacks of the\ncurrent method, are discussed.\n", "versions": [{"version": "v1", "created": "Wed, 27 Sep 2017 15:22:00 GMT"}], "update_date": "2017-09-28", "authors_parsed": [["Sosnovik", "Ivan", ""], ["Oseledets", "Ivan", ""]]}, {"id": "1709.09582", "submitter": "Karim Ahmed", "authors": "Karim Ahmed and Lorenzo Torresani", "title": "Connectivity Learning in Multi-Branch Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  While much of the work in the design of convolutional networks over the last\nfive years has revolved around the empirical investigation of the importance of\ndepth, filter sizes, and number of feature channels, recent studies have shown\nthat branching, i.e., splitting the computation along parallel but distinct\nthreads and then aggregating their outputs, represents a new promising\ndimension for significant improvements in performance. To combat the complexity\nof design choices in multi-branch architectures, prior work has adopted simple\nstrategies, such as a fixed branching factor, the same input being fed to all\nparallel branches, and an additive combination of the outputs produced by all\nbranches at aggregation points.\n  In this work we remove these predefined choices and propose an algorithm to\nlearn the connections between branches in the network. Instead of being chosen\na priori by the human designer, the multi-branch connectivity is learned\nsimultaneously with the weights of the network by optimizing a single loss\nfunction defined with respect to the end task. We demonstrate our approach on\nthe problem of multi-class image classification using three different datasets\nwhere it yields consistently higher accuracy compared to the state-of-the-art\n\"ResNeXt\" multi-branch network given the same learning capacity.\n", "versions": [{"version": "v1", "created": "Wed, 27 Sep 2017 15:34:21 GMT"}, {"version": "v2", "created": "Thu, 7 Dec 2017 16:57:45 GMT"}], "update_date": "2017-12-08", "authors_parsed": [["Ahmed", "Karim", ""], ["Torresani", "Lorenzo", ""]]}, {"id": "1709.09603", "submitter": "Minhyung Cho", "authors": "Minhyung Cho, Jaehyung Lee", "title": "Riemannian approach to batch normalization", "comments": "to appear at NIPS 2017", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Batch Normalization (BN) has proven to be an effective algorithm for deep\nneural network training by normalizing the input to each neuron and reducing\nthe internal covariate shift. The space of weight vectors in the BN layer can\nbe naturally interpreted as a Riemannian manifold, which is invariant to linear\nscaling of weights. Following the intrinsic geometry of this manifold provides\na new learning rule that is more efficient and easier to analyze. We also\npropose intuitive and effective gradient clipping and regularization methods\nfor the proposed algorithm by utilizing the geometry of the manifold. The\nresulting algorithm consistently outperforms the original BN on various types\nof network architectures and datasets.\n", "versions": [{"version": "v1", "created": "Wed, 27 Sep 2017 16:18:00 GMT"}, {"version": "v2", "created": "Thu, 19 Oct 2017 04:49:45 GMT"}, {"version": "v3", "created": "Tue, 31 Oct 2017 06:42:07 GMT"}], "update_date": "2017-11-01", "authors_parsed": [["Cho", "Minhyung", ""], ["Lee", "Jaehyung", ""]]}, {"id": "1709.09625", "submitter": "Amirhossein Taghvaei", "authors": "Amirhossein Taghvaei, Jin W. Kim, Prashant G. Mehta", "title": "How regularization affects the critical points in linear networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.OC cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper is concerned with the problem of representing and learning a\nlinear transformation using a linear neural network. In recent years, there has\nbeen a growing interest in the study of such networks in part due to the\nsuccesses of deep learning. The main question of this body of research and also\nof this paper pertains to the existence and optimality properties of the\ncritical points of the mean-squared loss function. The primary concern here is\nthe robustness of the critical points with regularization of the loss function.\nAn optimal control model is introduced for this purpose and a learning\nalgorithm (regularized form of backprop) derived for the same using the\nHamilton's formulation of optimal control. The formulation is used to provide a\ncomplete characterization of the critical points in terms of the solutions of a\nnonlinear matrix-valued equation, referred to as the characteristic equation.\nAnalytical and numerical tools from bifurcation theory are used to compute the\ncritical points via the solutions of the characteristic equation. The main\nconclusion is that the critical point diagram can be fundamentally different\neven with arbitrary small amounts of regularization.\n", "versions": [{"version": "v1", "created": "Wed, 27 Sep 2017 17:02:05 GMT"}], "update_date": "2017-09-28", "authors_parsed": [["Taghvaei", "Amirhossein", ""], ["Kim", "Jin W.", ""], ["Mehta", "Prashant G.", ""]]}, {"id": "1709.09676", "submitter": "Mine Alsan Ms", "authors": "Mine Alsan, Ranjitha Prasad and Vincent Y. F. Tan", "title": "Lower Bounds on the Bayes Risk of the Bayesian BTL Model with\n  Applications to Comparison Graphs", "comments": "Accepted for publication in IEEE Journal of Selected Topics in Signal\n  Processing", "journal-ref": null, "doi": "10.1109/JSTSP.2018.2827303", "report-no": null, "categories": "cs.IT cs.LG math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the problem of aggregating pairwise comparisons to obtain a\nconsensus ranking order over a collection of objects. We use the popular\nBradley-Terry-Luce (BTL) model which allows us to probabilistically describe\npairwise comparisons between objects. In particular, we employ the Bayesian BTL\nmodel which allows for meaningful prior assumptions and to cope with situations\nwhere the number of objects is large and the number of comparisons between some\nobjects is small or even zero. For the conventional Bayesian BTL model, we\nderive information-theoretic lower bounds on the Bayes risk of estimators for\nnorm-based distortion functions. We compare the information-theoretic lower\nbound with the Bayesian Cram\\'{e}r-Rao lower bound we derive for the case when\nthe Bayes risk is the mean squared error. We illustrate the utility of the\nbounds through simulations by comparing them with the error performance of an\nexpectation-maximization based inference algorithm proposed for the Bayesian\nBTL model. We draw parallels between pairwise comparisons in the BTL model and\ninter-player games represented as edges in a comparison graph and analyze the\neffect of various graph structures on the lower bounds. We also extend the\ninformation-theoretic and Bayesian Cram\\'{e}r-Rao lower bounds to the more\ngeneral Bayesian BTL model which takes into account home-field advantage.\n", "versions": [{"version": "v1", "created": "Wed, 27 Sep 2017 18:01:41 GMT"}, {"version": "v2", "created": "Fri, 29 Sep 2017 04:36:09 GMT"}, {"version": "v3", "created": "Wed, 3 Jan 2018 14:09:34 GMT"}, {"version": "v4", "created": "Fri, 20 Apr 2018 10:28:38 GMT"}], "update_date": "2019-01-30", "authors_parsed": [["Alsan", "Mine", ""], ["Prasad", "Ranjitha", ""], ["Tan", "Vincent Y. F.", ""]]}, {"id": "1709.09749", "submitter": "Bin Bi", "authors": "Bin Bi and Hao Ma", "title": "KeyVec: Key-semantics Preserving Document Representations", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Previous studies have demonstrated the empirical success of word embeddings\nin various applications. In this paper, we investigate the problem of learning\ndistributed representations for text documents which many machine learning\nalgorithms take as input for a number of NLP tasks.\n  We propose a neural network model, KeyVec, which learns document\nrepresentations with the goal of preserving key semantics of the input text. It\nenables the learned low-dimensional vectors to retain the topics and important\ninformation from the documents that will flow to downstream tasks. Our\nempirical evaluations show the superior quality of KeyVec representations in\ntwo different document understanding tasks.\n", "versions": [{"version": "v1", "created": "Wed, 27 Sep 2017 22:05:59 GMT"}], "update_date": "2017-09-29", "authors_parsed": [["Bi", "Bin", ""], ["Ma", "Hao", ""]]}, {"id": "1709.09778", "submitter": "Benjamin Rubinstein", "authors": "Benjamin Fish, Lev Reyzin, Benjamin I. P. Rubinstein", "title": "Sampling Without Compromising Accuracy in Adaptive Data Analysis", "comments": "Appearing in the 31st International Conference on Algorithmic\n  Learning Theory (ALT 2020)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this work, we study how to use sampling to speed up mechanisms for\nanswering adaptive queries into datasets without reducing the accuracy of those\nmechanisms. This is important to do when both the datasets and the number of\nqueries asked are very large. In particular, we describe a mechanism that\nprovides a polynomial speed-up per query over previous mechanisms, without\nneeding to increase the total amount of data required to maintain the same\ngeneralization error as before. We prove that this speed-up holds for arbitrary\nstatistical queries. We also provide an even faster method for achieving\nstatistically-meaningful responses wherein the mechanism is only allowed to see\na constant number of samples from the data per query. Finally, we show that our\ngeneral results yield a simple, fast, and unified approach for adaptively\noptimizing convex and strongly convex functions over a dataset.\n", "versions": [{"version": "v1", "created": "Thu, 28 Sep 2017 01:45:02 GMT"}, {"version": "v2", "created": "Mon, 28 Jan 2019 20:34:52 GMT"}, {"version": "v3", "created": "Thu, 2 Jan 2020 00:18:42 GMT"}], "update_date": "2020-01-03", "authors_parsed": [["Fish", "Benjamin", ""], ["Reyzin", "Lev", ""], ["Rubinstein", "Benjamin I. P.", ""]]}, {"id": "1709.09820", "submitter": "Jianbo Guo", "authors": "Jianbo Guo, Guangxiang Zhu, Jian Li", "title": "Generative Adversarial Mapping Networks", "comments": "9 pages, 7 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Generative Adversarial Networks (GANs) have shown impressive performance in\ngenerating photo-realistic images. They fit generative models by minimizing\ncertain distance measure between the real image distribution and the generated\ndata distribution. Several distance measures have been used, such as\nJensen-Shannon divergence, $f$-divergence, and Wasserstein distance, and\nchoosing an appropriate distance measure is very important for training the\ngenerative network. In this paper, we choose to use the maximum mean\ndiscrepancy (MMD) as the distance metric, which has several nice theoretical\nguarantees. In fact, generative moment matching network (GMMN) (Li, Swersky,\nand Zemel 2015) is such a generative model which contains only one generator\nnetwork $G$ trained by directly minimizing MMD between the real and generated\ndistributions. However, it fails to generate meaningful samples on challenging\nbenchmark datasets, such as CIFAR-10 and LSUN. To improve on GMMN, we propose\nto add an extra network $F$, called mapper. $F$ maps both real data\ndistribution and generated data distribution from the original data space to a\nfeature representation space $\\mathcal{R}$, and it is trained to maximize MMD\nbetween the two mapped distributions in $\\mathcal{R}$, while the generator $G$\ntries to minimize the MMD. We call the new model generative adversarial mapping\nnetworks (GAMNs). We demonstrate that the adversarial mapper $F$ can help $G$\nto better capture the underlying data distribution. We also show that GAMN\nsignificantly outperforms GMMN, and is also superior to or comparable with\nother state-of-the-art GAN based methods on MNIST, CIFAR-10 and LSUN-Bedrooms\ndatasets.\n", "versions": [{"version": "v1", "created": "Thu, 28 Sep 2017 06:41:28 GMT"}], "update_date": "2017-09-29", "authors_parsed": [["Guo", "Jianbo", ""], ["Zhu", "Guangxiang", ""], ["Li", "Jian", ""]]}, {"id": "1709.09844", "submitter": "Amit Mandelbaum", "authors": "Amit Mandelbaum and Daphna Weinshall", "title": "Distance-based Confidence Score for Neural Network Classifiers", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.CV cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The reliable measurement of confidence in classifiers' predictions is very\nimportant for many applications and is, therefore, an important part of\nclassifier design. Yet, although deep learning has received tremendous\nattention in recent years, not much progress has been made in quantifying the\nprediction confidence of neural network classifiers. Bayesian models offer a\nmathematically grounded framework to reason about model uncertainty, but\nusually come with prohibitive computational costs. In this paper we propose a\nsimple, scalable method to achieve a reliable confidence score, based on the\ndata embedding derived from the penultimate layer of the network. We\ninvestigate two ways to achieve desirable embeddings, by using either a\ndistance-based loss or Adversarial Training. We then test the benefits of our\nmethod when used for classification error prediction, weighting an ensemble of\nclassifiers, and novelty detection. In all tasks we show significant\nimprovement over traditional, commonly used confidence scores.\n", "versions": [{"version": "v1", "created": "Thu, 28 Sep 2017 08:09:47 GMT"}], "update_date": "2020-07-01", "authors_parsed": [["Mandelbaum", "Amit", ""], ["Weinshall", "Daphna", ""]]}, {"id": "1709.09868", "submitter": "Albert Swart", "authors": "Albert Swart and Niko Brummer", "title": "A Generative Model for Score Normalization in Speaker Recognition", "comments": null, "journal-ref": "InterSpeech 2017", "doi": null, "report-no": null, "categories": "stat.ML cs.LG cs.SD eess.AS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a theoretical framework for thinking about score normalization,\nwhich confirms that normalization is not needed under (admittedly fragile)\nideal conditions. If, however, these conditions are not met, e.g. under\ndata-set shift between training and runtime, our theory reveals dependencies\nbetween scores that could be exploited by strategies such as score\nnormalization. Indeed, it has been demonstrated over and over experimentally,\nthat various ad-hoc score normalization recipes do work. We present a first\nattempt at using probability theory to design a generative score-space\nnormalization model which gives similar improvements to ZT-norm on the\ntext-dependent RSR 2015 database.\n", "versions": [{"version": "v1", "created": "Thu, 28 Sep 2017 09:32:10 GMT"}], "update_date": "2017-09-29", "authors_parsed": [["Swart", "Albert", ""], ["Brummer", "Niko", ""]]}, {"id": "1709.09882", "submitter": "Giulia Pasquale", "authors": "Giulia Pasquale, Carlo Ciliberto, Francesca Odone, Lorenzo Rosasco and\n  Lorenzo Natale", "title": "Are we done with object recognition? The iCub robot's perspective", "comments": "21 pages + supplementary material", "journal-ref": "Robotics and Autonomous Systems, Volume 112, February 2019, Pages\n  260-281", "doi": "10.1016/j.robot.2018.11.001", "report-no": null, "categories": "cs.RO cs.AI cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We report on an extensive study of the benefits and limitations of current\ndeep learning approaches to object recognition in robot vision scenarios,\nintroducing a novel dataset used for our investigation. To avoid the biases in\ncurrently available datasets, we consider a natural human-robot interaction\nsetting to design a data-acquisition protocol for visual object recognition on\nthe iCub humanoid robot. Analyzing the performance of off-the-shelf models\ntrained off-line on large-scale image retrieval datasets, we show the necessity\nfor knowledge transfer. We evaluate different ways in which this last step can\nbe done, and identify the major bottlenecks affecting robotic scenarios. By\nstudying both object categorization and identification problems, we highlight\nkey differences between object recognition in robotics applications and in\nimage retrieval tasks, for which the considered deep learning approaches have\nbeen originally designed. In a nutshell, our results confirm the remarkable\nimprovements yield by deep learning in this setting, while pointing to specific\nopen challenges that need be addressed for seamless deployment in robotics.\n", "versions": [{"version": "v1", "created": "Thu, 28 Sep 2017 10:16:52 GMT"}, {"version": "v2", "created": "Thu, 3 Jan 2019 14:16:09 GMT"}], "update_date": "2019-01-04", "authors_parsed": [["Pasquale", "Giulia", ""], ["Ciliberto", "Carlo", ""], ["Odone", "Francesca", ""], ["Rosasco", "Lorenzo", ""], ["Natale", "Lorenzo", ""]]}, {"id": "1709.09883", "submitter": "Maciej Wielgosz", "authors": "Maciej Wielgosz, Matej Mertik, Andrzej Skocze\\'n, Ernesto De Matteis", "title": "The model of an anomaly detector for HiLumi LHC magnets based on\n  Recurrent Neural Networks and adaptive quantization", "comments": "Related to arXiv:1702.00833", "journal-ref": "Engineering Applications of Artificial Intelligence, Volume 74,\n  2018, Pages 166-185", "doi": "10.1016/j.engappai.2018.06.012", "report-no": null, "categories": "cs.LG physics.acc-ph physics.ins-det", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper focuses on an examination of an applicability of Recurrent Neural\nNetwork models for detecting anomalous behavior of the CERN superconducting\nmagnets. In order to conduct the experiments, the authors designed and\nimplemented an adaptive signal quantization algorithm and a custom GRU-based\ndetector and developed a method for the detector parameters selection. Three\ndifferent datasets were used for testing the detector. Two artificially\ngenerated datasets were used to assess the raw performance of the system\nwhereas the 231 MB dataset composed of the signals acquired from HiLumi magnets\nwas intended for real-life experiments and model training. Several different\nsetups of the developed anomaly detection system were evaluated and compared\nwith state-of-the-art OC-SVM reference model operating on the same data. The\nOC-SVM model was equipped with a rich set of feature extractors accounting for\na range of the input signal properties. It was determined in the course of the\nexperiments that the detector, along with its supporting design methodology,\nreaches F1 equal or very close to 1 for almost all test sets. Due to the\nprofile of the data, the best_length setup of the detector turned out to\nperform the best among all five tested configuration schemes of the detection\nsystem. The quantization parameters have the biggest impact on the overall\nperformance of the detector with the best values of input/output grid equal to\n16 and 8, respectively. The proposed solution of the detection significantly\noutperformed OC-SVM-based detector in most of the cases, with much more stable\nperformance across all the datasets.\n", "versions": [{"version": "v1", "created": "Thu, 28 Sep 2017 10:19:40 GMT"}, {"version": "v2", "created": "Sat, 25 Nov 2017 16:27:38 GMT"}], "update_date": "2018-08-02", "authors_parsed": [["Wielgosz", "Maciej", ""], ["Mertik", "Matej", ""], ["Skocze\u0144", "Andrzej", ""], ["De Matteis", "Ernesto", ""]]}, {"id": "1709.09929", "submitter": "Milad Zafar Nezhad", "authors": "Milad Zafar Nezhad, Dongxiao Zhu, Najibesadat Sadati, Kai Yang,\n  Phillip Levy", "title": "SUBIC: A Supervised Bi-Clustering Approach for Precision Medicine", "comments": null, "journal-ref": null, "doi": "10.1109/ICMLA.2017.00-68", "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Traditional medicine typically applies one-size-fits-all treatment for the\nentire patient population whereas precision medicine develops tailored\ntreatment schemes for different patient subgroups. The fact that some factors\nmay be more significant for a specific patient subgroup motivates clinicians\nand medical researchers to develop new approaches to subgroup detection and\nanalysis, which is an effective strategy to personalize treatment. In this\nstudy, we propose a novel patient subgroup detection method, called Supervised\nBiclustring (SUBIC) using convex optimization and apply our approach to detect\npatient subgroups and prioritize risk factors for hypertension (HTN) in a\nvulnerable demographic subgroup (African-American). Our approach not only finds\npatient subgroups with guidance of a clinically relevant target variable but\nalso identifies and prioritizes risk factors by pursuing sparsity of the input\nvariables and encouraging similarity among the input variables and between the\ninput and target variables\n", "versions": [{"version": "v1", "created": "Tue, 26 Sep 2017 22:21:46 GMT"}], "update_date": "2018-01-29", "authors_parsed": [["Nezhad", "Milad Zafar", ""], ["Zhu", "Dongxiao", ""], ["Sadati", "Najibesadat", ""], ["Yang", "Kai", ""], ["Levy", "Phillip", ""]]}, {"id": "1709.09994", "submitter": "Mingzhe Wang", "authors": "Mingzhe Wang, Yihe Tang, Jian Wang, Jia Deng", "title": "Premise Selection for Theorem Proving by Deep Graph Embedding", "comments": "Mingzhe Wang and Yihe Tang contributed equally", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a deep learning-based approach to the problem of premise\nselection: selecting mathematical statements relevant for proving a given\nconjecture. We represent a higher-order logic formula as a graph that is\ninvariant to variable renaming but still fully preserves syntactic and semantic\ninformation. We then embed the graph into a vector via a novel embedding method\nthat preserves the information of edge ordering. Our approach achieves\nstate-of-the-art results on the HolStep dataset, improving the classification\naccuracy from 83% to 90.3%.\n", "versions": [{"version": "v1", "created": "Thu, 28 Sep 2017 14:44:40 GMT"}], "update_date": "2017-10-09", "authors_parsed": [["Wang", "Mingzhe", ""], ["Tang", "Yihe", ""], ["Wang", "Jian", ""], ["Deng", "Jia", ""]]}, {"id": "1709.10030", "submitter": "Bart Paul Gerard Van Parys", "authors": "Dimitris Bertsimas, Bart Van Parys", "title": "Sparse Hierarchical Regression with Polynomials", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.OC cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a novel method for exact hierarchical sparse polynomial\nregression. Our regressor is that degree $r$ polynomial which depends on at\nmost $k$ inputs, counting at most $\\ell$ monomial terms, which minimizes the\nsum of the squares of its prediction errors. The previous hierarchical sparse\nspecification aligns well with modern big data settings where many inputs are\nnot relevant for prediction purposes and the functional complexity of the\nregressor needs to be controlled as to avoid overfitting. We present a two-step\napproach to this hierarchical sparse regression problem. First, we discard\nirrelevant inputs using an extremely fast input ranking heuristic. Secondly, we\ntake advantage of modern cutting plane methods for integer optimization to\nsolve our resulting reduced hierarchical $(k, \\ell)$-sparse problem exactly.\nThe ability of our method to identify all $k$ relevant inputs and all $\\ell$\nmonomial terms is shown empirically to experience a phase transition.\nCrucially, the same transition also presents itself in our ability to reject\nall irrelevant features and monomials as well. In the regime where our method\nis statistically powerful, its computational complexity is interestingly on par\nwith Lasso based heuristics. The presented work fills a void in terms of a lack\nof powerful disciplined nonlinear sparse regression methods in high-dimensional\nsettings. Our method is shown empirically to scale to regression problems with\n$n\\approx 10,000$ observations for input dimension $p\\approx 1,000$.\n", "versions": [{"version": "v1", "created": "Thu, 28 Sep 2017 16:01:08 GMT"}], "update_date": "2017-09-29", "authors_parsed": [["Bertsimas", "Dimitris", ""], ["Van Parys", "Bart", ""]]}, {"id": "1709.10056", "submitter": "Peter Xenopoulos", "authors": "Peter Xenopoulos", "title": "Introducing DeepBalance: Random Deep Belief Network Ensembles to Address\n  Class Imbalance", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Class imbalance problems manifest in domains such as financial fraud\ndetection or network intrusion analysis, where the prevalence of one class is\nmuch higher than another. Typically, practitioners are more interested in\npredicting the minority class than the majority class as the minority class may\ncarry a higher misclassification cost. However, classifier performance\ndeteriorates in the face of class imbalance as oftentimes classifiers may\npredict every point as the majority class. Methods for dealing with class\nimbalance include cost-sensitive learning or resampling techniques. In this\npaper, we introduce DeepBalance, an ensemble of deep belief networks trained\nwith balanced bootstraps and random feature selection. We demonstrate that our\nproposed method outperforms baseline resampling methods such as SMOTE and\nunder- and over-sampling in metrics such as AUC and sensitivity when applied to\na highly imbalanced financial transaction data. Additionally, we explore\nperformance and training time implications of various model parameters.\nFurthermore, we show that our model is easily parallelizable, which can reduce\ntraining times. Finally, we present an implementation of DeepBalance in R.\n", "versions": [{"version": "v1", "created": "Thu, 28 Sep 2017 16:49:14 GMT"}, {"version": "v2", "created": "Wed, 15 Nov 2017 07:48:10 GMT"}], "update_date": "2017-11-16", "authors_parsed": [["Xenopoulos", "Peter", ""]]}, {"id": "1709.10082", "submitter": "Jia Pan", "authors": "Pinxin Long, Tingxiang Fan, Xinyi Liao, Wenxi Liu, Hao Zhang and Jia\n  Pan", "title": "Towards Optimally Decentralized Multi-Robot Collision Avoidance via Deep\n  Reinforcement Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.AI cs.LG cs.MA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Developing a safe and efficient collision avoidance policy for multiple\nrobots is challenging in the decentralized scenarios where each robot generate\nits paths without observing other robots' states and intents. While other\ndistributed multi-robot collision avoidance systems exist, they often require\nextracting agent-level features to plan a local collision-free action, which\ncan be computationally prohibitive and not robust. More importantly, in\npractice the performance of these methods are much lower than their centralized\ncounterparts.\n  We present a decentralized sensor-level collision avoidance policy for\nmulti-robot systems, which directly maps raw sensor measurements to an agent's\nsteering commands in terms of movement velocity. As a first step toward\nreducing the performance gap between decentralized and centralized methods, we\npresent a multi-scenario multi-stage training framework to find an optimal\npolicy which is trained over a large number of robots on rich, complex\nenvironments simultaneously using a policy gradient based reinforcement\nlearning algorithm. We validate the learned sensor-level collision avoidance\npolicy in a variety of simulated scenarios with thorough performance\nevaluations and show that the final learned policy is able to find time\nefficient, collision-free paths for a large-scale robot system. We also\ndemonstrate that the learned policy can be well generalized to new scenarios\nthat do not appear in the entire training period, including navigating a\nheterogeneous group of robots and a large-scale scenario with 100 robots.\nVideos are available at https://sites.google.com/view/drlmaca\n", "versions": [{"version": "v1", "created": "Thu, 28 Sep 2017 17:44:09 GMT"}, {"version": "v2", "created": "Fri, 29 Sep 2017 02:20:12 GMT"}, {"version": "v3", "created": "Sun, 20 May 2018 08:36:24 GMT"}], "update_date": "2018-05-22", "authors_parsed": [["Long", "Pinxin", ""], ["Fan", "Tingxiang", ""], ["Liao", "Xinyi", ""], ["Liu", "Wenxi", ""], ["Zhang", "Hao", ""], ["Pan", "Jia", ""]]}, {"id": "1709.10087", "submitter": "Aravind Rajeswaran", "authors": "Aravind Rajeswaran, Vikash Kumar, Abhishek Gupta, Giulia Vezzani, John\n  Schulman, Emanuel Todorov, Sergey Levine", "title": "Learning Complex Dexterous Manipulation with Deep Reinforcement Learning\n  and Demonstrations", "comments": "Accepted for presentation at Robotics: Science and Systems (RSS)\n  2018. Project page:\n  https://sites.google.com/view/deeprl-dexterous-manipulation", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.RO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Dexterous multi-fingered hands are extremely versatile and provide a generic\nway to perform a multitude of tasks in human-centric environments. However,\neffectively controlling them remains challenging due to their high\ndimensionality and large number of potential contacts. Deep reinforcement\nlearning (DRL) provides a model-agnostic approach to control complex dynamical\nsystems, but has not been shown to scale to high-dimensional dexterous\nmanipulation. Furthermore, deployment of DRL on physical systems remains\nchallenging due to sample inefficiency. Consequently, the success of DRL in\nrobotics has thus far been limited to simpler manipulators and tasks. In this\nwork, we show that model-free DRL can effectively scale up to complex\nmanipulation tasks with a high-dimensional 24-DoF hand, and solve them from\nscratch in simulated experiments. Furthermore, with the use of a small number\nof human demonstrations, the sample complexity can be significantly reduced,\nwhich enables learning with sample sizes equivalent to a few hours of robot\nexperience. The use of demonstrations result in policies that exhibit very\nnatural movements and, surprisingly, are also substantially more robust.\n", "versions": [{"version": "v1", "created": "Thu, 28 Sep 2017 17:51:13 GMT"}, {"version": "v2", "created": "Tue, 26 Jun 2018 13:31:37 GMT"}], "update_date": "2018-06-27", "authors_parsed": [["Rajeswaran", "Aravind", ""], ["Kumar", "Vikash", ""], ["Gupta", "Abhishek", ""], ["Vezzani", "Giulia", ""], ["Schulman", "John", ""], ["Todorov", "Emanuel", ""], ["Levine", "Sergey", ""]]}, {"id": "1709.10089", "submitter": "Ashvin Nair", "authors": "Ashvin Nair, Bob McGrew, Marcin Andrychowicz, Wojciech Zaremba, Pieter\n  Abbeel", "title": "Overcoming Exploration in Reinforcement Learning with Demonstrations", "comments": "8 pages, ICRA 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.NE cs.RO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Exploration in environments with sparse rewards has been a persistent problem\nin reinforcement learning (RL). Many tasks are natural to specify with a sparse\nreward, and manually shaping a reward function can result in suboptimal\nperformance. However, finding a non-zero reward is exponentially more difficult\nwith increasing task horizon or action dimensionality. This puts many\nreal-world tasks out of practical reach of RL methods. In this work, we use\ndemonstrations to overcome the exploration problem and successfully learn to\nperform long-horizon, multi-step robotics tasks with continuous control such as\nstacking blocks with a robot arm. Our method, which builds on top of Deep\nDeterministic Policy Gradients and Hindsight Experience Replay, provides an\norder of magnitude of speedup over RL on simulated robotics tasks. It is simple\nto implement and makes only the additional assumption that we can collect a\nsmall set of demonstrations. Furthermore, our method is able to solve tasks not\nsolvable by either RL or behavior cloning alone, and often ends up\noutperforming the demonstrator policy.\n", "versions": [{"version": "v1", "created": "Thu, 28 Sep 2017 17:51:48 GMT"}, {"version": "v2", "created": "Sun, 25 Feb 2018 07:48:19 GMT"}], "update_date": "2018-02-27", "authors_parsed": [["Nair", "Ashvin", ""], ["McGrew", "Bob", ""], ["Andrychowicz", "Marcin", ""], ["Zaremba", "Wojciech", ""], ["Abbeel", "Pieter", ""]]}, {"id": "1709.10128", "submitter": "Monireh Dabaghchian", "authors": "Monireh Dabaghchian, Amir Alipour-Fanid, Kai Zeng, Qingsi Wang, Peter\n  Auer", "title": "Online Learning with Randomized Feedback Graphs for Optimal PUE Attacks\n  in Cognitive Radio Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI cs.CR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In a cognitive radio network, a secondary user learns the spectrum\nenvironment and dynamically accesses the channel where the primary user is\ninactive. At the same time, a primary user emulation (PUE) attacker can send\nfalsified primary user signals and prevent the secondary user from utilizing\nthe available channel. The best attacking strategies that an attacker can apply\nhave not been well studied. In this paper, for the first time, we study optimal\nPUE attack strategies by formulating an online learning problem where the\nattacker needs to dynamically decide the attacking channel in each time slot\nbased on its attacking experience. The challenge in our problem is that since\nthe PUE attack happens in the spectrum sensing phase, the attacker cannot\nobserve the reward on the attacked channel. To address this challenge, we\nutilize the attacker's observation capability. We propose online learning-based\nattacking strategies based on the attacker's observation capabilities. Through\nour analysis, we show that with no observation within the attacking slot, the\nattacker loses on the regret order, and with the observation of at least one\nchannel, there is a significant improvement on the attacking performance.\nObservation of multiple channels does not give additional benefit to the\nattacker (only a constant scaling) though it gives insight on the number of\nobservations required to achieve the minimum constant factor. Our proposed\nalgorithms are optimal in the sense that their regret upper bounds match their\ncorresponding regret lower-bounds. We show consistency between simulation and\nanalytical results under various system parameters.\n", "versions": [{"version": "v1", "created": "Thu, 28 Sep 2017 18:56:23 GMT"}, {"version": "v2", "created": "Fri, 16 Mar 2018 07:24:41 GMT"}, {"version": "v3", "created": "Mon, 19 Mar 2018 20:24:26 GMT"}], "update_date": "2018-03-21", "authors_parsed": [["Dabaghchian", "Monireh", ""], ["Alipour-Fanid", "Amir", ""], ["Zeng", "Kai", ""], ["Wang", "Qingsi", ""], ["Auer", "Peter", ""]]}, {"id": "1709.10152", "submitter": "Cheolmin Kim", "authors": "Cheolmin Kim, Diego Klabjan", "title": "A Simple and Fast Algorithm for L1-norm Kernel PCA", "comments": "14 pages, 7 figures", "journal-ref": "IEEE Transactions on Pattern Analysis and Machine Intelligence\n  (2019)", "doi": "10.1109/TPAMI.2019.2903505", "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present an algorithm for L1-norm kernel PCA and provide a convergence\nanalysis for it. While an optimal solution of L2-norm kernel PCA can be\nobtained through matrix decomposition, finding that of L1-norm kernel PCA is\nnot trivial due to its non-convexity and non-smoothness. We provide a novel\nreformulation through which an equivalent, geometrically interpretable problem\nis obtained. Based on the geometric interpretation of the reformulated problem,\nwe present a fixed-point type algorithm that iteratively computes a binary\nweight for each observation. As the algorithm requires only inner products of\ndata vectors, it is computationally efficient and the kernel trick is\napplicable. In the convergence analysis, we show that the algorithm converges\nto a local optimal solution in a finite number of steps. Moreover, we provide a\nrate of convergence analysis, which has been never done for any L1-norm PCA\nalgorithm, proving that the sequence of objective values converges at a linear\nrate. In numerical experiments, we show that the algorithm is robust in the\npresence of entry-wise perturbations and computationally scalable, especially\nin a large-scale setting. Lastly, we introduce an application to outlier\ndetection where the model based on the proposed algorithm outperforms the\nbenchmark algorithms.\n", "versions": [{"version": "v1", "created": "Thu, 28 Sep 2017 20:03:14 GMT"}, {"version": "v2", "created": "Thu, 11 Jun 2020 06:14:27 GMT"}], "update_date": "2020-06-12", "authors_parsed": [["Kim", "Cheolmin", ""], ["Klabjan", "Diego", ""]]}, {"id": "1709.10163", "submitter": "Nicholas Waytowich", "authors": "Garrett Warnell, Nicholas Waytowich, Vernon Lawhern, Peter Stone", "title": "Deep TAMER: Interactive Agent Shaping in High-Dimensional State Spaces", "comments": "9 pages, 6 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  While recent advances in deep reinforcement learning have allowed autonomous\nlearning agents to succeed at a variety of complex tasks, existing algorithms\ngenerally require a lot of training data. One way to increase the speed at\nwhich agents are able to learn to perform tasks is by leveraging the input of\nhuman trainers. Although such input can take many forms, real-time,\nscalar-valued feedback is especially useful in situations where it proves\ndifficult or impossible for humans to provide expert demonstrations. Previous\napproaches have shown the usefulness of human input provided in this fashion\n(e.g., the TAMER framework), but they have thus far not considered\nhigh-dimensional state spaces or employed the use of deep learning. In this\npaper, we do both: we propose Deep TAMER, an extension of the TAMER framework\nthat leverages the representational power of deep neural networks in order to\nlearn complex tasks in just a short amount of time with a human trainer. We\ndemonstrate Deep TAMER's success by using it and just 15 minutes of\nhuman-provided feedback to train an agent that performs better than humans on\nthe Atari game of Bowling - a task that has proven difficult for even\nstate-of-the-art reinforcement learning methods.\n", "versions": [{"version": "v1", "created": "Thu, 28 Sep 2017 20:43:40 GMT"}, {"version": "v2", "created": "Fri, 19 Jan 2018 20:36:13 GMT"}], "update_date": "2018-01-23", "authors_parsed": [["Warnell", "Garrett", ""], ["Waytowich", "Nicholas", ""], ["Lawhern", "Vernon", ""], ["Stone", "Peter", ""]]}, {"id": "1709.10204", "submitter": "Bin Bi", "authors": "Bin Bi and Hao Ma", "title": "A Neural Comprehensive Ranker (NCR) for Open-Domain Question Answering", "comments": "A paper with a similar method has been published earlier at\n  arXiv:1706.04815 The authors believe there is no need for a separate\n  publication", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper proposes a novel neural machine reading model for open-domain\nquestion answering at scale. Existing machine comprehension models typically\nassume that a short piece of relevant text containing answers is already\nidentified and given to the models, from which the models are designed to\nextract answers. This assumption, however, is not realistic for building a\nlarge-scale open-domain question answering system which requires both deep text\nunderstanding and identifying relevant text from corpus simultaneously.\n  In this paper, we introduce Neural Comprehensive Ranker (NCR) that integrates\nboth passage ranking and answer extraction in one single framework. A Q&A\nsystem based on this framework allows users to issue an open-domain question\nwithout needing to provide a piece of text that must contain the answer.\nExperiments show that the unified NCR model is able to outperform the\nstates-of-the-art in both retrieval of relevant text and answer extraction.\n", "versions": [{"version": "v1", "created": "Fri, 29 Sep 2017 00:27:48 GMT"}, {"version": "v2", "created": "Thu, 5 Oct 2017 17:56:02 GMT"}], "update_date": "2017-10-06", "authors_parsed": [["Bi", "Bin", ""], ["Ma", "Hao", ""]]}, {"id": "1709.10207", "submitter": "Nicholas Carlini", "authors": "Nicholas Carlini, Guy Katz, Clark Barrett, David L. Dill", "title": "Provably Minimally-Distorted Adversarial Examples", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The ability to deploy neural networks in real-world, safety-critical systems\nis severely limited by the presence of adversarial examples: slightly perturbed\ninputs that are misclassified by the network. In recent years, several\ntechniques have been proposed for increasing robustness to adversarial examples\n--- and yet most of these have been quickly shown to be vulnerable to future\nattacks. For example, over half of the defenses proposed by papers accepted at\nICLR 2018 have already been broken. We propose to address this difficulty\nthrough formal verification techniques. We show how to construct provably\nminimally distorted adversarial examples: given an arbitrary neural network and\ninput sample, we can construct adversarial examples which we prove are of\nminimal distortion. Using this approach, we demonstrate that one of the recent\nICLR defense proposals, adversarial retraining, provably succeeds at increasing\nthe distortion required to construct adversarial examples by a factor of 4.2.\n", "versions": [{"version": "v1", "created": "Fri, 29 Sep 2017 00:57:12 GMT"}, {"version": "v2", "created": "Tue, 20 Feb 2018 05:35:36 GMT"}], "update_date": "2018-02-21", "authors_parsed": [["Carlini", "Nicholas", ""], ["Katz", "Guy", ""], ["Barrett", "Clark", ""], ["Dill", "David L.", ""]]}, {"id": "1709.10222", "submitter": "Miron Ivanov", "authors": "Miron Ivanov", "title": "Comparison of PCA with ICA from data distribution perspective", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We performed an empirical comparison of ICA and PCA algorithms by applying\nthem on two simulated noisy time series with varying distribution parameters\nand level of noise. In general, ICA shows better results than PCA because it\ntakes into account higher moments of data distribution. On the other hand, PCA\nremains quite sensitive to the level of correlations among signals.\n", "versions": [{"version": "v1", "created": "Fri, 29 Sep 2017 02:51:52 GMT"}], "update_date": "2017-10-02", "authors_parsed": [["Ivanov", "Miron", ""]]}, {"id": "1709.10250", "submitter": "Aaditya Ramdas", "authors": "Aaditya Ramdas, Jianbo Chen, Martin J. Wainwright, Michael I. Jordan", "title": "DAGGER: A sequential algorithm for FDR control on DAGs", "comments": "29 pages, 10 figures, accepted for publication by Biometrika", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ME cs.LG math.ST stat.ML stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a linear-time, single-pass, top-down algorithm for multiple\ntesting on directed acyclic graphs (DAGs), where nodes represent hypotheses and\nedges specify a partial ordering in which hypotheses must be tested. The\nprocedure is guaranteed to reject a sub-DAG with bounded false discovery rate\n(FDR) while satisfying the logical constraint that a rejected node's parents\nmust also be rejected. It is designed for sequential testing settings, when the\nDAG structure is known a priori, but the $p$-values are obtained selectively\n(such as in a sequence of experiments), but the algorithm is also applicable in\nnon-sequential settings when all $p$-values can be calculated in advance (such\nas variable/model selection). Our DAGGER algorithm, shorthand for Greedily\nEvolving Rejections on DAGs, provably controls the false discovery rate under\nindependence, positive dependence or arbitrary dependence of the $p$-values.\nThe DAGGER procedure specializes to known algorithms in the special cases of\ntrees and line graphs, and simplifies to the classical Benjamini-Hochberg\nprocedure when the DAG has no edges. We explore the empirical performance of\nDAGGER using simulations, as well as a real dataset corresponding to a gene\nontology, showing favorable performance in terms of time and power.\n", "versions": [{"version": "v1", "created": "Fri, 29 Sep 2017 06:38:11 GMT"}, {"version": "v2", "created": "Tue, 10 Oct 2017 01:21:47 GMT"}, {"version": "v3", "created": "Tue, 4 Dec 2018 20:06:02 GMT"}], "update_date": "2018-12-06", "authors_parsed": [["Ramdas", "Aaditya", ""], ["Chen", "Jianbo", ""], ["Wainwright", "Martin J.", ""], ["Jordan", "Michael I.", ""]]}, {"id": "1709.10297", "submitter": "Behrooz Razeghi", "authors": "Behrooz Razeghi, Slava Voloshynovskiy, Dimche Kostadinov and Olga\n  Taran", "title": "Privacy Preserving Identification Using Sparse Approximation with\n  Ambiguization", "comments": "submitted to WIFS 2017", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we consider a privacy preserving encoding framework for\nidentification applications covering biometrics, physical object security and\nthe Internet of Things (IoT). The proposed framework is based on a sparsifying\ntransform, which consists of a trained linear map, an element-wise\nnonlinearity, and privacy amplification. The sparsifying transform and privacy\namplification are not symmetric for the data owner and data user. We\ndemonstrate that the proposed approach is closely related to sparse ternary\ncodes (STC), a recent information-theoretic concept proposed for fast\napproximate nearest neighbor (ANN) search in high dimensional feature spaces\nthat being machine learning in nature also offers significant benefits in\ncomparison to sparse approximation and binary embedding approaches. We\ndemonstrate that the privacy of the database outsourced to a server as well as\nthe privacy of the data user are preserved at a low computational cost, storage\nand communication burdens.\n", "versions": [{"version": "v1", "created": "Fri, 29 Sep 2017 09:24:06 GMT"}], "update_date": "2017-10-02", "authors_parsed": [["Razeghi", "Behrooz", ""], ["Voloshynovskiy", "Slava", ""], ["Kostadinov", "Dimche", ""], ["Taran", "Olga", ""]]}, {"id": "1709.10323", "submitter": "Nino Antulov-Fantulin", "authors": "Dijana Tolic, Nino Antulov-Fantulin, Ivica Kopriva", "title": "A Nonlinear Orthogonal Non-Negative Matrix Factorization Approach to\n  Subspace Clustering", "comments": null, "journal-ref": null, "doi": "10.1016/j.patcog.2018.04.029", "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A recent theoretical analysis shows the equivalence between non-negative\nmatrix factorization (NMF) and spectral clustering based approach to subspace\nclustering. As NMF and many of its variants are essentially linear, we\nintroduce a nonlinear NMF with explicit orthogonality and derive general\nkernel-based orthogonal multiplicative update rules to solve the subspace\nclustering problem. In nonlinear orthogonal NMF framework, we propose two\nsubspace clustering algorithms, named kernel-based non-negative subspace\nclustering KNSC-Ncut and KNSC-Rcut and establish their connection with spectral\nnormalized cut and ratio cut clustering. We further extend the nonlinear\northogonal NMF framework and introduce a graph regularization to obtain a\nfactorization that respects a local geometric structure of the data after the\nnonlinear mapping. The proposed NMF-based approach to subspace clustering takes\ninto account the nonlinear nature of the manifold, as well as its intrinsic\nlocal geometry, which considerably improves the clustering performance when\ncompared to the several recently proposed state-of-the-art methods.\n", "versions": [{"version": "v1", "created": "Fri, 29 Sep 2017 11:02:16 GMT"}], "update_date": "2018-10-08", "authors_parsed": [["Tolic", "Dijana", ""], ["Antulov-Fantulin", "Nino", ""], ["Kopriva", "Ivica", ""]]}, {"id": "1709.10367", "submitter": "Maja Rudolph", "authors": "Maja Rudolph, Francisco Ruiz, Susan Athey, David Blei", "title": "Structured Embedding Models for Grouped Data", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Word embeddings are a powerful approach for analyzing language, and\nexponential family embeddings (EFE) extend them to other types of data. Here we\ndevelop structured exponential family embeddings (S-EFE), a method for\ndiscovering embeddings that vary across related groups of data. We study how\nthe word usage of U.S. Congressional speeches varies across states and party\naffiliation, how words are used differently across sections of the ArXiv, and\nhow the co-purchase patterns of groceries can vary across seasons. Key to the\nsuccess of our method is that the groups share statistical information. We\ndevelop two sharing strategies: hierarchical modeling and amortization. We\ndemonstrate the benefits of this approach in empirical studies of speeches,\nabstracts, and shopping baskets. We show how S-EFE enables group-specific\ninterpretation of word usage, and outperforms EFE in predicting held-out data.\n", "versions": [{"version": "v1", "created": "Thu, 28 Sep 2017 14:14:58 GMT"}], "update_date": "2017-10-03", "authors_parsed": [["Rudolph", "Maja", ""], ["Ruiz", "Francisco", ""], ["Athey", "Susan", ""], ["Blei", "David", ""]]}, {"id": "1709.10380", "submitter": "Qinglong Wang", "authors": "Qinglong Wang, Kaixuan Zhang, Alexander G. Ororbia II, Xinyu Xing, Xue\n  Liu, C. Lee Giles", "title": "An Empirical Evaluation of Rule Extraction from Recurrent Neural\n  Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Rule extraction from black-box models is critical in domains that require\nmodel validation before implementation, as can be the case in credit scoring\nand medical diagnosis. Though already a challenging problem in statistical\nlearning in general, the difficulty is even greater when highly non-linear,\nrecursive models, such as recurrent neural networks (RNNs), are fit to data.\nHere, we study the extraction of rules from second-order recurrent neural\nnetworks trained to recognize the Tomita grammars. We show that production\nrules can be stably extracted from trained RNNs and that in certain cases the\nrules outperform the trained RNNs.\n", "versions": [{"version": "v1", "created": "Fri, 29 Sep 2017 12:56:25 GMT"}, {"version": "v2", "created": "Mon, 9 Oct 2017 14:43:43 GMT"}, {"version": "v3", "created": "Thu, 19 Oct 2017 18:34:46 GMT"}, {"version": "v4", "created": "Tue, 28 Nov 2017 02:59:17 GMT"}, {"version": "v5", "created": "Wed, 14 Nov 2018 19:50:30 GMT"}], "update_date": "2018-11-16", "authors_parsed": [["Wang", "Qinglong", ""], ["Zhang", "Kaixuan", ""], ["Ororbia", "Alexander G.", "II"], ["Xing", "Xinyu", ""], ["Liu", "Xue", ""], ["Giles", "C. Lee", ""]]}, {"id": "1709.10423", "submitter": "Yanchao Yu", "authors": "Yanchao Yu, Arash Eshghi, Oliver Lemon", "title": "Learning how to learn: an adaptive dialogue agent for incrementally\n  learning visually grounded word meanings", "comments": "10 pages, RoboNLP Workshop from ACL Conference", "journal-ref": null, "doi": "10.18653/v1/W17-2802", "report-no": null, "categories": "cs.CL cs.AI cs.LG cs.RO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present an optimised multi-modal dialogue agent for interactive learning\nof visually grounded word meanings from a human tutor, trained on real\nhuman-human tutoring data. Within a life-long interactive learning period, the\nagent, trained using Reinforcement Learning (RL), must be able to handle\nnatural conversations with human users and achieve good learning performance\n(accuracy) while minimising human effort in the learning process. We train and\nevaluate this system in interaction with a simulated human tutor, which is\nbuilt on the BURCHAK corpus -- a Human-Human Dialogue dataset for the visual\nlearning task. The results show that: 1) The learned policy can coherently\ninteract with the simulated user to achieve the goal of the task (i.e. learning\nvisual attributes of objects, e.g. colour and shape); and 2) it finds a better\ntrade-off between classifier accuracy and tutoring costs than hand-crafted\nrule-based policies, including ones with dynamic policies.\n", "versions": [{"version": "v1", "created": "Fri, 29 Sep 2017 14:21:31 GMT"}], "update_date": "2017-10-02", "authors_parsed": [["Yu", "Yanchao", ""], ["Eshghi", "Arash", ""], ["Lemon", "Oliver", ""]]}, {"id": "1709.10426", "submitter": "Yanchao Yu", "authors": "Yanchao Yu, Arash Eshghi, Oliver Lemon", "title": "Training an adaptive dialogue policy for interactive learning of\n  visually grounded word meanings", "comments": "11 pages, SIGDIAL 2016 Conference", "journal-ref": null, "doi": "10.18653/v1/W16-3643", "report-no": null, "categories": "cs.CL cs.AI cs.LG cs.RO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a multi-modal dialogue system for interactive learning of\nperceptually grounded word meanings from a human tutor. The system integrates\nan incremental, semantic parsing/generation framework - Dynamic Syntax and Type\nTheory with Records (DS-TTR) - with a set of visual classifiers that are\nlearned throughout the interaction and which ground the meaning representations\nthat it produces. We use this system in interaction with a simulated human\ntutor to study the effects of different dialogue policies and capabilities on\nthe accuracy of learned meanings, learning rates, and efforts/costs to the\ntutor. We show that the overall performance of the learning agent is affected\nby (1) who takes initiative in the dialogues; (2) the ability to express/use\ntheir confidence level about visual attributes; and (3) the ability to process\nelliptical and incrementally constructed dialogue turns. Ultimately, we train\nan adaptive dialogue policy which optimises the trade-off between classifier\naccuracy and tutoring costs.\n", "versions": [{"version": "v1", "created": "Fri, 29 Sep 2017 14:28:31 GMT"}], "update_date": "2017-10-02", "authors_parsed": [["Yu", "Yanchao", ""], ["Eshghi", "Arash", ""], ["Lemon", "Oliver", ""]]}, {"id": "1709.10431", "submitter": "Yanchao Yu", "authors": "Yanchao Yu, Arash Eshghi, Gregory Mills, Oliver Joseph Lemon", "title": "The BURCHAK corpus: a Challenge Data Set for Interactive Learning of\n  Visually Grounded Word Meanings", "comments": "10 pages, THE 6TH WORKSHOP ON VISION AND LANGUAGE (VL'17)", "journal-ref": null, "doi": "10.18653/v1/W17-2001", "report-no": null, "categories": "cs.CL cs.AI cs.LG cs.RO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We motivate and describe a new freely available human-human dialogue dataset\nfor interactive learning of visually grounded word meanings through ostensive\ndefinition by a tutor to a learner. The data has been collected using a novel,\ncharacter-by-character variant of the DiET chat tool (Healey et al., 2003;\nMills and Healey, submitted) with a novel task, where a Learner needs to learn\ninvented visual attribute words (such as \" burchak \" for square) from a tutor.\nAs such, the text-based interactions closely resemble face-to-face conversation\nand thus contain many of the linguistic phenomena encountered in natural,\nspontaneous dialogue. These include self-and other-correction, mid-sentence\ncontinuations, interruptions, overlaps, fillers, and hedges. We also present a\ngeneric n-gram framework for building user (i.e. tutor) simulations from this\ntype of incremental data, which is freely available to researchers. We show\nthat the simulations produce outputs that are similar to the original data\n(e.g. 78% turn match similarity). Finally, we train and evaluate a\nReinforcement Learning dialogue control agent for learning visually grounded\nword meanings, trained from the BURCHAK corpus. The learned policy shows\ncomparable performance to a rule-based system built previously.\n", "versions": [{"version": "v1", "created": "Fri, 29 Sep 2017 14:43:06 GMT"}], "update_date": "2017-10-02", "authors_parsed": [["Yu", "Yanchao", ""], ["Eshghi", "Arash", ""], ["Mills", "Gregory", ""], ["Lemon", "Oliver Joseph", ""]]}, {"id": "1709.10432", "submitter": "Qi Meng", "authors": "Qi Meng, Wei Chen, Yue Wang, Zhi-Ming Ma, Tie-Yan Liu", "title": "Convergence Analysis of Distributed Stochastic Gradient Descent with\n  Shuffling", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  When using stochastic gradient descent to solve large-scale machine learning\nproblems, a common practice of data processing is to shuffle the training data,\npartition the data across multiple machines if needed, and then perform several\nepochs of training on the re-shuffled (either locally or globally) data. The\nabove procedure makes the instances used to compute the gradients no longer\nindependently sampled from the training data set. Then does the distributed SGD\nmethod have desirable convergence properties in this practical situation? In\nthis paper, we give answers to this question. First, we give a mathematical\nformulation for the practical data processing procedure in distributed machine\nlearning, which we call data partition with global/local shuffling. We observe\nthat global shuffling is equivalent to without-replacement sampling if the\nshuffling operations are independent. We prove that SGD with global shuffling\nhas convergence guarantee in both convex and non-convex cases. An interesting\nfinding is that, the non-convex tasks like deep learning are more suitable to\napply shuffling comparing to the convex tasks. Second, we conduct the\nconvergence analysis for SGD with local shuffling. The convergence rate for\nlocal shuffling is slower than that for global shuffling, since it will lose\nsome information if there's no communication between partitioned data. Finally,\nwe consider the situation when the permutation after shuffling is not uniformly\ndistributed (insufficient shuffling), and discuss the condition under which\nthis insufficiency will not influence the convergence rate. Our theoretical\nresults provide important insights to large-scale machine learning, especially\nin the selection of data processing methods in order to achieve faster\nconvergence and good speedup. Our theoretical findings are verified by\nextensive experiments on logistic regression and deep neural networks.\n", "versions": [{"version": "v1", "created": "Fri, 29 Sep 2017 14:44:05 GMT"}], "update_date": "2017-10-02", "authors_parsed": [["Meng", "Qi", ""], ["Chen", "Wei", ""], ["Wang", "Yue", ""], ["Ma", "Zhi-Ming", ""], ["Liu", "Tie-Yan", ""]]}, {"id": "1709.10441", "submitter": "Bastian Bohn", "authors": "Bastian Bohn, Michael Griebel, Christian Rieger", "title": "A representer theorem for deep kernel learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG math.NA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we provide a finite-sample and an infinite-sample representer\ntheorem for the concatenation of (linear combinations of) kernel functions of\nreproducing kernel Hilbert spaces. These results serve as mathematical\nfoundation for the analysis of machine learning algorithms based on\ncompositions of functions. As a direct consequence in the finite-sample case,\nthe corresponding infinite-dimensional minimization problems can be recast into\n(nonlinear) finite-dimensional minimization problems, which can be tackled with\nnonlinear optimization algorithms. Moreover, we show how concatenated machine\nlearning problems can be reformulated as neural networks and how our\nrepresenter theorem applies to a broad class of state-of-the-art deep learning\nmethods.\n", "versions": [{"version": "v1", "created": "Fri, 29 Sep 2017 15:01:43 GMT"}, {"version": "v2", "created": "Wed, 18 Oct 2017 15:37:52 GMT"}, {"version": "v3", "created": "Thu, 7 Jun 2018 15:12:42 GMT"}], "update_date": "2018-06-08", "authors_parsed": [["Bohn", "Bastian", ""], ["Griebel", "Michael", ""], ["Rieger", "Christian", ""]]}, {"id": "1709.10459", "submitter": "Fred Bertsch", "authors": "Andrew Kyle Lampinen, David So, Douglas Eck, and Fred Bertsch", "title": "Improving image generative models with human interactions", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  GANs provide a framework for training generative models which mimic a data\ndistribution. However, in many cases we wish to train these generative models\nto optimize some auxiliary objective function within the data it generates,\nsuch as making more aesthetically pleasing images. In some cases, these\nobjective functions are difficult to evaluate, e.g. they may require human\ninteraction. Here, we develop a system for efficiently improving a GAN to\ntarget an objective involving human interaction, specifically generating images\nthat increase rates of positive user interactions. To improve the generative\nmodel, we build a model of human behavior in the targeted domain from a\nrelatively small set of interactions, and then use this behavioral model as an\nauxiliary loss function to improve the generative model. We show that this\nsystem is successful at improving positive interaction rates, at least on\nsimulated data, and characterize some of the factors that affect its\nperformance.\n", "versions": [{"version": "v1", "created": "Fri, 29 Sep 2017 15:38:42 GMT"}], "update_date": "2017-10-02", "authors_parsed": [["Lampinen", "Andrew Kyle", ""], ["So", "David", ""], ["Eck", "Douglas", ""], ["Bertsch", "Fred", ""]]}, {"id": "1709.10489", "submitter": "Gregory Kahn", "authors": "Gregory Kahn, Adam Villaflor, Bosen Ding, Pieter Abbeel, Sergey Levine", "title": "Self-supervised Deep Reinforcement Learning with Generalized Computation\n  Graphs for Robot Navigation", "comments": "ICRA 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.RO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Enabling robots to autonomously navigate complex environments is essential\nfor real-world deployment. Prior methods approach this problem by having the\nrobot maintain an internal map of the world, and then use a localization and\nplanning method to navigate through the internal map. However, these approaches\noften include a variety of assumptions, are computationally intensive, and do\nnot learn from failures. In contrast, learning-based methods improve as the\nrobot acts in the environment, but are difficult to deploy in the real-world\ndue to their high sample complexity. To address the need to learn complex\npolicies with few samples, we propose a generalized computation graph that\nsubsumes value-based model-free methods and model-based methods, with specific\ninstantiations interpolating between model-free and model-based. We then\ninstantiate this graph to form a navigation model that learns from raw images\nand is sample efficient. Our simulated car experiments explore the design\ndecisions of our navigation model, and show our approach outperforms\nsingle-step and $N$-step double Q-learning. We also evaluate our approach on a\nreal-world RC car and show it can learn to navigate through a complex indoor\nenvironment with a few hours of fully autonomous, self-supervised training.\nVideos of the experiments and code can be found at github.com/gkahn13/gcg\n", "versions": [{"version": "v1", "created": "Fri, 29 Sep 2017 16:47:14 GMT"}, {"version": "v2", "created": "Thu, 30 Nov 2017 23:55:32 GMT"}, {"version": "v3", "created": "Thu, 17 May 2018 22:32:25 GMT"}], "update_date": "2018-05-21", "authors_parsed": [["Kahn", "Gregory", ""], ["Villaflor", "Adam", ""], ["Ding", "Bosen", ""], ["Abbeel", "Pieter", ""], ["Levine", "Sergey", ""]]}, {"id": "1709.10498", "submitter": "Frank Nielsen", "authors": "Frank Nielsen", "title": "A generalization of the Jensen divergence: The chord gap divergence", "comments": "13 pages, 2 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.IT math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce a novel family of distances, called the chord gap divergences,\nthat generalizes the Jensen divergences (also called the Burbea-Rao distances),\nand study its properties. It follows a generalization of the celebrated\nstatistical Bhattacharyya distance that is frequently met in applications. We\nreport an iterative concave-convex procedure for computing centroids, and\nanalyze the performance of the $k$-means++ clustering with respect to that new\ndissimilarity measure by introducing the Taylor-Lagrange remainder form of the\nskew Jensen divergences.\n", "versions": [{"version": "v1", "created": "Fri, 29 Sep 2017 17:06:43 GMT"}, {"version": "v2", "created": "Sun, 12 Nov 2017 19:15:26 GMT"}], "update_date": "2017-11-15", "authors_parsed": [["Nielsen", "Frank", ""]]}]