[{"id": "1911.00002", "submitter": "Pablo Moreno-Mu\\~noz", "authors": "Pablo Moreno-Mu\\~noz, Antonio Art\\'es-Rodr\\'iguez and Mauricio A.\n  \\'Alvarez", "title": "Continual Multi-task Gaussian Processes", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We address the problem of continual learning in multi-task Gaussian process\n(GP) models for handling sequential input-output observations. Our approach\nextends the existing prior-posterior recursion of online Bayesian inference,\ni.e.\\ past posterior discoveries become future prior beliefs, to the infinite\nfunctional space setting of GP. For a reason of scalability, we introduce\nvariational inference together with an sparse approximation based on inducing\ninputs. As a consequence, we obtain tractable continual lower-bounds where two\nnovel Kullback-Leibler (KL) divergences intervene in a natural way. The key\ntechnical property of our method is the recursive reconstruction of conditional\nGP priors conditioned on the variational parameters learned so far. To achieve\nthis goal, we introduce a novel factorization of past variational\ndistributions, where the predictive GP equation propagates the posterior\nuncertainty forward. We then demonstrate that it is possible to derive GP\nmodels over many types of sequential observations, either discrete or\ncontinuous and amenable to stochastic optimization. The continual inference\napproach is also applicable to scenarios where potential multi-channel or\nheterogeneous observations might appear. Extensive experiments demonstrate that\nthe method is fully scalable, shows a reliable performance and is robust to\nuncertainty error propagation over a plenty of synthetic and real-world\ndatasets.\n", "versions": [{"version": "v1", "created": "Thu, 31 Oct 2019 13:49:11 GMT"}], "update_date": "2019-11-04", "authors_parsed": [["Moreno-Mu\u00f1oz", "Pablo", ""], ["Art\u00e9s-Rodr\u00edguez", "Antonio", ""], ["\u00c1lvarez", "Mauricio A.", ""]]}, {"id": "1911.00025", "submitter": "Raymond A. Yeh", "authors": "Iou-Jen Liu, Raymond A. Yeh, Alexander G. Schwing", "title": "PIC: Permutation Invariant Critic for Multi-Agent Deep Reinforcement\n  Learning", "comments": "Accepted to CORL2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Sample efficiency and scalability to a large number of agents are two\nimportant goals for multi-agent reinforcement learning systems. Recent works\ngot us closer to those goals, addressing non-stationarity of the environment\nfrom a single agent's perspective by utilizing a deep net critic which depends\non all observations and actions. The critic input concatenates agent\nobservations and actions in a user-specified order. However, since deep nets\naren't permutation invariant, a permuted input changes the critic output\ndespite the environment remaining identical. To avoid this inefficiency, we\npropose a 'permutation invariant critic' (PIC), which yields identical output\nirrespective of the agent permutation. This consistent representation enables\nour model to scale to 30 times more agents and to achieve improvements of test\nepisode reward between 15% to 50% on the challenging multi-agent particle\nenvironment (MPE).\n", "versions": [{"version": "v1", "created": "Thu, 31 Oct 2019 18:04:42 GMT"}], "update_date": "2019-11-04", "authors_parsed": [["Liu", "Iou-Jen", ""], ["Yeh", "Raymond A.", ""], ["Schwing", "Alexander G.", ""]]}, {"id": "1911.00029", "submitter": "Raymond A. Yeh", "authors": "Raymond A. Yeh, Yuan-Ting Hu, Alexander G. Schwing", "title": "Chirality Nets for Human Pose Regression", "comments": "Accepted to NeurIPS2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose Chirality Nets, a family of deep nets that is equivariant to the\n\"chirality transform,\" i.e., the transformation to create a chiral pair.\nThrough parameter sharing, odd and even symmetry, we propose and prove variants\nof standard building blocks of deep nets that satisfy the equivariance\nproperty, including fully connected layers, convolutional layers,\nbatch-normalization, and LSTM/GRU cells. The proposed layers lead to a more\ndata efficient representation and a reduction in computation by exploiting\nsymmetry. We evaluate chirality nets on the task of human pose regression,\nwhich naturally exploits the left/right mirroring of the human body. We study\nthree pose regression tasks: 3D pose estimation from video, 2D pose\nforecasting, and skeleton based activity recognition. Our approach\nachieves/matches state-of-the-art results, with more significant gains on small\ndatasets and limited-data settings.\n", "versions": [{"version": "v1", "created": "Thu, 31 Oct 2019 18:09:05 GMT"}], "update_date": "2019-11-04", "authors_parsed": [["Yeh", "Raymond A.", ""], ["Hu", "Yuan-Ting", ""], ["Schwing", "Alexander G.", ""]]}, {"id": "1911.00030", "submitter": "Saurabh Sahu", "authors": "Saurabh Sahu, Rahul Gupta, Carol Espy-Wilson", "title": "Modeling Feature Representations for Affective Speech using Generative\n  Adversarial Networks", "comments": null, "journal-ref": "TAFFC-2019-08-0222.R2", "doi": null, "report-no": null, "categories": "cs.LG cs.SD eess.AS stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Emotion recognition is a classic field of research with a typical setup\nextracting features and feeding them through a classifier for prediction. On\nthe other hand, generative models jointly capture the distributional\nrelationship between emotions and the feature profiles. Relatively recently,\nGenerative Adversarial Networks (GANs) have surfaced as a new class of\ngenerative models and have shown considerable success in modeling distributions\nin the fields of computer vision and natural language understanding. In this\nwork, we experiment with variants of GAN architectures to generate feature\nvectors corresponding to an emotion in two ways: (i) A generator is trained\nwith samples from a mixture prior. Each mixture component corresponds to an\nemotional class and can be sampled to generate features from the corresponding\nemotion. (ii) A one-hot vector corresponding to an emotion can be explicitly\nused to generate the features. We perform analysis on such models and also\npropose different metrics used to measure the performance of the GAN models in\ntheir ability to generate realistic synthetic samples. Apart from evaluation on\na given dataset of interest, we perform a cross-corpus study where we study the\nutility of the synthetic samples as additional training data in low resource\nconditions.\n", "versions": [{"version": "v1", "created": "Thu, 31 Oct 2019 18:09:45 GMT"}], "update_date": "2020-11-16", "authors_parsed": [["Sahu", "Saurabh", ""], ["Gupta", "Rahul", ""], ["Espy-Wilson", "Carol", ""]]}, {"id": "1911.00038", "submitter": "Ziteng Sun", "authors": "Jayadev Acharya, Keith Bonawitz, Peter Kairouz, Daniel Ramage, Ziteng\n  Sun", "title": "Context-Aware Local Differential Privacy", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR cs.DS cs.IT math.IT stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Local differential privacy (LDP) is a strong notion of privacy for individual\nusers that often comes at the expense of a significant drop in utility. The\nclassical definition of LDP assumes that all elements in the data domain are\nequally sensitive. However, in many applications, some symbols are more\nsensitive than others. This work proposes a context-aware framework of local\ndifferential privacy that allows a privacy designer to incorporate the\napplication's context into the privacy definition. For binary data domains, we\nprovide a universally optimal privatization scheme and highlight its\nconnections to Warner's randomized response (RR) and Mangat's improved\nresponse. Motivated by geolocation and web search applications, for $k$-ary\ndata domains, we consider two special cases of context-aware LDP:\nblock-structured LDP and high-low LDP. We study discrete distribution\nestimation and provide communication-efficient, sample-optimal schemes and\ninformation-theoretic lower bounds for both models. We show that using\ncontextual information can require fewer samples than classical LDP to achieve\nthe same accuracy.\n", "versions": [{"version": "v1", "created": "Thu, 31 Oct 2019 18:15:33 GMT"}, {"version": "v2", "created": "Mon, 27 Jul 2020 23:00:22 GMT"}], "update_date": "2020-07-29", "authors_parsed": [["Acharya", "Jayadev", ""], ["Bonawitz", "Keith", ""], ["Kairouz", "Peter", ""], ["Ramage", "Daniel", ""], ["Sun", "Ziteng", ""]]}, {"id": "1911.00055", "submitter": "Ali Sadeghian", "authors": "Ali Sadeghian, Mohammadreza Armandpour, Patrick Ding, Daisy Zhe Wang", "title": "DRUM: End-To-End Differentiable Rule Mining On Knowledge Graphs", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.LO stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we study the problem of learning probabilistic logical rules\nfor inductive and interpretable link prediction. Despite the importance of\ninductive link prediction, most previous works focused on transductive link\nprediction and cannot manage previously unseen entities. Moreover, they are\nblack-box models that are not easily explainable for humans. We propose DRUM, a\nscalable and differentiable approach for mining first-order logical rules from\nknowledge graphs which resolves these problems. We motivate our method by\nmaking a connection between learning confidence scores for each rule and\nlow-rank tensor approximation. DRUM uses bidirectional RNNs to share useful\ninformation across the tasks of learning rules for different relations. We also\nempirically demonstrate the efficiency of DRUM over existing rule mining\nmethods for inductive link prediction on a variety of benchmark datasets.\n", "versions": [{"version": "v1", "created": "Thu, 31 Oct 2019 18:51:33 GMT"}], "update_date": "2019-11-04", "authors_parsed": [["Sadeghian", "Ali", ""], ["Armandpour", "Mohammadreza", ""], ["Ding", "Patrick", ""], ["Wang", "Daisy Zhe", ""]]}, {"id": "1911.00061", "submitter": "Yuval Heffetz", "authors": "Yuval Heffetz, Roman Vainstein, Gilad Katz, Lior Rokach", "title": "DeepLine: AutoML Tool for Pipelines Generation using Deep Reinforcement\n  Learning and Hierarchical Actions Filtering", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Automatic machine learning (AutoML) is an area of research aimed at\nautomating machine learning (ML) activities that currently require human\nexperts. One of the most challenging tasks in this field is the automatic\ngeneration of end-to-end ML pipelines: combining multiple types of ML\nalgorithms into a single architecture used for end-to-end analysis of\npreviously-unseen data. This task has two challenging aspects: the first is the\nneed to explore a large search space of algorithms and pipeline architectures.\nThe second challenge is the computational cost of training and evaluating\nmultiple pipelines. In this study we present DeepLine, a reinforcement learning\nbased approach for automatic pipeline generation. Our proposed approach\nutilizes an efficient representation of the search space and leverages past\nknowledge gained from previously-analyzed datasets to make the problem more\ntractable. Additionally, we propose a novel hierarchical-actions algorithm that\nserves as a plugin, mediating the environment-agent interaction in deep\nreinforcement learning problems. The plugin significantly speeds up the\ntraining process of our model. Evaluation on 56 datasets shows that DeepLine\noutperforms state-of-the-art approaches both in accuracy and in computational\ncost.\n", "versions": [{"version": "v1", "created": "Thu, 31 Oct 2019 19:06:14 GMT"}], "update_date": "2019-11-04", "authors_parsed": [["Heffetz", "Yuval", ""], ["Vainstein", "Roman", ""], ["Katz", "Gilad", ""], ["Rokach", "Lior", ""]]}, {"id": "1911.00068", "submitter": "Curtis Northcutt", "authors": "Curtis G. Northcutt, Lu Jiang, Isaac L. Chuang", "title": "Confident Learning: Estimating Uncertainty in Dataset Labels", "comments": "Published in Journal of Artificial Intelligence Research (JAIR)", "journal-ref": "Journal of Artificial Intelligence Research (JAIR) (2021)", "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Learning exists in the context of data, yet notions of confidence typically\nfocus on model predictions, not label quality. Confident learning (CL) is an\nalternative approach which focuses instead on label quality by characterizing\nand identifying label errors in datasets, based on the principles of pruning\nnoisy data, counting with probabilistic thresholds to estimate noise, and\nranking examples to train with confidence. Whereas numerous studies have\ndeveloped these principles independently, here, we combine them, building on\nthe assumption of a class-conditional noise process to directly estimate the\njoint distribution between noisy (given) labels and uncorrupted (unknown)\nlabels. This results in a generalized CL which is provably consistent and\nexperimentally performant. We present sufficient conditions where CL exactly\nfinds label errors, and show CL performance exceeding seven recent competitive\napproaches for learning with noisy labels on the CIFAR dataset. Uniquely, the\nCL framework is not coupled to a specific data modality or model (e.g., we use\nCL to find several label errors in the presumed error-free MNIST dataset and\nimprove sentiment classification on text data in Amazon Reviews). We also\nemploy CL on ImageNet to quantify ontological class overlap (e.g., estimating\n645 \"missile\" images are mislabeled as their parent class \"projectile\"), and\nmoderately increase model accuracy (e.g., for ResNet) by cleaning data prior to\ntraining. These results are replicable using the open-source cleanlab release.\n", "versions": [{"version": "v1", "created": "Thu, 31 Oct 2019 19:26:33 GMT"}, {"version": "v2", "created": "Fri, 21 Feb 2020 22:16:56 GMT"}, {"version": "v3", "created": "Fri, 4 Sep 2020 08:12:20 GMT"}, {"version": "v4", "created": "Mon, 15 Feb 2021 23:56:53 GMT"}, {"version": "v5", "created": "Thu, 8 Apr 2021 20:00:05 GMT"}], "update_date": "2021-04-12", "authors_parsed": [["Northcutt", "Curtis G.", ""], ["Jiang", "Lu", ""], ["Chuang", "Isaac L.", ""]]}, {"id": "1911.00069", "submitter": "Jian Ni", "authors": "Jian Ni, Radu Florian", "title": "Neural Cross-Lingual Relation Extraction Based on Bilingual Word\n  Embedding Mapping", "comments": "11 pages, Conference on Empirical Methods in Natural Language\n  Processing (EMNLP), 2019", "journal-ref": null, "doi": "10.18653/v1/D19-1038", "report-no": null, "categories": "cs.CL cs.IR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Relation extraction (RE) seeks to detect and classify semantic relationships\nbetween entities, which provides useful information for many NLP applications.\nSince the state-of-the-art RE models require large amounts of manually\nannotated data and language-specific resources to achieve high accuracy, it is\nvery challenging to transfer an RE model of a resource-rich language to a\nresource-poor language. In this paper, we propose a new approach for\ncross-lingual RE model transfer based on bilingual word embedding mapping. It\nprojects word embeddings from a target language to a source language, so that a\nwell-trained source-language neural network RE model can be directly applied to\nthe target language. Experiment results show that the proposed approach\nachieves very good performance for a number of target languages on both\nin-house and open datasets, using a small bilingual dictionary with only 1K\nword pairs.\n", "versions": [{"version": "v1", "created": "Thu, 31 Oct 2019 19:30:54 GMT"}], "update_date": "2019-11-13", "authors_parsed": [["Ni", "Jian", ""], ["Florian", "Radu", ""]]}, {"id": "1911.00071", "submitter": "Mohammad Eslami", "authors": "Mohammad Eslami, Mahdi Karami, Sedigheh Eslami, Solale Tabarestani,\n  Farah Torkamani-Azar, Christoph Meinel", "title": "SignCol: Open-Source Software for Collecting Sign Language Gestures", "comments": "The paper is presented at ICSESS conference but the published version\n  by them on the IEEE Xplore is impaired and the quality of figures is\n  inappropriate!! This is the preprint version which had appropriate format and\n  figures", "journal-ref": null, "doi": "10.1109/ICSESS.2018.8663952", "report-no": null, "categories": "cs.HC cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Sign(ed) languages use gestures, such as hand or head movements, for\ncommunication. Sign language recognition is an assistive technology for\nindividuals with hearing disability and its goal is to improve such\nindividuals' life quality by facilitating their social involvement. Since sign\nlanguages are vastly varied in alphabets, as known as signs, a sign recognition\nsoftware should be capable of handling eight different types of sign\ncombinations, e.g. numbers, letters, words and sentences. Due to the intrinsic\ncomplexity and diversity of symbolic gestures, recognition algorithms need a\ncomprehensive visual dataset to learn by. In this paper, we describe the design\nand implementation of a Microsoft Kinect-based open source software, called\nSignCol, for capturing and saving the gestures used in sign languages. Our work\nsupports a multi-language database and reports the recorded items statistics.\nSignCol can capture and store colored(RGB) frames, depth frames, infrared\nframes, body index frames, coordinate mapped color-body frames, skeleton\ninformation of each frame and camera parameters simultaneously.\n", "versions": [{"version": "v1", "created": "Thu, 31 Oct 2019 19:36:18 GMT"}], "update_date": "2019-11-04", "authors_parsed": [["Eslami", "Mohammad", ""], ["Karami", "Mahdi", ""], ["Eslami", "Sedigheh", ""], ["Tabarestani", "Solale", ""], ["Torkamani-Azar", "Farah", ""], ["Meinel", "Christoph", ""]]}, {"id": "1911.00077", "submitter": "Alexandros Iosifidis", "authors": "William Lund Sommer and Alexandros Iosifidis", "title": "Text-to-image synthesis method evaluation based on visual patterns", "comments": "11 pages, including supplementary material", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A commonly used evaluation metric for text-to-image synthesis is the\nInception score (IS) \\cite{inceptionscore}, which has been shown to be a\nquality metric that correlates well with human judgment. However, IS does not\nreveal properties of the generated images indicating the ability of a\ntext-to-image synthesis method to correctly convey semantics of the input text\ndescriptions. In this paper, we introduce an evaluation metric and a visual\nevaluation method allowing for the simultaneous estimation of the realism,\nvariety and semantic accuracy of generated images. The proposed method uses a\npre-trained Inception network \\cite{inceptionnet} to produce high dimensional\nrepresentations for both real and generated images. These image representations\nare then visualized in a $2$-dimensional feature space defined by the\nt-distributed Stochastic Neighbor Embedding (t-SNE) \\cite{tsne}. Visual\nconcepts are determined by clustering the real image representations, and are\nsubsequently used to evaluate the similarity of the generated images to the\nreal ones by classifying them to the closest visual concept. The resulting\nclassification accuracy is shown to be a effective gauge for the semantic\naccuracy of text-to-image synthesis methods.\n", "versions": [{"version": "v1", "created": "Thu, 31 Oct 2019 19:50:42 GMT"}], "update_date": "2019-11-04", "authors_parsed": [["Sommer", "William Lund", ""], ["Iosifidis", "Alexandros", ""]]}, {"id": "1911.00081", "submitter": "Hao-Chih Lee", "authors": "Hao-Chih Lee, Matteo Danieletto, Riccardo Miotto, Sarah T. Cherng and\n  Joel T. Dudley", "title": "Scaling structural learning with NO-BEARS to infer causal transcriptome\n  networks", "comments": "Preprint of an article submitted for consideration in Pacific\n  Symposium on Biocomputing copyright 2019 World Scientific Publishing Co.,\n  Singapore, http://psb.stanford.edu/http://psb.stanford.edu/", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.GN cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Constructing gene regulatory networks is a critical step in revealing disease\nmechanisms from transcriptomic data. In this work, we present NO-BEARS, a novel\nalgorithm for estimating gene regulatory networks. The NO-BEARS algorithm is\nbuilt on the basis of the NOTEARS algorithm with two improvements. First, we\npropose a new constraint and its fast approximation to reduce the computational\ncost of the NO-TEARS algorithm. Next, we introduce a polynomial regression loss\nto handle non-linearity in gene expressions. Our implementation utilizes modern\nGPU computation that can decrease the time of hours-long CPU computation to\nseconds. Using synthetic data, we demonstrate improved performance, both in\nprocessing time and accuracy, on inferring gene regulatory networks from gene\nexpression data.\n", "versions": [{"version": "v1", "created": "Thu, 31 Oct 2019 19:52:18 GMT"}], "update_date": "2019-11-04", "authors_parsed": [["Lee", "Hao-Chih", ""], ["Danieletto", "Matteo", ""], ["Miotto", "Riccardo", ""], ["Cherng", "Sarah T.", ""], ["Dudley", "Joel T.", ""]]}, {"id": "1911.00089", "submitter": "Michael Hauser", "authors": "Yiwei Fu, Samer Saab Jr, Asok Ray and Michael Hauser", "title": "A Dynamically Controlled Recurrent Neural Network for Modeling Dynamical\n  Systems", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This work proposes a novel neural network architecture, called the\nDynamically Controlled Recurrent Neural Network (DCRNN), specifically designed\nto model dynamical systems that are governed by ordinary differential equations\n(ODEs). The current state vectors of these types of dynamical systems only\ndepend on their state-space models, along with the respective inputs and\ninitial conditions. Long Short-Term Memory (LSTM) networks, which have proven\nto be very effective for memory-based tasks, may fail to model physical\nprocesses as they tend to memorize, rather than learn how to capture the\ninformation on the underlying dynamics. The proposed DCRNN includes learnable\nskip-connections across previously hidden states, and introduces a\nregularization term in the loss function by relying on Lyapunov stability\ntheory. The regularizer enables the placement of eigenvalues of the transfer\nfunction induced by the DCRNN to desired values, thereby acting as an internal\ncontroller for the hidden state trajectory. The results show that, for\nforecasting a chaotic dynamical system, the DCRNN outperforms the LSTM in $100$\nout of $100$ randomized experiments by reducing the mean squared error of the\nLSTM's forecasting by $80.0\\% \\pm 3.0\\%$.\n", "versions": [{"version": "v1", "created": "Thu, 31 Oct 2019 20:22:38 GMT"}], "update_date": "2019-11-04", "authors_parsed": [["Fu", "Yiwei", ""], ["Saab", "Samer", "Jr"], ["Ray", "Asok", ""], ["Hauser", "Michael", ""]]}, {"id": "1911.00103", "submitter": "Haibin Chang", "authors": "Nanzhe Wang, Dongxiao Zhang, Haibin Chang, Heng Li", "title": "Deep Learning of Subsurface Flow via Theory-guided Neural Network", "comments": null, "journal-ref": "Journal of Hydrology, 2020, 584, 124700", "doi": "10.1016/j.jhydrol.2020.124700", "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Active researches are currently being performed to incorporate the wealth of\nscientific knowledge into data-driven approaches (e.g., neural networks) in\norder to improve the latter's effectiveness. In this study, the Theory-guided\nNeural Network (TgNN) is proposed for deep learning of subsurface flow. In the\nTgNN, as supervised learning, the neural network is trained with available\nobservations or simulation data while being simultaneously guided by theory\n(e.g., governing equations, other physical constraints, engineering controls,\nand expert knowledge) of the underlying problem. The TgNN can achieve higher\naccuracy than the ordinary Artificial Neural Network (ANN) because the former\nprovides physically feasible predictions and can be more readily generalized\nbeyond the regimes covered with the training data. Furthermore, the TgNN model\nis proposed for subsurface flow with heterogeneous model parameters. Several\nnumerical cases of two-dimensional transient saturated flow are introduced to\ntest the performance of the TgNN. In the learning process, the loss function\ncontains data mismatch, as well as PDE constraint, engineering control, and\nexpert knowledge. After obtaining the parameters of the neural network by\nminimizing the loss function, a TgNN model is built that not only fits the\ndata, but also adheres to physical/engineering constraints. Predicting the\nfuture response can be easily realized by the TgNN model. In addition, the TgNN\nmodel is tested in more complicated scenarios, such as prediction with changed\nboundary conditions, learning from noisy data or outliers, transfer learning,\nand engineering controls. Numerical results demonstrate that the TgNN model\nachieves much better predictability, reliability, and generalizability than ANN\nmodels due to the physical/engineering constraints in the former.\n", "versions": [{"version": "v1", "created": "Thu, 24 Oct 2019 08:49:57 GMT"}], "update_date": "2020-03-03", "authors_parsed": [["Wang", "Nanzhe", ""], ["Zhang", "Dongxiao", ""], ["Chang", "Haibin", ""], ["Li", "Heng", ""]]}, {"id": "1911.00104", "submitter": "Nabeel Seedat", "authors": "Nabeel Seedat and Christopher Kanan", "title": "Towards calibrated and scalable uncertainty representations for neural\n  networks", "comments": "33rd Conference on Neural Information Processing Systems (NeurIPS\n  2019): 4th workshop on Bayesian Deep Learning, Vancouver, Canada", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  For many applications it is critical to know the uncertainty of a neural\nnetwork's predictions. While a variety of neural network parameter estimation\nmethods have been proposed for uncertainty estimation, they have not been\nrigorously compared across uncertainty measures. We assess four of these\nparameter estimation methods to calibrate uncertainty estimation using four\ndifferent uncertainty measures: entropy, mutual information, aleatoric\nuncertainty and epistemic uncertainty. We evaluate the calibration of these\nparameter estimation methods using expected calibration error. Additionally, we\npropose a novel method of neural network parameter estimation called RECAST,\nwhich combines cosine annealing with warm restarts with Stochastic Gradient\nLangevin Dynamics, capturing more diverse parameter distributions. When\nbenchmarked against mutilated image data, we show that RECAST is\nwell-calibrated and when combined with predictive entropy and epistemic\nuncertainty it offers the best calibrated measure of uncertainty when compared\nto recent methods.\n", "versions": [{"version": "v1", "created": "Mon, 28 Oct 2019 02:29:55 GMT"}, {"version": "v2", "created": "Mon, 4 Nov 2019 01:30:14 GMT"}, {"version": "v3", "created": "Wed, 4 Dec 2019 02:19:35 GMT"}], "update_date": "2019-12-05", "authors_parsed": [["Seedat", "Nabeel", ""], ["Kanan", "Christopher", ""]]}, {"id": "1911.00105", "submitter": "Weiwen Jiang", "authors": "Qing Lu, Weiwen Jiang, Xiaowei Xu, Yiyu Shi, Jingtong Hu", "title": "On Neural Architecture Search for Resource-Constrained Hardware\n  Platforms", "comments": "8 pages, ICCAD 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.NE eess.SP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In the recent past, the success of Neural Architecture Search (NAS) has\nenabled researchers to broadly explore the design space using learning-based\nmethods. Apart from finding better neural network architectures, the idea of\nautomation has also inspired to improve their implementations on hardware.\nWhile some practices of hardware machine-learning automation have achieved\nremarkable performance, the traditional design concept is still followed: a\nnetwork architecture is first structured with excellent test accuracy, and then\ncompressed and optimized to fit into a target platform. Such a design flow will\neasily lead to inferior local-optimal solutions. To address this problem, we\npropose a new framework to jointly explore the space of neural architecture,\nhardware implementation, and quantization. Our objective is to find a quantized\narchitecture with the highest accuracy that is implementable on given hardware\nspecifications. We employ FPGAs to implement and test our designs with limited\nloop-up tables (LUTs) and required throughput. Compared to the separate\ndesign/searching methods, our framework has demonstrated much better\nperformance under strict specifications and generated designs of higher\naccuracy by 18\\% to 68\\% in the task of classifying CIFAR10 images. With 30,000\nLUTs, a light-weight design is found to achieve 82.98\\% accuracy and 1293\nimages/second throughput, compared to which, under the same constraints, the\ntraditional method even fails to find a valid solution.\n", "versions": [{"version": "v1", "created": "Thu, 31 Oct 2019 21:02:23 GMT"}], "update_date": "2019-11-04", "authors_parsed": [["Lu", "Qing", ""], ["Jiang", "Weiwen", ""], ["Xu", "Xiaowei", ""], ["Shi", "Yiyu", ""], ["Hu", "Jingtong", ""]]}, {"id": "1911.00108", "submitter": "Roman Vainshtein", "authors": "Doron Laadan, Roman Vainshtein, Yarden Curiel, Gilad Katz, Lior Rokach", "title": "RankML: a Meta Learning-Based Approach for Pre-Ranking Machine Learning\n  Pipelines", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The explosion of digital data has created multiple opportunities for\norganizations and individuals to leverage machine learning (ML) to transform\nthe way they operate. However, the shortage of experts in the field of machine\nlearning -- data scientists -- is often a setback to the use of ML. In an\nattempt to alleviate this shortage, multiple approaches for the automation of\nmachine learning have been proposed in recent years. While these approaches are\neffective, they often require a great deal of time and computing resources. In\nthis study, we propose RankML, a meta-learning based approach for predicting\nthe performance of whole machine learning pipelines. Given a previously-unseen\ndataset, a performance metric, and a set of candidate pipelines, RankML\nimmediately produces a ranked list of all pipelines based on their predicted\nperformance. Extensive evaluation on 244 datasets, both in regression and\nclassification tasks, shows that our approach either outperforms or is\ncomparable to state-of-the-art, computationally heavy approaches while\nrequiring a fraction of the time and computational cost.\n", "versions": [{"version": "v1", "created": "Thu, 31 Oct 2019 21:05:24 GMT"}, {"version": "v2", "created": "Wed, 20 Nov 2019 16:03:39 GMT"}], "update_date": "2019-11-21", "authors_parsed": [["Laadan", "Doron", ""], ["Vainshtein", "Roman", ""], ["Curiel", "Yarden", ""], ["Katz", "Gilad", ""], ["Rokach", "Lior", ""]]}, {"id": "1911.00111", "submitter": "Xiaodi Wu", "authors": "Shouvanik Chakrabarti, Yiming Huang, Tongyang Li, Soheil Feizi, Xiaodi\n  Wu", "title": "Quantum Wasserstein Generative Adversarial Networks", "comments": "Accepted to the 33rd Conference on Neural Information Processing\n  Systems (NeurIPS 2019). Codes are available at\n  https://github.com/yiminghwang/qWGAN", "journal-ref": null, "doi": null, "report-no": null, "categories": "quant-ph cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The study of quantum generative models is well-motivated, not only because of\nits importance in quantum machine learning and quantum chemistry but also\nbecause of the perspective of its implementation on near-term quantum machines.\nInspired by previous studies on the adversarial training of classical and\nquantum generative models, we propose the first design of quantum Wasserstein\nGenerative Adversarial Networks (WGANs), which has been shown to improve the\nrobustness and the scalability of the adversarial training of quantum\ngenerative models even on noisy quantum hardware. Specifically, we propose a\ndefinition of the Wasserstein semimetric between quantum data, which inherits a\nfew key theoretical merits of its classical counterpart. We also demonstrate\nhow to turn the quantum Wasserstein semimetric into a concrete design of\nquantum WGANs that can be efficiently implemented on quantum machines. Our\nnumerical study, via classical simulation of quantum systems, shows the more\nrobust and scalable numerical performance of our quantum WGANs over other\nquantum GAN proposals. As a surprising application, our quantum WGAN has been\nused to generate a 3-qubit quantum circuit of ~50 gates that well approximates\na 3-qubit 1-d Hamiltonian simulation circuit that requires over 10k gates using\nstandard techniques.\n", "versions": [{"version": "v1", "created": "Thu, 31 Oct 2019 21:11:57 GMT"}], "update_date": "2019-11-04", "authors_parsed": [["Chakrabarti", "Shouvanik", ""], ["Huang", "Yiming", ""], ["Li", "Tongyang", ""], ["Feizi", "Soheil", ""], ["Wu", "Xiaodi", ""]]}, {"id": "1911.00119", "submitter": "Chengcheng Wan", "authors": "Chengcheng Wan, Muhammad Santriaji, Eri Rogers, Henry Hoffmann,\n  Michael Maire, Shan Lu", "title": "ALERT: Accurate Learning for Energy and Timeliness", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.PF cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  An increasing number of software applications incorporate runtime Deep Neural\nNetworks (DNNs) to process sensor data and return inference results to humans.\nEffective deployment of DNNs in these interactive scenarios requires meeting\nlatency and accuracy constraints while minimizing energy, a problem exacerbated\nby common system dynamics. Prior approaches handle dynamics through either (1)\nsystem-oblivious DNN adaptation, which adjusts DNN latency/accuracy tradeoffs,\nor (2) application-oblivious system adaptation, which adjusts resources to\nchange latency/energy tradeoffs. In contrast, this paper improves on the\nstate-of-the-art by coordinating application- and system-level adaptation.\nALERT, our runtime scheduler, uses a probabilistic model to detect\nenvironmental volatility and then simultaneously select both a DNN and a system\nresource configuration to meet latency, accuracy, and energy constraints. We\nevaluate ALERT on CPU and GPU platforms for image and speech tasks in dynamic\nenvironments. ALERT's holistic approach achieves more than 13% energy\nreduction, and 27% error reduction over prior approaches that adapt solely at\nthe application or system level. Furthermore, ALERT incurs only 3% more energy\nconsumption and 2% higher DNN-inference error than an oracle scheme with\nperfect application and system knowledge.\n", "versions": [{"version": "v1", "created": "Thu, 31 Oct 2019 21:40:42 GMT"}, {"version": "v2", "created": "Thu, 28 May 2020 12:33:53 GMT"}], "update_date": "2020-05-29", "authors_parsed": [["Wan", "Chengcheng", ""], ["Santriaji", "Muhammad", ""], ["Rogers", "Eri", ""], ["Hoffmann", "Henry", ""], ["Maire", "Michael", ""], ["Lu", "Shan", ""]]}, {"id": "1911.00126", "submitter": "Juncheng Li", "authors": "Juncheng B. Li, Shuhui Qu, Xinjian Li, Joseph Szurley, J. Zico Kolter,\n  Florian Metze", "title": "Adversarial Music: Real World Audio Adversary Against Wake-word\n  Detection System", "comments": "9 pages, In Proceedings of NeurIPS 2019 Conference", "journal-ref": "NIPS2019_9362, pages = {11908--11918}, year = {2019}, publisher =\n  {Curran Associates, Inc.}, url =\n  {http://papers.nips.cc/paper/9362-adversarial-music-real-world-audio-adversary-against-wake-word-detection-system.pdf}\n  }", "doi": null, "report-no": null, "categories": "cs.CR cs.LG cs.SD", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Voice Assistants (VAs) such as Amazon Alexa or Google Assistant rely on\nwake-word detection to respond to people's commands, which could potentially be\nvulnerable to audio adversarial examples. In this work, we target our attack on\nthe wake-word detection system, jamming the model with some inconspicuous\nbackground music to deactivate the VAs while our audio adversary is present. We\nimplemented an emulated wake-word detection system of Amazon Alexa based on\nrecent publications. We validated our models against the real Alexa in terms of\nwake-word detection accuracy. Then we computed our audio adversaries with\nconsideration of expectation over transform and we implemented our audio\nadversary with a differentiable synthesizer. Next, we verified our audio\nadversaries digitally on hundreds of samples of utterances collected from the\nreal world. Our experiments show that we can effectively reduce the recognition\nF1 score of our emulated model from 93.4% to 11.0%. Finally, we tested our\naudio adversary over the air, and verified it works effectively against Alexa,\nreducing its F1 score from 92.5% to 11.0%.; We also verified that\nnon-adversarial music does not disable Alexa as effectively as our music at the\nsame sound level. To the best of our knowledge, this is the first real-world\nadversarial attack against a commercial-grade VA wake-word detection system.\nOur code and demo videos can be accessed at\n\\url{https://www.junchengbillyli.com/AdversarialMusic}\n", "versions": [{"version": "v1", "created": "Thu, 31 Oct 2019 21:58:50 GMT"}, {"version": "v2", "created": "Thu, 5 Dec 2019 17:03:17 GMT"}, {"version": "v3", "created": "Fri, 6 Dec 2019 02:12:45 GMT"}], "update_date": "2019-12-09", "authors_parsed": [["Li", "Juncheng B.", ""], ["Qu", "Shuhui", ""], ["Li", "Xinjian", ""], ["Szurley", "Joseph", ""], ["Kolter", "J. Zico", ""], ["Metze", "Florian", ""]]}, {"id": "1911.00139", "submitter": "Weiwen Jiang", "authors": "Weiwen Jiang, Qiuwen Lou, Zheyu Yan, Lei Yang, Jingtong Hu, Xiaobo\n  Sharon Hu, Yiyu Shi", "title": "Device-Circuit-Architecture Co-Exploration for Computing-in-Memory\n  Neural Accelerators", "comments": "10 pages, 6 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Co-exploration of neural architectures and hardware design is promising to\nsimultaneously optimize network accuracy and hardware efficiency. However,\nstate-of-the-art neural architecture search algorithms for the co-exploration\nare dedicated for the conventional von-neumann computing architecture, whose\nperformance is heavily limited by the well-known memory wall. In this paper, we\nare the first to bring the computing-in-memory architecture, which can easily\ntranscend the memory wall, to interplay with the neural architecture search,\naiming to find the most efficient neural architectures with high network\naccuracy and maximized hardware efficiency. Such a novel combination makes\nopportunities to boost performance, but also brings a bunch of challenges. The\ndesign space spans across multiple layers from device type, circuit topology to\nneural architecture. In addition, the performance may degrade in the presence\nof device variation. To address these challenges, we propose a cross-layer\nexploration framework, namely NACIM, which jointly explores device, circuit and\narchitecture design space and takes device variation into consideration to find\nthe most robust neural architectures. Experimental results demonstrate that\nNACIM can find the robust neural network with 0.45% accuracy loss in the\npresence of device variation, compared with a 76.44% loss from the\nstate-of-the-art NAS without consideration of variation; in addition, NACIM\nachieves an energy efficiency up to 16.3 TOPs/W, 3.17X higher than the\nstate-of-the-art NAS.\n", "versions": [{"version": "v1", "created": "Thu, 31 Oct 2019 22:42:33 GMT"}, {"version": "v2", "created": "Sat, 21 Mar 2020 00:21:42 GMT"}], "update_date": "2020-03-24", "authors_parsed": [["Jiang", "Weiwen", ""], ["Lou", "Qiuwen", ""], ["Yan", "Zheyu", ""], ["Yang", "Lei", ""], ["Hu", "Jingtong", ""], ["Hu", "Xiaobo Sharon", ""], ["Shi", "Yiyu", ""]]}, {"id": "1911.00140", "submitter": "Hyunseok  Seo", "authors": "Hyunseok Seo, Charles Huang, Maxime Bassenne, Ruoxiu Xiao, and Lei\n  Xing", "title": "Modified U-Net (mU-Net) with Incorporation of Object-Dependent High\n  Level Features for Improved Liver and Liver-Tumor Segmentation in CT Images", "comments": "Accept for publication at IEEE Transactions on Medical Imaging", "journal-ref": null, "doi": "10.1109/TMI.2019.2948320", "report-no": null, "categories": "eess.IV cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Segmentation of livers and liver tumors is one of the most important steps in\nradiation therapy of hepatocellular carcinoma. The segmentation task is often\ndone manually, making it tedious, labor intensive, and subject to intra-/inter-\noperator variations. While various algorithms for delineating organ-at-risks\n(OARs) and tumor targets have been proposed, automatic segmentation of livers\nand liver tumors remains intractable due to their low tissue contrast with\nrespect to the surrounding organs and their deformable shape in CT images. The\nU-Net has gained increasing popularity recently for image analysis tasks and\nhas shown promising results. Conventional U-Net architectures, however, suffer\nfrom three major drawbacks. To cope with these problems, we added a residual\npath with deconvolution and activation operations to the skip connection of the\nU-Net to avoid duplication of low resolution information of features. In the\ncase of small object inputs, features in the skip connection are not\nincorporated with features in the residual path. Furthermore, the proposed\narchitecture has additional convolution layers in the skip connection in order\nto extract high level global features of small object inputs as well as high\nlevel features of high resolution edge information of large object inputs.\nEfficacy of the modified U-Net (mU-Net) was demonstrated using the public\ndataset of Liver tumor segmentation (LiTS) challenge 2017. The proposed mU-Net\noutperformed existing state-of-art networks.\n", "versions": [{"version": "v1", "created": "Thu, 31 Oct 2019 22:42:53 GMT"}], "update_date": "2019-11-04", "authors_parsed": [["Seo", "Hyunseok", ""], ["Huang", "Charles", ""], ["Bassenne", "Maxime", ""], ["Xiao", "Ruoxiu", ""], ["Xing", "Lei", ""]]}, {"id": "1911.00147", "submitter": "Chris Thomas", "authors": "Christopher Thomas and Adriana Kovashka", "title": "Predicting the Politics of an Image Using Webly Supervised Data", "comments": null, "journal-ref": "33rd Conference on Neural Information Processing Systems (NeurIPS\n  2019), Vancouver, Canada", "doi": null, "report-no": null, "categories": "cs.LG cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The news media shape public opinion, and often, the visual bias they contain\nis evident for human observers. This bias can be inferred from how different\nmedia sources portray different subjects or topics. In this paper, we model\nvisual political bias in contemporary media sources at scale, using webly\nsupervised data. We collect a dataset of over one million unique images and\nassociated news articles from left- and right-leaning news sources, and develop\na method to predict the image's political leaning. This problem is particularly\nchallenging because of the enormous intra-class visual and semantic diversity\nof our data. We propose a two-stage method to tackle this problem. In the first\nstage, the model is forced to learn relevant visual concepts that, when joined\nwith document embeddings computed from articles paired with the images, enable\nthe model to predict bias. In the second stage, we remove the requirement of\nthe text domain and train a visual classifier from the features of the former\nmodel. We show this two-stage approach facilitates learning and outperforms\nseveral strong baselines. We also present extensive qualitative results\ndemonstrating the nuances of the data.\n", "versions": [{"version": "v1", "created": "Thu, 31 Oct 2019 23:11:21 GMT"}], "update_date": "2019-11-04", "authors_parsed": [["Thomas", "Christopher", ""], ["Kovashka", "Adriana", ""]]}, {"id": "1911.00155", "submitter": "Ali Ayub", "authors": "Ali Ayub, Alan R. Wagner", "title": "Centroid Based Concept Learning for RGB-D Indoor Scene Classification", "comments": "Accepted at BMVC 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper contributes a novel cognitively-inspired method for RGB-D indoor\nscene classification. High intra-class variance and low inter-class variance\nmake indoor scene classification an extremely challenging task. To cope with\nthis problem, we propose a clustering approach inspired by the concept learning\nmodel of the hippocampus and the neocortex, to generate clusters and centroids\nfor different scene categories. Test images depicting different scenes are\nclassified by using their distance to the closest centroids (concepts).\nModeling of RGB-D scenes as centroids not only leads to state-of-the-art\nclassification performance on benchmark datasets (SUN RGB-D and NYU Depth V2),\nbut also offers a method for inspecting and interpreting the space of\ncentroids. Inspection of the centroids generated by our approach on RGB-D\ndatasets leads us to propose a method for merging conceptually similar\ncategories, resulting in improved accuracy for all approaches.\n", "versions": [{"version": "v1", "created": "Fri, 1 Nov 2019 00:09:37 GMT"}, {"version": "v2", "created": "Thu, 23 Jan 2020 00:03:56 GMT"}, {"version": "v3", "created": "Thu, 6 Aug 2020 22:25:22 GMT"}, {"version": "v4", "created": "Sat, 15 Aug 2020 01:26:48 GMT"}], "update_date": "2020-08-18", "authors_parsed": [["Ayub", "Ali", ""], ["Wagner", "Alan R.", ""]]}, {"id": "1911.00165", "submitter": "Wenjie Lu", "authors": "Wenjie Lu and Dikai Liu", "title": "A2: Extracting Cyclic Switchings from DOB-nets for Rejecting Excessive\n  Disturbances", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Reinforcement Learning (RL) is limited in practice by its gray-box nature,\nwhich is responsible for insufficient trustiness from users, unsatisfied\ninterpretation for human intervention, inadequate analysis for future\nimprovement, etc. This paper seeks to partially characterize the interplay\nbetween dynamical environments and the DOB-net. The DOB-net obtained from RL\nsolves a set of Partially Observable Markovian Decision Processes (POMDPs). The\ntransition function of each POMDP is largely determined by the environments,\nwhich are excessive external disturbances in this research. This paper proposes\nan Attention-based Abstraction (A${}^2$) approach to extract a finite-state\nautomaton, referred to as a Key Moore Machine Network (KMMN), to capture the\nswitching mechanisms exhibited by the DOB-net in dealing with multiple such\nPOMDPs. This approach first quantizes the controlled platform by learning\ncontinuous-discrete interfaces. Then it extracts the KMMN by finding the key\nhidden states and transitions that attract sufficient attention from the\nDOB-net. Within the resultant KMMN, this study found three patterns of cyclic\nswitchings (between key hidden states), showing controls near their saturation\nare synchronized with unknown disturbances. Interestingly, the found switching\nmechanism has appeared previously in the design of hybrid control for\noften-saturated systems. It is further interpreted via an analogy to the\ndiscrete-event subsystem in the hybrid control.\n", "versions": [{"version": "v1", "created": "Fri, 1 Nov 2019 00:42:07 GMT"}], "update_date": "2019-11-04", "authors_parsed": [["Lu", "Wenjie", ""], ["Liu", "Dikai", ""]]}, {"id": "1911.00171", "submitter": "Vinicius G. Goecks", "authors": "Ritwik Bera, Vinicius G. Goecks, Gregory M. Gremillion, John Valasek,\n  and Nicholas R. Waytowich", "title": "PODNet: A Neural Network for Discovery of Plannable Options", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Learning from demonstration has been widely studied in machine learning but\nbecomes challenging when the demonstrated trajectories are unstructured and\nfollow different objectives. This short-paper proposes PODNet, Plannable Option\nDiscovery Network, addressing how to segment an unstructured set of\ndemonstrated trajectories for option discovery. This enables learning from\ndemonstration to perform multiple tasks and plan high-level trajectories based\non the discovered option labels. PODNet combines a custom categorical\nvariational autoencoder, a recurrent option inference network,\noption-conditioned policy network, and option dynamics model in an end-to-end\nlearning architecture. Due to the concurrently trained option-conditioned\npolicy network and option dynamics model, the proposed architecture has\nimplications in multi-task and hierarchical learning, explainable and\ninterpretable artificial intelligence, and applications where the agent is\nrequired to learn only from observations.\n", "versions": [{"version": "v1", "created": "Fri, 1 Nov 2019 01:09:46 GMT"}, {"version": "v2", "created": "Fri, 15 Nov 2019 07:04:21 GMT"}, {"version": "v3", "created": "Fri, 28 Feb 2020 14:51:39 GMT"}], "update_date": "2020-03-02", "authors_parsed": [["Bera", "Ritwik", ""], ["Goecks", "Vinicius G.", ""], ["Gremillion", "Gregory M.", ""], ["Valasek", "John", ""], ["Waytowich", "Nicholas R.", ""]]}, {"id": "1911.00179", "submitter": "Yifei Wang", "authors": "Yifei Wang, Rui Liu, Yong Chen, Hui Zhangs and Zhiwen Ye", "title": "Regularized Non-negative Spectral Embedding for Clustering", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Spectral Clustering is a popular technique to split data points into groups,\nespecially for complex datasets. The algorithms in the Spectral Clustering\nfamily typically consist of multiple separate stages (such as similarity matrix\nconstruction, low-dimensional embedding, and K-Means clustering as post\nprocessing), which may lead to sub-optimal results because of the possible\nmismatch between different stages. In this paper, we propose an end-to-end\nsingle-stage learning method to clustering called Regularized Non-negative\nSpectral Embedding (RNSE) which extends Spectral Clustering with the adaptive\nlearning of similarity matrix and meanwhile utilizes non-negative constraints\nto facilitate one-step clustering (directly from data points to clustering\nlabels). Two well-founded methods, successive alternating projection and\nstrategic multiplicative update, are employed to work out the quite challenging\noptimization problems in RNSE. Extensive experiments on both synthetic and\nreal-world datasets demonstrate RNSE superior clustering performance to some\nstate-of-the-art competitors.\n", "versions": [{"version": "v1", "created": "Fri, 1 Nov 2019 01:52:36 GMT"}], "update_date": "2019-11-04", "authors_parsed": [["Wang", "Yifei", ""], ["Liu", "Rui", ""], ["Chen", "Yong", ""], ["Zhangs", "Hui", ""], ["Ye", "Zhiwen", ""]]}, {"id": "1911.00184", "submitter": "Sreelekha Guggilam", "authors": "Sreelekha Guggilam and Syed M. A. Zaidi and Varun Chandola and Abani\n  K. Patra", "title": "Integrated Clustering and Anomaly Detection (INCAD) for Streaming Data\n  (Revised)", "comments": "13 pages; fixes typos in equations 5,6,9,10 on inference using Gibbs\n  sampling", "journal-ref": "ICCS 2019. Lecture Notes in Computer Science, vol 11539. Springer,\n  Cham,", "doi": "10.1007/978-3-030-22747-0_4", "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Most current clustering based anomaly detection methods use scoring schema\nand thresholds to classify anomalies. These methods are often tailored to\ntarget specific data sets with \"known\" number of clusters. The paper provides a\nstreaming clustering and anomaly detection algorithm that does not require\nstrict arbitrary thresholds on the anomaly scores or knowledge of the number of\nclusters while performing probabilistic anomaly detection and clustering\nsimultaneously. This ensures that the cluster formation is not impacted by the\npresence of anomalous data, thereby leading to more reliable definition of\n\"normal vs abnormal\" behavior. The motivations behind developing the INCAD\nmodel and the path that leads to the streaming model is discussed.\n", "versions": [{"version": "v1", "created": "Fri, 1 Nov 2019 02:27:08 GMT"}], "update_date": "2019-11-04", "authors_parsed": [["Guggilam", "Sreelekha", ""], ["Zaidi", "Syed M. A.", ""], ["Chandola", "Varun", ""], ["Patra", "Abani K.", ""]]}, {"id": "1911.00185", "submitter": "Ziru Liu", "authors": "Guangyan Zhang, Ziru Liu, Jichen Dai, Zilan Yu, Shuai Liu, and Wen\n  Zhang", "title": "ItLnc-BXE: a Bagging-XGBoost-ensemble method with multiple features for\n  identification of plant lncRNAs", "comments": "7 pages, 3 figures, 4 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.GN cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Motivation: Since long non-coding RNAs (lncRNAs) have involved in a wide\nrange of functions in cellular and developmental processes, an increasing\nnumber of methods have been proposed for distinguishing lncRNAs from coding\nRNAs. However, most of the existing methods are designed for lncRNAs in animal\nsystems, and only a few methods focus on the plant lncRNA identification.\nDifferent from lncRNAs in animal systems, plant lncRNAs have distinct\ncharacteristics. It is desirable to develop a computational method for accurate\nand robust identification of plant lncRNAs. Results: Herein, we present a plant\nlncRNA identification method ItLnc-BXE, which utilizes multiple features and\nthe ensemble learning strategy. First, a diversity of lncRNA features is\ncollected and filtered by feature selection to represent RNA transcripts. Then,\nseveral base learners are trained and further combined into a single\nmeta-learner by ensemble learning, and thus an ItLnc-BXE model is constructed.\nItLnc-BXE models are evaluated on datasets of six plant species, the results\nshow that ItLnc-BXE outperforms other state-of-the-art plant lncRNA\nidentification methods, achieving better and robust performances (AUC>95.91%).\nWe also perform some experiments about cross-species lncRNA identification, and\nthe results indicate that dicots-based and monocots-based models can be used to\naccurately identify lncRNAs in lower plant species, such as mosses and algae.\nAvailability: source codes are available at\nhttps://github.com/BioMedicalBigDataMiningLab/ItLnc-BXE. Contact:\nzhangwen@mail.hzau.edu.cn (or) zhangwen@whu.edu.cn Supplementary information:\nSupplementary data are available at Bioinformatics online.\n", "versions": [{"version": "v1", "created": "Fri, 1 Nov 2019 02:28:19 GMT"}, {"version": "v2", "created": "Fri, 24 Jan 2020 09:04:28 GMT"}], "update_date": "2020-01-27", "authors_parsed": [["Zhang", "Guangyan", ""], ["Liu", "Ziru", ""], ["Dai", "Jichen", ""], ["Yu", "Zilan", ""], ["Liu", "Shuai", ""], ["Zhang", "Wen", ""]]}, {"id": "1911.00188", "submitter": "Yuxuan Sun", "authors": "Yuxuan Sun, Sheng Zhou, Deniz G\\\"und\\\"uz", "title": "Energy-Aware Analog Aggregation for Federated Learning with Redundant\n  Data", "comments": "Submitted for publication", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IT cs.LG eess.SP math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Federated learning (FL) enables workers to learn a model collaboratively by\nusing their local data, with the help of a parameter server (PS) for global\nmodel aggregation. The high communication cost for periodic model updates and\nthe non-independent and identically distributed (i.i.d.) data become major\nbottlenecks for FL. In this work, we consider analog aggregation to scale down\nthe communication cost with respect to the number of workers, and introduce\ndata redundancy to the system to deal with non-i.i.d. data. We propose an\nonline energy-aware dynamic worker scheduling policy, which maximizes the\naverage number of workers scheduled for gradient update at each iteration under\na long-term energy constraint, and analyze its performance based on Lyapunov\noptimization. Experiments using MNIST dataset show that, for non-i.i.d. data,\ndoubling data storage can improve the accuracy by 9.8% under a stringent energy\nbudget, while the proposed policy can achieve close-to-optimal accuracy without\nviolating the energy constraint.\n", "versions": [{"version": "v1", "created": "Fri, 1 Nov 2019 02:57:05 GMT"}], "update_date": "2019-11-04", "authors_parsed": [["Sun", "Yuxuan", ""], ["Zhou", "Sheng", ""], ["G\u00fcnd\u00fcz", "Deniz", ""]]}, {"id": "1911.00190", "submitter": "Lucas Mentch", "authors": "Lucas Mentch and Siyu Zhou", "title": "Randomization as Regularization: A Degrees of Freedom Explanation for\n  Random Forest Success", "comments": "To Appear in the Journal of Machine Learning Research (JMLR)", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Random forests remain among the most popular off-the-shelf supervised machine\nlearning tools with a well-established track record of predictive accuracy in\nboth regression and classification settings. Despite their empirical success as\nwell as a bevy of recent work investigating their statistical properties, a\nfull and satisfying explanation for their success has yet to be put forth. Here\nwe aim to take a step forward in this direction by demonstrating that the\nadditional randomness injected into individual trees serves as a form of\nimplicit regularization, making random forests an ideal model in low\nsignal-to-noise ratio (SNR) settings. Specifically, from a model-complexity\nperspective, we show that the mtry parameter in random forests serves much the\nsame purpose as the shrinkage penalty in explicitly regularized regression\nprocedures like lasso and ridge regression. To highlight this point, we design\na randomized linear-model-based forward selection procedure intended as an\nanalogue to tree-based random forests and demonstrate its surprisingly strong\nempirical performance. Numerous demonstrations on both real and synthetic data\nare provided.\n", "versions": [{"version": "v1", "created": "Fri, 1 Nov 2019 03:13:12 GMT"}, {"version": "v2", "created": "Mon, 14 Sep 2020 07:27:22 GMT"}], "update_date": "2020-09-15", "authors_parsed": [["Mentch", "Lucas", ""], ["Zhou", "Siyu", ""]]}, {"id": "1911.00193", "submitter": "Mingliang Xu", "authors": "Chaochao Li, Pei Lv, Mingliang Xu, Xinyu Wang, Dinesh Manocha, Bing\n  Zhou, and Meng Wang", "title": "Personality-Aware Probabilistic Map for Trajectory Prediction of\n  Pedestrians", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.GR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a novel trajectory prediction algorithm for pedestrians based on a\npersonality-aware probabilistic feature map. This map is computed using a\nspatial query structure and each value represents the probability of the\npredicted pedestrian passing through various positions in the crowd space. We\nupdate this map dynamically based on the agents in the environment and prior\ntrajectory of a pedestrian. Furthermore, we estimate the personality\ncharacteristics of each pedestrian and use them to improve the prediction by\nestimating the shortest path in this map. Our approach is general and works\nwell on crowd videos with low and high pedestrian density. We evaluate our\nmodel on standard human-trajectory datasets. In practice, our prediction\nalgorithm improves the accuracy by 5-9% over prior algorithms.\n", "versions": [{"version": "v1", "created": "Fri, 1 Nov 2019 03:31:49 GMT"}], "update_date": "2019-11-04", "authors_parsed": [["Li", "Chaochao", ""], ["Lv", "Pei", ""], ["Xu", "Mingliang", ""], ["Wang", "Xinyu", ""], ["Manocha", "Dinesh", ""], ["Zhou", "Bing", ""], ["Wang", "Meng", ""]]}, {"id": "1911.00202", "submitter": "Ying Xu", "authors": "Y. Xu, X. Zhong, A. J. J. Yepes, J. H. Lau", "title": "Forget Me Not: Reducing Catastrophic Forgetting for Domain Adaptation in\n  Reading Comprehension", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The creation of large-scale open domain reading comprehension data sets in\nrecent years has enabled the development of end-to-end neural comprehension\nmodels with promising results. To use these models for domains with limited\ntraining data, one of the most effective approach is to first pretrain them on\nlarge out-of-domain source data and then fine-tune them with the limited target\ndata. The caveat of this is that after fine-tuning the comprehension models\ntend to perform poorly in the source domain, a phenomenon known as catastrophic\nforgetting. In this paper, we explore methods that overcome catastrophic\nforgetting during fine-tuning without assuming access to data from the source\ndomain. We introduce new auxiliary penalty terms and observe the best\nperformance when a combination of auxiliary penalty terms is used to regularise\nthe fine-tuning process for adapting comprehension models. To test our methods,\nwe develop and release 6 narrow domain data sets that could potentially be used\nas reading comprehension benchmarks.\n", "versions": [{"version": "v1", "created": "Fri, 1 Nov 2019 05:07:06 GMT"}, {"version": "v2", "created": "Thu, 30 Apr 2020 05:19:17 GMT"}, {"version": "v3", "created": "Fri, 20 Nov 2020 02:19:55 GMT"}], "update_date": "2020-11-23", "authors_parsed": [["Xu", "Y.", ""], ["Zhong", "X.", ""], ["Yepes", "A. J. J.", ""], ["Lau", "J. H.", ""]]}, {"id": "1911.00208", "submitter": "Kedar Tatwawadi", "authors": "Shubham Chandak, Kedar Tatwawadi, Chengtao Wen, Lingyun Wang, Juan\n  Aparicio, Tsachy Weissman", "title": "LFZip: Lossy compression of multivariate floating-point time series data\n  via improved prediction", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.SP cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Time series data compression is emerging as an important problem with the\ngrowth in IoT devices and sensors. Due to the presence of noise in these\ndatasets, lossy compression can often provide significant compression gains\nwithout impacting the performance of downstream applications. In this work, we\npropose an error-bounded lossy compressor, LFZip, for multivariate\nfloating-point time series data that provides guaranteed reconstruction up to\nuser-specified maximum absolute error. The compressor is based on the\nprediction-quantization-entropy coder framework and benefits from improved\nprediction using linear models and neural networks. We evaluate the compressor\non several time series datasets where it outperforms the existing\nstate-of-the-art error-bounded lossy compressors. The code and data are\navailable at https://github.com/shubhamchandak94/LFZip\n", "versions": [{"version": "v1", "created": "Fri, 1 Nov 2019 05:38:46 GMT"}, {"version": "v2", "created": "Mon, 13 Jan 2020 18:06:14 GMT"}], "update_date": "2020-01-14", "authors_parsed": [["Chandak", "Shubham", ""], ["Tatwawadi", "Kedar", ""], ["Wen", "Chengtao", ""], ["Wang", "Lingyun", ""], ["Aparicio", "Juan", ""], ["Weissman", "Tsachy", ""]]}, {"id": "1911.00212", "submitter": "Siyu Huang", "authors": "Tao Jin, Siyu Huang, Yingming Li, Zhongfei Zhang", "title": "Low-Rank HOCA: Efficient High-Order Cross-Modal Attention for Video\n  Captioning", "comments": "Accepted as a long paper at EMNLP 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CL cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper addresses the challenging task of video captioning which aims to\ngenerate descriptions for video data. Recently, the attention-based\nencoder-decoder structures have been widely used in video captioning. In\nexisting literature, the attention weights are often built from the information\nof an individual modality, while, the association relationships between\nmultiple modalities are neglected. Motivated by this observation, we propose a\nvideo captioning model with High-Order Cross-Modal Attention (HOCA) where the\nattention weights are calculated based on the high-order correlation tensor to\ncapture the frame-level cross-modal interaction of different modalities\nsufficiently. Furthermore, we novelly introduce Low-Rank HOCA which adopts\ntensor decomposition to reduce the extremely large space requirement of HOCA,\nleading to a practical and efficient implementation in real-world applications.\nExperimental results on two benchmark datasets, MSVD and MSR-VTT, show that\nLow-rank HOCA establishes a new state-of-the-art.\n", "versions": [{"version": "v1", "created": "Fri, 1 Nov 2019 05:53:50 GMT"}], "update_date": "2019-11-04", "authors_parsed": [["Jin", "Tao", ""], ["Huang", "Siyu", ""], ["Li", "Yingming", ""], ["Zhang", "Zhongfei", ""]]}, {"id": "1911.00216", "submitter": "Yahya H. Ezzeldin", "authors": "Osama A. Hanna, Yahya H. Ezzeldin, Tara Sadjadpour, Christina\n  Fragouli, Suhas Diggavi", "title": "On Distributed Quantization for Classification", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.IT math.IT stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the problem of distributed feature quantization, where the goal\nis to enable a pretrained classifier at a central node to carry out its\nclassification on features that are gathered from distributed nodes through\ncommunication constrained channels. We propose the design of distributed\nquantization schemes specifically tailored to the classification task: unlike\nquantization schemes that help the central node reconstruct the original signal\nas accurately as possible, our focus is not reconstruction accuracy, but\ninstead correct classification. Our work does not make any apriori\ndistributional assumptions on the data, but instead uses training data for the\nquantizer design. Our main contributions include: we prove NP-hardness of\nfinding optimal quantizers in the general case; we design an optimal scheme for\na special case; we propose quantization algorithms, that leverage discrete\nneural representations and training data, and can be designed in\npolynomial-time for any number of features, any number of classes, and\narbitrary division of features across the distributed nodes. We find that\ntailoring the quantizers to the classification task can offer significant\nsavings: as compared to alternatives, we can achieve more than a factor of two\nreduction in terms of the number of bits communicated, for the same\nclassification accuracy.\n", "versions": [{"version": "v1", "created": "Fri, 1 Nov 2019 06:10:49 GMT"}], "update_date": "2019-11-04", "authors_parsed": [["Hanna", "Osama A.", ""], ["Ezzeldin", "Yahya H.", ""], ["Sadjadpour", "Tara", ""], ["Fragouli", "Christina", ""], ["Diggavi", "Suhas", ""]]}, {"id": "1911.00218", "submitter": "Mikhail Yurochkin", "authors": "Mikhail Yurochkin, Mayank Agarwal, Soumya Ghosh, Kristjan Greenewald,\n  Trong Nghia Hoang", "title": "Statistical Model Aggregation via Parameter Matching", "comments": "NeurIPS 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the problem of aggregating models learned from sequestered,\npossibly heterogeneous datasets. Exploiting tools from Bayesian nonparametrics,\nwe develop a general meta-modeling framework that learns shared global latent\nstructures by identifying correspondences among local model parameterizations.\nOur proposed framework is model-independent and is applicable to a wide range\nof model types. After verifying our approach on simulated data, we demonstrate\nits utility in aggregating Gaussian topic models, hierarchical Dirichlet\nprocess based hidden Markov models, and sparse Gaussian processes with\napplications spanning text summarization, motion capture analysis, and\ntemperature forecasting.\n", "versions": [{"version": "v1", "created": "Fri, 1 Nov 2019 06:24:38 GMT"}], "update_date": "2019-11-04", "authors_parsed": [["Yurochkin", "Mikhail", ""], ["Agarwal", "Mayank", ""], ["Ghosh", "Soumya", ""], ["Greenewald", "Kristjan", ""], ["Hoang", "Trong Nghia", ""]]}, {"id": "1911.00219", "submitter": "Shikhar Vashishth", "authors": "Shikhar Vashishth, Soumya Sanyal, Vikram Nitin, Nilesh Agrawal, Partha\n  Talukdar", "title": "InteractE: Improving Convolution-based Knowledge Graph Embeddings by\n  Increasing Feature Interactions", "comments": "Accepted at AAAI 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Most existing knowledge graphs suffer from incompleteness, which can be\nalleviated by inferring missing links based on known facts. One popular way to\naccomplish this is to generate low-dimensional embeddings of entities and\nrelations, and use these to make inferences. ConvE, a recently proposed\napproach, applies convolutional filters on 2D reshapings of entity and relation\nembeddings in order to capture rich interactions between their components.\nHowever, the number of interactions that ConvE can capture is limited. In this\npaper, we analyze how increasing the number of these interactions affects link\nprediction performance, and utilize our observations to propose InteractE.\nInteractE is based on three key ideas -- feature permutation, a novel feature\nreshaping, and circular convolution. Through extensive experiments, we find\nthat InteractE outperforms state-of-the-art convolutional link prediction\nbaselines on FB15k-237. Further, InteractE achieves an MRR score that is 9%,\n7.5%, and 23% better than ConvE on the FB15k-237, WN18RR and YAGO3-10 datasets\nrespectively. The results validate our central hypothesis -- that increasing\nfeature interaction is beneficial to link prediction performance. We make the\nsource code of InteractE available to encourage reproducible research.\n", "versions": [{"version": "v1", "created": "Fri, 1 Nov 2019 06:26:09 GMT"}, {"version": "v2", "created": "Sat, 16 Nov 2019 06:56:20 GMT"}, {"version": "v3", "created": "Thu, 24 Sep 2020 17:06:41 GMT"}], "update_date": "2020-09-25", "authors_parsed": [["Vashishth", "Shikhar", ""], ["Sanyal", "Soumya", ""], ["Nitin", "Vikram", ""], ["Agrawal", "Nilesh", ""], ["Talukdar", "Partha", ""]]}, {"id": "1911.00222", "submitter": "Chuan Ma", "authors": "Kang Wei, Jun Li, Ming Ding, Chuan Ma, Howard H. Yang, Farokhi Farhad,\n  Shi Jin, Tony Q. S. Quek, H. Vincent Poor", "title": "Federated Learning with Differential Privacy: Algorithms and Performance\n  Analysis", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, to effectively prevent information leakage, we propose a novel\nframework based on the concept of differential privacy (DP), in which\nartificial noises are added to the parameters at the clients side before\naggregating, namely, noising before model aggregation FL (NbAFL). First, we\nprove that the NbAFL can satisfy DP under distinct protection levels by\nproperly adapting different variances of artificial noises. Then we develop a\ntheoretical convergence bound of the loss function of the trained FL model in\nthe NbAFL. Specifically, the theoretical bound reveals the following three key\nproperties: 1) There is a tradeoff between the convergence performance and\nprivacy protection levels, i.e., a better convergence performance leads to a\nlower protection level; 2) Given a fixed privacy protection level, increasing\nthe number $N$ of overall clients participating in FL can improve the\nconvergence performance; 3) There is an optimal number of maximum aggregation\ntimes (communication rounds) in terms of convergence performance for a given\nprotection level. Furthermore, we propose a $K$-random scheduling strategy,\nwhere $K$ ($1<K<N$) clients are randomly selected from the $N$ overall clients\nto participate in each aggregation. We also develop the corresponding\nconvergence bound of the loss function in this case and the $K$-random\nscheduling strategy can also retain the above three properties. Moreover, we\nfind that there is an optimal $K$ that achieves the best convergence\nperformance at a fixed privacy level. Evaluations demonstrate that our\ntheoretical results are consistent with simulations, thereby facilitating the\ndesigns on various privacy-preserving FL algorithms with different tradeoff\nrequirements on convergence performance and privacy levels.\n", "versions": [{"version": "v1", "created": "Fri, 1 Nov 2019 06:36:33 GMT"}, {"version": "v2", "created": "Fri, 8 Nov 2019 07:43:26 GMT"}], "update_date": "2019-11-11", "authors_parsed": [["Wei", "Kang", ""], ["Li", "Jun", ""], ["Ding", "Ming", ""], ["Ma", "Chuan", ""], ["Yang", "Howard H.", ""], ["Farhad", "Farokhi", ""], ["Jin", "Shi", ""], ["Quek", "Tony Q. S.", ""], ["Poor", "H. Vincent", ""]]}, {"id": "1911.00223", "submitter": "Huanbiao Zhu", "authors": "Huanbiao Zhu and Werner Stuetzle", "title": "A Simple and Efficient Method to Compute a Single Linkage Dendrogram", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.LG stat.CO stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We address the problem of computing a single linkage dendrogram. A possible\napproach is to: (i) Form an edge weighted graph $G$ over the data, with edge\nweights reflecting dissimilarities. (ii) Calculate the MST $T$ of $G$. (iii)\nBreak the longest edge of $T$ thereby splitting it into subtrees $T_L$, $T_R$.\n(iv) Apply the splitting process recursively to the subtrees. This approach has\nthe attractive feature that Prim's algorithm for MST construction calculates\ndistances as needed, and hence there is no need to ever store the inter-point\ndistance matrix. The recursive partitioning algorithm requires us to determine\nthe vertices (and edges) of $T_L$ and $T_R$. We show how this can be done\neasily and efficiently using information generated by Prim's algorithm without\nany additional computational cost.\n", "versions": [{"version": "v1", "created": "Fri, 1 Nov 2019 06:36:51 GMT"}], "update_date": "2019-11-04", "authors_parsed": [["Zhu", "Huanbiao", ""], ["Stuetzle", "Werner", ""]]}, {"id": "1911.00227", "submitter": "Yuma Kinoshita", "authors": "Ayana Kawamura, Yuma Kinoshita, and Hitoshi Kiya", "title": "Privacy-Preserving Machine Learning Using EtC Images", "comments": "to be presented at IWAIT2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.CV cs.LG cs.MM eess.IV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we propose a novel privacy-preserving machine learning scheme\nwith encrypted images, called EtC (Encryption-then-Compression) images. Using\nmachine learning algorithms in cloud environments has been spreading in many\nfields. However, there are serious issues with it for end users, due to\nsemi-trusted cloud providers. Accordingly, we propose using EtC images, which\nhave been proposed for EtC systems with JPEG compression. In this paper, a\nnovel property of EtC images is considered under the use of z-score\nnormalization. It is demonstrated that the use of EtC images allows us not only\nto protect visual information of images, but also to preserve both the\nEuclidean distance and the inner product between vectors. In addition,\ndimensionality reduction is shown to can be applied to EtC images for fast and\naccurate matching. In an experiment, the proposed scheme is applied to a facial\nrecognition algorithm with classifiers for confirming the effectiveness of the\nscheme under the use of support vector machine (SVM) with the kernel trick.\n", "versions": [{"version": "v1", "created": "Fri, 1 Nov 2019 06:54:27 GMT"}], "update_date": "2019-11-04", "authors_parsed": [["Kawamura", "Ayana", ""], ["Kinoshita", "Yuma", ""], ["Kiya", "Hitoshi", ""]]}, {"id": "1911.00231", "submitter": "Konstantinos Karanasos", "authors": "Konstantinos Karanasos, Matteo Interlandi, Doris Xin, Fotis Psallidas,\n  Rathijit Sen, Kwanghyun Park, Ivan Popivanov, Supun Nakandal, Subru Krishnan,\n  Markus Weimer, Yuan Yu, Raghu Ramakrishnan, Carlo Curino", "title": "Extending Relational Query Processing with ML Inference", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DB cs.LG", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  The broadening adoption of machine learning in the enterprise is increasing\nthe pressure for strict governance and cost-effective performance, in\nparticular for the common and consequential steps of model storage and\ninference. The RDBMS provides a natural starting point, given its mature\ninfrastructure for fast data access and processing, along with support for\nenterprise features (e.g., encryption, auditing, high-availability). To take\nadvantage of all of the above, we need to address a key concern: Can in-RDBMS\nscoring of ML models match (outperform?) the performance of dedicated\nframeworks? We answer the above positively by building Raven, a system that\nleverages native integration of ML runtimes (i.e., ONNX Runtime) deep within\nSQL Server, and a unified intermediate representation (IR) to enable advanced\ncross-optimizations between ML and DB operators. In this optimization space, we\ndiscover the most exciting research opportunities that combine DB/Compiler/ML\nthinking. Our initial evaluation on real data demonstrates performance gains of\nup to 5.5x from the native integration of ML in SQL Server, and up to 24x from\ncross-optimizations--we will demonstrate Raven live during the conference talk.\n", "versions": [{"version": "v1", "created": "Fri, 1 Nov 2019 07:09:08 GMT"}], "update_date": "2019-11-04", "authors_parsed": [["Karanasos", "Konstantinos", ""], ["Interlandi", "Matteo", ""], ["Xin", "Doris", ""], ["Psallidas", "Fotis", ""], ["Sen", "Rathijit", ""], ["Park", "Kwanghyun", ""], ["Popivanov", "Ivan", ""], ["Nakandal", "Supun", ""], ["Krishnan", "Subru", ""], ["Weimer", "Markus", ""], ["Yu", "Yuan", ""], ["Ramakrishnan", "Raghu", ""], ["Curino", "Carlo", ""]]}, {"id": "1911.00232", "submitter": "Mathew Monfort", "authors": "Mathew Monfort, Kandan Ramakrishnan, Alex Andonian, Barry A McNamara,\n  Alex Lascelles, Bowen Pan, Quanfu Fan, Dan Gutfreund, Rogerio Feris, Aude\n  Oliva", "title": "Multi-Moments in Time: Learning and Interpreting Models for Multi-Action\n  Video Understanding", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG eess.IV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  An event happening in the world is often made of different activities and\nactions that can unfold simultaneously or sequentially within a few seconds.\nHowever, most large-scale datasets built to train models for action recognition\nprovide a single label per video clip. Consequently, models can be incorrectly\npenalized for classifying actions that exist in the videos but are not\nexplicitly labeled and do not learn the full spectrum of information that would\nbe mandatory to more completely comprehend different events and eventually\nlearn causality between them. Towards this goal, we augmented the existing\nvideo dataset, Moments in Time (MiT), to include over two million action labels\nfor over one million three second videos. This multi-label dataset introduces\nnovel challenges on how to train and analyze models for multi-action detection.\nHere, we present baseline results for multi-action recognition using loss\nfunctions adapted for long tail multi-label learning and provide improved\nmethods for visualizing and interpreting models trained for multi-label action\ndetection.\n", "versions": [{"version": "v1", "created": "Fri, 1 Nov 2019 07:09:36 GMT"}, {"version": "v2", "created": "Mon, 4 Nov 2019 20:24:15 GMT"}, {"version": "v3", "created": "Fri, 10 Jan 2020 00:24:30 GMT"}], "update_date": "2020-01-13", "authors_parsed": [["Monfort", "Mathew", ""], ["Ramakrishnan", "Kandan", ""], ["Andonian", "Alex", ""], ["McNamara", "Barry A", ""], ["Lascelles", "Alex", ""], ["Pan", "Bowen", ""], ["Fan", "Quanfu", ""], ["Gutfreund", "Dan", ""], ["Feris", "Rogerio", ""], ["Oliva", "Aude", ""]]}, {"id": "1911.00234", "submitter": "Rishi Hazra", "authors": "Rishi Hazra and Parag Dutta and Shubham Gupta and Mohammed Abdul\n  Qaathir and Ambedkar Dukkipati", "title": "Active$^2$ Learning: Actively reducing redundancies in Active Learning\n  methods for Sequence Tagging and Machine Translation", "comments": "Accepted in NAACL-HLT 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.IR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  While deep learning is a powerful tool for natural language processing (NLP)\nproblems, successful solutions to these problems rely heavily on large amounts\nof annotated samples. However, manually annotating data is expensive and\ntime-consuming. Active Learning (AL) strategies reduce the need for huge\nvolumes of labeled data by iteratively selecting a small number of examples for\nmanual annotation based on their estimated utility in training the given model.\nIn this paper, we argue that since AL strategies choose examples independently,\nthey may potentially select similar examples, all of which may not contribute\nsignificantly to the learning process. Our proposed approach,\nActive$\\mathbf{^2}$ Learning (A$\\mathbf{^2}$L), actively adapts to the deep\nlearning model being trained to eliminate such redundant examples chosen by an\nAL strategy. We show that A$\\mathbf{^2}$L is widely applicable by using it in\nconjunction with several different AL strategies and NLP tasks. We empirically\ndemonstrate that the proposed approach is further able to reduce the data\nrequirements of state-of-the-art AL strategies by $\\approx \\mathbf{3-25\\%}$ on\nan absolute scale on multiple NLP tasks while achieving the same performance\nwith virtually no additional computation overhead.\n", "versions": [{"version": "v1", "created": "Fri, 1 Nov 2019 07:31:02 GMT"}, {"version": "v2", "created": "Mon, 13 Apr 2020 16:50:09 GMT"}, {"version": "v3", "created": "Wed, 16 Sep 2020 06:56:32 GMT"}, {"version": "v4", "created": "Tue, 6 Apr 2021 09:22:16 GMT"}], "update_date": "2021-04-08", "authors_parsed": [["Hazra", "Rishi", ""], ["Dutta", "Parag", ""], ["Gupta", "Shubham", ""], ["Qaathir", "Mohammed Abdul", ""], ["Dukkipati", "Ambedkar", ""]]}, {"id": "1911.00238", "submitter": "Takato Horii", "authors": "Kyoichiro Kobayashi, Takato Horii, Ryo Iwaki, Yukie Nagai and Minoru\n  Asada", "title": "Situated GAIL: Multitask imitation using task-conditioned adversarial\n  inverse reinforcement learning", "comments": "Submitted to Advanced Robotics", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.RO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Generative adversarial imitation learning (GAIL) has attracted increasing\nattention in the field of robot learning. It enables robots to learn a policy\nto achieve a task demonstrated by an expert while simultaneously estimating the\nreward function behind the expert's behaviors. However, this framework is\nlimited to learning a single task with a single reward function. This study\nproposes an extended framework called situated GAIL (S-GAIL), in which a task\nvariable is introduced to both the discriminator and generator of the GAIL\nframework. The task variable has the roles of discriminating different contexts\nand making the framework learn different reward functions and policies for\nmultiple tasks. To achieve the early convergence of learning and robustness\nduring reward estimation, we introduce a term to adjust the entropy\nregularization coefficient in the generator's objective function. Our\nexperiments using two setups (navigation in a discrete grid world and arm\nreaching in a continuous space) demonstrate that the proposed framework can\nacquire multiple reward functions and policies more effectively than existing\nframeworks. The task variable enables our framework to differentiate contexts\nwhile sharing common knowledge among multiple tasks.\n", "versions": [{"version": "v1", "created": "Fri, 1 Nov 2019 07:50:30 GMT"}], "update_date": "2019-11-04", "authors_parsed": [["Kobayashi", "Kyoichiro", ""], ["Horii", "Takato", ""], ["Iwaki", "Ryo", ""], ["Nagai", "Yukie", ""], ["Asada", "Minoru", ""]]}, {"id": "1911.00251", "submitter": "Fan Ang", "authors": "Fan Ang, Li Chen, Nan Zhao, Yunfei Chen, Weidong Wang, F. Richard Yu", "title": "Robust Federated Learning with Noisy Communication", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Federated learning is a communication-efficient training process that\nalternates between local training at the edge devices and averaging the updated\nlocal model at the central server. Nevertheless, it is impractical to achieve a\nperfect acquisition of the local models in wireless communication due to noise,\nwhich also brings serious effects on federated learning. To tackle this\nchallenge, we propose a robust design for federated learning to alleviate the\neffects of noise in this paper. Considering noise in the two aforementioned\nsteps, we first formulate the training problem as a parallel optimization for\neach node under the expectation-based model and the worst-case model. Due to\nthe non-convexity of the problem, a regularization for the loss function\napproximation method is proposed to make it tractable. Regarding the worst-case\nmodel, we develop a feasible training scheme which utilizes the sampling-based\nsuccessive convex approximation algorithm to tackle the unavailable maxima or\nminima noise condition and the non-convex issue of the objective function.\nFurthermore, the convergence rates of both new designs are analyzed from a\ntheoretical point of view. Finally, the improvement of prediction accuracy and\nthe reduction of loss function are demonstrated via simulations for the\nproposed designs.\n", "versions": [{"version": "v1", "created": "Fri, 1 Nov 2019 08:25:34 GMT"}], "update_date": "2019-11-04", "authors_parsed": [["Ang", "Fan", ""], ["Chen", "Li", ""], ["Zhao", "Nan", ""], ["Chen", "Yunfei", ""], ["Wang", "Weidong", ""], ["Yu", "F. Richard", ""]]}, {"id": "1911.00262", "submitter": "Marko Mihajlovic", "authors": "Marko Mihajlovic, Ning Xiong", "title": "Finding the most similar textual documents using Case-Based Reasoning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CL cs.IR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In recent years, huge amounts of unstructured textual data on the Internet\nare a big difficulty for AI algorithms to provide the best recommendations for\nusers and their search queries. Since the Internet became widespread, a lot of\nresearch has been done in the field of Natural Language Processing (NLP) and\nmachine learning. Almost every solution transforms documents into Vector Space\nModels (VSM) in order to apply AI algorithms over them. One such approach is\nbased on Case-Based Reasoning (CBR). Therefore, the most important part of\nthose systems is to compute the similarity between numerical data points. In\n2016, the new similarity TS-SS metric is proposed, which showed\nstate-of-the-art results in the field of textual mining for unsupervised\nlearning. However, no one before has investigated its performances for\nsupervised learning (classification task). In this work, we devised a CBR\nsystem capable of finding the most similar documents for a given query aiming\nto investigate performances of the new state-of-the-art metric, TS-SS, in\naddition to the two other geometrical similarity measures --- Euclidean\ndistance and Cosine similarity --- that showed the best predictive results over\nseveral benchmark corpora. The results show surprising inappropriateness of\nTS-SS measure for high dimensional features.\n", "versions": [{"version": "v1", "created": "Fri, 1 Nov 2019 08:46:35 GMT"}], "update_date": "2019-11-04", "authors_parsed": [["Mihajlovic", "Marko", ""], ["Xiong", "Ning", ""]]}, {"id": "1911.00265", "submitter": "Hiroaki Sasaki", "authors": "Hiroaki Sasaki, Takashi Takenouchi, Ricardo Monti, Aapo Hyv\\\"arinen", "title": "Robust contrastive learning and nonlinear ICA in the presence of\n  outliers", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Nonlinear independent component analysis (ICA) is a general framework for\nunsupervised representation learning, and aimed at recovering the latent\nvariables in data. Recent practical methods perform nonlinear ICA by solving a\nseries of classification problems based on logistic regression. However, it is\nwell-known that logistic regression is vulnerable to outliers, and thus the\nperformance can be strongly weakened by outliers. In this paper, we first\ntheoretically analyze nonlinear ICA models in the presence of outliers. Our\nanalysis implies that estimation in nonlinear ICA can be seriously hampered\nwhen outliers exist on the tails of the (noncontaminated) target density, which\nhappens in a typical case of contamination by outliers. We develop two robust\nnonlinear ICA methods based on the {\\gamma}-divergence, which is a robust\nalternative to the KL-divergence in logistic regression. The proposed methods\nare shown to have desired robustness properties in the context of nonlinear\nICA. We also experimentally demonstrate that the proposed methods are very\nrobust and outperform existing methods in the presence of outliers. Finally,\nthe proposed method is applied to ICA-based causal discovery and shown to find\na plausible causal relationship on fMRI data.\n", "versions": [{"version": "v1", "created": "Fri, 1 Nov 2019 08:50:01 GMT"}], "update_date": "2019-11-04", "authors_parsed": [["Sasaki", "Hiroaki", ""], ["Takenouchi", "Takashi", ""], ["Monti", "Ricardo", ""], ["Hyv\u00e4rinen", "Aapo", ""]]}, {"id": "1911.00274", "submitter": "Ning Miao", "authors": "Ning Miao, Hao Zhou, Chengqi Zhao, Wenxian Shi, Lei Li", "title": "Kernelized Bayesian Softmax for Text Generation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Neural models for text generation require a softmax layer with proper token\nembeddings during the decoding phase. Most existing approaches adopt single\npoint embedding for each token. However, a word may have multiple senses\naccording to different context, some of which might be distinct. In this paper,\nwe propose KerBS, a novel approach for learning better embeddings for text\ngeneration. KerBS embodies two advantages: (a) it employs a Bayesian\ncomposition of embeddings for words with multiple senses; (b) it is adaptive to\nsemantic variances of words and robust to rare sentence context by imposing\nlearned kernels to capture the closeness of words (senses) in the embedding\nspace. Empirical studies show that KerBS significantly boosts the performance\nof several text generation tasks.\n", "versions": [{"version": "v1", "created": "Fri, 1 Nov 2019 09:20:14 GMT"}], "update_date": "2019-11-04", "authors_parsed": [["Miao", "Ning", ""], ["Zhou", "Hao", ""], ["Zhao", "Chengqi", ""], ["Shi", "Wenxian", ""], ["Li", "Lei", ""]]}, {"id": "1911.00288", "submitter": "Avinash Madasu", "authors": "Avinash Madasu, Sivasankar E", "title": "Efficient Feature Selection techniques for Sentiment Analysis", "comments": "Accepted for publication at the springer journal Multimedia Tools And\n  Applications", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Sentiment analysis is a domain of study that focuses on identifying and\nclassifying the ideas expressed in the form of text into positive, negative and\nneutral polarities. Feature selection is a crucial process in machine learning.\nIn this paper, we aim to study the performance of different feature selection\ntechniques for sentiment analysis. Term Frequency Inverse Document Frequency\n(TF-IDF) is used as the feature extraction technique for creating feature\nvocabulary. Various Feature Selection (FS) techniques are experimented to\nselect the best set of features from feature vocabulary. The selected features\nare trained using different machine learning classifiers Logistic Regression\n(LR), Support Vector Machines (SVM), Decision Tree (DT) and Naive Bayes (NB).\nEnsemble techniques Bagging and Random Subspace are applied on classifiers to\nenhance the performance on sentiment analysis. We show that, when the best FS\ntechniques are trained using ensemble methods achieve remarkable results on\nsentiment analysis. We also compare the performance of FS methods trained using\nBagging, Random Subspace with varied neural network architectures. We show that\nFS techniques trained using ensemble classifiers outperform neural networks\nrequiring significantly less training time and parameters thereby eliminating\nthe need for extensive hyper-parameter tuning.\n", "versions": [{"version": "v1", "created": "Fri, 1 Nov 2019 10:20:05 GMT"}, {"version": "v2", "created": "Sun, 2 Feb 2020 13:55:21 GMT"}], "update_date": "2020-02-04", "authors_parsed": [["Madasu", "Avinash", ""], ["E", "Sivasankar", ""]]}, {"id": "1911.00289", "submitter": "Heechang Ryu", "authors": "Kiwook Bae, Heechang Ryu, Hayong Shin", "title": "Does Adam optimizer keep close to the optimal point?", "comments": "Accepted as a workshop paper at the 33rd Conference on Neural\n  Information Processing Systems (NeurIPS 2019), Vancouver, Canada", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  The adaptive optimizer for training neural networks has continually evolved\nto overcome the limitations of the previously proposed adaptive methods. Recent\nstudies have found the rare counterexamples that Adam cannot converge to the\noptimal point. Those counterexamples reveal the distortion of Adam due to a\nsmall second momentum from a small gradient. Unlike previous studies, we show\nAdam cannot keep closer to the optimal point for not only the counterexamples\nbut also a general convex region when the effective learning rate exceeds the\ncertain bound. Subsequently, we propose an algorithm that overcomes Adam's\nlimitation and ensures that it can reach and stay at the optimal point region.\n", "versions": [{"version": "v1", "created": "Fri, 1 Nov 2019 10:21:00 GMT"}], "update_date": "2019-11-04", "authors_parsed": [["Bae", "Kiwook", ""], ["Ryu", "Heechang", ""], ["Shin", "Hayong", ""]]}, {"id": "1911.00292", "submitter": "William Trouleau", "authors": "Farnood Salehi, William Trouleau, Matthias Grossglauser, Patrick\n  Thiran", "title": "Learning Hawkes Processes from a Handful of Events", "comments": "Appearing at NeurIPS 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Learning the causal-interaction network of multivariate Hawkes processes is a\nuseful task in many applications. Maximum-likelihood estimation is the most\ncommon approach to solve the problem in the presence of long observation\nsequences. However, when only short sequences are available, the lack of data\namplifies the risk of overfitting and regularization becomes critical. Due to\nthe challenges of hyper-parameter tuning, state-of-the-art methods only\nparameterize regularizers by a single shared hyper-parameter, hence limiting\nthe power of representation of the model. To solve both issues, we develop in\nthis work an efficient algorithm based on variational expectation-maximization.\nOur approach is able to optimize over an extended set of hyper-parameters. It\nis also able to take into account the uncertainty in the model parameters by\nlearning a posterior distribution over them. Experimental results on both\nsynthetic and real datasets show that our approach significantly outperforms\nstate-of-the-art methods under short observation sequences.\n", "versions": [{"version": "v1", "created": "Fri, 1 Nov 2019 10:40:27 GMT"}], "update_date": "2019-11-04", "authors_parsed": [["Salehi", "Farnood", ""], ["Trouleau", "William", ""], ["Grossglauser", "Matthias", ""], ["Thiran", "Patrick", ""]]}, {"id": "1911.00294", "submitter": "Adam Foster", "authors": "Adam Foster, Martin Jankowiak, Matthew O'Meara, Yee Whye Teh, Tom\n  Rainforth", "title": "A Unified Stochastic Gradient Approach to Designing Bayesian-Optimal\n  Experiments", "comments": "Published as a conference paper at AISTATS 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG stat.CO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce a fully stochastic gradient based approach to Bayesian optimal\nexperimental design (BOED). Our approach utilizes variational lower bounds on\nthe expected information gain (EIG) of an experiment that can be simultaneously\noptimized with respect to both the variational and design parameters. This\nallows the design process to be carried out through a single unified stochastic\ngradient ascent procedure, in contrast to existing approaches that typically\nconstruct a pointwise EIG estimator, before passing this estimator to a\nseparate optimizer. We provide a number of different variational objectives\nincluding the novel adaptive contrastive estimation (ACE) bound. Finally, we\nshow that our gradient-based approaches are able to provide effective design\noptimization in substantially higher dimensional settings than existing\napproaches.\n", "versions": [{"version": "v1", "created": "Fri, 1 Nov 2019 10:45:12 GMT"}, {"version": "v2", "created": "Thu, 27 Feb 2020 15:16:45 GMT"}], "update_date": "2020-02-28", "authors_parsed": [["Foster", "Adam", ""], ["Jankowiak", "Martin", ""], ["O'Meara", "Matthew", ""], ["Teh", "Yee Whye", ""], ["Rainforth", "Tom", ""]]}, {"id": "1911.00298", "submitter": "Stefano Almi", "authors": "Stefano Almi, Massimo Fornasier, Richard Huber", "title": "Data-driven Evolutions of Critical Points", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG math.AP math.DS stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we are concerned with the learnability of energies from data\nobtained by observing time evolutions of their critical points starting at\nrandom initial equilibria. As a byproduct of our theoretical framework we\nintroduce the novel concept of mean-field limit of critical point evolutions\nand of their energy balance as a new form of transport. We formulate the energy\nlearning as a variational problem, minimizing the discrepancy of energy\ncompetitors from fulfilling the equilibrium condition along any trajectory of\ncritical points originated at random initial equilibria. By Gamma-convergence\narguments we prove the convergence of minimal solutions obtained from finite\nnumber of observations to the exact energy in a suitable sense. The abstract\nframework is actually fully constructive and numerically implementable. Hence,\nthe approximation of the energy from a finite number of observations of past\nevolutions allows to simulate further evolutions, which are fully data-driven.\nAs we aim at a precise quantitative analysis, and to provide concrete examples\nof tractable solutions, we present analytic and numerical results on the\nreconstruction of an elastic energy for a one-dimensional model of thin\nnonlinear-elastic rod.\n", "versions": [{"version": "v1", "created": "Fri, 1 Nov 2019 11:00:56 GMT"}], "update_date": "2019-11-04", "authors_parsed": [["Almi", "Stefano", ""], ["Fornasier", "Massimo", ""], ["Huber", "Richard", ""]]}, {"id": "1911.00313", "submitter": "Yannis Papanikolaou", "authors": "Yannis Papanikolaou, Ian Roberts, Andrea Pierleoni", "title": "Deep Bidirectional Transformers for Relation Extraction without\n  Supervision", "comments": null, "journal-ref": "EMNLP DeepLo workshop 2019", "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a novel framework to deal with relation extraction tasks in cases\nwhere there is complete lack of supervision, either in the form of gold\nannotations, or relations from a knowledge base. Our approach leverages\nsyntactic parsing and pre-trained word embeddings to extract few but precise\nrelations,which are then used to annotate a larger cor-pus, in a manner\nidentical to distant supervision. The resulting data set is employed to fine\ntune a pre-trained BERT model in order to perform relation extraction.\nEmpirical evaluation on four data sets from the biomedical domain shows that\nour method significantly outperforms two simple baselines for unsupervised\nrelation extraction and, even if not using any supervision at all, achieves\nslightly worse results than the state-of-the-art in three out of four data\nsets. Importantly, we show that it is possible to successfully fine tune a\nlarge pre-trained language model with noisy data, as op-posed to previous works\nthat rely on gold data for fine tuning.\n", "versions": [{"version": "v1", "created": "Fri, 1 Nov 2019 11:47:28 GMT"}], "update_date": "2019-11-04", "authors_parsed": [["Papanikolaou", "Yannis", ""], ["Roberts", "Ian", ""], ["Pierleoni", "Andrea", ""]]}, {"id": "1911.00314", "submitter": "Josep Ramon Morros", "authors": "Ignasi Mas, Josep Ramon Morros, Veronica Vilaplana", "title": "Picking groups instead of samples: A close look at Static Pool-based\n  Meta-Active Learning", "comments": null, "journal-ref": "ICCV Workshop - MDALC 2019. Seoul, South Korea; 2019", "doi": null, "report-no": null, "categories": "cs.LG cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Active Learning techniques are used to tackle learning problems where\nobtaining training labels is costly. In this work we use Meta-Active Learning\nto learn to select a subset of samples from a pool of unsupervised input for\nfurther annotation. This scenario is called Static Pool-based Meta- Active\nLearning. We propose to extend existing approaches by performing the selection\nin a manner that, unlike previous works, can handle the selection of each\nsample based on the whole selected subset.\n", "versions": [{"version": "v1", "created": "Fri, 1 Nov 2019 12:08:47 GMT"}], "update_date": "2019-11-04", "authors_parsed": [["Mas", "Ignasi", ""], ["Morros", "Josep Ramon", ""], ["Vilaplana", "Veronica", ""]]}, {"id": "1911.00332", "submitter": "Daniel Goldfarb", "authors": "Daniel Goldfarb, Scott Evans", "title": "Causal Inference via Conditional Kolmogorov Complexity using MDL Binning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.IT math.IT stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent developments have linked causal inference with Algorithmic Information\nTheory, and methods have been developed that utilize Conditional Kolmogorov\nComplexity to determine causation between two random variables. We present a\nmethod for inferring causal direction between continuous variables by using an\nMDL Binning technique for data discretization and complexity calculation. Our\nmethod captures the shape of the data and uses it to determine which variable\nhas more information about the other. Its high predictive performance and\nrobustness is shown on several real world use cases.\n", "versions": [{"version": "v1", "created": "Thu, 31 Oct 2019 01:53:36 GMT"}, {"version": "v2", "created": "Wed, 6 Nov 2019 20:43:46 GMT"}], "update_date": "2019-11-11", "authors_parsed": [["Goldfarb", "Daniel", ""], ["Evans", "Scott", ""]]}, {"id": "1911.00334", "submitter": "Zhesong Yu", "authors": "Zhesong Yu, Xiaoshuo Xu, Xiaoou Chen, Deshun Yang", "title": "Learning a Representation for Cover Song Identification Using\n  Convolutional Neural Network", "comments": "MIREX2020-Cover Song Identification", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.MM cs.LG cs.SD eess.AS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Cover song identification represents a challenging task in the field of Music\nInformation Retrieval (MIR) due to complex musical variations between query\ntracks and cover versions. Previous works typically utilize hand-crafted\nfeatures and alignment algorithms for the task. More recently, further\nbreakthroughs are achieved employing neural network approaches. In this paper,\nwe propose a novel Convolutional Neural Network (CNN) architecture based on the\ncharacteristics of the cover song task. We first train the network through\nclassification strategies; the network is then used to extract music\nrepresentation for cover song identification. A scheme is designed to train\nrobust models against tempo changes. Experimental results show that our\napproach outperforms state-of-the-art methods on all public datasets, improving\nthe performance especially on the large dataset.\n", "versions": [{"version": "v1", "created": "Fri, 1 Nov 2019 12:32:40 GMT"}], "update_date": "2019-11-04", "authors_parsed": [["Yu", "Zhesong", ""], ["Xu", "Xiaoshuo", ""], ["Chen", "Xiaoou", ""], ["Yang", "Deshun", ""]]}, {"id": "1911.00348", "submitter": "Heinke Hihn", "authors": "Heinke Hihn and Daniel A. Braun", "title": "Hierarchical Expert Networks for Meta-Learning", "comments": "Presented at the 4th ICML Workshop on Life Long Machine Learning,\n  2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The goal of meta-learning is to train a model on a variety of learning tasks,\nsuch that it can adapt to new problems within only a few iterations. Here we\npropose a principled information-theoretic model that optimally partitions the\nunderlying problem space such that specialized expert decision-makers solve the\nresulting sub-problems. To drive this specialization we impose the same kind of\ninformation processing constraints both on the partitioning and the expert\ndecision-makers. We argue that this specialization leads to efficient\nadaptation to new tasks. To demonstrate the generality of our approach we\nevaluate three meta-learning domains: image classification, regression, and\nreinforcement learning.\n", "versions": [{"version": "v1", "created": "Thu, 31 Oct 2019 06:23:52 GMT"}, {"version": "v2", "created": "Thu, 7 Nov 2019 09:23:59 GMT"}, {"version": "v3", "created": "Wed, 13 Nov 2019 12:27:14 GMT"}, {"version": "v4", "created": "Thu, 14 Nov 2019 17:03:56 GMT"}, {"version": "v5", "created": "Wed, 4 Dec 2019 15:18:43 GMT"}, {"version": "v6", "created": "Tue, 4 Feb 2020 12:10:39 GMT"}, {"version": "v7", "created": "Wed, 9 Sep 2020 16:38:27 GMT"}], "update_date": "2020-09-10", "authors_parsed": [["Hihn", "Heinke", ""], ["Braun", "Daniel A.", ""]]}, {"id": "1911.00357", "submitter": "Erik Wijmans", "authors": "Erik Wijmans, Abhishek Kadian, Ari Morcos, Stefan Lee, Irfan Essa,\n  Devi Parikh, Manolis Savva, Dhruv Batra", "title": "DD-PPO: Learning Near-Perfect PointGoal Navigators from 2.5 Billion\n  Frames", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present Decentralized Distributed Proximal Policy Optimization (DD-PPO), a\nmethod for distributed reinforcement learning in resource-intensive simulated\nenvironments. DD-PPO is distributed (uses multiple machines), decentralized\n(lacks a centralized server), and synchronous (no computation is ever stale),\nmaking it conceptually simple and easy to implement. In our experiments on\ntraining virtual robots to navigate in Habitat-Sim, DD-PPO exhibits near-linear\nscaling -- achieving a speedup of 107x on 128 GPUs over a serial\nimplementation. We leverage this scaling to train an agent for 2.5 Billion\nsteps of experience (the equivalent of 80 years of human experience) -- over 6\nmonths of GPU-time training in under 3 days of wall-clock time with 64 GPUs.\n  This massive-scale training not only sets the state of art on Habitat\nAutonomous Navigation Challenge 2019, but essentially solves the task\n--near-perfect autonomous navigation in an unseen environment without access to\na map, directly from an RGB-D camera and a GPS+Compass sensor. Fortuitously,\nerror vs computation exhibits a power-law-like distribution; thus, 90% of peak\nperformance is obtained relatively early (at 100 million steps) and relatively\ncheaply (under 1 day with 8 GPUs). Finally, we show that the scene\nunderstanding and navigation policies learned can be transferred to other\nnavigation tasks -- the analog of ImageNet pre-training + task-specific\nfine-tuning for embodied AI. Our model outperforms ImageNet pre-trained CNNs on\nthese transfer tasks and can serve as a universal resource (all models and code\nare publicly available).\n", "versions": [{"version": "v1", "created": "Fri, 1 Nov 2019 13:07:37 GMT"}, {"version": "v2", "created": "Mon, 20 Jan 2020 04:18:58 GMT"}], "update_date": "2020-01-22", "authors_parsed": [["Wijmans", "Erik", ""], ["Kadian", "Abhishek", ""], ["Morcos", "Ari", ""], ["Lee", "Stefan", ""], ["Essa", "Irfan", ""], ["Parikh", "Devi", ""], ["Savva", "Manolis", ""], ["Batra", "Dhruv", ""]]}, {"id": "1911.00359", "submitter": "Marie-Anne Lachaux", "authors": "Guillaume Wenzek, Marie-Anne Lachaux, Alexis Conneau, Vishrav\n  Chaudhary, Francisco Guzm\\'an, Armand Joulin, Edouard Grave", "title": "CCNet: Extracting High Quality Monolingual Datasets from Web Crawl Data", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.IR cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Pre-training text representations have led to significant improvements in\nmany areas of natural language processing. The quality of these models benefits\ngreatly from the size of the pretraining corpora as long as its quality is\npreserved. In this paper, we describe an automatic pipeline to extract massive\nhigh-quality monolingual datasets from Common Crawl for a variety of languages.\nOur pipeline follows the data processing introduced in fastText (Mikolov et\nal., 2017; Grave et al., 2018), that deduplicates documents and identifies\ntheir language. We augment this pipeline with a filtering step to select\ndocuments that are close to high quality corpora like Wikipedia.\n", "versions": [{"version": "v1", "created": "Fri, 1 Nov 2019 13:09:28 GMT"}, {"version": "v2", "created": "Fri, 15 Nov 2019 00:03:54 GMT"}], "update_date": "2019-11-18", "authors_parsed": [["Wenzek", "Guillaume", ""], ["Lachaux", "Marie-Anne", ""], ["Conneau", "Alexis", ""], ["Chaudhary", "Vishrav", ""], ["Guzm\u00e1n", "Francisco", ""], ["Joulin", "Armand", ""], ["Grave", "Edouard", ""]]}, {"id": "1911.00361", "submitter": "Xishan Zhang", "authors": "Xishan Zhang, Shaoli Liu, Rui Zhang, Chang Liu, Di Huang, Shiyi Zhou,\n  Jiaming Guo, Yu Kang, Qi Guo, Zidong Du, Yunji Chen", "title": "Adaptive Precision Training: Quantify Back Propagation in Neural\n  Networks with Fixed-point Numbers", "comments": "We would like to withdraw the manuscript because it lacks of\n  comparisons. The main contribution is not well verified by experiments", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Adaptive Precision Training: Quantify Back Propagation in Neural Networks\nwith Fixed-point Numbers. Recent emerged quantization technique has been\napplied to inference of deep neural networks for fast and efficient execution.\nHowever, directly applying quantization in training can cause significant\naccuracy loss, thus remaining an open challenge.\n", "versions": [{"version": "v1", "created": "Fri, 1 Nov 2019 13:12:27 GMT"}, {"version": "v2", "created": "Thu, 5 Mar 2020 00:20:10 GMT"}], "update_date": "2020-03-06", "authors_parsed": [["Zhang", "Xishan", ""], ["Liu", "Shaoli", ""], ["Zhang", "Rui", ""], ["Liu", "Chang", ""], ["Huang", "Di", ""], ["Zhou", "Shiyi", ""], ["Guo", "Jiaming", ""], ["Kang", "Yu", ""], ["Guo", "Qi", ""], ["Du", "Zidong", ""], ["Chen", "Yunji", ""]]}, {"id": "1911.00385", "submitter": "Joseph Tassarotti", "authors": "Joseph Tassarotti, Koundinya Vajjha, Anindya Banerjee, Jean-Baptiste\n  Tristan", "title": "A Formal Proof of PAC Learnability for Decision Stumps", "comments": "13 pages, appeared in Certified Programs and Proofs (CPP) 2021", "journal-ref": null, "doi": "10.1145/3437992.3439917", "report-no": null, "categories": "cs.LG cs.LO stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a formal proof in Lean of probably approximately correct (PAC)\nlearnability of the concept class of decision stumps. This classic result in\nmachine learning theory derives a bound on error probabilities for a simple\ntype of classifier. Though such a proof appears simple on paper, analytic and\nmeasure-theoretic subtleties arise when carrying it out fully formally. Our\nproof is structured so as to separate reasoning about deterministic properties\nof a learning function from proofs of measurability and analysis of\nprobabilities.\n", "versions": [{"version": "v1", "created": "Fri, 1 Nov 2019 14:02:39 GMT"}, {"version": "v2", "created": "Fri, 29 Nov 2019 14:37:47 GMT"}, {"version": "v3", "created": "Thu, 7 Jan 2021 22:38:00 GMT"}], "update_date": "2021-01-11", "authors_parsed": [["Tassarotti", "Joseph", ""], ["Vajjha", "Koundinya", ""], ["Banerjee", "Anindya", ""], ["Tristan", "Jean-Baptiste", ""]]}, {"id": "1911.00397", "submitter": "Indu John", "authors": "Indu John, Chandramouli Kamanchi, Shalabh Bhatnagar", "title": "Generalized Speedy Q-learning", "comments": null, "journal-ref": "in IEEE Control Systems Letters, vol. 4, no. 3, pp. 524-529, July\n  2020", "doi": "10.1109/LCSYS.2020.2970555", "report-no": null, "categories": "cs.LG cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we derive a generalization of the Speedy Q-learning (SQL)\nalgorithm that was proposed in the Reinforcement Learning (RL) literature to\nhandle slow convergence of Watkins' Q-learning. In most RL algorithms such as\nQ-learning, the Bellman equation and the Bellman operator play an important\nrole. It is possible to generalize the Bellman operator using the technique of\nsuccessive relaxation. We use the generalized Bellman operator to derive a\nsimple and efficient family of algorithms called Generalized Speedy Q-learning\n(GSQL-w) and analyze its finite time performance. We show that GSQL-w has an\nimproved finite time performance bound compared to SQL for the case when the\nrelaxation parameter w is greater than 1. This improvement is a consequence of\nthe contraction factor of the generalized Bellman operator being less than that\nof the standard Bellman operator. Numerical experiments are provided to\ndemonstrate the empirical performance of the GSQL-w algorithm.\n", "versions": [{"version": "v1", "created": "Fri, 1 Nov 2019 14:18:59 GMT"}, {"version": "v2", "created": "Thu, 13 Feb 2020 04:20:51 GMT"}], "update_date": "2020-02-14", "authors_parsed": [["John", "Indu", ""], ["Kamanchi", "Chandramouli", ""], ["Bhatnagar", "Shalabh", ""]]}, {"id": "1911.00400", "submitter": "Paschalis Bizopoulos", "authors": "Paschalis Bizopoulos", "title": "Sparsely Activated Networks: A new method for decomposing and\n  compressing data", "comments": "PhD Thesis in Greek, 158 pages for the main text, 23 supplementary\n  pages for presentation, arXiv:1907.06592, arXiv:1904.13216, arXiv:1902.11122", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent literature on unsupervised learning focused on designing structural\npriors with the aim of learning meaningful features, but without considering\nthe description length of the representations. In this thesis, first we\nintroduce the{\\phi}metric that evaluates unsupervised models based on their\nreconstruction accuracy and the degree of compression of their internal\nrepresentations. We then present and define two activation functions (Identity,\nReLU) as base of reference and three sparse activation functions (top-k\nabsolutes, Extrema-Pool indices, Extrema) as candidate structures that minimize\nthe previously defined metric $\\varphi$. We lastly present Sparsely Activated\nNetworks (SANs) that consist of kernels with shared weights that, during\nencoding, are convolved with the input and then passed through a sparse\nactivation function. During decoding, the same weights are convolved with the\nsparse activation map and subsequently the partial reconstructions from each\nweight are summed to reconstruct the input. We compare SANs using the five\npreviously defined activation functions on a variety of datasets (Physionet,\nUCI-epilepsy, MNIST, FMNIST) and show that models that are selected using\n$\\varphi$ have small description representation length and consist of\ninterpretable kernels.\n", "versions": [{"version": "v1", "created": "Wed, 30 Oct 2019 20:11:29 GMT"}], "update_date": "2019-11-04", "authors_parsed": [["Bizopoulos", "Paschalis", ""]]}, {"id": "1911.00405", "submitter": "George Moustakides", "authors": "George V. Moustakides and Kalliopi Basioti", "title": "Training Neural Networks for Likelihood/Density Ratio Estimation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.SP cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Various problems in Engineering and Statistics require the computation of the\nlikelihood ratio function of two probability densities. In classical approaches\nthe two densities are assumed known or to belong to some known parametric\nfamily. In a data-driven version we replace this requirement with the\navailability of data sampled from the densities of interest. For most well\nknown problems in Detection and Hypothesis testing we develop solutions by\nproviding neural network based estimates of the likelihood ratio or its\ntransformations. This task necessitates the definition of proper optimizations\nwhich can be used for the training of the network. The main purpose of this\nwork is to offer a simple and unified methodology for defining such\noptimization problems with guarantees that the solution is indeed the desired\nfunction. Our results are extended to cover estimates for likelihood ratios of\nconditional densities and estimates for statistics encountered in local\napproaches.\n", "versions": [{"version": "v1", "created": "Fri, 1 Nov 2019 14:31:59 GMT"}, {"version": "v2", "created": "Tue, 5 Nov 2019 15:13:22 GMT"}], "update_date": "2019-11-06", "authors_parsed": [["Moustakides", "George V.", ""], ["Basioti", "Kalliopi", ""]]}, {"id": "1911.00417", "submitter": "Vincent Lostanlen", "authors": "Vincent Lostanlen, Kaitlin Palmer, Elly Knight, Christopher Clark,\n  Holger Klinck, Andrew Farnsworth, Tina Wong, Jason Cramer, Juan Pablo Bello", "title": "Long-distance Detection of Bioacoustic Events with Per-channel Energy\n  Normalization", "comments": "5 pages, 3 figures. Presented at the 3rd International Workshop on\n  Detection and Classification of Acoustic Scenes and Events (DCASE). 25--26\n  October 2019, New York, NY, USA", "journal-ref": null, "doi": "10.33682/ts6e-sn53", "report-no": null, "categories": "cs.SD cs.LG eess.AS", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  This paper proposes to perform unsupervised detection of bioacoustic events\nby pooling the magnitudes of spectrogram frames after per-channel energy\nnormalization (PCEN). Although PCEN was originally developed for speech\nrecognition, it also has beneficial effects in enhancing animal vocalizations,\ndespite the presence of atmospheric absorption and intermittent noise. We prove\nthat PCEN generalizes logarithm-based spectral flux, yet with a tunable time\nscale for background noise estimation. In comparison with pointwise logarithm,\nPCEN reduces false alarm rate by 50x in the near field and 5x in the far field,\nboth on avian and marine bioacoustic datasets. Such improvements come at\nmoderate computational cost and require no human intervention, thus heralding a\npromising future for PCEN in bioacoustics.\n", "versions": [{"version": "v1", "created": "Fri, 1 Nov 2019 14:50:33 GMT"}], "update_date": "2019-11-04", "authors_parsed": [["Lostanlen", "Vincent", ""], ["Palmer", "Kaitlin", ""], ["Knight", "Elly", ""], ["Clark", "Christopher", ""], ["Klinck", "Holger", ""], ["Farnsworth", "Andrew", ""], ["Wong", "Tina", ""], ["Cramer", "Jason", ""], ["Bello", "Juan Pablo", ""]]}, {"id": "1911.00418", "submitter": "Samyadeep Basu", "authors": "Samyadeep Basu, Xuchen You, Soheil Feizi", "title": "On Second-Order Group Influence Functions for Black-Box Predictions", "comments": "To Appear in ICML 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  With the rapid adoption of machine learning systems in sensitive\napplications, there is an increasing need to make black-box models explainable.\nOften we want to identify an influential group of training samples in a\nparticular test prediction for a given machine learning model. Existing\ninfluence functions tackle this problem by using first-order approximations of\nthe effect of removing a sample from the training set on model parameters. To\ncompute the influence of a group of training samples (rather than an individual\npoint) in model predictions, the change in optimal model parameters after\nremoving that group from the training set can be large. Thus, in such cases,\nthe first-order approximation can be loose. In this paper, we address this\nissue and propose second-order influence functions for identifying influential\ngroups in test-time predictions. For linear models, across different sizes and\ntypes of groups, we show that using the proposed second-order influence\nfunction improves the correlation between the computed influence values and the\nground truth ones. We also show that second-order influence functions could be\nused with optimization techniques to improve the selection of the most\ninfluential group for a test-sample.\n", "versions": [{"version": "v1", "created": "Fri, 1 Nov 2019 15:14:06 GMT"}, {"version": "v2", "created": "Tue, 7 Jul 2020 01:11:59 GMT"}], "update_date": "2020-07-08", "authors_parsed": [["Basu", "Samyadeep", ""], ["You", "Xuchen", ""], ["Feizi", "Soheil", ""]]}, {"id": "1911.00433", "submitter": "Kevin Schlegel", "authors": "Kevin Schlegel", "title": "Approximate Representer Theorems in Non-reflexive Banach Spaces", "comments": "18 pages, 1 figure", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.FA cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The representer theorem is one of the most important mathematical foundations\nfor regularised learning and kernel methods. Classical formulations of the\ntheorem state sufficient conditions under which a regularisation problem on a\nHilbert space admits a solution in the subspace spanned by the representers of\nthe data points. This turns the problem into an equivalent optimisation problem\nin a finite dimensional space, making it computationally tractable. Moreover,\nBanach space methods for learning have been receiving more and more attention.\nConsidering the representer theorem in Banach spaces is hence of increasing\nimportance. Recently the question of the necessary condition for a representer\ntheorem to hold in Hilbert spaces and certain Banach spaces has been\nconsidered. It has been shown that a classical representer theorem cannot exist\nin general in non-reflexive Banach spaces. In this paper we propose a notion of\napproximate solutions and approximate representer theorem to overcome this\nproblem. We show that for these notions we can indeed extend the previous\nresults to obtain a unified theory for the existence of representer theorems in\nany general Banach spaces, in particular including $l_1$-type spaces. We give a\nprecise characterisation when a regulariser admits a classical representer\ntheorem and when only an approximate representer theorem is possible.\n", "versions": [{"version": "v1", "created": "Fri, 1 Nov 2019 15:51:07 GMT"}], "update_date": "2019-11-04", "authors_parsed": [["Schlegel", "Kevin", ""]]}, {"id": "1911.00459", "submitter": "Danfei Xu", "authors": "Danfei Xu, Misha Denil", "title": "Positive-Unlabeled Reward Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Learning reward functions from data is a promising path towards achieving\nscalable Reinforcement Learning (RL) for robotics. However, a major challenge\nin training agents from learned reward models is that the agent can learn to\nexploit errors in the reward model to achieve high reward behaviors that do not\ncorrespond to the intended task. These reward delusions can lead to unintended\nand even dangerous behaviors. On the other hand, adversarial imitation learning\nframeworks tend to suffer the opposite problem, where the discriminator learns\nto trivially distinguish agent and expert behavior, resulting in reward models\nthat produce low reward signal regardless of the input state. In this paper, we\nconnect these two classes of reward learning methods to positive-unlabeled (PU)\nlearning, and we show that by applying a large-scale PU learning algorithm to\nthe reward learning problem, we can address both the reward under- and\nover-estimation problems simultaneously. Our approach drastically improves both\nGAIL and supervised reward learning, without any additional assumptions.\n", "versions": [{"version": "v1", "created": "Fri, 1 Nov 2019 16:47:44 GMT"}], "update_date": "2019-11-04", "authors_parsed": [["Xu", "Danfei", ""], ["Denil", "Misha", ""]]}, {"id": "1911.00461", "submitter": "Omar U. Florez", "authors": "Omar U. Florez", "title": "On the Unintended Social Bias of Training Language Generation Models\n  with Data from Local Media", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  There are concerns that neural language models may preserve some of the\nstereotypes of the underlying societies that generate the large corpora needed\nto train these models. For example, gender bias is a significant problem when\ngenerating text, and its unintended memorization could impact the user\nexperience of many applications (e.g., the smart-compose feature in Gmail).\n  In this paper, we introduce a novel architecture that decouples the\nrepresentation learning of a neural model from its memory management role. This\narchitecture allows us to update a memory module with an equal ratio across\ngender types addressing biased correlations directly in the latent space. We\nexperimentally show that our approach can mitigate the gender bias\namplification in the automatic generation of articles news while providing\nsimilar perplexity values when extending the Sequence2Sequence architecture.\n", "versions": [{"version": "v1", "created": "Fri, 1 Nov 2019 16:52:02 GMT"}], "update_date": "2019-11-04", "authors_parsed": [["Florez", "Omar U.", ""]]}, {"id": "1911.00465", "submitter": "Shahin Boluki", "authors": "Siamak Zamani Dadaneh, Shahin Boluki, Mingyuan Zhou and Xiaoning Qian", "title": "ARSM Gradient Estimator for Supervised Learning to Rank", "comments": "To appear in ICASSP 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a new model for supervised learning to rank. In our model, the\nrelevance labels are assumed to follow a categorical distribution whose\nprobabilities are constructed based on a scoring function. We optimize the\ntraining objective with respect to the multivariate categorical variables with\nan unbiased and low-variance gradient estimator. Learning-to-rank methods can\ngenerally be categorized into pointwise, pairwise, and listwise approaches.\nAlthough our scoring function is pointwise, the proposed framework permits\nflexibility over the choice of the loss function. In our new model, the loss\nfunction need not be differentiable and can either be pointwise or listwise.\nOur proposed method achieves better or comparable results on two datasets\ncompared with existing pairwise and listwise methods.\n", "versions": [{"version": "v1", "created": "Fri, 1 Nov 2019 17:05:29 GMT"}, {"version": "v2", "created": "Tue, 18 Feb 2020 05:36:29 GMT"}], "update_date": "2020-02-19", "authors_parsed": [["Dadaneh", "Siamak Zamani", ""], ["Boluki", "Shahin", ""], ["Zhou", "Mingyuan", ""], ["Qian", "Xiaoning", ""]]}, {"id": "1911.00467", "submitter": "Art Owen", "authors": "Masayoshi Mase and Art B. Owen and Benjamin Seiler", "title": "Explaining black box decisions by Shapley cohort refinement", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI econ.EM stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce a variable importance measure to quantify the impact of\nindividual input variables to a black box function. Our measure is based on the\nShapley value from cooperative game theory. Many measures of variable\nimportance operate by changing some predictor values with others held fixed,\npotentially creating unlikely or even logically impossible combinations. Our\ncohort Shapley measure uses only observed data points. Instead of changing the\nvalue of a predictor we include or exclude subjects similar to the target\nsubject on that predictor to form a similarity cohort. Then we apply Shapley\nvalue to the cohort averages. We connect variable importance measures from\nexplainable AI to function decompositions from global sensitivity analysis. We\nintroduce a squared cohort Shapley value that splits previously studied Shapley\neffects over subjects, consistent with a Shapley axiom.\n", "versions": [{"version": "v1", "created": "Fri, 1 Nov 2019 17:10:20 GMT"}, {"version": "v2", "created": "Thu, 1 Oct 2020 23:57:41 GMT"}], "update_date": "2020-10-05", "authors_parsed": [["Mase", "Masayoshi", ""], ["Owen", "Art B.", ""], ["Seiler", "Benjamin", ""]]}, {"id": "1911.00472", "submitter": "Michael Kuchnik", "authors": "Michael Kuchnik and George Amvrosiadis and Virginia Smith", "title": "Progressive Compressed Records: Taking a Byte out of Deep Learning Data", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep learning training accesses vast amounts of data at high velocity, posing\nbandwidth challenges for datasets retrieved over commodity networks and storage\ndevices. A common approach to reduce bandwidth involves resizing or compressing\ndata prior to training. We introduce a way to dynamically reduce the overhead\nof fetching and transporting data with a method we term Progressive Compressed\nRecords (PCRs). PCRs deviate from previous storage formats by combining\nprogressive compression with an efficient on-disk layout to view a single\ndataset at multiple qualities---all without adding to the total dataset size.\nWe implement PCRs and evaluate them on a range of datasets: ImageNet, HAM10000,\nStanford Cars, and CelebA-HQ. Our results show that: (i) the amount of\ncompression a dataset can tolerate depends on the training task, (ii) PCRs\nenable tasks to readily access appropriate levels of compression at\nruntime---resulting in a 2x speedup in training time on average over baseline\nformats, and (iii) the appropriate compression level for a task can be selected\nat runtime.\n", "versions": [{"version": "v1", "created": "Fri, 1 Nov 2019 17:28:56 GMT"}, {"version": "v2", "created": "Wed, 22 Apr 2020 00:03:15 GMT"}, {"version": "v3", "created": "Mon, 15 Jun 2020 01:17:15 GMT"}], "update_date": "2020-06-16", "authors_parsed": [["Kuchnik", "Michael", ""], ["Amvrosiadis", "George", ""], ["Smith", "Virginia", ""]]}, {"id": "1911.00473", "submitter": "Emad Elwany", "authors": "Emad Elwany, Dave Moore, Gaurav Oberoi", "title": "BERT Goes to Law School: Quantifying the Competitive Advantage of Access\n  to Large Legal Corpora in Contract Understanding", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Fine-tuning language models, such as BERT, on domain specific corpora has\nproven to be valuable in domains like scientific papers and biomedical text. In\nthis paper, we show that fine-tuning BERT on legal documents similarly provides\nvaluable improvements on NLP tasks in the legal domain. Demonstrating this\noutcome is significant for analyzing commercial agreements, because obtaining\nlarge legal corpora is challenging due to their confidential nature. As such,\nwe show that having access to large legal corpora is a competitive advantage\nfor commercial applications, and academic research on analyzing contracts.\n", "versions": [{"version": "v1", "created": "Fri, 1 Nov 2019 17:30:21 GMT"}], "update_date": "2019-11-04", "authors_parsed": [["Elwany", "Emad", ""], ["Moore", "Dave", ""], ["Oberoi", "Gaurav", ""]]}, {"id": "1911.00482", "submitter": "Hao Yan", "authors": "Nurettin Sergin, Hao Yan", "title": "High-dimensional Nonlinear Profile Monitoring based on Deep\n  Probabilistic Autoencoders", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Wide accessibility of imaging and profile sensors in modern industrial\nsystems created an abundance of high-dimensional sensing variables. This led to\na a growing interest in the research of high-dimensional process monitoring.\nHowever, most of the approaches in the literature assume the in-control\npopulation to lie on a linear manifold with a given basis (i.e., spline,\nwavelet, kernel, etc) or an unknown basis (i.e., principal component analysis\nand its variants), which cannot be used to efficiently model profiles with a\nnonlinear manifold which is common in many real-life cases. We propose deep\nprobabilistic autoencoders as a viable unsupervised learning approach to model\nsuch manifolds. To do so, we formulate nonlinear and probabilistic extensions\nof the monitoring statistics from classical approaches as the expected\nreconstruction error (ERE) and the KL-divergence (KLD) based monitoring\nstatistics. Through extensive simulation study, we provide insights on why\nlatent-space based statistics are unreliable and why residual-space based ones\ntypically perform much better for deep learning based approaches. Finally, we\ndemonstrate the superiority of deep probabilistic models via both simulation\nstudy and a real-life case study involving images of defects from a hot steel\nrolling process.\n", "versions": [{"version": "v1", "created": "Fri, 1 Nov 2019 17:47:49 GMT"}], "update_date": "2019-11-04", "authors_parsed": [["Sergin", "Nurettin", ""], ["Yan", "Hao", ""]]}, {"id": "1911.00483", "submitter": "Sumedha Singla", "authors": "Sumedha Singla, Brian Pollack, Junxiang Chen and Kayhan Batmanghelich", "title": "Explanation by Progressive Exaggeration", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CV", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  As machine learning methods see greater adoption and implementation in high\nstakes applications such as medical image diagnosis, the need for model\ninterpretability and explanation has become more critical. Classical approaches\nthat assess feature importance (e.g. saliency maps) do not explain how and why\na particular region of an image is relevant to the prediction. We propose a\nmethod that explains the outcome of a classification black-box by gradually\nexaggerating the semantic effect of a given class. Given a query input to a\nclassifier, our method produces a progressive set of plausible variations of\nthat query, which gradually changes the posterior probability from its original\nclass to its negation. These counter-factually generated samples preserve\nfeatures unrelated to the classification decision, such that a user can employ\nour method as a \"tuning knob\" to traverse a data manifold while crossing the\ndecision boundary. Our method is model agnostic and only requires the output\nvalue and gradient of the predictor with respect to its input.\n", "versions": [{"version": "v1", "created": "Fri, 1 Nov 2019 17:48:24 GMT"}, {"version": "v2", "created": "Tue, 5 Nov 2019 21:00:40 GMT"}, {"version": "v3", "created": "Mon, 10 Feb 2020 20:32:23 GMT"}], "update_date": "2020-02-12", "authors_parsed": [["Singla", "Sumedha", ""], ["Pollack", "Brian", ""], ["Chen", "Junxiang", ""], ["Batmanghelich", "Kayhan", ""]]}, {"id": "1911.00490", "submitter": "Alison Jenkins", "authors": "Alison Jenkins, Vinika Gupta, Alexis Myrick, Mary Lenoir", "title": "Variations of Genetic Algorithms", "comments": "genetic algorithm, elitism, generational, steady-state", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The goal of this project is to develop the Genetic Algorithms (GA) for\nsolving the Schaffer F6 function in fewer than 4000 function evaluations on a\ntotal of 30 runs. Four types of Genetic Algorithms (GA) are presented -\nGenerational GA (GGA), Steady-State (mu+1)-GA (SSGA), Steady-Generational\n(mu,mu)-GA (SGGA), and (mu+mu)-GA.\n", "versions": [{"version": "v1", "created": "Fri, 1 Nov 2019 17:57:03 GMT"}], "update_date": "2019-11-04", "authors_parsed": [["Jenkins", "Alison", ""], ["Gupta", "Vinika", ""], ["Myrick", "Alexis", ""], ["Lenoir", "Mary", ""]]}, {"id": "1911.00493", "submitter": "Veit Elser", "authors": "Veit Elser", "title": "Learning Without Loss", "comments": "52 pages, 24 figures, 1 table", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG math.ST stat.ML stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We explore a new approach for training neural networks where all loss\nfunctions are replaced by hard constraints. The same approach is very\nsuccessful in phase retrieval, where signals are reconstructed from magnitude\nconstraints and general characteristics (sparsity, support, etc.). Instead of\ntaking gradient steps, the optimizer in the constraint based approach, called\nrelaxed-reflect-reflect (RRR), derives its steps from projections to local\nconstraints. In neural networks one such projection makes the minimal\nmodification to the inputs $x$, the associated weights $w$, and the\npre-activation value $y$ at each neuron, to satisfy the equation $x\\cdot w=y$.\nThese projections, along with a host of other local projections (constraining\npre- and post-activations, etc.) can be partitioned into two sets such that all\nthe projections in each set can be applied concurrently, across the network and\nacross all data in the training batch. This partitioning into two sets is\nanalogous to the situation in phase retrieval and the setting for which the\ngeneral purpose RRR optimizer was designed. Owing to the novelty of the method,\nthis paper also serves as a self-contained tutorial. Starting with a\nsingle-layer network that performs non-negative matrix factorization, and\nconcluding with a generative model comprising an autoencoder and classifier,\nall applications and their implementations by projections are described in\ncomplete detail. Although the new approach has the potential to extend the\nscope of neural networks (e.g. by defining activation not through functions but\nconstraint sets), most of the featured models are standard to allow comparison\nwith stochastic gradient descent.\n", "versions": [{"version": "v1", "created": "Tue, 29 Oct 2019 19:20:08 GMT"}], "update_date": "2019-11-04", "authors_parsed": [["Elser", "Veit", ""]]}, {"id": "1911.00497", "submitter": "Nicholas Waytowich", "authors": "Nicholas Waytowich, Sean L. Barton, Vernon Lawhern, Garrett Warnell", "title": "A Narration-based Reward Shaping Approach using Grounded Natural\n  Language Commands", "comments": "Presented at the Imitation, Intent and Interaction (I3) workshop,\n  ICML 2019. arXiv admin note: substantial text overlap with arXiv:1906.02671", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  While deep reinforcement learning techniques have led to agents that are\nsuccessfully able to learn to perform a number of tasks that had been\npreviously unlearnable, these techniques are still susceptible to the\nlongstanding problem of reward sparsity. This is especially true for tasks such\nas training an agent to play StarCraft II, a real-time strategy game where\nreward is only given at the end of a game which is usually very long. While\nthis problem can be addressed through reward shaping, such approaches typically\nrequire a human expert with specialized knowledge. Inspired by the vision of\nenabling reward shaping through the more-accessible paradigm of\nnatural-language narration, we develop a technique that can provide the\nbenefits of reward shaping using natural language commands. Our\nnarration-guided RL agent projects sequences of natural-language commands into\nthe same high-dimensional representation space as corresponding goal states. We\nshow that we can get improved performance with our method compared to\ntraditional reward-shaping approaches. Additionally, we demonstrate the ability\nof our method to generalize to unseen natural-language commands.\n", "versions": [{"version": "v1", "created": "Thu, 31 Oct 2019 22:37:54 GMT"}], "update_date": "2019-11-05", "authors_parsed": [["Waytowich", "Nicholas", ""], ["Barton", "Sean L.", ""], ["Lawhern", "Vernon", ""], ["Warnell", "Garrett", ""]]}, {"id": "1911.00500", "submitter": "Tugba Erpek", "authors": "Yalin E. Sagduyu, Yi Shi, Tugba Erpek", "title": "Adversarial Deep Learning for Over-the-Air Spectrum Poisoning Attacks", "comments": "Accepted to IEEE Transactions on Mobile Computing. arXiv admin note:\n  text overlap with arXiv:1901.09247", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI cs.LG eess.SP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  An adversarial deep learning approach is presented to launch over-the-air\nspectrum poisoning attacks. A transmitter applies deep learning on its spectrum\nsensing results to predict idle time slots for data transmission. In the\nmeantime, an adversary learns the transmitter's behavior (exploratory attack)\nby building another deep neural network to predict when transmissions will\nsucceed. The adversary falsifies (poisons) the transmitter's spectrum sensing\ndata over the air by transmitting during the short spectrum sensing period of\nthe transmitter. Depending on whether the transmitter uses the sensing results\nas test data to make transmit decisions or as training data to retrain its deep\nneural network, either it is fooled into making incorrect decisions (evasion\nattack), or the transmitter's algorithm is retrained incorrectly for future\ndecisions (causative attack). Both attacks are energy efficient and hard to\ndetect (stealth) compared to jamming the long data transmission period, and\nsubstantially reduce the throughput. A dynamic defense is designed for the\ntransmitter that deliberately makes a small number of incorrect transmissions\n(selected by the confidence score on channel classification) to manipulate the\nadversary's training data. This defense effectively fools the adversary (if\nany) and helps the transmitter sustain its throughput with or without an\nadversary present.\n", "versions": [{"version": "v1", "created": "Fri, 1 Nov 2019 02:21:23 GMT"}], "update_date": "2019-11-05", "authors_parsed": [["Sagduyu", "Yalin E.", ""], ["Shi", "Yi", ""], ["Erpek", "Tugba", ""]]}, {"id": "1911.00502", "submitter": "Xinshi Chen", "authors": "Xinshi Chen", "title": "Review: Ordinary Differential Equations For Deep Learning", "comments": "arXiv admin note: substantial text overlap with arXiv:1902.00640", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  To better understand and improve the behavior of neural networks, a recent\nline of works bridged the connection between ordinary differential equations\n(ODEs) and deep neural networks (DNNs). The connections are made in two folds:\n(1) View DNN as ODE discretization; (2) View the training of DNN as solving an\noptimal control problem. The former connection motivates people either to\ndesign neural architectures based on ODE discretization schemes or to replace\nDNN by a continuous model characterized by ODEs. Several works demonstrated\ndistinct advantages of using a continuous model instead of traditional DNN in\nsome specific applications. The latter connection is inspiring. Based on\nPontryagin's maximum principle, which is popular in the optimal control\nliterature, some developed new optimization methods for training neural\nnetworks and some developed algorithms to train the infinite-deep continuous\nmodel with low memory-cost. This paper is organized as follows: In Section 2,\nthe relation between neural architecture and ODE discretization is introduced.\nSome architectures are not motivated by ODE, but they are later found to be\nassociated with some specific discretization schemes. Some architectures are\ndesigned based on ODE discretization and expected to achieve some special\nproperties. Section 3 formulates the optimization problem where a traditional\nneural network is replaced by a continuous model (ODE). The formulated\noptimization problem is an optimal control problem. Therefore, two different\ntypes of controls will also be discussed in this section. In Section 4, we will\ndiscuss how we can utilize the optimization methods that are popular in optimal\ncontrol literature to help the training of machine learning problems. Finally,\ntwo applications of using a continuous model will be shown in Section 5 and 6\nto demonstrate some of its advantages over traditional neural networks.\n", "versions": [{"version": "v1", "created": "Fri, 1 Nov 2019 04:26:22 GMT"}], "update_date": "2019-11-05", "authors_parsed": [["Chen", "Xinshi", ""]]}, {"id": "1911.00515", "submitter": "Gustav M{\\aa}rtensson", "authors": "Gustav M{\\aa}rtensson, Daniel Ferreira, Tobias Granberg, Lena\n  Cavallin, Ketil Oppedal, Alessandro Padovani, Irena Rektorova, Laura Bonanni,\n  Matteo Pardini, Milica Kramberger, John-Paul Taylor, Jakub Hort, J\\'on\n  Sn{\\ae}dal, Jaime Kulisevsky, Frederic Blanc, Angelo Antonini, Patrizia\n  Mecocci, Bruno Vellas, Magda Tsolaki, Iwona K{\\l}oszewska, Hilkka Soininen,\n  Simon Lovestone, Andrew Simmons, Dag Aarsland, Eric Westman", "title": "The reliability of a deep learning model in clinical out-of-distribution\n  MRI data: a multicohort study", "comments": "11 pages, 3 figures", "journal-ref": null, "doi": "10.1016/j.media.2020.101714", "report-no": null, "categories": "physics.med-ph cs.CV cs.LG eess.IV q-bio.QM stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep learning (DL) methods have in recent years yielded impressive results in\nmedical imaging, with the potential to function as clinical aid to\nradiologists. However, DL models in medical imaging are often trained on public\nresearch cohorts with images acquired with a single scanner or with strict\nprotocol harmonization, which is not representative of a clinical setting. The\naim of this study was to investigate how well a DL model performs in unseen\nclinical data sets---collected with different scanners, protocols and disease\npopulations---and whether more heterogeneous training data improves\ngeneralization. In total, 3117 MRI scans of brains from multiple dementia\nresearch cohorts and memory clinics, that had been visually rated by a\nneuroradiologist according to Scheltens' scale of medial temporal atrophy\n(MTA), were included in this study. By training multiple versions of a\nconvolutional neural network on different subsets of this data to predict MTA\nratings, we assessed the impact of including images from a wider distribution\nduring training had on performance in external memory clinic data. Our results\nshowed that our model generalized well to data sets acquired with similar\nprotocols as the training data, but substantially worse in clinical cohorts\nwith visibly different tissue contrasts in the images. This implies that future\nDL studies investigating performance in out-of-distribution (OOD) MRI data need\nto assess multiple external cohorts for reliable results. Further, by including\ndata from a wider range of scanners and protocols the performance improved in\nOOD data, which suggests that more heterogeneous training data makes the model\ngeneralize better. To conclude, this is the most comprehensive study to date\ninvestigating the domain shift in deep learning on MRI data, and we advocate\nrigorous evaluation of DL models on clinical data prior to being certified for\ndeployment.\n", "versions": [{"version": "v1", "created": "Fri, 1 Nov 2019 15:52:16 GMT"}], "update_date": "2020-05-05", "authors_parsed": [["M\u00e5rtensson", "Gustav", ""], ["Ferreira", "Daniel", ""], ["Granberg", "Tobias", ""], ["Cavallin", "Lena", ""], ["Oppedal", "Ketil", ""], ["Padovani", "Alessandro", ""], ["Rektorova", "Irena", ""], ["Bonanni", "Laura", ""], ["Pardini", "Matteo", ""], ["Kramberger", "Milica", ""], ["Taylor", "John-Paul", ""], ["Hort", "Jakub", ""], ["Sn\u00e6dal", "J\u00f3n", ""], ["Kulisevsky", "Jaime", ""], ["Blanc", "Frederic", ""], ["Antonini", "Angelo", ""], ["Mecocci", "Patrizia", ""], ["Vellas", "Bruno", ""], ["Tsolaki", "Magda", ""], ["K\u0142oszewska", "Iwona", ""], ["Soininen", "Hilkka", ""], ["Lovestone", "Simon", ""], ["Simmons", "Andrew", ""], ["Aarsland", "Dag", ""], ["Westman", "Eric", ""]]}, {"id": "1911.00523", "submitter": "Chenhao Tan", "authors": "David Atkinson, Kumar Bhargav Srinivasan, Chenhao Tan", "title": "What Gets Echoed? Understanding the \"Pointers\" in Explanations of\n  Persuasive Arguments", "comments": "19 pages, 3 figures, EMNLP 2019, the code and dataset are available\n  at https://chenhaot.com/papers/explanation-pointers.html", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.CY cs.HC cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Explanations are central to everyday life, and are a topic of growing\ninterest in the AI community. To investigate the process of providing natural\nlanguage explanations, we leverage the dynamics of the /r/ChangeMyView\nsubreddit to build a dataset with 36K naturally occurring explanations of why\nan argument is persuasive. We propose a novel word-level prediction task to\ninvestigate how explanations selectively reuse, or echo, information from what\nis being explained (henceforth, explanandum). We develop features to capture\nthe properties of a word in the explanandum, and show that our proposed\nfeatures not only have relatively strong predictive power on the echoing of a\nword in an explanation, but also enhance neural methods of generating\nexplanations. In particular, while the non-contextual properties of a word\nitself are more valuable for stopwords, the interaction between the constituent\nparts of an explanandum is crucial in predicting the echoing of content words.\nWe also find intriguing patterns of a word being echoed. For example, although\nnouns are generally less likely to be echoed, subjects and objects can,\ndepending on their source, be more likely to be echoed in the explanations.\n", "versions": [{"version": "v1", "created": "Fri, 1 Nov 2019 18:00:05 GMT"}], "update_date": "2019-11-05", "authors_parsed": [["Atkinson", "David", ""], ["Srinivasan", "Kumar Bhargav", ""], ["Tan", "Chenhao", ""]]}, {"id": "1911.00527", "submitter": "Konstantinos Drossos", "authors": "Niccol\\'o Nicodemo and Gaurav Naithani and Konstantinos Drossos and\n  Tuomas Virtanen and Roberto Saletti", "title": "Memory Requirement Reduction of Deep Neural Networks Using Low-bit\n  Quantization of Parameters", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.AS cs.LG cs.PF cs.SD", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Effective employment of deep neural networks (DNNs) in mobile devices and\nembedded systems is hampered by requirements for memory and computational\npower. This paper presents a non-uniform quantization approach which allows for\ndynamic quantization of DNN parameters for different layers and within the same\nlayer. A virtual bit shift (VBS) scheme is also proposed to improve the\naccuracy of the proposed scheme. Our method reduces the memory requirements,\npreserving the performance of the network. The performance of our method is\nvalidated in a speech enhancement application, where a fully connected DNN is\nused to predict the clean speech spectrum from the input noisy speech spectrum.\nA DNN is optimized and its memory footprint and performance are evaluated using\nthe short-time objective intelligibility, STOI, metric. The application of the\nlow-bit quantization allows a 50% reduction of the DNN memory footprint while\nthe STOI performance drops only by 2.7%.\n", "versions": [{"version": "v1", "created": "Fri, 1 Nov 2019 18:03:12 GMT"}], "update_date": "2019-11-05", "authors_parsed": [["Nicodemo", "Niccol\u00f3", ""], ["Naithani", "Gaurav", ""], ["Drossos", "Konstantinos", ""], ["Virtanen", "Tuomas", ""], ["Saletti", "Roberto", ""]]}, {"id": "1911.00536", "submitter": "Yizhe Zhang", "authors": "Yizhe Zhang, Siqi Sun, Michel Galley, Yen-Chun Chen, Chris Brockett,\n  Xiang Gao, Jianfeng Gao, Jingjing Liu, Bill Dolan", "title": "DialoGPT: Large-Scale Generative Pre-training for Conversational\n  Response Generation", "comments": "Accepted by ACL 2020 system demonstration", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a large, tunable neural conversational response generation model,\nDialoGPT (dialogue generative pre-trained transformer). Trained on 147M\nconversation-like exchanges extracted from Reddit comment chains over a period\nspanning from 2005 through 2017, DialoGPT extends the Hugging Face PyTorch\ntransformer to attain a performance close to human both in terms of automatic\nand human evaluation in single-turn dialogue settings. We show that\nconversational systems that leverage DialoGPT generate more relevant,\ncontentful and context-consistent responses than strong baseline systems. The\npre-trained model and training pipeline are publicly released to facilitate\nresearch into neural response generation and the development of more\nintelligent open-domain dialogue systems.\n", "versions": [{"version": "v1", "created": "Fri, 1 Nov 2019 18:16:54 GMT"}, {"version": "v2", "created": "Tue, 28 Apr 2020 05:45:19 GMT"}, {"version": "v3", "created": "Sat, 2 May 2020 07:09:50 GMT"}], "update_date": "2020-05-05", "authors_parsed": [["Zhang", "Yizhe", ""], ["Sun", "Siqi", ""], ["Galley", "Michel", ""], ["Chen", "Yen-Chun", ""], ["Brockett", "Chris", ""], ["Gao", "Xiang", ""], ["Gao", "Jianfeng", ""], ["Liu", "Jingjing", ""], ["Dolan", "Bill", ""]]}, {"id": "1911.00538", "submitter": "Anderson Ye Zhang", "authors": "Matthias L\\\"offler, Anderson Y. Zhang, Harrison H. Zhou", "title": "Optimality of Spectral Clustering in the Gaussian Mixture Model", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST cs.LG math.SP stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Spectral clustering is one of the most popular algorithms to group high\ndimensional data. It is easy to implement and computationally efficient.\nDespite its popularity and successful applications, its theoretical properties\nhave not been fully understood. In this paper, we show that spectral clustering\nis minimax optimal in the Gaussian Mixture Model with isotropic covariance\nmatrix, when the number of clusters is fixed and the signal-to-noise ratio is\nlarge enough. Spectral gap conditions are widely assumed in the literature to\nanalyze spectral clustering. On the contrary, these conditions are not needed\nto establish optimality of spectral clustering in this paper.\n", "versions": [{"version": "v1", "created": "Fri, 1 Nov 2019 18:24:36 GMT"}, {"version": "v2", "created": "Wed, 5 Aug 2020 21:20:55 GMT"}], "update_date": "2020-08-07", "authors_parsed": [["L\u00f6ffler", "Matthias", ""], ["Zhang", "Anderson Y.", ""], ["Zhou", "Harrison H.", ""]]}, {"id": "1911.00548", "submitter": "Anup Das", "authors": "Adarsha Balaji, Shihao Song, Anup Das, Nikil Dutt, Jeff Krichmar,\n  Nagarajan Kandasamy, Francky Catthoor", "title": "A Framework to Explore Workload-Specific Performance and Lifetime\n  Trade-offs in Neuromorphic Computing", "comments": "4 pages, 5 figures, 13 references, accepted for publication at IEEE\n  Computer Architecture Letters", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.ET cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Neuromorphic hardware with non-volatile memory (NVM) can implement machine\nlearning workload in an energy-efficient manner. Unfortunately, certain NVMs\nsuch as phase change memory (PCM) require high voltages for correct operation.\nThese voltages are supplied from an on-chip charge pump. If the charge pump is\nactivated too frequently, its internal CMOS devices do not recover from stress,\naccelerating their aging and leading to negative bias temperature instability\n(NBTI) generated defects. Forcefully discharging the stressed charge pump can\nlower the aging rate of its CMOS devices, but makes the neuromorphic hardware\nunavailable to perform computations while its charge pump is being discharged.\nThis negatively impacts performance such as latency and accuracy of the machine\nlearning workload being executed. In this paper, we propose a novel framework\nto exploit workload-specific performance and lifetime trade-offs in\nneuromorphic computing. Our framework first extracts the precise times at which\na charge pump in the hardware is activated to support neural computations\nwithin a workload. This timing information is then used with a characterized\nNBTI reliability model to estimate the charge pump's aging during the workload\nexecution. We use our framework to evaluate workload-specific performance and\nreliability impacts of using 1) different SNN mapping strategies and 2)\ndifferent charge pump discharge strategies. We show that our framework can be\nused by system designers to explore performance and reliability trade-offs\nearly in the design of neuromorphic hardware such that appropriate\nreliability-oriented design margins can be set.\n", "versions": [{"version": "v1", "created": "Fri, 1 Nov 2019 18:45:20 GMT"}], "update_date": "2019-11-05", "authors_parsed": [["Balaji", "Adarsha", ""], ["Song", "Shihao", ""], ["Das", "Anup", ""], ["Dutt", "Nikil", ""], ["Krichmar", "Jeff", ""], ["Kandasamy", "Nagarajan", ""], ["Catthoor", "Francky", ""]]}, {"id": "1911.00550", "submitter": "Lingling Yang", "authors": "Lingling Yang, Leanne Lai Hang Chan, and Yao Lu", "title": "Decoding of visual-related information from the human EEG using an\n  end-to-end deep learning approach", "comments": "\\c{opyright} 20XX IEEE. Personal use of this material is permitted.\n  Permission from IEEE must be obtained for all other uses, in any current or\n  future media, including reprinting/republishing this material for advertising\n  or promotional purposes, creating new collective works, for resale or\n  redistribution to servers or lists, or reuse of any copyrighted component of\n  this work in other works", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.SP cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  There is increasing interest in using deep learning approach for EEG analysis\nas there are still rooms for the improvement of EEG analysis in its accuracy.\nConvolutional long short-term (CNNLSTM) has been successfully applied in time\nseries data with spatial structure through end-to-end learning. Here, we\nproposed a CNNLSTM based neural network architecture termed EEG_CNNLSTMNet for\nthe classification of EEG signals in response to grating stimuli with different\nspatial frequencies. EEG_CNNLSTMNet comprises two convolutional layers and one\nbidirectional long short-term memory (LSTM) layer. The convolutional layers\ncapture local temporal characteristics of the EEG signal at each channel as\nwell as global spatial characteristics across channels, while the LSTM layer\nextracts long-term temporal dependency of EEG signals. Our experiment showed\nthat EEG_CNNLSTMNet performed much better at EEG classification than a\ntraditional machine learning approach, i.e. a support vector machine (SVM) with\nfeatures. Additionally, EEG_CNNLSTMNet outperformed EEGNet, a state-of-art\nneural network architecture for the intra-subject case. We infer that the\nunderperformance when using an LSTM layer in the inter-subject case is due to\nlong-term dependency characteristics in the EEG signal that vary greatly across\nsubjects. Moreover, the inter-subject fine-tuned classification model using\nvery little data of the new subject achieved much higher accuracy than that\ntrained only on the data from the other subjects. Our study suggests that the\nfine-tuned inter-subject model can be a potential end-to-end EEG analysis\nmethod considering both the accuracy and the required training data of the new\nsubject.\n", "versions": [{"version": "v1", "created": "Fri, 1 Nov 2019 18:47:54 GMT"}, {"version": "v2", "created": "Tue, 17 Dec 2019 19:58:13 GMT"}, {"version": "v3", "created": "Thu, 19 Dec 2019 15:37:26 GMT"}], "update_date": "2019-12-20", "authors_parsed": [["Yang", "Lingling", ""], ["Chan", "Leanne Lai Hang", ""], ["Lu", "Yao", ""]]}, {"id": "1911.00558", "submitter": "Lingling Yang", "authors": "Lingling Yang, Dongyang Li, Yao Lu", "title": "Prediction Modeling and Analysis for Telecom Customer Churn in Two\n  Months", "comments": "22 pages, 4 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A practical churn customer prediction model is critical to retain customers\nfor telecom companies in the saturated and competitive market. Previous studies\nfocus on predicting churn customers in current or next month, in which telecom\ncompanies don't have enough time to develop and carry out churn management\nstrategies. In this paper, we propose a new T+2 churn customer prediction\nmodel, in which the churn customers in two months are recognized and the\none-month window T+1 is reserved to carry out churn management strategies.\nHowever, the predictions for churn customers in two months are much more\ndifficult than in current or next month because of the weaker correlation\nbetween the customer information and churn states. Two characteristics of\ntelecom dataset, the discrimination between churn and non-churn customers is\ncomplicated and the class imbalance problem is serious, are observed. To\ndiscriminate the churn customers accurately, random forest (RF) classifier is\nchosen because RF solves the nonlinear separable problem with low bias and low\nvariance and handles high feature spaces and large number of training examples.\nTo overcome the imbalance problem, synthetic minority over-sampling with\nborderline or tomek link, in which the distribution of the samples remains and\nthe number of the training examples becomes larger, is applied. Overall, a\nprecision ratio of about 50% with a recall ratio of about 50% is achieved in\nthe T+2 churn prediction. The proposed prediction model provides an accurate\nand operable churn customer prediction model for telecom companies.\n", "versions": [{"version": "v1", "created": "Fri, 1 Nov 2019 19:15:07 GMT"}], "update_date": "2019-11-05", "authors_parsed": [["Yang", "Lingling", ""], ["Li", "Dongyang", ""], ["Lu", "Yao", ""]]}, {"id": "1911.00561", "submitter": "Hongfa Xue", "authors": "Hongfa Xue, Yongsheng Mei, Kailash Gogineni, Guru Venkataramani, Tian\n  Lan", "title": "Twin-Finder: Integrated Reasoning Engine for Pointer-related Code Clone\n  Detection", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SE cs.LG cs.PL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Detecting code clones is crucial in various software engineering tasks. In\nparticular, code clone detection can have significant uses in the context of\nanalyzing and fixing bugs in large scale applications. However, prior works,\nsuch as machine learning-based clone detection, may cause a considerable amount\nof false positives. In this paper, we propose Twin-Finder, a novel, closed-loop\napproach for pointer-related code clone detection that integrates machine\nlearning and symbolic execution techniques to achieve precision. Twin-Finder\nintroduces a clone verification mechanism to formally verify if two clone\nsamples are indeed clones and a feedback loop to automatically generated formal\nrules to tune machine learning algorithm and further reduce the false\npositives. Our experimental results show that Twin-Finder can swiftly identify\nup 9X more code clones comparing to a tree-based clone detector, Deckard and\nremove an average 91.69% false positives.\n", "versions": [{"version": "v1", "created": "Fri, 1 Nov 2019 19:20:33 GMT"}, {"version": "v2", "created": "Tue, 5 Nov 2019 18:53:11 GMT"}, {"version": "v3", "created": "Mon, 21 Sep 2020 21:02:48 GMT"}], "update_date": "2020-09-23", "authors_parsed": [["Xue", "Hongfa", ""], ["Mei", "Yongsheng", ""], ["Gogineni", "Kailash", ""], ["Venkataramani", "Guru", ""], ["Lan", "Tian", ""]]}, {"id": "1911.00567", "submitter": "Andrea Zanette", "authors": "Andrea Zanette, David Brandfonbrener, Emma Brunskill, Matteo Pirotta,\n  Alessandro Lazaric", "title": "Frequentist Regret Bounds for Randomized Least-Squares Value Iteration", "comments": "AISTATS 2020; minor bug fix", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the exploration-exploitation dilemma in finite-horizon\nreinforcement learning (RL). When the state space is large or continuous,\ntraditional tabular approaches are unfeasible and some form of function\napproximation is mandatory. In this paper, we introduce an\noptimistically-initialized variant of the popular randomized least-squares\nvalue iteration (RLSVI), a model-free algorithm where exploration is induced by\nperturbing the least-squares approximation of the action-value function. Under\nthe assumption that the Markov decision process has low-rank transition\ndynamics, we prove that the frequentist regret of RLSVI is upper-bounded by\n$\\widetilde O(d^2 H^2 \\sqrt{T})$ where $ d $ are the feature dimension, $ H $\nis the horizon, and $ T $ is the total number of steps. To the best of our\nknowledge, this is the first frequentist regret analysis for randomized\nexploration with function approximation.\n", "versions": [{"version": "v1", "created": "Fri, 1 Nov 2019 19:48:57 GMT"}, {"version": "v2", "created": "Tue, 7 Jan 2020 16:09:41 GMT"}, {"version": "v3", "created": "Fri, 10 Jan 2020 00:37:56 GMT"}, {"version": "v4", "created": "Tue, 3 Mar 2020 01:21:42 GMT"}, {"version": "v5", "created": "Mon, 22 Jun 2020 02:09:50 GMT"}], "update_date": "2020-06-23", "authors_parsed": [["Zanette", "Andrea", ""], ["Brandfonbrener", "David", ""], ["Brunskill", "Emma", ""], ["Pirotta", "Matteo", ""], ["Lazaric", "Alessandro", ""]]}, {"id": "1911.00569", "submitter": "Yaniv Yacoby", "authors": "Yaniv Yacoby, Weiwei Pan, Finale Doshi-Velez", "title": "Mitigating the Effects of Non-Identifiability on Inference for Bayesian\n  Neural Networks with Latent Variables", "comments": "Accepted at ICML's Uncertainty and Robustness in Deep Learning\n  Workshop 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Bayesian Neural Networks with Latent Variables (BNN+LVs) provide\nuncertainties in prediction estimates by explicitly modeling model uncertainty\n(via priors on network weights) and environmental stochasticity (via a latent\ninput noise variable). In this work, we first show that BNN+LV suffers from a\nserious form of non-identifiability: explanatory power can be transferred\nbetween model parameters and input noise while fitting the data equally well.\nWe demonstrate that as a result, the posterior mode over the network weights\nand latent variables is asymptotically biased away from the ground truth, and\nas a result, traditional inference methods may yield parameters that generalize\npoorly and mis-estimate uncertainty. Next, we develop a novel inference\nprocedure that explicitly mitigates the effects of likelihood\nnon-identifiability during training and yields high quality predictions as well\nas uncertainty estimates. We demonstrate that our inference method improves\nupon benchmark methods across a range of synthetic and real data sets.\n", "versions": [{"version": "v1", "created": "Fri, 1 Nov 2019 19:51:10 GMT"}, {"version": "v2", "created": "Sun, 14 Feb 2021 02:12:43 GMT"}], "update_date": "2021-02-16", "authors_parsed": [["Yacoby", "Yaniv", ""], ["Pan", "Weiwei", ""], ["Doshi-Velez", "Finale", ""]]}, {"id": "1911.00584", "submitter": "Timo Korthals", "authors": "Timo Korthals and Malte Schilling and J\\\"urgen Leitner", "title": "A Perceived Environment Design using a Multi-Modal Variational\n  Autoencoder for learning Active-Sensing", "comments": "Extended Abstract for the IROS 2019 Workshop on Deep Probabilistic\n  Generative Models for Cognitive Architecture in Robotics", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.AI cs.LG cs.MA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This contribution comprises the interplay between a multi-modal variational\nautoencoder and an environment to a perceived environment, on which an agent\ncan act. Furthermore, we conclude our work with a comparison to\ncuriosity-driven learning.\n", "versions": [{"version": "v1", "created": "Fri, 1 Nov 2019 20:38:37 GMT"}], "update_date": "2019-11-05", "authors_parsed": [["Korthals", "Timo", ""], ["Schilling", "Malte", ""], ["Leitner", "J\u00fcrgen", ""]]}, {"id": "1911.00605", "submitter": "Ziyuan Pu", "authors": "Ziyuan Pu, Zhiyong Cui, Shuo Wang, Qianmu Li, Yinhai Wang", "title": "Time-Aware Gated Recurrent Unit Networks for Road Surface Friction\n  Prediction Using Historical Data", "comments": null, "journal-ref": "IET Intelligent Transport Systems. 14.4 (2020): 213-219", "doi": "10.1049/iet-its.2019.0428", "report-no": null, "categories": "cs.LG eess.SP stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  An accurate road surface friction prediction algorithm can enable intelligent\ntransportation systems to share timely road surface condition to the public for\nincreasing the safety of the road users. Previously, scholars developed\nmultiple prediction models for forecasting road surface conditions using\nhistorical data. However, road surface condition data cannot be perfectly\ncollected at every timestamp, e.g. the data collected by on-vehicle sensors may\nbe influenced when vehicles cannot travel due to economic cost issue or weather\nissues. Such resulted missing values in the collected data can damage the\neffectiveness and accuracy of the existing prediction methods since they are\nassumed to have the input data with a fixed temporal resolution. This study\nproposed a road surface friction prediction model employing a Gated Recurrent\nUnit network-based decay mechanism (GRU-D) to handle the missing values. The\nevaluation results present that the proposed GRU-D networks outperform all\nbaseline models. The impact of missing rate on predictive accuracy, learning\nefficiency and learned decay rate are analyzed as well. The findings can help\nimprove the prediction accuracy and efficiency of forecasting road surface\nfriction using historical data sets with missing values, therefore mitigating\nthe impact of wet or icy road conditions on traffic safety.\n", "versions": [{"version": "v1", "created": "Fri, 1 Nov 2019 22:27:24 GMT"}], "update_date": "2020-07-13", "authors_parsed": [["Pu", "Ziyuan", ""], ["Cui", "Zhiyong", ""], ["Wang", "Shuo", ""], ["Li", "Qianmu", ""], ["Wang", "Yinhai", ""]]}, {"id": "1911.00616", "submitter": "Eduardo Soares Mr", "authors": "Eduardo Soares, Plamen Angelov", "title": "Novelty Detection and Learning from Extremely Weak Supervision", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we offer a method and algorithm, which make possible fully\nautonomous (unsupervised) detection of new classes, and learning following a\nvery parsimonious training priming (few labeled data samples only). Moreover,\nnew unknown classes may appear at a later stage and the proposed xClass method\nand algorithm are able to successfully discover this and learn from the data\nautonomously. Furthermore, the features (inputs to the classifier) are\nautomatically sub-selected by the algorithm based on the accumulated data\ndensity per feature per class. As a result, a highly efficient, lean,\nhuman-understandable, autonomously self-learning model (which only needs an\nextremely parsimonious priming) emerges from the data. To validate our proposal\nwe tested it on two challenging problems, including imbalanced Caltech-101 data\nset and iRoads dataset. Not only we achieved higher precision, but, more\nsignificantly, we only used a single class beforehand, while other methods used\nall the available classes) and we generated interpretable models with smaller\nnumber of features used, through extremely weak and weak supervision.\n", "versions": [{"version": "v1", "created": "Fri, 1 Nov 2019 23:51:08 GMT"}], "update_date": "2019-11-05", "authors_parsed": [["Soares", "Eduardo", ""], ["Angelov", "Plamen", ""]]}, {"id": "1911.00617", "submitter": "Mikael Henaff", "authors": "Mikael Henaff", "title": "Explicit Explore-Exploit Algorithms in Continuous State Spaces", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a new model-based algorithm for reinforcement learning (RL) which\nconsists of explicit exploration and exploitation phases, and is applicable in\nlarge or infinite state spaces. The algorithm maintains a set of dynamics\nmodels consistent with current experience and explores by finding policies\nwhich induce high disagreement between their state predictions. It then\nexploits using the refined set of models or experience gathered during\nexploration. We show that under realizability and optimal planning assumptions,\nour algorithm provably finds a near-optimal policy with a number of samples\nthat is polynomial in a structural complexity measure which we show to be low\nin several natural settings. We then give a practical approximation using\nneural networks and demonstrate its performance and sample efficiency in\npractice.\n", "versions": [{"version": "v1", "created": "Fri, 1 Nov 2019 23:58:05 GMT"}, {"version": "v2", "created": "Mon, 2 Dec 2019 16:21:13 GMT"}], "update_date": "2019-12-03", "authors_parsed": [["Henaff", "Mikael", ""]]}, {"id": "1911.00623", "submitter": "Sauptik Dhar", "authors": "Sauptik Dhar, Junyao Guo, Jiayi Liu, Samarth Tripathi, Unmesh Kurup,\n  Mohak Shah", "title": "On-Device Machine Learning: An Algorithms and Learning Theory\n  Perspective", "comments": "Edge Learning, TinyML, Resource Constrained Machine Learning, Deep\n  learning on device, Statistical Learning Theory, 45 pages survey", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.DC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The predominant paradigm for using machine learning models on a device is to\ntrain a model in the cloud and perform inference using the trained model on the\ndevice. However, with increasing number of smart devices and improved hardware,\nthere is interest in performing model training on the device. Given this surge\nin interest, a comprehensive survey of the field from a device-agnostic\nperspective sets the stage for both understanding the state-of-the-art and for\nidentifying open challenges and future avenues of research. However, on-device\nlearning is an expansive field with connections to a large number of related\ntopics in AI and machine learning (including online learning, model adaptation,\none/few-shot learning, etc.). Hence, covering such a large number of topics in\na single survey is impractical. This survey finds a middle ground by\nreformulating the problem of on-device learning as resource constrained\nlearning where the resources are compute and memory. This reformulation allows\ntools, techniques, and algorithms from a wide variety of research areas to be\ncompared equitably. In addition to summarizing the state-of-the-art, the survey\nalso identifies a number of challenges and next steps for both the algorithmic\nand theoretical aspects of on-device learning.\n", "versions": [{"version": "v1", "created": "Sat, 2 Nov 2019 01:16:02 GMT"}, {"version": "v2", "created": "Fri, 24 Jul 2020 07:04:34 GMT"}], "update_date": "2020-07-27", "authors_parsed": [["Dhar", "Sauptik", ""], ["Guo", "Junyao", ""], ["Liu", "Jiayi", ""], ["Tripathi", "Samarth", ""], ["Kurup", "Unmesh", ""], ["Shah", "Mohak", ""]]}, {"id": "1911.00630", "submitter": "Tal Ben-Nun", "authors": "Peter Gr\\\"onquist, Tal Ben-Nun, Nikoli Dryden, Peter Dueben, Luca\n  Lavarini, Shigang Li, Torsten Hoefler", "title": "Predicting Weather Uncertainty with Deep Convnets", "comments": "Poster presentation at NeurIPS2019 \"Machine Learning and the Physical\n  Sciences\" Workshop", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG physics.ao-ph stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Modern weather forecast models perform uncertainty quantification using\nensemble prediction systems, which collect nonparametric statistics based on\nmultiple perturbed simulations. To provide accurate estimation, dozens of such\ncomputationally intensive simulations must be run. We show that deep neural\nnetworks can be used on a small set of numerical weather simulations to\nestimate the spread of a weather forecast, significantly reducing computational\ncost. To train the system, we both modify the 3D U-Net architecture and explore\nmodels that incorporate temporal data. Our models serve as a starting point to\nimprove uncertainty quantification in current real-time weather forecasting\nsystems, which is vital for predicting extreme events.\n", "versions": [{"version": "v1", "created": "Sat, 2 Nov 2019 02:41:33 GMT"}, {"version": "v2", "created": "Wed, 4 Dec 2019 21:13:45 GMT"}], "update_date": "2019-12-06", "authors_parsed": [["Gr\u00f6nquist", "Peter", ""], ["Ben-Nun", "Tal", ""], ["Dryden", "Nikoli", ""], ["Dueben", "Peter", ""], ["Lavarini", "Luca", ""], ["Li", "Shigang", ""], ["Hoefler", "Torsten", ""]]}, {"id": "1911.00637", "submitter": "Chiyu Zhang", "authors": "Muhammad Abdul-Mageed, Chiyu Zhang, Arun Rajendran, AbdelRahim\n  Elmadany, Michael Przystupa and Lyle Ungar", "title": "Sentence-Level BERT and Multi-Task Learning of Age and Gender in Social\n  Media", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Social media currently provide a window on our lives, making it possible to\nlearn how people from different places, with different backgrounds, ages, and\ngenders use language. In this work we exploit a newly-created Arabic dataset\nwith ground truth age and gender labels to learn these attributes both\nindividually and in a multi-task setting at the sentence level. Our models are\nbased on variations of deep bidirectional neural networks. More specifically,\nwe build models with gated recurrent units and bidirectional encoder\nrepresentations from transformers (BERT). We show the utility of multi-task\nlearning (MTL) on the two tasks and identify task-specific attention as a\nsuperior choice in this context. We also find that a single-task BERT model\noutperform our best MTL models on the two tasks. We report tweet-level accuracy\nof 51.43% for the age task (three-way) and 65.30% on the gender task (binary),\nboth of which outperforms our baselines with a large margin. Our models are\nlanguage-agnostic, and so can be applied to other languages.\n", "versions": [{"version": "v1", "created": "Sat, 2 Nov 2019 03:39:19 GMT"}], "update_date": "2019-11-05", "authors_parsed": [["Abdul-Mageed", "Muhammad", ""], ["Zhang", "Chiyu", ""], ["Rajendran", "Arun", ""], ["Elmadany", "AbdelRahim", ""], ["Przystupa", "Michael", ""], ["Ungar", "Lyle", ""]]}, {"id": "1911.00638", "submitter": "Samuel Daulton", "authors": "Samuel Daulton, Shaun Singh, Vashist Avadhanula, Drew Dimmery, Eytan\n  Bakshy", "title": "Thompson Sampling for Contextual Bandit Problems with Auxiliary Safety\n  Constraints", "comments": "To appear at NeurIPS 2019, Workshop on Safety and Robustness in\n  Decision Making. 11 pages (including references and appendix)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent advances in contextual bandit optimization and reinforcement learning\nhave garnered interest in applying these methods to real-world sequential\ndecision making problems. Real-world applications frequently have constraints\nwith respect to a currently deployed policy. Many of the existing\nconstraint-aware algorithms consider problems with a single objective (the\nreward) and a constraint on the reward with respect to a baseline policy.\nHowever, many important applications involve multiple competing objectives and\nauxiliary constraints. In this paper, we propose a novel Thompson sampling\nalgorithm for multi-outcome contextual bandit problems with auxiliary\nconstraints. We empirically evaluate our algorithm on a synthetic problem.\nLastly, we apply our method to a real world video transcoding problem and\nprovide a practical way for navigating the trade-off between safety and\nperformance using Bayesian optimization.\n", "versions": [{"version": "v1", "created": "Sat, 2 Nov 2019 03:41:37 GMT"}], "update_date": "2019-11-05", "authors_parsed": [["Daulton", "Samuel", ""], ["Singh", "Shaun", ""], ["Avadhanula", "Vashist", ""], ["Dimmery", "Drew", ""], ["Bakshy", "Eytan", ""]]}, {"id": "1911.00645", "submitter": "Qingcan Wang", "authors": "Lei Wu, Qingcan Wang and Chao Ma", "title": "Global Convergence of Gradient Descent for Deep Linear Residual Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We analyze the global convergence of gradient descent for deep linear\nresidual networks by proposing a new initialization: zero-asymmetric (ZAS)\ninitialization. It is motivated by avoiding stable manifolds of saddle points.\nWe prove that under the ZAS initialization, for an arbitrary target matrix,\ngradient descent converges to an $\\varepsilon$-optimal point in $O(L^3\n\\log(1/\\varepsilon))$ iterations, which scales polynomially with the network\ndepth $L$. Our result and the $\\exp(\\Omega(L))$ convergence time for the\nstandard initialization (Xavier or near-identity) [Shamir, 2018] together\ndemonstrate the importance of the residual structure and the initialization in\nthe optimization for deep linear neural networks, especially when $L$ is large.\n", "versions": [{"version": "v1", "created": "Sat, 2 Nov 2019 04:14:41 GMT"}], "update_date": "2019-11-05", "authors_parsed": [["Wu", "Lei", ""], ["Wang", "Qingcan", ""], ["Ma", "Chao", ""]]}, {"id": "1911.00658", "submitter": "Xiaofei Wang", "authors": "Bin Wang, Xiaofei Wang, Jianhua Guo", "title": "Global Adaptive Generative Adjustment", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG eess.SP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Many traditional signal recovery approaches can behave well basing on the\npenalized likelihood. However, they have to meet with the difficulty in the\nselection of hyperparameters or tuning parameters in the penalties. In this\narticle, we propose a global adaptive generative adjustment (GAGA) algorithm\nfor signal recovery, in which multiple hyperpameters are automatically learned\nand alternatively updated with the signal. We further prove that the output of\nour algorithm directly guarantees the consistency of model selection and the\nasymptotic normality of signal estimate. Moreover, we also propose a variant\nGAGA algorithm for improving the computational efficiency in the\nhigh-dimensional data analysis. Finally, in the simulated experiment, we\nconsider the consistency of the outputs of our algorithms, and compare our\nalgorithms to other penalized likelihood methods: the Adaptive LASSO, the SCAD\nand the MCP. The simulation results support the efficiency of our algorithms\nfor signal recovery, and demonstrate that our algorithms outperform the other\nalgorithms.\n", "versions": [{"version": "v1", "created": "Sat, 2 Nov 2019 05:38:36 GMT"}, {"version": "v2", "created": "Wed, 6 Nov 2019 13:11:05 GMT"}], "update_date": "2019-11-07", "authors_parsed": [["Wang", "Bin", ""], ["Wang", "Xiaofei", ""], ["Guo", "Jianhua", ""]]}, {"id": "1911.00674", "submitter": "Zhibin Liao", "authors": "Zhibin Liao, Hany Girgis, Amir Abdi, Hooman Vaseli, Jorden\n  Hetherington, Robert Rohling, Ken Gin, Teresa Tsang, Purang Abolmaesumi", "title": "On Modelling Label Uncertainty in Deep Neural Networks: Automatic\n  Estimation of Intra-observer Variability in 2D Echocardiography Quality\n  Assessment", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV eess.IV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Uncertainty of labels in clinical data resulting from intra-observer\nvariability can have direct impact on the reliability of assessments made by\ndeep neural networks. In this paper, we propose a method for modelling such\nuncertainty in the context of 2D echocardiography (echo), which is a routine\nprocedure for detecting cardiovascular disease at point-of-care. Echo imaging\nquality and acquisition time is highly dependent on the operator's experience\nlevel. Recent developments have shown the possibility of automating echo image\nquality quantification by mapping an expert's assessment of quality to the echo\nimage via deep learning techniques. Nevertheless, the observer variability in\nthe expert's assessment can impact the quality quantification accuracy. Here,\nwe aim to model the intra-observer variability in echo quality assessment as an\naleatoric uncertainty modelling regression problem with the introduction of a\nnovel method that handles the regression problem with categorical labels. A key\nfeature of our design is that only a single forward pass is sufficient to\nestimate the level of uncertainty for the network output. Compared to the $0.11\n\\pm 0.09$ absolute error (in a scale from 0 to 1) archived by the conventional\nregression method, the proposed method brings the error down to $0.09 \\pm\n0.08$, where the improvement is statistically significant and equivalents to\n$5.7\\%$ test accuracy improvement. The simplicity of the proposed approach\nmeans that it could be generalized to other applications of deep learning in\nmedical imaging, where there is often uncertainty in clinical labels.\n", "versions": [{"version": "v1", "created": "Sat, 2 Nov 2019 07:51:05 GMT"}], "update_date": "2019-11-05", "authors_parsed": [["Liao", "Zhibin", ""], ["Girgis", "Hany", ""], ["Abdi", "Amir", ""], ["Vaseli", "Hooman", ""], ["Hetherington", "Jorden", ""], ["Rohling", "Robert", ""], ["Gin", "Ken", ""], ["Tsang", "Teresa", ""], ["Abolmaesumi", "Purang", ""]]}, {"id": "1911.00675", "submitter": "Otmar Ertl", "authors": "Otmar Ertl", "title": "ProbMinHash -- A Class of Locality-Sensitive Hash Algorithms for the\n  (Probability) Jaccard Similarity", "comments": "to be published in TKDE, source code available at\n  https://github.com/oertl/probminhash", "journal-ref": null, "doi": "10.1109/TKDE.2020.3021176", "report-no": null, "categories": "cs.DS cs.DB cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The probability Jaccard similarity was recently proposed as a natural\ngeneralization of the Jaccard similarity to measure the proximity of sets whose\nelements are associated with relative frequencies or probabilities. In\ncombination with a hash algorithm that maps those weighted sets to compact\nsignatures which allow fast estimation of pairwise similarities, it constitutes\na valuable method for big data applications such as near-duplicate detection,\nnearest neighbor search, or clustering. This paper introduces a class of\none-pass locality-sensitive hash algorithms that are orders of magnitude faster\nthan the original approach. The performance gain is achieved by calculating\nsignature components not independently, but collectively. Four different\nalgorithms are proposed based on this idea. Two of them are statistically\nequivalent to the original approach and can be used as drop-in replacements.\nThe other two may even improve the estimation error by introducing statistical\ndependence between signature components. Moreover, the presented techniques can\nbe specialized for the conventional Jaccard similarity, resulting in highly\nefficient algorithms that outperform traditional minwise hashing and that are\nable to compete with the state of the art.\n", "versions": [{"version": "v1", "created": "Sat, 2 Nov 2019 07:58:10 GMT"}, {"version": "v2", "created": "Sun, 5 Apr 2020 21:16:52 GMT"}, {"version": "v3", "created": "Mon, 26 Oct 2020 10:29:53 GMT"}], "update_date": "2020-10-27", "authors_parsed": [["Ertl", "Otmar", ""]]}, {"id": "1911.00677", "submitter": "Harvineet Singh", "authors": "Harvineet Singh, Rina Singh, Vishwali Mhasawade, Rumi Chunara", "title": "Fairness Violations and Mitigation under Covariate Shift", "comments": "11 pages main and 7 pages supplementary, To appear at ACM FAccT '21,\n  Previous arXiv version arXiv:1911.00677v1 was presented at Workshop on Fair\n  ML for Health '19", "journal-ref": null, "doi": "10.1145/3442188.3445865", "report-no": null, "categories": "cs.LG cs.CY stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the problem of learning fair prediction models for unseen test sets\ndistributed differently from the train set. Stability against changes in data\ndistribution is an important mandate for responsible deployment of models. The\ndomain adaptation literature addresses this concern, albeit with the notion of\nstability limited to that of prediction accuracy. We identify sufficient\nconditions under which stable models, both in terms of prediction accuracy and\nfairness, can be learned. Using the causal graph describing the data and the\nanticipated shifts, we specify an approach based on feature selection that\nexploits conditional independencies in the data to estimate accuracy and\nfairness metrics for the test set. We show that for specific fairness\ndefinitions, the resulting model satisfies a form of worst-case optimality. In\ncontext of a healthcare task, we illustrate the advantages of the approach in\nmaking more equitable decisions.\n", "versions": [{"version": "v1", "created": "Sat, 2 Nov 2019 08:10:58 GMT"}, {"version": "v2", "created": "Fri, 22 Jan 2021 20:03:54 GMT"}], "update_date": "2021-01-26", "authors_parsed": [["Singh", "Harvineet", ""], ["Singh", "Rina", ""], ["Mhasawade", "Vishwali", ""], ["Chunara", "Rumi", ""]]}, {"id": "1911.00686", "submitter": "Janis Keuper", "authors": "Ricard Durall, Margret Keuper, Franz-Josef Pfreundt, Janis Keuper", "title": "Unmasking DeepFakes with simple Features", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep generative models have recently achieved impressive results for many\nreal-world applications, successfully generating high-resolution and diverse\nsamples from complex datasets. Due to this improvement, fake digital contents\nhave proliferated growing concern and spreading distrust in image content,\nleading to an urgent need for automated ways to detect these AI-generated fake\nimages.\n  Despite the fact that many face editing algorithms seem to produce realistic\nhuman faces, upon closer examination, they do exhibit artifacts in certain\ndomains which are often hidden to the naked eye. In this work, we present a\nsimple way to detect such fake face images - so-called DeepFakes. Our method is\nbased on a classical frequency domain analysis followed by basic classifier.\nCompared to previous systems, which need to be fed with large amounts of\nlabeled data, our approach showed very good results using only a few annotated\ntraining samples and even achieved good accuracies in fully unsupervised\nscenarios. For the evaluation on high resolution face images, we combined\nseveral public datasets of real and fake faces into a new benchmark: Faces-HQ.\nGiven such high-resolution images, our approach reaches a perfect\nclassification accuracy of 100% when it is trained on as little as 20 annotated\nsamples. In a second experiment, in the evaluation of the medium-resolution\nimages of the CelebA dataset, our method achieves 100% accuracy supervised and\n96% in an unsupervised setting. Finally, evaluating a low-resolution video\nsequences of the FaceForensics++ dataset, our method achieves 91% accuracy\ndetecting manipulated videos.\n  Source Code: https://github.com/cc-hpc-itwm/DeepFakeDetection\n", "versions": [{"version": "v1", "created": "Sat, 2 Nov 2019 09:42:25 GMT"}, {"version": "v2", "created": "Fri, 8 Nov 2019 08:24:41 GMT"}, {"version": "v3", "created": "Wed, 4 Mar 2020 13:51:41 GMT"}], "update_date": "2020-03-05", "authors_parsed": [["Durall", "Ricard", ""], ["Keuper", "Margret", ""], ["Pfreundt", "Franz-Josef", ""], ["Keuper", "Janis", ""]]}, {"id": "1911.00689", "submitter": "Cyprien Ruffino", "authors": "Cyprien Ruffino and Romain H\\'erault and Eric Laloy and Gilles Gasso", "title": "Pixel-wise Conditioning of Generative Adversarial Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG eess.IV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Generative Adversarial Networks (GANs) have proven successful for\nunsupervised image generation. Several works extended GANs to image inpainting\nby conditioning the generation with parts of the image one wants to\nreconstruct. However, these methods have limitations in settings where only a\nsmall subset of the image pixels is known beforehand. In this paper, we study\nthe effectiveness of conditioning GANs by adding an explicit regularization\nterm to enforce pixel-wise conditions when very few pixel values are provided.\nIn addition, we also investigate the influence of this regularization term on\nthe quality of the generated images and the satisfaction of the conditions.\nConducted experiments on MNIST and FashionMNIST show evidence that this\nregularization term allows for controlling the trade-off between quality of the\ngenerated images and constraint satisfaction.\n", "versions": [{"version": "v1", "created": "Sat, 2 Nov 2019 10:13:39 GMT"}], "update_date": "2019-11-05", "authors_parsed": [["Ruffino", "Cyprien", ""], ["H\u00e9rault", "Romain", ""], ["Laloy", "Eric", ""], ["Gasso", "Gilles", ""]]}, {"id": "1911.00694", "submitter": "Song Yan", "authors": "Song Yan and Johan Wirta and Joni-Kristian K\\\"am\\\"ar\\\"ainen", "title": "Anthropometric clothing measurements from 3D body scans", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a full processing pipeline to acquire anthropometric measurements\nfrom 3D measurements. The first stage of our pipeline is a commercial point\ncloud scanner. In the second stage, a pre-defined body model is fitted to the\ncaptured point cloud. We have generated one male and one female model from the\nSMPL library. The fitting process is based on non-rigid Iterative Closest Point\n(ICP) algorithm that minimizes overall energy of point distance and local\nstiffness energy terms. In the third stage, we measure multiple circumference\npaths on the fitted model surface and use a non-linear regressor to provide the\nfinal estimates of anthropometric measurements. We scanned 194 male and 181\nfemale subjects and the proposed pipeline provides mean absolute errors from\n2.5 mm to 16.0 mm depending on the anthropometric measurement.\n", "versions": [{"version": "v1", "created": "Sat, 2 Nov 2019 10:55:45 GMT"}], "update_date": "2019-11-05", "authors_parsed": [["Yan", "Song", ""], ["Wirta", "Johan", ""], ["K\u00e4m\u00e4r\u00e4inen", "Joni-Kristian", ""]]}, {"id": "1911.00712", "submitter": "Sanjay Kamath", "authors": "Sanjay Kamath, Brigitte Grau, Yue Ma", "title": "How to Pre-Train Your Model? Comparison of Different Pre-Training Models\n  for Biomedical Question Answering", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Using deep learning models on small scale datasets would result in\noverfitting. To overcome this problem, the process of pre-training a model and\nfine-tuning it to the small scale dataset has been used extensively in domains\nsuch as image processing. Similarly for question answering, pre-training and\nfine-tuning can be done in several ways. Commonly reading comprehension models\nare used for pre-training, but we show that other types of pre-training can\nwork better. We compare two pre-training models based on reading comprehension\nand open domain question answering models and determine the performance when\nfine-tuned and tested over BIOASQ question answering dataset. We find open\ndomain question answering model to be a better fit for this task rather than\nreading comprehension model.\n", "versions": [{"version": "v1", "created": "Sat, 2 Nov 2019 13:25:15 GMT"}], "update_date": "2019-11-05", "authors_parsed": [["Kamath", "Sanjay", ""], ["Grau", "Brigitte", ""], ["Ma", "Yue", ""]]}, {"id": "1911.00714", "submitter": "Yu Qi", "authors": "Yu Qi, Bin Liu, Yueming Wang, Gang Pan", "title": "Dynamic Ensemble Modeling Approach to Nonstationary Neural Decoding in\n  Brain-Computer Interfaces", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.SP cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Brain-computer interfaces (BCIs) have enabled prosthetic device control by\ndecoding motor movements from neural activities. Neural signals recorded from\ncortex exhibit nonstationary property due to abrupt noises and neuroplastic\nchanges in brain activities during motor control. Current state-of-the-art\nneural signal decoders such as Kalman filter assume fixed relationship between\nneural activities and motor movements, thus will fail if this assumption is not\nsatisfied. We propose a dynamic ensemble modeling (DyEnsemble) approach that is\ncapable of adapting to changes in neural signals by employing a proper\ncombination of decoding functions. The DyEnsemble method firstly learns a set\nof diverse candidate models. Then, it dynamically selects and combines these\nmodels online according to Bayesian updating mechanism. Our method can mitigate\nthe effect of noises and cope with different task behaviors by automatic model\nswitching, thus gives more accurate predictions. Experiments with neural data\ndemonstrate that the DyEnsemble method outperforms Kalman filters remarkably,\nand its advantage is more obvious with noisy signals.\n", "versions": [{"version": "v1", "created": "Sat, 2 Nov 2019 13:41:26 GMT"}], "update_date": "2019-11-05", "authors_parsed": [["Qi", "Yu", ""], ["Liu", "Bin", ""], ["Wang", "Yueming", ""], ["Pan", "Gang", ""]]}, {"id": "1911.00731", "submitter": "Saber Salehkaleybar", "authors": "Arsalan Sharifnassab, Saber Salehkaleybar, S. Jamaloddin Golestani", "title": "Order Optimal One-Shot Distributed Learning", "comments": "arXiv admin note: substantial text overlap with arXiv:1905.04634", "journal-ref": "33rd Conference on Neural Information Processing Systems (NeurIPS\n  2019), Vancouver, Canada", "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider distributed statistical optimization in one-shot setting, where\nthere are $m$ machines each observing $n$ i.i.d. samples. Based on its observed\nsamples, each machine then sends an $O(\\log(mn))$-length message to a server,\nat which a parameter minimizing an expected loss is to be estimated. We propose\nan algorithm called Multi-Resolution Estimator (MRE) whose expected error is no\nlarger than $\\tilde{O}\\big(m^{-{1}/{\\max(d,2)}} n^{-1/2}\\big)$, where $d$ is\nthe dimension of the parameter space. This error bound meets existing lower\nbounds up to poly-logarithmic factors, and is thereby order optimal. The\nexpected error of MRE, unlike existing algorithms, tends to zero as the number\nof machines ($m$) goes to infinity, even when the number of samples per machine\n($n$) remains upper bounded by a constant. This property of the MRE algorithm\nmakes it applicable in new machine learning paradigms where $m$ is much larger\nthan $n$.\n", "versions": [{"version": "v1", "created": "Sat, 2 Nov 2019 15:14:40 GMT"}], "update_date": "2019-11-12", "authors_parsed": [["Sharifnassab", "Arsalan", ""], ["Salehkaleybar", "Saber", ""], ["Golestani", "S. Jamaloddin", ""]]}, {"id": "1911.00756", "submitter": "Neha Das", "authors": "Neha Das, Maximilian Karl, Philip Becker-Ehmck and Patrick van der\n  Smagt", "title": "Beta DVBF: Learning State-Space Models for Control from High Dimensional\n  Observations", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Learning a model of dynamics from high-dimensional images can be a core\ningredient for success in many applications across different domains,\nespecially in sequential decision making. However, currently prevailing methods\nbased on latent-variable models are limited to working with low resolution\nimages only. In this work, we show that some of the issues with using\nhigh-dimensional observations arise from the discrepancy between the\ndimensionality of the latent and observable space, and propose solutions to\novercome them.\n", "versions": [{"version": "v1", "created": "Sat, 2 Nov 2019 17:26:12 GMT"}], "update_date": "2019-11-05", "authors_parsed": [["Das", "Neha", ""], ["Karl", "Maximilian", ""], ["Becker-Ehmck", "Philip", ""], ["van der Smagt", "Patrick", ""]]}, {"id": "1911.00757", "submitter": "Komlan Atitey", "authors": "Komlan Atitey, Pavel Loskot and Lyudmila Mihaylova", "title": "Variational Bayesian inference of hidden stochastic processes with\n  unknown parameters", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.CO stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Estimating hidden processes from non-linear noisy observations is\nparticularly difficult when the parameters of these processes are not known.\nThis paper adopts a machine learning approach to devise variational Bayesian\ninference for such scenarios. In particular, a random process generated by the\nautoregressive moving average (ARMA) linear model is inferred from\nnon-linearity noise observations. The posterior distribution of hidden states\nare approximated by a set of weighted particles generated by the sequential\nMonte carlo (SMC) algorithm involving sampling with importance sampling\nresampling (SISR). Numerical efficiency and estimation accuracy of the proposed\ninference method are evaluated by computer simulations. Furthermore, the\nproposed inference method is demonstrated on a practical problem of estimating\nthe missing values in the gene expression time series assuming vector\nautoregressive (VAR) data model.\n", "versions": [{"version": "v1", "created": "Sat, 2 Nov 2019 17:27:11 GMT"}], "update_date": "2019-11-05", "authors_parsed": [["Atitey", "Komlan", ""], ["Loskot", "Pavel", ""], ["Mihaylova", "Lyudmila", ""]]}, {"id": "1911.00765", "submitter": "Jun Zhao", "authors": "Jun Zhao", "title": "Adaptive Statistical Learning with Bayesian Differential Privacy", "comments": "WPES '17 Proceedings of the 2017 on Workshop on Privacy in the\n  Electronic Society, held in conjunction with ACM SIGSAC 25th Annual\n  Conference on Computer and Communications Security (CCS), Dallas, Texas, US,\n  October 2017", "journal-ref": null, "doi": "10.1145/3139550.3139556", "report-no": null, "categories": "cs.LG cs.CR cs.CY stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In statistical learning, a dataset is often partitioned into two parts: the\ntraining set and the holdout (i.e., testing) set. For instance, the training\nset is used to learn a predictor, and then the holdout set is used for\nestimating the accuracy of the predictor on the true distribution. However,\noften in practice, the holdout dataset is reused and the estimates tested on\nthe holdout dataset are chosen adaptively based on the results of prior\nestimates, leading to that the predictor may become dependent of the holdout\nset. Hence, overfitting may occur, and the learned models may not generalize\nwell to the unseen datasets. Prior studies have established connections between\nthe stability of a learning algorithm and its ability to generalize, but the\ntraditional generalization is not robust to adaptive composition. Recently,\nDwork et al. in NIPS, STOC, and Science 2015 show that the holdout dataset from\ni.i.d. data samples can be reused in adaptive statistical learning, if the\nestimates are perturbed and coordinated using techniques developed for\ndifferential privacy, which is a widely used notion to quantify privacy. Yet,\nthe results of Dwork et al. are applicable to only the case of i.i.d. samples.\nIn contrast, correlations between data samples exist because of various\nbehavioral, social, and genetic relationships between users. Our results in\nadaptive statistical learning generalize the results of Dwork et al. for i.i.d.\ndata samples to arbitrarily correlated data. Specifically, we show that the\nholdout dataset from correlated samples can be reused in adaptive statistical\nlearning, if the estimates are perturbed and coordinated using techniques\ndeveloped for Bayesian differential privacy, which is a privacy notion recently\nintroduced by Yang et al. in SIGMOD 2015 to broaden the application scenarios\nof differential privacy when data records are correlated.\n", "versions": [{"version": "v1", "created": "Sat, 2 Nov 2019 18:45:31 GMT"}], "update_date": "2019-11-05", "authors_parsed": [["Zhao", "Jun", ""]]}, {"id": "1911.00773", "submitter": "Changmao Li", "authors": "Changmao Li, Tianhao Liu, Jinho D. Choi", "title": "Design and Challenges of Cloze-Style Reading Comprehension Tasks on\n  Multiparty Dialogue", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper analyzes challenges in cloze-style reading comprehension on\nmultiparty dialogue and suggests two new tasks for more comprehensive\npredictions of personal entities in daily conversations. We first demonstrate\nthat there are substantial limitations to the evaluation methods of previous\nwork, namely that randomized assignment of samples to training and test data\nsubstantially decreases the complexity of cloze-style reading comprehension.\nAccording to our analysis, replacing the random data split with a chronological\ndata split reduces test accuracy on previous single-variable passage completion\ntask from 72\\% to 34\\%, that leaves much more room to improve. Our proposed\ntasks extend the previous single-variable passage completion task by replacing\nmore character mentions with variables. Several deep learning models are\ndeveloped to validate these three tasks. A thorough error analysis is provided\nto understand the challenges and guide the future direction of this research.\n", "versions": [{"version": "v1", "created": "Sat, 2 Nov 2019 19:19:28 GMT"}, {"version": "v2", "created": "Mon, 12 Jul 2021 20:48:25 GMT"}], "update_date": "2021-07-14", "authors_parsed": [["Li", "Changmao", ""], ["Liu", "Tianhao", ""], ["Choi", "Jinho D.", ""]]}, {"id": "1911.00776", "submitter": "Changmao Li", "authors": "Changmao Li, Han He, Yunze Hao, Caleb Ziems", "title": "Ten-year Survival Prediction for Breast Cancer Patients", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This report assesses different machine learning approaches to 10-year\nsurvival prediction of breast cancer patients.\n", "versions": [{"version": "v1", "created": "Sat, 2 Nov 2019 19:53:32 GMT"}], "update_date": "2019-11-05", "authors_parsed": [["Li", "Changmao", ""], ["He", "Han", ""], ["Hao", "Yunze", ""], ["Ziems", "Caleb", ""]]}, {"id": "1911.00782", "submitter": "Bao Wang", "authors": "Bao Wang, Difan Zou, Quanquan Gu, Stanley Osher", "title": "Laplacian Smoothing Stochastic Gradient Markov Chain Monte Carlo", "comments": "27 pages, 5 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.NA math.NA stat.CO stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  As an important Markov Chain Monte Carlo (MCMC) method, stochastic gradient\nLangevin dynamics (SGLD) algorithm has achieved great success in Bayesian\nlearning and posterior sampling. However, SGLD typically suffers from slow\nconvergence rate due to its large variance caused by the stochastic gradient.\nIn order to alleviate these drawbacks, we leverage the recently developed\nLaplacian Smoothing (LS) technique and propose a Laplacian smoothing stochastic\ngradient Langevin dynamics (LS-SGLD) algorithm. We prove that for sampling from\nboth log-concave and non-log-concave densities, LS-SGLD achieves strictly\nsmaller discretization error in $2$-Wasserstein distance, although its mixing\nrate can be slightly slower. Experiments on both synthetic and real datasets\nverify our theoretical results, and demonstrate the superior performance of\nLS-SGLD on different machine learning tasks including posterior sampling,\nBayesian logistic regression and training Bayesian convolutional neural\nnetworks. The code is available at\n\\url{https://github.com/BaoWangMath/LS-MCMC}.\n", "versions": [{"version": "v1", "created": "Sat, 2 Nov 2019 20:32:11 GMT"}], "update_date": "2019-11-05", "authors_parsed": [["Wang", "Bao", ""], ["Zou", "Difan", ""], ["Gu", "Quanquan", ""], ["Osher", "Stanley", ""]]}, {"id": "1911.00783", "submitter": "Tolulope Odetola", "authors": "Tolulope A. Odetola and Hawzhin Raoof Mohammed and Syed Rafay Hasan", "title": "A Stealthy Hardware Trojan Exploiting the Architectural Vulnerability of\n  Deep Learning Architectures: Input Interception Attack (IIA)", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep learning architectures (DLA) have shown impressive performance in\ncomputer vision, natural language processing and so on. Many DLA make use of\ncloud computing to achieve classification due to the high computation and\nmemory requirements. Privacy and latency concerns resulting from cloud\ncomputing has inspired the deployment of DLA on embedded hardware accelerators.\nTo achieve short time-to-market and have access to global experts,\nstate-of-the-art techniques of DLA deployment on hardware accelerators are\noutsourced to untrusted third parties. This outsourcing raises security\nconcerns as hardware Trojans can be inserted into the hardware design of the\nmapped DLA of the hardware accelerator. We argue that existing hardware Trojan\nattacks highlighted in literature have no qualitative means how definite they\nare of the triggering of the Trojan. Also, most inserted Trojans show a obvious\nspike in the number of hardware resources utilized on the accelerator at the\ntime of triggering the Trojan or when the payload is active. In this paper, we\nintroduce a hardware Trojan attack called Input Interception Attack (IIA). In\nthis attack, we make use of the statistical properties of layer-by-layer output\nto ensure that asides from being stealthy. Our IIA is able to trigger with some\nmeasure of definiteness. Moreover, this IIA attack is tested on DLA used to\nclassify MNIST and Cifar-10 data sets. The attacked design utilizes\napproximately up to 2% more LUTs respectively compared to the un-compromised\ndesigns. Finally, this paper discusses potential defensive mechanisms that\ncould be used to combat such hardware Trojans based attack in hardware\naccelerators for DLA.\n", "versions": [{"version": "v1", "created": "Sat, 2 Nov 2019 20:34:16 GMT"}, {"version": "v2", "created": "Wed, 27 Jan 2021 16:07:07 GMT"}], "update_date": "2021-01-28", "authors_parsed": [["Odetola", "Tolulope A.", ""], ["Mohammed", "Hawzhin Raoof", ""], ["Hasan", "Syed Rafay", ""]]}, {"id": "1911.00792", "submitter": "Franz Heinsen", "authors": "Franz A. Heinsen", "title": "An Algorithm for Routing Capsules in All Domains", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Building on recent work on capsule networks, we propose a new,\ngeneral-purpose form of \"routing by agreement\" that activates output capsules\nin a layer as a function of their net benefit to use and net cost to ignore\ninput capsules from earlier layers. To illustrate the usefulness of our routing\nalgorithm, we present two capsule networks that apply it in different domains:\nvision and language. The first network achieves new state-of-the-art accuracy\nof 99.1% on the smallNORB visual recognition task with fewer parameters and an\norder of magnitude less training than previous capsule models, and we find\nevidence that it learns to perform a form of \"reverse graphics.\" The second\nnetwork achieves new state-of-the-art accuracies on the root sentences of the\nStanford Sentiment Treebank: 58.5% on fine-grained and 95.6% on binary labels\nwith a single-task model that routes frozen embeddings from a pretrained\ntransformer as capsules. In both domains, we train with the same regime. Code\nis available at https://github.com/glassroom/heinsen_routing along with\nreplication instructions.\n", "versions": [{"version": "v1", "created": "Sat, 2 Nov 2019 22:13:18 GMT"}, {"version": "v2", "created": "Tue, 5 Nov 2019 16:42:42 GMT"}, {"version": "v3", "created": "Fri, 8 Nov 2019 02:02:32 GMT"}, {"version": "v4", "created": "Sun, 8 Dec 2019 17:20:13 GMT"}, {"version": "v5", "created": "Sun, 15 Dec 2019 18:49:59 GMT"}, {"version": "v6", "created": "Fri, 28 Feb 2020 16:57:39 GMT"}], "update_date": "2020-03-02", "authors_parsed": [["Heinsen", "Franz A.", ""]]}, {"id": "1911.00804", "submitter": "Isabela Maria Carneiro de Albuquerque", "authors": "Isabela Albuquerque, Jo\\~ao Monteiro, Mohammad Darvishi, Tiago H.\n  Falk, and Ioannis Mitliagkas", "title": "Generalizing to unseen domains via distribution matching", "comments": "Major changes to the text and the title. Added experiments on\n  affective state prediction", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Supervised learning results typically rely on assumptions of i.i.d. data.\nUnfortunately, those assumptions are commonly violated in practice. In this\nwork, we tackle this problem by focusing on domain generalization: a\nformalization where the data generating process at test time may yield samples\nfrom never-before-seen domains (distributions). Our work relies on a simple\nlemma: by minimizing a notion of discrepancy between all pairs from a set of\ngiven domains, we also minimize the discrepancy between any pairs of mixtures\nof domains. Using this result, we derive a generalization bound for our\nsetting. We then show that low risk over unseen domains can be achieved by\nrepresenting the data in a space where (i) the training distributions are\nindistinguishable, and (ii) relevant information for the task at hand is\npreserved. Minimizing the terms in our bound yields an adversarial formulation\nwhich estimates and minimizes pairwise discrepancies. We validate our proposed\nstrategy on standard domain generalization benchmarks, outperforming a number\nof recently introduced methods. Notably, we tackle a real-world application\nwhere the underlying data corresponds to multi-channel electroencephalography\ntime series from different subjects, each considered as a distinct domain.\n", "versions": [{"version": "v1", "created": "Sun, 3 Nov 2019 01:03:15 GMT"}, {"version": "v2", "created": "Wed, 8 Apr 2020 22:33:52 GMT"}, {"version": "v3", "created": "Sat, 25 Apr 2020 21:04:02 GMT"}, {"version": "v4", "created": "Mon, 15 Jun 2020 17:42:47 GMT"}], "update_date": "2020-06-16", "authors_parsed": [["Albuquerque", "Isabela", ""], ["Monteiro", "Jo\u00e3o", ""], ["Darvishi", "Mohammad", ""], ["Falk", "Tiago H.", ""], ["Mitliagkas", "Ioannis", ""]]}, {"id": "1911.00809", "submitter": "Ruosong Wang", "authors": "Zhiyuan Li, Ruosong Wang, Dingli Yu, Simon S. Du, Wei Hu, Ruslan\n  Salakhutdinov, Sanjeev Arora", "title": "Enhanced Convolutional Neural Tangent Kernels", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent research shows that for training with $\\ell_2$ loss, convolutional\nneural networks (CNNs) whose width (number of channels in convolutional layers)\ngoes to infinity correspond to regression with respect to the CNN Gaussian\nProcess kernel (CNN-GP) if only the last layer is trained, and correspond to\nregression with respect to the Convolutional Neural Tangent Kernel (CNTK) if\nall layers are trained. An exact algorithm to compute CNTK (Arora et al., 2019)\nyielded the finding that classification accuracy of CNTK on CIFAR-10 is within\n6-7% of that of that of the corresponding CNN architecture (best figure being\naround 78%) which is interesting performance for a fixed kernel. Here we show\nhow to significantly enhance the performance of these kernels using two ideas.\n(1) Modifying the kernel using a new operation called Local Average Pooling\n(LAP) which preserves efficient computability of the kernel and inherits the\nspirit of standard data augmentation using pixel shifts. Earlier papers were\nunable to incorporate naive data augmentation because of the quadratic training\ncost of kernel regression. This idea is inspired by Global Average Pooling\n(GAP), which we show for CNN-GP and CNTK is equivalent to full translation data\naugmentation. (2) Representing the input image using a pre-processing technique\nproposed by Coates et al. (2011), which uses a single convolutional layer\ncomposed of random image patches. On CIFAR-10, the resulting kernel, CNN-GP\nwith LAP and horizontal flip data augmentation, achieves 89% accuracy, matching\nthe performance of AlexNet (Krizhevsky et al., 2012). Note that this is the\nbest such result we know of for a classifier that is not a trained neural\nnetwork. Similar improvements are obtained for Fashion-MNIST.\n", "versions": [{"version": "v1", "created": "Sun, 3 Nov 2019 02:24:39 GMT"}], "update_date": "2019-11-05", "authors_parsed": [["Li", "Zhiyuan", ""], ["Wang", "Ruosong", ""], ["Yu", "Dingli", ""], ["Du", "Simon S.", ""], ["Hu", "Wei", ""], ["Salakhutdinov", "Ruslan", ""], ["Arora", "Sanjeev", ""]]}, {"id": "1911.00815", "submitter": "Eric Goodman", "authors": "Eric L. Goodman, Dirk Grunwald", "title": "A Streaming Analytics Language for Processing Cyber Data", "comments": "Machine Learning and Data Mining 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.PL cs.CR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a domain-specific language called SAL(the Streaming Analytics\nLanguage) for processing data in a semi-streaming model. In particular we\nexamine the use case of processing netflow data in order to identify malicious\nactors within a network. Because of the large volume of data generated from\nnetworks, it is often only feasible to process the data with a single pass,\nutilizing a streaming (O(polylog n) space requirements) or semi-streaming\ncomputing model ( O(n polylog n) space requirements). Despite these\nconstraints, we are able to achieve an average of 0.87 for the AUC of the ROC\ncurve for a set of situations dealing with botnet detection. The implementation\nof an interpreter for SAL, which we call SAM (Streaming Analytics Machine),\nachieves scaling results that show improved throughput to 61 nodes (976 cores),\nwith an overall rate of 373,000 netflows per second or 32.2 billion per day.\nSAL provides a succinct way to describe common analyses that allow cyber\nanalysts to find data of interest, and SAM is a scalable interpreter of the\nlanguage.\n", "versions": [{"version": "v1", "created": "Sun, 3 Nov 2019 03:14:21 GMT"}], "update_date": "2019-11-05", "authors_parsed": [["Goodman", "Eric L.", ""], ["Grunwald", "Dirk", ""]]}, {"id": "1911.00822", "submitter": "Yujie Wu", "authors": "Lei Deng, Yujie Wu, Yifan Hu, Ling Liang, Guoqi Li, Xing Hu, Yufei\n  Ding, Peng Li, Yuan Xie", "title": "Comprehensive SNN Compression Using ADMM Optimization and Activity\n  Regularization", "comments": "Under review", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.LG eess.SP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  As well known, the huge memory and compute costs of both artificial neural\nnetworks (ANNs) and spiking neural networks (SNNs) greatly hinder their\ndeployment on edge devices with high efficiency. Model compression has been\nproposed as a promising technique to improve the running efficiency via\nparameter and operation reduction. Whereas, this technique is mainly practiced\nin ANNs rather than SNNs. It is interesting to answer how much an SNN model can\nbe compressed without compromising its functionality, where two challenges\nshould be addressed: i) the accuracy of SNNs is usually sensitive to model\ncompression, which requires an accurate compression methodology; ii) the\ncomputation of SNNs is event-driven rather than static, which produces an extra\ncompression dimension on dynamic spikes. To this end, we realize a\ncomprehensive SNN compression through three steps. First, we formulate the\nconnection pruning and weight quantization as a constrained optimization\nproblem. Second, we combine spatio-temporal backpropagation (STBP) and\nalternating direction method of multipliers (ADMM) to solve the problem with\nminimum accuracy loss. Third, we further propose activity regularization to\nreduce the spike events for fewer active operations. These methods can be\napplied in either a single way for moderate compression or a joint way for\naggressive compression. We define several quantitative metrics to evaluation\nthe compression performance for SNNs. Our methodology is validated in pattern\nrecognition tasks over MNIST, N-MNIST, CIFAR10, and CIFAR100 datasets, where\nextensive comparisons, analyses, and insights are provided. To our best\nknowledge, this is the first work that studies SNN compression in a\ncomprehensive manner by exploiting all compressible components and achieves\nbetter results.\n", "versions": [{"version": "v1", "created": "Sun, 3 Nov 2019 04:07:23 GMT"}, {"version": "v2", "created": "Fri, 24 Jul 2020 01:22:43 GMT"}, {"version": "v3", "created": "Thu, 20 Aug 2020 06:42:05 GMT"}], "update_date": "2020-08-21", "authors_parsed": [["Deng", "Lei", ""], ["Wu", "Yujie", ""], ["Hu", "Yifan", ""], ["Liang", "Ling", ""], ["Li", "Guoqi", ""], ["Hu", "Xing", ""], ["Ding", "Yufei", ""], ["Li", "Peng", ""], ["Xie", "Yuan", ""]]}, {"id": "1911.00828", "submitter": "Andrew Cohen", "authors": "Andrew Cohen and Lei Yu and Xingye Qiao and Xiangrong Tong", "title": "Maximum Entropy Diverse Exploration: Disentangling Maximum Entropy\n  Reinforcement Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Two hitherto disconnected threads of research, diverse exploration (DE) and\nmaximum entropy RL have addressed a wide range of problems facing reinforcement\nlearning algorithms via ostensibly distinct mechanisms. In this work, we\nidentify a connection between these two approaches. First, a\ndiscriminator-based diversity objective is put forward and connected to\ncommonly used divergence measures. We then extend this objective to the maximum\nentropy framework and propose an algorithm Maximum Entropy Diverse Exploration\n(MEDE) which provides a principled method to learn diverse behaviors. A\ntheoretical investigation shows that the set of policies learned by MEDE\ncapture the same modalities as the optimal maximum entropy policy. In effect,\nthe proposed algorithm disentangles the maximum entropy policy into its\ndiverse, constituent policies. Experiments show that MEDE is superior to the\nstate of the art in learning high performing and diverse policies.\n", "versions": [{"version": "v1", "created": "Sun, 3 Nov 2019 04:25:00 GMT"}], "update_date": "2019-11-05", "authors_parsed": [["Cohen", "Andrew", ""], ["Yu", "Lei", ""], ["Qiao", "Xingye", ""], ["Tong", "Xiangrong", ""]]}, {"id": "1911.00845", "submitter": "Xiaolei Lu", "authors": "Xiaolei Lu and Bin Ni", "title": "Low-dimensional Semantic Space: from Text to Word Embedding", "comments": "in Chinese", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This article focuses on the study of Word Embedding, a feature-learning\ntechnique in Natural Language Processing that maps words or phrases to\nlow-dimensional vectors. Beginning with the linguistic theories concerning\ncontextual similarities - \"Distributional Hypothesis\" and \"Context of\nSituation\", this article introduces two ways of numerical representation of\ntext: One-hot and Distributed Representation. In addition, this article\npresents statistical-based Language Models(such as Co-occurrence Matrix and\nSingular Value Decomposition) as well as Neural Network Language Models (NNLM,\nsuch as Continuous Bag-of-Words and Skip-Gram). This article also analyzes how\nWord Embedding can be applied to the study of word-sense disambiguation and\ndiachronic linguistics.\n", "versions": [{"version": "v1", "created": "Sun, 3 Nov 2019 07:11:58 GMT"}], "update_date": "2019-11-05", "authors_parsed": [["Lu", "Xiaolei", ""], ["Ni", "Bin", ""]]}, {"id": "1911.00847", "submitter": "Mahardhika Pratama Dr", "authors": "Mahardhika Pratama, Andri Ashfahani and Mohamad Abdul Hady", "title": "Weakly Supervised Deep Learning Approach in Streaming Environments", "comments": "This paper has been accepted for publication in The 2019 IEEE\n  International Conference on Big Data (IEEE BigData 2019), Los Angeles, CA,\n  USA", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG eess.SP stat.ML", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  The feasibility of existing data stream algorithms is often hindered by the\nweakly supervised condition of data streams. A self-evolving deep neural\nnetwork, namely Parsimonious Network (ParsNet), is proposed as a solution to\nvarious weakly-supervised data stream problems. A self-labelling strategy with\nhedge (SLASH) is proposed in which its auto-correction mechanism copes with\n\\textit{the accumulation of mistakes} significantly affecting the model's\ngeneralization. ParsNet is developed from a closed-loop configuration of the\nself-evolving generative and discriminative training processes exploiting\nshared parameters in which its structure flexibly grows and shrinks to overcome\nthe issue of concept drift with/without labels. The numerical evaluation has\nbeen performed under two challenging problems, namely sporadic access to ground\ntruth and infinitely delayed access to the ground truth. Our numerical study\nshows the advantage of ParsNet with a substantial margin from its counterparts\nin the high-dimensional data streams and infinite delay simulation protocol. To\nsupport the reproducible research initiative, the source code of ParsNet along\nwith supplementary materials are made available at https://bit.ly/2qNW7p4.\n", "versions": [{"version": "v1", "created": "Sun, 3 Nov 2019 07:31:25 GMT"}, {"version": "v2", "created": "Thu, 14 Nov 2019 14:40:51 GMT"}, {"version": "v3", "created": "Thu, 9 Jan 2020 12:28:12 GMT"}, {"version": "v4", "created": "Mon, 24 Aug 2020 07:47:19 GMT"}], "update_date": "2020-08-25", "authors_parsed": [["Pratama", "Mahardhika", ""], ["Ashfahani", "Andri", ""], ["Hady", "Mohamad Abdul", ""]]}, {"id": "1911.00856", "submitter": "Sheng Zhou", "authors": "Wenqi Shi, Sheng Zhou, Zhisheng Niu", "title": "Device Scheduling with Fast Convergence for Wireless Federated Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI cs.IT cs.LG math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Owing to the increasing need for massive data analysis and model training at\nthe network edge, as well as the rising concerns about the data privacy, a new\ndistributed training framework called federated learning (FL) has emerged. In\neach iteration of FL (called round), the edge devices update local models based\non their own data and contribute to the global training by uploading the model\nupdates via wireless channels. Due to the limited spectrum resources, only a\nportion of the devices can be scheduled in each round. While most of the\nexisting work on scheduling focuses on the convergence of FL w.r.t. rounds, the\nconvergence performance under a total training time budget is not yet explored.\nIn this paper, a joint bandwidth allocation and scheduling problem is\nformulated to capture the long-term convergence performance of FL, and is\nsolved by being decoupled into two sub-problems. For the bandwidth allocation\nsub-problem, the derived optimal solution suggests to allocate more bandwidth\nto the devices with worse channel conditions or weaker computation\ncapabilities. For the device scheduling sub-problem, by revealing the trade-off\nbetween the number of rounds required to attain a certain model accuracy and\nthe latency per round, a greedy policy is inspired, that continuously selects\nthe device that consumes the least time in model updating until achieving a\ngood trade-off between the learning efficiency and latency per round. The\nexperiments show that the proposed policy outperforms other state-of-the-art\nscheduling policies, with the best achievable model accuracy under training\ntime budgets.\n", "versions": [{"version": "v1", "created": "Sun, 3 Nov 2019 09:37:37 GMT"}], "update_date": "2019-11-05", "authors_parsed": [["Shi", "Wenqi", ""], ["Zhou", "Sheng", ""], ["Niu", "Zhisheng", ""]]}, {"id": "1911.00870", "submitter": "Shai Rozenberg", "authors": "Shai Rozenberg, Gal Elidan, Ran El-Yaniv", "title": "MadNet: Using a MAD Optimization for Defending Against Adversarial\n  Attacks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR cs.CV stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  This paper is concerned with the defense of deep models against adversarial\nattacks. Inspired by the certificate defense approach, we propose a maximal\nadversarial distortion (MAD) optimization method for robustifying deep\nnetworks. MAD captures the idea of increasing separability of class clusters in\nthe embedding space while decreasing the network sensitivity to small\ndistortions. Given a deep neural network (DNN) for a classification problem, an\napplication of MAD optimization results in MadNet, a version of the original\nnetwork, now equipped with an adversarial defense mechanism. MAD optimization\nis intuitive, effective and scalable, and the resulting MadNet can improve the\noriginal accuracy. We present an extensive empirical study demonstrating that\nMadNet improves adversarial robustness performance compared to state-of-the-art\nmethods.\n", "versions": [{"version": "v1", "created": "Sun, 3 Nov 2019 11:21:35 GMT"}, {"version": "v2", "created": "Fri, 12 Jun 2020 19:05:36 GMT"}], "update_date": "2020-06-16", "authors_parsed": [["Rozenberg", "Shai", ""], ["Elidan", "Gal", ""], ["El-Yaniv", "Ran", ""]]}, {"id": "1911.00874", "submitter": "Henning Urbat", "authors": "Henning Urbat and Lutz Schr\\\"oder", "title": "Automata Learning: An Algebraic Approach", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.FL cs.LG cs.LO", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We propose a generic categorical framework for learning unknown formal\nlanguages of various types (e.g. finite or infinite words, weighted and nominal\nlanguages). Our approach is parametric in a monad T that represents the given\ntype of languages and their recognizing algebraic structures. Using the concept\nof anautomata presentation of T-algebras, we demonstrate that the task of\nlearning a T-recognizable language can be reduced to learning an abstract form\nof algebraic automaton whose transitions are modeled by a functor. For the\nimportant case of adjoint automata, we devise a learning algorithm generalizing\nAngluin's L*. The algorithm is phrased in terms of categorically described\nextension steps; we provide for a termination and complexity analysis based on\na dedicated notion of finiteness. Our framework applies to structures like\nomega-regular languages that were not within the scope of existing categorical\naccounts of automata learning. In addition, it yields new learning algorithms\nfor several types of languages for which no such algorithms were previously\nknown at all, including sorted languages, nominal languages with name binding,\nand cost functions.\n", "versions": [{"version": "v1", "created": "Sun, 3 Nov 2019 11:42:50 GMT"}, {"version": "v2", "created": "Tue, 5 May 2020 15:44:53 GMT"}, {"version": "v3", "created": "Fri, 28 Aug 2020 13:35:41 GMT"}], "update_date": "2020-08-31", "authors_parsed": [["Urbat", "Henning", ""], ["Schr\u00f6der", "Lutz", ""]]}, {"id": "1911.00886", "submitter": "Yikai Wang", "authors": "Yikai Wang, Liang Zhang, Quanyu Dai, Fuchun Sun, Bo Zhang, Yang He,\n  Weipeng Yan, Yongjun Bao", "title": "Regularized Adversarial Sampling and Deep Time-aware Attention for\n  Click-Through Rate Prediction", "comments": "CIKM 2019 Long Paper, 10 pages", "journal-ref": null, "doi": "10.1145/3357384.3357936", "report-no": null, "categories": "cs.LG cs.IR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Improving the performance of click-through rate (CTR) prediction remains one\nof the core tasks in online advertising systems. With the rise of deep\nlearning, CTR prediction models with deep networks remarkably enhance model\ncapacities. In deep CTR models, exploiting users' historical data is essential\nfor learning users' behaviors and interests. As existing CTR prediction works\nneglect the importance of the temporal signals when embed users' historical\nclicking records, we propose a time-aware attention model which explicitly uses\nabsolute temporal signals for expressing the users' periodic behaviors and\nrelative temporal signals for expressing the temporal relation between items.\nBesides, we propose a regularized adversarial sampling strategy for negative\nsampling which eases the classification imbalance of CTR data and can make use\nof the strong guidance provided by the observed negative CTR samples. The\nadversarial sampling strategy significantly improves the training efficiency,\nand can be co-trained with the time-aware attention model seamlessly.\nExperiments are conducted on real-world CTR datasets from both in-station and\nout-station advertising places.\n", "versions": [{"version": "v1", "created": "Sun, 3 Nov 2019 13:40:57 GMT"}], "update_date": "2019-11-05", "authors_parsed": [["Wang", "Yikai", ""], ["Zhang", "Liang", ""], ["Dai", "Quanyu", ""], ["Sun", "Fuchun", ""], ["Zhang", "Bo", ""], ["He", "Yang", ""], ["Yan", "Weipeng", ""], ["Bao", "Yongjun", ""]]}, {"id": "1911.00887", "submitter": "Marc Fischer", "authors": "Marc Fischer, Matthew Mirman, Steven Stalder, Martin Vechev", "title": "Online Robustness Training for Deep Reinforcement Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In deep reinforcement learning (RL), adversarial attacks can trick an agent\ninto unwanted states and disrupt training. We propose a system called Robust\nStudent-DQN (RS-DQN), which permits online robustness training alongside Q\nnetworks, while preserving competitive performance. We show that RS-DQN can be\ncombined with (i) state-of-the-art adversarial training and (ii) provably\nrobust training to obtain an agent that is resilient to strong attacks during\ntraining and evaluation.\n", "versions": [{"version": "v1", "created": "Sun, 3 Nov 2019 13:44:42 GMT"}, {"version": "v2", "created": "Thu, 7 Nov 2019 13:09:37 GMT"}, {"version": "v3", "created": "Fri, 22 Nov 2019 07:12:00 GMT"}], "update_date": "2019-11-25", "authors_parsed": [["Fischer", "Marc", ""], ["Mirman", "Matthew", ""], ["Stalder", "Steven", ""], ["Vechev", "Martin", ""]]}, {"id": "1911.00888", "submitter": "Mingkui Tan", "authors": "Jiezhang Cao, Langyuan Mo, Yifan Zhang, Kui Jia, Chunhua Shen, Mingkui\n  Tan", "title": "Multi-marginal Wasserstein GAN", "comments": "This paper is accepted by NeurIPS 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Multiple marginal matching problem aims at learning mappings to match a\nsource domain to multiple target domains and it has attracted great attention\nin many applications, such as multi-domain image translation. However,\naddressing this problem has two critical challenges: (i) Measuring the\nmulti-marginal distance among different domains is very intractable; (ii) It is\nvery difficult to exploit cross-domain correlations to match the target domain\ndistributions. In this paper, we propose a novel Multi-marginal Wasserstein GAN\n(MWGAN) to minimize Wasserstein distance among domains. Specifically, with the\nhelp of multi-marginal optimal transport theory, we develop a new adversarial\nobjective function with inner- and inter-domain constraints to exploit\ncross-domain correlations. Moreover, we theoretically analyze the\ngeneralization performance of MWGAN, and empirically evaluate it on the\nbalanced and imbalanced translation tasks. Extensive experiments on toy and\nreal-world datasets demonstrate the effectiveness of MWGAN.\n", "versions": [{"version": "v1", "created": "Sun, 3 Nov 2019 13:47:19 GMT"}], "update_date": "2019-11-05", "authors_parsed": [["Cao", "Jiezhang", ""], ["Mo", "Langyuan", ""], ["Zhang", "Yifan", ""], ["Jia", "Kui", ""], ["Shen", "Chunhua", ""], ["Tan", "Mingkui", ""]]}, {"id": "1911.00890", "submitter": "Marylou Gabri\\'e", "authors": "Marylou Gabri\\'e", "title": "Mean-field inference methods for neural networks", "comments": null, "journal-ref": "JPhysA 2020", "doi": "10.1088/1751-8121/ab7f65", "report-no": null, "categories": "cond-mat.dis-nn cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Machine learning algorithms relying on deep neural networks recently allowed\na great leap forward in artificial intelligence. Despite the popularity of\ntheir applications, the efficiency of these algorithms remains largely\nunexplained from a theoretical point of view. The mathematical description of\nlearning problems involves very large collections of interacting random\nvariables, difficult to handle analytically as well as numerically. This\ncomplexity is precisely the object of study of statistical physics. Its\nmission, originally pointed towards natural systems, is to understand how\nmacroscopic behaviors arise from microscopic laws. Mean-field methods are one\ntype of approximation strategy developed in this view. We review a selection of\nclassical mean-field methods and recent progress relevant for inference in\nneural networks. In particular, we remind the principles of derivations of\nhigh-temperature expansions, the replica method and message passing algorithms,\nhighlighting their equivalences and complementarities. We also provide\nreferences for past and current directions of research on neural networks\nrelying on mean-field methods.\n", "versions": [{"version": "v1", "created": "Sun, 3 Nov 2019 14:04:57 GMT"}, {"version": "v2", "created": "Thu, 5 Mar 2020 12:13:23 GMT"}], "update_date": "2020-03-24", "authors_parsed": [["Gabri\u00e9", "Marylou", ""]]}, {"id": "1911.00891", "submitter": "Debanjan Ghosh", "authors": "Debanjan Ghosh, Elena Musi, Kartikeya Upasani, Smaranda Muresan", "title": "Interpreting Verbal Irony: Linguistic Strategies and the Connection to\n  the Type of Semantic Incongruity", "comments": "Accepted at Society for Computation in Linguistics (SCiL), 2020\n  Conference", "journal-ref": null, "doi": "10.7275/91ey-3n44", "report-no": null, "categories": "cs.CL cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Human communication often involves the use of verbal irony or sarcasm, where\nthe speakers usually mean the opposite of what they say. To better understand\nhow verbal irony is expressed by the speaker and interpreted by the hearer we\nconduct a crowdsourcing task: given an utterance expressing verbal irony, users\nare asked to verbalize their interpretation of the speaker's ironic message. We\npropose a typology of linguistic strategies for verbal irony interpretation and\nlink it to various theoretical linguistic frameworks. We design computational\nmodels to capture these strategies and present empirical studies aimed to\nanswer three questions: (1) what is the distribution of linguistic strategies\nused by hearers to interpret ironic messages?; (2) do hearers adopt similar\nstrategies for interpreting the speaker's ironic intent?; and (3) does the type\nof semantic incongruity in the ironic message (explicit vs. implicit) influence\nthe choice of interpretation strategies by the hearers?\n", "versions": [{"version": "v1", "created": "Sun, 3 Nov 2019 14:05:55 GMT"}, {"version": "v2", "created": "Tue, 5 Nov 2019 12:25:55 GMT"}, {"version": "v3", "created": "Sat, 9 May 2020 18:49:28 GMT"}], "update_date": "2020-05-12", "authors_parsed": [["Ghosh", "Debanjan", ""], ["Musi", "Elena", ""], ["Upasani", "Kartikeya", ""], ["Muresan", "Smaranda", ""]]}, {"id": "1911.00896", "submitter": "Amina Asif", "authors": "Amina Asif and Fayyaz ul Amir Afsar Minhas", "title": "Generalized Learning with Rejection for Classification and Regression\n  Problems", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Learning with rejection (LWR) allows development of machine learning systems\nwith the ability to discard low confidence decisions generated by a prediction\nmodel. That is, just like human experts, LWR allows machine models to abstain\nfrom generating a prediction when reliability of the prediction is expected to\nbe low. Several frameworks for this learning with rejection have been proposed\nin the literature. However, most of them work for classification problems only\nand regression with rejection has not been studied in much detail. In this\nwork, we present a neural framework for LWR based on a generalized meta-loss\nfunction that involves simultaneous training of two neural network models: a\npredictor model for generating predictions and a rejecter model for deciding\nwhether the prediction should be accepted or rejected. The proposed framework\ncan be used for classification as well as regression and other related machine\nlearning tasks. We have demonstrated the applicability and effectiveness of the\nmethod on synthetically generated data as well as benchmark datasets from UCI\nmachine learning repository for both classification and regression problems.\nDespite being simpler in implementation, the proposed scheme for learning with\nrejection has shown to perform at par or better than previously proposed\nmethods. Furthermore, we have applied the method to the problem of hurricane\nintensity prediction from satellite imagery. Significant improvement in\nperformance as compared to conventional supervised methods shows the\neffectiveness of the proposed scheme in real-world regression problems.\n", "versions": [{"version": "v1", "created": "Sun, 3 Nov 2019 14:21:04 GMT"}], "update_date": "2019-11-05", "authors_parsed": [["Asif", "Amina", ""], ["Minhas", "Fayyaz ul Amir Afsar", ""]]}, {"id": "1911.00914", "submitter": "Saturnino Luz", "authors": "Bridget Kane, Jing Su, Saturnino Luz", "title": "Potential Applications of Machine Learning at Multidisciplinary Medical\n  Team Meetings", "comments": "5 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.CY cs.HC cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  While machine learning (ML) systems have produced great advances in several\ndomains, their use in support of complex cooperative work remains a research\nchallenge. A particularly challenging setting, and one that may benefit from ML\nsupport is the work of multidisciplinary medical teams (MDTs). This paper\nfocuses on the activities performed during the multidisciplinary medical team\nmeeting (MDTM), reviewing their main characteristics in light of a longitudinal\nanalysis of several MDTs in a large teaching hospital over a period of ten\nyears and of our development of ML methods to support MDTMs, and identifying\nopportunities and possible pitfalls for the use of ML to support MDTMs.\n", "versions": [{"version": "v1", "created": "Sun, 3 Nov 2019 15:51:14 GMT"}], "update_date": "2019-11-05", "authors_parsed": [["Kane", "Bridget", ""], ["Su", "Jing", ""], ["Luz", "Saturnino", ""]]}, {"id": "1911.00922", "submitter": "Yuhao Su", "authors": "Yuhao Su and Jie Ding", "title": "Variable Grouping Based Bayesian Additive Regression Tree", "comments": "5 pages, 3 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG eess.SP stat.ME stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Using ensemble methods for regression has been a large success in obtaining\nhigh-accuracy prediction. Examples are Bagging, Random forest, Boosting, BART\n(Bayesian additive regression tree), and their variants. In this paper, we\npropose a new perspective named variable grouping to enhance the predictive\nperformance. The main idea is to seek for potential grouping of variables in\nsuch way that there is no nonlinear interaction term between variables of\ndifferent groups. Given a sum-of-learner model, each learner will only be\nresponsible for one group of variables, which would be more efficient in\nmodeling nonlinear interactions. We propose a two-stage method named variable\ngrouping based Bayesian additive regression tree (GBART) with a well-developed\npython package gbart available. The first stage is to search for potential\ninteractions and an appropriate grouping of variables. The second stage is to\nbuild a final model based on the discovered groups. Experiments on synthetic\nand real data show that the proposed method can perform significantly better\nthan classical approaches.\n", "versions": [{"version": "v1", "created": "Sun, 3 Nov 2019 16:08:56 GMT"}, {"version": "v2", "created": "Tue, 5 Nov 2019 02:16:02 GMT"}], "update_date": "2019-11-06", "authors_parsed": [["Su", "Yuhao", ""], ["Ding", "Jie", ""]]}, {"id": "1911.00926", "submitter": "Daniel Tanneberg", "authors": "Daniel Tanneberg, Elmar Rueckert, Jan Peters", "title": "Learning Algorithmic Solutions to Symbolic Planning Tasks with a Neural\n  Computer Architecture", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.AI cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A key feature of intelligent behavior is the ability to learn abstract\nstrategies that transfer to unfamiliar problems. Therefore, we present a novel\narchitecture, based on memory-augmented networks, that is inspired by the von\nNeumann and Harvard architectures of modern computers. This architecture\nenables the learning of abstract algorithmic solutions via Evolution Strategies\nin a reinforcement learning setting. Applied to Sokoban, sliding block puzzle\nand robotic manipulation tasks, we show that the architecture can learn\nalgorithmic solutions with strong generalization and abstraction: scaling to\narbitrary task configurations and complexities, and being independent of both\nthe data representation and the task domain.\n", "versions": [{"version": "v1", "created": "Wed, 30 Oct 2019 17:02:13 GMT"}, {"version": "v2", "created": "Wed, 3 Jun 2020 11:21:39 GMT"}], "update_date": "2020-06-04", "authors_parsed": [["Tanneberg", "Daniel", ""], ["Rueckert", "Elmar", ""], ["Peters", "Jan", ""]]}, {"id": "1911.00927", "submitter": "Jiamin Wang", "authors": "Ya-guan Qian, Dan-feng Ma, Bin Wang, Jun Pan, Jia-min Wang, Jian-hai\n  Chen, Wu-jie Zhou, Jing-sheng Lei", "title": "Spot Evasion Attacks: Adversarial Examples for License Plate Recognition\n  Systems with Convolutional Neural Networks", "comments": "26 pages, 16 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG eess.IV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent studies have shown convolution neural networks (CNNs) for image\nrecognition are vulnerable to evasion attacks with carefully manipulated\nadversarial examples. Previous work primarily focused on how to generate\nadversarial examples closed to source images, by introducing pixel-level\nperturbations into the whole or specific part of images. In this paper, we\npropose an evasion attack on CNN classifiers in the context of License Plate\nRecognition (LPR), which adds predetermined perturbations to specific regions\nof license plate images, simulating some sort of naturally formed spots (such\nas sludge, etc.). Therefore, the problem is modeled as an optimization process\nsearching for optimal perturbation positions, which is different from previous\nwork that consider pixel values as decision variables. Notice that this is a\ncomplex nonlinear optimization problem, and we use a genetic-algorithm based\napproach to obtain optimal perturbation positions. In experiments, we use the\nproposed algorithm to generate various adversarial examples in the form of\nrectangle, circle, ellipse and spots cluster. Experimental results show that\nthese adversarial examples are almost ignored by human eyes, but can fool\nHyperLPR with high attack success rate over 93%. Therefore, we believe that\nthis kind of spot evasion attacks would pose a great threat to current LPR\nsystems, and needs to be investigated further by the security community.\n", "versions": [{"version": "v1", "created": "Sun, 27 Oct 2019 05:34:23 GMT"}, {"version": "v2", "created": "Thu, 28 Nov 2019 02:23:19 GMT"}], "update_date": "2019-12-02", "authors_parsed": [["Qian", "Ya-guan", ""], ["Ma", "Dan-feng", ""], ["Wang", "Bin", ""], ["Pan", "Jun", ""], ["Wang", "Jia-min", ""], ["Chen", "Jian-hai", ""], ["Zhou", "Wu-jie", ""], ["Lei", "Jing-sheng", ""]]}, {"id": "1911.00934", "submitter": "Jun Sun Dr.", "authors": "Jun Sun, Gang Wang, Georgios B. Giannakis, Qinmin Yang, and Zaiyue\n  Yang", "title": "Finite-Sample Analysis of Decentralized Temporal-Difference Learning\n  with Linear Function Approximation", "comments": "25 pages, 3 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.IT cs.SY eess.SY math.IT math.OC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Motivated by the emerging use of multi-agent reinforcement learning (MARL) in\nengineering applications such as networked robotics, swarming drones, and\nsensor networks, we investigate the policy evaluation problem in a fully\ndecentralized setting, using temporal-difference (TD) learning with linear\nfunction approximation to handle large state spaces in practice. The goal of a\ngroup of agents is to collaboratively learn the value function of a given\npolicy from locally private rewards observed in a shared environment, through\nexchanging local estimates with neighbors. Despite their simplicity and\nwidespread use, our theoretical understanding of such decentralized TD learning\nalgorithms remains limited. Existing results were obtained based on i.i.d. data\nsamples, or by imposing an `additional' projection step to control the\n`gradient' bias incurred by the Markovian observations. In this paper, we\nprovide a finite-sample analysis of the fully decentralized TD(0) learning\nunder both i.i.d. as well as Markovian samples, and prove that all local\nestimates converge linearly to a small neighborhood of the optimum. The\nresultant error bounds are the first of its type---in the sense that they hold\nunder the most practical assumptions ---which is made possible by means of a\nnovel multi-step Lyapunov analysis.\n", "versions": [{"version": "v1", "created": "Sun, 3 Nov 2019 17:30:07 GMT"}, {"version": "v2", "created": "Wed, 29 Jan 2020 21:30:10 GMT"}], "update_date": "2020-01-31", "authors_parsed": [["Sun", "Jun", ""], ["Wang", "Gang", ""], ["Giannakis", "Georgios B.", ""], ["Yang", "Qinmin", ""], ["Yang", "Zaiyue", ""]]}, {"id": "1911.00936", "submitter": "Daeryong Kim", "authors": "Daeryong Kim and Bongwon Suh", "title": "Enhancing VAEs for Collaborative Filtering: Flexible Priors & Gating\n  Mechanisms", "comments": null, "journal-ref": "In Thirteenth ACM Conference on Recommender Systems (RecSys '19),\n  September 16-20, 2019, Copenhagen, Denmark. ACM, New York, NY, USA, 5 pages", "doi": "10.1145/3298689.3347015", "report-no": null, "categories": "stat.ML cs.IR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Neural network based models for collaborative filtering have started to gain\nattention recently. One branch of research is based on using deep generative\nmodels to model user preferences where variational autoencoders were shown to\nproduce state-of-the-art results. However, there are some potentially\nproblematic characteristics of the current variational autoencoder for CF. The\nfirst is the too simplistic prior that VAEs incorporate for learning the latent\nrepresentations of user preference. The other is the model's inability to learn\ndeeper representations with more than one hidden layer for each network. Our\ngoal is to incorporate appropriate techniques to mitigate the aforementioned\nproblems of variational autoencoder CF and further improve the recommendation\nperformance. Our work is the first to apply flexible priors to collaborative\nfiltering and show that simple priors (in original VAEs) may be too restrictive\nto fully model user preferences and setting a more flexible prior gives\nsignificant gains. We experiment with the VampPrior, originally proposed for\nimage generation, to examine the effect of flexible priors in CF. We also show\nthat VampPriors coupled with gating mechanisms outperform SOTA results\nincluding the Variational Autoencoder for Collaborative Filtering by meaningful\nmargins on 2 popular benchmark datasets (MovieLens & Netflix).\n", "versions": [{"version": "v1", "created": "Sun, 3 Nov 2019 17:42:57 GMT"}], "update_date": "2019-11-05", "authors_parsed": [["Kim", "Daeryong", ""], ["Suh", "Bongwon", ""]]}, {"id": "1911.00937", "submitter": "Qiyang Li", "authors": "Qiyang Li, Saminul Haque, Cem Anil, James Lucas, Roger Grosse,\n  J\\\"orn-Henrik Jacobsen", "title": "Preventing Gradient Attenuation in Lipschitz Constrained Convolutional\n  Networks", "comments": "9 main pages, 31 pages total, 3 figures. Accepted at 33rd Conference\n  on Neural Information Processing Systems (NeurIPS 2019)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Lipschitz constraints under L2 norm on deep neural networks are useful for\nprovable adversarial robustness bounds, stable training, and Wasserstein\ndistance estimation. While heuristic approaches such as the gradient penalty\nhave seen much practical success, it is challenging to achieve similar\npractical performance while provably enforcing a Lipschitz constraint. In\nprinciple, one can design Lipschitz constrained architectures using the\ncomposition property of Lipschitz functions, but Anil et al. recently\nidentified a key obstacle to this approach: gradient norm attenuation. They\nshowed how to circumvent this problem in the case of fully connected networks\nby designing each layer to be gradient norm preserving. We extend their\napproach to train scalable, expressive, provably Lipschitz convolutional\nnetworks. In particular, we present the Block Convolution Orthogonal\nParameterization (BCOP), an expressive parameterization of orthogonal\nconvolution operations. We show that even though the space of orthogonal\nconvolutions is disconnected, the largest connected component of BCOP with 2n\nchannels can represent arbitrary BCOP convolutions over n channels. Our BCOP\nparameterization allows us to train large convolutional networks with provable\nLipschitz bounds. Empirically, we find that it is competitive with existing\napproaches to provable adversarial robustness and Wasserstein distance\nestimation.\n", "versions": [{"version": "v1", "created": "Sun, 3 Nov 2019 17:57:10 GMT"}, {"version": "v2", "created": "Sat, 9 Nov 2019 21:22:38 GMT"}], "update_date": "2019-11-12", "authors_parsed": [["Li", "Qiyang", ""], ["Haque", "Saminul", ""], ["Anil", "Cem", ""], ["Lucas", "James", ""], ["Grosse", "Roger", ""], ["Jacobsen", "J\u00f6rn-Henrik", ""]]}, {"id": "1911.00941", "submitter": "Vladimir Vovk", "authors": "Vladimir Vovk, Ivan Petej, Ilia Nouretdinov, Valery Manokhin, and Alex\n  Gammerman", "title": "Computationally efficient versions of conformal predictive distributions", "comments": "31 pages, 14 figures, 1 table. The conference version published in\n  the Proceedings of COPA 2018, and the journal version is to appear in\n  Neurocomputing", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Conformal predictive systems are a recent modification of conformal\npredictors that output, in regression problems, probability distributions for\nlabels of test observations rather than set predictions. The extra information\nprovided by conformal predictive systems may be useful, e.g., in decision\nmaking problems. Conformal predictive systems inherit the relative\ncomputational inefficiency of conformal predictors. In this paper we discuss\ntwo computationally efficient versions of conformal predictive systems, which\nwe call split conformal predictive systems and cross-conformal predictive\nsystems. The main advantage of split conformal predictive systems is their\nguaranteed validity, whereas for cross-conformal predictive systems validity\nonly holds empirically and in the absence of excessive randomization. The main\nadvantage of cross-conformal predictive systems is their greater predictive\nefficiency.\n", "versions": [{"version": "v1", "created": "Sun, 3 Nov 2019 18:18:09 GMT"}], "update_date": "2019-11-05", "authors_parsed": [["Vovk", "Vladimir", ""], ["Petej", "Ivan", ""], ["Nouretdinov", "Ilia", ""], ["Manokhin", "Valery", ""], ["Gammerman", "Alex", ""]]}, {"id": "1911.00949", "submitter": "Zhongfang Zhuang", "authors": "Zhongfang Zhuang, Xiangnan Kong, Elke Rundensteiner, Jihane Zouaoui,\n  Aditya Arora", "title": "Attributed Sequence Embedding", "comments": "Accepted by IEEE Big Data 2019", "journal-ref": null, "doi": "10.1109/BigData47090.2019.9006481", "report-no": null, "categories": "cs.LG cs.CL cs.DB stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Mining tasks over sequential data, such as clickstreams and gene sequences,\nrequire a careful design of embeddings usable by learning algorithms. Recent\nresearch in feature learning has been extended to sequential data, where each\ninstance consists of a sequence of heterogeneous items with a variable length.\nHowever, many real-world applications often involve attributed sequences, where\neach instance is composed of both a sequence of categorical items and a set of\nattributes. In this paper, we study this new problem of attributed sequence\nembedding, where the goal is to learn the representations of attributed\nsequences in an unsupervised fashion. This problem is core to many important\ndata mining tasks ranging from user behavior analysis to the clustering of gene\nsequences. This problem is challenging due to the dependencies between\nsequences and their associated attributes. We propose a deep multimodal\nlearning framework, called NAS, to produce embeddings of attributed sequences.\nThe embeddings are task independent and can be used on various mining tasks of\nattributed sequences. We demonstrate the effectiveness of our embeddings of\nattributed sequences in various unsupervised learning tasks on real-world\ndatasets.\n", "versions": [{"version": "v1", "created": "Sun, 3 Nov 2019 19:16:51 GMT"}], "update_date": "2020-07-28", "authors_parsed": [["Zhuang", "Zhongfang", ""], ["Kong", "Xiangnan", ""], ["Rundensteiner", "Elke", ""], ["Zouaoui", "Jihane", ""], ["Arora", "Aditya", ""]]}, {"id": "1911.00954", "submitter": "Andrea Zanette", "authors": "Andrea Zanette, Emma Brunskill", "title": "Problem Dependent Reinforcement Learning Bounds Which Can Identify\n  Bandit Structure in MDPs", "comments": null, "journal-ref": "International Conference on Machine Learning, 2018", "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In order to make good decision under uncertainty an agent must learn from\nobservations. To do so, two of the most common frameworks are Contextual\nBandits and Markov Decision Processes (MDPs). In this paper, we study whether\nthere exist algorithms for the more general framework (MDP) which automatically\nprovide the best performance bounds for the specific problem at hand without\nuser intervention and without modifying the algorithm. In particular, it is\nfound that a very minor variant of a recently proposed reinforcement learning\nalgorithm for MDPs already matches the best possible regret bound $\\tilde O\n(\\sqrt{SAT})$ in the dominant term if deployed on a tabular Contextual Bandit\nproblem despite the agent being agnostic to such setting.\n", "versions": [{"version": "v1", "created": "Sun, 3 Nov 2019 19:44:30 GMT"}], "update_date": "2019-11-05", "authors_parsed": [["Zanette", "Andrea", ""], ["Brunskill", "Emma", ""]]}, {"id": "1911.00957", "submitter": "Iacopo Masi", "authors": "Iacopo Masi, Joe Mathai, Wael AbdAlmageed", "title": "Towards Learning Structure via Consensus for Face Segmentation and\n  Parsing", "comments": "To appear in the IEEE/CVF Conference on Computer Vision and Pattern\n  Recognition CVPR 2020. Project page at\n  https://github.com/isi-vista/structure_via_consensus", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG eess.IV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Face segmentation is the task of densely labeling pixels on the face\naccording to their semantics. While current methods place an emphasis on\ndeveloping sophisticated architectures, use conditional random fields for\nsmoothness, or rather employ adversarial training, we follow an alternative\npath towards robust face segmentation and parsing. Occlusions, along with other\nparts of the face, have a proper structure that needs to be propagated in the\nmodel during training. Unlike state-of-the-art methods that treat face\nsegmentation as an independent pixel prediction problem, we argue instead that\nit should hold highly correlated outputs within the same object pixels. We\nthereby offer a novel learning mechanism to enforce structure in the prediction\nvia consensus, guided by a robust loss function that forces pixel objects to be\nconsistent with each other. Our face parser is trained by transferring\nknowledge from another model, yet it encourages spatial consistency while\nfitting the labels. Different than current practice, our method enjoys\npixel-wise predictions, yet paves the way for fewer artifacts, less sparse\nmasks, and spatially coherent outputs.\n", "versions": [{"version": "v1", "created": "Sun, 3 Nov 2019 19:53:05 GMT"}, {"version": "v2", "created": "Sun, 10 Nov 2019 02:24:59 GMT"}, {"version": "v3", "created": "Sat, 28 Mar 2020 16:52:02 GMT"}], "update_date": "2020-03-31", "authors_parsed": [["Masi", "Iacopo", ""], ["Mathai", "Joe", ""], ["AbdAlmageed", "Wael", ""]]}, {"id": "1911.00958", "submitter": "Alexander Jung", "authors": "Alexander Jung", "title": "Clustering in Partially Labeled Stochastic Block Models via Total\n  Variation Minimization", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A main task in data analysis is to organize data points into coherent groups\nor clusters. The stochastic block model is a probabilistic model for the\ncluster structure. This model prescribes different probabilities for the\npresence of edges within a cluster and between different clusters. We assume\nthat the cluster assignments are known for at least one data point in each\ncluster. In such a partially labeled stochastic block model, clustering amounts\nto estimating the cluster assignments of the remaining data points. We study\ntotal variation minimization as a method for this clustering task. We implement\nthe resulting clustering algorithm as a highly scalable message-passing\nprotocol. We also provide a condition on the model parameters such that total\nvariation minimization allows for accurate clustering.\n", "versions": [{"version": "v1", "created": "Sun, 3 Nov 2019 19:57:38 GMT"}, {"version": "v2", "created": "Wed, 23 Sep 2020 17:22:33 GMT"}], "update_date": "2020-09-24", "authors_parsed": [["Jung", "Alexander", ""]]}, {"id": "1911.00962", "submitter": "Xiaofeng Liu", "authors": "Xiaofeng Liu, Yang Zou, Tong Che, Peng Ding, Ping Jia, Jane You, Kumar\n  B.V.K", "title": "Conservative Wasserstein Training for Pose Estimation", "comments": "ICCV 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG eess.IV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper targets the task with discrete and periodic class labels ($e.g.,$\npose/orientation estimation) in the context of deep learning. The commonly used\ncross-entropy or regression loss is not well matched to this problem as they\nignore the periodic nature of the labels and the class similarity, or assume\nlabels are continuous value. We propose to incorporate inter-class correlations\nin a Wasserstein training framework by pre-defining ($i.e.,$ using arc length\nof a circle) or adaptively learning the ground metric. We extend the ground\nmetric as a linear, convex or concave increasing function $w.r.t.$ arc length\nfrom an optimization perspective. We also propose to construct the conservative\ntarget labels which model the inlier and outlier noises using a wrapped\nunimodal-uniform mixture distribution. Unlike the one-hot setting, the\nconservative label makes the computation of Wasserstein distance more\nchallenging. We systematically conclude the practical closed-form solution of\nWasserstein distance for pose data with either one-hot or conservative target\nlabel. We evaluate our method on head, body, vehicle and 3D object pose\nbenchmarks with exhaustive ablation studies. The Wasserstein loss obtaining\nsuperior performance over the current methods, especially using convex mapping\nfunction for ground metric, conservative label, and closed-form solution.\n", "versions": [{"version": "v1", "created": "Sun, 3 Nov 2019 20:26:16 GMT"}], "update_date": "2019-11-05", "authors_parsed": [["Liu", "Xiaofeng", ""], ["Zou", "Yang", ""], ["Che", "Tong", ""], ["Ding", "Peng", ""], ["Jia", "Ping", ""], ["You", "Jane", ""], ["K", "Kumar B. V.", ""]]}, {"id": "1911.00969", "submitter": "Lin Shao", "authors": "Lin Shao, Toki Migimatsu and Jeannette Bohg", "title": "Learning to Scaffold the Development of Robotic Manipulation Skills", "comments": "Accepted to IEEE International Conference on Robotics and Automation\n  (ICRA) 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.AI cs.CV cs.LG cs.SY eess.SY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Learning contact-rich, robotic manipulation skills is a challenging problem\ndue to the high-dimensionality of the state and action space as well as\nuncertainty from noisy sensors and inaccurate motor control. To combat these\nfactors and achieve more robust manipulation, humans actively exploit contact\nconstraints in the environment. By adopting a similar strategy, robots can also\nachieve more robust manipulation. In this paper, we enable a robot to\nautonomously modify its environment and thereby discover how to ease\nmanipulation skill learning. Specifically, we provide the robot with fixtures\nthat it can freely place within the environment. These fixtures provide hard\nconstraints that limit the outcome of robot actions. Thereby, they funnel\nuncertainty from perception and motor control and scaffold manipulation skill\nlearning. We propose a learning system that consists of two learning loops. In\nthe outer loop, the robot positions the fixture in the workspace. In the inner\nloop, the robot learns a manipulation skill and after a fixed number of\nepisodes, returns the reward to the outer loop. Thereby, the robot is\nincentivised to place the fixture such that the inner loop quickly achieves a\nhigh reward. We demonstrate our framework both in simulation and in the real\nworld on three tasks: peg insertion, wrench manipulation and shallow-depth\ninsertion. We show that manipulation skill learning is dramatically sped up\nthrough this way of scaffolding.\n", "versions": [{"version": "v1", "created": "Sun, 3 Nov 2019 21:15:46 GMT"}, {"version": "v2", "created": "Thu, 3 Sep 2020 06:03:30 GMT"}, {"version": "v3", "created": "Mon, 5 Oct 2020 05:11:36 GMT"}], "update_date": "2020-10-06", "authors_parsed": [["Shao", "Lin", ""], ["Migimatsu", "Toki", ""], ["Bohg", "Jeannette", ""]]}, {"id": "1911.00972", "submitter": "Tian Li", "authors": "Tian Li, Zaoxing Liu, Vyas Sekar, Virginia Smith", "title": "Privacy for Free: Communication-Efficient Learning with Differential\n  Privacy Using Sketches", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Communication and privacy are two critical concerns in distributed learning.\nMany existing works treat these concerns separately. In this work, we argue\nthat a natural connection exists between methods for communication reduction\nand privacy preservation in the context of distributed machine learning. In\nparticular, we prove that Count Sketch, a simple method for data stream\nsummarization, has inherent differential privacy properties. Using these\nderived privacy guarantees, we propose a novel sketch-based framework\n(DiffSketch) for distributed learning, where we compress the transmitted\nmessages via sketches to simultaneously achieve communication efficiency and\nprovable privacy benefits. Our evaluation demonstrates that DiffSketch can\nprovide strong differential privacy guarantees (e.g., $\\varepsilon$= 1) and\nreduce communication by 20-50x with only marginal decreases in accuracy.\nCompared to baselines that treat privacy and communication separately,\nDiffSketch improves absolute test accuracy by 5%-50% while offering the same\nprivacy guarantees and communication compression.\n", "versions": [{"version": "v1", "created": "Sun, 3 Nov 2019 21:19:13 GMT"}, {"version": "v2", "created": "Fri, 6 Dec 2019 18:35:54 GMT"}], "update_date": "2019-12-09", "authors_parsed": [["Li", "Tian", ""], ["Liu", "Zaoxing", ""], ["Sekar", "Vyas", ""], ["Smith", "Virginia", ""]]}, {"id": "1911.00980", "submitter": "Yichong Xu", "authors": "Yichong Xu, Aparna Joshi, Aarti Singh, Artur Dubrawski", "title": "Zeroth Order Non-convex optimization with Dueling-Choice Bandits", "comments": "19 pages, 3 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider a novel setting of zeroth order non-convex optimization, where in\naddition to querying the function value at a given point, we can also duel two\npoints and get the point with the larger function value. We refer to this\nsetting as optimization with dueling-choice bandits since both direct queries\nand duels are available for optimization. We give the COMP-GP-UCB algorithm\nbased on GP-UCB (Srinivas et al., 2009), where instead of directly querying the\npoint with the maximum Upper Confidence Bound (UCB), we perform a constrained\noptimization and use comparisons to filter out suboptimal points. COMP-GP-UCB\ncomes with theoretical guarantee of $O(\\frac{\\Phi}{\\sqrt{T}})$ on simple regret\nwhere $T$ is the number of direct queries and $\\Phi$ is an improved information\ngain corresponding to a comparison based constraint set that restricts the\nsearch space for the optimum. In contrast, in the direct query only setting,\n$\\Phi$ depends on the entire domain. Finally, we present experimental results\nto show the efficacy of our algorithm.\n", "versions": [{"version": "v1", "created": "Sun, 3 Nov 2019 21:46:17 GMT"}], "update_date": "2019-11-05", "authors_parsed": [["Xu", "Yichong", ""], ["Joshi", "Aparna", ""], ["Singh", "Aarti", ""], ["Dubrawski", "Artur", ""]]}, {"id": "1911.00985", "submitter": "Karol Chlasta", "authors": "Karol Chlasta", "title": "Sentiment analysis model for Twitter data in Polish language", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.IR cs.LG cs.SI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Text mining analysis of tweets gathered during Polish presidential election\non May 10th, 2015. The project included implementation of engine to retrieve\ninformation from Twitter, building document corpora, corpora cleaning, and\ncreating Term-Document Matrix. Each tweet from the text corpora was assigned a\ncategory based on its sentiment score. The score was calculated using the\nnumber of positive and/or negative emoticons and Polish words in each document.\nThe result data set was used to train and test four machine learning\nclassifiers, to select these providing most accurate automatic tweet\nclassification results. The Naive Bayes and Maximum Entropy algorithms achieved\nthe best accuracy of respectively 71.76% and 77.32%. All implementation tasks\nwere completed using R programming language.\n", "versions": [{"version": "v1", "created": "Sun, 3 Nov 2019 22:06:03 GMT"}], "update_date": "2019-11-05", "authors_parsed": [["Chlasta", "Karol", ""]]}, {"id": "1911.00995", "submitter": "Nicholas James", "authors": "Nick James, Max Menzies, Lamiae Azizi, Jennifer Chan", "title": "Novel semi-metrics for multivariate change point analysis and anomaly\n  detection", "comments": "Accepted manuscript. Minor edits since v2. Equal contribution from\n  first two authors", "journal-ref": "Physica D: Nonlinear Phenomena 412 (2020) 132636", "doi": "10.1016/j.physd.2020.132636", "report-no": null, "categories": "cs.LG math.DS stat.CO stat.ME stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper proposes a new method for determining similarity and anomalies\nbetween time series, most practically effective in large collections of (likely\nrelated) time series, by measuring distances between structural breaks within\nsuch a collection. We introduce a class of \\emph{semi-metric} distance\nmeasures, which we term \\emph{MJ distances}. These semi-metrics provide an\nadvantage over existing options such as the Hausdorff and Wasserstein metrics.\nWe prove they have desirable properties, including better sensitivity to\noutliers, while experiments on simulated data demonstrate that they uncover\nsimilarity within collections of time series more effectively. Semi-metrics\ncarry a potential disadvantage: without the triangle inequality, they may not\nsatisfy a \"transitivity property of closeness.\" We analyse this failure with\nproof and introduce an computational method to investigate, in which we\ndemonstrate that our semi-metrics violate transitivity infrequently and mildly.\nFinally, we apply our methods to cryptocurrency and measles data, introducing a\njudicious application of eigenvalue analysis.\n", "versions": [{"version": "v1", "created": "Mon, 4 Nov 2019 00:04:30 GMT"}, {"version": "v2", "created": "Fri, 7 Feb 2020 14:58:46 GMT"}, {"version": "v3", "created": "Fri, 3 Jul 2020 10:44:42 GMT"}], "update_date": "2020-12-01", "authors_parsed": [["James", "Nick", ""], ["Menzies", "Max", ""], ["Azizi", "Lamiae", ""], ["Chan", "Jennifer", ""]]}, {"id": "1911.00996", "submitter": "Shigang Liu", "authors": "Shigang Liu, Jun Zhang, Yang Xiang, Wanlei Zhou, Dongxi Xiang", "title": "A Study of Data Pre-processing Techniques for Imbalanced Biomedical Data\n  Classification", "comments": "This paper is scheduled for inclusion in V16 N3 2020, International\n  Journal of Bioinformatics Research and Applications (IJBRA)", "journal-ref": "V16 N3, International Journal of Bioinformatics Research and\n  Applications (IJBRA), 2020", "doi": null, "report-no": null, "categories": "q-bio.QM cs.LG stat.ML", "license": "http://creativecommons.org/publicdomain/zero/1.0/", "abstract": "  Biomedical data are widely accepted in developing prediction models for\nidentifying a specific tumor, drug discovery and classification of human\ncancers. However, previous studies usually focused on different classifiers,\nand overlook the class imbalance problem in real-world biomedical datasets.\nThere are a lack of studies on evaluation of data pre-processing techniques,\nsuch as resampling and feature selection, on imbalanced biomedical data\nlearning. The relationship between data pre-processing techniques and the data\ndistributions has never been analysed in previous studies. This article mainly\nfocuses on reviewing and evaluating some popular and recently developed\nresampling and feature selection methods for class imbalance learning. We\nanalyse the effectiveness of each technique from data distribution perspective.\nExtensive experiments have been done based on five classifiers, four\nperformance measures, eight learning techniques across twenty real-world\ndatasets. Experimental results show that: (1) resampling and feature selection\ntechniques exhibit better performance using support vector machine (SVM)\nclassifier. However, resampling and Feature Selection techniques perform poorly\nwhen using C4.5 decision tree and Linear discriminant analysis classifiers; (2)\nfor datasets with different distributions, techniques such as Random\nundersampling and Feature Selection perform better than other data\npre-processing methods with T Location-Scale distribution when using SVM and\nKNN (K-nearest neighbours) classifiers. Random oversampling outperforms other\nmethods on Negative Binomial distribution using Random Forest classifier with\nlower level of imbalance ratio; (3) Feature Selection outperforms other data\npre-processing methods in most cases, thus, Feature Selection with SVM\nclassifier is the best choice for imbalanced biomedical data learning.\n", "versions": [{"version": "v1", "created": "Mon, 4 Nov 2019 00:32:32 GMT"}], "update_date": "2019-11-05", "authors_parsed": [["Liu", "Shigang", ""], ["Zhang", "Jun", ""], ["Xiang", "Yang", ""], ["Zhou", "Wanlei", ""], ["Xiang", "Dongxi", ""]]}, {"id": "1911.00997", "submitter": "Yichuan Charlie Tang", "authors": "Yichuan Charlie Tang, Ruslan Salakhutdinov", "title": "Multiple Futures Prediction", "comments": "In proceedings of NeurIPS 2019, Vancouver, British Columbia, Canada", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV cs.MA cs.RO stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Temporal prediction is critical for making intelligent and robust decisions\nin complex dynamic environments. Motion prediction needs to model the\ninherently uncertain future which often contains multiple potential outcomes,\ndue to multi-agent interactions and the latent goals of others. Towards these\ngoals, we introduce a probabilistic framework that efficiently learns latent\nvariables to jointly model the multi-step future motions of agents in a scene.\nOur framework is data-driven and learns semantically meaningful latent\nvariables to represent the multimodal future, without requiring explicit\nlabels. Using a dynamic attention-based state encoder, we learn to encode the\npast as well as the future interactions among agents, efficiently scaling to\nany number of agents. Finally, our model can be used for planning via computing\na conditional probability density over the trajectories of other agents given a\nhypothetical rollout of the 'self' agent. We demonstrate our algorithms by\npredicting vehicle trajectories of both simulated and real data, demonstrating\nthe state-of-the-art results on several vehicle trajectory datasets.\n", "versions": [{"version": "v1", "created": "Mon, 4 Nov 2019 00:42:01 GMT"}, {"version": "v2", "created": "Fri, 6 Dec 2019 23:36:01 GMT"}], "update_date": "2019-12-10", "authors_parsed": [["Tang", "Yichuan Charlie", ""], ["Salakhutdinov", "Ruslan", ""]]}, {"id": "1911.01004", "submitter": "Raed Al Kontar", "authors": "Xubo Yue, Raed Al Kontar", "title": "Why Non-myopic Bayesian Optimization is Promising and How Far Should We\n  Look-ahead? A Study via Rollout", "comments": "12 pages, 1 figure Accepted by AISTATS 2020", "journal-ref": "Artificial Intelligence and Statistics (AISTATS) 2020", "doi": null, "report-no": null, "categories": "cs.LG math.OC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Lookahead, also known as non-myopic, Bayesian optimization (BO) aims to find\noptimal sampling policies through solving a dynamic programming (DP)\nformulation that maximizes a long-term reward over a rolling horizon. Though\npromising, lookahead BO faces the risk of error propagation through its\nincreased dependence on a possibly mis-specified model. In this work we focus\non the rollout approximation for solving the intractable DP. We first prove the\nimproving nature of rollout in tackling lookahead BO and provide a sufficient\ncondition for the used heuristic to be rollout improving. We then provide both\na theoretical and practical guideline to decide on the rolling horizon\nstagewise. This guideline is built on quantifying the negative effect of a\nmis-specified model. To illustrate our idea, we provide case studies on both\nsingle and multi-information source BO. Empirical results show the advantageous\nproperties of our method over several myopic and non-myopic BO algorithms.\n", "versions": [{"version": "v1", "created": "Mon, 4 Nov 2019 01:57:40 GMT"}, {"version": "v2", "created": "Tue, 21 Jan 2020 03:02:43 GMT"}], "update_date": "2020-01-22", "authors_parsed": [["Yue", "Xubo", ""], ["Kontar", "Raed Al", ""]]}, {"id": "1911.01005", "submitter": "Fan Yang", "authors": "Fan Yang, Zijian Zhang, Haofan Wang, Yuening Li, Xia Hu", "title": "XDeep: An Interpretation Tool for Deep Neural Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  XDeep is an open-source Python package developed to interpret deep models for\nboth practitioners and researchers. Overall, XDeep takes a trained deep neural\nnetwork (DNN) as the input, and generates relevant interpretations as the\noutput with the post-hoc manner. From the functionality perspective, XDeep\nintegrates a wide range of interpretation algorithms from the\nstate-of-the-arts, covering different types of methodologies, and is capable of\nproviding both local explanation and global explanation for DNN when\ninterpreting model behaviours. With the well-documented API designed in XDeep,\nend-users can easily obtain the interpretations for their deep models at hand\nwith several lines of codes, and compare the results among different\nalgorithms. XDeep is generally compatible with Python 3, and can be installed\nthrough Python Package Index (PyPI). The source codes are available at:\nhttps://github.com/datamllab/xdeep.\n", "versions": [{"version": "v1", "created": "Mon, 4 Nov 2019 01:59:41 GMT"}], "update_date": "2019-11-05", "authors_parsed": [["Yang", "Fan", ""], ["Zhang", "Zijian", ""], ["Wang", "Haofan", ""], ["Li", "Yuening", ""], ["Hu", "Xia", ""]]}, {"id": "1911.01010", "submitter": "Enzo Busseti", "authors": "Enzo Busseti", "title": "Seasonally-Adjusted Auto-Regression of Vector Time Series", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG math.OC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a simple algorithm to forecast vector time series, that is robust\nagainst missing data, in both training and inference. It models seasonal\nannual, weekly, and daily baselines, and a Gaussian process for the\nseasonally-adjusted residuals. We develop a custom truncated eigendecomposition\nto fit a low-rank plus block-diagonal Gaussian kernel. Inference is performed\nwith the Schur complement, using Tikhonov regularization to prevent overfit,\nand the Woodbury formula to invert sub-matrices of the kernel efficiently.\nInference requires an amount of memory and computation linear in the dimension\nof the time series, and so the model can scale to very large datasets. We also\npropose a simple \"greedy\" grid search for automatic hyper-parameter tuning. The\npaper is accompanied by tsar (i.e., time series auto-regressor), a Python\nlibrary that implements the algorithm.\n", "versions": [{"version": "v1", "created": "Mon, 4 Nov 2019 02:28:50 GMT"}], "update_date": "2019-11-05", "authors_parsed": [["Busseti", "Enzo", ""]]}, {"id": "1911.01014", "submitter": "Muhammad Afzal", "authors": "Muhammad Afzal, S.M. Riazul Islam, Maqbool Hussain, and Sungyoung Lee", "title": "Precision Medicine Informatics: Principles, Prospects, and Challenges", "comments": "22 pages, 8 figures, 5 tables, journal paper", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Precision Medicine (PM) is an emerging approach that appears with the\nimpression of changing the existing paradigm of medical practice. Recent\nadvances in technological innovations and genetics, and the growing\navailability of health data have set a new pace of the research and imposes a\nset of new requirements on different stakeholders. To date, some studies are\navailable that discuss about different aspects of PM. Nevertheless, a holistic\nrepresentation of those aspects deemed to confer the technological perspective,\nin relation to applications and challenges, is mostly ignored. In this context,\nthis paper surveys advances in PM from informatics viewpoint and reviews the\nenabling tools and techniques in a categorized manner. In addition, the study\ndiscusses how other technological paradigms including big data, artificial\nintelligence, and internet of things can be exploited to advance the potentials\nof PM. Furthermore, the paper provides some guidelines for future research for\nseamless implementation and wide-scale deployment of PM based on identified\nopen issues and associated challenges. To this end, the paper proposes an\nintegrated holistic framework for PM motivating informatics researchers to\ndesign their relevant research works in an appropriate context.\n", "versions": [{"version": "v1", "created": "Mon, 4 Nov 2019 02:40:00 GMT"}], "update_date": "2019-11-05", "authors_parsed": [["Afzal", "Muhammad", ""], ["Islam", "S. M. Riazul", ""], ["Hussain", "Maqbool", ""], ["Lee", "Sungyoung", ""]]}, {"id": "1911.01024", "submitter": "Shen Zhang", "authors": "Shen Zhang, Shibo Zhang, Sufei Li, Liang Du, and Thomas G. Habetler", "title": "Visualization of Multi-Objective Switched Reluctance Machine\n  Optimization at Multiple Operating Conditions with t-SNE", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.SY eess.SY stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The optimization of electric machines at multiple operating points is crucial\nfor applications that require frequent changes on speeds and loads, such as the\nelectric vehicles, to strive for the machine optimal performance across the\nentire driving cycle. However, the number of objectives that would need to be\noptimized would significantly increase with the number of operating points\nconsidered in the optimization, thus posting a potential problem in regards to\nthe visualization techniques currently in use, such as in the scatter plots of\nPareto fronts, the parallel coordinates, and in the principal component\nanalysis (PCA), inhibiting their ability to provide machine designers with\nintuitive and informative visualizations of all of the design candidates and\ntheir ability to pick a few for further fine-tuning with performance\nverification. Therefore, this paper proposes the utilization of t-distributed\nstochastic neighbor embedding (t-SNE) to visualize all of the optimization\nobjectives of various electric machines design candidates with various\noperating conditions, which constitute a high-dimensional set of data that\nwould lie on several different, but related, low-dimensional manifolds.\nFinally, two case studies of switched reluctance machines (SRM) are presented\nto illustrate the superiority of then t-SNE when compared to traditional\nvisualization techniques used in electric machine optimizations.\n", "versions": [{"version": "v1", "created": "Mon, 4 Nov 2019 04:12:31 GMT"}], "update_date": "2019-11-05", "authors_parsed": [["Zhang", "Shen", ""], ["Zhang", "Shibo", ""], ["Li", "Sufei", ""], ["Du", "Liang", ""], ["Habetler", "Thomas G.", ""]]}, {"id": "1911.01026", "submitter": "Jeremy Wohlwend", "authors": "Jeremy Wohlwend, Ethan R. Elenberg, Samuel Altschul, Shawn Henry, Tao\n  Lei", "title": "Metric Learning for Dynamic Text Classification", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CL cs.IR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Traditional text classifiers are limited to predicting over a fixed set of\nlabels. However, in many real-world applications the label set is frequently\nchanging. For example, in intent classification, new intents may be added over\ntime while others are removed. We propose to address the problem of dynamic\ntext classification by replacing the traditional, fixed-size output layer with\na learned, semantically meaningful metric space. Here the distances between\ntextual inputs are optimized to perform nearest-neighbor classification across\noverlapping label sets. Changing the label set does not involve removing\nparameters, but rather simply adding or removing support points in the metric\nspace. Then the learned metric can be fine-tuned with only a few additional\ntraining examples. We demonstrate that this simple strategy is robust to\nchanges in the label space. Furthermore, our results show that learning a\nnon-Euclidean metric can improve performance in the low data regime, suggesting\nthat further work on metric spaces may benefit low-resource research.\n", "versions": [{"version": "v1", "created": "Mon, 4 Nov 2019 04:27:29 GMT"}], "update_date": "2019-11-05", "authors_parsed": [["Wohlwend", "Jeremy", ""], ["Elenberg", "Ethan R.", ""], ["Altschul", "Samuel", ""], ["Henry", "Shawn", ""], ["Lei", "Tao", ""]]}, {"id": "1911.01028", "submitter": "Dibakar Gope", "authors": "Dibakar Gope, Jesse Beu, Urmish Thakker, Matthew Mattina", "title": "Ternary MobileNets via Per-Layer Hybrid Filter Banks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  MobileNets family of computer vision neural networks have fueled tremendous\nprogress in the design and organization of resource-efficient architectures in\nrecent years. New applications with stringent real-time requirements on highly\nconstrained devices require further compression of MobileNets-like already\ncompute-efficient networks. Model quantization is a widely used technique to\ncompress and accelerate neural network inference and prior works have quantized\nMobileNets to 4-6 bits albeit with a modest to significant drop in accuracy.\nWhile quantization to sub-byte values (i.e. precision less than or equal to 8\nbits) has been valuable, even further quantization of MobileNets to binary or\nternary values is necessary to realize significant energy savings and possibly\nruntime speedups on specialized hardware, such as ASICs and FPGAs. Under the\nkey observation that convolutional filters at each layer of a deep neural\nnetwork may respond differently to ternary quantization, we propose a novel\nquantization method that generates per-layer hybrid filter banks consisting of\nfull-precision and ternary weight filters for MobileNets. The layer-wise hybrid\nfilter banks essentially combine the strengths of full-precision and ternary\nweight filters to derive a compact, energy-efficient architecture for\nMobileNets. Using this proposed quantization method, we quantized a substantial\nportion of weight filters of MobileNets to ternary values resulting in 27.98%\nsavings in energy, and a 51.07% reduction in the model size, while achieving\ncomparable accuracy and no degradation in throughput on specialized hardware in\ncomparison to the baseline full-precision MobileNets.\n", "versions": [{"version": "v1", "created": "Mon, 4 Nov 2019 04:32:59 GMT"}], "update_date": "2019-11-05", "authors_parsed": [["Gope", "Dibakar", ""], ["Beu", "Jesse", ""], ["Thakker", "Urmish", ""], ["Mattina", "Matthew", ""]]}, {"id": "1911.01030", "submitter": "Caihua Shan", "authors": "Caihua Shan, Nikos Mamoulis, Reynold Cheng, Guoliang Li, Xiang Li and\n  Yuqiu Qian", "title": "An End-to-End Deep RL Framework for Task Arrangement in Crowdsourcing\n  Platforms", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.DB stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we propose a Deep Reinforcement Learning (RL) framework for\ntask arrangement, which is a critical problem for the success of crowdsourcing\nplatforms. Previous works conduct the personalized recommendation of tasks to\nworkers via supervised learning methods. However, the majority of them only\nconsider the benefit of either workers or requesters independently. In\naddition, they cannot handle the dynamic environment and may produce\nsub-optimal results. To address these issues, we utilize Deep Q-Network (DQN),\nan RL-based method combined with a neural network to estimate the expected\nlong-term return of recommending a task. DQN inherently considers the immediate\nand future reward simultaneously and can be updated in real-time to deal with\nevolving data and dynamic changes. Furthermore, we design two DQNs that capture\nthe benefit of both workers and requesters and maximize the profit of the\nplatform. To learn value functions in DQN effectively, we also propose novel\nstate representations, carefully design the computation of Q values, and\npredict transition probabilities and future states. Experiments on synthetic\nand real datasets demonstrate the superior performance of our framework.\n", "versions": [{"version": "v1", "created": "Mon, 4 Nov 2019 04:53:11 GMT"}], "update_date": "2019-11-05", "authors_parsed": [["Shan", "Caihua", ""], ["Mamoulis", "Nikos", ""], ["Cheng", "Reynold", ""], ["Li", "Guoliang", ""], ["Li", "Xiang", ""], ["Qian", "Yuqiu", ""]]}, {"id": "1911.01032", "submitter": "Sayak Ray Chowdhury", "authors": "Sayak Ray Chowdhury, Aditya Gopalan", "title": "On Batch Bayesian Optimization", "comments": "All of Bayesian Nonparametrics workshop, Neural Information\n  Processing Systems, 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present two algorithms for Bayesian optimization in the batch feedback\nsetting, based on Gaussian process upper confidence bound and Thompson sampling\napproaches, along with frequentist regret guarantees and numerical results.\n", "versions": [{"version": "v1", "created": "Mon, 4 Nov 2019 05:04:21 GMT"}], "update_date": "2019-11-05", "authors_parsed": [["Chowdhury", "Sayak Ray", ""], ["Gopalan", "Aditya", ""]]}, {"id": "1911.01040", "submitter": "Adel Javanmard", "authors": "Yash Deshpande, Adel Javanmard, Mohammad Mehrabi", "title": "Online Debiasing for Adaptively Collected High-dimensional Data with\n  Applications to Time Series Analysis", "comments": "66 pages, 2 tables, 11 figures; updated with minor fixes and\n  reorganization", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ME cs.LG math.ST stat.ML stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Adaptive collection of data is commonplace in applications throughout science\nand engineering. From the point of view of statistical inference however,\nadaptive data collection induces memory and correlation in the samples, and\nposes significant challenge. We consider the high-dimensional linear\nregression, where the samples are collected adaptively, and the sample size $n$\ncan be smaller than $p$, the number of covariates. In this setting, there are\ntwo distinct sources of bias: the first due to regularization imposed for\nconsistent estimation, e.g. using the LASSO, and the second due to adaptivity\nin collecting the samples. We propose \"online debiasing\", a general procedure\nfor estimators such as the LASSO, which addresses both sources of bias. In two\nconcrete contexts $(i)$ time series analysis and $(ii)$ batched data\ncollection, we demonstrate that online debiasing optimally debiases the LASSO\nestimate when the underlying parameter $\\theta_0$ has sparsity of order\n$o(\\sqrt{n}/\\log p)$. In this regime, the debiased estimator can be used to\ncompute $p$-values and confidence intervals of optimal size.\n", "versions": [{"version": "v1", "created": "Mon, 4 Nov 2019 06:03:58 GMT"}, {"version": "v2", "created": "Wed, 18 Dec 2019 17:41:44 GMT"}, {"version": "v3", "created": "Tue, 5 May 2020 19:39:33 GMT"}], "update_date": "2020-05-07", "authors_parsed": [["Deshpande", "Yash", ""], ["Javanmard", "Adel", ""], ["Mehrabi", "Mohammad", ""]]}, {"id": "1911.01042", "submitter": "Caihua Shan", "authors": "Caihua Shan, Leong Hou U, Nikos Mamoulis, Reynold Cheng, and Xiang Li", "title": "A General Early-Stopping Module for Crowdsourced Ranking", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DB cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Crowdsourcing can be used to determine a total order for an object set (e.g.,\nthe top-10 NBA players) based on crowd opinions. This ranking problem is often\ndecomposed into a set of microtasks (e.g., pairwise comparisons). These\nmicrotasks are passed to a large number of workers and their answers are\naggregated to infer the ranking. The number of microtasks depends on the budget\nallocated for the problem. Intuitively, the higher the number of microtask\nanswers, the more accurate the ranking becomes. However, it is often hard to\ndecide the budget required for an accurate ranking. We study how a ranking\nprocess can be terminated early, and yet achieve a high-quality ranking and\ngreat savings in the budget. We use statistical tools to estimate the quality\nof the ranking result at any stage of the crowdsourcing process and terminate\nthe process as soon as the desired quality is achieved. Our proposed\nearly-stopping module can be seamlessly integrated with most existing inference\nalgorithms and task assignment methods. We conduct extensive experiments and\nshow that our early-stopping module is better than other existing general\nstopping criteria. We also implement a prototype system to demonstrate the\nusability and effectiveness of our approach in practice.\n", "versions": [{"version": "v1", "created": "Mon, 4 Nov 2019 06:15:52 GMT"}], "update_date": "2019-11-05", "authors_parsed": [["Shan", "Caihua", ""], ["U", "Leong Hou", ""], ["Mamoulis", "Nikos", ""], ["Cheng", "Reynold", ""], ["Li", "Xiang", ""]]}, {"id": "1911.01043", "submitter": "Kamil Nar", "authors": "Kamil Nar, S. Shankar Sastry", "title": "Persistency of Excitation for Robustness of Neural Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  When an online learning algorithm is used to estimate the unknown parameters\nof a model, the signals interacting with the parameter estimates should not\ndecay too quickly for the optimal values to be discovered correctly. This\nrequirement is referred to as persistency of excitation, and it arises in\nvarious contexts, such as optimization with stochastic gradient methods,\nexploration for multi-armed bandits, and adaptive control of dynamical systems.\nWhile training a neural network, the iterative optimization algorithm involved\nalso creates an online learning problem, and consequently, correct estimation\nof the optimal parameters requires persistent excitation of the network\nweights. In this work, we analyze the dynamics of the gradient descent\nalgorithm while training a two-layer neural network with two different loss\nfunctions, the squared-error loss and the cross-entropy loss; and we obtain\nconditions to guarantee persistent excitation of the network weights. We then\nshow that these conditions are difficult to satisfy when a multi-layer network\nis trained for a classification task, for the signals in the intermediate\nlayers of the network become low-dimensional during training and fail to remain\npersistently exciting. To provide a remedy, we delve into the classical\nregularization terms used for linear models, reinterpret them as a means to\nensure persistent excitation of the model parameters, and propose an algorithm\nfor neural networks by building an analogy. The results in this work shed some\nlight on why adversarial examples have become a challenging problem for neural\nnetworks, why merely augmenting training data sets will not be an effective\napproach to address them, and why there may not exist a data-independent\nregularization term for neural networks, which involve only the model\nparameters but not the training data.\n", "versions": [{"version": "v1", "created": "Mon, 4 Nov 2019 06:17:35 GMT"}], "update_date": "2019-11-05", "authors_parsed": [["Nar", "Kamil", ""], ["Sastry", "S. Shankar", ""]]}, {"id": "1911.01046", "submitter": "Shashi Raj Pandey", "authors": "Shashi Raj Pandey, Nguyen H. Tran, Mehdi Bennis, Yan Kyaw Tun, Aunas\n  Manzoor, and Choong Seon Hong", "title": "A Crowdsourcing Framework for On-Device Federated Learning", "comments": "Accepted in IEEE Transactions on Wireless Communications", "journal-ref": null, "doi": "10.1109/TWC.2020.2971981", "report-no": null, "categories": "cs.LG cs.GT cs.NI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Federated learning (FL) rests on the notion of training a global model in a\ndecentralized manner. Under this setting, mobile devices perform computations\non their local data before uploading the required updates to improve the global\nmodel. However, when the participating clients implement an uncoordinated\ncomputation strategy, the difficulty is to handle the communication efficiency\n(i.e., the number of communications per iteration) while exchanging the model\nparameters during aggregation. Therefore, a key challenge in FL is how users\nparticipate to build a high-quality global model with communication efficiency.\nWe tackle this issue by formulating a utility maximization problem, and propose\na novel crowdsourcing framework to leverage FL that considers the communication\nefficiency during parameters exchange. First, we show an incentive-based\ninteraction between the crowdsourcing platform and the participating client's\nindependent strategies for training a global learning model, where each side\nmaximizes its own benefit. We formulate a two-stage Stackelberg game to analyze\nsuch scenario and find the game's equilibria. Second, we formalize an admission\ncontrol scheme for participating clients to ensure a level of local accuracy.\nSimulated results demonstrate the efficacy of our proposed solution with up to\n22% gain in the offered reward.\n", "versions": [{"version": "v1", "created": "Mon, 4 Nov 2019 06:41:37 GMT"}, {"version": "v2", "created": "Mon, 3 Feb 2020 04:06:40 GMT"}], "update_date": "2020-05-07", "authors_parsed": [["Pandey", "Shashi Raj", ""], ["Tran", "Nguyen H.", ""], ["Bennis", "Mehdi", ""], ["Tun", "Yan Kyaw", ""], ["Manzoor", "Aunas", ""], ["Hong", "Choong Seon", ""]]}, {"id": "1911.01054", "submitter": "Arindam Das", "authors": "Arindam Das", "title": "SoildNet: Soiling Degradation Detection in Autonomous Driving", "comments": "Accepted at the NeurIPS 2019 Workshop on Machine Learning for\n  Autonomous Driving", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG cs.RO eess.IV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In the field of autonomous driving, camera sensors are extremely prone to\nsoiling because they are located outside of the car and interact with\nenvironmental sources of soiling such as rain drops, snow, dust, sand, mud and\nso on. This can lead to either partial or complete vision degradation. Hence\ndetecting such decay in vision is very important for safety and overall to\npreserve the functionality of the \"autonomous\" components in autonomous\ndriving. The contribution of this work involves: 1) Designing a Deep\nConvolutional Neural Network (DCNN) based baseline network, 2) Exploiting\nseveral network remodelling techniques such as employing static and dynamic\ngroup convolution, channel reordering to compress the baseline architecture and\nmake it suitable for low power embedded systems with nearly 1 TOPS, 3)\nComparing various result metrics of all interim networks dedicated for soiling\ndegradation detection at tile level of size 64 x 64 on input resolution 1280 x\n768. The compressed network, is called SoildNet (Sand, snOw, raIn/dIrt, oiL,\nDust/muD) that uses only 9.72% trainable parameters of the base network and\nreduces the model size by more than 7 times with no loss in accuracy\n", "versions": [{"version": "v1", "created": "Mon, 4 Nov 2019 07:13:26 GMT"}, {"version": "v2", "created": "Thu, 21 Nov 2019 03:56:41 GMT"}], "update_date": "2019-11-22", "authors_parsed": [["Das", "Arindam", ""]]}, {"id": "1911.01058", "submitter": "Sheng Shi", "authors": "Sheng Shi, Xinfeng Zhang and Wei Fan", "title": "Explaining the Predictions of Any Image Classifier via Decision Trees", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Despite outstanding contribution to the significant progress of Artificial\nIntelligence (AI), deep learning models remain mostly black boxes, which are\nextremely weak in explainability of the reasoning process and prediction\nresults. Explainability is not only a gateway between AI and society but also a\npowerful tool to detect flaws in the model and biases in the data. Local\nInterpretable Model-agnostic Explanation (LIME) is a recent approach that uses\nan interpretable model to form a local explanation for the individual\nprediction result. The current implementation of LIME adopts the linear\nregression as its interpretable function. However, being so restricted and\nusually over-simplifying the relationships, linear models fail in situations\nwhere nonlinear associations and interactions exist among features and\nprediction results. This paper implements a decision Tree-based LIME approach,\nwhich uses a decision tree model to form an interpretable representation that\nis locally faithful to the original model. Tree-LIME approach can capture\nnonlinear interactions among features in the data and creates plausible\nexplanations. Various experiments show that the Tree-LIME explanation of\nmultiple black-box models can achieve more reliable performance in terms of\nunderstandability, fidelity, and efficiency.\n", "versions": [{"version": "v1", "created": "Mon, 4 Nov 2019 07:31:30 GMT"}, {"version": "v2", "created": "Mon, 10 Feb 2020 01:20:25 GMT"}], "update_date": "2020-02-11", "authors_parsed": [["Shi", "Sheng", ""], ["Zhang", "Xinfeng", ""], ["Fan", "Wei", ""]]}, {"id": "1911.01067", "submitter": "Yunzong Xu", "authors": "David Simchi-Levi, Yunzong Xu, Jinglong Zhao", "title": "Blind Network Revenue Management and Bandits with Knapsacks under\n  Limited Switches", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.GT math.OC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Our work is motivated by a common business constraint in online markets.\nWhile firms respect the advantages of dynamic pricing and price\nexperimentation, they must limit the number of price changes (i.e., switches)\nto be within some budget due to various practical reasons. We study both the\nclassical price-based network revenue management problem in the\ndistributionally-unknown setup, and the bandits with knapsacks problem. In\nthese problems, a decision-maker (without prior knowledge of the environment)\nhas finite initial inventory of multiple resources to allocate over a finite\ntime horizon. Beyond the classical resource constraints, we introduce an\nadditional switching constraint to these problems, which restricts the total\nnumber of times that the decision-maker makes switches between actions to be\nwithin a fixed switching budget. For such problems, we show matching upper and\nlower bounds on the optimal regret, and propose computationally-efficient\nlimited-switch algorithms that achieve the optimal regret. Our work reveals a\nsurprising result: the optimal regret rate is completely characterized by a\npiecewise-constant function of the switching budget, which further depends on\nthe number of resource constraints -- to the best of our knowledge, this is the\nfirst time the number of resources constraints is shown to play a fundamental\nrole in determining the statistical complexity of online learning problems. We\nconduct computational experiments to examine the performance of our algorithms\non a numerical setup that is widely used in the literature. Compared with\nbenchmark algorithms from the literature, our proposed algorithms achieve\npromising performance with clear advantages on the number of incurred switches.\nPractically, firms can benefit from our study and improve their learning and\ndecision-making performance when they simultaneously face resource and\nswitching constraints.\n", "versions": [{"version": "v1", "created": "Mon, 4 Nov 2019 07:58:37 GMT"}, {"version": "v2", "created": "Mon, 18 Nov 2019 00:59:19 GMT"}, {"version": "v3", "created": "Thu, 13 Feb 2020 18:14:13 GMT"}, {"version": "v4", "created": "Tue, 1 Dec 2020 22:19:19 GMT"}], "update_date": "2020-12-03", "authors_parsed": [["Simchi-Levi", "David", ""], ["Xu", "Yunzong", ""], ["Zhao", "Jinglong", ""]]}, {"id": "1911.01071", "submitter": "Dino Ienco", "authors": "Dino Ienco, Roberto Interdonato and Raffaele Gaetano", "title": "Supervised level-wise pretraining for recurrent neural network\n  initialization in multi-class classification", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recurrent Neural Networks (RNNs) can be seriously impacted by the initial\nparameters assignment, which may result in poor generalization performances on\nnew unseen data. With the objective to tackle this crucial issue, in the\ncontext of RNN based classification, we propose a new supervised layer-wise\npretraining strategy to initialize network parameters. The proposed approach\nleverages a data-aware strategy that sets up a taxonomy of classification\nproblems automatically derived by the model behavior. To the best of our\nknowledge, despite the great interest in RNN-based classification, this is the\nfirst data-aware strategy dealing with the initialization of such models. The\nproposed strategy has been tested on four benchmarks coming from two different\ndomains, i.e., Speech Recognition and Remote Sensing. Results underline the\nsignificance of our approach and point out that data-aware strategies\npositively support the initialization of Recurrent Neural Network based\nclassification models.\n", "versions": [{"version": "v1", "created": "Mon, 4 Nov 2019 08:30:01 GMT"}], "update_date": "2019-11-05", "authors_parsed": [["Ienco", "Dino", ""], ["Interdonato", "Roberto", ""], ["Gaetano", "Raffaele", ""]]}, {"id": "1911.01103", "submitter": "Stephen James", "authors": "Alessandro Bonardi, Stephen James, Andrew J. Davison", "title": "Learning One-Shot Imitation from Humans without Humans", "comments": "Videos can be found here:\n  https://sites.google.com/view/tecnets-humans", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.AI cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Humans can naturally learn to execute a new task by seeing it performed by\nother individuals once, and then reproduce it in a variety of configurations.\nEndowing robots with this ability of imitating humans from third person is a\nvery immediate and natural way of teaching new tasks. Only recently, through\nmeta-learning, there have been successful attempts to one-shot imitation\nlearning from humans; however, these approaches require a lot of human\nresources to collect the data in the real world to train the robot. But is\nthere a way to remove the need for real world human demonstrations during\ntraining? We show that with Task-Embedded Control Networks, we can infer\ncontrol polices by embedding human demonstrations that can condition a control\npolicy and achieve one-shot imitation learning. Importantly, we do not use a\nreal human arm to supply demonstrations during training, but instead leverage\ndomain randomisation in an application that has not been seen before:\nsim-to-real transfer on humans. Upon evaluating our approach on pushing and\nplacing tasks in both simulation and in the real world, we show that in\ncomparison to a system that was trained on real-world data we are able to\nachieve similar results by utilising only simulation data.\n", "versions": [{"version": "v1", "created": "Mon, 4 Nov 2019 10:07:27 GMT"}], "update_date": "2019-11-05", "authors_parsed": [["Bonardi", "Alessandro", ""], ["James", "Stephen", ""], ["Davison", "Andrew J.", ""]]}, {"id": "1911.01138", "submitter": "Karttikeya Mangalam", "authors": "Karttikeya Mangalam, Ehsan Adeli, Kuan-Hui Lee, Adrien Gaidon, Juan\n  Carlos Niebles", "title": "Disentangling Human Dynamics for Pedestrian Locomotion Forecasting with\n  Noisy Supervision", "comments": "Accepted to WACV 2020 (Oral)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG cs.RO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We tackle the problem of Human Locomotion Forecasting, a task for jointly\npredicting the spatial positions of several keypoints on the human body in the\nnear future under an egocentric setting. In contrast to the previous work that\naims to solve either the task of pose prediction or trajectory forecasting in\nisolation, we propose a framework to unify the two problems and address the\npractically useful task of pedestrian locomotion prediction in the wild. Among\nthe major challenges in solving this task is the scarcity of annotated\negocentric video datasets with dense annotations for pose, depth, or egomotion.\nTo surmount this difficulty, we use state-of-the-art models to generate (noisy)\nannotations and propose robust forecasting models that can learn from this\nnoisy supervision. We present a method to disentangle the overall pedestrian\nmotion into easier to learn subparts by utilizing a pose completion and a\ndecomposition module. The completion module fills in the missing key-point\nannotations and the decomposition module breaks the cleaned locomotion down to\nglobal (trajectory) and local (pose keypoint movements). Further, with Quasi\nRNN as our backbone, we propose a novel hierarchical trajectory forecasting\nnetwork that utilizes low-level vision domain specific signals like egomotion\nand depth to predict the global trajectory. Our method leads to\nstate-of-the-art results for the prediction of human locomotion in the\negocentric view. Project pade: https://karttikeya.github.io/publication/plf/\n", "versions": [{"version": "v1", "created": "Mon, 4 Nov 2019 11:30:12 GMT"}, {"version": "v2", "created": "Mon, 13 Apr 2020 19:33:42 GMT"}], "update_date": "2020-04-15", "authors_parsed": [["Mangalam", "Karttikeya", ""], ["Adeli", "Ehsan", ""], ["Lee", "Kuan-Hui", ""], ["Gaidon", "Adrien", ""], ["Niebles", "Juan Carlos", ""]]}, {"id": "1911.01141", "submitter": "Leendert Remmelzwaal", "authors": "Leendert A Remmelzwaal, Amit Mishra, George F R Ellis", "title": "Human eye inspired log-polar pre-processing for neural networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.LG", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  In this paper we draw inspiration from the human visual system, and present a\nbio-inspired pre-processing stage for neural networks. We implement this by\napplying a log-polar transformation as a pre-processing step, and to\ndemonstrate, we have used a naive convolutional neural network (CNN). We\ndemonstrate that a bio-inspired pre-processing stage can achieve rotation and\nscale robustness in CNNs. A key point in this paper is that the CNN does not\nneed to be trained to identify rotation or scaling permutations; rather it is\nthe log-polar pre-processing step that converts the image into a format that\nallows the CNN to handle rotation and scaling permutations. In addition we\ndemonstrate how adding a log-polar transformation as a pre-processing step can\nreduce the image size to ~20\\% of the Euclidean image size, without\nsignificantly compromising classification accuracy of the CNN. The\npre-processing stage presented in this paper is modelled after the retina and\ntherefore is only tested against an image dataset. Note: This paper has been\nsubmitted for SAUPEC/RobMech/PRASA 2020.\n", "versions": [{"version": "v1", "created": "Mon, 4 Nov 2019 11:45:13 GMT"}], "update_date": "2019-11-05", "authors_parsed": [["Remmelzwaal", "Leendert A", ""], ["Mishra", "Amit", ""], ["Ellis", "George F R", ""]]}, {"id": "1911.01143", "submitter": "Yoshihiko Susuki", "authors": "Akitoshi Masuda, Yoshihiko Susuki, Manel Mart\\'inez-Ram\\'on, Andrea\n  Mammoli, Atsushi Ishigame", "title": "Application of Gaussian Process Regression to Koopman Mode Decomposition\n  for Noisy Dynamic Data", "comments": "7 pages, 6 figures, 2019 Japan Joint Automatic Control Conference", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.SP cs.LG math.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Koopman Mode Decomposition (KMD) is a technique of nonlinear time-series\nanalysis that originates from point spectrum of the Koopman operator defined\nfor an underlying nonlinear dynamical system. We present a numerical algorithm\nof KMD based on Gaussian process regression that is capable of handling noisy\nfinite-time data. The algorithm is applied to short-term swing dynamics of a\nmulti-machine power grid in order to estimate oscillatory modes embedded in the\ndynamics, and thereby the effectiveness of the algorithm is evaluated.\n", "versions": [{"version": "v1", "created": "Mon, 4 Nov 2019 11:46:34 GMT"}, {"version": "v2", "created": "Thu, 14 Nov 2019 23:24:55 GMT"}], "update_date": "2019-11-18", "authors_parsed": [["Masuda", "Akitoshi", ""], ["Susuki", "Yoshihiko", ""], ["Mart\u00ednez-Ram\u00f3n", "Manel", ""], ["Mammoli", "Andrea", ""], ["Ishigame", "Atsushi", ""]]}, {"id": "1911.01155", "submitter": "Kushal Satya", "authors": "Jagriti Sikka, Kushal Satya, Yaman Kumar, Shagun Uppal, Rajiv Ratn\n  Shah, Roger Zimmermann", "title": "Learning based Methods for Code Runtime Complexity Prediction", "comments": "14 pages, 2 figures, 8 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Predicting the runtime complexity of a programming code is an arduous task.\nIn fact, even for humans, it requires a subtle analysis and comprehensive\nknowledge of algorithms to predict time complexity with high fidelity, given\nany code. As per Turing's Halting problem proof, estimating code complexity is\nmathematically impossible. Nevertheless, an approximate solution to such a task\ncan help developers to get real-time feedback for the efficiency of their code.\nIn this work, we model this problem as a machine learning task and check its\nfeasibility with thorough analysis. Due to the lack of any open source dataset\nfor this task, we propose our own annotated dataset CoRCoD: Code Runtime\nComplexity Dataset, extracted from online judges. We establish baselines using\ntwo different approaches: feature engineering and code embeddings, to achieve\nstate of the art results and compare their performances. Such solutions can be\nwidely useful in potential applications like automatically grading coding\nassignments, IDE-integrated tools for static code analysis, and others.\n", "versions": [{"version": "v1", "created": "Mon, 4 Nov 2019 12:26:21 GMT"}], "update_date": "2019-11-05", "authors_parsed": [["Sikka", "Jagriti", ""], ["Satya", "Kushal", ""], ["Kumar", "Yaman", ""], ["Uppal", "Shagun", ""], ["Shah", "Rajiv Ratn", ""], ["Zimmermann", "Roger", ""]]}, {"id": "1911.01172", "submitter": "Le Shu", "authors": "Jiazhu Dai, Le Shu", "title": "Fast-UAP: An Algorithm for Speeding up Universal Adversarial\n  Perturbation Generation with Orientation of Perturbation Vectors", "comments": "9 pages, 7 figures, 1 table, 1 algorithm", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Convolutional neural networks (CNN) have become one of the most popular\nmachine learning tools and are being applied in various tasks, however, CNN\nmodels are vulnerable to universal perturbations, which are usually\nhuman-imperceptible but can cause natural images to be misclassified with high\nprobability. One of the state-of-the-art algorithms to generate universal\nperturbations is known as UAP. UAP only aggregates the minimal perturbations in\nevery iteration, which will lead to generated universal perturbation whose\nmagnitude cannot rise up efficiently and cause a slow generation. In this\npaper, we proposed an optimized algorithm to improve the performance of\ncrafting universal perturbations based on orientation of perturbation vectors.\nAt each iteration, instead of choosing minimal perturbation vector with respect\nto each image, we aggregate the current instance of universal perturbation with\nthe perturbation which has similar orientation to the former so that the\nmagnitude of the aggregation will rise up as large as possible at every\niteration. The experiment results show that we get universal perturbations in a\nshorter time and with a smaller number of training images. Furthermore, we\nobserve in experiments that universal perturbations generated by our proposed\nalgorithm have an average increment of fooling rate by 9% in white-box attacks\nand black-box attacks comparing with universal perturbations generated by UAP.\n", "versions": [{"version": "v1", "created": "Mon, 4 Nov 2019 12:57:17 GMT"}, {"version": "v2", "created": "Mon, 16 Dec 2019 12:00:11 GMT"}, {"version": "v3", "created": "Mon, 6 Jan 2020 10:28:26 GMT"}], "update_date": "2020-01-07", "authors_parsed": [["Dai", "Jiazhu", ""], ["Shu", "Le", ""]]}, {"id": "1911.01182", "submitter": "Ville Vestman", "authors": "Alexey Sholokhov, Tomi Kinnunen, Ville Vestman, Kong Aik Lee", "title": "Voice Biometrics Security: Extrapolating False Alarm Rate via\n  Hierarchical Bayesian Modeling of Speaker Verification Scores", "comments": "Accepted to be published in Computer Speech and Language", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.AS cs.LG cs.SD stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  How secure automatic speaker verification (ASV) technology is? More\nconcretely, given a specific target speaker, how likely is it to find another\nperson who gets falsely accepted as that target? This question may be addressed\nempirically by studying naturally confusable pairs of speakers within a large\nenough corpus. To this end, one might expect to find at least some speaker\npairs that are indistinguishable from each other in terms of ASV. To a certain\nextent, such aim is mirrored in the standardized ASV evaluation benchmarks.\nHowever, the number of speakers in such evaluation benchmarks represents only a\nsmall fraction of all possible human voices, making it challenging to\nextrapolate performance beyond a given corpus. Furthermore, the impostors used\nin performance evaluation are usually selected randomly. A potentially more\nmeaningful definition of an impostor - at least in the context of\nsecurity-driven ASV applications - would be closest (most confusable) other\nspeaker to a given target.\n  We put forward a novel performance assessment framework to address both the\ninadequacy of the random-impostor evaluation model and the size limitation of\nevaluation corpora by addressing ASV security against closest impostors on\narbitrarily large datasets. The framework allows one to make a prediction of\nthe safety of given ASV technology, in its current state, for arbitrarily large\nspeaker database size consisting of virtual (sampled) speakers. As a\nproof-of-concept, we analyze the performance of two state-of-the-art ASV\nsystems, based on i-vector and x-vector speaker embeddings (as implemented in\nthe popular Kaldi toolkit), on the recent VoxCeleb 1 & 2 corpora. We found that\nneither the i-vector or x-vector system is immune to increased false alarm rate\nat increased impostor database size.\n", "versions": [{"version": "v1", "created": "Mon, 4 Nov 2019 13:13:45 GMT"}], "update_date": "2019-11-05", "authors_parsed": [["Sholokhov", "Alexey", ""], ["Kinnunen", "Tomi", ""], ["Vestman", "Ville", ""], ["Lee", "Kong Aik", ""]]}, {"id": "1911.01196", "submitter": "Yu Meng", "authors": "Yu Meng, Jiaxin Huang, Guangyuan Wang, Chao Zhang, Honglei Zhuang,\n  Lance Kaplan, Jiawei Han", "title": "Spherical Text Embedding", "comments": "NeurIPS 2019. (Code:\n  https://github.com/yumeng5/Spherical-Text-Embedding)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Unsupervised text embedding has shown great power in a wide range of NLP\ntasks. While text embeddings are typically learned in the Euclidean space,\ndirectional similarity is often more effective in tasks such as word similarity\nand document clustering, which creates a gap between the training stage and\nusage stage of text embedding. To close this gap, we propose a spherical\ngenerative model based on which unsupervised word and paragraph embeddings are\njointly learned. To learn text embeddings in the spherical space, we develop an\nefficient optimization algorithm with convergence guarantee based on Riemannian\noptimization. Our model enjoys high efficiency and achieves state-of-the-art\nperformances on various text embedding tasks including word similarity and\ndocument clustering.\n", "versions": [{"version": "v1", "created": "Mon, 4 Nov 2019 18:36:12 GMT"}], "update_date": "2019-11-05", "authors_parsed": [["Meng", "Yu", ""], ["Huang", "Jiaxin", ""], ["Wang", "Guangyuan", ""], ["Zhang", "Chao", ""], ["Zhuang", "Honglei", ""], ["Kaplan", "Lance", ""], ["Han", "Jiawei", ""]]}, {"id": "1911.01198", "submitter": "Yanwei Cui", "authors": "Yanwei Cui, Xavier Illy", "title": "Understand customer reviews with less data and in short time: pretrained\n  language representation and active learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we address customer review understanding problems by using\nsupervised machine learning approaches, in order to achieve a fully automatic\nreview aspects categorisation and sentiment analysis. In general, such\nsupervised learning algorithms require domain-specific expert knowledge for\ngenerating high quality labeled training data, and the cost of labeling can be\nvery high. To achieve an in-production customer review machine learning enabled\nanalysis tool with only a limited amount of data and within a reasonable\ntraining data collection time, we propose to use pre-trained language\nrepresentation to boost model performance and active learning framework for\naccelerating the iterative training process. The results show that with\nintegration of both components, the fully automatic review analysis can be\nachieved at a much faster pace.\n", "versions": [{"version": "v1", "created": "Tue, 29 Oct 2019 12:39:37 GMT"}], "update_date": "2019-11-05", "authors_parsed": [["Cui", "Yanwei", ""], ["Illy", "Xavier", ""]]}, {"id": "1911.01205", "submitter": "Daniel Tarlow", "authors": "Daniel Tarlow, Subhodeep Moitra, Andrew Rice, Zimin Chen,\n  Pierre-Antoine Manzagol, Charles Sutton, Edward Aftandilian", "title": "Learning to Fix Build Errors with Graph2Diff Neural Networks", "comments": "Submitted for review on Aug 23, 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.SE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Professional software developers spend a significant amount of time fixing\nbuilds, but this has received little attention as a problem in automatic\nprogram repair. We present a new deep learning architecture, called Graph2Diff,\nfor automatically localizing and fixing build errors. We represent source code,\nbuild configuration files, and compiler diagnostic messages as a graph, and\nthen use a Graph Neural Network model to predict a diff. A diff specifies how\nto modify the code's abstract syntax tree, represented in the neural network as\na sequence of tokens and of pointers to code locations. Our network is an\ninstance of a more general abstraction that we call Graph2Tocopo, which is\npotentially useful in any development tool for predicting source code changes.\nWe evaluate the model on a dataset of over 500k real build errors and their\nresolutions from professional developers. Compared to the approach of DeepDelta\n(Mesbah et al., 2019), our approach tackles the harder task of predicting a\nmore precise diff but still achieves over double the accuracy.\n", "versions": [{"version": "v1", "created": "Mon, 4 Nov 2019 13:40:27 GMT"}], "update_date": "2019-11-05", "authors_parsed": [["Tarlow", "Daniel", ""], ["Moitra", "Subhodeep", ""], ["Rice", "Andrew", ""], ["Chen", "Zimin", ""], ["Manzagol", "Pierre-Antoine", ""], ["Sutton", "Charles", ""], ["Aftandilian", "Edward", ""]]}, {"id": "1911.01207", "submitter": "Philip Koopman", "authors": "Philip Koopman, Beth Osyk, Jack Weast", "title": "Autonomous Vehicles Meet the Physical World: RSS, Variability,\n  Uncertainty, and Proving Safety (Expanded Version)", "comments": "Safecomp 2019 expanded version, 22 pages including appendix", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The Responsibility-Sensitive Safety (RSS) model offers provable safety for\nvehicle behaviors such as minimum safe following distance. However, handling\nworst-case variability and uncertainty may significantly lower vehicle\npermissiveness, and in some situations safety cannot be guaranteed. Digging\ndeeper into Newtonian mechanics, we identify complications that result from\nconsidering vehicle status, road geometry and environmental parameters. An\nespecially challenging situation occurs if these parameters change during the\ncourse of a collision avoidance maneuver such as hard braking. As part of our\nanalysis, we expand the original RSS following distance equation to account for\nedge cases involving potential collisions mid-way through a braking process. We\nadditionally propose a Micro-Operational Design Domain ({\\mu}ODD) approach to\nsubdividing the operational space as a way of improving permissiveness.\nConfining probabilistic aspects of safety to {\\mu}ODD transitions permits\nproving safety (when possible) under the assumption that the system has\ntransitioned to the correct {\\mu}ODD for the situation. Each {\\mu}ODD can\nadditionally be used to encode system fault responses, take credit for advisory\ninformation (e.g., from vehicle-to-vehicle communication), and anticipate\nlikely emergent situations.\n", "versions": [{"version": "v1", "created": "Thu, 31 Oct 2019 00:11:33 GMT"}], "update_date": "2019-11-05", "authors_parsed": [["Koopman", "Philip", ""], ["Osyk", "Beth", ""], ["Weast", "Jack", ""]]}, {"id": "1911.01208", "submitter": "Alon Kipnis", "authors": "Alon Kipnis", "title": "Higher Criticism for Discriminating Word-Frequency Tables and Testing\n  Authorship", "comments": "under review (AOAS)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG stat.CO stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We adapt the Higher Criticism (HC) goodness-of-fit test to measure closeness\nbetween word-frequency tables. We apply this measure to authorship attribution\nchallenges, where the goal is to identify the author of a document using other\ndocuments whose authorship is known. The method is simple yet performs well\nwithout handcrafting and tuning; reporting accuracy at the state of the art\nlevel in various current challenges. As an inherent side effect, the HC\ncalculation identifies a subset of discriminating words. In practice, the\nidentified words have low variance across documents belonging to a corpus of\nhomogeneous authorship. We conclude that in comparing the similarity of a new\ndocument and a corpus of a single author, HC is mostly affected by words\ncharacteristic of the author and is relatively unaffected by topic structure.\n", "versions": [{"version": "v1", "created": "Wed, 30 Oct 2019 23:47:25 GMT"}, {"version": "v2", "created": "Fri, 13 Dec 2019 19:41:44 GMT"}, {"version": "v3", "created": "Mon, 6 Jul 2020 20:04:32 GMT"}], "update_date": "2020-07-08", "authors_parsed": [["Kipnis", "Alon", ""]]}, {"id": "1911.01212", "submitter": "Tamali Banerjee", "authors": "Tamali Banerjee, Rudra Murthy V, Pushpak Bhattacharyya", "title": "Scrambled Translation Problem: A Problem of Denoising UNMT", "comments": "Accepted by MT Summit 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we identify an interesting kind of error in the output of\nUnsupervised Neural Machine Translation (UNMT) systems like\n\\textit{Undreamt}(footnote). We refer to this error type as \\textit{Scrambled\nTranslation problem}. We observe that UNMT models which use \\textit{word\nshuffle} noise (as in case of Undreamt) can generate correct words, but fail to\nstitch them together to form phrases. As a result, words of the translated\nsentence look \\textit{scrambled}, resulting in decreased BLEU. We hypothesise\nthat the reason behind \\textit{scrambled translation problem} is 'shuffling\nnoise' which is introduced in every input sentence as a denoising strategy. To\ntest our hypothesis, we experiment by retraining UNMT models with a simple\n\\textit{retraining} strategy. We stop the training of the Denoising UNMT model\nafter a pre-decided number of iterations and resume the training for the\nremaining iterations -- which number is also pre-decided -- using original\nsentence as input without adding any noise. Our proposed solution achieves\nsignificant performance improvement UNMT models that train conventionally. We\ndemonstrate these performance gains on four language pairs, \\textit{viz.},\nEnglish-French, English-German, English-Spanish, Hindi-Punjabi. Our qualitative\nand quantitative analysis shows that the retraining strategy helps achieve\nbetter alignment as observed by attention heatmap and better phrasal\ntranslation, leading to statistically significant improvement in BLEU scores.\n", "versions": [{"version": "v1", "created": "Wed, 30 Oct 2019 12:22:37 GMT"}, {"version": "v2", "created": "Thu, 17 Jun 2021 10:57:15 GMT"}], "update_date": "2021-06-18", "authors_parsed": [["Banerjee", "Tamali", ""], ["Murthy", "Rudra", "V"], ["Bhattacharyya", "Pushpak", ""]]}, {"id": "1911.01217", "submitter": "Nikhil Oswal", "authors": "Deepshi Mediratta and Nikhil Oswal", "title": "Detect Toxic Content to Improve Online Conversations", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Social media is filled with toxic content. The aim of this paper is to build\na model that can detect insincere questions. We use the 'Quora Insincere\nQuestions Classification' dataset for our analysis. The dataset is composed of\nsincere and insincere questions, with the majority of sincere questions. The\ndataset is processed and analyzed using Python and its libraries such as\nsklearn, numpy, pandas, keras etc. The dataset is converted to vector form\nusing word embeddings such as GloVe, Wiki-news and TF-IDF. The imbalance in the\ndataset is handled by resampling techniques. We train and compare various\nmachine learning and deep learning models to come up with the best results.\nModels discussed include SVM, Naive Bayes, GRU and LSTM.\n", "versions": [{"version": "v1", "created": "Tue, 29 Oct 2019 01:42:22 GMT"}], "update_date": "2019-11-05", "authors_parsed": [["Mediratta", "Deepshi", ""], ["Oswal", "Nikhil", ""]]}, {"id": "1911.01218", "submitter": "Gerda Bortsova", "authors": "Gerda Bortsova, Florian Dubost, Laurens Hogeweg, Ioannis Katramados,\n  Marleen de Bruijne", "title": "Semi-Supervised Medical Image Segmentation via Learning Consistency\n  under Transformations", "comments": null, "journal-ref": "In proceedings of Medical Image Computing and Computer Assisted\n  Intervention - MICCAI 2019", "doi": "10.1007/978-3-030-32226-7_90", "report-no": null, "categories": "cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The scarcity of labeled data often limits the application of supervised deep\nlearning techniques for medical image segmentation. This has motivated the\ndevelopment of semi-supervised techniques that learn from a mixture of labeled\nand unlabeled images. In this paper, we propose a novel semi-supervised method\nthat, in addition to supervised learning on labeled training images, learns to\npredict segmentations consistent under a given class of transformations on both\nlabeled and unlabeled images. More specifically, in this work we explore\nlearning equivariance to elastic deformations. We implement this through: 1) a\nSiamese architecture with two identical branches, each of which receives a\ndifferently transformed image, and 2) a composite loss function with a\nsupervised segmentation loss term and an unsupervised term that encourages\nsegmentation consistency between the predictions of the two branches. We\nevaluate the method on a public dataset of chest radiographs with segmentations\nof anatomical structures using 5-fold cross-validation. The proposed method\nreaches significantly higher segmentation accuracy compared to supervised\nlearning. This is due to learning transformation consistency on both labeled\nand unlabeled images, with the latter contributing the most. We achieve the\nperformance comparable to state-of-the-art chest X-ray segmentation methods\nwhile using substantially fewer labeled images.\n", "versions": [{"version": "v1", "created": "Mon, 4 Nov 2019 13:51:17 GMT"}], "update_date": "2019-11-05", "authors_parsed": [["Bortsova", "Gerda", ""], ["Dubost", "Florian", ""], ["Hogeweg", "Laurens", ""], ["Katramados", "Ioannis", ""], ["de Bruijne", "Marleen", ""]]}, {"id": "1911.01220", "submitter": "Essam Rashed", "authors": "Essam A. Rashed, Yinliang Diao, Akimasa Hirata", "title": "Learning-based estimation of dielectric properties and tissue density in\n  head models for personalized radio-frequency dosimetry", "comments": "18 pages, 10 figures, 4 tables", "journal-ref": "Physics in Medicine and Biology 65, pp. 065001, 2020", "doi": "10.1088/1361-6560/ab7308", "report-no": null, "categories": "cs.LG eess.IV physics.med-ph stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Radio-frequency dosimetry is an important process in human safety and for\ncompliance of related products. Recently, computational human models generated\nfrom medical images have often been used for such assessment, especially to\nconsider the inter-variability of subjects. However, the common procedure to\ndevelop personalized models is time consuming because it involves excessive\nsegmentation of several components that represent different biological tissues,\nwhich limits the inter-variability assessment of radiation safety based on\npersonalized dosimetry. Deep learning methods have been shown to be a powerful\napproach for pattern recognition and signal analysis. Convolutional neural\nnetworks with deep architecture are proven robust for feature extraction and\nimage mapping in several biomedical applications. In this study, we develop a\nlearning-based approach for fast and accurate estimation of the dielectric\nproperties and density of tissues directly from magnetic resonance images in a\nsingle shot. The smooth distribution of the dielectric properties in head\nmodels, which is realized using a process without tissue segmentation, improves\nthe smoothness of the specific absorption rate (SAR) distribution compared with\nthat in the commonly used procedure. The estimated SAR distributions, as well\nas that averaged over 10-g of tissue in a cubic shape, are found to be highly\nconsistent with those computed using the conventional methods that employ\nsegmentation.\n", "versions": [{"version": "v1", "created": "Mon, 4 Nov 2019 13:55:30 GMT"}, {"version": "v2", "created": "Wed, 6 Nov 2019 03:16:33 GMT"}, {"version": "v3", "created": "Wed, 5 Feb 2020 01:07:54 GMT"}], "update_date": "2020-04-29", "authors_parsed": [["Rashed", "Essam A.", ""], ["Diao", "Yinliang", ""], ["Hirata", "Akimasa", ""]]}, {"id": "1911.01225", "submitter": "Fan (Fred) Lin", "authors": "Fred Lin, Keyur Muzumdar, Nikolay Pavlovich Laptev, Mihai-Valentin\n  Curelea, Seunghak Lee, Sriram Sankar", "title": "Fast Dimensional Analysis for Root Cause Investigation in a Large-Scale\n  Service Environment", "comments": "13 pages", "journal-ref": "POMACS 2020", "doi": "10.1145/3392149", "report-no": null, "categories": "cs.DC cs.DB cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Root cause analysis in a large-scale production environment is challenging\ndue to the complexity of services running across global data centers. Due to\nthe distributed nature of a large-scale system, the various hardware, software,\nand tooling logs are often maintained separately, making it difficult to review\nthe logs jointly for understanding production issues. Another challenge in\nreviewing the logs for identifying issues is the scale - there could easily be\nmillions of entities, each described by hundreds of features. In this paper we\npresent a fast dimensional analysis framework that automates the root cause\nanalysis on structured logs with improved scalability.\n  We first explore item-sets, i.e. combinations of feature values, that could\nidentify groups of samples with sufficient support for the target failures\nusing the Apriori algorithm and a subsequent improvement, FP-Growth. These\nalgorithms were designed for frequent item-set mining and association rule\nlearning over transactional databases. After applying them on structured logs,\nwe select the item-sets that are most unique to the target failures based on\nlift. We propose pre-processing steps with the use of a large-scale real-time\ndatabase and post-processing techniques and parallelism to further speed up the\nanalysis and improve interpretability, and demonstrate that such optimization\nis necessary for handling large-scale production datasets. We have successfully\nrolled out this approach for root cause investigation purposes in a large-scale\ninfrastructure. We also present the setup and results from multiple production\nuse cases in this paper.\n", "versions": [{"version": "v1", "created": "Fri, 1 Nov 2019 01:03:01 GMT"}, {"version": "v2", "created": "Thu, 6 Feb 2020 19:49:04 GMT"}], "update_date": "2020-04-30", "authors_parsed": [["Lin", "Fred", ""], ["Muzumdar", "Keyur", ""], ["Laptev", "Nikolay Pavlovich", ""], ["Curelea", "Mihai-Valentin", ""], ["Lee", "Seunghak", ""], ["Sankar", "Sriram", ""]]}, {"id": "1911.01226", "submitter": "Ruibin Ma", "authors": "Ruibin Ma and Po-Hsuan Cameron Chen and Gang Li and Wei-Hung Weng and\n  Angela Lin and Krishna Gadepalli and Yuannan Cai", "title": "Human-centric Metric for Accelerating Pathology Reports Annotation", "comments": "Machine Learning for Health (ML4H) at NeurIPS 2019 - Extended\n  Abstract", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.CY cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Pathology reports contain useful information such as the main involved organ,\ndiagnosis, etc. These information can be identified from the free text reports\nand used for large-scale statistical analysis or serve as annotation for other\nmodalities such as pathology slides images. However, manual classification for\na huge number of reports on multiple tasks is labor-intensive. In this paper,\nwe have developed an automatic text classifier based on BERT and we propose a\nhuman-centric metric to evaluate the model. According to the model confidence,\nwe identify low-confidence cases that require further expert annotation and\nhigh-confidence cases that are automatically classified. We report the\npercentage of low-confidence cases and the performance of automatically\nclassified cases. On the high-confidence cases, the model achieves\nclassification accuracy comparable to pathologists. This leads a potential of\nreducing 80% to 98% of the manual annotation workload.\n", "versions": [{"version": "v1", "created": "Thu, 31 Oct 2019 22:09:19 GMT"}, {"version": "v2", "created": "Tue, 12 Nov 2019 15:12:45 GMT"}], "update_date": "2019-11-13", "authors_parsed": [["Ma", "Ruibin", ""], ["Chen", "Po-Hsuan Cameron", ""], ["Li", "Gang", ""], ["Weng", "Wei-Hung", ""], ["Lin", "Angela", ""], ["Gadepalli", "Krishna", ""], ["Cai", "Yuannan", ""]]}, {"id": "1911.01258", "submitter": "Reza Yazdani Aminabadi", "authors": "Reza Yazdani, Olatunji Ruwase, Minjia Zhang, Yuxiong He, Jose-Maria\n  Arnau, Antonio Gonzalez", "title": "LSTM-Sharp: An Adaptable, Energy-Efficient Hardware Accelerator for Long\n  Short-Term Memory", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AR cs.NE cs.PF", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The effectiveness of LSTM neural networks for popular tasks such as Automatic\nSpeech Recognition has fostered an increasing interest in LSTM inference\nacceleration. Due to the recurrent nature and data dependencies of LSTM\ncomputations, designing a customized architecture specifically tailored to its\ncomputation pattern is crucial for efficiency. Since LSTMs are used for a\nvariety of tasks, generalizing this efficiency to diverse configurations, i.e.,\nadaptiveness, is another key feature of these accelerators. In this work, we\nfirst show the problem of low resource-utilization and adaptiveness for the\nstate-of-the-art LSTM implementations on GPU, FPGA and ASIC architectures. To\nsolve these issues, we propose an intelligent tiled-based dispatching mechanism\nthat efficiently handles the data dependencies and increases the adaptiveness\nof LSTM computation. To do so, we propose LSTM-Sharp as a hardware accelerator,\nwhich pipelines LSTM computation using an effective scheduling scheme to hide\nmost of the dependent serialization. Furthermore, LSTM-Sharp employs dynamic\nreconfigurable architecture to adapt to the model's characteristics. LSTM-Sharp\nachieves 1.5x, 2.86x, and 82x speedups on average over the state-of-the-art\nASIC, FPGA, and GPU implementations respectively, for different LSTM models and\nresource budgets. Furthermore, we provide significant energy-reduction with\nrespect to the previous solutions, due to the low power dissipation of\nLSTM-Sharp (383 GFLOPs/Watt).\n", "versions": [{"version": "v1", "created": "Mon, 4 Nov 2019 14:51:27 GMT"}], "update_date": "2019-11-05", "authors_parsed": [["Yazdani", "Reza", ""], ["Ruwase", "Olatunji", ""], ["Zhang", "Minjia", ""], ["He", "Yuxiong", ""], ["Arnau", "Jose-Maria", ""], ["Gonzalez", "Antonio", ""]]}, {"id": "1911.01266", "submitter": "Enrico Fini", "authors": "Enrico Fini, Alessio Brutti", "title": "Supervised online diarization with sample mean loss for multi-domain\n  data", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.AS cs.LG cs.SD", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recently, a fully supervised speaker diarization approach was proposed\n(UIS-RNN) which models speakers using multiple instances of a parameter-sharing\nrecurrent neural network. In this paper we propose qualitative modifications to\nthe model that significantly improve the learning efficiency and the overall\ndiarization performance. In particular, we introduce a novel loss function, we\ncalled Sample Mean Loss and we present a better modelling of the speaker turn\nbehaviour, by devising an analytical expression to compute the probability of a\nnew speaker joining the conversation. In addition, we demonstrate that our\nmodel can be trained on fixed-length speech segments, removing the need for\nspeaker change information in inference. Using x-vectors as input features, we\nevaluate our proposed approach on the multi-domain dataset employed in the\nDIHARD II challenge: our online method improves with respect to the original\nUIS-RNN and achieves similar performance to an offline agglomerative clustering\nbaseline using PLDA scoring.\n", "versions": [{"version": "v1", "created": "Mon, 4 Nov 2019 15:01:30 GMT"}, {"version": "v2", "created": "Fri, 8 Nov 2019 08:56:42 GMT"}, {"version": "v3", "created": "Wed, 13 Nov 2019 11:20:25 GMT"}], "update_date": "2019-11-14", "authors_parsed": [["Fini", "Enrico", ""], ["Brutti", "Alessio", ""]]}, {"id": "1911.01275", "submitter": "Wesam Alruwaili", "authors": "Wesam Alruwaili, Bradley Protano, Tejasvi Sirigiriraju, Hamed Alhoori", "title": "Using Arabic Tweets to Understand Drug Selling Behaviors", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.LG cs.SI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Twitter is a popular platform for e-commerce in the Arab region including the\nsale of illegal goods and services. Social media platforms present multiple\nopportunities to mine information about behaviors pertaining to both illicit\nand pharmaceutical drugs and likewise to legal prescription drugs sold without\na prescription, i.e., illegally. Recognized as a public health risk, the sale\nand use of illegal drugs, counterfeit versions of legal drugs, and legal drugs\nsold without a prescription constitute a widespread problem that is reflected\nin and facilitated by social media. Twitter provides a crucial resource for\nmonitoring legal and illegal drug sales in order to support the larger goal of\nfinding ways to protect patient safety. We collected our dataset using Arabic\nkeywords. We then categorized the data using four machine learning classifiers.\nBased on a comparison of the respective results, we assessed the accuracy of\neach classifier in predicting two important considerations in analysing the\nextent to which drugs are available on social media: references to drugs for\nsale and the legality/illegality of the drugs thus advertised. For predicting\ntweets selling drugs, Support Vector Machine, yielded the highest accuracy rate\n(96%), whereas for predicting the legality of the advertised drugs, the Naive\nBayes, classifier yielded the highest accuracy rate (85%).\n", "versions": [{"version": "v1", "created": "Sat, 26 Oct 2019 11:56:30 GMT"}], "update_date": "2019-11-05", "authors_parsed": [["Alruwaili", "Wesam", ""], ["Protano", "Bradley", ""], ["Sirigiriraju", "Tejasvi", ""], ["Alhoori", "Hamed", ""]]}, {"id": "1911.01288", "submitter": "Prateek Jaiswal", "authors": "Prateek Jaiswal, Harsha Honnappa and Vinayak A. Rao", "title": "Asymptotic Consistency of Loss-Calibrated Variational Bayes", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper establishes the asymptotic consistency of the {\\it loss-calibrated\nvariational Bayes} (LCVB) method. LCVB was proposed in~\\cite{LaSiGh2011} as a\nmethod for approximately computing Bayesian posteriors in a `loss aware'\nmanner. This methodology is also highly relevant in general data-driven\ndecision-making contexts. Here, we not only establish the asymptotic\nconsistency of the calibrated approximate posterior, but also the asymptotic\nconsistency of decision rules. We also establish the asymptotic consistency of\ndecision rules obtained from a `naive' variational Bayesian procedure.\n", "versions": [{"version": "v1", "created": "Mon, 4 Nov 2019 15:43:50 GMT"}], "update_date": "2019-11-05", "authors_parsed": [["Jaiswal", "Prateek", ""], ["Honnappa", "Harsha", ""], ["Rao", "Vinayak A.", ""]]}, {"id": "1911.01291", "submitter": "Andrew Ross", "authors": "Andrew Slavin Ross, Weiwei Pan, Leo Anthony Celi, Finale Doshi-Velez", "title": "Ensembles of Locally Independent Prediction Models", "comments": "This is an expansion of arXiv:1806.08716 with different applications\n  and focus, accepted to AAAI 2020. Latest update clarifies a derivation", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Ensembles depend on diversity for improved performance. Many ensemble\ntraining methods, therefore, attempt to optimize for diversity, which they\nalmost always define in terms of differences in training set predictions. In\nthis paper, however, we demonstrate the diversity of predictions on the\ntraining set does not necessarily imply diversity under mild covariate shift,\nwhich can harm generalization in practical settings. To address this issue, we\nintroduce a new diversity metric and associated method of training ensembles of\nmodels that extrapolate differently on local patches of the data manifold.\nAcross a variety of synthetic and real-world tasks, we find that our method\nimproves generalization and diversity in qualitatively novel ways, especially\nunder data limits and covariate shift.\n", "versions": [{"version": "v1", "created": "Mon, 4 Nov 2019 15:46:59 GMT"}, {"version": "v2", "created": "Wed, 27 Nov 2019 14:27:03 GMT"}, {"version": "v3", "created": "Fri, 7 Feb 2020 17:03:50 GMT"}], "update_date": "2020-02-10", "authors_parsed": [["Ross", "Andrew Slavin", ""], ["Pan", "Weiwei", ""], ["Celi", "Leo Anthony", ""], ["Doshi-Velez", "Finale", ""]]}, {"id": "1911.01325", "submitter": "Kevin Cheng", "authors": "Kevin C. Cheng, Shuchin Aeron, Michael C. Hughes, Erika Hussey, Eric\n  L. Miller", "title": "Optimal Transport Based Change Point Detection and Time Series Segment\n  Clustering", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.SP cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Two common problems in time series analysis are the decomposition of the data\nstream into disjoint segments that are each in some sense \"homogeneous\" - a\nproblem known as Change Point Detection (CPD) - and the grouping of similar\nnonadjacent segments, a problem that we call Time Series Segment Clustering\n(TSSC). Building upon recent theoretical advances characterizing the limiting\ndistribution-free behavior of the Wasserstein two-sample test (Ramdas et al.\n2015), we propose a novel algorithm for unsupervised, distribution-free CPD\nwhich is amenable to both offline and online settings. We also introduce a\nmethod to mitigate false positives in CPD and address TSSC by using the\nWasserstein distance between the detected segments to build an affinity matrix\nto which we apply spectral clustering. Results on both synthetic and real data\nsets show the benefits of the approach.\n", "versions": [{"version": "v1", "created": "Mon, 4 Nov 2019 16:42:19 GMT"}, {"version": "v2", "created": "Thu, 20 Feb 2020 21:35:41 GMT"}], "update_date": "2020-02-24", "authors_parsed": [["Cheng", "Kevin C.", ""], ["Aeron", "Shuchin", ""], ["Hughes", "Michael C.", ""], ["Hussey", "Erika", ""], ["Miller", "Eric L.", ""]]}, {"id": "1911.01346", "submitter": "Andrei Damian I", "authors": "Andrei Damian, Laurentiu Piciu, Alexandru Purdila and Nicolae Tapus", "title": "CloudifierNet -- Deep Vision Models for Artificial Image Processing", "comments": "ITQM 2019", "journal-ref": null, "doi": "10.1016/j.procs.2019.12.043", "report-no": null, "categories": "cs.CV cs.LG eess.IV", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Today, more and more, it is necessary that most applications and documents\ndeveloped in previous or current technologies to be accessible online on\ncloud-based infrastructures. That is why the migration of legacy systems\nincluding their hosts of documents to new technologies and online\ninfrastructures, using modern Artificial Intelligence techniques, is absolutely\nnecessary. With the advancement of Artificial Intelligence and Deep Learning\nwith its multitude of applications, a new area of research is emerging - that\nof automated systems development and maintenance. The underlying work objective\nthat led to this paper aims to research and develop truly intelligent systems\nable to analyze user interfaces from various sources and generate real and\nusable inferences ranging from architecture analysis to actual code generation.\nOne key element of such systems is that of artificial scene detection and\nanalysis based on deep learning computer vision systems. Computer vision models\nand particularly deep directed acyclic graphs based on convolutional modules\nare generally constructed and trained based on natural images datasets. Due to\nthis fact, the models will develop during the training process natural image\nfeature detectors apart from the base graph modules that will learn basic\nprimitive features. In the current paper, we will present the base principles\nof a deep neural pipeline for computer vision applied to artificial scenes\n(scenes generated by user interfaces or similar). Finally, we will present the\nconclusions based on experimental development and benchmarking against\nstate-of-the-art transfer-learning implemented deep vision models.\n", "versions": [{"version": "v1", "created": "Mon, 4 Nov 2019 17:16:35 GMT"}, {"version": "v2", "created": "Tue, 28 Jul 2020 11:13:43 GMT"}], "update_date": "2020-07-29", "authors_parsed": [["Damian", "Andrei", ""], ["Piciu", "Laurentiu", ""], ["Purdila", "Alexandru", ""], ["Tapus", "Nicolae", ""]]}, {"id": "1911.01366", "submitter": "Chainarong Amornbunchornvej", "authors": "Chainarong Amornbunchornvej and Tanya Berger-Wolf", "title": "Framework for Inferring Following Strategies from Time Series of\n  Movement Data", "comments": "This is the revised version of the preprint entitled \"Inferring\n  Coordination Strategies from Time Series of Movement Data\" following\n  reviewers' suggestions", "journal-ref": "ACM Transactions on Knowledge Discovery from Data (TKDD), 14(3),\n  35 (2020)", "doi": "10.1145/3385730", "report-no": null, "categories": "stat.ML cs.AI cs.LG cs.MA physics.data-an", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  How do groups of individuals achieve consensus in movement decisions? Do\nindividuals follow their friends, the one predetermined leader, or whomever\njust happens to be nearby? To address these questions computationally, we\nformalize \"Coordination Strategy Inference Problem\". In this setting, a group\nof multiple individuals moves in a coordinated manner towards a target path.\nEach individual uses a specific strategy to follow others (e.g. nearest\nneighbors, pre-defined leaders, preferred friends). Given a set of time series\nthat includes coordinated movement and a set of candidate strategies as inputs,\nwe provide the first methodology (to the best of our knowledge) to infer\nwhether each individual uses local-agreement-system or dictatorship-like\nstrategy to achieve movement coordination at the group level. We evaluate and\ndemonstrate the performance of the proposed framework by predicting the\ndirection of movement of an individual in a group in both simulated datasets as\nwell as two real-world datasets: a school of fish and a troop of baboons.\nMoreover, since there is no prior methodology for inferring individual-level\nstrategies, we compare our framework with the state-of-the-art approach for the\ntask of classification of group-level-coordination models. The results show\nthat our approach is highly accurate in inferring the correct strategy in\nsimulated datasets even in complicated mixed strategy settings, which no\nexisting method can infer. In the task of classification of\ngroup-level-coordination models, our framework performs better than the\nstate-of-the-art approach in all datasets. Animal data experiments show that\nfish, as expected, follow their neighbors, while baboons have a preference to\nfollow specific individuals. Our methodology generalizes to arbitrary time\nseries data of real numbers, beyond movement data.\n", "versions": [{"version": "v1", "created": "Mon, 4 Nov 2019 17:51:23 GMT"}, {"version": "v2", "created": "Sun, 12 Jan 2020 09:46:22 GMT"}], "update_date": "2020-05-20", "authors_parsed": [["Amornbunchornvej", "Chainarong", ""], ["Berger-Wolf", "Tanya", ""]]}, {"id": "1911.01373", "submitter": "Michalis Titsias", "authors": "Michalis K. Titsias, Petros Dellaportas", "title": "Gradient-based Adaptive Markov Chain Monte Carlo", "comments": "17 pages, 7 Figures, NeurIPS 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG stat.CO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce a gradient-based learning method to automatically adapt Markov\nchain Monte Carlo (MCMC) proposal distributions to intractable targets. We\ndefine a maximum entropy regularised objective function, referred to as\ngeneralised speed measure, which can be robustly optimised over the parameters\nof the proposal distribution by applying stochastic gradient optimisation. An\nadvantage of our method compared to traditional adaptive MCMC methods is that\nthe adaptation occurs even when candidate state values are rejected. This is a\nhighly desirable property of any adaptation strategy because the adaptation\nstarts in early iterations even if the initial proposal distribution is far\nfrom optimum. We apply the framework for learning multivariate random walk\nMetropolis and Metropolis-adjusted Langevin proposals with full covariance\nmatrices, and provide empirical evidence that our method can outperform other\nMCMC algorithms, including Hamiltonian Monte Carlo schemes.\n", "versions": [{"version": "v1", "created": "Mon, 4 Nov 2019 18:03:06 GMT"}, {"version": "v2", "created": "Mon, 6 Jan 2020 15:00:05 GMT"}], "update_date": "2020-01-07", "authors_parsed": [["Titsias", "Michalis K.", ""], ["Dellaportas", "Petros", ""]]}, {"id": "1911.01382", "submitter": "Hao Wu", "authors": "Hao Wu, Heiko Zimmermann, Eli Sennesh, Tuan Anh Le, and Jan-Willem van\n  de Meent", "title": "Amortized Population Gibbs Samplers with Neural Sufficient Statistics", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We develop amortized population Gibbs (APG) samplers, a class of scalable\nmethods that frames structured variational inference as adaptive importance\nsampling. APG samplers construct high-dimensional proposals by iterating over\nupdates to lower-dimensional blocks of variables. We train each conditional\nproposal by minimizing the inclusive KL divergence with respect to the\nconditional posterior. To appropriately account for the size of the input data,\nwe develop a new parameterization in terms of neural sufficient statistics.\nExperiments show that APG samplers can train highly structured deep generative\nmodels in an unsupervised manner, and achieve substantial improvements in\ninference accuracy relative to standard autoencoding variational methods.\n", "versions": [{"version": "v1", "created": "Mon, 4 Nov 2019 18:10:11 GMT"}, {"version": "v2", "created": "Thu, 26 Mar 2020 17:46:09 GMT"}, {"version": "v3", "created": "Thu, 9 Jul 2020 18:59:36 GMT"}], "update_date": "2020-07-13", "authors_parsed": [["Wu", "Hao", ""], ["Zimmermann", "Heiko", ""], ["Sennesh", "Eli", ""], ["Le", "Tuan Anh", ""], ["van de Meent", "Jan-Willem", ""]]}, {"id": "1911.01413", "submitter": "Tian Ding", "authors": "Tian Ding, Dawei Li, Ruoyu Sun", "title": "Sub-Optimal Local Minima Exist for Neural Networks with Almost All\n  Non-Linear Activations", "comments": "58 pages. The main theorem is strengthened. An early version was\n  submitted to Optimization Online on October 4, 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG math.OC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Does over-parameterization eliminate sub-optimal local minima for neural\nnetworks? An affirmative answer was given by a classical result in [59] for\n1-hidden-layer wide neural networks. A few recent works have extended the\nsetting to multi-layer neural networks, but none of them has proved every local\nminimum is global. Why is this result never extended to deep networks?\n  In this paper, we show that the task is impossible because the original\nresult for 1-hidden-layer network in [59] can not hold. More specifically, we\nprove that for any multi-layer network with generic input data and non-linear\nactivation functions, sub-optimal local minima can exist, no matter how wide\nthe network is (as long as the last hidden layer has at least two neurons).\nWhile the result of [59] assumes sigmoid activation, our counter-example covers\na large set of activation functions (dense in the set of continuous functions),\nindicating that the limitation is not due to the specific activation. Our\nresult indicates that \"no bad local-min\" may be unable to explain the benefit\nof over-parameterization for training neural nets.\n", "versions": [{"version": "v1", "created": "Mon, 4 Nov 2019 18:56:58 GMT"}, {"version": "v2", "created": "Wed, 26 Feb 2020 18:33:55 GMT"}, {"version": "v3", "created": "Sat, 14 Nov 2020 17:05:52 GMT"}], "update_date": "2020-11-17", "authors_parsed": [["Ding", "Tian", ""], ["Li", "Dawei", ""], ["Sun", "Ruoyu", ""]]}, {"id": "1911.01419", "submitter": "Loren Anderson", "authors": "Loren Anderson and Sahitya Senapathy", "title": "On Solving the 2-Dimensional Greedy Shooter Problem for UAVs", "comments": "7 pages, 13 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Unmanned Aerial Vehicles (UAVs), autonomously-guided aircraft, are widely\nused for tasks involving surveillance and reconnaissance. A version of the\npursuit-evasion problems centered around UAVs and its variants has been\nextensively studied in recent years due to numerous breakthroughs in AI. We\npresent an approach to UAV pursuit-evasion in a 2D aerial-engagement\nenvironment using reinforcement learning (RL), a machine learning paradigm\nconcerned with goal-oriented algorithms. In this work, a UAV wielding the\ngreedy shooter strategy engages with a UAV trained using deep Q-learning\ntechniques. Simulated results show that the latter UAV wins every engagement in\nwhich the UAVs are suffciently separated during initialization. This approach\nhighlights an exhaustive and robust application of reinforcement learning to\npursuit-evasion that provides insight into effective strategies for UAV flight\nand interaction.\n", "versions": [{"version": "v1", "created": "Sat, 2 Nov 2019 21:55:19 GMT"}], "update_date": "2019-11-06", "authors_parsed": [["Anderson", "Loren", ""], ["Senapathy", "Sahitya", ""]]}, {"id": "1911.01421", "submitter": "Sunil Kumar Kopparapu Dr", "authors": "Bansi Shah and Sunil Kumar Kopparapu", "title": "A Deep Learning approach for Hindi Named Entity Recognition", "comments": "7 pages; work done during internship at TCS", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Named Entity Recognition is one of the most important text processing\nrequirement in many NLP tasks. In this paper we use a deep architecture to\naccomplish the task of recognizing named entities in a given Hindi text\nsentence. Bidirectional Long Short Term Memory (BiLSTM) based techniques have\nbeen used for NER task in literature. In this paper, we first tune BiLSTM\nlow-resource scenario to work for Hindi NER and propose two enhancements namely\n(a) de-noising auto-encoder (DAE) LSTM and (b) conditioning LSTM which show\nimprovement in NER task compared to the BiLSTM approach. We use pre-trained\nword embedding to represent the words in the corpus, and the NER tags of the\nwords are as defined by the used annotated corpora. Experiments have been\nperformed to analyze the performance of different word embeddings and batch\nsizes which is essential for training deep models.\n", "versions": [{"version": "v1", "created": "Tue, 5 Nov 2019 05:47:22 GMT"}], "update_date": "2019-11-06", "authors_parsed": [["Shah", "Bansi", ""], ["Kopparapu", "Sunil Kumar", ""]]}, {"id": "1911.01425", "submitter": "Pablo S\\'anchez Mart\\'in", "authors": "Pablo S\\'anchez-Mart\\'in, Pablo M. Olmos and Fernando Perez-Cruz", "title": "Improved BiGAN training with marginal likelihood equalization", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.CV cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We propose a novel training procedure for improving the performance of\ngenerative adversarial networks (GANs), especially to bidirectional GANs.\nFirst, we enforce that the empirical distribution of the inverse inference\nnetwork matches the prior distribution, which favors the generator network\nreproducibility on the seen samples. Second, we have found that the marginal\nlog-likelihood of the samples shows a severe overrepresentation of a certain\ntype of samples. To address this issue, we propose to train the bidirectional\nGAN using a non-uniform sampling for the mini-batch selection, resulting in\nimproved quality and variety in generated samples measured quantitatively and\nby visual inspection. We illustrate our new procedure with the well-known\nCIFAR10, Fashion MNIST and CelebA datasets.\n", "versions": [{"version": "v1", "created": "Mon, 4 Nov 2019 17:02:20 GMT"}, {"version": "v2", "created": "Sat, 23 May 2020 10:38:03 GMT"}], "update_date": "2020-05-26", "authors_parsed": [["S\u00e1nchez-Mart\u00edn", "Pablo", ""], ["Olmos", "Pablo M.", ""], ["Perez-Cruz", "Fernando", ""]]}, {"id": "1911.01429", "submitter": "Johann Brehmer Mr", "authors": "Kyle Cranmer, Johann Brehmer, Gilles Louppe", "title": "The frontier of simulation-based inference", "comments": "10 pages, 3 figures, proceedings for the Sackler Colloquia at the US\n  National Academy of Sciences. v2: fixed typos. v3: clarified text, added\n  references", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG stat.ME", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Many domains of science have developed complex simulations to describe\nphenomena of interest. While these simulations provide high-fidelity models,\nthey are poorly suited for inference and lead to challenging inverse problems.\nWe review the rapidly developing field of simulation-based inference and\nidentify the forces giving new momentum to the field. Finally, we describe how\nthe frontier is expanding so that a broad audience can appreciate the profound\nchange these developments may have on science.\n", "versions": [{"version": "v1", "created": "Mon, 4 Nov 2019 19:00:00 GMT"}, {"version": "v2", "created": "Thu, 14 Nov 2019 20:16:42 GMT"}, {"version": "v3", "created": "Thu, 2 Apr 2020 14:08:04 GMT"}], "update_date": "2020-04-03", "authors_parsed": [["Cranmer", "Kyle", ""], ["Brehmer", "Johann", ""], ["Louppe", "Gilles", ""]]}, {"id": "1911.01452", "submitter": "Matthew Joseph", "authors": "Kareem Amin, Matthew Joseph, and Jieming Mao", "title": "Pan-Private Uniformity Testing", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.CR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A centrally differentially private algorithm maps raw data to differentially\nprivate outputs. In contrast, a locally differentially private algorithm may\nonly access data through public interaction with data holders, and this\ninteraction must be a differentially private function of the data. We study the\nintermediate model of pan-privacy. Unlike a locally private algorithm, a\npan-private algorithm receives data in the clear. Unlike a centrally private\nalgorithm, the algorithm receives data one element at a time and must maintain\na differentially private internal state while processing this stream.\n  First, we show that pure pan-privacy against multiple intrusions on the\ninternal state is equivalent to sequentially interactive local privacy. Next,\nwe contextualize pan-privacy against a single intrusion by analyzing the sample\ncomplexity of uniformity testing over domain $[k]$. Focusing on the dependence\non $k$, centrally private uniformity testing has sample complexity\n$\\Theta(\\sqrt{k})$, while noninteractive locally private uniformity testing has\nsample complexity $\\Theta(k)$. We show that the sample complexity of pure\npan-private uniformity testing is $\\Theta(k^{2/3})$. By a new $\\Omega(k)$ lower\nbound for the sequentially interactive setting, we also separate pan-private\nfrom sequentially interactive locally private and multi-intrusion pan-private\nuniformity testing.\n", "versions": [{"version": "v1", "created": "Mon, 4 Nov 2019 19:06:29 GMT"}, {"version": "v2", "created": "Fri, 19 Jun 2020 18:16:33 GMT"}, {"version": "v3", "created": "Fri, 17 Jul 2020 13:45:25 GMT"}], "update_date": "2020-07-20", "authors_parsed": [["Amin", "Kareem", ""], ["Joseph", "Matthew", ""], ["Mao", "Jieming", ""]]}, {"id": "1911.01458", "submitter": "Roberto Souza", "authors": "Roberto Souza, Mariana Bento, Nikita Nogovitsyn, Kevin J. Chung, R.\n  Marc Lebel and Richard Frayne", "title": "Dual-domain Cascade of U-nets for Multi-channel Magnetic Resonance Image\n  Reconstruction", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.IV cs.LG physics.med-ph stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The U-net is a deep-learning network model that has been used to solve a\nnumber of inverse problems. In this work, the concatenation of two-element\nU-nets, termed the W-net, operating in k-space (K) and image (I) domains, were\nevaluated for multi-channel magnetic resonance (MR) image reconstruction. The\ntwo element network combinations were evaluated for the four possible\nimage-k-space domain configurations: a) W-net II, b) W-net KK, c) W-net IK, and\nd) W-net KI were evaluated. Selected promising four element networks (WW-nets)\nwere also examined. Two configurations of each network were compared: 1) Each\ncoil channel processed independently, and 2) all channels processed\nsimultaneously. One hundred and eleven volumetric, T1-weighted, 12-channel coil\nk-space datasets were used in the experiments. Normalized root mean squared\nerror, peak signal to noise ratio, visual information fidelity and visual\ninspection were used to assess the reconstructed images against the fully\nsampled reference images. Our results indicated that networks that operate\nsolely in the image domain are better suited when processing individual\nchannels of multi-channel data independently. Dual domain methods are more\nadvantageous when simultaneously reconstructing all channels of multi-channel\ndata. Also, the appropriate cascade of U-nets compared favorably (p < 0.01) to\nthe previously published, state-of-the-art Deep Cascade model in in three out\nof four experiments.\n", "versions": [{"version": "v1", "created": "Mon, 4 Nov 2019 19:23:38 GMT"}], "update_date": "2019-11-06", "authors_parsed": [["Souza", "Roberto", ""], ["Bento", "Mariana", ""], ["Nogovitsyn", "Nikita", ""], ["Chung", "Kevin J.", ""], ["Lebel", "R. Marc", ""], ["Frayne", "Richard", ""]]}, {"id": "1911.01462", "submitter": "Surbhi Goel", "authors": "Surbhi Goel, Sushrut Karmalkar, Adam Klivans", "title": "Time/Accuracy Tradeoffs for Learning a ReLU with respect to Gaussian\n  Marginals", "comments": "To appear in NeurIPS 2019 (Spotlight)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.DS stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the problem of computing the best-fitting ReLU with respect to\nsquare-loss on a training set when the examples have been drawn according to a\nspherical Gaussian distribution (the labels can be arbitrary). Let\n$\\mathsf{opt} < 1$ be the population loss of the best-fitting ReLU. We prove:\n  1. Finding a ReLU with square-loss $\\mathsf{opt} + \\epsilon$ is as hard as\nthe problem of learning sparse parities with noise, widely thought to be\ncomputationally intractable. This is the first hardness result for learning a\nReLU with respect to Gaussian marginals, and our results imply -{\\emph\nunconditionally}- that gradient descent cannot converge to the global minimum\nin polynomial time.\n  2. There exists an efficient approximation algorithm for finding the\nbest-fitting ReLU that achieves error $O(\\mathsf{opt}^{2/3})$. The algorithm\nuses a novel reduction to noisy halfspace learning with respect to $0/1$ loss.\n  Prior work due to Soltanolkotabi [Sol17] showed that gradient descent can\nfind the best-fitting ReLU with respect to Gaussian marginals, if the training\nset is exactly labeled by a ReLU.\n", "versions": [{"version": "v1", "created": "Mon, 4 Nov 2019 19:35:49 GMT"}], "update_date": "2019-11-06", "authors_parsed": [["Goel", "Surbhi", ""], ["Karmalkar", "Sushrut", ""], ["Klivans", "Adam", ""]]}, {"id": "1911.01468", "submitter": "Viktoriia Oliinyk", "authors": "Giulio Morina, Viktoriia Oliinyk, Julian Waton, Ines Marusic and\n  Konstantinos Georgatzis", "title": "Auditing and Achieving Intersectional Fairness in Classification\n  Problems", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CY stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Machine learning algorithms are extensively used to make increasingly more\nconsequential decisions about people, so achieving optimal predictive\nperformance can no longer be the only focus. A particularly important\nconsideration is fairness with respect to race, gender, or any other sensitive\nattribute. This paper studies intersectional fairness, where intersections of\nmultiple sensitive attributes are considered. Prior research has mainly focused\non fairness with respect to a single sensitive attribute, with intersectional\nfairness being comparatively less studied despite its critical importance for\nthe safety of modern machine learning systems. We present a comprehensive\nframework for auditing and achieving intersectional fairness in classification\nproblems: we define a suite of metrics to assess intersectional fairness in the\ndata or model outputs by extending known single-attribute fairness metrics, and\npropose methods for robustly estimating them even when some intersectional\nsubgroups are underrepresented. Furthermore, we develop post-processing\ntechniques to mitigate any detected intersectional bias in a classification\nmodel. Our techniques do not rely on any assumptions regarding the underlying\nmodel and preserve predictive performance at a guaranteed level of fairness.\nFinally, we give guidance on a practical implementation, showing how the\nproposed methods perform on a real-world dataset.\n", "versions": [{"version": "v1", "created": "Mon, 4 Nov 2019 19:55:23 GMT"}, {"version": "v2", "created": "Mon, 8 Jun 2020 16:41:23 GMT"}], "update_date": "2020-06-09", "authors_parsed": [["Morina", "Giulio", ""], ["Oliinyk", "Viktoriia", ""], ["Waton", "Julian", ""], ["Marusic", "Ines", ""], ["Georgatzis", "Konstantinos", ""]]}, {"id": "1911.01469", "submitter": "Andre Wibisono", "authors": "Andre Wibisono", "title": "Proximal Langevin Algorithm: Rapid Convergence Under Isoperimetry", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.DS cs.IT cs.LG math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the Proximal Langevin Algorithm (PLA) for sampling from a\nprobability distribution $\\nu = e^{-f}$ on $\\mathbb{R}^n$ under isoperimetry.\nWe prove a convergence guarantee for PLA in Kullback-Leibler (KL) divergence\nwhen $\\nu$ satisfies log-Sobolev inequality (LSI) and $f$ has bounded second\nand third derivatives. This improves on the result for the Unadjusted Langevin\nAlgorithm (ULA), and matches the fastest known rate for sampling under LSI\n(without Metropolis filter) with a better dependence on the LSI constant. We\nalso prove convergence guarantees for PLA in R\\'enyi divergence of order $q >\n1$ when the biased limit satisfies either LSI or Poincar\\'e inequality.\n", "versions": [{"version": "v1", "created": "Mon, 4 Nov 2019 19:57:38 GMT"}], "update_date": "2019-11-06", "authors_parsed": [["Wibisono", "Andre", ""]]}, {"id": "1911.01477", "submitter": "Farzad Khalvati", "authors": "Khashayar Namdar, Isha Gujrathi, Masoom A. Haider, Farzad Khalvati", "title": "Evolution-based Fine-tuning of CNNs for Prostate Cancer Detection", "comments": "Accepted for the 33rd Conference on Neural Information Processing\n  Systems (NeurIPS 2019), Medical Imaging Meets NEURIPS Workshop", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.IV cs.CV cs.LG q-bio.QM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Convolutional Neural Networks (CNNs) have been used for automated detection\nof prostate cancer where Area Under Receiver Operating Characteristic (ROC)\ncurve (AUC) is usually used as the performance metric. Given that AUC is not\ndifferentiable, common practice is to train the CNN using a loss functions\nbased on other performance metrics such as cross entropy and monitoring AUC to\nselect the best model. In this work, we propose to fine-tune a trained CNN for\nprostate cancer detection using a Genetic Algorithm to achieve a higher AUC.\nOur dataset contained 6-channel Diffusion-Weighted MRI slices of prostate. On a\ncohort of 2,955 training, 1,417 validation, and 1,334 test slices, we reached\ntest AUC of 0.773; a 9.3% improvement compared to the base CNN model.\n", "versions": [{"version": "v1", "created": "Mon, 4 Nov 2019 20:40:29 GMT"}], "update_date": "2019-11-06", "authors_parsed": [["Namdar", "Khashayar", ""], ["Gujrathi", "Isha", ""], ["Haider", "Masoom A.", ""], ["Khalvati", "Farzad", ""]]}, {"id": "1911.01483", "submitter": "Yi Zhu", "authors": "Yi Zhu, Jing Dong", "title": "On Constructing Confidence Region for Model Parameters in Stochastic\n  Gradient Descent via Batch Means", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we study a simple algorithm to construct asymptotically valid\nconfidence regions for model parameters using the batch means method. The main\nidea is to cancel out the covariance matrix which is hard/costly to estimate.\nIn the process of developing the algorithm, we establish process-level\nfunctional central limit theorem for Polyak-Ruppert averaging based stochastic\ngradient descent estimators. We also extend the batch means method to\naccommodate more general batch size specifications.\n", "versions": [{"version": "v1", "created": "Mon, 4 Nov 2019 20:48:30 GMT"}, {"version": "v2", "created": "Fri, 31 Jan 2020 15:13:19 GMT"}], "update_date": "2020-02-03", "authors_parsed": [["Zhu", "Yi", ""], ["Dong", "Jing", ""]]}, {"id": "1911.01484", "submitter": "Brandon Foggo", "authors": "Brandon Foggo, Nanpeng Yu", "title": "Improving Supervised Phase Identification Through the Theory of\n  Information Losses", "comments": "To be published in IEEE Transactions on Smart Grid", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper considers the problem of Phase Identification in power\ndistribution systems. In particular, it focuses on improving supervised\nlearning accuracies by focusing on exploiting some of the problem's information\ntheoretic properties. This focus, along with recent advances in Information\nTheoretic Machine Learning (ITML), helps us to create two new techniques. The\nfirst transforms a bound on information losses into a data selection technique.\nThis is important because phase identification data labels are difficult to\nobtain in practice. The second interprets the properties of distribution\nsystems in the terms of ITML. This allows us to obtain an improvement in the\nrepresentation learned by any classifier applied to the problem. We tested\nthese two techniques experimentally on real datasets and have found that they\nyield phenomenal performance in every case. In the most extreme case, they\nimprove phase identification accuracy from $51.7\\%$ to $97.3\\%$. Furthermore,\nsince many problems share the physical properties of phase identification\nexploited in this paper, the techniques can be applied to a wide range of\nsimilar problems.\n", "versions": [{"version": "v1", "created": "Mon, 4 Nov 2019 20:51:26 GMT"}], "update_date": "2019-11-06", "authors_parsed": [["Foggo", "Brandon", ""], ["Yu", "Nanpeng", ""]]}, {"id": "1911.01485", "submitter": "Yi Chern Tan", "authors": "Yi Chern Tan, L. Elisa Celis", "title": "Assessing Social and Intersectional Biases in Contextualized Word\n  Representations", "comments": "NeurIPS 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.CY cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Social bias in machine learning has drawn significant attention, with work\nranging from demonstrations of bias in a multitude of applications, curating\ndefinitions of fairness for different contexts, to developing algorithms to\nmitigate bias. In natural language processing, gender bias has been shown to\nexist in context-free word embeddings. Recently, contextual word\nrepresentations have outperformed word embeddings in several downstream NLP\ntasks. These word representations are conditioned on their context within a\nsentence, and can also be used to encode the entire sentence. In this paper, we\nanalyze the extent to which state-of-the-art models for contextual word\nrepresentations, such as BERT and GPT-2, encode biases with respect to gender,\nrace, and intersectional identities. Towards this, we propose assessing bias at\nthe contextual word level. This novel approach captures the contextual effects\nof bias missing in context-free word embeddings, yet avoids confounding effects\nthat underestimate bias at the sentence encoding level. We demonstrate evidence\nof bias at the corpus level, find varying evidence of bias in embedding\nassociation tests, show in particular that racial bias is strongly encoded in\ncontextual word models, and observe that bias effects for intersectional\nminorities are exacerbated beyond their constituent minority identities.\nFurther, evaluating bias effects at the contextual word level captures biases\nthat are not captured at the sentence level, confirming the need for our novel\napproach.\n", "versions": [{"version": "v1", "created": "Mon, 4 Nov 2019 20:57:54 GMT"}], "update_date": "2019-11-06", "authors_parsed": [["Tan", "Yi Chern", ""], ["Celis", "L. Elisa", ""]]}, {"id": "1911.01486", "submitter": "Xavier Gitiaux", "authors": "Xavier Gitiaux, Shane A. Maloney, Anna Jungbluth, Carl Shneider, Paul\n  J. Wright, At{\\i}l{\\i}m G\\\"une\\c{s} Baydin, Michel Deudon, Yarin Gal, Alfredo\n  Kalaitzis, Andr\\'es Mu\\~noz-Jaramillo", "title": "Probabilistic Super-Resolution of Solar Magnetograms: Generating Many\n  Explanations and Measuring Uncertainties", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG astro-ph.SR eess.IV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Machine learning techniques have been successfully applied to\nsuper-resolution tasks on natural images where visually pleasing results are\nsufficient. However in many scientific domains this is not adequate and\nestimations of errors and uncertainties are crucial. To address this issue we\npropose a Bayesian framework that decomposes uncertainties into epistemic and\naleatoric uncertainties. We test the validity of our approach by\nsuper-resolving images of the Sun's magnetic field and by generating maps\nmeasuring the range of possible high resolution explanations compatible with a\ngiven low resolution magnetogram.\n", "versions": [{"version": "v1", "created": "Mon, 4 Nov 2019 20:58:32 GMT"}], "update_date": "2019-11-06", "authors_parsed": [["Gitiaux", "Xavier", ""], ["Maloney", "Shane A.", ""], ["Jungbluth", "Anna", ""], ["Shneider", "Carl", ""], ["Wright", "Paul J.", ""], ["Baydin", "At\u0131l\u0131m G\u00fcne\u015f", ""], ["Deudon", "Michel", ""], ["Gal", "Yarin", ""], ["Kalaitzis", "Alfredo", ""], ["Mu\u00f1oz-Jaramillo", "Andr\u00e9s", ""]]}, {"id": "1911.01490", "submitter": "Xavier Gitiaux", "authors": "Anna Jungbluth, Xavier Gitiaux, Shane A.Maloney, Carl Shneider, Paul\n  J. Wright, Alfredo Kalaitzis, Michel Deudon, At{\\i}l{\\i}m G\\\"une\\c{s} Baydin,\n  Yarin Gal, Andr\\'es Mu\\~noz-Jaramillo", "title": "Single-Frame Super-Resolution of Solar Magnetograms: Investigating\n  Physics-Based Metrics \\& Losses", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "astro-ph.SR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Breakthroughs in our understanding of physical phenomena have traditionally\nfollowed improvements in instrumentation. Studies of the magnetic field of the\nSun, and its influence on the solar dynamo and space weather events, have\nbenefited from improvements in resolution and measurement frequency of new\ninstruments. However, in order to fully understand the solar cycle,\nhigh-quality data across time-scales longer than the typical lifespan of a\nsolar instrument are required. At the moment, discrepancies between measurement\nsurveys prevent the combined use of all available data. In this work, we show\nthat machine learning can help bridge the gap between measurement surveys by\nlearning to \\textbf{super-resolve} low-resolution magnetic field images and\n\\textbf{translate} between characteristics of contemporary instruments in\norbit. We also introduce the notion of physics-based metrics and losses for\nsuper-resolution to preserve underlying physics and constrain the solution\nspace of possible super-resolution outputs.\n", "versions": [{"version": "v1", "created": "Mon, 4 Nov 2019 21:16:20 GMT"}], "update_date": "2019-11-06", "authors_parsed": [["Jungbluth", "Anna", ""], ["Gitiaux", "Xavier", ""], ["Maloney", "Shane A.", ""], ["Shneider", "Carl", ""], ["Wright", "Paul J.", ""], ["Kalaitzis", "Alfredo", ""], ["Deudon", "Michel", ""], ["Baydin", "At\u0131l\u0131m G\u00fcne\u015f", ""], ["Gal", "Yarin", ""], ["Mu\u00f1oz-Jaramillo", "Andr\u00e9s", ""]]}, {"id": "1911.01497", "submitter": "Vikas Raunak", "authors": "Vikas Raunak, Vaibhav Kumar and Florian Metze", "title": "On Compositionality in Neural Machine Translation", "comments": "Accepted at Context and Compositionality Workshop, NeurIPS 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We investigate two specific manifestations of compositionality in Neural\nMachine Translation (NMT) : (1) Productivity - the ability of the model to\nextend its predictions beyond the observed length in training data and (2)\nSystematicity - the ability of the model to systematically recombine known\nparts and rules. We evaluate a standard Sequence to Sequence model on tests\ndesigned to assess these two properties in NMT. We quantitatively demonstrate\nthat inadequate temporal processing, in the form of poor encoder\nrepresentations is a bottleneck for both Productivity and Systematicity. We\npropose a simple pre-training mechanism which alleviates model performance on\nthe two properties and leads to a significant improvement in BLEU scores.\n", "versions": [{"version": "v1", "created": "Mon, 4 Nov 2019 21:31:36 GMT"}, {"version": "v2", "created": "Thu, 14 Nov 2019 21:18:08 GMT"}, {"version": "v3", "created": "Sat, 14 Dec 2019 15:10:47 GMT"}], "update_date": "2019-12-17", "authors_parsed": [["Raunak", "Vikas", ""], ["Kumar", "Vaibhav", ""], ["Metze", "Florian", ""]]}, {"id": "1911.01509", "submitter": "Karthikeyan Natesan Ramamurthy", "authors": "Moninder Singh and Karthikeyan Natesan Ramamurthy", "title": "Understanding racial bias in health using the Medical Expenditure Panel\n  Survey data", "comments": "8 pages, 8 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CY stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Over the years, several studies have demonstrated that there exist\nsignificant disparities in health indicators in the United States population\nacross various groups. Healthcare expense is used as a proxy for health in\nalgorithms that drive healthcare systems and this exacerbates the existing\nbias. In this work, we focus on the presence of racial bias in health\nindicators in the publicly available, and nationally representative Medical\nExpenditure Panel Survey (MEPS) data. We show that predictive models for care\nmanagement trained using this data inherit this bias. Finally, we demonstrate\nthat this inherited bias can be reduced significantly using simple mitigation\ntechniques.\n", "versions": [{"version": "v1", "created": "Mon, 4 Nov 2019 22:14:52 GMT"}], "update_date": "2019-11-06", "authors_parsed": [["Singh", "Moninder", ""], ["Ramamurthy", "Karthikeyan Natesan", ""]]}, {"id": "1911.01521", "submitter": "Manuel Lladser", "authors": "Richard D. Tillquist and Manuel E. Lladser", "title": "Multilateration of Random Networks with Community Structure", "comments": "22 pages, 3 figures, 8 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.CO cs.DM cs.LG math.PR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The minimal number of nodes required to multilaterate a network endowed with\ngeodesic distance (i.e., to uniquely identify all nodes based on shortest path\ndistances to the selected nodes) is called its metric dimension. This quantity\nis related to a useful technique for embedding graphs in low-dimensional\nEuclidean spaces and representing the nodes of a graph numerically for\ndownstream analyses such as vertex classification via machine learning. While\nmetric dimension has been studied for many kinds of graphs, its behavior on the\nStochastic Block Model (SBM) ensemble has not. The simple community structure\nof graphs in this ensemble make them interesting in a variety of contexts. Here\nwe derive probabilistic bounds for the metric dimension of random graphs\ngenerated according to the SBM, and describe algorithms of varying complexity\nto find---with high probability---subsets of nodes for multilateration. Our\nmethods are tested on SBM ensembles with parameters extracted from real-world\nnetworks. We show that our methods scale well with increasing network size as\ncompared to the state-of-the-art Information Content Heuristic algorithm for\nmetric dimension approximation.\n", "versions": [{"version": "v1", "created": "Mon, 4 Nov 2019 22:57:21 GMT"}], "update_date": "2019-11-06", "authors_parsed": [["Tillquist", "Richard D.", ""], ["Lladser", "Manuel E.", ""]]}, {"id": "1911.01523", "submitter": "Shromona Ghosh", "authors": "Shromona Ghosh, Yash Vardhan Pant, Hadi Ravanbakhsh, and Sanjit A.\n  Seshia", "title": "Counterexample-Guided Synthesis of Perception Models and Control", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.SY cs.LG cs.LO cs.RO cs.SY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent advances in learning-based perception systems have led to drastic\nimprovements in the performance of robotic systems like autonomous vehicles and\nsurgical robots. These perception systems, however, are hard to analyze and\nerrors in them can propagate to cause catastrophic failures. In this paper, we\nconsider the problem of synthesizing safe and robust controllers for robotic\nsystems which rely on complex perception modules for feedback. We propose a\ncounterexample-guided synthesis framework that iteratively builds simple\nsurrogate models of the complex perception module and enables us to find safe\ncontrol policies. The framework uses a falsifier to find counterexamples, or\ntraces of the systems that violate a safety property, to extract information\nthat enables efficient modeling of the perception modules and errors in it.\nThese models are then used to synthesize controllers that are robust to errors\nin perception. If the resulting policy is not safe, we gather new\ncounterexamples. By repeating the process, we eventually find a controller\nwhich can keep the system safe even when there is a perception failure. We\ndemonstrate our framework on two scenarios in simulation, namely lane keeping\nand automatic braking, and show that it generates controllers that are safe, as\nwell as a simpler model of a deep neural network-based perception system that\ncan provide meaningful insight into operations of the perception system.\n", "versions": [{"version": "v1", "created": "Mon, 4 Nov 2019 23:03:32 GMT"}, {"version": "v2", "created": "Fri, 8 Nov 2019 16:05:27 GMT"}, {"version": "v3", "created": "Fri, 14 May 2021 02:25:24 GMT"}], "update_date": "2021-05-17", "authors_parsed": [["Ghosh", "Shromona", ""], ["Pant", "Yash Vardhan", ""], ["Ravanbakhsh", "Hadi", ""], ["Seshia", "Sanjit A.", ""]]}, {"id": "1911.01529", "submitter": "Jan Blumenkamp", "authors": "Jan Blumenkamp, Andreas Baude, Tim Laue", "title": "Closing the Reality Gap with Unsupervised Sim-to-Real Image Translation", "comments": "Accepted to RoboCup Symposium 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV cs.RO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep learning approaches have become the standard solution to many problems\nin computer vision and robotics, but obtaining sufficient training data in high\nenough quality is challenging, as human labor is error prone, time consuming,\nand expensive. Solutions based on simulation have become more popular in recent\nyears, but the gap between simulation and reality is still a major issue. In\nthis paper, we introduce a novel method for augmenting synthetic image data\nthrough unsupervised image-to-image translation by applying the style of real\nworld images to simulated images with open source frameworks. The generated\ndataset is combined with conventional augmentation methods and is then applied\nto a neural network model running in real-time on autonomous soccer robots. Our\nevaluation shows a significant improvement compared to models trained on images\ngenerated entirely in simulation.\n", "versions": [{"version": "v1", "created": "Mon, 4 Nov 2019 23:17:03 GMT"}, {"version": "v2", "created": "Tue, 15 Jun 2021 10:39:20 GMT"}], "update_date": "2021-06-16", "authors_parsed": [["Blumenkamp", "Jan", ""], ["Baude", "Andreas", ""], ["Laue", "Tim", ""]]}, {"id": "1911.01533", "submitter": "Haoqi Li", "authors": "Haoqi Li, Ming Tu, Jing Huang, Shrikanth Narayanan, Panayiotis\n  Georgiou", "title": "Speaker-invariant Affective Representation Learning via Adversarial\n  Training", "comments": "Accepted by ICASSP 2020; 5 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.AS cs.LG cs.SD", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Representation learning for speech emotion recognition is challenging due to\nlabeled data sparsity issue and lack of gold standard references. In addition,\nthere is much variability from input speech signals, human subjective\nperception of the signals and emotion label ambiguity. In this paper, we\npropose a machine learning framework to obtain speech emotion representations\nby limiting the effect of speaker variability in the speech signals.\nSpecifically, we propose to disentangle the speaker characteristics from\nemotion through an adversarial training network in order to better represent\nemotion. Our method combines the gradient reversal technique with an entropy\nloss function to remove such speaker information. Our approach is evaluated on\nboth IEMOCAP and CMU-MOSEI datasets. We show that our method improves speech\nemotion classification and increases generalization to unseen speakers.\n", "versions": [{"version": "v1", "created": "Mon, 4 Nov 2019 23:35:19 GMT"}, {"version": "v2", "created": "Tue, 11 Feb 2020 01:55:34 GMT"}], "update_date": "2020-02-12", "authors_parsed": [["Li", "Haoqi", ""], ["Tu", "Ming", ""], ["Huang", "Jing", ""], ["Narayanan", "Shrikanth", ""], ["Georgiou", "Panayiotis", ""]]}, {"id": "1911.01535", "submitter": "Xuhui Fan", "authors": "Xuhui Fan, Bin Li, Scott Anthony Sisson, Caoyuan Li, Ling Chen", "title": "Scalable Deep Generative Relational Models with High-Order Node\n  Dependence", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a probabilistic framework for modelling and exploring the latent\nstructure of relational data. Given feature information for the nodes in a\nnetwork, the scalable deep generative relational model (SDREM) builds a deep\nnetwork architecture that can approximate potential nonlinear mappings between\nnodes' feature information and the nodes' latent representations. Our\ncontribution is two-fold: (1) We incorporate high-order neighbourhood structure\ninformation to generate the latent representations at each node, which vary\nsmoothly over the network. (2) Due to the Dirichlet random variable structure\nof the latent representations, we introduce a novel data augmentation trick\nwhich permits efficient Gibbs sampling. The SDREM can be used for large sparse\nnetworks as its computational cost scales with the number of positive links. We\ndemonstrate its competitive performance through improved link prediction\nperformance on a range of real-world datasets.\n", "versions": [{"version": "v1", "created": "Mon, 4 Nov 2019 23:36:09 GMT"}], "update_date": "2019-11-06", "authors_parsed": [["Fan", "Xuhui", ""], ["Li", "Bin", ""], ["Sisson", "Scott Anthony", ""], ["Li", "Caoyuan", ""], ["Chen", "Ling", ""]]}, {"id": "1911.01537", "submitter": "Negin Musavi", "authors": "Negin Musavi, Dawei Sun, Sayan Mitra, Geir Dullerud, Sanjay Shakkottai", "title": "Verification and Parameter Synthesis for Stochastic Systems using\n  Optimistic Optimization", "comments": "24 pages, 7 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.FL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present an algorithm for formal verification and parameter synthesis of\ncontinuous state-space Markov chains. This class of problems captures the\ndesign and analysis of a wide variety of autonomous and cyber-physical systems\ndefined by nonlinear and black-box modules. In order to solve these problems,\none has to maximize certain probabilistic objective functions overall choices\nof initial states and parameters. In this paper, we identify the assumptions\nthat make it possible to view this problem as a multi-armed bandit problem.\nBased on this fresh perspective, we propose an algorithm (HOO-MB) for solving\nthe problem that carefully instantiates an existing bandit algorithm --\nHierarchical Optimistic Optimization -- with appropriate parameters. As a\nconsequence, we obtain theoretical regret bounds on sample efficiency of our\nsolution that depends on key problem parameters like smoothness,\nnear-optimality dimension, and batch size. The batch size parameter enables us\nto strike a balance between the sample efficiency and the memory usage of the\nalgorithm. Our experiments, using the tool HooVer, suggest that the approach\nscales to realistic-sized problems and is often more sample-efficient compared\nto PlasmaLab -- a leading tool for verification of stochastic systems.\nSpecifically, HooVer has distinct advantages in analyzing models in which the\nobjective function has sharp slopes. In addition, HooVer shows promising\nbehavior in parameter synthesis for a linear quadratic regulator (LQR) example.\n", "versions": [{"version": "v1", "created": "Mon, 4 Nov 2019 23:46:52 GMT"}, {"version": "v2", "created": "Thu, 3 Dec 2020 18:29:50 GMT"}], "update_date": "2020-12-04", "authors_parsed": [["Musavi", "Negin", ""], ["Sun", "Dawei", ""], ["Mitra", "Sayan", ""], ["Dullerud", "Geir", ""], ["Shakkottai", "Sanjay", ""]]}, {"id": "1911.01538", "submitter": "Adi Hanuka", "authors": "A. Hanuka, J. Duris, J. Shtalenkova, D. Kennedy, A. Edelen, D. Ratner,\n  X. Huang", "title": "Online tuning and light source control using a physics-informed Gaussian\n  process Adi", "comments": null, "journal-ref": "https://ml4physicalsciences.github.io/2019/files/NeurIPS_ML4PS_2019_85.pdf", "doi": null, "report-no": null, "categories": "physics.acc-ph cs.LG physics.comp-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Operating large-scale scientific facilities often requires fast tuning and\nrobust control in a high dimensional space. In this paper we introduce a new\nphysics-informed optimization algorithm based on Gaussian process regression.\nOur method takes advantage of the existing domain knowledge in the form of\nrealizations of a physics model of the observed system. We have applied a\nphysics-informed Gaussian Process method experimentally at the SPEAR3 storage\nring to demonstrate online accelerator optimization. This method outperforms\nGaussian Process trained on data as well as the standard approach routinely\nused for operation, in terms of convergence speed and optimal point. The\nproposed method could be applicable to automatic tuning and control of other\ncomplex systems, without a prerequisite for any observed data.\n", "versions": [{"version": "v1", "created": "Mon, 4 Nov 2019 23:50:23 GMT"}], "update_date": "2020-09-09", "authors_parsed": [["Hanuka", "A.", ""], ["Duris", "J.", ""], ["Shtalenkova", "J.", ""], ["Kennedy", "D.", ""], ["Edelen", "A.", ""], ["Ratner", "D.", ""], ["Huang", "X.", ""]]}, {"id": "1911.01545", "submitter": "Forough Arabshahi", "authors": "Forough Arabshahi, Zhichu Lu, Pranay Mundra, Sameer Singh, Animashree\n  Anandkumar", "title": "Compositional Generalization with Tree Stack Memory Units", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study compositional generalization, viz., the problem of zero-shot\ngeneralization to novel compositions of concepts in a domain. Standard neural\nnetworks fail to a large extent on compositional learning. We propose Tree\nStack Memory Units (Tree-SMU) to enable strong compositional generalization.\nTree-SMU is a recursive neural network with Stack Memory Units (\\SMU s), a\nnovel memory augmented neural network whose memory has a differentiable stack\nstructure. Each SMU in the tree architecture learns to read from its stack and\nto write to it by combining the stacks and states of its children through\ngating. The stack helps capture long-range dependencies in the problem domain,\nthereby enabling compositional generalization. Additionally, the stack also\npreserves the ordering of each node's descendants, thereby retaining locality\non the tree. We demonstrate strong empirical results on two mathematical\nreasoning benchmarks. We use four compositionality tests to assess the\ngeneralization performance of Tree-SMU and show that it enables accurate\ncompositional generalization compared to strong baselines such as Transformers\nand Tree-LSTMs.\n", "versions": [{"version": "v1", "created": "Tue, 5 Nov 2019 00:27:03 GMT"}, {"version": "v2", "created": "Fri, 8 Nov 2019 16:17:52 GMT"}, {"version": "v3", "created": "Mon, 24 Feb 2020 04:19:53 GMT"}, {"version": "v4", "created": "Mon, 15 Jun 2020 16:50:58 GMT"}, {"version": "v5", "created": "Fri, 16 Oct 2020 00:24:06 GMT"}], "update_date": "2020-10-19", "authors_parsed": [["Arabshahi", "Forough", ""], ["Lu", "Zhichu", ""], ["Mundra", "Pranay", ""], ["Singh", "Sameer", ""], ["Anandkumar", "Animashree", ""]]}, {"id": "1911.01546", "submitter": "Ramtin Keramati", "authors": "Ramtin Keramati, Christoph Dann, Alex Tamkin, Emma Brunskill", "title": "Being Optimistic to Be Conservative: Quickly Learning a CVaR Policy", "comments": null, "journal-ref": "Thirty-Fourth AAAI Conference on Artificial Intelligence (AAAI\n  2020)", "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  While maximizing expected return is the goal in most reinforcement learning\napproaches, risk-sensitive objectives such as conditional value at risk (CVaR)\nare more suitable for many high-stakes applications. However, relatively little\nis known about how to explore to quickly learn policies with good CVaR. In this\npaper, we present the first algorithm for sample-efficient learning of\nCVaR-optimal policies in Markov decision processes based on the optimism in the\nface of uncertainty principle. This method relies on a novel optimistic version\nof the distributional Bellman operator that moves probability mass from the\nlower to the upper tail of the return distribution. We prove asymptotic\nconvergence and optimism of this operator for the tabular policy evaluation\ncase. We further demonstrate that our algorithm finds CVaR-optimal policies\nsubstantially faster than existing baselines in several simulated environments\nwith discrete and continuous state spaces.\n", "versions": [{"version": "v1", "created": "Tue, 5 Nov 2019 00:28:07 GMT"}, {"version": "v2", "created": "Thu, 2 Apr 2020 19:25:02 GMT"}], "update_date": "2020-04-06", "authors_parsed": [["Keramati", "Ramtin", ""], ["Dann", "Christoph", ""], ["Tamkin", "Alex", ""], ["Brunskill", "Emma", ""]]}, {"id": "1911.01551", "submitter": "Sedigheh Mahdavi", "authors": "Shima Khoshraftar, Sedigheh Mahdavi, Aijun An, Yonggang Hu, Junfeng\n  Liu", "title": "Dynamic Graph Embedding via LSTM History Tracking", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.SI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Many real world networks are very large and constantly change over time.\nThese dynamic networks exist in various domains such as social networks,\ntraffic networks and biological interactions. To handle large dynamic networks\nin downstream applications such as link prediction and anomaly detection, it is\nessential for such networks to be transferred into a low dimensional space.\nRecently, network embedding, a technique that converts a large graph into a\nlow-dimensional representation, has become increasingly popular due to its\nstrength in preserving the structure of a network. Efficient dynamic network\nembedding, however, has not yet been fully explored. In this paper, we present\na dynamic network embedding method that integrates the history of nodes over\ntime into the current state of nodes. The key contribution of our work is 1)\ngenerating dynamic network embedding by combining both dynamic and static node\ninformation 2) tracking history of neighbors of nodes using LSTM 3)\nsignificantly decreasing the time and memory by training an autoencoder LSTM\nmodel using temporal walks rather than adjacency matrices of graphs which are\nthe common practice. We evaluate our method in multiple applications such as\nanomaly detection, link prediction and node classification in datasets from\nvarious domains.\n", "versions": [{"version": "v1", "created": "Tue, 5 Nov 2019 00:47:29 GMT"}], "update_date": "2019-11-06", "authors_parsed": [["Khoshraftar", "Shima", ""], ["Mahdavi", "Sedigheh", ""], ["An", "Aijun", ""], ["Hu", "Yonggang", ""], ["Liu", "Junfeng", ""]]}, {"id": "1911.01559", "submitter": "Ren Pang", "authors": "Ren Pang, Hua Shen, Xinyang Zhang, Shouling Ji, Yevgeniy Vorobeychik,\n  Xiapu Luo, Alex Liu, Ting Wang", "title": "A Tale of Evil Twins: Adversarial Inputs versus Poisoned Models", "comments": "Accepted as a full paper at ACM CCS 2020", "journal-ref": null, "doi": "10.1145/3372297.3417253", "report-no": null, "categories": "cs.LG cs.CR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Despite their tremendous success in a range of domains, deep learning systems\nare inherently susceptible to two types of manipulations: adversarial inputs --\nmaliciously crafted samples that deceive target deep neural network (DNN)\nmodels, and poisoned models -- adversely forged DNNs that misbehave on\npre-defined inputs. While prior work has intensively studied the two attack\nvectors in parallel, there is still a lack of understanding about their\nfundamental connections: what are the dynamic interactions between the two\nattack vectors? what are the implications of such interactions for optimizing\nexisting attacks? what are the potential countermeasures against the enhanced\nattacks? Answering these key questions is crucial for assessing and mitigating\nthe holistic vulnerabilities of DNNs deployed in realistic settings.\n  Here we take a solid step towards this goal by conducting the first\nsystematic study of the two attack vectors within a unified framework.\nSpecifically, (i) we develop a new attack model that jointly optimizes\nadversarial inputs and poisoned models; (ii) with both analytical and empirical\nevidence, we reveal that there exist intriguing \"mutual reinforcement\" effects\nbetween the two attack vectors -- leveraging one vector significantly amplifies\nthe effectiveness of the other; (iii) we demonstrate that such effects enable a\nlarge design spectrum for the adversary to enhance the existing attacks that\nexploit both vectors (e.g., backdoor attacks), such as maximizing the attack\nevasiveness with respect to various detection methods; (iv) finally, we discuss\npotential countermeasures against such optimized attacks and their technical\nchallenges, pointing to several promising research directions.\n", "versions": [{"version": "v1", "created": "Tue, 5 Nov 2019 01:32:57 GMT"}, {"version": "v2", "created": "Fri, 15 May 2020 22:14:26 GMT"}, {"version": "v3", "created": "Sat, 21 Nov 2020 04:54:13 GMT"}], "update_date": "2020-11-24", "authors_parsed": [["Pang", "Ren", ""], ["Shen", "Hua", ""], ["Zhang", "Xinyang", ""], ["Ji", "Shouling", ""], ["Vorobeychik", "Yevgeniy", ""], ["Luo", "Xiapu", ""], ["Liu", "Alex", ""], ["Wang", "Ting", ""]]}, {"id": "1911.01562", "submitter": "Bharathan Balaji", "authors": "Bharathan Balaji, Sunil Mallya, Sahika Genc, Saurabh Gupta, Leo Dirac,\n  Vineet Khare, Gourav Roy, Tao Sun, Yunzhe Tao, Brian Townsend, Eddie Calleja,\n  Sunil Muralidhara, Dhanasekar Karuppasamy", "title": "DeepRacer: Educational Autonomous Racing Platform for Experimentation\n  with Sim2Real Reinforcement Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.RO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  DeepRacer is a platform for end-to-end experimentation with RL and can be\nused to systematically investigate the key challenges in developing intelligent\ncontrol systems. Using the platform, we demonstrate how a 1/18th scale car can\nlearn to drive autonomously using RL with a monocular camera. It is trained in\nsimulation with no additional tuning in physical world and demonstrates: 1)\nformulation and solution of a robust reinforcement learning algorithm, 2)\nnarrowing the reality gap through joint perception and dynamics, 3) distributed\non-demand compute architecture for training optimal policies, and 4) a robust\nevaluation method to identify when to stop training. It is the first successful\nlarge-scale deployment of deep reinforcement learning on a robotic control\nagent that uses only raw camera images as observations and a model-free\nlearning method to perform robust path planning. We open source our code and\nvideo demo on GitHub: https://git.io/fjxoJ.\n", "versions": [{"version": "v1", "created": "Tue, 5 Nov 2019 01:40:42 GMT"}], "update_date": "2019-11-06", "authors_parsed": [["Balaji", "Bharathan", ""], ["Mallya", "Sunil", ""], ["Genc", "Sahika", ""], ["Gupta", "Saurabh", ""], ["Dirac", "Leo", ""], ["Khare", "Vineet", ""], ["Roy", "Gourav", ""], ["Sun", "Tao", ""], ["Tao", "Yunzhe", ""], ["Townsend", "Brian", ""], ["Calleja", "Eddie", ""], ["Muralidhara", "Sunil", ""], ["Karuppasamy", "Dhanasekar", ""]]}, {"id": "1911.01565", "submitter": "Yadan Luo", "authors": "Zijian Wang, Zheng Zhang, Yadan Luo, Zi Huang", "title": "Deep Collaborative Discrete Hashing with Semantic-Invariant Structure", "comments": null, "journal-ref": "SIGIR 2019", "doi": null, "report-no": null, "categories": "cs.IR cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Existing deep hashing approaches fail to fully explore semantic correlations\nand neglect the effect of linguistic context on visual attention learning,\nleading to inferior performance. This paper proposes a dual-stream learning\nframework, dubbed Deep Collaborative Discrete Hashing (DCDH), which constructs\na discriminative common discrete space by collaboratively incorporating the\nshared and individual semantics deduced from visual features and semantic\nlabels. Specifically, the context-aware representations are generated by\nemploying the outer product of visual embeddings and semantic encodings.\nMoreover, we reconstruct the labels and introduce the focal loss to take\nadvantage of frequent and rare concepts. The common binary code space is built\non the joint learning of the visual representations attended by language, the\nsemantic-invariant structure construction and the label distribution\ncorrection. Extensive experiments demonstrate the superiority of our method.\n", "versions": [{"version": "v1", "created": "Tue, 5 Nov 2019 01:46:52 GMT"}], "update_date": "2019-11-06", "authors_parsed": [["Wang", "Zijian", ""], ["Zhang", "Zheng", ""], ["Luo", "Yadan", ""], ["Huang", "Zi", ""]]}, {"id": "1911.01575", "submitter": "Anant Raj", "authors": "Anant Raj, Cameron Musco and Lester Mackey", "title": "Importance Sampling via Local Sensitivity", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.OC cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Given a loss function $F:\\mathcal{X} \\rightarrow \\R^+$ that can be written as\nthe sum of losses over a large set of inputs $a_1,\\ldots, a_n$, it is often\ndesirable to approximate $F$ by subsampling the input points. Strong\ntheoretical guarantees require taking into account the importance of each\npoint, measured by how much its individual loss contributes to $F(x)$.\nMaximizing this importance over all $x \\in \\mathcal{X}$ yields the\n\\emph{sensitivity score} of $a_i$. Sampling with probabilities proportional to\nthese scores gives strong guarantees, allowing one to approximately minimize of\n$F$ using just the subsampled points.\n  Unfortunately, sensitivity sampling is difficult to apply since (1) it is\nunclear how to efficiently compute the sensitivity scores and (2) the sample\nsize required is often impractically large. To overcome both obstacles we\nintroduce \\emph{local sensitivity}, which measures data point importance in a\nball around some center $x_0$. We show that the local sensitivity can be\nefficiently estimated using the \\emph{leverage scores} of a quadratic\napproximation to $F$ and that the sample size required to approximate $F$\naround $x_0$ can be bounded. We propose employing local sensitivity sampling in\nan iterative optimization method and analyze its convergence when $F$ is smooth\nand convex.\n", "versions": [{"version": "v1", "created": "Mon, 4 Nov 2019 03:59:58 GMT"}, {"version": "v2", "created": "Thu, 19 Mar 2020 13:53:48 GMT"}], "update_date": "2020-03-20", "authors_parsed": [["Raj", "Anant", ""], ["Musco", "Cameron", ""], ["Mackey", "Lester", ""]]}, {"id": "1911.01599", "submitter": "Nikolai Rozanov", "authors": "Edward Collins, Nikolai Rozanov, Bingbing Zhang", "title": "LIDA: Lightweight Interactive Dialogue Annotator", "comments": "9 pages, 7 figures, 1 table, EMNLP 2019", "journal-ref": "ACL, EMNLP(D19-3021), 121--126, (2019)", "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Dialogue systems have the potential to change how people interact with\nmachines but are highly dependent on the quality of the data used to train\nthem. It is therefore important to develop good dialogue annotation tools which\ncan improve the speed and quality of dialogue data annotation. With this in\nmind, we introduce LIDA, an annotation tool designed specifically for\nconversation data. As far as we know, LIDA is the first dialogue annotation\nsystem that handles the entire dialogue annotation pipeline from raw text, as\nmay be the output of transcription services, to structured conversation data.\nFurthermore it supports the integration of arbitrary machine learning models as\nannotation recommenders and also has a dedicated interface to resolve\ninter-annotator disagreements such as after crowdsourcing annotations for a\ndataset. LIDA is fully open source, documented and publicly available [\nhttps://github.com/Wluper/lida ]\n", "versions": [{"version": "v1", "created": "Tue, 5 Nov 2019 03:49:20 GMT"}], "update_date": "2019-11-06", "authors_parsed": [["Collins", "Edward", ""], ["Rozanov", "Nikolai", ""], ["Zhang", "Bingbing", ""]]}, {"id": "1911.01608", "submitter": "James Ferlez", "authors": "James Ferlez and Yasser Shoukry", "title": "AReN: Assured ReLU NN Architecture for Model Predictive Control of LTI\n  Systems", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.SY eess.SY math.OC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we consider the problem of automatically designing a Rectified\nLinear Unit (ReLU) Neural Network (NN) architecture that is sufficient to\nimplement the optimal Model Predictive Control (MPC) strategy for an LTI system\nwith quadratic cost. Specifically, we propose AReN, an algorithm to generate\nAssured ReLU Architectures. AReN takes as input an LTI system with quadratic\ncost specification, and outputs a ReLU NN architecture with the assurance that\nthere exist network weights that exactly implement the associated MPC\ncontroller. AReN thus offers new insight into the design of ReLU NN\narchitectures for the control of LTI systems: instead of training a\nheuristically chosen NN architecture on data -- or iterating over many\narchitectures until a suitable one is found -- AReN can suggest an adequate NN\narchitecture before training begins. While several previous works were inspired\nby the fact that both ReLU NN controllers and optimal MPC controller are both\nContinuous, Piecewise-Linear (CPWL) functions, exploiting this similarity to\ndesign NN architectures with correctness guarantees has remained elusive. AReN\nachieves this using two novel features. First, we reinterpret a recent result\nabout the implementation of CPWL functions via ReLU NNs to show that a CPWL\nfunction may be implemented by a ReLU architecture that is determined by the\nnumber of distinct affine regions in the function. Second, we show that we can\nefficiently over-approximate the number of affine regions in the optimal MPC\ncontroller without solving the MPC problem exactly. Together, these results\nconnect the MPC problem to a ReLU NN implementation without explicitly solving\nthe MPC and directly translates this feature to a ReLU NN architecture that\ncomes with the assurance that it can implement the MPC controller. We show\nthrough numerical results the effectiveness of AReN in designing an NN\narchitecture.\n", "versions": [{"version": "v1", "created": "Tue, 5 Nov 2019 04:08:59 GMT"}], "update_date": "2019-11-06", "authors_parsed": [["Ferlez", "James", ""], ["Shoukry", "Yasser", ""]]}, {"id": "1911.01612", "submitter": "Liyao Lyu", "authors": "Jingrun Chen and Rui Du and Panchi Li and Liyao Lyu", "title": "Quasi-Monte Carlo sampling for machine-learning partial differential\n  equations", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.NA cs.LG cs.NA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Solving partial differential equations in high dimensions by deep neural\nnetwork has brought significant attentions in recent years. In many scenarios,\nthe loss function is defined as an integral over a high-dimensional domain.\nMonte-Carlo method, together with the deep neural network, is used to overcome\nthe curse of dimensionality, while classical methods fail. Often, a deep neural\nnetwork outperforms classical numerical methods in terms of both accuracy and\nefficiency. In this paper, we propose to use quasi-Monte Carlo sampling,\ninstead of Monte-Carlo method to approximate the loss function. To demonstrate\nthe idea, we conduct numerical experiments in the framework of deep Ritz method\nproposed by Weinan E and Bing Yu. For the same accuracy requirement, it is\nobserved that quasi-Monte Carlo sampling reduces the size of training data set\nby more than two orders of magnitude compared to that of MC method. Under some\nassumptions, we prove that quasi-Monte Carlo sampling together with the deep\nneural network generates a convergent series with rate proportional to the\napproximation accuracy of quasi-Monte Carlo method for numerical integration.\nNumerically the fitted convergence rate is a bit smaller, but the proposed\napproach always outperforms Monte Carlo method. It is worth mentioning that the\nconvergence analysis is generic whenever a loss function is approximated by the\nquasi-Monte Carlo method, although observations here are based on deep Ritz\nmethod.\n", "versions": [{"version": "v1", "created": "Tue, 5 Nov 2019 04:20:50 GMT"}], "update_date": "2019-11-06", "authors_parsed": [["Chen", "Jingrun", ""], ["Du", "Rui", ""], ["Li", "Panchi", ""], ["Lyu", "Liyao", ""]]}, {"id": "1911.01625", "submitter": "Wenye Li", "authors": "Wenye Li and Senyue Hao", "title": "Sparse Lifting of Dense Vectors: Unifying Word and Sentence\n  Representations", "comments": "11 pages, 4 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  As the first step in automated natural language processing, representing\nwords and sentences is of central importance and has attracted significant\nresearch attention. Different approaches, from the early one-hot and\nbag-of-words representation to more recent distributional dense and sparse\nrepresentations, were proposed. Despite the successful results that have been\nachieved, such vectors tend to consist of uninterpretable components and face\nnontrivial challenge in both memory and computational requirement in practical\napplications. In this paper, we designed a novel representation model that\nprojects dense word vectors into a higher dimensional space and favors a highly\nsparse and binary representation of word vectors with potentially interpretable\ncomponents, while trying to maintain pairwise inner products between original\nvectors as much as possible. Computationally, our model is relaxed as a\nsymmetric non-negative matrix factorization problem which admits a fast yet\neffective solution. In a series of empirical evaluations, the proposed model\nexhibited consistent improvement and high potential in practical applications.\n", "versions": [{"version": "v1", "created": "Tue, 5 Nov 2019 05:28:05 GMT"}], "update_date": "2019-11-06", "authors_parsed": [["Li", "Wenye", ""], ["Hao", "Senyue", ""]]}, {"id": "1911.01629", "submitter": "Mahaveer Jain", "authors": "Mahaveer Jain, Kjell Schubert, Jay Mahadeokar, Ching-Feng Yeh,\n  Kaustubh Kalgaonkar, Anuroop Sriram, Christian Fuegen, Michael L. Seltzer", "title": "RNN-T For Latency Controlled ASR With Improved Beam Search", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG eess.AS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Neural transducer-based systems such as RNN Transducers (RNN-T) for automatic\nspeech recognition (ASR) blend the individual components of a traditional\nhybrid ASR systems (acoustic model, language model, punctuation model, inverse\ntext normalization) into one single model. This greatly simplifies training and\ninference and hence makes RNN-T a desirable choice for ASR systems. In this\nwork, we investigate use of RNN-T in applications that require a tune-able\nlatency budget during inference time. We also improved the decoding speed of\nthe originally proposed RNN-T beam search algorithm. We evaluated our proposed\nsystem on English videos ASR dataset and show that neural RNN-T models can\nachieve comparable WER and better computational efficiency compared to a well\ntuned hybrid ASR baseline.\n", "versions": [{"version": "v1", "created": "Tue, 5 Nov 2019 05:46:52 GMT"}, {"version": "v2", "created": "Thu, 16 Jan 2020 15:45:47 GMT"}], "update_date": "2020-01-17", "authors_parsed": [["Jain", "Mahaveer", ""], ["Schubert", "Kjell", ""], ["Mahadeokar", "Jay", ""], ["Yeh", "Ching-Feng", ""], ["Kalgaonkar", "Kaustubh", ""], ["Sriram", "Anuroop", ""], ["Fuegen", "Christian", ""], ["Seltzer", "Michael L.", ""]]}, {"id": "1911.01641", "submitter": "Vladimir Kobzar", "authors": "Vladimir A. Kobzar, Robert V. Kohn, Zhilei Wang", "title": "New Potential-Based Bounds for Prediction with Expert Advice", "comments": "To appear in COLT 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.GT math.AP math.OC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This work addresses the classic machine learning problem of online prediction\nwith expert advice. We consider the finite-horizon version of this zero-sum,\ntwo-person game. Using verification arguments from optimal control theory, we\nview the task of finding better lower and upper bounds on the value of the game\n(regret) as the problem of finding better sub- and supersolutions of certain\npartial differential equations (PDEs). These sub- and supersolutions serve as\nthe potentials for player and adversary strategies, which lead to the\ncorresponding bounds. To get explicit bounds, we use closed-form solutions of\nspecific PDEs. Our bounds hold for any given number of experts and horizon; in\ncertain regimes (which we identify) they improve upon the previous state of the\nart. For two and three experts, our bounds provide the optimal leading order\nterm.\n", "versions": [{"version": "v1", "created": "Tue, 5 Nov 2019 06:43:21 GMT"}, {"version": "v2", "created": "Sat, 1 Feb 2020 00:52:20 GMT"}, {"version": "v3", "created": "Mon, 29 Jun 2020 16:53:26 GMT"}], "update_date": "2020-06-30", "authors_parsed": [["Kobzar", "Vladimir A.", ""], ["Kohn", "Robert V.", ""], ["Wang", "Zhilei", ""]]}, {"id": "1911.01649", "submitter": "Chuang Wang", "authors": "Wei Wang, Chuang Wang, Tao Cui, Yue Li", "title": "Study of Constrained Network Structures for WGANs on Numeric Data\n  Generation", "comments": null, "journal-ref": null, "doi": "10.1109/ACCESS.2020.2993839", "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Some recent studies have suggested using GANs for numeric data generation\nsuch as to generate data for completing the imbalanced numeric data.\nConsidering the significant difference between the dimensions of the numeric\ndata and images, as well as the strong correlations between features of numeric\ndata, the conventional GANs normally face an overfitting problem, consequently\nleads to an ill-conditioning problem in generating numeric and structured data.\nThis paper studies the constrained network structures between generator G and\ndiscriminator D in WGAN, designs several structures including isomorphic,\nmirror and self-symmetric structures. We evaluates the performances of the\nconstrained WGANs in data augmentations, taking the non-constrained GANs and\nWGANs as the baselines. Experiments prove the constrained structures have been\nimproved in 17/20 groups of experiments. In twenty experiments on four UCI\nMachine Learning Repository datasets, Australian Credit Approval data, German\nCredit data, Pima Indians Diabetes data and SPECT heart data facing five\nconventional classifiers. Especially, Isomorphic WGAN is the best in 15/20\nexperiments. Finally, we theoretically proves that the effectiveness of\nconstrained structures by the directed graphic model (DGM) analysis.\n", "versions": [{"version": "v1", "created": "Tue, 5 Nov 2019 07:27:46 GMT"}], "update_date": "2020-05-11", "authors_parsed": [["Wang", "Wei", ""], ["Wang", "Chuang", ""], ["Cui", "Tao", ""], ["Li", "Yue", ""]]}, {"id": "1911.01654", "submitter": "Kasra Babaei", "authors": "Kasra Babaei, ZhiYuan Chen, Tomas Maul", "title": "Detecting Point Outliers Using Prune-based Outlier Factor (PLOF)", "comments": "Accepted by \"The 4th International Conference on Computing,\n  Mathematics and Statistics 2019 (iCMS2019)\"", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Outlier detection (also known as anomaly detection or deviation detection) is\na process of detecting data points in which their patterns deviate\nsignificantly from others. It is common to have outliers in industry\napplications, which could be generated by different causes such as human error,\nfraudulent activities, or system failure. Recently, density-based methods have\nshown promising results, particularly among which Local Outlier Factor (LOF) is\narguably dominating. However, one of the major drawbacks of LOF is that it is\ncomputationally expensive. Motivated by the mentioned problem, this research\npresents a novel pruning-based procedure in which the execution time of LOF is\nreduced while the performance is maintained. A novel Prune-based Local Outlier\nFactor (PLOF) approach is proposed, in which prior to employing LOF,\noutlierness of each data instance is measured. Next, based on a threshold, data\ninstances that require further investigation are separated and LOF score is\nonly computed for these points. Extensive experiments have been conducted and\nresults are promising. Comparison experiments with the original LOF and two\nstate-of-the-art variants of LOF have shown that PLOF produces higher accuracy\nand precision while reducing execution time.\n", "versions": [{"version": "v1", "created": "Tue, 5 Nov 2019 07:42:42 GMT"}], "update_date": "2019-11-06", "authors_parsed": [["Babaei", "Kasra", ""], ["Chen", "ZhiYuan", ""], ["Maul", "Tomas", ""]]}, {"id": "1911.01658", "submitter": "Guoqiang Wu", "authors": "Guoqiang Wu, Ruobing Zheng, Yingjie Tian, Dalian Liu", "title": "Joint Ranking SVM and Binary Relevance with Robust Low-Rank Learning for\n  Multi-Label Classification", "comments": "57 pages, 5 figures, to be published in the journal of Neural\n  Networks", "journal-ref": "Neural Networks, 2020, 122: 24-39", "doi": "10.1016/j.neunet.2019.10.002", "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Multi-label classification studies the task where each example belongs to\nmultiple labels simultaneously. As a representative method, Ranking Support\nVector Machine (Rank-SVM) aims to minimize the Ranking Loss and can also\nmitigate the negative influence of the class-imbalance issue. However, due to\nits stacking-style way for thresholding, it may suffer error accumulation and\nthus reduces the final classification performance. Binary Relevance (BR) is\nanother typical method, which aims to minimize the Hamming Loss and only needs\none-step learning. Nevertheless, it might have the class-imbalance issue and\ndoes not take into account label correlations. To address the above issues, we\npropose a novel multi-label classification model, which joints Ranking support\nvector machine and Binary Relevance with robust Low-rank learning (RBRL). RBRL\ninherits the ranking loss minimization advantages of Rank-SVM, and thus\novercomes the disadvantages of BR suffering the class-imbalance issue and\nignoring the label correlations. Meanwhile, it utilizes the hamming loss\nminimization and one-step learning advantages of BR, and thus tackles the\ndisadvantages of Rank-SVM including another thresholding learning step.\nBesides, a low-rank constraint is utilized to further exploit high-order label\ncorrelations under the assumption of low dimensional label space. Furthermore,\nto achieve nonlinear multi-label classifiers, we derive the kernelization RBRL.\nTwo accelerated proximal gradient methods (APG) are used to solve the\noptimization problems efficiently. Extensive comparative experiments with\nseveral state-of-the-art methods illustrate a highly competitive or superior\nperformance of our method RBRL.\n", "versions": [{"version": "v1", "created": "Tue, 5 Nov 2019 07:50:36 GMT"}], "update_date": "2019-11-06", "authors_parsed": [["Wu", "Guoqiang", ""], ["Zheng", "Ruobing", ""], ["Tian", "Yingjie", ""], ["Liu", "Dalian", ""]]}, {"id": "1911.01679", "submitter": "Tom Zahavy", "authors": "Tom Zahavy, Alon Cohen, Haim Kaplan and Yishay Mansour", "title": "Apprenticeship Learning via Frank-Wolfe", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the applications of the Frank-Wolfe (FW) algorithm for\nApprenticeship Learning (AL). In this setting, we are given a Markov Decision\nProcess (MDP) without an explicit reward function. Instead, we observe an\nexpert that acts according to some policy, and the goal is to find a policy\nwhose feature expectations are closest to those of the expert policy. We\nformulate this problem as finding the projection of the feature expectations of\nthe expert on the feature expectations polytope -- the convex hull of the\nfeature expectations of all the deterministic policies in the MDP. We show that\nthis formulation is equivalent to the AL objective and that solving this\nproblem using the FW algorithm is equivalent well-known Projection method of\nAbbeel and Ng (2004). This insight allows us to analyze AL with tools from\nconvex optimization literature and derive tighter convergence bounds on AL.\nSpecifically, we show that a variation of the FW method that is based on taking\n\"away steps\" achieves a linear rate of convergence when applied to AL and that\na stochastic version of the FW algorithm can be used to avoid precise\nestimation of feature expectations. We also experimentally show that this\nversion outperforms the FW baseline. To the best of our knowledge, this is the\nfirst work that shows linear convergence rates for AL.\n", "versions": [{"version": "v1", "created": "Tue, 5 Nov 2019 09:26:06 GMT"}, {"version": "v2", "created": "Wed, 20 Nov 2019 14:50:44 GMT"}], "update_date": "2019-11-21", "authors_parsed": [["Zahavy", "Tom", ""], ["Cohen", "Alon", ""], ["Kaplan", "Haim", ""], ["Mansour", "Yishay", ""]]}, {"id": "1911.01685", "submitter": "Jeroen Bertels", "authors": "Jeroen Bertels, Tom Eelbode, Maxim Berman, Dirk Vandermeulen, Frederik\n  Maes, Raf Bisschops, Matthew Blaschko", "title": "Optimizing the Dice Score and Jaccard Index for Medical Image\n  Segmentation: Theory & Practice", "comments": "MICCAI 2019", "journal-ref": "LNCS 11765, Springer Nature Switzerland AG 2019", "doi": "10.1007/978-3-030-32245-8_11", "report-no": null, "categories": "cs.CV cs.LG eess.IV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The Dice score and Jaccard index are commonly used metrics for the evaluation\nof segmentation tasks in medical imaging. Convolutional neural networks trained\nfor image segmentation tasks are usually optimized for (weighted)\ncross-entropy. This introduces an adverse discrepancy between the learning\noptimization objective (the loss) and the end target metric. Recent works in\ncomputer vision have proposed soft surrogates to alleviate this discrepancy and\ndirectly optimize the desired metric, either through relaxations (soft-Dice,\nsoft-Jaccard) or submodular optimization (Lov\\'asz-softmax). The aim of this\nstudy is two-fold. First, we investigate the theoretical differences in a risk\nminimization framework and question the existence of a weighted cross-entropy\nloss with weights theoretically optimized to surrogate Dice or Jaccard. Second,\nwe empirically investigate the behavior of the aforementioned loss functions\nw.r.t. evaluation with Dice score and Jaccard index on five medical\nsegmentation tasks. Through the application of relative approximation bounds,\nwe show that all surrogates are equivalent up to a multiplicative factor, and\nthat no optimal weighting of cross-entropy exists to approximate Dice or\nJaccard measures. We validate these findings empirically and show that, while\nit is important to opt for one of the target metric surrogates rather than a\ncross-entropy-based loss, the choice of the surrogate does not make a\nstatistical difference on a wide range of medical segmentation tasks.\n", "versions": [{"version": "v1", "created": "Tue, 5 Nov 2019 09:42:25 GMT"}], "update_date": "2020-10-09", "authors_parsed": [["Bertels", "Jeroen", ""], ["Eelbode", "Tom", ""], ["Berman", "Maxim", ""], ["Vandermeulen", "Dirk", ""], ["Maes", "Frederik", ""], ["Bisschops", "Raf", ""], ["Blaschko", "Matthew", ""]]}, {"id": "1911.01690", "submitter": "Zhuo Wang", "authors": "Zhuo Wang, Runlong Hu, Qian Chen, Pei Gao, and Xiaowei Xu", "title": "ColluEagle: Collusive review spammer detection using Markov random\n  fields", "comments": "16 pages, 12 figures", "journal-ref": "Data mining and knowledge discovery, 2020, 34(6): 1621-1641", "doi": "10.1007/s10618-020-00693-w", "report-no": null, "categories": "cs.IR cs.LG cs.SI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Product reviews are extremely valuable for online shoppers in providing\npurchase decisions. Driven by immense profit incentives, fraudsters\ndeliberately fabricate untruthful reviews to distort the reputation of online\nproducts. As online reviews become more and more important, group spamming,\ni.e., a team of fraudsters working collaboratively to attack a set of target\nproducts, becomes a new fashion. Previous works use review network effects,\ni.e. the relationships among reviewers, reviews, and products, to detect fake\nreviews or review spammers, but ignore time effects, which are critical in\ncharacterizing group spamming. In this paper, we propose a novel Markov random\nfield (MRF)-based method (ColluEagle) to detect collusive review spammers, as\nwell as review spam campaigns, considering both network effects and time\neffects. First we identify co-review pairs, a review phenomenon that happens\nbetween two reviewers who review a common product in a similar way, and then\nmodel reviewers and their co-review pairs as a pairwise-MRF, and use loopy\nbelief propagation to evaluate the suspiciousness of reviewers. We further\ndesign a high quality yet easy-to-compute node prior for ColluEagle, through\nwhich the review spammer groups can also be subsequently identified.\nExperiments show that ColluEagle can not only detect collusive spammers with\nhigh precision, significantly outperforming state-of-the-art baselines ---\nFraudEagle and SpEagle, but also identify highly suspicious review spammer\ncampaigns.\n", "versions": [{"version": "v1", "created": "Tue, 5 Nov 2019 09:57:36 GMT"}], "update_date": "2020-10-08", "authors_parsed": [["Wang", "Zhuo", ""], ["Hu", "Runlong", ""], ["Chen", "Qian", ""], ["Gao", "Pei", ""], ["Xu", "Xiaowei", ""]]}, {"id": "1911.01694", "submitter": "Nader Bshouty", "authors": "Nader H. Bshouty and George Haddad and Catherine A. Haddad-Zaknoon", "title": "Bounds for the Number of Tests in Non-Adaptive Randomized Algorithms for\n  Group Testing", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG math.ST stat.ML stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the group testing problem with non-adaptive randomized algorithms.\nSeveral models have been discussed in the literature to determine how to\nrandomly choose the tests. For a model ${\\cal M}$, let $m_{\\cal M}(n,d)$ be the\nminimum number of tests required to detect at most $d$ defectives within $n$\nitems, with success probability at least $1-\\delta$, for some constant\n$\\delta$. In this paper, we study the measures $$c_{\\cal M}(d)=\\lim_{n\\to\n\\infty} \\frac{m_{\\cal M}(n,d)}{\\ln n} \\mbox{ and } c_{\\cal M}=\\lim_{d\\to\n\\infty} \\frac{c_{\\cal M}(d)}{d}.$$\n  In the literature, the analyses of such models only give upper bounds for\n$c_{\\cal M}(d)$ and $c_{\\cal M}$, and for some of them, the bounds are not\ntight. We give new analyses that yield tight bounds for $c_{\\cal M}(d)$ and\n$c_{\\cal M}$ for all the known models~${\\cal M}$.\n", "versions": [{"version": "v1", "created": "Tue, 5 Nov 2019 10:09:28 GMT"}], "update_date": "2019-11-06", "authors_parsed": [["Bshouty", "Nader H.", ""], ["Haddad", "George", ""], ["Haddad-Zaknoon", "Catherine A.", ""]]}, {"id": "1911.01695", "submitter": "Mohammadi Zaki", "authors": "Mohammadi Zaki, Avinash Mohan and Aditya Gopalan", "title": "Towards Optimal and Efficient Best Arm Identification in Linear Bandits", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG math.OC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We give a new algorithm for best arm identification in linearly parameterised\nbandits in the fixed confidence setting. The algorithm generalises the\nwell-known LUCB algorithm of Kalyanakrishnan et al. (2012) by playing an arm\nwhich minimises a suitable notion of geometric overlap of the statistical\nconfidence set for the unknown parameter, and is fully adaptive and\ncomputationally efficient as compared to several state-of-the methods. We\ntheoretically analyse the sample complexity of the algorithm for problems with\ntwo and three arms, showing optimality in many cases. Numerical results\nindicate favourable performance over other algorithms with which we compare.\n", "versions": [{"version": "v1", "created": "Tue, 5 Nov 2019 10:11:49 GMT"}, {"version": "v2", "created": "Thu, 7 Nov 2019 07:20:35 GMT"}], "update_date": "2019-11-11", "authors_parsed": [["Zaki", "Mohammadi", ""], ["Mohan", "Avinash", ""], ["Gopalan", "Aditya", ""]]}, {"id": "1911.01700", "submitter": "Magnus Wiese", "authors": "Magnus Wiese, Lianjun Bai, Ben Wood, Hans Buehler", "title": "Deep Hedging: Learning to Simulate Equity Option Markets", "comments": null, "journal-ref": "NeurIPS 2019 Workshop on Robust AI in Financial Services: Data,\n  Fairness, Explainability, Trustworthiness, and Privacy", "doi": null, "report-no": null, "categories": "q-fin.CP cs.LG q-fin.MF q-fin.ST stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We construct realistic equity option market simulators based on generative\nadversarial networks (GANs). We consider recurrent and temporal convolutional\narchitectures, and assess the impact of state compression. Option market\nsimulators are highly relevant because they allow us to extend the limited\nreal-world data sets available for the training and evaluation of option\ntrading strategies. We show that network-based generators outperform classical\nmethods on a range of benchmark metrics, and adversarial training achieves the\nbest performance. Our work demonstrates for the first time that GANs can be\nsuccessfully applied to the task of generating multivariate financial time\nseries.\n", "versions": [{"version": "v1", "created": "Tue, 5 Nov 2019 10:23:39 GMT"}], "update_date": "2020-04-21", "authors_parsed": [["Wiese", "Magnus", ""], ["Bai", "Lianjun", ""], ["Wood", "Ben", ""], ["Buehler", "Hans", ""]]}, {"id": "1911.01702", "submitter": "Johannes Rausch", "authors": "Johannes Rausch, Octavio Martinez, Fabian Bissig, Ce Zhang, Stefan\n  Feuerriegel", "title": "DocParser: Hierarchical Structure Parsing of Document Renderings", "comments": "AAAI 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CL cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Translating renderings (e. g. PDFs, scans) into hierarchical document\nstructures is extensively demanded in the daily routines of many real-world\napplications. However, a holistic, principled approach to inferring the\ncomplete hierarchical structure of documents is missing. As a remedy, we\ndeveloped \"DocParser\": an end-to-end system for parsing the complete document\nstructure - including all text elements, nested figures, tables, and table cell\nstructures. Our second contribution is to provide a dataset for evaluating\nhierarchical document structure parsing. Our third contribution is to propose a\nscalable learning framework for settings where domain-specific data are scarce,\nwhich we address by a novel approach to weak supervision that significantly\nimproves the document structure parsing performance. Our experiments confirm\nthe effectiveness of our proposed weak supervision: Compared to the baseline\nwithout weak supervision, it improves the mean average precision for detecting\ndocument entities by 39.1 % and improves the F1 score of classifying\nhierarchical relations by 35.8 %.\n", "versions": [{"version": "v1", "created": "Tue, 5 Nov 2019 10:42:08 GMT"}, {"version": "v2", "created": "Mon, 25 Jan 2021 11:54:38 GMT"}], "update_date": "2021-01-26", "authors_parsed": [["Rausch", "Johannes", ""], ["Martinez", "Octavio", ""], ["Bissig", "Fabian", ""], ["Zhang", "Ce", ""], ["Feuerriegel", "Stefan", ""]]}, {"id": "1911.01704", "submitter": "Chieh-Fang Teng", "authors": "Chieh-Fang Teng, Kuan-Shiuan Ho, Chen-Hsi Wu, Sin-Sheng Wong, and\n  An-Yeu Wu", "title": "Convolutional Neural Network-aided Bit-flipping for Belief Propagation\n  Decoding of Polar Codes", "comments": "5 pages, 6 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.SP cs.IT cs.LG math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Known for their capacity-achieving abilities, polar codes have been selected\nas the control channel coding scheme for 5G communications. To satisfy the\nneeds of high throughput and low latency, belief propagation (BP) is chosen as\nthe decoding algorithm. However, in general, the error performance of BP is\nworse than that of enhanced successive cancellation (SC). Recently,\ncritical-set bit-flipping (CS-BF) is applied to BP decoding to lower the error\nrate. However, its trial and error process result in even longer latency. In\nthis work, we propose a convolutional neural network-assisted bit-flipping\n(CNN-BF) mechanism to further enhance BP decoding of polar codes. With\ncarefully designed input data and model architecture, our proposed CNN-BF can\nachieve much higher prediction accuracy and better error correction capability\nthan CS-BF but with only half latency. It also achieves a lower block error\nrate (BLER) than SC list (CA-SCL).\n", "versions": [{"version": "v1", "created": "Tue, 5 Nov 2019 10:54:08 GMT"}, {"version": "v2", "created": "Mon, 3 Feb 2020 12:07:04 GMT"}, {"version": "v3", "created": "Wed, 5 Feb 2020 16:45:43 GMT"}], "update_date": "2020-02-06", "authors_parsed": [["Teng", "Chieh-Fang", ""], ["Ho", "Kuan-Shiuan", ""], ["Wu", "Chen-Hsi", ""], ["Wong", "Sin-Sheng", ""], ["Wu", "An-Yeu", ""]]}, {"id": "1911.01705", "submitter": "Rudrasis Chakraborty Dr.", "authors": "Liu Yang and Rudrasis Chakraborty", "title": "A GMM based algorithm to generate point-cloud and its application to\n  neuroimaging", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG eess.IV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent years have witnessed the emergence of 3D medical imaging techniques\nwith the development of 3D sensors and technology. Due to the presence of noise\nin image acquisition, registration researchers focused on an alternative way to\nrepresent medical images. An alternative way to analyze medical imaging is by\nunderstanding the 3D shapes represented in terms of point-cloud. Though in the\nmedical imaging community, 3D point-cloud processing is not a ``go-to'' choice,\nit is a ``natural'' way to capture 3D shapes. However, as the number of samples\nfor medical images are small, researchers have used pre-trained models to\nfine-tune on medical images. Furthermore, due to different modality in medical\nimages, standard generative models can not be used to generate new samples of\nmedical images. In this work, we use the advantage of point-cloud\nrepresentation of 3D structures of medical images and propose a Gaussian\nmixture model-based generation scheme. Our proposed method is robust to\noutliers. Experimental validation has been performed to show that the proposed\nscheme can generate new 3D structures using interpolation techniques, i.e.,\ngiven two 3D structures represented as point-clouds, we can generate\npoint-clouds in between. We have also generated new point-clouds for subjects\nwith and without dementia and show that the generated samples are indeed\nclosely matched to the respective training samples from the same class.\n", "versions": [{"version": "v1", "created": "Tue, 5 Nov 2019 10:54:53 GMT"}], "update_date": "2019-11-06", "authors_parsed": [["Yang", "Liu", ""], ["Chakraborty", "Rudrasis", ""]]}, {"id": "1911.01710", "submitter": "Chieh-Fang Teng", "authors": "Chieh-Fang Teng, and An-Yeu Wu", "title": "Unsupervised Learning for Neural Network-based Polar Decoder via\n  Syndrome Loss", "comments": "four pages, six figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.SP cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  With the rapid growth of deep learning in many fields, machine\nlearning-assisted communication systems had attracted lots of researches with\nmany eye-catching initial results. At the present stage, most of the methods\nstill have great demand of massive labeled data for supervised learning.\nHowever, obtaining labeled data in the practical applications is not feasible,\nwhich may result in severe performance degradation due to channel variations.\nTo overcome such a constraint, syndrome loss has been proposed to penalize\nnon-valid decoded codewords and achieve unsupervised learning for neural\nnetwork-based decoder. However, it cannot be applied to polar decoder directly.\nIn this work, by exploiting the nature of polar codes, we propose a modified\nsyndrome loss. From simulation results, the proposed method demonstrates that\ndomain-specific knowledge and know-how in code structure can enable\nunsupervised learning for neural network-based polar decoder.\n", "versions": [{"version": "v1", "created": "Tue, 5 Nov 2019 10:59:29 GMT"}], "update_date": "2019-11-06", "authors_parsed": [["Teng", "Chieh-Fang", ""], ["Wu", "An-Yeu", ""]]}, {"id": "1911.01715", "submitter": "Diego Ferigo", "authors": "Diego Ferigo, Silvio Traversaro, Giorgio Metta, Daniele Pucci", "title": "Gym-Ignition: Reproducible Robotic Simulations for Reinforcement\n  Learning", "comments": "Accepted in SII2020", "journal-ref": "2020 IEEE/SICE International Symposium on System Integration (SII)", "doi": "10.1109/SII46433.2020.9025951", "report-no": null, "categories": "cs.RO cs.DC cs.LG cs.SY eess.SY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper presents Gym-Ignition, a new framework to create reproducible\nrobotic environments for reinforcement learning research. It interfaces with\nthe new generation of Gazebo, part of the Ignition Robotics suite, which\nprovides three main improvements for reinforcement learning applications\ncompared to the alternatives: 1) the modular architecture enables using the\nsimulator as a C++ library, simplifying the interconnection with external\nsoftware; 2) multiple physics and rendering engines are supported as plugins,\nsimplifying their selection during the execution; 3) the new distributed\nsimulation capability allows simulating complex scenarios while sharing the\nload on multiple workers and machines. The core of Gym-Ignition is a component\nthat contains the Ignition Gazebo simulator and exposes a simple interface for\nits configuration and execution. We provide a Python package that allows\ndevelopers to create robotic environments simulated in Ignition Gazebo.\nEnvironments expose the common OpenAI Gym interface, making them compatible\nout-of-the-box with third-party frameworks containing reinforcement learning\nalgorithms. Simulations can be executed in both headless and GUI mode, the\nphysics engine can run in accelerated mode, and instances can be parallelized.\nFurthermore, the Gym-Ignition software architecture provides abstraction of the\nRobot and the Task, making environments agnostic on the specific runtime. This\nabstraction allows their execution also in a real-time setting on actual\nrobotic platforms, even if driven by different middlewares.\n", "versions": [{"version": "v1", "created": "Tue, 5 Nov 2019 11:19:58 GMT"}, {"version": "v2", "created": "Mon, 2 Dec 2019 08:23:41 GMT"}], "update_date": "2020-04-17", "authors_parsed": [["Ferigo", "Diego", ""], ["Traversaro", "Silvio", ""], ["Metta", "Giorgio", ""], ["Pucci", "Daniele", ""]]}, {"id": "1911.01721", "submitter": "Eirini Troullinou", "authors": "Eirini Troullinou, Grigorios Tsagkatakis, Ganna Palagina, Maria\n  Papadopouli, Stelios Manolis Smirnakis, Panagiotis Tsakalides", "title": "Adversarial dictionary learning for a robust analysis and modelling of\n  spontaneous neuronal activity", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.NC cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The field of neuroscience is experiencing rapid growth in the complexity and\nquantity of the recorded neural activity allowing us unprecedented access to\nits dynamics in different brain areas. The objective of this work is to\ndiscover directly from the experimental data rich and comprehensible models for\nbrain function that will be concurrently robust to noise. Considering this task\nfrom the perspective of dimensionality reduction, we develop an innovative,\nrobust to noise dictionary learning framework based on adversarial training\nmethods for the identification of patterns of synchronous firing activity as\nwell as within a time lag. We employ real-world binary datasets describing the\nspontaneous neuronal activity of laboratory mice over time, and we aim to their\nefficient low-dimensional representation. The results on the classification\naccuracy for the discrimination between the clean and the adversarial-noisy\nactivation patterns obtained by an SVM classifier highlight the efficacy of the\nproposed scheme compared to other methods, and the visualization of the\ndictionary's distribution demonstrates the multifarious information that we\nobtain from it.\n", "versions": [{"version": "v1", "created": "Tue, 5 Nov 2019 11:32:06 GMT"}, {"version": "v2", "created": "Tue, 24 Dec 2019 17:18:05 GMT"}], "update_date": "2019-12-25", "authors_parsed": [["Troullinou", "Eirini", ""], ["Tsagkatakis", "Grigorios", ""], ["Palagina", "Ganna", ""], ["Papadopouli", "Maria", ""], ["Smirnakis", "Stelios Manolis", ""], ["Tsakalides", "Panagiotis", ""]]}, {"id": "1911.01731", "submitter": "Yanqiao Zhu", "authors": "Fenyu Hu, Yanqiao Zhu, Shu Wu, Weiran Huang, Liang Wang, Tieniu Tan", "title": "GraphAIR: Graph Representation Learning with Neighborhood Aggregation\n  and Interaction", "comments": "12 pages, accepted to Pattern Recognition", "journal-ref": null, "doi": "10.1016/j.patcog.2020.107745", "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Graph representation learning is of paramount importance for a variety of\ngraph analytical tasks, ranging from node classification to community\ndetection. Recently, graph convolutional networks (GCNs) have been successfully\napplied for graph representation learning. These GCNs generate node\nrepresentation by aggregating features from the neighborhoods, which follows\nthe \"neighborhood aggregation\" scheme. In spite of having achieved promising\nperformance on various tasks, existing GCN-based models have difficulty in well\ncapturing complicated non-linearity of graph data. In this paper, we first\ntheoretically prove that coefficients of the neighborhood interacting terms are\nrelatively small in current models, which explains why GCNs barely outperforms\nlinear models. Then, in order to better capture the complicated non-linearity\nof graph data, we present a novel GraphAIR framework which models the\nneighborhood interaction in addition to neighborhood aggregation. Comprehensive\nexperiments conducted on benchmark tasks including node classification and link\nprediction using public datasets demonstrate the effectiveness of the proposed\nmethod.\n", "versions": [{"version": "v1", "created": "Tue, 5 Nov 2019 11:47:58 GMT"}, {"version": "v2", "created": "Thu, 14 Nov 2019 12:21:06 GMT"}, {"version": "v3", "created": "Thu, 5 Nov 2020 16:11:49 GMT"}], "update_date": "2020-11-10", "authors_parsed": [["Hu", "Fenyu", ""], ["Zhu", "Yanqiao", ""], ["Wu", "Shu", ""], ["Huang", "Weiran", ""], ["Wang", "Liang", ""], ["Tan", "Tieniu", ""]]}, {"id": "1911.01738", "submitter": "Sergey Pavlov", "authors": "Sergey Pavlov, Alexey Artemov, Maksim Sharaev, Alexander Bernstein,\n  Evgeny Burnaev", "title": "Weakly Supervised Fine Tuning Approach for Brain Tumor Segmentation\n  Problem", "comments": "Accepted to IEEE International Conference on Machine Learning and\n  Applications (ICMLA 2019). Typos corrected, images updated", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.IV cs.CV cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Segmentation of tumors in brain MRI images is a challenging task, where most\nrecent methods demand large volumes of data with pixel-level annotations, which\nare generally costly to obtain. In contrast, image-level annotations, where\nonly the presence of lesion is marked, are generally cheap, generated in far\nlarger volumes compared to pixel-level labels, and contain less labeling noise.\nIn the context of brain tumor segmentation, both pixel-level and image-level\nannotations are commonly available; thus, a natural question arises whether a\nsegmentation procedure could take advantage of both. In the present work we: 1)\npropose a learning-based framework that allows simultaneous usage of both\npixel- and image-level annotations in MRI images to learn a segmentation model\nfor brain tumor; 2) study the influence of comparative amounts of pixel- and\nimage-level annotations on the quality of brain tumor segmentation; 3) compare\nour approach to the traditional fully-supervised approach and show that the\nperformance of our method in terms of segmentation quality may be competitive.\n", "versions": [{"version": "v1", "created": "Tue, 5 Nov 2019 12:14:40 GMT"}, {"version": "v2", "created": "Wed, 6 Nov 2019 07:48:01 GMT"}], "update_date": "2019-11-07", "authors_parsed": [["Pavlov", "Sergey", ""], ["Artemov", "Alexey", ""], ["Sharaev", "Maksim", ""], ["Bernstein", "Alexander", ""], ["Burnaev", "Evgeny", ""]]}, {"id": "1911.01764", "submitter": "Mathias Perslev", "authors": "Mathias Perslev, Erik Bj{\\o}rnager Dam, Akshay Pai, Christian Igel", "title": "One Network to Segment Them All: A General, Lightweight System for\n  Accurate 3D Medical Image Segmentation", "comments": null, "journal-ref": "Medical Image Computing and Computer Assisted Intervention\n  (MICCAI), LNCS 11765, pp. 30-38, Springer, 2019", "doi": "10.1007/978-3-030-32245-8_4", "report-no": null, "categories": "cs.LG eess.IV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Many recent medical segmentation systems rely on powerful deep learning\nmodels to solve highly specific tasks. To maximize performance, it is standard\npractice to evaluate numerous pipelines with varying model topologies,\noptimization parameters, pre- & postprocessing steps, and even model cascades.\nIt is often not clear how the resulting pipeline transfers to different tasks.\nWe propose a simple and thoroughly evaluated deep learning framework for\nsegmentation of arbitrary medical image volumes. The system requires no\ntask-specific information, no human interaction and is based on a fixed model\ntopology and a fixed hyperparameter set, eliminating the process of model\nselection and its inherent tendency to cause method-level over-fitting. The\nsystem is available in open source and does not require deep learning expertise\nto use. Without task-specific modifications, the system performed better than\nor similar to highly specialized deep learning methods across 3 separate\nsegmentation tasks. In addition, it ranked 5-th and 6-th in the first and\nsecond round of the 2018 Medical Segmentation Decathlon comprising another 10\ntasks. The system relies on multi-planar data augmentation which facilitates\nthe application of a single 2D architecture based on the familiar U-Net.\nMulti-planar training combines the parameter efficiency of a 2D fully\nconvolutional neural network with a systematic train- and test-time\naugmentation scheme, which allows the 2D model to learn a representation of the\n3D image volume that fosters generalization.\n", "versions": [{"version": "v1", "created": "Tue, 5 Nov 2019 13:37:53 GMT"}], "update_date": "2019-11-06", "authors_parsed": [["Perslev", "Mathias", ""], ["Dam", "Erik Bj\u00f8rnager", ""], ["Pai", "Akshay", ""], ["Igel", "Christian", ""]]}, {"id": "1911.01786", "submitter": "Peidong Liu", "authors": "Peidong Liu, Xiyu Yan, Yong Jiang, Shu-Tao Xia", "title": "Deep Flow Collaborative Network for Online Visual Tracking", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The deep learning-based visual tracking algorithms such as MDNet achieve high\nperformance leveraging to the feature extraction ability of a deep neural\nnetwork. However, the tracking efficiency of these trackers is not very high\ndue to the slow feature extraction for each frame in a video. In this paper, we\npropose an effective tracking algorithm to alleviate the time-consuming\nproblem. Specifically, we design a deep flow collaborative network, which\nexecutes the expensive feature network only on sparse keyframes and transfers\nthe feature maps to other frames via optical flow. Moreover, we raise an\neffective adaptive keyframe scheduling mechanism to select the most appropriate\nkeyframe. We evaluate the proposed approach on large-scale datasets: OTB2013\nand OTB2015. The experiment results show that our algorithm achieves\nconsiderable speedup and high precision as well.\n", "versions": [{"version": "v1", "created": "Tue, 5 Nov 2019 14:13:07 GMT"}], "update_date": "2019-11-06", "authors_parsed": [["Liu", "Peidong", ""], ["Yan", "Xiyu", ""], ["Jiang", "Yong", ""], ["Xia", "Shu-Tao", ""]]}, {"id": "1911.01802", "submitter": "Ziqi Fan", "authors": "Ziqi Fan, Vibhav Vineet, Hannes Gamper, Nikunj Raghuvanshi", "title": "Fast acoustic scattering using convolutional neural networks", "comments": "Accepted by ICASSP 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.AS cs.LG cs.SD eess.IV eess.SP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Diffracted scattering and occlusion are important acoustic effects in\ninteractive auralization and noise control applications, typically requiring\nexpensive numerical simulation. We propose training a convolutional neural\nnetwork to map from a convex scatterer's cross-section to a 2D slice of the\nresulting spatial loudness distribution. We show that employing a\nfull-resolution residual network for the resulting image-to-image regression\nproblem yields spatially detailed loudness fields with a root-mean-squared\nerror of less than 1 dB, at over 100x speedup compared to full wave simulation.\n", "versions": [{"version": "v1", "created": "Wed, 30 Oct 2019 23:53:18 GMT"}, {"version": "v2", "created": "Wed, 6 Nov 2019 04:32:21 GMT"}, {"version": "v3", "created": "Sat, 15 Feb 2020 20:04:43 GMT"}], "update_date": "2020-02-18", "authors_parsed": [["Fan", "Ziqi", ""], ["Vineet", "Vibhav", ""], ["Gamper", "Hannes", ""], ["Raghuvanshi", "Nikunj", ""]]}, {"id": "1911.01803", "submitter": "Taejun Kim", "authors": "Taejun Kim and Juhan Nam", "title": "Temporal Feedback Convolutional Recurrent Neural Networks for Keyword\n  Spotting", "comments": "This paper is submitted to ICASSP 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.AS cs.CL cs.LG cs.SD eess.SP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  While end-to-end learning has become a trend in deep learning, the model\narchitecture is often designed to incorporate domain knowledge. We propose a\nnovel convolutional recurrent neural network (CRNN) architecture with temporal\nfeedback connections, inspired by the feedback pathways from the brain to ears\nin the human auditory system. The proposed architecture uses a hidden state of\nthe RNN module at the previous time to control the sensitivity of channel-wise\nfeature activations in the CNN blocks at the current time, which is analogous\nto the mechanism of the outer hair-cell. We apply the proposed model to keyword\nspotting where the speech commands have sequential nature. We show the proposed\nmodel consistently outperforms the compared model without temporal feedback for\ndifferent input/output settings in the CRNN framework. We also investigate the\ndetails of the performance improvement by conducting a failure analysis of the\nkeyword spotting task and a visualization of the channel-wise feature scaling\nin each CNN block.\n", "versions": [{"version": "v1", "created": "Wed, 30 Oct 2019 04:11:29 GMT"}], "update_date": "2019-11-06", "authors_parsed": [["Kim", "Taejun", ""], ["Nam", "Juhan", ""]]}, {"id": "1911.01806", "submitter": "Zhiyuan Peng", "authors": "Zhiyuan Peng, Siyuan Feng, Tan Lee", "title": "Mixture factorized auto-encoder for unsupervised hierarchical deep\n  factorization of speech signal", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.AS cs.LG cs.MM cs.SD", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Speech signal is constituted and contributed by various informative factors,\nsuch as linguistic content and speaker characteristic. There have been notable\nrecent studies attempting to factorize speech signal into these individual\nfactors without requiring any annotation. These studies typically assume\ncontinuous representation for linguistic content, which is not in accordance\nwith general linguistic knowledge and may make the extraction of speaker\ninformation less successful. This paper proposes the mixture factorized\nauto-encoder (mFAE) for unsupervised deep factorization. The encoder part of\nmFAE comprises a frame tokenizer and an utterance embedder. The frame tokenizer\nmodels linguistic content of input speech with a discrete categorical\ndistribution. It performs frame clustering by assigning each frame a soft\nmixture label. The utterance embedder generates an utterance-level vector\nrepresentation. A frame decoder serves to reconstruct speech features from the\nencoders'outputs. The mFAE is evaluated on speaker verification (SV) task and\nunsupervised subword modeling (USM) task. The SV experiments on VoxCeleb 1 show\nthat the utterance embedder is capable of extracting speaker-discriminative\nembeddings with performance comparable to a x-vector baseline. The USM\nexperiments on ZeroSpeech 2017 dataset verify that the frame tokenizer is able\nto capture linguistic content and the utterance embedder can acquire\nspeaker-related information.\n", "versions": [{"version": "v1", "created": "Wed, 30 Oct 2019 08:54:34 GMT"}], "update_date": "2019-11-06", "authors_parsed": [["Peng", "Zhiyuan", ""], ["Feng", "Siyuan", ""], ["Lee", "Tan", ""]]}, {"id": "1911.01812", "submitter": "Zaoxing Liu", "authors": "Zaoxing Liu, Tian Li, Virginia Smith, Vyas Sekar", "title": "Enhancing the Privacy of Federated Learning with Sketching", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR cs.NI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In response to growing concerns about user privacy, federated learning has\nemerged as a promising tool to train statistical models over networks of\ndevices while keeping data localized. Federated learning methods run training\ntasks directly on user devices and do not share the raw user data with third\nparties. However, current methods still share model updates, which may contain\nprivate information (e.g., one's weight and height), during the training\nprocess. Existing efforts that aim to improve the privacy of federated learning\nmake compromises in one or more of the following key areas: performance\n(particularly communication cost), accuracy, or privacy. To better optimize\nthese trade-offs, we propose that \\textit{sketching algorithms} have a unique\nadvantage in that they can provide both privacy and performance benefits while\nmaintaining accuracy. We evaluate the feasibility of sketching-based federated\nlearning with a prototype on three representative learning models. Our initial\nfindings show that it is possible to provide strong privacy guarantees for\nfederated learning without sacrificing performance or accuracy. Our work\nhighlights that there exists a fundamental connection between privacy and\ncommunication in distributed settings, and suggests important open problems\nsurrounding the theoretical understanding, methodology, and system design of\npractical, private federated learning.\n", "versions": [{"version": "v1", "created": "Tue, 5 Nov 2019 14:38:18 GMT"}], "update_date": "2019-11-06", "authors_parsed": [["Liu", "Zaoxing", ""], ["Li", "Tian", ""], ["Smith", "Virginia", ""], ["Sekar", "Vyas", ""]]}, {"id": "1911.01831", "submitter": "Jonas Degrave", "authors": "Jonas Degrave, Abbas Abdolmaleki, Jost Tobias Springenberg, Nicolas\n  Heess, Martin Riedmiller", "title": "Quinoa: a Q-function You Infer Normalized Over Actions", "comments": "Deep RL Workshop/NeurIPS", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present an algorithm for learning an approximate action-value soft\nQ-function in the relative entropy regularised reinforcement learning setting,\nfor which an optimal improved policy can be recovered in closed form. We use\nrecent advances in normalising flows for parametrising the policy together with\na learned value-function; and show how this combination can be used to\nimplicitly represent Q-values of an arbitrary policy in continuous action\nspace. Using simple temporal difference learning on the Q-values then leads to\na unified objective for policy and value learning. We show how this approach\nconsiderably simplifies standard Actor-Critic off-policy algorithms, removing\nthe need for a policy optimisation step. We perform experiments on a range of\nestablished reinforcement learning benchmarks, demonstrating that our approach\nallows for complex, multimodal policy distributions in continuous action\nspaces, while keeping the process of sampling from the policy both fast and\nexact.\n", "versions": [{"version": "v1", "created": "Tue, 5 Nov 2019 14:51:06 GMT"}], "update_date": "2019-11-06", "authors_parsed": [["Degrave", "Jonas", ""], ["Abdolmaleki", "Abbas", ""], ["Springenberg", "Jost Tobias", ""], ["Heess", "Nicolas", ""], ["Riedmiller", "Martin", ""]]}, {"id": "1911.01840", "submitter": "Fu Song", "authors": "Guangke Chen, Sen Chen, Lingling Fan, Xiaoning Du, Zhe Zhao, Fu Song,\n  Yang Liu", "title": "Who is Real Bob? Adversarial Attacks on Speaker Recognition Systems", "comments": "IEEE Symposium on Security and Privacy 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.AS cs.CR cs.LG cs.MM cs.SD", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Speaker recognition (SR) is widely used in our daily life as a biometric\nauthentication or identification mechanism. The popularity of SR brings in\nserious security concerns, as demonstrated by recent adversarial attacks.\nHowever, the impacts of such threats in the practical black-box setting are\nstill open, since current attacks consider the white-box setting only. In this\npaper, we conduct the first comprehensive and systematic study of the\nadversarial attacks on SR systems (SRSs) to understand their security weakness\nin the practical blackbox setting. For this purpose, we propose an adversarial\nattack, named FAKEBOB, to craft adversarial samples. Specifically, we formulate\nthe adversarial sample generation as an optimization problem, incorporated with\nthe confidence of adversarial samples and maximal distortion to balance between\nthe strength and imperceptibility of adversarial voices. One key contribution\nis to propose a novel algorithm to estimate the score threshold, a feature in\nSRSs, and use it in the optimization problem to solve the optimization problem.\nWe demonstrate that FAKEBOB achieves 99% targeted attack success rate on both\nopen-source and commercial systems. We further demonstrate that FAKEBOB is also\neffective on both open-source and commercial systems when playing over the air\nin the physical world. Moreover, we have conducted a human study which reveals\nthat it is hard for human to differentiate the speakers of the original and\nadversarial voices. Last but not least, we show that four promising defense\nmethods for adversarial attack from the speech recognition domain become\nineffective on SRSs against FAKEBOB, which calls for more effective defense\nmethods. We highlight that our study peeks into the security implications of\nadversarial attacks on SRSs, and realistically fosters to improve the security\nrobustness of SRSs.\n", "versions": [{"version": "v1", "created": "Sun, 3 Nov 2019 16:50:13 GMT"}, {"version": "v2", "created": "Fri, 24 Apr 2020 02:10:01 GMT"}], "update_date": "2020-04-27", "authors_parsed": [["Chen", "Guangke", ""], ["Chen", "Sen", ""], ["Fan", "Lingling", ""], ["Du", "Xiaoning", ""], ["Zhao", "Zhe", ""], ["Song", "Fu", ""], ["Liu", "Yang", ""]]}, {"id": "1911.01861", "submitter": "Massih-Reza Amini", "authors": "Anastasiia Doinychko and Massih-Reza Amini", "title": "Biconditional Generative Adversarial Networks for Multiview Learning\n  with Missing Views", "comments": "15 pages, 3 figure", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we present a conditional GAN with two generators and a common\ndiscriminator for multiview learning problems where observations have two\nviews, but one of them may be missing for some of the training samples. This is\nfor example the case for multilingual collections where documents are not\navailable in all languages. Some studies tackled this problem by assuming the\nexistence of view generation functions to approximately complete the missing\nviews; for example Machine Translation to translate documents into the missing\nlanguages. These functions generally require an external resource to be set and\ntheir quality has a direct impact on the performance of the learned multiview\nclassifier over the completed training set. Our proposed approach addresses\nthis problem by jointly learning the missing views and the multiview classifier\nusing a tripartite game with two generators and a discriminator. Each of the\ngenerators is associated to one of the views and tries to fool the\ndiscriminator by generating the other missing view conditionally on the\ncorresponding observed view. The discriminator then tries to identify if for an\nobservation, one of its views is completed by one of the generators or if both\nviews are completed along with its class. Our results on a subset of Reuters\nRCV1/RCV2 collections show that the discriminator achieves significant\nclassification performance; and that the generators learn the missing views\nwith high quality without the need of any consequent external resource.\n", "versions": [{"version": "v1", "created": "Tue, 5 Nov 2019 15:20:06 GMT"}, {"version": "v2", "created": "Thu, 7 Nov 2019 08:37:45 GMT"}], "update_date": "2019-11-11", "authors_parsed": [["Doinychko", "Anastasiia", ""], ["Amini", "Massih-Reza", ""]]}, {"id": "1911.01867", "submitter": "Ayman Taha", "authors": "Ayman Taha, Hoda M.Onsi, Mohammed Nour El din, Osman M. Hegazy", "title": "A Model for Spatial Outlier Detection Based on Weighted Neighborhood\n  Relationship", "comments": "Geographic Information Systems (GIS), Spatial Data Mining (SDM),\n  Spatial Data Computing (SDC), Spatial Outlier Detection (SOD), Spatial\n  Autocorrelation, Neighborhood relationship. arXiv admin note: substantial\n  text overlap with arXiv:1601.07241", "journal-ref": "Egyptian Informatics Journal 2, 2005", "doi": null, "report-no": null, "categories": "cs.LG cs.DB", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Spatial outliers are used to discover inconsistent objects producing\nimplicit, hidden, and interesting knowledge, which has an effective role in\ndecision-making process. In this paper, we propose a model to redefine the\nspatial neighborhood relationship by considering weights of the most effective\nparameters of neighboring objects in a given spatial data set. The spatial\nparameters, which are taken into our consideration, are distance, cost, and\nnumber of direct connections between neighboring objects. This model is\nadaptable to be applied on polygonal objects. The proposed model is applied to\na GIS system supporting literacy project in Fayoum governorate.\n", "versions": [{"version": "v1", "created": "Mon, 4 Nov 2019 12:40:38 GMT"}], "update_date": "2019-11-06", "authors_parsed": [["Taha", "Ayman", ""], ["Onsi", "Hoda M.", ""], ["din", "Mohammed Nour El", ""], ["Hegazy", "Osman M.", ""]]}, {"id": "1911.01871", "submitter": "Sayak Ray Chowdhury", "authors": "Sayak Ray Chowdhury, Aditya Gopalan", "title": "On Online Learning in Kernelized Markov Decision Processes", "comments": "arXiv admin note: text overlap with arXiv:1805.08052", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We develop algorithms with low regret for learning episodic Markov decision\nprocesses based on kernel approximation techniques. The algorithms are based on\nboth the Upper Confidence Bound (UCB) as well as Posterior or Thompson Sampling\n(PSRL) philosophies, and work in the general setting of continuous state and\naction spaces when the true unknown transition dynamics are assumed to have\nsmoothness induced by an appropriate Reproducing Kernel Hilbert Space (RKHS).\n", "versions": [{"version": "v1", "created": "Mon, 4 Nov 2019 05:17:28 GMT"}], "update_date": "2019-11-06", "authors_parsed": [["Chowdhury", "Sayak Ray", ""], ["Gopalan", "Aditya", ""]]}, {"id": "1911.01877", "submitter": "Tim J. Adler", "authors": "Tim J. Adler, Leonardo Ayala, Lynton Ardizzone, Hannes G. Kenngott,\n  Anant Vemuri, Beat P. M\\\"uller-Stich, Carsten Rother, Ullrich K\\\"othe, and\n  Lena Maier-Hein", "title": "Out of distribution detection for intra-operative functional imaging", "comments": "The final authenticated version is available online at\n  https://doi.org/10.1007/978-3-030-32689-0_8", "journal-ref": "Proceedings of the First International Workshop on Uncertainty for\n  Safe Utilization of Machine Learning in Medical Imaging, UNSURE 2019, and the\n  8th International Workshop on Clinical Image-Based Procedures, CLIP 2019", "doi": "10.1007/978-3-030-32689-0_8", "report-no": null, "categories": "eess.IV cs.LG physics.med-ph stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Multispectral optical imaging is becoming a key tool in the operating room.\nRecent research has shown that machine learning algorithms can be used to\nconvert pixel-wise reflectance measurements to tissue parameters, such as\noxygenation. However, the accuracy of these algorithms can only be guaranteed\nif the spectra acquired during surgery match the ones seen during training. It\nis therefore of great interest to detect so-called out of distribution (OoD)\nspectra to prevent the algorithm from presenting spurious results. In this\npaper we present an information theory based approach to OoD detection based on\nthe widely applicable information criterion (WAIC). Our work builds upon recent\nmethodology related to invertible neural networks (INN). Specifically, we make\nuse of an ensemble of INNs as we need their tractable Jacobians in order to\ncompute the WAIC. Comprehensive experiments with in silico, and in vivo\nmultispectral imaging data indicate that our approach is well-suited for OoD\ndetection. Our method could thus be an important step towards reliable\nfunctional imaging in the operating room.\n", "versions": [{"version": "v1", "created": "Tue, 5 Nov 2019 15:31:29 GMT"}], "update_date": "2019-11-06", "authors_parsed": [["Adler", "Tim J.", ""], ["Ayala", "Leonardo", ""], ["Ardizzone", "Lynton", ""], ["Kenngott", "Hannes G.", ""], ["Vemuri", "Anant", ""], ["M\u00fcller-Stich", "Beat P.", ""], ["Rother", "Carsten", ""], ["K\u00f6the", "Ullrich", ""], ["Maier-Hein", "Lena", ""]]}, {"id": "1911.01888", "submitter": "Michael Lomnitz", "authors": "Michael Lomnitz, Nina Lopatina, Paul Gamble, Zigfried Hampel-Arias,\n  Lucas Tindall, Felipe A. Mejia, Maria Alejandra Barrios", "title": "Reducing audio membership inference attack accuracy to chance: 4\n  defenses", "comments": "7 pages, 2 figures, 7 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.LG eess.AS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  It is critical to understand the privacy and robustness vulnerabilities of\nmachine learning models, as their implementation expands in scope. In\nmembership inference attacks, adversaries can determine whether a particular\nset of data was used in training, putting the privacy of the data at risk.\nExisting work has mostly focused on image related tasks; we generalize this\ntype of attack to speaker identification on audio samples. We demonstrate\nattack precision of 85.9\\% and recall of 90.8\\% for LibriSpeech, and 78.3\\%\nprecision and 90.7\\% recall for VOiCES (Voices Obscured in Complex\nEnvironmental Settings). We find that implementing defenses such as prediction\nobfuscation, defensive distillation or adversarial training, can reduce attack\naccuracy to chance.\n", "versions": [{"version": "v1", "created": "Thu, 31 Oct 2019 21:18:40 GMT"}], "update_date": "2019-11-06", "authors_parsed": [["Lomnitz", "Michael", ""], ["Lopatina", "Nina", ""], ["Gamble", "Paul", ""], ["Hampel-Arias", "Zigfried", ""], ["Tindall", "Lucas", ""], ["Mejia", "Felipe A.", ""], ["Barrios", "Maria Alejandra", ""]]}, {"id": "1911.01894", "submitter": "Tomas Geffner", "authors": "Tomas Geffner and Justin Domke", "title": "A Rule for Gradient Estimator Selection, with an Application to\n  Variational Inference", "comments": "18 pages, preliminary work. International Conference on Artificial\n  Intelligence and Statistics. 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Stochastic gradient descent (SGD) is the workhorse of modern machine\nlearning. Sometimes, there are many different potential gradient estimators\nthat can be used. When so, choosing the one with the best tradeoff between cost\nand variance is important. This paper analyzes the convergence rates of SGD as\na function of time, rather than iterations. This results in a simple rule to\nselect the estimator that leads to the best optimization convergence guarantee.\nThis choice is the same for different variants of SGD, and with different\nassumptions about the objective (e.g. convexity or smoothness). Inspired by\nthis principle, we propose a technique to automatically select an estimator\nwhen a finite pool of estimators is given. Then, we extend to infinite pools of\nestimators, where each one is indexed by control variate weights. This is\nenabled by a reduction to a mixed-integer quadratic program. Empirically,\nautomatically choosing an estimator performs comparably to the best estimator\nchosen with hindsight.\n", "versions": [{"version": "v1", "created": "Tue, 5 Nov 2019 15:57:19 GMT"}], "update_date": "2020-10-23", "authors_parsed": [["Geffner", "Tomas", ""], ["Domke", "Justin", ""]]}, {"id": "1911.01898", "submitter": "Sergey Pavlov", "authors": "Marina Pominova, Ekaterina Kondrateva, Maksim Sharaev, Sergey Pavlov,\n  Alexander Bernstein, Evgeny Burnaev", "title": "3D Deformable Convolutions for MRI classification", "comments": "Accepted to IEEE International Conference on Machine Learning and\n  Applications (ICMLA 2019)", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.IV cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep learning convolutional neural networks have proved to be a powerful tool\nfor MRI analysis. In current work, we explore the potential of the deformable\nconvolutional deep neural network layers for MRI data classification. We\npropose new 3D deformable convolutions(d-convolutions), implement them in\nVoxResNet architecture and apply for structural MRI data classification. We\nshow that 3D d-convolutions outperform standard ones and are effective for\nunprocessed 3D MR images being robust to particular geometrical properties of\nthe data. Firstly proposed dVoxResNet architecture exhibits high potential for\nthe use in MRI data classification.\n", "versions": [{"version": "v1", "created": "Tue, 5 Nov 2019 16:02:10 GMT"}], "update_date": "2019-11-06", "authors_parsed": [["Pominova", "Marina", ""], ["Kondrateva", "Ekaterina", ""], ["Sharaev", "Maksim", ""], ["Pavlov", "Sergey", ""], ["Bernstein", "Alexander", ""], ["Burnaev", "Evgeny", ""]]}, {"id": "1911.01911", "submitter": "Maximilian Denninger", "authors": "Maximilian Denninger, Martin Sundermeyer, Dominik Winkelbauer, Youssef\n  Zidan, Dmitry Olefir, Mohamad Elbadrawy, Ahsan Lodhi, Harinandan Katam", "title": "BlenderProc", "comments": "7 pages, 8 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.GR cs.LG cs.RO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  BlenderProc is a modular procedural pipeline, which helps in generating real\nlooking images for the training of convolutional neural networks. These can be\nused in a variety of use cases including segmentation, depth, normal and pose\nestimation and many others. A key feature of our extension of blender is the\nsimple to use modular pipeline, which was designed to be easily extendable. By\noffering standard modules, which cover a variety of scenarios, we provide a\nstarting point on which new modules can be created.\n", "versions": [{"version": "v1", "created": "Fri, 25 Oct 2019 16:53:12 GMT"}], "update_date": "2019-11-06", "authors_parsed": [["Denninger", "Maximilian", ""], ["Sundermeyer", "Martin", ""], ["Winkelbauer", "Dominik", ""], ["Zidan", "Youssef", ""], ["Olefir", "Dmitry", ""], ["Elbadrawy", "Mohamad", ""], ["Lodhi", "Ahsan", ""], ["Katam", "Harinandan", ""]]}, {"id": "1911.01914", "submitter": "Gonzalo Mart\\'inez-Mu\\~noz", "authors": "Candice Bent\\'ejac and Anna Cs\\\"org\\H{o} and Gonzalo\n  Mart\\'inez-Mu\\~noz", "title": "A Comparative Analysis of XGBoost", "comments": null, "journal-ref": null, "doi": "10.1007/s10462-020-09896-5", "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  XGBoost is a scalable ensemble technique based on gradient boosting that has\ndemonstrated to be a reliable and efficient machine learning challenge solver.\nThis work proposes a practical analysis of how this novel technique works in\nterms of training speed, generalization performance and parameter setup. In\naddition, a comprehensive comparison between XGBoost, random forests and\ngradient boosting has been performed using carefully tuned models as well as\nusing the default settings. The results of this comparison may indicate that\nXGBoost is not necessarily the best choice under all circumstances. Finally an\nextensive analysis of XGBoost parametrization tuning process is carried out.\n", "versions": [{"version": "v1", "created": "Tue, 5 Nov 2019 16:18:29 GMT"}], "update_date": "2020-09-11", "authors_parsed": [["Bent\u00e9jac", "Candice", ""], ["Cs\u00f6rg\u0151", "Anna", ""], ["Mart\u00ednez-Mu\u00f1oz", "Gonzalo", ""]]}, {"id": "1911.01915", "submitter": "Pablo Morales-\\'Alvarez", "authors": "Pablo Morales-\\'Alvarez and Pablo Ruiz and Scott Coughlin and Rafael\n  Molina and Aggelos K. Katsaggelos", "title": "Scalable Variational Gaussian Processes for Crowdsourcing: Glitch\n  Detection in LIGO", "comments": "16 pages, under review", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV gr-qc stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In the last years, crowdsourcing is transforming the way classification\ntraining sets are obtained. Instead of relying on a single expert annotator,\ncrowdsourcing shares the labelling effort among a large number of\ncollaborators. For instance, this is being applied to the data acquired by the\nlaureate Laser Interferometer Gravitational Waves Observatory (LIGO), in order\nto detect glitches which might hinder the identification of true\ngravitational-waves. The crowdsourcing scenario poses new challenging\ndifficulties, as it deals with different opinions from a heterogeneous group of\nannotators with unknown degrees of expertise. Probabilistic methods, such as\nGaussian Processes (GP), have proven successful in modeling this setting.\nHowever, GPs do not scale well to large data sets, which hampers their broad\nadoption in real practice (in particular at LIGO). This has led to the recent\nintroduction of deep learning based crowdsourcing methods, which have become\nthe state-of-the-art. However, the accurate uncertainty quantification of GPs\nhas been partially sacrificed. This is an important aspect for astrophysicists\nin LIGO, since a glitch detection system should provide very accurate\nprobability distributions of its predictions. In this work, we leverage the\nmost popular sparse GP approximation to develop a novel GP based crowdsourcing\nmethod that factorizes into mini-batches. This makes it able to cope with\npreviously-prohibitive data sets. The approach, which we refer to as Scalable\nVariational Gaussian Processes for Crowdsourcing (SVGPCR), brings back GP-based\nmethods to the state-of-the-art, and excels at uncertainty quantification.\nSVGPCR is shown to outperform deep learning based methods and previous\nprobabilistic approaches when applied to the LIGO data. Moreover, its behavior\nand main properties are carefully analyzed in a controlled experiment based on\nthe MNIST data set.\n", "versions": [{"version": "v1", "created": "Tue, 5 Nov 2019 16:20:38 GMT"}], "update_date": "2019-11-06", "authors_parsed": [["Morales-\u00c1lvarez", "Pablo", ""], ["Ruiz", "Pablo", ""], ["Coughlin", "Scott", ""], ["Molina", "Rafael", ""], ["Katsaggelos", "Aggelos K.", ""]]}, {"id": "1911.01916", "submitter": "Xuezhi Wang", "authors": "Xuezhi Wang, Nithum Thain, Anu Sinha, Flavien Prost, Ed H. Chi, Jilin\n  Chen, Alex Beutel", "title": "Practical Compositional Fairness: Understanding Fairness in\n  Multi-Component Recommender Systems", "comments": "WSDM 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  How can we build recommender systems to take into account fairness?\nReal-world recommender systems are often composed of multiple models, built by\nmultiple teams. However, most research on fairness focuses on improving\nfairness in a single model. Further, recent research on classification fairness\nhas shown that combining multiple \"fair\" classifiers can still result in an\n\"unfair\" classification system. This presents a significant challenge: how do\nwe understand and improve fairness in recommender systems composed of multiple\ncomponents?\n  In this paper, we study the compositionality of recommender fairness. We\nconsider two recently proposed fairness ranking metrics: equality of exposure\nand pairwise ranking accuracy. While we show that fairness in recommendation is\nnot guaranteed to compose, we provide theory for a set of conditions under\nwhich fairness of individual models does compose. We then present an analytical\nframework for both understanding whether a real system's signals can achieve\ncompositional fairness, and improving which component would have the greatest\nimpact on the fairness of the overall system. In addition to the theoretical\nresults, we find on multiple datasets -- including a large-scale real-world\nrecommender system -- that the overall system's end-to-end fairness is largely\nachievable by improving fairness in individual components.\n", "versions": [{"version": "v1", "created": "Tue, 5 Nov 2019 16:22:25 GMT"}, {"version": "v2", "created": "Wed, 6 Nov 2019 01:44:40 GMT"}, {"version": "v3", "created": "Wed, 20 Jan 2021 05:44:06 GMT"}, {"version": "v4", "created": "Mon, 25 Jan 2021 21:43:49 GMT"}], "update_date": "2021-01-27", "authors_parsed": [["Wang", "Xuezhi", ""], ["Thain", "Nithum", ""], ["Sinha", "Anu", ""], ["Prost", "Flavien", ""], ["Chi", "Ed H.", ""], ["Chen", "Jilin", ""], ["Beutel", "Alex", ""]]}, {"id": "1911.01918", "submitter": "Qiang Hu", "authors": "Hu Qiang and Gao Feifei and Zhang Hao and Jin Shi and Li Geoffrey Ye", "title": "Deep Learning for MIMO Channel Estimation: Interpretation, Performance,\n  and Comparison", "comments": "An interpretation to DL based channel estimation; We have found that\n  the expressions (19) and (20) in the first version are flawed. To address\n  this issue, we have made necessary modifications to our paper and have\n  updated the second version; Some contents are added and we have updated the\n  third version", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.SP cs.IT cs.LG math.IT", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Deep learning (DL) has emerged as an effective tool for channel estimation in\nwireless communication systems, especially under some imperfect environments.\nHowever, even with such unprecedented success, DL methods are often regarded as\nblack boxes and are lack of explanations on their internal mechanisms, which\nseverely limits further improvement and extension. In this paper, we present a\npreliminary theoretical analysis on DL based channel estimation for\nmultiple-antenna systems to understand and interpret its internal mechanism.\nDeep neural network (DNN) with rectified linear unit (ReLU) activation function\nis mathematically equivalent to a piecewise linear function. Hence, the\ncorresponding DL estimator can achieve universal approximation to a large\nfamily of functions by making efficient use of piecewise linearity. We\ndemonstrate that DL based channel estimation does not restrict to any specific\nsignal model and approaches to the minimum mean-squared error (MMSE) estimation\nin various scenarios without requiring any prior knowledge of channel\nstatistics. Therefore, DL based channel estimation outperforms or is at least\ncomparable with traditional channel estimation, depending on the types of\nchannels. Simulation results confirm the accuracy of the proposed\ninterpretation and demonstrate the effectiveness of DL based channel estimation\nunder both linear and nonlinear signal models.\n", "versions": [{"version": "v1", "created": "Tue, 5 Nov 2019 16:26:08 GMT"}, {"version": "v2", "created": "Sun, 19 Apr 2020 14:14:47 GMT"}, {"version": "v3", "created": "Sat, 16 May 2020 14:04:16 GMT"}], "update_date": "2020-05-19", "authors_parsed": [["Qiang", "Hu", ""], ["Feifei", "Gao", ""], ["Hao", "Zhang", ""], ["Shi", "Jin", ""], ["Ye", "Li Geoffrey", ""]]}, {"id": "1911.01921", "submitter": "Philip Sperl", "authors": "Philip Sperl, Ching-Yu Kao, Peng Chen, Konstantin B\\\"ottinger", "title": "DLA: Dense-Layer-Analysis for Adversarial Example Detection", "comments": null, "journal-ref": null, "doi": "10.1109/EuroSP48549.2020.00021", "report-no": null, "categories": "cs.CR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In recent years Deep Neural Networks (DNNs) have achieved remarkable results\nand even showed super-human capabilities in a broad range of domains. This led\npeople to trust in DNNs' classifications and resulting actions even in\nsecurity-sensitive environments like autonomous driving.\n  Despite their impressive achievements, DNNs are known to be vulnerable to\nadversarial examples. Such inputs contain small perturbations to intentionally\nfool the attacked model.\n  In this paper, we present a novel end-to-end framework to detect such attacks\nduring classification without influencing the target model's performance.\nInspired by recent research in neuron-coverage guided testing we show that\ndense layers of DNNs carry security-sensitive information. With a secondary DNN\nwe analyze the activation patterns of the dense layers during classification\nruntime, which enables effective and real-time detection of adversarial\nexamples.\n  Our prototype implementation successfully detects adversarial examples in\nimage, natural language, and audio processing. Thereby, we cover a variety of\ntarget DNNs, including Long Short Term Memory (LSTM) architectures. In\naddition, to effectively defend against state-of-the-art attacks, our approach\ngeneralizes between different sets of adversarial examples. Thus, our method\nmost likely enables us to detect even future, yet unknown attacks. Finally,\nduring white-box adaptive attacks, we show our method cannot be easily\nbypassed.\n", "versions": [{"version": "v1", "created": "Tue, 5 Nov 2019 16:31:23 GMT"}], "update_date": "2020-12-14", "authors_parsed": [["Sperl", "Philip", ""], ["Kao", "Ching-Yu", ""], ["Chen", "Peng", ""], ["B\u00f6ttinger", "Konstantin", ""]]}, {"id": "1911.01929", "submitter": "Pavel Berkovich", "authors": "Pavel Berkovich, Eric Perim, Wessel Bruinsma", "title": "GP-ALPS: Automatic Latent Process Selection for Multi-Output Gaussian\n  Process Models", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG stat.ME", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A simple and widely adopted approach to extend Gaussian processes (GPs) to\nmultiple outputs is to model each output as a linear combination of a\ncollection of shared, unobserved latent GPs. An issue with this approach is\nchoosing the number of latent processes and their kernels. These choices are\ntypically done manually, which can be time consuming and prone to human biases.\nWe propose Gaussian Process Automatic Latent Process Selection (GP-ALPS), which\nautomatically chooses the latent processes by turning off those that do not\nmeaningfully contribute to explaining the data. We develop a variational\ninference scheme, assess the quality of the variational posterior by comparing\nit against the gold standard MCMC, and demonstrate the suitability of GP-ALPS\nin a set of preliminary experiments.\n", "versions": [{"version": "v1", "created": "Tue, 5 Nov 2019 16:46:37 GMT"}, {"version": "v2", "created": "Tue, 17 Dec 2019 12:02:55 GMT"}], "update_date": "2019-12-18", "authors_parsed": [["Berkovich", "Pavel", ""], ["Perim", "Eric", ""], ["Bruinsma", "Wessel", ""]]}, {"id": "1911.01931", "submitter": "Hanbaek Lyu", "authors": "Hanbaek Lyu, Deanna Needell, and Laura Balzano", "title": "Online matrix factorization for Markovian data and applications to\n  Network Dictionary Learning", "comments": "39 pages, 13 figures", "journal-ref": "Journal of Machine Learning Research 21 (2020)", "doi": null, "report-no": null, "categories": "cs.LG cs.DS math.OC math.PR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Online Matrix Factorization (OMF) is a fundamental tool for dictionary\nlearning problems, giving an approximate representation of complex data sets in\nterms of a reduced number of extracted features. Convergence guarantees for\nmost of the OMF algorithms in the literature assume independence between data\nmatrices, and the case of dependent data streams remains largely unexplored. In\nthis paper, we show that a non-convex generalization of the well-known OMF\nalgorithm for i.i.d. stream of data in \\citep{mairal2010online} converges\nalmost surely to the set of critical points of the expected loss function, even\nwhen the data matrices are functions of some underlying Markov chain satisfying\na mild mixing condition. This allows one to extract features more efficiently\nfrom dependent data streams, as there is no need to subsample the data sequence\nto approximately satisfy the independence assumption. As the main application,\nby combining online non-negative matrix factorization and a recent MCMC\nalgorithm for sampling motifs from networks, we propose a novel framework of\nNetwork Dictionary Learning, which extracts ``network dictionary patches' from\na given network in an online manner that encodes main features of the network.\nWe demonstrate this technique and its application to network denoising problems\non real-world network data.\n", "versions": [{"version": "v1", "created": "Tue, 5 Nov 2019 16:47:28 GMT"}, {"version": "v2", "created": "Wed, 6 Nov 2019 01:32:44 GMT"}, {"version": "v3", "created": "Sat, 9 Nov 2019 05:52:03 GMT"}, {"version": "v4", "created": "Thu, 16 Apr 2020 01:01:38 GMT"}, {"version": "v5", "created": "Wed, 14 Oct 2020 03:27:15 GMT"}, {"version": "v6", "created": "Sat, 7 Nov 2020 22:41:18 GMT"}], "update_date": "2020-11-10", "authors_parsed": [["Lyu", "Hanbaek", ""], ["Needell", "Deanna", ""], ["Balzano", "Laura", ""]]}, {"id": "1911.01933", "submitter": "Amelia Drew", "authors": "Amelia Drew and Alexander Heinecke", "title": "Training Neural Machine Translation (NMT) Models using Tensor Train\n  Decomposition on TensorFlow (T3F)", "comments": "10 pages, 2 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CL stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We implement a Tensor Train layer in the TensorFlow Neural Machine\nTranslation (NMT) model using the t3f library. We perform training runs on the\nIWSLT English-Vietnamese '15 and WMT German-English '16 datasets with learning\nrates $\\in \\{0.0004,0.0008,0.0012\\}$, maximum ranks $\\in \\{2,4,8,16\\}$ and a\nrange of core dimensions. We compare against a target BLEU test score of 24.0,\nobtained by our benchmark run. For the IWSLT English-Vietnamese training, we\nobtain BLEU test/dev scores of 24.0/21.9 and 24.2/21.9 using core dimensions\n$(2, 2, 256) \\times (2, 2, 512)$ with learning rate 0.0012 and rank\ndistributions $(1,4,4,1)$ and $(1,4,16,1)$ respectively. These runs use 113\\%\nand 397\\% of the flops of the benchmark run respectively. We find that, of the\nparameters surveyed, a higher learning rate and more `rectangular' core\ndimensions generally produce higher BLEU scores. For the WMT German-English\ndataset, we obtain BLEU scores of 24.0/23.8 using core dimensions $(4, 4, 128)\n\\times (4, 4, 256)$ with learning rate 0.0012 and rank distribution\n$(1,2,2,1)$. We discuss the potential for future optimization and application\nof Tensor Train decomposition to other NMT models.\n", "versions": [{"version": "v1", "created": "Tue, 5 Nov 2019 16:48:30 GMT"}], "update_date": "2019-11-06", "authors_parsed": [["Drew", "Amelia", ""], ["Heinecke", "Alexander", ""]]}, {"id": "1911.01944", "submitter": "Yaniv Shulman", "authors": "Yaniv Shulman", "title": "Dynamic Time Warp Convolutional Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Where dealing with temporal sequences it is fair to assume that the same kind\nof deformations that motivated the development of the Dynamic Time Warp\nalgorithm could be relevant also in the calculation of the dot product\n(\"convolution\") in a 1-D convolution layer. In this work a method is proposed\nfor aligning the convolution filter and the input where they are locally out of\nphase utilising an algorithm similar to the Dynamic Time Warp. The proposed\nmethod enables embedding a non-parametric warping of temporal sequences for\nincreasing similarity directly in deep networks and can expand on the\ngeneralisation capabilities and the capacity of standard 1-D convolution layer\nwhere local sequential deformations are present in the input. Experimental\nresults demonstrate the proposed method exceeds or matches the standard 1-D\nconvolution layer in terms of the maximum accuracy achieved on a number of time\nseries classification tasks. In addition the impact of different\nhyperparameters settings is investigated given different datasets and the\nresults support the conclusions of previous work done in relation to the choice\nof DTW parameter values. The proposed layer can be freely integrated with other\ntypical layers to compose deep artificial neural networks of an arbitrary\narchitecture that are trained using standard stochastic gradient descent.\n", "versions": [{"version": "v1", "created": "Tue, 5 Nov 2019 17:08:02 GMT"}], "update_date": "2019-11-06", "authors_parsed": [["Shulman", "Yaniv", ""]]}, {"id": "1911.01952", "submitter": "Wei Huang", "authors": "Wei Huang, Youcheng Sun, Xingyu Zhao, James Sharp, Wenjie Ruan, Jie\n  Meng, and Xiaowei Huang", "title": "Coverage Guided Testing for Recurrent Neural Networks", "comments": "Accepted by IEEE Transactions on Reliability", "journal-ref": null, "doi": "10.1109/TR.2021.3080664", "report-no": null, "categories": "cs.LG cs.NE", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  Recurrent neural networks (RNNs) have been applied to a broad range of\napplications, including natural language processing, drug discovery, and video\nrecognition. Their vulnerability to input perturbation is also known. Aligning\nwith a view from software defect detection, this paper aims to develop a\ncoverage guided testing approach to systematically exploit the internal\nbehaviour of RNNs, with the expectation that such testing can detect defects\nwith high possibility. Technically, the long short term memory network (LSTM),\na major class of RNNs, is thoroughly studied. A family of three test metrics\nare designed to quantify not only the values but also the temporal relations\n(including both step-wise and bounded-length) exhibited when LSTM processing\ninputs. A genetic algorithm is applied to efficiently generate test cases. The\ntest metrics and test case generation algorithm are implemented into a tool\nTestRNN, which is then evaluated on a set of LSTM benchmarks. Experiments\nconfirm that TestRNN has advantages over the state-of-art tool DeepStellar and\nattack-based defect detection methods, owing to its working with finer temporal\nsemantics and the consideration of the naturalness of input perturbation.\nFurthermore, TestRNN enables meaningful information to be collected and\nexhibited for users to understand the testing results, which is an important\nstep towards interpretable neural network testing.\n", "versions": [{"version": "v1", "created": "Tue, 5 Nov 2019 17:21:30 GMT"}, {"version": "v2", "created": "Wed, 25 Mar 2020 12:55:28 GMT"}, {"version": "v3", "created": "Thu, 13 May 2021 14:20:55 GMT"}], "update_date": "2021-05-14", "authors_parsed": [["Huang", "Wei", ""], ["Sun", "Youcheng", ""], ["Zhao", "Xingyu", ""], ["Sharp", "James", ""], ["Ruan", "Wenjie", ""], ["Meng", "Jie", ""], ["Huang", "Xiaowei", ""]]}, {"id": "1911.01953", "submitter": "Christino Tamon", "authors": "Christino Tamon and Weichen Xie", "title": "A Note on Quantum Markov Models", "comments": "18 pages, 4 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "quant-ph cs.LG math.OC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The study of Markov models is central to control theory and machine learning.\nA quantum analogue of partially observable Markov decision process was studied\nin (Barry, Barry, and Aaronson, Phys. Rev. A, 90, 2014). It was proved that\ngoal-state reachability is undecidable in the quantum setting, whereas it is\ndecidable classically. In contrast to this classical-to-quantum transition from\ndecidable to undecidable, we observe that the problem of approximating the\noptimal policy which maximizes the average discounted reward over an infinite\nhorizon remains decidable in the quantum setting. Given that most relevant\nproblems related to Markov decision process are undecidable classically (which\nimmediately implies undecidability in the quantum case), this provides one of\nthe few examples where the quantum problem is tractable.\n", "versions": [{"version": "v1", "created": "Tue, 5 Nov 2019 17:22:38 GMT"}], "update_date": "2019-11-06", "authors_parsed": [["Tamon", "Christino", ""], ["Xie", "Weichen", ""]]}, {"id": "1911.01971", "submitter": "Elena Limonova", "authors": "Elena Limonova, Daniil Matveev, Dmitry Nikolaev, Vladimir V. Arlazarov", "title": "Bipolar Morphological Neural Networks: Convolution Without\n  Multiplication", "comments": "Submitted to International Conference on Machine Vision 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.CV cs.LG eess.IV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In the paper we introduce a novel bipolar morphological neuron and bipolar\nmorphological layer models. The models use only such operations as addition,\nsubtraction and maximum inside the neuron and exponent and logarithm as\nactivation functions for the layer. The proposed models unlike previously\nintroduced morphological neural networks approximate the classical computations\nand show better recognition results. We also propose layer-by-layer approach to\ntrain the bipolar morphological networks, which can be further developed to an\nincremental approach for separate neurons to get higher accuracy. Both these\napproaches do not require special training algorithms and can use a variety of\ngradient descent methods. To demonstrate efficiency of the proposed model we\nconsider classical convolutional neural networks and convert the pre-trained\nconvolutional layers to the bipolar morphological layers. Seeing that the\nexperiments on recognition of MNIST and MRZ symbols show only moderate decrease\nof accuracy after conversion and training, bipolar neuron model can provide\nfaster inference and be very useful in mobile and embedded systems.\n", "versions": [{"version": "v1", "created": "Tue, 5 Nov 2019 17:57:35 GMT"}], "update_date": "2019-11-06", "authors_parsed": [["Limonova", "Elena", ""], ["Matveev", "Daniil", ""], ["Nikolaev", "Dmitry", ""], ["Arlazarov", "Vladimir V.", ""]]}, {"id": "1911.01986", "submitter": "Xuan Phi Nguyen", "authors": "Xuan-Phi Nguyen, Shafiq Joty, Wu Kui, Ai Ti Aw", "title": "Data Diversification: A Simple Strategy For Neural Machine Translation", "comments": "Accepted as a conference paper at NeurIPS 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce Data Diversification: a simple but effective strategy to boost\nneural machine translation (NMT) performance. It diversifies the training data\nby using the predictions of multiple forward and backward models and then\nmerging them with the original dataset on which the final NMT model is trained.\nOur method is applicable to all NMT models. It does not require extra\nmonolingual data like back-translation, nor does it add more computations and\nparameters like ensembles of models. Our method achieves state-of-the-art BLEU\nscores of 30.7 and 43.7 in the WMT'14 English-German and English-French\ntranslation tasks, respectively. It also substantially improves on 8 other\ntranslation tasks: 4 IWSLT tasks (English-German and English-French) and 4\nlow-resource translation tasks (English-Nepali and English-Sinhala). We\ndemonstrate that our method is more effective than knowledge distillation and\ndual learning, it exhibits strong correlation with ensembles of models, and it\ntrades perplexity off for better BLEU score. We have released our source code\nat https://github.com/nxphi47/data_diversification\n", "versions": [{"version": "v1", "created": "Tue, 5 Nov 2019 18:25:42 GMT"}, {"version": "v2", "created": "Thu, 9 Apr 2020 10:32:18 GMT"}, {"version": "v3", "created": "Wed, 3 Jun 2020 16:06:04 GMT"}, {"version": "v4", "created": "Sun, 4 Oct 2020 15:08:17 GMT"}], "update_date": "2020-10-06", "authors_parsed": [["Nguyen", "Xuan-Phi", ""], ["Joty", "Shafiq", ""], ["Kui", "Wu", ""], ["Aw", "Ai Ti", ""]]}, {"id": "1911.02002", "submitter": "Luca Celotti", "authors": "Luca Celotti, Simon Brodeur, Jean Rouat", "title": "Language coverage and generalization in RNN-based continuous sentence\n  embeddings for interacting agents", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Continuous sentence embeddings using recurrent neural networks (RNNs), where\nvariable-length sentences are encoded into fixed-dimensional vectors, are often\nthe main building blocks of architectures applied to language tasks such as\ndialogue generation. While it is known that those embeddings are able to learn\nsome structures of language (e.g. grammar) in a purely data-driven manner,\nthere is very little work on the objective evaluation of their ability to cover\nthe whole language space and to generalize to sentences outside the language\nbias of the training data. Using a manually designed context-free grammar (CFG)\nto generate a large-scale dataset of sentences related to the content of\nrealistic 3D indoor scenes, we evaluate the language coverage and\ngeneralization abilities of the most common continuous sentence embeddings\nbased on RNNs. We also propose a new embedding method based on arithmetic\ncoding, AriEL, that is not data-driven and that efficiently encodes in\ncontinuous space any sentence from the CFG. We find that RNN-based embeddings\nunderfit the training data and cover only a small subset of the language\ndefined by the CFG. They also fail to learn the underlying CFG and generalize\nto unbiased sentences from that same CFG. We found that AriEL provides an\ninsightful baseline.\n", "versions": [{"version": "v1", "created": "Tue, 5 Nov 2019 18:57:50 GMT"}], "update_date": "2019-11-06", "authors_parsed": [["Celotti", "Luca", ""], ["Brodeur", "Simon", ""], ["Rouat", "Jean", ""]]}, {"id": "1911.02007", "submitter": "Hongjia Li", "authors": "Hongjia Li, Sheng Lin, Ning Liu, Caiwen Ding, and Yanzhi Wang", "title": "Deep Compressed Pneumonia Detection for Low-Power Embedded Devices", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.IV cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep neural networks (DNNs) have been expanded into medical fields and\ntriggered the revolution of some medical applications by extracting complex\nfeatures and achieving high accuracy and performance, etc. On the contrast, the\nlarge-scale network brings high requirements of both memory storage and\ncomputation resource, especially for portable medical devices and other\nembedded systems. In this work, we first train a DNN for pneumonia detection\nusing the dataset provided by RSNA Pneumonia Detection Challenge. To overcome\nhardware limitation for implementing large-scale networks, we develop a\nsystematic structured weight pruning method with filter sparsity, column\nsparsity and combined sparsity. Experiments show that we can achieve up to 36x\ncompression ratio compared to the original model with 106 layers, while\nmaintaining no accuracy degradation. We evaluate the proposed methods on an\nembedded low-power device, Jetson TX2, and achieve low power usage and high\nenergy efficiency.\n", "versions": [{"version": "v1", "created": "Mon, 4 Nov 2019 20:05:40 GMT"}], "update_date": "2019-11-07", "authors_parsed": [["Li", "Hongjia", ""], ["Lin", "Sheng", ""], ["Liu", "Ning", ""], ["Ding", "Caiwen", ""], ["Wang", "Yanzhi", ""]]}, {"id": "1911.02008", "submitter": "Yang-Hui He", "authors": "Laura Alessandretti, Andrea Baronchelli, Yang-Hui He", "title": "Machine Learning meets Number Theory: The Data Science of\n  Birch-Swinnerton-Dyer", "comments": "40 pages, 19 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.NT cs.LG hep-th stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Empirical analysis is often the first step towards the birth of a conjecture.\nThis is the case of the Birch-Swinnerton-Dyer (BSD) Conjecture describing the\nrational points on an elliptic curve, one of the most celebrated unsolved\nproblems in mathematics. Here we extend the original empirical approach, to the\nanalysis of the Cremona database of quantities relevant to BSD, inspecting more\nthan 2.5 million elliptic curves by means of the latest techniques in data\nscience, machine-learning and topological data analysis. Key quantities such as\nrank, Weierstrass coefficients, period, conductor, Tamagawa number, regulator\nand order of the Tate-Shafarevich group give rise to a high-dimensional\npoint-cloud whose statistical properties we investigate. We reveal patterns and\ndistributions in the rank versus Weierstrass coefficients, as well as the Beta\ndistribution of the BSD ratio of the quantities. Via gradient boosted trees,\nmachine learning is applied in finding inter-correlation amongst the various\nquantities. We anticipate that our approach will spark further research on the\nstatistical properties of large datasets in Number Theory and more in general\nin pure Mathematics.\n", "versions": [{"version": "v1", "created": "Mon, 4 Nov 2019 21:52:36 GMT"}], "update_date": "2019-11-18", "authors_parsed": [["Alessandretti", "Laura", ""], ["Baronchelli", "Andrea", ""], ["He", "Yang-Hui", ""]]}, {"id": "1911.02014", "submitter": "Zhanghexuan Ji", "authors": "Zhanghexuan Ji, Yan Shen, Chunwei Ma, Mingchen Gao", "title": "Scribble-based Hierarchical Weakly Supervised Learning for Brain Tumor\n  Segmentation", "comments": "22nd International Conference on Medical Image Computing and Computer\n  Assisted Intervention (MICCAI 2019) Accept", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.IV cs.CV cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The recent state-of-the-art deep learning methods have significantly improved\nbrain tumor segmentation. However, fully supervised training requires a large\namount of manually labeled masks, which is highly time-consuming and needs\ndomain expertise. Weakly supervised learning with scribbles provides a good\ntrade-off between model accuracy and the effort of manual labeling. However,\nfor segmenting the hierarchical brain tumor structures, manually labeling\nscribbles for each substructure could still be demanding. In this paper, we use\nonly two kinds of weak labels, i.e., scribbles on whole tumor and healthy brain\ntissue, and global labels for the presence of each substructure, to train a\ndeep learning model to segment all the sub-regions. Specifically, we train two\nnetworks in two phases: first, we only use whole tumor scribbles to train a\nwhole tumor (WT) segmentation network, which roughly recovers the WT mask of\ntraining data; then we cluster the WT region with the guide of global labels.\nThe rough substructure segmentation from clustering is used as weak labels to\ntrain the second network. The dense CRF loss is used to refine the weakly\nsupervised segmentation. We evaluate our approach on the BraTS2017 dataset and\nachieve competitive WT dice score as well as comparable scores on substructure\nsegmentation compared to an upper bound when trained with fully annotated\nmasks.\n", "versions": [{"version": "v1", "created": "Tue, 5 Nov 2019 16:56:35 GMT"}], "update_date": "2019-11-07", "authors_parsed": [["Ji", "Zhanghexuan", ""], ["Shen", "Yan", ""], ["Ma", "Chunwei", ""], ["Gao", "Mingchen", ""]]}, {"id": "1911.02035", "submitter": "Sitan Chen", "authors": "Sitan Chen, Jerry Li, Ankur Moitra", "title": "Efficiently Learning Structured Distributions from Untrusted Batches", "comments": "46 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the problem, introduced by Qiao and Valiant, of learning from\nuntrusted batches. Here, we assume $m$ users, all of whom have samples from\nsome underlying distribution $p$ over $1, \\ldots, n$. Each user sends a batch\nof $k$ i.i.d. samples from this distribution; however an $\\epsilon$-fraction of\nusers are untrustworthy and can send adversarially chosen responses. The goal\nis then to learn $p$ in total variation distance. When $k = 1$ this is the\nstandard robust univariate density estimation setting and it is well-understood\nthat $\\Omega (\\epsilon)$ error is unavoidable. Suprisingly, Qiao and Valiant\ngave an estimator which improves upon this rate when $k$ is large.\nUnfortunately, their algorithms run in time exponential in either $n$ or $k$.\n  We first give a sequence of polynomial time algorithms whose estimation error\napproaches the information-theoretically optimal bound for this problem. Our\napproach is based on recent algorithms derived from the sum-of-squares\nhierarchy, in the context of high-dimensional robust estimation. We show that\nalgorithms for learning from untrusted batches can also be cast in this\nframework, but by working with a more complicated set of test functions.\n  It turns out this abstraction is quite powerful and can be generalized to\nincorporate additional problem specific constraints. Our second and main result\nis to show that this technology can be leveraged to build in prior knowledge\nabout the shape of the distribution. Crucially, this allows us to reduce the\nsample complexity of learning from untrusted batches to polylogarithmic in $n$\nfor most natural classes of distributions, which is important in many\napplications. To do so, we demonstrate that these sum-of-squares algorithms for\nrobust mean estimation can be made to handle complex combinatorial constraints\n(e.g. those arising from VC theory), which may be of independent technical\ninterest.\n", "versions": [{"version": "v1", "created": "Tue, 5 Nov 2019 19:01:46 GMT"}], "update_date": "2019-11-07", "authors_parsed": [["Chen", "Sitan", ""], ["Li", "Jerry", ""], ["Moitra", "Ankur", ""]]}, {"id": "1911.02042", "submitter": "Thai Le", "authors": "Thai Le, Suhang Wang, Dongwon Lee", "title": "GRACE: Generating Concise and Informative Contrastive Sample to Explain\n  Neural Network Model's Prediction", "comments": "Accepted at the 26th SIGKDD Conference on Knowledge Discovery and\n  Data Mining (KDD 2020)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Despite the recent development in the topic of explainable AI/ML for image\nand text data, the majority of current solutions are not suitable to explain\nthe prediction of neural network models when the datasets are tabular and their\nfeatures are in high-dimensional vectorized formats. To mitigate this\nlimitation, therefore, we borrow two notable ideas (i.e., \"explanation by\nintervention\" from causality and \"explanation are contrastive\" from philosophy)\nand propose a novel solution, named as GRACE, that better explains neural\nnetwork models' predictions for tabular datasets. In particular, given a\nmodel's prediction as label X, GRACE intervenes and generates a\nminimally-modified contrastive sample to be classified as Y, with an intuitive\ntextual explanation, answering the question of \"Why X rather than Y?\" We carry\nout comprehensive experiments using eleven public datasets of different scales\nand domains (e.g., # of features ranges from 5 to 216) and compare GRACE with\ncompeting baselines on different measures: fidelity, conciseness, info-gain,\nand influence. The user-studies show that our generated explanation is not only\nmore intuitive and easy-to-understand but also facilitates end-users to make as\nmuch as 60% more accurate post-explanation decisions than that of Lime.\n", "versions": [{"version": "v1", "created": "Tue, 5 Nov 2019 19:06:29 GMT"}, {"version": "v2", "created": "Thu, 11 Jun 2020 15:08:19 GMT"}, {"version": "v3", "created": "Sun, 21 Jun 2020 17:49:01 GMT"}, {"version": "v4", "created": "Sun, 27 Sep 2020 10:17:36 GMT"}, {"version": "v5", "created": "Mon, 26 Oct 2020 11:43:03 GMT"}], "update_date": "2020-10-27", "authors_parsed": [["Le", "Thai", ""], ["Wang", "Suhang", ""], ["Lee", "Dongwon", ""]]}, {"id": "1911.02048", "submitter": "Pavel Sulimov Mr", "authors": "Pavel Sulimov, Elena Sukmanova, Roman Chereshnev, and Attila\n  Kertesz-Farkas", "title": "Guided Layer-wise Learning for Deep Models using Side Information", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Training of deep models for classification tasks is hindered by local minima\nproblems and vanishing gradients, while unsupervised layer-wise pretraining\ndoes not exploit information from class labels. Here, we propose a new\nregularization technique, called diversifying regularization (DR), which\napplies a penalty on hidden units at any layer if they obtain similar features\nfor different types of data. For generative models, DR is defined as divergence\nover the variational posteriori distributions and included in the maximum\nlikelihood estimation as a prior. Thus, DR includes class label information for\ngreedy pretraining of deep belief networks which result in a better weight\ninitialization for fine-tuning methods. On the other hand, for discriminative\ntraining of deep neural networks, DR is defined as a distance over the features\nand included in the learning objective. With our experimental tests, we show\nthat DR can help the backpropagation to cope with vanishing gradient problems\nand to provide faster convergence and smaller generalization errors.\n", "versions": [{"version": "v1", "created": "Tue, 5 Nov 2019 19:27:16 GMT"}], "update_date": "2019-11-07", "authors_parsed": [["Sulimov", "Pavel", ""], ["Sukmanova", "Elena", ""], ["Chereshnev", "Roman", ""], ["Kertesz-Farkas", "Attila", ""]]}, {"id": "1911.02052", "submitter": "Zhisheng Xiao", "authors": "Zhisheng Xiao, Qing Yan, Yali Amit", "title": "A Method to Model Conditional Distributions with Normalizing Flows", "comments": "10 pages. Work in progress", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this work, we investigate the use of normalizing flows to model\nconditional distributions. In particular, we use our proposed method to analyze\ninverse problems with invertible neural networks by maximizing the posterior\nlikelihood. Our method uses only a single loss and is easy to train. This is an\nimprovement on the previous method that solves similar inverse problems with\ninvertible neural networks but which involves a combination of several loss\nterms with ad-hoc weighting. In addition, our method provides a natural\nframework to incorporate conditioning in normalizing flows, and therefore, we\ncan train an invertible network to perform conditional generation. We analyze\nour method and perform a careful comparison with previous approaches. Simple\nexperiments show the effectiveness of our method, and more comprehensive\nexperimental evaluations are undergoing.\n", "versions": [{"version": "v1", "created": "Tue, 5 Nov 2019 19:37:37 GMT"}], "update_date": "2019-11-07", "authors_parsed": [["Xiao", "Zhisheng", ""], ["Yan", "Qing", ""], ["Amit", "Yali", ""]]}, {"id": "1911.02053", "submitter": "Sebastian Claici", "authors": "Pierre Monteiller, Sebastian Claici, Edward Chien, Farzaneh\n  Mirzazadeh, Justin Solomon, Mikhail Yurochkin", "title": "Alleviating Label Switching with Optimal Transport", "comments": "33rd Conference on Neural Information Processing Systems (NeurIPS\n  2019), Vancouver, Canada", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Label switching is a phenomenon arising in mixture model posterior inference\nthat prevents one from meaningfully assessing posterior statistics using\nstandard Monte Carlo procedures. This issue arises due to invariance of the\nposterior under actions of a group; for example, permuting the ordering of\nmixture components has no effect on the likelihood. We propose a resolution to\nlabel switching that leverages machinery from optimal transport. Our algorithm\nefficiently computes posterior statistics in the quotient space of the symmetry\ngroup. We give conditions under which there is a meaningful solution to label\nswitching and demonstrate advantages over alternative approaches on simulated\nand real data.\n", "versions": [{"version": "v1", "created": "Tue, 5 Nov 2019 19:40:27 GMT"}, {"version": "v2", "created": "Sun, 10 Nov 2019 20:34:57 GMT"}], "update_date": "2019-11-12", "authors_parsed": [["Monteiller", "Pierre", ""], ["Claici", "Sebastian", ""], ["Chien", "Edward", ""], ["Mirzazadeh", "Farzaneh", ""], ["Solomon", "Justin", ""], ["Yurochkin", "Mikhail", ""]]}, {"id": "1911.02054", "submitter": "Xingchao Peng", "authors": "Xingchao Peng, Zijun Huang, Yizhe Zhu, Kate Saenko", "title": "Federated Adversarial Domain Adaptation", "comments": "Published as a conference paper at ICLR 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Federated learning improves data privacy and efficiency in machine learning\nperformed over networks of distributed devices, such as mobile phones, IoT and\nwearable devices, etc. Yet models trained with federated learning can still\nfail to generalize to new devices due to the problem of domain shift. Domain\nshift occurs when the labeled data collected by source nodes statistically\ndiffers from the target node's unlabeled data. In this work, we present a\nprincipled approach to the problem of federated domain adaptation, which aims\nto align the representations learned among the different nodes with the data\ndistribution of the target node. Our approach extends adversarial adaptation\ntechniques to the constraints of the federated setting. In addition, we devise\na dynamic attention mechanism and leverage feature disentanglement to enhance\nknowledge transfer. Empirically, we perform extensive experiments on several\nimage and text classification tasks and show promising results under\nunsupervised federated domain adaptation setting.\n", "versions": [{"version": "v1", "created": "Tue, 5 Nov 2019 19:45:49 GMT"}, {"version": "v2", "created": "Sat, 21 Dec 2019 22:03:36 GMT"}], "update_date": "2019-12-24", "authors_parsed": [["Peng", "Xingchao", ""], ["Huang", "Zijun", ""], ["Zhu", "Yizhe", ""], ["Saenko", "Kate", ""]]}, {"id": "1911.02065", "submitter": "Ibrahim Abdelaziz", "authors": "Maxwell Crouse, Ibrahim Abdelaziz, Bassem Makni, Spencer Whitehead,\n  Cristina Cornelio, Pavan Kapanipathi, Kavitha Srinivas, Veronika Thost,\n  Michael Witbrock, Achille Fokoue", "title": "A Deep Reinforcement Learning Approach to First-Order Logic Theorem\n  Proving", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Automated theorem provers have traditionally relied on manually tuned\nheuristics to guide how they perform proof search. Deep reinforcement learning\nhas been proposed as a way to obviate the need for such heuristics, however,\nits deployment in automated theorem proving remains a challenge. In this paper\nwe introduce TRAIL, a system that applies deep reinforcement learning to\nsaturation-based theorem proving. TRAIL leverages (a) a novel neural\nrepresentation of the state of a theorem prover and (b) a novel\ncharacterization of the inference selection process in terms of an\nattention-based action policy. We show through systematic analysis that these\nmechanisms allow TRAIL to significantly outperform previous\nreinforcement-learning-based theorem provers on two benchmark datasets for\nfirst-order logic automated theorem proving (proving around 15% more theorems).\n", "versions": [{"version": "v1", "created": "Tue, 5 Nov 2019 20:03:58 GMT"}, {"version": "v2", "created": "Thu, 13 Feb 2020 18:14:22 GMT"}, {"version": "v3", "created": "Wed, 16 Sep 2020 01:22:17 GMT"}], "update_date": "2020-09-17", "authors_parsed": [["Crouse", "Maxwell", ""], ["Abdelaziz", "Ibrahim", ""], ["Makni", "Bassem", ""], ["Whitehead", "Spencer", ""], ["Cornelio", "Cristina", ""], ["Kapanipathi", "Pavan", ""], ["Srinivas", "Kavitha", ""], ["Thost", "Veronika", ""], ["Witbrock", "Michael", ""], ["Fokoue", "Achille", ""]]}, {"id": "1911.02067", "submitter": "Humoud Alsabah", "authors": "Humoud Alsabah, Agostino Capponi, Octavio Ruiz Lacedelli, and Matt\n  Stern", "title": "Robo-advising: Learning Investors' Risk Preferences via Portfolio\n  Choices", "comments": null, "journal-ref": null, "doi": "10.1093/jjfinec/nbz040", "report-no": null, "categories": "q-fin.PM cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce a reinforcement learning framework for retail robo-advising. The\nrobo-advisor does not know the investor's risk preference, but learns it over\ntime by observing her portfolio choices in different market environments. We\ndevelop an exploration-exploitation algorithm which trades off costly\nsolicitations of portfolio choices by the investor with autonomous trading\ndecisions based on stale estimates of investor's risk aversion. We show that\nthe algorithm's value function converges to the optimal value function of an\nomniscient robo-advisor over a number of periods that is polynomial in the\nstate and action space. By correcting for the investor's mistakes, the\nrobo-advisor may outperform a stand-alone investor, regardless of the\ninvestor's opportunity cost for making portfolio decisions.\n", "versions": [{"version": "v1", "created": "Tue, 5 Nov 2019 20:08:43 GMT"}, {"version": "v2", "created": "Sat, 16 Nov 2019 16:56:03 GMT"}], "update_date": "2020-04-16", "authors_parsed": [["Alsabah", "Humoud", ""], ["Capponi", "Agostino", ""], ["Lacedelli", "Octavio Ruiz", ""], ["Stern", "Matt", ""]]}, {"id": "1911.02069", "submitter": "Alper Ahmeto\\u{g}lu", "authors": "Alper Ahmeto\\u{g}lu and Ethem Alpayd{\\i}n", "title": "Hierarchical Mixtures of Generators for Adversarial Learning", "comments": null, "journal-ref": null, "doi": "10.1109/ICPR48806.2021.9413249", "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Generative adversarial networks (GANs) are deep neural networks that allow us\nto sample from an arbitrary probability distribution without explicitly\nestimating the distribution. There is a generator that takes a latent vector as\ninput and transforms it into a valid sample from the distribution. There is\nalso a discriminator that is trained to discriminate such fake samples from\ntrue samples of the distribution; at the same time, the generator is trained to\ngenerate fakes that the discriminator cannot tell apart from the true samples.\nInstead of learning a global generator, a recent approach involves training\nmultiple generators each responsible from one part of the distribution. In this\nwork, we review such approaches and propose the hierarchical mixture of\ngenerators, inspired from the hierarchical mixture of experts model, that\nlearns a tree structure implementing a hierarchical clustering with soft splits\nin the decision nodes and local generators in the leaves. Since the generators\nare combined softly, the whole model is continuous and can be trained using\ngradient-based optimization, just like the original GAN model. Our experiments\non five image data sets, namely, MNIST, FashionMNIST, UTZap50K, Oxford Flowers,\nand CelebA, show that our proposed model generates samples of high quality and\ndiversity in terms of popular GAN evaluation metrics. The learned hierarchical\nstructure also leads to knowledge extraction.\n", "versions": [{"version": "v1", "created": "Tue, 5 Nov 2019 20:13:31 GMT"}], "update_date": "2021-06-22", "authors_parsed": [["Ahmeto\u011flu", "Alper", ""], ["Alpayd\u0131n", "Ethem", ""]]}, {"id": "1911.02073", "submitter": "Max Morrison", "authors": "Max Morrison, Bryan Pardo", "title": "OtoMechanic: Auditory Automobile Diagnostics via Query-by-Example", "comments": "Submitted to Workshop on Detection and Classification of Acoustic\n  Scenes and Events 2019 (DCASE2019)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SD cs.LG eess.AS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Early detection and repair of failing components in automobiles reduces the\nrisk of vehicle failure in life-threatening situations. Many automobile\ncomponents in need of repair produce characteristic sounds. For example, loose\ndrive belts emit a high-pitched squeaking sound, and bad starter motors have a\ncharacteristic whirring or clicking noise. Often drivers can tell that the\nsound of their car is not normal, but may not be able to identify the cause. To\nmitigate this knowledge gap, we have developed OtoMechanic, a web application\nto detect and diagnose vehicle component issues from their corresponding\nsounds. It compares a user's recording of a problematic sound to a database of\nannotated sounds caused by failing automobile components. OtoMechanic returns\nthe most similar sounds, and provides weblinks for more information on the\ndiagnosis associated with each sound, along with an estimate of the similarity\nof each retrieved sound. In user studies, we find that OtoMechanic\nsignificantly increases diagnostic accuracy relative to a baseline accuracy of\nconsumer performance.\n", "versions": [{"version": "v1", "created": "Tue, 5 Nov 2019 20:25:25 GMT"}], "update_date": "2019-11-07", "authors_parsed": [["Morrison", "Max", ""], ["Pardo", "Bryan", ""]]}, {"id": "1911.02074", "submitter": "Kunal Talwar", "authors": "Kunal Talwar", "title": "Computational Separations between Sampling and Optimization", "comments": "NeurIPS 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Two commonly arising computational tasks in Bayesian learning are\nOptimization (Maximum A Posteriori estimation) and Sampling (from the posterior\ndistribution). In the convex case these two problems are efficiently reducible\nto each other. Recent work (Ma et al. 2019) shows that in the non-convex case,\nsampling can sometimes be provably faster. We present a simpler and stronger\nseparation. We then compare sampling and optimization in more detail and show\nthat they are provably incomparable: there are families of continuous functions\nfor which optimization is easy but sampling is NP-hard, and vice versa.\nFurther, we show function families that exhibit a sharp phase transition in the\ncomputational complexity of sampling, as one varies the natural temperature\nparameter. Our results draw on a connection to analogous separations in the\ndiscrete setting which are well-studied.\n", "versions": [{"version": "v1", "created": "Tue, 5 Nov 2019 20:29:20 GMT"}], "update_date": "2019-11-07", "authors_parsed": [["Talwar", "Kunal", ""]]}, {"id": "1911.02079", "submitter": "Hui Guan", "authors": "Hui Guan, Andrey Malevich, Jiyan Yang, Jongsoo Park, Hector Yuen", "title": "Post-Training 4-bit Quantization on Embedding Tables", "comments": "Accepted in MLSys@NeurIPS'19 (http://learningsys.org/neurips19/)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.IR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Continuous representations have been widely adopted in recommender systems\nwhere a large number of entities are represented using embedding vectors. As\nthe cardinality of the entities increases, the embedding components can easily\ncontain millions of parameters and become the bottleneck in both storage and\ninference due to large memory consumption. This work focuses on post-training\n4-bit quantization on the continuous embeddings. We propose row-wise uniform\nquantization with greedy search and codebook-based quantization that\nconsistently outperforms state-of-the-art quantization approaches on reducing\naccuracy degradation. We deploy our uniform quantization technique on a\nproduction model in Facebook and demonstrate that it can reduce the model size\nto only 13.89% of the single-precision version while the model quality stays\nneutral.\n", "versions": [{"version": "v1", "created": "Tue, 5 Nov 2019 20:43:51 GMT"}], "update_date": "2019-11-07", "authors_parsed": [["Guan", "Hui", ""], ["Malevich", "Andrey", ""], ["Yang", "Jiyan", ""], ["Park", "Jongsoo", ""], ["Yuen", "Hector", ""]]}, {"id": "1911.02080", "submitter": "Weilin Fu", "authors": "Weilin Fu and Lennart Husvogt and Stefan Ploner James G. Fujimoto\n  Andreas Maier", "title": "Lesson Learnt: Modularization of Deep Networks Allow Cross-Modality\n  Reuse", "comments": "6 pages, 3 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.IV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Fundus photography and Optical Coherence Tomography Angiography (OCT-A) are\ntwo commonly used modalities in ophthalmic imaging. With the development of\ndeep learning algorithms, fundus image processing, especially retinal vessel\nsegmentation, has been extensively studied. Built upon the known operator\ntheory, interpretable deep network pipelines with well-defined modules have\nbeen constructed on fundus images. In this work, we firstly train a modularized\nnetwork pipeline for the task of retinal vessel segmentation on the fundus\ndatabase DRIVE. The pretrained preprocessing module from the pipeline is then\ndirectly transferred onto OCT-A data for image quality enhancement without\nfurther fine-tuning. Output images show that the preprocessing net can balance\nthe contrast, suppress noise and thereby produce vessel trees with improved\nconnectivity in both image modalities. The visual impression is confirmed by an\nobserver study with five OCT-A experts. Statistics of the grades by the experts\nindicate that the transferred module improves both the image quality and the\ndiagnostic quality. Our work provides an example that modules within network\npipelines that are built upon the known operator theory facilitate\ncross-modality reuse without additional training or transfer learning.\n", "versions": [{"version": "v1", "created": "Tue, 5 Nov 2019 20:44:24 GMT"}], "update_date": "2019-11-07", "authors_parsed": [["Fu", "Weilin", ""], ["Husvogt", "Lennart", ""], ["Maier", "Stefan Ploner James G. Fujimoto Andreas", ""]]}, {"id": "1911.02088", "submitter": "Gregory Meyer", "authors": "Gregory P. Meyer", "title": "An Alternative Probabilistic Interpretation of the Huber Loss", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The Huber loss is a robust loss function used for a wide range of regression\ntasks. To utilize the Huber loss, a parameter that controls the transitions\nfrom a quadratic function to an absolute value function needs to be selected.\nWe believe the standard probabilistic interpretation that relates the Huber\nloss to the Huber density fails to provide adequate intuition for identifying\nthe transition point. As a result, a hyper-parameter search is often necessary\nto determine an appropriate value. In this work, we propose an alternative\nprobabilistic interpretation of the Huber loss, which relates minimizing the\nloss to minimizing an upper-bound on the Kullback-Leibler divergence between\nLaplace distributions, where one distribution represents the noise in the\nground-truth and the other represents the noise in the prediction. In addition,\nwe show that the parameters of the Laplace distributions are directly related\nto the transition point of the Huber loss. We demonstrate, through a toy\nproblem, that the optimal transition point of the Huber loss is closely related\nto the distribution of the noise in the ground-truth data. As a result, our\ninterpretation provides an intuitive way to identify well-suited\nhyper-parameters by approximating the amount of noise in the data, which we\ndemonstrate through a case study and experimentation on the Faster R-CNN and\nRetinaNet object detectors.\n", "versions": [{"version": "v1", "created": "Tue, 5 Nov 2019 21:15:19 GMT"}, {"version": "v2", "created": "Tue, 21 Apr 2020 19:23:10 GMT"}, {"version": "v3", "created": "Wed, 18 Nov 2020 19:27:22 GMT"}], "update_date": "2020-11-20", "authors_parsed": [["Meyer", "Gregory P.", ""]]}, {"id": "1911.02098", "submitter": "Tolulope Odetola", "authors": "Tolulope A. Odetola and Ogheneuriri Oderhohwo and Syed Rafay Hasan", "title": "A Scalable Multilabel Classification to Deploy Deep Learning\n  Architectures For Edge Devices", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Convolution Neural Networks (CNN) have performed well in many applications\nsuch as object detection, pattern recognition, video surveillance and so on.\nCNN carryout feature extraction on labelled data to perform classification.\nMulti-label classification assigns more than one label to a particular data\nsample in a data set. In multi-label classification, properties of a data point\nthat are considered to be mutually exclusive are classified. However, existing\nmulti-label classification requires some form of data pre-processing that\ninvolves image training data cropping or image tiling. The computation and\nmemory requirement of these multi-label CNN models makes their deployment on\nedge devices challenging. In this paper, we propose a methodology that solves\nthis problem by extending the capability of existing multi-label classification\nand provide models with lower latency that requires smaller memory size when\ndeployed on edge devices. We make use of a single CNN model designed with\nmultiple loss layers and multiple accuracy layers. This methodology is tested\non state-of-the-art deep learning algorithms such as AlexNet, GoogleNet and\nSqueezeNet using the Stanford Cars Dataset and deployed on Raspberry Pi3. From\nthe results the proposed methodology achieves comparable accuracy with 1.8x\nless MACC operation, 0.97x reduction in latency and 0.5x, 0.84x and 0.97x\nreduction in size for the generated AlexNet, GoogleNet and SqueezeNet CNN\nmodels respectively when compared to conventional ways of achieving multi-label\nclassification like hard-coding multi-label instances into single labels. The\nmethodology also yields CNN models that achieve 50\\% less MACC operations, 50%\nreduction in latency and size of generated versions of AlexNet, GoogleNet and\nSqueezeNet respectively when compared to conventional ways using 2 different\nsingle-labelled models to achieve multi-label classification.\n", "versions": [{"version": "v1", "created": "Tue, 5 Nov 2019 21:45:36 GMT"}, {"version": "v2", "created": "Thu, 7 Nov 2019 04:35:51 GMT"}, {"version": "v3", "created": "Wed, 27 Jan 2021 15:14:13 GMT"}], "update_date": "2021-01-28", "authors_parsed": [["Odetola", "Tolulope A.", ""], ["Oderhohwo", "Ogheneuriri", ""], ["Hasan", "Syed Rafay", ""]]}, {"id": "1911.02106", "submitter": "Peter Tonner", "authors": "Peter D. Tonner, Daniel V. Samarov, A. Gilad Kusne", "title": "Designing over uncertain outcomes with stochastic sampling Bayesian\n  optimization", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Optimization is becoming increasingly common in scientific and engineering\ndomains. Oftentimes, these problems involve various levels of stochasticity or\nuncertainty in generating proposed solutions. Therefore, optimization in these\nscenarios must consider this stochasticity to properly guide the design of\nfuture experiments. Here, we adapt Bayesian optimization to handle uncertain\noutcomes, proposing a new framework called stochastic sampling Bayesian\noptimization (SSBO). We show that the bounds on expected regret for an upper\nconfidence bound search in SSBO resemble those of earlier Bayesian optimization\napproaches, with added penalties due to the stochastic generation of inputs.\nAdditionally, we adapt existing batch optimization techniques to properly limit\nthe myopic decision making that can arise when selecting multiple instances\nbefore feedback. Finally, we show that SSBO techniques properly optimize a set\nof standard optimization problems as well as an applied problem inspired by\nbioengineering.\n", "versions": [{"version": "v1", "created": "Tue, 5 Nov 2019 22:21:07 GMT"}, {"version": "v2", "created": "Wed, 3 Jun 2020 21:55:42 GMT"}], "update_date": "2020-06-05", "authors_parsed": [["Tonner", "Peter D.", ""], ["Samarov", "Daniel V.", ""], ["Kusne", "A. Gilad", ""]]}, {"id": "1911.02109", "submitter": "Jingshuang Chen", "authors": "Zhiqiang Cai, Jingshuang Chen, Min Liu, Xinyu Liu", "title": "Deep least-squares methods: an unsupervised learning-based numerical\n  method for solving elliptic PDEs", "comments": "15 pages, 6 figures, 5 tables, accepted by Journal of Computational\n  Physics", "journal-ref": null, "doi": "10.1016/j.jcp.2020.109707", "report-no": null, "categories": "cs.LG cs.NA math.NA physics.comp-ph stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper studies an unsupervised deep learning-based numerical approach for\nsolving partial differential equations (PDEs). The approach makes use of the\ndeep neural network to approximate solutions of PDEs through the compositional\nconstruction and employs least-squares functionals as loss functions to\ndetermine parameters of the deep neural network. There are various\nleast-squares functionals for a partial differential equation. This paper\nfocuses on the so-called first-order system least-squares (FOSLS) functional\nstudied in [3], which is based on a first-order system of scalar second-order\nelliptic PDEs. Numerical results for second-order elliptic PDEs in one\ndimension are presented.\n", "versions": [{"version": "v1", "created": "Tue, 5 Nov 2019 22:24:06 GMT"}, {"version": "v2", "created": "Sun, 7 Jun 2020 18:42:28 GMT"}, {"version": "v3", "created": "Sun, 12 Jul 2020 16:56:33 GMT"}], "update_date": "2020-08-26", "authors_parsed": [["Cai", "Zhiqiang", ""], ["Chen", "Jingshuang", ""], ["Liu", "Min", ""], ["Liu", "Xinyu", ""]]}, {"id": "1911.02121", "submitter": "Amir Abdi", "authors": "Amir H. Abdi, Teresa Tsang, Purang Abolmaesumi", "title": "GAN-enhanced Conditional Echocardiogram Generation", "comments": "Workshop of Medical Imaging Meets NeurIPS, NeurIPS 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.IV cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Echocardiography (echo) is a common means of evaluating cardiac conditions.\nDue to the label scarcity, semi-supervised paradigms in automated echo analysis\nare getting traction. One of the most sought-after problems in echo is the\nsegmentation of cardiac structures (e.g. chambers). Accordingly, we propose an\nechocardiogram generation approach using generative adversarial networks with a\nconditional patch-based discriminator. In this work, we validate the\nfeasibility of GAN-enhanced echo generation with different conditions\n(segmentation masks), namely, the left ventricle, ventricular myocardium, and\natrium. Results show that the proposed adversarial algorithm can generate\nhigh-quality echo frames whose cardiac structures match the given segmentation\nmasks. This method is expected to facilitate the training of other machine\nlearning models in a semi-supervised fashion as suggested in similar\nresearches.\n", "versions": [{"version": "v1", "created": "Tue, 5 Nov 2019 22:49:25 GMT"}, {"version": "v2", "created": "Sat, 23 Nov 2019 21:37:19 GMT"}], "update_date": "2019-11-26", "authors_parsed": [["Abdi", "Amir H.", ""], ["Tsang", "Teresa", ""], ["Abolmaesumi", "Purang", ""]]}, {"id": "1911.02133", "submitter": "Farley Lai", "authors": "Farley Lai, Ning Xie, Derek Doran and Asim Kadav", "title": "Contextual Grounding of Natural Language Entities in Images", "comments": "Accepted to NeurIPS 2019 workshop on Visually Grounded Interaction\n  and Language (ViGIL)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we introduce a contextual grounding approach that captures the\ncontext in corresponding text entities and image regions to improve the\ngrounding accuracy. Specifically, the proposed architecture accepts pre-trained\ntext token embeddings and image object features from an off-the-shelf object\ndetector as input. Additional encoding to capture the positional and spatial\ninformation can be added to enhance the feature quality. There are separate\ntext and image branches facilitating respective architectural refinements for\ndifferent modalities. The text branch is pre-trained on a large-scale masked\nlanguage modeling task while the image branch is trained from scratch. Next,\nthe model learns the contextual representations of the text tokens and image\nobjects through layers of high-order interaction respectively. The final\ngrounding head ranks the correspondence between the textual and visual\nrepresentations through cross-modal interaction. In the evaluation, we show\nthat our model achieves the state-of-the-art grounding accuracy of 71.36% over\nthe Flickr30K Entities dataset. No additional pre-training is necessary to\ndeliver competitive results compared with related work that often requires\ntask-agnostic and task-specific pre-training on cross-modal dadasets. The\nimplementation is publicly available at https://gitlab.com/necla-ml/grounding.\n", "versions": [{"version": "v1", "created": "Tue, 5 Nov 2019 23:23:58 GMT"}], "update_date": "2019-11-07", "authors_parsed": [["Lai", "Farley", ""], ["Xie", "Ning", ""], ["Doran", "Derek", ""], ["Kadav", "Asim", ""]]}, {"id": "1911.02134", "submitter": "Yujing Chen", "authors": "Yujing Chen, Yue Ning, Martin Slawski and Huzefa Rangwala", "title": "Asynchronous Online Federated Learning for Edge Devices with Non-IID\n  Data", "comments": "11 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Federated learning (FL) is a machine learning paradigm where a shared central\nmodel is learned across distributed edge devices while the training data\nremains on these devices. Federated Averaging (FedAvg) is the leading\noptimization method for training non-convex models in this setting with a\nsynchronized protocol. However, the assumptions made by FedAvg are not\nrealistic given the heterogeneity of devices. In particular, the volume and\ndistribution of collected data vary in the training process due to different\nsampling rates of edge devices. The edge devices themselves also vary in their\navailable communication bandwidth and system configurations, such as memory,\nprocessor speed, and power requirements. This leads to vastly different\ntraining times as well as model/data transfer times. Furthermore, availability\nissues at edge devices can lead to a lack of contribution from specific edge\ndevices to the federated model. In this paper, we present an Asynchronous\nOnline Federated Learning (ASO-Fed) framework, where the edge devices perform\nonline learning with continuous streaming local data and a central server\naggregates model parameters from clients. Our framework updates the central\nmodel in an asynchronous manner to tackle the challenges associated with both\nvarying computational loads at heterogeneous edge devices and edge devices that\nlag behind or dropout. We perform extensive experiments on a simulated\nbenchmark image dataset and three real-world non-IID streaming datasets. The\nresults demonstrate the effectiveness of \\model~on converging fast and\nmaintaining good prediction performance.\n", "versions": [{"version": "v1", "created": "Tue, 5 Nov 2019 23:24:29 GMT"}, {"version": "v2", "created": "Tue, 19 May 2020 19:30:10 GMT"}, {"version": "v3", "created": "Tue, 20 Oct 2020 22:38:31 GMT"}], "update_date": "2020-10-22", "authors_parsed": [["Chen", "Yujing", ""], ["Ning", "Yue", ""], ["Slawski", "Martin", ""], ["Rangwala", "Huzefa", ""]]}, {"id": "1911.02140", "submitter": "Derek Yang", "authors": "Derek Yang, Li Zhao, Zichuan Lin, Tao Qin, Jiang Bian, Tieyan Liu", "title": "Fully Parameterized Quantile Function for Distributional Reinforcement\n  Learning", "comments": "NeurIPS 2019. Code at https://github.com/microsoft/FQF", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Distributional Reinforcement Learning (RL) differs from traditional RL in\nthat, rather than the expectation of total returns, it estimates distributions\nand has achieved state-of-the-art performance on Atari Games. The key challenge\nin practical distributional RL algorithms lies in how to parameterize estimated\ndistributions so as to better approximate the true continuous distribution.\nExisting distributional RL algorithms parameterize either the probability side\nor the return value side of the distribution function, leaving the other side\nuniformly fixed as in C51, QR-DQN or randomly sampled as in IQN. In this paper,\nwe propose fully parameterized quantile function that parameterizes both the\nquantile fraction axis (i.e., the x-axis) and the value axis (i.e., y-axis) for\ndistributional RL. Our algorithm contains a fraction proposal network that\ngenerates a discrete set of quantile fractions and a quantile value network\nthat gives corresponding quantile values. The two networks are jointly trained\nto find the best approximation of the true distribution. Experiments on 55\nAtari Games show that our algorithm significantly outperforms existing\ndistributional RL algorithms and creates a new record for the Atari Learning\nEnvironment for non-distributed agents.\n", "versions": [{"version": "v1", "created": "Tue, 5 Nov 2019 23:38:57 GMT"}, {"version": "v2", "created": "Sat, 16 Nov 2019 03:48:25 GMT"}, {"version": "v3", "created": "Sun, 2 Aug 2020 09:13:34 GMT"}], "update_date": "2020-08-04", "authors_parsed": [["Yang", "Derek", ""], ["Zhao", "Li", ""], ["Lin", "Zichuan", ""], ["Qin", "Tao", ""], ["Bian", "Jiang", ""], ["Liu", "Tieyan", ""]]}, {"id": "1911.02142", "submitter": "Fabio Pierazzi Dr", "authors": "Fabio Pierazzi, Feargus Pendlebury, Jacopo Cortellazzi, Lorenzo\n  Cavallaro", "title": "Intriguing Properties of Adversarial ML Attacks in the Problem Space", "comments": "This arXiv version (v2) corresponds to the one published at IEEE\n  Symposium on Security & Privacy (Oakland), 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent research efforts on adversarial ML have investigated problem-space\nattacks, focusing on the generation of real evasive objects in domains where,\nunlike images, there is no clear inverse mapping to the feature space (e.g.,\nsoftware). However, the design, comparison, and real-world implications of\nproblem-space attacks remain underexplored. This paper makes two major\ncontributions. First, we propose a novel formalization for adversarial ML\nevasion attacks in the problem-space, which includes the definition of a\ncomprehensive set of constraints on available transformations, preserved\nsemantics, robustness to preprocessing, and plausibility. We shed light on the\nrelationship between feature space and problem space, and we introduce the\nconcept of side-effect features as the byproduct of the inverse feature-mapping\nproblem. This enables us to define and prove necessary and sufficient\nconditions for the existence of problem-space attacks. We further demonstrate\nthe expressive power of our formalization by using it to describe several\nattacks from related literature across different domains. Second, building on\nour formalization, we propose a novel problem-space attack on Android malware\nthat overcomes past limitations. Experiments on a dataset with 170K Android\napps from 2017 and 2018 show the practical feasibility of evading a\nstate-of-the-art malware classifier along with its hardened version. Our\nresults demonstrate that \"adversarial-malware as a service\" is a realistic\nthreat, as we automatically generate thousands of realistic and inconspicuous\nadversarial applications at scale, where on average it takes only a few minutes\nto generate an adversarial app. Our formalization of problem-space attacks\npaves the way to more principled research in this domain.\n", "versions": [{"version": "v1", "created": "Tue, 5 Nov 2019 23:39:55 GMT"}, {"version": "v2", "created": "Mon, 16 Mar 2020 20:05:29 GMT"}], "update_date": "2020-03-18", "authors_parsed": [["Pierazzi", "Fabio", ""], ["Pendlebury", "Feargus", ""], ["Cortellazzi", "Jacopo", ""], ["Cavallaro", "Lorenzo", ""]]}, {"id": "1911.02146", "submitter": "Yang Cai", "authors": "Johaness Brustle, Yang Cai, Constantinos Daskalakis", "title": "Multi-Item Mechanisms without Item-Independence: Learnability via\n  Robustness", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.GT cs.DS cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the sample complexity of learning revenue-optimal multi-item\nauctions. We obtain the first set of positive results that go beyond the\nstandard but unrealistic setting of item-independence. In particular, we\nconsider settings where bidders' valuations are drawn from correlated\ndistributions that can be captured by Markov Random Fields or Bayesian Networks\n-- two of the most prominent graphical models. We establish parametrized sample\ncomplexity bounds for learning an up-to-$\\varepsilon$ optimal mechanism in both\nmodels, which scale polynomially in the size of the model, i.e.~the number of\nitems and bidders, and only exponential in the natural complexity measure of\nthe model, namely either the largest in-degree (for Bayesian Networks) or the\nsize of the largest hyper-edge (for Markov Random Fields).\n  We obtain our learnability results through a novel and modular framework that\ninvolves first proving a robustness theorem. We show that, given only\n``approximate distributions'' for bidder valuations, we can learn a mechanism\nwhose revenue is nearly optimal simultaneously for all ``true distributions''\nthat are close to the ones we were given in Prokhorov distance. Thus, to learn\na good mechanism, it suffices to learn approximate distributions. When item\nvalues are independent, learning in Prokhorov distance is immediate, hence our\nframework directly implies the main result of Gonczarowski and Weinberg. When\nitem values are sampled from more general graphical models, we combine our\nrobustness theorem with novel sample complexity results for learning Markov\nRandom Fields or Bayesian Networks in Prokhorov distance, which may be of\nindependent interest. Finally, in the single-item case, our robustness result\ncan be strengthened to hold under an even weaker distribution distance, the\nL\\'evy distance.\n", "versions": [{"version": "v1", "created": "Wed, 6 Nov 2019 00:05:26 GMT"}, {"version": "v2", "created": "Sun, 31 May 2020 16:25:00 GMT"}], "update_date": "2020-06-02", "authors_parsed": [["Brustle", "Johaness", ""], ["Cai", "Yang", ""], ["Daskalakis", "Constantinos", ""]]}, {"id": "1911.02147", "submitter": "Chenyang Huang", "authors": "Chenyang Huang, Amine Trabelsi, Xuebin Qin, Nawshad Farruque, Osmar R.\n  Za\\\"iane", "title": "Seq2Emo for Multi-label Emotion Classification Based on Latent Variable\n  Chains Transformation", "comments": "10 pages, 2 figures, 5 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Emotion detection in text is an important task in NLP and is essential in\nmany applications. Most of the existing methods treat this task as a problem of\nsingle-label multi-class text classification. To predict multiple emotions for\none instance, most of the existing works regard it as a general Multi-label\nClassification (MLC) problem, where they usually either apply a manually\ndetermined threshold on the last output layer of their neural network models or\ntrain multiple binary classifiers and make predictions in the fashion of\none-vs-all. However, compared to labels in the general MLC datasets, the number\nof emotion categories are much fewer (less than 10). Additionally, emotions\ntend to have more correlations with each other. For example, the human usually\ndoes not express \"joy\" and \"anger\" at the same time, but it is very likely to\nhave \"joy\" and \"love\" expressed together. Given this intuition, in this paper,\nwe propose a Latent Variable Chain (LVC) transformation and a tailored model --\nSeq2Emo model that not only naturally predicts multiple emotion labels but also\ntakes into consideration their correlations. We perform the experiments on the\nexisting multi-label emotion datasets as well as on our newly collected\ndatasets. The results show that our model compares favorably with existing\nstate-of-the-art methods.\n", "versions": [{"version": "v1", "created": "Wed, 6 Nov 2019 00:08:19 GMT"}, {"version": "v2", "created": "Fri, 8 Nov 2019 04:55:18 GMT"}], "update_date": "2019-11-11", "authors_parsed": [["Huang", "Chenyang", ""], ["Trabelsi", "Amine", ""], ["Qin", "Xuebin", ""], ["Farruque", "Nawshad", ""], ["Za\u00efane", "Osmar R.", ""]]}, {"id": "1911.02150", "submitter": "Noam Shazeer", "authors": "Noam Shazeer", "title": "Fast Transformer Decoding: One Write-Head is All You Need", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Multi-head attention layers, as used in the Transformer neural sequence\nmodel, are a powerful alternative to RNNs for moving information across and\nbetween sequences. While training these layers is generally fast and simple,\ndue to parallelizability across the length of the sequence, incremental\ninference (where such paralleization is impossible) is often slow, due to the\nmemory-bandwidth cost of repeatedly loading the large \"keys\" and \"values\"\ntensors. We propose a variant called multi-query attention, where the keys and\nvalues are shared across all of the different attention \"heads\", greatly\nreducing the size of these tensors and hence the memory bandwidth requirements\nof incremental decoding. We verify experimentally that the resulting models can\nindeed be much faster to decode, and incur only minor quality degradation from\nthe baseline.\n", "versions": [{"version": "v1", "created": "Wed, 6 Nov 2019 00:19:05 GMT"}], "update_date": "2019-11-07", "authors_parsed": [["Shazeer", "Noam", ""]]}, {"id": "1911.02151", "submitter": "Mahdi Haghifam", "authors": "Jeffrey Negrea, Mahdi Haghifam, Gintare Karolina Dziugaite, Ashish\n  Khisti, Daniel M. Roy", "title": "Information-Theoretic Generalization Bounds for SGLD via Data-Dependent\n  Estimates", "comments": "23 pages, 1 figure. To appear in, Advances in Neural Information\n  Processing Systems (33), 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.IT cs.LG math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this work, we improve upon the stepwise analysis of noisy iterative\nlearning algorithms initiated by Pensia, Jog, and Loh (2018) and recently\nextended by Bu, Zou, and Veeravalli (2019). Our main contributions are\nsignificantly improved mutual information bounds for Stochastic Gradient\nLangevin Dynamics via data-dependent estimates. Our approach is based on the\nvariational characterization of mutual information and the use of\ndata-dependent priors that forecast the mini-batch gradient based on a subset\nof the training samples. Our approach is broadly applicable within the\ninformation-theoretic framework of Russo and Zou (2015) and Xu and Raginsky\n(2017). Our bound can be tied to a measure of flatness of the empirical risk\nsurface. As compared with other bounds that depend on the squared norms of\ngradients, empirical investigations show that the terms in our bounds are\norders of magnitude smaller.\n", "versions": [{"version": "v1", "created": "Wed, 6 Nov 2019 00:28:33 GMT"}, {"version": "v2", "created": "Fri, 8 Nov 2019 02:01:39 GMT"}, {"version": "v3", "created": "Sat, 25 Jan 2020 20:43:31 GMT"}], "update_date": "2020-01-28", "authors_parsed": [["Negrea", "Jeffrey", ""], ["Haghifam", "Mahdi", ""], ["Dziugaite", "Gintare Karolina", ""], ["Khisti", "Ashish", ""], ["Roy", "Daniel M.", ""]]}, {"id": "1911.02155", "submitter": "James Murphy", "authors": "James M. Murphy", "title": "Spatially regularized active diffusion learning for high-dimensional\n  images", "comments": "17 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ME stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  An active learning algorithm for the classification of high-dimensional\nimages is proposed in which spatially-regularized nonlinear diffusion geometry\nis used to characterize cluster cores. The proposed method samples from\nestimated cluster cores in order to generate a small but potent set of training\nlabels which propagate to the remainder of the dataset via the underlying\ndiffusion process. By spatially regularizing the rich, high-dimensional\nspectral information of the image to efficiently estimate the most significant\nand influential points in the data, our approach avoids redundancy in the\ntraining dataset. This allows it to produce high-accuracy labelings with a very\nsmall number of training labels. The proposed algorithm admits an efficient\nnumerical implementation that scales essentially linearly in the number of data\npoints under a suitable data model and enjoys state-of-the-art performance on\nreal hyperspectral images.\n", "versions": [{"version": "v1", "created": "Wed, 6 Nov 2019 00:58:24 GMT"}], "update_date": "2019-11-07", "authors_parsed": [["Murphy", "James M.", ""]]}, {"id": "1911.02156", "submitter": "Ahmadreza Moradipari", "authors": "Ahmadreza Moradipari, Sanae Amani, Mahnoosh Alizadeh, Christos\n  Thrampoulidis", "title": "Safe Linear Thompson Sampling with Side Information", "comments": "Comparing with safe versions of linear UCB algorithms, Providing more\n  intuition for proof sketch", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The design and performance analysis of bandit algorithms in the presence of\nstage-wise safety or reliability constraints has recently garnered significant\ninterest. In this work, we consider the linear stochastic bandit problem under\nadditional \\textit{linear safety constraints} that need to be satisfied at each\nround. We provide a new safe algorithm based on linear Thompson Sampling (TS)\nfor this problem and show a frequentist regret of order $\\mathcal{O}\n(d^{3/2}\\log^{1/2}d \\cdot T^{1/2}\\log^{3/2}T)$, which remarkably matches the\nresults provided by (Abeille et al., 2017) for the standard linear TS algorithm\nin the absence of safety constraints. We compare the performance of our\nalgorithm with UCB-based safe algorithms and highlight how the inherently\nrandomized nature of TS leads to a superior performance in expanding the set of\nsafe actions the algorithm has access to at each round.\n", "versions": [{"version": "v1", "created": "Wed, 6 Nov 2019 00:59:20 GMT"}, {"version": "v2", "created": "Sat, 29 Feb 2020 21:13:37 GMT"}], "update_date": "2020-03-03", "authors_parsed": [["Moradipari", "Ahmadreza", ""], ["Amani", "Sanae", ""], ["Alizadeh", "Mahnoosh", ""], ["Thrampoulidis", "Christos", ""]]}, {"id": "1911.02161", "submitter": "Chuyang Ke", "authors": "Chuyang Ke, Jean Honorio", "title": "Exact Partitioning of High-order Models with a Novel Convex Tensor Cone\n  Relaxation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we propose an algorithm for exact partitioning of high-order\nmodels. We define a general class of $m$-degree Homogeneous Polynomial Models,\nwhich subsumes several examples motivated from prior literature. Exact\npartitioning can be formulated as a tensor optimization problem. We relax this\nhigh-order combinatorial problem to a convex conic form problem. To this end,\nwe carefully define the Carath\\'eodory symmetric tensor cone, and show its\nconvexity, and the convexity of its dual cone. This allows us to construct a\nprimal-dual certificate to show that the solution of the convex relaxation is\ncorrect (equal to the unobserved true group assignment) and to analyze the\nstatistical upper bound of exact partitioning.\n", "versions": [{"version": "v1", "created": "Wed, 6 Nov 2019 01:52:05 GMT"}, {"version": "v2", "created": "Thu, 15 Jul 2021 17:21:46 GMT"}], "update_date": "2021-07-16", "authors_parsed": [["Ke", "Chuyang", ""], ["Honorio", "Jean", ""]]}, {"id": "1911.02166", "submitter": "Zichuan Lin", "authors": "Zichuan Lin, Li Zhao, Derek Yang, Tao Qin, Guangwen Yang and Tie-Yan\n  Liu", "title": "Distributional Reward Decomposition for Reinforcement Learning", "comments": "NeurlPS 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Many reinforcement learning (RL) tasks have specific properties that can be\nleveraged to modify existing RL algorithms to adapt to those tasks and further\nimprove performance, and a general class of such properties is the multiple\nreward channel. In those environments the full reward can be decomposed into\nsub-rewards obtained from different channels. Existing work on reward\ndecomposition either requires prior knowledge of the environment to decompose\nthe full reward, or decomposes reward without prior knowledge but with degraded\nperformance. In this paper, we propose Distributional Reward Decomposition for\nReinforcement Learning (DRDRL), a novel reward decomposition algorithm which\ncaptures the multiple reward channel structure under distributional setting.\nEmpirically, our method captures the multi-channel structure and discovers\nmeaningful reward decomposition, without any requirements on prior knowledge.\nConsequently, our agent achieves better performance than existing methods on\nenvironments with multiple reward channels.\n", "versions": [{"version": "v1", "created": "Wed, 6 Nov 2019 02:13:50 GMT"}], "update_date": "2019-11-07", "authors_parsed": [["Lin", "Zichuan", ""], ["Zhao", "Li", ""], ["Yang", "Derek", ""], ["Qin", "Tao", ""], ["Yang", "Guangwen", ""], ["Liu", "Tie-Yan", ""]]}, {"id": "1911.02172", "submitter": "C.-H. Huck Yang", "authors": "Yi-Chieh Liu, Yung-An Hsieh, Min-Hung Chen, Chao-Han Huck Yang, Jesper\n  Tegner, Yi-Chang James Tsai", "title": "Interpretable Self-Attention Temporal Reasoning for Driving Behavior\n  Understanding", "comments": "Submitted to IEEE ICASSP 2020; Pytorch code will be released soon", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://creativecommons.org/publicdomain/zero/1.0/", "abstract": "  Performing driving behaviors based on causal reasoning is essential to ensure\ndriving safety. In this work, we investigated how state-of-the-art 3D\nConvolutional Neural Networks (CNNs) perform on classifying driving behaviors\nbased on causal reasoning. We proposed a perturbation-based visual explanation\nmethod to inspect the models' performance visually. By examining the video\nattention saliency, we found that existing models could not precisely capture\nthe causes (e.g., traffic light) of the specific action (e.g., stopping).\nTherefore, the Temporal Reasoning Block (TRB) was proposed and introduced to\nthe models. With the TRB models, we achieved the accuracy of $\\mathbf{86.3\\%}$,\nwhich outperform the state-of-the-art 3D CNNs from previous works. The\nattention saliency also demonstrated that TRB helped models focus on the causes\nmore precisely. With both numerical and visual evaluations, we concluded that\nour proposed TRB models were able to provide accurate driving behavior\nprediction by learning the causal reasoning of the behaviors.\n", "versions": [{"version": "v1", "created": "Wed, 6 Nov 2019 02:49:30 GMT"}], "update_date": "2019-11-07", "authors_parsed": [["Liu", "Yi-Chieh", ""], ["Hsieh", "Yung-An", ""], ["Chen", "Min-Hung", ""], ["Yang", "Chao-Han Huck", ""], ["Tegner", "Jesper", ""], ["Tsai", "Yi-Chang James", ""]]}, {"id": "1911.02175", "submitter": "Robert Osazuwa Ness", "authors": "Robert Osazuwa Ness, Kaushal Paneri, and Olga Vitek", "title": "Integrating Markov processes with structural causal modeling enables\n  counterfactual inference in complex systems", "comments": "Accepted to Thirty-third Conference on Neural Information Processing\n  Systems (2019)", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG q-bio.MN stat.AP", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  This manuscript contributes a general and practical framework for casting a\nMarkov process model of a system at equilibrium as a structural causal model,\nand carrying out counterfactual inference. Markov processes mathematically\ndescribe the mechanisms in the system, and predict the system's equilibrium\nbehavior upon intervention, but do not support counterfactual inference. In\ncontrast, structural causal models support counterfactual inference, but do not\nidentify the mechanisms. This manuscript leverages the benefits of both\napproaches. We define the structural causal models in terms of the parameters\nand the equilibrium dynamics of the Markov process models, and counterfactual\ninference flows from these settings. The proposed approach alleviates the\nidentifiability drawback of the structural causal models, in that the\ncounterfactual inference is consistent with the counterfactual trajectories\nsimulated from the Markov process model. We showcase the benefits of this\nframework in case studies of complex biomolecular systems with nonlinear\ndynamics. We illustrate that, in presence of Markov process model\nmisspecification, counterfactual inference leverages prior data, and therefore\nestimates the outcome of an intervention more accurately than a direct\nsimulation.\n", "versions": [{"version": "v1", "created": "Wed, 6 Nov 2019 03:01:45 GMT"}], "update_date": "2019-11-07", "authors_parsed": [["Ness", "Robert Osazuwa", ""], ["Paneri", "Kaushal", ""], ["Vitek", "Olga", ""]]}, {"id": "1911.02182", "submitter": "Gordon Wichern", "authors": "Fatemeh Pishdadian, Gordon Wichern, Jonathan Le Roux", "title": "Finding Strength in Weakness: Learning to Separate Sounds with Weak\n  Supervision", "comments": null, "journal-ref": "IEEE/ACM Transactions on Audio, Speech and Language Processing vol\n  28 (2020) 2386-2399", "doi": "10.1109/TASLP.2020.3013105", "report-no": null, "categories": "cs.SD cs.LG eess.AS stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  While there has been much recent progress using deep learning techniques to\nseparate speech and music audio signals, these systems typically require large\ncollections of isolated sources during the training process. When extending\naudio source separation algorithms to more general domains such as\nenvironmental monitoring, it may not be possible to obtain isolated signals for\ntraining. Here, we propose objective functions and network architectures that\nenable training a source separation system with weak labels. In this scenario,\nweak labels are defined in contrast with strong time-frequency (TF) labels such\nas those obtained from isolated sources, and refer either to frame-level weak\nlabels where one only has access to the time periods when different sources are\nactive in an audio mixture, or to clip-level weak labels that only indicate the\npresence or absence of sounds in an entire audio clip. We train a separator\nthat estimates a TF mask for each type of sound event, using a sound event\nclassifier as an assessor of the separator's performance to bridge the gap\nbetween the TF-level separation and the ground truth weak labels only available\nat the frame or clip level. Our objective function requires the classifier\napplied to a separated source to assign high probability to the class\ncorresponding to that source and low probability to all other classes. The\nobjective function also enforces that the separated sources sum up to the\nmixture. We benchmark the performance of our algorithm using synthetic mixtures\nof overlapping events created from a database of sounds recorded in urban\nenvironments. Compared to training a network using isolated sources, our model\nachieves somewhat lower but still significant SI-SDR improvement, even in\nscenarios with significant sound event overlap.\n", "versions": [{"version": "v1", "created": "Wed, 6 Nov 2019 03:36:55 GMT"}, {"version": "v2", "created": "Fri, 28 Aug 2020 18:53:04 GMT"}], "update_date": "2020-09-01", "authors_parsed": [["Pishdadian", "Fatemeh", ""], ["Wichern", "Gordon", ""], ["Roux", "Jonathan Le", ""]]}, {"id": "1911.02191", "submitter": "Lucas Oliveira Souza", "authors": "Lucas Oliveira Souza, Gabriel de Oliveira Ramos, Celia Ghedini Ralha", "title": "Experience Sharing Between Cooperative Reinforcement Learning Agents", "comments": "Published at the Proceedings of the 31st IEEE International\n  Conference on Tools with Artificial Intelligence", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The idea of experience sharing between cooperative agents naturally emerges\nfrom our understanding of how humans learn. Our evolution as a species is\ntightly linked to the ability to exchange learned knowledge with one another.\nIt follows that experience sharing (ES) between autonomous and independent\nagents could become the key to accelerate learning in cooperative multiagent\nsettings. We investigate if randomly selecting experiences to share can\nincrease the performance of deep reinforcement learning agents, and propose\nthree new methods for selecting experiences to accelerate the learning process.\nFirstly, we introduce Focused ES, which prioritizes unexplored regions of the\nstate space. Secondly, we present Prioritized ES, in which temporal-difference\nerror is used as a measure of priority. Finally, we devise Focused Prioritized\nES, which combines both previous approaches. The methods are empirically\nvalidated in a control problem. While sharing randomly selected experiences\nbetween two Deep Q-Network agents shows no improvement over a single agent\nbaseline, we show that the proposed ES methods can successfully outperform the\nbaseline. In particular, the Focused ES accelerates learning by a factor of 2,\nreducing by 51% the number of episodes required to complete the task.\n", "versions": [{"version": "v1", "created": "Wed, 6 Nov 2019 03:57:14 GMT"}], "update_date": "2019-11-07", "authors_parsed": [["Souza", "Lucas Oliveira", ""], ["Ramos", "Gabriel de Oliveira", ""], ["Ralha", "Celia Ghedini", ""]]}, {"id": "1911.02206", "submitter": "Shuhan Yao", "authors": "Shuhan Yao, Jiuxiang Gu, Peng Wang, Tianyang Zhao, Huajun Zhang,\n  Xiaochuan Liu", "title": "Resilient Load Restoration in Microgrids Considering Mobile Energy\n  Storage Fleets: A Deep Reinforcement Learning Approach", "comments": "Submitted to 2020 IEEE Power and Energy Society General Meeting", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.OC cs.LG cs.SY eess.SY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Mobile energy storage systems (MESSs) provide mobility and flexibility to\nenhance distribution system resilience. The paper proposes a Markov decision\nprocess (MDP) formulation for an integrated service restoration strategy that\ncoordinates the scheduling of MESSs and resource dispatching of microgrids. The\nuncertainties in load consumption are taken into account. The deep\nreinforcement learning (DRL) algorithm is utilized to solve the MDP for optimal\nscheduling. Specifically, the twin delayed deep deterministic policy gradient\n(TD3) is applied to train the deep Q-network and policy network, then the well\ntrained policy can be deployed in on-line manner to perform multiple actions\nsimultaneously. The proposed model is demonstrated on an integrated test system\nwith three microgrids connected by Sioux Falls transportation network. The\nsimulation results indicate that mobile and stationary energy resources can be\nwell coordinated to improve system resilience.\n", "versions": [{"version": "v1", "created": "Wed, 6 Nov 2019 05:14:54 GMT"}, {"version": "v2", "created": "Fri, 27 Mar 2020 12:30:33 GMT"}], "update_date": "2020-03-30", "authors_parsed": [["Yao", "Shuhan", ""], ["Gu", "Jiuxiang", ""], ["Wang", "Peng", ""], ["Zhao", "Tianyang", ""], ["Zhang", "Huajun", ""], ["Liu", "Xiaochuan", ""]]}, {"id": "1911.02210", "submitter": "Sayandev Mukherjee", "authors": "Sayandev Mukherjee", "title": "Machine Learning using the Variational Predictive Information Bottleneck\n  with a Validation Set", "comments": "11 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.IT math.IT stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Zellner (1988) modeled statistical inference in terms of information\nprocessing and postulated the Information Conservation Principle (ICP) between\nthe input and output of the information processing block, showing that this\nyielded Bayesian inference as the optimum information processing rule.\nRecently, Alemi (2019) reviewed Zellner's work in the context of machine\nlearning and showed that the ICP could be seen as a special case of a more\ngeneral optimum information processing criterion, namely the Predictive\nInformation Bottleneck Objective. However, Alemi modeled the model training\nstep in machine learning as using training and test data sets only, and did not\naccount for the use of a validation data set during training. The present note\nis an attempt to extend Alemi's information processing formulation of machine\nlearning, and the predictive information bottleneck objective for model\ntraining, to the widely-used scenario where training utilizes not only a\ntraining but also a validation data set.\n", "versions": [{"version": "v1", "created": "Wed, 6 Nov 2019 05:31:59 GMT"}, {"version": "v2", "created": "Wed, 11 Dec 2019 02:25:37 GMT"}], "update_date": "2019-12-12", "authors_parsed": [["Mukherjee", "Sayandev", ""]]}, {"id": "1911.02212", "submitter": "Max Simchowitz", "authors": "Mark Braverman, Elad Hazan, Max Simchowitz, Blake Woodworth", "title": "The gradient complexity of linear regression", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.DS math.OC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We investigate the computational complexity of several basic linear algebra\nprimitives, including largest eigenvector computation and linear regression, in\nthe computational model that allows access to the data via a matrix-vector\nproduct oracle. We show that for polynomial accuracy, $\\Theta(d)$ calls to the\noracle are necessary and sufficient even for a randomized algorithm.\n  Our lower bound is based on a reduction to estimating the least eigenvalue of\na random Wishart matrix. This simple distribution enables a concise proof,\nleveraging a few key properties of the random Wishart ensemble.\n", "versions": [{"version": "v1", "created": "Wed, 6 Nov 2019 05:45:05 GMT"}, {"version": "v2", "created": "Tue, 30 Jun 2020 01:06:45 GMT"}, {"version": "v3", "created": "Sun, 23 May 2021 05:12:54 GMT"}], "update_date": "2021-05-25", "authors_parsed": [["Braverman", "Mark", ""], ["Hazan", "Elad", ""], ["Simchowitz", "Max", ""], ["Woodworth", "Blake", ""]]}, {"id": "1911.02216", "submitter": "Takuya Fujioka", "authors": "Takuya Fujioka, Dario Bertero, Takeshi Homma, Kenji Nagamatsu", "title": "Addressing Ambiguity of Emotion Labels Through Meta-Learning", "comments": "Submitted to ICASSP 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.AS cs.LG cs.SD", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Emotion labels in emotion recognition corpora are highly noisy and ambiguous,\ndue to the annotators' subjective perception of emotions. Such ambiguity may\nintroduce errors in automatic classification and affect the overall\nperformance. We therefore propose a dynamic label correction and sample\ncontribution weight estimation model. Our model is based on a standard BLSTM\nmodel with attention with two extra parameters. The first learns a new\ncorrected label distribution, and is aimed to fix the inaccurate labels from\nthe dataset. The other instead estimates the contribution of each sample to the\ntraining process, and is aimed to ignore the ambiguous and noisy samples while\ngiving higher weight to the clear ones. We train our model through an\nalternating optimization method, where in the first epoch we update the neural\nnetwork parameters, and in the second we keep them fixed to update the label\ncorrection and sample importance parameters. When training and evaluating our\nmodel on the IEMOCAP dataset, we obtained a weighted accuracy (WA) and\nunweighted accuracy (UA) of respectively 65.9% and 61.4%. This yielded an\nabsolute improvement of 2.5%, 2.7% respectively compared to a BLSTM with\nattention baseline, trained on the corpus gold labels.\n", "versions": [{"version": "v1", "created": "Wed, 6 Nov 2019 06:21:31 GMT"}, {"version": "v2", "created": "Thu, 7 Nov 2019 06:24:44 GMT"}], "update_date": "2019-11-11", "authors_parsed": [["Fujioka", "Takuya", ""], ["Bertero", "Dario", ""], ["Homma", "Takeshi", ""], ["Nagamatsu", "Kenji", ""]]}, {"id": "1911.02222", "submitter": "Priyansh Saxena", "authors": "Vaishnav Chandak, Priyansh Saxena, Manisha Pattanaik and Gaurav\n  Kaushal", "title": "Semantic Image Completion and Enhancement using Deep Learning", "comments": "6 pages, 8 figures. Proceedings of \"The 10th International Conference\n  on Computing, Communication and Networking Technologies (ICCCNT)\". Conference\n  Proceedings ISBN Number: ISBN: 978-1-5386-5906-9; Link:\n  https://ieeexplore.ieee.org/document/8944750", "journal-ref": null, "doi": "10.1109/ICCCNT45670.2019.8944750", "report-no": null, "categories": "eess.IV cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In real-life applications, certain images utilized are corrupted in which the\nimage pixels are damaged or missing, which increases the complexity of computer\nvision tasks. In this paper, a deep learning architecture is proposed to deal\nwith image completion and enhancement. Generative Adversarial Networks (GAN),\nhas been turned out to be helpful in picture completion tasks. Therefore, in\nGANs, Wasserstein GAN architecture is used for image completion which creates\nthe coarse patches to filling the missing region in the distorted picture, and\nthe enhancement network will additionally refine the resultant pictures\nutilizing residual learning procedures and hence give better complete pictures\nfor computer vision applications. Experimental outcomes show that the proposed\napproach improves the Peak Signal to Noise ratio and Structural Similarity\nIndex values by 2.45% and 4% respectively when compared to the recently\nreported data.\n", "versions": [{"version": "v1", "created": "Wed, 6 Nov 2019 06:47:08 GMT"}, {"version": "v2", "created": "Sun, 5 Jan 2020 07:07:53 GMT"}], "update_date": "2020-01-07", "authors_parsed": [["Chandak", "Vaishnav", ""], ["Saxena", "Priyansh", ""], ["Pattanaik", "Manisha", ""], ["Kaushal", "Gaurav", ""]]}, {"id": "1911.02242", "submitter": "Chung-Cheng Chiu", "authors": "Chung-Cheng Chiu, Wei Han, Yu Zhang, Ruoming Pang, Sergey Kishchenko,\n  Patrick Nguyen, Arun Narayanan, Hank Liao, Shuyuan Zhang, Anjuli Kannan,\n  Rohit Prabhavalkar, Zhifeng Chen, Tara Sainath, Yonghui Wu", "title": "A comparison of end-to-end models for long-form speech recognition", "comments": "ASRU camera-ready version", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.AS cs.CL cs.LG cs.SD", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  End-to-end automatic speech recognition (ASR) models, including both\nattention-based models and the recurrent neural network transducer (RNN-T),\nhave shown superior performance compared to conventional systems. However,\nprevious studies have focused primarily on short utterances that typically last\nfor just a few seconds or, at most, a few tens of seconds. Whether such\narchitectures are practical on long utterances that last from minutes to hours\nremains an open question. In this paper, we both investigate and improve the\nperformance of end-to-end models on long-form transcription. We first present\nan empirical comparison of different end-to-end models on a real world\nlong-form task and demonstrate that the RNN-T model is much more robust than\nattention-based systems in this regime. We next explore two improvements to\nattention-based systems that significantly improve its performance: restricting\nthe attention to be monotonic, and applying a novel decoding algorithm that\nbreaks long utterances into shorter overlapping segments. Combining these two\nimprovements, we show that attention-based end-to-end models can be very\ncompetitive to RNN-T on long-form speech recognition.\n", "versions": [{"version": "v1", "created": "Wed, 6 Nov 2019 08:01:16 GMT"}], "update_date": "2019-11-07", "authors_parsed": [["Chiu", "Chung-Cheng", ""], ["Han", "Wei", ""], ["Zhang", "Yu", ""], ["Pang", "Ruoming", ""], ["Kishchenko", "Sergey", ""], ["Nguyen", "Patrick", ""], ["Narayanan", "Arun", ""], ["Liao", "Hank", ""], ["Zhang", "Shuyuan", ""], ["Kannan", "Anjuli", ""], ["Prabhavalkar", "Rohit", ""], ["Chen", "Zhifeng", ""], ["Sainath", "Tara", ""], ["Wu", "Yonghui", ""]]}, {"id": "1911.02247", "submitter": "Arthur Bra\\v{z}inskas", "authors": "Arthur Bra\\v{z}inskas, Mirella Lapata and Ivan Titov", "title": "Unsupervised Opinion Summarization as Copycat-Review Generation", "comments": "ACL 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.IR cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Opinion summarization is the task of automatically creating summaries that\nreflect subjective information expressed in multiple documents, such as product\nreviews. While the majority of previous work has focused on the extractive\nsetting, i.e., selecting fragments from input reviews to produce a summary, we\nlet the model generate novel sentences and hence produce abstractive summaries.\nRecent progress in summarization has seen the development of supervised models\nwhich rely on large quantities of document-summary pairs. Since such training\ndata is expensive to acquire, we instead consider the unsupervised setting, in\nother words, we do not use any summaries in training. We define a generative\nmodel for a review collection which capitalizes on the intuition that when\ngenerating a new review given a set of other reviews of a product, we should be\nable to control the \"amount of novelty\" going into the new review or,\nequivalently, vary the extent to which it deviates from the input. At test\ntime, when generating summaries, we force the novelty to be minimal, and\nproduce a text reflecting consensus opinions. We capture this intuition by\ndefining a hierarchical variational autoencoder model. Both individual reviews\nand the products they correspond to are associated with stochastic latent\ncodes, and the review generator (\"decoder\") has direct access to the text of\ninput reviews through the pointer-generator mechanism. Experiments on Amazon\nand Yelp datasets, show that setting at test time the review's latent code to\nits mean, allows the model to produce fluent and coherent summaries reflecting\ncommon opinions.\n", "versions": [{"version": "v1", "created": "Wed, 6 Nov 2019 08:20:13 GMT"}, {"version": "v2", "created": "Sun, 19 Apr 2020 15:49:31 GMT"}], "update_date": "2020-04-21", "authors_parsed": [["Bra\u017einskas", "Arthur", ""], ["Lapata", "Mirella", ""], ["Titov", "Ivan", ""]]}, {"id": "1911.02248", "submitter": "Fan Wang", "authors": "Fan Wang, Xiaomin Fang, Lihang Liu, Hao Tian, Zhiming Peng", "title": "MBCAL: Sample Efficient and Variance Reduced Reinforcement Learning for\n  Recommender Systems", "comments": null, "journal-ref": "1st International Workshop on Industrial Recommendation Systems\n  (IRS), KDD 2020", "doi": null, "report-no": null, "categories": "cs.IR cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  In recommender systems such as news feed stream, it is essential to optimize\nthe long-term utilities in the continuous user-system interaction processes.\nPrevious works have proved the capability of reinforcement learning in this\nproblem. However, there are many practical challenges to implement deep\nreinforcement learning in online systems, including low sample efficiency,\nuncontrollable risks, and excessive variances. To address these issues, we\npropose a novel reinforcement learning method, namely model-based\ncounterfactual advantage learning (MBCAL). The proposed method takes advantage\nof the characteristics of recommender systems and draws ideas from the\nmodel-based reinforcement learning method for higher sample efficiency. It has\ntwo components: an environment model that predicts the instant user behavior\none-by-one in an auto-regressive form, and a future advantage model that\npredicts the future utility. To alleviate the impact of excessive variance when\nlearning the future advantage model, we employ counterfactual comparisons\nderived from the environment model. In consequence, the proposed method\npossesses high sample efficiency and significantly lower variance; Also, it is\nable to use existing user logs to avoid the risks of starting from scratch. In\ncontrast to its capability, its implementation cost is relatively low, which\nfits well with practical systems. Theoretical analysis and elaborate\nexperiments are presented. Results show that the proposed method transcends the\nother supervised learning and RL-based methods in both sample efficiency and\nasymptotic performances.\n", "versions": [{"version": "v1", "created": "Wed, 6 Nov 2019 08:26:32 GMT"}, {"version": "v2", "created": "Thu, 18 Jun 2020 04:45:44 GMT"}], "update_date": "2020-06-19", "authors_parsed": [["Wang", "Fan", ""], ["Fang", "Xiaomin", ""], ["Liu", "Lihang", ""], ["Tian", "Hao", ""], ["Peng", "Zhiming", ""]]}, {"id": "1911.02254", "submitter": "Chaoyue Niu", "authors": "Chaoyue Niu, Fan Wu, Shaojie Tang, Lifeng Hua, Rongfei Jia, Chengfei\n  Lv, Zhihua Wu, and Guihai Chen", "title": "Secure Federated Submodel Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR cs.DC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Federated learning was proposed with an intriguing vision of achieving\ncollaborative machine learning among numerous clients without uploading their\nprivate data to a cloud server. However, the conventional framework requires\neach client to leverage the full model for learning, which can be prohibitively\ninefficient for resource-constrained clients and large-scale deep learning\ntasks. We thus propose a new framework, called federated submodel learning,\nwhere clients download only the needed parts of the full model, namely\nsubmodels, and then upload the submodel updates. Nevertheless, the \"position\"\nof a client's truly required submodel corresponds to her private data, and its\ndisclosure to the cloud server during interactions inevitably breaks the tenet\nof federated learning. To integrate efficiency and privacy, we have designed a\nsecure federated submodel learning scheme coupled with a private set union\nprotocol as a cornerstone. Our secure scheme features the properties of\nrandomized response, secure aggregation, and Bloom filter, and endows each\nclient with a customized plausible deniability, in terms of local differential\nprivacy, against the position of her desired submodel, thus protecting her\nprivate data. We further instantiated our scheme with the e-commerce\nrecommendation scenario in Alibaba, implemented a prototype system, and\nextensively evaluated its performance over 30-day Taobao user data. The\nanalysis and evaluation results demonstrate the feasibility and scalability of\nour scheme from model accuracy and convergency, practical communication,\ncomputation, and storage overheads, as well as manifest its remarkable\nadvantages over the conventional federated learning framework.\n", "versions": [{"version": "v1", "created": "Wed, 6 Nov 2019 08:49:23 GMT"}, {"version": "v2", "created": "Mon, 11 Nov 2019 14:07:41 GMT"}], "update_date": "2019-11-12", "authors_parsed": [["Niu", "Chaoyue", ""], ["Wu", "Fan", ""], ["Tang", "Shaojie", ""], ["Hua", "Lifeng", ""], ["Jia", "Rongfei", ""], ["Lv", "Chengfei", ""], ["Wu", "Zhihua", ""], ["Chen", "Guihai", ""]]}, {"id": "1911.02256", "submitter": "Seyed Kamyar Seyed Ghasemipour", "authors": "Seyed Kamyar Seyed Ghasemipour, Richard Zemel, Shixiang Gu", "title": "A Divergence Minimization Perspective on Imitation Learning Methods", "comments": "Published at Conference on Robot Learning (CoRL) 2019. For datasets\n  and reproducing results please refer to\n  https://github.com/KamyarGh/rl_swiss/blob/master/reproducing/fmax_paper.md", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In many settings, it is desirable to learn decision-making and control\npolicies through learning or bootstrapping from expert demonstrations. The most\ncommon approaches under this Imitation Learning (IL) framework are Behavioural\nCloning (BC), and Inverse Reinforcement Learning (IRL). Recent methods for IRL\nhave demonstrated the capacity to learn effective policies with access to a\nvery limited set of demonstrations, a scenario in which BC methods often fail.\nUnfortunately, due to multiple factors of variation, directly comparing these\nmethods does not provide adequate intuition for understanding this difference\nin performance. In this work, we present a unified probabilistic perspective on\nIL algorithms based on divergence minimization. We present $f$-MAX, an\n$f$-divergence generalization of AIRL [Fu et al., 2018], a state-of-the-art IRL\nmethod. $f$-MAX enables us to relate prior IRL methods such as GAIL [Ho &\nErmon, 2016] and AIRL [Fu et al., 2018], and understand their algorithmic\nproperties. Through the lens of divergence minimization we tease apart the\ndifferences between BC and successful IRL approaches, and empirically evaluate\nthese nuances on simulated high-dimensional continuous control domains. Our\nfindings conclusively identify that IRL's state-marginal matching objective\ncontributes most to its superior performance. Lastly, we apply our new\nunderstanding of IL methods to the problem of state-marginal matching, where we\ndemonstrate that in simulated arm pushing environments we can teach agents a\ndiverse range of behaviours using simply hand-specified state distributions and\nno reward functions or expert demonstrations. For datasets and reproducing\nresults please refer to\nhttps://github.com/KamyarGh/rl_swiss/blob/master/reproducing/fmax_paper.md .\n", "versions": [{"version": "v1", "created": "Wed, 6 Nov 2019 08:50:50 GMT"}], "update_date": "2019-11-07", "authors_parsed": [["Ghasemipour", "Seyed Kamyar Seyed", ""], ["Zemel", "Richard", ""], ["Gu", "Shixiang", ""]]}, {"id": "1911.02257", "submitter": "Ying Luo", "authors": "Ying Luo, Fengshun Xiao, Hai Zhao", "title": "Hierarchical Contextualized Representation for Named Entity Recognition", "comments": "Accepted by AAAI 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Named entity recognition (NER) models are typically based on the architecture\nof Bi-directional LSTM (BiLSTM). The constraints of sequential nature and the\nmodeling of single input prevent the full utilization of global information\nfrom larger scope, not only in the entire sentence, but also in the entire\ndocument (dataset). In this paper, we address these two deficiencies and\npropose a model augmented with hierarchical contextualized representation:\nsentence-level representation and document-level representation. In\nsentence-level, we take different contributions of words in a single sentence\ninto consideration to enhance the sentence representation learned from an\nindependent BiLSTM via label embedding attention mechanism. In document-level,\nthe key-value memory network is adopted to record the document-aware\ninformation for each unique word which is sensitive to similarity of context\ninformation. Our two-level hierarchical contextualized representations are\nfused with each input token embedding and corresponding hidden state of BiLSTM,\nrespectively. The experimental results on three benchmark NER datasets\n(CoNLL-2003 and Ontonotes 5.0 English datasets, CoNLL-2002 Spanish dataset)\nshow that we establish new state-of-the-art results.\n", "versions": [{"version": "v1", "created": "Wed, 6 Nov 2019 08:52:52 GMT"}, {"version": "v2", "created": "Tue, 19 Nov 2019 14:02:29 GMT"}], "update_date": "2019-11-20", "authors_parsed": [["Luo", "Ying", ""], ["Xiao", "Fengshun", ""], ["Zhao", "Hai", ""]]}, {"id": "1911.02265", "submitter": "Priyansh Saxena", "authors": "Priyansh Saxena, Akshat Maheshwari, Shivani Tayal and Saumil\n  Maheshwari", "title": "Predictive modeling of brain tumor: A Deep learning approach", "comments": "An author was incorrectly added and the research is still in\n  progress. Will add the paper soon as soon as the work is complete. Shivani\n  Tayal was mistakenly added as an author due to some trivial error by the\n  uploader", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG eess.IV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Image processing concepts can visualize the different anatomy structure of\nthe human body. Recent advancements in the field of deep learning have made it\npossible to detect the growth of cancerous tissue just by a patient's brain\nMagnetic Resonance Imaging (MRI) scans. These methods require very high\naccuracy and meager false negative rates to be of any practical use. This paper\npresents a Convolutional Neural Network (CNN) based transfer learning approach\nto classify the brain MRI scans into two classes using three pre-trained\nmodels. The performances of these models are compared with each other.\nExperimental results show that the Resnet-50 model achieves the highest\naccuracy and least false negative rates as 95% and zero respectively. It is\nfollowed by VGG-16 and Inception-V3 model with an accuracy of 90% and 55%\nrespectively.\n", "versions": [{"version": "v1", "created": "Wed, 6 Nov 2019 09:27:48 GMT"}, {"version": "v2", "created": "Wed, 18 Dec 2019 12:04:18 GMT"}, {"version": "v3", "created": "Thu, 19 Dec 2019 05:48:24 GMT"}, {"version": "v4", "created": "Mon, 9 Mar 2020 07:16:18 GMT"}, {"version": "v5", "created": "Wed, 19 May 2021 15:10:59 GMT"}], "update_date": "2021-05-20", "authors_parsed": [["Saxena", "Priyansh", ""], ["Maheshwari", "Akshat", ""], ["Tayal", "Shivani", ""], ["Maheshwari", "Saumil", ""]]}, {"id": "1911.02277", "submitter": "Sina Molavipour", "authors": "Sina Molavipour, Germ\\'an Bassi, Mikael Skoglund", "title": "Conditional Mutual Information Neural Estimator", "comments": "To be presented at ICASSP 2020", "journal-ref": "ICASSP 2020, Barcelona, Spain, 2020, pp. 5025-5029", "doi": "10.1109/ICASSP40776.2020.9053422", "report-no": null, "categories": "cs.IT cs.LG math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Several recent works in communication systems have proposed to leverage the\npower of neural networks in the design of encoders and decoders. In this\napproach, these blocks can be tailored to maximize the transmission rate based\non aggregated samples from the channel. Motivated by the fact that, in many\ncommunication schemes, the achievable transmission rate is determined by a\nconditional mutual information term, this paper focuses on neural-based\nestimators for this information-theoretic quantity. Our results are based on\nvariational bounds for the KL-divergence and, in contrast to some previous\nworks, we provide a mathematically rigorous lower bound. However, additional\nchallenges with respect to the unconditional mutual information emerge due to\nthe presence of a conditional density function which we address here.\n", "versions": [{"version": "v1", "created": "Wed, 6 Nov 2019 09:52:29 GMT"}, {"version": "v2", "created": "Fri, 14 Feb 2020 12:29:18 GMT"}], "update_date": "2020-07-15", "authors_parsed": [["Molavipour", "Sina", ""], ["Bassi", "Germ\u00e1n", ""], ["Skoglund", "Mikael", ""]]}, {"id": "1911.02319", "submitter": "Othmane Mounjid", "authors": "Othmane Mounjid and Charles-Albert Lehalle", "title": "Improving reinforcement learning algorithms: towards optimal learning\n  rate policies", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG math.OC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper investigates to what extent one can improve reinforcement learning\nalgorithms. Our study is split in three parts. First, our analysis shows that\nthe classical asymptotic convergence rate $O(1/\\sqrt{N})$ is pessimistic and\ncan be replaced by $O((\\log(N)/N)^{\\beta})$ with $\\frac{1}{2}\\leq \\beta \\leq 1$\nand $N$ the number of iterations. Second, we propose a dynamic optimal policy\nfor the choice of the learning rate $(\\gamma_k)_{k\\geq 0}$ used in stochastic\napproximation (SA). We decompose our policy into two interacting levels: the\ninner and the outer level. In the inner level, we present the\n\\nameref{Alg:v_4_s} algorithm (for \"PAst Sign Search\") which, based on a\npredefined sequence $(\\gamma^o_k)_{k\\geq 0}$, constructs a new sequence\n$(\\gamma^i_k)_{k\\geq 0}$ whose error decreases faster. In the outer level, we\npropose an optimal methodology for the selection of the predefined sequence\n$(\\gamma^o_k)_{k\\geq 0}$. Third, we show empirically that our selection\nmethodology of the learning rate outperforms significantly standard algorithms\nused in reinforcement learning (RL) in the three following applications: the\nestimation of a drift, the optimal placement of limit orders and the optimal\nexecution of large number of shares.\n", "versions": [{"version": "v1", "created": "Wed, 6 Nov 2019 11:17:53 GMT"}, {"version": "v2", "created": "Tue, 10 Mar 2020 19:05:39 GMT"}, {"version": "v3", "created": "Thu, 12 Mar 2020 21:12:12 GMT"}, {"version": "v4", "created": "Tue, 21 Apr 2020 18:04:00 GMT"}], "update_date": "2020-04-23", "authors_parsed": [["Mounjid", "Othmane", ""], ["Lehalle", "Charles-Albert", ""]]}, {"id": "1911.02320", "submitter": "Sandy Huang", "authors": "Sandy H. Huang, Isabella Huang, Ravi Pandya, Anca D. Dragan", "title": "Nonverbal Robot Feedback for Human Teachers", "comments": "CoRL 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.HC cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Robots can learn preferences from human demonstrations, but their success\ndepends on how informative these demonstrations are. Being informative is\nunfortunately very challenging, because during teaching, people typically get\nno transparency into what the robot already knows or has learned so far. In\ncontrast, human students naturally provide a wealth of nonverbal feedback that\nreveals their level of understanding and engagement. In this work, we study how\na robot can similarly provide feedback that is minimally disruptive, yet gives\nhuman teachers a better mental model of the robot learner, and thus enables\nthem to teach more effectively. Our idea is that at any point, the robot can\nindicate what it thinks the correct next action is, shedding light on its\ncurrent estimate of the human's preferences. We analyze how useful this\nfeedback is, both in theory and with two user studies---one with a virtual\ncharacter that tests the feedback itself, and one with a PR2 robot that uses\ngaze as the feedback mechanism. We find that feedback can be useful for\nimproving both the quality of teaching and teachers' understanding of the\nrobot's capability.\n", "versions": [{"version": "v1", "created": "Wed, 6 Nov 2019 11:26:31 GMT"}], "update_date": "2019-11-07", "authors_parsed": [["Huang", "Sandy H.", ""], ["Huang", "Isabella", ""], ["Pandya", "Ravi", ""], ["Dragan", "Anca D.", ""]]}, {"id": "1911.02344", "submitter": "Haiping Huang", "authors": "Tianqi Hou and Haiping Huang", "title": "Statistical physics of unsupervised learning with prior knowledge in\n  neural networks", "comments": "15 pages, 3 figures with supplemental material", "journal-ref": "Phys. Rev. Lett. 124, 248302 (2020)", "doi": "10.1103/PhysRevLett.124.248302", "report-no": null, "categories": "cond-mat.dis-nn cond-mat.stat-mech cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Integrating sensory inputs with prior beliefs from past experiences in\nunsupervised learning is a common and fundamental characteristic of brain or\nartificial neural computation. However, a quantitative role of prior knowledge\nin unsupervised learning remains unclear, prohibiting a scientific\nunderstanding of unsupervised learning. Here, we propose a statistical physics\nmodel of unsupervised learning with prior knowledge, revealing that the sensory\ninputs drive a series of continuous phase transitions related to spontaneous\nintrinsic-symmetry breaking. The intrinsic symmetry includes both reverse\nsymmetry and permutation symmetry, commonly observed in most artificial neural\nnetworks. Compared to the prior-free scenario, the prior reduces more strongly\nthe minimal data size triggering the reverse symmetry breaking transition, and\nmoreover, the prior merges, rather than separates, permutation symmetry\nbreaking phases. We claim that the prior can be learned from data samples,\nwhich in physics corresponds to a two-parameter Nishimori constraint. This work\nthus reveals mechanisms about the influence of the prior on unsupervised\nlearning.\n", "versions": [{"version": "v1", "created": "Wed, 6 Nov 2019 12:40:39 GMT"}, {"version": "v2", "created": "Wed, 27 May 2020 13:57:05 GMT"}], "update_date": "2020-06-19", "authors_parsed": [["Hou", "Tianqi", ""], ["Huang", "Haiping", ""]]}, {"id": "1911.02361", "submitter": "Jarek Duda dr", "authors": "Jaros{\\l}aw Duda, Robert Syrek, Henryk Gurgul", "title": "Modelling bid-ask spread conditional distributions using hierarchical\n  correlation reconstruction", "comments": "10 pages, 7 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-fin.TR cs.LG q-fin.ST stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  While we would like to predict exact values, available incomplete information\nis rarely sufficient - usually allowing only to predict conditional probability\ndistributions. This article discusses hierarchical correlation reconstruction\n(HCR) methodology for such prediction on example of usually unavailable bid-ask\nspreads, predicted from more accessible data like closing price, volume,\nhigh/low price, returns. In HCR methodology we first normalize marginal\ndistributions to nearly uniform like in copula theory. Then we model (joint)\ndensities as linear combinations of orthonormal polynomials, getting its\ndecomposition into (mixed) moments. Then here we model each moment (separately)\nof predicted variable as a linear combination of mixed moments of known\nvariables using least squares linear regression - getting accurate description\nwith interpretable coefficients describing linear relations between moments.\nCombining such predicted moments we get predicted density as a polynomial, for\nwhich we can e.g. calculate expected value, but also variance to evaluate\nuncertainty of such prediction, or we can use the entire distribution e.g. for\nmore accurate further calculations or generating random values. There were\nperformed 10-fold cross-validation log-likelihood tests for 22 DAX companies,\nleading to very accurate predictions, especially when using individual models\nfor each company as there were found large differences between their behaviors.\nAdditional advantage of the discussed methodology is being computationally\ninexpensive, finding and evaluation a model with hundreds of parameters and\nthousands of data points takes a second on a laptop.\n", "versions": [{"version": "v1", "created": "Mon, 4 Nov 2019 09:57:27 GMT"}], "update_date": "2019-11-07", "authors_parsed": [["Duda", "Jaros\u0142aw", ""], ["Syrek", "Robert", ""], ["Gurgul", "Henryk", ""]]}, {"id": "1911.02363", "submitter": "Chi-Ning Chou", "authors": "Chi-Ning Chou, Mien Brabeeba Wang", "title": "ODE-Inspired Analysis for the Biological Version of Oja's Rule in\n  Solving Streaming PCA", "comments": "Accepted for presentation at the Conference on Learning Theory (COLT)\n  2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.NC cs.DS cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Oja's rule [Oja, Journal of mathematical biology 1982] is a well-known\nbiologically-plausible algorithm using a Hebbian-type synaptic update rule to\nsolve streaming principal component analysis (PCA). Computational\nneuroscientists have known that this biological version of Oja's rule converges\nto the top eigenvector of the covariance matrix of the input in the limit.\nHowever, prior to this work, it was open to prove any convergence rate\nguarantee.\n  In this work, we give the first convergence rate analysis for the biological\nversion of Oja's rule in solving streaming PCA. Moreover, our convergence rate\nmatches the information theoretical lower bound up to logarithmic factors and\noutperforms the state-of-the-art upper bound for streaming PCA. Furthermore, we\ndevelop a novel framework inspired by ordinary differential equations (ODE) to\nanalyze general stochastic dynamics. The framework abandons the traditional\nstep-by-step analysis and instead analyzes a stochastic dynamic in one-shot by\ngiving a closed-form solution to the entire dynamic. The one-shot framework\nallows us to apply stopping time and martingale techniques to have a flexible\nand precise control on the dynamic. We believe that this general framework is\npowerful and should lead to effective yet simple analysis for a large class of\nproblems with stochastic dynamics.\n", "versions": [{"version": "v1", "created": "Mon, 4 Nov 2019 16:01:32 GMT"}, {"version": "v2", "created": "Wed, 17 Jun 2020 21:32:51 GMT"}], "update_date": "2020-06-19", "authors_parsed": [["Chou", "Chi-Ning", ""], ["Wang", "Mien Brabeeba", ""]]}, {"id": "1911.02365", "submitter": "Tassilo Klein", "authors": "Tassilo Klein, Moin Nabi", "title": "Learning to Answer by Learning to Ask: Getting the Best of GPT-2 and\n  BERT Worlds", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Automatic question generation aims at the generation of questions from a\ncontext, with the corresponding answers being sub-spans of the given passage.\nWhereas, most of the methods mostly rely on heuristic rules to generate\nquestions, more recently also neural network approaches have been proposed. In\nthis work, we propose a variant of the self-attention Transformer network\narchitectures model to generate meaningful and diverse questions. To this end,\nwe propose an easy to use model consisting of the conjunction of the\nTransformer decoder GPT-2 model with Transformer encoder BERT for the\ndownstream task for question answering. The model is trained in an end-to-end\nfashion, where the language model is trained to produce a question-answer-aware\ninput representation that facilitates to generate an answer focused question.\nOur result of neural question generation from text on the SQuAD 1.1 dataset\nsuggests that our method can produce semantically correct and diverse\nquestions. Additionally, we assessed the performance of our proposed method for\nthe downstream task of question answering. The analysis shows that our proposed\ngeneration & answering collaboration framework relatively improves both tasks\nand is particularly powerful in the semi-supervised setup. The results further\nsuggest a robust and comparably lean pipeline facilitating question generation\nin the small-data regime.\n", "versions": [{"version": "v1", "created": "Wed, 6 Nov 2019 13:23:41 GMT"}], "update_date": "2019-11-07", "authors_parsed": [["Klein", "Tassilo", ""], ["Nabi", "Moin", ""]]}, {"id": "1911.02367", "submitter": "Petr M\\'anek", "authors": "Petr M\\'anek, Benedikt Bergmann, Petr Burian, Luk\\'a\\v{s} Meduna,\n  Stanislav Posp\\'i\\v{s}il, Michal Suk", "title": "Randomized Computer Vision Approaches for Pattern Recognition in Timepix\n  and Timepix3 Detectors", "comments": "Presented at Connecting the Dots and Workshop on Intelligent Trackers\n  (CTD/WIT 2019)", "journal-ref": null, "doi": null, "report-no": "PROC-CTD19-012", "categories": "physics.data-an cs.LG", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Timepix and Timepix3 are hybrid pixel detectors ($256\\times 256$ pixels),\ncapable of tracking ionizing particles as isolated clusters of pixels. To\nefficiently analyze such clusters at potentially high rates, we introduce\nmultiple randomized pattern recognition algorithms inspired by computer vision.\nOffering desirable probabilistic bounds on accuracy and complexity, the\npresented methods are well-suited for use in real-time applications, and some\nmay even be modified to tackle trans-dimensional problems. In Timepix\ndetectors, which do not support data-driven acquisition, they have been shown\nto correctly separate clusters of overlapping tracks. In Timepix3 detectors,\nsimultaneous acquisition of Time-of-Arrival (ToA) and Time-over-Threshold (ToT)\npixel data enables reconstruction of the depth, transitioning from 2D to 3D\npoint clouds. The presented algorithms have been tested on simulated inputs,\ntest beam data from the Heidelberg Ion therapy Center and the Super Proton\nSynchrotron and were applied to data acquired in the MoEDAL and ATLAS\nexperiments at CERN.\n", "versions": [{"version": "v1", "created": "Wed, 6 Nov 2019 13:27:15 GMT"}], "update_date": "2019-11-07", "authors_parsed": [["M\u00e1nek", "Petr", ""], ["Bergmann", "Benedikt", ""], ["Burian", "Petr", ""], ["Meduna", "Luk\u00e1\u0161", ""], ["Posp\u00ed\u0161il", "Stanislav", ""], ["Suk", "Michal", ""]]}, {"id": "1911.02369", "submitter": "Abhishek .", "authors": "Abhishek Abhishek (1 and 2) and Wojciech Fedorko (2) and Patrick de\n  Perio (2) and Nicholas Prouse (2) and Julian Z. Ding (2 and 3) ((1)\n  University of Manitoba, (2) TRIUMF, (3) University of British Columbia)", "title": "Variational Autoencoders for Generative Modelling of Water Cherenkov\n  Detectors", "comments": "6 pages, 4 figures, 1 table, submitted to Machine Learning and the\n  Physical Sciences Workshop at NeurIPS 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "physics.ins-det cs.LG hep-ex stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Matter-antimatter asymmetry is one of the major unsolved problems in physics\nthat can be probed through precision measurements of charge-parity symmetry\nviolation at current and next-generation neutrino oscillation experiments. In\nthis work, we demonstrate the capability of variational autoencoders and\nnormalizing flows to approximate the generative distribution of simulated data\nfor water Cherenkov detectors commonly used in these experiments. We study the\nperformance of these methods and their applicability for semi-supervised\nlearning and synthetic data generation.\n", "versions": [{"version": "v1", "created": "Fri, 1 Nov 2019 22:16:03 GMT"}], "update_date": "2019-11-07", "authors_parsed": [["Abhishek", "Abhishek", "", "1 and 2"], ["Fedorko", "Wojciech", "", "2 and 3"], ["de Perio", "Patrick", "", "2 and 3"], ["Prouse", "Nicholas", "", "2 and 3"], ["Ding", "Julian Z.", "", "2 and 3"]]}, {"id": "1911.02372", "submitter": "Ziyuan Pu", "authors": "Ziyuan Pu, Shuo Wang, Chenglong Liu, Zhiyong Cui, Yinhai Wang", "title": "Road Surface Friction Prediction Using Long Short-Term Memory Neural\n  Network Based on Historical Data", "comments": "arXiv admin note: text overlap with arXiv:1911.00605", "journal-ref": "Journal of Intelligent Transportation Systems (2020): 1-12", "doi": "10.1080/15472450.2020.1780922", "report-no": null, "categories": "eess.SP cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Road surface friction significantly impacts traffic safety and mobility. A\nprecise road surface friction prediction model can help to alleviate the\ninfluence of inclement road conditions on traffic safety, Level of Service,\ntraffic mobility, fuel efficiency, and sustained economic productivity. Most\nrelated previous studies are laboratory-based methods that are difficult for\npractical implementation. Moreover, in other data-driven methods, the\ndemonstrated time-series features of road surface conditions have not been\nconsidered. This study employed a Long-Short Term Memory (LSTM) neural network\nto develop a data-driven road surface friction prediction model based on\nhistorical data. The proposed prediction model outperformed the other baseline\nmodels in terms of the lowest value of predictive performance measurements. The\ninfluence of the number of time-lags and the predicting time interval on\npredictive accuracy was analyzed. In addition, the influence of adding road\nsurface water thickness, road surface temperature and air temperature on\npredictive accuracy also were investigated. The findings of this study can\nsupport road maintenance strategy development and decision making, thus\nmitigating the impact of inclement road conditions on traffic mobility and\nsafety. Future work includes a modified LSTM-based prediction model development\nby accommodating flexible time intervals between time-lags.\n", "versions": [{"version": "v1", "created": "Fri, 1 Nov 2019 07:08:00 GMT"}], "update_date": "2020-07-13", "authors_parsed": [["Pu", "Ziyuan", ""], ["Wang", "Shuo", ""], ["Liu", "Chenglong", ""], ["Cui", "Zhiyong", ""], ["Wang", "Yinhai", ""]]}, {"id": "1911.02377", "submitter": "Quanming Yao", "authors": "Quanming Yao, Hansi Yang, Bo Han, Gang Niu, James Kwok", "title": "Searching to Exploit Memorization Effect in Learning from Corrupted\n  Labels", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Sample selection approaches are popular in robust learning from noisy labels.\nHowever, how to properly control the selection process so that deep networks\ncan benefit from the memorization effect is a hard problem. In this paper,\nmotivated by the success of automated machine learning (AutoML), we model this\nissue as a function approximation problem. Specifically, we design a\ndomain-specific search space based on general patterns of the memorization\neffect and propose a novel Newton algorithm to solve the bi-level optimization\nproblem efficiently. We further provide theoretical analysis of the algorithm,\nwhich ensures a good approximation to critical points. Experiments are\nperformed on benchmark data sets. Results demonstrate that the proposed method\nis much better than the state-of-the-art noisy-label-learning approaches, and\nalso much more efficient than existing AutoML algorithms.\n", "versions": [{"version": "v1", "created": "Wed, 6 Nov 2019 13:36:04 GMT"}, {"version": "v2", "created": "Sun, 12 Apr 2020 08:22:25 GMT"}, {"version": "v3", "created": "Wed, 24 Jun 2020 16:46:01 GMT"}, {"version": "v4", "created": "Fri, 28 Aug 2020 20:00:08 GMT"}, {"version": "v5", "created": "Fri, 18 Sep 2020 16:14:11 GMT"}], "update_date": "2020-09-21", "authors_parsed": [["Yao", "Quanming", ""], ["Yang", "Hansi", ""], ["Han", "Bo", ""], ["Niu", "Gang", ""], ["Kwok", "James", ""]]}, {"id": "1911.02388", "submitter": "Pavel Korshunov", "authors": "Md Sahidullah, Jose Patino, Samuele Cornell, Ruiqing Yin, Sunit\n  Sivasankaran, Herv\\'e Bredin, Pavel Korshunov, Alessio Brutti, Romain\n  Serizel, Emmanuel Vincent, Nicholas Evans, S\\'ebastien Marcel, Stefano\n  Squartini, Claude Barras", "title": "The Speed Submission to DIHARD II: Contributions & Lessons Learned", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.AS cs.LG cs.SD", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper describes the speaker diarization systems developed for the Second\nDIHARD Speech Diarization Challenge (DIHARD II) by the Speed team. Besides\ndescribing the system, which considerably outperformed the challenge baselines,\nwe also focus on the lessons learned from numerous approaches that we tried for\nsingle and multi-channel systems. We present several components of our\ndiarization system, including categorization of domains, speech enhancement,\nspeech activity detection, speaker embeddings, clustering methods,\nresegmentation, and system fusion. We analyze and discuss the effect of each\nsuch component on the overall diarization performance within the realistic\nsettings of the challenge.\n", "versions": [{"version": "v1", "created": "Wed, 6 Nov 2019 13:53:18 GMT"}], "update_date": "2019-11-07", "authors_parsed": [["Sahidullah", "Md", ""], ["Patino", "Jose", ""], ["Cornell", "Samuele", ""], ["Yin", "Ruiqing", ""], ["Sivasankaran", "Sunit", ""], ["Bredin", "Herv\u00e9", ""], ["Korshunov", "Pavel", ""], ["Brutti", "Alessio", ""], ["Serizel", "Romain", ""], ["Vincent", "Emmanuel", ""], ["Evans", "Nicholas", ""], ["Marcel", "S\u00e9bastien", ""], ["Squartini", "Stefano", ""], ["Barras", "Claude", ""]]}, {"id": "1911.02417", "submitter": "Zhaohui Yang", "authors": "Zhaohui Yang and Mingzhe Chen and Walid Saad and Choong Seon Hong and\n  Mohammad Shikh-Bahaei", "title": "Energy Efficient Federated Learning Over Wireless Communication Networks", "comments": "In IEEE TWC", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IT cs.LG math.IT stat.ML", "license": "http://creativecommons.org/licenses/by-sa/4.0/", "abstract": "  In this paper, the problem of energy efficient transmission and computation\nresource allocation for federated learning (FL) over wireless communication\nnetworks is investigated. In the considered model, each user exploits limited\nlocal computational resources to train a local FL model with its collected data\nand, then, sends the trained FL model to a base station (BS) which aggregates\nthe local FL model and broadcasts it back to all of the users. Since FL\ninvolves an exchange of a learning model between users and the BS, both\ncomputation and communication latencies are determined by the learning accuracy\nlevel. Meanwhile, due to the limited energy budget of the wireless users, both\nlocal computation energy and transmission energy must be considered during the\nFL process. This joint learning and communication problem is formulated as an\noptimization problem whose goal is to minimize the total energy consumption of\nthe system under a latency constraint. To solve this problem, an iterative\nalgorithm is proposed where, at every step, closed-form solutions for time\nallocation, bandwidth allocation, power control, computation frequency, and\nlearning accuracy are derived. Since the iterative algorithm requires an\ninitial feasible solution, we construct the completion time minimization\nproblem and a bisection-based algorithm is proposed to obtain the optimal\nsolution, which is a feasible solution to the original energy minimization\nproblem. Numerical results show that the proposed algorithms can reduce up to\n59.5% energy consumption compared to the conventional FL method.\n", "versions": [{"version": "v1", "created": "Wed, 6 Nov 2019 14:51:49 GMT"}, {"version": "v2", "created": "Wed, 18 Nov 2020 03:17:03 GMT"}], "update_date": "2020-11-19", "authors_parsed": [["Yang", "Zhaohui", ""], ["Chen", "Mingzhe", ""], ["Saad", "Walid", ""], ["Hong", "Choong Seon", ""], ["Shikh-Bahaei", "Mohammad", ""]]}, {"id": "1911.02423", "submitter": "Dorjan Hitaj", "authors": "Fabio De Gaspari, Dorjan Hitaj, Giulio Pagnotta, Lorenzo De Carli,\n  Luigi V. Mancini", "title": "The Naked Sun: Malicious Cooperation Between Benign-Looking Processes", "comments": "15 pages, 6 figures, 4 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent progress in machine learning has generated promising results in\nbehavioral malware detection. Behavioral modeling identifies malicious\nprocesses via features derived by their runtime behavior. Behavioral features\nhold great promise as they are intrinsically related to the functioning of each\nmalware, and are therefore considered difficult to evade. Indeed, while a\nsignificant amount of results exists on evasion of static malware features,\nevasion of dynamic features has seen limited work. This paper thoroughly\nexamines the robustness of behavioral malware detectors to evasion, focusing\nparticularly on anti-ransomware evasion. We choose ransomware as its behavior\ntends to differ significantly from that of benign processes, making it a\nlow-hanging fruit for behavioral detection (and a difficult candidate for\nevasion). Our analysis identifies a set of novel attacks that distribute the\noverall malware workload across a small set of cooperating processes to avoid\nthe generation of significant behavioral features. Our most effective attack\ndecreases the accuracy of a state-of-the-art classifier from 98.6% to 0% using\nonly 18 cooperating processes. Furthermore, we show our attacks to be effective\nagainst commercial ransomware detectors even in a black-box setting.\n", "versions": [{"version": "v1", "created": "Wed, 6 Nov 2019 15:04:07 GMT"}], "update_date": "2019-11-07", "authors_parsed": [["De Gaspari", "Fabio", ""], ["Hitaj", "Dorjan", ""], ["Pagnotta", "Giulio", ""], ["De Carli", "Lorenzo", ""], ["Mancini", "Luigi V.", ""]]}, {"id": "1911.02425", "submitter": "Maddalena Torricelli", "authors": "Maddalena Torricelli, M\\'arton Karsai, Laetitia Gauvin", "title": "weg2vec: Event embedding for temporal networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "physics.soc-ph cs.LG cs.SI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Network embedding techniques are powerful to capture structural regularities\nin networks and to identify similarities between their local fabrics. However,\nconventional network embedding models are developed for static structures,\ncommonly consider nodes only and they are seriously challenged when the network\nis varying in time. Temporal networks may provide an advantage in the\ndescription of real systems, but they code more complex information, which\ncould be effectively represented only by a handful of methods so far. Here, we\npropose a new method of event embedding of temporal networks, called weg2vec,\nwhich builds on temporal and structural similarities of events to learn a low\ndimensional representation of a temporal network. This projection successfully\ncaptures latent structures and similarities between events involving different\nnodes at different times and provides ways to predict the final outcome of\nspreading processes unfolding on the temporal structure.\n", "versions": [{"version": "v1", "created": "Wed, 6 Nov 2019 15:09:37 GMT"}], "update_date": "2019-11-07", "authors_parsed": [["Torricelli", "Maddalena", ""], ["Karsai", "M\u00e1rton", ""], ["Gauvin", "Laetitia", ""]]}, {"id": "1911.02444", "submitter": "Javiera Astudillo Bessi", "authors": "Javiera Astudillo, Pavlos Protopapas, Karim Pichara, Pablo Huijse", "title": "An Information Theory Approach on Deciding Spectroscopic Follow Ups", "comments": null, "journal-ref": null, "doi": "10.3847/1538-3881/ab557d", "report-no": null, "categories": "astro-ph.IM cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Classification and characterization of variable phenomena and transient\nphenomena are critical for astrophysics and cosmology. These objects are\ncommonly studied using photometric time series or spectroscopic data. Given\nthat many ongoing and future surveys are in time-domain and given that adding\nspectra provide further insights but requires more observational resources, it\nwould be valuable to know which objects should we prioritize to have spectrum\nin addition to time series. We propose a methodology in a probabilistic setting\nthat determines a-priory which objects are worth taking spectrum to obtain\nbetter insights, where we focus 'insight' as the type of the object\n(classification). Objects for which we query its spectrum are reclassified\nusing their full spectrum information. We first train two classifiers, one that\nuses photometric data and another that uses photometric and spectroscopic data\ntogether. Then for each photometric object we estimate the probability of each\npossible spectrum outcome. We combine these models in various probabilistic\nframeworks (strategies) which are used to guide the selection of follow up\nobservations. The best strategy depends on the intended use, whether it is\ngetting more confidence or accuracy. For a given number of candidate objects\n(127, equal to 5% of the dataset) for taking spectra, we improve 37% class\nprediction accuracy as opposed to 20% of a non-naive (non-random) best\nbase-line strategy. Our approach provides a general framework for follow-up\nstrategies and can be extended beyond classification and to include other forms\nof follow-ups beyond spectroscopy.\n", "versions": [{"version": "v1", "created": "Wed, 6 Nov 2019 15:43:17 GMT"}], "update_date": "2020-01-08", "authors_parsed": [["Astudillo", "Javiera", ""], ["Protopapas", "Pavlos", ""], ["Pichara", "Karim", ""], ["Huijse", "Pablo", ""]]}, {"id": "1911.02455", "submitter": "Agathe Balayn", "authors": "Agathe Balayn, Alessandro Bozzon, Zoltan Szlavik", "title": "Unfairness towards subjective opinions in Machine Learning", "comments": "Human-Centered Machine Learning Perspectives (HCML) workshop at the\n  CHI conference 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CY cs.HC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Despite the high interest for Machine Learning (ML) in academia and industry,\nmany issues related to the application of ML to real-life problems are yet to\nbe addressed. Here we put forward one limitation which arises from a lack of\nadaptation of ML models and datasets to specific applications. We formalise a\nnew notion of unfairness as exclusion of opinions. We propose ways to quantify\nthis unfairness, and aid understanding its causes through visualisation. These\ninsights into the functioning of ML-based systems hint at methods to mitigate\nunfairness.\n", "versions": [{"version": "v1", "created": "Wed, 6 Nov 2019 16:11:41 GMT"}], "update_date": "2019-11-07", "authors_parsed": [["Balayn", "Agathe", ""], ["Bozzon", "Alessandro", ""], ["Szlavik", "Zoltan", ""]]}, {"id": "1911.02469", "submitter": "James Lucas", "authors": "James Lucas, George Tucker, Roger Grosse, Mohammad Norouzi", "title": "Don't Blame the ELBO! A Linear VAE Perspective on Posterior Collapse", "comments": "11 main pages, 10 appendix pages. 13 figures total. Accepted at 33rd\n  Conference on Neural Information Processing Systems (NeurIPS 2019)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Posterior collapse in Variational Autoencoders (VAEs) arises when the\nvariational posterior distribution closely matches the prior for a subset of\nlatent variables. This paper presents a simple and intuitive explanation for\nposterior collapse through the analysis of linear VAEs and their direct\ncorrespondence with Probabilistic PCA (pPCA). We explain how posterior collapse\nmay occur in pPCA due to local maxima in the log marginal likelihood.\nUnexpectedly, we prove that the ELBO objective for the linear VAE does not\nintroduce additional spurious local maxima relative to log marginal likelihood.\nWe show further that training a linear VAE with exact variational inference\nrecovers an identifiable global maximum corresponding to the principal\ncomponent directions. Empirically, we find that our linear analysis is\npredictive even for high-capacity, non-linear VAEs and helps explain the\nrelationship between the observation noise, local maxima, and posterior\ncollapse in deep Gaussian VAEs.\n", "versions": [{"version": "v1", "created": "Wed, 6 Nov 2019 16:34:04 GMT"}], "update_date": "2019-11-07", "authors_parsed": [["Lucas", "James", ""], ["Tucker", "George", ""], ["Grosse", "Roger", ""], ["Norouzi", "Mohammad", ""]]}, {"id": "1911.02471", "submitter": "Agathe Balayn", "authors": "Agathe Balayn, Alessandro Bozzon", "title": "Designing Evaluations of Machine Learning Models for Subjective\n  Inference: The Case of Sentence Toxicity", "comments": "presented at the Rigorous Evaluation of Artificial Intelligence\n  Systems (REAIS) workshop co-located with HCOMP 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CL stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Machine Learning (ML) is increasingly applied in real-life scenarios, raising\nconcerns about bias in automatic decision making. We focus on bias as a notion\nof opinion exclusion, that stems from the direct application of traditional ML\npipelines to infer subjective properties. We argue that such ML systems should\nbe evaluated with subjectivity and bias in mind. Considering the lack of\nevaluation standards yet to create evaluation benchmarks, we propose an initial\nlist of specifications to define prior to creating evaluation datasets, in\norder to later accurately evaluate the biases. With the example of a sentence\ntoxicity inference system, we illustrate how the specifications support the\nanalysis of biases related to subjectivity. We highlight difficulties in\ninstantiating these specifications and list future work for the crowdsourcing\ncommunity to help the creation of appropriate evaluation datasets.\n", "versions": [{"version": "v1", "created": "Wed, 6 Nov 2019 16:38:19 GMT"}], "update_date": "2019-11-07", "authors_parsed": [["Balayn", "Agathe", ""], ["Bozzon", "Alessandro", ""]]}, {"id": "1911.02475", "submitter": "Xiaofeng Liu", "authors": "Xiaofeng Liu, Xu Han, Yukai Qiao, Yi Ge, Lu Jun", "title": "Unimodal-uniform Constrained Wasserstein Training for Medical Diagnosis", "comments": "ICCV VRMI workshop Oral. arXiv admin note: text overlap with\n  arXiv:1911.00962", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.IV cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The labels in medical diagnosis task are usually discrete and successively\ndistributed. For example, the Diabetic Retinopathy Diagnosis (DR) involves five\nhealth risk levels: no DR (0), mild DR (1), moderate DR (2), severe DR (3) and\nproliferative DR (4). This labeling system is common for medical disease.\nPrevious methods usually construct a multi-binary-classification task or\npropose some re-parameter schemes in the output unit. In this paper, we target\non this task from the perspective of loss function. More specifically, the\nWasserstein distance is utilized as an alternative, explicitly incorporating\nthe inter-class correlations by pre-defining its ground metric. Then, the\nground metric which serves as a linear, convex or concave increasing function\nw.r.t. the Euclidean distance in a line is explored from an optimization\nperspective. Meanwhile, this paper also proposes of constructing the smoothed\ntarget labels that model the inlier and outlier noises by using a\nunimodal-uniform mixture distribution. Different from the one-hot setting, the\nsmoothed label endues the computation of Wasserstein distance with more\nchallenging features. With either one-hot or smoothed target label, this paper\nsystematically concludes the practical closed-form solution. We evaluate our\nmethod on several medical diagnosis tasks (e.g., Diabetic Retinopathy and\nUltrasound Breast dataset) and achieve state-of-the-art performance.\n", "versions": [{"version": "v1", "created": "Sun, 3 Nov 2019 20:41:14 GMT"}], "update_date": "2019-11-07", "authors_parsed": [["Liu", "Xiaofeng", ""], ["Han", "Xu", ""], ["Qiao", "Yukai", ""], ["Ge", "Yi", ""], ["Jun", "Lu", ""]]}, {"id": "1911.02490", "submitter": "Joaquin Vanschoren", "authors": "Matthias Feurer, Jan N. van Rijn, Arlind Kadra, Pieter Gijsbers,\n  Neeratyoy Mallik, Sahithya Ravi, Andreas M\\\"uller, Joaquin Vanschoren, Frank\n  Hutter", "title": "OpenML-Python: an extensible Python API for OpenML", "comments": null, "journal-ref": "Journal of Machine Learning Research 22(100), 2021", "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  OpenML is an online platform for open science collaboration in machine\nlearning, used to share datasets and results of machine learning experiments.\nIn this paper we introduce OpenML-Python, a client API for Python, opening up\nthe OpenML platform for a wide range of Python-based tools. It provides easy\naccess to all datasets, tasks and experiments on OpenML from within Python. It\nalso provides functionality to conduct machine learning experiments, upload the\nresults to OpenML, and reproduce results which are stored on OpenML.\nFurthermore, it comes with a scikit-learn plugin and a plugin mechanism to\neasily integrate other machine learning libraries written in Python into the\nOpenML ecosystem. Source code and documentation is available at\nhttps://github.com/openml/openml-python/.\n", "versions": [{"version": "v1", "created": "Wed, 6 Nov 2019 16:59:30 GMT"}, {"version": "v2", "created": "Wed, 23 Jun 2021 14:04:39 GMT"}], "update_date": "2021-06-24", "authors_parsed": [["Feurer", "Matthias", ""], ["van Rijn", "Jan N.", ""], ["Kadra", "Arlind", ""], ["Gijsbers", "Pieter", ""], ["Mallik", "Neeratyoy", ""], ["Ravi", "Sahithya", ""], ["M\u00fcller", "Andreas", ""], ["Vanschoren", "Joaquin", ""], ["Hutter", "Frank", ""]]}, {"id": "1911.02496", "submitter": "Dmtri Babaev", "authors": "Dmitrii Babaev, Maxim Savchenko, Alexander Tuzhilin, Dmitrii Umerenkov", "title": "E.T.-RNN: Applying Deep Learning to Credit Loan Applications", "comments": "KDD 2019", "journal-ref": null, "doi": "10.1145/3292500.3330693", "report-no": null, "categories": "cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we present a novel approach to credit scoring of retail\ncustomers in the banking industry based on deep learning methods. We used RNNs\non fine grained transnational data to compute credit scores for the loan\napplicants. We demonstrate that our approach significantly outperforms the\nbaselines based on the customer data of a large European bank. We also\nconducted a pilot study on loan applicants of the bank, and the study produced\nsignificant financial gains for the organization. In addition, our method has\nseveral other advantages described in the paper that are very significant for\nthe bank.\n", "versions": [{"version": "v1", "created": "Wed, 6 Nov 2019 17:13:03 GMT"}], "update_date": "2019-11-07", "authors_parsed": [["Babaev", "Dmitrii", ""], ["Savchenko", "Maxim", ""], ["Tuzhilin", "Alexander", ""], ["Umerenkov", "Dmitrii", ""]]}, {"id": "1911.02497", "submitter": "Vinu Joseph", "authors": "Vinu Joseph, Saurav Muralidharan, Animesh Garg, Michael Garland,\n  Ganesh Gopalakrishnan", "title": "A Programmable Approach to Neural Network Compression", "comments": "This is an updated version of a paper published in IEEE Micro, vol.\n  40, no. 5, pp. 17-25, Sept.-Oct. 2020 at\n  https://ieeexplore.ieee.org/document/9151283", "journal-ref": "IEEE Micro, Volume: 40, Issue: 5, Sept.-Oct. 2020, pp. 17-25", "doi": "10.1109/MM.2020.3012391", "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep neural networks (DNNs) frequently contain far more weights, represented\nat a higher precision, than are required for the specific task which they are\ntrained to perform. Consequently, they can often be compressed using techniques\nsuch as weight pruning and quantization that reduce both the model size and\ninference time without appreciable loss in accuracy. However, finding the best\ncompression strategy and corresponding target sparsity for a given DNN,\nhardware platform, and optimization objective currently requires expensive,\nfrequently manual, trial-and-error experimentation. In this paper, we introduce\na programmable system for model compression called Condensa. Users\nprogrammatically compose simple operators, in Python, to build more complex and\npractically interesting compression strategies. Given a strategy and\nuser-provided objective (such as minimization of running time), Condensa uses a\nnovel Bayesian optimization-based algorithm to automatically infer desirable\nsparsities. Our experiments on four real-world DNNs demonstrate memory\nfootprint and hardware runtime throughput improvements of 188x and 2.59x,\nrespectively, using at most ten samples per search. We have released a\nreference implementation of Condensa at https://github.com/NVlabs/condensa.\n", "versions": [{"version": "v1", "created": "Wed, 6 Nov 2019 17:14:32 GMT"}, {"version": "v2", "created": "Tue, 1 Dec 2020 22:55:11 GMT"}], "update_date": "2020-12-03", "authors_parsed": [["Joseph", "Vinu", ""], ["Muralidharan", "Saurav", ""], ["Garg", "Animesh", ""], ["Garland", "Michael", ""], ["Gopalakrishnan", "Ganesh", ""]]}, {"id": "1911.02502", "submitter": "Junming Yang", "authors": "Junming Yang, Yaoqi Li, Xuanyu Chen, Jiahang Cao and Kangkang Jiang", "title": "Deep Learning for Stock Selection Based on High Frequency Price-Volume\n  Data", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "q-fin.CP cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Training a practical and effective model for stock selection has been a\ngreatly concerned problem in the field of artificial intelligence. Even though\nsome of the models from previous works have achieved good performance in the\nU.S. market by using low-frequency data and features, training a suitable model\nwith high-frequency stock data is still a problem worth exploring. Based on the\nhigh-frequency price data of the past several days, we construct two separate\nmodels-Convolution Neural Network and Long Short-Term Memory-which can predict\nthe expected return rate of stocks on the current day, and select the stocks\nwith the highest expected yield at the opening to maximize the total return. In\nour CNN model, we propose improvements on the CNNpred model presented by E.\nHoseinzade and S. Haratizadeh in their paper which deals with low-frequency\nfeatures. Such improvements enable our CNN model to exploit the convolution\nlayer's ability to extract high-level factors and avoid excessive loss of\noriginal information at the same time. Our LSTM model utilizes Recurrent Neural\nNetwork'advantages in handling time series data. Despite considerable\ntransaction fees due to the daily changes of our stock position, annualized net\nrate of return is 62.27% for our CNN model, and 50.31% for our LSTM model.\n", "versions": [{"version": "v1", "created": "Wed, 6 Nov 2019 17:25:53 GMT"}], "update_date": "2019-11-07", "authors_parsed": [["Yang", "Junming", ""], ["Li", "Yaoqi", ""], ["Chen", "Xuanyu", ""], ["Cao", "Jiahang", ""], ["Jiang", "Kangkang", ""]]}, {"id": "1911.02508", "submitter": "Dylan Slack", "authors": "Dylan Slack, Sophie Hilgard, Emily Jia, Sameer Singh, Himabindu\n  Lakkaraju", "title": "Fooling LIME and SHAP: Adversarial Attacks on Post hoc Explanation\n  Methods", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  As machine learning black boxes are increasingly being deployed in domains\nsuch as healthcare and criminal justice, there is growing emphasis on building\ntools and techniques for explaining these black boxes in an interpretable\nmanner. Such explanations are being leveraged by domain experts to diagnose\nsystematic errors and underlying biases of black boxes. In this paper, we\ndemonstrate that post hoc explanations techniques that rely on input\nperturbations, such as LIME and SHAP, are not reliable. Specifically, we\npropose a novel scaffolding technique that effectively hides the biases of any\ngiven classifier by allowing an adversarial entity to craft an arbitrary\ndesired explanation. Our approach can be used to scaffold any biased classifier\nin such a way that its predictions on the input data distribution still remain\nbiased, but the post hoc explanations of the scaffolded classifier look\ninnocuous. Using extensive evaluation with multiple real-world datasets\n(including COMPAS), we demonstrate how extremely biased (racist) classifiers\ncrafted by our framework can easily fool popular explanation techniques such as\nLIME and SHAP into generating innocuous explanations which do not reflect the\nunderlying biases.\n", "versions": [{"version": "v1", "created": "Wed, 6 Nov 2019 17:52:20 GMT"}, {"version": "v2", "created": "Mon, 3 Feb 2020 18:53:50 GMT"}], "update_date": "2020-02-04", "authors_parsed": [["Slack", "Dylan", ""], ["Hilgard", "Sophie", ""], ["Jia", "Emily", ""], ["Singh", "Sameer", ""], ["Lakkaraju", "Himabindu", ""]]}, {"id": "1911.02516", "submitter": "Alessandro Rigazzi", "authors": "Alessandro Rigazzi", "title": "DC-S3GD: Delay-Compensated Stale-Synchronous SGD for Large-Scale\n  Decentralized Neural Network Training", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.DC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Data parallelism has become the de facto standard for training Deep Neural\nNetwork on multiple processing units. In this work we propose DC-S3GD, a\ndecentralized (without Parameter Server) stale-synchronous version of the\nDelay-Compensated Asynchronous Stochastic Gradient Descent (DC-ASGD) algorithm.\nIn our approach, we allow for the overlap of computation and communication, and\ncompensate the inherent error with a first-order correction of the gradients.\nWe prove the effectiveness of our approach by training Convolutional Neural\nNetwork with large batches and achieving state-of-the-art results.\n", "versions": [{"version": "v1", "created": "Wed, 6 Nov 2019 17:54:56 GMT"}], "update_date": "2019-11-07", "authors_parsed": [["Rigazzi", "Alessandro", ""]]}, {"id": "1911.02521", "submitter": "Hyunseok  Seo", "authors": "Hyunseok Seo, Masoud Badiei Khuzani, Varun Vasudevan, Charles Huang,\n  Hongyi Ren, Ruoxiu Xiao, Xiao Jia, Lei Xing", "title": "Machine Learning Techniques for Biomedical Image Segmentation: An\n  Overview of Technical Aspects and Introduction to State-of-Art Applications", "comments": "Accept for publication at Medical Physics", "journal-ref": null, "doi": "10.1002/mp.13649", "report-no": null, "categories": "eess.IV cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In recent years, significant progress has been made in developing more\naccurate and efficient machine learning algorithms for segmentation of medical\nand natural images. In this review article, we highlight the imperative role of\nmachine learning algorithms in enabling efficient and accurate segmentation in\nthe field of medical imaging. We specifically focus on several key studies\npertaining to the application of machine learning methods to biomedical image\nsegmentation. We review classical machine learning algorithms such as Markov\nrandom fields, k-means clustering, random forest, etc. Although such classical\nlearning models are often less accurate compared to the deep learning\ntechniques, they are often more sample efficient and have a less complex\nstructure. We also review different deep learning architectures, such as the\nartificial neural networks (ANNs), the convolutional neural networks (CNNs),\nand the recurrent neural networks (RNNs), and present the segmentation results\nattained by those learning models that were published in the past three years.\nWe highlight the successes and limitations of each machine learning paradigm.\nIn addition, we discuss several challenges related to the training of different\nmachine learning models, and we present some heuristics to address those\nchallenges.\n", "versions": [{"version": "v1", "created": "Wed, 6 Nov 2019 17:59:39 GMT"}], "update_date": "2019-11-07", "authors_parsed": [["Seo", "Hyunseok", ""], ["Khuzani", "Masoud Badiei", ""], ["Vasudevan", "Varun", ""], ["Huang", "Charles", ""], ["Ren", "Hongyi", ""], ["Xiao", "Ruoxiu", ""], ["Jia", "Xiao", ""], ["Xing", "Lei", ""]]}, {"id": "1911.02522", "submitter": "Jiayi Liu", "authors": "Jiayi Liu, Samarth Tripathi, Unmesh Kurup, Mohak Shah", "title": "Auptimizer -- an Extensible, Open-Source Framework for Hyperparameter\n  Tuning", "comments": "Accepted at IEEE Big Data 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Tuning machine learning models at scale, especially finding the right\nhyperparameter values, can be difficult and time-consuming. In addition to the\ncomputational effort required, this process also requires some ancillary\nefforts including engineering tasks (e.g., job scheduling) as well as more\nmundane tasks (e.g., keeping track of the various parameters and associated\nresults). We present Auptimizer, a general Hyperparameter Optimization (HPO)\nframework to help data scientists speed up model tuning and bookkeeping. With\nAuptimizer, users can use all available computing resources in distributed\nsettings for model training. The user-friendly system design simplifies\ncreating, controlling, and tracking of a typical machine learning project. The\ndesign also allows researchers to integrate new HPO algorithms. To demonstrate\nits flexibility, we show how Auptimizer integrates a few major HPO techniques\n(from random search to neural architecture search). The code is available at\nhttps://github.com/LGE-ARC-AdvancedAI/auptimizer.\n", "versions": [{"version": "v1", "created": "Wed, 6 Nov 2019 18:00:31 GMT"}], "update_date": "2019-11-07", "authors_parsed": [["Liu", "Jiayi", ""], ["Tripathi", "Samarth", ""], ["Kurup", "Unmesh", ""], ["Shah", "Mohak", ""]]}, {"id": "1911.02536", "submitter": "David Alvarez-Melis", "authors": "David Alvarez-Melis, Youssef Mroueh, Tommi S. Jaakkola", "title": "Unsupervised Hierarchy Matching with Optimal Transport over Hyperbolic\n  Spaces", "comments": "AISTATS 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper focuses on the problem of unsupervised alignment of hierarchical\ndata such as ontologies or lexical databases. This is a problem that appears\nacross areas, from natural language processing to bioinformatics, and is\ntypically solved by appeal to outside knowledge bases and label-textual\nsimilarity. In contrast, we approach the problem from a purely geometric\nperspective: given only a vector-space representation of the items in the two\nhierarchies, we seek to infer correspondences across them. Our work derives\nfrom and interweaves hyperbolic-space representations for hierarchical data, on\none hand, and unsupervised word-alignment methods, on the other. We first\nprovide a set of negative results showing how and why Euclidean methods fail in\nthis hyperbolic setting. We then propose a novel approach based on optimal\ntransport over hyperbolic spaces, and show that it outperforms standard\nembedding alignment techniques in various experiments on cross-lingual WordNet\nalignment and ontology matching tasks.\n", "versions": [{"version": "v1", "created": "Wed, 6 Nov 2019 18:20:35 GMT"}, {"version": "v2", "created": "Fri, 8 May 2020 01:52:26 GMT"}], "update_date": "2020-05-11", "authors_parsed": [["Alvarez-Melis", "David", ""], ["Mroueh", "Youssef", ""], ["Jaakkola", "Tommi S.", ""]]}, {"id": "1911.02549", "submitter": "Cody Coleman", "authors": "Vijay Janapa Reddi, Christine Cheng, David Kanter, Peter Mattson,\n  Guenther Schmuelling, Carole-Jean Wu, Brian Anderson, Maximilien Breughe,\n  Mark Charlebois, William Chou, Ramesh Chukka, Cody Coleman, Sam Davis, Pan\n  Deng, Greg Diamos, Jared Duke, Dave Fick, J. Scott Gardner, Itay Hubara,\n  Sachin Idgunji, Thomas B. Jablin, Jeff Jiao, Tom St. John, Pankaj Kanwar,\n  David Lee, Jeffery Liao, Anton Lokhmotov, Francisco Massa, Peng Meng, Paulius\n  Micikevicius, Colin Osborne, Gennady Pekhimenko, Arun Tejusve Raghunath\n  Rajan, Dilip Sequeira, Ashish Sirasao, Fei Sun, Hanlin Tang, Michael Thomson,\n  Frank Wei, Ephrem Wu, Lingjie Xu, Koichi Yamada, Bing Yu, George Yuan, Aaron\n  Zhong, Peizhao Zhang, Yuchen Zhou", "title": "MLPerf Inference Benchmark", "comments": "ISCA 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.PF stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Machine-learning (ML) hardware and software system demand is burgeoning.\nDriven by ML applications, the number of different ML inference systems has\nexploded. Over 100 organizations are building ML inference chips, and the\nsystems that incorporate existing models span at least three orders of\nmagnitude in power consumption and five orders of magnitude in performance;\nthey range from embedded devices to data-center solutions. Fueling the hardware\nare a dozen or more software frameworks and libraries. The myriad combinations\nof ML hardware and ML software make assessing ML-system performance in an\narchitecture-neutral, representative, and reproducible manner challenging.\nThere is a clear need for industry-wide standard ML benchmarking and evaluation\ncriteria. MLPerf Inference answers that call. In this paper, we present our\nbenchmarking method for evaluating ML inference systems. Driven by more than 30\norganizations as well as more than 200 ML engineers and practitioners, MLPerf\nprescribes a set of rules and best practices to ensure comparability across\nsystems with wildly differing architectures. The first call for submissions\ngarnered more than 600 reproducible inference-performance measurements from 14\norganizations, representing over 30 systems that showcase a wide range of\ncapabilities. The submissions attest to the benchmark's flexibility and\nadaptability.\n", "versions": [{"version": "v1", "created": "Wed, 6 Nov 2019 18:43:10 GMT"}, {"version": "v2", "created": "Sat, 9 May 2020 23:40:20 GMT"}], "update_date": "2020-05-12", "authors_parsed": [["Reddi", "Vijay Janapa", ""], ["Cheng", "Christine", ""], ["Kanter", "David", ""], ["Mattson", "Peter", ""], ["Schmuelling", "Guenther", ""], ["Wu", "Carole-Jean", ""], ["Anderson", "Brian", ""], ["Breughe", "Maximilien", ""], ["Charlebois", "Mark", ""], ["Chou", "William", ""], ["Chukka", "Ramesh", ""], ["Coleman", "Cody", ""], ["Davis", "Sam", ""], ["Deng", "Pan", ""], ["Diamos", "Greg", ""], ["Duke", "Jared", ""], ["Fick", "Dave", ""], ["Gardner", "J. Scott", ""], ["Hubara", "Itay", ""], ["Idgunji", "Sachin", ""], ["Jablin", "Thomas B.", ""], ["Jiao", "Jeff", ""], ["John", "Tom St.", ""], ["Kanwar", "Pankaj", ""], ["Lee", "David", ""], ["Liao", "Jeffery", ""], ["Lokhmotov", "Anton", ""], ["Massa", "Francisco", ""], ["Meng", "Peng", ""], ["Micikevicius", "Paulius", ""], ["Osborne", "Colin", ""], ["Pekhimenko", "Gennady", ""], ["Rajan", "Arun Tejusve Raghunath", ""], ["Sequeira", "Dilip", ""], ["Sirasao", "Ashish", ""], ["Sun", "Fei", ""], ["Tang", "Hanlin", ""], ["Thomson", "Michael", ""], ["Wei", "Frank", ""], ["Wu", "Ephrem", ""], ["Xu", "Lingjie", ""], ["Yamada", "Koichi", ""], ["Yu", "Bing", ""], ["Yuan", "George", ""], ["Zhong", "Aaron", ""], ["Zhang", "Peizhao", ""], ["Zhou", "Yuchen", ""]]}, {"id": "1911.02557", "submitter": "Pragaash Ponnusamy", "authors": "Pragaash Ponnusamy, Alireza Roshan Ghias, Chenlei Guo, Ruhi Sarikaya", "title": "Feedback-Based Self-Learning in Large-Scale Conversational AI Agents", "comments": "8 pages, 2 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Today, most large-scale conversational AI agents (e.g. Alexa, Siri, or Google\nAssistant) are built using manually annotated data to train the different\ncomponents of the system. Typically, the accuracy of the ML models in these\ncomponents are improved by manually transcribing and annotating data. As the\nscope of these systems increase to cover more scenarios and domains, manual\nannotation to improve the accuracy of these components becomes prohibitively\ncostly and time consuming. In this paper, we propose a system that leverages\nuser-system interaction feedback signals to automate learning without any\nmanual annotation. Users here tend to modify a previous query in hopes of\nfixing an error in the previous turn to get the right results. These\nreformulations, which are often preceded by defective experiences caused by\nerrors in ASR, NLU, ER or the application. In some cases, users may not\nproperly formulate their requests (e.g. providing partial title of a song), but\ngleaning across a wider pool of users and sessions reveals the underlying\nrecurrent patterns. Our proposed self-learning system automatically detects the\nerrors, generate reformulations and deploys fixes to the runtime system to\ncorrect different types of errors occurring in different components of the\nsystem. In particular, we propose leveraging an absorbing Markov Chain model as\na collaborative filtering mechanism in a novel attempt to mine these patterns.\nWe show that our approach is highly scalable, and able to learn reformulations\nthat reduce Alexa-user errors by pooling anonymized data across millions of\ncustomers. The proposed self-learning system achieves a win/loss ratio of 11.8\nand effectively reduces the defect rate by more than 30% on utterance level\nreformulations in our production A/B tests. To the best of our knowledge, this\nis the first self-learning large-scale conversational AI system in production.\n", "versions": [{"version": "v1", "created": "Wed, 6 Nov 2019 18:55:42 GMT"}], "update_date": "2019-11-07", "authors_parsed": [["Ponnusamy", "Pragaash", ""], ["Ghias", "Alireza Roshan", ""], ["Guo", "Chenlei", ""], ["Sarikaya", "Ruhi", ""]]}, {"id": "1911.02559", "submitter": "Zhiqiang Shen", "authors": "Zhiqiang Shen and Harsh Maheshwari and Weichen Yao and Marios Savvides", "title": "SCL: Towards Accurate Domain Adaptive Object Detection via Gradient\n  Detach Based Stacked Complementary Losses", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Unsupervised domain adaptive object detection aims to learn a robust detector\nin the domain shift circumstance, where the training (source) domain is\nlabel-rich with bounding box annotations, while the testing (target) domain is\nlabel-agnostic and the feature distributions between training and testing\ndomains are dissimilar or even totally different. In this paper, we propose a\ngradient detach based stacked complementary losses (SCL) method that uses\ndetection losses as the primary objective, and cuts in several auxiliary losses\nin different network stages accompanying with gradient detach training to learn\nmore discriminative representations. We argue that the prior methods mainly\nleverage more loss functions for training but ignore the interaction of\ndifferent losses and also the compatible training strategy (gradient detach\nupdating in our work). Thus, our proposed method is a more syncretic adaptation\nlearning process. We conduct comprehensive experiments on seven datasets, the\nresults demonstrate that our method performs favorably better than the\nstate-of-the-art methods by a significant margin. For instance, from Cityscapes\nto FoggyCityscapes, we achieve 37.9% mAP, outperforming the previous art\nStrong-Weak by 3.6%.\n", "versions": [{"version": "v1", "created": "Wed, 6 Nov 2019 18:59:01 GMT"}, {"version": "v2", "created": "Mon, 11 Nov 2019 18:21:36 GMT"}, {"version": "v3", "created": "Thu, 21 Nov 2019 05:43:14 GMT"}], "update_date": "2019-11-22", "authors_parsed": [["Shen", "Zhiqiang", ""], ["Maheshwari", "Harsh", ""], ["Yao", "Weichen", ""], ["Savvides", "Marios", ""]]}, {"id": "1911.02590", "submitter": "Jonathan Lorraine", "authors": "Jonathan Lorraine, Paul Vicol, David Duvenaud", "title": "Optimizing Millions of Hyperparameters by Implicit Differentiation", "comments": "Submitted to AISTATS 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose an algorithm for inexpensive gradient-based hyperparameter\noptimization that combines the implicit function theorem (IFT) with efficient\ninverse Hessian approximations. We present results about the relationship\nbetween the IFT and differentiating through optimization, motivating our\nalgorithm. We use the proposed approach to train modern network architectures\nwith millions of weights and millions of hyper-parameters. For example, we\nlearn a data-augmentation network - where every weight is a hyperparameter\ntuned for validation performance - outputting augmented training examples.\nJointly tuning weights and hyperparameters with our approach is only a few\ntimes more costly in memory and compute than standard training.\n", "versions": [{"version": "v1", "created": "Wed, 6 Nov 2019 19:04:16 GMT"}], "update_date": "2019-11-11", "authors_parsed": [["Lorraine", "Jonathan", ""], ["Vicol", "Paul", ""], ["Duvenaud", "David", ""]]}, {"id": "1911.02613", "submitter": "Ruochi Zhang", "authors": "Ruochi Zhang, Yuesong Zou, Jian Ma", "title": "Hyper-SAGNN: a self-attention based graph neural network for hypergraphs", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Graph representation learning for hypergraphs can be used to extract patterns\namong higher-order interactions that are critically important in many real\nworld problems. Current approaches designed for hypergraphs, however, are\nunable to handle different types of hypergraphs and are typically not generic\nfor various learning tasks. Indeed, models that can predict variable-sized\nheterogeneous hyperedges have not been available. Here we develop a new\nself-attention based graph neural network called Hyper-SAGNN applicable to\nhomogeneous and heterogeneous hypergraphs with variable hyperedge sizes. We\nperform extensive evaluations on multiple datasets, including four benchmark\nnetwork datasets and two single-cell Hi-C datasets in genomics. We demonstrate\nthat Hyper-SAGNN significantly outperforms the state-of-the-art methods on\ntraditional tasks while also achieving great performance on a new task called\noutsider identification. Hyper-SAGNN will be useful for graph representation\nlearning to uncover complex higher-order interactions in different\napplications.\n", "versions": [{"version": "v1", "created": "Wed, 6 Nov 2019 20:10:24 GMT"}], "update_date": "2019-11-11", "authors_parsed": [["Zhang", "Ruochi", ""], ["Zou", "Yuesong", ""], ["Ma", "Jian", ""]]}, {"id": "1911.02617", "submitter": "Yue Wu", "authors": "Yue Wu, Leman Akoglu, Ian Davidson", "title": "Coverage-based Outlier Explanation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Outlier detection is a core task in data mining with a plethora of algorithms\nthat have enjoyed wide scale usage. Existing algorithms are primarily focused\non detection, that is the identification of outliers in a given dataset. In\nthis paper we explore the relatively under-studied problem of the outlier\nexplanation problem. Our goal is, given a dataset that is already divided into\noutliers and normal instances, explain what characterizes the outliers. We\nexplore the novel direction of a semantic explanation that a domain expert or\npolicy maker is able to understand. We formulate this as an optimization\nproblem to find explanations that are both interpretable and pure. Through\nexperiments on real-world data sets, we quantitatively show that our method can\nefficiently generate better explanations compared with rule-based learners.\n", "versions": [{"version": "v1", "created": "Wed, 6 Nov 2019 20:19:00 GMT"}], "update_date": "2019-11-11", "authors_parsed": [["Wu", "Yue", ""], ["Akoglu", "Leman", ""], ["Davidson", "Ian", ""]]}, {"id": "1911.02621", "submitter": "Olakunle Ibitoye", "authors": "Olakunle Ibitoye, Rana Abou-Khamis, Ashraf Matrawy and M. Omair Shafiq", "title": "The Threat of Adversarial Attacks on Machine Learning in Network\n  Security -- A Survey", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.LG cs.NI", "license": "http://creativecommons.org/publicdomain/zero/1.0/", "abstract": "  Machine learning models have made many decision support systems to be faster,\nmore accurate and more efficient. However, applications of machine learning in\nnetwork security face more disproportionate threat of active adversarial\nattacks compared to other domains. This is because machine learning\napplications in network security such as malware detection, intrusion\ndetection, and spam filtering are by themselves adversarial in nature. In what\ncould be considered an arms race between attackers and defenders, adversaries\nconstantly probe machine learning systems with inputs which are explicitly\ndesigned to bypass the system and induce a wrong prediction. In this survey, we\nfirst provide a taxonomy of machine learning techniques, styles, and\nalgorithms. We then introduce a classification of machine learning in network\nsecurity applications. Next, we examine various adversarial attacks against\nmachine learning in network security and introduce two classification\napproaches for adversarial attacks in network security. First, we classify\nadversarial attacks in network security based on a taxonomy of network security\napplications. Secondly, we categorize adversarial attacks in network security\ninto a problem space vs. feature space dimensional classification model. We\nthen analyze the various defenses against adversarial attacks on machine\nlearning-based network security applications. We conclude by introducing an\nadversarial risk model and evaluate several existing adversarial attacks\nagainst machine learning in network security using the risk model. We also\nidentify where each attack classification resides within the adversarial risk\nmodel\n", "versions": [{"version": "v1", "created": "Wed, 6 Nov 2019 20:29:56 GMT"}, {"version": "v2", "created": "Sun, 4 Oct 2020 10:29:05 GMT"}], "update_date": "2020-10-06", "authors_parsed": [["Ibitoye", "Olakunle", ""], ["Abou-Khamis", "Rana", ""], ["Matrawy", "Ashraf", ""], ["Shafiq", "M. Omair", ""]]}, {"id": "1911.02623", "submitter": "Soumi Das", "authors": "Soumi Das, Rajath Nandan Kalava, Kolli Kiran Kumar, Akhil Kandregula,\n  Kalpam Suhaas, Sourangshu Bhattacharya, Niloy Ganguly", "title": "Map Enhanced Route Travel Time Prediction using Deep Neural Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Travel time estimation is a fundamental problem in transportation science\nwith extensive literature. The study of these techniques has intensified due to\navailability of many publicly available large trip datasets. Recently developed\ndeep learning based models have improved the generality and performance and\nhave focused on estimating times for individual sub-trajectories and\naggregating them to predict the travel time of the entire trajectory. However,\nthese techniques ignore the road network information. In this work, we propose\nand study techniques for incorporating road networks along with historical\ntrips' data into travel time prediction. We incorporate both node embeddings as\nwell as road distance into the existing model. Experiments on large real-world\nbenchmark datasets suggest improved performance, especially when the train data\nis small. As expected, the proposed method performs better than the baseline\nwhen there is a larger difference between road distance and Vincenty distance\nbetween start and end points.\n", "versions": [{"version": "v1", "created": "Wed, 6 Nov 2019 20:52:02 GMT"}], "update_date": "2019-11-11", "authors_parsed": [["Das", "Soumi", ""], ["Kalava", "Rajath Nandan", ""], ["Kumar", "Kolli Kiran", ""], ["Kandregula", "Akhil", ""], ["Suhaas", "Kalpam", ""], ["Bhattacharya", "Sourangshu", ""], ["Ganguly", "Niloy", ""]]}, {"id": "1911.02624", "submitter": "Nathana\\\"el Fijalkow", "authors": "Judith Clymo, Haik Manukian, Nathana\\\"el Fijalkow, Adri\\`a Gasc\\'on,\n  Brooks Paige", "title": "Data Generation for Neural Programming by Example", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.NE cs.PL stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Programming by example is the problem of synthesizing a program from a small\nset of input / output pairs. Recent works applying machine learning methods to\nthis task show promise, but are typically reliant on generating synthetic\nexamples for training. A particular challenge lies in generating meaningful\nsets of inputs and outputs, which well-characterize a given program and\naccurately demonstrate its behavior. Where examples used for testing are\ngenerated by the same method as training data then the performance of a model\nmay be partly reliant on this similarity. In this paper we introduce a novel\napproach using an SMT solver to synthesize inputs which cover a diverse set of\nbehaviors for a given program. We carry out a case study comparing this method\nto existing synthetic data generation procedures in the literature, and find\nthat data generated using our approach improves both the discriminatory power\nof example sets and the ability of trained machine learning models to\ngeneralize to unfamiliar data.\n", "versions": [{"version": "v1", "created": "Wed, 6 Nov 2019 20:57:03 GMT"}], "update_date": "2019-11-11", "authors_parsed": [["Clymo", "Judith", ""], ["Manukian", "Haik", ""], ["Fijalkow", "Nathana\u00ebl", ""], ["Gasc\u00f3n", "Adri\u00e0", ""], ["Paige", "Brooks", ""]]}, {"id": "1911.02639", "submitter": "Kian Kenyon-Dean", "authors": "Kian Kenyon-Dean", "title": "Word Embedding Algorithms as Generalized Low Rank Models and their\n  Canonical Form", "comments": "82 pages; McGill University master's thesis, 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Word embedding algorithms produce very reliable feature representations of\nwords that are used by neural network models across a constantly growing\nmultitude of NLP tasks. As such, it is imperative for NLP practitioners to\nunderstand how their word representations are produced, and why they are so\nimpactful.\n  The present work presents the Simple Embedder framework, generalizing the\nstate-of-the-art existing word embedding algorithms (including Word2vec (SGNS)\nand GloVe) under the umbrella of generalized low rank models. We derive that\nboth of these algorithms attempt to produce embedding inner products that\napproximate pointwise mutual information (PMI) statistics in the corpus. Once\ncast as Simple Embedders, comparison of these models reveals that these\nsuccessful embedders all resemble a straightforward maximum likelihood estimate\n(MLE) of the PMI parametrized by the inner product (between embeddings). This\nMLE induces our proposed novel word embedding model, Hilbert-MLE, as the\ncanonical representative of the Simple Embedder framework.\n  We empirically compare these algorithms with evaluations on 17 different\ndatasets. Hilbert-MLE consistently observes second-best performance on every\nextrinsic evaluation (news classification, sentiment analysis, POS-tagging, and\nsupersense tagging), while the first-best model depends varying on the task.\nMoreover, Hilbert-MLE consistently observes the least variance in results with\nrespect to the random initialization of the weights in bidirectional LSTMs. Our\nempirical results demonstrate that Hilbert-MLE is a very consistent word\nembedding algorithm that can be reliably integrated into existing NLP systems\nto obtain high-quality results.\n", "versions": [{"version": "v1", "created": "Wed, 6 Nov 2019 21:40:34 GMT"}], "update_date": "2019-11-11", "authors_parsed": [["Kenyon-Dean", "Kian", ""]]}, {"id": "1911.02645", "submitter": "Yadollah Yaghoobzadeh", "authors": "Alexandre Rochette, Yadollah Yaghoobzadeh, Timothy J. Hazen", "title": "Unsupervised Domain Adaptation of Contextual Embeddings for Low-Resource\n  Duplicate Question Detection", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Answering questions is a primary goal of many conversational systems or\nsearch products. While most current systems have focused on answering questions\nagainst structured databases or curated knowledge graphs, on-line community\nforums or frequently asked questions (FAQ) lists offer an alternative source of\ninformation for question answering systems. Automatic duplicate question\ndetection (DQD) is the key technology need for question answering systems to\nutilize existing online forums like StackExchange. Existing annotations of\nduplicate questions in such forums are community-driven, making them sparse or\neven completely missing for many domains. Therefore, it is important to\ntransfer knowledge from related domains and tasks. Recently, contextual\nembedding models such as BERT have been outperforming many baselines by\ntransferring self-supervised information to downstream tasks. In this paper, we\napply BERT to DQD and advance it by unsupervised adaptation to StackExchange\ndomains using self-supervised learning. We show the effectiveness of this\nadaptation for low-resource settings, where little or no training data is\navailable from the target domain. Our analysis reveals that unsupervised BERT\ndomain adaptation on even small amounts of data boosts the performance of BERT.\n", "versions": [{"version": "v1", "created": "Wed, 6 Nov 2019 22:01:18 GMT"}], "update_date": "2019-11-11", "authors_parsed": [["Rochette", "Alexandre", ""], ["Yaghoobzadeh", "Yadollah", ""], ["Hazen", "Timothy J.", ""]]}, {"id": "1911.02656", "submitter": "Karthik Bharath", "authors": "Rachel Carrington, Karthik Bharath and Simon Preston", "title": "Invariance and identifiability issues for word embeddings", "comments": "NIPS 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.CL cs.LG stat.CO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Word embeddings are commonly obtained as optimizers of a criterion function\n$f$ of a text corpus, but assessed on word-task performance using a different\nevaluation function $g$ of the test data. We contend that a possible source of\ndisparity in performance on tasks is the incompatibility between classes of\ntransformations that leave $f$ and $g$ invariant. In particular, word\nembeddings defined by $f$ are not unique; they are defined only up to a class\nof transformations to which $f$ is invariant, and this class is larger than the\nclass to which $g$ is invariant. One implication of this is that the apparent\nsuperiority of one word embedding over another, as measured by word task\nperformance, may largely be a consequence of the arbitrary elements selected\nfrom the respective solution sets. We provide a formal treatment of the above\nidentifiability issue, present some numerical examples, and discuss possible\nresolutions.\n", "versions": [{"version": "v1", "created": "Wed, 6 Nov 2019 22:41:04 GMT"}], "update_date": "2019-11-11", "authors_parsed": [["Carrington", "Rachel", ""], ["Bharath", "Karthik", ""], ["Preston", "Simon", ""]]}, {"id": "1911.02660", "submitter": "Weilin Fu", "authors": "Weilin Fu and Katharina Breininger and Zhaoya Pan and Andreas Maier", "title": "What Do We Really Need? Degenerating U-Net on Retinal Vessel\n  Segmentation", "comments": "7 pages, 2 figures, submitted in BVM 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.IV cs.CV cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Retinal vessel segmentation is an essential step for fundus image analysis.\nWith the recent advances of deep learning technologies, many convolutional\nneural networks have been applied in this field, including the successful\nU-Net. In this work, we firstly modify the U-Net with functional blocks aiming\nto pursue higher performance. The absence of the expected performance boost\nthen lead us to dig into the opposite direction of shrinking the U-Net and\nexploring the extreme conditions such that its segmentation performance is\nmaintained. Experiment series to simplify the network structure, reduce the\nnetwork size and restrict the training conditions are designed. Results show\nthat for retinal vessel segmentation on DRIVE database, U-Net does not\ndegenerate until surprisingly acute conditions: one level, one filter in\nconvolutional layers, and one training sample. This experimental discovery is\nboth counter-intuitive and worthwhile. Not only are the extremes of the U-Net\nexplored on a well-studied application, but also one intriguing warning is\nraised for the research methodology which seeks for marginal performance\nenhancement regardless of the resource cost.\n", "versions": [{"version": "v1", "created": "Wed, 6 Nov 2019 22:49:55 GMT"}], "update_date": "2019-11-11", "authors_parsed": [["Fu", "Weilin", ""], ["Breininger", "Katharina", ""], ["Pan", "Zhaoya", ""], ["Maier", "Andreas", ""]]}, {"id": "1911.02673", "submitter": "Emily Aiken", "authors": "Emily L. Aiken, Andre T. Nguyen, Mauricio Santillana", "title": "Towards the Use of Neural Networks for Influenza Prediction at Multiple\n  Spatial Resolutions", "comments": "Machine Learning for Health (ML4H) at NeurIPS 2019 - Extended\n  Abstract; Added Footer", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CY stat.AP stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce the use of a Gated Recurrent Unit (GRU) for influenza prediction\nat the state- and city-level in the US, and experiment with the inclusion of\nreal-time flu-related Internet search data. We find that a GRU has lower\nprediction error than current state-of-the-art methods for data-driven\ninfluenza prediction at time horizons of over two weeks. In contrast with other\nmachine learning approaches, the inclusion of real-time Internet search data\ndoes not improve GRU predictions.\n", "versions": [{"version": "v1", "created": "Wed, 6 Nov 2019 23:14:53 GMT"}, {"version": "v2", "created": "Wed, 13 Nov 2019 05:10:27 GMT"}], "update_date": "2019-11-14", "authors_parsed": [["Aiken", "Emily L.", ""], ["Nguyen", "Andre T.", ""], ["Santillana", "Mauricio", ""]]}, {"id": "1911.02681", "submitter": "Anbang Wu", "authors": "Anbang Wu, Shuangxi Chen, Chunming Wu", "title": "Generalized Transformation-based Gradient", "comments": "There is some errors in the proof to the conclusion, therefore\n  leading to untrusted conclusion, so I want to withdraw this paper", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG math.OC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The reparameterization trick has become one of the most useful tools in the\nfield of variational inference. However, the reparameterization trick is based\non the standardization transformation which restricts the scope of application\nof this method to distributions that have tractable inverse cumulative\ndistribution functions or are expressible as deterministic transformations of\nsuch distributions. In this paper, we generalized the reparameterization trick\nby allowing a general transformation. We discover that the proposed model is a\nspecial case of control variate indicating that the proposed model can combine\nthe advantages of CV and generalized reparameterization.\n", "versions": [{"version": "v1", "created": "Wed, 6 Nov 2019 23:40:12 GMT"}, {"version": "v2", "created": "Sat, 15 Feb 2020 01:30:21 GMT"}, {"version": "v3", "created": "Tue, 25 Feb 2020 10:38:09 GMT"}], "update_date": "2020-02-26", "authors_parsed": [["Wu", "Anbang", ""], ["Chen", "Shuangxi", ""], ["Wu", "Chunming", ""]]}, {"id": "1911.02682", "submitter": "Arka Daw", "authors": "Arka Daw, R. Quinn Thomas, Cayelan C. Carey, Jordan S. Read, Alison P.\n  Appling, Anuj Karpatne", "title": "Physics-Guided Architecture (PGA) of Neural Networks for Quantifying\n  Uncertainty in Lake Temperature Modeling", "comments": "11 pages, 15 figures, 2 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG physics.comp-ph stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  To simultaneously address the rising need of expressing uncertainties in deep\nlearning models along with producing model outputs which are consistent with\nthe known scientific knowledge, we propose a novel physics-guided architecture\n(PGA) of neural networks in the context of lake temperature modeling where the\nphysical constraints are hard coded in the neural network architecture. This\nallows us to integrate such models with state of the art uncertainty estimation\napproaches such as Monte Carlo (MC) Dropout without sacrificing the physical\nconsistency of our results. We demonstrate the effectiveness of our approach in\nensuring better generalizability as well as physical consistency in MC\nestimates over data collected from Lake Mendota in Wisconsin and Falling Creek\nReservoir in Virginia, even with limited training data. We further show that\nour MC estimates correctly match the distribution of ground-truth observations,\nthus making the PGA paradigm amenable to physically grounded uncertainty\nquantification.\n", "versions": [{"version": "v1", "created": "Wed, 6 Nov 2019 23:47:14 GMT"}], "update_date": "2019-11-11", "authors_parsed": [["Daw", "Arka", ""], ["Thomas", "R. Quinn", ""], ["Carey", "Cayelan C.", ""], ["Read", "Jordan S.", ""], ["Appling", "Alison P.", ""], ["Karpatne", "Anuj", ""]]}, {"id": "1911.02685", "submitter": "Fuzhen Zhuang", "authors": "Fuzhen Zhuang, Zhiyuan Qi, Keyu Duan, Dongbo Xi, Yongchun Zhu, Hengshu\n  Zhu, Hui Xiong, Qing He", "title": "A Comprehensive Survey on Transfer Learning", "comments": "31 pages, 7 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Transfer learning aims at improving the performance of target learners on\ntarget domains by transferring the knowledge contained in different but related\nsource domains. In this way, the dependence on a large number of target domain\ndata can be reduced for constructing target learners. Due to the wide\napplication prospects, transfer learning has become a popular and promising\narea in machine learning. Although there are already some valuable and\nimpressive surveys on transfer learning, these surveys introduce approaches in\na relatively isolated way and lack the recent advances in transfer learning.\nDue to the rapid expansion of the transfer learning area, it is both necessary\nand challenging to comprehensively review the relevant studies. This survey\nattempts to connect and systematize the existing transfer learning researches,\nas well as to summarize and interpret the mechanisms and the strategies of\ntransfer learning in a comprehensive way, which may help readers have a better\nunderstanding of the current research status and ideas. Unlike previous\nsurveys, this survey paper reviews more than forty representative transfer\nlearning approaches, especially homogeneous transfer learning approaches, from\nthe perspectives of data and model. The applications of transfer learning are\nalso briefly introduced. In order to show the performance of different transfer\nlearning models, over twenty representative transfer learning models are used\nfor experiments. The models are performed on three different datasets, i.e.,\nAmazon Reviews, Reuters-21578, and Office-31. And the experimental results\ndemonstrate the importance of selecting appropriate transfer learning models\nfor different applications in practice.\n", "versions": [{"version": "v1", "created": "Thu, 7 Nov 2019 00:15:02 GMT"}, {"version": "v2", "created": "Tue, 17 Dec 2019 02:20:48 GMT"}, {"version": "v3", "created": "Tue, 23 Jun 2020 15:52:46 GMT"}], "update_date": "2020-06-24", "authors_parsed": [["Zhuang", "Fuzhen", ""], ["Qi", "Zhiyuan", ""], ["Duan", "Keyu", ""], ["Xi", "Dongbo", ""], ["Zhu", "Yongchun", ""], ["Zhu", "Hengshu", ""], ["Xiong", "Hui", ""], ["He", "Qing", ""]]}, {"id": "1911.02692", "submitter": "Haoming Jiang", "authors": "Haoming Jiang, Chen Liang, Chong Wang, Tuo Zhao", "title": "Multi-Domain Neural Machine Translation with Word-Level Adaptive\n  Layer-wise Domain Mixing", "comments": null, "journal-ref": "The 58th annual meeting of the Association for Computational\n  Linguistics (ACL 2020)", "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Many multi-domain neural machine translation (NMT) models achieve knowledge\ntransfer by enforcing one encoder to learn shared embedding across domains.\nHowever, this design lacks adaptation to individual domains. To overcome this\nlimitation, we propose a novel multi-domain NMT model using individual modules\nfor each domain, on which we apply word-level, adaptive and layer-wise domain\nmixing. We first observe that words in a sentence are often related to multiple\ndomains. Hence, we assume each word has a domain proportion, which indicates\nits domain preference. Then word representations are obtained by mixing their\nembedding in individual domains based on their domain proportions. We show this\ncan be achieved by carefully designing multi-head dot-product attention modules\nfor different domains, and eventually taking weighted averages of their\nparameters by word-level layer-wise domain proportions. Through this, we can\nachieve effective domain knowledge sharing, and capture fine-grained\ndomain-specific knowledge as well. Our experiments show that our proposed model\noutperforms existing ones in several NMT tasks.\n", "versions": [{"version": "v1", "created": "Thu, 7 Nov 2019 00:54:06 GMT"}, {"version": "v2", "created": "Fri, 1 May 2020 19:21:33 GMT"}, {"version": "v3", "created": "Fri, 12 Feb 2021 07:30:17 GMT"}], "update_date": "2021-02-15", "authors_parsed": [["Jiang", "Haoming", ""], ["Liang", "Chen", ""], ["Wang", "Chong", ""], ["Zhao", "Tuo", ""]]}, {"id": "1911.02700", "submitter": "David Wolpert", "authors": "David H. Wolpert", "title": "Uncertainty relations and fluctuation theorems for Bayes nets", "comments": "5 pages main text, 10 pages appendices, 1 figure - typos fixed from\n  earlier version", "journal-ref": "Phys. Rev. Lett. 125, 200602 (2020)", "doi": "10.1103/PhysRevLett.125.200602", "report-no": null, "categories": "cond-mat.stat-mech cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent research has considered the stochastic thermodynamics of multiple\ninteracting systems, representing the overall system as a Bayes net. I derive\nfluctuation theorems governing the entropy production (EP)of arbitrary sets of\nthe systems in such a Bayes net. I also derive ``conditional'' fluctuation\ntheorems, governing the distribution of EP in one set of systems conditioned on\nthe EP of a different set of systems. I then derive thermodynamic uncertainty\nrelations relating the EP of the overall system to the precisions of\nprobability currents within the individual systems.\n", "versions": [{"version": "v1", "created": "Thu, 7 Nov 2019 01:17:00 GMT"}, {"version": "v2", "created": "Thu, 2 Jan 2020 16:40:58 GMT"}, {"version": "v3", "created": "Mon, 24 Feb 2020 23:06:57 GMT"}, {"version": "v4", "created": "Thu, 27 Feb 2020 18:51:40 GMT"}, {"version": "v5", "created": "Mon, 1 Jun 2020 21:59:18 GMT"}], "update_date": "2020-11-18", "authors_parsed": [["Wolpert", "David H.", ""]]}, {"id": "1911.02710", "submitter": "Craig Gin", "authors": "Craig Gin, Bethany Lusch, Steven L. Brunton, J. Nathan Kutz", "title": "Deep Learning Models for Global Coordinate Transformations that\n  Linearize PDEs", "comments": "23 pages, 18 figures", "journal-ref": null, "doi": "10.1017/S0956792520000327", "report-no": null, "categories": "math.DS cs.LG physics.comp-ph stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We develop a deep autoencoder architecture that can be used to find a\ncoordinate transformation which turns a nonlinear PDE into a linear PDE. Our\narchitecture is motivated by the linearizing transformations provided by the\nCole-Hopf transform for Burgers equation and the inverse scattering transform\nfor completely integrable PDEs. By leveraging a residual network architecture,\na near-identity transformation can be exploited to encode intrinsic coordinates\nin which the dynamics are linear. The resulting dynamics are given by a Koopman\noperator matrix $\\mathbf{K}$. The decoder allows us to transform back to the\noriginal coordinates as well. Multiple time step prediction can be performed by\nrepeated multiplication by the matrix $\\mathbf{K}$ in the intrinsic\ncoordinates. We demonstrate our method on a number of examples, including the\nheat equation and Burgers equation, as well as the substantially more\nchallenging Kuramoto-Sivashinsky equation, showing that our method provides a\nrobust architecture for discovering interpretable, linearizing transforms for\nnonlinear PDEs.\n", "versions": [{"version": "v1", "created": "Thu, 7 Nov 2019 01:46:33 GMT"}], "update_date": "2020-09-30", "authors_parsed": [["Gin", "Craig", ""], ["Lusch", "Bethany", ""], ["Brunton", "Steven L.", ""], ["Kutz", "J. Nathan", ""]]}, {"id": "1911.02714", "submitter": "Benjamin Caulfield", "authors": "Benjamin Caulfield, Sanjit A. Seshia", "title": "Modularity in Query-Based Concept Learning", "comments": "17 pages, 4 figures, submitted to TACAS 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We define and study the problem of modular concept learning, that is,\nlearning a concept that is a cross product of component concepts. If an\nelement's membership in a concept depends solely on it's membership in the\ncomponents, learning the concept as a whole can be reduced to learning the\ncomponents. We analyze this problem with respect to different types of oracle\ninterfaces, defining different sets of queries. If a given oracle interface\ncannot answer questions about the components, learning can be difficult, even\nwhen the components are easy to learn with the same type of oracle queries.\nWhile learning from superset queries is easy, learning from membership,\nequivalence, or subset queries is harder. However, we show that these problems\nbecome tractable when oracles are given a positive example and are allowed to\nask membership queries.\n", "versions": [{"version": "v1", "created": "Thu, 7 Nov 2019 02:05:25 GMT"}], "update_date": "2019-11-11", "authors_parsed": [["Caulfield", "Benjamin", ""], ["Seshia", "Sanjit A.", ""]]}, {"id": "1911.02723", "submitter": "Rakhoon Hwang", "authors": "Rakhoon Hwang, Hanjin Lee, Hyung Ju Hwang", "title": "Option Compatible Reward Inverse Reinforcement Learning", "comments": "This paper is under consideration at Pattern Recognition Letters", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Reinforcement learning in complex environments is a challenging problem. In\nparticular, the success of reinforcement learning algorithms depends on a\nwell-designed reward function. Inverse reinforcement learning (IRL) solves the\nproblem of recovering reward functions from expert demonstrations. In this\npaper, we solve a hierarchical inverse reinforcement learning problem within\nthe options framework, which allows us to utilize intrinsic motivation of the\nexpert demonstrations. A gradient method for parametrized options is used to\ndeduce a defining equation for the Q-feature space, which leads to a reward\nfeature space. Using a second-order optimality condition for option parameters,\nan optimal reward function is selected. Experimental results in both discrete\nand continuous domains confirm that our recovered rewards provide a solution to\nthe IRL problem using temporal abstraction, which in turn are effective in\naccelerating transfer learning tasks. We also show that our method is robust to\nnoises contained in expert demonstrations.\n", "versions": [{"version": "v1", "created": "Thu, 7 Nov 2019 02:29:58 GMT"}, {"version": "v2", "created": "Tue, 19 Jan 2021 04:14:35 GMT"}], "update_date": "2021-01-20", "authors_parsed": [["Hwang", "Rakhoon", ""], ["Lee", "Hanjin", ""], ["Hwang", "Hyung Ju", ""]]}, {"id": "1911.02728", "submitter": "Meimei Liu", "authors": "Meimei Liu, Zhengwu Zhang and David B. Dunson", "title": "Auto-encoding brain networks with applications to analyzing large-scale\n  brain imaging datasets", "comments": "31 pages, 12 figures, 5 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  There has been huge interest in studying human brain connectomes inferred\nfrom different imaging modalities and exploring their relationship with human\ntraits, such as cognition. Brain connectomes are usually represented as\nnetworks, with nodes corresponding to different regions of interest (ROIs) and\nedges to connection strengths between ROIs. Due to the high-dimensionality and\nnon-Euclidean nature of networks, it is challenging to depict their population\ndistribution and relate them to human traits. Current approaches focus on\nsummarizing the network using either pre-specified topological features or\nprincipal components analysis (PCA). In this paper, building on recent advances\nin deep learning, we develop a nonlinear latent factor model to characterize\nthe population distribution of brain graphs and infer the relationships between\nbrain structural connectomes and human traits. We refer to our method as Graph\nAuTo-Encoding (GATE). We applied GATE to two large-scale brain imaging\ndatasets, the Adolescent Brain Cognitive Development (ABCD) study and the Human\nConnectome Project (HCP) for adults, to understand the structural brain\nconnectome and its relationship with cognition. Numerical results demonstrate\nhuge advantages of GATE over competitors in terms of prediction accuracy,\nstatistical inference and computing efficiency. We found that structural\nconnectomes have a stronger association with a wide range of human cognitive\ntraits than was apparent using previous approaches.\n", "versions": [{"version": "v1", "created": "Thu, 7 Nov 2019 02:51:35 GMT"}, {"version": "v2", "created": "Wed, 30 Jun 2021 18:38:28 GMT"}], "update_date": "2021-07-02", "authors_parsed": [["Liu", "Meimei", ""], ["Zhang", "Zhengwu", ""], ["Dunson", "David B.", ""]]}, {"id": "1911.02739", "submitter": "Zhihan Zhang", "authors": "Zhihan Zhang, Zhiyi Yin, Shuhuai Ren, Xinhang Li, Shicheng Li", "title": "DCA: Diversified Co-Attention towards Informative Live Video Commenting", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We focus on the task of Automatic Live Video Commenting (ALVC), which aims to\ngenerate real-time video comments with both video frames and other viewers'\ncomments as inputs. A major challenge in this task is how to properly leverage\nthe rich and diverse information carried by video and text. In this paper, we\naim to collect diversified information from video and text for informative\ncomment generation. To achieve this, we propose a Diversified Co-Attention\n(DCA) model for this task. Our model builds bidirectional interactions between\nvideo frames and surrounding comments from multiple perspectives via metric\nlearning, to collect a diversified and informative context for comment\ngeneration. We also propose an effective parameter orthogonalization technique\nto avoid excessive overlap of information learned from different perspectives.\nResults show that our approach outperforms existing methods in the ALVC task,\nachieving new state-of-the-art results.\n", "versions": [{"version": "v1", "created": "Thu, 7 Nov 2019 03:28:38 GMT"}, {"version": "v2", "created": "Sat, 4 Apr 2020 05:14:34 GMT"}, {"version": "v3", "created": "Sat, 8 Aug 2020 13:37:10 GMT"}], "update_date": "2020-08-11", "authors_parsed": [["Zhang", "Zhihan", ""], ["Yin", "Zhiyi", ""], ["Ren", "Shuhuai", ""], ["Li", "Xinhang", ""], ["Li", "Shicheng", ""]]}, {"id": "1911.02743", "submitter": "Ishan D Khurjekar", "authors": "Ishan D. Khurjekar and Joel B. Harley", "title": "Accounting for Physics Uncertainty in Ultrasonic Wave Propagation using\n  Deep Learning", "comments": "Second Workshop on Machine Learning and the Physical Sciences\n  (NeurIPS 2019), Vancouver, Canada", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG eess.AS eess.SP stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Ultrasonic guided waves are commonly used to localize structural damage in\ninfrastructures such as buildings, airplanes, bridges. Damage localization can\nbe viewed as an inverse problem. Physical model based techniques are popular\nfor guided wave based damage localization. The performance of these techniques\ndepend on the degree of faithfulness with which the physical model describes\nwave propagation. External factors such as environmental variations and random\nnoise are a source of uncertainty in wave propagation. The physical modeling of\nuncertainty in an inverse problem is still a challenging problem. In this work,\nwe propose a deep learning based model for robust damage localization in\npresence of uncertainty. Wave data with uncertainty is simulated to reflect\nvariations due to external factors and Gaussian noise is added to reflect\nrandom noise in the environment. After evaluating the localization error on\ntest data with uncertainty, we observe that the deep learning model trained\nwith uncertainty can learn robust representations. The approach shows potential\nfor dealing with uncertainty in physical science problems using deep learning\nmodels.\n", "versions": [{"version": "v1", "created": "Thu, 7 Nov 2019 03:44:18 GMT"}], "update_date": "2019-11-11", "authors_parsed": [["Khurjekar", "Ishan D.", ""], ["Harley", "Joel B.", ""]]}, {"id": "1911.02744", "submitter": "Haoxuan You", "authors": "Can Qin, Haoxuan You, Lichen Wang, C.-C. Jay Kuo, Yun Fu", "title": "PointDAN: A Multi-Scale 3D Domain Adaption Network for Point Cloud\n  Representation", "comments": "12 pages, 4 figures, 33rd Conference on Neural Information Processing\n  Systems (NeurIPS 2019)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Domain Adaptation (DA) approaches achieved significant improvements in a wide\nrange of machine learning and computer vision tasks (i.e., classification,\ndetection, and segmentation). However, as far as we are aware, there are few\nmethods yet to achieve domain adaptation directly on 3D point cloud data. The\nunique challenge of point cloud data lies in its abundant spatial geometric\ninformation, and the semantics of the whole object is contributed by including\nregional geometric structures. Specifically, most general-purpose DA methods\nthat struggle for global feature alignment and ignore local geometric\ninformation are not suitable for 3D domain alignment. In this paper, we propose\na novel 3D Domain Adaptation Network for point cloud data (PointDAN). PointDAN\njointly aligns the global and local features in multi-level. For local\nalignment, we propose Self-Adaptive (SA) node module with an adjusted receptive\nfield to model the discriminative local structures for aligning domains. To\nrepresent hierarchically scaled features, node-attention module is further\nintroduced to weight the relationship of SA nodes across objects and domains.\nFor global alignment, an adversarial-training strategy is employed to learn and\nalign global features across domains. Since there is no common evaluation\nbenchmark for 3D point cloud DA scenario, we build a general benchmark (i.e.,\nPointDA-10) extracted from three popular 3D object/scene datasets (i.e.,\nModelNet, ShapeNet and ScanNet) for cross-domain 3D objects classification\nfashion. Extensive experiments on PointDA-10 illustrate the superiority of our\nmodel over the state-of-the-art general-purpose DA methods.\n", "versions": [{"version": "v1", "created": "Thu, 7 Nov 2019 04:03:07 GMT"}], "update_date": "2019-11-26", "authors_parsed": [["Qin", "Can", ""], ["You", "Haoxuan", ""], ["Wang", "Lichen", ""], ["Kuo", "C. -C. Jay", ""], ["Fu", "Yun", ""]]}, {"id": "1911.02749", "submitter": "Tong Zhang", "authors": "Tong Zhang and Fatih Porikli", "title": "Sparse Coding on Cascaded Residuals", "comments": "ACCV 2016", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG eess.IV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper seeks to combine dictionary learning and hierarchical image\nrepresentation in a principled way. To make dictionary atoms capturing\nadditional information from extended receptive fields and attain improved\ndescriptive capacity, we present a two-pass multi-resolution cascade framework\nfor dictionary learning and sparse coding. The cascade allows collaborative\nreconstructions at different resolutions using the same dimensional dictionary\natoms. Our jointly learned dictionary comprises atoms that adapt to the\ninformation available at the coarsest layer where the support of atoms reaches\ntheir maximum range and the residual images where the supplementary details\nprogressively refine the reconstruction objective. The residual at a layer is\ncomputed by the difference between the aggregated reconstructions of the\nprevious layers and the downsampled original image at that layer. Our method\ngenerates more flexible and accurate representations using much less number of\ncoefficients. Its computational efficiency stems from encoding at the coarsest\nresolution, which is minuscule, and encoding the residuals, which are\nrelatively much sparse. Our extensive experiments on multiple datasets\ndemonstrate that this new method is powerful in image coding, denoising,\ninpainting and artifact removal tasks outperforming the state-of-the-art\ntechniques.\n", "versions": [{"version": "v1", "created": "Thu, 7 Nov 2019 04:17:46 GMT"}], "update_date": "2019-11-11", "authors_parsed": [["Zhang", "Tong", ""], ["Porikli", "Fatih", ""]]}, {"id": "1911.02752", "submitter": "Rocky Chen", "authors": "Tong Chen, Hongzhi Yin, Quoc Viet Hung Nguyen, Wen-Chih Peng, Xue Li,\n  Xiaofang Zhou", "title": "Sequence-Aware Factorization Machines for Temporal Predictive Analytics", "comments": "To appear in ICDE'20, Dallas, Texas, USA. Code link updated", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.IR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In various web applications like targeted advertising and recommender\nsystems, the available categorical features (e.g., product type) are often of\ngreat importance but sparse. As a widely adopted solution, models based on\nFactorization Machines (FMs) are capable of modelling high-order interactions\namong features for effective sparse predictive analytics. As the volume of\nweb-scale data grows exponentially over time, sparse predictive analytics\ninevitably involves dynamic and sequential features. However, existing FM-based\nmodels assume no temporal orders in the data, and are unable to capture the\nsequential dependencies or patterns within the dynamic features, impeding the\nperformance and adaptivity of these methods. Hence, in this paper, we propose a\nnovel Sequence-Aware Factorization Machine (SeqFM) for temporal predictive\nanalytics, which models feature interactions by fully investigating the effect\nof sequential dependencies. As static features (e.g., user gender) and dynamic\nfeatures (e.g., user interacted items) express different semantics, we\ninnovatively devise a multi-view self-attention scheme that separately models\nthe effect of static features, dynamic features and the mutual interactions\nbetween static and dynamic features in three different views. In SeqFM, we\nfurther map the learned representations of feature interactions to the desired\noutput with a shared residual network. To showcase the versatility and\ngeneralizability of SeqFM, we test SeqFM in three popular application scenarios\nfor FM-based models, namely ranking, classification and regression tasks.\nExtensive experimental results on six large-scale datasets demonstrate the\nsuperior effectiveness and efficiency of SeqFM.\n", "versions": [{"version": "v1", "created": "Thu, 7 Nov 2019 04:29:53 GMT"}, {"version": "v2", "created": "Mon, 18 Nov 2019 01:44:19 GMT"}], "update_date": "2019-11-19", "authors_parsed": [["Chen", "Tong", ""], ["Yin", "Hongzhi", ""], ["Nguyen", "Quoc Viet Hung", ""], ["Peng", "Wen-Chih", ""], ["Li", "Xue", ""], ["Zhou", "Xiaofang", ""]]}, {"id": "1911.02761", "submitter": "Han Bao", "authors": "Han Bao", "title": "Investigations of the Influences of a CNN's Receptive Field on\n  Segmentation of Subnuclei of Bilateral Amygdalae", "comments": "16 pages, 10 figures, ADEIJ journal", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.IV cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Segmentation of objects with various sizes is relatively less explored in\nmedical imaging, and has been very challenging in computer vision tasks in\ngeneral. We hypothesize that the receptive field of a deep model corresponds\nclosely to the size of object to be segmented, which could critically influence\nthe segmentation accuracy of objects with varied sizes. In this study, we\nemployed \"AmygNet\", a dual-branch fully convolutional neural network (FCNN)\nwith two different sizes of receptive fields, to investigate the effects of\nreceptive field on segmenting four major subnuclei of bilateral amygdalae. The\nexperiment was conducted on 14 subjects, which are all 3-dimensional MRI human\nbrain images. Since the scale of different subnuclear groups are different, by\ninvestigating the accuracy of each subnuclear group while using receptive\nfields of various sizes, we may find which kind of receptive field is suitable\nfor object of which scale respectively. In the given condition, AmygNet with\nmultiple receptive fields presents great potential in segmenting objects of\ndifferent sizes.\n", "versions": [{"version": "v1", "created": "Thu, 7 Nov 2019 05:39:56 GMT"}], "update_date": "2019-11-11", "authors_parsed": [["Bao", "Han", ""]]}, {"id": "1911.02768", "submitter": "Vitor Hadad", "authors": "Vitor Hadad, David A. Hirshberg, Ruohan Zhan, Stefan Wager, Susan\n  Athey", "title": "Confidence Intervals for Policy Evaluation in Adaptive Experiments", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG stat.ME", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Adaptive experiment designs can dramatically improve statistical efficiency\nin randomized trials, but they also complicate statistical inference. For\nexample, it is now well known that the sample mean is biased in adaptive\ntrials. Inferential challenges are exacerbated when our parameter of interest\ndiffers from the parameter the trial was designed to target, such as when we\nare interested in estimating the value of a sub-optimal treatment after running\na trial to determine the optimal treatment using a stochastic bandit design. In\nthis context, typical estimators that use inverse propensity weighting to\neliminate sampling bias can be problematic: their distributions become skewed\nand heavy-tailed as the propensity scores decay to zero. In this paper, we\npresent a class of estimators that overcome these issues. Our approach is to\nadaptively reweight the terms of an augmented inverse propensity weighting\nestimator to control the contribution of each term to the estimator's variance.\nThis adaptive weighting scheme prevents estimates from becoming heavy-tailed,\nensuring asymptotically correct coverage. It also reduces variance, allowing us\nto test hypotheses with greater power - especially hypotheses that were not\ntargeted by the experimental design. We validate the accuracy of the resulting\nestimates and their confidence intervals in numerical experiments and show our\nmethods compare favorably to existing alternatives in terms of RMSE and\ncoverage.\n", "versions": [{"version": "v1", "created": "Thu, 7 Nov 2019 06:15:52 GMT"}, {"version": "v2", "created": "Tue, 7 Jul 2020 17:44:37 GMT"}, {"version": "v3", "created": "Fri, 10 Jul 2020 18:09:03 GMT"}, {"version": "v4", "created": "Fri, 12 Feb 2021 20:03:50 GMT"}], "update_date": "2021-02-16", "authors_parsed": [["Hadad", "Vitor", ""], ["Hirshberg", "David A.", ""], ["Zhan", "Ruohan", ""], ["Wager", "Stefan", ""], ["Athey", "Susan", ""]]}, {"id": "1911.02770", "submitter": "Yunshen Zhou", "authors": "Yunshen Zhou, Zhaojun Bai, Ren-Cang Li", "title": "Linear Constrained Rayleigh Quotient Optimization: Theory and Algorithms", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.NA cs.LG cs.NA math.OC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the following constrained Rayleigh quotient optimization problem\n(CRQopt) $$ \\min_{x\\in \\mathbb{R}^n} x^{T}Ax\\,\\,\\mbox{subject to}\\,\\,\nx^{T}x=1\\,\\mbox{and}\\,C^{T}x=b, $$ where $A$ is an $n\\times n$ real symmetric\nmatrix and $C$ is an $n\\times m$ real matrix.\n  Usually, $m\\ll n$. The problem is also known as the constrained eigenvalue\nproblem in the literature because it becomes an eigenvalue problem if the\nlinear constraint $C^{T}x=b$ is removed. We start by equivalently transforming\nCRQopt into an optimization problem, called LGopt, of minimizing the Lagrangian\nmultiplier of CRQopt, and then an problem, called QEPmin, of finding the\nsmallest eigenvalue of a quadratic eigenvalue problem. Although such\nequivalences has been discussed in the literature, it appears to be the first\ntime that these equivalences are rigorously justified. Then we propose to\nnumerically solve LGopt and QEPmin by the Krylov subspace projection method via\nthe Lanczos process. The basic idea, as the Lanczos method for the symmetric\neigenvalue problem, is to first reduce LGopt and QEPmin by projecting them onto\nKrylov subspaces to yield problems of the same types but of much smaller sizes,\nand then solve the reduced problems by some direct methods, which is either a\nsecular equation solver (in the case of LGopt) or an eigensolver (in the case\nof QEPmin). The resulting algorithm is called the Lanczos algorithm. We perform\nconvergence analysis for the proposed method and obtain error bounds. The\nsharpness of the error bound is demonstrated by artificial examples, although\nin applications the method often converges much faster than the bounds suggest.\nFinally, we apply the Lanczos algorithm to semi-supervised learning in the\ncontext of constrained clustering.\n", "versions": [{"version": "v1", "created": "Thu, 7 Nov 2019 06:20:25 GMT"}], "update_date": "2019-11-11", "authors_parsed": [["Zhou", "Yunshen", ""], ["Bai", "Zhaojun", ""], ["Li", "Ren-Cang", ""]]}, {"id": "1911.02789", "submitter": "Guoxian Yu", "authors": "Jinzheng Tu, Guoxian Yu, Carlotta Domeniconi, Jun Wang, Xiangliang\n  Zhang", "title": "Active Multi-Label Crowd Consensus", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.HC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Crowdsourcing is an economic and efficient strategy aimed at collecting\nannotations of data through an online platform. Crowd workers with different\nexpertise are paid for their service, and the task requester usually has a\nlimited budget. How to collect reliable annotations for multi-label data and\nhow to compute the consensus within budget is an interesting and challenging,\nbut rarely studied, problem. In this paper, we propose a novel approach to\naccomplish Active Multi-label Crowd Consensus (AMCC). AMCC accounts for the\ncommonality and individuality of workers, and assumes that workers can be\norganized into different groups. Each group includes a set of workers who share\na similar annotation behavior and label correlations. To achieve an effective\nmulti-label consensus, AMCC models workers' annotations via a linear\ncombination of commonality and individuality, and reduces the impact of\nunreliable workers by assigning smaller weights to the group. To collect\nreliable annotations with reduced cost, AMCC introduces an active crowdsourcing\nlearning strategy that selects sample-label-worker triplets. In a triplet, the\nselected sample and label are the most informative for the consensus model, and\nthe selected worker can reliably annotate the sample with low cost. Our\nexperimental results on multi-label datasets demonstrate the advantages of AMCC\nover state-of-the-art solutions on computing crowd consensus and on reducing\nthe budget by choosing cost-effective triplets.\n", "versions": [{"version": "v1", "created": "Thu, 7 Nov 2019 07:59:46 GMT"}], "update_date": "2019-11-11", "authors_parsed": [["Tu", "Jinzheng", ""], ["Yu", "Guoxian", ""], ["Domeniconi", "Carlotta", ""], ["Wang", "Jun", ""], ["Zhang", "Xiangliang", ""]]}, {"id": "1911.02792", "submitter": "Frank Noe", "authors": "Frank No\\'e, Alexandre Tkatchenko, Klaus-Robert M\\\"uller, Cecilia\n  Clementi", "title": "Machine learning for molecular simulation", "comments": null, "journal-ref": "No\\'e F, Tkatchenko A, M\\\"uller KR, Clementi C. 2020. Machine\n  learning for molecular simulation. Annu. Rev. Phys. Chem. 71", "doi": "10.1146/annurev-physchem-042018-052331", "report-no": null, "categories": "physics.chem-ph cs.LG physics.comp-ph quant-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Machine learning (ML) is transforming all areas of science. The complex and\ntime-consuming calculations in molecular simulations are particularly suitable\nfor a machine learning revolution and have already been profoundly impacted by\nthe application of existing ML methods. Here we review recent ML methods for\nmolecular simulation, with particular focus on (deep) neural networks for the\nprediction of quantum-mechanical energies and forces, coarse-grained molecular\ndynamics, the extraction of free energy surfaces and kinetics and generative\nnetwork approaches to sample molecular equilibrium structures and compute\nthermodynamics. To explain these methods and illustrate open methodological\nproblems, we review some important principles of molecular physics and describe\nhow they can be incorporated into machine learning structures. Finally, we\nidentify and describe a list of open challenges for the interface between ML\nand molecular simulation.\n", "versions": [{"version": "v1", "created": "Thu, 7 Nov 2019 08:14:18 GMT"}], "update_date": "2019-11-11", "authors_parsed": [["No\u00e9", "Frank", ""], ["Tkatchenko", "Alexandre", ""], ["M\u00fcller", "Klaus-Robert", ""], ["Clementi", "Cecilia", ""]]}, {"id": "1911.02833", "submitter": "Fan Zhang Dr", "authors": "Fan Zhang, Mariana Afonso and David R. Bull", "title": "ViSTRA2: Video Coding using Spatial Resolution and Effective Bit Depth\n  Adaptation", "comments": "9 pages", "journal-ref": null, "doi": "10.1016/j.image.2021.116355", "report-no": null, "categories": "eess.IV cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We present a new video compression framework (ViSTRA2) which exploits\nadaptation of spatial resolution and effective bit depth, down-sampling these\nparameters at the encoder based on perceptual criteria, and up-sampling at the\ndecoder using a deep convolution neural network. ViSTRA2 has been integrated\nwith the reference software of both the HEVC (HM 16.20) and VVC (VTM 4.01), and\nevaluated under the Joint Video Exploration Team Common Test Conditions using\nthe Random Access configuration. Our results show consistent and significant\ncompression gains against HM and VVC based on Bj{\\o}negaard Delta measurements,\nwith average BD-rate savings of 12.6% (PSNR) and 19.5% (VMAF) over HM and 5.5%\n(PSNR) and 8.6% (VMAF) over VTM.\n", "versions": [{"version": "v1", "created": "Thu, 7 Nov 2019 10:33:50 GMT"}], "update_date": "2021-06-22", "authors_parsed": [["Zhang", "Fan", ""], ["Afonso", "Mariana", ""], ["Bull", "David R.", ""]]}, {"id": "1911.02875", "submitter": "Wei Pan", "authors": "Minghao Han, Yuan Tian, Lixian Zhang, Jun Wang, Wei Pan", "title": "$H_\\infty$ Model-free Reinforcement Learning with Robust Stability\n  Guarantee", "comments": "NeurIPS 2019 Workshop on Robot Learning: Control and Interaction in\n  the Real World, Vancouver, Canada", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.RO cs.SY eess.SY", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Reinforcement learning is showing great potentials in robotics applications,\nincluding autonomous driving, robot manipulation and locomotion. However, with\ncomplex uncertainties in the real-world environment, it is difficult to\nguarantee the successful generalization and sim-to-real transfer of learned\npolicies theoretically. In this paper, we introduce and extend the idea of\nrobust stability and $H_\\infty$ control to design policies with both stability\nand robustness guarantee. Specifically, a sample-based approach for analyzing\nthe Lyapunov stability and performance robustness of a learning-based control\nsystem is proposed. Based on the theoretical results, a maximum entropy\nalgorithm is developed for searching Lyapunov function and designing a policy\nwith provable robust stability guarantee. Without any specific domain\nknowledge, our method can find a policy that is robust to various uncertainties\nand generalizes well to different test environments. In our experiments, we\nshow that our method achieves better robustness to both large impulsive\ndisturbances and parametric variations in the environment than the state-of-art\nresults in both robust and generic RL, as well as classic control. Anonymous\ncode is available to reproduce the experimental results at\nhttps://github.com/RobustStabilityGuaranteeRL/RobustStabilityGuaranteeRL.\n", "versions": [{"version": "v1", "created": "Thu, 7 Nov 2019 12:32:27 GMT"}, {"version": "v2", "created": "Fri, 15 Nov 2019 20:00:30 GMT"}, {"version": "v3", "created": "Sat, 25 Jul 2020 16:21:12 GMT"}], "update_date": "2020-07-28", "authors_parsed": [["Han", "Minghao", ""], ["Tian", "Yuan", ""], ["Zhang", "Lixian", ""], ["Wang", "Jun", ""], ["Pan", "Wei", ""]]}, {"id": "1911.02882", "submitter": "Semin Joung", "authors": "Semin Joung, Jaewook Kim, Sehyun Kwak, J.G. Bak, S.G. Lee, H.S. Han,\n  H.S. Kim, Geunho Lee, Daeho Kwon, and Y.-c. Ghim", "title": "Deep neural network Grad-Shafranov solver constrained with measured\n  magnetic signals", "comments": null, "journal-ref": null, "doi": "10.1088/1741-4326/ab555f", "report-no": null, "categories": "physics.plasm-ph cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  A neural network solving Grad-Shafranov equation constrained with measured\nmagnetic signals to reconstruct magnetic equilibria in real time is developed.\nDatabase created to optimize the neural network's free parameters contain\noff-line EFIT results as the output of the network from $1,118$ KSTAR\nexperimental discharges of two different campaigns. Input data to the network\nconstitute magnetic signals measured by a Rogowski coil (plasma current),\nmagnetic pick-up coils (normal and tangential components of magnetic fields)\nand flux loops (poloidal magnetic fluxes). The developed neural networks fully\nreconstruct not only the poloidal flux function $\\psi\\left( R, Z\\right)$ but\nalso the toroidal current density function $j_\\phi\\left( R, Z\\right)$ with the\noff-line EFIT quality. To preserve robustness of the networks against a few\nmissing input data, an imputation scheme is utilized to eliminate the required\nadditional training sets with large number of possible combinations of the\nmissing inputs.\n", "versions": [{"version": "v1", "created": "Thu, 7 Nov 2019 13:03:09 GMT"}], "update_date": "2020-01-08", "authors_parsed": [["Joung", "Semin", ""], ["Kim", "Jaewook", ""], ["Kwak", "Sehyun", ""], ["Bak", "J. G.", ""], ["Lee", "S. G.", ""], ["Han", "H. S.", ""], ["Kim", "H. S.", ""], ["Lee", "Geunho", ""], ["Kwon", "Daeho", ""], ["Ghim", "Y. -c.", ""]]}, {"id": "1911.02883", "submitter": "Elif Vural", "authors": "Yusuf Yigit Pilavci, Eylem Tugce Guneyi, Cemil Cengiz and Elif Vural", "title": "Graph Domain Adaptation with Localized Graph Signal Representations", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we propose a domain adaptation algorithm designed for graph\ndomains. Given a source graph with many labeled nodes and a target graph with\nfew or no labeled nodes, we aim to estimate the target labels by making use of\nthe similarity between the characteristics of the variation of the label\nfunctions on the two graphs. Our assumption about the source and the target\ndomains is that the local behaviour of the label function, such as its spread\nand speed of variation on the graph, bears resemblance between the two graphs.\nWe estimate the unknown target labels by solving an optimization problem where\nthe label information is transferred from the source graph to the target graph\nbased on the prior that the projections of the label functions onto localized\ngraph bases be similar between the source and the target graphs. In order to\nefficiently capture the local variation of the label functions on the graphs,\nspectral graph wavelets are used as the graph bases. Experimentation on various\ndata sets shows that the proposed method yields quite satisfactory\nclassification accuracy compared to reference domain adaptation methods.\n", "versions": [{"version": "v1", "created": "Thu, 7 Nov 2019 13:05:52 GMT"}, {"version": "v2", "created": "Mon, 24 Aug 2020 15:31:15 GMT"}], "update_date": "2020-08-25", "authors_parsed": [["Pilavci", "Yusuf Yigit", ""], ["Guneyi", "Eylem Tugce", ""], ["Cengiz", "Cemil", ""], ["Vural", "Elif", ""]]}, {"id": "1911.02888", "submitter": "Himalaya Jain", "authors": "Victor Besnier, Himalaya Jain, Andrei Bursuc, Matthieu Cord, Patrick\n  P\\'erez", "title": "This dataset does not exist: training models from generated images", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG eess.IV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Current generative networks are increasingly proficient in generating\nhigh-resolution realistic images. These generative networks, especially the\nconditional ones, can potentially become a great tool for providing new image\ndatasets. This naturally brings the question: Can we train a classifier only on\nthe generated data? This potential availability of nearly unlimited amounts of\ntraining data challenges standard practices for training machine learning\nmodels, which have been crafted across the years for limited and fixed size\ndatasets. In this work we investigate this question and its related challenges.\nWe identify ways to improve significantly the performance over naive training\non randomly generated images with regular heuristics. We propose three\nstandalone techniques that can be applied at different stages of the pipeline,\ni.e., data generation, training on generated data, and deploying on real data.\nWe evaluate our proposed approaches on a subset of the ImageNet dataset and\nshow encouraging results compared to classifiers trained on real images.\n", "versions": [{"version": "v1", "created": "Thu, 7 Nov 2019 13:23:39 GMT"}], "update_date": "2019-11-11", "authors_parsed": [["Besnier", "Victor", ""], ["Jain", "Himalaya", ""], ["Bursuc", "Andrei", ""], ["Cord", "Matthieu", ""], ["P\u00e9rez", "Patrick", ""]]}, {"id": "1911.02891", "submitter": "Lifu Tu", "authors": "Lifu Tu, Richard Yuanzhe Pang, Kevin Gimpel", "title": "Improving Joint Training of Inference Networks and Structured Prediction\n  Energy Networks", "comments": "EMNLP 2020 Workshop on Structured Prediction for NLP (SPNLP)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep energy-based models are powerful, but pose challenges for learning and\ninference (Belanger and McCallum, 2016). Tu and Gimpel (2018) developed an\nefficient framework for energy-based models by training \"inference networks\" to\napproximate structured inference instead of using gradient descent. However,\ntheir alternating optimization approach suffers from instabilities during\ntraining, requiring additional loss terms and careful hyperparameter tuning. In\nthis paper, we contribute several strategies to stabilize and improve this\njoint training of energy functions and inference networks for structured\nprediction. We design a compound objective to jointly train both cost-augmented\nand test-time inference networks along with the energy function. We propose\njoint parameterizations for the inference networks that encourage them to\ncapture complementary functionality during learning. We empirically validate\nour strategies on two sequence labeling tasks, showing easier paths to strong\nperformance than prior work, as well as further improvements with global energy\nterms.\n", "versions": [{"version": "v1", "created": "Thu, 7 Nov 2019 13:26:07 GMT"}, {"version": "v2", "created": "Sat, 10 Oct 2020 16:19:50 GMT"}], "update_date": "2020-10-13", "authors_parsed": [["Tu", "Lifu", ""], ["Pang", "Richard Yuanzhe", ""], ["Gimpel", "Kevin", ""]]}, {"id": "1911.02897", "submitter": "Matt Angus", "authors": "Matt Angus, Krzysztof Czarnecki, Rick Salay", "title": "Efficacy of Pixel-Level OOD Detection for Semantic Segmentation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG eess.IV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The detection of out of distribution samples for image classification has\nbeen widely researched. Safety critical applications, such as autonomous\ndriving, would benefit from the ability to localise the unusual objects causing\nthe image to be out of distribution. This paper adapts state-of-the-art methods\nfor detecting out of distribution images for image classification to the new\ntask of detecting out of distribution pixels, which can localise the unusual\nobjects. It further experimentally compares the adapted methods on two new\ndatasets derived from existing semantic segmentation datasets using PSPNet and\nDeeplabV3+ architectures, as well as proposing a new metric for the task. The\nevaluation shows that the performance ranking of the compared methods does not\ntransfer to the new task and every method performs significantly worse than\ntheir image-level counterparts.\n", "versions": [{"version": "v1", "created": "Thu, 7 Nov 2019 13:37:38 GMT"}], "update_date": "2019-11-11", "authors_parsed": [["Angus", "Matt", ""], ["Czarnecki", "Krzysztof", ""], ["Salay", "Rick", ""]]}, {"id": "1911.02903", "submitter": "Jakob Heiss", "authors": "Jakob Heiss, Josef Teichmann, Hanna Wutte", "title": "How Implicit Regularization of ReLU Neural Networks Characterizes the\n  Learned Function -- Part I: the 1-D Case of Two Layers with Random First\n  Layer", "comments": "further generalizing training loss L, fixing typos, improving\n  formulations", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.NA math.NA stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Today, various forms of neural networks are trained to perform approximation\ntasks in many fields. However, the estimates obtained are not fully understood\non function space. Empirical results suggest that typical training algorithms\nfavor regularized solutions. These observations motivate us to analyze\nproperties of the neural networks found by gradient descent initialized close\nto zero, that is frequently employed to perform the training task. As a\nstarting point, we consider one dimensional (shallow) ReLU neural networks in\nwhich weights are chosen randomly and only the terminal layer is trained.\nFirst, we rigorously show that for such networks ridge regularized regression\ncorresponds in function space to regularizing the estimate's second derivative\nfor fairly general loss functionals. For least squares regression, we show that\nthe trained network converges to the smooth spline interpolation of the\ntraining data as the number of hidden nodes tends to infinity. Moreover, we\nderive a correspondence between the early stopped gradient descent and the\nsmoothing spline regression. Our analysis might give valuable insight on the\nproperties of the solutions obtained using gradient descent methods in general\nsettings.\n", "versions": [{"version": "v1", "created": "Thu, 7 Nov 2019 13:48:15 GMT"}, {"version": "v2", "created": "Wed, 26 Feb 2020 19:31:46 GMT"}, {"version": "v3", "created": "Fri, 2 Jul 2021 19:54:00 GMT"}], "update_date": "2021-07-06", "authors_parsed": [["Heiss", "Jakob", ""], ["Teichmann", "Josef", ""], ["Wutte", "Hanna", ""]]}, {"id": "1911.02922", "submitter": "Luciano Melodia", "authors": "Luciano Melodia, Richard Lenz", "title": "Persistent Homology as Stopping-Criterion for Voronoi Interpolation", "comments": "Former title: \"Persistent Homology as Stopping-Criterion for Natural\n  Neighbor Interpolation\"", "journal-ref": "Int.Worksh.Comb.Img.Ana 2020 (29-44)", "doi": "10.1007/978-3-030-51002-2_3", "report-no": null, "categories": "cs.CG cs.LG math.AT stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this study the Voronoi interpolation is used to interpolate a set of\npoints drawn from a topological space with higher homology groups on its\nfiltration. The technique is based on Voronoi tessellation, which induces a\nnatural dual map to the Delaunay triangulation. Advantage is taken from this\nfact calculating the persistent homology on it after each iteration to capture\nthe changing topology of the data. The boundary points are identified as\ncritical. The Bottleneck and Wasserstein distance serve as a measure of quality\nbetween the original point set and the interpolation. If the norm of two\ndistances exceeds a heuristically determined threshold, the algorithm\nterminates. We give the theoretical basis for this approach and justify its\nvalidity with numerical experiments.\n", "versions": [{"version": "v1", "created": "Fri, 8 Nov 2019 14:46:30 GMT"}, {"version": "v10", "created": "Fri, 24 Jan 2020 15:36:53 GMT"}, {"version": "v11", "created": "Thu, 5 Mar 2020 15:23:36 GMT"}, {"version": "v12", "created": "Wed, 1 Apr 2020 08:16:04 GMT"}, {"version": "v13", "created": "Mon, 8 Jun 2020 14:11:42 GMT"}, {"version": "v14", "created": "Fri, 4 Dec 2020 12:40:47 GMT"}, {"version": "v2", "created": "Mon, 11 Nov 2019 14:25:10 GMT"}, {"version": "v3", "created": "Tue, 12 Nov 2019 19:33:17 GMT"}, {"version": "v4", "created": "Thu, 21 Nov 2019 08:52:31 GMT"}, {"version": "v5", "created": "Fri, 6 Dec 2019 09:42:25 GMT"}, {"version": "v6", "created": "Tue, 10 Dec 2019 17:48:50 GMT"}, {"version": "v7", "created": "Fri, 13 Dec 2019 15:28:36 GMT"}, {"version": "v8", "created": "Fri, 27 Dec 2019 12:11:29 GMT"}, {"version": "v9", "created": "Tue, 14 Jan 2020 13:19:46 GMT"}], "update_date": "2020-12-07", "authors_parsed": [["Melodia", "Luciano", ""], ["Lenz", "Richard", ""]]}, {"id": "1911.02924", "submitter": "S. Ashwin Renganathan", "authors": "S. Ashwin Renganathan, Kohei Harada and Dimitri N. Mavris", "title": "Aerodynamic Data Fusion Towards the Digital Twin Paradigm", "comments": "33 pages, 19 figures", "journal-ref": "AIAA Journal 2020", "doi": "10.2514/1.J059203", "report-no": null, "categories": "cs.CE cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We consider the fusion of two aerodynamic data sets originating from\ndiffering fidelity physical or computer experiments. We specifically address\nthe fusion of: 1) noisy and in-complete fields from wind tunnel measurements\nand 2) deterministic but biased fields from numerical simulations. These two\ndata sources are fused in order to estimate the \\emph{true} field that best\nmatches measured quantities that serves as the ground truth. For example, two\nsources of pressure fields about an aircraft are fused based on measured forces\nand moments from a wind-tunnel experiment. A fundamental challenge in this\nproblem is that the true field is unknown and can not be estimated with 100\\%\ncertainty. We employ a Bayesian framework to infer the true fields conditioned\non measured quantities of interest; essentially we perform a \\emph{statistical\ncorrection} to the data. The fused data may then be used to construct more\naccurate surrogate models suitable for early stages of aerospace design. We\nalso introduce an extension of the Proper Orthogonal Decomposition with\nconstraints to solve the same problem. Both methods are demonstrated on fusing\nthe pressure distributions for flow past the RAE2822 airfoil and the Common\nResearch Model wing at transonic conditions. Comparison of both methods reveal\nthat the Bayesian method is more robust when data is scarce while capable of\nalso accounting for uncertainties in the data. Furthermore, given adequate\ndata, the POD based and Bayesian approaches lead to \\emph{similar} results.\n", "versions": [{"version": "v1", "created": "Sat, 2 Nov 2019 02:38:48 GMT"}], "update_date": "2020-08-04", "authors_parsed": [["Renganathan", "S. Ashwin", ""], ["Harada", "Kohei", ""], ["Mavris", "Dimitri N.", ""]]}, {"id": "1911.02926", "submitter": "Marie Roald", "authors": "Marie Roald, Suchita Bhinge, Chunying Jia, Vince Calhoun, T\\\"ulay\n  Adal{\\i}, Evrim Acar", "title": "Tracing Network Evolution Using the PARAFAC2 Model", "comments": "5 pages, 5 figures, conference", "journal-ref": null, "doi": "10.1109/ICASSP40776.2020.9053902", "report-no": null, "categories": "stat.AP cs.LG q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Characterizing time-evolving networks is a challenging task, but it is\ncrucial for understanding the dynamic behavior of complex systems such as the\nbrain. For instance, how spatial networks of functional connectivity in the\nbrain evolve during a task is not well-understood. A traditional approach in\nneuroimaging data analysis is to make simplifications through the assumption of\nstatic spatial networks. In this paper, without assuming static networks in\ntime and/or space, we arrange the temporal data as a higher-order tensor and\nuse a tensor factorization model called PARAFAC2 to capture underlying patterns\n(spatial networks) in time-evolving data and their evolution. Numerical\nexperiments on simulated data demonstrate that PARAFAC2 can successfully reveal\nthe underlying networks and their dynamics. We also show the promising\nperformance of the model in terms of tracing the evolution of task-related\nfunctional connectivity in the brain through the analysis of functional\nmagnetic resonance imaging data.\n", "versions": [{"version": "v1", "created": "Wed, 23 Oct 2019 08:45:29 GMT"}], "update_date": "2021-01-27", "authors_parsed": [["Roald", "Marie", ""], ["Bhinge", "Suchita", ""], ["Jia", "Chunying", ""], ["Calhoun", "Vince", ""], ["Adal\u0131", "T\u00fclay", ""], ["Acar", "Evrim", ""]]}, {"id": "1911.02928", "submitter": "Mustafa Coskun", "authors": "Mustafa Coskun", "title": "Graph Convolutional Networks Meet with High Dimensionality Reduction", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Recently, Graph Convolutional Networks (GCNs) and their variants have been\nreceiving many research interests for learning graph-related tasks. While the\nGCNs have been successfully applied to this problem, some caveats inherited\nfrom classical deep learning still remain as open research topics in the\ncontext of the node classification problem. One such inherited caveat is that\nGCNs only consider the nodes that are a few propagations away from the labeled\nnodes to classify them. However, taking only a few propagation steps away nodes\ninto account defeats the purpose of using the graph topological information in\nthe GCNs. To remedy this problem, the-state-of-the-art methods leverage the\nnetwork diffusion approaches, namely personalized page rank and its variants,\nto fully account for the graph topology, {\\em after} they use the Neural\nNetworks in the GCNs. However, these approaches overlook the fact that the\nnetwork diffusion methods favour high degree nodes in the graph, resulting in\nthe propagation of labels to unlabeled centralized, hub, nodes. To address this\nbiasing hub nodes problem, in this paper, we propose to utilize a\ndimensionality reduction technique conjugate with personalized page rank so\nthat we can both take advantage from graph topology and resolve the hub node\nfavouring problem for GCNs. Here, our approach opens a new holistic road for\nmessage passing phase of GCNs by suggesting the usage of other proximity\nmatrices instead of well-known Laplacian. Testing on two real-world networks\nthat are commonly used in benchmarking GCNs' performance for the node\nclassification context, we systematically evaluate the performance of the\nproposed methodology and show that our approach outperforms existing methods\nfor wide ranges of parameter values with very limited deep learning training\n{\\em epochs}.\n", "versions": [{"version": "v1", "created": "Thu, 7 Nov 2019 14:22:07 GMT"}], "update_date": "2019-11-11", "authors_parsed": [["Coskun", "Mustafa", ""]]}, {"id": "1911.02933", "submitter": "Mohammad Kassem Zein", "authors": "Rema Daher, Mohammad Kassem Zein, Julia El Zini, Mariette Awad, and\n  Daniel Asmar", "title": "Change your singer: a transfer learning generative adversarial framework\n  for song to song conversion", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.SD eess.AS stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Have you ever wondered how a song might sound if performed by a different\nartist? In this work, we propose SCM-GAN, an end-to-end non-parallel song\nconversion system powered by generative adversarial and transfer learning that\nallows users to listen to a selected target singer singing any song. SCM-GAN\nfirst separates songs into vocals and instrumental music using a U-Net network,\nthen converts the vocal segments to the target singer using advanced\nCycleGAN-VC, before merging the converted vocals with their corresponding\nbackground music. SCM-GAN is first initialized with feature representations\nlearned from a state-of-the-art voice-to-voice conversion and then trained on a\ndataset of non-parallel songs. Furthermore, SCM-GAN is evaluated against a set\nof metrics including global variance GV and modulation spectra MS on the 24\nMel-cepstral coefficients (MCEPs). Transfer learning improves the GV by 35% and\nthe MS by 13% on average. A subjective comparison is conducted to test the user\nsatisfaction with the quality and the naturalness of the conversion. Results\nshow above par similarity between SCM-GAN's output and the target (70\\% on\naverage) as well as great naturalness of the converted songs.\n", "versions": [{"version": "v1", "created": "Thu, 7 Nov 2019 14:32:43 GMT"}, {"version": "v2", "created": "Thu, 30 Jan 2020 19:03:39 GMT"}], "update_date": "2020-02-03", "authors_parsed": [["Daher", "Rema", ""], ["Zein", "Mohammad Kassem", ""], ["Zini", "Julia El", ""], ["Awad", "Mariette", ""], ["Asmar", "Daniel", ""]]}, {"id": "1911.02945", "submitter": "Hemant Kumar Aggarwal", "authors": "Hemant Kumar Aggarwal, Mathews Jacob", "title": "J-MoDL: Joint Model-Based Deep Learning for Optimized Sampling and\n  Reconstruction", "comments": null, "journal-ref": "IEEE Journal of Selected Topics in Signal Processing, 14(6), 2020", "doi": "10.1109/JSTSP.2020.3004094", "report-no": null, "categories": "eess.IV cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Modern MRI schemes, which rely on compressed sensing or deep learning\nalgorithms to recover MRI data from undersampled multichannel Fourier\nmeasurements, are widely used to reduce scan time. The image quality of these\napproaches is heavily dependent on the sampling pattern. We introduce a\ncontinuous strategy to jointly optimize the sampling pattern and network\nparameters. We use a multichannel forward model, consisting of a non-uniform\nFourier transform with continuously defined sampling locations, to realize the\ndata consistency block within a model-based deep learning image reconstruction\nscheme. This approach facilitates the joint and continuous optimization of the\nsampling pattern and the CNN parameters to improve image quality. We observe\nthat the joint optimization of the sampling patterns and the reconstruction\nmodule significantly improves the performance of most deep learning\nreconstruction algorithms. The source code of the proposed joint learning\nframework is available at https://github.com/hkaggarwal/J-MoDL.\n", "versions": [{"version": "v1", "created": "Wed, 6 Nov 2019 16:10:45 GMT"}, {"version": "v2", "created": "Fri, 20 Dec 2019 18:18:24 GMT"}, {"version": "v3", "created": "Sun, 3 May 2020 05:21:22 GMT"}, {"version": "v4", "created": "Thu, 2 Jul 2020 19:48:27 GMT"}], "update_date": "2020-07-06", "authors_parsed": [["Aggarwal", "Hemant Kumar", ""], ["Jacob", "Mathews", ""]]}, {"id": "1911.02961", "submitter": "Carlos Eduardo Rosar Kos Lassance", "authors": "Carlos Lassance, Yasir Latif, Ravi Garg, Vincent Gripon, Ian Reid", "title": "Improved Visual Localization via Graph Smoothing", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Vision based localization is the problem of inferring the pose of the camera\ngiven a single image. One solution to this problem is to learn a deep neural\nnetwork to infer the pose of a query image after learning on a dataset of\nimages with known poses. Another more commonly used approach rely on image\nretrieval where the query image is compared against the database of images and\nits pose is inferred with the help of the retrieved images. The latter approach\nassumes that images taken from the same places consists of the same landmarks\nand, thus would have similar feature representations. These representation can\nbe learned using full supervision to be robust to different variations in\ncapture conditions like time of the day and weather. In this work, we introduce\na framework to enhance the performance of these retrieval based localization\nmethods by taking into account the additional information including GPS\ncoordinates and temporal neighbourhood of the images provided by the\nacquisition process in addition to the descriptor similarity of pairs of images\nin the reference or query database which is used traditionally for\nlocalization. Our method constructs a graph based on this additional\ninformation and use it for robust retrieval by smoothing the feature\nrepresentation of reference and/or query images. We show that the proposed\nmethod is able to significantly improve the localization accuracy on two large\nscale datasets over the baselines.\n", "versions": [{"version": "v1", "created": "Thu, 7 Nov 2019 15:15:24 GMT"}], "update_date": "2019-11-11", "authors_parsed": [["Lassance", "Carlos", ""], ["Latif", "Yasir", ""], ["Garg", "Ravi", ""], ["Gripon", "Vincent", ""], ["Reid", "Ian", ""]]}, {"id": "1911.02966", "submitter": "Vishal Anand", "authors": "Vishal Anand, S.R. Sreeja, Debasis Samanta", "title": "An automated approach for task evaluation using EEG signals", "comments": "19 pages, 10 figures, 4 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG eess.SP stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Critical task and cognition-based environments, such as in military and\ndefense operations, aviation user-technology interaction evaluation on UI,\nunderstanding intuitiveness of a hardware model or software toolkit, etc.\nrequire an assessment of how much a particular task is generating mental\nworkload on a user. This is necessary for understanding how those tasks,\noperations, and activities can be improvised and made better suited for the\nusers so that they reduce the mental workload on the individual and the\noperators can use them with ease and less difficulty. However, a particular\ntask can be gauged by a user as simple while for others it may be difficult.\nUnderstanding the complexity of a particular task can only be done on user\nlevel and we propose to do this by understanding the mental workload (MWL)\ngenerated on an operator while performing a task which requires processing a\nlot of information to get the task done. In this work, we have proposed an\nexperimental setup which replicates modern day workload on doing regular day\njob tasks. We propose an approach to automatically evaluate the task complexity\nperceived by an individual by using electroencephalogram (EEG) data of a user\nduring operation. Few crucial steps that are addressed in this work include\nextraction and optimization of different features and selection of relevant\nfeatures for dimensionality reduction and using supervised machine learning\ntechniques. In addition to this, performance results of the classifiers are\ncompared using all features and also using only the selected features. From the\nresults, it can be inferred that machine learning algorithms perform better as\ncompared to traditional approaches for mental workload estimation.\n", "versions": [{"version": "v1", "created": "Thu, 7 Nov 2019 15:37:40 GMT"}, {"version": "v2", "created": "Thu, 14 Nov 2019 16:36:27 GMT"}], "update_date": "2019-11-15", "authors_parsed": [["Anand", "Vishal", ""], ["Sreeja", "S. R.", ""], ["Samanta", "Debasis", ""]]}, {"id": "1911.02970", "submitter": "Liang Ma", "authors": "Swati Rallapalli, Liang Ma, Mudhakar Srivatsa, Ananthram Swami,\n  Heesung Kwon, Graham Bent, Christopher Simpkin", "title": "SENSE: Semantically Enhanced Node Sequence Embedding", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CL stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Effectively capturing graph node sequences in the form of vector embeddings\nis critical to many applications. We achieve this by (i) first learning vector\nembeddings of single graph nodes and (ii) then composing them to compactly\nrepresent node sequences. Specifically, we propose SENSE-S (Semantically\nEnhanced Node Sequence Embedding - for Single nodes), a skip-gram based novel\nembedding mechanism, for single graph nodes that co-learns graph structure as\nwell as their textual descriptions. We demonstrate that SENSE-S vectors\nincrease the accuracy of multi-label classification tasks by up to 50% and\nlink-prediction tasks by up to 78% under a variety of scenarios using real\ndatasets. Based on SENSE-S, we next propose generic SENSE to compute composite\nvectors that represent a sequence of nodes, where preserving the node order is\nimportant. We prove that this approach is efficient in embedding node\nsequences, and our experiments on real data confirm its high accuracy in node\norder decoding.\n", "versions": [{"version": "v1", "created": "Thu, 7 Nov 2019 16:21:40 GMT"}], "update_date": "2019-11-11", "authors_parsed": [["Rallapalli", "Swati", ""], ["Ma", "Liang", ""], ["Srivatsa", "Mudhakar", ""], ["Swami", "Ananthram", ""], ["Kwon", "Heesung", ""], ["Bent", "Graham", ""], ["Simpkin", "Christopher", ""]]}, {"id": "1911.02971", "submitter": "Zhuosheng Zhang", "authors": "Zhuosheng Zhang, Rui Wang, Kehai Chen, Masao Utiyama, Eiichiro Sumita,\n  Hai Zhao", "title": "Probing Contextualized Sentence Representations with Visual Awareness", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a universal framework to model contextualized sentence\nrepresentations with visual awareness that is motivated to overcome the\nshortcomings of the multimodal parallel data with manual annotations. For each\nsentence, we first retrieve a diversity of images from a shared cross-modal\nembedding space, which is pre-trained on a large-scale of text-image pairs.\nThen, the texts and images are respectively encoded by transformer encoder and\nconvolutional neural network. The two sequences of representations are further\nfused by a simple and effective attention layer. The architecture can be easily\napplied to text-only natural language processing tasks without manually\nannotating multimodal parallel corpora. We apply the proposed method on three\ntasks, including neural machine translation, natural language inference and\nsequence labeling and experimental results verify the effectiveness.\n", "versions": [{"version": "v1", "created": "Thu, 7 Nov 2019 16:34:31 GMT"}], "update_date": "2019-11-12", "authors_parsed": [["Zhang", "Zhuosheng", ""], ["Wang", "Rui", ""], ["Chen", "Kehai", ""], ["Utiyama", "Masao", ""], ["Sumita", "Eiichiro", ""], ["Zhao", "Hai", ""]]}, {"id": "1911.02972", "submitter": "Jiezhong Qiu", "authors": "Jiezhong Qiu, Hao Ma, Omer Levy, Scott Wen-tau Yih, Sinong Wang, Jie\n  Tang", "title": "Blockwise Self-Attention for Long Document Understanding", "comments": "Accepted at Findings of EMNLP'20 and SustaiNLP 2020 at EMNLP'20, 12\n  pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present BlockBERT, a lightweight and efficient BERT model for better\nmodeling long-distance dependencies. Our model extends BERT by introducing\nsparse block structures into the attention matrix to reduce both memory\nconsumption and training/inference time, which also enables attention heads to\ncapture either short- or long-range contextual information. We conduct\nexperiments on language model pre-training and several benchmark question\nanswering datasets with various paragraph lengths. BlockBERT uses 18.7-36.1%\nless memory and 12.0-25.1% less time to learn the model. During testing,\nBlockBERT saves 27.8% inference time, while having comparable and sometimes\nbetter prediction accuracy, compared to an advanced BERT-based model, RoBERTa.\n", "versions": [{"version": "v1", "created": "Thu, 7 Nov 2019 16:35:53 GMT"}, {"version": "v2", "created": "Sun, 1 Nov 2020 12:48:03 GMT"}], "update_date": "2020-11-03", "authors_parsed": [["Qiu", "Jiezhong", ""], ["Ma", "Hao", ""], ["Levy", "Omer", ""], ["Yih", "Scott Wen-tau", ""], ["Wang", "Sinong", ""], ["Tang", "Jie", ""]]}, {"id": "1911.02986", "submitter": "Shatian Wang", "authors": "Shatian Wang, Zhen Xu, Van-Anh Truong", "title": "Beyond Adaptive Submodularity: Adaptive Influence Maximization with\n  Intermediary Constraints", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG math.OC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider a brand with a given budget that wants to promote a product over\nmultiple rounds of influencer marketing. In each round, it commissions an\ninfluencer to promote the product over a social network, and then observes the\nsubsequent diffusion of the product before adaptively choosing the next\ninfluencer to commission. This process terminates when the budget is exhausted.\nWe assume that the diffusion process follows the popular Independent Cascade\nmodel. We also consider an online learning setting, where the brand initially\ndoes not know the diffusion parameters associated with the model, and has to\ngradually learn the parameters over time.\n  Unlike in existing models, the rounds in our model are correlated through an\nintermediary constraint: each user can be commissioned for an unlimited number\nof times. However, each user will spread influence without commission at most\nonce. Due to this added constraint, the order in which the influencers are\nchosen can change the influence spread, making obsolete existing analysis\ntechniques that based on the notion of adaptive submodularity. We devise a\nsample path analysis to prove that a greedy policy that knows the diffusion\nparameters achieves at least $1-1/e - \\epsilon$ times the expected reward of\nthe optimal policy.\n  In the online-learning setting, we are the first to consider a truly adaptive\ndecision making framework, rather than assuming independent epochs, and\nadaptivity only within epochs. Under mild assumptions, we derive a regret bound\nfor our algorithm. In our numerical experiments, we simulate information\ndiffusions on four Twitter sub-networks, and compare our UCB-based learning\nalgorithms with several baseline adaptive seeding strategies. Our learning\nalgorithm consistently outperforms the baselines and achieves rewards close to\nthe greedy policy that knows the true diffusion parameters.\n", "versions": [{"version": "v1", "created": "Fri, 8 Nov 2019 02:09:50 GMT"}], "update_date": "2019-11-11", "authors_parsed": [["Wang", "Shatian", ""], ["Xu", "Zhen", ""], ["Truong", "Van-Anh", ""]]}, {"id": "1911.02987", "submitter": "Zihan Jiang", "authors": "Zihan Jiang, Jiansong Li, Jiangfeng Zhan", "title": "The Pitfall of Evaluating Performance on Emerging AI Accelerators", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.PF cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In recent years, domain-specific hardware has brought significant performance\nimprovements in deep learning (DL). Both industry and academia only focus on\nthroughput when evaluating these AI accelerators, which usually are custom\nASICs deployed in datacenter to speed up the inference phase of DL workloads.\nPursuing higher hardware throughput such as OPS (Operation Per Second) using\nvarious optimizations seems to be their main design target. However, they\nignore the importance of accuracy in the DL nature. Motivated by this, this\npaper argue that a single throughput metric can not comprehensively reflect the\nreal-world performance of AI accelerators. To reveal this pitfall, we evaluates\nseveral frequently-used optimizations on a typical AI accelerator and\nquantifies their impact on accuracy and throughout under representative DL\ninference workloads. Based on our experimental results, we find that some\noptimizations cause significant loss on accuracy in some workloads, although it\ncan improves the throughout. Furthermore, our results show the importance of\nend-to-end evaluation in DL.\n", "versions": [{"version": "v1", "created": "Fri, 8 Nov 2019 02:13:21 GMT"}], "update_date": "2019-11-11", "authors_parsed": [["Jiang", "Zihan", ""], ["Li", "Jiansong", ""], ["Zhan", "Jiangfeng", ""]]}, {"id": "1911.02991", "submitter": "Joy Bose", "authors": "Joy Bose, Sumanta Mukherjee", "title": "Semi-Supervised Method using Gaussian Random Fields for Boilerplate\n  Removal in Web Browsers", "comments": "4 pages, 1 figure, IEEE INDICON conference", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.IR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Boilerplate removal refers to the problem of removing noisy content from a\nwebpage such as ads and extracting relevant content that can be used by various\nservices. This can be useful in several features in web browsers such as ad\nblocking, accessibility tools such as read out loud, translation, summarization\netc. In order to create a training dataset to train a model for boilerplate\ndetection and removal, labeling or tagging webpage data manually can be tedious\nand time consuming. Hence, a semi-supervised model, in which some of the\nwebpage elements are labeled manually and labels for others are inferred based\non some parameters, can be useful. In this paper we present a solution for\nextraction of relevant content from a webpage that relies on semi-supervised\nlearning using Gaussian Random Fields. We first represent the webpage as a\ngraph, with text elements as nodes and the edge weights representing similarity\nbetween nodes. After this, we label a few nodes in the graph using heuristics\nand label the remaining nodes by a weighted measure of similarity to the\nalready labeled nodes. We describe the system architecture and a few\npreliminary results on a dataset of webpages.\n", "versions": [{"version": "v1", "created": "Fri, 8 Nov 2019 02:23:33 GMT"}], "update_date": "2019-11-11", "authors_parsed": [["Bose", "Joy", ""], ["Mukherjee", "Sumanta", ""]]}, {"id": "1911.02996", "submitter": "Elijah Bolluyt", "authors": "Elijah D. Bolluyt, Cristina Comaniciu", "title": "Collapse Resistant Deep Convolutional GAN for Multi-Object Image\n  Generation", "comments": "Accepted to IEEE International Conference on Machine Learning and\n  Applications 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV eess.IV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This work introduces a novel system for the generation of images that contain\nmultiple classes of objects. Recent work in Generative Adversarial Networks\nhave produced high quality images, but many focus on generating images of a\nsingle object or set of objects. Our system addresses the task of image\ngeneration conditioned on a list of desired classes to be included in a single\nimage. This enables our system to generate images with any given combination of\nobjects, all composed into a visually realistic natural image. The system\nlearns the interrelationships of all classes represented in a dataset, and can\ngenerate diverse samples including a set of these classes. It displays the\nability to arrange these objects together, accounting for occlusions and\ninter-object spatial relations that characterize complex natural images. To\naccomplish this, we introduce a novel architecture based on Conditional Deep\nConvolutional GANs that is stabilized against collapse relative to both mode\nand condition. The system learns to rectify mode collapse during training,\nself-correcting to avoid suboptimal generation modes.\n", "versions": [{"version": "v1", "created": "Fri, 8 Nov 2019 02:27:23 GMT"}], "update_date": "2019-11-11", "authors_parsed": [["Bolluyt", "Elijah D.", ""], ["Comaniciu", "Cristina", ""]]}, {"id": "1911.03010", "submitter": "Mehdi Ghatee Dr.", "authors": "Mohammad Mahdi Bejani and Mehdi Ghatee", "title": "Regularized Deep Networks in Intelligent Transportation Systems: A\n  Taxonomy and a Case Study", "comments": "A review paper with 8 pages, 2 figures, and 2 tables, submitted to\n  18th International Conference on Traffic & Transportation Engineering,\n  Tehran, February 25-27, 2020. Artificial Intelligence Review (2021)", "journal-ref": null, "doi": "10.1007/s10462-021-09975-1", "report-no": null, "categories": "cs.LG cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Intelligent Transportation Systems (ITS) are much correlated with data\nscience mechanisms. Among the different correlation branches, this paper\nfocuses on the neural network learning models. Some of the considered models\nare shallow and they get some user-defined features and learn the relationship,\nwhile deep models extract the necessary features before learning by themselves.\nBoth of these paradigms are utilized in the recent intelligent transportation\nsystems (ITS) to support decision-making by the aid of different operations\nsuch as frequent patterns mining, regression, clustering, and classification.\nWhen these learners cannot generalize the results and just memorize the\ntraining samples, they fail to support the necessities. In these cases, the\ntesting error is bigger than the training error. This phenomenon is addressed\nas overfitting in the literature. Because, this issue decreases the reliability\nof learning systems, in ITS applications, we cannot use such over-fitted\nmachine learning models for different tasks such as traffic prediction, the\nsignal controlling, safety applications, emergency responses, mode detection,\ndriving evaluation, etc. Besides, deep learning models use a great number of\nhyper-parameters, the overfitting in deep models is more attention. To solve\nthis problem, the regularized learning models can be followed. The aim of this\npaper is to review the approaches presented to regularize the overfitting in\ndifferent categories of ITS studies. Then, we give a case study on driving\nsafety that uses a regularized version of the convolutional neural network\n(CNN).\n", "versions": [{"version": "v1", "created": "Fri, 8 Nov 2019 03:03:11 GMT"}], "update_date": "2021-03-10", "authors_parsed": [["Bejani", "Mohammad Mahdi", ""], ["Ghatee", "Mehdi", ""]]}, {"id": "1911.03011", "submitter": "Qinbin Li", "authors": "Qinbin Li, Zeyi Wen, Bingsheng He", "title": "Adaptive Kernel Value Caching for SVM Training", "comments": "Accepted by IEEE Transactions on Neural Networks and Learning Systems\n  (TNNLS)", "journal-ref": null, "doi": "10.1109/TNNLS.2019.2944562", "report-no": null, "categories": "cs.LG cs.PF stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Support Vector Machines (SVMs) can solve structured multi-output learning\nproblems such as multi-label classification, multiclass classification and\nvector regression. SVM training is expensive especially for large and high\ndimensional datasets. The bottleneck of the SVM training often lies in the\nkernel value computation. In many real-world problems, the same kernel values\nare used in many iterations during the training, which makes the caching of\nkernel values potentially useful. The majority of the existing studies simply\nadopt the LRU (least recently used) replacement strategy for caching kernel\nvalues. However, as we analyze in this paper, the LRU strategy generally\nachieves high hit ratio near the final stage of the training, but does not work\nwell in the whole training process. Therefore, we propose a new caching\nstrategy called EFU (less frequently used) which replaces the less frequently\nused kernel values that enhances LFU (least frequently used). Our experimental\nresults show that EFU often has 20\\% higher hit ratio than LRU in the training\nwith the Gaussian kernel. To further optimize the strategy, we propose a\ncaching strategy called HCST (hybrid caching for the SVM training), which has a\nnovel mechanism to automatically adapt the better caching strategy in the\ndifferent stages of the training. We have integrated the caching strategy into\nThunderSVM, a recent SVM library on many-core processors. Our experiments show\nthat HCST adaptively achieves high hit ratios with little runtime overhead\namong different problems including multi-label classification, multiclass\nclassification and regression problems. Compared with other existing caching\nstrategies, HCST achieves 20\\% more reduction in training time on average.\n", "versions": [{"version": "v1", "created": "Fri, 8 Nov 2019 03:06:42 GMT"}], "update_date": "2019-11-11", "authors_parsed": [["Li", "Qinbin", ""], ["Wen", "Zeyi", ""], ["He", "Bingsheng", ""]]}, {"id": "1911.03014", "submitter": "Simeng Han", "authors": "Simeng Han, Xiang Lin and Shafiq Joty", "title": "Resurrecting Submodularity for Neural Text Generation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Submodularity is desirable for a variety of objectives in content selection\nwhere the current neural encoder-decoder framework is inadequate. However, it\nhas so far not been explored in the neural encoder-decoder system for text\ngeneration. In this work, we define diminishing attentions with submodular\nfunctions and in turn, prove the submodularity of the effective neural\ncoverage. The greedy algorithm approximating the solution to the submodular\nmaximization problem is not suited to attention score optimization in\nauto-regressive generation. Therefore instead of following how submodular\nfunction has been widely used, we propose a simplified yet principled solution.\nThe resulting attention module offers an architecturally simple and empirically\neffective method to improve the coverage of neural text generation. We run\nexperiments on three directed text generation tasks with different levels of\nrecovering rate, across two modalities, three different neural model\narchitectures and two training strategy variations. The results and analyses\ndemonstrate that our method generalizes well across these settings, produces\ntexts of good quality and outperforms state-of-the-art baselines.\n", "versions": [{"version": "v1", "created": "Fri, 8 Nov 2019 03:17:54 GMT"}, {"version": "v2", "created": "Sat, 13 Jun 2020 16:47:33 GMT"}, {"version": "v3", "created": "Sun, 4 Oct 2020 08:09:57 GMT"}], "update_date": "2020-10-06", "authors_parsed": [["Han", "Simeng", ""], ["Lin", "Xiang", ""], ["Joty", "Shafiq", ""]]}, {"id": "1911.03019", "submitter": "Dave Biagioni", "authors": "David Biagioni, Peter Graf, Xiangyu Zhang, Ahmed Zamzam, Kyri Baker,\n  Jennifer King", "title": "Learning-Accelerated ADMM for Distributed Optimal Power Flow", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.OC cs.LG cs.SY eess.SY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a novel data-driven method to accelerate the convergence of\nAlternating Direction Method of Multipliers (ADMM) for solving distributed DC\noptimal power flow (DC-OPF) where lines are shared between independent network\npartitions. Using previous observations of ADMM trajectories for a given system\nunder varying load, the method trains a recurrent neural network (RNN) to\npredict the converged values of dual and consensus variables. Given a new\nrealization of system load, a small number of initial ADMM iterations is taken\nas input to infer the converged values and directly inject them into the\niteration. We empirically demonstrate that the online injection of these values\ninto the ADMM iteration accelerates convergence by a significant factor for\npartitioned 14-, 118- and 2848-bus test systems under differing load scenarios.\nThe proposed method has several advantages: it maintains the security of\nprivate decision variables inherent in consensus ADMM; inference is fast and so\nmay be used in online settings; RNN-generated predictions can dramatically\nimprove time to convergence but, by construction, can never result in\ninfeasible ADMM subproblems; it can be easily integrated into existing software\nimplementations. While we focus on the ADMM formulation of distributed DC-OPF\nin this paper, the ideas presented are naturally extended to other distributed\noptimization problems.\n", "versions": [{"version": "v1", "created": "Fri, 8 Nov 2019 03:40:35 GMT"}, {"version": "v2", "created": "Tue, 15 Sep 2020 17:34:12 GMT"}], "update_date": "2020-09-16", "authors_parsed": [["Biagioni", "David", ""], ["Graf", "Peter", ""], ["Zhang", "Xiangyu", ""], ["Zamzam", "Ahmed", ""], ["Baker", "Kyri", ""], ["King", "Jennifer", ""]]}, {"id": "1911.03022", "submitter": "Qiyuan Hu", "authors": "Qiyuan Hu, Heather M. Whitney, Maryellen L. Giger", "title": "Transfer Learning in 4D for Breast Cancer Diagnosis using Dynamic\n  Contrast-Enhanced Magnetic Resonance Imaging", "comments": "Machine Learning for Health (ML4H) at NeurIPS 2019 - Extended\n  Abstract", "journal-ref": null, "doi": null, "report-no": null, "categories": "physics.med-ph cs.CV cs.LG eess.IV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep transfer learning using dynamic contrast-enhanced magnetic resonance\nimaging (DCE-MRI) has shown strong predictive power in characterization of\nbreast lesions. However, pretrained convolutional neural networks (CNNs)\nrequire 2D inputs, limiting the ability to exploit the rich 4D (volumetric and\ntemporal) image information inherent in DCE-MRI that is clinically valuable for\nlesion assessment. Training 3D CNNs from scratch, a common method to utilize\nhigh-dimensional information in medical images, is computationally expensive\nand is not best suited for moderately sized healthcare datasets. Therefore, we\npropose a novel approach using transfer learning that incorporates the 4D\ninformation from DCE-MRI, where volumetric information is collapsed at feature\nlevel by max pooling along the projection perpendicular to the transverse\nslices and the temporal information is contained either in second-post contrast\nsubtraction images. Our methodology yielded an area under the receiver\noperating characteristic curve of 0.89+/-0.01 on a dataset of 1161 breast\nlesions, significantly outperforming a previous approach that incorporates the\n4D information in DCE-MRI by the use of maximum intensity projection (MIP)\nimages.\n", "versions": [{"version": "v1", "created": "Fri, 8 Nov 2019 03:45:24 GMT"}], "update_date": "2019-11-11", "authors_parsed": [["Hu", "Qiyuan", ""], ["Whitney", "Heather M.", ""], ["Giger", "Maryellen L.", ""]]}, {"id": "1911.03029", "submitter": "Wei-Hong Lin", "authors": "Wei-Hong Lin and Jia-Xing Zhong and Shan Liu and Thomas Li and Ge Li", "title": "RoIMix: Proposal-Fusion among Multiple Images for Underwater Object\n  Detection", "comments": "ICASSP 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG eess.IV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Generic object detection algorithms have proven their excellent performance\nin recent years. However, object detection on underwater datasets is still less\nexplored. In contrast to generic datasets, underwater images usually have color\nshift and low contrast; sediment would cause blurring in underwater images. In\naddition, underwater creatures often appear closely to each other on images due\nto their living habits. To address these issues, our work investigates\naugmentation policies to simulate overlapping, occluded and blurred objects,\nand we construct a model capable of achieving better generalization. We propose\nan augmentation method called RoIMix, which characterizes interactions among\nimages. Proposals extracted from different images are mixed together. Previous\ndata augmentation methods operate on a single image while we apply RoIMix to\nmultiple images to create enhanced samples as training data. Experiments show\nthat our proposed method improves the performance of region-based object\ndetectors on both Pascal VOC and URPC datasets.\n", "versions": [{"version": "v1", "created": "Fri, 8 Nov 2019 03:56:22 GMT"}, {"version": "v2", "created": "Tue, 24 Mar 2020 14:02:31 GMT"}], "update_date": "2020-03-25", "authors_parsed": [["Lin", "Wei-Hong", ""], ["Zhong", "Jia-Xing", ""], ["Liu", "Shan", ""], ["Li", "Thomas", ""], ["Li", "Ge", ""]]}, {"id": "1911.03030", "submitter": "Chuan Guo", "authors": "Chuan Guo, Tom Goldstein, Awni Hannun, Laurens van der Maaten", "title": "Certified Data Removal from Machine Learning Models", "comments": "Accepted to ICML 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Good data stewardship requires removal of data at the request of the data's\nowner. This raises the question if and how a trained machine-learning model,\nwhich implicitly stores information about its training data, should be affected\nby such a removal request. Is it possible to \"remove\" data from a\nmachine-learning model? We study this problem by defining certified removal: a\nvery strong theoretical guarantee that a model from which data is removed\ncannot be distinguished from a model that never observed the data to begin\nwith. We develop a certified-removal mechanism for linear classifiers and\nempirically study learning settings in which this mechanism is practical.\n", "versions": [{"version": "v1", "created": "Fri, 8 Nov 2019 03:57:41 GMT"}, {"version": "v2", "created": "Mon, 11 Nov 2019 06:41:24 GMT"}, {"version": "v3", "created": "Tue, 11 Feb 2020 19:46:46 GMT"}, {"version": "v4", "created": "Thu, 13 Aug 2020 00:01:30 GMT"}, {"version": "v5", "created": "Fri, 14 Aug 2020 20:57:16 GMT"}], "update_date": "2020-08-18", "authors_parsed": [["Guo", "Chuan", ""], ["Goldstein", "Tom", ""], ["Hannun", "Awni", ""], ["van der Maaten", "Laurens", ""]]}, {"id": "1911.03034", "submitter": "Shuo Yang", "authors": "Shuo Yang, Yanyao Shen, Sujay Sanghavi", "title": "Interaction Hard Thresholding: Consistent Sparse Quadratic Regression in\n  Sub-quadratic Time and Space", "comments": "Accepted by NeurIPS 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Quadratic regression involves modeling the response as a (generalized) linear\nfunction of not only the features $x^{j_1}$ but also of quadratic terms\n$x^{j_1}x^{j_2}$. The inclusion of such higher-order \"interaction terms\" in\nregression often provides an easy way to increase accuracy in\nalready-high-dimensional problems. However, this explodes the problem dimension\nfrom linear $O(p)$ to quadratic $O(p^2)$, and it is common to look for sparse\ninteractions (typically via heuristics). In this paper, we provide a new\nalgorithm - Interaction Hard Thresholding (IntHT) which is the first one to\nprovably accurately solve this problem in sub-quadratic time and space. It is a\nvariant of Iterative Hard Thresholding; one that uses the special quadratic\nstructure to devise a new way to (approx.) extract the top elements of a $p^2$\nsize gradient in sub-$p^2$ time and space. Our main result is to theoretically\nprove that, in spite of the many speedup-related approximations, IntHT linearly\nconverges to a consistent estimate under standard high-dimensional sparse\nrecovery assumptions. We also demonstrate its value via synthetic experiments.\nMoreover, we numerically show that IntHT can be extended to higher-order\nregression problems, and also theoretically analyze an SVRG variant of IntHT.\n", "versions": [{"version": "v1", "created": "Fri, 8 Nov 2019 04:02:38 GMT"}], "update_date": "2019-11-11", "authors_parsed": [["Yang", "Shuo", ""], ["Shen", "Yanyao", ""], ["Sanghavi", "Sujay", ""]]}, {"id": "1911.03038", "submitter": "Yihan Jiang", "authors": "Yihan Jiang, Hyeji Kim, Himanshu Asnani, Sreeram Kannan, Sewoong Oh,\n  Pramod Viswanath", "title": "Turbo Autoencoder: Deep learning based channel codes for point-to-point\n  communication channels", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IT cs.LG eess.SP math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Designing codes that combat the noise in a communication medium has remained\na significant area of research in information theory as well as wireless\ncommunications. Asymptotically optimal channel codes have been developed by\nmathematicians for communicating under canonical models after over 60 years of\nresearch. On the other hand, in many non-canonical channel settings, optimal\ncodes do not exist and the codes designed for canonical models are adapted via\nheuristics to these channels and are thus not guaranteed to be optimal. In this\nwork, we make significant progress on this problem by designing a fully\nend-to-end jointly trained neural encoder and decoder, namely, Turbo\nAutoencoder (TurboAE), with the following contributions: ($a$) under moderate\nblock lengths, TurboAE approaches state-of-the-art performance under canonical\nchannels; ($b$) moreover, TurboAE outperforms the state-of-the-art codes under\nnon-canonical settings in terms of reliability. TurboAE shows that the\ndevelopment of channel coding design can be automated via deep learning, with\nnear-optimal performance.\n", "versions": [{"version": "v1", "created": "Fri, 8 Nov 2019 04:14:56 GMT"}], "update_date": "2019-11-11", "authors_parsed": [["Jiang", "Yihan", ""], ["Kim", "Hyeji", ""], ["Asnani", "Himanshu", ""], ["Kannan", "Sreeram", ""], ["Oh", "Sewoong", ""], ["Viswanath", "Pramod", ""]]}, {"id": "1911.03043", "submitter": "Holden Lee", "authors": "Rong Ge, Holden Lee, Jianfeng Lu", "title": "Estimating Normalizing Constants for Log-Concave Distributions:\n  Algorithms and Lower Bounds", "comments": "46 pages", "journal-ref": "Proceedings of the 52nd Annual ACM SIGACT Symposium on Theory of\n  Computing. 2020. p. 579-586", "doi": null, "report-no": null, "categories": "cs.DS cs.LG math.PR math.ST stat.ML stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Estimating the normalizing constant of an unnormalized probability\ndistribution has important applications in computer science, statistical\nphysics, machine learning, and statistics. In this work, we consider the\nproblem of estimating the normalizing constant $Z=\\int_{\\mathbb{R}^d}\ne^{-f(x)}\\,\\mathrm{d}x$ to within a multiplication factor of $1 \\pm\n\\varepsilon$ for a $\\mu$-strongly convex and $L$-smooth function $f$, given\nquery access to $f(x)$ and $\\nabla f(x)$. We give both algorithms and\nlowerbounds for this problem. Using an annealing algorithm combined with a\nmultilevel Monte Carlo method based on underdamped Langevin dynamics, we show\nthat $\\widetilde{\\mathcal{O}}\\Bigl(\\frac{d^{4/3}\\kappa +\nd^{7/6}\\kappa^{7/6}}{\\varepsilon^2}\\Bigr)$ queries to $\\nabla f$ are\nsufficient, where $\\kappa= L / \\mu$ is the condition number. Moreover, we\nprovide an information theoretic lowerbound, showing that at least\n$\\frac{d^{1-o(1)}}{\\varepsilon^{2-o(1)}}$ queries are necessary. This provides\na first nontrivial lowerbound for the problem.\n", "versions": [{"version": "v1", "created": "Fri, 8 Nov 2019 04:32:11 GMT"}, {"version": "v2", "created": "Tue, 23 Jun 2020 19:22:32 GMT"}], "update_date": "2020-06-25", "authors_parsed": [["Ge", "Rong", ""], ["Lee", "Holden", ""], ["Lu", "Jianfeng", ""]]}, {"id": "1911.03044", "submitter": "Min Xu", "authors": "Xiangrui Zeng, Min Xu", "title": "AITom: Open-source AI platform for cryo-electron tomography data\n  analysis", "comments": "2 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.QM cs.LG eess.IV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Cryo-electron tomography (cryo-ET) is an emerging technology for the 3D\nvisualization of structural organizations and interactions of subcellular\ncomponents at near-native state and sub-molecular resolution. Tomograms\ncaptured by cryo-ET contain heterogeneous structures representing the complex\nand dynamic subcellular environment. Since the structures are not purified or\nfluorescently labeled, the spatial organization and interaction between both\nthe known and unknown structures can be studied in their native environment.\nThe rapid advances of cryo-electron tomography (cryo-ET) have generated\nabundant 3D cellular imaging data. However, the systematic localization,\nidentification, segmentation, and structural recovery of the subcellular\ncomponents require efficient and accurate large-scale image analysis methods.\nWe introduce AITom, an open-source artificial intelligence platform for cryo-ET\nresearchers. AITom provides many public as well as in-house algorithms for\nperforming cryo-ET data analysis through both the traditional template-based or\ntemplate-free approach and the deep learning approach. AITom also supports\nremote interactive analysis. Comprehensive tutorials for each analysis module\nare provided to guide the user through. We welcome researchers and developers\nto join this collaborative open-source software development project.\nAvailability: https://github.com/xulabs/aitom\n", "versions": [{"version": "v1", "created": "Fri, 8 Nov 2019 04:33:18 GMT"}, {"version": "v2", "created": "Fri, 30 Oct 2020 17:44:31 GMT"}], "update_date": "2020-11-02", "authors_parsed": [["Zeng", "Xiangrui", ""], ["Xu", "Min", ""]]}, {"id": "1911.03053", "submitter": "Michael Rotman", "authors": "Michael Rotman, Lior Wolf", "title": "Electric Analog Circuit Design with Hypernetworks and a Differential\n  Simulator", "comments": "The paper will be presented at ICASSP 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG eess.SP stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The manual design of analog circuits is a tedious task of parameter tuning\nthat requires hours of work by human experts. In this work, we make a\nsignificant step towards a fully automatic design method that is based on deep\nlearning. The method selects the components and their configuration, as well as\ntheir numerical parameters. By contrast, the current literature methods are\nlimited to the parameter fitting part only. A two-stage network is used, which\nfirst generates a chain of circuit components and then predicts their\nparameters. A hypernetwork scheme is used in which a weight generating network,\nwhich is conditioned on the circuit's power spectrum, produces the parameters\nof a primal RNN network that places the components. A differential simulator is\nused for refining the numerical values of the components. We show that our\nmodel provides an efficient design solution, and is superior to alternative\nsolutions.\n", "versions": [{"version": "v1", "created": "Fri, 8 Nov 2019 05:13:05 GMT"}, {"version": "v2", "created": "Mon, 10 Feb 2020 13:36:09 GMT"}], "update_date": "2020-02-11", "authors_parsed": [["Rotman", "Michael", ""], ["Wolf", "Lior", ""]]}, {"id": "1911.03054", "submitter": "Suryabhan Singh Hada", "authors": "Arman Zharmagambetov and Suryabhan Singh Hada and Miguel \\'A.\n  Carreira-Perpi\\~n\\'an and Magzhan Gabidolla", "title": "An Experimental Comparison of Old and New Decision Tree Algorithms", "comments": "12 pages, 0 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper presents a detailed comparison of a recently proposed algorithm\nfor optimizing decision trees, tree alternating optimization (TAO), with other\npopular, established algorithms. We compare their performance on a number of\nclassification and regression datasets of various complexity, different size\nand dimensionality, across different performance factors: accuracy and tree\nsize (in terms of the number of leaves or the depth of the tree). We find that\nTAO achieves higher accuracy in nearly all datasets, often by a large margin.\n", "versions": [{"version": "v1", "created": "Fri, 8 Nov 2019 05:14:48 GMT"}, {"version": "v2", "created": "Fri, 20 Mar 2020 01:21:47 GMT"}], "update_date": "2020-03-23", "authors_parsed": [["Zharmagambetov", "Arman", ""], ["Hada", "Suryabhan Singh", ""], ["Carreira-Perpi\u00f1\u00e1n", "Miguel \u00c1.", ""], ["Gabidolla", "Magzhan", ""]]}, {"id": "1911.03063", "submitter": "Jiawei Zhang", "authors": "Jiawei Zhang, Jie Ding, Yuhong Yang", "title": "A Binary Regression Adaptive Goodness-of-fit Test (BAGofT)", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The Pearson's $\\chi^2$ test and residual deviance test are two classical\ngoodness-of-fit tests for binary regression models such as logistic regression.\nThese two tests cannot be applied when we have one or more continuous\ncovariates in the data, a quite common situation in practice. In that case, the\nmost widely used approach is the Hosmer-Lemeshow test, which partitions the\ncovariate space into groups according to quantiles of the fitted probabilities\nfrom all the observations. However, its grouping scheme is not flexible enough\nto explore how to adversarially partition the data space in order to enhance\nthe power. In this work, we propose a new methodology, named binary regression\nadaptive grouping goodness-of-fit test (BAGofT), to address the above concern.\nIt is a two-stage solution where the first stage adaptively selects candidate\npartitions using \"training\" data, and the second stage performs $\\chi^2$ tests\nwith necessary corrections based on \"test\" data. A proper data splitting\nensures that the test has desirable size and power properties. From our\nexperimental results, BAGofT performs much better than Hosmer-Lemeshow test in\nmany situations.\n", "versions": [{"version": "v1", "created": "Fri, 8 Nov 2019 05:55:05 GMT"}], "update_date": "2019-11-11", "authors_parsed": [["Zhang", "Jiawei", ""], ["Ding", "Jie", ""], ["Yang", "Yuhong", ""]]}, {"id": "1911.03064", "submitter": "Po-Sen Huang", "authors": "Po-Sen Huang, Huan Zhang, Ray Jiang, Robert Stanforth, Johannes Welbl,\n  Jack Rae, Vishal Maini, Dani Yogatama, Pushmeet Kohli", "title": "Reducing Sentiment Bias in Language Models via Counterfactual Evaluation", "comments": "Accepted in the Findings of EMNLP, 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.CY cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Advances in language modeling architectures and the availability of large\ntext corpora have driven progress in automatic text generation. While this\nresults in models capable of generating coherent texts, it also prompts models\nto internalize social biases present in the training corpus. This paper aims to\nquantify and reduce a particular type of bias exhibited by language models:\nbias in the sentiment of generated text. Given a conditioning context (e.g., a\nwriting prompt) and a language model, we analyze if (and how) the sentiment of\nthe generated text is affected by changes in values of sensitive attributes\n(e.g., country names, occupations, genders) in the conditioning context using a\nform of counterfactual evaluation. We quantify sentiment bias by adopting\nindividual and group fairness metrics from the fair machine learning\nliterature, and demonstrate that large-scale models trained on two different\ncorpora (news articles, and Wikipedia) exhibit considerable levels of bias. We\nthen propose embedding and sentiment prediction-derived regularization on the\nlanguage model's latent representations. The regularizations improve fairness\nmetrics while retaining comparable levels of perplexity and semantic\nsimilarity.\n", "versions": [{"version": "v1", "created": "Fri, 8 Nov 2019 05:56:01 GMT"}, {"version": "v2", "created": "Thu, 30 Apr 2020 17:51:20 GMT"}, {"version": "v3", "created": "Thu, 8 Oct 2020 17:58:35 GMT"}], "update_date": "2020-10-09", "authors_parsed": [["Huang", "Po-Sen", ""], ["Zhang", "Huan", ""], ["Jiang", "Ray", ""], ["Stanforth", "Robert", ""], ["Welbl", "Johannes", ""], ["Rae", "Jack", ""], ["Maini", "Vishal", ""], ["Yogatama", "Dani", ""], ["Kohli", "Pushmeet", ""]]}, {"id": "1911.03070", "submitter": "Mozhi Zhang", "authors": "Michelle Yuan, Mozhi Zhang, Benjamin Van Durme, Leah Findlater, Jordan\n  Boyd-Graber", "title": "Interactive Refinement of Cross-Lingual Word Embeddings", "comments": "EMNLP 2020; first two authors contribute equally", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Cross-lingual word embeddings transfer knowledge between languages: models\ntrained on high-resource languages can predict in low-resource languages. We\nintroduce CLIME, an interactive system to quickly refine cross-lingual word\nembeddings for a given classification problem. First, CLIME ranks words by\ntheir salience to the downstream task. Then, users mark similarity between\nkeywords and their nearest neighbors in the embedding space. Finally, CLIME\nupdates the embeddings using the annotations. We evaluate CLIME on identifying\nhealth-related text in four low-resource languages: Ilocano, Sinhalese,\nTigrinya, and Uyghur. Embeddings refined by CLIME capture more nuanced word\nsemantics and have higher test accuracy than the original embeddings. CLIME\noften improves accuracy faster than an active learning baseline and can be\neasily combined with active learning to improve results.\n", "versions": [{"version": "v1", "created": "Fri, 8 Nov 2019 06:07:25 GMT"}, {"version": "v2", "created": "Wed, 8 Apr 2020 17:58:45 GMT"}, {"version": "v3", "created": "Wed, 7 Oct 2020 17:49:50 GMT"}, {"version": "v4", "created": "Thu, 3 Jun 2021 17:20:11 GMT"}], "update_date": "2021-06-04", "authors_parsed": [["Yuan", "Michelle", ""], ["Zhang", "Mozhi", ""], ["Van Durme", "Benjamin", ""], ["Findlater", "Leah", ""], ["Boyd-Graber", "Jordan", ""]]}, {"id": "1911.03078", "submitter": "Xu Li", "authors": "Xu Li, Jinghua Zhong, Xixin Wu, Jianwei Yu, Xunying Liu and Helen Meng", "title": "Adversarial Attacks on GMM i-vector based Speaker Verification Systems", "comments": "Accepted by ICASSP 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.AS cs.CL cs.CR cs.LG eess.SP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This work investigates the vulnerability of Gaussian Mixture Model (GMM)\ni-vector based speaker verification systems to adversarial attacks, and the\ntransferability of adversarial samples crafted from GMM i-vector based systems\nto x-vector based systems. In detail, we formulate the GMM i-vector system as a\nscoring function of enrollment and testing utterance pairs. Then we leverage\nthe fast gradient sign method (FGSM) to optimize testing utterances for\nadversarial samples generation. These adversarial samples are used to attack\nboth GMM i-vector and x-vector systems. We measure the system vulnerability by\nthe degradation of equal error rate and false acceptance rate. Experiment\nresults show that GMM i-vector systems are seriously vulnerable to adversarial\nattacks, and the crafted adversarial samples prove to be transferable and pose\nthreats to neuralnetwork speaker embedding based systems (e.g. x-vector\nsystems).\n", "versions": [{"version": "v1", "created": "Fri, 8 Nov 2019 06:38:14 GMT"}, {"version": "v2", "created": "Wed, 12 Feb 2020 13:54:35 GMT"}], "update_date": "2020-02-13", "authors_parsed": [["Li", "Xu", ""], ["Zhong", "Jinghua", ""], ["Wu", "Xixin", ""], ["Yu", "Jianwei", ""], ["Liu", "Xunying", ""], ["Meng", "Helen", ""]]}, {"id": "1911.03080", "submitter": "Carlos Eduardo Rosar Kos Lassance", "authors": "Carlos Lassance, Myriam Bontonou, Ghouthi Boukli Hacene, Vincent\n  Gripon, Jian Tang, Antonio Ortega", "title": "Deep geometric knowledge distillation with graphs", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In most cases deep learning architectures are trained disregarding the amount\nof operations and energy consumption. However, some applications, like embedded\nsystems, can be resource-constrained during inference. A popular approach to\nreduce the size of a deep learning architecture consists in distilling\nknowledge from a bigger network (teacher) to a smaller one (student). Directly\ntraining the student to mimic the teacher representation can be effective, but\nit requires that both share the same latent space dimensions. In this work, we\nfocus instead on relative knowledge distillation (RKD), which considers the\ngeometry of the respective latent spaces, allowing for dimension-agnostic\ntransfer of knowledge. Specifically we introduce a graph-based RKD method, in\nwhich graphs are used to capture the geometry of latent spaces. Using classical\ncomputer vision benchmarks, we demonstrate the ability of the proposed method\nto efficiently distillate knowledge from the teacher to the student, leading to\nbetter accuracy for the same budget as compared to existing RKD alternatives.\n", "versions": [{"version": "v1", "created": "Fri, 8 Nov 2019 06:42:07 GMT"}], "update_date": "2019-11-11", "authors_parsed": [["Lassance", "Carlos", ""], ["Bontonou", "Myriam", ""], ["Hacene", "Ghouthi Boukli", ""], ["Gripon", "Vincent", ""], ["Tang", "Jian", ""], ["Ortega", "Antonio", ""]]}, {"id": "1911.03082", "submitter": "Shikhar Vashishth", "authors": "Shikhar Vashishth, Soumya Sanyal, Vikram Nitin, Partha Talukdar", "title": "Composition-based Multi-Relational Graph Convolutional Networks", "comments": "In Proceedings of ICLR 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Graph Convolutional Networks (GCNs) have recently been shown to be quite\nsuccessful in modeling graph-structured data. However, the primary focus has\nbeen on handling simple undirected graphs. Multi-relational graphs are a more\ngeneral and prevalent form of graphs where each edge has a label and direction\nassociated with it. Most of the existing approaches to handle such graphs\nsuffer from over-parameterization and are restricted to learning\nrepresentations of nodes only. In this paper, we propose CompGCN, a novel Graph\nConvolutional framework which jointly embeds both nodes and relations in a\nrelational graph. CompGCN leverages a variety of entity-relation composition\noperations from Knowledge Graph Embedding techniques and scales with the number\nof relations. It also generalizes several of the existing multi-relational GCN\nmethods. We evaluate our proposed method on multiple tasks such as node\nclassification, link prediction, and graph classification, and achieve\ndemonstrably superior results. We make the source code of CompGCN available to\nfoster reproducible research.\n", "versions": [{"version": "v1", "created": "Fri, 8 Nov 2019 06:48:40 GMT"}, {"version": "v2", "created": "Sat, 18 Jan 2020 22:50:01 GMT"}], "update_date": "2020-01-22", "authors_parsed": [["Vashishth", "Shikhar", ""], ["Sanyal", "Soumya", ""], ["Nitin", "Vikram", ""], ["Talukdar", "Partha", ""]]}, {"id": "1911.03086", "submitter": "Vajira Thambawita", "authors": "Vajira Thambawita, P{\\aa}l Halvorsen, Hugo Hammer, Michael Riegler,\n  Trine B. Haugen", "title": "Stacked dense optical flows and dropout layers to predict sperm motility\n  and morphology", "comments": "3 pages, 2 figures, MediaEval 19, 27-29 October 2019, Sophia\n  Antipolis, France", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.IV cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we analyse two deep learning methods to predict sperm motility\nand sperm morphology from sperm videos. We use two different inputs: stacked\npure frames of videos and dense optical flows of video frames. To solve this\nregression task of predicting motility and morphology, stacked dense optical\nflows and extracted original frames from sperm videos were used with the\nmodified state of the art convolution neural networks. For modifications of the\nselected models, we have introduced an additional multi-layer perceptron to\novercome the problem of over-fitting. The method which had an additional\nmulti-layer perceptron with dropout layers, shows the best results when the\ninputs consist of both dense optical flows and an original frame of videos.\n", "versions": [{"version": "v1", "created": "Fri, 8 Nov 2019 06:59:35 GMT"}], "update_date": "2019-11-11", "authors_parsed": [["Thambawita", "Vajira", ""], ["Halvorsen", "P\u00e5l", ""], ["Hammer", "Hugo", ""], ["Riegler", "Michael", ""], ["Haugen", "Trine B.", ""]]}, {"id": "1911.03093", "submitter": "Parikshit Pareek", "authors": "Parikshit Pareek, Chuan Wang, Hung D. Nguyen", "title": "Non-parametric Probabilistic Load Flow using Gaussian Process Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.SY cs.LG cs.SY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this work, we propose a non-parametric probabilistic load flow (NP-PLF)\ntechnique based on the Gaussian Process (GP) learning to understand the power\nsystem behavior under uncertainty for better operational decisions. The\ntechnique can provide \"semi-explicit\" power flow solutions by implementing the\nlearning and testing steps which map control variables to inputs. The proposed\nNP-PLF leverages upon GP upper confidence bound (GP-UCB) sampling algorithm.\nThe salient features of this NP-PLF method are: i) applicable for power flow\nproblem having power injection uncertainty with an unknown class of\ndistribution; ii) providing probabilistic learning bound (PLB) which further\nprovides control over the error and convergence; iii) capable of handling\nintermittent distributed generation as well as load uncertainties, and iv)\napplicable to both balanced and unbalanced power flow with different type and\nsize of power systems. The simulation results performed on the IEEE 30-bus and\nIEEE 118-bus system show that the proposed method can learn the voltage\nfunction over the power injection subspace using a small number of training\nsamples. Further, the testing with different input uncertainty distributions\nindicates that complete statistical information can be obtained for the\nprobabilistic load flow problem with average percentage relative error of order\n$10^{-3}$\\% on 50000 test points.\n", "versions": [{"version": "v1", "created": "Fri, 8 Nov 2019 07:07:28 GMT"}, {"version": "v2", "created": "Wed, 18 Mar 2020 09:25:47 GMT"}], "update_date": "2020-03-19", "authors_parsed": [["Pareek", "Parikshit", ""], ["Wang", "Chuan", ""], ["Nguyen", "Hung D.", ""]]}, {"id": "1911.03100", "submitter": "Vajira Thambawita", "authors": "Vajira Thambawita, P{\\aa}l Halvorsen, Hugo Hammer, Michael Riegler,\n  Trine B. Haugen", "title": "Extracting temporal features into a spatial domain using autoencoders\n  for sperm video analysis", "comments": "3 pages, 1 figure, MediaEval 19, 27-29 October 2019, Sophia\n  Antipolis, France", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG cs.MM eess.IV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we present a two-step deep learning method that is used to\npredict sperm motility and morphology-based on video recordings of human\nspermatozoa. First, we use an autoencoder to extract temporal features from a\ngiven semen video and plot these into image-space, which we call\nfeature-images. Second, these feature-images are used to perform transfer\nlearning to predict the motility and morphology values of human sperm. The\npresented method shows it's capability to extract temporal information into\nspatial domain feature-images which can be used with traditional convolutional\nneural networks. Furthermore, the accuracy of the predicted motility of a given\nsemen sample shows that a deep learning-based model can capture the temporal\ninformation of microscopic recordings of human semen.\n", "versions": [{"version": "v1", "created": "Fri, 8 Nov 2019 07:29:03 GMT"}], "update_date": "2019-11-11", "authors_parsed": [["Thambawita", "Vajira", ""], ["Halvorsen", "P\u00e5l", ""], ["Hammer", "Hugo", ""], ["Riegler", "Michael", ""], ["Haugen", "Trine B.", ""]]}, {"id": "1911.03105", "submitter": "Yi Hao", "authors": "Yi Hao, Alon Orlitsky", "title": "Unified Sample-Optimal Property Estimation in Near-Linear Time", "comments": "Appeared at NeurIPS 2019. Fixed a few typos and minor issues in\n  corner cases", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG math.ST stat.ML stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the fundamental learning problem of estimating properties of\ndistributions over large domains. Using a novel piecewise-polynomial\napproximation technique, we derive the first unified methodology for\nconstructing sample- and time-efficient estimators for all sufficiently smooth,\nsymmetric and non-symmetric, additive properties. This technique yields\nnear-linear-time computable estimators whose approximation values are\nasymptotically optimal and highly-concentrated, resulting in the first: 1)\nestimators achieving the $\\mathcal{O}(k/(\\varepsilon^2\\log k))$ min-max\n$\\varepsilon$-error sample complexity for all $k$-symbol Lipschitz properties;\n2) unified near-optimal differentially private estimators for a variety of\nproperties; 3) unified estimator achieving optimal bias and near-optimal\nvariance for five important properties; 4) near-optimal sample-complexity\nestimators for several important symmetric properties over both domain sizes\nand confidence levels. In addition, we establish a McDiarmid's inequality under\nPoisson sampling, which is of independent interest.\n", "versions": [{"version": "v1", "created": "Fri, 8 Nov 2019 07:46:47 GMT"}, {"version": "v2", "created": "Tue, 17 Mar 2020 17:43:02 GMT"}], "update_date": "2020-03-18", "authors_parsed": [["Hao", "Yi", ""], ["Orlitsky", "Alon", ""]]}, {"id": "1911.03112", "submitter": "Alina Kloss", "authors": "Alina Kloss, Maria Bauza, Jiajun Wu, Joshua B. Tenenbaum, Alberto\n  Rodriguez and Jeannette Bohg", "title": "Accurate Vision-based Manipulation through Contact Reasoning", "comments": "accepted at ICRA 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Planning contact interactions is one of the core challenges of many robotic\ntasks. Optimizing contact locations while taking dynamics into account is\ncomputationally costly and, in environments that are only partially observable,\nexecuting contact-based tasks often suffers from low accuracy. We present an\napproach that addresses these two challenges for the problem of vision-based\nmanipulation. First, we propose to disentangle contact from motion\noptimization. Thereby, we improve planning efficiency by focusing computation\non promising contact locations. Second, we use a hybrid approach for perception\nand state estimation that combines neural networks with a physically meaningful\nstate representation. In simulation and real-world experiments on the task of\nplanar pushing, we show that our method is more efficient and achieves a higher\nmanipulation accuracy than previous vision-based approaches.\n", "versions": [{"version": "v1", "created": "Fri, 8 Nov 2019 08:05:07 GMT"}, {"version": "v2", "created": "Fri, 17 Apr 2020 15:08:59 GMT"}], "update_date": "2020-04-20", "authors_parsed": [["Kloss", "Alina", ""], ["Bauza", "Maria", ""], ["Wu", "Jiajun", ""], ["Tenenbaum", "Joshua B.", ""], ["Rodriguez", "Alberto", ""], ["Bohg", "Jeannette", ""]]}, {"id": "1911.03117", "submitter": "Matthieu Heitz", "authors": "Matthieu Heitz, Nicolas Bonneel, David Coeurjolly, Marco Cuturi,\n  Gabriel Peyr\\'e", "title": "Ground Metric Learning on Graphs", "comments": "Fixed sign of gradient", "journal-ref": "Journal of Mathematical Imaging and Vision (2020): 1-19", "doi": "10.1007/s10851-020-00996-z", "report-no": null, "categories": "stat.ML cs.GR cs.LG math.OC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Optimal transport (OT) distances between probability distributions are\nparameterized by the ground metric they use between observations. Their\nrelevance for real-life applications strongly hinges on whether that ground\nmetric parameter is suitably chosen. Selecting it adaptively and\nalgorithmically from prior knowledge, the so-called ground metric learning GML)\nproblem, has therefore appeared in various settings. We consider it in this\npaper when the learned metric is constrained to be a geodesic distance on a\ngraph that supports the measures of interest. This imposes a rich structure for\ncandidate metrics, but also enables far more efficient learning procedures when\ncompared to a direct optimization over the space of all metric matrices. We use\nthis setting to tackle an inverse problem stemming from the observation of a\ndensity evolving with time: we seek a graph ground metric such that the OT\ninterpolation between the starting and ending densities that result from that\nground metric agrees with the observed evolution. This OT dynamic framework is\nrelevant to model natural phenomena exhibiting displacements of mass, such as\nfor instance the evolution of the color palette induced by the modification of\nlighting and materials.\n", "versions": [{"version": "v1", "created": "Fri, 8 Nov 2019 08:27:19 GMT"}, {"version": "v2", "created": "Sun, 18 Oct 2020 12:14:11 GMT"}, {"version": "v3", "created": "Thu, 5 Nov 2020 15:17:39 GMT"}], "update_date": "2020-11-06", "authors_parsed": [["Heitz", "Matthieu", ""], ["Bonneel", "Nicolas", ""], ["Coeurjolly", "David", ""], ["Cuturi", "Marco", ""], ["Peyr\u00e9", "Gabriel", ""]]}, {"id": "1911.03118", "submitter": "Segev Shlomov", "authors": "Ateret Anaby-Tavor, Boaz Carmeli, Esther Goldbraich, Amir Kantor,\n  George Kour, Segev Shlomov, Naama Tepper, and Naama Zwerdling", "title": "Not Enough Data? Deep Learning to the Rescue!", "comments": "20 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Based on recent advances in natural language modeling and those in text\ngeneration capabilities, we propose a novel data augmentation method for text\nclassification tasks. We use a powerful pre-trained neural network model to\nartificially synthesize new labeled data for supervised learning. We mainly\nfocus on cases with scarce labeled data. Our method, referred to as\nlanguage-model-based data augmentation (LAMBADA), involves fine-tuning a\nstate-of-the-art language generator to a specific task through an initial\ntraining phase on the existing (usually small) labeled data. Using the\nfine-tuned model and given a class label, new sentences for the class are\ngenerated. Our process then filters these new sentences by using a classifier\ntrained on the original data. In a series of experiments, we show that LAMBADA\nimproves classifiers' performance on a variety of datasets. Moreover, LAMBADA\nsignificantly improves upon the state-of-the-art techniques for data\naugmentation, specifically those applicable to text classification tasks with\nlittle data.\n", "versions": [{"version": "v1", "created": "Fri, 8 Nov 2019 08:30:22 GMT"}, {"version": "v2", "created": "Wed, 27 Nov 2019 12:15:52 GMT"}], "update_date": "2019-11-28", "authors_parsed": [["Anaby-Tavor", "Ateret", ""], ["Carmeli", "Boaz", ""], ["Goldbraich", "Esther", ""], ["Kantor", "Amir", ""], ["Kour", "George", ""], ["Shlomov", "Segev", ""], ["Tepper", "Naama", ""], ["Zwerdling", "Naama", ""]]}, {"id": "1911.03127", "submitter": "Muftah Al-Mahdawi", "authors": "Attayeb Mohsen, Muftah Al-Mahdawi, Mostafa M. Fouda, Mikihiko Oogane,\n  Yasuo Ando, Zubair Md Fadlullah", "title": "AI Aided Noise Processing of Spintronic Based IoT Sensor for\n  Magnetocardiography Application", "comments": "Presented at IEEE International Conference on Communications 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.SP cs.LG physics.app-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  As we are about to embark upon the highly hyped \"Society 5.0\", powered by the\nInternet of Things (IoT), traditional ways to monitor human heart signals for\ntracking cardio-vascular conditions are challenging, particularly in remote\nhealthcare settings. On the merits of low power consumption, portability, and\nnon-intrusiveness, there are no suitable IoT solutions that can provide\ninformation comparable to the conventional Electrocardiography (ECG). In this\npaper, we propose an IoT device utilizing a spintronic ultra-sensitive sensor\nthat measures the magnetic fields produced by cardio-vascular electrical\nactivity, i.e. Magentocardiography (MCG). After that, we treat the\nlow-frequency noise generated by the sensors, which is also a challenge for\nmost other sensors dealing with low-frequency bio-magnetic signals. Instead of\nrelying on generic signal processing techniques such as averaging or filtering,\nwe employ deep-learning training on bio-magnetic signals. Using an existing\ndataset of ECG records, MCG labels are synthetically constructed. A unique deep\nlearning structure composed of combined Convolutional Neural Network (CNN) with\nGated Recurrent Unit (GRU) is trained using the labeled data moving through a\nstriding window, which is able to smartly capture and eliminate the noise\nfeatures. Simulation results are reported to evaluate the effectiveness of the\nproposed method that demonstrates encouraging performance.\n", "versions": [{"version": "v1", "created": "Fri, 8 Nov 2019 08:45:54 GMT"}, {"version": "v2", "created": "Wed, 10 Jun 2020 14:26:03 GMT"}], "update_date": "2020-06-11", "authors_parsed": [["Mohsen", "Attayeb", ""], ["Al-Mahdawi", "Muftah", ""], ["Fouda", "Mostafa M.", ""], ["Oogane", "Mikihiko", ""], ["Ando", "Yasuo", ""], ["Fadlullah", "Zubair Md", ""]]}, {"id": "1911.03183", "submitter": "Erik-Jan van Kesteren", "authors": "Erik-Jan van Kesteren, Chang Sun, Daniel L. Oberski, Michel Dumontier,\n  Lianne Ippel", "title": "Privacy-Preserving Generalized Linear Models using Distributed Block\n  Coordinate Descent", "comments": "Fully reproducible code for all results and images can be found at\n  https://github.com/vankesteren/privacy-preserving-glm, and the software\n  package can be found at https://github.com/vankesteren/privreg", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR cs.DC stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Combining data from varied sources has considerable potential for knowledge\ndiscovery: collaborating data parties can mine data in an expanded feature\nspace, allowing them to explore a larger range of scientific questions.\nHowever, data sharing among different parties is highly restricted by legal\nconditions, ethical concerns, and / or data volume. Fueled by these concerns,\nthe fields of cryptography and distributed learning have made great progress\ntowards privacy-preserving and distributed data mining. However, practical\nimplementations have been hampered by the limited scope or computational\ncomplexity of these methods. In this paper, we greatly extend the range of\nanalyses available for vertically partitioned data, i.e., data collected by\nseparate parties with different features on the same subjects. To this end, we\npresent a novel approach for privacy-preserving generalized linear models, a\nfundamental and powerful framework underlying many prediction and\nclassification procedures. We base our method on a distributed block coordinate\ndescent algorithm to obtain parameter estimates, and we develop an extension to\ncompute accurate standard errors without additional communication cost. We\ncritically evaluate the information transfer for semi-honest collaborators and\nshow that our protocol is secure against data reconstruction. Through both\nsimulated and real-world examples we illustrate the functionality of our\nproposed algorithm. Without leaking information, our method performs as well on\nvertically partitioned data as existing methods on combined data -- all within\nmere minutes of computation time. We conclude that our method is a viable\napproach for vertically partitioned data analysis with a wide range of\nreal-world applications.\n", "versions": [{"version": "v1", "created": "Fri, 8 Nov 2019 11:07:07 GMT"}], "update_date": "2019-11-11", "authors_parsed": [["van Kesteren", "Erik-Jan", ""], ["Sun", "Chang", ""], ["Oberski", "Daniel L.", ""], ["Dumontier", "Michel", ""], ["Ippel", "Lianne", ""]]}, {"id": "1911.03193", "submitter": "Eurico Covas", "authors": "Eurico Covas", "title": "Transfer Learning in Spatial-Temporal Forecasting of the Solar Magnetic\n  Field", "comments": null, "journal-ref": null, "doi": "10.1002/asna.202013690", "report-no": null, "categories": "astro-ph.SR cs.LG nlin.CD", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Machine learning techniques have been widely used in attempts to forecast\nseveral solar datasets. Most of these approaches employ supervised machine\nlearning algorithms which are, in general, very data hungry. This hampers the\nattempts to forecast some of these data series, particularly the ones that\ndepend on (relatively) recent space observations. Here we focus on an attempt\nto forecast the solar surface longitudinally averaged radial magnetic field\ndistribution using a form of spatial-temporal neural networks. Given that the\nrecording of these spatial-temporal datasets only started in 1975 and are\ntherefore quite short, the forecasts are predictably quite modest. However,\ngiven that there is a potential physical relationship between sunspots and the\nmagnetic field, we employ another machine learning technique called transfer\nlearning which has recently received considerable attention in the literature.\nHere, this approach consists in first training the source spatial-temporal\nneural network on the much longer time/latitude sunspot area dataset, which\nstarts in 1874, then transferring the trained set of layers to a target\nnetwork, and continue training the latter on the magnetic field dataset. The\nemployment of transfer learning in the field of computer vision is known to\nobtain a generalized set of feature filters that can be reused for other\ndatasets and tasks. Here we obtain a similar result, whereby we first train the\nnetwork on the spatial-temporal sunspot area data, then the first few layers of\nthe neural network are able to identify the two main features of the solar\ncycle, i.e. the amplitude variation and the migration to the equator, and\ntherefore can be used to train on the magnetic field dataset and forecast\nbetter than a prediction based only on the historical magnetic field data.\n", "versions": [{"version": "v1", "created": "Fri, 8 Nov 2019 11:25:37 GMT"}], "update_date": "2020-07-15", "authors_parsed": [["Covas", "Eurico", ""]]}, {"id": "1911.03219", "submitter": "Nicolas Lair", "authors": "Nicolas Lair, C\\'edric Colas, R\\'emy Portelas, Jean-Michel Dussoux,\n  Peter Ford Dominey, Pierre-Yves Oudeyer", "title": "Language Grounding through Social Interactions and Curiosity-Driven\n  Multi-Goal Learning", "comments": "NeurIPS 2019 Workshop ViGIL : Visually Grounded Interaction and\n  Language", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CL stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Autonomous reinforcement learning agents, like children, do not have access\nto predefined goals and reward functions. They must discover potential goals,\nlearn their own reward functions and engage in their own learning trajectory.\nChildren, however, benefit from exposure to language, helping to organize and\nmediate their thought. We propose LE2 (Language Enhanced Exploration), a\nlearning algorithm leveraging intrinsic motivations and natural language (NL)\ninteractions with a descriptive social partner (SP). Using NL descriptions from\nthe SP, it can learn an NL-conditioned reward function to formulate goals for\nintrinsically motivated goal exploration and learn a goal-conditioned policy.\nBy exploring, collecting descriptions from the SP and jointly learning the\nreward function and the policy, the agent grounds NL descriptions into real\nbehavioral goals. From simple goals discovered early to more complex goals\ndiscovered by experimenting on simpler ones, our agent autonomously builds its\nown behavioral repertoire. This naturally occurring curriculum is supplemented\nby an active learning curriculum resulting from the agent's intrinsic\nmotivations. Experiments are presented with a simulated robotic arm that\ninteracts with several objects including tools.\n", "versions": [{"version": "v1", "created": "Fri, 8 Nov 2019 12:42:22 GMT"}], "update_date": "2019-11-11", "authors_parsed": [["Lair", "Nicolas", ""], ["Colas", "C\u00e9dric", ""], ["Portelas", "R\u00e9my", ""], ["Dussoux", "Jean-Michel", ""], ["Dominey", "Peter Ford", ""], ["Oudeyer", "Pierre-Yves", ""]]}, {"id": "1911.03221", "submitter": "Valentin Thorey", "authors": "Antoine Guillot, Fabien Sauvet, Emmanuel H During and Valentin Thorey", "title": "Dreem Open Datasets: Multi-Scored Sleep Datasets to compare Human and\n  Automated sleep staging", "comments": "10 pages, journal submitted", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.QM cs.LG eess.SP stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Sleep stage classification constitutes an important element of sleep disorder\ndiagnosis. It relies on the visual inspection of polysomnography records by\ntrained sleep technologists. Automated approaches have been designed to\nalleviate this resource-intensive task. However, such approaches are usually\ncompared to a single human scorer annotation despite an inter-rater agreement\nof about 85 % only. The present study introduces two publicly-available\ndatasets, DOD-H including 25 healthy volunteers and DOD-O including 55 patients\nsuffering from obstructive sleep apnea (OSA). Both datasets have been scored by\n5 sleep technologists from different sleep centers. We developed a framework to\ncompare automated approaches to a consensus of multiple human scorers. Using\nthis framework, we benchmarked and compared the main literature approaches. We\nalso developed and benchmarked a new deep learning method, SimpleSleepNet,\ninspired by current state-of-the-art. We demonstrated that many methods can\nreach human-level performance on both datasets. SimpleSleepNet achieved an F1\nof 89.9 % vs 86.8 % on average for human scorers on DOD-H, and an F1 of 88.3 %\nvs 84.8 % on DOD-O. Our study highlights that using state-of-the-art automated\nsleep staging outperforms human scorers performance for healthy volunteers and\npatients suffering from OSA. Consideration could be made to use automated\napproaches in the clinical setting.\n", "versions": [{"version": "v1", "created": "Thu, 31 Oct 2019 16:12:43 GMT"}, {"version": "v2", "created": "Tue, 12 Nov 2019 17:21:23 GMT"}, {"version": "v3", "created": "Mon, 2 Mar 2020 16:53:12 GMT"}, {"version": "v4", "created": "Mon, 27 Apr 2020 09:45:45 GMT"}], "update_date": "2020-04-28", "authors_parsed": [["Guillot", "Antoine", ""], ["Sauvet", "Fabien", ""], ["During", "Emmanuel H", ""], ["Thorey", "Valentin", ""]]}, {"id": "1911.03222", "submitter": "Valentin Vielzeuf", "authors": "Valentin Vielzeuf, Alexis Lechervy, St\\'ephane Pateux, Fr\\'ed\\'eric\n  Jurie", "title": "Towards a General Model of Knowledge for Facial Analysis by Multi-Source\n  Transfer Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper proposes a step toward obtaining general models of knowledge for\nfacial analysis, by addressing the question of multi-source transfer learning.\nMore precisely, the proposed approach consists in two successive training\nsteps: the first one consists in applying a combination operator to define a\ncommon embedding for the multiple sources materialized by different existing\ntrained models. The proposed operator relies on an auto-encoder, trained on a\nlarge dataset, efficient both in terms of compression ratio and transfer\nlearning performance. In a second step we exploit a distillation approach to\nobtain a lightweight student model mimicking the collection of the fused\nexisting models. This model outperforms its teacher on novel tasks, achieving\nresults on par with state-of-the-art methods on 15 facial analysis tasks (and\ndomains), at an affordable training cost. Moreover, this student has 75 times\nless parameters than the original teacher and can be applied to a variety of\nnovel face-related tasks.\n", "versions": [{"version": "v1", "created": "Fri, 8 Nov 2019 12:47:03 GMT"}], "update_date": "2019-11-11", "authors_parsed": [["Vielzeuf", "Valentin", ""], ["Lechervy", "Alexis", ""], ["Pateux", "St\u00e9phane", ""], ["Jurie", "Fr\u00e9d\u00e9ric", ""]]}, {"id": "1911.03224", "submitter": "Zachary del Rosario", "authors": "Zachary del Rosario and Matthias Rupp and Yoolhee Kim and Erin Antono\n  and Julia Ling", "title": "Assessing the Frontier: Active Learning, Model Accuracy, and\n  Multi-objective Materials Discovery and Optimization", "comments": "17 pages, 10 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG stat.ME", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Discovering novel materials can be greatly accelerated by iterative machine\nlearning-informed proposal of candidates---active learning. However, standard\n\\emph{global-scope error} metrics for model quality are not predictive of\ndiscovery performance, and can be misleading. We introduce the notion of\n\\emph{Pareto shell-scope error} to help judge the suitability of a model for\nproposing material candidates. Further, through synthetic cases and a\nthermoelectric dataset, we probe the relation between acquisition function\nfidelity and active learning performance. Results suggest novel diagnostic\ntools, as well as new insights for acquisition function design.\n", "versions": [{"version": "v1", "created": "Wed, 6 Nov 2019 17:24:35 GMT"}, {"version": "v2", "created": "Sat, 4 Jan 2020 22:42:41 GMT"}, {"version": "v3", "created": "Mon, 27 Jan 2020 18:06:43 GMT"}], "update_date": "2020-01-28", "authors_parsed": [["del Rosario", "Zachary", ""], ["Rupp", "Matthias", ""], ["Kim", "Yoolhee", ""], ["Antono", "Erin", ""], ["Ling", "Julia", ""]]}, {"id": "1911.03229", "submitter": "Eliya Nachmani", "authors": "Eliya Nachmani, Lior Wolf", "title": "A Gated Hypernet Decoder for Polar Codes", "comments": "Accepted to ICASSP 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IT cs.LG math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Hypernetworks were recently shown to improve the performance of message\npassing algorithms for decoding error correcting codes. In this work, we\ndemonstrate how hypernetworks can be applied to decode polar codes by employing\na new formalization of the polar belief propagation decoding scheme. We\ndemonstrate that our method improves the previous results of neural polar\ndecoders and achieves, for large SNRs, the same bit-error-rate performances as\nthe successive list cancellation method, which is known to be better than any\nbelief propagation decoders and very close to the maximum likelihood decoder.\n", "versions": [{"version": "v1", "created": "Fri, 8 Nov 2019 12:58:43 GMT"}, {"version": "v2", "created": "Mon, 10 Feb 2020 11:08:54 GMT"}], "update_date": "2020-02-11", "authors_parsed": [["Nachmani", "Eliya", ""], ["Wolf", "Lior", ""]]}, {"id": "1911.03242", "submitter": "Zhuo Ma", "authors": "Yang Liu, Zhuo Ma, Ximeng Liu, Zhuzhu Wang, Siqi Ma, Ken Ren", "title": "Revocable Federated Learning: A Benchmark of Federated Forest", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A learning federation is composed of multiple participants who use the\nfederated learning technique to collaboratively train a machine learning model\nwithout directly revealing the local data. Nevertheless, the existing federated\nlearning frameworks have a serious defect that even a participant is revoked,\nits data are still remembered by the trained model. In a company-level\ncooperation, allowing the remaining companies to use a trained model that\ncontains the memories from a revoked company is obviously unacceptable, because\nit can lead to a big conflict of interest. Therefore, we emphatically discuss\nthe participant revocation problem of federated learning and design a revocable\nfederated random forest (RF) framework, RevFRF, to further illustrate the\nconcept of revocable federated learning. In RevFRF, we first define the\nsecurity problems to be resolved by a revocable federated RF. Then, a suite of\nhomomorphic encryption based secure protocols are designed for federated RF\nconstruction, prediction and revocation. Through theoretical analysis and\nexperiments, we show that the protocols can securely and efficiently implement\ncollaborative training of an RF and ensure that the memories of a revoked\nparticipant in the trained RF are securely removed.\n", "versions": [{"version": "v1", "created": "Fri, 8 Nov 2019 13:20:16 GMT"}], "update_date": "2019-11-11", "authors_parsed": [["Liu", "Yang", ""], ["Ma", "Zhuo", ""], ["Liu", "Ximeng", ""], ["Wang", "Zhuzhu", ""], ["Ma", "Siqi", ""], ["Ren", "Ken", ""]]}, {"id": "1911.03249", "submitter": "Tomas Kliegr", "authors": "Tom\\'a\\v{s} Kliegr, \\v{S}t\\v{e}p\\'an Bahn\\'ik, Johannes F\\\"urnkranz", "title": "Advances in Machine Learning for the Behavioral Sciences", "comments": null, "journal-ref": "American Behavioral Scientist 64.2 (2020): 145-175", "doi": "10.1177/0002764219859639", "report-no": null, "categories": "cs.LG cs.CL stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The areas of machine learning and knowledge discovery in databases have\nconsiderably matured in recent years. In this article, we briefly review recent\ndevelopments as well as classical algorithms that stood the test of time. Our\ngoal is to provide a general introduction into different tasks such as learning\nfrom tabular data, behavioral data, or textual data, with a particular focus on\nactual and potential applications in behavioral sciences. The supplemental\nappendix to the article also provides practical guidance for using the methods\nby pointing the reader to proven software implementations. The focus is on R,\nbut we also cover some libraries in other programming languages as well as\nsystems with easy-to-use graphical interfaces.\n", "versions": [{"version": "v1", "created": "Fri, 8 Nov 2019 13:30:21 GMT"}], "update_date": "2020-12-09", "authors_parsed": [["Kliegr", "Tom\u00e1\u0161", ""], ["Bahn\u00edk", "\u0160t\u011bp\u00e1n", ""], ["F\u00fcrnkranz", "Johannes", ""]]}, {"id": "1911.03264", "submitter": "Ali Taleb Zadeh Kasgari", "authors": "Ali Taleb Zadeh Kasgari, Walid Saad, Mohammad Mozaffari, H. Vincent\n  Poor", "title": "Experienced Deep Reinforcement Learning with Generative Adversarial\n  Networks (GANs) for Model-Free Ultra Reliable Low Latency Communication", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IT cs.LG cs.NI math.IT stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, a novel experienced deep reinforcement learning (deep-RL)\nframework is proposed to provide model-free resource allocation for ultra\nreliable low latency communication (URLLC). The proposed, experienced deep-RL\nframework can guarantee high end-to-end reliability and low end-to-end latency,\nunder explicit data rate constraints, for each wireless without any models of\nor assumptions on the users' traffic. In particular, in order to enable the\ndeep-RL framework to account for extreme network conditions and operate in\nhighly reliable systems, a new approach based on generative adversarial\nnetworks (GANs) is proposed. This GAN approach is used to pre-train the deep-RL\nframework using a mix of real and synthetic data, thus creating an experienced\ndeep-RL framework that has been exposed to a broad range of network conditions.\nFormally, the URLLC resource allocation problem is posed as a power\nminimization problem under reliability, latency, and rate constraints. To solve\nthis problem using experienced deep-RL, first, the rate of each user is\ndetermined. Then, these rates are mapped to the resource block and power\nallocation vectors of the studied wireless system. Finally, the end-to-end\nreliability and latency of each user are used as feedback to the deep-RL\nframework. It is then shown that at the fixed-point of the deep-RL algorithm,\nthe reliability and latency of the users are near-optimal. Moreover, for the\nproposed GAN approach, a theoretical limit for the generator output is\nanalytically derived. Simulation results show how the proposed approach can\nachieve near-optimal performance within the rate-reliability-latency region,\ndepending on the network and service requirements. The results also show that\nthe proposed experienced deep-RL framework is able to remove the transient\ntraining time that makes conventional deep-RL methods unsuitable for URLLC.\n", "versions": [{"version": "v1", "created": "Fri, 1 Nov 2019 16:50:48 GMT"}, {"version": "v2", "created": "Wed, 14 Oct 2020 01:23:10 GMT"}], "update_date": "2020-10-15", "authors_parsed": [["Kasgari", "Ali Taleb Zadeh", ""], ["Saad", "Walid", ""], ["Mozaffari", "Mohammad", ""], ["Poor", "H. Vincent", ""]]}, {"id": "1911.03267", "submitter": "Chris Ding", "authors": "Chi Ding, Zheng Cao, Matthew S. Emigh, Jose C. Principe, Bing Ouyang,\n  Anni Vuorenkoski, Fraser Dalgleish, Brian Ramos, Yanjun Li", "title": "Algorithmic Design and Implementation of Unobtrusive Multistatic Serial\n  LiDAR Image", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.IV cs.CV cs.LG eess.SP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  To fully understand interactions between marine hydrokinetic (MHK) equipment\nand marine animals, a fast and effective monitoring system is required to\ncapture relevant information whenever underwater animals appear. A new\nautomated underwater imaging system composed of LiDAR (Light Detection and\nRanging) imaging hardware and a scene understanding software module named\nUnobtrusive Multistatic Serial LiDAR Imager (UMSLI) to supervise the presence\nof animals near turbines. UMSLI integrates the front end LiDAR hardware and a\nseries of software modules to achieve image preprocessing, detection, tracking,\nsegmentation and classification in a hierarchical manner.\n", "versions": [{"version": "v1", "created": "Fri, 8 Nov 2019 13:58:00 GMT"}], "update_date": "2019-11-11", "authors_parsed": [["Ding", "Chi", ""], ["Cao", "Zheng", ""], ["Emigh", "Matthew S.", ""], ["Principe", "Jose C.", ""], ["Ouyang", "Bing", ""], ["Vuorenkoski", "Anni", ""], ["Dalgleish", "Fraser", ""], ["Ramos", "Brian", ""], ["Li", "Yanjun", ""]]}, {"id": "1911.03268", "submitter": "Dan Schwartz", "authors": "Dan Schwartz, Mariya Toneva, Leila Wehbe", "title": "Inducing brain-relevant bias in natural language processing models", "comments": "To be published in the proceedings of the 33rd Conference on Neural\n  Information Processing Systems (NeurIPS 2019), Vancouver, Canada", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.NC cs.CL cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Progress in natural language processing (NLP) models that estimate\nrepresentations of word sequences has recently been leveraged to improve the\nunderstanding of language processing in the brain. However, these models have\nnot been specifically designed to capture the way the brain represents language\nmeaning. We hypothesize that fine-tuning these models to predict recordings of\nbrain activity of people reading text will lead to representations that encode\nmore brain-activity-relevant language information. We demonstrate that a\nversion of BERT, a recently introduced and powerful language model, can improve\nthe prediction of brain activity after fine-tuning. We show that the\nrelationship between language and brain activity learned by BERT during this\nfine-tuning transfers across multiple participants. We also show that, for some\nparticipants, the fine-tuned representations learned from both\nmagnetoencephalography (MEG) and functional magnetic resonance imaging (fMRI)\nare better for predicting fMRI than the representations learned from fMRI\nalone, indicating that the learned representations capture\nbrain-activity-relevant information that is not simply an artifact of the\nmodality. While changes to language representations help the model predict\nbrain activity, they also do not harm the model's ability to perform downstream\nNLP tasks. Our findings are notable for research on language understanding in\nthe brain.\n", "versions": [{"version": "v1", "created": "Tue, 29 Oct 2019 23:28:16 GMT"}], "update_date": "2019-11-11", "authors_parsed": [["Schwartz", "Dan", ""], ["Toneva", "Mariya", ""], ["Wehbe", "Leila", ""]]}, {"id": "1911.03274", "submitter": "Xavier Renard", "authors": "Vincent Ballet, Xavier Renard, Jonathan Aigrain, Thibault Laugel,\n  Pascal Frossard, Marcin Detyniecki", "title": "Imperceptible Adversarial Attacks on Tabular Data", "comments": "presented at NeurIPS 2019 Workshop on Robust AI in Financial\n  Services: Data, Fairness, Explainability, Trustworthiness, and Privacy\n  (Robust AI in FS 2019), Vancouver, Canada", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.CR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Security of machine learning models is a concern as they may face adversarial\nattacks for unwarranted advantageous decisions. While research on the topic has\nmainly been focusing on the image domain, numerous industrial applications, in\nparticular in finance, rely on standard tabular data. In this paper, we discuss\nthe notion of adversarial examples in the tabular domain. We propose a\nformalization based on the imperceptibility of attacks in the tabular domain\nleading to an approach to generate imperceptible adversarial examples.\nExperiments show that we can generate imperceptible adversarial examples with a\nhigh fooling rate.\n", "versions": [{"version": "v1", "created": "Fri, 8 Nov 2019 14:14:11 GMT"}, {"version": "v2", "created": "Fri, 13 Dec 2019 11:15:29 GMT"}], "update_date": "2019-12-16", "authors_parsed": [["Ballet", "Vincent", ""], ["Renard", "Xavier", ""], ["Aigrain", "Jonathan", ""], ["Laugel", "Thibault", ""], ["Frossard", "Pascal", ""], ["Detyniecki", "Marcin", ""]]}, {"id": "1911.03276", "submitter": "Shuoguang Yang", "authors": "Shuoguang Yang, Shatian Wang, Van-Anh Truong", "title": "Online Learning and Optimization Under a New Linear-Threshold Model with\n  Negative Influence", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Problem definition: Corporate brands, grassroots activists, and ordinary\ncitizens all routinely employ Word-of-mouth (WoM) diffusion to promote products\nand instigate social change. Our work models the formation and spread of\nnegative attitudes via WoM on a social network represented by a directed graph.\nIn an online learning setting, we examine how an agent could simultaneously\nlearn diffusion parameters and choose sets of seed users to initiate diffusions\nand maximize positive influence. In contrast to edge-level feedback, in which\nan agent observes the relationship (edge) through which a user (node) is\ninfluenced, we more realistically assume node-level feedback, where an agent\nonly observes when a user is influenced and whether that influence is positive\nor negative. Methodology/results: We propose a new class of negativity-aware\nLinear Threshold Models. We show that in these models, the expected positive\ninfluence spread is a monotone submodular function of the seed set. Therefore,\nwhen maximizing positive influence by selecting a seed set of fixed size, a\ngreedy algorithm can guarantee a solution with a constant approximation ratio.\nFor the online learning setting, we propose an algorithm that runs in epochs of\ngrowing lengths, each consisting of a fixed number of exploration rounds\nfollowed by an increasing number of exploitation rounds controlled by a\nhyperparameter. Under mild assumptions, we show that our algorithm achieves\nasymptotic expected average scaled regret that is inversely related to any\nfractional constant power of the number of rounds. Managerial implications:\nDuring seed selection, our negativity-aware models and algorithms allow WoM\ncampaigns to discover and best account for characteristics of local users and\npropagated content. We also give the first algorithms with regret guarantees\nfor influence maximization under node-level feedback.\n", "versions": [{"version": "v1", "created": "Fri, 8 Nov 2019 14:17:12 GMT"}, {"version": "v2", "created": "Thu, 20 Feb 2020 18:39:10 GMT"}, {"version": "v3", "created": "Thu, 6 May 2021 15:17:40 GMT"}], "update_date": "2021-05-07", "authors_parsed": [["Yang", "Shuoguang", ""], ["Wang", "Shatian", ""], ["Truong", "Van-Anh", ""]]}, {"id": "1911.03295", "submitter": "Mohammad Taha Bahadori", "authors": "Mohammad Taha Bahadori and Layne C. Price", "title": "Discovering Invariances in Healthcare Neural Networks", "comments": "The extended version", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG q-bio.QM stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the invariance characteristics of pre-trained predictive models by\nempirically learning transformations on the input that leave the prediction\nfunction approximately unchanged. To learn invariant transformations, we\nminimize the Wasserstein distance between the predictive distribution\nconditioned on the data instances and the predictive distribution conditioned\non the transformed data instances. To avoid finding degenerate or perturbative\ntransformations, we add a similarity regularization to discourage similarity\nbetween the data and its transformed values. We theoretically analyze the\ncorrectness of the algorithm and the structure of the solutions. Applying the\nproposed technique to clinical time series data, we discover variables that\ncommonly-used LSTM models do not rely on for their prediction, especially when\nthe LSTM is trained to be adversarially robust. We also analyze the invariances\nof BioBERT on clinical notes and discover words that it is invariant to.\n", "versions": [{"version": "v1", "created": "Fri, 8 Nov 2019 14:48:05 GMT"}, {"version": "v2", "created": "Tue, 14 Jan 2020 03:40:38 GMT"}, {"version": "v3", "created": "Tue, 3 Mar 2020 18:00:06 GMT"}], "update_date": "2020-03-04", "authors_parsed": [["Bahadori", "Mohammad Taha", ""], ["Price", "Layne C.", ""]]}, {"id": "1911.03299", "submitter": "Hankui Peng", "authors": "Hankui Peng, Nicos G. Pavlidis", "title": "Subspace Clustering with Active Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Subspace clustering is a growing field of unsupervised learning that has\ngained much popularity in the computer vision community. Applications can be\nfound in areas such as motion segmentation and face clustering. It assumes that\ndata originate from a union of subspaces, and clusters the data depending on\nthe corresponding subspace. In practice, it is reasonable to assume that a\nlimited amount of labels can be obtained, potentially at a cost. Therefore,\nalgorithms that can effectively and efficiently incorporate this information to\nimprove the clustering model are desirable. In this paper, we propose an active\nlearning framework for subspace clustering that sequentially queries\ninformative points and updates the subspace model. The query stage of the\nproposed framework relies on results from the perturbation theory of principal\ncomponent analysis, to identify influential and potentially misclassified\npoints. A constrained subspace clustering algorithm is proposed that\nmonotonically decreases the objective function subject to the constraints\nimposed by the labelled data. We show that our proposed framework is suitable\nfor subspace clustering algorithms including iterative methods and spectral\nmethods. Experiments on synthetic data sets, motion segmentation data sets, and\nYale Faces data sets demonstrate the advantage of our proposed active strategy\nover state-of-the-art.\n", "versions": [{"version": "v1", "created": "Fri, 8 Nov 2019 14:54:45 GMT"}, {"version": "v2", "created": "Mon, 11 Nov 2019 14:00:24 GMT"}], "update_date": "2019-11-12", "authors_parsed": [["Peng", "Hankui", ""], ["Pavlidis", "Nicos G.", ""]]}, {"id": "1911.03306", "submitter": "Bahram Mohammadi", "authors": "Mohammed Gharib, Bahram Mohammadi, Shadi Hejareh Dastgerdi, Mohammad\n  Sabokrou", "title": "AutoIDS: Auto-encoder Based Method for Intrusion Detection System", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Intrusion Detection System (IDS) is one of the most effective solutions for\nproviding primary security services. IDSs are generally working based on attack\nsignatures or by detecting anomalies. In this paper, we have presented AutoIDS,\na novel yet efficient solution for IDS, based on a semi-supervised machine\nlearning technique. AutoIDS can distinguish abnormal packet flows from normal\nones by taking advantage of cascading two efficient detectors. These detectors\nare two encoder-decoder neural networks that are forced to provide a compressed\nand a sparse representation from the normal flows. In the test phase, failing\nthese neural networks on providing compressed or sparse representation from an\nincoming packet flow, means such flow does not comply with the normal traffic\nand thus it is considered as an intrusion. For lowering the computational cost\nalong with preserving the accuracy, a large number of flows are just processed\nby the first detector. In fact, the second detector is only used for difficult\nsamples which the first detector is not confident about them. We have evaluated\nAutoIDS on the NSL-KDD benchmark as a widely-used and well-known dataset. The\naccuracy of AutoIDS is 90.17\\% showing its superiority compared to the other\nstate-of-the-art methods.\n", "versions": [{"version": "v1", "created": "Fri, 8 Nov 2019 15:03:31 GMT"}], "update_date": "2019-11-11", "authors_parsed": [["Gharib", "Mohammed", ""], ["Mohammadi", "Bahram", ""], ["Dastgerdi", "Shadi Hejareh", ""], ["Sabokrou", "Mohammad", ""]]}, {"id": "1911.03308", "submitter": "Matt Benatan", "authors": "Matt Benatan and Edward O. Pyzer-Knapp", "title": "Fully Bayesian Recurrent Neural Networks for Safe Reinforcement Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Reinforcement Learning (RL) has demonstrated state-of-the-art results in a\nnumber of autonomous system applications, however many of the underlying\nalgorithms rely on black-box predictions. This results in poor explainability\nof the behaviour of these systems, raising concerns as to their use in\nsafety-critical applications. Recent work has demonstrated that\nuncertainty-aware models exhibit more cautious behaviours through the\nincorporation of model uncertainty estimates. In this work, we build on\nProbabilistic Backpropagation to introduce a fully Bayesian Recurrent Neural\nNetwork architecture. We apply this within a Safe RL scenario, and demonstrate\nthat the proposed method significantly outperforms a popular approach for\nobtaining model uncertainties in collision avoidance tasks. Furthermore, we\ndemonstrate that the proposed approach requires less training and is far more\nefficient than the current leading method, both in terms of compute resource\nand memory footprint.\n", "versions": [{"version": "v1", "created": "Fri, 8 Nov 2019 15:08:51 GMT"}, {"version": "v2", "created": "Tue, 26 Nov 2019 11:36:03 GMT"}], "update_date": "2019-11-27", "authors_parsed": [["Benatan", "Matt", ""], ["Pyzer-Knapp", "Edward O.", ""]]}, {"id": "1911.03314", "submitter": "Xiaying Wang", "authors": "Xiaying Wang, Michele Magno, Lukas Cavigelli and Luca Benini", "title": "FANN-on-MCU: An Open-Source Toolkit for Energy-Efficient Neural Network\n  Inference at the Edge of the Internet of Things", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG eess.SP stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The growing number of low-power smart devices in the Internet of Things is\ncoupled with the concept of \"Edge Computing\", that is moving some of the\nintelligence, especially machine learning, towards the edge of the network.\nEnabling machine learning algorithms to run on resource-constrained hardware,\ntypically on low-power smart devices, is challenging in terms of hardware\n(optimized and energy-efficient integrated circuits), algorithmic and firmware\nimplementations. This paper presents FANN-on-MCU, an open-source toolkit built\nupon the Fast Artificial Neural Network (FANN) library to run lightweight and\nenergy-efficient neural networks on microcontrollers based on both the ARM\nCortex-M series and the novel RISC-V-based Parallel Ultra-Low-Power (PULP)\nplatform. The toolkit takes multi-layer perceptrons trained with FANN and\ngenerates code targeted at execution on low-power microcontrollers either with\na floating-point unit (i.e., ARM Cortex-M4F and M7F) or without (i.e., ARM\nCortex M0-M3 or PULP-based processors). This paper also provides an\narchitectural performance evaluation of neural networks on the most popular ARM\nCortex-M family and the parallel RISC-V processor called Mr. Wolf. The\nevaluation includes experimental results for three different applications using\na self-sustainable wearable multi-sensor bracelet. Experimental results show a\nmeasured latency in the order of only a few microseconds and a power\nconsumption of few milliwatts while keeping the memory requirements below the\nlimitations of the targeted microcontrollers. In particular, the parallel\nimplementation on the octa-core RISC-V platform reaches a speedup of 22x and a\n69% reduction in energy consumption with respect to a single-core\nimplementation on Cortex-M4 for continuous real-time classification.\n", "versions": [{"version": "v1", "created": "Fri, 8 Nov 2019 15:14:50 GMT"}, {"version": "v2", "created": "Mon, 3 Feb 2020 19:01:22 GMT"}], "update_date": "2020-02-05", "authors_parsed": [["Wang", "Xiaying", ""], ["Magno", "Michele", ""], ["Cavigelli", "Lukas", ""], ["Benini", "Luca", ""]]}, {"id": "1911.03315", "submitter": "Michael Maiworm", "authors": "Michael Maiworm, Daniel Limon, Rolf Findeisen", "title": "Online learning-based Model Predictive Control with Gaussian Process\n  Models and Stability Guarantees", "comments": "29 pages, 13 figures, 3 tables, 1 algorithm, revision submitted to\n  International Journal of Robust and Nonlinear Control", "journal-ref": null, "doi": "10.1002/rnc.5361", "report-no": null, "categories": "eess.SY cs.LG cs.SY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Model predictive control allows to provide high performance and safety\nguarantees in the form of constraint satisfaction. These properties, however,\ncan be satisfied only if the underlying model, used for prediction, of the\ncontrolled process is sufficiently accurate. One way to address this challenge\nis by data-driven and machine learning approaches, such as Gaussian processes,\nthat allow to refine the model online during operation. We present a\ncombination of an output feedback model predictive control scheme and a\nGaussian process-based prediction model that is capable of efficient online\nlearning. To this end, the concept of evolving Gaussian processes is combined\nwith recursive posterior prediction updates. The presented approach guarantees\nrecursive constraint satisfaction and input-to-state stability with respect to\nthe model-plant mismatch. Simulation studies underline that the Gaussian\nprocess prediction model can be successfully and efficiently learned online.\nThe resulting computational load is significantly reduced via the combination\nof the recursive update procedure and by limiting the number of training data\npoints while maintaining good performance.\n", "versions": [{"version": "v1", "created": "Fri, 8 Nov 2019 15:14:53 GMT"}, {"version": "v2", "created": "Thu, 26 Mar 2020 09:36:14 GMT"}, {"version": "v3", "created": "Mon, 27 Jul 2020 05:13:10 GMT"}, {"version": "v4", "created": "Tue, 1 Dec 2020 10:28:41 GMT"}], "update_date": "2021-02-25", "authors_parsed": [["Maiworm", "Michael", ""], ["Limon", "Daniel", ""], ["Findeisen", "Rolf", ""]]}, {"id": "1911.03318", "submitter": "Zhanhong Jiang", "authors": "Zhanhong Jiang and Young M. Lee", "title": "Deep Transfer Learning for Thermal Dynamics Modeling in Smart Buildings", "comments": "5 pages, 2 figures; Accepted at 2019 IEEE International Conference on\n  Big Data (IEEE BigData 2019)", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG cs.SY eess.SY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Thermal dynamics modeling has been a critical issue in building heating,\nventilation, and air-conditioning (HVAC) systems, which can significantly\naffect the control and maintenance strategies. Due to the uniqueness of each\nspecific building, traditional thermal dynamics modeling approaches heavily\ndepending on physics knowledge cannot generalize well. This study proposes a\ndeep supervised domain adaptation (DSDA) method for thermal dynamics modeling\nof building indoor temperature evolution and energy consumption. A long short\nterm memory network based Sequence to Sequence scheme is pre-trained based on a\nlarge amount of data collected from a building and then adapted to another\nbuilding which has a limited amount of data by applying the model fine-tuning.\nWe use four publicly available datasets: SML and AHU for temperature evolution,\nlong-term datasets from two different commercial buildings, termed as Building\n1 and Building 2 for energy consumption. We show that the deep supervised\ndomain adaptation is effective to adapt the pre-trained model from one building\nto another building and has better predictive performance than learning from\nscratch with only a limited amount of data.\n", "versions": [{"version": "v1", "created": "Fri, 8 Nov 2019 15:19:33 GMT"}], "update_date": "2019-11-11", "authors_parsed": [["Jiang", "Zhanhong", ""], ["Lee", "Young M.", ""]]}, {"id": "1911.03329", "submitter": "Stuart Shieber", "authors": "Mirac Suzgun and Sebastian Gehrmann and Yonatan Belinkov and Stuart M.\n  Shieber", "title": "Memory-Augmented Recurrent Neural Networks Can Learn Generalized Dyck\n  Languages", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce three memory-augmented Recurrent Neural Networks (MARNNs) and\nexplore their capabilities on a series of simple language modeling tasks whose\nsolutions require stack-based mechanisms. We provide the first demonstration of\nneural networks recognizing the generalized Dyck languages, which express the\ncore of what it means to be a language with hierarchical structure. Our\nmemory-augmented architectures are easy to train in an end-to-end fashion and\ncan learn the Dyck languages over as many as six parenthesis-pairs, in addition\nto two deterministic palindrome languages and the string-reversal transduction\ntask, by emulating pushdown automata. Our experiments highlight the increased\nmodeling capacity of memory-augmented models over simple RNNs, while inflecting\nour understanding of the limitations of these models.\n", "versions": [{"version": "v1", "created": "Fri, 8 Nov 2019 15:33:51 GMT"}], "update_date": "2019-11-11", "authors_parsed": [["Suzgun", "Mirac", ""], ["Gehrmann", "Sebastian", ""], ["Belinkov", "Yonatan", ""], ["Shieber", "Stuart M.", ""]]}, {"id": "1911.03332", "submitter": "Victor Gimenez-Abalos", "authors": "Victor Gimenez-Abalos, Armand Vilalta, Dario Garcia-Gasulla, Jesus\n  Labarta and Eduard Ayguad\\'e", "title": "Feature discriminativity estimation in CNNs for transfer learning", "comments": "Presented in the 22nd International Conference of the Catalan\n  Association for Artificial Intelligence (CCIA 19)", "journal-ref": "Volume 319: Artificial Intelligence Research and Development 2019", "doi": "10.3233/FAIA190109", "report-no": null, "categories": "cs.NE cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The purpose of feature extraction on convolutional neural networks is to\nreuse deep representations learnt for a pre-trained model to solve a new,\npotentially unrelated problem. However, raw feature extraction from all layers\nis unfeasible given the massive size of these networks. Recently, a supervised\nmethod using complexity reduction was proposed, resulting in significant\nimprovements in performance for transfer learning tasks. This approach first\ncomputes the discriminative power of features, and then discretises them using\nthresholds computed for the task. In this paper, we analyse the behaviour of\nthese thresholds, with the purpose of finding a methodology for their\nestimation. After a comprehensive study, we find a very strong correlation\nbetween problem size and threshold value, with coefficient of determination\nabove 90%. These results allow us to propose a unified model for threshold\nestimation, with potential application to transfer learning tasks.\n", "versions": [{"version": "v1", "created": "Fri, 8 Nov 2019 15:37:25 GMT"}], "update_date": "2019-11-11", "authors_parsed": [["Gimenez-Abalos", "Victor", ""], ["Vilalta", "Armand", ""], ["Garcia-Gasulla", "Dario", ""], ["Labarta", "Jesus", ""], ["Ayguad\u00e9", "Eduard", ""]]}, {"id": "1911.03338", "submitter": "Yaroslav Koshka", "authors": "Yaroslav Koshka, M.A. Novotny", "title": "Comparison of D-Wave Quantum Annealing and Classical Simulated Annealing\n  for Local Minima Determination", "comments": "11 pages, 8 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "quant-ph cs.IR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Restricted Boltzmann Machines trained with different numbers of iterations\nwere used to provide a diverse set of energy functions each containing many\nlocal valleys (LVs) with different energies, widths, escape barrier heights,\netc. They were used to verify the previously reported possibility of using the\nD-Wave quantum annealer (QA) to find potentially important LVs in the energy\nfunctions of Ising spin glasses that may be missed by classical searches. For\nclassical search, extensive simulated annealing (SA) was conducted to find as\nmany LVs as possible regardless of the computational cost. SA was conducted\nlong enough to ensure that the number of SA-found LVs approaches that and\neventually significantly exceeds the number of the LVs found by a single call\nsubmitted to the D-Wave. Even after a prohibitively long SA search, as many as\n30-50% of the D-Wave-found LVs remained not found by the SA. In order to\nestablish if LVs found only by the D-Wave represent potentially important\nregions of the configuration space, they were compared to those that were found\nby both techniques. While the LVs found by the D-Wave but missed by SA\npredominantly had higher energies and lower escape barriers, there was a\nsignificant fraction having intermediate values of the energy and barrier\nheight. With respect to most other important LV parameters, the LVs found only\nby the D-Wave were distributed in a wide range of the parameters' values. It\nwas established that for large or small, shallow or deep, wide or narrow LVs,\nthe LVs found only by the D-Wave are distinguished by a few-times smaller size\nof the LV basin of attraction (BoA). Apparently, the size of the BoA is not or\nat least is less important for QA search compared to the classical search,\nallowing QA to easily find many potentially important (e.g., wide and deep) LVs\nmissed by even prohibitively lengthy classical searches.\n", "versions": [{"version": "v1", "created": "Fri, 8 Nov 2019 15:53:51 GMT"}], "update_date": "2019-11-11", "authors_parsed": [["Koshka", "Yaroslav", ""], ["Novotny", "M. A.", ""]]}, {"id": "1911.03347", "submitter": "Juri Opitz", "authors": "Juri Opitz and Sebastian Burst", "title": "Macro F1 and Macro F1", "comments": "6 pages (+ appendix), 6 figures, fixed typo", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The 'macro F1' metric is frequently used to evaluate binary, multi-class and\nmulti-label classification problems. Yet, we find that there exist two\ndifferent formulas to calculate this quantity. In this note, we show that only\nunder rare circumstances the two computations can be considered equivalent.\nMore specifically, one formula well 'rewards' classifiers which produce a\nskewed error type distribution. In fact, the difference in outcome of the two\ncomputations can be as high as 0.5. The two computations may not only diverge\nin their scalar result but can also lead to different classifier rankings.\n", "versions": [{"version": "v1", "created": "Fri, 8 Nov 2019 16:13:54 GMT"}, {"version": "v2", "created": "Wed, 20 Nov 2019 09:24:02 GMT"}, {"version": "v3", "created": "Mon, 8 Feb 2021 18:20:55 GMT"}], "update_date": "2021-02-09", "authors_parsed": [["Opitz", "Juri", ""], ["Burst", "Sebastian", ""]]}, {"id": "1911.03362", "submitter": "Nikolay Bogoychev Dr", "authors": "Nikolay Bogoychev and Rico Sennrich", "title": "Domain, Translationese and Noise in Synthetic Data for Neural Machine\n  Translation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The quality of neural machine translation can be improved by leveraging\nadditional monolingual resources to create synthetic training data. Source-side\nmonolingual data can be (forward-)translated into the target language for\nself-training; target-side monolingual data can be back-translated. It has been\nwidely reported that back-translation delivers superior results, but could this\nbe due to artefacts in the test sets? We perform a case study using\nFrench-English news translation task and separate test sets based on their\noriginal languages. We show that forward translation delivers superior gains in\nterms of BLEU on sentences that were originally in the source language,\ncomplementing previous studies which show large improvements with\nback-translation on sentences that were originally in the target language. To\nbetter understand when and why forward and back-translation are effective, we\nstudy the role of domains, translationese, and noise. While translationese\neffects are well known to influence MT evaluation, we also find evidence that\nnews data from different languages shows subtle domain differences, which is\nanother explanation for varying performance on different portions of the test\nset. We perform additional low-resource experiments which demonstrate that\nforward translation is more sensitive to the quality of the initial translation\nsystem than back-translation, and tends to perform worse in low-resource\nsettings.\n", "versions": [{"version": "v1", "created": "Wed, 6 Nov 2019 17:30:57 GMT"}, {"version": "v2", "created": "Sat, 3 Oct 2020 17:14:02 GMT"}], "update_date": "2020-10-06", "authors_parsed": [["Bogoychev", "Nikolay", ""], ["Sennrich", "Rico", ""]]}, {"id": "1911.03366", "submitter": "Ankita Tondwalkar", "authors": "Ankita Tondwalkar and Dr Andres Kwasinski", "title": "Deep Reinforcement Learning for Distributed Uncoordinated Cognitive\n  Radios Resource Allocation", "comments": "This paper has been submitted in the 21st IEEE International Workshop\n  On Signal Processing Advances In Wireless Communications (SPAWC 2020)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper presents a novel deep reinforcement learning-based resource\nallocation technique for the multi-agent environment presented by a cognitive\nradio network that coexists through underlay dynamic spectrum access (DSA) with\na primary network. The resource allocation technique presented in this work is\ndistributed, not requiring coordination with other agents. The presented\nalgorithm is the first deep reinforcement learning technique for which\nconvergence to equilibrium policies can be shown in the non-stationary\nmulti-agent environment that results from the uncoordinated dynamic interaction\nbetween radios through the shared wireless environment. Moreover, simulation\nresults show that in a finite learning time the presented technique is able to\nfind policies that yield performance within 3 % of an exhaustive search\nsolution, finding the optimal policy in nearly 70 % of cases. Moreover, it is\nshown that standard single-agent deep reinforcement learning may not achieve\nconvergence when used in a non-coordinated, coupled multi-radio scenario.\n", "versions": [{"version": "v1", "created": "Tue, 29 Oct 2019 20:19:37 GMT"}, {"version": "v2", "created": "Fri, 6 Mar 2020 16:54:41 GMT"}], "update_date": "2020-03-09", "authors_parsed": [["Tondwalkar", "Ankita", ""], ["Kwasinski", "Dr Andres", ""]]}, {"id": "1911.03378", "submitter": "Maryam Fazel-Zarandi", "authors": "Maryam Fazel-Zarandi, Longshaokan Wang, Aditya Tiwari, Spyros\n  Matsoukas", "title": "Investigation of Error Simulation Techniques for Learning Dialog\n  Policies for Conversational Error Recovery", "comments": "The 3rd Conversational AI workshop - today's practice and tomorrow's\n  potential", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Training dialog policies for speech-based virtual assistants requires a\nplethora of conversational data. The data collection phase is often expensive\nand time consuming due to human involvement. To address this issue, a common\nsolution is to build user simulators for data generation. For the successful\ndeployment of the trained policies into real world domains, it is vital that\nthe user simulator mimics realistic conditions. In particular, speech-based\nassistants are heavily affected by automatic speech recognition and language\nunderstanding errors, hence the user simulator should be able to simulate\nsimilar errors. In this paper, we review the existing error simulation methods\nthat induce errors at audio, phoneme, text, or semantic level; and conduct\ndetailed comparisons between the audio-level and text-level methods. In the\nprocess, we improve the existing text-level method by introducing confidence\nscore prediction and out-of-vocabulary word mapping. We also explore the impact\nof audio-level and text-level methods on learning a simple clarification dialog\npolicy to recover from errors to provide insight on future improvement for both\napproaches.\n", "versions": [{"version": "v1", "created": "Fri, 8 Nov 2019 16:59:17 GMT"}], "update_date": "2019-11-11", "authors_parsed": [["Fazel-Zarandi", "Maryam", ""], ["Wang", "Longshaokan", ""], ["Tiwari", "Aditya", ""], ["Matsoukas", "Spyros", ""]]}, {"id": "1911.03393", "submitter": "Yuge Shi", "authors": "Yuge Shi, N. Siddharth, Brooks Paige, Philip H.S. Torr", "title": "Variational Mixture-of-Experts Autoencoders for Multi-Modal Deep\n  Generative Models", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Learning generative models that span multiple data modalities, such as vision\nand language, is often motivated by the desire to learn more useful,\ngeneralisable representations that faithfully capture common underlying factors\nbetween the modalities. In this work, we characterise successful learning of\nsuch models as the fulfillment of four criteria: i) implicit latent\ndecomposition into shared and private subspaces, ii) coherent joint generation\nover all modalities, iii) coherent cross-generation across individual\nmodalities, and iv) improved model learning for individual modalities through\nmulti-modal integration. Here, we propose a mixture-of-experts multimodal\nvariational autoencoder (MMVAE) to learn generative models on different sets of\nmodalities, including a challenging image-language dataset, and demonstrate its\nability to satisfy all four criteria, both qualitatively and quantitatively.\n", "versions": [{"version": "v1", "created": "Fri, 8 Nov 2019 17:18:57 GMT"}], "update_date": "2019-11-11", "authors_parsed": [["Shi", "Yuge", ""], ["Siddharth", "N.", ""], ["Paige", "Brooks", ""], ["Torr", "Philip H. S.", ""]]}, {"id": "1911.03405", "submitter": "Mario Diaz", "authors": "Mario Diaz and Peter Kairouz and Jiachun Liao and Lalitha Sankar", "title": "Theoretical Guarantees for Model Auditing with Finite Adversaries", "comments": "18 pages, 1 figure", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Privacy concerns have led to the development of privacy-preserving approaches\nfor learning models from sensitive data. Yet, in practice, even models learned\nwith privacy guarantees can inadvertently memorize unique training examples or\nleak sensitive features. To identify such privacy violations, existing model\nauditing techniques use finite adversaries defined as machine learning models\nwith (a) access to some finite side information (e.g., a small auditing\ndataset), and (b) finite capacity (e.g., a fixed neural network architecture).\nOur work investigates the requirements under which an unsuccessful attempt to\nidentify privacy violations by a finite adversary implies that no stronger\nadversary can succeed at such a task. We do so via parameters that quantify the\ncapabilities of the finite adversary, including the size of the neural network\nemployed by such an adversary and the amount of side information it has access\nto as well as the regularity of the (perhaps privacy-guaranteeing) audited\nmodel.\n", "versions": [{"version": "v1", "created": "Fri, 8 Nov 2019 17:39:00 GMT"}], "update_date": "2019-11-11", "authors_parsed": [["Diaz", "Mario", ""], ["Kairouz", "Peter", ""], ["Liao", "Jiachun", ""], ["Sankar", "Lalitha", ""]]}, {"id": "1911.03409", "submitter": "Parthe Pandit", "authors": "Parthe Pandit, Mojtaba Sahraee-Ardakan, Sundeep Rangan, Philip\n  Schniter, Alyson K. Fletcher", "title": "Inference with Deep Generative Priors in High Dimensions", "comments": "50 pages, double-spaced", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.IT cs.NE eess.SP math.IT stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep generative priors offer powerful models for complex-structured data,\nsuch as images, audio, and text. Using these priors in inverse problems\ntypically requires estimating the input and/or hidden signals in a multi-layer\ndeep neural network from observation of its output. While these approaches have\nbeen successful in practice, rigorous performance analysis is complicated by\nthe non-convex nature of the underlying optimization problems. This paper\npresents a novel algorithm, Multi-Layer Vector Approximate Message Passing\n(ML-VAMP), for inference in multi-layer stochastic neural networks. ML-VAMP can\nbe configured to compute maximum a priori (MAP) or approximate minimum\nmean-squared error (MMSE) estimates for these networks. We show that the\nperformance of ML-VAMP can be exactly predicted in a certain high-dimensional\nrandom limit. Furthermore, under certain conditions, ML-VAMP yields estimates\nthat achieve the minimum (i.e., Bayes-optimal) MSE as predicted by the replica\nmethod. In this way, ML-VAMP provides a computationally efficient method for\nmulti-layer inference with an exact performance characterization and testable\nconditions for optimality in the large-system limit.\n", "versions": [{"version": "v1", "created": "Fri, 8 Nov 2019 17:54:10 GMT"}], "update_date": "2019-11-11", "authors_parsed": [["Pandit", "Parthe", ""], ["Sahraee-Ardakan", "Mojtaba", ""], ["Rangan", "Sundeep", ""], ["Schniter", "Philip", ""], ["Fletcher", "Alyson K.", ""]]}, {"id": "1911.03417", "submitter": "Claire Donnat", "authors": "Claire Donnat, Susan Holmes", "title": "Convex Hierarchical Clustering for Graph-Structured Data", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.AP cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Convex clustering is a recent stable alternative to hierarchical clustering.\nIt formulates the recovery of progressively coalescing clusters as a\nregularized convex problem. While convex clustering was originally designed for\nhandling Euclidean distances between data points, in a growing number of\napplications, the data is directly characterized by a similarity matrix or\nweighted graph. In this paper, we extend the robust hierarchical clustering\napproach to these broader classes of similarities. Having defined an\nappropriate convex objective, the crux of this adaptation lies in our ability\nto provide: (a) an efficient recovery of the regularization path and (b) an\nempirical demonstration of the use of our method. We address the first\nchallenge through a proximal dual algorithm, for which we characterize both the\ntheoretical efficiency as well as the empirical performance on a set of\nexperiments. Finally, we highlight the potential of our method by showing its\napplication to several real-life datasets, thus providing a natural extension\nto the current scope of applications of convex clustering.\n", "versions": [{"version": "v1", "created": "Fri, 8 Nov 2019 18:08:21 GMT"}, {"version": "v2", "created": "Wed, 11 Dec 2019 00:00:38 GMT"}], "update_date": "2019-12-12", "authors_parsed": [["Donnat", "Claire", ""], ["Holmes", "Susan", ""]]}, {"id": "1911.03422", "submitter": "Konstantinos Gatsis", "authors": "Konstantinos Gatsis, George J. Pappas", "title": "Statistical Learning for Analysis of Networked Control Systems over\n  Unknown Channels", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.SY cs.LG cs.SY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent control trends are increasingly relying on communication networks and\nwireless channels to close the loop for Internet-of-Things applications.\nTraditionally these approaches are model-based, i.e., assuming a network or\nchannel model they are focused on stability analysis and appropriate controller\ndesigns. However the availability of such wireless channel modeling is\nfundamentally challenging in practice as channels are typically unknown a\npriori and only available through data samples. In this work we aim to develop\nalgorithms that rely on channel sample data to determine the stability and\nperformance of networked control tasks. In this regard our work is the first to\ncharacterize the amount of channel modeling that is required to answer such a\nquestion. Specifically we examine how many channel data samples are required in\norder to answer with high confidence whether a given networked control system\nis stable or not. This analysis is based on the notion of sample complexity\nfrom the learning literature and is facilitated by concentration inequalities.\nMoreover we establish a direct relation between the sample complexity and the\nnetworked system stability margin, i.e., the underlying packet success rate of\nthe channel and the spectral radius of the dynamics of the control system. This\nillustrates that it becomes impractical to verify stability under a large range\nof plant and channel configurations. We validate our theoretical results in\nnumerical simulations.\n", "versions": [{"version": "v1", "created": "Fri, 8 Nov 2019 18:14:49 GMT"}], "update_date": "2019-11-11", "authors_parsed": [["Gatsis", "Konstantinos", ""], ["Pappas", "George J.", ""]]}, {"id": "1911.03429", "submitter": "Jay DeYoung", "authors": "Jay DeYoung, Sarthak Jain, Nazneen Fatema Rajani, Eric Lehman, Caiming\n  Xiong, Richard Socher, Byron C. Wallace", "title": "ERASER: A Benchmark to Evaluate Rationalized NLP Models", "comments": "Accepted as a long paper to ACL2020 Website and leaderboard available\n  at http://www.eraserbenchmark.com/ Code available at\n  https://github.com/jayded/eraserbenchmark", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  State-of-the-art models in NLP are now predominantly based on deep neural\nnetworks that are opaque in terms of how they come to make predictions. This\nlimitation has increased interest in designing more interpretable deep models\nfor NLP that reveal the `reasoning' behind model outputs. But work in this\ndirection has been conducted on different datasets and tasks with\ncorrespondingly unique aims and metrics; this makes it difficult to track\nprogress. We propose the Evaluating Rationales And Simple English Reasoning\n(ERASER) benchmark to advance research on interpretable models in NLP. This\nbenchmark comprises multiple datasets and tasks for which human annotations of\n\"rationales\" (supporting evidence) have been collected. We propose several\nmetrics that aim to capture how well the rationales provided by models align\nwith human rationales, and also how faithful these rationales are (i.e., the\ndegree to which provided rationales influenced the corresponding predictions).\nOur hope is that releasing this benchmark facilitates progress on designing\nmore interpretable NLP systems. The benchmark, code, and documentation are\navailable at https://www.eraserbenchmark.com/\n", "versions": [{"version": "v1", "created": "Fri, 8 Nov 2019 18:29:03 GMT"}, {"version": "v2", "created": "Fri, 24 Apr 2020 17:25:40 GMT"}], "update_date": "2020-04-27", "authors_parsed": [["DeYoung", "Jay", ""], ["Jain", "Sarthak", ""], ["Rajani", "Nazneen Fatema", ""], ["Lehman", "Eric", ""], ["Xiong", "Caiming", ""], ["Socher", "Richard", ""], ["Wallace", "Byron C.", ""]]}, {"id": "1911.03432", "submitter": "Akshay Mehra", "authors": "Akshay Mehra and Jihun Hamm", "title": "Penalty Method for Inversion-Free Deep Bilevel Optimization", "comments": "22 Pages, 7 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG math.OC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Bilevel optimization problems are at the center of several important machine\nlearning problems such as hyperparameter tuning, data denoising, meta- and\nfew-shot learning, and training-data poisoning. Different from simultaneous or\nmulti-objective optimization, the steepest descent direction for minimizing the\nupper-level cost requires the inverse of the Hessian of the lower-level cost.\nIn this paper, we propose a new method for solving bilevel optimization\nproblems using the classical penalty function approach which avoids computing\nthe inverse and can also handle additional constraints easily. We prove the\nconvergence of the method under mild conditions and show that the exact\nhypergradient is obtained asymptotically. Our method's simplicity and small\nspace and time complexities enable us to effectively solve large-scale bilevel\nproblems involving deep neural networks. We present results on data denoising,\nfew-shot learning, and training-data poisoning problems in a large scale\nsetting and show that our method outperforms or is comparable to previously\nproposed methods based on automatic differentiation and approximate inversion\nin terms of accuracy, run-time and convergence speed.\n", "versions": [{"version": "v1", "created": "Fri, 8 Nov 2019 18:33:29 GMT"}, {"version": "v2", "created": "Sun, 29 Dec 2019 05:29:39 GMT"}, {"version": "v3", "created": "Sat, 15 Feb 2020 14:34:59 GMT"}, {"version": "v4", "created": "Thu, 20 Feb 2020 18:42:21 GMT"}, {"version": "v5", "created": "Sun, 28 Jun 2020 17:45:39 GMT"}], "update_date": "2020-06-30", "authors_parsed": [["Mehra", "Akshay", ""], ["Hamm", "Jihun", ""]]}, {"id": "1911.03437", "submitter": "Haoming Jiang", "authors": "Haoming Jiang, Pengcheng He, Weizhu Chen, Xiaodong Liu, Jianfeng Gao,\n  Tuo Zhao", "title": "SMART: Robust and Efficient Fine-Tuning for Pre-trained Natural Language\n  Models through Principled Regularized Optimization", "comments": "The 58th annual meeting of the Association for Computational\n  Linguistics (ACL 2020)", "journal-ref": null, "doi": "10.18653/v1/2020.acl-main.197", "report-no": null, "categories": "cs.CL cs.LG math.OC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Transfer learning has fundamentally changed the landscape of natural language\nprocessing (NLP) research. Many existing state-of-the-art models are first\npre-trained on a large text corpus and then fine-tuned on downstream tasks.\nHowever, due to limited data resources from downstream tasks and the extremely\nlarge capacity of pre-trained models, aggressive fine-tuning often causes the\nadapted model to overfit the data of downstream tasks and forget the knowledge\nof the pre-trained model. To address the above issue in a more principled\nmanner, we propose a new computational framework for robust and efficient\nfine-tuning for pre-trained language models. Specifically, our proposed\nframework contains two important ingredients: 1. Smoothness-inducing\nregularization, which effectively manages the capacity of the model; 2. Bregman\nproximal point optimization, which is a class of trust-region methods and can\nprevent knowledge forgetting. Our experiments demonstrate that our proposed\nmethod achieves the state-of-the-art performance on multiple NLP benchmarks.\n", "versions": [{"version": "v1", "created": "Fri, 8 Nov 2019 18:41:31 GMT"}, {"version": "v2", "created": "Fri, 1 May 2020 18:44:04 GMT"}, {"version": "v3", "created": "Mon, 18 Jan 2021 19:58:17 GMT"}, {"version": "v4", "created": "Mon, 15 Feb 2021 17:52:35 GMT"}], "update_date": "2021-02-16", "authors_parsed": [["Jiang", "Haoming", ""], ["He", "Pengcheng", ""], ["Chen", "Weizhu", ""], ["Liu", "Xiaodong", ""], ["Gao", "Jianfeng", ""], ["Zhao", "Tuo", ""]]}, {"id": "1911.03441", "submitter": "Chao Wang", "authors": "Chao Wang, Yi Hou, and Matthew Barth", "title": "Data-Driven Multi-step Demand Prediction for Ride-hailing Services Using\n  Convolutional Neural Network", "comments": null, "journal-ref": "Advances in Computer Vision. CVC 2019. Advances in Intelligent\n  Systems and Computing, vol 944", "doi": "10.1007/978-3-030-17798-0_2", "report-no": null, "categories": "cs.LG cs.SY eess.SP eess.SY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Ride-hailing services are growing rapidly and becoming one of the most\ndisruptive technologies in the transportation realm. Accurate prediction of\nride-hailing trip demand not only enables cities to better understand people's\nactivity patterns, but also helps ride-hailing companies and drivers make\ninformed decisions to reduce deadheading vehicle miles traveled, traffic\ncongestion, and energy consumption. In this study, a convolutional neural\nnetwork (CNN)-based deep learning model is proposed for multi-step ride-hailing\ndemand prediction using the trip request data in Chengdu, China, offered by\nDiDi Chuxing. The CNN model is capable of accurately predicting the\nride-hailing pick-up demand at each 1-km by 1-km zone in the city of Chengdu\nfor every 10 minutes. Compared with another deep learning model based on long\nshort-term memory, the CNN model is 30% faster for the training and predicting\nprocess. The proposed model can also be easily extended to make multi-step\npredictions, which would benefit the on-demand shared autonomous vehicles\napplications and fleet operators in terms of supply-demand rebalancing. The\nprediction error attenuation analysis shows that the accuracy stays acceptable\nas the model predicts more steps.\n", "versions": [{"version": "v1", "created": "Fri, 8 Nov 2019 18:49:12 GMT"}], "update_date": "2019-11-11", "authors_parsed": [["Wang", "Chao", ""], ["Hou", "Yi", ""], ["Barth", "Matthew", ""]]}, {"id": "1911.03443", "submitter": "Rudrasis Chakraborty Dr.", "authors": "Liu Yang and Rudrasis Chakraborty", "title": "An \"augmentation-free\" rotation invariant classification scheme on\n  point-cloud and its application to neuroimaging", "comments": "arXiv admin note: text overlap with arXiv:1910.13050 and\n  arXiv:1911.01705", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.IV cs.CV cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent years have witnessed the emergence and increasing popularity of 3D\nmedical imaging techniques with the development of 3D sensors and technology.\nHowever, achieving geometric invariance in the processing of 3D medical images\nis computationally expensive but nonetheless essential due to the presence of\npossible errors caused by rigid registration techniques. An alternative way to\nanalyze medical imaging is by understanding the 3D shapes represented in terms\nof point-cloud. Though in the medical imaging community, 3D point-cloud\nprocessing is not a \"go-to\" choice, it is a canonical way to preserve rotation\ninvariance. Unfortunately, due to the presence of discrete topology, one can\nnot use the standard convolution operator on point-cloud. To the best of our\nknowledge, the existing ways to do \"convolution\" can not preserve the rotation\ninvariance without explicit data augmentation. Therefore, we propose a rotation\ninvariant convolution operator by inducing topology from hypersphere.\nExperimental validation has been performed on publicly available OASIS dataset\nin terms of classification accuracy between subjects with (without) dementia,\ndemonstrating the usefulness of our proposed method in terms of model\ncomplexity, classification accuracy, and last but most important invariance to\nrotations.\n", "versions": [{"version": "v1", "created": "Tue, 5 Nov 2019 10:45:56 GMT"}], "update_date": "2019-11-11", "authors_parsed": [["Yang", "Liu", ""], ["Chakraborty", "Rudrasis", ""]]}, {"id": "1911.03444", "submitter": "Karl B\\\"ackstr\\\"om", "authors": "Karl B\\\"ackstr\\\"om, Marina Papatriantafilou, Philippas Tsigas", "title": "MindTheStep-AsyncPSGD: Adaptive Asynchronous Parallel Stochastic\n  Gradient Descent", "comments": "12 pages, 3 figures, accepted in IEEE BigData 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Stochastic Gradient Descent (SGD) is very useful in optimization problems\nwith high-dimensional non-convex target functions, and hence constitutes an\nimportant component of several Machine Learning and Data Analytics methods.\nRecently there have been significant works on understanding the parallelism\ninherent to SGD, and its convergence properties. Asynchronous, parallel SGD\n(AsyncPSGD) has received particular attention, due to observed performance\nbenefits. On the other hand, asynchrony implies inherent challenges in\nunderstanding the execution of the algorithm and its convergence, stemming from\nthe fact that the contribution of a thread might be based on an old (stale)\nview of the state. In this work we aim to deepen the understanding of AsyncPSGD\nin order to increase the statistical efficiency in the presence of stale\ngradients. We propose new models for capturing the nature of the staleness\ndistribution in a practical setting. Using the proposed models, we derive a\nstaleness-adaptive SGD framework, MindTheStep-AsyncPSGD, for adapting the step\nsize in an online-fashion, which provably reduces the negative impact of\nasynchrony. Moreover, we provide general convergence time bounds for a wide\nclass of staleness-adaptive step size strategies for convex target functions.\nWe also provide a detailed empirical study, showing how our approach implies\nfaster convergence for deep learning applications.\n", "versions": [{"version": "v1", "created": "Fri, 8 Nov 2019 18:53:10 GMT"}], "update_date": "2019-11-11", "authors_parsed": [["B\u00e4ckstr\u00f6m", "Karl", ""], ["Papatriantafilou", "Marina", ""], ["Tsigas", "Philippas", ""]]}, {"id": "1911.03451", "submitter": "Xingyao Zhang", "authors": "Xingyao Zhang, Shuaiwen Leon Song, Chenhao Xie, Jing Wang, Weigong\n  Zhang and Xin Fu", "title": "Enabling Highly Efficient Capsule Networks Processing Through A\n  PIM-Based Architecture Design", "comments": "To appear in the 2020 26th International Symposium on\n  High-Performance Computer Architecture (HPCA 2020)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.AR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In recent years, the CNNs have achieved great successes in the image\nprocessing tasks, e.g., image recognition and object detection. Unfortunately,\ntraditional CNN's classification is found to be easily misled by increasingly\ncomplex image features due to the usage of pooling operations, hence unable to\npreserve accurate position and pose information of the objects. To address this\nchallenge, a novel neural network structure called Capsule Network has been\nproposed, which introduces equivariance through capsules to significantly\nenhance the learning ability for image segmentation and object detection. Due\nto its requirement of performing a high volume of matrix operations, CapsNets\nhave been generally accelerated on modern GPU platforms that provide highly\noptimized software library for common deep learning tasks. However, based on\nour performance characterization on modern GPUs, CapsNets exhibit low\nefficiency due to the special program and execution features of their routing\nprocedure, including massive unshareable intermediate variables and intensive\nsynchronizations, which are very difficult to optimize at software level. To\naddress these challenges, we propose a hybrid computing architecture design\nnamed \\textit{PIM-CapsNet}. It preserves GPU's on-chip computing capability for\naccelerating CNN types of layers in CapsNet, while pipelining with an off-chip\nin-memory acceleration solution that effectively tackles routing procedure's\ninefficiency by leveraging the processing-in-memory capability of today's 3D\nstacked memory. Using routing procedure's inherent parallellization feature,\nour design enables hierarchical improvements on CapsNet inference efficiency\nthrough minimizing data movement and maximizing parallel processing in memory.\n", "versions": [{"version": "v1", "created": "Thu, 7 Nov 2019 06:03:46 GMT"}], "update_date": "2019-11-12", "authors_parsed": [["Zhang", "Xingyao", ""], ["Song", "Shuaiwen Leon", ""], ["Xie", "Chenhao", ""], ["Wang", "Jing", ""], ["Zhang", "Weigong", ""], ["Fu", "Xin", ""]]}, {"id": "1911.03459", "submitter": "Hwiyeol Jo", "authors": "Hwiyeol Jo and Byoung-Tak Zhang", "title": "Ruminating Word Representations with Random Noised Masker", "comments": "AAAI ver", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce a training method for both better word representation and\nperformance, which we call GROVER (Gradual Rumination On the Vector with\nmaskERs). The method is to gradually and iteratively add random noises to word\nembeddings while training a model. GROVER first starts from conventional\ntraining process, and then extracts the fine-tuned representations. Next, we\ngradually add random noises to the word representations and repeat the training\nprocess from scratch, but initialize with the noised word representations.\nThrough the re-training process, we can mitigate some noises to be compensated\nand utilize other noises to learn better representations. As a result, we can\nget word representations further fine-tuned and specialized on the task. When\nwe experiment with our method on 5 text classification datasets, our method\nimproves model performances on most of the datasets. Moreover, we show that our\nmethod can be combined with other regularization techniques, further improving\nthe model performance.\n", "versions": [{"version": "v1", "created": "Fri, 8 Nov 2019 05:23:43 GMT"}], "update_date": "2019-11-12", "authors_parsed": [["Jo", "Hwiyeol", ""], ["Zhang", "Byoung-Tak", ""]]}, {"id": "1911.03462", "submitter": "Umberto Michieli", "authors": "Umberto Michieli and Pietro Zanuttigh", "title": "Knowledge Distillation for Incremental Learning in Semantic Segmentation", "comments": "Computer Vision and Image Understanding (CVIU), 2021. arXiv admin\n  note: text overlap with arXiv:1907.13372", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG eess.IV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep learning architectures have shown remarkable results in scene\nunderstanding problems, however they exhibit a critical drop of performances\nwhen they are required to learn incrementally new tasks without forgetting old\nones. This catastrophic forgetting phenomenon impacts on the deployment of\nartificial intelligence in real world scenarios where systems need to learn new\nand different representations over time. Current approaches for incremental\nlearning deal only with image classification and object detection tasks, while\nin this work we formally introduce incremental learning for semantic\nsegmentation. We tackle the problem applying various knowledge distillation\ntechniques on the previous model. In this way, we retain the information about\nlearned classes, whilst updating the current model to learn the new ones. We\ndeveloped four main methodologies of knowledge distillation working on both\noutput layers and internal feature representations. We do not store any image\nbelonging to previous training stages and only the last model is used to\npreserve high accuracy on previously learned classes. Extensive experimental\nresults on the Pascal VOC2012 and MSRC-v2 datasets show the effectiveness of\nthe proposed approaches in several incremental learning scenarios.\n", "versions": [{"version": "v1", "created": "Fri, 8 Nov 2019 08:17:03 GMT"}, {"version": "v2", "created": "Sun, 26 Jan 2020 11:29:10 GMT"}, {"version": "v3", "created": "Tue, 4 Feb 2020 17:53:16 GMT"}, {"version": "v4", "created": "Wed, 20 Jan 2021 20:03:16 GMT"}], "update_date": "2021-01-22", "authors_parsed": [["Michieli", "Umberto", ""], ["Zanuttigh", "Pietro", ""]]}, {"id": "1911.03472", "submitter": "Matthias Zisler", "authors": "Matthias Zisler, Artjom Zern, Stefania Petra, Christoph Schn\\\"orr", "title": "Self-Assignment Flows for Unsupervised Data Labeling on Graphs", "comments": "42 pages, 17 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper extends the recently introduced assignment flow approach for\nsupervised image labeling to unsupervised scenarios where no labels are given.\nThe resulting self-assignment flow takes a pairwise data affinity matrix as\ninput data and maximizes the correlation with a low-rank matrix that is\nparametrized by the variables of the assignment flow, which entails an\nassignment of the data to themselves through the formation of latent labels\n(feature prototypes). A single user parameter, the neighborhood size for the\ngeometric regularization of assignments, drives the entire process. By smooth\ngeodesic interpolation between different normalizations of self-assignment\nmatrices on the positive definite matrix manifold, a one-parameter family of\nself-assignment flows is defined. Accordingly, our approach can be\ncharacterized from different viewpoints, e.g. as performing spatially\nregularized, rank-constrained discrete optimal transport, or as computing\nspatially regularized normalized spectral cuts. Regarding combinatorial\noptimization, our approach successfully determines completely positive\nfactorizations of self-assignments in large-scale scenarios, subject to spatial\nregularization. Various experiments including the unsupervised learning of\npatch dictionaries using a locally invariant distance function, illustrate the\nproperties of the approach.\n", "versions": [{"version": "v1", "created": "Fri, 8 Nov 2019 16:35:13 GMT"}, {"version": "v2", "created": "Tue, 24 Mar 2020 12:35:23 GMT"}], "update_date": "2020-03-25", "authors_parsed": [["Zisler", "Matthias", ""], ["Zern", "Artjom", ""], ["Petra", "Stefania", ""], ["Schn\u00f6rr", "Christoph", ""]]}, {"id": "1911.03508", "submitter": "Jason Cheuk Nam Liang", "authors": "Negin Golrezaei, Patrick Jaillet, Jason Cheuk Nam Liang", "title": "Incentive-aware Contextual Pricing with Non-parametric Market Noise", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.GT stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider a dynamic pricing problem for repeated contextual second-price\nauctions with strategic buyers whose goals are to maximize their long-term time\ndiscounted utility. The seller has very limited information about buyers'\noverall demand curves, which depends on $d$-dimensional context vectors\ncharacterizing auctioned items, and a non-parametric market noise distribution\nthat captures buyers' idiosyncratic tastes. The noise distribution and the\nrelationship between the context vectors and buyers' demand curves are both\nunknown to the seller. We focus on designing the seller's learning policy to\nset contextual reserve prices where the seller's goal is to minimize his regret\nfor revenue. We first propose a pricing policy when buyers are truthful and\nshow that it achieves a $T$-period regret bound of\n$\\tilde{\\mathcal{O}}(\\sqrt{dT})$ against a clairvoyant policy that has full\ninformation of the buyers' demand. Next, under the setting where buyers bid\nstrategically to maximize their long-term discounted utility, we develop a\nvariant of our first policy that is robust to strategic (corrupted) bids. This\npolicy incorporates randomized \"isolation\" periods, during which a buyer is\nrandomly chosen to solely participate in the auction. We show that this design\nallows the seller to control the number of periods in which buyers\nsignificantly corrupt their bids. Because of this nice property, our robust\npolicy enjoys a $T$-period regret of $\\tilde{\\mathcal{O}}(\\sqrt{dT})$, matching\nthat under the truthful setting up to a constant factor that depends on the\nutility discount factor.\n", "versions": [{"version": "v1", "created": "Fri, 8 Nov 2019 19:20:36 GMT"}, {"version": "v2", "created": "Sat, 7 Nov 2020 02:28:33 GMT"}], "update_date": "2020-11-10", "authors_parsed": [["Golrezaei", "Negin", ""], ["Jaillet", "Patrick", ""], ["Liang", "Jason Cheuk Nam", ""]]}, {"id": "1911.03512", "submitter": "Ronny Guendel", "authors": "Moeness G. Amin and Ronny G. Guendel", "title": "Radar Human Motion Recognition Using Motion States and Two-Way\n  Classifications", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.SP cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We perform classification of activities of daily living (ADL) using a\nFrequency-Modulated Continuous Waveform (FMCW) radar. In particular, we\nconsider contiguous motions that are inseparable in time. Both the\nmicro-Doppler signature and range-map are used to determine transitions from\ntranslation (walking) to in-place motions and vice versa, as well as to provide\nmotion onset and the offset times. The possible classes of activities post and\nprior to the translation motion can be separately handled by forward and\nbackground classifiers. The paper describes ADL in terms of states and\ntransitioning actions, and sets a framework to deal with separable and\ninseparable contiguous motions. It is shown that considering only the\nphysically possible classes of motions stemming from the current motion state\nimproves classification rates compared to incorporating all ADL for any given\ntime.\n", "versions": [{"version": "v1", "created": "Fri, 8 Nov 2019 19:29:02 GMT"}], "update_date": "2019-12-18", "authors_parsed": [["Amin", "Moeness G.", ""], ["Guendel", "Ronny G.", ""]]}, {"id": "1911.03522", "submitter": "Ignacio Peis", "authors": "Ignacio Peis, Pablo M. Olmos, Constanza Vera-Varela, Mar\\'ia Luisa\n  Barrig\\'on, Philippe Courtet, Enrique Baca-Garc\\'ia and Antonio\n  Art\\'es-Rodr\\'iguez", "title": "Deep Sequential Models for Suicidal Ideation from Multiple Source Data", "comments": "Accepted for publication in IEEE Journal of Biomedical and Health\n  Informatics (JBHI)", "journal-ref": "Journal of Biomedical and Health Informatics, vol.23, no. 6, 2019", "doi": "10.1109/JBHI.2019.2919270", "report-no": null, "categories": "cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  This article presents a novel method for predicting suicidal ideation from\nElectronic Health Records (EHR) and Ecological Momentary Assessment (EMA) data\nusing deep sequential models. Both EHR longitudinal data and EMA question forms\nare defined by asynchronous, variable length, randomly-sampled data sequences.\nIn our method, we model each of them with a Recurrent Neural Network (RNN), and\nboth sequences are aligned by concatenating the hidden state of each of them\nusing temporal marks. Furthermore, we incorporate attention schemes to improve\nperformance in long sequences and time-independent pre-trained schemes to cope\nwith very short sequences. Using a database of 1023 patients, our experimental\nresults show that the addition of EMA records boosts the system recall to\npredict the suicidal ideation diagnosis from 48.13% obtained exclusively from\nEHR-based state-of-the-art methods to 67.78%. Additionally, our method provides\ninterpretability through the t-SNE representation of the latent space. Further,\nthe most relevant input features are identified and interpreted medically.\n", "versions": [{"version": "v1", "created": "Wed, 6 Nov 2019 12:55:28 GMT"}], "update_date": "2019-11-12", "authors_parsed": [["Peis", "Ignacio", ""], ["Olmos", "Pablo M.", ""], ["Vera-Varela", "Constanza", ""], ["Barrig\u00f3n", "Mar\u00eda Luisa", ""], ["Courtet", "Philippe", ""], ["Baca-Garc\u00eda", "Enrique", ""], ["Art\u00e9s-Rodr\u00edguez", "Antonio", ""]]}, {"id": "1911.03531", "submitter": "Ali Fadel", "authors": "Ali Fadel, Ibraheem Tuffaha, Bara' Al-Jawarneh, Mahmoud Al-Ayyoub", "title": "Neural Arabic Text Diacritization: State of the Art Results and a Novel\n  Approach for Machine Translation", "comments": "18 pages, 17 figures, 14 tables", "journal-ref": null, "doi": "10.18653/v1/D19-5229", "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this work, we present several deep learning models for the automatic\ndiacritization of Arabic text. Our models are built using two main approaches,\nviz. Feed-Forward Neural Network (FFNN) and Recurrent Neural Network (RNN),\nwith several enhancements such as 100-hot encoding, embeddings, Conditional\nRandom Field (CRF) and Block-Normalized Gradient (BNG). The models are tested\non the only freely available benchmark dataset and the results show that our\nmodels are either better or on par with other models, which require\nlanguage-dependent post-processing steps, unlike ours. Moreover, we show that\ndiacritics in Arabic can be used to enhance the models of NLP tasks such as\nMachine Translation (MT) by proposing the Translation over Diacritization (ToD)\napproach.\n", "versions": [{"version": "v1", "created": "Fri, 8 Nov 2019 20:52:12 GMT"}], "update_date": "2019-11-12", "authors_parsed": [["Fadel", "Ali", ""], ["Tuffaha", "Ibraheem", ""], ["Al-Jawarneh", "Bara'", ""], ["Al-Ayyoub", "Mahmoud", ""]]}, {"id": "1911.03539", "submitter": "Soroosh Shafieezadeh-Abadeh", "authors": "Viet Anh Nguyen and Soroosh Shafieezadeh-Abadeh and Daniel Kuhn and\n  Peyman Mohajerin Esfahani", "title": "Bridging Bayesian and Minimax Mean Square Error Estimation via\n  Wasserstein Distributionally Robust Optimization", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.OC cs.LG math.ST stat.ML stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce a distributionally robust minimium mean square error estimation\nmodel with a Wasserstein ambiguity set to recover an unknown signal from a\nnoisy observation. The proposed model can be viewed as a zero-sum game between\na statistician choosing an estimator -- that is, a measurable function of the\nobservation -- and a fictitious adversary choosing a prior -- that is, a pair\nof signal and noise distributions ranging over independent Wasserstein balls --\nwith the goal to minimize and maximize the expected squared estimation error,\nrespectively. We show that if the Wasserstein balls are centered at normal\ndistributions, then the zero-sum game admits a Nash equilibrium, where the\nplayers' optimal strategies are given by an {\\em affine} estimator and a {\\em\nnormal} prior, respectively. We further prove that this Nash equilibrium can be\ncomputed by solving a tractable convex program. Finally, we develop a\nFrank-Wolfe algorithm that can solve this convex program orders of magnitude\nfaster than state-of-the-art general purpose solvers. We show that this\nalgorithm enjoys a linear convergence rate and that its direction-finding\nsubproblems can be solved in quasi-closed form.\n", "versions": [{"version": "v1", "created": "Fri, 8 Nov 2019 21:10:25 GMT"}, {"version": "v2", "created": "Wed, 27 Jan 2021 10:00:16 GMT"}], "update_date": "2021-01-28", "authors_parsed": [["Nguyen", "Viet Anh", ""], ["Shafieezadeh-Abadeh", "Soroosh", ""], ["Kuhn", "Daniel", ""], ["Esfahani", "Peyman Mohajerin", ""]]}, {"id": "1911.03548", "submitter": "Dushyant Sahoo", "authors": "Soham Dan and Dushyant Sahoo", "title": "Variance Reduced Stochastic Proximal Algorithm for AUC Maximization", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Stochastic Gradient Descent has been widely studied with classification\naccuracy as a performance measure. However, these stochastic algorithms cannot\nbe directly used when non-decomposable pairwise performance measures are used\nsuch as Area under the ROC curve (AUC) which is a common performance metric\nwhen the classes are imbalanced. There have been several algorithms proposed\nfor optimizing AUC as a performance metric, and one of the recent being a\nstochastic proximal gradient algorithm (SPAM). But the downside of the\nstochastic methods is that they suffer from high variance leading to slower\nconvergence. To combat this issue, several variance reduced methods have been\nproposed with faster convergence guarantees than vanilla stochastic gradient\ndescent. Again, these variance reduced methods are not directly applicable when\nnon-decomposable performance measures are used. In this paper, we develop a\nVariance Reduced Stochastic Proximal algorithm for AUC Maximization\n(\\textsc{VRSPAM}) and perform a theoretical analysis as well as empirical\nanalysis to show that our algorithm converges faster than SPAM which is the\nprevious state-of-the-art for the AUC maximization problem.\n", "versions": [{"version": "v1", "created": "Fri, 8 Nov 2019 21:23:20 GMT"}, {"version": "v2", "created": "Fri, 4 Dec 2020 16:45:03 GMT"}], "update_date": "2020-12-07", "authors_parsed": [["Dan", "Soham", ""], ["Sahoo", "Dushyant", ""]]}, {"id": "1911.03561", "submitter": "Alireza Mohammadshahi", "authors": "Alireza Mohammadshahi and James Henderson", "title": "Graph-to-Graph Transformer for Transition-based Dependency Parsing", "comments": "Accepted to Findings of EMNLP 2020", "journal-ref": null, "doi": "10.18653/v1/2020.findings-emnlp.294", "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose the Graph2Graph Transformer architecture for conditioning on and\npredicting arbitrary graphs, and apply it to the challenging task of\ntransition-based dependency parsing. After proposing two novel Transformer\nmodels of transition-based dependency parsing as strong baselines, we show that\nadding the proposed mechanisms for conditioning on and predicting graphs of\nGraph2Graph Transformer results in significant improvements, both with and\nwithout BERT pre-training. The novel baselines and their integration with\nGraph2Graph Transformer significantly outperform the state-of-the-art in\ntraditional transition-based dependency parsing on both English Penn Treebank,\nand 13 languages of Universal Dependencies Treebanks. Graph2Graph Transformer\ncan be integrated with many previous structured prediction methods, making it\neasy to apply to a wide range of NLP tasks.\n", "versions": [{"version": "v1", "created": "Fri, 8 Nov 2019 22:14:35 GMT"}, {"version": "v2", "created": "Thu, 30 Apr 2020 09:11:16 GMT"}, {"version": "v3", "created": "Wed, 7 Oct 2020 10:22:09 GMT"}, {"version": "v4", "created": "Fri, 30 Oct 2020 09:37:18 GMT"}], "update_date": "2021-03-22", "authors_parsed": [["Mohammadshahi", "Alireza", ""], ["Henderson", "James", ""]]}, {"id": "1911.03572", "submitter": "Mohit Goyal", "authors": "Mohit Goyal, Kedar Tatwawadi, Shubham Chandak, Idoia Ochoa", "title": "DZip: improved general-purpose lossless compression based on novel\n  neural network modeling", "comments": "Updated manuscript and an efficient implementation added", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.IT math.IT stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider lossless compression based on statistical data modeling followed\nby prediction-based encoding, where an accurate statistical model for the input\ndata leads to substantial improvements in compression. We propose DZip, a\ngeneral-purpose compressor for sequential data that exploits the well-known\nmodeling capabilities of neural networks (NNs) for prediction, followed by\narithmetic coding. Dzip uses a novel hybrid architecture based on adaptive and\nsemi-adaptive training. Unlike most NN based compressors, DZip does not require\nadditional training data and is not restricted to specific data types, only\nneeding the alphabet size of the input data. The proposed compressor\noutperforms general-purpose compressors such as Gzip (on average 26% reduction)\non a variety of real datasets, achieves near-optimal compression on synthetic\ndatasets, and performs close to specialized compressors for large sequence\nlengths, without any human input. The main limitation of DZip in its current\nimplementation is the encoding/decoding time, which limits its practicality.\nNevertheless, the results showcase the potential of developing improved\ngeneral-purpose compressors based on neural networks and hybrid modeling.\n", "versions": [{"version": "v1", "created": "Fri, 8 Nov 2019 22:50:02 GMT"}, {"version": "v2", "created": "Fri, 18 Sep 2020 17:58:10 GMT"}], "update_date": "2020-09-21", "authors_parsed": [["Goyal", "Mohit", ""], ["Tatwawadi", "Kedar", ""], ["Chandak", "Shubham", ""], ["Ochoa", "Idoia", ""]]}, {"id": "1911.03577", "submitter": "Gabriel Peyr\\'e", "authors": "Clarice Poon and Gabriel Peyr\\'e", "title": "Degrees of freedom for off-the-grid sparse estimation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A central question in modern machine learning and imaging sciences is to\nquantify the number of effective parameters of vastly over-parameterized\nmodels. The degrees of freedom is a mathematically convenient way to define\nthis number of parameters. Its computation and properties are well understood\nwhen dealing with discretized linear models, possibly regularized using\nsparsity. In this paper, we argue that this way of thinking is plagued when\ndealing with models having very large parameter spaces. In this case it makes\nmore sense to consider \"off-the-grid\" approaches, using a continuous parameter\nspace. This type of approach is the one favoured when training multi-layer\nperceptrons, and is also becoming popular to solve super-resolution problems in\nimaging. Training these off-the-grid models with a sparsity inducing prior can\nbe achieved by solving a convex optimization problem over the space of\nmeasures, which is often called the Beurling Lasso (Blasso), and is the\ncontinuous counterpart of the celebrated Lasso parameter selection method. In\nprevious works, the degrees of freedom for the Lasso was shown to coincide with\nthe size of the smallest solution support. Our main contribution is a proof of\na continuous counterpart to this result for the Blasso. Our findings suggest\nthat discretized methods actually vastly over-estimate the number of intrinsic\ncontinuous degrees of freedom. Our second contribution is a detailed study of\nthe case of sampling Fourier coefficients in 1D, which corresponds to a\nsuper-resolution problem. We show that our formula for the degrees of freedom\nis valid outside of a set of measure zero of observations, which in turn\njustifies its use to compute an unbiased estimator of the prediction risk using\nthe Stein Unbiased Risk Estimator (SURE).\n", "versions": [{"version": "v1", "created": "Fri, 8 Nov 2019 23:29:52 GMT"}], "update_date": "2019-11-12", "authors_parsed": [["Poon", "Clarice", ""], ["Peyr\u00e9", "Gabriel", ""]]}, {"id": "1911.03583", "submitter": "Guixiang Ma", "authors": "Jiahao Liu, Guixiang Ma, Fei Jiang, Chun-Ta Lu, Philip S. Yu, Ann B.\n  Ragin", "title": "Community-preserving Graph Convolutions for Structural and Functional\n  Joint Embedding of Brain Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG eess.IV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Brain networks have received considerable attention given the critical\nsignificance for understanding human brain organization, for investigating\nneurological disorders and for clinical diagnostic applications. Structural\nbrain network (e.g. DTI) and functional brain network (e.g. fMRI) are the\nprimary networks of interest. Most existing works in brain network analysis\nfocus on either structural or functional connectivity, which cannot leverage\nthe complementary information from each other. Although multi-view learning\nmethods have been proposed to learn from both networks (or views), these\nmethods aim to reach a consensus among multiple views, and thus distinct\nintrinsic properties of each view may be ignored. How to jointly learn\nrepresentations from structural and functional brain networks while preserving\ntheir inherent properties is a critical problem. In this paper, we propose a\nframework of Siamese community-preserving graph convolutional network (SCP-GCN)\nto learn the structural and functional joint embedding of brain networks.\nSpecifically, we use graph convolutions to learn the structural and functional\njoint embedding, where the graph structure is defined with structural\nconnectivity and node features are from the functional connectivity. Moreover,\nwe propose to preserve the community structure of brain networks in the graph\nconvolutions by considering the intra-community and inter-community properties\nin the learning process. Furthermore, we use Siamese architecture which models\nthe pair-wise similarity learning to guide the learning process. To evaluate\nthe proposed approach, we conduct extensive experiments on two real brain\nnetwork datasets. The experimental results demonstrate the superior performance\nof the proposed approach in structural and functional joint embedding for\nneurological disorder analysis, indicating its promising value for clinical\napplications.\n", "versions": [{"version": "v1", "created": "Fri, 8 Nov 2019 23:47:34 GMT"}], "update_date": "2019-11-12", "authors_parsed": [["Liu", "Jiahao", ""], ["Ma", "Guixiang", ""], ["Jiang", "Fei", ""], ["Lu", "Chun-Ta", ""], ["Yu", "Philip S.", ""], ["Ragin", "Ann B.", ""]]}, {"id": "1911.03584", "submitter": "Jean-Baptiste Cordonnier", "authors": "Jean-Baptiste Cordonnier, Andreas Loukas, Martin Jaggi", "title": "On the Relationship between Self-Attention and Convolutional Layers", "comments": "To appear at ICLR 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CL cs.CV stat.ML", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Recent trends of incorporating attention mechanisms in vision have led\nresearchers to reconsider the supremacy of convolutional layers as a primary\nbuilding block. Beyond helping CNNs to handle long-range dependencies,\nRamachandran et al. (2019) showed that attention can completely replace\nconvolution and achieve state-of-the-art performance on vision tasks. This\nraises the question: do learned attention layers operate similarly to\nconvolutional layers? This work provides evidence that attention layers can\nperform convolution and, indeed, they often learn to do so in practice.\nSpecifically, we prove that a multi-head self-attention layer with sufficient\nnumber of heads is at least as expressive as any convolutional layer. Our\nnumerical experiments then show that self-attention layers attend to pixel-grid\npatterns similarly to CNN layers, corroborating our analysis. Our code is\npublicly available.\n", "versions": [{"version": "v1", "created": "Fri, 8 Nov 2019 23:48:38 GMT"}, {"version": "v2", "created": "Fri, 10 Jan 2020 09:06:09 GMT"}], "update_date": "2020-01-13", "authors_parsed": [["Cordonnier", "Jean-Baptiste", ""], ["Loukas", "Andreas", ""], ["Jaggi", "Martin", ""]]}, {"id": "1911.03585", "submitter": "Ursula Challita", "authors": "Ursula Challita, Henrik A. Ryden, and Hugo Tullberg", "title": "When Machine Learning Meets Wireless Cellular Networks: Deployment,\n  Challenges, and Applications", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IT cs.LG math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Artificial intelligence (AI) powered wireless networks promise to\nrevolutionize the conventional operation and structure of current networks from\nnetwork design to infrastructure management, cost reduction, and user\nperformance improvement. Empowering future networks with AI functionalities\nwill enable a shift from reactive/incident driven operations to\nproactive/data-driven operations. This paper provides an overview on the\nintegration of AI functionalities in 5G and beyond networks. Key factors for\nsuccessful AI integration such as data, security, and explainable AI are\nhighlighted. We also summarize the various types of network intelligence as\nwell as machine learning based air interface in future networks. Use case\nexamples for the application of AI to the wireless domain are then summarized.\nWe highlight on applications to the physical layer, mobility management,\nwireless security, and localization.\n", "versions": [{"version": "v1", "created": "Fri, 8 Nov 2019 23:54:18 GMT"}, {"version": "v2", "created": "Fri, 1 May 2020 20:50:59 GMT"}], "update_date": "2020-05-05", "authors_parsed": [["Challita", "Ursula", ""], ["Ryden", "Henrik A.", ""], ["Tullberg", "Hugo", ""]]}, {"id": "1911.03588", "submitter": "Linqing Liu", "authors": "Linqing Liu, Huan Wang, Jimmy Lin, Richard Socher, Caiming Xiong", "title": "MKD: a Multi-Task Knowledge Distillation Approach for Pretrained\n  Language Models", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Pretrained language models have led to significant performance gains in many\nNLP tasks. However, the intensive computing resources to train such models\nremain an issue. Knowledge distillation alleviates this problem by learning a\nlight-weight student model. So far the distillation approaches are all\ntask-specific. In this paper, we explore knowledge distillation under the\nmulti-task learning setting. The student is jointly distilled across different\ntasks. It acquires more general representation capacity through multi-tasking\ndistillation and can be further fine-tuned to improve the model in the target\ndomain. Unlike other BERT distillation methods which specifically designed for\nTransformer-based architectures, we provide a general learning framework. Our\napproach is model agnostic and can be easily applied on different future\nteacher model architectures. We evaluate our approach on a Transformer-based\nand LSTM based student model. Compared to a strong, similarly LSTM-based\napproach, we achieve better quality under the same computational constraints.\nCompared to the present state of the art, we reach comparable results with much\nfaster inference speed.\n", "versions": [{"version": "v1", "created": "Sat, 9 Nov 2019 00:22:05 GMT"}, {"version": "v2", "created": "Thu, 30 Apr 2020 23:19:01 GMT"}], "update_date": "2020-05-04", "authors_parsed": [["Liu", "Linqing", ""], ["Wang", "Huan", ""], ["Lin", "Jimmy", ""], ["Socher", "Richard", ""], ["Xiong", "Caiming", ""]]}, {"id": "1911.03594", "submitter": "Florian Golemo", "authors": "Maxime Chevalier-Boisvert, Guillaume Alain, Florian Golemo, Derek\n  Nowrouzezahrai", "title": "Robo-PlaNet: Learning to Poke in a Day", "comments": "4 pages, 3 figures. Version 2: added reference and acknowledgement", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.RO stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recently, the Deep Planning Network (PlaNet) approach was introduced as a\nmodel-based reinforcement learning method that learns environment dynamics\ndirectly from pixel observations. This architecture is useful for learning\ntasks in which either the agent does not have access to meaningful states (like\nposition/velocity of robotic joints) or where the observed states significantly\ndeviate from the physical state of the agent (which is commonly the case in\nlow-cost robots in the form of backlash or noisy joint readings). PlaNet, by\ndesign, interleaves phases of training the dynamics model with phases of\ncollecting more data on the target environment, leading to long training times.\nIn this work, we introduce Robo-PlaNet, an asynchronous version of PlaNet. This\nalgorithm consistently reaches higher performance in the same amount of time,\nwhich we demonstrate in both a simulated and a real robotic experiment.\n", "versions": [{"version": "v1", "created": "Sat, 9 Nov 2019 02:05:18 GMT"}, {"version": "v2", "created": "Tue, 19 Nov 2019 23:12:39 GMT"}], "update_date": "2019-11-21", "authors_parsed": [["Chevalier-Boisvert", "Maxime", ""], ["Alain", "Guillaume", ""], ["Golemo", "Florian", ""], ["Nowrouzezahrai", "Derek", ""]]}, {"id": "1911.03598", "submitter": "Lili Yu", "authors": "Lili Yu, Howard Chen, Sida Wang, Tao Lei, Yoav Artzi", "title": "Interactive Classification by Asking Informative Questions", "comments": "Accepted at ACL 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.HC cs.IR cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We study the potential for interaction in natural language classification. We\nadd a limited form of interaction for intent classification, where users\nprovide an initial query using natural language, and the system asks for\nadditional information using binary or multi-choice questions. At each turn,\nour system decides between asking the most informative question or making the\nfinal classification prediction.The simplicity of the model allows for\nbootstrapping of the system without interaction data, instead relying on simple\ncrowdsourcing tasks. We evaluate our approach on two domains, showing the\nbenefit of interaction and the advantage of learning to balance between asking\nadditional questions and making the final prediction.\n", "versions": [{"version": "v1", "created": "Sat, 9 Nov 2019 03:05:50 GMT"}, {"version": "v2", "created": "Sun, 3 May 2020 19:47:51 GMT"}], "update_date": "2020-05-05", "authors_parsed": [["Yu", "Lili", ""], ["Chen", "Howard", ""], ["Wang", "Sida", ""], ["Lei", "Tao", ""], ["Artzi", "Yoav", ""]]}, {"id": "1911.03605", "submitter": "Justin Chen", "authors": "Justin Y. Chen, Gregory Valiant, Paul Valiant", "title": "Worst-Case Analysis for Randomly Collected Data", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce a framework for statistical estimation that leverages knowledge\nof how samples are collected but makes no distributional assumptions on the\ndata values. Specifically, we consider a population of elements\n$[n]={1,\\ldots,n}$ with corresponding data values $x_1,\\ldots,x_n$. We observe\nthe values for a \"sample\" set $A \\subset [n]$ and wish to estimate some\nstatistic of the values for a \"target\" set $B \\subset [n]$ where $B$ could be\nthe entire set. Crucially, we assume that the sets $A$ and $B$ are drawn\naccording to some known distribution $P$ over pairs of subsets of $[n]$. A\ngiven estimation algorithm is evaluated based on its \"worst-case, expected\nerror\" where the expectation is with respect to the distribution $P$ from which\nthe sample $A$ and target sets $B$ are drawn, and the worst-case is with\nrespect to the data values $x_1,\\ldots,x_n$. Within this framework, we give an\nefficient algorithm for estimating the target mean that returns a weighted\ncombination of the sample values--where the weights are functions of the\ndistribution $P$ and the sample and target sets $A$, $B$--and show that the\nworst-case expected error achieved by this algorithm is at most a\nmultiplicative $\\pi/2$ factor worse than the optimal of such algorithms. The\nalgorithm and proof leverage a surprising connection to the Grothendieck\nproblem. This framework, which makes no distributional assumptions on the data\nvalues but rather relies on knowledge of the data collection process, is a\nsignificant departure from typical estimation and introduces a uniform\nalgorithmic analysis for the many natural settings where membership in a sample\nmay be correlated with data values, such as when sampling probabilities vary as\nin \"importance sampling\", when individuals are recruited into a sample via a\nsocial network as in \"snowball sampling\", or when samples have chronological\nstructure as in \"selective prediction\".\n", "versions": [{"version": "v1", "created": "Sat, 9 Nov 2019 03:35:14 GMT"}, {"version": "v2", "created": "Mon, 26 Oct 2020 16:05:01 GMT"}], "update_date": "2020-10-27", "authors_parsed": [["Chen", "Justin Y.", ""], ["Valiant", "Gregory", ""], ["Valiant", "Paul", ""]]}, {"id": "1911.03614", "submitter": "Yiming Cui", "authors": "Ziqing Yang, Yiming Cui, Wanxiang Che, Ting Liu, Shijin Wang, Guoping\n  Hu", "title": "Improving Machine Reading Comprehension via Adversarial Training", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Adversarial training (AT) as a regularization method has proved its\neffectiveness in various tasks, such as image classification and text\nclassification. Though there are successful applications of AT in many tasks of\nnatural language processing (NLP), the mechanism behind it is still unclear. In\nthis paper, we aim to apply AT on machine reading comprehension (MRC) and study\nits effects from multiple perspectives. We experiment with three different\nkinds of RC tasks: span-based RC, span-based RC with unanswerable questions and\nmulti-choice RC. The experimental results show that the proposed method can\nimprove the performance significantly and universally on SQuAD1.1, SQuAD2.0 and\nRACE. With virtual adversarial training (VAT), we explore the possibility of\nimproving the RC models with semi-supervised learning and prove that examples\nfrom a different task are also beneficial. We also find that AT helps little in\ndefending against artificial adversarial examples, but AT helps the model to\nlearn better on examples that contain more low-frequency words.\n", "versions": [{"version": "v1", "created": "Sat, 9 Nov 2019 05:31:40 GMT"}], "update_date": "2019-11-12", "authors_parsed": [["Yang", "Ziqing", ""], ["Cui", "Yiming", ""], ["Che", "Wanxiang", ""], ["Liu", "Ting", ""], ["Wang", "Shijin", ""], ["Hu", "Guoping", ""]]}, {"id": "1911.03618", "submitter": "Yichuan Charlie Tang", "authors": "Yichuan Charlie Tang, Jian Zhang, Ruslan Salakhutdinov", "title": "Worst Cases Policy Gradients", "comments": "Conference on Robot Learning 2019 (CoRL 2019)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent advances in deep reinforcement learning have demonstrated the\ncapability of learning complex control policies from many types of\nenvironments. When learning policies for safety-critical applications, it is\nessential to be sensitive to risks and avoid catastrophic events. Towards this\ngoal, we propose an actor-critic framework that models the uncertainty of the\nfuture and simultaneously learns a policy based on that uncertainty model.\nSpecifically, given a distribution of the future return for any state and\naction, we optimize policies for varying levels of conditional Value-at-Risk.\nThe learned policy can map the same state to different actions depending on the\npropensity for risk. We demonstrate the effectiveness of our approach in the\ndomain of driving simulations, where we learn maneuvers in two scenarios. Our\nlearned controller can dynamically select actions along a continuous axis,\nwhere safe and conservative behaviors are found at one end while riskier\nbehaviors are found at the other. Finally, when testing with very different\nsimulation parameters, our risk-averse policies generalize significantly better\ncompared to other reinforcement learning approaches.\n", "versions": [{"version": "v1", "created": "Sat, 9 Nov 2019 06:24:43 GMT"}], "update_date": "2019-11-12", "authors_parsed": [["Tang", "Yichuan Charlie", ""], ["Zhang", "Jian", ""], ["Salakhutdinov", "Ruslan", ""]]}, {"id": "1911.03620", "submitter": "Hossein Esfandiari", "authors": "Hossein Esfandiari, Amin Karbasi, Vahab Mirrokni", "title": "Adaptivity in Adaptive Submodularity", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.DS stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Adaptive sequential decision making is one of the central challenges in\nmachine learning and artificial intelligence. In such problems, the goal is to\ndesign an interactive policy that plans for an action to take, from a finite\nset of $n$ actions, given some partial observations. It has been shown that in\nmany applications such as active learning, robotics, sequential experimental\ndesign, and active detection, the utility function satisfies adaptive\nsubmodularity, a notion that generalizes the notion of diminishing returns to\npolicies. In this paper, we revisit the power of adaptivity in maximizing an\nadaptive monotone submodular function. We propose an efficient semi adaptive\npolicy that with $O(\\log n \\times\\log k)$ adaptive rounds of observations can\nachieve an almost tight $1-1/e-\\epsilon$ approximation guarantee with respect\nto an optimal policy that carries out $k$ actions in a fully sequential manner.\nTo complement our results, we also show that it is impossible to achieve a\nconstant factor approximation with $o(\\log n)$ adaptive rounds. We also extend\nour result to the case of adaptive stochastic minimum cost coverage where the\ngoal is to reach a desired utility $Q$ with the cheapest policy. We first prove\nthe conjecture of the celebrated work of Golovin and Krause by showing that the\ngreedy policy achieves the asymptotically tight logarithmic approximation\nguarantee without resorting to stronger notions of adaptivity. We then propose\na semi adaptive policy that provides the same guarantee in polylogarithmic\nadaptive rounds through a similar information-parallelism scheme. Our results\nshrink the adaptivity gap in adaptive submodular maximization by an exponential\nfactor.\n", "versions": [{"version": "v1", "created": "Sat, 9 Nov 2019 06:31:14 GMT"}, {"version": "v2", "created": "Mon, 27 Jul 2020 06:32:51 GMT"}], "update_date": "2020-07-28", "authors_parsed": [["Esfandiari", "Hossein", ""], ["Karbasi", "Amin", ""], ["Mirrokni", "Vahab", ""]]}, {"id": "1911.03623", "submitter": "Kommy Weldemariam Dr", "authors": "Reginald Bryant, Celia Cintas, Isaac Wambugu, Andrew Kinai, Komminist\n  Weldemariam", "title": "Analyzing Bias in Sensitive Personal Information Used to Train Financial\n  Models", "comments": "5 pages, 4 figures, IEEE Global Conference on Signal and Information\n  Processing (GlobalSIP 2019)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.DB cs.LG", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Bias in data can have unintended consequences that propagate to the design,\ndevelopment, and deployment of machine learning models. In the financial\nservices sector, this can result in discrimination from certain financial\ninstruments and services. At the same time, data privacy is of paramount\nimportance, and recent data breaches have seen reputational damage for large\ninstitutions. Presented in this paper is a trusted model-lifecycle management\nplatform that attempts to ensure consumer data protection, anonymization, and\nfairness. Specifically, we examine how datasets can be reproduced using deep\nlearning techniques to effectively retain important statistical features in\ndatasets whilst simultaneously protecting data privacy and enabling safe and\nsecure sharing of sensitive personal information beyond the current\nstate-of-practice.\n", "versions": [{"version": "v1", "created": "Sat, 9 Nov 2019 06:43:21 GMT"}], "update_date": "2019-11-12", "authors_parsed": [["Bryant", "Reginald", ""], ["Cintas", "Celia", ""], ["Wambugu", "Isaac", ""], ["Kinai", "Andrew", ""], ["Weldemariam", "Komminist", ""]]}, {"id": "1911.03626", "submitter": "Chun Yuan Yuan", "authors": "Qianwen Ma, Chunyuan Yuan, Wei Zhou, Jizhong Han, Songlin Hu", "title": "Beyond Statistical Relations: Integrating Knowledge Relations into Style\n  Correlations for Multi-Label Music Style Classification", "comments": "Accepted as WSDM 2020 Regular Paper", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.IR cs.LG", "license": "http://creativecommons.org/publicdomain/zero/1.0/", "abstract": "  Automatically labeling multiple styles for every song is a comprehensive\napplication in all kinds of music websites. Recently, some researches explore\nreview-driven multi-label music style classification and exploit style\ncorrelations for this task. However, their methods focus on mining the\nstatistical relations between different music styles and only consider shallow\nstyle relations. Moreover, these statistical relations suffer from the\nunderfitting problem because some music styles have little training data.\n  To tackle these problems, we propose a novel knowledge relations integrated\nframework (KRF) to capture the complete style correlations, which jointly\nexploits the inherent relations between music styles according to external\nknowledge and their statistical relations. Based on the two types of relations,\nwe use a graph convolutional network to learn the deep correlations between\nstyles automatically. Experimental results show that our framework\nsignificantly outperforms state-of-the-art methods. Further studies demonstrate\nthat our framework can effectively alleviate the underfitting problem and learn\nmeaningful style correlations. The source code can be available at\nhttps://github.com/Makwen1995/MusicGenre.\n", "versions": [{"version": "v1", "created": "Sat, 9 Nov 2019 06:55:39 GMT"}, {"version": "v2", "created": "Mon, 11 Jan 2021 08:30:13 GMT"}], "update_date": "2021-01-12", "authors_parsed": [["Ma", "Qianwen", ""], ["Yuan", "Chunyuan", ""], ["Zhou", "Wei", ""], ["Han", "Jizhong", ""], ["Hu", "Songlin", ""]]}, {"id": "1911.03642", "submitter": "Andrew Gaut", "authors": "Andrew Gaut, Tony Sun, Shirlyn Tang, Yuxin Huang, Jing Qian, Mai\n  ElSherief, Jieyu Zhao, Diba Mirza, Elizabeth Belding, Kai-Wei Chang, William\n  Yang Wang", "title": "Towards Understanding Gender Bias in Relation Extraction", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CL stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent developments in Neural Relation Extraction (NRE) have made significant\nstrides towards Automated Knowledge Base Construction (AKBC). While much\nattention has been dedicated towards improvements in accuracy, there have been\nno attempts in the literature to our knowledge to evaluate social biases in NRE\nsystems. We create WikiGenderBias, a distantly supervised dataset with a human\nannotated test set. WikiGenderBias has sentences specifically curated to\nanalyze gender bias in relation extraction systems. We use WikiGenderBias to\nevaluate systems for bias and find that NRE systems exhibit gender biased\npredictions and lay groundwork for future evaluation of bias in NRE. We also\nanalyze how name anonymization, hard debiasing for word embeddings, and\ncounterfactual data augmentation affect gender bias in predictions and\nperformance.\n", "versions": [{"version": "v1", "created": "Sat, 9 Nov 2019 08:43:02 GMT"}, {"version": "v2", "created": "Tue, 26 May 2020 22:38:12 GMT"}, {"version": "v3", "created": "Sat, 8 Aug 2020 23:59:54 GMT"}], "update_date": "2020-08-11", "authors_parsed": [["Gaut", "Andrew", ""], ["Sun", "Tony", ""], ["Tang", "Shirlyn", ""], ["Huang", "Yuxin", ""], ["Qian", "Jing", ""], ["ElSherief", "Mai", ""], ["Zhao", "Jieyu", ""], ["Mirza", "Diba", ""], ["Belding", "Elizabeth", ""], ["Chang", "Kai-Wei", ""], ["Wang", "William Yang", ""]]}, {"id": "1911.03645", "submitter": "Ondrej \\v{S}uch", "authors": "Ondrej \\v{S}uch, Peter Tar\\'abek, Katar\\'ina Bachrat\\'a, Andrea\n  Tinajov\\'a", "title": "Pairwise coupling of convolutional neural networks for better\n  explicability of classification systems", "comments": "25 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We examine several aspects of explicability of a classification system built\nfrom neural networks. The first aspect is the pairwise explicability, which is\nthe ability to provide the most accurate prediction when the range of\npossibilities is narrowed to just two. Next we consider explicability in\ndevelopment, which means ability to make incremental improvement in prediction\naccuracy based on observed deficiency of the system. Inherent stochasticity of\nneural network based classifiers can be interpreted using likelihood randomness\nexplicability. Finally, sureness explicability indicates confidence of the\nclassifying system to make any prediction at all.\n  These concepts are examined in the framework of pairwise coupling, which is a\nnon-trainable metamodel that originated during development of support vector\nmachines. Several methodologies are evaluated, of which the key one is shown to\nbe the choice of the pairwise coupling method. We compare two methods: the\nestablished Wu-Lin-Weng method with the recently proposed Bayes covariant\nmethod. Our experiments indicate that the Wu-Lin-Weng method gives more weight\nto a single pairwise classifier, whereas the latter tries to balance\ninformation from the whole matrix of pairwise likelihoods. This translates into\nhigher accuracy, and better sureness predictions for the Bayes covariant\nmethod.\n  Pairwise coupling methodology has its costs, especially in terms of the\nnumber of parameters (but not necessarily in terms of training costs). However,\nwhen additional explicability aspects beyond accuracy are desired in an\napplication, the pairwise coupling models are a promising alternative to the\nestablished methodology.\n", "versions": [{"version": "v1", "created": "Sat, 9 Nov 2019 09:28:10 GMT"}], "update_date": "2019-11-12", "authors_parsed": [["\u0160uch", "Ondrej", ""], ["Tar\u00e1bek", "Peter", ""], ["Bachrat\u00e1", "Katar\u00edna", ""], ["Tinajov\u00e1", "Andrea", ""]]}, {"id": "1911.03648", "submitter": "Kiet Nguyen Van", "authors": "Hang Thi-Thuy Do, Huy Duc Huynh, Kiet Van Nguyen, Ngan Luu-Thuy\n  Nguyen, Anh Gia-Tuan Nguyen", "title": "Hate Speech Detection on Vietnamese Social Media Text using the\n  Bidirectional-LSTM Model", "comments": null, "journal-ref": "VLSP Workshop 2019", "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://creativecommons.org/publicdomain/zero/1.0/", "abstract": "  In this paper, we describe our system which participates in the shared task\nof Hate Speech Detection on Social Networks of VLSP 2019 evaluation campaign.\nWe are provided with the pre-labeled dataset and an unlabeled dataset for\nsocial media comments or posts. Our mission is to pre-process and build machine\nlearning models to classify comments/posts. In this report, we use\nBidirectional Long Short-Term Memory to build the model that can predict labels\nfor social media text according to Clean, Offensive, Hate. With this system, we\nachieve comparative results with 71.43% on the public standard test set of VLSP\n2019.\n", "versions": [{"version": "v1", "created": "Sat, 9 Nov 2019 09:33:42 GMT"}], "update_date": "2019-11-12", "authors_parsed": [["Do", "Hang Thi-Thuy", ""], ["Huynh", "Huy Duc", ""], ["Van Nguyen", "Kiet", ""], ["Nguyen", "Ngan Luu-Thuy", ""], ["Nguyen", "Anh Gia-Tuan", ""]]}, {"id": "1911.03653", "submitter": "Alberto Redondo", "authors": "Alberto Redondo and David Rios Insua", "title": "Protecting from Malware Obfuscation Attacks through Adversarial Risk\n  Analysis", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Malware constitutes a major global risk affecting millions of users each\nyear. Standard algorithms in detection systems perform insufficiently when\ndealing with malware passed through obfuscation tools. We illustrate this\nstudying in detail an open source metamorphic software, making use of a hybrid\nframework to obtain the relevant features from binaries. We then provide an\nimproved alternative solution based on adversarial risk analysis which we\nillustrate describe with an example.\n", "versions": [{"version": "v1", "created": "Sat, 9 Nov 2019 10:02:41 GMT"}], "update_date": "2019-11-12", "authors_parsed": [["Redondo", "Alberto", ""], ["Insua", "David Rios", ""]]}, {"id": "1911.03654", "submitter": "Anis Elgabli", "authors": "Anis Elgabli, Jihong Park, Sabbir Ahmed, and Mehdi Bennis", "title": "L-FGADMM: Layer-Wise Federated Group ADMM for Communication Efficient\n  Decentralized Deep Learning", "comments": "6 pages; 4 figures; presented at IEEE WCNC'2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.DC cs.NI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This article proposes a communication-efficient decentralized deep learning\nalgorithm, coined layer-wise federated group ADMM (L-FGADMM). To minimize an\nempirical risk, every worker in L-FGADMM periodically communicates with two\nneighbors, in which the periods are separately adjusted for different layers of\nits deep neural network. A constrained optimization problem for this setting is\nformulated and solved using the stochastic version of GADMM proposed in our\nprior work. Numerical evaluations show that by less frequently exchanging the\nlargest layer, L-FGADMM can significantly reduce the communication cost,\nwithout compromising the convergence speed. Surprisingly, despite less\nexchanged information and decentralized operations, intermittently skipping the\nlargest layer consensus in L-FGADMM creates a regularizing effect, thereby\nachieving the test accuracy as high as federated learning (FL), a baseline\nmethod with the entire layer consensus by the aid of a central entity.\n", "versions": [{"version": "v1", "created": "Sat, 9 Nov 2019 10:03:21 GMT"}, {"version": "v2", "created": "Sun, 5 Jul 2020 09:33:25 GMT"}], "update_date": "2020-07-07", "authors_parsed": [["Elgabli", "Anis", ""], ["Park", "Jihong", ""], ["Ahmed", "Sabbir", ""], ["Bennis", "Mehdi", ""]]}, {"id": "1911.03655", "submitter": "Rising Odegua", "authors": "Rising Odegua and Festus Ikpotokin", "title": "DataSist: A Python-based library for easy data analysis, visualization\n  and modeling", "comments": "16 pages, 16 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://creativecommons.org/publicdomain/zero/1.0/", "abstract": "  A large amount of data is produced every second from modern information\nsystems such as mobile devices, the world wide web, Internet of Things, social\nmedia, etc. Analysis and mining of this massive data requires a lot of advanced\ntools and techniques. Therefore, big data analytics and mining is currently an\nactive and trending area of research because of the enormous benefits\nbusinesses and organizations derive from it. Numerous tools like Pandas, Numpy,\nSTATA, SPSS, have been created to help analyze and mine these huge outburst of\ndata and some have become so popular and widely used in the field. This paper\npresents a new python-based library, DataSist, which offers high level,\nintuitive and easy to use functions, and methods that helps data\nscientists/analyst to quickly analyze, mine and visualize big data sets. The\nobjectives of this project were to (i) design a python library to aid data\nanalysis process by abstracting low level syntax, (ii) increase productivity of\ndata scientist by making them focus on what to do rather than how to do it.\nThis project shows that data analysis can be automated and much faster when we\nabstract certain functions, and will serve as an important tool in the workflow\nof data scientists.\n", "versions": [{"version": "v1", "created": "Sat, 9 Nov 2019 10:05:38 GMT"}, {"version": "v2", "created": "Fri, 10 Jan 2020 17:34:19 GMT"}], "update_date": "2020-01-13", "authors_parsed": [["Odegua", "Rising", ""], ["Ikpotokin", "Festus", ""]]}, {"id": "1911.03658", "submitter": "Magda Friedjungov\\'a", "authors": "Magda Friedjungov\\'a, Daniel Va\\v{s}ata, Marcel Ji\\v{r}ina", "title": "Missing Features Reconstruction and Its Impact on Classification\n  Accuracy", "comments": "Preprint of the conference paper (ICCS 2019), part of the Lecture\n  Notes in Computer Science", "journal-ref": "Computational Science - ICCS 2019. ICCS 2019. Lecture Notes in\n  Computer Science 11538 (2019) 207-220", "doi": "10.1007/978-3-030-22744-9_16", "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In real-world applications, we can encounter situations when a well-trained\nmodel has to be used to predict from a damaged dataset. The damage caused by\nmissing or corrupted values can be either on the level of individual instances\nor on the level of entire features. Both situations have a negative impact on\nthe usability of the model on such a dataset. This paper focuses on the\nscenario where entire features are missing which can be understood as a\nspecific case of transfer learning. Our aim is to experimentally research the\ninfluence of various imputation methods on the performance of several\nclassification models. The imputation impact is researched on a combination of\ntraditional methods such as k-NN, linear regression, and MICE compared to\nmodern imputation methods such as multi-layer perceptron (MLP) and gradient\nboosted trees (XGBT). For linear regression, MLP, and XGBT we also propose two\napproaches to using them for multiple features imputation. The experiments were\nperformed on both real world and artificial datasets with continuous features\nwhere different numbers of features, varying from one feature to 50%, were\nmissing. The results show that MICE and linear regression are generally good\nimputers regardless of the conditions. On the other hand, the performance of\nMLP and XGBT is strongly dataset dependent. Their performance is the best in\nsome cases, but more often they perform worse than MICE or linear regression.\n", "versions": [{"version": "v1", "created": "Sat, 9 Nov 2019 10:37:12 GMT"}], "update_date": "2019-11-12", "authors_parsed": [["Friedjungov\u00e1", "Magda", ""], ["Va\u0161ata", "Daniel", ""], ["Ji\u0159ina", "Marcel", ""]]}, {"id": "1911.03663", "submitter": "Dongyeop Kang", "authors": "Dongyeop Kang, Eduard Hovy", "title": "Style is NOT a single variable: Case Studies for Cross-Style Language\n  Understanding", "comments": "Accepted to ACL 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Every natural text is written in some style. Style is formed by a complex\ncombination of different stylistic factors, including formality markers,\nemotions, metaphors, etc. One cannot form a complete understanding of a text\nwithout considering these factors. The factors combine and co-vary in complex\nways to form styles. Studying the nature of the co-varying combinations sheds\nlight on stylistic language in general, sometimes called cross-style language\nunderstanding. This paper provides the benchmark corpus (xSLUE) that combines\nexisting datasets and collects a new one for sentence-level cross-style\nlanguage understanding and evaluation. The benchmark contains text in 15\ndifferent styles under the proposed four theoretical groupings: figurative,\npersonal, affective, and interpersonal groups. For valid evaluation, we collect\nan additional diagnostic set by annotating all 15 styles on the same text.\nUsing xSLUE, we propose three interesting cross-style applications in\nclassification, correlation, and generation. First, our proposed cross-style\nclassifier trained with multiple styles together helps improve overall\nclassification performance against individually-trained style classifiers.\nSecond, our study shows that some styles are highly dependent on each other in\nhuman-written text. Finally, we find that combinations of some contradictive\nstyles likely generate stylistically less appropriate text. We believe our\nbenchmark and case studies help explore interesting future directions for\ncross-style research. The preprocessed datasets and code are publicly\navailable.\n", "versions": [{"version": "v1", "created": "Sat, 9 Nov 2019 10:55:34 GMT"}, {"version": "v2", "created": "Wed, 2 Jun 2021 00:41:40 GMT"}], "update_date": "2021-06-03", "authors_parsed": [["Kang", "Dongyeop", ""], ["Hovy", "Eduard", ""]]}, {"id": "1911.03667", "submitter": "Satyajit Neogi", "authors": "Satyajit Neogi, Justin Dauwels", "title": "Factored Latent-Dynamic Conditional Random Fields for Single and\n  Multi-label Sequence Modeling", "comments": "To be submitted to Journal of Machine Learning Research (JMLR)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG eess.SP stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Conditional Random Fields (CRF) are frequently applied for labeling and\nsegmenting sequence data. Morency et al. (2007) introduced hidden state\nvariables in a labeled CRF structure in order to model the latent dynamics\nwithin class labels, thus improving the labeling performance. Such a model is\nknown as Latent-Dynamic CRF (LDCRF). We present Factored LDCRF (FLDCRF), a\nstructure that allows multiple latent dynamics of the class labels to interact\nwith each other. Including such latent-dynamic interactions leads to improved\nlabeling performance on single-label and multi-label sequence modeling tasks.\nWe apply our FLDCRF models on two single-label (one nested cross-validation)\nand one multi-label sequence tagging (nested cross-validation) experiments\nacross two different datasets - UCI gesture phase data and UCI opportunity\ndata. FLDCRF outperforms all state-of-the-art sequence models, i.e., CRF,\nLDCRF, LSTM, LSTM-CRF, Factorial CRF, Coupled CRF and a multi-label LSTM model\nin all our experiments. In addition, LSTM based models display inconsistent\nperformance across validation and test data, and pose diffculty to select\nmodels on validation data during our experiments. FLDCRF offers easier model\nselection, consistency across validation and test performance and lucid model\nintuition. FLDCRF is also much faster to train compared to LSTM, even without a\nGPU. FLDCRF outshines the best LSTM model by ~4% on a single-label task on UCI\ngesture phase data and outperforms LSTM performance by ~2% on average across\nnested cross-validation test sets on the multi-label sequence tagging\nexperiment on UCI opportunity data. The idea of FLDCRF can be extended to joint\n(multi-agent interactions) and heterogeneous (discrete and continuous) state\nspace models.\n", "versions": [{"version": "v1", "created": "Sat, 9 Nov 2019 11:16:42 GMT"}, {"version": "v2", "created": "Tue, 12 Nov 2019 10:56:29 GMT"}], "update_date": "2019-11-13", "authors_parsed": [["Neogi", "Satyajit", ""], ["Dauwels", "Justin", ""]]}, {"id": "1911.03671", "submitter": "Kota Matsui", "authors": "Kota Matsui, Shunya Kusakawa, Keisuke Ando, Kentaro Kutsukake, Toru\n  Ujihara, Ichiro Takeuchi", "title": "Bayesian Active Learning for Structured Output Design", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we propose an active learning method for an inverse problem\nthat aims to find an input that achieves a desired structured-output. The\nproposed method provides new acquisition functions for minimizing the error\nbetween the desired structured-output and the prediction of a Gaussian process\nmodel, by effectively incorporating the correlation between multiple outputs of\nthe underlying multi-valued black box output functions. The effectiveness of\nthe proposed method is verified by applying it to two synthetic shape search\nproblem and real data. In the real data experiment, we tackle the input\nparameter search which achieves the desired crystal growth rate in silicon\ncarbide (SiC) crystal growth modeling, that is a problem of materials\ninformatics.\n", "versions": [{"version": "v1", "created": "Sat, 9 Nov 2019 11:39:14 GMT"}], "update_date": "2019-11-12", "authors_parsed": [["Matsui", "Kota", ""], ["Kusakawa", "Shunya", ""], ["Ando", "Keisuke", ""], ["Kutsukake", "Kentaro", ""], ["Ujihara", "Toru", ""], ["Takeuchi", "Ichiro", ""]]}, {"id": "1911.03674", "submitter": "Kommy Weldemariam Dr", "authors": "Samuel C. Maina, Reginald E. Bryant, William O. Goal, Robert-Florian\n  Samoilescu, Kush R. Varshney, Komminist Weldemariam", "title": "Preservation of Anomalous Subgroups On Machine Learning Transformed Data", "comments": "5 pages, 3 figures, 2 tables, submitted to icassp 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR stat.ML", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  In this paper, we investigate the effect of machine learning based\nanonymization on anomalous subgroup preservation. In particular, we train a\nbinary classifier to discover the most anomalous subgroup in a dataset by\nmaximizing the bias between the group's predicted odds ratio from the model and\nobserved odds ratio from the data. We then perform anonymization using a\nvariational autoencoder (VAE) to synthesize an entirely new dataset that would\nideally be drawn from the distribution of the original data. We repeat the\nanomalous subgroup discovery task on the new data and compare it to what was\nidentified pre-anonymization. We evaluated our approach using publicly\navailable datasets from the financial industry. Our evaluation confirmed that\nthe approach was able to produce synthetic datasets that preserved a high level\nof subgroup differentiation as identified initially in the original dataset.\nSuch a distinction was maintained while having distinctly different records\nbetween the synthetic and original dataset. Finally, we packed the above end to\nend process into what we call Utility Guaranteed Deep Privacy (UGDP) system.\nUGDP can be easily extended to onboard alternative generative approaches such\nas GANs to synthesize tabular data.\n", "versions": [{"version": "v1", "created": "Sat, 9 Nov 2019 12:09:53 GMT"}], "update_date": "2019-11-12", "authors_parsed": [["Maina", "Samuel C.", ""], ["Bryant", "Reginald E.", ""], ["Goal", "William O.", ""], ["Samoilescu", "Robert-Florian", ""], ["Varshney", "Kush R.", ""], ["Weldemariam", "Komminist", ""]]}, {"id": "1911.03677", "submitter": "Wei Zou", "authors": "Wei Zou, Shujian Huang, Jun Xie, Xinyu Dai, Jiajun Chen", "title": "A Reinforced Generation of Adversarial Examples for Neural Machine\n  Translation", "comments": "12 pages, ACL2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Neural machine translation systems tend to fail on less decent inputs despite\nits significant efficacy, which may significantly harm the credibility of this\nsystems-fathoming how and when neural-based systems fail in such cases is\ncritical for industrial maintenance. Instead of collecting and analyzing bad\ncases using limited handcrafted error features, here we investigate this issue\nby generating adversarial examples via a new paradigm based on reinforcement\nlearning. Our paradigm could expose pitfalls for a given performance metric,\ne.g., BLEU, and could target any given neural machine translation architecture.\nWe conduct experiments of adversarial attacks on two mainstream neural machine\ntranslation architectures, RNN-search, and Transformer. The results show that\nour method efficiently produces stable attacks with meaning-preserving\nadversarial examples. We also present a qualitative and quantitative analysis\nfor the preference pattern of the attack, demonstrating its capability of\npitfall exposure.\n", "versions": [{"version": "v1", "created": "Sat, 9 Nov 2019 12:33:47 GMT"}, {"version": "v2", "created": "Tue, 26 May 2020 14:36:00 GMT"}], "update_date": "2020-05-27", "authors_parsed": [["Zou", "Wei", ""], ["Huang", "Shujian", ""], ["Xie", "Jun", ""], ["Dai", "Xinyu", ""], ["Chen", "Jiajun", ""]]}, {"id": "1911.03698", "submitter": "Alice Coucke", "authors": "St\\'ephane d'Ascoli, Alice Coucke, Francesco Caltagirone, Alexandre\n  Caulier, Marc Lelarge", "title": "Conditioned Query Generation for Task-Oriented Dialogue Systems", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Scarcity of training data for task-oriented dialogue systems is a well known\nproblem that is usually tackled with costly and time-consuming manual data\nannotation. An alternative solution is to rely on automatic text generation\nwhich, although less accurate than human supervision, has the advantage of\nbeing cheap and fast. In this paper we propose a novel controlled data\ngeneration method that could be used as a training augmentation framework for\nclosed-domain dialogue. Our contribution is twofold. First we show how to\noptimally train and control the generation of intent-specific sentences using a\nconditional variational autoencoder. Then we introduce a novel protocol called\nquery transfer that allows to leverage a broad, unlabelled dataset to extract\nrelevant information. Comparison with two different baselines shows that our\nmethod, in the appropriate regime, consistently improves the diversity of the\ngenerated queries without compromising their quality.\n", "versions": [{"version": "v1", "created": "Sat, 9 Nov 2019 14:22:57 GMT"}], "update_date": "2019-11-12", "authors_parsed": [["d'Ascoli", "St\u00e9phane", ""], ["Coucke", "Alice", ""], ["Caltagirone", "Francesco", ""], ["Caulier", "Alexandre", ""], ["Lelarge", "Marc", ""]]}, {"id": "1911.03722", "submitter": "Junjie Li", "authors": "Junjie Li, Ding Liu", "title": "Information Bottleneck Theory on Convolutional Neural Networks", "comments": "7 pages,28 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent years, many researches attempt to open the black box of deep neural\nnetworks and propose a various of theories to understand it. Among them,\nInformation Bottleneck (IB) theory claims that there are two distinct phases\nconsisting of fitting phase and compression phase in the course of training.\nThis statement attracts many attentions since its success in explaining the\ninner behavior of feedforward neural networks. In this paper, we employ IB\ntheory to understand the dynamic behavior of convolutional neural networks\n(CNNs) and investigate how the fundamental features such as convolutional layer\nwidth, kernel size, network depth, pooling layers and multi-fully connected\nlayer have impact on the performance of CNNs. In particular, through a series\nof experimental analysis on benchmark of MNIST and Fashion-MNIST, we\ndemonstrate that the compression phase is not observed in all these cases. This\nshows us the CNNs have a rather complicated behavior than feedforward neural\nnetworks.\n", "versions": [{"version": "v1", "created": "Sat, 9 Nov 2019 15:55:54 GMT"}, {"version": "v2", "created": "Fri, 19 Feb 2021 12:12:10 GMT"}], "update_date": "2021-02-22", "authors_parsed": [["Li", "Junjie", ""], ["Liu", "Ding", ""]]}, {"id": "1911.03723", "submitter": "Chen Chen", "authors": "Chen Chen, Chen Qin, Huaqi Qiu, Giacomo Tarroni, Jinming Duan, Wenjia\n  Bai, and Daniel Rueckert", "title": "Deep learning for cardiac image segmentation: A review", "comments": "Under review", "journal-ref": null, "doi": "10.3389/fcvm.2020.00025", "report-no": null, "categories": "eess.IV cs.CV cs.LG q-bio.QM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep learning has become the most widely used approach for cardiac image\nsegmentation in recent years. In this paper, we provide a review of over 100\ncardiac image segmentation papers using deep learning, which covers common\nimaging modalities including magnetic resonance imaging (MRI), computed\ntomography (CT), and ultrasound (US) and major anatomical structures of\ninterest (ventricles, atria and vessels). In addition, a summary of publicly\navailable cardiac image datasets and code repositories are included to provide\na base for encouraging reproducible research. Finally, we discuss the\nchallenges and limitations with current deep learning-based approaches\n(scarcity of labels, model generalizability across different domains,\ninterpretability) and suggest potential directions for future research.\n", "versions": [{"version": "v1", "created": "Sat, 9 Nov 2019 15:58:48 GMT"}], "update_date": "2020-03-10", "authors_parsed": [["Chen", "Chen", ""], ["Qin", "Chen", ""], ["Qiu", "Huaqi", ""], ["Tarroni", "Giacomo", ""], ["Duan", "Jinming", ""], ["Bai", "Wenjia", ""], ["Rueckert", "Daniel", ""]]}, {"id": "1911.03725", "submitter": "Waheed Bajwa", "authors": "Talal Ahmed, Haroon Raja, and Waheed U. Bajwa", "title": "Tensor Regression Using Low-rank and Sparse Tucker Decompositions", "comments": "28 pages, 5 figures, 2 tables; preprint of a journal paper published\n  in SIAM Journal on Mathematics of Data Science", "journal-ref": "SIAM J. Math. Data Science, vol. 2, no. 4, pp. 944-966, 2020", "doi": "10.1137/19M1299335", "report-no": null, "categories": "cs.LG eess.SP math.ST stat.ML stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper studies a tensor-structured linear regression model with a scalar\nresponse variable and tensor-structured predictors, such that the regression\nparameters form a tensor of order $d$ (i.e., a $d$-fold multiway array) in\n$\\mathbb{R}^{n_1 \\times n_2 \\times \\cdots \\times n_d}$. It focuses on the task\nof estimating the regression tensor from $m$ realizations of the response\nvariable and the predictors where $m\\ll n = \\prod \\nolimits_{i} n_i$. Despite\nthe seeming ill-posedness of this problem, it can still be solved if the\nparameter tensor belongs to the space of sparse, low Tucker-rank tensors.\nAccordingly, the estimation procedure is posed as a non-convex optimization\nprogram over the space of sparse, low Tucker-rank tensors, and a tensor variant\nof projected gradient descent is proposed to solve the resulting non-convex\nproblem. In addition, mathematical guarantees are provided that establish the\nproposed method linearly converges to an appropriate solution under a certain\nset of conditions. Further, an upper bound on sample complexity of tensor\nparameter estimation for the model under consideration is characterized for the\nspecial case when the individual (scalar) predictors independently draw values\nfrom a sub-Gaussian distribution. The sample complexity bound is shown to have\na polylogarithmic dependence on $\\bar{n} = \\max \\big\\{n_i: i\\in \\{1,2,\\ldots,d\n\\} \\big\\}$ and, orderwise, it matches the bound one can obtain from a heuristic\nparameter counting argument. Finally, numerical experiments demonstrate the\nefficacy of the proposed tensor model and estimation method on a synthetic\ndataset and a collection of neuroimaging datasets pertaining to attention\ndeficit hyperactivity disorder. Specifically, the proposed method exhibits\nbetter sample complexities on both synthetic and real datasets, demonstrating\nthe usefulness of the model and the method in settings where $n \\gg m$.\n", "versions": [{"version": "v1", "created": "Sat, 9 Nov 2019 16:00:38 GMT"}, {"version": "v2", "created": "Tue, 21 Jul 2020 03:44:59 GMT"}], "update_date": "2020-11-26", "authors_parsed": [["Ahmed", "Talal", ""], ["Raja", "Haroon", ""], ["Bajwa", "Waheed U.", ""]]}, {"id": "1911.03731", "submitter": "Jonathan Baxter", "authors": "Jonathan Baxter", "title": "Learning Internal Representations (PhD Thesis)", "comments": "Phd Thesis, Jonathan Baxter, 1994", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Most machine learning theory and practice is concerned with learning a single\ntask. In this thesis it is argued that in general there is insufficient\ninformation in a single task for a learner to generalise well and that what is\nrequired for good generalisation is information about many similar learning\ntasks. Similar learning tasks form a body of prior information that can be used\nto constrain the learner and make it generalise better. Examples of learning\nscenarios in which there are many similar tasks are handwritten character\nrecognition and spoken word recognition.\n  The concept of the environment of a learner is introduced as a probability\nmeasure over the set of learning problems the learner might be expected to\nlearn. It is shown how a sample from the environment may be used to learn a\nrepresentation, or recoding of the input space that is appropriate for the\nenvironment. Learning a representation can equivalently be thought of as\nlearning the appropriate features of the environment. Bounds are derived on the\nsample size required to ensure good generalisation from a representation\nlearning process. These bounds show that under certain circumstances learning a\nrepresentation appropriate for $n$ tasks reduces the number of examples\nrequired of each task by a factor of $n$.\n  Once a representation is learnt it can be used to learn novel tasks from the\nsame environment, with the result that far fewer examples are required of the\nnew tasks to ensure good generalisation. Bounds are given on the number of\ntasks and the number of samples from each task required to ensure that a\nrepresentation will be a good one for learning novel tasks.\n  The results on representation learning are generalised to cover any form of\nautomated hypothesis space bias.\n", "versions": [{"version": "v1", "created": "Sat, 9 Nov 2019 16:25:33 GMT"}, {"version": "v2", "created": "Fri, 22 Nov 2019 15:20:46 GMT"}], "update_date": "2019-11-25", "authors_parsed": [["Baxter", "Jonathan", ""]]}, {"id": "1911.03737", "submitter": "Andreas Venzke", "authors": "George S. Misyris, Andreas Venzke and Spyros Chatzivasileiadis", "title": "Physics-Informed Neural Networks for Power Systems", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.SY cs.LG cs.SY eess.SP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper introduces for the first time, to our knowledge, a framework for\nphysics-informed neural networks in power system applications. Exploiting the\nunderlying physical laws governing power systems, and inspired by recent\ndevelopments in the field of machine learning, this paper proposes a neural\nnetwork training procedure that can make use of the wide range of mathematical\nmodels describing power system behavior, both in steady-state and in dynamics.\nPhysics-informed neural networks require substantially less training data and\ncan result in simpler neural network structures, while achieving high accuracy.\nThis work unlocks a range of opportunities in power systems, being able to\ndetermine dynamic states, such as rotor angles and frequency, and uncertain\nparameters such as inertia and damping at a fraction of the computational time\nrequired by conventional methods. This paper focuses on introducing the\nframework and showcases its potential using a single-machine infinite bus\nsystem as a guiding example. Physics-informed neural networks are shown to\naccurately determine rotor angle and frequency up to 87 times faster than\nconventional methods.\n", "versions": [{"version": "v1", "created": "Sat, 9 Nov 2019 17:03:08 GMT"}, {"version": "v2", "created": "Sun, 22 Dec 2019 20:14:06 GMT"}, {"version": "v3", "created": "Wed, 29 Jan 2020 16:32:14 GMT"}], "update_date": "2020-01-30", "authors_parsed": [["Misyris", "George S.", ""], ["Venzke", "Andreas", ""], ["Chatzivasileiadis", "Spyros", ""]]}, {"id": "1911.03740", "submitter": "Sheng Liu", "authors": "Sheng Liu, Chhavi Yadav, Carlos Fernandez-Granda, Narges Razavian", "title": "On the design of convolutional neural networks for automatic detection\n  of Alzheimer's disease", "comments": "Machine Learning for Health Workshop, NeurIPS2019. Authors\n  Fernandez-Granda and Razavian are joint last authors", "journal-ref": "Proceedings of Machine Learning Research, 2019", "doi": null, "report-no": null, "categories": "eess.IV cs.CV cs.LG eess.SP stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Early detection is a crucial goal in the study of Alzheimer's Disease (AD).\nIn this work, we describe several techniques to boost the performance of 3D\ndeep convolutional neural networks (CNNs) trained to detect AD using structural\nbrain MRI scans. Specifically, we provide evidence that (1) instance\nnormalization outperforms batch normalization, (2) early spatial downsampling\nnegatively affects performance, (3) widening the model brings consistent gains\nwhile increasing the depth does not, and (4) incorporating age information\nyields moderate improvement. Together, these insights yield an increment of\napproximately 14% in test accuracy over existing models when distinguishing\nbetween patients with AD, mild cognitive impairment, and controls in the ADNI\ndataset. Similar performance is achieved on an independent dataset.\n", "versions": [{"version": "v1", "created": "Sat, 9 Nov 2019 17:08:34 GMT"}, {"version": "v2", "created": "Tue, 12 Nov 2019 18:18:06 GMT"}, {"version": "v3", "created": "Sun, 5 Apr 2020 01:47:59 GMT"}], "update_date": "2020-04-07", "authors_parsed": [["Liu", "Sheng", ""], ["Yadav", "Chhavi", ""], ["Fernandez-Granda", "Carlos", ""], ["Razavian", "Narges", ""]]}, {"id": "1911.03743", "submitter": "Homagni Saha", "authors": "Homagni Saha, Vijay Venkataraman, Alberto Speranzon, Soumik Sarkar", "title": "A perspective on multi-agent communication for information fusion", "comments": "NeuRIPS 2019, Workshop on Visually Grounded Interaction and Language,\n  Vancouver, CA", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.MA cs.AI cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Collaborative decision making in multi-agent systems typically requires a\npredefined communication protocol among agents. Usually, agent-level\nobservations are locally processed and information is exchanged using the\npredefined protocol, enabling the team to perform more efficiently than each\nagent operating in isolation. In this work, we consider the situation where\nagents, with complementary sensing modalities must co-operate to achieve a\ncommon goal/task by learning an efficient communication protocol. We frame the\nproblem within an actor-critic scheme, where the agents learn optimal policies\nin a centralized fashion, while taking action in a distributed manner. We\nprovide an interpretation of the emergent communication between the agents. We\nobserve that the information exchanged is not just an encoding of the raw\nsensor data but is, rather, a specific set of directive actions that depend on\nthe overall task. Simulation results demonstrate the interpretability of the\nlearnt communication in a variety of tasks.\n", "versions": [{"version": "v1", "created": "Sat, 9 Nov 2019 17:56:47 GMT"}], "update_date": "2019-11-12", "authors_parsed": [["Saha", "Homagni", ""], ["Venkataraman", "Vijay", ""], ["Speranzon", "Alberto", ""], ["Sarkar", "Soumik", ""]]}, {"id": "1911.03759", "submitter": "Shuchismita Biswas", "authors": "Shuchismita Biswas, Rounak Meyur, Virgilio Centeno", "title": "DeVLearn: A Deep Visual Learning Framework for Localizing Temporary\n  Faults in Power Systems", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.SY cs.LG cs.SY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Frequently recurring transient faults in a transmission network may be\nindicative of impending permanent failures. Hence, determining their location\nis a critical task. This paper proposes a novel image embedding aided deep\nlearning framework called DeVLearn for faulted line location using PMU\nmeasurements at generator buses. Inspired by breakthroughs in computer vision,\nDeVLearn represents measurements (one-dimensional time series data) as\ntwo-dimensional unthresholded Recurrent Plot (RP) images. These RP images\npreserve the temporal relationships present in the original time series and are\nused to train a deep Variational Auto-Encoder (VAE). The VAE learns the\ndistribution of latent features in the images. Our results show that for faults\non two different lines in the IEEE 68-bus network, DeVLearn is able to project\nPMU measurements into a two-dimensional space such that data for faults at\ndifferent locations separate into well-defined clusters. This compressed\nrepresentation may then be used with off-the-shelf classifiers for determining\nfault location. The efficacy of the proposed framework is demonstrated using\nlocal voltage magnitude measurements at two generator buses.\n", "versions": [{"version": "v1", "created": "Sat, 9 Nov 2019 19:18:19 GMT"}], "update_date": "2019-11-12", "authors_parsed": [["Biswas", "Shuchismita", ""], ["Meyur", "Rounak", ""], ["Centeno", "Virgilio", ""]]}, {"id": "1911.03762", "submitter": "Zhong Meng", "authors": "Zhong Meng, Yashesh Gaur, Jinyu Li, Yifan Gong", "title": "Speaker Adaptation for Attention-Based End-to-End Speech Recognition", "comments": "5 pages, 3 figures, Interspeech 2019", "journal-ref": "Interspeech 2019, Graz, Austria", "doi": "10.21437/Interspeech.2019-3135", "report-no": null, "categories": "cs.CL cs.LG cs.SD eess.AS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose three regularization-based speaker adaptation approaches to adapt\nthe attention-based encoder-decoder (AED) model with very limited adaptation\ndata from target speakers for end-to-end automatic speech recognition. The\nfirst method is Kullback-Leibler divergence (KLD) regularization, in which the\noutput distribution of a speaker-dependent (SD) AED is forced to be close to\nthat of the speaker-independent (SI) model by adding a KLD regularization to\nthe adaptation criterion. To compensate for the asymmetric deficiency in KLD\nregularization, an adversarial speaker adaptation (ASA) method is proposed to\nregularize the deep-feature distribution of the SD AED through the adversarial\nlearning of an auxiliary discriminator and the SD AED. The third approach is\nthe multi-task learning, in which an SD AED is trained to jointly perform the\nprimary task of predicting a large number of output units and an auxiliary task\nof predicting a small number of output units to alleviate the target sparsity\nissue. Evaluated on a Microsoft short message dictation task, all three methods\nare highly effective in adapting the AED model, achieving up to 12.2% and 3.0%\nword error rate improvement over an SI AED trained from 3400 hours data for\nsupervised and unsupervised adaptation, respectively.\n", "versions": [{"version": "v1", "created": "Sat, 9 Nov 2019 19:41:50 GMT"}], "update_date": "2019-11-12", "authors_parsed": [["Meng", "Zhong", ""], ["Gaur", "Yashesh", ""], ["Li", "Jinyu", ""], ["Gong", "Yifan", ""]]}, {"id": "1911.03769", "submitter": "Jorge Gomez Robles", "authors": "J. Gomez Robles, J. Vanschoren", "title": "Learning to reinforcement learn for Neural Architecture Search", "comments": "32 pages, 21 figures, 9 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Reinforcement learning (RL) is a goal-oriented learning solution that has\nproven to be successful for Neural Architecture Search (NAS) on the CIFAR and\nImageNet datasets. However, a limitation of this approach is its high\ncomputational cost, making it unfeasible to replay it on other datasets.\nThrough meta-learning, we could bring this cost down by adapting previously\nlearned policies instead of learning them from scratch. In this work, we\npropose a deep meta-RL algorithm that learns an adaptive policy over a set of\nenvironments, making it possible to transfer it to previously unseen tasks. The\nalgorithm was applied to various proof-of-concept environments in the past, but\nwe adapt it to the NAS problem. We empirically investigate the agent's behavior\nduring training when challenged to design chain-structured neural architectures\nfor three datasets with increasing levels of hardness, to later fix the policy\nand evaluate it on two unseen datasets of different difficulty. Our results\nshow that, under resource constraints, the agent effectively adapts its\nstrategy during training to design better architectures than the ones designed\nby a standard RL algorithm, and can design good architectures during the\nevaluation on previously unseen environments. We also provide guidelines on the\napplicability of our framework in a more complex NAS setting by studying the\nprogress of the agent when challenged to design multi-branch architectures.\n", "versions": [{"version": "v1", "created": "Sat, 9 Nov 2019 20:13:00 GMT"}, {"version": "v2", "created": "Mon, 2 Dec 2019 22:22:35 GMT"}], "update_date": "2019-12-04", "authors_parsed": [["Robles", "J. Gomez", ""], ["Vanschoren", "J.", ""]]}, {"id": "1911.03779", "submitter": "Joseph Chow", "authors": "Susan Jia Xu, Qian Xie, Joseph Y. J. Chow, Xintao Liu", "title": "Empirical validation of network learning with taxi GPS data from Wuhan,\n  China", "comments": null, "journal-ref": "IEEE Intelligent Transportation Systems Magazine 13(1) (2021)\n  42-58", "doi": "10.1109/MITS.2020.3037324", "report-no": null, "categories": "physics.soc-ph cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In prior research, a statistically cheap method was developed to monitor\ntransportation network performance by using only a few groups of agents without\nhaving to forecast the population flows. The current study validates this\n\"multi-agent inverse optimization\" method using taxi GPS probe data from the\ncity of Wuhan, China. Using a controlled 2062-link network environment and\ndifferent GPS data processing algorithms, an online monitoring environment is\nsimulated using the real data over a 4-hour period. Results show that using\nonly samples from one OD pair, the multi-agent inverse optimization method can\nlearn network parameters such that forecasted travel times have a 0.23\ncorrelation with the observed travel times. By increasing to monitoring from\njust two OD pairs, the correlation improves further to 0.56.\n", "versions": [{"version": "v1", "created": "Sat, 9 Nov 2019 21:18:22 GMT"}, {"version": "v2", "created": "Mon, 17 Aug 2020 13:49:44 GMT"}], "update_date": "2021-06-08", "authors_parsed": [["Xu", "Susan Jia", ""], ["Xie", "Qian", ""], ["Chow", "Joseph Y. J.", ""], ["Liu", "Xintao", ""]]}, {"id": "1911.03782", "submitter": "Abdelrahman Mohamed", "authors": "Siddharth Dalmia, Abdelrahman Mohamed, Mike Lewis, Florian Metze, Luke\n  Zettlemoyer", "title": "Enforcing Encoder-Decoder Modularity in Sequence-to-Sequence Models", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Inspired by modular software design principles of independence,\ninterchangeability, and clarity of interface, we introduce a method for\nenforcing encoder-decoder modularity in seq2seq models without sacrificing the\noverall model quality or its full differentiability. We discretize the encoder\noutput units into a predefined interpretable vocabulary space using the\nConnectionist Temporal Classification (CTC) loss. Our modular systems achieve\nnear SOTA performance on the 300h Switchboard benchmark, with WER of 8.3% and\n17.6% on the SWB and CH subsets, using seq2seq models with encoder and decoder\nmodules which are independent and interchangeable.\n", "versions": [{"version": "v1", "created": "Sat, 9 Nov 2019 21:36:28 GMT"}], "update_date": "2019-11-12", "authors_parsed": [["Dalmia", "Siddharth", ""], ["Mohamed", "Abdelrahman", ""], ["Lewis", "Mike", ""], ["Metze", "Florian", ""], ["Zettlemoyer", "Luke", ""]]}, {"id": "1911.03784", "submitter": "Marc Khoury", "authors": "Marc Khoury", "title": "Adaptive versus Standard Descent Methods and Robustness Against\n  Adversarial Examples", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Adversarial examples are a pervasive phenomenon of machine learning models\nwhere seemingly imperceptible perturbations to the input lead to\nmisclassifications for otherwise statistically accurate models. In this paper\nwe study how the choice of optimization algorithm influences the robustness of\nthe resulting classifier to adversarial examples. Specifically we show an\nexample of a learning problem for which the solution found by adaptive\noptimization algorithms exhibits qualitatively worse robustness properties\nagainst both $L_{2}$- and $L_{\\infty}$-adversaries than the solution found by\nnon-adaptive algorithms. Then we fully characterize the geometry of the loss\nlandscape of $L_{2}$-adversarial training in least-squares linear regression.\nThe geometry of the loss landscape is subtle and has important consequences for\noptimization algorithms. Finally we provide experimental evidence which\nsuggests that non-adaptive methods consistently produce more robust models than\nadaptive methods.\n", "versions": [{"version": "v1", "created": "Sat, 9 Nov 2019 21:54:53 GMT"}, {"version": "v2", "created": "Sat, 8 Feb 2020 19:09:14 GMT"}], "update_date": "2020-02-11", "authors_parsed": [["Khoury", "Marc", ""]]}, {"id": "1911.03787", "submitter": "Yue Cao", "authors": "Yue Cao, Tianlong Chen, Zhangyang Wang, Yang Shen", "title": "Learning to Optimize in Swarms", "comments": "Accepted to Neural Information Processing Systems (NeurIPS2019)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG q-bio.BM stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Learning to optimize has emerged as a powerful framework for various\noptimization and machine learning tasks. Current such \"meta-optimizers\" often\nlearn in the space of continuous optimization algorithms that are point-based\nand uncertainty-unaware. To overcome the limitations, we propose a\nmeta-optimizer that learns in the algorithmic space of both point-based and\npopulation-based optimization algorithms. The meta-optimizer targets at a\nmeta-loss function consisting of both cumulative regret and entropy.\nSpecifically, we learn and interpret the update formula through a population of\nLSTMs embedded with sample- and feature-level attentions. Meanwhile, we\nestimate the posterior directly over the global optimum and use an uncertainty\nmeasure to help guide the learning process. Empirical results over non-convex\ntest functions and the protein-docking application demonstrate that this new\nmeta-optimizer outperforms existing competitors.\n", "versions": [{"version": "v1", "created": "Sat, 9 Nov 2019 22:25:05 GMT"}, {"version": "v2", "created": "Sat, 16 Nov 2019 19:16:42 GMT"}], "update_date": "2019-11-19", "authors_parsed": [["Cao", "Yue", ""], ["Chen", "Tianlong", ""], ["Wang", "Zhangyang", ""], ["Shen", "Yang", ""]]}, {"id": "1911.03799", "submitter": "Zhiqian Qiao", "authors": "Zhiqian Qiao, Zachariah Tyree, Priyantha Mudalige, Jeff Schneider and\n  John M. Dolan", "title": "Hierarchical Reinforcement Learning Method for Autonomous Vehicle\n  Behavior Planning", "comments": "8 pages, 10 figures, Submitted to IEEE Robotics and Automation\n  Letters", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this work, we propose a hierarchical reinforcement learning (HRL)\nstructure which is capable of performing autonomous vehicle planning tasks in\nsimulated environments with multiple sub-goals. In this hierarchical structure,\nthe network is capable of 1) learning one task with multiple sub-goals\nsimultaneously; 2) extracting attentions of states according to changing\nsub-goals during the learning process; 3) reusing the well-trained network of\nsub-goals for other similar tasks with the same sub-goals. The states are\ndefined as processed observations which are transmitted from the perception\nsystem of the autonomous vehicle. A hybrid reward mechanism is designed for\ndifferent hierarchical layers in the proposed HRL structure. Compared to\ntraditional RL methods, our algorithm is more sample-efficient since its\nmodular design allows reusing the policies of sub-goals across similar tasks.\nThe results show that the proposed method converges to an optimal policy faster\nthan traditional RL methods.\n", "versions": [{"version": "v1", "created": "Sat, 9 Nov 2019 23:19:59 GMT"}], "update_date": "2019-11-12", "authors_parsed": [["Qiao", "Zhiqian", ""], ["Tyree", "Zachariah", ""], ["Mudalige", "Priyantha", ""], ["Schneider", "Jeff", ""], ["Dolan", "John M.", ""]]}, {"id": "1911.03801", "submitter": "Zhiqian Qiao", "authors": "Zhiqian Qiao, Jing Zhao, Zachariah Tyree, Priyantha Mudalige, Jeff\n  Schneider and John M. Dolan", "title": "Human Driver Behavior Prediction based on UrbanFlow", "comments": "7 pages, 12 figures, submitted to 2020 International Conference on\n  Robotics and Automation (ICRA)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  How autonomous vehicles and human drivers share public transportation systems\nis an important problem, as fully automatic transportation environments are\nstill a long way off. Understanding human drivers' behavior can be beneficial\nfor autonomous vehicle decision making and planning, especially when the\nautonomous vehicle is surrounded by human drivers who have various driving\nbehaviors and patterns of interaction with other vehicles. In this paper, we\npropose an LSTM-based trajectory prediction method for human drivers which can\nhelp the autonomous vehicle make better decisions, especially in urban\nintersection scenarios. Meanwhile, in order to collect human drivers' driving\nbehavior data in the urban scenario, we describe a system called UrbanFlow\nwhich includes the whole procedure from raw bird's-eye view data collection via\ndrone to the final processed trajectories. The system is mainly intended for\nurban scenarios but can be extended to be used for any traffic scenarios.\n", "versions": [{"version": "v1", "created": "Sat, 9 Nov 2019 23:25:41 GMT"}], "update_date": "2019-11-12", "authors_parsed": [["Qiao", "Zhiqian", ""], ["Zhao", "Jing", ""], ["Tyree", "Zachariah", ""], ["Mudalige", "Priyantha", ""], ["Schneider", "Jeff", ""], ["Dolan", "John M.", ""]]}, {"id": "1911.03803", "submitter": "Arash Mohammadi", "authors": "Elahe Rahimian, Soheil Zabihi, Seyed Farokh Atashzar, Amir Asif, and\n  Arash Mohammadi", "title": "XceptionTime: A Novel Deep Architecture based on Depthwise Separable\n  Convolutions for Hand Gesture Classification", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG eess.SP stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Capitalizing on the need for addressing the existing challenges associated\nwith gesture recognition via sparse multichannel surface Electromyography\n(sEMG) signals, the paper proposes a novel deep learning model, referred to as\nthe XceptionTime architecture. The proposed innovative XceptionTime is designed\nby integration of depthwise separable convolutions, adaptive average pooling,\nand a novel non-linear normalization technique. At the heart of the proposed\narchitecture is several XceptionTime modules concatenated in series fashion\ndesigned to capture both temporal and spatial information-bearing contents of\nthe sparse multichannel sEMG signals without the need for data augmentation\nand/or manual design of feature extraction. In addition, through integration of\nadaptive average pooling, Conv1D, and the non-linear normalization approach,\nXceptionTime is less prone to overfitting, more robust to temporal translation\nof the input, and more importantly is independent from the input window size.\nFinally, by utilizing the depthwise separable convolutions, the XceptionTime\nnetwork has far fewer parameters resulting in a less complex network. The\nperformance of XceptionTime is tested on a sub Ninapro dataset, DB1, and the\nresults showed a superior performance in comparison to any existing\ncounterparts. In this regard, 5:71% accuracy improvement, on a window size\n200ms, is reported in this paper, for the first time.\n", "versions": [{"version": "v1", "created": "Sat, 9 Nov 2019 23:34:28 GMT"}], "update_date": "2019-11-12", "authors_parsed": [["Rahimian", "Elahe", ""], ["Zabihi", "Soheil", ""], ["Atashzar", "Seyed Farokh", ""], ["Asif", "Amir", ""], ["Mohammadi", "Arash", ""]]}, {"id": "1911.03804", "submitter": "Anru Zhang", "authors": "Anru Zhang, Yuetian Luo, Garvesh Raskutti, Ming Yuan", "title": "ISLET: Fast and Optimal Low-rank Tensor Regression via Importance\n  Sketching", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG cs.NA math.NA math.ST stat.ME stat.TH", "license": "http://creativecommons.org/licenses/by-sa/4.0/", "abstract": "  In this paper, we develop a novel procedure for low-rank tensor regression,\nnamely \\emph{\\underline{I}mportance \\underline{S}ketching \\underline{L}ow-rank\n\\underline{E}stimation for \\underline{T}ensors} (ISLET). The central idea\nbehind ISLET is \\emph{importance sketching}, i.e., carefully designed sketches\nbased on both the responses and low-dimensional structure of the parameter of\ninterest. We show that the proposed method is sharply minimax optimal in terms\nof the mean-squared error under low-rank Tucker assumptions and under\nrandomized Gaussian ensemble design. In addition, if a tensor is low-rank with\ngroup sparsity, our procedure also achieves minimax optimality. Further, we\nshow through numerical study that ISLET achieves comparable or better\nmean-squared error performance to existing state-of-the-art methods while\nhaving substantial storage and run-time advantages including capabilities for\nparallel and distributed computing. In particular, our procedure performs\nreliable estimation with tensors of dimension $p = O(10^8)$ and is $1$ or $2$\norders of magnitude faster than baseline methods.\n", "versions": [{"version": "v1", "created": "Sat, 9 Nov 2019 23:36:13 GMT"}, {"version": "v2", "created": "Fri, 8 May 2020 05:36:30 GMT"}], "update_date": "2020-05-11", "authors_parsed": [["Zhang", "Anru", ""], ["Luo", "Yuetian", ""], ["Raskutti", "Garvesh", ""], ["Yuan", "Ming", ""]]}, {"id": "1911.03809", "submitter": "Guoqing Zheng", "authors": "Guoqing Zheng, Ahmed Hassan Awadallah, Susan Dumais", "title": "Meta Label Correction for Learning with Weak Supervision", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Leveraging weak or noisy supervision for building effective machine learning\nmodels has long been an important research problem. The growing need for\nlarge-scale datasets to train deep learning models has increased its\nimportance. Weak or noisy supervision could originate from multiple sources\nincluding non-expert annotators or automatic labeling based on heuristics or\nuser interaction signals. Previous work on modeling and correcting weak labels\nhave been focused on various aspects, including loss correction, training\ninstance re-weighting, etc. In this paper, we approach this problem from a\nnovel perspective based on meta-learning. We view the label correction\nprocedure as a meta-process and propose a new meta-learning based framework\ntermed MLC for learning with weak supervision. Experiments with different label\nnoise levels on multiple datasets show that MLC can achieve large improvement\nover previous methods incorporating weak labels for learning.\n", "versions": [{"version": "v1", "created": "Sun, 10 Nov 2019 00:24:08 GMT"}], "update_date": "2019-11-12", "authors_parsed": [["Zheng", "Guoqing", ""], ["Awadallah", "Ahmed Hassan", ""], ["Dumais", "Susan", ""]]}, {"id": "1911.03810", "submitter": "Joseph Gaudio", "authors": "Joseph E. Gaudio, Anuradha M. Annaswamy, Eugene Lavretsky, Michael A.\n  Bolender", "title": "Parameter Estimation in Adaptive Control of Time-Varying Systems Under a\n  Range of Excitation Conditions", "comments": "8 Pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.OC cs.LG cs.SY eess.SY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper presents a new parameter estimation algorithm for the adaptive\ncontrol of a class of time-varying plants. The main feature of this algorithm\nis a matrix of time-varying learning rates, which enables parameter estimation\nerror trajectories to tend exponentially fast towards a compact set whenever\nexcitation conditions are satisfied. This algorithm is employed in a large\nclass of problems where unknown parameters are present and are time-varying. It\nis shown that this algorithm guarantees global boundedness of the state and\nparameter errors of the system, and avoids an often used filtering approach for\nconstructing key regressor signals. In addition, intervals of time over which\nthese errors tend exponentially fast toward a compact set are provided, both in\nthe presence of finite and persistent excitation. A projection operator is used\nto ensure the boundedness of the learning rate matrix, as compared to a\ntime-varying forgetting factor. Numerical simulations are provided to\ncomplement the theoretical analysis.\n", "versions": [{"version": "v1", "created": "Sun, 10 Nov 2019 00:28:00 GMT"}, {"version": "v2", "created": "Thu, 2 Jan 2020 14:03:41 GMT"}], "update_date": "2020-01-03", "authors_parsed": [["Gaudio", "Joseph E.", ""], ["Annaswamy", "Anuradha M.", ""], ["Lavretsky", "Eugene", ""], ["Bolender", "Michael A.", ""]]}, {"id": "1911.03821", "submitter": "Gaurav Sahu", "authors": "Gaurav Sahu, Olga Vechtomova", "title": "Adaptive Fusion Techniques for Multimodal Data", "comments": "Camera-ready version for EACL 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.CV cs.LG eess.AS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Effective fusion of data from multiple modalities, such as video, speech, and\ntext, is challenging due to the heterogeneous nature of multimodal data. In\nthis paper, we propose adaptive fusion techniques that aim to model context\nfrom different modalities effectively. Instead of defining a deterministic\nfusion operation, such as concatenation, for the network, we let the network\ndecide \"how\" to combine a given set of multimodal features more effectively. We\npropose two networks: 1) Auto-Fusion, which learns to compress information from\ndifferent modalities while preserving the context, and 2) GAN-Fusion, which\nregularizes the learned latent space given context from complementing\nmodalities. A quantitative evaluation on the tasks of multimodal machine\ntranslation and emotion recognition suggests that our lightweight, adaptive\nnetworks can better model context from other modalities than existing methods,\nmany of which employ massive transformer-based networks.\n", "versions": [{"version": "v1", "created": "Sun, 10 Nov 2019 01:39:46 GMT"}, {"version": "v2", "created": "Tue, 26 Jan 2021 08:08:02 GMT"}], "update_date": "2021-01-27", "authors_parsed": [["Sahu", "Gaurav", ""], ["Vechtomova", "Olga", ""]]}, {"id": "1911.03827", "submitter": "Yiheng Lin", "authors": "Yiheng Lin, Gautam Goel, Adam Wierman", "title": "Online Optimization with Predictions and Non-convex Losses", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study online optimization in a setting where an online learner seeks to\noptimize a per-round hitting cost, which may be non-convex, while incurring a\nmovement cost when changing actions between rounds. We ask: \\textit{under what\ngeneral conditions is it possible for an online learner to leverage predictions\nof future cost functions in order to achieve near-optimal costs?} Prior work\nhas provided near-optimal online algorithms for specific combinations of\nassumptions about hitting and switching costs, but no general results are\nknown. In this work, we give two general sufficient conditions that specify a\nrelationship between the hitting and movement costs which guarantees that a new\nalgorithm, Synchronized Fixed Horizon Control (SFHC), provides a $1+O(1/w)$\ncompetitive ratio, where $w$ is the number of predictions available to the\nlearner. Our conditions do not require the cost functions to be convex, and we\nalso derive competitive ratio results for non-convex hitting and movement\ncosts. Our results provide the first constant, dimension-free competitive ratio\nfor online non-convex optimization with movement costs. Further, we give an\nexample of a natural instance, Convex Body Chasing (CBC), where the sufficient\nconditions are not satisfied and we can prove that no online algorithm can have\na competitive ratio that converges to 1.\n", "versions": [{"version": "v1", "created": "Sun, 10 Nov 2019 02:01:20 GMT"}, {"version": "v2", "created": "Fri, 24 Jan 2020 00:39:02 GMT"}], "update_date": "2020-01-27", "authors_parsed": [["Lin", "Yiheng", ""], ["Goel", "Gautam", ""], ["Wierman", "Adam", ""]]}, {"id": "1911.03829", "submitter": "Yen-Chun Chen", "authors": "Yen-Chun Chen, Zhe Gan, Yu Cheng, Jingzhou Liu, Jingjing Liu", "title": "Distilling Knowledge Learned in BERT for Text Generation", "comments": "ACL 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Large-scale pre-trained language model such as BERT has achieved great\nsuccess in language understanding tasks. However, it remains an open question\nhow to utilize BERT for language generation. In this paper, we present a novel\napproach, Conditional Masked Language Modeling (C-MLM), to enable the\nfinetuning of BERT on target generation tasks. The finetuned BERT (teacher) is\nexploited as extra supervision to improve conventional Seq2Seq models (student)\nfor better text generation performance. By leveraging BERT's idiosyncratic\nbidirectional nature, distilling knowledge learned in BERT can encourage\nauto-regressive Seq2Seq models to plan ahead, imposing global sequence-level\nsupervision for coherent text generation. Experiments show that the proposed\napproach significantly outperforms strong Transformer baselines on multiple\nlanguage generation tasks such as machine translation and text summarization.\nOur proposed model also achieves new state of the art on IWSLT German-English\nand English-Vietnamese MT datasets. Code is available at\nhttps://github.com/ChenRocks/Distill-BERT-Textgen.\n", "versions": [{"version": "v1", "created": "Sun, 10 Nov 2019 02:12:38 GMT"}, {"version": "v2", "created": "Sat, 2 May 2020 01:59:18 GMT"}, {"version": "v3", "created": "Fri, 17 Jul 2020 22:24:29 GMT"}], "update_date": "2020-07-21", "authors_parsed": [["Chen", "Yen-Chun", ""], ["Gan", "Zhe", ""], ["Cheng", "Yu", ""], ["Liu", "Jingzhou", ""], ["Liu", "Jingjing", ""]]}, {"id": "1911.03831", "submitter": "He Lyu", "authors": "He Lyu, Ningyu Sha, Shuyang Qin, Ming Yan, Yuying Xie, Rongrong Wang", "title": "Manifold Denoising by Nonlinear Robust Principal Component Analysis", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper extends robust principal component analysis (RPCA) to nonlinear\nmanifolds. Suppose that the observed data matrix is the sum of a sparse\ncomponent and a component drawn from some low dimensional manifold. Is it\npossible to separate them by using similar ideas as RPCA? Is there any benefit\nin treating the manifold as a whole as opposed to treating each local region\nindependently? We answer these two questions affirmatively by proposing and\nanalyzing an optimization framework that separates the sparse component from\nthe manifold under noisy data. Theoretical error bounds are provided when the\ntangent spaces of the manifold satisfy certain incoherence conditions. We also\nprovide a near optimal choice of the tuning parameters for the proposed\noptimization formulation with the help of a new curvature estimation method.\nThe efficacy of our method is demonstrated on both synthetic and real datasets.\n", "versions": [{"version": "v1", "created": "Sun, 10 Nov 2019 02:16:28 GMT"}], "update_date": "2019-11-12", "authors_parsed": [["Lyu", "He", ""], ["Sha", "Ningyu", ""], ["Qin", "Shuyang", ""], ["Yan", "Ming", ""], ["Xie", "Yuying", ""], ["Wang", "Rongrong", ""]]}, {"id": "1911.03839", "submitter": "Dongrui Wu", "authors": "Bo Zhang and Yuqi Cui and Meng Wang and Jingjing Li and Lei Jin and\n  Dongrui Wu", "title": "In Vitro Fertilization (IVF) Cumulative Pregnancy Rate Prediction from\n  Basic Patient Characteristics", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.QM cs.CY cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Tens of millions of women suffer from infertility worldwide each year. In\nvitro fertilization (IVF) is the best choice for many such patients. However,\nIVF is expensive, time-consuming, and both physically and emotionally\ndemanding. The first question that a patient usually asks before the IVF is how\nlikely she will conceive, given her basic medical examination information. This\npaper proposes three approaches to predict the cumulative pregnancy rate after\nmultiple oocyte pickup cycles. Experiments on 11,190 patients showed that first\nclustering the patients into different groups and then building a support\nvector machine model for each group can achieve the best overall performance.\nOur model could be a quick and economic approach for reliably estimating the\ncumulative pregnancy rate for a patient, given only her basic medical\nexamination information, well before starting the actual IVF procedure. The\npredictions can help the patient make optimal decisions on whether to use her\nown oocyte or donor oocyte, how many oocyte pickup cycles she may need, whether\nto use embryo frozen, etc. They will also reduce the patient's cost and time to\npregnancy, and improve her quality of life.\n", "versions": [{"version": "v1", "created": "Sun, 10 Nov 2019 03:00:07 GMT"}], "update_date": "2019-11-12", "authors_parsed": [["Zhang", "Bo", ""], ["Cui", "Yuqi", ""], ["Wang", "Meng", ""], ["Li", "Jingjing", ""], ["Jin", "Lei", ""], ["Wu", "Dongrui", ""]]}, {"id": "1911.03843", "submitter": "Arindam Jati", "authors": "Arindam Jati, Amrutha Nadarajan, Karel Mundnich, Shrikanth Narayanan", "title": "Characterizing dynamically varying acoustic scenes from egocentric audio\n  recordings in workplace setting", "comments": "The paper is submitted to IEEE International Conference on Acoustics,\n  Speech and Signal Processing (ICASSP), 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.AS cs.LG cs.SD", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Devices capable of detecting and categorizing acoustic scenes have numerous\napplications such as providing context-aware user experiences. In this paper,\nwe address the task of characterizing acoustic scenes in a workplace setting\nfrom audio recordings collected with wearable microphones. The acoustic scenes,\ntracked with Bluetooth transceivers, vary dynamically with time from the\negocentric perspective of a mobile user. Our dataset contains experience\nsampled long audio recordings collected from clinical providers in a hospital,\nwho wore the audio badges during multiple work shifts. To handle the long\negocentric recordings, we propose a Time Delay Neural Network~(TDNN)-based\nsegment-level modeling. The experiments show that TDNN outperforms other models\nin the acoustic scene classification task. We investigate the effect of primary\nspeaker's speech in determining acoustic scenes from audio badges, and provide\na comparison between performance of different models. Moreover, we explore the\nrelationship between the sequence of acoustic scenes experienced by the users\nand the nature of their jobs, and find that the scene sequence predicted by our\nmodel tend to possess similar relationship. The initial promising results\nreveal numerous research directions for acoustic scene classification via\nwearable devices as well as egocentric analysis of dynamic acoustic scenes\nencountered by the users.\n", "versions": [{"version": "v1", "created": "Sun, 10 Nov 2019 04:11:47 GMT"}], "update_date": "2019-11-12", "authors_parsed": [["Jati", "Arindam", ""], ["Nadarajan", "Amrutha", ""], ["Mundnich", "Karel", ""], ["Narayanan", "Shrikanth", ""]]}, {"id": "1911.03845", "submitter": "Xueying Bai", "authors": "Xueying Bai, Jian Guan, Hongning Wang", "title": "Model-Based Reinforcement Learning with Adversarial Training for Online\n  Recommendation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.IR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Reinforcement learning is well suited for optimizing policies of recommender\nsystems. Current solutions mostly focus on model-free approaches, which require\nfrequent interactions with the real environment, and thus are expensive in\nmodel learning. Offline evaluation methods, such as importance sampling, can\nalleviate such limitations, but usually request a large amount of logged data\nand do not work well when the action space is large. In this work, we propose a\nmodel-based reinforcement learning solution which models user-agent interaction\nfor offline policy learning via a generative adversarial network. To reduce\nbias in the learned model and policy, we use a discriminator to evaluate the\nquality of generated data and scale the generated rewards. Our theoretical\nanalysis and empirical evaluations demonstrate the effectiveness of our\nsolution in learning policies from the offline and generated data.\n", "versions": [{"version": "v1", "created": "Sun, 10 Nov 2019 04:24:04 GMT"}, {"version": "v2", "created": "Wed, 13 Nov 2019 01:40:22 GMT"}, {"version": "v3", "created": "Fri, 17 Jan 2020 20:47:53 GMT"}], "update_date": "2020-01-22", "authors_parsed": [["Bai", "Xueying", ""], ["Guan", "Jian", ""], ["Wang", "Hongning", ""]]}, {"id": "1911.03849", "submitter": "Xinghua Qu", "authors": "Xinghua Qu, Zhu Sun, Yew-Soon Ong, Abhishek Gupta, Pengfei Wei", "title": "Minimalistic Attacks: How Little it Takes to Fool a Deep Reinforcement\n  Learning Policy", "comments": "Accepted by IEEE Transactions on Cognitive and Developmental System", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent studies have revealed that neural network-based policies can be easily\nfooled by adversarial examples. However, while most prior works analyze the\neffects of perturbing every pixel of every frame assuming white-box policy\naccess, in this paper we take a more restrictive view towards adversary\ngeneration - with the goal of unveiling the limits of a model's vulnerability.\nIn particular, we explore minimalistic attacks by defining three key settings:\n(1) black-box policy access: where the attacker only has access to the input\n(state) and output (action probability) of an RL policy; (2) fractional-state\nadversary: where only several pixels are perturbed, with the extreme case being\na single-pixel adversary; and (3) tactically-chanced attack: where only\nsignificant frames are tactically chosen to be attacked. We formulate the\nadversarial attack by accommodating the three key settings and explore their\npotency on six Atari games by examining four fully trained state-of-the-art\npolicies. In Breakout, for example, we surprisingly find that: (i) all policies\nshowcase significant performance degradation by merely modifying 0.01% of the\ninput state, and (ii) the policy trained by DQN is totally deceived by\nperturbation to only 1% frames.\n", "versions": [{"version": "v1", "created": "Sun, 10 Nov 2019 04:39:56 GMT"}, {"version": "v2", "created": "Fri, 22 Nov 2019 08:28:44 GMT"}, {"version": "v3", "created": "Fri, 21 Feb 2020 00:51:06 GMT"}, {"version": "v4", "created": "Fri, 6 Mar 2020 01:46:01 GMT"}, {"version": "v5", "created": "Thu, 29 Oct 2020 13:40:22 GMT"}], "update_date": "2020-10-30", "authors_parsed": [["Qu", "Xinghua", ""], ["Sun", "Zhu", ""], ["Ong", "Yew-Soon", ""], ["Gupta", "Abhishek", ""], ["Wei", "Pengfei", ""]]}, {"id": "1911.03853", "submitter": "Rakesh Bal", "authors": "Rakesh Bal and Sayan Sinha", "title": "Modelling Bahdanau Attention using Election methods aided by Q-Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CL stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Neural Machine Translation has lately gained a lot of \"attention\" with the\nadvent of more and more sophisticated but drastically improved models.\nAttention mechanism has proved to be a boon in this direction by providing\nweights to the input words, making it easy for the decoder to identify words\nrepresenting the present context. But by and by, as newer attention models with\nmore complexity came into development, they involved large computation, making\ninference slow. In this paper, we have modelled the attention network using\ntechniques resonating with social choice theory. Along with that, the attention\nmechanism, being a Markov Decision Process, has been represented by\nreinforcement learning techniques. Thus, we propose to use an election method\n($k$-Borda), fine-tuned using Q-learning, as a replacement for attention\nnetworks. The inference time for this network is less than a standard Bahdanau\ntranslator, and the results of the translation are comparable. This not only\nexperimentally verifies the claims stated above but also helped provide a\nfaster inference.\n", "versions": [{"version": "v1", "created": "Sun, 10 Nov 2019 04:55:46 GMT"}, {"version": "v2", "created": "Mon, 9 Dec 2019 14:46:21 GMT"}], "update_date": "2019-12-10", "authors_parsed": [["Bal", "Rakesh", ""], ["Sinha", "Sayan", ""]]}, {"id": "1911.03861", "submitter": "Yadollah Yaghoobzadeh", "authors": "Yadollah Yaghoobzadeh, Soroush Mehri, Remi Tachet, T.J. Hazen,\n  Alessandro Sordoni", "title": "Increasing Robustness to Spurious Correlations using Forgettable\n  Examples", "comments": "14 pages, Accepted at EACL2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Neural NLP models tend to rely on spurious correlations between labels and\ninput features to perform their tasks. Minority examples, i.e., examples that\ncontradict the spurious correlations present in the majority of data points,\nhave been shown to increase the out-of-distribution generalization of\npre-trained language models. In this paper, we first propose using example\nforgetting to find minority examples without prior knowledge of the spurious\ncorrelations present in the dataset. Forgettable examples are instances either\nlearned and then forgotten during training or never learned. We empirically\nshow how these examples are related to minorities in our training sets. Then,\nwe introduce a new approach to robustify models by fine-tuning our models\ntwice, first on the full training data and second on the minorities only. We\nobtain substantial improvements in out-of-distribution generalization when\napplying our approach to the MNLI, QQP, and FEVER datasets.\n", "versions": [{"version": "v1", "created": "Sun, 10 Nov 2019 05:56:41 GMT"}, {"version": "v2", "created": "Tue, 2 Feb 2021 03:10:10 GMT"}], "update_date": "2021-02-03", "authors_parsed": [["Yaghoobzadeh", "Yadollah", ""], ["Mehri", "Soroush", ""], ["Tachet", "Remi", ""], ["Hazen", "T. J.", ""], ["Sordoni", "Alessandro", ""]]}, {"id": "1911.03863", "submitter": "Trapit Bansal", "authors": "Trapit Bansal, Rishikesh Jha, Andrew McCallum", "title": "Learning to Few-Shot Learn Across Diverse Natural Language\n  Classification Tasks", "comments": "To appear at COLING 2020, camera-ready version", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Self-supervised pre-training of transformer models has shown enormous success\nin improving performance on a number of downstream tasks. However, fine-tuning\non a new task still requires large amounts of task-specific labelled data to\nachieve good performance. We consider this problem of learning to generalize to\nnew tasks with few examples as a meta-learning problem. While meta-learning has\nshown tremendous progress in recent years, its application is still limited to\nsimulated problems or problems with limited diversity across tasks. We develop\na novel method, LEOPARD, which enables optimization-based meta-learning across\ntasks with different number of classes, and evaluate different methods on\ngeneralization to diverse NLP classification tasks. LEOPARD is trained with the\nstate-of-the-art transformer architecture and shows better generalization to\ntasks not seen at all during training, with as few as 4 examples per label.\nAcross 17 NLP tasks, including diverse domains of entity typing, natural\nlanguage inference, sentiment analysis, and several other text classification\ntasks, we show that LEOPARD learns better initial parameters for few-shot\nlearning than self-supervised pre-training or multi-task training,\noutperforming many strong baselines, for example, yielding 14.5% average\nrelative gain in accuracy on unseen tasks with only 4 examples per label.\n", "versions": [{"version": "v1", "created": "Sun, 10 Nov 2019 06:10:47 GMT"}, {"version": "v2", "created": "Mon, 9 Mar 2020 00:59:14 GMT"}, {"version": "v3", "created": "Sun, 15 Nov 2020 20:57:53 GMT"}], "update_date": "2020-11-17", "authors_parsed": [["Bansal", "Trapit", ""], ["Jha", "Rishikesh", ""], ["McCallum", "Andrew", ""]]}, {"id": "1911.03864", "submitter": "Ofir Press", "authors": "Ofir Press, Noah A. Smith, Omer Levy", "title": "Improving Transformer Models by Reordering their Sublayers", "comments": "To appear at ACL 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Multilayer transformer networks consist of interleaved self-attention and\nfeedforward sublayers. Could ordering the sublayers in a different pattern lead\nto better performance? We generate randomly ordered transformers and train them\nwith the language modeling objective. We observe that some of these models are\nable to achieve better performance than the interleaved baseline, and that\nthose successful variants tend to have more self-attention at the bottom and\nmore feedforward sublayers at the top. We propose a new transformer pattern\nthat adheres to this property, the sandwich transformer, and show that it\nimproves perplexity on multiple word-level and character-level language\nmodeling benchmarks, at no cost in parameters, memory, or training time.\nHowever, the sandwich reordering pattern does not guarantee performance gains\nacross every task, as we demonstrate on machine translation models. Instead, we\nsuggest that further exploration of task-specific sublayer reorderings is\nneeded in order to unlock additional gains.\n", "versions": [{"version": "v1", "created": "Sun, 10 Nov 2019 06:14:15 GMT"}, {"version": "v2", "created": "Thu, 23 Apr 2020 10:16:33 GMT"}], "update_date": "2020-04-24", "authors_parsed": [["Press", "Ofir", ""], ["Smith", "Noah A.", ""], ["Levy", "Omer", ""]]}, {"id": "1911.03867", "submitter": "Sandeep Madireddy", "authors": "Sandeep Madireddy, Nan Li, Nesar Ramachandra, James Butler, Prasanna\n  Balaprakash, Salman Habib, Katrin Heitmann", "title": "A Modular Deep Learning Pipeline for Galaxy-Scale Strong Gravitational\n  Lens Detection and Modeling", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "astro-ph.IM astro-ph.CO cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Upcoming large astronomical surveys are expected to capture an unprecedented\nnumber of strong gravitational lensing systems in the Universe. Deep learning\nis emerging as a promising practical tool in detection and quantification of\nthese galaxy-scale image distortions. However, absence of large quantities of\nrepresentative data from current astronomical surveys requires development of\nrobust forward modeling of synthetic lensing images. Using a realistic and\nunbiased sample of the strong lenses created by using state-of-the-art\nextragalactic catalogs, we train a modular deep learning pipeline for\nuncertainty-quantified detection and modeling with intermediate image\nprocessing components for denoising and deblending the lensing systems. We\ndemonstrate a higher degree of interpretability and controlled systematics due\nto domain-specific task modules that are trained with different stages of\nsynthetic image generation. For lens detection and modeling, we obtain\nsemantically meaningful latent spaces that separate classes and provide\nuncertainty estimates that explain the misclassified images and provide\nuncertainty bounds on the lens parameters. In addition, we obtain an improved\nperformance---lens detection (classification) improved from 82% with the\nbaseline to 94%, while the lens modeling (regression) accuracy improved by 25%\nover the baseline model.\n", "versions": [{"version": "v1", "created": "Sun, 10 Nov 2019 06:49:38 GMT"}, {"version": "v2", "created": "Mon, 29 Jun 2020 05:52:37 GMT"}], "update_date": "2020-06-30", "authors_parsed": [["Madireddy", "Sandeep", ""], ["Li", "Nan", ""], ["Ramachandra", "Nesar", ""], ["Butler", "James", ""], ["Balaprakash", "Prasanna", ""], ["Habib", "Salman", ""], ["Heitmann", "Katrin", ""]]}, {"id": "1911.03869", "submitter": "Pratyay Banerjee", "authors": "Pratyay Banerjee, Kuntal Kumar Pal, Murthy Devarakonda, Chitta Baral", "title": "Knowledge Guided Named Entity Recognition for BioMedical Text", "comments": "6 pages, 2 figures, 5 tables, WIP", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.IR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this work, we formulate the NER task as a multi-answer knowledge guided QA\ntask (KGQA) which helps to predict entities only by assigning B, I and O tags\nwithout associating entity types with the tags. We provide different knowledge\ncontexts, such as, entity types, questions, definitions and examples along with\nthe text and train on a combined dataset of 18 biomedical corpora. This\nformulation (a) enables systems to jointly learn NER specific features from\nvaried NER datasets, (b) can use knowledge-text attention to identify words\nhaving higher similarity to provided knowledge, improving performance, (c)\nreduces system confusion by reducing the prediction classes to B, I, O only,\nand (d) makes detection of nested entities easier. We perform extensive\nexperiments of this KGQA formulation on 18 biomedical NER datasets, and through\nexperiments we note that knowledge helps in achieving better performance. Our\nproblem formulation is able to achieve state-of-the-art results in 12 datasets.\n", "versions": [{"version": "v1", "created": "Sun, 10 Nov 2019 07:05:25 GMT"}, {"version": "v2", "created": "Tue, 7 Apr 2020 03:15:54 GMT"}, {"version": "v3", "created": "Fri, 17 Apr 2020 07:42:01 GMT"}, {"version": "v4", "created": "Fri, 18 Sep 2020 04:38:31 GMT"}], "update_date": "2020-09-21", "authors_parsed": [["Banerjee", "Pratyay", ""], ["Pal", "Kuntal Kumar", ""], ["Devarakonda", "Murthy", ""], ["Baral", "Chitta", ""]]}, {"id": "1911.03872", "submitter": "Yann Dubois", "authors": "Yann Dubois, Gautier Dagan, Dieuwke Hupkes, Elia Bruni", "title": "Location Attention for Extrapolation to Longer Sequences", "comments": "11 pages, 9 figures, Accepted for publication at ACL 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Neural networks are surprisingly good at interpolating and perform remarkably\nwell when the training set examples resemble those in the test set. However,\nthey are often unable to extrapolate patterns beyond the seen data, even when\nthe abstractions required for such patterns are simple. In this paper, we first\nreview the notion of extrapolation, why it is important and how one could hope\nto tackle it. We then focus on a specific type of extrapolation which is\nespecially useful for natural language processing: generalization to sequences\nthat are longer than the training ones. We hypothesize that models with a\nseparate content- and location-based attention are more likely to extrapolate\nthan those with common attention mechanisms. We empirically support our claim\nfor recurrent seq2seq models with our proposed attention on variants of the\nLookup Table task. This sheds light on some striking failures of neural models\nfor sequences and on possible methods to approaching such issues.\n", "versions": [{"version": "v1", "created": "Sun, 10 Nov 2019 07:39:42 GMT"}, {"version": "v2", "created": "Tue, 21 Apr 2020 21:46:40 GMT"}], "update_date": "2020-04-23", "authors_parsed": [["Dubois", "Yann", ""], ["Dagan", "Gautier", ""], ["Hupkes", "Dieuwke", ""], ["Bruni", "Elia", ""]]}, {"id": "1911.03875", "submitter": "Khalil Mrini", "authors": "Khalil Mrini, Franck Dernoncourt, Quan Tran, Trung Bui, Walter Chang,\n  Ndapa Nakashole", "title": "Rethinking Self-Attention: Towards Interpretability in Neural Parsing", "comments": "EMNLP 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Attention mechanisms have improved the performance of NLP tasks while\nallowing models to remain explainable. Self-attention is currently widely used,\nhowever interpretability is difficult due to the numerous attention\ndistributions. Recent work has shown that model representations can benefit\nfrom label-specific information, while facilitating interpretation of\npredictions. We introduce the Label Attention Layer: a new form of\nself-attention where attention heads represent labels. We test our novel layer\nby running constituency and dependency parsing experiments and show our new\nmodel obtains new state-of-the-art results for both tasks on both the Penn\nTreebank (PTB) and Chinese Treebank. Additionally, our model requires fewer\nself-attention layers compared to existing work. Finally, we find that the\nLabel Attention heads learn relations between syntactic categories and show\npathways to analyze errors.\n", "versions": [{"version": "v1", "created": "Sun, 10 Nov 2019 08:17:11 GMT"}, {"version": "v2", "created": "Sat, 2 May 2020 04:34:52 GMT"}, {"version": "v3", "created": "Thu, 29 Oct 2020 06:17:11 GMT"}], "update_date": "2020-10-30", "authors_parsed": [["Mrini", "Khalil", ""], ["Dernoncourt", "Franck", ""], ["Tran", "Quan", ""], ["Bui", "Trung", ""], ["Chang", "Walter", ""], ["Nakashole", "Ndapa", ""]]}, {"id": "1911.03878", "submitter": "Dingzhu Wen", "authors": "Dingzhu Wen, Xiaoyang Li, Qunsong Zeng, Jinke Ren, and Kaibin Huang", "title": "An Overview of Data-Importance Aware Radio Resource Management for Edge\n  Machine Learning", "comments": "This work is an invited paper for Journal of Communications and\n  Information Networks", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IT cs.LG math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The 5G network connecting billions of Internet-of-Things (IoT) devices will\nmake it possible to harvest an enormous amount of real-time mobile data.\nFurthermore, the 5G virtualization architecture will enable cloud computing at\nthe (network) edge. The availability of both rich data and computation power at\nthe edge has motivated Internet companies to deploy artificial intelligence\n(AI) there, creating the hot area of edge-AI. Edge learning, the theme of this\nproject, concerns training edge-AI models, which endow on IoT devices\nintelligence for responding to real-time events. However, the transmission of\nhigh-dimensional data from many edge devices to servers can result in excessive\ncommunication latency, creating a bottleneck for edge learning. Traditional\nwireless techniques deigned for only radio access are ineffective in tackling\nthe challenge. Attempts to overcome the communication bottleneck has led to the\ndevelopment of a new class of techniques for intelligent radio resource\nmanagement (RRM), called data-importance aware RRM. Their designs feature the\ninterplay of active machine learning and wireless communication. Specifically,\nthe metrics that measure data importance in active learning (e.g.,\nclassification uncertainty and data diversity) are applied to RRM for efficient\nacquisition of distributed data in wireless networks to train AI models at\nservers. This article aims at providing an introduction to the emerging area of\nimportance-aware RRM. To this end, we will introduce the design principles,\nsurvey recent advancements in the area, discuss some design examples, and\nsuggest some promising research opportunities.\n", "versions": [{"version": "v1", "created": "Sun, 10 Nov 2019 08:59:21 GMT"}, {"version": "v2", "created": "Sun, 8 Dec 2019 09:39:28 GMT"}], "update_date": "2019-12-10", "authors_parsed": [["Wen", "Dingzhu", ""], ["Li", "Xiaoyang", ""], ["Zeng", "Qunsong", ""], ["Ren", "Jinke", ""], ["Huang", "Kaibin", ""]]}, {"id": "1911.03882", "submitter": "Canwen Xu", "authors": "Yu Duan, Canwen Xu, Jiaxin Pei, Jialong Han, Chenliang Li", "title": "Pre-train and Plug-in: Flexible Conditional Text Generation with\n  Variational Auto-Encoders", "comments": "Accepted as a long paper at ACL 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Conditional Text Generation has drawn much attention as a topic of Natural\nLanguage Generation (NLG) which provides the possibility for humans to control\nthe properties of generated contents. Current conditional generation models\ncannot handle emerging conditions due to their joint end-to-end learning\nfashion. When a new condition added, these techniques require full retraining.\nIn this paper, we present a new framework named Pre-train and Plug-in\nVariational Auto-Encoder (PPVAE) towards flexible conditional text generation.\nPPVAE decouples the text generation module from the condition representation\nmodule to allow \"one-to-many\" conditional generation. When a fresh condition\nemerges, only a lightweight network needs to be trained and works as a plug-in\nfor PPVAE, which is efficient and desirable for real-world applications.\nExtensive experiments demonstrate the superiority of PPVAE against the existing\nalternatives with better conditionality and diversity but less training effort.\n", "versions": [{"version": "v1", "created": "Sun, 10 Nov 2019 09:23:42 GMT"}, {"version": "v2", "created": "Sat, 4 Apr 2020 15:34:10 GMT"}, {"version": "v3", "created": "Sat, 25 Apr 2020 07:44:11 GMT"}, {"version": "v4", "created": "Fri, 8 May 2020 06:28:46 GMT"}], "update_date": "2020-05-11", "authors_parsed": [["Duan", "Yu", ""], ["Xu", "Canwen", ""], ["Pei", "Jiaxin", ""], ["Han", "Jialong", ""], ["Li", "Chenliang", ""]]}, {"id": "1911.03883", "submitter": "Jiarui Qin", "authors": "Jiarui Qin, Kan Ren, Yuchen Fang, Weinan Zhang, Yong Yu", "title": "Sequential Recommendation with Dual Side Neighbor-based Collaborative\n  Relation Modeling", "comments": "WSDM 2020", "journal-ref": null, "doi": "10.1145/3336191.3371842", "report-no": null, "categories": "cs.IR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Sequential recommendation task aims to predict user preference over items in\nthe future given user historical behaviors. The order of user behaviors implies\nthat there are resourceful sequential patterns embedded in the behavior history\nwhich reveal the underlying dynamics of user interests. Various sequential\nrecommendation methods are proposed to model the dynamic user behaviors.\nHowever, most of the models only consider the user's own behaviors and\ndynamics, while ignoring the collaborative relations among users and items,\ni.e., similar tastes of users or analogous properties of items. Without\nmodeling collaborative relations, those methods suffer from the lack of\nrecommendation diversity and thus may have worse performance. Worse still, most\nexisting methods only consider the user-side sequence and ignore the temporal\ndynamics on the item side. To tackle the problems of the current sequential\nrecommendation models, we propose Sequential Collaborative Recommender (SCoRe)\nwhich effectively mines high-order collaborative information using\ncross-neighbor relation modeling and, additionally utilizes both user-side and\nitem-side historical sequences to better capture user and item dynamics.\nExperiments on three real-world yet large-scale datasets demonstrate the\nsuperiority of the proposed model over strong baselines.\n", "versions": [{"version": "v1", "created": "Sun, 10 Nov 2019 09:28:20 GMT"}], "update_date": "2019-11-12", "authors_parsed": [["Qin", "Jiarui", ""], ["Ren", "Kan", ""], ["Fang", "Yuchen", ""], ["Zhang", "Weinan", ""], ["Yu", "Yong", ""]]}, {"id": "1911.03886", "submitter": "Kai Mei", "authors": "Kai Mei, Jun Liu, Xiaochen Zhang, Nandana Rajatheva and Jibo Wei", "title": "Performance Analysis on Machine Learning-Based Channel Estimation", "comments": "11 pages, 10 figures. To appear in IEEE Transactions on\n  Communications", "journal-ref": null, "doi": "10.1109/TCOMM.2021.3083597", "report-no": null, "categories": "eess.SP cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recently, machine learning-based channel estimation has attracted much\nattention. The performance of machine learning-based estimation has been\nvalidated by simulation experiments. However, little attention has been paid to\nthe theoretical performance analysis. In this paper, we investigate the mean\nsquare error (MSE) performance of machine learning-based estimation. Hypothesis\ntesting is employed to analyze its MSE upper bound. Furthermore, we build a\nstatistical model for hypothesis testing, which holds when the linear learning\nmodule with a low input dimension is used in machine learning-based channel\nestimation, and derive a clear analytical relation between the size of the\ntraining data and performance. Then, we simulate the machine learning-based\nchannel estimation in orthogonal frequency division multiplexing (OFDM) systems\nto verify our analysis results. Finally, the design considerations for the\nsituation where only limited training data is available are discussed. In this\nsituation, our analysis results can be applied to assess the performance and\nsupport the design of machine learning-based channel estimation.\n", "versions": [{"version": "v1", "created": "Sun, 10 Nov 2019 09:59:34 GMT"}, {"version": "v2", "created": "Wed, 14 Jul 2021 13:31:36 GMT"}], "update_date": "2021-07-15", "authors_parsed": [["Mei", "Kai", ""], ["Liu", "Jun", ""], ["Zhang", "Xiaochen", ""], ["Rajatheva", "Nandana", ""], ["Wei", "Jibo", ""]]}, {"id": "1911.03887", "submitter": "Liang Wang", "authors": "Liang Wang, Kezhi Wang, Cunhua Pan, Wei Xu, Nauman Aslam, Arumugam\n  Nallanathan", "title": "Deep Reinforcement Learning Based Dynamic Trajectory Control for\n  UAV-assisted Mobile Edge Computing", "comments": "Accepted by IEEE Transactions on Mobile Computing", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.SP cs.LG cs.NI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we consider a platform of flying mobile edge computing\n(F-MEC), where unmanned aerial vehicles (UAVs) serve as equipment providing\ncomputation resource, and they enable task offloading from user equipment (UE).\nWe aim to minimize energy consumption of all the UEs via optimizing the user\nassociation, resource allocation and the trajectory of UAVs. To this end, we\nfirst propose a Convex optimizAtion based Trajectory control algorithm (CAT),\nwhich solves the problem in an iterative way by using block coordinate descent\n(BCD) method. Then, to make the real-time decision while taking into account\nthe dynamics of the environment (i.e., UAV may take off from different\nlocations), we propose a deep Reinforcement leArning based Trajectory control\nalgorithm (RAT). In RAT, we apply the Prioritized Experience Replay (PER) to\nimprove the convergence of the training procedure. Different from the convex\noptimization based algorithm which may be susceptible to the initial points and\nrequires iterations, RAT can be adapted to any taking off points of the UAVs\nand can obtain the solution more rapidly than CAT once training process has\nbeen completed. Simulation results show that the proposed CAT and RAT achieve\nthe similar performance and both outperform traditional algorithms.\n", "versions": [{"version": "v1", "created": "Sun, 10 Nov 2019 10:24:04 GMT"}, {"version": "v2", "created": "Sat, 13 Feb 2021 15:42:03 GMT"}], "update_date": "2021-02-16", "authors_parsed": [["Wang", "Liang", ""], ["Wang", "Kezhi", ""], ["Pan", "Cunhua", ""], ["Xu", "Wei", ""], ["Aslam", "Nauman", ""], ["Nallanathan", "Arumugam", ""]]}, {"id": "1911.03895", "submitter": "John Wieting", "authors": "John Wieting, Graham Neubig, Taylor Berg-Kirkpatrick", "title": "A Bilingual Generative Transformer for Semantic Sentence Embedding", "comments": "Published as a long paper at EMNLP 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Semantic sentence embedding models encode natural language sentences into\nvectors, such that closeness in embedding space indicates closeness in the\nsemantics between the sentences. Bilingual data offers a useful signal for\nlearning such embeddings: properties shared by both sentences in a translation\npair are likely semantic, while divergent properties are likely stylistic or\nlanguage-specific. We propose a deep latent variable model that attempts to\nperform source separation on parallel sentences, isolating what they have in\ncommon in a latent semantic vector, and explaining what is left over with\nlanguage-specific latent vectors. Our proposed approach differs from past work\non semantic sentence encoding in two ways. First, by using a variational\nprobabilistic framework, we introduce priors that encourage source separation,\nand can use our model's posterior to predict sentence embeddings for\nmonolingual data at test time. Second, we use high-capacity transformers as\nboth data generating distributions and inference networks -- contrasting with\nmost past work on sentence embeddings. In experiments, our approach\nsubstantially outperforms the state-of-the-art on a standard suite of\nunsupervised semantic similarity evaluations. Further, we demonstrate that our\napproach yields the largest gains on more difficult subsets of these\nevaluations where simple word overlap is not a good indicator of similarity.\n", "versions": [{"version": "v1", "created": "Sun, 10 Nov 2019 10:48:09 GMT"}, {"version": "v2", "created": "Thu, 19 Nov 2020 17:21:10 GMT"}], "update_date": "2020-11-20", "authors_parsed": [["Wieting", "John", ""], ["Neubig", "Graham", ""], ["Berg-Kirkpatrick", "Taylor", ""]]}, {"id": "1911.03898", "submitter": "Joris Baan", "authors": "Joris Baan, Maartje ter Hoeve, Marlies van der Wees, Anne Schuth,\n  Maarten de Rijke", "title": "Understanding Multi-Head Attention in Abstractive Summarization", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Attention mechanisms in deep learning architectures have often been used as a\nmeans of transparency and, as such, to shed light on the inner workings of the\narchitectures. Recently, there has been a growing interest in whether or not\nthis assumption is correct. In this paper we investigate the interpretability\nof multi-head attention in abstractive summarization, a sequence-to-sequence\ntask for which attention does not have an intuitive alignment role, such as in\nmachine translation. We first introduce three metrics to gain insight in the\nfocus of attention heads and observe that these heads specialize towards\nrelative positions, specific part-of-speech tags, and named entities. However,\nwe also find that ablating and pruning these heads does not lead to a\nsignificant drop in performance, indicating redundancy. By replacing the\nsoftmax activation functions with sparsemax activation functions, we find that\nattention heads behave seemingly more transparent: we can ablate fewer heads\nand heads score higher on our interpretability metrics. However, if we apply\npruning to the sparsemax model we find that we can prune even more heads,\nraising the question whether enforced sparsity actually improves transparency.\nFinally, we find that relative positions heads seem integral to summarization\nperformance and persistently remain after pruning.\n", "versions": [{"version": "v1", "created": "Sun, 10 Nov 2019 10:56:10 GMT"}], "update_date": "2019-11-12", "authors_parsed": [["Baan", "Joris", ""], ["ter Hoeve", "Maartje", ""], ["van der Wees", "Marlies", ""], ["Schuth", "Anne", ""], ["de Rijke", "Maarten", ""]]}, {"id": "1911.03904", "submitter": "Deli Chen", "authors": "Deli Chen, Xiaoqian Liu, Yankai Lin, Peng Li, Jie Zhou, Qi Su, Xu Sun", "title": "HighwayGraph: Modelling Long-distance Node Relations for Improving\n  General Graph Neural Network", "comments": "8 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CL cs.SI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Graph Neural Networks (GNNs) are efficient approaches to process\ngraph-structured data. Modelling long-distance node relations is essential for\nGNN training and applications. However, conventional GNNs suffer from bad\nperformance in modelling long-distance node relations due to limited-layer\ninformation propagation. Existing studies focus on building deep GNN\narchitectures, which face the over-smoothing issue and cannot model node\nrelations in particularly long distance. To address this issue, we propose to\nmodel long-distance node relations by simply relying on shallow GNN\narchitectures with two solutions: (1) Implicitly modelling by learning to\npredict node pair relations (2) Explicitly modelling by adding edges between\nnodes that potentially have the same label. To combine our two solutions, we\npropose a model-agnostic training framework named HighwayGraph, which overcomes\nthe challenge of insufficient labeled nodes by sampling node pairs from the\ntraining set and adopting the self-training method. Extensive experimental\nresults show that our HighwayGraph achieves consistent and significant\nimprovements over four representative GNNs on three benchmark datasets.\n", "versions": [{"version": "v1", "created": "Sun, 10 Nov 2019 11:23:37 GMT"}, {"version": "v2", "created": "Sun, 17 May 2020 05:18:55 GMT"}], "update_date": "2020-05-19", "authors_parsed": [["Chen", "Deli", ""], ["Liu", "Xiaoqian", ""], ["Lin", "Yankai", ""], ["Li", "Peng", ""], ["Zhou", "Jie", ""], ["Su", "Qi", ""], ["Sun", "Xu", ""]]}, {"id": "1911.03912", "submitter": "Abdelrahman Mohamed", "authors": "Alexei Baevski, Michael Auli, Abdelrahman Mohamed", "title": "Effectiveness of self-supervised pre-training for speech recognition", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We compare self-supervised representation learning algorithms which either\nexplicitly quantize the audio data or learn representations without\nquantization. We find the former to be more accurate since it builds a good\nvocabulary of the data through vq-wav2vec [1] to enable learning of effective\nrepresentations in subsequent BERT training. Different to previous work, we\ndirectly fine-tune the pre-trained BERT models on transcribed speech using a\nConnectionist Temporal Classification (CTC) loss instead of feeding the\nrepresentations into a task-specific model. We also propose a BERT-style model\nlearning directly from the continuous audio data and compare pre-training on\nraw audio to spectral features. Fine-tuning a BERT model on 10 hour of labeled\nLibrispeech data with a vq-wav2vec vocabulary is almost as good as the best\nknown reported system trained on 100 hours of labeled data on testclean, while\nachieving a 25% WER reduction on test-other. When using only 10 minutes of\nlabeled data, WER is 25.2 on test-other and 16.3 on test-clean. This\ndemonstrates that self-supervision can enable speech recognition systems\ntrained on a near-zero amount of transcribed data.\n", "versions": [{"version": "v1", "created": "Sun, 10 Nov 2019 11:50:14 GMT"}, {"version": "v2", "created": "Fri, 14 Feb 2020 21:54:00 GMT"}, {"version": "v3", "created": "Mon, 18 May 2020 21:39:19 GMT"}], "update_date": "2020-05-20", "authors_parsed": [["Baevski", "Alexei", ""], ["Auli", "Michael", ""], ["Mohamed", "Abdelrahman", ""]]}, {"id": "1911.03923", "submitter": "Sara Masoud", "authors": "Sara Masoud, Bijoy Chowdhury, Young-Jun Son, Chieri Kubota, Russell\n  Tronstad", "title": "A Dynamic Modelling Framework for Human Hand Gesture Task Recognition", "comments": "6 pages, 5 figures, 2 tables, conference proceedings", "journal-ref": "(2018). A dynamic modelling framework for human hand gesture task\n  recognition. 563-568. Paper presented at 2018 Institute of Industrial and\n  Systems Engineers Annual Conference and Expo, IISE 2018, Orlando, United\n  States", "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Gesture recognition and hand motion tracking are important tasks in advanced\ngesture based interaction systems. In this paper, we propose to apply a sliding\nwindows filtering approach to sample the incoming streams of data from data\ngloves and a decision tree model to recognize the gestures in real time for a\nmanual grafting operation of a vegetable seedling propagation facility. The\nsequence of these recognized gestures defines the tasks that are taking place,\nwhich helps to evaluate individuals' performances and to identify any\nbottlenecks in real time. In this work, two pairs of data gloves are utilized,\nwhich reports the location of the fingers, hands, and wrists wirelessly (i.e.,\nvia Bluetooth). To evaluate the performance of the proposed framework, a\npreliminary experiment was conducted in multiple lab settings of tomato\ngrafting operations, where multiple subjects wear the data gloves while\nperforming different tasks. Our results show an accuracy of 91% on average, in\nterms of gesture recognition in real time by employing our proposed framework.\n", "versions": [{"version": "v1", "created": "Sun, 10 Nov 2019 13:06:48 GMT"}, {"version": "v2", "created": "Thu, 28 Nov 2019 05:01:22 GMT"}], "update_date": "2019-12-02", "authors_parsed": [["Masoud", "Sara", ""], ["Chowdhury", "Bijoy", ""], ["Son", "Young-Jun", ""], ["Kubota", "Chieri", ""], ["Tronstad", "Russell", ""]]}, {"id": "1911.03925", "submitter": "Chao Yu", "authors": "Chao Yu, Zhiguo Su", "title": "Symmetrical Gaussian Error Linear Units (SGELUs)", "comments": "6 pages, 5 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, a novel neural network activation function, called Symmetrical\nGaussian Error Linear Unit (SGELU), is proposed to obtain high performance. It\nis achieved by effectively integrating the property of the stochastic\nregularizer in the Gaussian Error Linear Unit (GELU) with the symmetrical\ncharacteristics. Combining with these two merits, the proposed unit introduces\nthe capability of the bidirection convergence to successfully optimize the\nnetwork without the gradient diminishing problem. The evaluations of SGELU\nagainst GELU and Linearly Scaled Hyperbolic Tangent (LiSHT) have been carried\nout on MNIST classification and MNIST auto-encoder, which provide great\nvalidations in terms of the performance, the convergence rate among these\napplications.\n", "versions": [{"version": "v1", "created": "Sun, 10 Nov 2019 13:14:22 GMT"}], "update_date": "2019-11-12", "authors_parsed": [["Yu", "Chao", ""], ["Su", "Zhiguo", ""]]}, {"id": "1911.03930", "submitter": "Mostafa Sadeghi", "authors": "Mostafa Sadeghi and Xavier Alameda-Pineda", "title": "Robust Unsupervised Audio-visual Speech Enhancement Using a Mixture of\n  Variational Autoencoders", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.AS cs.LG cs.SD", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recently, an audio-visual speech generative model based on variational\nautoencoder (VAE) has been proposed, which is combined with a nonnegative\nmatrix factorization (NMF) model for noise variance to perform unsupervised\nspeech enhancement. When visual data is clean, speech enhancement with\naudio-visual VAE shows a better performance than with audio-only VAE, which is\ntrained on audio-only data. However, audio-visual VAE is not robust against\nnoisy visual data, e.g., when for some video frames, speaker face is not\nfrontal or lips region is occluded. In this paper, we propose a robust\nunsupervised audio-visual speech enhancement method based on a per-frame VAE\nmixture model. This mixture model consists of a trained audio-only VAE and a\ntrained audio-visual VAE. The motivation is to skip noisy visual frames by\nswitching to the audio-only VAE model. We present a variational\nexpectation-maximization method to estimate the parameters of the model.\nExperiments show the promising performance of the proposed method.\n", "versions": [{"version": "v1", "created": "Sun, 10 Nov 2019 13:36:47 GMT"}], "update_date": "2019-11-12", "authors_parsed": [["Sadeghi", "Mostafa", ""], ["Alameda-Pineda", "Xavier", ""]]}, {"id": "1911.03936", "submitter": "Philipp Sadler", "authors": "Philipp Sadler, Tatjana Scheffler and David Schlangen", "title": "Can Neural Image Captioning be Controlled via Forced Attention?", "comments": "Accepted shortpaper for the 12th International Conference on Natural\n  Language Generation", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.CV cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Learned dynamic weighting of the conditioning signal (attention) has been\nshown to improve neural language generation in a variety of settings. The\nweights applied when generating a particular output sequence have also been\nviewed as providing a potentially explanatory insight into the internal\nworkings of the generator. In this paper, we reverse the direction of this\nconnection and ask whether through the control of the attention of the model we\ncan control its output. Specifically, we take a standard neural image\ncaptioning model that uses attention, and fix the attention to pre-determined\nareas in the image. We evaluate whether the resulting output is more likely to\nmention the class of the object in that area than the normally generated\ncaption. We introduce three effective methods to control the attention and find\nthat these are producing expected results in up to 28.56% of the cases.\n", "versions": [{"version": "v1", "created": "Sun, 10 Nov 2019 14:00:27 GMT"}], "update_date": "2019-11-12", "authors_parsed": [["Sadler", "Philipp", ""], ["Scheffler", "Tatjana", ""], ["Schlangen", "David", ""]]}, {"id": "1911.03941", "submitter": "Frederik Kratzert", "authors": "Frederik Kratzert, Daniel Klotz, Johannes Brandstetter, Pieter-Jan\n  Hoedt, Grey Nearing, Sepp Hochreiter", "title": "Using LSTMs for climate change assessment studies on droughts and floods", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG physics.ao-ph stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Climate change affects occurrences of floods and droughts worldwide. However,\npredicting climate impacts over individual watersheds is difficult, primarily\nbecause accurate hydrological forecasts require models that are calibrated to\npast data. In this work we present a large-scale LSTM-based modeling approach\nthat -- by training on large data sets -- learns a diversity of hydrological\nbehaviors. Previous work shows that this model is more accurate than current\nstate-of-the-art models, even when the LSTM-based approach operates\nout-of-sample and the latter in-sample. In this work, we show how this model\ncan assess the sensitivity of the underlying systems with regard to extreme\n(high and low) flows in individual watersheds over the continental US.\n", "versions": [{"version": "v1", "created": "Sun, 10 Nov 2019 14:50:48 GMT"}, {"version": "v2", "created": "Thu, 28 Nov 2019 09:36:48 GMT"}], "update_date": "2019-12-02", "authors_parsed": [["Kratzert", "Frederik", ""], ["Klotz", "Daniel", ""], ["Brandstetter", "Johannes", ""], ["Hoedt", "Pieter-Jan", ""], ["Nearing", "Grey", ""], ["Hochreiter", "Sepp", ""]]}, {"id": "1911.03949", "submitter": "Babak Hosseini", "authors": "Babak Hosseini, Barbara Hammer", "title": "Interpretable Multiple-Kernel Prototype Learning for Discriminative\n  Representation and Feature Selection", "comments": "CIKM 2019 conference", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Prototype-based methods are of the particular interest for domain specialists\nand practitioners as they summarize a dataset by a small set of\nrepresentatives. Therefore, in a classification setting, interpretability of\nthe prototypes is as significant as the prediction accuracy of the algorithm.\nNevertheless, the state-of-the-art methods make inefficient trade-offs between\nthese concerns by sacrificing one in favor of the other, especially if the\ngiven data has a kernel-based representation. In this paper, we propose a novel\ninterpretable multiple-kernel prototype learning (IMKPL) to construct highly\ninterpretable prototypes in the feature space, which are also efficient for the\ndiscriminative representation of the data. Our method focuses on the local\ndiscrimination of the classes in the feature space and shaping the prototypes\nbased on condensed class-homogeneous neighborhoods of data. Besides, IMKPL\nlearns a combined embedding in the feature space in which the above objectives\nare better fulfilled. When the base kernels coincide with the data dimensions,\nthis embedding results in a discriminative features selection. We evaluate\nIMKPL on several benchmarks from different domains which demonstrate its\nsuperiority to the related state-of-the-art methods regarding both\ninterpretability and discriminative representation.\n", "versions": [{"version": "v1", "created": "Sun, 10 Nov 2019 15:53:06 GMT"}], "update_date": "2019-11-12", "authors_parsed": [["Hosseini", "Babak", ""], ["Hammer", "Barbara", ""]]}, {"id": "1911.03951", "submitter": "Eyke H\\\"ullermeier", "authors": "Ammar Shaker and Eyke H\\\"ullermeier", "title": "TSK-Streams: Learning TSK Fuzzy Systems on Data Streams", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The problem of adaptive learning from evolving and possibly non-stationary\ndata streams has attracted a lot of interest in machine learning in the recent\npast, and also stimulated research in related fields, such as computational\nintelligence and fuzzy systems. In particular, several rule-based methods for\nthe incremental induction of regression models have been proposed. In this\npaper, we develop a method that combines the strengths of two existing\napproaches rooted in different learning paradigms. More concretely, our method\nadopts basic principles of the state-of-the-art learning algorithm AMRules and\nenriches them by the representational advantages of fuzzy rules. In a\ncomprehensive experimental study, TSK-Streams is shown to be highly competitive\nin terms of performance.\n", "versions": [{"version": "v1", "created": "Sun, 10 Nov 2019 16:04:22 GMT"}], "update_date": "2019-11-12", "authors_parsed": [["Shaker", "Ammar", ""], ["H\u00fcllermeier", "Eyke", ""]]}, {"id": "1911.03959", "submitter": "Samarth Gupta", "authors": "Samarth Gupta, Shreyas Chaudhari, Gauri Joshi and Osman Ya\\u{g}an", "title": "Multi-Armed Bandits with Correlated Arms", "comments": "A special case of the model studied in this paper is presented in\n  arXiv:1808.05904", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider a multi-armed bandit framework where the rewards obtained by\npulling different arms are correlated. We develop a unified approach to\nleverage these reward correlations and present fundamental generalizations of\nclassic bandit algorithms to the correlated setting. We present a unified proof\ntechnique to analyze the proposed algorithms. Rigorous analysis of C-UCB and\nC-TS (the correlated bandit versions of Upper-confidence-bound and Thompson\nsampling) reveals that the algorithms end up pulling certain sub-optimal arms,\ntermed as non-competitive, only O(1) times, as opposed to the O(log T) pulls\nrequired by classic bandit algorithms such as UCB, TS etc. We present\nregret-lower bound and show that when arms are correlated through a latent\nrandom source, our algorithms obtain order-optimal regret. We validate the\nproposed algorithms via experiments on the MovieLens and Goodreads datasets,\nand show significant improvement over classical bandit algorithms.\n", "versions": [{"version": "v1", "created": "Wed, 6 Nov 2019 16:56:46 GMT"}, {"version": "v2", "created": "Tue, 3 Dec 2019 23:29:49 GMT"}, {"version": "v3", "created": "Tue, 16 Jun 2020 18:05:23 GMT"}], "update_date": "2020-06-18", "authors_parsed": [["Gupta", "Samarth", ""], ["Chaudhari", "Shreyas", ""], ["Joshi", "Gauri", ""], ["Ya\u011fan", "Osman", ""]]}, {"id": "1911.03966", "submitter": "Youzuo Lin", "authors": "Tiantong Wang, Daniel Trugman, and Youzuo Lin", "title": "SeismoGen: Seismic Waveform Synthesis Using Generative Adversarial\n  Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG physics.geo-ph stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Detecting earthquake events from seismic time series has proved itself a\nchallenging task. Manual detection can be expensive and tedious due to the\nintensive labor and large scale data set. In recent years, automatic detection\nmethods based on machine learning have been developed to improve accuracy and\nefficiency. However, the accuracy of those methods relies on a sufficient\namount of high-quality training data, which itself can be expensive to obtain\ndue to the requirement of domain knowledge and subject matter expertise. This\npaper is to resolve this dilemma by answering two questions: (1) provided with\na limited number of reliable labels, can we use them to generate more synthetic\nlabels; (2) Can we use those synthetic labels to improve the detectability?\nAmong all the existing generative models, the generative adversarial network\n(GAN) shows its supreme capability in generating high-quality synthetic samples\nin multiple domains. We designed our model based on GAN. In particular, we\nstudied several different network structures. By comparing the generated\nresults, our GAN-based generative model yields the highest quality. We further\ncombine the dataset with synthetic samples generated by our generative model\nand show that the detectability of our earthquake classification model is\nsignificantly improved than the one trained without augmenting the training\nset.\n", "versions": [{"version": "v1", "created": "Sun, 10 Nov 2019 17:32:09 GMT"}, {"version": "v2", "created": "Sat, 2 May 2020 21:46:21 GMT"}], "update_date": "2020-05-05", "authors_parsed": [["Wang", "Tiantong", ""], ["Trugman", "Daniel", ""], ["Lin", "Youzuo", ""]]}, {"id": "1911.03970", "submitter": "Yassir Fathullah", "authors": "Yassir Fathullah, Chao Zhang, Philip C. Woodland", "title": "Improved Large-margin Softmax Loss for Speaker Diarisation", "comments": "ICASSP 2020", "journal-ref": "ICASSP 2020, Barcelona, Spain, 2020, pp. 7104-7108", "doi": "10.1109/ICASSP40776.2020.9053373", "report-no": null, "categories": "eess.AS cs.CL cs.LG cs.SD", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Speaker diarisation systems nowadays use embeddings generated from speech\nsegments in a bottleneck layer, which are needed to be discriminative for\nunseen speakers. It is well-known that large-margin training can improve the\ngeneralisation ability to unseen data, and its use in such open-set problems\nhas been widespread. Therefore, this paper introduces a general approach to the\nlarge-margin softmax loss without any approximations to improve the quality of\nspeaker embeddings for diarisation. Furthermore, a novel and simple way to\nstabilise training, when large-margin softmax is used, is proposed. Finally, to\ncombat the effect of overlapping speech, different training margins are used to\nreduce the negative effect overlapping speech has on creating discriminative\nembeddings. Experiments on the AMI meeting corpus show that the use of\nlarge-margin softmax significantly improves the speaker error rate (SER). By\nusing all hyper parameters of the loss in a unified way, further improvements\nwere achieved which reached a relative SER reduction of 24.6% over the\nbaseline. However, by training overlapping and single speaker speech samples\nwith different margins, the best result was achieved, giving overall a 29.5%\nSER reduction relative to the baseline.\n", "versions": [{"version": "v1", "created": "Sun, 10 Nov 2019 17:41:11 GMT"}, {"version": "v2", "created": "Fri, 14 Feb 2020 17:34:53 GMT"}, {"version": "v3", "created": "Mon, 6 Jul 2020 09:32:49 GMT"}], "update_date": "2020-07-07", "authors_parsed": [["Fathullah", "Yassir", ""], ["Zhang", "Chao", ""], ["Woodland", "Philip C.", ""]]}, {"id": "1911.03972", "submitter": "Mohammad Hamed Mozaffari", "authors": "M. Hamed Mozaffari, Md. Aminur Rab Ratul, Won-Sook Lee", "title": "IrisNet: Deep Learning for Automatic and Real-time Tongue Contour\n  Tracking in Ultrasound Video Data using Peripheral Vision", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.IV cs.CV cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The progress of deep convolutional neural networks has been successfully\nexploited in various real-time computer vision tasks such as image\nclassification and segmentation. Owing to the development of computational\nunits, availability of digital datasets, and improved performance of deep\nlearning models, fully automatic and accurate tracking of tongue contours in\nreal-time ultrasound data became practical only in recent years. Recent studies\nhave shown that the performance of deep learning techniques is significant in\nthe tracking of ultrasound tongue contours in real-time applications such as\npronunciation training using multimodal ultrasound-enhanced approaches. Due to\nthe high correlation between ultrasound tongue datasets, it is feasible to have\na general model that accomplishes automatic tongue tracking for almost all\ndatasets. In this paper, we proposed a deep learning model comprises of a\nconvolutional module mimicking the peripheral vision ability of the human eye\nto handle real-time, accurate, and fully automatic tongue contour tracking\ntasks, applicable for almost all primary ultrasound tongue datasets.\nQualitative and quantitative assessment of IrisNet on different ultrasound\ntongue datasets and PASCAL VOC2012 revealed its outstanding generalization\nachievement in compare with similar techniques.\n", "versions": [{"version": "v1", "created": "Sun, 10 Nov 2019 17:59:28 GMT"}, {"version": "v2", "created": "Fri, 17 Apr 2020 20:01:29 GMT"}], "update_date": "2020-04-21", "authors_parsed": [["Mozaffari", "M. Hamed", ""], ["Ratul", "Md. Aminur Rab", ""], ["Lee", "Won-Sook", ""]]}, {"id": "1911.03976", "submitter": "Teng Long", "authors": "Teng Long, Yanshuai Cao, Jackie Chi Kit Cheung", "title": "On Posterior Collapse and Encoder Feature Dispersion in Sequence VAEs", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CL stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Variational autoencoders (VAEs) hold great potential for modelling text, as\nthey could in theory separate high-level semantic and syntactic properties from\nlocal regularities of natural language. Practically, however, VAEs with\nautoregressive decoders often suffer from posterior collapse, a phenomenon\nwhere the model learns to ignore the latent variables, causing the sequence VAE\nto degenerate into a language model. In this paper, we argue that posterior\ncollapse is in part caused by the lack of dispersion in encoder features. We\nprovide empirical evidence to verify this hypothesis, and propose a\nstraightforward fix using pooling. This simple technique effectively prevents\nposterior collapse, allowing model to achieve significantly better data\nlog-likelihood than standard sequence VAEs. Comparing to existing work, our\nproposed method is able to achieve comparable or superior performances while\nbeing more computationally efficient.\n", "versions": [{"version": "v1", "created": "Sun, 10 Nov 2019 18:50:46 GMT"}, {"version": "v2", "created": "Tue, 10 Nov 2020 17:38:27 GMT"}], "update_date": "2020-11-11", "authors_parsed": [["Long", "Teng", ""], ["Cao", "Yanshuai", ""], ["Cheung", "Jackie Chi Kit", ""]]}, {"id": "1911.03977", "submitter": "Chao Zhang", "authors": "Chao Zhang, Zichao Yang, Xiaodong He, Li Deng", "title": "Multimodal Intelligence: Representation Learning, Information Fusion,\n  and Applications", "comments": null, "journal-ref": null, "doi": "10.1109/JSTSP.2020.2987728", "report-no": null, "categories": "cs.AI cs.CL cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep learning methods have revolutionized speech recognition, image\nrecognition, and natural language processing since 2010. Each of these tasks\ninvolves a single modality in their input signals. However, many applications\nin the artificial intelligence field involve multiple modalities. Therefore, it\nis of broad interest to study the more difficult and complex problem of\nmodeling and learning across multiple modalities. In this paper, we provide a\ntechnical review of available models and learning methods for multimodal\nintelligence. The main focus of this review is the combination of vision and\nnatural language modalities, which has become an important topic in both the\ncomputer vision and natural language processing research communities. This\nreview provides a comprehensive analysis of recent works on multimodal deep\nlearning from three perspectives: learning multimodal representations, fusing\nmultimodal signals at various levels, and multimodal applications. Regarding\nmultimodal representation learning, we review the key concepts of embedding,\nwhich unify multimodal signals into a single vector space and thereby enable\ncross-modality signal processing. We also review the properties of many types\nof embeddings that are constructed and learned for general downstream tasks.\nRegarding multimodal fusion, this review focuses on special architectures for\nthe integration of representations of unimodal signals for a particular task.\nRegarding applications, selected areas of a broad interest in the current\nliterature are covered, including image-to-text caption generation,\ntext-to-image generation, and visual question answering. We believe that this\nreview will facilitate future studies in the emerging field of multimodal\nintelligence for related communities.\n", "versions": [{"version": "v1", "created": "Sun, 10 Nov 2019 18:58:20 GMT"}, {"version": "v2", "created": "Mon, 23 Mar 2020 11:00:48 GMT"}, {"version": "v3", "created": "Fri, 10 Apr 2020 09:16:13 GMT"}], "update_date": "2020-07-15", "authors_parsed": [["Zhang", "Chao", ""], ["Yang", "Zichao", ""], ["He", "Xiaodong", ""], ["Deng", "Li", ""]]}, {"id": "1911.03988", "submitter": "Dionysios Kalogerias", "authors": "Dionysios S. Kalogerias, Mark Eisen, George J. Pappas, Alejandro\n  Ribeiro", "title": "Model-Free Learning of Optimal Ergodic Policies in Wireless Systems", "comments": "13 pages, 4 figures", "journal-ref": null, "doi": "10.1109/TSP.2020.3030073", "report-no": null, "categories": "eess.SY cs.LG cs.SY eess.SP math.OC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Learning optimal resource allocation policies in wireless systems can be\neffectively achieved by formulating finite dimensional constrained programs\nwhich depend on system configuration, as well as the adopted learning\nparameterization. The interest here is in cases where system models are\nunavailable, prompting methods that probe the wireless system with candidate\npolicies, and then use observed performance to determine better policies. This\ngeneric procedure is difficult because of the need to cull accurate gradient\nestimates out of these limited system queries. This paper constructs and\nexploits smoothed surrogates of constrained ergodic resource allocation\nproblems, the gradients of the former being representable exactly as averages\nof finite differences that can be obtained through limited system probing.\nLeveraging this unique property, we develop a new model-free primal-dual\nalgorithm for learning optimal ergodic resource allocations, while we\nrigorously analyze the relationships between original policy search problems\nand their surrogates, in both primal and dual domains. First, we show that both\nprimal and dual domain surrogates are uniformly consistent approximations of\ntheir corresponding original finite dimensional counterparts. Upon further\nassuming the use of near-universal policy parameterizations, we also develop\nexplicit bounds on the gap between optimal values of initial, infinite\ndimensional resource allocation problems, and dual values of their\nparameterized smoothed surrogates. In fact, we show that this duality gap\ndecreases at a linear rate relative to smoothing and universality parameters.\nThus, it can be made arbitrarily small at will, also justifying our proposed\nprimal-dual algorithmic recipe. Numerical simulations confirm the effectiveness\nof our approach.\n", "versions": [{"version": "v1", "created": "Sun, 10 Nov 2019 19:56:12 GMT"}], "update_date": "2020-12-02", "authors_parsed": [["Kalogerias", "Dionysios S.", ""], ["Eisen", "Mark", ""], ["Pappas", "George J.", ""], ["Ribeiro", "Alejandro", ""]]}, {"id": "1911.03991", "submitter": "Asma Balamane", "authors": "Asma Balamane and Zina Taklit", "title": "Using Deep Neural Networks for Estimating Loop Unrolling Factor", "comments": "Key words: Loop Unrolling, Deep Neural Network, Feature Extraction,\n  TIRAMISU compiler", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Optimizing programs requires deep expertise. On one hand, it is a tedious\ntask, because it requires a lot of tests to find out the best combination of\noptimizations to apply with their best factors. On the other hand, this task is\ncritical, because it may degrade the performance of programs instead of\nimproving it. The automatization of this task can deal with this problem and\npermit to obtain good results. Optimizing loops that take the most significant\npart of the program execution time plays a crucial role to achieve best\nperformance. In this paper, we address Loop unrolling optimization, by\nproposing a deep Neural Network model to predict the optimal unrolling factor\nfor programs written for TIRAMISU. TIRAMISU is a polyhedral framework designed\nto generate high performance code for multiple platforms including multicores,\nGPUs, and distributed machines. TIRAMISU introduces a scheduling language with\nnovel commands to explicitly manage the complexities that arise when targeting\nthese systems.\n", "versions": [{"version": "v1", "created": "Sun, 10 Nov 2019 20:19:33 GMT"}], "update_date": "2019-11-12", "authors_parsed": [["Balamane", "Asma", ""], ["Taklit", "Zina", ""]]}, {"id": "1911.03992", "submitter": "Bach Tran", "authors": "Hoai An Le Thi, Hoai Minh Le, Duy Nhat Phan, Bach Tran", "title": "Stochastic DCA for minimizing a large sum of DC functions with\n  application to Multi-class Logistic Regression", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.OC cs.LG cs.NA math.NA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the large sum of DC (Difference of Convex) functions minimization\nproblem which appear in several different areas, especially in stochastic\noptimization and machine learning. Two DCA (DC Algorithm) based algorithms are\nproposed: stochastic DCA and inexact stochastic DCA. We prove that the\nconvergence of both algorithms to a critical point is guaranteed with\nprobability one. Furthermore, we develop our stochastic DCA for solving an\nimportant problem in multi-task learning, namely group variables selection in\nmulti class logistic regression. The corresponding stochastic DCA is very\ninexpensive, all computations are explicit. Numerical experiments on several\nbenchmark datasets and synthetic datasets illustrate the efficiency of our\nalgorithms and their superiority over existing methods, with respect to\nclassification accuracy, sparsity of solution as well as running time.\n", "versions": [{"version": "v1", "created": "Sun, 10 Nov 2019 20:20:00 GMT"}], "update_date": "2019-11-12", "authors_parsed": [["Thi", "Hoai An Le", ""], ["Le", "Hoai Minh", ""], ["Phan", "Duy Nhat", ""], ["Tran", "Bach", ""]]}, {"id": "1911.04004", "submitter": "Chara Podimata", "authors": "Yiling Chen, Yang Liu and Chara Podimata", "title": "Learning Strategy-Aware Linear Classifiers", "comments": "Appears in NeurIPS2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.GT cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We address the question of repeatedly learning linear classifiers against\nagents who are strategically trying to game the deployed classifiers, and we\nuse the Stackelberg regret to measure the performance of our algorithms. First,\nwe show that Stackelberg and external regret for the problem of strategic\nclassification are strongly incompatible: i.e., there exist worst-case\nscenarios, where any sequence of actions providing sublinear external regret\nmight result in linear Stackelberg regret and vice versa. Second, we present a\nstrategy-aware algorithm for minimizing the Stackelberg regret for which we\nprove nearly matching upper and lower regret bounds. Finally, we provide\nsimulations to complement our theoretical analysis. Our results advance the\ngrowing literature of learning from revealed preferences, which has so far\nfocused on \"smoother\" assumptions from the perspective of the learner and the\nagents respectively.\n", "versions": [{"version": "v1", "created": "Sun, 10 Nov 2019 22:21:36 GMT"}, {"version": "v2", "created": "Wed, 8 Apr 2020 00:56:49 GMT"}, {"version": "v3", "created": "Fri, 12 Jun 2020 14:19:08 GMT"}, {"version": "v4", "created": "Mon, 16 Nov 2020 02:16:16 GMT"}], "update_date": "2020-11-17", "authors_parsed": [["Chen", "Yiling", ""], ["Liu", "Yang", ""], ["Podimata", "Chara", ""]]}, {"id": "1911.04006", "submitter": "Valentina Maria Salvatelli", "authors": "Valentina Salvatelli, Souvik Bose, Brad Neuberg, Luiz F. G. dos\n  Santos, Mark Cheung, Miho Janvier, Atilim Gunes Baydin, Yarin Gal, Meng Jin", "title": "Using U-Nets to Create High-Fidelity Virtual Observations of the Solar\n  Corona", "comments": "5 pages, 6 figures, Accepted at the NeurIPS 2019 Workshop ML4PS", "journal-ref": null, "doi": null, "report-no": null, "categories": "astro-ph.SR astro-ph.IM cs.LG physics.space-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Understanding and monitoring the complex and dynamic processes of the Sun is\nimportant for a number of human activities on Earth and in space. For this\nreason, NASA's Solar Dynamics Observatory (SDO) has been continuously\nmonitoring the multi-layered Sun's atmosphere in high-resolution since its\nlaunch in 2010, generating terabytes of observational data every day. The\nsynergy between machine learning and this enormous amount of data has the\npotential, still largely unexploited, to advance our understanding of the Sun\nand extend the capabilities of heliophysics missions. In the present work, we\nshow that deep learning applied to SDO data can be successfully used to create\na high-fidelity virtual telescope that generates synthetic observations of the\nsolar corona by image translation. Towards this end we developed a deep neural\nnetwork, structured as an encoder-decoder with skip connections (U-Net), that\nreconstructs the Sun's image of one instrument channel given temporally aligned\nimages in three other channels. The approach we present has the potential to\nreduce the telemetry needs of SDO, enhance the capabilities of missions that\nhave less observing channels, and transform the concept development of future\nmissions.\n", "versions": [{"version": "v1", "created": "Sun, 10 Nov 2019 22:48:56 GMT"}], "update_date": "2019-11-12", "authors_parsed": [["Salvatelli", "Valentina", ""], ["Bose", "Souvik", ""], ["Neuberg", "Brad", ""], ["Santos", "Luiz F. G. dos", ""], ["Cheung", "Mark", ""], ["Janvier", "Miho", ""], ["Baydin", "Atilim Gunes", ""], ["Gal", "Yarin", ""], ["Jin", "Meng", ""]]}, {"id": "1911.04008", "submitter": "Valentina Maria Salvatelli", "authors": "Brad Neuberg, Souvik Bose, Valentina Salvatelli, Luiz F.G. dos Santos,\n  Mark Cheung, Miho Janvier, Atilim Gunes Baydin, Yarin Gal, Meng Jin", "title": "Auto-Calibration of Remote Sensing Solar Telescopes with Deep Learning", "comments": "6 pages, 3 figures, Accepted at NeurIPS 2019 Workshop ML4PS", "journal-ref": null, "doi": null, "report-no": null, "categories": "astro-ph.SR astro-ph.IM cs.LG physics.space-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  As a part of NASA's Heliophysics System Observatory (HSO) fleet of\nsatellites,the Solar Dynamics Observatory (SDO) has continuously monitored the\nSun since2010. Ultraviolet (UV) and Extreme UV (EUV) instruments in orbit, such\nasSDO's Atmospheric Imaging Assembly (AIA) instrument, suffer time-dependent\ndegradation which reduces instrument sensitivity. Accurate calibration for\n(E)UV instruments currently depends on periodic sounding rockets, which are\ninfrequent and not practical for heliophysics missions in deep space. In the\npresent work, we develop a Convolutional Neural Network (CNN) that\nauto-calibrates SDO/AIA channels and corrects sensitivity degradation by\nexploiting spatial patterns in multi-wavelength observations to arrive at a\nself-calibration of (E)UV imaging instruments. Our results remove a major\nimpediment to developing future HSOmissions of the same scientific caliber as\nSDO but in deep space, able to observe the Sun from more vantage points than\njust SDO's current geosynchronous orbit.This approach can be adopted to perform\nautocalibration of other imaging systems exhibiting similar forms of\ndegradation\n", "versions": [{"version": "v1", "created": "Sun, 10 Nov 2019 23:04:45 GMT"}], "update_date": "2019-11-12", "authors_parsed": [["Neuberg", "Brad", ""], ["Bose", "Souvik", ""], ["Salvatelli", "Valentina", ""], ["Santos", "Luiz F. G. dos", ""], ["Cheung", "Mark", ""], ["Janvier", "Miho", ""], ["Baydin", "Atilim Gunes", ""], ["Gal", "Yarin", ""], ["Jin", "Meng", ""]]}, {"id": "1911.04013", "submitter": "Vishal Anand", "authors": "Vishal Anand, Ravi Shukla, Ashwani Gupta and Abhishek Kumar", "title": "Customized video filtering on YouTube", "comments": "13 pages, 5 figures, 1 table", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CY cs.IR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Inappropriate and profane content on social media is exponentially increasing\nand big corporations are becoming more aware of the type of content on which\nthey are advertising and how it may affect their brand reputation. But with a\nhuge surge in content being posted online it becomes seemingly difficult to\nfilter out related videos on which they can run their ads without compromising\nbrand name. Advertising on youtube videos generates a huge amount of revenue\nfor corporations. It becomes increasingly important for such corporations to\nadvertise on only the videos that don't hurt the feelings, community or harmony\nof the audience at large. In this paper, we propose a system to identify\ninappropriate content on YouTube and leverage it to perform a first of its\nkind, large scale, quantitative characterization that reveals some of the risks\nof YouTube ads consumption on inappropriate videos. Customization of the\narchitecture have also been included to serve different requirements of\ncorporations. Our analysis reveals that YouTube is still plagued by such\ndisturbing videos and its currently deployed countermeasures are ineffective in\nterms of detecting them in a timely manner. Our framework tries to fill this\ngap by providing a handy, add on solution to filter the videos and help\ncorporations and companies to push ads on the platform without worrying about\nthe content on which the ads are displayed.\n", "versions": [{"version": "v1", "created": "Mon, 11 Nov 2019 00:05:17 GMT"}, {"version": "v2", "created": "Tue, 19 Nov 2019 13:31:25 GMT"}], "update_date": "2019-11-20", "authors_parsed": [["Anand", "Vishal", ""], ["Shukla", "Ravi", ""], ["Gupta", "Ashwani", ""], ["Kumar", "Abhishek", ""]]}, {"id": "1911.04014", "submitter": "Yuval Dagan", "authors": "Yuval Dagan, Vitaly Feldman", "title": "Interaction is necessary for distributed learning with privacy or\n  communication constraints", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR cs.DS stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Local differential privacy (LDP) is a model where users send privatized data\nto an untrusted central server whose goal it to solve some data analysis task.\nIn the non-interactive version of this model the protocol consists of a single\nround in which a server sends requests to all users then receives their\nresponses. This version is deployed in industry due to its practical advantages\nand has attracted significant research interest. Our main result is an\nexponential lower bound on the number of samples necessary to solve the\nstandard task of learning a large-margin linear separator in the\nnon-interactive LDP model. Via a standard reduction this lower bound implies an\nexponential lower bound for stochastic convex optimization and specifically,\nfor learning linear models with a convex, Lipschitz and smooth loss. These\nresults answer the questions posed in \\citep{SmithTU17,DanielyF18}. Our lower\nbound relies on a new technique for constructing pairs of distributions with\nnearly matching moments but whose supports can be nearly separated by a large\nmargin hyperplane. These lower bounds also hold in the model where\ncommunication from each user is limited and follow from a lower bound on\nlearning using non-adaptive \\emph{statistical queries}.\n", "versions": [{"version": "v1", "created": "Mon, 11 Nov 2019 00:06:17 GMT"}, {"version": "v2", "created": "Wed, 23 Sep 2020 09:04:56 GMT"}], "update_date": "2020-09-24", "authors_parsed": [["Dagan", "Yuval", ""], ["Feldman", "Vitaly", ""]]}, {"id": "1911.04018", "submitter": "Yang Yang", "authors": "Yang Yang, Guillaume Sauti\\`ere, J. Jon Ryu, Taco S Cohen", "title": "Feedback Recurrent AutoEncoder", "comments": null, "journal-ref": "ICASSP 2020 - 2020 IEEE International Conference on Acoustics,\n  Speech and Signal Processing (ICASSP)", "doi": null, "report-no": null, "categories": "cs.LG cs.SD eess.AS stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this work, we propose a new recurrent autoencoder architecture, termed\nFeedback Recurrent AutoEncoder (FRAE), for online compression of sequential\ndata with temporal dependency. The recurrent structure of FRAE is designed to\nefficiently extract the redundancy along the time dimension and allows a\ncompact discrete representation of the data to be learned. We demonstrate its\neffectiveness in speech spectrogram compression. Specifically, we show that the\nFRAE, paired with a powerful neural vocoder, can produce high-quality speech\nwaveforms at a low, fixed bitrate. We further show that by adding a learned\nprior for the latent space and using an entropy coder, we can achieve an even\nlower variable bitrate.\n", "versions": [{"version": "v1", "created": "Mon, 11 Nov 2019 00:31:14 GMT"}, {"version": "v2", "created": "Mon, 17 Feb 2020 11:10:50 GMT"}], "update_date": "2020-02-18", "authors_parsed": [["Yang", "Yang", ""], ["Sauti\u00e8re", "Guillaume", ""], ["Ryu", "J. Jon", ""], ["Cohen", "Taco S", ""]]}, {"id": "1911.04021", "submitter": "Abdelrahman Hosny", "authors": "Abdelrahman Hosny, Soheil Hashemi, Mohamed Shalan and Sherief Reda", "title": "DRiLLS: Deep Reinforcement Learning for Logic Synthesis", "comments": "ASPDAC'2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Logic synthesis requires extensive tuning of the synthesis optimization flow\nwhere the quality of results (QoR) depends on the sequence of optimizations\nused. Efficient design space exploration is challenging due to the exponential\nnumber of possible optimization permutations. Therefore, automating the\noptimization process is necessary. In this work, we propose a novel\nreinforcement learning-based methodology that navigates the optimization space\nwithout human intervention. We demonstrate the training of an Advantage Actor\nCritic (A2C) agent that seeks to minimize area subject to a timing constraint.\nUsing the proposed methodology, designs can be optimized autonomously with\nno-humans in-loop. Evaluation on the comprehensive EPFL benchmark suite shows\nthat the agent outperforms existing exploration methodologies and improves QoRs\nby an average of 13%.\n", "versions": [{"version": "v1", "created": "Mon, 11 Nov 2019 00:38:39 GMT"}, {"version": "v2", "created": "Wed, 13 Nov 2019 04:07:24 GMT"}], "update_date": "2019-11-14", "authors_parsed": [["Hosny", "Abdelrahman", ""], ["Hashemi", "Soheil", ""], ["Shalan", "Mohamed", ""], ["Reda", "Sherief", ""]]}, {"id": "1911.04024", "submitter": "Swaminathan Gurumurthy", "authors": "Swaminathan Gurumurthy, Sumit Kumar, Katia Sycara", "title": "MAME : Model-Agnostic Meta-Exploration", "comments": "CoRL 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.RO stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Meta-Reinforcement learning approaches aim to develop learning procedures\nthat can adapt quickly to a distribution of tasks with the help of a few\nexamples. Developing efficient exploration strategies capable of finding the\nmost useful samples becomes critical in such settings. Existing approaches\ntowards finding efficient exploration strategies add auxiliary objectives to\npromote exploration by the pre-update policy, however, this makes the\nadaptation using a few gradient steps difficult as the pre-update (exploration)\nand post-update (exploitation) policies are often quite different. Instead, we\npropose to explicitly model a separate exploration policy for the task\ndistribution. Having two different policies gives more flexibility in training\nthe exploration policy and also makes adaptation to any specific task easier.\nWe show that using self-supervised or supervised learning objectives for\nadaptation allows for more efficient inner-loop updates and also demonstrate\nthe superior performance of our model compared to prior works in this domain.\n", "versions": [{"version": "v1", "created": "Mon, 11 Nov 2019 00:58:50 GMT"}], "update_date": "2019-11-12", "authors_parsed": [["Gurumurthy", "Swaminathan", ""], ["Kumar", "Sumit", ""], ["Sycara", "Katia", ""]]}, {"id": "1911.04047", "submitter": "Qi Qian", "authors": "Qi Qian, Juhua Hu, Hao Li", "title": "Hierarchically Robust Representation Learning", "comments": "accepted by CVPR'20", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  With the tremendous success of deep learning in visual tasks, the\nrepresentations extracted from intermediate layers of learned models, that is,\ndeep features, attract much attention of researchers. Previous empirical\nanalysis shows that those features can contain appropriate semantic\ninformation. Therefore, with a model trained on a large-scale benchmark data\nset (e.g., ImageNet), the extracted features can work well on other tasks. In\nthis work, we investigate this phenomenon and demonstrate that deep features\ncan be suboptimal due to the fact that they are learned by minimizing the\nempirical risk. When the data distribution of the target task is different from\nthat of the benchmark data set, the performance of deep features can degrade.\nHence, we propose a hierarchically robust optimization method to learn more\ngeneric features. Considering the example-level and concept-level robustness\nsimultaneously, we formulate the problem as a distributionally robust\noptimization problem with Wasserstein ambiguity set constraints, and an\nefficient algorithm with the conventional training pipeline is proposed.\nExperiments on benchmark data sets demonstrate the effectiveness of the robust\ndeep representations.\n", "versions": [{"version": "v1", "created": "Mon, 11 Nov 2019 02:51:46 GMT"}, {"version": "v2", "created": "Fri, 27 Mar 2020 18:21:02 GMT"}], "update_date": "2020-03-31", "authors_parsed": [["Qian", "Qi", ""], ["Hu", "Juhua", ""], ["Li", "Hao", ""]]}, {"id": "1911.04048", "submitter": "Rogers Silva", "authors": "Rogers F. Silva (1 and 2), Sergey M. Plis (1 and 2), Tulay Adali (3),\n  Marios S. Pattichis (4), Vince D. Calhoun (1 and 2) ((1) Tri-Institutional\n  Center for Translational Research in Neuroimaging and Data Science (TReNDS),\n  Georgia State University, Georgia Institute of Technology, and Emory\n  University, Atlanta, GA, USA, (2) The Mind Research Network, Albuquerque, NM,\n  USA, (3) Dept. of CSEE, University of Maryland Baltimore County, Baltimore,\n  Maryland, USA, (4) Dept. of ECE at The University of New Mexico, Albuquerque,\n  NM, USA)", "title": "Multidataset Independent Subspace Analysis with Application to\n  Multimodal Fusion", "comments": "For associated code, see https://github.com/rsilva8/MISA For\n  associated data, see https://github.com/rsilva8/MISA-data Submitted to IEEE\n  Transactions on Image Processing on Nov/7/2019: 13 pages, 8 figures\n  Supplement: 16 pages, 5 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG eess.IV eess.SP stat.AP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In the last two decades, unsupervised latent variable models---blind source\nseparation (BSS) especially---have enjoyed a strong reputation for the\ninterpretable features they produce. Seldom do these models combine the rich\ndiversity of information available in multiple datasets. Multidatasets, on the\nother hand, yield joint solutions otherwise unavailable in isolation, with a\npotential for pivotal insights into complex systems.\n  To take advantage of the complex multidimensional subspace structures that\ncapture underlying modes of shared and unique variability across and within\ndatasets, we present a direct, principled approach to multidataset combination.\nWe design a new method called multidataset independent subspace analysis (MISA)\nthat leverages joint information from multiple heterogeneous datasets in a\nflexible and synergistic fashion.\n  Methodological innovations exploiting the Kotz distribution for subspace\nmodeling in conjunction with a novel combinatorial optimization for evasion of\nlocal minima enable MISA to produce a robust generalization of independent\ncomponent analysis (ICA), independent vector analysis (IVA), and independent\nsubspace analysis (ISA) in a single unified model.\n  We highlight the utility of MISA for multimodal information fusion, including\nsample-poor regimes and low signal-to-noise ratio scenarios, promoting novel\napplications in both unimodal and multimodal brain imaging data.\n", "versions": [{"version": "v1", "created": "Mon, 11 Nov 2019 02:52:55 GMT"}], "update_date": "2019-11-12", "authors_parsed": [["Silva", "Rogers F.", "", "1 and 2"], ["Plis", "Sergey M.", "", "1 and 2"], ["Adali", "Tulay", "", "1 and 2"], ["Pattichis", "Marios S.", "", "1 and 2"], ["Calhoun", "Vince D.", "", "1 and 2"]]}, {"id": "1911.04052", "submitter": "Ajay Mandlekar", "authors": "Ajay Mandlekar, Jonathan Booher, Max Spero, Albert Tung, Anchit Gupta,\n  Yuke Zhu, Animesh Garg, Silvio Savarese, Li Fei-Fei", "title": "Scaling Robot Supervision to Hundreds of Hours with RoboTurk: Robotic\n  Manipulation Dataset through Human Reasoning and Dexterity", "comments": "Published at IROS 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.HC cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Large, richly annotated datasets have accelerated progress in fields such as\ncomputer vision and natural language processing, but replicating these\nsuccesses in robotics has been challenging. While prior data collection\nmethodologies such as self-supervision have resulted in large datasets, the\ndata can have poor signal-to-noise ratio. By contrast, previous efforts to\ncollect task demonstrations with humans provide better quality data, but they\ncannot reach the same data magnitude. Furthermore, neither approach places\nguarantees on the diversity of the data collected, in terms of solution\nstrategies. In this work, we leverage and extend the RoboTurk platform to scale\nup data collection for robotic manipulation using remote teleoperation. The\nprimary motivation for our platform is two-fold: (1) to address the\nshortcomings of prior work and increase the total quantity of manipulation data\ncollected through human supervision by an order of magnitude without\nsacrificing the quality of the data and (2) to collect data on challenging\nmanipulation tasks across several operators and observe a diverse set of\nemergent behaviors and solutions. We collected over 111 hours of robot\nmanipulation data across 54 users and 3 challenging manipulation tasks in 1\nweek, resulting in the largest robot dataset collected via remote\nteleoperation. We evaluate the quality of our platform, the diversity of\ndemonstrations in our dataset, and the utility of our dataset via quantitative\nand qualitative analysis. For additional results, supplementary videos, and to\ndownload our dataset, visit http://roboturk.stanford.edu/realrobotdataset .\n", "versions": [{"version": "v1", "created": "Mon, 11 Nov 2019 03:13:46 GMT"}], "update_date": "2019-11-12", "authors_parsed": [["Mandlekar", "Ajay", ""], ["Booher", "Jonathan", ""], ["Spero", "Max", ""], ["Tung", "Albert", ""], ["Gupta", "Anchit", ""], ["Zhu", "Yuke", ""], ["Garg", "Animesh", ""], ["Savarese", "Silvio", ""], ["Fei-Fei", "Li", ""]]}, {"id": "1911.04060", "submitter": "Ayush Jaiswal", "authors": "Ayush Jaiswal, Daniel Moyer, Greg Ver Steeg, Wael AbdAlmageed,\n  Premkumar Natarajan", "title": "Invariant Representations through Adversarial Forgetting", "comments": "To appear in Proceedings of the 34th AAAI Conference on Artificial\n  Intelligence (AAAI-20)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a novel approach to achieving invariance for deep neural networks\nin the form of inducing amnesia to unwanted factors of data through a new\nadversarial forgetting mechanism. We show that the forgetting mechanism serves\nas an information-bottleneck, which is manipulated by the adversarial training\nto learn invariance to unwanted factors. Empirical results show that the\nproposed framework achieves state-of-the-art performance at learning invariance\nin both nuisance and bias settings on a diverse collection of datasets and\ntasks.\n", "versions": [{"version": "v1", "created": "Mon, 11 Nov 2019 03:29:13 GMT"}, {"version": "v2", "created": "Wed, 20 Nov 2019 23:36:20 GMT"}], "update_date": "2019-11-22", "authors_parsed": [["Jaiswal", "Ayush", ""], ["Moyer", "Daniel", ""], ["Steeg", "Greg Ver", ""], ["AbdAlmageed", "Wael", ""], ["Natarajan", "Premkumar", ""]]}, {"id": "1911.04061", "submitter": "Jeremiah Zhe Liu", "authors": "Jeremiah Zhe Liu, John Paisley, Marianthi-Anna Kioumourtzoglou, Brent\n  Coull", "title": "Accurate Uncertainty Estimation and Decomposition in Ensemble Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Ensemble learning is a standard approach to building machine learning systems\nthat capture complex phenomena in real-world data. An important aspect of these\nsystems is the complete and valid quantification of model uncertainty. We\nintroduce a Bayesian nonparametric ensemble (BNE) approach that augments an\nexisting ensemble model to account for different sources of model uncertainty.\nBNE augments a model's prediction and distribution functions using Bayesian\nnonparametric machinery. It has a theoretical guarantee in that it robustly\nestimates the uncertainty patterns in the data distribution, and can decompose\nits overall predictive uncertainty into distinct components that are due to\ndifferent sources of noise and error. We show that our method achieves accurate\nuncertainty estimates under complex observational noise, and illustrate its\nreal-world utility in terms of uncertainty decomposition and model bias\ndetection for an ensemble in predict air pollution exposures in Eastern\nMassachusetts, USA.\n", "versions": [{"version": "v1", "created": "Mon, 11 Nov 2019 03:39:13 GMT"}], "update_date": "2019-11-12", "authors_parsed": [["Liu", "Jeremiah Zhe", ""], ["Paisley", "John", ""], ["Kioumourtzoglou", "Marianthi-Anna", ""], ["Coull", "Brent", ""]]}, {"id": "1911.04062", "submitter": "Junjie Liang", "authors": "Junjie Liang, Dongkuan Xu, Yiwei Sun and Vasant Honavar", "title": "LMLFM: Longitudinal Multi-Level Factorization Machine", "comments": "Thirty-Fourth AAAI Conference on Artificial Intelligence, accepted", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG stat.AP stat.ME", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the problem of learning predictive models from longitudinal data,\nconsisting of irregularly repeated, sparse observations from a set of\nindividuals over time. Such data often exhibit {\\em longitudinal correlation}\n(LC) (correlations among observations for each individual over time), {\\em\ncluster correlation} (CC) (correlations among individuals that have similar\ncharacteristics), or both. These correlations are often accounted for using\n{\\em mixed effects models} that include {\\em fixed effects} and {\\em random\neffects}, where the fixed effects capture the regression parameters that are\nshared by all individuals, whereas random effects capture those parameters that\nvary across individuals. However, the current state-of-the-art methods are\nunable to select the most predictive fixed effects and random effects from a\nlarge number of variables, while accounting for complex correlation structure\nin the data and non-linear interactions among the variables. We propose\nLongitudinal Multi-Level Factorization Machine (LMLFM), to the best of our\nknowledge, the first model to address these challenges in learning predictive\nmodels from longitudinal data. We establish the convergence properties, and\nanalyze the computational complexity, of LMLFM. We present results of\nexperiments with both simulated and real-world longitudinal data which show\nthat LMLFM outperforms the state-of-the-art methods in terms of predictive\naccuracy, variable selection ability, and scalability to data with large number\nof variables. The code and supplemental material is available at\n\\url{https://github.com/junjieliang672/LMLFM}.\n", "versions": [{"version": "v1", "created": "Mon, 11 Nov 2019 03:45:39 GMT"}, {"version": "v2", "created": "Thu, 21 Nov 2019 19:06:26 GMT"}], "update_date": "2019-11-25", "authors_parsed": [["Liang", "Junjie", ""], ["Xu", "Dongkuan", ""], ["Sun", "Yiwei", ""], ["Honavar", "Vasant", ""]]}, {"id": "1911.04069", "submitter": "Hyemin Ahn", "authors": "Hyemin Ahn, Jaehun Kim, Kihyun Kim, Songhwai Oh", "title": "Generative Autoregressive Networks for 3D Dancing Move Synthesis from\n  Music", "comments": "8 pages, 10 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.RO eess.AS stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper proposes a framework which is able to generate a sequence of\nthree-dimensional human dance poses for a given music. The proposed framework\nconsists of three components: a music feature encoder, a pose generator, and a\nmusic genre classifier. We focus on integrating these components for generating\na realistic 3D human dancing move from music, which can be applied to\nartificial agents and humanoid robots. The trained dance pose generator, which\nis a generative autoregressive model, is able to synthesize a dance sequence\nlonger than 5,000 pose frames. Experimental results of generated dance\nsequences from various songs show how the proposed method generates human-like\ndancing move to a given music. In addition, a generated 3D dance sequence is\napplied to a humanoid robot, showing that the proposed framework can make a\nrobot to dance just by listening to music.\n", "versions": [{"version": "v1", "created": "Mon, 11 Nov 2019 04:27:22 GMT"}], "update_date": "2019-11-12", "authors_parsed": [["Ahn", "Hyemin", ""], ["Kim", "Jaehun", ""], ["Kim", "Kihyun", ""], ["Oh", "Songhwai", ""]]}, {"id": "1911.04070", "submitter": "Zihao Ye", "authors": "Zihao Ye, Qipeng Guo, Quan Gan, Xipeng Qiu, Zheng Zhang", "title": "BP-Transformer: Modelling Long-Range Context via Binary Partitioning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The Transformer model is widely successful on many natural language\nprocessing tasks. However, the quadratic complexity of self-attention limit its\napplication on long text. In this paper, adopting a fine-to-coarse attention\nmechanism on multi-scale spans via binary partitioning (BP), we propose\nBP-Transformer (BPT for short). BPT yields $O(k\\cdot n\\log (n/k))$ connections\nwhere $k$ is a hyperparameter to control the density of attention. BPT has a\ngood balance between computation complexity and model capacity. A series of\nexperiments on text classification, machine translation and language modeling\nshows BPT has a superior performance for long text than previous self-attention\nmodels. Our code, hyperparameters and CUDA kernels for sparse attention are\navailable in PyTorch.\n", "versions": [{"version": "v1", "created": "Mon, 11 Nov 2019 04:31:23 GMT"}], "update_date": "2019-11-12", "authors_parsed": [["Ye", "Zihao", ""], ["Guo", "Qipeng", ""], ["Gan", "Quan", ""], ["Qiu", "Xipeng", ""], ["Zhang", "Zheng", ""]]}, {"id": "1911.04081", "submitter": "Zihan Liu", "authors": "Zihan Liu, Jamin Shin, Yan Xu, Genta Indra Winata, Peng Xu, Andrea\n  Madotto, Pascale Fung", "title": "Zero-shot Cross-lingual Dialogue Systems with Transferable Latent\n  Variables", "comments": "Accepted in EMNLP 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Despite the surging demands for multilingual task-oriented dialog systems\n(e.g., Alexa, Google Home), there has been less research done in multilingual\nor cross-lingual scenarios. Hence, we propose a zero-shot adaptation of\ntask-oriented dialogue system to low-resource languages. To tackle this\nchallenge, we first use a set of very few parallel word pairs to refine the\naligned cross-lingual word-level representations. We then employ a latent\nvariable model to cope with the variance of similar sentences across different\nlanguages, which is induced by imperfect cross-lingual alignments and inherent\ndifferences in languages. Finally, the experimental results show that even\nthough we utilize much less external resources, our model achieves better\nadaptation performance for natural language understanding task (i.e., the\nintent detection and slot filling) compared to the current state-of-the-art\nmodel in the zero-shot scenario.\n", "versions": [{"version": "v1", "created": "Mon, 11 Nov 2019 05:22:26 GMT"}], "update_date": "2019-11-12", "authors_parsed": [["Liu", "Zihan", ""], ["Shin", "Jamin", ""], ["Xu", "Yan", ""], ["Winata", "Genta Indra", ""], ["Xu", "Peng", ""], ["Madotto", "Andrea", ""], ["Fung", "Pascale", ""]]}, {"id": "1911.04092", "submitter": "Wenqian Fang", "authors": "Wenqian Fang, Lihua Fu, Meng Zhang and Zhiming Li", "title": "Seismic data interpolation based on U-net with texture loss", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "physics.geo-ph cs.LG eess.IV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Missing traces in acquired seismic data is a common occurrence during the\ncollection of seismic data. Deep neural network (DNN) has shown considerable\npromise in restoring incomplete seismic data. However, several DNN-based\napproaches ignore the specific characteristics of seismic data itself, and only\nfocus on reducing the difference between the recovered and the original\nsignals. In this study, a novel Seismic U-net InterpolaTor (SUIT) is proposed\nto preserve the seismic texture information while reconstructing the missing\ntraces. Aside from minimizing the reconstruction error, SUIT enhances the\ntexture consistency between the recovery and the original completely seismic\ndata, by designing a pre-trained U-Net to extract the texture information. The\nexperiments show that our method outperforms the classic state-of-art methods\nin terms of robustness.\n", "versions": [{"version": "v1", "created": "Mon, 11 Nov 2019 05:52:34 GMT"}], "update_date": "2019-11-12", "authors_parsed": [["Fang", "Wenqian", ""], ["Fu", "Lihua", ""], ["Zhang", "Meng", ""], ["Li", "Zhiming", ""]]}, {"id": "1911.04094", "submitter": "Xinghu Yao", "authors": "Xinghu Yao, Chao Wen, Yuhui Wang and Xiaoyang Tan", "title": "SMIX($\\lambda$): Enhancing Centralized Value Functions for Cooperative\n  Multi-Agent Reinforcement Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.MA cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Learning a stable and generalizable centralized value function (CVF) is a\ncrucial but challenging task in multi-agent reinforcement learning (MARL), as\nit has to deal with the issue that the joint action space increases\nexponentially with the number of agents in such scenarios. This paper proposes\nan approach, named SMIX(${\\lambda}$), to address the issue using an efficient\noff-policy centralized training method within a flexible learner search space.\nAs importance sampling for such off-policy training is both computationally\ncostly and numerically unstable, we proposed to use the ${\\lambda}$-return as a\nproxy to compute the TD error. With this new loss function objective, we adopt\na modified QMIX network structure as the base to train our model. By further\nconnecting it with the ${Q(\\lambda)}$ approach from an unified expectation\ncorrection viewpoint, we show that the proposed SMIX(${\\lambda}$) is equivalent\nto ${Q(\\lambda)}$ and hence shares its convergence properties, while without\nbeing suffered from the aforementioned curse of dimensionality problem inherent\nin MARL. Experiments on the StarCraft Multi-Agent Challenge (SMAC) benchmark\ndemonstrate that our approach not only outperforms several state-of-the-art\nMARL methods by a large margin, but also can be used as a general tool to\nimprove the overall performance of other CTDE-type algorithms by enhancing\ntheir CVFs.\n", "versions": [{"version": "v1", "created": "Mon, 11 Nov 2019 05:56:13 GMT"}, {"version": "v2", "created": "Tue, 12 Nov 2019 07:45:04 GMT"}, {"version": "v3", "created": "Mon, 18 Nov 2019 12:21:26 GMT"}, {"version": "v4", "created": "Wed, 13 May 2020 14:46:31 GMT"}, {"version": "v5", "created": "Sun, 9 Aug 2020 15:40:16 GMT"}], "update_date": "2020-08-11", "authors_parsed": [["Yao", "Xinghu", ""], ["Wen", "Chao", ""], ["Wang", "Yuhui", ""], ["Tan", "Xiaoyang", ""]]}, {"id": "1911.04101", "submitter": "Asma Aloufi", "authors": "Asma Aloufi, Peizhao Hu", "title": "Collaborative Homomorphic Computation on Data Encrypted under Multiple\n  Keys", "comments": "8 pages, 2 figures, In International Workshop on Privacy Engineering\n  (IWPE'19), co-located with IEEE Symposium on Security and Privacy (S&P'19)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Homomorphic encryption (HE) is a promising cryptographic technique for\nenabling secure collaborative machine learning in the cloud. However, support\nfor homomorphic computation on ciphertexts under multiple keys is inefficient.\nCurrent solutions often require key setup before any computation or incur large\nciphertext size (at best, grow linearly to the number of involved keys). In\nthis paper, we proposed a new approach that leverages threshold and multi-key\nHE to support computations on ciphertexts under different keys. Our new\napproach removes the need for key setup between each client and the set of\nmodel owners. At the same time, this approach reduces the number of encrypted\nmodels to be offloaded to the cloud evaluator, and the ciphertext size with a\ndimension reduction from (N+1)x2 to 2x2. We present the details of each step\nand discuss the complexity and security of our approach.\n", "versions": [{"version": "v1", "created": "Mon, 11 Nov 2019 06:30:52 GMT"}], "update_date": "2019-11-12", "authors_parsed": [["Aloufi", "Asma", ""], ["Hu", "Peizhao", ""]]}, {"id": "1911.04102", "submitter": "Anis Koubaa", "authors": "Anis Koubaa, Adel Ammar, Bilel Benjdira, Abdullatif Al-Hadid, Belal\n  Kawaf, Saleh Ali Al-Yahri, Abdelrahman Babiker, Koutaiba Assaf, Mohannad Ba\n  Ras", "title": "Activity Monitoring of Islamic Prayer (Salat) Postures using Deep\n  Learning", "comments": "Submitted to the 6th International Conference on Data Science and\n  Machine Learning Applications (CDMA 2020)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.CY cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  In the Muslim community, the prayer (i.e. Salat) is the second pillar of\nIslam, and it is the most essential and fundamental worshiping activity that\nbelievers have to perform five times a day. From a gestures' perspective, there\nare predefined human postures that must be performed in a precise manner.\nHowever, for several people, these postures are not correctly performed, due to\nbeing new to Salat or even having learned prayers in an incorrect manner.\nFurthermore, the time spent in each posture has to be balanced. To address\nthese issues, we propose to develop an artificial intelligence assistive\nframework that guides worshippers to evaluate the correctness of the postures\nof their prayers. This paper represents the first step to achieve this\nobjective and addresses the problem of the recognition of the basic gestures of\nIslamic prayer using Convolutional Neural Networks (CNN). The contribution of\nthis paper lies in building a dataset for the basic Salat positions, and train\na YOLOv3 neural network for the recognition of the gestures. Experimental\nresults demonstrate that the mean average precision attains 85% for a training\ndataset of 764 images of the different postures. To the best of our knowledge,\nthis is the first work that addresses human activity recognition of Salat using\ndeep learning.\n", "versions": [{"version": "v1", "created": "Mon, 11 Nov 2019 06:31:40 GMT"}], "update_date": "2019-11-12", "authors_parsed": [["Koubaa", "Anis", ""], ["Ammar", "Adel", ""], ["Benjdira", "Bilel", ""], ["Al-Hadid", "Abdullatif", ""], ["Kawaf", "Belal", ""], ["Al-Yahri", "Saleh Ali", ""], ["Babiker", "Abdelrahman", ""], ["Assaf", "Koutaiba", ""], ["Ras", "Mohannad Ba", ""]]}, {"id": "1911.04107", "submitter": "Gang Chen", "authors": "Gang Chen, Dingcheng Li and Ran Xu", "title": "Context-aware Active Multi-Step Reinforcement Learning", "comments": "9 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Reinforcement learning has attracted great attention recently, especially\npolicy gradient algorithms, which have been demonstrated on challenging\ndecision making and control tasks. In this paper, we propose an active\nmulti-step TD algorithm with adaptive stepsizes to learn actor and critic.\nSpecifically, our model consists of two components: active stepsize learning\nand adaptive multi-step TD algorithm. Firstly, we divide the time horizon into\nchunks and actively select state and action inside each chunk. Then given the\nselected samples, we propose the adaptive multi-step TD, which generalizes\nTD($\\lambda$), but adaptively switch on/off the backups from future returns of\ndifferent steps. Particularly, the adaptive multi-step TD introduces a\ncontext-aware mechanism, here a binary classifier, which decides whether or not\nto turn on its future backups based on the context changes. Thus, our model is\nkind of combination of active learning and multi-step TD algorithm, which has\nthe capacity for learning off-policy without the need of importance sampling.\nWe evaluate our approach on both discrete and continuous space tasks in an\noff-policy setting respectively, and demonstrate competitive results compared\nto other reinforcement learning baselines.\n", "versions": [{"version": "v1", "created": "Mon, 11 Nov 2019 06:37:47 GMT"}, {"version": "v2", "created": "Wed, 27 Nov 2019 06:47:54 GMT"}], "update_date": "2019-11-28", "authors_parsed": [["Chen", "Gang", ""], ["Li", "Dingcheng", ""], ["Xu", "Ran", ""]]}, {"id": "1911.04120", "submitter": "Emir Konuk Konuk", "authors": "Emir Konuk, Kevin Smith", "title": "An empirical study of the relation between network architecture and\n  complexity", "comments": "Accepted to ICCV 2019 Preregistration Workshop", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this preregistration submission, we propose an empirical study of how\nnetworks handle changes in complexity of the data. We investigate the effect of\nnetwork capacity on generalization performance in the face of increasing data\ncomplexity. For this, we measure the generalization error for an image\nclassification task where the number of classes steadily increases. We compare\na number of modern architectures at different scales in this setting. The\nmethodology, setup, and hypotheses described in this proposal were evaluated by\npeer review before experiments were conducted.\n", "versions": [{"version": "v1", "created": "Mon, 11 Nov 2019 07:45:01 GMT"}], "update_date": "2019-11-12", "authors_parsed": [["Konuk", "Emir", ""], ["Smith", "Kevin", ""]]}, {"id": "1911.04129", "submitter": "Songtao Liu", "authors": "Songtao Liu, Lingwei Chen, Hanze Dong, Zihao Wang, Dinghao Wu,\n  Zengfeng Huang", "title": "Higher-order Weighted Graph Convolutional Networks", "comments": "15 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Graph Convolution Network (GCN) has been recognized as one of the most\neffective graph models for semi-supervised learning, but it extracts merely the\nfirst-order or few-order neighborhood information through information\npropagation, which suffers performance drop-off for deeper structure. Existing\napproaches that deal with the higher-order neighbors tend to take advantage of\nadjacency matrix power. In this paper, we assume a seemly trivial condition\nthat the higher-order neighborhood information may be similar to that of the\nfirst-order neighbors. Accordingly, we present an unsupervised approach to\ndescribe such similarities and learn the weight matrices of higher-order\nneighbors automatically through Lasso that minimizes the feature loss between\nthe first-order and higher-order neighbors, based on which we formulate the new\nconvolutional filter for GCN to learn the better node representations. Our\nmodel, called higher-order weighted GCN(HWGCN), has achieved the\nstate-of-the-art results on a number of node classification tasks over Cora,\nCiteseer and Pubmed datasets.\n", "versions": [{"version": "v1", "created": "Mon, 11 Nov 2019 08:20:56 GMT"}, {"version": "v2", "created": "Tue, 12 Nov 2019 03:10:03 GMT"}], "update_date": "2019-11-13", "authors_parsed": [["Liu", "Songtao", ""], ["Chen", "Lingwei", ""], ["Dong", "Hanze", ""], ["Wang", "Zihao", ""], ["Wu", "Dinghao", ""], ["Huang", "Zengfeng", ""]]}, {"id": "1911.04143", "submitter": "Ziqiang Cheng", "authors": "Ziqiang Cheng, Yang Yang, Wei Wang, Wenjie Hu, Yueting Zhuang, Guojie\n  Song", "title": "Time2Graph: Revisiting Time Series Modeling with Dynamic Shapelets", "comments": "An extended version with 11 pages including appendix; Accepted by\n  AAAI'2020", "journal-ref": null, "doi": "10.1609/aaai.v34i04.5769", "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Time series modeling has attracted extensive research efforts; however,\nachieving both reliable efficiency and interpretability from a unified model\nstill remains a challenging problem. Among the literature, shapelets offer\ninterpretable and explanatory insights in the classification tasks, while most\nexisting works ignore the differing representative power at different time\nslices, as well as (more importantly) the evolution pattern of shapelets. In\nthis paper, we propose to extract time-aware shapelets by designing a two-level\ntiming factor. Moreover, we define and construct the shapelet evolution graph,\nwhich captures how shapelets evolve over time and can be incorporated into the\ntime series embeddings by graph embedding algorithms. To validate whether the\nrepresentations obtained in this way can be applied effectively in various\nscenarios, we conduct experiments based on three public time series datasets,\nand two real-world datasets from different domains. Experimental results\nclearly show the improvements achieved by our approach compared with 17\nstate-of-the-art baselines.\n", "versions": [{"version": "v1", "created": "Mon, 11 Nov 2019 08:55:55 GMT"}, {"version": "v2", "created": "Mon, 30 Nov 2020 12:28:11 GMT"}], "update_date": "2020-12-01", "authors_parsed": [["Cheng", "Ziqiang", ""], ["Yang", "Yang", ""], ["Wang", "Wei", ""], ["Hu", "Wenjie", ""], ["Zhuang", "Yueting", ""], ["Song", "Guojie", ""]]}, {"id": "1911.04172", "submitter": "Shubham Gupta", "authors": "Shubham Gupta, Gururaj K., Ambedkar Dukkipati, Rui M. Castro", "title": "Equipping SBMs with RBMs: An Explainable Approach for Analysis of\n  Networks with Covariates", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Networks with node covariates offer two advantages to community detection\nmethods, namely, (i) exploit covariates to improve the quality of communities,\nand more importantly, (ii) explain the discovered communities by identifying\nthe relative importance of different covariates in them. Recent methods have\nalmost exclusively focused on the first point above. However, the quantitative\nimprovements offered by them are often due to complex black-box models like\ndeep neural networks at the expense of explainability. Approaches that focus on\nthe second point are either domain-specific or have poor performance in\npractice. This paper proposes explainable, domain-independent statistical\nmodels for networks with node covariates that additionally offer good\nquantitative performance. Our models combine the strengths of Stochastic Block\nModels and Restricted Boltzmann Machines to provide interpretable insights\nabout the communities. They support both pure and mixed community memberships.\nBesides providing explainability, our approach's main strength is that it does\nnot explicitly assume a causal direction between community memberships and node\ncovariates, making it applicable in diverse domains. We derive efficient\ninference procedures for our models, which can, in some cases, run in linear\ntime in the number of nodes and edges. Experiments on several synthetic and\nreal-world networks demonstrate that our models achieve close to\nstate-of-the-art performance on community detection and link prediction tasks\nwhile also providing explanations for the discovered communities.\n", "versions": [{"version": "v1", "created": "Mon, 11 Nov 2019 10:50:19 GMT"}, {"version": "v2", "created": "Mon, 5 Apr 2021 22:32:40 GMT"}], "update_date": "2021-04-07", "authors_parsed": [["Gupta", "Shubham", ""], ["K.", "Gururaj", ""], ["Dukkipati", "Ambedkar", ""], ["Castro", "Rui M.", ""]]}, {"id": "1911.04174", "submitter": "Hiroshi Kera", "authors": "Hiroshi Kera, Yoshihiko Hasegawa", "title": "Gradient Boosts the Approximate Vanishing Ideal", "comments": "9+10 pages, 1+4 figures, AAAI'20", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In the last decade, the approximate vanishing ideal and its basis\nconstruction algorithms have been extensively studied in computer algebra and\nmachine learning as a general model to reconstruct the algebraic variety on\nwhich noisy data approximately lie. In particular, the basis construction\nalgorithms developed in machine learning are widely used in applications across\nmany fields because of their monomial-order-free property; however, they lose\nmany of the theoretical properties of computer-algebraic algorithms. In this\npaper, we propose general methods that equip monomial-order-free algorithms\nwith several advantageous theoretical properties. Specifically, we exploit the\ngradient to (i) sidestep the spurious vanishing problem in polynomial time to\nremove symbolically trivial redundant bases, (ii) achieve consistent output\nwith respect to the translation and scaling of input, and (iii) remove\nnontrivially redundant bases. The proposed methods work in a fully numerical\nmanner, whereas existing algorithms require the awkward monomial order or\nexponentially costly (and mostly symbolic) computation to realize properties\n(i) and (iii). To our knowledge, property (ii) has not been achieved by any\nexisting basis construction algorithm of the approximate vanishing ideal.\n", "versions": [{"version": "v1", "created": "Mon, 11 Nov 2019 10:52:38 GMT"}], "update_date": "2019-11-12", "authors_parsed": [["Kera", "Hiroshi", ""], ["Hasegawa", "Yoshihiko", ""]]}, {"id": "1911.04175", "submitter": "Praveen Palanisamy", "authors": "Praveen Palanisamy", "title": "Multi-Agent Connected Autonomous Driving using Deep Reinforcement\n  Learning", "comments": "Accepted, Machine Learning for Autonomous Driving Workshop at the\n  33rd Conference on Neural Information Processing Systems(NeurIPS 2019)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.MA cs.RO stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The capability to learn and adapt to changes in the driving environment is\ncrucial for developing autonomous driving systems that are scalable beyond\ngeo-fenced operational design domains. Deep Reinforcement Learning (RL)\nprovides a promising and scalable framework for developing adaptive learning\nbased solutions. Deep RL methods usually model the problem as a (Partially\nObservable) Markov Decision Process in which an agent acts in a stationary\nenvironment to learn an optimal behavior policy. However, driving involves\ncomplex interaction between multiple, intelligent (artificial or human) agents\nin a highly non-stationary environment. In this paper, we propose the use of\nPartially Observable Markov Games(POSG) for formulating the connected\nautonomous driving problems with realistic assumptions. We provide a taxonomy\nof multi-agent learning environments based on the nature of tasks, nature of\nagents and the nature of the environment to help in categorizing various\nautonomous driving problems that can be addressed under the proposed\nformulation. As our main contributions, we provide MACAD-Gym, a Multi-Agent\nConnected, Autonomous Driving agent learning platform for furthering research\nin this direction. Our MACAD-Gym platform provides an extensible set of\nConnected Autonomous Driving (CAD) simulation environments that enable the\nresearch and development of Deep RL- based integrated sensing, perception,\nplanning and control algorithms for CAD systems with unlimited operational\ndesign domain under realistic, multi-agent settings. We also share the\nMACAD-Agents that were trained successfully using the MACAD-Gym platform to\nlearn control policies for multiple vehicle agents in a partially observable,\nstop-sign controlled, 3-way urban intersection environment with raw (camera)\nsensor observations.\n", "versions": [{"version": "v1", "created": "Mon, 11 Nov 2019 10:55:25 GMT"}], "update_date": "2019-11-12", "authors_parsed": [["Palanisamy", "Praveen", ""]]}, {"id": "1911.04180", "submitter": "M. Alex O. Vasilescu", "authors": "M. Alex O. Vasilescu and Eric Kim", "title": "Compositional Hierarchical Tensor Factorization: Representing\n  Hierarchical Intrinsic and Extrinsic Causal Factors", "comments": "VERS 2: Fixed out of sync ref. Added\n  [7,14,15,28,37,50,52,53,61,77,78] M.A.O. Vasilescu and E.Kim. Compositional\n  Hierarchical Tensor Factorization: Representing Hierarchical Intrinsic and\n  Extrinsic Causal Factors. In 25th ACM SIGKDD Conference on Knowledge\n  Discovery and Data Mining (KDD'19): Tensor Methods for Emerging Data Science\n  Challenges, August 04-08, 2019, Anchorage, AK.ACM, New York, NY", "journal-ref": "25th ACM SIGKDD Conference on Knowledge Discovery and Data Mining\n  (KDD'19): Tensor Methods for Emerging Data Science Challenges Workshop,\n  August 04-08, 2019, Anchorage, AK.ACM, New York, NY", "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.LG math.DG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Visual objects are composed of a recursive hierarchy of perceptual wholes and\nparts, whose properties, such as shape, reflectance, and color, constitute a\nhierarchy of intrinsic causal factors of object appearance. However, object\nappearance is the compositional consequence of both an object's intrinsic and\nextrinsic causal factors, where the extrinsic causal factors are related to\nillumination, and imaging conditions. Therefore, this paper proposes a unified\ntensor model of wholes and parts, and introduces a compositional hierarchical\ntensor factorization that disentangles the hierarchical causal structure of\nobject image formation, and subsumes multilinear block tensor decomposition as\na special case. The resulting object representation is an interpretable\ncombinatorial choice of wholes' and parts' representations that renders object\nrecognition robust to occlusion and reduces training data requirements. We\ndemonstrate ourapproach in the context of face recognition by training on an\nextremely reduced dataset of synthetic images, and report encouragingface\nverification results on two datasets - the Freiburg dataset, andthe Labeled\nFace in the Wild (LFW) dataset consisting of real world images, thus,\nsubstantiating the suitability of our approach for data starved domains.\n", "versions": [{"version": "v1", "created": "Mon, 11 Nov 2019 11:03:53 GMT"}, {"version": "v2", "created": "Wed, 1 Jan 2020 06:23:19 GMT"}], "update_date": "2021-03-01", "authors_parsed": [["Vasilescu", "M. Alex O.", ""], ["Kim", "Eric", ""]]}, {"id": "1911.04206", "submitter": "Qinbin Li", "authors": "Qinbin Li, Zeyi Wen, Bingsheng He", "title": "Practical Federated Gradient Boosting Decision Trees", "comments": "Accepted to AAAI-20", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Gradient Boosting Decision Trees (GBDTs) have become very successful in\nrecent years, with many awards in machine learning and data mining\ncompetitions. There have been several recent studies on how to train GBDTs in\nthe federated learning setting. In this paper, we focus on horizontal federated\nlearning, where data samples with the same features are distributed among\nmultiple parties. However, existing studies are not efficient or effective\nenough for practical use. They suffer either from the inefficiency due to the\nusage of costly data transformations such as secret sharing and homomorphic\nencryption, or from the low model accuracy due to differential privacy designs.\nIn this paper, we study a practical federated environment with relaxed privacy\nconstraints. In this environment, a dishonest party might obtain some\ninformation about the other parties' data, but it is still impossible for the\ndishonest party to derive the actual raw data of other parties. Specifically,\neach party boosts a number of trees by exploiting similarity information based\non locality-sensitive hashing. We prove that our framework is secure without\nexposing the original record to other parties, while the computation overhead\nin the training process is kept low. Our experimental studies show that,\ncompared with normal training with the local data of each party, our approach\ncan significantly improve the predictive accuracy, and achieve comparable\naccuracy to the original GBDT with the data from all parties.\n", "versions": [{"version": "v1", "created": "Mon, 11 Nov 2019 12:15:23 GMT"}, {"version": "v2", "created": "Fri, 13 Dec 2019 09:15:43 GMT"}], "update_date": "2019-12-16", "authors_parsed": [["Li", "Qinbin", ""], ["Wen", "Zeyi", ""], ["He", "Bingsheng", ""]]}, {"id": "1911.04207", "submitter": "Ling Pan", "authors": "Ling Pan, Qingpeng Cai, Longbo Huang", "title": "Multi-Path Policy Optimization", "comments": "AAMAS-2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent years have witnessed a tremendous improvement of deep reinforcement\nlearning. However, a challenging problem is that an agent may suffer from\ninefficient exploration, particularly for on-policy methods. Previous\nexploration methods either rely on complex structure to estimate the novelty of\nstates, or incur sensitive hyper-parameters causing instability. We propose an\nefficient exploration method, Multi-Path Policy Optimization (MPPO), which does\nnot incur high computation cost and ensures stability. MPPO maintains an\nefficient mechanism that effectively utilizes a population of diverse policies\nto enable better exploration, especially in sparse environments. We also give a\ntheoretical guarantee of the stable performance. We build our scheme upon two\nwidely-adopted on-policy methods, the Trust-Region Policy Optimization\nalgorithm and Proximal Policy Optimization algorithm. We conduct extensive\nexperiments on several MuJoCo tasks and their sparsified variants to fairly\nevaluate the proposed method. Results show that MPPO significantly outperforms\nstate-of-the-art exploration methods in terms of both sample efficiency and\nfinal performance.\n", "versions": [{"version": "v1", "created": "Mon, 11 Nov 2019 12:19:23 GMT"}, {"version": "v2", "created": "Fri, 22 Nov 2019 06:34:06 GMT"}, {"version": "v3", "created": "Fri, 14 Feb 2020 15:17:23 GMT"}], "update_date": "2020-02-17", "authors_parsed": [["Pan", "Ling", ""], ["Cai", "Qingpeng", ""], ["Huang", "Longbo", ""]]}, {"id": "1911.04209", "submitter": "Qinbin Li", "authors": "Qinbin Li, Zhaomin Wu, Zeyi Wen, Bingsheng He", "title": "Privacy-Preserving Gradient Boosting Decision Trees", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The Gradient Boosting Decision Tree (GBDT) is a popular machine learning\nmodel for various tasks in recent years. In this paper, we study how to improve\nmodel accuracy of GBDT while preserving the strong guarantee of differential\nprivacy. Sensitivity and privacy budget are two key design aspects for the\neffectiveness of differential private models. Existing solutions for GBDT with\ndifferential privacy suffer from the significant accuracy loss due to too loose\nsensitivity bounds and ineffective privacy budget allocations (especially\nacross different trees in the GBDT model). Loose sensitivity bounds lead to\nmore noise to obtain a fixed privacy level. Ineffective privacy budget\nallocations worsen the accuracy loss especially when the number of trees is\nlarge. Therefore, we propose a new GBDT training algorithm that achieves\ntighter sensitivity bounds and more effective noise allocations. Specifically,\nby investigating the property of gradient and the contribution of each tree in\nGBDTs, we propose to adaptively control the gradients of training data for each\niteration and leaf node clipping in order to tighten the sensitivity bounds.\nFurthermore, we design a novel boosting framework to allocate the privacy\nbudget between trees so that the accuracy loss can be further reduced. Our\nexperiments show that our approach can achieve much better model accuracy than\nother baselines.\n", "versions": [{"version": "v1", "created": "Mon, 11 Nov 2019 12:20:24 GMT"}, {"version": "v2", "created": "Wed, 11 Dec 2019 16:24:01 GMT"}, {"version": "v3", "created": "Thu, 29 Oct 2020 02:38:31 GMT"}, {"version": "v4", "created": "Tue, 16 Mar 2021 06:25:41 GMT"}], "update_date": "2021-03-17", "authors_parsed": [["Li", "Qinbin", ""], ["Wu", "Zhaomin", ""], ["Wen", "Zeyi", ""], ["He", "Bingsheng", ""]]}, {"id": "1911.04220", "submitter": "Xiangyuan Zhang", "authors": "Xiangyuan Zhang, Kaiqing Zhang, Erik Miehling, Tamer Ba\\c{s}ar", "title": "Non-Cooperative Inverse Reinforcement Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.GT cs.AI cs.LG cs.SY eess.SY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Making decisions in the presence of a strategic opponent requires one to take\ninto account the opponent's ability to actively mask its intended objective. To\ndescribe such strategic situations, we introduce the non-cooperative inverse\nreinforcement learning (N-CIRL) formalism. The N-CIRL formalism consists of two\nagents with completely misaligned objectives, where only one of the agents\nknows the true objective function. Formally, we model the N-CIRL formalism as a\nzero-sum Markov game with one-sided incomplete information. Through interacting\nwith the more informed player, the less informed player attempts to both infer,\nand act according to, the true objective function. As a result of the one-sided\nincomplete information, the multi-stage game can be decomposed into a sequence\nof single-stage games expressed by a recursive formula. Solving this recursive\nformula yields the value of the N-CIRL game and the more informed player's\nequilibrium strategy. Another recursive formula, constructed by forming an\nauxiliary game, termed the dual game, yields the less informed player's\nstrategy. Building upon these two recursive formulas, we develop a\ncomputationally tractable algorithm to approximately solve for the equilibrium\nstrategies. Finally, we demonstrate the benefits of our N-CIRL formalism over\nthe existing multi-agent IRL formalism via extensive numerical simulation in a\nnovel cyber security setting.\n", "versions": [{"version": "v1", "created": "Sun, 3 Nov 2019 16:59:57 GMT"}, {"version": "v2", "created": "Mon, 6 Jan 2020 08:56:59 GMT"}], "update_date": "2020-01-07", "authors_parsed": [["Zhang", "Xiangyuan", ""], ["Zhang", "Kaiqing", ""], ["Miehling", "Erik", ""], ["Ba\u015far", "Tamer", ""]]}, {"id": "1911.04221", "submitter": "Tuyen Truong", "authors": "Tuyen Trung Truong", "title": "Convergence to minima for the continuous version of Backtracking\n  Gradient Descent", "comments": "20 pages. Definition 1.2 is revised to ensure that Armijo's condition\n  is satisfied. A part iv is added to Theorem 1.3. For readers' convenience,\n  two lemmas are added to help make proofs easy to follow. Typos corrected,\n  exposition revised", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.OC cs.LG cs.NA math.NA stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The main result of this paper is:\n  {\\bf Theorem.} Let $f:\\mathbb{R}^k\\rightarrow \\mathbb{R}$ be a $C^{1}$\nfunction, so that $\\nabla f$ is locally Lipschitz continuous. Assume moreover\nthat $f$ is $C^2$ near its generalised saddle points. Fix real numbers\n$\\delta_0>0$ and $0<\\alpha <1$. Then there is a smooth function\n$h:\\mathbb{R}^k\\rightarrow (0,\\delta_0]$ so that the map\n$H:\\mathbb{R}^k\\rightarrow \\mathbb{R}^k$ defined by $H(x)=x-h(x)\\nabla f(x)$\nhas the following property:\n  (i) For all $x\\in \\mathbb{R}^k$, we have $f(H(x)))-f(x)\\leq -\\alpha\nh(x)||\\nabla f(x)||^2$.\n  (ii) For every $x_0\\in \\mathbb{R}^k$, the sequence $x_{n+1}=H(x_n)$ either\nsatisfies $\\lim_{n\\rightarrow\\infty}||x_{n+1}-x_n||=0$ or $\n\\lim_{n\\rightarrow\\infty}||x_n||=\\infty$. Each cluster point of $\\{x_n\\}$ is a\ncritical point of $f$. If moreover $f$ has at most countably many critical\npoints, then $\\{x_n\\}$ either converges to a critical point of $f$ or\n$\\lim_{n\\rightarrow\\infty}||x_n||=\\infty$.\n  (iii) There is a set $\\mathcal{E}_1\\subset \\mathbb{R}^k$ of Lebesgue measure\n$0$ so that for all $x_0\\in \\mathbb{R}^k\\backslash \\mathcal{E}_1$, the sequence\n$x_{n+1}=H(x_n)$, {\\bf if converges}, cannot converge to a {\\bf generalised}\nsaddle point.\n  (iv) There is a set $\\mathcal{E}_2\\subset \\mathbb{R}^k$ of Lebesgue measure\n$0$ so that for all $x_0\\in \\mathbb{R}^k\\backslash \\mathcal{E}_2$, any cluster\npoint of the sequence $x_{n+1}=H(x_n)$ is not a saddle point, and more\ngenerally cannot be an isolated generalised saddle point.\n  Some other results are proven.\n", "versions": [{"version": "v1", "created": "Mon, 11 Nov 2019 12:58:21 GMT"}, {"version": "v2", "created": "Wed, 13 Nov 2019 12:54:04 GMT"}], "update_date": "2019-11-14", "authors_parsed": [["Truong", "Tuyen Trung", ""]]}, {"id": "1911.04225", "submitter": "Adarsh Barik", "authors": "Adarsh Barik and Jean Honorio", "title": "Provable Computational and Statistical Guarantees for Efficient Learning\n  of Continuous-Action Graphical Games", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.GT cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we study the problem of learning the set of pure strategy Nash\nequilibria and the exact structure of a continuous-action graphical game with\nquadratic payoffs by observing a small set of perturbed equilibria. A\ncontinuous-action graphical game can possibly have an uncountable set of Nash\neuqilibria. We propose a $\\ell_{12}-$ block regularized method which recovers a\ngraphical game, whose Nash equilibria are the $\\epsilon$-Nash equilibria of the\ngame from which the data was generated (true game). Under a slightly stringent\ncondition on the parameters of the true game, our method recovers the exact\nstructure of the graphical game. Our method has a logarithmic sample complexity\nwith respect to the number of players. It also runs in polynomial time.\n", "versions": [{"version": "v1", "created": "Fri, 8 Nov 2019 16:49:32 GMT"}], "update_date": "2019-11-12", "authors_parsed": [["Barik", "Adarsh", ""], ["Honorio", "Jean", ""]]}, {"id": "1911.04226", "submitter": "Takao Murakami", "authors": "Takao Murakami, Koki Hamada, Yusuke Kawamoto, Takuma Hatano", "title": "Privacy-Preserving Multiple Tensor Factorization for Synthesizing\n  Large-Scale Location Traces with Cluster-Specific Features", "comments": "This is a full version of the paper accepted at PETS 2021 (The 21st\n  Privacy Enhancing Technologies Symposium)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.DB cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  With the widespread use of LBSs (Location-based Services), synthesizing\nlocation traces plays an increasingly important role in analyzing spatial big\ndata while protecting user privacy. In particular, a synthetic trace that\npreserves a feature specific to a cluster of users (e.g., those who commute by\ntrain, those who go shopping) is important for various geo-data analysis tasks\nand for providing a synthetic location dataset. Although location synthesizers\nhave been widely studied, existing synthesizers do not provide sufficient\nutility, privacy, or scalability, hence are not practical for large-scale\nlocation traces. To overcome this issue, we propose a novel location\nsynthesizer called PPMTF (Privacy-Preserving Multiple Tensor Factorization). We\nmodel various statistical features of the original traces by a transition-count\ntensor and a visit-count tensor. We factorize these two tensors simultaneously\nvia multiple tensor factorization, and train factor matrices via posterior\nsampling. Then we synthesize traces from reconstructed tensors, and perform a\nplausible deniability test for a synthetic trace. We comprehensively evaluate\nPPMTF using two datasets. Our experimental results show that PPMTF preserves\nvarious statistical features including cluster-specific features, protects user\nprivacy, and synthesizes large-scale location traces in practical time. PPMTF\nalso significantly outperforms the state-of-the-art methods in terms of utility\nand scalability at the same level of privacy.\n", "versions": [{"version": "v1", "created": "Mon, 11 Nov 2019 13:08:30 GMT"}, {"version": "v2", "created": "Fri, 15 Nov 2019 13:43:03 GMT"}, {"version": "v3", "created": "Sat, 21 Dec 2019 05:48:29 GMT"}, {"version": "v4", "created": "Thu, 27 Feb 2020 19:27:56 GMT"}, {"version": "v5", "created": "Mon, 2 Mar 2020 23:49:57 GMT"}, {"version": "v6", "created": "Sun, 31 May 2020 18:49:35 GMT"}, {"version": "v7", "created": "Thu, 19 Nov 2020 01:02:55 GMT"}], "update_date": "2020-11-20", "authors_parsed": [["Murakami", "Takao", ""], ["Hamada", "Koki", ""], ["Kawamoto", "Yusuke", ""], ["Hatano", "Takuma", ""]]}, {"id": "1911.04227", "submitter": "Valentina Zantedeschi Dr", "authors": "Valentina Zantedeschi, Fabrizio Falasca, Alyson Douglas, Richard\n  Strange, Matt J. Kusner, Duncan Watson-Parris", "title": "Cumulo: A Dataset for Learning Cloud Classes", "comments": null, "journal-ref": "Tackling Climate Change with Machine Learning Workshop, 33rd\n  Conference on Neural Information Processing Systems (NeurIPS 2019),\n  Vancouver, Canada", "doi": null, "report-no": null, "categories": "physics.ao-ph cs.CV cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  One of the greatest sources of uncertainty in future climate projections\ncomes from limitations in modelling clouds and in understanding how different\ncloud types interact with the climate system. A key first step in reducing this\nuncertainty is to accurately classify cloud types at high spatial and temporal\nresolution. In this paper, we introduce Cumulo, a benchmark dataset for\ntraining and evaluating global cloud classification models. It consists of one\nyear of 1km resolution MODIS hyperspectral imagery merged with pixel-width\n'tracks' of CloudSat cloud labels. Bringing these complementary datasets\ntogether is a crucial first step, enabling the Machine-Learning community to\ndevelop innovative new techniques which could greatly benefit the Climate\ncommunity. To showcase Cumulo, we provide baseline performance analysis using\nan invertible flow generative model (IResNet), which further allows us to\ndiscover new sub-classes for a given cloud class by exploring the latent space.\nTo compare methods, we introduce a set of evaluation criteria, to identify\nmodels that are not only accurate, but also physically-realistic. CUMULO can be\ndownload from\nhttps://www.dropbox.com/sh/6gca7f0mb3b0ikz/AADq2lk4u7k961Qa31FwIDEpa?dl=0 .\n", "versions": [{"version": "v1", "created": "Tue, 5 Nov 2019 09:36:16 GMT"}, {"version": "v2", "created": "Tue, 14 Apr 2020 10:01:33 GMT"}], "update_date": "2020-04-15", "authors_parsed": [["Zantedeschi", "Valentina", ""], ["Falasca", "Fabrizio", ""], ["Douglas", "Alyson", ""], ["Strange", "Richard", ""], ["Kusner", "Matt J.", ""], ["Watson-Parris", "Duncan", ""]]}, {"id": "1911.04239", "submitter": "Ahmet M. Elbir", "authors": "Ahmet M. Elbir and Anastasios Papazafeiropoulos", "title": "Hybrid Precoding for Multi-User Millimeter Wave Massive MIMO Systems: A\n  Deep Learning Approach", "comments": "Accepted paper in IEEE Transactions on Vehicular Technology, Oct 2019", "journal-ref": null, "doi": "10.1109/TVT.2019.2951501", "report-no": null, "categories": "eess.SP cs.IT cs.LG math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In multi-user millimeter wave (mmWave) multiple-input-multiple-output (MIMO)\nsystems, hybrid precoding is a crucial task to lower the complexity and cost\nwhile achieving a sufficient sum-rate. Previous works on hybrid precoding were\nusually based on optimization or greedy approaches. These methods either\nprovide higher complexity or have sub-optimum performance. Moreover, the\nperformance of these methods mostly relies on the quality of the channel data.\nIn this work, we propose a deep learning (DL) framework to improve the\nperformance and provide less computation time as compared to conventional\ntechniques. In fact, we design a convolutional neural network for MIMO\n(CNN-MIMO) that accepts as input an imperfect channel matrix and gives the\nanalog precoder and combiners at the output. The procedure includes two main\nstages. First, we develop an exhaustive search algorithm to select the analog\nprecoder and combiners from a predefined codebook maximizing the achievable\nsum-rate. Then, the selected precoder and combiners are used as output labels\nin the training stage of CNN-MIMO where the input-output pairs are obtained. We\nevaluate the performance of the proposed method through numerous and extensive\nsimulations and show that the proposed DL framework outperforms conventional\ntechniques. Overall, CNN-MIMO provides a robust hybrid precoding scheme in the\npresence of imperfections regarding the channel matrix. On top of this, the\nproposed approach exhibits less computation time with comparison to the\noptimization and codebook based approaches.\n", "versions": [{"version": "v1", "created": "Mon, 11 Nov 2019 13:19:50 GMT"}], "update_date": "2020-04-28", "authors_parsed": [["Elbir", "Ahmet M.", ""], ["Papazafeiropoulos", "Anastasios", ""]]}, {"id": "1911.04240", "submitter": "Nikhil Muralidhar", "authors": "Nikhil Muralidhar, Jie Bu, Ze Cao, Long He, Naren Ramakrishnan, Danesh\n  Tafti, Anuj Karpatne", "title": "Physics-guided Design and Learning of Neural Networks for Predicting\n  Drag Force on Particle Suspensions in Moving Fluids", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG physics.comp-ph stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Physics-based simulations are often used to model and understand complex\nphysical systems and processes in domains like fluid dynamics. Such\nsimulations, although used frequently, have many limitations which could arise\neither due to the inability to accurately model a physical process owing to\nincomplete knowledge about certain facets of the process or due to the\nunderlying process being too complex to accurately encode into a simulation\nmodel. In such situations, it is often useful to rely on machine learning\nmethods to fill in the gap by learning a model of the complex physical process\ndirectly from simulation data. However, as data generation through simulations\nis costly, we need to develop models, being cognizant of data paucity issues.\nIn such scenarios it is often helpful if the rich physical knowledge of the\napplication domain is incorporated in the architectural design of machine\nlearning models. Further, we can also use information from physics-based\nsimulations to guide the learning process using aggregate supervision to\nfavorably constrain the learning process. In this paper, we propose PhyDNN, a\ndeep learning model using physics-guided structural priors and physics-guided\naggregate supervision for modeling the drag forces acting on each particle in a\nComputational Fluid Dynamics-Discrete Element Method(CFD-DEM). We conduct\nextensive experiments in the context of drag force prediction and showcase the\nusefulness of including physics knowledge in our deep learning formulation both\nin the design and through learning process. Our proposed PhyDNN model has been\ncompared to several state-of-the-art models and achieves a significant\nperformance improvement of 8.46% on average across all baseline models. The\nsource code has been made available and the dataset used is detailed in [1, 2].\n", "versions": [{"version": "v1", "created": "Wed, 6 Nov 2019 00:05:37 GMT"}], "update_date": "2019-11-12", "authors_parsed": [["Muralidhar", "Nikhil", ""], ["Bu", "Jie", ""], ["Cao", "Ze", ""], ["He", "Long", ""], ["Ramakrishnan", "Naren", ""], ["Tafti", "Danesh", ""], ["Karpatne", "Anuj", ""]]}, {"id": "1911.04244", "submitter": "Franyell Silfa", "authors": "Franyell Silfa, Jose-Maria Arnau, Antonio Gonz\\`alez", "title": "Boosting LSTM Performance Through Dynamic Precision Selection", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.SP cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The use of low numerical precision is a fundamental optimization included in\nmodern accelerators for Deep Neural Networks (DNNs). The number of bits of the\nnumerical representation is set to the minimum precision that is able to retain\naccuracy based on an offline profiling, and it is kept constant for DNN\ninference.\n  In this work, we explore the use of dynamic precision selection during DNN\ninference. We focus on Long Short Term Memory (LSTM) networks, which represent\nthe state-of-the-art networks for applications such as machine translation and\nspeech recognition. Unlike conventional DNNs, LSTM networks remember\ninformation from previous evaluations by storing data in the LSTM cell state.\nOur key observation is that the cell state determines the amount of precision\nrequired: time steps where the cell state changes significantly require higher\nprecision, whereas time steps where the cell state is stable can be computed\nwith lower precision without any loss in accuracy.\n  Based on this observation, we implement a novel hardware scheme that tracks\nthe evolution of the elements in the LSTM cell state and dynamically selects\nthe appropriate precision in each time step. For a set of popular LSTM\nnetworks, our scheme selects the lowest precision for more than 66% of the\ntime, outperforming systems that fix the precision statically. We evaluate our\nproposal on top of a modern accelerator highly optimized for LSTM computation,\nand show that it provides 1.56x speedup and 23% energy savings on average\nwithout any loss in accuracy. The extra hardware to determine the appropriate\nprecision represents a small area overhead of 8.8%.\n", "versions": [{"version": "v1", "created": "Thu, 7 Nov 2019 13:39:53 GMT"}], "update_date": "2019-11-12", "authors_parsed": [["Silfa", "Franyell", ""], ["Arnau", "Jose-Maria", ""], ["Gonz\u00e0lez", "Antonio", ""]]}, {"id": "1911.04250", "submitter": "Suvodeep Majumder", "authors": "Suvodeep Majumder, Rahul Krishna and Tim Menzies", "title": "Learning GENERAL Principles from Hundreds of Software Projects", "comments": "34 pages, 9 figures, 3 Tables Empirical Software Engineering (EMSE)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SE cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Managers and practitioners become dubious about software analytics when its\nconclusions keep changing as we look at new projects. GENERAL is a new approach\nfor quickly finding conclusions that generalize across hundreds of projects.\nThis algorithm (a) removes spurious attributes via feature selection; (b) fixes\ntraining data imbalance via synthetic instances; (c) recursively clusters the\nproject data; (d) finds the best model within any cluster, then promotes it up\nthe cluster tree; (e) returns the model promoted to the top. GENERAL is much\nfaster than prior methods (4.8 hours versus 204 hours our case studies) and\ntheoretically scales better (O(N^2/m) versus O(N^2), which is a large reduction\nsince often we find m>20 clusters).\n  When tested on 756 Github projects, a single defect prediction model\ngeneralized over all those projects while also being useful and insightful and\ngeneralizable; i.e. that model worked just as well as 756 separate models\nlearned from each project; and that model succinctly show what key factors most\ncontributed to defects. Hence, when exploring hundreds of projects, we endorse\nGENERAL reasoning.\n", "versions": [{"version": "v1", "created": "Wed, 6 Nov 2019 19:20:37 GMT"}, {"version": "v2", "created": "Tue, 13 Oct 2020 13:49:57 GMT"}], "update_date": "2020-10-14", "authors_parsed": [["Majumder", "Suvodeep", ""], ["Krishna", "Rahul", ""], ["Menzies", "Tim", ""]]}, {"id": "1911.04252", "submitter": "Qizhe Xie", "authors": "Qizhe Xie, Minh-Thang Luong, Eduard Hovy, Quoc V. Le", "title": "Self-training with Noisy Student improves ImageNet classification", "comments": "CVPR 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present Noisy Student Training, a semi-supervised learning approach that\nworks well even when labeled data is abundant. Noisy Student Training achieves\n88.4% top-1 accuracy on ImageNet, which is 2.0% better than the\nstate-of-the-art model that requires 3.5B weakly labeled Instagram images. On\nrobustness test sets, it improves ImageNet-A top-1 accuracy from 61.0% to\n83.7%, reduces ImageNet-C mean corruption error from 45.7 to 28.3, and reduces\nImageNet-P mean flip rate from 27.8 to 12.2.\n  Noisy Student Training extends the idea of self-training and distillation\nwith the use of equal-or-larger student models and noise added to the student\nduring learning. On ImageNet, we first train an EfficientNet model on labeled\nimages and use it as a teacher to generate pseudo labels for 300M unlabeled\nimages. We then train a larger EfficientNet as a student model on the\ncombination of labeled and pseudo labeled images. We iterate this process by\nputting back the student as the teacher. During the learning of the student, we\ninject noise such as dropout, stochastic depth, and data augmentation via\nRandAugment to the student so that the student generalizes better than the\nteacher. Models are available at\nhttps://github.com/tensorflow/tpu/tree/master/models/official/efficientnet.\nCode is available at https://github.com/google-research/noisystudent.\n", "versions": [{"version": "v1", "created": "Mon, 11 Nov 2019 18:59:27 GMT"}, {"version": "v2", "created": "Tue, 7 Jan 2020 07:07:57 GMT"}, {"version": "v3", "created": "Tue, 28 Apr 2020 22:27:37 GMT"}, {"version": "v4", "created": "Fri, 19 Jun 2020 17:36:57 GMT"}], "update_date": "2020-06-22", "authors_parsed": [["Xie", "Qizhe", ""], ["Luong", "Minh-Thang", ""], ["Hovy", "Eduard", ""], ["Le", "Quoc V.", ""]]}, {"id": "1911.04255", "submitter": "Abhiram Singh", "authors": "Abhiram Singh, Ashwin Gumaste", "title": "Decoding Imagined Speech and Computer Control using Brain Waves", "comments": "Published in the Journal of Neuroscience Methods", "journal-ref": "Journal of Neuroscience Methods, Volume 358, 1 July 2021, 109196", "doi": "10.1016/j.jneumeth.2021.109196", "report-no": null, "categories": "eess.SP cs.HC cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this work, we explore the possibility of decoding Imagined Speech brain\nwaves using machine learning techniques. We propose a covariance matrix of\nElectroencephalogram channels as input features, projection to tangent space of\ncovariance matrices for obtaining vectors from covariance matrices, principal\ncomponent analysis for dimension reduction of vectors, an artificial\nfeed-forward neural network as a classification model and bootstrap aggregation\nfor creating an ensemble of neural network models. After the classification,\ntwo different Finite State Machines are designed that create an interface for\ncontrolling a computer system using an Imagined Speech-based BCI system. The\nproposed approach is able to decode the Imagined Speech signal with a maximum\nmean classification accuracy of 85% on binary classification task of one long\nword and a short word. We also show that our proposed approach is able to\ndifferentiate between imagined speech brain signals and rest state brain\nsignals with maximum mean classification accuracy of 94%. We compared our\nproposed method with other approaches for decoding imagined speech and show\nthat our approach performs equivalent to the state of the art approach on\ndecoding long vs. short words and outperforms it significantly on the other two\ntasks of decoding three short words and three vowels with an average margin of\n11% and 9%, respectively. We also obtain an information transfer rate of\n21-bits-per-minute when using an IS based system to operate a computer. These\nresults show that the proposed approach is able to decode a wide variety of\nimagined speech signals without any human-designed features.\n", "versions": [{"version": "v1", "created": "Fri, 8 Nov 2019 12:18:36 GMT"}, {"version": "v2", "created": "Sat, 14 Dec 2019 11:41:29 GMT"}, {"version": "v3", "created": "Tue, 24 Nov 2020 13:13:21 GMT"}, {"version": "v4", "created": "Fri, 30 Apr 2021 05:42:49 GMT"}], "update_date": "2021-05-03", "authors_parsed": [["Singh", "Abhiram", ""], ["Gumaste", "Ashwin", ""]]}, {"id": "1911.04278", "submitter": "Giulio Zizzo", "authors": "Giulio Zizzo, Chris Hankin, Sergio Maffeis, Kevin Jones", "title": "Intrusion Detection for Industrial Control Systems: Evaluation Analysis\n  and Adversarial Attacks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Neural networks are increasingly used in security applications for intrusion\ndetection on industrial control systems. In this work we examine two areas that\nmust be considered for their effective use. Firstly, is their vulnerability to\nadversarial attacks when used in a time series setting. Secondly, is potential\nover-estimation of performance arising from data leakage artefacts.\n  To investigate these areas we implement a long short-term memory (LSTM) based\nintrusion detection system (IDS) which effectively detects cyber-physical\nattacks on a water treatment testbed representing a strong baseline IDS.\n  For investigating adversarial attacks we model two different white box\nattackers. The first attacker is able to manipulate sensor readings on a subset\nof the Secure Water Treatment (SWaT) system. By creating a stream of\nadversarial data the attacker is able to hide the cyber-physical attacks from\nthe IDS. For the cyber-physical attacks which are detected by the IDS, the\nattacker required on average 2.48 out of 12 total sensors to be compromised for\nthe cyber-physical attacks to be hidden from the IDS. The second attacker model\nwe explore is an $L_{\\infty}$ bounded attacker who can send fake readings to\nthe IDS, but to remain imperceptible, limits their perturbations to the\nsmallest $L_{\\infty}$ value needed.\n  Additionally, we examine data leakage problems arising from tuning for $F_1$\nscore on the whole SWaT attack set and propose a method to tune detection\nparameters that does not utilise any attack data. If attack after-effects are\naccounted for then our new parameter tuning method achieved an $F_1$ score of\n0.811$\\pm$0.0103.\n", "versions": [{"version": "v1", "created": "Fri, 8 Nov 2019 17:27:33 GMT"}], "update_date": "2019-11-12", "authors_parsed": [["Zizzo", "Giulio", ""], ["Hankin", "Chris", ""], ["Maffeis", "Sergio", ""], ["Jones", "Kevin", ""]]}, {"id": "1911.04279", "submitter": "Joaquim Dias Garcia", "authors": "Raphael Araujo Sampaio, Gerson Couto Oliveira, Luiz Carlos da Costa\n  Jr. and Joaquim Dias Garcia", "title": "Community Detection for Power Systems Network Aggregation Considering\n  Renewable Variability", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "physics.soc-ph cs.LG cs.SY eess.SY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The increasing penetration of variable renewable energy (VRE) has brought\nsignificant challenges for power systems planning and operation. These highly\nvariable sources are typically distributed in the grid; therefore, a detailed\nrepresentation of transmission bottlenecks is fundamental to approximate the\nimpact of the transmission network on the dispatch with VRE resources. The fine\ngrain temporal scale of short term and day-ahead dispatch, taking into account\nthe network constraints, also mandatory for mid-term planning studies, combined\nwith the high variability of the VRE has brought the need to represent these\nuncertainties in stochastic optimization models while taking into account the\ntransmission system. These requirements impose a computational burden to solve\nthe planning and operation models. We propose a methodology based on community\ndetection to aggregate the network representation, capable of preserving the\nlocational marginal price (LMP) differences in multiple VRE scenarios, and\ndescribe a real-world operational planning study. The optimal expected cost\nsolution considering aggregated networks is compared with the full network\nrepresentation. Both representations were embedded in an operation model\nrelying on Stochastic Dual Dynamic Programming (SDDP) to deal with the random\nvariables in a multi-stage problem.\n", "versions": [{"version": "v1", "created": "Fri, 8 Nov 2019 18:53:24 GMT"}], "update_date": "2019-11-12", "authors_parsed": [["Sampaio", "Raphael Araujo", ""], ["Oliveira", "Gerson Couto", ""], ["Costa", "Luiz Carlos da", "Jr."], ["Garcia", "Joaquim Dias", ""]]}, {"id": "1911.04283", "submitter": "Sathish Indurthi", "authors": "Sathish Indurthi, Houjeung Han, Nikhil Kumar Lakumarapu, Beomseok Lee,\n  Insoo Chung, Sangha Kim, Chanwoo Kim", "title": "Data Efficient Direct Speech-to-Text Translation with Modality Agnostic\n  Meta-Learning", "comments": "ICASSP 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG cs.SD eess.AS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  End-to-end Speech Translation (ST) models have several advantages such as\nlower latency, smaller model size, and less error compounding over conventional\npipelines that combine Automatic Speech Recognition (ASR) and text Machine\nTranslation (MT) models. However, collecting large amounts of parallel data for\nST task is more difficult compared to the ASR and MT tasks. Previous studies\nhave proposed the use of transfer learning approaches to overcome the above\ndifficulty. These approaches benefit from weakly supervised training data, such\nas ASR speech-to-transcript or MT text-to-text translation pairs. However, the\nparameters in these models are updated independently of each task, which may\nlead to sub-optimal solutions. In this work, we adopt a meta-learning algorithm\nto train a modality agnostic multi-task model that transfers knowledge from\nsource tasks=ASR+MT to target task=ST where ST task severely lacks data. In the\nmeta-learning phase, the parameters of the model are exposed to vast amounts of\nspeech transcripts (e.g., English ASR) and text translations (e.g.,\nEnglish-German MT). During this phase, parameters are updated in such a way to\nunderstand speech, text representations, the relation between them, as well as\nact as a good initialization point for the target ST task. We evaluate the\nproposed meta-learning approach for ST tasks on English-German (En-De) and\nEnglish-French (En-Fr) language pairs from the Multilingual Speech Translation\nCorpus (MuST-C). Our method outperforms the previous transfer learning\napproaches and sets new state-of-the-art results for En-De and En-Fr ST tasks\nby obtaining 9.18, and 11.76 BLEU point improvements, respectively.\n", "versions": [{"version": "v1", "created": "Mon, 11 Nov 2019 14:03:52 GMT"}, {"version": "v2", "created": "Tue, 28 Apr 2020 03:33:56 GMT"}], "update_date": "2020-04-29", "authors_parsed": [["Indurthi", "Sathish", ""], ["Han", "Houjeung", ""], ["Lakumarapu", "Nikhil Kumar", ""], ["Lee", "Beomseok", ""], ["Chung", "Insoo", ""], ["Kim", "Sangha", ""], ["Kim", "Chanwoo", ""]]}, {"id": "1911.04285", "submitter": "Patrick Flaherty", "authors": "Patrick Flaherty, Pitchaya Wiratchotisatian, Ji Ah Lee, Zhou Tang,\n  Andrew C. Trapp", "title": "MAP Clustering under the Gaussian Mixture Model via Mixed Integer\n  Nonlinear Optimization", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG math.OC stat.ME", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a global optimization approach for solving the maximum\na-posteriori (MAP) clustering problem under the Gaussian mixture model.Our\napproach can accommodate side constraints and it preserves the combinatorial\nstructure of the MAP clustering problem by formulating it asa mixed-integer\nnonlinear optimization problem (MINLP). We approximate the MINLP through a\nmixed-integer quadratic program (MIQP) transformation that improves\ncomputational aspects while guaranteeing $\\epsilon$-global optimality. An\nimportant benefit of our approach is the explicit quantification of the degree\nof suboptimality, via the optimality gap, en route to finding the globally\noptimal MAP clustering. Numerical experiments comparing our method to other\napproaches show that our method finds a better solution than standard\nclustering methods. Finally, we cluster a real breast cancer gene expression\ndata set incorporating intrinsic subtype information; the induced constraints\nsubstantially improve the computational performance and produce more coherent\nand bio-logically meaningful clusters.\n", "versions": [{"version": "v1", "created": "Fri, 8 Nov 2019 15:53:26 GMT"}, {"version": "v2", "created": "Tue, 17 Mar 2020 02:51:11 GMT"}], "update_date": "2020-03-18", "authors_parsed": [["Flaherty", "Patrick", ""], ["Wiratchotisatian", "Pitchaya", ""], ["Lee", "Ji Ah", ""], ["Tang", "Zhou", ""], ["Trapp", "Andrew C.", ""]]}, {"id": "1911.04286", "submitter": "Guy Rotman", "authors": "Guy Rotman and Roi Reichart", "title": "Deep Contextualized Self-training for Low Resource Dependency Parsing", "comments": "Accepted to TACL in September 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Neural dependency parsing has proven very effective, achieving\nstate-of-the-art results on numerous domains and languages. Unfortunately, it\nrequires large amounts of labeled data, that is costly and laborious to create.\nIn this paper we propose a self-training algorithm that alleviates this\nannotation bottleneck by training a parser on its own output. Our Deep\nContextualized Self-training (DCST) algorithm utilizes representation models\ntrained on sequence labeling tasks that are derived from the parser's output\nwhen applied to unlabeled data, and integrates these models with the base\nparser through a gating mechanism. We conduct experiments across multiple\nlanguages, both in low resource in-domain and in cross-domain setups, and\ndemonstrate that DCST substantially outperforms traditional self-training as\nwell as recent semi-supervised training methods.\n", "versions": [{"version": "v1", "created": "Mon, 11 Nov 2019 14:07:46 GMT"}], "update_date": "2019-11-12", "authors_parsed": [["Rotman", "Guy", ""], ["Reichart", "Roi", ""]]}, {"id": "1911.04289", "submitter": "Maria Ines Meyer", "authors": "Maria Ines Meyer and Ezequiel de la Rosa and Koen Van Leemput and\n  Diana M. Sima", "title": "Relevance Vector Machines for harmonization of MRI brain volumes using\n  image descriptors", "comments": "9 pages, 4 figures. Presented at the International Workshop on\n  Machine Learning in Clinical Neuroimaging (MLCN) 2019", "journal-ref": "OR 2.0 Context-Aware Operating Theaters and Machine Learning in\n  Clinical Neuroimaging. OR 2.0 2019, MLCN 2019. Lecture Notes in Computer\n  Science, vol 11796. Springer, Cham", "doi": "10.1007/978-3-030-32695-1_9", "report-no": null, "categories": "eess.IV cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  With the increased need for multi-center magnetic resonance imaging studies,\nproblems arise related to differences in hardware and software between centers.\nNamely, current algorithms for brain volume quantification are unreliable for\nthe longitudinal assessment of volume changes in this type of setting.\nCurrently most methods attempt to decrease this issue by regressing the\nscanner- and/or center-effects from the original data. In this work, we explore\na novel approach to harmonize brain volume measurements by using only image\ndescriptors. First, we explore the relationships between volumes and image\ndescriptors. Then, we train a Relevance Vector Machine (RVM) model over a large\nmulti-site dataset of healthy subjects to perform volume harmonization.\nFinally, we validate the method over two different datasets: i) a subset of\nunseen healthy controls; and ii) a test-retest dataset of multiple sclerosis\n(MS) patients. The method decreases scanner and center variability while\npreserving measurements that did not require correction in MS patient data. We\nshow that image descriptors can be used as input to a machine learning\nalgorithm to improve the reliability of longitudinal volumetric studies.\n", "versions": [{"version": "v1", "created": "Fri, 8 Nov 2019 14:37:14 GMT"}], "update_date": "2019-11-12", "authors_parsed": [["Meyer", "Maria Ines", ""], ["de la Rosa", "Ezequiel", ""], ["Van Leemput", "Koen", ""], ["Sima", "Diana M.", ""]]}, {"id": "1911.04291", "submitter": "Matthias Mehlhose", "authors": "Matthias Mehlhose, Daniyal Amir Awany, Renato L. G. Cavalcante, Martin\n  Kurras and Slawomir Stanczak", "title": "Machine Learning-Based Adaptive Receive Filtering: Proof-of-Concept on\n  an SDR Platform", "comments": "submitted to ICC 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.SP cs.IT cs.LG math.IT stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Conventional multiuser detection techniques either require a large number of\nantennas at the receiver for a desired performance, or they are too complex for\npractical implementation. Moreover, many of these techniques, such as\nsuccessive interference cancellation (SIC), suffer from errors in parameter\nestimation (user channels, covariance matrix, noise variance, etc.) that is\nperformed before detection of user data symbols. As an alternative to\nconventional methods, this paper proposes and demonstrates a low-complexity\npractical Machine Learning (ML) based receiver that achieves similar (and at\ntimes better) performance to the SIC receiver. The proposed receiver does not\nrequire parameter estimation; instead it uses supervised learning to detect the\nuser modulation symbols directly. We perform comparisons with minimum mean\nsquare error (MMSE) and SIC receivers in terms of symbol error rate (SER) and\ncomplexity.\n", "versions": [{"version": "v1", "created": "Mon, 11 Nov 2019 14:10:44 GMT"}], "update_date": "2019-11-12", "authors_parsed": [["Mehlhose", "Matthias", ""], ["Awany", "Daniyal Amir", ""], ["Cavalcante", "Renato L. G.", ""], ["Kurras", "Martin", ""], ["Stanczak", "Slawomir", ""]]}, {"id": "1911.04292", "submitter": "Jia Xu Dr.", "authors": "Abdul Rafae Khan and Jia Xu", "title": "Diversity by Phonetics and its Application in Neural Machine Translation", "comments": "In openreview.net (28 May 2019)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG cs.SD eess.AS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce a powerful approach for Neural Machine Translation (NMT),\nwhereby, during training and testing, together with the input we provide its\nphonetic encoding and the variants of such an encoding. This way we obtain very\nsignificant improvements up to 4 BLEU points over the state-of-the-art\nlarge-scale system. The phonetic encoding is the first part of our\ncontribution, with a second being a theory that aims to understand the reason\nfor this improvement. Our hypothesis states that the phonetic encoding helps\nNMT because it encodes a procedure to emphasize the difference between\nsemantically diverse sentences. We conduct an empirical geometric validation of\nour hypothesis in support of which we obtain overwhelming evidence.\nSubsequently, as our third contribution and based on our theory, we develop\nartificial mechanisms that leverage during learning the hypothesized (and\nverified) effect phonetics. We achieve significant and consistent improvements\noverall language pairs and datasets: French-English, German-English, and\nChinese-English in medium task IWSLT'17 and French-English in large task WMT'18\nBio, with up to 4 BLEU points over the state-of-the-art. Moreover, our\napproaches are more robust than baselines when evaluated on unknown\nout-of-domain test sets with up to a 5 BLEU point increase.\n", "versions": [{"version": "v1", "created": "Mon, 11 Nov 2019 14:11:21 GMT"}], "update_date": "2019-11-12", "authors_parsed": [["Khan", "Abdul Rafae", ""], ["Xu", "Jia", ""]]}, {"id": "1911.04293", "submitter": "Ting Tao", "authors": "Ting Tao, Shaohua Pan and Shujun Bi", "title": "Error bound of critical points and KL property of exponent $1/2$ for\n  squared F-norm regularized factorization", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.OC cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper is concerned with the squared F(robenius)-norm regularized\nfactorization form for noisy low-rank matrix recovery problems. Under a\nsuitable assumption on the restricted condition number of the Hessian for the\nloss function, we derive an error bound to the true matrix for the non-strict\ncritical points with rank not more than that of the true matrix. Then, for the\nsquared F-norm regularized factorized least squares loss function, under the\nnoisy and full sample setting we establish its KL property of exponent $1/2$ on\nits global minimizer set, and under the noisy and partial sample setting\nachieve this property for a class of critical points. These theoretical\nfindings are also confirmed by solving the squared F-norm regularized\nfactorization problem with an accelerated alternating minimization method.\n", "versions": [{"version": "v1", "created": "Mon, 11 Nov 2019 14:14:13 GMT"}, {"version": "v2", "created": "Sat, 26 Jun 2021 13:15:55 GMT"}], "update_date": "2021-06-29", "authors_parsed": [["Tao", "Ting", ""], ["Pan", "Shaohua", ""], ["Bi", "Shujun", ""]]}, {"id": "1911.04301", "submitter": "Antonia Marcu", "authors": "Antonia Marcu and Adam Pr\\\"ugel-Bennett", "title": "Rethinking Generalisation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  In this paper, a new approach to computing the generalisation performance is\npresented that assumes the distribution of risks, $\\rho(r)$, for a learning\nscenario is known. From this, the expected error of a learning machine using\nempirical risk minimisation is computed for both classification and regression\nproblems. A critical quantity in determining the generalisation performance is\nthe power-law behaviour of $\\rho(r)$ around its minimum value---a quantity we\ncall attunement. The distribution $\\rho(r)$ is computed for the case of all\nBoolean functions and for the perceptron used in two different problem\nsettings. Initially a simplified analysis is presented where an independence\nassumption about the losses is made. A more accurate analysis is carried out\ntaking into account chance correlations in the training set. This leads to\ncorrections in the typical behaviour that is observed.\n", "versions": [{"version": "v1", "created": "Mon, 11 Nov 2019 14:25:50 GMT"}, {"version": "v2", "created": "Thu, 26 Mar 2020 15:03:06 GMT"}], "update_date": "2020-03-27", "authors_parsed": [["Marcu", "Antonia", ""], ["Pr\u00fcgel-Bennett", "Adam", ""]]}, {"id": "1911.04307", "submitter": "Douglas Leith", "authors": "Daron Anderson and Douglas J. Leith", "title": "Learning The Best Expert Efficiently", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider online learning problems where the aim is to achieve regret which\nis efficient in the sense that it is the same order as the lowest regret\namongst K experts. This is a substantially stronger requirement that achieving\n$O(\\sqrt{n})$ or $O(\\log n)$ regret with respect to the best expert and\nstandard algorithms are insufficient, even in easy cases where the regrets of\nthe available actions are very different from one another. We show that a\nparticular lazy form of the online subgradient algorithm can be used to achieve\nminimal regret in a number of \"easy\" regimes while retaining an $O(\\sqrt{n})$\nworst-case regret guarantee. We also show that for certain classes of problem\nminimal regret strategies exist for some of the remaining \"hard\" regimes.\n", "versions": [{"version": "v1", "created": "Mon, 11 Nov 2019 14:40:04 GMT"}], "update_date": "2019-11-12", "authors_parsed": [["Anderson", "Daron", ""], ["Leith", "Douglas J.", ""]]}, {"id": "1911.04317", "submitter": "Aravind Sampathkumar", "authors": "Jiayi He, Aravind Sampath Kumar, Arun Chada, Bhyrav Mutnury, James\n  Drewniak", "title": "Machine Learning for high speed channel optimization", "comments": "3 Pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.OT cs.LG eess.SP stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Design of printed circuit board (PCB) stack-up requires the consideration of\ncharacteristic impedance, insertion loss and crosstalk. As there are many\nparameters in a PCB stack-up design, the optimization of these parameters needs\nto be efficient and accurate. A less optimal stack-up would lead to expensive\nPCB material choices in high speed designs. In this paper, an efficient global\noptimization method using parallel and intelligent Bayesian optimization is\nproposed for the stripline design.\n", "versions": [{"version": "v1", "created": "Fri, 1 Nov 2019 23:46:26 GMT"}], "update_date": "2019-11-12", "authors_parsed": [["He", "Jiayi", ""], ["Kumar", "Aravind Sampath", ""], ["Chada", "Arun", ""], ["Mutnury", "Bhyrav", ""], ["Drewniak", "James", ""]]}, {"id": "1911.04322", "submitter": "Zhu Li", "authors": "Zhu Li, Adrian Perez-Suay, Gustau Camps-Valls, Dino Sejdinovic", "title": "Kernel Dependence Regularizers and Gaussian Processes with Applications\n  to Algorithmic Fairness", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Current adoption of machine learning in industrial, societal and economical\nactivities has raised concerns about the fairness, equity and ethics of\nautomated decisions. Predictive models are often developed using biased\ndatasets and thus retain or even exacerbate biases in their decisions and\nrecommendations. Removing the sensitive covariates, such as gender or race, is\ninsufficient to remedy this issue since the biases may be retained due to other\nrelated covariates. We present a regularization approach to this problem that\ntrades off predictive accuracy of the learned models (with respect to biased\nlabels) for the fairness in terms of statistical parity, i.e. independence of\nthe decisions from the sensitive covariates. In particular, we consider a\ngeneral framework of regularized empirical risk minimization over reproducing\nkernel Hilbert spaces and impose an additional regularizer of dependence\nbetween predictors and sensitive covariates using kernel-based measures of\ndependence, namely the Hilbert-Schmidt Independence Criterion (HSIC) and its\nnormalized version. This approach leads to a closed-form solution in the case\nof squared loss, i.e. ridge regression. Moreover, we show that the dependence\nregularizer has an interpretation as modifying the corresponding Gaussian\nprocess (GP) prior. As a consequence, a GP model with a prior that encourages\nfairness to sensitive variables can be derived, allowing principled\nhyperparameter selection and studying of the relative relevance of covariates\nunder fairness constraints. Experimental results in synthetic examples and in\nreal problems of income and crime prediction illustrate the potential of the\napproach to improve fairness of automated decisions.\n", "versions": [{"version": "v1", "created": "Mon, 11 Nov 2019 15:09:32 GMT"}], "update_date": "2019-11-12", "authors_parsed": [["Li", "Zhu", ""], ["Perez-Suay", "Adrian", ""], ["Camps-Valls", "Gustau", ""], ["Sejdinovic", "Dino", ""]]}, {"id": "1911.04335", "submitter": "Fabian Horst", "authors": "Johannes Burdack, Fabian Horst, Sven Giesselbach, Ibrahim Hassan,\n  Sabrina Daffner, Wolfgang I. Sch\\\"ollhorn", "title": "Systematic Comparison of the Influence of Different Data Preprocessing\n  Methods on the Performance of Gait Classifications Using Machine Learning", "comments": "12 pages, 3 figures, 4 tables", "journal-ref": "Front. Bioeng. Biotechnol. 8 (2020) 260", "doi": "10.3389/fbioe.2020.00260", "report-no": null, "categories": "cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Human movements are characterized by highly non-linear and multi-dimensional\ninteractions within the motor system. Recently, an increasing emphasis on\nmachine-learning applications has led to a significant contribution to the\nfield of gait analysis, e.g., in increasing the classification performance. In\norder to ensure the generalizability of the machine-learning models, different\ndata preprocessing steps are usually carried out to process the measured raw\ndata before the classifications. In the past, various methods have been used\nfor each of these preprocessing steps. However, there are hardly any standard\nprocedures or rather systematic comparisons of these different methods and\ntheir impact on the classification performance. Therefore, the aim of this\nanalysis is to compare different combinations of commonly applied data\npreprocessing steps and test their effects on the classification performance of\ngait patterns. A publicly available dataset on intra-individual changes of gait\npatterns was used for this analysis. Forty-two healthy participants performed 6\nsessions of 15 gait trials for 1 day. For each trial, two force plates recorded\nthe 3D ground reaction forces (GRFs). The data was preprocessed with the\nfollowing steps: GRF filtering, time derivative, time normalization, data\nreduction, weight normalization and data scaling. Subsequently, combinations of\nall methods from each preprocessing step were analyzed by comparing their\nprediction performance in a six-session classification using Support Vector\nMachines, Random Forest Classifiers, Multi-Layer Perceptrons, and Convolutional\nNeural Networks. In conclusion, the present results provide first\ndomain-specific recommendations for commonly applied data preprocessing methods\nand might help to build more comparable and more robust classification models\nbased on machine learning that are suitable for a practical application.\n", "versions": [{"version": "v1", "created": "Mon, 11 Nov 2019 15:27:40 GMT"}, {"version": "v2", "created": "Thu, 30 Jul 2020 15:15:00 GMT"}], "update_date": "2020-07-31", "authors_parsed": [["Burdack", "Johannes", ""], ["Horst", "Fabian", ""], ["Giesselbach", "Sven", ""], ["Hassan", "Ibrahim", ""], ["Daffner", "Sabrina", ""], ["Sch\u00f6llhorn", "Wolfgang I.", ""]]}, {"id": "1911.04336", "submitter": "Dylan Slack", "authors": "Dylan Slack, Sorelle Friedler, Emile Givental", "title": "Fair Meta-Learning: Learning How to Learn Fairly", "comments": "arXiv admin note: substantial text overlap with arXiv:1908.09092", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Data sets for fairness relevant tasks can lack examples or be biased\naccording to a specific label in a sensitive attribute. We demonstrate the\nusefulness of weight based meta-learning approaches in such situations. For\nmodels that can be trained through gradient descent, we demonstrate that there\nare some parameter configurations that allow models to be optimized from a few\nnumber of gradient steps and with minimal data which are both fair and\naccurate. To learn such weight sets, we adapt the popular MAML algorithm to\nFair-MAML by the inclusion of a fairness regularization term. In practice,\nFair-MAML allows practitioners to train fair machine learning models from only\na few examples when data from related tasks is available. We empirically\nexhibit the value of this technique by comparing to relevant baselines.\n", "versions": [{"version": "v1", "created": "Wed, 6 Nov 2019 21:43:53 GMT"}], "update_date": "2019-11-12", "authors_parsed": [["Slack", "Dylan", ""], ["Friedler", "Sorelle", ""], ["Givental", "Emile", ""]]}, {"id": "1911.04338", "submitter": "Dongrui Wu", "authors": "Xue Jiang and Xiao Zhang and Dongrui Wu", "title": "Active Learning for Black-Box Adversarial Attacks in EEG-Based\n  Brain-Computer Interfaces", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR cs.HC eess.SP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep learning has made significant breakthroughs in many fields, including\nelectroencephalogram (EEG) based brain-computer interfaces (BCIs). However,\ndeep learning models are vulnerable to adversarial attacks, in which\ndeliberately designed small perturbations are added to the benign input samples\nto fool the deep learning model and degrade its performance. This paper\nconsiders transferability-based black-box attacks, where the attacker trains a\nsubstitute model to approximate the target model, and then generates\nadversarial examples from the substitute model to attack the target model.\nLearning a good substitute model is critical to the success of these attacks,\nbut it requires a large number of queries to the target model. We propose a\nnovel framework which uses query synthesis based active learning to improve the\nquery efficiency in training the substitute model. Experiments on three\nconvolutional neural network (CNN) classifiers and three EEG datasets\ndemonstrated that our method can improve the attack success rate with the same\nnumber of queries, or, in other words, our method requires fewer queries to\nachieve a desired attack performance. To our knowledge, this is the first work\nthat integrates active learning and adversarial attacks for EEG-based BCIs.\n", "versions": [{"version": "v1", "created": "Thu, 7 Nov 2019 15:00:24 GMT"}], "update_date": "2019-11-12", "authors_parsed": [["Jiang", "Xue", ""], ["Zhang", "Xiao", ""], ["Wu", "Dongrui", ""]]}, {"id": "1911.04351", "submitter": "Talha Cihad Gulcu", "authors": "Talha Cihad Gulcu", "title": "Stronger Convergence Results for Deep Residual Networks: Network Width\n  Scales Linearly with Training Data Size", "comments": "33 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep neural networks are highly expressive machine learning models with the\nability to interpolate arbitrary datasets. Deep nets are typically optimized\nvia first-order methods and the optimization process crucially depends on the\ncharacteristics of the network as well as the dataset. This work sheds light on\nthe relation between the network size and the properties of the dataset with an\nemphasis on deep residual networks (ResNets). Our contribution is that if the\nnetwork Jacobian is full rank, gradient descent for the quadratic loss and\nsmooth activation converges to the global minima even if the network width $m$\nof the ResNet scales linearly with the sample size $n$, and independently from\nthe network depth. To the best of our knowledge, this is the first work which\nprovides a theoretical guarantee for the convergence of neural networks in the\n$m=\\Omega(n)$ regime.\n", "versions": [{"version": "v1", "created": "Mon, 11 Nov 2019 15:50:11 GMT"}], "update_date": "2019-11-12", "authors_parsed": [["Gulcu", "Talha Cihad", ""]]}, {"id": "1911.04357", "submitter": "Steven Guan", "authors": "Steven Guan, Amir A. Khan, Siddhartha Sikdar, Parag V. Chitnis", "title": "Limited View and Sparse Photoacoustic Tomography for Neuroimaging with\n  Deep Learning", "comments": null, "journal-ref": "Sci Rep 10, 8510 (2020)", "doi": "10.1038/s41598-020-65235-2", "report-no": null, "categories": "eess.IV cs.CV cs.LG physics.med-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Photoacoustic tomography (PAT) is a nonionizing imaging modality capable of\nacquiring high contrast and resolution images of optical absorption at depths\ngreater than traditional optical imaging techniques. Practical considerations\nwith instrumentation and geometry limit the number of available acoustic\nsensors and their view of the imaging target, which result in significant image\nreconstruction artifacts degrading image quality. Iterative reconstruction\nmethods can be used to reduce artifacts but are computationally expensive. In\nthis work, we propose a novel deep learning approach termed pixelwise deep\nlearning (PixelDL) that first employs pixelwise interpolation governed by the\nphysics of photoacoustic wave propagation and then uses a convolution neural\nnetwork to directly reconstruct an image. Simulated photoacoustic data from\nsynthetic vasculature phantom and mouse-brain vasculature were used for\ntraining and testing, respectively. Results demonstrated that PixelDL achieved\ncomparable performance to iterative methods and outperformed other CNN-based\napproaches for correcting artifacts. PixelDL is a computationally efficient\napproach that enables for realtime PAT rendering and for improved image\nquality, quantification, and interpretation.\n", "versions": [{"version": "v1", "created": "Mon, 11 Nov 2019 15:59:11 GMT"}, {"version": "v2", "created": "Sat, 27 Jun 2020 18:01:53 GMT"}], "update_date": "2020-06-30", "authors_parsed": [["Guan", "Steven", ""], ["Khan", "Amir A.", ""], ["Sikdar", "Siddhartha", ""], ["Chitnis", "Parag V.", ""]]}, {"id": "1911.04362", "submitter": "Nicole Fitzgerald", "authors": "Nicole Fitzgerald", "title": "To Populate is To Regulate", "comments": "EmeCom Neurips 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CL stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We examine the effects of instantiating Lewis signaling games within a\npopulation of speaker and listener agents with the aim of producing a set of\ngeneral and robust representations of unstructured pixel data. Preliminary\nexperiments suggest that the set of representations associated with languages\ngenerated within a population outperform those generated between a single\nspeaker-listener pair on this objective, making a case for the adoption of\npopulation-based approaches in emergent communication studies. Furthermore,\npost-hoc analysis reveals that population-based learning induces a number of\nnovel factors to the conventional emergent communication setup, inviting a wide\nrange of future research questions regarding communication dynamics and the\nflow of information within them.\n", "versions": [{"version": "v1", "created": "Wed, 6 Nov 2019 23:51:45 GMT"}], "update_date": "2019-11-12", "authors_parsed": [["Fitzgerald", "Nicole", ""]]}, {"id": "1911.04365", "submitter": "Jun He", "authors": "Jun He, Quan-Jie Cao, Lei Zhang", "title": "Conditionally Learn to Pay Attention for Sequential Visual Task", "comments": null, "journal-ref": "IEEE Access 8(2020) 56695-56710", "doi": "10.1109/ACCESS.2020.2982571", "report-no": null, "categories": "cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Sequential visual task usually requires to pay attention to its current\ninterested object conditional on its previous observations. Different from\npopular soft attention mechanism, we propose a new attention framework by\nintroducing a novel conditional global feature which represents the weak\nfeature descriptor of the current focused object. Specifically, for a standard\nCNN (Convolutional Neural Network) pipeline, the convolutional layers with\ndifferent receptive fields are used to produce the attention maps by measuring\nhow the convolutional features align to the conditional global feature. The\nconditional global feature can be generated by different recurrent structure\naccording to different visual tasks, such as a simple recurrent neural network\nfor multiple objects recognition, or a moderate complex language model for\nimage caption. Experiments show that our proposed conditional attention model\nachieves the best performance on the SVHN (Street View House Numbers) dataset\nwith / without extra bounding box; and for image caption, our attention model\ngenerates better scores than the popular soft attention model.\n", "versions": [{"version": "v1", "created": "Mon, 11 Nov 2019 16:11:46 GMT"}], "update_date": "2020-04-02", "authors_parsed": [["He", "Jun", ""], ["Cao", "Quan-Jie", ""], ["Zhang", "Lei", ""]]}, {"id": "1911.04379", "submitter": "Sharaj Panwar", "authors": "Sharaj Panwar, Paul Rad, Tzyy-Ping Jung, Yufei Huang", "title": "Modeling EEG data distribution with a Wasserstein Generative Adversarial\n  Network to predict RSVP Events", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.IV cs.LG stat.AP stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Electroencephalography (EEG) data are difficult to obtain due to complex\nexperimental setups and reduced comfort with prolonged wearing. This poses\nchallenges to train powerful deep learning model with the limited EEG data.\nBeing able to generate EEG data computationally could address this limitation.\nWe propose a novel Wasserstein Generative Adversarial Network with gradient\npenalty (WGAN-GP) to synthesize EEG data. This network addresses several\nmodeling challenges of simulating time-series EEG data including frequency\nartifacts and training instability. We further extended this network to a\nclass-conditioned variant that also includes a classification branch to perform\nevent-related classification. We trained the proposed networks to generate one\nand 64-channel data resembling EEG signals routinely seen in a rapid serial\nvisual presentation (RSVP) experiment and demonstrated the validity of the\ngenerated samples. We also tested intra-subject cross-session classification\nperformance for classifying the RSVP target events and showed that\nclass-conditioned WGAN-GP can achieve improved event-classification performance\nover EEGNet.\n", "versions": [{"version": "v1", "created": "Mon, 11 Nov 2019 16:43:06 GMT"}, {"version": "v2", "created": "Wed, 1 Jul 2020 16:17:27 GMT"}], "update_date": "2020-07-02", "authors_parsed": [["Panwar", "Sharaj", ""], ["Rad", "Paul", ""], ["Jung", "Tzyy-Ping", ""], ["Huang", "Yufei", ""]]}, {"id": "1911.04383", "submitter": "Zilong Zhao", "authors": "Zilong Zhao, Robert Birke, Rui Han, Bogdan Robu, Sara Bouchenak, Sonia\n  Ben Mokhtar, Lydia Y. Chen", "title": "RAD: On-line Anomaly Detection for Highly Unreliable Data", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Classification algorithms have been widely adopted to detect anomalies for\nvarious systems, e.g., IoT, cloud and face recognition, under the common\nassumption that the data source is clean, i.e., features and labels are\ncorrectly set. However, data collected from the wild can be unreliable due to\ncareless annotations or malicious data transformation for incorrect anomaly\ndetection. In this paper, we present a two-layer on-line learning framework for\nrobust anomaly detection (RAD) in the presence of unreliable anomaly labels,\nwhere the first layer is to filter out the suspicious data, and the second\nlayer detects the anomaly patterns from the remaining data. To adapt to the\non-line nature of anomaly detection, we extend RAD with additional features of\nrepetitively cleaning, conflicting opinions of classifiers, and oracle\nknowledge. We on-line learn from the incoming data streams and continuously\ncleanse the data, so as to adapt to the increasing learning capacity from the\nlarger accumulated data set. Moreover, we explore the concept of oracle\nlearning that provides additional information of true labels for difficult data\npoints. We specifically focus on three use cases, (i) detecting 10 classes of\nIoT attacks, (ii) predicting 4 classes of task failures of big data jobs, (iii)\nrecognising 20 celebrities faces. Our evaluation results show that RAD can\nrobustly improve the accuracy of anomaly detection, to reach up to 98% for IoT\ndevice attacks (i.e., +11%), up to 84% for cloud task failures (i.e., +20%)\nunder 40% noise, and up to 74% for face recognition (i.e., +28%) under 30%\nnoisy labels. The proposed RAD is general and can be applied to different\nanomaly detection algorithms.\n", "versions": [{"version": "v1", "created": "Mon, 11 Nov 2019 16:50:13 GMT"}], "update_date": "2019-11-12", "authors_parsed": [["Zhao", "Zilong", ""], ["Birke", "Robert", ""], ["Han", "Rui", ""], ["Robu", "Bogdan", ""], ["Bouchenak", "Sara", ""], ["Mokhtar", "Sonia Ben", ""], ["Chen", "Lydia Y.", ""]]}, {"id": "1911.04384", "submitter": "Shangtong Zhang", "authors": "Shangtong Zhang, Bo Liu, Hengshuai Yao, Shimon Whiteson", "title": "Provably Convergent Two-Timescale Off-Policy Actor-Critic with Function\n  Approximation", "comments": "ICML 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present the first provably convergent two-timescale off-policy\nactor-critic algorithm (COF-PAC) with function approximation. Key to COF-PAC is\nthe introduction of a new critic, the emphasis critic, which is trained via\nGradient Emphasis Learning (GEM), a novel combination of the key ideas of\nGradient Temporal Difference Learning and Emphatic Temporal Difference\nLearning. With the help of the emphasis critic and the canonical value function\ncritic, we show convergence for COF-PAC, where the critics are linear and the\nactor can be nonlinear.\n", "versions": [{"version": "v1", "created": "Mon, 11 Nov 2019 16:50:14 GMT"}, {"version": "v2", "created": "Tue, 4 Feb 2020 18:34:28 GMT"}, {"version": "v3", "created": "Fri, 7 Feb 2020 15:26:50 GMT"}, {"version": "v4", "created": "Thu, 11 Jun 2020 04:06:07 GMT"}, {"version": "v5", "created": "Tue, 21 Jul 2020 00:01:02 GMT"}, {"version": "v6", "created": "Wed, 29 Jul 2020 22:11:24 GMT"}, {"version": "v7", "created": "Fri, 31 Jul 2020 18:19:26 GMT"}, {"version": "v8", "created": "Sat, 31 Oct 2020 00:23:49 GMT"}, {"version": "v9", "created": "Mon, 23 Nov 2020 21:22:42 GMT"}], "update_date": "2020-11-25", "authors_parsed": [["Zhang", "Shangtong", ""], ["Liu", "Bo", ""], ["Yao", "Hengshuai", ""], ["Whiteson", "Shimon", ""]]}, {"id": "1911.04386", "submitter": "Antonio Paiva", "authors": "Weike Sun, Antonio R. C. Paiva, Peng Xu, Anantha Sundaram, Richard D.\n  Braatz", "title": "Fault Detection and Identification using Bayesian Recurrent Neural\n  Networks", "comments": "43 pages, 23 figures. Accepted for publication in Computers &\n  Chemical Engineering", "journal-ref": null, "doi": "10.1016/j.compchemeng.2020.106991", "report-no": null, "categories": "stat.ML cs.LG cs.SY eess.SY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In processing and manufacturing industries, there has been a large push to\nproduce higher quality products and ensure maximum efficiency of processes.\nThis requires approaches to effectively detect and resolve disturbances to\nensure optimal operations. While the control system can compensate for many\ntypes of disturbances, there are changes to the process which it still cannot\nhandle adequately. It is therefore important to further develop monitoring\nsystems to effectively detect and identify those faults such that they can be\nquickly resolved by operators. In this paper, a novel probabilistic fault\ndetection and identification method is proposed which adopts a newly developed\ndeep learning approach using Bayesian recurrent neural networks~(BRNNs) with\nvariational dropout. The BRNN model is general and can model complex nonlinear\ndynamics. Moreover, compared to traditional statistic-based data-driven fault\ndetection and identification methods, the proposed BRNN-based method yields\nuncertainty estimates which allow for simultaneous fault detection of chemical\nprocesses, direct fault identification, and fault propagation analysis. The\noutstanding performance of this method is demonstrated and contrasted to\n(dynamic) principal component analysis, which are widely applied in the\nindustry, in the benchmark Tennessee Eastman process~(TEP) and a real chemical\nmanufacturing dataset.\n", "versions": [{"version": "v1", "created": "Mon, 11 Nov 2019 16:56:28 GMT"}, {"version": "v2", "created": "Fri, 26 Jun 2020 20:47:17 GMT"}], "update_date": "2021-02-05", "authors_parsed": [["Sun", "Weike", ""], ["Paiva", "Antonio R. C.", ""], ["Xu", "Peng", ""], ["Sundaram", "Anantha", ""], ["Braatz", "Richard D.", ""]]}, {"id": "1911.04389", "submitter": "Niklas Rindtorff", "authors": "Niklas T. Rindtorff, MingYu Lu, Nisarg A. Patel, Huahua Zheng,\n  Alexander D'Amour", "title": "A Biologically Plausible Benchmark for Contextual Bandit Algorithms in\n  Precision Oncology Using in vitro Data", "comments": "Machine Learning for Health (ML4H) at NeurIPS 2019 - Extended\n  Abstract", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Precision oncology, the genetic sequencing of tumors to identify druggable\ntargets, has emerged as the standard of care in the treatment of many cancers.\nNonetheless, due to the pace of therapy development and variability in patient\ninformation, designing effective protocols for individual treatment assignment\nin a sample-efficient way remains a major challenge. One promising approach to\nthis problem is to frame precision oncology treatment as a contextual bandit\nproblem and to apply sequential decision-making algorithms designed to minimize\nregret in this setting. However, a clear prerequisite for considering this\nmethodology in high-stakes clinical decisions is careful benchmarking to\nunderstand realistic costs and benefits. Here, we propose a benchmark dataset\nto evaluate contextual bandit algorithms based on real in vitro drug response\nof approximately 900 cancer cell lines. Specifically, we curated a dataset of\ncomplete treatment responses for a subset of 7 treatments from prior in vitro\nstudies. This allows us to compute the regret of proposed decision policies\nusing biologically plausible counterfactuals. We ran a suite of Bayesian bandit\nalgorithms on our benchmark, and found that the methods accumulate less regret\nover a sequence of treatment assignment tasks than a rule-based baseline\nderived from current clinical practice. This effect was more pronounced when\ngenomic information was included as context. We expect this work to be a\nstarting point for evaluation of both the unique structural requirements and\nethical implications for real-world testing of bandit based clinical decision\nsupport.\n", "versions": [{"version": "v1", "created": "Mon, 11 Nov 2019 16:59:11 GMT"}], "update_date": "2019-11-12", "authors_parsed": [["Rindtorff", "Niklas T.", ""], ["Lu", "MingYu", ""], ["Patel", "Nisarg A.", ""], ["Zheng", "Huahua", ""], ["D'Amour", "Alexander", ""]]}, {"id": "1911.04393", "submitter": "Michael Rapp", "authors": "Michael Rapp, Eneldo Loza Menc\\'ia, Johannes F\\\"urnkranz", "title": "Simplifying Random Forests: On the Trade-off between Interpretability\n  and Accuracy", "comments": null, "journal-ref": "1st Workshop on Deep Continuous-Discrete Machine Learning\n  (DeCoDeML), ECML-PKDD 2019, W\\\"urzburg Germany", "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We analyze the trade-off between model complexity and accuracy for random\nforests by breaking the trees up into individual classification rules and\nselecting a subset of them. We show experimentally that already a few rules are\nsufficient to achieve an acceptable accuracy close to that of the original\nmodel. Moreover, our results indicate that in many cases, this can lead to\nsimpler models that clearly outperform the original ones.\n", "versions": [{"version": "v1", "created": "Mon, 11 Nov 2019 17:05:19 GMT"}], "update_date": "2020-12-09", "authors_parsed": [["Rapp", "Michael", ""], ["Menc\u00eda", "Eneldo Loza", ""], ["F\u00fcrnkranz", "Johannes", ""]]}, {"id": "1911.04400", "submitter": "Pietro Ferraro", "authors": "Meghana Rathi, Pietro Ferraro, Giovanni Russo", "title": "Driving Reinforcement Learning with Models", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we propose a new approach to complement reinforcement learning\n(RL) with model-based control (in particular, Model Predictive Control - MPC).\nWe introduce an algorithm, the MPC augmented RL (MPRL) that combines RL and MPC\nin a novel way so that they can augment each other's strengths. We demonstrate\nthe effectiveness of the MPRL by letting it play against the Atari game Pong.\nFor this task, the results highlight how MPRL is able to outperform both RL and\nMPC when these are used individually.\n", "versions": [{"version": "v1", "created": "Mon, 11 Nov 2019 17:14:56 GMT"}, {"version": "v2", "created": "Wed, 26 Feb 2020 15:25:52 GMT"}], "update_date": "2020-02-27", "authors_parsed": [["Rathi", "Meghana", ""], ["Ferraro", "Pietro", ""], ["Russo", "Giovanni", ""]]}, {"id": "1911.04410", "submitter": "Kianoush Falahkheirkhah", "authors": "Kianoush Falahkheirkhah, Kevin Yeh, Shachi Mittal, Luke Pfister, Rohit\n  Bhargava", "title": "A deep learning framework for morphologic detail beyond the diffraction\n  limit in infrared spectroscopic imaging", "comments": "corrected typos (the word \"lack\" was missing in the abstract)", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.IV cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Infrared (IR) microscopes measure spectral information that quantifies\nmolecular content to assign the identity of biomedical cells but lack the\nspatial quality of optical microscopy to appreciate morphologic features. Here,\nwe propose a method to utilize the semantic information of cellular identity\nfrom IR imaging with the morphologic detail of pathology images in a deep\nlearning-based approach to image super-resolution. Using Generative Adversarial\nNetworks (GANs), we enhance the spatial detail in IR imaging beyond the\ndiffraction limit while retaining their spectral contrast. This technique can\nbe rapidly integrated with modern IR microscopes to provide a framework useful\nfor routine pathology.\n", "versions": [{"version": "v1", "created": "Wed, 6 Nov 2019 16:50:27 GMT"}, {"version": "v2", "created": "Thu, 19 Dec 2019 16:33:42 GMT"}], "update_date": "2019-12-20", "authors_parsed": [["Falahkheirkhah", "Kianoush", ""], ["Yeh", "Kevin", ""], ["Mittal", "Shachi", ""], ["Pfister", "Luke", ""], ["Bhargava", "Rohit", ""]]}, {"id": "1911.04415", "submitter": "Cyrille W. Combettes", "authors": "Cyrille W. Combettes and Sebastian Pokutta", "title": "Revisiting the Approximate Carath\\'eodory Problem via the Frank-Wolfe\n  Algorithm", "comments": "21 pages and 2 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.OC cs.DS cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The approximate Carath\\'eodory theorem states that given a compact convex set\n$\\mathcal{C}\\subset\\mathbb{R}^n$ and $p\\in\\left[2,+\\infty\\right[$, each point\n$x^*\\in\\mathcal{C}$ can be approximated to $\\epsilon$-accuracy in the\n$\\ell_p$-norm as the convex combination of $\\mathcal{O}(pD_p^2/\\epsilon^2)$\nvertices of $\\mathcal{C}$, where $D_p$ is the diameter of $\\mathcal{C}$ in the\n$\\ell_p$-norm. A solution satisfying these properties can be built using\nprobabilistic arguments or by applying mirror descent to the dual problem. We\nrevisit the approximate Carath\\'eodory problem by solving the primal problem\nvia the Frank-Wolfe algorithm, providing a simplified analysis and leading to\nan efficient practical method. Furthermore, improved cardinality bounds are\nderived naturally using existing convergence rates of the Frank-Wolfe algorithm\nin different scenarios, when $x^*$ is in the (relative) interior of\n$\\mathcal{C}$, when $x^*$ is the convex combination of a subset of vertices\nwith small diameter, or when $\\mathcal{C}$ is uniformly convex. We also propose\ncardinality bounds when $p\\in\\left[1,2\\right[\\cup\\{+\\infty\\}$ via a nonsmooth\nvariant of the algorithm. Lastly, we address the problem of finding sparse\napproximate projections onto $\\mathcal{C}$ in the $\\ell_p$-norm,\n$p\\in\\left[1,+\\infty\\right]$.\n", "versions": [{"version": "v1", "created": "Mon, 11 Nov 2019 17:41:58 GMT"}, {"version": "v2", "created": "Sun, 19 Apr 2020 04:12:32 GMT"}, {"version": "v3", "created": "Mon, 12 Apr 2021 08:53:28 GMT"}, {"version": "v4", "created": "Tue, 13 Apr 2021 17:53:30 GMT"}], "update_date": "2021-04-14", "authors_parsed": [["Combettes", "Cyrille W.", ""], ["Pokutta", "Sebastian", ""]]}, {"id": "1911.04427", "submitter": "Manirupa Das", "authors": "Manirupa Das, Juanxi Li, Eric Fosler-Lussier, Simon Lin, Soheil\n  Moosavinasab, Steve Rust, Yungui Huang and Rajiv Ramnath", "title": "Sequence-to-Set Semantic Tagging: End-to-End Multi-label Prediction\n  using Neural Attention for Complex Query Reformulation and Automated Text\n  Categorization", "comments": "8 pages, 4 figures, 1 table", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.IR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Novel contexts may often arise in complex querying scenarios such as in\nevidence-based medicine (EBM) involving biomedical literature, that may not\nexplicitly refer to entities or canonical concept forms occurring in any fact-\nor rule-based knowledge source such as an ontology like the UMLS. Moreover,\nhidden associations between candidate concepts meaningful in the current\ncontext, may not exist within a single document, but within the collection, via\nalternate lexical forms. Therefore, inspired by the recent success of\nsequence-to-sequence neural models in delivering the state-of-the-art in a wide\nrange of NLP tasks, we develop a novel sequence-to-set framework with neural\nattention for learning document representations that can effect term transfer\nwithin the corpus, for semantically tagging a large collection of documents. We\ndemonstrate that our proposed method can be effective in both a supervised\nmulti-label classification setup for text categorization, as well as in a\nunique unsupervised setting with no human-annotated document labels that uses\nno external knowledge resources and only corpus-derived term statistics to\ndrive the training. Further, we show that semi-supervised training using our\narchitecture on large amounts of unlabeled data can augment performance on the\ntext categorization task when limited labeled data is available. Our approach\nto generate document encodings employing our sequence-to-set models for\ninference of semantic tags, gives to the best of our knowledge, the\nstate-of-the-art for both, the unsupervised query expansion task for the TREC\nCDS 2016 challenge dataset when evaluated on an Okapi BM25--based document\nretrieval system; and also over the MLTM baseline (Soleimani et al, 2016), for\nboth supervised and semi-supervised multi-label prediction tasks on the\ndel.icio.us and Ohsumed datasets. We will make our code and data publicly\navailable.\n", "versions": [{"version": "v1", "created": "Mon, 11 Nov 2019 18:13:05 GMT"}], "update_date": "2019-11-12", "authors_parsed": [["Das", "Manirupa", ""], ["Li", "Juanxi", ""], ["Fosler-Lussier", "Eric", ""], ["Lin", "Simon", ""], ["Moosavinasab", "Soheil", ""], ["Rust", "Steve", ""], ["Huang", "Yungui", ""], ["Ramnath", "Rajiv", ""]]}, {"id": "1911.04429", "submitter": "Xiaoyun Wang", "authors": "Xiaoyun Wang, Xuanqing Liu, Cho-Jui Hsieh", "title": "GraphDefense: Towards Robust Graph Convolutional Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we study the robustness of graph convolutional networks\n(GCNs). Despite the good performance of GCNs on graph semi-supervised learning\ntasks, previous works have shown that the original GCNs are very unstable to\nadversarial perturbations. In particular, we can observe a severe performance\ndegradation by slightly changing the graph adjacency matrix or the features of\na few nodes, making it unsuitable for security-critical applications. Inspired\nby the previous works on adversarial defense for deep neural networks, and\nespecially adversarial training algorithm, we propose a method called\nGraphDefense to defend against the adversarial perturbations. In addition, for\nour defense method, we could still maintain semi-supervised learning settings,\nwithout a large label rate. We also show that adversarial training in features\nis equivalent to adversarial training for edges with a small perturbation. Our\nexperiments show that the proposed defense methods successfully increase the\nrobustness of Graph Convolutional Networks. Furthermore, we show that with\ncareful design, our proposed algorithm can scale to large graphs, such as\nReddit dataset.\n", "versions": [{"version": "v1", "created": "Mon, 11 Nov 2019 18:15:12 GMT"}], "update_date": "2019-11-12", "authors_parsed": [["Wang", "Xiaoyun", ""], ["Liu", "Xuanqing", ""], ["Hsieh", "Cho-Jui", ""]]}, {"id": "1911.04436", "submitter": "Changxiao Cai", "authors": "Changxiao Cai, Gen Li, H. Vincent Poor, Yuxin Chen", "title": "Nonconvex Low-Rank Tensor Completion from Noisy Data", "comments": "Accepted to Operations Research", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.IT math.IT math.OC math.ST stat.ML stat.TH", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We study a noisy tensor completion problem of broad practical interest,\nnamely, the reconstruction of a low-rank tensor from highly incomplete and\nrandomly corrupted observations of its entries. While a variety of prior work\nhas been dedicated to this problem, prior algorithms either are computationally\ntoo expensive for large-scale applications, or come with sub-optimal\nstatistical guarantees. Focusing on \"incoherent\" and well-conditioned tensors\nof a constant CP rank, we propose a two-stage nonconvex algorithm -- (vanilla)\ngradient descent following a rough initialization -- that achieves the best of\nboth worlds. Specifically, the proposed nonconvex algorithm faithfully\ncompletes the tensor and retrieves all individual tensor factors within nearly\nlinear time, while at the same time enjoying near-optimal statistical\nguarantees (i.e. minimal sample complexity and optimal estimation accuracy).\nThe estimation errors are evenly spread out across all entries, thus achieving\noptimal $\\ell_{\\infty}$ statistical accuracy. We have also discussed how to\nextend our approach to accommodate asymmetric tensors. The insight conveyed\nthrough our analysis of nonconvex optimization might have implications for\nother tensor estimation problems.\n", "versions": [{"version": "v1", "created": "Mon, 11 Nov 2019 18:21:26 GMT"}, {"version": "v2", "created": "Thu, 3 Jun 2021 03:32:06 GMT"}], "update_date": "2021-06-04", "authors_parsed": [["Cai", "Changxiao", ""], ["Li", "Gen", ""], ["Poor", "H. Vincent", ""], ["Chen", "Yuxin", ""]]}, {"id": "1911.04448", "submitter": "Simon Ramstedt", "authors": "Simon Ramstedt, Christopher Pal", "title": "Real-Time Reinforcement Learning", "comments": "Neural Information Processing Systems (2019)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Markov Decision Processes (MDPs), the mathematical framework underlying most\nalgorithms in Reinforcement Learning (RL), are often used in a way that\nwrongfully assumes that the state of an agent's environment does not change\nduring action selection. As RL systems based on MDPs begin to find application\nin real-world safety critical situations, this mismatch between the assumptions\nunderlying classical MDPs and the reality of real-time computation may lead to\nundesirable outcomes. In this paper, we introduce a new framework, in which\nstates and actions evolve simultaneously and show how it is related to the\nclassical MDP formulation. We analyze existing algorithms under the new\nreal-time formulation and show why they are suboptimal when used in real-time.\nWe then use those insights to create a new algorithm Real-Time Actor-Critic\n(RTAC) that outperforms the existing state-of-the-art continuous control\nalgorithm Soft Actor-Critic both in real-time and non-real-time settings. Code\nand videos can be found at https://github.com/rmst/rtrl.\n", "versions": [{"version": "v1", "created": "Mon, 11 Nov 2019 18:52:04 GMT"}, {"version": "v2", "created": "Wed, 13 Nov 2019 18:56:26 GMT"}, {"version": "v3", "created": "Thu, 14 Nov 2019 18:54:06 GMT"}, {"version": "v4", "created": "Thu, 12 Dec 2019 08:46:32 GMT"}], "update_date": "2019-12-13", "authors_parsed": [["Ramstedt", "Simon", ""], ["Pal", "Christopher", ""]]}, {"id": "1911.04453", "submitter": "Xiaocong Du", "authors": "Gokul Krishnan, Xiaocong Du, Yu Cao", "title": "Structural Pruning in Deep Neural Networks: A Small-World Approach", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep Neural Networks (DNNs) are usually over-parameterized, causing excessive\nmemory and interconnection cost on the hardware platform. Existing pruning\napproaches remove secondary parameters at the end of training to reduce the\nmodel size; but without exploiting the intrinsic network property, they still\nrequire the full interconnection to prepare the network. Inspired by the\nobservation that brain networks follow the Small-World model, we propose a\nnovel structural pruning scheme, which includes (1) hierarchically trimming the\nnetwork into a Small-World model before training, (2) training the network for\na given dataset, and (3) optimizing the network for accuracy. The new scheme\neffectively reduces both the model size and the interconnection needed before\ntraining, achieving a locally clustered and globally sparse model. We\ndemonstrate our approach on LeNet-5 for MNIST and VGG-16 for CIFAR-10,\ndecreasing the number of parameters to 2.3% and 9.02% of the baseline model,\nrespectively.\n", "versions": [{"version": "v1", "created": "Mon, 11 Nov 2019 18:53:50 GMT"}], "update_date": "2019-11-12", "authors_parsed": [["Krishnan", "Gokul", ""], ["Du", "Xiaocong", ""], ["Cao", "Yu", ""]]}, {"id": "1911.04462", "submitter": "Quanquan Gu", "authors": "Dongruo Zhou and Lihong Li and Quanquan Gu", "title": "Neural Contextual Bandits with UCB-based Exploration", "comments": "27 pages, 2 figures, 1 table. In ICML 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the stochastic contextual bandit problem, where the reward is\ngenerated from an unknown function with additive noise. No assumption is made\nabout the reward function other than boundedness. We propose a new algorithm,\nNeuralUCB, which leverages the representation power of deep neural networks and\nuses a neural network-based random feature mapping to construct an upper\nconfidence bound (UCB) of reward for efficient exploration. We prove that,\nunder standard assumptions, NeuralUCB achieves $\\tilde O(\\sqrt{T})$ regret,\nwhere $T$ is the number of rounds. To the best of our knowledge, it is the\nfirst neural network-based contextual bandit algorithm with a near-optimal\nregret guarantee. We also show the algorithm is empirically competitive against\nrepresentative baselines in a number of benchmarks.\n", "versions": [{"version": "v1", "created": "Mon, 11 Nov 2019 18:58:30 GMT"}, {"version": "v2", "created": "Wed, 4 Mar 2020 05:46:20 GMT"}, {"version": "v3", "created": "Thu, 2 Jul 2020 17:57:22 GMT"}], "update_date": "2020-07-03", "authors_parsed": [["Zhou", "Dongruo", ""], ["Li", "Lihong", ""], ["Gu", "Quanquan", ""]]}, {"id": "1911.04464", "submitter": "Siddharth Bhatia", "authors": "Siddharth Bhatia, Bryan Hooi, Minji Yoon, Kijung Shin, Christos\n  Faloutsos", "title": "MIDAS: Microcluster-Based Detector of Anomalies in Edge Streams", "comments": "8 pages, Accepted at AAAI Conference on Artificial Intelligence\n  (AAAI), 2020 [oral paper]; minor fixes, updated experiments", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Given a stream of graph edges from a dynamic graph, how can we assign anomaly\nscores to edges in an online manner, for the purpose of detecting unusual\nbehavior, using constant time and memory? Existing approaches aim to detect\nindividually surprising edges. In this work, we propose MIDAS, which focuses on\ndetecting microcluster anomalies, or suddenly arriving groups of suspiciously\nsimilar edges, such as lockstep behavior, including denial of service attacks\nin network traffic data. MIDAS has the following properties: (a) it detects\nmicrocluster anomalies while providing theoretical guarantees about its false\npositive probability; (b) it is online, thus processing each edge in constant\ntime and constant memory, and also processes the data 162-644 times faster than\nstate-of-the-art approaches; (c) it provides 42%-48% higher accuracy (in terms\nof AUC) than state-of-the-art approaches.\n", "versions": [{"version": "v1", "created": "Mon, 11 Nov 2019 18:59:24 GMT"}, {"version": "v2", "created": "Wed, 13 Nov 2019 13:54:08 GMT"}, {"version": "v3", "created": "Thu, 6 Feb 2020 13:45:27 GMT"}, {"version": "v4", "created": "Tue, 21 Apr 2020 09:37:23 GMT"}, {"version": "v5", "created": "Sun, 23 Aug 2020 15:32:57 GMT"}], "update_date": "2020-08-25", "authors_parsed": [["Bhatia", "Siddharth", ""], ["Hooi", "Bryan", ""], ["Yoon", "Minji", ""], ["Shin", "Kijung", ""], ["Faloutsos", "Christos", ""]]}, {"id": "1911.04467", "submitter": "Chenye Wu", "authors": "Kui Wang, Jian Sun, Chenye Wu and Yang Yu", "title": "Conductor Galloping Prediction on Imbalanced Datasets: SVM with Smart\n  Sampling", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.SP cs.LG cs.SY eess.SY stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Conductor galloping is the high-amplitude, low-frequency oscillation of\noverhead power lines due to wind. Such movements may lead to severe damages to\ntransmission lines, and hence pose significant risks to the power system\noperation. In this paper, we target to design a prediction framework for\nconductor galloping. The difficulty comes from imbalanced dataset as galloping\nhappens rarely. By examining the impacts of data balance and data volume on the\nprediction performance, we propose to employ proper sample adjustment methods\nto achieve better performance. Numerical study suggests that using only three\nfeatures, together with over sampling, the SVM based prediction framework\nachieves an F_1-score of 98.9%.\n", "versions": [{"version": "v1", "created": "Sat, 9 Nov 2019 13:13:12 GMT"}], "update_date": "2019-11-13", "authors_parsed": [["Wang", "Kui", ""], ["Sun", "Jian", ""], ["Wu", "Chenye", ""], ["Yu", "Yang", ""]]}, {"id": "1911.04468", "submitter": "Foroozan Karimzadeh", "authors": "Foroozan Karimzadeh, Ningyuan Cao, Brian Crafton, Justin Romberg,\n  Arijit Raychowdhury", "title": "Hardware-aware Pruning of DNNs using LFSR-Generated Pseudo-Random\n  Indices", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep neural networks (DNNs) have been emerged as the state-of-the-art\nalgorithms in broad range of applications. To reduce the memory foot-print of\nDNNs, in particular for embedded applications, sparsification techniques have\nbeen proposed. Unfortunately, these techniques come with a large hardware\noverhead. In this paper, we present a hardware-aware pruning method where the\nlocations of non-zero weights are derived in real-time from a Linear Feedback\nShift Registers (LFSRs). Using the proposed method, we demonstrate a total\nsaving of energy and area up to 63.96% and 64.23% for VGG-16 network on\ndown-sampled ImageNet, respectively for iso-compression-rate and iso-accuracy.\n", "versions": [{"version": "v1", "created": "Sat, 9 Nov 2019 17:26:54 GMT"}], "update_date": "2019-11-13", "authors_parsed": [["Karimzadeh", "Foroozan", ""], ["Cao", "Ningyuan", ""], ["Crafton", "Brian", ""], ["Romberg", "Justin", ""], ["Raychowdhury", "Arijit", ""]]}, {"id": "1911.04469", "submitter": "Ahmed Hammam", "authors": "Ahmed Ali Hammam, Mona Soliman, Aboul Ella Hassanien", "title": "A Proposed Artificial intelligence Model for Real-Time Human Action\n  Localization and Tracking", "comments": "SUBMITTED TO IEEE TRANSACTIONS ON NEURAL NETWORKS AND LEARNING\n  SYSTEMS", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG eess.IV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In recent years, artificial intelligence (AI) based on deep learning (DL) has\nsparked tremendous global interest. DL is widely used today and has expanded\ninto various interesting areas. It is becoming more popular in cross-subject\nresearch, such as studies of smart city systems, which combine computer science\nwith engineering applications. Human action detection is one of these areas.\nHuman action detection is an interesting challenge due to its stringent\nrequirements in terms of computing speed and accuracy. High-accuracy real-time\nobject tracking is also considered a significant challenge. This paper\nintegrates the YOLO detection network, which is considered a state-of-the-art\ntool for real-time object detection, with motion vectors and the Coyote\nOptimization Algorithm (COA) to construct a real-time human action localization\nand tracking system. The proposed system starts with the extraction of motion\ninformation from a compressed video stream and the extraction of appearance\ninformation from RGB frames using an object detector. Then, a fusion step\nbetween the two streams is performed, and the results are fed into the proposed\naction tracking model. The COA is used in object tracking due to its accuracy\nand fast convergence. The basic foundation of the proposed model is the\nutilization of motion vectors, which already exist in a compressed video bit\nstream and provide sufficient information to improve the localization of the\ntarget action without requiring high consumption of computational resources\ncompared with other popular methods of extracting motion information, such as\noptical flows. This advantage allows the proposed approach to be implemented in\nchallenging environments where the computational resources are limited, such as\nInternet of Things (IoT) systems.\n", "versions": [{"version": "v1", "created": "Sat, 9 Nov 2019 19:59:17 GMT"}], "update_date": "2019-11-13", "authors_parsed": [["Hammam", "Ahmed Ali", ""], ["Soliman", "Mona", ""], ["Hassanien", "Aboul Ella", ""]]}, {"id": "1911.04470", "submitter": "Yuxin Song", "authors": "Jianjun Lei, Yuxin Song, Bo Peng, Zhanyu Ma, Ling Shao, Yi-Zhe Song", "title": "Semi-Heterogeneous Three-Way Joint Embedding Network for Sketch-Based\n  Image Retrieval", "comments": "Accepted by IEEE Transactions on Circuits and Systems for Video\n  Technology", "journal-ref": null, "doi": "10.1109/TCSVT.2019.2936710", "report-no": null, "categories": "cs.CV cs.LG eess.IV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Sketch-based image retrieval (SBIR) is a challenging task due to the large\ncross-domain gap between sketches and natural images. How to align abstract\nsketches and natural images into a common high-level semantic space remains a\nkey problem in SBIR. In this paper, we propose a novel semi-heterogeneous\nthree-way joint embedding network (Semi3-Net), which integrates three branches\n(a sketch branch, a natural image branch, and an edgemap branch) to learn more\ndiscriminative cross-domain feature representations for the SBIR task. The key\ninsight lies with how we cultivate the mutual and subtle relationships amongst\nthe sketches, natural images, and edgemaps. A semi-heterogeneous feature\nmapping is designed to extract bottom features from each domain, where the\nsketch and edgemap branches are shared while the natural image branch is\nheterogeneous to the other branches. In addition, a joint semantic embedding is\nintroduced to embed the features from different domains into a common\nhigh-level semantic space, where all of the three branches are shared. To\nfurther capture informative features common to both natural images and the\ncorresponding edgemaps, a co-attention model is introduced to conduct common\nchannel-wise feature recalibration between different domains. A hybrid-loss\nmechanism is designed to align the three branches, where an alignment loss and\na sketch-edgemap contrastive loss are presented to encourage the network to\nlearn invariant cross-domain representations. Experimental results on two\nwidely used category-level datasets (Sketchy and TU-Berlin Extension)\ndemonstrate that the proposed method outperforms state-of-the-art methods.\n", "versions": [{"version": "v1", "created": "Sun, 10 Nov 2019 02:53:06 GMT"}], "update_date": "2019-11-13", "authors_parsed": [["Lei", "Jianjun", ""], ["Song", "Yuxin", ""], ["Peng", "Bo", ""], ["Ma", "Zhanyu", ""], ["Shao", "Ling", ""], ["Song", "Yi-Zhe", ""]]}, {"id": "1911.04472", "submitter": "Hossein Yousefi", "authors": "Mohammad Rasoul Tanhatalab, Hossein Yousefi, Hesam Mohammad Hosseini,\n  Mostafa Mofarah Bonab, Vahid Fakharian, Hadis Abarghouei", "title": "Deep RAN: A Scalable Data-driven platform to Detect Anomalies in Live\n  Cellular Network Using Recurrent Convolutional Neural Network", "comments": "6 pages,", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.SP cs.LG cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we propose a novel algorithm to detect anomaly in terms of Key\nParameter Indicators (KPI)s over live cellular networks based on the\ncombination of Recurrent Neural Networks (RNN), and Convolutional Neural\nNetworks (CNN), as Recurrent Convolutional Neural Networks (R-CNN). CNN models\nthe spatial correlations and information, whereas, RNN models the temporal\ncorrelations and information. In this paper, the studied cellular network\nconsists of 2G, 3G, 4G, and 4.5G technologies, and the KPIs include Voice and\ndata traffic of the cells. The data and voice traffic are extremely important\nfor the owner of wireless networks because it is directly related to the\nrevenue and quality of service that users experience. These traffic changes\nhappen due to a couple of reasons: the subscriber behavior changes due to\nspecial events, making neighbor sites on-air or down, or by shifting the\ntraffic to the other technologies, e.g. shifting the traffic from 3G to 4G.\nTraditionally, in order to keep the network stable, the traffic should be\nobserved layer by layer during each interval to detect major changes in KPIs,\nin large scale telecommunication networks it will be too time-consuming with\nthe low accuracy of anomaly detection. However, the proposed algorithm is\ncapable of detecting the abnormal KPIs for each element of the network in a\ntime-efficient and accurate manner. It observes the traffic layer trends and\nclassifies them into 8 traffic categories: Normal, Suddenly Increasing,\nGradually Increasing, Suddenly Decreasing, Gradually Decreasing, Faulty Site,\nNew Site, and Down Site. This classification task enables the vendors and\noperators to detect anomalies in their live networks in order to keep the KPIs\nin a normal trend. The algorithm is trained and tested on the real dataset over\na cellular network with more than 25000 cells.\n", "versions": [{"version": "v1", "created": "Sun, 10 Nov 2019 08:36:33 GMT"}], "update_date": "2019-11-13", "authors_parsed": [["Tanhatalab", "Mohammad Rasoul", ""], ["Yousefi", "Hossein", ""], ["Hosseini", "Hesam Mohammad", ""], ["Bonab", "Mostafa Mofarah", ""], ["Fakharian", "Vahid", ""], ["Abarghouei", "Hadis", ""]]}, {"id": "1911.04474", "submitter": "Hang Yan", "authors": "Hang Yan, Bocao Deng, Xiaonan Li, Xipeng Qiu", "title": "TENER: Adapting Transformer Encoder for Named Entity Recognition", "comments": "Corrept typos, update performance based on the public available codes", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The Bidirectional long short-term memory networks (BiLSTM) have been widely\nused as an encoder in models solving the named entity recognition (NER) task.\nRecently, the Transformer is broadly adopted in various Natural Language\nProcessing (NLP) tasks owing to its parallelism and advantageous performance.\nNevertheless, the performance of the Transformer in NER is not as good as it is\nin other NLP tasks. In this paper, we propose TENER, a NER architecture\nadopting adapted Transformer Encoder to model the character-level features and\nword-level features. By incorporating the direction and relative distance aware\nattention and the un-scaled attention, we prove the Transformer-like encoder is\njust as effective for NER as other NLP tasks.\n", "versions": [{"version": "v1", "created": "Sun, 10 Nov 2019 15:05:48 GMT"}, {"version": "v2", "created": "Tue, 19 Nov 2019 17:34:19 GMT"}, {"version": "v3", "created": "Tue, 10 Dec 2019 07:01:25 GMT"}], "update_date": "2019-12-11", "authors_parsed": [["Yan", "Hang", ""], ["Deng", "Bocao", ""], ["Li", "Xiaonan", ""], ["Qiu", "Xipeng", ""]]}, {"id": "1911.04477", "submitter": "Xianda Xu", "authors": "Xianda Xu, Marco Pedersoli", "title": "A Computing Kernel for Network Binarization on PyTorch", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep Neural Networks have now achieved state-of-the-art results in a wide\nrange of tasks including image classification, object detection and so on.\nHowever, they are both computation consuming and memory intensive, making them\ndifficult to deploy on low-power devices. Network binarization is one of the\nexisting effective techniques for model compression and acceleration, but there\nis no computing kernel yet to support it on PyTorch. In this paper we developed\na computing kernel supporting 1-bit xnor and bitcount computation on PyTorch.\nExperimental results show that our kernel could accelerate the inference of the\nbinarized neural network by 3 times in GPU and by 4.5 times in CPU compared\nwith the control group.\n", "versions": [{"version": "v1", "created": "Mon, 11 Nov 2019 05:26:04 GMT"}], "update_date": "2019-11-13", "authors_parsed": [["Xu", "Xianda", ""], ["Pedersoli", "Marco", ""]]}, {"id": "1911.04489", "submitter": "Daniel Philps", "authors": "Daniel Philps, Artur d'Avila Garcez, Tillman Weyde", "title": "Making Good on LSTMs' Unfulfilled Promise", "comments": "33rd Conference on Neural Information Processing Systems (NeurIPS\n  2019), Vancouver, Canada. arXiv admin note: text overlap with\n  arXiv:1812.02340", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG q-fin.CP q-fin.PM stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  LSTMs promise much to financial time-series analysis, temporal and\ncross-sectional inference, but we find that they do not deliver in a real-world\nfinancial management task. We examine an alternative called Continual Learning\n(CL), a memory-augmented approach, which can provide transparent explanations,\ni.e. which memory did what and when. This work has implications for many\nfinancial applications including credit, time-varying fairness in decision\nmaking and more. We make three important new observations. Firstly, as well as\nbeing more explainable, time-series CL approaches outperform LSTMs as well as a\nsimple sliding window learner using feed-forward neural networks (FFNN).\nSecondly, we show that CL based on a sliding window learner (FFNN) is more\neffective than CL based on a sequential learner (LSTM). Thirdly, we examine how\nreal-world, time-series noise impacts several similarity approaches used in CL\nmemory addressing. We provide these insights using an approach called Continual\nLearning Augmentation (CLA) tested on a complex real-world problem, emerging\nmarket equities investment decision making. CLA provides a test-bed as it can\nbe based on different types of time-series learners, allowing testing of LSTM\nand FFNN learners side by side. CLA is also used to test several distance\napproaches used in a memory recall-gate: Euclidean distance (ED), dynamic time\nwarping (DTW), auto-encoders (AE) and a novel hybrid approach, warp-AE. We find\nthat ED under-performs DTW and AE but warp-AE shows the best overall\nperformance in a real-world financial task.\n", "versions": [{"version": "v1", "created": "Mon, 11 Nov 2019 18:57:37 GMT"}, {"version": "v2", "created": "Sat, 23 Nov 2019 14:56:54 GMT"}, {"version": "v3", "created": "Sun, 1 Dec 2019 12:44:27 GMT"}, {"version": "v4", "created": "Mon, 9 Dec 2019 02:07:27 GMT"}], "update_date": "2019-12-11", "authors_parsed": [["Philps", "Daniel", ""], ["Garcez", "Artur d'Avila", ""], ["Weyde", "Tillman", ""]]}, {"id": "1911.04521", "submitter": "Lakshmi Nair", "authors": "Nithin Shrivatsav, Lakshmi Nair and Sonia Chernova", "title": "Tool Substitution with Shape and Material Reasoning Using Dual Neural\n  Networks", "comments": "7 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper explores the problem of tool substitution, namely, identifying\nsubstitute tools for performing a task from a given set of candidate tools. We\nintroduce a novel approach to tool substitution, that unlike prior work in the\narea, combines both shape and material reasoning to effectively identify\nsubstitute tools. Our approach combines the use of visual and spectral\nreasoning using dual neural networks. It takes as input, the desired action to\nbe performed, and outputs a ranking of the available candidate tools based on\ntheir suitability for performing the action. Our results on a test set of 30\nreal-world objects show that our approach is able to effectively match shape\nand material similarities, with improved tool substitution performance when\ncombining both.\n", "versions": [{"version": "v1", "created": "Mon, 11 Nov 2019 19:11:44 GMT"}], "update_date": "2019-11-13", "authors_parsed": [["Shrivatsav", "Nithin", ""], ["Nair", "Lakshmi", ""], ["Chernova", "Sonia", ""]]}, {"id": "1911.04523", "submitter": "Gordon Plotkin", "authors": "Martin Abadi, Gordon D. Plotkin", "title": "A Simple Differentiable Programming Language", "comments": "In POPL2020", "journal-ref": null, "doi": "10.1145/3371106", "report-no": null, "categories": "cs.PL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Automatic differentiation plays a prominent role in scientific computing and\nin modern machine learning, often in the context of powerful programming\nsystems. The relation of the various embodiments of automatic differentiation\nto the mathematical notion of derivative is not always entirely\nclear---discrepancies can arise, sometimes inadvertently. In order to study\nautomatic differentiation in such programming contexts, we define a small but\nexpressive programming language that includes a construct for reverse-mode\ndifferentiation. We give operational and denotational semantics for this\nlanguage. The operational semantics employs popular implementation techniques,\nwhile the denotational semantics employs notions of differentiation familiar\nfrom real analysis. We establish that these semantics coincide.\n", "versions": [{"version": "v1", "created": "Mon, 11 Nov 2019 19:14:15 GMT"}, {"version": "v2", "created": "Mon, 18 Nov 2019 23:02:37 GMT"}, {"version": "v3", "created": "Tue, 31 Dec 2019 15:58:58 GMT"}, {"version": "v4", "created": "Sat, 1 Feb 2020 19:42:56 GMT"}], "update_date": "2020-02-04", "authors_parsed": [["Abadi", "Martin", ""], ["Plotkin", "Gordon D.", ""]]}, {"id": "1911.04542", "submitter": "Weisi Guo", "authors": "Weisi Guo", "title": "Explainable Artificial Intelligence (XAI) for 6G: Improving Trust\n  between Human and Machine", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.SP cs.LG cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  As the 5th Generation (5G) mobile networks are bringing about global societal\nbenefits, the design phase for the 6th Generation (6G) has started. 6G will\nneed to enable greater levels of autonomy, improve human machine interfacing,\nand achieve deep connectivity in more diverse environments. The need for\nincreased explainability to enable trust is critical for 6G as it manages a\nwide range of mission critical services (e.g. autonomous driving) to safety\ncritical tasks (e.g. remote surgery). As we migrate from traditional\nmodel-based optimisation to deep learning, the trust we have in our\noptimisation modules decrease. This loss of trust means we cannot understand\nthe impact of: 1) poor/bias/malicious data, and 2) neural network design on\ndecisions; nor can we explain to the engineer or the public the network's\nactions. In this review, we outline the core concepts of Explainable Artificial\nIntelligence (XAI) for 6G, including: public and legal motivations, definitions\nof explainability, performance vs. explainability trade-offs, methods to\nimprove explainability, and frameworks to incorporate XAI into future wireless\nsystems. Our review is grounded in cases studies for both PHY and MAC layer\noptimisation, and provide the community with an important research area to\nembark upon.\n", "versions": [{"version": "v1", "created": "Mon, 11 Nov 2019 19:49:11 GMT"}, {"version": "v2", "created": "Tue, 19 Nov 2019 21:37:33 GMT"}], "update_date": "2019-11-21", "authors_parsed": [["Guo", "Weisi", ""]]}, {"id": "1911.04554", "submitter": "Joshua Tobin", "authors": "Josh Tobin, OpenAI Robotics, Pieter Abbeel", "title": "Geometry-Aware Neural Rendering", "comments": "16 pages, 13 figures", "journal-ref": "33rd Conference on Neural Information Processing Systems (NeurIPS\n  2019), Vancouver, Canada", "doi": null, "report-no": null, "categories": "cs.CV cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Understanding the 3-dimensional structure of the world is a core challenge in\ncomputer vision and robotics. Neural rendering approaches learn an implicit 3D\nmodel by predicting what a camera would see from an arbitrary viewpoint. We\nextend existing neural rendering to more complex, higher dimensional scenes\nthan previously possible. We propose Epipolar Cross Attention (ECA), an\nattention mechanism that leverages the geometry of the scene to perform\nefficient non-local operations, requiring only $O(n)$ comparisons per spatial\ndimension instead of $O(n^2)$. We introduce three new simulated datasets\ninspired by real-world robotics and demonstrate that ECA significantly improves\nthe quantitative and qualitative performance of Generative Query Networks\n(GQN).\n", "versions": [{"version": "v1", "created": "Mon, 28 Oct 2019 03:10:39 GMT"}], "update_date": "2019-11-13", "authors_parsed": [["Tobin", "Josh", ""], ["Robotics", "OpenAI", ""], ["Abbeel", "Pieter", ""]]}, {"id": "1911.04559", "submitter": "Anirban Das", "authors": "Anirban Das and Thomas Brunschwiler", "title": "Privacy is What We Care About: Experimental Investigation of Federated\n  Learning on Edge Devices", "comments": "Accepted in ACM AIChallengeIoT 2019, New York, USA", "journal-ref": null, "doi": "10.1145/3363347.3363365", "report-no": null, "categories": "cs.LG cs.DC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Federated Learning enables training of a general model through edge devices\nwithout sending raw data to the cloud. Hence, this approach is attractive for\ndigital health applications, where data is sourced through edge devices and\nusers care about privacy. Here, we report on the feasibility to train deep\nneural networks on the Raspberry Pi4s as edge devices. A CNN, a LSTM and a MLP\nwere successfully trained on the MNIST data-set. Further, federated learning is\ndemonstrated experimentally on IID and non-IID samples in a parametric study,\nto benchmark the model convergence. The weight updates from the workers are\nshared with the cloud to train the general model through federated learning.\nWith the CNN and the non-IID samples a test-accuracy of up to 85% could be\nachieved within a training time of 2 minutes, while exchanging less than $10$\nMB data per device. In addition, we discuss federated learning from an use-case\nstandpoint, elaborating on privacy risks and labeling requirements for the\napplication of emotion detection from sound. Based on the experimental\nfindings, we discuss possible research directions to improve model and system\nperformance. Finally, we provide best practices for a practitioner, considering\nthe implementation of federated learning.\n", "versions": [{"version": "v1", "created": "Mon, 11 Nov 2019 20:44:03 GMT"}], "update_date": "2019-11-13", "authors_parsed": [["Das", "Anirban", ""], ["Brunschwiler", "Thomas", ""]]}, {"id": "1911.04574", "submitter": "Ruslan Shaydulin", "authors": "Sami Khairy, Ruslan Shaydulin, Lukasz Cincio, Yuri Alexeev, Prasanna\n  Balaprakash", "title": "Reinforcement-Learning-Based Variational Quantum Circuits Optimization\n  for Combinatorial Problems", "comments": null, "journal-ref": null, "doi": null, "report-no": "LA-UR-19-28945", "categories": "cs.LG quant-ph stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Quantum computing exploits basic quantum phenomena such as state\nsuperposition and entanglement to perform computations. The Quantum Approximate\nOptimization Algorithm (QAOA) is arguably one of the leading quantum algorithms\nthat can outperform classical state-of-the-art methods in the near term. QAOA\nis a hybrid quantum-classical algorithm that combines a parameterized quantum\nstate evolution with a classical optimization routine to approximately solve\ncombinatorial problems. The quality of the solution obtained by QAOA within a\nfixed budget of calls to the quantum computer depends on the performance of the\nclassical optimization routine used to optimize the variational parameters. In\nthis work, we propose an approach based on reinforcement learning (RL) to train\na policy network that can be used to quickly find high-quality variational\nparameters for unseen combinatorial problem instances. The RL agent is trained\non small problem instances which can be simulated on a classical computer, yet\nthe learned RL policy is generalizable and can be used to efficiently solve\nlarger instances. Extensive simulations using the IBM Qiskit Aer quantum\ncircuit simulator demonstrate that our trained RL policy can reduce the\noptimality gap by a factor up to 8.61 compared with other off-the-shelf\noptimizers tested.\n", "versions": [{"version": "v1", "created": "Mon, 11 Nov 2019 21:34:33 GMT"}], "update_date": "2019-11-18", "authors_parsed": [["Khairy", "Sami", ""], ["Shaydulin", "Ruslan", ""], ["Cincio", "Lukasz", ""], ["Alexeev", "Yuri", ""], ["Balaprakash", "Prasanna", ""]]}, {"id": "1911.04580", "submitter": "Marvin Coto Mr.", "authors": "Marvin Coto-Jimenez", "title": "Supervised Initialization of LSTM Networks for Fundamental Frequency\n  Detection in Noisy Speech Signals", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SD cs.LG eess.AS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Fundamental frequency is one of the most important parameters of human\nspeech, of importance for the classification of accent, gender, speaking\nstyles, speaker identification, age, among others. The proper detection of this\nparameter remains as an important challenge for severely degraded signals. In\nprevious references for detecting fundamental frequency in noisy speech using\ndeep learning, the networks, such as Long Short-term Memory (LSTM) has been\ninitialized with random weights, and then trained following a back-propagation\nthrough time algorithm. In this work, a proposal for a more efficient\ninitialization, based on a supervised training using an Auto-associative\nnetwork, is presented. This initialization is a better starting point for the\ndetection of fundamental frequency in noisy speech. The advantages of this\ninitialization are noticeable using objective measures for the accuracy of the\ndetection and for the training of the networks, under the presence of additive\nwhite noise at different signal-to-noise levels.\n", "versions": [{"version": "v1", "created": "Mon, 11 Nov 2019 21:57:29 GMT"}], "update_date": "2019-11-13", "authors_parsed": [["Coto-Jimenez", "Marvin", ""]]}, {"id": "1911.04583", "submitter": "Yannet Interian", "authors": "Khoury Ibrahim and Danielle A. Savage and Addie Schnirel and Paul\n  Intrevado and Yannet Interian", "title": "ContamiNet: Detecting Contamination in Municipal Solid Waste", "comments": "8 pages, 3 figures, ICMLA 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Leveraging over 30,000 images each with up to 89 labels collected by\nRecology---an integrated resource recovery company with both residential and\ncommercial trash, recycling and composting services---the authors develop\nContamiNet, a convolutional neural network, to identify contaminating material\nin residential recycling and compost bins. When training the model on a subset\nof labels that meet a minimum frequency threshold, ContamiNet preforms almost\nas well human experts in detecting contamination (0.86 versus 0.88 AUC).\nRecology is actively piloting ContamiNet in their daily municipal solid waste\n(MSW) collection to identify contaminants in recycling and compost bins to\nsubsequently inform and educate customers about best sorting practices.\n", "versions": [{"version": "v1", "created": "Mon, 11 Nov 2019 22:10:40 GMT"}], "update_date": "2019-11-13", "authors_parsed": [["Ibrahim", "Khoury", ""], ["Savage", "Danielle A.", ""], ["Schnirel", "Addie", ""], ["Intrevado", "Paul", ""], ["Interian", "Yannet", ""]]}, {"id": "1911.04587", "submitter": "Xintao Wu", "authors": "Depeng Xu, Shuhan Yuan, Xintao Wu", "title": "Achieving Differential Privacy in Vertically Partitioned Multiparty\n  Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CY cs.DC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Preserving differential privacy has been well studied under centralized\nsetting. However, it's very challenging to preserve differential privacy under\nmultiparty setting, especially for the vertically partitioned case. In this\nwork, we propose a new framework for differential privacy preserving multiparty\nlearning in the vertically partitioned setting. Our core idea is based on the\nfunctional mechanism that achieves differential privacy of the released model\nby adding noise to the objective function. We show the server can simply\ndissect the objective function into single-party and cross-party sub-functions,\nand allocate computation and perturbation of their polynomial coefficients to\nlocal parties. Our method needs only one round of noise addition and secure\naggregation. The released model in our framework achieves the same utility as\napplying the functional mechanism in the centralized setting. Evaluation on\nreal-world and synthetic datasets for linear and logistic regressions shows the\neffectiveness of our proposed method.\n", "versions": [{"version": "v1", "created": "Mon, 11 Nov 2019 22:28:07 GMT"}], "update_date": "2019-11-13", "authors_parsed": [["Xu", "Depeng", ""], ["Yuan", "Shuhan", ""], ["Wu", "Xintao", ""]]}, {"id": "1911.04594", "submitter": "Babak Esmaeili", "authors": "Alican Bozkurt, Babak Esmaeili, Jean-Baptiste Tristan, Dana H. Brooks,\n  Jennifer G. Dy, Jan-Willem van de Meent", "title": "Rate-Regularization and Generalization in VAEs", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Variational autoencoders optimize an objective that combines a reconstruction\nloss (the distortion) and a KL term (the rate). The rate is an upper bound on\nthe mutual information, which is often interpreted as a regularizer that\ncontrols the degree of compression. We here examine whether inclusion of the\nrate also acts as an inductive bias that improves generalization. We perform\nrate-distortion analyses that control the strength of the rate term, the\nnetwork capacity, and the difficulty of the generalization problem. Decreasing\nthe strength of the rate paradoxically improves generalization in most\nsettings, and reducing the mutual information typically leads to underfitting.\nMoreover, we show that generalization continues to improve even after the\nmutual information saturates, indicating that the gap on the bound (i.e. the KL\ndivergence relative to the inference marginal) affects generalization. This\nsuggests that the standard Gaussian prior is not an inductive bias that\ntypically aids generalization, prompting work to understand what choices of\npriors improve generalization in VAEs.\n", "versions": [{"version": "v1", "created": "Mon, 11 Nov 2019 23:06:40 GMT"}, {"version": "v2", "created": "Tue, 7 Jul 2020 02:54:43 GMT"}, {"version": "v3", "created": "Mon, 11 Jan 2021 18:48:43 GMT"}, {"version": "v4", "created": "Wed, 10 Mar 2021 05:56:51 GMT"}, {"version": "v5", "created": "Tue, 16 Mar 2021 17:55:09 GMT"}, {"version": "v6", "created": "Thu, 25 Mar 2021 18:13:55 GMT"}], "update_date": "2021-03-29", "authors_parsed": [["Bozkurt", "Alican", ""], ["Esmaeili", "Babak", ""], ["Tristan", "Jean-Baptiste", ""], ["Brooks", "Dana H.", ""], ["Dy", "Jennifer G.", ""], ["van de Meent", "Jan-Willem", ""]]}, {"id": "1911.04597", "submitter": "Chen Tang", "authors": "Chen Tang, Jianyu Chen, Masayoshi Tomizuka", "title": "Adaptive Probabilistic Vehicle Trajectory Prediction Through Physically\n  Feasible Bayesian Recurrent Neural Network", "comments": "Published as Conference Paper at ICRA 2019", "journal-ref": null, "doi": "10.1109/ICRA.2019.8794130", "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Probabilistic vehicle trajectory prediction is essential for robust safety of\nautonomous driving. Current methods for long-term trajectory prediction cannot\nguarantee the physical feasibility of predicted distribution. Moreover, their\nmodels cannot adapt to the driving policy of the predicted target human driver.\nIn this work, we propose to overcome these two shortcomings by a Bayesian\nrecurrent neural network model consisting of Bayesian-neural-network-based\npolicy model and known physical model of the scenario. Bayesian neural network\ncan ensemble complicated output distribution, enabling rich family of\ntrajectory distribution. The embedded physical model ensures feasibility of the\ndistribution. Moreover, the adopted gradient-based training method allows\ndirect optimization for better performance in long prediction horizon.\nFurthermore, a particle-filter-based parameter adaptation algorithm is designed\nto adapt the policy Bayesian neural network to the predicted target online.\nEffectiveness of the proposed methods is verified with a toy example with\nmulti-modal stochastic feedback gain and naturalistic car following data.\n", "versions": [{"version": "v1", "created": "Mon, 11 Nov 2019 23:13:06 GMT"}], "update_date": "2019-11-13", "authors_parsed": [["Tang", "Chen", ""], ["Chen", "Jianyu", ""], ["Tomizuka", "Masayoshi", ""]]}, {"id": "1911.04606", "submitter": "Dongrui Wu", "authors": "Lubin Meng and Chin-Teng Lin and Tzyy-Ring Jung and Dongrui Wu", "title": "White-Box Target Attack for EEG-Based BCI Regression Problems", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.AI cs.LG eess.SP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Machine learning has achieved great success in many applications, including\nelectroencephalogram (EEG) based brain-computer interfaces (BCIs).\nUnfortunately, many machine learning models are vulnerable to adversarial\nexamples, which are crafted by adding deliberately designed perturbations to\nthe original inputs. Many adversarial attack approaches for classification\nproblems have been proposed, but few have considered target adversarial attacks\nfor regression problems. This paper proposes two such approaches. More\nspecifically, we consider white-box target attacks for regression problems,\nwhere we know all information about the regression model to be attacked, and\nwant to design small perturbations to change the regression output by a\npre-determined amount. Experiments on two BCI regression problems verified that\nboth approaches are effective. Moreover, adversarial examples generated from\nboth approaches are also transferable, which means that we can use adversarial\nexamples generated from one known regression model to attack an unknown\nregression model, i.e., to perform black-box attacks. To our knowledge, this is\nthe first study on adversarial attacks for EEG-based BCI regression problems,\nwhich calls for more attention on the security of BCI systems.\n", "versions": [{"version": "v1", "created": "Thu, 7 Nov 2019 14:52:12 GMT"}], "update_date": "2019-11-13", "authors_parsed": [["Meng", "Lubin", ""], ["Lin", "Chin-Teng", ""], ["Jung", "Tzyy-Ring", ""], ["Wu", "Dongrui", ""]]}, {"id": "1911.04610", "submitter": "Wotao Yin", "authors": "Lei Guan, Wotao Yin, Dongsheng Li and Xicheng Lu", "title": "XPipe: Efficient Pipeline Model Parallelism for Multi-GPU DNN Training", "comments": "9 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.PF", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose XPipe, an efficient asynchronous pipeline model parallelism\napproach for multi-GPU DNN training. XPipe is designed to use multiple GPUs to\nconcurrently and continuously train different parts of a DNN model. To improve\nGPU utilization and achieve high throughput, it splits a mini-batch into a set\nof micro-batches. It allows the overlapping of the pipelines of multiple\nmicro-batches, including those belonging to different mini-batches. Most\nimportantly, the novel weight prediction strategy adopted by XPipe enables it\nto effectively address the weight inconsistency and staleness issues incurred\nby the asynchronous pipeline parallelism. As a result, XPipe incorporates the\nadvantages of both synchronous and asynchronous pipeline model parallelism\napproaches. Concretely, it can achieve very comparable (even slightly better)\nmodel accuracy as its synchronous counterpart while obtaining higher throughput\nthan it. Experimental results show that XPipe outperforms other\nstate-of-the-art synchronous and asynchronous model parallelism approaches.\n", "versions": [{"version": "v1", "created": "Thu, 24 Oct 2019 00:13:54 GMT"}, {"version": "v2", "created": "Wed, 20 Nov 2019 02:42:57 GMT"}, {"version": "v3", "created": "Mon, 9 Nov 2020 12:53:41 GMT"}], "update_date": "2020-11-10", "authors_parsed": [["Guan", "Lei", ""], ["Yin", "Wotao", ""], ["Li", "Dongsheng", ""], ["Lu", "Xicheng", ""]]}, {"id": "1911.04616", "submitter": "Ziheng Chen", "authors": "Ziheng Chen and Hongshik Ahn", "title": "Item Response Theory based Ensemble in Machine Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG stat.AP stat.CO stat.OT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this article, we propose a novel probabilistic framework to improve the\naccuracy of a weighted majority voting algorithm. In order to assign higher\nweights to the classifiers which can correctly classify hard-to-classify\ninstances, we introduce the Item Response Theory (IRT) framework to evaluate\nthe samples' difficulty and classifiers' ability simultaneously. Three models\nare created with different assumptions suitable for different cases. When\nmaking an inference, we keep a balance between the accuracy and complexity. In\nour experiment, all the base models are constructed by single trees via\nbootstrap. To explain the models, we illustrate how the IRT ensemble model\nconstructs the classifying boundary. We also compare their performance with\nother widely used methods and show that our model performs well on 19 datasets.\n", "versions": [{"version": "v1", "created": "Mon, 11 Nov 2019 23:48:18 GMT"}], "update_date": "2019-11-13", "authors_parsed": [["Chen", "Ziheng", ""], ["Ahn", "Hongshik", ""]]}, {"id": "1911.04620", "submitter": "Xintao Wu", "authors": "Panpan Zheng, Shuhan Yuan, Xintao Wu, Yubao Wu", "title": "Identifying Hidden Buyers in Darknet Markets via Dirichlet Hawkes\n  Process", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CY cs.SI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The darknet markets are notorious black markets in cyberspace, which involve\nselling or brokering drugs, weapons, stolen credit cards, and other illicit\ngoods. To combat illicit transactions in the cyberspace, it is important to\nanalyze the behaviors of participants in darknet markets. Currently, many\nstudies focus on studying the behavior of vendors. However, there is no much\nwork on analyzing buyers. The key challenge is that the buyers are anonymized\nin darknet markets. For most of the darknet markets, We only observe the first\nand last digits of a buyer's ID, such as ``a**b''. To tackle this challenge, we\npropose a hidden buyer identification model, called UNMIX, which can group the\ntransactions from one hidden buyer into one cluster given a transaction\nsequence from an anonymized ID. UNMIX is able to model the temporal dynamics\ninformation as well as the product, comment, and vendor information associated\nwith each transaction. As a result, the transactions with similar patterns in\nterms of time and content group together as the subsequence from one hidden\nbuyer. Experiments on the data collected from three real-world darknet markets\ndemonstrate the effectiveness of our approach measured by various clustering\nmetrics. Case studies on real transaction sequences explicitly show that our\napproach can group transactions with similar patterns into the same clusters.\n", "versions": [{"version": "v1", "created": "Tue, 12 Nov 2019 00:17:29 GMT"}], "update_date": "2019-11-13", "authors_parsed": [["Zheng", "Panpan", ""], ["Yuan", "Shuhan", ""], ["Wu", "Xintao", ""], ["Wu", "Yubao", ""]]}, {"id": "1911.04628", "submitter": "Alan Yang", "authors": "Alan Yang and AmirEmad Ghassami and Maxim Raginsky and Negar Kiyavash\n  and Elyse Rosenbaum", "title": "Model-Augmented Estimation of Conditional Mutual Information for Feature\n  Selection", "comments": "Accepted to UAI 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Markov blanket feature selection, while theoretically optimal, is generally\nchallenging to implement. This is due to the shortcomings of existing\napproaches to conditional independence (CI) testing, which tend to struggle\neither with the curse of dimensionality or computational complexity. We propose\na novel two-step approach which facilitates Markov blanket feature selection in\nhigh dimensions. First, neural networks are used to map features to\nlow-dimensional representations. In the second step, CI testing is performed by\napplying the $k$-NN conditional mutual information estimator to the learned\nfeature maps. The mappings are designed to ensure that mapped samples both\npreserve information and share similar information about the target variable if\nand only if they are close in Euclidean distance. We show that these properties\nboost the performance of the $k$-NN estimator in the second step. The\nperformance of the proposed method is evaluated on both synthetic and real\ndata.\n", "versions": [{"version": "v1", "created": "Tue, 12 Nov 2019 01:20:54 GMT"}, {"version": "v2", "created": "Mon, 24 Feb 2020 20:45:53 GMT"}, {"version": "v3", "created": "Fri, 19 Jun 2020 20:38:29 GMT"}], "update_date": "2020-06-23", "authors_parsed": [["Yang", "Alan", ""], ["Ghassami", "AmirEmad", ""], ["Raginsky", "Maxim", ""], ["Kiyavash", "Negar", ""], ["Rosenbaum", "Elyse", ""]]}, {"id": "1911.04636", "submitter": "Arash Rahnama", "authors": "Arash Rahnama, Andre T. Nguyen and Edward Raff", "title": "Robust Design of Deep Neural Networks against Adversarial Attacks based\n  on Lyapunov Theory", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.SY eess.SY stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep neural networks (DNNs) are vulnerable to subtle adversarial\nperturbations applied to the input. These adversarial perturbations, though\nimperceptible, can easily mislead the DNN. In this work, we take a control\ntheoretic approach to the problem of robustness in DNNs. We treat each\nindividual layer of the DNN as a nonlinear dynamical system and use Lyapunov\ntheory to prove stability and robustness locally. We then proceed to prove\nstability and robustness globally for the entire DNN. We develop empirically\ntight bounds on the response of the output layer, or any hidden layer, to\nadversarial perturbations added to the input, or the input of hidden layers.\nRecent works have proposed spectral norm regularization as a solution for\nimproving robustness against l2 adversarial attacks. Our results give new\ninsights into how spectral norm regularization can mitigate the adversarial\neffects. Finally, we evaluate the power of our approach on a variety of data\nsets and network architectures and against some of the well-known adversarial\nattacks.\n", "versions": [{"version": "v1", "created": "Tue, 12 Nov 2019 02:17:01 GMT"}], "update_date": "2019-11-13", "authors_parsed": [["Rahnama", "Arash", ""], ["Nguyen", "Andre T.", ""], ["Raff", "Edward", ""]]}, {"id": "1911.04644", "submitter": "Qinglong Wang", "authors": "Qinglong Wang, Kaixuan Zhang, Xue Liu, C. Lee Giles", "title": "Connecting First and Second Order Recurrent Networks with Deterministic\n  Finite Automata", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose an approach that connects recurrent networks with different orders\nof hidden interaction with regular grammars of different levels of complexity.\nWe argue that the correspondence between recurrent networks and formal\ncomputational models gives understanding to the analysis of the complicated\nbehaviors of recurrent networks. We introduce an entropy value that categorizes\nall regular grammars into three classes with different levels of complexity,\nand show that several existing recurrent networks match grammars from either\nall or partial classes. As such, the differences between regular grammars\nreveal the different properties of these models. We also provide a unification\nof all investigated recurrent networks. Our evaluation shows that the unified\nrecurrent network has improved performance in learning grammars, and\ndemonstrates comparable performance on a real-world dataset with more\ncomplicated models.\n", "versions": [{"version": "v1", "created": "Tue, 12 Nov 2019 03:05:15 GMT"}], "update_date": "2019-11-13", "authors_parsed": [["Wang", "Qinglong", ""], ["Zhang", "Kaixuan", ""], ["Liu", "Xue", ""], ["Giles", "C. Lee", ""]]}, {"id": "1911.04650", "submitter": "Wumo Yan", "authors": "Zhuojin Li, Wumo Yan, Marco Paolieri, Leana Golubchik", "title": "Throughput Prediction of Asynchronous SGD in TensorFlow", "comments": null, "journal-ref": null, "doi": "10.1145/3358960.3379141", "report-no": null, "categories": "cs.DC cs.LG cs.PF", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Modern machine learning frameworks can train neural networks using multiple\nnodes in parallel, each computing parameter updates with stochastic gradient\ndescent (SGD) and sharing them asynchronously through a central parameter\nserver. Due to communication overhead and bottlenecks, the total throughput of\nSGD updates in a cluster scales sublinearly, saturating as the number of nodes\nincreases. In this paper, we present a solution to predicting training\nthroughput from profiling traces collected from a single-node configuration.\nOur approach is able to model the interaction of multiple nodes and the\nscheduling of concurrent transmissions between the parameter server and each\nnode. By accounting for the dependencies between received parts and pending\ncomputations, we predict overlaps between computation and communication and\ngenerate synthetic execution traces for configurations with multiple nodes. We\nvalidate our approach on TensorFlow training jobs for popular image\nclassification neural networks, on AWS and on our in-house cluster, using nodes\nequipped with GPUs or only with CPUs. We also investigate the effects of data\ntransmission policies used in TensorFlow and the accuracy of our approach when\ncombined with optimizations of the transmission schedule.\n", "versions": [{"version": "v1", "created": "Tue, 12 Nov 2019 03:17:20 GMT"}, {"version": "v2", "created": "Fri, 28 Feb 2020 06:32:31 GMT"}], "update_date": "2020-03-02", "authors_parsed": [["Li", "Zhuojin", ""], ["Yan", "Wumo", ""], ["Paolieri", "Marco", ""], ["Golubchik", "Leana", ""]]}, {"id": "1911.04651", "submitter": "Ainaz Hajimoradlou", "authors": "Ainaz Hajimoradlou, Gioachino Roberti, David Poole", "title": "Predicting Landslides Using Locally Aligned Convolutional Neural\n  Networks", "comments": "Published in IJCAI 2020", "journal-ref": null, "doi": "10.24963/ijcai.2020/462", "report-no": null, "categories": "cs.CV cs.LG", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Landslides, movement of soil and rock under the influence of gravity, are\ncommon phenomena that cause significant human and economic losses every year.\nExperts use heterogeneous features such as slope, elevation, land cover,\nlithology, rock age, and rock family to predict landslides. To work with such\nfeatures, we adapted convolutional neural networks to consider relative spatial\ninformation for the prediction task. Traditional filters in these networks\neither have a fixed orientation or are rotationally invariant. Intuitively, the\nfilters should orient uphill, but there is not enough data to learn the concept\nof uphill; instead, it can be provided as prior knowledge. We propose a model\ncalled Locally Aligned Convolutional Neural Network, LACNN, that follows the\nground surface at multiple scales to predict possible landslide occurrence for\na single point. To validate our method, we created a standardized dataset of\ngeoreferenced images consisting of the heterogeneous features as inputs, and\ncompared our method to several baselines, including linear regression, a neural\nnetwork, and a convolutional network, using log-likelihood error and Receiver\nOperating Characteristic curves on the test set. Our model achieves 2-7%\nimprovement in terms of accuracy and 2-15% boost in terms of log likelihood\ncompared to the other proposed baselines.\n", "versions": [{"version": "v1", "created": "Tue, 12 Nov 2019 03:21:53 GMT"}, {"version": "v2", "created": "Thu, 6 Feb 2020 01:57:23 GMT"}, {"version": "v3", "created": "Tue, 28 Apr 2020 04:19:41 GMT"}, {"version": "v4", "created": "Wed, 29 Apr 2020 03:24:03 GMT"}, {"version": "v5", "created": "Fri, 17 Jul 2020 18:13:17 GMT"}], "update_date": "2020-07-21", "authors_parsed": [["Hajimoradlou", "Ainaz", ""], ["Roberti", "Gioachino", ""], ["Poole", "David", ""]]}, {"id": "1911.04654", "submitter": "Xinyan Dai", "authors": "Xinyan Dai, Xiao Yan, Kelvin K. W. Ng, Jie Liu, James Cheng", "title": "Norm-Explicit Quantization: Improving Vector Quantization for Maximum\n  Inner Product Search", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Vector quantization (VQ) techniques are widely used in similarity search for\ndata compression, fast metric computation and etc. Originally designed for\nEuclidean distance, existing VQ techniques (e.g., PQ, AQ) explicitly or\nimplicitly minimize the quantization error. In this paper, we present a new\nangle to analyze the quantization error, which decomposes the quantization\nerror into norm error and direction error. We show that quantization errors in\nnorm have much higher influence on inner products than quantization errors in\ndirection, and small quantization error does not necessarily lead to good\nperformance in maximum inner product search (MIPS). Based on this observation,\nwe propose norm-explicit quantization (NEQ) --- a general paradigm that\nimproves existing VQ techniques for MIPS. NEQ quantizes the norms of items in a\ndataset explicitly to reduce errors in norm, which is crucial for MIPS. For the\ndirection vectors, NEQ can simply reuse an existing VQ technique to quantize\nthem without modification. We conducted extensive experiments on a variety of\ndatasets and parameter configurations. The experimental results show that NEQ\nimproves the performance of various VQ techniques for MIPS, including PQ, OPQ,\nRQ and AQ.\n", "versions": [{"version": "v1", "created": "Tue, 12 Nov 2019 03:35:17 GMT"}, {"version": "v2", "created": "Wed, 20 Nov 2019 05:56:21 GMT"}], "update_date": "2019-11-21", "authors_parsed": [["Dai", "Xinyan", ""], ["Yan", "Xiao", ""], ["Ng", "Kelvin K. W.", ""], ["Liu", "Jie", ""], ["Cheng", "James", ""]]}, {"id": "1911.04655", "submitter": "Xinyan Dai", "authors": "Xinyan Dai, Xiao Yan, Kaiwen Zhou, Han Yang, Kelvin K. W. Ng, James\n  Cheng, Yu Fan", "title": "Hyper-Sphere Quantization: Communication-Efficient SGD for Federated\n  Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.IR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The high cost of communicating gradients is a major bottleneck for federated\nlearning, as the bandwidth of the participating user devices is limited.\nExisting gradient compression algorithms are mainly designed for data centers\nwith high-speed network and achieve $O(\\sqrt{d} \\log d)$ per-iteration\ncommunication cost at best, where $d$ is the size of the model. We propose\nhyper-sphere quantization (HSQ), a general framework that can be configured to\nachieve a continuum of trade-offs between communication efficiency and gradient\naccuracy. In particular, at the high compression ratio end, HSQ provides a low\nper-iteration communication cost of $O(\\log d)$, which is favorable for\nfederated learning. We prove the convergence of HSQ theoretically and show by\nexperiments that HSQ significantly reduces the communication cost of model\ntraining without hurting convergence accuracy.\n", "versions": [{"version": "v1", "created": "Tue, 12 Nov 2019 03:36:09 GMT"}, {"version": "v2", "created": "Mon, 25 Nov 2019 11:00:41 GMT"}], "update_date": "2019-11-26", "authors_parsed": [["Dai", "Xinyan", ""], ["Yan", "Xiao", ""], ["Zhou", "Kaiwen", ""], ["Yang", "Han", ""], ["Ng", "Kelvin K. W.", ""], ["Cheng", "James", ""], ["Fan", "Yu", ""]]}, {"id": "1911.04660", "submitter": "Juliano Henrique Foleiss", "authors": "Juliano Henrique Foleiss, Tiago Fernandes Tavares", "title": "Random Projections of Mel-Spectrograms as Low-Level Features for\n  Automatic Music Genre Classification", "comments": "Submitted to IEEE Signal Processing Letters", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SD cs.IR cs.LG eess.AS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this work, we analyse the random projections of Mel-spectrograms as\nlow-level features for music genre classification. This approach was compared\nto handcrafted features, features learned using an auto-encoder and features\nobtained from a transfer learning setting. Tests in five different well-known,\npublicly available datasets show that random projections leads to results\ncomparable to learned features and outperforms features obtained via transfer\nlearning in a shallow learning scenario. Random projections do not require\nusing extensive specialist knowledge and, simultaneously, requires less\ncomputational power for training than other projection-based low-level\nfeatures. Therefore, they can be are a viable choice for usage in shallow\nlearning content-based music genre classification.\n", "versions": [{"version": "v1", "created": "Tue, 12 Nov 2019 03:58:11 GMT"}], "update_date": "2019-11-13", "authors_parsed": [["Foleiss", "Juliano Henrique", ""], ["Tavares", "Tiago Fernandes", ""]]}, {"id": "1911.04666", "submitter": "Juliano Henrique Foleiss", "authors": "Juliano Henrique Foleiss, Tiago Fernandes Tavares", "title": "Segment Relevance Estimation for Audio Analysis and Weakly-Labelled\n  Classification", "comments": "Submitted to IEEE Signal Processing Letters", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.AS cs.LG cs.SD", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a method that quantifies the importance, namely relevance, of\naudio segments for classification in weakly-labelled problems. It works by\ndrawing information from a set of class-wise one-vs-all classifiers. By\nselecting the classifiers used in each specific classification problem, the\nrelevance measure adapts to different user-defined viewpoints without requiring\nadditional neural network training. This characteristic allows the relevance\nmeasure to highlight audio segments that quickly adapt to user-defined\ncriteria. Such functionality can be used for computer-assisted audio analysis.\nAlso, we propose a neural network architecture, namely RELNET, that leverages\nthe relevance measure for weakly-labelled audio classification problems. RELNET\nwas evaluated in the DCASE2018 dataset and achieved competitive classification\nresults when compared to previous attention-based proposals.\n", "versions": [{"version": "v1", "created": "Tue, 12 Nov 2019 04:19:43 GMT"}], "update_date": "2019-11-13", "authors_parsed": [["Foleiss", "Juliano Henrique", ""], ["Tavares", "Tiago Fernandes", ""]]}, {"id": "1911.04669", "submitter": "Yekun Chai", "authors": "Yekun Chai, Naomi Saphra, Adam Lopez", "title": "How to Evaluate Word Representations of Informal Domain?", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.IR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Diverse word representations have surged in most state-of-the-art natural\nlanguage processing (NLP) applications. Nevertheless, how to efficiently\nevaluate such word embeddings in the informal domain such as Twitter or forums,\nremains an ongoing challenge due to the lack of sufficient evaluation dataset.\nWe derived a large list of variant spelling pairs from UrbanDictionary with the\nautomatic approaches of weakly-supervised pattern-based bootstrapping and\nself-training linear-chain conditional random field (CRF). With these extracted\nrelation pairs we promote the odds of eliding the text normalization procedure\nof traditional NLP pipelines and directly adopting representations of\nnon-standard words in the informal domain. Our code is available.\n", "versions": [{"version": "v1", "created": "Tue, 12 Nov 2019 04:38:19 GMT"}, {"version": "v2", "created": "Wed, 13 Nov 2019 04:32:00 GMT"}], "update_date": "2019-11-14", "authors_parsed": [["Chai", "Yekun", ""], ["Saphra", "Naomi", ""], ["Lopez", "Adam", ""]]}, {"id": "1911.04676", "submitter": "Indraneel Patil", "authors": "Indraneel Patil, B.K. Rout, V. Kalaichelvi", "title": "Prediction of Bottleneck Points for Manipulation Planning in Cluttered\n  Environment using a 3D Convolutional Neural Network", "comments": "7 pages, 12 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.AI cs.DS cs.LG cs.SY eess.SY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Latest research in industrial robotics is aimed at making human robot\ncollaboration possible seamlessly. For this purpose, industrial robots are\nexpected to work on the fly in unstructured and cluttered environments and\nhence the subject of perception driven motion planning plays a vital role.\nSampling based motion planners are proven to be the most effective for such\nhigh dimensional planning problems with real time constraints. Unluckily random\nstochastic samplers suffer from the phenomenon of 'narrow passages' or\nbottleneck regions which need targeted sampling to improve their convergence\nrate. Also identifying these bottleneck regions in a diverse set of planning\nproblems is a challenge. In this paper an attempt has been made to address\nthese two problems by designing an intelligent 'bottleneck guided' heuristic\nfor a Rapidly Exploring Random Tree Star (RRT*) planner which is based on\nrelevant context extracted from the planning scenario using a 3D Convolutional\nNeural Network and it is also proven that the proposed technique generalises to\nunseen problem instances. This paper benchmarks the technique (bottleneck\nguided RRT*) against a 10% Goal biased RRT star planner, shows significant\nimprovement in planning time and memory requirement and uses ABB 1410\nindustrial manipulator as a platform for implantation and validation of the\nresults.\n", "versions": [{"version": "v1", "created": "Tue, 12 Nov 2019 05:16:40 GMT"}], "update_date": "2019-11-13", "authors_parsed": [["Patil", "Indraneel", ""], ["Rout", "B. K.", ""], ["Kalaichelvi", "V.", ""]]}, {"id": "1911.04681", "submitter": "Abhratanu Dutta", "authors": "Pranjal Awasthi, Abhratanu Dutta and Aravindan Vijayaraghavan", "title": "On Robustness to Adversarial Examples and Polynomial Optimization", "comments": "To appear at NeurIPS2019. 30 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.DS stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the design of computationally efficient algorithms with provable\nguarantees, that are robust to adversarial (test time) perturbations. While\nthere has been an proliferation of recent work on this topic due to its\nconnections to test time robustness of deep networks, there is limited\ntheoretical understanding of several basic questions like (i) when and how can\none design provably robust learning algorithms? (ii) what is the price of\nachieving robustness to adversarial examples in a computationally efficient\nmanner?\n  The main contribution of this work is to exhibit a strong connection between\nachieving robustness to adversarial examples, and a rich class of polynomial\noptimization problems, thereby making progress on the above questions. In\nparticular, we leverage this connection to (a) design computationally efficient\nrobust algorithms with provable guarantees for a large class of hypothesis,\nnamely linear classifiers and degree-2 polynomial threshold functions (PTFs),\n(b) give a precise characterization of the price of achieving robustness in a\ncomputationally efficient manner for these classes, (c) design efficient\nalgorithms to certify robustness and generate adversarial attacks in a\nprincipled manner for 2-layer neural networks. We empirically demonstrate the\neffectiveness of these attacks on real data.\n", "versions": [{"version": "v1", "created": "Tue, 12 Nov 2019 05:33:06 GMT"}], "update_date": "2019-11-13", "authors_parsed": [["Awasthi", "Pranjal", ""], ["Dutta", "Abhratanu", ""], ["Vijayaraghavan", "Aravindan", ""]]}, {"id": "1911.04687", "submitter": "Marcel B\\\"ohme", "authors": "Marcel B\\\"ohme", "title": "MCPA: Program Analysis as Machine Learning", "comments": "10+2 pages. Feedback and (industry/research) collaborations welcome", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SE cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Static program analysis today takes an analytical approach which is quite\nsuitable for a well-scoped system. Data- and control-flow is taken into\naccount. Special cases such as pointers, procedures, and undefined behavior\nmust be handled. A program is analyzed precisely on the statement level.\nHowever, the analytical approach is ill-equiped to handle implementations of\ncomplex, large-scale, heterogeneous software systems we see in the real world.\nExisting static analysis techniques that scale, trade correctness (i.e.,\nsoundness or completeness) for scalability and build on strong assumptions\n(e.g., language-specificity). Scalable static analysis are well-known to report\nerrors that do *not* exist (false positives) or fail to report errors that *do*\nexist (false negatives). Then, how do we know the degree to which the analysis\noutcome is correct?\n  In this paper, we propose an approach to scale-oblivious greybox program\nanalysis with bounded error which applies efficient approximation schemes\n(FPRAS) from the foundations of machine learning: PAC learnability. Given two\nparameters $\\delta$ and $\\epsilon$, with probability at least $(1-\\delta)$, our\nMonte Carlo Program Analysis (MCPA) approach produces an outcome that has an\naverage error at most $\\epsilon$. The parameters $\\delta>0$ and $\\epsilon>0$\ncan be chosen arbitrarily close to zero (0) such that the program analysis\noutcome is said to be probably-approximately correct (PAC). We demonstrate the\npertinent concepts of MCPA using three applications:\n$(\\epsilon,\\delta)$-approximate quantitative analysis,\n$(\\epsilon,\\delta)$-approximate software verification, and\n$(\\epsilon,\\delta)$-approximate patch verification.\n", "versions": [{"version": "v1", "created": "Tue, 12 Nov 2019 05:50:29 GMT"}], "update_date": "2019-11-13", "authors_parsed": [["B\u00f6hme", "Marcel", ""]]}, {"id": "1911.04690", "submitter": "Kerl Chen", "authors": "Wenqiang Chen, Lizhang Zhan, Yuanlong Ci, Minghua Yang, Chen Lin,\n  Dugang Liu", "title": "FLEN: Leveraging Field for Scalable CTR Prediction", "comments": "KDD'20 DLP workshop, 9 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Click-Through Rate (CTR) prediction has been an indispensable component for\nmany industrial applications, such as recommendation systems and online\nadvertising. CTR prediction systems are usually based on multi-field\ncategorical features, i.e., every feature is categorical and belongs to one and\nonly one field. Modeling feature conjunctions is crucial for CTR prediction\naccuracy. However, it requires a massive number of parameters to explicitly\nmodel all feature conjunctions, which is not scalable for real-world production\nsystems. In this paper, we describe a novel Field-Leveraged Embedding Network\n(FLEN) which has been deployed in the commercial recommender system in Meitu\nand serves the main traffic. FLEN devises a field-wise bi-interaction pooling\ntechnique. By suitably exploiting field information, the field-wise\nbi-interaction pooling captures both inter-field and intra-field feature\nconjunctions with a small number of model parameters and an acceptable time\ncomplexity for industrial applications. We show that a variety of\nstate-of-the-art CTR models can be expressed under this technique. Furthermore,\nwe develop Dicefactor: a dropout technique to prevent independent latent\nfeatures from co-adapting. Extensive experiments, including offline evaluations\nand online A/B testing on real production systems, demonstrate the\neffectiveness and efficiency of FLEN against the state-of-the-arts. Notably,\nFLEN has obtained 5.19% improvement on CTR with 1/6 of memory usage and\ncomputation time, compared to last version (i.e. NFM).\n", "versions": [{"version": "v1", "created": "Tue, 12 Nov 2019 05:54:45 GMT"}, {"version": "v2", "created": "Wed, 29 Jan 2020 11:15:39 GMT"}, {"version": "v3", "created": "Tue, 3 Mar 2020 06:46:18 GMT"}, {"version": "v4", "created": "Mon, 28 Sep 2020 10:22:19 GMT"}], "update_date": "2020-09-29", "authors_parsed": [["Chen", "Wenqiang", ""], ["Zhan", "Lizhang", ""], ["Ci", "Yuanlong", ""], ["Yang", "Minghua", ""], ["Lin", "Chen", ""], ["Liu", "Dugang", ""]]}, {"id": "1911.04695", "submitter": "Yadan Luo", "authors": "Yadan Luo, Zi Huang, Zheng Zhang, Ziwei Wang, Mahsa Baktashmotlagh,\n  Yang Yang", "title": "Learning from the Past: Continual Meta-Learning via Bayesian Graph\n  Modeling", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Meta-learning for few-shot learning allows a machine to leverage previously\nacquired knowledge as a prior, thus improving the performance on novel tasks\nwith only small amounts of data. However, most mainstream models suffer from\ncatastrophic forgetting and insufficient robustness issues, thereby failing to\nfully retain or exploit long-term knowledge while being prone to cause severe\nerror accumulation. In this paper, we propose a novel Continual Meta-Learning\napproach with Bayesian Graph Neural Networks (CML-BGNN) that mathematically\nformulates meta-learning as continual learning of a sequence of tasks. With\neach task forming as a graph, the intra- and inter-task correlations can be\nwell preserved via message-passing and history transition. To remedy\ntopological uncertainty from graph initialization, we utilize Bayes by Backprop\nstrategy that approximates the posterior distribution of task-specific\nparameters with amortized inference networks, which are seamlessly integrated\ninto the end-to-end edge learning. Extensive experiments conducted on the\nminiImageNet and tieredImageNet datasets demonstrate the effectiveness and\nefficiency of the proposed method, improving the performance by 42.8% compared\nwith state-of-the-art on the miniImageNet 5-way 1-shot classification task.\n", "versions": [{"version": "v1", "created": "Tue, 12 Nov 2019 06:10:11 GMT"}], "update_date": "2019-11-13", "authors_parsed": [["Luo", "Yadan", ""], ["Huang", "Zi", ""], ["Zhang", "Zheng", ""], ["Wang", "Ziwei", ""], ["Baktashmotlagh", "Mahsa", ""], ["Yang", "Yang", ""]]}, {"id": "1911.04699", "submitter": "Sambuddha Ghosal", "authors": "John Just and Sambuddha Ghosal", "title": "Deep Generative Models Strike Back! Improving Understanding and\n  Evaluation in Light of Unmet Expectations for OoD Data", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Advances in deep generative and density models have shown impressive capacity\nto model complex probability density functions in lower-dimensional space.\nAlso, applying such models to high-dimensional image data to model the PDF has\nshown poor generalization, with out-of-distribution data being assigned equal\nor higher likelihood than in-sample data. Methods to deal with this have been\nproposed that deviate from a fully unsupervised approach, requiring large\nensembles or additional knowledge about the data, not commonly available in the\nreal-world. In this work, the previously offered reasoning behind these issues\nis challenged empirically, and it is shown that data-sets such as MNIST\nfashion/digits and CIFAR10/SVHN are trivially separable and have no overlap on\ntheir respective data manifolds that explains the higher OoD likelihood. Models\nlike masked autoregressive flows and block neural autoregressive flows are\nshown to not suffer from OoD likelihood issues to the extent of GLOW,\nPixelCNN++, and real NVP. A new avenue is also explored which involves a change\nof basis to a new space of the same dimension with an orthonormal unitary basis\nof eigenvectors before modeling. In the test data-sets and models, this aids in\npushing down the relative likelihood of the contrastive OoD data set and\nimprove discrimination results. The significance of the density of the original\nspace is maintained, while invertibility remains tractable. Finally, a look to\nthe previous generation of generative models in the form of probabilistic\nprincipal component analysis is inspired, and revisited for the same data-sets\nand shown to work really well for discriminating anomalies based on likelihood\nin a fully unsupervised fashion compared with pixelCNN++, GLOW, and real NVP\nwith less complexity and faster training. Also, dimensionality reduction using\nPCA is shown to improve anomaly detection in generative models.\n", "versions": [{"version": "v1", "created": "Tue, 12 Nov 2019 06:41:22 GMT"}], "update_date": "2019-11-13", "authors_parsed": [["Just", "John", ""], ["Ghosal", "Sambuddha", ""]]}, {"id": "1911.04700", "submitter": "Yinhe Zheng Dr.", "authors": "Yinhe Zheng, Rongsheng Zhang, Xiaoxi Mao, Minlie Huang", "title": "A Pre-training Based Personalized Dialogue Generation Model with\n  Persona-sparse Data", "comments": "Long paper accepted at AAAI 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Endowing dialogue systems with personas is essential to deliver more\nhuman-like conversations. However, this problem is still far from well explored\ndue to the difficulties of both embodying personalities in natural languages\nand the persona sparsity issue observed in most dialogue corpora. This paper\nproposes a pre-training based personalized dialogue model that can generate\ncoherent responses using persona-sparse dialogue data. In this method, a\npre-trained language model is used to initialize an encoder and decoder, and\npersonal attribute embeddings are devised to model richer dialogue contexts by\nencoding speakers' personas together with dialogue histories. Further, to\nincorporate the target persona in the decoding process and to balance its\ncontribution, an attention routing structure is devised in the decoder to merge\nfeatures extracted from the target persona and dialogue contexts using\ndynamically predicted weights. Our model can utilize persona-sparse dialogues\nin a unified manner during the training process, and can also control the\namount of persona-related features to exhibit during the inference process.\nBoth automatic and manual evaluation demonstrates that the proposed model\noutperforms state-of-the-art methods for generating more coherent and persona\nconsistent responses with persona-sparse data.\n", "versions": [{"version": "v1", "created": "Tue, 12 Nov 2019 07:13:42 GMT"}], "update_date": "2019-11-13", "authors_parsed": [["Zheng", "Yinhe", ""], ["Zhang", "Rongsheng", ""], ["Mao", "Xiaoxi", ""], ["Huang", "Minlie", ""]]}, {"id": "1911.04705", "submitter": "Ali Hassani", "authors": "Ali Hassani, Amir Iranmanesh, Najme Mansouri", "title": "Text Mining using Nonnegative Matrix Factorization and Latent Semantic\n  Analysis", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Text clustering is arguably one of the most important topics in modern data\nmining. Nevertheless, text data require tokenization which usually yields a\nvery large and highly sparse term-document matrix, which is usually difficult\nto process using conventional machine learning algorithms. Methods such as\nLatent Semantic Analysis have helped mitigate this issue, but are nevertheless\nnot completely stable in practice. As a result, we propose a new feature\nagglomeration method based on Nonnegative Matrix Factorization, which is\nemployed to separate the terms into groups, and then each group's term vectors\nare agglomerated into a new feature vector. Together, these feature vectors\ncreate a new feature space much more suitable for clustering. In addition, we\npropose a new deterministic initialization for spherical K-Means, which proves\nvery useful for this specific type of data. In order to evaluate the proposed\nmethod, we compare it to some of the latest research done in this field, as\nwell as some of the most practiced methods. In our experiments, we conclude\nthat the proposed method either significantly improves clustering performance,\nor maintains the performance of other methods, while improving stability in\nresults.\n", "versions": [{"version": "v1", "created": "Tue, 12 Nov 2019 07:30:46 GMT"}, {"version": "v2", "created": "Sun, 29 Dec 2019 10:13:47 GMT"}, {"version": "v3", "created": "Mon, 24 Feb 2020 07:47:52 GMT"}], "update_date": "2020-02-25", "authors_parsed": [["Hassani", "Ali", ""], ["Iranmanesh", "Amir", ""], ["Mansouri", "Najme", ""]]}, {"id": "1911.04706", "submitter": "Chi Wang", "authors": "Chi Wang, Qingyun Wu, Markus Weimer, and Erkang Zhu", "title": "FLAML: A Fast and Lightweight AutoML Library", "comments": "14 pages, published in Fourth Conference on Machine Learning and\n  Systems (MLSys 2021)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the problem of using low computational cost to automate the choices\nof learners and hyperparameters for an ad-hoc training dataset and error\nmetric, by conducting trials of different configurations on the given training\ndata. We investigate the joint impact of multiple factors on both trial cost\nand model error, and propose several design guidelines. Following them, we\nbuild a fast and lightweight library FLAML which optimizes for low\ncomputational resource in finding accurate models. FLAML integrates several\nsimple but effective search strategies into an adaptive system. It\nsignificantly outperforms top-ranked AutoML libraries on a large open source\nAutoML benchmark under equal, or sometimes orders of magnitude smaller budget\nconstraints.\n", "versions": [{"version": "v1", "created": "Tue, 12 Nov 2019 07:33:35 GMT"}, {"version": "v2", "created": "Tue, 22 Dec 2020 07:57:36 GMT"}, {"version": "v3", "created": "Wed, 19 May 2021 00:34:30 GMT"}], "update_date": "2021-05-20", "authors_parsed": [["Wang", "Chi", ""], ["Wu", "Qingyun", ""], ["Weimer", "Markus", ""], ["Zhu", "Erkang", ""]]}, {"id": "1911.04738", "submitter": "Shion Honda", "authors": "Shion Honda, Shoi Shi, Hiroki R. Ueda", "title": "SMILES Transformer: Pre-trained Molecular Fingerprint for Low Data Drug\n  Discovery", "comments": "9 pages, 4 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In drug-discovery-related tasks such as virtual screening, machine learning\nis emerging as a promising way to predict molecular properties. Conventionally,\nmolecular fingerprints (numerical representations of molecules) are calculated\nthrough rule-based algorithms that map molecules to a sparse discrete space.\nHowever, these algorithms perform poorly for shallow prediction models or small\ndatasets. To address this issue, we present SMILES Transformer. Inspired by\nTransformer and pre-trained language models from natural language processing,\nSMILES Transformer learns molecular fingerprints through unsupervised\npre-training of the sequence-to-sequence language model using a huge corpus of\nSMILES, a text representation system for molecules. We performed benchmarks on\n10 datasets against existing fingerprints and graph-based methods and\ndemonstrated the superiority of the proposed algorithms in small-data settings\nwhere pre-training facilitated good generalization. Moreover, we define a novel\nmetric to concurrently measure model accuracy and data efficiency.\n", "versions": [{"version": "v1", "created": "Tue, 12 Nov 2019 08:44:49 GMT"}], "update_date": "2019-11-13", "authors_parsed": [["Honda", "Shion", ""], ["Shi", "Shoi", ""], ["Ueda", "Hiroki R.", ""]]}, {"id": "1911.04759", "submitter": "Mehdi Mirzapour", "authors": "K\\'evin Cousot (TEXTE), Mehdi Mirzapour (TEXTE), Waleed Ragheb\n  (ADVANSE)", "title": "Prediction of Missing Semantic Relations in Lexical-Semantic Network\n  using Random Forest Classifier", "comments": null, "journal-ref": "CJC PRAXILING 2019, Nov 2019, Montpellier, France", "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This study focuses on the prediction of missing six semantic relations (such\nas is_a and has_part) between two given nodes in RezoJDM a French\nlexical-semantic network. The output of this prediction is a set of pairs in\nwhich the first entries are semantic relations and the second entries are the\nprobabilities of existence of such relations. Due to the statement of the\nproblem we choose the random forest (RF) predictor classifier approach to\ntackle this problem. We take for granted the existing semantic relations, for\ntraining/test dataset, gathered and validated by crowdsourcing. We describe how\nall of the mentioned ideas can be followed after using the node2vec approach in\nthe feature extraction phase. We show how this approach can lead to acceptable\nresults.\n", "versions": [{"version": "v1", "created": "Tue, 12 Nov 2019 09:41:44 GMT"}], "update_date": "2019-11-13", "authors_parsed": [["Cousot", "K\u00e9vin", "", "TEXTE"], ["Mirzapour", "Mehdi", "", "TEXTE"], ["Ragheb", "Waleed", "", "ADVANSE"]]}, {"id": "1911.04787", "submitter": "David Paulus", "authors": "David Paulus, Gerdien de Vries, Bartel Van de Walle", "title": "Effects of data ambiguity and cognitive biases on the interpretability\n  of machine learning models in humanitarian decision making", "comments": "3 pager, 1 figure, AAAI Fall Symposium - AI for Social Good, November\n  7-9, 2019, Arlington, USA", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.HC stat.ML", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  The effectiveness of machine learning algorithms depends on the quality and\namount of data and the operationalization and interpretation by the human\nanalyst. In humanitarian response, data is often lacking or overburdening, thus\nambiguous, and the time-scarce, volatile, insecure environments of humanitarian\nactivities are likely to inflict cognitive biases. This paper proposes to\nresearch the effects of data ambiguity and cognitive biases on the\ninterpretability of machine learning algorithms in humanitarian decision\nmaking.\n", "versions": [{"version": "v1", "created": "Tue, 12 Nov 2019 10:50:42 GMT"}], "update_date": "2019-11-13", "authors_parsed": [["Paulus", "David", ""], ["de Vries", "Gerdien", ""], ["Van de Walle", "Bartel", ""]]}, {"id": "1911.04801", "submitter": "Ruoyun Chen", "authors": "Ruoyun Chen, Hancheng Lu, Yujiao Lu, Jinxue Liu", "title": "MSDF: A Deep Reinforcement Learning Framework for Service Function Chain\n  Migration", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Under dynamic traffic, service function chain (SFC) migration is considered\nas an effective way to improve resource utilization. However, the lack of\nfuture network information leads to non-optimal solutions, which motivates us\nto study reinforcement learning based SFC migration from a long-term\nperspective. In this paper, we formulate the SFC migration problem as a\nminimization problem with the objective of total network operation cost under\nconstraints of users' quality of service. We firstly design a deep Q-network\nbased algorithm to solve single SFC migration problem, which can adjust\nmigration strategy online without knowing future information. Further, a novel\nmulti-agent cooperative framework, called MSDF, is proposed to address the\nchallenge of considering multiple SFC migration on the basis of single SFC\nmigration. MSDF reduces the complexity thus accelerates the convergence speed,\nespecially in large scale networks. Experimental results demonstrate that MSDF\noutperforms typical heuristic algorithms under various scenarios.\n", "versions": [{"version": "v1", "created": "Tue, 12 Nov 2019 11:41:38 GMT"}, {"version": "v2", "created": "Wed, 13 Nov 2019 03:04:38 GMT"}], "update_date": "2019-11-14", "authors_parsed": [["Chen", "Ruoyun", ""], ["Lu", "Hancheng", ""], ["Lu", "Yujiao", ""], ["Liu", "Jinxue", ""]]}, {"id": "1911.04808", "submitter": "Guillermo C\\'ambara", "authors": "Guillermo C\\'ambara, Jordi Luque, Mireia Farr\\'us", "title": "Detection of speech events and speaker characteristics through\n  photo-plethysmographic signal neural processing", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.AS cs.LG cs.SD stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  The use of photoplethysmogram signal (PPG) for heart and sleep monitoring is\ncommonly found nowadays in smartphones and wrist wearables. Besides common\nusages, it has been proposed and reported that person information can be\nextracted from PPG for other uses, like biometry tasks. In this work, we\nexplore several end-to-end convolutional neural network architectures for\ndetection of human's characteristics such as gender or person identity. In\naddition, we evaluate whether speech/non-speech events may be inferred from PPG\nsignal, where speech might translate in fluctuations into the pulse signal. The\nobtained results are promising and clearly show the potential of fully\nend-to-end topologies for automatic extraction of meaningful biomarkers, even\nfrom a noisy signal sampled by a low-cost PPG sensor. The AUCs for best\narchitectures put forward PPG wave as biological discriminant, reaching $79\\%$\nand $89.0\\%$, respectively for gender and person verification tasks.\nFurthermore, speech detection experiments reporting AUCs around $69\\%$\nencourage us for further exploration about the feasibility of PPG for speech\nprocessing tasks.\n", "versions": [{"version": "v1", "created": "Tue, 12 Nov 2019 11:58:42 GMT"}], "update_date": "2019-11-13", "authors_parsed": [["C\u00e1mbara", "Guillermo", ""], ["Luque", "Jordi", ""], ["Farr\u00fas", "Mireia", ""]]}, {"id": "1911.04817", "submitter": "Mattis Manfred K\\\"ammerer", "authors": "Mattis Manfred K\\\"ammerer", "title": "On Policy Gradients", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  The goal of policy gradient approaches is to find a policy in a given class\nof policies which maximizes the expected return. Given a differentiable model\nof the policy, we want to apply a gradient-ascent technique to reach a local\noptimum. We mainly use gradient ascent, because it is theoretically well\nresearched. The main issue is that the policy gradient with respect to the\nexpected return is not available, thus we need to estimate it. As policy\ngradient algorithms also tend to require on-policy data for the gradient\nestimate, their biggest weakness is sample efficiency. For this reason, most\nresearch is focused on finding algorithms with improved sample efficiency. This\npaper provides a formal introduction to policy gradient that shows the\ndevelopment of policy gradient approaches, and should enable the reader to\nfollow current research on the topic.\n", "versions": [{"version": "v1", "created": "Tue, 12 Nov 2019 12:28:29 GMT"}], "update_date": "2019-11-13", "authors_parsed": [["K\u00e4mmerer", "Mattis Manfred", ""]]}, {"id": "1911.04820", "submitter": "Qiang Ren", "authors": "Qiang Ren", "title": "Grouping Capsules Based Different Types", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Capsule network was introduced as a new architecture of neural networks, it\nencoding features as capsules to overcome the lacking of equivariant in the\nconvolutional neural networks. It uses dynamic routing algorithm to train\nparameters in different capsule layers, but the dynamic routing algorithm need\nto be improved. In this paper, we propose a novel capsule network architecture\nand discussed the effect of initialization method of the coupling coefficient\n$c_{ij}$ on the model. First, we analyze the rate of change of the initial\nvalue of $c_{ij}$ when the dynamic routing algorithm iterates. The larger the\ninitial value of $c_{ij}$, the better effect of the model. Then, we proposed\nimprovement that training different types of capsules by grouping capsules\nbased different types. And this improvement can adjust the initial value of\n$c_{ij}$ to make it more suitable. We experimented with our improvements on\nsome computer vision datasets and achieved better results than the original\ncapsule network\n", "versions": [{"version": "v1", "created": "Tue, 12 Nov 2019 12:39:20 GMT"}], "update_date": "2019-11-13", "authors_parsed": [["Ren", "Qiang", ""]]}, {"id": "1911.04822", "submitter": "Dai Quoc Nguyen", "authors": "Dai Quoc Nguyen and Tu Dinh Nguyen and Dat Quoc Nguyen and Dinh Phung", "title": "A Capsule Network-based Model for Learning Node Embeddings", "comments": "Extended version of our CIKM 2020 paper, including inductive results", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CL stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we focus on learning low-dimensional embeddings for nodes in\ngraph-structured data. To achieve this, we propose Caps2NE -- a new\nunsupervised embedding model leveraging a network of two capsule layers.\nCaps2NE induces a routing process to aggregate feature vectors of context\nneighbors of a given target node at the first capsule layer, then feed these\nfeatures into the second capsule layer to infer a plausible embedding for the\ntarget node. Experimental results show that our proposed Caps2NE obtains\nstate-of-the-art performances on benchmark datasets for the node classification\ntask. Our code is available at: \\url{https://github.com/daiquocnguyen/Caps2NE}.\n", "versions": [{"version": "v1", "created": "Tue, 12 Nov 2019 12:44:26 GMT"}, {"version": "v2", "created": "Tue, 18 Aug 2020 15:48:59 GMT"}], "update_date": "2020-08-19", "authors_parsed": [["Nguyen", "Dai Quoc", ""], ["Nguyen", "Tu Dinh", ""], ["Nguyen", "Dat Quoc", ""], ["Phung", "Dinh", ""]]}, {"id": "1911.04831", "submitter": "Jonguk Kim", "authors": "Jonguk Kim, Jeong-Han Yun, Hyoung Chun Kim", "title": "Anomaly Detection for Industrial Control Systems Using\n  Sequence-to-Sequence Neural Networks", "comments": "Accepted to 5th Workshop on the Security of Industrial Control\n  Systems & of Cyber-Physical Systems (CyberICPS 2019) in conjunction with\n  ESORICS 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This study proposes an anomaly detection method for operational data of\nindustrial control systems (ICSs). Sequence-to-sequence neural networks were\napplied to train and predict ICS operational data and interpret their\ntime-series characteristic. The proposed method requires only a normal dataset\nto understand ICS's normal state and detect outliers. This method was evaluated\nwith SWaT (secure water treatment) dataset, and 29 out of 36 attacks were\ndetected. The reported method also detects the attack points, and 25 out of 53\npoints were detected. This study provides a detailed analysis of false\npositives and false negatives of the experimental results.\n", "versions": [{"version": "v1", "created": "Tue, 12 Nov 2019 13:16:15 GMT"}], "update_date": "2019-11-13", "authors_parsed": [["Kim", "Jonguk", ""], ["Yun", "Jeong-Han", ""], ["Kim", "Hyoung Chun", ""]]}, {"id": "1911.04841", "submitter": "Massih-Reza Amini", "authors": "Vasilii Feofanov and Emilie Devijver and Massih-Reza Amini", "title": "Semi-supervised Wrapper Feature Selection by Modeling Imperfect Labels", "comments": "18 pages, 1 figure", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we propose a new wrapper feature selection approach with\npartially labeled training examples where unlabeled observations are\npseudo-labeled using the predictions of an initial classifier trained on the\nlabeled training set. The wrapper is composed of a genetic algorithm for\nproposing new feature subsets, and an evaluation measure for scoring the\ndifferent feature subsets. The selection of feature subsets is done by\nassigning weights to characteristics and recursively eliminating those that are\nirrelevant. The selection criterion is based on a new multi-class\n$\\mathcal{C}$-bound that explicitly takes into account the mislabeling errors\ninduced by the pseudo-labeling mechanism, using a probabilistic error model.\nEmpirical results on different data sets show the effectiveness of our\nframework compared to several state-of-the-art semi-supervised feature\nselection approaches.\n", "versions": [{"version": "v1", "created": "Tue, 12 Nov 2019 13:35:58 GMT"}, {"version": "v2", "created": "Tue, 10 Mar 2020 11:18:27 GMT"}], "update_date": "2020-03-11", "authors_parsed": [["Feofanov", "Vasilii", ""], ["Devijver", "Emilie", ""], ["Amini", "Massih-Reza", ""]]}, {"id": "1911.04852", "submitter": "Radu Tudor Ionescu", "authors": "Mariana-Iuliana Georgescu, Radu Tudor Ionescu", "title": "Recognizing Facial Expressions of Occluded Faces using Convolutional\n  Neural Networks", "comments": "Accepted at ICONIP 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we present an approach based on convolutional neural networks\n(CNNs) for facial expression recognition in a difficult setting with severe\nocclusions. More specifically, our task is to recognize the facial expression\nof a person wearing a virtual reality (VR) headset which essentially occludes\nthe upper part of the face. In order to accurately train neural networks for\nthis setting, in which faces are severely occluded, we modify the training\nexamples by intentionally occluding the upper half of the face. This forces the\nneural networks to focus on the lower part of the face and to obtain better\naccuracy rates than models trained on the entire faces. Our empirical results\non two benchmark data sets, FER+ and AffectNet, show that our CNN models'\npredictions on lower-half faces are up to 13% higher than the baseline CNN\nmodels trained on entire faces, proving their suitability for the VR setting.\nFurthermore, our models' predictions on lower-half faces are no more than 10%\nunder the baseline models' predictions on full faces, proving that there are\nenough clues in the lower part of the face to accurately predict facial\nexpressions.\n", "versions": [{"version": "v1", "created": "Tue, 12 Nov 2019 13:53:56 GMT"}], "update_date": "2019-11-13", "authors_parsed": [["Georgescu", "Mariana-Iuliana", ""], ["Ionescu", "Radu Tudor", ""]]}, {"id": "1911.04856", "submitter": "Hufei Zhu", "authors": "Hufei Zhu and Chenghao Wei", "title": "Efficient Inverse-Free Algorithms for Extreme Learning Machine Based on\n  the Recursive Matrix Inverse and the Inverse LDL' Factorization", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The inverse-free extreme learning machine (ELM) algorithm proposed in [4] was\nbased on an inverse-free algorithm to compute the regularized pseudo-inverse,\nwhich was deduced from an inverse-free recursive algorithm to update the\ninverse of a Hermitian matrix. Before that recursive algorithm was applied in\n[4], its improved version had been utilized in previous literatures [9], [10].\nAccordingly from the improved recursive algorithm [9], [10], we deduce a more\nefficient inverse-free algorithm\n  to update the regularized pseudo-inverse, from which we develop the proposed\ninverse-free ELM algorithm 1. Moreover, the proposed ELM algorithm 2 further\nreduces the computational complexity, which computes the output weights\ndirectly from the updated inverse, and avoids computing the regularized\npseudoinverse. Lastly, instead of updating the inverse, the proposed ELM\nalgorithm 3 updates the LDLT factor of the inverse by the inverse LDLT\nfactorization [11], to avoid numerical instabilities after a very large number\nof iterations [12]. With respect to the existing ELM algorithm, the proposed\nELM algorithms 1, 2 and 3 are expected to require only (8+3)/M , (8+1)/M and\n(8+1)/M of complexities, respectively, where M is the output node number. In\nthe numerical experiments, the standard ELM, the existing inverse-free ELM\nalgorithm and the proposed ELM algorithms 1, 2 and 3 achieve the same\nperformance in regression and classification, while all the 3 proposed\nalgorithms significantly accelerate the existing inverse-free ELM algorithm\n", "versions": [{"version": "v1", "created": "Tue, 12 Nov 2019 14:00:02 GMT"}], "update_date": "2019-11-13", "authors_parsed": [["Zhu", "Hufei", ""], ["Wei", "Chenghao", ""]]}, {"id": "1911.04862", "submitter": "Yong Ruan", "authors": "Yong Ruan, Xiangdong Wang, Hong Liu, Zhigang Ou, Yun Gao, Jianfeng\n  Cheng, Yueliang Qian", "title": "An End-to-end Approach for Lexical Stress Detection based on Transformer", "comments": "Submission to ICASSP 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.AS cs.LG cs.SD stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The dominant automatic lexical stress detection method is to split the\nutterance into syllable segments using phoneme sequence and their time-aligned\nboundaries. Then we extract features from syllable to use classification method\nto classify the lexical stress. However, we can't get very accurate time\nboundaries of each phoneme and we have to design some features in the syllable\nsegments to classify the lexical stress. Therefore, we propose a end-to-end\napproach using sequence to sequence model of transformer to estimate lexical\nstress. For this, we train transformer model using feature sequence of audio\nand their phoneme sequence with lexical stress marks. During the recognition\nprocess, the recognized phoneme sequence is restricted according to the\noriginal standard phoneme sequence without lexical stress marks, but the\nlexical stress mark of each phoneme is not limited. We train the model in\ndifferent subset of Librispeech and do lexical stress recognition in TIMIT and\nL2-ARCTIC dataset. For all subsets, the end-to-end model will perform better\nthan the syllable segments classification method. Our method can achieve a\n6.36% phoneme error rate on the TIMIT dataset, which exceeds the 7.2% error\nrate in other studies.\n", "versions": [{"version": "v1", "created": "Wed, 6 Nov 2019 11:29:37 GMT"}], "update_date": "2019-11-13", "authors_parsed": [["Ruan", "Yong", ""], ["Wang", "Xiangdong", ""], ["Liu", "Hong", ""], ["Ou", "Zhigang", ""], ["Gao", "Yun", ""], ["Cheng", "Jianfeng", ""], ["Qian", "Yueliang", ""]]}, {"id": "1911.04870", "submitter": "Elsa Rizk", "authors": "Elsa Rizk, Roula Nassif, Ali H. Sayed", "title": "Network Classifiers With Output Smoothing", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG cs.MA stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This work introduces two strategies for training network classifiers with\nheterogeneous agents. One strategy promotes global smoothing over the graph and\na second strategy promotes local smoothing over neighbourhoods. It is assumed\nthat the feature sizes can vary from one agent to another, with some agents\nobserving insufficient attributes to be able to make reliable decisions on\ntheir own. As a result, cooperation with neighbours is necessary. However, due\nto the fact that the feature dimensions are different across the agents, their\nclassifier dimensions will also be different. This means that cooperation\ncannot rely on combining the classifier parameters. We instead propose\nsmoothing the outputs of the classifiers, which are the predicted labels. By\ndoing so, the dynamics that describes the evolution of the network classifier\nbecomes more challenging than usual because the classifier parameters end up\nappearing as part of the regularization term as well. We illustrate performance\nby means of computer simulations.\n", "versions": [{"version": "v1", "created": "Wed, 30 Oct 2019 14:28:16 GMT"}], "update_date": "2019-11-13", "authors_parsed": [["Rizk", "Elsa", ""], ["Nassif", "Roula", ""], ["Sayed", "Ali H.", ""]]}, {"id": "1911.04872", "submitter": "Hufei Zhu", "authors": "Hufei Zhu", "title": "Two Ridge Solutions for the Incremental Broad Learning System on Added\n  Nodes", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The original Broad Learning System (BLS) on new added nodes and its existing\nefficient implementation both assume the ridge parameter is near 0 in the ridge\ninverse to approximate the generalized inverse, and compute the generalized\ninverse solution for the output weights. In this paper, we propose two ridge\nsolutions for the output weights in the BLS on added nodes, where the ridge\nparameter can be any positive real number. One of the proposed ridge solutions\ncomputes the output weights from the inverse Cholesky factor, which is updated\nby extending the existing inverse Cholesky factorization. The other proposed\nridge solution computes the output weights from the ridge inverse, and updates\nthe ridge inverse by extending the Greville method that can only computes the\ngeneralized inverse of a partitioned matrix. The proposed BLS algorithm based\non the ridge inverse requires the same complexity as the original BLS\nalgorithm, while the proposed BLS algorithm based on the inverse Cholesky\nfactor requires less complexity and training time than the original BLS and the\nexisting efficient BLS. Both the proposed ridge solutions for BLS achieve the\nsame testing accuracy as the standard ridge solution in the numerical\nexperiments. The difference between the testing accuracy of the proposed ridge\nsolutions and that of the existing generalized inverse solutions is negligible\nwhen the ridge parameter is very small, and becomes too big to be ignored when\nthe ridge parameter is not very small. When the ridge parameter is not near 0,\nusually the proposed two ridge solutions for BLS achieve better testing\naccuracy than the existing generalized inverse solutions for BLS, and then the\nformer are more preferred than the latter.\n", "versions": [{"version": "v1", "created": "Tue, 12 Nov 2019 14:12:33 GMT"}, {"version": "v2", "created": "Mon, 5 Jul 2021 14:17:17 GMT"}], "update_date": "2021-07-06", "authors_parsed": [["Zhu", "Hufei", ""]]}, {"id": "1911.04873", "submitter": "Bartosz Piotrowski", "authors": "Bartosz Piotrowski, Josef Urban, Chad E. Brown, Cezary Kaliszyk", "title": "Can Neural Networks Learn Symbolic Rewriting?", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This work investigates if the current neural architectures are adequate for\nlearning symbolic rewriting. Two kinds of data sets are proposed for this\nresearch -- one based on automated proofs and the other being a synthetic set\nof polynomial terms. The experiments with use of the current neural machine\ntranslation models are performed and its results are discussed. Ideas for\nextending this line of research are proposed, and its relevance is motivated.\n", "versions": [{"version": "v1", "created": "Thu, 7 Nov 2019 11:22:44 GMT"}, {"version": "v2", "created": "Tue, 26 May 2020 23:43:51 GMT"}], "update_date": "2020-05-28", "authors_parsed": [["Piotrowski", "Bartosz", ""], ["Urban", "Josef", ""], ["Brown", "Chad E.", ""], ["Kaliszyk", "Cezary", ""]]}, {"id": "1911.04890", "submitter": "Takaki Makino", "authors": "Takaki Makino (1), Hank Liao (1), Yannis Assael (2), Brendan\n  Shillingford (2), Basilio Garcia (1), Otavio Braga (1), Olivier Siohan (1)\n  ((1) Google Inc. (2) DeepMind)", "title": "Recurrent Neural Network Transducer for Audio-Visual Speech Recognition", "comments": "Will be presented in 2019 IEEE Automatic Speech Recognition and\n  Understanding Workshop (ASRU 2019)", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.AS cs.CL cs.CV cs.LG cs.SD", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This work presents a large-scale audio-visual speech recognition system based\non a recurrent neural network transducer (RNN-T) architecture. To support the\ndevelopment of such a system, we built a large audio-visual (A/V) dataset of\nsegmented utterances extracted from YouTube public videos, leading to 31k hours\nof audio-visual training content. The performance of an audio-only,\nvisual-only, and audio-visual system are compared on two large-vocabulary test\nsets: a set of utterance segments from public YouTube videos called YTDEV18 and\nthe publicly available LRS3-TED set. To highlight the contribution of the\nvisual modality, we also evaluated the performance of our system on the YTDEV18\nset artificially corrupted with background noise and overlapping speech. To the\nbest of our knowledge, our system significantly improves the state-of-the-art\non the LRS3-TED set.\n", "versions": [{"version": "v1", "created": "Fri, 8 Nov 2019 22:01:42 GMT"}], "update_date": "2019-11-13", "authors_parsed": [["Makino", "Takaki", "", "Google Inc"], ["Liao", "Hank", "", "Google Inc"], ["Assael", "Yannis", "", "DeepMind"], ["Shillingford", "Brendan", "", "DeepMind"], ["Garcia", "Basilio", "", "Google Inc"], ["Braga", "Otavio", "", "Google Inc"], ["Siohan", "Olivier", "", "Google Inc"]]}, {"id": "1911.04894", "submitter": "Yishen Wang", "authors": "Xinan Wang, Yishen Wang, Di Shi, Jianhui Wang, Zhiwei Wang", "title": "Two-stage WECC Composite Load Modeling: A Double Deep Q-Learning\n  Networks Approach", "comments": "To appear in IEEE Transactions on Smart Grid", "journal-ref": null, "doi": "10.1109/TSG.2020.2988171", "report-no": null, "categories": "eess.SY cs.LG cs.SY eess.SP stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  With the increasing complexity of modern power systems, conventional dynamic\nload modeling with ZIP and induction motors (ZIP + IM) is no longer adequate to\naddress the current load characteristic transitions. In recent years, the WECC\ncomposite load model (WECC CLM) has shown to effectively capture the dynamic\nload responses over traditional load models in various stability studies and\ncontingency analyses. However, a detailed WECC CLM model typically has a high\ndegree of complexity, with over one hundred parameters, and no systematic\napproach to identifying and calibrating these parameters. Enabled by the wide\ndeployment of PMUs and advanced deep learning algorithms, proposed here is a\ndouble deep Q-learning network (DDQN)-based, two-stage load modeling framework\nfor the WECC CLM. This two-stage method decomposes the complicated WECC CLM for\nmore efficient identification and does not require explicit model details. In\nthe first stage, the DDQN agent determines an accurate load composition. In the\nsecond stage, the parameters of the WECC CLM are selected from a group of\nMonte-Carlo simulations. The set of selected load parameters is expected to\nbest approximate the true transient responses. The proposed framework is\nverified using an IEEE 39-bus test system on commercial simulation platforms.\n", "versions": [{"version": "v1", "created": "Fri, 8 Nov 2019 02:15:03 GMT"}, {"version": "v2", "created": "Wed, 15 Apr 2020 23:41:04 GMT"}], "update_date": "2020-04-17", "authors_parsed": [["Wang", "Xinan", ""], ["Wang", "Yishen", ""], ["Shi", "Di", ""], ["Wang", "Jianhui", ""], ["Wang", "Zhiwei", ""]]}, {"id": "1911.04898", "submitter": "Tom Van Steenkiste", "authors": "Tom Van Steenkiste, Dirk Deschrijver and Tom Dhaene", "title": "Generating an Explainable ECG Beat Space With Variational Auto-Encoders", "comments": "Machine Learning for Health (ML4H) at NeurIPS 2019 - Extended\n  Abstract. Extended abstract based on previously published research: Van\n  Steenkiste, Tom, Dirk Deschrijver, and Tom Dhaene. \"Interpretable ECG Beat\n  Embedding using Disentangled Variational Auto-Encoders.\" In 2019 IEEE 32nd\n  International Symposium on Computer-Based Medical Systems (CBMS), pp.\n  373-378. IEEE, 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG eess.SP stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Electrocardiogram signals are omnipresent in medicine. A vital aspect in the\nanalysis of this data is the identification and classification of heart beat\ntypes which is often done through automated algorithms. Advancements in neural\nnetworks and deep learning have led to a high classification accuracy. However,\nthe final adoption of these models into clinical practice is limited due to the\nblack-box nature of the methods. In this work, we explore the use of\nvariational auto-encoders based on linear dense networks to learn human\ninterpretable beat embeddings in time-series data. We demonstrate that using\nthis method, an interpretable and explainable ECG beat space can be generated,\nset up by characteristic base beats.\n", "versions": [{"version": "v1", "created": "Tue, 12 Nov 2019 14:41:15 GMT"}], "update_date": "2019-11-13", "authors_parsed": [["Van Steenkiste", "Tom", ""], ["Deschrijver", "Dirk", ""], ["Dhaene", "Tom", ""]]}, {"id": "1911.04908", "submitter": "Nanxin Chen", "authors": "Nanxin Chen, Shinji Watanabe, Jes\\'us Villalba, Najim Dehak", "title": "Listen and Fill in the Missing Letters: Non-Autoregressive Transformer\n  for Speech Recognition", "comments": null, "journal-ref": null, "doi": "10.1109/LSP.2020.3044547", "report-no": null, "categories": "eess.AS cs.LG cs.SD stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recently very deep transformers have outperformed conventional bi-directional\nlong short-term memory networks by a large margin in speech recognition.\nHowever, to put it into production usage, inference computation cost is still a\nserious concern in real scenarios. In this paper, we study two different\nnon-autoregressive transformer structure for automatic speech recognition\n(ASR): A-CMLM and A-FMLM. During training, for both frameworks, input tokens\nfed to the decoder are randomly replaced by special mask tokens. The network is\nrequired to predict the tokens corresponding to those mask tokens by taking\nboth unmasked context and input speech into consideration. During inference, we\nstart from all mask tokens and the network iteratively predicts missing tokens\nbased on partial results. We show that this framework can support different\ndecoding strategies, including traditional left-to-right. A new decoding\nstrategy is proposed as an example, which starts from the easiest predictions\nto the most difficult ones. Results on Mandarin (Aishell) and Japanese (CSJ)\nASR benchmarks show the possibility to train such a non-autoregressive network\nfor ASR. Especially in Aishell, the proposed method outperformed the Kaldi ASR\nsystem and it matches the performance of the state-of-the-art autoregressive\ntransformer with 7x speedup. Pretrained models and code will be made available\nafter publication.\n", "versions": [{"version": "v1", "created": "Sun, 10 Nov 2019 06:05:14 GMT"}, {"version": "v2", "created": "Mon, 6 Apr 2020 14:45:19 GMT"}], "update_date": "2021-04-27", "authors_parsed": [["Chen", "Nanxin", ""], ["Watanabe", "Shinji", ""], ["Villalba", "Jes\u00fas", ""], ["Dehak", "Najim", ""]]}, {"id": "1911.04910", "submitter": "Guangtao Wang", "authors": "Yun Tang, Jing Huang, Guangtao Wang, Xiaodong He, Bowen Zhou", "title": "Orthogonal Relation Transforms with Graph Context Modeling for Knowledge\n  Graph Embedding", "comments": "Accepted by ACL 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Translational distance-based knowledge graph embedding has shown progressive\nimprovements on the link prediction task, from TransE to the latest\nstate-of-the-art RotatE. However, N-1, 1-N and N-N predictions still remain\nchallenging. In this work, we propose a novel translational distance-based\napproach for knowledge graph link prediction. The proposed method includes\ntwo-folds, first we extend the RotatE from 2D complex domain to high dimension\nspace with orthogonal transforms to model relations for better modeling\ncapacity. Second, the graph context is explicitly modeled via two directed\ncontext representations. These context representations are used as part of the\ndistance scoring function to measure the plausibility of the triples during\ntraining and inference. The proposed approach effectively improves prediction\naccuracy on the difficult N-1, 1-N and N-N cases for knowledge graph link\nprediction task. The experimental results show that it achieves better\nperformance on two benchmark data sets compared to the baseline RotatE,\nespecially on data set (FB15k-237) with many high in-degree connection nodes.\n", "versions": [{"version": "v1", "created": "Sat, 9 Nov 2019 07:02:33 GMT"}, {"version": "v2", "created": "Thu, 9 Apr 2020 20:32:11 GMT"}, {"version": "v3", "created": "Wed, 15 Apr 2020 20:13:30 GMT"}], "update_date": "2020-04-17", "authors_parsed": [["Tang", "Yun", ""], ["Huang", "Jing", ""], ["Wang", "Guangtao", ""], ["He", "Xiaodong", ""], ["Zhou", "Bowen", ""]]}, {"id": "1911.04913", "submitter": "Brij Mohan Lal Srivastava", "authors": "Brij Mohan Lal Srivastava, Aur\\'elien Bellet, Marc Tommasi, Emmanuel\n  Vincent", "title": "Privacy-Preserving Adversarial Representation Learning in ASR: Reality\n  or Illusion?", "comments": null, "journal-ref": null, "doi": "10.21437/Interspeech.2019-2415", "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Automatic speech recognition (ASR) is a key technology in many services and\napplications. This typically requires user devices to send their speech data to\nthe cloud for ASR decoding. As the speech signal carries a lot of information\nabout the speaker, this raises serious privacy concerns. As a solution, an\nencoder may reside on each user device which performs local computations to\nanonymize the representation. In this paper, we focus on the protection of\nspeaker identity and study the extent to which users can be recognized based on\nthe encoded representation of their speech as obtained by a deep\nencoder-decoder architecture trained for ASR. Through speaker identification\nand verification experiments on the Librispeech corpus with open and closed\nsets of speakers, we show that the representations obtained from a standard\narchitecture still carry a lot of information about speaker identity. We then\npropose to use adversarial training to learn representations that perform well\nin ASR while hiding speaker identity. Our results demonstrate that adversarial\ntraining dramatically reduces the closed-set classification accuracy, but this\ndoes not translate into increased open-set verification error hence into\nincreased protection of the speaker identity in practice. We suggest several\npossible reasons behind this negative result.\n", "versions": [{"version": "v1", "created": "Tue, 12 Nov 2019 14:53:34 GMT"}], "update_date": "2019-11-13", "authors_parsed": [["Srivastava", "Brij Mohan Lal", ""], ["Bellet", "Aur\u00e9lien", ""], ["Tommasi", "Marc", ""], ["Vincent", "Emmanuel", ""]]}, {"id": "1911.04922", "submitter": "Shuai Wang", "authors": "Shuai Wang, Yik-Chung Wu, Minghua Xia, Rui Wang, and H. Vincent Poor", "title": "Machine Intelligence at the Edge with Learning Centric Power Allocation", "comments": "14 figures, 15 pages, to appear in IEEE Transactions on Wireless\n  Communications", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IT cs.AI cs.LG math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  While machine-type communication (MTC) devices generate considerable amounts\nof data, they often cannot process the data due to limited energy and\ncomputational power. To empower MTC with intelligence, edge machine learning\nhas been proposed. However, power allocation in this paradigm requires\nmaximizing the learning performance instead of the communication throughput,\nfor which the celebrated water-filling and max-min fairness algorithms become\ninefficient. To this end, this paper proposes learning centric power allocation\n(LCPA), which provides a new perspective on radio resource allocation in\nlearning driven scenarios. By employing 1) an empirical classification error\nmodel that is supported by learning theory and 2) an uncertainty sampling\nmethod that accounts for different distributions at users, LCPA is formulated\nas a nonconvex nonsmooth optimization problem, and is solved using a\nmajorization minimization (MM) framework. To get deeper insights into LCPA,\nasymptotic analysis shows that the transmit powers are inversely proportional\nto the channel gains, and scale exponentially with the learning parameters.\nThis is in contrast to traditional power allocations where quality of wireless\nchannels is the only consideration. Last but not least, a large-scale\noptimization algorithm termed mirror-prox LCPA is further proposed to enable\nLCPA in large-scale settings. Extensive numerical results demonstrate that the\nproposed LCPA algorithms outperform traditional power allocation algorithms,\nand the large-scale optimization algorithm reduces the computation time by\norders of magnitude compared with MM-based LCPA but still achieves competing\nlearning performance.\n", "versions": [{"version": "v1", "created": "Tue, 12 Nov 2019 15:10:34 GMT"}, {"version": "v2", "created": "Fri, 17 Jul 2020 03:00:39 GMT"}], "update_date": "2020-07-20", "authors_parsed": [["Wang", "Shuai", ""], ["Wu", "Yik-Chung", ""], ["Xia", "Minghua", ""], ["Wang", "Rui", ""], ["Poor", "H. Vincent", ""]]}, {"id": "1911.04929", "submitter": "Boris Ruf", "authors": "Vincent Grari, Boris Ruf, Sylvain Lamprier, Marcin Detyniecki", "title": "Fairness-Aware Neural R\\'eyni Minimization for Continuous Features", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CY stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The past few years have seen a dramatic rise of academic and societal\ninterest in fair machine learning. While plenty of fair algorithms have been\nproposed recently to tackle this challenge for discrete variables, only a few\nideas exist for continuous ones. The objective in this paper is to ensure some\nindependence level between the outputs of regression models and any given\ncontinuous sensitive variables. For this purpose, we use the\nHirschfeld-Gebelein-R\\'enyi (HGR) maximal correlation coefficient as a fairness\nmetric. We propose two approaches to minimize the HGR coefficient. First, by\nreducing an upper bound of the HGR with a neural network estimation of the\n$\\chi^{2}$ divergence. Second, by minimizing the HGR directly with an\nadversarial neural network architecture. The idea is to predict the output Y\nwhile minimizing the ability of an adversarial neural network to find the\nestimated transformations which are required to predict the HGR coefficient. We\nempirically assess and compare our approaches and demonstrate significant\nimprovements on previously presented work in the field.\n", "versions": [{"version": "v1", "created": "Tue, 12 Nov 2019 15:20:29 GMT"}], "update_date": "2019-11-13", "authors_parsed": [["Grari", "Vincent", ""], ["Ruf", "Boris", ""], ["Lamprier", "Sylvain", ""], ["Detyniecki", "Marcin", ""]]}, {"id": "1911.04931", "submitter": "Mohammad Mahdi Kamani", "authors": "Mohammad Mahdi Kamani, Farzin Haddadpour, Rana Forsati, Mehrdad\n  Mahdavi", "title": "Efficient Fair Principal Component Analysis", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.DS math.OC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  It has been shown that dimension reduction methods such as PCA may be\ninherently prone to unfairness and treat data from different sensitive groups\nsuch as race, color, sex, etc., unfairly. In pursuit of fairness-enhancing\ndimensionality reduction, using the notion of Pareto optimality, we propose an\nadaptive first-order algorithm to learn a subspace that preserves fairness,\nwhile slightly compromising the reconstruction loss. Theoretically, we provide\nsufficient conditions that the solution of the proposed algorithm belongs to\nthe Pareto frontier for all sensitive groups; thereby, the optimal trade-off\nbetween overall reconstruction loss and fairness constraints is guaranteed. We\nalso provide the convergence analysis of our algorithm and show its efficacy\nthrough empirical studies on different datasets, which demonstrates superior\nperformance in comparison with state-of-the-art algorithms. The proposed\nfairness-aware PCA algorithm can be efficiently generalized to multiple group\nsensitive features and effectively reduce the unfairness decisions in\ndownstream tasks such as classification.\n", "versions": [{"version": "v1", "created": "Tue, 12 Nov 2019 15:29:05 GMT"}, {"version": "v2", "created": "Sun, 8 Mar 2020 01:31:11 GMT"}], "update_date": "2020-03-10", "authors_parsed": [["Kamani", "Mohammad Mahdi", ""], ["Haddadpour", "Farzin", ""], ["Forsati", "Rana", ""], ["Mahdavi", "Mehrdad", ""]]}, {"id": "1911.04932", "submitter": "Jesus Lago", "authors": "Jesus Lago and Karel De Brabandere and Fjo De Ridder and Bart De\n  Schutter", "title": "Short-term forecasting of solar irradiance without local telemetry: a\n  generalized model using satellite data", "comments": null, "journal-ref": "Solar Energy 173 (2018), pages 566-577", "doi": "10.1016/j.solener.2018.07.050", "report-no": null, "categories": "stat.ML cs.LG stat.AP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Due to the increasing integration of solar power into the electrical grid,\nforecasting short-term solar irradiance has become key for many applications,\ne.g.~operational planning, power purchases, reserve activation, etc. In this\ncontext, as solar generators are geographically dispersed and ground\nmeasurements are not always easy to obtain, it is very important to have\ngeneral models that can predict solar irradiance without the need of local\ndata. In this paper, a model that can perform short-term forecasting of solar\nirradiance in any general location without the need of ground measurements is\nproposed. To do so, the model considers satellite-based measurements and\nweather-based forecasts, and employs a deep neural network structure that is\nable to generalize across locations; particularly, the network is trained only\nusing a small subset of sites where ground data is available, and the model is\nable to generalize to a much larger number of locations where ground data does\nnot exist. As a case study, 25 locations in The Netherlands are considered and\nthe proposed model is compared against four local models that are individually\ntrained for each location using ground measurements. Despite the general nature\nof the model, it is shown show that the proposed model is equal or better than\nthe local models: when comparing the average performance across all the\nlocations and prediction horizons, the proposed model obtains a 31.31% rRMSE\n(relative root mean square error) while the best local model achieves a 32.01%\nrRMSE.\n", "versions": [{"version": "v1", "created": "Tue, 12 Nov 2019 15:30:55 GMT"}], "update_date": "2019-11-13", "authors_parsed": [["Lago", "Jesus", ""], ["De Brabandere", "Karel", ""], ["De Ridder", "Fjo", ""], ["De Schutter", "Bart", ""]]}, {"id": "1911.04933", "submitter": "Aditya Golatkar", "authors": "Aditya Golatkar, Alessandro Achille, Stefano Soatto", "title": "Eternal Sunshine of the Spotless Net: Selective Forgetting in Deep\n  Networks", "comments": "Accepted at CVPR 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We explore the problem of selectively forgetting a particular subset of the\ndata used for training a deep neural network. While the effects of the data to\nbe forgotten can be hidden from the output of the network, insights may still\nbe gleaned by probing deep into its weights. We propose a method for\n\"scrubbing'\" the weights clean of information about a particular set of\ntraining data. The method does not require retraining from scratch, nor access\nto the data originally used for training. Instead, the weights are modified so\nthat any probing function of the weights is indistinguishable from the same\nfunction applied to the weights of a network trained without the data to be\nforgotten. This condition is a generalized and weaker form of Differential\nPrivacy. Exploiting ideas related to the stability of stochastic gradient\ndescent, we introduce an upper-bound on the amount of information remaining in\nthe weights, which can be estimated efficiently even for deep neural networks.\n", "versions": [{"version": "v1", "created": "Tue, 12 Nov 2019 15:35:39 GMT"}, {"version": "v2", "created": "Sat, 16 Nov 2019 20:14:45 GMT"}, {"version": "v3", "created": "Mon, 25 Nov 2019 05:44:33 GMT"}, {"version": "v4", "created": "Mon, 16 Mar 2020 06:53:59 GMT"}, {"version": "v5", "created": "Tue, 31 Mar 2020 22:48:01 GMT"}], "update_date": "2020-04-02", "authors_parsed": [["Golatkar", "Aditya", ""], ["Achille", "Alessandro", ""], ["Soatto", "Stefano", ""]]}, {"id": "1911.04936", "submitter": "Qiang Ma", "authors": "Qiang Ma, Suwen Ge, Danyang He, Darshan Thaker, Iddo Drori", "title": "Combinatorial Optimization by Graph Pointer Networks and Hierarchical\n  Reinforcement Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this work, we introduce Graph Pointer Networks (GPNs) trained using\nreinforcement learning (RL) for tackling the traveling salesman problem (TSP).\nGPNs build upon Pointer Networks by introducing a graph embedding layer on the\ninput, which captures relationships between nodes. Furthermore, to approximate\nsolutions to constrained combinatorial optimization problems such as the TSP\nwith time windows, we train hierarchical GPNs (HGPNs) using RL, which learns a\nhierarchical policy to find an optimal city permutation under constraints. Each\nlayer of the hierarchy is designed with a separate reward function, resulting\nin stable training. Our results demonstrate that GPNs trained on small-scale\nTSP50/100 problems generalize well to larger-scale TSP500/1000 problems, with\nshorter tour lengths and faster computational times. We verify that for\nconstrained TSP problems such as the TSP with time windows, the feasible\nsolutions found via hierarchical RL training outperform previous baselines. In\nthe spirit of reproducible research we make our data, models, and code publicly\navailable.\n", "versions": [{"version": "v1", "created": "Tue, 12 Nov 2019 15:39:21 GMT"}], "update_date": "2019-11-13", "authors_parsed": [["Ma", "Qiang", ""], ["Ge", "Suwen", ""], ["He", "Danyang", ""], ["Thaker", "Darshan", ""], ["Drori", "Iddo", ""]]}, {"id": "1911.04946", "submitter": "Zheng Wang", "authors": "Vicent Sanz Marco, Ben Taylor, Zheng Wang, Yehia Elkhatib", "title": "Optimizing Deep Learning Inference on Embedded Systems Through Adaptive\n  Model Selection", "comments": "Accepted to be published at ACM TECS. arXiv admin note: substantial\n  text overlap with arXiv:1805.04252", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.DC cs.PF", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Deep neural networks ( DNNs ) are becoming a key enabling technology for many\napplication domains. However, on-device inference on battery-powered,\nresource-constrained embedding systems is often infeasible due to prohibitively\nlong inferencing time and resource requirements of many DNNs. Offloading\ncomputation into the cloud is often unacceptable due to privacy concerns, high\nlatency, or the lack of connectivity. While compression algorithms often\nsucceed in reducing inferencing times, they come at the cost of reduced\naccuracy. This paper presents a new, alternative approach to enable efficient\nexecution of DNNs on embedded devices. Our approach dynamically determines\nwhich DNN to use for a given input, by considering the desired accuracy and\ninference time. It employs machine learning to develop a low-cost predictive\nmodel to quickly select a pre-trained DNN to use for a given input and the\noptimization constraint. We achieve this by first off-line training a\npredictive model, and then using the learned model to select a DNN model to use\nfor new, unseen inputs. We apply our approach to two representative DNN\ndomains: image classification and machine translation. We evaluate our approach\non a Jetson TX2 embedded deep learning platform and consider a range of\ninfluential DNN models including convolutional and recurrent neural networks.\nFor image classification, we achieve a 1.8x reduction in inference time with a\n7.52% improvement in accuracy, over the most-capable single DNN model. For\nmachine translation, we achieve a 1.34x reduction in inference time over the\nmost-capable single model, with little impact on the quality of translation.\n", "versions": [{"version": "v1", "created": "Sat, 9 Nov 2019 23:56:19 GMT"}], "update_date": "2019-11-13", "authors_parsed": [["Marco", "Vicent Sanz", ""], ["Taylor", "Ben", ""], ["Wang", "Zheng", ""], ["Elkhatib", "Yehia", ""]]}, {"id": "1911.04947", "submitter": "Hardik Meisheri", "authors": "Hardik Meisheri, Omkar Shelke, Richa Verma, Harshad Khadilkar", "title": "Accelerating Training in Pommerman with Imitation and Reinforcement\n  Learning", "comments": "Presented at Deep Reinforcement Learning workshop, NeurIPS-2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The Pommerman simulation was recently developed to mimic the classic Japanese\ngame Bomberman, and focuses on competitive gameplay in a multi-agent setting.\nWe focus on the 2$\\times$2 team version of Pommerman, developed for a\ncompetition at NeurIPS 2018. Our methodology involves training an agent\ninitially through imitation learning on a noisy expert policy, followed by a\nproximal-policy optimization (PPO) reinforcement learning algorithm. The basic\nPPO approach is modified for stable transition from the imitation learning\nphase through reward shaping, action filters based on heuristics, and\ncurriculum learning. The proposed methodology is able to beat heuristic and\npure reinforcement learning baselines with a combined 100,000 training games,\nsignificantly faster than other non-tree-search methods in literature. We\npresent results against multiple agents provided by the developers of the\nsimulation, including some that we have enhanced. We include a sensitivity\nanalysis over different parameters, and highlight undesirable effects of some\nstrategies that initially appear promising. Since Pommerman is a complex\nmulti-agent competitive environment, the strategies developed here provide\ninsights into several real-world problems with characteristics such as partial\nobservability, decentralized execution (without communication), and very sparse\nand delayed rewards.\n", "versions": [{"version": "v1", "created": "Tue, 12 Nov 2019 15:50:18 GMT"}, {"version": "v2", "created": "Wed, 13 Nov 2019 05:53:58 GMT"}], "update_date": "2019-11-14", "authors_parsed": [["Meisheri", "Hardik", ""], ["Shelke", "Omkar", ""], ["Verma", "Richa", ""], ["Khadilkar", "Harshad", ""]]}, {"id": "1911.04951", "submitter": "Fabien Cardinaux", "authors": "Fabien Cardinaux, Stefan Uhlich, Kazuki Yoshiyama, Javier Alonso\n  Garcia, Lukas Mauch, Stephen Tiedemann, Thomas Kemp, Akira Nakamura", "title": "Iteratively Training Look-Up Tables for Network Quantization", "comments": "Copyright 2019 IEEE. Personal use of this material is permitted.\n  Permission from IEEE must be obtained for all other uses, in any current or\n  future media, including reprinting/republishing this material for advertising\n  or promotional purposes, creating new collective works, for resale or\n  redistribution to servers or lists, or reuse of any copyrighted component of\n  this work in other works", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Operating deep neural networks (DNNs) on devices with limited resources\nrequires the reduction of their memory as well as computational footprint.\nPopular reduction methods are network quantization or pruning, which either\nreduce the word length of the network parameters or remove weights from the\nnetwork if they are not needed. In this article we discuss a general framework\nfor network reduction which we call `Look-Up Table Quantization` (LUT-Q). For\neach layer, we learn a value dictionary and an assignment matrix to represent\nthe network weights. We propose a special solver which combines gradient\ndescent and a one-step k-means update to learn both the value dictionaries and\nassignment matrices iteratively. This method is very flexible: by constraining\nthe value dictionary, many different reduction problems such as non-uniform\nnetwork quantization, training of multiplierless networks, network pruning or\nsimultaneous quantization and pruning can be implemented without changing the\nsolver. This flexibility of the LUT-Q method allows us to use the same method\nto train networks for different hardware capabilities.\n", "versions": [{"version": "v1", "created": "Tue, 12 Nov 2019 15:52:36 GMT"}], "update_date": "2019-11-13", "authors_parsed": [["Cardinaux", "Fabien", ""], ["Uhlich", "Stefan", ""], ["Yoshiyama", "Kazuki", ""], ["Garcia", "Javier Alonso", ""], ["Mauch", "Lukas", ""], ["Tiedemann", "Stephen", ""], ["Kemp", "Thomas", ""], ["Nakamura", "Akira", ""]]}, {"id": "1911.04954", "submitter": "Mohammed Elhenawy Dr", "authors": "Mohammed Elhenawy, Arash Jahangiri, Hesham Rakha", "title": "Impact of Narrow Lanes on Arterial Road Vehicle Crashes: A Machine\n  Learning Approach", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://creativecommons.org/publicdomain/zero/1.0/", "abstract": "  In this paper we adopted state-of-the-art machine learning algorithms,\nnamely: random forest (RF) and least squares boosting, to model crash data and\nidentify the optimum model to study the impact of narrow lanes on the safety of\narterial roads. Using a ten-year crash dataset in four cities in Nebraska, two\nmachine learning models were assessed based on the prediction error. The RF\nmodel was identified as the best model. The RF was used to compute the\nimportance of the lane width predictors in our regression model based on two\ndifferent measures. Subsequently, the RF model was used to simulate the crash\nrate for different lane widths. The Kruskal-Wallis test, was then conducted to\ndetermine if simulated values from the four lane width groups have equal means.\nThe test null hypothesis of equal means for simulated values from the four lane\nwidth groups was rejected. Consequently, it was concluded that the crash rates\nfrom at least one lane width group was statistically different from the others.\nFinally, the results from the pairwise comparisons using the Tukey and Kramer\ntest showed that the changes in crash rates between any two lane width\nconditions were statistically significant.\n", "versions": [{"version": "v1", "created": "Thu, 7 Nov 2019 12:21:02 GMT"}], "update_date": "2019-11-13", "authors_parsed": [["Elhenawy", "Mohammed", ""], ["Jahangiri", "Arash", ""], ["Rakha", "Hesham", ""]]}, {"id": "1911.04964", "submitter": "George Monta\\~nez", "authors": "Julius Lauw, Dominique Macias, Akshay Trikha, Julia Vendemiatti,\n  George D. Montanez", "title": "The Bias-Expressivity Trade-off", "comments": "arXiv admin note: text overlap with arXiv:1907.06010", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Learning algorithms need bias to generalize and perform better than random\nguessing. We examine the flexibility (expressivity) of biased algorithms. An\nexpressive algorithm can adapt to changing training data, altering its outcome\nbased on changes in its input. We measure expressivity by using an\ninformation-theoretic notion of entropy on algorithm outcome distributions,\ndemonstrating a trade-off between bias and expressivity. To the degree an\nalgorithm is biased is the degree to which it can outperform uniform random\nsampling, but is also the degree to which is becomes inflexible. We derive\nbounds relating bias to expressivity, proving the necessary trade-offs inherent\nin trying to create strongly performing yet flexible algorithms.\n", "versions": [{"version": "v1", "created": "Sat, 9 Nov 2019 19:51:02 GMT"}], "update_date": "2019-11-13", "authors_parsed": [["Lauw", "Julius", ""], ["Macias", "Dominique", ""], ["Trikha", "Akshay", ""], ["Vendemiatti", "Julia", ""], ["Montanez", "George D.", ""]]}, {"id": "1911.04965", "submitter": "Florence Regol", "authors": "Soumyasundar Pal, Florence Regol, Mark Coates", "title": "Bayesian Graph Convolutional Neural Networks using Node Copying", "comments": "arXiv admin note: text overlap with arXiv:1910.12132", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Graph convolutional neural networks (GCNN) have numerous applications in\ndifferent graph based learning tasks. Although the techniques obtain impressive\nresults, they often fall short in accounting for the uncertainty associated\nwith the underlying graph structure. In the recently proposed Bayesian GCNN\n(BGCN) framework, this issue is tackled by viewing the observed graph as a\nsample from a parametric random graph model and targeting joint inference of\nthe graph and the GCNN weights. In this paper, we introduce an alternative\ngenerative model for graphs based on copying nodes and incorporate it within\nthe BGCN framework. Our approach has the benefit that it uses information\nprovided by the node features and training labels in the graph topology\ninference. Experiments show that the proposed algorithm compares favorably to\nthe state-of-the-art in benchmark node classification tasks.\n", "versions": [{"version": "v1", "created": "Fri, 8 Nov 2019 19:16:24 GMT"}], "update_date": "2019-11-13", "authors_parsed": [["Pal", "Soumyasundar", ""], ["Regol", "Florence", ""], ["Coates", "Mark", ""]]}, {"id": "1911.04967", "submitter": "Louis van Harten", "authors": "Louis D. van Harten, Jelmer M. Wolterink, Joost J.C. Verhoeff, Ivana\n  I\\v{s}gum", "title": "Exploiting Clinically Available Delineations for CNN-based Segmentation\n  in Radiotherapy Treatment Planning", "comments": "SPIE Medical Imaging 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Convolutional neural networks (CNNs) have been widely and successfully used\nfor medical image segmentation. However, CNNs are typically considered to\nrequire large numbers of dedicated expert-segmented training volumes, which may\nbe limiting in practice. This work investigates whether clinically obtained\nsegmentations which are readily available in picture archiving and\ncommunication systems (PACS) could provide a possible source of data to train a\nCNN for segmentation of organs-at-risk (OARs) in radiotherapy treatment\nplanning. In such data, delineations of structures deemed irrelevant to the\ntarget clinical use may be lacking. To overcome this issue, we use multi-label\ninstead of multi-class segmentation. We empirically assess how many clinical\ndelineations would be sufficient to train a CNN for the segmentation of OARs\nand find that increasing the training set size beyond a limited number of\nimages leads to sharply diminishing returns. Moreover, we find that by using\nmulti-label segmentation, missing structures in the reference standard do not\nhave a negative effect on overall segmentation accuracy. These results indicate\nthat segmentations obtained in a clinical workflow can be used to train an\naccurate OAR segmentation model.\n", "versions": [{"version": "v1", "created": "Tue, 12 Nov 2019 15:58:23 GMT"}], "update_date": "2019-11-13", "authors_parsed": [["van Harten", "Louis D.", ""], ["Wolterink", "Jelmer M.", ""], ["Verhoeff", "Joost J. C.", ""], ["I\u0161gum", "Ivana", ""]]}, {"id": "1911.04969", "submitter": "Babak Hosseini", "authors": "Babak Hosseini, Romain Montagne, Barbara Hammer", "title": "Deep-Aligned Convolutional Neural Network for Skeleton-based Action\n  Recognition and Segmentation", "comments": "19th IEEE International Conference on Data Mining (ICDM 2019)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV eess.IV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Convolutional neural networks (CNNs) are deep learning frameworks which are\nwell-known for their notable performance in classification tasks. Hence, many\nskeleton-based action recognition and segmentation (SBARS) algorithms benefit\nfrom them in their designs. However, a shortcoming of such applications is the\ngeneral lack of spatial relationships between the input features in such data\ntypes. Besides, non-uniform temporal scalings is a common issue in\nskeleton-based data streams which leads to having different input sizes even\nwithin one specific action category. In this work, we propose a novel\ndeep-aligned convolutional neural network (DACNN) to tackle the above\nchallenges for the particular problem of SBARS. Our network is designed by\nintroducing a new type of filters in the context of CNNs which are trained\nbased on their alignments to the local subsequences in the inputs. These\nfilters result in efficient predictions as well as learning interpretable\npatterns in the data. We empirically evaluate our framework on real-world\nbenchmarks showing that the proposed DACNN algorithm obtains a competitive\nperformance compared to the state-of-the-art while benefiting from a less\ncomplicated yet more interpretable model.\n", "versions": [{"version": "v1", "created": "Tue, 12 Nov 2019 16:00:56 GMT"}], "update_date": "2019-11-13", "authors_parsed": [["Hosseini", "Babak", ""], ["Montagne", "Romain", ""], ["Hammer", "Barbara", ""]]}, {"id": "1911.04970", "submitter": "K\\\"ur\\c{s}at Tekb{\\i}y{\\i}k", "authors": "K\\\"ur\\c{s}at Tekb{\\i}y{\\i}k, Ali R{\\i}za Ekti, Ali G\\\"or\\c{c}in,\n  G\\\"une\\c{s} Karabulut Kurt, Cihat Ke\\c{c}eci", "title": "Robust and Fast Automatic Modulation Classification with CNN under\n  Multipath Fading Channels", "comments": null, "journal-ref": null, "doi": "10.1109/VTC2020-Spring48590.2020.9128408", "report-no": null, "categories": "cs.LG eess.SP stat.ML", "license": "http://creativecommons.org/licenses/by-sa/4.0/", "abstract": "  Automatic modulation classification (AMC) has been studied for more than a\nquarter of a century; however, it has been difficult to design a classifier\nthat operates successfully under changing multipath fading conditions and other\nimpairments. Recently, deep learning (DL)-based methods are adopted by AMC\nsystems and major improvements are reported. In this paper, a novel\nconvolutional neural network (CNN) classifier model is proposed to classify\nmodulation classes in terms of their families, i.e., types. The proposed\nclassifier is robust against realistic wireless channel impairments and in\nrelation to that when the data sets that are utilized for testing and\nevaluating the proposed methods are considered, it is seen that RadioML2016.10a\nis the main dataset utilized for testing and evaluation of the proposed\nmethods. However, the channel effects incorporated in this dataset and some\nothers may lack the appropriate modeling of the real-world conditions since it\nonly considers two distributions for channel models for a single tap\nconfiguration. Therefore, in this paper, a more comprehensive dataset, named as\nHisarMod2019.1, is also introduced, considering real-life applicability.\nHisarMod2019.1 includes 26 modulation classes passing through the channels with\n5 different fading types and several numbers of taps for classification. It is\nshown that the proposed model performs better than the existing models in terms\nof both accuracy and training time under more realistic conditions. Even more,\nsurpassed their performance when the RadioML2016.10a dataset is utilized.\n", "versions": [{"version": "v1", "created": "Tue, 12 Nov 2019 16:02:52 GMT"}, {"version": "v2", "created": "Sat, 7 Mar 2020 12:24:02 GMT"}], "update_date": "2020-09-01", "authors_parsed": [["Tekb\u0131y\u0131k", "K\u00fcr\u015fat", ""], ["Ekti", "Ali R\u0131za", ""], ["G\u00f6r\u00e7in", "Ali", ""], ["Kurt", "G\u00fcne\u015f Karabulut", ""], ["Ke\u00e7eci", "Cihat", ""]]}, {"id": "1911.04971", "submitter": "Tal Daniel", "authors": "Tal Daniel, Thanard Kurutach and Aviv Tamar", "title": "Deep Variational Semi-Supervised Novelty Detection", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV cs.RO stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In anomaly detection (AD), one seeks to identify whether a test sample is\nabnormal, given a data set of normal samples. A recent and promising approach\nto AD relies on deep generative models, such as variational autoencoders\n(VAEs), for unsupervised learning of the normal data distribution. In\nsemi-supervised AD (SSAD), the data also includes a small sample of labeled\nanomalies. In this work, we propose two variational methods for training VAEs\nfor SSAD. The intuitive idea in both methods is to train the encoder to\n`separate' between latent vectors for normal and outlier data. We show that\nthis idea can be derived from principled probabilistic formulations of the\nproblem, and propose simple and effective algorithms. Our methods can be\napplied to various data types, as we demonstrate on SSAD datasets ranging from\nnatural images to astronomy and medicine, can be combined with any VAE model\narchitecture, and are naturally compatible with ensembling. When comparing to\nstate-of-the-art SSAD methods that are not specific to particular data types,\nwe obtain marked improvement in outlier detection.\n", "versions": [{"version": "v1", "created": "Tue, 12 Nov 2019 16:03:50 GMT"}, {"version": "v2", "created": "Sat, 22 May 2021 08:52:08 GMT"}], "update_date": "2021-05-25", "authors_parsed": [["Daniel", "Tal", ""], ["Kurutach", "Thanard", ""], ["Tamar", "Aviv", ""]]}, {"id": "1911.04972", "submitter": "Tristan Carsault", "authors": "Tristan Carsault, Andrew McLeod, Philippe Esling, J\\'er\\^ome Nika,\n  Eita Nakamura and Kazuyoshi Yoshii", "title": "Multi-Step Chord Sequence Prediction Based on Aggregated Multi-Scale\n  Encoder-Decoder Network", "comments": "Accepted for publication in MLSP, 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.SD eess.AS stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper studies the prediction of chord progressions for jazz music by\nrelying on machine learning models. The motivation of our study comes from the\nrecent success of neural networks for performing automatic music composition.\nAlthough high accuracies are obtained in single-step prediction scenarios, most\nmodels fail to generate accurate multi-step chord predictions. In this paper,\nwe postulate that this comes from the multi-scale structure of musical\ninformation and propose new architectures based on an iterative temporal\naggregation of input labels. Specifically, the input and ground truth labels\nare merged into increasingly large temporal bags, on which we train a family of\nencoder-decoder networks for each temporal scale. In a second step, we use\nthese pre-trained encoder bottleneck features at each scale in order to train a\nfinal encoder-decoder network. Furthermore, we rely on different reductions of\nthe initial chord alphabet into three adapted chord alphabets. We perform\nevaluations against several state-of-the-art models and show that our\nmulti-scale architecture outperforms existing methods in terms of accuracy and\nperplexity, while requiring relatively few parameters. We analyze musical\nproperties of the results, showing the influence of downbeat position within\nthe analysis window on accuracy, and evaluate errors using a musically-informed\ndistance metric.\n", "versions": [{"version": "v1", "created": "Tue, 12 Nov 2019 16:04:04 GMT"}], "update_date": "2019-11-13", "authors_parsed": [["Carsault", "Tristan", ""], ["McLeod", "Andrew", ""], ["Esling", "Philippe", ""], ["Nika", "J\u00e9r\u00f4me", ""], ["Nakamura", "Eita", ""], ["Yoshii", "Kazuyoshi", ""]]}, {"id": "1911.04973", "submitter": "Tristan Carsault", "authors": "Tristan Carsault, J\\'er\\^ome Nika and Philippe Esling", "title": "Using musical relationships between chord labels in automatic chord\n  extraction tasks", "comments": "Accepted for publication in ISMIR, 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SD cs.IR cs.LG eess.AS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent researches on Automatic Chord Extraction (ACE) have focused on the\nimprovement of models based on machine learning. However, most models still\nfail to take into account the prior knowledge underlying the labeling alphabets\n(chord labels). Furthermore, recent works have shown that ACE performances are\nconverging towards a glass ceiling. Therefore, this prompts the need to focus\non other aspects of the task, such as the introduction of musical knowledge in\nthe representation, the improvement of the models towards more complex chord\nalphabets and the development of more adapted evaluation methods.\n  In this paper, we propose to exploit specific properties and relationships\nbetween chord labels in order to improve the learning of statistical ACE\nmodels. Hence, we analyze the interdependence of the representations of chords\nand their associated distances, the precision of the chord alphabets, and the\nimpact of the reduction of the alphabet before or after training of the model.\nFurthermore, we propose new training losses based on musical theory. We show\nthat these improve the results of ACE systems based on Convolutional Neural\nNetworks. By performing an in-depth analysis of our results, we uncover a set\nof related insights on ACE tasks based on statistical models, and also\nformalize the musical meaning of some classification errors.\n", "versions": [{"version": "v1", "created": "Tue, 12 Nov 2019 16:04:22 GMT"}, {"version": "v2", "created": "Thu, 14 Nov 2019 15:32:30 GMT"}], "update_date": "2019-11-15", "authors_parsed": [["Carsault", "Tristan", ""], ["Nika", "J\u00e9r\u00f4me", ""], ["Esling", "Philippe", ""]]}, {"id": "1911.04974", "submitter": "Benjamin Lengerich", "authors": "Benjamin Lengerich, Sarah Tan, Chun-Hao Chang, Giles Hooker, Rich\n  Caruana", "title": "Purifying Interaction Effects with the Functional ANOVA: An Efficient\n  Algorithm for Recovering Identifiable Additive Models", "comments": "AISTATS 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.AI cs.LG stat.ME", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Models which estimate main effects of individual variables alongside\ninteraction effects have an identifiability challenge: effects can be freely\nmoved between main effects and interaction effects without changing the model\nprediction. This is a critical problem for interpretability because it permits\n\"contradictory\" models to represent the same function. To solve this problem,\nwe propose pure interaction effects: variance in the outcome which cannot be\nrepresented by any smaller subset of features. This definition has an\nequivalence with the Functional ANOVA decomposition. To compute this\ndecomposition, we present a fast, exact algorithm that transforms any\npiecewise-constant function (such as a tree-based model) into a purified,\ncanonical representation. We apply this algorithm to Generalized Additive\nModels with interactions trained on several datasets and show large disparity,\nincluding contradictions, between the effects before and after purification.\nThese results underscore the need to specify data distributions and ensure\nidentifiability before interpreting model parameters.\n", "versions": [{"version": "v1", "created": "Tue, 12 Nov 2019 16:06:21 GMT"}, {"version": "v2", "created": "Sun, 19 Apr 2020 20:20:28 GMT"}, {"version": "v3", "created": "Fri, 1 May 2020 21:45:40 GMT"}], "update_date": "2020-05-05", "authors_parsed": [["Lengerich", "Benjamin", ""], ["Tan", "Sarah", ""], ["Chang", "Chun-Hao", ""], ["Hooker", "Giles", ""], ["Caruana", "Rich", ""]]}, {"id": "1911.04975", "submitter": "Tomasz Arodz", "authors": "Aliakbar Panahi, Seyran Saeedi, Tom Arodz", "title": "word2ket: Space-efficient Word Embeddings inspired by Quantum\n  Entanglement", "comments": null, "journal-ref": "International Conference on Learning Representations 2020", "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep learning natural language processing models often use vector word\nembeddings, such as word2vec or GloVe, to represent words. A discrete sequence\nof words can be much more easily integrated with downstream neural layers if it\nis represented as a sequence of continuous vectors. Also, semantic\nrelationships between words, learned from a text corpus, can be encoded in the\nrelative configurations of the embedding vectors. However, storing and\naccessing embedding vectors for all words in a dictionary requires large amount\nof space, and may stain systems with limited GPU memory. Here, we used\napproaches inspired by quantum computing to propose two related methods, {\\em\nword2ket} and {\\em word2ketXS}, for storing word embedding matrix during\ntraining and inference in a highly efficient way. Our approach achieves a\nhundred-fold or more reduction in the space required to store the embeddings\nwith almost no relative drop in accuracy in practical natural language\nprocessing tasks.\n", "versions": [{"version": "v1", "created": "Tue, 12 Nov 2019 16:06:50 GMT"}, {"version": "v2", "created": "Mon, 10 Feb 2020 12:23:59 GMT"}, {"version": "v3", "created": "Tue, 3 Mar 2020 14:08:07 GMT"}], "update_date": "2020-03-04", "authors_parsed": [["Panahi", "Aliakbar", ""], ["Saeedi", "Seyran", ""], ["Arodz", "Tom", ""]]}, {"id": "1911.04986", "submitter": "Louis van Harten", "authors": "Louis D. van Harten, Jelmer M. Wolterink, Joost J.C. Verhoeff, Ivana\n  I\\v{s}gum", "title": "Automatic Online Quality Control of Synthetic CTs", "comments": "SPIE Medical Imaging 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.IV cs.CV cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Accurate MR-to-CT synthesis is a requirement for MR-only workflows in\nradiotherapy (RT) treatment planning. In recent years, deep learning-based\napproaches have shown impressive results in this field. However, to prevent\ndownstream errors in RT treatment planning, it is important that deep learning\nmodels are only applied to data for which they are trained and that generated\nsynthetic CT (sCT) images do not contain severe errors. For this, a mechanism\nfor online quality control should be in place. In this work, we use an ensemble\nof sCT generators and assess their disagreement as a measure of uncertainty of\nthe results. We show that this uncertainty measure can be used for two kinds of\nonline quality control. First, to detect input images that are outside the\nexpected distribution of MR images. Second, to identify sCT images that were\ngenerated from suitable MR images but potentially contain errors. Such\nautomatic online quality control for sCT generation is likely to become an\nintegral part of MR-only RT workflows.\n", "versions": [{"version": "v1", "created": "Tue, 12 Nov 2019 16:19:20 GMT"}], "update_date": "2019-11-13", "authors_parsed": [["van Harten", "Louis D.", ""], ["Wolterink", "Jelmer M.", ""], ["Verhoeff", "Joost J. C.", ""], ["I\u0161gum", "Ivana", ""]]}, {"id": "1911.05010", "submitter": "Tianyu Li", "authors": "Tianyu Li and Bogdan Mazoure and Doina Precup and Guillaume Rabusseau", "title": "Efficient Planning under Partial Observability with Unnormalized Q\n  Functions and Spectral Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Learning and planning in partially-observable domains is one of the most\ndifficult problems in reinforcement learning. Traditional methods consider\nthese two problems as independent, resulting in a classical two-stage paradigm:\nfirst learn the environment dynamics and then plan accordingly. This approach,\nhowever, disconnects the two problems and can consequently lead to algorithms\nthat are sample inefficient and time consuming. In this paper, we propose a\nnovel algorithm that combines learning and planning together. Our algorithm is\nclosely related to the spectral learning algorithm for predicitive state\nrepresentations and offers appealing theoretical guarantees and time\ncomplexity. We empirically show on two domains that our approach is more sample\nand time efficient compared to classical methods.\n", "versions": [{"version": "v1", "created": "Tue, 12 Nov 2019 16:56:37 GMT"}, {"version": "v2", "created": "Fri, 22 Nov 2019 02:37:51 GMT"}], "update_date": "2019-11-25", "authors_parsed": [["Li", "Tianyu", ""], ["Mazoure", "Bogdan", ""], ["Precup", "Doina", ""], ["Rabusseau", "Guillaume", ""]]}, {"id": "1911.05013", "submitter": "Vishaal Udandarao", "authors": "Abhishek Agarwal, Nikhil Sachdeva, Raj Kamal Yadav, Vishaal Udandarao,\n  Vrinda Mittal, Anubha Gupta, Abhinav Mathur", "title": "EDUQA: Educational Domain Question Answering System using Conceptual\n  Network Mapping", "comments": "Published in the 44th International Conference on Acoustics, Speech,\n  and Signal Processing (ICASSP) 2019", "journal-ref": "IEEE ICASSP (2019) 8137-8141", "doi": "10.1109/ICASSP.2019.8683538", "report-no": null, "categories": "cs.AI cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Most of the existing question answering models can be largely compiled into\ntwo categories: i) open domain question answering models that answer generic\nquestions and use large-scale knowledge base along with the targeted web-corpus\nretrieval and ii) closed domain question answering models that address focused\nquestioning area and use complex deep learning models. Both the above models\nderive answers through textual comprehension methods. Due to their inability to\ncapture the pedagogical meaning of textual content, these models are not\nappropriately suited to the educational field for pedagogy. In this paper, we\npropose an on-the-fly conceptual network model that incorporates educational\nsemantics. The proposed model preserves correlations between conceptual\nentities by applying intelligent indexing algorithms on the concept network so\nas to improve answer generation. This model can be utilized for building\ninteractive conversational agents for aiding classroom learning.\n", "versions": [{"version": "v1", "created": "Tue, 12 Nov 2019 17:11:55 GMT"}], "update_date": "2019-11-13", "authors_parsed": [["Agarwal", "Abhishek", ""], ["Sachdeva", "Nikhil", ""], ["Yadav", "Raj Kamal", ""], ["Udandarao", "Vishaal", ""], ["Mittal", "Vrinda", ""], ["Gupta", "Anubha", ""], ["Mathur", "Abhinav", ""]]}, {"id": "1911.05020", "submitter": "Jianjun Hu", "authors": "Yabo Dan, Yong Zhao, Xiang Li, Shaobo Li, Ming Hu and Jianjun Hu", "title": "Generative adversarial networks (GAN) based efficient sampling of\n  chemical space for inverse design of inorganic materials", "comments": "15 pages", "journal-ref": "npj Comput Mater 6, 84 (2020)", "doi": "10.1038/s41524-020-00352-0", "report-no": null, "categories": "cs.LG cs.NE stat.ML", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  A major challenge in materials design is how to efficiently search the vast\nchemical design space to find the materials with desired properties. One\neffective strategy is to develop sampling algorithms that can exploit both\nexplicit chemical knowledge and implicit composition rules embodied in the\nlarge materials database. Here, we propose a generative machine learning model\n(MatGAN) based on a generative adversarial network (GAN) for efficient\ngeneration of new hypothetical inorganic materials. Trained with materials from\nthe ICSD database, our GAN model can generate hypothetical materials not\nexisting in the training dataset, reaching a novelty of 92.53% when generating\n2 million samples. The percentage of chemically valid (charge neutral and\nelectronegativity balanced) samples out of all generated ones reaches 84.5% by\nour GAN when trained with materials from ICSD even though no such chemical\nrules are explicitly enforced in our GAN model, indicating its capability to\nlearn implicit chemical composition rules. Our algorithm could be used to speed\nup inverse design or computational screening of inorganic materials.\n", "versions": [{"version": "v1", "created": "Tue, 12 Nov 2019 17:31:37 GMT"}], "update_date": "2020-06-30", "authors_parsed": [["Dan", "Yabo", ""], ["Zhao", "Yong", ""], ["Li", "Xiang", ""], ["Li", "Shaobo", ""], ["Hu", "Ming", ""], ["Hu", "Jianjun", ""]]}, {"id": "1911.05030", "submitter": "Jean Barbier Dr.", "authors": "Jean Barbier and Nicolas Macris", "title": "0-1 phase transitions in sparse spiked matrix estimation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IT cond-mat.dis-nn cs.LG math.IT math.PR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider statistical models of estimation of a rank-one matrix (the spike)\ncorrupted by an additive gaussian noise matrix in the sparse limit. In this\nlimit the underlying hidden vector (that constructs the rank-one matrix) has a\nnumber of non-zero components that scales sub-linearly with the total dimension\nof the vector, and the signal strength tends to infinity at an appropriate\nspeed. We prove explicit low-dimensional variational formulas for the\nasymptotic mutual information between the spike and the observed noisy matrix\nin suitable sparse limits. For Bernoulli and Bernoulli-Rademacher distributed\nvectors, and when the sparsity and signal strength satisfy an appropriate\nscaling relation, these formulas imply sharp 0-1 phase transitions for the\nasymptotic minimum mean-square-error. A similar phase transition was analyzed\nrecently in the context of sparse high-dimensional linear regression\n(compressive sensing).\n", "versions": [{"version": "v1", "created": "Tue, 12 Nov 2019 17:43:10 GMT"}], "update_date": "2019-11-13", "authors_parsed": [["Barbier", "Jean", ""], ["Macris", "Nicolas", ""]]}, {"id": "1911.05034", "submitter": "Tianxiang Sun", "authors": "Tianxiang Sun, Yunfan Shao, Xiaonan Li, Pengfei Liu, Hang Yan, Xipeng\n  Qiu, Xuanjing Huang", "title": "Learning Sparse Sharing Architectures for Multiple Tasks", "comments": "Accepted by AAAI 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Most existing deep multi-task learning models are based on parameter sharing,\nsuch as hard sharing, hierarchical sharing, and soft sharing. How choosing a\nsuitable sharing mechanism depends on the relations among the tasks, which is\nnot easy since it is difficult to understand the underlying shared factors\namong these tasks. In this paper, we propose a novel parameter sharing\nmechanism, named \\emph{Sparse Sharing}. Given multiple tasks, our approach\nautomatically finds a sparse sharing structure. We start with an\nover-parameterized base network, from which each task extracts a subnetwork.\nThe subnetworks of multiple tasks are partially overlapped and trained in\nparallel. We show that both hard sharing and hierarchical sharing can be\nformulated as particular instances of the sparse sharing framework. We conduct\nextensive experiments on three sequence labeling tasks. Compared with\nsingle-task models and three typical multi-task learning baselines, our\nproposed approach achieves consistent improvement while requiring fewer\nparameters.\n", "versions": [{"version": "v1", "created": "Tue, 12 Nov 2019 17:50:35 GMT"}, {"version": "v2", "created": "Sat, 16 Nov 2019 13:53:10 GMT"}], "update_date": "2019-11-19", "authors_parsed": [["Sun", "Tianxiang", ""], ["Shao", "Yunfan", ""], ["Li", "Xiaonan", ""], ["Liu", "Pengfei", ""], ["Yan", "Hang", ""], ["Qiu", "Xipeng", ""], ["Huang", "Xuanjing", ""]]}, {"id": "1911.05035", "submitter": "Konstantin Rusch", "authors": "Konstantin Rusch, John W. Pearson, Konstantinos C. Zygalakis", "title": "Constructing Gradient Controllable Recurrent Neural Networks Using\n  Hamiltonian Dynamics", "comments": "Reasons: 1. theoretical result of bounding the gradient dynamics is\n  highly important when tackling the exploding gradient problem. However, we\n  only proved the boundedness in one dimension and cannot generalize to the\n  higher dimensional case, as the Hamiltonian argument is not valid in the\n  general higher dimensional case. 2. The only medium strong performance on the\n  widely used sMNIST problem", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.NA math.NA math.OC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recurrent neural networks (RNNs) have gained a great deal of attention in\nsolving sequential learning problems. The learning of long-term dependencies,\nhowever, remains challenging due to the problem of a vanishing or exploding\nhidden states gradient. By exploring further the recently established\nconnections between RNNs and dynamical systems we propose a novel RNN\narchitecture, which we call a Hamiltonian recurrent neural network (Hamiltonian\nRNN), based on a symplectic discretization of an appropriately chosen\nHamiltonian system. The key benefit of this approach is that the corresponding\nRNN inherits the favorable long time properties of the Hamiltonian system,\nwhich in turn allows us to control the hidden states gradient with a\nhyperparameter of the Hamiltonian RNN architecture. This enables us to handle\nsequential learning problems with arbitrary sequence lengths, since for a range\nof values of this hyperparameter the gradient neither vanishes nor explodes.\nAdditionally, we provide a heuristic for the optimal choice of the\nhyperparameter, which we use in our numerical simulations to illustrate that\nthe Hamiltonian RNN is able to outperform other state-of-the-art RNNs without\nthe need of computationally intensive hyperparameter optimization.\n", "versions": [{"version": "v1", "created": "Mon, 11 Nov 2019 10:38:10 GMT"}, {"version": "v2", "created": "Mon, 16 Mar 2020 08:22:52 GMT"}], "update_date": "2020-03-17", "authors_parsed": [["Rusch", "Konstantin", ""], ["Pearson", "John W.", ""], ["Zygalakis", "Konstantinos C.", ""]]}, {"id": "1911.05045", "submitter": "Michele Alberti", "authors": "Michele Alberti, Angela Botros, Narayan Schuez, Rolf Ingold, Marcus\n  Liwicki and Mathias Seuret", "title": "Trainable Spectrally Initializable Matrix Transformations in\n  Convolutional Neural Networks", "comments": "8 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this work, we investigate the application of trainable and spectrally\ninitializable matrix transformations on the feature maps produced by\nconvolution operations. While previous literature has already demonstrated the\npossibility of adding static spectral transformations as feature processors,\nour focus is on more general trainable transforms. We study the transforms in\nvarious architectural configurations on four datasets of different nature: from\nmedical (ColorectalHist, HAM10000) and natural (Flowers, ImageNet) images to\nhistorical documents (CB55) and handwriting recognition (GPDS). With rigorous\nexperiments that control for the number of parameters and randomness, we show\nthat networks utilizing the introduced matrix transformations outperform\nvanilla neural networks. The observed accuracy increases by an average of 2.2\nacross all datasets. In addition, we show that the benefit of spectral\ninitialization leads to significantly faster convergence, as opposed to\nrandomly initialized matrix transformations. The transformations are\nimplemented as auto-differentiable PyTorch modules that can be incorporated\ninto any neural network architecture. The entire code base is open-source.\n", "versions": [{"version": "v1", "created": "Tue, 12 Nov 2019 18:06:52 GMT"}, {"version": "v2", "created": "Wed, 13 Nov 2019 17:36:08 GMT"}], "update_date": "2019-11-14", "authors_parsed": [["Alberti", "Michele", ""], ["Botros", "Angela", ""], ["Schuez", "Narayan", ""], ["Ingold", "Rolf", ""], ["Liwicki", "Marcus", ""], ["Seuret", "Mathias", ""]]}, {"id": "1911.05047", "submitter": "Xiao Li", "authors": "Xiao Li, Shixiang Chen, Zengde Deng, Qing Qu, Zhihui Zhu and Anthony\n  Man Cho So", "title": "Weakly Convex Optimization over Stiefel Manifold Using Riemannian\n  Subgradient-Type Methods", "comments": "30 pages. Accepted to SIAM Journal on Optimization", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.OC cs.IT cs.LG math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider a class of nonsmooth optimization problems over the Stiefel\nmanifold, in which the objective function is weakly convex in the ambient\nEuclidean space. Such problems are ubiquitous in engineering applications but\nstill largely unexplored. We present a family of Riemannian subgradient-type\nmethods -- namely Riemannain subgradient, incremental subgradient, and\nstochastic subgradient methods -- to solve these problems and show that they\nall have an iteration complexity of ${\\cal O}(\\varepsilon^{-4})$ for driving a\nnatural stationarity measure below $\\varepsilon$. In addition, we establish the\nlocal linear convergence of the Riemannian subgradient and incremental\nsubgradient methods when the problem at hand further satisfies a sharpness\nproperty and the algorithms are properly initialized and use geometrically\ndiminishing stepsizes. To the best of our knowledge, these are the first\nconvergence guarantees for using Riemannian subgradient-type methods to\noptimize a class of nonconvex nonsmooth functions over the Stiefel manifold.\nThe fundamental ingredient in the proof of the aforementioned convergence\nresults is a new Riemannian subgradient inequality for restrictions of weakly\nconvex functions on the Stiefel manifold, which could be of independent\ninterest. We also show that our convergence results can be extended to handle a\nclass of compact embedded submanifolds of the Euclidean space. Finally, we\ndiscuss the sharpness properties of various formulations of the robust subspace\nrecovery and orthogonal dictionary learning problems and demonstrate the\nconvergence performance of the algorithms on both problems via numerical\nsimulations.\n", "versions": [{"version": "v1", "created": "Tue, 12 Nov 2019 18:12:17 GMT"}, {"version": "v2", "created": "Thu, 5 Dec 2019 18:11:50 GMT"}, {"version": "v3", "created": "Tue, 18 Feb 2020 14:04:32 GMT"}, {"version": "v4", "created": "Thu, 25 Mar 2021 02:09:03 GMT"}], "update_date": "2021-03-26", "authors_parsed": [["Li", "Xiao", ""], ["Chen", "Shixiang", ""], ["Deng", "Zengde", ""], ["Qu", "Qing", ""], ["Zhu", "Zhihui", ""], ["So", "Anthony Man Cho", ""]]}, {"id": "1911.05050", "submitter": "Yan Zhang", "authors": "Yan Zhang, Robert J. Ravier, Michael M. Zavlanos, Vahid Tarokh", "title": "A Distributed Online Convex Optimization Algorithm with Improved Dynamic\n  Regret", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.OC cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we consider the problem of distributed online convex\noptimization, where a network of local agents aim to jointly optimize a convex\nfunction over a period of multiple time steps. The agents do not have any\ninformation about the future. Existing algorithms have established dynamic\nregret bounds that have explicit dependence on the number of time steps. In\nthis work, we show that we can remove this dependence assuming that the local\nobjective functions are strongly convex. More precisely, we propose a gradient\ntracking algorithm where agents jointly communicate and descend based on\ncorrected gradient steps. We verify our theoretical results through numerical\nexperiments.\n", "versions": [{"version": "v1", "created": "Tue, 12 Nov 2019 18:14:21 GMT"}], "update_date": "2019-11-13", "authors_parsed": [["Zhang", "Yan", ""], ["Ravier", "Robert J.", ""], ["Zavlanos", "Michael M.", ""], ["Tarokh", "Vahid", ""]]}, {"id": "1911.05059", "submitter": "Quanquan Gu", "authors": "Yuan Cao and Quanquan Gu", "title": "Tight Sample Complexity of Learning One-hidden-layer Convolutional\n  Neural Networks", "comments": "45 pages, 3 figures, 1 table. In NeurIPS 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the sample complexity of learning one-hidden-layer convolutional\nneural networks (CNNs) with non-overlapping filters. We propose a novel\nalgorithm called approximate gradient descent for training CNNs, and show that,\nwith high probability, the proposed algorithm with random initialization grants\na linear convergence to the ground-truth parameters up to statistical\nprecision. Compared with existing work, our result applies to general\nnon-trivial, monotonic and Lipschitz continuous activation functions including\nReLU, Leaky ReLU, Sigmod and Softplus etc. Moreover, our sample complexity\nbeats existing results in the dependency of the number of hidden nodes and\nfilter size. In fact, our result matches the information-theoretic lower bound\nfor learning one-hidden-layer CNNs with linear activation functions, suggesting\nthat our sample complexity is tight. Our theoretical analysis is backed up by\nnumerical experiments.\n", "versions": [{"version": "v1", "created": "Tue, 12 Nov 2019 18:34:19 GMT"}], "update_date": "2019-11-13", "authors_parsed": [["Cao", "Yuan", ""], ["Gu", "Quanquan", ""]]}, {"id": "1911.05063", "submitter": "Krishna Murthy Jatavallabhula", "authors": "Krishna Murthy Jatavallabhula, Edward Smith, Jean-Francois Lafleche,\n  Clement Fuji Tsang, Artem Rozantsev, Wenzheng Chen, Tommy Xiang, Rev\n  Lebaredian, Sanja Fidler", "title": "Kaolin: A PyTorch Library for Accelerating 3D Deep Learning Research", "comments": "Kaolin is available as open-source software at\n  https://github.com/NVIDIAGameWorks/kaolin/", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG cs.RO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present Kaolin, a PyTorch library aiming to accelerate 3D deep learning\nresearch. Kaolin provides efficient implementations of differentiable 3D\nmodules for use in deep learning systems. With functionality to load and\npreprocess several popular 3D datasets, and native functions to manipulate\nmeshes, pointclouds, signed distance functions, and voxel grids, Kaolin\nmitigates the need to write wasteful boilerplate code. Kaolin packages together\nseveral differentiable graphics modules including rendering, lighting, shading,\nand view warping. Kaolin also supports an array of loss functions and\nevaluation metrics for seamless evaluation and provides visualization\nfunctionality to render the 3D results. Importantly, we curate a comprehensive\nmodel zoo comprising many state-of-the-art 3D deep learning architectures, to\nserve as a starting point for future research endeavours. Kaolin is available\nas open-source software at https://github.com/NVIDIAGameWorks/kaolin/.\n", "versions": [{"version": "v1", "created": "Tue, 12 Nov 2019 18:47:37 GMT"}, {"version": "v2", "created": "Wed, 13 Nov 2019 18:34:03 GMT"}], "update_date": "2019-11-14", "authors_parsed": [["Jatavallabhula", "Krishna Murthy", ""], ["Smith", "Edward", ""], ["Lafleche", "Jean-Francois", ""], ["Tsang", "Clement Fuji", ""], ["Rozantsev", "Artem", ""], ["Chen", "Wenzheng", ""], ["Xiang", "Tommy", ""], ["Lebaredian", "Rev", ""], ["Fidler", "Sanja", ""]]}, {"id": "1911.05071", "submitter": "Yen-Chen Lin", "authors": "Lin Yen-Chen, Maria Bauza, Phillip Isola", "title": "Experience-Embedded Visual Foresight", "comments": "CoRL 2019. Project website: http://yenchenlin.me/evf/", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG cs.RO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Visual foresight gives an agent a window into the future, which it can use to\nanticipate events before they happen and plan strategic behavior. Although\nimpressive results have been achieved on video prediction in constrained\nsettings, these models fail to generalize when confronted with unfamiliar\nreal-world objects. In this paper, we tackle the generalization problem via\nfast adaptation, where we train a prediction model to quickly adapt to the\nobserved visual dynamics of a novel object. Our method, Experience-embedded\nVisual Foresight (EVF), jointly learns a fast adaptation module, which encodes\nobserved trajectories of the new object into a vector embedding, and a visual\nprediction model, which conditions on this embedding to generate physically\nplausible predictions. For evaluation, we compare our method against baselines\non video prediction and benchmark its utility on two real-world control tasks.\nWe show that our method is able to quickly adapt to new visual dynamics and\nachieves lower error than the baselines when manipulating novel objects.\n", "versions": [{"version": "v1", "created": "Tue, 12 Nov 2019 18:58:30 GMT"}, {"version": "v2", "created": "Sun, 17 Nov 2019 14:45:06 GMT"}], "update_date": "2019-11-19", "authors_parsed": [["Yen-Chen", "Lin", ""], ["Bauza", "Maria", ""], ["Isola", "Phillip", ""]]}, {"id": "1911.05072", "submitter": "Zhe Li", "authors": "Zhe Li, Wieland Brendel, Edgar Y. Walker, Erick Cobos, Taliah\n  Muhammad, Jacob Reimer, Matthias Bethge, Fabian H. Sinz, Xaq Pitkow, Andreas\n  S. Tolias", "title": "Learning From Brains How to Regularize Machines", "comments": "14 pages, 7 figures, NeurIPS 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CV q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Despite impressive performance on numerous visual tasks, Convolutional Neural\nNetworks (CNNs) --- unlike brains --- are often highly sensitive to small\nperturbations of their input, e.g. adversarial noise leading to erroneous\ndecisions. We propose to regularize CNNs using large-scale neuroscience data to\nlearn more robust neural features in terms of representational similarity. We\npresented natural images to mice and measured the responses of thousands of\nneurons from cortical visual areas. Next, we denoised the notoriously variable\nneural activity using strong predictive models trained on this large corpus of\nresponses from the mouse visual system, and calculated the representational\nsimilarity for millions of pairs of images from the model's predictions. We\nthen used the neural representation similarity to regularize CNNs trained on\nimage classification by penalizing intermediate representations that deviated\nfrom neural ones. This preserved performance of baseline models when\nclassifying images under standard benchmarks, while maintaining substantially\nhigher performance compared to baseline or control models when classifying\nnoisy images. Moreover, the models regularized with cortical representations\nalso improved model robustness in terms of adversarial attacks. This\ndemonstrates that regularizing with neural data can be an effective tool to\ncreate an inductive bias towards more robust inference.\n", "versions": [{"version": "v1", "created": "Mon, 11 Nov 2019 21:53:26 GMT"}], "update_date": "2019-11-14", "authors_parsed": [["Li", "Zhe", ""], ["Brendel", "Wieland", ""], ["Walker", "Edgar Y.", ""], ["Cobos", "Erick", ""], ["Muhammad", "Taliah", ""], ["Reimer", "Jacob", ""], ["Bethge", "Matthias", ""], ["Sinz", "Fabian H.", ""], ["Pitkow", "Xaq", ""], ["Tolias", "Andreas S.", ""]]}, {"id": "1911.05073", "submitter": "Yaohua Hu", "authors": "Xin Li, Yaohua Hu, Chong Li, Xiaoqi Yang, Tianzi Jiang", "title": "Sparse estimation via $\\ell_q$ optimization method in high-dimensional\n  linear regression", "comments": "32 pages, 1 figure", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG math.OC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we discuss the statistical properties of the $\\ell_q$\noptimization methods $(0<q\\leq 1)$, including the $\\ell_q$ minimization method\nand the $\\ell_q$ regularization method, for estimating a sparse parameter from\nnoisy observations in high-dimensional linear regression with either a\ndeterministic or random design. For this purpose, we introduce a general\n$q$-restricted eigenvalue condition (REC) and provide its sufficient conditions\nin terms of several widely-used regularity conditions such as sparse eigenvalue\ncondition, restricted isometry property, and mutual incoherence property. By\nvirtue of the $q$-REC, we exhibit the stable recovery property of the $\\ell_q$\noptimization methods for either deterministic or random designs by showing that\nthe $\\ell_2$ recovery bound $O(\\epsilon^2)$ for the $\\ell_q$ minimization\nmethod and the oracle inequality and $\\ell_2$ recovery bound\n$O(\\lambda^{\\frac{2}{2-q}}s)$ for the $\\ell_q$ regularization method hold\nrespectively with high probability. The results in this paper are nonasymptotic\nand only assume the weak $q$-REC. The preliminary numerical results verify the\nestablished statistical property and demonstrate the advantages of the $\\ell_q$\nregularization method over some existing sparse optimization methods.\n", "versions": [{"version": "v1", "created": "Tue, 12 Nov 2019 00:34:18 GMT"}], "update_date": "2019-11-14", "authors_parsed": [["Li", "Xin", ""], ["Hu", "Yaohua", ""], ["Li", "Chong", ""], ["Yang", "Xiaoqi", ""], ["Jiang", "Tianzi", ""]]}, {"id": "1911.05075", "submitter": "Kira Maag", "authors": "Kira Maag, Matthias Rottmann and Hanno Gottschalk", "title": "Time-Dynamic Estimates of the Reliability of Deep Semantic Segmentation\n  Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG eess.IV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In the semantic segmentation of street scenes with neural networks, the\nreliability of predictions is of highest interest. The assessment of neural\nnetworks by means of uncertainties is a common ansatz to prevent safety issues.\nAs in applications like automated driving, video streams of images are\navailable, we present a time-dynamic approach to investigating uncertainties\nand assessing the prediction quality of neural networks. We track segments over\ntime and gather aggregated metrics per segment, thus obtaining time series of\nmetrics from which we assess prediction quality. This is done by either\nclassifying between intersection over union equal to 0 and greater than 0 or\npredicting the intersection over union directly. We study different models for\nthese two tasks and analyze the influence of the time series length on the\npredictive power of our metrics.\n", "versions": [{"version": "v1", "created": "Tue, 12 Nov 2019 13:55:50 GMT"}, {"version": "v2", "created": "Mon, 5 Oct 2020 09:37:54 GMT"}], "update_date": "2020-10-06", "authors_parsed": [["Maag", "Kira", ""], ["Rottmann", "Matthias", ""], ["Gottschalk", "Hanno", ""]]}, {"id": "1911.05076", "submitter": "Octavian-Eugen Ganea", "authors": "Gregor Bachmann, Gary B\\'ecigneul, Octavian-Eugen Ganea", "title": "Constant Curvature Graph Convolutional Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Interest has been rising lately towards methods representing data in\nnon-Euclidean spaces, e.g. hyperbolic or spherical, that provide specific\ninductive biases useful for certain real-world data properties, e.g.\nscale-free, hierarchical or cyclical. However, the popular graph neural\nnetworks are currently limited in modeling data only via Euclidean geometry and\nassociated vector space operations. Here, we bridge this gap by proposing\nmathematically grounded generalizations of graph convolutional networks (GCN)\nto (products of) constant curvature spaces. We do this by i) introducing a\nunified formalism that can interpolate smoothly between all geometries of\nconstant curvature, ii) leveraging gyro-barycentric coordinates that generalize\nthe classic Euclidean concept of the center of mass. Our class of models\nsmoothly recover their Euclidean counterparts when the curvature goes to zero\nfrom either side. Empirically, we outperform Euclidean GCNs in the tasks of\nnode classification and distortion minimization for symbolic data exhibiting\nnon-Euclidean behavior, according to their discrete curvature.\n", "versions": [{"version": "v1", "created": "Tue, 12 Nov 2019 16:57:00 GMT"}, {"version": "v2", "created": "Tue, 18 Feb 2020 23:20:10 GMT"}, {"version": "v3", "created": "Tue, 19 May 2020 17:48:48 GMT"}], "update_date": "2020-05-20", "authors_parsed": [["Bachmann", "Gregor", ""], ["B\u00e9cigneul", "Gary", ""], ["Ganea", "Octavian-Eugen", ""]]}, {"id": "1911.05100", "submitter": "Djordje Gligorijevic", "authors": "Djordje Gligorijevic, Jelena Gligorijevic and Aaron Flores", "title": "Time-Aware Prospective Modeling of Users for Online Display Advertising", "comments": "Accepted at AdKDD 2019 workshop at KDD'19 conference, Anchorage,\n  Alaska, USA", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.IR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Prospective display advertising poses a great challenge for large advertising\nplatforms as the strongest predictive signals of users are not eligible to be\nused in the conversion prediction systems. To that end efforts are made to\ncollect as much information as possible about each user from various data\nsources and to design powerful models that can capture weaker signals\nultimately obtaining good quality of conversion prediction probability\nestimates. In this study we propose a novel time-aware approach to model\nheterogeneous sequences of users' activities and capture implicit signals of\nusers' conversion intents. On two real-world datasets we show that our approach\noutperforms other, previously proposed approaches, while providing\ninterpretability of signal impact to conversion probability.\n", "versions": [{"version": "v1", "created": "Tue, 12 Nov 2019 19:06:59 GMT"}], "update_date": "2019-11-14", "authors_parsed": [["Gligorijevic", "Djordje", ""], ["Gligorijevic", "Jelena", ""], ["Flores", "Aaron", ""]]}, {"id": "1911.05109", "submitter": "Jeremy Weiss", "authors": "Yoonjung Kim and Jeremy C. Weiss", "title": "Harmonic Mean Point Processes: Proportional Rate Error Minimization for\n  Obtundation Prediction", "comments": "Machine Learning for Health (ML4H) at NeurIPS 2019 - Extended\n  Abstract", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In healthcare, the highest risk individuals for morbidity and mortality are\nrarely those with the greatest modifiable risk. By contrast, many machine\nlearning formulations implicitly attend to the highest risk individuals. We\nfocus on this problem in point processes, a popular modeling technique for the\nanalysis of the temporal event sequences in electronic health records (EHR)\ndata with applications in risk stratification and risk score systems. We show\nthat optimization of the log-likelihood function also gives disproportionate\nattention to high risk individuals and leads to poor prediction results for low\nrisk individuals compared to ones at high risk. We characterize the problem and\npropose an adjusted log-likelihood formulation as a new objective for point\nprocesses. We demonstrate the benefits of our method in simulations and in EHR\ndata of patients admitted to the critical care unit for intracerebral\nhemorrhage.\n", "versions": [{"version": "v1", "created": "Tue, 12 Nov 2019 19:19:36 GMT"}, {"version": "v2", "created": "Thu, 14 Nov 2019 18:45:13 GMT"}], "update_date": "2019-11-15", "authors_parsed": [["Kim", "Yoonjung", ""], ["Weiss", "Jeremy C.", ""]]}, {"id": "1911.05113", "submitter": "Ho Hin Lee", "authors": "Ho Hin Lee, Yucheng Tang, Olivia Tang, Yuchen Xu, Yunqiang Chen,\n  Dashan Gao, Shizhong Han, Riqiang Gao, Michael R. Savona, Richard G.\n  Abramson, Yuankai Huo, Bennett A. Landman", "title": "Semi-Supervised Multi-Organ Segmentation through Quality Assurance\n  Supervision", "comments": "7 pages, 5 figures, Accepted by SPIE 2020: Medical Imaging", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.IV cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Human in-the-loop quality assurance (QA) is typically performed after medical\nimage segmentation to ensure that the systems are performing as intended, as\nwell as identifying and excluding outliers. By performing QA on large-scale,\npreviously unlabeled testing data, categorical QA scores can be generatedIn\nthis paper, we propose a semi-supervised multi-organ segmentation deep neural\nnetwork consisting of a traditional segmentation model generator and a QA\ninvolved discriminator. A large-scale dataset of 2027 volumes are used to train\nthe generator, whose 2-D montage images and segmentation mask with QA scores\nare used to train the discriminator. To generate the QA scores, the 2-D montage\nimages were reviewed manually and coded 0 (success), 1 (errors consistent with\npublished performance), and 2 (gross failure). Then, the ResNet-18 network was\ntrained with 1623 montage images in equal distribution of all three code labels\nand achieved an accuracy 94% for classification predictions with 404 montage\nimages withheld for the test cohort. To assess the performance of using the QA\nsupervision, the discriminator was used as a loss function in a multi-organ\nsegmentation pipeline. The inclusion of QA-loss function boosted performance on\nthe unlabeled test dataset from 714 patients to 951 patients over the baseline\nmodel. Additionally, the number of failures decreased from 606 (29.90%) to 402\n(19.83%). The contributions of the proposed method are threefold: We show that\n(1) the QA scores can be used as a loss function to perform semi-supervised\nlearning for unlabeled data, (2) the well trained discriminator is learnt by QA\nscore rather than traditional true/false, and (3) the performance of\nmulti-organ segmentation on unlabeled datasets can be fine-tuned with more\nrobust and higher accuracy than the original baseline method.\n", "versions": [{"version": "v1", "created": "Tue, 12 Nov 2019 19:35:58 GMT"}], "update_date": "2019-11-14", "authors_parsed": [["Lee", "Ho Hin", ""], ["Tang", "Yucheng", ""], ["Tang", "Olivia", ""], ["Xu", "Yuchen", ""], ["Chen", "Yunqiang", ""], ["Gao", "Dashan", ""], ["Han", "Shizhong", ""], ["Gao", "Riqiang", ""], ["Savona", "Michael R.", ""], ["Abramson", "Richard G.", ""], ["Huo", "Yuankai", ""], ["Landman", "Bennett A.", ""]]}, {"id": "1911.05116", "submitter": "Robert MacKay", "authors": "Nicholas Beale, Heather Battey, Anthony C. Davison, and Robert S.\n  MacKay", "title": "An Unethical Optimization Principle", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "q-fin.RM cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  If an artificial intelligence aims to maximise risk-adjusted return, then\nunder mild conditions it is disproportionately likely to pick an unethical\nstrategy unless the objective function allows sufficiently for this risk. Even\nif the proportion ${\\eta}$ of available unethical strategies is small, the\nprobability ${p_U}$ of picking an unethical strategy can become large; indeed\nunless returns are fat-tailed ${p_U}$ tends to unity as the strategy space\nbecomes large. We define an Unethical Odds Ratio Upsilon (${\\Upsilon}$) that\nallows us to calculate ${p_U}$ from ${\\eta}$, and we derive a simple formula\nfor the limit of ${\\Upsilon}$ as the strategy space becomes large. We give an\nalgorithm for estimating ${\\Upsilon}$ and ${p_U}$ in finite cases and discuss\nhow to deal with infinite strategy spaces. We show how this principle can be\nused to help detect unethical strategies and to estimate ${\\eta}$. Finally we\nsketch some policy implications of this work.\n", "versions": [{"version": "v1", "created": "Tue, 12 Nov 2019 19:41:46 GMT"}], "update_date": "2019-11-14", "authors_parsed": [["Beale", "Nicholas", ""], ["Battey", "Heather", ""], ["Davison", "Anthony C.", ""], ["MacKay", "Robert S.", ""]]}, {"id": "1911.05121", "submitter": "Chufan Gao", "authors": "Chufan Gao, Fabian Falck, Mononito Goswami, Anthony Wertz, Michael R.\n  Pinsky, Artur Dubrawski", "title": "Detecting Patterns of Physiological Response to Hemodynamic Stress via\n  Unsupervised Deep Learning", "comments": "Machine Learning for Health (ML4H) at NeurIPS 2019 - Extended\n  Abstract", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Monitoring physiological responses to hemodynamic stress can help in\ndetermining appropriate treatment and ensuring good patient outcomes.\nPhysicians' intuition suggests that the human body has a number of\nphysiological response patterns to hemorrhage which escalate as blood loss\ncontinues, however the exact etiology and phenotypes of such responses are not\nwell known or understood only at a coarse level. Although previous research has\nshown that machine learning models can perform well in hemorrhage detection and\nsurvival prediction, it is unclear whether machine learning could help to\nidentify and characterize the underlying physiological responses in raw vital\nsign data. We approach this problem by first transforming the high-dimensional\nvital sign time series into a tractable, lower-dimensional latent space using a\ndilated, causal convolutional encoder model trained purely unsupervised.\nSecond, we identify informative clusters in the embeddings. By analyzing the\nclusters of latent embeddings and visualizing them over time, we hypothesize\nthat the clusters correspond to the physiological response patterns that match\nphysicians' intuition. Furthermore, we attempt to evaluate the latent\nembeddings using a variety of methods, such as predicting the cluster labels\nusing explainable features.\n", "versions": [{"version": "v1", "created": "Tue, 12 Nov 2019 19:55:16 GMT"}], "update_date": "2019-11-14", "authors_parsed": [["Gao", "Chufan", ""], ["Falck", "Fabian", ""], ["Goswami", "Mononito", ""], ["Wertz", "Anthony", ""], ["Pinsky", "Michael R.", ""], ["Dubrawski", "Artur", ""]]}, {"id": "1911.05140", "submitter": "Kiret Dhindsa", "authors": "Umaseh Sivanesan and Luis H. Braga and Ranil R. Sonnadara and Kiret\n  Dhindsa", "title": "Unsupervised Medical Image Segmentation with Adversarial Networks: From\n  Edge Diagrams to Segmentation Maps", "comments": "16 pages, 8 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.IV cs.AI cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We develop and approach to unsupervised semantic medical image segmentation\nthat extends previous work with generative adversarial networks. We use\nexisting edge detection methods to construct simple edge diagrams, train a\ngenerative model to convert them into synthetic medical images, and construct a\ndataset of synthetic images with known segmentations using variations on\nextracted edge diagrams. This synthetic dataset is then used to train a\nsupervised image segmentation model. We test our approach on a clinical dataset\nof kidney ultrasound images and the benchmark ISIC 2018 skin lesion dataset. We\nshow that our unsupervised approach is more accurate than previous unsupervised\nmethods, and performs reasonably compared to supervised image segmentation\nmodels. All code and trained models are available at\nhttps://github.com/kiretd/Unsupervised-MIseg.\n", "versions": [{"version": "v1", "created": "Tue, 12 Nov 2019 20:56:33 GMT"}], "update_date": "2019-11-14", "authors_parsed": [["Sivanesan", "Umaseh", ""], ["Braga", "Luis H.", ""], ["Sonnadara", "Ranil R.", ""], ["Dhindsa", "Kiret", ""]]}, {"id": "1911.05142", "submitter": "Zhiyuan Liu", "authors": "Zhiyuan Liu, Huazheng Wang, Fan Shen, Kai Liu, Lijun Chen", "title": "Incentivized Exploration for Multi-Armed Bandits under Reward Drift", "comments": "10 pages, 2 figures, AAAI 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study incentivized exploration for the multi-armed bandit (MAB) problem\nwhere the players receive compensation for exploring arms other than the greedy\nchoice and may provide biased feedback on reward. We seek to understand the\nimpact of this drifted reward feedback by analyzing the performance of three\ninstantiations of the incentivized MAB algorithm: UCB, $\\varepsilon$-Greedy,\nand Thompson Sampling. Our results show that they all achieve $\\mathcal{O}(\\log\nT)$ regret and compensation under the drifted reward, and are therefore\neffective in incentivizing exploration. Numerical examples are provided to\ncomplement the theoretical analysis.\n", "versions": [{"version": "v1", "created": "Tue, 12 Nov 2019 21:04:30 GMT"}, {"version": "v2", "created": "Thu, 12 Dec 2019 21:06:01 GMT"}, {"version": "v3", "created": "Mon, 16 Dec 2019 03:11:49 GMT"}], "update_date": "2019-12-17", "authors_parsed": [["Liu", "Zhiyuan", ""], ["Wang", "Huazheng", ""], ["Shen", "Fan", ""], ["Liu", "Kai", ""], ["Chen", "Lijun", ""]]}, {"id": "1911.05146", "submitter": "Ammar Ahmad Awan", "authors": "Ammar Ahmad Awan, Arpan Jain, Quentin Anthony, Hari Subramoni, and\n  Dhabaleswar K. Panda", "title": "HyPar-Flow: Exploiting MPI and Keras for Scalable Hybrid-Parallel DNN\n  Training using TensorFlow", "comments": "18 pages, 10 figures, Accepted, to be presented at ISC '20", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.AI cs.LG cs.PF", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  To reduce training time of large-scale DNNs, scientists have started to\nexplore parallelization strategies like data-parallelism, model-parallelism,\nand hybrid-parallelism. While data-parallelism has been extensively studied and\ndeveloped, several problems exist in realizing model-parallelism and\nhybrid-parallelism efficiently. Four major problems we focus on are: 1)\ndefining a notion of a distributed model across processes, 2) implementing\nforward/back-propagation across process boundaries that requires explicit\ncommunication, 3) obtaining parallel speedup on an inherently sequential task,\nand 4) achieving scalability without losing out on a model's accuracy. To\naddress these problems, we create HyPar-Flow --- a model-size/-type agnostic,\nscalable, practical, and user-transparent system for hybrid-parallel training\nby exploiting MPI, Keras, and TensorFlow. HyPar-Flow provides a single API that\ncan be used to perform data, model, and hybrid parallel training of any Keras\nmodel at scale. We create an internal distributed representation of the\nuser-provided Keras model, utilize TF's Eager execution features for\ndistributed forward/back-propagation across processes, exploit pipelining to\nimprove performance and leverage efficient MPI primitives for scalable\ncommunication. Between model partitions, we use send and recv to exchange\nlayer-data/partial-errors while allreduce is used to accumulate/average\ngradients across model replicas. Beyond the design and implementation of\nHyPar-Flow, we also provide comprehensive correctness and performance results\non three state-of-the-art HPC systems including TACC Frontera (#5 on\nTop500.org). For ResNet-1001, an ultra-deep model, HyPar-Flow provides: 1) Up\nto 1.6x speedup over Horovod-based data-parallel training, 2) 110x speedup over\nsingle-node on 128 Stampede2 nodes, and 3) 481x speedup over single-node on 512\nFrontera nodes.\n", "versions": [{"version": "v1", "created": "Tue, 12 Nov 2019 21:07:42 GMT"}, {"version": "v2", "created": "Wed, 19 Feb 2020 15:16:53 GMT"}], "update_date": "2020-02-20", "authors_parsed": [["Awan", "Ammar Ahmad", ""], ["Jain", "Arpan", ""], ["Anthony", "Quentin", ""], ["Subramoni", "Hari", ""], ["Panda", "Dhabaleswar K.", ""]]}, {"id": "1911.05151", "submitter": "Ren Yi", "authors": "Ren Yi, Pi-Chuan Chang, Gunjan Baid, Andrew Carroll", "title": "Learning from Data-Rich Problems: A Case Study on Genetic Variant\n  Calling", "comments": "Machine Learning for Health (ML4H) at NeurIPS 2019 - Extended\n  Abstract", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.GN cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Next Generation Sequencing can sample the whole genome (WGS) or the 1-2% of\nthe genome that codes for proteins called the whole exome (WES). Machine\nlearning approaches to variant calling achieve high accuracy in WGS data, but\nthe reduced number of training examples causes training with WES data alone to\nachieve lower accuracy. We propose and compare three different data\naugmentation strategies for improving performance on WES data: 1) joint\ntraining with WES and WGS data, 2) warmstarting the WES model from a WGS model,\nand 3) joint training with the sequencing type specified. All three approaches\nshow improved accuracy over a model trained using just WES data, suggesting the\nability of models to generalize insights from the greater WGS data while\nretaining performance on the specialized WES problem. These data augmentation\napproaches may apply to other problem areas in genomics, where several\nspecialized models would each see only a subset of the genome.\n", "versions": [{"version": "v1", "created": "Tue, 12 Nov 2019 21:31:29 GMT"}, {"version": "v2", "created": "Fri, 15 Nov 2019 22:58:38 GMT"}], "update_date": "2019-11-19", "authors_parsed": [["Yi", "Ren", ""], ["Chang", "Pi-Chuan", ""], ["Baid", "Gunjan", ""], ["Carroll", "Andrew", ""]]}, {"id": "1911.05159", "submitter": "Lili Du", "authors": "Wang Peng and Lili Du", "title": "Coordination Group Formation for OnLine Coordinated Routing Mechanisms", "comments": "24 pages, 15 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "physics.soc-ph cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This study considers that the collective route choices of travelers en route\nrepresent a resolution of their competition on network routes. Well\nunderstanding this competition and coordinating their route choices help\nmitigate urban traffic congestion. Even though existing studies have developed\nsuch mechanisms (e.g., the CRM [1]), we still lack the quantitative method to\nevaluate the coordination penitential and identify proper coordination groups\n(CG) to implement the CRM. Thus, they hit prohibitive computing difficulty when\nimplemented with many opt-in travelers. Motived by this view, this study\ndevelops mathematical approaches to quantify the coordination potential between\ntwo and among multiple travelers. Next, we develop the adaptive centroid-based\nclustering algorithm (ACCA), which splits travelers en route in a local network\ninto CGs, each with proper size and strong coordination potential. Moreover,\nthe ACCA is statistically secured to stop at a local optimal clustering\nsolution, which balances the inner-cluster and inter-cluster coordination\npotential. It can be implemented by parallel computation to accelerate its\ncomputing efficiency. Furthermore, we propose a clustering based coordinated\nrouting mechanism (CB-CRM), which implements a CRM on each individual CG. The\nnumerical experiments built upon both Sioux Falls and Hardee city networks show\nthat the ACCA works efficiently to form proper coordination groups so that as\ncompared to the CRM, the CB-CRM significantly improves computation efficiency\nwith minor system performance loss in a large network. This merit becomes more\napparent under high penetration and congested traffic condition. Last, the\nexperiments validate the good features of the ACCA as well as the value of\nimplementing parallel computation.\n", "versions": [{"version": "v1", "created": "Tue, 12 Nov 2019 21:56:14 GMT"}], "update_date": "2019-11-14", "authors_parsed": [["Peng", "Wang", ""], ["Du", "Lili", ""]]}, {"id": "1911.05166", "submitter": "John Chen", "authors": "John Chen, Vatsal Shah, Anastasios Kyrillidis", "title": "Negative sampling in semi-supervised learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce Negative Sampling in Semi-Supervised Learning (NS3L), a simple,\nfast, easy to tune algorithm for semi-supervised learning (SSL). NS3L is\nmotivated by the success of negative sampling/contrastive estimation. We\ndemonstrate that adding the NS3L loss to state-of-the-art SSL algorithms, such\nas the Virtual Adversarial Training (VAT), significantly improves upon vanilla\nVAT and its variant, VAT with Entropy Minimization. By adding the NS3L loss to\nMixMatch, the current state-of-the-art approach on semi-supervised tasks, we\nobserve significant improvements over vanilla MixMatch. We conduct extensive\nexperiments on the CIFAR10, CIFAR100, SVHN and STL10 benchmark datasets.\n", "versions": [{"version": "v1", "created": "Tue, 12 Nov 2019 22:13:25 GMT"}, {"version": "v2", "created": "Sun, 28 Jun 2020 18:43:58 GMT"}], "update_date": "2020-06-30", "authors_parsed": [["Chen", "John", ""], ["Shah", "Vatsal", ""], ["Kyrillidis", "Anastasios", ""]]}, {"id": "1911.05167", "submitter": "Zhongruo Wang", "authors": "Zhongruo Wang", "title": "Nonconvex Stochastic Nested Optimization via Stochastic ADMM", "comments": "Nested ADMM", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG math.OC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the stochastic nested composition optimization problem where the\nobjective is a composition of two expected-value functions. We proposed the\nstochastic ADMM to solve this complicated objective. In order to find an\n$\\epsilon$ stationary point where the expected norm of the subgradient of\ncorresponding augmented Lagrangian is smaller than $\\epsilon$, the total sample\ncomplexity of our method is $\\mathcal{O}(\\epsilon^{-3})$ for the online case\nand $\\mathcal{O} \\Bigl((2N_1 + N_2) + (2N_1 + N_2)^{1/2}\\epsilon^{-2}\\Bigr)$\nfor the finite sum case. The computational complexity is consistent with\nproximal version proposed in \\cite{zhang2019multi}, but our algorithm can solve\nmore general problem when the proximal mapping of the penalty is not easy to\ncompute.\n", "versions": [{"version": "v1", "created": "Tue, 12 Nov 2019 22:14:04 GMT"}], "update_date": "2019-11-14", "authors_parsed": [["Wang", "Zhongruo", ""]]}, {"id": "1911.05171", "submitter": "Siddharth Prasad", "authors": "Federico Echenique and Siddharth Prasad", "title": "Incentive Compatible Active Learning", "comments": "22 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.GT cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider active learning under incentive compatibility constraints. The\nmain application of our results is to economic experiments, in which a learner\nseeks to infer the parameters of a subject's preferences: for example their\nattitudes towards risk, or their beliefs over uncertain events. By cleverly\nadapting the experimental design, one can save on the time spent by subjects in\nthe laboratory, or maximize the information obtained from each subject in a\ngiven laboratory session; but the resulting adaptive design raises\ncomplications due to incentive compatibility. A subject in the lab may answer\nquestions strategically, and not truthfully, so as to steer subsequent\nquestions in a profitable direction.\n  We analyze two standard economic problems: inference of preferences over risk\nfrom multiple price lists, and belief elicitation in experiments on choice over\nuncertainty. In the first setting, we tune a simple and fast learning algorithm\nto retain certain incentive compatibility properties. In the second setting, we\nprovide an incentive compatible learning algorithm based on scoring rules with\nquery complexity that differs from obvious methods of achieving fast learning\nrates only by subpolynomial factors. Thus, for these areas of application,\nincentive compatibility may be achieved without paying a large sample\ncomplexity price.\n", "versions": [{"version": "v1", "created": "Tue, 12 Nov 2019 22:31:58 GMT"}], "update_date": "2019-11-15", "authors_parsed": [["Echenique", "Federico", ""], ["Prasad", "Siddharth", ""]]}, {"id": "1911.05181", "submitter": "Jonathan Baxter", "authors": "Douglas Aberdeen, Jonathan Baxter and Robert Edwards", "title": "92c/MFlops/s, Ultra-Large-Scale Neural-Network Training on a PIII\n  Cluster", "comments": "SC '00: Proceedings of the 2000 ACM/IEEE Conference on Supercomputing", "journal-ref": "ACM/IEEE SC 2000 Conference (SC00)", "doi": "10.1109/SC.2000.10031", "report-no": null, "categories": "cs.LG cs.DC cs.PF stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Artificial neural networks with millions of adjustable parameters and a\nsimilar number of training examples are a potential solution for difficult,\nlarge-scale pattern recognition problems in areas such as speech and face\nrecognition, classification of large volumes of web data, and finance. The\nbottleneck is that neural network training involves iterative gradient descent\nand is extremely computationally intensive. In this paper we present a\ntechnique for distributed training of Ultra Large Scale Neural Networks (ULSNN)\non Bunyip, a Linux-based cluster of 196 Pentium III processors. To illustrate\nULSNN training we describe an experiment in which a neural network with 1.73\nmillion adjustable parameters was trained to recognize machine-printed Japanese\ncharacters from a database containing 9 million training patterns. The training\nruns with a average performance of 163.3 GFlops/s (single precision). With a\nmachine cost of \\$150,913, this yields a price/performance ratio of\n92.4c/MFlops/s (single precision). For comparison purposes, training using\ndouble precision and the ATLAS DGEMM produces a sustained performance of 70\nMFlops/s or \\$2.16 / MFlop/s (double precision).\n", "versions": [{"version": "v1", "created": "Tue, 12 Nov 2019 22:57:09 GMT"}], "update_date": "2019-11-14", "authors_parsed": [["Aberdeen", "Douglas", ""], ["Baxter", "Jonathan", ""], ["Edwards", "Robert", ""]]}, {"id": "1911.05184", "submitter": "Qiao Zhang", "authors": "Qiao Zhang, Cong Wang, Chunsheng Xin and Hongyi Wu", "title": "CHEETAH: An Ultra-Fast, Approximation-Free, and Privacy-Preserved Neural\n  Network Framework based on Joint Obscure Linear and Nonlinear Computations", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Machine Learning as a Service (MLaaS) is enabling a wide range of smart\napplications on end devices. However, such convenience comes with a cost of\nprivacy because users have to upload their private data to the cloud. This\nresearch aims to provide effective and efficient MLaaS such that the cloud\nserver learns nothing about user data and the users cannot infer the\nproprietary model parameters owned by the server. This work makes the following\ncontributions. First, it unveils the fundamental performance bottleneck of\nexisting schemes due to the heavy permutations in computing linear\ntransformation and the use of communication intensive Garbled Circuits for\nnonlinear transformation. Second, it introduces an ultra-fast secure MLaaS\nframework, CHEETAH, which features a carefully crafted secret sharing scheme\nthat runs significantly faster than existing schemes without accuracy loss.\nThird, CHEETAH is evaluated on the benchmark of well-known, practical deep\nnetworks such as AlexNet and VGG-16 on the MNIST and ImageNet datasets. The\nresults demonstrate more than 100x speedup over the fastest GAZELLE (Usenix\nSecurity'18), 2000x speedup over MiniONN (ACM CCS'17) and five orders of\nmagnitude speedup over CryptoNets (ICML'16). This significant speedup enables a\nwide range of practical applications based on privacy-preserved deep neural\nnetworks.\n", "versions": [{"version": "v1", "created": "Tue, 12 Nov 2019 23:08:45 GMT"}, {"version": "v2", "created": "Thu, 11 Feb 2021 23:58:21 GMT"}], "update_date": "2021-02-15", "authors_parsed": [["Zhang", "Qiao", ""], ["Wang", "Cong", ""], ["Xin", "Chunsheng", ""], ["Wu", "Hongyi", ""]]}, {"id": "1911.05186", "submitter": "Wei Zou", "authors": "Wubo Li, Wei Zou, Xiangang Li", "title": "TCT: A Cross-supervised Learning Method for Multimodal Sequence\n  Representation", "comments": "submitted to ICASSP 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.CL cs.LG cs.SD eess.AS stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Multimodalities provide promising performance than unimodality in most tasks.\nHowever, learning the semantic of the representations from multimodalities\nefficiently is extremely challenging. To tackle this, we propose the\nTransformer based Cross-modal Translator (TCT) to learn unimodal sequence\nrepresentations by translating from other related multimodal sequences on a\nsupervised learning method. Combined TCT with Multimodal Transformer Network\n(MTN), we evaluate MTN-TCT on the video-grounded dialogue which uses\nmultimodality. The proposed method reports new state-of-the-art performance on\nvideo-grounded dialogue which indicates representations learned by TCT are more\nsemantics compared to directly use unimodality.\n", "versions": [{"version": "v1", "created": "Wed, 23 Oct 2019 05:02:15 GMT"}], "update_date": "2019-11-14", "authors_parsed": [["Li", "Wubo", ""], ["Zou", "Wei", ""], ["Li", "Xiangang", ""]]}, {"id": "1911.05187", "submitter": "Carl Norman", "authors": "Carl Norman", "title": "AI in Pursuit of Happiness, Finding Only Sadness: Multi-Modal Facial\n  Emotion Recognition Challenge", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG cs.SD eess.AS stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The importance of automated Facial Emotion Recognition (FER) grows the more\ncommon human-machine interactions become, which will only continue to increase\ndramatically with time. A common method to describe human sentiment or feeling\nis the categorical model the `7 basic emotions', consisting of `Angry',\n`Disgust', `Fear', `Happiness', `Sadness', `Surprise' and `Neutral'. The\n`Emotion Recognition in the Wild' (EmotiW) competition is now in its 7th year\nand has become the standard benchmark for measuring FER performance. The focus\nof this paper is the EmotiW sub-challenge of classifying videos in the `Acted\nFacial Expression in the Wild' (AFEW) dataset, consisting of both visual and\naudio modalities, into one of the above classes. Machine learning has exploded\nas a research topic in recent years, with advancements in `Deep Learning' a key\npart of this. Although Deep Learning techniques have been widely applied to the\nFER task by entrants in previous years, this paper has two main contributions:\n(i) to apply the latest `state-of-the-art' visual and temporal networks and\n(ii) exploring various methods of fusing features extracted from the visual and\naudio elements to enrich the information available to the final model making\nthe prediction. There are a number of complex issues that arise when trying to\nclassify emotions for `in-the-wild' video sequences, which the above two\napproaches attempt to directly address. There are some positive findings when\ncomparing the results of this paper to past submissions, indicating that\nfurther research into the proposed methods and fine-tuning of the models\ndeployed, could result in another step forwards in the field of automated FER.\n", "versions": [{"version": "v1", "created": "Thu, 24 Oct 2019 14:49:39 GMT"}], "update_date": "2019-11-14", "authors_parsed": [["Norman", "Carl", ""]]}, {"id": "1911.05189", "submitter": "Dmitry Rodin", "authors": "Dmitry Rodin and Nikita Orlov", "title": "Fast Glare Detection in Document Images", "comments": "4 pages, Workshop on Industrial Applications of Document Analysis and\n  Recognition 2019", "journal-ref": null, "doi": "10.1109/ICDARW.2019.60123", "report-no": null, "categories": "cs.CV cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Glare is a phenomenon that occurs when the scene has a reflection of a light\nsource or has one in it. This luminescence can hide useful information from the\nimage, making text recognition virtually impossible. In this paper, we propose\nan approach to detect glare in images taken by users via mobile devices. Our\nmethod divides the document into blocks and collects luminance features from\nthe original image and black-white strokes histograms of the binarized image.\nFinally, glare is detected using a convolutional neural network on the\naforementioned histograms and luminance features. The network consists of\nseveral feature extraction blocks, one for each type of input, and the\ndetection block, which calculates the resulting glare heatmap based on the\noutput of the extraction part. The proposed solution detects glare with high\nrecall and f-score.\n", "versions": [{"version": "v1", "created": "Thu, 24 Oct 2019 09:12:01 GMT"}], "update_date": "2019-11-14", "authors_parsed": [["Rodin", "Dmitry", ""], ["Orlov", "Nikita", ""]]}, {"id": "1911.05206", "submitter": "Antonio Orvieto", "authors": "Antonio Orvieto, Aurelien Lucchi", "title": "Shadowing Properties of Optimization Algorithms", "comments": null, "journal-ref": "Advances in neural information processing systems. 2019", "doi": null, "report-no": null, "categories": "math.OC cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Ordinary differential equation (ODE) models of gradient-based optimization\nmethods can provide insights into the dynamics of learning and inspire the\ndesign of new algorithms. Unfortunately, this thought-provoking perspective is\nweakened by the fact that, in the worst case, the error between the algorithm\nsteps and its ODE approximation grows exponentially with the number of\niterations. In an attempt to encourage the use of continuous-time methods in\noptimization, we show that, if some additional regularity on the objective is\nassumed, the ODE representations of Gradient Descent and Heavy-ball do not\nsuffer from the aforementioned problem, once we allow for a small perturbation\non the algorithm initial condition. In the dynamical systems literature, this\nphenomenon is called shadowing. Our analysis relies on the concept of\nhyperbolicity, as well as on tools from numerical analysis.\n", "versions": [{"version": "v1", "created": "Tue, 12 Nov 2019 23:46:36 GMT"}], "update_date": "2019-11-14", "authors_parsed": [["Orvieto", "Antonio", ""], ["Lucchi", "Aurelien", ""]]}, {"id": "1911.05210", "submitter": "Fei Ding", "authors": "Fei Ding and Feng Luo and Yin Yang", "title": "Double cycle-consistent generative adversarial network for unsupervised\n  conditional generation", "comments": "12 pages, 4 figures, and 12 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Conditional generative models have achieved considerable success in the past\nfew years, but usually require a lot of labeled data. Recently, ClusterGAN\ncombines GAN with an encoder to achieve remarkable clustering performance via\nunsupervised conditional generation. However, it ignores the real conditional\ndistribution of data, which leads to generating less diverse samples for each\nclass and makes the encoder only achieve sub-optimal clustering performance.\nHere, we propose a new unsupervised conditional generation framework, Double\nCycle-Consistent Conditional GAN (DC3-GAN), which can generate diverse\nclass-conditioned samples. We enforce the encoder and the generator of GAN to\nform an encoder-generator pair in addition to the generator-encoder pair, which\nenables us to avoid the low-diversity generation and the triviality of latent\nfeatures. We train the encoder-generator pair using real data, which can\nindirectly estimate the real conditional distribution. Meanwhile, this\nframework enforces the outputs of the encoder to match the inputs of GAN and\nthe prior noise distribution, which disentangles latent space into two parts:\none-hot discrete and continuous latent variables. The former can be directly\nexpressed as clusters and the latter represents remaining unspecified factors.\nThis work demonstrates that enhancing the diversity of unsupervised conditional\ngenerated samples can improve the clustering performance. Experiments on\ndifferent benchmark datasets show that the proposed method outperforms existing\ngenerative model-based clustering methods, and also achieves the optimal\ndisentanglement performance.\n", "versions": [{"version": "v1", "created": "Wed, 13 Nov 2019 00:11:50 GMT"}, {"version": "v2", "created": "Mon, 20 Jul 2020 00:52:00 GMT"}, {"version": "v3", "created": "Mon, 5 Apr 2021 15:25:55 GMT"}], "update_date": "2021-04-06", "authors_parsed": [["Ding", "Fei", ""], ["Luo", "Feng", ""], ["Yang", "Yin", ""]]}, {"id": "1911.05211", "submitter": "Amanda Minnich", "authors": "Amanda J. Minnich, Kevin McLoughlin, Margaret Tse, Jason Deng, Andrew\n  Weber, Neha Murad, Benjamin D. Madej, Bharath Ramsundar, Tom Rush, Stacie\n  Calad-Thomson, Jim Brase, Jonathan E. Allen", "title": "AMPL: A Data-Driven Modeling Pipeline for Drug Discovery", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.QM cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  One of the key requirements for incorporating machine learning into the drug\ndiscovery process is complete reproducibility and traceability of the model\nbuilding and evaluation process. With this in mind, we have developed an\nend-to-end modular and extensible software pipeline for building and sharing\nmachine learning models that predict key pharma-relevant parameters. The ATOM\nModeling PipeLine, or AMPL, extends the functionality of the open source\nlibrary DeepChem and supports an array of machine learning and molecular\nfeaturization tools. We have benchmarked AMPL on a large collection of\npharmaceutical datasets covering a wide range of parameters. As a result of\nthese comprehensive experiments, we have found that physicochemical descriptors\nand deep learning-based graph representations significantly outperform\ntraditional fingerprints in the characterization of molecular features. We have\nalso found that dataset size is directly correlated to prediction performance,\nand that single-task deep learning models only outperform shallow learners if\nthere is sufficient data. Likewise, dataset size has a direct impact on model\npredictivity, independent of comprehensive hyperparameter model tuning. Our\nfindings point to the need for public dataset integration or\nmulti-task/transfer learning approaches. Lastly, we found that uncertainty\nquantification (UQ) analysis may help identify model error; however, efficacy\nof UQ to filter predictions varies considerably between datasets and\nfeaturization/model types. AMPL is open source and available for download at\nhttp://github.com/ATOMconsortium/AMPL.\n", "versions": [{"version": "v1", "created": "Wed, 13 Nov 2019 00:13:08 GMT"}, {"version": "v2", "created": "Thu, 14 Nov 2019 01:38:49 GMT"}], "update_date": "2019-11-15", "authors_parsed": [["Minnich", "Amanda J.", ""], ["McLoughlin", "Kevin", ""], ["Tse", "Margaret", ""], ["Deng", "Jason", ""], ["Weber", "Andrew", ""], ["Murad", "Neha", ""], ["Madej", "Benjamin D.", ""], ["Ramsundar", "Bharath", ""], ["Rush", "Tom", ""], ["Calad-Thomson", "Stacie", ""], ["Brase", "Jim", ""], ["Allen", "Jonathan E.", ""]]}, {"id": "1911.05242", "submitter": "Abdelrahman Zayed", "authors": "Abdelrahman Zayed and Hassan Rivaz", "title": "Fast Approximate Time-Delay Estimation in Ultrasound Elastography Using\n  Principal Component Analysis", "comments": "Accepted to be Published in 2019, 41th Annual International\n  Conference of the IEEE Engineering in Medicine and Biology Society (EMBC),\n  Berlin, Germany", "journal-ref": "2019 41st Annual International Conference of the IEEE Engineering\n  in Medicine and Biology Society (EMBC)", "doi": "10.1109/embc.2019.8857242", "report-no": null, "categories": "eess.IV cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Time delay estimation (TDE) is a critical and challenging step in all\nultrasound elastography methods. A growing number of TDE techniques require an\napproximate but robust and fast method to initialize solving for TDE. Herein,\nwe present a fast method for calculating an approximate TDE between two radio\nfrequency (RF) frames of ultrasound. Although this approximate TDE can be\nuseful for several algorithms, we focus on GLobal Ultrasound Elastography\n(GLUE), which currently relies on Dynamic Programming (DP) to provide this\napproximate TDE. We exploit Principal Component Analysis (PCA) to find the\ngeneral modes of deformation in quasi-static elastography, and therefore call\nour method PCA-GLUE. PCA-GLUE is a data-driven approach that learns a set of\nTDE principal components from a training database in real experiments. In the\ntest phase, TDE is approximated as a weighted sum of these principal\ncomponents. Our algorithm robustly estimates the weights from sparse feature\nmatches, then passes the resulting displacement field to GLUE as initial\nestimates to perform a more accurate displacement estimation. PCA-GLUE is more\nthan ten times faster than DP in estimation of the initial displacement field\nand yields similar results.\n", "versions": [{"version": "v1", "created": "Wed, 13 Nov 2019 01:54:18 GMT"}], "update_date": "2019-11-14", "authors_parsed": [["Zayed", "Abdelrahman", ""], ["Rivaz", "Hassan", ""]]}, {"id": "1911.05245", "submitter": "Abdelrahman Zayed", "authors": "Abdelrahman Zayed and Hassan Rivaz", "title": "Automatic Frame Selection Using MLP Neural Network in Ultrasound\n  Elastography", "comments": null, "journal-ref": "International Conference on Image Analysis and Recognition (ICIAR\n  2019), Lecture Notes in Computer Science", "doi": "10.1007/978-3-030-27272-2_41", "report-no": null, "categories": "eess.IV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Ultrasound elastography estimates the mechanical properties of the tissue\nfrom two Radio-Frequency (RF) frames collected before and after tissue\ndeformation due to an external or internal force. This work focuses on strain\nimaging in quasi-static elastography, where the tissue undergoes slow\ndeformations and strain images are estimated as a surrogate for elasticity\nmodulus. The quality of the strain image depends heavily on the underlying\ndeformation, and even the best strain estimation algorithms cannot estimate a\ngood strain image if the underlying deformation is not suitable. Herein, we\nintroduce a new method for tracking the RF frames and selecting automatically\nthe best possible pair. We achieve this by decomposing the axial displacement\nimage into a linear combination of principal components (which are calculated\noffline) multiplied by their corresponding weights. We then use the calculated\nweights as the input feature vector to a multi-layer perceptron (MLP)\nclassifier. The output is a binary decision, either 1 which refers to good\nframes, or 0 which refers to bad frames. Our MLP model is trained on in-vivo\ndataset and tested on different datasets of both in-vivo and phantom data.\nResults show that by using our technique, we would be able to achieve higher\nquality strain images compared to the traditional methods of picking up pairs\nthat are 1, 2 or 3 frames apart. The training phase of our algorithm is\ncomputationally expensive and takes few hours, but it is only done once. The\ntesting phase chooses the optimal pair of frames in only 1.9 ms.\n", "versions": [{"version": "v1", "created": "Wed, 13 Nov 2019 01:56:58 GMT"}], "update_date": "2019-11-14", "authors_parsed": [["Zayed", "Abdelrahman", ""], ["Rivaz", "Hassan", ""]]}, {"id": "1911.05248", "submitter": "Sara Hooker", "authors": "Sara Hooker, Aaron Courville, Gregory Clark, Yann Dauphin, Andrea\n  Frome", "title": "What Do Compressed Deep Neural Networks Forget?", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CV cs.HC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep neural network pruning and quantization techniques have demonstrated it\nis possible to achieve high levels of compression with surprisingly little\ndegradation to test set accuracy. However, this measure of performance conceals\nsignificant differences in how different classes and images are impacted by\nmodel compression techniques. We find that models with radically different\nnumbers of weights have comparable top-line performance metrics but diverge\nconsiderably in behavior on a narrow subset of the dataset. This small subset\nof data points, which we term Pruning Identified Exemplars (PIEs) are\nsystematically more impacted by the introduction of sparsity. Compression\ndisproportionately impacts model performance on the underrepresented long-tail\nof the data distribution. PIEs over-index on atypical or noisy images that are\nfar more challenging for both humans and algorithms to classify. Our work\nprovides intuition into the role of capacity in deep neural networks and the\ntrade-offs incurred by compression. An understanding of this disparate impact\nis critical given the widespread deployment of compressed models in the wild.\n", "versions": [{"version": "v1", "created": "Wed, 13 Nov 2019 02:02:19 GMT"}, {"version": "v2", "created": "Mon, 13 Jul 2020 18:24:24 GMT"}], "update_date": "2020-11-17", "authors_parsed": [["Hooker", "Sara", ""], ["Courville", "Aaron", ""], ["Clark", "Gregory", ""], ["Dauphin", "Yann", ""], ["Frome", "Andrea", ""]]}, {"id": "1911.05256", "submitter": "Michael Lingzhi Li", "authors": "Michael Lingzhi Li, Meng Dong, Jiawei Zhou, Alexander M. Rush", "title": "A Hierarchy of Graph Neural Networks Based on Learnable Local Features", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Graph neural networks (GNNs) are a powerful tool to learn representations on\ngraphs by iteratively aggregating features from node neighbourhoods. Many\nvariant models have been proposed, but there is limited understanding on both\nhow to compare different architectures and how to construct GNNs\nsystematically. Here, we propose a hierarchy of GNNs based on their aggregation\nregions. We derive theoretical results about the discriminative power and\nfeature representation capabilities of each class. Then, we show how this\nframework can be utilized to systematically construct arbitrarily powerful\nGNNs. As an example, we construct a simple architecture that exceeds the\nexpressiveness of the Weisfeiler-Lehman graph isomorphism test. We empirically\nvalidate our theory on both synthetic and real-world benchmarks, and\ndemonstrate our example's theoretical power translates to strong results on\nnode classification, graph classification, and graph regression tasks.\n", "versions": [{"version": "v1", "created": "Wed, 13 Nov 2019 02:22:54 GMT"}], "update_date": "2019-11-14", "authors_parsed": [["Li", "Michael Lingzhi", ""], ["Dong", "Meng", ""], ["Zhou", "Jiawei", ""], ["Rush", "Alexander M.", ""]]}, {"id": "1911.05263", "submitter": "Pedram Hosseini", "authors": "Behnam Sabeti, Pedram Hosseini, Gholamreza Ghassem-Sani, Seyed\n  Abolghasem Mirroshandel", "title": "LexiPers: An ontology based sentiment lexicon for Persian", "comments": null, "journal-ref": null, "doi": "10.29007/f4j4", "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Sentiment analysis refers to the use of natural language processing to\nidentify and extract subjective information from textual resources. One\napproach for sentiment extraction is using a sentiment lexicon. A sentiment\nlexicon is a set of words associated with the sentiment orientation that they\nexpress. In this paper, we describe the process of generating a general purpose\nsentiment lexicon for Persian. A new graph-based method is introduced for seed\nselection and expansion based on an ontology. Sentiment lexicon generation is\nthen mapped to a document classification problem. We used the K-nearest\nneighbors and nearest centroid methods for classification. These classifiers\nhave been evaluated based on a set of hand labeled synsets. The final sentiment\nlexicon has been generated by the best classifier. The results show an\nacceptable performance in terms of accuracy and F-measure in the generated\nsentiment lexicon.\n", "versions": [{"version": "v1", "created": "Wed, 13 Nov 2019 02:48:33 GMT"}], "update_date": "2019-11-14", "authors_parsed": [["Sabeti", "Behnam", ""], ["Hosseini", "Pedram", ""], ["Ghassem-Sani", "Gholamreza", ""], ["Mirroshandel", "Seyed Abolghasem", ""]]}, {"id": "1911.05266", "submitter": "Dipan Pal", "authors": "Dipan K. Pal, Akshay Chawla, Marios Savvides", "title": "Learning Non-Parametric Invariances from Data with Permanent Random\n  Connectomes", "comments": "Preprint (accepted at NeurIPS SVRHM 2019 Workshop)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  One of the fundamental problems in supervised classification and in machine\nlearning in general, is the modelling of non-parametric invariances that exist\nin data. Most prior art has focused on enforcing priors in the form of\ninvariances to parametric nuisance transformations that are expected to be\npresent in data. Learning non-parametric invariances directly from data remains\nan important open problem. In this paper, we introduce a new architectural\nlayer for convolutional networks which is capable of learning general\ninvariances from data itself. This layer can learn invariance to non-parametric\ntransformations and interestingly, motivates and incorporates permanent random\nconnectomes, thereby being called Permanent Random Connectome Non-Parametric\nTransformation Networks (PRC-NPTN). PRC-NPTN networks are initialized with\nrandom connections (not just weights) which are a small subset of the\nconnections in a fully connected convolution layer. Importantly, these\nconnections in PRC-NPTNs once initialized remain permanent throughout training\nand testing. Permanent random connectomes make these architectures loosely more\nbiologically plausible than many other mainstream network architectures which\nrequire highly ordered structures. We motivate randomly initialized connections\nas a simple method to learn invariance from data itself while invoking\ninvariance towards multiple nuisance transformations simultaneously. We find\nthat these randomly initialized permanent connections have positive effects on\ngeneralization, outperform much larger ConvNet baselines and the recently\nproposed Non-Parametric Transformation Network (NPTN) on benchmarks that\nenforce learning invariances from the data itself.\n", "versions": [{"version": "v1", "created": "Wed, 13 Nov 2019 03:03:48 GMT"}, {"version": "v2", "created": "Fri, 21 Feb 2020 15:32:41 GMT"}, {"version": "v3", "created": "Fri, 14 Aug 2020 00:54:18 GMT"}], "update_date": "2020-08-17", "authors_parsed": [["Pal", "Dipan K.", ""], ["Chawla", "Akshay", ""], ["Savvides", "Marios", ""]]}, {"id": "1911.05268", "submitter": "Rey Wiyatno", "authors": "Rey Reza Wiyatno, Anqi Xu, Ousmane Dia, Archy de Berker", "title": "Adversarial Examples in Modern Machine Learning: A Review", "comments": "Work in progress, 97 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent research has found that many families of machine learning models are\nvulnerable to adversarial examples: inputs that are specifically designed to\ncause the target model to produce erroneous outputs. In this survey, we focus\non machine learning models in the visual domain, where methods for generating\nand detecting such examples have been most extensively studied. We explore a\nvariety of adversarial attack methods that apply to image-space content, real\nworld adversarial attacks, adversarial defenses, and the transferability\nproperty of adversarial examples. We also discuss strengths and weaknesses of\nvarious methods of adversarial attack and defense. Our aim is to provide an\nextensive coverage of the field, furnishing the reader with an intuitive\nunderstanding of the mechanics of adversarial attack and defense mechanisms and\nenlarging the community of researchers studying this fundamental set of\nproblems.\n", "versions": [{"version": "v1", "created": "Wed, 13 Nov 2019 03:09:40 GMT"}, {"version": "v2", "created": "Fri, 15 Nov 2019 23:07:01 GMT"}], "update_date": "2019-11-19", "authors_parsed": [["Wiyatno", "Rey Reza", ""], ["Xu", "Anqi", ""], ["Dia", "Ousmane", ""], ["de Berker", "Archy", ""]]}, {"id": "1911.05275", "submitter": "Gaurav Menghani", "authors": "Gaurav Menghani, Sujith Ravi", "title": "Learning from a Teacher using Unlabeled Data", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Knowledge distillation is a widely used technique for model compression. We\nposit that the teacher model used in a distillation setup, captures\nrelationships between classes, that extend beyond the original dataset. We\nempirically show that a teacher model can transfer this knowledge to a student\nmodel even on an {\\it out-of-distribution} dataset. Using this approach, we\nshow promising results on MNIST, CIFAR-10, and Caltech-256 datasets using\nunlabeled image data from different sources. Our results are encouraging and\nhelp shed further light from the perspective of understanding knowledge\ndistillation and utilizing unlabeled data to improve model quality.\n", "versions": [{"version": "v1", "created": "Wed, 13 Nov 2019 03:43:29 GMT"}], "update_date": "2019-11-14", "authors_parsed": [["Menghani", "Gaurav", ""], ["Ravi", "Sujith", ""]]}, {"id": "1911.05276", "submitter": "Jae-woong Lee", "authors": "Jae-woong Lee, Minjin Choi, Jongwuk Lee, and Hyunjung Shim", "title": "Collaborative Distillation for Top-N Recommendation", "comments": "10 pages, ICDM 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.IR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Knowledge distillation (KD) is a well-known method to reduce inference\nlatency by compressing a cumbersome teacher model to a small student model.\nDespite the success of KD in the classification task, applying KD to\nrecommender models is challenging due to the sparsity of positive feedback, the\nambiguity of missing feedback, and the ranking problem associated with the\ntop-N recommendation. To address the issues, we propose a new KD model for the\ncollaborative filtering approach, namely collaborative distillation (CD).\nSpecifically, (1) we reformulate a loss function to deal with the ambiguity of\nmissing feedback. (2) We exploit probabilistic rank-aware sampling for the\ntop-N recommendation. (3) To train the proposed model effectively, we develop\ntwo training strategies for the student model, called the teacher- and the\nstudent-guided training methods, selecting the most useful feedback from the\nteacher model. Via experimental results, we demonstrate that the proposed model\noutperforms the state-of-the-art method by 2.7-33.2% and 2.7-29.1% in hit rate\n(HR) and normalized discounted cumulative gain (NDCG), respectively. Moreover,\nthe proposed model achieves the performance comparable to the teacher model.\n", "versions": [{"version": "v1", "created": "Wed, 13 Nov 2019 03:43:35 GMT"}], "update_date": "2019-11-14", "authors_parsed": [["Lee", "Jae-woong", ""], ["Choi", "Minjin", ""], ["Lee", "Jongwuk", ""], ["Shim", "Hyunjung", ""]]}, {"id": "1911.05281", "submitter": "Chen Xu", "authors": "Chen Xu, Jian Wang, Tianhang Yu, Chuili Kong, Yourui Huangfu, Rong Li,\n  Yiqun Ge, Jun Wang", "title": "Buffer-aware Wireless Scheduling based on Deep Reinforcement Learning", "comments": "submitted to WCNC2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IT cs.LG math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, the downlink packet scheduling problem for cellular networks\nis modeled, which jointly optimizes throughput, fairness and packet drop rate.\nTwo genie-aided heuristic search methods are employed to explore the solution\nspace. A deep reinforcement learning (DRL) framework with A2C algorithm is\nproposed for the optimization problem. Several methods have been utilized in\nthe framework to improve the sampling and training efficiency and to adapt the\nalgorithm to a specific scheduling problem. Numerical results show that DRL\noutperforms the baseline algorithm and achieves similar performance as\ngenie-aided methods without using the future information.\n", "versions": [{"version": "v1", "created": "Wed, 13 Nov 2019 04:15:02 GMT"}], "update_date": "2019-11-14", "authors_parsed": [["Xu", "Chen", ""], ["Wang", "Jian", ""], ["Yu", "Tianhang", ""], ["Kong", "Chuili", ""], ["Huangfu", "Yourui", ""], ["Li", "Rong", ""], ["Ge", "Yiqun", ""], ["Wang", "Jun", ""]]}, {"id": "1911.05289", "submitter": "Jeffrey Dean", "authors": "Jeffrey Dean", "title": "The Deep Learning Revolution and Its Implications for Computer\n  Architecture and Chip Design", "comments": "Companion paper to accompany a keynote talk at ISSCC 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The past decade has seen a remarkable series of advances in machine learning,\nand in particular deep learning approaches based on artificial neural networks,\nto improve our abilities to build more accurate systems across a broad range of\nareas, including computer vision, speech recognition, language translation, and\nnatural language understanding tasks. This paper is a companion paper to a\nkeynote talk at the 2020 International Solid-State Circuits Conference (ISSCC)\ndiscussing some of the advances in machine learning, and their implications on\nthe kinds of computational devices we need to build, especially in the\npost-Moore's Law-era. It also discusses some of the ways that machine learning\nmay also be able to help with some aspects of the circuit design process.\nFinally, it provides a sketch of at least one interesting direction towards\nmuch larger-scale multi-task models that are sparsely activated and employ much\nmore dynamic, example- and task-based routing than the machine learning models\nof today.\n", "versions": [{"version": "v1", "created": "Wed, 13 Nov 2019 04:41:31 GMT"}], "update_date": "2019-11-14", "authors_parsed": [["Dean", "Jeffrey", ""]]}, {"id": "1911.05309", "submitter": "Mengying Zhu", "authors": "Mengying Zhu, Xiaolin Zheng, Yan Wang, Yuyuan Li, Qianqiao Liang", "title": "Adaptive Portfolio by Solving Multi-armed Bandit via Thompson Sampling", "comments": "conference", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG q-fin.PM stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  As the cornerstone of modern portfolio theory, Markowitz's mean-variance\noptimization is considered a major model adopted in portfolio management.\nHowever, due to the difficulty of estimating its parameters, it cannot be\napplied to all periods. In some cases, naive strategies such as\nEqually-weighted and Value-weighted portfolios can even get better performance.\nUnder these circumstances, we can use multiple classic strategies as multiple\nstrategic arms in multi-armed bandit to naturally establish a connection with\nthe portfolio selection problem. This can also help to maximize the rewards in\nthe bandit algorithm by the trade-off between exploration and exploitation. In\nthis paper, we present a portfolio bandit strategy through Thompson sampling\nwhich aims to make online portfolio choices by effectively exploiting the\nperformances among multiple arms. Also, by constructing multiple strategic\narms, we can obtain the optimal investment portfolio to adapt different\ninvestment periods. Moreover, we devise a novel reward function based on users'\ndifferent investment risk preferences, which can be adaptive to various\ninvestment styles. Our experimental results demonstrate that our proposed\nportfolio strategy has marked superiority across representative real-world\nmarket datasets in terms of extensive evaluation criteria.\n", "versions": [{"version": "v1", "created": "Wed, 13 Nov 2019 06:08:44 GMT"}, {"version": "v2", "created": "Thu, 14 Nov 2019 06:39:38 GMT"}], "update_date": "2019-11-15", "authors_parsed": [["Zhu", "Mengying", ""], ["Zheng", "Xiaolin", ""], ["Wang", "Yan", ""], ["Li", "Yuyuan", ""], ["Liang", "Qianqiao", ""]]}, {"id": "1911.05312", "submitter": "Mohammed Elhenawy Dr", "authors": "Mohammed Elhenawy, Mahmoud Masoud, Sebastian Glaser, Andry\n  Rakotonirainy", "title": "Topological Stability: a New Algorithm for Selecting The Nearest\n  Neighbors in Non-Linear Dimensionality Reduction Techniques", "comments": null, "journal-ref": null, "doi": "10.13140/RG.2.2.16800.17922", "report-no": null, "categories": "cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by-sa/4.0/", "abstract": "  In the machine learning field, dimensionality reduction is an important task.\nIt mitigates the undesired properties of high-dimensional spaces to facilitate\nclassification, compression, and visualization of high-dimensional data. During\nthe last decade, researchers proposed many new (non-linear) techniques for\ndimensionality reduction. Most of these techniques are based on the intuition\nthat data lies on or near a complex low-dimensional manifold that is embedded\nin the high-dimensional space. New techniques for dimensionality reduction aim\nat identifying and extracting the manifold from the high-dimensional space.\nIsomap is one of widely-used low-dimensional embedding methods, where geodesic\ndistances on a weighted graph are incorporated with the classical scaling\n(metric multidimensional scaling). The Isomap chooses the nearest neighbours\nbased on the distance only which causes bridges and topological instability. In\nthis paper, we propose a new algorithm to choose the nearest neighbours to\nreduce the number of short-circuit errors and hence improves the topological\nstability. Because at any point on the manifold, that point and its nearest\nneighbours form a vector subspace and the orthogonal to that subspace is\northogonal to all vectors spans the vector subspace. The prposed algorithmuses\nthe point itself and its two nearest neighbours to find the bases of the\nsubspace and the orthogonal to that subspace which belongs to the orthogonal\ncomplementary subspace. The proposed algorithm then adds new points to the two\nnearest neighbours based on the distance and the angle between each new point\nand the orthogonal to the subspace. The superior performance of the new\nalgorithm in choosing the nearest neighbours is confirmed through experimental\nwork with several datasets.\n", "versions": [{"version": "v1", "created": "Wed, 13 Nov 2019 06:17:12 GMT"}, {"version": "v2", "created": "Sun, 17 Nov 2019 04:22:43 GMT"}], "update_date": "2019-11-19", "authors_parsed": [["Elhenawy", "Mohammed", ""], ["Masoud", "Mahmoud", ""], ["Glaser", "Sebastian", ""], ["Rakotonirainy", "Andry", ""]]}, {"id": "1911.05316", "submitter": "Ziqi Ke", "authors": "Ziqi Ke, Haris Vikalo", "title": "A Graph Auto-Encoder for Haplotype Assembly and Viral Quasispecies\n  Reconstruction", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.GN cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Reconstructing components of a genomic mixture from data obtained by means of\nDNA sequencing is a challenging problem encountered in a variety of\napplications including single individual haplotyping and studies of viral\ncommunities. High-throughput DNA sequencing platforms oversample mixture\ncomponents to provide massive amounts of reads whose relative positions can be\ndetermined by mapping the reads to a known reference genome; assembly of the\ncomponents, however, requires discovery of the reads' origin -- an NP-hard\nproblem that the existing methods struggle to solve with the required level of\naccuracy. In this paper, we present a learning framework based on a graph\nauto-encoder designed to exploit structural properties of sequencing data. The\nalgorithm is a neural network which essentially trains to ignore sequencing\nerrors and infers the posteriori probabilities of the origin of sequencing\nreads. Mixture components are then reconstructed by finding consensus of the\nreads determined to originate from the same genomic component. Results on\nrealistic synthetic as well as experimental data demonstrate that the proposed\nframework reliably assembles haplotypes and reconstructs viral communities,\noften significantly outperforming state-of-the-art techniques.\n", "versions": [{"version": "v1", "created": "Wed, 13 Nov 2019 06:32:48 GMT"}], "update_date": "2019-11-14", "authors_parsed": [["Ke", "Ziqi", ""], ["Vikalo", "Haris", ""]]}, {"id": "1911.05321", "submitter": "Ajay Mandlekar", "authors": "Ajay Mandlekar, Fabio Ramos, Byron Boots, Silvio Savarese, Li Fei-Fei,\n  Animesh Garg, Dieter Fox", "title": "IRIS: Implicit Reinforcement without Interaction at Scale for Learning\n  Control from Offline Robot Manipulation Data", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Learning from offline task demonstrations is a problem of great interest in\nrobotics. For simple short-horizon manipulation tasks with modest variation in\ntask instances, offline learning from a small set of demonstrations can produce\ncontrollers that successfully solve the task. However, leveraging a fixed batch\nof data can be problematic for larger datasets and longer-horizon tasks with\ngreater variations. The data can exhibit substantial diversity and consist of\nsuboptimal solution approaches. In this paper, we propose Implicit\nReinforcement without Interaction at Scale (IRIS), a novel framework for\nlearning from large-scale demonstration datasets. IRIS factorizes the control\nproblem into a goal-conditioned low-level controller that imitates short\ndemonstration sequences and a high-level goal selection mechanism that sets\ngoals for the low-level and selectively combines parts of suboptimal solutions\nleading to more successful task completions. We evaluate IRIS across three\ndatasets, including the RoboTurk Cans dataset collected by humans via\ncrowdsourcing, and show that performant policies can be learned from purely\noffline learning. Additional results at\nhttps://sites.google.com/stanford.edu/iris/ .\n", "versions": [{"version": "v1", "created": "Wed, 13 Nov 2019 06:56:21 GMT"}, {"version": "v2", "created": "Sun, 23 Feb 2020 02:33:41 GMT"}], "update_date": "2020-02-25", "authors_parsed": [["Mandlekar", "Ajay", ""], ["Ramos", "Fabio", ""], ["Boots", "Byron", ""], ["Savarese", "Silvio", ""], ["Fei-Fei", "Li", ""], ["Garg", "Animesh", ""], ["Fox", "Dieter", ""]]}, {"id": "1911.05332", "submitter": "Anqi Liu", "authors": "Anqi Liu, Maya Srikanth, Nicholas Adams-Cohen, R. Michael Alvarez,\n  Anima Anandkumar", "title": "Finding Social Media Trolls: Dynamic Keyword Selection Methods for\n  Rapidly-Evolving Online Debates", "comments": "AI for Social Good workshop at NeurIPS (2019)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CY cs.SI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Online harassment is a significant social problem. Prevention of online\nharassment requires rapid detection of harassing, offensive, and negative\nsocial media posts. In this paper, we propose the use of word embedding models\nto identify offensive and harassing social media messages in two aspects:\ndetecting fast-changing topics for more effective data collection and\nrepresenting word semantics in different domains. We demonstrate with\npreliminary results that using the GloVe (Global Vectors for Word\nRepresentation) model facilitates the discovery of new and relevant keywords to\nuse for data collection and trolling detection. Our paper concludes with a\ndiscussion of a research agenda to further develop and test word embedding\nmodels for identification of social media harassment and trolling.\n", "versions": [{"version": "v1", "created": "Wed, 13 Nov 2019 07:20:24 GMT"}, {"version": "v2", "created": "Sat, 16 Nov 2019 03:05:41 GMT"}], "update_date": "2019-11-19", "authors_parsed": [["Liu", "Anqi", ""], ["Srikanth", "Maya", ""], ["Adams-Cohen", "Nicholas", ""], ["Alvarez", "R. Michael", ""], ["Anandkumar", "Anima", ""]]}, {"id": "1911.05343", "submitter": "Ruizhe Li", "authors": "Ruizhe Li, Xiao Li, Chenghua Lin, Matthew Collinson and Rui Mao", "title": "A Stable Variational Autoencoder for Text Modelling", "comments": "Accepted by INLG 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Variational Autoencoder (VAE) is a powerful method for learning\nrepresentations of high-dimensional data. However, VAEs can suffer from an\nissue known as latent variable collapse (or KL loss vanishing), where the\nposterior collapses to the prior and the model will ignore the latent codes in\ngenerative tasks. Such an issue is particularly prevalent when employing\nVAE-RNN architectures for text modelling (Bowman et al., 2016). In this paper,\nwe present a simple architecture called holistic regularisation VAE (HR-VAE),\nwhich can effectively avoid latent variable collapse. Compared to existing\nVAE-RNN architectures, we show that our model can achieve much more stable\ntraining process and can generate text with significantly better quality.\n", "versions": [{"version": "v1", "created": "Wed, 13 Nov 2019 08:11:42 GMT"}], "update_date": "2019-11-14", "authors_parsed": [["Li", "Ruizhe", ""], ["Li", "Xiao", ""], ["Lin", "Chenghua", ""], ["Collinson", "Matthew", ""], ["Mao", "Rui", ""]]}, {"id": "1911.05346", "submitter": "St\\'ephane Ga\\\"iffas", "authors": "Anastasiia Kabeshova, Yiyang Yu, Bertrand Lukacs, Emmanuel Bacry,\n  St\\'ephane Ga\\\"iffas", "title": "ZiMM: a deep learning model for long term and blurry relapses with\n  non-clinical claims data", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper considers the problems of modeling and predicting a long-term and\n``blurry'' relapse that occurs after a medical act, such as a surgery. The\nrelapse is observed only indirectly, in a ``blurry'' fashion, through\nlongitudinal prescriptions of drugs over a long period of time after the\nmedical act. We introduce a new model, called ZiMM (Zero-inflated Mixture of\nMultinomial distributions) in order to capture long-term and blurry relapses.\nOn top of it, we build an end-to-end deep-learning architecture called ZiMM\nEncoder-Decoder (ZiMM ED) that can learn from the complex, irregular, highly\nheterogeneous and sparse patterns of health events that are observed through a\nclaims-only database. ZiMM ED is applied on a ``non-clinical'' claims database,\nthat contains only timestamped reimbursement codes for drug purchases, medical\nprocedures and hospital diagnoses, the only available clinical feature being\nthe age of the patient. This setting is more challenging than a setting where\nbedside clinical signals are available. Our motivation for using such a\nnon-clinical claims database is its exhaustivity population-wise, compared to\nclinical electronic health records coming from a single or a small set of\nhospitals. Indeed, we consider a dataset containing the claims of almost\n\\emph{all French citizens} who had surgery for prostatic problems, with a\nhistory between 1.5 and 5 years. We consider a long-term (18 months) relapse\n(urination problems still occur despite surgery), which is blurry since it is\nobserved only through the reimbursement of a specific set of drugs for\nurination problems. Our experiments show that ZiMM ED improves several\nbaselines, including non-deep learning and deep-learning approaches, and that\nit allows working on such a dataset with minimal preprocessing work.\n", "versions": [{"version": "v1", "created": "Wed, 13 Nov 2019 08:23:20 GMT"}, {"version": "v2", "created": "Thu, 5 Mar 2020 22:12:47 GMT"}, {"version": "v3", "created": "Sat, 25 Jul 2020 19:42:46 GMT"}], "update_date": "2020-07-28", "authors_parsed": [["Kabeshova", "Anastasiia", ""], ["Yu", "Yiyang", ""], ["Lukacs", "Bertrand", ""], ["Bacry", "Emmanuel", ""], ["Ga\u00efffas", "St\u00e9phane", ""]]}, {"id": "1911.05350", "submitter": "Shingo Yashima", "authors": "Shingo Yashima, Atsushi Nitanda, Taiji Suzuki", "title": "Exponential Convergence Rates of Classification Errors on Learning with\n  SGD and Random Features", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Although kernel methods are widely used in many learning problems, they have\npoor scalability to large datasets. To address this problem, sketching and\nstochastic gradient methods are the most commonly used techniques to derive\nefficient large-scale learning algorithms. In this study, we consider solving a\nbinary classification problem using random features and stochastic gradient\ndescent. In recent research, an exponential convergence rate of the expected\nclassification error under the strong low-noise condition has been shown. We\nextend these analyses to a random features setting, analyzing the error induced\nby the approximation of random features in terms of the distance between the\ngenerated hypothesis including population risk minimizers and empirical risk\nminimizers when using general Lipschitz loss functions, to show that an\nexponential convergence of the expected classification error is achieved even\nif random features approximation is applied. Additionally, we demonstrate that\nthe convergence rate does not depend on the number of features and there is a\nsignificant computational benefit in using random features in classification\nproblems because of the strong low-noise condition.\n", "versions": [{"version": "v1", "created": "Wed, 13 Nov 2019 08:46:12 GMT"}], "update_date": "2019-11-14", "authors_parsed": [["Yashima", "Shingo", ""], ["Nitanda", "Atsushi", ""], ["Suzuki", "Taiji", ""]]}, {"id": "1911.05369", "submitter": "Boris Ruf", "authors": "Vincent Grari, Boris Ruf, Sylvain Lamprier, Marcin Detyniecki", "title": "Fair Adversarial Gradient Tree Boosting", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CY stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Fair classification has become an important topic in machine learning\nresearch. While most bias mitigation strategies focus on neural networks, we\nnoticed a lack of work on fair classifiers based on decision trees even though\nthey have proven very efficient. In an up-to-date comparison of\nstate-of-the-art classification algorithms in tabular data, tree boosting\noutperforms deep learning. For this reason, we have developed a novel approach\nof adversarial gradient tree boosting. The objective of the algorithm is to\npredict the output $Y$ with gradient tree boosting while minimizing the ability\nof an adversarial neural network to predict the sensitive attribute $S$. The\napproach incorporates at each iteration the gradient of the neural network\ndirectly in the gradient tree boosting. We empirically assess our approach on 4\npopular data sets and compare against state-of-the-art algorithms. The results\nshow that our algorithm achieves a higher accuracy while obtaining the same\nlevel of fairness, as measured using a set of different common fairness\ndefinitions.\n", "versions": [{"version": "v1", "created": "Wed, 13 Nov 2019 09:43:55 GMT"}, {"version": "v2", "created": "Mon, 18 Nov 2019 10:28:37 GMT"}], "update_date": "2019-11-19", "authors_parsed": [["Grari", "Vincent", ""], ["Ruf", "Boris", ""], ["Lamprier", "Sylvain", ""], ["Detyniecki", "Marcin", ""]]}, {"id": "1911.05370", "submitter": "Sunil Mallya", "authors": "Sunil Mallya, Marc Overhage, Sravan Bodapati, Navneet Srivastava,\n  Sahika Genc", "title": "SAVEHR: Self Attention Vector Representations for EHR based Personalized\n  Chronic Disease Onset Prediction and Interpretability", "comments": "ML4H Workshop at Neurips 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Chronic disease progression is emerging as an important area of investment\nfor healthcare providers. As the quantity and richness of available clinical\ndata continue to increase along with advances in machine learning, there is\ngreat potential to advance our approaches to caring for patients. An ideal\napproach to this problem should generate good performance on at least three\naxes namely, a) perform across many clinical conditions without requiring deep\nclinical expertise or extensive data scientist effort, b) generalization across\npopulations, and c) be explainable (model interpretability). We present SAVEHR,\na self-attention based architecture on heterogeneous structured EHR data that\nachieves $>$ 0.51 AUC-PR and $>$ 0.87 AUC-ROC gains on predicting the onset of\nfour clinical conditions (CHF, Kidney Failure, Diabetes and COPD) 15-months in\nadvance, and transfers with high performance onto a new population. We\ndemonstrate that SAVEHR model performs superior to ten baselines on all three\naxes stated formerly.\n", "versions": [{"version": "v1", "created": "Wed, 13 Nov 2019 09:45:55 GMT"}], "update_date": "2019-11-14", "authors_parsed": [["Mallya", "Sunil", ""], ["Overhage", "Marc", ""], ["Bodapati", "Sravan", ""], ["Srivastava", "Navneet", ""], ["Genc", "Sahika", ""]]}, {"id": "1911.05384", "submitter": "Cl\\'ement Vignac", "authors": "Cl\\'ement Vignac, Guillermo Ortiz-Jim\\'enez, Pascal Frossard", "title": "On the choice of graph neural network architectures", "comments": "5 pages, 1 figure, accepted at ICASSP 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SI cs.LG eess.SP stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Seminal works on graph neural networks have primarily targeted\nsemi-supervised node classification problems with few observed labels and\nhigh-dimensional signals. With the development of graph networks, this setup\nhas become a de facto benchmark for a significant body of research.\nInterestingly, several works have recently shown that in this particular\nsetting, graph neural networks do not perform much better than predefined\nlow-pass filters followed by a linear classifier. However, when learning from\nlittle data in a high-dimensional space, it is not surprising that simple and\nheavily regularized methods are near-optimal. In this paper, we show\nempirically that in settings with fewer features and more training data, more\ncomplex graph networks significantly outperform simple models, and propose a\nfew insights towards the proper choice of graph network architectures. We\nfinally outline the importance of using sufficiently diverse benchmarks\n(including lower dimensional signals as well) when designing and studying new\ntypes of graph neural networks.\n", "versions": [{"version": "v1", "created": "Wed, 13 Nov 2019 10:25:08 GMT"}, {"version": "v2", "created": "Mon, 10 Feb 2020 17:35:36 GMT"}], "update_date": "2020-02-11", "authors_parsed": [["Vignac", "Cl\u00e9ment", ""], ["Ortiz-Jim\u00e9nez", "Guillermo", ""], ["Frossard", "Pascal", ""]]}, {"id": "1911.05402", "submitter": "Biswarup Das", "authors": "Biswarup Das and Eugene. A. Golikov", "title": "Quadratic number of nodes is sufficient to learn a dataset via gradient\n  descent", "comments": "Machine learning using neural networks, gradient descent,\n  optimization, overparametrization regime", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.OC cs.LG math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We prove that if an activation function satisfies some mild conditions and\nnumber of neurons in a two-layered fully connected neural network with this\nactivation function is beyond a certain threshold, then gradient descent on\nquadratic loss function finds the optimal weights of input layer for global\nminima in linear time. This threshold value is an improvement over previously\nobtained values. We hypothesise that this bound cannot be improved by the\nmethod we are using in this work.\n", "versions": [{"version": "v1", "created": "Wed, 13 Nov 2019 11:17:32 GMT"}], "update_date": "2019-11-14", "authors_parsed": [["Das", "Biswarup", ""], ["Golikov", "Eugene. A.", ""]]}, {"id": "1911.05403", "submitter": "Yavuz Koroglu", "authors": "Yavuz Koroglu and Alper Sen", "title": "Reinforcement Learning-Driven Test Generation for Android GUI\n  Applications using Formal Specifications", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SE cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  There have been many studies on automated test generation for mobile\nGraphical User Interface (GUI) applications. These studies successfully\ndemonstrate how to detect fatal exceptions and achieve high code and activity\ncoverage with fully automated test generation engines. However, it is unclear\nhow many GUI functions these engines manage to test. Furthermore, these engines\nimplement only implicit test oracles. We propose Fully Automated Reinforcement\nLEArning-Driven Specification-Based Test Generator for Android\n(FARLEAD-Android). FARLEAD-Android accepts a GUI-level formal specification as\na Linear-time Temporal Logic (LTL) formula. By dynamically executing the\nApplication Under Test (AUT), it learns how to generate a test that satisfies\nthe LTL formula using Reinforcement Learning (RL). The LTL formula does not\njust guide the test generation but also acts as a specified test oracle,\nenabling the developer to define automated test oracles for a wide variety of\nGUI functions by changing the formula. Our evaluation shows that\nFARLEAD-Android is more effective and achieves higher performance in generating\ntests for specified GUI functions than three known approaches, Random, Monkey,\nand QBEa. To the best of our knowledge, FARLEAD-Android is the first fully\nautomated mobile GUI testing engine that uses formal specifications.\n", "versions": [{"version": "v1", "created": "Wed, 13 Nov 2019 11:19:30 GMT"}, {"version": "v2", "created": "Wed, 27 Nov 2019 05:18:45 GMT"}], "update_date": "2019-11-28", "authors_parsed": [["Koroglu", "Yavuz", ""], ["Sen", "Alper", ""]]}, {"id": "1911.05419", "submitter": "Hubert Banville", "authors": "Hubert Banville, Isabela Albuquerque, Aapo Hyv\\\"arinen, Graeme Moffat,\n  Denis-Alexander Engemann and Alexandre Gramfort", "title": "Self-supervised representation learning from electroencephalography\n  signals", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG eess.SP stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The supervised learning paradigm is limited by the cost - and sometimes the\nimpracticality - of data collection and labeling in multiple domains.\nSelf-supervised learning, a paradigm which exploits the structure of unlabeled\ndata to create learning problems that can be solved with standard supervised\napproaches, has shown great promise as a pretraining or feature learning\napproach in fields like computer vision and time series processing. In this\nwork, we present self-supervision strategies that can be used to learn\ninformative representations from multivariate time series. One successful\napproach relies on predicting whether time windows are sampled from the same\ntemporal context or not. As demonstrated on a clinically relevant task (sleep\nscoring) and with two electroencephalography datasets, our approach outperforms\na purely supervised approach in low data regimes, while capturing important\nphysiological information without any access to labels.\n", "versions": [{"version": "v1", "created": "Wed, 13 Nov 2019 12:17:31 GMT"}], "update_date": "2019-11-14", "authors_parsed": [["Banville", "Hubert", ""], ["Albuquerque", "Isabela", ""], ["Hyv\u00e4rinen", "Aapo", ""], ["Moffat", "Graeme", ""], ["Engemann", "Denis-Alexander", ""], ["Gramfort", "Alexandre", ""]]}, {"id": "1911.05438", "submitter": "Etienne Bennequin", "authors": "Mohamed Salah Za\\\"iem and Etienne Bennequin", "title": "Learning to Communicate in Multi-Agent Reinforcement Learning : A Review", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.MA stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the issue of multiple agents learning to communicate through\nreinforcement learning within partially observable environments, with a focus\non information asymmetry in the second part of our work. We provide a review of\nthe recent algorithms developed to improve the agents' policy by allowing the\nsharing of information between agents and the learning of communication\nstrategies, with a focus on Deep Recurrent Q-Network-based models. We also\ndescribe recent efforts to interpret the languages generated by these agents\nand study their properties in an attempt to generate human-language-like\nsentences. We discuss the metrics used to evaluate the generated communication\nstrategies and propose a novel entropy-based evaluation metric. Finally, we\naddress the issue of the cost of communication and introduce the idea of an\nexperimental setup to expose this cost in cooperative-competitive game.\n", "versions": [{"version": "v1", "created": "Wed, 13 Nov 2019 13:08:46 GMT"}], "update_date": "2019-11-14", "authors_parsed": [["Za\u00efem", "Mohamed Salah", ""], ["Bennequin", "Etienne", ""]]}, {"id": "1911.05439", "submitter": "Megumi Nakao", "authors": "Megumi Nakao, Mitsuhiro Nakamura, Takashi Mizowaki, Tetsuya Matsuda", "title": "Statistical Deformation Reconstruction Using Multi-organ Shape Features\n  for Pancreatic Cancer Localization", "comments": null, "journal-ref": "Medical Image Analysis, Vol. 67, 101829, 2021", "doi": "10.1016/j.media.2020.101829", "report-no": null, "categories": "cs.CV cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Respiratory motion and the associated deformations of abdominal organs and\ntumors are essential information in clinical applications. However, inter- and\nintra-patient multi-organ deformations are complex and have not been\nstatistically formulated, whereas single organ deformations have been widely\nstudied. In this paper, we introduce a multi-organ deformation library and its\napplication to deformation reconstruction based on the shape features of\nmultiple abdominal organs. Statistical multi-organ motion/deformation models of\nthe stomach, liver, left and right kidneys, and duodenum were generated by\nshape matching their region labels defined on four-dimensional computed\ntomography images. A total of 250 volumes were measured from 25 pancreatic\ncancer patients. This paper also proposes a per-region-based deformation\nlearning using the reproducing kernel to predict the displacement of pancreatic\ncancer for adaptive radiotherapy. The experimental results show that the\nproposed concept estimates deformations better than general per-patient-based\nlearning models and achieves a clinically acceptable estimation error with a\nmean distance of 1.2 $\\pm$ 0.7 mm and a Hausdorff distance of 4.2 $\\pm$ 2.3 mm\nthroughout the respiratory motion.\n", "versions": [{"version": "v1", "created": "Wed, 13 Nov 2019 13:10:10 GMT"}], "update_date": "2020-11-04", "authors_parsed": [["Nakao", "Megumi", ""], ["Nakamura", "Mitsuhiro", ""], ["Mizowaki", "Takashi", ""], ["Matsuda", "Tetsuya", ""]]}, {"id": "1911.05441", "submitter": "Xinyu Fan", "authors": "Faen Zhang, Xinyu Fan, Hui Xu, Pengcheng Zhou, Yujian He, Junlong Liu", "title": "Regression via Arbitrary Quantile Modeling", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In the regression problem, L1 and L2 are the most commonly used loss\nfunctions, which produce mean predictions with different biases. However, the\npredictions are neither robust nor adequate enough since they only capture a\nfew conditional distributions instead of the whole distribution, especially for\nsmall datasets. To address this problem, we proposed arbitrary quantile\nmodeling to regulate the prediction, which achieved better performance compared\nto traditional loss functions. More specifically, a new distribution regression\nmethod, Deep Distribution Regression (DDR), is proposed to estimate arbitrary\nquantiles of the response variable. Our DDR method consists of two models: a Q\nmodel, which predicts the corresponding value for arbitrary quantile, and an F\nmodel, which predicts the corresponding quantile for arbitrary value.\nFurthermore, the duality between Q and F models enables us to design a novel\nloss function for joint training and perform a dual inference mechanism. Our\nexperiments demonstrate that our DDR-joint and DDR-disjoint methods outperform\nprevious methods such as AdaBoost, random forest, LightGBM, and neural networks\nboth in terms of mean and quantile prediction.\n", "versions": [{"version": "v1", "created": "Wed, 13 Nov 2019 13:11:30 GMT"}], "update_date": "2019-11-14", "authors_parsed": [["Zhang", "Faen", ""], ["Fan", "Xinyu", ""], ["Xu", "Hui", ""], ["Zhou", "Pengcheng", ""], ["He", "Yujian", ""], ["Liu", "Junlong", ""]]}, {"id": "1911.05443", "submitter": "Xinyu Fan", "authors": "Xinyu Fan", "title": "Dynamic Connected Neural Decision Classifier and Regressor with Dynamic\n  Softing Pruning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  To deal with various datasets over different complexity, this paper presents\nan self-adaptive learning model that combines the proposed Dynamic Connected\nNeural Decision Networks (DNDN) and a new pruning method--Dynamic Soft Pruning\n(DSP). DNDN is a combination of random forests and deep neural networks that\nenjoys both the advantages of strong classification capability of tree-like\nstructure and representation learning capability of network structure. Based on\nDeep Neural Decision Forests (DNDF), this paper adopts an end-to-end training\napproach by representing the classification distribution with multiple randomly\ninitialized softmax layers, which further allows an ensemble of multiple random\nforests attached to layers of neural network with different depth. We also\npropose a soft pruning method DSP to reduce the redundant connections of the\nnetwork adaptively to avoid over-fitting simple dataset. The model demonstrates\nno performance loss compared with unpruned models and even higher robustness\nover different data and feature distribution. Extensive experiments on\ndifferent datasets demonstrate the superiority of the proposed model over other\npopular algorithms in solving classification tasks.\n", "versions": [{"version": "v1", "created": "Wed, 13 Nov 2019 13:21:10 GMT"}, {"version": "v2", "created": "Wed, 20 Nov 2019 15:12:09 GMT"}, {"version": "v3", "created": "Mon, 22 Feb 2021 07:35:07 GMT"}], "update_date": "2021-02-23", "authors_parsed": [["Fan", "Xinyu", ""]]}, {"id": "1911.05461", "submitter": "Rodrigo Fernandes De Mello", "authors": "Rodrigo Fernandes de Mello", "title": "On the Complexity of Labeled Datasets", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The Statistical Learning Theory (SLT) provides the foundation to ensure that\na supervised algorithm generalizes the mapping $f: \\mathcal{X} \\to \\mathcal{Y}$\ngiven $f$ is selected from its search space bias $\\mathcal{F}$. SLT depends on\nthe Shattering coefficient function $\\mathcal{N}(\\mathcal{F},n)$ to upper bound\nthe empirical risk minimization principle, from which one can estimate the\nnecessary training sample size to ensure the probabilistic learning convergence\nand, most importantly, the characterization of the capacity of $\\mathcal{F}$,\nincluding its underfitting and overfitting abilities while addressing specific\ntarget problems. However, the analytical solution of the Shattering coefficient\nis still an open problem since the first studies by Vapnik and Chervonenkis in\n$1962$, which we address on specific datasets, in this paper, by employing\nequivalence relations from Topology, data separability results by Har-Peled and\nJones, and combinatorics. Our approach computes the Shattering coefficient for\nboth binary and multi-class datasets, leading to the following additional\ncontributions: (i) the estimation of the required number of hyperplanes in the\nworst and best-case classification scenarios and the respective $\\Omega$ and\n$O$ complexities; (ii) the estimation of the training sample sizes required to\nensure supervised learning; and (iii) the comparison of dataset embeddings,\nonce they (re)organize samples into some new space configuration. All results\nintroduced and discussed along this paper are supported by the R package\nshattering (https://cran.r-project.org/web/packages/shattering).\n", "versions": [{"version": "v1", "created": "Wed, 13 Nov 2019 13:50:46 GMT"}, {"version": "v2", "created": "Wed, 30 Sep 2020 16:45:38 GMT"}, {"version": "v3", "created": "Sun, 18 Jul 2021 13:07:33 GMT"}], "update_date": "2021-07-20", "authors_parsed": [["de Mello", "Rodrigo Fernandes", ""]]}, {"id": "1911.05464", "submitter": "Riccardo di Clemente", "authors": "Sharon Xu, Riccardo Di Clemente, Marta C. Gonz\\'alez", "title": "Mining urban lifestyles: urban computing, human behavior and recommender\n  systems", "comments": "8 pages, 4 figures", "journal-ref": "Big Data Recommender Systems - Volume 2: Application Paradigms,\n  Chapter 5 Mining urban lifestyles: urban computing, human behavior and\n  recommender systems, pp. 71-81, (Institution of Engineering and Technology\n  2019)", "doi": "10.1049/PBPC035G_ch5", "report-no": null, "categories": "cs.SI cs.CY cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In the last decade, the digital age has sharply redefined the way we study\nhuman behavior. With the advancement of data storage and sensing technologies,\nelectronic records now encompass a diverse spectrum of human activity, ranging\nfrom location data, phone and email communication to Twitter activity and\nopen-source contributions on Wikipedia and OpenStreetMap. In particular, the\nstudy of the shopping and mobility patterns of individual consumers has the\npotential to give deeper insight into the lifestyles and infrastructure of the\nregion. Credit card records (CCRs) provide detailed insight into purchase\nbehavior and have been found to have inherent regularity in consumer shopping\npatterns; call detail records (CDRs) present new opportunities to understand\nhuman mobility, analyze wealth, and model social network dynamics. In this\nchapter, we jointly model the lifestyles of individuals, a more challenging\nproblem with higher variability when compared to the aggregated behavior of\ncity regions. Using collective matrix factorization, we propose a unified dual\nview of lifestyles. Understanding these lifestyles will not only inform\ncommercial opportunities, but also help policymakers and nonprofit\norganizations understand the characteristics and needs of the entire region, as\nwell as of the individuals within that region. The applications of this range\nfrom targeted advertisements and promotions to the diffusion of digital\nfinancial services among low-income groups.\n", "versions": [{"version": "v1", "created": "Mon, 4 Nov 2019 17:19:39 GMT"}], "update_date": "2019-11-14", "authors_parsed": [["Xu", "Sharon", ""], ["Di Clemente", "Riccardo", ""], ["Gonz\u00e1lez", "Marta C.", ""]]}, {"id": "1911.05465", "submitter": "Carl Yang", "authors": "Carl Yang, Jieyu Zhang, Haonan Wang, Sha Li, Myungwan Kim, Matt\n  Walker, Yiou Xiao, Jiawei Han", "title": "Relation Learning on Social Networks with Multi-Modal Graph Edge\n  Variational Autoencoders", "comments": "To appear in WSDM 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  While node semantics have been extensively explored in social networks,\nlittle research attention has been paid to profile edge semantics, i.e., social\nrelations. Ideal edge semantics should not only show that two users are\nconnected, but also why they know each other and what they share in common.\nHowever, relations in social networks are often hard to profile, due to noisy\nmulti-modal signals and limited user-generated ground-truth labels.\n  In this work, we aim to develop a unified and principled framework that can\nprofile user relations as edge semantics in social networks by integrating\nmulti-modal signals in the presence of noisy and incomplete data. Our framework\nis also flexible towards limited or missing supervision. Specifically, we\nassume a latent distribution of multiple relations underlying each user link,\nand learn them with multi-modal graph edge variational autoencoders. We encode\nthe network data with a graph convolutional network, and decode arbitrary\nsignals with multiple reconstruction networks. Extensive experiments and case\nstudies on two public DBLP author networks and two internal LinkedIn member\nnetworks demonstrate the superior effectiveness and efficiency of our proposed\nmodel.\n", "versions": [{"version": "v1", "created": "Mon, 4 Nov 2019 18:04:55 GMT"}], "update_date": "2019-11-14", "authors_parsed": [["Yang", "Carl", ""], ["Zhang", "Jieyu", ""], ["Wang", "Haonan", ""], ["Li", "Sha", ""], ["Kim", "Myungwan", ""], ["Walker", "Matt", ""], ["Xiao", "Yiou", ""], ["Han", "Jiawei", ""]]}, {"id": "1911.05466", "submitter": "Fei Yu", "authors": "Fei Yu, Feiyi Fan, Shouxu Jiang, Kaiping Zheng", "title": "Attentive Geo-Social Group Recommendation", "comments": "12 pages, 7 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SI cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Social activities play an important role in people's daily life since they\ninteract. For recommendations based on social activities, it is vital to have\nnot only the activity information but also individuals' social relations.\nThanks to the geo-social networks and widespread use of location-aware mobile\ndevices, massive geo-social data is now readily available for exploitation by\nthe recommendation system. In this paper, a novel group recommendation method,\ncalled attentive geo-social group recommendation, is proposed to recommend the\ntarget user with both activity locations and a group of users that may join the\nactivities. We present an attention mechanism to model the influence of the\ntarget user $u_T$ in candidate user groups that satisfy the social constraints.\nIt helps to retrieve the optimal user group and activity topic candidates, as\nwell as explains the group decision-making process. Once the user group and\ntopics are retrieved, a novel efficient spatial query algorithm SPA-DF is\nemployed to determine the activity location under the constraints of the given\nuser group and activity topic candidates. The proposed method is evaluated in\nreal-world datasets and the experimental results show that the proposed model\nsignificantly outperforms baseline methods.\n", "versions": [{"version": "v1", "created": "Wed, 6 Nov 2019 11:13:27 GMT"}, {"version": "v2", "created": "Fri, 15 Nov 2019 03:31:32 GMT"}], "update_date": "2019-11-18", "authors_parsed": [["Yu", "Fei", ""], ["Fan", "Feiyi", ""], ["Jiang", "Shouxu", ""], ["Zheng", "Kaiping", ""]]}, {"id": "1911.05467", "submitter": "Haijun Yu", "authors": "Shanshan Tang and Bo Li and Haijun Yu", "title": "ChebNet: Efficient and Stable Constructions of Deep Neural Networks with\n  Rectified Power Units using Chebyshev Approximations", "comments": "18 pages, 6 figures, 2 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.NA math.NA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In a recent paper [B. Li, S. Tang and H. Yu, arXiv:1903.05858], it was shown\nthat deep neural networks built with rectified power units (RePU) can give\nbetter approximation for sufficient smooth functions than those with rectified\nlinear units, by converting polynomial approximation given in power series into\ndeep neural networks with optimal complexity and no approximation error.\nHowever, in practice, power series are not easy to compute. In this paper, we\npropose a new and more stable way to construct deep RePU neural networks based\non Chebyshev polynomial approximations. By using a hierarchical structure of\nChebyshev polynomial approximation in frequency domain, we build efficient and\nstable deep neural network constructions. In theory, ChebNets and the deep RePU\nnets based on Power series have the same upper error bounds for general\nfunction approximations. But numerically, ChebNets are much more stable.\nNumerical results show that the constructed ChebNets can be further trained and\nobtain much better results than those obtained by training deep RePU nets\nconstructed basing on power series.\n", "versions": [{"version": "v1", "created": "Thu, 7 Nov 2019 06:30:47 GMT"}, {"version": "v2", "created": "Fri, 20 Dec 2019 19:08:57 GMT"}], "update_date": "2019-12-24", "authors_parsed": [["Tang", "Shanshan", ""], ["Li", "Bo", ""], ["Yu", "Haijun", ""]]}, {"id": "1911.05469", "submitter": "Anuththari Gamage", "authors": "Anuththari Gamage, Eli Chien, Jianhao Peng, Olgica Milenkovic", "title": "Multi-MotifGAN (MMGAN): Motif-targeted Graph Generation and Prediction", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SI cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Generative graph models create instances of graphs that mimic the properties\nof real-world networks. Generative models are successful at retaining pairwise\nassociations in the underlying networks but often fail to capture higher-order\nconnectivity patterns known as network motifs. Different types of graphs\ncontain different network motifs, an example of which are triangles that often\narise in social and biological networks. It is hence vital to capture these\nhigher-order structures to simulate real-world networks accurately. We propose\nMulti-MotifGAN (MMGAN), a motif-targeted Generative Adversarial Network (GAN)\nthat generalizes the benchmark NetGAN approach. The generalization consists of\ncombining multiple biased random walks, each of which captures a different\nmotif structure. MMGAN outperforms NetGAN at creating new graphs that\naccurately reflect the network motif statistics of input graphs such as\nCiteseer, Cora and Facebook.\n", "versions": [{"version": "v1", "created": "Fri, 8 Nov 2019 19:28:13 GMT"}], "update_date": "2019-11-14", "authors_parsed": [["Gamage", "Anuththari", ""], ["Chien", "Eli", ""], ["Peng", "Jianhao", ""], ["Milenkovic", "Olgica", ""]]}, {"id": "1911.05473", "submitter": "Francesco Farina", "authors": "Francesco Farina, Stefano Melacci, Andrea Garulli, Antonio\n  Giannitrapani", "title": "Asynchronous Distributed Learning from Constraints", "comments": null, "journal-ref": null, "doi": "10.1109/TNNLS.2019.2947740", "report-no": null, "categories": "cs.LG math.OC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, the extension of the framework of Learning from Constraints\n(LfC) to a distributed setting where multiple parties, connected over the\nnetwork, contribute to the learning process is studied. LfC relies on the\ngeneric notion of \"constraint\" to inject knowledge into the learning problem\nand, due to its generality, it deals with possibly nonconvex constraints,\nenforced either in a hard or soft way. Motivated by recent progresses in the\nfield of distributed and constrained nonconvex optimization, we apply the\n(distributed) Asynchronous Method of Multipliers (ASYMM) to LfC. The study\nshows that such a method allows us to support scenarios where selected\nconstraints (i.e., knowledge), data, and outcomes of the learning process can\nbe locally stored in each computational node without being shared with the rest\nof the network, opening the road to further investigations into\nprivacy-preserving LfC. Constraints act as a bridge between what is shared over\nthe net and what is private to each node and no central authority is required.\nWe demonstrate the applicability of these ideas in two distributed real-world\nsettings in the context of digit recognition and document classification.\n", "versions": [{"version": "v1", "created": "Wed, 13 Nov 2019 14:08:28 GMT"}], "update_date": "2019-11-14", "authors_parsed": [["Farina", "Francesco", ""], ["Melacci", "Stefano", ""], ["Garulli", "Andrea", ""], ["Giannitrapani", "Antonio", ""]]}, {"id": "1911.05479", "submitter": "Asim Iqbal", "authors": "Asim Iqbal, Phil Dong, Christopher M Kim, Heeun Jang", "title": "Decoding Neural Responses in Mouse Visual Cortex through a Deep Neural\n  Network", "comments": null, "journal-ref": "2019 International Joint Conference on Neural Networks (IJCNN).\n  IEEE, 2019", "doi": "10.1109/IJCNN.2019.8852121", "report-no": null, "categories": "q-bio.NC cs.AI cs.LG cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Finding a code to unravel the population of neural responses that leads to a\ndistinct animal behavior has been a long-standing question in the field of\nneuroscience. With the recent advances in machine learning, it is shown that\nthe hierarchically Deep Neural Networks (DNNs) perform optimally in decoding\nunique features out of complex datasets. In this study, we utilize the power of\na DNN to explore the computational principles in the mammalian brain by\nexploiting the Neuropixel data from Allen Brain Institute. We decode the neural\nresponses from mouse visual cortex to predict the presented stimuli to the\nanimal for natural (bear, trees, cheetah, etc.) and artificial (drifted\ngratings, orientated bars, etc.) classes. Our results indicate that neurons in\nmouse visual cortex encode the features of natural and artificial objects in a\ndistinct manner, and such neural code is consistent across animals. We\ninvestigate this by applying transfer learning to train a DNN on the neural\nresponses of a single animal and test its generalized performance across\nmultiple animals. Within a single animal, DNN is able to decode the neural\nresponses with as much as 100% classification accuracy. Across animals, this\naccuracy is reduced to 91%. This study demonstrates the potential of utilizing\nthe DNN models as a computational framework to understand the neural coding\nprinciples in the mammalian brain.\n", "versions": [{"version": "v1", "created": "Sat, 26 Oct 2019 05:02:33 GMT"}], "update_date": "2019-11-14", "authors_parsed": [["Iqbal", "Asim", ""], ["Dong", "Phil", ""], ["Kim", "Christopher M", ""], ["Jang", "Heeun", ""]]}, {"id": "1911.05484", "submitter": "Mohammad Amin", "authors": "M. Amin, F. Safaei, N. S. Ghaderian", "title": "Extracting a Discriminative Structural Sub-Network for ASD Screening\n  using the Evolutionary Algorithm", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SI cs.LG cs.NE", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Autism spectrum disorder (ASD) is one of the most significant neurological\ndisorders that disrupt a person's social communication skills. The progression\nand development of neuroimaging technologies has made structural network\nconstruction of brain regions possible. In this paper, after finding the\ndiscriminative sub-network using the evolutionary algorithm, the simple\nfeatures of the sub-network lead us to diagnose autism in various subjects with\nplausible accuracy (76% on average). This method yields substantially better\nresults compared to previous researches. Thus, this method may be used as an\naccurate assistance in autism screening\n", "versions": [{"version": "v1", "created": "Sat, 26 Oct 2019 12:21:58 GMT"}], "update_date": "2019-11-14", "authors_parsed": [["Amin", "M.", ""], ["Safaei", "F.", ""], ["Ghaderian", "N. S.", ""]]}, {"id": "1911.05485", "submitter": "Johannes Klicpera", "authors": "Johannes Klicpera, Stefan Wei{\\ss}enberger, Stephan G\\\"unnemann", "title": "Diffusion Improves Graph Learning", "comments": "Published as a conference paper at NeurIPS 2019", "journal-ref": "Thirty-third Conference on Neural Information Processing Systems\n  (NeurIPS), Vancouver, Canada, 2019", "doi": null, "report-no": null, "categories": "cs.SI cs.AI cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Graph convolution is the core of most Graph Neural Networks (GNNs) and\nusually approximated by message passing between direct (one-hop) neighbors. In\nthis work, we remove the restriction of using only the direct neighbors by\nintroducing a powerful, yet spatially localized graph convolution: Graph\ndiffusion convolution (GDC). GDC leverages generalized graph diffusion,\nexamples of which are the heat kernel and personalized PageRank. It alleviates\nthe problem of noisy and often arbitrarily defined edges in real graphs. We\nshow that GDC is closely related to spectral-based models and thus combines the\nstrengths of both spatial (message passing) and spectral methods. We\ndemonstrate that replacing message passing with graph diffusion convolution\nconsistently leads to significant performance improvements across a wide range\nof models on both supervised and unsupervised tasks and a variety of datasets.\nFurthermore, GDC is not limited to GNNs but can trivially be combined with any\ngraph-based model or algorithm (e.g. spectral clustering) without requiring any\nchanges to the latter or affecting its computational complexity. Our\nimplementation is available online.\n", "versions": [{"version": "v1", "created": "Mon, 28 Oct 2019 17:51:46 GMT"}, {"version": "v2", "created": "Thu, 14 Nov 2019 08:41:14 GMT"}, {"version": "v3", "created": "Tue, 3 Dec 2019 14:42:37 GMT"}, {"version": "v4", "created": "Mon, 23 Dec 2019 21:13:40 GMT"}, {"version": "v5", "created": "Sun, 29 Dec 2019 22:33:56 GMT"}], "update_date": "2020-01-01", "authors_parsed": [["Klicpera", "Johannes", ""], ["Wei\u00dfenberger", "Stefan", ""], ["G\u00fcnnemann", "Stephan", ""]]}, {"id": "1911.05489", "submitter": "James Atwood", "authors": "James Atwood, Hansa Srinivasan, Yoni Halpern, D Sculley", "title": "Fair treatment allocations in social networks", "comments": "To appear in the Fair ML for Health workshop at NeurIPS 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SI cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Simulations of infectious disease spread have long been used to understand\nhow epidemics evolve and how to effectively treat them. However, comparatively\nlittle attention has been paid to understanding the fairness implications of\ndifferent treatment strategies -- that is, how might such strategies distribute\nthe expected disease burden differentially across various subgroups or\ncommunities in the population? In this work, we define the precision disease\ncontrol problem -- the problem of optimally allocating vaccines in a social\nnetwork in a step-by-step fashion -- and we use the ML Fairness Gym to simulate\nepidemic control and study it from both an efficiency and fairness perspective.\nWe then present an exploratory analysis of several different environments and\ndiscuss the fairness implications of different treatment strategies.\n", "versions": [{"version": "v1", "created": "Fri, 1 Nov 2019 15:31:27 GMT"}], "update_date": "2019-11-14", "authors_parsed": [["Atwood", "James", ""], ["Srinivasan", "Hansa", ""], ["Halpern", "Yoni", ""], ["Sculley", "D", ""]]}, {"id": "1911.05493", "submitter": "Sirui Song", "authors": "Sirui Song, Tong Xia, Depeng Jin, Pan Hui, Yong Li", "title": "UrbanRhythm: Revealing Urban Dynamics Hidden in Mobility Data", "comments": "Submitted to IEEE Transactions on Knowledge and Data Engineering\n  (TKDE)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SI cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Understanding urban dynamics, i.e., how the types and intensity of urban\nresidents' activities in the city change along with time, is of urgent demand\nfor building an efficient and livable city. Nonetheless, this is challenging\ndue to the expanding urban population and the complicated spatial distribution\nof residents. In this paper, to reveal urban dynamics, we propose a novel\nsystem UrbanRhythm to reveal the urban dynamics hidden in human mobility data.\nUrbanRhythm addresses three questions: 1) What mobility feature should be used\nto present residents' high-dimensional activities in the city? 2) What are\nbasic components of urban dynamics? 3) What are the long-term periodicity and\nshort-term regularity of urban dynamics? In UrbanRhythm, we extract staying,\nleaving, arriving three attributes of mobility and use a image processing\nmethod Saak transform to calculate the mobility distribution feature. For the\nsecond question, several city states are identified by hierarchy clustering as\nthe basic components of urban dynamics, such as sleeping states and working\nstates. We further characterize the urban dynamics as the transform of city\nstates along time axis. For the third question, we directly observe the\nlong-term periodicity of urban dynamics from visualization. Then for the\nshort-term regularity, we design a novel motif analysis method to discovery\nmotifs as well as their hierarchy relationships. We evaluate our proposed\nsystem on two real-life datesets and validate the results according to App\nusage records. This study sheds light on urban dynamics hidden in human\nmobility and can further pave the way for more complicated mobility behavior\nmodeling and deeper urban understanding.\n", "versions": [{"version": "v1", "created": "Sun, 3 Nov 2019 02:45:20 GMT"}], "update_date": "2019-11-14", "authors_parsed": [["Song", "Sirui", ""], ["Xia", "Tong", ""], ["Jin", "Depeng", ""], ["Hui", "Pan", ""], ["Li", "Yong", ""]]}, {"id": "1911.05494", "submitter": "Abhijit Suprem", "authors": "Abhijit Suprem, Aibek Musaev, Calton Pu", "title": "Concept Drift Adaptive Physical Event Detection for Social Media Streams", "comments": null, "journal-ref": "Services Congress 2019", "doi": null, "report-no": null, "categories": "cs.SI cs.CY cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Event detection has long been the domain of physical sensors operating in a\nstatic dataset assumption. The prevalence of social media and web access has\nled to the emergence of social, or human sensors who report on events globally.\nThis warrants development of event detectors that can take advantage of the\ntruly dense and high spatial and temporal resolution data provided by more than\n3 billion social users. The phenomenon of concept drift, which causes terms and\nsignals associated with a topic to change over time, renders static machine\nlearning ineffective. Towards this end, we present an application for physical\nevent detection on social sensors that improves traditional physical event\ndetection with concept drift adaptation. Our approach continuously updates its\nmachine learning classifiers automatically, without the need for human\nintervention. It integrates data from heterogeneous sources and is designed to\nhandle weak-signal events (landslides, wildfires) with around ten posts per\nevent in addition to large-signal events (hurricanes, earthquakes) with\nhundreds of thousands of posts per event. We demonstrate a landslide detector\non our application that detects almost 350% more land-slides compared to static\napproaches. Our application has high performance: using classifiers trained in\n2014, achieving event detection accuracy of 0.988, compared to 0.762 for static\napproaches.\n", "versions": [{"version": "v1", "created": "Tue, 17 Sep 2019 05:15:23 GMT"}], "update_date": "2019-11-14", "authors_parsed": [["Suprem", "Abhijit", ""], ["Musaev", "Aibek", ""], ["Pu", "Calton", ""]]}, {"id": "1911.05495", "submitter": "Prakamya Mishra", "authors": "Prakamya Mishra", "title": "Correlated Feature Selection for Tweet Spam Classification", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SI cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The identification of spam messages on social networks is a very challenging\ntask. Social media sites like Twitter \\& Facebook attracts a lot of users and\ncompanies to advertise and attract users of personal gains. These\nadvertisements most of the time leads to spamming, which in return leads to\npoor user experience. The purpose of this paper is to undertake the analysis of\nspamming on Twitter. To classify spams efficiently, it is necessary to first\nunderstand the features of the spam tweets as well as identify attributes of\nthe spammer. We extract both tweet based features and user-based features for\nour analysis and observe the correlation between these features. This step is\nnecessary as we can reduce the training time if we combine the highly\ncorrelated features. Our proposed approach uses a classification model based on\nartificial neural networks to classify the tweets as spam or non-spam giving\nthe highest accuracy of 97.57\\% when compared with four other standard\nclassifiers namely, SVM, K Nearest Neighbours, Naive Bayes, and Random Forest.\n", "versions": [{"version": "v1", "created": "Wed, 6 Nov 2019 15:16:35 GMT"}, {"version": "v2", "created": "Wed, 27 Nov 2019 22:22:01 GMT"}, {"version": "v3", "created": "Tue, 26 May 2020 22:44:27 GMT"}, {"version": "v4", "created": "Sun, 25 Oct 2020 20:23:53 GMT"}], "update_date": "2020-10-27", "authors_parsed": [["Mishra", "Prakamya", ""]]}, {"id": "1911.05496", "submitter": "Lutz Oettershagen", "authors": "Lutz Oettershagen, Nils M. Kriege, Christopher Morris, Petra Mutzel", "title": "Temporal Graph Kernels for Classifying Dissemination Processes", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SI cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Many real-world graphs or networks are temporal, e.g., in a social network\npersons only interact at specific points in time. This information directs\ndissemination processes on the network, such as the spread of rumors, fake\nnews, or diseases. However, the current state-of-the-art methods for supervised\ngraph classification are designed mainly for static graphs and may not be able\nto capture temporal information. Hence, they are not powerful enough to\ndistinguish between graphs modeling different dissemination processes. To\naddress this, we introduce a framework to lift standard graph kernels to the\ntemporal domain. Specifically, we explore three different approaches and\ninvestigate the trade-offs between loss of temporal information and efficiency.\nMoreover, to handle large-scale graphs, we propose stochastic variants of our\nkernels with provable approximation guarantees. We evaluate our methods on a\nwide range of real-world social networks. Our methods beat static kernels by a\nlarge margin in terms of accuracy while still being scalable to large graphs\nand data sets. Hence, we confirm that taking temporal information into account\nis crucial for the successful classification of dissemination processes.\n", "versions": [{"version": "v1", "created": "Mon, 14 Oct 2019 06:19:58 GMT"}], "update_date": "2019-11-14", "authors_parsed": [["Oettershagen", "Lutz", ""], ["Kriege", "Nils M.", ""], ["Morris", "Christopher", ""], ["Mutzel", "Petra", ""]]}, {"id": "1911.05503", "submitter": "Bertrand Charpentier", "authors": "Marin Bilo\\v{s}, Bertrand Charpentier, Stephan G\\\"unnemann", "title": "Uncertainty on Asynchronous Time Event Prediction", "comments": "Neurips 2019 (Spotlight)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Asynchronous event sequences are the basis of many applications throughout\ndifferent industries. In this work, we tackle the task of predicting the next\nevent (given a history), and how this prediction changes with the passage of\ntime. Since at some time points (e.g. predictions far into the future) we might\nnot be able to predict anything with confidence, capturing uncertainty in the\npredictions is crucial. We present two new architectures, WGP-LN and FD-Dir,\nmodelling the evolution of the distribution on the probability simplex with\ntime-dependent logistic normal and Dirichlet distributions. In both cases, the\ncombination of RNNs with either Gaussian process or function decomposition\nallows to express rich temporal evolution of the distribution parameters, and\nnaturally captures uncertainty. Experiments on class prediction, time\nprediction and anomaly detection demonstrate the high performances of our\nmodels on various datasets compared to other approaches.\n", "versions": [{"version": "v1", "created": "Wed, 13 Nov 2019 14:26:30 GMT"}, {"version": "v2", "created": "Wed, 8 Jan 2020 12:20:50 GMT"}], "update_date": "2020-01-09", "authors_parsed": [["Bilo\u0161", "Marin", ""], ["Charpentier", "Bertrand", ""], ["G\u00fcnnemann", "Stephan", ""]]}, {"id": "1911.05504", "submitter": "Anurenjan Purushothaman", "authors": "Anurenjan Purushothaman, Anirudh Sreeram and Sriram Ganapathy", "title": "3-D Feature and Acoustic Modeling for Far-Field Speech Recognition", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.AS cs.LG cs.SD", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Automatic speech recognition in multi-channel reverberant conditions is a\nchallenging task. The conventional way of suppressing the reverberation\nartifacts involves a beamforming based enhancement of the multi-channel speech\nsignal, which is used to extract spectrogram based features for a neural\nnetwork acoustic model. In this paper, we propose to extract features directly\nfrom the multi-channel speech signal using a multi variate autoregressive (MAR)\nmodeling approach, where the correlations among all the three dimensions of\ntime, frequency and channel are exploited. The MAR features are fed to a\nconvolutional neural network (CNN) architecture which performs the joint\nacoustic modeling on the three dimensions. The 3-D CNN architecture allows the\ncombination of multi-channel features that optimize the speech recognition cost\ncompared to the traditional beamforming models that focus on the enhancement\ntask. Experiments are conducted on the CHiME-3 and REVERB Challenge dataset\nusing multi-channel reverberant speech. In these experiments, the proposed 3-D\nfeature and acoustic modeling approach provides significant improvements over\nan ASR system trained with beamformed audio (average relative improvements of\n10 % and 9 % in word error rates for CHiME-3 and REVERB Challenge datasets\nrespectively.\n", "versions": [{"version": "v1", "created": "Wed, 13 Nov 2019 14:26:54 GMT"}, {"version": "v2", "created": "Mon, 27 Jan 2020 04:31:26 GMT"}], "update_date": "2020-01-28", "authors_parsed": [["Purushothaman", "Anurenjan", ""], ["Sreeram", "Anirudh", ""], ["Ganapathy", "Sriram", ""]]}, {"id": "1911.05507", "submitter": "Jack Rae", "authors": "Jack W. Rae and Anna Potapenko and Siddhant M. Jayakumar and Timothy\n  P. Lillicrap", "title": "Compressive Transformers for Long-Range Sequence Modelling", "comments": "19 pages, 6 figures, 10 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present the Compressive Transformer, an attentive sequence model which\ncompresses past memories for long-range sequence learning. We find the\nCompressive Transformer obtains state-of-the-art language modelling results in\nthe WikiText-103 and Enwik8 benchmarks, achieving 17.1 ppl and 0.97 bpc\nrespectively. We also find it can model high-frequency speech effectively and\ncan be used as a memory mechanism for RL, demonstrated on an object matching\ntask. To promote the domain of long-range sequence learning, we propose a new\nopen-vocabulary language modelling benchmark derived from books, PG-19.\n", "versions": [{"version": "v1", "created": "Wed, 13 Nov 2019 14:36:01 GMT"}], "update_date": "2019-11-14", "authors_parsed": [["Rae", "Jack W.", ""], ["Potapenko", "Anna", ""], ["Jayakumar", "Siddhant M.", ""], ["Lillicrap", "Timothy P.", ""]]}, {"id": "1911.05521", "submitter": "Felix Christian Bauer", "authors": "Felix Christian Bauer, Dylan Richard Muir, Giacomo Indiveri", "title": "Real-time ultra-low power ECG anomaly detection using an event-driven\n  neuromorphic processor", "comments": null, "journal-ref": null, "doi": "10.1109/TBCAS.2019.2953001", "report-no": null, "categories": "eess.SP cs.LG cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Accurate detection of pathological conditions in human subjects can be\nachieved through off-line analysis of recorded biological signals such as\nelectrocardiograms (ECGs). However, human diagnosis is time-consuming and\nexpensive, as it requires the time of medical professionals. This is especially\ninefficient when indicative patterns in the biological signals are infrequent.\nMoreover, patients with suspected pathologies are often monitored for extended\nperiods, requiring the storage and examination of large amounts of\nnon-pathological data, and entailing a difficult visual search task for\ndiagnosing professionals.\n  In this work we propose a compact and sub-mW low power neural processing\nsystem that can be used to perform on-line and real-time preliminary diagnosis\nof pathological conditions, to raise warnings for the existence of possible\npathological conditions, or to trigger an off-line data recording system for\nfurther analysis by a medical professional. We apply the system to real-time\nclassification of ECG data for distinguishing between healthy heartbeats and\npathological rhythms.\n  Multi-channel analog ECG traces are encoded as asynchronous streams of binary\nevents and processed using a spiking recurrent neural network operated in a\nreservoir computing paradigm. An event-driven neuron output layer is then\ntrained to recognize one of several pathologies. Finally, the filtered activity\nof this output layer is used to generate a binary trigger signal indicating the\npresence or absence of a pathological pattern.\n  We validate the approach proposed using a Dynamic Neuromorphic Asynchronous\nProcessor (DYNAP) chip, implemented using a standard 180 nm CMOS VLSI process,\nand present experimental results measured from the chip.\n", "versions": [{"version": "v1", "created": "Wed, 13 Nov 2019 14:56:36 GMT"}], "update_date": "2019-11-14", "authors_parsed": [["Bauer", "Felix Christian", ""], ["Muir", "Dylan Richard", ""], ["Indiveri", "Giacomo", ""]]}, {"id": "1911.05531", "submitter": "Iddo Drori", "authors": "Iddo Drori, Darshan Thaker, Arjun Srivatsa, Daniel Jeong, Yueqi Wang,\n  Linyong Nan, Fan Wu, Dimitri Leggas, Jinhao Lei, Weiyi Lu, Weilong Fu, Yuan\n  Gao, Sashank Karri, Anand Kannan, Antonio Moretti, Mohammed AlQuraishi, Chen\n  Keasar, Itsik Pe'er", "title": "Accurate Protein Structure Prediction by Embeddings and Deep Learning\n  Representations", "comments": null, "journal-ref": "Machine Learning in Computational Biology, 2019", "doi": null, "report-no": null, "categories": "q-bio.BM cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Proteins are the major building blocks of life, and actuators of almost all\nchemical and biophysical events in living organisms. Their native structures in\nturn enable their biological functions which have a fundamental role in drug\ndesign. This motivates predicting the structure of a protein from its sequence\nof amino acids, a fundamental problem in computational biology. In this work,\nwe demonstrate state-of-the-art protein structure prediction (PSP) results\nusing embeddings and deep learning models for prediction of backbone atom\ndistance matrices and torsion angles. We recover 3D coordinates of backbone\natoms and reconstruct full atom protein by optimization. We create a new gold\nstandard dataset of proteins which is comprehensive and easy to use. Our\ndataset consists of amino acid sequences, Q8 secondary structures, position\nspecific scoring matrices, multiple sequence alignment co-evolutionary\nfeatures, backbone atom distance matrices, torsion angles, and 3D coordinates.\nWe evaluate the quality of our structure prediction by RMSD on the latest\nCritical Assessment of Techniques for Protein Structure Prediction (CASP) test\ndata and demonstrate competitive results with the winning teams and AlphaFold\nin CASP13 and supersede the results of the winning teams in CASP12. We make our\ndata, models, and code publicly available.\n", "versions": [{"version": "v1", "created": "Sat, 9 Nov 2019 00:21:17 GMT"}], "update_date": "2019-11-14", "authors_parsed": [["Drori", "Iddo", ""], ["Thaker", "Darshan", ""], ["Srivatsa", "Arjun", ""], ["Jeong", "Daniel", ""], ["Wang", "Yueqi", ""], ["Nan", "Linyong", ""], ["Wu", "Fan", ""], ["Leggas", "Dimitri", ""], ["Lei", "Jinhao", ""], ["Lu", "Weiyi", ""], ["Fu", "Weilong", ""], ["Gao", "Yuan", ""], ["Karri", "Sashank", ""], ["Kannan", "Anand", ""], ["Moretti", "Antonio", ""], ["AlQuraishi", "Mohammed", ""], ["Keasar", "Chen", ""], ["Pe'er", "Itsik", ""]]}, {"id": "1911.05541", "submitter": "Icaro Oliveira", "authors": "Icaro O. de Oliveira, Rayson Laroca, David Menotti, Keiko V. O.\n  Fonseca and Rodrigo Minetto", "title": "Vehicle-Rear: A New Dataset to Explore Feature Fusion for Vehicle\n  Identification Using Convolutional Neural Networks", "comments": null, "journal-ref": "IEEE Access, vol. 9, pp. 101065-101077, 2021", "doi": "10.1109/ACCESS.2021.3097964", "report-no": null, "categories": "cs.CV cs.LG", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  This work addresses the problem of vehicle identification through\nnon-overlapping cameras. As our main contribution, we introduce a novel dataset\nfor vehicle identification, called Vehicle-Rear, that contains more than three\nhours of high-resolution videos, with accurate information about the make,\nmodel, color and year of nearly 3,000 vehicles, in addition to the position and\nidentification of their license plates. To explore our dataset we design a\ntwo-stream CNN that simultaneously uses two of the most distinctive and\npersistent features available: the vehicle's appearance and its license plate.\nThis is an attempt to tackle a major problem: false alarms caused by vehicles\nwith similar designs or by very close license plate identifiers. In the first\nnetwork stream, shape similarities are identified by a Siamese CNN that uses a\npair of low-resolution vehicle patches recorded by two different cameras. In\nthe second stream, we use a CNN for OCR to extract textual information,\nconfidence scores, and string similarities from a pair of high-resolution\nlicense plate patches. Then, features from both streams are merged by a\nsequence of fully connected layers for decision. In our experiments, we\ncompared the two-stream network against several well-known CNN architectures\nusing single or multiple vehicle features. The architectures, trained models,\nand dataset are publicly available at https://github.com/icarofua/vehicle-rear.\n", "versions": [{"version": "v1", "created": "Wed, 13 Nov 2019 15:23:04 GMT"}, {"version": "v2", "created": "Wed, 6 May 2020 11:43:28 GMT"}, {"version": "v3", "created": "Sun, 25 Jul 2021 11:39:59 GMT"}], "update_date": "2021-07-28", "authors_parsed": [["de Oliveira", "Icaro O.", ""], ["Laroca", "Rayson", ""], ["Menotti", "David", ""], ["Fonseca", "Keiko V. O.", ""], ["Minetto", "Rodrigo", ""]]}, {"id": "1911.05544", "submitter": "Zhongkai Sun", "authors": "Zhongkai Sun, Prathusha Sarma, William Sethares, Yingyu Liang", "title": "Learning Relationships between Text, Audio, and Video via Deep Canonical\n  Correlation for Multimodal Language Analysis", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://creativecommons.org/publicdomain/zero/1.0/", "abstract": "  Multimodal language analysis often considers relationships between features\nbased on text and those based on acoustical and visual properties. Text\nfeatures typically outperform non-text features in sentiment analysis or\nemotion recognition tasks in part because the text features are derived from\nadvanced language models or word embeddings trained on massive data sources\nwhile audio and video features are human-engineered and comparatively\nunderdeveloped. Given that the text, audio, and video are describing the same\nutterance in different ways, we hypothesize that the multimodal sentiment\nanalysis and emotion recognition can be improved by learning (hidden)\ncorrelations between features extracted from the outer product of text and\naudio (we call this text-based audio) and analogous text-based video. This\npaper proposes a novel model, the Interaction Canonical Correlation Network\n(ICCN), to learn such multimodal embeddings. ICCN learns correlations between\nall three modes via deep canonical correlation analysis (DCCA) and the proposed\nembeddings are then tested on several benchmark datasets and against other\nstate-of-the-art multimodal embedding algorithms. Empirical results and\nablation studies confirm the effectiveness of ICCN in capturing useful\ninformation from all three views.\n", "versions": [{"version": "v1", "created": "Wed, 13 Nov 2019 15:27:37 GMT"}, {"version": "v2", "created": "Sat, 30 Nov 2019 23:48:59 GMT"}], "update_date": "2019-12-03", "authors_parsed": [["Sun", "Zhongkai", ""], ["Sarma", "Prathusha", ""], ["Sethares", "William", ""], ["Liang", "Yingyu", ""]]}, {"id": "1911.05546", "submitter": "Daniela Mihai", "authors": "Daniela Mihai and Jonathon Hare", "title": "Avoiding hashing and encouraging visual semantics in referential\n  emergent language games", "comments": "4 pages, presented at Emergent Communication: Towards Natural\n  Language workshop (NeurIPS 2019)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  There has been an increasing interest in the area of emergent communication\nbetween agents which learn to play referential signalling games with realistic\nimages. In this work, we consider the signalling game setting of Havrylov and\nTitov and investigate the effect of the feature extractor's weights and of the\ntask being solved on the visual semantics learned or captured by the models. We\nimpose various augmentation to the input images and additional tasks in the\ngame with the aim to induce visual representations which capture conceptual\nproperties of images. Through our set of experiments, we demonstrate that\ncommunication systems which capture visual semantics can be learned in a\ncompletely self-supervised manner by playing the right types of game.\n", "versions": [{"version": "v1", "created": "Wed, 13 Nov 2019 15:31:48 GMT"}], "update_date": "2019-11-14", "authors_parsed": [["Mihai", "Daniela", ""], ["Hare", "Jonathon", ""]]}, {"id": "1911.05584", "submitter": "Feng Huang", "authors": "Feng Huang, Xiang Yue, Zhankun Xiong, Zhouxin Yu and Wen Zhang", "title": "Tensor Decomposition with Relational Constraints for Predicting Multiple\n  Types of MicroRNA-disease Associations", "comments": null, "journal-ref": null, "doi": "10.1093/bib/bbaa140", "report-no": null, "categories": "cs.LG q-bio.QM stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  MicroRNAs (miRNAs) play crucial roles in multifarious biological processes\nassociated with human diseases. Identifying potential miRNA-disease\nassociations contributes to understanding the molecular mechanisms of\nmiRNA-related diseases. Most of the existing computational methods mainly focus\non predicting whether a miRNA-disease association exists or not. However, the\nroles of miRNAs in diseases are prominently diverged, for instance, Genetic\nvariants of microRNA (mir-15) may affect expression level of miRNAs leading to\nB cell chronic lymphocytic leukemia, while circulating miRNAs (including\nmir-1246, mir-1307-3p, etc.) have potentials to detecting breast cancer in the\nearly stage. In this paper, we aim to predict multi-type miRNA-disease\nassociations instead of taking them as binary. To this end, we innovatively\nrepresent miRNA-disease-type triplets as a tensor and introduce Tensor\nDecomposition methods to solve the prediction task. Experimental results on two\nwidely-adopted miRNA-disease datasets: HMDD v2.0 and HMDD v3.2 show that tensor\ndecomposition methods improve a recent baseline in a large scale (up to 38% in\ntop-1 F1). We further propose a novel method, Tensor Decomposition with\nRelational Constraints (TDRC), which incorporates biological features as\nrelational constraints to further the existing tensor decomposition methods.\nCompared with two existing tensor decomposition methods, TDRC can produce\nbetter performance while being more efficient.\n", "versions": [{"version": "v1", "created": "Wed, 13 Nov 2019 16:25:24 GMT"}, {"version": "v2", "created": "Mon, 9 Mar 2020 11:43:02 GMT"}], "update_date": "2021-03-30", "authors_parsed": [["Huang", "Feng", ""], ["Yue", "Xiang", ""], ["Xiong", "Zhankun", ""], ["Yu", "Zhouxin", ""], ["Zhang", "Wen", ""]]}, {"id": "1911.05585", "submitter": "Ekaterina Lobacheva Ms", "authors": "Ekaterina Lobacheva, Nadezhda Chirkova, Alexander Markovich, Dmitry\n  Vetrov", "title": "Structured Sparsification of Gated Recurrent Neural Networks", "comments": "Published in Workshop on Context and Compositionality in Biological\n  and Artificial Neural Systems, NeurIPS 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CL stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recently, a lot of techniques were developed to sparsify the weights of\nneural networks and to remove networks' structure units, e.g. neurons. We\nadjust the existing sparsification approaches to the gated recurrent\narchitectures. Specifically, in addition to the sparsification of weights and\nneurons, we propose sparsifying the preactivations of gates. This makes some\ngates constant and simplifies LSTM structure. We test our approach on the text\nclassification and language modeling tasks. We observe that the resulting\nstructure of gate sparsity depends on the task and connect the learned\nstructure to the specifics of the particular tasks. Our method also improves\nneuron-wise compression of the model in most of the tasks.\n", "versions": [{"version": "v1", "created": "Wed, 13 Nov 2019 16:26:22 GMT"}], "update_date": "2019-11-14", "authors_parsed": [["Lobacheva", "Ekaterina", ""], ["Chirkova", "Nadezhda", ""], ["Markovich", "Alexander", ""], ["Vetrov", "Dmitry", ""]]}, {"id": "1911.05586", "submitter": "Quanshi Zhang", "authors": "Li Chen, Hailun Ding, Qi Li, Zhuo Li, Jian Peng, Haifeng Li", "title": "Understanding the Importance of Single Directions via Representative\n  Substitution", "comments": "In AAAI-19 Workshop on Network Interpretability for Deep Learning.\n  Published version of arXiv:1811.11053", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Understanding the internal representations of deep neural networks (DNNs) is\ncrucal to explain their behavior. The interpretation of individual units, which\nare neurons in MLPs or convolution kernels in convolutional networks, has been\npaid much attention given their fundamental role. However, recent research\n(Morcos et al. 2018) presented a counterintuitive phenomenon, which suggests\nthat an individual unit with high class selectivity, called interpretable\nunits, has poor contributions to generalization of DNNs. In this work, we\nprovide a new perspective to understand this counterintuitive phenomenon, which\nmakes sense when we introduce Representative Substitution (RS). Instead of\nindividually selective units with classes, the RS refers to the independence of\na unit's representations in the same layer without any annotation. Our\nexperiments demonstrate that interpretable units have high RS which are not\ncritical to network's generalization. The RS provides new insights into the\ninterpretation of DNNs and suggests that we need to focus on the independence\nand relationship of the representations.\n", "versions": [{"version": "v1", "created": "Sun, 20 Jan 2019 18:49:17 GMT"}], "update_date": "2019-11-14", "authors_parsed": [["Chen", "Li", ""], ["Ding", "Hailun", ""], ["Li", "Qi", ""], ["Li", "Zhuo", ""], ["Peng", "Jian", ""], ["Li", "Haifeng", ""]]}, {"id": "1911.05588", "submitter": "Quanshi Zhang", "authors": "A. Deliege, A. Cioppa and M. Van Droogenbroeck", "title": "An Effective Hit-or-Miss Layer Favoring Feature Interpretation as\n  Learned Prototypes Deformations", "comments": "In AAAI-19 Workshop on Network Interpretability for Deep Learning.\n  Published version of arXiv:1806.06519", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Neural networks designed for the task of classification have become a\ncommodity in recent years. Many works target the development of more effective\nnetworks, which results in a complexification of their architectures with more\nlayers, multiple sub-networks, or even the combination of multiple classifiers,\nbut this often comes at the expense of producing uninterpretable black boxes.\nIn this paper, we redesign a simple capsule network to enable it to synthesize\nclass-representative samples, called prototypes, by replacing the last layer\nwith a novel Hit-or-Miss layer. This layer contains activated vectors, called\ncapsules, that we train to hit or miss a fixed target capsule by tailoring a\nspecific centripetal loss function. This possibility allows to develop a data\naugmentation step combining information from the data space and the feature\nspace, resulting in a hybrid data augmentation process. We show that our\nnetwork, named HitNet, is able to reach better performances than those\nreproduced with the initial CapsNet on several datasets, while allowing to\nvisualize the nature of the features extracted as deformations of the\nprototypes, which provides a direct insight into the feature representation\nlearned by the network .\n", "versions": [{"version": "v1", "created": "Sat, 23 Feb 2019 01:28:27 GMT"}], "update_date": "2019-11-14", "authors_parsed": [["Deliege", "A.", ""], ["Cioppa", "A.", ""], ["Van Droogenbroeck", "M.", ""]]}, {"id": "1911.05589", "submitter": "Rohit Singh Mr", "authors": "Rohit Singh, Douglas Sicker, Kazi Mohammed Saidul Huq", "title": "MOTH- Mobility-induced Outages in THz: A Beyond 5G (B5G) application", "comments": "To appear in IEEE CCNC 2020. The document has 9 pages and 16 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  5G will enable the growing demand for Internet of Things (IoT),\nhigh-resolution video streaming, and low latency wireless services. Demand for\nsuch services is expected to growth rapid, which will require a search for\nBeyond 5G technological advancements in wireless communications. Part of these\nadvancements is the need for additional spectrum, namely moving toward the\nterahertz (THz) range. To compensate for the high path loss in THz, narrow\nbeamwidths are used to improve antenna gains. However, with narrow beamwidths,\neven minor fluctuations in device location (such as through body movement) can\ncause frequent link failures due to beam misalignment. In this paper, we\nprovide a solution to these small-scale indoor movement that result in\nmobility-induced outages. Like a moth randomly flutters about, Mobility-induced\nOutages in THz (MOTH) can be ephemeral in nature and hard to avoid. To deal\nwith MOTH we propose two methods to predict these outage scenarios: (i)\nAlign-After-Failure (AAF), which predicts based on fixed time margins, and (ii)\nAlign-Before-Failure (ABF), which learns the time margins through user mobility\npatterns. In this paper, two different online classifiers were used to train\nthe ABF model to predicate if a mobility-induced outage is going to occur;\nthereby, significantly reducing the time spent in outage scenarios. Simulation\nresults demonstrate a relationship between optimal beamwidth and human mobility\npatterns. Additionally, to cater to a future with dense deployment of Wireless\nPersonal Area Network (WPAN), it is necessary that we have efficient deployment\nof resources (e.g., THz-APs). One solution is to maximize the user coverage for\na single AP, which might be dependent on multiple parameters. We identify these\nparameters and observe their tradeoffs for improving user coverage through a\nsingle THz-AP.\n", "versions": [{"version": "v1", "created": "Wed, 13 Nov 2019 16:30:51 GMT"}, {"version": "v2", "created": "Tue, 19 Nov 2019 21:18:32 GMT"}], "update_date": "2019-11-21", "authors_parsed": [["Singh", "Rohit", ""], ["Sicker", "Douglas", ""], ["Huq", "Kazi Mohammed Saidul", ""]]}, {"id": "1911.05594", "submitter": "Andreas R\\\"uckl\\'e", "authors": "Andreas R\\\"uckl\\'e, Nafise Sadat Moosavi, Iryna Gurevych", "title": "Neural Duplicate Question Detection without Labeled Training Data", "comments": "Accepted as long paper at EMNLP-2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Supervised training of neural models to duplicate question detection in\ncommunity Question Answering (cQA) requires large amounts of labeled question\npairs, which are costly to obtain. To minimize this cost, recent works thus\noften used alternative methods, e.g., adversarial domain adaptation. In this\nwork, we propose two novel methods: (1) the automatic generation of duplicate\nquestions, and (2) weak supervision using the title and body of a question. We\nshow that both can achieve improved performances even though they do not\nrequire any labeled data. We provide comprehensive comparisons of popular\ntraining strategies, which provides important insights on how to best train\nmodels in different scenarios. We show that our proposed approaches are more\neffective in many cases because they can utilize larger amounts of unlabeled\ndata from cQA forums. Finally, we also show that our proposed approach for weak\nsupervision with question title and body information is also an effective\nmethod to train cQA answer selection models without direct answer supervision.\n", "versions": [{"version": "v1", "created": "Wed, 13 Nov 2019 16:38:30 GMT"}, {"version": "v2", "created": "Sat, 19 Sep 2020 10:51:46 GMT"}], "update_date": "2020-09-22", "authors_parsed": [["R\u00fcckl\u00e9", "Andreas", ""], ["Moosavi", "Nafise Sadat", ""], ["Gurevych", "Iryna", ""]]}, {"id": "1911.05611", "submitter": "Junjiao Tian", "authors": "Junjiao Tian, Wesley Cheung, Nathan Glaser, Yen-Cheng Liu, Zsolt Kira", "title": "UNO: Uncertainty-aware Noisy-Or Multimodal Fusion for Unanticipated\n  Input Degradation", "comments": "IEEE International Conference on Robotics and Automation (ICRA),\n  2020. IROS Workshop on the Importance of Uncertainty in Deep Learning for\n  Robotics, 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG cs.RO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The fusion of multiple sensor modalities, especially through deep learning\narchitectures, has been an active area of study. However, an under-explored\naspect of such work is whether the methods can be robust to degradations across\ntheir input modalities, especially when they must generalize to degradations\nnot seen during training. In this work, we propose an uncertainty-aware fusion\nscheme to effectively fuse inputs that might suffer from a range of known and\nunknown degradations. Specifically, we analyze a number of uncertainty\nmeasures, each of which captures a different aspect of uncertainty, and we\npropose a novel way to fuse degraded inputs by scaling modality-specific output\nsoftmax probabilities. We additionally propose a novel data-dependent spatial\ntemperature scaling method to complement these existing uncertainty measures.\nFinally, we integrate the uncertainty-scaled output from each modality using a\nprobabilistic noisy-or fusion method. In a photo-realistic simulation\nenvironment (AirSim), we show that our method achieves significantly better\nresults on a semantic segmentation task, compared to state-of-art fusion\narchitectures, on a range of degradations (e.g. fog, snow, frost, and various\nother types of noise), some of which are unknown during training. We\nspecifically improve upon the state-of-art[1] by 28% in mean IoU on various\ndegradations. [1] Abhinav Valada, Rohit Mohan, and Wolfram Burgard.\nSelf-Supervised Model Adaptation for Multimodal Semantic Segmentation. In:\narXiv e-prints, arXiv:1808.03833 (Aug. 2018), arXiv:1808.03833. arXiv:\n1808.03833 [cs.CV].\n", "versions": [{"version": "v1", "created": "Wed, 6 Nov 2019 09:42:04 GMT"}, {"version": "v2", "created": "Wed, 4 Mar 2020 03:39:54 GMT"}], "update_date": "2020-03-05", "authors_parsed": [["Tian", "Junjiao", ""], ["Cheung", "Wesley", ""], ["Glaser", "Nathan", ""], ["Liu", "Yen-Cheng", ""], ["Kira", "Zsolt", ""]]}, {"id": "1911.05620", "submitter": "Weiguan Wang", "authors": "Johannes Ruf, Weiguan Wang", "title": "Neural networks for option pricing and hedging: a literature review", "comments": "Minor changes. Accepted for publications in Journal of Computational\n  Finance", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-fin.CP cs.LG q-fin.RM q-fin.ST stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Neural networks have been used as a nonparametric method for option pricing\nand hedging since the early 1990s. Far over a hundred papers have been\npublished on this topic. This note intends to provide a comprehensive review.\nPapers are compared in terms of input features, output variables, benchmark\nmodels, performance measures, data partition methods, and underlying assets.\nFurthermore, related work and regularisation techniques are discussed.\n", "versions": [{"version": "v1", "created": "Wed, 13 Nov 2019 17:01:36 GMT"}, {"version": "v2", "created": "Sat, 9 May 2020 12:45:34 GMT"}], "update_date": "2020-05-12", "authors_parsed": [["Ruf", "Johannes", ""], ["Wang", "Weiguan", ""]]}, {"id": "1911.05625", "submitter": "Umit Kacar", "authors": "Cihan Akin, Umit Kacar, and Murvet Kirci", "title": "Twins Recognition Using Hierarchical Score Level Fusion", "comments": "4 pages, 5 figures, 1 table", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG eess.SP", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  With the development of technology, the usage areas and importance of\nbiometric systems have started to increase. Since the characteristics of each\nperson are different from each other, a single model biometric system can yield\nsuccessful results. However, because the characteristics of twin people are\nvery close to each other, multiple biometric systems including multiple\ncharacteristics of individuals will be more appropriate and will increase the\nrecognition rate. In this study, a multiple biometric recognition system\nconsisting of a combination of multiple algorithms and multiple models was\ndeveloped to distinguish people from other people and their twins. Ear and\nvoice biometric data were used for the multimodal model and 38 pair of twin ear\nimages and sound recordings were used in the data set. Sound and ear\nrecognition rates were obtained using classical (hand-crafted) and deep\nlearning algorithms. The results obtained were combined with the hierarchical\nscore level fusion method to achieve a success rate of 94.74% in rank-1 and\n100% in rank -2.\n", "versions": [{"version": "v1", "created": "Sun, 27 Oct 2019 11:33:16 GMT"}], "update_date": "2019-11-14", "authors_parsed": [["Akin", "Cihan", ""], ["Kacar", "Umit", ""], ["Kirci", "Murvet", ""]]}, {"id": "1911.05627", "submitter": "Prashnna Gyawali", "authors": "Prashnna K Gyawali, Rudra Saha, Linwei Wang, VSR Veeravasarapu and\n  Maneesh Singh", "title": "Wavelets to the Rescue: Improving Sample Quality of Latent Variable Deep\n  Generative Models", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG eess.IV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Variational Autoencoders (VAE) are probabilistic deep generative models\nunderpinned by elegant theory, stable training processes, and meaningful\nmanifold representations. However, they produce blurry images due to a lack of\nexplicit emphasis over high-frequency textural details of the images, and the\ndifficulty to directly model the complex joint probability distribution over\nthe high-dimensional image space. In this work, we approach these two\nchallenges with a novel wavelet space VAE that uses the decoder to model the\nimages in the wavelet coefficient space. This enables the VAE to emphasize over\nhigh-frequency components within an image obtained via wavelet decomposition.\nAdditionally, by decomposing the complex function of generating\nhigh-dimensional images into inverse wavelet transformation and generation of\nwavelet coefficients, the latter becomes simpler to model by the VAE. We\nempirically validate that deep generative models operating in the wavelet space\ncan generate images of higher quality than the image (RGB) space counterparts.\nQuantitatively, on benchmark natural image datasets, we achieve consistently\nbetter FID scores than VAE based architectures and competitive FID scores with\na variety of GAN models for the same architectural and experimental setup.\nFurthermore, the proposed wavelet-based generative model retains desirable\nattributes like disentangled and informative latent representation without\nlosing the quality in the generated samples.\n", "versions": [{"version": "v1", "created": "Sat, 26 Oct 2019 15:16:05 GMT"}], "update_date": "2019-11-15", "authors_parsed": [["Gyawali", "Prashnna K", ""], ["Saha", "Rudra", ""], ["Wang", "Linwei", ""], ["Veeravasarapu", "VSR", ""], ["Singh", "Maneesh", ""]]}, {"id": "1911.05628", "submitter": "Adam Kashlak", "authors": "Milad Kiaee, Adam B Kashlak, Jisu Kim, Giseon Heo", "title": "Diagnosis of Pediatric Obstructive Sleep Apnea via Face Classification\n  with Persistent Homology and Convolutional Neural Networks", "comments": "23 pages, 9 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Obstructive sleep apnea is a serious condition causing a litany of health\nproblems especially in the pediatric population. However, this chronic\ncondition can be treated if diagnosis is possible. The gold standard for\ndiagnosis is an overnight sleep study, which is often unobtainable by many\npotentially suffering from this condition. Hence, we attempt to develop a fast\nnon-invasive diagnostic tool by training a classifier on 2D and 3D facial\nimages of a patient to recognize facial features associated with obstructive\nsleep apnea. In this comparative study, we consider both persistent homology\nand geometric shape analysis from the field of computational topology as well\nas convolutional neural networks, a powerful method from deep learning whose\nsuccess in image and specifically facial recognition has already been\ndemonstrated by computer scientists.\n", "versions": [{"version": "v1", "created": "Sat, 26 Oct 2019 03:43:44 GMT"}], "update_date": "2019-11-14", "authors_parsed": [["Kiaee", "Milad", ""], ["Kashlak", "Adam B", ""], ["Kim", "Jisu", ""], ["Heo", "Giseon", ""]]}, {"id": "1911.05630", "submitter": "Lucas C. Uzal", "authors": "Marcos Pividori and Guillermo L. Grinblat and Lucas C. Uzal", "title": "Exploiting GAN Internal Capacity for High-Quality Reconstruction of\n  Natural Images", "comments": "This preprint is the result of the work done for the undergraduate\n  dissertation of M. Pividori supervised by L.C. Uzal and G.L. Grinblat, and\n  presented in July 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Generative Adversarial Networks (GAN) have demonstrated impressive results in\nmodeling the distribution of natural images, learning latent representations\nthat capture semantic variations in an unsupervised basis. Beyond the\ngeneration of novel samples, it is of special interest to exploit the ability\nof the GAN generator to model the natural image manifold and hence generate\ncredible changes when manipulating images. However, this line of work is\nconditioned by the quality of the reconstruction. Until now, only inversion to\nthe latent space has been considered, we propose to exploit the representation\nin intermediate layers of the generator, and we show that this leads to\nincreased capacity. In particular, we observe that the representation after the\nfirst dense layer, present in all state-of-the-art GAN models, is expressive\nenough to represent natural images with high visual fidelity. It is possible to\ninterpolate around these images obtaining a sequence of new plausible synthetic\nimages that cannot be generated from the latent space. Finally, as an example\nof potential applications that arise from this inversion mechanism, we show\npreliminary results in exploiting the learned representation in the attention\nmap of the generator to obtain an unsupervised segmentation of natural images.\n", "versions": [{"version": "v1", "created": "Sat, 26 Oct 2019 22:07:24 GMT"}], "update_date": "2019-11-14", "authors_parsed": [["Pividori", "Marcos", ""], ["Grinblat", "Guillermo L.", ""], ["Uzal", "Lucas C.", ""]]}, {"id": "1911.05640", "submitter": "F{\\i}rat Tuna", "authors": "Firat Tuna", "title": "Neural Network Processing Neural Networks: An efficient way to learn\n  higher order functions", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Functions are rich in meaning and can be interpreted in a variety of ways.\nNeural networks were proven to be capable of approximating a large class of\nfunctions[1]. In this paper, we propose a new class of neural networks called\n\"Neural Network Processing Neural Networks\" (NNPNNs), which inputs neural\nnetworks and numerical values, instead of just numerical values. Thus enabling\nneural networks to represent and process rich structures.\n", "versions": [{"version": "v1", "created": "Wed, 6 Nov 2019 19:15:34 GMT"}, {"version": "v2", "created": "Tue, 14 Jan 2020 23:11:27 GMT"}], "update_date": "2020-01-16", "authors_parsed": [["Tuna", "Firat", ""]]}, {"id": "1911.05647", "submitter": "Ishanu Chattopadhyay", "authors": "Timmy Li, Yi Huang, James Evans and Ishanu Chattopadhyay", "title": "Long-range Event-level Prediction and Response Simulation for Urban\n  Crime and Global Terrorism with Granger Networks", "comments": "16 pages, 5 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.AP cs.LG cs.SI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Large-scale trends in urban crime and global terrorism are well-predicted by\nsocio-economic drivers, but focused, event-level predictions have had limited\nsuccess. Standard machine learning approaches are promising, but lack\ninterpretability, are generally interpolative, and ineffective for precise\nfuture interventions with costly and wasteful false positives. Here, we are\nintroducing Granger Network inference as a new forecasting approach for\nindividual infractions with demonstrated performance far surpassing past\nresults, yet transparent enough to validate and extend social theory.\nConsidering the problem of predicting crime in the City of Chicago, we achieve\nan average AUC of ~90\\% for events predicted a week in advance within spatial\ntiles approximately $1000$ ft across. Instead of pre-supposing that crimes\nunfold across contiguous spaces akin to diffusive systems, we learn the local\ntransport rules from data. As our key insights, we uncover indications of\nsuburban bias -- how law-enforcement response is modulated by socio-economic\ncontexts with disproportionately negative impacts in the inner city -- and how\nthe dynamics of violent and property crimes co-evolve and constrain each other\n-- lending quantitative support to controversial pro-active policing policies.\nTo demonstrate broad applicability to spatio-temporal phenomena, we analyze\nterror attacks in the middle-east in the recent past, and achieve an AUC of\n~80% for predictions made a week in advance, and within spatial tiles measuring\napproximately 120 miles across. We conclude that while crime operates near an\nequilibrium quickly dissipating perturbations, terrorism does not. Indeed\nterrorism aims to destabilize social order, as shown by its dynamics being\nsusceptible to run-away increases in event rates under small perturbations.\n", "versions": [{"version": "v1", "created": "Mon, 4 Nov 2019 15:41:50 GMT"}], "update_date": "2019-11-14", "authors_parsed": [["Li", "Timmy", ""], ["Huang", "Yi", ""], ["Evans", "James", ""], ["Chattopadhyay", "Ishanu", ""]]}, {"id": "1911.05652", "submitter": "Petr Plechac", "authors": "Petr Plech\\'a\\v{c}", "title": "Relative contributions of Shakespeare and Fletcher in Henry VIII: An\n  Analysis Based on Most Frequent Words and Most Frequent Rhythmic Patterns", "comments": null, "journal-ref": null, "doi": "10.1093/llc/fqaa032", "report-no": null, "categories": "cs.CL cs.LG stat.AP stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The versified play Henry VIII is nowadays widely recognized to be a\ncollaborative work not written solely by William Shakespeare. We employ\ncombined analysis of vocabulary and versification together with machine\nlearning techniques to determine which authors also took part in the writing of\nthe play and what were their relative contributions. Unlike most previous\nstudies, we go beyond the attribution of particular scenes and use the rolling\nattribution approach to determine the probabilities of authorship of pieces of\ntexts, without respecting the scene boundaries. Our results highly support the\ncanonical division of the play between William Shakespeare and John Fletcher\nproposed by James Spedding, but also bring new evidence supporting the\nmodifications proposed later by Thomas Merriam.\n", "versions": [{"version": "v1", "created": "Wed, 30 Oct 2019 22:40:05 GMT"}], "update_date": "2020-06-30", "authors_parsed": [["Plech\u00e1\u010d", "Petr", ""]]}, {"id": "1911.05659", "submitter": "Trisha Mittal", "authors": "Trisha Mittal, Uttaran Bhattacharya, Rohan Chandra, Aniket Bera,\n  Dinesh Manocha", "title": "M3ER: Multiplicative Multimodal Emotion Recognition Using Facial,\n  Textual, and Speech Cues", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.SP cs.CL cs.LG eess.AS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present M3ER, a learning-based method for emotion recognition from\nmultiple input modalities. Our approach combines cues from multiple\nco-occurring modalities (such as face, text, and speech) and also is more\nrobust than other methods to sensor noise in any of the individual modalities.\nM3ER models a novel, data-driven multiplicative fusion method to combine the\nmodalities, which learn to emphasize the more reliable cues and suppress others\non a per-sample basis. By introducing a check step which uses Canonical\nCorrelational Analysis to differentiate between ineffective and effective\nmodalities, M3ER is robust to sensor noise. M3ER also generates proxy features\nin place of the ineffectual modalities. We demonstrate the efficiency of our\nnetwork through experimentation on two benchmark datasets, IEMOCAP and\nCMU-MOSEI. We report a mean accuracy of 82.7% on IEMOCAP and 89.0% on\nCMU-MOSEI, which, collectively, is an improvement of about 5% over prior work.\n", "versions": [{"version": "v1", "created": "Sat, 9 Nov 2019 01:58:03 GMT"}, {"version": "v2", "created": "Fri, 22 Nov 2019 18:48:47 GMT"}], "update_date": "2019-11-25", "authors_parsed": [["Mittal", "Trisha", ""], ["Bhattacharya", "Uttaran", ""], ["Chandra", "Rohan", ""], ["Bera", "Aniket", ""], ["Manocha", "Dinesh", ""]]}, {"id": "1911.05663", "submitter": "Rohan Gala", "authors": "Rohan Gala, Nathan Gouwens, Zizhen Yao, Agata Budzillo, Osnat Penn,\n  Bosiljka Tasic, Gabe Murphy, Hongkui Zeng, Uygar S\\\"umb\\\"ul", "title": "A coupled autoencoder approach for multi-modal analysis of cell types", "comments": "Main text : 10 pages, 5 figures. Supp text : 6 pages, 3 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.NC cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent developments in high throughput profiling of individual neurons have\nspurred data driven exploration of the idea that there exist natural groupings\nof neurons referred to as cell types. The promise of this idea is that the\nimmense complexity of brain circuits can be reduced, and effectively studied by\nmeans of interactions between cell types. While clustering of neuron\npopulations based on a particular data modality can be used to define cell\ntypes, such definitions are often inconsistent across different\ncharacterization modalities. We pose this issue of cross-modal alignment as an\noptimization problem and develop an approach based on coupled training of\nautoencoders as a framework for such analyses. We apply this framework to a\nPatch-seq dataset consisting of transcriptomic and electrophysiological\nprofiles for the same set of neurons to study consistency of representations\nacross modalities, and evaluate cross-modal data prediction ability. We explore\nthe problem where only a subset of neurons is characterized with more than one\nmodality, and demonstrate that representations learned by coupled autoencoders\ncan be used to identify types sampled only by a single modality.\n", "versions": [{"version": "v1", "created": "Wed, 6 Nov 2019 00:58:02 GMT"}], "update_date": "2019-11-14", "authors_parsed": [["Gala", "Rohan", ""], ["Gouwens", "Nathan", ""], ["Yao", "Zizhen", ""], ["Budzillo", "Agata", ""], ["Penn", "Osnat", ""], ["Tasic", "Bosiljka", ""], ["Murphy", "Gabe", ""], ["Zeng", "Hongkui", ""], ["S\u00fcmb\u00fcl", "Uygar", ""]]}, {"id": "1911.05683", "submitter": "Leon Gatys", "authors": "Jonas Rauber, Emily B. Fox, Leon A. Gatys", "title": "Modeling patterns of smartphone usage and their relationship to\n  cognitive health", "comments": "Machine Learning for Health (ML4H) at NeurIPS 2019 - Extended\n  Abstract", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.HC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The ubiquity of smartphone usage in many people's lives make it a rich source\nof information about a person's mental and cognitive state. In this work we\nanalyze 12 weeks of phone usage data from 113 older adults, 31 with diagnosed\ncognitive impairment and 82 without. We develop structured models of users'\nsmartphone interactions to reveal differences in phone usage patterns between\npeople with and without cognitive impairment. In particular, we focus on\ninferring specific types of phone usage sessions that are predictive of\ncognitive impairment. Our model achieves an AUROC of 0.79 when discriminating\nbetween healthy and symptomatic subjects, and its interpretability enables\nnovel insights into which aspects of phone usage strongly relate with cognitive\nhealth in our dataset.\n", "versions": [{"version": "v1", "created": "Wed, 13 Nov 2019 18:04:18 GMT"}], "update_date": "2019-11-14", "authors_parsed": [["Rauber", "Jonas", ""], ["Fox", "Emily B.", ""], ["Gatys", "Leon A.", ""]]}, {"id": "1911.05695", "submitter": "Xinwen Hou", "authors": "Pei Yingjun, Hou Xinwen", "title": "Learning Representations in Reinforcement Learning:An Information\n  Bottleneck Approach", "comments": "22 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The information bottleneck principle is an elegant and useful approach to\nrepresentation learning. In this paper, we investigate the problem of\nrepresentation learning in the context of reinforcement learning using the\ninformation bottleneck framework, aiming at improving the sample efficiency of\nthe learning algorithms. %by accelerating the process of discarding irrelevant\ninformation when the %input states are extremely high-dimensional. We\nanalytically derive the optimal conditional distribution of the representation,\nand provide a variational lower bound. Then, we maximize this lower bound with\nthe Stein variational (SV) gradient method. We incorporate this framework in\nthe advantageous actor critic algorithm (A2C) and the proximal policy\noptimization algorithm (PPO). Our experimental results show that our framework\ncan improve the sample efficiency of vanilla A2C and PPO significantly.\nFinally, we study the information bottleneck (IB) perspective in deep RL with\nthe algorithm called mutual information neural estimation(MINE) . We\nexperimentally verify that the information extraction-compression process also\nexists in deep RL and our framework is capable of accelerating this process. We\nalso analyze the relationship between MINE and our method, through this\nrelationship, we theoretically derive an algorithm to optimize our IB framework\nwithout constructing the lower bound.\n", "versions": [{"version": "v1", "created": "Tue, 12 Nov 2019 02:51:55 GMT"}], "update_date": "2019-11-14", "authors_parsed": [["Yingjun", "Pei", ""], ["Xinwen", "Hou", ""]]}, {"id": "1911.05696", "submitter": "Adrien Hadj-Salah", "authors": "Adrien Hadj-Salah, R\\'emi Verdier, Cl\\'ement Caron, Mathieu Picard,\n  Mika\\\"el Capelle", "title": "Schedule Earth Observation satellites with Deep Reinforcement Learning", "comments": null, "journal-ref": "IWPSS 2019, Jul 2019, Berkeley, United States", "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Optical Earth observation satellites acquire images worldwide , covering up\nto several million square kilometers every day. The complexity of scheduling\nacquisitions for such systems increases exponentially when considering the\ninteroperabil-ity of several satellite constellations together with the\nuncertainties from weather forecasts. In order to deliver valid images to\ncustomers as fast as possible, it is crucial to acquire cloud-free images.\nDepending on weather forecasts, up to 50% of images acquired by operational\nsatellites can be trashed due to excessive cloud covers, showing there is room\nfor improvement. We propose an acquisition scheduling approach based on Deep\nReinforcement Learning and experiment on a simplified environment. We find that\nit challenges classical methods relying on human-expert heuristic.\n", "versions": [{"version": "v1", "created": "Tue, 12 Nov 2019 15:28:34 GMT"}], "update_date": "2019-11-14", "authors_parsed": [["Hadj-Salah", "Adrien", ""], ["Verdier", "R\u00e9mi", ""], ["Caron", "Cl\u00e9ment", ""], ["Picard", "Mathieu", ""], ["Capelle", "Mika\u00ebl", ""]]}, {"id": "1911.05697", "submitter": "Kamanchi Chandramouli", "authors": "Raghuram Bharadwaj Diddigi, Chandramouli Kamanchi, Shalabh Bhatnagar", "title": "A Convergent Off-Policy Temporal Difference Algorithm", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Learning the value function of a given policy (target policy) from the data\nsamples obtained from a different policy (behavior policy) is an important\nproblem in Reinforcement Learning (RL). This problem is studied under the\nsetting of off-policy prediction. Temporal Difference (TD) learning algorithms\nare a popular class of algorithms for solving the prediction problem. TD\nalgorithms with linear function approximation are shown to be convergent when\nthe samples are generated from the target policy (known as on-policy\nprediction). However, it has been well established in the literature that\noff-policy TD algorithms under linear function approximation diverge. In this\nwork, we propose a convergent on-line off-policy TD algorithm under linear\nfunction approximation. The main idea is to penalize the updates of the\nalgorithm in a way as to ensure convergence of the iterates. We provide a\nconvergence analysis of our algorithm. Through numerical evaluations, we\nfurther demonstrate the effectiveness of our algorithm.\n", "versions": [{"version": "v1", "created": "Wed, 13 Nov 2019 18:17:38 GMT"}], "update_date": "2019-11-14", "authors_parsed": [["Diddigi", "Raghuram Bharadwaj", ""], ["Kamanchi", "Chandramouli", ""], ["Bhatnagar", "Shalabh", ""]]}, {"id": "1911.05698", "submitter": "Zichang Wang", "authors": "Zichang Wang, Haoran Li, Luchen Liu, Haoxian Wu and Ming Zhang", "title": "Predictive Multi-level Patient Representations from Electronic Health\n  Records", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The advent of the Internet era has led to an explosive growth in the\nElectronic Health Records (EHR) in the past decades. The EHR data can be\nregarded as a collection of clinical events, including laboratory results,\nmedication records, physiological indicators, etc, which can be used for\nclinical outcome prediction tasks to support constructions of intelligent\nhealth systems. Learning patient representation from these clinical events for\nthe clinical outcome prediction is an important but challenging step. Most\nrelated studies transform EHR data of a patient into a sequence of clinical\nevents in temporal order and then use sequential models to learn patient\nrepresentations for outcome prediction. However, clinical event sequence\ncontains thousands of event types and temporal dependencies. We further make an\nobservation that clinical events occurring in a short period are not\nconstrained by any temporal order but events in a long term are influenced by\ntemporal dependencies. The multi-scale temporal property makes it difficult for\ntraditional sequential models to capture the short-term co-occurrence and the\nlong-term temporal dependencies in clinical event sequences. In response to the\nabove challenges, this paper proposes a Multi-level Representation Model (MRM).\nMRM first uses a sparse attention mechanism to model the short-term\nco-occurrence, then uses interval-based event pooling to remove redundant\ninformation and reduce sequence length and finally predicts clinical outcomes\nthrough Long Short-Term Memory (LSTM). Experiments on real-world datasets\nindicate that our proposed model largely improves the performance of clinical\noutcome prediction tasks using EHR data.\n", "versions": [{"version": "v1", "created": "Tue, 12 Nov 2019 11:40:12 GMT"}], "update_date": "2019-11-14", "authors_parsed": [["Wang", "Zichang", ""], ["Li", "Haoran", ""], ["Liu", "Luchen", ""], ["Wu", "Haoxian", ""], ["Zhang", "Ming", ""]]}, {"id": "1911.05699", "submitter": "Fanyou Wu", "authors": "Yang Liu, Fanyou Wu, Baosheng Yu, Zhiyuan Liu, Jieping Ye", "title": "Building Effective Large-Scale Traffic State Prediction System:\n  Traffic4cast Challenge Solution", "comments": "6 pages, 2 figures, Traffic4cast", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  How to build an effective large-scale traffic state prediction system is a\nchallenging but highly valuable problem. This study focuses on the construction\nof an effective solution designed for spatio-temporal data to predict\nlarge-scale traffic state. Considering the large data size in Traffic4cast\nChallenge and our limited computational resources, we emphasize model design to\nachieve a relatively high prediction performance within acceptable running\ntime. We adopt a structure similar to U-net and use a mask instead of spatial\nattention to address the data sparsity. Then, combined with the experience of\ntime series prediction problem, we design a number of features, which are input\ninto the model as different channels. Region cropping is used to decrease the\ndifference between the size of the receptive field and the study area, and the\nmodels can be specially optimized for each sub-region. The fusion of\ninterdisciplinary knowledge and experience is an emerging demand in classical\ntraffic research. Several interdisciplinary studies we have been studying are\nalso discussed in the Complementary Challenges. The source codes are available\nin https://github.com/wufanyou/traffic4cast-TLab.\n", "versions": [{"version": "v1", "created": "Mon, 11 Nov 2019 15:48:09 GMT"}], "update_date": "2019-11-14", "authors_parsed": [["Liu", "Yang", ""], ["Wu", "Fanyou", ""], ["Yu", "Baosheng", ""], ["Liu", "Zhiyuan", ""], ["Ye", "Jieping", ""]]}, {"id": "1911.05700", "submitter": "Jiaqi Ma", "authors": "Jiaqi Ma, Qiaozhu Mei", "title": "Graph Representation Learning via Multi-task Knowledge Distillation", "comments": "NeurIPS 2019 GRL Workshop", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Machine learning on graph structured data has attracted much research\ninterest due to its ubiquity in real world data. However, how to efficiently\nrepresent graph data in a general way is still an open problem. Traditional\nmethods use handcraft graph features in a tabular form but suffer from the\ndefects of domain expertise requirement and information loss. Graph\nrepresentation learning overcomes these defects by automatically learning the\ncontinuous representations from graph structures, but they require abundant\ntraining labels, which are often hard to fulfill for graph-level prediction\nproblems. In this work, we demonstrate that, if available, the domain expertise\nused for designing handcraft graph features can improve the graph-level\nrepresentation learning when training labels are scarce. Specifically, we\nproposed a multi-task knowledge distillation method. By incorporating\nnetwork-theory-based graph metrics as auxiliary tasks, we show on both\nsynthetic and real datasets that the proposed multi-task learning method can\nimprove the prediction performance of the original learning task, especially\nwhen the training data size is small.\n", "versions": [{"version": "v1", "created": "Mon, 11 Nov 2019 03:42:13 GMT"}], "update_date": "2019-11-14", "authors_parsed": [["Ma", "Jiaqi", ""], ["Mei", "Qiaozhu", ""]]}, {"id": "1911.05701", "submitter": "Hankz Hankui Zhuo", "authors": "Junyi Shen, Hankz Hankui Zhuo, Jin Xu, Bin Zhong, Sinno Jialin Pan", "title": "Transfer Value Iteration Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Value iteration networks (VINs) have been demonstrated to have a good\ngeneralization ability for reinforcement learning tasks across similar domains.\nHowever, based on our experiments, a policy learned by VINs still fail to\ngeneralize well on the domain whose action space and feature space are not\nidentical to those in the domain where it is trained. In this paper, we propose\na transfer learning approach on top of VINs, termed Transfer VINs (TVINs), such\nthat a learned policy from a source domain can be generalized to a target\ndomain with only limited training data, even if the source domain and the\ntarget domain have domain-specific actions and features. We empirically verify\nthat our proposed TVINs outperform VINs when the source and the target domains\nhave similar but not identical action and feature spaces. Furthermore, we show\nthat the performance improvement is consistent across different environments,\nmaze sizes, dataset sizes as well as different values of hyperparameters such\nas number of iteration and kernel size.\n", "versions": [{"version": "v1", "created": "Mon, 11 Nov 2019 08:07:49 GMT"}, {"version": "v2", "created": "Wed, 27 Nov 2019 01:55:19 GMT"}], "update_date": "2019-11-28", "authors_parsed": [["Shen", "Junyi", ""], ["Zhuo", "Hankz Hankui", ""], ["Xu", "Jin", ""], ["Zhong", "Bin", ""], ["Pan", "Sinno Jialin", ""]]}, {"id": "1911.05702", "submitter": "Tong Wang", "authors": "Tong Wang and Fujie Jin and Yu Hu and Yuan Cheng", "title": "Early Predictions for Medical Crowdfunding: A Deep Learning Approach\n  Using Diverse Inputs", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Medical crowdfunding is a popular channel for people needing financial help\npaying medical bills to collect donations from large numbers of people.\nHowever, large heterogeneity exists in donations across cases, and fundraisers\nface significant uncertainty in whether their crowdfunding campaigns can meet\nfundraising goals. Therefore, it is important to provide early warnings for\nfundraisers if such a channel will eventually fail. In this study, we aim to\ndevelop novel algorithms to provide accurate and timely predictions of\nfundraising performance, to better inform fundraisers. In particular, we\npropose a new approach to combine time-series features and time-invariant\nfeatures in the deep learning model, to process diverse sources of input data.\nCompared with baseline models, our model achieves better accuracy and requires\na shorter observation window of the time-varying features from the campaign\nlaunch to provide robust predictions with high confidence. To extract\ninterpretable insights, we further conduct a multivariate time-series\nclustering analysis and identify four typical temporal donation patterns. This\ndemonstrates the heterogeneity in the features and how they relate to the\nfundraising outcome. The prediction model and the interpretable insights can be\napplied to assist fundraisers with better promoting their fundraising campaigns\nand can potentially help crowdfunding platforms to provide more timely feedback\nto all fundraisers. Our proposed framework is also generalizable to other\nfields where diverse structured and unstructured data are valuable for\npredictions.\n", "versions": [{"version": "v1", "created": "Sat, 9 Nov 2019 06:08:10 GMT"}], "update_date": "2019-11-25", "authors_parsed": [["Wang", "Tong", ""], ["Jin", "Fujie", ""], ["Hu", "Yu", ""], ["Cheng", "Yuan", ""]]}, {"id": "1911.05704", "submitter": "Sam Green", "authors": "Sam Green, Craig M. Vineyard, Ryan Helinski, \\c{C}etin Kaya Ko\\c{c}", "title": "RAPDARTS: Resource-Aware Progressive Differentiable Architecture Search", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Early neural network architectures were designed by so-called \"grad student\ndescent\". Since then, the field of Neural Architecture Search (NAS) has\ndeveloped with the goal of algorithmically designing architectures tailored for\na dataset of interest. Recently, gradient-based NAS approaches have been\ncreated to rapidly perform the search. Gradient-based approaches impose more\nstructure on the search, compared to alternative NAS methods, enabling faster\nsearch phase optimization. In the real-world, neural architecture performance\nis measured by more than just high accuracy. There is increasing need for\nefficient neural architectures, where resources such as model size or latency\nmust also be considered. Gradient-based NAS is also suitable for such\nmulti-objective optimization. In this work we extend a popular gradient-based\nNAS method to support one or more resource costs. We then perform in-depth\nanalysis on the discovery of architectures satisfying single-resource\nconstraints for classification of CIFAR-10.\n", "versions": [{"version": "v1", "created": "Fri, 8 Nov 2019 23:18:00 GMT"}], "update_date": "2019-11-14", "authors_parsed": [["Green", "Sam", ""], ["Vineyard", "Craig M.", ""], ["Helinski", "Ryan", ""], ["Ko\u00e7", "\u00c7etin Kaya", ""]]}, {"id": "1911.05712", "submitter": "Edoardo Manino", "authors": "Edoardo Manino, Long Tran-Thanh, Nicholas R. Jennings", "title": "Streaming Bayesian Inference for Crowdsourced Classification", "comments": "Accepted at the 33rd Conference on Neural Information Processing\n  Systems (NeurIPS 2019), Vancouver, Canada", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A key challenge in crowdsourcing is inferring the ground truth from noisy and\nunreliable data. To do so, existing approaches rely on collecting redundant\ninformation from the crowd, and aggregating it with some probabilistic method.\nHowever, oftentimes such methods are computationally inefficient, are\nrestricted to some specific settings, or lack theoretical guarantees. In this\npaper, we revisit the problem of binary classification from crowdsourced data.\nSpecifically we propose Streaming Bayesian Inference for Crowdsourcing (SBIC),\na new algorithm that does not suffer from any of these limitations. First, SBIC\nhas low complexity and can be used in a real-time online setting. Second, SBIC\nhas the same accuracy as the best state-of-the-art algorithms in all settings.\nThird, SBIC has provable asymptotic guarantees both in the online and offline\nsettings.\n", "versions": [{"version": "v1", "created": "Wed, 13 Nov 2019 18:41:08 GMT"}], "update_date": "2019-11-14", "authors_parsed": [["Manino", "Edoardo", ""], ["Tran-Thanh", "Long", ""], ["Jennings", "Nicholas R.", ""]]}, {"id": "1911.05718", "submitter": "Alessandro Corbetta", "authors": "Alessandro Corbetta, Vlado Menkovski, Roberto Benzi, Federico Toschi", "title": "Deep learning velocity signals allows to quantify turbulence intensity", "comments": null, "journal-ref": "Science Advances 7, eaba7281, 2021", "doi": "10.1126/sciadv.aba7281", "report-no": null, "categories": "physics.flu-dyn cond-mat.stat-mech cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Turbulence, the ubiquitous and chaotic state of fluid motions, is\ncharacterized by strong and statistically non-trivial fluctuations of the\nvelocity field, over a wide range of length- and time-scales, and it can be\nquantitatively described only in terms of statistical averages. Strong\nnon-stationarities hinder the possibility to achieve statistical convergence,\nmaking it impossible to define the turbulence intensity and, in particular, its\nbasic dimensionless estimator, the Reynolds number.\n  Here we show that by employing Deep Neural Networks (DNN) we can accurately\nestimate the Reynolds number within $15\\%$ accuracy, from a statistical sample\nas small as two large-scale eddy-turnover times. In contrast, physics-based\nstatistical estimators are limited by the rate of convergence of the central\nlimit theorem, and provide, for the same statistical sample, an error at least\n$100$ times larger. Our findings open up new perspectives in the possibility to\nquantitatively define and, therefore, study highly non-stationary turbulent\nflows as ordinarily found in nature as well as in industrial processes.\n", "versions": [{"version": "v1", "created": "Wed, 13 Nov 2019 18:49:56 GMT"}, {"version": "v2", "created": "Thu, 14 Nov 2019 07:37:49 GMT"}], "update_date": "2021-03-31", "authors_parsed": [["Corbetta", "Alessandro", ""], ["Menkovski", "Vlado", ""], ["Benzi", "Roberto", ""], ["Toschi", "Federico", ""]]}, {"id": "1911.05731", "submitter": "Beno\\^it Otjacques", "authors": "Beno\\^it Otjacques", "title": "Reporting on Decision-Making Algorithms and some Related Ethical\n  Questions", "comments": "62 pages, Final paper presented to obtain the University Certificate\n  in Business Ethics and Compliance Management, Louvain School of Management,\n  Belgium, December 2017", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Companies report on their financial performance for decades. More recently\nthey have also started to report on their environmental impact and their social\nresponsibility. The latest trend is now to deliver one single integrated report\nwhere all stakeholders of the company can easily connect all facets of the\nbusiness with their impact considered in a broad sense. The main purpose of\nthis integrated approach is to avoid delivering data related to disconnected\nsilos, which consequently makes it very difficult to globally assess the\noverall performance of an entity or a business line. In this paper, we focus on\nhow companies report on risks and ethical issues related to the increasing use\nof Artificial Intelligence (AI). We explain some of these risks and potential\nissues. Next, we identify some recent initiatives by various stakeholders to\ndefine a global ethical framework for AI. Finally, we illustrate with four\ncases that companies are very shy to report on these facets of AI.\n", "versions": [{"version": "v1", "created": "Mon, 4 Nov 2019 08:13:54 GMT"}], "update_date": "2019-11-14", "authors_parsed": [["Otjacques", "Beno\u00eet", ""]]}, {"id": "1911.05733", "submitter": "Shahan Ali Memon", "authors": "Hira Dhamyal, Shahan Ali Memon, Bhiksha Raj, Rita Singh", "title": "The phonetic bases of vocal expressed emotion: natural versus acted", "comments": "5 pages, 6 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.AS cs.CL cs.LG cs.SD", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Can vocal emotions be emulated? This question has been a recurrent concern of\nthe speech community, and has also been vigorously investigated. It has been\nfueled further by its link to the issue of validity of acted emotion databases.\nMuch of the speech and vocal emotion research has relied on acted emotion\ndatabases as valid proxies for studying natural emotions. To create models that\ngeneralize to natural settings, it is crucial to work with valid prototypes --\nones that can be assumed to reliably represent natural emotions. More\nconcretely, it is important to study emulated emotions against natural emotions\nin terms of their physiological, and psychological concomitants. In this paper,\nwe present an on-scale systematic study of the differences between natural and\nacted vocal emotions. We use a self-attention based emotion classification\nmodel to understand the phonetic bases of emotions by discovering the most\n'attended' phonemes for each class of emotions. We then compare these\nattended-phonemes in their importance and distribution across acted and natural\nclasses. Our tests show significant differences in the manner and choice of\nphonemes in acted and natural speech, concluding moderate to low validity and\nvalue in using acted speech databases for emotion classification tasks.\n", "versions": [{"version": "v1", "created": "Wed, 13 Nov 2019 03:44:08 GMT"}, {"version": "v2", "created": "Tue, 19 Nov 2019 20:49:50 GMT"}, {"version": "v3", "created": "Sat, 25 Jul 2020 02:49:50 GMT"}], "update_date": "2020-07-28", "authors_parsed": [["Dhamyal", "Hira", ""], ["Memon", "Shahan Ali", ""], ["Raj", "Bhiksha", ""], ["Singh", "Rita", ""]]}, {"id": "1911.05755", "submitter": "Nicholas Schmidt", "authors": "Nicholas Schmidt and Bryce Stephens", "title": "An Introduction to Artificial Intelligence and Solutions to the Problems\n  of Algorithmic Discrimination", "comments": "16 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.GL cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  There is substantial evidence that Artificial Intelligence (AI) and Machine\nLearning (ML) algorithms can generate bias against minorities, women, and other\nprotected classes. Federal and state laws have been enacted to protect\nconsumers from discrimination in credit, housing, and employment, where\nregulators and agencies are tasked with enforcing these laws. Additionally,\nthere are laws in place to ensure that consumers understand why they are denied\naccess to services and products, such as consumer loans. In this article, we\nprovide an overview of the potential benefits and risks associated with the use\nof algorithms and data, and focus specifically on fairness. While our\nobservations generalize to many contexts, we focus on the fairness concerns\nraised in consumer credit and the legal requirements of the Equal Credit and\nOpportunity Act. We propose a methodology for evaluating algorithmic fairness\nand minimizing algorithmic bias that aligns with the provisions of federal and\nstate anti-discrimination statutes that outlaw overt, disparate treatment, and,\nspecifically, disparate impact discrimination. We argue that while the use of\nAI and ML algorithms heighten potential discrimination risks, these risks can\nbe evaluated and mitigated, but doing so requires a deep understanding of these\nalgorithms and the contexts and domains in which they are being used.\n", "versions": [{"version": "v1", "created": "Fri, 8 Nov 2019 22:29:56 GMT"}], "update_date": "2019-11-15", "authors_parsed": [["Schmidt", "Nicholas", ""], ["Stephens", "Bryce", ""]]}, {"id": "1911.05771", "submitter": "Maede Zolanvari", "authors": "Maede Zolanvari, Marcio A. Teixeira, Lav Gupta, Khaled M. Khan, Raj\n  Jain", "title": "Machine Learning Based Network Vulnerability Analysis of Industrial\n  Internet of Things", "comments": null, "journal-ref": "in IEEE Internet of Things Journal, vol. 6, no. 4, pp. 6822-6834,\n  Aug. 2019", "doi": null, "report-no": null, "categories": "cs.CR cs.LG cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  It is critical to secure the Industrial Internet of Things (IIoT) devices\nbecause of potentially devastating consequences in case of an attack. Machine\nlearning and big data analytics are the two powerful leverages for analyzing\nand securing the Internet of Things (IoT) technology. By extension, these\ntechniques can help improve the security of the IIoT systems as well. In this\npaper, we first present common IIoT protocols and their associated\nvulnerabilities. Then, we run a cyber-vulnerability assessment and discuss the\nutilization of machine learning in countering these susceptibilities. Following\nthat, a literature review of the available intrusion detection solutions using\nmachine learning models is presented. Finally, we discuss our case study, which\nincludes details of a real-world testbed that we have built to conduct\ncyber-attacks and to design an intrusion detection system (IDS). We deploy\nbackdoor, command injection, and Structured Query Language (SQL) injection\nattacks against the system and demonstrate how a machine learning based anomaly\ndetection system can perform well in detecting these attacks. We have evaluated\nthe performance through representative metrics to have a fair point of view on\nthe effectiveness of the methods.\n", "versions": [{"version": "v1", "created": "Wed, 13 Nov 2019 19:25:53 GMT"}], "update_date": "2019-11-15", "authors_parsed": [["Zolanvari", "Maede", ""], ["Teixeira", "Marcio A.", ""], ["Gupta", "Lav", ""], ["Khan", "Khaled M.", ""], ["Jain", "Raj", ""]]}, {"id": "1911.05774", "submitter": "Jicong Fan", "authors": "Jicong Fan, Lijun Ding, Yudong Chen, and Madeleine Udell", "title": "Factor Group-Sparse Regularization for Efficient Low-Rank Matrix\n  Recovery", "comments": "Accepted by NeurIPS 2019. The supplementary material is at\n  https://github.com/jicongfan/Supplementary-material-of-conference-papers", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper develops a new class of nonconvex regularizers for low-rank matrix\nrecovery. Many regularizers are motivated as convex relaxations of the matrix\nrank function. Our new factor group-sparse regularizers are motivated as a\nrelaxation of the number of nonzero columns in a factorization of the matrix.\nThese nonconvex regularizers are sharper than the nuclear norm; indeed, we show\nthey are related to Schatten-$p$ norms with arbitrarily small $0 < p \\leq 1$.\nMoreover, these factor group-sparse regularizers can be written in a factored\nform that enables efficient and effective nonconvex optimization; notably, the\nmethod does not use singular value decomposition. We provide generalization\nerror bounds for low-rank matrix completion which show improved upper bounds\nfor Schatten-$p$ norm reglarization as $p$ decreases. Compared to the max norm\nand the factored formulation of the nuclear norm, factor group-sparse\nregularizers are more efficient, accurate, and robust to the initial guess of\nrank. Experiments show promising performance of factor group-sparse\nregularization for low-rank matrix completion and robust principal component\nanalysis.\n", "versions": [{"version": "v1", "created": "Wed, 13 Nov 2019 19:30:35 GMT"}, {"version": "v2", "created": "Mon, 18 Nov 2019 16:30:50 GMT"}], "update_date": "2019-11-19", "authors_parsed": [["Fan", "Jicong", ""], ["Ding", "Lijun", ""], ["Chen", "Yudong", ""], ["Udell", "Madeleine", ""]]}, {"id": "1911.05781", "submitter": "Jonathan Baxter", "authors": "Jonathan Baxter", "title": "Learning Internal Representations (COLT 1995)", "comments": null, "journal-ref": "COLT '95 Proceedings of the eighth annual conference on\n  Computational learning theory (1995) 311-320", "doi": "10.1145/225298.225336", "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Probably the most important problem in machine learning is the preliminary\nbiasing of a learner's hypothesis space so that it is small enough to ensure\ngood generalisation from reasonable training sets, yet large enough that it\ncontains a good solution to the problem being learnt. In this paper a mechanism\nfor {\\em automatically} learning or biasing the learner's hypothesis space is\nintroduced. It works by first learning an appropriate {\\em internal\nrepresentation} for a learning environment and then using that representation\nto bias the learner's hypothesis space for the learning of future tasks drawn\nfrom the same environment.\n  An internal representation must be learnt by sampling from {\\em many similar\ntasks}, not just a single task as occurs in ordinary machine learning. It is\nproved that the number of examples $m$ {\\em per task} required to ensure good\ngeneralisation from a representation learner obeys $m = O(a+b/n)$ where $n$ is\nthe number of tasks being learnt and $a$ and $b$ are constants. If the tasks\nare learnt independently ({\\em i.e.} without a common representation) then\n$m=O(a+b)$. It is argued that for learning environments such as speech and\ncharacter recognition $b\\gg a$ and hence representation learning in these\nenvironments can potentially yield a drastic reduction in the number of\nexamples required per task. It is also proved that if $n = O(b)$ (with\n$m=O(a+b/n)$) then the representation learnt will be good for learning novel\ntasks from the same environment, and that the number of examples required to\ngeneralise well on a novel task will be reduced to $O(a)$ (as opposed to\n$O(a+b)$ if no representation is used).\n  It is shown that gradient descent can be used to train neural network\nrepresentations and experiment results are reported providing strong\nqualitative support for the theoretical results.\n", "versions": [{"version": "v1", "created": "Wed, 13 Nov 2019 19:48:11 GMT"}, {"version": "v2", "created": "Wed, 20 Nov 2019 00:53:48 GMT"}, {"version": "v3", "created": "Thu, 19 Dec 2019 13:45:56 GMT"}], "update_date": "2019-12-20", "authors_parsed": [["Baxter", "Jonathan", ""]]}, {"id": "1911.05797", "submitter": "Cristiano Fanelli", "authors": "E. Cisbani, A. Del Dotto, C.Fanelli, M. Williams, M. Alfred, F.\n  Barbosa, L. Barion, V. Berdnikov, W. Brooks, T. Cao, M. Contalbrigo, S.\n  Danagoulian, A. Datta, M. Demarteau, A. Denisov, M. Diefenthaler, A. Durum,\n  D. Fields, Y. Furletova, C. Gleason, M. Grosse-Perdekamp, M. Hattawy, X. He,\n  H. van Hecke, D. Higinbotham, T. Horn, C. Hyde, Y. Ilieva, G. Kalicy, A.\n  Kebede, B. Kim, M. Liu, J. McKisson, R. Mendez, P. Nadel-Turonski, I. Pegg,\n  D. Romanov, M. Sarsour, C.L. da Silva, J. Stevens, X. Sun, S. Syed, R.\n  Towell, J. Xie, Z.W. Zhao, B. Zihlmann and C. Zorn", "title": "AI-optimized detector design for the future Electron-Ion Collider: the\n  dual-radiator RICH case", "comments": "22 pages, 11 figures", "journal-ref": "Journal of Instrumentation, Volume 15, May 2020", "doi": "10.1088/1748-0221/15/05/P05009", "report-no": "JLAB-PHY-20-3207", "categories": "physics.ins-det cs.LG hep-ex", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Advanced detector R&D requires performing computationally intensive and\ndetailed simulations as part of the detector-design optimization process. We\npropose a general approach to this process based on Bayesian optimization and\nmachine learning that encodes detector requirements. As a case study, we focus\non the design of the dual-radiator Ring Imaging Cherenkov (dRICH) detector\nunder development as part of the particle-identification system at the future\nElectron-Ion Collider (EIC). The EIC is a US-led frontier accelerator project\nfor nuclear physics, which has been proposed to further explore the structure\nand interactions of nuclear matter at the scale of sea quarks and gluons. We\nshow that the detector design obtained with our automated and highly\nparallelized framework outperforms the baseline dRICH design within the\nassumptions of the current model. Our approach can be applied to any detector\nR&D, provided that realistic simulations are available.\n", "versions": [{"version": "v1", "created": "Wed, 13 Nov 2019 20:12:49 GMT"}, {"version": "v2", "created": "Sat, 6 Jun 2020 23:24:06 GMT"}], "update_date": "2020-06-11", "authors_parsed": [["Cisbani", "E.", ""], ["Del Dotto", "A.", ""], ["Fanelli", "C.", ""], ["Williams", "M.", ""], ["Alfred", "M.", ""], ["Barbosa", "F.", ""], ["Barion", "L.", ""], ["Berdnikov", "V.", ""], ["Brooks", "W.", ""], ["Cao", "T.", ""], ["Contalbrigo", "M.", ""], ["Danagoulian", "S.", ""], ["Datta", "A.", ""], ["Demarteau", "M.", ""], ["Denisov", "A.", ""], ["Diefenthaler", "M.", ""], ["Durum", "A.", ""], ["Fields", "D.", ""], ["Furletova", "Y.", ""], ["Gleason", "C.", ""], ["Grosse-Perdekamp", "M.", ""], ["Hattawy", "M.", ""], ["He", "X.", ""], ["van Hecke", "H.", ""], ["Higinbotham", "D.", ""], ["Horn", "T.", ""], ["Hyde", "C.", ""], ["Ilieva", "Y.", ""], ["Kalicy", "G.", ""], ["Kebede", "A.", ""], ["Kim", "B.", ""], ["Liu", "M.", ""], ["McKisson", "J.", ""], ["Mendez", "R.", ""], ["Nadel-Turonski", "P.", ""], ["Pegg", "I.", ""], ["Romanov", "D.", ""], ["Sarsour", "M.", ""], ["da Silva", "C. L.", ""], ["Stevens", "J.", ""], ["Sun", "X.", ""], ["Syed", "S.", ""], ["Towell", "R.", ""], ["Xie", "J.", ""], ["Zhao", "Z. W.", ""], ["Zihlmann", "B.", ""], ["Zorn", "C.", ""]]}, {"id": "1911.05806", "submitter": "Yule Vaz", "authors": "Yule Vaz, Rodrigo Fernandes de Mello and Carlos Henrique Grossi", "title": "Coarse-Refinement Dilemma: On Generalization Bounds for Data Clustering", "comments": "52 pages (in which 5 pages contain references, 1 contains notation, 1\n  contains dictionary of terms, 2 contain proofs, 5 contain dataset images and\n  7 contain results)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The Data Clustering (DC) problem is of central importance for the area of\nMachine Learning (ML), given its usefulness to represent data structural\nsimilarities from input spaces. Differently from Supervised Machine Learning\n(SML), which relies on the theoretical frameworks of the Statistical Learning\nTheory (SLT) and the Algorithm Stability (AS), DC has scarce literature on\ngeneral-purpose learning guarantees, affecting conclusive remarks on how those\nalgorithms should be designed as well as on the validity of their results. In\nthis context, this manuscript introduces a new concept, based on\nmultidimensional persistent homology, to analyze the conditions on which a\nclustering model is capable of generalizing data. As a first step, we propose a\nmore general definition of DC problem by relying on Topological Spaces, instead\nof metric ones as typically approached in the literature. From that, we show\nthat the DC problem presents an analogous dilemma to the Bias-Variance one,\nwhich is here referred to as the Coarse-Refinement (CR) dilemma. CR is intended\nto clarify the contrast between: (i) highly-refined partitions and the\nclustering instability (overfitting); and (ii) over-coarse partitions and the\nlack of representativeness (underfitting); consequently, the CR dilemma\nsuggests the need of a relaxation of Kleinberg's richness axiom. Experimental\nresults were used to illustrate that multidimensional persistent homology\nsupport the measurement of divergences among DC models, leading to a\nconsistency criterion.\n", "versions": [{"version": "v1", "created": "Wed, 13 Nov 2019 20:42:17 GMT"}], "update_date": "2019-11-15", "authors_parsed": [["Vaz", "Yule", ""], ["de Mello", "Rodrigo Fernandes", ""], ["Grossi", "Carlos Henrique", ""]]}, {"id": "1911.05811", "submitter": "Anqi Liu", "authors": "Anqi Liu, Hao Liu, Anima Anandkumar, Yisong Yue", "title": "Triply Robust Off-Policy Evaluation", "comments": "Preliminary Work", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a robust regression approach to off-policy evaluation (OPE) for\ncontextual bandits. We frame OPE as a covariate-shift problem and leverage\nmodern robust regression tools. Ours is a general approach that can be used to\naugment any existing OPE method that utilizes the direct method. When\naugmenting doubly robust methods, we call the resulting method Triply Robust.\nWe prove upper bounds on the resulting bias and variance, as well as derive\nnovel minimax bounds based on robust minimax analysis for covariate shift. Our\nrobust regression method is compatible with deep learning, and is thus\napplicable to complex OPE settings that require powerful function\napproximators. Finally, we demonstrate superior empirical performance across\nthe standard OPE benchmarks, especially in the case where the logging policy is\nunknown and must be estimated from data.\n", "versions": [{"version": "v1", "created": "Wed, 13 Nov 2019 20:57:36 GMT"}, {"version": "v2", "created": "Sat, 16 Nov 2019 03:15:24 GMT"}], "update_date": "2019-11-19", "authors_parsed": [["Liu", "Anqi", ""], ["Liu", "Hao", ""], ["Anandkumar", "Anima", ""], ["Yue", "Yisong", ""]]}, {"id": "1911.05815", "submitter": "Dipendra Misra", "authors": "Dipendra Misra, Mikael Henaff, Akshay Krishnamurthy and John Langford", "title": "Kinematic State Abstraction and Provably Efficient Rich-Observation\n  Reinforcement Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present an algorithm, HOMER, for exploration and reinforcement learning in\nrich observation environments that are summarizable by an unknown latent state\nspace. The algorithm interleaves representation learning to identify a new\nnotion of kinematic state abstraction with strategic exploration to reach new\nstates using the learned abstraction. The algorithm provably explores the\nenvironment with sample complexity scaling polynomially in the number of latent\nstates and the time horizon, and, crucially, with no dependence on the size of\nthe observation space, which could be infinitely large. This exploration\nguarantee further enables sample-efficient global policy optimization for any\nreward function. On the computational side, we show that the algorithm can be\nimplemented efficiently whenever certain supervised learning problems are\ntractable. Empirically, we evaluate HOMER on a challenging exploration problem,\nwhere we show that the algorithm is exponentially more sample efficient than\nstandard reinforcement learning baselines.\n", "versions": [{"version": "v1", "created": "Wed, 13 Nov 2019 21:07:44 GMT"}], "update_date": "2019-11-15", "authors_parsed": [["Misra", "Dipendra", ""], ["Henaff", "Mikael", ""], ["Krishnamurthy", "Akshay", ""], ["Langford", "John", ""]]}, {"id": "1911.05822", "submitter": "Christos Thrampoulidis", "authors": "Zeyu Deng, Abla Kammoun and Christos Thrampoulidis", "title": "A Model of Double Descent for High-dimensional Binary Linear\n  Classification", "comments": "Short version submitted to ICASSP 2020; Updates in 2nd version:\n  revised proofs, typos fixed, extended discussions and numerical illustrations", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG eess.SP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider a model for logistic regression where only a subset of features\nof size $p$ is used for training a linear classifier over $n$ training samples.\nThe classifier is obtained by running gradient descent (GD) on logistic loss.\nFor this model, we investigate the dependence of the classification error on\nthe overparameterization ratio $\\kappa=p/n$. First, building on known\ndeterministic results on the implicit bias of GD, we uncover a phase-transition\nphenomenon for the case of Gaussian features: the classification error of GD is\nthe same as that of the maximum-likelihood (ML) solution when\n$\\kappa<\\kappa_\\star$, and that of the max-margin (SVM) solution when\n$\\kappa>\\kappa_\\star$. Next, using the convex Gaussian min-max theorem (CGMT),\nwe sharply characterize the performance of both the ML and the SVM solutions.\nCombining these results, we obtain curves that explicitly characterize the\nclassification error for varying values of $\\kappa$. The numerical results\nvalidate the theoretical predictions and unveil double-descent phenomena that\ncomplement similar recent findings in linear regression settings as well as\nempirical observations in more complex learning scenarios.\n", "versions": [{"version": "v1", "created": "Wed, 13 Nov 2019 21:41:38 GMT"}, {"version": "v2", "created": "Sun, 10 May 2020 19:10:56 GMT"}], "update_date": "2020-05-12", "authors_parsed": [["Deng", "Zeyu", ""], ["Kammoun", "Abla", ""], ["Thrampoulidis", "Christos", ""]]}, {"id": "1911.05833", "submitter": "Khaled Koutini", "authors": "Khaled Koutini, Shreyan Chowdhury, Verena Haunschmid, Hamid\n  Eghbal-zadeh, Gerhard Widmer", "title": "Emotion and Theme Recognition in Music with Frequency-Aware\n  RF-Regularized CNNs", "comments": "MediaEval`19, 27-29 October 2019, Sophia Antipolis, France", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SD cs.LG cs.MM eess.AS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present CP-JKU submission to MediaEval 2019; a Receptive\nField-(RF)-regularized and Frequency-Aware CNN approach for tagging music with\nemotion/mood labels. We perform an investigation regarding the impact of the RF\nof the CNNs on their performance on this dataset. We observe that ResNets with\nsmaller receptive fields -- originally adapted for acoustic scene\nclassification -- also perform well in the emotion tagging task. We improve the\nperformance of such architectures using techniques such as Frequency Awareness\nand Shake-Shake regularization, which were used in previous work on general\nacoustic recognition tasks.\n", "versions": [{"version": "v1", "created": "Mon, 28 Oct 2019 10:19:55 GMT"}], "update_date": "2019-11-15", "authors_parsed": [["Koutini", "Khaled", ""], ["Chowdhury", "Shreyan", ""], ["Haunschmid", "Verena", ""], ["Eghbal-zadeh", "Hamid", ""], ["Widmer", "Gerhard", ""]]}, {"id": "1911.05843", "submitter": "Ardavan Afshar", "authors": "Ardavan Afshar, Ioakeim Perros, Haesun Park, Christopher deFilippi,\n  Xiaowei Yan, Walter Stewart, Joyce Ho, Jimeng Sun", "title": "TASTE: Temporal and Static Tensor Factorization for Phenotyping\n  Electronic Health Records", "comments": "19 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Phenotyping electronic health records (EHR) focuses on defining meaningful\npatient groups (e.g., heart failure group and diabetes group) and identifying\nthe temporal evolution of patients in those groups. Tensor factorization has\nbeen an effective tool for phenotyping. Most of the existing works assume\neither a static patient representation with aggregate data or only model\ntemporal data. However, real EHR data contain both temporal (e.g., longitudinal\nclinical visits) and static information (e.g., patient demographics), which are\ndifficult to model simultaneously. In this paper, we propose Temporal And\nStatic TEnsor factorization (TASTE) that jointly models both static and\ntemporal information to extract phenotypes. TASTE combines the PARAFAC2 model\nwith non-negative matrix factorization to model a temporal and a static tensor.\nTo fit the proposed model, we transform the original problem into simpler ones\nwhich are optimally solved in an alternating fashion. For each of the\nsub-problems, our proposed mathematical reformulations lead to efficient\nsub-problem solvers. Comprehensive experiments on large EHR data from a heart\nfailure (HF) study confirmed that TASTE is up to 14x faster than several\nbaselines and the resulting phenotypes were confirmed to be clinically\nmeaningful by a cardiologist. Using 80 phenotypes extracted by TASTE, a simple\nlogistic regression can achieve the same level of area under the curve (AUC)\nfor HF prediction compared to a deep learning model using recurrent neural\nnetworks (RNN) with 345 features.\n", "versions": [{"version": "v1", "created": "Wed, 13 Nov 2019 22:28:57 GMT"}], "update_date": "2019-11-15", "authors_parsed": [["Afshar", "Ardavan", ""], ["Perros", "Ioakeim", ""], ["Park", "Haesun", ""], ["deFilippi", "Christopher", ""], ["Yan", "Xiaowei", ""], ["Stewart", "Walter", ""], ["Ho", "Joyce", ""], ["Sun", "Jimeng", ""]]}, {"id": "1911.05856", "submitter": "Shunwang Gong", "authors": "Shunwang Gong, Lei Chen, Michael Bronstein, Stefanos Zafeiriou", "title": "SpiralNet++: A Fast and Highly Efficient Mesh Convolution Operator", "comments": "The IEEE International Conference on Computer Vision (ICCV)\n  Workshops, 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Intrinsic graph convolution operators with differentiable kernel functions\nplay a crucial role in analyzing 3D shape meshes. In this paper, we present a\nfast and efficient intrinsic mesh convolution operator that does not rely on\nthe intricate design of kernel function. We explicitly formulate the order of\naggregating neighboring vertices, instead of learning weights between nodes,\nand then a fully connected layer follows to fuse local geometric structure\ninformation with vertex features. We provide extensive evidence showing that\nmodels based on this convolution operator are easier to train, and can\nefficiently learn invariant shape features. Specifically, we evaluate our\nmethod on three different types of tasks of dense shape correspondence, 3D\nfacial expression classification, and 3D shape reconstruction, and show that it\nsignificantly outperforms state-of-the-art approaches while being significantly\nfaster, without relying on shape descriptors. Our source code is available on\nGitHub.\n", "versions": [{"version": "v1", "created": "Wed, 13 Nov 2019 22:59:19 GMT"}], "update_date": "2019-11-15", "authors_parsed": [["Gong", "Shunwang", ""], ["Chen", "Lei", ""], ["Bronstein", "Michael", ""], ["Zafeiriou", "Stefanos", ""]]}, {"id": "1911.05861", "submitter": "Stephen Pfohl", "authors": "Stephen R. Pfohl, Andrew M. Dai, Katherine Heller", "title": "Federated and Differentially Private Learning for Electronic Health\n  Records", "comments": "Machine Learning for Health (ML4H) at NeurIPS 2019 - Extended\n  Abstract", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The use of collaborative and decentralized machine learning techniques such\nas federated learning have the potential to enable the development and\ndeployment of clinical risk predictions models in low-resource settings without\nrequiring sensitive data be shared or stored in a central repository. This\nprocess necessitates communication of model weights or updates between\ncollaborating entities, but it is unclear to what extent patient privacy is\ncompromised as a result. To gain insight into this question, we study the\nefficacy of centralized versus federated learning in both private and\nnon-private settings. The clinical prediction tasks we consider are the\nprediction of prolonged length of stay and in-hospital mortality across thirty\none hospitals in the eICU Collaborative Research Database. We find that while\nit is straightforward to apply differentially private stochastic gradient\ndescent to achieve strong privacy bounds when training in a centralized\nsetting, it is considerably more difficult to do so in the federated setting.\n", "versions": [{"version": "v1", "created": "Wed, 13 Nov 2019 23:42:06 GMT"}], "update_date": "2019-11-15", "authors_parsed": [["Pfohl", "Stephen R.", ""], ["Dai", "Andrew M.", ""], ["Heller", "Katherine", ""]]}, {"id": "1911.05873", "submitter": "Ching-An Cheng", "authors": "Ching-An Cheng, Remi Tachet des Combes, Byron Boots, Geoff Gordon", "title": "A Reduction from Reinforcement Learning to No-Regret Online Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a reduction from reinforcement learning (RL) to no-regret online\nlearning based on the saddle-point formulation of RL, by which \"any\" online\nalgorithm with sublinear regret can generate policies with provable performance\nguarantees. This new perspective decouples the RL problem into two parts:\nregret minimization and function approximation. The first part admits a\nstandard online-learning analysis, and the second part can be quantified\nindependently of the learning algorithm. Therefore, the proposed reduction can\nbe used as a tool to systematically design new RL algorithms. We demonstrate\nthis idea by devising a simple RL algorithm based on mirror descent and the\ngenerative-model oracle. For any $\\gamma$-discounted tabular RL problem, with\nprobability at least $1-\\delta$, it learns an $\\epsilon$-optimal policy using\nat most\n$\\tilde{O}\\left(\\frac{|\\mathcal{S}||\\mathcal{A}|\\log(\\frac{1}{\\delta})}{(1-\\gamma)^4\\epsilon^2}\\right)$\nsamples. Furthermore, this algorithm admits a direct extension to linearly\nparameterized function approximators for large-scale applications, with\ncomputation and sample complexities independent of\n$|\\mathcal{S}|$,$|\\mathcal{A}|$, though at the cost of potential approximation\nbias.\n", "versions": [{"version": "v1", "created": "Thu, 14 Nov 2019 00:47:47 GMT"}, {"version": "v2", "created": "Wed, 1 Jan 2020 21:25:39 GMT"}], "update_date": "2020-01-03", "authors_parsed": [["Cheng", "Ching-An", ""], ["Combes", "Remi Tachet des", ""], ["Boots", "Byron", ""], ["Gordon", "Geoff", ""]]}, {"id": "1911.05878", "submitter": "Zhengchun Liu", "authors": "Vibhatha Abeykoon, Zhengchun Liu, Rajkumar Kettimuthu, Geoffrey Fox,\n  Ian Foster", "title": "Scientific Image Restoration Anywhere", "comments": "6 pages, 8 figures, 1 table", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.IV cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The use of deep learning models within scientific experimental facilities\nfrequently requires low-latency inference, so that, for example, quality\ncontrol operations can be performed while data are being collected. Edge\ncomputing devices can be useful in this context, as their low cost and compact\nform factor permit them to be co-located with the experimental apparatus. Can\nsuch devices, with their limited resources, can perform neural network\nfeed-forward computations efficiently and effectively? We explore this question\nby evaluating the performance and accuracy of a scientific image restoration\nmodel, for which both model input and output are images, on edge computing\ndevices. Specifically, we evaluate deployments of TomoGAN, an image-denoising\nmodel based on generative adversarial networks developed for low-dose x-ray\nimaging, on the Google Edge TPU and NVIDIA Jetson. We adapt TomoGAN for edge\nexecution, evaluate model inference performance, and propose methods to address\nthe accuracy drop caused by model quantization. We show that these edge\ncomputing devices can deliver accuracy comparable to that of a full-fledged CPU\nor GPU model, at speeds that are more than adequate for use in the intended\ndeployments, denoising a 1024 x 1024 image in less than a second. Our\nexperiments also show that the Edge TPU models can provide 3x faster inference\nresponse than a CPU-based model and 1.5x faster than an edge GPU-based model.\nThis combination of high speed and low cost permits image restoration anywhere.\n", "versions": [{"version": "v1", "created": "Tue, 12 Nov 2019 21:33:14 GMT"}], "update_date": "2019-11-15", "authors_parsed": [["Abeykoon", "Vibhatha", ""], ["Liu", "Zhengchun", ""], ["Kettimuthu", "Rajkumar", ""], ["Fox", "Geoffrey", ""], ["Foster", "Ian", ""]]}, {"id": "1911.05879", "submitter": "Gayathri Radhabai Gopinathan Nair", "authors": "Gayathri R G, Atul Sajjanhar, Yong Xiang", "title": "Image-Based Feature Representation for Insider Threat Classification", "comments": "8 pages, 5 figures", "journal-ref": "Applied Sciences, vol. 10, no. 14, p. 4945, 2020", "doi": "10.3390/app10144945", "report-no": null, "categories": "cs.CR cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Insiders are the trusted entities in the organization, but poses threat to\nthe with access to sensitive information network and resources. The insider\nthreat detection is a well studied problem in security analytics. Identifying\nthe features from data sources and using them with the right data analytics\nalgorithms makes various kinds of threat analysis possible. The insider threat\nanalysis is mainly done using the frequency based attributes extracted from the\nraw data available from data sources. In this paper, we propose an image-based\nfeature representation of the daily resource usage pattern of users in the\norganization. The features extracted from the audit files of the organization\nare represented as gray scale images. Hence, these images are used to represent\nthe resource access patterns and thereby the behavior of users. Classification\nmodels are applied to the representative images to detect anomalous behavior of\ninsiders. The images are classified to malicious and non-malicious. The\neffectiveness of the proposed representation is evaluated using the CMU CERT\ndata V4.2, and state-of-art image classification models like Mobilenet, VGG and\nResNet. The experimental results showed improved accuracy. The comparison with\nexisting works show a performance improvement in terms of high recall and\nprecision values.\n", "versions": [{"version": "v1", "created": "Wed, 13 Nov 2019 03:00:55 GMT"}], "update_date": "2021-06-29", "authors_parsed": [["G", "Gayathri R", ""], ["Sajjanhar", "Atul", ""], ["Xiang", "Yong", ""]]}, {"id": "1911.05887", "submitter": "Jiawei Wen", "authors": "Jiawei Wen, Hossein Vahabi, Mihajlo Grbovic", "title": "Revenue Maximization of Airbnb Marketplace using Search Results", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Correctly pricing products or services in an online marketplace presents a\nchallenging problem and one of the critical factors for the success of the\nbusiness. When users are looking to buy an item they typically search for it.\nQuery relevance models are used at this stage to retrieve and rank the items on\nthe search page from most relevant to least relevant. The presented items are\nnaturally \"competing\" against each other for user purchases. We provide a\npractical two-stage model to price this set of retrieved items for which\ndistributions of their values are learned. The initial output of the pricing\nstrategy is a price vector for the top displayed items in one search event. We\nlater aggregate these results over searches to provide the supplier with the\noptimal price for each item. We applied our solution to large-scale search data\nobtained from Airbnb Experiences marketplace. Offline evaluation results show\nthat our strategy improves upon baseline pricing strategies on key metrics by\nat least +20% in terms of booking regret and +55% in terms of revenue\npotential.\n", "versions": [{"version": "v1", "created": "Thu, 14 Nov 2019 01:43:27 GMT"}, {"version": "v2", "created": "Sat, 16 Nov 2019 02:12:53 GMT"}], "update_date": "2019-11-19", "authors_parsed": [["Wen", "Jiawei", ""], ["Vahabi", "Hossein", ""], ["Grbovic", "Mihajlo", ""]]}, {"id": "1911.05892", "submitter": "Sumitra Ganesh", "authors": "Sumitra Ganesh, Nelson Vadori, Mengda Xu, Hua Zheng, Prashant Reddy,\n  Manuela Veloso", "title": "Reinforcement Learning for Market Making in a Multi-agent Dealer Market", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "q-fin.TR cs.LG cs.MA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Market makers play an important role in providing liquidity to markets by\ncontinuously quoting prices at which they are willing to buy and sell, and\nmanaging inventory risk. In this paper, we build a multi-agent simulation of a\ndealer market and demonstrate that it can be used to understand the behavior of\na reinforcement learning (RL) based market maker agent. We use the simulator to\ntrain an RL-based market maker agent with different competitive scenarios,\nreward formulations and market price trends (drifts). We show that the\nreinforcement learning agent is able to learn about its competitor's pricing\npolicy; it also learns to manage inventory by smartly selecting asymmetric\nprices on the buy and sell sides (skewing), and maintaining a positive (or\nnegative) inventory depending on whether the market price drift is positive (or\nnegative). Finally, we propose and test reward formulations for creating risk\naverse RL-based market maker agents.\n", "versions": [{"version": "v1", "created": "Thu, 14 Nov 2019 01:55:31 GMT"}], "update_date": "2019-11-15", "authors_parsed": [["Ganesh", "Sumitra", ""], ["Vadori", "Nelson", ""], ["Xu", "Mengda", ""], ["Zheng", "Hua", ""], ["Reddy", "Prashant", ""], ["Veloso", "Manuela", ""]]}, {"id": "1911.05904", "submitter": "Dong Yizhen", "authors": "Yizhen Dong, Peixin Zhang, Jingyi Wang, Shuang Liu, Jun Sun, Jianye\n  Hao, Xinyu Wang, Li Wang, Jin Song Dong, Dai Ting", "title": "There is Limited Correlation between Coverage and Robustness for Deep\n  Neural Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.SE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep neural networks (DNN) are increasingly applied in safety-critical\nsystems, e.g., for face recognition, autonomous car control and malware\ndetection. It is also shown that DNNs are subject to attacks such as\nadversarial perturbation and thus must be properly tested. Many coverage\ncriteria for DNN since have been proposed, inspired by the success of code\ncoverage criteria for software programs. The expectation is that if a DNN is a\nwell tested (and retrained) according to such coverage criteria, it is more\nlikely to be robust. In this work, we conduct an empirical study to evaluate\nthe relationship between coverage, robustness and attack/defense metrics for\nDNN. Our study is the largest to date and systematically done based on 100 DNN\nmodels and 25 metrics. One of our findings is that there is limited correlation\nbetween coverage and robustness, i.e., improving coverage does not help improve\nthe robustness. Our dataset and implementation have been made available to\nserve as a benchmark for future studies on testing DNN.\n", "versions": [{"version": "v1", "created": "Thu, 14 Nov 2019 02:36:40 GMT"}], "update_date": "2019-11-15", "authors_parsed": [["Dong", "Yizhen", ""], ["Zhang", "Peixin", ""], ["Wang", "Jingyi", ""], ["Liu", "Shuang", ""], ["Sun", "Jun", ""], ["Hao", "Jianye", ""], ["Wang", "Xinyu", ""], ["Wang", "Li", ""], ["Dong", "Jin Song", ""], ["Ting", "Dai", ""]]}, {"id": "1911.05909", "submitter": "Mengzhuo Guo", "authors": "Mengzhuo Guo, Zhongzhi Xu, Qingpeng Zhang, Xiuwu Liao, Jiapeng Liu", "title": "Explainable Ordinal Factorization Model: Deciphering the Effects of\n  Attributes by Piece-wise Linear Approximation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Ordinal regression predicts the objects' labels that exhibit a natural\nordering, which is important to many managerial problems such as credit scoring\nand clinical diagnosis. In these problems, the ability to explain how the\nattributes affect the prediction is critical to users. However, most, if not\nall, existing ordinal regression models simplify such explanation in the form\nof constant coefficients for the main and interaction effects of individual\nattributes. Such explanation cannot characterize the contributions of\nattributes at different value scales. To address this challenge, we propose a\nnew explainable ordinal regression model, namely, the Explainable Ordinal\nFactorization Model (XOFM). XOFM uses the piece-wise linear functions to\napproximate the actual contributions of individual attributes and their\ninteractions. Moreover, XOFM introduces a novel ordinal transformation process\nto assign each object the probabilities of belonging to multiple relevant\nclasses, instead of fixing boundaries to differentiate classes. XOFM is based\non the Factorization Machines to handle the potential sparsity problem as a\nresult of discretizing the attribute scales. Comprehensive experiments with\nbenchmark datasets and baseline models demonstrate that the proposed XOFM\nexhibits superior explainability and leads to state-of-the-art prediction\naccuracy.\n", "versions": [{"version": "v1", "created": "Thu, 14 Nov 2019 02:53:15 GMT"}], "update_date": "2019-11-15", "authors_parsed": [["Guo", "Mengzhuo", ""], ["Xu", "Zhongzhi", ""], ["Zhang", "Qingpeng", ""], ["Liao", "Xiuwu", ""], ["Liu", "Jiapeng", ""]]}, {"id": "1911.05916", "submitter": "Ziang Yan", "authors": "Ziang Yan, Yiwen Guo, Changshui Zhang", "title": "Adversarial Margin Maximization Networks", "comments": "11 pages + 1 page appendix, accepted by T-PAMI", "journal-ref": null, "doi": "10.1109/TPAMI.2019.2948348", "report-no": null, "categories": "cs.LG cs.CV cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The tremendous recent success of deep neural networks (DNNs) has sparked a\nsurge of interest in understanding their predictive ability. Unlike the human\nvisual system which is able to generalize robustly and learn with little\nsupervision, DNNs normally require a massive amount of data to learn new\nconcepts. In addition, research works also show that DNNs are vulnerable to\nadversarial examples-maliciously generated images which seem perceptually\nsimilar to the natural ones but are actually formed to fool learning models,\nwhich means the models have problem generalizing to unseen data with certain\ntype of distortions. In this paper, we analyze the generalization ability of\nDNNs comprehensively and attempt to improve it from a geometric point of view.\nWe propose adversarial margin maximization (AMM), a learning-based\nregularization which exploits an adversarial perturbation as a proxy. It\nencourages a large margin in the input space, just like the support vector\nmachines. With a differentiable formulation of the perturbation, we train the\nregularized DNNs simply through back-propagation in an end-to-end manner.\nExperimental results on various datasets (including MNIST, CIFAR-10/100, SVHN\nand ImageNet) and different DNN architectures demonstrate the superiority of\nour method over previous state-of-the-arts. Code and models for reproducing our\nresults will be made publicly available.\n", "versions": [{"version": "v1", "created": "Thu, 14 Nov 2019 03:13:17 GMT"}], "update_date": "2019-11-15", "authors_parsed": [["Yan", "Ziang", ""], ["Guo", "Yiwen", ""], ["Zhang", "Changshui", ""]]}, {"id": "1911.05920", "submitter": "Xiang Li", "authors": "Li Xiang, Chen Shuo, Xia Yan and Yang Jian", "title": "Understanding the Disharmony between Weight Normalization Family and\n  Weight Decay: $\\epsilon-$shifted $L_2$ Regularizer", "comments": "12 pages, 9 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The merits of fast convergence and potentially better performance of the\nweight normalization family have drawn increasing attention in recent years.\nThese methods use standardization or normalization that changes the weight\n$\\boldsymbol{W}$ to $\\boldsymbol{W}'$, which makes $\\boldsymbol{W}'$\nindependent to the magnitude of $\\boldsymbol{W}$. Surprisingly,\n$\\boldsymbol{W}$ must be decayed during gradient descent, otherwise we will\nobserve a severe under-fitting problem, which is very counter-intuitive since\nweight decay is widely known to prevent deep networks from over-fitting. In\nthis paper, we \\emph{theoretically} prove that the weight decay term\n$\\frac{1}{2}\\lambda||{\\boldsymbol{W}}||^2$ merely modulates the effective\nlearning rate for improving objective optimization, and has no influence on\ngeneralization when the weight normalization family is compositely employed.\nFurthermore, we also expose several critical problems when introducing weight\ndecay term to weight normalization family, including the missing of global\nminimum and training instability. To address these problems, we propose an\n$\\epsilon-$shifted $L_2$ regularizer, which shifts the $L_2$ objective by a\npositive constant $\\epsilon$. Such a simple operation can theoretically\nguarantee the existence of global minimum, while preventing the network weights\nfrom being too small and thus avoiding gradient float overflow. It\nsignificantly improves the training stability and can achieve slightly better\nperformance in our practice. The effectiveness of $\\epsilon-$shifted $L_2$\nregularizer is comprehensively validated on the ImageNet, CIFAR-100, and COCO\ndatasets. Our codes and pretrained models will be released in\nhttps://github.com/implus/PytorchInsight.\n", "versions": [{"version": "v1", "created": "Thu, 14 Nov 2019 03:31:13 GMT"}], "update_date": "2019-11-15", "authors_parsed": [["Xiang", "Li", ""], ["Shuo", "Chen", ""], ["Yan", "Xia", ""], ["Jian", "Yang", ""]]}, {"id": "1911.05922", "submitter": "Nicholas Kullman", "authors": "Nicholas D. Kullman, Jorge E. Mendoza, Martin Cousineau, Justin C.\n  Goodson", "title": "Atari-fying the Vehicle Routing Problem with Stochastic Service Requests", "comments": "11 pages, 4 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG math.OC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a new general approach to modeling research problems as Atari-like\nvideogames to make them amenable to recent groundbreaking solution methods from\nthe deep reinforcement learning community. The approach is flexible, applicable\nto a wide range of problems. We demonstrate its application on a well known\nvehicle routing problem. Our preliminary results on this problem, though not\ntransformative, show signs of success and suggest that Atari-fication may be a\nuseful modeling approach for researchers studying problems involving sequential\ndecision making under uncertainty.\n", "versions": [{"version": "v1", "created": "Thu, 14 Nov 2019 03:41:11 GMT"}], "update_date": "2019-11-15", "authors_parsed": [["Kullman", "Nicholas D.", ""], ["Mendoza", "Jorge E.", ""], ["Cousineau", "Martin", ""], ["Goodson", "Justin C.", ""]]}, {"id": "1911.05927", "submitter": "Amin Sakzad", "authors": "Shangqi Lai, Xingliang Yuan, Amin Sakzad, Mahsa Salehi, Joseph K. Liu,\n  and Dongxi Liu", "title": "Enabling Efficient Privacy-Assured Outlier Detection over Encrypted\n  Incremental Datasets", "comments": "To appear in IEEE Internet of Things Journal", "journal-ref": null, "doi": "10.1109/JIOT.2019.2949374", "report-no": null, "categories": "cs.CR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Outlier detection is widely used in practice to track the anomaly on\nincremental datasets such as network traffic and system logs. However, these\ndatasets often involve sensitive information, and sharing the data to third\nparties for anomaly detection raises privacy concerns. In this paper, we\npresent a privacy-preserving outlier detection protocol (PPOD) for incremental\ndatasets. The protocol decomposes the outlier detection algorithm into several\nphases and recognises the necessary cryptographic operations in each phase. It\nrealises several cryptographic modules via efficient and interchangeable\nprotocols to support the above cryptographic operations and composes them in\nthe overall protocol to enable outlier detection over encrypted datasets. To\nsupport efficient updates, it integrates the sliding window model to\nperiodically evict the expired data in order to maintain a constant update\ntime. We build a prototype of PPOD and systematically evaluates the\ncryptographic modules and the overall protocols under various parameter\nsettings. Our results show that PPOD can handle encrypted incremental datasets\nwith a moderate computation and communication cost.\n", "versions": [{"version": "v1", "created": "Thu, 14 Nov 2019 04:01:42 GMT"}], "update_date": "2019-11-15", "authors_parsed": [["Lai", "Shangqi", ""], ["Yuan", "Xingliang", ""], ["Sakzad", "Amin", ""], ["Salehi", "Mahsa", ""], ["Liu", "Joseph K.", ""], ["Liu", "Dongxi", ""]]}, {"id": "1911.05934", "submitter": "Raul Astudillo", "authors": "Raul Astudillo, Peter I. Frazier", "title": "Multi-Attribute Bayesian Optimization With Interactive Preference\n  Learning", "comments": "In Proceedings of the 23rd International Conference on Artificial\n  Intelligence and Statistics, 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG math.OC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider black-box global optimization of time-consuming-to-evaluate\nfunctions on behalf of a decision-maker (DM) whose preferences must be learned.\nEach feasible design is associated with a time-consuming-to-evaluate vector of\nattributes and each vector of attributes is assigned a utility by the DM's\nutility function, which may be learned approximately using preferences\nexpressed over pairs of attribute vectors. Past work has used a point estimate\nof this utility function as if it were error-free within single-objective\noptimization. However, utility estimation errors may yield a poor suggested\ndesign. Furthermore, this approach produces a single suggested \"best\" design,\nwhereas DMs often prefer to choose from a menu. We propose a novel\nmulti-attribute Bayesian optimization with preference learning approach. Our\napproach acknowledges the uncertainty in preference estimation and implicitly\nchooses designs to evaluate that are good not just for a single estimated\nutility function but a range of likely ones. The outcome of our approach is a\nmenu of designs and evaluated attributes from which the DM makes a final\nselection. We demonstrate the value and flexibility of our approach in a\nvariety of experiments.\n", "versions": [{"version": "v1", "created": "Thu, 14 Nov 2019 04:29:31 GMT"}, {"version": "v2", "created": "Tue, 3 Mar 2020 22:37:57 GMT"}], "update_date": "2020-03-05", "authors_parsed": [["Astudillo", "Raul", ""], ["Frazier", "Peter I.", ""]]}, {"id": "1911.05939", "submitter": "Uehwan Kim", "authors": "Ue-Hwan Kim and Se-Ho Kim and Jong-Hwan Kim", "title": "SimVODIS: Simultaneous Visual Odometry, Object Detection, and Instance\n  Segmentation", "comments": "Submitted to TPAMI", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Intelligent agents need to understand the surrounding environment to provide\nmeaningful services to or interact intelligently with humans. The agents should\nperceive geometric features as well as semantic entities inherent in the\nenvironment. Contemporary methods in general provide one type of information\nregarding the environment at a time, making it difficult to conduct high-level\ntasks. Moreover, running two types of methods and associating two resultant\ninformation requires a lot of computation and complicates the software\narchitecture. To overcome these limitations, we propose a neural architecture\nthat simultaneously performs both geometric and semantic tasks in a single\nthread: simultaneous visual odometry, object detection, and instance\nsegmentation (SimVODIS). Training SimVODIS requires unlabeled video sequences\nand the photometric consistency between input image frames generates\nself-supervision signals. The performance of SimVODIS outperforms or matches\nthe state-of-the-art performance in pose estimation, depth map prediction,\nobject detection, and instance segmentation tasks while completing all the\ntasks in a single thread. We expect SimVODIS would enhance the autonomy of\nintelligent agents and let the agents provide effective services to humans.\n", "versions": [{"version": "v1", "created": "Thu, 14 Nov 2019 05:03:47 GMT"}, {"version": "v2", "created": "Sat, 16 Nov 2019 10:39:06 GMT"}], "update_date": "2019-11-19", "authors_parsed": [["Kim", "Ue-Hwan", ""], ["Kim", "Se-Ho", ""], ["Kim", "Jong-Hwan", ""]]}, {"id": "1911.05940", "submitter": "Arvind Krishna", "authors": "Arvind Krishna, Simon Mak and Roshan Joseph", "title": "Distributional Clustering: A distribution-preserving clustering method", "comments": "Submitted to Statistica Sinica", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  One key use of k-means clustering is to identify cluster prototypes which can\nserve as representative points for a dataset. However, a drawback of using\nk-means cluster centers as representative points is that such points distort\nthe distribution of the underlying data. This can be highly disadvantageous in\nproblems where the representative points are subsequently used to gain insights\non the data distribution, as these points do not mimic the distribution of the\ndata. To this end, we propose a new clustering method called \"distributional\nclustering\", which ensures cluster centers capture the distribution of the\nunderlying data. We first prove the asymptotic convergence of the proposed\ncluster centers to the data generating distribution, then present an efficient\nalgorithm for computing these cluster centers in practice. Finally, we\ndemonstrate the effectiveness of distributional clustering on synthetic and\nreal datasets.\n", "versions": [{"version": "v1", "created": "Thu, 14 Nov 2019 05:06:28 GMT"}], "update_date": "2019-11-15", "authors_parsed": [["Krishna", "Arvind", ""], ["Mak", "Simon", ""], ["Joseph", "Roshan", ""]]}, {"id": "1911.05941", "submitter": "Yoeng Jye Yeoh", "authors": "Yoeng Jye Yeoh, Takashi Morie, Hakaru Tamukoh", "title": "An Efficient Hardware-Oriented Dropout Algorithm", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper proposes a hardware-oriented dropout algorithm, which is efficient\nfor field programmable gate array (FPGA) implementation. In deep neural\nnetworks (DNNs), overfitting occurs when networks are overtrained and adapt too\nwell to training data. Consequently, they fail in predicting unseen data used\nas test data. Dropout is a common technique that is often applied in DNNs to\novercome this problem. In general, implementing such training algorithms of\nDNNs in embedded systems is difficult due to power and memory constraints.\nTraining DNNs is power-, time-, and memory- intensive; however, embedded\nsystems require low power consumption and real-time processing. An FPGA is\nsuitable for embedded systems for its parallel processing characteristic and\nlow operating power; however, due to its limited memory and different\narchitecture, it is difficult to apply general neural network algorithms.\nTherefore, we propose a hardware-oriented dropout algorithm that can\neffectively utilize the characteristics of an FPGA with less memory required.\nSoftware program verification demonstrates that the performance of the proposed\nmethod is identical to that of conventional dropout, and hardware synthesis\ndemonstrates that it results in significant resource reduction.\n", "versions": [{"version": "v1", "created": "Thu, 14 Nov 2019 05:22:11 GMT"}], "update_date": "2019-11-15", "authors_parsed": [["Yeoh", "Yoeng Jye", ""], ["Morie", "Takashi", ""], ["Tamukoh", "Hakaru", ""]]}, {"id": "1911.05942", "submitter": "Quan Chen", "authors": "Bo Wang, Quan Chen, Min Zhou, Zhiqiang Zhang, Xiaogang Jin, Kun Gai", "title": "Progressive Feature Polishing Network for Salient Object Detection", "comments": "Accepted by AAAI 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Feature matters for salient object detection. Existing methods mainly focus\non designing a sophisticated structure to incorporate multi-level features and\nfilter out cluttered features. We present Progressive Feature Polishing Network\n(PFPN), a simple yet effective framework to progressively polish the\nmulti-level features to be more accurate and representative. By employing\nmultiple Feature Polishing Modules (FPMs) in a recurrent manner, our approach\nis able to detect salient objects with fine details without any\npost-processing. A FPM parallelly updates the features of each level by\ndirectly incorporating all higher level context information. Moreover, it can\nkeep the dimensions and hierarchical structures of the feature maps, which\nmakes it flexible to be integrated with any CNN-based models. Empirical\nexperiments show that our results are monotonically getting better with\nincreasing number of FPMs. Without bells and whistles, PFPN outperforms the\nstate-of-the-art methods significantly on five benchmark datasets under various\nevaluation metrics.\n", "versions": [{"version": "v1", "created": "Thu, 14 Nov 2019 05:22:12 GMT"}], "update_date": "2019-11-15", "authors_parsed": [["Wang", "Bo", ""], ["Chen", "Quan", ""], ["Zhou", "Min", ""], ["Zhang", "Zhiqiang", ""], ["Jin", "Xiaogang", ""], ["Gai", "Kun", ""]]}, {"id": "1911.05944", "submitter": "Tolulope Odetola", "authors": "Tolulope A. Odetola and Katie M. Groves and Syed Rafay Hasan", "title": "2L-3W: 2-Level 3-Way Hardware-Software Co-Verification for the Mapping\n  of Deep Learning Architecture (DLA) onto FPGA Boards", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  FPGAs have become a popular choice for deploying deep learning architectures\n(DLA). There are many researchers that have explored the deployment and mapping\nof DLA on FPGA. However, there has been a growing need to do design-time\nhardware-software co-verification of these deployments. To the best of our\nknowledge this is the first work that proposes a 2-Level 3-Way (2L-3W)\nhardware-software co-verification methodology and provides a step-by-step guide\nfor the successful mapping, deployment and verification of DLA on FPGA boards.\nThe 2-Level verification is to make sure the implementation in each stage\n(software and hardware) are following the desired behavior. The 3-Way\nco-verification provides a cross-paradigm (software, design and hardware)\nlayer-by-layer parameter check to assure the correct implementation and mapping\nof the DLA onto FPGA boards. The proposed 2L-3W co-verification methodology has\nbeen evaluated over several test cases. In each case, the prediction and\nlayer-by-layer output of the DLA deployed on PYNQ FPGA board (hardware)\nalongside with the intermediate design results of the layer-by-layer output of\nthe DLA implemented on Vivado HLS and the prediction and layer-by-layer output\nof the software level (Caffe deep learning framework) are compared to obtain a\nlayer-by-layer similarity score. The comparison is achieved using a completely\nautomated Python script. The comparison provides a layer-by-layer similarity\nscore that informs us the degree of success of the DLA mapping to the FPGA or\nhelp identify in design time the layer to be debugged in the case of\nunsuccessful mapping. We demonstrated our technique on LeNet DLA and Caffe\ninspired Cifar-10 DLA and the co-verification results yielded layer-by-layer\nsimilarity scores of 99\\% accuracy.\n", "versions": [{"version": "v1", "created": "Thu, 14 Nov 2019 05:33:28 GMT"}], "update_date": "2019-11-15", "authors_parsed": [["Odetola", "Tolulope A.", ""], ["Groves", "Katie M.", ""], ["Hasan", "Syed Rafay", ""]]}, {"id": "1911.05949", "submitter": "Haoyu Zhao", "authors": "Haoyu Zhao, Wei Chen", "title": "Online Second Price Auction with Semi-bandit Feedback Under the\n  Non-Stationary Setting", "comments": "Accepted to AAAI-20", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.DS cs.GT stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we study the non-stationary online second price auction\nproblem. We assume that the seller is selling the same type of items in $T$\nrounds by the second price auction, and she can set the reserve price in each\nround. In each round, the bidders draw their private values from a joint\ndistribution unknown to the seller. Then, the seller announced the reserve\nprice in this round. Next, bidders with private values higher than the\nannounced reserve price in that round will report their values to the seller as\ntheir bids. The bidder with the highest bid larger than the reserved price\nwould win the item and she will pay to the seller the price equal to the\nsecond-highest bid or the reserve price, whichever is larger. The seller wants\nto maximize her total revenue during the time horizon $T$ while learning the\ndistribution of private values over time. The problem is more challenging than\nthe standard online learning scenario since the private value distribution is\nnon-stationary, meaning that the distribution of bidders' private values may\nchange over time, and we need to use the \\emph{non-stationary regret} to\nmeasure the performance of our algorithm. To our knowledge, this paper is the\nfirst to study the repeated auction in the non-stationary setting\ntheoretically. Our algorithm achieves the non-stationary regret upper bound\n$\\tilde{\\mathcal{O}}(\\min\\{\\sqrt{\\mathcal S T},\n\\bar{\\mathcal{V}}^{\\frac{1}{3}}T^{\\frac{2}{3}}\\})$, where $\\mathcal S$ is the\nnumber of switches in the distribution, and $\\bar{\\mathcal{V}}$ is the sum of\ntotal variation, and $\\mathcal S$ and $\\bar{\\mathcal{V}}$ are not needed to be\nknown by the algorithm. We also prove regret lower bounds\n$\\Omega(\\sqrt{\\mathcal S T})$ in the switching case and\n$\\Omega(\\bar{\\mathcal{V}}^{\\frac{1}{3}}T^{\\frac{2}{3}})$ in the dynamic case,\nshowing that our algorithm has nearly optimal \\emph{non-stationary regret}.\n", "versions": [{"version": "v1", "created": "Thu, 14 Nov 2019 05:46:42 GMT"}], "update_date": "2019-11-15", "authors_parsed": [["Zhao", "Haoyu", ""], ["Chen", "Wei", ""]]}, {"id": "1911.05954", "submitter": "Zhen Zhang", "authors": "Zhen Zhang, Jiajun Bu, Martin Ester, Jianfeng Zhang, Chengwei Yao, Zhi\n  Yu, Can Wang", "title": "Hierarchical Graph Pooling with Structure Learning", "comments": "Typo corrected, reference added and code is available at\n  https://github.com/cszhangzhen/HGP-SL", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Graph Neural Networks (GNNs), which generalize deep neural networks to\ngraph-structured data, have drawn considerable attention and achieved\nstate-of-the-art performance in numerous graph related tasks. However, existing\nGNN models mainly focus on designing graph convolution operations. The graph\npooling (or downsampling) operations, that play an important role in learning\nhierarchical representations, are usually overlooked. In this paper, we propose\na novel graph pooling operator, called Hierarchical Graph Pooling with\nStructure Learning (HGP-SL), which can be integrated into various graph neural\nnetwork architectures. HGP-SL incorporates graph pooling and structure learning\ninto a unified module to generate hierarchical representations of graphs. More\nspecifically, the graph pooling operation adaptively selects a subset of nodes\nto form an induced subgraph for the subsequent layers. To preserve the\nintegrity of graph's topological information, we further introduce a structure\nlearning mechanism to learn a refined graph structure for the pooled graph at\neach layer. By combining HGP-SL operator with graph neural networks, we perform\ngraph level representation learning with focus on graph classification task.\nExperimental results on six widely used benchmarks demonstrate the\neffectiveness of our proposed model.\n", "versions": [{"version": "v1", "created": "Thu, 14 Nov 2019 05:55:17 GMT"}, {"version": "v2", "created": "Thu, 5 Dec 2019 02:00:59 GMT"}, {"version": "v3", "created": "Wed, 25 Dec 2019 15:09:28 GMT"}], "update_date": "2019-12-30", "authors_parsed": [["Zhang", "Zhen", ""], ["Bu", "Jiajun", ""], ["Ester", "Martin", ""], ["Zhang", "Jianfeng", ""], ["Yao", "Chengwei", ""], ["Yu", "Zhi", ""], ["Wang", "Can", ""]]}, {"id": "1911.05956", "submitter": "Vishal Jain", "authors": "Harsh Deshpande, Vishal Jain, Sharayu Moharir", "title": "Contextual Bandits Evolving Over Finite Time", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Contextual bandits have the same exploration-exploitation trade-off as\nstandard multi-armed bandits. On adding positive externalities that decay with\ntime, this problem becomes much more difficult as wrong decisions at the start\nare hard to recover from. We explore existing policies in this setting and\nhighlight their biases towards the inherent reward matrix. We propose a\nrejection based policy that achieves a low regret irrespective of the structure\nof the reward probability matrix.\n", "versions": [{"version": "v1", "created": "Thu, 14 Nov 2019 06:14:14 GMT"}], "update_date": "2019-11-15", "authors_parsed": [["Deshpande", "Harsh", ""], ["Jain", "Vishal", ""], ["Moharir", "Sharayu", ""]]}, {"id": "1911.05975", "submitter": "Seyed Mostafa Mousavi", "authors": "S.Mostafa Mousavi and Gregory C. Beroza", "title": "A Machine-Learning Approach for Earthquake Magnitude Estimation", "comments": null, "journal-ref": null, "doi": "10.1029/2019GL085976", "report-no": null, "categories": "physics.geo-ph cs.AI cs.LG eess.SP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this study we develop a single-station deep-learning approach for fast and\nreliable estimation of earthquake magnitude directly from raw waveforms. We\ndesign a regressor composed of convolutional and recurrent neural networks that\nis not sensitive to the data normalization, hence waveform amplitude\ninformation can be utilized during the training. Our network can predict\nearthquake magnitudes with an average error close to zero and standard\ndeviation of ~0.2 based on single-station waveforms without instrument response\ncorrection. We test the network for both local and duration magnitude scales\nand show a station-based learning can be an effective approach for improving\nthe performance. The proposed approach has a variety of potential applications\nfrom routine earthquake monitoring to early warning systems.\n", "versions": [{"version": "v1", "created": "Thu, 14 Nov 2019 07:33:49 GMT"}], "update_date": "2020-02-05", "authors_parsed": [["Mousavi", "S. Mostafa", ""], ["Beroza", "Gregory C.", ""]]}, {"id": "1911.05978", "submitter": "Pradyumna Narayana", "authors": "Pradyumna Narayana, Aniket Pednekar, Abishek Krishnamoorthy, Kazoo\n  Sone, Sugato Basu", "title": "HUSE: Hierarchical Universal Semantic Embeddings", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  There is a recent surge of interest in cross-modal representation learning\ncorresponding to images and text. The main challenge lies in mapping images and\ntext to a shared latent space where the embeddings corresponding to a similar\nsemantic concept lie closer to each other than the embeddings corresponding to\ndifferent semantic concepts, irrespective of the modality. Ranking losses are\ncommonly used to create such shared latent space -- however, they do not impose\nany constraints on inter-class relationships resulting in neighboring clusters\nto be completely unrelated. The works in the domain of visual semantic\nembeddings address this problem by first constructing a semantic embedding\nspace based on some external knowledge and projecting image embeddings onto\nthis fixed semantic embedding space. These works are confined only to image\ndomain and constraining the embeddings to a fixed space adds additional burden\non learning. This paper proposes a novel method, HUSE, to learn cross-modal\nrepresentation with semantic information. HUSE learns a shared latent space\nwhere the distance between any two universal embeddings is similar to the\ndistance between their corresponding class embeddings in the semantic embedding\nspace. HUSE also uses a classification objective with a shared classification\nlayer to make sure that the image and text embeddings are in the same shared\nlatent space. Experiments on UPMC Food-101 show our method outperforms previous\nstate-of-the-art on retrieval, hierarchical precision and classification\nresults.\n", "versions": [{"version": "v1", "created": "Thu, 14 Nov 2019 07:45:32 GMT"}], "update_date": "2019-11-15", "authors_parsed": [["Narayana", "Pradyumna", ""], ["Pednekar", "Aniket", ""], ["Krishnamoorthy", "Abishek", ""], ["Sone", "Kazoo", ""], ["Basu", "Sugato", ""]]}, {"id": "1911.05990", "submitter": "David Kappel", "authors": "Lukas Hahne, Timo L\\\"uddecke, Florentin W\\\"org\\\"otter, David Kappel", "title": "Attention on Abstract Visual Reasoning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Attention mechanisms have been boosting the performance of deep learning\nmodels on a wide range of applications, ranging from speech understanding to\nprogram induction. However, despite experiments from psychology which suggest\nthat attention plays an essential role in visual reasoning, the full potential\nof attention mechanisms has so far not been explored to solve abstract\ncognitive tasks on image data. In this work, we propose a hybrid network\narchitecture, grounded on self-attention and relational reasoning. We call this\nnew model Attention Relation Network (ARNe). ARNe combines features from the\nrecently introduced Transformer and the Wild Relation Network (WReN). We test\nARNe on the Procedurally Generated Matrices (PGMs) datasets for abstract visual\nreasoning. ARNe excels the WReN model on this task by 11.28 ppt. Relational\nconcepts between objects are efficiently learned demanding only 35% of the\ntraining samples to surpass reported accuracy of the base line model. Our\nproposed hybrid model, represents an alternative on learning abstract relations\nusing self-attention and demonstrates that the Transformer network is also well\nsuited for abstract visual reasoning.\n", "versions": [{"version": "v1", "created": "Thu, 14 Nov 2019 08:33:40 GMT"}], "update_date": "2019-11-15", "authors_parsed": [["Hahne", "Lukas", ""], ["L\u00fcddecke", "Timo", ""], ["W\u00f6rg\u00f6tter", "Florentin", ""], ["Kappel", "David", ""]]}, {"id": "1911.05996", "submitter": "Mohammad Malekzadeh", "authors": "Mohammad Malekzadeh, Richard G. Clegg, Andrea Cavallaro, Hamed Haddadi", "title": "Privacy and Utility Preserving Sensor-Data Transformations", "comments": "Accepted to appear in Pervasive and Mobile computing (PMC) Journal,\n  Elsevier", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.HC eess.SP stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Sensitive inferences and user re-identification are major threats to privacy\nwhen raw sensor data from wearable or portable devices are shared with\ncloud-assisted applications. To mitigate these threats, we propose mechanisms\nto transform sensor data before sharing them with applications running on\nusers' devices. These transformations aim at eliminating patterns that can be\nused for user re-identification or for inferring potentially sensitive\nactivities, while introducing a minor utility loss for the target application\n(or task). We show that, on gesture and activity recognition tasks, we can\nprevent inference of potentially sensitive activities while keeping the\nreduction in recognition accuracy of non-sensitive activities to less than 5\npercentage points. We also show that we can reduce the accuracy of user\nre-identification and of the potential inference of gender to the level of a\nrandom guess, while keeping the accuracy of activity recognition comparable to\nthat obtained on the original data.\n", "versions": [{"version": "v1", "created": "Thu, 14 Nov 2019 08:47:29 GMT"}], "update_date": "2019-11-15", "authors_parsed": [["Malekzadeh", "Mohammad", ""], ["Clegg", "Richard G.", ""], ["Cavallaro", "Andrea", ""], ["Haddadi", "Hamed", ""]]}, {"id": "1911.05999", "submitter": "Daiki Suehiro", "authors": "Daiki Suehiro, Eiji Takimoto", "title": "Reduction Scheme for Empirical Risk Minimization and Its Applications to\n  Multiple-Instance Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we propose a simple reduction scheme for empirical risk\nminimization (ERM) that preserves empirical Rademacher complexity. The\nreduction allows us to transfer known generalization bounds and algorithms for\nERM to the target learning problems in a straightforward way. In particular, we\napply our reduction scheme to the multiple-instance learning (MIL) problem, for\nwhich generalization bounds and ERM algorithms have been extensively studied.\nWe show that various learning problems can be reduced to MIL. Examples include\ntop-1 ranking learning, multi-class learning, and labeled and complementarily\nlabeled learning. It turns out that, some of the generalization bounds derived\nare, despite the simplicity of derivation, incomparable or competitive with the\nexisting bounds. Moreover, in some setting of labeled and complementarily\nlabeled learning, the algorithm derived is the first polynomial-time algorithm.\n", "versions": [{"version": "v1", "created": "Thu, 14 Nov 2019 08:56:06 GMT"}, {"version": "v2", "created": "Sat, 6 Jun 2020 03:19:34 GMT"}], "update_date": "2020-06-09", "authors_parsed": [["Suehiro", "Daiki", ""], ["Takimoto", "Eiji", ""]]}, {"id": "1911.06009", "submitter": "Hideaki Hayashi D.Eng.", "authors": "Hideaki Hayashi, Taro Shibanoki, Keisuke Shima, Yuichi Kurita and\n  Toshio Tsuji", "title": "A Recurrent Probabilistic Neural Network with Dimensionality Reduction\n  Based on Time-series Discriminant Component Analysis", "comments": "Published in IEEE Transactions on Neural Networks and Learning\n  Systems", "journal-ref": "IEEE Transactions on Neural Networks and Learning Systems, Vol.\n  26, No.12, pp. 3021-3033, 2015", "doi": "10.1109/TNNLS.2015.2400448", "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper proposes a probabilistic neural network developed on the basis of\ntime-series discriminant component analysis (TSDCA) that can be used to\nclassify high-dimensional time-series patterns. TSDCA involves the compression\nof high-dimensional time series into a lower-dimensional space using a set of\northogonal transformations and the calculation of posterior probabilities based\non a continuous-density hidden Markov model with a Gaussian mixture model\nexpressed in the reduced-dimensional space. The analysis can be incorporated\ninto a neural network, which is named a time-series discriminant component\nnetwork (TSDCN), so that parameters of dimensionality reduction and\nclassification can be obtained simultaneously as network coefficients according\nto a backpropagation through time-based learning algorithm with the Lagrange\nmultiplier method. The TSDCN is considered to enable high-accuracy\nclassification of high-dimensional time-series patterns and to reduce the\ncomputation time taken for network training. The validity of the TSDCN is\ndemonstrated for high-dimensional artificial data and EEG signals in the\nexperiments conducted during the study.\n", "versions": [{"version": "v1", "created": "Thu, 14 Nov 2019 09:48:41 GMT"}], "update_date": "2019-11-15", "authors_parsed": [["Hayashi", "Hideaki", ""], ["Shibanoki", "Taro", ""], ["Shima", "Keisuke", ""], ["Kurita", "Yuichi", ""], ["Tsuji", "Toshio", ""]]}, {"id": "1911.06015", "submitter": "Maximilian Toller", "authors": "Maximilian Toller and Roman Kern", "title": "Robust Parameter-Free Season Length Detection in Time Series", "comments": "MileTS 2017", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The in-depth analysis of time series has gained a lot of research interest in\nrecent years, with the identification of periodic patterns being one important\naspect. Many of the methods for identifying periodic patterns require time\nseries' season length as input parameter. There exist only a few algorithms for\nautomatic season length approximation. Many of these rely on simplifications\nsuch as data discretization and user defined parameters. This paper presents an\nalgorithm for season length detection that is designed to be sufficiently\nreliable to be used in practical applications and does not require any input\nother than the time series to be analyzed. The algorithm estimates a time\nseries' season length by interpolating, filtering and detrending the data. This\nis followed by analyzing the distances between zeros in the directly\ncorresponding autocorrelation function. Our algorithm was tested against a\ncomparable algorithm and outperformed it by passing 122 out of 165 tests, while\nthe existing algorithm passed 83 tests. The robustness of our method can be\njointly attributed to both the algorithmic approach and also to design\ndecisions taken at the implementational level.\n", "versions": [{"version": "v1", "created": "Thu, 14 Nov 2019 10:07:41 GMT"}], "update_date": "2019-11-15", "authors_parsed": [["Toller", "Maximilian", ""], ["Kern", "Roman", ""]]}, {"id": "1911.06028", "submitter": "Hideaki Hayashi D.Eng.", "authors": "Hideaki Hayashi and Seiichi Uchida", "title": "A Discriminative Gaussian Mixture Model with Sparsity", "comments": "Published as a conference paper at ICLR 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  In probabilistic classification, a discriminative model based on the softmax\nfunction has a potential limitation in that it assumes unimodality for each\nclass in the feature space. The mixture model can address this issue, although\nit leads to an increase in the number of parameters. We propose a sparse\nclassifier based on a discriminative GMM, referred to as a sparse\ndiscriminative Gaussian mixture (SDGM). In the SDGM, a GMM-based discriminative\nmodel is trained via sparse Bayesian learning. Using this sparse learning\nframework, we can simultaneously remove redundant Gaussian components and\nreduce the number of parameters used in the remaining components during\nlearning; this learning method reduces the model complexity, thereby improving\nthe generalization capability. Furthermore, the SDGM can be embedded into\nneural networks (NNs), such as convolutional NNs, and can be trained in an\nend-to-end manner. Experimental results demonstrated that the proposed method\noutperformed the existing softmax-based discriminative models.\n", "versions": [{"version": "v1", "created": "Thu, 14 Nov 2019 10:42:41 GMT"}, {"version": "v2", "created": "Fri, 7 May 2021 08:23:12 GMT"}], "update_date": "2021-05-10", "authors_parsed": [["Hayashi", "Hideaki", ""], ["Uchida", "Seiichi", ""]]}, {"id": "1911.06047", "submitter": "Dipu Manandhar", "authors": "Dipu Manandhar, Muhammet Bastan and Kim-Hui Yap", "title": "Semantic Granularity Metric Learning for Visual Search", "comments": "10 pages, 10 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep metric learning applied to various applications has shown promising\nresults in identification, retrieval and recognition. Existing methods often do\nnot consider different granularity in visual similarity. However, in many\ndomain applications, images exhibit similarity at multiple granularities with\nvisual semantic concepts, e.g. fashion demonstrates similarity ranging from\nclothing of the exact same instance to similar looks/design or a common\ncategory. Therefore, training image triplets/pairs used for metric learning\ninherently possess different degree of information. However, the existing\nmethods often treats them with equal importance during training. This hinders\ncapturing the underlying granularities in feature similarity required for\neffective visual search.\n  In view of this, we propose a new deep semantic granularity metric learning\n(SGML) that develops a novel idea of leveraging attribute semantic space to\ncapture different granularity of similarity, and then integrate this\ninformation into deep metric learning. The proposed method simultaneously\nlearns image attributes and embeddings using multitask CNNs. The two tasks are\nnot only jointly optimized but are further linked by the semantic granularity\nsimilarity mappings to leverage the correlations between the tasks. To this\nend, we propose a new soft-binomial deviance loss that effectively integrates\nthe degree of information in training samples, which helps to capture visual\nsimilarity at multiple granularities. Compared to recent ensemble-based\nmethods, our framework is conceptually elegant, computationally simple and\nprovides better performance. We perform extensive experiments on benchmark\nmetric learning datasets and demonstrate that our method outperforms recent\nstate-of-the-art methods, e.g., 1-4.5\\% improvement in Recall@1 over the\nprevious state-of-the-arts [1],[2] on DeepFashion In-Shop dataset.\n", "versions": [{"version": "v1", "created": "Thu, 14 Nov 2019 11:36:16 GMT"}], "update_date": "2021-05-17", "authors_parsed": [["Manandhar", "Dipu", ""], ["Bastan", "Muhammet", ""], ["Yap", "Kim-Hui", ""]]}, {"id": "1911.06048", "submitter": "Simon Bartels", "authors": "Simon Bartels and Philipp Hennig", "title": "Conjugate Gradients for Kernel Machines", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Regularized least-squares (kernel-ridge / Gaussian process) regression is a\nfundamental algorithm of statistics and machine learning. Because generic\nalgorithms for the exact solution have cubic complexity in the number of\ndatapoints, large datasets require to resort to approximations. In this work,\nthe computation of the least-squares prediction is itself treated as a\nprobabilistic inference problem. We propose a structured Gaussian regression\nmodel on the kernel function that uses projections of the kernel matrix to\nobtain a low-rank approximation of the kernel and the matrix. A central result\nis an enhanced way to use the method of conjugate gradients for the specific\nsetting of least-squares regression as encountered in machine learning. Our\nmethod improves the approximation of the kernel ridge regressor / Gaussian\nprocess posterior mean over vanilla conjugate gradients and, allows computation\nof the posterior variance and the log marginal likelihood (evidence) without\nfurther overhead.\n", "versions": [{"version": "v1", "created": "Thu, 14 Nov 2019 11:38:05 GMT"}], "update_date": "2019-11-15", "authors_parsed": [["Bartels", "Simon", ""], ["Hennig", "Philipp", ""]]}, {"id": "1911.06057", "submitter": "Takayuki Osogami Ph.D.", "authors": "Takayuki Osogami", "title": "Supplementary material for Uncorrected least-squares temporal difference\n  with lambda-return", "comments": "9 pages, supplementary material for an AAAI-20 paper", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Here, we provide a supplementary material for Takayuki Osogami, \"Uncorrected\nleast-squares temporal difference with lambda-return,\" which appears in {\\it\nProceedings of the 34th AAAI Conference on Artificial Intelligence} (AAAI-20).\n", "versions": [{"version": "v1", "created": "Thu, 14 Nov 2019 12:18:34 GMT"}], "update_date": "2019-11-15", "authors_parsed": [["Osogami", "Takayuki", ""]]}, {"id": "1911.06105", "submitter": "Aaron Vose", "authors": "Aaron D. Vose, Jacob Balma, Damon Farnsworth, Kaylie Anderson, and\n  Yuri K. Peterson", "title": "PharML.Bind: Pharmacologic Machine Learning for Protein-Ligand\n  Interactions", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.BM cs.LG cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Is it feasible to create an analysis paradigm that can analyze and then\naccurately and quickly predict known drugs from experimental data? PharML.Bind\nis a machine learning toolkit which is able to accomplish this feat. Utilizing\ndeep neural networks and big data, PharML.Bind correlates\nexperimentally-derived drug affinities and protein-ligand X-ray structures to\ncreate novel predictions. The utility of PharML.Bind is in its application as a\nrapid, accurate, and robust prediction platform for discovery and personalized\nmedicine. This paper demonstrates that graph neural networks (GNNs) can be\ntrained to screen hundreds of thousands of compounds against thousands of\ntargets in minutes, a vastly shorter time than previous approaches. This\nmanuscript presents results from training and testing using the entirety of\nBindingDB after cleaning; this includes a test set with 19,708 X-ray structures\nand 247,633 drugs, leading to 2,708,151 unique protein-ligand pairings.\nPharML.Bind achieves a prodigious 98.3% accuracy on this test set in under 25\nminutes. PharML.Bind is premised on the following key principles: 1) speed and\na high enrichment factor per unit compute time, provided by high-quality\ntraining data combined with a novel GNN architecture and use of\nhigh-performance computing resources, 2) the ability to generalize to proteins\nand drugs outside of the training set, including those with unknown active\nsites, through the use of an active-site-agnostic GNN mapping, and 3) the\nability to be easily integrated as a component of increasingly-complex\nprediction and analysis pipelines. PharML.Bind represents a timely and\npractical approach to leverage the power of machine learning to efficiently\nanalyze and predict drug action on any practical scale and will provide utility\nin a variety of discovery and medical applications.\n", "versions": [{"version": "v1", "created": "Wed, 23 Oct 2019 23:32:44 GMT"}], "update_date": "2019-11-15", "authors_parsed": [["Vose", "Aaron D.", ""], ["Balma", "Jacob", ""], ["Farnsworth", "Damon", ""], ["Anderson", "Kaylie", ""], ["Peterson", "Yuri K.", ""]]}, {"id": "1911.06106", "submitter": "Fayyaz Minhas", "authors": "Sadaf Gull and Fayyaz Minhas", "title": "AMP0: Species-Specific Prediction of Anti-microbial Peptides using Zero\n  and Few Shot Learning", "comments": "Under journal submission, 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.BM cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The evolution of drug-resistant microbial species is one of the major\nchallenges to global health. The development of new antimicrobial treatments\nsuch as antimicrobial peptides needs to be accelerated to combat this threat.\nHowever, the discovery of novel antimicrobial peptides is hampered by\nlow-throughput biochemical assays. Computational techniques can be used for\nrapid screening of promising antimicrobial peptide candidates prior to testing\nin the wet lab. The vast majority of existing antimicrobial peptide predictors\nare non-targeted in nature, i.e., they can predict whether a given peptide\nsequence is antimicrobial, but they are unable to predict whether the sequence\ncan target a particular microbial species. In this work, we have developed a\ntargeted antimicrobial peptide activity predictor that can predict whether a\npeptide is effective against a given microbial species or not. This has been\nmade possible through zero-shot and few-shot machine learning. The proposed\npredictor called AMP0 takes in the peptide amino acid sequence and any\nN/C-termini modifications together with the genomic sequence of a target\nmicrobial species to generate targeted predictions. It is important to note\nthat the proposed method can generate predictions for species that are not part\nof its training set. The accuracy of predictions for novel test species can be\nfurther improved by providing a few example peptides for that species. Our\ncomputational cross-validation results show that the pro-posed scheme is\nparticularly effective for targeted antimicrobial prediction in comparison to\nexisting approaches and can be used for screening potential antimicrobial\npeptides in a targeted manner especially for cases in which the number of\ntraining examples is small. The webserver of the method is available at\nhttp://ampzero.pythonanywhere.com.\n", "versions": [{"version": "v1", "created": "Mon, 28 Oct 2019 08:27:28 GMT"}], "update_date": "2019-11-15", "authors_parsed": [["Gull", "Sadaf", ""], ["Minhas", "Fayyaz", ""]]}, {"id": "1911.06107", "submitter": "Joe Kileel", "authors": "Nathan Zelesko, Amit Moscovich, Joe Kileel, Amit Singer", "title": "Earthmover-based manifold learning for analyzing molecular conformation\n  spaces", "comments": "5 pages, 4 figures, 1 table", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.BM cs.LG eess.IV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we propose a novel approach for manifold learning that\ncombines the Earthmover's distance (EMD) with the diffusion maps method for\ndimensionality reduction. We demonstrate the potential benefits of this\napproach for learning shape spaces of proteins and other flexible\nmacromolecules using a simulated dataset of 3-D density maps that mimic the\nnon-uniform rotary motion of ATP synthase. Our results show that EMD-based\ndiffusion maps require far fewer samples to recover the intrinsic geometry than\nthe standard diffusion maps algorithm that is based on the Euclidean distance.\nTo reduce the computational burden of calculating the EMD for all volume pairs,\nwe employ a wavelet-based approximation to the EMD which reduces the\ncomputation of the pairwise EMDs to a computation of pairwise weighted-$\\ell_1$\ndistances between wavelet coefficient vectors.\n", "versions": [{"version": "v1", "created": "Wed, 16 Oct 2019 01:38:52 GMT"}], "update_date": "2019-11-15", "authors_parsed": [["Zelesko", "Nathan", ""], ["Moscovich", "Amit", ""], ["Kileel", "Joe", ""], ["Singer", "Amit", ""]]}, {"id": "1911.06111", "submitter": "Andrew O. Arnold", "authors": "Andrew O. Arnold, William W. Cohen", "title": "Instance-based Transfer Learning for Multilingual Deep Retrieval", "comments": null, "journal-ref": "The Web Conference Workshop on Multilingual Search, 2021", "doi": null, "report-no": null, "categories": "cs.CL cs.IR cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We focus on the problem of search in the multilingual setting. Examining the\nproblems of next-sentence prediction and inverse cloze, we show that at large\nscale, instance-based transfer learning is surprisingly effective in the\nmultilingual setting, leading to positive transfer on all of the 35 target\nlanguages and two tasks tested. We analyze this improvement and argue that the\nmost natural explanation, namely direct vocabulary overlap between languages,\nonly partially explains the performance gains: in fact, we demonstrate\ntarget-language improvement can occur after adding data from an auxiliary\nlanguage even with no vocabulary in common with the target. This surprising\nresult is due to the effect of transitive vocabulary overlaps between pairs of\nauxiliary and target languages.\n", "versions": [{"version": "v1", "created": "Fri, 8 Nov 2019 22:23:30 GMT"}, {"version": "v2", "created": "Mon, 6 Apr 2020 18:11:37 GMT"}, {"version": "v3", "created": "Thu, 15 Apr 2021 15:22:31 GMT"}], "update_date": "2021-04-16", "authors_parsed": [["Arnold", "Andrew O.", ""], ["Cohen", "William W.", ""]]}, {"id": "1911.06118", "submitter": "Jayashree P.", "authors": "P. Jayashree, Ballijepalli Shreya, and P.K. Srijith", "title": "Learning Multi-Sense Word Distributions using Approximate\n  Kullback-Leibler Divergence", "comments": "7 pages, 4 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Learning word representations has garnered greater attention in the recent\npast due to its diverse text applications. Word embeddings encapsulate the\nsyntactic and semantic regularities of sentences. Modelling word embedding as\nmulti-sense gaussian mixture distributions, will additionally capture\nuncertainty and polysemy of words. We propose to learn the Gaussian mixture\nrepresentation of words using a Kullback-Leibler (KL) divergence based\nobjective function. The KL divergence based energy function provides a better\ndistance metric which can effectively capture entailment and distribution\nsimilarity among the words. Due to the intractability of KL divergence for\nGaussian mixture, we go for a KL approximation between Gaussian mixtures. We\nperform qualitative and quantitative experiments on benchmark word similarity\nand entailment datasets which demonstrate the effectiveness of the proposed\napproach.\n", "versions": [{"version": "v1", "created": "Tue, 12 Nov 2019 06:59:38 GMT"}], "update_date": "2019-11-15", "authors_parsed": [["Jayashree", "P.", ""], ["Shreya", "Ballijepalli", ""], ["Srijith", "P. K.", ""]]}, {"id": "1911.06129", "submitter": "Jonathan Baxter", "authors": "Jonathan Baxter", "title": "A Bayesian/Information Theoretic Model of Bias Learning", "comments": null, "journal-ref": "COLT 96 Proceedings of the ninth annual conference on\n  Computational learning theory (1996) Pages 77-88", "doi": "10.1145/238061.238071", "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper the problem of learning appropriate bias for an environment of\nrelated tasks is examined from a Bayesian perspective. The environment of\nrelated tasks is shown to be naturally modelled by the concept of an {\\em\nobjective} prior distribution. Sampling from the objective prior corresponds to\nsampling different learning tasks from the environment. It is argued that for\nmany common machine learning problems, although we don't know the true\n(objective) prior for the problem, we do have some idea of a set of possible\npriors to which the true prior belongs. It is shown that under these\ncircumstances a learner can use Bayesian inference to learn the true prior by\nsampling from the objective prior. Bounds are given on the amount of\ninformation required to learn a task when it is simultaneously learnt with\nseveral other tasks. The bounds show that if the learner has little knowledge\nof the true prior, and the dimensionality of the true prior is small, then\nsampling multiple tasks is highly advantageous.\n", "versions": [{"version": "v1", "created": "Thu, 14 Nov 2019 14:34:58 GMT"}], "update_date": "2019-11-15", "authors_parsed": [["Baxter", "Jonathan", ""]]}, {"id": "1911.06137", "submitter": "Yu Cao", "authors": "Yu Cao, Meng Fang, Baosheng Yu, Joey Tianyi Zhou", "title": "Unsupervised Domain Adaptation on Reading Comprehension", "comments": "8 pages, 6 figures, 5 tables, Accepted by AAAI 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Reading comprehension (RC) has been studied in a variety of datasets with the\nboosted performance brought by deep neural networks. However, the\ngeneralization capability of these models across different domains remains\nunclear. To alleviate this issue, we are going to investigate unsupervised\ndomain adaptation on RC, wherein a model is trained on labeled source domain\nand to be applied to the target domain with only unlabeled samples. We first\nshow that even with the powerful BERT contextual representation, the\nperformance is still unsatisfactory when the model trained on one dataset is\ndirectly applied to another target dataset. To solve this, we provide a novel\nconditional adversarial self-training method (CASe). Specifically, our approach\nleverages a BERT model fine-tuned on the source dataset along with the\nconfidence filtering to generate reliable pseudo-labeled samples in the target\ndomain for self-training. On the other hand, it further reduces domain\ndistribution discrepancy through conditional adversarial learning across\ndomains. Extensive experiments show our approach achieves comparable accuracy\nto supervised models on multiple large-scale benchmark datasets.\n", "versions": [{"version": "v1", "created": "Wed, 13 Nov 2019 00:54:39 GMT"}, {"version": "v2", "created": "Mon, 13 Jan 2020 02:19:15 GMT"}, {"version": "v3", "created": "Sat, 25 Jan 2020 10:59:15 GMT"}, {"version": "v4", "created": "Thu, 7 May 2020 09:37:36 GMT"}, {"version": "v5", "created": "Mon, 27 Jul 2020 02:44:59 GMT"}], "update_date": "2020-07-28", "authors_parsed": [["Cao", "Yu", ""], ["Fang", "Meng", ""], ["Yu", "Baosheng", ""], ["Zhou", "Joey Tianyi", ""]]}, {"id": "1911.06147", "submitter": "Sergio Gast\\'on Burdisso", "authors": "Sergio G. Burdisso, Marcelo Errecalde, Manuel Montes-y-G\\'omez", "title": "t-SS3: a text classifier with dynamic n-grams for early risk detection\n  over text streams", "comments": "Highlights: (*) A classifier that is able to dynamically learn and\n  recognize important word n-grams. (*) A novel text classifier having the\n  ability to visually explain its rationale. (*) Support for incremental\n  learning and text classification over streams. (*) Efficient model for\n  addressing early risk detection problems", "journal-ref": "Pattern Recognition Letters, Elsevier, 2020", "doi": "10.1016/j.patrec.2020.07.001", "report-no": null, "categories": "cs.CL cs.IR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A recently introduced classifier, called SS3, has shown to be well suited to\ndeal with early risk detection (ERD) problems on text streams. It obtained\nstate-of-the-art performance on early depression and anorexia detection on\nReddit in the CLEF's eRisk open tasks. SS3 was created to deal with ERD\nproblems naturally since: it supports incremental training and classification\nover text streams, and it can visually explain its rationale. However, SS3\nprocesses the input using a bag-of-word model lacking the ability to recognize\nimportant word sequences. This aspect could negatively affect the\nclassification performance and also reduces the descriptiveness of visual\nexplanations. In the standard document classification field, it is very common\nto use word n-grams to try to overcome some of these limitations.\nUnfortunately, when working with text streams, using n-grams is not trivial\nsince the system must learn and recognize which n-grams are important \"on the\nfly\". This paper introduces t-SS3, an extension of SS3 that allows it to\nrecognize useful patterns over text streams dynamically. We evaluated our model\nin the eRisk 2017 and 2018 tasks on early depression and anorexia detection.\nExperimental results suggest that t-SS3 is able to improve both current results\nand the richness of visual explanations.\n", "versions": [{"version": "v1", "created": "Mon, 11 Nov 2019 22:06:40 GMT"}, {"version": "v2", "created": "Wed, 6 May 2020 23:04:03 GMT"}], "update_date": "2020-07-14", "authors_parsed": [["Burdisso", "Sergio G.", ""], ["Errecalde", "Marcelo", ""], ["Montes-y-G\u00f3mez", "Manuel", ""]]}, {"id": "1911.06154", "submitter": "Ahmed El-Kishky", "authors": "Ahmed El-Kishky, Vishrav Chaudhary, Francisco Guzman, Philipp Koehn", "title": "CCAligned: A Massive Collection of Cross-Lingual Web-Document Pairs", "comments": "EMNLP 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Cross-lingual document alignment aims to identify pairs of documents in two\ndistinct languages that are of comparable content or translations of each\nother. In this paper, we exploit the signals embedded in URLs to label web\ndocuments at scale with an average precision of 94.5% across different language\npairs. We mine sixty-eight snapshots of the Common Crawl corpus and identify\nweb document pairs that are translations of each other. We release a new web\ndataset consisting of over 392 million URL pairs from Common Crawl covering\ndocuments in 8144 language pairs of which 137 pairs include English. In\naddition to curating this massive dataset, we introduce baseline methods that\nleverage cross-lingual representations to identify aligned documents based on\ntheir textual content. Finally, we demonstrate the value of this parallel\ndocuments dataset through a downstream task of mining parallel sentences and\nmeasuring the quality of machine translations from models trained on this mined\ndata. Our objective in releasing this dataset is to foster new research in\ncross-lingual NLP across a variety of low, medium, and high-resource languages.\n", "versions": [{"version": "v1", "created": "Sun, 10 Nov 2019 02:09:11 GMT"}, {"version": "v2", "created": "Sun, 11 Oct 2020 06:00:35 GMT"}], "update_date": "2020-10-13", "authors_parsed": [["El-Kishky", "Ahmed", ""], ["Chaudhary", "Vishrav", ""], ["Guzman", "Francisco", ""], ["Koehn", "Philipp", ""]]}, {"id": "1911.06155", "submitter": "Jianmin Guo", "authors": "Jianmin Guo, Yue Zhao, Quan Zhang, Yu Jiang", "title": "RNN-Test: Towards Adversarial Testing for Recurrent Neural Network\n  Systems", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  While massive efforts have been investigated in adversarial testing of\nconvolutional neural networks (CNN), testing for recurrent neural networks\n(RNN) is still limited and leaves threats for vast sequential application\ndomains. In this paper, we propose an adversarial testing framework RNN-Test\nfor RNN systems, focusing on the main sequential domains, not only\nclassification tasks. First, we design a novel search methodology customized\nfor RNN models by maximizing the inconsistency of RNN states to produce\nadversarial inputs. Next, we introduce two state-based coverage metrics\naccording to the distinctive structure of RNNs to explore more inference\nlogics. Finally, RNN-Test solves the joint optimization problem to maximize\nstate inconsistency and state coverage, and crafts adversarial inputs for\nvarious tasks of different kinds of inputs.\n  For evaluations, we apply RNN-Test on three sequential models of common RNN\nstructures. On the tested models, the RNN-Test approach is demonstrated to be\ncompetitive in generating adversarial inputs, outperforming FGSM-based and\nDLFuzz-based methods to reduce the model performance more sharply with 2.78% to\n32.5% higher success (or generation) rate. RNN-Test could also achieve 52.65%\nto 66.45% higher adversary rate on MNIST-LSTM model than relevant work testRNN.\nCompared with the neuron coverage, the proposed state coverage metrics as\nguidance excel with 4.17% to 97.22% higher success (or generation) rate.\n", "versions": [{"version": "v1", "created": "Mon, 11 Nov 2019 05:30:53 GMT"}, {"version": "v2", "created": "Fri, 8 Jan 2021 03:28:00 GMT"}], "update_date": "2021-01-11", "authors_parsed": [["Guo", "Jianmin", ""], ["Zhao", "Yue", ""], ["Zhang", "Quan", ""], ["Jiang", "Yu", ""]]}, {"id": "1911.06156", "submitter": "Dhanasekar Sundararaman", "authors": "Dhanasekar Sundararaman, Vivek Subramanian, Guoyin Wang, Shijing Si,\n  Dinghan Shen, Dong Wang, Lawrence Carin", "title": "Syntax-Infused Transformer and BERT models for Machine Translation and\n  Natural Language Understanding", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Attention-based models have shown significant improvement over traditional\nalgorithms in several NLP tasks. The Transformer, for instance, is an\nillustrative example that generates abstract representations of tokens inputted\nto an encoder based on their relationships to all tokens in a sequence. Recent\nstudies have shown that although such models are capable of learning syntactic\nfeatures purely by seeing examples, explicitly feeding this information to deep\nlearning models can significantly enhance their performance. Leveraging\nsyntactic information like part of speech (POS) may be particularly beneficial\nin limited training data settings for complex models such as the Transformer.\nWe show that the syntax-infused Transformer with multiple features achieves an\nimprovement of 0.7 BLEU when trained on the full WMT 14 English to German\ntranslation dataset and a maximum improvement of 1.99 BLEU points when trained\non a fraction of the dataset. In addition, we find that the incorporation of\nsyntax into BERT fine-tuning outperforms baseline on a number of downstream\ntasks from the GLUE benchmark.\n", "versions": [{"version": "v1", "created": "Sun, 10 Nov 2019 04:42:13 GMT"}], "update_date": "2019-11-15", "authors_parsed": [["Sundararaman", "Dhanasekar", ""], ["Subramanian", "Vivek", ""], ["Wang", "Guoyin", ""], ["Si", "Shijing", ""], ["Shen", "Dinghan", ""], ["Wang", "Dong", ""], ["Carin", "Lawrence", ""]]}, {"id": "1911.06164", "submitter": "Jonathan Baxter", "authors": "Jonathan Baxter", "title": "Learning Model Bias", "comments": null, "journal-ref": "Advances in Neural Information Processing Systems 8, 1995, 169-175", "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper the problem of {\\em learning} appropriate domain-specific bias\nis addressed. It is shown that this can be achieved by learning many related\ntasks from the same domain, and a theorem is given bounding the number tasks\nthat must be learnt. A corollary of the theorem is that if the tasks are known\nto possess a common {\\em internal representation} or {\\em preprocessing} then\nthe number of examples required per task for good generalisation when learning\n$n$ tasks simultaneously scales like $O(a + \\frac{b}{n})$, where $O(a)$ is a\nbound on the minimum number of examples required to learn a single task, and\n$O(a + b)$ is a bound on the number of examples required to learn each task\nindependently. An experiment providing strong qualitative support for the\ntheoretical results is reported.\n", "versions": [{"version": "v1", "created": "Thu, 14 Nov 2019 15:07:08 GMT"}], "update_date": "2019-11-15", "authors_parsed": [["Baxter", "Jonathan", ""]]}, {"id": "1911.06174", "submitter": "Tongyang Xu", "authors": "Tongyang Xu and Izzat Darwazeh", "title": "Deep Learning for Over-the-Air Non-Orthogonal Signal Classification", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.SP cs.LG cs.SY eess.SY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Non-cooperative communications, where a receiver can automatically\ndistinguish and classify transmitted signal formats prior to detection, are\ndesirable for low-cost and low-latency systems. This work focuses on the deep\nlearning enabled blind classification of multi-carrier signals covering their\northogonal and non-orthogonal varieties. We define two signal groups, in which\nType-I includes signals with large feature diversity while Type-II has strong\nfeature similarity. We evaluate time-domain and frequency-domain convolutional\nneural network (CNN) models in simulation with wireless channel/hardware\nimpairments. Simulation results reveal that the time-domain neural network\ntraining is more efficient than its frequency-domain counterpart in terms of\nclassification accuracy and computational complexity. In addition, the\ntime-domain CNN models can classify Type-I signals with high accuracy but\nreduced performance in Type-II signals because of their high signal feature\nsimilarity. Experimental systems are designed and tested, using software\ndefined radio (SDR) devices, operated for different signal formats to form full\nwireless communication links with line-of-sight and non-line-of-sight\nscenarios. Testing, using four different time-domain CNN models, showed the\npre-trained CNN models to have limited efficiency and utility due to the\nmismatch between the analytical/simulation and practical/real-world\nenvironments. Transfer learning, which is an approach to fine-tune learnt\nsignal features, is applied based on measured over-the-air time-domain signal\nsamples. Experimental results indicate that transfer learning based CNN can\nefficiently distinguish different signal formats in both line-of-sight and\nnon-line-of-sight scenarios with great accuracy improvement relative to the\nnon-transfer-learning approaches.\n", "versions": [{"version": "v1", "created": "Thu, 14 Nov 2019 15:30:53 GMT"}], "update_date": "2019-11-15", "authors_parsed": [["Xu", "Tongyang", ""], ["Darwazeh", "Izzat", ""]]}, {"id": "1911.06181", "submitter": "Teppei Suzuki", "authors": "Teppei Suzuki and Ikuro Sato", "title": "Adversarial Transformations for Semi-Supervised Learning", "comments": "Accepted by AAAI 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a Regularization framework based on Adversarial Transformations\n(RAT) for semi-supervised learning. RAT is designed to enhance robustness of\nthe output distribution of class prediction for a given data against input\nperturbation. RAT is an extension of Virtual Adversarial Training (VAT) in such\na way that RAT adversarialy transforms data along the underlying data\ndistribution by a rich set of data transformation functions that leave class\nlabel invariant, whereas VAT simply produces adversarial additive noises. In\naddition, we verified that a technique of gradually increasing of perturbation\nregion further improve the robustness. In experiments, we show that RAT\nsignificantly improves classification performance on CIFAR-10 and SVHN compared\nto existing regularization methods under standard semi-supervised image\nclassification settings.\n", "versions": [{"version": "v1", "created": "Wed, 13 Nov 2019 08:01:47 GMT"}, {"version": "v2", "created": "Mon, 18 Nov 2019 06:53:12 GMT"}], "update_date": "2019-11-19", "authors_parsed": [["Suzuki", "Teppei", ""], ["Sato", "Ikuro", ""]]}, {"id": "1911.06182", "submitter": "Itzik Malkiel", "authors": "Itzik Malkiel, Lior Wolf", "title": "MML: Maximal Multiverse Learning for Robust Fine-Tuning of Language\n  Models", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent state-of-the-art language models utilize a two-phase training\nprocedure comprised of (i) unsupervised pre-training on unlabeled text, and\n(ii) fine-tuning for a specific supervised task. More recently, many studies\nhave been focused on trying to improve these models by enhancing the\npre-training phase, either via better choice of hyperparameters or by\nleveraging an improved formulation. However, the pre-training phase is\ncomputationally expensive and often done on private datasets. In this work, we\npresent a method that leverages BERT's fine-tuning phase to its fullest, by\napplying an extensive number of parallel classifier heads, which are enforced\nto be orthogonal, while adaptively eliminating the weaker heads during\ntraining. Our method allows the model to converge to an optimal number of\nparallel classifiers, depending on the given dataset at hand.\n  We conduct an extensive inter- and intra-dataset evaluations, showing that\nour method improves the robustness of BERT, sometimes leading to a +9\\% gain in\naccuracy. These results highlight the importance of a proper fine-tuning\nprocedure, especially for relatively smaller-sized datasets. Our code is\nattached as supplementary and our models will be made completely public.\n", "versions": [{"version": "v1", "created": "Tue, 5 Nov 2019 21:21:40 GMT"}], "update_date": "2019-11-15", "authors_parsed": [["Malkiel", "Itzik", ""], ["Wolf", "Lior", ""]]}, {"id": "1911.06191", "submitter": "Yingce Xia", "authors": "Yingce Xia, Xu Tan, Fei Tian, Fei Gao, Weicong Chen, Yang Fan, Linyuan\n  Gong, Yichong Leng, Renqian Luo, Yiren Wang, Lijun Wu, Jinhua Zhu, Tao Qin,\n  Tie-Yan Liu", "title": "Microsoft Research Asia's Systems for WMT19", "comments": "Accepted to \"Fourth Conference on Machine Translation (WMT19)\"", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG stat.ML", "license": "http://creativecommons.org/publicdomain/zero/1.0/", "abstract": "  We Microsoft Research Asia made submissions to 11 language directions in the\nWMT19 news translation tasks. We won the first place for 8 of the 11 directions\nand the second place for the other three. Our basic systems are built on\nTransformer, back translation and knowledge distillation. We integrate several\nof our rececent techniques to enhance the baseline systems: multi-agent dual\nlearning (MADL), masked sequence-to-sequence pre-training (MASS), neural\narchitecture optimization (NAO), and soft contextual data augmentation (SCA).\n", "versions": [{"version": "v1", "created": "Thu, 7 Nov 2019 03:55:53 GMT"}], "update_date": "2019-11-15", "authors_parsed": [["Xia", "Yingce", ""], ["Tan", "Xu", ""], ["Tian", "Fei", ""], ["Gao", "Fei", ""], ["Chen", "Weicong", ""], ["Fan", "Yang", ""], ["Gong", "Linyuan", ""], ["Leng", "Yichong", ""], ["Luo", "Renqian", ""], ["Wang", "Yiren", ""], ["Wu", "Lijun", ""], ["Zhu", "Jinhua", ""], ["Qin", "Tao", ""], ["Liu", "Tie-Yan", ""]]}, {"id": "1911.06192", "submitter": "Li Zhou", "authors": "Li Zhou and Kevin Small", "title": "Multi-domain Dialogue State Tracking as Dynamic Knowledge Graph Enhanced\n  Question Answering", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Multi-domain dialogue state tracking (DST) is a critical component for\nconversational AI systems. The domain ontology (i.e., specification of domains,\nslots, and values) of a conversational AI system is generally incomplete,\nmaking the capability for DST models to generalize to new slots, values, and\ndomains during inference imperative. In this paper, we propose to model\nmulti-domain DST as a question answering problem, referred to as Dialogue State\nTracking via Question Answering (DSTQA). Within DSTQA, each turn generates a\nquestion asking for the value of a (domain, slot) pair, thus making it\nnaturally extensible to unseen domains, slots, and values. Additionally, we use\na dynamically-evolving knowledge graph to explicitly learn relationships\nbetween (domain, slot) pairs. Our model has a 5.80% and 12.21% relative\nimprovement over the current state-of-the-art model on MultiWOZ 2.0 and\nMultiWOZ 2.1 datasets, respectively. Additionally, our model consistently\noutperforms the state-of-the-art model in domain adaptation settings. (Code is\nreleased at https://github.com/alexa/dstqa )\n", "versions": [{"version": "v1", "created": "Thu, 7 Nov 2019 10:00:16 GMT"}, {"version": "v2", "created": "Sat, 20 Jun 2020 21:07:14 GMT"}], "update_date": "2020-06-23", "authors_parsed": [["Zhou", "Li", ""], ["Small", "Kevin", ""]]}, {"id": "1911.06193", "submitter": "Ravi Vadlamani", "authors": "B. Shravan Kumar, Vadlamani Ravi and Rishabh Miglani", "title": "Predicting Indian stock market using the psycho-linguistic features of\n  financial news", "comments": "45 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-fin.ST cs.LG", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Financial forecasting using news articles is an emerging field. In this\npaper, we proposed hybrid intelligent models for stock market prediction using\nthe psycholinguistic variables (LIWC and TAALES) extracted from news articles\nas predictor variables. For prediction purpose, we employed various intelligent\ntechniques such as Multilayer Perceptron (MLP), Group Method of Data Handling\n(GMDH), General Regression Neural Network (GRNN), Random Forest (RF), Quantile\nRegression Random Forest (QRRF), Classification and regression tree (CART) and\nSupport Vector Regression (SVR). We experimented on the data of 12 companies\nstocks, which are listed in the Bombay Stock Exchange (BSE). We employed\nchi-squared and maximum relevance and minimum redundancy (MRMR) feature\nselection techniques on the psycho-linguistic features obtained from the new\narticles etc. After extensive experimentation, using the Diebold-Mariano test,\nwe conclude that GMDH and GRNN are statistically the best techniques in that\norder with respect to the MAPE and NRMSE values.\n", "versions": [{"version": "v1", "created": "Thu, 7 Nov 2019 11:07:00 GMT"}], "update_date": "2019-11-15", "authors_parsed": [["Kumar", "B. Shravan", ""], ["Ravi", "Vadlamani", ""], ["Miglani", "Rishabh", ""]]}, {"id": "1911.06194", "submitter": "Xisen Jin", "authors": "Xisen Jin, Zhongyu Wei, Junyi Du, Xiangyang Xue, Xiang Ren", "title": "Towards Hierarchical Importance Attribution: Explaining Compositional\n  Semantics for Neural Sequence Models", "comments": "ICLR 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The impressive performance of neural networks on natural language processing\ntasks attributes to their ability to model complicated word and phrase\ncompositions. To explain how the model handles semantic compositions, we study\nhierarchical explanation of neural network predictions. We identify\nnon-additivity and context independent importance attributions within\nhierarchies as two desirable properties for highlighting word and phrase\ncompositions. We show some prior efforts on hierarchical explanations, e.g.\ncontextual decomposition, do not satisfy the desired properties mathematically,\nleading to inconsistent explanation quality in different models. In this paper,\nwe start by proposing a formal and general way to quantify the importance of\neach word and phrase. Following the formulation, we propose Sampling and\nContextual Decomposition (SCD) algorithm and Sampling and Occlusion (SOC)\nalgorithm. Human and metrics evaluation on both LSTM models and BERT\nTransformer models on multiple datasets show that our algorithms outperform\nprior hierarchical explanation algorithms. Our algorithms help to visualize\nsemantic composition captured by models, extract classification rules and\nimprove human trust of models. Project page: https://inklab.usc.edu/hiexpl/\n", "versions": [{"version": "v1", "created": "Fri, 8 Nov 2019 03:25:04 GMT"}, {"version": "v2", "created": "Mon, 15 Jun 2020 05:47:05 GMT"}], "update_date": "2020-06-16", "authors_parsed": [["Jin", "Xisen", ""], ["Wei", "Zhongyu", ""], ["Du", "Junyi", ""], ["Xue", "Xiangyang", ""], ["Ren", "Xiang", ""]]}, {"id": "1911.06197", "submitter": "Vivian Chou", "authors": "Vivian T. Chou, LeAnna Kent, Joel A. G\\'ongora, Sam Ballerini, Carl D.\n  Hoover", "title": "Towards automatic extractive text summarization of A-133 Single Audit\n  reports with machine learning", "comments": "8 pages, first version", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The rapid growth of text data has motivated the development of\nmachine-learning based automatic text summarization strategies that concisely\ncapture the essential ideas in a larger text. This study aimed to devise an\nextractive summarization method for A-133 Single Audits, which assess if\nrecipients of federal grants are compliant with program requirements for use of\nfederal funding. Currently, these voluminous audits must be manually analyzed\nby officials for oversight, risk management, and prioritization purposes.\nAutomated summarization has the potential to streamline these processes.\nAnalysis focused on the \"Findings\" section of ~20,000 Single Audits spanning\n2016-2018. Following text preprocessing and GloVe embedding, sentence-level\nk-means clustering was performed to partition sentences by topic and to\nestablish the importance of each sentence. For each audit, key summary\nsentences were extracted by proximity to cluster centroids. Summaries were\njudged by non-expert human evaluation and compared to human-generated summaries\nusing the ROUGE metric. Though the goal was to fully automate summarization of\nA-133 audits, human input was required at various stages due to large\nvariability in audit writing style, content, and context. Examples of human\ninputs include the number of clusters, the choice to keep or discard certain\nclusters based on their content relevance, and the definition of a top\nsentence. Overall, this approach made progress towards automated extractive\nsummaries of A-133 audits, with future work to focus on full automation and\nimproving summary consistency. This work highlights the inherent difficulty and\nsubjective nature of automated summarization in a real-world application.\n", "versions": [{"version": "v1", "created": "Fri, 8 Nov 2019 14:49:25 GMT"}], "update_date": "2019-11-15", "authors_parsed": [["Chou", "Vivian T.", ""], ["Kent", "LeAnna", ""], ["G\u00f3ngora", "Joel A.", ""], ["Ballerini", "Sam", ""], ["Hoover", "Carl D.", ""]]}, {"id": "1911.06213", "submitter": "Simone Gramsch", "authors": "Simone Gramsch and Alex Sarishvili and Andre Schmei{\\ss}er", "title": "Analysis of the fiber laydown quality in spunbond processes with\n  simulation experiments evaluated by blocked neural networks", "comments": "12 pages, 23 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a simulation framework for spunbond processes and use a design of\nexperiments to investigate the cause-and-effect-relations of process and\nmaterial parameters onto the fiber laydown on a conveyor belt. The virtual\nexperiments are analyzed by a blocked neural network. This forms the basis for\nthe prediction of the fiber laydown characteristics and enables a quick ranking\nof the significance of the influencing effects. We conclude our research by an\nanalysis of the nonlinear cause-and-effect relations.\n", "versions": [{"version": "v1", "created": "Thu, 14 Nov 2019 16:10:01 GMT"}, {"version": "v2", "created": "Wed, 22 Jan 2020 12:45:07 GMT"}], "update_date": "2020-01-23", "authors_parsed": [["Gramsch", "Simone", ""], ["Sarishvili", "Alex", ""], ["Schmei\u00dfer", "Andre", ""]]}, {"id": "1911.06215", "submitter": "Huiming Zhang", "authors": "Xiaowei Yang, Huiming Zhang, Haoyu Wei, Shouzheng Zhang", "title": "Sparse Density Estimation with Measurement Errors", "comments": "34 pages, 4 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST cs.LG stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper aims to build an estimate of an unknown density of the data with\nmeasurement error as a linear combination of functions from a dictionary.\nInspired by the penalization approach, we propose the weighted Elastic-net\npenalized minimal $\\ell_2$-distance method for sparse coefficients estimation,\nwhere the adaptive weights come from sharp concentration inequalities. The\noptimal weighted tuning parameters are obtained by the first-order conditions\nholding with a high probability. Under local coherence or minimal eigenvalue\nassumptions, non-asymptotical oracle inequalities are derived. These\ntheoretical results are transposed to obtain the support recovery with a high\nprobability. Then, some numerical experiments for discrete and continuous\ndistributions confirm the significant improvement obtained by our procedure\nwhen compared with other conventional approaches. Finally, the application is\nperformed in a meteorology data set. It shows that our method has potency and\nsuperiority of detecting the shape of multi-mode density compared with other\nconventional approaches.\n", "versions": [{"version": "v1", "created": "Thu, 14 Nov 2019 16:13:11 GMT"}, {"version": "v2", "created": "Sat, 8 Feb 2020 15:56:39 GMT"}, {"version": "v3", "created": "Mon, 6 Jul 2020 13:33:06 GMT"}], "update_date": "2020-07-07", "authors_parsed": [["Yang", "Xiaowei", ""], ["Zhang", "Huiming", ""], ["Wei", "Haoyu", ""], ["Zhang", "Shouzheng", ""]]}, {"id": "1911.06216", "submitter": "Jeremiah Johnson", "authors": "Jeremiah W. Johnson", "title": "Detecting Invasive Ductal Carcinoma with Semi-Supervised Conditional\n  GANs", "comments": "5 pages, 3 figures", "journal-ref": "Proceedings of the Future Technologies Conference (FTC) 2020, vol.\n  3, pp.113-120", "doi": "10.1007/978-3-030-63092-8", "report-no": null, "categories": "eess.IV cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Invasive ductal carcinoma (IDC) comprises nearly 80% of all breast cancers.\nThe detection of IDC is a necessary preprocessing step in determining the\naggressiveness of the cancer, determining treatment protocols, and predicting\npatient outcomes, and is usually performed manually by an expert pathologist.\nHere, we describe a novel algorithm for automatically detecting IDC using\nsemi-supervised conditional generative adversarial networks (cGANs). The\nframework is simple and effective at improving scores on a range of metrics\nover a baseline CNN.\n", "versions": [{"version": "v1", "created": "Thu, 14 Nov 2019 16:16:20 GMT"}, {"version": "v2", "created": "Tue, 30 Mar 2021 20:30:36 GMT"}], "update_date": "2021-04-01", "authors_parsed": [["Johnson", "Jeremiah W.", ""]]}, {"id": "1911.06217", "submitter": "Tobias Skovgaard Jepsen", "authors": "Tobias Skovgaard Jepsen, Christian S. Jensen, Thomas Dyhre Nielsen", "title": "On Network Embedding for Machine Learning on Road Networks: A Case Study\n  on the Danish Road Network", "comments": "Best Paper at the 3rd IEEE International Workshop on Big Spatial Data\n  (BSD 2018)", "journal-ref": "2018 IEEE International Conference on Big Data (Big Data), 2018,\n  pp. 3422-3431", "doi": "10.1109/BigData.2018.8622416", "report-no": null, "categories": "cs.LG cs.DB stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Road networks are a type of spatial network, where edges may be associated\nwith qualitative information such as road type and speed limit. Unfortunately,\nsuch information is often incomplete; for instance, OpenStreetMap only has\nspeed limits for 13% of all Danish road segments. This is problematic for\nanalysis tasks that rely on such information for machine learning. To enable\nmachine learning in such circumstances, one may consider the application of\nnetwork embedding methods to extract structural information from the network.\nHowever, these methods have so far mostly been used in the context of social\nnetworks, which differ significantly from road networks in terms of, e.g., node\ndegree and level of homophily (which are key to the performance of many network\nembedding methods). We analyze the use of network embedding methods,\nspecifically node2vec, for learning road segment embeddings in road networks.\nDue to the often limited availability of information on other relevant road\ncharacteristics, the analysis focuses on leveraging the spatial network\nstructure. Our results suggest that network embedding methods can indeed be\nused for deriving relevant network features (that may, e.g, be used for\npredicting speed limits), but that the qualities of the embeddings differ from\nembeddings for social networks.\n", "versions": [{"version": "v1", "created": "Thu, 14 Nov 2019 16:18:36 GMT"}, {"version": "v2", "created": "Fri, 15 Nov 2019 10:51:56 GMT"}], "update_date": "2019-11-18", "authors_parsed": [["Jepsen", "Tobias Skovgaard", ""], ["Jensen", "Christian S.", ""], ["Nielsen", "Thomas Dyhre", ""]]}, {"id": "1911.06239", "submitter": "Aditya Narayan Ravi", "authors": "Aditya Narayan Ravi, Pranav Poduval and Dr. Sharayu Moharir", "title": "Unreliable Multi-Armed Bandits: A Novel Approach to Recommendation\n  Systems", "comments": "4 pages, 4 figures, Aditya Narayan Ravi and Pranav Poduval have equal\n  contribution", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG stat.AP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We use a novel modification of Multi-Armed Bandits to create a new model for\nrecommendation systems. We model the recommendation system as a bandit seeking\nto maximize reward by pulling on arms with unknown rewards. The catch however\nis that this bandit can only access these arms through an unreliable\nintermediate that has some level of autonomy while choosing its arms. For\nexample, in a streaming website the user has a lot of autonomy while choosing\ncontent they want to watch. The streaming sites can use targeted advertising as\na means to bias opinions of these users. Here the streaming site is the bandit\naiming to maximize reward and the user is the unreliable intermediate. We model\nthe intermediate as accessing states via a Markov chain. The bandit is allowed\nto perturb this Markov chain. We prove fundamental theorems for this setting\nafter which we show a close-to-optimal Explore-Commit algorithm.\n", "versions": [{"version": "v1", "created": "Thu, 14 Nov 2019 16:55:29 GMT"}], "update_date": "2019-11-15", "authors_parsed": [["Ravi", "Aditya Narayan", ""], ["Poduval", "Pranav", ""], ["Moharir", "Dr. Sharayu", ""]]}, {"id": "1911.06241", "submitter": "Xiaolei Lu", "authors": "Xiaolei Lu and Bin Ni", "title": "BERT-CNN: a Hierarchical Patent Classifier Based on a Pre-Trained\n  Language Model", "comments": "in Chinese", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The automatic classification is a process of automatically assigning text\ndocuments to predefined categories. An accurate automatic patent classifier is\ncrucial to patent inventors and patent examiners in terms of intellectual\nproperty protection, patent management, and patent information retrieval. We\npresent BERT-CNN, a hierarchical patent classifier based on pre-trained\nlanguage model by training the national patent application documents collected\nfrom the State Information Center, China. The experimental results show that\nBERT-CNN achieves 84.3% accuracy, which is far better than the two compared\nbaseline methods, Convolutional Neural Networks and Recurrent Neural Networks.\nWe didn't apply our model to the third and fourth hierarchical level of the\nInternational Patent Classification - \"subclass\" and \"group\".The visualization\nof the Attention Mechanism shows that BERT-CNN obtains new state-of-the-art\nresults in representing vocabularies and semantics. This article demonstrates\nthe practicality and effectiveness of BERT-CNN in the field of automatic patent\nclassification.\n", "versions": [{"version": "v1", "created": "Sun, 3 Nov 2019 07:21:41 GMT"}], "update_date": "2019-11-15", "authors_parsed": [["Lu", "Xiaolei", ""], ["Ni", "Bin", ""]]}, {"id": "1911.06242", "submitter": "Fabrizio Ruffini", "authors": "Alessandro Betti (1), Emanuele Crisostomi (2), Gianluca Paolinelli\n  (3), Antonio Piazzi (1), Fabrizio Ruffini (1) and Mauro Tucci (2) ((1) i-EM\n  S.r.l., (2) Department of Energy, Systems, Territory and Constructions\n  Engineering, University of Pisa and (3) Pure Power Control S.r.l.)", "title": "Condition monitoring and early diagnostics methodologies for hydropower\n  plants", "comments": "8 pages, 4 figures. This work has been submitted to the Elsevier\n  Renewable Energy for possible publication", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.SP cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Hydropower plants are one of the most convenient option for power generation,\nas they generate energy exploiting a renewable source, they have relatively low\noperating and maintenance costs, and they may be used to provide ancillary\nservices, exploiting the large reservoirs of available water. The recent\nadvances in Information and Communication Technologies (ICT) and in machine\nlearning methodologies are seen as fundamental enablers to upgrade and\nmodernize the current operation of most hydropower plants, in terms of\ncondition monitoring, early diagnostics and eventually predictive maintenance.\nWhile very few works, or running technologies, have been documented so far for\nthe hydro case, in this paper we propose a novel Key Performance Indicator\n(KPI) that we have recently developed and tested on operating hydropower\nplants. In particular, we show that after more than one year of operation it\nhas been able to identify several faults, and to support the operation and\nmaintenance tasks of plant operators. Also, we show that the proposed KPI\noutperforms conventional multivariable process control charts, like the\nHotelling $t_2$ index.\n", "versions": [{"version": "v1", "created": "Wed, 13 Nov 2019 09:15:32 GMT"}], "update_date": "2019-11-15", "authors_parsed": [["Betti", "Alessandro", ""], ["Crisostomi", "Emanuele", ""], ["Paolinelli", "Gianluca", ""], ["Piazzi", "Antonio", ""], ["Ruffini", "Fabrizio", ""], ["Tucci", "Mauro", ""]]}, {"id": "1911.06253", "submitter": "Michael Perlmutter", "authors": "Michael Perlmutter and Feng Gao and Guy Wolf and Matthew Hirn", "title": "Understanding Graph Neural Networks with Asymmetric Geometric Scattering\n  Transforms", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The scattering transform is a multilayered wavelet-based deep learning\narchitecture that acts as a model of convolutional neural networks. Recently,\nseveral works have introduced generalizations of the scattering transform for\nnon-Euclidean settings such as graphs. Our work builds upon these constructions\nby introducing windowed and non-windowed graph scattering transforms based upon\na very general class of asymmetric wavelets. We show that these asymmetric\ngraph scattering transforms have many of the same theoretical guarantees as\ntheir symmetric counterparts. This work helps bridge the gap between scattering\nand other graph neural networks by introducing a large family of networks with\nprovable stability and invariance guarantees. This lays the groundwork for\nfuture deep learning architectures for graph-structured data that have learned\nfilters and also provably have desirable theoretical properties.\n", "versions": [{"version": "v1", "created": "Thu, 14 Nov 2019 17:23:06 GMT"}], "update_date": "2019-11-15", "authors_parsed": [["Perlmutter", "Michael", ""], ["Gao", "Feng", ""], ["Wolf", "Guy", ""], ["Hirn", "Matthew", ""]]}, {"id": "1911.06256", "submitter": "Luca Della Libera", "authors": "Luca Della Libera", "title": "A Comparative Study between Bayesian and Frequentist Neural Networks for\n  Remaining Useful Life Estimation in Condition-Based Maintenance", "comments": "Withdrawn to resolve an authorship dispute", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In the last decade, deep learning (DL) has outperformed model-based and\nstatistical approaches in predicting the remaining useful life (RUL) of\nmachinery in the context of condition-based maintenance. One of the major\ndrawbacks of DL is that it heavily depends on a large amount of labeled data,\nwhich are typically expensive and time-consuming to obtain, especially in\nindustrial applications. Scarce training data lead to uncertain estimates of\nthe model's parameters, which in turn result in poor prognostic performance.\nQuantifying this parameter uncertainty is important in order to determine how\nreliable the prediction is. Traditional DL techniques such as neural networks\nare incapable of capturing the uncertainty in the training data, thus they are\noverconfident about their estimates. On the contrary, Bayesian deep learning\nhas recently emerged as a promising solution to account for uncertainty in the\ntraining process, achieving state-of-the-art performance in many classification\nand regression tasks. In this work Bayesian DL techniques such as Bayesian\ndense neural networks and Bayesian convolutional neural networks are applied to\nRUL estimation and compared to their frequentist counterparts from the\nliterature. The effectiveness of the proposed models is verified on the popular\nC-MAPSS dataset. Furthermore, parameter uncertainty is quantified and used to\ngain additional insight into the data.\n", "versions": [{"version": "v1", "created": "Thu, 14 Nov 2019 17:31:04 GMT"}, {"version": "v2", "created": "Fri, 20 Dec 2019 15:12:36 GMT"}], "update_date": "2020-01-10", "authors_parsed": [["Della Libera", "Luca", ""]]}, {"id": "1911.06257", "submitter": "Ahmed Alkhateeb", "authors": "Muhammad Alrabeiah, Andrew Hredzak, Zhenhao Liu, and Ahmed Alkhateeb", "title": "ViWi: A Deep Learning Dataset Framework for Vision-Aided Wireless\n  Communications", "comments": "IEEE VTC 2020. The ViWi datasets and applications are available at\n  https://www.viwi-dataset.net", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.IT eess.SP math.IT stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The growing role that artificial intelligence and specifically machine\nlearning is playing in shaping the future of wireless communications has opened\nup many new and intriguing research directions. This paper motivates the\nresearch in the novel direction of \\textit{vision-aided wireless\ncommunications}, which aims at leveraging visual sensory information in\ntackling wireless communication problems. Like any new research direction\ndriven by machine learning, obtaining a development dataset poses the first and\nmost important challenge to vision-aided wireless communications. This paper\naddresses this issue by introducing the Vision-Wireless (ViWi) dataset\nframework. It is developed to be a parametric, systematic, and scalable data\ngeneration framework. It utilizes advanced 3D-modeling and ray-tracing\nsoftwares to generate high-fidelity synthetic wireless and vision data samples\nfor the same scenes. The result is a framework that does not only offer a way\nto generate training and testing datasets but helps provide a common ground on\nwhich the quality of different machine learning-powered solutions could be\nassessed.\n", "versions": [{"version": "v1", "created": "Thu, 14 Nov 2019 17:32:02 GMT"}, {"version": "v2", "created": "Wed, 22 Apr 2020 13:32:33 GMT"}], "update_date": "2020-04-23", "authors_parsed": [["Alrabeiah", "Muhammad", ""], ["Hredzak", "Andrew", ""], ["Liu", "Zhenhao", ""], ["Alkhateeb", "Ahmed", ""]]}, {"id": "1911.06259", "submitter": "Jo\\~ao Caldeira", "authors": "Jo\\~ao Caldeira, Joshua Job, Steven H. Adachi, Brian Nord, Gabriel N.\n  Perdue", "title": "Restricted Boltzmann Machines for galaxy morphology classification with\n  a quantum annealer", "comments": "15 pages; LaTeX; 14 figures", "journal-ref": null, "doi": null, "report-no": "FERMILAB-PUB-19-546-QIS-SCD", "categories": "quant-ph astro-ph.GA cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present the application of Restricted Boltzmann Machines (RBMs) to the\ntask of astronomical image classification using a quantum annealer built by\nD-Wave Systems. Morphological analysis of galaxies provides critical\ninformation for studying their formation and evolution across cosmic time\nscales. We compress galaxy images using principal component analysis to fit a\nrepresentation on the quantum hardware. Then, we train RBMs with discriminative\nand generative algorithms, including contrastive divergence and hybrid\ngenerative-discriminative approaches, to classify different galaxy\nmorphologies. The methods we compare include Quantum Annealing (QA), Markov\nChain Monte Carlo (MCMC) Gibbs Sampling, and Simulated Annealing (SA) as well\nas machine learning algorithms like gradient boosted decision trees. We find\nthat RBMs implemented on D-Wave hardware perform well, and that they show some\nclassification performance advantages on small datasets, but they don't offer a\nbroadly strategic advantage for this task. During this exploration, we analyzed\nthe steps required for Boltzmann sampling with the D-Wave 2000Q, including a\nstudy of temperature estimation, and examined the impact of qubit noise by\ncomparing and contrasting the original D-Wave 2000Q to the lower-noise version\nrecently made available. While these analyses ultimately had minimal impact on\nthe performance of the RBMs, we include them for reference.\n", "versions": [{"version": "v1", "created": "Thu, 14 Nov 2019 17:32:30 GMT"}, {"version": "v2", "created": "Thu, 13 Feb 2020 21:41:15 GMT"}], "update_date": "2020-02-17", "authors_parsed": [["Caldeira", "Jo\u00e3o", ""], ["Job", "Joshua", ""], ["Adachi", "Steven H.", ""], ["Nord", "Brian", ""], ["Perdue", "Gabriel N.", ""]]}, {"id": "1911.06266", "submitter": "Soumi Maiti", "authors": "Soumi Maiti and Michael I Mandel", "title": "Speaker independence of neural vocoders and their effect on parametric\n  resynthesis speech enhancement", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SD cs.LG eess.AS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Traditional speech enhancement systems produce speech with compromised\nquality. Here we propose to use the high quality speech generation capability\nof neural vocoders for better quality speech enhancement. We term this\nparametric resynthesis (PR). In previous work, we showed that PR systems\ngenerate high quality speech for a single speaker using two neural vocoders,\nWaveNet and WaveGlow. Both these vocoders are traditionally speaker dependent.\nHere we first show that when trained on data from enough speakers, these\nvocoders can generate speech from unseen speakers, both male and female, with\nsimilar quality as seen speakers in training. Next using these two vocoders and\na new vocoder LPCNet, we evaluate the noise reduction quality of PR on unseen\nspeakers and show that objective signal and overall quality is higher than the\nstate-of-the-art speech enhancement systems Wave-U-Net, Wavenet-denoise, and\nSEGAN. Moreover, in subjective quality, multiple-speaker PR out-performs the\noracle Wiener mask.\n", "versions": [{"version": "v1", "created": "Thu, 14 Nov 2019 17:45:44 GMT"}], "update_date": "2019-11-15", "authors_parsed": [["Maiti", "Soumi", ""], ["Mandel", "Michael I", ""]]}, {"id": "1911.06269", "submitter": "Feng Chen", "authors": "Feng Chen, Yunkai Shang, Bo Xu, Jincheng Hu", "title": "Few-Features Attack to Fool Machine Learning Models through Mask-Based\n  GAN", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  GAN is a deep-learning based generative approach to generate contents such as\nimages, languages and speeches. Recently, studies have shown that GAN can also\nbe applied to generative adversarial attack examples to fool the\nmachine-learning models. In comparison with the previous non-learning\nadversarial example attack approaches, the GAN-based adversarial attack example\napproach can generate the adversarial samples quickly using the GAN\narchitecture every time facing a new sample after training, but meanwhile needs\nto perturb the attack samples in great quantities, which results in the\nunpractical application in reality. To address this issue, we propose a new\napproach, named Few-Feature-Attack-GAN (FFA-GAN). FFA-GAN has a significant\ntime-consuming advantage than the non-learning adversarial samples approaches\nand a better non-zero-features performance than the GANbased adversarial sample\napproaches. FFA-GAN can automatically generate the attack samples in the\nblack-box attack through the GAN architecture instead of the evolutional\nalgorithms or the other non-learning approaches. Besides, we introduce the mask\nmechanism into the generator network of the GAN architecture to optimize the\nconstraint issue, which can also be regarded as the sparsity problem of the\nimportant features. During the training, the different weights of losses of the\ngenerator are set in the different training phases to ensure the divergence of\nthe two above mentioned parallel networks of the generator. Experiments are\nmade respectively on the structured data sets KDD-Cup 1999 and CIC-IDS 2017, in\nwhich the dimensions of the data are relatively low, and also on the\nunstructured data sets MNIST and CIFAR-10 with the data of the relatively high\ndimensions. The results of the experiments demonstrate the effectiveness and\nthe robustness of our proposed approach.\n", "versions": [{"version": "v1", "created": "Tue, 12 Nov 2019 02:51:00 GMT"}], "update_date": "2019-11-15", "authors_parsed": [["Chen", "Feng", ""], ["Shang", "Yunkai", ""], ["Xu", "Bo", ""], ["Hu", "Jincheng", ""]]}, {"id": "1911.06270", "submitter": "Jie Xu", "authors": "Jie Xu and Benjamin S. Glicksberg and Chang Su and Peter Walker and\n  Jiang Bian and Fei Wang", "title": "Federated Learning for Healthcare Informatics", "comments": "18 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  With the rapid development of computer software and hardware technologies,\nmore and more healthcare data are becoming readily available from clinical\ninstitutions, patients, insurance companies and pharmaceutical industries,\namong others. This access provides an unprecedented opportunity for data\nscience technologies to derive data-driven insights and improve the quality of\ncare delivery. Healthcare data, however, are usually fragmented and private\nmaking it difficult to generate robust results across populations. For example,\ndifferent hospitals own the electronic health records (EHR) of different\npatient populations and these records are difficult to share across hospitals\nbecause of their sensitive nature. This creates a big barrier for developing\neffective analytical approaches that are generalizable, which need diverse,\n\"big data\". Federated learning, a mechanism of training a shared global model\nwith a central server while keeping all the sensitive data in local\ninstitutions where the data belong, provides great promise to connect the\nfragmented healthcare data sources with privacy-preservation. The goal of this\nsurvey is to provide a review for federated learning technologies, particularly\nwithin the biomedical space. In particular, we summarize the general solutions\nto the statistical challenges, system challenges and privacy issues in\nfederated learning, and point out the implications and potentials in\nhealthcare.\n", "versions": [{"version": "v1", "created": "Wed, 13 Nov 2019 01:42:31 GMT"}, {"version": "v2", "created": "Thu, 20 Aug 2020 19:05:42 GMT"}], "update_date": "2020-08-24", "authors_parsed": [["Xu", "Jie", ""], ["Glicksberg", "Benjamin S.", ""], ["Su", "Chang", ""], ["Walker", "Peter", ""], ["Bian", "Jiang", ""], ["Wang", "Fei", ""]]}, {"id": "1911.06283", "submitter": "Mengyuan Yan", "authors": "Mengyuan Yan, Yilin Zhu, Ning Jin, Jeannette Bohg", "title": "Self-Supervised Learning of State Estimation for Manipulating Deformable\n  Linear Objects", "comments": "v3: update acknowledgements", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We demonstrate model-based, visual robot manipulation of linear deformable\nobjects. Our approach is based on a state-space representation of the physical\nsystem that the robot aims to control. This choice has multiple advantages,\nincluding the ease of incorporating physics priors in the dynamics model and\nperception model, and the ease of planning manipulation actions. In addition,\nphysical states can naturally represent object instances of different\nappearances. Therefore, dynamics in the state space can be learned in one\nsetting and directly used in other visually different settings. This is in\ncontrast to dynamics learned in pixel space or latent space, where\ngeneralization to visual differences are not guaranteed. Challenges in taking\nthe state-space approach are the estimation of the high-dimensional state of a\ndeformable object from raw images, where annotations are very expensive on real\ndata, and finding a dynamics model that is both accurate, generalizable, and\nefficient to compute. We are the first to demonstrate self-supervised training\nof rope state estimation on real images, without requiring expensive\nannotations. This is achieved by our novel self-supervising learning objective,\nwhich is generalizable across a wide range of visual appearances. With\nestimated rope states, we train a fast and differentiable neural network\ndynamics model that encodes the physics of mass-spring systems. Our method has\na higher accuracy in predicting future states compared to models that do not\ninvolve explicit state estimation and do not use any physics prior, while only\nusing 3\\% of training data. We also show that our approach achieves more\nefficient manipulation, both in simulation and on a real robot, when used\nwithin a model predictive controller.\n", "versions": [{"version": "v1", "created": "Thu, 14 Nov 2019 18:04:51 GMT"}, {"version": "v2", "created": "Sun, 19 Jan 2020 22:31:33 GMT"}, {"version": "v3", "created": "Tue, 6 Oct 2020 04:06:53 GMT"}], "update_date": "2020-10-07", "authors_parsed": [["Yan", "Mengyuan", ""], ["Zhu", "Yilin", ""], ["Jin", "Ning", ""], ["Bohg", "Jeannette", ""]]}, {"id": "1911.06285", "submitter": "Isaac Corley", "authors": "Isaac Corley, Jonathan Lwowski, Justin Hoffman", "title": "DomainGAN: Generating Adversarial Examples to Attack Domain Generation\n  Algorithm Classifiers", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR eess.SP stat.ML", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Domain Generation Algorithms (DGAs) are frequently used to generate numerous\ndomains for use by botnets. These domains are often utilized as rendezvous\npoints for servers that malware has command and control over. There are many\nalgorithms that are used to generate domains, however many of these algorithms\nare simplistic and easily detected by traditional machine learning techniques.\nIn this paper, three variants of Generative Adversarial Networks (GANs) are\noptimized to generate domains which have similar characteristics of benign\ndomains, resulting in domains which greatly evade several state-of-the-art deep\nlearning based DGA classifiers. We additionally provide a detailed analysis\ninto offensive usability for each variant with respect to repeated and existing\ndomain collisions. Finally, we fine-tune the state-of-the-art DGA classifiers\nby adding GAN generated samples to their original training datasets and analyze\nthe changes in performance. Our results conclude that GAN based DGAs are\nsuperior in evading DGA classifiers in comparison to traditional DGAs, and of\nthe variants, the Wasserstein GAN with Gradient Penalty (WGANGP) is the highest\nperforming DGA for uses both offensively and defensively.\n", "versions": [{"version": "v1", "created": "Thu, 14 Nov 2019 18:12:36 GMT"}, {"version": "v2", "created": "Mon, 18 Nov 2019 19:48:07 GMT"}, {"version": "v3", "created": "Fri, 14 Feb 2020 19:08:31 GMT"}], "update_date": "2020-02-18", "authors_parsed": [["Corley", "Isaac", ""], ["Lwowski", "Jonathan", ""], ["Hoffman", "Justin", ""]]}, {"id": "1911.06287", "submitter": "Wessel Bruinsma", "authors": "Wessel P. Bruinsma, Eric Perim, Will Tebbutt, J. Scott Hosking, Arno\n  Solin, and Richard E. Turner", "title": "Scalable Exact Inference in Multi-Output Gaussian Processes", "comments": "31 pages, 12 figures, 5 tables, includes appendix; to appear in ICML\n  2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Multi-output Gaussian processes (MOGPs) leverage the flexibility and\ninterpretability of GPs while capturing structure across outputs, which is\ndesirable, for example, in spatio-temporal modelling. The key problem with\nMOGPs is their computational scaling $O(n^3 p^3)$, which is cubic in the number\nof both inputs $n$ (e.g., time points or locations) and outputs $p$. For this\nreason, a popular class of MOGPs assumes that the data live around a\nlow-dimensional linear subspace, reducing the complexity to $O(n^3 m^3)$.\nHowever, this cost is still cubic in the dimensionality of the subspace $m$,\nwhich is still prohibitively expensive for many applications. We propose the\nuse of a sufficient statistic of the data to accelerate inference and learning\nin MOGPs with orthogonal bases. The method achieves linear scaling in $m$ in\npractice, allowing these models to scale to large $m$ without sacrificing\nsignificant expressivity or requiring approximation. This advance opens up a\nwide range of real-world tasks and can be combined with existing GP\napproximations in a plug-and-play way. We demonstrate the efficacy of the\nmethod on various synthetic and real-world data sets.\n", "versions": [{"version": "v1", "created": "Thu, 14 Nov 2019 18:19:22 GMT"}, {"version": "v2", "created": "Tue, 30 Jun 2020 09:29:46 GMT"}, {"version": "v3", "created": "Fri, 17 Jul 2020 12:10:27 GMT"}], "update_date": "2020-07-20", "authors_parsed": [["Bruinsma", "Wessel P.", ""], ["Perim", "Eric", ""], ["Tebbutt", "Will", ""], ["Hosking", "J. Scott", ""], ["Solin", "Arno", ""], ["Turner", "Richard E.", ""]]}, {"id": "1911.06294", "submitter": "Kai Liang Tan", "authors": "Kai Liang Tan, Subhadipto Poddar, Anuj Sharma, Soumik Sarkar", "title": "Deep Reinforcement Learning for Adaptive Traffic Signal Control", "comments": "ASME 2019 Dynamic Systems and Control Conference (DSCC), October\n  9-11, Park City, Utah, USA", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.SY cs.LG cs.SY eess.SP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Many existing traffic signal controllers are either simple adaptive\ncontrollers based on sensors placed around traffic intersections, or optimized\nby traffic engineers on a fixed schedule. Optimizing traffic controllers is\ntime consuming and usually require experienced traffic engineers. Recent\nresearch has demonstrated the potential of using deep reinforcement learning\n(DRL) in this context. However, most of the studies do not consider realistic\nsettings that could seamlessly transition into deployment. In this paper, we\npropose a DRL-based adaptive traffic signal control framework that explicitly\nconsiders realistic traffic scenarios, sensors, and physical constraints. In\nthis framework, we also propose a novel reward function that shows\nsignificantly improved traffic performance compared to the typical baseline\npre-timed and fully-actuated traffic signals controllers. The framework is\nimplemented and validated on a simulation platform emulating real-life traffic\nscenarios and sensor data streams.\n", "versions": [{"version": "v1", "created": "Thu, 14 Nov 2019 18:31:50 GMT"}], "update_date": "2019-11-15", "authors_parsed": [["Tan", "Kai Liang", ""], ["Poddar", "Subhadipto", ""], ["Sharma", "Anuj", ""], ["Sarkar", "Soumik", ""]]}, {"id": "1911.06311", "submitter": "\\c{C}a\\u{g}atay Demiralp", "authors": "Dan Zhang and Yoshihiko Suhara and Jinfeng Li and Madelon Hulsebos and\n  \\c{C}a\\u{g}atay Demiralp and Wang-Chiew Tan", "title": "Sato: Contextual Semantic Type Detection in Tables", "comments": "VLDB'20", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DB cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Detecting the semantic types of data columns in relational tables is\nimportant for various data preparation and information retrieval tasks such as\ndata cleaning, schema matching, data discovery, and semantic search. However,\nexisting detection approaches either perform poorly with dirty data, support\nonly a limited number of semantic types, fail to incorporate the table context\nof columns or rely on large sample sizes for training data. We introduce Sato,\na hybrid machine learning model to automatically detect the semantic types of\ncolumns in tables, exploiting the signals from the context as well as the\ncolumn values. Sato combines a deep learning model trained on a large-scale\ntable corpus with topic modeling and structured prediction to achieve\nsupport-weighted and macro average F1 scores of 0.925 and 0.735, respectively,\nexceeding the state-of-the-art performance by a significant margin. We\nextensively analyze the overall and per-type performance of Sato, discussing\nhow individual modeling components, as well as feature categories, contribute\nto its performance.\n", "versions": [{"version": "v1", "created": "Thu, 14 Nov 2019 18:51:59 GMT"}, {"version": "v2", "created": "Mon, 9 Mar 2020 03:47:14 GMT"}, {"version": "v3", "created": "Wed, 3 Jun 2020 04:54:28 GMT"}], "update_date": "2020-06-04", "authors_parsed": [["Zhang", "Dan", ""], ["Suhara", "Yoshihiko", ""], ["Li", "Jinfeng", ""], ["Hulsebos", "Madelon", ""], ["Demiralp", "\u00c7a\u011fatay", ""], ["Tan", "Wang-Chiew", ""]]}, {"id": "1911.06317", "submitter": "Qiuyi Zhang", "authors": "Daniel Golovin, John Karro, Greg Kochanski, Chansoo Lee, Xingyou Song,\n  Qiuyi Zhang", "title": "Gradientless Descent: High-Dimensional Zeroth-Order Optimization", "comments": "11 main pages, 26 total pages", "journal-ref": "ICLR 2020 Spotlight", "doi": null, "report-no": null, "categories": "cs.LG math.OC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Zeroth-order optimization is the process of minimizing an objective $f(x)$,\ngiven oracle access to evaluations at adaptively chosen inputs $x$. In this\npaper, we present two simple yet powerful GradientLess Descent (GLD) algorithms\nthat do not rely on an underlying gradient estimate and are numerically stable.\nWe analyze our algorithm from a novel geometric perspective and present a novel\nanalysis that shows convergence within an $\\epsilon$-ball of the optimum in\n$O(kQ\\log(n)\\log(R/\\epsilon))$ evaluations, for any monotone transform of a\nsmooth and strongly convex objective with latent dimension $k < n$, where the\ninput dimension is $n$, $R$ is the diameter of the input space and $Q$ is the\ncondition number. Our rates are the first of its kind to be both 1)\npoly-logarithmically dependent on dimensionality and 2) invariant under\nmonotone transformations. We further leverage our geometric perspective to show\nthat our analysis is optimal. Both monotone invariance and its ability to\nutilize a low latent dimensionality are key to the empirical success of our\nalgorithms, as demonstrated on BBOB and MuJoCo benchmarks.\n", "versions": [{"version": "v1", "created": "Thu, 14 Nov 2019 18:58:13 GMT"}, {"version": "v2", "created": "Fri, 15 Nov 2019 01:23:11 GMT"}, {"version": "v3", "created": "Tue, 19 Nov 2019 01:16:07 GMT"}, {"version": "v4", "created": "Mon, 18 May 2020 20:08:57 GMT"}], "update_date": "2020-05-20", "authors_parsed": [["Golovin", "Daniel", ""], ["Karro", "John", ""], ["Kochanski", "Greg", ""], ["Lee", "Chansoo", ""], ["Song", "Xingyou", ""], ["Zhang", "Qiuyi", ""]]}, {"id": "1911.06319", "submitter": "Jonathan Baxter", "authors": "Jonathan Baxter", "title": "The Canonical Distortion Measure for Vector Quantization and Function\n  Approximation", "comments": null, "journal-ref": "In: Thrun S., Pratt L. (eds) Learning to Learn (1998). Pages\n  159-177", "doi": "10.1007/978-1-4615-5529-2_7", "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  To measure the quality of a set of vector quantization points a means of\nmeasuring the distance between a random point and its quantization is required.\nCommon metrics such as the {\\em Hamming} and {\\em Euclidean} metrics, while\nmathematically simple, are inappropriate for comparing natural signals such as\nspeech or images. In this paper it is shown how an {\\em environment} of\nfunctions on an input space $X$ induces a {\\em canonical distortion measure}\n(CDM) on X. The depiction 'canonical\" is justified because it is shown that\noptimizing the reconstruction error of X with respect to the CDM gives rise to\noptimal piecewise constant approximations of the functions in the environment.\nThe CDM is calculated in closed form for several different function classes. An\nalgorithm for training neural networks to implement the CDM is presented along\nwith some encouraging experimental results.\n", "versions": [{"version": "v1", "created": "Thu, 14 Nov 2019 18:59:38 GMT"}], "update_date": "2019-11-15", "authors_parsed": [["Baxter", "Jonathan", ""]]}, {"id": "1911.06322", "submitter": "Robert Murphy", "authors": "Robert A. Murphy", "title": "Auto-encoding a Knowledge Graph Using a Deep Belief Network: A Random\n  Fields Perspective", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.LG math.PR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We started with a knowledge graph of connected entities and descriptive\nproperties of those entities, from which, a hierarchical representation of the\nknowledge graph is derived. Using a graphical, energy-based neural network, we\nare able to show that the structure of the hierarchy can be internally captured\nby the neural network, which allows for efficient output of the underlying\nequilibrium distribution from which the data are drawn.\n", "versions": [{"version": "v1", "created": "Thu, 14 Nov 2019 22:41:21 GMT"}, {"version": "v2", "created": "Thu, 19 Dec 2019 18:48:56 GMT"}, {"version": "v3", "created": "Mon, 23 Dec 2019 19:09:52 GMT"}, {"version": "v4", "created": "Thu, 26 Dec 2019 02:17:47 GMT"}], "update_date": "2019-12-30", "authors_parsed": [["Murphy", "Robert A.", ""]]}, {"id": "1911.06353", "submitter": "Yiding Cao", "authors": "Yiding Cao, Yingjun Dong, Minjun Kim, Neil G. MacLaren, Ankita\n  Kulkarni, Shelley D. Dionne, Francis J. Yammarino, and Hiroki Sayama", "title": "Capturing the Production of the Innovative Ideas: An Online Social\n  Network Experiment and \"Idea Geography\" Visualization", "comments": "16 pages, 10 figures, submitted to CSS 2019 (Computational Social\n  Science 2019)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Collective design and innovation are crucial in organizations. To investigate\nhow the collective design and innovation processes would be affected by the\ndiversity of knowledge and background of collective individual members, we\nconducted three collaborative design task experiments which involved nearly 300\nparticipants who worked together anonymously in a social network structure\nusing a custom-made computer-mediated collaboration platform. We compared the\nidea generation activity among three different background distribution\nconditions (clustered, random, and dispersed) with the help of the \"doc2vec\"\ntext representation machine learning algorithm. We also developed a new method\ncalled \"Idea Geography\" to visualize the idea utility terrain on a 2D problem\ndomain. The results showed that groups with random background allocation tended\nto produce the best design idea with highest utility values. It was also\nsuggested that the diversity of participants' backgrounds distribution on the\nnetwork might interact with each other to affect the diversity of ideas\ngenerated. The proposed idea geography successfully visualized that the\ncollective design processes did find the high utility area through exploration\nand exploitation in collaborative work.\n", "versions": [{"version": "v1", "created": "Thu, 14 Nov 2019 19:38:50 GMT"}, {"version": "v2", "created": "Tue, 25 Feb 2020 04:07:23 GMT"}], "update_date": "2020-02-26", "authors_parsed": [["Cao", "Yiding", ""], ["Dong", "Yingjun", ""], ["Kim", "Minjun", ""], ["MacLaren", "Neil G.", ""], ["Kulkarni", "Ankita", ""], ["Dionne", "Shelley D.", ""], ["Yammarino", "Francis J.", ""], ["Sayama", "Hiroki", ""]]}, {"id": "1911.06356", "submitter": "Devendra Singh Dhami", "authors": "Devendra Singh Dhami, Siwen Yan, Gautam Kunapuli, David Page and\n  Sriraam Natarajan", "title": "Beyond Textual Data: Predicting Drug-Drug Interactions from Molecular\n  Structure Images using Siamese Neural Networks", "comments": "9 pages, 9 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Predicting and discovering drug-drug interactions (DDIs) is an important\nproblem and has been studied extensively both from medical and machine learning\npoint of view. Almost all of the machine learning approaches have focused on\ntext data or textual representation of the structural data of drugs. We present\nthe first work that uses drug structure images as the input and utilizes a\nSiamese convolutional network architecture to predict DDIs.\n", "versions": [{"version": "v1", "created": "Thu, 14 Nov 2019 19:51:14 GMT"}, {"version": "v2", "created": "Mon, 29 Jun 2020 04:57:42 GMT"}], "update_date": "2020-06-30", "authors_parsed": [["Dhami", "Devendra Singh", ""], ["Yan", "Siwen", ""], ["Kunapuli", "Gautam", ""], ["Page", "David", ""], ["Natarajan", "Sriraam", ""]]}, {"id": "1911.06357", "submitter": "Katharina Hoebel", "authors": "Katharina Hoebel, Ken Chang, Jay Patel, Praveer Singh, Jayashree\n  Kalpathy-Cramer", "title": "Give me (un)certainty -- An exploration of parameters that affect\n  segmentation uncertainty", "comments": "Machine Learning for Health (ML4H) at NeurIPS 2019 - Extended\n  Abstract", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.IV cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Segmentation tasks in medical imaging are inherently ambiguous: the boundary\nof a target structure is oftentimes unclear due to image quality and biological\nfactors. As such, predicted segmentations from deep learning algorithms are\ninherently ambiguous. Additionally, \"ground truth\" segmentations performed by\nhuman annotators are in fact weak labels that further increase the uncertainty\nof outputs of supervised models developed on these manual labels. To date, most\ndeep learning segmentation studies utilize predicted segmentations without\nuncertainty quantification. In contrast, we explore the use of Monte Carlo\ndropout U-Nets for the segmentation with additional quantification of\nsegmentation uncertainty. We assess the utility of three measures of\nuncertainty (Coefficient of Variation, Mean Pairwise Dice, and Mean Voxelwise\nUncertainty) for the segmentation of a less ambiguous target structure (liver)\nand a more ambiguous one (liver tumors). Furthermore, we assess how the utility\nof these measures changes with different patch sizes and cost functions. Our\nresults suggest that models trained using larger patches and the weighted\ncategorical cross-entropy as cost function allow the extraction of more\nmeaningful uncertainty measures compared to smaller patches and soft dice loss.\nAmong the three uncertainty measures Mean Pairwise Dice shows the strongest\ncorrelation with segmentation quality. Our study serves as a proof-of-concept\nof how uncertainty measures can be used to assess the quality of a predicted\nsegmentation, potentially serving to flag low quality segmentations from a\ngiven model for further human review.\n", "versions": [{"version": "v1", "created": "Thu, 14 Nov 2019 19:52:08 GMT"}], "update_date": "2019-11-18", "authors_parsed": [["Hoebel", "Katharina", ""], ["Chang", "Ken", ""], ["Patel", "Jay", ""], ["Singh", "Praveer", ""], ["Kalpathy-Cramer", "Jayashree", ""]]}, {"id": "1911.06363", "submitter": "Feng Jin", "authors": "Feng Jin, Renyuan Zhang, Arindam Sengupta, Siyang Cao, Salim Hariri,\n  Nimit K. Agarwal and Sumit K. Agarwal", "title": "Multiple Patients Behavior Detection in Real-time using mmWave Radar and\n  Deep CNNs", "comments": "This paper has been submitted to IEEE Radar Conference 2019", "journal-ref": null, "doi": "10.1109/RADAR.2019.8835656", "report-no": null, "categories": "eess.SP cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  To address potential gaps noted in patient monitoring in the hospital, a\nnovel patient behavior detection system using mmWave radar and deep convolution\nneural network (CNN), which supports the simultaneous recognition of multiple\npatients' behaviors in real-time, is proposed. In this study, we use an mmWave\nradar to track multiple patients and detect the scattering point cloud of each\none. For each patient, the Doppler pattern of the point cloud over a time\nperiod is collected as the behavior signature. A three-layer CNN model is\ncreated to classify the behavior for each patient. The tracking and point\nclouds detection algorithm was also implemented on an mmWave radar hardware\nplatform with an embedded graphics processing unit (GPU) board to collect\nDoppler pattern and run the CNN model. A training dataset of six types of\nbehavior were collected, over a long duration, to train the model using Adam\noptimizer with an objective to minimize cross-entropy loss function. Lastly,\nthe system was tested for real-time operation and obtained a very good\ninference accuracy when predicting each patient's behavior in a two-patient\nscenario.\n", "versions": [{"version": "v1", "created": "Thu, 14 Nov 2019 19:59:56 GMT"}], "update_date": "2020-03-06", "authors_parsed": [["Jin", "Feng", ""], ["Zhang", "Renyuan", ""], ["Sengupta", "Arindam", ""], ["Cao", "Siyang", ""], ["Hariri", "Salim", ""], ["Agarwal", "Nimit K.", ""], ["Agarwal", "Sumit K.", ""]]}, {"id": "1911.06364", "submitter": "Feng Jin", "authors": "Feng Jin, Arindam Sengupta, Siyang Cao and Yao-Jan Wu", "title": "MmWave Radar Point Cloud Segmentation using GMM in Multimodal Traffic\n  Monitoring", "comments": "This paper has been accepted by the IEEE International Radar\n  Conference 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.SP cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In multimodal traffic monitoring, we gather traffic statistics for distinct\ntransportation modes, such as pedestrians, cars and bicycles, in order to\nanalyze and improve people's daily mobility in terms of safety and convenience.\nOn account of its robustness to bad light and adverse weather conditions, and\ninherent speed measurement ability, the radar sensor is a suitable option for\nthis application. However, the sparse radar data from conventional commercial\nradars make it extremely challenging for transportation mode classification.\nThus, we propose to use a high-resolution millimeter-wave(mmWave) radar sensor\nto obtain a relatively richer radar point cloud representation for a traffic\nmonitoring scenario. Based on a new feature vector, we use the multivariate\nGaussian mixture model (GMM) to do the radar point cloud segmentation, i.e.\n`point-wise' classification, in an unsupervised learning environment. In our\nexperiment, we collected radar point clouds for pedestrians and cars, which\nalso contained the inevitable clutter from the surroundings. The experimental\nresults using GMM on the new feature vector demonstrated a good segmentation\nperformance in terms of the intersection-over-union (IoU) metrics. The detailed\nmethodology and validation metrics are presented and discussed.\n", "versions": [{"version": "v1", "created": "Thu, 14 Nov 2019 20:00:53 GMT"}, {"version": "v2", "created": "Sat, 23 Nov 2019 04:08:44 GMT"}, {"version": "v3", "created": "Fri, 31 Jan 2020 17:58:19 GMT"}], "update_date": "2020-03-06", "authors_parsed": [["Jin", "Feng", ""], ["Sengupta", "Arindam", ""], ["Cao", "Siyang", ""], ["Wu", "Yao-Jan", ""]]}, {"id": "1911.06379", "submitter": "Andr\\'es Almansa", "authors": "Mario Gonz\\'alez, Andr\\'es Almansa, Mauricio Delbracio, Pablo Mus\\'e,\n  Pauline Tan", "title": "Solving Inverse Problems by Joint Posterior Maximization with a VAE\n  Prior", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.CV cs.LG eess.IV math.OC", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  In this paper we address the problem of solving ill-posed inverse problems in\nimaging where the prior is a neural generative model. Specifically we consider\nthe decoupled case where the prior is trained once and can be reused for many\ndifferent log-concave degradation models without retraining. Whereas previous\nMAP-based approaches to this problem lead to highly non-convex optimization\nalgorithms, our approach computes the joint (space-latent) MAP that naturally\nleads to alternate optimization algorithms and to the use of a stochastic\nencoder to accelerate computations. The resulting technique is called JPMAP\nbecause it performs Joint Posterior Maximization using an Autoencoding Prior.\nWe show theoretical and experimental evidence that the proposed objective\nfunction is quite close to bi-convex. Indeed it satisfies a weak bi-convexity\nproperty which is sufficient to guarantee that our optimization scheme\nconverges to a stationary point.\n  Experimental results also show the higher quality of the solutions obtained\nby our JPMAP approach with respect to other non-convex MAP approaches which\nmore often get stuck in spurious local optima.\n", "versions": [{"version": "v1", "created": "Thu, 14 Nov 2019 20:52:09 GMT"}], "update_date": "2019-11-18", "authors_parsed": [["Gonz\u00e1lez", "Mario", ""], ["Almansa", "Andr\u00e9s", ""], ["Delbracio", "Mauricio", ""], ["Mus\u00e9", "Pablo", ""], ["Tan", "Pauline", ""]]}, {"id": "1911.06393", "submitter": "Daniel Stoller", "authors": "Daniel Stoller, Mi Tian, Sebastian Ewert, Simon Dixon", "title": "Seq-U-Net: A One-Dimensional Causal U-Net for Efficient Sequence\n  Modelling", "comments": "Code available at https://github.com/f90/Seq-U-Net", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.SD eess.AS stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Convolutional neural networks (CNNs) with dilated filters such as the Wavenet\nor the Temporal Convolutional Network (TCN) have shown good results in a\nvariety of sequence modelling tasks. However, efficiently modelling long-term\ndependencies in these sequences is still challenging. Although the receptive\nfield of these models grows exponentially with the number of layers, computing\nthe convolutions over very long sequences of features in each layer is time and\nmemory-intensive, prohibiting the use of longer receptive fields in practice.\nTo increase efficiency, we make use of the \"slow feature\" hypothesis stating\nthat many features of interest are slowly varying over time. For this, we use a\nU-Net architecture that computes features at multiple time-scales and adapt it\nto our auto-regressive scenario by making convolutions causal. We apply our\nmodel (\"Seq-U-Net\") to a variety of tasks including language and audio\ngeneration. In comparison to TCN and Wavenet, our network consistently saves\nmemory and computation time, with speed-ups for training and inference of over\n4x in the audio generation experiment in particular, while achieving a\ncomparable performance in all tasks.\n", "versions": [{"version": "v1", "created": "Thu, 14 Nov 2019 21:39:20 GMT"}], "update_date": "2019-11-18", "authors_parsed": [["Stoller", "Daniel", ""], ["Tian", "Mi", ""], ["Ewert", "Sebastian", ""], ["Dixon", "Simon", ""]]}, {"id": "1911.06407", "submitter": "Ahmed El-Kishky", "authors": "Hyungsul Kim, Ahmed El-Kishky, Xiang Ren, Jiawei Han", "title": "Mining News Events from Comparable News Corpora: A Multi-Attribute\n  Proximity Network Modeling Approach", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.IR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present ProxiModel, a novel event mining framework for extracting\nhigh-quality structured event knowledge from large, redundant, and noisy news\ndata sources. The proposed model differentiates itself from other approaches by\nmodeling both the event correlation within each individual document as well as\nacross the corpus. To facilitate this, we introduce the concept of a\nproximity-network, a novel space-efficient data structure to facilitate\nscalable event mining. This proximity network captures the corpus-level\nco-occurence statistics for candidate event descriptors, event attributes, as\nwell as their connections. We probabilistically model the proximity network as\na generative process with sparsity-inducing regularization. This allows us to\nefficiently and effectively extract high-quality and interpretable news events.\nExperiments on three different news corpora demonstrate that the proposed\nmethod is effective and robust at generating high-quality event descriptors and\nattributes. We briefly detail many interesting applications from our proposed\nframework such as news summarization, event tracking and multi-dimensional\nanalysis on news. Finally, we explore a case study on visualizing the events\nfor a Japan Tsunami news corpus and demonstrate ProxiModel's ability to\nautomatically summarize emerging news events.\n", "versions": [{"version": "v1", "created": "Thu, 14 Nov 2019 22:22:12 GMT"}], "update_date": "2019-11-18", "authors_parsed": [["Kim", "Hyungsul", ""], ["El-Kishky", "Ahmed", ""], ["Ren", "Xiang", ""], ["Han", "Jiawei", ""]]}, {"id": "1911.06410", "submitter": "Andrew Dai", "authors": "Kun Zhang, Yuan Xue, Gerardo Flores, Alvin Rajkomar, Claire Cui,\n  Andrew M. Dai", "title": "Modelling EHR timeseries by restricting feature interaction", "comments": "Machine Learning for Health (ML4H) at NeurIPS 2019 - Extended\n  Abstract", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CY stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Time series data are prevalent in electronic health records, mostly in the\nform of physiological parameters such as vital signs and lab tests. The\npatterns of these values may be significant indicators of patients' clinical\nstates and there might be patterns that are unknown to clinicians but are\nhighly predictive of some outcomes. Many of these values are also missing which\nmakes it difficult to apply existing methods like decision trees. We propose a\nrecurrent neural network model that reduces overfitting to noisy observations\nby limiting interactions between features. We analyze its performance on\nmortality, ICD-9 and AKI prediction from observational values on the Medical\nInformation Mart for Intensive Care III (MIMIC-III) dataset. Our models result\nin an improvement of 1.1% [p<0.01] in AU-ROC for mortality prediction under the\nMetaVision subset and 1.0% and 2.2% [p<0.01] respectively for mortality and AKI\nunder the full MIMIC-III dataset compared to existing state-of-the-art\ninterpolation, embedding and decay-based recurrent models.\n", "versions": [{"version": "v1", "created": "Thu, 14 Nov 2019 23:06:11 GMT"}], "update_date": "2019-11-18", "authors_parsed": [["Zhang", "Kun", ""], ["Xue", "Yuan", ""], ["Flores", "Gerardo", ""], ["Rajkomar", "Alvin", ""], ["Cui", "Claire", ""], ["Dai", "Andrew M.", ""]]}, {"id": "1911.06411", "submitter": "Saloni Dash", "authors": "Saloni Dash, Ritik Dutta, Isabelle Guyon, Adrien Pavao, Andrew Yale,\n  Kristin P. Bennett", "title": "Synthetic Event Time Series Health Data Generation", "comments": "Machine Learning for Health (ML4H) at NeurIPS 2019 - Extended\n  Abstract", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CY stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Synthetic medical data which preserves privacy while maintaining utility can\nbe used as an alternative to real medical data, which has privacy costs and\nresource constraints associated with it. At present, most models focus on\ngenerating cross-sectional health data which is not necessarily representative\nof real data. In reality, medical data is longitudinal in nature, with a single\npatient having multiple health events, non-uniformly distributed throughout\ntheir lifetime. These events are influenced by patient covariates such as\ncomorbidities, age group, gender etc. as well as external temporal effects\n(e.g. flu season). While there exist seminal methods to model time series data,\nit becomes increasingly challenging to extend these methods to medical event\ntime series data. Due to the complexity of the real data, in which each patient\nvisit is an event, we transform the data by using summary statistics to\ncharacterize the events for a fixed set of time intervals, to facilitate\nanalysis and interpretability. We then train a generative adversarial network\nto generate synthetic data. We demonstrate this approach by generating human\nsleep patterns, from a publicly available dataset. We empirically evaluate the\ngenerated data and show close univariate resemblance between synthetic and real\ndata. However, we also demonstrate how stratification by covariates is required\nto gain a deeper understanding of synthetic data quality.\n", "versions": [{"version": "v1", "created": "Thu, 14 Nov 2019 23:11:19 GMT"}, {"version": "v2", "created": "Wed, 27 Nov 2019 18:47:20 GMT"}], "update_date": "2019-11-28", "authors_parsed": [["Dash", "Saloni", ""], ["Dutta", "Ritik", ""], ["Guyon", "Isabelle", ""], ["Pavao", "Adrien", ""], ["Yale", "Andrew", ""], ["Bennett", "Kristin P.", ""]]}, {"id": "1911.06415", "submitter": "Max Raphael Sobroza Marques", "authors": "Max Raphael Sobroza, Tales Marra, Deok-Hee Kim-Dufor, Claude Berrou", "title": "Sparse associative memory based on contextual code learning for\n  disambiguating word senses", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In recent literature, contextual pretrained Language Models (LMs)\ndemonstrated their potential in generalizing the knowledge to several Natural\nLanguage Processing (NLP) tasks including supervised Word Sense Disambiguation\n(WSD), a challenging problem in the field of Natural Language Understanding\n(NLU). However, word representations from these models are still very dense,\ncostly in terms of memory footprint, as well as minimally interpretable. In\norder to address such issues, we propose a new supervised biologically inspired\ntechnique for transferring large pre-trained language model representations\ninto a compressed representation, for the case of WSD. Our produced\nrepresentation contributes to increase the general interpretability of the\nframework and to decrease memory footprint, while enhancing performance.\n", "versions": [{"version": "v1", "created": "Thu, 14 Nov 2019 23:31:02 GMT"}], "update_date": "2019-11-18", "authors_parsed": [["Sobroza", "Max Raphael", ""], ["Marra", "Tales", ""], ["Kim-Dufor", "Deok-Hee", ""], ["Berrou", "Claude", ""]]}, {"id": "1911.06443", "submitter": "Matthew Vowels", "authors": "Matthew J. Vowels and Necati Cihan Camgoz and Richard Bowden", "title": "Gated Variational AutoEncoders: Incorporating Weak Supervision to\n  Encourage Disentanglement", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Variational AutoEncoders (VAEs) provide a means to generate representational\nlatent embeddings. Previous research has highlighted the benefits of achieving\nrepresentations that are disentangled, particularly for downstream tasks.\nHowever, there is some debate about how to encourage disentanglement with VAEs\nand evidence indicates that existing implementations of VAEs do not achieve\ndisentanglement consistently. The evaluation of how well a VAE's latent space\nhas been disentangled is often evaluated against our subjective expectations of\nwhich attributes should be disentangled for a given problem. Therefore, by\ndefinition, we already have domain knowledge of what should be achieved and yet\nwe use unsupervised approaches to achieve it. We propose a weakly-supervised\napproach that incorporates any available domain knowledge into the training\nprocess to form a Gated-VAE. The process involves partitioning the\nrepresentational embedding and gating backpropagation. All partitions are\nutilised on the forward pass but gradients are backpropagated through different\npartitions according to selected image/target pairings. The approach can be\nused to modify existing VAE models such as beta-VAE, InfoVAE and DIP-VAE-II.\nExperiments demonstrate that using gated backpropagation, latent factors are\nrepresented in their intended partition. The approach is applied to images of\nfaces for the purpose of disentangling head-pose from facial expression.\nQuantitative metrics show that using Gated-VAE improves average\ndisentanglement, completeness and informativeness, as compared with un-gated\nimplementations. Qualitative assessment of latent traversals demonstrate its\ndisentanglement of head-pose from expression, even when only weak/noisy\nsupervision is available.\n", "versions": [{"version": "v1", "created": "Fri, 15 Nov 2019 01:46:16 GMT"}], "update_date": "2019-11-18", "authors_parsed": [["Vowels", "Matthew J.", ""], ["Camgoz", "Necati Cihan", ""], ["Bowden", "Richard", ""]]}, {"id": "1911.06446", "submitter": "Kexin Huang", "authors": "Kexin Huang, Cao Xiao, Trong Nghia Hoang, Lucas M. Glass, Jimeng Sun", "title": "CASTER: Predicting Drug Interactions with Chemical Substructure\n  Representation", "comments": "Accepted by AAAI 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG q-bio.QM stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Adverse drug-drug interactions (DDIs) remain a leading cause of morbidity and\nmortality. Identifying potential DDIs during the drug design process is\ncritical for patients and society. Although several computational models have\nbeen proposed for DDI prediction, there are still limitations: (1) specialized\ndesign of drug representation for DDI predictions is lacking; (2) predictions\nare based on limited labelled data and do not generalize well to unseen drugs\nor DDIs; and (3) models are characterized by a large number of parameters, thus\nare hard to interpret. In this work, we develop a ChemicAl SubstrucTurE\nRepresentation (CASTER) framework that predicts DDIs given chemical structures\nof drugs.CASTER aims to mitigate these limitations via (1) a sequential pattern\nmining module rooted in the DDI mechanism to efficiently characterize\nfunctional sub-structures of drugs; (2) an auto-encoding module that leverages\nboth labelled and unlabelled chemical structure data to improve predictive\naccuracy and generalizability; and (3) a dictionary learning module that\nexplains the prediction via a small set of coefficients which measure the\nrelevance of each input sub-structures to the DDI outcome. We evaluated CASTER\non two real-world DDI datasets and showed that it performed better than\nstate-of-the-art baselines and provided interpretable predictions.\n", "versions": [{"version": "v1", "created": "Fri, 15 Nov 2019 01:50:44 GMT"}, {"version": "v2", "created": "Wed, 20 Nov 2019 03:55:01 GMT"}], "update_date": "2019-11-21", "authors_parsed": [["Huang", "Kexin", ""], ["Xiao", "Cao", ""], ["Hoang", "Trong Nghia", ""], ["Glass", "Lucas M.", ""], ["Sun", "Jimeng", ""]]}, {"id": "1911.06455", "submitter": "Seongjun Yun", "authors": "Seongjun Yun, Minbyul Jeong, Raehyun Kim, Jaewoo Kang, Hyunwoo J. Kim", "title": "Graph Transformer Networks", "comments": "Neural Information Processing Systems (NeurIPS), 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.SI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Graph neural networks (GNNs) have been widely used in representation learning\non graphs and achieved state-of-the-art performance in tasks such as node\nclassification and link prediction. However, most existing GNNs are designed to\nlearn node representations on the fixed and homogeneous graphs. The limitations\nespecially become problematic when learning representations on a misspecified\ngraph or a heterogeneous graph that consists of various types of nodes and\nedges. In this paper, we propose Graph Transformer Networks (GTNs) that are\ncapable of generating new graph structures, which involve identifying useful\nconnections between unconnected nodes on the original graph, while learning\neffective node representation on the new graphs in an end-to-end fashion. Graph\nTransformer layer, a core layer of GTNs, learns a soft selection of edge types\nand composite relations for generating useful multi-hop connections so-called\nmeta-paths. Our experiments show that GTNs learn new graph structures, based on\ndata and tasks without domain knowledge, and yield powerful node representation\nvia convolution on the new graphs. Without domain-specific graph preprocessing,\nGTNs achieved the best performance in all three benchmark node classification\ntasks against the state-of-the-art methods that require pre-defined meta-paths\nfrom domain knowledge.\n", "versions": [{"version": "v1", "created": "Wed, 6 Nov 2019 06:40:05 GMT"}, {"version": "v2", "created": "Wed, 5 Feb 2020 04:23:19 GMT"}], "update_date": "2020-02-06", "authors_parsed": [["Yun", "Seongjun", ""], ["Jeong", "Minbyul", ""], ["Kim", "Raehyun", ""], ["Kang", "Jaewoo", ""], ["Kim", "Hyunwoo J.", ""]]}, {"id": "1911.06459", "submitter": "Haidar Khan", "authors": "Michael P. Perrone, Haidar Khan, Changhoan Kim, Anastasios Kyrillidis,\n  Jerry Quinn, Valentina Salapura", "title": "Optimal Mini-Batch Size Selection for Fast Gradient Descent", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.DC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper presents a methodology for selecting the mini-batch size that\nminimizes Stochastic Gradient Descent (SGD) learning time for single and\nmultiple learner problems. By decoupling algorithmic analysis issues from\nhardware and software implementation details, we reveal a robust empirical\ninverse law between mini-batch size and the average number of SGD updates\nrequired to converge to a specified error threshold. Combining this empirical\ninverse law with measured system performance, we create an accurate,\nclosed-form model of average training time and show how this model can be used\nto identify quantifiable implications for both algorithmic and hardware aspects\nof machine learning. We demonstrate the inverse law empirically, on both image\nrecognition (MNIST, CIFAR10 and CIFAR100) and machine translation (Europarl)\ntasks, and provide a theoretic justification via proving a novel bound on\nmini-batch SGD training.\n", "versions": [{"version": "v1", "created": "Fri, 15 Nov 2019 03:07:27 GMT"}], "update_date": "2019-11-18", "authors_parsed": [["Perrone", "Michael P.", ""], ["Khan", "Haidar", ""], ["Kim", "Changhoan", ""], ["Kyrillidis", "Anastasios", ""], ["Quinn", "Jerry", ""], ["Salapura", "Valentina", ""]]}, {"id": "1911.06465", "submitter": "Tarik Dzanic", "authors": "Tarik Dzanic, Karan Shah, and Freddie Witherden", "title": "Fourier Spectrum Discrepancies in Deep Network Generated Images", "comments": "11 pages, 7 figures", "journal-ref": "Neural Information Processing Systems 33 (2020) 3022-3032", "doi": null, "report-no": null, "categories": "eess.IV cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Advancements in deep generative models such as generative adversarial\nnetworks and variational autoencoders have resulted in the ability to generate\nrealistic images that are visually indistinguishable from real images, which\nraises concerns about their potential malicious usage. In this paper, we\npresent an analysis of the high-frequency Fourier modes of real and deep\nnetwork generated images and show that deep network generated images share an\nobservable, systematic shortcoming in replicating the attributes of these\nhigh-frequency modes. Using this, we propose a detection method based on the\nfrequency spectrum of the images which is able to achieve an accuracy of up to\n99.2% in classifying real and deep network generated images from various GAN\nand VAE architectures on a dataset of 5000 images with as few as 8 training\nexamples. Furthermore, we show the impact of image transformations such as\ncompression, cropping, and resolution reduction on the classification accuracy\nand suggest a method for modifying the high-frequency attributes of deep\nnetwork generated images to mimic real images.\n", "versions": [{"version": "v1", "created": "Fri, 15 Nov 2019 03:55:12 GMT"}, {"version": "v2", "created": "Sat, 6 Jun 2020 18:57:52 GMT"}, {"version": "v3", "created": "Thu, 22 Oct 2020 17:29:32 GMT"}], "update_date": "2021-02-16", "authors_parsed": [["Dzanic", "Tarik", ""], ["Shah", "Karan", ""], ["Witherden", "Freddie", ""]]}, {"id": "1911.06468", "submitter": "Dylan Foster", "authors": "Dylan J. Foster and Alexander Rakhlin", "title": "$\\ell_{\\infty}$ Vector Contraction for Rademacher Complexity", "comments": "Technical note", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG math.ST stat.ML stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We show that the Rademacher complexity of any $\\mathbb{R}^{K}$-valued\nfunction class composed with an $\\ell_{\\infty}$-Lipschitz function is bounded\nby the maximum Rademacher complexity of the restriction of the function class\nalong each coordinate, times a factor of $\\tilde{O}(\\sqrt{K})$.\n", "versions": [{"version": "v1", "created": "Fri, 15 Nov 2019 04:04:55 GMT"}], "update_date": "2019-11-18", "authors_parsed": [["Foster", "Dylan J.", ""], ["Rakhlin", "Alexander", ""]]}, {"id": "1911.06470", "submitter": "YueFeng Chen", "authors": "Kejiang Chen, Hang Zhou, Yuefeng Chen, Xiaofeng Mao, Yuhong Li, Yuan\n  He, Hui Xue, Weiming Zhang, Nenghai Yu", "title": "Self-supervised Adversarial Training", "comments": "Accepted to ICASSP 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent work has demonstrated that neural networks are vulnerable to\nadversarial examples. To escape from the predicament, many works try to harden\nthe model in various ways, in which adversarial training is an effective way\nwhich learns robust feature representation so as to resist adversarial attacks.\nMeanwhile, the self-supervised learning aims to learn robust and semantic\nembedding from data itself. With these views, we introduce self-supervised\nlearning to against adversarial examples in this paper. Specifically, the\nself-supervised representation coupled with k-Nearest Neighbour is proposed for\nclassification. To further strengthen the defense ability, self-supervised\nadversarial training is proposed, which maximizes the mutual information\nbetween the representations of original examples and the corresponding\nadversarial examples. Experimental results show that the self-supervised\nrepresentation outperforms its supervised version in respect of robustness and\nself-supervised adversarial training can further improve the defense ability\nefficiently.\n", "versions": [{"version": "v1", "created": "Fri, 15 Nov 2019 04:13:11 GMT"}, {"version": "v2", "created": "Sat, 1 Feb 2020 12:10:27 GMT"}], "update_date": "2020-02-04", "authors_parsed": [["Chen", "Kejiang", ""], ["Zhou", "Hang", ""], ["Chen", "Yuefeng", ""], ["Mao", "Xiaofeng", ""], ["Li", "Yuhong", ""], ["He", "Yuan", ""], ["Xue", "Hui", ""], ["Zhang", "Weiming", ""], ["Yu", "Nenghai", ""]]}, {"id": "1911.06471", "submitter": "Mojan Javaheripi", "authors": "Mojan Javaheripi and Mohammad Samragh and Tara Javidi and Farinaz\n  Koushanfar", "title": "ASCAI: Adaptive Sampling for acquiring Compact AI", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper introduces ASCAI, a novel adaptive sampling methodology that can\nlearn how to effectively compress Deep Neural Networks (DNNs) for accelerated\ninference on resource-constrained platforms. Modern DNN compression techniques\ncomprise various hyperparameters that require per-layer customization to ensure\nhigh accuracy. Choosing such hyperparameters is cumbersome as the pertinent\nsearch space grows exponentially with the number of model layers. To\neffectively traverse this large space, we devise an intelligent sampling\nmechanism that adapts the sampling strategy using customized operations\ninspired by genetic algorithms. As a special case, we consider the space of\nmodel compression as a vector space. The adaptively selected samples enable\nASCAI to automatically learn how to tune per-layer compression hyperparameters\nto optimize the accuracy/model-size trade-off. Our extensive evaluations show\nthat ASCAI outperforms rule-based and reinforcement learning methods in terms\nof compression rate and/or accuracy\n", "versions": [{"version": "v1", "created": "Fri, 15 Nov 2019 04:13:55 GMT"}], "update_date": "2019-11-18", "authors_parsed": [["Javaheripi", "Mojan", ""], ["Samragh", "Mohammad", ""], ["Javidi", "Tara", ""], ["Koushanfar", "Farinaz", ""]]}, {"id": "1911.06472", "submitter": "Prithwish Chakraborty", "authors": "Prithwish Chakraborty and Fei Wang and Jianying Hu and Daby Sow", "title": "Explicit-Blurred Memory Network for Analyzing Patient Electronic Health\n  Records", "comments": "accepted to DSHealth 20", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In recent years, we have witnessed an increased interest in temporal modeling\nof patient records from large scale Electronic Health Records (EHR). While\nsimpler RNN models have been used for such problems, memory networks, which in\nother domains were found to generalize well, are underutilized. Traditional\nmemory networks involve diffused and non-linear operations where influence of\npast events on outputs are not readily quantifiable. We posit that this lack of\ninterpretability makes such networks not applicable for EHR analysis. While\nnetworks with explicit memory have been proposed recently, the discontinuities\nimposed by the discrete operations make such networks harder to train and\nrequire more supervision. The problem is further exacerbated in the limited\ndata setting of EHR studies. In this paper, we propose a novel memory\narchitecture that is more interpretable than traditional memory networks while\nbeing easier to train than explicit memory banks. Inspired by well-known models\nof human cognition, we propose partitioning the external memory space into (a)\na primary explicit memory block to store exact replicas of recent events to\nsupport interpretations, followed by (b) a secondary blurred memory block that\naccumulates salient aspects of past events dropped from the explicit block as\nhigher level abstractions and allow training with less supervision by stabilize\nthe gradients. We apply the model for 3 learning problems on ICU records from\nthe MIMIC III database spanning millions of data points. Our model performs\ncomparably to the state-of the art while also, crucially, enabling ready\ninterpretation of the results.\n", "versions": [{"version": "v1", "created": "Fri, 15 Nov 2019 04:19:26 GMT"}, {"version": "v2", "created": "Mon, 13 Jul 2020 19:08:58 GMT"}], "update_date": "2020-07-15", "authors_parsed": [["Chakraborty", "Prithwish", ""], ["Wang", "Fei", ""], ["Hu", "Jianying", ""], ["Sow", "Daby", ""]]}, {"id": "1911.06478", "submitter": "Mingi Ji", "authors": "Mingi Ji, Weonyoung Joo, Kyungwoo Song, Yoon-Yeong Kim, Il-Chul Moon", "title": "Sequential Recommendation with Relation-Aware Kernelized Self-Attention", "comments": "8 pages, 5 figures, AAAI", "journal-ref": "AAAI 2020", "doi": null, "report-no": null, "categories": "cs.LG cs.IR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent studies identified that sequential Recommendation is improved by the\nattention mechanism. By following this development, we propose Relation-Aware\nKernelized Self-Attention (RKSA) adopting a self-attention mechanism of the\nTransformer with augmentation of a probabilistic model. The original\nself-attention of Transformer is a deterministic measure without\nrelation-awareness. Therefore, we introduce a latent space to the\nself-attention, and the latent space models the recommendation context from\nrelation as a multivariate skew-normal distribution with a kernelized\ncovariance matrix from co-occurrences, item characteristics, and user\ninformation. This work merges the self-attention of the Transformer and the\nsequential recommendation by adding a probabilistic model of the recommendation\ntask specifics. We experimented RKSA over the benchmark datasets, and RKSA\nshows significant improvements compared to the recent baseline models. Also,\nRKSA were able to produce a latent space model that answers the reasons for\nrecommendation.\n", "versions": [{"version": "v1", "created": "Fri, 15 Nov 2019 04:54:54 GMT"}], "update_date": "2019-11-18", "authors_parsed": [["Ji", "Mingi", ""], ["Joo", "Weonyoung", ""], ["Song", "Kyungwoo", ""], ["Kim", "Yoon-Yeong", ""], ["Moon", "Il-Chul", ""]]}, {"id": "1911.06479", "submitter": "Shufei Zhang Mr", "authors": "Shufei Zhang and Kaizhu Huang and Zenglin Xu", "title": "On Model Robustness Against Adversarial Examples", "comments": "some theoretical bounds need to be revised", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the model robustness against adversarial examples, referred to as\nsmall perturbed input data that may however fool many state-of-the-art deep\nlearning models. Unlike previous research, we establish a novel theory\naddressing the robustness issue from the perspective of stability of the loss\nfunction in the small neighborhood of natural examples. We propose to exploit\nan energy function to describe the stability and prove that reducing such\nenergy guarantees the robustness against adversarial examples. We also show\nthat the traditional training methods including adversarial training with the\n$l_2$ norm constraint (AT) and Virtual Adversarial Training (VAT) tend to\nminimize the lower bound of our proposed energy function. We make an analysis\nshowing that minimization of such lower bound can however lead to insufficient\nrobustness within the neighborhood around the input sample. Furthermore, we\ndesign a more rational method with the energy regularization which proves to\nachieve better robustness than previous methods. Through a series of\nexperiments, we demonstrate the superiority of our model on both supervised\ntasks and semi-supervised tasks. In particular, our proposed adversarial\nframework achieves the best performance compared with previous adversarial\ntraining methods on benchmark datasets MNIST, CIFAR-10, and SVHN. Importantly,\nthey demonstrate much better robustness against adversarial examples than all\nthe other comparison methods.\n", "versions": [{"version": "v1", "created": "Fri, 15 Nov 2019 05:02:25 GMT"}, {"version": "v2", "created": "Wed, 10 Jun 2020 05:26:51 GMT"}], "update_date": "2020-06-11", "authors_parsed": [["Zhang", "Shufei", ""], ["Huang", "Kaizhu", ""], ["Xu", "Zenglin", ""]]}, {"id": "1911.06486", "submitter": "Sohini Roychowdhury", "authors": "Sohini Roy Chowdhury, Lars Tornberg, Robin Halvfordsson, Jonatan\n  Nordh, Adam Suhren Gustafsson, Joel Wall, Mattias Westerberg, Adam Wirehed,\n  Louis Tilloy, Zhanying Hu, Haoyuan Tan, Meng Pan and Jonas Sjoberg", "title": "Automated Augmentation with Reinforcement Learning and GANs for Robust\n  Identification of Traffic Signs using Front Camera Images", "comments": "5 pages, 4 figures", "journal-ref": null, "doi": null, "report-no": "IEEE Asilomar SSC 2019", "categories": "cs.CV cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Traffic sign identification using camera images from vehicles plays a\ncritical role in autonomous driving and path planning. However, the front\ncamera images can be distorted due to blurriness, lighting variations and\nvandalism which can lead to degradation of detection performances. As a\nsolution, machine learning models must be trained with data from multiple\ndomains, and collecting and labeling more data in each new domain is time\nconsuming and expensive. In this work, we present an end-to-end framework to\naugment traffic sign training data using optimal reinforcement learning\npolicies and a variety of Generative Adversarial Network (GAN) models, that can\nthen be used to train traffic sign detector modules. Our automated augmenter\nenables learning from transformed nightime, poor lighting, and varying degrees\nof occlusions using the LISA Traffic Sign and BDD-Nexar dataset. The proposed\nmethod enables mapping training data from one domain to another, thereby\nimproving traffic sign detection precision/recall from 0.70/0.66 to 0.83/0.71\nfor nighttime images.\n", "versions": [{"version": "v1", "created": "Fri, 15 Nov 2019 06:23:50 GMT"}], "update_date": "2020-05-19", "authors_parsed": [["Chowdhury", "Sohini Roy", ""], ["Tornberg", "Lars", ""], ["Halvfordsson", "Robin", ""], ["Nordh", "Jonatan", ""], ["Gustafsson", "Adam Suhren", ""], ["Wall", "Joel", ""], ["Westerberg", "Mattias", ""], ["Wirehed", "Adam", ""], ["Tilloy", "Louis", ""], ["Hu", "Zhanying", ""], ["Tan", "Haoyuan", ""], ["Pan", "Meng", ""], ["Sjoberg", "Jonas", ""]]}, {"id": "1911.06487", "submitter": "Qi She", "authors": "Qi She, Fan Feng, Xinyue Hao, Qihan Yang, Chuanlin Lan, Vincenzo\n  Lomonaco, Xuesong Shi, Zhengwei Wang, Yao Guo, Yimin Zhang, Fei Qiao, Rosa H.\n  M. Chan", "title": "OpenLORIS-Object: A Robotic Vision Dataset and Benchmark for Lifelong\n  Deep Learning", "comments": "7 pages, 7 figures, 4 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG cs.RO stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The recent breakthroughs in computer vision have benefited from the\navailability of large representative datasets (e.g. ImageNet and COCO) for\ntraining. Yet, robotic vision poses unique challenges for applying visual\nalgorithms developed from these standard computer vision datasets due to their\nimplicit assumption over non-varying distributions for a fixed set of tasks.\nFully retraining models each time a new task becomes available is infeasible\ndue to computational, storage and sometimes privacy issues, while na\\\"{i}ve\nincremental strategies have been shown to suffer from catastrophic forgetting.\nIt is crucial for the robots to operate continuously under open-set and\ndetrimental conditions with adaptive visual perceptual systems, where lifelong\nlearning is a fundamental capability. However, very few datasets and benchmarks\nare available to evaluate and compare emerging techniques. To fill this gap, we\nprovide a new lifelong robotic vision dataset (\"OpenLORIS-Object\") collected\nvia RGB-D cameras. The dataset embeds the challenges faced by a robot in the\nreal-life application and provides new benchmarks for validating lifelong\nobject recognition algorithms. Moreover, we have provided a testbed of $9$\nstate-of-the-art lifelong learning algorithms. Each of them involves $48$ tasks\nwith $4$ evaluation metrics over the OpenLORIS-Object dataset. The results\ndemonstrate that the object recognition task in the ever-changing difficulty\nenvironments is far from being solved and the bottlenecks are at the\nforward/backward transfer designs. Our dataset and benchmark are publicly\navailable at at\n\\href{https://lifelong-robotic-vision.github.io/dataset/object}{\\underline{https://lifelong-robotic-vision.github.io/dataset/object}}.\n", "versions": [{"version": "v1", "created": "Fri, 15 Nov 2019 06:27:27 GMT"}, {"version": "v2", "created": "Fri, 6 Mar 2020 05:31:06 GMT"}], "update_date": "2020-03-09", "authors_parsed": [["She", "Qi", ""], ["Feng", "Fan", ""], ["Hao", "Xinyue", ""], ["Yang", "Qihan", ""], ["Lan", "Chuanlin", ""], ["Lomonaco", "Vincenzo", ""], ["Shi", "Xuesong", ""], ["Wang", "Zhengwei", ""], ["Guo", "Yao", ""], ["Zhang", "Yimin", ""], ["Qiao", "Fei", ""], ["Chan", "Rosa H. M.", ""]]}, {"id": "1911.06489", "submitter": "Yanjie Gou", "authors": "Yanjie Gou, Yinjie Lei, Lingqiao Liu, Pingping Zhang, Xi Peng", "title": "Improving Distant Supervised Relation Extraction by Dynamic Neural\n  Network", "comments": "29 pages, 8 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Distant Supervised Relation Extraction (DSRE) is usually formulated as a\nproblem of classifying a bag of sentences that contain two query entities, into\nthe predefined relation classes. Most existing methods consider those relation\nclasses as distinct semantic categories while ignoring their potential\nconnection to query entities. In this paper, we propose to leverage this\nconnection to improve the relation extraction accuracy. Our key ideas are\ntwofold: (1) For sentences belonging to the same relation class, the expression\nstyle, i.e. words choice, can vary according to the query entities. To account\nfor this style shift, the model should adjust its parameters in accordance with\nentity types. (2) Some relation classes are semantically similar, and the\nentity types appear in one relation may also appear in others. Therefore, it\ncan be trained cross different relation classes and further enhance those\nclasses with few samples, i.e., long-tail classes. To unify these two\narguments, we developed a novel Dynamic Neural Network for Relation Extraction\n(DNNRE). The network adopts a novel dynamic parameter generator that\ndynamically generates the network parameters according to the query entity\ntypes and relation classes. By using this mechanism, the network can\nsimultaneously handle the style shift problem and enhance the prediction\naccuracy for long-tail classes. Through our experimental study, we demonstrate\nthe effectiveness of the proposed method and show that it can achieve superior\nperformance over the state-of-the-art methods.\n", "versions": [{"version": "v1", "created": "Fri, 15 Nov 2019 06:31:13 GMT"}, {"version": "v2", "created": "Fri, 13 Dec 2019 04:29:41 GMT"}], "update_date": "2019-12-16", "authors_parsed": [["Gou", "Yanjie", ""], ["Lei", "Yinjie", ""], ["Liu", "Lingqiao", ""], ["Zhang", "Pingping", ""], ["Peng", "Xi", ""]]}, {"id": "1911.06502", "submitter": "Kazuhiro Takemoto", "authors": "Hokuto Hirano, Kazuhiro Takemoto", "title": "Simple iterative method for generating targeted universal adversarial\n  perturbations", "comments": "4 pages, 3 figures, 1 table", "journal-ref": "Algorithms 13, 268 (2020)", "doi": "10.3390/a13110268", "report-no": null, "categories": "cs.CV cs.CR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep neural networks (DNNs) are vulnerable to adversarial attacks. In\nparticular, a single perturbation known as the universal adversarial\nperturbation (UAP) can foil most classification tasks conducted by DNNs. Thus,\ndifferent methods for generating UAPs are required to fully evaluate the\nvulnerability of DNNs. A realistic evaluation would be with cases that consider\ntargeted attacks; wherein the generated UAP causes DNN to classify an input\ninto a specific class. However, the development of UAPs for targeted attacks\nhas largely fallen behind that of UAPs for non-targeted attacks. Therefore, we\npropose a simple iterative method to generate UAPs for targeted attacks. Our\nmethod combines the simple iterative method for generating non-targeted UAPs\nand the fast gradient sign method for generating a targeted adversarial\nperturbation for an input. We applied the proposed method to state-of-the-art\nDNN models for image classification and proved the existence of almost\nimperceptible UAPs for targeted attacks; further, we demonstrated that such\nUAPs are easily generatable.\n", "versions": [{"version": "v1", "created": "Fri, 15 Nov 2019 08:02:20 GMT"}, {"version": "v2", "created": "Mon, 18 Nov 2019 05:53:03 GMT"}], "update_date": "2020-10-23", "authors_parsed": [["Hirano", "Hokuto", ""], ["Takemoto", "Kazuhiro", ""]]}, {"id": "1911.06509", "submitter": "Koujin Takeda", "authors": "Shun Kimura, Koujin Takeda", "title": "Improved algorithm for neuronal ensemble inference by Monte Carlo method", "comments": "14 pages, 3 figures", "journal-ref": "Proceedings of NetSci-X 2020, pp.77-90", "doi": "10.1007/978-3-030-38965-9_6", "report-no": null, "categories": "cond-mat.dis-nn cs.LG q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Neuronal ensemble inference is one of the significant problems in the study\nof biological neural networks. Various methods have been proposed for ensemble\ninference from their activity data taken experimentally. Here we focus on\nBayesian inference approach for ensembles with generative model, which was\nproposed in recent work. However, this method requires large computational\ncost, and the result sometimes gets stuck in bad local maximum solution of\nBayesian inference. In this work, we give improved Bayesian inference algorithm\nfor these problems. We modify ensemble generation rule in Markov chain Monte\nCarlo method, and introduce the idea of simulated annealing for hyperparameter\ncontrol. We also compare the performance of ensemble inference between our\nalgorithm and the original one.\n", "versions": [{"version": "v1", "created": "Fri, 15 Nov 2019 08:16:28 GMT"}], "update_date": "2020-03-30", "authors_parsed": [["Kimura", "Shun", ""], ["Takeda", "Koujin", ""]]}, {"id": "1911.06515", "submitter": "Ryo Kamoi", "authors": "Ryo Kamoi, Kei Kobayashi", "title": "Likelihood Assignment for Out-of-Distribution Inputs in Deep Generative\n  Models is Sensitive to Prior Distribution Choice", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent work has shown that deep generative models assign higher likelihood to\nout-of-distribution inputs than to training data. We show that a factor\nunderlying this phenomenon is a mismatch between the nature of the prior\ndistribution and that of the data distribution, a problem found in widely used\ndeep generative models such as VAEs and Glow. While a typical choice for a\nprior distribution is a standard Gaussian distribution, properties of\ndistributions of real data sets may not be consistent with a unimodal prior\ndistribution. This paper focuses on the relationship between the choice of a\nprior distribution and the likelihoods assigned to out-of-distribution inputs.\nWe propose the use of a mixture distribution as a prior to make likelihoods\nassigned by deep generative models sensitive to out-of-distribution inputs.\nFurthermore, we explain the theoretical advantages of adopting a mixture\ndistribution as the prior, and we present experimental results to support our\nclaims. Finally, we demonstrate that a mixture prior lowers the\nout-of-distribution likelihood with respect to two pairs of real image data\nsets: Fashion-MNIST vs. MNIST and CIFAR10 vs. SVHN.\n", "versions": [{"version": "v1", "created": "Fri, 15 Nov 2019 08:40:45 GMT"}], "update_date": "2019-11-18", "authors_parsed": [["Kamoi", "Ryo", ""], ["Kobayashi", "Kei", ""]]}, {"id": "1911.06537", "submitter": "Graziano Mita", "authors": "Graziano Mita, Paolo Papotti, Maurizio Filippone, Pietro Michiardi", "title": "LIBRE: Learning Interpretable Boolean Rule Ensembles", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a novel method - LIBRE - to learn an interpretable classifier,\nwhich materializes as a set of Boolean rules. LIBRE uses an ensemble of\nbottom-up weak learners operating on a random subset of features, which allows\nfor the learning of rules that generalize well on unseen data even in\nimbalanced settings. Weak learners are combined with a simple union so that the\nfinal ensemble is also interpretable. Experimental results indicate that LIBRE\nefficiently strikes the right balance between prediction accuracy, which is\ncompetitive with black box methods, and interpretability, which is often\nsuperior to alternative methods from the literature.\n", "versions": [{"version": "v1", "created": "Fri, 15 Nov 2019 09:45:31 GMT"}], "update_date": "2019-11-18", "authors_parsed": [["Mita", "Graziano", ""], ["Papotti", "Paolo", ""], ["Filippone", "Maurizio", ""], ["Michiardi", "Pietro", ""]]}, {"id": "1911.06556", "submitter": "Marco Gallieri", "authors": "Marco Gallieri and Seyed Sina Mirrazavi Salehian and Nihat Engin Toklu\n  and Alessio Quaglino and Jonathan Masci and Jan Koutn\\'ik and Faustino Gomez", "title": "Safe Interactive Model-Based Learning", "comments": "NeurIPS 2019 workshop on Safety and Robustness in Decision-Making", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.SY cs.LG cs.NE cs.SY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Control applications present hard operational constraints. A violation of\nthese can result in unsafe behavior. This paper introduces Safe Interactive\nModel Based Learning (SiMBL), a framework to refine an existing controller and\na system model while operating on the real environment. SiMBL is composed of\nthe following trainable components: a Lyapunov function, which determines a\nsafe set; a safe control policy; and a Bayesian RNN forward model. A min-max\ncontrol framework, based on alternate minimisation and backpropagation through\nthe forward model, is used for the offline computation of the controller and\nthe safe set. Safety is formally verified a-posteriori with a probabilistic\nmethod that utilizes the Noise Contrastive Priors (NPC) idea to build a\nBayesian RNN forward model with an additive state uncertainty estimate which is\nlarge outside the training data distribution. Iterative refinement of the model\nand the safe set is achieved thanks to a novel loss that conditions the\nuncertainty estimates of the new model to be close to the current one. The\nlearned safe set and model can also be used for safe exploration, i.e., to\ncollect data within the safe invariant set, for which a simple one-step MPC is\nproposed. The single components are tested on the simulation of an inverted\npendulum with limited torque and stability region, showing that iteratively\nadding more data can improve the model, the controller and the size of the safe\nregion.\n", "versions": [{"version": "v1", "created": "Fri, 15 Nov 2019 10:34:45 GMT"}, {"version": "v2", "created": "Mon, 18 Nov 2019 09:54:23 GMT"}], "update_date": "2019-11-19", "authors_parsed": [["Gallieri", "Marco", ""], ["Salehian", "Seyed Sina Mirrazavi", ""], ["Toklu", "Nihat Engin", ""], ["Quaglino", "Alessio", ""], ["Masci", "Jonathan", ""], ["Koutn\u00edk", "Jan", ""], ["Gomez", "Faustino", ""]]}, {"id": "1911.06557", "submitter": "Liang Yang", "authors": "Liang Yang, Xi-Zhu Wu, Yuan Jiang, Zhi-Hua Zhou", "title": "Multi-Label Learning with Deep Forest", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In multi-label learning, each instance is associated with multiple labels and\nthe crucial task is how to leverage label correlations in building models. Deep\nneural network methods usually jointly embed the feature and label information\ninto a latent space to exploit label correlations. However, the success of\nthese methods highly depends on the precise choice of model depth. Deep forest\nis a recent deep learning framework based on tree model ensembles, which does\nnot rely on backpropagation. We consider the advantages of deep forest models\nare very appropriate for solving multi-label problems. Therefore we design the\nMulti-Label Deep Forest (MLDF) method with two mechanisms: measure-aware\nfeature reuse and measure-aware layer growth. The measure-aware feature reuse\nmechanism reuses the good representation in the previous layer guided by\nconfidence. The measure-aware layer growth mechanism ensures MLDF gradually\nincrease the model complexity by performance measure. MLDF handles two\nchallenging problems at the same time: one is restricting the model complexity\nto ease the overfitting issue; another is optimizing the performance measure on\nuser's demand since there are many different measures in the multi-label\nevaluation. Experiments show that our proposal not only beats the compared\nmethods over six measures on benchmark datasets but also enjoys label\ncorrelation discovery and other desired properties in multi-label learning.\n", "versions": [{"version": "v1", "created": "Fri, 15 Nov 2019 10:40:12 GMT"}], "update_date": "2019-11-18", "authors_parsed": [["Yang", "Liang", ""], ["Wu", "Xi-Zhu", ""], ["Jiang", "Yuan", ""], ["Zhou", "Zhi-Hua", ""]]}, {"id": "1911.06591", "submitter": "YueFeng Chen", "authors": "Xiaodan Li, Yuefeng Chen, Yuan He, Hui Xue", "title": "AdvKnn: Adversarial Attacks On K-Nearest Neighbor Classifiers With\n  Approximate Gradients", "comments": "Submitted to ICASSP 2020, Implementation\n  https://github.com/fiona-lxd/AdvKnn", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep neural networks have been shown to be vulnerable to adversarial\nexamples---maliciously crafted examples that can trigger the target model to\nmisbehave by adding imperceptible perturbations. Existing attack methods for\nk-nearest neighbor~(kNN) based algorithms either require large perturbations or\nare not applicable for large k. To handle this problem, this paper proposes a\nnew method called AdvKNN for evaluating the adversarial robustness of kNN-based\nmodels. Firstly, we propose a deep kNN block to approximate the output of kNN\nmethods, which is differentiable thus can provide gradients for attacks to\ncross the decision boundary with small distortions. Second, a new consistency\nlearning for distribution instead of classification is proposed for the\neffectiveness in distribution based methods. Extensive experimental results\nindicate that the proposed method significantly outperforms state of the art in\nterms of attack success rate and the added perturbations.\n", "versions": [{"version": "v1", "created": "Fri, 15 Nov 2019 12:42:10 GMT"}, {"version": "v2", "created": "Fri, 29 Nov 2019 11:10:18 GMT"}], "update_date": "2019-12-02", "authors_parsed": [["Li", "Xiaodan", ""], ["Chen", "Yuefeng", ""], ["He", "Yuan", ""], ["Xue", "Hui", ""]]}, {"id": "1911.06600", "submitter": "Duc Nguyen", "authors": "Anh-Duc Nguyen, Seonghwa Choi, Woojae Kim, Sanghoon Lee", "title": "GraphX-Convolution for Point Cloud Deformation in 2D-to-3D Conversion", "comments": "In Proceedings of the IEEE International Conference on Computer\n  Vision 2019. Fixed minor details and added some updates. Project page:\n  https://git.io/JeovA", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.CG cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we present a novel deep method to reconstruct a point cloud of\nan object from a single still image. Prior arts in the field struggle to\nreconstruct an accurate and scalable 3D model due to either the inefficient and\nexpensive 3D representations, the dependency between the output and number of\nmodel parameters or the lack of a suitable computing operation. We propose to\novercome these by deforming a random point cloud to the object shape through\ntwo steps: feature blending and deformation. In the first step, the global and\npoint-specific shape features extracted from a 2D object image are blended with\nthe encoded feature of a randomly generated point cloud, and then this mixture\nis sent to the deformation step to produce the final representative point set\nof the object. In the deformation process, we introduce a new layer termed as\nGraphX that considers the inter-relationship between points like common graph\nconvolutions but operates on unordered sets. Moreover, with a simple trick, the\nproposed model can generate an arbitrary-sized point cloud, which is the first\ndeep method to do so. Extensive experiments verify that we outperform existing\nmodels and halve the state-of-the-art distance score in single image 3D\nreconstruction.\n", "versions": [{"version": "v1", "created": "Fri, 15 Nov 2019 13:14:13 GMT"}], "update_date": "2019-11-18", "authors_parsed": [["Nguyen", "Anh-Duc", ""], ["Choi", "Seonghwa", ""], ["Kim", "Woojae", ""], ["Lee", "Sanghoon", ""]]}, {"id": "1911.06603", "submitter": "Pavel Karpov Dr", "authors": "Pavel Karpov and Guillaume Godin and Igor V. Tetko", "title": "Transformer-CNN: Fast and Reliable tool for QSAR", "comments": null, "journal-ref": null, "doi": "10.1186/s13321-020-00423-w", "report-no": null, "categories": "q-bio.QM cs.CL cs.LG", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  We present SMILES-embeddings derived from the internal encoder state of a\nTransformer [1] model trained to canonize SMILES as a Seq2Seq problem. Using a\nCharNN [2] architecture upon the embeddings results in higher quality\ninterpretable QSAR/QSPR models on diverse benchmark datasets including\nregression and classification tasks. The proposed Transformer-CNN method uses\nSMILES augmentation for training and inference, and thus the prognosis is based\non an internal consensus. That both the augmentation and transfer learning are\nbased on embeddings allows the method to provide good results for small\ndatasets. We discuss the reasons for such effectiveness and draft future\ndirections for the development of the method. The source code and the\nembeddings needed to train a QSAR model are available on\nhttps://github.com/bigchem/transformer-cnn. The repository also has a\nstandalone program for QSAR prognosis which calculates individual atoms\ncontributions, thus interpreting the model's result. OCHEM [3] environment\n(https://ochem.eu) hosts the on-line implementation of the method proposed.\n", "versions": [{"version": "v1", "created": "Mon, 21 Oct 2019 12:49:55 GMT"}, {"version": "v2", "created": "Tue, 25 Feb 2020 13:35:29 GMT"}, {"version": "v3", "created": "Wed, 26 Feb 2020 14:43:18 GMT"}], "update_date": "2020-09-23", "authors_parsed": [["Karpov", "Pavel", ""], ["Godin", "Guillaume", ""], ["Tetko", "Igor V.", ""]]}, {"id": "1911.06612", "submitter": "Dustin Juliano", "authors": "Dustin Juliano", "title": "Position Paper: Towards Transparent Machine Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Transparent machine learning is introduced as an alternative form of machine\nlearning, where both the model and the learning system are represented in\nsource code form. The goal of this project is to enable direct human\nunderstanding of machine learning models, giving us the ability to learn,\nverify, and refine them as programs. If solved, this technology could represent\na best-case scenario for the safety and security of AI systems going forward.\n", "versions": [{"version": "v1", "created": "Tue, 12 Nov 2019 10:49:55 GMT"}], "update_date": "2019-11-18", "authors_parsed": [["Juliano", "Dustin", ""]]}, {"id": "1911.06615", "submitter": "D\\'avid Sztah\\'o", "authors": "D\\'avid Sztah\\'o, Gy\\\"orgy Szasz\\'ak, Andr\\'as Beke", "title": "Deep learning methods in speaker recognition: a review", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.AS cs.LG cs.SD stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper summarizes the applied deep learning practices in the field of\nspeaker recognition, both verification and identification. Speaker recognition\nhas been a widely used field topic of speech technology. Many research works\nhave been carried out and little progress has been achieved in the past 5-6\nyears. However, as deep learning techniques do advance in most machine learning\nfields, the former state-of-the-art methods are getting replaced by them in\nspeaker recognition too. It seems that DL becomes the now state-of-the-art\nsolution for both speaker verification and identification. The standard\nx-vectors, additional to i-vectors, are used as baseline in most of the novel\nworks. The increasing amount of gathered data opens up the territory to DL,\nwhere they are the most effective.\n", "versions": [{"version": "v1", "created": "Thu, 14 Nov 2019 12:32:07 GMT"}], "update_date": "2019-11-18", "authors_parsed": [["Sztah\u00f3", "D\u00e1vid", ""], ["Szasz\u00e1k", "Gy\u00f6rgy", ""], ["Beke", "Andr\u00e1s", ""]]}, {"id": "1911.06616", "submitter": "G\\\"unter Klambauer", "authors": "Susanne Kimeswenger, Elisabeth Rumetshofer, Markus Hofmarcher, Philipp\n  Tschandl, Harald Kittler, Sepp Hochreiter, Wolfram H\\\"otzenecker, G\\\"unter\n  Klambauer", "title": "Detecting cutaneous basal cell carcinomas in ultra-high resolution and\n  weakly labelled histopathological images", "comments": "Machine Learning for Health (ML4H) at NeurIPS 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.IV cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Diagnosing basal cell carcinomas (BCC), one of the most common cutaneous\nmalignancies in humans, is a task regularly performed by pathologists and\ndermato-pathologists. Improving histological diagnosis by providing diagnosis\nsuggestions, i.e. computer-assisted diagnoses is actively researched to improve\nsafety, quality and efficiency. Increasingly, machine learning methods are\napplied due to their superior performance. However, typical images obtained by\nscanning histological sections often have a resolution that is prohibitive for\nprocessing with current state-of-the-art neural networks. Furthermore, the data\npose a problem of weak labels, since only a tiny fraction of the image is\nindicative of the disease class, whereas a large fraction of the image is\nhighly similar to the non-disease class. The aim of this study is to evaluate\nwhether it is possible to detect basal cell carcinomas in histological sections\nusing attention-based deep learning models and to overcome the ultra-high\nresolution and the weak labels of whole slide images. We demonstrate that\nattention-based models can indeed yield almost perfect classification\nperformance with an AUC of 0.99.\n", "versions": [{"version": "v1", "created": "Thu, 14 Nov 2019 17:45:59 GMT"}, {"version": "v2", "created": "Tue, 19 Nov 2019 08:41:40 GMT"}, {"version": "v3", "created": "Mon, 2 Dec 2019 10:35:25 GMT"}], "update_date": "2019-12-03", "authors_parsed": [["Kimeswenger", "Susanne", ""], ["Rumetshofer", "Elisabeth", ""], ["Hofmarcher", "Markus", ""], ["Tschandl", "Philipp", ""], ["Kittler", "Harald", ""], ["Hochreiter", "Sepp", ""], ["H\u00f6tzenecker", "Wolfram", ""], ["Klambauer", "G\u00fcnter", ""]]}, {"id": "1911.06621", "submitter": "Shiyu Liu", "authors": "Shiyu Liu and Mehul Motani", "title": "Long-range Prediction of Vital Signs Using Generative Boosting via LSTM\n  Networks", "comments": "Machine Learning for Health (ML4H) at NeurIPS 2019 - Extended\n  Abstract", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG eess.SP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Vital signs including heart rate, respiratory rate, body temperature and\nblood pressure, are critical in the clinical decision making process. Effective\nearly prediction of vital signs help to alert medical practitioner ahead of\ntime and may prevent adverse health outcomes. In this paper, we suggest a new\napproach called generative boosting, in order to effectively perform early\nprediction of vital signs. Generative boosting consists of a generative model,\nto generate synthetic data for next few time steps, and several predictive\nmodels, to directly make long-range predictions based on observed and generated\ndata. We explore generative boosting via long short-term memory (LSTM) for both\nthe predictive and generative models, leading to a scheme called generative\nLSTM (GLSTM). Our experiments indicate that GLSTM outperforms a diverse range\nof strong benchmark models, with and without generative boosting. Finally, we\nuse a mutual information based clustering algorithm to select a more\nrepresentative dataset to train the generative model of GLSTM. This\nsignificantly improves the long-range predictive performance of high variation\nvital signs such as heart rate and systolic blood pressure.\n", "versions": [{"version": "v1", "created": "Thu, 14 Nov 2019 05:56:07 GMT"}], "update_date": "2019-11-18", "authors_parsed": [["Liu", "Shiyu", ""], ["Motani", "Mehul", ""]]}, {"id": "1911.06623", "submitter": "Vikas Ramachandra", "authors": "Vikas Ramachandra", "title": "Deep Clustering for Mars Rover image datasets", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "astro-ph.IM astro-ph.EP cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we build autoencoders to learn a latent space from unlabeled\nimage datasets obtained from the Mars rover. Then, once the latent feature\nspace has been learnt, we use k-means to cluster the data. We test the\nperformance of the algorithm on a smaller labeled dataset, and report good\naccuracy and concordance with the ground truth labels. This is the first\nattempt to use deep learning based unsupervised algorithms to cluster Mars\nRover images. This algorithm can be used to augment human annotations for such\ndatasets (which are time consuming) and speed up the generation of ground truth\nlabels for Mars Rover image data, and potentially other planetary and space\nimages.\n", "versions": [{"version": "v1", "created": "Tue, 12 Nov 2019 21:31:07 GMT"}], "update_date": "2019-11-18", "authors_parsed": [["Ramachandra", "Vikas", ""]]}, {"id": "1911.06641", "submitter": "Zhiwei Liang", "authors": "Zhiyue Liu, Jiahai Wang, Zhiwei Liang", "title": "CatGAN: Category-aware Generative Adversarial Networks with Hierarchical\n  Evolutionary Learning for Category Text Generation", "comments": "15 pages, 4 figures. Accepted by AAAI 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Generating multiple categories of texts is a challenging task and draws more\nand more attention. Since generative adversarial nets (GANs) have shown\ncompetitive results on general text generation, they are extended for category\ntext generation in some previous works. However, the complicated model\nstructures and learning strategies limit their performance and exacerbate the\ntraining instability. This paper proposes a category-aware GAN (CatGAN) which\nconsists of an efficient category-aware model for category text generation and\na hierarchical evolutionary learning algorithm for training our model. The\ncategory-aware model directly measures the gap between real samples and\ngenerated samples on each category, then reducing this gap will guide the model\nto generate high-quality category samples. The Gumbel-Softmax relaxation\nfurther frees our model from complicated learning strategies for updating\nCatGAN on discrete data. Moreover, only focusing on the sample quality normally\nleads the mode collapse problem, thus a hierarchical evolutionary learning\nalgorithm is introduced to stabilize the training procedure and obtain the\ntrade-off between quality and diversity while training CatGAN. Experimental\nresults demonstrate that CatGAN outperforms most of the existing\nstate-of-the-art methods.\n", "versions": [{"version": "v1", "created": "Fri, 15 Nov 2019 14:03:30 GMT"}, {"version": "v2", "created": "Wed, 20 Nov 2019 09:16:28 GMT"}], "update_date": "2019-11-21", "authors_parsed": [["Liu", "Zhiyue", ""], ["Wang", "Jiahai", ""], ["Liang", "Zhiwei", ""]]}, {"id": "1911.06643", "submitter": "Andrew Cropper", "authors": "Andrew Cropper", "title": "Forgetting to learn logic programs", "comments": "AAAI20", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Most program induction approaches require predefined, often hand-engineered,\nbackground knowledge (BK). To overcome this limitation, we explore methods to\nautomatically acquire BK through multi-task learning. In this approach, a\nlearner adds learned programs to its BK so that they can be reused to help\nlearn other programs. To improve learning performance, we explore the idea of\nforgetting, where a learner can additionally remove programs from its BK. We\nconsider forgetting in an inductive logic programming (ILP) setting. We show\nthat forgetting can significantly reduce both the size of the hypothesis space\nand the sample complexity of an ILP learner. We introduce Forgetgol, a\nmulti-task ILP learner which supports forgetting. We experimentally compare\nForgetgol against approaches that either remember or forget everything. Our\nexperimental results show that Forgetgol outperforms the alternative approaches\nwhen learning from over 10,000 tasks.\n", "versions": [{"version": "v1", "created": "Fri, 15 Nov 2019 14:05:23 GMT"}], "update_date": "2019-11-18", "authors_parsed": [["Cropper", "Andrew", ""]]}, {"id": "1911.06646", "submitter": "David Cortes", "authors": "David Cortes", "title": "Imputing missing values with unsupervised random trees", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This work proposes a non-iterative strategy for missing value imputations\nwhich is guided by similarity between observations, but instead of explicitly\ndetermining distances or nearest neighbors, it assigns observations to\noverlapping buckets through recursive semi-random hyperplane cuts, in which\nweighted averages are determined as imputations for each variable. The quality\nof these imputations is oftentimes not as good as that of chained equations,\nbut the proposed technique is much faster, non-iterative, can make imputations\non new data without re-calculating anything, and scales easily to large and\nhigh-dimensional datasets, providing a significant boost over simple\nmean/median imputation in regression and classification metrics with imputed\nvalues when other methods are not feasible.\n", "versions": [{"version": "v1", "created": "Fri, 15 Nov 2019 14:12:06 GMT"}, {"version": "v2", "created": "Thu, 21 Nov 2019 20:47:01 GMT"}], "update_date": "2019-11-25", "authors_parsed": [["Cortes", "David", ""]]}, {"id": "1911.06663", "submitter": "Matthias Schubert", "authors": "Teodora Pandeva and Matthias Schubert", "title": "MMGAN: Generative Adversarial Networks for Multi-Modal Distributions", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Over the past years, Generative Adversarial Networks (GANs) have shown a\nremarkable generation performance especially in image synthesis. Unfortunately,\nthey are also known for having an unstable training process and might loose\nparts of the data distribution for heterogeneous input data. In this paper, we\npropose a novel GAN extension for multi-modal distribution learning (MMGAN). In\nour approach, we model the latent space as a Gaussian mixture model with a\nnumber of clusters referring to the number of disconnected data manifolds in\nthe observation space, and include a clustering network, which relates each\ndata manifold to one Gaussian cluster. Thus, the training gets more stable.\nMoreover, MMGAN allows for clustering real data according to the learned data\nmanifold in the latent space. By a series of benchmark experiments, we\nillustrate that MMGAN outperforms competitive state-of-the-art models in terms\nof clustering performance.\n", "versions": [{"version": "v1", "created": "Fri, 15 Nov 2019 14:31:02 GMT"}], "update_date": "2019-11-18", "authors_parsed": [["Pandeva", "Teodora", ""], ["Schubert", "Matthias", ""]]}, {"id": "1911.06679", "submitter": "Sean Augenstein", "authors": "Sean Augenstein, H. Brendan McMahan, Daniel Ramage, Swaroop Ramaswamy,\n  Peter Kairouz, Mingqing Chen, Rajiv Mathews, Blaise Aguera y Arcas", "title": "Generative Models for Effective ML on Private, Decentralized Datasets", "comments": "26 pages, 8 figures. Camera-ready ICLR 2020 version", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  To improve real-world applications of machine learning, experienced modelers\ndevelop intuition about their datasets, their models, and how the two interact.\nManual inspection of raw data - of representative samples, of outliers, of\nmisclassifications - is an essential tool in a) identifying and fixing problems\nin the data, b) generating new modeling hypotheses, and c) assigning or\nrefining human-provided labels. However, manual data inspection is problematic\nfor privacy sensitive datasets, such as those representing the behavior of\nreal-world individuals. Furthermore, manual data inspection is impossible in\nthe increasingly important setting of federated learning, where raw examples\nare stored at the edge and the modeler may only access aggregated outputs such\nas metrics or model parameters. This paper demonstrates that generative models\n- trained using federated methods and with formal differential privacy\nguarantees - can be used effectively to debug many commonly occurring data\nissues even when the data cannot be directly inspected. We explore these\nmethods in applications to text with differentially private federated RNNs and\nto images using a novel algorithm for differentially private federated GANs.\n", "versions": [{"version": "v1", "created": "Fri, 15 Nov 2019 14:56:44 GMT"}, {"version": "v2", "created": "Tue, 4 Feb 2020 22:38:20 GMT"}], "update_date": "2020-02-06", "authors_parsed": [["Augenstein", "Sean", ""], ["McMahan", "H. Brendan", ""], ["Ramage", "Daniel", ""], ["Ramaswamy", "Swaroop", ""], ["Kairouz", "Peter", ""], ["Chen", "Mingqing", ""], ["Mathews", "Rajiv", ""], ["Arcas", "Blaise Aguera y", ""]]}, {"id": "1911.06685", "submitter": "Drago Plecko", "authors": "Drago Ple\\v{c}ko, Nicolai Meinshausen", "title": "Fair Data Adaptation with Quantile Preservation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Fairness of classification and regression has received much attention\nrecently and various, partially non-compatible, criteria have been proposed.\nThe fairness criteria can be enforced for a given classifier or, alternatively,\nthe data can be adapated to ensure that every classifier trained on the data\nwill adhere to desired fairness criteria. We present a practical data adaption\nmethod based on quantile preservation in causal structural equation models. The\ndata adaptation is based on a presumed counterfactual model for the data. While\nthe counterfactual model itself cannot be verified experimentally, we show that\ncertain population notions of fairness are still guaranteed even if the\ncounterfactual model is misspecified. The precise nature of the fulfilled\nnon-causal fairness notion (such as demographic parity, separation or\nsufficiency) depends on the structure of the underlying causal model and the\nchoice of resolving variables. We describe an implementation of the proposed\ndata adaptation procedure based on Random Forests and demonstrate its practical\nuse on simulated and real-world data.\n", "versions": [{"version": "v1", "created": "Fri, 15 Nov 2019 15:16:24 GMT"}], "update_date": "2019-11-18", "authors_parsed": [["Ple\u010dko", "Drago", ""], ["Meinshausen", "Nicolai", ""]]}, {"id": "1911.06704", "submitter": "Tirtharaj Dash", "authors": "Rohit Kaushik, Shikhar Jain, Siddhant Jain, Tirtharaj Dash", "title": "Performance evaluation of deep neural networks for forecasting\n  time-series with multiple structural breaks and high volatility", "comments": "Preprint (18 pages)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The problem of automatic and accurate forecasting of time-series data has\nalways been an interesting challenge for the machine learning and forecasting\ncommunity. A majority of the real-world time-series problems have\nnon-stationary characteristics that make the understanding of trend and\nseasonality difficult. Our interest in this paper is to study the applicability\nof the popular deep neural networks (DNN) as function approximators for\nnon-stationary TSF. We evaluate the following DNN models: Multi-layer\nPerceptron (MLP), Convolutional Neural Network (CNN), and RNN with Long-Short\nTerm Memory (LSTM-RNN) and RNN with Gated-Recurrent Unit (GRU-RNN). These DNN\nmethods have been evaluated over 10 popular Indian financial stocks data.\nFurther, the performance evaluation of these DNNs has been carried out in\nmultiple independent runs for two settings of forecasting: (1) single-step\nforecasting, and (2) multi-step forecasting. These DNN methods show convincing\nperformance for single-step forecasting (one-day ahead forecast). For the\nmulti-step forecasting (multiple days ahead forecast), we have evaluated the\nmethods for different forecast periods. The performance of these methods\ndemonstrates that long forecast periods have an adverse effect on performance.\n", "versions": [{"version": "v1", "created": "Thu, 14 Nov 2019 16:44:23 GMT"}, {"version": "v2", "created": "Sat, 25 Jul 2020 13:26:36 GMT"}], "update_date": "2020-07-28", "authors_parsed": [["Kaushik", "Rohit", ""], ["Jain", "Shikhar", ""], ["Jain", "Siddhant", ""], ["Dash", "Tirtharaj", ""]]}, {"id": "1911.06716", "submitter": "Kumar Goutam", "authors": "Kumar Goutam, Vineet Goyal, Agathe Soret", "title": "A Generalized Markov Chain Model to Capture Dynamic Preferences and\n  Choice Overload", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "econ.TH cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Assortment optimization is an important problem that arises in many\nindustries such as retailing and online advertising where the goal is to find a\nsubset of products from a universe of substitutable products which maximize\nseller's expected revenue. One of the key challenges in this problem is to\nmodel the customer substitution behavior. Many parametric random utility\nmaximization (RUM) based choice models have been considered in the literature.\nHowever, in all these models, probability of purchase increases as we include\nmore products to an assortment. This is not true in general and in many\nsettings more choices hurt sales. This is commonly referred to as the choice\noverload. In this paper we attempt to address this limitation in RUM through a\ngeneralization of the Markov chain based choice model considered in Blanchet et\nal. (2016). As a special case, we show that our model reduces to a\ngeneralization of MNL with no-purchase attractions dependent on the assortment\nS and strictly increasing with the size of assortment S. While we show that the\nassortment optimization under this model is NP-hard, we present fully\npolynomial-time approximation scheme (FPTAS) under reasonable assumptions.\n", "versions": [{"version": "v1", "created": "Fri, 15 Nov 2019 16:02:16 GMT"}, {"version": "v2", "created": "Tue, 19 Nov 2019 16:34:27 GMT"}, {"version": "v3", "created": "Wed, 15 Jul 2020 17:15:18 GMT"}, {"version": "v4", "created": "Mon, 14 Dec 2020 04:23:19 GMT"}], "update_date": "2020-12-15", "authors_parsed": [["Goutam", "Kumar", ""], ["Goyal", "Vineet", ""], ["Soret", "Agathe", ""]]}, {"id": "1911.06722", "submitter": "Max Hinne", "authors": "Max Hinne, Marcel A.J. van Gerven, Luca Ambrogioni", "title": "Causal inference using Bayesian non-parametric quasi-experimental design", "comments": "17 pages, 5 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ME cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  The de facto standard for causal inference is the randomized controlled\ntrial, where one compares an manipulated group with a control group in order to\ndetermine the effect of an intervention. However, this research design is not\nalways realistically possible due to pragmatic or ethical concerns. In these\nsituations, quasi-experimental designs may provide a solution, as these allow\nfor causal conclusions at the cost of additional design assumptions. In this\npaper, we provide a framework for quasi-experimental design using Bayesian\nmodel comparison. We provide a theoretical motivation for a Gaussian process\nbased approach, and demonstrate its convenient use in a number of simulations.\nFinally, we apply the framework to determine the effect the 2005 smoking ban in\nSicily on the number of acute coronary events, and of the effect of an alleged\nhistorical phantom border in the Netherlands on Dutch voting behaviour.\n", "versions": [{"version": "v1", "created": "Fri, 15 Nov 2019 16:10:00 GMT"}, {"version": "v2", "created": "Thu, 16 Jul 2020 15:17:40 GMT"}], "update_date": "2020-07-17", "authors_parsed": [["Hinne", "Max", ""], ["van Gerven", "Marcel A. J.", ""], ["Ambrogioni", "Luca", ""]]}, {"id": "1911.06741", "submitter": "Behzad Kamgar-Parsi", "authors": "Behzad Kamgar-Parsi and Behrooz Kamgar-Parsi", "title": "Penalized k-means algorithms for finding the correct number of clusters\n  in a dataset", "comments": "15 pages, 8 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In many applications we want to find the number of clusters in a dataset. A\ncommon approach is to use the penalized k-means algorithm with an additive\npenalty term linear in the number of clusters. An open problem is estimating\nthe value of the coefficient of the penalty term. Since estimating the value of\nthe coefficient in a principled manner appears to be intractable for general\nclusters, we investigate \"ideal clusters\", i.e. identical spherical clusters\nwith no overlaps and no outlier background noise. In this paper: (a) We derive,\nfor the case of ideal clusters, rigorous bounds for the coefficient of the\nadditive penalty. Unsurprisingly, the bounds depend on the correct number of\nclusters, which we want to find in the first place. We further show that\nadditive penalty, even for this simplest case of ideal clusters, typically\nproduces a weak and often ambiguous signature for the correct number of\nclusters. (b) As an alternative, we examine the k-means with multiplicative\npenalty, and show that this parameter-free formulation has a stronger, and less\noften ambiguous, signature for the correct number of clusters. We also\nempirically investigate certain types of deviations from ideal cluster\nassumption and show that combination of k-means with additive and\nmultiplicative penalties can resolve ambiguous solutions.\n", "versions": [{"version": "v1", "created": "Fri, 15 Nov 2019 16:49:10 GMT"}], "update_date": "2019-11-18", "authors_parsed": [["Kamgar-Parsi", "Behzad", ""], ["Kamgar-Parsi", "Behrooz", ""]]}, {"id": "1911.06747", "submitter": "Maryam Fazel-Zarandi", "authors": "Maryam Fazel-Zarandi, Sampat Biswas, Ryan Summers, Ahmed Elmalt, Andy\n  McCraw, Michael McPhilips, John Peach", "title": "Towards Personalized Dialog Policies for Conversational Skill Discovery", "comments": "The 3rd Conversational AI workshop - today's practice and tomorrow's\n  potential", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.HC cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Many businesses and consumers are extending the capabilities of voice-based\nservices such as Amazon Alexa, Google Home, Microsoft Cortana, and Apple Siri\nto create custom voice experiences (also known as skills). As the number of\nthese experiences increases, a key problem is the discovery of skills that can\nbe used to address a user's request. In this paper, we focus on conversational\nskill discovery and present a conversational agent which engages in a dialog\nwith users to help them find the skills that fulfill their needs. To this end,\nwe start with a rule-based agent and improve it by using reinforcement\nlearning. In this way, we enable the agent to adapt to different user\nattributes and conversational styles as it interacts with users. We evaluate\nour approach in a real production setting by deploying the agent to interact\nwith real users, and show the effectiveness of the conversational agent in\nhelping users find the skills that serve their request.\n", "versions": [{"version": "v1", "created": "Fri, 15 Nov 2019 16:56:17 GMT"}], "update_date": "2019-11-18", "authors_parsed": [["Fazel-Zarandi", "Maryam", ""], ["Biswas", "Sampat", ""], ["Summers", "Ryan", ""], ["Elmalt", "Ahmed", ""], ["McCraw", "Andy", ""], ["McPhilips", "Michael", ""], ["Peach", "John", ""]]}, {"id": "1911.06750", "submitter": "Chanyoung Park", "authors": "Chanyoung Park, Donghyun Kim, Jiawei Han, Hwanjo Yu", "title": "Unsupervised Attributed Multiplex Network Embedding", "comments": "AAAI 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Nodes in a multiplex network are connected by multiple types of relations.\nHowever, most existing network embedding methods assume that only a single type\nof relation exists between nodes. Even for those that consider the multiplexity\nof a network, they overlook node attributes, resort to node labels for\ntraining, and fail to model the global properties of a graph. We present a\nsimple yet effective unsupervised network embedding method for attributed\nmultiplex network called DMGI, inspired by Deep Graph Infomax (DGI) that\nmaximizes the mutual information between local patches of a graph, and the\nglobal representation of the entire graph. We devise a systematic way to\njointly integrate the node embeddings from multiple graphs by introducing 1)\nthe consensus regularization framework that minimizes the disagreements among\nthe relation-type specific node embeddings, and 2) the universal discriminator\nthat discriminates true samples regardless of the relation types. We also show\nthat the attention mechanism infers the importance of each relation type, and\nthus can be useful for filtering unnecessary relation types as a preprocessing\nstep. Extensive experiments on various downstream tasks demonstrate that DMGI\noutperforms the state-of-the-art methods, even though DMGI is fully\nunsupervised.\n", "versions": [{"version": "v1", "created": "Fri, 15 Nov 2019 17:08:03 GMT"}, {"version": "v2", "created": "Sun, 29 Mar 2020 02:22:54 GMT"}], "update_date": "2020-03-31", "authors_parsed": [["Park", "Chanyoung", ""], ["Kim", "Donghyun", ""], ["Han", "Jiawei", ""], ["Yu", "Hwanjo", ""]]}, {"id": "1911.06777", "submitter": "Ali Jahanshahi", "authors": "Ali Jahanshahi", "title": "TinyCNN: A Tiny Modular CNN Accelerator for Embedded FPGA", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://creativecommons.org/publicdomain/zero/1.0/", "abstract": "  In recent years, Convolutional Neural Network (CNN) based methods have\nachieved great success in a large number of applications and have been among\nthe most powerful and widely used techniques in computer vision. However,\nCNN-based methods are computational-intensive and resource-consuming, and thus\nare hard to be integrated into embedded systems such as smart phones, smart\nglasses, and robots. FPGA is one of the most promising platforms for\naccelerating CNN, but the limited on-chip memory size limit the performance of\nFPGA accelerator for CNN. In this paper, we propose a framework for designing\nCNN accelerator on embedded FPGA for image classification. The proposed\nframework provides a tool for FPGA resource-aware design space exploration of\nCNNs and automatically generates the hardware description of the CNN to be\nprogrammed on a target FPGA. The framework consists of three main backends;\nsoftware, hardware generation, and simulation/precision adjustment. The\nsoftware backend serves as an API to the designer to design the CNN and train\nit according to the hardware resources that are available. Using the CNN model,\nhardware backend generates the necessary hardware components and integrates\nthem to generate the hardware description of the CNN. Finaly,\nSimulation/precision adjustment backend adjusts the inter-layer precision units\nto minimize the classification error. We used 16-bit fixed-point data in a CNN\naccelerator (FPGA) and compared it to the exactly similar software version\nrunning on an ARM processor (32-bit floating point data). We encounter about 3%\naccuracy loss in classification of the accelerated (FPGA) version. In return,\nwe got up to 15.75x speedup by classifying with the accelerated version on the\nFPGA.\n", "versions": [{"version": "v1", "created": "Fri, 15 Nov 2019 17:42:52 GMT"}], "update_date": "2019-11-18", "authors_parsed": [["Jahanshahi", "Ali", ""]]}, {"id": "1911.06786", "submitter": "Akshay Kulkarni", "authors": "Akshay Kulkarni, Navid Panchi, Sharath Chandra Raparthy and Shital\n  Chiddarwar", "title": "Data Efficient Stagewise Knowledge Distillation", "comments": "15 pages, 1 figure, 6 tables and 1 algorithm", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Despite the success of Deep Learning (DL), the deployment of modern DL models\nrequiring large computational power poses a significant problem for\nresource-constrained systems. This necessitates building compact networks that\nreduce computations while preserving performance. Traditional Knowledge\nDistillation (KD) methods that transfer knowledge from teacher to student (a)\nuse a single-stage and (b) require the whole data set while distilling the\nknowledge to the student. In this work, we propose a new method called\nStagewise Knowledge Distillation (SKD) which builds on traditional KD methods\nby progressive stagewise training to leverage the knowledge gained from the\nteacher, resulting in data-efficient distillation process. We evaluate our\nmethod on classification and semantic segmentation tasks. We show, across the\ntested tasks, significant performance gains even with a fraction of the data\nused in distillation, without compromising on the metric. We also compare our\nmethod with existing KD techniques and show that SKD outperforms them.\nMoreover, our method can be viewed as a generalized model compression technique\nthat complements other model compression methods such as quantization or\npruning.\n", "versions": [{"version": "v1", "created": "Fri, 15 Nov 2019 18:06:26 GMT"}, {"version": "v2", "created": "Tue, 10 Dec 2019 10:47:40 GMT"}, {"version": "v3", "created": "Tue, 23 Jun 2020 09:02:52 GMT"}], "update_date": "2020-06-24", "authors_parsed": [["Kulkarni", "Akshay", ""], ["Panchi", "Navid", ""], ["Raparthy", "Sharath Chandra", ""], ["Chiddarwar", "Shital", ""]]}, {"id": "1911.06791", "submitter": "Francesco Quinzan", "authors": "Vanja Dosko\\v{c} and Tobias Friedrich and Andreas G\\\"obel and Frank\n  Neumann and Aneta Neumann and Francesco Quinzan", "title": "Non-Monotone Submodular Maximization with Multiple Knapsacks in Static\n  and Dynamic Settings", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the problem of maximizing a non-monotone submodular function under\nmultiple knapsack constraints. We propose a simple discrete greedy algorithm to\napproach this problem, and prove that it yields strong approximation guarantees\nfor functions with bounded curvature. In contrast to other heuristics, this\nrequires no problem relaxation to continuous domains and it maintains a\nconstant-factor approximation guarantee in the problem size. In the case of a\nsingle knapsack, our analysis suggests that the standard greedy can be used in\nnon-monotone settings.\n  Additionally, we study this problem in a dynamic setting, by which knapsacks\nchange during the optimization process. We modify our greedy algorithm to avoid\na complete restart at each constraint update. This modification retains the\napproximation guarantees of the static case.\n  We evaluate our results experimentally on a video summarization and sensor\nplacement task. We show that our proposed algorithm competes with the\nstate-of-the-art in static settings. Furthermore, we show that in dynamic\nsettings with tight computational time budget, our modified greedy yields\nsignificant improvements over starting the greedy from scratch, in terms of the\nsolution quality achieved.\n", "versions": [{"version": "v1", "created": "Fri, 15 Nov 2019 18:22:46 GMT"}, {"version": "v2", "created": "Mon, 18 Nov 2019 20:20:10 GMT"}, {"version": "v3", "created": "Tue, 18 Feb 2020 10:55:31 GMT"}], "update_date": "2020-02-19", "authors_parsed": [["Dosko\u010d", "Vanja", ""], ["Friedrich", "Tobias", ""], ["G\u00f6bel", "Andreas", ""], ["Neumann", "Frank", ""], ["Neumann", "Aneta", ""], ["Quinzan", "Francesco", ""]]}, {"id": "1911.06813", "submitter": "Alex Fedorov", "authors": "Usman Mahmood, Md Mahfuzur Rahman, Alex Fedorov, Zening Fu, Sergey\n  Plis", "title": "Transfer Learning of fMRI Dynamics", "comments": "Machine Learning for Health (ML4H) at NeurIPS 2019 - Extended\n  Abstract", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.IV cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  As a mental disorder progresses, it may affect brain structure, but brain\nfunction expressed in brain dynamics is affected much earlier. Capturing the\nmoment when brain dynamics express the disorder is crucial for early diagnosis.\nThe traditional approach to this problem via training classifiers either\nproceeds from handcrafted features or requires large datasets to combat the\n$m>>n$ problem when a high dimensional fMRI volume only has a single label that\ncarries learning signal. Large datasets may not be available for a study of\neach disorder, or rare disorder types or sub-populations may not warrant for\nthem. In this paper, we demonstrate a self-supervised pre-training method that\nenables us to pre-train directly on fMRI dynamics of healthy control subjects\nand transfer the learning to much smaller datasets of schizophrenia. Not only\nwe enable classification of disorder directly based on fMRI dynamics in small\ndata but also significantly speed up the learning when possible. This is\nencouraging evidence of informative transfer learning across datasets and\ndiagnostic categories.\n", "versions": [{"version": "v1", "created": "Sat, 16 Nov 2019 07:08:31 GMT"}], "update_date": "2019-11-19", "authors_parsed": [["Mahmood", "Usman", ""], ["Rahman", "Md Mahfuzur", ""], ["Fedorov", "Alex", ""], ["Fu", "Zening", ""], ["Plis", "Sergey", ""]]}, {"id": "1911.06816", "submitter": "Zahra Riahi Samani", "authors": "Zahra Riahi Samani, Jacob Antony Alappatt, Drew Parker, Abdol Aziz\n  Ould Ismail, Ragini Verma", "title": "QC-Automator: Deep Learning-based Automated Quality Control for\n  Diffusion MR Images", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.IV cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Quality assessment of diffusion MRI (dMRI) data is essential prior to any\nanalysis, so that appropriate pre-processing can be used to improve data\nquality and ensure that the presence of MRI artifacts do not affect the results\nof subsequent image analysis. Manual quality assessment of the data is\nsubjective, possibly error-prone, and infeasible, especially considering the\ngrowing number of consortium-like studies, underlining the need for automation\nof the process. In this paper, we have developed a deep-learning-based\nautomated quality control (QC) tool, QC-Automator, for dMRI data, that can\nhandle a variety of artifacts such as motion, multiband interleaving, ghosting,\nsusceptibility, herringbone and chemical shifts. QC-Automator uses\nconvolutional neural networks along with transfer learning to train the\nautomated artifact detection on a labeled dataset of ~332000 slices of dMRI\ndata, from 155 unique subjects and 5 scanners with different dMRI acquisitions,\nachieving a 98% accuracy in detecting artifacts. The method is fast and paves\nthe way for efficient and effective artifact detection in large datasets. It is\nalso demonstrated to be replicable on other datasets with different acquisition\nparameters.\n", "versions": [{"version": "v1", "created": "Fri, 15 Nov 2019 08:11:17 GMT"}], "update_date": "2019-11-19", "authors_parsed": [["Samani", "Zahra Riahi", ""], ["Alappatt", "Jacob Antony", ""], ["Parker", "Drew", ""], ["Ismail", "Abdol Aziz Ould", ""], ["Verma", "Ragini", ""]]}, {"id": "1911.06832", "submitter": "Kevin Sebastian Luck", "authors": "Kevin Sebastian Luck, Heni Ben Amor, Roberto Calandra", "title": "Data-efficient Co-Adaptation of Morphology and Behaviour with Deep\n  Reinforcement Learning", "comments": "Accepted for the Conference on Robot Learning 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.NE cs.RO stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Humans and animals are capable of quickly learning new behaviours to solve\nnew tasks. Yet, we often forget that they also rely on a highly specialized\nmorphology that co-adapted with motor control throughout thousands of years.\nAlthough compelling, the idea of co-adapting morphology and behaviours in\nrobots is often unfeasible because of the long manufacturing times, and the\nneed to re-design an appropriate controller for each morphology. In this paper,\nwe propose a novel approach to automatically and efficiently co-adapt a robot\nmorphology and its controller. Our approach is based on recent advances in deep\nreinforcement learning, and specifically the soft actor critic algorithm. Key\nto our approach is the possibility of leveraging previously tested morphologies\nand behaviors to estimate the performance of new candidate morphologies. As\nsuch, we can make full use of the information available for making more\ninformed decisions, with the ultimate goal of achieving a more data-efficient\nco-adaptation (i.e., reducing the number of morphologies and behaviors tested).\nSimulated experiments show that our approach requires drastically less design\nprototypes to find good morphology-behaviour combinations, making this method\nparticularly suitable for future co-adaptation of robot designs in the real\nworld.\n", "versions": [{"version": "v1", "created": "Fri, 15 Nov 2019 19:01:21 GMT"}], "update_date": "2019-11-19", "authors_parsed": [["Luck", "Kevin Sebastian", ""], ["Amor", "Heni Ben", ""], ["Calandra", "Roberto", ""]]}, {"id": "1911.06833", "submitter": "Kevin Sebastian Luck", "authors": "Kevin Sebastian Luck, Mel Vecerik, Simon Stepputtis, Heni Ben Amor,\n  Jonathan Scholz", "title": "Improved Exploration through Latent Trajectory Optimization in Deep\n  Deterministic Policy Gradient", "comments": "Accepted for IROS 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.RO stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Model-free reinforcement learning algorithms such as Deep Deterministic\nPolicy Gradient (DDPG) often require additional exploration strategies,\nespecially if the actor is of deterministic nature. This work evaluates the use\nof model-based trajectory optimization methods used for exploration in Deep\nDeterministic Policy Gradient when trained on a latent image embedding. In\naddition, an extension of DDPG is derived using a value function as critic,\nmaking use of a learned deep dynamics model to compute the policy gradient.\nThis approach leads to a symbiotic relationship between the deep reinforcement\nlearning algorithm and the latent trajectory optimizer. The trajectory\noptimizer benefits from the critic learned by the RL algorithm and the latter\nfrom the enhanced exploration generated by the planner. The developed methods\nare evaluated on two continuous control tasks, one in simulation and one in the\nreal world. In particular, a Baxter robot is trained to perform an insertion\ntask, while only receiving sparse rewards and images as observations from the\nenvironment.\n", "versions": [{"version": "v1", "created": "Fri, 15 Nov 2019 19:01:29 GMT"}], "update_date": "2019-11-19", "authors_parsed": [["Luck", "Kevin Sebastian", ""], ["Vecerik", "Mel", ""], ["Stepputtis", "Simon", ""], ["Amor", "Heni Ben", ""], ["Scholz", "Jonathan", ""]]}, {"id": "1911.06837", "submitter": "Joshua Williams", "authors": "Joshua Williams, J. Zico Kolter", "title": "Dynamic Modeling and Equilibria in Fair Decision Making", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent studies on fairness in automated decision making systems have both\ninvestigated the potential future impact of these decisions on the population\nat large, and emphasized that imposing ''typical'' fairness constraints such as\ndemographic parity or equality of opportunity does not guarantee a benefit to\ndisadvantaged groups. However, these previous studies have focused on either\nsimple one-step cost/benefit criteria, or on discrete underlying state spaces.\nIn this work, we first propose a natural continuous representation of\npopulation state, governed by the Beta distribution, using a loan granting\nsetting as a running example. Next, we apply a model of population dynamics\nunder lending decisions, and show that when conditional payback probabilities\nare estimated correctly 1) ``optimal'' behavior by lenders can lead to\n''Matthew Effect'' bifurcations (i.e., ''the rich get richer and the poor get\npoorer''), but that 2) many common fairness constraints on the allowable\npolicies cause groups to converge to the same equilibrium point. Last, we\ncontrast our results in the case of misspecified conditional probability\nestimates with prior work, and show that for this model, different levels of\ngroup misestimation guarantees that even fair policies lead to bifurcations. We\nillustrate some of the modeling conclusions on real data from credit scoring.\n", "versions": [{"version": "v1", "created": "Fri, 15 Nov 2019 19:09:55 GMT"}], "update_date": "2019-11-19", "authors_parsed": [["Williams", "Joshua", ""], ["Kolter", "J. Zico", ""]]}, {"id": "1911.06845", "submitter": "Eyob Gebretinsae Beyene", "authors": "Eyob Gebretinsae Beyene", "title": "Handwritten and Machine printed OCR for Geez Numbers Using Artificial\n  Neural Network", "comments": "Presented at NeurIPS 2019 Workshop on Machine Learning for the\n  Developing World", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG eess.IV", "license": "http://creativecommons.org/publicdomain/zero/1.0/", "abstract": "  Researches have been done on Ethiopic scripts. However studies excluded the\nGeez numbers from the studies because of different reasons. This paper presents\noffline handwritten and machine printed Geez number recognition using feed\nforward back propagation artificial neural network. On this study, different\nGeez image characters were collected from google image search and three persons\nare instructed to write the numbers using pencil. In total we have collected\n560 numbers of characters. We have used 460 of the characters for training and\n100 are used for testing. Accordingly we have achieved overall all\nclassification ~89:88%\n", "versions": [{"version": "v1", "created": "Fri, 15 Nov 2019 19:37:54 GMT"}], "update_date": "2019-11-19", "authors_parsed": [["Beyene", "Eyob Gebretinsae", ""]]}, {"id": "1911.06847", "submitter": "Wei Pan", "authors": "Hongpeng Zhou, Chahine Ibrahim, Wei Pan", "title": "A Sparse Bayesian Deep Learning Approach for Identification of Cascaded\n  Tanks Benchmark", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.SY cs.LG cs.SY", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Nonlinear system identification is important with a wide range of\napplications. The typical approaches for nonlinear system identification\ninclude Volterra series models, nonlinear autoregressive with exogenous inputs\nmodels, block-structured models, state-space models and neural network models.\nAmong them, neural networks (NN) is an important black-box method thanks to its\nuniversal approximation capability and less dependency on prior information.\nHowever, there are several challenges associated with NN. The first one lies in\nthe design of a proper neural network structure. A relatively simple network\ncannot approximate the feature of the system, while a complex model may lead to\noverfitting. The second lies in the availability of data for some nonlinear\nsystems. For some systems, it is difficult to collect enough data to train a\nneural network. This raises the challenge that how to train a neural network\nfor system identification with a small dataset. In addition, if the uncertainty\nof the NN parameter could be obtained, it would be also beneficial for further\nanalysis. In this paper, we propose a sparse Bayesian deep learning approach to\naddress the above problems. Specifically, the Bayesian method can reinforce the\nregularization on neural networks by introducing introduced sparsity-inducing\npriors. The Bayesian method can also compute the uncertainty of the NN\nparameter. An efficient iterative re-weighted algorithm is presented in this\npaper. We also test the capacity of our method to identify the system on\nvarious ratios of the original dataset. The one-step-ahead prediction\nexperiment on Cascaded Tank System shows the effectiveness of our method.\nFurthermore, we test our algorithm with more challenging simulation experiment\non this benchmark, which also outperforms other methods.\n", "versions": [{"version": "v1", "created": "Fri, 15 Nov 2019 19:40:17 GMT"}, {"version": "v2", "created": "Tue, 26 Nov 2019 21:30:38 GMT"}], "update_date": "2019-11-28", "authors_parsed": [["Zhou", "Hongpeng", ""], ["Ibrahim", "Chahine", ""], ["Pan", "Wei", ""]]}, {"id": "1911.06848", "submitter": "Han-Chin Shing", "authors": "Han-Chin Shing, Guoli Wang, Philip Resnik", "title": "Assigning Medical Codes at the Encounter Level by Paying Attention to\n  Documents", "comments": "Machine Learning for Health (ML4H) at NeurIPS 2019 - Extended\n  Abstract", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The vast majority of research in computer assisted medical coding focuses on\ncoding at the document level, but a substantial proportion of medical coding in\nthe real world involves coding at the level of clinical encounters, each of\nwhich is typically represented by a potentially large set of documents. We\nintroduce encounter-level document attention networks, which use hierarchical\nattention to explicitly take the hierarchical structure of encounter\ndocumentation into account. Experimental evaluation demonstrates improvements\nin coding accuracy as well as facilitation of human reviewers in their ability\nto identify which documents within an encounter play a role in determining the\nencounter level codes.\n", "versions": [{"version": "v1", "created": "Fri, 15 Nov 2019 19:40:57 GMT"}], "update_date": "2019-11-19", "authors_parsed": [["Shing", "Han-Chin", ""], ["Wang", "Guoli", ""], ["Resnik", "Philip", ""]]}, {"id": "1911.06849", "submitter": "Radu Tudor Ionescu", "authors": "Petru Soviany, Radu Tudor Ionescu, Paolo Rota, Nicu Sebe", "title": "Curriculum Self-Paced Learning for Cross-Domain Object Detection", "comments": "Accepted for publication in Computer Vision and Image Understanding", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Training (source) domain bias affects state-of-the-art object detectors, such\nas Faster R-CNN, when applied to new (target) domains. To alleviate this\nproblem, researchers proposed various domain adaptation methods to improve\nobject detection results in the cross-domain setting, e.g. by translating\nimages with ground-truth labels from the source domain to the target domain\nusing Cycle-GAN. On top of combining Cycle-GAN transformations and self-paced\nlearning in a smart and efficient way, in this paper, we propose a novel\nself-paced algorithm that learns from easy to hard. Our method is simple and\neffective, without any overhead during inference. It uses only pseudo-labels\nfor samples taken from the target domain, i.e. the domain adaptation is\nunsupervised. We conduct experiments on four cross-domain benchmarks, showing\nbetter results than the state of the art. We also perform an ablation study\ndemonstrating the utility of each component in our framework. Additionally, we\nstudy the applicability of our framework to other object detectors.\nFurthermore, we compare our difficulty measure with other measures from the\nrelated literature, proving that it yields superior results and that it\ncorrelates well with the performance metric.\n", "versions": [{"version": "v1", "created": "Fri, 15 Nov 2019 19:43:23 GMT"}, {"version": "v2", "created": "Mon, 9 Nov 2020 22:24:32 GMT"}, {"version": "v3", "created": "Wed, 13 Jan 2021 18:33:04 GMT"}, {"version": "v4", "created": "Wed, 20 Jan 2021 19:11:38 GMT"}], "update_date": "2021-01-22", "authors_parsed": [["Soviany", "Petru", ""], ["Ionescu", "Radu Tudor", ""], ["Rota", "Paolo", ""], ["Sebe", "Nicu", ""]]}, {"id": "1911.06854", "submitter": "Cameron Voloshin", "authors": "Cameron Voloshin, Hoang M. Le, Nan Jiang, Yisong Yue", "title": "Empirical Study of Off-Policy Policy Evaluation for Reinforcement\n  Learning", "comments": "Main paper is 8 pages. The appendix contains many pages of tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.RO stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The disparate experimental conditions in recent off-policy policy evaluation\n(OPE) literature make it difficult both for practitioners to choose a reliable\nestimator for their application domain, as well as for researchers to identify\nfruitful research directions. In this work, we present the first detailed\nempirical study of a broad suite of OPE methods. Based on thousands of\nexperiments and empirical analysis, we offer a summarized set of guidelines to\nadvance the understanding of OPE performance in practice, and suggest\ndirections for future research. Along the way, our empirical findings challenge\nseveral commonly held beliefs about which class of approaches tends to perform\nwell. Our accompanying software implementation serves as a first comprehensive\nbenchmark for OPE.\n", "versions": [{"version": "v1", "created": "Fri, 15 Nov 2019 19:58:42 GMT"}, {"version": "v2", "created": "Tue, 25 Feb 2020 02:24:05 GMT"}], "update_date": "2020-02-26", "authors_parsed": [["Voloshin", "Cameron", ""], ["Le", "Hoang M.", ""], ["Jiang", "Nan", ""], ["Yue", "Yisong", ""]]}, {"id": "1911.06858", "submitter": "Soheil Rostami", "authors": "Soheil Rostami, Walid Saad, and Choong Seon Hong", "title": "Deep Learning with Persistent Homology for Orbital Angular Momentum\n  (OAM) Decoding", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.SP cs.IT cs.LG eess.IV math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Orbital angular momentum (OAM)-encoding has recently emerged as an effective\napproach for increasing the channel capacity of free-space optical\ncommunications. In this paper, OAM-based decoding is formulated as a supervised\nclassification problem. To maintain lower error rate in presence of severe\natmospheric turbulence, a new approach that combines effective machine learning\ntools from persistent homology and convolutional neural networks (CNNs) is\nproposed to decode the OAM modes. A Gaussian kernel with learnable parameters\nis proposed in order to connect persistent homology to CNN, allowing the system\nto extract and distinguish robust and unique topological features for the OAM\nmodes. Simulation results show that the proposed approach achieves up to 20%\ngains in classification accuracy rate over state-of-the-art of method based on\nonly CNNs. These results essentially show that geometric and topological\nfeatures play a pivotal role in the OAM mode classification problem.\n", "versions": [{"version": "v1", "created": "Fri, 15 Nov 2019 20:09:58 GMT"}], "update_date": "2019-11-19", "authors_parsed": [["Rostami", "Soheil", ""], ["Saad", "Walid", ""], ["Hong", "Choong Seon", ""]]}, {"id": "1911.06859", "submitter": "Minsoo Rhu", "authors": "Bongjoon Hyun, Youngeun Kwon, Yujeong Choi, John Kim, Minsoo Rhu", "title": "NeuMMU: Architectural Support for Efficient Address Translations in\n  Neural Processing Units", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AR cs.DC cs.LG cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  To satisfy the compute and memory demands of deep neural networks, neural\nprocessing units (NPUs) are widely being utilized for accelerating deep\nlearning algorithms. Similar to how GPUs have evolved from a slave device into\na mainstream processor architecture, it is likely that NPUs will become first\nclass citizens in this fast-evolving heterogeneous architecture space. This\npaper makes a case for enabling address translation in NPUs to decouple the\nvirtual and physical memory address space. Through a careful data-driven\napplication characterization study, we root-cause several limitations of prior\nGPU-centric address translation schemes and propose a memory management unit\n(MMU) that is tailored for NPUs. Compared to an oracular MMU design point, our\nproposal incurs only an average 0.06% performance overhead.\n", "versions": [{"version": "v1", "created": "Fri, 15 Nov 2019 20:10:01 GMT"}], "update_date": "2019-11-19", "authors_parsed": [["Hyun", "Bongjoon", ""], ["Kwon", "Youngeun", ""], ["Choi", "Yujeong", ""], ["Kim", "John", ""], ["Rhu", "Minsoo", ""]]}, {"id": "1911.06876", "submitter": "Lawrence Phillips", "authors": "Lawrence Phillips, Garrett Goh, Nathan Hodas", "title": "Explanatory Masks for Neural Network Interpretability", "comments": "Presented at IJCAI-18 Workshop on Explainable Artificial Intelligence\n  (XAI)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Neural network interpretability is a vital component for applications across\na wide variety of domains. In such cases it is often useful to analyze a\nnetwork which has already been trained for its specific purpose. In this work,\nwe develop a method to produce explanation masks for pre-trained networks. The\nmask localizes the most important aspects of each input for prediction of the\noriginal network. Masks are created by a secondary network whose goal is to\ncreate as small an explanation as possible while still preserving the\npredictive accuracy of the original network. We demonstrate the applicability\nof our method for image classification with CNNs, sentiment analysis with RNNs,\nand chemical property prediction with mixed CNN/RNN architectures.\n", "versions": [{"version": "v1", "created": "Fri, 15 Nov 2019 21:10:50 GMT"}], "update_date": "2019-11-19", "authors_parsed": [["Phillips", "Lawrence", ""], ["Goh", "Garrett", ""], ["Hodas", "Nathan", ""]]}, {"id": "1911.06892", "submitter": "Roy Abel", "authors": "Roy Abel, Idan Benami, Yoram Louzoun", "title": "Topological based classification using graph convolutional networks", "comments": "arXiv admin note: text overlap with arXiv:1904.07787", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SI cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In colored graphs, node classes are often associated with either their\nneighbors class or with information not incorporated in the graph associated\nwith each node. We here propose that node classes are also associated with\ntopological features of the nodes. We use this association to improve Graph\nmachine learning in general and specifically, Graph Convolutional Networks\n(GCN).\n  First, we show that even in the absence of any external information on nodes,\na good accuracy can be obtained on the prediction of the node class using\neither topological features, or using the neighbors class as an input to a GCN.\nThis accuracy is slightly less than the one that can be obtained using content\nbased GCN.\n  Secondly, we show that explicitly adding the topology as an input to the GCN\ndoes not improve the accuracy when combined with external information on nodes.\nHowever, adding an additional adjacency matrix with edges between distant nodes\nwith similar topology to the GCN does significantly improve its accuracy,\nleading to results better than all state of the art methods in multiple\ndatasets.\n", "versions": [{"version": "v1", "created": "Sat, 26 Oct 2019 10:56:07 GMT"}], "update_date": "2019-11-19", "authors_parsed": [["Abel", "Roy", ""], ["Benami", "Idan", ""], ["Louzoun", "Yoram", ""]]}, {"id": "1911.06902", "submitter": "Aniket Anand Deshmukh", "authors": "Urun Dogan, Aniket Anand Deshmukh, Marcin Machura, Christian Igel", "title": "Label-similarity Curriculum Learning", "comments": "Accepted as a conference paper at ECCV 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Curriculum learning can improve neural network training by guiding the\noptimization to desirable optima. We propose a novel curriculum learning\napproach for image classification that adapts the loss function by changing the\nlabel representation. The idea is to use a probability distribution over\nclasses as target label, where the class probabilities reflect the similarity\nto the true class. Gradually, this label representation is shifted towards the\nstandard one-hot-encoding. That is, in the beginning minor mistakes are\ncorrected less than large mistakes, resembling a teaching process in which\nbroad concepts are explained first before subtle differences are taught.\n  The class similarity can be based on prior knowledge. For the special case of\nthe labels being natural words, we propose a generic way to automatically\ncompute the similarities. The natural words are embedded into Euclidean space\nusing a standard word embedding. The probability of each class is then a\nfunction of the cosine similarity between the vector representations of the\nclass and the true label. The proposed label-similarity curriculum learning\n(LCL) approach was empirically evaluated using several popular deep learning\narchitectures for image classification tasks applied to five datasets including\nImageNet, CIFAR100, and AWA2. In all scenarios, LCL was able to improve the\nclassification accuracy on the test data compared to standard training.\n", "versions": [{"version": "v1", "created": "Fri, 15 Nov 2019 23:03:58 GMT"}, {"version": "v2", "created": "Thu, 23 Jul 2020 00:48:48 GMT"}], "update_date": "2020-07-24", "authors_parsed": [["Dogan", "Urun", ""], ["Deshmukh", "Aniket Anand", ""], ["Machura", "Marcin", ""], ["Igel", "Christian", ""]]}, {"id": "1911.06903", "submitter": "Kuang Xu", "authors": "Kuang Xu", "title": "Query Complexity of Bayesian Private Learning", "comments": "A conference version of this manuscript appeared in the proceedings\n  of the {Conference on Neural Information Processing Systems (NeurIPS)},\n  December 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.IT math.IT math.PR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the query complexity of Bayesian Private Learning: a learner wishes\nto locate a random target within an interval by submitting queries, in the\npresence of an adversary who observes all of her queries but not the responses.\nHow many queries are necessary and sufficient in order for the learner to\naccurately estimate the target, while simultaneously concealing the target from\nthe adversary?\n  Our main result is a query complexity lower bound that is tight up to the\nfirst order. We show that if the learner wants to estimate the target within an\nerror of $\\varepsilon$, while ensuring that no adversary estimator can achieve\na constant additive error with probability greater than $1/L$, then the query\ncomplexity is on the order of $L\\log(1/\\varepsilon)$, as $\\varepsilon \\to 0$.\nOur result demonstrates that increased privacy, as captured by $L$, comes at\nthe expense of a {multiplicative} increase in query complexity.\n  Our proof method builds on Fano's inequality and a family of\nproportional-sampling estimators. As an illustration of the method's wider\napplicability, we generalize the complexity lower bound to settings involving\nhigh-dimensional linear query learning and partial adversary observation.\n", "versions": [{"version": "v1", "created": "Fri, 15 Nov 2019 23:10:56 GMT"}], "update_date": "2019-11-19", "authors_parsed": [["Xu", "Kuang", ""]]}, {"id": "1911.06904", "submitter": "Maxwell Crouse", "authors": "Maxwell Crouse, Ibrahim Abdelaziz, Cristina Cornelio, Veronika Thost,\n  Lingfei Wu, Kenneth Forbus, Achille Fokoue", "title": "Improving Graph Neural Network Representations of Logical Formulae with\n  Subgraph Pooling", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG cs.LO cs.SC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent advances in the integration of deep learning with automated theorem\nproving have centered around the representation of logical formulae as inputs\nto deep learning systems. In particular, there has been a growing interest in\nadapting structure-aware neural methods to work with the underlying graph\nrepresentations of logical expressions. While more effective than character and\ntoken-level approaches, graph-based methods have often made representational\ntrade-offs that limited their ability to capture key structural properties of\ntheir inputs. In this work we propose a novel approach for embedding logical\nformulae that is designed to overcome the representational limitations of prior\napproaches. Our architecture works for logics of different expressivity; e.g.,\nfirst-order and higher-order logic. We evaluate our approach on two standard\ndatasets and show that the proposed architecture achieves state-of-the-art\nperformance on both premise selection and proof step classification.\n", "versions": [{"version": "v1", "created": "Fri, 15 Nov 2019 23:12:30 GMT"}, {"version": "v2", "created": "Tue, 11 Feb 2020 21:08:20 GMT"}, {"version": "v3", "created": "Fri, 5 Jun 2020 17:24:50 GMT"}], "update_date": "2020-06-08", "authors_parsed": [["Crouse", "Maxwell", ""], ["Abdelaziz", "Ibrahim", ""], ["Cornelio", "Cristina", ""], ["Thost", "Veronika", ""], ["Wu", "Lingfei", ""], ["Forbus", "Kenneth", ""], ["Fokoue", "Achille", ""]]}, {"id": "1911.06905", "submitter": "Ethan Shi", "authors": "Dai Shi, Junbin Gao, Xia Hong, S.T. Boris Choy and Zhiyong Wang", "title": "Coupling Matrix Manifolds and Their Applications in Optimal Transport", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Optimal transport (OT) is a powerful tool for measuring the distance between\ntwo defined probability distributions. In this paper, we develop a new manifold\nnamed the coupling matrix manifold (CMM), where each point on CMM can be\nregarded as the transportation plan of the OT problem. We firstly explore the\nRiemannian geometry of CMM with the metric expressed by the Fisher information.\nThese geometrical features of CMM have paved the way for developing numerical\nRiemannian optimization algorithms such as Riemannian gradient descent and\nRiemannian trust-region algorithms, forming a uniform optimization method for\nall types of OT problems. The proposed method is then applied to solve several\nOT problems studied by previous literature. The results of the numerical\nexperiments illustrate that the optimization algorithms that are based on the\nmethod proposed in this paper are comparable to the classic ones, for example,\nthe Sinkhorn algorithm, while outperforming other state-of-the-art algorithms\nwithout considering the geometry information, especially in the case of\nnon-entropy optimal transport.\n", "versions": [{"version": "v1", "created": "Fri, 15 Nov 2019 23:14:53 GMT"}, {"version": "v2", "created": "Sun, 24 Nov 2019 13:31:50 GMT"}], "update_date": "2019-11-26", "authors_parsed": [["Shi", "Dai", ""], ["Gao", "Junbin", ""], ["Hong", "Xia", ""], ["Choy", "S. T. Boris", ""], ["Wang", "Zhiyong", ""]]}, {"id": "1911.06910", "submitter": "Bo Peng", "authors": "Bo Peng, Renqiang Min, Xia Ning", "title": "CNN-based Dual-Chain Models for Knowledge Graph Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.IR cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Knowledge graph learning plays a critical role in integrating domain specific\nknowledge bases when deploying machine learning and data mining models in\npractice. Existing methods on knowledge graph learning primarily focus on\nmodeling the relations among entities as translations among the relations and\nentities, and many of these methods are not able to handle zero-shot problems,\nwhen new entities emerge. In this paper, we present a new convolutional neural\nnetwork (CNN)-based dual-chain model. Different from translation based methods,\nin our model, interactions among relations and entities are directly captured\nvia CNN over their embeddings. Moreover, a secondary chain of learning is\nconducted simultaneously to incorporate additional information and to enable\nbetter performance. We also present an extension of this model, which\nincorporates descriptions of entities and learns a second set of entity\nembeddings from the descriptions. As a result, the extended model is able to\neffectively handle zero-shot problems. We conducted comprehensive experiments,\ncomparing our methods with 15 methods on 8 benchmark datasets. Extensive\nexperimental results demonstrate that our proposed methods achieve or\noutperform the state-of-the-art results on knowledge graph learning, and\noutperform other methods on zero-shot problems. In addition, our methods\napplied to real-world biomedical data are able to produce results that conform\nto expert domain knowledge.\n", "versions": [{"version": "v1", "created": "Fri, 15 Nov 2019 23:24:17 GMT"}, {"version": "v2", "created": "Tue, 26 Nov 2019 13:40:35 GMT"}], "update_date": "2019-11-27", "authors_parsed": [["Peng", "Bo", ""], ["Min", "Renqiang", ""], ["Ning", "Xia", ""]]}, {"id": "1911.06913", "submitter": "Jann Goschenhofer", "authors": "Kamer A. Yuksel, Jann Goschenhofer, Hridya V. Varma, Urban Fietzek,\n  Franz M.J. Pfister", "title": "Granular Motor State Monitoring of Free Living Parkinson's Disease\n  Patients via Deep Learning", "comments": "Machine Learning for Health (ML4H) at NeurIPS 2019 -- Extended\n  Abstract", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.AP cs.LG eess.IV", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Parkinson's disease (PD) is the second most common neurodegenerative disease\nworldwide and affects around 1% of the (60+ years old) elderly population in\nindustrial nations. More than 80% of PD patients suffer from motor symptoms,\nwhich could be well addressed if a personalized medication schedule and dosage\ncould be administered to them. However, such personalized medication schedule\nrequires a continuous, objective and precise measurement of motor symptoms\nexperienced by the patients during their regular daily activities. In this\nwork, we propose the use of a wrist-worn smart-watch, which is equipped with 3D\nmotion sensors, for estimating the motor fluctuation severity of PD patients in\na free-living environment. We introduce a novel network architecture, a\npost-training scheme and a custom loss function that accounts for label noise\nto improve the results of our previous work in this domain and to establish a\nnovel benchmark for nine-level PD motor state estimation.\n", "versions": [{"version": "v1", "created": "Fri, 15 Nov 2019 23:30:02 GMT"}, {"version": "v2", "created": "Wed, 11 Dec 2019 23:55:59 GMT"}], "update_date": "2019-12-13", "authors_parsed": [["Yuksel", "Kamer A.", ""], ["Goschenhofer", "Jann", ""], ["Varma", "Hridya V.", ""], ["Fietzek", "Urban", ""], ["Pfister", "Franz M. J.", ""]]}, {"id": "1911.06919", "submitter": "Fajri Koto", "authors": "Fajri Koto, Jey Han Lau, Timothy Baldwin", "title": "Improved Document Modelling with a Neural Discourse Parser", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Despite the success of attention-based neural models for natural language\ngeneration and classification tasks, they are unable to capture the discourse\nstructure of larger documents. We hypothesize that explicit discourse\nrepresentations have utility for NLP tasks over longer documents or document\nsequences, which sequence-to-sequence models are unable to capture. For\nabstractive summarization, for instance, conventional neural models simply\nmatch source documents and the summary in a latent space without explicit\nrepresentation of text structure or relations. In this paper, we propose to use\nneural discourse representations obtained from a rhetorical structure theory\n(RST) parser to enhance document representations. Specifically, document\nrepresentations are generated for discourse spans, known as the elementary\ndiscourse units (EDUs). We empirically investigate the benefit of the proposed\napproach on two different tasks: abstractive summarization and popularity\nprediction of online petitions. We find that the proposed approach leads to\nimprovements in all cases.\n", "versions": [{"version": "v1", "created": "Sat, 16 Nov 2019 00:07:09 GMT"}], "update_date": "2019-11-19", "authors_parsed": [["Koto", "Fajri", ""], ["Lau", "Jey Han", ""], ["Baldwin", "Timothy", ""]]}, {"id": "1911.06922", "submitter": "Abdul Dakkak", "authors": "Cheng Li, Abdul Dakkak, Jinjun Xiong, Wen-mei Hwu", "title": "Benanza: Automatic $\\mu$Benchmark Generation to Compute \"Lower-bound\"\n  Latency and Inform Optimizations of Deep Learning Models on GPUs", "comments": null, "journal-ref": null, "doi": "10.1109/IPDPS47924.2020.00053", "report-no": null, "categories": "cs.LG cs.DC cs.PF stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  As Deep Learning (DL) models have been increasingly used in latency-sensitive\napplications, there has been a growing interest in improving their response\ntime. An important venue for such improvement is to profile the execution of\nthese models and characterize their performance to identify possible\noptimization opportunities. However, the current profiling tools lack the\nhighly desired abilities to characterize ideal performance, identify sources of\ninefficiency, and quantify the benefits of potential optimizations. Such\ndeficiencies have led to slow characterization/optimization cycles that cannot\nkeep up with the fast pace at which new DL models are introduced.\n  We propose Benanza, a sustainable and extensible benchmarking and analysis\ndesign that speeds up the characterization/optimization cycle of DL models on\nGPUs. Benanza consists of four major components: a model processor that parses\nmodels into an internal representation, a configurable benchmark generator that\nautomatically generates micro-benchmarks given a set of models, a database of\nbenchmark results, and an analyzer that computes the \"lower-bound\" latency of\nDL models using the benchmark data and informs optimizations of model\nexecution. The \"lower-bound\" latency metric estimates the ideal model execution\non a GPU system and serves as the basis for identifying optimization\nopportunities in frameworks or system libraries. We used Benanza to evaluate 30\nONNX models in MXNet, ONNX Runtime, and PyTorch on 7 GPUs ranging from Kepler\nto the latest Turing, and identified optimizations in parallel layer execution,\ncuDNN convolution algorithm selection, framework inefficiency, layer fusion,\nand using Tensor Cores.\n", "versions": [{"version": "v1", "created": "Sat, 16 Nov 2019 00:24:05 GMT"}, {"version": "v2", "created": "Tue, 19 Nov 2019 01:15:16 GMT"}, {"version": "v3", "created": "Wed, 19 Feb 2020 16:46:32 GMT"}], "update_date": "2020-06-04", "authors_parsed": [["Li", "Cheng", ""], ["Dakkak", "Abdul", ""], ["Xiong", "Jinjun", ""], ["Hwu", "Wen-mei", ""]]}, {"id": "1911.06928", "submitter": "Tien Mai", "authors": "Tien Mai and Kennard Chan and Patrick Jaillet", "title": "Generalized Maximum Causal Entropy for Inverse Reinforcement Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the problem of learning from demonstrated trajectories with\ninverse reinforcement learning (IRL). Motivated by a limitation of the\nclassical maximum entropy model in capturing the structure of the network of\nstates, we propose an IRL model based on a generalized version of the causal\nentropy maximization problem, which allows us to generate a class of maximum\nentropy IRL models. Our generalized model has an advantage of being able to\nrecover, in addition to a reward function, another expert's function that would\n(partially) capture the impact of the connecting structure of the states on\nexperts' decisions. Empirical evaluation on a real-world dataset and a\ngrid-world dataset shows that our generalized model outperforms the classical\nones, in terms of recovering reward functions and demonstrated trajectories.\n", "versions": [{"version": "v1", "created": "Sat, 16 Nov 2019 01:07:23 GMT"}, {"version": "v2", "created": "Tue, 18 Aug 2020 10:58:04 GMT"}], "update_date": "2020-08-19", "authors_parsed": [["Mai", "Tien", ""], ["Chan", "Kennard", ""], ["Jaillet", "Patrick", ""]]}, {"id": "1911.06930", "submitter": "Tien Mai", "authors": "Tien Mai and Quoc Phong Nguyen and Kian Hsiang Low and Patrick Jaillet", "title": "Inverse Reinforcement Learning with Missing Data", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the problem of recovering an expert's reward function with\ninverse reinforcement learning (IRL) when there are missing/incomplete\nstate-action pairs or observations in the demonstrated trajectories. This issue\nof missing trajectory data or information occurs in many situations, e.g., GPS\nsignals from vehicles moving on a road network are intermittent. In this paper,\nwe propose a tractable approach to directly compute the log-likelihood of\ndemonstrated trajectories with incomplete/missing data. Our algorithm is\nefficient in handling a large number of missing segments in the demonstrated\ntrajectories, as it performs the training with incomplete data by solving a\nsequence of systems of linear equations, and the number of such systems to be\nsolved does not depend on the number of missing segments. Empirical evaluation\non a real-world dataset shows that our training algorithm outperforms other\nconventional techniques.\n", "versions": [{"version": "v1", "created": "Sat, 16 Nov 2019 01:17:33 GMT"}], "update_date": "2019-11-19", "authors_parsed": [["Mai", "Tien", ""], ["Nguyen", "Quoc Phong", ""], ["Low", "Kian Hsiang", ""], ["Jaillet", "Patrick", ""]]}, {"id": "1911.06932", "submitter": "Praneet Dutta", "authors": "Praneet Dutta, Bruce Power, Adam Halpert, Carlos Ezequiel, Aravind\n  Subramanian, Chanchal Chatterjee, Sindhu Hari, Kenton Prindle, Vishal\n  Vaddina, Andrew Leach, Raj Domala, Laura Bandura, Massimo Mascaro", "title": "3D Conditional Generative Adversarial Networks to enable large-scale\n  seismic image enhancement", "comments": "To be Presented at the NeurIPS 2019, Second Workshop on Machine\n  Learning and the Physicial Sciences, Vancouver, Canada", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.IV cs.CV cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We propose GAN-based image enhancement models for frequency enhancement of 2D\nand 3D seismic images. Seismic imagery is used to understand and characterize\nthe Earth's subsurface for energy exploration. Because these images often\nsuffer from resolution limitations and noise contamination, our proposed method\nperforms large-scale seismic volume frequency enhancement and denoising. The\nenhanced images reduce uncertainty and improve decisions about issues, such as\noptimal well placement, that often rely on low signal-to-noise ratio (SNR)\nseismic volumes. We explored the impact of adding lithology class information\nto the models, resulting in improved performance on PSNR and SSIM metrics over\na baseline model with no conditional information.\n", "versions": [{"version": "v1", "created": "Sat, 16 Nov 2019 01:39:21 GMT"}], "update_date": "2019-11-19", "authors_parsed": [["Dutta", "Praneet", ""], ["Power", "Bruce", ""], ["Halpert", "Adam", ""], ["Ezequiel", "Carlos", ""], ["Subramanian", "Aravind", ""], ["Chatterjee", "Chanchal", ""], ["Hari", "Sindhu", ""], ["Prindle", "Kenton", ""], ["Vaddina", "Vishal", ""], ["Leach", "Andrew", ""], ["Domala", "Raj", ""], ["Bandura", "Laura", ""], ["Mascaro", "Massimo", ""]]}, {"id": "1911.06935", "submitter": "Martin Bertran", "authors": "Natalia Martinez, Martin Bertran, Guillermo Sapiro", "title": "Fairness With Minimal Harm: A Pareto-Optimal Approach For Healthcare", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Common fairness definitions in machine learning focus on balancing notions of\ndisparity and utility. In this work, we study fairness in the context of risk\ndisparity among sub-populations. We are interested in learning models that\nminimize performance discrepancies across sensitive groups without causing\nunnecessary harm. This is relevant to high-stakes domains such as healthcare,\nwhere non-maleficence is a core principle. We formalize this objective using\nPareto frontiers, and provide analysis, based on recent works in fairness, to\nexemplify scenarios were perfect fairness might not be feasible without doing\nunnecessary harm. We present a methodology for training neural networks that\nachieve our goal by dynamically re-balancing subgroups risks. We argue that\neven in domains where fairness at cost is required, finding a\nnon-unnecessary-harm fairness model is the optimal initial step. We demonstrate\nthis methodology on real case-studies of predicting ICU patient mortality, and\nclassifying skin lesions from dermatoscopic images.\n", "versions": [{"version": "v1", "created": "Sat, 16 Nov 2019 01:51:26 GMT"}], "update_date": "2019-11-19", "authors_parsed": [["Martinez", "Natalia", ""], ["Bertran", "Martin", ""], ["Sapiro", "Guillermo", ""]]}, {"id": "1911.06944", "submitter": "Donghui Yan", "authors": "Ke Alexander Wang, Xinran Bian, Pan Liu, Donghui Yan", "title": "$DC^2$: A Divide-and-conquer Algorithm for Large-scale Kernel Learning\n  with Application to Clustering", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.DC stat.CO stat.ME stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Divide-and-conquer is a general strategy to deal with large scale problems.\nIt is typically applied to generate ensemble instances, which potentially\nlimits the problem size it can handle. Additionally, the data are often divided\nby random sampling which may be suboptimal. To address these concerns, we\npropose the $DC^2$ algorithm. Instead of ensemble instances, we produce\nstructure-preserving signature pieces to be assembled and conquered. $DC^2$\nachieves the efficiency of sampling-based large scale kernel methods while\nenabling parallel multicore or clustered computation. The data partition and\nsubsequent compression are unified by recursive random projections. Empirically\ndividing the data by random projections induces smaller mean squared\napproximation errors than conventional random sampling. The power of $DC^2$ is\ndemonstrated by our clustering algorithm $rpfCluster^+$, which is as accurate\nas some fastest approximate spectral clustering algorithms while maintaining a\nrunning time close to that of K-means clustering. Analysis on $DC^2$ when\napplied to spectral clustering shows that the loss in clustering accuracy due\nto data division and reduction is upper bounded by the data approximation error\nwhich would vanish with recursive random projections. Due to its easy\nimplementation and flexibility, we expect $DC^2$ to be applicable to general\nlarge scale learning problems.\n", "versions": [{"version": "v1", "created": "Sat, 16 Nov 2019 03:10:36 GMT"}], "update_date": "2019-11-19", "authors_parsed": [["Wang", "Ke Alexander", ""], ["Bian", "Xinran", ""], ["Liu", "Pan", ""], ["Yan", "Donghui", ""]]}, {"id": "1911.06949", "submitter": "Hanpeng Hu", "authors": "Hanpeng Hu, Dan Wang, Chuan Wu", "title": "Distributed Machine Learning through Heterogeneous Edge Systems", "comments": "Copyright 2020, Association for the Advancement of Artificial\n  Intelligence (www.aaai.org). All rights reserved", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Many emerging AI applications request distributed machine learning (ML) among\nedge systems (e.g., IoT devices and PCs at the edge of the Internet), where\ndata cannot be uploaded to a central venue for model training, due to their\nlarge volumes and/or security/privacy concerns. Edge devices are intrinsically\nheterogeneous in computing capacity, posing significant challenges to parameter\nsynchronization for parallel training with the parameter server (PS)\narchitecture. This paper proposes ADSP, a parameter synchronization scheme for\ndistributed machine learning (ML) with heterogeneous edge systems. Eliminating\nthe significant waiting time occurring with existing parameter synchronization\nmodels, the core idea of ADSP is to let faster edge devices continue training,\nwhile committing their model updates at strategically decided intervals. We\ndesign algorithms that decide time points for each worker to commit its model\nupdate, and ensure not only global model convergence but also faster\nconvergence. Our testbed implementation and experiments show that ADSP\noutperforms existing parameter synchronization models significantly in terms of\nML model convergence time, scalability and adaptability to large heterogeneity.\n", "versions": [{"version": "v1", "created": "Sat, 16 Nov 2019 03:47:16 GMT"}], "update_date": "2019-11-19", "authors_parsed": [["Hu", "Hanpeng", ""], ["Wang", "Dan", ""], ["Wu", "Chuan", ""]]}, {"id": "1911.06957", "submitter": "Kanika Narang", "authors": "Kanika Narang, Chaoqi Yang, Adit Krishnan, Junting Wang, Hari Sundaram\n  and Carolyn Sutter", "title": "An Induced Multi-Relational Framework for Answer Selection in Community\n  Question Answer Platforms", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SI cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  This paper addresses the question of identifying the best candidate answer to\na question on Community Question Answer (CQA) forums. The problem is important\nbecause Individuals often visit CQA forums to seek answers to nuanced\nquestions. We develop a novel induced relational graph convolutional network\n(IR-GCN) framework to address the question. We make three contributions. First,\nwe introduce a modular framework that separates the construction of the graph\nwith the label selection mechanism. We use equivalence relations to induce a\ngraph comprising cliques and identify two label assignment mechanisms---label\ncontrast, label sharing. Then, we show how to encode these assignment\nmechanisms in GCNs. Second, we show that encoding contrast creates\ndiscriminative magnification---enhancing the separation between nodes in the\nembedding space. Third, we show a surprising result---boosting techniques\nimprove learning over familiar stacking, fusion, or aggregation approaches for\nneural architectures. We show strong results over the state-of-the-art neural\nbaselines in extensive experiments on 50 StackExchange communities.\n", "versions": [{"version": "v1", "created": "Sat, 16 Nov 2019 05:10:11 GMT"}], "update_date": "2019-11-19", "authors_parsed": [["Narang", "Kanika", ""], ["Yang", "Chaoqi", ""], ["Krishnan", "Adit", ""], ["Wang", "Junting", ""], ["Sundaram", "Hari", ""], ["Sutter", "Carolyn", ""]]}, {"id": "1911.06958", "submitter": "Frank Ban", "authors": "Frank Ban, David Woodruff, Qiuyi Zhang", "title": "Regularized Weighted Low Rank Approximation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The classical low rank approximation problem is to find a rank $k$ matrix\n$UV$ (where $U$ has $k$ columns and $V$ has $k$ rows) that minimizes the\nFrobenius norm of $A - UV$. Although this problem can be solved efficiently, we\nstudy an NP-hard variant of this problem that involves weights and\nregularization. A previous paper of [Razenshteyn et al. '16] derived a\npolynomial time algorithm for weighted low rank approximation with constant\nrank. We derive provably sharper guarantees for the regularized version by\nobtaining parameterized complexity bounds in terms of the statistical dimension\nrather than the rank, allowing for a rank-independent runtime that can be\nsignificantly faster. Our improvement comes from applying sharper matrix\nconcentration bounds, using a novel conditioning technique, and proving\nstructural theorems for regularized low rank problems.\n", "versions": [{"version": "v1", "created": "Sat, 16 Nov 2019 05:14:45 GMT"}, {"version": "v2", "created": "Tue, 19 Nov 2019 03:54:41 GMT"}], "update_date": "2019-11-20", "authors_parsed": [["Ban", "Frank", ""], ["Woodruff", "David", ""], ["Zhang", "Qiuyi", ""]]}, {"id": "1911.06959", "submitter": "Nazgol Tavabi", "authors": "Nazgol Tavabi, Homa Hosseinmardi, Jennifer L. Villatte, Andr\\'es\n  Abeliuk, Shrikanth Narayanan, Emilio Ferrara, Kristina Lerman", "title": "Learning Behavioral Representations from Wearable Sensors", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG eess.SP stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Continuous collection of physiological data from wearable sensors enables\ntemporal characterization of individual behaviors. Understanding the relation\nbetween an individual's behavioral patterns and psychological states can help\nidentify strategies to improve quality of life. One challenge in analyzing\nphysiological data is extracting the underlying behavioral states from the\ntemporal sensor signals and interpreting them. Here, we use a non-parametric\nBayesian approach to model sensor data from multiple people and discover the\ndynamic behaviors they share. We apply this method to data collected from\nsensors worn by a population of hospital workers and show that the learned\nstates can cluster participants into meaningful groups and better predict their\ncognitive and psychological states. This method offers a way to learn\ninterpretable compact behavioral representations from multivariate sensor\nsignals.\n", "versions": [{"version": "v1", "created": "Sat, 16 Nov 2019 05:21:55 GMT"}, {"version": "v2", "created": "Sat, 4 Jul 2020 20:52:20 GMT"}], "update_date": "2020-07-07", "authors_parsed": [["Tavabi", "Nazgol", ""], ["Hosseinmardi", "Homa", ""], ["Villatte", "Jennifer L.", ""], ["Abeliuk", "Andr\u00e9s", ""], ["Narayanan", "Shrikanth", ""], ["Ferrara", "Emilio", ""], ["Lerman", "Kristina", ""]]}, {"id": "1911.06962", "submitter": "Komal Teru", "authors": "Komal K. Teru, Etienne Denis, William L. Hamilton", "title": "Inductive Relation Prediction by Subgraph Reasoning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  The dominant paradigm for relation prediction in knowledge graphs involves\nlearning and operating on latent representations (i.e., embeddings) of entities\nand relations. However, these embedding-based methods do not explicitly capture\nthe compositional logical rules underlying the knowledge graph, and they are\nlimited to the transductive setting, where the full set of entities must be\nknown during training. Here, we propose a graph neural network based relation\nprediction framework, GraIL, that reasons over local subgraph structures and\nhas a strong inductive bias to learn entity-independent relational semantics.\nUnlike embedding-based models, GraIL is naturally inductive and can generalize\nto unseen entities and graphs after training. We provide theoretical proof and\nstrong empirical evidence that GraIL can represent a useful subset of\nfirst-order logic and show that GraIL outperforms existing rule-induction\nbaselines in the inductive setting. We also demonstrate significant gains\nobtained by ensembling GraIL with various knowledge graph embedding methods in\nthe transductive setting, highlighting the complementary inductive bias of our\nmethod.\n", "versions": [{"version": "v1", "created": "Sat, 16 Nov 2019 05:25:56 GMT"}, {"version": "v2", "created": "Wed, 12 Feb 2020 02:16:11 GMT"}], "update_date": "2020-02-13", "authors_parsed": [["Teru", "Komal K.", ""], ["Denis", "Etienne", ""], ["Hamilton", "William L.", ""]]}, {"id": "1911.06964", "submitter": "Mina Lee", "authors": "Mina Lee, Tatsunori B. Hashimoto, Percy Liang", "title": "Learning Autocomplete Systems as a Communication Game", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study textual autocomplete---the task of predicting a full sentence from a\npartial sentence---as a human-machine communication game. Specifically, we\nconsider three competing goals for effective communication: use as few tokens\nas possible (efficiency), transmit sentences faithfully (accuracy), and be\nlearnable to humans (interpretability). We propose an unsupervised approach\nwhich tackles all three desiderata by constraining the communication scheme to\nkeywords extracted from a source sentence for interpretability and optimizing\nthe efficiency-accuracy tradeoff. Our experiments show that this approach\nresults in an autocomplete system that is 52% more accurate at a given\nefficiency level compared to baselines, is robust to user variations, and saves\ntime by nearly 50% compared to typing full sentences.\n", "versions": [{"version": "v1", "created": "Sat, 16 Nov 2019 05:34:47 GMT"}], "update_date": "2019-11-19", "authors_parsed": [["Lee", "Mina", ""], ["Hashimoto", "Tatsunori B.", ""], ["Liang", "Percy", ""]]}, {"id": "1911.06965", "submitter": "Stanis{\\l}aw Saganowski", "authors": "Hubert Jegierski, Stanis{\\l}aw Saganowski", "title": "An \"outside the box\" solution for imbalanced data classification", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A common problem of the real-world data sets is the class imbalance, which\ncan significantly affect the classification abilities of classifiers. Numerous\nmethods have been proposed to cope with this problem; however, even\nstate-of-the-art methods offer a limited improvement (if any) for data sets\nwith critically under-represented minority classes. For such problematic cases,\nan \"outside the box\" solution is required. Therefore, we propose a novel\ntechnique, called enrichment, which uses the information (observations) from\nthe external data set(s). We present three approaches to implement enrichment\ntechnique: (1) selecting observations randomly, (2) iteratively choosing\nobservations that improve the classification result, (3) adding observations\nthat help the classifier to determine the border between classes better. We\nthen thoroughly analyze developed solutions on ten real-world data sets to\nexperimentally validate their usefulness. On average, our best approach\nimproves the classification quality by 27\\%, and in the best case, by\noutstanding 66\\%. We also compare our technique with the universally applicable\nstate-of-the-art methods. We find that our technique surpasses the existing\nmethods performing, on average, 21\\% better. The advantage is especially\nnoticeable for the smallest data sets, for which existing methods failed, while\nour solutions achieved the best results. Additionally, our technique applies to\nboth the multi-class and binary classification tasks. It can also be combined\nwith other techniques dealing with the class imbalance problem.\n", "versions": [{"version": "v1", "created": "Sat, 16 Nov 2019 05:36:03 GMT"}], "update_date": "2019-11-19", "authors_parsed": [["Jegierski", "Hubert", ""], ["Saganowski", "Stanis\u0142aw", ""]]}, {"id": "1911.06970", "submitter": "Komal Teru", "authors": "Riashat Islam, Komal K. Teru, Deepak Sharma, Joelle Pineau", "title": "Off-Policy Policy Gradient Algorithms by Constraining the State\n  Distribution Shift", "comments": "Accepted at NeurIPS 2019 workshop on Deep Reinforcement Learning", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Off-policy deep reinforcement learning (RL) algorithms are incapable of\nlearning solely from batch offline data without online interactions with the\nenvironment, due to the phenomenon known as \\textit{extrapolation error}. This\nis often due to past data available in the replay buffer that may be quite\ndifferent from the data distribution under the current policy. We argue that\nmost off-policy learning methods fundamentally suffer from a \\textit{state\ndistribution shift} due to the mismatch between the state visitation\ndistribution of the data collected by the behavior and target policies. This\ndata distribution shift between current and past samples can significantly\nimpact the performance of most modern off-policy based policy optimization\nalgorithms. In this work, we first do a systematic analysis of state\ndistribution mismatch in off-policy learning, and then develop a novel\noff-policy policy optimization method to constraint the state distribution\nshift. To do this, we first estimate the state distribution based on features\nof the state, using a density estimator and then develop a novel constrained\noff-policy gradient objective that minimizes the state distribution shift. Our\nexperimental results on continuous control tasks show that minimizing this\ndistribution mismatch can significantly improve performance in most popular\npractical off-policy policy gradient algorithms.\n", "versions": [{"version": "v1", "created": "Sat, 16 Nov 2019 06:00:52 GMT"}, {"version": "v2", "created": "Sun, 1 Dec 2019 05:06:13 GMT"}], "update_date": "2019-12-03", "authors_parsed": [["Islam", "Riashat", ""], ["Teru", "Komal K.", ""], ["Sharma", "Deepak", ""], ["Pineau", "Joelle", ""]]}, {"id": "1911.06971", "submitter": "Zhiqin Chen", "authors": "Zhiqin Chen and Andrea Tagliasacchi and Hao Zhang", "title": "BSP-Net: Generating Compact Meshes via Binary Space Partitioning", "comments": "CVPR 2020 Best Student Paper Award. Project page:\n  https://bsp-net.github.io, Code:\n  https://github.com/czq142857/BSP-NET-original", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.GR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Polygonal meshes are ubiquitous in the digital 3D domain, yet they have only\nplayed a minor role in the deep learning revolution. Leading methods for\nlearning generative models of shapes rely on implicit functions, and generate\nmeshes only after expensive iso-surfacing routines. To overcome these\nchallenges, we are inspired by a classical spatial data structure from computer\ngraphics, Binary Space Partitioning (BSP), to facilitate 3D learning. The core\ningredient of BSP is an operation for recursive subdivision of space to obtain\nconvex sets. By exploiting this property, we devise BSP-Net, a network that\nlearns to represent a 3D shape via convex decomposition. Importantly, BSP-Net\nis unsupervised since no convex shape decompositions are needed for training.\nThe network is trained to reconstruct a shape using a set of convexes obtained\nfrom a BSP-tree built on a set of planes. The convexes inferred by BSP-Net can\nbe easily extracted to form a polygon mesh, without any need for iso-surfacing.\nThe generated meshes are compact (i.e., low-poly) and well suited to represent\nsharp geometry; they are guaranteed to be watertight and can be easily\nparameterized. We also show that the reconstruction quality by BSP-Net is\ncompetitive with state-of-the-art methods while using much fewer primitives.\nCode is available at https://github.com/czq142857/BSP-NET-original.\n", "versions": [{"version": "v1", "created": "Sat, 16 Nov 2019 06:25:26 GMT"}, {"version": "v2", "created": "Sat, 28 Mar 2020 07:07:37 GMT"}, {"version": "v3", "created": "Wed, 17 Jun 2020 17:58:07 GMT"}, {"version": "v4", "created": "Mon, 31 Aug 2020 23:41:51 GMT"}, {"version": "v5", "created": "Mon, 23 Nov 2020 22:12:27 GMT"}, {"version": "v6", "created": "Mon, 7 Dec 2020 20:02:19 GMT"}], "update_date": "2020-12-09", "authors_parsed": [["Chen", "Zhiqin", ""], ["Tagliasacchi", "Andrea", ""], ["Zhang", "Hao", ""]]}, {"id": "1911.06981", "submitter": "Hilmi Enes Egilmez", "authors": "Hilmi E. Egilmez, Oguzhan Teke, Amir Said, Vadim Seregin, Marta\n  Karczewicz", "title": "Parametric Graph-based Separable Transforms for Video Coding", "comments": "5 pages, submitted to IEEE ICIP 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.MM cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In many video coding systems, separable transforms (such as two-dimensional\nDCT-2) have been used to code block residual signals obtained after prediction.\nThis paper proposes a parametric approach to build graph-based separable\ntransforms (GBSTs) for video coding. Specifically, a GBST is derived from a\npair of line graphs, whose weights are determined based on two non-negative\nparameters. As certain choices of those parameters correspond to the discrete\nsine and cosine transform types used in recent video coding standards\n(including DCT-2, DST-7 and DCT-8), this paper further optimizes these graph\nparameters to better capture residual block statistics and improve video coding\nefficiency. The proposed GBSTs are tested on the Versatile Video Coding (VVC)\nreference software, and the experimental results show that about 0.4% average\ncoding gain is achieved over the existing set of separable transforms\nconstructed based on DCT-2, DST-7 and DCT-8 in VVC.\n", "versions": [{"version": "v1", "created": "Sat, 16 Nov 2019 07:24:20 GMT"}, {"version": "v2", "created": "Wed, 12 Feb 2020 09:13:52 GMT"}, {"version": "v3", "created": "Sat, 18 Apr 2020 12:42:11 GMT"}], "update_date": "2020-04-21", "authors_parsed": [["Egilmez", "Hilmi E.", ""], ["Teke", "Oguzhan", ""], ["Said", "Amir", ""], ["Seregin", "Vadim", ""], ["Karczewicz", "Marta", ""]]}, {"id": "1911.06982", "submitter": "Zekun Cai", "authors": "Renhe Jiang, Zekun Cai, Zhaonan Wang, Chuang Yang, Zipei Fan, Xuan\n  Song, Kota Tsubouchi, Ryosuke Shibasaki", "title": "VLUC: An Empirical Benchmark for Video-Like Urban Computing on Citywide\n  Crowd and Traffic Prediction", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Nowadays, massive urban human mobility data are being generated from mobile\nphones, car navigation systems, and traffic sensors. Predicting the density and\nflow of the crowd or traffic at a citywide level becomes possible by using the\nbig data and cutting-edge AI technologies. It has been a very significant\nresearch topic with high social impact, which can be widely applied to\nemergency management, traffic regulation, and urban planning. In particular, by\nmeshing a large urban area to a number of fine-grained mesh-grids, citywide\ncrowd and traffic information in a continuous time period can be represented\nlike a video, where each timestamp can be seen as one video frame. Based on\nthis idea, a series of methods have been proposed to address video-like\nprediction for citywide crowd and traffic. In this study, we publish a new\naggregated human mobility dataset generated from a real-world smartphone\napplication and build a standard benchmark for such kind of video-like urban\ncomputing with this new dataset and the existing open datasets. We first\ncomprehensively review the state-of-the-art works of literature and formulate\nthe density and in-out flow prediction problem, then conduct a thorough\nperformance assessment for those methods. With this benchmark, we hope\nresearchers can easily follow up and quickly launch a new solution on this\ntopic.\n", "versions": [{"version": "v1", "created": "Sat, 16 Nov 2019 07:38:44 GMT"}], "update_date": "2019-11-19", "authors_parsed": [["Jiang", "Renhe", ""], ["Cai", "Zekun", ""], ["Wang", "Zhaonan", ""], ["Yang", "Chuang", ""], ["Fan", "Zipei", ""], ["Song", "Xuan", ""], ["Tsubouchi", "Kota", ""], ["Shibasaki", "Ryosuke", ""]]}, {"id": "1911.06996", "submitter": "Berry Weinstein", "authors": "Berry Weinstein, Shai Fine, Yacov Hel-Or", "title": "Selective sampling for accelerating training of deep neural networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a selective sampling method designed to accelerate the training of\ndeep neural networks. To this end, we introduce a novel measurement, the\nminimal margin score (MMS), which measures the minimal amount of displacement\nan input should take until its predicted classification is switched. For\nmulti-class linear classification, the MMS measure is a natural generalization\nof the margin-based selection criterion, which was thoroughly studied in the\nbinary classification setting. In addition, the MMS measure provides an\ninteresting insight into the progress of the training process and can be useful\nfor designing and monitoring new training regimes. Empirically we demonstrate a\nsubstantial acceleration when training commonly used deep neural network\narchitectures for popular image classification tasks. The efficiency of our\nmethod is compared against the standard training procedures, and against\ncommonly used selective sampling alternatives: Hard negative mining selection,\nand Entropy-based selection. Finally, we demonstrate an additional speedup when\nwe adopt a more aggressive learning drop regime while using the MMS selective\nsampling method.\n", "versions": [{"version": "v1", "created": "Sat, 16 Nov 2019 08:49:13 GMT"}], "update_date": "2019-11-19", "authors_parsed": [["Weinstein", "Berry", ""], ["Fine", "Shai", ""], ["Hel-Or", "Yacov", ""]]}, {"id": "1911.06997", "submitter": "Ngoc-Trung Tran", "authors": "Ngoc-Trung Tran, Viet-Hung Tran, Ngoc-Bao Nguyen, Linxiao Yang,\n  Ngai-Man Cheung", "title": "Self-supervised GAN: Analysis and Improvement with Multi-class Minimax\n  Game", "comments": "Accepted at NeurIPS 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Self-supervised (SS) learning is a powerful approach for representation\nlearning using unlabeled data. Recently, it has been applied to Generative\nAdversarial Networks (GAN) training. Specifically, SS tasks were proposed to\naddress the catastrophic forgetting issue in the GAN discriminator. In this\nwork, we perform an in-depth analysis to understand how SS tasks interact with\nlearning of generator. From the analysis, we identify issues of SS tasks which\nallow a severely mode-collapsed generator to excel the SS tasks. To address the\nissues, we propose new SS tasks based on a multi-class minimax game. The\ncompetition between our proposed SS tasks in the game encourages the generator\nto learn the data distribution and generate diverse samples. We provide both\ntheoretical and empirical analysis to support that our proposed SS tasks have\nbetter convergence property. We conduct experiments to incorporate our proposed\nSS tasks into two different GAN baseline models. Our approach establishes\nstate-of-the-art FID scores on CIFAR-10, CIFAR-100, STL-10, CelebA, Imagenet\n$32\\times32$ and Stacked-MNIST datasets, outperforming existing works by\nconsiderable margins in some cases. Our unconditional GAN model approaches\nperformance of conditional GAN without using labeled data. Our code:\nhttps://github.com/tntrung/msgan\n", "versions": [{"version": "v1", "created": "Sat, 16 Nov 2019 08:51:50 GMT"}, {"version": "v2", "created": "Wed, 8 Jan 2020 18:00:44 GMT"}], "update_date": "2020-01-09", "authors_parsed": [["Tran", "Ngoc-Trung", ""], ["Tran", "Viet-Hung", ""], ["Nguyen", "Ngoc-Bao", ""], ["Yang", "Linxiao", ""], ["Cheung", "Ngai-Man", ""]]}, {"id": "1911.07004", "submitter": "Guo-Jun Qi", "authors": "Feng Lin, Haohang Xu, Houqiang Li, Hongkai Xiong, Guo-Jun Qi", "title": "AETv2: AutoEncoding Transformations for Self-Supervised Representation\n  Learning by Minimizing Geodesic Distances in Lie Groups", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Self-supervised learning by predicting transformations has demonstrated\noutstanding performances in both unsupervised and (semi-)supervised tasks.\nAmong the state-of-the-art methods is the AutoEncoding Transformations (AET) by\ndecoding transformations from the learned representations of original and\ntransformed images. Both deterministic and probabilistic AETs rely on the\nEuclidean distance to measure the deviation of estimated transformations from\ntheir groundtruth counterparts. However, this assumption is questionable as a\ngroup of transformations often reside on a curved manifold rather staying in a\nflat Euclidean space. For this reason, we should use the geodesic to\ncharacterize how an image transform along the manifold of a transformation\ngroup, and adopt its length to measure the deviation between transformations.\nParticularly, we present to autoencode a Lie group of homography\ntransformations PG(2) to learn image representations. For this, we make an\nestimate of the intractable Riemannian logarithm by projecting PG(2) to a\nsubgroup of rotation transformations SO(3) that allows the closed-form\nexpression of geodesic distances. Experiments demonstrate the proposed AETv2\nmodel outperforms the previous version as well as the other state-of-the-art\nself-supervised models in multiple tasks.\n", "versions": [{"version": "v1", "created": "Sat, 16 Nov 2019 09:58:58 GMT"}], "update_date": "2019-11-19", "authors_parsed": [["Lin", "Feng", ""], ["Xu", "Haohang", ""], ["Li", "Houqiang", ""], ["Xiong", "Hongkai", ""], ["Qi", "Guo-Jun", ""]]}, {"id": "1911.07013", "submitter": "Jingjing Xu", "authors": "Jingjing Xu, Xu Sun, Zhiyuan Zhang, Guangxiang Zhao, Junyang Lin", "title": "Understanding and Improving Layer Normalization", "comments": "Accepted by NeurIPS 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CL stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Layer normalization (LayerNorm) is a technique to normalize the distributions\nof intermediate layers. It enables smoother gradients, faster training, and\nbetter generalization accuracy. However, it is still unclear where the\neffectiveness stems from. In this paper, our main contribution is to take a\nstep further in understanding LayerNorm. Many of previous studies believe that\nthe success of LayerNorm comes from forward normalization. Unlike them, we find\nthat the derivatives of the mean and variance are more important than forward\nnormalization by re-centering and re-scaling backward gradients. Furthermore,\nwe find that the parameters of LayerNorm, including the bias and gain, increase\nthe risk of over-fitting and do not work in most cases. Experiments show that a\nsimple version of LayerNorm (LayerNorm-simple) without the bias and gain\noutperforms LayerNorm on four datasets. It obtains the state-of-the-art\nperformance on En-Vi machine translation. To address the over-fitting problem,\nwe propose a new normalization method, Adaptive Normalization (AdaNorm), by\nreplacing the bias and gain with a new transformation function. Experiments\nshow that AdaNorm demonstrates better results than LayerNorm on seven out of\neight datasets.\n", "versions": [{"version": "v1", "created": "Sat, 16 Nov 2019 11:00:16 GMT"}], "update_date": "2019-11-19", "authors_parsed": [["Xu", "Jingjing", ""], ["Sun", "Xu", ""], ["Zhang", "Zhiyuan", ""], ["Zhao", "Guangxiang", ""], ["Lin", "Junyang", ""]]}, {"id": "1911.07014", "submitter": "Chao Xia", "authors": "Pengyu Gao, Siyu Xia, Joseph Robinson, Junkang Zhang, Chao Xia, Ming\n  Shao, Yun Fu", "title": "What Will Your Child Look Like? DNA-Net: Age and Gender Aware Kin Face\n  Synthesizer", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Visual kinship recognition aims to identify blood relatives from facial\nimages. Its practical application-- like in law-enforcement, video\nsurveillance, automatic family album management, and more-- has motivated many\nresearchers to put forth effort on the topic as of recent. In this paper, we\nfocus on a new view of visual kinship technology: kin-based face generation.\nSpecifically, we propose a two-stage kin-face generation model to predict the\nappearance of a child given a pair of parents. The first stage includes a deep\ngenerative adversarial autoencoder conditioned on ages and genders to map\nbetween facial appearance and high-level features. The second stage is our\nproposed DNA-Net, which serves as a transformation between the deep and genetic\nfeatures based on a random selection process to fuse genes of a parent pair to\nform the genes of a child. We demonstrate the effectiveness of the proposed\nmethod quantitatively and qualitatively: quantitatively, pre-trained models and\nhuman subjects perform kinship verification on the generated images of\nchildren; qualitatively, we show photo-realistic face images of children that\nclosely resemble the given pair of parents. In the end, experiments validate\nthat the proposed model synthesizes convincing kin-faces using both subjective\nand objective standards.\n", "versions": [{"version": "v1", "created": "Sat, 16 Nov 2019 11:09:17 GMT"}], "update_date": "2019-11-19", "authors_parsed": [["Gao", "Pengyu", ""], ["Xia", "Siyu", ""], ["Robinson", "Joseph", ""], ["Zhang", "Junkang", ""], ["Xia", "Chao", ""], ["Shao", "Ming", ""], ["Fu", "Yun", ""]]}, {"id": "1911.07015", "submitter": "Anshuman Chhabra", "authors": "Anshuman Chhabra, Abhishek Roy, Prasant Mohapatra", "title": "Suspicion-Free Adversarial Attacks on Clustering Algorithms", "comments": "AAAI 2020 Main Technical Conference", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Clustering algorithms are used in a large number of applications and play an\nimportant role in modern machine learning-- yet, adversarial attacks on\nclustering algorithms seem to be broadly overlooked unlike supervised learning.\nIn this paper, we seek to bridge this gap by proposing a black-box adversarial\nattack for clustering models for linearly separable clusters. Our attack works\nby perturbing a single sample close to the decision boundary, which leads to\nthe misclustering of multiple unperturbed samples, named spill-over adversarial\nsamples. We theoretically show the existence of such adversarial samples for\nthe K-Means clustering. Our attack is especially strong as (1) we ensure the\nperturbed sample is not an outlier, hence not detectable, and (2) the exact\nmetric used for clustering is not known to the attacker. We theoretically\njustify that the attack can indeed be successful without the knowledge of the\ntrue metric. We conclude by providing empirical results on a number of\ndatasets, and clustering algorithms. To the best of our knowledge, this is the\nfirst work that generates spill-over adversarial samples without the knowledge\nof the true metric ensuring that the perturbed sample is not an outlier, and\ntheoretically proves the above.\n", "versions": [{"version": "v1", "created": "Sat, 16 Nov 2019 11:37:02 GMT"}], "update_date": "2019-11-19", "authors_parsed": [["Chhabra", "Anshuman", ""], ["Roy", "Abhishek", ""], ["Mohapatra", "Prasant", ""]]}, {"id": "1911.07023", "submitter": "Min Jin Chong", "authors": "Min Jin Chong, David Forsyth", "title": "Effectively Unbiased FID and Inception Score and where to find them", "comments": "CVPR 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper shows that two commonly used evaluation metrics for generative\nmodels, the Fr\\'echet Inception Distance (FID) and the Inception Score (IS),\nare biased -- the expected value of the score computed for a finite sample set\nis not the true value of the score. Worse, the paper shows that the bias term\ndepends on the particular model being evaluated, so model A may get a better\nscore than model B simply because model A's bias term is smaller. This effect\ncannot be fixed by evaluating at a fixed number of samples. This means all\ncomparisons using FID or IS as currently computed are unreliable.\n  We then show how to extrapolate the score to obtain an effectively bias-free\nestimate of scores computed with an infinite number of samples, which we term\n$\\overline{\\textrm{FID}}_\\infty$ and $\\overline{\\textrm{IS}}_\\infty$. In turn,\nthis effectively bias-free estimate requires good estimates of scores with a\nfinite number of samples. We show that using Quasi-Monte Carlo integration\nnotably improves estimates of FID and IS for finite sample sets. Our\nextrapolated scores are simple, drop-in replacements for the finite sample\nscores. Additionally, we show that using low discrepancy sequence in GAN\ntraining offers small improvements in the resulting generator.\n", "versions": [{"version": "v1", "created": "Sat, 16 Nov 2019 12:54:05 GMT"}, {"version": "v2", "created": "Sun, 15 Mar 2020 22:31:57 GMT"}, {"version": "v3", "created": "Mon, 15 Jun 2020 23:01:14 GMT"}], "update_date": "2020-06-17", "authors_parsed": [["Chong", "Min Jin", ""], ["Forsyth", "David", ""]]}, {"id": "1911.07027", "submitter": "Yang Yu", "authors": "Tian Xu, Ziniu Li, Yang Yu", "title": "On Value Discrepancy of Imitation Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Imitation learning trains a policy from expert demonstrations. Imitation\nlearning approaches have been designed from various principles, such as\nbehavioral cloning via supervised learning, apprenticeship learning via inverse\nreinforcement learning, and GAIL via generative adversarial learning. In this\npaper, we propose a framework to analyze the theoretical property of imitation\nlearning approaches based on discrepancy propagation analysis. Under the\ninfinite-horizon setting, the framework leads to the value discrepancy of\nbehavioral cloning in an order of O((1-\\gamma)^{-2}). We also show that the\nframework leads to the value discrepancy of GAIL in an order of\nO((1-\\gamma)^{-1}). It implies that GAIL has less compounding errors than\nbehavioral cloning, which is also verified empirically in this paper. To the\nbest of our knowledge, we are the first one to analyze GAIL's performance\ntheoretically. The above results indicate that the proposed framework is a\ngeneral tool to analyze imitation learning approaches. We hope our theoretical\nresults can provide insights for future improvements in imitation learning\nalgorithms.\n", "versions": [{"version": "v1", "created": "Sat, 16 Nov 2019 13:21:39 GMT"}], "update_date": "2019-11-19", "authors_parsed": [["Xu", "Tian", ""], ["Li", "Ziniu", ""], ["Yu", "Yang", ""]]}, {"id": "1911.07033", "submitter": "Zhihang Yuan", "authors": "Zhihang Yuan, Bingzhe Wu, Zheng Liang, Shiwan Zhao, Weichen Bi,\n  Guangyu Sun", "title": "S2DNAS:Transforming Static CNN Model for Dynamic Inference via Neural\n  Architecture Search", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recently, dynamic inference has emerged as a promising way to reduce the\ncomputational cost of deep convolutional neural network (CNN). In contrast to\nstatic methods (e.g. weight pruning), dynamic inference adaptively adjusts the\ninference process according to each input sample, which can considerably reduce\nthe computational cost on \"easy\" samples while maintaining the overall model\nperformance. In this paper, we introduce a general framework, S2DNAS, which can\ntransform various static CNN models to support dynamic inference via neural\narchitecture search. To this end, based on a given CNN model, we first generate\na CNN architecture space in which each architecture is a multi-stage CNN\ngenerated from the given model using some predefined transformations. Then, we\npropose a reinforcement learning based approach to automatically search for the\noptimal CNN architecture in the generated space. At last, with the searched\nmulti-stage network, we can perform dynamic inference by adaptively choosing a\nstage to evaluate for each sample. Unlike previous works that introduce\nirregular computations or complex controllers in the inference or re-design a\nCNN model from scratch, our method can generalize to most of the popular CNN\narchitectures and the searched dynamic network can be directly deployed using\nexisting deep learning frameworks in various hardware devices.\n", "versions": [{"version": "v1", "created": "Sat, 16 Nov 2019 13:49:44 GMT"}, {"version": "v2", "created": "Tue, 17 Dec 2019 02:54:18 GMT"}], "update_date": "2019-12-18", "authors_parsed": [["Yuan", "Zhihang", ""], ["Wu", "Bingzhe", ""], ["Liang", "Zheng", ""], ["Zhao", "Shiwan", ""], ["Bi", "Weichen", ""], ["Sun", "Guangyu", ""]]}, {"id": "1911.07041", "submitter": "Sainath Adapa", "authors": "Manoj Sukhavasi, Sainath Adapa", "title": "Music theme recognition using CNN and self-attention", "comments": "MediaEval 2019, 27-29 October 2019, Sophia Antipolis, France", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SD cs.LG eess.AS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present an efficient architecture to detect mood/themes in music tracks on\nautotagging-moodtheme subset of the MTG-Jamendo dataset. Our approach consists\nof two blocks, a CNN block based on MobileNetV2 architecture and a\nself-attention block from Transformer architecture to capture long term\ntemporal characteristics. We show that our proposed model produces a\nsignificant improvement over the baseline model. Our model (team name: AMLAG)\nachieves 4th place on PR-AUC-macro Leaderboard in MediaEval 2019: Emotion and\nTheme Recognition in Music Using Jamendo.\n", "versions": [{"version": "v1", "created": "Sat, 16 Nov 2019 14:53:01 GMT"}], "update_date": "2019-11-19", "authors_parsed": [["Sukhavasi", "Manoj", ""], ["Adapa", "Sainath", ""]]}, {"id": "1911.07056", "submitter": "Pattarawat Chormai", "authors": "Pattarawat Chormai and Ponrawee Prasertsom and Attapol Rutherford", "title": "AttaCut: A Fast and Accurate Neural Thai Word Segmenter", "comments": "14 pages, 7 figures, accepted as oral presentation at New in ML\n  Workshop, NeurIPS 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Word segmentation is a fundamental pre-processing step for Thai Natural\nLanguage Processing. The current off-the-shelf solutions are not benchmarked\nconsistently, so it is difficult to compare their trade-offs. We conducted a\nspeed and accuracy comparison of the popular systems on three different domains\nand found that the state-of-the-art deep learning system is slow and moreover\ndoes not use sub-word structures to guide the model. Here, we propose a fast\nand accurate neural Thai Word Segmenter that uses dilated CNN filters to\ncapture the environment of each character and uses syllable embeddings as\nfeatures. Our system runs at least 5.6x faster and outperforms the previous\nstate-of-the-art system on some domains. In addition, we develop the first\nML-based Thai orthographical syllable segmenter, which yields syllable\nembeddings to be used as features by the word segmenter.\n", "versions": [{"version": "v1", "created": "Sat, 16 Nov 2019 16:27:44 GMT"}], "update_date": "2019-11-19", "authors_parsed": [["Chormai", "Pattarawat", ""], ["Prasertsom", "Ponrawee", ""], ["Rutherford", "Attapol", ""]]}, {"id": "1911.07068", "submitter": "Owain Evans", "authors": "Owain Evans", "title": "Sensory Optimization: Neural Networks as a Model for Understanding and\n  Creating Art", "comments": "27 pages. Web version with high-resolution images:\n  https://owainevans.github.io/visual_aesthetics/sensory-optimization.html", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This article is about the cognitive science of visual art. Artists create\nphysical artifacts (such as sculptures or paintings) which depict people,\nobjects, and events. These depictions are usually stylized rather than\nphoto-realistic. How is it that humans are able to understand and create\nstylized representations? Does this ability depend on general cognitive\ncapacities or an evolutionary adaptation for art? What role is played by\nlearning and culture?\n  Machine Learning can shed light on these questions. It's possible to train\nconvolutional neural networks (CNNs) to recognize objects without training them\non any visual art. If such CNNs can generalize to visual art (by creating and\nunderstanding stylized representations), then CNNs provide a model for how\nhumans could understand art without innate adaptations or cultural learning. I\nargue that Deep Dream and Style Transfer show that CNNs can create a basic form\nof visual art, and that humans could create art by similar processes. This\nsuggests that artists make art by optimizing for effects on the human\nobject-recognition system. Physical artifacts are optimized to evoke real-world\nobjects for this system (e.g. to evoke people or landscapes) and to serve as\nsuperstimuli for this system.\n", "versions": [{"version": "v1", "created": "Sat, 16 Nov 2019 18:10:00 GMT"}], "update_date": "2019-11-19", "authors_parsed": [["Evans", "Owain", ""]]}, {"id": "1911.07084", "submitter": "Scott Fleming", "authors": "Scott L. Fleming, Kuhan Jeyapragasan, Tony Duan, Daisy Ding, Saurabh\n  Gombar, Nigam Shah, Emma Brunskill", "title": "Missingness as Stability: Understanding the Structure of Missingness in\n  Longitudinal EHR data and its Impact on Reinforcement Learning in Healthcare", "comments": "Machine Learning for Health (ML4H) at NeurIPS 2019 - Extended\n  Abstract", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  There is an emerging trend in the reinforcement learning for healthcare\nliterature. In order to prepare longitudinal, irregularly sampled, clinical\ndatasets for reinforcement learning algorithms, many researchers will resample\nthe time series data to short, regular intervals and use\nlast-observation-carried-forward (LOCF) imputation to fill in these gaps.\nTypically, they will not maintain any explicit information about which values\nwere imputed. In this work, we (1) call attention to this practice and discuss\nits potential implications; (2) propose an alternative representation of the\npatient state that addresses some of these issues; and (3) demonstrate in a\nnovel but representative clinical dataset that our alternative representation\nyields consistently better results for achieving optimal control, as measured\nby off-policy policy evaluation, compared to representations that do not\nincorporate missingness information.\n", "versions": [{"version": "v1", "created": "Sat, 16 Nov 2019 19:40:23 GMT"}], "update_date": "2019-11-19", "authors_parsed": [["Fleming", "Scott L.", ""], ["Jeyapragasan", "Kuhan", ""], ["Duan", "Tony", ""], ["Ding", "Daisy", ""], ["Gombar", "Saurabh", ""], ["Shah", "Nigam", ""], ["Brunskill", "Emma", ""]]}, {"id": "1911.07086", "submitter": "Saeid Asgari Taghanaki", "authors": "Saeid Asgari Taghanaki, Kumar Abhishek, Ghassan Hamarneh", "title": "Signed Input Regularization", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG eess.IV", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Over-parameterized deep models usually over-fit to a given training\ndistribution, which makes them sensitive to small changes and\nout-of-distribution samples at inference time, leading to low generalization\nperformance. To this end, several model-based and randomized data-dependent\nregularization methods are applied, such as data augmentation, which prevents a\nmodel from memorizing the training distribution. Instead of the random\ntransformation of the input images, we propose SIGN, a new regularization\nmethod, which modifies the input variables using a linear transformation by\nestimating each variable's contribution to the final prediction. Our proposed\ntechnique maps the input data to a new manifold where the less important\nvariables are de-emphasized. To test the effectiveness of the proposed idea and\ncompare it with other competing methods, we design several test scenarios, such\nas classification performance, uncertainty, out-of-distribution, and robustness\nanalyses. We compare the methods using three different datasets and four\nmodels. We find that SIGN encourages more compact class representations, which\nresults in the model's robustness to random corruptions and out-of-distribution\nsamples while also simultaneously achieving superior performance on normal data\ncompared to other competing methods. Our experiments also demonstrate the\nsuccessful transferability of the SIGN samples from one model to another.\n", "versions": [{"version": "v1", "created": "Sat, 16 Nov 2019 19:56:43 GMT"}, {"version": "v2", "created": "Tue, 19 Nov 2019 18:44:33 GMT"}, {"version": "v3", "created": "Wed, 11 Dec 2019 05:09:35 GMT"}], "update_date": "2019-12-12", "authors_parsed": [["Taghanaki", "Saeid Asgari", ""], ["Abhishek", "Kumar", ""], ["Hamarneh", "Ghassan", ""]]}, {"id": "1911.07100", "submitter": "Sanjay Kariyappa", "authors": "Sanjay Kariyappa, Moinuddin K Qureshi", "title": "Defending Against Model Stealing Attacks with Adaptive Misinformation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.CR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep Neural Networks (DNNs) are susceptible to model stealing attacks, which\nallows a data-limited adversary with no knowledge of the training dataset to\nclone the functionality of a target model, just by using black-box query\naccess. Such attacks are typically carried out by querying the target model\nusing inputs that are synthetically generated or sampled from a surrogate\ndataset to construct a labeled dataset. The adversary can use this labeled\ndataset to train a clone model, which achieves a classification accuracy\ncomparable to that of the target model. We propose \"Adaptive Misinformation\" to\ndefend against such model stealing attacks. We identify that all existing model\nstealing attacks invariably query the target model with Out-Of-Distribution\n(OOD) inputs. By selectively sending incorrect predictions for OOD queries, our\ndefense substantially degrades the accuracy of the attacker's clone model (by\nup to 40%), while minimally impacting the accuracy (<0.5%) for benign users.\nCompared to existing defenses, our defense has a significantly better security\nvs accuracy trade-off and incurs minimal computational overhead.\n", "versions": [{"version": "v1", "created": "Sat, 16 Nov 2019 21:13:33 GMT"}], "update_date": "2019-11-19", "authors_parsed": [["Kariyappa", "Sanjay", ""], ["Qureshi", "Moinuddin K", ""]]}, {"id": "1911.07101", "submitter": "Qian Lou", "authors": "Qian Lou and Bo Feng and Geoffrey C. Fox and Lei Jiang", "title": "Glyph: Fast and Accurately Training Deep Neural Networks on Encrypted\n  Data", "comments": "10 pages, 34th Conference on Neural Information Processing Systems\n  (NeurIPS 2020), Vancouver, Canada", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Big data is one of the cornerstones to enabling and training deep neural\nnetworks (DNNs). Because of the lack of expertise, to gain benefits from their\ndata, average users have to rely on and upload their private data to big data\ncompanies they may not trust. Due to the compliance, legal, or privacy\nconstraints, most users are willing to contribute only their encrypted data,\nand lack interests or resources to join the training of DNNs in cloud. To train\na DNN on encrypted data in a completely non-interactive way, a recent work\nproposes a fully homomorphic encryption (FHE)-based technique implementing all\nactivations in the neural network by \\textit{Brakerski-Gentry-Vaikuntanathan\n(BGV)}-based lookup tables. However, such inefficient lookup-table-based\nactivations significantly prolong the training latency of privacy-preserving\nDNNs.\n  In this paper, we propose, Glyph, a FHE-based scheme to fast and accurately\ntrain DNNs on encrypted data by switching between TFHE (Fast Fully Homomorphic\nEncryption over the Torus) and BGV cryptosystems. Glyph uses\nlogic-operation-friendly TFHE to implement nonlinear activations, while adopts\nvectorial-arithmetic-friendly BGV to perform multiply-accumulation (MAC)\noperations. Glyph further applies transfer learning on the training of DNNs to\nimprove the test accuracy and reduce the number of MAC operations between\nciphertext and ciphertext in convolutional layers. Our experimental results\nshow Glyph obtains the state-of-the-art test accuracy, but reduces the training\nlatency by $99\\%$ over the prior FHE-based technique on various encrypted\ndatasets.\n", "versions": [{"version": "v1", "created": "Sat, 16 Nov 2019 21:30:19 GMT"}, {"version": "v2", "created": "Thu, 30 Jan 2020 19:22:02 GMT"}, {"version": "v3", "created": "Thu, 22 Oct 2020 02:09:14 GMT"}], "update_date": "2020-10-23", "authors_parsed": [["Lou", "Qian", ""], ["Feng", "Bo", ""], ["Fox", "Geoffrey C.", ""], ["Jiang", "Lei", ""]]}, {"id": "1911.07104", "submitter": "Farzaneh Khoshnevisan", "authors": "Farzaneh Khoshnevisan, Zhewen Fan", "title": "RSM-GAN: A Convolutional Recurrent GAN for Anomaly Detection in\n  Contaminated Seasonal Multivariate Time Series", "comments": "8 pages, 5 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Robust anomaly detection is a requirement for monitoring complex modern\nsystems with applications such as cyber-security, fraud prevention, and\nmaintenance. These systems generate multiple correlated time series that are\nhighly seasonal and noisy. This paper presents a novel unsupervised deep\nlearning architecture for multivariate time series anomaly detection, called\nRobust Seasonal Multivariate Generative Adversarial Network (RSM-GAN). It\nextends recent advancements in GANs with adoption of convolutional-LSTM layers\nand an attention mechanism to produce state-of-the-art performance. We conduct\nextensive experiments to demonstrate the strength of our architecture in\nadjusting for complex seasonality patterns and handling severe levels of\ntraining data contamination. We also propose a novel anomaly score assignment\nand causal inference framework. We compare RSM-GAN with existing classical and\ndeep-learning based anomaly detection models, and the results show that our\narchitecture is associated with the lowest false positive rate and improves\nprecision by 30% and 16% in real-world and synthetic data, respectively.\nFurthermore, we report the superiority of RSM-GAN regarding accurate root cause\nidentification and NAB scores in all data settings.\n", "versions": [{"version": "v1", "created": "Sat, 16 Nov 2019 21:45:38 GMT"}], "update_date": "2019-11-19", "authors_parsed": [["Khoshnevisan", "Farzaneh", ""], ["Fan", "Zhewen", ""]]}, {"id": "1911.07107", "submitter": "He Wang", "authors": "He Wang, Feixiang He, Zhexi Peng, Yongliang Yang, Tianjia Shao, Kun\n  Zhou, David Hogg", "title": "SMART: Skeletal Motion Action Recognition aTtack", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG eess.IV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Adversarial attack has inspired great interest in computer vision, by showing\nthat classification-based solutions are prone to imperceptible attack in many\ntasks. In this paper, we propose a method, SMART, to attack action recognizers\nwhich rely on 3D skeletal motions. Our method involves an innovative perceptual\nloss which ensures the imperceptibility of the attack. Empirical studies\ndemonstrate that SMART is effective in both white-box and black-box scenarios.\nIts generalizability is evidenced on a variety of action recognizers and\ndatasets. Its versatility is shown in different attacking strategies. Its\ndeceitfulness is proven in extensive perceptual studies. Finally, SMART shows\nthat adversarial attack on 3D skeletal motion, one type of time-series data, is\nsignificantly different from traditional adversarial attack problems.\n", "versions": [{"version": "v1", "created": "Sat, 16 Nov 2019 22:25:29 GMT"}, {"version": "v2", "created": "Thu, 21 Nov 2019 13:15:49 GMT"}, {"version": "v3", "created": "Tue, 10 Mar 2020 13:12:04 GMT"}], "update_date": "2020-03-11", "authors_parsed": [["Wang", "He", ""], ["He", "Feixiang", ""], ["Peng", "Zhexi", ""], ["Yang", "Yongliang", ""], ["Shao", "Tianjia", ""], ["Zhou", "Kun", ""], ["Hogg", "David", ""]]}, {"id": "1911.07109", "submitter": "Xiaojian Ma", "authors": "Mingxuan Jing, Xiaojian Ma, Wenbing Huang, Fuchun Sun, Chao Yang, Bin\n  Fang, Huaping Liu", "title": "Reinforcement Learning from Imperfect Demonstrations under Soft Expert\n  Guidance", "comments": "Accepted to AAAI 2020. Xiaojian Ma and Mingxuan Jing contributed\n  equally to this work", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.RO stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we study Reinforcement Learning from Demonstrations (RLfD)\nthat improves the exploration efficiency of Reinforcement Learning (RL) by\nproviding expert demonstrations. Most of existing RLfD methods require\ndemonstrations to be perfect and sufficient, which yet is unrealistic to meet\nin practice. To work on imperfect demonstrations, we first define an imperfect\nexpert setting for RLfD in a formal way, and then point out that previous\nmethods suffer from two issues in terms of optimality and convergence,\nrespectively. Upon the theoretical findings we have derived, we tackle these\ntwo issues by regarding the expert guidance as a soft constraint on regulating\nthe policy exploration of the agent, which eventually leads to a constrained\noptimization problem. We further demonstrate that such problem is able to be\naddressed efficiently by performing a local linear search on its dual form.\nConsiderable empirical evaluations on a comprehensive collection of benchmarks\nindicate our method attains consistent improvement over other RLfD\ncounterparts.\n", "versions": [{"version": "v1", "created": "Sat, 16 Nov 2019 22:33:38 GMT"}, {"version": "v2", "created": "Sat, 23 Nov 2019 23:22:09 GMT"}], "update_date": "2019-11-26", "authors_parsed": [["Jing", "Mingxuan", ""], ["Ma", "Xiaojian", ""], ["Huang", "Wenbing", ""], ["Sun", "Fuchun", ""], ["Yang", "Chao", ""], ["Fang", "Bin", ""], ["Liu", "Huaping", ""]]}, {"id": "1911.07115", "submitter": "Alison Jenkins", "authors": "Alison Jenkins, Vinika Gupta, Mary Lenoir", "title": "General Regression Neural Networks, Radial Basis Function Neural\n  Networks, Support Vector Machines, and Feedforward Neural Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.SY cs.LG cs.NE cs.SY eess.SP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The aim of this project is to develop a code to discover the optimal sigma\nvalue that maximum the F1 score and the optimal sigma value that maximizes the\naccuracy and to find out if they are the same. Four algorithms which can be\nused to solve this problem are: Genetic Regression Neural Networks (GRNNs),\nRadial Based Function (RBF) Neural Networks (RBFNNs), Support Vector Machines\n(SVMs) and Feedforward Neural Network (FFNNs).\n", "versions": [{"version": "v1", "created": "Sat, 16 Nov 2019 23:31:26 GMT"}], "update_date": "2019-11-19", "authors_parsed": [["Jenkins", "Alison", ""], ["Gupta", "Vinika", ""], ["Lenoir", "Mary", ""]]}, {"id": "1911.07116", "submitter": "Ruoxi Jia", "authors": "Min Du, Ruoxi Jia, Dawn Song", "title": "Robust Anomaly Detection and Backdoor Attack Detection Via Differential\n  Privacy", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Outlier detection and novelty detection are two important topics for anomaly\ndetection. Suppose the majority of a dataset are drawn from a certain\ndistribution, outlier detection and novelty detection both aim to detect data\nsamples that do not fit the distribution. Outliers refer to data samples within\nthis dataset, while novelties refer to new samples. In the meantime, backdoor\npoisoning attacks for machine learning models are achieved through injecting\npoisoning samples into the training dataset, which could be regarded as\n\"outliers\" that are intentionally added by attackers. Differential privacy has\nbeen proposed to avoid leaking any individual's information, when aggregated\nanalysis is performed on a given dataset. It is typically achieved by adding\nrandom noise, either directly to the input dataset, or to intermediate results\nof the aggregation mechanism. In this paper, we demonstrate that applying\ndifferential privacy can improve the utility of outlier detection and novelty\ndetection, with an extension to detect poisoning samples in backdoor attacks.\nWe first present a theoretical analysis on how differential privacy helps with\nthe detection, and then conduct extensive experiments to validate the\neffectiveness of differential privacy in improving outlier detection, novelty\ndetection, and backdoor attack detection.\n", "versions": [{"version": "v1", "created": "Sat, 16 Nov 2019 23:32:20 GMT"}], "update_date": "2019-11-19", "authors_parsed": [["Du", "Min", ""], ["Jia", "Ruoxi", ""], ["Song", "Dawn", ""]]}, {"id": "1911.07123", "submitter": "Donghan Yu", "authors": "Donghan Yu, Ruohong Zhang, Zhengbao Jiang, Yuexin Wu, Yiming Yang", "title": "Graph-Revised Convolutional Network", "comments": "ECML-PKDD 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Graph Convolutional Networks (GCNs) have received increasing attention in the\nmachine learning community for effectively leveraging both the content features\nof nodes and the linkage patterns across graphs in various applications. As\nreal-world graphs are often incomplete and noisy, treating them as ground-truth\ninformation, which is a common practice in most GCNs, unavoidably leads to\nsub-optimal solutions. Existing efforts for addressing this problem either\ninvolve an over-parameterized model which is difficult to scale, or simply\nre-weight observed edges without dealing with the missing-edge issue. This\npaper proposes a novel framework called Graph-Revised Convolutional Network\n(GRCN), which avoids both extremes. Specifically, a GCN-based graph revision\nmodule is introduced for predicting missing edges and revising edge weights\nw.r.t. downstream tasks via joint optimization. A theoretical analysis reveals\nthe connection between GRCN and previous work on multigraph belief propagation.\nExperiments on six benchmark datasets show that GRCN consistently outperforms\nstrong baseline methods by a large margin, especially when the original graphs\nare severely incomplete or the labeled instances for model training are highly\nsparse.\n", "versions": [{"version": "v1", "created": "Sun, 17 Nov 2019 01:00:12 GMT"}, {"version": "v2", "created": "Fri, 6 Mar 2020 01:29:28 GMT"}, {"version": "v3", "created": "Wed, 30 Dec 2020 16:58:18 GMT"}], "update_date": "2021-01-01", "authors_parsed": [["Yu", "Donghan", ""], ["Zhang", "Ruohong", ""], ["Jiang", "Zhengbao", ""], ["Wu", "Yuexin", ""], ["Yang", "Yiming", ""]]}, {"id": "1911.07125", "submitter": "Fabian Filipp", "authors": "Fabian V. Filipp", "title": "Opportunities for artificial intelligence in advancing precision\n  medicine", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG q-bio.BM q-bio.GN q-bio.MN", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Machine learning (ML), deep learning (DL), and artificial intelligence (AI)\nare of increasing importance in biomedicine. The goal of this work is to show\nprogress in ML in digital health, to exemplify future needs and trends, and to\nidentify any essential prerequisites of AI and ML for precision health.\nHigh-throughput technologies are delivering growing volumes of biomedical data,\nsuch as large-scale genome-wide sequencing assays, libraries of medical images,\nor drug perturbation screens of healthy, developing, and diseased tissue.\nMulti-omics data in biomedicine is deep and complex, offering an opportunity\nfor data-driven insights and automated disease classification. Learning from\nthese data will open our understanding and definition of healthy baselines and\ndisease signatures. State-of-the-art applications of deep neural networks\ninclude digital image recognition, single cell clustering, and virtual drug\nscreens, demonstrating breadths and power of ML in biomedicine. Significantly,\nAI and systems biology have embraced big data challenges and may enable novel\nbiotechnology-derived therapies to facilitate the implementation of precision\nmedicine approaches.\n", "versions": [{"version": "v1", "created": "Sun, 17 Nov 2019 01:29:54 GMT"}], "update_date": "2019-11-19", "authors_parsed": [["Filipp", "Fabian V.", ""]]}, {"id": "1911.07128", "submitter": "Ruoxi Jia", "authors": "Ruoxi Jia, Fan Wu, Xuehui Sun, Jiacen Xu, David Dao, Bhavya Kailkhura,\n  Ce Zhang, Bo Li, Dawn Song", "title": "Scalability vs. Utility: Do We Have to Sacrifice One for the Other in\n  Data Importance Quantification?", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Quantifying the importance of each training point to a learning task is a\nfundamental problem in machine learning and the estimated importance scores\nhave been leveraged to guide a range of data workflows such as data\nsummarization and domain adaption. One simple idea is to use the leave-one-out\nerror of each training point to indicate its importance. Recent work has also\nproposed to use the Shapley value, as it defines a unique value distribution\nscheme that satisfies a set of appealing properties. However, calculating\nShapley values is often expensive, which limits its applicability in real-world\napplications at scale. Multiple heuristics to improve the scalability of\ncalculating Shapley values have been proposed recently, with the potential risk\nof compromising their utility in real-world applications.\n  \\textit{How well do existing data quantification methods perform on existing\nworkflows? How do these methods compare with each other, empirically and\ntheoretically? Must we sacrifice scalability for the utility in these workflows\nwhen using these methods?} In this paper, we conduct a novel theoretical\nanalysis comparing the utility of different importance quantification methods,\nand report extensive experimental studies on existing and proposed workflows\nsuch as noisy label detection, watermark removal, data summarization, data\nacquisition, and domain adaptation. We show that Shapley value approximation\nbased on a $K$NN surrogate over pre-trained feature embeddings obtains\ncomparable utility with existing algorithms while achieving significant\nscalability improvement, often by orders of magnitude. Our theoretical analysis\nalso justifies its advantage over the leave-one-out error.\n  The code is available at \\url{https://github.com/AI-secure/Shapley-Study}.\n", "versions": [{"version": "v1", "created": "Sun, 17 Nov 2019 02:00:10 GMT"}, {"version": "v2", "created": "Sun, 25 Apr 2021 20:36:02 GMT"}], "update_date": "2021-04-27", "authors_parsed": [["Jia", "Ruoxi", ""], ["Wu", "Fan", ""], ["Sun", "Xuehui", ""], ["Xu", "Jiacen", ""], ["Dao", "David", ""], ["Kailkhura", "Bhavya", ""], ["Zhang", "Ce", ""], ["Li", "Bo", ""], ["Song", "Dawn", ""]]}, {"id": "1911.07132", "submitter": "Quanming Yao", "authors": "Yongqi Zhang, Quanming Yao, Lei Chen", "title": "Interstellar: Searching Recurrent Architecture for Knowledge Graph\n  Embedding", "comments": "Accepted to NeurIPS 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Knowledge graph (KG) embedding is well-known in learning representations of\nKGs. Many models have been proposed to learn the interactions between entities\nand relations of the triplets. However, long-term information among multiple\ntriplets is also important to KG. In this work, based on the relational paths,\nwhich are composed of a sequence of triplets, we define the Interstellar as a\nrecurrent neural architecture search problem for the short-term and long-term\ninformation along the paths. First, we analyze the difficulty of using a\nunified model to work as the Interstellar. Then, we propose to search for\nrecurrent architecture as the Interstellar for different KG tasks. A case study\non synthetic data illustrates the importance of the defined search problem.\nExperiments on real datasets demonstrate the effectiveness of the searched\nmodels and the efficiency of the proposed hybrid-search algorithm.\n", "versions": [{"version": "v1", "created": "Sun, 17 Nov 2019 02:16:24 GMT"}, {"version": "v2", "created": "Sat, 24 Oct 2020 14:24:10 GMT"}, {"version": "v3", "created": "Wed, 28 Apr 2021 07:16:19 GMT"}], "update_date": "2021-04-29", "authors_parsed": [["Zhang", "Yongqi", ""], ["Yao", "Quanming", ""], ["Chen", "Lei", ""]]}, {"id": "1911.07135", "submitter": "Ruoxi Jia", "authors": "Yuheng Zhang, Ruoxi Jia, Hengzhi Pei, Wenxiao Wang, Bo Li, Dawn Song", "title": "The Secret Revealer: Generative Model-Inversion Attacks Against Deep\n  Neural Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper studies model-inversion attacks, in which the access to a model is\nabused to infer information about the training data. Since its first\nintroduction, such attacks have raised serious concerns given that training\ndata usually contain privacy-sensitive information. Thus far, successful\nmodel-inversion attacks have only been demonstrated on simple models, such as\nlinear regression and logistic regression. Previous attempts to invert neural\nnetworks, even the ones with simple architectures, have failed to produce\nconvincing results. We present a novel attack method, termed the generative\nmodel-inversion attack, which can invert deep neural networks with high success\nrates. Rather than reconstructing private training data from scratch, we\nleverage partial public information, which can be very generic, to learn a\ndistributional prior via generative adversarial networks (GANs) and use it to\nguide the inversion process. Moreover, we theoretically prove that a model's\npredictive power and its vulnerability to inversion attacks are indeed two\nsides of the same coin---highly predictive models are able to establish a\nstrong correlation between features and labels, which coincides exactly with\nwhat an adversary exploits to mount the attacks. Our extensive experiments\ndemonstrate that the proposed attack improves identification accuracy over the\nexisting work by about 75\\% for reconstructing face images from a\nstate-of-the-art face recognition classifier. We also show that differential\nprivacy, in its canonical form, is of little avail to defend against our\nattacks.\n", "versions": [{"version": "v1", "created": "Sun, 17 Nov 2019 02:48:05 GMT"}, {"version": "v2", "created": "Sat, 18 Apr 2020 00:14:27 GMT"}], "update_date": "2020-04-21", "authors_parsed": [["Zhang", "Yuheng", ""], ["Jia", "Ruoxi", ""], ["Pei", "Hengzhi", ""], ["Wang", "Wenxiao", ""], ["Li", "Bo", ""], ["Song", "Dawn", ""]]}, {"id": "1911.07140", "submitter": "Zhichao Huang", "authors": "Zhichao Huang, Tong Zhang", "title": "Black-Box Adversarial Attack with Transferable Model-based Embedding", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a new method for black-box adversarial attack. Unlike previous\nmethods that combined transfer-based and scored-based methods by using the\ngradient or initialization of a surrogate white-box model, this new method\ntries to learn a low-dimensional embedding using a pretrained model, and then\nperforms efficient search within the embedding space to attack an unknown\ntarget network. The method produces adversarial perturbations with high level\nsemantic patterns that are easily transferable. We show that this approach can\ngreatly improve the query efficiency of black-box adversarial attack across\ndifferent target network architectures. We evaluate our approach on MNIST,\nImageNet and Google Cloud Vision API, resulting in a significant reduction on\nthe number of queries. We also attack adversarially defended networks on\nCIFAR10 and ImageNet, where our method not only reduces the number of queries,\nbut also improves the attack success rate.\n", "versions": [{"version": "v1", "created": "Sun, 17 Nov 2019 03:10:49 GMT"}, {"version": "v2", "created": "Sun, 5 Jan 2020 12:39:05 GMT"}], "update_date": "2020-01-07", "authors_parsed": [["Huang", "Zhichao", ""], ["Zhang", "Tong", ""]]}, {"id": "1911.07141", "submitter": "Ricky Loynd", "authors": "Ricky Loynd, Roland Fernandez, Asli Celikyilmaz, Adith Swaminathan and\n  Matthew Hausknecht", "title": "Working Memory Graphs", "comments": "11 pages, 6 figures, 7 page appendix", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Transformers have increasingly outperformed gated RNNs in obtaining new\nstate-of-the-art results on supervised tasks involving text sequences. Inspired\nby this trend, we study the question of how Transformer-based models can\nimprove the performance of sequential decision-making agents. We present the\nWorking Memory Graph (WMG), an agent that employs multi-head self-attention to\nreason over a dynamic set of vectors representing observed and recurrent state.\nWe evaluate WMG in three environments featuring factored observation spaces: a\nPathfinding environment that requires complex reasoning over past observations,\nBabyAI gridworld levels that involve variable goals, and Sokoban which\nemphasizes future planning. We find that the combination of WMG's\nTransformer-based architecture with factored observation spaces leads to\nsignificant gains in learning efficiency compared to baseline architectures\nacross all tasks. WMG demonstrates how Transformer-based models can\ndramatically boost sample efficiency in RL environments for which observations\ncan be factored.\n", "versions": [{"version": "v1", "created": "Sun, 17 Nov 2019 03:14:02 GMT"}, {"version": "v2", "created": "Thu, 20 Feb 2020 02:09:20 GMT"}, {"version": "v3", "created": "Wed, 8 Jul 2020 16:51:20 GMT"}, {"version": "v4", "created": "Tue, 18 Aug 2020 15:56:25 GMT"}], "update_date": "2020-08-19", "authors_parsed": [["Loynd", "Ricky", ""], ["Fernandez", "Roland", ""], ["Celikyilmaz", "Asli", ""], ["Swaminathan", "Adith", ""], ["Hausknecht", "Matthew", ""]]}, {"id": "1911.07147", "submitter": "Kui Yu", "authors": "Kui Yu, Xianjie Guo, Lin Liu, Jiuyong Li, Hao Wang, Zhaolong Ling,\n  Xindong Wu", "title": "Causality-based Feature Selection: Methods and Evaluations", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Feature selection is a crucial preprocessing step in data analytics and\nmachine learning. Classical feature selection algorithms select features based\non the correlations between predictive features and the class variable and do\nnot attempt to capture causal relationships between them. It has been shown\nthat the knowledge about the causal relationships between features and the\nclass variable has potential benefits for building interpretable and robust\nprediction models, since causal relationships imply the underlying mechanism of\na system. Consequently, causality-based feature selection has gradually\nattracted greater attentions and many algorithms have been proposed. In this\npaper, we present a comprehensive review of recent advances in causality-based\nfeature selection. To facilitate the development of new algorithms in the\nresearch area and make it easy for the comparisons between new methods and\nexisting ones, we develop the first open-source package, called CausalFS, which\nconsists of most of the representative causality-based feature selection\nalgorithms (available at https://github.com/kuiy/CausalFS). Using CausalFS, we\nconduct extensive experiments to compare the representative algorithms with\nboth synthetic and real-world data sets. Finally, we discuss some challenging\nproblems to be tackled in future causality-based feature selection research.\n", "versions": [{"version": "v1", "created": "Sun, 17 Nov 2019 03:49:39 GMT"}], "update_date": "2019-11-19", "authors_parsed": [["Yu", "Kui", ""], ["Guo", "Xianjie", ""], ["Liu", "Lin", ""], ["Li", "Jiuyong", ""], ["Wang", "Hao", ""], ["Ling", "Zhaolong", ""], ["Wu", "Xindong", ""]]}, {"id": "1911.07179", "submitter": "Shibo Zhang", "authors": "Shibo Zhang, Yuqi Zhao, Dzung Tri Nguyen, Runsheng Xu, Sougata Sen,\n  Josiah Hester, Nabil Alshurafa", "title": "NeckSense: A Multi-Sensor Necklace for Detecting Eating Activities in\n  Free-Living Conditions", "comments": "21 pages, 15 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.HC cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present the design, implementation, and evaluation of a multi-sensor\nlow-power necklace 'NeckSense' for automatically and unobtrusively capturing\nfine-grained information about an individual's eating activity and eating\nepisodes, across an entire waking-day in a naturalistic setting. The NeckSense\nfuses and classifies the proximity of the necklace from the chin, the ambient\nlight, the Lean Forward Angle, and the energy signals to determine chewing\nsequences, a building block of the eating activity. It then clusters the\nidentified chewing sequences to determine eating episodes. We tested NeckSense\nwith 11 obese and 9 non-obese participants across two studies, where we\ncollected more than 470 hours of data in naturalistic setting. Our result\ndemonstrates that NeckSense enables reliable eating-detection for an entire\nwaking-day, even in free-living environments. Overall, our system achieves an\nF1-score of 81.6% in detecting eating episodes in an exploratory study.\nMoreover, our system can achieve a F1-score of 77.1% for episodes even in an\nall-day-around free-living setting. With more than 15.8 hours of battery-life\nNeckSense will allow researchers and dietitians to better understand natural\nchewing and eating behaviors, and also enable real-time interventions.\n", "versions": [{"version": "v1", "created": "Sun, 17 Nov 2019 08:13:11 GMT"}, {"version": "v2", "created": "Wed, 20 Nov 2019 20:41:33 GMT"}], "update_date": "2019-11-22", "authors_parsed": [["Zhang", "Shibo", ""], ["Zhao", "Yuqi", ""], ["Nguyen", "Dzung Tri", ""], ["Xu", "Runsheng", ""], ["Sen", "Sougata", ""], ["Hester", "Josiah", ""], ["Alshurafa", "Nabil", ""]]}, {"id": "1911.07183", "submitter": "Kunjin Chen", "authors": "Kunjin Chen, Yu Zhang, Qin Wang, Jun Hu, Hang Fan, Jinliang He", "title": "Scale- and Context-Aware Convolutional Non-intrusive Load Monitoring", "comments": "Accepted by IEEE Transactions on Power Systems", "journal-ref": null, "doi": "10.1109/TPWRS.2019.2953225", "report-no": null, "categories": "eess.SP cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Non-intrusive load monitoring addresses the challenging task of decomposing\nthe aggregate signal of a household's electricity consumption into\nappliance-level data without installing dedicated meters. By detecting load\nmalfunction and recommending energy reduction programs, cost-effective\nnon-intrusive load monitoring provides intelligent demand-side management for\nutilities and end users. In this paper, we boost the accuracy of energy\ndisaggregation with a novel neural network structure named scale- and\ncontext-aware network, which exploits multi-scale features and contextual\ninformation. Specifically, we develop a multi-branch architecture with multiple\nreceptive field sizes and branch-wise gates that connect the branches in the\nsub-networks. We build a self-attention module to facilitate the integration of\nglobal context, and we incorporate an adversarial loss and on-state\naugmentation to further improve the model's performance. Extensive simulation\nresults tested on open datasets corroborate the merits of the proposed\napproach, which significantly outperforms state-of-the-art methods.\n", "versions": [{"version": "v1", "created": "Sun, 17 Nov 2019 08:25:38 GMT"}], "update_date": "2019-11-19", "authors_parsed": [["Chen", "Kunjin", ""], ["Zhang", "Yu", ""], ["Wang", "Qin", ""], ["Hu", "Jun", ""], ["Fan", "Hang", ""], ["He", "Jinliang", ""]]}, {"id": "1911.07190", "submitter": "Evgenii Zheltonozhskii", "authors": "Yury Nahshan, Brian Chmiel, Chaim Baskin, Evgenii Zheltonozhskii, Ron\n  Banner, Alex M. Bronstein, Avi Mendelson", "title": "Loss Aware Post-training Quantization", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Neural network quantization enables the deployment of large models on\nresource-constrained devices. Current post-training quantization methods fall\nshort in terms of accuracy for INT4 (or lower) but provide reasonable accuracy\nfor INT8 (or above). In this work, we study the effect of quantization on the\nstructure of the loss landscape. Additionally, we show that the structure is\nflat and separable for mild quantization, enabling straightforward\npost-training quantization methods to achieve good results. We show that with\nmore aggressive quantization, the loss landscape becomes highly non-separable\nwith steep curvature, making the selection of quantization parameters more\nchallenging. Armed with this understanding, we design a method that quantizes\nthe layer parameters jointly, enabling significant accuracy improvement over\ncurrent post-training quantization methods. Reference implementation is\navailable at\nhttps://github.com/ynahshan/nn-quantization-pytorch/tree/master/lapq\n", "versions": [{"version": "v1", "created": "Sun, 17 Nov 2019 09:10:23 GMT"}, {"version": "v2", "created": "Mon, 16 Mar 2020 09:23:27 GMT"}], "update_date": "2020-03-17", "authors_parsed": [["Nahshan", "Yury", ""], ["Chmiel", "Brian", ""], ["Baskin", "Chaim", ""], ["Zheltonozhskii", "Evgenii", ""], ["Banner", "Ron", ""], ["Bronstein", "Alex M.", ""], ["Mendelson", "Avi", ""]]}, {"id": "1911.07192", "submitter": "Qin Zou", "authors": "Qin Zou, Zheng Zhang, Ling Cao, Long Chen, Song Wang", "title": "Transductive Zero-Shot Hashing for Multilabel Image Retrieval", "comments": "15 pages", "journal-ref": "IEEE Transactions on Neural Networks and Learning Systems, 2020", "doi": "10.1109/TNNLS.2020.3043298", "report-no": null, "categories": "cs.CV cs.LG", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Hash coding has been widely used in approximate nearest neighbor search for\nlarge-scale image retrieval. Given semantic annotations such as class labels\nand pairwise similarities of the training data, hashing methods can learn and\ngenerate effective and compact binary codes. While some newly introduced images\nmay contain undefined semantic labels, which we call unseen images, zeor-shot\nhashing techniques have been studied. However, existing zeor-shot hashing\nmethods focus on the retrieval of single-label images, and cannot handle\nmulti-label images. In this paper, for the first time, a novel transductive\nzero-shot hashing method is proposed for multi-label unseen image retrieval. In\norder to predict the labels of the unseen/target data, a visual-semantic bridge\nis built via instance-concept coherence ranking on the seen/source data. Then,\npairwise similarity loss and focal quantization loss are constructed for\ntraining a hashing model using both the seen/source and unseen/target data.\nExtensive evaluations on three popular multi-label datasets demonstrate that,\nthe proposed hashing method achieves significantly better results than the\ncompeting methods.\n", "versions": [{"version": "v1", "created": "Sun, 17 Nov 2019 09:21:14 GMT"}, {"version": "v2", "created": "Wed, 30 Jun 2021 05:09:10 GMT"}], "update_date": "2021-07-01", "authors_parsed": [["Zou", "Qin", ""], ["Zhang", "Zheng", ""], ["Cao", "Ling", ""], ["Chen", "Long", ""], ["Wang", "Song", ""]]}, {"id": "1911.07198", "submitter": "Evgenii Zheltonozhskii", "authors": "Yaniv Nemcovsky, Evgenii Zheltonozhskii, Chaim Baskin, Brian Chmiel,\n  Maxim Fishman, Alex M. Bronstein, Avi Mendelson", "title": "Smoothed Inference for Adversarially-Trained Models", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Deep neural networks are known to be vulnerable to adversarial attacks.\nCurrent methods of defense from such attacks are based on either implicit or\nexplicit regularization, e.g., adversarial training. Randomized smoothing, the\naveraging of the classifier outputs over a random distribution centered in the\nsample, has been shown to guarantee the performance of a classifier subject to\nbounded perturbations of the input. In this work, we study the application of\nrandomized smoothing as a way to improve performance on unperturbed data as\nwell as to increase robustness to adversarial attacks. The proposed technique\ncan be applied on top of any existing adversarial defense, but works\nparticularly well with the randomized approaches. We examine its performance on\ncommon white-box (PGD) and black-box (transfer and NAttack) attacks on CIFAR-10\nand CIFAR-100, substantially outperforming previous art for most scenarios and\ncomparable on others. For example, we achieve 60.4% accuracy under a PGD attack\non CIFAR-10 using ResNet-20, outperforming previous art by 11.7%. Since our\nmethod is based on sampling, it lends itself well for trading-off between the\nmodel inference complexity and its performance. A reference implementation of\nthe proposed techniques is provided at https://github.com/yanemcovsky/SIAM\n", "versions": [{"version": "v1", "created": "Sun, 17 Nov 2019 09:38:45 GMT"}, {"version": "v2", "created": "Mon, 16 Mar 2020 14:13:03 GMT"}], "update_date": "2020-03-17", "authors_parsed": [["Nemcovsky", "Yaniv", ""], ["Zheltonozhskii", "Evgenii", ""], ["Baskin", "Chaim", ""], ["Chmiel", "Brian", ""], ["Fishman", "Maxim", ""], ["Bronstein", "Alex M.", ""], ["Mendelson", "Avi", ""]]}, {"id": "1911.07203", "submitter": "Zhuo Yang", "authors": "Zhuo Yang, Yufei Han, Guoxian Yu, Qiang Yang, Xiangliang Zhang", "title": "Prototypical Networks for Multi-Label Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose to formulate multi-label learning as a estimation of class\ndistribution in a non-linear embedding space, where for each label, its\npositive data embeddings and negative data embeddings distribute compactly to\nform a positive component and negative component respectively, while the\npositive component and negative component are pushed away from each other. Duo\nto the shared embedding space for all labels, the distribution of embeddings\npreserves instances' label membership and feature matrix, thus encodes the\nfeature-label relation and nonlinear label dependency. Labels of a given\ninstance are inferred in the embedding space by measuring the probabilities of\nits belongingness to the positive or negative components of each label.\nSpecially, the probabilities are modeled as the distance from the given\ninstance to representative positive or negative prototypes. Extensive\nexperiments validate that the proposed solution can provide distinctively more\naccurate multi-label classification than other state-of-the-art algorithms.\n", "versions": [{"version": "v1", "created": "Sun, 17 Nov 2019 10:16:45 GMT"}, {"version": "v2", "created": "Thu, 17 Dec 2020 07:16:46 GMT"}], "update_date": "2020-12-18", "authors_parsed": [["Yang", "Zhuo", ""], ["Han", "Yufei", ""], ["Yu", "Guoxian", ""], ["Yang", "Qiang", ""], ["Zhang", "Xiangliang", ""]]}, {"id": "1911.07205", "submitter": "Wenxiao Wang", "authors": "Xinyun Chen, Wenxiao Wang, Chris Bender, Yiming Ding, Ruoxi Jia, Bo\n  Li, Dawn Song", "title": "REFIT: A Unified Watermark Removal Framework For Deep Learning Systems\n  With Limited Data", "comments": "ACM Asia Conference on Computer and Communications Security\n  (AsiaCCS), 2021. Early version in ICML 2019 Workshop on Security and Privacy\n  of Machine Learning. The first two authors contribute equally", "journal-ref": null, "doi": "10.1145/3433210.3453079", "report-no": null, "categories": "cs.CR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Training deep neural networks from scratch could be computationally expensive\nand requires a lot of training data. Recent work has explored different\nwatermarking techniques to protect the pre-trained deep neural networks from\npotential copyright infringements. However, these techniques could be\nvulnerable to watermark removal attacks. In this work, we propose REFIT, a\nunified watermark removal framework based on fine-tuning, which does not rely\non the knowledge of the watermarks, and is effective against a wide range of\nwatermarking schemes. In particular, we conduct a comprehensive study of a\nrealistic attack scenario where the adversary has limited training data, which\nhas not been emphasized in prior work on attacks against watermarking schemes.\nTo effectively remove the watermarks without compromising the model\nfunctionality under this weak threat model, we propose two techniques that are\nincorporated into our fine-tuning framework: (1) an adaption of the elastic\nweight consolidation (EWC) algorithm, which is originally proposed for\nmitigating the catastrophic forgetting phenomenon; and (2) unlabeled data\naugmentation (AU), where we leverage auxiliary unlabeled data from other\nsources. Our extensive evaluation shows the effectiveness of REFIT against\ndiverse watermark embedding schemes. In particular, both EWC and AU\nsignificantly decrease the amount of labeled training data needed for effective\nwatermark removal, and the unlabeled data samples used for AU do not\nnecessarily need to be drawn from the same distribution as the benign data for\nmodel evaluation. The experimental results demonstrate that our fine-tuning\nbased watermark removal attacks could pose real threats to the copyright of\npre-trained models, and thus highlight the importance of further investigating\nthe watermarking problem and proposing more robust watermark embedding schemes\nagainst the attacks.\n", "versions": [{"version": "v1", "created": "Sun, 17 Nov 2019 10:30:08 GMT"}, {"version": "v2", "created": "Wed, 22 Jan 2020 06:39:35 GMT"}, {"version": "v3", "created": "Thu, 25 Mar 2021 08:34:02 GMT"}], "update_date": "2021-03-26", "authors_parsed": [["Chen", "Xinyun", ""], ["Wang", "Wenxiao", ""], ["Bender", "Chris", ""], ["Ding", "Yiming", ""], ["Jia", "Ruoxi", ""], ["Li", "Bo", ""], ["Song", "Dawn", ""]]}, {"id": "1911.07223", "submitter": "Kiet Nguyen Van", "authors": "Phu X. V. Nguyen, Tham T. T. Hong, Kiet Van Nguyen, Ngan Luu-Thuy\n  Nguyen", "title": "Deep Learning versus Traditional Classifiers on Vietnamese Students'\n  Feedback Corpus", "comments": "In Proceeding of the 5th NAFOSTED Conference on Information and\n  Computer Science (NICS 2018)", "journal-ref": "5th NAFOSTED Conference on Information and Computer Science (NICS\n  2018)", "doi": null, "report-no": null, "categories": "cs.CL cs.CY cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Student's feedback is an important source of collecting students' opinions to\nimprove the quality of training activities. Implementing sentiment analysis\ninto student feedback data, we can determine sentiments polarities which\nexpress all problems in the institution since changes necessary will be applied\nto improve the quality of teaching and learning. This study focused on machine\nlearning and natural language processing techniques (NaiveBayes, Maximum\nEntropy, Long Short-Term Memory, Bi-Directional Long Short-Term Memory) on the\nVietnameseStudents' Feedback Corpus collected from a university. The final\nresults were compared and evaluated to find the most effective model based on\ndifferent evaluation criteria. The experimental results show that the\nBi-Directional LongShort-Term Memory algorithm outperformed than three other\nalgorithms in terms of the F1-score measurement with 92.0% on the sentiment\nclassification task and 89.6% on the topic classification task. In addition, we\ndeveloped a sentiment analysis application analyzing student feedback. The\napplication will help the institution to recognize students' opinions about a\nproblem and identify shortcomings that still exist. With the use of this\napplication, the institution can propose an appropriate method to improve the\nquality of training activities in the future.\n", "versions": [{"version": "v1", "created": "Sun, 17 Nov 2019 12:32:50 GMT"}], "update_date": "2019-11-19", "authors_parsed": [["Nguyen", "Phu X. V.", ""], ["Hong", "Tham T. T.", ""], ["Van Nguyen", "Kiet", ""], ["Nguyen", "Ngan Luu-Thuy", ""]]}, {"id": "1911.07224", "submitter": "Sujoy Paul", "authors": "Sujoy Paul, Jeroen van Baar, Amit K. Roy-Chowdhury", "title": "Learning from Trajectories via Subgoal Discovery", "comments": "NeurIPS 2019 Accepted", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.RO stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Learning to solve complex goal-oriented tasks with sparse terminal-only\nrewards often requires an enormous number of samples. In such cases, using a\nset of expert trajectories could help to learn faster. However, Imitation\nLearning (IL) via supervised pre-training with these trajectories may not\nperform as well and generally requires additional finetuning with\nexpert-in-the-loop. In this paper, we propose an approach which uses the expert\ntrajectories and learns to decompose the complex main task into smaller\nsub-goals. We learn a function which partitions the state-space into sub-goals,\nwhich can then be used to design an extrinsic reward function. We follow a\nstrategy where the agent first learns from the trajectories using IL and then\nswitches to Reinforcement Learning (RL) using the identified sub-goals, to\nalleviate the errors in the IL step. To deal with states which are\nunder-represented by the trajectory set, we also learn a function to modulate\nthe sub-goal predictions. We show that our method is able to solve complex\ngoal-oriented tasks, which other RL, IL or their combinations in literature are\nnot able to solve.\n", "versions": [{"version": "v1", "created": "Sun, 3 Nov 2019 02:55:45 GMT"}], "update_date": "2019-11-19", "authors_parsed": [["Paul", "Sujoy", ""], ["van Baar", "Jeroen", ""], ["Roy-Chowdhury", "Amit K.", ""]]}, {"id": "1911.07227", "submitter": "Leen Alawieh", "authors": "Leen Alawieh, Jonathan Goodman, John B. Bell", "title": "Iterative Construction of Gaussian Process Surrogate Models for Bayesian\n  Inference", "comments": null, "journal-ref": null, "doi": "10.1016/j.jspi.2019.11.002", "report-no": null, "categories": "stat.ML cs.LG stat.AP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A new algorithm is developed to tackle the issue of sampling non-Gaussian\nmodel parameter posterior probability distributions that arise from solutions\nto Bayesian inverse problems. The algorithm aims to mitigate some of the\nhurdles faced by traditional Markov Chain Monte Carlo (MCMC) samplers, through\nconstructing proposal probability densities that are both, easy to sample and\nthat provide a better approximation to the target density than a simple\nGaussian proposal distribution would. To achieve that, a Gaussian proposal\ndistribution is augmented with a Gaussian Process (GP) surface that helps\ncapture non-linearities in the log-likelihood function. In order to train the\nGP surface, an iterative approach is adopted for the optimal selection of\npoints in parameter space. Optimality is sought by maximizing the information\ngain of the GP surface using a minimum number of forward model simulation runs.\nThe accuracy of the GP-augmented surface approximation is assessed in two ways.\nThe first consists of comparing predictions obtained from the approximate\nsurface with those obtained through running the actual simulation model at\nhold-out points in parameter space. The second consists of a measure based on\nthe relative variance of sample weights obtained from sampling the approximate\nposterior probability distribution of the model parameters. The efficacy of\nthis new algorithm is tested on inferring reaction rate parameters in a 3-node\nand 6-node network toy problems, which imitate idealized reaction networks in\ncombustion applications.\n", "versions": [{"version": "v1", "created": "Sun, 17 Nov 2019 12:57:32 GMT"}], "update_date": "2019-11-19", "authors_parsed": [["Alawieh", "Leen", ""], ["Goodman", "Jonathan", ""], ["Bell", "John B.", ""]]}, {"id": "1911.07228", "submitter": "Kiet Nguyen Van", "authors": "Binh An Nguyen, Kiet Van Nguyen, Ngan Luu-Thuy Nguyen", "title": "Error Analysis for Vietnamese Named Entity Recognition on Deep Neural\n  Network Models", "comments": "19th International Conference on Computational Linguistics and\n  Intelligent Text Processing (CICLING 2018)", "journal-ref": "19th International Conference on Computational Linguistics and\n  Intelligent Text Processing (CICLING 2018)", "doi": null, "report-no": null, "categories": "cs.CL cs.LG cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In recent years, Vietnamese Named Entity Recognition (NER) systems have had a\ngreat breakthrough when using Deep Neural Network methods. This paper describes\nthe primary errors of the state-of-the-art NER systems on Vietnamese language.\nAfter conducting experiments on BLSTM-CNN-CRF and BLSTM-CRF models with\ndifferent word embeddings on the Vietnamese NER dataset. This dataset is\nprovided by VLSP in 2016 and used to evaluate most of the current Vietnamese\nNER systems. We noticed that BLSTM-CNN-CRF gives better results, therefore, we\nanalyze the errors on this model in detail. Our error-analysis results provide\nus thorough insights in order to increase the performance of NER for the\nVietnamese language and improve the quality of the corpus in the future works.\n", "versions": [{"version": "v1", "created": "Sun, 17 Nov 2019 13:03:07 GMT"}, {"version": "v2", "created": "Tue, 19 Nov 2019 13:08:38 GMT"}], "update_date": "2019-11-20", "authors_parsed": [["Nguyen", "Binh An", ""], ["Van Nguyen", "Kiet", ""], ["Nguyen", "Ngan Luu-Thuy", ""]]}, {"id": "1911.07245", "submitter": "Krisztian Buza", "authors": "Krisztian Buza", "title": "Encouraging an Appropriate Representation Simplifies Training of Neural\n  Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A common assumption about neural networks is that they can learn an\nappropriate internal representations on their own, see e.g. end-to-end\nlearning. In this work we challenge this assumption. We consider two simple\ntasks and show that the state-of-the-art training algorithm fails, although the\nmodel itself is able to represent an appropriate solution. We will demonstrate\nthat encouraging an appropriate internal representation allows the same model\nto solve these tasks. While we do not claim that it is impossible to solve\nthese tasks by other means (such as neural networks with more layers), our\nresults illustrate that integration of domain knowledge in form of a desired\ninternal representation may improve the generalization ability of neural\nnetworks.\n", "versions": [{"version": "v1", "created": "Sun, 17 Nov 2019 14:30:50 GMT"}], "update_date": "2019-11-19", "authors_parsed": [["Buza", "Krisztian", ""]]}, {"id": "1911.07246", "submitter": "Youngwoon Lee", "authors": "Youngwoon Lee, Edward S. Hu, Zhengyu Yang, Alex Yin, and Joseph J. Lim", "title": "IKEA Furniture Assembly Environment for Long-Horizon Complex\n  Manipulation Tasks", "comments": "Simulator", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.AI cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The IKEA Furniture Assembly Environment is one of the first benchmarks for\ntesting and accelerating the automation of complex manipulation tasks. The\nenvironment is designed to advance reinforcement learning from simple toy tasks\nto complex tasks requiring both long-term planning and sophisticated low-level\ncontrol. Our environment supports over 80 different furniture models, Sawyer\nand Baxter robot simulation, and domain randomization. The IKEA Furniture\nAssembly Environment is a testbed for methods aiming to solve complex\nmanipulation tasks. The environment is publicly available at\nhttps://clvrai.com/furniture\n", "versions": [{"version": "v1", "created": "Sun, 17 Nov 2019 14:32:20 GMT"}], "update_date": "2019-11-19", "authors_parsed": [["Lee", "Youngwoon", ""], ["Hu", "Edward S.", ""], ["Yang", "Zhengyu", ""], ["Yin", "Alex", ""], ["Lim", "Joseph J.", ""]]}, {"id": "1911.07247", "submitter": "Jonathan Baxter", "authors": "Peter L. Bartlett and Jonathan Baxter", "title": "Hebbian Synaptic Modifications in Spiking Neurons that Learn", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we derive a new model of synaptic plasticity, based on recent\nalgorithms for reinforcement learning (in which an agent attempts to learn\nappropriate actions to maximize its long-term average reward). We show that\nthese direct reinforcement learning algorithms also give locally optimal\nperformance for the problem of reinforcement learning with multiple agents,\nwithout any explicit communication between agents. By considering a network of\nspiking neurons as a collection of agents attempting to maximize the long-term\naverage of a reward signal, we derive a synaptic update rule that is\nqualitatively similar to Hebb's postulate. This rule requires only simple\ncomputations, such as addition and leaky integration, and involves only\nquantities that are available in the vicinity of the synapse. Furthermore, it\nleads to synaptic connection strengths that give locally optimal values of the\nlong term average reward. The reinforcement learning paradigm is sufficiently\nbroad to encompass many learning problems that are solved by the brain. We\nillustrate, with simulations, that the approach is effective for simple pattern\nclassification and motor learning tasks.\n", "versions": [{"version": "v1", "created": "Sun, 17 Nov 2019 14:36:21 GMT"}], "update_date": "2019-11-19", "authors_parsed": [["Bartlett", "Peter L.", ""], ["Baxter", "Jonathan", ""]]}, {"id": "1911.07249", "submitter": "Martin Gauch", "authors": "Martin Gauch, Juliane Mai, Jimmy Lin", "title": "The Proper Care and Feeding of CAMELS: How Limited Training Data Affects\n  Streamflow Prediction", "comments": "13 pages, 3 figures", "journal-ref": "Environmental Modelling & Software, Volume 135, 2021, 104926", "doi": "10.1016/j.envsoft.2020.104926", "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Accurate streamflow prediction largely relies on historical meteorological\nrecords and streamflow measurements. For many regions, however, such data are\nonly scarcely available. Facing this problem, many studies simply trained their\nmachine learning models on the region's available data, leaving possible\nrepercussions of this strategy unclear. In this study, we evaluate the\nsensitivity of tree- and LSTM-based models to limited training data, both in\nterms of geographic diversity and different time spans. We feed the models\nmeteorological observations disseminated with the CAMELS dataset, and\nindividually restrict the training period length, number of training basins,\nand input sequence length. We quantify how additional training data improve\npredictions and how many previous days of forcings we should feed the models to\nobtain best predictions for each training set size. Further, our findings show\nthat tree- and LSTM-based models provide similarly accurate predictions on\nsmall datasets, while LSTMs are superior given more training data.\n", "versions": [{"version": "v1", "created": "Sun, 17 Nov 2019 14:50:04 GMT"}, {"version": "v2", "created": "Thu, 14 May 2020 13:50:19 GMT"}, {"version": "v3", "created": "Tue, 11 Aug 2020 08:56:22 GMT"}], "update_date": "2020-11-23", "authors_parsed": [["Gauch", "Martin", ""], ["Mai", "Juliane", ""], ["Lin", "Jimmy", ""]]}, {"id": "1911.07255", "submitter": "Amit Boyarski", "authors": "Amit Boyarski, Sanketh Vedula, Alex Bronstein", "title": "Spectral Geometric Matrix Completion", "comments": "Accepted to Mathematical and Scientific Machine Learning (MSML) 2021\n  https://msml21.github.io/", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CG cs.CV stat.ML", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Deep Matrix Factorization (DMF) is an emerging approach to the problem of\nmatrix completion. Recent works have established that gradient descent applied\nto a DMF model induces an implicit regularization on the rank of the recovered\nmatrix. In this work we interpret the DMF model through the lens of spectral\ngeometry. This allows us to incorporate explicit regularization without\nbreaking the DMF structure, thus enjoying the best of both worlds. In\nparticular, we focus on matrix completion problems with underlying geometric or\ntopological relations between the rows and/or columns. Such relations are\nprevalent in matrix completion problems that arise in many applications, such\nas recommender systems and drug-target interaction. Our contributions enable\nDMF models to exploit these relations, and make them competitive on real\nbenchmarks, while exhibiting one of the first successful applications of deep\nlinear networks.\n", "versions": [{"version": "v1", "created": "Sun, 17 Nov 2019 15:06:34 GMT"}, {"version": "v2", "created": "Sun, 23 Feb 2020 12:10:30 GMT"}, {"version": "v3", "created": "Mon, 7 Jun 2021 14:27:53 GMT"}], "update_date": "2021-06-08", "authors_parsed": [["Boyarski", "Amit", ""], ["Vedula", "Sanketh", ""], ["Bronstein", "Alex", ""]]}, {"id": "1911.07257", "submitter": "Hao-Yun Chen", "authors": "Hao-Yun Chen, Li-Huang Tsai, Shih-Chieh Chang, Jia-Yu Pan, Yu-Ting\n  Chen, Wei Wei, Da-Cheng Juan", "title": "Learning with Hierarchical Complement Objective", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Label hierarchies widely exist in many vision-related problems, ranging from\nexplicit label hierarchies existed in image classification to latent label\nhierarchies existed in semantic segmentation. Nevertheless, state-of-the-art\nmethods often deploy cross-entropy loss that implicitly assumes class labels to\nbe exclusive and thus independence from each other. Motivated by the fact that\nclasses from the same parental category usually share certain similarity, we\ndesign a new training diagram called Hierarchical Complement Objective Training\n(HCOT) that leverages the information from label hierarchy. HCOT maximizes the\nprobability of the ground truth class, and at the same time, neutralizes the\nprobabilities of rest of the classes in a hierarchical fashion, making the\nmodel take advantage of the label hierarchy explicitly. The proposed HCOT is\nevaluated on both image classification and semantic segmentation tasks.\nExperimental results confirm that HCOT outperforms state-of-the-art models in\nCIFAR-100, ImageNet-2012, and PASCAL-Context. The study further demonstrates\nthat HCOT can be applied on tasks with latent label hierarchies, which is a\ncommon characteristic in many machine learning tasks.\n", "versions": [{"version": "v1", "created": "Sun, 17 Nov 2019 15:46:38 GMT"}], "update_date": "2019-11-19", "authors_parsed": [["Chen", "Hao-Yun", ""], ["Tsai", "Li-Huang", ""], ["Chang", "Shih-Chieh", ""], ["Pan", "Jia-Yu", ""], ["Chen", "Yu-Ting", ""], ["Wei", "Wei", ""], ["Juan", "Da-Cheng", ""]]}, {"id": "1911.07279", "submitter": "Ekin Gedik", "authors": "Alessio Rosatelli, Ekin Gedik, Hayley Hung", "title": "Detecting F-formations & Roles in Crowded Social Scenes with Wearables:\n  Combining Proxemics & Dynamics using LSTMs", "comments": "2019 8th International Conference on Affective Computing and\n  Intelligent Interaction Workshops and Demos (ACIIW)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG cs.SI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we investigate the use of proxemics and dynamics for\nautomatically identifying conversing groups, or so-called F-formations. More\nformally we aim to automatically identify whether wearable sensor data coming\nfrom 2 people is indicative of F-formation membership. We also explore the\nproblem of jointly detecting membership and more descriptive information about\nthe pair relating to the role they take in the conversation (i.e. speaker or\nlistener). We jointly model the concepts of proxemics and dynamics using binary\nproximity and acceleration obtained through a single wearable sensor per\nperson. We test our approaches on the publicly available MatchNMingle dataset\nwhich was collected during real-life mingling events. We find out that fusion\nof these two modalities performs significantly better than them independently,\nproviding an AUC of 0.975 when data from 30-second windows are used.\nFurthermore, our investigation into roles detection shows that each role pair\nrequires a different time resolution for accurate detection.\n", "versions": [{"version": "v1", "created": "Sun, 17 Nov 2019 16:43:44 GMT"}], "update_date": "2019-11-19", "authors_parsed": [["Rosatelli", "Alessio", ""], ["Gedik", "Ekin", ""], ["Hung", "Hayley", ""]]}, {"id": "1911.07292", "submitter": "Hufei Zhu", "authors": "Hufei Zhu", "title": "Efficient Ridge Solutions for the Incremental Broad Learning System on\n  Added Inputs by Updating the Inverse or the Inverse Cholesky Factor of the\n  Hermitian matrix in the Ridge Inverse", "comments": "arXiv admin note: text overlap with arXiv:1911.04872", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This brief proposes two BLS algorithms to improve the existing BLS for new\nadded inputs in [7]. The proposed BLS algorithms avoid computing the ridge\ninverse, by computing the ridge solution (i.e., the output weights) from the\ninverse or the inverse Cholesky factor of the Hermitian matrix in the ridge\ninverse. The proposed BLS algorithm 1 updates the inverse of the Hermitian\nmatrix by the matrix inversion lemma [12]. To update the upper-triangular\ninverse Cholesky factor of the Hermitian matrix, the proposed BLS algorithm 2\nmultiplies the inverse Cholesky factor with an upper-triangular intermediate\nmatrix, which is computed by a Cholesky factorization or an inverse Cholesky\nfactorization. Assume that the newly added input matrix corresponding to the\nadded inputs is p * k, where p and k are the number of added training samples\nand the total node number, respectively. When p > k, the inverse of a sum of\nmatrices [11] is utilized to compute the intermediate variables by a smaller\nmatrix inverse in the proposed algorithm 1, or by a smaller inverse Cholesky\nfactorization in the proposed algorithm 2. Usually the Hermitian matrix in the\nridge inverse is smaller than the ridge inverse. Thus the proposed algorithms 1\nand 2 require less flops (floating-point operations) than the existing BLS\nalgorithm, which is verified by the theoretical flops calculation. In numerical\nexperiments, the speedups for the case of p > k in each additional training\ntime of the proposed BLS algorithms 1 and 2 over the existing algorithm are\n1.95 - 5.43 and 2.29 - 6.34, respectively, and the speedups for the case of p <\nk are 8.83 - 10.21 and 2.28 - 2.58, respectively.\n", "versions": [{"version": "v1", "created": "Tue, 12 Nov 2019 14:19:52 GMT"}, {"version": "v2", "created": "Tue, 13 Apr 2021 04:36:01 GMT"}, {"version": "v3", "created": "Fri, 16 Apr 2021 06:34:18 GMT"}], "update_date": "2021-04-19", "authors_parsed": [["Zhu", "Hufei", ""]]}, {"id": "1911.07293", "submitter": "Yifan Zhang", "authors": "Yifan Zhang, Ying Wei, Peilin Zhao, Shuaicheng Niu, Qingyao Wu,\n  Mingkui Tan, Junzhou Huang", "title": "Collaborative Unsupervised Domain Adaptation for Medical Image Diagnosis", "comments": "Medical Imaging meets NeurIPS, 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Deep learning based medical image diagnosis has shown great potential in\nclinical medicine. However, it often suffers two major difficulties in\npractice: 1) only limited labeled samples are available due to expensive\nannotation costs over medical images; 2) labeled images may contain\nconsiderable label noises (e.g., mislabeling labels) due to diagnostic\ndifficulties. In this paper, we seek to exploit rich labeled data from relevant\ndomains to help the learning in the target task with unsupervised domain\nadaptation (UDA). Unlike most existing UDA methods which rely on clean labeled\ndata or assume samples are equally transferable, we propose a novel\nCollaborative Unsupervised Domain Adaptation algorithm to conduct\ntransferability-aware domain adaptation and conquer label noise in a\ncooperative way. Promising empirical results verify the superiority of the\nproposed method.\n", "versions": [{"version": "v1", "created": "Sun, 17 Nov 2019 17:18:06 GMT"}], "update_date": "2019-11-19", "authors_parsed": [["Zhang", "Yifan", ""], ["Wei", "Ying", ""], ["Zhao", "Peilin", ""], ["Niu", "Shuaicheng", ""], ["Wu", "Qingyao", ""], ["Tan", "Mingkui", ""], ["Huang", "Junzhou", ""]]}, {"id": "1911.07304", "submitter": "Konstantinos Spiliopoulos", "authors": "Justin Sirignano and Konstantinos Spiliopoulos", "title": "Asymptotics of Reinforcement Learning with Neural Networks", "comments": "arXiv admin note: text overlap with arXiv:1907.04108", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG math.PR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We prove that a single-layer neural network trained with the Q-learning\nalgorithm converges in distribution to a random ordinary differential equation\nas the size of the model and the number of training steps become large.\nAnalysis of the limit differential equation shows that it has a unique\nstationary solution which is the solution of the Bellman equation, thus giving\nthe optimal control for the problem. In addition, we study the convergence of\nthe limit differential equation to the stationary solution. As a by-product of\nour analysis, we obtain the limiting behavior of single-layer neural networks\nwhen trained on i.i.d. data with stochastic gradient descent under the\nwidely-used Xavier initialization.\n", "versions": [{"version": "v1", "created": "Wed, 13 Nov 2019 13:27:32 GMT"}, {"version": "v2", "created": "Thu, 12 Nov 2020 02:20:03 GMT"}, {"version": "v3", "created": "Wed, 3 Feb 2021 16:57:56 GMT"}, {"version": "v4", "created": "Fri, 2 Apr 2021 19:15:17 GMT"}], "update_date": "2021-04-06", "authors_parsed": [["Sirignano", "Justin", ""], ["Spiliopoulos", "Konstantinos", ""]]}, {"id": "1911.07309", "submitter": "Anush Sankaran", "authors": "Senthil Mani, Anush Sankaran, Srikanth Tamilselvam, Akshay Sethi", "title": "Coverage Testing of Deep Learning Models using Dataset Characterization", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep Neural Networks (DNNs), with its promising performance, are being\nincreasingly used in safety critical applications such as autonomous driving,\ncancer detection, and secure authentication. With growing importance in deep\nlearning, there is a requirement for a more standardized framework to evaluate\nand test deep learning models. The primary challenge involved in automated\ngeneration of extensive test cases are: (i) neural networks are difficult to\ninterpret and debug and (ii) availability of human annotators to generate\nspecialized test points. In this research, we explain the necessity to measure\nthe quality of a dataset and propose a test case generation system guided by\nthe dataset properties. From a testing perspective, four different dataset\nquality dimensions are proposed: (i) equivalence partitioning, (ii) centroid\npositioning, (iii) boundary conditioning, and (iv) pair-wise boundary\nconditioning. The proposed system is evaluated on well known image\nclassification datasets such as MNIST, Fashion-MNIST, CIFAR10, CIFAR100, and\nSVHN against popular deep learning models such as LeNet, ResNet-20, VGG-19.\nFurther, we conduct various experiments to demonstrate the effectiveness of\nsystematic test case generation system for evaluating deep learning models.\n", "versions": [{"version": "v1", "created": "Sun, 17 Nov 2019 18:07:07 GMT"}], "update_date": "2019-11-19", "authors_parsed": [["Mani", "Senthil", ""], ["Sankaran", "Anush", ""], ["Tamilselvam", "Srikanth", ""], ["Sethi", "Akshay", ""]]}, {"id": "1911.07320", "submitter": "Giulia Fracastoro", "authors": "Giuseppe C. Calafiore and Giulia Fracastoro", "title": "Sparse $\\ell_1$ and $\\ell_2$ Center Classifiers", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The nearest-centroid classifier is a simple linear-time classifier based on\ncomputing the centroids of the data classes in the training phase, and then\nassigning a new datum to the class corresponding to its nearest centroid.\nThanks to its very low computational cost, the nearest-centroid classifier is\nstill widely used in machine learning, despite the development of many other\nmore sophisticated classification methods. In this paper, we propose two sparse\nvariants of the nearest-centroid classifier, based respectively on $\\ell_1$ and\n$\\ell_2$ distance criteria. The proposed sparse classifiers perform\nsimultaneous classification and feature selection, by detecting the features\nthat are most relevant for the classification purpose. We show that training of\nthe proposed sparse models, with both distance criteria, can be performed\nexactly (i.e., the globally optimal set of features is selected) and at a\nquasi-linear computational cost. The experimental results show that the\nproposed methods are competitive in accuracy with state-of-the-art feature\nselection techniques, while having a significantly lower computational cost.\n", "versions": [{"version": "v1", "created": "Sun, 17 Nov 2019 19:15:59 GMT"}, {"version": "v2", "created": "Mon, 25 Nov 2019 11:10:45 GMT"}], "update_date": "2019-11-26", "authors_parsed": [["Calafiore", "Giuseppe C.", ""], ["Fracastoro", "Giulia", ""]]}, {"id": "1911.07323", "submitter": "Ziniu Hu", "authors": "Difan Zou and Ziniu Hu and Yewen Wang and Song Jiang and Yizhou Sun\n  and Quanquan Gu", "title": "Layer-Dependent Importance Sampling for Training Deep and Large Graph\n  Convolutional Networks", "comments": "Published in NeurIPS 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.SI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Graph convolutional networks (GCNs) have recently received wide attentions,\ndue to their successful applications in different graph tasks and different\ndomains. Training GCNs for a large graph, however, is still a challenge.\nOriginal full-batch GCN training requires calculating the representation of all\nthe nodes in the graph per GCN layer, which brings in high computation and\nmemory costs. To alleviate this issue, several sampling-based methods have been\nproposed to train GCNs on a subset of nodes. Among them, the node-wise\nneighbor-sampling method recursively samples a fixed number of neighbor nodes,\nand thus its computation cost suffers from exponential growing neighbor size;\nwhile the layer-wise importance-sampling method discards the neighbor-dependent\nconstraints, and thus the nodes sampled across layer suffer from sparse\nconnection problem. To deal with the above two problems, we propose a new\neffective sampling algorithm called LAyer-Dependent ImportancE Sampling\n(LADIES). Based on the sampled nodes in the upper layer, LADIES selects their\nneighborhood nodes, constructs a bipartite subgraph and computes the importance\nprobability accordingly. Then, it samples a fixed number of nodes by the\ncalculated probability, and recursively conducts such procedure per layer to\nconstruct the whole computation graph. We prove theoretically and\nexperimentally, that our proposed sampling algorithm outperforms the previous\nsampling methods in terms of both time and memory costs. Furthermore, LADIES is\nshown to have better generalization accuracy than original full-batch GCN, due\nto its stochastic nature.\n", "versions": [{"version": "v1", "created": "Sun, 17 Nov 2019 19:40:10 GMT"}], "update_date": "2019-11-19", "authors_parsed": [["Zou", "Difan", ""], ["Hu", "Ziniu", ""], ["Wang", "Yewen", ""], ["Jiang", "Song", ""], ["Sun", "Yizhou", ""], ["Gu", "Quanquan", ""]]}, {"id": "1911.07324", "submitter": "Maryam Aliakbarpour", "authors": "Maryam Aliakbarpour, Sandeep Silwal", "title": "Testing Properties of Multiple Distributions with Few Samples", "comments": "ITCS 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.DM cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a new setting for testing properties of distributions while\nreceiving samples from several distributions, but few samples per distribution.\nGiven samples from $s$ distributions, $p_1, p_2, \\ldots, p_s$, we design\ntesters for the following problems: (1) Uniformity Testing: Testing whether all\nthe $p_i$'s are uniform or $\\epsilon$-far from being uniform in\n$\\ell_1$-distance (2) Identity Testing: Testing whether all the $p_i$'s are\nequal to an explicitly given distribution $q$ or $\\epsilon$-far from $q$ in\n$\\ell_1$-distance, and (3) Closeness Testing: Testing whether all the $p_i$'s\nare equal to a distribution $q$ which we have sample access to, or\n$\\epsilon$-far from $q$ in $\\ell_1$-distance. By assuming an additional natural\ncondition about the source distributions, we provide sample optimal testers for\nall of these problems.\n", "versions": [{"version": "v1", "created": "Sun, 17 Nov 2019 19:44:13 GMT"}], "update_date": "2019-11-19", "authors_parsed": [["Aliakbarpour", "Maryam", ""], ["Silwal", "Sandeep", ""]]}, {"id": "1911.07328", "submitter": "Christine Bauer", "authors": "Christine Bauer", "title": "The Potential of the Confluence of Theoretical and Algorithmic Modeling\n  in Music Recommendation", "comments": "6 pages; 1st ACM CHI 2019 Workshop on Computational Modeling in\n  Human-Computer Interaction; workshop", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.HC cs.LG", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  The task of a music recommender system is to predict what music item a\nparticular user would like to listen to next. This position paper discusses the\nmain challenges of the music preference prediction task: the lack of\ninformation on the many contextual factors influencing a user's music\npreferences in existing open datasets, the lack of clarity of what the right\nchoice of music is and whether a right choice exists at all; the multitude of\ncriteria (beyond accuracy) that have to be met for a \"good\" music item\nrecommendation; and the need for explanations on relationships to identify (and\npotentially counteract) unwanted biases in recommendation approaches. The paper\nsubstantiates the position that the confluence of theoretical modeling (which\nseeks to explain behaviors) and algorithmic modeling (which seeks to predict\nbehaviors) seems to be an effective avenue to take in computational modeling\nfor music recommender systems.\n", "versions": [{"version": "v1", "created": "Sun, 17 Nov 2019 20:23:41 GMT"}], "update_date": "2019-11-19", "authors_parsed": [["Bauer", "Christine", ""]]}, {"id": "1911.07335", "submitter": "Haw-Shiuan Chang", "authors": "Haw-Shiuan Chang, Shankar Vembu, Sunil Mohan, Rheeya Uppaal, Andrew\n  McCallum", "title": "Using Error Decay Prediction to Overcome Practical Issues of Deep Active\n  Learning for Named Entity Recognition", "comments": "This is a pre-print of an article published in Springer Machine\n  Learning journal. The final authenticated version is available online at:\n  https://doi.org/10.1007/s10994-020-05897-1", "journal-ref": null, "doi": "10.1007/s10994-020-05897-1", "report-no": null, "categories": "cs.CL cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Existing deep active learning algorithms achieve impressive sampling\nefficiency on natural language processing tasks. However, they exhibit several\nweaknesses in practice, including (a) inability to use uncertainty sampling\nwith black-box models, (b) lack of robustness to labeling noise, and (c) lack\nof transparency. In response, we propose a transparent batch active sampling\nframework by estimating the error decay curves of multiple feature-defined\nsubsets of the data. Experiments on four named entity recognition (NER) tasks\ndemonstrate that the proposed methods significantly outperform\ndiversification-based methods for black-box NER taggers, and can make the\nsampling process more robust to labeling noise when combined with\nuncertainty-based methods. Furthermore, the analysis of experimental results\nsheds light on the weaknesses of different active sampling strategies, and when\ntraditional uncertainty-based or diversification-based methods can be expected\nto work well.\n", "versions": [{"version": "v1", "created": "Sun, 17 Nov 2019 20:41:32 GMT"}, {"version": "v2", "created": "Tue, 21 Jul 2020 00:33:11 GMT"}], "update_date": "2020-07-22", "authors_parsed": [["Chang", "Haw-Shiuan", ""], ["Vembu", "Shankar", ""], ["Mohan", "Sunil", ""], ["Uppaal", "Rheeya", ""], ["McCallum", "Andrew", ""]]}, {"id": "1911.07337", "submitter": "Scott Cameron", "authors": "Scott A. Cameron, Hans C. Eggers and Steve Kroon", "title": "Stochastic Gradient Annealed Importance Sampling for Efficient Online\n  Marginal Likelihood Estimation", "comments": null, "journal-ref": "Entropy 2019, 21(11), 1109", "doi": "10.3390/e21111109", "report-no": null, "categories": "stat.ML cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We consider estimating the marginal likelihood in settings with independent\nand identically distributed (i.i.d.) data. We propose estimating the predictive\ndistributions in a sequential factorization of the marginal likelihood in such\nsettings by using stochastic gradient Markov Chain Monte Carlo techniques. This\napproach is far more efficient than traditional marginal likelihood estimation\ntechniques such as nested sampling and annealed importance sampling due to its\nuse of mini-batches to approximate the likelihood. Stability of the estimates\nis provided by an adaptive annealing schedule. The resulting stochastic\ngradient annealed importance sampling (SGAIS) technique, which is the key\ncontribution of our paper, enables us to estimate the marginal likelihood of a\nnumber of models considerably faster than traditional approaches, with no\nnoticeable loss of accuracy. An important benefit of our approach is that the\nmarginal likelihood is calculated in an online fashion as data becomes\navailable, allowing the estimates to be used for applications such as online\nweighted model combination.\n", "versions": [{"version": "v1", "created": "Sun, 17 Nov 2019 20:59:51 GMT"}], "update_date": "2019-11-19", "authors_parsed": [["Cameron", "Scott A.", ""], ["Eggers", "Hans C.", ""], ["Kroon", "Steve", ""]]}, {"id": "1911.07346", "submitter": "Haichao Yu", "authors": "Haichao Yu, Haoxiang Li, Honghui Shi, Thomas S. Huang, Gang Hua", "title": "Any-Precision Deep Neural Networks", "comments": "AAAI 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present any-precision deep neural networks (DNNs), which are trained with\na new method that allows the learned DNNs to be flexible in numerical precision\nduring inference. The same model in runtime can be flexibly and directly set to\ndifferent bit-widths, by truncating the least significant bits, to support\ndynamic speed and accuracy trade-off. When all layers are set to low-bits, we\nshow that the model achieved accuracy comparable to dedicated models trained at\nthe same precision. This nice property facilitates flexible deployment of deep\nlearning models in real-world applications, where in practice trade-offs\nbetween model accuracy and runtime efficiency are often sought. Previous\nliterature presents solutions to train models at each individual fixed\nefficiency/accuracy trade-off point. But how to produce a model flexible in\nruntime precision is largely unexplored. When the demand of efficiency/accuracy\ntrade-off varies from time to time or even dynamically changes in runtime, it\nis infeasible to re-train models accordingly, and the storage budget may forbid\nkeeping multiple models. Our proposed framework achieves this flexibility\nwithout performance degradation. More importantly, we demonstrate that this\nachievement is agnostic to model architectures and applicable to multiple\nvision tasks. Our code is released at\nhttps://github.com/SHI-Labs/Any-Precision-DNNs.\n", "versions": [{"version": "v1", "created": "Sun, 17 Nov 2019 21:35:32 GMT"}, {"version": "v2", "created": "Fri, 15 Jan 2021 08:13:10 GMT"}], "update_date": "2021-01-18", "authors_parsed": [["Yu", "Haichao", ""], ["Li", "Haoxiang", ""], ["Shi", "Honghui", ""], ["Huang", "Thomas S.", ""], ["Hua", "Gang", ""]]}, {"id": "1911.07349", "submitter": "Mengmi Zhang", "authors": "Mengmi Zhang, Claire Tseng, Gabriel Kreiman", "title": "Putting visual object recognition in context", "comments": "8 pages, CVPR2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG eess.IV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Context plays an important role in visual recognition. Recent studies have\nshown that visual recognition networks can be fooled by placing objects in\ninconsistent contexts (e.g., a cow in the ocean). To model the role of\ncontextual information in visual recognition, we systematically investigated\nten critical properties of where, when, and how context modulates recognition,\nincluding the amount of context, context and object resolution, geometrical\nstructure of context, context congruence, and temporal dynamics of contextual\nmodulation. The tasks involved recognizing a target object surrounded with\ncontext in a natural image. As an essential benchmark, we conducted a series of\npsychophysics experiments where we altered one aspect of context at a time, and\nquantified recognition accuracy. We propose a biologically-inspired\ncontext-aware object recognition model consisting of a two-stream architecture.\nThe model processes visual information at the fovea and periphery in parallel,\ndynamically incorporates object and contextual information, and sequentially\nreasons about the class label for the target object. Across a wide range of\nbehavioral tasks, the model approximates human level performance without\nretraining for each task, captures the dependence of context enhancement on\nimage properties, and provides initial steps towards integrating scene and\nobject information for visual recognition. All source code and data are\npublicly available: https://github.com/kreimanlab/Put-In-Context.\n", "versions": [{"version": "v1", "created": "Sun, 17 Nov 2019 21:43:00 GMT"}, {"version": "v2", "created": "Mon, 9 Dec 2019 02:08:31 GMT"}, {"version": "v3", "created": "Wed, 25 Mar 2020 22:46:13 GMT"}], "update_date": "2020-03-27", "authors_parsed": [["Zhang", "Mengmi", ""], ["Tseng", "Claire", ""], ["Kreiman", "Gabriel", ""]]}, {"id": "1911.07357", "submitter": "Cl\\'ement Canonne", "authors": "Cl\\'ement L. Canonne, Xi Chen, Gautam Kamath, Amit Levi, Erik\n  Waingarten", "title": "Random Restrictions of High-Dimensional Distributions and Uniformity\n  Testing with Subcube Conditioning", "comments": "Added Remark 4.4, which discusses the time complexity (the algorithms\n  are polynomial-time, based on an observation from [CJLW20]); removing log log\n  log n factor for the Gaussian testing algorithm. These changes reflect those\n  included in the conference version (SODA'21)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.IT cs.LG math.IT math.PR math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We give a nearly-optimal algorithm for testing uniformity of distributions\nsupported on $\\{-1,1\\}^n$, which makes $\\tilde O (\\sqrt{n}/\\varepsilon^2)$\nqueries to a subcube conditional sampling oracle (Bhattacharyya and Chakraborty\n(2018)). The key technical component is a natural notion of random restriction\nfor distributions on $\\{-1,1\\}^n$, and a quantitative analysis of how such a\nrestriction affects the mean vector of the distribution. Along the way, we\nconsider the problem of mean testing with independent samples and provide a\nnearly-optimal algorithm.\n", "versions": [{"version": "v1", "created": "Sun, 17 Nov 2019 22:39:17 GMT"}, {"version": "v2", "created": "Thu, 4 Feb 2021 23:30:41 GMT"}], "update_date": "2021-02-08", "authors_parsed": [["Canonne", "Cl\u00e9ment L.", ""], ["Chen", "Xi", ""], ["Kamath", "Gautam", ""], ["Levi", "Amit", ""], ["Waingarten", "Erik", ""]]}, {"id": "1911.07361", "submitter": "Alessio Bernardo", "authors": "Alessio Bernardo, Emanuele Della Valle and Albert Bifet", "title": "Rebalancing Learning on Evolving Data Streams", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://creativecommons.org/publicdomain/zero/1.0/", "abstract": "  Nowadays, every device connected to the Internet generates an ever-growing\nstream of data (formally, unbounded). Machine Learning on unbounded data\nstreams is a grand challenge due to its resource constraints. In fact, standard\nmachine learning techniques are not able to deal with data whose statistics is\nsubject to gradual or sudden changes without any warning. Massive Online\nAnalysis (MOA) is the collective name, as well as a software library, for new\nlearners that are able to manage data streams. In this paper, we present a\nresearch study on streaming rebalancing. Indeed, data streams can be imbalanced\nas static data, but there is not a method to rebalance them incrementally, one\nelement at a time. For this reason we propose a new streaming approach able to\nrebalance data streams online. Our new methodology is evaluated against some\nsynthetically generated datasets using prequential evaluation in order to\ndemonstrate that it outperforms the existing approaches.\n", "versions": [{"version": "v1", "created": "Sun, 17 Nov 2019 23:13:21 GMT"}], "update_date": "2019-11-19", "authors_parsed": [["Bernardo", "Alessio", ""], ["Della Valle", "Emanuele", ""], ["Bifet", "Albert", ""]]}, {"id": "1911.07368", "submitter": "Jason Wei", "authors": "Lia X. Harrington, Jason W. Wei, Arief A. Suriawinata, Todd A.\n  Mackenzie, Saeed Hassanpour", "title": "Predicting colorectal polyp recurrence using time-to-event analysis of\n  medical records", "comments": "Accepted in AMIA 2020 Informatics Summit", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.AP cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Identifying patient characteristics that influence the rate of colorectal\npolyp recurrence can provide important insights into which patients are at\nhigher risk for recurrence. We used natural language processing to extract\npolyp morphological characteristics from 953 polyp-presenting patients'\nelectronic medical records. We used subsequent colonoscopy reports to examine\nhow the time to polyp recurrence (731 patients experienced recurrence) is\ninfluenced by these characteristics as well as anthropometric features using\nKaplan-Meier curves, Cox proportional hazards modeling, and random survival\nforest models. We found that the rate of recurrence differed significantly by\npolyp size, number, and location and patient smoking status. Additionally,\nright-sided colon polyps increased recurrence risk by 30% compared to\nleft-sided polyps. History of tobacco use increased polyp recurrence risk by\n20% compared to never-users. A random survival forest model showed an AUC of\n0.65 and identified several other predictive variables, which can inform\ndevelopment of personalized polyp surveillance plans.\n", "versions": [{"version": "v1", "created": "Mon, 18 Nov 2019 00:01:23 GMT"}], "update_date": "2019-11-19", "authors_parsed": [["Harrington", "Lia X.", ""], ["Wei", "Jason W.", ""], ["Suriawinata", "Arief A.", ""], ["Mackenzie", "Todd A.", ""], ["Hassanpour", "Saeed", ""]]}, {"id": "1911.07375", "submitter": "Li-Yang Tan", "authors": "Guy Blanc, Jane Lange, Li-Yang Tan", "title": "Top-down induction of decision trees: rigorous guarantees and inherent\n  limitations", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.CC cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Consider the following heuristic for building a decision tree for a function\n$f : \\{0,1\\}^n \\to \\{\\pm 1\\}$. Place the most influential variable $x_i$ of $f$\nat the root, and recurse on the subfunctions $f_{x_i=0}$ and $f_{x_i=1}$ on the\nleft and right subtrees respectively; terminate once the tree is an\n$\\varepsilon$-approximation of $f$. We analyze the quality of this heuristic,\nobtaining near-matching upper and lower bounds:\n  $\\circ$ Upper bound: For every $f$ with decision tree size $s$ and every\n$\\varepsilon \\in (0,\\frac1{2})$, this heuristic builds a decision tree of size\nat most $s^{O(\\log(s/\\varepsilon)\\log(1/\\varepsilon))}$.\n  $\\circ$ Lower bound: For every $\\varepsilon \\in (0,\\frac1{2})$ and $s \\le\n2^{\\tilde{O}(\\sqrt{n})}$, there is an $f$ with decision tree size $s$ such that\nthis heuristic builds a decision tree of size $s^{\\tilde{\\Omega}(\\log s)}$.\n  We also obtain upper and lower bounds for monotone functions:\n$s^{O(\\sqrt{\\log s}/\\varepsilon)}$ and $s^{\\tilde{\\Omega}(\\sqrt[4]{\\log s } )}$\nrespectively. The lower bound disproves conjectures of Fiat and Pechyony (2004)\nand Lee (2009).\n  Our upper bounds yield new algorithms for properly learning decision trees\nunder the uniform distribution. We show that these algorithms---which are\nmotivated by widely employed and empirically successful top-down decision tree\nlearning heuristics such as ID3, C4.5, and CART---achieve provable guarantees\nthat compare favorably with those of the current fastest algorithm (Ehrenfeucht\nand Haussler, 1989). Our lower bounds shed new light on the limitations of\nthese heuristics.\n  Finally, we revisit the classic work of Ehrenfeucht and Haussler. We extend\nit to give the first uniform-distribution proper learning algorithm that\nachieves polynomial sample and memory complexity, while matching its\nstate-of-the-art quasipolynomial runtime.\n", "versions": [{"version": "v1", "created": "Mon, 18 Nov 2019 00:25:31 GMT"}], "update_date": "2019-11-19", "authors_parsed": [["Blanc", "Guy", ""], ["Lange", "Jane", ""], ["Tan", "Li-Yang", ""]]}, {"id": "1911.07381", "submitter": "Srikrishna Karanam", "authors": "Meng Zheng, Srikrishna Karanam, Terrence Chen, Richard J. Radke, and\n  Ziyan Wu", "title": "Learning Similarity Attention", "comments": "10 pages, 7 figures, 4 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the problem of learning similarity functions. While there has\nbeen substantial progress in learning suitable distance metrics, these\ntechniques in general lack decision reasoning, i.e., explaining why the input\nset of images is similar or dissimilar. In this work, we solve this key problem\nby proposing the first method to generate generic visual similarity\nexplanations with gradient-based attention. We demonstrate that our technique\nis agnostic to the specific similarity model type, e.g., we show applicability\nto Siamese, triplet, and quadruplet models. Furthermore, we make our proposed\nsimilarity attention a principled part of the learning process, resulting in a\nnew paradigm for learning similarity functions. We demonstrate that our\nlearning mechanism results in more generalizable, as well as explainable,\nsimilarity models. Finally, we demonstrate the generality of our framework by\nmeans of experiments on a variety of tasks, including image retrieval, person\nre-identification, and low-shot semantic segmentation.\n", "versions": [{"version": "v1", "created": "Mon, 18 Nov 2019 00:46:40 GMT"}], "update_date": "2019-11-19", "authors_parsed": [["Zheng", "Meng", ""], ["Karanam", "Srikrishna", ""], ["Chen", "Terrence", ""], ["Radke", "Richard J.", ""], ["Wu", "Ziyan", ""]]}, {"id": "1911.07383", "submitter": "Srikrishna Karanam", "authors": "Ren Li, Changjiang Cai, Georgios Georgakis, Srikrishna Karanam,\n  Terrence Chen, and Ziyan Wu", "title": "Towards Robust RGB-D Human Mesh Recovery", "comments": "10 pages, 4 figures, 4 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG cs.RO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the problem of human pose estimation. While much recent work has\nfocused on the RGB domain, these techniques are inherently under-constrained\nsince there can be many 3D configurations that explain the same 2D projection.\nTo this end, we propose a new method that uses RGB-D data to estimate a\nparametric human mesh model. Our key innovations include (a) the design of a\nnew dynamic data fusion module that facilitates learning with a combination of\nRGB-only and RGB-D datasets, (b) a new constraint generator module that\nprovides SMPL supervisory signals when explicit SMPL annotations are not\navailable, and (c) the design of a new depth ranking learning objective, all of\nwhich enable principled model training with RGB-D data. We conduct extensive\nexperiments on a variety of RGB-D datasets to demonstrate efficacy.\n", "versions": [{"version": "v1", "created": "Mon, 18 Nov 2019 00:55:37 GMT"}], "update_date": "2019-11-19", "authors_parsed": [["Li", "Ren", ""], ["Cai", "Changjiang", ""], ["Georgakis", "Georgios", ""], ["Karanam", "Srikrishna", ""], ["Chen", "Terrence", ""], ["Wu", "Ziyan", ""]]}, {"id": "1911.07389", "submitter": "Srikrishna Karanam", "authors": "Wenqian Liu, Runze Li, Meng Zheng, Srikrishna Karanam, Ziyan Wu, Bir\n  Bhanu, Richard J. Radke, Octavia Camps", "title": "Towards Visually Explaining Variational Autoencoders", "comments": "10 pages, 9 figures, 2 tables, CVPR 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent advances in Convolutional Neural Network (CNN) model interpretability\nhave led to impressive progress in visualizing and understanding model\npredictions. In particular, gradient-based visual attention methods have driven\nmuch recent effort in using visual attention maps as a means for visual\nexplanations. A key problem, however, is these methods are designed for\nclassification and categorization tasks, and their extension to explaining\ngenerative models, e.g. variational autoencoders (VAE) is not trivial. In this\nwork, we take a step towards bridging this crucial gap, proposing the first\ntechnique to visually explain VAEs by means of gradient-based attention. We\npresent methods to generate visual attention from the learned latent space, and\nalso demonstrate such attention explanations serve more than just explaining\nVAE predictions. We show how these attention maps can be used to localize\nanomalies in images, demonstrating state-of-the-art performance on the MVTec-AD\ndataset. We also show how they can be infused into model training, helping\nbootstrap the VAE into learning improved latent space disentanglement,\ndemonstrated on the Dsprites dataset.\n", "versions": [{"version": "v1", "created": "Mon, 18 Nov 2019 01:05:41 GMT"}, {"version": "v2", "created": "Mon, 24 Feb 2020 16:11:16 GMT"}, {"version": "v3", "created": "Thu, 5 Mar 2020 15:52:04 GMT"}, {"version": "v4", "created": "Wed, 11 Mar 2020 14:20:02 GMT"}, {"version": "v5", "created": "Mon, 23 Mar 2020 15:09:27 GMT"}, {"version": "v6", "created": "Tue, 24 Mar 2020 15:51:40 GMT"}, {"version": "v7", "created": "Tue, 14 Apr 2020 16:52:49 GMT"}], "update_date": "2020-04-15", "authors_parsed": [["Liu", "Wenqian", ""], ["Li", "Runze", ""], ["Zheng", "Meng", ""], ["Karanam", "Srikrishna", ""], ["Wu", "Ziyan", ""], ["Bhanu", "Bir", ""], ["Radke", "Richard J.", ""], ["Camps", "Octavia", ""]]}, {"id": "1911.07391", "submitter": "Zhaoyuan Yang", "authors": "Nurali Virani, Naresh Iyer, Zhaoyuan Yang", "title": "Justification-Based Reliability in Machine Learning", "comments": "Extended version of paper accepted at AAAI 2020 with supplementary\n  materials", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  With the advent of Deep Learning, the field of machine learning (ML) has\nsurpassed human-level performance on diverse classification tasks. At the same\ntime, there is a stark need to characterize and quantify reliability of a\nmodel's prediction on individual samples. This is especially true in\napplication of such models in safety-critical domains of industrial control and\nhealthcare. To address this need, we link the question of reliability of a\nmodel's individual prediction to the epistemic uncertainty of the model's\nprediction. More specifically, we extend the theory of Justified True Belief\n(JTB) in epistemology, created to study the validity and limits of\nhuman-acquired knowledge, towards characterizing the validity and limits of\nknowledge in supervised classifiers. We present an analysis of neural network\nclassifiers linking the reliability of its prediction on an input to\ncharacteristics of the support gathered from the input and latent spaces of the\nnetwork. We hypothesize that the JTB analysis exposes the epistemic uncertainty\n(or ignorance) of a model with respect to its inference, thereby allowing for\nthe inference to be only as strong as the justification permits. We explore\nvarious forms of support (for e.g., k-nearest neighbors (k-NN) and l_p-norm\nbased) generated for an input, using the training data to construct a\njustification for the prediction with that input. Through experiments conducted\non simulated and real datasets, we demonstrate that our approach can provide\nreliability for individual predictions and characterize regions where such\nreliability cannot be ascertained.\n", "versions": [{"version": "v1", "created": "Mon, 18 Nov 2019 01:15:24 GMT"}, {"version": "v2", "created": "Tue, 21 Jan 2020 22:47:44 GMT"}], "update_date": "2020-01-23", "authors_parsed": [["Virani", "Nurali", ""], ["Iyer", "Naresh", ""], ["Yang", "Zhaoyuan", ""]]}, {"id": "1911.07399", "submitter": "Xijie Huang", "authors": "Xijie Huang, Moustafa Alzantot, Mani Srivastava", "title": "NeuronInspect: Detecting Backdoors in Neural Networks via Output\n  Explanations", "comments": "8 pages, 13 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep neural networks have achieved state-of-the-art performance on various\ntasks. However, lack of interpretability and transparency makes it easier for\nmalicious attackers to inject trojan backdoor into the neural networks, which\nwill make the model behave abnormally when a backdoor sample with a specific\ntrigger is input. In this paper, we propose NeuronInspect, a framework to\ndetect trojan backdoors in deep neural networks via output explanation\ntechniques. NeuronInspect first identifies the existence of backdoor attack\ntargets by generating the explanation heatmap of the output layer. We observe\nthat generated heatmaps from clean and backdoored models have different\ncharacteristics. Therefore we extract features that measure the attributes of\nexplanations from an attacked model namely: sparse, smooth and persistent. We\ncombine these features and use outlier detection to figure out the outliers,\nwhich is the set of attack targets. We demonstrate the effectiveness and\nefficiency of NeuronInspect on MNIST digit recognition dataset and GTSRB\ntraffic sign recognition dataset. We extensively evaluate NeuronInspect on\ndifferent attack scenarios and prove better robustness and effectiveness over\nstate-of-the-art trojan backdoor detection techniques Neural Cleanse by a great\nmargin.\n", "versions": [{"version": "v1", "created": "Mon, 18 Nov 2019 02:27:10 GMT"}], "update_date": "2019-11-19", "authors_parsed": [["Huang", "Xijie", ""], ["Alzantot", "Moustafa", ""], ["Srivastava", "Mani", ""]]}, {"id": "1911.07409", "submitter": "Qinyi Chen", "authors": "Andrea Boskovic, Qinyi Chen, Dominik Kufel, Zijie Zhou", "title": "Online Learning and Matching for Resource Allocation Problems", "comments": "22 pages, 9 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.OC cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In order for an e-commerce platform to maximize its revenue, it must\nrecommend customers items they are most likely to purchase. However, the\ncompany often has business constraints on these items, such as the number of\neach item in stock. In this work, our goal is to recommend items to users as\nthey arrive on a webpage sequentially, in an online manner, in order to\nmaximize reward for a company, but also satisfy budget constraints. We first\napproach the simpler online problem in which the customers arrive as a\nstationary Poisson process, and present an integrated algorithm that performs\nonline optimization and online learning together. We then make the model more\ncomplicated but more realistic, treating the arrival processes as\nnon-stationary Poisson processes. To deal with heterogeneous customer arrivals,\nwe propose a time segmentation algorithm that converts a non-stationary problem\ninto a series of stationary problems. Experiments conducted on large-scale\nsynthetic data demonstrate the effectiveness and efficiency of our proposed\napproaches on solving constrained resource allocation problems.\n", "versions": [{"version": "v1", "created": "Mon, 18 Nov 2019 03:36:37 GMT"}], "update_date": "2019-11-19", "authors_parsed": [["Boskovic", "Andrea", ""], ["Chen", "Qinyi", ""], ["Kufel", "Dominik", ""], ["Zhou", "Zijie", ""]]}, {"id": "1911.07412", "submitter": "Cenk Baykal", "authors": "Lucas Liebenwein, Cenk Baykal, Harry Lang, Dan Feldman, Daniela Rus", "title": "Provable Filter Pruning for Efficient Neural Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a provable, sampling-based approach for generating compact\nConvolutional Neural Networks (CNNs) by identifying and removing redundant\nfilters from an over-parameterized network. Our algorithm uses a small batch of\ninput data points to assign a saliency score to each filter and constructs an\nimportance sampling distribution where filters that highly affect the output\nare sampled with correspondingly high probability. In contrast to existing\nfilter pruning approaches, our method is simultaneously data-informed, exhibits\nprovable guarantees on the size and performance of the pruned network, and is\nwidely applicable to varying network architectures and data sets. Our\nanalytical bounds bridge the notions of compressibility and importance of\nnetwork structures, which gives rise to a fully-automated procedure for\nidentifying and preserving filters in layers that are essential to the\nnetwork's performance. Our experimental evaluations on popular architectures\nand data sets show that our algorithm consistently generates sparser and more\nefficient models than those constructed by existing filter pruning approaches.\n", "versions": [{"version": "v1", "created": "Mon, 18 Nov 2019 03:56:49 GMT"}, {"version": "v2", "created": "Mon, 23 Mar 2020 04:39:39 GMT"}], "update_date": "2020-03-24", "authors_parsed": [["Liebenwein", "Lucas", ""], ["Baykal", "Cenk", ""], ["Lang", "Harry", ""], ["Feldman", "Dan", ""], ["Rus", "Daniela", ""]]}, {"id": "1911.07418", "submitter": "Dian Ang Yap", "authors": "Dian Ang Yap, Nicholas Roberts, Vinay Uday Prabhu", "title": "Grassmannian Packings in Neural Networks: Learning with Maximal Subspace\n  Packings for Diversity and Anti-Sparsity", "comments": "Presented at Bayesian Deep Learning and Workshop on Information\n  Theory and Machine Learning, 33rd Conference on Neural Information\n  ProcessingSystems (NeurIPS 2019), Vancouver, Canada", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.IT math.IT stat.ML", "license": "http://creativecommons.org/publicdomain/zero/1.0/", "abstract": "  Kernel sparsity (\"dying ReLUs\") and lack of diversity are commonly observed\nin CNN kernels, which decreases model capacity. Drawing inspiration from\ninformation theory and wireless communications, we demonstrate the intersection\nof coding theory and deep learning through the Grassmannian subspace packing\nproblem in CNNs. We propose Grassmannian packings for initial kernel layers to\nbe initialized maximally far apart based on chordal or Fubini-Study distance.\nConvolutional kernels initialized with Grassmannian packings exhibit diverse\nfeatures and obtain diverse representations. We show that Grassmannian\npackings, especially in the initial layers, address kernel sparsity and\nencourage diversity, while improving classification accuracy across shallow and\ndeep CNNs with better convergence rates.\n", "versions": [{"version": "v1", "created": "Mon, 18 Nov 2019 04:17:06 GMT"}], "update_date": "2019-11-19", "authors_parsed": [["Yap", "Dian Ang", ""], ["Roberts", "Nicholas", ""], ["Prabhu", "Vinay Uday", ""]]}, {"id": "1911.07420", "submitter": "Ignavier Ng", "authors": "Ignavier Ng, Shengyu Zhu, Zhitang Chen, Zhuangyan Fang", "title": "A Graph Autoencoder Approach to Causal Structure Learning", "comments": "NeurIPS 2019 Workshop \"Do the right thing\": machine learning and\n  causal inference for improved decision making", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Causal structure learning has been a challenging task in the past decades and\nseveral mainstream approaches such as constraint- and score-based methods have\nbeen studied with theoretical guarantees. Recently, a new approach has\ntransformed the combinatorial structure learning problem into a continuous one\nand then solved it using gradient-based optimization methods. Following the\nrecent state-of-the-arts, we propose a new gradient-based method to learn\ncausal structures from observational data. The proposed method generalizes the\nrecent gradient-based methods to a graph autoencoder framework that allows\nnonlinear structural equation models and is easily applicable to vector-valued\nvariables. We demonstrate that on synthetic datasets, our proposed method\noutperforms other gradient-based methods significantly, especially on large\ncausal graphs. We further investigate the scalability and efficiency of our\nmethod, and observe a near linear training time when scaling up the graph size.\n", "versions": [{"version": "v1", "created": "Mon, 18 Nov 2019 04:22:00 GMT"}], "update_date": "2019-11-19", "authors_parsed": [["Ng", "Ignavier", ""], ["Zhu", "Shengyu", ""], ["Chen", "Zhitang", ""], ["Fang", "Zhuangyan", ""]]}, {"id": "1911.07421", "submitter": "Xiaofeng Liu", "authors": "Tong Che, Xiaofeng Liu, Site Li, Yubin Ge, Ruixiang Zhang, Caiming\n  Xiong, Yoshua Bengio", "title": "Deep Verifier Networks: Verification of Deep Discriminative Models with\n  Deep Generative Models", "comments": "Accepted to AAAI 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.LG cs.MM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  AI Safety is a major concern in many deep learning applications such as\nautonomous driving. Given a trained deep learning model, an important natural\nproblem is how to reliably verify the model's prediction. In this paper, we\npropose a novel framework -- deep verifier networks (DVN) to verify the inputs\nand outputs of deep discriminative models with deep generative models. Our\nproposed model is based on conditional variational auto-encoders with\ndisentanglement constraints. We give both intuitive and theoretical\njustifications of the model. Our verifier network is trained independently with\nthe prediction model, which eliminates the need of retraining the verifier\nnetwork for a new model. We test the verifier network on out-of-distribution\ndetection and adversarial example detection problems, as well as anomaly\ndetection problems in structured prediction tasks such as image caption\ngeneration. We achieve state-of-the-art results in all of these problems.\n", "versions": [{"version": "v1", "created": "Mon, 18 Nov 2019 04:23:12 GMT"}, {"version": "v2", "created": "Sat, 8 Feb 2020 03:10:15 GMT"}, {"version": "v3", "created": "Fri, 1 Jan 2021 21:08:11 GMT"}], "update_date": "2021-01-05", "authors_parsed": [["Che", "Tong", ""], ["Liu", "Xiaofeng", ""], ["Li", "Site", ""], ["Ge", "Yubin", ""], ["Zhang", "Ruixiang", ""], ["Xiong", "Caiming", ""], ["Bengio", "Yoshua", ""]]}, {"id": "1911.07424", "submitter": "Cheol-Hwan Yoo", "authors": "Cheol-hwan Yoo, Seo-won Ji, Yong-goo Shin, Seung-wook Kim, and\n  Sung-jea Ko", "title": "Fast and Accurate 3D Hand Pose Estimation via Recurrent Neural Network\n  for Capturing Hand Articulations", "comments": null, "journal-ref": "IEEE Access. 8 (2020) 114010-114019", "doi": "10.1109/ACCESS.2020.3001637", "report-no": null, "categories": "cs.CV cs.LG eess.IV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  3D hand pose estimation from a single depth image plays an important role in\ncomputer vision and human-computer interaction. Although recent hand pose\nestimation methods using convolution neural network (CNN) have shown notable\nimprovements in accuracy, most of them have a limitation that they rely on a\ncomplex network structure without fully exploiting the articulated structure of\nthe hand. A hand, which is an articulated object, is composed of six local\nparts: the palm and five independent fingers. Each finger consists of\nsequential-joints that provide constrained motion, referred to as a kinematic\nchain. In this paper, we propose a hierarchically-structured convolutional\nrecurrent neural network (HCRNN) with six branches that estimate the 3D\nposition of the palm and five fingers independently. The palm position is\npredicted via fully-connected layers. Each sequential-joint, i.e. finger\nposition, is obtained using a recurrent neural network (RNN) to capture the\nspatial dependencies between adjacent joints. Then the output features of the\npalm and finger branches are concatenated to estimate the global hand position.\nHCRNN directly takes the depth map as an input without a time-consuming data\nconversion, such as 3D voxels and point clouds. Experimental results on public\ndatasets demonstrate that the proposed HCRNN not only outperforms most 2D\nCNN-based methods using the depth image as their inputs but also achieves\ncompetitive results with state-of-the-art 3D CNN-based methods with a highly\nefficient running speed of 285 fps on a single GPU.\n", "versions": [{"version": "v1", "created": "Mon, 18 Nov 2019 04:38:25 GMT"}, {"version": "v2", "created": "Wed, 18 Mar 2020 04:36:31 GMT"}], "update_date": "2020-08-28", "authors_parsed": [["Yoo", "Cheol-hwan", ""], ["Ji", "Seo-won", ""], ["Shin", "Yong-goo", ""], ["Kim", "Seung-wook", ""], ["Ko", "Sung-jea", ""]]}, {"id": "1911.07427", "submitter": "Kai Hu", "authors": "Kai Hu, Barnabas Poczos", "title": "RotationOut as a Regularization Method for Neural Network", "comments": "20 pages, 8 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we propose a novel regularization method, RotationOut, for\nneural networks. Different from Dropout that handles each neuron/channel\nindependently, RotationOut regards its input layer as an entire vector and\nintroduces regularization by randomly rotating the vector. RotationOut can also\nbe used in convolutional layers and recurrent layers with small modifications.\nWe further use a noise analysis method to interpret the difference between\nRotationOut and Dropout in co-adaptation reduction. Using this method, we also\nshow how to use RotationOut/Dropout together with Batch Normalization.\nExtensive experiments in vision and language tasks are conducted to show the\neffectiveness of the proposed method. Codes are available at\n\\url{https://github.com/RotationOut/RotationOut}.\n", "versions": [{"version": "v1", "created": "Mon, 18 Nov 2019 04:45:47 GMT"}], "update_date": "2019-11-19", "authors_parsed": [["Hu", "Kai", ""], ["Poczos", "Barnabas", ""]]}, {"id": "1911.07429", "submitter": "Furao Shen", "authors": "Yahui Liu, Furao Shen, Jian Zhao", "title": "Pairwise Interactive Graph Attention Network for Context-Aware\n  Recommendation", "comments": "8 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Context-aware recommender systems (CARS), which consider rich side\ninformation to improve recommendation performance, have caught more and more\nattention in both academia and industry. How to predict user preferences from\ndiverse contextual features is the core of CARS. Several recent models pay\nattention to user behaviors and use specifically designed structures to extract\nadaptive user interests from history behaviors. However, few works take item\nhistory interactions into consideration, which leads to the insufficiency of\nitem feature representation and item attraction extraction. From these\nobservations, we model the user-item interaction as a dynamic interaction graph\n(DIG) and proposed a GNN-based model called Pairwise Interactive Graph\nAttention Network (PIGAT) to capture dynamic user interests and item\nattractions simultaneously. PIGAT introduces the attention mechanism to\nconsider the importance of each interacted user/item to both the user and the\nitem, which captures user interests, item attractions and their influence on\nthe recommendation context. Moreover, confidence embeddings are applied to\ninteractions to distinguish the confidence of interactions occurring at\ndifferent times. Then more expressive user/item representations and adaptive\ninteraction features are generated, which benefits the recommendation\nperformance especially when involving long-tail items. We conduct experiments\non three real-world datasets to demonstrate the effectiveness of PIGAT.\n", "versions": [{"version": "v1", "created": "Mon, 18 Nov 2019 05:06:05 GMT"}], "update_date": "2019-11-19", "authors_parsed": [["Liu", "Yahui", ""], ["Shen", "Furao", ""], ["Zhao", "Jian", ""]]}, {"id": "1911.07446", "submitter": "Cong Hao", "authors": "Cong Hao, Yao Chen, Xinheng Liu, Atif Sarwari, Daryl Sew, Ashutosh\n  Dhar, Bryan Wu, Dongdong Fu, Jinjun Xiong, Wen-mei Hwu, Junli Gu, Deming Chen", "title": "NAIS: Neural Architecture and Implementation Search and its Applications\n  in Autonomous Driving", "comments": "8 pages, ICCAD 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The rapidly growing demands for powerful AI algorithms in many application\ndomains have motivated massive investment in both high-quality deep neural\nnetwork (DNN) models and high-efficiency implementations. In this position\npaper, we argue that a simultaneous DNN/implementation co-design methodology,\nnamed Neural Architecture and Implementation Search (NAIS), deserves more\nresearch attention to boost the development productivity and efficiency of both\nDNN models and implementation optimization. We propose a stylized design\nmethodology that can drastically cut down the search cost while preserving the\nquality of the end solution.As an illustration, we discuss this\nDNN/implementation methodology in the context of both FPGAs and GPUs. We take\nautonomous driving as a key use case as it is one of the most demanding areas\nfor high quality AI algorithms and accelerators. We discuss how such a\nco-design methodology can impact the autonomous driving industry significantly.\nWe identify several research opportunities in this exciting domain.\n", "versions": [{"version": "v1", "created": "Mon, 18 Nov 2019 06:17:14 GMT"}], "update_date": "2019-11-19", "authors_parsed": [["Hao", "Cong", ""], ["Chen", "Yao", ""], ["Liu", "Xinheng", ""], ["Sarwari", "Atif", ""], ["Sew", "Daryl", ""], ["Dhar", "Ashutosh", ""], ["Wu", "Bryan", ""], ["Fu", "Dongdong", ""], ["Xiong", "Jinjun", ""], ["Hwu", "Wen-mei", ""], ["Gu", "Junli", ""], ["Chen", "Deming", ""]]}, {"id": "1911.07453", "submitter": "Chenye Wu", "authors": "Jingshi Cui, Haoxiang Wang, Chenye Wu, Yang Yu", "title": "Vulnerability Analysis for Data Driven Pricing Schemes", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.SY eess.SP eess.SY stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Data analytics and machine learning techniques are being rapidly adopted into\nthe power system, including power system control as well as electricity market\ndesign. In this paper, from an adversarial machine learning point of view, we\nexamine the vulnerability of data-driven electricity market design. More\nprecisely, we follow the idea that consumer's load profile should uniquely\ndetermine its electricity rate, which yields a clustering oriented pricing\nscheme. We first identify the strategic behaviors of malicious users by\ndefining a notion of disguising. Based on this notion, we characterize the\nsensitivity zones to evaluate the percentage of malicious users in each\ncluster. Based on a thorough cost benefit analysis, we conclude with the\nvulnerability analysis.\n", "versions": [{"version": "v1", "created": "Mon, 18 Nov 2019 06:58:20 GMT"}], "update_date": "2019-11-19", "authors_parsed": [["Cui", "Jingshi", ""], ["Wang", "Haoxiang", ""], ["Wu", "Chenye", ""], ["Yu", "Yang", ""]]}, {"id": "1911.07456", "submitter": "Aleksandar Haber", "authors": "Aleksandar Haber", "title": "Steady-State Control and Machine Learning of Large-Scale Deformable\n  Mirror Models", "comments": "5 pages, 6 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.SY cs.LG cs.SY math.OC physics.optics stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We use Machine Learning (ML) and system identification validation approaches\nto estimate neural network models of large-scale Deformable Mirrors (DMs) used\nin Adaptive Optics (AO) systems. To obtain the training, validation, and test\ndata sets, we simulate a realistic large-scale Finite Element (FE) model of a\nfaceplate DM. The estimated models reproduce the input-output behavior of\nVector AutoRegressive with eXogenous (VARX) input models and can be used for\nthe design of high-performance AO systems. We address the model order selection\nand overfitting problems. We also provide an FE based approach for computing\nsteady-state control signals that produce the desired wavefront shape. This\napproach can be used to predict the steady-state DM correction performance for\ndifferent actuator spacings and configurations. The presented methods are\ntested on models with thousands of state variables and hundreds of actuators.\nThe numerical simulations are performed on low-cost high-performance graphic\nprocessing units and implemented using the TensorFlow machine learning\nframework. The used codes are available online. The approaches presented in\nthis paper are useful for the design and optimization of high-performance DMs\nand AO systems.\n", "versions": [{"version": "v1", "created": "Mon, 18 Nov 2019 07:09:47 GMT"}], "update_date": "2019-11-19", "authors_parsed": [["Haber", "Aleksandar", ""]]}, {"id": "1911.07460", "submitter": "Ilja Manakov", "authors": "Ilja Manakov, Markus Rohm, Volker Tresp", "title": "Walking the Tightrope: An Investigation of the Convolutional Autoencoder\n  Bottleneck", "comments": "code available at https://github.com/IljaManakov/WalkingTheTightrope", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV", "license": "http://creativecommons.org/licenses/by-sa/4.0/", "abstract": "  In this paper, we present an in-depth investigation of the convolutional\nautoencoder (CAE) bottleneck. Autoencoders (AE), and especially their\nconvolutional variants, play a vital role in the current deep learning toolbox.\nResearchers and practitioners employ CAEs for a variety of tasks, ranging from\noutlier detection and compression to transfer and representation learning.\nDespite their widespread adoption, we have limited insight into how the\nbottleneck shape impacts the emergent properties of the CAE. We demonstrate\nthat increased height and width of the bottleneck drastically improves\ngeneralization, which in turn leads to better performance of the latent codes\nin downstream transfer learning tasks. The number of channels in the\nbottleneck, on the other hand, is secondary in importance. Furthermore, we show\nempirically that, contrary to popular belief, CAEs do not learn to copy their\ninput, even when the bottleneck has the same number of neurons as there are\npixels in the input. Copying does not occur, despite training the CAE for 1,000\nepochs on a tiny ($\\approx$ 600 images) dataset. We believe that the findings\nin this paper are directly applicable and will lead to improvements in models\nthat rely on CAEs.\n", "versions": [{"version": "v1", "created": "Mon, 18 Nov 2019 07:19:14 GMT"}, {"version": "v2", "created": "Tue, 12 May 2020 19:27:36 GMT"}], "update_date": "2020-05-14", "authors_parsed": [["Manakov", "Ilja", ""], ["Rohm", "Markus", ""], ["Tresp", "Volker", ""]]}, {"id": "1911.07489", "submitter": "Haoyi Xiong", "authors": "Ruosi Wan and Haoyi Xiong and Xingjian Li and Zhanxing Zhu and Jun\n  Huan", "title": "Towards Making Deep Transfer Learning Never Hurt", "comments": "10 pages", "journal-ref": "accapted as long paper at the 19th IEEE International Conference\n  on Data Mining, 2019", "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Transfer learning have been frequently used to improve deep neural network\ntraining through incorporating weights of pre-trained networks as the\nstarting-point of optimization for regularization. While deep transfer learning\ncan usually boost the performance with better accuracy and faster convergence,\ntransferring weights from inappropriate networks hurts training procedure and\nmay lead to even lower accuracy. In this paper, we consider deep transfer\nlearning as minimizing a linear combination of empirical loss and regularizer\nbased on pre-trained weights, where the regularizer would restrict the training\nprocedure from lowering the empirical loss, with conflicted descent directions\n(e.g., derivatives). Following the view, we propose a novel strategy making\nregularization-based Deep Transfer learning Never Hurt (DTNH) that, for each\niteration of training procedure, computes the derivatives of the two terms\nseparately, then re-estimates a new descent direction that does not hurt the\nempirical loss minimization while preserving the regularization affects from\nthe pre-trained weights. Extensive experiments have been done using common\ntransfer learning regularizers, such as L2-SP and knowledge distillation, on\ntop of a wide range of deep transfer learning benchmarks including Caltech, MIT\nindoor 67, CIFAR-10 and ImageNet. The empirical results show that the proposed\ndescent direction estimation strategy DTNH can always improve the performance\nof deep transfer learning tasks based on all above regularizers, even when\ntransferring pre-trained weights from inappropriate networks. All in all, DTNH\nstrategy can improve state-of-the-art regularizers in all cases with 0.1%--7%\nhigher accuracy in all experiments.\n", "versions": [{"version": "v1", "created": "Mon, 18 Nov 2019 09:00:05 GMT"}], "update_date": "2019-11-19", "authors_parsed": [["Wan", "Ruosi", ""], ["Xiong", "Haoyi", ""], ["Li", "Xingjian", ""], ["Zhu", "Zhanxing", ""], ["Huan", "Jun", ""]]}, {"id": "1911.07498", "submitter": "Yifan Zhang", "authors": "Yifan Zhang, Peilin Zhao, Shuaicheng Niu, Qingyao Wu, Jiezhang Cao,\n  Junzhou Huang, Mingkui Tan", "title": "Online Adaptive Asymmetric Active Learning with Limited Budgets", "comments": null, "journal-ref": "IEEE Transactions on Knowledge and Data Engineering (TKDE), 2019", "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Online Active Learning (OAL) aims to manage unlabeled datastream by\nselectively querying the label of data. OAL is applicable to many real-world\nproblems, such as anomaly detection in health-care and finance. In these\nproblems, there are two key challenges: the query budget is often limited; the\nratio between classes is highly imbalanced. In practice, it is quite difficult\nto handle imbalanced unlabeled datastream when only a limited budget of labels\ncan be queried for training. To solve this, previous OAL studies adopt either\nasymmetric losses or queries (an isolated asymmetric strategy) to tackle the\nimbalance, and use first-order methods to optimize the cost-sensitive measure.\nHowever, the isolated strategy limits their performance in class imbalance,\nwhile first-order methods restrict their optimization performance. In this\npaper, we propose a novel Online Adaptive Asymmetric Active learning algorithm,\nbased on a new asymmetric strategy (merging both asymmetric losses and queries\nstrategies), and second-order optimization. We theoretically analyze its\nmistake bound and cost-sensitive metric bounds. Moreover, to better balance\nperformance and efficiency, we enhance our algorithm via a sketching technique,\nwhich significantly accelerates the computational speed with quite slight\nperformance degradation. Promising results demonstrate the effectiveness and\nefficiency of the proposed methods.\n", "versions": [{"version": "v1", "created": "Mon, 18 Nov 2019 09:36:38 GMT"}], "update_date": "2019-11-19", "authors_parsed": [["Zhang", "Yifan", ""], ["Zhao", "Peilin", ""], ["Niu", "Shuaicheng", ""], ["Wu", "Qingyao", ""], ["Cao", "Jiezhang", ""], ["Huang", "Junzhou", ""], ["Tan", "Mingkui", ""]]}, {"id": "1911.07508", "submitter": "Cl\\'ement Elvira", "authors": "Cl\\'ement Elvira and C\\'edric Herzet", "title": "Safe squeezing for antisparse coding", "comments": null, "journal-ref": null, "doi": "10.1109/TSP.2020.2995192", "report-no": null, "categories": "cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Spreading the information over all coefficients of a representation is a\ndesirable property in many applications such as digital communication or\nmachine learning. This so-called antisparse representation can be obtained by\nsolving a convex program involving an $\\ell_\\infty$-norm penalty combined with\na quadratic discrepancy. In this paper, we propose a new methodology, dubbed\nsafe squeezing, to accelerate the computation of antisparse representation. We\ndescribe a test that allows to detect saturated entries in the solution of the\noptimization problem. The contribution of these entries is compacted into a\nsingle vector, thus operating a form of dimensionality reduction. We propose\ntwo algorithms to solve the resulting lower dimensional problem. Numerical\nexperiments show the effectiveness of the proposed method to detect the\nsaturated components of the solution and illustrates the induced computational\ngains in the resolution of the antisparse problem.\n", "versions": [{"version": "v1", "created": "Mon, 18 Nov 2019 09:46:20 GMT"}, {"version": "v2", "created": "Sat, 28 Mar 2020 17:35:20 GMT"}], "update_date": "2020-07-15", "authors_parsed": [["Elvira", "Cl\u00e9ment", ""], ["Herzet", "C\u00e9dric", ""]]}, {"id": "1911.07509", "submitter": "Anis Koubaa", "authors": "Marwa Ben Jabra, Adel Ammar, Anis Koubaa, Omar Cheikhrouhou, Habib\n  Hamam", "title": "AI-based Pilgrim Detection using Convolutional Neural Networks", "comments": "Accepted in ATSIP'2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG cs.NE", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Pilgrimage represents the most important Islamic religious gathering in the\nworld where millions of pilgrims visit the holy places of Makkah and Madinah to\nperform their rituals. The safety and security of pilgrims is the highest\npriority for the authorities. In Makkah, 5000 cameras are spread around the\nholy for monitoring pilgrims, but it is almost impossible to track all events\nby humans considering the huge number of images collected every second. To\naddress this issue, we propose to use artificial intelligence technique based\non deep learning and convolution neural networks to detect and identify\nPilgrims and their features. For this purpose, we built a comprehensive dataset\nfor the detection of pilgrims and their genders. Then, we develop two\nconvolutional neural networks based on YOLOv3 and Faster-RCNN for the detection\nof Pilgrims. Experiments results show that Faster RCNN with Inception v2\nfeature extractor provides the best mean average precision over all classes of\n51%.\n", "versions": [{"version": "v1", "created": "Mon, 18 Nov 2019 09:46:54 GMT"}, {"version": "v2", "created": "Tue, 18 Feb 2020 19:06:10 GMT"}], "update_date": "2020-02-20", "authors_parsed": [["Jabra", "Marwa Ben", ""], ["Ammar", "Adel", ""], ["Koubaa", "Anis", ""], ["Cheikhrouhou", "Omar", ""], ["Hamam", "Habib", ""]]}, {"id": "1911.07511", "submitter": "Florian Pfisterer", "authors": "Florian Pfisterer and Laura Beggel and Xudong Sun and Fabian Scheipl\n  and Bernd Bischl", "title": "Benchmarking time series classification -- Functional data vs machine\n  learning approaches", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Time series classification problems have drawn increasing attention in the\nmachine learning and statistical community. Closely related is the field of\nfunctional data analysis (FDA): it refers to the range of problems that deal\nwith the analysis of data that is continuously indexed over some domain. While\noften employing different methods, both fields strive to answer similar\nquestions, a common example being classification or regression problems with\nfunctional covariates. We study methods from functional data analysis, such as\nfunctional generalized additive models, as well as functionality to concatenate\n(functional-) feature extraction or basis representations with traditional\nmachine learning algorithms like support vector machines or classification\ntrees. In order to assess the methods and implementations, we run a benchmark\non a wide variety of representative (time series) data sets, with in-depth\nanalysis of empirical results, and strive to provide a reference ranking for\nwhich method(s) to use for non-expert practitioners. Additionally, we provide a\nsoftware framework in R for functional data analysis for supervised learning,\nincluding machine learning and more linear approaches from statistics. This\nallows convenient access, and in connection with the machine-learning toolbox\nmlr, those methods can now also be tuned and benchmarked.\n", "versions": [{"version": "v1", "created": "Mon, 18 Nov 2019 09:52:28 GMT"}, {"version": "v2", "created": "Wed, 24 Feb 2021 10:31:48 GMT"}], "update_date": "2021-02-25", "authors_parsed": [["Pfisterer", "Florian", ""], ["Beggel", "Laura", ""], ["Sun", "Xudong", ""], ["Scheipl", "Fabian", ""], ["Bischl", "Bernd", ""]]}, {"id": "1911.07515", "submitter": "Syed Jawad Shah", "authors": "Ahmed Awad Albishri, Syed Jawad Hussain Shah, Anthony Schmiedler,\n  Seung Suk Kang, Yugyung Lee", "title": "Automated Human Claustrum Segmentation using Deep Learning Technologies", "comments": "6 pages, 4 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.IV cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In recent years, Deep Learning (DL) has shown promising results in conducting\nAI tasks such as computer vision and image segmentation. Specifically,\nConvolutional Neural Network (CNN) models in DL have been applied to\nprevention,detection, and diagnosis in predictive medicine. Image segmentation\nplays a significant role in disease detection and prevention.However, there are\nenormous challenges in performing DL-based automatic segmentation due to the\nnature of medical images such as heterogeneous modalities and formats,\ninsufficient labeled training data, and the high-class imbalance in the labeled\ndata. Furthermore, automating segmentation of medical images,like magnetic\nresonance images (MRI), becomes a challenging task. The need for automated\nsegmentation or annotation is what motivates our work. In this paper, we\npropose a fully automated approach that aims to segment the human claustrum for\nanalytical purposes. We applied a U-Net CNN model to segment the claustrum (Cl)\nfrom a MRI dataset. With this approach, we have achieved an average Dice per\ncase score of 0.72 for Cl segmentation, with K=5 for cross-validation. The\nexpert in the medical domain also evaluates these results.\n", "versions": [{"version": "v1", "created": "Mon, 18 Nov 2019 09:59:09 GMT"}], "update_date": "2019-11-19", "authors_parsed": [["Albishri", "Ahmed Awad", ""], ["Shah", "Syed Jawad Hussain", ""], ["Schmiedler", "Anthony", ""], ["Kang", "Seung Suk", ""], ["Lee", "Yugyung", ""]]}, {"id": "1911.07523", "submitter": "Ramtine Tofighi-Shirazi", "authors": "Ramtine Tofighi-Shirazi (TL), Irina Mariuca Asavoae (TL), Philippe\n  Elbaz-Vincent (IF)", "title": "Fine-Grained Static Detection of Obfuscation Transforms Using\n  Ensemble-Learning and Semantic Reasoning", "comments": "Software Security, Protection, and Reverse Engineering Workshop\n  (SSPREW9), Dec 2019, San Juan, United States", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.CR cs.IT cs.LG math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The ability to efficiently detect the software protections used is at a prime\nto facilitate the selection and application of adequate deob-fuscation\ntechniques. We present a novel approach that combines semantic reasoning\ntechniques with ensemble learning classification for the purpose of providing a\nstatic detection framework for obfuscation transformations. By contrast to\nexisting work, we provide a methodology that can detect multiple layers of\nobfuscation, without depending on knowledge of the underlying functionality of\nthe training-set used. We also extend our work to detect constructions of\nobfuscation transformations, thus providing a fine-grained methodology. To that\nend, we provide several studies for the best practices of the use of machine\nlearning techniques for a scalable and efficient model. According to our\nexperimental results and evaluations on obfuscators such as Tigress and OLLVM,\nour models have up to 91% accuracy on state-of-the-art obfuscation\ntransformations. Our overall accuracies for their constructions are up to 100%.\n", "versions": [{"version": "v1", "created": "Mon, 18 Nov 2019 10:16:38 GMT"}], "update_date": "2019-11-19", "authors_parsed": [["Tofighi-Shirazi", "Ramtine", "", "TL"], ["Asavoae", "Irina Mariuca", "", "TL"], ["Elbaz-Vincent", "Philippe", "", "IF"]]}, {"id": "1911.07532", "submitter": "Michael Poli", "authors": "Michael Poli, Stefano Massaroli, Junyoung Park, Atsushi Yamashita,\n  Hajime Asama, Jinkyoo Park", "title": "Graph Neural Ordinary Differential Equations", "comments": "Accepted [Spotlight] at the AAAI workshop DLGMA20. For the extended\n  version, see \"Continuous-Depth Neural Models for Dynamic Graph Prediction\"", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce the framework of continuous--depth graph neural networks (GNNs).\nGraph neural ordinary differential equations (GDEs) are formalized as the\ncounterpart to GNNs where the input-output relationship is determined by a\ncontinuum of GNN layers, blending discrete topological structures and\ndifferential equations. The proposed framework is shown to be compatible with\nvarious static and autoregressive GNN models. Results prove general\neffectiveness of GDEs: in static settings they offer computational advantages\nby incorporating numerical methods in their forward pass; in dynamic settings,\non the other hand, they are shown to improve performance by exploiting the\ngeometry of the underlying dynamics.\n", "versions": [{"version": "v1", "created": "Mon, 18 Nov 2019 10:46:15 GMT"}, {"version": "v2", "created": "Sat, 15 Feb 2020 06:18:16 GMT"}, {"version": "v3", "created": "Tue, 16 Jun 2020 05:40:32 GMT"}, {"version": "v4", "created": "Tue, 22 Jun 2021 07:40:01 GMT"}], "update_date": "2021-06-23", "authors_parsed": [["Poli", "Michael", ""], ["Massaroli", "Stefano", ""], ["Park", "Junyoung", ""], ["Yamashita", "Atsushi", ""], ["Asama", "Hajime", ""], ["Park", "Jinkyoo", ""]]}, {"id": "1911.07537", "submitter": "Arsany Guirguis", "authors": "El Mahdi El Mhamdi, Rachid Guerraoui, Arsany Guirguis", "title": "Fast Machine Learning with Byzantine Workers and Servers", "comments": "This paper has been merged with arXiv:1905.03853, which has been\n  accepted to appear in the ACM Symposium on Principles of Distributed\n  Computing (PODC) 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Machine Learning (ML) solutions are nowadays distributed and are prone to\nvarious types of component failures, which can be encompassed in so-called\nByzantine behavior. This paper introduces LiuBei, a Byzantine-resilient ML\nalgorithm that does not trust any individual component in the network (neither\nworkers nor servers), nor does it induce additional communication rounds (on\naverage), compared to standard non-Byzantine resilient algorithms. LiuBei\nbuilds upon gradient aggregation rules (GARs) to tolerate a minority of\nByzantine workers. Besides, LiuBei replicates the parameter server on multiple\nmachines instead of trusting it. We introduce a novel filtering mechanism that\nenables workers to filter out replies from Byzantine server replicas without\nrequiring communication with all servers. Such a filtering mechanism is based\non network synchrony, Lipschitz continuity of the loss function, and the GAR\nused to aggregate workers' gradients. We also introduce a protocol,\nscatter/gather, to bound drifts between models on correct servers with a small\nnumber of communication messages. We theoretically prove that LiuBei achieves\nByzantine resilience to both servers and workers and guarantees convergence. We\nbuild LiuBei using TensorFlow, and we show that LiuBei tolerates Byzantine\nbehavior with an accuracy loss of around 5% and around 24% convergence overhead\ncompared to vanilla TensorFlow. We moreover show that the throughput gain of\nLiuBei compared to another state-of-the-art Byzantine-resilient ML algorithm\n(that assumes network asynchrony) is 70%.\n", "versions": [{"version": "v1", "created": "Mon, 18 Nov 2019 10:57:50 GMT"}, {"version": "v2", "created": "Thu, 28 May 2020 17:30:12 GMT"}, {"version": "v3", "created": "Sat, 18 Jul 2020 10:23:05 GMT"}], "update_date": "2020-07-21", "authors_parsed": [["Mhamdi", "El Mahdi El", ""], ["Guerraoui", "Rachid", ""], ["Guirguis", "Arsany", ""]]}, {"id": "1911.07543", "submitter": "Marcela Carvalho", "authors": "Marcela Carvalho and Bertrand Le Saux and Pauline Trouv\\'e-Peloux and\n  Fr\\'ed\\'eric Champagnat and Andr\\'es Almansa", "title": "Multi-Task Learning of Height and Semantics from Aerial Images", "comments": "Published IEEE Geoscience and Remote Sensing Letters. Code\n  https://github.com/marcelampc/mtl_aerial_images", "journal-ref": null, "doi": "10.1109/LGRS.2019.2947783", "report-no": null, "categories": "cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Aerial or satellite imagery is a great source for land surface analysis,\nwhich might yield land use maps or elevation models. In this investigation, we\npresent a neural network framework for learning semantics and local height\ntogether. We show how this joint multi-task learning benefits to each task on\nthe large dataset of the 2018 Data Fusion Contest. Moreover, our framework also\nyields an uncertainty map which allows assessing the prediction of the model.\nCode is available at https://github.com/marcelampc/mtl_aerial_images .\n", "versions": [{"version": "v1", "created": "Mon, 18 Nov 2019 11:08:11 GMT"}], "update_date": "2019-11-19", "authors_parsed": [["Carvalho", "Marcela", ""], ["Saux", "Bertrand Le", ""], ["Trouv\u00e9-Peloux", "Pauline", ""], ["Champagnat", "Fr\u00e9d\u00e9ric", ""], ["Almansa", "Andr\u00e9s", ""]]}, {"id": "1911.07571", "submitter": "Maxim Chernodub", "authors": "M. N. Chernodub, Harold Erbin, I. V. Grishmanovskii, V. A. Goy, A. V.\n  Molochkov", "title": "Casimir effect with machine learning", "comments": "7 pages, 4 figures; minor changes, published version", "journal-ref": "Phys. Rev. Research 2, 033375 (2020)", "doi": "10.1103/PhysRevResearch.2.033375", "report-no": null, "categories": "hep-lat cond-mat.mes-hall cs.LG hep-th", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Vacuum fluctuations of quantum fields between physical objects depend on the\nshapes, positions, and internal composition of the latter. For objects of\narbitrary shapes, even made from idealized materials, the calculation of the\nassociated zero-point (Casimir) energy is an analytically intractable\nchallenge. We propose a new numerical approach to this problem based on\nmachine-learning techniques and illustrate the effectiveness of the method in a\n(2+1) dimensional scalar field theory. The Casimir energy is first calculated\nnumerically using a Monte-Carlo algorithm for a set of the Dirichlet boundaries\nof various shapes. Then, a neural network is trained to compute this energy\ngiven the Dirichlet domain, treating the latter as black-and-white pixelated\nimages. We show that after the learning phase, the neural network is able to\nquickly predict the Casimir energy for new boundaries of general shapes with\nreasonable accuracy.\n", "versions": [{"version": "v1", "created": "Mon, 18 Nov 2019 12:04:33 GMT"}, {"version": "v2", "created": "Sat, 24 Oct 2020 08:01:24 GMT"}], "update_date": "2020-10-27", "authors_parsed": [["Chernodub", "M. N.", ""], ["Erbin", "Harold", ""], ["Grishmanovskii", "I. V.", ""], ["Goy", "V. A.", ""], ["Molochkov", "A. V.", ""]]}, {"id": "1911.07572", "submitter": "Yang Guo", "authors": "Yang Guo, Zhengyuan Liu, Pavitra Krishnswamy, Savitha Ramasamy", "title": "Bayesian Recurrent Framework for Missing Data Imputation and Prediction\n  with Clinical Time Series", "comments": "Machine Learning for Health (ML4H) at NeurIPS 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Real-world clinical time series data sets exhibit a high prevalence of\nmissing values. Hence, there is an increasing interest in missing data\nimputation. Traditional statistical approaches impose constraints on the\ndata-generating process and decouple imputation from prediction. Recent works\npropose recurrent neural network based approaches for missing data imputation\nand prediction with time series data. However, they generate deterministic\noutputs and neglect the inherent uncertainty. In this work, we introduce a\nunified Bayesian recurrent framework for simultaneous imputation and prediction\non time series data sets. We evaluate our approach on two real-world mortality\nprediction tasks using the MIMIC-III and PhysioNet benchmark datasets. We\ndemonstrate strong performance gains over state-of-the-art (SOTA) methods, and\nprovide strategies to use the resulting probability distributions to better\nassess reliability of the imputations and predictions.\n", "versions": [{"version": "v1", "created": "Mon, 18 Nov 2019 12:05:49 GMT"}, {"version": "v2", "created": "Fri, 10 Jan 2020 08:17:24 GMT"}], "update_date": "2020-01-13", "authors_parsed": [["Guo", "Yang", ""], ["Liu", "Zhengyuan", ""], ["Krishnswamy", "Pavitra", ""], ["Ramasamy", "Savitha", ""]]}, {"id": "1911.07574", "submitter": "Wen-Yen Chang", "authors": "Wen-Yen Chang and Wen-Huan Chiang and Shao-Hao Lu and Tingfan Wu and\n  Min Sun", "title": "Bias-Aware Heapified Policy for Active Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.IR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The data efficiency of learning-based algorithms is more and more important\nsince high-quality and clean data is expensive as well as hard to collect. In\norder to achieve high model performance with the least number of samples,\nactive learning is a technique that queries the most important subset of data\nfrom the original dataset. In active learning domain, one of the mainstream\nresearch is the heuristic uncertainty-based method which is useful for the\nlearning-based system. Recently, a few works propose to apply policy\nreinforcement learning (PRL) for querying important data. It seems more general\nthan heuristic uncertainty-based method owing that PRL method depends on data\nfeature which is reliable than human prior. However, there have two problems -\nsample inefficiency of policy learning and overconfidence, when applying PRL on\nactive learning. To be more precise, sample inefficiency of policy learning\noccurs when sampling within a large action space, in the meanwhile, class\nimbalance can lead to the overconfidence. In this paper, we propose a\nbias-aware policy network called Heapified Active Learning (HAL), which\nprevents overconfidence, and improves sample efficiency of policy learning by\nheapified structure without ignoring global inforamtion(overview of the whole\nunlabeled set). In our experiment, HAL outperforms other baseline methods on\nMNIST dataset and duplicated MNIST. Last but not least, we investigate the\ngeneralization of the HAL policy learned on MNIST dataset by directly applying\nit on MNIST-M. We show that the agent can generalize and outperform\ndirectly-learned policy under constrained labeled sets.\n", "versions": [{"version": "v1", "created": "Mon, 18 Nov 2019 12:08:09 GMT"}], "update_date": "2019-11-19", "authors_parsed": [["Chang", "Wen-Yen", ""], ["Chiang", "Wen-Huan", ""], ["Lu", "Shao-Hao", ""], ["Wu", "Tingfan", ""], ["Sun", "Min", ""]]}, {"id": "1911.07590", "submitter": "Stefano Gasperini", "authors": "Stefano Gasperini, Magdalini Paschali, Carsten Hopke, David Wittmann,\n  Nassir Navab", "title": "Signal Clustering with Class-independent Segmentation", "comments": "Under Review for IEEE ICASSP 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG eess.SP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Radar signals have been dramatically increasing in complexity, limiting the\nsource separation ability of traditional approaches. In this paper we propose a\nDeep Learning-based clustering method, which encodes concurrent signals into\nimages, and, for the first time, tackles clustering with image segmentation.\nNovel loss functions are introduced to optimize a Neural Network to separate\nthe input pulses into pure and non-fragmented clusters. Outperforming a variety\nof baselines, the proposed approach is capable of clustering inputs directly\nwith a Neural Network, in an end-to-end fashion.\n", "versions": [{"version": "v1", "created": "Mon, 18 Nov 2019 12:43:57 GMT"}], "update_date": "2020-11-04", "authors_parsed": [["Gasperini", "Stefano", ""], ["Paschali", "Magdalini", ""], ["Hopke", "Carsten", ""], ["Wittmann", "David", ""], ["Navab", "Nassir", ""]]}, {"id": "1911.07596", "submitter": "Anas Barakat", "authors": "Anas Barakat and Pascal Bianchi", "title": "Convergence Analysis of a Momentum Algorithm with Adaptive Step Size for\n  Non Convex Optimization", "comments": "28 pages, 1 figure, published in ACML2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.OC cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Although ADAM is a very popular algorithm for optimizing the weights of\nneural networks, it has been recently shown that it can diverge even in simple\nconvex optimization examples. Several variants of ADAM have been proposed to\ncircumvent this convergence issue. In this work, we study the ADAM algorithm\nfor smooth nonconvex optimization under a boundedness assumption on the\nadaptive learning rate. The bound on the adaptive step size depends on the\nLipschitz constant of the gradient of the objective function and provides safe\ntheoretical adaptive step sizes. Under this boundedness assumption, we show a\nnovel first order convergence rate result in both deterministic and stochastic\ncontexts. Furthermore, we establish convergence rates of the function value\nsequence using the Kurdyka-Lojasiewicz property.\n", "versions": [{"version": "v1", "created": "Mon, 18 Nov 2019 13:00:02 GMT"}, {"version": "v2", "created": "Thu, 24 Sep 2020 12:52:11 GMT"}], "update_date": "2020-09-25", "authors_parsed": [["Barakat", "Anas", ""], ["Bianchi", "Pascal", ""]]}, {"id": "1911.07602", "submitter": "Julian Bock", "authors": "Julian Bock, Robert Krajewski, Tobias Moers, Steffen Runde, Lennart\n  Vater and Lutz Eckstein", "title": "The inD Dataset: A Drone Dataset of Naturalistic Road User Trajectories\n  at German Intersections", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG cs.RO eess.SP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Automated vehicles rely heavily on data-driven methods, especially for\ncomplex urban environments. Large datasets of real world measurement data in\nthe form of road user trajectories are crucial for several tasks like road user\nprediction models or scenario-based safety validation. So far, though, this\ndemand is unmet as no public dataset of urban road user trajectories is\navailable in an appropriate size, quality and variety. By contrast, the highway\ndrone dataset (highD) has recently shown that drones are an efficient method\nfor acquiring naturalistic road user trajectories. Compared to driving studies\nor ground-level infrastructure sensors, one major advantage of using a drone is\nthe possibility to record naturalistic behavior, as road users do not notice\nmeasurements taking place. Due to the ideal viewing angle, an entire\nintersection scenario can be measured with significantly less occlusion than\nwith sensors at ground level. Both the class and the trajectory of each road\nuser can be extracted from the video recordings with high precision using\nstate-of-the-art deep neural networks. Therefore, we propose the creation of a\ncomprehensive, large-scale urban intersection dataset with naturalistic road\nuser behavior using camera-equipped drones as successor of the highD dataset.\nThe resulting dataset contains more than 11500 road users including vehicles,\nbicyclists and pedestrians at intersections in Germany and is called inD. The\ndataset consists of 10 hours of measurement data from four intersections and is\navailable online for non-commercial research at: http://www.inD-dataset.com\n", "versions": [{"version": "v1", "created": "Mon, 18 Nov 2019 13:20:41 GMT"}], "update_date": "2019-11-19", "authors_parsed": [["Bock", "Julian", ""], ["Krajewski", "Robert", ""], ["Moers", "Tobias", ""], ["Runde", "Steffen", ""], ["Vater", "Lennart", ""], ["Eckstein", "Lutz", ""]]}, {"id": "1911.07605", "submitter": "Antonino Sabetta", "authors": "Roc\\`io Cabrera Lozoya, Arnaud Baumann, Antonino Sabetta, Michele\n  Bezzi", "title": "Commit2Vec: Learning Distributed Representations of Code Changes", "comments": "A previous version of this paper had the following title: \"patch2vec:\n  Distributed Representation of Code Changes\"; we updated the title to avoid\n  confusion with another approach, also called patch2vec, that we found in the\n  meantime and that is used in the domain of image processing", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SE cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep learning methods, which have found successful applications in fields\nlike image classification and natural language processing, have recently been\napplied to source code analysis too, due to the enormous amount of freely\navailable source code (e.g., from open-source software repositories).\n  In this work, we elaborate upon a state-of-the-art approach to the\nrepresentation of source code that uses information about its syntactic\nstructure, and we adapt it to represent source changes (i.e., commits). We use\nthis representation to classify security-relevant commits.\n  Because our method uses transfer learning (that is, we train a network on a\n\"pretext task\" for which abundant labeled data is available, and then we use\nsuch network for the target task of commit classification, for which fewer\nlabeled instances are available), we studied the impact of pre-training the\nnetwork using two different pretext tasks versus a randomly initialized model.\n  Our results indicate that representations that leverage the structural\ninformation obtained through code syntax outperform token-based\nrepresentations. Furthermore, the performance metrics obtained when\npre-training on a loosely related pretext task with a very large dataset\n($>10^6$ samples) were surpassed when pretraining on a smaller dataset ($>10^4$\nsamples) but for a pretext task that is more closely related to the target\ntask.\n", "versions": [{"version": "v1", "created": "Mon, 18 Nov 2019 13:23:57 GMT"}, {"version": "v2", "created": "Tue, 19 Nov 2019 15:02:03 GMT"}, {"version": "v3", "created": "Wed, 20 Nov 2019 09:55:48 GMT"}], "update_date": "2019-11-21", "authors_parsed": [["Lozoya", "Roc\u00eco Cabrera", ""], ["Baumann", "Arnaud", ""], ["Sabetta", "Antonino", ""], ["Bezzi", "Michele", ""]]}, {"id": "1911.07608", "submitter": "Ali Asgher Mansoor Habiby", "authors": "Ali Asgher Mansoor Habiby and Ahamed Thoppu", "title": "Application of Reinforcement Learning for 5G Scheduling Parameter\n  Optimization", "comments": "7 pages, 11 figures. Complete experiment conducted on a Live 5G\n  Network and live 5G site", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  RF Network parametric optimization requires a wealth of experience and\nknowledge to achieve the optimal balance between coverage, capacity, system\nefficiency and customer experience from the telecom sites serving the users.\nWith 5G, the complications of Air interface scheduling have increased due to\nthe usage of massive MIMO, beamforming and introduction of higher modulation\nschemes with varying numerologies. In this work, we tune a machine learning\nmodel to \"learn\" the best combination of parameters for a given traffic profile\nusing Cross Entropy Method Reinforcement Learning and compare these with RF\nSubject Matter Expert \"SME\" recommendations. This work is aimed towards\nautomatic parameter tuning and feature optimization by acting as a Self\nOrganizing Network module\n", "versions": [{"version": "v1", "created": "Mon, 21 Oct 2019 16:05:53 GMT"}], "update_date": "2019-11-19", "authors_parsed": [["Habiby", "Ali Asgher Mansoor", ""], ["Thoppu", "Ahamed", ""]]}, {"id": "1911.07613", "submitter": "Md Saiful Islam", "authors": "Aisha Khatun, Anisur Rahman, Hemayet Ahmed Chowdhury, Md. Saiful Islam\n  and Ayesha Tasnim", "title": "A Subword Level Language Model for Bangla Language", "comments": "12 pages, Conference Paper", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Language models are at the core of natural language processing. The ability\nto represent natural language gives rise to its applications in numerous NLP\ntasks including text classification, summarization, and translation. Research\nin this area is very limited in Bangla due to the scarcity of resources, except\nfor some count-based models and very recent neural language models being\nproposed, which are all based on words and limited in practical tasks due to\ntheir high perplexity. This paper attempts to approach this issue of perplexity\nand proposes a subword level neural language model with the AWD-LSTM\narchitecture and various other techniques suitable for training in Bangla\nlanguage. The model is trained on a corpus of Bangla newspaper articles of an\nappreciable size consisting of more than 28.5 million word tokens. The\nperformance comparison with various other models depicts the significant\nreduction in perplexity the proposed model provides, reaching as low as 39.84,\nin just 20 epochs.\n", "versions": [{"version": "v1", "created": "Fri, 15 Nov 2019 08:22:33 GMT"}], "update_date": "2019-11-19", "authors_parsed": [["Khatun", "Aisha", ""], ["Rahman", "Anisur", ""], ["Chowdhury", "Hemayet Ahmed", ""], ["Islam", "Md. Saiful", ""], ["Tasnim", "Ayesha", ""]]}, {"id": "1911.07615", "submitter": "Jun Li", "authors": "Jun Li, Xiaoman Shen, Lei Chen and Jiajia Chen", "title": "Bandwidth Slicing to Boost Federated Learning in Edge Computing", "comments": "Conference,3 pages, 3 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI cs.DC cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Bandwidth slicing is introduced to support federated learning in edge\ncomputing to assure low communication delay for training traffic. Results\nreveal that bandwidth slicing significantly improves training efficiency while\nachieving good learning accuracy.\n", "versions": [{"version": "v1", "created": "Thu, 24 Oct 2019 07:49:22 GMT"}], "update_date": "2019-11-19", "authors_parsed": [["Li", "Jun", ""], ["Shen", "Xiaoman", ""], ["Chen", "Lei", ""], ["Chen", "Jiajia", ""]]}, {"id": "1911.07625", "submitter": "Ahmed Ben Said", "authors": "Ahmed Ben Said and Abdelkarim Erradi", "title": "Deep-Gap: A deep learning framework for forecasting crowdsourcing\n  supply-demand gap based on imaging time series and residual learning", "comments": "Accepted at CloudCom 2019 Conference", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI cs.HC cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Mobile crowdsourcing has become easier thanks to the widespread of\nsmartphones capable of seamlessly collecting and pushing the desired data to\ncloud services. However, the success of mobile crowdsourcing relies on\nbalancing the supply and demand by first accurately forecasting spatially and\ntemporally the supply-demand gap, and then providing efficient incentives to\nencourage participant movements to maintain the desired balance. In this paper,\nwe propose Deep-Gap, a deep learning approach based on residual learning to\npredict the gap between mobile crowdsourced service supply and demand at a\ngiven time and space. The prediction can drive the incentive model to achieve a\ngeographically balanced service coverage in order to avoid the case where some\nareas are over-supplied while other areas are under-supplied. This allows\nanticipating the supply-demand gap and redirecting crowdsourced service\nproviders towards target areas. Deep-Gap relies on historical supply-demand\ntime series data as well as available external data such as weather conditions\nand day type (e.g., weekday, weekend, holiday). First, we roll and encode the\ntime series of supply-demand as images using the Gramian Angular Summation\nField (GASF), Gramian Angular Difference Field (GADF) and the Recurrence Plot\n(REC). These images are then used to train deep Convolutional Neural Networks\n(CNN) to extract the low and high-level features and forecast the crowdsourced\nservices gap. We conduct comprehensive comparative study by establishing two\nsupply-demand gap forecasting scenarios: with and without external data.\nCompared to state-of-art approaches, Deep-Gap achieves the lowest forecasting\nerrors in both scenarios.\n", "versions": [{"version": "v1", "created": "Sat, 2 Nov 2019 17:32:39 GMT"}], "update_date": "2019-11-19", "authors_parsed": [["Said", "Ahmed Ben", ""], ["Erradi", "Abdelkarim", ""]]}, {"id": "1911.07626", "submitter": "Tong Zhang", "authors": "Cong Fang and Yihong Gu and Weizhong Zhang and Tong Zhang", "title": "Convex Formulation of Overparameterized Deep Neural Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Analysis of over-parameterized neural networks has drawn significant\nattention in recentyears. It was shown that such systems behave like convex\nsystems under various restrictedsettings, such as for two-level neural\nnetworks, and when learning is only restricted locally inthe so-called neural\ntangent kernel space around specialized initializations. However, there areno\ntheoretical techniques that can analyze fully trained deep neural networks\nencountered inpractice. This paper solves this fundamental problem by\ninvestigating such overparameterizeddeep neural networks when fully trained. We\ngeneralize a new technique called neural feature repopulation, originally\nintroduced in (Fang et al., 2019a) for two-level neural networks, to analyze\ndeep neural networks. It is shown that under suitable representations,\noverparameterized deep neural networks are inherently convex, and when\noptimized, the system can learn effective features suitable for the underlying\nlearning task under mild conditions. This new analysis is consistent with\nempirical observations that deep neural networks are capable of learning\nefficient feature representations. Therefore, the highly unexpected result of\nthis paper can satisfactorily explain the practical success of deep neural\nnetworks. Empirical studies confirm that predictions of our theory are\nconsistent with results observed in practice.\n", "versions": [{"version": "v1", "created": "Mon, 18 Nov 2019 13:42:04 GMT"}], "update_date": "2019-11-19", "authors_parsed": [["Fang", "Cong", ""], ["Gu", "Yihong", ""], ["Zhang", "Weizhong", ""], ["Zhang", "Tong", ""]]}, {"id": "1911.07629", "submitter": "Atul Sahay", "authors": "Atul Sahay, Smita Gholkar, Kavi Arya", "title": "Selection-based Question Answering of an MOOC", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  e-Yantra Robotics Competition (eYRC) is a unique Robotics Competition hosted\nby IIT Bombay that is actually an Embedded Systems and Robotics MOOC.\nRegistrations have been growing exponentially in each year from 4500 in 2012 to\nover 34000 in 2019. In this 5-month long competition students learn complex\nskills under severe time pressure and have access to a discussion forum to post\ndoubts about the learning material. Responding to questions in real-time is a\nchallenge for project staff. Here, we illustrate the advantage of Deep Learning\nfor real-time question answering in the eYRC discussion forum. We illustrate\nthe advantage of Transformer based contextual embedding mechanisms such as\nBidirectional Encoder Representation From Transformer (BERT) over word\nembedding mechanisms such as Word2Vec. We propose a weighted similarity metric\nas a measure of matching and find it more reliable than Content-Content or\nTitle-Title similarities alone. The automation of replying to questions has\nbrought the turn around response time(TART) down from a minimum of 21 mins to a\nminimum of 0.3 secs.\n", "versions": [{"version": "v1", "created": "Fri, 15 Nov 2019 09:20:32 GMT"}], "update_date": "2019-11-19", "authors_parsed": [["Sahay", "Atul", ""], ["Gholkar", "Smita", ""], ["Arya", "Kavi", ""]]}, {"id": "1911.07630", "submitter": "Sandeep Madireddy", "authors": "Peihong Jiang, Hieu Doan, Sandeep Madireddy, Rajeev Surendran Assary,\n  Prasanna Balaprakash", "title": "Value-Added Chemical Discovery Using Reinforcement Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.OH cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Computer-assisted synthesis planning aims to help chemists find better\nreaction pathways faster. Finding viable and short pathways from sugar\nmolecules to value-added chemicals can be modeled as a retrosynthesis planning\nproblem with a catalyst allowed. This is a crucial step in efficient biomass\nconversion. The traditional computational chemistry approach to identifying\npossible reaction pathways involves computing the reaction energies of hundreds\nof intermediates, which is a critical bottleneck in silico reaction discovery.\nDeep reinforcement learning has shown in other domains that a well-trained\nagent with little or no prior human knowledge can surpass human performance.\nWhile some effort has been made to adapt machine learning techniques to the\nretrosynthesis planning problem, value-added chemical discovery presents unique\nchallenges. Specifically, the reaction can occur in several different sites in\na molecule, a subtle case that has never been treated in previous works. With a\nmore versatile formulation of the problem as a Markov decision process, we\naddress the problem using deep reinforcement learning techniques and present\npromising preliminary results.\n", "versions": [{"version": "v1", "created": "Sun, 10 Nov 2019 07:36:37 GMT"}], "update_date": "2019-11-19", "authors_parsed": [["Jiang", "Peihong", ""], ["Doan", "Hieu", ""], ["Madireddy", "Sandeep", ""], ["Assary", "Rajeev Surendran", ""], ["Balaprakash", "Prasanna", ""]]}, {"id": "1911.07643", "submitter": "Miguel Suau", "authors": "Miguel Suau, Jinke He, Elena Congeduti, Rolf A.N. Starre, Aleksander\n  Czechowski, Frans A. Oliehoek", "title": "Influence-aware Memory Architectures for Deep Reinforcement Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Due to its perceptual limitations, an agent may have too little information\nabout the state of the environment to act optimally. In such cases, it is\nimportant to keep track of the observation history to uncover hidden state.\nRecent deep reinforcement learning methods use recurrent neural networks (RNN)\nto memorize past observations. However, these models are expensive to train and\nhave convergence difficulties, especially when dealing with high dimensional\ninput spaces. In this paper, we propose influence-aware memory (IAM), a\ntheoretically inspired memory architecture that tries to alleviate the training\ndifficulties by restricting the input of the recurrent layers to those\nvariables that influence the hidden state information. Moreover, as opposed to\nstandard RNNs, in which every piece of information used for estimating Q values\nis inevitably fed back into the network for the next prediction, our model\nallows information to flow without being necessarily stored in the RNN's\ninternal memory. Results indicate that, by letting the recurrent layers focus\non a small fraction of the observation variables while processing the rest of\nthe information with a feedforward neural network, we can outperform standard\nrecurrent architectures both in training speed and policy performance. This\napproach also reduces runtime and obtains better scores than methods that stack\nmultiple observations to remove partial observability.\n", "versions": [{"version": "v1", "created": "Mon, 18 Nov 2019 13:54:25 GMT"}, {"version": "v2", "created": "Thu, 21 Nov 2019 20:50:00 GMT"}, {"version": "v3", "created": "Tue, 18 Aug 2020 09:00:18 GMT"}, {"version": "v4", "created": "Wed, 17 Feb 2021 18:26:14 GMT"}], "update_date": "2021-02-18", "authors_parsed": [["Suau", "Miguel", ""], ["He", "Jinke", ""], ["Congeduti", "Elena", ""], ["Starre", "Rolf A. N.", ""], ["Czechowski", "Aleksander", ""], ["Oliehoek", "Frans A.", ""]]}, {"id": "1911.07644", "submitter": "Yan Zhang", "authors": "Yan Zhang, Steve Farrell, Michael Crowley, Lee Makowski, Jack Deslippe", "title": "A Molecular-MNIST Dataset for Machine Learning Study on Diffraction\n  Imaging and Microscopy", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.IV cs.CV cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  An image dataset of 10 different size molecules, where each molecule has\n2,000 structural variants, is generated from the 2D cross-sectional projection\nof Molecular Dynamics trajectories. The purpose of this dataset is to provide a\nbenchmark dataset for the increasing need of machine learning, deep learning\nand image processing on the study of scattering, imaging and microscopy.\n", "versions": [{"version": "v1", "created": "Fri, 15 Nov 2019 18:48:02 GMT"}], "update_date": "2019-11-19", "authors_parsed": [["Zhang", "Yan", ""], ["Farrell", "Steve", ""], ["Crowley", "Michael", ""], ["Makowski", "Lee", ""], ["Deslippe", "Jack", ""]]}, {"id": "1911.07652", "submitter": "Linara Adilova", "authors": "Linara Adilova, Julia Rosenzweig, Michael Kamp", "title": "Information-Theoretic Perspective of Federated Learning", "comments": "5 pages, 8 figures Workshop on Information Theory and Machine\n  Learning, 33rd Conference on Neural Information Processing Systems (NeurIPS\n  2019), Vancouver, Canada", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.DC cs.IT math.IT stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  An approach to distributed machine learning is to train models on local\ndatasets and aggregate these models into a single, stronger model. A popular\ninstance of this form of parallelization is federated learning, where the nodes\nperiodically send their local models to a coordinator that aggregates them and\nredistributes the aggregation back to continue training with it. The most\nfrequently used form of aggregation is averaging the model parameters, e.g.,\nthe weights of a neural network. However, due to the non-convexity of the loss\nsurface of neural networks, averaging can lead to detrimental effects and it\nremains an open question under which conditions averaging is beneficial. In\nthis paper, we study this problem from the perspective of information theory:\nWe measure the mutual information between representation and inputs as well as\nrepresentation and labels in local models and compare it to the respective\ninformation contained in the representation of the averaged model. Our\nempirical results confirm previous observations about the practical usefulness\nof averaging for neural networks, even if local dataset distributions vary\nstrongly. Furthermore, we obtain more insights about the impact of the\naggregation frequency on the information flow and thus on the success of\ndistributed learning. These insights will be helpful both in improving the\ncurrent synchronization process and in further understanding the effects of\nmodel aggregation.\n", "versions": [{"version": "v1", "created": "Fri, 15 Nov 2019 13:51:27 GMT"}], "update_date": "2019-11-19", "authors_parsed": [["Adilova", "Linara", ""], ["Rosenzweig", "Julia", ""], ["Kamp", "Michael", ""]]}, {"id": "1911.07654", "submitter": "Alena Harley", "authors": "Alena Harley", "title": "Deep Discriminative Fine-Tuning for Cancer Type Classification", "comments": "4 pages, 1 figure, ML4H NeurIPS Workshop", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.GN cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Determining the primary site of origin for metastatic tumors is one of the\nopen problems in cancer care because the efficacy of treatment often depends on\nthe cancer tissue of origin. Classification methods that can leverage tumor\ngenomic data and predict the site of origin are therefore of great value.\nBecause tumor DNA point mutation data is very sparse, only limited accuracy\n(64.5% for 12 tumor classes) was previously demonstrated by methods that rely\non point mutations as features (1). Tumor classification accuracy can be\ngreatly improved (to over 90% for 33 classes) by relying on gene expression\ndata (2). However, this additional data is often not readily available in\nclinical setting, because point mutations are better profiled and targeted by\nclinical mutational profiling.\n  Here we sought to develop an accurate deep transfer learning and fine-tuning\nmethod for tumor sub-type classification, where predicted class is indicative\nof the primary site of origin. Our method significantly outperforms the\nstate-of-the-art for tumor classification using DNA point mutations, reducing\nthe error by more than 30% at the same time discriminating over many more\nclasses on The Cancer Genome Atlas (TCGA) dataset. Using our method, we achieve\nstate-of-the-art tumor type classification accuracy of 78.3% for 29 tumor\nclasses relying on DNA point mutations in the tumor only.\n", "versions": [{"version": "v1", "created": "Fri, 15 Nov 2019 07:30:17 GMT"}], "update_date": "2019-11-19", "authors_parsed": [["Harley", "Alena", ""]]}, {"id": "1911.07656", "submitter": "Xiangzhu Meng", "authors": "Xiangzhu Meng, Huibing Wang, Lin Feng", "title": "The Similarity-Consensus Regularized Multi-view Learning for Dimension\n  Reduction", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  During the last decades, learning a low-dimensional space with discriminative\ninformation for dimension reduction (DR) has gained a surge of interest.\nHowever, it's not accessible for these DR methods to achieve satisfactory\nperformance when facing the features from multiple views. In multi-view\nlearning problems, one instance can be represented by multiple heterogeneous\nfeatures, which are highly related but sometimes look different from each\nother. In addition, correlations between features from multiple views always\nvary greatly, which challenges the capability of multi-view learning methods.\nConsequently, constructing a multi-view learning framework with generalization\nand scalability, which could take advantage of multi-view information as much\nas possible, is extremely necessary but challenging. To implement the above\ntarget, this paper proposes a novel multi-view learning framework based on\nsimilarity consensus, which makes full use of correlations among multi-view\nfeatures while considering the scalability and robustness of the framework. It\naims to straightforwardly extend those existing DR methods into multi-view\nlearning domain by preserving the similarity between different views to capture\nthe low-dimensional embedding. Two schemes based on pairwise-consensus and\ncentroid-consensus are separately proposed to force multiple views to learn\nfrom each other and then an iterative alternating strategy is developed to\nobtain the optimal solution. The proposed method is evaluated on 5 benchmark\ndatasets and comprehensive experiments show that our proposed multi-view\nframework can yield comparable and promising performance with previous\napproaches proposed in recent literatures.\n", "versions": [{"version": "v1", "created": "Fri, 15 Nov 2019 02:41:46 GMT"}], "update_date": "2019-11-19", "authors_parsed": [["Meng", "Xiangzhu", ""], ["Wang", "Huibing", ""], ["Feng", "Lin", ""]]}, {"id": "1911.07658", "submitter": "Michael Kissner", "authors": "Michael Kissner", "title": "Hacking Neural Networks: A Short Introduction", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A large chunk of research on the security issues of neural networks is\nfocused on adversarial attacks. However, there exists a vast sea of simpler\nattacks one can perform both against and with neural networks. In this article,\nwe give a quick introduction on how deep learning in security works and explore\nthe basic methods of exploitation, but also look at the offensive capabilities\ndeep learning enabled tools provide. All presented attacks, such as\nbackdooring, GPU-based buffer overflows or automated bug hunting, are\naccompanied by short open-source exercises for anyone to try out.\n", "versions": [{"version": "v1", "created": "Mon, 18 Nov 2019 14:15:58 GMT"}, {"version": "v2", "created": "Sun, 1 Dec 2019 12:35:02 GMT"}], "update_date": "2019-12-03", "authors_parsed": [["Kissner", "Michael", ""]]}, {"id": "1911.07661", "submitter": "Toshihiko Matsuura", "authors": "Toshihiko Matsuura and Tatsuya Harada", "title": "Domain Generalization Using a Mixture of Multiple Latent Domains", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  When domains, which represent underlying data distributions, vary during\ntraining and testing processes, deep neural networks suffer a drop in their\nperformance. Domain generalization allows improvements in the generalization\nperformance for unseen target domains by using multiple source domains.\nConventional methods assume that the domain to which each sample belongs is\nknown in training. However, many datasets, such as those collected via web\ncrawling, contain a mixture of multiple latent domains, in which the domain of\neach sample is unknown. This paper introduces domain generalization using a\nmixture of multiple latent domains as a novel and more realistic scenario,\nwhere we try to train a domain-generalized model without using domain labels.\nTo address this scenario, we propose a method that iteratively divides samples\ninto latent domains via clustering, and which trains the domain-invariant\nfeature extractor shared among the divided latent domains via adversarial\nlearning. We assume that the latent domain of images is reflected in their\nstyle, and thus, utilize style features for clustering. By using these\nfeatures, our proposed method successfully discovers latent domains and\nachieves domain generalization even if the domain labels are not given.\nExperiments show that our proposed method can train a domain-generalized model\nwithout using domain labels. Moreover, it outperforms conventional domain\ngeneralization methods, including those that utilize domain labels.\n", "versions": [{"version": "v1", "created": "Mon, 18 Nov 2019 14:31:36 GMT"}], "update_date": "2019-11-19", "authors_parsed": [["Matsuura", "Toshihiko", ""], ["Harada", "Tatsuya", ""]]}, {"id": "1911.07662", "submitter": "Haiping Huang", "authors": "Haiping Huang", "title": "Variational mean-field theory for training restricted Boltzmann machines\n  with binary synapses", "comments": "9 pages, 2 figures, a mean-field framework proposed for unsupervised\n  learning in RBM with discrete synapses, which was previously out of reach", "journal-ref": "Phys. Rev. E 102, 030301 (2020)", "doi": "10.1103/PhysRevE.102.030301", "report-no": null, "categories": "stat.ML cond-mat.dis-nn cs.LG cs.NE q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Unsupervised learning requiring only raw data is not only a fundamental\nfunction of the cerebral cortex, but also a foundation for a next generation of\nartificial neural networks. However, a unified theoretical framework to treat\nsensory inputs, synapses and neural activity together is still lacking. The\ncomputational obstacle originates from the discrete nature of synapses, and\ncomplex interactions among these three essential elements of learning. Here, we\npropose a variational mean-field theory in which the distribution of synaptic\nweights is considered. The unsupervised learning can then be decomposed into\ntwo intertwined steps: a maximization step is carried out as a gradient ascent\nof the lower-bound on the data log-likelihood, in which the synaptic weight\ndistribution is determined by updating variational parameters, and an\nexpectation step is carried out as a message passing procedure on an equivalent\nor dual neural network whose parameter is specified by the variational\nparameters of the weight distribution. Therefore, our framework provides\ninsights on how data (or sensory inputs), synapses and neural activities\ninteract with each other to achieve the goal of extracting statistical\nregularities in sensory inputs. This variational framework is verified in\nrestricted Boltzmann machines with planted synaptic weights and\nhandwritten-digits learning.\n", "versions": [{"version": "v1", "created": "Mon, 11 Nov 2019 02:12:08 GMT"}, {"version": "v2", "created": "Tue, 18 Aug 2020 03:58:24 GMT"}], "update_date": "2020-09-09", "authors_parsed": [["Huang", "Haiping", ""]]}, {"id": "1911.07675", "submitter": "Yilun Jin", "authors": "Yilun Jin, Guojie Song, Chuan Shi", "title": "GraLSP: Graph Neural Networks with Local Structural Patterns", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  It is not until recently that graph neural networks (GNNs) are adopted to\nperform graph representation learning, among which, those based on the\naggregation of features within the neighborhood of a node achieved great\nsuccess. However, despite such achievements, GNNs illustrate defects in\nidentifying some common structural patterns which, unfortunately, play\nsignificant roles in various network phenomena. In this paper, we propose\nGraLSP, a GNN framework which explicitly incorporates local structural patterns\ninto the neighborhood aggregation through random anonymous walks. Specifically,\nwe capture local graph structures via random anonymous walks, powerful and\nflexible tools that represent structural patterns. The walks are then fed into\nthe feature aggregation, where we design various mechanisms to address the\nimpact of structural features, including adaptive receptive radius, attention\nand amplification. In addition, we design objectives that capture similarities\nbetween structures and are optimized jointly with node proximity objectives.\nWith the adequate leverage of structural patterns, our model is able to\noutperform competitive counterparts in various prediction tasks in multiple\ndatasets.\n", "versions": [{"version": "v1", "created": "Mon, 18 Nov 2019 14:53:41 GMT"}, {"version": "v2", "created": "Sat, 7 Dec 2019 08:57:46 GMT"}], "update_date": "2019-12-10", "authors_parsed": [["Jin", "Yilun", ""], ["Song", "Guojie", ""], ["Shi", "Chuan", ""]]}, {"id": "1911.07676", "submitter": "Tor Lattimore", "authors": "Tor Lattimore and Csaba Szepesvari and Gellert Weisz", "title": "Learning with Good Feature Representations in Bandits and in RL with a\n  Generative Model", "comments": "13 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The construction by Du et al. (2019) implies that even if a learner is given\nlinear features in $\\mathbb R^d$ that approximate the rewards in a bandit with\na uniform error of $\\epsilon$, then searching for an action that is optimal up\nto $O(\\epsilon)$ requires examining essentially all actions. We use the\nKiefer-Wolfowitz theorem to prove a positive result that by checking only a few\nactions, a learner can always find an action that is suboptimal with an error\nof at most $O(\\epsilon \\sqrt{d})$. Thus, features are useful when the\napproximation error is small relative to the dimensionality of the features.\nThe idea is applied to stochastic bandits and reinforcement learning with a\ngenerative model where the learner has access to $d$-dimensional linear\nfeatures that approximate the action-value functions for all policies to an\naccuracy of $\\epsilon$. For linear bandits, we prove a bound on the regret of\norder $\\sqrt{dn \\log(k)} + \\epsilon n \\sqrt{d} \\log(n)$ with $k$ the number of\nactions and $n$ the horizon. For RL we show that approximate policy iteration\ncan learn a policy that is optimal up to an additive error of order $\\epsilon\n\\sqrt{d}/(1 - \\gamma)^2$ and using $d/(\\epsilon^2(1 - \\gamma)^4)$ samples from\na generative model. These bounds are independent of the finer details of the\nfeatures. We also investigate how the structure of the feature set impacts the\ntradeoff between sample complexity and estimation error.\n", "versions": [{"version": "v1", "created": "Mon, 18 Nov 2019 14:55:50 GMT"}, {"version": "v2", "created": "Wed, 19 Feb 2020 15:36:51 GMT"}], "update_date": "2020-02-20", "authors_parsed": [["Lattimore", "Tor", ""], ["Szepesvari", "Csaba", ""], ["Weisz", "Gellert", ""]]}, {"id": "1911.07679", "submitter": "Josie Williams", "authors": "Josie Williams and Narges Razavian", "title": "Towards Quantification of Bias in Machine Learning for Healthcare: A\n  Case Study of Renal Failure Prediction", "comments": "Accepted at Fairness in Machine Learning in Health workshop at\n  NeurIPS 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.AP stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  As machine learning (ML) models, trained on real-world datasets, become\ncommon practice, it is critical to measure and quantify their potential biases.\nIn this paper, we focus on renal failure and compare a commonly used\ntraditional risk score, Tangri, with a more powerful machine learning model,\nwhich has access to a larger variable set and trained on 1.6 million patients'\nEHR data. We will compare and discuss the generalization and applicability of\nthese two models, in an attempt to quantify biases of status quo clinical\npractice, compared to ML-driven models.\n", "versions": [{"version": "v1", "created": "Mon, 18 Nov 2019 15:04:31 GMT"}], "update_date": "2019-11-19", "authors_parsed": [["Williams", "Josie", ""], ["Razavian", "Narges", ""]]}, {"id": "1911.07682", "submitter": "Zhaohui Che", "authors": "Zhaohui Che and Ali Borji and Guangtao Zhai and Suiyi Ling and Jing Li\n  and Patrick Le Callet", "title": "A New Ensemble Adversarial Attack Powered by Long-term Gradient Memories", "comments": "Accepted by AAAI2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep neural networks are vulnerable to adversarial attacks.\n", "versions": [{"version": "v1", "created": "Mon, 18 Nov 2019 15:05:09 GMT"}], "update_date": "2019-11-19", "authors_parsed": [["Che", "Zhaohui", ""], ["Borji", "Ali", ""], ["Zhai", "Guangtao", ""], ["Ling", "Suiyi", ""], ["Li", "Jing", ""], ["Callet", "Patrick Le", ""]]}, {"id": "1911.07683", "submitter": "Paolo Notaro", "authors": "Paolo Notaro, Magdalini Paschali, Carsten Hopke, David Wittmann,\n  Nassir Navab", "title": "Radar Emitter Classification with Attribute-specific Recurrent Neural\n  Networks", "comments": "Submitted for review to IEEE ICASSP 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.SP cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Radar pulse streams exhibit increasingly complex temporal patterns and can no\nlonger rely on a purely value-based analysis of the pulse attributes for the\npurpose of emitter classification. In this paper, we employ Recurrent Neural\nNetworks (RNNs) to efficiently model and exploit the temporal dependencies\npresent inside pulse streams. With the purpose of enhancing the network\nprediction capability, we introduce two novel techniques: a per-sequence\nnormalization, able to mine the useful temporal patterns; and\nattribute-specific RNN processing, capable of processing the extracted\ninformation effectively. The new techniques are evaluated with an ablation\nstudy and the proposed solution is compared to previous Deep Learning (DL)\napproaches. Finally, a comparative study on the robustness of the same\napproaches is conducted and its results are presented.\n", "versions": [{"version": "v1", "created": "Mon, 18 Nov 2019 15:06:46 GMT"}, {"version": "v2", "created": "Tue, 19 Nov 2019 17:20:38 GMT"}], "update_date": "2019-11-20", "authors_parsed": [["Notaro", "Paolo", ""], ["Paschali", "Magdalini", ""], ["Hopke", "Carsten", ""], ["Wittmann", "David", ""], ["Navab", "Nassir", ""]]}, {"id": "1911.07693", "submitter": "Lu Bai", "authors": "Lu Bai, Yew-Soon Ong, Tiantian He, Abhishek Gupta", "title": "A Multi-Task Gradient Descent Method for Multi-Label Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Multi-label learning studies the problem where an instance is associated with\na set of labels. By treating single-label learning problem as one task, the\nmulti-label learning problem can be casted as solving multiple related tasks\nsimultaneously. In this paper, we propose a novel Multi-task Gradient Descent\n(MGD) algorithm to solve a group of related tasks simultaneously. In the\nproposed algorithm, each task minimizes its individual cost function using\nreformative gradient descent, where the relations among the tasks are\nfacilitated through effectively transferring model parameter values across\nmultiple tasks. Theoretical analysis shows that the proposed algorithm is\nconvergent with a proper transfer mechanism. Compared with the existing\napproaches, MGD is easy to implement, has less requirement on the training\nmodel, can achieve seamless asymmetric transformation such that negative\ntransfer is mitigated, and can benefit from parallel computing when the number\nof tasks is large. The competitive experimental results on multi-label learning\ndatasets validate the effectiveness of the proposed algorithm.\n", "versions": [{"version": "v1", "created": "Mon, 18 Nov 2019 15:17:33 GMT"}, {"version": "v2", "created": "Tue, 19 Nov 2019 14:53:08 GMT"}], "update_date": "2019-11-20", "authors_parsed": [["Bai", "Lu", ""], ["Ong", "Yew-Soon", ""], ["He", "Tiantian", ""], ["Gupta", "Abhishek", ""]]}, {"id": "1911.07698", "submitter": "Maurizio Ferrari Dacrema", "authors": "Maurizio Ferrari Dacrema and Simone Boglio and Paolo Cremonesi and\n  Dietmar Jannach", "title": "A Troubling Analysis of Reproducibility and Progress in Recommender\n  Systems Research", "comments": "Source code and full results available at:\n  https://github.com/MaurizioFD/RecSys2019_DeepLearning_Evaluation", "journal-ref": "ACM Transactions on Information Systems 39, 2, Article 20 (January\n  2021), 49 pages", "doi": "10.1145/3434185", "report-no": null, "categories": "cs.IR cs.LG cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The design of algorithms that generate personalized ranked item lists is a\ncentral topic of research in the field of recommender systems. In the past few\nyears, in particular, approaches based on deep learning (neural) techniques\nhave become dominant in the literature. For all of them, substantial progress\nover the state-of-the-art is claimed. However, indications exist of certain\nproblems in today's research practice, e.g., with respect to the choice and\noptimization of the baselines used for comparison, raising questions about the\npublished claims. In order to obtain a better understanding of the actual\nprogress, we have tried to reproduce recent results in the area of neural\nrecommendation approaches based on collaborative filtering. The worrying\noutcome of the analysis of these recent works-all were published at prestigious\nscientific conferences between 2015 and 2018-is that 11 out of the 12\nreproducible neural approaches can be outperformed by conceptually simple\nmethods, e.g., based on the nearest-neighbor heuristics. None of the\ncomputationally complex neural methods was actually consistently better than\nalready existing learning-based techniques, e.g., using matrix factorization or\nlinear models. In our analysis, we discuss common issues in today's research\npractice, which, despite the many papers that are published on the topic, have\napparently led the field to a certain level of stagnation.\n", "versions": [{"version": "v1", "created": "Mon, 18 Nov 2019 15:27:09 GMT"}, {"version": "v2", "created": "Thu, 27 Aug 2020 10:18:34 GMT"}, {"version": "v3", "created": "Thu, 7 Jan 2021 14:09:01 GMT"}], "update_date": "2021-01-08", "authors_parsed": [["Dacrema", "Maurizio Ferrari", ""], ["Boglio", "Simone", ""], ["Cremonesi", "Paolo", ""], ["Jannach", "Dietmar", ""]]}, {"id": "1911.07702", "submitter": "Lev Utkin", "authors": "Lev V. Utkin, Maxim S. Kovalev, Ernest M. Kasimov", "title": "An explanation method for Siamese neural networks", "comments": "International Scientific Conference Telecommunications, Computing and\n  Control (TELECCON-2019)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A new method for explaining the Siamese neural network is proposed. It uses\nthe following main ideas. First, the explained feature vector is compared with\nthe prototype of the corresponding class computed at the embedding level (the\nSiamese neural network output). The important features at this level are\ndetermined as features which are close to the same features of the prototype.\nSecond, an autoencoder is trained in a special way in order to take into\naccount the embedding level of the Si-amese network, and its decoder part is\nused for reconstructing input data with the corresponding changes. Numerical\nexperiments with the well-known dataset MNIST illustrate the propose method.\n", "versions": [{"version": "v1", "created": "Mon, 18 Nov 2019 15:30:36 GMT"}], "update_date": "2019-11-19", "authors_parsed": [["Utkin", "Lev V.", ""], ["Kovalev", "Maxim S.", ""], ["Kasimov", "Ernest M.", ""]]}, {"id": "1911.07710", "submitter": "Zilong Zhao", "authors": "Zilong Zhao, Sophie Cerf, Bogdan Robu and Nicolas Marchand", "title": "Feedback Control for Online Training of Neural Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Convolutional neural networks (CNNs) are commonly used for image\nclassification tasks, raising the challenge of their application on data flows.\nDuring their training, adaptation is often performed by tuning the learning\nrate. Usual learning rate strategies are time-based i.e. monotonously\ndecreasing. In this paper, we advocate switching to a performance-based\nadaptation, in order to improve the learning efficiency. We present E\n(Exponential)/PD (Proportional Derivative)-Control, a conditional learning rate\nstrategy that combines a feedback PD controller based on the CNN loss function,\nwith an exponential control signal to smartly boost the learning and adapt the\nPD parameters. Stability proof is provided as well as an experimental\nevaluation using two state of the art image datasets (CIFAR-10 and\nFashion-MNIST). Results show better performances than the related works (faster\nnetwork accuracy growth reaching higher levels) and robustness of the\nE/PD-Control regarding its parametrization.\n", "versions": [{"version": "v1", "created": "Mon, 18 Nov 2019 15:40:06 GMT"}], "update_date": "2019-11-19", "authors_parsed": [["Zhao", "Zilong", ""], ["Cerf", "Sophie", ""], ["Robu", "Bogdan", ""], ["Marchand", "Nicolas", ""]]}, {"id": "1911.07716", "submitter": "Farhad Pourkamali-Anaraki", "authors": "Farhad Pourkamali-Anaraki and Michael B. Wakin", "title": "The Effectiveness of Variational Autoencoders for Active Learning", "comments": "8 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV cs.IR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The high cost of acquiring labels is one of the main challenges in deploying\nsupervised machine learning algorithms. Active learning is a promising approach\nto control the learning process and address the difficulties of data labeling\nby selecting labeled training examples from a large pool of unlabeled\ninstances. In this paper, we propose a new data-driven approach to active\nlearning by choosing a small set of labeled data points that are both\ninformative and representative. To this end, we present an efficient geometric\ntechnique to select a diverse core-set in a low-dimensional latent space\nobtained by training a Variational Autoencoder (VAE). Our experiments\ndemonstrate an improvement in accuracy over two related techniques and, more\nimportantly, signify the representation power of generative modeling for\ndeveloping new active learning methods in high-dimensional data settings.\n", "versions": [{"version": "v1", "created": "Mon, 18 Nov 2019 15:42:20 GMT"}], "update_date": "2019-11-19", "authors_parsed": [["Pourkamali-Anaraki", "Farhad", ""], ["Wakin", "Michael B.", ""]]}, {"id": "1911.07721", "submitter": "Yihe Lu", "authors": "Lu Yihe, Scott C. Lowe, Penelope A. Lewis, Mark C. W. van Rossum", "title": "Program synthesis performance constrained by non-linear spatial\n  relations in Synthetic Visual Reasoning Test", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Despite remarkable advances in automated visual recognition by machines, some\nvisual tasks remain challenging for machines. Fleuret et al. (2011) introduced\nthe Synthetic Visual Reasoning Test (SVRT) to highlight this point, which\nrequired classification of images consisting of randomly generated shapes based\non hidden abstract rules using only a few examples. Ellis et al. (2015)\ndemonstrated that a program synthesis approach could solve some of the SVRT\nproblems with unsupervised, few-shot learning, whereas they remained\nchallenging for several convolutional neural networks trained with thousands of\nexamples. Here we re-considered the human and machine experiments, because they\nfollowed different protocols and yielded different statistics. We thus proposed\na quantitative reintepretation of the data between the protocols, so that we\ncould make fair comparison between human and machine performance. We improved\nthe program synthesis classifier by correcting the image parsings, and compared\nthe results to the performance of other machine agents and human subjects. We\ngrouped the SVRT problems into different types by the two aspects of the core\ncharacteristics for classification: shape specification and location relation.\nWe found that the program synthesis classifier could not solve problems\ninvolving shape distances, because it relied on symbolic computation which\nscales poorly with input dimension and adding distances into such computation\nwould increase the dimension combinatorially with the number of shapes in an\nimage. Therefore, although the program synthesis classifier is capable of\nabstract reasoning, its performance is highly constrained by the accessible\ninformation in image parsings.\n", "versions": [{"version": "v1", "created": "Mon, 18 Nov 2019 15:47:03 GMT"}, {"version": "v2", "created": "Tue, 19 Nov 2019 12:32:25 GMT"}], "update_date": "2019-11-20", "authors_parsed": [["Yihe", "Lu", ""], ["Lowe", "Scott C.", ""], ["Lewis", "Penelope A.", ""], ["van Rossum", "Mark C. W.", ""]]}, {"id": "1911.07722", "submitter": "Celestine Mendler-D\\\"unner", "authors": "Nikolas Ioannou, Celestine Mendler-D\\\"unner, Thomas Parnell", "title": "SySCD: A System-Aware Parallel Coordinate Descent Algorithm", "comments": "accepted as a spotlight at NeurIPS 2019, Vancouver, Canada", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.DC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we propose a novel parallel stochastic coordinate descent (SCD)\nalgorithm with convergence guarantees that exhibits strong scalability. We\nstart by studying a state-of-the-art parallel implementation of SCD and\nidentify scalability as well as system-level performance bottlenecks of the\nrespective implementation. We then take a principled approach to develop a new\nSCD variant which is designed to avoid the identified system bottlenecks, such\nas limited scaling due to coherence traffic of model sharing across threads,\nand inefficient CPU cache accesses. Our proposed system-aware parallel\ncoordinate descent algorithm (SySCD) scales to many cores and across numa\nnodes, and offers a consistent bottom line speedup in training time of up to\nx12 compared to an optimized asynchronous parallel SCD algorithm and up to x42,\ncompared to state-of-the-art GLM solvers (scikit-learn, Vowpal Wabbit, and H2O)\non a range of datasets and multi-core CPU architectures.\n", "versions": [{"version": "v1", "created": "Mon, 18 Nov 2019 15:47:30 GMT"}], "update_date": "2019-11-19", "authors_parsed": [["Ioannou", "Nikolas", ""], ["Mendler-D\u00fcnner", "Celestine", ""], ["Parnell", "Thomas", ""]]}, {"id": "1911.07729", "submitter": "Luc Frachon", "authors": "Luc Frachon, Wei Pang, George M. Coghill", "title": "ImmuNeCS: Neural Committee Search by an Artificial Immune System", "comments": "16 pages including references, 6 figures, 3 tables, 2 algorithms", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Current Neural Architecture Search techniques can suffer from a few\nshortcomings, including high computational cost, excessive bias from the search\nspace, conceptual complexity or uncertain empirical benefits over random\nsearch. In this paper, we present ImmuNeCS, an attempt at addressing these\nissues with a method that offers a simple, flexible, and efficient way of\nbuilding deep learning models automatically, and we demonstrate its\neffectiveness in the context of convolutional neural networks. Instead of\nsearching for the 1-best architecture for a given task, we focus on building a\npopulation of neural networks that are then ensembled into a neural network\ncommittee, an approach we dub 'Neural Committee Search'. To ensure sufficient\nperformance from the committee, our search algorithm is based on an artificial\nimmune system that balances individual performance with population diversity.\nThis allows us to stop the search when accuracy starts to plateau, and to\nbridge the performance gap through ensembling. In order to justify our method,\nwe first verify that the chosen search space exhibits the locality property. To\nfurther improve efficiency, we also combine partial evaluation, weight\ninheritance, and progressive search. First, experiments are run to verify the\nvalidity of these techniques. Then, preliminary experimental results on two\npopular computer vision benchmarks show that our method consistently\noutperforms random search and yields promising results within reasonable GPU\nbudgets. An additional experiment also shows that ImmuNeCS's solutions transfer\neffectively to a more difficult task, where they achieve results comparable to\na direct search on the new task. We believe these findings can open the way for\nnew, accessible alternatives to traditional NAS.\n", "versions": [{"version": "v1", "created": "Mon, 18 Nov 2019 16:00:28 GMT"}, {"version": "v2", "created": "Tue, 19 Nov 2019 15:39:03 GMT"}, {"version": "v3", "created": "Mon, 22 Jun 2020 11:06:38 GMT"}, {"version": "v4", "created": "Thu, 22 Oct 2020 20:23:51 GMT"}], "update_date": "2020-10-26", "authors_parsed": [["Frachon", "Luc", ""], ["Pang", "Wei", ""], ["Coghill", "George M.", ""]]}, {"id": "1911.07736", "submitter": "Tianyu Hua", "authors": "Tianyu Hua, Maithilee Kunda", "title": "Modeling Gestalt Visual Reasoning on the Raven's Progressive Matrices\n  Intelligence Test Using Generative Image Inpainting Techniques", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG eess.IV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Psychologists recognize Raven's Progressive Matrices as a very effective test\nof general human intelligence. While many computational models have been\ndeveloped by the AI community to investigate different forms of top-down,\ndeliberative reasoning on the test, there has been less research on bottom-up\nperceptual processes, like Gestalt image completion, that are also critical in\nhuman test performance. In this work, we investigate how Gestalt visual\nreasoning on the Raven's test can be modeled using generative image inpainting\ntechniques from computer vision. We demonstrate that a self-supervised\ninpainting model trained only on photorealistic images of objects achieves a\nscore of 27/36 on the Colored Progressive Matrices, which corresponds to\naverage performance for nine-year-old children. We also show that models\ntrained on other datasets (faces, places, and textures) do not perform as well.\nOur results illustrate how learning visual regularities in real-world images\ncan translate into successful reasoning about artificial test stimuli. On the\nflip side, our results also highlight the limitations of such transfer, which\nmay explain why intelligence tests like the Raven's are often sensitive to\npeople's individual sociocultural backgrounds.\n", "versions": [{"version": "v1", "created": "Mon, 18 Nov 2019 16:16:55 GMT"}, {"version": "v2", "created": "Tue, 26 Nov 2019 08:32:20 GMT"}], "update_date": "2019-11-27", "authors_parsed": [["Hua", "Tianyu", ""], ["Kunda", "Maithilee", ""]]}, {"id": "1911.07738", "submitter": "Steven Van Rossem", "authors": "Steven Van Rossem, Wouter Tavernier, Didier Colle, Mario Pickavet,\n  Piet Demeester", "title": "Profile-based Resource Allocation for Virtualized Network Functions", "comments": "accepted in IEEE TNSM journal", "journal-ref": "IEEE Transactions on Network and Service Management, 2019, Early\n  Access", "doi": "10.1109/TNSM.2019.2943779", "report-no": null, "categories": "cs.NI cs.LG cs.PF stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The virtualization of compute and network resources enables an unseen\nflexibility for deploying network services. A wide spectrum of emerging\ntechnologies allows an ever-growing range of orchestration possibilities in\ncloud-based environments. But in this context it remains challenging to rhyme\ndynamic cloud configurations with deterministic performance. The service\noperator must somehow map the performance specification in the Service Level\nAgreement (SLA) to an adequate resource allocation in the virtualized\ninfrastructure. We propose the use of a VNF profile to alleviate this process.\nThis is illustrated by profiling the performance of four example network\nfunctions (a virtual router, switch, firewall and cache server) under varying\nworkloads and resource configurations. We then compare several methods to\nderive a model from the profiled datasets. We select the most accurate method\nto further train a model which predicts the services' performance, in function\nof incoming workload and allocated resources. Our presented method can offer\nthe service operator a recommended resource allocation for the targeted\nservice, in function of the targeted performance and maximum workload specified\nin the SLA. This helps to deploy the softwarized service with an optimal amount\nof resources to meet the SLA requirements, thereby avoiding unnecessary scaling\nsteps.\n", "versions": [{"version": "v1", "created": "Mon, 18 Nov 2019 16:21:41 GMT"}], "update_date": "2019-11-19", "authors_parsed": [["Van Rossem", "Steven", ""], ["Tavernier", "Wouter", ""], ["Colle", "Didier", ""], ["Pickavet", "Mario", ""], ["Demeester", "Piet", ""]]}, {"id": "1911.07747", "submitter": "Qun Liu", "authors": "Qun Liu, Saikat Basu, Sangram Ganguly, Supratik Mukhopadhyay, Robert\n  DiBiano, Manohar Karki, Ramakrishna Nemani", "title": "DeepSat V2: Feature Augmented Convolutional Neural Nets for Satellite\n  Image Classification", "comments": "This is an Accepted Manuscript of an article published by Taylor &\n  Francis Group in Remote Sensing Letters. arXiv admin note: text overlap with\n  arXiv:1509.03602", "journal-ref": null, "doi": "10.1080/2150704X.2019.1693071", "report-no": null, "categories": "cs.CV cs.LG eess.IV", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Satellite image classification is a challenging problem that lies at the\ncrossroads of remote sensing, computer vision, and machine learning. Due to the\nhigh variability inherent in satellite data, most of the current object\nclassification approaches are not suitable for handling satellite datasets. The\nprogress of satellite image analytics has also been inhibited by the lack of a\nsingle labeled high-resolution dataset with multiple class labels. In a\npreliminary version of this work, we introduced two new high resolution\nsatellite imagery datasets (SAT-4 and SAT-6) and proposed DeepSat framework for\nclassification based on \"handcrafted\" features and a deep belief network (DBN).\nThe present paper is an extended version, we present an end-to-end framework\nleveraging an improved architecture that augments a convolutional neural\nnetwork (CNN) with handcrafted features (instead of using DBN-based\narchitecture) for classification. Our framework, having access to fused spatial\ninformation obtained from handcrafted features as well as CNN feature maps,\nhave achieved accuracies of 99.90% and 99.84% respectively, on SAT-4 and SAT-6,\nsurpassing all the other state-of-the-art results. A statistical analysis based\non Distribution Separability Criterion substantiates the robustness of our\napproach in learning better representations for satellite imagery.\n", "versions": [{"version": "v1", "created": "Fri, 15 Nov 2019 04:07:09 GMT"}], "update_date": "2019-11-19", "authors_parsed": [["Liu", "Qun", ""], ["Basu", "Saikat", ""], ["Ganguly", "Sangram", ""], ["Mukhopadhyay", "Supratik", ""], ["DiBiano", "Robert", ""], ["Karki", "Manohar", ""], ["Nemani", "Ramakrishna", ""]]}, {"id": "1911.07749", "submitter": "Andr\\'e Artelt", "authors": "Andr\\'e Artelt, Barbara Hammer", "title": "On the computation of counterfactual explanations -- A survey", "comments": "In progress. arXiv admin note: text overlap with arXiv:1908.00735", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Due to the increasing use of machine learning in practice it becomes more and\nmore important to be able to explain the prediction and behavior of machine\nlearning models. An instance of explanations are counterfactual explanations\nwhich provide an intuitive and useful explanations of machine learning models.\nIn this survey we review model-specific methods for efficiently computing\ncounterfactual explanations of many different machine learning models and\npropose methods for models that have not been considered in literature so far.\n", "versions": [{"version": "v1", "created": "Fri, 15 Nov 2019 08:14:26 GMT"}], "update_date": "2019-11-19", "authors_parsed": [["Artelt", "Andr\u00e9", ""], ["Hammer", "Barbara", ""]]}, {"id": "1911.07755", "submitter": "Alberto Marchesi", "authors": "Alberto Marchesi, Francesco Trov\\`o, Nicola Gatti", "title": "Learning Probably Approximately Correct Maximin Strategies in\n  Simulation-Based Games with Infinite Strategy Spaces", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.GT cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We tackle the problem of learning equilibria in simulation-based games. In\nsuch games, the players' utility functions cannot be described analytically, as\nthey are given through a black-box simulator that can be queried to obtain\nnoisy estimates of the utilities. This is the case in many real-world games in\nwhich a complete description of the elements involved is not available upfront,\nsuch as complex military settings and online auctions. In these situations, one\nusually needs to run costly simulation processes to get an accurate estimate of\nthe game outcome. As a result, solving these games begets the challenge of\ndesigning learning algorithms that can find (approximate) equilibria with high\nconfidence, using as few simulator queries as possible. Moreover, since running\nthe simulator during the game is unfeasible, the algorithms must first perform\na pure exploration learning phase and, then, use the (approximate) equilibrium\nlearned this way to play the game. In this work, we focus on two-player\nzero-sum games with infinite strategy spaces. Drawing from the best arm\nidentification literature, we design two algorithms with theoretical guarantees\nto learn maximin strategies in these games. The first one works in the\nfixed-confidence setting, guaranteeing the desired confidence level while\nminimizing the number of queries. Instead, the second algorithm fits the\nfixed-budget setting, maximizing the confidence without exceeding the given\nmaximum number of queries. First, we formally prove {\\delta}-PAC theoretical\nguarantees for our algorithms under some regularity assumptions, which are\nencoded by letting the utility functions be drawn from a Gaussian process.\nThen, we experimentally evaluate our techniques on a testbed made of randomly\ngenerated games and instances representing simple real-world security settings.\n", "versions": [{"version": "v1", "created": "Mon, 18 Nov 2019 16:37:08 GMT"}, {"version": "v2", "created": "Tue, 25 Feb 2020 15:59:44 GMT"}], "update_date": "2020-02-26", "authors_parsed": [["Marchesi", "Alberto", ""], ["Trov\u00f2", "Francesco", ""], ["Gatti", "Nicola", ""]]}, {"id": "1911.07758", "submitter": "Hao Wang", "authors": "Fan Zhang, Hao Wang, Jiashan Wang, Kai Yang", "title": "Inexact Primal-Dual Gradient Projection Methods for Nonlinear\n  Optimization on Convex Set", "comments": "25 pages, 7 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.OC cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we propose a novel primal-dual inexact gradient projection\nmethod for nonlinear optimization problems with convex-set constraint. This\nmethod only needs inexact computation of the projections onto the convex set\nfor each iteration, consequently reducing the computational cost for\nprojections per iteration. This feature is attractive especially for solving\nproblems where the projections are computationally not easy to calculate.\nGlobal convergence guarantee and O(1/k) ergodic convergence rate of the\noptimality residual are provided under loose assumptions. We apply our proposed\nstrategy to l1-ball constrained problems. Numerical results exhibit that our\ninexact gradient projection methods for solving l1-ball constrained problems\nare more efficient than the exact methods.\n", "versions": [{"version": "v1", "created": "Mon, 18 Nov 2019 16:41:33 GMT"}], "update_date": "2019-11-19", "authors_parsed": [["Zhang", "Fan", ""], ["Wang", "Hao", ""], ["Wang", "Jiashan", ""], ["Yang", "Kai", ""]]}, {"id": "1911.07790", "submitter": "Masahiro Nomura", "authors": "Masahiro Nomura, Kenshi Abe", "title": "A Simple Heuristic for Bayesian Optimization with A Low Budget", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The aim of black-box optimization is to optimize an objective function within\nthe constraints of a given evaluation budget. In this problem, it is generally\nassumed that the computational cost for evaluating a point is large; thus, it\nis important to search efficiently with as low budget as possible. Bayesian\noptimization is an efficient method for black-box optimization and provides\nexploration-exploitation trade-off by constructing a surrogate model that\nconsiders uncertainty of the objective function. However, because Bayesian\noptimization should construct the surrogate model for the entire search space,\nit does not exhibit good performance when points are not sampled sufficiently.\nIn this study, we develop a heuristic method refining the search space for\nBayesian optimization when the available evaluation budget is low. The proposed\nmethod refines a promising region by dividing the original region so that\nBayesian optimization can be executed with the promising region as the initial\nsearch space. We confirm that Bayesian optimization with the proposed method\noutperforms Bayesian optimization alone and shows equal or better performance\nto two search-space division algorithms through experiments on the benchmark\nfunctions and the hyperparameter optimization of machine learning algorithms.\n", "versions": [{"version": "v1", "created": "Mon, 18 Nov 2019 17:43:59 GMT"}, {"version": "v2", "created": "Tue, 19 Nov 2019 05:36:30 GMT"}, {"version": "v3", "created": "Sat, 30 Nov 2019 15:42:01 GMT"}], "update_date": "2019-12-03", "authors_parsed": [["Nomura", "Masahiro", ""], ["Abe", "Kenshi", ""]]}, {"id": "1911.07794", "submitter": "Craig Sherstan", "authors": "Craig Sherstan, Shibhansh Dohare, James MacGlashan, Johannes\n  G\\\"unther, Patrick M. Pilarski", "title": "Gamma-Nets: Generalizing Value Estimation over Timescale", "comments": "AAAI 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present $\\Gamma$-nets, a method for generalizing value function estimation\nover timescale. By using the timescale as one of the estimator's inputs we can\nestimate value for arbitrary timescales. As a result, the prediction target for\nany timescale is available and we are free to train on multiple timescales at\neach timestep. Here we empirically evaluate $\\Gamma$-nets in the policy\nevaluation setting. We first demonstrate the approach on a square wave and then\non a robot arm using linear function approximation. Next, we consider the deep\nreinforcement learning setting using several Atari video games. Our results\nshow that $\\Gamma$-nets can be effective for predicting arbitrary timescales,\nwith only a small cost in accuracy as compared to learning estimators for fixed\ntimescales. $\\Gamma$-nets provide a method for compactly making predictions at\nmany timescales without requiring a priori knowledge of the task, making it a\nvaluable contribution to ongoing work on model-based planning, representation\nlearning, and lifelong learning algorithms.\n", "versions": [{"version": "v1", "created": "Mon, 18 Nov 2019 17:49:06 GMT"}, {"version": "v2", "created": "Wed, 20 Nov 2019 19:34:12 GMT"}, {"version": "v3", "created": "Sat, 23 Nov 2019 23:34:23 GMT"}, {"version": "v4", "created": "Fri, 31 Jan 2020 16:28:51 GMT"}, {"version": "v5", "created": "Fri, 16 Oct 2020 21:19:11 GMT"}], "update_date": "2020-10-20", "authors_parsed": [["Sherstan", "Craig", ""], ["Dohare", "Shibhansh", ""], ["MacGlashan", "James", ""], ["G\u00fcnther", "Johannes", ""], ["Pilarski", "Patrick M.", ""]]}, {"id": "1911.07805", "submitter": "Shokooh Taghian", "authors": "Shokooh Taghian, Mohammad H. Nadimi-Shahraki", "title": "Binary Sine Cosine Algorithms for Feature Selection from Medical Data", "comments": null, "journal-ref": null, "doi": "10.5121/acij.2019.10501", "report-no": null, "categories": "cs.LG cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A well-constructed classification model highly depends on input feature\nsubsets from a dataset, which may contain redundant, irrelevant, or noisy\nfeatures. This challenge can be worse while dealing with medical datasets. The\nmain aim of feature selection as a pre-processing task is to eliminate these\nfeatures and select the most effective ones. In the literature, metaheuristic\nalgorithms show a successful performance to find optimal feature subsets. In\nthis paper, two binary metaheuristic algorithms named S-shaped binary Sine\nCosine Algorithm (SBSCA) and V-shaped binary Sine Cosine Algorithm (VBSCA) are\nproposed for feature selection from the medical data. In these algorithms, the\nsearch space remains continuous, while a binary position vector is generated by\ntwo transfer functions S-shaped and V-shaped for each solution. The proposed\nalgorithms are compared with four latest binary optimization algorithms over\nfive medical datasets from the UCI repository. The experimental results confirm\nthat using both bSCA variants enhance the accuracy of classification on these\nmedical datasets compared to four other algorithms.\n", "versions": [{"version": "v1", "created": "Fri, 15 Nov 2019 12:57:09 GMT"}], "update_date": "2019-11-19", "authors_parsed": [["Taghian", "Shokooh", ""], ["Nadimi-Shahraki", "Mohammad H.", ""]]}, {"id": "1911.07819", "submitter": "Ioana Baldini", "authors": "Shivashankar Subramanian, Ioana Baldini, Sushma Ravichandran, Dmitriy\n  A. Katz-Rogozhnikov, Karthikeyan Natesan Ramamurthy, Prasanna Sattigeri, Kush\n  R. Varshney, Annmarie Wang, Pradeep Mangalath, Laura B. Kleiman", "title": "Drug Repurposing for Cancer: An NLP Approach to Identify Low-Cost\n  Therapies", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  More than 200 generic drugs approved by the U.S. Food and Drug Administration\nfor non-cancer indications have shown promise for treating cancer. Due to their\nlong history of safe patient use, low cost, and widespread availability,\nrepurposing of generic drugs represents a major opportunity to rapidly improve\noutcomes for cancer patients and reduce healthcare costs worldwide. Evidence on\nthe efficacy of non-cancer generic drugs being tested for cancer exists in\nscientific publications, but trying to manually identify and extract such\nevidence is intractable. In this paper, we introduce a system to automate this\nevidence extraction from PubMed abstracts. Our primary contribution is to\ndefine the natural language processing pipeline required to obtain such\nevidence, comprising the following modules: querying, filtering, cancer type\nentity extraction, therapeutic association classification, and study type\nclassification. Using the subject matter expertise on our team, we create our\nown datasets for these specialized domain-specific tasks. We obtain promising\nperformance in each of the modules by utilizing modern language modeling\ntechniques and plan to treat them as baseline approaches for future improvement\nof individual components.\n", "versions": [{"version": "v1", "created": "Mon, 18 Nov 2019 18:32:25 GMT"}, {"version": "v2", "created": "Thu, 5 Dec 2019 16:22:39 GMT"}], "update_date": "2019-12-06", "authors_parsed": [["Subramanian", "Shivashankar", ""], ["Baldini", "Ioana", ""], ["Ravichandran", "Sushma", ""], ["Katz-Rogozhnikov", "Dmitriy A.", ""], ["Ramamurthy", "Karthikeyan Natesan", ""], ["Sattigeri", "Prasanna", ""], ["Varshney", "Kush R.", ""], ["Wang", "Annmarie", ""], ["Mangalath", "Pradeep", ""], ["Kleiman", "Laura B.", ""]]}, {"id": "1911.07820", "submitter": "Tuyen Truong", "authors": "Tuyen Trung Truong", "title": "Coordinate-wise Armijo's condition", "comments": "6 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.OC cs.LG cs.NA math.NA stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Let $z=(x,y)$ be coordinates for the product space $\\mathbb{R}^{m_1}\\times\n\\mathbb{R}^{m_2}$. Let $f:\\mathbb{R}^{m_1}\\times \\mathbb{R}^{m_2}\\rightarrow\n\\mathbb{R}$ be a $C^1$ function, and $\\nabla f=(\\partial _xf,\\partial _yf)$ its\ngradient. Fix $0<\\alpha <1$. For a point $(x,y) \\in \\mathbb{R}^{m_1}\\times\n\\mathbb{R}^{m_2}$, a number $\\delta >0$ satisfies Armijo's condition at $(x,y)$\nif the following inequality holds: \\begin{eqnarray*} f(x-\\delta \\partial\n_xf,y-\\delta \\partial _yf)-f(x,y)\\leq -\\alpha \\delta (||\\partial\n_xf||^2+||\\partial _yf||^2). \\end{eqnarray*}\n  When $f(x,y)=f_1(x)+f_2(y)$ is a coordinate-wise sum map, we propose the\nfollowing {\\bf coordinate-wise} Armijo's condition. Fix again $0<\\alpha <1$. A\npair of positive numbers $\\delta _1,\\delta _2>0$ satisfies the coordinate-wise\nvariant of Armijo's condition at $(x,y)$ if the following inequality holds:\n\\begin{eqnarray*} [f_1(x-\\delta _1\\nabla f_1(x))+f_2(y-\\delta _2\\nabla\nf_2(y))]-[f_1(x)+f_2(y)]\\leq -\\alpha (\\delta _1||\\nabla f_1(x)||^2+\\delta\n_2||\\nabla f_2(y)||^2). \\end{eqnarray*}\n  We then extend results in our recent previous results, on Backtracking\nGradient Descent and some variants, to this setting. We show by an example the\nadvantage of using coordinate-wise Armijo's condition over the usual Armijo's\ncondition.\n", "versions": [{"version": "v1", "created": "Mon, 18 Nov 2019 18:35:46 GMT"}], "update_date": "2019-11-19", "authors_parsed": [["Truong", "Tuyen Trung", ""]]}, {"id": "1911.07831", "submitter": "Mehmet A. S\\\"uzen PhD", "authors": "Mehmet S\\\"uzen, J.J. Cerd\\`a, Cornelius Weber", "title": "Periodic Spectral Ergodicity: A Complexity Measure for Deep Neural\n  Networks and Neural Architecture Search", "comments": "9 pages, 5 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cond-mat.dis-nn cond-mat.stat-mech stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Establishing associations between the structure and the generalisation\nability of deep neural networks (DNNs) is a challenging task in modern machine\nlearning. Producing solutions to this challenge will bring progress both in the\ntheoretical understanding of DNNs and in building new architectures\nefficiently. In this work, we address this challenge by developing a new\ncomplexity measure based on the concept of {Periodic Spectral Ergodicity} (PSE)\noriginating from quantum statistical mechanics. Based on this measure a\ntechnique is devised to quantify the complexity of deep neural networks from\nthe learned weights and traversing the network connectivity in a sequential\nmanner, hence the term cascading PSE (cPSE), as an empirical complexity\nmeasure. This measure will capture both topological and internal neural\nprocessing complexity simultaneously. Because of this cascading approach, i.e.,\na symmetric divergence of PSE on the consecutive layers, it is possible to use\nthis measure for Neural Architecture Search (NAS). We demonstrate the\nusefulness of this measure in practice on two sets of vision models, ResNet and\nVGG, and sketch the computation of cPSE for more complex network structures.\n", "versions": [{"version": "v1", "created": "Sun, 10 Nov 2019 03:10:27 GMT"}, {"version": "v2", "created": "Sun, 19 Jan 2020 16:57:02 GMT"}, {"version": "v3", "created": "Sat, 1 Feb 2020 03:39:35 GMT"}, {"version": "v4", "created": "Thu, 30 Apr 2020 03:32:07 GMT"}], "update_date": "2020-05-01", "authors_parsed": [["S\u00fczen", "Mehmet", ""], ["Cerd\u00e0", "J. J.", ""], ["Weber", "Cornelius", ""]]}, {"id": "1911.07844", "submitter": "Tharindu Fernando", "authors": "Tharindu Fernando, Clinton Fookes, Simon Denman, Sridha Sridharan", "title": "Exploiting Human Social Cognition for the Detection of Fake and\n  Fraudulent Faces via Memory Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG cs.MM stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Advances in computer vision have brought us to the point where we have the\nability to synthesise realistic fake content. Such approaches are seen as a\nsource of disinformation and mistrust, and pose serious concerns to governments\naround the world. Convolutional Neural Networks (CNNs) demonstrate encouraging\nresults when detecting fake images that arise from the specific type of\nmanipulation they are trained on. However, this success has not transitioned to\nunseen manipulation types, resulting in a significant gap in the\nline-of-defense. We propose a Hierarchical Memory Network (HMN) architecture,\nwhich is able to successfully detect faked faces by utilising knowledge stored\nin neural memories as well as visual cues to reason about the perceived face\nand anticipate its future semantic embeddings. This renders a generalisable\nface tampering detection framework. Experimental results demonstrate the\nproposed approach achieves superior performance for fake and fraudulent face\ndetection compared to the state-of-the-art.\n", "versions": [{"version": "v1", "created": "Sun, 17 Nov 2019 23:20:23 GMT"}], "update_date": "2019-11-20", "authors_parsed": [["Fernando", "Tharindu", ""], ["Fookes", "Clinton", ""], ["Denman", "Simon", ""], ["Sridharan", "Sridha", ""]]}, {"id": "1911.07845", "submitter": "Yun-Hao Cao", "authors": "Yun-Hao Cao and Jianxin Wu and Hanchen Wang and Joan Lasenby", "title": "Neural Random Subspace", "comments": "38 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The random subspace method, known as the pillar of random forests, is good at\nmaking precise and robust predictions. However, there is not a straightforward\nway yet to combine it with deep learning. In this paper, we therefore propose\nNeural Random Subspace (NRS), a novel deep learning based random subspace\nmethod. In contrast to previous forest methods, NRS enjoys the benefits of\nend-to-end, data-driven representation learning, as well as pervasive support\nfrom deep learning software and hardware platforms, hence achieving faster\ninference speed and higher accuracy. Furthermore, as a non-linear component to\nbe encoded into Convolutional Neural Networks (CNNs), NRS learns non-linear\nfeature representations in CNNs more efficiently than previous higher-order\npooling methods, producing good results with negligible increase in parameters,\nfloating point operations (FLOPs) and real running time. Compared with random\nsubspaces, random forests and gradient boosting decision trees (GBDTs), NRS\nachieves superior performance on 35 machine learning datasets. Moreover, on\nboth 2D image and 3D point cloud recognition tasks, integration of NRS with CNN\narchitectures achieves consistent improvements with minor extra cost. Code is\navailable at https://github.com/CupidJay/NRS_pytorch.\n", "versions": [{"version": "v1", "created": "Mon, 18 Nov 2019 02:28:04 GMT"}, {"version": "v2", "created": "Fri, 12 Jun 2020 01:03:43 GMT"}, {"version": "v3", "created": "Tue, 15 Sep 2020 01:07:47 GMT"}], "update_date": "2020-09-16", "authors_parsed": [["Cao", "Yun-Hao", ""], ["Wu", "Jianxin", ""], ["Wang", "Hanchen", ""], ["Lasenby", "Joan", ""]]}, {"id": "1911.07846", "submitter": "Shi Yin", "authors": "Shangfei Wang, Shi Yin, Longfei Hao and Guang Liang", "title": "Multiple Face Analyses through Adversarial Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This inherent relations among multiple face analysis tasks, such as landmark\ndetection, head pose estimation, gender recognition and face attribute\nestimation are crucial to boost the performance of each task, but have not been\nthoroughly explored since typically these multiple face analysis tasks are\nhandled as separate tasks. In this paper, we propose a novel deep multi-task\nadversarial learning method to localize facial landmark, estimate head pose and\nrecognize gender jointly or estimate multiple face attributes simultaneously\nthrough exploring their dependencies from both image representation-level and\nlabel-level. Specifically, the proposed method consists of a deep recognition\nnetwork R and a discriminator D. The deep recognition network is used to learn\nthe shared middle-level image representation and conducts multiple face\nanalysis tasks simultaneously. Through multi-task learning mechanism, the\nrecognition network explores the dependencies among multiple face analysis\ntasks, such as facial landmark localization, head pose estimation, gender\nrecognition and face attribute estimation from image representation-level. The\ndiscriminator is introduced to enforce the distribution of the multiple face\nanalysis tasks to converge to that inherent in the ground-truth labels. During\ntraining, the recognizer tries to confuse the discriminator, while the\ndiscriminator competes with the recognizer through distinguishing the predicted\nlabel combination from the ground-truth one. Though adversarial learning, we\nexplore the dependencies among multiple face analysis tasks from label-level.\nExperimental results on four benchmark databases, i.e., the AFLW database, the\nMulti-PIE database, the CelebA database and the LFWA database, demonstrate the\neffectiveness of the proposed method for multiple face analyses.\n", "versions": [{"version": "v1", "created": "Mon, 18 Nov 2019 04:24:17 GMT"}], "update_date": "2019-11-20", "authors_parsed": [["Wang", "Shangfei", ""], ["Yin", "Shi", ""], ["Hao", "Longfei", ""], ["Liang", "Guang", ""]]}, {"id": "1911.07848", "submitter": "Sijie Mai", "authors": "Sijie Mai and Haifeng Hu and Songlong Xing", "title": "Modality to Modality Translation: An Adversarial Representation Learning\n  and Graph Fusion Network for Multimodal Fusion", "comments": "Accepted by AAAI-2020; code is available at:\n  https://github.com/TmacMai/ARGF_multimodal_fusion", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG cs.MM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Learning joint embedding space for various modalities is of vital importance\nfor multimodal fusion. Mainstream modality fusion approaches fail to achieve\nthis goal, leaving a modality gap which heavily affects cross-modal fusion. In\nthis paper, we propose a novel adversarial encoder-decoder-classifier framework\nto learn a modality-invariant embedding space. Since the distributions of\nvarious modalities vary in nature, to reduce the modality gap, we translate the\ndistributions of source modalities into that of target modality via their\nrespective encoders using adversarial training. Furthermore, we exert\nadditional constraints on embedding space by introducing reconstruction loss\nand classification loss. Then we fuse the encoded representations using\nhierarchical graph neural network which explicitly explores unimodal, bimodal\nand trimodal interactions in multi-stage. Our method achieves state-of-the-art\nperformance on multiple datasets. Visualization of the learned embeddings\nsuggests that the joint embedding space learned by our method is\ndiscriminative. code is available at:\n\\url{https://github.com/TmacMai/ARGF_multimodal_fusion}\n", "versions": [{"version": "v1", "created": "Mon, 18 Nov 2019 08:29:20 GMT"}, {"version": "v2", "created": "Fri, 22 Nov 2019 08:34:28 GMT"}, {"version": "v3", "created": "Thu, 12 Dec 2019 15:43:06 GMT"}, {"version": "v4", "created": "Thu, 10 Dec 2020 01:52:20 GMT"}], "update_date": "2020-12-11", "authors_parsed": [["Mai", "Sijie", ""], ["Hu", "Haifeng", ""], ["Xing", "Songlong", ""]]}, {"id": "1911.07849", "submitter": "David W. Romero", "authors": "David W. Romero, Mark Hoogendoorn", "title": "Co-Attentive Equivariant Neural Networks: Focusing Equivariance On\n  Transformations Co-Occurring In Data", "comments": "Proceedings of the 8th International Conference on Learning\n  Representations (ICLR), 2020", "journal-ref": "Proceedings of the International Conference on Learning\n  Representations, 2020", "doi": null, "report-no": null, "categories": "cs.CV cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Equivariance is a nice property to have as it produces much more parameter\nefficient neural architectures and preserves the structure of the input through\nthe feature mapping. Even though some combinations of transformations might\nnever appear (e.g. an upright face with a horizontal nose), current equivariant\narchitectures consider the set of all possible transformations in a\ntransformation group when learning feature representations. Contrarily, the\nhuman visual system is able to attend to the set of relevant transformations\noccurring in the environment and utilizes this information to assist and\nimprove object recognition. Based on this observation, we modify conventional\nequivariant feature mappings such that they are able to attend to the set of\nco-occurring transformations in data and generalize this notion to act on\ngroups consisting of multiple symmetries. We show that our proposed\nco-attentive equivariant neural networks consistently outperform conventional\nrotation equivariant and rotation & reflection equivariant neural networks on\nrotated MNIST and CIFAR-10.\n", "versions": [{"version": "v1", "created": "Mon, 18 Nov 2019 12:41:12 GMT"}, {"version": "v2", "created": "Mon, 10 Feb 2020 13:56:10 GMT"}], "update_date": "2020-02-11", "authors_parsed": [["Romero", "David W.", ""], ["Hoogendoorn", "Mark", ""]]}, {"id": "1911.07874", "submitter": "Cheng Ji", "authors": "Jianxin Li, Cheng Ji, Hao Peng, Yu He, Yangqiu Song, Xinmiao Zhang,\n  Fanzhang Peng", "title": "RWNE: A Scalable Random-Walk-Based Network Embedding Framework with\n  Personalized Higher-Order Proximity Preserved", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Higher-order proximity preserved network embedding has attracted increasing\nattention. In particular, due to the superior scalability, random-walk-based\nnetwork embedding has also been well developed, which could efficiently explore\nhigher-order neighborhoods via multi-hop random walks. However, despite the\nsuccess of current random-walk-based methods, most of them are usually not\nexpressive enough to preserve the personalized higher-order proximity and lack\na straightforward objective to theoretically articulate what and how network\nproximity is preserved. In this paper, to address the above issues, we present\na general scalable random-walk-based network embedding framework, in which\nrandom walk is explicitly incorporated into a sound objective designed\ntheoretically to preserve arbitrary higher-order proximity. Further, we\nintroduce the random walk with restart process into the framework to naturally\nand effectively achieve personalized-weighted preservation of proximities of\ndifferent orders. We conduct extensive experiments on several real-world\nnetworks and demonstrate that our proposed method consistently and\nsubstantially outperforms the state-of-the-art network embedding methods.\n", "versions": [{"version": "v1", "created": "Mon, 18 Nov 2019 19:02:21 GMT"}, {"version": "v2", "created": "Wed, 7 Apr 2021 11:57:24 GMT"}], "update_date": "2021-04-08", "authors_parsed": [["Li", "Jianxin", ""], ["Ji", "Cheng", ""], ["Peng", "Hao", ""], ["He", "Yu", ""], ["Song", "Yangqiu", ""], ["Zhang", "Xinmiao", ""], ["Peng", "Fanzhang", ""]]}, {"id": "1911.07875", "submitter": "Sandhya Tripathi", "authors": "Aditya Petety, Sandhya Tripathi, N Hemachandra", "title": "Attribute noise robust binary classification", "comments": "Accepted for Student Abstract presentation at AAAI2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We consider the problem of learning linear classifiers when both features and\nlabels are binary. In addition, the features are noisy, i.e., they could be\nflipped with an unknown probability. In Sy-De attribute noise model, where all\nfeatures could be noisy together with same probability, we show that $0$-$1$\nloss ($l_{0-1}$) need not be robust but a popular surrogate, squared loss\n($l_{sq}$) is. In Asy-In attribute noise model, we prove that $l_{0-1}$ is\nrobust for any distribution over 2 dimensional feature space. However, due to\ncomputational intractability of $l_{0-1}$, we resort to $l_{sq}$ and observe\nthat it need not be Asy-In noise robust. Our empirical results support Sy-De\nrobustness of squared loss for low to moderate noise rates.\n", "versions": [{"version": "v1", "created": "Mon, 18 Nov 2019 19:03:02 GMT"}], "update_date": "2019-11-20", "authors_parsed": [["Petety", "Aditya", ""], ["Tripathi", "Sandhya", ""], ["Hemachandra", "N", ""]]}, {"id": "1911.07891", "submitter": "Alexander Jung", "authors": "Alexander Jung and Ivan Baranov", "title": "Basic Principles of Clustering Methods", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Clustering methods group a set of data points into a few coherent groups or\nclusters of similar data points. As an example, consider clustering pixels in\nan image (or video) if they belong to the same object. Different clustering\nmethods are obtained by using different notions of similarity and different\nrepresentations of data points.\n", "versions": [{"version": "v1", "created": "Mon, 18 Nov 2019 19:32:04 GMT"}, {"version": "v2", "created": "Tue, 10 Dec 2019 18:28:58 GMT"}], "update_date": "2019-12-11", "authors_parsed": [["Jung", "Alexander", ""], ["Baranov", "Ivan", ""]]}, {"id": "1911.07893", "submitter": "Chengjin Xu", "authors": "Chengjin Xu and Mojtaba Nayyeri and Fouad Alkhoury and Hamed Shariat\n  Yazdi and Jens Lehmann", "title": "Temporal Knowledge Graph Embedding Model based on Additive Time Series\n  Decomposition", "comments": "This paper has been accepted by ISWC2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Knowledge Graph (KG) embedding has attracted more attention in recent years.\nMost KG embedding models learn from time-unaware triples. However, the\ninclusion of temporal information beside triples would further improve the\nperformance of a KGE model. In this regard, we propose ATiSE, a temporal KG\nembedding model which incorporates time information into entity/relation\nrepresentations by using Additive Time Series decomposition. Moreover,\nconsidering the temporal uncertainty during the evolution of entity/relation\nrepresentations over time, we map the representations of temporal KGs into the\nspace of multi-dimensional Gaussian distributions. The mean of each\nentity/relation embedding at a time step shows the current expected position,\nwhereas its covariance (which is temporally stationary) represents its temporal\nuncertainty. Experimental results show that ATiSE chieves the state-of-the-art\non link prediction over four temporal KGs.\n", "versions": [{"version": "v1", "created": "Mon, 18 Nov 2019 19:36:26 GMT"}, {"version": "v2", "created": "Wed, 27 May 2020 07:23:58 GMT"}, {"version": "v3", "created": "Fri, 2 Oct 2020 08:03:43 GMT"}, {"version": "v4", "created": "Tue, 6 Oct 2020 20:07:17 GMT"}, {"version": "v5", "created": "Sat, 24 Oct 2020 14:14:20 GMT"}, {"version": "v6", "created": "Wed, 28 Oct 2020 12:28:46 GMT"}], "update_date": "2020-10-29", "authors_parsed": [["Xu", "Chengjin", ""], ["Nayyeri", "Mojtaba", ""], ["Alkhoury", "Fouad", ""], ["Yazdi", "Hamed Shariat", ""], ["Lehmann", "Jens", ""]]}, {"id": "1911.07896", "submitter": "Vishnu Sashank Dorbala", "authors": "Vishnu Sashank Dorbala, A.H. Abdul Hafez, C.V. Jawahar", "title": "A Deep Learning Approach for Robust Corridor Following", "comments": "7 pages, 7 figures. Paper published at 2019 IEEE/RSJ International\n  Conference on Intelligent Robots and Systems (IROS)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.CV cs.LG eess.IV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  For an autonomous corridor following task where the environment is\ncontinuously changing, several forms of environmental noise prevent an\nautomated feature extraction procedure from performing reliably. Moreover, in\ncases where pre-defined features are absent from the captured data, a well\ndefined control signal for performing the servoing task fails to get produced.\nIn order to overcome these drawbacks, we present in this work, using a\nconvolutional neural network (CNN) to directly estimate the required control\nsignal from an image, encompassing feature extraction and control law\ncomputation into one single end-to-end framework. In particular, we study the\ntask of autonomous corridor following using a CNN and present clear advantages\nin cases where a traditional method used for performing the same task fails to\ngive a reliable outcome. We evaluate the performance of our method on this task\non a Wheelchair Platform developed at our institute for this purpose.\n", "versions": [{"version": "v1", "created": "Mon, 18 Nov 2019 19:46:54 GMT"}], "update_date": "2019-11-20", "authors_parsed": [["Dorbala", "Vishnu Sashank", ""], ["Hafez", "A. H. Abdul", ""], ["Jawahar", "C. V.", ""]]}, {"id": "1911.07910", "submitter": "Shi Dong", "authors": "Benjamin Van Roy, Shi Dong", "title": "Comments on the Du-Kakade-Wang-Yang Lower Bounds", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Du, Kakade, Wang, and Yang recently established intriguing lower bounds on\nsample complexity, which suggest that reinforcement learning with a\nmisspecified representation is intractable. Another line of work, which centers\naround a statistic called the eluder dimension, establishes tractability of\nproblems similar to those considered in the Du-Kakade-Wang-Yang paper. We\ncompare these results and reconcile interpretations.\n", "versions": [{"version": "v1", "created": "Mon, 18 Nov 2019 20:15:15 GMT"}], "update_date": "2019-11-20", "authors_parsed": [["Van Roy", "Benjamin", ""], ["Dong", "Shi", ""]]}, {"id": "1911.07916", "submitter": "Adonis Emmanuel Tio", "authors": "Adonis Emmanuel Tio", "title": "Face shape classification using Inception v3", "comments": "6 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we present experimental results obtained from retraining the\nlast layer of the Inception v3 model in classifying images of human faces into\none of five basic face shapes. The accuracy of the retrained Inception v3 model\nwas compared with that of the following classification methods that uses facial\nlandmark distance ratios and angles as features: linear discriminant analysis\n(LDA), support vector machines with linear kernel (SVM-LIN), support vector\nmachines with radial basis function kernel (SVM-RBF), artificial neural\nnetworks or multilayer perceptron (MLP), and k-nearest neighbors (KNN). All\nclassifiers were trained and tested using a total of 500 images of female\ncelebrities with known face shapes collected from the Internet. Results show\nthat training accuracy and overall accuracy ranges from 98.0% to 100% and from\n84.4% to 84.8% for Inception v3 and from 50.6% to 73.0% and from 36.4% to 64.6%\nfor the other classifiers depending on the training set size used. This result\nshows that the retrained Inception v3 model was able to fit the training data\nwell and outperform the other classifiers without the need to handpick specific\nfeatures to include in model training. Future work should consider expanding\nthe labeled dataset, preferably one that can also be freely distributed to the\nresearch community, so that proper model cross-validation can be performed. As\nfar as we know, this is the first in the literature to use convolutional neural\nnetworks in face-shape classification. The scripts are available at\nhttps://github.com/adonistio/inception-face-shape-classifier.\n", "versions": [{"version": "v1", "created": "Fri, 15 Nov 2019 02:29:59 GMT"}], "update_date": "2019-11-20", "authors_parsed": [["Tio", "Adonis Emmanuel", ""]]}, {"id": "1911.07917", "submitter": "Xin Shu", "authors": "Shaoyong Jia, Xin Shu, Yang Yang, Dawei Liang, Qiyue Liu, Junhui Liu", "title": "Cross-modal supervised learning for better acoustic representations", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG cs.SD eess.AS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Obtaining large-scale human-labeled datasets to train acoustic representation\nmodels is a very challenging task. On the contrary, we can easily collect data\nwith machine-generated labels. In this work, we propose to exploit\nmachine-generated labels to learn better acoustic representations, based on the\nsynchronization between vision and audio. Firstly, we collect a large-scale\nvideo dataset with 15 million samples, which totally last 16,320 hours. Each\nvideo is 3 to 5 seconds in length and annotated automatically by publicly\navailable visual and audio classification models. Secondly, we train various\nclassical convolutional neural networks (CNNs) including VGGish, ResNet 50 and\nMobilenet v2. We also make several improvements to VGGish and achieve better\nresults. Finally, we transfer our models on three external standard benchmarks\nfor audio classification task, and achieve significant performance boost over\nthe state-of-the-art results. Models and codes are available at:\nhttps://github.com/Deeperjia/vgg-like-audio-models.\n", "versions": [{"version": "v1", "created": "Fri, 15 Nov 2019 02:23:23 GMT"}, {"version": "v2", "created": "Wed, 1 Jan 2020 06:22:39 GMT"}], "update_date": "2020-01-03", "authors_parsed": [["Jia", "Shaoyong", ""], ["Shu", "Xin", ""], ["Yang", "Yang", ""], ["Liang", "Dawei", ""], ["Liu", "Qiyue", ""], ["Liu", "Junhui", ""]]}, {"id": "1911.07918", "submitter": "Vivek Gupta", "authors": "Vivek Gupta, Ankit Saw, Pegah Nokhiz, Harshit Gupta, Partha Talukdar", "title": "Improving Document Classification with Multi-Sense Embeddings", "comments": "8 Pages, 7 Figures, 12 Tables, under review at ECAI 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.IR cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Efficient representation of text documents is an important building block in\nmany NLP tasks. Research on long text categorization has shown that simple\nweighted averaging of word vectors for sentence representation often\noutperforms more sophisticated neural models. Recently proposed Sparse\nComposite Document Vector (SCDV) (Mekala et. al, 2017) extends this approach\nfrom sentences to documents using soft clustering over word vectors. However,\nSCDV disregards the multi-sense nature of words, and it also suffers from the\ncurse of higher dimensionality. In this work, we address these shortcomings and\npropose SCDV-MS. SCDV-MS utilizes multi-sense word embeddings and learns a\nlower dimensional manifold. Through extensive experiments on multiple\nreal-world datasets, we show that SCDV-MS embeddings outperform previous\nstate-of-the-art embeddings on multi-class and multi-label text categorization\ntasks. Furthermore, SCDV-MS embeddings are more efficient than SCDV in terms of\ntime and space complexity on textual classification tasks.\n", "versions": [{"version": "v1", "created": "Mon, 18 Nov 2019 20:30:06 GMT"}], "update_date": "2019-11-20", "authors_parsed": [["Gupta", "Vivek", ""], ["Saw", "Ankit", ""], ["Nokhiz", "Pegah", ""], ["Gupta", "Harshit", ""], ["Talukdar", "Partha", ""]]}, {"id": "1911.07921", "submitter": "Chris Mesterharm", "authors": "Rauf Izmailov and Peter Lin and Chris Mesterharm and Samyadeep Basu", "title": "Privacy Leakage Avoidance with Switching Ensembles", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider membership inference attacks, one of the main privacy issues in\nmachine learning. These recently developed attacks have been proven successful\nin determining, with confidence better than a random guess, whether a given\nsample belongs to the dataset on which the attacked machine learning model was\ntrained. Several approaches have been developed to mitigate this privacy\nleakage but the tradeoff performance implications of these defensive mechanisms\n(i.e., accuracy and utility of the defended machine learning model) are not\nwell studied yet. We propose a novel approach of privacy leakage avoidance with\nswitching ensembles (PASE), which both protects against current membership\ninference attacks and does that with very small accuracy penalty, while\nrequiring acceptable increase in training and inference time. We test our PASE\nmethod, along with the the current state-of-the-art PATE approach, on three\ncalibration image datasets and analyze their tradeoffs.\n", "versions": [{"version": "v1", "created": "Mon, 18 Nov 2019 20:33:44 GMT"}], "update_date": "2019-11-20", "authors_parsed": [["Izmailov", "Rauf", ""], ["Lin", "Peter", ""], ["Mesterharm", "Chris", ""], ["Basu", "Samyadeep", ""]]}, {"id": "1911.07922", "submitter": "Marcus Bloice", "authors": "Marcus D. Bloice, Peter M. Roth, Andreas Holzinger", "title": "Patch augmentation: Towards efficient decision boundaries for neural\n  networks", "comments": "Version 2: updated author list, reduced abstract length, plots\n  consolidated as sub-plots", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we propose a new augmentation technique, called patch\naugmentation, that, in our experiments, improves model accuracy and makes\nnetworks more robust to adversarial attacks. In brief, this data-independent\napproach creates new image data based on image/label pairs, where a patch from\none of the two images in the pair is superimposed on to the other image,\ncreating a new augmented sample. The new image's label is a linear combination\nof the image pair's corresponding labels. Initial experiments show a several\npercentage point increase in accuracy on CIFAR-10, from a baseline of\napproximately 81% to 89%. CIFAR-100 sees larger improvements still, from a\nbaseline of 52% to 68% accuracy. Networks trained using patch augmentation are\nalso more robust to adversarial attacks, which we demonstrate using the Fast\nGradient Sign Method.\n", "versions": [{"version": "v1", "created": "Fri, 8 Nov 2019 07:11:31 GMT"}, {"version": "v2", "created": "Mon, 25 Nov 2019 14:05:08 GMT"}], "update_date": "2019-11-26", "authors_parsed": [["Bloice", "Marcus D.", ""], ["Roth", "Peter M.", ""], ["Holzinger", "Andreas", ""]]}, {"id": "1911.07925", "submitter": "Tianfu Li", "authors": "Tianfu Li, Zhibin Zhao, Chuang Sun, Li Cheng, Xuefeng Chen, Ruqiang\n  Yan, Robert X. Gao", "title": "WaveletKernelNet: An Interpretable Deep Neural Network for Industrial\n  Intelligent Diagnosis", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Convolutional neural network (CNN), with ability of feature learning and\nnonlinear mapping, has demonstrated its effectiveness in prognostics and health\nmanagement (PHM). However, explanation on the physical meaning of a CNN\narchitecture has rarely been studied. In this paper, a novel wavelet driven\ndeep neural network termed as WaveletKernelNet (WKN) is presented, where a\ncontinuous wavelet convolutional (CWConv) layer is designed to replace the\nfirst convolutional layer of the standard CNN. This enables the first CWConv\nlayer to discover more meaningful filters. Furthermore, only the scale\nparameter and translation parameter are directly learned from raw data at this\nCWConv layer. This provides a very effective way to obtain a customized filter\nbank, specifically tuned for extracting defect-related impact component\nembedded in the vibration signal. In addition, three experimental verification\nusing data from laboratory environment are carried out to verify effectiveness\nof the proposed method for mechanical fault diagnosis. The results show the\nimportance of the designed CWConv layer and the output of CWConv layer is\ninterpretable. Besides, it is found that WKN has fewer parameters, higher fault\nclassification accuracy and faster convergence speed than standard CNN.\n", "versions": [{"version": "v1", "created": "Tue, 12 Nov 2019 07:22:56 GMT"}, {"version": "v2", "created": "Sat, 23 Nov 2019 12:47:17 GMT"}, {"version": "v3", "created": "Wed, 6 May 2020 04:37:47 GMT"}], "update_date": "2020-05-07", "authors_parsed": [["Li", "Tianfu", ""], ["Zhao", "Zhibin", ""], ["Sun", "Chuang", ""], ["Cheng", "Li", ""], ["Chen", "Xuefeng", ""], ["Yan", "Ruqiang", ""], ["Gao", "Robert X.", ""]]}, {"id": "1911.07928", "submitter": "Wei Pang Xubu", "authors": "Wei Pang and Xiaojie Wang", "title": "Visual Dialogue State Tracking for Question Generation", "comments": "8 pages, 4 figures, Accept-Oral by AAAI-2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  GuessWhat?! is a visual dialogue task between a guesser and an oracle. The\nguesser aims to locate an object supposed by the oracle oneself in an image by\nasking a sequence of Yes/No questions. Asking proper questions with the\nprogress of dialogue is vital for achieving successful final guess. As a\nresult, the progress of dialogue should be properly represented and tracked.\nPrevious models for question generation pay less attention on the\nrepresentation and tracking of dialogue states, and therefore are prone to\nasking low quality questions such as repeated questions. This paper proposes\nvisual dialogue state tracking (VDST) based method for question generation. A\nvisual dialogue state is defined as the distribution on objects in the image as\nwell as representations of objects. Representations of objects are updated with\nthe change of the distribution on objects. An object-difference based attention\nis used to decode new question. The distribution on objects is updated by\ncomparing the question-answer pair and objects. Experimental results on\nGuessWhat?! dataset show that our model significantly outperforms existing\nmethods and achieves new state-of-the-art performance. It is also noticeable\nthat our model reduces the rate of repeated questions from more than 50% to\n21.9% compared with previous state-of-the-art methods.\n", "versions": [{"version": "v1", "created": "Tue, 12 Nov 2019 15:54:55 GMT"}, {"version": "v2", "created": "Mon, 25 Nov 2019 03:32:28 GMT"}], "update_date": "2019-11-26", "authors_parsed": [["Pang", "Wei", ""], ["Wang", "Xiaojie", ""]]}, {"id": "1911.07929", "submitter": "Jessica Velasco", "authors": "Jessica Velasco, Cherry Pascion, Jean Wilmar Alberio, Jonathan Apuang,\n  John Stephen Cruz, Mark Angelo Gomez, Benjamin Jr. Molina, Lyndon Tuala,\n  August Thio-ac and Romeo Jr. Jorda", "title": "A Smartphone-Based Skin Disease Classification Using MobileNet CNN", "comments": null, "journal-ref": "International Journal of Advanced Trends in Computer Science and\n  Engineering (2019) 2632-2637", "doi": "10.30534/ijatcse/2019/116852019", "report-no": null, "categories": "cs.CV cs.CY cs.LG eess.IV stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  The MobileNet model was used by applying transfer learning on the 7 skin\ndiseases to create a skin disease classification system on Android application.\nThe proponents gathered a total of 3,406 images and it is considered as\nimbalanced dataset because of the unequal number of images on its classes.\nUsing different sampling method and preprocessing of input data was explored to\nfurther improved the accuracy of the MobileNet. Using under-sampling method and\nthe default preprocessing of input data achieved an 84.28% accuracy. While,\nusing imbalanced dataset and default preprocessing of input data achieved a\n93.6% accuracy. Then, researchers explored oversampling the dataset and the\nmodel attained a 91.8% accuracy. Lastly, by using oversampling technique and\ndata augmentation on preprocessing the input data provide a 94.4% accuracy and\nthis model was deployed on the developed Android application.\n", "versions": [{"version": "v1", "created": "Wed, 13 Nov 2019 11:04:05 GMT"}], "update_date": "2019-11-20", "authors_parsed": [["Velasco", "Jessica", ""], ["Pascion", "Cherry", ""], ["Alberio", "Jean Wilmar", ""], ["Apuang", "Jonathan", ""], ["Cruz", "John Stephen", ""], ["Gomez", "Mark Angelo", ""], ["Molina", "Benjamin Jr.", ""], ["Tuala", "Lyndon", ""], ["Thio-ac", "August", ""], ["Jorda", "Romeo Jr.", ""]]}, {"id": "1911.07936", "submitter": "Efe Bozkir", "authors": "Efe Bozkir, Ali Burak \\\"Unal, Mete Akg\\\"un, Enkelejda Kasneci, Nico\n  Pfeifer", "title": "Privacy Preserving Gaze Estimation using Synthetic Images via a\n  Randomized Encoding Based Framework", "comments": "In Symposium on Eye Tracking Research and Applications (ETRA '20).\n  Authors' copy of the published paper, refer to the doi for the definitive\n  version", "journal-ref": null, "doi": "10.1145/3379156.3391364", "report-no": null, "categories": "cs.CV cs.CR cs.HC cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Eye tracking is handled as one of the key technologies for applications that\nassess and evaluate human attention, behavior, and biometrics, especially using\ngaze, pupillary, and blink behaviors. One of the challenges with regard to the\nsocial acceptance of eye tracking technology is however the preserving of\nsensitive and personal information. To tackle this challenge, we employ a\nprivacy-preserving framework based on randomized encoding to train a Support\nVector Regression model using synthetic eye images privately to estimate the\nhuman gaze. During the computation, none of the parties learn about the data or\nthe result that any other party has. Furthermore, the party that trains the\nmodel cannot reconstruct pupil, blinks or visual scanpath. The experimental\nresults show that our privacy-preserving framework is capable of working in\nreal-time, with the same accuracy as compared to non-private version and could\nbe extended to other eye tracking related problems.\n", "versions": [{"version": "v1", "created": "Wed, 6 Nov 2019 12:52:09 GMT"}, {"version": "v2", "created": "Wed, 5 Feb 2020 13:57:04 GMT"}, {"version": "v3", "created": "Mon, 6 Apr 2020 21:09:16 GMT"}, {"version": "v4", "created": "Tue, 13 Jul 2021 13:04:07 GMT"}], "update_date": "2021-07-14", "authors_parsed": [["Bozkir", "Efe", ""], ["\u00dcnal", "Ali Burak", ""], ["Akg\u00fcn", "Mete", ""], ["Kasneci", "Enkelejda", ""], ["Pfeifer", "Nico", ""]]}, {"id": "1911.07937", "submitter": "Talip Ucar", "authors": "Talip Ucar", "title": "Inverse Graphics: Unsupervised Learning of 3D Shapes from Single Images", "comments": "10 pages, 15 figures. In the second version of the paper, a link to a\n  demo site is added under Figure-12", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Using generative models for Inverse Graphics is an active area of research.\nHowever, most works focus on developing models for supervised and\nsemi-supervised methods. In this paper, we study the problem of unsupervised\nlearning of 3D geometry from single images. Our approach is to use a generative\nmodel that produces 2-D images as projections of a latent 3D voxel grid, which\nwe train either as a variational auto-encoder or using adversarial methods. Our\ncontributions are as follows: First, we show how to recover 3D shape and pose\nfrom general datasets such as MNIST, and MNIST Fashion in good quality. Second,\nwe compare the shapes learned using adversarial and variational methods.\nAdversarial approach gives denser 3D shapes. Third, we explore the idea of\nmodelling the pose of an object as uniform distribution to recover 3D shape\nfrom a single image. Our experiment with the CelebA dataset\n\\cite{liu2015faceattributes} proves that we can recover complete 3D shape from\na single image when the object is symmetric along one, or more axis whilst\nresults obtained using ModelNet40 \\cite{wu20153d} show the potential\nside-effects, in which the model learns 3D shapes such that it can render the\nsame image from any viewpoint. Forth, we present a general end-to-end approach\nto learning 3D shapes from single images in a completely unsupervised fashion\nby modelling the factors of variation such as azimuth as independent latent\nvariables. Our method makes no assumptions about the dataset, and can work with\nsynthetic as well as real images (i.e. unsupervised in true sense). We present\nour results, by training the model using the $\\mu$-VAE objective\n\\cite{ucar2019bridging} and a dataset combining all images from MNIST, MNIST\nFashion, CelebA and six categories of ModelNet40. The model is able to learn 3D\nshapes and the pose in qood quality and leverages information learned across\nall datasets.\n", "versions": [{"version": "v1", "created": "Thu, 31 Oct 2019 09:14:28 GMT"}, {"version": "v2", "created": "Mon, 2 Dec 2019 16:19:18 GMT"}], "update_date": "2019-12-03", "authors_parsed": [["Ucar", "Talip", ""]]}, {"id": "1911.07940", "submitter": "Phawis Thammasorn", "authors": "Phawis Thammasorn, Daniel Hippe, Wanpracha Chaovalitwongse, Matthew\n  Spraker, Landon Wootton, Matthew Nyflot, Stephanie Combs, Jan Peeken, Eric\n  Ford", "title": "Neighborhood Watch: Representation Learning with Local-Margin Triplet\n  Loss and Sampling Strategy for K-Nearest-Neighbor Image Classification", "comments": "Triplet Network, Representation Learning, Transfer Learning, Nearest\n  Neighbor, Medical Image Classification", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep representation learning using triplet network for classification suffers\nfrom a lack of theoretical foundation and difficulty in tuning both the network\nand classifiers for performance. To address the problem, local-margin triplet\nloss along with local positive and negative mining strategy is proposed with\ntheory on how the strategy integrate nearest-neighbor hyper-parameter with\ntriplet learning to increase subsequent classification performance. Results in\nexperiments with 2 public datasets, MNIST and Cifar-10, and 2 small medical\nimage datasets demonstrate that proposed strategy outperforms end-to-end\nsoftmax and typical triplet loss in settings without data augmentation while\nmaintaining utility of transferable feature for related tasks. The method\nserves as a good performance baseline where end-to-end methods encounter\ndifficulties such as small sample data with limited allowable data\naugmentation.\n", "versions": [{"version": "v1", "created": "Mon, 28 Oct 2019 06:35:01 GMT"}], "update_date": "2019-11-20", "authors_parsed": [["Thammasorn", "Phawis", ""], ["Hippe", "Daniel", ""], ["Chaovalitwongse", "Wanpracha", ""], ["Spraker", "Matthew", ""], ["Wootton", "Landon", ""], ["Nyflot", "Matthew", ""], ["Combs", "Stephanie", ""], ["Peeken", "Jan", ""], ["Ford", "Eric", ""]]}, {"id": "1911.07951", "submitter": "Scott Wisdom", "authors": "Efthymios Tzinis, Scott Wisdom, John R. Hershey, Aren Jansen, Daniel\n  P. W. Ellis", "title": "Improving Universal Sound Separation Using Sound Classification", "comments": null, "journal-ref": "ICASSP 2020 - 2020 IEEE International Conference on Acoustics,\n  Speech and Signal Processing (ICASSP)", "doi": "10.1109/ICASSP40776.2020.9053921", "report-no": null, "categories": "cs.SD cs.LG eess.AS stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep learning approaches have recently achieved impressive performance on\nboth audio source separation and sound classification. Most audio source\nseparation approaches focus only on separating sources belonging to a\nrestricted domain of source classes, such as speech and music. However, recent\nwork has demonstrated the possibility of \"universal sound separation\", which\naims to separate acoustic sources from an open domain, regardless of their\nclass. In this paper, we utilize the semantic information learned by sound\nclassifier networks trained on a vast amount of diverse sounds to improve\nuniversal sound separation. In particular, we show that semantic embeddings\nextracted from a sound classifier can be used to condition a separation\nnetwork, providing it with useful additional information. This approach is\nespecially useful in an iterative setup, where source estimates from an initial\nseparation stage and their corresponding classifier-derived embeddings are fed\nto a second separation network. By performing a thorough hyperparameter search\nconsisting of over a thousand experiments, we find that classifier embeddings\nfrom clean sources provide nearly one dB of SNR gain, and our best iterative\nmodels achieve a significant fraction of this oracle performance, establishing\na new state-of-the-art for universal sound separation.\n", "versions": [{"version": "v1", "created": "Mon, 18 Nov 2019 20:56:26 GMT"}], "update_date": "2021-05-14", "authors_parsed": [["Tzinis", "Efthymios", ""], ["Wisdom", "Scott", ""], ["Hershey", "John R.", ""], ["Jansen", "Aren", ""], ["Ellis", "Daniel P. W.", ""]]}, {"id": "1911.07953", "submitter": "Hakan Erdogan", "authors": "Zhong-Qiu Wang, Hakan Erdogan, Scott Wisdom, Kevin Wilson, Desh Raj,\n  Shinji Watanabe, Zhuo Chen, John R. Hershey", "title": "Sequential Multi-Frame Neural Beamforming for Speech Separation and\n  Enhancement", "comments": "7 pages, 7 figures, IEEE SLT 2021 (slt2020.org)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SD cs.LG eess.AS stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This work introduces sequential neural beamforming, which alternates between\nneural network based spectral separation and beamforming based spatial\nseparation. Our neural networks for separation use an advanced convolutional\narchitecture trained with a novel stabilized signal-to-noise ratio loss\nfunction. For beamforming, we explore multiple ways of computing time-varying\ncovariance matrices, including factorizing the spatial covariance into a\ntime-varying amplitude component and a time-invariant spatial component, as\nwell as using block-based techniques. In addition, we introduce a multi-frame\nbeamforming method which improves the results significantly by adding\ncontextual frames to the beamforming formulations. We extensively evaluate and\nanalyze the effects of window size, block size, and multi-frame context size\nfor these methods. Our best method utilizes a sequence of three neural\nseparation and multi-frame time-invariant spatial beamforming stages, and\ndemonstrates an average improvement of 2.75 dB in scale-invariant\nsignal-to-noise ratio and 14.2% absolute reduction in a comparative speech\nrecognition metric across four challenging reverberant speech enhancement and\nseparation tasks. We also use our three-speaker separation model to separate\nreal recordings in the LibriCSS evaluation set into non-overlapping tracks, and\nachieve a better word error rate as compared to a baseline mask based\nbeamformer.\n", "versions": [{"version": "v1", "created": "Mon, 18 Nov 2019 20:59:03 GMT"}, {"version": "v2", "created": "Tue, 19 May 2020 01:01:56 GMT"}, {"version": "v3", "created": "Tue, 3 Nov 2020 19:35:49 GMT"}], "update_date": "2020-11-05", "authors_parsed": [["Wang", "Zhong-Qiu", ""], ["Erdogan", "Hakan", ""], ["Wisdom", "Scott", ""], ["Wilson", "Kevin", ""], ["Raj", "Desh", ""], ["Watanabe", "Shinji", ""], ["Chen", "Zhuo", ""], ["Hershey", "John R.", ""]]}, {"id": "1911.07954", "submitter": "Patrick Hansen", "authors": "Patrick Hansen, Alexey Vilkin, Yury Khrustalev, James Imber, David\n  Hanwell, Matthew Mattina, Paul N. Whatmough", "title": "ISP4ML: Understanding the Role of Image Signal Processing in Efficient\n  Deep Learning Vision Systems", "comments": "13 pages, 11 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.IV cs.CV cs.LG", "license": "http://creativecommons.org/publicdomain/zero/1.0/", "abstract": "  Convolutional neural networks (CNNs) are now predominant components in a\nvariety of computer vision (CV) systems. These systems typically include an\nimage signal processor (ISP), even though the ISP is traditionally designed to\nproduce images that look appealing to humans. In CV systems, it is not clear\nwhat the role of the ISP is, or if it is even required at all for accurate\nprediction. In this work, we investigate the efficacy of the ISP in CNN\nclassification tasks, and outline the system-level trade-offs between\nprediction accuracy and computational cost. To do so, we build software models\nof a configurable ISP and an imaging sensor in order to train CNNs on ImageNet\nwith a range of different ISP settings and functionality. Results on ImageNet\nshow that an ISP improves accuracy by 4.6%-12.2% on MobileNet architectures of\ndifferent widths. Results using ResNets demonstrate that these trends also\ngeneralize to deeper networks. An ablation study of the various processing\nstages in a typical ISP reveals that the tone mapper is the most significant\nstage when operating on high dynamic range (HDR) images, by providing 5.8%\naverage accuracy improvement alone. Overall, the ISP benefits system efficiency\nbecause the memory and computational costs of the ISP is minimal compared to\nthe cost of using a larger CNN to achieve the same accuracy.\n", "versions": [{"version": "v1", "created": "Mon, 18 Nov 2019 21:05:44 GMT"}, {"version": "v2", "created": "Mon, 25 Nov 2019 16:14:25 GMT"}, {"version": "v3", "created": "Wed, 21 Oct 2020 19:49:15 GMT"}, {"version": "v4", "created": "Wed, 17 Mar 2021 15:15:35 GMT"}], "update_date": "2021-03-18", "authors_parsed": [["Hansen", "Patrick", ""], ["Vilkin", "Alexey", ""], ["Khrustalev", "Yury", ""], ["Imber", "James", ""], ["Hanwell", "David", ""], ["Mattina", "Matthew", ""], ["Whatmough", "Paul N.", ""]]}, {"id": "1911.07956", "submitter": "Xiaoixa Wu", "authors": "Xiaoxia Wu and Edgar Dobriban and Tongzheng Ren and Shanshan Wu and\n  Zhiyuan Li and Suriya Gunasekar and Rachel Ward and Qiang Liu", "title": "Implicit Regularization and Convergence for Weight Normalization", "comments": "NeurIPS 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV math.OC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Normalization methods such as batch [Ioffe and Szegedy, 2015], weight\n[Salimansand Kingma, 2016], instance [Ulyanov et al., 2016], and layer\nnormalization [Baet al., 2016] have been widely used in modern machine\nlearning. Here, we study the weight normalization (WN) method [Salimans and\nKingma, 2016] and a variant called reparametrized projected gradient descent\n(rPGD) for overparametrized least-squares regression. WN and rPGD reparametrize\nthe weights with a scale g and a unit vector w and thus the objective function\nbecomes non-convex. We show that this non-convex formulation has beneficial\nregularization effects compared to gradient descent on the original objective.\nThese methods adaptively regularize the weights and converge close to the\nminimum l2 norm solution, even for initializations far from zero. For certain\nstepsizes of g and w , we show that they can converge close to the minimum norm\nsolution. This is different from the behavior of gradient descent, which\nconverges to the minimum norm solution only when started at a point in the\nrange space of the feature matrix, and is thus more sensitive to\ninitialization.\n", "versions": [{"version": "v1", "created": "Mon, 18 Nov 2019 21:10:21 GMT"}, {"version": "v2", "created": "Sat, 23 Nov 2019 04:36:05 GMT"}, {"version": "v3", "created": "Mon, 19 Oct 2020 06:05:43 GMT"}, {"version": "v4", "created": "Mon, 7 Dec 2020 19:09:58 GMT"}], "update_date": "2020-12-09", "authors_parsed": [["Wu", "Xiaoxia", ""], ["Dobriban", "Edgar", ""], ["Ren", "Tongzheng", ""], ["Wu", "Shanshan", ""], ["Li", "Zhiyuan", ""], ["Gunasekar", "Suriya", ""], ["Ward", "Rachel", ""], ["Liu", "Qiang", ""]]}, {"id": "1911.07963", "submitter": "Ziteng Sun", "authors": "Ziteng Sun, Peter Kairouz, Ananda Theertha Suresh, H. Brendan McMahan", "title": "Can You Really Backdoor Federated Learning?", "comments": "To appear at the 2nd International Workshop on Federated Learning for\n  Data Privacy and Confidentiality at NeurIPS 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The decentralized nature of federated learning makes detecting and defending\nagainst adversarial attacks a challenging task. This paper focuses on backdoor\nattacks in the federated learning setting, where the goal of the adversary is\nto reduce the performance of the model on targeted tasks while maintaining good\nperformance on the main task. Unlike existing works, we allow non-malicious\nclients to have correctly labeled samples from the targeted tasks. We conduct a\ncomprehensive study of backdoor attacks and defenses for the EMNIST dataset, a\nreal-life, user-partitioned, and non-iid dataset. We observe that in the\nabsence of defenses, the performance of the attack largely depends on the\nfraction of adversaries present and the \"complexity'' of the targeted task.\nMoreover, we show that norm clipping and \"weak'' differential privacy mitigate\nthe attacks without hurting the overall performance. We have implemented the\nattacks and defenses in TensorFlow Federated (TFF), a TensorFlow framework for\nfederated learning. In open-sourcing our code, our goal is to encourage\nresearchers to contribute new attacks and defenses and evaluate them on\nstandard federated datasets.\n", "versions": [{"version": "v1", "created": "Mon, 18 Nov 2019 21:25:03 GMT"}, {"version": "v2", "created": "Mon, 2 Dec 2019 19:00:11 GMT"}], "update_date": "2019-12-04", "authors_parsed": [["Sun", "Ziteng", ""], ["Kairouz", "Peter", ""], ["Suresh", "Ananda Theertha", ""], ["McMahan", "H. Brendan", ""]]}, {"id": "1911.07964", "submitter": "Kyle Helfrich", "authors": "Kyle Helfrich and Qiang Ye", "title": "Eigenvalue Normalized Recurrent Neural Networks for Short Term Memory", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Several variants of recurrent neural networks (RNNs) with orthogonal or\nunitary recurrent matrices have recently been developed to mitigate the\nvanishing/exploding gradient problem and to model long-term dependencies of\nsequences. However, with the eigenvalues of the recurrent matrix on the unit\ncircle, the recurrent state retains all input information which may\nunnecessarily consume model capacity. In this paper, we address this issue by\nproposing an architecture that expands upon an orthogonal/unitary RNN with a\nstate that is generated by a recurrent matrix with eigenvalues in the unit\ndisc. Any input to this state dissipates in time and is replaced with new\ninputs, simulating short-term memory. A gradient descent algorithm is derived\nfor learning such a recurrent matrix. The resulting method, called the\nEigenvalue Normalized RNN (ENRNN), is shown to be highly competitive in several\nexperiments.\n", "versions": [{"version": "v1", "created": "Mon, 18 Nov 2019 21:28:02 GMT"}], "update_date": "2019-11-20", "authors_parsed": [["Helfrich", "Kyle", ""], ["Ye", "Qiang", ""]]}, {"id": "1911.07967", "submitter": "Abdul Dakkak", "authors": "Cheng Li, Abdul Dakkak, Jinjun Xiong, Wen-mei Hwu", "title": "DLBricks: Composable Benchmark Generation to Reduce Deep Learning\n  Benchmarking Effort on CPUs (Extended)", "comments": null, "journal-ref": null, "doi": "10.1145/3358960.3379143", "report-no": null, "categories": "cs.LG cs.PF cs.SE stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  The past few years have seen a surge of applying Deep Learning (DL) models\nfor a wide array of tasks such as image classification, object detection,\nmachine translation, etc. While DL models provide an opportunity to solve\notherwise intractable tasks, their adoption relies on them being optimized to\nmeet latency and resource requirements. Benchmarking is a key step in this\nprocess but has been hampered in part due to the lack of representative and\nup-to-date benchmarking suites. This is exacerbated by the fast-evolving pace\nof DL models.\n  This paper proposes DLBricks, a composable benchmark generation design that\nreduces the effort of developing, maintaining, and running DL benchmarks on\nCPUs. DLBricks decomposes DL models into a set of unique runnable networks and\nconstructs the original model's performance using the performance of the\ngenerated benchmarks. DLBricks leverages two key observations: DL layers are\nthe performance building blocks of DL models and layers are extensively\nrepeated within and across DL models. Since benchmarks are generated\nautomatically and the benchmarking time is minimized, DLBricks can keep\nup-to-date with the latest proposed models, relieving the pressure of selecting\nrepresentative DL models. Moreover, DLBricks allows users to represent\nproprietary models within benchmark suites. We evaluate DLBricks using $50$\nMXNet models spanning $5$ DL tasks on $4$ representative CPU systems. We show\nthat DLBricks provides an accurate performance estimate for the DL models and\nreduces the benchmarking time across systems (e.g. within $95\\%$ accuracy and\nup to $4.4\\times$ benchmarking time speedup on Amazon EC2 c5.xlarge).\n", "versions": [{"version": "v1", "created": "Mon, 18 Nov 2019 21:42:36 GMT"}, {"version": "v2", "created": "Wed, 20 Nov 2019 15:51:05 GMT"}, {"version": "v3", "created": "Wed, 11 Mar 2020 16:51:34 GMT"}], "update_date": "2021-03-02", "authors_parsed": [["Li", "Cheng", ""], ["Dakkak", "Abdul", ""], ["Xiong", "Jinjun", ""], ["Hwu", "Wen-mei", ""]]}, {"id": "1911.07970", "submitter": "George Kesidis", "authors": "Zhen Xiang, David J. Miller, George Kesidis", "title": "Revealing Perceptible Backdoors, without the Training Set, via the\n  Maximum Achievable Misclassification Fraction Statistic", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recently, a backdoor data poisoning attack was proposed, which adds\nmislabeled examples to the training set, with an embedded backdoor pattern,\naiming to have the classifier learn to classify to a target class whenever the\nbackdoor pattern is present in a test sample. Here, we address post-training\ndetection of innocuous perceptible backdoors in DNN image classifiers, wherein\nthe defender does not have access to the poisoned training set, but only to the\ntrained classifier, as well as unpoisoned examples. This problem is challenging\nbecause without the poisoned training set, we have no hint about the actual\nbackdoor pattern used during training. This post-training scenario is also of\ngreat import because in many practical contexts the DNN user did not train the\nDNN and does not have access to the training data. We identify two important\nproperties of perceptible backdoor patterns - spatial invariance and robustness\n- based upon which we propose a novel detector using the maximum achievable\nmisclassification fraction (MAMF) statistic. We detect whether the trained DNN\nhas been backdoor-attacked and infer the source and target classes. Our\ndetector outperforms other existing detectors and, coupled with an\nimperceptible backdoor detector, helps achieve post-training detection of all\nevasive backdoors.\n", "versions": [{"version": "v1", "created": "Mon, 18 Nov 2019 21:44:27 GMT"}, {"version": "v2", "created": "Mon, 6 Apr 2020 15:19:35 GMT"}], "update_date": "2020-04-07", "authors_parsed": [["Xiang", "Zhen", ""], ["Miller", "David J.", ""], ["Kesidis", "George", ""]]}, {"id": "1911.07971", "submitter": "Raj Kumar Maity", "authors": "Venkata Gandikota, Daniel Kane, Raj Kumar Maity, Arya Mazumdar", "title": "vqSGD: Vector Quantized Stochastic Gradient Descent", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.DC cs.IT math.IT stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this work, we present a family of vector quantization schemes \\emph{vqSGD}\n(Vector-Quantized Stochastic Gradient Descent) that provide an asymptotic\nreduction in the communication cost with convergence guarantees in first-order\ndistributed optimization. In the process we derive the following fundamental\ninformation theoretic fact: $\\Theta(\\frac{d}{R^2})$ bits are necessary and\nsufficient to describe an unbiased estimator ${\\hat{g}}({g})$ for any ${g}$ in\nthe $d$-dimensional unit sphere, under the constraint that\n$\\|{\\hat{g}}({g})\\|_2\\le R$ almost surely. In particular, we consider a\nrandomized scheme based on the convex hull of a point set, that returns an\nunbiased estimator of a $d$-dimensional gradient vector with almost surely\nbounded norm. We provide multiple efficient instances of our scheme, that are\nnear optimal, and require only $o(d)$ bits of communication at the expense of\ntolerable increase in error. The instances of our quantization scheme are\nobtained using the properties of binary error-correcting codes and provide a\nsmooth tradeoff between the communication and the estimation error of\nquantization. Furthermore, we show that \\emph{vqSGD} also offers strong privacy\nguarantees.\n", "versions": [{"version": "v1", "created": "Mon, 18 Nov 2019 21:48:01 GMT"}, {"version": "v2", "created": "Sun, 9 Feb 2020 18:22:02 GMT"}, {"version": "v3", "created": "Fri, 12 Jun 2020 09:18:41 GMT"}, {"version": "v4", "created": "Thu, 24 Dec 2020 21:07:55 GMT"}], "update_date": "2020-12-29", "authors_parsed": [["Gandikota", "Venkata", ""], ["Kane", "Daniel", ""], ["Maity", "Raj Kumar", ""], ["Mazumdar", "Arya", ""]]}, {"id": "1911.07976", "submitter": "Sourbh Bhadane", "authors": "Jayadev Acharya, Sourbh Bhadane, Piotr Indyk, Ziteng Sun", "title": "Estimating Entropy of Distributions in Constant Space", "comments": "NeurIPS 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IT cs.DS cs.LG math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the task of estimating the entropy of $k$-ary distributions from\nsamples in the streaming model, where space is limited. Our main contribution\nis an algorithm that requires $O\\left(\\frac{k \\log\n(1/\\varepsilon)^2}{\\varepsilon^3}\\right)$ samples and a constant $O(1)$ memory\nwords of space and outputs a $\\pm\\varepsilon$ estimate of $H(p)$. Without space\nlimitations, the sample complexity has been established as\n$S(k,\\varepsilon)=\\Theta\\left(\\frac k{\\varepsilon\\log k}+\\frac{\\log^2\nk}{\\varepsilon^2}\\right)$, which is sub-linear in the domain size $k$, and the\ncurrent algorithms that achieve optimal sample complexity also require\nnearly-linear space in $k$.\n  Our algorithm partitions $[0,1]$ into intervals and estimates the entropy\ncontribution of probability values in each interval. The intervals are designed\nto trade off the bias and variance of these estimates.\n", "versions": [{"version": "v1", "created": "Mon, 18 Nov 2019 21:54:59 GMT"}], "update_date": "2019-11-20", "authors_parsed": [["Acharya", "Jayadev", ""], ["Bhadane", "Sourbh", ""], ["Indyk", "Piotr", ""], ["Sun", "Ziteng", ""]]}, {"id": "1911.07979", "submitter": "Ekagra Ranjan", "authors": "Ekagra Ranjan, Soumya Sanyal, Partha Pratim Talukdar", "title": "ASAP: Adaptive Structure Aware Pooling for Learning Hierarchical Graph\n  Representations", "comments": "The Thirty-Fourth AAAI Conference on Artificial Intelligence (AAAI\n  2020)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Graph Neural Networks (GNN) have been shown to work effectively for modeling\ngraph structured data to solve tasks such as node classification, link\nprediction and graph classification. There has been some recent progress in\ndefining the notion of pooling in graphs whereby the model tries to generate a\ngraph level representation by downsampling and summarizing the information\npresent in the nodes. Existing pooling methods either fail to effectively\ncapture the graph substructure or do not easily scale to large graphs. In this\nwork, we propose ASAP (Adaptive Structure Aware Pooling), a sparse and\ndifferentiable pooling method that addresses the limitations of previous graph\npooling architectures. ASAP utilizes a novel self-attention network along with\na modified GNN formulation to capture the importance of each node in a given\ngraph. It also learns a sparse soft cluster assignment for nodes at each layer\nto effectively pool the subgraphs to form the pooled graph. Through extensive\nexperiments on multiple datasets and theoretical analysis, we motivate our\nchoice of the components used in ASAP. Our experimental results show that\ncombining existing GNN architectures with ASAP leads to state-of-the-art\nresults on multiple graph classification benchmarks. ASAP has an average\nimprovement of 4%, compared to current sparse hierarchical state-of-the-art\nmethod.\n", "versions": [{"version": "v1", "created": "Mon, 18 Nov 2019 22:04:52 GMT"}, {"version": "v2", "created": "Sun, 26 Jan 2020 13:33:17 GMT"}, {"version": "v3", "created": "Sun, 2 Feb 2020 12:53:57 GMT"}], "update_date": "2020-02-04", "authors_parsed": [["Ranjan", "Ekagra", ""], ["Sanyal", "Soumya", ""], ["Talukdar", "Partha Pratim", ""]]}, {"id": "1911.07982", "submitter": "Qian Wang", "authors": "Qian Wang, Toby P. Breckon", "title": "Unsupervised Domain Adaptation via Structured Prediction Based Selective\n  Pseudo-Labeling", "comments": "Accepted to AAAI 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV cs.MM stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Unsupervised domain adaptation aims to address the problem of classifying\nunlabeled samples from the target domain whilst labeled samples are only\navailable from the source domain and the data distributions are different in\nthese two domains. As a result, classifiers trained from labeled samples in the\nsource domain suffer from significant performance drop when directly applied to\nthe samples from the target domain. To address this issue, different approaches\nhave been proposed to learn domain-invariant features or domain-specific\nclassifiers. In either case, the lack of labeled samples in the target domain\ncan be an issue which is usually overcome by pseudo-labeling. Inaccurate\npseudo-labeling, however, could result in catastrophic error accumulation\nduring learning. In this paper, we propose a novel selective pseudo-labeling\nstrategy based on structured prediction. The idea of structured prediction is\ninspired by the fact that samples in the target domain are well clustered\nwithin the deep feature space so that unsupervised clustering analysis can be\nused to facilitate accurate pseudo-labeling. Experimental results on four\ndatasets (i.e. Office-Caltech, Office31, ImageCLEF-DA and Office-Home) validate\nour approach outperforms contemporary state-of-the-art methods.\n", "versions": [{"version": "v1", "created": "Mon, 18 Nov 2019 22:21:47 GMT"}], "update_date": "2019-11-20", "authors_parsed": [["Wang", "Qian", ""], ["Breckon", "Toby P.", ""]]}, {"id": "1911.07984", "submitter": "Shivam Kalra", "authors": "Shivam Kalra, Mohammed Adnan, Graham Taylor, Hamid Tizhoosh", "title": "Learning Permutation Invariant Representations using Memory Networks", "comments": "Accepted at ECCV 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Many real-world tasks such as classification of digital histopathology images\nand 3D object detection involve learning from a set of instances. In these\ncases, only a group of instances or a set, collectively, contains meaningful\ninformation and therefore only the sets have labels, and not individual data\ninstances. In this work, we present a permutation invariant neural network\ncalled Memory-based Exchangeable Model (MEM) for learning set functions. The\nMEM model consists of memory units that embed an input sequence to high-level\nfeatures enabling the model to learn inter-dependencies among instances through\na self-attention mechanism. We evaluated the learning ability of MEM on various\ntoy datasets, point cloud classification, and classification of lung whole\nslide images (WSIs) into two subtypes of lung cancer---Lung Adenocarcinoma, and\nLung Squamous Cell Carcinoma. We systematically extracted patches from lung\nWSIs downloaded from The Cancer Genome Atlas~(TCGA) dataset, the largest public\nrepository of WSIs, achieving a competitive accuracy of 84.84\\% for\nclassification of two sub-types of lung cancer. The results on other datasets\nare promising as well, and demonstrate the efficacy of our model.\n", "versions": [{"version": "v1", "created": "Mon, 18 Nov 2019 22:28:30 GMT"}, {"version": "v2", "created": "Fri, 3 Jul 2020 16:27:23 GMT"}], "update_date": "2020-07-06", "authors_parsed": [["Kalra", "Shivam", ""], ["Adnan", "Mohammed", ""], ["Taylor", "Graham", ""], ["Tizhoosh", "Hamid", ""]]}, {"id": "1911.07989", "submitter": "Micah Goldblum", "authors": "Ping-Yeh Chiang, Jonas Geiping, Micah Goldblum, Tom Goldstein, Renkun\n  Ni, Steven Reich, Ali Shafahi", "title": "WITCHcraft: Efficient PGD attacks with random step size", "comments": "Authors contributed equally and are listed in alphabetical order", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR cs.CV eess.SP stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  State-of-the-art adversarial attacks on neural networks use expensive\niterative methods and numerous random restarts from different initial points.\nIterative FGSM-based methods without restarts trade off performance for\ncomputational efficiency because they do not adequately explore the image space\nand are highly sensitive to the choice of step size. We propose a variant of\nProjected Gradient Descent (PGD) that uses a random step size to improve\nperformance without resorting to expensive random restarts. Our method, Wide\nIterative Stochastic crafting (WITCHcraft), achieves results superior to the\nclassical PGD attack on the CIFAR-10 and MNIST data sets but without additional\ncomputational cost. This simple modification of PGD makes crafting attacks more\neconomical, which is important in situations like adversarial training where\nattacks need to be crafted in real time.\n", "versions": [{"version": "v1", "created": "Mon, 18 Nov 2019 22:40:08 GMT"}], "update_date": "2019-11-20", "authors_parsed": [["Chiang", "Ping-Yeh", ""], ["Geiping", "Jonas", ""], ["Goldblum", "Micah", ""], ["Goldstein", "Tom", ""], ["Ni", "Renkun", ""], ["Reich", "Steven", ""], ["Shafahi", "Ali", ""]]}, {"id": "1911.07990", "submitter": "Qian Wang", "authors": "Qian Wang, Toby P. Breckon", "title": "Crowd Counting via Segmentation Guided Attention Networks and Curriculum\n  Loss", "comments": "Technical Report, Durham University", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG cs.MM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Automatic crowd behaviour analysis is an important task for intelligent\ntransportation systems to enable effective flow control and dynamic route\nplanning for varying road participants. Crowd counting is one of the keys to\nautomatic crowd behaviour analysis. Crowd counting using deep convolutional\nneural networks (CNN) has achieved encouraging progress in recent years.\nResearchers have devoted much effort to the design of variant CNN architectures\nand most of them are based on the pre-trained VGG16 model. Due to the\ninsufficient expressive capacity, the backbone network of VGG16 is usually\nfollowed by another cumbersome network specially designed for good counting\nperformance. Although VGG models have been outperformed by Inception models in\nimage classification tasks, the existing crowd counting networks built with\nInception modules still only have a small number of layers with basic types of\nInception modules. To fill in this gap, in this paper, we firstly benchmark the\nbaseline Inception-v3 model on commonly used crowd counting datasets and\nachieve surprisingly good performance comparable with or better than most\nexisting crowd counting models. Subsequently, we push the boundary of this\ndisruptive work further by proposing a Segmentation Guided Attention Network\n(SGANet) with Inception-v3 as the backbone and a novel curriculum loss for\ncrowd counting. We conduct thorough experiments to compare the performance of\nour SGANet with prior arts and the proposed model can achieve state-of-the-art\nperformance with MAE of 57.6, 6.3 and 87.6 on ShanghaiTechA, ShanghaiTechB and\nUCF\\_QNRF, respectively.\n", "versions": [{"version": "v1", "created": "Mon, 18 Nov 2019 22:40:13 GMT"}, {"version": "v2", "created": "Mon, 3 Aug 2020 21:06:44 GMT"}], "update_date": "2020-08-05", "authors_parsed": [["Wang", "Qian", ""], ["Breckon", "Toby P.", ""]]}, {"id": "1911.08004", "submitter": "Dana Yang", "authors": "Jian Ding, Yihong Wu, Jiaming Xu, and Dana Yang", "title": "Consistent recovery threshold of hidden nearest neighbor graphs", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.LG cs.SI math.ST stat.ML stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Motivated by applications such as discovering strong ties in social networks\nand assembling genome subsequences in biology, we study the problem of\nrecovering a hidden $2k$-nearest neighbor (NN) graph in an $n$-vertex complete\ngraph, whose edge weights are independent and distributed according to $P_n$\nfor edges in the hidden $2k$-NN graph and $Q_n$ otherwise. The special case of\nBernoulli distributions corresponds to a variant of the Watts-Strogatz\nsmall-world graph. We focus on two types of asymptotic recovery guarantees as\n$n\\to \\infty$: (1) exact recovery: all edges are classified correctly with\nprobability tending to one; (2) almost exact recovery: the expected number of\nmisclassified edges is $o(nk)$. We show that the maximum likelihood estimator\nachieves (1) exact recovery for $2 \\le k \\le n^{o(1)}$ if $ \\liminf\n\\frac{2\\alpha_n}{\\log n}>1$; (2) almost exact recovery for $ 1 \\le k \\le\no\\left( \\frac{\\log n}{\\log \\log n} \\right)$ if $\\liminf\n\\frac{kD(P_n||Q_n)}{\\log n}>1$, where $\\alpha_n \\triangleq -2 \\log \\int \\sqrt{d\nP_n d Q_n}$ is the R\\'enyi divergence of order $\\frac{1}{2}$ and $D(P_n||Q_n)$\nis the Kullback-Leibler divergence. Under mild distributional assumptions,\nthese conditions are shown to be information-theoretically necessary for any\nalgorithm to succeed. A key challenge in the analysis is the enumeration of\n$2k$-NN graphs that differ from the hidden one by a given number of edges.\n", "versions": [{"version": "v1", "created": "Mon, 18 Nov 2019 23:44:54 GMT"}], "update_date": "2019-11-21", "authors_parsed": [["Ding", "Jian", ""], ["Wu", "Yihong", ""], ["Xu", "Jiaming", ""], ["Yang", "Dana", ""]]}, {"id": "1911.08009", "submitter": "Nuwanthika Rajapaksha", "authors": "Nuwanthika Rajapaksha, Nandana Rajatheva, Matti Latva-aho", "title": "Low Complexity Autoencoder based End-to-End Learning of Coded\n  Communications Systems", "comments": "Submitted to VTC2020-Spring", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IT cs.LG eess.SP math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  End-to-end learning of a communications system using the deep learning-based\nautoencoder concept has drawn interest in recent research due to its\nsimplicity, flexibility and its potential of adapting to complex channel models\nand practical system imperfections. In this paper, we have compared the bit\nerror rate (BER) performance of autoencoder based systems and conventional\nchannel coded systems with convolutional coding (CC), in order to understand\nthe potential of deep learning-based systems as alternatives to conventional\nsystems. From the simulations, autoencoder implementation was observed to have\na better BER in 0-5 dB $E_{b}/N_{0}$ range than its equivalent half-rate\nconvolutional coded BPSK with hard decision decoding, and to have only less\nthan 1 dB gap at a BER of $10^{-5}$. Furthermore, we have also proposed a novel\nlow complexity autoencoder architecture to implement end-to-end learning of\ncoded systems in which we have shown better BER performance than the baseline\nimplementation. The newly proposed low complexity autoencoder was capable of\nachieving a better BER performance than half-rate 16-QAM with hard decision\ndecoding over the full 0-10 dB $E_{b}/N_{0}$ range and a better BER performance\nthan the soft decision decoding in 0-4 dB $E_{b}/N_{0}$ range.\n", "versions": [{"version": "v1", "created": "Tue, 19 Nov 2019 00:04:29 GMT"}, {"version": "v2", "created": "Mon, 20 Jan 2020 17:29:32 GMT"}], "update_date": "2020-01-22", "authors_parsed": [["Rajapaksha", "Nuwanthika", ""], ["Rajatheva", "Nandana", ""], ["Latva-aho", "Matti", ""]]}, {"id": "1911.08010", "submitter": "Daouda Diouf Dr", "authors": "Daouda Diouf, Djibril Seck, Mountaga Diop and Abdoulye Ba", "title": "Convolutional Neural Network and decision support in medical imaging:\n  case study of the recognition of blood cell subtypes", "comments": "7 pages, 6 figures, 1 table", "journal-ref": "CEUR-WS.org/Vol-2647 (2019), pp. 128-140", "doi": null, "report-no": "ISSN 1613-0073", "categories": "eess.IV cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Identifying and characterizing the patient's blood samples is indispensable\nin diagnostics of malignance suspicious. A painstaking and sometimes subjective\ntask is used in laboratories to manually classify white blood cells. Neural\nmathematical methods as deep learnings can be very useful in the automated\nrecognition of blood cells. This study uses a particular type of deep learning\ni.e., convolutional neural networks (CNNs or ConvNets) for image recognition of\nthe four (4) blood cell types (neutrophil, eosinophil, lymphocyte and monocyte)\nand to enable it to tag them employing a dataset of blood cells with labels for\nthe corresponding cell types. The elements of the database are the input of our\nCNN and they allowed us to create learning models for the image\nrecognition/classification of the blood cells. We evaluated the recognition\nperformance and outputs learned by the networks in order to implement a neural\nimage recognition model capable of distinguishing polynuclear cells (neutrophil\nand eosinophil) from those of mononuclear cells (lymphocyte and monocyte). The\nvalidation accuracy is 97.77%.\n", "versions": [{"version": "v1", "created": "Tue, 19 Nov 2019 00:10:41 GMT"}, {"version": "v2", "created": "Thu, 22 Oct 2020 01:11:47 GMT"}], "update_date": "2020-10-23", "authors_parsed": [["Diouf", "Daouda", ""], ["Seck", "Djibril", ""], ["Diop", "Mountaga", ""], ["Ba", "Abdoulye", ""]]}, {"id": "1911.08011", "submitter": "Iman Niazazari", "authors": "Iman Niazazari, Hanif Livani", "title": "Attack on Grid Event Cause Analysis: An Adversarial Machine Learning\n  Approach", "comments": "5 pages, 4 figures, IEEE Innovative Smart Grid Technologies North\n  American 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG eess.SP stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  With the ever-increasing reliance on data for data-driven applications in\npower grids, such as event cause analysis, the authenticity of data streams has\nbecome crucially important. The data can be prone to adversarial stealthy\nattacks aiming to manipulate the data such that residual-based bad data\ndetectors cannot detect them, and the perception of system operators or event\nclassifiers changes about the actual event. This paper investigates the impact\nof adversarial attacks on convolutional neural network-based event cause\nanalysis frameworks. We have successfully verified the ability of adversaries\nto maliciously misclassify events through stealthy data manipulations. The\nvulnerability assessment is studied with respect to the number of compromised\nmeasurements. Furthermore, a defense mechanism to robustify the performance of\nthe event cause analysis is proposed. The effectiveness of adversarial attacks\non changing the output of the framework is studied using the data generated by\nreal-time digital simulator (RTDS) under different scenarios such as type of\nattacks and level of access to data.\n", "versions": [{"version": "v1", "created": "Tue, 19 Nov 2019 00:14:54 GMT"}, {"version": "v2", "created": "Mon, 25 Nov 2019 06:05:27 GMT"}], "update_date": "2019-11-26", "authors_parsed": [["Niazazari", "Iman", ""], ["Livani", "Hanif", ""]]}, {"id": "1911.08017", "submitter": "Neale Ratzlaff", "authors": "Neale Ratzlaff, Qinxun Bai, Li Fuxin, Wei Xu", "title": "Implicit Generative Modeling for Efficient Exploration", "comments": "14 pages, 9 figures, Accepted to ICML 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Efficient exploration remains a challenging problem in reinforcement\nlearning, especially for those tasks where rewards from environments are\nsparse. A commonly used approach for exploring such environments is to\nintroduce some \"intrinsic\" reward. In this work, we focus on model uncertainty\nestimation as an intrinsic reward for efficient exploration. In particular, we\nintroduce an implicit generative modeling approach to estimate a Bayesian\nuncertainty of the agent's belief of the environment dynamics. Each random draw\nfrom our generative model is a neural network that instantiates the dynamic\nfunction, hence multiple draws would approximate the posterior, and the\nvariance in the future prediction based on this posterior is used as an\nintrinsic reward for exploration. We design a training algorithm for our\ngenerative model based on the amortized Stein Variational Gradient Descent. In\nexperiments, we compare our implementation with state-of-the-art intrinsic\nreward-based exploration approaches, including two recent approaches based on\nan ensemble of dynamic models. In challenging exploration tasks, our implicit\ngenerative model consistently outperforms competing approaches regarding data\nefficiency in exploration.\n", "versions": [{"version": "v1", "created": "Tue, 19 Nov 2019 00:37:23 GMT"}, {"version": "v2", "created": "Wed, 26 Feb 2020 20:56:10 GMT"}, {"version": "v3", "created": "Tue, 14 Jul 2020 19:21:32 GMT"}], "update_date": "2020-07-16", "authors_parsed": [["Ratzlaff", "Neale", ""], ["Bai", "Qinxun", ""], ["Fuxin", "Li", ""], ["Xu", "Wei", ""]]}, {"id": "1911.08019", "submitter": "Eugene Belilovsky", "authors": "Lucas Caccia, Eugene Belilovsky, Massimo Caccia, Joelle Pineau", "title": "Online Learned Continual Compression with Adaptive Quantization Modules", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce and study the problem of Online Continual Compression, where one\nattempts to simultaneously learn to compress and store a representative dataset\nfrom a non i.i.d data stream, while only observing each sample once. A naive\napplication of auto-encoders in this setting encounters a major challenge:\nrepresentations derived from earlier encoder states must be usable by later\ndecoder states. We show how to use discrete auto-encoders to effectively\naddress this challenge and introduce Adaptive Quantization Modules (AQM) to\ncontrol variation in the compression ability of the module at any given stage\nof learning. This enables selecting an appropriate compression for incoming\nsamples, while taking into account overall memory constraints and current\nprogress of the learned compression. Unlike previous methods, our approach does\nnot require any pretraining, even on challenging datasets. We show that using\nAQM to replace standard episodic memory in continual learning settings leads to\nsignificant gains on continual learning benchmarks. Furthermore we demonstrate\nthis approach with larger images, LiDAR, and reinforcement learning\nenvironments.\n", "versions": [{"version": "v1", "created": "Tue, 19 Nov 2019 00:43:16 GMT"}, {"version": "v2", "created": "Thu, 12 Mar 2020 00:23:18 GMT"}, {"version": "v3", "created": "Thu, 20 Aug 2020 19:19:56 GMT"}], "update_date": "2020-08-24", "authors_parsed": [["Caccia", "Lucas", ""], ["Belilovsky", "Eugene", ""], ["Caccia", "Massimo", ""], ["Pineau", "Joelle", ""]]}, {"id": "1911.08020", "submitter": "Ao Ren", "authors": "Ao Ren, Tao Zhang, Yuhao Wang, Sheng Lin, Peiyan Dong, Yen-kuang Chen,\n  Yuan Xie, Yanzhi Wang", "title": "DARB: A Density-Aware Regular-Block Pruning for Deep Neural Networks", "comments": "This paper has been accepted by AAAI'2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The rapidly growing parameter volume of deep neural networks (DNNs) hinders\nthe artificial intelligence applications on resource constrained devices, such\nas mobile and wearable devices. Neural network pruning, as one of the\nmainstream model compression techniques, is under extensive study to reduce the\nnumber of parameters and computations. In contrast to irregular pruning that\nincurs high index storage and decoding overhead, structured pruning techniques\nhave been proposed as the promising solutions. However, prior studies on\nstructured pruning tackle the problem mainly from the perspective of\nfacilitating hardware implementation, without analyzing the characteristics of\nsparse neural networks. The neglect on the study of sparse neural networks\ncauses inefficient trade-off between regularity and pruning ratio.\nConsequently, the potential of structurally pruning neural networks is not\nsufficiently mined.\n  In this work, we examine the structural characteristics of the irregularly\npruned weight matrices, such as the diverse redundancy of different rows, the\nsensitivity of different rows to pruning, and the positional characteristics of\nretained weights. By leveraging the gained insights as a guidance, we first\npropose the novel block-max weight masking (BMWM) method, which can effectively\nretain the salient weights while imposing high regularity to the weight matrix.\nAs a further optimization, we propose a density-adaptive regular-block (DARB)\npruning that outperforms prior structured pruning work with high pruning ratio\nand decoding efficiency. Our experimental results show that DARB can achieve\n13$\\times$ to 25$\\times$ pruning ratio, which are 2.8$\\times$ to 4.3$\\times$\nimprovements than the state-of-the-art counterparts on multiple neural network\nmodels and tasks. Moreover, DARB can achieve 14.3$\\times$ decoding efficiency\nthan block pruning with higher pruning ratio.\n", "versions": [{"version": "v1", "created": "Tue, 19 Nov 2019 00:46:05 GMT"}, {"version": "v2", "created": "Wed, 20 Nov 2019 05:33:11 GMT"}], "update_date": "2019-11-21", "authors_parsed": [["Ren", "Ao", ""], ["Zhang", "Tao", ""], ["Wang", "Yuhao", ""], ["Lin", "Sheng", ""], ["Dong", "Peiyan", ""], ["Chen", "Yen-kuang", ""], ["Xie", "Yuan", ""], ["Wang", "Yanzhi", ""]]}, {"id": "1911.08024", "submitter": "Baokun He", "authors": "Baokun He, Guihong Wan, Haim Schweitzer", "title": "A Bias Trick for Centered Robust Principal Component Analysis", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Outlier based Robust Principal Component Analysis (RPCA) requires centering\nof the non-outliers. We show a \"bias trick\" that automatically centers these\nnon-outliers. Using this bias trick we obtain the first RPCA algorithm that is\noptimal with respect to centering.\n", "versions": [{"version": "v1", "created": "Tue, 19 Nov 2019 00:59:54 GMT"}], "update_date": "2019-11-20", "authors_parsed": [["He", "Baokun", ""], ["Wan", "Guihong", ""], ["Schweitzer", "Haim", ""]]}, {"id": "1911.08030", "submitter": "Abenezer Girma Mr", "authors": "Abenezer Girma, Xuyang Yan, Abdollah Homaifar", "title": "Driver Identification Based on Vehicle Telematics Data using\n  LSTM-Recurrent Neural Network", "comments": "IEEE ICTAI 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.NE eess.SP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Despite advancements in vehicle security systems, over the last decade,\nauto-theft rates have increased, and cyber-security attacks on\ninternet-connected and autonomous vehicles are becoming a new threat. In this\npaper, a deep learning model is proposed, which can identify drivers from their\ndriving behaviors based on vehicle telematics data. The proposed\nLong-Short-Term-Memory (LSTM) model predicts the identity of the driver based\non the individual's unique driving patterns learned from the vehicle telematics\ndata. Given the telematics is time-series data, the problem is formulated as a\ntime series prediction task to exploit the embedded sequential information. The\nperformance of the proposed approach is evaluated on three naturalistic driving\ndatasets, which gives high accuracy prediction results. The robustness of the\nmodel on noisy and anomalous data that is usually caused by sensor defects or\nenvironmental factors is also investigated. Results show that the proposed\nmodel prediction accuracy remains satisfactory and outperforms the other\napproaches despite the extent of anomalies and noise-induced in the data.\n", "versions": [{"version": "v1", "created": "Tue, 19 Nov 2019 01:15:20 GMT"}], "update_date": "2019-11-20", "authors_parsed": [["Girma", "Abenezer", ""], ["Yan", "Xuyang", ""], ["Homaifar", "Abdollah", ""]]}, {"id": "1911.08031", "submitter": "Abdul Dakkak", "authors": "Cheng Li, Abdul Dakkak, Jinjun Xiong, Wen-mei Hwu", "title": "The Design and Implementation of a Scalable DL Benchmarking Platform", "comments": null, "journal-ref": "2020 IEEE 13th International Conference on Cloud Computing\n  (CLOUD), 414-425", "doi": "10.1109/CLOUD49709.2020.00063", "report-no": null, "categories": "cs.DC cs.GL cs.LG cs.PF stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  The current Deep Learning (DL) landscape is fast-paced and is rife with\nnon-uniform models, hardware/software (HW/SW) stacks, but lacks a DL\nbenchmarking platform to facilitate evaluation and comparison of DL\ninnovations, be it models, frameworks, libraries, or hardware. Due to the lack\nof a benchmarking platform, the current practice of evaluating the benefits of\nproposed DL innovations is both arduous and error-prone - stifling the adoption\nof the innovations.\n  In this work, we first identify $10$ design features which are desirable\nwithin a DL benchmarking platform. These features include: performing the\nevaluation in a consistent, reproducible, and scalable manner, being framework\nand hardware agnostic, supporting real-world benchmarking workloads, providing\nin-depth model execution inspection across the HW/SW stack levels, etc. We then\npropose MLModelScope, a DL benchmarking platform design that realizes the $10$\nobjectives. MLModelScope proposes a specification to define DL model\nevaluations and techniques to provision the evaluation workflow using the\nuser-specified HW/SW stack. MLModelScope defines abstractions for frameworks\nand supports board range of DL models and evaluation scenarios. We implement\nMLModelScope as an open-source project with support for all major frameworks\nand hardware architectures. Through MLModelScope's evaluation and automated\nanalysis workflows, we performed case-study analyses of $37$ models across $4$\nsystems and show how model, hardware, and framework selection affects model\naccuracy and performance under different benchmarking scenarios. We further\ndemonstrated how MLModelScope's tracing capability gives a holistic view of\nmodel execution and helps pinpoint bottlenecks.\n", "versions": [{"version": "v1", "created": "Tue, 19 Nov 2019 01:16:08 GMT"}], "update_date": "2021-03-02", "authors_parsed": [["Li", "Cheng", ""], ["Dakkak", "Abdul", ""], ["Xiong", "Jinjun", ""], ["Hwu", "Wen-mei", ""]]}, {"id": "1911.08040", "submitter": "Alvin Chan", "authors": "Alvin Chan and Yew-Soon Ong", "title": "Poison as a Cure: Detecting & Neutralizing Variable-Sized Backdoor\n  Attacks in Deep Neural Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.CR cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Deep learning models have recently shown to be vulnerable to backdoor\npoisoning, an insidious attack where the victim model predicts clean images\ncorrectly but classifies the same images as the target class when a trigger\npoison pattern is added. This poison pattern can be embedded in the training\ndataset by the adversary. Existing defenses are effective under certain\nconditions such as a small size of the poison pattern, knowledge about the\nratio of poisoned training samples or when a validated clean dataset is\navailable. Since a defender may not have such prior knowledge or resources, we\npropose a defense against backdoor poisoning that is effective even when those\nprerequisites are not met. It is made up of several parts: one to extract a\nbackdoor poison signal, detect poison target and base classes, and filter out\npoisoned from clean samples with proven guarantees. The final part of our\ndefense involves retraining the poisoned model on a dataset augmented with the\nextracted poison signal and corrective relabeling of poisoned samples to\nneutralize the backdoor. Our approach has shown to be effective in defending\nagainst backdoor attacks that use both small and large-sized poison patterns on\nnine different target-base class pairs from the CIFAR10 dataset.\n", "versions": [{"version": "v1", "created": "Tue, 19 Nov 2019 01:59:59 GMT"}], "update_date": "2019-11-20", "authors_parsed": [["Chan", "Alvin", ""], ["Ong", "Yew-Soon", ""]]}, {"id": "1911.08044", "submitter": "Pin Wang", "authors": "Pin Wang, Dapeng Liu, Jiayu Chen, Hanhan Li, and Ching-Yao Chan", "title": "Decision Making for Autonomous Driving via Augmented Adversarial Inverse\n  Reinforcement Learning", "comments": "The 2021 International Conference on Robotics and Automation (ICRA\n  2021)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Making decisions in complex driving environments is a challenging task for\nautonomous agents. Imitation learning methods have great potentials for\nachieving such a goal. Adversarial Inverse Reinforcement Learning (AIRL) is one\nof the state-of-art imitation learning methods that can learn both a behavioral\npolicy and a reward function simultaneously, yet it is only demonstrated in\nsimple and static environments where no interactions are introduced. In this\npaper, we improve and stabilize AIRL's performance by augmenting it with\nsemantic rewards in the learning framework. Additionally, we adapt the\naugmented AIRL to a more practical and challenging decision-making task in a\nhighly interactive environment in autonomous driving. The proposed method is\ncompared with four baselines and evaluated by four performance metrics.\nSimulation results show that the augmented AIRL outperforms all the baseline\nmethods, and its performance is comparable with that of the experts on all of\nthe four metrics.\n", "versions": [{"version": "v1", "created": "Tue, 19 Nov 2019 02:06:16 GMT"}, {"version": "v2", "created": "Sun, 2 Feb 2020 22:57:56 GMT"}, {"version": "v3", "created": "Fri, 26 Mar 2021 04:55:47 GMT"}], "update_date": "2021-03-29", "authors_parsed": [["Wang", "Pin", ""], ["Liu", "Dapeng", ""], ["Chen", "Jiayu", ""], ["Li", "Hanhan", ""], ["Chan", "Ching-Yao", ""]]}, {"id": "1911.08048", "submitter": "Yixuan Qiu", "authors": "Yixuan Qiu, Jing Lei, and Kathryn Roeder", "title": "Gradient-based Sparse Principal Component Analysis with Extensions to\n  Online Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ME cs.LG stat.CO stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Sparse principal component analysis (PCA) is an important technique for\ndimensionality reduction of high-dimensional data. However, most existing\nsparse PCA algorithms are based on non-convex optimization, which provide\nlittle guarantee on the global convergence. Sparse PCA algorithms based on a\nconvex formulation, for example the Fantope projection and selection (FPS),\novercome this difficulty, but are computationally expensive. In this work we\nstudy sparse PCA based on the convex FPS formulation, and propose a new\nalgorithm that is computationally efficient and applicable to large and\nhigh-dimensional data sets. Nonasymptotic and explicit bounds are derived for\nboth the optimization error and the statistical accuracy, which can be used for\ntesting and inference problems. We also extend our algorithm to online learning\nproblems, where data are obtained in a streaming fashion. The proposed\nalgorithm is applied to high-dimensional gene expression data for the detection\nof functional gene groups.\n", "versions": [{"version": "v1", "created": "Tue, 19 Nov 2019 02:17:09 GMT"}], "update_date": "2019-11-20", "authors_parsed": [["Qiu", "Yixuan", ""], ["Lei", "Jing", ""], ["Roeder", "Kathryn", ""]]}, {"id": "1911.08050", "submitter": "Hwanjun Song", "authors": "Hwanjun Song, Minseok Kim, Sundong Kim, Jae-Gil Lee", "title": "Carpe Diem, Seize the Samples Uncertain \"At the Moment\" for Adaptive\n  Batch Selection", "comments": "Published at CIKM 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The accuracy of deep neural networks is significantly affected by how well\nmini-batches are constructed during the training step. In this paper, we\npropose a novel adaptive batch selection algorithm called Recency Bias that\nexploits the uncertain samples predicted inconsistently in recent iterations.\nThe historical label predictions of each training sample are used to evaluate\nits predictive uncertainty within a sliding window. Then, the sampling\nprobability for the next mini-batch is assigned to each training sample in\nproportion to its predictive uncertainty. By taking advantage of this design,\nRecency Bias not only accelerates the training step but also achieves a more\naccurate network. We demonstrate the superiority of Recency Bias by extensive\nevaluation on two independent tasks. Compared with existing batch selection\nmethods, the results showed that Recency Bias reduced the test error by up to\n20.97% in a fixed wall-clock training time. At the same time, it improved the\ntraining time by up to 59.32% to reach the same test error\n", "versions": [{"version": "v1", "created": "Tue, 19 Nov 2019 02:28:07 GMT"}, {"version": "v2", "created": "Wed, 23 Dec 2020 01:15:51 GMT"}], "update_date": "2020-12-24", "authors_parsed": [["Song", "Hwanjun", ""], ["Kim", "Minseok", ""], ["Kim", "Sundong", ""], ["Lee", "Jae-Gil", ""]]}, {"id": "1911.08051", "submitter": "Akash Srivastava", "authors": "Akash Srivastava, Jessie Rosenberg, Dan Gutfreund, David D. Cox", "title": "SimVAE: Simulator-Assisted Training forInterpretable Generative Models", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper presents a simulator-assisted training method (SimVAE) for\nvariational autoencoders (VAE) that leads to a disentangled and interpretable\nlatent space. Training SimVAE is a two-step process in which first a deep\ngenerator network(decoder) is trained to approximate the simulator. During this\nstep, the simulator acts as the data source or as a teacher network. Then an\ninference network (encoder)is trained to invert the decoder. As such, upon\ncomplete training, the encoder represents an approximately inverted simulator.\nBy decoupling the training of the encoder and decoder we bypass some of the\ndifficulties that arise in training generative models such as VAEs and\ngenerative adversarial networks (GANs). We show applications of our approach in\na variety of domains such as circuit design, graphics de-rendering and other\nnatural science problems that involve inference via simulation.\n", "versions": [{"version": "v1", "created": "Tue, 19 Nov 2019 02:39:27 GMT"}], "update_date": "2019-11-20", "authors_parsed": [["Srivastava", "Akash", ""], ["Rosenberg", "Jessie", ""], ["Gutfreund", "Dan", ""], ["Cox", "David D.", ""]]}, {"id": "1911.08054", "submitter": "Himank Yadav", "authors": "Himank Yadav, Zhengxiao Du, Thorsten Joachims", "title": "Policy-Gradient Training of Fair and Unbiased Ranking Functions", "comments": null, "journal-ref": null, "doi": "10.1145/3404835.3462953", "report-no": null, "categories": "cs.LG cs.CY cs.IR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  While implicit feedback (e.g., clicks, dwell times, etc.) is an abundant and\nattractive source of data for learning to rank, it can produce unfair ranking\npolicies for both exogenous and endogenous reasons. Exogenous reasons typically\nmanifest themselves as biases in the training data, which then get reflected in\nthe learned ranking policy and often lead to rich-get-richer dynamics.\nMoreover, even after the correction of such biases, reasons endogenous to the\ndesign of the learning algorithm can still lead to ranking policies that do not\nallocate exposure among items in a fair way. To address both exogenous and\nendogenous sources of unfairness, we present the first learning-to-rank\napproach that addresses both presentation bias and merit-based fairness of\nexposure simultaneously. Specifically, we define a class of amortized\nfairness-of-exposure constraints that can be chosen based on the needs of an\napplication, and we show how these fairness criteria can be enforced despite\nthe selection biases in implicit feedback data. The key result is an efficient\nand flexible policy-gradient algorithm, called FULTR, which is the first to\nenable the use of counterfactual estimators for both utility estimation and\nfairness constraints. Beyond the theoretical justification of the framework, we\nshow empirically that the proposed algorithm can learn accurate and fair\nranking policies from biased and noisy feedback.\n", "versions": [{"version": "v1", "created": "Tue, 19 Nov 2019 02:45:42 GMT"}, {"version": "v2", "created": "Sun, 9 May 2021 11:15:39 GMT"}], "update_date": "2021-05-11", "authors_parsed": [["Yadav", "Himank", ""], ["Du", "Zhengxiao", ""], ["Joachims", "Thorsten", ""]]}, {"id": "1911.08056", "submitter": "Nishant Parashar", "authors": "Nishant Parashar and Sawan S. Sinha and Balaji Srinivasan", "title": "Modelling pressure-Hessian from local velocity gradients information in\n  an incompressible turbulent flow field using deep neural networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The understanding of the dynamics of the velocity gradients in turbulent\nflows is critical to understanding various non-linear turbulent processes. The\npressure-Hessian and the viscous-Laplacian govern the evolution of the\nvelocity-gradients and are known to be non-local in nature. Over the years,\nseveral simplified dynamical models have been proposed that models the\nviscous-Laplacian and the pressure-Hessian primarily in terms of local velocity\ngradients information. These models can also serve as closure models for the\nLagrangian PDF methods. The recent fluid deformation closure model (RFDM) has\nbeen shown to retrieve excellent one-time statistics of the viscous process.\nHowever, the pressure-Hessian modelled by the RFDM has various physical\nlimitations. In this work, we first demonstrate the limitations of the RFDM in\nestimating the pressure-Hessian. Further, we employ a tensor basis neural\nnetwork (TBNN) to model the pressure-Hessian from the velocity gradient tensor\nitself. The neural network is trained on high-resolution data obtained from\ndirect numerical simulation (DNS) of isotropic turbulence at Reynolds number of\n433 (JHU turbulence database, JHTD). The predictions made by the TBNN are\ntested against two different isotropic turbulence datasets at Reynolds number\nof 433 (JHTD) and 315 (UP Madrid turbulence database, UPMTD) and channel flow\ndataset at Reynolds number of 1000 (UT Texas and JHTD). The evaluation of the\nneural network output is made in terms of the alignment statistics of the\npredicted pressure-Hessian eigenvectors with the strain-rate eigenvectors for\nturbulent isotropic flow as well as channel flow. Our analysis of the predicted\nsolution leads to the discovery of ten unique coefficients of the tensor basis\nof strain-rate and rotation-rate tensors, the linear combination over which\naccurately captures key alignment statistics of the pressure-Hessian tensor.\n", "versions": [{"version": "v1", "created": "Tue, 19 Nov 2019 02:48:22 GMT"}], "update_date": "2019-11-20", "authors_parsed": [["Parashar", "Nishant", ""], ["Sinha", "Sawan S.", ""], ["Srinivasan", "Balaji", ""]]}, {"id": "1911.08059", "submitter": "Hwanjun Song", "authors": "Hwanjun Song, Minseok Kim, Dongmin Park, Jae-Gil Lee", "title": "How does Early Stopping Help Generalization against Label Noise?", "comments": "International Conference on Machine Learning, Workshop on Uncertainty\n  and Robustness in Deep Learning. See:\n  https://sites.google.com/view/udlworkshop2020/home", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Noisy labels are very common in real-world training data, which lead to poor\ngeneralization on test data because of overfitting to the noisy labels. In this\npaper, we claim that such overfitting can be avoided by \"early stopping\"\ntraining a deep neural network before the noisy labels are severely memorized.\nThen, we resume training the early stopped network using a \"maximal safe set,\"\nwhich maintains a collection of almost certainly true-labeled samples at each\nepoch since the early stop point. Putting them all together, our novel\ntwo-phase training method, called Prestopping, realizes noise-free training\nunder any type of label noise for practical use. Extensive experiments using\nfour image benchmark data sets verify that our method significantly outperforms\nfour state-of-the-art methods in test error by 0.4-8.2 percent points under\nexistence of real-world noise.\n", "versions": [{"version": "v1", "created": "Tue, 19 Nov 2019 02:51:15 GMT"}, {"version": "v2", "created": "Thu, 2 Jul 2020 06:23:50 GMT"}, {"version": "v3", "created": "Tue, 8 Sep 2020 06:23:48 GMT"}], "update_date": "2020-09-09", "authors_parsed": [["Song", "Hwanjun", ""], ["Kim", "Minseok", ""], ["Park", "Dongmin", ""], ["Lee", "Jae-Gil", ""]]}, {"id": "1911.08065", "submitter": "Yingru Liu", "authors": "Yingru Liu, Xuewen Yang, Dongliang Xie, Xin Wang, Li Shen, Haozhi\n  Huang, Niranjan Balasubramanian", "title": "Adaptive Activation Network and Functional Regularization for Efficient\n  and Flexible Deep Multi-Task Learning", "comments": "To appear in AAAI-2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Multi-task learning (MTL) is a common paradigm that seeks to improve the\ngeneralization performance of task learning by training related tasks\nsimultaneously. However, it is still a challenging problem to search the\nflexible and accurate architecture that can be shared among multiple tasks. In\nthis paper, we propose a novel deep learning model called Task Adaptive\nActivation Network (TAAN) that can automatically learn the optimal network\narchitecture for MTL. The main principle of TAAN is to derive flexible\nactivation functions for different tasks from the data with other parameters of\nthe network fully shared. We further propose two functional regularization\nmethods that improve the MTL performance of TAAN. The improved performance of\nboth TAAN and the regularization methods is demonstrated by comprehensive\nexperiments.\n", "versions": [{"version": "v1", "created": "Tue, 19 Nov 2019 03:05:26 GMT"}], "update_date": "2019-11-20", "authors_parsed": [["Liu", "Yingru", ""], ["Yang", "Xuewen", ""], ["Xie", "Dongliang", ""], ["Wang", "Xin", ""], ["Shen", "Li", ""], ["Huang", "Haozhi", ""], ["Balasubramanian", "Niranjan", ""]]}, {"id": "1911.08068", "submitter": "Yangchen Pan", "authors": "Yangchen Pan, Kirby Banman, Martha White", "title": "Fuzzy Tiling Activations: A Simple Approach to Learning Sparse\n  Representations Online", "comments": "ICLR 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent work has shown that sparse representations -- where only a small\npercentage of units are active -- can significantly reduce interference. Those\nworks, however, relied on relatively complex regularization or meta-learning\napproaches, that have only been used offline in a pre-training phase. In this\nwork, we pursue a direction that achieves sparsity by design, rather than by\nlearning. Specifically, we design an activation function that produces sparse\nrepresentations deterministically by construction, and so is more amenable to\nonline training. The idea relies on the simple approach of binning, but\novercomes the two key limitations of binning: zero gradients for the flat\nregions almost everywhere, and lost precision -- reduced discrimination -- due\nto coarse aggregation. We introduce a Fuzzy Tiling Activation (FTA) that\nprovides non-negligible gradients and produces overlap between bins that\nimproves discrimination. We first show that FTA is robust under covariate shift\nin a synthetic online supervised learning problem, where we can vary the level\nof correlation and drift. Then we move to the deep reinforcement learning\nsetting and investigate both value-based and policy gradient algorithms that\nuse neural networks with FTAs, in classic discrete control and Mujoco\ncontinuous control environments. We show that algorithms equipped with FTAs are\nable to learn a stable policy faster without needing target networks on most\ndomains.\n", "versions": [{"version": "v1", "created": "Tue, 19 Nov 2019 03:12:06 GMT"}, {"version": "v2", "created": "Sat, 15 Feb 2020 22:36:15 GMT"}, {"version": "v3", "created": "Tue, 16 Mar 2021 16:32:19 GMT"}], "update_date": "2021-03-17", "authors_parsed": [["Pan", "Yangchen", ""], ["Banman", "Kirby", ""], ["White", "Martha", ""]]}, {"id": "1911.08074", "submitter": "Liang Li", "authors": "Yu-Xuan Li, Jin-Yuan Liu, Liang Li and Xiang Guan", "title": "Thick-Net: Parallel Network Structure for Sequential Modeling", "comments": "11 pages, 4 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recurrent neural networks have been widely used in sequence learning tasks.\nIn previous studies, the performance of the model has always been improved by\neither wider or deeper structures. However, the former becomes more prone to\noverfitting, while the latter is difficult to optimize. In this paper, we\npropose a simple new model named Thick-Net, by expanding the network from\nanother dimension: thickness. Multiple parallel values are obtained via more\nsets of parameters in each hidden state, and the maximum value is selected as\nthe final output among parallel intermediate outputs. Notably, Thick-Net can\nefficiently avoid overfitting, and is easier to optimize than the vanilla\nstructures due to the large dropout affiliated with it. Our model is evaluated\non four sequential tasks including adding problem, permuted sequential MNIST,\ntext classification and language modeling. The results of these tasks\ndemonstrate that our model can not only improve accuracy with faster\nconvergence but also facilitate a better generalization ability.\n", "versions": [{"version": "v1", "created": "Tue, 19 Nov 2019 03:18:30 GMT"}], "update_date": "2019-11-20", "authors_parsed": [["Li", "Yu-Xuan", ""], ["Liu", "Jin-Yuan", ""], ["Li", "Liang", ""], ["Guan", "Xiang", ""]]}, {"id": "1911.08077", "submitter": "Zhongxin Bai", "authors": "Zhongxin Bai, Xiao-Lei Zhang, and Jingdong Chen", "title": "Partial AUC optimization based deep speaker embeddings with class-center\n  learning for text-independent speaker verification", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.SD eess.AS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep embedding based text-independent speaker verification has demonstrated\nsuperior performance to traditional methods in many challenging scenarios. Its\nloss functions can be generally categorized into two classes, i.e.,\nverification and identification. The verification loss functions match the\npipeline of speaker verification, but their implementations are difficult.\nThus, most state-of-the-art deep embedding methods use the identification loss\nfunctions with softmax output units or their variants. In this paper, we\npropose a verification loss function, named the maximization of partial area\nunder the Receiver-operating-characteristic (ROC) curve (pAUC), for deep\nembedding based text-independent speaker verification. We also propose a\nclass-center based training trial construction method to improve the training\nefficiency, which is critical for the proposed loss function to be comparable\nto the identification loss in performance. Experiments on the Speaker in the\nWild (SITW) and NIST SRE 2016 datasets show that the proposed pAUC loss\nfunction is highly competitive with the state-of-the-art identification loss\nfunctions.\n", "versions": [{"version": "v1", "created": "Tue, 19 Nov 2019 03:30:09 GMT"}], "update_date": "2019-11-20", "authors_parsed": [["Bai", "Zhongxin", ""], ["Zhang", "Xiao-Lei", ""], ["Chen", "Jingdong", ""]]}, {"id": "1911.08082", "submitter": "Liang Li", "authors": "Ping-Ping Wang, Liang Li and Guang-Hui Cheng", "title": "Low rank tensor completion with sparse regularization in a transformed\n  domain", "comments": "18 pages, 8 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.NA cs.LG cs.NA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Tensor completion is a challenging problem with various applications. Many\nrelated models based on the low-rank prior of the tensor have been proposed.\nHowever, the low-rank prior may not be enough to recover the original tensor\nfrom the observed incomplete tensor. In this paper, we prose a tensor\ncompletion method by exploiting both the low-rank and sparse prior of tensor.\nSpecifically, the tensor completion task can be formulated as a low-rank\nminimization problem with a sparse regularizer. The low-rank property is\ndepicted by the tensor truncated nuclear norm based on tensor singular value\ndecomposition (T-SVD) which is a better approximation of tensor tubal rank than\ntensor nuclear norm. While the sparse regularizer is imposed by a\n$\\ell_{1}$-norm in a discrete cosine transformation (DCT) domain, which can\nbetter employ the local sparse property of completed data. To solve the\noptimization problem, we employ an alternating direction method of multipliers\n(ADMM) in which we only need to solve several subproblems which have\nclosed-form solutions. Substantial experiments on real world images and videos\nshow that the proposed method has better performances than the existing\nstate-of-the-art methods.\n", "versions": [{"version": "v1", "created": "Tue, 19 Nov 2019 03:56:21 GMT"}], "update_date": "2019-11-20", "authors_parsed": [["Wang", "Ping-Ping", ""], ["Li", "Liang", ""], ["Cheng", "Guang-Hui", ""]]}, {"id": "1911.08085", "submitter": "Sushrut Karmalkar", "authors": "Ilias Diakonikolas, Sushrut Karmalkar, Daniel Kane, Eric Price,\n  Alistair Stewart", "title": "Outlier-Robust High-Dimensional Sparse Estimation via Iterative\n  Filtering", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study high-dimensional sparse estimation tasks in a robust setting where a\nconstant fraction of the dataset is adversarially corrupted. Specifically, we\nfocus on the fundamental problems of robust sparse mean estimation and robust\nsparse PCA. We give the first practically viable robust estimators for these\nproblems. In more detail, our algorithms are sample and computationally\nefficient and achieve near-optimal robustness guarantees. In contrast to prior\nprovable algorithms which relied on the ellipsoid method, our algorithms use\nspectral techniques to iteratively remove outliers from the dataset. Our\nexperimental evaluation on synthetic data shows that our algorithms are\nscalable and significantly outperform a range of previous approaches, nearly\nmatching the best error rate without corruptions.\n", "versions": [{"version": "v1", "created": "Tue, 19 Nov 2019 04:12:54 GMT"}], "update_date": "2019-11-20", "authors_parsed": [["Diakonikolas", "Ilias", ""], ["Karmalkar", "Sushrut", ""], ["Kane", "Daniel", ""], ["Price", "Eric", ""], ["Stewart", "Alistair", ""]]}, {"id": "1911.08089", "submitter": "Joseph Futoma", "authors": "Mark Sendak, Madeleine Elish, Michael Gao, Joseph Futoma, William\n  Ratliff, Marshall Nichols, Armando Bedoya, Suresh Balu, Cara O'Brien", "title": "\"The Human Body is a Black Box\": Supporting Clinical Decision-Making\n  with Deep Learning", "comments": "To appear at ACM FAT* 2020, Barcelona. Updated to camera-ready\n  version", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.AI cs.HC cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Machine learning technologies are increasingly developed for use in\nhealthcare. While research communities have focused on creating\nstate-of-the-art models, there has been less focus on real world implementation\nand the associated challenges to accuracy, fairness, accountability, and\ntransparency that come from actual, situated use. Serious questions remain\nunder examined regarding how to ethically build models, interpret and explain\nmodel output, recognize and account for biases, and minimize disruptions to\nprofessional expertise and work cultures. We address this gap in the literature\nand provide a detailed case study covering the development, implementation, and\nevaluation of Sepsis Watch, a machine learning-driven tool that assists\nhospital clinicians in the early diagnosis and treatment of sepsis. We, the\nteam that developed and evaluated the tool, discuss our conceptualization of\nthe tool not as a model deployed in the world but instead as a socio-technical\nsystem requiring integration into existing social and professional contexts.\nRather than focusing on model interpretability to ensure a fair and accountable\nmachine learning, we point toward four key values and practices that should be\nconsidered when developing machine learning to support clinical\ndecision-making: rigorously define the problem in context, build relationships\nwith stakeholders, respect professional discretion, and create ongoing feedback\nloops with stakeholders. Our work has significant implications for future\nresearch regarding mechanisms of institutional accountability and\nconsiderations for designing machine learning systems. Our work underscores the\nlimits of model interpretability as a solution to ensure transparency,\naccuracy, and accountability in practice. Instead, our work demonstrates other\nmeans and goals to achieve FATML values in design and in practice.\n", "versions": [{"version": "v1", "created": "Tue, 19 Nov 2019 04:28:47 GMT"}, {"version": "v2", "created": "Sat, 7 Dec 2019 03:42:06 GMT"}], "update_date": "2019-12-10", "authors_parsed": [["Sendak", "Mark", ""], ["Elish", "Madeleine", ""], ["Gao", "Michael", ""], ["Futoma", "Joseph", ""], ["Ratliff", "William", ""], ["Nichols", "Marshall", ""], ["Bedoya", "Armando", ""], ["Balu", "Suresh", ""], ["O'Brien", "Cara", ""]]}, {"id": "1911.08090", "submitter": "Sarfaraz Hussein", "authors": "Javier Echauz, Keith Kenemer, Sarfaraz Hussein, Jay Dhaliwal, Saurabh\n  Shintre, Slawomir Grzonkowski and Andrew Gardner", "title": "Deep Detector Health Management under Adversarial Campaigns", "comments": "International Journal of Prognostics and Health Management, Special\n  Issue: PHM Applications of Deep Learning and Emerging Analytics, 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Machine learning models are vulnerable to adversarial inputs that induce\nseemingly unjustifiable errors. As automated classifiers are increasingly used\nin industrial control systems and machinery, these adversarial errors could\ngrow to be a serious problem. Despite numerous studies over the past few years,\nthe field of adversarial ML is still considered alchemy, with no practical\nunbroken defenses demonstrated to date, leaving PHM practitioners with few\nmeaningful ways of addressing the problem. We introduce turbidity detection as\na practical superset of the adversarial input detection problem, coping with\nadversarial campaigns rather than statistically invisible one-offs. This\nperspective is coupled with ROC-theoretic design guidance that prescribes an\ninexpensive domain adaptation layer at the output of a deep learning model\nduring an attack campaign. The result aims to approximate the Bayes optimal\nmitigation that ameliorates the detection model's degraded health. A\nproactively reactive type of prognostics is achieved via Monte Carlo simulation\nof various adversarial campaign scenarios, by sampling from the model's own\nturbidity distribution to quickly deploy the correct mitigation during a\nreal-world campaign.\n", "versions": [{"version": "v1", "created": "Tue, 19 Nov 2019 04:33:05 GMT"}], "update_date": "2019-11-20", "authors_parsed": [["Echauz", "Javier", ""], ["Kenemer", "Keith", ""], ["Hussein", "Sarfaraz", ""], ["Dhaliwal", "Jay", ""], ["Shintre", "Saurabh", ""], ["Grzonkowski", "Slawomir", ""], ["Gardner", "Andrew", ""]]}, {"id": "1911.08105", "submitter": "Megumi Nakao", "authors": "Megumi Nakao, Keiho Imanishi, Nobuhiro Ueda, Yuichiro Imai, Tadaaki\n  Kirita, Tetsuya Matsuda", "title": "Three-dimensional Generative Adversarial Nets for Unsupervised Metal\n  Artifact Reduction", "comments": null, "journal-ref": "IEEE Access, 8, 109453-109465 (2020)", "doi": "10.1109/ACCESS.2020.3002090", "report-no": null, "categories": "eess.IV cs.AI cs.CV cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  The reduction of metal artifacts in computed tomography (CT) images,\nspecifically for strong artifacts generated from multiple metal objects, is a\nchallenging issue in medical imaging research. Although there have been some\nstudies on supervised metal artifact reduction through the learning of\nsynthesized artifacts, it is difficult for simulated artifacts to cover the\ncomplexity of the real physical phenomena that may be observed in X-ray\npropagation. In this paper, we introduce metal artifact reduction methods based\non an unsupervised volume-to-volume translation learned from clinical CT\nimages. We construct three-dimensional adversarial nets with a regularized loss\nfunction designed for metal artifacts from multiple dental fillings. The\nresults of experiments using 915 CT volumes from real patients demonstrate that\nthe proposed framework has an outstanding capacity to reduce strong artifacts\nand to recover underlying missing voxels, while preserving the anatomical\nfeatures of soft tissues and tooth structures from the original images.\n", "versions": [{"version": "v1", "created": "Tue, 19 Nov 2019 05:56:54 GMT"}, {"version": "v2", "created": "Tue, 31 Mar 2020 03:40:43 GMT"}, {"version": "v3", "created": "Fri, 21 Aug 2020 04:50:09 GMT"}], "update_date": "2020-08-24", "authors_parsed": [["Nakao", "Megumi", ""], ["Imanishi", "Keiho", ""], ["Ueda", "Nobuhiro", ""], ["Imai", "Yuichiro", ""], ["Kirita", "Tadaaki", ""], ["Matsuda", "Tetsuya", ""]]}, {"id": "1911.08111", "submitter": "Jiangbin Lyu Dr.", "authors": "Jin Qiu, Jiangbin Lyu and Liqun Fu", "title": "Placement Optimization of Aerial Base Stations with Deep Reinforcement\n  Learning", "comments": "6 pages, 4 figures, accepted for publication in 2020 IEEE\n  International Conference on Communications (ICC 2020)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IT cs.AI cs.LG math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Unmanned aerial vehicles (UAVs) can be utilized as aerial base stations\n(ABSs) to assist terrestrial infrastructure for keeping wireless connectivity\nin various emergency scenarios. To maximize the coverage rate of N ground users\n(GUs) by jointly placing multiple ABSs with limited coverage range is known to\nbe a NP-hard problem with exponential complexity in N. The problem is further\ncomplicated when the coverage range becomes irregular due to site-specific\nblockage (e.g., buildings) on the air-ground channel in the 3-dimensional (3D)\nspace. To tackle this challenging problem, this paper applies the Deep\nReinforcement Learning (DRL) method by 1) representing the state by a coverage\nbitmap to capture the spatial correlation of GUs/ABSs, whose dimension and\nassociated neural network complexity is invariant with arbitrarily large N; and\n2) designing the action and reward for the DRL agent to effectively learn from\nthe dynamic interactions with the complicated propagation environment\nrepresented by a 3D Terrain Map. Specifically, a novel two-level design\napproach is proposed, consisting of a preliminary design based on the dominant\nline-of-sight (LoS) channel model, and an advanced design to further refine the\nABS positions based on site-specific LoS/non-LoS channel states. The double\ndeep Q-network (DQN) with Prioritized Experience Replay (Prioritized Replay\nDDQN) algorithm is applied to train the policy of multi-ABS placement decision.\nNumerical results show that the proposed approach significantly improves the\ncoverage rate in complex environment, compared to the benchmark DQN and K-means\nalgorithms.\n", "versions": [{"version": "v1", "created": "Tue, 19 Nov 2019 06:35:15 GMT"}, {"version": "v2", "created": "Wed, 5 Feb 2020 07:53:53 GMT"}], "update_date": "2020-02-06", "authors_parsed": [["Qiu", "Jin", ""], ["Lyu", "Jiangbin", ""], ["Fu", "Liqun", ""]]}, {"id": "1911.08112", "submitter": "Hongwei Zeng", "authors": "Hongwei Zeng, Zhuo Zhi, Jun Liu, Bifan Wei", "title": "Extended Answer and Uncertainty Aware Neural Question Generation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we study automatic question generation, the task of creating\nquestions from corresponding text passages where some certain spans of the text\ncan serve as the answers. We propose an Extended Answer-aware Network (EAN)\nwhich is trained with Word-based Coverage Mechanism (WCM) and decodes with\nUncertainty-aware Beam Search (UBS). The EAN represents the target answer by\nits surrounding sentence with an encoder, and incorporates the information of\nthe extended answer into paragraph representation with gated\nparagraph-to-answer attention to tackle the problem of the inadequate\nrepresentation of the target answer. To reduce undesirable repetition, the WCM\npenalizes repeatedly attending to the same words at different time-steps in the\ntraining stage. The UBS aims to seek a better balance between the model\nconfidence in copying words from an input text paragraph and the confidence in\ngenerating words from a vocabulary. We conduct experiments on the SQuAD\ndataset, and the results show our approach achieves significant performance\nimprovement.\n", "versions": [{"version": "v1", "created": "Tue, 19 Nov 2019 06:38:14 GMT"}], "update_date": "2019-11-20", "authors_parsed": [["Zeng", "Hongwei", ""], ["Zhi", "Zhuo", ""], ["Liu", "Jun", ""], ["Wei", "Bifan", ""]]}, {"id": "1911.08117", "submitter": "Preslav Nakov", "authors": "Minh-Thang Luong, Preslav Nakov, Min-Yen Kan", "title": "A Hybrid Morpheme-Word Representation for Machine Translation of\n  Morphologically Rich Languages", "comments": null, "journal-ref": "EMNLP-2010", "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a language-independent approach for improving statistical machine\ntranslation for morphologically rich languages using a hybrid morpheme-word\nrepresentation where the basic unit of translation is the morpheme, but word\nboundaries are respected at all stages of the translation process. Our model\nextends the classic phrase-based model by means of (1) word boundary-aware\nmorpheme-level phrase extraction, (2) minimum error-rate training for a\nmorpheme-level translation model using word-level BLEU, and (3) joint scoring\nwith morpheme- and word-level language models. Further improvements are\nachieved by combining our model with the classic one. The evaluation on English\nto Finnish using Europarl (714K sentence pairs; 15.5M English words) shows\nstatistically significant improvements over the classic model based on BLEU and\nhuman judgments.\n", "versions": [{"version": "v1", "created": "Tue, 19 Nov 2019 06:50:59 GMT"}], "update_date": "2019-11-20", "authors_parsed": [["Luong", "Minh-Thang", ""], ["Nakov", "Preslav", ""], ["Kan", "Min-Yen", ""]]}, {"id": "1911.08119", "submitter": "Qiang Ren", "authors": "Qiang Ren, Shaohua Shang, Lianghua He", "title": "Adaptive Routing Between Capsules", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Capsule network is the most recent exciting advancement in the deep learning\nfield and represents positional information by stacking features into vectors.\nThe dynamic routing algorithm is used in the capsule network, however, there\nare some disadvantages such as the inability to stack multiple layers and a\nlarge amount of computation. In this paper, we propose an adaptive routing\nalgorithm that can solve the problems mentioned above. First, the low-layer\ncapsules adaptively adjust their direction and length in the routing algorithm\nand removing the influence of the coupling coefficient on the gradient\npropagation, so that the network can work when stacked in multiple layers.\nThen, the iterative process of routing is simplified to reduce the amount of\ncomputation and we introduce the gradient coefficient $\\lambda$. Further, we\ntested the performance of our proposed adaptive routing algorithm on CIFAR10,\nFashion-MNIST, SVHN and MNIST, while achieving better results than the dynamic\nrouting algorithm.\n", "versions": [{"version": "v1", "created": "Tue, 19 Nov 2019 06:56:36 GMT"}], "update_date": "2019-11-20", "authors_parsed": [["Ren", "Qiang", ""], ["Shang", "Shaohua", ""], ["He", "Lianghua", ""]]}, {"id": "1911.08128", "submitter": "Xiaoyu Wang", "authors": "Xiaoyu Wang, Ye Deng, Jinjun Wang", "title": "Distributed Generative Adversarial Net", "comments": "9 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recently the Generative Adversarial Network has become a hot topic.\nConsidering the application of GAN in multi-user environment, we propose\nDistributed-GAN. It enables multiple users to train with their own data locally\nand generates more diverse samples. Users don't need to share data with each\nother to avoid the leakage of privacy. In recent years, commercial companies\nhave launched cloud platforms based on artificial intelligence to provide model\nfor users who lack computing power. We hope our work can inspire these\ncompanies to provide more powerful AI services.\n", "versions": [{"version": "v1", "created": "Tue, 19 Nov 2019 07:15:23 GMT"}], "update_date": "2019-11-20", "authors_parsed": [["Wang", "Xiaoyu", ""], ["Deng", "Ye", ""], ["Wang", "Jinjun", ""]]}, {"id": "1911.08136", "submitter": "Erico Tjoa", "authors": "Erico Tjoa, Guo Heng, Lu Yuhao, Cuntai Guan", "title": "Enhancing the Extraction of Interpretable Information for Ischemic\n  Stroke Imaging from Deep Neural Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.IV cs.LG q-bio.QM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We implement a visual interpretability method Layer-wise Relevance\nPropagation (LRP) on top of 3D U-Net trained to perform lesion segmentation on\nthe small dataset of multi-modal images provided by ISLES 2017 competition. We\ndemonstrate that LRP modifications could provide more sensible visual\nexplanations to an otherwise highly noise-skewed saliency map. We also link\namplitude of modified signals to useful information content. High amplitude\nlocalized signals appear to constitute the noise that undermines the\ninterpretability capacity of LRP. Furthermore, mathematical framework for\npossible analysis of function approximation is developed by analogy.\n", "versions": [{"version": "v1", "created": "Tue, 19 Nov 2019 07:45:46 GMT"}, {"version": "v2", "created": "Mon, 13 Jan 2020 05:30:39 GMT"}], "update_date": "2020-01-14", "authors_parsed": [["Tjoa", "Erico", ""], ["Heng", "Guo", ""], ["Yuhao", "Lu", ""], ["Guan", "Cuntai", ""]]}, {"id": "1911.08141", "submitter": "Daesik Kim", "authors": "Daesik Kim, Gyujeong Lee, Jisoo Jeong, Nojun Kwak", "title": "Tell Me What They're Holding: Weakly-supervised Object Detection with\n  Transferable Knowledge from Human-object Interaction", "comments": "AAAI 2020 Oral Camera Ready", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this work, we introduce a novel weakly supervised object detection (WSOD)\nparadigm to detect objects belonging to rare classes that have not many\nexamples using transferable knowledge from human-object interactions (HOI).\nWhile WSOD shows lower performance than full supervision, we mainly focus on\nHOI as the main context which can strongly supervise complex semantics in\nimages. Therefore, we propose a novel module called RRPN (relational region\nproposal network) which outputs an object-localizing attention map only with\nhuman poses and action verbs. In the source domain, we fully train an object\ndetector and the RRPN with full supervision of HOI. With transferred knowledge\nabout localization map from the trained RRPN, a new object detector can learn\nunseen objects with weak verbal supervision of HOI without bounding box\nannotations in the target domain. Because the RRPN is designed as an add-on\ntype, we can apply it not only to the object detection but also to other\ndomains such as semantic segmentation. The experimental results on HICO-DET\ndataset show the possibility that the proposed method can be a cheap\nalternative for the current supervised object detection paradigm. Moreover,\nqualitative results demonstrate that our model can properly localize unseen\nobjects on HICO-DET and V-COCO datasets.\n", "versions": [{"version": "v1", "created": "Tue, 19 Nov 2019 08:03:11 GMT"}], "update_date": "2019-11-20", "authors_parsed": [["Kim", "Daesik", ""], ["Lee", "Gyujeong", ""], ["Jeong", "Jisoo", ""], ["Kwak", "Nojun", ""]]}, {"id": "1911.08142", "submitter": "Xiang Gao", "authors": "Xiang Gao, Wei Hu, Guo-Jun Qi", "title": "GraphTER: Unsupervised Learning of Graph Transformation Equivariant\n  Representations via Auto-Encoding Node-wise Transformations", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent advances in Graph Convolutional Neural Networks (GCNNs) have shown\ntheir efficiency for non-Euclidean data on graphs, which often require a large\namount of labeled data with high cost. It it thus critical to learn graph\nfeature representations in an unsupervised manner in practice. To this end, we\npropose a novel unsupervised learning of Graph Transformation Equivariant\nRepresentations (GraphTER), aiming to capture intrinsic patterns of graph\nstructure under both global and local transformations. Specifically, we allow\nto sample different groups of nodes from a graph and then transform them\nnode-wise isotropically or anisotropically. Then, we self-train a\nrepresentation encoder to capture the graph structures by reconstructing these\nnode-wise transformations from the feature representations of the original and\ntransformed graphs. In experiments, we apply the learned GraphTER to graphs of\n3D point cloud data, and results on point cloud segmentation/classification\nshow that GraphTER significantly outperforms state-of-the-art unsupervised\napproaches and pushes greatly closer towards the upper bound set by the fully\nsupervised counterparts. The code is available at:\nhttps://github.com/gyshgx868/graph-ter.\n", "versions": [{"version": "v1", "created": "Tue, 19 Nov 2019 08:03:12 GMT"}, {"version": "v2", "created": "Thu, 19 Mar 2020 02:50:11 GMT"}], "update_date": "2020-03-20", "authors_parsed": [["Gao", "Xiang", ""], ["Hu", "Wei", ""], ["Qi", "Guo-Jun", ""]]}, {"id": "1911.08147", "submitter": "Nina Miolane", "authors": "Nina Miolane, Susan Holmes", "title": "Learning Weighted Submanifolds with Variational Autoencoders and\n  Riemannian Variational Autoencoders", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG math.DG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Manifold-valued data naturally arises in medical imaging. In cognitive\nneuroscience, for instance, brain connectomes base the analysis of coactivation\npatterns between different brain regions on the analysis of the correlations of\ntheir functional Magnetic Resonance Imaging (fMRI) time series - an object thus\nconstrained by construction to belong to the manifold of symmetric positive\ndefinite matrices. One of the challenges that naturally arises consists of\nfinding a lower-dimensional subspace for representing such manifold-valued\ndata. Traditional techniques, like principal component analysis, are\nill-adapted to tackle non-Euclidean spaces and may fail to achieve a\nlower-dimensional representation of the data - thus potentially pointing to the\nabsence of lower-dimensional representation of the data. However, these\ntechniques are restricted in that: (i) they do not leverage the assumption that\nthe connectomes belong on a pre-specified manifold, therefore discarding\ninformation; (ii) they can only fit a linear subspace to the data. In this\npaper, we are interested in variants to learn potentially highly curved\nsubmanifolds of manifold-valued data. Motivated by the brain connectomes\nexample, we investigate a latent variable generative model, which has the added\nbenefit of providing us with uncertainty estimates - a crucial quantity in the\nmedical applications we are considering. While latent variable models have been\nproposed to learn linear and nonlinear spaces for Euclidean data, or geodesic\nsubspaces for manifold data, no intrinsic latent variable model exists to learn\nnongeodesic subspaces for manifold data. This paper fills this gap and\nformulates a Riemannian variational autoencoder with an intrinsic generative\nmodel of manifold-valued data. We evaluate its performances on synthetic and\nreal datasets by introducing the formalism of weighted Riemannian submanifolds.\n", "versions": [{"version": "v1", "created": "Tue, 19 Nov 2019 08:15:31 GMT"}], "update_date": "2019-11-20", "authors_parsed": [["Miolane", "Nina", ""], ["Holmes", "Susan", ""]]}, {"id": "1911.08153", "submitter": "SyuSiang Wang", "authors": "Syu-Siang Wang, Yu-You Liang, Jeih-weih Hung, Yu Tsao, Hsin-Min Wang,\n  Shih-Hau Fang", "title": "Distributed Microphone Speech Enhancement based on Deep Learning", "comments": "deep neural network, multi-channel speech enhancement, distributed\n  microphone architecture, diffuse noise environment", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.AS cs.LG cs.SD", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Speech-related applications deliver inferior performance in complex noise\nenvironments. Therefore, this study primarily addresses this problem by\nintroducing speech-enhancement (SE) systems based on deep neural networks\n(DNNs) applied to a distributed microphone architecture, and then investigates\nthe effectiveness of three different DNN-model structures. The first system\nconstructs a DNN model for each microphone to enhance the recorded noisy speech\nsignal, and the second system combines all the noisy recordings into a large\nfeature structure that is then enhanced through a DNN model. As for the third\nsystem, a channel-dependent DNN is first used to enhance the corresponding\nnoisy input, and all the channel-wise enhanced outputs are fed into a DNN\nfusion model to construct a nearly clean signal. All the three DNN SE systems\nare operated in the acoustic frequency domain of speech signals in a\ndiffuse-noise field environment. Evaluation experiments were conducted on the\nTaiwan Mandarin Hearing in Noise Test (TMHINT) database, and the results\nindicate that all the three DNN-based SE systems provide the original\nnoise-corrupted signals with improved speech quality and intelligibility,\nwhereas the third system delivers the highest signal-to-noise ratio (SNR)\nimprovement and optimal speech intelligibility.\n", "versions": [{"version": "v1", "created": "Tue, 19 Nov 2019 08:23:17 GMT"}, {"version": "v2", "created": "Fri, 22 Nov 2019 04:22:48 GMT"}, {"version": "v3", "created": "Sun, 24 May 2020 10:07:23 GMT"}], "update_date": "2020-05-26", "authors_parsed": [["Wang", "Syu-Siang", ""], ["Liang", "Yu-You", ""], ["Hung", "Jeih-weih", ""], ["Tsao", "Yu", ""], ["Wang", "Hsin-Min", ""], ["Fang", "Shih-Hau", ""]]}, {"id": "1911.08160", "submitter": "Chaoshun Li", "authors": "Chaoshun Li, Geng Tang, Xiaoming Xue, Xinbiao Chen, Ruoheng Wang and\n  Chu Zhang", "title": "Deep interval prediction model with gradient descend optimization method\n  for short-term wind power prediction", "comments": "24 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.SY cs.LG cs.SY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The application of wind power interval prediction for power systems attempts\nto give more comprehensive support to dispatchers and operators of the grid.\nLower upper bound estimation (LUBE) method is widely applied in interval\nprediction. However, the existing LUBE approaches are trained by meta-heuristic\noptimization, which is either time-consuming or show poor effect when the LUBE\nmodel is complex. In this paper, a deep interval prediction method is designed\nin the framework of LUBE and an efficient gradient descend (GD) training\napproach is proposed to train the LUBE model. In this method, the long\nshort-term memory is selected as a representative to show the modelling\napproach. The architecture of the proposed model consists of three parts,\nnamely the long short-term memory module, the fully connected layers and the\nrank ordered module. Two loss functions are specially designed for implementing\nthe GD training method based on the root mean square back propagation\nalgorithm. To verify the performance of the proposed model, conventional LUBE\nmodels, as well as popular statistic interval prediction models are compared in\nnumerical experiments. The results show that the proposed approach performs\nbest in terms of effectiveness and efficiency with average 45% promotion in\nquality of prediction interval and 66% reduction of time consumptions compared\nto traditional LUBE models.\n", "versions": [{"version": "v1", "created": "Tue, 19 Nov 2019 08:54:46 GMT"}], "update_date": "2019-11-20", "authors_parsed": [["Li", "Chaoshun", ""], ["Tang", "Geng", ""], ["Xue", "Xiaoming", ""], ["Chen", "Xinbiao", ""], ["Wang", "Ruoheng", ""], ["Zhang", "Chu", ""]]}, {"id": "1911.08177", "submitter": "Oriane Sim\\'eoni", "authors": "Oriane Sim\\'eoni, Mateusz Budnik, Yannis Avrithis, Guillaume Gravier", "title": "Rethinking deep active learning: Using unlabeled data at model training", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Active learning typically focuses on training a model on few labeled examples\nalone, while unlabeled ones are only used for acquisition. In this work we\ndepart from this setting by using both labeled and unlabeled data during model\ntraining across active learning cycles. We do so by using unsupervised feature\nlearning at the beginning of the active learning pipeline and semi-supervised\nlearning at every active learning cycle, on all available data. The former has\nnot been investigated before in active learning, while the study of latter in\nthe context of deep learning is scarce and recent findings are not conclusive\nwith respect to its benefit. Our idea is orthogonal to acquisition strategies\nby using more data, much like ensemble methods use more models. By\nsystematically evaluating on a number of popular acquisition strategies and\ndatasets, we find that the use of unlabeled data during model training brings a\nsurprising accuracy improvement in image classification, compared to the\ndifferences between acquisition strategies. We thus explore smaller label\nbudgets, even one label per class.\n", "versions": [{"version": "v1", "created": "Tue, 19 Nov 2019 09:42:33 GMT"}], "update_date": "2019-11-20", "authors_parsed": [["Sim\u00e9oni", "Oriane", ""], ["Budnik", "Mateusz", ""], ["Avrithis", "Yannis", ""], ["Gravier", "Guillaume", ""]]}, {"id": "1911.08192", "submitter": "Zhiwei Jia", "authors": "Zhiwei Jia and Hao Su", "title": "Information-Theoretic Local Minima Characterization and Regularization", "comments": "ICML 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent advances in deep learning theory have evoked the study of\ngeneralizability across different local minima of deep neural networks (DNNs).\nWhile current work focused on either discovering properties of good local\nminima or developing regularization techniques to induce good local minima, no\napproach exists that can tackle both problems. We achieve these two goals\nsuccessfully in a unified manner. Specifically, based on the observed Fisher\ninformation we propose a metric both strongly indicative of generalizability of\nlocal minima and effectively applied as a practical regularizer. We provide\ntheoretical analysis including a generalization bound and empirically\ndemonstrate the success of our approach in both capturing and improving the\ngeneralizability of DNNs. Experiments are performed on CIFAR-10, CIFAR-100 and\nImageNet for various network architectures.\n", "versions": [{"version": "v1", "created": "Tue, 19 Nov 2019 10:14:33 GMT"}, {"version": "v2", "created": "Tue, 30 Jun 2020 10:23:27 GMT"}], "update_date": "2020-07-01", "authors_parsed": [["Jia", "Zhiwei", ""], ["Su", "Hao", ""]]}, {"id": "1911.08197", "submitter": "Dhruti Shah", "authors": "Dhruti Shah, Tuhinangshu Choudhury, Nikhil Karamchandani, Aditya\n  Gopalan", "title": "Sequential Mode Estimation with Oracle Queries", "comments": "A shorter version of this paper has been accepted for publication at\n  Association for the Advancement of Artificial Intelligence - AAAI 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.IT math.IT stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the problem of adaptively PAC-learning a probability distribution\n$\\mathcal{P}$'s mode by querying an oracle for information about a sequence of\ni.i.d. samples $X_1, X_2, \\ldots$ generated from $\\mathcal{P}$. We consider two\ndifferent query models: (a) each query is an index $i$ for which the oracle\nreveals the value of the sample $X_i$, (b) each query is comprised of two\nindices $i$ and $j$ for which the oracle reveals if the samples $X_i$ and $X_j$\nare the same or not. For these query models, we give sequential mode-estimation\nalgorithms which, at each time $t$, either make a query to the corresponding\noracle based on past observations, or decide to stop and output an estimate for\nthe distribution's mode, required to be correct with a specified confidence. We\nanalyze the query complexity of these algorithms for any underlying\ndistribution $\\mathcal{P}$, and derive corresponding lower bounds on the\noptimal query complexity under the two querying models.\n", "versions": [{"version": "v1", "created": "Tue, 19 Nov 2019 10:25:32 GMT"}], "update_date": "2019-11-20", "authors_parsed": [["Shah", "Dhruti", ""], ["Choudhury", "Tuhinangshu", ""], ["Karamchandani", "Nikhil", ""], ["Gopalan", "Aditya", ""]]}, {"id": "1911.08199", "submitter": "Zhijie Lin", "authors": "Zhijie Lin, Zhou Zhao, Zhu Zhang, Qi Wang and Huasheng Liu", "title": "Weakly-Supervised Video Moment Retrieval via Semantic Completion Network", "comments": "Accepted by AAAI 2020 as a full paper", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG cs.MM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Video moment retrieval is to search the moment that is most relevant to the\ngiven natural language query. Existing methods are mostly trained in a\nfully-supervised setting, which requires the full annotations of temporal\nboundary for each query. However, manually labeling the annotations is actually\ntime-consuming and expensive. In this paper, we propose a novel\nweakly-supervised moment retrieval framework requiring only coarse video-level\nannotations for training. Specifically, we devise a proposal generation module\nthat aggregates the context information to generate and score all candidate\nproposals in one single pass. We then devise an algorithm that considers both\nexploitation and exploration to select top-K proposals. Next, we build a\nsemantic completion module to measure the semantic similarity between the\nselected proposals and query, compute reward and provide feedbacks to the\nproposal generation module for scoring refinement. Experiments on the\nActivityCaptions and Charades-STA demonstrate the effectiveness of our proposed\nmethod.\n", "versions": [{"version": "v1", "created": "Tue, 19 Nov 2019 10:31:43 GMT"}, {"version": "v2", "created": "Tue, 14 Jan 2020 12:40:37 GMT"}, {"version": "v3", "created": "Wed, 15 Jan 2020 11:09:43 GMT"}], "update_date": "2020-01-16", "authors_parsed": [["Lin", "Zhijie", ""], ["Zhao", "Zhou", ""], ["Zhang", "Zhu", ""], ["Wang", "Qi", ""], ["Liu", "Huasheng", ""]]}, {"id": "1911.08200", "submitter": "Shengcai Liu", "authors": "Shengcai Liu, Ke Tang, Yunwen Lei and Xin Yao", "title": "On Performance Estimation in Automatic Algorithm Configuration", "comments": "accepted by AAAI 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Over the last decade, research on automated parameter tuning, often referred\nto as automatic algorithm configuration (AAC), has made significant progress.\nAlthough the usefulness of such tools has been widely recognized in real world\napplications, the theoretical foundations of AAC are still very weak. This\npaper addresses this gap by studying the performance estimation problem in AAC.\nMore specifically, this paper first proves the universal best performance\nestimator in a practical setting, and then establishes theoretical bounds on\nthe estimation error, i.e., the difference between the training performance and\nthe true performance for a parameter configuration, considering finite and\ninfinite configuration spaces respectively. These findings were verified in\nextensive experiments conducted on four algorithm configuration scenarios\ninvolving different problem domains. Moreover, insights for enhancing existing\nAAC methods are also identified.\n", "versions": [{"version": "v1", "created": "Tue, 19 Nov 2019 10:33:19 GMT"}], "update_date": "2019-11-20", "authors_parsed": [["Liu", "Shengcai", ""], ["Tang", "Ke", ""], ["Lei", "Yunwen", ""], ["Yao", "Xin", ""]]}, {"id": "1911.08201", "submitter": "Giulia Fracastoro", "authors": "Giuseppe C. Calafiore, Marisa H. Morales, Vittorio Tiozzo, Giulia\n  Fracastoro, Serge Marquie", "title": "Survival and Neural Models for Private Equity Exit Prediction", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Within the Private Equity (PE) market, the event of a private company\nundertaking an Initial Public Offering (IPO) is usually a very high-return one\nfor the investors in the company. For this reason, an effective predictive\nmodel for the IPO event is considered as a valuable tool in the PE market, an\nendeavor in which publicly available quantitative information is generally\nscarce. In this paper, we describe a data-analytic procedure for predicting the\nprobability with which a company will go public in a given forward period of\ntime. The proposed method is based on the interplay of a neural network (NN)\nmodel for estimating the overall event probability, and Survival Analysis (SA)\nfor further modeling the probability of the IPO event in any given interval of\ntime. The proposed neuro-survival model is tuned and tested across nine\nindustrial sectors using real data from the Thomson Reuters Eikon PE database.\n", "versions": [{"version": "v1", "created": "Tue, 19 Nov 2019 10:33:38 GMT"}, {"version": "v2", "created": "Wed, 20 Nov 2019 08:30:11 GMT"}, {"version": "v3", "created": "Thu, 21 Nov 2019 08:44:12 GMT"}, {"version": "v4", "created": "Mon, 25 Nov 2019 10:56:37 GMT"}], "update_date": "2019-11-26", "authors_parsed": [["Calafiore", "Giuseppe C.", ""], ["Morales", "Marisa H.", ""], ["Tiozzo", "Vittorio", ""], ["Fracastoro", "Giulia", ""], ["Marquie", "Serge", ""]]}, {"id": "1911.08216", "submitter": "Neelanjan Bhowmik", "authors": "Neelanjan Bhowmik, Yona Falinie A. Gaus, Samet Akcay, Jack W. Barker,\n  Toby P. Breckon", "title": "On the Impact of Object and Sub-component Level Segmentation Strategies\n  for Supervised Anomaly Detection within X-ray Security Imagery", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG eess.IV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  X-ray security screening is in widespread use to maintain transportation\nsecurity against a wide range of potential threat profiles. Of particular\ninterest is the recent focus on the use of automated screening approaches,\nincluding the potential anomaly detection as a methodology for concealment\ndetection within complex electronic items. Here we address this problem\nconsidering varying segmentation strategies to enable the use of both object\nlevel and sub-component level anomaly detection via the use of secondary\nconvolutional neural network (CNN) architectures. Relative performance is\nevaluated over an extensive dataset of exemplar cluttered X-ray imagery, with a\nfocus on consumer electronics items. We find that sub-component level\nsegmentation produces marginally superior performance in the secondary anomaly\ndetection via classification stage, with true positive of ~98% of anomalies,\nwith a ~3% false positive.\n", "versions": [{"version": "v1", "created": "Tue, 19 Nov 2019 11:54:18 GMT"}], "update_date": "2019-11-20", "authors_parsed": [["Bhowmik", "Neelanjan", ""], ["Gaus", "Yona Falinie A.", ""], ["Akcay", "Samet", ""], ["Barker", "Jack W.", ""], ["Breckon", "Toby P.", ""]]}, {"id": "1911.08250", "submitter": "Aritra Dutta", "authors": "Aritra Dutta, El Houcine Bergou, Ahmed M. Abdelmoniem, Chen-Yu Ho,\n  Atal Narayan Sahu, Marco Canini, Panos Kalnis", "title": "On the Discrepancy between the Theoretical Analysis and Practical\n  Implementations of Compressed Communication for Distributed Deep Learning", "comments": "To Appear In Proceedings of Thirty-Fourth AAAI Conference on\n  Artificial Intelligence, 2020", "journal-ref": "In Proceedings of Thirty-Fourth AAAI Conference on Artificial\n  Intelligence, 2020", "doi": null, "report-no": null, "categories": "cs.DC cs.LG math.OC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Compressed communication, in the form of sparsification or quantization of\nstochastic gradients, is employed to reduce communication costs in distributed\ndata-parallel training of deep neural networks. However, there exists a\ndiscrepancy between theory and practice: while theoretical analysis of most\nexisting compression methods assumes compression is applied to the gradients of\nthe entire model, many practical implementations operate individually on the\ngradients of each layer of the model. In this paper, we prove that layer-wise\ncompression is, in theory, better, because the convergence rate is upper\nbounded by that of entire-model compression for a wide range of biased and\nunbiased compression methods. However, despite the theoretical bound, our\nexperimental study of six well-known methods shows that convergence, in\npractice, may or may not be better, depending on the actual trained model and\ncompression ratio. Our findings suggest that it would be advantageous for deep\nlearning frameworks to include support for both layer-wise and entire-model\ncompression.\n", "versions": [{"version": "v1", "created": "Tue, 19 Nov 2019 13:22:22 GMT"}], "update_date": "2019-11-20", "authors_parsed": [["Dutta", "Aritra", ""], ["Bergou", "El Houcine", ""], ["Abdelmoniem", "Ahmed M.", ""], ["Ho", "Chen-Yu", ""], ["Sahu", "Atal Narayan", ""], ["Canini", "Marco", ""], ["Kalnis", "Panos", ""]]}, {"id": "1911.08251", "submitter": "Gabriele Cesa", "authors": "Maurice Weiler and Gabriele Cesa", "title": "General $E(2)$-Equivariant Steerable CNNs", "comments": "Conference on Neural Information Processing Systems (NeurIPS), 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG eess.IV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The big empirical success of group equivariant networks has led in recent\nyears to the sprouting of a great variety of equivariant network architectures.\nA particular focus has thereby been on rotation and reflection equivariant CNNs\nfor planar images. Here we give a general description of $E(2)$-equivariant\nconvolutions in the framework of Steerable CNNs. The theory of Steerable CNNs\nthereby yields constraints on the convolution kernels which depend on group\nrepresentations describing the transformation laws of feature spaces. We show\nthat these constraints for arbitrary group representations can be reduced to\nconstraints under irreducible representations. A general solution of the kernel\nspace constraint is given for arbitrary representations of the Euclidean group\n$E(2)$ and its subgroups. We implement a wide range of previously proposed and\nentirely new equivariant network architectures and extensively compare their\nperformances. $E(2)$-steerable convolutions are further shown to yield\nremarkable gains on CIFAR-10, CIFAR-100 and STL-10 when used as a drop-in\nreplacement for non-equivariant convolutions.\n", "versions": [{"version": "v1", "created": "Tue, 19 Nov 2019 13:25:49 GMT"}, {"version": "v2", "created": "Tue, 6 Apr 2021 17:46:56 GMT"}], "update_date": "2021-04-07", "authors_parsed": [["Weiler", "Maurice", ""], ["Cesa", "Gabriele", ""]]}, {"id": "1911.08252", "submitter": "Furao Shen", "authors": "Junyi An, Fengshan Liu, Jian Zhao, Furao Shen", "title": "IC-Network: Efficient Structure for Convolutional Neural Networks", "comments": "9 pages, 4 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Neural networks have been widely used, and most networks achieve excellent\nperformance by stacking certain types of basic units. Compared to increasing\nthe depth and width of the network, designing more effective basic units has\nbecome an important research topic. Inspired by the elastic collision model in\nphysics, we present a universal structure that could be integrated into the\nexisting network structures to speed up the training process and increase their\ngeneralization abilities. We term this structure the \"Inter-layer Collision\"\n(IC) structure. We built two kinds of basic computational units (IC layer and\nIC block) that compose the convolutional neural networks (CNNs) by combining\nthe IC structure with the convolution operation. Compared to traditional\nconvolutions, both of the proposed computational units have a stronger\nnon-linear representation ability and can filter features useful for a given\ntask. Using these computational units to build networks, we bring significant\nimprovements in performance for existing state-of-the-art CNNs. On the imagenet\nexperiment, we integrate the IC block into ResNet-50 and reduce the top-1 error\nfrom 22.85% to 21.49%, which also exceeds the top-1 error of ResNet-100\n(21.75%).\n", "versions": [{"version": "v1", "created": "Tue, 19 Nov 2019 13:26:06 GMT"}, {"version": "v2", "created": "Mon, 20 Jan 2020 07:13:37 GMT"}, {"version": "v3", "created": "Wed, 3 Jun 2020 02:58:07 GMT"}, {"version": "v4", "created": "Thu, 4 Jun 2020 15:05:47 GMT"}], "update_date": "2020-06-05", "authors_parsed": [["An", "Junyi", ""], ["Liu", "Fengshan", ""], ["Zhao", "Jian", ""], ["Shen", "Furao", ""]]}, {"id": "1911.08265", "submitter": "Julian Schrittwieser", "authors": "Julian Schrittwieser, Ioannis Antonoglou, Thomas Hubert, Karen\n  Simonyan, Laurent Sifre, Simon Schmitt, Arthur Guez, Edward Lockhart, Demis\n  Hassabis, Thore Graepel, Timothy Lillicrap, David Silver", "title": "Mastering Atari, Go, Chess and Shogi by Planning with a Learned Model", "comments": null, "journal-ref": null, "doi": "10.1038/s41586-020-03051-4", "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Constructing agents with planning capabilities has long been one of the main\nchallenges in the pursuit of artificial intelligence. Tree-based planning\nmethods have enjoyed huge success in challenging domains, such as chess and Go,\nwhere a perfect simulator is available. However, in real-world problems the\ndynamics governing the environment are often complex and unknown. In this work\nwe present the MuZero algorithm which, by combining a tree-based search with a\nlearned model, achieves superhuman performance in a range of challenging and\nvisually complex domains, without any knowledge of their underlying dynamics.\nMuZero learns a model that, when applied iteratively, predicts the quantities\nmost directly relevant to planning: the reward, the action-selection policy,\nand the value function. When evaluated on 57 different Atari games - the\ncanonical video game environment for testing AI techniques, in which\nmodel-based planning approaches have historically struggled - our new algorithm\nachieved a new state of the art. When evaluated on Go, chess and shogi, without\nany knowledge of the game rules, MuZero matched the superhuman performance of\nthe AlphaZero algorithm that was supplied with the game rules.\n", "versions": [{"version": "v1", "created": "Tue, 19 Nov 2019 13:58:52 GMT"}, {"version": "v2", "created": "Fri, 21 Feb 2020 18:05:30 GMT"}], "update_date": "2021-01-27", "authors_parsed": [["Schrittwieser", "Julian", ""], ["Antonoglou", "Ioannis", ""], ["Hubert", "Thomas", ""], ["Simonyan", "Karen", ""], ["Sifre", "Laurent", ""], ["Schmitt", "Simon", ""], ["Guez", "Arthur", ""], ["Lockhart", "Edward", ""], ["Hassabis", "Demis", ""], ["Graepel", "Thore", ""], ["Lillicrap", "Timothy", ""], ["Silver", "David", ""]]}, {"id": "1911.08288", "submitter": "Kyongsik Yun", "authors": "E. Natasha Stavros, Ali Agha, Allen Sirota, Marco Quadrelli, Kamak\n  Ebadi, Kyongsik Yun", "title": "Smoke Sky -- Exploring New Frontiers of Unmanned Aerial Systems for\n  Wildland Fire Science and Applications", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.LG cs.RO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Wildfire has had increasing impacts on society as the climate changes and the\nwildland urban interface grows. As such, there is a demand for innovative\nsolutions to help manage fire. Managing wildfire can include proactive fire\nmanagement such as prescribed burning within constrained areas or advancements\nfor reactive fire management (e.g., fire suppression). Because of the growing\nsocietal impact, the JPL BlueSky program sought to assess the current state of\nfire management and technology and determine areas with high return on\ninvestment. To accomplish this, we met with the national interagency Unmanned\nAerial System (UAS) Advisory Group (UASAG) and with leading technology transfer\nexperts for fire science and management applications. We provide an overview of\nthe current state as well as an analysis of the impact, maturity and\nfeasibility of integrating different technologies that can be developed by JPL.\nBased on the findings, the highest return on investment technologies for fire\nmanagement are first to develop single micro-aerial vehicle (MAV) autonomy,\nautonomous sensing over fire, and the associated data and information system\nfor active fire local environment mapping. Once this is completed for a single\nMAV, expanding the work to include many in a swarm would require further\ninvestment of distributed MAV autonomy and MAV swarm mechanics, but could\ngreatly expand the breadth of application over large fires. Important to\ninvesting in these technologies will be in developing collaborations with the\nkey influencers and champions for using UAS technology in fire management.\n", "versions": [{"version": "v1", "created": "Tue, 12 Nov 2019 20:37:19 GMT"}], "update_date": "2019-11-20", "authors_parsed": [["Stavros", "E. Natasha", ""], ["Agha", "Ali", ""], ["Sirota", "Allen", ""], ["Quadrelli", "Marco", ""], ["Ebadi", "Kamak", ""], ["Yun", "Kyongsik", ""]]}, {"id": "1911.08327", "submitter": "Dhruv Paranjpye", "authors": "Dhruv Paranjpye, Ashish Mahabal, A.N. Ramaprakash, Gina Panopoulou,\n  Kieran Cleary, Anthony Readhead, Dmitry Blinov, Kostas Tassis", "title": "Eliminating artefacts in Polarimetric Images using Deep Learning", "comments": "7 pages, 15 figures", "journal-ref": null, "doi": "10.1093/mnras/stz3250", "report-no": null, "categories": "cs.LG astro-ph.IM stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Polarization measurements done using Imaging Polarimeters such as the Robotic\nPolarimeter are very sensitive to the presence of artefacts in images.\nArtefacts can range from internal reflections in a telescope to satellite\ntrails that could contaminate an area of interest in the image. With the advent\nof wide-field polarimetry surveys, it is imperative to develop methods that\nautomatically flag artefacts in images. In this paper, we implement a\nConvolutional Neural Network to identify the most dominant artefacts in the\nimages. We find that our model can successfully classify sources with 98\\% true\npositive and 97\\% true negative rates. Such models, combined with transfer\nlearning, will give us a running start in artefact elimination for near-future\nsurveys like WALOP.\n", "versions": [{"version": "v1", "created": "Tue, 19 Nov 2019 15:03:21 GMT"}], "update_date": "2019-12-02", "authors_parsed": [["Paranjpye", "Dhruv", ""], ["Mahabal", "Ashish", ""], ["Ramaprakash", "A. N.", ""], ["Panopoulou", "Gina", ""], ["Cleary", "Kieran", ""], ["Readhead", "Anthony", ""], ["Blinov", "Dmitry", ""], ["Tassis", "Kostas", ""]]}, {"id": "1911.08332", "submitter": "Dhananjay Ram", "authors": "Dhananjay Ram, Lesly Miculicich and Herv\\'e Bourlard", "title": "Neural Network based End-to-End Query by Example Spoken Term Detection", "comments": "Submitted to IEEE/ACM TRANSACTIONS ON AUDIO, SPEECH, AND LANGUAGE\n  PROCESSING", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.AS cs.CL cs.LG cs.SD stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper focuses on the problem of query by example spoken term detection\n(QbE-STD) in zero-resource scenario. State-of-the-art approaches primarily rely\non dynamic time warping (DTW) based template matching techniques using phone\nposterior or bottleneck features extracted from a deep neural network (DNN). We\nuse both monolingual and multilingual bottleneck features, and show that\nmultilingual features perform increasingly better with more training languages.\nPreviously, it has been shown that the DTW based matching can be replaced with\na CNN based matching while using posterior features. Here, we show that the CNN\nbased matching outperforms DTW based matching using bottleneck features as\nwell. In this case, the feature extraction and pattern matching stages of our\nQbE-STD system are optimized independently of each other. We propose to\nintegrate these two stages in a fully neural network based end-to-end learning\nframework to enable joint optimization of those two stages simultaneously. The\nproposed approaches are evaluated on two challenging multilingual datasets:\nSpoken Web Search 2013 and Query by Example Search on Speech Task 2014,\ndemonstrating in each case significant improvements.\n", "versions": [{"version": "v1", "created": "Tue, 19 Nov 2019 15:07:07 GMT"}], "update_date": "2019-11-20", "authors_parsed": [["Ram", "Dhananjay", ""], ["Miculicich", "Lesly", ""], ["Bourlard", "Herv\u00e9", ""]]}, {"id": "1911.08335", "submitter": "Krishna Subramani", "authors": "Krishna Subramani, Alexandre D'Hooge, Preeti Rao", "title": "Generative Audio Synthesis with a Parametric Model", "comments": "ISMIR 2019 Late Breaking/Demo", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.AS cs.LG cs.SD", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Use a parametric representation of audio to train a generative model in the\ninterest of obtaining more flexible control over the generated sound.\n", "versions": [{"version": "v1", "created": "Fri, 15 Nov 2019 20:59:30 GMT"}], "update_date": "2019-11-20", "authors_parsed": [["Subramani", "Krishna", ""], ["D'Hooge", "Alexandre", ""], ["Rao", "Preeti", ""]]}, {"id": "1911.08339", "submitter": "Jonathan Ullman", "authors": "Alexander Edmonds and Aleksandar Nikolov and Jonathan Ullman", "title": "The Power of Factorization Mechanisms in Local and Central Differential\n  Privacy", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.CR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We give new characterizations of the sample complexity of answering linear\nqueries (statistical queries) in the local and central models of differential\nprivacy:\n  *In the non-interactive local model, we give the first approximate\ncharacterization of the sample complexity. Informally our bounds are tight to\nwithin polylogarithmic factors in the number of queries and desired accuracy.\nOur characterization extends to agnostic learning in the local model.\n  *In the central model, we give a characterization of the sample complexity in\nthe high-accuracy regime that is analogous to that of Nikolov, Talwar, and\nZhang (STOC 2013), but is both quantitatively tighter and has a dramatically\nsimpler proof.\n  Our lower bounds apply equally to the empirical and population estimation\nproblems. In both cases, our characterizations show that a particular\nfactorization mechanism is approximately optimal, and the optimal sample\ncomplexity is bounded from above and below by well studied factorization norms\nof a matrix associated with the queries.\n", "versions": [{"version": "v1", "created": "Tue, 19 Nov 2019 15:17:18 GMT"}], "update_date": "2019-11-20", "authors_parsed": [["Edmonds", "Alexander", ""], ["Nikolov", "Aleksandar", ""], ["Ullman", "Jonathan", ""]]}, {"id": "1911.08342", "submitter": "Max Berrendorf", "authors": "Max Berrendorf, Evgeniy Faerman, Valentyn Melnychuk, Volker Tresp,\n  Thomas Seidl", "title": "Knowledge Graph Entity Alignment with Graph Convolutional Networks:\n  Lessons Learned", "comments": null, "journal-ref": null, "doi": "10.1007/978-3-030-45442-5_1", "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this work, we focus on the problem of entity alignment in Knowledge Graphs\n(KG) and we report on our experiences when applying a Graph Convolutional\nNetwork (GCN) based model for this task. Variants of GCN are used in multiple\nstate-of-the-art approaches and therefore it is important to understand the\nspecifics and limitations of GCN-based models. Despite serious efforts, we were\nnot able to fully reproduce the results from the original paper and after a\nthorough audit of the code provided by authors, we concluded, that their\nimplementation is different from the architecture described in the paper. In\naddition, several tricks are required to make the model work and some of them\nare not very intuitive. We provide an extensive ablation study to quantify the\neffects these tricks and changes of architecture have on final performance.\nFurthermore, we examine current evaluation approaches and systematize available\nbenchmark datasets. We believe that people interested in KG matching might\nprofit from our work, as well as novices entering the field\n", "versions": [{"version": "v1", "created": "Tue, 19 Nov 2019 15:20:53 GMT"}, {"version": "v2", "created": "Thu, 23 Jan 2020 12:20:45 GMT"}], "update_date": "2021-05-27", "authors_parsed": [["Berrendorf", "Max", ""], ["Faerman", "Evgeniy", ""], ["Melnychuk", "Valentyn", ""], ["Tresp", "Volker", ""], ["Seidl", "Thomas", ""]]}, {"id": "1911.08348", "submitter": "Oran Gafni", "authors": "Oran Gafni, Lior Wolf, Yaniv Taigman", "title": "Live Face De-Identification in Video", "comments": "ICCV 2019", "journal-ref": "Proceedings of the IEEE International Conference on Computer\n  Vision (2019) 9378--9387", "doi": null, "report-no": null, "categories": "cs.LG cs.CV cs.GR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a method for face de-identification that enables fully automatic\nvideo modification at high frame rates. The goal is to maximally decorrelate\nthe identity, while having the perception (pose, illumination and expression)\nfixed. We achieve this by a novel feed-forward encoder-decoder network\narchitecture that is conditioned on the high-level representation of a person's\nfacial image. The network is global, in the sense that it does not need to be\nretrained for a given video or for a given identity, and it creates natural\nlooking image sequences with little distortion in time.\n", "versions": [{"version": "v1", "created": "Tue, 19 Nov 2019 15:28:35 GMT"}], "update_date": "2019-11-20", "authors_parsed": [["Gafni", "Oran", ""], ["Wolf", "Lior", ""], ["Taigman", "Yaniv", ""]]}, {"id": "1911.08350", "submitter": "Juan Banda", "authors": "Toqi Tahamid Sarker and Juan M. Banda", "title": "Solar Event Tracking with Deep Regression Networks: A Proof of Concept\n  Evaluation", "comments": "8 pages, 5 figures, this has been submitted and accepted for\n  publication at IEEE Big Data 2019 - SABID Workshop", "journal-ref": "2019 IEEE International Conference on Big Data (Big Data)", "doi": "10.1109/BigData47090.2019.9006273", "report-no": null, "categories": "cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  With the advent of deep learning for computer vision tasks, the need for\naccurately labeled data in large volumes is vital for any application. The\nincreasingly available large amounts of solar image data generated by the Solar\nDynamic Observatory (SDO) mission make this domain particularly interesting for\nthe development and testing of deep learning systems. The currently available\nlabeled solar data is generated by the SDO mission's Feature Finding Team's\n(FFT) specialized detection modules. The major drawback of these modules is\nthat detection and labeling is performed with a cadence of every 4 to 12 hours,\ndepending on the module. Since SDO image data products are created every 10\nseconds, there is a considerable gap between labeled observations and the\ncontinuous data stream. In order to address this shortcoming, we trained a deep\nregression network to track the movement of two solar phenomena: Active Region\nand Coronal Hole events. To the best of our knowledge, this is the first\nattempt of solar event tracking using a deep learning approach. Since it is\nimpossible to fully evaluate the performance of the suggested event tracks with\nthe original data (only partial ground truth is available), we demonstrate with\nseveral metrics the effectiveness of our approach. With the purpose of\ngenerating continuously labeled solar image data, we present this feasibility\nanalysis showing the great promise of deep regression networks for this task.\n", "versions": [{"version": "v1", "created": "Tue, 19 Nov 2019 15:32:10 GMT"}], "update_date": "2020-04-01", "authors_parsed": [["Sarker", "Toqi Tahamid", ""], ["Banda", "Juan M.", ""]]}, {"id": "1911.08354", "submitter": "Sorelle Friedler", "authors": "Kadan Lottick, Silvia Susai, Sorelle A. Friedler, and Jonathan P.\n  Wilson", "title": "Energy Usage Reports: Environmental awareness as part of algorithmic\n  accountability", "comments": "Workshop on Tackling Climate Change with Machine Learning at NeurIPS\n  2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CY stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The carbon footprint of algorithms must be measured and transparently\nreported so computer scientists can take an honest and active role in\nenvironmental sustainability. In this paper, we take analyses usually applied\nat the industrial level and make them accessible for individual computer\nscience researchers with an easy-to-use Python package. Localizing to the\nenergy mixture of the electrical power grid, we make the conversion from energy\nusage to CO2 emissions, in addition to contextualizing these results with more\nhuman-understandable benchmarks such as automobile miles driven. We also\ninclude comparisons with energy mixtures employed in electrical grids around\nthe world. We propose including these automatically-generated Energy Usage\nReports as part of standard algorithmic accountability practices, and\ndemonstrate the use of these reports as part of model-choice in a machine\nlearning context.\n", "versions": [{"version": "v1", "created": "Tue, 19 Nov 2019 15:34:28 GMT"}, {"version": "v2", "created": "Mon, 16 Dec 2019 17:48:35 GMT"}], "update_date": "2019-12-17", "authors_parsed": [["Lottick", "Kadan", ""], ["Susai", "Silvia", ""], ["Friedler", "Sorelle A.", ""], ["Wilson", "Jonathan P.", ""]]}, {"id": "1911.08361", "submitter": "Ilkka Rautiainen", "authors": "Ilkka Rautiainen, Sami \\\"Ayr\\\"am\\\"o", "title": "Predicting overweight and obesity in later life from childhood data: A\n  review of predictive modeling approaches", "comments": "8 pages, 1 figure", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.AP stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Background: Overweight and obesity are an increasing phenomenon worldwide.\nPredicting future overweight or obesity early in the childhood reliably could\nenable a successful intervention by experts. While a lot of research has been\ndone using explanatory modeling methods, capability of machine learning, and\npredictive modeling, in particular, remain mainly unexplored. In predictive\nmodeling models are validated with previously unseen examples, giving a more\naccurate estimate of their performance and generalization ability in real-life\nscenarios.\n  Objective: To find and review existing overweight or obesity research from\nthe perspective of employing childhood data and predictive modeling methods.\n  Methods: The initial phase included bibliographic searches using relevant\nsearch terms in PubMed, IEEE database and Google Scholar. The second phase\nconsisted of iteratively searching references of potential studies and recent\nresearch that cite the potential studies.\n  Results: Eight research articles and three review articles were identified as\nrelevant for this review.\n  Conclusions: Prediction models with high performance either have a relatively\nshort time period to predict or/and are based on late childhood data. Logistic\nregression is currently the most often used method in forming the prediction\nmodels. In addition to child's own weight and height information, maternal\nweight status or body mass index was often used as predictors in the models.\n", "versions": [{"version": "v1", "created": "Tue, 19 Nov 2019 15:44:09 GMT"}], "update_date": "2019-11-20", "authors_parsed": [["Rautiainen", "Ilkka", ""], ["\u00c4yr\u00e4m\u00f6", "Sami", ""]]}, {"id": "1911.08362", "submitter": "Kenneth Young", "authors": "Kenny Young", "title": "Variance Reduced Advantage Estimation with $\\delta$ Hindsight Credit\n  Assignment", "comments": "Removed incorrect sentence regarding policy gradients of any 2\n  different different actions necessarily being negative for softmax\n  parameterization", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Hindsight Credit Assignment (HCA) refers to a recently proposed family of\nmethods for producing more efficient credit assignment in reinforcement\nlearning. These methods work by explicitly estimating the probability that\ncertain actions were taken in the past given present information. Prior work\nhas studied the properties of such methods and demonstrated their behaviour\nempirically. We extend this work by introducing a particular HCA algorithm\nwhich has provably lower variance than the conventional Monte-Carlo estimator\nwhen the necessary functions can be estimated exactly. This result provides a\nstrong theoretical basis for how HCA could be broadly useful.\n", "versions": [{"version": "v1", "created": "Tue, 19 Nov 2019 15:46:20 GMT"}, {"version": "v2", "created": "Mon, 23 Dec 2019 20:37:24 GMT"}, {"version": "v3", "created": "Thu, 9 Jan 2020 21:56:06 GMT"}, {"version": "v4", "created": "Mon, 28 Sep 2020 16:15:25 GMT"}], "update_date": "2020-09-29", "authors_parsed": [["Young", "Kenny", ""]]}, {"id": "1911.08363", "submitter": "Sasha Salter", "authors": "Sasha Salter, Dushyant Rao, Markus Wulfmeier, Raia Hadsell, Ingmar\n  Posner", "title": "Attention-Privileged Reinforcement Learning", "comments": "Published at Conference on Robot Learning (CoRL) 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Image-based Reinforcement Learning is known to suffer from poor sample\nefficiency and generalisation to unseen visuals such as distractors\n(task-independent aspects of the observation space). Visual domain\nrandomisation encourages transfer by training over visual factors of variation\nthat may be encountered in the target domain. This increases learning\ncomplexity, can negatively impact learning rate and performance, and requires\nknowledge of potential variations during deployment. In this paper, we\nintroduce Attention-Privileged Reinforcement Learning (APRiL) which uses a\nself-supervised attention mechanism to significantly alleviate these drawbacks:\nby focusing on task-relevant aspects of the observations, attention provides\nrobustness to distractors as well as significantly increased learning\nefficiency. APRiL trains two attention-augmented actor-critic agents: one\npurely based on image observations, available across training and transfer\ndomains; and one with access to privileged information (such as environment\nstates) available only during training. Experience is shared between both\nagents and their attention mechanisms are aligned. The image-based policy can\nthen be deployed without access to privileged information. We experimentally\ndemonstrate accelerated and more robust learning on a diverse set of domains,\nleading to improved final performance for environments both within and outside\nthe training distribution.\n", "versions": [{"version": "v1", "created": "Tue, 19 Nov 2019 15:49:29 GMT"}, {"version": "v2", "created": "Wed, 11 Mar 2020 21:22:39 GMT"}, {"version": "v3", "created": "Mon, 11 Jan 2021 14:41:34 GMT"}], "update_date": "2021-01-12", "authors_parsed": [["Salter", "Sasha", ""], ["Rao", "Dushyant", ""], ["Wulfmeier", "Markus", ""], ["Hadsell", "Raia", ""], ["Posner", "Ingmar", ""]]}, {"id": "1911.08378", "submitter": "Rishiraj Saha Roy", "authors": "Azin Ghazimatin, Oana Balalau, Rishiraj Saha Roy, Gerhard Weikum", "title": "PRINCE: Provider-side Interpretability with Counterfactual Explanations\n  in Recommender Systems", "comments": "WSDM 2020, 9 pages", "journal-ref": null, "doi": "10.1145/3336191.3371824", "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Interpretable explanations for recommender systems and other machine learning\nmodels are crucial to gain user trust. Prior works that have focused on paths\nconnecting users and items in a heterogeneous network have several limitations,\nsuch as discovering relationships rather than true explanations, or\ndisregarding other users' privacy. In this work, we take a fresh perspective,\nand present PRINCE: a provider-side mechanism to produce tangible explanations\nfor end-users, where an explanation is defined to be a set of minimal actions\nperformed by the user that, if removed, changes the recommendation to a\ndifferent item. Given a recommendation, PRINCE uses a polynomial-time optimal\nalgorithm for finding this minimal set of a user's actions from an exponential\nsearch space, based on random walks over dynamic graphs. Experiments on two\nreal-world datasets show that PRINCE provides more compact explanations than\nintuitive baselines, and insights from a crowdsourced user-study demonstrate\nthe viability of such action-based explanations. We thus posit that PRINCE\nproduces scrutable, actionable, and concise explanations, owing to its use of\ncounterfactual evidence, a user's own actions, and minimal sets, respectively.\n", "versions": [{"version": "v1", "created": "Tue, 19 Nov 2019 16:23:02 GMT"}, {"version": "v2", "created": "Thu, 21 Nov 2019 09:23:52 GMT"}, {"version": "v3", "created": "Mon, 2 Dec 2019 13:08:49 GMT"}, {"version": "v4", "created": "Tue, 24 Dec 2019 07:31:30 GMT"}], "update_date": "2019-12-25", "authors_parsed": [["Ghazimatin", "Azin", ""], ["Balalau", "Oana", ""], ["Roy", "Rishiraj Saha", ""], ["Weikum", "Gerhard", ""]]}, {"id": "1911.08382", "submitter": "Vladimir Vargas-Calder\\'on", "authors": "Vladimir Vargas-Calder\\'on and Jorge E. Camargo", "title": "A model for predicting price polarity of real estate properties using\n  information of real estate market websites", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  This paper presents a model that uses the information that sellers publish in\nreal estate market websites to predict whether a property has higher or lower\nprice than the average price of its similar properties. The model learns the\ncorrelation between price and information (text descriptions and features) of\nreal estate properties through automatic identification of latent semantic\ncontent given by a machine learning model based on doc2vec and xgboost. The\nproposed model was evaluated with a data set of 57,516 publications of real\nestate properties collected from 2016 to 2018 of Bogot\\'a city. Results show\nthat the accuracy of a classifier that involves text descriptions is slightly\nhigher than a classifier that only uses features of the real estate properties,\nas text descriptions tends to contain detailed information about the property.\n", "versions": [{"version": "v1", "created": "Tue, 19 Nov 2019 16:29:59 GMT"}], "update_date": "2019-11-20", "authors_parsed": [["Vargas-Calder\u00f3n", "Vladimir", ""], ["Camargo", "Jorge E.", ""]]}, {"id": "1911.08388", "submitter": "Mohammadreza Soltaninejad PhD", "authors": "Mehdi Amian and Mohammadreza Soltaninejad", "title": "Multi-Resolution 3D CNN for MRI Brain Tumor Segmentation and Survival\n  Prediction", "comments": "Submitted to Lecture Notes in Computer Science (LNCS) BraTS\n  proceedings", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.IV cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this study, an automated three dimensional (3D) deep segmentation approach\nfor detecting gliomas in 3D pre-operative MRI scans is proposed. Then, a\nclassi-fication algorithm based on random forests, for survival prediction is\npresented. The objective is to segment the glioma area and produce segmentation\nlabels for its different sub-regions, i.e. necrotic and the non-enhancing tumor\ncore, the peri-tumoral edema, and enhancing tumor. The proposed deep\narchitecture for the segmentation task encompasses two parallel streamlines\nwith two different reso-lutions. One deep convolutional neural network is to\nlearn local features of the input data while the other one is set to have a\nglobal observation on whole image. Deemed to be complementary, the outputs of\neach stream are then merged to pro-vide an ensemble complete learning of the\ninput image. The proposed network takes the whole image as input instead of\npatch-based approaches in order to con-sider the semantic features throughout\nthe whole volume. The algorithm is trained on BraTS 2019 which included 335\ntraining cases, and validated on 127 unseen cases from the validation dataset\nusing a blind testing approach. The proposed method was also evaluated on the\nBraTS 2019 challenge test dataset of 166 cases. The results show that the\nproposed methods provide promising segmentations as well as survival\nprediction. The mean Dice overlap measures of automatic brain tumor\nsegmentation for validation set were 0.84, 0.74 and 0.71 for the whole tu-mor,\ncore and enhancing tumor, respectively. The corresponding results for the\nchallenge test dataset were 0.82, 0.72, and 0.70, respectively. The overall\naccura-cy of the proposed model for the survival prediction task is %52 for the\nvalida-tion and %49 for the test dataset.\n", "versions": [{"version": "v1", "created": "Tue, 19 Nov 2019 16:36:54 GMT"}], "update_date": "2019-11-20", "authors_parsed": [["Amian", "Mehdi", ""], ["Soltaninejad", "Mohammadreza", ""]]}, {"id": "1911.08395", "submitter": "Ashwin Geet D'Sa", "authors": "Ashwin Geet D'Sa, Irina Illina, Dominique Fohr", "title": "Towards non-toxic landscapes: Automatic toxic comment detection using\n  DNN", "comments": null, "journal-ref": "In Proceedings of the Second Workshop on Trolling, Aggression and\n  Cyberbullying 2020 May (pp. 21-25)", "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The spectacular expansion of the Internet has led to the development of a new\nresearch problem in the field of natural language processing: automatic toxic\ncomment detection, since many countries prohibit hate speech in public media.\nThere is no clear and formal definition of hate, offensive, toxic and abusive\nspeeches. In this article, we put all these terms under the umbrella of \"toxic\"\nspeech. The contribution of this paper is the design of binary classification\nand regression-based approaches aiming to predict whether a comment is toxic or\nnot. We compare different unsupervised word representations and different DNN\nbased classifiers. Moreover, we study the robustness of the proposed approaches\nto adversarial attacks by adding one (healthy or toxic) word. We evaluate the\nproposed methodology on the English Wikipedia Detox corpus. Our experiments\nshow that using BERT fine-tuning outperforms feature-based BERT, Mikolov's and\nfastText representations with different DNN classifiers.\n", "versions": [{"version": "v1", "created": "Tue, 19 Nov 2019 16:58:54 GMT"}, {"version": "v2", "created": "Wed, 16 Sep 2020 20:09:40 GMT"}], "update_date": "2020-09-18", "authors_parsed": [["D'Sa", "Ashwin Geet", ""], ["Illina", "Irina", ""], ["Fohr", "Dominique", ""]]}, {"id": "1911.08411", "submitter": "Ondrej Skopek", "authors": "Ondrej Skopek, Octavian-Eugen Ganea, Gary B\\'ecigneul", "title": "Mixed-curvature Variational Autoencoders", "comments": "ICLR 2020 camera ready version", "journal-ref": "International Conference on Learning Representations (ICLR) 2020", "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Euclidean geometry has historically been the typical \"workhorse\" for machine\nlearning applications due to its power and simplicity. However, it has recently\nbeen shown that geometric spaces with constant non-zero curvature improve\nrepresentations and performance on a variety of data types and downstream\ntasks. Consequently, generative models like Variational Autoencoders (VAEs)\nhave been successfully generalized to elliptical and hyperbolic latent spaces.\nWhile these approaches work well on data with particular kinds of biases e.g.\ntree-like data for a hyperbolic VAE, there exists no generic approach unifying\nand leveraging all three models. We develop a Mixed-curvature Variational\nAutoencoder, an efficient way to train a VAE whose latent space is a product of\nconstant curvature Riemannian manifolds, where the per-component curvature is\nfixed or learnable. This generalizes the Euclidean VAE to curved latent spaces\nand recovers it when curvatures of all latent space components go to 0.\n", "versions": [{"version": "v1", "created": "Tue, 19 Nov 2019 17:30:45 GMT"}, {"version": "v2", "created": "Thu, 13 Feb 2020 00:05:33 GMT"}], "update_date": "2020-02-14", "authors_parsed": [["Skopek", "Ondrej", ""], ["Ganea", "Octavian-Eugen", ""], ["B\u00e9cigneul", "Gary", ""]]}, {"id": "1911.08414", "submitter": "Hongqian Qin", "authors": "Hongqian Qin", "title": "Comparison of Deep learning models on time series forecasting : a case\n  study of Dissolved Oxygen Prediction", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.SP cs.LG stat.AP stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep learning has achieved impressive prediction performance in the field of\nsequence learning recently. Dissolved oxygen prediction, as a kind of\ntime-series forecasting, is suitable for this technique. Although many\nresearchers have developed hybrid models or variant models based on deep\nlearning techniques, there is no comprehensive and sound comparison among the\ndeep learning models in this field currently. Plus, most previous studies\nfocused on one-step forecasting by using a small data set. As the convenient\naccess to high-frequency data, this paper compares multi-step deep learning\nforecasting by using walk-forward validation. Specifically, we test\nConvolutional Neural Network (CNN), Temporal Convolutional Network (TCN), Long\nShort-Term Memory (LSTM), Gated Recurrent Unit (GRU), Bidirectional Recurrent\nNeural Network (BiRNN) based on the real-time data recorded automatically at a\nfixed observation point in the Yangtze River from 2012 to 2016. By comparing\nthe average accumulated statistical metrics of root mean square error (RMSE),\nmean absolute error (MAE), and coefficient of determination in each time step,\nWe find for multi-step time series forecasting, the average performance of each\ntime step does not decrease linearly. GRU outperforms other models with\nsignificant advantages.\n", "versions": [{"version": "v1", "created": "Sun, 17 Nov 2019 01:44:06 GMT"}, {"version": "v2", "created": "Thu, 21 Nov 2019 13:22:47 GMT"}], "update_date": "2019-11-22", "authors_parsed": [["Qin", "Hongqian", ""]]}, {"id": "1911.08415", "submitter": "Chuanpan Zheng", "authors": "Chuanpan Zheng, Xiaoliang Fan, Cheng Wang, and Jianzhong Qi", "title": "GMAN: A Graph Multi-Attention Network for Traffic Prediction", "comments": "AAAI 2020 paper", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.SP cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Long-term traffic prediction is highly challenging due to the complexity of\ntraffic systems and the constantly changing nature of many impacting factors.\nIn this paper, we focus on the spatio-temporal factors, and propose a graph\nmulti-attention network (GMAN) to predict traffic conditions for time steps\nahead at different locations on a road network graph. GMAN adapts an\nencoder-decoder architecture, where both the encoder and the decoder consist of\nmultiple spatio-temporal attention blocks to model the impact of the\nspatio-temporal factors on traffic conditions. The encoder encodes the input\ntraffic features and the decoder predicts the output sequence. Between the\nencoder and the decoder, a transform attention layer is applied to convert the\nencoded traffic features to generate the sequence representations of future\ntime steps as the input of the decoder. The transform attention mechanism\nmodels the direct relationships between historical and future time steps that\nhelps to alleviate the error propagation problem among prediction time steps.\nExperimental results on two real-world traffic prediction tasks (i.e., traffic\nvolume prediction and traffic speed prediction) demonstrate the superiority of\nGMAN. In particular, in the 1 hour ahead prediction, GMAN outperforms\nstate-of-the-art methods by up to 4% improvement in MAE measure. The source\ncode is available at https://github.com/zhengchuanpan/GMAN.\n", "versions": [{"version": "v1", "created": "Mon, 11 Nov 2019 07:48:43 GMT"}, {"version": "v2", "created": "Tue, 26 Nov 2019 03:10:26 GMT"}], "update_date": "2019-11-27", "authors_parsed": [["Zheng", "Chuanpan", ""], ["Fan", "Xiaoliang", ""], ["Wang", "Cheng", ""], ["Qi", "Jianzhong", ""]]}, {"id": "1911.08426", "submitter": "Sannidhan M S", "authors": "Sukhada Chokkadi, Sannidhan M S, Sudeepa K B and Abhir Bhandary", "title": "A Study on various state of the art of the Art Face Recognition System\n  using Deep Learning Techniques", "comments": null, "journal-ref": "International Journal of Advanced Trends in Computer Science and\n  Engineering, 8(4), July- August 2019, 1590", "doi": "10.30534/ijatcse/2019/84842019", "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Considering the existence of very large amount of available data repositories\nand reach to the very advanced system of hardware, systems meant for facial\nidentification ave evolved enormously over the past few decades. Sketch\nrecognition is one of the most important areas that have evolved as an integral\ncomponent adopted by the agencies of law administration in current trends of\nforensic science. Matching of derived sketches to photo images of face is also\na difficult assignment as the considered sketches are produced upon the verbal\nexplanation depicted by the eye witness of the crime scene and may have\nscarcity of sensitive elements that exist in the photograph as one can\naccurately depict due to the natural human error. Substantial amount of the\nnovel research work carried out in this area up late used recognition system\nthrough traditional extraction and classification models. But very recently,\nfew researches work focused on using deep learning techniques to take an\nadvantage of learning models for the feature extraction and classification to\nrule out potential domain challenges. The first part of this review paper\nbasically focuses on deep learning techniques used in face recognition and\nmatching which as improved the accuracy of face recognition technique with\ntraining of huge sets of data. This paper also includes a survey on different\ntechniques used to match composite sketches to human images which includes\ncomponent-based representation approach, automatic composite sketch recognition\ntechnique etc.\n", "versions": [{"version": "v1", "created": "Tue, 19 Nov 2019 17:48:29 GMT"}], "update_date": "2019-11-20", "authors_parsed": [["Chokkadi", "Sukhada", ""], ["S", "Sannidhan M", ""], ["B", "Sudeepa K", ""], ["Bhandary", "Abhir", ""]]}, {"id": "1911.08437", "submitter": "Mohammad Hashir", "authors": "Mohammad Hashir and Rapinder Sawhney", "title": "Towards unstructured mortality prediction with free-text clinical notes", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CL stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Healthcare data continues to flourish yet a relatively small portion, mostly\nstructured, is being utilized effectively for predicting clinical outcomes. The\nrich subjective information available in unstructured clinical notes can\npossibly facilitate higher discrimination but tends to be under-utilized in\nmortality prediction. This work attempts to assess the gain in performance when\nmultiple notes that have been minimally preprocessed are used as an input for\nprediction. A hierarchical architecture consisting of both convolutional and\nrecurrent layers is used to concurrently model the different notes compiled in\nan individual hospital stay. This approach is evaluated on predicting\nin-hospital mortality on the MIMIC-III dataset. On comparison to approaches\nutilizing structured data, it achieved higher metrics despite requiring less\ncleaning and preprocessing. This demonstrates the potential of unstructured\ndata in enhancing mortality prediction and signifies the need to incorporate\nmore raw unstructured data into current clinical prediction methods.\n", "versions": [{"version": "v1", "created": "Tue, 19 Nov 2019 18:02:06 GMT"}], "update_date": "2019-11-20", "authors_parsed": [["Hashir", "Mohammad", ""], ["Sawhney", "Rapinder", ""]]}, {"id": "1911.08444", "submitter": "Homanga Bharadhwaj", "authors": "Homanga Bharadhwaj, Shoichiro Yamaguchi, Shin-ichi Maeda", "title": "MANGA: Method Agnostic Neural-policy Generalization and Adaptation", "comments": "Under Review. Video available at\n  https://drive.google.com/file/d/12GsDq3iQDXEutE-xpzXxqrEfD6dYhKjs/view?usp=sharing\n  Other details will be made available in the author's webpage\n  www.homangabharadhwaj.com", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.RO stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we target the problem of transferring policies across multiple\nenvironments with different dynamics parameters and motor noise variations, by\nintroducing a framework that decouples the processes of policy learning and\nsystem identification. Efficiently transferring learned policies to an unknown\nenvironment with changes in dynamics configurations in the presence of motor\nnoise is very important for operating robots in the real world, and our work is\na novel attempt in that direction. We introduce MANGA: Method Agnostic\nNeural-policy Generalization and Adaptation, that trains dynamics conditioned\npolicies and efficiently learns to estimate the dynamics parameters of the\nenvironment given off-policy state-transition rollouts in the environment. Our\nscheme is agnostic to the type of training method used - both reinforcement\nlearning (RL) and imitation learning (IL) strategies can be used. We\ndemonstrate the effectiveness of our approach by experimenting with four\ndifferent MuJoCo agents and comparing against previously proposed transfer\nbaselines.\n", "versions": [{"version": "v1", "created": "Tue, 19 Nov 2019 18:10:56 GMT"}], "update_date": "2019-11-20", "authors_parsed": [["Bharadhwaj", "Homanga", ""], ["Yamaguchi", "Shoichiro", ""], ["Maeda", "Shin-ichi", ""]]}, {"id": "1911.08453", "submitter": "Soroush Nasiriany", "authors": "Soroush Nasiriany, Vitchyr H. Pong, Steven Lin, Sergey Levine", "title": "Planning with Goal-Conditioned Policies", "comments": "In Advances in Neural Information Processing Systems, 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.RO stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Planning methods can solve temporally extended sequential decision making\nproblems by composing simple behaviors. However, planning requires suitable\nabstractions for the states and transitions, which typically need to be\ndesigned by hand. In contrast, model-free reinforcement learning (RL) can\nacquire behaviors from low-level inputs directly, but often struggles with\ntemporally extended tasks. Can we utilize reinforcement learning to\nautomatically form the abstractions needed for planning, thus obtaining the\nbest of both approaches? We show that goal-conditioned policies learned with RL\ncan be incorporated into planning, so that a planner can focus on which states\nto reach, rather than how those states are reached. However, with complex state\nobservations such as images, not all inputs represent valid states. We\ntherefore also propose using a latent variable model to compactly represent the\nset of valid states for the planner, so that the policies provide an\nabstraction of actions, and the latent variable model provides an abstraction\nof states. We compare our method with planning-based and model-free methods and\nfind that our method significantly outperforms prior work when evaluated on\nimage-based robot navigation and manipulation tasks that require non-greedy,\nmulti-staged behavior.\n", "versions": [{"version": "v1", "created": "Tue, 19 Nov 2019 18:25:22 GMT"}], "update_date": "2019-11-20", "authors_parsed": [["Nasiriany", "Soroush", ""], ["Pong", "Vitchyr H.", ""], ["Lin", "Steven", ""], ["Levine", "Sergey", ""]]}, {"id": "1911.08459", "submitter": "Tian Han", "authors": "Dandan Zhu, Tian Han, Linqi Zhou, Xiaokang Yang, Ying Nian Wu", "title": "Deep Unsupervised Clustering with Clustered Generator Model", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper addresses the problem of unsupervised clustering which remains one\nof the most fundamental challenges in machine learning and artificial\nintelligence. We propose the clustered generator model for clustering which\ncontains both continuous and discrete latent variables. Discrete latent\nvariables model the cluster label while the continuous ones model variations\nwithin each cluster. The learning of the model proceeds in a unified\nprobabilistic framework and incorporates the unsupervised clustering as an\ninner step without the need for an extra inference model as in existing\nvariational-based models. The latent variables learned serve as both observed\ndata embedding or latent representation for data distribution. Our experiments\nshow that the proposed model can achieve competitive unsupervised clustering\naccuracy and can learn disentangled latent representations to generate\nrealistic samples. In addition, the model can be naturally extended to\nper-pixel unsupervised clustering which remains largely unexplored.\n", "versions": [{"version": "v1", "created": "Tue, 19 Nov 2019 18:39:44 GMT"}], "update_date": "2019-11-20", "authors_parsed": [["Zhu", "Dandan", ""], ["Han", "Tian", ""], ["Zhou", "Linqi", ""], ["Yang", "Xiaokang", ""], ["Wu", "Ying Nian", ""]]}, {"id": "1911.08478", "submitter": "Ankur Mali", "authors": "Ankur Mali, Alexander G. Ororbia, Clyde Lee Giles", "title": "Sibling Neural Estimators: Improving Iterative Image Decoding with\n  Gradient Communication", "comments": "11 Pages, 2 figures, 1 Table", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  For lossy image compression, we develop a neural-based system which learns a\nnonlinear estimator for decoding from quantized representations. The system\nlinks two recurrent networks that \\help\" each other reconstruct same target\nimage patches using complementary portions of spatial context that communicate\nvia gradient signals. This dual agent system builds upon prior work that\nproposed the iterative refinement algorithm for recurrent neural network\n(RNN)based decoding which improved image reconstruction compared to standard\ndecoding techniques. Our approach, which works with any encoder, neural or\nnon-neural, This system progressively reduces image patch reconstruction error\nover a fixed number of steps. Experiment with variants of RNN memory cells,\nwith and without future information, find that our model consistently creates\nlower distortion images of higher perceptual quality compared to other\napproaches. Specifically, on the Kodak Lossless True Color Image Suite, we\nobserve as much as a 1:64 decibel (dB) gain over JPEG, a 1:46 dB gain over JPEG\n2000, a 1:34 dB gain over the GOOG neural baseline, 0:36 over E2E (a modern\ncompetitive neural compression model), and 0:37 over a single iterative neural\ndecoder.\n", "versions": [{"version": "v1", "created": "Wed, 20 Nov 2019 00:18:44 GMT"}], "update_date": "2019-11-21", "authors_parsed": [["Mali", "Ankur", ""], ["Ororbia", "Alexander G.", ""], ["Giles", "Clyde Lee", ""]]}, {"id": "1911.08483", "submitter": "Chengliang Dai", "authors": "Shuo Wang, Chengliang Dai, Yuanhan Mo, Elsa Angelini, Yike Guo, Wenjia\n  Bai", "title": "Automatic Brain Tumour Segmentation and Biophysics-Guided Survival\n  Prediction", "comments": "MICCAI BraTS 2019 Challenge", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.IV cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Gliomas are the most common malignant brain tumourswith intrinsic\nheterogeneity. Accurate segmentation of gliomas and theirsub-regions on\nmulti-parametric magnetic resonance images (mpMRI)is of great clinical\nimportance, which defines tumour size, shape andappearance and provides\nabundant information for preoperative diag-nosis, treatment planning and\nsurvival prediction. Recent developmentson deep learning have significantly\nimproved the performance of auto-mated medical image segmentation. In this\npaper, we compare severalstate-of-the-art convolutional neural network models\nfor brain tumourimage segmentation. Based on the ensembled segmentation, we\npresenta biophysics-guided prognostic model for patient overall survival\npredic-tion which outperforms a data-driven radiomics approach. Our methodwon\nthe second place of the MICCAI 2019 BraTS Challenge for theoverall survival\nprediction.\n", "versions": [{"version": "v1", "created": "Tue, 19 Nov 2019 14:44:55 GMT"}], "update_date": "2019-11-21", "authors_parsed": [["Wang", "Shuo", ""], ["Dai", "Chengliang", ""], ["Mo", "Yuanhan", ""], ["Angelini", "Elsa", ""], ["Guo", "Yike", ""], ["Bai", "Wenjia", ""]]}, {"id": "1911.08508", "submitter": "Hector Javier Hortua", "authors": "Hector J. Hortua, Riccardo Volpi, Dimitri Marinelli, and Luigi\n  Malag\\`o", "title": "Parameters Estimation for the Cosmic Microwave Background with Bayesian\n  Neural Networks", "comments": "24 pages with 19 figures", "journal-ref": "Phys. Rev. D 102, 103509 (2020)", "doi": "10.1103/PhysRevD.102.103509", "report-no": null, "categories": "astro-ph.IM cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we present the first study that compares different models of\nBayesian Neural Networks (BNNs) to predict the posterior distribution of the\ncosmological parameters directly from the Cosmic Microwave Background\ntemperature and polarization maps. We focus our analysis on four different\nmethods to sample the weights of the network during training: Dropout,\nDropConnect, Reparameterization Trick (RT), and Flipout. We find out that\nFlipout outperforms all other methods regardless of the architecture used, and\nprovides tighter constraints for the cosmological parameters. Moreover we\ncompare with MCMC posterior analysis obtaining comparable error correlation\namong parameters, with BNNs being orders of magnitude faster in inference,\nalthough less accurate. Thanks to the speed of the inference process with BNNs,\nthe posterior distribution, outcome of the neural network, can be used as the\ninitial proposal for the Markov Chain. We show that this combined approach\nincreases the acceptance rate in the Metropolis-Hasting algorithm and\naccelerates the convergence of the MCMC, while reaching the same final\naccuracy. In the second part of the paper, we present a guide to the training\nand calibration of a successful multi-channel BNN for the CMB temperature and\npolarization map. We show how tuning the regularization parameter for the\nstandard deviation of the approximate posterior on the weights in Flipout and\nRT we can produce unbiased and reliable uncertainty estimates, i.e., the\nregularizer acts like a hyperparameter analogous to the dropout rate in\nDropout. Finally, we show how polarization, when combined with the temperature\nin a unique multi-channel tensor fed to a single BNN, helps to break\ndegeneracies among parameters and provides stringent constraints.\n", "versions": [{"version": "v1", "created": "Tue, 19 Nov 2019 19:09:53 GMT"}, {"version": "v2", "created": "Mon, 23 Dec 2019 17:02:26 GMT"}, {"version": "v3", "created": "Fri, 30 Oct 2020 05:30:09 GMT"}], "update_date": "2020-11-13", "authors_parsed": [["Hortua", "Hector J.", ""], ["Volpi", "Riccardo", ""], ["Marinelli", "Dimitri", ""], ["Malag\u00f2", "Luigi", ""]]}, {"id": "1911.08517", "submitter": "Mo Yu", "authors": "Xiang Ni, Jing Li, Mo Yu, Wang Zhou, Kun-Lung Wu", "title": "Generalizable Resource Allocation in Stream Processing via Deep\n  Reinforcement Learning", "comments": "Accepted by AAAI 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.DC eess.SP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper considers the problem of resource allocation in stream processing,\nwhere continuous data flows must be processed in real time in a large\ndistributed system. To maximize system throughput, the resource allocation\nstrategy that partitions the computation tasks of a stream processing graph\nonto computing devices must simultaneously balance workload distribution and\nminimize communication. Since this problem of graph partitioning is known to be\nNP-complete yet crucial to practical streaming systems, many heuristic-based\nalgorithms have been developed to find reasonably good solutions. In this\npaper, we present a graph-aware encoder-decoder framework to learn a\ngeneralizable resource allocation strategy that can properly distribute\ncomputation tasks of stream processing graphs unobserved from training data.\nWe, for the first time, propose to leverage graph embedding to learn the\nstructural information of the stream processing graphs. Jointly trained with\nthe graph-aware decoder using deep reinforcement learning, our approach can\neffectively find optimized solutions for unseen graphs. Our experiments show\nthat the proposed model outperforms both METIS, a state-of-the-art graph\npartitioning algorithm, and an LSTM-based encoder-decoder model, in about 70%\nof the test cases.\n", "versions": [{"version": "v1", "created": "Tue, 19 Nov 2019 19:25:42 GMT"}], "update_date": "2019-11-21", "authors_parsed": [["Ni", "Xiang", ""], ["Li", "Jing", ""], ["Yu", "Mo", ""], ["Zhou", "Wang", ""], ["Wu", "Kun-Lung", ""]]}, {"id": "1911.08522", "submitter": "Omar U. Florez", "authors": "Omar U. Florez and Erik Mueller", "title": "Aging Memories Generate More Fluent Dialogue Responses with Memory\n  Augmented Neural Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Memory Networks have emerged as effective models to incorporate Knowledge\nBases (KB) into neural networks. By storing KB embeddings into a memory\ncomponent, these models can learn meaningful representations that are grounded\nto external knowledge. However, as the memory unit becomes full, the oldest\nmemories are replaced by newer representations.\n  In this paper, we question this approach and provide experimental evidence\nthat conventional Memory Networks store highly correlated vectors during\ntraining. While increasing the memory size mitigates this problem, this also\nleads to overfitting as the memory stores a large number of training latent\nrepresentations. To address these issues, we propose a novel regularization\nmechanism named memory dropout which 1) Samples a single latent vector from the\ndistribution of redundant memories. 2) Ages redundant memories thus increasing\ntheir probability of overwriting them during training. This fully\ndifferentiable technique allows us to achieve state-of-the-art response\ngeneration in the Stanford Multi-Turn Dialogue and Cambridge Restaurant\ndatasets.\n", "versions": [{"version": "v1", "created": "Tue, 19 Nov 2019 19:34:15 GMT"}, {"version": "v2", "created": "Sun, 27 Sep 2020 02:42:46 GMT"}], "update_date": "2020-09-29", "authors_parsed": [["Florez", "Omar U.", ""], ["Mueller", "Erik", ""]]}, {"id": "1911.08530", "submitter": "Hongteng Xu", "authors": "Hongteng Xu", "title": "Gromov-Wasserstein Factorization Models for Graph Clustering", "comments": "The Thirty-Fourth AAAI Conference on Artificial Intelligence\n  (AAAI-20)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a new nonlinear factorization model for graphs that are with\ntopological structures, and optionally, node attributes. This model is based on\na pseudometric called Gromov-Wasserstein (GW) discrepancy, which compares\ngraphs in a relational way. It estimates observed graphs as GW barycenters\nconstructed by a set of atoms with different weights. By minimizing the GW\ndiscrepancy between each observed graph and its GW barycenter-based estimation,\nwe learn the atoms and their weights associated with the observed graphs. The\nmodel achieves a novel and flexible factorization mechanism under GW\ndiscrepancy, in which both the observed graphs and the learnable atoms can be\nunaligned and with different sizes. We design an effective approximate\nalgorithm for learning this Gromov-Wasserstein factorization (GWF) model,\nunrolling loopy computations as stacked modules and computing gradients with\nbackpropagation. The stacked modules can be with two different architectures,\nwhich correspond to the proximal point algorithm (PPA) and Bregman alternating\ndirection method of multipliers (BADMM), respectively. Experiments show that\nour model obtains encouraging results on clustering graphs.\n", "versions": [{"version": "v1", "created": "Tue, 19 Nov 2019 19:49:04 GMT"}], "update_date": "2019-11-21", "authors_parsed": [["Xu", "Hongteng", ""]]}, {"id": "1911.08532", "submitter": "Ayush Jain", "authors": "Ayush Jain, Alon Orlitsky", "title": "Optimal Robust Learning of Discrete Distributions from Batches", "comments": "Added experiments, minor improvement in results", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Many applications, including natural language processing, sensor networks,\ncollaborative filtering, and federated learning, call for estimating discrete\ndistributions from data collected in batches, some of which may be\nuntrustworthy, erroneous, faulty, or even adversarial.\n  Previous estimators for this setting ran in exponential time, and for some\nregimes required a suboptimal number of batches. We provide the first\npolynomial-time estimator that is optimal in the number of batches and achieves\nessentially the best possible estimation accuracy.\n", "versions": [{"version": "v1", "created": "Tue, 19 Nov 2019 19:51:25 GMT"}, {"version": "v2", "created": "Mon, 24 Feb 2020 19:18:34 GMT"}], "update_date": "2020-02-26", "authors_parsed": [["Jain", "Ayush", ""], ["Orlitsky", "Alon", ""]]}, {"id": "1911.08538", "submitter": "Yuxiang Ren", "authors": "Yuxiang Ren, Bo Liu, Chao Huang, Peng Dai, Liefeng Bo, Jiawei Zhang", "title": "Heterogeneous Deep Graph Infomax", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.SI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Graph representation learning is to learn universal node representations that\npreserve both node attributes and structural information. The derived node\nrepresentations can be used to serve various downstream tasks, such as node\nclassification and node clustering. When a graph is heterogeneous, the problem\nbecomes more challenging than the homogeneous graph node learning problem.\nInspired by the emerging information theoretic-based learning algorithm, in\nthis paper we propose an unsupervised graph neural network Heterogeneous Deep\nGraph Infomax (HDGI) for heterogeneous graph representation learning. We use\nthe meta-path structure to analyze the connections involving semantics in\nheterogeneous graphs and utilize graph convolution module and semantic-level\nattention mechanism to capture local representations. By maximizing\nlocal-global mutual information, HDGI effectively learns high-level node\nrepresentations that can be utilized in downstream graph-related tasks.\nExperiment results show that HDGI remarkably outperforms state-of-the-art\nunsupervised graph representation learning methods on both classification and\nclustering tasks. By feeding the learned representations into a parametric\nmodel, such as logistic regression, we even achieve comparable performance in\nnode classification tasks when comparing with state-of-the-art supervised\nend-to-end GNN models.\n", "versions": [{"version": "v1", "created": "Tue, 19 Nov 2019 20:07:45 GMT"}, {"version": "v2", "created": "Tue, 4 Feb 2020 17:12:17 GMT"}, {"version": "v3", "created": "Thu, 30 Jul 2020 03:55:24 GMT"}, {"version": "v4", "created": "Fri, 31 Jul 2020 01:19:32 GMT"}, {"version": "v5", "created": "Fri, 13 Nov 2020 07:34:57 GMT"}], "update_date": "2020-11-16", "authors_parsed": [["Ren", "Yuxiang", ""], ["Liu", "Bo", ""], ["Huang", "Chao", ""], ["Dai", "Peng", ""], ["Bo", "Liefeng", ""], ["Zhang", "Jiawei", ""]]}, {"id": "1911.08542", "submitter": "Omar U. Florez", "authors": "Omar U. Florez and Erik Mueller", "title": "Learning to Control Latent Representations for Few-Shot Learning of\n  Named Entities", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Humans excel in continuously learning with small data without forgetting how\nto solve old problems. However, neural networks require large datasets to\ncompute latent representations across different tasks while minimizing a loss\nfunction. For example, a natural language understanding (NLU) system will often\ndeal with emerging entities during its deployment as interactions with users in\nrealistic scenarios will generate new and infrequent names, events, and\nlocations. Here, we address this scenario by introducing an RL trainable\ncontroller that disentangles the representation learning of a neural encoder\nfrom its memory management role.\n  Our proposed solution is straightforward and simple: we train a controller to\nexecute an optimal sequence of reading and writing operations on an external\nmemory with the goal of leveraging diverse activations from the past and\nprovide accurate predictions. Our approach is named Learning to Control (LTC)\nand allows few-shot learning with two degrees of memory plasticity. We\nexperimentally show that our system obtains accurate results for few-shot\nlearning of entity recognition in the Stanford Task-Oriented Dialogue dataset.\n", "versions": [{"version": "v1", "created": "Tue, 19 Nov 2019 20:15:08 GMT"}], "update_date": "2019-11-21", "authors_parsed": [["Florez", "Omar U.", ""], ["Mueller", "Erik", ""]]}, {"id": "1911.08551", "submitter": "Jason Ren", "authors": "Jason Ren, Russell Kunes, Finale Doshi-Velez", "title": "Prediction Focused Topic Models for Electronic Health Records", "comments": "Machine Learning for Health (ML4H) at NeurIPS 2019 - Extended\n  Abstract. arXiv admin note: substantial text overlap with arXiv:1910.05495", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Electronic Health Record (EHR) data can be represented as discrete counts\nover a high dimensional set of possible procedures, diagnoses, and medications.\nSupervised topic models present an attractive option for incorporating EHR data\nas features into a prediction problem: given a patient's record, we estimate a\nset of latent factors that are predictive of the response variable. However,\nexisting methods for supervised topic modeling struggle to balance prediction\nquality and coherence of the latent factors. We introduce a novel approach, the\nprediction-focused topic model, that uses the supervisory signal to retain only\nfeatures that improve, or do not hinder, prediction performance. By removing\nfeatures with irrelevant signal, the topic model is able to learn\ntask-relevant, interpretable topics. We demonstrate on a EHR dataset and a\nmovie review dataset that compared to existing approaches, prediction-focused\ntopic models are able to learn much more coherent topics while maintaining\ncompetitive predictions.\n", "versions": [{"version": "v1", "created": "Fri, 15 Nov 2019 23:19:43 GMT"}], "update_date": "2019-11-21", "authors_parsed": [["Ren", "Jason", ""], ["Kunes", "Russell", ""], ["Doshi-Velez", "Finale", ""]]}, {"id": "1911.08553", "submitter": "Brian Gaudet", "authors": "Brian Gaudet, Richard Linares, Roberto Furfaro", "title": "Six Degree-of-Freedom Body-Fixed Hovering over Unmapped Asteroids via\n  LIDAR Altimetry and Reinforcement Meta-Learning", "comments": "Earlier version presented at 2020 AIAA Scitech conference. arXiv\n  admin note: substantial text overlap with arXiv:1907.06098, arXiv:1906.02113", "journal-ref": null, "doi": "10.1016/j.actaastro.2020.03.026", "report-no": null, "categories": "eess.SY cs.AI cs.LG cs.SY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We optimize a six degrees of freedom hovering policy using reinforcement\nmeta-learning. The policy maps flash LIDAR measurements directly to on/off\nspacecraft body-frame thrust commands, allowing hovering at a fixed position\nand attitude in the asteroid body-fixed reference frame. Importantly, the\npolicy does not require position and velocity estimates, and can operate in\nenvironments with unknown dynamics, and without an asteroid shape model or\nnavigation aids. Indeed, during optimization the agent is confronted with a new\nrandomly generated asteroid for each episode, insuring that it does not learn\nan asteroid's shape, texture, or environmental dynamics. This allows the\ndeployed policy to generalize well to novel asteroid characteristics, which we\ndemonstrate in our experiments. Moreover, our experiments show that the\noptimized policy adapts to actuator failure and sensor noise. Although the\npolicy is optimized using randomly generated synthetic asteroids, it is tested\non two shape models from actual asteroids: Bennu and Itokawa. We find that the\npolicy generalizes well to these shape models. The hovering controller has the\npotential to simplify mission planning by allowing asteroid body-fixed hovering\nimmediately upon the spacecraft's arrival to an asteroid. This in turn\nsimplifies shape model generation and allows resource mapping via remote\nsensing immediately upon arrival at the target asteroid.\n", "versions": [{"version": "v1", "created": "Sat, 16 Nov 2019 00:04:31 GMT"}, {"version": "v2", "created": "Sat, 8 Feb 2020 19:56:15 GMT"}], "update_date": "2020-09-16", "authors_parsed": [["Gaudet", "Brian", ""], ["Linares", "Richard", ""], ["Furfaro", "Roberto", ""]]}, {"id": "1911.08554", "submitter": "Sam Shleifer", "authors": "Sam Shleifer, Manish Chablani, Anitha Kannan, Namit Katariya, Xavier\n  Amatriain", "title": "Classification as Decoder: Trading Flexibility for Control in Medical\n  Dialogue", "comments": "Machine Learning for Health (ML4H) at NeurIPS 2019 - Extended\n  Abstract. arXiv admin note: substantial text overlap with arXiv:1910.03476", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Generative seq2seq dialogue systems are trained to predict the next word in\ndialogues that have already occurred. They can learn from large unlabeled\nconversation datasets, build a deeper understanding of conversational context,\nand generate a wide variety of responses. This flexibility comes at the cost of\ncontrol, a concerning tradeoff in doctor/patient interactions. Inaccuracies,\ntypos, or undesirable content in the training data will be reproduced by the\nmodel at inference time. We trade a small amount of labeling effort and some\nloss of response variety in exchange for quality control. More specifically, a\npretrained language model encodes the conversational context, and we finetune a\nclassification head to map an encoded conversational context to a response\nclass, where each class is a noisily labeled group of interchangeable\nresponses. Experts can update these exemplar responses over time as best\npractices change without retraining the classifier or invalidating old training\ndata. Expert evaluation of 775 unseen doctor/patient conversations shows that\nonly 12% of the discriminative model's responses are worse than the what the\ndoctor ended up writing, compared to 18% for the generative model.\n", "versions": [{"version": "v1", "created": "Sat, 16 Nov 2019 01:58:27 GMT"}], "update_date": "2019-11-21", "authors_parsed": [["Shleifer", "Sam", ""], ["Chablani", "Manish", ""], ["Kannan", "Anitha", ""], ["Katariya", "Namit", ""], ["Amatriain", "Xavier", ""]]}, {"id": "1911.08556", "submitter": "Komal Teru", "authors": "Komal K. Teru and Aishik Chakraborty", "title": "Towards Reducing Bias in Gender Classification", "comments": "arXiv admin note: text overlap with arXiv:1706.00409 by other authors", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Societal bias towards certain communities is a big problem that affects a lot\nof machine learning systems. This work aims at addressing the racial bias\npresent in many modern gender recognition systems. We learn race invariant\nrepresentations of human faces with an adversarially trained autoencoder model.\nWe show that such representations help us achieve less biased performance in\ngender classification. We use variance in classification accuracy across\ndifferent races as a surrogate for the racial bias of the model and achieve a\ndrop of over 40% in variance with race invariant representations.\n", "versions": [{"version": "v1", "created": "Sat, 16 Nov 2019 05:21:54 GMT"}], "update_date": "2019-11-21", "authors_parsed": [["Teru", "Komal K.", ""], ["Chakraborty", "Aishik", ""]]}, {"id": "1911.08567", "submitter": "Praveen Kumar Bodigutla", "authors": "Praveen Kumar Bodigutla, Lazaros Polymenakos, Spyros Matsoukas", "title": "Multi-domain Conversation Quality Evaluation via User Satisfaction\n  Estimation", "comments": "The 3rd Conversational AI workshop: Today's practice and tomorrow's\n  potential at NeurIPS 2019. arXiv admin note: substantial text overlap with\n  arXiv:1908.07064", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.HC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  An automated metric to evaluate dialogue quality is vital for optimizing data\ndriven dialogue management. The common approach of relying on explicit user\nfeedback during a conversation is intrusive and sparse. Current models to\nestimate user satisfaction use limited feature sets and employ annotation\nschemes with limited generalizability to conversations spanning multiple\ndomains. To address these gaps, we created a new Response Quality annotation\nscheme, introduced five new domain-independent feature sets and experimented\nwith six machine learning models to estimate User Satisfaction at both turn and\ndialogue level.\n  Response Quality ratings achieved significantly high correlation (0.76) with\nexplicit turn-level user ratings. Using the new feature sets we introduced,\nGradient Boosting Regression model achieved best (rating [1-5]) prediction\nperformance on 26 seen (linear correlation ~0.79) and one new multi-turn domain\n(linear correlation 0.67). We observed a 16% relative improvement (68% -> 79%)\nin binary (\"satisfactory/dissatisfactory\") class prediction accuracy of a\ndomain-independent dialogue-level satisfaction estimation model after including\npredicted turn-level satisfaction ratings as features.\n", "versions": [{"version": "v1", "created": "Mon, 18 Nov 2019 00:11:47 GMT"}], "update_date": "2019-11-21", "authors_parsed": [["Bodigutla", "Praveen Kumar", ""], ["Polymenakos", "Lazaros", ""], ["Matsoukas", "Spyros", ""]]}, {"id": "1911.08568", "submitter": "Michael Diodato", "authors": "Michael Diodato, Yu Li, Antonia Lovjer, Minsu Yeom, Albert Song,\n  Yiyang Zeng, Abhay Khosla, Benedikt Schifferer, Manik Goyal, Iddo Drori", "title": "Accurate Trajectory Prediction for Autonomous Vehicles", "comments": "arXiv admin note: text overlap with arXiv:1910.10318,\n  arXiv:1910.10317", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Predicting vehicle trajectories, angle and speed is important for safe and\ncomfortable driving. We demonstrate the best predicted angle, speed, and best\nperformance overall winning the top three places of the ICCV 2019 Learning to\nDrive challenge. Our key contributions are (i) a general neural network system\narchitecture which embeds and fuses together multiple inputs by encoding, and\ndecodes multiple outputs using neural networks, (ii) using pre-trained neural\nnetworks for augmenting the given input data with segmentation maps and\nsemantic information, and (iii) leveraging the form and distribution of the\nexpected output in the model.\n", "versions": [{"version": "v1", "created": "Mon, 18 Nov 2019 06:38:33 GMT"}], "update_date": "2019-11-21", "authors_parsed": [["Diodato", "Michael", ""], ["Li", "Yu", ""], ["Lovjer", "Antonia", ""], ["Yeom", "Minsu", ""], ["Song", "Albert", ""], ["Zeng", "Yiyang", ""], ["Khosla", "Abhay", ""], ["Schifferer", "Benedikt", ""], ["Goyal", "Manik", ""], ["Drori", "Iddo", ""]]}, {"id": "1911.08577", "submitter": "Vasco Portilheiro", "authors": "Vasco Portilheiro", "title": "Representation Learning with Multisets", "comments": "Under review as a conference paper at ICLR 2020. Preliminary version\n  accepted to the NeurIPS 2019 workshop on Sets and Partitions", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the problem of learning permutation invariant representations that\ncan capture \"flexible\" notions of containment. We formalize this problem via a\nmeasure theoretic definition of multisets, and obtain a theoretically-motivated\nlearning model. We propose training this model on a novel task: predicting the\nsize of the symmetric difference (or intersection) between pairs of multisets.\nWe demonstrate that our model not only performs very well on predicting\ncontainment relations (and more effectively predicts the sizes of symmetric\ndifferences and intersections than DeepSets-based approaches with unconstrained\nobject representations), but that it also learns meaningful representations.\n", "versions": [{"version": "v1", "created": "Tue, 19 Nov 2019 20:50:20 GMT"}], "update_date": "2019-11-21", "authors_parsed": [["Portilheiro", "Vasco", ""]]}, {"id": "1911.08581", "submitter": "Yiheng Han", "authors": "Yiheng Han, Wang Zhao, Jia Pan, Zipeng Ye, Ran Yi, Yong-Jin Liu", "title": "A Configuration-Space Decomposition Scheme for Learning-based Collision\n  Checking", "comments": "7 pages,4 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Motion planning for robots of high degrees-of-freedom (DOFs) is an important\nproblem in robotics with sampling-based methods in configuration space C as one\npopular solution. Recently, machine learning methods have been introduced into\nsampling-based motion planning methods, which train a classifier to distinguish\ncollision free subspace from in-collision subspace in C. In this paper, we\npropose a novel configuration space decomposition method and show two nice\nproperties resulted from this decomposition. Using these two properties, we\nbuild a composite classifier that works compatibly with previous machine\nlearning methods by using them as the elementary classifiers. Experimental\nresults are presented, showing that our composite classifier outperforms\nstate-of-the-art single classifier methods by a large margin. A real\napplication of motion planning in a multi-robot system in plant phenotyping\nusing three UR5 robotic arms is also presented.\n", "versions": [{"version": "v1", "created": "Sun, 17 Nov 2019 11:48:16 GMT"}], "update_date": "2019-11-21", "authors_parsed": [["Han", "Yiheng", ""], ["Zhao", "Wang", ""], ["Pan", "Jia", ""], ["Ye", "Zipeng", ""], ["Yi", "Ran", ""], ["Liu", "Yong-Jin", ""]]}, {"id": "1911.08582", "submitter": "Jan Blumenkamp", "authors": "Jan Blumenkamp", "title": "End to end collision avoidance based on optical flow and neural networks", "comments": "Technical Report for project work", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.CV cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Optical flow is believed to play an important role in the agile flight of\nbirds and insects. Even though it is a very simple concept, it is rarely used\nin computer vision for collision avoidance. This work implements a neural\nnetwork based collision avoidance which was deployed and evaluated on a solely\nfor this purpose refitted car.\n", "versions": [{"version": "v1", "created": "Wed, 6 Nov 2019 14:50:17 GMT"}], "update_date": "2019-11-21", "authors_parsed": [["Blumenkamp", "Jan", ""]]}, {"id": "1911.08584", "submitter": "Eilif Muller", "authors": "Eilif B. Muller, Philippe Beaudoin", "title": "Neocortical plasticity: an unsupervised cake but no free lunch", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.NC cs.AI cs.LG cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The fields of artificial intelligence and neuroscience have a long history of\nfertile bi-directional interactions. On the one hand, important inspiration for\nthe development of artificial intelligence systems has come from the study of\nnatural systems of intelligence, the mammalian neocortex in particular. On the\nother, important inspiration for models and theories of the brain have emerged\nfrom artificial intelligence research. A central question at the intersection\nof these two areas is concerned with the processes by which neocortex learns,\nand the extent to which they are analogous to the back-propagation training\nalgorithm of deep networks. Matching the data efficiency, transfer and\ngeneralization properties of neocortical learning remains an area of active\nresearch in the field of deep learning. Recent advances in our understanding of\nneuronal, synaptic and dendritic physiology of the neocortex suggest new\napproaches for unsupervised representation learning, perhaps through a new\nclass of objective functions, which could act alongside or in lieu of\nback-propagation. Such local learning rules have implicit rather than explicit\nobjectives with respect to the training data, facilitating domain adaptation\nand generalization. Incorporating them into deep networks for representation\nlearning could better leverage unlabelled datasets to offer significant\nimprovements in data efficiency of downstream supervised readout learning, and\nreduce susceptibility to adversarial perturbations, at the cost of a more\nrestricted domain of applicability.\n", "versions": [{"version": "v1", "created": "Fri, 15 Nov 2019 18:32:42 GMT"}], "update_date": "2019-11-21", "authors_parsed": [["Muller", "Eilif B.", ""], ["Beaudoin", "Philippe", ""]]}, {"id": "1911.08585", "submitter": "Thomas Mesnard", "authors": "Thomas Mesnard, Gaetan Vignoud, Joao Sacramento, Walter Senn, Yoshua\n  Bengio", "title": "Ghost Units Yield Biologically Plausible Backprop in Deep Neural\n  Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.NC cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In the past few years, deep learning has transformed artificial intelligence\nresearch and led to impressive performance in various difficult tasks. However,\nit is still unclear how the brain can perform credit assignment across many\nareas as efficiently as backpropagation does in deep neural networks. In this\npaper, we introduce a model that relies on a new role for a neuronal inhibitory\nmachinery, referred to as ghost units. By cancelling the feedback coming from\nthe upper layer when no target signal is provided to the top layer, the ghost\nunits enables the network to backpropagate errors and do efficient credit\nassignment in deep structures. While considering one-compartment neurons and\nrequiring very few biological assumptions, it is able to approximate the error\ngradient and achieve good performance on classification tasks. Error\nbackpropagation occurs through the recurrent dynamics of the network and thanks\nto biologically plausible local learning rules. In particular, it does not\nrequire separate feedforward and feedback circuits. Different mechanisms for\ncancelling the feedback were studied, ranging from complete duplication of the\nconnectivity by long term processes to online replication of the feedback\nactivity. This reduced system combines the essential elements to have a working\nbiologically abstracted analogue of backpropagation with a simple formulation\nand proofs of the associated results. Therefore, this model is a step towards\nunderstanding how learning and memory are implemented in cortical multilayer\nstructures, but it also raises interesting perspectives for neuromorphic\nhardware.\n", "versions": [{"version": "v1", "created": "Fri, 15 Nov 2019 17:47:00 GMT"}], "update_date": "2019-11-21", "authors_parsed": [["Mesnard", "Thomas", ""], ["Vignoud", "Gaetan", ""], ["Sacramento", "Joao", ""], ["Senn", "Walter", ""], ["Bengio", "Yoshua", ""]]}, {"id": "1911.08587", "submitter": "Mee Seong Im", "authors": "Venkat R. Dasari, Mee Seong Im, Lubjana Beshaj", "title": "Solving machine learning optimization problems using quantum computers", "comments": "5 pages, 3 figures. Submitted to Proc. SPIE", "journal-ref": null, "doi": null, "report-no": null, "categories": "quant-ph cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Classical optimization algorithms in machine learning often take a long time\nto compute when applied to a multi-dimensional problem and require a huge\namount of CPU and GPU resource. Quantum parallelism has a potential to speed up\nmachine learning algorithms. We describe a generic mathematical model to\nleverage quantum parallelism to speed-up machine learning algorithms. We also\napply quantum machine learning and quantum parallelism applied to a\n$3$-dimensional image that vary with time.\n", "versions": [{"version": "v1", "created": "Sun, 17 Nov 2019 17:36:41 GMT"}], "update_date": "2019-11-21", "authors_parsed": [["Dasari", "Venkat R.", ""], ["Im", "Mee Seong", ""], ["Beshaj", "Lubjana", ""]]}, {"id": "1911.08588", "submitter": "Qilei Chen", "authors": "Qilei Chen, Xinzi Sun, Ning Zhang, Yu Cao, Benyuan Liu", "title": "Mini Lesions Detection on Diabetic Retinopathy Images via Large Scale\n  CNN Features", "comments": "diabetic retinopathy, mini lesion detection, FPN", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG cs.MM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Diabetic retinopathy (DR) is a diabetes complication that affects eyes. DR is\na primary cause of blindness in working-age people and it is estimated that 3\nto 4 million people with diabetes are blinded by DR every year worldwide. Early\ndiagnosis have been considered an effective way to mitigate such problem. The\nultimate goal of our research is to develop novel machine learning techniques\nto analyze the DR images generated by the fundus camera for automatically DR\ndiagnosis. In this paper, we focus on identifying small lesions on DR fundus\nimages. The results from our analysis, which include the lesion category and\ntheir exact locations in the image, can be used to facilitate the determination\nof DR severity (indicated by DR stages). Different from traditional object\ndetection for natural images, lesion detection for fundus images have unique\nchallenges. Specifically, the size of a lesion instance is usually very small,\ncompared with the original resolution of the fundus images, making them\ndiffcult to be detected. We analyze the lesion-vs-image scale carefully and\npropose a large-size feature pyramid network (LFPN) to preserve more image\ndetails for mini lesion instance detection. Our method includes an effective\nregion proposal strategy to increase the sensitivity. The experimental results\nshow that our proposed method is superior to the original feature pyramid\nnetwork (FPN) method and Faster RCNN.\n", "versions": [{"version": "v1", "created": "Tue, 19 Nov 2019 21:06:50 GMT"}], "update_date": "2019-11-21", "authors_parsed": [["Chen", "Qilei", ""], ["Sun", "Xinzi", ""], ["Zhang", "Ning", ""], ["Cao", "Yu", ""], ["Liu", "Benyuan", ""]]}, {"id": "1911.08603", "submitter": "Thilo Hagendorff", "authors": "Thilo Hagendorff", "title": "Forbidden knowledge in machine learning -- Reflections on the limits of\n  research and publication", "comments": null, "journal-ref": null, "doi": "10.1007/s00146-020-01045-4", "report-no": null, "categories": "cs.LG cs.AI cs.CY stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Certain research strands can yield \"forbidden knowledge\". This term refers to\nknowledge that is considered too sensitive, dangerous or taboo to be produced\nor shared. Discourses about such publication restrictions are already\nentrenched in scientific fields like IT security, synthetic biology or nuclear\nphysics research. This paper makes the case for transferring this discourse to\nmachine learning research. Some machine learning applications can very easily\nbe misused and unfold harmful consequences, for instance with regard to\ngenerative video or text synthesis, personality analysis, behavior\nmanipulation, software vulnerability detection and the like. Up to now, the\nmachine learning research community embraces the idea of open access. However,\nthis is opposed to precautionary efforts to prevent the malicious use of\nmachine learning applications. Information about or from such applications may,\nif improperly disclosed, cause harm to people, organizations or whole\nsocieties. Hence, the goal of this work is to outline norms that can help to\ndecide whether and when the dissemination of such information should be\nprevented. It proposes review parameters for the machine learning community to\nestablish an ethical framework on how to deal with forbidden knowledge and\ndual-use applications.\n", "versions": [{"version": "v1", "created": "Tue, 19 Nov 2019 21:43:06 GMT"}], "update_date": "2020-09-08", "authors_parsed": [["Hagendorff", "Thilo", ""]]}, {"id": "1911.08606", "submitter": "Luca Mocerino", "authors": "Luca Mocerino, Andrea Calimera", "title": "CoopNet: Cooperative Convolutional Neural Network for Low-Power MCUs", "comments": null, "journal-ref": "2019 26th IEEE International Conference on Electronics, Circuits\n  and Systems (ICECS)", "doi": "10.1109/ICECS46596.2019.8964993", "report-no": null, "categories": "cs.CV cs.LG eess.IV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Fixed-point quantization and binarization are two reduction methods adopted\nto deploy Convolutional Neural Networks (CNN) on end-nodes powered by low-power\nmicro-controller units (MCUs). While most of the existing works use them as\nstand-alone optimizations, this work aims at demonstrating there is margin for\na joint cooperation that leads to inferential engines with lower latency and\nhigher accuracy. Called CoopNet, the proposed heterogeneous model is conceived,\nimplemented and tested on off-the-shelf MCUs with small on-chip memory and few\ncomputational resources. Experimental results conducted on three different CNNs\nusing as test-bench the low-power RISC core of the Cortex-M family by ARM\nvalidate the CoopNet proposal by showing substantial improvements w.r.t.\ndesigns where quantization and binarization are applied separately.\n", "versions": [{"version": "v1", "created": "Tue, 19 Nov 2019 21:47:23 GMT"}, {"version": "v2", "created": "Tue, 26 Nov 2019 18:35:18 GMT"}, {"version": "v3", "created": "Sat, 25 Jan 2020 12:10:51 GMT"}], "update_date": "2020-01-28", "authors_parsed": [["Mocerino", "Luca", ""], ["Calimera", "Andrea", ""]]}, {"id": "1911.08608", "submitter": "Michele Rossi", "authors": "Riccardo Bonetto, Mattia Soldan, Alberto Lanaro, Simone Milani,\n  Michele Rossi", "title": "Seq2Seq RNN based Gait Anomaly Detection from Smartphone Acquired\n  Multimodal Motion Data", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.SP cs.HC cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Smartphones and wearable devices are fast growing technologies that, in\nconjunction with advances in wireless sensor hardware, are enabling ubiquitous\nsensing applications. Wearables are suitable for indoor and outdoor scenarios,\ncan be placed on many parts of the human body and can integrate a large number\nof sensors capable of gathering physiological and behavioral biometric\ninformation. Here, we are concerned with gait analysis systems that extract\nmeaningful information from a user's movements to identify anomalies and\nchanges in their walking style. The solution that is put forward is\nsubject-specific, as the designed feature extraction and classification tools\nare trained on the subject under observation. A smartphone mounted on an ad-hoc\nmade chest support is utilized to gather inertial data and video signals from\nits built-in sensors and rear-facing camera. The collected video and inertial\ndata are preprocessed, combined and then classified by means of a Recurrent\nNeural Network (RNN) based Sequence-to-Sequence (Seq2Seq) model, which is used\nas a feature extractor, and a following Convolutional Neural Network (CNN)\nclassifier. This architecture provides excellent results, being able to\ncorrectly assess anomalies in 100% of the cases, for the considered tests,\nsurpassing the performance of support vector machine classifiers.\n", "versions": [{"version": "v1", "created": "Tue, 19 Nov 2019 21:57:42 GMT"}], "update_date": "2019-11-21", "authors_parsed": [["Bonetto", "Riccardo", ""], ["Soldan", "Mattia", ""], ["Lanaro", "Alberto", ""], ["Milani", "Simone", ""], ["Rossi", "Michele", ""]]}, {"id": "1911.08610", "submitter": "Borislav Mavrin", "authors": "Borislav Mavrin, Daniel Graves, Alan Chan", "title": "Efficient decorrelation of features using Gramian in Reinforcement\n  Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Learning good representations is a long standing problem in reinforcement\nlearning (RL). One of the conventional ways to achieve this goal in the\nsupervised setting is through regularization of the parameters. Extending some\nof these ideas to the RL setting has not yielded similar improvements in\nlearning. In this paper, we develop an online regularization framework for\ndecorrelating features in RL and demonstrate its utility in several test\nenvironments. We prove that the proposed algorithm converges in the linear\nfunction approximation setting and does not change the main objective of\nmaximizing cumulative reward. We demonstrate how to scale the approach to deep\nRL using the Gramian of the features achieving linear computational complexity\nin the number of features and squared complexity in size of the batch. We\nconduct an extensive empirical study of the new approach on Atari 2600 games\nand show a significant improvement in sample efficiency in 40 out of 49 games.\n", "versions": [{"version": "v1", "created": "Tue, 19 Nov 2019 22:10:08 GMT"}], "update_date": "2019-11-21", "authors_parsed": [["Mavrin", "Borislav", ""], ["Graves", "Daniel", ""], ["Chan", "Alan", ""]]}, {"id": "1911.08618", "submitter": "Badri Narayana Patro", "authors": "Badri N. Patro, Anupriy and Vinay P. Namboodiri", "title": "Explanation vs Attention: A Two-Player Game to Obtain Attention for VQA", "comments": "AAAI-2020(Accepted)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG cs.MM eess.IV", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  In this paper, we aim to obtain improved attention for a visual question\nanswering (VQA) task. It is challenging to provide supervision for attention.\nAn observation we make is that visual explanations as obtained through class\nactivation mappings (specifically Grad-CAM) that are meant to explain the\nperformance of various networks could form a means of supervision. However, as\nthe distributions of attention maps and that of Grad-CAMs differ, it would not\nbe suitable to directly use these as a form of supervision. Rather, we propose\nthe use of a discriminator that aims to distinguish samples of visual\nexplanation and attention maps. The use of adversarial training of the\nattention regions as a two-player game between attention and explanation serves\nto bring the distributions of attention maps and visual explanations closer.\nSignificantly, we observe that providing such a means of supervision also\nresults in attention maps that are more closely related to human attention\nresulting in a substantial improvement over baseline stacked attention network\n(SAN) models. It also results in a good improvement in rank correlation metric\non the VQA task. This method can also be combined with recent MCB based methods\nand results in consistent improvement. We also provide comparisons with other\nmeans for learning distributions such as based on Correlation Alignment\n(Coral), Maximum Mean Discrepancy (MMD) and Mean Square Error (MSE) losses and\nobserve that the adversarial loss outperforms the other forms of learning the\nattention maps. Visualization of the results also confirms our hypothesis that\nattention maps improve using this form of supervision.\n", "versions": [{"version": "v1", "created": "Tue, 19 Nov 2019 22:30:13 GMT"}], "update_date": "2019-11-21", "authors_parsed": [["Patro", "Badri N.", ""], ["Anupriy", "", ""], ["Namboodiri", "Vinay P.", ""]]}, {"id": "1911.08623", "submitter": "Guansong Pang", "authors": "Guansong Pang, Chunhua Shen, Anton van den Hengel", "title": "Deep Anomaly Detection with Deviation Networks", "comments": "10 Pages, Published in KDD19", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Although deep learning has been applied to successfully address many data\nmining problems, relatively limited work has been done on deep learning for\nanomaly detection. Existing deep anomaly detection methods, which focus on\nlearning new feature representations to enable downstream anomaly detection\nmethods, perform indirect optimization of anomaly scores, leading to\ndata-inefficient learning and suboptimal anomaly scoring. Also, they are\ntypically designed as unsupervised learning due to the lack of large-scale\nlabeled anomaly data. As a result, they are difficult to leverage prior\nknowledge (e.g., a few labeled anomalies) when such information is available as\nin many real-world anomaly detection applications.\n  This paper introduces a novel anomaly detection framework and its\ninstantiation to address these problems. Instead of representation learning,\nour method fulfills an end-to-end learning of anomaly scores by a neural\ndeviation learning, in which we leverage a few (e.g., multiple to dozens)\nlabeled anomalies and a prior probability to enforce statistically significant\ndeviations of the anomaly scores of anomalies from that of normal data objects\nin the upper tail. Extensive results show that our method can be trained\nsubstantially more data-efficiently and achieves significantly better anomaly\nscoring than state-of-the-art competing methods.\n", "versions": [{"version": "v1", "created": "Tue, 19 Nov 2019 23:05:36 GMT"}], "update_date": "2019-11-21", "authors_parsed": [["Pang", "Guansong", ""], ["Shen", "Chunhua", ""], ["Hengel", "Anton van den", ""]]}, {"id": "1911.08635", "submitter": "Minh Le", "authors": "Minh Le", "title": "Robust Deep Neural Networks Inspired by Fuzzy Logic", "comments": "7 pages, 4 figures, source code:\n  https://bitbucket.org/minhlab/newlogic", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.LO stat.ML", "license": "http://creativecommons.org/licenses/by-sa/4.0/", "abstract": "  Deep neural networks have achieved impressive performance and become the\nde-facto standard in many tasks. However, troubling phenomena such as\nadversarial and fooling examples suggest that the generalization they make is\nflawed. I argue that among the roots of the phenomena are two geometric\nproperties of common deep learning architectures: their distributed nature and\nthe connectedness of their decision regions. As a remedy, I propose new\narchitectures inspired by fuzzy logic that combine several alternative design\nelements. Through experiments on MNIST and CIFAR-10, the new models are shown\nto be more local, better at rejecting noise samples, and more robust against\nadversarial examples. Ablation analyses reveal behaviors on adversarial\nexamples that cannot be explained by the linearity hypothesis but are\nconsistent with the hypothesis that logic-inspired traits create more robust\nmodels.\n", "versions": [{"version": "v1", "created": "Wed, 20 Nov 2019 00:12:26 GMT"}, {"version": "v2", "created": "Mon, 3 Feb 2020 09:01:55 GMT"}, {"version": "v3", "created": "Sun, 26 Apr 2020 22:29:40 GMT"}], "update_date": "2020-04-28", "authors_parsed": [["Le", "Minh", ""]]}, {"id": "1911.08644", "submitter": "Hiromu Yakura", "authors": "Hiromu Yakura, Youhei Akimoto, Jun Sakuma", "title": "Generate (non-software) Bugs to Fool Classifiers", "comments": "Accepted by AAAI 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In adversarial attacks intended to confound deep learning models, most\nstudies have focused on limiting the magnitude of the modification so that\nhumans do not notice the attack. On the other hand, during an attack against\nautonomous cars, for example, most drivers would not find it strange if a small\ninsect image were placed on a stop sign, or they may overlook it. In this\npaper, we present a systematic approach to generate natural adversarial\nexamples against classification models by employing such natural-appearing\nperturbations that imitate a certain object or signal. We first show the\nfeasibility of this approach in an attack against an image classifier by\nemploying generative adversarial networks that produce image patches that have\nthe appearance of a natural object to fool the target model. We also introduce\nan algorithm to optimize placement of the perturbation in accordance with the\ninput image, which makes the generation of adversarial examples fast and likely\nto succeed. Moreover, we experimentally show that the proposed approach can be\nextended to the audio domain, for example, to generate perturbations that sound\nlike the chirping of birds to fool a speech classifier.\n", "versions": [{"version": "v1", "created": "Wed, 20 Nov 2019 00:43:07 GMT"}], "update_date": "2019-11-21", "authors_parsed": [["Yakura", "Hiromu", ""], ["Akimoto", "Youhei", ""], ["Sakuma", "Jun", ""]]}, {"id": "1911.08650", "submitter": "Jordan MacLachlan", "authors": "Jordan MacLachlan, Yi Mei, Juergen Branke, Mengjie Zhang", "title": "Genetic Programming Hyper-Heuristics with Vehicle Collaboration for\n  Uncertain Capacitated Arc Routing Problems", "comments": null, "journal-ref": null, "doi": "10.1162/evco_a_00267", "report-no": null, "categories": "cs.NE cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Due to its direct relevance to post-disaster operations, meter reading and\ncivil refuse collection, the Uncertain Capacitated Arc Routing Problem (UCARP)\nis an important optimisation problem. Stochastic models are critical to study\nas they more accurately represent the real-world than their deterministic\ncounterparts. Although there have been extensive studies in solving routing\nproblems under uncertainty, very few have considered UCARP, and none consider\ncollaboration between vehicles to handle the negative effects of uncertainty.\nThis paper proposes a novel Solution Construction Procedure (SCP) that\ngenerates solutions to UCARP within a collaborative, multi-vehicle framework.\nIt consists of two types of collaborative activities: one when a vehicle\nunexpectedly expends capacity (\\emph{route failure}), and the other during the\nrefill process. Then, we propose a Genetic Programming Hyper-Heuristic (GPHH)\nalgorithm to evolve the routing policy used within the collaborative framework.\nThe experimental studies show that the new heuristic with vehicle collaboration\nand GP-evolved routing policy significantly outperforms the compared\nstate-of-the-art algorithms on commonly studied test problems. This is shown to\nbe especially true on instances with larger numbers of tasks and vehicles. This\nclearly shows the advantage of vehicle collaboration in handling the uncertain\nenvironment, and the effectiveness of the newly proposed algorithm.\n", "versions": [{"version": "v1", "created": "Wed, 20 Nov 2019 00:55:00 GMT"}], "update_date": "2019-11-21", "authors_parsed": [["MacLachlan", "Jordan", ""], ["Mei", "Yi", ""], ["Branke", "Juergen", ""], ["Zhang", "Mengjie", ""]]}, {"id": "1911.08654", "submitter": "Phillip Pope", "authors": "Phillip Pope, Yogesh Balaji, Soheil Feizi", "title": "Adversarial Robustness of Flow-Based Generative Models", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Flow-based generative models leverage invertible generator functions to fit a\ndistribution to the training data using maximum likelihood. Despite their use\nin several application domains, robustness of these models to adversarial\nattacks has hardly been explored. In this paper, we study adversarial\nrobustness of flow-based generative models both theoretically (for some simple\nmodels) and empirically (for more complex ones). First, we consider a linear\nflow-based generative model and compute optimal sample-specific and universal\nadversarial perturbations that maximally decrease the likelihood scores. Using\nthis result, we study the robustness of the well-known adversarial training\nprocedure, where we characterize the fundamental trade-off between model\nrobustness and accuracy. Next, we empirically study the robustness of two\nprominent deep, non-linear, flow-based generative models, namely GLOW and\nRealNVP. We design two types of adversarial attacks; one that minimizes the\nlikelihood scores of in-distribution samples, while the other that maximizes\nthe likelihood scores of out-of-distribution ones. We find that GLOW and\nRealNVP are extremely sensitive to both types of attacks. Finally, using a\nhybrid adversarial training procedure, we significantly boost the robustness of\nthese generative models.\n", "versions": [{"version": "v1", "created": "Wed, 20 Nov 2019 01:16:57 GMT"}], "update_date": "2019-11-21", "authors_parsed": [["Pope", "Phillip", ""], ["Balaji", "Yogesh", ""], ["Feizi", "Soheil", ""]]}, {"id": "1911.08655", "submitter": "Rui Wang", "authors": "Rui Wang, Karthik Kashinath, Mustafa Mustafa, Adrian Albert, Rose Yu", "title": "Towards Physics-informed Deep Learning for Turbulent Flow Prediction", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "physics.comp-ph cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  While deep learning has shown tremendous success in a wide range of domains,\nit remains a grand challenge to incorporate physical principles in a systematic\nmanner to the design, training, and inference of such models. In this paper, we\naim to predict turbulent flow by learning its highly nonlinear dynamics from\nspatiotemporal velocity fields of large-scale fluid flow simulations of\nrelevance to turbulence modeling and climate modeling. We adopt a hybrid\napproach by marrying two well-established turbulent flow simulation techniques\nwith deep learning. Specifically, we introduce trainable spectral filters in a\ncoupled model of Reynolds-averaged Navier-Stokes (RANS) and Large Eddy\nSimulation (LES), followed by a specialized U-net for prediction. Our approach,\nwhich we call turbulent-Flow Net (TF-Net), is grounded in a principled physics\nmodel, yet offers the flexibility of learned representations. We compare our\nmodel, TF-Net, with state-of-the-art baselines and observe significant\nreductions in error for predictions 60 frames ahead. Most importantly, our\nmethod predicts physical fields that obey desirable physical characteristics,\nsuch as conservation of mass, whilst faithfully emulating the turbulent kinetic\nenergy field and spectrum, which are critical for accurate prediction of\nturbulent flows.\n", "versions": [{"version": "v1", "created": "Wed, 20 Nov 2019 01:16:57 GMT"}, {"version": "v2", "created": "Sat, 21 Dec 2019 19:50:00 GMT"}, {"version": "v3", "created": "Wed, 27 May 2020 16:48:51 GMT"}, {"version": "v4", "created": "Sat, 13 Jun 2020 22:11:29 GMT"}], "update_date": "2020-06-16", "authors_parsed": [["Wang", "Rui", ""], ["Kashinath", "Karthik", ""], ["Mustafa", "Mustafa", ""], ["Albert", "Adrian", ""], ["Yu", "Rose", ""]]}, {"id": "1911.08666", "submitter": "Vibhavari Dasagi", "authors": "Vibhavari Dasagi, Robert Lee, Jake Bruce and J\\\"urgen Leitner", "title": "Evaluating task-agnostic exploration for fixed-batch learning of\n  arbitrary future tasks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.RO stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep reinforcement learning has been shown to solve challenging tasks where\nlarge amounts of training experience is available, usually obtained online\nwhile learning the task. Robotics is a significant potential application domain\nfor many of these algorithms, but generating robot experience in the real world\nis expensive, especially when each task requires a lengthy online training\nprocedure. Off-policy algorithms can in principle learn arbitrary tasks from a\ndiverse enough fixed dataset. In this work, we evaluate popular exploration\nmethods by generating robotics datasets for the purpose of learning to solve\ntasks completely offline without any further interaction in the real world. We\npresent results on three popular continuous control tasks in simulation, as\nwell as continuous control of a high-dimensional real robot arm. Code\ndocumenting all algorithms, experiments, and hyper-parameters is available at\nhttps://github.com/qutrobotlearning/batchlearning.\n", "versions": [{"version": "v1", "created": "Wed, 20 Nov 2019 02:03:35 GMT"}], "update_date": "2019-11-21", "authors_parsed": [["Dasagi", "Vibhavari", ""], ["Lee", "Robert", ""], ["Bruce", "Jake", ""], ["Leitner", "J\u00fcrgen", ""]]}, {"id": "1911.08670", "submitter": "Hamid Reza Vaezi Joze", "authors": "Hamid Reza Vaezi Joze, Amirreza Shaban, Michael L. Iuzzolino and\n  Kazuhito Koishida", "title": "MMTM: Multimodal Transfer Module for CNN Fusion", "comments": null, "journal-ref": "The IEEE Conference on Computer Vision and Pattern Recognition\n  (CVPR), 2020", "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In late fusion, each modality is processed in a separate unimodal\nConvolutional Neural Network (CNN) stream and the scores of each modality are\nfused at the end. Due to its simplicity late fusion is still the predominant\napproach in many state-of-the-art multimodal applications. In this paper, we\npresent a simple neural network module for leveraging the knowledge from\nmultiple modalities in convolutional neural networks. The propose unit, named\nMultimodal Transfer Module (MMTM), can be added at different levels of the\nfeature hierarchy, enabling slow modality fusion. Using squeeze and excitation\noperations, MMTM utilizes the knowledge of multiple modalities to recalibrate\nthe channel-wise features in each CNN stream. Despite other intermediate fusion\nmethods, the proposed module could be used for feature modality fusion in\nconvolution layers with different spatial dimensions. Another advantage of the\nproposed method is that it could be added among unimodal branches with minimum\nchanges in the their network architectures, allowing each branch to be\ninitialized with existing pretrained weights. Experimental results show that\nour framework improves the recognition accuracy of well-known multimodal\nnetworks. We demonstrate state-of-the-art or competitive performance on four\ndatasets that span the task domains of dynamic hand gesture recognition, speech\nenhancement, and action recognition with RGB and body joints.\n", "versions": [{"version": "v1", "created": "Wed, 20 Nov 2019 02:32:16 GMT"}, {"version": "v2", "created": "Mon, 30 Mar 2020 22:40:45 GMT"}], "update_date": "2020-04-01", "authors_parsed": [["Joze", "Hamid Reza Vaezi", ""], ["Shaban", "Amirreza", ""], ["Iuzzolino", "Michael L.", ""], ["Koishida", "Kazuhito", ""]]}, {"id": "1911.08678", "submitter": "Zhao Zhang", "authors": "Huan Zhang, Zhao Zhang, Mingbo Zhao, Qiaolin Ye, Min Zhang and Meng\n  Wang", "title": "Robust Triple-Matrix-Recovery-Based Auto-Weighted Label Propagation for\n  Classification", "comments": "Accepted by IEEE TNNNLS", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The graph-based semi-supervised label propagation algorithm has delivered\nimpressive classification results. However, the estimated soft labels typically\ncontain mixed signs and noise, which cause inaccurate predictions due to the\nlack of suitable constraints. Moreover, available methods typically calculate\nthe weights and estimate the labels in the original input space, which\ntypically contains noise and corruption. Thus, the en-coded similarities and\nmanifold smoothness may be inaccurate for label estimation. In this paper, we\npresent effective schemes for resolving these issues and propose a novel and\nrobust semi-supervised classification algorithm, namely, the\ntri-ple-matrix-recovery-based robust auto-weighted label propa-gation framework\n(ALP-TMR). Our ALP-TMR introduces a triple matrix recovery mechanism to remove\nnoise or mixed signs from the estimated soft labels and improve the robustness\nto noise and outliers in the steps of assigning weights and pre-dicting the\nlabels simultaneously. Our method can jointly re-cover the underlying clean\ndata, clean labels and clean weighting spaces by decomposing the original data,\npredicted soft labels or weights into a clean part plus an error part by\nfitting noise. In addition, ALP-TMR integrates the au-to-weighting process by\nminimizing reconstruction errors over the recovered clean data and clean soft\nlabels, which can en-code the weights more accurately to improve both data\nrep-resentation and classification. By classifying samples in the recovered\nclean label and weight spaces, one can potentially improve the label prediction\nresults. The results of extensive experiments demonstrated the satisfactory\nperformance of our ALP-TMR.\n", "versions": [{"version": "v1", "created": "Wed, 20 Nov 2019 03:10:43 GMT"}], "update_date": "2019-11-21", "authors_parsed": [["Zhang", "Huan", ""], ["Zhang", "Zhao", ""], ["Zhao", "Mingbo", ""], ["Ye", "Qiaolin", ""], ["Zhang", "Min", ""], ["Wang", "Meng", ""]]}, {"id": "1911.08684", "submitter": "Kaiqun Fu", "authors": "Kaiqun Fu, Taoran Ji, Liang Zhao, Chang-Tien Lu", "title": "TITAN: A Spatiotemporal Feature Learning Framework for Traffic Incident\n  Duration Prediction", "comments": null, "journal-ref": null, "doi": "10.1145/3347146.3359381", "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Critical incident stages identification and reasonable prediction of traffic\nincident duration are essential in traffic incident management. In this paper,\nwe propose a traffic incident duration prediction model that simultaneously\npredicts the impact of the traffic incidents and identifies the critical groups\nof temporal features via a multi-task learning framework. First, we formulate a\nsparsity optimization problem that extracts low-level temporal features based\non traffic speed readings and then generalizes higher level features as phases\nof traffic incidents. Second, we propose novel constraints on feature\nsimilarity exploiting prior knowledge about the spatial connectivity of the\nroad network to predict the incident duration. The proposed problem is\nchallenging to solve due to the orthogonality constraints, non-convexity\nobjective, and non-smoothness penalties. We develop an algorithm based on the\nalternating direction method of multipliers (ADMM) framework to solve the\nproposed formulation. Extensive experiments and comparisons to other models on\nreal-world traffic data and traffic incident records justify the efficacy of\nour model.\n", "versions": [{"version": "v1", "created": "Wed, 20 Nov 2019 03:32:43 GMT"}], "update_date": "2019-11-21", "authors_parsed": [["Fu", "Kaiqun", ""], ["Ji", "Taoran", ""], ["Zhao", "Liang", ""], ["Lu", "Chang-Tien", ""]]}, {"id": "1911.08688", "submitter": "Sheng Jin", "authors": "Sheng Jin, Shangchen Zhou, Yao Liu, Chao Chen, Xiaoshuai Sun, Hongxun\n  Yao, Xiansheng Hua", "title": "SSAH: Semi-supervised Adversarial Deep Hashing with Self-paced Hard\n  Sample Generation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep hashing methods have been proved to be effective and efficient for\nlarge-scale Web media search. The success of these data-driven methods largely\ndepends on collecting sufficient labeled data, which is usually a crucial\nlimitation in practical cases. The current solutions to this issue utilize\nGenerative Adversarial Network (GAN) to augment data in semi-supervised\nlearning. However, existing GAN-based methods treat image generations and\nhashing learning as two isolated processes, leading to generation\nineffectiveness. Besides, most works fail to exploit the semantic information\nin unlabeled data. In this paper, we propose a novel Semi-supervised Self-pace\nAdversarial Hashing method, named SSAH to solve the above problems in a unified\nframework. The SSAH method consists of an adversarial network (A-Net) and a\nhashing network (H-Net). To improve the quality of generative images, first,\nthe A-Net learns hard samples with multi-scale occlusions and multi-angle\nrotated deformations which compete against the learning of accurate hashing\ncodes. Second, we design a novel self-paced hard generation policy to gradually\nincrease the hashing difficulty of generated samples. To make use of the\nsemantic information in unlabeled ones, we propose a semi-supervised consistent\nloss. The experimental results show that our method can significantly improve\nstate-of-the-art models on both the widely-used hashing datasets and\nfine-grained datasets.\n", "versions": [{"version": "v1", "created": "Wed, 20 Nov 2019 03:45:34 GMT"}], "update_date": "2019-11-21", "authors_parsed": [["Jin", "Sheng", ""], ["Zhou", "Shangchen", ""], ["Liu", "Yao", ""], ["Chen", "Chao", ""], ["Sun", "Xiaoshuai", ""], ["Yao", "Hongxun", ""], ["Hua", "Xiansheng", ""]]}, {"id": "1911.08689", "submitter": "Thodoris Lykouris", "authors": "Thodoris Lykouris, Max Simchowitz, Aleksandrs Slivkins, Wen Sun", "title": "Corruption robust exploration in episodic reinforcement learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.DS stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We initiate the study of multi-stage episodic reinforcement learning under\nadversarial corruptions in both the rewards and the transition probabilities of\nthe underlying system extending recent results for the special case of\nstochastic bandits. We provide a framework which modifies the aggressive\nexploration enjoyed by existing reinforcement learning approaches based on\n\"optimism in the face of uncertainty\", by complementing them with principles\nfrom \"action elimination\". Importantly, our framework circumvents the major\nchallenges posed by naively applying action elimination in the RL setting, as\nformalized by a lower bound we demonstrate. Our framework yields efficient\nalgorithms which (a) attain near-optimal regret in the absence of corruptions\nand (b) adapt to unknown levels corruption, enjoying regret guarantees which\ndegrade gracefully in the total corruption encountered. To showcase the\ngenerality of our approach, we derive results for both tabular settings (where\nstates and actions are finite) as well as linear-function-approximation\nsettings (where the dynamics and rewards admit a linear underlying\nrepresentation). Notably, our work provides the first sublinear regret\nguarantee which accommodates any deviation from purely i.i.d. transitions in\nthe bandit-feedback model for episodic reinforcement learning.\n", "versions": [{"version": "v1", "created": "Wed, 20 Nov 2019 03:49:13 GMT"}, {"version": "v2", "created": "Wed, 29 Apr 2020 21:20:40 GMT"}], "update_date": "2020-05-01", "authors_parsed": [["Lykouris", "Thodoris", ""], ["Simchowitz", "Max", ""], ["Slivkins", "Aleksandrs", ""], ["Sun", "Wen", ""]]}, {"id": "1911.08696", "submitter": "Jingfeng Zhang", "authors": "Jingfeng Zhang, Bo Han, Gang Niu, Tongliang Liu, Masashi Sugiyama", "title": "Where is the Bottleneck of Adversarial Learning with Unlabeled Data?", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep neural networks (DNNs) are incredibly brittle due to adversarial\nexamples. To robustify DNNs, adversarial training was proposed, which requires\nlarge-scale but well-labeled data. However, it is quite expensive to annotate\nlarge-scale data well. To compensate for this shortage, several seminal works\nare utilizing large-scale unlabeled data. In this paper, we observe that\nseminal works do not perform well, since the quality of pseudo labels on\nunlabeled data is quite poor, especially when the amount of unlabeled data is\nsignificantly larger than that of labeled data. We believe that the quality of\npseudo labels is the bottleneck of adversarial learning with unlabeled data. To\ntackle this bottleneck, we leverage deep co-training, which trains two deep\nnetworks and encourages two networks diverged by exploiting peer's adversarial\nexamples. Based on deep co-training, we propose robust co-training (RCT) for\nadversarial learning with unlabeled data. We conduct comprehensive experiments\non CIFAR-10 and SVHN datasets. Empirical results demonstrate that our RCT can\nsignificantly outperform baselines (e.g., robust self-training (RST)) in both\nstandard test accuracy and robust test accuracy w.r.t. different datasets,\ndifferent network structures, and different types of adversarial training.\n", "versions": [{"version": "v1", "created": "Wed, 20 Nov 2019 04:13:46 GMT"}], "update_date": "2019-11-21", "authors_parsed": [["Zhang", "Jingfeng", ""], ["Han", "Bo", ""], ["Niu", "Gang", ""], ["Liu", "Tongliang", ""], ["Sugiyama", "Masashi", ""]]}, {"id": "1911.08701", "submitter": "Tom Blau", "authors": "Tom Blau, Lionel Ott, Fabio Ramos", "title": "Bayesian Curiosity for Efficient Exploration in Reinforcement Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Balancing exploration and exploitation is a fundamental part of reinforcement\nlearning, yet most state-of-the-art algorithms use a naive exploration protocol\nlike $\\epsilon$-greedy. This contributes to the problem of high sample\ncomplexity, as the algorithm wastes effort by repeatedly visiting parts of the\nstate space that have already been explored. We introduce a novel method based\non Bayesian linear regression and latent space embedding to generate an\nintrinsic reward signal that encourages the learning agent to seek out\nunexplored parts of the state space. This method is computationally efficient,\nsimple to implement, and can extend any state-of-the-art reinforcement learning\nalgorithm. We evaluate the method on a range of algorithms and challenging\ncontrol tasks, on both simulated and physical robots, demonstrating how the\nproposed method can significantly improve sample complexity.\n", "versions": [{"version": "v1", "created": "Wed, 20 Nov 2019 04:30:20 GMT"}], "update_date": "2019-11-21", "authors_parsed": [["Blau", "Tom", ""], ["Ott", "Lionel", ""], ["Ramos", "Fabio", ""]]}, {"id": "1911.08703", "submitter": "Kaito Shimamura", "authors": "Kaito Shimamura, Shuichi Kawano", "title": "Bayesian sparse convex clustering via global-local shrinkage priors", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG stat.ME", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Sparse convex clustering is to cluster observations and conduct variable\nselection simultaneously in the framework of convex clustering. Although a\nweighted $L_1$ norm is usually employed for the regularization term in sparse\nconvex clustering, its use increases the dependence on the data and reduces the\nestimation accuracy if the sample size is not sufficient. To tackle these\nproblems, this paper proposes a Bayesian sparse convex clustering method based\non the ideas of Bayesian lasso and global-local shrinkage priors. We introduce\nGibbs sampling algorithms for our method using scale mixtures of normal\ndistributions. The effectiveness of the proposed methods is shown in simulation\nstudies and a real data analysis.\n", "versions": [{"version": "v1", "created": "Wed, 20 Nov 2019 04:41:05 GMT"}, {"version": "v2", "created": "Tue, 26 May 2020 17:25:18 GMT"}], "update_date": "2020-05-27", "authors_parsed": [["Shimamura", "Kaito", ""], ["Kawano", "Shuichi", ""]]}, {"id": "1911.08705", "submitter": "Xin He", "authors": "Xin He, Shihao Wang, Shaohuai Shi, Zhenheng Tang, Yuxin Wang, Zhihao\n  Zhao, Jing Dai, Ronghao Ni, Xiaofeng Zhang, Xiaoming Liu, Zhili Wu, Wu Yu,\n  Xiaowen Chu", "title": "Computer-Aided Clinical Skin Disease Diagnosis Using CNN and Object\n  Detection Models", "comments": "KDDBHI Workshop 2019, IEEE BigData Conference", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.IV cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Skin disease is one of the most common types of human diseases, which may\nhappen to everyone regardless of age, gender or race. Due to the high visual\ndiversity, human diagnosis highly relies on personal experience; and there is a\nserious shortage of experienced dermatologists in many countries. To alleviate\nthis problem, computer-aided diagnosis with state-of-the-art (SOTA) machine\nlearning techniques would be a promising solution. In this paper, we aim at\nunderstanding the performance of convolutional neural network (CNN) based\napproaches. We first build two versions of skin disease datasets from Internet\nimages: (a) Skin-10, which contains 10 common classes of skin disease with a\ntotal of 10,218 images; (b) Skin-100, which is a larger dataset that consists\nof 19,807 images of 100 skin disease classes. Based on these datasets, we\nbenchmark several SOTA CNN models and show that the accuracy of skin-100 is\nmuch lower than the accuracy of skin-10. We then implement an ensemble method\nbased on several CNN models and achieve the best accuracy of 79.01\\% for\nSkin-10 and 53.54\\% for Skin-100. We also present an object detection based\napproach by introducing bounding boxes into the Skin-10 dataset. Our results\nshow that object detection can help improve the accuracy of some skin disease\nclasses.\n", "versions": [{"version": "v1", "created": "Wed, 20 Nov 2019 04:53:18 GMT"}], "update_date": "2019-11-21", "authors_parsed": [["He", "Xin", ""], ["Wang", "Shihao", ""], ["Shi", "Shaohuai", ""], ["Tang", "Zhenheng", ""], ["Wang", "Yuxin", ""], ["Zhao", "Zhihao", ""], ["Dai", "Jing", ""], ["Ni", "Ronghao", ""], ["Zhang", "Xiaofeng", ""], ["Liu", "Xiaoming", ""], ["Wu", "Zhili", ""], ["Yu", "Wu", ""], ["Chu", "Xiaowen", ""]]}, {"id": "1911.08708", "submitter": "Uttaran Bhattacharya", "authors": "Uttaran Bhattacharya, Christian Roncal, Trisha Mittal, Rohan Chandra,\n  Kyra Kapsaskis, Kurt Gray, Aniket Bera, Dinesh Manocha", "title": "Take an Emotion Walk: Perceiving Emotions from Gaits Using Hierarchical\n  Attention Pooling and Affective Mapping", "comments": "In proceedings of the 16th European Conference on Computer Vision,\n  2020. Total pages 18. Total figures 5. Total tables 3", "journal-ref": "European Conference on Computer Vision, 2020, Lecture Notes in\n  Computer Science, Vol. 12355, PP 145-163", "doi": "10.1007/978-3-030-58607-2_9", "report-no": null, "categories": "cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present an autoencoder-based semi-supervised approach to classify\nperceived human emotions from walking styles obtained from videos or\nmotion-captured data and represented as sequences of 3D poses. Given the motion\non each joint in the pose at each time step extracted from 3D pose sequences,\nwe hierarchically pool these joint motions in a bottom-up manner in the\nencoder, following the kinematic chains in the human body. We also constrain\nthe latent embeddings of the encoder to contain the space of\npsychologically-motivated affective features underlying the gaits. We train the\ndecoder to reconstruct the motions per joint per time step in a top-down manner\nfrom the latent embeddings. For the annotated data, we also train a classifier\nto map the latent embeddings to emotion labels. Our semi-supervised approach\nachieves a mean average precision of 0.84 on the Emotion-Gait benchmark\ndataset, which contains both labeled and unlabeled gaits collected from\nmultiple sources. We outperform current state-of-art algorithms for both\nemotion recognition and action recognition from 3D gaits by 7%--23% on the\nabsolute. More importantly, we improve the average precision by 10%--50% on the\nabsolute on classes that each makes up less than 25% of the labeled part of the\nEmotion-Gait benchmark dataset.\n", "versions": [{"version": "v1", "created": "Wed, 20 Nov 2019 05:04:16 GMT"}, {"version": "v2", "created": "Sun, 2 Aug 2020 00:24:06 GMT"}, {"version": "v3", "created": "Sun, 14 Feb 2021 02:19:49 GMT"}], "update_date": "2021-02-16", "authors_parsed": [["Bhattacharya", "Uttaran", ""], ["Roncal", "Christian", ""], ["Mittal", "Trisha", ""], ["Chandra", "Rohan", ""], ["Kapsaskis", "Kyra", ""], ["Gray", "Kurt", ""], ["Bera", "Aniket", ""], ["Manocha", "Dinesh", ""]]}, {"id": "1911.08709", "submitter": "Wenlin Wang", "authors": "Wenlin Wang, Hongteng Xu, Zhe Gan, Bai Li, Guoyin Wang, Liqun Chen,\n  Qian Yang, Wenqi Wang and Lawrence Carin", "title": "Graph-Driven Generative Models for Heterogeneous Multi-Task Learning", "comments": "Accepted by AAAI-2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a novel graph-driven generative model, that unifies multiple\nheterogeneous learning tasks into the same framework. The proposed model is\nbased on the fact that heterogeneous learning tasks, which correspond to\ndifferent generative processes, often rely on data with a shared graph\nstructure. Accordingly, our model combines a graph convolutional network (GCN)\nwith multiple variational autoencoders, thus embedding the nodes of the graph\ni.e., samples for the tasks) in a uniform manner while specializing their\norganization and usage to different tasks. With a focus on healthcare\napplications (tasks), including clinical topic modeling, procedure\nrecommendation and admission-type prediction, we demonstrate that our method\nsuccessfully leverages information across different tasks, boosting performance\nin all tasks and outperforming existing state-of-the-art approaches.\n", "versions": [{"version": "v1", "created": "Wed, 20 Nov 2019 05:14:35 GMT"}], "update_date": "2019-11-21", "authors_parsed": [["Wang", "Wenlin", ""], ["Xu", "Hongteng", ""], ["Gan", "Zhe", ""], ["Li", "Bai", ""], ["Wang", "Guoyin", ""], ["Chen", "Liqun", ""], ["Yang", "Qian", ""], ["Wang", "Wenqi", ""], ["Carin", "Lawrence", ""]]}, {"id": "1911.08716", "submitter": "Yuan Liu", "authors": "Amirata Ghorbani, Vivek Natarajan, David Coz, Yuan Liu", "title": "DermGAN: Synthetic Generation of Clinical Skin Images with Pathology", "comments": "In full proceedings of NeurIPS ML4H workshop, 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Despite the recent success in applying supervised deep learning to medical\nimaging tasks, the problem of obtaining large and diverse expert-annotated\ndatasets required for the development of high performant models remains\nparticularly challenging. In this work, we explore the possibility of using\nGenerative Adverserial Networks (GAN) to synthesize clinical images with skin\ncondition. We propose DermGAN, an adaptation of the popular Pix2Pix\narchitecture, to create synthetic images for a pre-specified skin condition\nwhile being able to vary its size, location and the underlying skin color. We\ndemonstrate that the generated images are of high fidelity using objective GAN\nevaluation metrics. In a Human Turing test, we note that the synthetic images\nare not only visually similar to real images, but also embody the respective\nskin condition in dermatologists' eyes. Finally, when using the synthetic\nimages as a data augmentation technique for training a skin condition\nclassifier, we observe that the model performs comparably to the baseline model\noverall while improving on rare but malignant conditions.\n", "versions": [{"version": "v1", "created": "Wed, 20 Nov 2019 05:48:16 GMT"}], "update_date": "2019-11-21", "authors_parsed": [["Ghorbani", "Amirata", ""], ["Natarajan", "Vivek", ""], ["Coz", "David", ""], ["Liu", "Yuan", ""]]}, {"id": "1911.08717", "submitter": "Junliang Guo", "authors": "Junliang Guo, Xu Tan, Linli Xu, Tao Qin, Enhong Chen, Tie-Yan Liu", "title": "Fine-Tuning by Curriculum Learning for Non-Autoregressive Neural Machine\n  Translation", "comments": "AAAI 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Non-autoregressive translation (NAT) models remove the dependence on previous\ntarget tokens and generate all target tokens in parallel, resulting in\nsignificant inference speedup but at the cost of inferior translation accuracy\ncompared to autoregressive translation (AT) models. Considering that AT models\nhave higher accuracy and are easier to train than NAT models, and both of them\nshare the same model configurations, a natural idea to improve the accuracy of\nNAT models is to transfer a well-trained AT model to an NAT model through\nfine-tuning. However, since AT and NAT models differ greatly in training\nstrategy, straightforward fine-tuning does not work well. In this work, we\nintroduce curriculum learning into fine-tuning for NAT. Specifically, we design\na curriculum in the fine-tuning process to progressively switch the training\nfrom autoregressive generation to non-autoregressive generation. Experiments on\nfour benchmark translation datasets show that the proposed method achieves good\nimprovement (more than $1$ BLEU score) over previous NAT baselines in terms of\ntranslation accuracy, and greatly speed up (more than $10$ times) the inference\nprocess over AT baselines.\n", "versions": [{"version": "v1", "created": "Wed, 20 Nov 2019 05:48:31 GMT"}, {"version": "v2", "created": "Thu, 21 Nov 2019 09:43:45 GMT"}], "update_date": "2019-11-25", "authors_parsed": [["Guo", "Junliang", ""], ["Tan", "Xu", ""], ["Xu", "Linli", ""], ["Qin", "Tao", ""], ["Chen", "Enhong", ""], ["Liu", "Tie-Yan", ""]]}, {"id": "1911.08723", "submitter": "Lirong He", "authors": "Lirong He, Ziyi Guo, Kaizhu Huang, Zenglin Xu", "title": "Deep Minimax Probability Machine", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep neural networks enjoy a powerful representation and have proven\neffective in a number of applications. However, recent advances show that deep\nneural networks are vulnerable to adversarial attacks incurred by the so-called\nadversarial examples. Although the adversarial example is only slightly\ndifferent from the input sample, the neural network classifies it as the wrong\nclass. In order to alleviate this problem, we propose the Deep Minimax\nProbability Machine (DeepMPM), which applies MPM to deep neural networks in an\nend-to-end fashion. In a worst-case scenario, MPM tries to minimize an upper\nbound of misclassification probabilities, considering the global information\n(i.e., mean and covariance information of each class). DeepMPM can be more\nrobust since it learns the worst-case bound on the probability of\nmisclassification of future data. Experiments on two real-world datasets can\nachieve comparable classification performance with CNN, while can be more\nrobust on adversarial attacks.\n", "versions": [{"version": "v1", "created": "Wed, 20 Nov 2019 06:11:48 GMT"}], "update_date": "2019-11-21", "authors_parsed": [["He", "Lirong", ""], ["Guo", "Ziyi", ""], ["Huang", "Kaizhu", ""], ["Xu", "Zenglin", ""]]}, {"id": "1911.08727", "submitter": "Shaohuai Shi", "authors": "Shaohuai Shi, Zhenheng Tang, Qiang Wang, Kaiyong Zhao, Xiaowen Chu", "title": "Layer-wise Adaptive Gradient Sparsification for Distributed Deep\n  Learning with Convergence Guarantees", "comments": "8 pages. To appear at ECAI 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.DC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  To reduce the long training time of large deep neural network (DNN) models,\ndistributed synchronous stochastic gradient descent (S-SGD) is commonly used on\na cluster of workers. However, the speedup brought by multiple workers is\nlimited by the communication overhead. Two approaches, namely pipelining and\ngradient sparsification, have been separately proposed to alleviate the impact\nof communication overheads. Yet, the gradient sparsification methods can only\ninitiate the communication after the backpropagation, and hence miss the\npipelining opportunity. In this paper, we propose a new distributed\noptimization method named LAGS-SGD, which combines S-SGD with a novel\nlayer-wise adaptive gradient sparsification (LAGS) scheme. In LAGS-SGD, every\nworker selects a small set of \"significant\" gradients from each layer\nindependently whose size can be adaptive to the communication-to-computation\nratio of that layer. The layer-wise nature of LAGS-SGD opens the opportunity of\noverlapping communications with computations, while the adaptive nature of\nLAGS-SGD makes it flexible to control the communication time. We prove that\nLAGS-SGD has convergence guarantees and it has the same order of convergence\nrate as vanilla S-SGD under a weak analytical assumption. Extensive experiments\nare conducted to verify the analytical assumption and the convergence\nperformance of LAGS-SGD. Experimental results on a 16-GPU cluster show that\nLAGS-SGD outperforms the original S-SGD and existing sparsified S-SGD without\nlosing obvious model accuracy.\n", "versions": [{"version": "v1", "created": "Wed, 20 Nov 2019 06:24:50 GMT"}, {"version": "v2", "created": "Thu, 21 Nov 2019 06:46:41 GMT"}, {"version": "v3", "created": "Fri, 28 Feb 2020 14:22:12 GMT"}, {"version": "v4", "created": "Mon, 2 Mar 2020 01:54:25 GMT"}], "update_date": "2020-03-03", "authors_parsed": [["Shi", "Shaohuai", ""], ["Tang", "Zhenheng", ""], ["Wang", "Qiang", ""], ["Zhao", "Kaiyong", ""], ["Chu", "Xiaowen", ""]]}, {"id": "1911.08729", "submitter": "Stefan Lessmann", "authors": "Robin M. Gubela, Stefan Lessmann, Szymon Jaroszewicz", "title": "Response Transformation and Profit Decomposition for Revenue Uplift\n  Modeling", "comments": "53 pages including online appendix", "journal-ref": "European Journal of Operational Research 2019", "doi": "10.1016/j.ejor.2019.11.030", "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Uplift models support decision-making in marketing campaign planning.\nEstimating the causal effect of a marketing treatment, an uplift model\nfacilitates targeting communication to responsive customers and efficient\nallocation of marketing budgets. Research into uplift models focuses on\nconversion models to maximize incremental sales. The paper introduces uplift\nmodeling strategies for maximizing incremental revenues. If customers differ in\ntheir spending behavior, revenue maximization is a more plausible business\nobjective compared to maximizing conversions. The proposed methodology entails\na transformation of the prediction target, customer-level revenues, that\nfacilitates implementing a causal uplift model using standard machine learning\nalgorithms. The distribution of campaign revenues is typically zero-inflated\nbecause of many non-buyers. Remedies to this modeling challenge are\nincorporated in the proposed revenue uplift strategies in the form of two-stage\nmodels. Empirical experiments using real-world e-commerce data confirm the\nmerits of the proposed revenue uplift strategy over relevant alternatives\nincluding uplift models for conver-sion and recently developed causal machine\nlearning algorithms. To quantify the degree to which improved targeting\ndecisions raise return on marketing, the paper develops a decomposition of\ncampaign profit. Applying the decomposition to a digital coupon targeting\ncampaign, the paper provides evidence that revenue uplift modeling, as well as\ncausal machine learning, can improve cam-paign profit substantially.\n", "versions": [{"version": "v1", "created": "Wed, 20 Nov 2019 06:36:07 GMT"}], "update_date": "2019-11-21", "authors_parsed": [["Gubela", "Robin M.", ""], ["Lessmann", "Stefan", ""], ["Jaroszewicz", "Szymon", ""]]}, {"id": "1911.08731", "submitter": "Shiori Sagawa", "authors": "Shiori Sagawa, Pang Wei Koh, Tatsunori B. Hashimoto, Percy Liang", "title": "Distributionally Robust Neural Networks for Group Shifts: On the\n  Importance of Regularization for Worst-Case Generalization", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Overparameterized neural networks can be highly accurate on average on an\ni.i.d. test set yet consistently fail on atypical groups of the data (e.g., by\nlearning spurious correlations that hold on average but not in such groups).\nDistributionally robust optimization (DRO) allows us to learn models that\ninstead minimize the worst-case training loss over a set of pre-defined groups.\nHowever, we find that naively applying group DRO to overparameterized neural\nnetworks fails: these models can perfectly fit the training data, and any model\nwith vanishing average training loss also already has vanishing worst-case\ntraining loss. Instead, the poor worst-case performance arises from poor\ngeneralization on some groups. By coupling group DRO models with increased\nregularization---a stronger-than-typical L2 penalty or early stopping---we\nachieve substantially higher worst-group accuracies, with 10-40 percentage\npoint improvements on a natural language inference task and two image tasks,\nwhile maintaining high average accuracies. Our results suggest that\nregularization is important for worst-group generalization in the\noverparameterized regime, even if it is not needed for average generalization.\nFinally, we introduce a stochastic optimization algorithm, with convergence\nguarantees, to efficiently train group DRO models.\n", "versions": [{"version": "v1", "created": "Wed, 20 Nov 2019 06:43:41 GMT"}, {"version": "v2", "created": "Thu, 2 Apr 2020 05:40:29 GMT"}], "update_date": "2020-04-03", "authors_parsed": [["Sagawa", "Shiori", ""], ["Koh", "Pang Wei", ""], ["Hashimoto", "Tatsunori B.", ""], ["Liang", "Percy", ""]]}, {"id": "1911.08736", "submitter": "Hamid Tizhoosh", "authors": "Shivam Kalra, H.R. Tizhoosh, Sultaan Shah, Charles Choi, Savvas\n  Damaskinos, Amir Safarpoor, Sobhan Shafiei, Morteza Babaie, Phedias\n  Diamandis, Clinton JV Campbell, and Liron Pantanowitz", "title": "Pan-Cancer Diagnostic Consensus Through Searching Archival\n  Histopathology Images Using Artificial Intelligence", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.IV cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The emergence of digital pathology has opened new horizons for histopathology\nand cytology. Artificial-intelligence algorithms are able to operate on\ndigitized slides to assist pathologists with diagnostic tasks. Whereas machine\nlearning involving classification and segmentation methods have obvious\nbenefits for image analysis in pathology, image search represents a fundamental\nshift in computational pathology. Matching the pathology of new patients with\nalready diagnosed and curated cases offers pathologist a novel approach to\nimprove diagnostic accuracy through visual inspection of similar cases and\ncomputational majority vote for consensus building. In this study, we report\nthe results from searching the largest public repository (The Cancer Genome\nAtlas [TCGA] program by National Cancer Institute, USA) of whole slide images\nfrom almost 11,000 patients depicting different types of malignancies. For the\nfirst time, we successfully indexed and searched almost 30,000 high-resolution\ndigitized slides constituting 16 terabytes of data comprised of 20 million\n1000x1000 pixels image patches. The TCGA image database covers 25 anatomic\nsites and contains 32 cancer subtypes. High-performance storage and GPU power\nwere employed for experimentation. The results were assessed with conservative\n\"majority voting\" to build consensus for subtype diagnosis through vertical\nsearch and demonstrated high accuracy values for both frozen sections slides\n(e.g., bladder urothelial carcinoma 93%, kidney renal clear cell carcinoma 97%,\nand ovarian serous cystadenocarcinoma 99%) and permanent histopathology slides\n(e.g., prostate adenocarcinoma 98%, skin cutaneous melanoma 99%, and thymoma\n100%). The key finding of this validation study was that computational\nconsensus appears to be possible for rendering diagnoses if a sufficiently\nlarge number of searchable cases are available for each cancer subtype.\n", "versions": [{"version": "v1", "created": "Wed, 20 Nov 2019 06:53:07 GMT"}], "update_date": "2019-11-21", "authors_parsed": [["Kalra", "Shivam", ""], ["Tizhoosh", "H. R.", ""], ["Shah", "Sultaan", ""], ["Choi", "Charles", ""], ["Damaskinos", "Savvas", ""], ["Safarpoor", "Amir", ""], ["Shafiei", "Sobhan", ""], ["Babaie", "Morteza", ""], ["Diamandis", "Phedias", ""], ["Campbell", "Clinton JV", ""], ["Pantanowitz", "Liron", ""]]}, {"id": "1911.08739", "submitter": "Nikhil Thakurdesai", "authors": "Nikhil Thakurdesai, Anupam Tripathi, Dheeraj Butani, Smita Sankhe", "title": "Vision: A Deep Learning Approach to provide walking assistance to the\n  visually impaired", "comments": "10 pages, 10 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Blind people face a lot of problems in their daily routines. They have to\nstruggle a lot just to do their day-to-day chores. In this paper, we have\nproposed a system with the objective to help the visually impaired by providing\naudio aid guiding them to avoid obstacles, which will assist them to move in\ntheir surroundings. Object Detection using YOLO will help them detect the\nnearby objects and Depth Estimation using monocular vision will tell the\napproximate distance of the detected objects from the user. Despite a higher\naccuracy, stereo vision has many hardware constraints, which makes monocular\nvision the preferred choice for this application.\n", "versions": [{"version": "v1", "created": "Wed, 20 Nov 2019 07:02:00 GMT"}], "update_date": "2019-11-21", "authors_parsed": [["Thakurdesai", "Nikhil", ""], ["Tripathi", "Anupam", ""], ["Butani", "Dheeraj", ""], ["Sankhe", "Smita", ""]]}, {"id": "1911.08744", "submitter": "Amir Farzad", "authors": "Amir Farzad and T. Aaron Gulliver", "title": "Log Message Anomaly Detection and Classification Using Auto-B/LSTM and\n  Auto-GRU", "comments": "18 pages, 5 figures, 3 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Log messages are now widely used in software systems. They are important for\nclassification as millions of logs are generated each day. Most logs are\nunstructured which makes classification a challenge. In this paper, Deep\nLearning (DL) methods called Auto-LSTM, Auto-BLSTM and Auto-GRU are developed\nfor anomaly detection and log classification. These models are used to convert\nunstructured log data to extracted features which is suitable for\nclassification algorithms. They are evaluated using four data sets, namely BGL,\nOpenstack, Thunderbird and IMDB. The first three are popular log data sets\nwhile the fourth is a movie review data set which is used for sentiment\nclassification. The results obtained show that Auto-LSTM, Auto-BLSTM and\nAuto-GRU perform better than other well-known algorithms.\n", "versions": [{"version": "v1", "created": "Wed, 20 Nov 2019 07:18:38 GMT"}, {"version": "v2", "created": "Wed, 7 Apr 2021 02:01:36 GMT"}], "update_date": "2021-04-08", "authors_parsed": [["Farzad", "Amir", ""], ["Gulliver", "T. Aaron", ""]]}, {"id": "1911.08747", "submitter": "Zhijian Ou", "authors": "Keyu An, Hongyu Xiang, Zhijian Ou", "title": "CAT: CRF-based ASR Toolkit", "comments": "Code released at: https://github.com/thu-spmi/cat", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.SD eess.AS stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we present a new open source toolkit for automatic speech\nrecognition (ASR), named CAT (CRF-based ASR Toolkit). A key feature of CAT is\ndiscriminative training in the framework of conditional random field (CRF),\nparticularly with connectionist temporal classification (CTC) inspired state\ntopology. CAT contains a full-fledged implementation of CTC-CRF and provides a\ncomplete workflow for CRF-based end-to-end speech recognition. Evaluation\nresults on Chinese and English benchmarks such as Switchboard and Aishell show\nthat CAT obtains the state-of-the-art results among existing end-to-end models\nwith less parameters, and is competitive compared with the hybrid DNN-HMM\nmodels. Towards flexibility, we show that i-vector based speaker-adapted\nrecognition and latency control mechanism can be explored easily and\neffectively in CAT. We hope CAT, especially the CRF-based framework and\nsoftware, will be of broad interest to the community, and can be further\nexplored and improved.\n", "versions": [{"version": "v1", "created": "Wed, 20 Nov 2019 07:33:21 GMT"}], "update_date": "2019-11-21", "authors_parsed": [["An", "Keyu", ""], ["Xiang", "Hongyu", ""], ["Ou", "Zhijian", ""]]}, {"id": "1911.08748", "submitter": "Hamid Tizhoosh", "authors": "S. Kalra, C. Choi, S. Shah, L. Pantanowitz, H.R. Tizhoosh", "title": "Yottixel -- An Image Search Engine for Large Archives of Histopathology\n  Whole Slide Images", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.IV cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  With the emergence of digital pathology, searching for similar images in\nlarge archives has gained considerable attention. Image retrieval can provide\npathologists with unprecedented access to the evidence embodied in already\ndiagnosed and treated cases from the past. This paper proposes a search engine\nspecialized for digital pathology, called Yottixel, a portmanteau for \"one\nyotta pixel,\" alluding to the big-data nature of histopathology images. The\nmost impressive characteristic of Yottixel is its ability to represent whole\nslide images (WSIs) in a compact manner. Yottixel can perform millions of\nsearches in real-time with a high search accuracy and low storage profile.\nYottixel uses an intelligent indexing algorithm capable of representing WSIs\nwith a mosaic of patches by converting them into a small number of methodically\nextracted barcodes, called \"Bunch of Barcodes\" (BoB), the most prominent\nperformance enabler of Yottixel. The performance of the prototype platform is\nqualitatively tested using 300 WSIs from the University of Pittsburgh Medical\nCenter (UPMC) and 2,020 WSIs from The Cancer Genome Atlas Program (TCGA)\nprovided by the National Cancer Institute. Both datasets amount to more than\n4,000,000 patches of 1000x1000 pixels. We report three sets of experiments that\nshow that Yottixel can accurately retrieve organs and malignancies, and its\nsemantic ordering shows good agreement with the subjective evaluation of human\nobservers.\n", "versions": [{"version": "v1", "created": "Wed, 20 Nov 2019 07:34:49 GMT"}], "update_date": "2019-11-21", "authors_parsed": [["Kalra", "S.", ""], ["Choi", "C.", ""], ["Shah", "S.", ""], ["Pantanowitz", "L.", ""], ["Tizhoosh", "H. R.", ""]]}, {"id": "1911.08756", "submitter": "Jarom\\'ir Janisch", "authors": "Jarom\\'ir Janisch, Tom\\'a\\v{s} Pevn\\'y and Viliam Lis\\'y", "title": "Hierarchical Multiple-Instance Data Classification with Costly Features", "comments": "RL4RealLife @ ICML2021; code available at\n  https://github.com/jaromiru/rcwcf", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We extend the framework of Classification with Costly Features (CwCF) that\nworks with samples of fixed dimensions to trees of varying depth and breadth\n(similar to a JSON/XML file). In this setting, the sample is a tree - sets of\nsets of features. Individually for each sample, the task is to sequentially\nselect informative features that help the classification. Each feature has a\nreal-valued cost, and the objective is to maximize accuracy while minimizing\nthe total cost. The process is modeled as an MDP where the states represent the\nacquired features, and the actions select unknown features. We present a\nspecialized neural network architecture trained through deep reinforcement\nlearning that naturally fits the data and directly selects features in the\ntree. We demonstrate our method in seven datasets and compare it to two\nbaselines.\n", "versions": [{"version": "v1", "created": "Wed, 20 Nov 2019 08:15:09 GMT"}, {"version": "v2", "created": "Thu, 6 Feb 2020 13:20:38 GMT"}, {"version": "v3", "created": "Mon, 14 Sep 2020 13:21:42 GMT"}, {"version": "v4", "created": "Mon, 26 Jul 2021 13:59:18 GMT"}], "update_date": "2021-07-27", "authors_parsed": [["Janisch", "Jarom\u00edr", ""], ["Pevn\u00fd", "Tom\u00e1\u0161", ""], ["Lis\u00fd", "Viliam", ""]]}, {"id": "1911.08764", "submitter": "Matteo Testa", "authors": "Matteo Testa, Arslan Ali, Tiziano Bianchi, Enrico Magli", "title": "Learning mappings onto regularized latent spaces for biometric\n  authentication", "comments": "Accepted at IEEE MMSP 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG cs.MM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a novel architecture for generic biometric authentication based on\ndeep neural networks: RegNet. Differently from other methods, RegNet learns a\nmapping of the input biometric traits onto a target distribution in a\nwell-behaved space in which users can be separated by means of simple and\ntunable boundaries. More specifically, authorized and unauthorized users are\nmapped onto two different and well behaved Gaussian distributions. The novel\napproach of learning the mapping instead of the boundaries further avoids the\nproblem encountered in typical classifiers for which the learnt boundaries may\nbe complex and difficult to analyze. RegNet achieves high performance in terms\nof security metrics such as Equal Error Rate (EER), False Acceptance Rate (FAR)\nand Genuine Acceptance Rate (GAR). The experiments we conducted on publicly\navailable datasets of face and fingerprint confirm the effectiveness of the\nproposed system.\n", "versions": [{"version": "v1", "created": "Wed, 20 Nov 2019 08:40:44 GMT"}], "update_date": "2019-11-21", "authors_parsed": [["Testa", "Matteo", ""], ["Ali", "Arslan", ""], ["Bianchi", "Tiziano", ""], ["Magli", "Enrico", ""]]}, {"id": "1911.08769", "submitter": "Md. Aminur Rab Ratul", "authors": "Syeda Noor Jaha Azim, Md. Aminur Rab Ratul", "title": "Inspect Transfer Learning Architecture with Dilated Convolution", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  There are many award-winning pre-trained Convolutional Neural Network (CNN),\nwhich have a common phenomenon of increasing depth in convolutional layers.\nHowever, I inspect on VGG network, which is one of the famous model submitted\nto ILSVRC-2014, to show that slight modification in the basic architecture can\nenhance the accuracy result of the image classification task. In this paper, We\npresent two improve architectures of pre-trained VGG-16 and VGG-19 networks\nthat apply transfer learning when trained on a different dataset. I report a\nseries of experimental result on various modification of the primary VGG\nnetworks and achieved significant out-performance on image classification task\nby: (1) freezing the first two blocks of the convolutional layers to prevent\nover-fitting and (2) applying different combination of dilation rate in the\nlast three blocks of convolutional layer to reduce image resolution for feature\nextraction. Both the proposed architecture achieves a competitive result on\nCIFAR-10 and CIFAR-100 dataset.\n", "versions": [{"version": "v1", "created": "Wed, 20 Nov 2019 08:45:56 GMT"}], "update_date": "2019-11-21", "authors_parsed": [["Azim", "Syeda Noor Jaha", ""], ["Ratul", "Md. Aminur Rab", ""]]}, {"id": "1911.08772", "submitter": "Shaohuai Shi", "authors": "Shaohuai Shi, Xiaowen Chu, Ka Chun Cheung, Simon See", "title": "Understanding Top-k Sparsification in Distributed Deep Learning", "comments": "14 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.DC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Distributed stochastic gradient descent (SGD) algorithms are widely deployed\nin training large-scale deep learning models, while the communication overhead\namong workers becomes the new system bottleneck. Recently proposed gradient\nsparsification techniques, especially Top-$k$ sparsification with error\ncompensation (TopK-SGD), can significantly reduce the communication traffic\nwithout an obvious impact on the model accuracy. Some theoretical studies have\nbeen carried out to analyze the convergence property of TopK-SGD. However,\nexisting studies do not dive into the details of Top-$k$ operator in gradient\nsparsification and use relaxed bounds (e.g., exact bound of Random-$k$) for\nanalysis; hence the derived results cannot well describe the real convergence\nperformance of TopK-SGD. To this end, we first study the gradient distributions\nof TopK-SGD during the training process through extensive experiments. We then\ntheoretically derive a tighter bound for the Top-$k$ operator. Finally, we\nexploit the property of gradient distribution to propose an approximate top-$k$\nselection algorithm, which is computing-efficient for GPUs, to improve the\nscaling efficiency of TopK-SGD by significantly reducing the computing\noverhead. Codes are available at:\n\\url{https://github.com/hclhkbu/GaussianK-SGD}.\n", "versions": [{"version": "v1", "created": "Wed, 20 Nov 2019 08:50:59 GMT"}], "update_date": "2019-11-21", "authors_parsed": [["Shi", "Shaohuai", ""], ["Chu", "Xiaowen", ""], ["Cheung", "Ka Chun", ""], ["See", "Simon", ""]]}, {"id": "1911.08776", "submitter": "Siyu Yao", "authors": "Siyu Yao, Ruijie Wang, Shen Sun, Derui Bu, Jun Liu", "title": "Joint Embedding Learning of Educational Knowledge Graphs", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  As an efficient model for knowledge organization, the knowledge graph has\nbeen widely adopted in several fields, e.g., biomedicine, sociology, and\neducation. And there is a steady trend of learning embedding representations of\nknowledge graphs to facilitate knowledge graph construction and downstream\ntasks. In general, knowledge graph embedding techniques aim to learn vectorized\nrepresentations which preserve the structural information of the graph. And\nconventional embedding learning models rely on structural relationships among\nentities and relations. However, in educational knowledge graphs, structural\nrelationships are not the focus. Instead, rich literals of the graphs are more\nvaluable. In this paper, we focus on this problem and propose a novel model for\nembedding learning of educational knowledge graphs. Our model considers both\nstructural and literal information and jointly learns embedding\nrepresentations. Three experimental graphs were constructed based on an\neducational knowledge graph which has been applied in real-world teaching. We\nconducted two experiments on the three graphs and other common benchmark\ngraphs. The experimental results proved the effectiveness of our model and its\nsuperiority over other baselines when processing educational knowledge graphs.\n", "versions": [{"version": "v1", "created": "Wed, 20 Nov 2019 09:05:11 GMT"}, {"version": "v2", "created": "Mon, 23 Dec 2019 14:52:03 GMT"}], "update_date": "2019-12-24", "authors_parsed": [["Yao", "Siyu", ""], ["Wang", "Ruijie", ""], ["Sun", "Shen", ""], ["Bu", "Derui", ""], ["Liu", "Jun", ""]]}, {"id": "1911.08780", "submitter": "Ioannis Mollas", "authors": "Ioannis Mollas, Nick Bassiliades, Ioannis Vlahavas, Grigorios\n  Tsoumakas", "title": "LionForests: Local Interpretation of Random Forests", "comments": "8 Pages, 4 Tables, 6 Figures, Submitted to NeHuAI-2020 Workshop of\n  ECAI2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Towards a future where machine learning systems will integrate into every\naspect of people's lives, researching methods to interpret such systems is\nnecessary, instead of focusing exclusively on enhancing their performance.\nEnriching the trust between these systems and people will accelerate this\nintegration process. Many medical and retail banking/finance applications use\nstate-of-the-art machine learning techniques to predict certain aspects of new\ninstances. Tree ensembles, like random forests, are widely acceptable solutions\non these tasks, while at the same time they are avoided due to their black-box\nuninterpretable nature, creating an unreasonable paradox. In this paper, we\nprovide a methodology for shedding light on the predictions of the misjudged\nfamily of tree ensemble algorithms. Using classic unsupervised learning\ntechniques and an enhanced similarity metric, to wander among transparent trees\ninside a forest following breadcrumbs, the interpretable essence of tree\nensembles arises. An interpretation provided by these systems using our\napproach, which we call \"LionForests\", can be a simple, comprehensive rule.\n", "versions": [{"version": "v1", "created": "Wed, 20 Nov 2019 09:18:25 GMT"}, {"version": "v2", "created": "Tue, 10 Mar 2020 13:12:20 GMT"}, {"version": "v3", "created": "Thu, 23 Jul 2020 13:19:52 GMT"}], "update_date": "2020-07-24", "authors_parsed": [["Mollas", "Ioannis", ""], ["Bassiliades", "Nick", ""], ["Vlahavas", "Ioannis", ""], ["Tsoumakas", "Grigorios", ""]]}, {"id": "1911.08784", "submitter": "Qun Liu", "authors": "Qun Liu, Lihua Fu, and Meng Zhang", "title": "Deep-seismic-prior-based reconstruction of seismic data using\n  convolutional neural networks", "comments": "5 pages,12 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG physics.data-an stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Reconstruction of seismic data with missing traces is a long-standing issue\nin seismic data processing. In recent years, rank reduction operations are\nbeing commonly utilized to overcome this problem, which require the rank of\nseismic data to be a prior. However, the rank of field data is unknown; usually\nit requires much time to manually adjust the rank and just obtain an\napproximated rank. Methods based on deep learning require very large datasets\nfor training; however acquiring large datasets is difficult owing to physical\nor financial constraints in practice. Therefore, in this work, we developed a\nnovel method based on unsupervised learning using the intrinsic properties of a\nconvolutional neural network known as U-net, without training datasets. Only\none undersampled seismic data was needed, and the deep seismic prior of input\ndata could be exploited by the network itself, thus making the reconstruction\nconvenient. Furthermore, this method can handle both irregular and regular\nseismic data. Synthetic and field data were tested to assess the performance of\nthe proposed algorithm (DSPRecon algorithm); the advantages of using our method\nwere evaluated by comparing it with the singular spectrum analysis (SSA) method\nfor irregular data reconstruction and de-aliased Cadzow method for regular data\nreconstruction. Experimental results showed that our method provided better\nreconstruction performance than the SSA or Cadzow methods. The recovered\nsignal-to-noise ratios (SNRs) were 32.68 dB and 19.11 dB for the DSPRecon and\nSSA algorithms, respectively. Those for the DSPRecon and Cadzow methods were\n35.91 dB and 15.32 dB, respectively.\n", "versions": [{"version": "v1", "created": "Wed, 20 Nov 2019 09:30:34 GMT"}], "update_date": "2019-11-21", "authors_parsed": [["Liu", "Qun", ""], ["Fu", "Lihua", ""], ["Zhang", "Meng", ""]]}, {"id": "1911.08793", "submitter": "Neema Kachappilly Davis", "authors": "Neema Davis, Gaurav Raina, Krishna Jagannathan", "title": "A Framework for End-to-End Deep Learning-Based Anomaly Detection in\n  Transportation Networks", "comments": "Preprint submitted to Elsevier TRIP. arXiv admin note: text overlap\n  with arXiv:1909.06041", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG eess.SP stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We develop an end-to-end deep learning-based anomaly detection model for\ntemporal data in transportation networks. The proposed EVT-LSTM model is\nderived from the popular LSTM (Long Short-Term Memory) network and adopts an\nobjective function that is based on fundamental results from EVT (Extreme Value\nTheory). We compare the EVT-LSTM model with some established statistical,\nmachine learning, and hybrid deep learning baselines. Experiments on seven\ndiverse real-world data sets demonstrate the superior anomaly detection\nperformance of our proposed model over the other models considered in the\ncomparison study.\n", "versions": [{"version": "v1", "created": "Wed, 20 Nov 2019 09:49:58 GMT"}], "update_date": "2019-11-21", "authors_parsed": [["Davis", "Neema", ""], ["Raina", "Gaurav", ""], ["Jagannathan", "Krishna", ""]]}, {"id": "1911.08795", "submitter": "Chi Thang Duong", "authors": "Chi Thang Duong, Thanh Dat Hoang, Ha The Hien Dang, Quoc Viet Hung\n  Nguyen, Karl Aberer", "title": "On Node Features for Graph Neural Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Graph neural network (GNN) is a deep model for graph representation learning.\nOne advantage of graph neural network is its ability to incorporate node\nfeatures into the learning process. However, this prevents graph neural network\nfrom being applied into featureless graphs. In this paper, we first analyze the\neffects of node features on the performance of graph neural network. We show\nthat GNNs work well if there is a strong correlation between node features and\nnode labels. Based on these results, we propose new feature initialization\nmethods that allows to apply graph neural network to non-attributed graphs. Our\nexperimental results show that the artificial features are highly competitive\nwith real features.\n", "versions": [{"version": "v1", "created": "Wed, 20 Nov 2019 10:02:19 GMT"}], "update_date": "2019-11-21", "authors_parsed": [["Duong", "Chi Thang", ""], ["Hoang", "Thanh Dat", ""], ["Dang", "Ha The Hien", ""], ["Nguyen", "Quoc Viet Hung", ""], ["Aberer", "Karl", ""]]}, {"id": "1911.08799", "submitter": "Sanket Shah", "authors": "Sanket Shah, Arunesh Sinha, Pradeep Varakantham, Andrew Perrault,\n  Milind Tambe", "title": "Solving Online Threat Screening Games using Constrained Action Space\n  Reinforcement Learning", "comments": "Accepted to the Thirty-Fourth AAAI Conference on Artificial\n  Intelligence (AAAI-20)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.GT cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Large-scale screening for potential threats with limited resources and\ncapacity for screening is a problem of interest at airports, seaports, and\nother ports of entry. Adversaries can observe screening procedures and arrive\nat a time when there will be gaps in screening due to limited resource\ncapacities. To capture this game between ports and adversaries, this problem\nhas been previously represented as a Stackelberg game, referred to as a Threat\nScreening Game (TSG). Given the significant complexity associated with solving\nTSGs and uncertainty in arrivals of customers, existing work has assumed that\nscreenees arrive and are allocated security resources at the beginning of the\ntime window. In practice, screenees such as airport passengers arrive in bursts\ncorrelated with flight time and are not bound by fixed time windows. To address\nthis, we propose an online threat screening model in which screening strategy\nis determined adaptively as a passenger arrives while satisfying a hard bound\non acceptable risk of not screening a threat. To solve the online problem with\na hard bound on risk, we formulate it as a Reinforcement Learning (RL) problem\nwith constraints on the action space (hard bound on risk). We provide a novel\nway to efficiently enforce linear inequality constraints on the action output\nin Deep Reinforcement Learning. We show that our solution allows us to\nsignificantly reduce screenee wait time while guaranteeing a bound on risk.\n", "versions": [{"version": "v1", "created": "Wed, 20 Nov 2019 10:15:07 GMT"}], "update_date": "2019-11-21", "authors_parsed": [["Shah", "Sanket", ""], ["Sinha", "Arunesh", ""], ["Varakantham", "Pradeep", ""], ["Perrault", "Andrew", ""], ["Tambe", "Milind", ""]]}, {"id": "1911.08815", "submitter": "Yawogan Jean Eudes Gbodjo", "authors": "Yawogan Jean Eudes Gbodjo and Dino Ienco and Louise Leroux and Roberto\n  Interdonato and Raffaele Gaetano and Babacar Ndao and Stephane Dupuy", "title": "Object-based multi-temporal and multi-source land cover mapping\n  leveraging hierarchical class relationships", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  European satellite missions Sentinel-1 (S1) and Sentinel-2 (S2) provide at\nhighspatial resolution and high revisit time, respectively, radar and optical\nimagesthat support a wide range of Earth surface monitoring tasks such as\nLandUse/Land Cover mapping. A long-standing challenge in the remote\nsensingcommunity is about how to efficiently exploit multiple sources of\ninformation and leverage their complementary. In this particular case, get the\nmost out ofradar and optical satellite image time series (SITS). Here, we\npropose to dealwith land cover mapping through a deep learning framework\nespecially tailoredto leverage the multi-source complementarity provided by\nradar and opticalSITS. The proposed architecture is based on an extension of\nRecurrent NeuralNetwork (RNN) enriched via a customized attention mechanism\ncapable to fitthe specificity of SITS data. In addition, we propose a new\npretraining strategythat exploits domain expert knowledge to guide the model\nparameter initial-ization. Thorough experimental evaluations involving several\nmachine learningcompetitors, on two contrasted study sites, have demonstrated\nthe suitabilityof our new attention mechanism combined with the extend RNN\nmodel as wellas the benefit/limit to inject domain expert knowledge in the\nneural networktraining process.\n", "versions": [{"version": "v1", "created": "Wed, 20 Nov 2019 10:50:13 GMT"}], "update_date": "2019-11-21", "authors_parsed": [["Gbodjo", "Yawogan Jean Eudes", ""], ["Ienco", "Dino", ""], ["Leroux", "Louise", ""], ["Interdonato", "Roberto", ""], ["Gaetano", "Raffaele", ""], ["Ndao", "Babacar", ""], ["Dupuy", "Stephane", ""]]}, {"id": "1911.08817", "submitter": "Laurens Bliek", "authors": "Laurens Bliek, Sicco Verwer and Mathijs de Weerdt", "title": "Black-box Combinatorial Optimization using Models with Integer-valued\n  Minima", "comments": null, "journal-ref": "Annals of Mathematics and Artificial Intelligence 89, 639-653\n  (2021)", "doi": "10.1007/s10472-020-09712-4", "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  When a black-box optimization objective can only be evaluated with costly or\nnoisy measurements, most standard optimization algorithms are unsuited to find\nthe optimal solution. Specialized algorithms that deal with exactly this\nsituation make use of surrogate models. These models are usually continuous and\nsmooth, which is beneficial for continuous optimization problems, but not\nnecessarily for combinatorial problems. However, by choosing the basis\nfunctions of the surrogate model in a certain way, we show that it can be\nguaranteed that the optimal solution of the surrogate model is integer. This\napproach outperforms random search, simulated annealing and one Bayesian\noptimization algorithm on the problem of finding robust routes for a\nnoise-perturbed traveling salesman benchmark problem, with similar performance\nas another Bayesian optimization algorithm, and outperforms all compared\nalgorithms on a convex binary optimization problem with a large number of\nvariables.\n", "versions": [{"version": "v1", "created": "Wed, 20 Nov 2019 10:56:53 GMT"}], "update_date": "2021-06-11", "authors_parsed": [["Bliek", "Laurens", ""], ["Verwer", "Sicco", ""], ["de Weerdt", "Mathijs", ""]]}, {"id": "1911.08820", "submitter": "Daniel Chao Zhou", "authors": "Daniel Chao Zhou, Zhongming Jin, Tong Zhang", "title": "A Fast Sampling Gradient Tree Boosting Framework", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  As an adaptive, interpretable, robust, and accurate meta-algorithm for\narbitrary differentiable loss functions, gradient tree boosting is one of the\nmost popular machine learning techniques, though the computational\nexpensiveness severely limits its usage. Stochastic gradient boosting could be\nadopted to accelerates gradient boosting by uniformly sampling training\ninstances, but its estimator could introduce a high variance. This situation\narises motivation for us to optimize gradient tree boosting. We combine\ngradient tree boosting with importance sampling, which achieves better\nperformance by reducing the stochastic variance. Furthermore, we use a\nregularizer to improve the diagonal approximation in the Newton step of\ngradient boosting. The theoretical analysis supports that our strategies\nachieve a linear convergence rate on logistic loss. Empirical results show that\nour algorithm achieves a 2.5x--18x acceleration on two different gradient\nboosting algorithms (LogitBoost and LambdaMART) without appreciable performance\nloss.\n", "versions": [{"version": "v1", "created": "Wed, 20 Nov 2019 11:00:53 GMT"}], "update_date": "2019-11-21", "authors_parsed": [["Zhou", "Daniel Chao", ""], ["Jin", "Zhongming", ""], ["Zhang", "Tong", ""]]}, {"id": "1911.08826", "submitter": "Akshay Dharmavaram", "authors": "Akshay Dharmavaram, Matthew Riemer, Shalabh Bhatnagar", "title": "Hierarchical Average Reward Policy Gradient Algorithms", "comments": "6 pages, 3 figures, to be published in Proceedings of the\n  Thirty-Fourth AAAI Conference on Artificial Intelligence", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Option-critic learning is a general-purpose reinforcement learning (RL)\nframework that aims to address the issue of long term credit assignment by\nleveraging temporal abstractions. However, when dealing with extended\ntimescales, discounting future rewards can lead to incorrect credit\nassignments. In this work, we address this issue by extending the hierarchical\noption-critic policy gradient theorem for the average reward criterion. Our\nproposed framework aims to maximize the long-term reward obtained in the\nsteady-state of the Markov chain defined by the agent's policy. Furthermore, we\nuse an ordinary differential equation based approach for our convergence\nanalysis and prove that the parameters of the intra-option policies,\ntermination functions, and value functions, converge to their corresponding\noptimal values, with probability one. Finally, we illustrate the competitive\nadvantage of learning options, in the average reward setting, on a grid-world\nenvironment with sparse rewards.\n", "versions": [{"version": "v1", "created": "Wed, 20 Nov 2019 11:13:48 GMT"}], "update_date": "2019-11-21", "authors_parsed": [["Dharmavaram", "Akshay", ""], ["Riemer", "Matthew", ""], ["Bhatnagar", "Shalabh", ""]]}, {"id": "1911.08827", "submitter": "Ofer Givoli", "authors": "Ofer Givoli and Roi Reichart", "title": "Zero-Shot Semantic Parsing for Instructions", "comments": "ACL 2019", "journal-ref": "In Proceedings of the 57th Annual Meeting of the Association for\n  Computational Linguistics, pages 4454-4464 (2019)", "doi": "10.18653/v1/P19-1438", "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider a zero-shot semantic parsing task: parsing instructions into\ncompositional logical forms, in domains that were not seen during training. We\npresent a new dataset with 1,390 examples from 7 application domains (e.g. a\ncalendar or a file manager), each example consisting of a triplet: (a) the\napplication's initial state, (b) an instruction, to be carried out in the\ncontext of that state, and (c) the state of the application after carrying out\nthe instruction. We introduce a new training algorithm that aims to train a\nsemantic parser on examples from a set of source domains, so that it can\neffectively parse instructions from an unknown target domain. We integrate our\nalgorithm into the floating parser of Pasupat and Liang (2015), and further\naugment the parser with features and a logical form candidate filtering logic,\nto support zero-shot adaptation. Our experiments with various zero-shot\nadaptation setups demonstrate substantial performance gains over a non-adapted\nparser.\n", "versions": [{"version": "v1", "created": "Wed, 20 Nov 2019 11:14:07 GMT"}], "update_date": "2019-11-21", "authors_parsed": [["Givoli", "Ofer", ""], ["Reichart", "Roi", ""]]}, {"id": "1911.08850", "submitter": "Hiroharu Kato", "authors": "Hiroharu Kato, Tatsuya Harada", "title": "Self-supervised Learning of 3D Objects from Natural Images", "comments": "Technical report. Project page:\n  http://hiroharu-kato.com/projects_en/cifar10_3d.html", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG eess.IV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a method to learn single-view reconstruction of the 3D shape,\npose, and texture of objects from categorized natural images in a\nself-supervised manner. Since this is a severely ill-posed problem, carefully\ndesigning a training method and introducing constraints are essential. To avoid\nthe difficulty of training all elements at the same time, we propose training\ncategory-specific base shapes with fixed pose distribution and simple textures\nfirst, and subsequently training poses and textures using the obtained shapes.\nAnother difficulty is that shapes and backgrounds sometimes become excessively\ncomplicated to mistakenly reconstruct textures on object surfaces. To suppress\nit, we propose using strong regularization and constraints on object surfaces\nand background images. With these two techniques, we demonstrate that we can\nuse natural image collections such as CIFAR-10 and PASCAL objects for training,\nwhich indicates the possibility to realize 3D object reconstruction on diverse\nobject categories beyond synthetic datasets.\n", "versions": [{"version": "v1", "created": "Wed, 20 Nov 2019 12:07:12 GMT"}], "update_date": "2019-11-21", "authors_parsed": [["Kato", "Hiroharu", ""], ["Harada", "Tatsuya", ""]]}, {"id": "1911.08856", "submitter": "Redouane Lguensat", "authors": "Redouane Lguensat, Julien Le Sommer, Sammy Metref, Emmanuel Cosme,\n  Ronan Fablet", "title": "Learning Generalized Quasi-Geostrophic Models Using Deep Neural\n  Numerical Models", "comments": "Accepted for the 2nd Workshop on Machine Learning and the Physical\n  Sciences (NeurIPS 2019), Vancouver, Canada", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG physics.ao-ph stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce a new strategy designed to help physicists discover hidden laws\ngoverning dynamical systems. We propose to use machine learning automatic\ndifferentiation libraries to develop hybrid numerical models that combine\ncomponents based on prior physical knowledge with components based on neural\nnetworks. In these architectures, named Deep Neural Numerical Models (DNNMs),\nthe neural network components are used as building-blocks then deployed for\nlearning hidden variables of underlying physical laws governing dynamical\nsystems. In this paper, we illustrate an application of DNNMs to upper ocean\ndynamics, more precisely the dynamics of a sea surface tracer, the Sea Surface\nHeight (SSH). We develop an advection-based fully differentiable numerical\nscheme, where parts of the computations can be replaced with learnable\nConvNets, and make connections with the single-layer Quasi-Geostrophic (QG)\nmodel, a baseline theory in physical oceanography developed decades ago.\n", "versions": [{"version": "v1", "created": "Wed, 20 Nov 2019 12:30:58 GMT"}], "update_date": "2019-11-21", "authors_parsed": [["Lguensat", "Redouane", ""], ["Sommer", "Julien Le", ""], ["Metref", "Sammy", ""], ["Cosme", "Emmanuel", ""], ["Fablet", "Ronan", ""]]}, {"id": "1911.08870", "submitter": "Parnia Bahar", "authors": "Parnia Bahar, Tobias Bieschke, and Hermann Ney", "title": "A Comparative Study on End-to-end Speech to Text Translation", "comments": "8 pages, IEEE Automatic Speech Recognition and Understanding Workshop\n  (ASRU), Sentosa, Singapore, December 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG eess.AS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent advances in deep learning show that end-to-end speech to text\ntranslation model is a promising approach to direct the speech translation\nfield. In this work, we provide an overview of different end-to-end\narchitectures, as well as the usage of an auxiliary connectionist temporal\nclassification (CTC) loss for better convergence. We also investigate on\npre-training variants such as initializing different components of a model\nusing pre-trained models, and their impact on the final performance, which\ngives boosts up to 4% in BLEU and 5% in TER. Our experiments are performed on\n270h IWSLT TED-talks En->De, and 100h LibriSpeech Audiobooks En->Fr. We also\nshow improvements over the current end-to-end state-of-the-art systems on both\ntasks.\n", "versions": [{"version": "v1", "created": "Wed, 20 Nov 2019 13:01:56 GMT"}], "update_date": "2019-11-21", "authors_parsed": [["Bahar", "Parnia", ""], ["Bieschke", "Tobias", ""], ["Ney", "Hermann", ""]]}, {"id": "1911.08871", "submitter": "Jayasree Saha", "authors": "Jayasree Saha and Jayanta Mukherjee", "title": "CNAK : Cluster Number Assisted K-means", "comments": null, "journal-ref": "Pattern Recognition (Elsevier) 2020", "doi": "10.1016/j.patcog.2020.107625", "report-no": null, "categories": "cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Determining the number of clusters present in a dataset is an important\nproblem in cluster analysis. Conventional clustering techniques generally\nassume this parameter to be provided up front. %user supplied. %Recently,\nrobustness of any given clustering algorithm is analyzed to measure cluster\nstability/instability which in turn determines the cluster number. In this\npaper, we propose a method which analyzes cluster stability for predicting the\ncluster number. Under the same computational framework, the technique also\nfinds representatives of the clusters. The method is apt for handling big data,\nas we design the algorithm using \\emph{Monte-Carlo} simulation. Also, we\nexplore a few pertinent issues found to be of also clustering. Experiments\nreveal that the proposed method is capable of identifying a single cluster. It\nis robust in handling high dimensional dataset and performs reasonably well\nover datasets having cluster imbalance. Moreover, it can indicate cluster\nhierarchy, if present. Overall we have observed significant improvement in\nspeed and quality for predicting cluster numbers as well as the composition of\nclusters in a large dataset.\n", "versions": [{"version": "v1", "created": "Wed, 20 Nov 2019 13:03:24 GMT"}], "update_date": "2020-09-01", "authors_parsed": [["Saha", "Jayasree", ""], ["Mukherjee", "Jayanta", ""]]}, {"id": "1911.08874", "submitter": "Serkan Ak", "authors": "Serkan Ak and Stefan Bruggenwirth", "title": "Avoiding Jammers: A Reinforcement Learning Approach", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG eess.SP stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper investigates the anti-jamming performance of a cognitive radar\nunder a partially observable Markov decision process (POMDP) model. First, we\nobtain an explicit expression for uncertainty of jammer dynamics, which paves\nthe way for illuminating the performance metric of probability of being jammed\nfor the radar beyond a conventional signal-to-noise ratio ($\\mathsf{SNR}$)\nbased analysis. Considering two frequency hopping strategies developed in the\nframework of reinforcement learning (RL), this performance metric is analyzed\nwith deep Q-network (DQN) and long short term memory (LSTM) networks under\nvarious uncertainty values. Finally, the requirement of the target network in\nthe RL algorithm for both network architectures is replaced with a softmax\noperator. Simulation results show that this operator improves upon the\nperformance of the traditional target network.\n", "versions": [{"version": "v1", "created": "Wed, 20 Nov 2019 13:06:22 GMT"}, {"version": "v2", "created": "Wed, 27 Nov 2019 08:45:41 GMT"}], "update_date": "2019-11-28", "authors_parsed": [["Ak", "Serkan", ""], ["Bruggenwirth", "Stefan", ""]]}, {"id": "1911.08876", "submitter": "Parnia Bahar", "authors": "Parnia Bahar, Albert Zeyer, Ralf Schl\\\"uter and Hermann Ney", "title": "On Using SpecAugment for End-to-End Speech Translation", "comments": "8 pages, International Workshop on Spoken Language Translation\n  (IWSLT), Hong Kong, China, November 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG eess.AS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This work investigates a simple data augmentation technique, SpecAugment, for\nend-to-end speech translation. SpecAugment is a low-cost implementation method\napplied directly to the audio input features and it consists of masking blocks\nof frequency channels, and/or time steps. We apply SpecAugment on end-to-end\nspeech translation tasks and achieve up to +2.2\\% \\BLEU on LibriSpeech\nAudiobooks En->Fr and +1.2% on IWSLT TED-talks En->De by alleviating\noverfitting to some extent. We also examine the effectiveness of the method in\na variety of data scenarios and show that the method also leads to significant\nimprovements in various data conditions irrespective of the amount of training\ndata.\n", "versions": [{"version": "v1", "created": "Wed, 20 Nov 2019 13:11:41 GMT"}], "update_date": "2019-11-21", "authors_parsed": [["Bahar", "Parnia", ""], ["Zeyer", "Albert", ""], ["Schl\u00fcter", "Ralf", ""], ["Ney", "Hermann", ""]]}, {"id": "1911.08888", "submitter": "Parnia Bahar", "authors": "Parnia Bahar, Albert Zeyer, Ralf Schl\\\"uter, and Hermann Ney", "title": "On using 2D sequence-to-sequence models for speech recognition", "comments": "5 pages, IEEE International Conference on Acoustics, Speech, and\n  Signal Processing (ICASSP), Brighton, UK, May 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG eess.AS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Attention-based sequence-to-sequence models have shown promising results in\nautomatic speech recognition. Using these architectures, one-dimensional input\nand output sequences are related by an attention approach, thereby replacing\nmore explicit alignment processes, like in classical HMM-based modeling. In\ncontrast, here we apply a novel two-dimensional long short-term memory (2DLSTM)\narchitecture to directly model the input/output relation between audio/feature\nvector sequences and word sequences. The proposed model is an alternative model\nsuch that instead of using any type of attention components, we apply a 2DLSTM\nlayer to assimilate the context from both input observations and output\ntranscriptions. The experimental evaluation on the Switchboard 300h automatic\nspeech recognition task shows word error rates for the 2DLSTM model that are\ncompetitive to end-to-end attention-based model.\n", "versions": [{"version": "v1", "created": "Wed, 20 Nov 2019 13:25:06 GMT"}], "update_date": "2019-11-21", "authors_parsed": [["Bahar", "Parnia", ""], ["Zeyer", "Albert", ""], ["Schl\u00fcter", "Ralf", ""], ["Ney", "Hermann", ""]]}, {"id": "1911.08891", "submitter": "Ting-En Lin", "authors": "Ting-En Lin, Hua Xu, Hanlei Zhang", "title": "Discovering New Intents via Constrained Deep Adaptive Clustering with\n  Cluster Refinement", "comments": "Accepted by AAAI2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Identifying new user intents is an essential task in the dialogue system.\nHowever, it is hard to get satisfying clustering results since the definition\nof intents is strongly guided by prior knowledge. Existing methods incorporate\nprior knowledge by intensive feature engineering, which not only leads to\noverfitting but also makes it sensitive to the number of clusters. In this\npaper, we propose constrained deep adaptive clustering with cluster refinement\n(CDAC+), an end-to-end clustering method that can naturally incorporate\npairwise constraints as prior knowledge to guide the clustering process.\nMoreover, we refine the clusters by forcing the model to learn from the high\nconfidence assignments. After eliminating low confidence assignments, our\napproach is surprisingly insensitive to the number of clusters. Experimental\nresults on the three benchmark datasets show that our method can yield\nsignificant improvements over strong baselines.\n", "versions": [{"version": "v1", "created": "Wed, 20 Nov 2019 13:26:43 GMT"}], "update_date": "2019-11-21", "authors_parsed": [["Lin", "Ting-En", ""], ["Xu", "Hua", ""], ["Zhang", "Hanlei", ""]]}, {"id": "1911.08905", "submitter": "Ke He", "authors": "Ke He, Bo Liu, Yu Zhang, Andrew Ling and Dian Gu", "title": "FeCaffe: FPGA-enabled Caffe with OpenCL for Deep Learning Training and\n  Inference on Intel Stratix 10", "comments": "11 pages, 7 figures and 4 tables", "journal-ref": "FPGA 2020 The 2020 ACM/SIGDA International Symposium on\n  Field-Programmable Gate Arrays", "doi": "10.1145/3373087.3375389", "report-no": "314", "categories": "cs.DC cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep learning and Convolutional Neural Network (CNN) have becoming\nincreasingly more popular and important in both academic and industrial areas\nin recent years cause they are able to provide better accuracy and result in\nclassification, detection and recognition areas, compared to traditional\napproaches. Currently, there are many popular frameworks in the market for deep\nlearning development, such as Caffe, TensorFlow, Pytorch, and most of\nframeworks natively support CPU and consider GPU as the mainline accelerator by\ndefault. FPGA device, viewed as a potential heterogeneous platform, still\ncannot provide a comprehensive support for CNN development in popular\nframeworks, in particular to the training phase. In this paper, we firstly\npropose the FeCaffe, i.e. FPGA-enabled Caffe, a hierarchical software and\nhardware design methodology based on the Caffe to enable FPGA to support\nmainline deep learning development features, e.g. training and inference with\nCaffe. Furthermore, we provide some benchmarks with FeCaffe by taking some\nclassical CNN networks as examples, and further analysis of kernel execution\ntime in details accordingly. Finally, some optimization directions including\nFPGA kernel design, system pipeline, network architecture, user case\napplication and heterogeneous platform levels, have been proposed gradually to\nimprove FeCaffe performance and efficiency. The result demonstrates the\nproposed FeCaffe is capable of supporting almost full features during CNN\nnetwork training and inference respectively with high degree of design\nflexibility, expansibility and reusability for deep learning development.\nCompared to prior studies, our architecture can support more network and\ntraining settings, and current configuration can achieve 6.4x and 8.4x average\nexecution time improvement for forward and backward respectively for LeNet.\n", "versions": [{"version": "v1", "created": "Mon, 18 Nov 2019 16:52:26 GMT"}], "update_date": "2020-03-24", "authors_parsed": [["He", "Ke", ""], ["Liu", "Bo", ""], ["Zhang", "Yu", ""], ["Ling", "Andrew", ""], ["Gu", "Dian", ""]]}, {"id": "1911.08907", "submitter": "Ruobing Han", "authors": "Ruobing Han, James Demmel, Yang You", "title": "Auto-Precision Scaling for Distributed Deep Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  It has been reported that the communication cost for synchronizing gradients\ncan be a bottleneck, which limits the scalability of distributed deep learning.\nUsing low-precision gradients is a promising technique for reducing the\nbandwidth requirement. In this work, we propose Auto Precision Scaling (APS),\nan algorithm that can improve the accuracy when we communicate gradients by\nlow-precision floating-point values. APS can improve the accuracy for all\nprecisions with a trivial communication cost. Our experimental results show\nthat for many applications, APS can train state-of-the-art models by 8-bit\ngradients with no or only a tiny accuracy loss (<0.05%). Furthermore, we can\navoid any accuracy loss by designing a hybrid-precision technique. Finally, we\npropose a performance model to evaluate the proposed method. Our experimental\nresults show that APS can get a significant speedup over state-of-the-art\nmethods. To make it available to researchers and developers, we design and\nimplement CPD (Customized-Precision Deep Learning) system, which can simulate\nthe training process using an arbitrary low-precision customized floating-point\nformat. We integrate CPD into PyTorch and make it open-source.\n", "versions": [{"version": "v1", "created": "Wed, 20 Nov 2019 13:41:45 GMT"}, {"version": "v2", "created": "Fri, 11 Sep 2020 04:39:01 GMT"}, {"version": "v3", "created": "Sun, 16 May 2021 11:08:55 GMT"}], "update_date": "2021-05-18", "authors_parsed": [["Han", "Ruobing", ""], ["Demmel", "James", ""], ["You", "Yang", ""]]}, {"id": "1911.08914", "submitter": "Yunyi Li", "authors": "Yunyi Li, Li Liu, Yu Zhao, Xiefeng Cheng, Guan Gui", "title": "Nonconvex Nonsmooth Low-Rank Minimization for Generalized Image\n  Compressed Sensing via Group Sparse Representation", "comments": "This paper has been submitted to the Journal of the Franklin\n  Institute. arXiv admin note: substantial text overlap with arXiv:1903.09787", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.IV cs.LG eess.SP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Group sparse representation (GSR) based method has led to great successes in\nvarious image recovery tasks, which can be converted into a low-rank matrix\nminimization problem. As a widely used surrogate function of low-rank, the\nnuclear norm based convex surrogate usually leads to over-shrinking problem,\nsince the standard soft-thresholding operator shrinks all singular values\nequally. To improve traditional sparse representation based image compressive\nsensing (CS) performance, we propose a generalized CS framework based on GSR\nmodel, which leads to a nonconvex nonsmooth low-rank minimization problem. The\npopular L_2-norm and M-estimator are employed for standard image CS and robust\nCS problem to fit the data respectively. For the better approximation of the\nrank of group-matrix, a family of nuclear norms are employed to address the\nover-shrinking problem. Moreover, we also propose a flexible and effective\niteratively-weighting strategy to control the weighting and contribution of\neach singular value. Then we develop an iteratively reweighted nuclear norm\nalgorithm for our generalized framework via an alternating direction method of\nmultipliers framework, namely, GSR-AIR. Experimental results demonstrate that\nour proposed CS framework can achieve favorable reconstruction performance\ncompared with current state-of-the-art methods and the robust CS framework can\nsuppress the outliers effectively.\n", "versions": [{"version": "v1", "created": "Mon, 18 Nov 2019 01:50:03 GMT"}, {"version": "v2", "created": "Mon, 13 Jan 2020 06:46:06 GMT"}], "update_date": "2020-01-14", "authors_parsed": [["Li", "Yunyi", ""], ["Liu", "Li", ""], ["Zhao", "Yu", ""], ["Cheng", "Xiefeng", ""], ["Gui", "Guan", ""]]}, {"id": "1911.08927", "submitter": "Matteo Saveriano", "authors": "Pietro Falco, Abdallah Attawia, Matteo Saveriano and Dongheui Lee", "title": "On Policy Learning Robust to Irreversible Events: An Application to\n  Robotic In-Hand Manipulation", "comments": null, "journal-ref": null, "doi": "10.1109/LRA.2018.2800110", "report-no": null, "categories": "cs.RO cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this letter, we present an approach for learning in-hand manipulation\nskills with a low-cost, underactuated prosthetic hand in the presence of\nirreversible events. Our approach combines reinforcement learning based on\nvisual perception with low-level reactive control based on tactile perception,\nwhich aims to avoid slipping. The objective of the reinforcement learning level\nconsists not only in fulfilling the in-hand manipulation goal, but also in\nminimizing the intervention of the tactile reactive control. This way, the\noccurrence of object slipping during the learning procedure, which we consider\nan irreversible event, is significantly reduced. When an irreversible event\noccurs, the learning process is considered failed. We show the performance in\ntwo tasks, which consist in reorienting a cup and a bottle only using the\nfingers. The experimental results show that the proposed architecture allows\nreaching the goal in the Cartesian space and reduces significantly the\noccurrence of object slipping during the learning procedure. Moreover, without\nthe proposed synergy between reactive control and reinforcement learning it was\nnot possible to avoid irreversible events and, therefore, to learn the task.\n", "versions": [{"version": "v1", "created": "Wed, 20 Nov 2019 14:19:03 GMT"}], "update_date": "2019-11-21", "authors_parsed": [["Falco", "Pietro", ""], ["Attawia", "Abdallah", ""], ["Saveriano", "Matteo", ""], ["Lee", "Dongheui", ""]]}, {"id": "1911.08928", "submitter": "Matteo Saveriano", "authors": "Pietro Falco, Matteo Saveriano, Eka Gibran Hasany, Nicholas H. Kirk\n  and Dongheui Lee", "title": "A Human Action Descriptor Based on Motion Coordination", "comments": null, "journal-ref": null, "doi": "10.1109/LRA.2017.2652494", "report-no": null, "categories": "cs.RO cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we present a descriptor for human whole-body actions based on\nmotion coordination. We exploit the principle, well known in neuromechanics,\nthat humans move their joints in a coordinated fashion. Our coordination-based\ndescriptor (CODE) is computed by two main steps. The first step is to identify\nthe most informative joints which characterize the motion. The second step\nenriches the descriptor considering minimum and maximum joint velocities and\nthe correlations between the most informative joints. In order to compute the\ndistances between action descriptors, we propose a novel correlation-based\nsimilarity measure. The performance of CODE is tested on two public datasets,\nnamely HDM05 and Berkeley MHAD, and compared with state-of-the-art approaches,\nshowing recognition results.\n", "versions": [{"version": "v1", "created": "Wed, 20 Nov 2019 14:22:28 GMT"}], "update_date": "2019-11-21", "authors_parsed": [["Falco", "Pietro", ""], ["Saveriano", "Matteo", ""], ["Hasany", "Eka Gibran", ""], ["Kirk", "Nicholas H.", ""], ["Lee", "Dongheui", ""]]}, {"id": "1911.08934", "submitter": "Guillaume Carbajal", "authors": "Guillaume Carbajal, Romain Serizel, Emmanuel Vincent, Eric Humbert", "title": "Joint NN-Supported Multichannel Reduction of Acoustic Echo,\n  Reverberation and Noise", "comments": null, "journal-ref": "IEEE/ACM Transactions on Audio, Speech and Language Processing\n  2020", "doi": "10.1109/TASLP.2020.3008974", "report-no": null, "categories": "cs.SD cs.LG eess.AS stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the problem of simultaneous reduction of acoustic echo,\nreverberation and noise. In real scenarios, these distortion sources may occur\nsimultaneously and reducing them implies combining the corresponding\ndistortion-specific filters. As these filters interact with each other, they\nmust be jointly optimized. We propose to model the target and residual signals\nafter linear echo cancellation and dereverberation using a multichannel\nGaussian modeling framework and to jointly represent their spectra by means of\na neural network. We develop an iterative block-coordinate ascent algorithm to\nupdate all the filters. We evaluate our system on real recordings of acoustic\necho, reverberation and noise acquired with a smart speaker in various\nsituations. The proposed approach outperforms in terms of overall distortion a\ncascade of the individual approaches and a joint reduction approach which does\nnot rely on a spectral model of the target and residual signals.\n", "versions": [{"version": "v1", "created": "Wed, 20 Nov 2019 14:37:36 GMT"}, {"version": "v2", "created": "Fri, 20 Dec 2019 10:10:53 GMT"}, {"version": "v3", "created": "Tue, 19 May 2020 12:59:50 GMT"}, {"version": "v4", "created": "Mon, 27 Jul 2020 09:13:04 GMT"}], "update_date": "2020-07-28", "authors_parsed": [["Carbajal", "Guillaume", ""], ["Serizel", "Romain", ""], ["Vincent", "Emmanuel", ""], ["Humbert", "Eric", ""]]}, {"id": "1911.08935", "submitter": "Guanglin Niu", "authors": "Guanglin Niu, Yongfei Zhang, Bo Li, Peng Cui, Si Liu, Jingyang Li,\n  Xiaowei Zhang", "title": "Rule-Guided Compositional Representation Learning on Knowledge Graphs", "comments": "The full version of a paper accepted to AAAI 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Representation learning on a knowledge graph (KG) is to embed entities and\nrelations of a KG into low-dimensional continuous vector spaces. Early KG\nembedding methods only pay attention to structured information encoded in\ntriples, which would cause limited performance due to the structure sparseness\nof KGs. Some recent attempts consider paths information to expand the structure\nof KGs but lack explainability in the process of obtaining the path\nrepresentations. In this paper, we propose a novel Rule and Path-based Joint\nEmbedding (RPJE) scheme, which takes full advantage of the explainability and\naccuracy of logic rules, the generalization of KG embedding as well as the\nsupplementary semantic structure of paths. Specifically, logic rules of\ndifferent lengths (the number of relations in rule body) in the form of Horn\nclauses are first mined from the KG and elaborately encoded for representation\nlearning. Then, the rules of length 2 are applied to compose paths accurately\nwhile the rules of length 1 are explicitly employed to create semantic\nassociations among relations and constrain relation embeddings. Besides, the\nconfidence level of each rule is also considered in optimization to guarantee\nthe availability of applying the rule to representation learning. Extensive\nexperimental results illustrate that RPJE outperforms other state-of-the-art\nbaselines on KG completion task, which also demonstrate the superiority of\nutilizing logic rules as well as paths for improving the accuracy and\nexplainability of representation learning.\n", "versions": [{"version": "v1", "created": "Wed, 20 Nov 2019 14:38:58 GMT"}, {"version": "v2", "created": "Sat, 28 Dec 2019 15:33:17 GMT"}], "update_date": "2020-01-01", "authors_parsed": [["Niu", "Guanglin", ""], ["Zhang", "Yongfei", ""], ["Li", "Bo", ""], ["Cui", "Peng", ""], ["Liu", "Si", ""], ["Li", "Jingyang", ""], ["Zhang", "Xiaowei", ""]]}, {"id": "1911.08936", "submitter": "Wei Hu", "authors": "Zequn Sun, Chengming Wang, Wei Hu, Muhao Chen, Jian Dai, Wei Zhang,\n  Yuzhong Qu", "title": "Knowledge Graph Alignment Network with Gated Multi-hop Neighborhood\n  Aggregation", "comments": "Accepted by the 34th AAAI Conference on Artificial Intelligence (AAAI\n  2020)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Graph neural networks (GNNs) have emerged as a powerful paradigm for\nembedding-based entity alignment due to their capability of identifying\nisomorphic subgraphs. However, in real knowledge graphs (KGs), the counterpart\nentities usually have non-isomorphic neighborhood structures, which easily\ncauses GNNs to yield different representations for them. To tackle this\nproblem, we propose a new KG alignment network, namely AliNet, aiming at\nmitigating the non-isomorphism of neighborhood structures in an end-to-end\nmanner. As the direct neighbors of counterpart entities are usually dissimilar\ndue to the schema heterogeneity, AliNet introduces distant neighbors to expand\nthe overlap between their neighborhood structures. It employs an attention\nmechanism to highlight helpful distant neighbors and reduce noises. Then, it\ncontrols the aggregation of both direct and distant neighborhood information\nusing a gating mechanism. We further propose a relation loss to refine entity\nrepresentations. We perform thorough experiments with detailed ablation studies\nand analyses on five entity alignment datasets, demonstrating the effectiveness\nof AliNet.\n", "versions": [{"version": "v1", "created": "Wed, 20 Nov 2019 14:40:23 GMT"}], "update_date": "2019-11-21", "authors_parsed": [["Sun", "Zequn", ""], ["Wang", "Chengming", ""], ["Hu", "Wei", ""], ["Chen", "Muhao", ""], ["Dai", "Jian", ""], ["Zhang", "Wei", ""], ["Qu", "Yuzhong", ""]]}, {"id": "1911.08941", "submitter": "Claudio Gallicchio", "authors": "Claudio Gallicchio and Alessio Micheli", "title": "Fast and Deep Graph Neural Networks", "comments": "Pre-print of 'Fast and Deep Graph Neural Networks', accepted for AAAI\n  2020. This document includes the Supplementary Material", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG math.DS stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We address the efficiency issue for the construction of a deep graph neural\nnetwork (GNN). The approach exploits the idea of representing each input graph\nas a fixed point of a dynamical system (implemented through a recurrent neural\nnetwork), and leverages a deep architectural organization of the recurrent\nunits. Efficiency is gained by many aspects, including the use of small and\nvery sparse networks, where the weights of the recurrent units are left\nuntrained under the stability condition introduced in this work. This can be\nviewed as a way to study the intrinsic power of the architecture of a deep GNN,\nand also to provide insights for the set-up of more complex fully-trained\nmodels. Through experimental results, we show that even without training of the\nrecurrent connections, the architecture of small deep GNN is surprisingly able\nto achieve or improve the state-of-the-art performance on a significant set of\ntasks in the field of graphs classification.\n", "versions": [{"version": "v1", "created": "Wed, 20 Nov 2019 14:46:54 GMT"}], "update_date": "2019-11-21", "authors_parsed": [["Gallicchio", "Claudio", ""], ["Micheli", "Alessio", ""]]}, {"id": "1911.08942", "submitter": "Zikri Bayraktar", "authors": "Zikri Bayraktar", "title": "Adaptive Wind Driven Optimization Trained Artificial Neural Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper presents the application of a newly developed nature-inspired\nmetaheuristic optimization method, namely the Adaptive Wind Driven Optimization\n(AWDO), to the training of feedforward artificial neural networks (NN) and\npresents a discussion into the future research of AWDO implementation in Deep\nLearning (DL). Application example of digit classification with MNIST dataset\nreveals interesting behavior of the derivative-free AWDO method compared to\nsteepest descent method where results and future work on the implementation of\nAWDO in deep neural networks are discussed.\n", "versions": [{"version": "v1", "created": "Wed, 20 Nov 2019 14:49:33 GMT"}], "update_date": "2019-11-21", "authors_parsed": [["Bayraktar", "Zikri", ""]]}, {"id": "1911.08966", "submitter": "Neelanjan Bhowmik", "authors": "Yona Falinie A. Gaus, Neelanjan Bhowmik, Samet Akcay, Toby P. Breckon", "title": "Evaluating the Transferability and Adversarial Discrimination of\n  Convolutional Neural Networks for Threat Object Detection and Classification\n  within X-Ray Security Imagery", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG eess.IV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  X-ray imagery security screening is essential to maintaining transport\nsecurity against a varying profile of threat or prohibited items. Particular\ninterest lies in the automatic detection and classification of weapons such as\nfirearms and knives within complex and cluttered X-ray security imagery. Here,\nwe address this problem by exploring various end-to-end object detection\nConvolutional Neural Network (CNN) architectures. We evaluate several leading\nvariants spanning the Faster R-CNN, Mask R-CNN, and RetinaNet architectures to\nexplore the transferability of such models between varying X-ray scanners with\ndiffering imaging geometries, image resolutions and material colour profiles.\nWhilst the limited availability of X-ray threat imagery can pose a challenge,\nwe employ a transfer learning approach to evaluate whether such inter-scanner\ngeneralisation may exist over a multiple class detection problem. Overall, we\nachieve maximal detection performance using a Faster R-CNN architecture with a\nResNet$_{101}$ classification network, obtaining 0.88 and 0.86 of mean Average\nPrecision (mAP) for a three-class and two class item from varying X-ray imaging\nsources. Our results exhibit a remarkable degree of generalisability in terms\nof cross-scanner performance (mAP: 0.87, firearm detection: 0.94 AP). In\naddition, we examine the inherent adversarial discriminative capability of such\nnetworks using a specifically generated adversarial dataset for firearms\ndetection - with a variable low false positive, as low as 5%, this shows both\nthe challenge and promise of such threat detection within X-ray security\nimagery.\n", "versions": [{"version": "v1", "created": "Wed, 20 Nov 2019 15:29:12 GMT"}], "update_date": "2019-11-21", "authors_parsed": [["Gaus", "Yona Falinie A.", ""], ["Bhowmik", "Neelanjan", ""], ["Akcay", "Samet", ""], ["Breckon", "Toby P.", ""]]}, {"id": "1911.08967", "submitter": "Fuzhen Zhuang", "authors": "Fuzhen Zhuang, Keyu Duan, Tongjia Guo, Yongchun Zhu, Dongbo Xi,\n  Zhiyuan Qi, Qing He", "title": "Transfer Learning Toolkit: Primers and Benchmarks", "comments": "A Transfer Learning Toolkit", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The transfer learning toolkit wraps the codes of 17 transfer learning models\nand provides integrated interfaces, allowing users to use those models by\ncalling a simple function. It is easy for primary researchers to use this\ntoolkit and to choose proper models for real-world applications. The toolkit is\nwritten in Python and distributed under MIT open source license. In this paper,\nthe current state of this toolkit is described and the necessary environment\nsetting and usage are introduced.\n", "versions": [{"version": "v1", "created": "Wed, 20 Nov 2019 15:30:36 GMT"}], "update_date": "2019-11-21", "authors_parsed": [["Zhuang", "Fuzhen", ""], ["Duan", "Keyu", ""], ["Guo", "Tongjia", ""], ["Zhu", "Yongchun", ""], ["Xi", "Dongbo", ""], ["Qi", "Zhiyuan", ""], ["He", "Qing", ""]]}, {"id": "1911.09001", "submitter": "Vikas Ramachandra", "authors": "Vikas Ramachandra", "title": "Weather event severity prediction using buoy data and machine learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.AP cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we predict severity of extreme weather events (tropical\nstorms, hurricanes, etc.) using buoy data time series variables such as wind\nspeed and air temperature. The prediction/forecasting method is based on\nvarious forecasting and machine learning models. The following steps are used.\nData sources for the buoys and weather events are identified, aggregated and\nmerged. For missing data imputation, we use Kalman filters as well as splines\nfor multivariate time series. Then, statistical tests are run to ascertain\nincreasing trends in weather event severity. Next, we use machine learning to\npredict/forecast event severity using buoy variables, and report good\naccuracies for the models built.\n", "versions": [{"version": "v1", "created": "Sun, 17 Nov 2019 00:41:15 GMT"}], "update_date": "2019-11-21", "authors_parsed": [["Ramachandra", "Vikas", ""]]}, {"id": "1911.09002", "submitter": "\\c{C}a\\u{g}kan Yapar", "authors": "Ron Levie, \\c{C}a\\u{g}kan Yapar, Gitta Kutyniok, Giuseppe Caire", "title": "RadioUNet: Fast Radio Map Estimation with Convolutional Neural Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.SP cs.IT cs.LG math.IT stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we propose a highly efficient and very accurate deep learning\nmethod for estimating the propagation pathloss from a point $x$ (transmitter\nlocation) to any point $y$ on a planar domain. For applications such as\nuser-cell site association and device-to-device link scheduling, an accurate\nknowledge of the pathloss function for all pairs of transmitter-receiver\nlocations is very important. Commonly used statistical models approximate the\npathloss as a decaying function of the distance between transmitter and\nreceiver. However, in realistic propagation environments characterized by the\npresence of buildings, street canyons, and objects at different heights, such\nradial-symmetric functions yield very misleading results. In this paper we show\nthat properly designed and trained deep neural networks are able to learn how\nto estimate the pathloss function, given an urban environment, in a very\naccurate and computationally efficient manner. Our proposed method, termed\nRadioUNet, learns from a physical simulation dataset, and generates pathloss\nestimations that are very close to the simulations, but are much faster to\ncompute for real-time applications. Moreover, we propose methods for\ntransferring what was learned from simulations to real-life. Numerical results\nshow that our method significantly outperforms previously proposed methods.\n", "versions": [{"version": "v1", "created": "Sun, 17 Nov 2019 10:31:11 GMT"}, {"version": "v2", "created": "Sat, 2 May 2020 18:57:08 GMT"}, {"version": "v3", "created": "Tue, 22 Dec 2020 15:14:31 GMT"}], "update_date": "2020-12-23", "authors_parsed": [["Levie", "Ron", ""], ["Yapar", "\u00c7a\u011fkan", ""], ["Kutyniok", "Gitta", ""], ["Caire", "Giuseppe", ""]]}, {"id": "1911.09006", "submitter": "Gilles Kratzer", "authors": "Gilles Kratzer, Fraser Iain Lewis, Arianna Comin, Marta Pittavino,\n  Reinhard Furrer", "title": "Additive Bayesian Network Modelling with the R Package abn", "comments": "37 pages, 14 figures and 2 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG stat.ME", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The R package abn is designed to fit additive Bayesian models to\nobservational datasets. It contains routines to score Bayesian networks based\non Bayesian or information theoretic formulations of generalized linear models.\nIt is equipped with exact search and greedy search algorithms to select the\nbest network. It supports a possible blend of continuous, discrete and count\ndata and input of prior knowledge at a structural level. The Bayesian\nimplementation supports random effects to control for one-layer clustering. In\nthis paper, we give an overview of the methodology and illustrate the package's\nfunctionalities using a veterinary dataset about respiratory diseases in\ncommercial swine production.\n", "versions": [{"version": "v1", "created": "Wed, 20 Nov 2019 16:22:22 GMT"}], "update_date": "2019-11-21", "authors_parsed": [["Kratzer", "Gilles", ""], ["Lewis", "Fraser Iain", ""], ["Comin", "Arianna", ""], ["Pittavino", "Marta", ""], ["Furrer", "Reinhard", ""]]}, {"id": "1911.09007", "submitter": "Abdulkadir Celikkanat", "authors": "Abdulkadir \\c{C}elikkanat and Fragkiskos D. Malliaros", "title": "Exponential Family Graph Embeddings", "comments": "Accepted to the The Thirty-Fourth AAAI Conference on Artificial\n  Intelligence (AAAI-20), New York City, New York, 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Representing networks in a low dimensional latent space is a crucial task\nwith many interesting applications in graph learning problems, such as link\nprediction and node classification. A widely applied network representation\nlearning paradigm is based on the combination of random walks for sampling\ncontext nodes and the traditional \\textit{Skip-Gram} model to capture\ncenter-context node relationships. In this paper, we emphasize on exponential\nfamily distributions to capture rich interaction patterns between nodes in\nrandom walk sequences. We introduce the generic \\textit{exponential family\ngraph embedding} model, that generalizes random walk-based network\nrepresentation learning techniques to exponential family conditional\ndistributions. We study three particular instances of this model, analyzing\ntheir properties and showing their relationship to existing unsupervised\nlearning models. Our experimental evaluation on real-world datasets\ndemonstrates that the proposed techniques outperform well-known baseline\nmethods in two downstream machine learning tasks.\n", "versions": [{"version": "v1", "created": "Wed, 20 Nov 2019 16:23:09 GMT"}], "update_date": "2019-11-21", "authors_parsed": [["\u00c7elikkanat", "Abdulkadir", ""], ["Malliaros", "Fragkiskos D.", ""]]}, {"id": "1911.09008", "submitter": "Harry Clifford MSci DPhil", "authors": "Geoffroy Dubourg-Felonneau, Yasmeen Kussad, Dominic Kirkham, John W\n  Cassidy, Nirmesh Patel, Harry W Clifford", "title": "Learning Embeddings from Cancer Mutation Sets for Classification Tasks", "comments": "Sets & Partitions Workshop at NeurIPS 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG eess.IV q-bio.GN stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Analysis of somatic mutation profiles from cancer patients is essential in\nthe development of cancer research. However, the low frequency of most\nmutations and the varying rates of mutations across patients makes the data\nextremely challenging to statistically analyze as well as difficult to use in\nclassification problems, for clustering, visualization or for learning useful\ninformation. Thus, the creation of low dimensional representations of somatic\nmutation profiles that hold useful information about the DNA of cancer cells\nwill facilitate the use of such data in applications that will progress\nprecision medicine. In this paper, we talk about the open problem of learning\nfrom somatic mutations, and present Flatsomatic: a solution that utilizes\nvariational autoencoders (VAEs) to create latent representations of somatic\nprofiles. The work done in this paper shows great potential for this method,\nwith the VAE embeddings performing better than PCA for a clustering task, and\nperforming equally well to the raw high dimensional data for a classification\ntask. We believe the methods presented herein can be of great value in future\nresearch and in bringing data-driven models into precision oncology.\n", "versions": [{"version": "v1", "created": "Wed, 20 Nov 2019 16:23:30 GMT"}], "update_date": "2019-11-21", "authors_parsed": [["Dubourg-Felonneau", "Geoffroy", ""], ["Kussad", "Yasmeen", ""], ["Kirkham", "Dominic", ""], ["Cassidy", "John W", ""], ["Patel", "Nirmesh", ""], ["Clifford", "Harry W", ""]]}, {"id": "1911.09010", "submitter": "Neelanjan Bhowmik", "authors": "Ganesh Samarth C.A., Neelanjan Bhowmik, Toby P. Breckon", "title": "Experimental Exploration of Compact Convolutional Neural Network\n  Architectures for Non-temporal Real-time Fire Detection", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG eess.IV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this work we explore different Convolutional Neural Network (CNN)\narchitectures and their variants for non-temporal binary fire detection and\nlocalization in video or still imagery. We consider the performance of\nexperimentally defined, reduced complexity deep CNN architectures for this task\nand evaluate the effects of different optimization and normalization techniques\napplied to different CNN architectures (spanning the Inception, ResNet and\nEfficientNet architectural concepts). Contrary to contemporary trends in the\nfield, our work illustrates a maximum overall accuracy of 0.96 for full frame\nbinary fire detection and 0.94 for superpixel localization using an\nexperimentally defined reduced CNN architecture based on the concept of\nInceptionV4. We notably achieve a lower false positive rate of 0.06 compared to\nprior work in the field presenting an efficient, robust and real-time solution\nfor fire region detection.\n", "versions": [{"version": "v1", "created": "Wed, 20 Nov 2019 16:27:10 GMT"}], "update_date": "2019-11-21", "authors_parsed": [["A.", "Ganesh Samarth C.", ""], ["Bhowmik", "Neelanjan", ""], ["Breckon", "Toby P.", ""]]}, {"id": "1911.09011", "submitter": "Soma Yokoi", "authors": "Soma Yokoi and Issei Sato", "title": "Bayesian interpretation of SGD as Ito process", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The current interpretation of stochastic gradient descent (SGD) as a\nstochastic process lacks generality in that its numerical scheme restricts\ncontinuous-time dynamics as well as the loss function and the distribution of\ngradient noise. We introduce a simplified scheme with milder conditions that\nflexibly interprets SGD as a discrete-time approximation of an Ito process. The\nscheme also works as a common foundation of SGD and stochastic gradient\nLangevin dynamics (SGLD), providing insights into their asymptotic properties.\nWe investigate the convergence of SGD with biased gradient in terms of the\nequilibrium mode and the overestimation problem of the second moment of SGLD.\n", "versions": [{"version": "v1", "created": "Wed, 20 Nov 2019 16:29:45 GMT"}], "update_date": "2019-11-21", "authors_parsed": [["Yokoi", "Soma", ""], ["Sato", "Issei", ""]]}, {"id": "1911.09017", "submitter": "Quanshi Zhang", "authors": "Hao Zhang, Jiayi Chen, Haotian Xue, Quanshi Zhang", "title": "Towards a Unified Evaluation of Explanation Methods without Ground Truth", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper proposes a set of criteria to evaluate the objectiveness of\nexplanation methods of neural networks, which is crucial for the development of\nexplainable AI, but it also presents significant challenges. The core challenge\nis that people usually cannot obtain ground-truth explanations of the neural\nnetwork. To this end, we design four metrics to evaluate explanation results\nwithout ground-truth explanations. Our metrics can be broadly applied to nine\nbenchmark methods of interpreting neural networks, which provides new insights\nof explanation methods.\n", "versions": [{"version": "v1", "created": "Wed, 20 Nov 2019 16:44:48 GMT"}], "update_date": "2019-11-21", "authors_parsed": [["Zhang", "Hao", ""], ["Chen", "Jiayi", ""], ["Xue", "Haotian", ""], ["Zhang", "Quanshi", ""]]}, {"id": "1911.09026", "submitter": "Paolo Andreini", "authors": "Simone Bonechi, Paolo Andreini, Monica Bianchini, Franco Scarselli", "title": "Weak Supervision for Generating Pixel-Level Annotations in Scene Text\n  Segmentation", "comments": "arXiv admin note: substantial text overlap with arXiv:1904.00818", "journal-ref": null, "doi": "10.1016/j.patrec.2020.06.023", "report-no": null, "categories": "cs.CV cs.LG eess.IV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Providing pixel-level supervisions for scene text segmentation is inherently\ndifficult and costly, so that only few small datasets are available for this\ntask. To face the scarcity of training data, previous approaches based on\nConvolutional Neural Networks (CNNs) rely on the use of a synthetic dataset for\npre-training. However, synthetic data cannot reproduce the complexity and\nvariability of natural images. In this work, we propose to use a weakly\nsupervised learning approach to reduce the domain-shift between synthetic and\nreal data. Leveraging the bounding-box supervision of the COCO-Text and the MLT\ndatasets, we generate weak pixel-level supervisions of real images. In\nparticular, the COCO-Text-Segmentation (COCO_TS) and the MLT-Segmentation\n(MLT_S) datasets are created and released. These two datasets are used to train\na CNN, the Segmentation Multiscale Attention Network (SMANet), which is\nspecifically designed to face some peculiarities of the scene text segmentation\ntask. The SMANet is trained end-to-end on the proposed datasets, and the\nexperiments show that COCO_TS and MLT_S are a valid alternative to synthetic\nimages, allowing to use only a fraction of the training samples and improving\nsignificantly the performances.\n", "versions": [{"version": "v1", "created": "Tue, 19 Nov 2019 09:55:27 GMT"}], "update_date": "2020-06-30", "authors_parsed": [["Bonechi", "Simone", ""], ["Andreini", "Paolo", ""], ["Bianchini", "Monica", ""], ["Scarselli", "Franco", ""]]}, {"id": "1911.09030", "submitter": "Cong Xie", "authors": "Cong Xie, Oluwasanmi Koyejo, Indranil Gupta, Haibin Lin", "title": "Local AdaAlter: Communication-Efficient Stochastic Gradient Descent with\n  Adaptive Learning Rates", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.DC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  When scaling distributed training, the communication overhead is often the\nbottleneck. In this paper, we propose a novel SGD variant with reduced\ncommunication and adaptive learning rates. We prove the convergence of the\nproposed algorithm for smooth but non-convex problems. Empirical results show\nthat the proposed algorithm significantly reduces the communication overhead,\nwhich, in turn, reduces the training time by up to 30% for the 1B word dataset.\n", "versions": [{"version": "v1", "created": "Wed, 20 Nov 2019 16:58:40 GMT"}, {"version": "v2", "created": "Sat, 5 Dec 2020 00:26:57 GMT"}], "update_date": "2020-12-08", "authors_parsed": [["Xie", "Cong", ""], ["Koyejo", "Oluwasanmi", ""], ["Gupta", "Indranil", ""], ["Lin", "Haibin", ""]]}, {"id": "1911.09032", "submitter": "Christian Schilling", "authors": "Thomas A. Henzinger and Anna Lukina and Christian Schilling", "title": "Outside the Box: Abstraction-Based Monitoring of Neural Networks", "comments": "accepted at ECAI 2020", "journal-ref": null, "doi": "10.3233/FAIA200375", "report-no": null, "categories": "cs.LG cs.AI cs.LO stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Neural networks have demonstrated unmatched performance in a range of\nclassification tasks. Despite numerous efforts of the research community,\nnovelty detection remains one of the significant limitations of neural\nnetworks. The ability to identify previously unseen inputs as novel is crucial\nfor our understanding of the decisions made by neural networks. At runtime,\ninputs not falling into any of the categories learned during training cannot be\nclassified correctly by the neural network. Existing approaches treat the\nneural network as a black box and try to detect novel inputs based on the\nconfidence of the output predictions. However, neural networks are not trained\nto reduce their confidence for novel inputs, which limits the effectiveness of\nthese approaches. We propose a framework to monitor a neural network by\nobserving the hidden layers. We employ a common abstraction from program\nanalysis - boxes - to identify novel behaviors in the monitored layers, i.e.,\ninputs that cause behaviors outside the box. For each neuron, the boxes range\nover the values seen in training. The framework is efficient and flexible to\nachieve a desired trade-off between raising false warnings and detecting novel\ninputs. We illustrate the performance and the robustness to variability in the\nunknown classes on popular image-classification benchmarks.\n", "versions": [{"version": "v1", "created": "Wed, 20 Nov 2019 17:03:21 GMT"}, {"version": "v2", "created": "Fri, 29 Nov 2019 10:32:30 GMT"}, {"version": "v3", "created": "Wed, 19 Feb 2020 15:46:18 GMT"}], "update_date": "2020-09-22", "authors_parsed": [["Henzinger", "Thomas A.", ""], ["Lukina", "Anna", ""], ["Schilling", "Christian", ""]]}, {"id": "1911.09033", "submitter": "Eric Crawford", "authors": "Eric Crawford, Joelle Pineau", "title": "Exploiting Spatial Invariance for Scalable Unsupervised Object Tracking", "comments": "Accepted at AAAI 2020. Code: https://github.com/e2crawfo/silot.\n  Visualizations: https://sites.google.com/view/silot", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The ability to detect and track objects in the visual world is a crucial\nskill for any intelligent agent, as it is a necessary precursor to any\nobject-level reasoning process. Moreover, it is important that agents learn to\ntrack objects without supervision (i.e. without access to annotated training\nvideos) since this will allow agents to begin operating in new environments\nwith minimal human assistance. The task of learning to discover and track\nobjects in videos, which we call \\textit{unsupervised object tracking}, has\ngrown in prominence in recent years; however, most architectures that address\nit still struggle to deal with large scenes containing many objects. In the\ncurrent work, we propose an architecture that scales well to the large-scene,\nmany-object setting by employing spatially invariant computations (convolutions\nand spatial attention) and representations (a spatially local object\nspecification scheme). In a series of experiments, we demonstrate a number of\nattractive features of our architecture; most notably, that it outperforms\ncompeting methods at tracking objects in cluttered scenes with many objects,\nand that it can generalize well to videos that are larger and/or contain more\nobjects than videos encountered during training.\n", "versions": [{"version": "v1", "created": "Wed, 20 Nov 2019 17:03:51 GMT"}], "update_date": "2019-11-21", "authors_parsed": [["Crawford", "Eric", ""], ["Pineau", "Joelle", ""]]}, {"id": "1911.09040", "submitter": "Quanshi Zhang", "authors": "Wen Shen, Binbin Zhang, Shikun Huang, Zhihua Wei, Quanshi Zhang", "title": "3D-Rotation-Equivariant Quaternion Neural Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper proposes a set of rules to revise various neural networks for 3D\npoint cloud processing to rotation-equivariant quaternion neural networks\n(REQNNs). We find that when a neural network uses quaternion features under\ncertain conditions, the network feature naturally has the rotation-equivariance\nproperty. Rotation equivariance means that applying a specific rotation\ntransformation to the input point cloud is equivalent to applying the same\nrotation transformation to all intermediate-layer quaternion features. Besides,\nthe REQNN also ensures that the intermediate-layer features are invariant to\nthe permutation of input points. Compared with the original neural network, the\nREQNN exhibits higher rotation robustness.\n", "versions": [{"version": "v1", "created": "Wed, 20 Nov 2019 17:10:52 GMT"}, {"version": "v2", "created": "Sun, 11 Oct 2020 08:24:30 GMT"}], "update_date": "2020-10-13", "authors_parsed": [["Shen", "Wen", ""], ["Zhang", "Binbin", ""], ["Huang", "Shikun", ""], ["Wei", "Zhihua", ""], ["Zhang", "Quanshi", ""]]}, {"id": "1911.09045", "submitter": "Saeed Khaki", "authors": "Saeed Khaki, Lizhi Wang and Sotirios V. Archontoulis", "title": "A CNN-RNN Framework for Crop Yield Prediction", "comments": "26 Pages, 14 Figures", "journal-ref": "Frontiers in Plant Science, 2019", "doi": "10.3389/fpls.2019.01750", "report-no": null, "categories": "cs.LG q-bio.QM stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Crop yield prediction is extremely challenging due to its dependence on\nmultiple factors such as crop genotype, environmental factors, management\npractices, and their interactions. This paper presents a deep learning\nframework using convolutional neural networks (CNN) and recurrent neural\nnetworks (RNN) for crop yield prediction based on environmental data and\nmanagement practices. The proposed CNN-RNN model, along with other popular\nmethods such as random forest (RF), deep fully-connected neural networks\n(DFNN), and LASSO, was used to forecast corn and soybean yield across the\nentire Corn Belt (including 13 states) in the United States for years 2016,\n2017, and 2018 using historical data. The new model achieved a\nroot-mean-square-error (RMSE) 9% and 8% of their respective average yields,\nsubstantially outperforming all other methods that were tested. The CNN-RNN\nhave three salient features that make it a potentially useful method for other\ncrop yield prediction studies. (1) The CNN-RNN model was designed to capture\nthe time dependencies of environmental factors and the genetic improvement of\nseeds over time without having their genotype information. (2) The model\ndemonstrated the capability to generalize the yield prediction to untested\nenvironments without significant drop in the prediction accuracy. (3) Coupled\nwith the backpropagation method, the model could reveal the extent to which\nweather conditions, accuracy of weather predictions, soil conditions, and\nmanagement practices were able to explain the variation in the crop yields.\n", "versions": [{"version": "v1", "created": "Wed, 20 Nov 2019 17:18:48 GMT"}, {"version": "v2", "created": "Fri, 24 Jan 2020 19:10:32 GMT"}], "update_date": "2020-01-28", "authors_parsed": [["Khaki", "Saeed", ""], ["Wang", "Lizhi", ""], ["Archontoulis", "Sotirios V.", ""]]}, {"id": "1911.09046", "submitter": "Xiangfeng Wang", "authors": "Junjie Wang, Xiangfeng Wang, Bo Jin, Junchi Yan, Wenjie Zhang,\n  Hongyuan Zha", "title": "Heterogeneous Graph-based Knowledge Transfer for Generalized Zero-shot\n  Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Generalized zero-shot learning (GZSL) tackles the problem of learning to\nclassify instances involving both seen classes and unseen ones. The key issue\nis how to effectively transfer the model learned from seen classes to unseen\nclasses. Existing works in GZSL usually assume that some prior information\nabout unseen classes are available. However, such an assumption is unrealistic\nwhen new unseen classes appear dynamically. To this end, we propose a novel\nheterogeneous graph-based knowledge transfer method (HGKT) for GZSL, agnostic\nto unseen classes and instances, by leveraging graph neural network.\nSpecifically, a structured heterogeneous graph is constructed with high-level\nrepresentative nodes for seen classes, which are chosen through Wasserstein\nbarycenter in order to simultaneously capture inter-class and intra-class\nrelationship. The aggregation and embedding functions can be learned through\ngraph neural network, which can be used to compute the embeddings of unseen\nclasses by transferring the knowledge from their neighbors. Extensive\nexperiments on public benchmark datasets show that our method achieves\nstate-of-the-art results.\n", "versions": [{"version": "v1", "created": "Wed, 20 Nov 2019 17:20:05 GMT"}], "update_date": "2019-11-21", "authors_parsed": [["Wang", "Junjie", ""], ["Wang", "Xiangfeng", ""], ["Jin", "Bo", ""], ["Yan", "Junchi", ""], ["Zhang", "Wenjie", ""], ["Zha", "Hongyuan", ""]]}, {"id": "1911.09052", "submitter": "Olga Ohrimenko", "authors": "Olga Ohrimenko and Shruti Tople and Sebastian Tschiatschek", "title": "Collaborative Machine Learning Markets with Data-Replication-Robust\n  Payments", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.GT cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the problem of collaborative machine learning markets where multiple\nparties can achieve improved performance on their machine learning tasks by\ncombining their training data. We discuss desired properties for these machine\nlearning markets in terms of fair revenue distribution and potential threats,\nincluding data replication. We then instantiate a collaborative market for\ncases where parties share a common machine learning task and where parties'\ntasks are different. Our marketplace incentivizes parties to submit high\nquality training and true validation data. To this end, we introduce a novel\npayment division function that is robust-to-replication and customized output\nmodels that perform well only on requested machine learning tasks. In\nexperiments, we validate the assumptions underlying our theoretical analysis\nand show that these are approximately satisfied for commonly used machine\nlearning models.\n", "versions": [{"version": "v1", "created": "Fri, 8 Nov 2019 13:58:31 GMT"}], "update_date": "2019-11-21", "authors_parsed": [["Ohrimenko", "Olga", ""], ["Tople", "Shruti", ""], ["Tschiatschek", "Sebastian", ""]]}, {"id": "1911.09053", "submitter": "Quanshi Zhang", "authors": "Wen Shen, Zhihua Wei, Shikun Huang, Binbin Zhang, Panyue Chen, Ping\n  Zhao, Quanshi Zhang", "title": "Verifiability and Predictability: Interpreting Utilities of Network\n  Architectures for Point Cloud Processing", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we diagnose deep neural networks for 3D point cloud processing\nto explore utilities of different intermediate-layer network architectures. We\npropose a number of hypotheses on the effects of specific intermediate-layer\nnetwork architectures on the representation capacity of DNNs. In order to prove\nthe hypotheses, we design five metrics to diagnose various types of DNNs from\nthe following perspectives, information discarding, information concentration,\nrotation robustness, adversarial robustness, and neighborhood inconsistency. We\nconduct comparative studies based on such metrics to verify the hypotheses. We\nfurther use the verified hypotheses to revise intermediate-layer architectures\nof existing DNNs and improve their utilities. Experiments demonstrate the\neffectiveness of our method.\n", "versions": [{"version": "v1", "created": "Wed, 20 Nov 2019 17:33:19 GMT"}, {"version": "v2", "created": "Sun, 11 Oct 2020 09:00:39 GMT"}, {"version": "v3", "created": "Thu, 1 Apr 2021 03:54:03 GMT"}], "update_date": "2021-04-02", "authors_parsed": [["Shen", "Wen", ""], ["Wei", "Zhihua", ""], ["Huang", "Shikun", ""], ["Zhang", "Binbin", ""], ["Chen", "Panyue", ""], ["Zhao", "Ping", ""], ["Zhang", "Quanshi", ""]]}, {"id": "1911.09058", "submitter": "Omid Poursaeed", "authors": "Omid Poursaeed, Tianxing Jiang, Yordanos Goshu, Harry Yang, Serge\n  Belongie, Ser-Nam Lim", "title": "Fine-grained Synthesis of Unrestricted Adversarial Examples", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.CR cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a novel approach for generating unrestricted adversarial examples\nby manipulating fine-grained aspects of image generation. Unlike existing\nunrestricted attacks that typically hand-craft geometric transformations, we\nlearn stylistic and stochastic modifications leveraging state-of-the-art\ngenerative models. This allows us to manipulate an image in a controlled,\nfine-grained manner without being bounded by a norm threshold. Our approach can\nbe used for targeted and non-targeted unrestricted attacks on classification,\nsemantic segmentation and object detection models. Our attacks can bypass\ncertified defenses, yet our adversarial images look indistinguishable from\nnatural images as verified by human evaluation. Moreover, we demonstrate that\nadversarial training with our examples improves performance of the model on\nclean images without requiring any modifications to the architecture. We\nperform experiments on LSUN, CelebA-HQ and COCO-Stuff as high resolution\ndatasets to validate efficacy of our proposed approach.\n", "versions": [{"version": "v1", "created": "Wed, 20 Nov 2019 17:42:12 GMT"}, {"version": "v2", "created": "Thu, 22 Oct 2020 16:53:26 GMT"}], "update_date": "2020-10-23", "authors_parsed": [["Poursaeed", "Omid", ""], ["Jiang", "Tianxing", ""], ["Goshu", "Yordanos", ""], ["Yang", "Harry", ""], ["Belongie", "Serge", ""], ["Lim", "Ser-Nam", ""]]}, {"id": "1911.09061", "submitter": "Azim Ahmadzadeh", "authors": "Azim Ahmadzadeh, Maxwell Hostetter, Berkay Aydin, Manolis K.\n  Georgoulis, Dustin J. Kempton, Sushant S. Mahajan, and Rafal A. Angryk", "title": "Challenges with Extreme Class-Imbalance and Temporal Coherence: A Study\n  on Solar Flare Data", "comments": "9 pages, 9 figures, and 1 table, accepted in IEEE BigData 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG astro-ph.SR stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  In analyses of rare-events, regardless of the domain of application,\nclass-imbalance issue is intrinsic. Although the challenges are known to data\nexperts, their explicit impact on the analytic and the decisions made based on\nthe findings are often overlooked. This is in particular prevalent in\ninterdisciplinary research where the theoretical aspects are sometimes\novershadowed by the challenges of the application. To show-case these\nundesirable impacts, we conduct a series of experiments on a recently created\nbenchmark data, named Space Weather ANalytics for Solar Flares (SWAN-SF). This\nis a multivariate time series dataset of magnetic parameters of active regions.\nAs a remedy for the imbalance issue, we study the impact of data manipulation\n(undersampling and oversampling) and model manipulation (using class weights).\nFurthermore, we bring to focus the auto-correlation of time series that is\ninherited from the use of sliding window for monitoring flares' history.\nTemporal coherence, as we call this phenomenon, invalidates the randomness\nassumption, thus impacting all sampling practices including different\ncross-validation techniques. We illustrate how failing to notice this concept\ncould give an artificial boost in the forecast performance and result in\nmisleading findings. Throughout this study we utilized Support Vector Machine\nas a classifier, and True Skill Statistics as a verification metric for\ncomparison of experiments. We conclude our work by specifying the correct\npractice in each case, and we hope that this study could benefit researchers in\nother domains where time series of rare events are of interest.\n", "versions": [{"version": "v1", "created": "Wed, 20 Nov 2019 17:46:38 GMT"}], "update_date": "2019-11-21", "authors_parsed": [["Ahmadzadeh", "Azim", ""], ["Hostetter", "Maxwell", ""], ["Aydin", "Berkay", ""], ["Georgoulis", "Manolis K.", ""], ["Kempton", "Dustin J.", ""], ["Mahajan", "Sushant S.", ""], ["Angryk", "Rafal A.", ""]]}, {"id": "1911.09070", "submitter": "Mingxing Tan", "authors": "Mingxing Tan, Ruoming Pang, Quoc V. Le", "title": "EfficientDet: Scalable and Efficient Object Detection", "comments": "CVPR 2020", "journal-ref": "Proceedings of the IEEE Conference on Computer Vision and Pattern\n  Recognition (2020)", "doi": null, "report-no": null, "categories": "cs.CV cs.LG eess.IV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Model efficiency has become increasingly important in computer vision. In\nthis paper, we systematically study neural network architecture design choices\nfor object detection and propose several key optimizations to improve\nefficiency. First, we propose a weighted bi-directional feature pyramid network\n(BiFPN), which allows easy and fast multiscale feature fusion; Second, we\npropose a compound scaling method that uniformly scales the resolution, depth,\nand width for all backbone, feature network, and box/class prediction networks\nat the same time. Based on these optimizations and better backbones, we have\ndeveloped a new family of object detectors, called EfficientDet, which\nconsistently achieve much better efficiency than prior art across a wide\nspectrum of resource constraints. In particular, with single model and\nsingle-scale, our EfficientDet-D7 achieves state-of-the-art 55.1 AP on COCO\ntest-dev with 77M parameters and 410B FLOPs, being 4x - 9x smaller and using\n13x - 42x fewer FLOPs than previous detectors. Code is available at\nhttps://github.com/google/automl/tree/master/efficientdet.\n", "versions": [{"version": "v1", "created": "Wed, 20 Nov 2019 18:16:09 GMT"}, {"version": "v2", "created": "Sun, 15 Mar 2020 22:55:42 GMT"}, {"version": "v3", "created": "Tue, 31 Mar 2020 18:47:08 GMT"}, {"version": "v4", "created": "Fri, 3 Apr 2020 20:34:21 GMT"}, {"version": "v5", "created": "Sun, 24 May 2020 07:12:44 GMT"}, {"version": "v6", "created": "Sun, 14 Jun 2020 18:28:53 GMT"}, {"version": "v7", "created": "Mon, 27 Jul 2020 15:55:16 GMT"}], "update_date": "2020-07-28", "authors_parsed": [["Tan", "Mingxing", ""], ["Pang", "Ruoming", ""], ["Le", "Quoc V.", ""]]}, {"id": "1911.09071", "submitter": "Katherine Hermann", "authors": "Katherine L. Hermann, Ting Chen, and Simon Kornblith", "title": "The Origins and Prevalence of Texture Bias in Convolutional Neural\n  Networks", "comments": "NeurIPS'2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent work has indicated that, unlike humans, ImageNet-trained CNNs tend to\nclassify images by texture rather than by shape. How pervasive is this bias,\nand where does it come from? We find that, when trained on datasets of images\nwith conflicting shape and texture, CNNs learn to classify by shape at least as\neasily as by texture. What factors, then, produce the texture bias in CNNs\ntrained on ImageNet? Different unsupervised training objectives and different\narchitectures have small but significant and largely independent effects on the\nlevel of texture bias. However, all objectives and architectures still lead to\nmodels that make texture-based classification decisions a majority of the time,\neven if shape information is decodable from their hidden representations. The\neffect of data augmentation is much larger. By taking less aggressive random\ncrops at training time and applying simple, naturalistic augmentation (color\ndistortion, noise, and blur), we train models that classify ambiguous images by\nshape a majority of the time, and outperform baselines on out-of-distribution\ntest sets. Our results indicate that apparent differences in the way humans and\nImageNet-trained CNNs process images may arise not primarily from differences\nin their internal workings, but from differences in the data that they see.\n", "versions": [{"version": "v1", "created": "Wed, 20 Nov 2019 18:16:38 GMT"}, {"version": "v2", "created": "Mon, 29 Jun 2020 20:48:56 GMT"}, {"version": "v3", "created": "Tue, 3 Nov 2020 22:51:23 GMT"}], "update_date": "2020-11-05", "authors_parsed": [["Hermann", "Katherine L.", ""], ["Chen", "Ting", ""], ["Kornblith", "Simon", ""]]}, {"id": "1911.09074", "submitter": "Yu Liu", "authors": "Yu Liu, Xuhui Jia, Mingxing Tan, Raviteja Vemulapalli, Yukun Zhu,\n  Bradley Green, Xiaogang Wang", "title": "Search to Distill: Pearls are Everywhere but not the Eyes", "comments": "Accepted as an oral representation to CVPR 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Standard Knowledge Distillation (KD) approaches distill the knowledge of a\ncumbersome teacher model into the parameters of a student model with a\npre-defined architecture. However, the knowledge of a neural network, which is\nrepresented by the network's output distribution conditioned on its input,\ndepends not only on its parameters but also on its architecture. Hence, a more\ngeneralized approach for KD is to distill the teacher's knowledge into both the\nparameters and architecture of the student. To achieve this, we present a new\nArchitecture-aware Knowledge Distillation (AKD) approach that finds student\nmodels (pearls for the teacher) that are best for distilling the given teacher\nmodel. In particular, we leverage Neural Architecture Search (NAS), equipped\nwith our KD-guided reward, to search for the best student architectures for a\ngiven teacher. Experimental results show our proposed AKD consistently\noutperforms the conventional NAS plus KD approach, and achieves\nstate-of-the-art results on the ImageNet classification task under various\nlatency settings. Furthermore, the best AKD student architecture for the\nImageNet classification task also transfers well to other tasks such as million\nlevel face recognition and ensemble learning.\n", "versions": [{"version": "v1", "created": "Wed, 20 Nov 2019 18:19:25 GMT"}, {"version": "v2", "created": "Tue, 17 Mar 2020 03:48:49 GMT"}], "update_date": "2020-03-18", "authors_parsed": [["Liu", "Yu", ""], ["Jia", "Xuhui", ""], ["Tan", "Mingxing", ""], ["Vemulapalli", "Raviteja", ""], ["Zhu", "Yukun", ""], ["Green", "Bradley", ""], ["Wang", "Xiaogang", ""]]}, {"id": "1911.09083", "submitter": "Gabriele Vajente", "authors": "Gabriele Vajente, Yiwen Huang, Maximiliano Isi, Jenne C. Driggers,\n  Jeffrey S. Kissel, Marek J. Szczepanczyk, Salvatore Vitale", "title": "Machine-learning non-stationary noise out of gravitational wave\n  detectors", "comments": null, "journal-ref": "Phys. Rev. D 101, 042003 (2020)", "doi": "10.1103/PhysRevD.101.042003", "report-no": null, "categories": "gr-qc astro-ph.IM cs.LG physics.data-an physics.ins-det", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Signal extraction out of background noise is a common challenge in high\nprecision physics experiments, where the measurement output is often a\ncontinuous data stream. To improve the signal to noise ratio of the detection,\nwitness sensors are often used to independently measure background noises and\nsubtract them from the main signal. If the noise coupling is linear and\nstationary, optimal techniques already exist and are routinely implemented in\nmany experiments. However, when the noise coupling is non-stationary, linear\ntechniques often fail or are sub-optimal. Inspired by the properties of the\nbackground noise in gravitational wave detectors, this work develops a novel\nalgorithm to efficiently characterize and remove non-stationary noise\ncouplings, provided there exist witnesses of the noise source and of the\nmodulation. In this work, the algorithm is described in its most general\nformulation, and its efficiency is demonstrated with examples from the data of\nthe Advanced LIGO gravitational wave observatory, where we could obtain an\nimprovement of the detector gravitational wave reach without introducing any\nbias on the source parameter estimation.\n", "versions": [{"version": "v1", "created": "Wed, 20 Nov 2019 18:41:24 GMT"}, {"version": "v2", "created": "Fri, 10 Jan 2020 21:45:19 GMT"}, {"version": "v3", "created": "Tue, 28 Jan 2020 23:57:39 GMT"}], "update_date": "2020-02-26", "authors_parsed": [["Vajente", "Gabriele", ""], ["Huang", "Yiwen", ""], ["Isi", "Maximiliano", ""], ["Driggers", "Jenne C.", ""], ["Kissel", "Jeffrey S.", ""], ["Szczepanczyk", "Marek J.", ""], ["Vitale", "Salvatore", ""]]}, {"id": "1911.09086", "submitter": "Monica Arul", "authors": "Monica Arul and Ahsan Kareem", "title": "Shapelets for earthquake detection", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper introduces EQShapelets (EarthQuake Shapelets) a time-series\nshape-based approach embedded in machine learning to autonomously detect\nearthquakes. It promises to overcome the challenges in the field of seismology\nrelated to automated detection and cataloging of earthquakes. EQShapelets are\namplitude and phase-independent, i.e., their detection sensitivity is\nirrespective of the magnitude of the earthquake and the time of occurrence.\nThey are also robust to noise and other spurious signals. The detection\ncapability of EQShapelets is tested on one week of continuous seismic data\nprovided by the Northern California Seismic Network (NCSN) obtained from a\nstation in central California near the Calaveras Fault. EQShapelets combined\nwith a Random Forest classifier, detected all of the cataloged earthquakes and\n281 uncataloged events with lower false detection rate thus offering a better\nperformance than autocorrelation and FAST algorithms. The primary advantage of\nEQShapelets over competing methods is the interpretability and insight it\noffers. Shape-based approaches are intuitive, visually meaningful and offers\nimmediate insight into the problem domain that goes beyond their use in\naccurate detection. EQShapelets, if implemented at a large scale, can\nsignificantly reduce catalog completeness magnitudes and can serve as an\neffective tool for near real-time earthquake monitoring and cataloging.\n", "versions": [{"version": "v1", "created": "Wed, 20 Nov 2019 18:50:25 GMT"}], "update_date": "2019-11-21", "authors_parsed": [["Arul", "Monica", ""], ["Kareem", "Ahsan", ""]]}, {"id": "1911.09098", "submitter": "Pierrick Coupe", "authors": "Pierrick Coup\\'e, Boris Mansencal, Micha\\\"el Cl\\'ement, R\\'emi Giraud,\n  Baudouin Denis de Senneville, Vinh-Thong Ta, Vincent Lepetit, Jos\\'e V.\n  Manjon", "title": "AssemblyNet: A large ensemble of CNNs for 3D Whole Brain MRI\n  Segmentation", "comments": "arXiv admin note: substantial text overlap with arXiv:1906.01862", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.IV cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Whole brain segmentation using deep learning (DL) is a very challenging task\nsince the number of anatomical labels is very high compared to the number of\navailable training images. To address this problem, previous DL methods\nproposed to use a single convolution neural network (CNN) or few independent\nCNNs. In this paper, we present a novel ensemble method based on a large number\nof CNNs processing different overlapping brain areas. Inspired by parliamentary\ndecision-making systems, we propose a framework called AssemblyNet, made of two\n\"assemblies\" of U-Nets. Such a parliamentary system is capable of dealing with\ncomplex decisions, unseen problem and reaching a consensus quickly. AssemblyNet\nintroduces sharing of knowledge among neighboring U-Nets, an \"amendment\"\nprocedure made by the second assembly at higher-resolution to refine the\ndecision taken by the first one, and a final decision obtained by majority\nvoting. During our validation, AssemblyNet showed competitive performance\ncompared to state-of-the-art methods such as U-Net, Joint label fusion and\nSLANT. Moreover, we investigated the scan-rescan consistency and the robustness\nto disease effects of our method. These experiences demonstrated the\nreliability of AssemblyNet. Finally, we showed the interest of using\nsemi-supervised learning to improve the performance of our method.\n", "versions": [{"version": "v1", "created": "Wed, 20 Nov 2019 13:37:16 GMT"}], "update_date": "2019-11-22", "authors_parsed": [["Coup\u00e9", "Pierrick", ""], ["Mansencal", "Boris", ""], ["Cl\u00e9ment", "Micha\u00ebl", ""], ["Giraud", "R\u00e9mi", ""], ["de Senneville", "Baudouin Denis", ""], ["Ta", "Vinh-Thong", ""], ["Lepetit", "Vincent", ""], ["Manjon", "Jos\u00e9 V.", ""]]}, {"id": "1911.09101", "submitter": "Santiago Paternain Mr", "authors": "Santiago Paternain, Miguel Calvo-Fullana, Luiz F. O. Chamon and\n  Alejandro Ribeiro", "title": "Safe Policies for Reinforcement Learning via Primal-Dual Methods", "comments": "arXiv admin note: text overlap with arXiv:1910.13393", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.SY cs.LG cs.SY math.OC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we study the learning of safe policies in the setting of\nreinforcement learning problems. This is, we aim to control a Markov Decision\nProcess (MDP) of which we do not know the transition probabilities, but we have\naccess to sample trajectories through experience. We define safety as the agent\nremaining in a desired safe set with high probability during the operation\ntime. We therefore consider a constrained MDP where the constraints are\nprobabilistic. Since there is no straightforward way to optimize the policy\nwith respect to the probabilistic constraint in a reinforcement learning\nframework, we propose an ergodic relaxation of the problem. The advantages of\nthe proposed relaxation are threefold. (i) The safety guarantees are maintained\nin the case of episodic tasks and they are kept up to a given time horizon for\ncontinuing tasks. (ii) The constrained optimization problem despite its\nnon-convexity has arbitrarily small duality gap if the parametrization of the\npolicy is rich enough. (iii) The gradients of the Lagrangian associated with\nthe safe-learning problem can be easily computed using standard policy gradient\nresults and stochastic approximation tools. Leveraging these advantages, we\nestablish that primal-dual algorithms are able to find policies that are safe\nand optimal. We test the proposed approach in a navigation task in a continuous\ndomain. The numerical results show that our algorithm is capable of dynamically\nadapting the policy to the environment and the required safety levels.\n", "versions": [{"version": "v1", "created": "Wed, 20 Nov 2019 17:56:39 GMT"}], "update_date": "2019-11-22", "authors_parsed": [["Paternain", "Santiago", ""], ["Calvo-Fullana", "Miguel", ""], ["Chamon", "Luiz F. O.", ""], ["Ribeiro", "Alejandro", ""]]}, {"id": "1911.09103", "submitter": "Andrew White", "authors": "Rainier Barrett and Andrew D. White", "title": "Investigating Active Learning and Meta-Learning for Iterative Peptide\n  Design", "comments": "19 pages, 8 figures, 9 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.BM cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Often the development of novel functional peptides is not amenable to high\nthroughput or purely computational screening methods. Peptides must be\nsynthesized one at a time in a process that does not generate large amounts of\ndata. One way this method can be improved is by ensuring that each experiment\nprovides the best improvement in both peptide properties and predictive\nmodeling accuracy. Here, we study the effectiveness of active learning,\noptimizing experiment order, and meta-learning, transferring knowledge between\ncontexts, to reduce the number of experiments necessary to build a predictive\nmodel. We present a multi-task benchmark database of peptides designed to\nadvance these methods for experimental design. Each task is binary\nclassification of peptides represented as a sequence string. We find neither\nactive learning method tested to be better than random choice. The\nmeta-learning method Reptile was found to improve average accuracy across\ndatasets. Combining meta-learning with active learning offers inconsistent\nbenefits.\n", "versions": [{"version": "v1", "created": "Wed, 20 Nov 2019 18:33:01 GMT"}, {"version": "v2", "created": "Thu, 6 Feb 2020 14:46:46 GMT"}, {"version": "v3", "created": "Mon, 27 Jul 2020 23:33:27 GMT"}, {"version": "v4", "created": "Thu, 10 Dec 2020 22:02:17 GMT"}], "update_date": "2020-12-14", "authors_parsed": [["Barrett", "Rainier", ""], ["White", "Andrew D.", ""]]}, {"id": "1911.09105", "submitter": "Gregory Wornell", "authors": "Shao-Lun Huang, Anuran Makur, Gregory W. Wornell, and Lizhong Zheng", "title": "On Universal Features for High-Dimensional Learning and Inference", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.IT math.IT stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the problem of identifying universal low-dimensional features\nfrom high-dimensional data for inference tasks in settings involving learning.\nFor such problems, we introduce natural notions of universality and we show a\nlocal equivalence among them. Our analysis is naturally expressed via\ninformation geometry, and represents a conceptually and computationally useful\nanalysis. The development reveals the complementary roles of the singular value\ndecomposition, Hirschfeld-Gebelein-R\\'enyi maximal correlation, the canonical\ncorrelation and principle component analyses of Hotelling and Pearson, Tishby's\ninformation bottleneck, Wyner's common information, Ky Fan $k$-norms, and\nBrieman and Friedman's alternating conditional expectations algorithm. We\nfurther illustrate how this framework facilitates understanding and optimizing\naspects of learning systems, including multinomial logistic (softmax)\nregression and the associated neural network architecture, matrix factorization\nmethods for collaborative filtering and other applications, rank-constrained\nmultivariate linear regression, and forms of semi-supervised learning.\n", "versions": [{"version": "v1", "created": "Wed, 20 Nov 2019 19:00:00 GMT"}], "update_date": "2019-11-22", "authors_parsed": [["Huang", "Shao-Lun", ""], ["Makur", "Anuran", ""], ["Wornell", "Gregory W.", ""], ["Zheng", "Lizhong", ""]]}, {"id": "1911.09117", "submitter": "Shi-Xin Zhang", "authors": "Shi-Xin Zhang, Zhou-Quan Wan, and Hong Yao", "title": "Automatic Differentiable Monte Carlo: Theory and Application", "comments": "11.5 pages + supplemental materials, 4 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "physics.comp-ph cond-mat.dis-nn cond-mat.stat-mech cond-mat.str-el cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Differentiable programming has emerged as a key programming paradigm\nempowering rapid developments of deep learning while its applications to\nimportant computational methods such as Monte Carlo remain largely unexplored.\nHere we present the general theory enabling infinite-order automatic\ndifferentiation on expectations computed by Monte Carlo with unnormalized\nprobability distributions, which we call \"automatic differentiable Monte Carlo\"\n(ADMC). By implementing ADMC algorithms on computational graphs, one can also\nleverage state-of-the-art machine learning frameworks and techniques to\ntraditional Monte Carlo applications in statistics and physics. We illustrate\nthe versatility of ADMC by showing some applications: fast search of phase\ntransitions and accurately finding ground states of interacting many-body\nmodels in two dimensions. ADMC paves a promising way to innovate Monte Carlo in\nvarious aspects to achieve higher accuracy and efficiency, e.g. easing or\nsolving the sign problem of quantum many-body models through ADMC.\n", "versions": [{"version": "v1", "created": "Wed, 20 Nov 2019 19:00:03 GMT"}], "update_date": "2019-11-25", "authors_parsed": [["Zhang", "Shi-Xin", ""], ["Wan", "Zhou-Quan", ""], ["Yao", "Hong", ""]]}, {"id": "1911.09143", "submitter": "Xinshao Wang Mr", "authors": "Xinshao Wang, Elyor Kodirov, Yang Hua, Neil M. Robertson", "title": "ID-aware Quality for Set-based Person Re-identification", "comments": "A Set-based Person Re-identification Baseline: Simple Average Fusion\n  of Global Spatial Representations, without temporal information, without\n  parts/poses/attributes information", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG eess.IV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Set-based person re-identification (SReID) is a matching problem that aims to\nverify whether two sets are of the same identity (ID). Existing SReID models\ntypically generate a feature representation per image and aggregate them to\nrepresent the set as a single embedding. However, they can easily be perturbed\nby noises--perceptually/semantically low quality images--which are inevitable\ndue to imperfect tracking/detection systems, or overfit to trivial images. In\nthis work, we present a novel and simple solution to this problem based on\nID-aware quality that measures the perceptual and semantic quality of images\nguided by their ID information. Specifically, we propose an ID-aware Embedding\nthat consists of two key components: (1) Feature learning attention that aims\nto learn robust image embeddings by focusing on 'medium' hard images. This way\nit can prevent overfitting to trivial images, and alleviate the influence of\noutliers. (2) Feature fusion attention is to fuse image embeddings in the set\nto obtain the set-level embedding. It ignores noisy information and pays more\nattention to discriminative images to aggregate more discriminative\ninformation. Experimental results on four datasets show that our method\noutperforms state-of-the-art approaches despite the simplicity of our approach.\n", "versions": [{"version": "v1", "created": "Wed, 20 Nov 2019 19:49:27 GMT"}], "update_date": "2019-11-22", "authors_parsed": [["Wang", "Xinshao", ""], ["Kodirov", "Elyor", ""], ["Hua", "Yang", ""], ["Robertson", "Neil M.", ""]]}, {"id": "1911.09145", "submitter": "Justin Sirignano", "authors": "Jonathan B. Freund, Jonathan F. MacArt, and Justin Sirignano", "title": "DPM: A deep learning PDE augmentation method (with application to\n  large-eddy simulation)", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Machine learning for scientific applications faces the challenge of limited\ndata. We propose a framework that leverages a priori known physics to reduce\noverfitting when training on relatively small datasets. A deep neural network\nis embedded in a partial differential equation (PDE) that expresses the known\nphysics and learns to describe the corresponding unknown or unrepresented\nphysics from the data. Crafted as such, the neural network can also provide\ncorrections for erroneously represented physics, such as discretization errors\nassociated with the PDE's numerical solution. Once trained, the deep learning\nPDE model (DPM) can make out-of-sample predictions for new physical parameters,\ngeometries, and boundary conditions.\n  Our approach optimizes over the functional form of the PDE. Estimating the\nembedded neural network requires optimizing over the entire PDE, which itself\nis a function of the neural network. Adjoint partial differential equations are\nused to efficiently calculate the high-dimensional gradient of the objective\nfunction with respect to the neural network parameters. A stochastic adjoint\nmethod (SAM), similar in spirit to stochastic gradient descent, further\naccelerates training.\n  The approach is demonstrated and evaluated for turbulence predictions using\nlarge-eddy simulation (LES), a filtered version of the Navier--Stokes equation\ncontaining unclosed sub-filter-scale terms. The DPM outperforms the widely-used\nconstant-coefficient and dynamic Smagorinsky models, even for filter sizes so\nlarge that these established models become qualitatively incorrect. It also\nsignificantly outperforms a priori trained models, which do not account for the\nfull PDE. A relaxation of the discrete enforcement of the divergence-free\nconstraint is also considered, instead allowing the DPM to approximately\nenforce incompressibility physics.\n", "versions": [{"version": "v1", "created": "Wed, 20 Nov 2019 19:51:14 GMT"}], "update_date": "2019-11-22", "authors_parsed": [["Freund", "Jonathan B.", ""], ["MacArt", "Jonathan F.", ""], ["Sirignano", "Justin", ""]]}, {"id": "1911.09153", "submitter": "Tyler Lu", "authors": "Ivan Vendrov, Tyler Lu, Qingqing Huang, Craig Boutilier", "title": "Gradient-based Optimization for Bayesian Preference Elicitation", "comments": "To appear in the Thirty-Fourth AAAI Conference on Artificial\n  Intelligence (AAAI-20)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Effective techniques for eliciting user preferences have taken on added\nimportance as recommender systems (RSs) become increasingly interactive and\nconversational. A common and conceptually appealing Bayesian criterion for\nselecting queries is expected value of information (EVOI). Unfortunately, it is\ncomputationally prohibitive to construct queries with maximum EVOI in RSs with\nlarge item spaces. We tackle this issue by introducing a continuous formulation\nof EVOI as a differentiable network that can be optimized using gradient\nmethods available in modern machine learning (ML) computational frameworks\n(e.g., TensorFlow, PyTorch). We exploit this to develop a novel, scalable Monte\nCarlo method for EVOI optimization, which is more scalable for large item\nspaces than methods requiring explicit enumeration of items. While we emphasize\nthe use of this approach for pairwise (or k-wise) comparisons of items, we also\ndemonstrate how our method can be adapted to queries involving subsets of item\nattributes or \"partial items,\" which are often more cognitively manageable for\nusers. Experiments show that our gradient-based EVOI technique achieves\nstate-of-the-art performance across several domains while scaling to large item\nspaces.\n", "versions": [{"version": "v1", "created": "Wed, 20 Nov 2019 20:08:25 GMT"}], "update_date": "2019-11-22", "authors_parsed": [["Vendrov", "Ivan", ""], ["Lu", "Tyler", ""], ["Huang", "Qingqing", ""], ["Boutilier", "Craig", ""]]}, {"id": "1911.09156", "submitter": "Javier S\\'anchez-Monedero", "authors": "Javier S\\'anchez-Monedero and Lina Dencik", "title": "The politics of deceptive borders: 'biomarkers of deceit' and the case\n  of iBorderCtrl", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper critically examines a recently developed proposal for a border\ncontrol system called iBorderCtrl, designed to detect deception based on facial\nrecognition technology and the measurement of micro-expressions, termed\n'biomarkers of deceit'. Funded under the European Commission's Horizon 2020\nprogramme, we situate our analysis in the wider political economy of 'emotional\nAI' and the history of deception detection technologies. We then move on to\ninterrogate the design of iBorderCtrl using publicly available documents and\nassess the assumptions and scientific validation underpinning the project\ndesign. Finally, drawing on a Bayesian analysis we outline statistical\nfallacies in the foundational premise of mass screening and argue that it is\nvery unlikely that the model that iBorderCtrl provides for deception detection\nwould work in practice. By interrogating actual systems in this way, we argue\nthat we can begin to question the very premise of the development of\ndata-driven systems, and emotional AI and deception detection in particular,\npushing back on the assumption that these systems are fulfilling the tasks they\nclaim to be attending to and instead ask what function such projects carry out\nin the creation of subjects and management of populations. This function is not\nmerely technical but, rather, we argue, distinctly political and forms part of\na mode of governance increasingly shaping life opportunities and fundamental\nrights.\n", "versions": [{"version": "v1", "created": "Wed, 20 Nov 2019 20:17:11 GMT"}, {"version": "v2", "created": "Mon, 23 Dec 2019 20:22:23 GMT"}, {"version": "v3", "created": "Fri, 10 Jan 2020 12:48:18 GMT"}, {"version": "v4", "created": "Tue, 23 Jun 2020 12:18:36 GMT"}], "update_date": "2020-06-24", "authors_parsed": [["S\u00e1nchez-Monedero", "Javier", ""], ["Dencik", "Lina", ""]]}, {"id": "1911.09157", "submitter": "Gal Dalal", "authors": "Gal Dalal, Balazs Szorenyi, Gugan Thoppe", "title": "A Tale of Two-Timescale Reinforcement Learning with the Tightest\n  Finite-Time Bound", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG math.PR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Policy evaluation in reinforcement learning is often conducted using\ntwo-timescale stochastic approximation, which results in various gradient\ntemporal difference methods such as GTD(0), GTD2, and TDC. Here, we provide\nconvergence rate bounds for this suite of algorithms. Algorithms such as these\nhave two iterates, $\\theta_n$ and $w_n,$ which are updated using two distinct\nstepsize sequences, $\\alpha_n$ and $\\beta_n,$ respectively. Assuming $\\alpha_n\n= n^{-\\alpha}$ and $\\beta_n = n^{-\\beta}$ with $1 > \\alpha > \\beta > 0,$ we\nshow that, with high probability, the two iterates converge to their respective\nsolutions $\\theta^*$ and $w^*$ at rates given by $\\|\\theta_n - \\theta^*\\| =\n\\tilde{O}( n^{-\\alpha/2})$ and $\\|w_n - w^*\\| = \\tilde{O}(n^{-\\beta/2});$ here,\n$\\tilde{O}$ hides logarithmic terms. Via comparable lower bounds, we show that\nthese bounds are, in fact, tight. To the best of our knowledge, ours is the\nfirst finite-time analysis which achieves these rates. While it was known that\nthe two timescale components decouple asymptotically, our results depict this\nphenomenon more explicitly by showing that it in fact happens from some finite\ntime onwards. Lastly, compared to existing works, our result applies to a\nbroader family of stepsizes, including non-square summable ones.\n", "versions": [{"version": "v1", "created": "Wed, 20 Nov 2019 20:21:21 GMT"}, {"version": "v2", "created": "Wed, 4 Dec 2019 13:07:57 GMT"}], "update_date": "2019-12-05", "authors_parsed": [["Dalal", "Gal", ""], ["Szorenyi", "Balazs", ""], ["Thoppe", "Gugan", ""]]}, {"id": "1911.09158", "submitter": "Fanghui Liu", "authors": "Fanghui Liu, Xiaolin Huang, Yudong Chen, Jie Yang, Johan A.K. Suykens", "title": "Random Fourier Features via Fast Surrogate Leverage Weighted Sampling", "comments": "accepted by AAAI-20", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we propose a fast surrogate leverage weighted sampling\nstrategy to generate refined random Fourier features for kernel approximation.\nCompared to the current state-of-the-art method that uses the leverage weighted\nscheme [Li-ICML2019], our new strategy is simpler and more effective. It uses\nkernel alignment to guide the sampling process and it can avoid the matrix\ninversion operator when we compute the leverage function. Given n observations\nand s random features, our strategy can reduce the time complexity from\nO(ns^2+s^3) to O(ns^2), while achieving comparable (or even slightly better)\nprediction performance when applied to kernel ridge regression (KRR). In\naddition, we provide theoretical guarantees on the generalization performance\nof our approach, and in particular characterize the number of random features\nrequired to achieve statistical guarantees in KRR. Experiments on several\nbenchmark datasets demonstrate that our algorithm achieves comparable\nprediction performance and takes less time cost when compared to [Li-ICML2019].\n", "versions": [{"version": "v1", "created": "Wed, 20 Nov 2019 20:24:41 GMT"}], "update_date": "2019-11-22", "authors_parsed": [["Liu", "Fanghui", ""], ["Huang", "Xiaolin", ""], ["Chen", "Yudong", ""], ["Yang", "Jie", ""], ["Suykens", "Johan A. K.", ""]]}, {"id": "1911.09159", "submitter": "JInglai Li", "authors": "Yuzhou Gao, Tengchao Yu, Jinglai Li", "title": "Bayesian optimization with local search", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG math.OC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Global optimization finds applications in a wide range of real world\nproblems. The multi-start methods are a popular class of global optimization\ntechniques, which are based on the ideas of conducting local searches at\nmultiple starting points. In this work we propose a new multi-start algorithm\nwhere the starting points are determined in a Bayesian optimization framework.\nSpecifically, the method can be understood as to construct a new function by\nconducting local searches of the original objective function, where the new\nfunction attains the same global optima as the original one. Bayesian\noptimization is then applied to find the global optima of the new local search\ndefined function.\n", "versions": [{"version": "v1", "created": "Wed, 20 Nov 2019 20:25:49 GMT"}, {"version": "v2", "created": "Fri, 29 May 2020 19:21:57 GMT"}, {"version": "v3", "created": "Tue, 30 Jun 2020 11:46:57 GMT"}], "update_date": "2020-07-01", "authors_parsed": [["Gao", "Yuzhou", ""], ["Yu", "Tengchao", ""], ["Li", "Jinglai", ""]]}, {"id": "1911.09162", "submitter": "Changjian Shui", "authors": "Changjian Shui, Fan Zhou, Christian Gagn\\'e, Boyu Wang", "title": "Deep Active Learning: Unified and Principled Method for Query and\n  Training", "comments": "AISTATS 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we are proposing a unified and principled method for both the\nquerying and training processes in deep batch active learning. We are providing\ntheoretical insights from the intuition of modeling the interactive procedure\nin active learning as distribution matching, by adopting the Wasserstein\ndistance. As a consequence, we derived a new training loss from the theoretical\nanalysis, which is decomposed into optimizing deep neural network parameters\nand batch query selection through alternative optimization. In addition, the\nloss for training a deep neural network is naturally formulated as a min-max\noptimization problem through leveraging the unlabeled data information.\nMoreover, the proposed principles also indicate an explicit\nuncertainty-diversity trade-off in the query batch selection. Finally, we\nevaluate our proposed method on different benchmarks, consistently showing\nbetter empirical performances and a better time-efficient query strategy\ncompared to the baselines.\n", "versions": [{"version": "v1", "created": "Wed, 20 Nov 2019 20:36:45 GMT"}, {"version": "v2", "created": "Wed, 26 Feb 2020 14:39:02 GMT"}], "update_date": "2020-02-27", "authors_parsed": [["Shui", "Changjian", ""], ["Zhou", "Fan", ""], ["Gagn\u00e9", "Christian", ""], ["Wang", "Boyu", ""]]}, {"id": "1911.09168", "submitter": "Hamed Aghdam", "authors": "Hamed H. Aghdam, Abel Gonzalez-Garcia, Joost van de Weijer, Antonio M.\n  L\\'opez", "title": "Active Learning for Deep Detection Neural Networks", "comments": "Accepted at ICCV 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The cost of drawing object bounding boxes (i.e. labeling) for millions of\nimages is prohibitively high. For instance, labeling pedestrians in a regular\nurban image could take 35 seconds on average. Active learning aims to reduce\nthe cost of labeling by selecting only those images that are informative to\nimprove the detection network accuracy. In this paper, we propose a method to\nperform active learning of object detectors based on convolutional neural\nnetworks. We propose a new image-level scoring process to rank unlabeled images\nfor their automatic selection, which clearly outperforms classical scores. The\nproposed method can be applied to videos and sets of still images. In the\nformer case, temporal selection rules can complement our scoring process. As a\nrelevant use case, we extensively study the performance of our method on the\ntask of pedestrian detection. Overall, the experiments show that the proposed\nmethod performs better than random selection. Our codes are publicly available\nat www.gitlab.com/haghdam/deep_active_learning.\n", "versions": [{"version": "v1", "created": "Wed, 20 Nov 2019 20:57:44 GMT"}], "update_date": "2019-11-22", "authors_parsed": [["Aghdam", "Hamed H.", ""], ["Gonzalez-Garcia", "Abel", ""], ["van de Weijer", "Joost", ""], ["L\u00f3pez", "Antonio M.", ""]]}, {"id": "1911.09179", "submitter": "Kaicheng Yang", "authors": "Kai-Cheng Yang, Onur Varol, Pik-Mai Hui, Filippo Menczer", "title": "Scalable and Generalizable Social Bot Detection through Data Selection", "comments": "AAAI 2020", "journal-ref": null, "doi": "10.1609/aaai.v34i01.5460", "report-no": null, "categories": "cs.CY cs.LG cs.SI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Efficient and reliable social bot classification is crucial for detecting\ninformation manipulation on social media. Despite rapid development,\nstate-of-the-art bot detection models still face generalization and scalability\nchallenges, which greatly limit their applications. In this paper we propose a\nframework that uses minimal account metadata, enabling efficient analysis that\nscales up to handle the full stream of public tweets of Twitter in real time.\nTo ensure model accuracy, we build a rich collection of labeled datasets for\ntraining and validation. We deploy a strict validation system so that model\nperformance on unseen datasets is also optimized, in addition to traditional\ncross-validation. We find that strategically selecting a subset of training\ndata yields better model accuracy and generalization than exhaustively training\non all available data. Thanks to the simplicity of the proposed model, its\nlogic can be interpreted to provide insights into social bot characteristics.\n", "versions": [{"version": "v1", "created": "Wed, 20 Nov 2019 21:31:36 GMT"}], "update_date": "2020-06-05", "authors_parsed": [["Yang", "Kai-Cheng", ""], ["Varol", "Onur", ""], ["Hui", "Pik-Mai", ""], ["Menczer", "Filippo", ""]]}, {"id": "1911.09189", "submitter": "Alexander Alemi", "authors": "Ravid Shwartz-Ziv, Alexander A. Alemi", "title": "Information in Infinite Ensembles of Infinitely-Wide Neural Networks", "comments": "2nd Symposium on Advances in Approximate Bayesian Inference, 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.IT math.IT stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this preliminary work, we study the generalization properties of infinite\nensembles of infinitely-wide neural networks. Amazingly, this model family\nadmits tractable calculations for many information-theoretic quantities. We\nreport analytical and empirical investigations in the search for signals that\ncorrelate with generalization.\n", "versions": [{"version": "v1", "created": "Wed, 20 Nov 2019 21:56:11 GMT"}, {"version": "v2", "created": "Sat, 23 Nov 2019 23:17:55 GMT"}], "update_date": "2019-11-26", "authors_parsed": [["Shwartz-Ziv", "Ravid", ""], ["Alemi", "Alexander A.", ""]]}, {"id": "1911.09194", "submitter": "Angela Fan", "authors": "Angela Fan, Jack Urbanek, Pratik Ringshia, Emily Dinan, Emma Qian,\n  Siddharth Karamcheti, Shrimai Prabhumoye, Douwe Kiela, Tim Rocktaschel,\n  Arthur Szlam, Jason Weston", "title": "Generating Interactive Worlds with Text", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Procedurally generating cohesive and interesting game environments is\nchallenging and time-consuming. In order for the relationships between the game\nelements to be natural, common-sense has to be encoded into arrangement of the\nelements. In this work, we investigate a machine learning approach for world\ncreation using content from the multi-player text adventure game environment\nLIGHT. We introduce neural network based models to compositionally arrange\nlocations, characters, and objects into a coherent whole. In addition to\ncreating worlds based on existing elements, our models can generate new game\ncontent. Humans can also leverage our models to interactively aid in\nworldbuilding. We show that the game environments created with our approach are\ncohesive, diverse, and preferred by human evaluators compared to other machine\nlearning based world construction algorithms.\n", "versions": [{"version": "v1", "created": "Wed, 20 Nov 2019 22:20:52 GMT"}, {"version": "v2", "created": "Wed, 4 Dec 2019 19:46:21 GMT"}], "update_date": "2019-12-06", "authors_parsed": [["Fan", "Angela", ""], ["Urbanek", "Jack", ""], ["Ringshia", "Pratik", ""], ["Dinan", "Emily", ""], ["Qian", "Emma", ""], ["Karamcheti", "Siddharth", ""], ["Prabhumoye", "Shrimai", ""], ["Kiela", "Douwe", ""], ["Rocktaschel", "Tim", ""], ["Szlam", "Arthur", ""], ["Weston", "Jason", ""]]}, {"id": "1911.09214", "submitter": "Jia-Jie Zhu", "authors": "Jia-Jie Zhu, Georg Martius", "title": "Fast Non-Parametric Learning to Accelerate Mixed-Integer Programming for\n  Online Hybrid Model Predictive Control", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.OC cs.LG cs.SY eess.SY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Today's fast linear algebra and numerical optimization tools have pushed the\nfrontier of model predictive control (MPC) forward, to the efficient control of\nhighly nonlinear and hybrid systems. The field of hybrid MPC has demonstrated\nthat exact optimal control law can be computed, e.g., by mixed-integer\nprogramming (MIP) under piecewise-affine (PWA) system models. Despite the\nelegant theory, online solving hybrid MPC is still out of reach for many\napplications. We aim to speed up MIP by combining geometric insights from\nhybrid MPC, a simple-yet-effective learning algorithm, and MIP warm start\ntechniques. Following a line of work in approximate explicit MPC, the proposed\nlearning-control algorithm, LNMS, gains computational advantage over MIP at\nlittle cost and is straightforward for practitioners to implement.\n", "versions": [{"version": "v1", "created": "Wed, 20 Nov 2019 23:29:53 GMT"}, {"version": "v2", "created": "Thu, 7 May 2020 19:14:33 GMT"}], "update_date": "2020-05-11", "authors_parsed": [["Zhu", "Jia-Jie", ""], ["Martius", "Georg", ""]]}, {"id": "1911.09218", "submitter": "Yifeng Gao", "authors": "Yifeng Gao and Jessica Lin", "title": "Discovering Subdimensional Motifs of Different Lengths in Large-Scale\n  Multivariate Time Series", "comments": "Accepted by ICDM 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Detecting repeating patterns of different lengths in time series, also called\nvariable-length motifs, has received a great amount of attention by researchers\nand practitioners. Despite the significant progress that has been made in\nrecent single dimensional variable-length motif discovery work, detecting\nvariable-length \\textit{subdimensional motifs}---patterns that are\nsimultaneously occurring only in a subset of dimensions in multivariate time\nseries---remains a difficult task. The main challenge is scalability. On the\none hand, the brute-force enumeration solution, which searches for motifs of\nall possible lengths, is very time consuming even in single dimensional time\nseries. On the other hand, previous work show that index-based fixed-length\napproximate motif discovery algorithms such as random projection are not\nsuitable for detecting variable-length motifs due to memory requirement. In\nthis paper, we introduce an approximate variable-length subdimensional motif\ndiscovery algorithm called \\textbf{C}ollaborative \\textbf{HI}erarchy based\n\\textbf{M}otif \\textbf{E}numeration (CHIME) to efficiently detect\nvariable-length subdimensional motifs given a minimum motif length in\nlarge-scale multivariate time series. We show that the memory cost of the\napproach is significantly smaller than that of random projection. Moreover, the\nspeed of the proposed algorithm is significantly faster than that of the\nstate-of-the-art algorithms. We demonstrate that CHIME can efficiently detect\nmeaningful variable-length subdimensional motifs in large real world\nmultivariate time series datasets.\n", "versions": [{"version": "v1", "created": "Wed, 20 Nov 2019 23:35:15 GMT"}], "update_date": "2019-11-22", "authors_parsed": [["Gao", "Yifeng", ""], ["Lin", "Jessica", ""]]}, {"id": "1911.09228", "submitter": "Weitang Liu", "authors": "Weitang Liu, Lifeng Wei, James Sharpnack, John D. Owens", "title": "Unsupervised Object Segmentation with Explicit Localization Module", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG eess.IV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we propose a novel architecture that iteratively discovers and\nsegments out the objects of a scene based on the image reconstruction quality.\nDifferent from other approaches, our model uses an explicit localization module\nthat localizes objects of the scene based on the pixel-level reconstruction\nqualities at each iteration, where simpler objects tend to be reconstructed\nbetter at earlier iterations and thus are segmented out first. We show that our\nlocalization module improves the quality of the segmentation, especially on a\nchallenging background.\n", "versions": [{"version": "v1", "created": "Thu, 21 Nov 2019 00:50:48 GMT"}], "update_date": "2019-11-22", "authors_parsed": [["Liu", "Weitang", ""], ["Wei", "Lifeng", ""], ["Sharpnack", "James", ""], ["Owens", "John D.", ""]]}, {"id": "1911.09249", "submitter": "Hasnine Haque", "authors": "Hasnine Haque, Masahiro Hashimoto, Nozomu Uetake, Masahiro Jinzaki", "title": "Semantic Segmentation of Thigh Muscle using 2.5D Deep Learning Network\n  Trained with Limited Datasets", "comments": "7 pages, 5 figures, This manuscript was a detailed version of our\n  accepted oral paper in RSNA 2018. Ref: Haque,H, Hashimoto,M, Uetake,N,\n  Jinzaki,M, End to End Solution for Complete Thigh Muscle Semantic\n  Segmentation from Musculoskeletal CT using Deep Learning.\n  http://archive.rsna.org/2018/18006583.html", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.IV cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Purpose: We propose a 2.5D deep learning neural network (DLNN) to\nautomatically classify thigh muscle into 11 classes and evaluate its\nclassification accuracy over 2D and 3D DLNN when trained with limited datasets.\nEnables operator invariant quantitative assessment of the thigh muscle volume\nchange with respect to the disease progression. Materials and methods:\nRetrospective datasets consist of 48 thigh volume (TV) cropped from CT DICOM\nimages. Cropped volumes were aligned with femur axis and resample in 2 mm\nvoxel-spacing. Proposed 2.5D DLNN consists of three 2D U-Net trained with\naxial, coronal and sagittal muscle slices respectively. A voting algorithm was\nused to combine the output of U-Nets to create final segmentation. 2.5D U-Net\nwas trained on PC with 38 TV and the remaining 10 TV were used to evaluate\nsegmentation accuracy of 10 classes within Thigh. The result segmentation of\nboth left and right thigh were de-cropped to original CT volume space. Finally,\nsegmentation accuracies were compared between proposed DLNN and 2D/3D U-Net.\nResults: Average segmentation DSC score accuracy of all classes with 2.5D U-Net\nas 91.18% and Average Surface distance (ASD) accuracy as 0.84 mm. We found,\nmean DSC score for 2D U-Net was 3.3% lower than the that of 2.5D U-Net and mean\nDSC score of 3D U-Net was 5.7% lower than that of 2.5D U-Net when trained with\nsame datasets. Conclusion: We achieved a faster computationally efficient and\nautomatic segmentation of thigh muscle into 11 classes with reasonable\naccuracy. Enables quantitative evaluation of muscle atrophy with disease\nprogression.\n", "versions": [{"version": "v1", "created": "Thu, 21 Nov 2019 02:30:31 GMT"}], "update_date": "2019-11-22", "authors_parsed": [["Haque", "Hasnine", ""], ["Hashimoto", "Masahiro", ""], ["Uetake", "Nozomu", ""], ["Jinzaki", "Masahiro", ""]]}, {"id": "1911.09251", "submitter": "Tunhou Zhang", "authors": "Tunhou Zhang, Hsin-Pai Cheng, Zhenwen Li, Feng Yan, Chengyu Huang, Hai\n  Li, Yiran Chen", "title": "AutoShrink: A Topology-aware NAS for Discovering Efficient Neural\n  Architecture", "comments": null, "journal-ref": null, "doi": null, "report-no": "Thirty-Fourth AAAI Conference on Artificial Intelligence (AAAI-20)", "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Resource is an important constraint when deploying Deep Neural Networks\n(DNNs) on mobile and edge devices. Existing works commonly adopt the cell-based\nsearch approach, which limits the flexibility of network patterns in learned\ncell structures. Moreover, due to the topology-agnostic nature of existing\nworks, including both cell-based and node-based approaches, the search process\nis time consuming and the performance of found architecture may be sub-optimal.\nTo address these problems, we propose AutoShrink, a topology-aware Neural\nArchitecture Search(NAS) for searching efficient building blocks of neural\narchitectures. Our method is node-based and thus can learn flexible network\npatterns in cell structures within a topological search space. Directed Acyclic\nGraphs (DAGs) are used to abstract DNN architectures and progressively optimize\nthe cell structure through edge shrinking. As the search space intrinsically\nreduces as the edges are progressively shrunk, AutoShrink explores more\nflexible search space with even less search time. We evaluate AutoShrink on\nimage classification and language tasks by crafting ShrinkCNN and ShrinkRNN\nmodels. ShrinkCNN is able to achieve up to 48% parameter reduction and save 34%\nMultiply-Accumulates (MACs) on ImageNet-1K with comparable accuracy of\nstate-of-the-art (SOTA) models. Specifically, both ShrinkCNN and ShrinkRNN are\ncrafted within 1.5 GPU hours, which is 7.2x and 6.7x faster than the crafting\ntime of SOTA CNN and RNN models, respectively.\n", "versions": [{"version": "v1", "created": "Thu, 21 Nov 2019 02:40:00 GMT"}], "update_date": "2020-03-04", "authors_parsed": [["Zhang", "Tunhou", ""], ["Cheng", "Hsin-Pai", ""], ["Li", "Zhenwen", ""], ["Yan", "Feng", ""], ["Huang", "Chengyu", ""], ["Li", "Hai", ""], ["Chen", "Yiran", ""]]}, {"id": "1911.09257", "submitter": "Alexander Wong", "authors": "Andrew Hryniowski and Alexander Wong", "title": "DeepLABNet: End-to-end Learning of Deep Radial Basis Networks with Fully\n  Learnable Basis Functions", "comments": "10 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  From fully connected neural networks to convolutional neural networks, the\nlearned parameters within a neural network have been primarily relegated to the\nlinear parameters (e.g., convolutional filters). The non-linear functions\n(e.g., activation functions) have largely remained, with few exceptions in\nrecent years, parameter-less, static throughout training, and seen limited\nvariation in design. Largely ignored by the deep learning community, radial\nbasis function (RBF) networks provide an interesting mechanism for learning\nmore complex non-linear activation functions in addition to the linear\nparameters in a network. However, the interest in RBF networks has waned over\ntime due to the difficulty of integrating RBFs into more complex deep neural\nnetwork architectures in a tractable and stable manner. In this work, we\npresent a novel approach that enables end-to-end learning of deep RBF networks\nwith fully learnable activation basis functions in an automatic and tractable\nmanner. We demonstrate that our approach for enabling the use of learnable\nactivation basis functions in deep neural networks, which we will refer to as\nDeepLABNet, is an effective tool for automated activation function learning\nwithin complex network architectures.\n", "versions": [{"version": "v1", "created": "Thu, 21 Nov 2019 03:06:15 GMT"}], "update_date": "2019-11-22", "authors_parsed": [["Hryniowski", "Andrew", ""], ["Wong", "Alexander", ""]]}, {"id": "1911.09267", "submitter": "Yujun Shen", "authors": "Ceyuan Yang, Yujun Shen, Bolei Zhou", "title": "Semantic Hierarchy Emerges in Deep Generative Representations for Scene\n  Synthesis", "comments": "15 pages, 20 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.GR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Despite the success of Generative Adversarial Networks (GANs) in image\nsynthesis, there lacks enough understanding on what generative models have\nlearned inside the deep generative representations and how photo-realistic\nimages are able to be composed of the layer-wise stochasticity introduced in\nrecent GANs. In this work, we show that highly-structured semantic hierarchy\nemerges as variation factors from synthesizing scenes from the generative\nrepresentations in state-of-the-art GAN models, like StyleGAN and BigGAN. By\nprobing the layer-wise representations with a broad set of semantics at\ndifferent abstraction levels, we are able to quantify the causality between the\nactivations and semantics occurring in the output image. Such a quantification\nidentifies the human-understandable variation factors learned by GANs to\ncompose scenes. The qualitative and quantitative results further suggest that\nthe generative representations learned by the GANs with layer-wise latent codes\nare specialized to synthesize different hierarchical semantics: the early\nlayers tend to determine the spatial layout and configuration, the middle\nlayers control the categorical objects, and the later layers finally render the\nscene attributes as well as color scheme. Identifying such a set of\nmanipulatable latent variation factors facilitates semantic scene manipulation.\n", "versions": [{"version": "v1", "created": "Thu, 21 Nov 2019 03:26:15 GMT"}, {"version": "v2", "created": "Fri, 29 Nov 2019 02:12:56 GMT"}, {"version": "v3", "created": "Tue, 11 Feb 2020 05:49:15 GMT"}], "update_date": "2020-02-12", "authors_parsed": [["Yang", "Ceyuan", ""], ["Shen", "Yujun", ""], ["Zhou", "Bolei", ""]]}, {"id": "1911.09272", "submitter": "Alexander Levine", "authors": "Alexander Levine, Soheil Feizi", "title": "Robustness Certificates for Sparse Adversarial Attacks by Randomized\n  Ablation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recently, techniques have been developed to provably guarantee the robustness\nof a classifier to adversarial perturbations of bounded L_1 and L_2 magnitudes\nby using randomized smoothing: the robust classification is a consensus of base\nclassifications on randomly noised samples where the noise is additive. In this\npaper, we extend this technique to the L_0 threat model. We propose an\nefficient and certifiably robust defense against sparse adversarial attacks by\nrandomly ablating input features, rather than using additive noise.\nExperimentally, on MNIST, we can certify the classifications of over 50% of\nimages to be robust to any distortion of at most 8 pixels. This is comparable\nto the observed empirical robustness of unprotected classifiers on MNIST to\nmodern L_0 attacks, demonstrating the tightness of the proposed robustness\ncertificate. We also evaluate our certificate on ImageNet and CIFAR-10. Our\ncertificates represent an improvement on those provided in a concurrent work\n(Lee et al. 2019) which uses random noise rather than ablation (median\ncertificates of 8 pixels versus 4 pixels on MNIST; 16 pixels versus 1 pixel on\nImageNet.) Additionally, we empirically demonstrate that our classifier is\nhighly robust to modern sparse adversarial attacks on MNIST. Our\nclassifications are robust, in median, to adversarial perturbations of up to 31\npixels, compared to 22 pixels reported as the state-of-the-art defense, at the\ncost of a slight decrease (around 2.3%) in the classification accuracy. Code is\navailable at https://github.com/alevine0/randomizedAblation/.\n", "versions": [{"version": "v1", "created": "Thu, 21 Nov 2019 03:52:32 GMT"}], "update_date": "2019-11-22", "authors_parsed": [["Levine", "Alexander", ""], ["Feizi", "Soheil", ""]]}, {"id": "1911.09273", "submitter": "Zihan Liu", "authors": "Zihan Liu, Genta Indra Winata, Zhaojiang Lin, Peng Xu, Pascale Fung", "title": "Attention-Informed Mixed-Language Training for Zero-shot Cross-lingual\n  Task-oriented Dialogue Systems", "comments": "Accepted as an oral presentation in AAAI 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recently, data-driven task-oriented dialogue systems have achieved promising\nperformance in English. However, developing dialogue systems that support\nlow-resource languages remains a long-standing challenge due to the absence of\nhigh-quality data. In order to circumvent the expensive and time-consuming data\ncollection, we introduce Attention-Informed Mixed-Language Training (MLT), a\nnovel zero-shot adaptation method for cross-lingual task-oriented dialogue\nsystems. It leverages very few task-related parallel word pairs to generate\ncode-switching sentences for learning the inter-lingual semantics across\nlanguages. Instead of manually selecting the word pairs, we propose to extract\nsource words based on the scores computed by the attention layer of a trained\nEnglish task-related model and then generate word pairs using existing\nbilingual dictionaries. Furthermore, intensive experiments with different\ncross-lingual embeddings demonstrate the effectiveness of our approach.\nFinally, with very few word pairs, our model achieves significant zero-shot\nadaptation performance improvements in both cross-lingual dialogue state\ntracking and natural language understanding (i.e., intent detection and slot\nfilling) tasks compared to the current state-of-the-art approaches, which\nutilize a much larger amount of bilingual data.\n", "versions": [{"version": "v1", "created": "Thu, 21 Nov 2019 03:52:50 GMT"}], "update_date": "2019-11-22", "authors_parsed": [["Liu", "Zihan", ""], ["Winata", "Genta Indra", ""], ["Lin", "Zhaojiang", ""], ["Xu", "Peng", ""], ["Fung", "Pascale", ""]]}, {"id": "1911.09275", "submitter": "Hengshu Zhu", "authors": "Dazhong Shen, Qi Zhang, Tong Xu, Hengshu Zhu, Wenjia Zhao, Zikai Yin,\n  Peilun Zhou, Lihua Fang, Enhong Chen, Hui Xiong", "title": "A Machine Learning-enhanced Robust P-Phase Picker for Real-time Seismic\n  Monitoring", "comments": "Note that this paper is the English version of our work published in\n  SCIENTIA SINICA Informationis\n  (http://engine.scichina.com/doi/10.1360/SSI-2020-0214), which is suggested to\n  be cited if needed", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.SP cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Identifying the arrival times of seismic P-phases plays a significant role in\nreal-time seismic monitoring, which provides critical guidance for emergency\nresponse activities. While considerable research has been conducted on this\ntopic, efficiently capturing the arrival times of seismic P-phases hidden\nwithin intensively distributed and noisy seismic waves, such as those generated\nby the aftershocks of destructive earthquakes, remains a real challenge since\nmost common existing methods in seismology rely on laborious expert\nsupervision. To this end, in this paper, we present a machine learning-enhanced\nframework based on ensemble learning strategy, EL-Picker, for the automatic\nidentification of seismic P-phase arrivals on continuous and massive waveforms.\nMore specifically, EL-Picker consists of three modules, namely, Trigger,\nClassifier, and Refiner, and an ensemble learning strategy is exploited to\nintegrate several machine learning classifiers. An evaluation of the\naftershocks following the MS 8.0 Wenchuan earthquake demonstrates that\nEL-Picker can not only achieve the best identification performance but also\nidentify 120% more seismic P-phase arrivals as complementary data. Meanwhile,\nexperimental results also reveal both the applicability of different machine\nlearning models for waveforms collected from different seismic stations and the\nregularities of seismic P-phase arrivals that might be neglected during manual\ninspection. These findings clearly validate the effectiveness, efficiency,\nflexibility and stability of EL-Picker.\n", "versions": [{"version": "v1", "created": "Thu, 21 Nov 2019 04:03:03 GMT"}, {"version": "v2", "created": "Wed, 19 Aug 2020 09:12:04 GMT"}, {"version": "v3", "created": "Thu, 20 Aug 2020 07:28:25 GMT"}], "update_date": "2020-08-21", "authors_parsed": [["Shen", "Dazhong", ""], ["Zhang", "Qi", ""], ["Xu", "Tong", ""], ["Zhu", "Hengshu", ""], ["Zhao", "Wenjia", ""], ["Yin", "Zikai", ""], ["Zhou", "Peilun", ""], ["Fang", "Lihua", ""], ["Chen", "Enhong", ""], ["Xiong", "Hui", ""]]}, {"id": "1911.09281", "submitter": "Abhijit Suprem", "authors": "Abhijit Suprem and Calton Pu", "title": "Event Detection in Noisy Streaming Data with Combination of\n  Corroborative and Probabilistic Sources", "comments": null, "journal-ref": "IEEE Collaboration in Computing 2019", "doi": null, "report-no": null, "categories": "cs.LG cs.SI cs.SY eess.SY stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Global physical event detection has traditionally relied on dense coverage of\nphysical sensors around the world; while this is an expensive undertaking,\nthere have not been alternatives until recently. The ubiquity of social\nnetworks and human sensors in the field provides a tremendous amount of\nreal-time, live data about true physical events from around the world. However,\nwhile such human sensor data have been exploited for retrospective large-scale\nevent detection, such as hurricanes or earthquakes, they has been limited to no\nsuccess in exploiting this rich resource for general physical event detection.\n  Prior implementation approaches have suffered from the concept drift\nphenomenon, where real-world data exhibits constant, unknown, unbounded changes\nin its data distribution, making static machine learning models ineffective in\nthe long term. We propose and implement an end-to-end collaborative drift\nadaptive system that integrates corroborative and probabilistic sources to\ndeliver real-time predictions. Furthermore, out system is adaptive to concept\ndrift and performs automated continuous learning to maintain high performance.\nWe demonstrate our approach in a real-time demo available online for landslide\ndisaster detection, with extensibility to other real-world physical events such\nas flooding, wildfires, hurricanes, and earthquakes.\n", "versions": [{"version": "v1", "created": "Thu, 21 Nov 2019 04:19:16 GMT"}], "update_date": "2019-12-16", "authors_parsed": [["Suprem", "Abhijit", ""], ["Pu", "Calton", ""]]}, {"id": "1911.09287", "submitter": "Adam Dziedzic", "authors": "Adam Dziedzic and John Paparrizos and Sanjay Krishnan and Aaron Elmore\n  and Michael Franklin", "title": "Band-limited Training and Inference for Convolutional Neural Networks", "comments": "Published at International Conference on Machine Learning (ICML)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The convolutional layers are core building blocks of neural network\narchitectures. In general, a convolutional filter applies to the entire\nfrequency spectrum of the input data. We explore artificially constraining the\nfrequency spectra of these filters and data, called band-limiting, during\ntraining. The frequency domain constraints apply to both the feed-forward and\nback-propagation steps. Experimentally, we observe that Convolutional Neural\nNetworks (CNNs) are resilient to this compression scheme and results suggest\nthat CNNs learn to leverage lower-frequency components. In particular, we\nfound: (1) band-limited training can effectively control the resource usage\n(GPU and memory); (2) models trained with band-limited layers retain high\nprediction accuracy; and (3) requires no modification to existing training\nalgorithms or neural network architectures to use unlike other compression\nschemes.\n", "versions": [{"version": "v1", "created": "Thu, 21 Nov 2019 04:43:02 GMT"}], "update_date": "2019-11-22", "authors_parsed": [["Dziedzic", "Adam", ""], ["Paparrizos", "John", ""], ["Krishnan", "Sanjay", ""], ["Elmore", "Aaron", ""], ["Franklin", "Michael", ""]]}, {"id": "1911.09290", "submitter": "Zhao Kang", "authors": "Zhao Kang, Wangtao Zhou, Zhitong Zhao, Junming Shao, Meng Han, Zenglin\n  Xu", "title": "Large-scale Multi-view Subspace Clustering in Linear Time", "comments": "Accepted by AAAI 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A plethora of multi-view subspace clustering (MVSC) methods have been\nproposed over the past few years. Researchers manage to boost clustering\naccuracy from different points of view. However, many state-of-the-art MVSC\nalgorithms, typically have a quadratic or even cubic complexity, are\ninefficient and inherently difficult to apply at large scales. In the era of\nbig data, the computational issue becomes critical. To fill this gap, we\npropose a large-scale MVSC (LMVSC) algorithm with linear order complexity.\nInspired by the idea of anchor graph, we first learn a smaller graph for each\nview. Then, a novel approach is designed to integrate those graphs so that we\ncan implement spectral clustering on a smaller graph. Interestingly, it turns\nout that our model also applies to single-view scenario. Extensive experiments\non various large-scale benchmark data sets validate the effectiveness and\nefficiency of our approach with respect to state-of-the-art clustering methods.\n", "versions": [{"version": "v1", "created": "Thu, 21 Nov 2019 05:10:29 GMT"}], "update_date": "2019-11-22", "authors_parsed": [["Kang", "Zhao", ""], ["Zhou", "Wangtao", ""], ["Zhao", "Zhitong", ""], ["Shao", "Junming", ""], ["Han", "Meng", ""], ["Xu", "Zenglin", ""]]}, {"id": "1911.09291", "submitter": "Pablo Samuel Castro", "authors": "Pablo Samuel Castro", "title": "Scalable methods for computing state similarity in deterministic Markov\n  Decision Processes", "comments": "To appear in Proceedings of the Thirty-Fourth AAAI Conference on\n  Artificial Intelligence (AAAI-20)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present new algorithms for computing and approximating bisimulation\nmetrics in Markov Decision Processes (MDPs). Bisimulation metrics are an\nelegant formalism that capture behavioral equivalence between states and\nprovide strong theoretical guarantees on differences in optimal behaviour.\nUnfortunately, their computation is expensive and requires a tabular\nrepresentation of the states, which has thus far rendered them impractical for\nlarge problems. In this paper we present a new version of the metric that is\ntied to a behavior policy in an MDP, along with an analysis of its theoretical\nproperties. We then present two new algorithms for approximating bisimulation\nmetrics in large, deterministic MDPs. The first does so via sampling and is\nguaranteed to converge to the true metric. The second is a differentiable loss\nwhich allows us to learn an approximation even for continuous state MDPs, which\nprior to this work had not been possible.\n", "versions": [{"version": "v1", "created": "Thu, 21 Nov 2019 05:11:20 GMT"}], "update_date": "2019-11-22", "authors_parsed": [["Castro", "Pablo Samuel", ""]]}, {"id": "1911.09292", "submitter": "Adam Dziedzic", "authors": "Vanlin Sathya, Adam Dziedzic, Monisha Ghosh, Sanjay Krishnan", "title": "Machine Learning based detection of multiple Wi-Fi BSSs for LTE-U CSAT", "comments": "Published at International Conference on Computing, Networking and\n  Communications (ICNC 2020)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  According to the LTE-U Forum specification, a LTE-U base-station (BS) reduces\nits duty cycle from 50% to 33% when it senses an increase in the number of\nco-channel Wi-Fi basic service sets (BSSs) from one to two. The detection of\nthe number of Wi-Fi BSSs that are operating on the channel in real-time,\nwithout decoding the Wi-Fi packets, still remains a challenge. In this paper,\nwe present a novel machine learning (ML) approach that solves the problem by\nusing energy values observed during LTE-U OFF duration. Observing the energy\nvalues (at LTE-U BS OFF time) is a much simpler operation than decoding the\nentire Wi-Fi packets. In this work, we implement and validate the proposed ML\nbased approach in real-time experiments, and demonstrate that there are two\ndistinct patterns between one and two Wi-Fi APs. This approach delivers an\naccuracy close to 100% compared to auto-correlation (AC) and energy detection\n(ED) approaches.\n", "versions": [{"version": "v1", "created": "Thu, 21 Nov 2019 05:14:05 GMT"}], "update_date": "2019-11-22", "authors_parsed": [["Sathya", "Vanlin", ""], ["Dziedzic", "Adam", ""], ["Ghosh", "Monisha", ""], ["Krishnan", "Sanjay", ""]]}, {"id": "1911.09298", "submitter": "Ligong Han", "authors": "Ligong Han, Ruijiang Gao, Mun Kim, Xin Tao, Bo Liu, Dimitris Metaxas", "title": "Robust Conditional GAN from Uncertainty-Aware Pairwise Comparisons", "comments": "Accepted for spotlight at AAAI-20", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Conditional generative adversarial networks have shown exceptional generation\nperformance over the past few years. However, they require large numbers of\nannotations. To address this problem, we propose a novel generative adversarial\nnetwork utilizing weak supervision in the form of pairwise comparisons (PC-GAN)\nfor image attribute editing. In the light of Bayesian uncertainty estimation\nand noise-tolerant adversarial training, PC-GAN can estimate attribute rating\nefficiently and demonstrate robust performance in noise resistance. Through\nextensive experiments, we show both qualitatively and quantitatively that\nPC-GAN performs comparably with fully-supervised methods and outperforms\nunsupervised baselines.\n", "versions": [{"version": "v1", "created": "Thu, 21 Nov 2019 05:37:46 GMT"}, {"version": "v2", "created": "Thu, 5 Mar 2020 00:08:23 GMT"}], "update_date": "2020-03-06", "authors_parsed": [["Han", "Ligong", ""], ["Gao", "Ruijiang", ""], ["Kim", "Mun", ""], ["Tao", "Xin", ""], ["Liu", "Bo", ""], ["Metaxas", "Dimitris", ""]]}, {"id": "1911.09307", "submitter": "Ke Sun", "authors": "Ke Sun, Bing Yu, Zhouchen Lin, Zhanxing Zhu", "title": "Patch-level Neighborhood Interpolation: A General and Effective\n  Graph-based Regularization Strategy", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Regularization plays a crucial role in machine learning models, especially\nfor deep neural networks. The existing regularization techniques mainly reply\non the i.i.d. assumption and only employ the information of the current sample,\nwithout the leverage of neighboring information between samples. In this work,\nwe propose a general regularizer called Patch-level Neighborhood\nInterpolation~(\\textbf{Pani}) that fully exploits the relationship between\nsamples. Furthermore, by explicitly constructing a patch-level graph in the\ndifferent network layers and interpolating the neighborhood features to refine\nthe representation of the current sample, our Patch-level Neighborhood\nInterpolation can then be applied to enhance two popular regularization\nstrategies, namely Virtual Adversarial Training (VAT) and MixUp, yielding their\nneighborhood versions. The first derived \\textbf{Pani VAT} presents a novel way\nto construct non-local adversarial smoothness by incorporating patch-level\ninterpolated perturbations. In addition, the \\textbf{Pani MixUp} method extends\nthe original MixUp regularization to the patch level and then can be developed\nto MixMatch, achieving the state-of-the-art performance. Finally, extensive\nexperiments are conducted to verify the effectiveness of the Patch-level\nNeighborhood Interpolation in both supervised and semi-supervised settings.\n", "versions": [{"version": "v1", "created": "Thu, 21 Nov 2019 06:31:59 GMT"}], "update_date": "2019-11-22", "authors_parsed": [["Sun", "Ke", ""], ["Yu", "Bing", ""], ["Lin", "Zhouchen", ""], ["Zhu", "Zhanxing", ""]]}, {"id": "1911.09309", "submitter": "Zhijie Chen", "authors": "Zhijie Chen, Junchi Yan, Longyuan Li and Xiaokang Yang", "title": "Decoding Spiking Mechanism with Dynamic Learning on Neuron Population", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.NC cs.LG cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A main concern in cognitive neuroscience is to decode the overt neural spike\ntrain observations and infer latent representations under neural circuits.\nHowever, traditional methods entail strong prior on network structure and\nhardly meet the demand for real spike data. Here we propose a novel neural\nnetwork approach called Neuron Activation Network that extracts neural\ninformation explicitly from single trial neuron population spike trains. Our\nproposed method consists of a spatiotemporal learning procedure on sensory\nenvironment and a message passing mechanism on population graph, followed by a\nneuron activation process in a recursive fashion. Our model is aimed to\nreconstruct neuron information while inferring representations of neuron\nspiking states. We apply our model to retinal ganglion cells and the\nexperimental results suggest that our model holds a more potent capability in\ngenerating neural spike sequences with high fidelity than the state-of-the-art\nmethods, as well as being more expressive and having potential to disclose\nlatent spiking mechanism. The source code will be released with the final\npaper.\n", "versions": [{"version": "v1", "created": "Thu, 21 Nov 2019 06:56:57 GMT"}], "update_date": "2019-11-22", "authors_parsed": [["Chen", "Zhijie", ""], ["Yan", "Junchi", ""], ["Li", "Longyuan", ""], ["Yang", "Xiaokang", ""]]}, {"id": "1911.09310", "submitter": "Lantao Yu", "authors": "Yuxuan Song, Lantao Yu, Zhangjie Cao, Zhiming Zhou, Jian Shen, Shuo\n  Shao, Weinan Zhang, Yong Yu", "title": "Improving Unsupervised Domain Adaptation with Variational Information\n  Bottleneck", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Domain adaptation aims to leverage the supervision signal of source domain to\nobtain an accurate model for target domain, where the labels are not available.\nTo leverage and adapt the label information from source domain, most existing\nmethods employ a feature extracting function and match the marginal\ndistributions of source and target domains in a shared feature space. In this\npaper, from the perspective of information theory, we show that representation\nmatching is actually an insufficient constraint on the feature space for\nobtaining a model with good generalization performance in target domain. We\nthen propose variational bottleneck domain adaptation (VBDA), a new domain\nadaptation method which improves feature transferability by explicitly\nenforcing the feature extractor to ignore the task-irrelevant factors and focus\non the information that is essential to the task of interest for both source\nand target domains. Extensive experimental results demonstrate that VBDA\nsignificantly outperforms state-of-the-art methods across three domain\nadaptation benchmark datasets.\n", "versions": [{"version": "v1", "created": "Thu, 21 Nov 2019 07:07:17 GMT"}], "update_date": "2019-11-22", "authors_parsed": [["Song", "Yuxuan", ""], ["Yu", "Lantao", ""], ["Cao", "Zhangjie", ""], ["Zhou", "Zhiming", ""], ["Shen", "Jian", ""], ["Shao", "Shuo", ""], ["Zhang", "Weinan", ""], ["Yu", "Yong", ""]]}, {"id": "1911.09315", "submitter": "Alberto Barbado Gonzalez", "authors": "Alberto Barbado, \\'Oscar Corcho, Richard Benjamins", "title": "Rule Extraction in Unsupervised Anomaly Detection for Model\n  Explainability: Application to OneClass SVM", "comments": "23 pages, 18 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://creativecommons.org/licenses/by-sa/4.0/", "abstract": "  OneClass SVM is a popular method for unsupervised anomaly detection. As many\nother methods, it suffers from the black box problem: it is difficult to\njustify, in an intuitive and simple manner, why the decision frontier is\nidentifying data points as anomalous or non anomalous. Such type of problem is\nbeing widely addressed for supervised models. However, it is still an uncharted\narea for unsupervised learning. In this paper, we evaluate several rule\nextraction techniques over OneClass SVM models, as well as present alternative\ndesigns for some of those algorithms. Together with that, we propose algorithms\nto compute metrics related with eXplainable Artificial Intelligence (XAI)\nregarding the \"comprehensibility\", \"representativeness\", \"stability\" and\n\"diversity\" of the extracted rules. We evaluate our proposals with different\ndatasets, including real-world data coming from industry. With this, our\nproposal contributes to extend XAI techniques to unsupervised machine learning\nmodels.\n", "versions": [{"version": "v1", "created": "Thu, 21 Nov 2019 07:14:43 GMT"}, {"version": "v2", "created": "Wed, 1 Apr 2020 11:10:00 GMT"}, {"version": "v3", "created": "Sat, 6 Jun 2020 09:21:27 GMT"}, {"version": "v4", "created": "Mon, 29 Jun 2020 07:07:28 GMT"}, {"version": "v5", "created": "Thu, 1 Apr 2021 08:24:04 GMT"}], "update_date": "2021-04-02", "authors_parsed": [["Barbado", "Alberto", ""], ["Corcho", "\u00d3scar", ""], ["Benjamins", "Richard", ""]]}, {"id": "1911.09320", "submitter": "Chenze Shao", "authors": "Chenze Shao, Jinchao Zhang, Yang Feng, Fandong Meng and Jie Zhou", "title": "Minimizing the Bag-of-Ngrams Difference for Non-Autoregressive Neural\n  Machine Translation", "comments": "AAAI 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Non-Autoregressive Neural Machine Translation (NAT) achieves significant\ndecoding speedup through generating target words independently and\nsimultaneously. However, in the context of non-autoregressive translation, the\nword-level cross-entropy loss cannot model the target-side sequential\ndependency properly, leading to its weak correlation with the translation\nquality. As a result, NAT tends to generate influent translations with\nover-translation and under-translation errors. In this paper, we propose to\ntrain NAT to minimize the Bag-of-Ngrams (BoN) difference between the model\noutput and the reference sentence. The bag-of-ngrams training objective is\ndifferentiable and can be efficiently calculated, which encourages NAT to\ncapture the target-side sequential dependency and correlates well with the\ntranslation quality. We validate our approach on three translation tasks and\nshow that our approach largely outperforms the NAT baseline by about 5.0 BLEU\nscores on WMT14 En$\\leftrightarrow$De and about 2.5 BLEU scores on WMT16\nEn$\\leftrightarrow$Ro.\n", "versions": [{"version": "v1", "created": "Thu, 21 Nov 2019 07:26:05 GMT"}], "update_date": "2019-11-22", "authors_parsed": [["Shao", "Chenze", ""], ["Zhang", "Jinchao", ""], ["Feng", "Yang", ""], ["Meng", "Fandong", ""], ["Zhou", "Jie", ""]]}, {"id": "1911.09322", "submitter": "Minje Park", "authors": "Minje Park", "title": "Data Proxy Generation for Fast and Efficient Neural Architecture Search", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Due to the recent advances on Neural Architecture Search (NAS), it gains\npopularity in designing best networks for specific tasks. Although it shows\npromising results on many benchmarks and competitions, NAS still suffers from\nits demanding computation cost for searching high dimensional architectural\ndesign space, and this problem becomes even worse when we want to use a\nlarge-scale dataset. If we can make a reliable data proxy for NAS, the\nefficiency of NAS approaches increase accordingly. Our basic observation for\nmaking a data proxy is that each example in a specific dataset has a different\nimpact on NAS process and most of examples are redundant from a relative\naccuracy ranking perspective, which we should preserve when making a data\nproxy. We propose a systematic approach to measure the importance of each\nexample from this relative accuracy ranking point of view, and make a reliable\ndata proxy based on the statistics of training and testing examples. Our\nexperiment shows that we can preserve the almost same relative accuracy ranking\nbetween all possible network configurations even with 10-20$\\times$ smaller\ndata proxy.\n", "versions": [{"version": "v1", "created": "Thu, 21 Nov 2019 07:39:57 GMT"}], "update_date": "2019-11-22", "authors_parsed": [["Park", "Minje", ""]]}, {"id": "1911.09334", "submitter": "Tianyi Li", "authors": "Tianyi Li, Sujian Li", "title": "Incorporating Textual Evidence in Visual Storytelling", "comments": null, "journal-ref": "In Proceeding of DSNNLG 2019", "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Previous work on visual storytelling mainly focused on exploring image\nsequence as evidence for storytelling and neglected textual evidence for\nguiding story generation. Motivated by human storytelling process which recalls\nstories for familiar images, we exploit textual evidence from similar images to\nhelp generate coherent and meaningful stories. To pick the images which may\nprovide textual experience, we propose a two-step ranking method based on image\nobject recognition techniques. To utilize textual information, we design an\nextended Seq2Seq model with two-channel encoder and attention. Experiments on\nthe VIST dataset show that our method outperforms state-of-the-art baseline\nmodels without heavy engineering.\n", "versions": [{"version": "v1", "created": "Thu, 21 Nov 2019 08:22:37 GMT"}], "update_date": "2019-11-26", "authors_parsed": [["Li", "Tianyi", ""], ["Li", "Sujian", ""]]}, {"id": "1911.09336", "submitter": "Han Shi", "authors": "Han Shi, Renjie Pi, Hang Xu, Zhenguo Li, James T. Kwok, Tong Zhang", "title": "Bridging the Gap between Sample-based and One-shot Neural Architecture\n  Search with BONAS", "comments": "Accepted by NeurIPS 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Neural Architecture Search (NAS) has shown great potentials in finding better\nneural network designs. Sample-based NAS is the most reliable approach which\naims at exploring the search space and evaluating the most promising\narchitectures. However, it is computationally very costly. As a remedy, the\none-shot approach has emerged as a popular technique for accelerating NAS using\nweight-sharing. However, due to the weight-sharing of vastly different\nnetworks, the one-shot approach is less reliable than the sample-based\napproach. In this work, we propose BONAS (Bayesian Optimized Neural\nArchitecture Search), a sample-based NAS framework which is accelerated using\nweight-sharing to evaluate multiple related architectures simultaneously.\nSpecifically, we apply Graph Convolutional Network predictor as a surrogate\nmodel for Bayesian Optimization to select multiple related candidate models in\neach iteration. We then apply weight-sharing to train multiple candidate models\nsimultaneously. This approach not only accelerates the traditional sample-based\napproach significantly, but also keeps its reliability. This is because\nweight-sharing among related architectures are more reliable than those in the\none-shot approach. Extensive experiments are conducted to verify the\neffectiveness of our method over many competing algorithms.\n", "versions": [{"version": "v1", "created": "Thu, 21 Nov 2019 08:29:00 GMT"}, {"version": "v2", "created": "Thu, 5 Mar 2020 09:23:45 GMT"}, {"version": "v3", "created": "Fri, 23 Oct 2020 03:47:56 GMT"}, {"version": "v4", "created": "Wed, 25 Nov 2020 02:13:43 GMT"}], "update_date": "2020-11-26", "authors_parsed": [["Shi", "Han", ""], ["Pi", "Renjie", ""], ["Xu", "Hang", ""], ["Li", "Zhenguo", ""], ["Kwok", "James T.", ""], ["Zhang", "Tong", ""]]}, {"id": "1911.09344", "submitter": "Weizhu Qian", "authors": "Weizhu Qian, Fabrice Lauri, Franck Gechter", "title": "Convolutional Mixture Density Recurrent Neural Network for Predicting\n  User Location with WiFi Fingerprints", "comments": "5 pages, 3 figures, conference paper", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG eess.SP stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Predicting smartphone users activity using WiFi fingerprints has been a\npopular approach for indoor positioning in recent years. However, such a high\ndimensional time-series prediction problem can be very tricky to solve. To\naddress this issue, we propose a novel deep learning model, the convolutional\nmixture density recurrent neural network (CMDRNN), which combines the strengths\nof convolutional neural networks, recurrent neural networks and mixture density\nnetworks. In our model, the CNN sub-model is employed to detect the feature of\nthe high dimensional input, the RNN sub-model is utilized to capture the time\ndependency and the MDN sub-model is for predicting the final output. For\nvalidation, we conduct the experiments on the real-world dataset and the\nobtained results illustrate the effectiveness of our method.\n", "versions": [{"version": "v1", "created": "Thu, 21 Nov 2019 08:47:00 GMT"}], "update_date": "2019-11-22", "authors_parsed": [["Qian", "Weizhu", ""], ["Lauri", "Fabrice", ""], ["Gechter", "Franck", ""]]}, {"id": "1911.09345", "submitter": "Naveed Akhtar Dr.", "authors": "Nayyer Aafaq, Naveed Akhtar, Wei Liu, Ajmal Mian", "title": "Empirical Autopsy of Deep Video Captioning Frameworks", "comments": "09 pages, 05 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Contemporary deep learning based video captioning follows encoder-decoder\nframework. In encoder, visual features are extracted with 2D/3D Convolutional\nNeural Networks (CNNs) and a transformed version of those features is passed to\nthe decoder. The decoder uses word embeddings and a language model to map\nvisual features to natural language captions. Due to its composite nature, the\nencoder-decoder pipeline provides the freedom of multiple choices for each of\nits components, e.g the choices of CNNs models, feature transformations, word\nembeddings, and language models etc. Component selection can have drastic\neffects on the overall video captioning performance. However, current\nliterature is void of any systematic investigation in this regard. This article\nfills this gap by providing the first thorough empirical analysis of the role\nthat each major component plays in a contemporary video captioning pipeline. We\nperform extensive experiments by varying the constituent components of the\nvideo captioning framework, and quantify the performance gains that are\npossible by mere component selection. We use the popular MSVD dataset as the\ntest-bed, and demonstrate that substantial performance gains are possible by\ncareful selection of the constituent components without major changes to the\npipeline itself. These results are expected to provide guiding principles for\nfuture research in the fast growing direction of video captioning.\n", "versions": [{"version": "v1", "created": "Thu, 21 Nov 2019 08:47:36 GMT"}], "update_date": "2019-11-22", "authors_parsed": [["Aafaq", "Nayyer", ""], ["Akhtar", "Naveed", ""], ["Liu", "Wei", ""], ["Mian", "Ajmal", ""]]}, {"id": "1911.09349", "submitter": "Di Xie", "authors": "Jiaxu Chen and Jing Hao and Kai Chen and Di Xie and Shicai Yang and\n  Shiliang Pu", "title": "An End-to-End Audio Classification System based on Raw Waveforms and\n  Mix-Training Strategy", "comments": "InterSpeech 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.AS cs.CV cs.LG cs.MM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Audio classification can distinguish different kinds of sounds, which is\nhelpful for intelligent applications in daily life. However, it remains a\nchallenging task since the sound events in an audio clip is probably multiple,\neven overlapping. This paper introduces an end-to-end audio classification\nsystem based on raw waveforms and mix-training strategy. Compared to\nhuman-designed features which have been widely used in existing research, raw\nwaveforms contain more complete information and are more appropriate for\nmulti-label classification. Taking raw waveforms as input, our network consists\nof two variants of ResNet structure which can learn a discriminative\nrepresentation. To explore the information in intermediate layers, a\nmulti-level prediction with attention structure is applied in our model.\nFurthermore, we design a mix-training strategy to break the performance\nlimitation caused by the amount of training data. Experiments show that the\nmean average precision of the proposed audio classification system on Audio Set\ndataset is 37.2%. Without using extra training data, our system exceeds the\nstate-of-the-art multi-level attention model.\n", "versions": [{"version": "v1", "created": "Thu, 21 Nov 2019 08:54:48 GMT"}], "update_date": "2019-11-22", "authors_parsed": [["Chen", "Jiaxu", ""], ["Hao", "Jing", ""], ["Chen", "Kai", ""], ["Xie", "Di", ""], ["Yang", "Shicai", ""], ["Pu", "Shiliang", ""]]}, {"id": "1911.09355", "submitter": "Weizhu Qian", "authors": "Weizhu Qian, Fabrice Lauri, Franck Gechter", "title": "A Probabilistic Approach for Discovering Daily Human Mobility Patterns\n  with Mobile Data", "comments": "10 pages, 14 figures, journal paper", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI eess.SP stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Discovering human mobility patterns with geo-location data collected from\nsmartphone users has been a hot research topic in recent years. In this paper,\nwe attempt to discover daily mobile patterns based on GPS data. We view this\nproblem from a probabilistic perspective in order to explore more information\nfrom the original GPS data compared to other conventional methods. A\nnon-parameter Bayesian modeling method, Infinite Gaussian Mixture Model, is\nused to estimate the probability density for the daily mobility. Then, we use\nKullback-Leibler divergence as the metrics to measure the similarity of\ndifferent probability distributions. And combining Infinite Gaussian Mixture\nModel and Kullback-Leibler divergence, we derived an automatic clustering\nalgorithm to discover mobility patterns for each individual user without\nsetting the number of clusters in advance. In the experiments, the\neffectiveness of our method is validated on the real user data collected from\ndifferent users. The results show that the IGMM-based algorithm outperforms the\nGMM-based algorithm. We also test our methods on the dataset with different\nlengths to discover the minimum data length for discovering mobility patterns.\n", "versions": [{"version": "v1", "created": "Thu, 21 Nov 2019 09:17:32 GMT"}], "update_date": "2020-07-02", "authors_parsed": [["Qian", "Weizhu", ""], ["Lauri", "Fabrice", ""], ["Gechter", "Franck", ""]]}, {"id": "1911.09359", "submitter": "Guang Liu", "authors": "Liu Guang and Wang Xiaojie and Li Ruifan", "title": "Multi-Scale RCNN Model for Financial Time-series Classification", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG q-fin.CP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Financial time-series classification (FTC) is extremely valuable for\ninvestment management. In past decades, it draws a lot of attention from a wide\nextent of research areas, especially Artificial Intelligence (AI). Existing\nresearches majorly focused on exploring the effects of the Multi-Scale (MS)\nproperty or the Temporal Dependency (TD) within financial time-series.\nUnfortunately, most previous researches fail to combine these two properties\neffectively and often fall short of accuracy and profitability. To effectively\ncombine and utilize both properties of financial time-series, we propose a\nMulti-Scale Temporal Dependent Recurrent Convolutional Neural Network\n(MSTD-RCNN) for FTC. In the proposed method, the MS features are simultaneously\nextracted by convolutional units to precisely describe the state of the\nfinancial market. Moreover, the TD and complementary across different scales\nare captured through a Recurrent Neural Network. The proposed method is\nevaluated on three financial time-series datasets which source from the Chinese\nstock market. Extensive experimental results indicate that our model achieves\nthe state-of-the-art performance in trend classification and simulated trading,\ncompared with classical and advanced baseline models.\n", "versions": [{"version": "v1", "created": "Thu, 21 Nov 2019 09:32:20 GMT"}], "update_date": "2019-11-22", "authors_parsed": [["Guang", "Liu", ""], ["Xiaojie", "Wang", ""], ["Ruifan", "Li", ""]]}, {"id": "1911.09373", "submitter": "Zeyi Wen", "authors": "Zeyi Wen, Zeyu Huang and Rui Zhang", "title": "Entity Extraction with Knowledge from Web Scale Corpora", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.DB cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Entity extraction is an important task in text mining and natural language\nprocessing. A popular method for entity extraction is by comparing substrings\nfrom free text against a dictionary of entities. In this paper, we present\nseveral techniques as a post-processing step for improving the effectiveness of\nthe existing entity extraction technique. These techniques utilise models\ntrained with the web-scale corpora which makes our techniques robust and\nversatile. Experiments show that our techniques bring a notable improvement on\nefficiency and effectiveness.\n", "versions": [{"version": "v1", "created": "Thu, 21 Nov 2019 10:01:16 GMT"}], "update_date": "2019-11-22", "authors_parsed": [["Wen", "Zeyi", ""], ["Huang", "Zeyu", ""], ["Zhang", "Rui", ""]]}, {"id": "1911.09375", "submitter": "Monika Sharma", "authors": "Monika Sharma, Shikha Gupta, Arindam Chowdhury, Lovekesh Vig", "title": "ChartNet: Visual Reasoning over Statistical Charts using MAC-Networks", "comments": null, "journal-ref": "International Joint Conference on Neural Networks (IJCNN) 2019", "doi": "10.1109/IJCNN.2019.8852427", "report-no": null, "categories": "cs.CV cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Despite the improvements in perception accuracies brought about via deep\nlearning, developing systems combining accurate visual perception with the\nability to reason over the visual percepts remains extremely challenging. A\nparticular application area of interest from an accessibility perspective is\nthat of reasoning over statistical charts such as bar and pie charts. To this\nend, we formulate the problem of reasoning over statistical charts as a\nclassification task using MAC-Networks to give answers from a predefined\nvocabulary of generic answers. Additionally, we enhance the capabilities of\nMAC-Networks to give chart-specific answers to open-ended questions by\nreplacing the classification layer by a regression layer to localize the\ntextual answers present over the images. We call our network ChartNet, and\ndemonstrate its efficacy on predicting both in vocabulary and out of vocabulary\nanswers. To test our methods, we generated our own dataset of statistical chart\nimages and corresponding question answer pairs. Results show that ChartNet\nconsistently outperform other state-of-the-art methods on reasoning over these\nquestions and may be a viable candidate for applications containing images of\nstatistical charts.\n", "versions": [{"version": "v1", "created": "Thu, 21 Nov 2019 10:03:25 GMT"}], "update_date": "2019-11-22", "authors_parsed": [["Sharma", "Monika", ""], ["Gupta", "Shikha", ""], ["Chowdhury", "Arindam", ""], ["Vig", "Lovekesh", ""]]}, {"id": "1911.09391", "submitter": "Eivind B{\\o}hn", "authors": "Eivind B{\\o}hn, Signe Moe, Tor Arne Johansen", "title": "Accelerating Reinforcement Learning with Suboptimal Guidance", "comments": "Submitted to IFAC 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.RO stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Reinforcement Learning in domains with sparse rewards is a difficult problem,\nand a large part of the training process is often spent searching the state\nspace in a more or less random fashion for any learning signals. For control\nproblems, we often have some controller readily available which might be\nsuboptimal but nevertheless solves the problem to some degree. This controller\ncan be used to guide the initial exploration phase of the learning controller\ntowards reward yielding states, reducing the time before refinement of a viable\npolicy can be initiated. In our work, the agent is guided through an auxiliary\nbehaviour cloning loss which is made conditional on a Q-filter, i.e. it is only\napplied in situations where the critic deems the guiding controller to be\nbetter than the agent. The Q-filter provides a natural way to adjust the\nguidance throughout the training process, allowing the agent to exceed the\nguiding controller in a manner that is adaptive to the task at hand and the\nproficiency of the guiding controller. The contribution of this paper lies in\nidentifying shortcomings in previously proposed implementations of the Q-filter\nconcept, and in suggesting some ways these issues can be mitigated. These\nmodifications are tested on the OpenAI Gym Fetch environments, showing clear\nimprovements in adaptivity and yielding increased performance in all robotic\nenvironments tested.\n", "versions": [{"version": "v1", "created": "Thu, 21 Nov 2019 10:27:46 GMT"}], "update_date": "2019-11-22", "authors_parsed": [["B\u00f8hn", "Eivind", ""], ["Moe", "Signe", ""], ["Johansen", "Tor Arne", ""]]}, {"id": "1911.09411", "submitter": "Anderson Ara", "authors": "Anderson Ara, Mateus Maia, Samuel Mac\\^edo and Francisco Louzada", "title": "Random Machines: A bagged-weighted support vector model with free kernel\n  choice", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Improvement of statistical learning models in order to increase efficiency in\nsolving classification or regression problems is still a goal pursued by the\nscientific community. In this way, the support vector machine model is one of\nthe most successful and powerful algorithms for those tasks. However, its\nperformance depends directly from the choice of the kernel function and their\nhyperparameters. The traditional choice of them, actually, can be\ncomputationally expensive to do the kernel choice and the tuning processes. In\nthis article, it is proposed a novel framework to deal with the kernel function\nselection called Random Machines. The results improved accuracy and reduced\ncomputational time. The data study was performed in simulated data and over 27\nreal benchmarking datasets.\n", "versions": [{"version": "v1", "created": "Thu, 21 Nov 2019 11:11:22 GMT"}], "update_date": "2019-11-22", "authors_parsed": [["Ara", "Anderson", ""], ["Maia", "Mateus", ""], ["Mac\u00eado", "Samuel", ""], ["Louzada", "Francisco", ""]]}, {"id": "1911.09419", "submitter": "Jie Wang", "authors": "Zhanqiu Zhang, Jianyu Cai, Yongdong Zhang, and Jie Wang", "title": "Learning Hierarchy-Aware Knowledge Graph Embeddings for Link Prediction", "comments": "Accepted to AAAI 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CL stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Knowledge graph embedding, which aims to represent entities and relations as\nlow dimensional vectors (or matrices, tensors, etc.), has been shown to be a\npowerful technique for predicting missing links in knowledge graphs. Existing\nknowledge graph embedding models mainly focus on modeling relation patterns\nsuch as symmetry/antisymmetry, inversion, and composition. However, many\nexisting approaches fail to model semantic hierarchies, which are common in\nreal-world applications. To address this challenge, we propose a novel\nknowledge graph embedding model---namely, Hierarchy-Aware Knowledge Graph\nEmbedding (HAKE)---which maps entities into the polar coordinate system. HAKE\nis inspired by the fact that concentric circles in the polar coordinate system\ncan naturally reflect the hierarchy. Specifically, the radial coordinate aims\nto model entities at different levels of the hierarchy, and entities with\nsmaller radii are expected to be at higher levels; the angular coordinate aims\nto distinguish entities at the same level of the hierarchy, and these entities\nare expected to have roughly the same radii but different angles. Experiments\ndemonstrate that HAKE can effectively model the semantic hierarchies in\nknowledge graphs, and significantly outperforms existing state-of-the-art\nmethods on benchmark datasets for the link prediction task.\n", "versions": [{"version": "v1", "created": "Thu, 21 Nov 2019 11:37:18 GMT"}, {"version": "v2", "created": "Wed, 25 Dec 2019 12:31:40 GMT"}], "update_date": "2019-12-30", "authors_parsed": [["Zhang", "Zhanqiu", ""], ["Cai", "Jianyu", ""], ["Zhang", "Yongdong", ""], ["Wang", "Jie", ""]]}, {"id": "1911.09427", "submitter": "Guy Shalev", "authors": "Guy Shalev, Ran El-Yaniv, Daniel Klotz, Frederik Kratzert, Asher\n  Metzger, Sella Nevo", "title": "Accurate Hydrologic Modeling Using Less Information", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Joint models are a common and important tool in the intersection of machine\nlearning and the physical sciences, particularly in contexts where real-world\nmeasurements are scarce. Recent developments in rainfall-runoff modeling, one\nof the prime challenges in hydrology, show the value of a joint model with\nshared representation in this important context. However, current\nstate-of-the-art models depend on detailed and reliable attributes\ncharacterizing each site to help the model differentiate correctly between the\nbehavior of different sites. This dependency can present a challenge in\ndata-poor regions. In this paper, we show that we can replace the need for such\nlocation-specific attributes with a completely data-driven learned embedding,\nand match previous state-of-the-art results with less information.\n", "versions": [{"version": "v1", "created": "Thu, 21 Nov 2019 12:01:19 GMT"}], "update_date": "2019-11-22", "authors_parsed": [["Shalev", "Guy", ""], ["El-Yaniv", "Ran", ""], ["Klotz", "Daniel", ""], ["Kratzert", "Frederik", ""], ["Metzger", "Asher", ""], ["Nevo", "Sella", ""]]}, {"id": "1911.09430", "submitter": "Tao Zhang", "authors": "Tao Zhang, Yang Cong, Gan Sun, Qianqian Wang, Zhenming Ding", "title": "Visual Tactile Fusion Object Clustering", "comments": "8 pages, 5 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.RO stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Object clustering, aiming at grouping similar objects into one cluster with\nan unsupervised strategy, has been extensivelystudied among various data-driven\napplications. However, most existing state-of-the-art object clustering methods\n(e.g., single-view or multi-view clustering methods) only explore visual\ninformation, while ignoring one of most important sensing modalities, i.e.,\ntactile information which can help capture different object properties and\nfurther boost the performance of object clustering task. To effectively benefit\nboth visual and tactile modalities for object clustering, in this paper, we\npropose a deep Auto-Encoder-like Non-negative Matrix Factorization framework\nfor visual-tactile fusion clustering. Specifically, deep matrix factorization\nconstrained by an under-complete Auto-Encoder-like architecture is employed to\njointly learn hierarchical expression of visual-tactile fusion data, and\npreserve the local structure of data generating distribution of visual and\ntactile modalities. Meanwhile, a graph regularizer is introduced to capture the\nintrinsic relations of data samples within each modality. Furthermore, we\npropose a modality-level consensus regularizer to effectively align thevisual\nand tactile data in a common subspace in which the gap between visual and\ntactile data is mitigated. For the model optimization, we present an efficient\nalternating minimization strategy to solve our proposed model. Finally, we\nconduct extensive experiments on public datasets to verify the effectiveness of\nour framework.\n", "versions": [{"version": "v1", "created": "Thu, 21 Nov 2019 12:04:17 GMT"}], "update_date": "2019-11-22", "authors_parsed": [["Zhang", "Tao", ""], ["Cong", "Yang", ""], ["Sun", "Gan", ""], ["Wang", "Qianqian", ""], ["Ding", "Zhenming", ""]]}, {"id": "1911.09431", "submitter": "Thomas Demeester", "authors": "Thomas Demeester", "title": "System Identification with Time-Aware Neural Sequence Models", "comments": "34th AAAI Conference on Artificial Intelligence (AAAI 2020)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.SY eess.SY stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Established recurrent neural networks are well-suited to solve a wide variety\nof prediction tasks involving discrete sequences. However, they do not perform\nas well in the task of dynamical system identification, when dealing with\nobservations from continuous variables that are unevenly sampled in time, for\nexample due to missing observations. We show how such neural sequence models\ncan be adapted to deal with variable step sizes in a natural way. In\nparticular, we introduce a time-aware and stationary extension of existing\nmodels (including the Gated Recurrent Unit) that allows them to deal with\nunevenly sampled system observations by adapting to the observation times,\nwhile facilitating higher-order temporal behavior. We discuss the properties\nand demonstrate the validity of the proposed approach, based on samples from\ntwo industrial input/output processes.\n", "versions": [{"version": "v1", "created": "Thu, 21 Nov 2019 12:09:08 GMT"}], "update_date": "2019-11-22", "authors_parsed": [["Demeester", "Thomas", ""]]}, {"id": "1911.09445", "submitter": "Guoqiang Zhang", "authors": "Guoqiang Zhang, Kenta Niwa and W. B. Kleijn", "title": "Approximated Orthonormal Normalisation in Training Neural Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Generalisation of a deep neural network (DNN) is one major concern when\nemploying the deep learning approach for solving practical problems. In this\npaper we propose a new technique, named approximated orthonormal normalisation\n(AON), to improve the generalisation capacity of a DNN model. Considering a\nweight matrix W from a particular neural layer in the model, our objective is\nto design a function h(W) such that its row vectors are approximately\northogonal to each other while allowing the DNN model to fit the training data\nsufficiently accurate. By doing so, it would avoid co-adaptation among neurons\nof the same layer to be able to improve network-generalisation capacity.\nSpecifically, at each iteration, we first approximate (WW^T)^(-1/2) using its\nTaylor expansion before multiplying the matrix W. After that, the matrix\nproduct is then normalised by applying the spectral normalisation (SN)\ntechnique to obtain h(W). Conceptually speaking, AON is designed to turn\northonormal regularisation into orthonormal normalisation to avoid manual\nbalancing the original and penalty functions. Experimental results show that\nAON yields promising validation performance compared to orthonormal\nregularisation.\n", "versions": [{"version": "v1", "created": "Thu, 21 Nov 2019 12:57:50 GMT"}, {"version": "v2", "created": "Tue, 14 Jan 2020 11:05:56 GMT"}], "update_date": "2020-01-15", "authors_parsed": [["Zhang", "Guoqiang", ""], ["Niwa", "Kenta", ""], ["Kleijn", "W. B.", ""]]}, {"id": "1911.09447", "submitter": "Gregor Ulm", "authors": "Gregor Ulm, Simon Smith, Adrian Nilsson, Emil Gustavsson, Mats\n  Jirstrand", "title": "S-RASTER: Contraction Clustering for Evolving Data Streams", "comments": "24 pages, 5 figures, 2 tables", "journal-ref": "Journal of Big Data (Springer) Vol. 7, Article number: 62 (2020)", "doi": "10.1186/s40537-020-00336-3", "report-no": null, "categories": "cs.DS cs.DC cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Contraction Clustering (RASTER) is a single-pass algorithm for density-based\nclustering of 2D data. It can process arbitrary amounts of data in linear time\nand in constant memory, quickly identifying approximate clusters. It also\nexhibits good scalability in the presence of multiple CPU cores. RASTER\nexhibits very competitive performance compared to standard clustering\nalgorithms, but at the cost of decreased precision. Yet, RASTER is limited to\nbatch processing and unable to identify clusters that only exist temporarily.\nIn contrast, S-RASTER is an adaptation of RASTER to the stream processing\nparadigm that is able to identify clusters in evolving data streams. This\nalgorithm retains the main benefits of its parent algorithm, i.e. single-pass\nlinear time cost and constant memory requirements for each discrete time step\nwithin a sliding window. The sliding window is efficiently pruned, and\nclustering is still performed in linear time. Like RASTER, S-RASTER trades off\nan often negligible amount of precision for speed. Our evaluation shows that\ncompeting algorithms are at least 50% slower. Furthermore, S-RASTER shows good\nqualitative results, based on standard metrics. It is very well suited to\nreal-world scenarios where clustering does not happen continually but only\nperiodically.\n", "versions": [{"version": "v1", "created": "Thu, 21 Nov 2019 13:01:43 GMT"}, {"version": "v2", "created": "Tue, 4 Feb 2020 12:57:20 GMT"}, {"version": "v3", "created": "Mon, 15 Jun 2020 22:48:06 GMT"}, {"version": "v4", "created": "Mon, 6 Jul 2020 19:38:21 GMT"}, {"version": "v5", "created": "Wed, 16 Sep 2020 12:43:59 GMT"}], "update_date": "2020-09-17", "authors_parsed": [["Ulm", "Gregor", ""], ["Smith", "Simon", ""], ["Nilsson", "Adrian", ""], ["Gustavsson", "Emil", ""], ["Jirstrand", "Mats", ""]]}, {"id": "1911.09450", "submitter": "Haoli Bai", "authors": "Haoli Bai, Jiaxiang Wu, Irwin King, Michael Lyu", "title": "Few Shot Network Compression via Cross Distillation", "comments": "AAAI 2020", "journal-ref": "The Thirty-Fourth AAAI Conference on Artificial Intelligence\n  (AAAI), 2020", "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Model compression has been widely adopted to obtain light-weighted deep\nneural networks. Most prevalent methods, however, require fine-tuning with\nsufficient training data to ensure accuracy, which could be challenged by\nprivacy and security issues. As a compromise between privacy and performance,\nin this paper we investigate few shot network compression: given few samples\nper class, how can we effectively compress the network with negligible\nperformance drop? The core challenge of few shot network compression lies in\nhigh estimation errors from the original network during inference, since the\ncompressed network can easily over-fits on the few training instances. The\nestimation errors could propagate and accumulate layer-wisely and finally\ndeteriorate the network output. To address the problem, we propose cross\ndistillation, a novel layer-wise knowledge distillation approach. By\ninterweaving hidden layers of teacher and student network, layer-wisely\naccumulated estimation errors can be effectively reduced.The proposed method\noffers a general framework compatible with prevalent network compression\ntechniques such as pruning. Extensive experiments on benchmark datasets\ndemonstrate that cross distillation can significantly improve the student\nnetwork's accuracy when only a few training instances are available.\n", "versions": [{"version": "v1", "created": "Thu, 21 Nov 2019 13:07:52 GMT"}, {"version": "v2", "created": "Sat, 2 May 2020 10:20:20 GMT"}], "update_date": "2020-05-05", "authors_parsed": [["Bai", "Haoli", ""], ["Wu", "Jiaxiang", ""], ["King", "Irwin", ""], ["Lyu", "Michael", ""]]}, {"id": "1911.09454", "submitter": "Bitan Hou", "authors": "Bitan Hou, Yujing Wang, Ming Zeng, Shan Jiang, Ole J. Mengshoel,\n  Yunhai Tong, Jing Bai", "title": "Customized Graph Embedding: Tailoring Embedding Vectors to different\n  Applications", "comments": "The first three authors contributed equally to this paper", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.SI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Graph is a natural representation of data for a variety of real-word\napplications, such as knowledge graph mining, social network analysis and\nbiological network comparison. For these applications, graph embedding is\ncrucial as it provides vector representations of the graph. One limitation of\nexisting graph embedding methods is that their embedding optimization\nprocedures are disconnected from the target application. In this paper, we\npropose a novel approach, namely Customized Graph Embedding (CGE) to tackle\nthis problem. The CGE algorithm learns customized vector representations of\ngraph nodes by differentiating the importance of distinct graph paths\nautomatically for a specific application. Extensive experiments were carried\nout on a diverse set of node classification datasets, which demonstrate strong\nperformances of CGE and provide deep insights into the model.\n", "versions": [{"version": "v1", "created": "Thu, 21 Nov 2019 13:09:26 GMT"}, {"version": "v2", "created": "Wed, 22 Jan 2020 09:17:17 GMT"}, {"version": "v3", "created": "Thu, 23 Jan 2020 10:07:19 GMT"}], "update_date": "2020-01-24", "authors_parsed": [["Hou", "Bitan", ""], ["Wang", "Yujing", ""], ["Zeng", "Ming", ""], ["Jiang", "Shan", ""], ["Mengshoel", "Ole J.", ""], ["Tong", "Yunhai", ""], ["Bai", "Jing", ""]]}, {"id": "1911.09458", "submitter": "Jinhang Zuo", "authors": "Jinhang Zuo, Xiaoxi Zhang, Carlee Joe-Wong", "title": "Observe Before Play: Multi-armed Bandit with Pre-observations", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the stochastic multi-armed bandit (MAB) problem in a setting\nwhere a player can pay to pre-observe arm rewards before playing an arm in each\nround. Apart from the usual trade-off between exploring new arms to find the\nbest one and exploiting the arm believed to offer the highest reward, we\nencounter an additional dilemma: pre-observing more arms gives a higher chance\nto play the best one, but incurs a larger cost. For the single-player setting,\nwe design an Observe-Before-Play Upper Confidence Bound (OBP-UCB) algorithm for\n$K$ arms with Bernoulli rewards, and prove a $T$-round regret upper bound\n$O(K^2\\log T)$. In the multi-player setting, collisions will occur when players\nselect the same arm to play in the same round. We design a centralized\nalgorithm, C-MP-OBP, and prove its $T$-round regret relative to an offline\ngreedy strategy is upper bounded in $O(\\frac{K^4}{M^2}\\log T)$ for $K$ arms and\n$M$ players. We also propose distributed versions of the C-MP-OBP policy,\ncalled D-MP-OBP and D-MP-Adapt-OBP, achieving logarithmic regret with respect\nto collision-free target policies. Experiments on synthetic data and wireless\nchannel traces show that C-MP-OBP and D-MP-OBP outperform random heuristics and\noffline optimal policies that do not allow pre-observations.\n", "versions": [{"version": "v1", "created": "Thu, 21 Nov 2019 13:22:21 GMT"}], "update_date": "2019-11-22", "authors_parsed": [["Zuo", "Jinhang", ""], ["Zhang", "Xiaoxi", ""], ["Joe-Wong", "Carlee", ""]]}, {"id": "1911.09461", "submitter": "David Bergman", "authors": "David Bergman, Teng Huang, Philip Brooks, Andrea Lodi, Arvind U.\n  Raghunathan", "title": "JANOS: An Integrated Predictive and Prescriptive Modeling Framework", "comments": "12 pages, 3 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG math.OC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Business research practice is witnessing a surge in the integration of\npredictive modeling and prescriptive analysis. We describe a modeling framework\nJANOS that seamlessly integrates the two streams of analytics, for the first\ntime allowing researchers and practitioners to embed machine learning models in\nan optimization framework. JANOS allows for specifying a prescriptive model\nusing standard optimization modeling elements such as constraints and\nvariables. The key novelty lies in providing modeling constructs that allow for\nthe specification of commonly used predictive models and their features as\nconstraints and variables in the optimization model. The framework considers\ntwo sets of decision variables; regular and predicted. The relationship between\nthe regular and the predicted variables are specified by the user as\npre-trained predictive models. JANOS currently supports linear regression,\nlogistic regression, and neural network with rectified linear activation\nfunctions, but we plan to expand on this set in the future. In this paper, we\ndemonstrate the flexibility of the framework through an example on scholarship\nallocation in a student enrollment problem and provide a numeric performance\nevaluation.\n", "versions": [{"version": "v1", "created": "Thu, 21 Nov 2019 13:31:24 GMT"}], "update_date": "2019-11-22", "authors_parsed": [["Bergman", "David", ""], ["Huang", "Teng", ""], ["Brooks", "Philip", ""], ["Lodi", "Andrea", ""], ["Raghunathan", "Arvind U.", ""]]}, {"id": "1911.09464", "submitter": "Xu Shen", "authors": "Jiwei Yang, Xu Shen, Jun Xing, Xinmei Tian, Houqiang Li, Bing Deng,\n  Jianqiang Huang, Xiansheng Hua", "title": "Quantization Networks", "comments": "10 pages, CVPR2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Although deep neural networks are highly effective, their high computational\nand memory costs severely challenge their applications on portable devices. As\na consequence, low-bit quantization, which converts a full-precision neural\nnetwork into a low-bitwidth integer version, has been an active and promising\nresearch topic. Existing methods formulate the low-bit quantization of networks\nas an approximation or optimization problem. Approximation-based methods\nconfront the gradient mismatch problem, while optimization-based methods are\nonly suitable for quantizing weights and could introduce high computational\ncost in the training stage. In this paper, we propose a novel perspective of\ninterpreting and implementing neural network quantization by formulating\nlow-bit quantization as a differentiable non-linear function (termed\nquantization function). The proposed quantization function can be learned in a\nlossless and end-to-end manner and works for any weights and activations of\nneural networks in a simple and uniform way. Extensive experiments on image\nclassification and object detection tasks show that our quantization networks\noutperform the state-of-the-art methods. We believe that the proposed method\nwill shed new insights on the interpretation of neural network quantization.\nOur code is available at\nhttps://github.com/aliyun/alibabacloud-quantization-networks.\n", "versions": [{"version": "v1", "created": "Thu, 21 Nov 2019 13:44:03 GMT"}, {"version": "v2", "created": "Thu, 28 Nov 2019 02:37:31 GMT"}], "update_date": "2019-12-02", "authors_parsed": [["Yang", "Jiwei", ""], ["Shen", "Xu", ""], ["Xing", "Jun", ""], ["Tian", "Xinmei", ""], ["Li", "Houqiang", ""], ["Deng", "Bing", ""], ["Huang", "Jianqiang", ""], ["Hua", "Xiansheng", ""]]}, {"id": "1911.09471", "submitter": "Sahan Bulathwela", "authors": "Sahan Bulathwela, Maria Perez-Ortiz, Emine Yilmaz and John\n  Shawe-Taylor", "title": "TrueLearn: A Family of Bayesian Algorithms to Match Lifelong Learners to\n  Open Educational Resources", "comments": "In Proceedings of AAAI Conference on Artificial Intelligence 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.IR cs.LG stat.AP stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The recent advances in computer-assisted learning systems and the\navailability of open educational resources today promise a pathway to providing\ncost-efficient, high-quality education to large masses of learners. One of the\nmost ambitious use cases of computer-assisted learning is to build a lifelong\nlearning recommendation system. Unlike short-term courses, lifelong learning\npresents unique challenges, requiring sophisticated recommendation models that\naccount for a wide range of factors such as background knowledge of learners or\nnovelty of the material while effectively maintaining knowledge states of\nmasses of learners for significantly longer periods of time (ideally, a\nlifetime). This work presents the foundations towards building a dynamic,\nscalable and transparent recommendation system for education, modelling\nlearner's knowledge from implicit data in the form of engagement with open\neducational resources. We i) use a text ontology based on Wikipedia to\nautomatically extract knowledge components of educational resources and, ii)\npropose a set of online Bayesian strategies inspired by the well-known areas of\nitem response theory and knowledge tracing. Our proposal, TrueLearn, focuses on\nrecommendations for which the learner has enough background knowledge (so they\nare able to understand and learn from the material), and the material has\nenough novelty that would help the learner improve their knowledge about the\nsubject and keep them engaged. We further construct a large open educational\nvideo lectures dataset and test the performance of the proposed algorithms,\nwhich show clear promise towards building an effective educational\nrecommendation system.\n", "versions": [{"version": "v1", "created": "Thu, 21 Nov 2019 13:56:40 GMT"}], "update_date": "2019-11-22", "authors_parsed": [["Bulathwela", "Sahan", ""], ["Perez-Ortiz", "Maria", ""], ["Yilmaz", "Emine", ""], ["Shawe-Taylor", "John", ""]]}, {"id": "1911.09476", "submitter": "Golnaz Habibi", "authors": "Golnaz Habibi, Nikita Japuria, Jonathan P. How", "title": "Incremental Learning of Motion Primitives for Pedestrian Trajectory\n  Prediction at Intersections", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper presents a novel incremental learning algorithm for pedestrian\nmotion prediction, with the ability to improve the learned model over time when\ndata is incrementally available. In this setup, trajectories are modeled as\nsimple segments called motion primitives. Transitions between motion primitives\nare modeled as Gaussian Processes. When new data is available, the motion\nprimitives learned from the new data are compared with the previous ones by\nmeasuring the inner product of the motion primitive vectors. Similar motion\nprimitives and transitions are fused and novel motion primitives are added to\ncapture newly observed behaviors. The proposed approach is tested and compared\nwith other baselines in intersection scenarios where the data is incrementally\navailable either from a single intersection or from multiple intersections with\ndifferent geometries. In both cases, our method incrementally learns motion\npatterns and outperforms the offline learning approach in terms of prediction\nerrors. The results also show that the model size in our algorithm grows at a\nmuch lower rate than standard incremental learning, where newly learned motion\nprimitives and transitions are simply accumulated over time.\n", "versions": [{"version": "v1", "created": "Thu, 21 Nov 2019 14:06:18 GMT"}], "update_date": "2019-11-22", "authors_parsed": [["Habibi", "Golnaz", ""], ["Japuria", "Nikita", ""], ["How", "Jonathan P.", ""]]}, {"id": "1911.09483", "submitter": "Deli Chen", "authors": "Guangxiang Zhao, Xu Sun, Jingjing Xu, Zhiyuan Zhang, Liangchen Luo", "title": "MUSE: Parallel Multi-Scale Attention for Sequence to Sequence Learning", "comments": "Achieve state-of-the-art BLEU scores on WMT14 En-De, En-Fr, and IWSLT\n  De-En", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In sequence to sequence learning, the self-attention mechanism proves to be\nhighly effective, and achieves significant improvements in many tasks. However,\nthe self-attention mechanism is not without its own flaws. Although\nself-attention can model extremely long dependencies, the attention in deep\nlayers tends to overconcentrate on a single token, leading to insufficient use\nof local information and difficultly in representing long sequences. In this\nwork, we explore parallel multi-scale representation learning on sequence data,\nstriving to capture both long-range and short-range language structures. To\nthis end, we propose the Parallel MUlti-Scale attEntion (MUSE) and MUSE-simple.\nMUSE-simple contains the basic idea of parallel multi-scale sequence\nrepresentation learning, and it encodes the sequence in parallel, in terms of\ndifferent scales with the help from self-attention, and pointwise\ntransformation. MUSE builds on MUSE-simple and explores combining convolution\nand self-attention for learning sequence representations from more different\nscales. We focus on machine translation and the proposed approach achieves\nsubstantial performance improvements over Transformer, especially on long\nsequences. More importantly, we find that although conceptually simple, its\nsuccess in practice requires intricate considerations, and the multi-scale\nattention must build on unified semantic space. Under common setting, the\nproposed model achieves substantial performance and outperforms all previous\nmodels on three main machine translation tasks. In addition, MUSE has potential\nfor accelerating inference due to its parallelism. Code will be available at\nhttps://github.com/lancopku/MUSE\n", "versions": [{"version": "v1", "created": "Sun, 17 Nov 2019 09:36:07 GMT"}], "update_date": "2019-11-22", "authors_parsed": [["Zhao", "Guangxiang", ""], ["Sun", "Xu", ""], ["Xu", "Jingjing", ""], ["Zhang", "Zhiyuan", ""], ["Luo", "Liangchen", ""]]}, {"id": "1911.09501", "submitter": "Kia Khezeli", "authors": "Kia Khezeli and Eilyan Bitar", "title": "Safe Linear Stochastic Bandits", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce the safe linear stochastic bandit framework---a generalization\nof linear stochastic bandits---where, in each stage, the learner is required to\nselect an arm with an expected reward that is no less than a predetermined\n(safe) threshold with high probability. We assume that the learner initially\nhas knowledge of an arm that is known to be safe, but not necessarily optimal.\nLeveraging on this assumption, we introduce a learning algorithm that\nsystematically combines known safe arms with exploratory arms to safely expand\nthe set of safe arms over time, while facilitating safe greedy exploitation in\nsubsequent stages. In addition to ensuring the satisfaction of the safety\nconstraint at every stage of play, the proposed algorithm is shown to exhibit\nan expected regret that is no more than $O(\\sqrt{T}\\log (T))$ after $T$ stages\nof play.\n", "versions": [{"version": "v1", "created": "Thu, 21 Nov 2019 14:45:43 GMT"}], "update_date": "2019-11-22", "authors_parsed": [["Khezeli", "Kia", ""], ["Bitar", "Eilyan", ""]]}, {"id": "1911.09508", "submitter": "Szilvia Lestyan", "authors": "Mina Remeli, Szilvia Lestyan, Gergely Acs, and Gergely Biczok", "title": "Automatic Driver Identification from In-Vehicle Network Logs", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.LG eess.SP stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Data generated by cars is growing at an unprecedented scale. As cars\ngradually become part of the Internet of Things (IoT) ecosystem, several\nstakeholders discover the value of in-vehicle network logs containing the\nmeasurements of the multitude of sensors deployed within the car. This wealth\nof data is also expected to be exploitable by third parties for the purpose of\nprofiling drivers in order to provide personalized, valueadded services.\nAlthough several prior works have successfully demonstrated the feasibility of\ndriver re-identification using the in-vehicle network data captured on the\nvehicle's CAN (Controller Area Network) bus, they inferred the identity of the\ndriver only from known sensor signals (such as the vehicle's speed, brake pedal\nposition, steering wheel angle, etc.) extracted from the CAN messages. However,\ncar manufacturers intentionally do not reveal exact signal location and\nsemantics within CAN logs. We show that the inference of driver identity is\npossible even with off-the-shelf machine learning techniques without\nreverse-engineering the CAN protocol. We demonstrate our approach on a dataset\nof 33 drivers and show that a driver can be re-identified and distinguished\nfrom other drivers with an accuracy of 75-85%.\n", "versions": [{"version": "v1", "created": "Fri, 25 Oct 2019 15:28:08 GMT"}], "update_date": "2019-11-22", "authors_parsed": [["Remeli", "Mina", ""], ["Lestyan", "Szilvia", ""], ["Acs", "Gergely", ""], ["Biczok", "Gergely", ""]]}, {"id": "1911.09512", "submitter": "Akbar Siami Namin", "authors": "Sima Siami-Namini and Neda Tavakoli and Akbar Siami Namin", "title": "A Comparative Analysis of Forecasting Financial Time Series Using ARIMA,\n  LSTM, and BiLSTM", "comments": "8 pages, 3 figures, 3 tables, 1 listing, IEEE BigData 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CE cs.PF stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Machine and deep learning-based algorithms are the emerging approaches in\naddressing prediction problems in time series. These techniques have been shown\nto produce more accurate results than conventional regression-based modeling.\nIt has been reported that artificial Recurrent Neural Networks (RNN) with\nmemory, such as Long Short-Term Memory (LSTM), are superior compared to\nAutoregressive Integrated Moving Average (ARIMA) with a large margin. The\nLSTM-based models incorporate additional \"gates\" for the purpose of memorizing\nlonger sequences of input data. The major question is that whether the gates\nincorporated in the LSTM architecture already offers a good prediction and\nwhether additional training of data would be necessary to further improve the\nprediction.\n  Bidirectional LSTMs (BiLSTMs) enable additional training by traversing the\ninput data twice (i.e., 1) left-to-right, and 2) right-to-left). The research\nquestion of interest is then whether BiLSTM, with additional training\ncapability, outperforms regular unidirectional LSTM. This paper reports a\nbehavioral analysis and comparison of BiLSTM and LSTM models. The objective is\nto explore to what extend additional layers of training of data would be\nbeneficial to tune the involved parameters. The results show that additional\ntraining of data and thus BiLSTM-based modeling offers better predictions than\nregular LSTM-based models. More specifically, it was observed that BiLSTM\nmodels provide better predictions compared to ARIMA and LSTM models. It was\nalso observed that BiLSTM models reach the equilibrium much slower than\nLSTM-based models.\n", "versions": [{"version": "v1", "created": "Thu, 21 Nov 2019 14:58:52 GMT"}], "update_date": "2019-11-22", "authors_parsed": [["Siami-Namini", "Sima", ""], ["Tavakoli", "Neda", ""], ["Namin", "Akbar Siami", ""]]}, {"id": "1911.09514", "submitter": "Tameem Adel", "authors": "Tameem Adel, Han Zhao, Richard E. Turner", "title": "Continual Learning with Adaptive Weights (CLAW)", "comments": "ICLR 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Approaches to continual learning aim to successfully learn a set of related\ntasks that arrive in an online manner. Recently, several frameworks have been\ndeveloped which enable deep learning to be deployed in this learning scenario.\nA key modelling decision is to what extent the architecture should be shared\nacross tasks. On the one hand, separately modelling each task avoids\ncatastrophic forgetting but it does not support transfer learning and leads to\nlarge models. On the other hand, rigidly specifying a shared component and a\ntask-specific part enables task transfer and limits the model size, but it is\nvulnerable to catastrophic forgetting and restricts the form of task-transfer\nthat can occur. Ideally, the network should adaptively identify which parts of\nthe network to share in a data driven way. Here we introduce such an approach\ncalled Continual Learning with Adaptive Weights (CLAW), which is based on\nprobabilistic modelling and variational inference. Experiments show that CLAW\nachieves state-of-the-art performance on six benchmarks in terms of overall\ncontinual learning performance, as measured by classification accuracy, and in\nterms of addressing catastrophic forgetting.\n", "versions": [{"version": "v1", "created": "Thu, 21 Nov 2019 14:59:58 GMT"}, {"version": "v2", "created": "Tue, 16 Jun 2020 01:00:11 GMT"}], "update_date": "2020-06-17", "authors_parsed": [["Adel", "Tameem", ""], ["Zhao", "Han", ""], ["Turner", "Richard E.", ""]]}, {"id": "1911.09518", "submitter": "Arjun Krishna Mr", "authors": "Arjun Krishna and A S Akil Arif Ibrahim", "title": "Video Segment Copy Detection Using Memory Constrained Hierarchical\n  Batch-Normalized LSTM Autoencoder", "comments": "Undergraduate Thesis", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this report, we introduce a video hashing method for scalable video\nsegment copy detection. The objective of video segment copy detection is to\nfind the video (s) present in a large database, one of whose segments (cropped\nin time) is a (transformed) copy of the given query video. This transformation\nmay be temporal (for example frame dropping, change in frame rate) or spatial\n(brightness and contrast change, addition of noise etc.) in nature although the\nprimary focus of this report is detecting temporal attacks. The video hashing\nmethod proposed by us uses a deep learning neural network to learn variable\nlength binary hash codes for the entire video considering both temporal and\nspatial features into account. This is in contrast to most existing video\nhashing methods, as they use conventional image hashing techniques to obtain\nhash codes for a video after extracting features for every frame or certain key\nframes, in which case the temporal information present in the video is not\nexploited. Our hashing method is specifically resilient to time cropping making\nit extremely useful in video segment copy detection. Experimental results\nobtained on the large augmented dataset consisting of around 25,000 videos with\nsegment copies demonstrate the efficacy of our proposed video hashing method.\n", "versions": [{"version": "v1", "created": "Wed, 20 Nov 2019 15:00:02 GMT"}], "update_date": "2019-11-22", "authors_parsed": [["Krishna", "Arjun", ""], ["Ibrahim", "A S Akil Arif", ""]]}, {"id": "1911.09531", "submitter": "Joao Moreira", "authors": "Remzi Celebi, Joao Rebelo Moreira, Ahmed A. Hassan, Sandeep Ayyar,\n  Lars Ridder, Tobias Kuhn, and Michel Dumontier", "title": "Towards FAIR protocols and workflows: The OpenPREDICT case study", "comments": "Preprint. Submitted to PeerJ on 13th November 2019. 3 appendixes as\n  PDF files", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  It is essential for the advancement of science that scientists and\nresearchers share, reuse and reproduce workflows and protocols used by others.\nThe FAIR principles are a set of guidelines that aim to maximize the value and\nusefulness of research data, and emphasize a number of important points\nregarding the means by which digital objects are found and reused by others.\nThe question of how to apply these principles not just to the static input and\noutput data but also to the dynamic workflows and protocols that consume and\nproduce them is still under debate and poses a number of challenges. In this\npaper we describe our inclusive and overarching approach to apply the FAIR\nprinciples to workflows and protocols and demonstrate its benefits. We apply\nand evaluate our approach on a case study that consists of making the PREDICT\nworkflow, a highly cited drug repurposing workflow, open and FAIR. This\nincludes FAIRification of the involved datasets, as well as applying semantic\ntechnologies to represent and store data about the detailed versions of the\ngeneral protocol, of the concrete workflow instructions, and of their execution\ntraces. A semantic model was proposed to better address these specific\nrequirements and were evaluated by answering competency questions. This\nsemantic model consists of classes and relations from a number of existing\nontologies, including Workflow4ever, PROV, EDAM, and BPMN. This allowed us then\nto formulate and answer new kinds of competency questions. Our evaluation shows\nthe high degree to which our FAIRified OpenPREDICT workflow now adheres to the\nFAIR principles and the practicality and usefulness of being able to answer our\nnew competency questions.\n", "versions": [{"version": "v1", "created": "Wed, 20 Nov 2019 08:53:57 GMT"}], "update_date": "2019-11-22", "authors_parsed": [["Celebi", "Remzi", ""], ["Moreira", "Joao Rebelo", ""], ["Hassan", "Ahmed A.", ""], ["Ayyar", "Sandeep", ""], ["Ridder", "Lars", ""], ["Kuhn", "Tobias", ""], ["Dumontier", "Michel", ""]]}, {"id": "1911.09535", "submitter": "Oluwafemi Azeez", "authors": "Siddharth Ghiya, Oluwafemi Azeez, Brendan Miller", "title": "Agent Probing Interaction Policies", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.MA cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Reinforcement learning in a multi agent system is difficult because these\nsystems are inherently non-stationary in nature. In such a case, identifying\nthe type of the opposite agent is crucial and can help us address this\nnon-stationary environment. We have investigated if we can employ some probing\npolicies which help us better identify the type of the other agent in the\nenvironment. We've made a simplifying assumption that the other agent has a\nstationary policy that our probing policy is trying to approximate. Our work\nextends Environmental Probing Interaction Policy framework to handle multi\nagent environments.\n", "versions": [{"version": "v1", "created": "Thu, 21 Nov 2019 15:20:43 GMT"}, {"version": "v2", "created": "Tue, 26 Nov 2019 17:56:37 GMT"}, {"version": "v3", "created": "Fri, 13 Dec 2019 16:10:42 GMT"}], "update_date": "2019-12-16", "authors_parsed": [["Ghiya", "Siddharth", ""], ["Azeez", "Oluwafemi", ""], ["Miller", "Brendan", ""]]}, {"id": "1911.09537", "submitter": "Jindong Gu", "authors": "Jindong Gu and Volker Tresp", "title": "Neural Network Memorization Dissection", "comments": "Workshop on Machine Learning with Guarantees, NeurIPS 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep neural networks (DNNs) can easily fit a random labeling of the training\ndata with zero training error. What is the difference between DNNs trained with\nrandom labels and the ones trained with true labels? Our paper answers this\nquestion with two contributions. First, we study the memorization properties of\nDNNs. Our empirical experiments shed light on how DNNs prioritize the learning\nof simple input patterns. In the second part, we propose to measure the\nsimilarity between what different DNNs have learned and memorized. With the\nproposed approach, we analyze and compare DNNs trained on data with true labels\nand random labels. The analysis shows that DNNs have \\textit{One way to Learn}\nand \\textit{N ways to Memorize}. We also use gradient information to gain an\nunderstanding of the analysis results.\n", "versions": [{"version": "v1", "created": "Thu, 21 Nov 2019 15:24:55 GMT"}], "update_date": "2019-11-22", "authors_parsed": [["Gu", "Jindong", ""], ["Tresp", "Volker", ""]]}, {"id": "1911.09554", "submitter": "Pedro Henrique da Costa Avelar", "authors": "Pedro H. C. Avelar, Anderson R. Tavares, Marco Gori, Luis C. Lamb", "title": "Discrete and Continuous Deep Residual Learning Over Graphs", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we propose the use of continuous residual modules for graph\nkernels in Graph Neural Networks. We show how both discrete and continuous\nresidual layers allow for more robust training, being that continuous residual\nlayers are those which are applied by integrating through an Ordinary\nDifferential Equation (ODE) solver to produce their output. We experimentally\nshow that these residuals achieve better results than the ones with\nnon-residual modules when multiple layers are used, mitigating the low-pass\nfiltering effect of GCN-based models. Finally, we apply and analyse the\nbehaviour of these techniques and give pointers to how this technique can be\nuseful in other domains by allowing more predictable behaviour under dynamic\ntimes of computation.\n", "versions": [{"version": "v1", "created": "Thu, 21 Nov 2019 15:48:15 GMT"}, {"version": "v2", "created": "Tue, 26 Nov 2019 11:15:03 GMT"}], "update_date": "2019-11-27", "authors_parsed": [["Avelar", "Pedro H. C.", ""], ["Tavares", "Anderson R.", ""], ["Gori", "Marco", ""], ["Lamb", "Luis C.", ""]]}, {"id": "1911.09560", "submitter": "Kai Arulkumaran", "authors": "Andrea Agostinelli, Kai Arulkumaran, Marta Sarrico, Pierre Richemond,\n  Anil Anthony Bharath", "title": "Memory-Efficient Episodic Control Reinforcement Learning with Dynamic\n  Online k-means", "comments": "Workshop on Biological and Artificial Reinforcement Learning, NeurIPS\n  2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recently, neuro-inspired episodic control (EC) methods have been developed to\novercome the data-inefficiency of standard deep reinforcement learning\napproaches. Using non-/semi-parametric models to estimate the value function,\nthey learn rapidly, retrieving cached values from similar past states. In\nrealistic scenarios, with limited resources and noisy data, maintaining\nmeaningful representations in memory is essential to speed up the learning and\navoid catastrophic forgetting. Unfortunately, EC methods have a large space and\ntime complexity. We investigate different solutions to these problems based on\nprioritising and ranking stored states, as well as online clustering\ntechniques. We also propose a new dynamic online k-means algorithm that is both\ncomputationally-efficient and yields significantly better performance at\nsmaller memory sizes; we validate this approach on classic reinforcement\nlearning environments and Atari games.\n", "versions": [{"version": "v1", "created": "Thu, 21 Nov 2019 15:54:49 GMT"}], "update_date": "2019-11-22", "authors_parsed": [["Agostinelli", "Andrea", ""], ["Arulkumaran", "Kai", ""], ["Sarrico", "Marta", ""], ["Richemond", "Pierre", ""], ["Bharath", "Anil Anthony", ""]]}, {"id": "1911.09564", "submitter": "Kwang-Sung Jun", "authors": "Kwang-Sung Jun, Francesco Orabona", "title": "Parameter-Free Locally Differentially Private Stochastic Subgradient\n  Descent", "comments": "to appear at Privacy in Machine Learning (PriML) workshop, NeurIPS'19", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR math.OC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the problem of minimizing a convex risk with stochastic\nsubgradients guaranteeing $\\epsilon$-locally differentially private\n($\\epsilon$-LDP). While it has been shown that stochastic optimization is\npossible with $\\epsilon$-LDP via the standard SGD (Song et al., 2013), its\nconvergence rate largely depends on the learning rate, which must be tuned via\nrepeated runs. Further, tuning is detrimental to privacy loss since it\nsignificantly increases the number of gradient requests. In this work, we\npropose BANCO (Betting Algorithm for Noisy COins), the first $\\epsilon$-LDP SGD\nalgorithm that essentially matches the convergence rate of the tuned SGD\nwithout any learning rate parameter, reducing privacy loss and saving privacy\nbudget.\n", "versions": [{"version": "v1", "created": "Thu, 21 Nov 2019 15:58:17 GMT"}], "update_date": "2019-11-22", "authors_parsed": [["Jun", "Kwang-Sung", ""], ["Orabona", "Francesco", ""]]}, {"id": "1911.09572", "submitter": "Wenxin Hu", "authors": "Wenxin Hu, Xiaofeng Zhang, Gang Yang", "title": "Automatically Generating Macro Research Reports from a Piece of News", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.IR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Automatically generating macro research reports from economic news is an\nimportant yet challenging task. As we all know, it requires the macro analysts\nto write such reports within a short period of time after the important\neconomic news are released. This motivates our work, i.e., using AI techniques\nto save manual cost. The goal of the proposed system is to generate macro\nresearch reports as the draft for macro analysts. Essentially, the core\nchallenge is the long text generation issue. To address this issue, we propose\na novel deep learning technique based approach which includes two components,\ni.e., outline generation and macro research report generation.For the model\nperformance evaluation, we first crawl a large news-to-report dataset and then\nevaluate our approach on this dataset, and the generated reports are given for\nthe subjective evaluation.\n", "versions": [{"version": "v1", "created": "Thu, 21 Nov 2019 16:05:02 GMT"}], "update_date": "2019-11-22", "authors_parsed": [["Hu", "Wenxin", ""], ["Zhang", "Xiaofeng", ""], ["Yang", "Gang", ""]]}, {"id": "1911.09576", "submitter": "Gordon MacDonald", "authors": "Gordon MacDonald and Andrew Godbout and Bryn Gillcash and Stephanie\n  Cairns", "title": "Volume-preserving Neural Networks", "comments": "20 pages, 8 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a novel approach to addressing the vanishing (or exploding)\ngradient problem in deep neural networks. We construct a new architecture for\ndeep neural networks where all layers (except the output layer) of the network\nare a combination of rotation, permutation, diagonal, and activation sublayers\nwhich are all volume preserving. Our approach replaces the standard weight\nmatrix of a neural network with a combination of diagonal, rotational and\npermutation matrices, all of which are volume-preserving. We introduce a\ncoupled activation function allowing us to preserve volume even in the\nactivation function portion of a neural network layer. This control on the\nvolume forces the gradient (on average) to maintain equilibrium and not explode\nor vanish. To demonstrate our architecture we apply our volume-preserving\nneural network model to two standard datasets.\n", "versions": [{"version": "v1", "created": "Thu, 21 Nov 2019 16:10:41 GMT"}, {"version": "v2", "created": "Fri, 22 Nov 2019 17:29:50 GMT"}, {"version": "v3", "created": "Mon, 26 Apr 2021 16:05:32 GMT"}], "update_date": "2021-04-27", "authors_parsed": [["MacDonald", "Gordon", ""], ["Godbout", "Andrew", ""], ["Gillcash", "Bryn", ""], ["Cairns", "Stephanie", ""]]}, {"id": "1911.09586", "submitter": "Akbar Siami Namin", "authors": "Faranak Abri and Sima Siami-Namini and Mahdi Adl Khanghah and Fahimeh\n  Mirza Soltani and Akbar Siami Namin", "title": "The Performance of Machine and Deep Learning Classifiers in Detecting\n  Zero-Day Vulnerabilities", "comments": "8 pages, 2 figures, 3 tables, IEEE BigData 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The detection of zero-day attacks and vulnerabilities is a challenging\nproblem. It is of utmost importance for network administrators to identify them\nwith high accuracy. The higher the accuracy is, the more robust the defense\nmechanism will be. In an ideal scenario (i.e., 100% accuracy) the system can\ndetect zero-day malware without being concerned about mistakenly tagging benign\nfiles as malware or enabling disruptive malicious code running as\nnone-malicious ones. This paper investigates different machine learning\nalgorithms to find out how well they can detect zero-day malware. Through the\nexamination of 34 machine/deep learning classifiers, we found that the random\nforest classifier offered the best accuracy. The paper poses several research\nquestions regarding the performance of machine and deep learning algorithms\nwhen detecting zero-day malware with zero rates for false positive and false\nnegative.\n", "versions": [{"version": "v1", "created": "Thu, 21 Nov 2019 16:25:44 GMT"}], "update_date": "2019-11-22", "authors_parsed": [["Abri", "Faranak", ""], ["Siami-Namini", "Sima", ""], ["Khanghah", "Mahdi Adl", ""], ["Soltani", "Fahimeh Mirza", ""], ["Namin", "Akbar Siami", ""]]}, {"id": "1911.09587", "submitter": "Matthijs van Leeuwen", "authors": "Micky Faas and Matthijs van Leeuwen", "title": "Vouw: Geometric Pattern Mining using the MDL Principle", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce geometric pattern mining, the problem of finding recurring local\nstructure in discrete, geometric matrices. It differs from existing pattern\nmining problems by identifying complex spatial relations between elements,\nresulting in arbitrarily shaped patterns. After we formalise this new type of\npattern mining, we propose an approach to selecting a set of patterns using the\nMinimum Description Length principle. We demonstrate the potential of our\napproach by introducing Vouw, a heuristic algorithm for mining exact geometric\npatterns. We show that Vouw delivers high-quality results with a synthetic\nbenchmark.\n", "versions": [{"version": "v1", "created": "Thu, 21 Nov 2019 16:28:12 GMT"}, {"version": "v2", "created": "Fri, 22 Nov 2019 18:39:54 GMT"}], "update_date": "2019-11-25", "authors_parsed": [["Faas", "Micky", ""], ["van Leeuwen", "Matthijs", ""]]}, {"id": "1911.09592", "submitter": "Arindam Sengupta", "authors": "Arindam Sengupta, Feng Jin, Renyuan Zhang and Siyang Cao", "title": "mm-Pose: Real-Time Human Skeletal Posture Estimation using mmWave Radars\n  and CNNs", "comments": "Submitted to IEEE Sensors Journal", "journal-ref": null, "doi": "10.1109/JSEN.2020.2991741", "report-no": null, "categories": "eess.SP cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, mm-Pose, a novel approach to detect and track human skeletons\nin real-time using an mmWave radar, is proposed. To the best of the authors'\nknowledge, this is the first method to detect >15 distinct skeletal joints\nusing mmWave radar reflection signals. The proposed method would find several\napplications in traffic monitoring systems, autonomous vehicles, patient\nmonitoring systems and defense forces to detect and track human skeleton for\neffective and preventive decision making in real-time. The use of radar makes\nthe system operationally robust to scene lighting and adverse weather\nconditions. The reflected radar point cloud in range, azimuth and elevation are\nfirst resolved and projected in Range-Azimuth and Range-Elevation planes. A\nnovel low-size high-resolution radar-to-image representation is also presented,\nthat overcomes the sparsity in traditional point cloud data and offers\nsignificant reduction in the subsequent machine learning architecture. The RGB\nchannels were assigned with the normalized values of range, elevation/azimuth\nand the power level of the reflection signals for each of the points. A forked\nCNN architecture was used to predict the real-world position of the skeletal\njoints in 3-D space, using the radar-to-image representation. The proposed\nmethod was tested for a single human scenario for four primary motions, (i)\nWalking, (ii) Swinging left arm, (iii) Swinging right arm, and (iv) Swinging\nboth arms to validate accurate predictions for motion in range, azimuth and\nelevation. The detailed methodology, implementation, challenges, and validation\nresults are presented.\n", "versions": [{"version": "v1", "created": "Thu, 21 Nov 2019 16:37:18 GMT"}], "update_date": "2020-05-05", "authors_parsed": [["Sengupta", "Arindam", ""], ["Jin", "Feng", ""], ["Zhang", "Renyuan", ""], ["Cao", "Siyang", ""]]}, {"id": "1911.09602", "submitter": "David Harwath", "authors": "David Harwath, Wei-Ning Hsu, James Glass", "title": "Learning Hierarchical Discrete Linguistic Units from Visually-Grounded\n  Speech", "comments": "Camera-ready version for ICLR", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG cs.SD eess.AS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we present a method for learning discrete linguistic units by\nincorporating vector quantization layers into neural models of visually\ngrounded speech. We show that our method is capable of capturing both\nword-level and sub-word units, depending on how it is configured. What\ndifferentiates this paper from prior work on speech unit learning is the choice\nof training objective. Rather than using a reconstruction-based loss, we use a\ndiscriminative, multimodal grounding objective which forces the learned units\nto be useful for semantic image retrieval. We evaluate the sub-word units on\nthe ZeroSpeech 2019 challenge, achieving a 27.3\\% reduction in ABX error rate\nover the top-performing submission, while keeping the bitrate approximately the\nsame. We also present experiments demonstrating the noise robustness of these\nunits. Finally, we show that a model with multiple quantizers can\nsimultaneously learn phone-like detectors at a lower layer and word-like\ndetectors at a higher layer. We show that these detectors are highly accurate,\ndiscovering 279 words with an F1 score of greater than 0.5.\n", "versions": [{"version": "v1", "created": "Thu, 21 Nov 2019 16:54:14 GMT"}, {"version": "v2", "created": "Fri, 14 Feb 2020 18:38:28 GMT"}], "update_date": "2020-02-17", "authors_parsed": [["Harwath", "David", ""], ["Hsu", "Wei-Ning", ""], ["Glass", "James", ""]]}, {"id": "1911.09615", "submitter": "Kai Arulkumaran", "authors": "Marta Sarrico, Kai Arulkumaran, Andrea Agostinelli, Pierre Richemond,\n  Anil Anthony Bharath", "title": "Sample-Efficient Reinforcement Learning with Maximum Entropy Mellowmax\n  Episodic Control", "comments": "Workshop on Biological and Artificial Reinforcement Learning, NeurIPS\n  2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep networks have enabled reinforcement learning to scale to more complex\nand challenging domains, but these methods typically require large quantities\nof training data. An alternative is to use sample-efficient episodic control\nmethods: neuro-inspired algorithms which use non-/semi-parametric models that\npredict values based on storing and retrieving previously experienced\ntransitions. One way to further improve the sample efficiency of these\napproaches is to use more principled exploration strategies. In this work, we\ntherefore propose maximum entropy mellowmax episodic control (MEMEC), which\nsamples actions according to a Boltzmann policy with a state-dependent\ntemperature. We demonstrate that MEMEC outperforms other uncertainty- and\nsoftmax-based exploration methods on classic reinforcement learning\nenvironments and Atari games, achieving both more rapid learning and higher\nfinal rewards.\n", "versions": [{"version": "v1", "created": "Thu, 21 Nov 2019 17:19:36 GMT"}], "update_date": "2019-11-22", "authors_parsed": [["Sarrico", "Marta", ""], ["Arulkumaran", "Kai", ""], ["Agostinelli", "Andrea", ""], ["Richemond", "Pierre", ""], ["Bharath", "Anil Anthony", ""]]}, {"id": "1911.09645", "submitter": "Zahra Shakeri", "authors": "Siddharth Gururani, Kilol Gupta, Dhaval Shah, Zahra Shakeri, Jervis\n  Pinto", "title": "Prosody Transfer in Neural Text to Speech Using Global Pitch and\n  Loudness Features", "comments": "5 pages, in review for conference publication", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SD cs.CL cs.LG eess.AS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper presents a simple yet effective method to achieve prosody transfer\nfrom a reference speech signal to synthesized speech. The main idea is to\nincorporate well-known acoustic correlates of prosody such as pitch and\nloudness contours of the reference speech into a modern neural text-to-speech\n(TTS) synthesizer such as Tacotron2 (TC2). More specifically, a small set of\nacoustic features are extracted from reference audio and then used to condition\na TC2 synthesizer. The trained model is evaluated using subjective listening\ntests and a novel objective evaluation of prosody transfer is proposed.\nListening tests show that the synthesized speech is rated as highly natural and\nthat prosody is successfully transferred from the reference speech signal to\nthe synthesized signal.\n", "versions": [{"version": "v1", "created": "Thu, 21 Nov 2019 18:04:47 GMT"}, {"version": "v2", "created": "Fri, 15 May 2020 20:46:24 GMT"}], "update_date": "2020-05-19", "authors_parsed": [["Gururani", "Siddharth", ""], ["Gupta", "Kilol", ""], ["Shah", "Dhaval", ""], ["Shakeri", "Zahra", ""], ["Pinto", "Jervis", ""]]}, {"id": "1911.09647", "submitter": "David Kofler", "authors": "Lukas Gonon, Philipp Grohs, Arnulf Jentzen, David Kofler, and David\n  \\v{S}i\\v{s}ka", "title": "Uniform error estimates for artificial neural network approximations for\n  heat equations", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.NA cs.LG cs.NA math.PR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recently, artificial neural networks (ANNs) in conjunction with stochastic\ngradient descent optimization methods have been employed to approximately\ncompute solutions of possibly rather high-dimensional partial differential\nequations (PDEs). Very recently, there have also been a number of rigorous\nmathematical results in the scientific literature which examine the\napproximation capabilities of such deep learning based approximation algorithms\nfor PDEs. These mathematical results from the scientific literature prove in\npart that algorithms based on ANNs are capable of overcoming the curse of\ndimensionality in the numerical approximation of high-dimensional PDEs. In\nthese mathematical results from the scientific literature usually the error\nbetween the solution of the PDE and the approximating ANN is measured in the\n$L^p$-sense with respect to some $p \\in [1,\\infty)$ and some probability\nmeasure. In many applications it is, however, also important to control the\nerror in a uniform $L^\\infty$-sense. The key contribution of the main result of\nthis article is to develop the techniques to obtain error estimates between\nsolutions of PDEs and approximating ANNs in the uniform $L^\\infty$-sense. In\nparticular, we prove that the number of parameters of an ANN to uniformly\napproximate the classical solution of the heat equation in a region $ [a,b]^d $\nfor a fixed time point $ T \\in (0,\\infty) $ grows at most polynomially in the\ndimension $ d \\in \\mathbb{N} $ and the reciprocal of the approximation\nprecision $ \\varepsilon > 0 $. This shows that ANNs can overcome the curse of\ndimensionality in the numerical approximation of the heat equation when the\nerror is measured in the uniform $L^\\infty$-norm.\n", "versions": [{"version": "v1", "created": "Wed, 20 Nov 2019 16:29:17 GMT"}, {"version": "v2", "created": "Mon, 17 Feb 2020 08:00:25 GMT"}, {"version": "v3", "created": "Mon, 15 Jun 2020 05:53:30 GMT"}], "update_date": "2020-06-16", "authors_parsed": [["Gonon", "Lukas", ""], ["Grohs", "Philipp", ""], ["Jentzen", "Arnulf", ""], ["Kofler", "David", ""], ["\u0160i\u0161ka", "David", ""]]}, {"id": "1911.09652", "submitter": "Oluwafemi Azeez", "authors": "Oluwafemi Azeez", "title": "Unsupervised Domain Adaptation by Optical Flow Augmentation in Semantic\n  Segmentation", "comments": "arXiv admin note: text overlap with arXiv:1910.10369 by other authors", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG eess.IV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  It is expensive to generate real-life image labels and there is a domain gap\nbetween real-life and simulated images, hence a model trained on the latter\ncannot adapt to the former. Solving this can totally eliminate the need for\nlabeling real-life datasets completely. Class balanced self-training is one of\nthe existing techniques that attempt to reduce the domain gap. Moreover,\naugmenting RGB with flow maps has improved performance in simple semantic\nsegmentation and geometry is preserved across domains. Hence, by augmenting\nimages with dense optical flow map, domain adaptation in semantic segmentation\ncan be improved.\n", "versions": [{"version": "v1", "created": "Wed, 20 Nov 2019 07:36:45 GMT"}], "update_date": "2019-11-22", "authors_parsed": [["Azeez", "Oluwafemi", ""]]}, {"id": "1911.09655", "submitter": "Haytham Fayek", "authors": "Haytham M. Fayek, Justin Johnson", "title": "Temporal Reasoning via Audio Question Answering", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG cs.SD eess.AS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Multimodal question answering tasks can be used as proxy tasks to study\nsystems that can perceive and reason about the world. Answering questions about\ndifferent types of input modalities stresses different aspects of reasoning\nsuch as visual reasoning, reading comprehension, story understanding, or\nnavigation. In this paper, we use the task of Audio Question Answering (AQA) to\nstudy the temporal reasoning abilities of machine learning models. To this end,\nwe introduce the Diagnostic Audio Question Answering (DAQA) dataset comprising\naudio sequences of natural sound events and programmatically generated\nquestions and answers that probe various aspects of temporal reasoning. We\nadapt several recent state-of-the-art methods for visual question answering to\nthe AQA task, and use DAQA to demonstrate that they perform poorly on questions\nthat require in-depth temporal reasoning. Finally, we propose a new model,\nMultiple Auxiliary Controllers for Linear Modulation (MALiMo) that extends the\nrecent Feature-wise Linear Modulation (FiLM) model and significantly improves\nits temporal reasoning capabilities. We envisage DAQA to foster research on AQA\nand temporal reasoning and MALiMo a step towards models for AQA.\n", "versions": [{"version": "v1", "created": "Thu, 21 Nov 2019 18:26:30 GMT"}], "update_date": "2019-11-22", "authors_parsed": [["Fayek", "Haytham M.", ""], ["Johnson", "Justin", ""]]}, {"id": "1911.09660", "submitter": "Sabber Ahamed", "authors": "Sabber Ahamed", "title": "Estimating uncertainty of earthquake rupture using Bayesian neural\n  network", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG physics.geo-ph", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Bayesian neural networks (BNN) are the probabilistic model that combines the\nstrengths of both neural network (NN) and stochastic processes. As a result,\nBNN can combat overfitting and perform well in applications where data is\nlimited. Earthquake rupture study is such a problem where data is insufficient,\nand scientists have to rely on many trial and error numerical or physical\nmodels. Lack of resources and computational expenses, often, it becomes hard to\ndetermine the reasons behind the earthquake rupture. In this work, a BNN has\nbeen used (1) to combat the small data problem and (2) to find out the\nparameter combinations responsible for earthquake rupture and (3) to estimate\nthe uncertainty associated with earthquake rupture. Two thousand rupture\nsimulations are used to train and test the model. A simple 2D rupture geometry\nis considered where the fault has a Gaussian geometric heterogeneity at the\ncenter, and eight parameters vary in each simulation. The test F1-score of BNN\n(0.8334), which is 2.34% higher than plain NN score. Results show that the\nparameters of rupture propagation have higher uncertainty than the rupture\narrest. Normal stresses play a vital role in determining rupture propagation\nand are also the highest source of uncertainty, followed by the dynamic\nfriction coefficient. Shear stress has a moderate role, whereas the geometric\nfeatures such as the width and height of the fault are least significant and\nuncertain.\n", "versions": [{"version": "v1", "created": "Thu, 21 Nov 2019 18:42:35 GMT"}], "update_date": "2019-11-22", "authors_parsed": [["Ahamed", "Sabber", ""]]}, {"id": "1911.09661", "submitter": "Martin Andrews", "authors": "Sam Witteveen, Martin Andrews", "title": "Paraphrasing with Large Language Models", "comments": "Accepted paper for WNGT workshop at EMNLP-IJCNLP 2019. (7 pages\n  including references and supplemental material)", "journal-ref": null, "doi": "10.18653/v1/D19-5623", "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recently, large language models such as GPT-2 have shown themselves to be\nextremely adept at text generation and have also been able to achieve\nhigh-quality results in many downstream NLP tasks such as text classification,\nsentiment analysis and question answering with the aid of fine-tuning. We\npresent a useful technique for using a large language model to perform the task\nof paraphrasing on a variety of texts and subjects. Our approach is\ndemonstrated to be capable of generating paraphrases not only at a sentence\nlevel but also for longer spans of text such as paragraphs without needing to\nbreak the text into smaller chunks.\n", "versions": [{"version": "v1", "created": "Thu, 21 Nov 2019 18:45:54 GMT"}], "update_date": "2019-11-22", "authors_parsed": [["Witteveen", "Sam", ""], ["Andrews", "Martin", ""]]}, {"id": "1911.09669", "submitter": "Alex Labach", "authors": "Alex Labach and Shahrokh Valaee", "title": "Regularizing Neural Networks by Stochastically Training Layer Ensembles", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Dropout and similar stochastic neural network regularization methods are\noften interpreted as implicitly averaging over a large ensemble of models. We\npropose STE (stochastically trained ensemble) layers, which enhance the\naveraging properties of such methods by training an ensemble of weight matrices\nwith stochastic regularization while explicitly averaging outputs. This\nprovides stronger regularization with no additional computational cost at test\ntime. We show consistent improvement on various image classification tasks\nusing standard network topologies.\n", "versions": [{"version": "v1", "created": "Thu, 21 Nov 2019 18:56:29 GMT"}], "update_date": "2019-11-22", "authors_parsed": [["Labach", "Alex", ""], ["Valaee", "Shahrokh", ""]]}, {"id": "1911.09676", "submitter": "Deepak Pathak", "authors": "Pratyusha Sharma, Deepak Pathak, Abhinav Gupta", "title": "Third-Person Visual Imitation Learning via Decoupled Hierarchical\n  Controller", "comments": "Accepted at NeurIPS 2019. Videos at\n  https://pathak22.github.io/hierarchical-imitation/", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV cs.RO stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study a generalized setup for learning from demonstration to build an\nagent that can manipulate novel objects in unseen scenarios by looking at only\na single video of human demonstration from a third-person perspective. To\naccomplish this goal, our agent should not only learn to understand the intent\nof the demonstrated third-person video in its context but also perform the\nintended task in its environment configuration. Our central insight is to\nenforce this structure explicitly during learning by decoupling what to achieve\n(intended task) from how to perform it (controller). We propose a hierarchical\nsetup where a high-level module learns to generate a series of first-person\nsub-goals conditioned on the third-person video demonstration, and a low-level\ncontroller predicts the actions to achieve those sub-goals. Our agent acts from\nraw image observations without any access to the full state information. We\nshow results on a real robotic platform using Baxter for the manipulation tasks\nof pouring and placing objects in a box. Project video and code are at\nhttps://pathak22.github.io/hierarchical-imitation/\n", "versions": [{"version": "v1", "created": "Thu, 21 Nov 2019 18:59:29 GMT"}], "update_date": "2019-11-22", "authors_parsed": [["Sharma", "Pratyusha", ""], ["Pathak", "Deepak", ""], ["Gupta", "Abhinav", ""]]}, {"id": "1911.09682", "submitter": "Artur Garcia-Saez", "authors": "Artur Garcia-Saez and Jordi Riu", "title": "Quantum Observables for continuous control of the Quantum Approximate\n  Optimization Algorithm via Reinforcement Learning", "comments": "6 pages, 4 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "quant-ph cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a classical control mechanism for Quantum devices using\nReinforcement Learning. Our strategy is applied to the Quantum Approximate\nOptimization Algorithm (QAOA) in order to optimize an objective function that\nencodes a solution to a hard combinatorial problem. This method provides\noptimal control of the Quantum device following a reformulation of QAOA as an\nenvironment where an autonomous classical agent interacts and performs actions\nto achieve higher rewards. This formulation allows a hybrid classical-Quantum\ndevice to train itself from previous executions using a continuous formulation\nof deep Q-learning to control the continuous degrees of freedom of QAOA. Our\napproach makes a selective use of Quantum measurements to complete the\nobservations of the Quantum state available to the agent. We run tests of this\napproach on MAXCUT instances of size up to N = 21 obtaining optimal results. We\nshow how this formulation can be used to transfer the knowledge from shorter\ntraining episodes to reach a regime of longer executions where QAOA delivers\nhigher results.\n", "versions": [{"version": "v1", "created": "Thu, 21 Nov 2019 12:45:52 GMT"}], "update_date": "2019-11-25", "authors_parsed": [["Garcia-Saez", "Artur", ""], ["Riu", "Jordi", ""]]}, {"id": "1911.09704", "submitter": "Tanner Bohn", "authors": "Charles X. Ling and Tanner Bohn", "title": "A Conceptual Framework for Lifelong Learning", "comments": "39 pages, 14 figures, 2 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Humans can learn a variety of concepts and skills incrementally over the\ncourse of their lives while exhibiting many desirable properties, such as\ncontinual learning without forgetting, forward transfer and backward transfer\nof knowledge, and learning a new concept or task with only a few examples.\nSeveral lines of machine learning research, such as lifelong learning, few-shot\nlearning, and transfer learning, attempt to capture these properties. However,\nmost previous approaches can only demonstrate subsets of these properties,\noften by different complex mechanisms. In this work, we propose a simple yet\npowerful unified framework that supports almost all of these properties and\napproaches through one central mechanism. We also draw connections between many\npeculiarities of human learning (such as memory loss and \"rain man\") and our\nframework. While we do not present any state-of-the-art results, we hope that\nthis conceptual framework provides a novel perspective on existing work and\nproposes many new research directions.\n", "versions": [{"version": "v1", "created": "Thu, 21 Nov 2019 19:08:18 GMT"}, {"version": "v2", "created": "Thu, 28 Nov 2019 21:38:51 GMT"}, {"version": "v3", "created": "Tue, 9 Jun 2020 23:01:24 GMT"}, {"version": "v4", "created": "Mon, 15 Jun 2020 18:34:47 GMT"}], "update_date": "2020-06-17", "authors_parsed": [["Ling", "Charles X.", ""], ["Bohn", "Tanner", ""]]}, {"id": "1911.09715", "submitter": "Talha Khan", "authors": "Yun Chen, Xingqin Lin, Talha Khan, Mohammad Mozaffari", "title": "Efficient Drone Mobility Support Using Reinforcement Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IT cs.LG eess.SP math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Flying drones can be used in a wide range of applications and services from\nsurveillance to package delivery. To ensure robust control and safety of drone\noperations, cellular networks need to provide reliable wireless connectivity to\ndrone user equipments (UEs). To date, existing mobile networks have been\nprimarily designed and optimized for serving ground UEs, thus making the\nmobility support in the sky challenging. In this paper, a novel handover (HO)\nmechanism is developed for a cellular-connected drone system to ensure robust\nwireless connectivity and mobility support for drone-UEs. By leveraging tools\nfrom reinforcement learning, HO decisions are dynamically optimized using a\nQ-learning algorithm to provide an efficient mobility support in the sky. The\nresults show that the proposed approach can significantly reduce (e.g., by 80%)\nthe number of HOs, while maintaining connectivity, compared to the baseline HO\nscheme in which the drone always connects to the strongest cell.\n", "versions": [{"version": "v1", "created": "Thu, 21 Nov 2019 19:27:16 GMT"}], "update_date": "2019-11-25", "authors_parsed": [["Chen", "Yun", ""], ["Lin", "Xingqin", ""], ["Khan", "Talha", ""], ["Mozaffari", "Mohammad", ""]]}, {"id": "1911.09721", "submitter": "Raj Kumar Maity", "authors": "Avishek Ghosh, Raj Kumar Maity, Swanand Kadhe, Arya Mazumdar and\n  Kannan Ramchandran", "title": "Communication-Efficient and Byzantine-Robust Distributed Learning with\n  Error Feedback", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.DC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We develop a communication-efficient distributed learning algorithm that is\nrobust against Byzantine worker machines. We propose and analyze a distributed\ngradient-descent algorithm that performs a simple thresholding based on\ngradient norms to mitigate Byzantine failures. We show the (statistical)\nerror-rate of our algorithm matches that of Yin et al.~\\cite{dong}, which uses\nmore complicated schemes (coordinate-wise median, trimmed mean). Furthermore,\nfor communication efficiency, we consider a generic class of\n$\\delta$-approximate compressors from Karimireddi et al.~\\cite{errorfeed} that\nencompasses sign-based compressors and top-$k$ sparsification. Our algorithm\nuses compressed gradients and gradient norms for aggregation and Byzantine\nremoval respectively. We establish the statistical error rate for non-convex\nsmooth loss functions. We show that, in certain range of the compression factor\n$\\delta$, the (order-wise) rate of convergence is not affected by the\ncompression operation. Moreover, we analyze the compressed gradient descent\nalgorithm with error feedback (proposed in \\cite{errorfeed}) in a distributed\nsetting and in the presence of Byzantine worker machines. We show that\nexploiting error feedback improves the statistical error rate. Finally, we\nexperimentally validate our results and show good performance in convergence\nfor convex (least-square regression) and non-convex (neural network training)\nproblems.\n", "versions": [{"version": "v1", "created": "Thu, 21 Nov 2019 19:39:53 GMT"}, {"version": "v2", "created": "Sun, 10 May 2020 20:04:58 GMT"}, {"version": "v3", "created": "Fri, 10 Jul 2020 20:27:47 GMT"}, {"version": "v4", "created": "Thu, 11 Mar 2021 20:21:26 GMT"}], "update_date": "2021-03-15", "authors_parsed": [["Ghosh", "Avishek", ""], ["Maity", "Raj Kumar", ""], ["Kadhe", "Swanand", ""], ["Mazumdar", "Arya", ""], ["Ramchandran", "Kannan", ""]]}, {"id": "1911.09722", "submitter": "A Lakshmi", "authors": "Lakshmi Annamalai, Anirban Chakraborty and Chetan Singh Thakur", "title": "EvAn: Neuromorphic Event-based Anomaly Detection", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG eess.IV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Event-based cameras are bio-inspired novel sensors that asynchronously record\nchanges in illumination in the form of events, thus resulting in significant\nadvantages over conventional cameras in terms of low power utilization, high\ndynamic range, and no motion blur. Moreover, such cameras, by design, encode\nonly the relative motion between the scene and the sensor (and not the static\nbackground) to yield a very sparse data structure, which can be utilized for\nvarious motion analytics tasks. In this paper, for the first time in event data\nanalytics community, we leverage these advantages of an event camera towards a\ncritical vision application - video anomaly detection. We propose to model the\nmotion dynamics in the event domain with dual discriminator conditional\nGenerative adversarial Network (cGAN) built on state-of-the-art architectures.\nTo adapt event data for using as input to cGAN, we also put forward a deep\nlearning solution to learn a novel representation of event data, which retains\nthe sparsity of the data as well as encode the temporal information readily\navailable from these sensors. Since there is no existing dataset for anomaly\ndetection in event domain, we also provide an anomaly detection event dataset\nwith an exhaustive set of anomalies. Careful analysis reveals that the proposed\nmethod results in huge reduction in computational complexity as compared to\nprevious state-of-the-art conventional anomaly detection networks.\n", "versions": [{"version": "v1", "created": "Thu, 21 Nov 2019 19:43:51 GMT"}, {"version": "v2", "created": "Sat, 15 Feb 2020 19:23:42 GMT"}], "update_date": "2020-02-18", "authors_parsed": [["Annamalai", "Lakshmi", ""], ["Chakraborty", "Anirban", ""], ["Thakur", "Chetan Singh", ""]]}, {"id": "1911.09724", "submitter": "Xiuyuan Lu", "authors": "Xiuyuan Lu, Benjamin Van Roy", "title": "Information-Theoretic Confidence Bounds for Reinforcement Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We integrate information-theoretic concepts into the design and analysis of\noptimistic algorithms and Thompson sampling. By making a connection between\ninformation-theoretic quantities and confidence bounds, we obtain results that\nrelate the per-period performance of the agent with its information gain about\nthe environment, thus explicitly characterizing the exploration-exploitation\ntradeoff. The resulting cumulative regret bound depends on the agent's\nuncertainty over the environment and quantifies the value of prior information.\nWe show applicability of this approach to several environments, including\nlinear bandits, tabular MDPs, and factored MDPs. These examples demonstrate the\npotential of a general information-theoretic approach for the design and\nanalysis of reinforcement learning algorithms.\n", "versions": [{"version": "v1", "created": "Thu, 21 Nov 2019 19:48:43 GMT"}], "update_date": "2019-11-25", "authors_parsed": [["Lu", "Xiuyuan", ""], ["Van Roy", "Benjamin", ""]]}, {"id": "1911.09728", "submitter": "Yacine Jernite", "authors": "Xinyi Wang, Jason Weston, Michael Auli, Yacine Jernite", "title": "Improving Conditioning in Context-Aware Sequence to Sequence Models", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Neural sequence to sequence models are well established for applications\nwhich can be cast as mapping a single input sequence into a single output\nsequence. In this work, we focus on cases where generation is conditioned on\nboth a short query and a long context, such as abstractive question answering\nor document-level translation. We modify the standard sequence-to-sequence\napproach to make better use of both the query and the context by expanding the\nconditioning mechanism to intertwine query and context attention. We also\nintroduce a simple and efficient data augmentation method for the proposed\nmodel. Experiments on three different tasks show that both changes lead to\nconsistent improvements.\n", "versions": [{"version": "v1", "created": "Thu, 21 Nov 2019 20:01:46 GMT"}], "update_date": "2019-11-25", "authors_parsed": [["Wang", "Xinyi", ""], ["Weston", "Jason", ""], ["Auli", "Michael", ""], ["Jernite", "Yacine", ""]]}, {"id": "1911.09731", "submitter": "Konstantin Ushenin", "authors": "Konstantin Ushenin, Tatyana Nesterova, Dmitry Shmarko, Vladimir\n  Sholokhov", "title": "Phase mapping for cardiac unipolar electrograms with neural network\n  instead of phase transformation", "comments": null, "journal-ref": null, "doi": "10.1109/USBEREIT48449.2020.9117627", "report-no": null, "categories": "eess.SP cs.LG q-bio.TO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A phase mapping is an approach to processing signals of electrograms recorded\nfrom the surface of cardiac tissue. The main concept of phase mapping is the\napplication of the phase transformation with the aim to obtain signals with\nuseful properties. In our study, we propose to use a simple sawtooth signal\ninstead of a phase signal for processing of electrogram data and building of\nthe phase maps. We denote transformation that can provide this signal as a\nphase-like transformation (PLT). PLT defined via a convolutional neural network\nthat is trained on a dataset from computer models of cardiac tissue\nelectrophysiology. The proposed approaches were validated on data from the\ndetailed personalized model of the human torso electrophysiology. This paper\nincludes visualization of the phase map based on PLT and shows the robustness\nof the proposed approaches in the analysis of the complex non-stationary\nperiodic activity of the excitable cardiac tissue.\n", "versions": [{"version": "v1", "created": "Thu, 21 Nov 2019 20:19:04 GMT"}, {"version": "v2", "created": "Sun, 16 Feb 2020 19:40:29 GMT"}, {"version": "v3", "created": "Tue, 13 Apr 2021 14:08:51 GMT"}], "update_date": "2021-04-14", "authors_parsed": [["Ushenin", "Konstantin", ""], ["Nesterova", "Tatyana", ""], ["Shmarko", "Dmitry", ""], ["Sholokhov", "Vladimir", ""]]}, {"id": "1911.09732", "submitter": "Yu Meng", "authors": "Yu Meng, Maryam Karimzadehgan, Honglei Zhuang, Donald Metzler", "title": "Separate and Attend in Personal Email Search", "comments": "WSDM 2020", "journal-ref": null, "doi": "10.1145/3336191.3371775", "report-no": null, "categories": "cs.IR cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In personal email search, user queries often impose different requirements on\ndifferent aspects of the retrieved emails. For example, the query \"my recent\nflight to the US\" requires emails to be ranked based on both textual contents\nand recency of the email documents, while other queries such as \"medical\nhistory\" do not impose any constraints on the recency of the email. Recent deep\nlearning-to-rank models for personal email search often directly concatenate\ndense numerical features (e.g., document age) with embedded sparse features\n(e.g., n-gram embeddings). In this paper, we first show with a set of\nexperiments on synthetic datasets that direct concatenation of dense and sparse\nfeatures does not lead to the optimal search performance of deep neural ranking\nmodels. To effectively incorporate both sparse and dense email features into\npersonal email search ranking, we propose a novel neural model, SepAttn.\nSepAttn first builds two separate neural models to learn from sparse and dense\nfeatures respectively, and then applies an attention mechanism at the\nprediction level to derive the final prediction from these two models. We\nconduct a comprehensive set of experiments on a large-scale email search\ndataset, and demonstrate that our SepAttn model consistently improves the\nsearch quality over the baseline models.\n", "versions": [{"version": "v1", "created": "Thu, 21 Nov 2019 20:19:28 GMT"}], "update_date": "2019-11-25", "authors_parsed": [["Meng", "Yu", ""], ["Karimzadehgan", "Maryam", ""], ["Zhuang", "Honglei", ""], ["Metzler", "Donald", ""]]}, {"id": "1911.09737", "submitter": "Saurabh Singh", "authors": "Saurabh Singh, Shankar Krishnan", "title": "Filter Response Normalization Layer: Eliminating Batch Dependence in the\n  Training of Deep Neural Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Batch Normalization (BN) uses mini-batch statistics to normalize the\nactivations during training, introducing dependence between mini-batch\nelements. This dependency can hurt the performance if the mini-batch size is\ntoo small, or if the elements are correlated. Several alternatives, such as\nBatch Renormalization and Group Normalization (GN), have been proposed to\naddress this issue. However, they either do not match the performance of BN for\nlarge batches, or still exhibit degradation in performance for smaller batches,\nor introduce artificial constraints on the model architecture. In this paper we\npropose the Filter Response Normalization (FRN) layer, a novel combination of a\nnormalization and an activation function, that can be used as a replacement for\nother normalizations and activations. Our method operates on each activation\nchannel of each batch element independently, eliminating the dependency on\nother batch elements. Our method outperforms BN and other alternatives in a\nvariety of settings for all batch sizes. FRN layer performs $\\approx 0.7-1.0\\%$\nbetter than BN on top-1 validation accuracy with large mini-batch sizes for\nImagenet classification using InceptionV3 and ResnetV2-50 architectures.\nFurther, it performs $>1\\%$ better than GN on the same problem in the small\nmini-batch size regime. For object detection problem on COCO dataset, FRN layer\noutperforms all other methods by at least $0.3-0.5\\%$ in all batch size\nregimes.\n", "versions": [{"version": "v1", "created": "Thu, 21 Nov 2019 20:32:04 GMT"}, {"version": "v2", "created": "Wed, 1 Apr 2020 04:19:08 GMT"}], "update_date": "2020-04-02", "authors_parsed": [["Singh", "Saurabh", ""], ["Krishnan", "Shankar", ""]]}, {"id": "1911.09762", "submitter": "Zhiyun Lu", "authors": "Zhiyun Lu, Liangliang Cao, Yu Zhang, Chung-Cheng Chiu, James Fan", "title": "Speech Sentiment Analysis via Pre-trained Features from End-to-end ASR\n  Models", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG eess.AS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we propose to use pre-trained features from end-to-end ASR\nmodels to solve speech sentiment analysis as a down-stream task. We show that\nend-to-end ASR features, which integrate both acoustic and text information\nfrom speech, achieve promising results. We use RNN with self-attention as the\nsentiment classifier, which also provides an easy visualization through\nattention weights to help interpret model predictions. We use well benchmarked\nIEMOCAP dataset and a new large-scale speech sentiment dataset SWBD-sentiment\nfor evaluation. Our approach improves the-state-of-the-art accuracy on IEMOCAP\nfrom 66.6% to 71.7%, and achieves an accuracy of 70.10% on SWBD-sentiment with\nmore than 49,500 utterances.\n", "versions": [{"version": "v1", "created": "Thu, 21 Nov 2019 21:38:36 GMT"}, {"version": "v2", "created": "Thu, 5 Mar 2020 00:21:49 GMT"}], "update_date": "2020-03-06", "authors_parsed": [["Lu", "Zhiyun", ""], ["Cao", "Liangliang", ""], ["Zhang", "Yu", ""], ["Chiu", "Chung-Cheng", ""], ["Fan", "James", ""]]}, {"id": "1911.09771", "submitter": "Ruqi Zhang", "authors": "Ruqi Zhang and Christopher De Sa", "title": "Poisson-Minibatching for Gibbs Sampling with Convergence Rate Guarantees", "comments": "Published at NeurIPS 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Gibbs sampling is a Markov chain Monte Carlo method that is often used for\nlearning and inference on graphical models. Minibatching, in which a small\nrandom subset of the graph is used at each iteration, can help make Gibbs\nsampling scale to large graphical models by reducing its computational cost. In\nthis paper, we propose a new auxiliary-variable minibatched Gibbs sampling\nmethod, {\\it Poisson-minibatching Gibbs}, which both produces unbiased samples\nand has a theoretical guarantee on its convergence rate. In comparison to\nprevious minibatched Gibbs algorithms, Poisson-minibatching Gibbs supports fast\nsampling from continuous state spaces and avoids the need for a\nMetropolis-Hastings correction on discrete state spaces. We demonstrate the\neffectiveness of our method on multiple applications and in comparison with\nboth plain Gibbs and previous minibatched methods.\n", "versions": [{"version": "v1", "created": "Thu, 21 Nov 2019 22:05:51 GMT"}], "update_date": "2019-11-25", "authors_parsed": [["Zhang", "Ruqi", ""], ["De Sa", "Christopher", ""]]}, {"id": "1911.09776", "submitter": "Purushottam Dixit", "authors": "Purushottam D. Dixit", "title": "TMI: Thermodynamic inference of data manifolds", "comments": null, "journal-ref": "Phys. Rev. Research 2, 023201 (2020)", "doi": "10.1103/PhysRevResearch.2.023201", "report-no": null, "categories": "cond-mat.stat-mech cs.LG q-bio.QM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The Gibbs-Boltzmann distribution offers a physically interpretable way to\nmassively reduce the dimensionality of high dimensional probability\ndistributions where the extensive variables are `features' and the intensive\nvariables are `descriptors'. However, not all probability distributions can be\nmodeled using the Gibbs-Boltzmann form. Here, we present TMI: TMI, {\\bf\nT}hermodynamic {\\bf M}anifold {\\bf I}nference; a thermodynamic approach to\napproximate a collection of arbitrary distributions. TMI simultaneously learns\nfrom data intensive and extensive variables and achieves dimensionality\nreduction through a multiplicative, positive valued, and interpretable\ndecomposition of the data. Importantly, the reduced dimensional space of\nintensive parameters is not homogeneous. The Gibbs-Boltzmann distribution\ndefines an analytically tractable Riemannian metric on the space of intensive\nvariables allowing us to calculate geodesics and volume elements. We discuss\nthe applications of TMI with multiple real and artificial data sets. Possible\nextensions are discussed as well.\n", "versions": [{"version": "v1", "created": "Thu, 21 Nov 2019 22:52:56 GMT"}], "update_date": "2020-05-27", "authors_parsed": [["Dixit", "Purushottam D.", ""]]}, {"id": "1911.09777", "submitter": "Stacey Truex", "authors": "Stacey Truex, Ling Liu, Mehmet Emre Gursoy, Wenqi Wei, Lei Yu", "title": "Effects of Differential Privacy and Data Skewness on Membership\n  Inference Vulnerability", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Membership inference attacks seek to infer the membership of individual\ntraining instances of a privately trained model. This paper presents a\nmembership privacy analysis and evaluation system, called MPLens, with three\nunique contributions. First, through MPLens, we demonstrate how membership\ninference attack methods can be leveraged in adversarial machine learning.\nSecond, through MPLens, we highlight how the vulnerability of pre-trained\nmodels under membership inference attack is not uniform across all classes,\nparticularly when the training data itself is skewed. We show that risk from\nmembership inference attacks is routinely increased when models use skewed\ntraining data. Finally, we investigate the effectiveness of differential\nprivacy as a mitigation technique against membership inference attacks. We\ndiscuss the trade-offs of implementing such a mitigation strategy with respect\nto the model complexity, the learning task complexity, the dataset complexity\nand the privacy parameter settings. Our empirical results reveal that (1)\nminority groups within skewed datasets display increased risk for membership\ninference and (2) differential privacy presents many challenging trade-offs as\na mitigation technique to membership inference risk.\n", "versions": [{"version": "v1", "created": "Thu, 21 Nov 2019 22:54:40 GMT"}], "update_date": "2019-11-25", "authors_parsed": [["Truex", "Stacey", ""], ["Liu", "Ling", ""], ["Gursoy", "Mehmet Emre", ""], ["Wei", "Wenqi", ""], ["Yu", "Lei", ""]]}, {"id": "1911.09781", "submitter": "Lu Jiang", "authors": "Lu Jiang, Di Huang, Mason Liu, Weilong Yang", "title": "Beyond Synthetic Noise: Deep Learning on Controlled Noisy Labels", "comments": "published at ICML 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Performing controlled experiments on noisy data is essential in understanding\ndeep learning across noise levels. Due to the lack of suitable datasets,\nprevious research has only examined deep learning on controlled synthetic label\nnoise, and real-world label noise has never been studied in a controlled\nsetting. This paper makes three contributions. First, we establish the first\nbenchmark of controlled real-world label noise from the web. This new benchmark\nenables us to study the web label noise in a controlled setting for the first\ntime. The second contribution is a simple but effective method to overcome both\nsynthetic and real noisy labels. We show that our method achieves the best\nresult on our dataset as well as on two public benchmarks (CIFAR and\nWebVision). Third, we conduct the largest study by far into understanding deep\nneural networks trained on noisy labels across different noise levels, noise\ntypes, network architectures, and training settings. The data and code are\nreleased at the following link: http://www.lujiang.info/cnlw.html\n", "versions": [{"version": "v1", "created": "Thu, 21 Nov 2019 23:05:28 GMT"}, {"version": "v2", "created": "Tue, 30 Jun 2020 03:27:24 GMT"}, {"version": "v3", "created": "Thu, 27 Aug 2020 06:07:44 GMT"}], "update_date": "2020-08-28", "authors_parsed": [["Jiang", "Lu", ""], ["Huang", "Di", ""], ["Liu", "Mason", ""], ["Yang", "Weilong", ""]]}, {"id": "1911.09783", "submitter": "Amir Zadeh", "authors": "Amir Zadeh, Tianjun Ma, Soujanya Poria, Louis-Philippe Morency", "title": "WildMix Dataset and Spectro-Temporal Transformer Model for Monoaural\n  Audio Source Separation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.SD eess.AS stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Monoaural audio source separation is a challenging research area in machine\nlearning. In this area, a mixture containing multiple audio sources is given,\nand a model is expected to disentangle the mixture into isolated atomic\nsources. In this paper, we first introduce a challenging new dataset for\nmonoaural source separation called WildMix. WildMix is designed with the goal\nof extending the boundaries of source separation beyond what previous datasets\nin this area would allow. It contains diverse in-the-wild recordings from 25\ndifferent sound classes, combined with each other using arbitrary composition\npolicies. Source separation often requires modeling long-range dependencies in\nboth temporal and spectral domains. To this end, we introduce a novel\ntrasnformer-based model called Spectro-Temporal Transformer (STT). STT utilizes\na specialized encoder, called Spectro-Temporal Encoder (STE). STE highlights\ntemporal and spectral components of sources within a mixture, using a\nself-attention mechanism. It subsequently disentangles them in a hierarchical\nmanner. In our experiments, STT swiftly outperforms various previous baselines\nfor monoaural source separation on the challenging WildMix dataset.\n", "versions": [{"version": "v1", "created": "Thu, 21 Nov 2019 23:23:02 GMT"}], "update_date": "2019-11-25", "authors_parsed": [["Zadeh", "Amir", ""], ["Ma", "Tianjun", ""], ["Poria", "Soujanya", ""], ["Morency", "Louis-Philippe", ""]]}, {"id": "1911.09785", "submitter": "David Berthelot", "authors": "David Berthelot, Nicholas Carlini, Ekin D. Cubuk, Alex Kurakin, Kihyuk\n  Sohn, Han Zhang, Colin Raffel", "title": "ReMixMatch: Semi-Supervised Learning with Distribution Alignment and\n  Augmentation Anchoring", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We improve the recently-proposed \"MixMatch\" semi-supervised learning\nalgorithm by introducing two new techniques: distribution alignment and\naugmentation anchoring. Distribution alignment encourages the marginal\ndistribution of predictions on unlabeled data to be close to the marginal\ndistribution of ground-truth labels. Augmentation anchoring feeds multiple\nstrongly augmented versions of an input into the model and encourages each\noutput to be close to the prediction for a weakly-augmented version of the same\ninput. To produce strong augmentations, we propose a variant of AutoAugment\nwhich learns the augmentation policy while the model is being trained. Our new\nalgorithm, dubbed ReMixMatch, is significantly more data-efficient than prior\nwork, requiring between $5\\times$ and $16\\times$ less data to reach the same\naccuracy. For example, on CIFAR-10 with 250 labeled examples we reach $93.73\\%$\naccuracy (compared to MixMatch's accuracy of $93.58\\%$ with $4{,}000$ examples)\nand a median accuracy of $84.92\\%$ with just four labels per class. We make our\ncode and data open-source at https://github.com/google-research/remixmatch.\n", "versions": [{"version": "v1", "created": "Thu, 21 Nov 2019 23:44:25 GMT"}, {"version": "v2", "created": "Thu, 13 Feb 2020 23:14:46 GMT"}], "update_date": "2020-02-17", "authors_parsed": [["Berthelot", "David", ""], ["Carlini", "Nicholas", ""], ["Cubuk", "Ekin D.", ""], ["Kurakin", "Alex", ""], ["Sohn", "Kihyuk", ""], ["Zhang", "Han", ""], ["Raffel", "Colin", ""]]}, {"id": "1911.09787", "submitter": "Busra Celikkaya", "authors": "Ming Zhu, Busra Celikkaya, Parminder Bhatia, Chandan K. Reddy", "title": "LATTE: Latent Type Modeling for Biomedical Entity Linking", "comments": "AAAI 2020 Conference", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.IR cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Entity linking is the task of linking mentions of named entities in natural\nlanguage text, to entities in a curated knowledge-base. This is of significant\nimportance in the biomedical domain, where it could be used to semantically\nannotate a large volume of clinical records and biomedical literature, to\nstandardized concepts described in an ontology such as Unified Medical Language\nSystem (UMLS). We observe that with precise type information, entity\ndisambiguation becomes a straightforward task. However, fine-grained type\ninformation is usually not available in biomedical domain. Thus, we propose\nLATTE, a LATent Type Entity Linking model, that improves entity linking by\nmodeling the latent fine-grained type information about mentions and entities.\nUnlike previous methods that perform entity linking directly between the\nmentions and the entities, LATTE jointly does entity disambiguation, and latent\nfine-grained type learning, without direct supervision. We evaluate our model\non two biomedical datasets: MedMentions, a large scale public dataset annotated\nwith UMLS concepts, and a de-identified corpus of dictated doctor's notes that\nhas been annotated with ICD concepts. Extensive experimental evaluation shows\nour model achieves significant performance improvements over several\nstate-of-the-art techniques.\n", "versions": [{"version": "v1", "created": "Thu, 21 Nov 2019 23:55:15 GMT"}, {"version": "v2", "created": "Mon, 20 Jan 2020 23:17:27 GMT"}], "update_date": "2020-01-22", "authors_parsed": [["Zhu", "Ming", ""], ["Celikkaya", "Busra", ""], ["Bhatia", "Parminder", ""], ["Reddy", "Chandan K.", ""]]}, {"id": "1911.09788", "submitter": "Yu-Ming Shang", "authors": "Yuming Shang", "title": "Are Noisy Sentences Useless for Distant Supervised Relation Extraction?", "comments": "9 pages 5 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The noisy labeling problem has been one of the major obstacles for distant\nsupervised relation extraction. Existing approaches usually consider that the\nnoisy sentences are useless and will harm the model's performance. Therefore,\nthey mainly alleviate this problem by reducing the influence of noisy\nsentences, such as applying bag-level selective attention or removing noisy\nsentences from sentence-bags. However, the underlying cause of the noisy\nlabeling problem is not the lack of useful information, but the missing\nrelation labels. Intuitively, if we can allocate credible labels for noisy\nsentences, they will be transformed into useful training data and benefit the\nmodel's performance. Thus, in this paper, we propose a novel method for distant\nsupervised relation extraction, which employs unsupervised deep clustering to\ngenerate reliable labels for noisy sentences. Specifically, our model contains\nthree modules: a sentence encoder, a noise detector and a label generator. The\nsentence encoder is used to obtain feature representations. The noise detector\ndetects noisy sentences from sentence-bags, and the label generator produces\nhigh-confidence relation labels for noisy sentences. Extensive experimental\nresults demonstrate that our model outperforms the state-of-the-art baselines\non a popular benchmark dataset, and can indeed alleviate the noisy labeling\nproblem.\n", "versions": [{"version": "v1", "created": "Fri, 22 Nov 2019 00:00:31 GMT"}], "update_date": "2019-11-25", "authors_parsed": [["Shang", "Yuming", ""]]}, {"id": "1911.09798", "submitter": "Sebastian Bruch", "authors": "Sebastian Bruch", "title": "An Alternative Cross Entropy Loss for Learning-to-Rank", "comments": null, "journal-ref": null, "doi": "10.1145/3442381.3449794", "report-no": null, "categories": "cs.LG cs.IR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Listwise learning-to-rank methods form a powerful class of ranking algorithms\nthat are widely adopted in applications such as information retrieval. These\nalgorithms learn to rank a set of items by optimizing a loss that is a function\nof the entire set -- as a surrogate to a typically non-differentiable ranking\nmetric. Despite their empirical success, existing listwise methods are based on\nheuristics and remain theoretically ill-understood. In particular, none of the\nempirically successful loss functions are related to ranking metrics. In this\nwork, we propose a cross entropy-based learning-to-rank loss function that is\ntheoretically sound, is a convex bound on NDCG -- a popular ranking metric --\nand is consistent with NDCG under learning scenarios common in information\nretrieval. Furthermore, empirical evaluation of an implementation of the\nproposed method with gradient boosting machines on benchmark learning-to-rank\ndatasets demonstrates the superiority of our proposed formulation over existing\nalgorithms in quality and robustness.\n", "versions": [{"version": "v1", "created": "Fri, 22 Nov 2019 00:58:11 GMT"}, {"version": "v2", "created": "Wed, 27 Nov 2019 01:14:31 GMT"}, {"version": "v3", "created": "Wed, 20 May 2020 19:41:23 GMT"}, {"version": "v4", "created": "Fri, 22 May 2020 12:51:42 GMT"}, {"version": "v5", "created": "Thu, 4 Feb 2021 19:02:56 GMT"}], "update_date": "2021-02-08", "authors_parsed": [["Bruch", "Sebastian", ""]]}, {"id": "1911.09804", "submitter": "Zhijie Deng", "authors": "Zhijie Deng, Yucen Luo, Jun Zhu, Bo Zhang", "title": "Measuring Uncertainty through Bayesian Learning of Deep Neural Network\n  Structure", "comments": "2nd Workshop on Neural Architecture Search at ICLR 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Bayesian neural networks (BNNs) augment deep networks with uncertainty\nquantification by Bayesian treatment of the network weights. However, such\nmodels face the challenge of Bayesian inference in a high-dimensional and\nusually over-parameterized space. This paper investigates a new line of\nBayesian deep learning by performing Bayesian inference on network structure.\nInstead of building structure from scratch inefficiently, we draw inspirations\nfrom neural architecture search to represent the network structure. We then\ndevelop an efficient stochastic variational inference approach which unifies\nthe learning of both network structure and weights. Empirically, our method\nexhibits competitive predictive performance while preserving the benefits of\nBayesian principles across challenging scenarios. We also provide convincing\nexperimental justification for our modeling choice.\n", "versions": [{"version": "v1", "created": "Fri, 22 Nov 2019 01:31:28 GMT"}, {"version": "v2", "created": "Tue, 6 Oct 2020 02:31:19 GMT"}, {"version": "v3", "created": "Sat, 27 Mar 2021 08:51:47 GMT"}], "update_date": "2021-03-30", "authors_parsed": [["Deng", "Zhijie", ""], ["Luo", "Yucen", ""], ["Zhu", "Jun", ""], ["Zhang", "Bo", ""]]}, {"id": "1911.09812", "submitter": "M Saiful Bari", "authors": "M Saiful Bari and Shafiq Joty and Prathyusha Jwalapuram", "title": "Zero-Resource Cross-Lingual Named Entity Recognition", "comments": null, "journal-ref": "Proceedings of the 34th AAAI Conference on Artificial Intelligence\n  (AAAI-2020)", "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recently, neural methods have achieved state-of-the-art (SOTA) results in\nNamed Entity Recognition (NER) tasks for many languages without the need for\nmanually crafted features. However, these models still require manually\nannotated training data, which is not available for many languages. In this\npaper, we propose an unsupervised cross-lingual NER model that can transfer NER\nknowledge from one language to another in a completely unsupervised way without\nrelying on any bilingual dictionary or parallel data. Our model achieves this\nthrough word-level adversarial learning and augmented fine-tuning with\nparameter sharing and feature augmentation. Experiments on five different\nlanguages demonstrate the effectiveness of our approach, outperforming existing\nmodels by a good margin and setting a new SOTA for each language pair.\n", "versions": [{"version": "v1", "created": "Fri, 22 Nov 2019 02:09:08 GMT"}], "update_date": "2019-11-25", "authors_parsed": [["Bari", "M Saiful", ""], ["Joty", "Shafiq", ""], ["Jwalapuram", "Prathyusha", ""]]}, {"id": "1911.09815", "submitter": "Sina Baharlouei", "authors": "Maziar Sanjabi, Sina Baharlouei, Meisam Razaviyayn, Jason D. Lee", "title": "When Does Non-Orthogonal Tensor Decomposition Have No Spurious Local\n  Minima?", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the optimization problem for decomposing $d$ dimensional\nfourth-order Tensors with $k$ non-orthogonal components. We derive\n\\textit{deterministic} conditions under which such a problem does not have\nspurious local minima. In particular, we show that if $\\kappa =\n\\frac{\\lambda_{max}}{\\lambda_{min}} < \\frac{5}{4}$, and incoherence coefficient\nis of the order $O(\\frac{1}{\\sqrt{d}})$, then all the local minima are globally\noptimal. Using standard techniques, these conditions could be easily\ntransformed into conditions that would hold with high probability in high\ndimensions when the components are generated randomly. Finally, we prove that\nthe tensor power method with deflation and restarts could efficiently extract\nall the components within a tolerance level $O(\\kappa \\sqrt{k\\tau^3})$ that\nseems to be the noise floor of non-orthogonal tensor decomposition.\n", "versions": [{"version": "v1", "created": "Fri, 22 Nov 2019 02:28:44 GMT"}], "update_date": "2019-11-25", "authors_parsed": [["Sanjabi", "Maziar", ""], ["Baharlouei", "Sina", ""], ["Razaviyayn", "Meisam", ""], ["Lee", "Jason D.", ""]]}, {"id": "1911.09818", "submitter": "Jing Pan", "authors": "Jing Pan, Weian Sheng, Santanu Dey", "title": "Order Matters at Fanatics Recommending Sequentially Ordered Products by\n  LSTM Embedded with Word2Vec", "comments": "5 pages, 2 figures, KDD 2019 Workshop, Deep Learning on Graphics,", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CL cs.IR stat.ML", "license": "http://creativecommons.org/publicdomain/zero/1.0/", "abstract": "  A unique challenge for e-commerce recommendation is that customers are often\ninterested in products that are more advanced than their already purchased\nproducts, but not reversed. The few existing recommender systems modeling\nunidirectional sequence output a limited number of categories or continuous\nvariables. To model the ordered sequence, we design the first recommendation\nsystem that both embed purchased items with Word2Vec, and model the sequence\nwith stateless LSTM RNN. The click-through rate of this recommender system in\nproduction outperforms its solely Word2Vec based predecessor. Developed in\n2017, it was perhaps the first published real-world application that makes\ndistributed predictions of a single machine trained Keras model on Spark slave\nnodes at a scale of more than 0.4 million columns per row.\n", "versions": [{"version": "v1", "created": "Fri, 22 Nov 2019 02:39:41 GMT"}], "update_date": "2019-11-25", "authors_parsed": [["Pan", "Jing", ""], ["Sheng", "Weian", ""], ["Dey", "Santanu", ""]]}, {"id": "1911.09821", "submitter": "Canran Xu", "authors": "Canran Xu, Ming Wu", "title": "Learning Feature Interactions with Lorentzian Factorization Machine", "comments": "8 pages, 5 figures, accepted to AAAI-2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.AI cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Learning representations for feature interactions to model user behaviors is\ncritical for recommendation system and click-trough rate (CTR) predictions.\nRecent advances in this area are empowered by deep learning methods which could\nlearn sophisticated feature interactions and achieve the state-of-the-art\nresult in an end-to-end manner. These approaches require large number of\ntraining parameters integrated with the low-level representations, and thus are\nmemory and computational inefficient. In this paper, we propose a new model\nnamed \"LorentzFM\" that can learn feature interactions embedded in a hyperbolic\nspace in which the violation of triangle inequality for Lorentz distances is\navailable. To this end, the learned representation is benefited by the peculiar\ngeometric properties of hyperbolic triangles, and result in a significant\nreduction in the number of parameters (20\\% to 80\\%) because all the top deep\nlearning layers are not required. With such a lightweight architecture,\nLorentzFM achieves comparable and even materially better results than the deep\nlearning methods such as DeepFM, xDeepFM and Deep \\& Cross in both\nrecommendation and CTR prediction tasks.\n", "versions": [{"version": "v1", "created": "Fri, 22 Nov 2019 02:43:39 GMT"}], "update_date": "2019-11-26", "authors_parsed": [["Xu", "Canran", ""], ["Wu", "Ming", ""]]}, {"id": "1911.09824", "submitter": "Ren Bing", "authors": "Shengwen Yang, Bing Ren, Xuhui Zhou, Liping Liu", "title": "Parallel Distributed Logistic Regression for Vertical Federated Learning\n  without Third-Party Coordinator", "comments": "IJCAI-19 Workshop on Federated Machine Learning for User Privacy and\n  Data Confidentiality (IJCAI (FML)) 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Federated Learning is a new distributed learning mechanism which allows model\ntraining on a large corpus of decentralized data owned by different data\nproviders, without sharing or leakage of raw data. According to the\ncharacteristics of data dis-tribution, it could be usually classified into\nthree categories: horizontal federated learning, vertical federated learning,\nand federated transfer learning. In this paper we present a solution for\nparallel dis-tributed logistic regression for vertical federated learning. As\ncompared with existing works, the role of third-party coordinator is removed in\nour proposed solution. The system is built on the pa-rameter server\narchitecture and aims to speed up the model training via utilizing a cluster of\nservers in case of large volume of training data. We also evaluate the\nperformance of the parallel distributed model training and the experimental\nresults show the great scalability of the system.\n", "versions": [{"version": "v1", "created": "Fri, 22 Nov 2019 02:57:01 GMT"}], "update_date": "2019-11-25", "authors_parsed": [["Yang", "Shengwen", ""], ["Ren", "Bing", ""], ["Zhou", "Xuhui", ""], ["Liu", "Liping", ""]]}, {"id": "1911.09826", "submitter": "Amir Zadeh", "authors": "Amir Zadeh, Chengfeng Mao, Kelly Shi, Yiwei Zhang, Paul Pu Liang,\n  Soujanya Poria, Louis-Philippe Morency", "title": "Factorized Multimodal Transformer for Multimodal Sequential Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CL stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The complex world around us is inherently multimodal and sequential\n(continuous). Information is scattered across different modalities and requires\nmultiple continuous sensors to be captured. As machine learning leaps towards\nbetter generalization to real world, multimodal sequential learning becomes a\nfundamental research area. Arguably, modeling arbitrarily distributed\nspatio-temporal dynamics within and across modalities is the biggest challenge\nin this research area. In this paper, we present a new transformer model,\ncalled the Factorized Multimodal Transformer (FMT) for multimodal sequential\nlearning. FMT inherently models the intramodal and intermodal (involving two or\nmore modalities) dynamics within its multimodal input in a factorized manner.\nThe proposed factorization allows for increasing the number of self-attentions\nto better model the multimodal phenomena at hand; without encountering\ndifficulties during training (e.g. overfitting) even on relatively low-resource\nsetups. All the attention mechanisms within FMT have a full time-domain\nreceptive field which allows them to asynchronously capture long-range\nmultimodal dynamics. In our experiments we focus on datasets that contain the\nthree commonly studied modalities of language, vision and acoustic. We perform\na wide range of experiments, spanning across 3 well-studied datasets and 21\ndistinct labels. FMT shows superior performance over previously proposed\nmodels, setting new state of the art in the studied datasets.\n", "versions": [{"version": "v1", "created": "Fri, 22 Nov 2019 03:14:32 GMT"}], "update_date": "2019-11-25", "authors_parsed": [["Zadeh", "Amir", ""], ["Mao", "Chengfeng", ""], ["Shi", "Kelly", ""], ["Zhang", "Yiwei", ""], ["Liang", "Paul Pu", ""], ["Poria", "Soujanya", ""], ["Morency", "Louis-Philippe", ""]]}, {"id": "1911.09827", "submitter": "Xinglong Zhang", "authors": "Xinglong Zhang, Jiahang Liu, Xin Xu, Shuyou Yu, and Hong Chen", "title": "Robust Learning-based Predictive Control for Discrete-time Nonlinear\n  Systems with Unknown Dynamics and State Constraints", "comments": "This work has been submitted to the IEEE for possible publication.\n  Copyright may be transferred without notice, after which this version may no\n  longer be accessible", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.SY cs.LG cs.SY math.OC stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Model predictive control (MPC) has been widely employed as an effective\nmethod for model-based constrained control. For systems with unknown dynamics,\nreinforcement learning (RL) and adaptive dynamic programming (ADP) have\nreceived notable attention to solving adaptive optimal control problems.\nRecently, works on the use of RL in the framework of MPC have emerged, which\ncan enhance the ability of MPC for data-driven control. However, the safety\nunder state constraints and the closed-loop robustness are difficult to be\nverified due to approximation errors of RL with function approximation\nstructures. Aiming at the above problem, we propose a data-driven robust MPC\nsolution based on incremental RL, called data-driven robust learning-based\npredictive control (dr-LPC), for perturbed unknown nonlinear systems subject to\nsafety constraints. A data-driven robust MPC (dr-MPC) is firstly formulated\nwith a learned predictor. The incremental Dual Heuristic Programming (DHP)\nalgorithm using an actor-critic architecture is then utilized to solve the\nonline optimization problem of dr-MPC. In each prediction horizon, the actor\nand critic learn time-varying laws for approximating the optimal control policy\nand costate respectively, which is different from classical MPCs. The state and\ncontrol constraints are enforced in the learning process via building a\nHamilton-Jacobi-Bellman (HJB) equation and a regularized actor-critic learning\nstructure using logarithmic barrier functions. The closed-loop robustness and\nsafety of the dr-LPC are proven under function approximation errors. Simulation\nresults on two control examples have been reported, which show that the dr-LPC\ncan outperform the DHP and dr-MPC in terms of state regulation, and its average\ncomputational time is much smaller than that with the dr-MPC in both examples.\n", "versions": [{"version": "v1", "created": "Fri, 22 Nov 2019 03:15:18 GMT"}, {"version": "v2", "created": "Tue, 15 Sep 2020 05:23:26 GMT"}, {"version": "v3", "created": "Wed, 14 Apr 2021 01:31:47 GMT"}], "update_date": "2021-04-15", "authors_parsed": [["Zhang", "Xinglong", ""], ["Liu", "Jiahang", ""], ["Xu", "Xin", ""], ["Yu", "Shuyou", ""], ["Chen", "Hong", ""]]}, {"id": "1911.09830", "submitter": "Tianyang Zhang", "authors": "Tianyang Zhang, Rui Ma", "title": "Identify the cells' nuclei based on the deep learning neural network", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG eess.IV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Identify the cells' nuclei is the important point for most medical analyses.\nTo assist doctors finding the accurate cell' nuclei location automatically is\nhighly demanded in the clinical practice. Recently, fully convolutional neural\nnetwork (FCNs) serve as the back-bone in many image segmentation, like liver\nand tumer segmentation in medical field, human body block in technical filed.\nThe cells' nuclei identification task is also kind of image segmentation. To\nachieve this, we prefer to use deep learning algorithms. we construct three\ngeneral frameworks, one is Mask Region-based Convolutional Neural Network (Mask\nRCNN), which has the high performance in many image segmentations, one is\nU-net, which has the high generalization performance on small dataset and the\nother is DenseUNet, which is mixture network architecture with Dense Net and\nU-net. we compare the performance of these three frameworks. And we evaluated\nour method on the dataset of data science bowl 2018 challenge. For single model\nwithout any ensemble, they all have good performance.\n", "versions": [{"version": "v1", "created": "Fri, 22 Nov 2019 03:30:05 GMT"}], "update_date": "2019-11-25", "authors_parsed": [["Zhang", "Tianyang", ""], ["Ma", "Rui", ""]]}, {"id": "1911.09837", "submitter": "Jianyu Su", "authors": "Jianyu Su, Peter A. Beling, Rui Guo, Kyungtae Han", "title": "Graph Convolution Networks for Probabilistic Modeling of Driving\n  Acceleration", "comments": "Accepted by ITSC 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV eess.SP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The ability to model and predict ego-vehicle's surrounding traffic is crucial\nfor autonomous pilots and intelligent driver-assistance systems. Acceleration\nprediction is important as one of the major components of traffic prediction.\nThis paper proposes novel approaches to the acceleration prediction problem. By\nrepresenting spatial relationships between vehicles with a graph model, we\nbuild a generalized acceleration prediction framework. This paper studies the\neffectiveness of proposed Graph Convolution Networks, which operate on graphs\npredicting the acceleration distribution for vehicles driving on highways. We\nfurther investigate prediction improvement through integrating of Recurrent\nNeural Networks to disentangle the temporal complexity inherent in the traffic\ndata. Results from simulation studies using comprehensive performance metrics\nsupport the conclusion that our proposed networks outperform state-of-the-art\nmethods in generating realistic trajectories over a prediction horizon.\n", "versions": [{"version": "v1", "created": "Fri, 22 Nov 2019 03:48:43 GMT"}, {"version": "v2", "created": "Sun, 8 Mar 2020 01:32:45 GMT"}, {"version": "v3", "created": "Thu, 7 May 2020 23:40:38 GMT"}], "update_date": "2020-05-11", "authors_parsed": [["Su", "Jianyu", ""], ["Beling", "Peter A.", ""], ["Guo", "Rui", ""], ["Han", "Kyungtae", ""]]}, {"id": "1911.09839", "submitter": "Wonyeol Lee", "authors": "Hyoungjin Lim, Gwonsoo Che, Wonyeol Lee, Hongseok Yang", "title": "Differentiable Algorithm for Marginalising Changepoints", "comments": "To appear at AAAI 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.CO stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present an algorithm for marginalising changepoints in time-series models\nthat assume a fixed number of unknown changepoints. Our algorithm is\ndifferentiable with respect to its inputs, which are the values of latent\nrandom variables other than changepoints. Also, it runs in time O(mn) where n\nis the number of time steps and m the number of changepoints, an improvement\nover a naive marginalisation method with O(n^m) time complexity. We derive the\nalgorithm by identifying quantities related to this marginalisation problem,\nshowing that these quantities satisfy recursive relationships, and transforming\nthe relationships to an algorithm via dynamic programming. Since our algorithm\nis differentiable, it can be applied to convert a model non-differentiable due\nto changepoints to a differentiable one, so that the resulting models can be\nanalysed using gradient-based inference or learning techniques. We empirically\nshow the effectiveness of our algorithm in this application by tackling the\nposterior inference problem on synthetic and real-world data.\n", "versions": [{"version": "v1", "created": "Fri, 22 Nov 2019 03:54:25 GMT"}], "update_date": "2019-11-25", "authors_parsed": [["Lim", "Hyoungjin", ""], ["Che", "Gwonsoo", ""], ["Lee", "Wonyeol", ""], ["Yang", "Hongseok", ""]]}, {"id": "1911.09840", "submitter": "Mohammad Hamed Mozaffari", "authors": "M. Hamed Mozaffari and Won-Sook Lee", "title": "Real-time Ultrasound-enhanced Multimodal Imaging of Tongue using 3D\n  Printable Stabilizer System: A Deep Learning Approach", "comments": "12 figures, 1 table", "journal-ref": "Canadian Acoustics. 48, 1 (Mar. 2020)", "doi": null, "report-no": null, "categories": "cs.CV cs.LG cs.SD eess.AS eess.IV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Despite renewed awareness of the importance of articulation, it remains a\nchallenge for instructors to handle the pronunciation needs of language\nlearners. There are relatively scarce pedagogical tools for pronunciation\nteaching and learning. Unlike inefficient, traditional pronunciation\ninstructions like listening and repeating, electronic visual feedback (EVF)\nsystems such as ultrasound technology have been employed in new approaches.\nRecently, an ultrasound-enhanced multimodal method has been developed for\nvisualizing tongue movements of a language learner overlaid on the face-side of\nthe speaker's head. That system was evaluated for several language courses via\na blended learning paradigm at the university level. The result was asserted\nthat visualizing the articulator's system as biofeedback to language learners\nwill significantly improve articulation learning efficiency. In spite of the\nsuccessful usage of multimodal techniques for pronunciation training, it still\nrequires manual works and human manipulation. In this article, we aim to\ncontribute to this growing body of research by addressing difficulties of the\nprevious approaches by proposing a new comprehensive, automatic, real-time\nmultimodal pronunciation training system, benefits from powerful artificial\nintelligence techniques. The main objective of this research was to combine the\nadvantages of ultrasound technology, three-dimensional printing, and deep\nlearning algorithms to enhance the performance of previous systems. Our\npreliminary pedagogical evaluation of the proposed system revealed a\nsignificant improvement in flexibility, control, robustness, and autonomy.\n", "versions": [{"version": "v1", "created": "Fri, 22 Nov 2019 03:54:31 GMT"}], "update_date": "2020-05-15", "authors_parsed": [["Mozaffari", "M. Hamed", ""], ["Lee", "Won-Sook", ""]]}, {"id": "1911.09843", "submitter": "Jin Woo Jang", "authors": "Hyung Ju Hwang, Jin Woo Jang, Hyeontae Jo, Jae Yong Lee", "title": "Trend to Equilibrium for the Kinetic Fokker-Planck Equation via the\n  Neural Network Approach", "comments": "31 pages, 13 figures", "journal-ref": null, "doi": "10.1016/j.jcp.2020.109665", "report-no": null, "categories": "math.NA cs.LG cs.NA physics.comp-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The issue of the relaxation to equilibrium has been at the core of the\nkinetic theory of rarefied gas dynamics. In the paper, we introduce the Deep\nNeural Network (DNN) approximated solutions to the kinetic Fokker-Planck\nequation in a bounded interval and study the large-time asymptotic behavior of\nthe solutions and other physically relevant macroscopic quantities. We impose\nthe varied types of boundary conditions including the inflow-type and the\nreflection-type boundaries as well as the varied diffusion and friction\ncoefficients and study the boundary effects on the asymptotic behaviors. These\ninclude the predictions on the large-time behaviors of the pointwise values of\nthe particle distribution and the macroscopic physical quantities including the\ntotal kinetic energy, the entropy, and the free energy. We also provide the\ntheoretical supports for the pointwise convergence of the neural network\nsolutions to the \\textit{a priori} analytic solutions. We use the library\n\\textit{PyTorch}, the activation function \\textit{tanh} between layers, and the\n\\textit{Adam} optimizer for the Deep Learning algorithm.\n", "versions": [{"version": "v1", "created": "Fri, 22 Nov 2019 04:03:26 GMT"}], "update_date": "2020-07-15", "authors_parsed": [["Hwang", "Hyung Ju", ""], ["Jang", "Jin Woo", ""], ["Jo", "Hyeontae", ""], ["Lee", "Jae Yong", ""]]}, {"id": "1911.09857", "submitter": "Chao Liu", "authors": "Chao Liu, Heming Sun, Junan Chen, Zhengxue Cheng, Masaru Takeuchi,\n  Jiro Katto, Xiaoyang Zeng and Yibo Fan", "title": "Dual Learning-based Video Coding with Inception Dense Blocks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.IV cs.LG cs.MM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, a dual learning-based method in intra coding is introduced for\nPCS Grand Challenge. This method is mainly composed of two parts: intra\nprediction and reconstruction filtering. They use different network structures,\nthe neural network-based intra prediction uses the full-connected network to\npredict the block while the neural network-based reconstruction filtering\nutilizes the convolutional networks. Different with the previous filtering\nworks, we use a network with more powerful feature extraction capabilities in\nour reconstruction filtering network. And the filtering unit is the block-level\nso as to achieve a more accurate filtering compensation. To our best knowledge,\namong all the learning-based methods, this is the first attempt to combine two\ndifferent networks in one application, and we achieve the state-of-the-art\nperformance for AI configuration on the HEVC Test sequences. The experimental\nresult shows that our method leads to significant BD-rate saving for provided 8\nsequences compared to HM-16.20 baseline (average 10.24% and 3.57% bitrate\nreductions for all-intra and random-access coding, respectively). For HEVC test\nsequences, our model also achieved a 9.70% BD-rate saving compared to HM-16.20\nbaseline for all-intra configuration.\n", "versions": [{"version": "v1", "created": "Fri, 22 Nov 2019 04:57:44 GMT"}], "update_date": "2019-11-25", "authors_parsed": [["Liu", "Chao", ""], ["Sun", "Heming", ""], ["Chen", "Junan", ""], ["Cheng", "Zhengxue", ""], ["Takeuchi", "Masaru", ""], ["Katto", "Jiro", ""], ["Zeng", "Xiaoyang", ""], ["Fan", "Yibo", ""]]}, {"id": "1911.09858", "submitter": "Sheikh Rabiul Islam", "authors": "Sheikh Rabiul Islam, William Eberle, Sheikh K. Ghafoor, Sid C. Bundy,\n  Douglas A. Talbert, and Ambareen Siraj", "title": "Investigating bankruptcy prediction models in the presence of extreme\n  class imbalance and multiple stages of economy", "comments": "Under review in Expert Systems with Applications", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG q-fin.RM stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In the area of credit risk analytics, current Bankruptcy Prediction Models\n(BPMs) struggle with (a) the availability of comprehensive and real-world data\nsets and (b) the presence of extreme class imbalance in the data (i.e., very\nfew samples for the minority class) that degrades the performance of the\nprediction model. Moreover, little research has compared the relative\nperformance of well-known BPM's on public datasets addressing the class\nimbalance problem. In this work, we apply eight classes of well-known BPMs, as\nsuggested by a review of decades of literature, on a new public dataset named\nFreddie Mac Single-Family Loan-Level Dataset with resampling (i.e., adding\nsynthetic minority samples) of the minority class to tackle class imbalance.\nAdditionally, we apply some recent AI techniques (e.g., tree-based ensemble\ntechniques) that demonstrate potentially better results on models trained with\nresampled data. In addition, from the analysis of 19 years (1999-2017) of data,\nwe discover that models behave differently when presented with sudden changes\nin the economy (e.g., a global financial crisis) resulting in abrupt\nfluctuations in the national default rate. In summary, this study should aid\npractitioners/researchers in determining the appropriate model with respect to\ndata that contains a class imbalance and various economic stages.\n", "versions": [{"version": "v1", "created": "Fri, 22 Nov 2019 05:00:09 GMT"}], "update_date": "2019-11-25", "authors_parsed": [["Islam", "Sheikh Rabiul", ""], ["Eberle", "William", ""], ["Ghafoor", "Sheikh K.", ""], ["Bundy", "Sid C.", ""], ["Talbert", "Douglas A.", ""], ["Siraj", "Ambareen", ""]]}, {"id": "1911.09860", "submitter": "Ganesh Ramakrishnan", "authors": "Oishik Chatterjee, Ganesh Ramakrishnan, Sunita Sarawagi", "title": "Data Programming using Continuous and Quality-Guided Labeling Functions", "comments": "Accepted paper at the 34th AAAI Conference on Artificial Intelligence\n  (AAAI-18), New York, USA", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CL stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Scarcity of labeled data is a bottleneck for supervised learning models. A\nparadigm that has evolved for dealing with this problem is data programming. An\nexisting data programming paradigm allows human supervision to be provided as a\nset of discrete labeling functions (LF) that output possibly noisy labels to\ninput instances and a generative modelfor consolidating the weak labels. We\nenhance and generalize this paradigm by supporting functions that output a\ncontinuous score (instead of a hard label) that noisily correlates with labels.\nWe show across five applications that continuous LFs are more natural to\nprogram and lead to improved recall. We also show that accuracy of existing\ngenerative models is unstable with respect to initialization, training epochs,\nand learning rates. We give control to the data programmer to guide the\ntraining process by providing intuitive quality guides with each LF. We propose\nan elegant method of incorporating these guides into the generative model. Our\noverall method, called CAGE, makes the data programming paradigm more reliable\nthan other tricks based on initialization, sign-penalties, or soft-accuracy\nconstraints.\n", "versions": [{"version": "v1", "created": "Fri, 22 Nov 2019 05:05:42 GMT"}], "update_date": "2019-11-25", "authors_parsed": [["Chatterjee", "Oishik", ""], ["Ramakrishnan", "Ganesh", ""], ["Sarawagi", "Sunita", ""]]}, {"id": "1911.09870", "submitter": "Huy Kang Kim", "authors": "Kyung Ho Park, Huy Kang Kim", "title": "This Car is Mine!: Automobile Theft Countermeasure Leveraging Driver\n  Identification with Generative Adversarial Networks", "comments": "6 pages, 3 figures, 3 tables, In Proceedings of the escar Asia 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.LG eess.SP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  As a car becomes more connected, a countermeasure against automobile theft\nhas become a significant task in the real world. To respond to automobile\ntheft, data mining, biometrics, and additional authentication methods are\nproposed. Among current countermeasures, data mining method is one of the\nefficient ways to capture the owner driver's unique characteristics. To\nidentify the owner driver from thieves, previous works applied various\nalgorithms toward driving data. Such data mining methods utilized supervised\nlearning, thus required labeled data set. However, it is unrealistic to gather\nand apply the thief's driving pattern. To overcome this problem, we propose\ndriver identification method with GAN. GAN has merit to build identification\nmodel by learning the owner driver's data only. We trained GAN only with owner\ndriver's data and used trained discriminator to identify the owner driver. From\nactual driving data, we evaluated our identification model recognizes the owner\ndriver well. By ensembling various driver authentication methods with the\nproposed model, we expect industry can develop automobile theft countermeasures\navailable in the real world.\n", "versions": [{"version": "v1", "created": "Fri, 22 Nov 2019 06:00:18 GMT"}], "update_date": "2019-11-25", "authors_parsed": [["Park", "Kyung Ho", ""], ["Kim", "Huy Kang", ""]]}, {"id": "1911.09873", "submitter": "Amit Daniely", "authors": "Amit Daniely", "title": "Neural Networks Learning and Memorization with (almost) no\n  Over-Parameterization", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Many results in recent years established polynomial time learnability of\nvarious models via neural networks algorithms. However, unless the model is\nlinear separable, or the activation is a polynomial, these results require very\nlarge networks -- much more than what is needed for the mere existence of a\ngood predictor.\n  In this paper we prove that SGD on depth two neural networks can memorize\nsamples, learn polynomials with bounded weights, and learn certain kernel\nspaces, with near optimal network size, sample complexity, and runtime. In\nparticular, we show that SGD on depth two network with\n$\\tilde{O}\\left(\\frac{m}{d}\\right)$ hidden neurons (and hence $\\tilde{O}(m)$\nparameters) can memorize $m$ random labeled points in $\\mathbb{S}^{d-1}$.\n", "versions": [{"version": "v1", "created": "Fri, 22 Nov 2019 06:26:53 GMT"}], "update_date": "2019-11-25", "authors_parsed": [["Daniely", "Amit", ""]]}, {"id": "1911.09876", "submitter": "Fereshte Khani", "authors": "Fereshte Khani, Percy Liang", "title": "Feature Noise Induces Loss Discrepancy Across Groups", "comments": "ICML 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The performance of standard learning procedures has been observed to differ\nwidely across groups. Recent studies usually attribute this loss discrepancy to\nan information deficiency for one group (e.g., one group has less data). In\nthis work, we point to a more subtle source of loss discrepancy---feature\nnoise. Our main result is that even when there is no information deficiency\nspecific to one group (e.g., both groups have infinite data), adding the same\namount of feature noise to all individuals leads to loss discrepancy. For\nlinear regression, we thoroughly characterize the effect of feature noise on\nloss discrepancy in terms of the amount of noise, the difference between\nmoments of the two groups, and whether group information is used or not. We\nthen show this loss discrepancy does not vanish immediately if a shift in\ndistribution causes the groups to have similar moments. On three real-world\ndatasets, we show feature noise increases the loss discrepancy if groups have\ndifferent distributions, while it does not affect the loss discrepancy on\ndatasets where groups have similar distributions.\n", "versions": [{"version": "v1", "created": "Fri, 22 Nov 2019 06:36:23 GMT"}, {"version": "v2", "created": "Fri, 6 Nov 2020 01:51:22 GMT"}], "update_date": "2020-11-09", "authors_parsed": [["Khani", "Fereshte", ""], ["Liang", "Percy", ""]]}, {"id": "1911.09877", "submitter": "Jian Li", "authors": "Jian Li, Xing Wang, Baosong Yang, Shuming Shi, Michael R. Lyu,\n  Zhaopeng Tu", "title": "Neuron Interaction Based Representation Composition for Neural Machine\n  Translation", "comments": "AAAI 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent NLP studies reveal that substantial linguistic information can be\nattributed to single neurons, i.e., individual dimensions of the representation\nvectors. We hypothesize that modeling strong interactions among neurons helps\nto better capture complex information by composing the linguistic properties\nembedded in individual neurons. Starting from this intuition, we propose a\nnovel approach to compose representations learned by different components in\nneural machine translation (e.g., multi-layer networks or multi-head\nattention), based on modeling strong interactions among neurons in the\nrepresentation vectors. Specifically, we leverage bilinear pooling to model\npairwise multiplicative interactions among individual neurons, and a low-rank\napproximation to make the model computationally feasible. We further propose\nextended bilinear pooling to incorporate first-order representations.\nExperiments on WMT14 English-German and English-French translation tasks show\nthat our model consistently improves performances over the SOTA Transformer\nbaseline. Further analyses demonstrate that our approach indeed captures more\nsyntactic and semantic information as expected.\n", "versions": [{"version": "v1", "created": "Fri, 22 Nov 2019 06:38:42 GMT"}], "update_date": "2019-11-25", "authors_parsed": [["Li", "Jian", ""], ["Wang", "Xing", ""], ["Yang", "Baosong", ""], ["Shi", "Shuming", ""], ["Lyu", "Michael R.", ""], ["Tu", "Zhaopeng", ""]]}, {"id": "1911.09879", "submitter": "Saurabh Khanna", "authors": "Saurabh Khanna and Vincent Y. F. Tan", "title": "Economy Statistical Recurrent Units For Inferring Nonlinear Granger\n  Causality", "comments": "A new RNN architecture for inferring nonlinear Granger causality from\n  time series data with emphasis on learning time-localized predictive features", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG eess.SP stat.AP stat.ME stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Granger causality is a widely-used criterion for analyzing interactions in\nlarge-scale networks. As most physical interactions are inherently nonlinear,\nwe consider the problem of inferring the existence of pairwise Granger\ncausality between nonlinearly interacting stochastic processes from their time\nseries measurements. Our proposed approach relies on modeling the embedded\nnonlinearities in the measurements using a component-wise time series\nprediction model based on Statistical Recurrent Units (SRUs). We make a case\nthat the network topology of Granger causal relations is directly inferrable\nfrom a structured sparse estimate of the internal parameters of the SRU\nnetworks trained to predict the processes$'$ time series measurements. We\npropose a variant of SRU, called economy-SRU, which, by design has considerably\nfewer trainable parameters, and therefore less prone to overfitting. The\neconomy-SRU computes a low-dimensional sketch of its high-dimensional hidden\nstate in the form of random projections to generate the feedback for its\nrecurrent processing. Additionally, the internal weight parameters of the\neconomy-SRU are strategically regularized in a group-wise manner to facilitate\nthe proposed network in extracting meaningful predictive features that are\nhighly time-localized to mimic real-world causal events. Extensive experiments\nare carried out to demonstrate that the proposed economy-SRU based time series\nprediction model outperforms the MLP, LSTM and attention-gated CNN-based time\nseries models considered previously for inferring Granger causality.\n", "versions": [{"version": "v1", "created": "Fri, 22 Nov 2019 06:40:07 GMT"}, {"version": "v2", "created": "Tue, 14 Jan 2020 04:48:30 GMT"}], "update_date": "2020-01-15", "authors_parsed": [["Khanna", "Saurabh", ""], ["Tan", "Vincent Y. F.", ""]]}, {"id": "1911.09882", "submitter": "Nikki Lijing Kuang", "authors": "Nikki Lijing Kuang and Clement H.C. Leung", "title": "Analysis of Evolutionary Behavior in Self-Learning Media Search Engines", "comments": "IEEE BigData 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.IR cs.LG cs.MM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The diversity of intrinsic qualities of multimedia entities tends to impede\ntheir effective retrieval. In a SelfLearning Search Engine architecture, the\nsubtle nuances of human perceptions and deep knowledge are taught and captured\nthrough unsupervised reinforcement learning, where the degree of reinforcement\nmay be suitably calibrated. Such architectural paradigm enables indexes to\nevolve naturally while accommodating the dynamic changes of user interests. It\noperates by continuously constructing indexes over time, while injecting\nprogressive improvement in search performance. For search operations to be\neffective, convergence of index learning is of crucial importance to ensure\nefficiency and robustness. In this paper, we develop a Self-Learning Search\nEngine architecture based on reinforcement learning using a Markov Decision\nProcess framework. The balance between exploration and exploitation is achieved\nthrough evolutionary exploration Strategies. The evolutionary index learning\nbehavior is then studied and formulated using stochastic analysis. Experimental\nresults are presented which corroborate the steady convergence of the index\nevolution mechanism. Index Term\n", "versions": [{"version": "v1", "created": "Fri, 22 Nov 2019 06:43:56 GMT"}], "update_date": "2019-11-25", "authors_parsed": [["Kuang", "Nikki Lijing", ""], ["Leung", "Clement H. C.", ""]]}, {"id": "1911.09886", "submitter": "Tapas Nayak", "authors": "Tapas Nayak and Hwee Tou Ng", "title": "Effective Modeling of Encoder-Decoder Architecture for Joint Entity and\n  Relation Extraction", "comments": "Accepted at AAAI 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A relation tuple consists of two entities and the relation between them, and\noften such tuples are found in unstructured text. There may be multiple\nrelation tuples present in a text and they may share one or both entities among\nthem. Extracting such relation tuples from a sentence is a difficult task and\nsharing of entities or overlapping entities among the tuples makes it more\nchallenging. Most prior work adopted a pipeline approach where entities were\nidentified first followed by finding the relations among them, thus missing the\ninteraction among the relation tuples in a sentence. In this paper, we propose\ntwo approaches to use encoder-decoder architecture for jointly extracting\nentities and relations. In the first approach, we propose a representation\nscheme for relation tuples which enables the decoder to generate one word at a\ntime like machine translation models and still finds all the tuples present in\na sentence with full entity names of different length and with overlapping\nentities. Next, we propose a pointer network-based decoding approach where an\nentire tuple is generated at every time step. Experiments on the publicly\navailable New York Times corpus show that our proposed approaches outperform\nprevious work and achieve significantly higher F1 scores.\n", "versions": [{"version": "v1", "created": "Fri, 22 Nov 2019 06:52:21 GMT"}], "update_date": "2019-11-25", "authors_parsed": [["Nayak", "Tapas", ""], ["Ng", "Hwee Tou", ""]]}, {"id": "1911.09891", "submitter": "Nikki Lijing Kuang", "authors": "Nikki Lijing Kuang and Clement H.C. Leung", "title": "Performance Effectiveness of Multimedia Information Search Using the\n  Epsilon-Greedy Algorithm", "comments": "8 pages, 10 figures. IEEE ICMLA 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.LG cs.MM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In the search and retrieval of multimedia objects, it is impractical to\neither manually or automatically extract the contents for indexing since most\nof the multimedia contents are not machine extractable, while manual extraction\ntends to be highly laborious and time-consuming. However, by systematically\ncapturing and analyzing the feedback patterns of human users, vital information\nconcerning the multimedia contents can be harvested for effective indexing and\nsubsequent search. By learning from the human judgment and mental evaluation of\nusers, effective search indices can be gradually developed and built up, and\nsubsequently be exploited to find the most relevant multimedia objects. To\navoid hovering around a local maximum, we apply the epsilon-greedy method to\nsystematically explore the search space. Through such methodic exploration, we\nshow that the proposed approach is able to guarantee that the most relevant\nobjects can always be discovered, even though initially it may have been\noverlooked or not regarded as relevant. The search behavior of the present\napproach is quantitatively analyzed, and closed-form expressions are obtained\nfor the performance of two variants of the epsilon-greedy algorithm, namely\nEGSE-A and EGSE-B. Simulations and experiments on real data set have been\nperformed which show good agreement with the theoretical findings. The present\nmethod is able to leverage exploration in an effective way to significantly\nraise the performance of multimedia information search, and enables the certain\ndiscovery of relevant objects which may be otherwise undiscoverable.\n", "versions": [{"version": "v1", "created": "Fri, 22 Nov 2019 07:12:05 GMT"}], "update_date": "2019-11-25", "authors_parsed": [["Kuang", "Nikki Lijing", ""], ["Leung", "Clement H. C.", ""]]}, {"id": "1911.09895", "submitter": "Mohammed Haroon Dupty", "authors": "Mohammed Haroon Dupty, Zhen Zhang, Wee Sun Lee", "title": "Visual Relationship Detection with Low Rank Non-Negative Tensor\n  Decomposition", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We address the problem of Visual Relationship Detection (VRD) which aims to\ndescribe the relationships between pairs of objects in the form of triplets of\n(subject, predicate, object). We observe that given a pair of bounding box\nproposals, objects often participate in multiple relations implying the\ndistribution of triplets is multimodal. We leverage the strong correlations\nwithin triplets to learn the joint distribution of triplet variables\nconditioned on the image and the bounding box proposals, doing away with the\nhitherto used independent distribution of triplets. To make learning the\ntriplet joint distribution feasible, we introduce a novel technique of learning\nconditional triplet distributions in the form of their normalized low rank\nnon-negative tensor decompositions. Normalized tensor decompositions take form\nof mixture distributions of discrete variables and thus are able to capture\nmultimodality. This allows us to efficiently learn higher order discrete\nmultimodal distributions and at the same time keep the parameter size\nmanageable. We further model the probability of selecting an object proposal\npair and include a relation triplet prior in our model. We show that each part\nof the model improves performance and the combination outperforms\nstate-of-the-art score on the Visual Genome (VG) and Visual Relationship\nDetection (VRD) datasets.\n", "versions": [{"version": "v1", "created": "Fri, 22 Nov 2019 07:23:02 GMT"}], "update_date": "2019-11-25", "authors_parsed": [["Dupty", "Mohammed Haroon", ""], ["Zhang", "Zhen", ""], ["Lee", "Wee Sun", ""]]}, {"id": "1911.09906", "submitter": "Weizhu Qian", "authors": "Weizhu Qian, Fabrice Lauri, Franck Gechter", "title": "Supervised and Semi-supervised Deep Probabilistic Models for Indoor\n  Positioning Problems", "comments": "11 pages, 10 figures", "journal-ref": "Neurocomputing, vol. 435C, pp. 228-238, 2021", "doi": "10.1016/j.neucom.2020.12.131", "report-no": null, "categories": "cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Predicting smartphone users location with WiFi fingerprints has been a\npopular research topic recently. In this work, we propose two novel deep\nlearning-based models, the convolutional mixture density recurrent neural\nnetwork and the VAE-based semi-supervised learning model. The convolutional\nmixture density recurrent neural network is designed for path prediction, in\nwhich the advantages of convolutional neural networks, recurrent neural\nnetworks and mixture density networks are combined. Further, since most of\nreal-world datasets are not labeled, we devise the VAE-based model for the\nsemi-supervised learning tasks. In order to test the proposed models, we\nconduct the validation experiments on the real-world datasets. The final\nresults verify the effectiveness of our approaches and show the superiority\nover other existing methods.\n", "versions": [{"version": "v1", "created": "Fri, 22 Nov 2019 07:50:27 GMT"}, {"version": "v2", "created": "Thu, 19 Dec 2019 14:02:39 GMT"}, {"version": "v3", "created": "Tue, 16 Mar 2021 07:46:27 GMT"}], "update_date": "2021-03-17", "authors_parsed": [["Qian", "Weizhu", ""], ["Lauri", "Fabrice", ""], ["Gechter", "Franck", ""]]}, {"id": "1911.09925", "submitter": "Hasan Genc", "authors": "Hasan Genc, Seah Kim, Alon Amid, Ameer Haj-Ali, Vighnesh Iyer, Pranav\n  Prakash, Jerry Zhao, Daniel Grubb, Harrison Liew, Howard Mao, Albert Ou,\n  Colin Schmidt, Samuel Steffl, John Wright, Ion Stoica, Jonathan Ragan-Kelley,\n  Krste Asanovic, Borivoje Nikolic, Yakun Sophia Shao", "title": "Gemmini: Enabling Systematic Deep-Learning Architecture Evaluation via\n  Full-Stack Integration", "comments": "To appear at the 58th IEEE/ACM Design Automation Conference (DAC),\n  December 2021, San Francisco, CA, USA", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.AR cs.LG cs.PF", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  DNN accelerators are often developed and evaluated in isolation without\nconsidering the cross-stack, system-level effects in real-world environments.\nThis makes it difficult to appreciate the impact of System-on-Chip (SoC)\nresource contention, OS overheads, and programming-stack inefficiencies on\noverall performance/energy-efficiency. To address this challenge, we present\nGemmini, an open-source*, full-stack DNN accelerator generator. Gemmini\ngenerates a wide design-space of efficient ASIC accelerators from a flexible\narchitectural template, together with flexible programming stacks and full SoCs\nwith shared resources that capture system-level effects. Gemmini-generated\naccelerators have also been fabricated, delivering up to three\norders-of-magnitude speedups over high-performance CPUs on various DNN\nbenchmarks.\n  * https://github.com/ucb-bar/gemmini\n", "versions": [{"version": "v1", "created": "Fri, 22 Nov 2019 08:51:28 GMT"}, {"version": "v2", "created": "Sat, 7 Dec 2019 10:33:50 GMT"}, {"version": "v3", "created": "Fri, 9 Jul 2021 06:53:12 GMT"}], "update_date": "2021-07-12", "authors_parsed": [["Genc", "Hasan", ""], ["Kim", "Seah", ""], ["Amid", "Alon", ""], ["Haj-Ali", "Ameer", ""], ["Iyer", "Vighnesh", ""], ["Prakash", "Pranav", ""], ["Zhao", "Jerry", ""], ["Grubb", "Daniel", ""], ["Liew", "Harrison", ""], ["Mao", "Howard", ""], ["Ou", "Albert", ""], ["Schmidt", "Colin", ""], ["Steffl", "Samuel", ""], ["Wright", "John", ""], ["Stoica", "Ion", ""], ["Ragan-Kelley", "Jonathan", ""], ["Asanovic", "Krste", ""], ["Nikolic", "Borivoje", ""], ["Shao", "Yakun Sophia", ""]]}, {"id": "1911.09943", "submitter": "Hao Dong", "authors": "Guanqi Zhan, Yihao Zhao, Bingchan Zhao, Haoqi Yuan, Baoquan Chen, Hao\n  Dong", "title": "DLGAN: Disentangling Label-Specific Fine-Grained Features for Image\n  Manipulation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent studies have shown how disentangling images into content and feature\nspaces can provide controllable image translation/ manipulation. In this paper,\nwe propose a framework to enable utilizing discrete multi-labels to control\nwhich features to be disentangled, i.e., disentangling label-specific\nfine-grained features for image manipulation (dubbed DLGAN). By mapping the\ndiscrete label-specific attribute features into a continuous prior\ndistribution, we leverage the advantages of both discrete labels and reference\nimages to achieve image manipulation in a hybrid fashion. For example, given a\nface image dataset (e.g., CelebA) with multiple discrete fine-grained labels,\nwe can learn to smoothly interpolate a face image between black hair and blond\nhair through reference images while immediately controlling the gender and age\nthrough discrete input labels. To the best of our knowledge, this is the first\nwork that realizes such a hybrid manipulation within a single model. More\nimportantly, it is the first work to achieve image interpolation between two\ndifferent domains without requiring continuous labels as the supervision.\nQualitative and quantitative experiments demonstrate the effectiveness of the\nproposed method.\n", "versions": [{"version": "v1", "created": "Fri, 22 Nov 2019 09:42:52 GMT"}, {"version": "v2", "created": "Tue, 25 Aug 2020 04:47:37 GMT"}], "update_date": "2020-08-26", "authors_parsed": [["Zhan", "Guanqi", ""], ["Zhao", "Yihao", ""], ["Zhao", "Bingchan", ""], ["Yuan", "Haoqi", ""], ["Chen", "Baoquan", ""], ["Dong", "Hao", ""]]}, {"id": "1911.09946", "submitter": "Mona Buisson-Fenet", "authors": "Mona Buisson-Fenet, Friedrich Solowjow, and Sebastian Trimpe", "title": "Actively Learning Gaussian Process Dynamics", "comments": null, "journal-ref": "Actively Learning Gaussian Process Dynamics, Proceedings of the\n  2nd Conference on Learning for Dynamics and Control, Proceedings of Machine\n  Learning Research vol 120, pp. 5-15, 2020", "doi": null, "report-no": null, "categories": "cs.LG cs.RO stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Despite the availability of ever more data enabled through modern sensor and\ncomputer technology, it still remains an open problem to learn dynamical\nsystems in a sample-efficient way. We propose active learning strategies that\nleverage information-theoretical properties arising naturally during Gaussian\nprocess regression, while respecting constraints on the sampling process\nimposed by the system dynamics. Sample points are selected in regions with high\nuncertainty, leading to exploratory behavior and data-efficient training of the\nmodel. All results are finally verified in an extensive numerical benchmark.\n", "versions": [{"version": "v1", "created": "Fri, 22 Nov 2019 09:47:17 GMT"}, {"version": "v2", "created": "Wed, 22 Apr 2020 09:48:49 GMT"}, {"version": "v3", "created": "Sun, 26 Apr 2020 11:25:00 GMT"}], "update_date": "2020-12-08", "authors_parsed": [["Buisson-Fenet", "Mona", ""], ["Solowjow", "Friedrich", ""], ["Trimpe", "Sebastian", ""]]}, {"id": "1911.09948", "submitter": "Dominique Beroule", "authors": "Dominique B\\'eroule (LIMSI), Pascale Gisquet-Verrier (Neuro-PSI)", "title": "Decision Making guided by Emotion A computational architecture", "comments": null, "journal-ref": "WCCI 2012 IEEE world congress on computational intelligence, Jun\n  2012, Brisbane, France", "doi": null, "report-no": null, "categories": "q-bio.NC cs.LG cs.NE q-bio.QM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A computational architecture is presented, in which \"swift and fuzzy\"\nemotional channels guide a \"slow and precise\" decision-making channel. Reported\nneurobiological studies first provide hints on the representation of both\nemotional and cognitive dimensions across brain structures, mediated by the\nneuromodulation system. The related model is based on Guided Propagation\nNetworks, the inner flows of which can be guided through modulation. A\nkey-channel of this model grows from a few emotional cues, and is aimed at\nanticipating the consequences of ongoing possible actions. Current experimental\nresults of a computer simulation show the integrated contribution of several\nemotional influences, as well as issues of accidental all-out emotions.\n", "versions": [{"version": "v1", "created": "Fri, 22 Nov 2019 09:49:34 GMT"}], "update_date": "2019-11-25", "authors_parsed": [["B\u00e9roule", "Dominique", "", "LIMSI"], ["Gisquet-Verrier", "Pascale", "", "Neuro-PSI"]]}, {"id": "1911.09968", "submitter": "Yasin Almalioglu", "authors": "Yasin Almalioglu, Mehmet Turan, Alp Eren Sari, Muhamad Risqi U.\n  Saputra, Pedro P. B. de Gusm\\~ao, Andrew Markham, Niki Trigoni", "title": "SelfVIO: Self-Supervised Deep Monocular Visual-Inertial Odometry and\n  Depth Estimation", "comments": "15 pages, submitted to The IEEE Transactions on Robotics (T-RO)\n  journal, under review", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG eess.IV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In the last decade, numerous supervised deep learning approaches requiring\nlarge amounts of labeled data have been proposed for visual-inertial odometry\n(VIO) and depth map estimation. To overcome the data limitation,\nself-supervised learning has emerged as a promising alternative, exploiting\nconstraints such as geometric and photometric consistency in the scene. In this\nstudy, we introduce a novel self-supervised deep learning-based VIO and depth\nmap recovery approach (SelfVIO) using adversarial training and self-adaptive\nvisual-inertial sensor fusion. SelfVIO learns to jointly estimate 6\ndegrees-of-freedom (6-DoF) ego-motion and a depth map of the scene from\nunlabeled monocular RGB image sequences and inertial measurement unit (IMU)\nreadings. The proposed approach is able to perform VIO without the need for IMU\nintrinsic parameters and/or the extrinsic calibration between the IMU and the\ncamera. estimation and single-view depth recovery network. We provide\ncomprehensive quantitative and qualitative evaluations of the proposed\nframework comparing its performance with state-of-the-art VIO, VO, and visual\nsimultaneous localization and mapping (VSLAM) approaches on the KITTI, EuRoC\nand Cityscapes datasets. Detailed comparisons prove that SelfVIO outperforms\nstate-of-the-art VIO approaches in terms of pose estimation and depth recovery,\nmaking it a promising approach among existing methods in the literature.\n", "versions": [{"version": "v1", "created": "Fri, 22 Nov 2019 10:51:09 GMT"}, {"version": "v2", "created": "Thu, 23 Jul 2020 13:37:41 GMT"}], "update_date": "2020-07-24", "authors_parsed": [["Almalioglu", "Yasin", ""], ["Turan", "Mehmet", ""], ["Sari", "Alp Eren", ""], ["Saputra", "Muhamad Risqi U.", ""], ["de Gusm\u00e3o", "Pedro P. B.", ""], ["Markham", "Andrew", ""], ["Trigoni", "Niki", ""]]}, {"id": "1911.09976", "submitter": "Xinshao Wang Mr", "authors": "Xinshao Wang, Elyor Kodirov, Yang Hua, Neil Robertson", "title": "Instance Cross Entropy for Deep Metric Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV cs.IR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Loss functions play a crucial role in deep metric learning thus a variety of\nthem have been proposed. Some supervise the learning process by pairwise or\ntripletwise similarity constraints while others take advantage of structured\nsimilarity information among multiple data points. In this work, we approach\ndeep metric learning from a novel perspective. We propose instance cross\nentropy (ICE) which measures the difference between an estimated instance-level\nmatching distribution and its ground-truth one. ICE has three main appealing\nproperties. Firstly, similar to categorical cross entropy (CCE), ICE has clear\nprobabilistic interpretation and exploits structured semantic similarity\ninformation for learning supervision. Secondly, ICE is scalable to infinite\ntraining data as it learns on mini-batches iteratively and is independent of\nthe training set size. Thirdly, motivated by our relative weight analysis,\nseamless sample reweighting is incorporated. It rescales samples' gradients to\ncontrol the differentiation degree over training examples instead of truncating\nthem by sample mining. In addition to its simplicity and intuitiveness,\nextensive experiments on three real-world benchmarks demonstrate the\nsuperiority of ICE.\n", "versions": [{"version": "v1", "created": "Fri, 22 Nov 2019 11:12:48 GMT"}], "update_date": "2019-11-25", "authors_parsed": [["Wang", "Xinshao", ""], ["Kodirov", "Elyor", ""], ["Hua", "Yang", ""], ["Robertson", "Neil", ""]]}, {"id": "1911.09982", "submitter": "Ling Luo", "authors": "Ling Luo, Dingyu Xue, Xinglong Feng", "title": "HybridNetSeg: A Compact Hybrid Network for Retinal Vessel Segmentation", "comments": "16 pages, 3 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.IV cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A large number of retinal vessel analysis methods based on image segmentation\nhave emerged in recent years. However, existing methods depend on cumbersome\nbackbones, such as VGG16 and ResNet-50, benefiting from their powerful feature\nextraction capabilities but suffering from high computational costs. In this\npaper, we propose a novel neural network (HybridNetSeg) dedicated to solving\nthis drawback while further improving overall performance. Considering\ndeformable convolution can extract complex and variable structural information,\nand larger kernel in mixed depthwise convolution makes contribution to higher\naccuracy. We have integrated these two modules and propose a Hybrid Convolution\nBlock (HCB) using the idea of heuristic learning. Inspired by the U-Net, we use\nHCB to replace a part of the common convolution of the U-Net encoder,\ndrastically reducing the parameter count to 0.71M while accelerating the\ninference process. Not only that, we also propose a multi-scale mixed loss\nmechanism. Extensive experiments on three major benchmark datasets demonstrate\nthe effectiveness of our proposed method\n", "versions": [{"version": "v1", "created": "Fri, 22 Nov 2019 11:42:09 GMT"}], "update_date": "2019-11-25", "authors_parsed": [["Luo", "Ling", ""], ["Xue", "Dingyu", ""], ["Feng", "Xinglong", ""]]}, {"id": "1911.09983", "submitter": "Zeyu Sun", "authors": "Zeyu Sun and Qihao Zhu and Yingfei Xiong and Yican Sun and Lili Mou\n  and Lu Zhang", "title": "TreeGen: A Tree-Based Transformer Architecture for Code Generation", "comments": null, "journal-ref": "AAAI 2020", "doi": null, "report-no": null, "categories": "cs.LG cs.SE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A code generation system generates programming language code based on an\ninput natural language description. State-of-the-art approaches rely on neural\nnetworks for code generation. However, these code generators suffer from two\nproblems. One is the long dependency problem, where a code element often\ndepends on another far-away code element. A variable reference, for example,\ndepends on its definition, which may appear quite a few lines before. The other\nproblem is structure modeling, as programs contain rich structural information.\nIn this paper, we propose a novel tree-based neural architecture, TreeGen, for\ncode generation. TreeGen uses the attention mechanism of Transformers to\nalleviate the long-dependency problem, and introduces a novel AST reader\n(encoder) to incorporate grammar rules and AST structures into the network. We\nevaluated TreeGen on a Python benchmark, HearthStone, and two semantic parsing\nbenchmarks, ATIS and GEO. TreeGen outperformed the previous state-of-the-art\napproach by 4.5 percentage points on HearthStone, and achieved the best\naccuracy among neural network-based approaches on ATIS (89.1%) and GEO (89.6%).\nWe also conducted an ablation test to better understand each component of our\nmodel.\n", "versions": [{"version": "v1", "created": "Fri, 22 Nov 2019 11:45:26 GMT"}, {"version": "v2", "created": "Thu, 28 Nov 2019 08:50:00 GMT"}], "update_date": "2019-12-02", "authors_parsed": [["Sun", "Zeyu", ""], ["Zhu", "Qihao", ""], ["Xiong", "Yingfei", ""], ["Sun", "Yican", ""], ["Mou", "Lili", ""], ["Zhang", "Lu", ""]]}, {"id": "1911.10008", "submitter": "Sambuddha Saha", "authors": "Sambuddha Saha, Aashish Kumar, Pratyush Sahay, George Jose, Srinivas\n  Kruthiventi, Harikrishna Muralidhara", "title": "Attack Agnostic Statistical Method for Adversarial Detection", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep Learning based AI systems have shown great promise in various domains\nsuch as vision, audio, autonomous systems (vehicles, drones), etc. Recent\nresearch on neural networks has shown the susceptibility of deep networks to\nadversarial attacks - a technique of adding small perturbations to the inputs\nwhich can fool a deep network into misclassifying them. Developing defenses\nagainst such adversarial attacks is an active research area, with some\napproaches proposing robust models that are immune to such adversaries, while\nother techniques attempt to detect such adversarial inputs. In this paper, we\npresent a novel statistical approach for adversarial detection in image\nclassification. Our approach is based on constructing a per-class feature\ndistribution and detecting adversaries based on comparison of features of a\ntest image with the feature distribution of its class. For this purpose, we\nmake use of various statistical distances such as ED (Energy Distance), MMD\n(Maximum Mean Discrepancy) for adversarial detection, and analyze the\nperformance of each metric. We experimentally show that our approach achieves\ngood adversarial detection performance on MNIST and CIFAR-10 datasets\nirrespective of the attack method, sample size and the degree of adversarial\nperturbation.\n", "versions": [{"version": "v1", "created": "Fri, 22 Nov 2019 12:52:11 GMT"}], "update_date": "2019-11-25", "authors_parsed": [["Saha", "Sambuddha", ""], ["Kumar", "Aashish", ""], ["Sahay", "Pratyush", ""], ["Jose", "George", ""], ["Kruthiventi", "Srinivas", ""], ["Muralidhara", "Harikrishna", ""]]}, {"id": "1911.10017", "submitter": "Sixin Zhang", "authors": "Sixin Zhang, St\\'ephane Mallat", "title": "Maximum Entropy Models from Phase Harmonic Covariances", "comments": null, "journal-ref": null, "doi": "10.1016/j.acha.2021.01.003", "report-no": null, "categories": "eess.SP cs.IT cs.LG math.IT stat.ML", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  The covariance of a stationary process $X$ is diagonalized by a Fourier\ntransform. It does not take into account the complex Fourier phase and defines\nGaussian maximum entropy models. We introduce a general family of phase\nharmonic covariance moments, which rely on complex phases to capture\nnon-Gaussian properties. They are defined as the covariance of $\\hat{H} (L X)$,\nwhere $L$ is a complex linear operator and $\\hat{H} $ is a non-linear phase\nharmonic operator which multiplies the phase of each complex coefficient by\nintegers. The operator $\\hat{H} (L X)$ can also be calculated from rectifiers,\nwhich relates $\\hat{H} (L X)$ to neural network coefficients. If $L$ is a\nFourier transform then the covariance is a sparse matrix whose non-zero\noff-diagonal coefficients capture dependencies between frequencies. These\ncoefficients have similarities with high order moment, but smaller statistical\nvariabilities because $\\hat{H} (L X)$ is Lipschitz. If $L$ is a complex wavelet\ntransform then off-diagonal coefficients reveal dependencies across scales,\nwhich specify the geometry of local coherent structures. We introduce maximum\nentropy models conditioned by these wavelet phase harmonic covariances. The\nprecision of these models is numerically evaluated to synthesize images of\nturbulent flows and other stationary processes.\n", "versions": [{"version": "v1", "created": "Fri, 22 Nov 2019 13:04:37 GMT"}, {"version": "v2", "created": "Fri, 29 Jan 2021 15:04:46 GMT"}], "update_date": "2021-02-04", "authors_parsed": [["Zhang", "Sixin", ""], ["Mallat", "St\u00e9phane", ""]]}, {"id": "1911.10022", "submitter": "Friso Heslinga", "authors": "Friso G. Heslinga, Josien P.W. Pluim, A.J.H.M. Houben, Miranda T.\n  Schram, Ronald M.A. Henry, Coen D.A. Stehouwer, Marleen J. van Greevenbroek,\n  Tos T.J.M. Berendschot, and Mitko Veta", "title": "Direct Classification of Type 2 Diabetes From Retinal Fundus Images in a\n  Population-based Sample From The Maastricht Study", "comments": "to be published in the proceeding of SPIE - Medical Imaging 2020, 6\n  pages, 1 figure", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.IV cs.CV cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Type 2 Diabetes (T2D) is a chronic metabolic disorder that can lead to\nblindness and cardiovascular disease. Information about early stage T2D might\nbe present in retinal fundus images, but to what extent these images can be\nused for a screening setting is still unknown. In this study, deep neural\nnetworks were employed to differentiate between fundus images from individuals\nwith and without T2D. We investigated three methods to achieve high\nclassification performance, measured by the area under the receiver operating\ncurve (ROC-AUC). A multi-target learning approach to simultaneously output\nretinal biomarkers as well as T2D works best (AUC = 0.746 [$\\pm$0.001]).\nFurthermore, the classification performance can be improved when images with\nhigh prediction uncertainty are referred to a specialist. We also show that the\ncombination of images of the left and right eye per individual can further\nimprove the classification performance (AUC = 0.758 [$\\pm$0.003]), using a\nsimple averaging approach. The results are promising, suggesting the\nfeasibility of screening for T2D from retinal fundus images.\n", "versions": [{"version": "v1", "created": "Fri, 22 Nov 2019 13:17:04 GMT"}], "update_date": "2019-11-25", "authors_parsed": [["Heslinga", "Friso G.", ""], ["Pluim", "Josien P. W.", ""], ["Houben", "A. J. H. M.", ""], ["Schram", "Miranda T.", ""], ["Henry", "Ronald M. A.", ""], ["Stehouwer", "Coen D. A.", ""], ["van Greevenbroek", "Marleen J.", ""], ["Berendschot", "Tos T. J. M.", ""], ["Veta", "Mitko", ""]]}, {"id": "1911.10023", "submitter": "Mateusz Juda", "authors": "Mateusz Juda", "title": "Unsupervised Features Learning for Sampled Vector Fields", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG math.AT math.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we introduce a new approach to computing hidden features of\nsampled vector fields. The basic idea is to convert the vector field data to a\ngraph structure and use tools designed for automatic, unsupervised analysis of\ngraphs. Using a few data sets we show that the collected features of the vector\nfields are correlated with the dynamics known for analytic models which\ngenerates the data. In particular the method may be useful in analysis of data\nsets where the analytic model is poorly understood or not known.\n", "versions": [{"version": "v1", "created": "Fri, 22 Nov 2019 13:17:13 GMT"}, {"version": "v2", "created": "Tue, 11 Aug 2020 10:38:40 GMT"}], "update_date": "2020-08-12", "authors_parsed": [["Juda", "Mateusz", ""]]}, {"id": "1911.10024", "submitter": "Angelo Porrello", "authors": "Stefano Vincenzi, Angelo Porrello, Pietro Buzzega, Annamaria Conte,\n  Carla Ippoliti, Luca Candeloro, Alessio Di Lorenzo, Andrea Capobianco\n  Dondona, Simone Calderara", "title": "Spotting insects from satellites: modeling the presence of Culicoides\n  imicola through Deep CNNs", "comments": "8 pages, 2 figures. Accepted in the 15th International Conference on\n  SIGNAL IMAGE TECHNOLOGY & INTERNET BASED SYSTEMS (SITIS-2019)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG eess.IV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Nowadays, Vector-Borne Diseases (VBDs) raise a severe threat for public\nhealth, accounting for a considerable amount of human illnesses. Recently,\nseveral surveillance plans have been put in place for limiting the spread of\nsuch diseases, typically involving on-field measurements. Such a systematic and\neffective plan still misses, due to the high costs and efforts required for\nimplementing it. Ideally, any attempt in this field should consider the\ntriangle vectors-host-pathogen, which is strictly linked to the environmental\nand climatic conditions. In this paper, we exploit satellite imagery from\nSentinel-2 mission, as we believe they encode the environmental factors\nresponsible for the vector's spread. Our analysis - conducted in a data-driver\nfashion - couples spectral images with ground-truth information on the\nabundance of Culicoides imicola. In this respect, we frame our task as a binary\nclassification problem, underpinning Convolutional Neural Networks (CNNs) as\nbeing able to learn useful representation from multi-band images. Additionally,\nwe provide a multi-instance variant, aimed at extracting temporal patterns from\na short sequence of spectral images. Experiments show promising results,\nproviding the foundations for novel supportive tools, which could depict where\nsurveillance and prevention measures could be prioritized.\n", "versions": [{"version": "v1", "created": "Fri, 22 Nov 2019 13:17:19 GMT"}], "update_date": "2019-11-25", "authors_parsed": [["Vincenzi", "Stefano", ""], ["Porrello", "Angelo", ""], ["Buzzega", "Pietro", ""], ["Conte", "Annamaria", ""], ["Ippoliti", "Carla", ""], ["Candeloro", "Luca", ""], ["Di Lorenzo", "Alessio", ""], ["Dondona", "Andrea Capobianco", ""], ["Calderara", "Simone", ""]]}, {"id": "1911.10036", "submitter": "Artyom Gadetsky", "authors": "Artyom Gadetsky, Kirill Struminsky, Christopher Robinson, Novi\n  Quadrianto, Dmitry Vetrov", "title": "Low-variance Black-box Gradient Estimates for the Plackett-Luce\n  Distribution", "comments": "Accepted as a conference paper at AAAI 2020. Shortened version of the\n  paper appears at BDL NeurIPS 2019 workshop", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Learning models with discrete latent variables using stochastic gradient\ndescent remains a challenge due to the high variance of gradient estimates.\nModern variance reduction techniques mostly consider categorical distributions\nand have limited applicability when the number of possible outcomes becomes\nlarge. In this work, we consider models with latent permutations and propose\ncontrol variates for the Plackett-Luce distribution. In particular, the control\nvariates allow us to optimize black-box functions over permutations using\nstochastic gradient descent. To illustrate the approach, we consider a variety\nof causal structure learning tasks for continuous and discrete data. We show\nthat our method outperforms competitive relaxation-based optimization methods\nand is also applicable to non-differentiable score functions.\n", "versions": [{"version": "v1", "created": "Fri, 22 Nov 2019 13:34:50 GMT"}], "update_date": "2019-11-25", "authors_parsed": [["Gadetsky", "Artyom", ""], ["Struminsky", "Kirill", ""], ["Robinson", "Christopher", ""], ["Quadrianto", "Novi", ""], ["Vetrov", "Dmitry", ""]]}, {"id": "1911.10049", "submitter": "Matej Ul\\v{c}ar", "authors": "Matej Ul\\v{c}ar, Marko Robnik-\\v{S}ikonja", "title": "High Quality ELMo Embeddings for Seven Less-Resourced Languages", "comments": "8 pages, 3 figures, LREC2020 conference", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Recent results show that deep neural networks using contextual embeddings\nsignificantly outperform non-contextual embeddings on a majority of text\nclassification task. We offer precomputed embeddings from popular contextual\nELMo model for seven languages: Croatian, Estonian, Finnish, Latvian,\nLithuanian, Slovenian, and Swedish. We demonstrate that the quality of\nembeddings strongly depends on the size of training set and show that existing\npublicly available ELMo embeddings for listed languages shall be improved. We\ntrain new ELMo embeddings on much larger training sets and show their advantage\nover baseline non-contextual FastText embeddings. In evaluation, we use two\nbenchmarks, the analogy task and the NER task.\n", "versions": [{"version": "v1", "created": "Fri, 22 Nov 2019 14:06:21 GMT"}, {"version": "v2", "created": "Fri, 27 Mar 2020 17:18:53 GMT"}], "update_date": "2020-03-30", "authors_parsed": [["Ul\u010dar", "Matej", ""], ["Robnik-\u0160ikonja", "Marko", ""]]}, {"id": "1911.10071", "submitter": "Aleksei Triastcyn", "authors": "Aleksei Triastcyn, Boi Faltings", "title": "Federated Learning with Bayesian Differential Privacy", "comments": "Accepted at 2019 IEEE International Conference on Big Data (IEEE Big\n  Data 2019). 10 pages, 2 figures, 4 tables. arXiv admin note: text overlap\n  with arXiv:1901.09697", "journal-ref": null, "doi": "10.1109/BigData47090.2019.9005465", "report-no": null, "categories": "cs.LG cs.CR cs.DC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the problem of reinforcing federated learning with formal privacy\nguarantees. We propose to employ Bayesian differential privacy, a relaxation of\ndifferential privacy for similarly distributed data, to provide sharper privacy\nloss bounds. We adapt the Bayesian privacy accounting method to the federated\nsetting and suggest multiple improvements for more efficient privacy budgeting\nat different levels. Our experiments show significant advantage over the\nstate-of-the-art differential privacy bounds for federated learning on image\nclassification tasks, including a medical application, bringing the privacy\nbudget below 1 at the client level, and below 0.1 at the instance level. Lower\namounts of noise also benefit the model accuracy and reduce the number of\ncommunication rounds.\n", "versions": [{"version": "v1", "created": "Fri, 22 Nov 2019 14:54:04 GMT"}], "update_date": "2020-03-26", "authors_parsed": [["Triastcyn", "Aleksei", ""], ["Faltings", "Boi", ""]]}, {"id": "1911.10073", "submitter": "Abolfazl Asudeh", "authors": "Abolfazl Asudeh and H. V. Jagadish", "title": "Responsible Scoring Mechanisms Through Function Sampling", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Human decision-makers often receive assistance from data-driven algorithmic\nsystems that provide a score for evaluating objects, including individuals. The\nscores are generated by a function (mechanism) that takes a set of features as\ninput and generates a score.The scoring functions are either machine-learned or\nhuman-designed and can be used for different decision purposes such as ranking\nor classification.\n  Given the potential impact of these scoring mechanisms on individuals' lives\nand on society, it is important to make sure these scores are computed\nresponsibly. Hence we need tools for responsible scoring mechanism design. In\nthis paper, focusing on linear scoring functions, we highlight the importance\nof unbiased function sampling and perturbation in the function space for\ndevising such tools. We provide unbiased samplers for the entire function\nspace, as well as a $\\theta$-vicinity around a given function.\n  We then illustrate the value of these samplers for designing effective\nalgorithms in three diverse problem scenarios in the context of ranking.\nFinally, as a fundamental method for designing responsible scoring mechanisms,\nwe propose a novel approach for approximating the construction of the\narrangement of hyperplanes. Despite the exponential complexity of an\narrangement in the number of dimensions, using function sampling, our algorithm\nis linear in the number of samples and hyperplanes, and independent of the\nnumber of dimensions.\n", "versions": [{"version": "v1", "created": "Fri, 22 Nov 2019 15:05:26 GMT"}], "update_date": "2019-11-25", "authors_parsed": [["Asudeh", "Abolfazl", ""], ["Jagadish", "H. V.", ""]]}, {"id": "1911.10074", "submitter": "Mariane Maynard", "authors": "Mariane Maynard, Thibault Duhamel, Froduald Kabanza", "title": "Cost-Based Goal Recognition Meets Deep Learning", "comments": "An earlier version of this paper was published in PAIR (AAAI 2019\n  workshop)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The ability to observe the effects of actions performed by others and to\ninfer their intent, most likely goals, or course of action, is known as a plan\nor intention recognition cognitive capability and has long been one of the\nfundamental research challenges in AI. Deep learning has recently been making\nsignificant inroads on various pattern recognition problems, except for\nintention recognition. While extensively explored since the seventies, the\nproblem remains unsolved for most interesting cases in various areas, ranging\nfrom natural language understanding to human behavior understanding based on\nvideo feeds. This paper compares symbolic inverse planning, one of the most\ninvestigated approaches to goal recognition, to deep learning using CNN and\nLTSM neural network architectures, on five synthetic benchmarks often used in\nthe literature. The results show that the deep learning approach achieves\nbetter goal-prediction accuracy and timeliness than the symbolic cost-based\nplan recognizer in these domains. Although preliminary, these results point to\ninteresting future research avenues.\n", "versions": [{"version": "v1", "created": "Fri, 22 Nov 2019 15:09:14 GMT"}], "update_date": "2019-11-26", "authors_parsed": [["Maynard", "Mariane", ""], ["Duhamel", "Thibault", ""], ["Kabanza", "Froduald", ""]]}, {"id": "1911.10081", "submitter": "Taha Ceritli", "authors": "Taha Ceritli, Christopher K. I. Williams, James Geddes", "title": "ptype: Probabilistic Type Inference", "comments": null, "journal-ref": "Data Mining and Knowledge Discovery (2020)", "doi": "10.1007/s10618-020-00680-1", "report-no": null, "categories": "cs.LG cs.PL stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Type inference refers to the task of inferring the data type of a given\ncolumn of data. Current approaches often fail when data contains missing data\nand anomalies, which are found commonly in real-world data sets. In this paper,\nwe propose ptype, a probabilistic robust type inference method that allows us\nto detect such entries, and infer data types. We further show that the proposed\nmethod outperforms the existing methods.\n", "versions": [{"version": "v1", "created": "Fri, 22 Nov 2019 15:21:15 GMT"}, {"version": "v2", "created": "Mon, 23 Mar 2020 12:25:40 GMT"}], "update_date": "2020-03-24", "authors_parsed": [["Ceritli", "Taha", ""], ["Williams", "Christopher K. I.", ""], ["Geddes", "James", ""]]}, {"id": "1911.10088", "submitter": "Xinyi Wang", "authors": "Xinyi Wang, Hieu Pham, Paul Michel, Antonios Anastasopoulos, Jaime\n  Carbonell, Graham Neubig", "title": "Optimizing Data Usage via Differentiable Rewards", "comments": "Accepted at ICML 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CL stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  To acquire a new skill, humans learn better and faster if a tutor, based on\ntheir current knowledge level, informs them of how much attention they should\npay to particular content or practice problems. Similarly, a machine learning\nmodel could potentially be trained better with a scorer that \"adapts\" to its\ncurrent learning state and estimates the importance of each training data\ninstance. Training such an adaptive scorer efficiently is a challenging\nproblem; in order to precisely quantify the effect of a data instance at a\ngiven time during the training, it is typically necessary to first complete the\nentire training process. To efficiently optimize data usage, we propose a\nreinforcement learning approach called Differentiable Data Selection (DDS). In\nDDS, we formulate a scorer network as a learnable function of the training\ndata, which can be efficiently updated along with the main model being trained.\nSpecifically, DDS updates the scorer with an intuitive reward signal: it should\nup-weigh the data that has a similar gradient with a dev set upon which we\nwould finally like to perform well. Without significant computing overhead, DDS\ndelivers strong and consistent improvements over several strong baselines on\ntwo very different tasks of machine translation and image classification.\n", "versions": [{"version": "v1", "created": "Fri, 22 Nov 2019 15:38:01 GMT"}, {"version": "v2", "created": "Wed, 24 Jun 2020 03:46:58 GMT"}, {"version": "v3", "created": "Wed, 16 Jun 2021 18:33:21 GMT"}], "update_date": "2021-06-18", "authors_parsed": [["Wang", "Xinyi", ""], ["Pham", "Hieu", ""], ["Michel", "Paul", ""], ["Anastasopoulos", "Antonios", ""], ["Carbonell", "Jaime", ""], ["Neubig", "Graham", ""]]}, {"id": "1911.10092", "submitter": "Jayanta Mandi", "authors": "Jaynta Mandi, Emir Demirovi\\'c, Peter. J Stuckey, Tias Guns", "title": "Smart Predict-and-Optimize for Hard Combinatorial Optimization Problems", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI math.OC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Combinatorial optimization assumes that all parameters of the optimization\nproblem, e.g. the weights in the objective function is fixed. Often, these\nweights are mere estimates and increasingly machine learning techniques are\nused to for their estimation. Recently, Smart Predict and Optimize (SPO) has\nbeen proposed for problems with a linear objective function over the\npredictions, more specifically linear programming problems. It takes the regret\nof the predictions on the linear problem into account, by repeatedly solving it\nduring learning. We investigate the use of SPO to solve more realistic discrete\noptimization problems. The main challenge is the repeated solving of the\noptimization problem. To this end, we investigate ways to relax the problem as\nwell as warmstarting the learning and the solving. Our results show that even\nfor discrete problems it often suffices to train by solving the relaxation in\nthe SPO loss. Furthermore, this approach outperforms, for most instances, the\nstate-of-the-art approach of Wilder, Dilkina, and Tambe. We experiment with\nweighted knapsack problems as well as complex scheduling problems and show for\nthe first time that a predict-and-optimize approach can successfully be used on\nlarge-scale combinatorial optimization problems.\n", "versions": [{"version": "v1", "created": "Fri, 22 Nov 2019 15:45:26 GMT"}], "update_date": "2019-11-25", "authors_parsed": [["Mandi", "Jaynta", ""], ["Demirovi\u0107", "Emir", ""], ["Stuckey", "Peter. J", ""], ["Guns", "Tias", ""]]}, {"id": "1911.10097", "submitter": "Fangyu Liu", "authors": "Fangyu Liu, Rongtian Ye, Xun Wang, Shuaipeng Li", "title": "HAL: Improved Text-Image Matching by Mitigating Visual Semantic Hubs", "comments": "AAAI-20 (to appear)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CL cs.CV", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  The hubness problem widely exists in high-dimensional embedding space and is\na fundamental source of error for cross-modal matching tasks. In this work, we\nstudy the emergence of hubs in Visual Semantic Embeddings (VSE) with\napplication to text-image matching. We analyze the pros and cons of two widely\nadopted optimization objectives for training VSE and propose a novel\nhubness-aware loss function (HAL) that addresses previous methods' defects.\nUnlike (Faghri et al.2018) which simply takes the hardest sample within a\nmini-batch, HAL takes all samples into account, using both local and global\nstatistics to scale up the weights of \"hubs\". We experiment our method with\nvarious configurations of model architectures and datasets. The method exhibits\nexceptionally good robustness and brings consistent improvement on the task of\ntext-image matching across all settings. Specifically, under the same model\narchitectures as (Faghri et al. 2018) and (Lee at al. 2018), by switching only\nthe learning objective, we report a maximum R@1improvement of 7.4% on MS-COCO\nand 8.3% on Flickr30k.\n", "versions": [{"version": "v1", "created": "Fri, 22 Nov 2019 15:51:08 GMT"}], "update_date": "2019-11-25", "authors_parsed": [["Liu", "Fangyu", ""], ["Ye", "Rongtian", ""], ["Wang", "Xun", ""], ["Li", "Shuaipeng", ""]]}, {"id": "1911.10107", "submitter": "Zihao Zhang", "authors": "Zihao Zhang, Stefan Zohren, and Stephen Roberts", "title": "Deep Reinforcement Learning for Trading", "comments": "16 pages, 3 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-fin.CP cs.LG q-fin.TR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We adopt Deep Reinforcement Learning algorithms to design trading strategies\nfor continuous futures contracts. Both discrete and continuous action spaces\nare considered and volatility scaling is incorporated to create reward\nfunctions which scale trade positions based on market volatility. We test our\nalgorithms on the 50 most liquid futures contracts from 2011 to 2019, and\ninvestigate how performance varies across different asset classes including\ncommodities, equity indices, fixed income and FX markets. We compare our\nalgorithms against classical time series momentum strategies, and show that our\nmethod outperforms such baseline models, delivering positive profits despite\nheavy transaction costs. The experiments show that the proposed algorithms can\nfollow large market trends without changing positions and can also scale down,\nor hold, through consolidation periods.\n", "versions": [{"version": "v1", "created": "Fri, 22 Nov 2019 16:10:45 GMT"}], "update_date": "2019-11-25", "authors_parsed": [["Zhang", "Zihao", ""], ["Zohren", "Stefan", ""], ["Roberts", "Stephen", ""]]}, {"id": "1911.10109", "submitter": "Benjamin Steel", "authors": "Benjamin D. Steel", "title": "Implementation of Optical Deep Neural Networks using the Fabry-Perot\n  Interferometer", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.ET cs.LG eess.IV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Future developments in deep learning applications requiring large datasets\nwill be limited by power and speed limitations of silicon based Von-Neumann\ncomputing architectures. Optical architectures provide a low power and high\nspeed hardware alternative. Recent publications have suggested promising\nimplementations of optical neural networks (ONNs), showing huge orders of\nmagnitude efficiency and speed gains over current state of the art hardware\nalternatives. In this work, the transmission of the Fabry-Perot Interferometer\n(FPI) is proposed as a low power, low footprint activation function unit.\nNumerical simulations of optical CNNs using the FPI based activation functions\nshow accuracies of 98% on the MNIST dataset. An investigation of possible\nphysical implementation of the network shows that an ONN based on current\ntunable FPIs could be slowed by actuation delays, but rapidly developing\noptical hardware fabrication techniques could make an integrated approach using\nthe proposed FPI setups a powerful solution for previously inaccessible deep\nlearning applications.\n", "versions": [{"version": "v1", "created": "Fri, 22 Nov 2019 16:12:05 GMT"}, {"version": "v2", "created": "Fri, 28 Feb 2020 03:22:35 GMT"}], "update_date": "2020-03-02", "authors_parsed": [["Steel", "Benjamin D.", ""]]}, {"id": "1911.10113", "submitter": "Mohammed K Alzaylaee Dr", "authors": "Mohammed K. Alzaylaee, Suleiman Y. Yerima and Sakir Sezer", "title": "DL-Droid: Deep learning based android malware detection using real\n  devices", "comments": null, "journal-ref": null, "doi": "10.1016/j.cose.2019.101663", "report-no": null, "categories": "cs.CR cs.LG cs.NE stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  The Android operating system has been the most popular for smartphones and\ntablets since 2012. This popularity has led to a rapid raise of Android malware\nin recent years. The sophistication of Android malware obfuscation and\ndetection avoidance methods have significantly improved, making many\ntraditional malware detection methods obsolete. In this paper, we propose\nDL-Droid, a deep learning system to detect malicious Android applications\nthrough dynamic analysis using stateful input generation. Experiments performed\nwith over 30,000 applications (benign and malware) on real devices are\npresented. Furthermore, experiments were also conducted to compare the\ndetection performance and code coverage of the stateful input generation method\nwith the commonly used stateless approach using the deep learning system. Our\nstudy reveals that DL-Droid can achieve up to 97.8% detection rate (with\ndynamic features only) and 99.6% detection rate (with dynamic + static\nfeatures) respectively which outperforms traditional machine learning\ntechniques. Furthermore, the results highlight the significance of enhanced\ninput generation for dynamic analysis as DL-Droid with the state-based input\ngeneration is shown to outperform the existing state-of-the-art approaches.\n", "versions": [{"version": "v1", "created": "Fri, 22 Nov 2019 16:16:15 GMT"}], "update_date": "2019-11-25", "authors_parsed": [["Alzaylaee", "Mohammed K.", ""], ["Yerima", "Suleiman Y.", ""], ["Sezer", "Sakir", ""]]}, {"id": "1911.10115", "submitter": "Chiranjib Sur", "authors": "Chiranjib Sur", "title": "TPsgtR: Neural-Symbolic Tensor Product Scene-Graph-Triplet\n  Representation for Image Captioning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.CV cs.LG", "license": "http://creativecommons.org/licenses/by-sa/4.0/", "abstract": "  Image captioning can be improved if the structure of the graphical\nrepresentations can be formulated with conceptual positional binding. In this\nwork, we have introduced a novel technique for caption generation using the\nneural-symbolic encoding of the scene-graphs, derived from regional visual\ninformation of the images and we call it Tensor Product Scene-Graph-Triplet\nRepresentation (TP$_{sgt}$R). While, most of the previous works concentrated on\nidentification of the object features in images, we introduce a neuro-symbolic\nembedding that can embed identified relationships among different regions of\nthe image into concrete forms, instead of relying on the model to compose for\nany/all combinations. These neural symbolic representation helps in better\ndefinition of the neural symbolic space for neuro-symbolic attention and can be\ntransformed to better captions. With this approach, we introduced two novel\narchitectures (TP$_{sgt}$R-TDBU and TP$_{sgt}$R-sTDBU) for comparison and\nexperiment result demonstrates that our approaches outperformed the other\nmodels, and generated captions are more comprehensive and natural.\n", "versions": [{"version": "v1", "created": "Fri, 22 Nov 2019 16:17:21 GMT"}], "update_date": "2019-11-25", "authors_parsed": [["Sur", "Chiranjib", ""]]}, {"id": "1911.10119", "submitter": "Omar Peracha", "authors": "Omar Peracha and Shawn Head", "title": "GANkyoku: a Generative Adversarial Network for Shakuhachi Music", "comments": "Proceedings of the 2019 International Computer Music Conference, ICMC", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SD cs.LG eess.AS", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  A common approach to generating symbolic music using neural networks involves\nrepeated sampling of an autoregressive model until the full output sequence is\nobtained. While such approaches have shown some promise in generating short\nsequences of music, this typically has not extended to cases where the final\ntarget sequence is significantly longer, for example an entire piece of music.\nIn this work we propose a network trained in an adversarial process to generate\nentire pieces of solo shakuhachi music, in the form of symbolic notation. The\npieces are intended to refer clearly to traditional shakuhachi music,\nmaintaining idiomaticity and key aesthetic qualities, while also adding novel\nfeatures, ultimately creating worthy additions to the contemporary shakuhachi\nrepertoire. A key subproblem is also addressed, namely the lack of relevant\ntraining data readily available, in two steps: firstly, we introduce the\nPH_Shaku dataset for symbolic traditional shakuhachi music; secondly, we build\non previous work using conditioning in generative adversarial networks to\nintroduce a technique for data augmentation.\n", "versions": [{"version": "v1", "created": "Fri, 22 Nov 2019 16:19:40 GMT"}], "update_date": "2019-11-25", "authors_parsed": [["Peracha", "Omar", ""], ["Head", "Shawn", ""]]}, {"id": "1911.10120", "submitter": "Timothy Verstraeten", "authors": "Timothy Verstraeten and Eugenio Bargiacchi and Pieter JK Libin and Jan\n  Helsen and Diederik M Roijers and Ann Now\\'e", "title": "Multi-Agent Thompson Sampling for Bandit Applications with Sparse\n  Neighbourhood Structures", "comments": null, "journal-ref": "Sci Rep 10, 6728 (2020)", "doi": "10.1038/s41598-020-62939-3", "report-no": null, "categories": "cs.LG cs.AI cs.MA stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Multi-agent coordination is prevalent in many real-world applications.\nHowever, such coordination is challenging due to its combinatorial nature. An\nimportant observation in this regard is that agents in the real world often\nonly directly affect a limited set of neighbouring agents. Leveraging such\nloose couplings among agents is key to making coordination in multi-agent\nsystems feasible. In this work, we focus on learning to coordinate.\nSpecifically, we consider the multi-agent multi-armed bandit framework, in\nwhich fully cooperative loosely-coupled agents must learn to coordinate their\ndecisions to optimize a common objective. We propose multi-agent Thompson\nsampling (MATS), a new Bayesian exploration-exploitation algorithm that\nleverages loose couplings. We provide a regret bound that is sublinear in time\nand low-order polynomial in the highest number of actions of a single agent for\nsparse coordination graphs. Additionally, we empirically show that MATS\noutperforms the state-of-the-art algorithm, MAUCE, on two synthetic benchmarks,\nand a novel benchmark with Poisson distributions. An example of a\nloosely-coupled multi-agent system is a wind farm. Coordination within the wind\nfarm is necessary to maximize power production. As upstream wind turbines only\naffect nearby downstream turbines, we can use MATS to efficiently learn the\noptimal control mechanism for the farm. To demonstrate the benefits of our\nmethod toward applications we apply MATS to a realistic wind farm control task.\nIn this task, wind turbines must coordinate their alignments with respect to\nthe incoming wind vector in order to optimize power production. Our results\nshow that MATS improves significantly upon state-of-the-art coordination\nmethods in terms of performance, demonstrating the value of using MATS in\npractical applications with sparse neighbourhood structures.\n", "versions": [{"version": "v1", "created": "Fri, 22 Nov 2019 16:21:25 GMT"}, {"version": "v2", "created": "Fri, 7 Feb 2020 10:42:24 GMT"}], "update_date": "2020-06-25", "authors_parsed": [["Verstraeten", "Timothy", ""], ["Bargiacchi", "Eugenio", ""], ["Libin", "Pieter JK", ""], ["Helsen", "Jan", ""], ["Roijers", "Diederik M", ""], ["Now\u00e9", "Ann", ""]]}, {"id": "1911.10121", "submitter": "Timothy Verstraeten", "authors": "Timothy Verstraeten and Pieter JK Libin and Ann Now\\'e", "title": "Fleet Control using Coregionalized Gaussian Process Policy Iteration", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.SY eess.SY stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In many settings, as for example wind farms, multiple machines are\ninstantiated to perform the same task, which is called a fleet. The recent\nadvances with respect to the Internet of Things allow control devices and/or\nmachines to connect through cloud-based architectures in order to share\ninformation about their status and environment. Such an infrastructure allows\nseamless data sharing between fleet members, which could greatly improve the\nsample-efficiency of reinforcement learning techniques. However in practice,\nthese machines, while almost identical in design, have small discrepancies due\nto production errors or degradation, preventing control algorithms to simply\naggregate and employ all fleet data. We propose a novel reinforcement learning\nmethod that learns to transfer knowledge between similar fleet members and\ncreates member-specific dynamics models for control. Our algorithm uses\nGaussian processes to establish cross-member covariances. This is significantly\ndifferent from standard transfer learning methods, as the focus is not on\nsharing information over tasks, but rather over system specifications. We\ndemonstrate our approach on two benchmarks and a realistic wind farm setting.\nOur method significantly outperforms two baseline approaches, namely individual\nlearning and joint learning where all samples are aggregated, in terms of the\nmedian and variance of the results.\n", "versions": [{"version": "v1", "created": "Fri, 22 Nov 2019 16:23:34 GMT"}], "update_date": "2019-11-25", "authors_parsed": [["Verstraeten", "Timothy", ""], ["Libin", "Pieter JK", ""], ["Now\u00e9", "Ann", ""]]}, {"id": "1911.10124", "submitter": "Timoth\\'ee Masquelier Dr", "authors": "Romain Zimmer, Thomas Pellegrini, Srisht Fateh Singh, Timoth\\'ee\n  Masquelier", "title": "Technical report: supervised training of convolutional spiking neural\n  networks with PyTorch", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recently, it has been shown that spiking neural networks (SNNs) can be\ntrained efficiently, in a supervised manner, using backpropagation through\ntime. Indeed, the most commonly used spiking neuron model, the leaky\nintegrate-and-fire neuron, obeys a differential equation which can be\napproximated using discrete time steps, leading to a recurrent relation for the\npotential. The firing threshold causes optimization issues, but they can be\novercome using a surrogate gradient. Here, we extend previous approaches in two\nways. Firstly, we show that the approach can be used to train convolutional\nlayers. Convolutions can be done in space, time (which simulates conduction\ndelays), or both. Secondly, we include fast horizontal connections \\`a la\nDen\\`eve: when a neuron N fires, we subtract to the potentials of all the\nneurons with the same receptive the dot product between their weight vectors\nand the one of neuron N. As Den\\`eve et al. showed, this is useful to represent\na dynamic multidimensional analog signal in a population of spiking neurons.\nHere we demonstrate that, in addition, such connections also allow implementing\na multidimensional send-on-delta coding scheme. We validate our approach on one\nspeech classification benchmarks: the Google speech command dataset. We managed\nto reach nearly state-of-the-art accuracy (94%) while maintaining low firing\nrates (about 5Hz). Our code is based on PyTorch and is available in open source\nat http://github.com/romainzimmer/s2net\n", "versions": [{"version": "v1", "created": "Fri, 22 Nov 2019 16:24:38 GMT"}], "update_date": "2019-11-25", "authors_parsed": [["Zimmer", "Romain", ""], ["Pellegrini", "Thomas", ""], ["Singh", "Srisht Fateh", ""], ["Masquelier", "Timoth\u00e9e", ""]]}, {"id": "1911.10131", "submitter": "Toshiaki Koike-Akino", "authors": "Toshiaki Koike-Akino, Ye Wang, David S. Millar, Keisuke Kojima, Kieran\n  Parsons", "title": "Neural Turbo Equalization: Deep Learning for Fiber-Optic Nonlinearity\n  Compensation", "comments": "7 pages, 13 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.SP cs.IT cs.LG math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recently, data-driven approaches motivated by modern deep learning have been\napplied to optical communications in place of traditional model-based\ncounterparts. The application of deep neural networks (DNN) allows flexible\nstatistical analysis of complicated fiber-optic systems without relying on any\nspecific physical models. Due to the inherent nonlinearity in DNN, various\nequalizers based on DNN have shown significant potentials to mitigate fiber\nnonlinearity. In this paper, we propose a turbo equalization (TEQ) based on DNN\nas a new alternative framework to deal with nonlinear fiber impairments for\nfuture coherent optical communications. The proposed DNN-TEQ is constructed\nwith nested deep residual networks (ResNet) to train extrinsic likelihood given\nsoft-information feedback from channel decoding. Through extrinsic information\ntransfer (EXIT) analysis, we verify that our DNN-TEQ can accelerate decoding\nconvergence to achieve a significant gain in achievable throughput by\n0.61b/s/Hz. We also demonstrate that optimizing irregular low-density\nparity-check (LDPC) codes to match EXIT chart of the DNN-TEQ can improve\nachievable rates by up to 0.12 b/s/Hz.\n", "versions": [{"version": "v1", "created": "Fri, 22 Nov 2019 16:40:51 GMT"}], "update_date": "2019-11-25", "authors_parsed": [["Koike-Akino", "Toshiaki", ""], ["Wang", "Ye", ""], ["Millar", "David S.", ""], ["Kojima", "Keisuke", ""], ["Parsons", "Kieran", ""]]}, {"id": "1911.10134", "submitter": "Thibault Duhamel", "authors": "Thibault Duhamel, Mariane Maynard, Froduald Kabanza", "title": "A Transfer Learning Method for Goal Recognition Exploiting Cross-Domain\n  Spatial Features", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The ability to infer the intentions of others, predict their goals, and\ndeduce their plans are critical features for intelligent agents. For a long\ntime, several approaches investigated the use of symbolic representations and\ninferences with limited success, principally because it is difficult to capture\nthe cognitive knowledge behind human decisions explicitly. The trend, nowadays,\nis increasingly focusing on learning to infer intentions directly from data,\nusing deep learning in particular. We are now observing interesting\napplications of intent classification in natural language processing, visual\nactivity recognition, and emerging approaches in other domains. This paper\ndiscusses a novel approach combining few-shot and transfer learning with\ncross-domain features, to learn to infer the intent of an agent navigating in\nphysical environments, executing arbitrary long sequences of actions to achieve\ntheir goals. Experiments in synthetic environments demonstrate improved\nperformance in terms of learning from few samples and generalizing to unseen\nconfigurations, compared to a deep-learning baseline approach.\n", "versions": [{"version": "v1", "created": "Fri, 22 Nov 2019 16:53:19 GMT"}], "update_date": "2019-11-25", "authors_parsed": [["Duhamel", "Thibault", ""], ["Maynard", "Mariane", ""], ["Kabanza", "Froduald", ""]]}, {"id": "1911.10137", "submitter": "Uri Stemmer", "authors": "Haim Kaplan, Katrina Ligett, Yishay Mansour, Moni Naor, Uri Stemmer", "title": "Privately Learning Thresholds: Closing the Exponential Gap", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.CR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the sample complexity of learning threshold functions under the\nconstraint of differential privacy. It is assumed that each labeled example in\nthe training data is the information of one individual and we would like to\ncome up with a generalizing hypothesis $h$ while guaranteeing differential\nprivacy for the individuals. Intuitively, this means that any single labeled\nexample in the training data should not have a significant effect on the choice\nof the hypothesis. This problem has received much attention recently; unlike\nthe non-private case, where the sample complexity is independent of the domain\nsize and just depends on the desired accuracy and confidence, for private\nlearning the sample complexity must depend on the domain size $X$ (even for\napproximate differential privacy). Alon et al. (STOC 2019) showed a lower bound\nof $\\Omega(\\log^*|X|)$ on the sample complexity and Bun et al. (FOCS 2015)\npresented an approximate-private learner with sample complexity\n$\\tilde{O}\\left(2^{\\log^*|X|}\\right)$. In this work we reduce this gap\nsignificantly, almost settling the sample complexity. We first present a new\nupper bound (algorithm) of $\\tilde{O}\\left(\\left(\\log^*|X|\\right)^2\\right)$ on\nthe sample complexity and then present an improved version with sample\ncomplexity $\\tilde{O}\\left(\\left(\\log^*|X|\\right)^{1.5}\\right)$.\n  Our algorithm is constructed for the related interior point problem, where\nthe goal is to find a point between the largest and smallest input elements. It\nis based on selecting an input-dependent hash function and using it to embed\nthe database into a domain whose size is reduced logarithmically; this results\nin a new database, an interior point of which can be used to generate an\ninterior point in the original database in a differentially private manner.\n", "versions": [{"version": "v1", "created": "Fri, 22 Nov 2019 16:58:25 GMT"}], "update_date": "2019-11-25", "authors_parsed": [["Kaplan", "Haim", ""], ["Ligett", "Katrina", ""], ["Mansour", "Yishay", ""], ["Naor", "Moni", ""], ["Stemmer", "Uri", ""]]}, {"id": "1911.10143", "submitter": "Taihong Xiao", "authors": "Taihong Xiao, Yi-Hsuan Tsai, Kihyuk Sohn, Manmohan Chandraker,\n  Ming-Hsuan Yang", "title": "Adversarial Learning of Privacy-Preserving and Task-Oriented\n  Representations", "comments": null, "journal-ref": "AAAI 2020", "doi": null, "report-no": null, "categories": "cs.LG cs.CR cs.CV", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Data privacy has emerged as an important issue as data-driven deep learning\nhas been an essential component of modern machine learning systems. For\ninstance, there could be a potential privacy risk of machine learning systems\nvia the model inversion attack, whose goal is to reconstruct the input data\nfrom the latent representation of deep networks. Our work aims at learning a\nprivacy-preserving and task-oriented representation to defend against such\nmodel inversion attacks. Specifically, we propose an adversarial reconstruction\nlearning framework that prevents the latent representations decoded into\noriginal input data. By simulating the expected behavior of adversary, our\nframework is realized by minimizing the negative pixel reconstruction loss or\nthe negative feature reconstruction (i.e., perceptual distance) loss. We\nvalidate the proposed method on face attribute prediction, showing that our\nmethod allows protecting visual privacy with a small decrease in utility\nperformance. In addition, we show the utility-privacy trade-off with different\nchoices of hyperparameter for negative perceptual distance loss at training,\nallowing service providers to determine the right level of privacy-protection\nwith a certain utility performance. Moreover, we provide an extensive study\nwith different selections of features, tasks, and the data to further analyze\ntheir influence on privacy protection.\n", "versions": [{"version": "v1", "created": "Fri, 22 Nov 2019 17:06:28 GMT"}], "update_date": "2019-11-25", "authors_parsed": [["Xiao", "Taihong", ""], ["Tsai", "Yi-Hsuan", ""], ["Sohn", "Kihyuk", ""], ["Chandraker", "Manmohan", ""], ["Yang", "Ming-Hsuan", ""]]}, {"id": "1911.10150", "submitter": "Alex Lang", "authors": "Sourabh Vora, Alex H. Lang, Bassam Helou, and Oscar Beijbom", "title": "PointPainting: Sequential Fusion for 3D Object Detection", "comments": "11 pages, 6 figures, 8 tables. v1 is initial submission to CVPR 2020.\n  v2 is final version accepted for publication at CVPR 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG eess.IV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Camera and lidar are important sensor modalities for robotics in general and\nself-driving cars in particular. The sensors provide complementary information\noffering an opportunity for tight sensor-fusion. Surprisingly, lidar-only\nmethods outperform fusion methods on the main benchmark datasets, suggesting a\ngap in the literature. In this work, we propose PointPainting: a sequential\nfusion method to fill this gap. PointPainting works by projecting lidar points\ninto the output of an image-only semantic segmentation network and appending\nthe class scores to each point. The appended (painted) point cloud can then be\nfed to any lidar-only method. Experiments show large improvements on three\ndifferent state-of-the art methods, Point-RCNN, VoxelNet and PointPillars on\nthe KITTI and nuScenes datasets. The painted version of PointRCNN represents a\nnew state of the art on the KITTI leaderboard for the bird's-eye view detection\ntask. In ablation, we study how the effects of Painting depends on the quality\nand format of the semantic segmentation output, and demonstrate how latency can\nbe minimized through pipelining.\n", "versions": [{"version": "v1", "created": "Fri, 22 Nov 2019 17:19:50 GMT"}, {"version": "v2", "created": "Wed, 6 May 2020 17:17:18 GMT"}], "update_date": "2020-05-07", "authors_parsed": [["Vora", "Sourabh", ""], ["Lang", "Alex H.", ""], ["Helou", "Bassam", ""], ["Beijbom", "Oscar", ""]]}, {"id": "1911.10164", "submitter": "Jacob Rafati", "authors": "Jacob Rafati, David C. Noelle", "title": "Efficient Exploration through Intrinsic Motivation Learning for\n  Unsupervised Subgoal Discovery in Model-Free Hierarchical Reinforcement\n  Learning", "comments": "arXiv admin note: substantial text overlap with arXiv:1810.10096", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Efficient exploration for automatic subgoal discovery is a challenging\nproblem in Hierarchical Reinforcement Learning (HRL). In this paper, we show\nthat intrinsic motivation learning increases the efficiency of exploration,\nleading to successful subgoal discovery. We introduce a model-free subgoal\ndiscovery method based on unsupervised learning over a limited memory of\nagent's experiences during intrinsic motivation. Additionally, we offer a\nunified approach to learning representations in model-free HRL.\n", "versions": [{"version": "v1", "created": "Mon, 18 Nov 2019 23:30:36 GMT"}], "update_date": "2019-11-25", "authors_parsed": [["Rafati", "Jacob", ""], ["Noelle", "David C.", ""]]}, {"id": "1911.10167", "submitter": "Marco Avella", "authors": "Marco Avella-Medina", "title": "Privacy-preserving parametric inference: a case for robust statistics", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Differential privacy is a cryptographically-motivated approach to privacy\nthat has become a very active field of research over the last decade in\ntheoretical computer science and machine learning. In this paradigm one assumes\nthere is a trusted curator who holds the data of individuals in a database and\nthe goal of privacy is to simultaneously protect individual data while allowing\nthe release of global characteristics of the database. In this setting we\nintroduce a general framework for parametric inference with differential\nprivacy guarantees. We first obtain differentially private estimators based on\nbounded influence M-estimators by leveraging their gross-error sensitivity in\nthe calibration of a noise term added to them in order to ensure privacy. We\nthen show how a similar construction can also be applied to construct\ndifferentially private test statistics analogous to the Wald, score and\nlikelihood ratio tests. We provide statistical guarantees for all our proposals\nvia an asymptotic analysis. An interesting consequence of our results is to\nfurther clarify the connection between differential privacy and robust\nstatistics. In particular, we demonstrate that differential privacy is a weaker\nstability requirement than infinitesimal robustness, and show that robust\nM-estimators can be easily randomized in order to guarantee both differential\nprivacy and robustness towards the presence of contaminated data. We illustrate\nour results both on simulated and real data.\n", "versions": [{"version": "v1", "created": "Fri, 22 Nov 2019 17:59:58 GMT"}], "update_date": "2019-11-25", "authors_parsed": [["Avella-Medina", "Marco", ""]]}, {"id": "1911.10175", "submitter": "Houxiang Ji", "authors": "Zhangxiaowen Gong, Houxiang Ji, Christopher Fletcher, Christopher\n  Hughes, Josep Torrellas", "title": "SparseTrain:Leveraging Dynamic Sparsity in Training DNNs on\n  General-Purpose SIMD Processors", "comments": null, "journal-ref": null, "doi": "10.1145/3410463.3414655", "report-no": null, "categories": "cs.LG cs.DC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Our community has greatly improved the efficiency of deep learning\napplications, including by exploiting sparsity in inputs. Most of that work,\nthough, is for inference, where weight sparsity is known statically, and/or for\nspecialized hardware. We propose a scheme to leverage dynamic sparsity during\ntraining. In particular, we exploit zeros introduced by the ReLU activation\nfunction to both feature maps and their gradients. This is challenging because\nthe sparsity degree is moderate and the locations of zeros change over time. We\nalso rely purely on software. We identify zeros in a dense data representation\nwithout transforming the data and performs conventional vectorized computation.\nVariations of the scheme are applicable to all major components of training:\nforward propagation, backward propagation by inputs, and backward propagation\nby weights. Our method significantly outperforms a highly-optimized dense\ndirect convolution on several popular deep neural networks. At realistic\nsparsity, we speed up the training of the non-initial convolutional layers in\nVGG16, ResNet-34, ResNet-50, and Fixup ResNet-50 by 2.19x, 1.37x, 1.31x, and\n1.51x respectively on an Intel Skylake-X CPU.\n", "versions": [{"version": "v1", "created": "Fri, 22 Nov 2019 18:19:32 GMT"}], "update_date": "2020-12-04", "authors_parsed": [["Gong", "Zhangxiaowen", ""], ["Ji", "Houxiang", ""], ["Fletcher", "Christopher", ""], ["Hughes", "Christopher", ""], ["Torrellas", "Josep", ""]]}, {"id": "1911.10182", "submitter": "Jon Vadillo Jueguen", "authors": "Jon Vadillo and Roberto Santana", "title": "Universal adversarial examples in speech command classification", "comments": "14 pages, 2 figures, 4 tables; Revised external links", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG eess.AS stat.ML", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Adversarial examples are inputs intentionally perturbed with the aim of\nforcing a machine learning model to produce a wrong prediction, while the\nchanges are not easily detectable by a human. Although this topic has been\nintensively studied in the image domain, classification tasks in the audio\ndomain have received less attention. In this paper we address the existence of\nuniversal perturbations for speech command classification. We provide evidence\nthat universal attacks can be generated for speech command classification\ntasks, which are able to generalize across different models to a significant\nextent. Additionally, a novel analytical framework is proposed for the\nevaluation of universal perturbations under different levels of universality,\ndemonstrating that the feasibility of generating effective perturbations\ndecreases as the universality level increases. Finally, we propose a more\ndetailed and rigorous framework to measure the amount of distortion introduced\nby the perturbations, demonstrating that the methods employed by convention are\nnot realistic in audio-based problems.\n", "versions": [{"version": "v1", "created": "Fri, 22 Nov 2019 18:31:52 GMT"}, {"version": "v2", "created": "Tue, 26 Nov 2019 22:55:43 GMT"}, {"version": "v3", "created": "Sat, 21 Mar 2020 19:20:15 GMT"}, {"version": "v4", "created": "Sat, 13 Feb 2021 12:00:32 GMT"}], "update_date": "2021-02-16", "authors_parsed": [["Vadillo", "Jon", ""], ["Santana", "Roberto", ""]]}, {"id": "1911.10225", "submitter": "Juan Jose Giraldo Gutierrez", "authors": "Juan-Jos\\'e Giraldo and Mauricio A. \\'Alvarez", "title": "A Fully Natural Gradient Scheme for Improving Inference of the\n  Heterogeneous Multi-Output Gaussian Process Model", "comments": "we have rewritten: sections 2 and 3, included details of the HetMOGP\n  and our proposed inference method in sections 4 and 6; a brief\n  state-of-the-art review of MOGPs in 4.1; included a novel extension of the\n  HetMOGP with convolution processes in 5. We derived the fully natural\n  gradient updates for the new model in section 6.2; new results and discussion\n  in experiments section; new appendices added", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A recent novel extension of multi-output Gaussian processes handles\nheterogeneous outputs assuming that each output has its own likelihood\nfunction. It uses a vector-valued Gaussian process prior to jointly model all\nlikelihoods' parameters as latent functions drawn from a Gaussian process with\na linear model of coregionalisation covariance. By means of an inducing points\nframework, the model is able to obtain tractable variational bounds amenable to\nstochastic variational inference. Nonetheless, the strong conditioning between\nthe variational parameters and the hyper-parameters burdens the adaptive\ngradient optimisation methods used in the original approach. To overcome this\nissue we borrow ideas from variational optimisation introducing an exploratory\ndistribution over the hyper-parameters, allowing inference together with the\nposterior's variational parameters through a fully natural gradient\noptimisation scheme. Furthermore, in this work we introduce an extension of the\nheterogeneous multi-output model, where its latent functions are drawn from\nconvolution processes. We show that our optimisation scheme can achieve better\nlocal optima solutions with higher test performance rates than adaptive\ngradient methods, this for both the linear model of coregionalisation and the\nconvolution processes model. We also show how to make the convolutional model\nscalable by means of stochastic variational inference and how to optimise it\nthrough a fully natural gradient scheme. We compare the performance of the\ndifferent methods over toy and real databases.\n", "versions": [{"version": "v1", "created": "Fri, 22 Nov 2019 19:29:27 GMT"}, {"version": "v2", "created": "Wed, 27 Nov 2019 11:52:01 GMT"}, {"version": "v3", "created": "Mon, 13 Jul 2020 20:32:07 GMT"}], "update_date": "2020-07-15", "authors_parsed": [["Giraldo", "Juan-Jos\u00e9", ""], ["\u00c1lvarez", "Mauricio A.", ""]]}, {"id": "1911.10227", "submitter": "Vyom Raval", "authors": "Vyom Raval, Kevin P. Nguyen, Ashley Gerald, Richard B. Dewey Jr.,\n  Albert Montillo", "title": "Prediction of individual progression rate in Parkinson's disease using\n  clinical measures and biomechanical measures of gait and postural stability", "comments": "5 pages, 4 figures, IEEE ICASSP conference submission", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.SP cs.LG q-bio.NC q-bio.QM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Parkinson's disease (PD) is a common neurological disorder characterized by\ngait impairment. PD has no cure, and an impediment to developing a treatment is\nthe lack of any accepted method to predict disease progression rate. The\nprimary aim of this study was to develop a model using clinical measures and\nbiomechanical measures of gait and postural stability to predict an\nindividual's PD progression over two years. Data from 160 PD subjects were\nutilized. Machine learning models, including XGBoost and Feed Forward Neural\nNetworks, were developed using extensive model optimization and\ncross-validation. The highest performing model was a neural network that used a\ngroup of clinical measures, achieved a PPV of 71% in identifying fast\nprogressors, and explained a large portion (37%) of the variance in an\nindividual's progression rate on held-out test data. This demonstrates the\npotential to predict individual PD progression rate and enrich trials by\nanalyzing clinical and biomechanical measures with machine learning.\n", "versions": [{"version": "v1", "created": "Fri, 22 Nov 2019 19:35:55 GMT"}], "update_date": "2019-11-26", "authors_parsed": [["Raval", "Vyom", ""], ["Nguyen", "Kevin P.", ""], ["Gerald", "Ashley", ""], ["Dewey", "Richard B.", "Jr."], ["Montillo", "Albert", ""]]}, {"id": "1911.10232", "submitter": "Kai Ni", "authors": "Amit Pande, Kai Ni and Venkataramani Kini", "title": "SWAG: Item Recommendations using Convolutions on Weighted Graphs", "comments": "10 pages, 8 figures, 2019 IEEE BigData special session", "journal-ref": "2019 IEEE International Conference on Big Data", "doi": "10.1109/BigData47090.2019.9005633", "report-no": null, "categories": "cs.IR cs.LG stat.CO stat.ML", "license": "http://creativecommons.org/publicdomain/zero/1.0/", "abstract": "  Recent advancements in deep neural networks for graph-structured data have\nled to state-of-the-art performance on recommender system benchmarks. In this\nwork, we present a Graph Convolutional Network (GCN) algorithm SWAG (Sample\nWeight and AGgregate), which combines efficient random walks and graph\nconvolutions on weighted graphs to generate embeddings for nodes (items) that\nincorporate both graph structure as well as node feature information such as\nitem-descriptions and item-images. The three important SWAG operations that\nenable us to efficiently generate node embeddings based on graph structures are\n(a) Sampling of graph to homogeneous structure, (b) Weighting the sampling,\nwalks and convolution operations, and (c) using AGgregation functions for\ngenerating convolutions. The work is an adaptation of graphSAGE over weighted\ngraphs. We deploy SWAG at Target and train it on a graph of more than 500K\nproducts sold online with over 50M edges. Offline and online evaluations reveal\nthe benefit of using a graph-based approach and the benefits of weighing to\nproduce high quality embeddings and product recommendations.\n", "versions": [{"version": "v1", "created": "Fri, 22 Nov 2019 19:51:58 GMT"}], "update_date": "2020-08-24", "authors_parsed": [["Pande", "Amit", ""], ["Ni", "Kai", ""], ["Kini", "Venkataramani", ""]]}, {"id": "1911.10235", "submitter": "Yiren Wang", "authors": "Yiren Wang, Hongzhao Huang, Zhe Liu, Yutong Pang, Yongqiang Wang,\n  ChengXiang Zhai, Fuchun Peng", "title": "Improving N-gram Language Models with Pre-trained Deep Transformer", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Although n-gram language models (LMs) have been outperformed by the\nstate-of-the-art neural LMs, they are still widely used in speech recognition\ndue to its high efficiency in inference. In this paper, we demonstrate that\nn-gram LM can be improved by neural LMs through a text generation based data\naugmentation method. In contrast to previous approaches, we employ a\nlarge-scale general domain pre-training followed by in-domain fine-tuning\nstrategy to construct deep Transformer based neural LMs. Large amount of\nin-domain text data is generated with the well trained deep Transformer to\nconstruct new n-gram LMs, which are then interpolated with baseline n-gram\nsystems. Empirical studies on different speech recognition tasks show that the\nproposed approach can effectively improve recognition accuracy. In particular,\nour proposed approach brings significant relative word error rate reduction up\nto 6.0% for domains with limited in-domain data.\n", "versions": [{"version": "v1", "created": "Fri, 22 Nov 2019 20:11:40 GMT"}], "update_date": "2019-12-03", "authors_parsed": [["Wang", "Yiren", ""], ["Huang", "Hongzhao", ""], ["Liu", "Zhe", ""], ["Pang", "Yutong", ""], ["Wang", "Yongqiang", ""], ["Zhai", "ChengXiang", ""], ["Peng", "Fuchun", ""]]}, {"id": "1911.10241", "submitter": "Samuel Finlayson", "authors": "Samuel G. Finlayson, Matthew B.A. McDermott, Alex V. Pickering, Scott\n  L. Lipnick, Isaac S. Kohane", "title": "Cross-modal representation alignment of molecular structure and\n  perturbation-induced transcriptional profiles", "comments": "Accepted for oral presentation at the Pacific Symposium of\n  Biocomputing, 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.QM cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Modeling the relationship between chemical structure and molecular activity\nis a key goal in drug development. Many benchmark tasks have been proposed for\nmolecular property prediction, but these tasks are generally aimed at specific,\nisolated biomedical properties. In this work, we propose a new cross-modal\nsmall molecule retrieval task, designed to force a model to learn to associate\nthe structure of a small molecule with the transcriptional change it induces.\nWe develop this task formally as multi-view alignment problem, and present a\ncoordinated deep learning approach that jointly optimizes representations of\nboth chemical structure and perturbational gene expression profiles. We\nbenchmark our results against oracle models and principled baselines, and find\nthat cell line variability markedly influences performance in this domain. Our\nwork establishes the feasibility of this new task, elucidates the limitations\nof current data and systems, and may serve to catalyze future research in small\nmolecule representation learning.\n", "versions": [{"version": "v1", "created": "Fri, 22 Nov 2019 20:30:43 GMT"}, {"version": "v2", "created": "Fri, 2 Oct 2020 01:15:26 GMT"}], "update_date": "2020-10-05", "authors_parsed": [["Finlayson", "Samuel G.", ""], ["McDermott", "Matthew B. A.", ""], ["Pickering", "Alex V.", ""], ["Lipnick", "Scott L.", ""], ["Kohane", "Isaac S.", ""]]}, {"id": "1911.10244", "submitter": "Daniel Kroening", "authors": "Mohammadhosein Hasanbeig, Natasha Yogananda Jeppu, Alessandro Abate,\n  Tom Melham, Daniel Kroening", "title": "DeepSynth: Automata Synthesis for Automatic Task Segmentation in Deep\n  Reinforcement Learning", "comments": "Extended version of AAAI 2021 paper", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.LO stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper proposes DeepSynth, a method for effective training of deep\nReinforcement Learning (RL) agents when the reward is sparse and non-Markovian,\nbut at the same time progress towards the reward requires achieving an unknown\nsequence of high-level objectives. Our method employs a novel algorithm for\nsynthesis of compact automata to uncover this sequential structure\nautomatically. We synthesise a human-interpretable automaton from trace data\ncollected by exploring the environment. The state space of the environment is\nthen enriched with the synthesised automaton so that the generation of a\ncontrol policy by deep RL is guided by the discovered structure encoded in the\nautomaton. The proposed approach is able to cope with both high-dimensional,\nlow-level features and unknown sparse non-Markovian rewards. We have evaluated\nDeepSynth's performance in a set of experiments that includes the Atari game\nMontezuma's Revenge. Compared to existing approaches, we obtain a reduction of\ntwo orders of magnitude in the number of iterations required for policy\nsynthesis, and also a significant improvement in scalability.\n", "versions": [{"version": "v1", "created": "Fri, 22 Nov 2019 20:44:27 GMT"}, {"version": "v2", "created": "Wed, 12 Feb 2020 13:51:38 GMT"}, {"version": "v3", "created": "Thu, 27 Feb 2020 17:46:02 GMT"}, {"version": "v4", "created": "Tue, 22 Sep 2020 19:58:16 GMT"}, {"version": "v5", "created": "Sat, 6 Mar 2021 09:53:15 GMT"}], "update_date": "2021-03-09", "authors_parsed": [["Hasanbeig", "Mohammadhosein", ""], ["Jeppu", "Natasha Yogananda", ""], ["Abate", "Alessandro", ""], ["Melham", "Tom", ""], ["Kroening", "Daniel", ""]]}, {"id": "1911.10258", "submitter": "Sahil Singla", "authors": "Sahil Singla, Soheil Feizi", "title": "Fantastic Four: Differentiable Bounds on Singular Values of Convolution\n  Layers", "comments": "Accepted at ICLR, 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In deep neural networks, the spectral norm of the Jacobian of a layer bounds\nthe factor by which the norm of a signal changes during forward/backward\npropagation. Spectral norm regularizations have been shown to improve\ngeneralization, robustness and optimization of deep learning methods. Existing\nmethods to compute the spectral norm of convolution layers either rely on\nheuristics that are efficient in computation but lack guarantees or are\ntheoretically-sound but computationally expensive. In this work, we obtain the\nbest of both worlds by deriving {\\it four} provable upper bounds on the\nspectral norm of a standard 2D multi-channel convolution layer. These bounds\nare differentiable and can be computed efficiently during training with\nnegligible overhead. One of these bounds is in fact the popular heuristic\nmethod of Miyato et al. (multiplied by a constant factor depending on filter\nsizes). Each of these four bounds can achieve the tightest gap depending on\nconvolution filters. Thus, we propose to use the minimum of these four bounds\nas a tight, differentiable and efficient upper bound on the spectral norm of\nconvolution layers. We show that our spectral bound is an effective regularizer\nand can be used to bound either the lipschitz constant or curvature values\n(eigenvalues of the Hessian) of neural networks. Through experiments on MNIST\nand CIFAR-10, we demonstrate the effectiveness of our spectral bound in\nimproving generalization and provable robustness of deep networks.\n", "versions": [{"version": "v1", "created": "Fri, 22 Nov 2019 21:29:32 GMT"}, {"version": "v2", "created": "Fri, 30 Apr 2021 14:35:43 GMT"}, {"version": "v3", "created": "Sat, 12 Jun 2021 10:04:31 GMT"}], "update_date": "2021-06-15", "authors_parsed": [["Singla", "Sahil", ""], ["Feizi", "Soheil", ""]]}, {"id": "1911.10273", "submitter": "Xianfeng Tang", "authors": "Xianfeng Tang, Huaxiu Yao, Yiwei Sun, Charu Aggarwal, Prasenjit Mitra,\n  Suhang Wang", "title": "Joint Modeling of Local and Global Temporal Dynamics for Multivariate\n  Time Series Forecasting with Missing Values", "comments": "Accepted by AAAI 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Multivariate time series (MTS) forecasting is widely used in various domains,\nsuch as meteorology and traffic. Due to limitations on data collection,\ntransmission, and storage, real-world MTS data usually contains missing values,\nmaking it infeasible to apply existing MTS forecasting models such as linear\nregression and recurrent neural networks. Though many efforts have been devoted\nto this problem, most of them solely rely on local dependencies for imputing\nmissing values, which ignores global temporal dynamics. Local\ndependencies/patterns would become less useful when the missing ratio is high,\nor the data have consecutive missing values; while exploring global patterns\ncan alleviate such problems. Thus, jointly modeling local and global temporal\ndynamics is very promising for MTS forecasting with missing values. However,\nwork in this direction is rather limited. Therefore, we study a novel problem\nof MTS forecasting with missing values by jointly exploring local and global\ntemporal dynamics. We propose a new framework LGnet, which leverages memory\nnetwork to explore global patterns given estimations from local perspectives.\nWe further introduce adversarial training to enhance the modeling of global\ntemporal distribution. Experimental results on real-world datasets show the\neffectiveness of LGnet for MTS forecasting with missing values and its\nrobustness under various missing ratios.\n", "versions": [{"version": "v1", "created": "Fri, 22 Nov 2019 22:52:14 GMT"}], "update_date": "2019-11-26", "authors_parsed": [["Tang", "Xianfeng", ""], ["Yao", "Huaxiu", ""], ["Sun", "Yiwei", ""], ["Aggarwal", "Charu", ""], ["Mitra", "Prasenjit", ""], ["Wang", "Suhang", ""]]}, {"id": "1911.10287", "submitter": "Ghouthi Boukli Hacene", "authors": "Ghouthi Boukli Hacene, Fran\\c{c}ois Leduc-Primeau, Amal Ben Soussia,\n  Vincent Gripon and Fran\\c{c}ois Gagnon", "title": "Training Modern Deep Neural Networks for Memory-Fault Robustness", "comments": null, "journal-ref": "In 2019 IEEE International Symposium on Circuits and Systems\n  (ISCAS) (pp. 1-5). IEEE", "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Because deep neural networks (DNNs) rely on a large number of parameters and\ncomputations, their implementation in energy-constrained systems is\nchallenging. In this paper, we investigate the solution of reducing the supply\nvoltage of the memories used in the system, which results in bit-cell faults.\nWe explore the robustness of state-of-the-art DNN architectures towards such\ndefects and propose a regularizer meant to mitigate their effects on accuracy.\nOur experiments clearly demonstrate the interest of operating the system in a\nfaulty regime to save energy without reducing accuracy.\n", "versions": [{"version": "v1", "created": "Sat, 23 Nov 2019 00:09:36 GMT"}], "update_date": "2019-11-26", "authors_parsed": [["Hacene", "Ghouthi Boukli", ""], ["Leduc-Primeau", "Fran\u00e7ois", ""], ["Soussia", "Amal Ben", ""], ["Gripon", "Vincent", ""], ["Gagnon", "Fran\u00e7ois", ""]]}, {"id": "1911.10290", "submitter": "Sam Kriegman", "authors": "Sam Kriegman, Amir Mohammadi Nasab, Dylan Shah, Hannah Steele,\n  Gabrielle Branin, Michael Levin, Josh Bongard, Rebecca Kramer-Bottiglio", "title": "Scalable sim-to-real transfer of soft robot designs", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The manual design of soft robots and their controllers is notoriously\nchallenging, but it could be augmented---or, in some cases, entirely\nreplaced---by automated design tools. Machine learning algorithms can\nautomatically propose, test, and refine designs in simulation, and the most\npromising ones can then be manufactured in reality (sim2real). However, it is\ncurrently not known how to guarantee that behavior generated in simulation can\nbe preserved when deployed in reality. Although many previous studies have\ndevised training protocols that facilitate sim2real transfer of control\npolices, little to no work has investigated the simulation-reality gap as a\nfunction of morphology. This is due in part to an overall lack of tools capable\nof systematically designing and rapidly manufacturing robots. Here we introduce\na low cost, open source, and modular soft robot design and construction kit,\nand use it to simulate, fabricate, and measure the simulation-reality gap of\nminimally complex yet soft, locomoting machines. We prove the scalability of\nthis approach by transferring an order of magnitude more robot designs from\nsimulation to reality than any other method. The kit and its instructions can\nbe found here: https://github.com/skriegman/sim2real4designs\n", "versions": [{"version": "v1", "created": "Sat, 23 Nov 2019 01:11:29 GMT"}], "update_date": "2019-11-26", "authors_parsed": [["Kriegman", "Sam", ""], ["Nasab", "Amir Mohammadi", ""], ["Shah", "Dylan", ""], ["Steele", "Hannah", ""], ["Branin", "Gabrielle", ""], ["Levin", "Michael", ""], ["Bongard", "Josh", ""], ["Kramer-Bottiglio", "Rebecca", ""]]}, {"id": "1911.10291", "submitter": "Wei-An Lin", "authors": "Wei-An Lin and Yogesh Balaji and Pouya Samangouei and Rama Chellappa", "title": "Invert and Defend: Model-based Approximate Inversion of Generative\n  Adversarial Networks for Secure Inference", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Inferring the latent variable generating a given test sample is a challenging\nproblem in Generative Adversarial Networks (GANs). In this paper, we propose\nInvGAN - a novel framework for solving the inference problem in GANs, which\ninvolves training an encoder network capable of inverting a pre-trained\ngenerator network without access to any training data. Under mild assumptions,\nwe theoretically show that using InvGAN, we can approximately invert the\ngenerations of any latent code of a trained GAN model. Furthermore, we\nempirically demonstrate the superiority of our inference scheme by quantitative\nand qualitative comparisons with other methods that perform a similar task. We\nalso show the effectiveness of our framework in the problem of adversarial\ndefenses where InvGAN can successfully be used as a projection-based defense\nmechanism. Additionally, we show how InvGAN can be used to implement\nreparameterization white-box attacks on projection-based defense mechanisms.\nExperimental validation on several benchmark datasets demonstrate the efficacy\nof our method in achieving improved performance on several white-box and\nblack-box attacks. Our code is available at\nhttps://github.com/yogeshbalaji/InvGAN.\n", "versions": [{"version": "v1", "created": "Sat, 23 Nov 2019 01:15:32 GMT"}], "update_date": "2019-12-02", "authors_parsed": [["Lin", "Wei-An", ""], ["Balaji", "Yogesh", ""], ["Samangouei", "Pouya", ""], ["Chellappa", "Rama", ""]]}, {"id": "1911.10293", "submitter": "Jianguo Chen", "authors": "Jianguo Chen and Philip S. Yu", "title": "A Domain Adaptive Density Clustering Algorithm for Data with Varying\n  Density Distribution", "comments": "IEEE Transactions on Knowledge and Data Engineering, 2019", "journal-ref": null, "doi": "10.1109/TKDE.2019.2954133", "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  As one type of efficient unsupervised learning methods, clustering algorithms\nhave been widely used in data mining and knowledge discovery with noticeable\nadvantages. However, clustering algorithms based on density peak have limited\nclustering effect on data with varying density distribution (VDD), equilibrium\ndistribution (ED), and multiple domain-density maximums (MDDM), leading to the\nproblems of sparse cluster loss and cluster fragmentation. To address these\nproblems, we propose a Domain-Adaptive Density Clustering (DADC) algorithm,\nwhich consists of three steps: domain-adaptive density measurement, cluster\ncenter self-identification, and cluster self-ensemble. For data with VDD\nfeatures, clusters in sparse regions are often neglected by using uniform\ndensity peak thresholds, which results in the loss of sparse clusters. We\ndefine a domain-adaptive density measurement method based on K-Nearest\nNeighbors (KNN) to adaptively detect the density peaks of different density\nregions. We treat each data point and its KNN neighborhood as a subgroup to\nbetter reflect its density distribution in a domain view. In addition, for data\nwith ED or MDDM features, a large number of density peaks with similar values\ncan be identified, which results in cluster fragmentation. We propose a cluster\ncenter self-identification and cluster self-ensemble method to automatically\nextract the initial cluster centers and merge the fragmented clusters.\nExperimental results demonstrate that compared with other comparative\nalgorithms, the proposed DADC algorithm can obtain more reasonable clustering\nresults on data with VDD, ED and MDDM features. Benefitting from a few\nparameter requirements and non-iterative nature, DADC achieves low\ncomputational complexity and is suitable for large-scale data clustering.\n", "versions": [{"version": "v1", "created": "Sat, 23 Nov 2019 01:21:47 GMT"}], "update_date": "2019-11-26", "authors_parsed": [["Chen", "Jianguo", ""], ["Yu", "Philip S.", ""]]}, {"id": "1911.10298", "submitter": "Eric Wolff", "authors": "Tung Phan-Minh, Elena Corina Grigore, Freddy A. Boulton, Oscar\n  Beijbom, and Eric M. Wolff", "title": "CoverNet: Multimodal Behavior Prediction using Trajectory Sets", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.RO stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present CoverNet, a new method for multimodal, probabilistic trajectory\nprediction for urban driving. Previous work has employed a variety of methods,\nincluding multimodal regression, occupancy maps, and 1-step stochastic\npolicies. We instead frame the trajectory prediction problem as classification\nover a diverse set of trajectories. The size of this set remains manageable due\nto the limited number of distinct actions that can be taken over a reasonable\nprediction horizon. We structure the trajectory set to a) ensure a desired\nlevel of coverage of the state space, and b) eliminate physically impossible\ntrajectories. By dynamically generating trajectory sets based on the agent's\ncurrent state, we can further improve our method's efficiency. We demonstrate\nour approach on public, real-world self-driving datasets, and show that it\noutperforms state-of-the-art methods.\n", "versions": [{"version": "v1", "created": "Sat, 23 Nov 2019 01:46:59 GMT"}, {"version": "v2", "created": "Wed, 1 Apr 2020 22:41:55 GMT"}], "update_date": "2020-04-03", "authors_parsed": [["Phan-Minh", "Tung", ""], ["Grigore", "Elena Corina", ""], ["Boulton", "Freddy A.", ""], ["Beijbom", "Oscar", ""], ["Wolff", "Eric M.", ""]]}, {"id": "1911.10305", "submitter": "Yibo Yang", "authors": "Yibo Yang, Jianlong Wu, Hongyang Li, Xia Li, Tiancheng Shen, Zhouchen\n  Lin", "title": "Dynamical System Inspired Adaptive Time Stepping Controller for Residual\n  Network Families", "comments": "AAAI-20", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The correspondence between residual networks and dynamical systems motivates\nresearchers to unravel the physics of ResNets with well-developed tools in\nnumeral methods of ODE systems. The Runge-Kutta-Fehlberg method is an adaptive\ntime stepping that renders a good trade-off between the stability and\nefficiency. Can we also have an adaptive time stepping for ResNets to ensure\nboth stability and performance? In this study, we analyze the effects of time\nstepping on the Euler method and ResNets. We establish a stability condition\nfor ResNets with step sizes and weight parameters, and point out the effects of\nstep sizes on the stability and performance. Inspired by our analyses, we\ndevelop an adaptive time stepping controller that is dependent on the\nparameters of the current step, and aware of previous steps. The controller is\njointly optimized with the network training so that variable step sizes and\nevolution time can be adaptively adjusted. We conduct experiments on ImageNet\nand CIFAR to demonstrate the effectiveness. It is shown that our proposed\nmethod is able to improve both stability and accuracy without introducing\nadditional overhead in inference phase.\n", "versions": [{"version": "v1", "created": "Sat, 23 Nov 2019 03:22:24 GMT"}], "update_date": "2019-11-26", "authors_parsed": [["Yang", "Yibo", ""], ["Wu", "Jianlong", ""], ["Li", "Hongyang", ""], ["Li", "Xia", ""], ["Shen", "Tiancheng", ""], ["Lin", "Zhouchen", ""]]}, {"id": "1911.10309", "submitter": "Sai Ravela", "authors": "Margaret Trautner and Sai Ravela", "title": "Neural Integration of Continuous Dynamics", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.NA math.DS math.NA nlin.CD stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Neural dynamical systems are dynamical systems that are described at least in\npart by neural networks. The class of continuous-time neural dynamical systems\nmust, however, be numerically integrated for simulation and learning. Here, we\npresent a compact neural circuit for two common numerical integrators: the\nexplicit fixed-step Runge-Kutta method of any order and the\nsemi-implicit/predictor-corrector Adams-Bashforth-Moulton method. Modeled as\nconstant-sized recurrent networks embedding a continuous neural differential\nequation, they achieve fully neural temporal output. Using the polynomial class\nof dynamical systems, we demonstrate the equivalence of neural and numerical\nintegration.\n", "versions": [{"version": "v1", "created": "Sat, 23 Nov 2019 03:52:42 GMT"}], "update_date": "2019-11-26", "authors_parsed": [["Trautner", "Margaret", ""], ["Ravela", "Sai", ""]]}, {"id": "1911.10311", "submitter": "Shijie Xu", "authors": "Shijie Xu and Jiayan Fang and Xiang-Yang Li", "title": "Weighted Laplacian and Its Theoretical Applications", "comments": null, "journal-ref": null, "doi": "10.1088/1757-899X/768/7/072032", "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we develop a novel weighted Laplacian method, which is\npartially inspired by the theory of graph Laplacian, to study recent popular\ngraph problems, such as multilevel graph partitioning and balanced minimum cut\nproblem, in a more convenient manner. Since the weighted Laplacian strategy\ninherits the virtues of spectral methods, graph algorithms designed using\nweighted Laplacian will necessarily possess more robust theoretical guarantees\nfor algorithmic performances, comparing with those existing algorithms that are\nheuristically proposed. In order to illustrate its powerful utility both in\ntheory and in practice, we also present two effective applications of our\nweighted Laplacian method to multilevel graph partitioning and balanced minimum\ncut problem, respectively. By means of variational methods and theory of\npartial differential equations (PDEs), we have established the equivalence\nrelations among the weighted cut problem, balanced minimum cut problem and the\ninitial clustering problem that arises in the middle stage of graph\npartitioning algorithms under a multilevel structure. These equivalence\nrelations can indeed provide solid theoretical support for algorithms based on\nour proposed weighted Laplacian strategy. Moreover, from the perspective of the\napplication to the balanced minimum cut problem, weighted Laplacian can make it\npossible for research of numerical solutions of PDEs to be a powerful tool for\nthe algorithmic study of graph problems. Experimental results also indicate\nthat the algorithm embedded with our strategy indeed outperforms other existing\ngraph algorithms, especially in terms of accuracy, thus verifying the efficacy\nof the proposed weighted Laplacian.\n", "versions": [{"version": "v1", "created": "Sat, 23 Nov 2019 04:14:37 GMT"}], "update_date": "2020-05-20", "authors_parsed": [["Xu", "Shijie", ""], ["Fang", "Jiayan", ""], ["Li", "Xiang-Yang", ""]]}, {"id": "1911.10321", "submitter": "Juliano S. Assine", "authors": "Juliano S. Assine, Alan Godoy, Eduardo Valle", "title": "Compressing Representations for Embedded Deep Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Despite recent advances in architectures for mobile devices, deep learning\ncomputational requirements remains prohibitive for most embedded devices. To\naddress that issue, we envision sharing the computational costs of inference\nbetween local devices and the cloud, taking advantage of the compression\nperformed by the first layers of the networks to reduce communication costs.\nInference in such distributed setting would allow new applications, but\nrequires balancing a triple trade-off between computation cost, communication\nbandwidth, and model accuracy. We explore that trade-off by studying the\ncompressibility of representations at different stages of MobileNetV2, showing\nthose results agree with theoretical intuitions about deep learning, and that\nan optimal splitting layer for network can be found with a simple PCA-based\ncompression scheme.\n", "versions": [{"version": "v1", "created": "Sat, 23 Nov 2019 07:12:47 GMT"}], "update_date": "2019-11-26", "authors_parsed": [["Assine", "Juliano S.", ""], ["Godoy", "Alan", ""], ["Valle", "Eduardo", ""]]}, {"id": "1911.10322", "submitter": "Kiran Lekkala", "authors": "Kiran Lekkala and Sami Abu-El-Haija and Laurent Itti", "title": "Meta Adaptation using Importance Weighted Demonstrations", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Imitation learning has gained immense popularity because of its high\nsample-efficiency. However, in real-world scenarios, where the trajectory\ndistribution of most of the tasks dynamically shifts, model fitting on\ncontinuously aggregated data alone would be futile. In some cases, the\ndistribution shifts, so much, that it is difficult for an agent to infer the\nnew task. We propose a novel algorithm to generalize on any related task by\nleveraging prior knowledge on a set of specific tasks, which involves assigning\nimportance weights to each past demonstration. We show experiments where the\nrobot is trained from a diversity of environmental tasks and is also able to\nadapt to an unseen environment, using few-shot learning. We also developed a\nprototype robot system to test our approach on the task of visual navigation,\nand experimental results obtained were able to confirm these suppositions.\n", "versions": [{"version": "v1", "created": "Sat, 23 Nov 2019 07:22:32 GMT"}], "update_date": "2019-11-26", "authors_parsed": [["Lekkala", "Kiran", ""], ["Abu-El-Haija", "Sami", ""], ["Itti", "Laurent", ""]]}, {"id": "1911.10326", "submitter": "Ron Ziv", "authors": "Ron Ziv, Alex Dikopoltsev, Tom Zahavy, Ittai Rubinstein, Pavel\n  Sidorenko, Oren Cohen and Mordechai Segev", "title": "Deep learning reconstruction of ultrashort pulses from 2D spatial\n  intensity patterns recorded by an all-in-line system in a single-shot", "comments": null, "journal-ref": null, "doi": "10.1364/OE.383217", "report-no": null, "categories": "physics.optics cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a simple all-in-line single-shot scheme for diagnostics of\nultrashort laser pulses, consisting of a multi-mode fiber, a nonlinear crystal\nand a CCD camera. The system records a 2D spatial intensity pattern, from which\nthe pulse shape (amplitude and phase) are recovered, through a fast Deep\nLearning algorithm. We explore this scheme in simulations and demonstrate the\nrecovery of ultrashort pulses, robustness to noise in measurements and to\ninaccuracies in the parameters of the system components. Our technique\nmitigates the need for commonly used iterative optimization reconstruction\nmethods, which are usually slow and hampered by the presence of noise. These\nfeatures make our concept system advantageous for real time probing of\nultrafast processes and noisy conditions. Moreover, this work exemplifies that\nusing deep learning we can unlock new types of systems for pulse recovery.\n", "versions": [{"version": "v1", "created": "Sat, 23 Nov 2019 08:43:43 GMT"}], "update_date": "2020-04-22", "authors_parsed": [["Ziv", "Ron", ""], ["Dikopoltsev", "Alex", ""], ["Zahavy", "Tom", ""], ["Rubinstein", "Ittai", ""], ["Sidorenko", "Pavel", ""], ["Cohen", "Oren", ""], ["Segev", "Mordechai", ""]]}, {"id": "1911.10335", "submitter": "Di Wu", "authors": "Di Wu, Chao Wang, Yong Wu and De-Shuang Huang", "title": "Attention Deep Model with Multi-Scale Deep Supervision for Person\n  Re-Identification", "comments": "This work has been submitted to the IEEE for possible publication.\n  Copyright may be transferred without notice, after which this version may no\n  longer be accessible", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In recent years, person re-identification (PReID) has become a hot topic in\ncomputer vision duo to it is an important part in intelligent surveillance.\nMany state-of-the-art PReID methods are attention-based or multi-scale feature\nlearning deep models. However, introducing attention mechanism may lead to some\nimportant feature information losing issue. Besides, most of the multi-scale\nmodels embedding the multi-scale feature learning block into the feature\nextraction deep network, which reduces the efficiency of inference network. To\naddress these issue, in this study, we introduce an attention deep architecture\nwith multi-scale deep supervision for PReID. Technically, we contribute a\nreverse attention block to complement the attention block, and a novel\nmulti-scale layer with deep supervision operator for training the backbone\nnetwork. The proposed block and operator are only used for training, and\ndiscard in test phase. Experiments have been performed on Market-1501,\nDukeMTMC-reID and CUHK03 datasets. All the experiment results show that the\nproposed model significantly outperforms the other competitive state-of-the-art\nmethods.\n", "versions": [{"version": "v1", "created": "Sat, 23 Nov 2019 09:27:53 GMT"}, {"version": "v2", "created": "Wed, 27 Nov 2019 09:01:52 GMT"}, {"version": "v3", "created": "Thu, 22 Oct 2020 08:08:09 GMT"}], "update_date": "2020-10-23", "authors_parsed": [["Wu", "Di", ""], ["Wang", "Chao", ""], ["Wu", "Yong", ""], ["Huang", "De-Shuang", ""]]}, {"id": "1911.10354", "submitter": "Kohei Uehara", "authors": "Kohei Uehara, Tatsuya Harada", "title": "Unsupervised Keyword Extraction for Full-sentence VQA", "comments": "EMNLP 2020 workshop: NLP Beyond Text (NLPBT)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In the majority of the existing Visual Question Answering (VQA) research, the\nanswers consist of short, often single words, as per instructions given to the\nannotators during dataset construction. This study envisions a VQA task for\nnatural situations, where the answers are more likely to be sentences rather\nthan single words. To bridge the gap between this natural VQA and existing VQA\napproaches, a novel unsupervised keyword extraction method is proposed. The\nmethod is based on the principle that the full-sentence answers can be\ndecomposed into two parts: one that contains new information answering the\nquestion (i.e., keywords), and one that contains information already included\nin the question. Discriminative decoders were designed to achieve such\ndecomposition, and the method was experimentally implemented on VQA datasets\ncontaining full-sentence answers. The results show that the proposed model can\naccurately extract the keywords without being given explicit annotations\ndescribing them.\n", "versions": [{"version": "v1", "created": "Sat, 23 Nov 2019 12:18:03 GMT"}, {"version": "v2", "created": "Fri, 6 Mar 2020 07:37:34 GMT"}, {"version": "v3", "created": "Mon, 12 Oct 2020 09:20:30 GMT"}], "update_date": "2020-10-13", "authors_parsed": [["Uehara", "Kohei", ""], ["Harada", "Tatsuya", ""]]}, {"id": "1911.10357", "submitter": "Yang Wang", "authors": "Huibing Wang, Yang Wang, Zhao Zhang, Xianping Fu, Zhuo Li, Mingliang\n  Xu, Meng Wang", "title": "Kernelized Multiview Subspace Analysis by Self-weighted Learning", "comments": "Appearing at IEEE Transactions on Multimedia", "journal-ref": null, "doi": "10.1109/TMM.2020.3032023", "report-no": null, "categories": "cs.LG cs.MM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  With the popularity of multimedia technology, information is always\nrepresented or transmitted from multiple views. Most of the existing algorithms\nare graph-based ones to learn the complex structures within multiview data but\noverlooked the information within data representations. Furthermore, many\nexisting works treat multiple views discriminatively by introducing some\nhyperparameters, which is undesirable in practice. To this end, abundant\nmultiview based methods have been proposed for dimension reduction. However,\nthere are still no research to leverage the existing work into a unified\nframework. To address this issue, in this paper, we propose a general framework\nfor multiview data dimension reduction, named Kernelized Multiview Subspace\nAnalysis (KMSA). It directly handles the multi-view feature representation in\nthe kernel space, which provides a feasible channel for direct manipulations on\nmultiview data with different dimensions. Meanwhile, compared with those\ngraph-based methods, KMSA can fully exploit information from multiview data\nwith nothing to lose. Furthermore, since different views have different\ninfluences on KMSA, we propose a self-weighted strategy to treat different\nviews discriminatively according to their contributions. A co-regularized term\nis proposed to promote the mutual learning from multi-views. KMSA combines\nself-weighted learning with the co-regularized term to learn appropriate\nweights for all views. We also discuss the influence of the parameters in KMSA\nregarding the weights of multi-views. We evaluate our proposed framework on 6\nmultiview datasets for classification and image retrieval. The experimental\nresults validate the advantages of our proposed method.\n", "versions": [{"version": "v1", "created": "Sat, 23 Nov 2019 12:40:14 GMT"}, {"version": "v2", "created": "Fri, 5 Jun 2020 10:47:29 GMT"}, {"version": "v3", "created": "Fri, 16 Oct 2020 02:37:55 GMT"}], "update_date": "2020-10-19", "authors_parsed": [["Wang", "Huibing", ""], ["Wang", "Yang", ""], ["Zhang", "Zhao", ""], ["Fu", "Xianping", ""], ["Li", "Zhuo", ""], ["Xu", "Mingliang", ""], ["Wang", "Meng", ""]]}, {"id": "1911.10367", "submitter": "Aurelien Lucchi", "authors": "Aurelien Lucchi and Jonas Kohler", "title": "A Stochastic Tensor Method for Non-convex Optimization", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.OC cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a stochastic optimization method that uses a fourth-order\nregularized model to find local minima of smooth and potentially non-convex\nobjective functions with a finite-sum structure. This algorithm uses\nsub-sampled derivatives instead of exact quantities. The proposed approach is\nshown to find an $(\\epsilon_1,\\epsilon_2,\\epsilon_3)$-third-order critical\npoint in at most $\\bigO\\left(\\max\\left(\\epsilon_1^{-4/3}, \\epsilon_2^{-2},\n\\epsilon_3^{-4}\\right)\\right)$ iterations, thereby matching the rate of\ndeterministic approaches. In order to prove this result, we derive a novel\ntensor concentration inequality for sums of tensors of any order that makes\nexplicit use of the finite-sum structure of the objective function.\n", "versions": [{"version": "v1", "created": "Sat, 23 Nov 2019 13:46:39 GMT"}, {"version": "v2", "created": "Fri, 13 Nov 2020 16:38:32 GMT"}], "update_date": "2020-11-16", "authors_parsed": [["Lucchi", "Aurelien", ""], ["Kohler", "Jonas", ""]]}, {"id": "1911.10373", "submitter": "Zhuo Feng", "authors": "Yongyu Wang, Zhiqiang Zhao, and Zhuo Feng", "title": "GRASPEL: Graph Spectral Learning at Scale", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Learning meaningful graphs from data plays important roles in many data\nmining and machine learning tasks, such as data representation and analysis,\ndimension reduction, data clustering, and visualization, etc. In this work, for\nthe first time, we present a highly-scalable spectral approach (GRASPEL) for\nlearning large graphs from data. By limiting the precision matrix to be a graph\nLaplacian, our approach aims to estimate ultra-sparse (tree-like) weighted\nundirected graphs and shows a clear connection with the prior graphical Lasso\nmethod. By interleaving the latest high-performance nearly-linear time spectral\nmethods for graph sparsification, coarsening and embedding, ultra-sparse yet\nspectrally-robust graphs can be learned by identifying and including the most\nspectrally-critical edges into the graph. Compared with prior state-of-the-art\ngraph learning approaches, GRASPEL is more scalable and allows substantially\nimproving computing efficiency and solution quality of a variety of data mining\nand machine learning applications, such as spectral clustering (SC), and\nt-Distributed Stochastic Neighbor Embedding (t-SNE). {For example, when\ncomparing with graphs constructed using existing methods, GRASPEL achieved the\nbest spectral clustering efficiency and accuracy.\n", "versions": [{"version": "v1", "created": "Sat, 23 Nov 2019 14:51:13 GMT"}, {"version": "v2", "created": "Wed, 29 Apr 2020 00:19:38 GMT"}, {"version": "v3", "created": "Tue, 28 Jul 2020 21:08:51 GMT"}], "update_date": "2020-07-30", "authors_parsed": [["Wang", "Yongyu", ""], ["Zhao", "Zhiqiang", ""], ["Feng", "Zhuo", ""]]}, {"id": "1911.10395", "submitter": "Siddharth Biswal", "authors": "Siddharth Biswal, Cao Xiao, Lucas M. Glass, Elizabeth Milkovits,\n  Jimeng Sun", "title": "Doctor2Vec: Dynamic Doctor Representation Learning for Clinical Trial\n  Recruitment", "comments": "Accepted by AAAI 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CY stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Massive electronic health records (EHRs) enable the success of learning\naccurate patient representations to support various predictive health\napplications. In contrast, doctor representation was not well studied despite\nthat doctors play pivotal roles in healthcare. How to construct the right\ndoctor representations? How to use doctor representation to solve important\nhealth analytic problems? In this work, we study the problem on {\\it clinical\ntrial recruitment}, which is about identifying the right doctors to help\nconduct the trials based on the trial description and patient EHR data of those\ndoctors. We propose doctor2vec which simultaneously learns 1) doctor\nrepresentations from EHR data and 2) trial representations from the description\nand categorical information about the trials. In particular, doctor2vec\nutilizes a dynamic memory network where the doctor's experience with patients\nare stored in the memory bank and the network will dynamically assign weights\nbased on the trial representation via an attention mechanism. Validated on\nlarge real-world trials and EHR data including 2,609 trials, 25K doctors and\n430K patients, doctor2vec demonstrated improved performance over the best\nbaseline by up to $8.7\\%$ in PR-AUC. We also demonstrated that the doctor2vec\nembedding can be transferred to benefit data insufficiency settings including\ntrial recruitment in less populated/newly explored country with $13.7\\%$\nimprovement or for rare diseases with $8.1\\%$ improvement in PR-AUC.\n", "versions": [{"version": "v1", "created": "Sat, 23 Nov 2019 17:59:12 GMT"}], "update_date": "2019-11-26", "authors_parsed": [["Biswal", "Siddharth", ""], ["Xiao", "Cao", ""], ["Glass", "Lucas M.", ""], ["Milkovits", "Elizabeth", ""], ["Sun", "Jimeng", ""]]}, {"id": "1911.10414", "submitter": "Matan Atzmon", "authors": "Matan Atzmon and Yaron Lipman", "title": "SAL: Sign Agnostic Learning of Shapes from Raw Data", "comments": "Accepted to CVPR 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.GR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recently, neural networks have been used as implicit representations for\nsurface reconstruction, modelling, learning, and generation. So far, training\nneural networks to be implicit representations of surfaces required training\ndata sampled from a ground-truth signed implicit functions such as signed\ndistance or occupancy functions, which are notoriously hard to compute.\n  In this paper we introduce Sign Agnostic Learning (SAL), a deep learning\napproach for learning implicit shape representations directly from raw,\nunsigned geometric data, such as point clouds and triangle soups.\n  We have tested SAL on the challenging problem of surface reconstruction from\nan un-oriented point cloud, as well as end-to-end human shape space learning\ndirectly from raw scans dataset, and achieved state of the art reconstructions\ncompared to current approaches. We believe SAL opens the door to many geometric\ndeep learning applications with real-world data, alleviating the usual\npainstaking, often manual pre-process.\n", "versions": [{"version": "v1", "created": "Sat, 23 Nov 2019 20:18:29 GMT"}, {"version": "v2", "created": "Tue, 31 Mar 2020 19:50:00 GMT"}], "update_date": "2020-04-02", "authors_parsed": [["Atzmon", "Matan", ""], ["Lipman", "Yaron", ""]]}, {"id": "1911.10416", "submitter": "Yuyang Wang", "authors": "Ali Caner Turkmen, Yuyang Wang, Tim Januschowski", "title": "Intermittent Demand Forecasting with Deep Renewal Processes", "comments": "NeurIPS 2019 Workshop on Temporal Point Processes", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Intermittent demand, where demand occurrences appear sporadically in time, is\na common and challenging problem in forecasting. In this paper, we first make\nthe connections between renewal processes, and a collection of current models\nused for intermittent demand forecasting. We then develop a set of models that\nbenefit from recurrent neural networks to parameterize conditional interdemand\ntime and size distributions, building on the latest paradigm in \"deep\" temporal\npoint processes. We present favorable empirical findings on discrete and\ncontinuous time intermittent demand data, validating the practical value of our\napproach.\n", "versions": [{"version": "v1", "created": "Sat, 23 Nov 2019 20:39:23 GMT"}], "update_date": "2019-11-26", "authors_parsed": [["Turkmen", "Ali Caner", ""], ["Wang", "Yuyang", ""], ["Januschowski", "Tim", ""]]}, {"id": "1911.10418", "submitter": "Yue Zhao", "authors": "Yue Zhao and Maciej K. Hryniewicki", "title": "DCSO: Dynamic Combination of Detector Scores for Outlier Ensembles", "comments": "ACM SIGKDD Conference on Knowledge Discovery and Data Mining (KDD),\n  Outlier Detection De-constructed Workshop, 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.DB cs.IR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Selecting and combining the outlier scores of different base detectors used\nwithin outlier ensembles can be quite challenging in the absence of ground\ntruth. In this paper, an unsupervised outlier detector combination framework\ncalled DCSO is proposed, demonstrated and assessed for the dynamic selection of\nmost competent base detectors, with an emphasis on data locality. The proposed\nDCSO framework first defines the local region of a test instance by its k\nnearest neighbors and then identifies the top-performing base detectors within\nthe local region. Experimental results on ten benchmark datasets demonstrate\nthat DCSO provides consistent performance improvement over existing static\ncombination approaches in mining outlying objects. To facilitate\ninterpretability and reliability of the proposed method, DCSO is analyzed using\nboth theoretical frameworks and visualization techniques, and presented\nalongside empirical parameter setting instructions that can be used to improve\nthe overall performance.\n", "versions": [{"version": "v1", "created": "Sat, 23 Nov 2019 21:16:00 GMT"}], "update_date": "2019-11-26", "authors_parsed": [["Zhao", "Yue", ""], ["Hryniewicki", "Maciej K.", ""]]}, {"id": "1911.10425", "submitter": "Nibraas Khan", "authors": "Nibraas Khan, Joshua Phillips", "title": "Combined Model for Partially-Observable and Non-Observable Task\n  Switching: Solving Hierarchical Reinforcement Learning Problems Statically\n  and Dynamically with Transfer Learning", "comments": "8 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  An integral function of fully autonomous robots and humans is the ability to\nfocus attention on a few relevant percepts to reach a certain goal while\ndisregarding irrelevant percepts. Humans and animals rely on the interactions\nbetween the Pre-Frontal Cortex (PFC) and the Basal Ganglia (BG) to achieve this\nfocus called Working Memory (WM). The Working Memory Toolkit (WMtk) was\ndeveloped based on a computational neuroscience model of this phenomenon with\nTemporal Difference (TD) Learning for autonomous systems. Recent adaptations of\nthe toolkit either utilize Abstract Task Representations (ATRs) to solve\nNon-Observable (NO) tasks or storage of past input features to solve\nPartially-Observable (PO) tasks, but not both. We propose a new model,\nPONOWMtk, which combines both approaches, ATRs and input storage, with a static\nor dynamic number of ATRs. The results of our experiments show that PONOWMtk\nperforms effectively for tasks that exhibit PO, NO, or both properties.\n", "versions": [{"version": "v1", "created": "Sat, 23 Nov 2019 22:01:52 GMT"}, {"version": "v2", "created": "Tue, 26 Nov 2019 06:11:23 GMT"}, {"version": "v3", "created": "Fri, 29 Nov 2019 23:53:57 GMT"}, {"version": "v4", "created": "Fri, 17 Apr 2020 22:20:58 GMT"}], "update_date": "2020-04-21", "authors_parsed": [["Khan", "Nibraas", ""], ["Phillips", "Joshua", ""]]}, {"id": "1911.10434", "submitter": "Yuedong Wang", "authors": "Danqing Xu and Yuedong Wang", "title": "Low Rank Approximation for Smoothing Spline via Eigensystem Truncation", "comments": "2 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG stat.CO stat.ME", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Smoothing splines provide a powerful and flexible means for nonparametric\nestimation and inference. With a cubic time complexity, fitting smoothing\nspline models to large data is computationally prohibitive. In this paper, we\nuse the theoretical optimal eigenspace to derive a low rank approximation of\nthe smoothing spline estimates. We develop a method to approximate the\neigensystem when it is unknown and derive error bounds for the approximate\nestimates. The proposed methods are easy to implement with existing software.\nExtensive simulations show that the new methods are accurate, fast, and\ncompares favorably against existing methods.\n", "versions": [{"version": "v1", "created": "Sat, 23 Nov 2019 23:50:29 GMT"}, {"version": "v2", "created": "Tue, 8 Dec 2020 17:04:32 GMT"}], "update_date": "2020-12-09", "authors_parsed": [["Xu", "Danqing", ""], ["Wang", "Yuedong", ""]]}, {"id": "1911.10438", "submitter": "Ranran Haoran Zhang", "authors": "Daojian Zeng, Ranran Haoran Zhang, Qianying Liu", "title": "CopyMTL: Copy Mechanism for Joint Extraction of Entities and Relations\n  with Multi-Task Learning", "comments": "AAAI 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Joint extraction of entities and relations has received significant attention\ndue to its potential of providing higher performance for both tasks. Among\nexisting methods, CopyRE is effective and novel, which uses a\nsequence-to-sequence framework and copy mechanism to directly generate the\nrelation triplets. However, it suffers from two fatal problems. The model is\nextremely weak at differing the head and tail entity, resulting in inaccurate\nentity extraction. It also cannot predict multi-token entities (e.g.\n\\textit{Steven Jobs}). To address these problems, we give a detailed analysis\nof the reasons behind the inaccurate entity extraction problem, and then\npropose a simple but extremely effective model structure to solve this problem.\nIn addition, we propose a multi-task learning framework equipped with copy\nmechanism, called CopyMTL, to allow the model to predict multi-token entities.\nExperiments reveal the problems of CopyRE and show that our model achieves\nsignificant improvement over the current state-of-the-art method by 9% in NYT\nand 16% in WebNLG (F1 score). Our code is available at\nhttps://github.com/WindChimeRan/CopyMTL\n", "versions": [{"version": "v1", "created": "Sun, 24 Nov 2019 00:24:32 GMT"}, {"version": "v2", "created": "Wed, 16 Sep 2020 15:47:57 GMT"}], "update_date": "2020-09-17", "authors_parsed": [["Zeng", "Daojian", ""], ["Zhang", "Ranran Haoran", ""], ["Liu", "Qianying", ""]]}, {"id": "1911.10442", "submitter": "Eli (Omid) David", "authors": "Ido Faran, Nathan S. Netanyahu, Eli David, Maxim Shoshany, Fadi Kizel,\n  Jisung Geba Chang, Ronit Rud", "title": "Ground Truth Simulation for Deep Learning Classification of\n  Mid-Resolution Venus Images Via Unmixing of High-Resolution Hyperspectral\n  Fenix Data", "comments": null, "journal-ref": "IEEE International Geoscience and Remote Sensing Symposium\n  (IGARSS), pages 807-810, Yokohama, Japan, July 2019", "doi": "10.1109/IGARSS.2019.8900186", "report-no": null, "categories": "eess.IV cs.CV cs.LG cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Training a deep neural network for classification constitutes a major problem\nin remote sensing due to the lack of adequate field data. Acquiring\nhigh-resolution ground truth (GT) by human interpretation is both\ncost-ineffective and inconsistent. We propose, instead, to utilize\nhigh-resolution, hyperspectral images for solving this problem, by unmixing\nthese images to obtain reliable GT for training a deep network. Specifically,\nwe simulate GT from high-resolution, hyperspectral FENIX images, and use it for\ntraining a convolutional neural network (CNN) for pixel-based classification.\nWe show how the model can be transferred successfully to classify new\nmid-resolution VENuS imagery.\n", "versions": [{"version": "v1", "created": "Sun, 24 Nov 2019 01:31:35 GMT"}], "update_date": "2019-11-26", "authors_parsed": [["Faran", "Ido", ""], ["Netanyahu", "Nathan S.", ""], ["David", "Eli", ""], ["Shoshany", "Maxim", ""], ["Kizel", "Fadi", ""], ["Chang", "Jisung Geba", ""], ["Rud", "Ronit", ""]]}, {"id": "1911.10454", "submitter": "Davoud Ataee Tarzanagh", "authors": "Davoud Ataee Tarzanagh and George Michailidis", "title": "Regularized and Smooth Double Core Tensor Factorization for\n  Heterogeneous Data", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce a general tensor model suitable for data analytic tasks for\nheterogeneous data sets, wherein there are joint low-rank structures within\ngroups of observations, but also discriminative structures across different\ngroups. To capture such complex structures, a double core tensor (DCOT)\nfactorization model is introduced together with a family of smoothing loss\nfunctions. By leveraging the proposed smoothing function, the model accurately\nestimates the model factors, even in the presence of missing entries. A\nlinearized ADMM method is employed to solve regularized versions of DCOT\nfactorizations, that avoid large tensor operations and large memory storage\nrequirements. Further, we establish theoretically its global convergence,\ntogether with consistency of the estimates of the model parameters. The\neffectiveness of the DCOT model is illustrated on several real-world examples\nincluding image completion, recommender systems, subspace clustering and\ndetecting modules in heterogeneous Omics multi-modal data, since it provides\nmore insightful decompositions than conventional tensor methods.\n", "versions": [{"version": "v1", "created": "Sun, 24 Nov 2019 04:01:16 GMT"}], "update_date": "2019-11-26", "authors_parsed": [["Tarzanagh", "Davoud Ataee", ""], ["Michailidis", "George", ""]]}, {"id": "1911.10460", "submitter": "Shizhe Chen", "authors": "Shizhe Chen, Bei Liu, Jianlong Fu, Ruihua Song, Qin Jin, Pingping Lin,\n  Xiaoyu Qi, Chunting Wang and Jin Zhou", "title": "Neural Storyboard Artist: Visualizing Stories with Coherent Image\n  Sequences", "comments": "ACM MM 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CL cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A storyboard is a sequence of images to illustrate a story containing\nmultiple sentences, which has been a key process to create different story\nproducts. In this paper, we tackle a new multimedia task of automatic\nstoryboard creation to facilitate this process and inspire human artists.\nInspired by the fact that our understanding of languages is based on our past\nexperience, we propose a novel inspire-and-create framework with a\nstory-to-image retriever that selects relevant cinematic images for inspiration\nand a storyboard creator that further refines and renders images to improve the\nrelevancy and visual consistency. The proposed retriever dynamically employs\ncontextual information in the story with hierarchical attentions and applies\ndense visual-semantic matching to accurately retrieve and ground images. The\ncreator then employs three rendering steps to increase the flexibility of\nretrieved images, which include erasing irrelevant regions, unifying styles of\nimages and substituting consistent characters. We carry out extensive\nexperiments on both in-domain and out-of-domain visual story datasets. The\nproposed model achieves better quantitative performance than the\nstate-of-the-art baselines for storyboard creation. Qualitative visualizations\nand user studies further verify that our approach can create high-quality\nstoryboards even for stories in the wild.\n", "versions": [{"version": "v1", "created": "Sun, 24 Nov 2019 05:06:41 GMT"}], "update_date": "2019-12-02", "authors_parsed": [["Chen", "Shizhe", ""], ["Liu", "Bei", ""], ["Fu", "Jianlong", ""], ["Song", "Ruihua", ""], ["Jin", "Qin", ""], ["Lin", "Pingping", ""], ["Qi", "Xiaoyu", ""], ["Wang", "Chunting", ""], ["Zhou", "Jin", ""]]}, {"id": "1911.10461", "submitter": "Leonardo Babun", "authors": "Leonardo Babun, Z. Berkay Celik, Patrick McDaniel, A. Selcuk Uluagac", "title": "Real-time Analysis of Privacy-(un)aware IoT Applications", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Users trust IoT apps to control and automate their smart devices. These apps\nnecessarily have access to sensitive data to implement their functionality.\nHowever, users lack visibility into how their sensitive data is used (or\nleaked), and they often blindly trust the app developers. In this paper, we\npresent IoTWatcH, a novel dynamic analysis tool that uncovers the privacy risks\nof IoT apps in real-time. We designed and built IoTWatcH based on an IoT\nprivacy survey that considers the privacy needs of IoT users. IoTWatcH provides\nusers with a simple interface to specify their privacy preferences with an IoT\napp. Then, in runtime, it analyzes both the data that is sent out of the IoT\napp and its recipients using Natural Language Processing (NLP) techniques.\nMoreover, IoTWatcH informs the users with its findings to make them aware of\nthe privacy risks with the IoT app. We implemented IoTWatcH on real IoT\napplications. Specifically, we analyzed 540 IoT apps to train the NLP model and\nevaluate its effectiveness. IoTWatcH successfully classifies IoT app data sent\nto external parties to correct privacy labels with an average accuracy of\n94.25%, and flags IoT apps that leak privacy data to unauthorized parties.\nFinally, IoTWatcH yields minimal overhead to an IoT app's execution, on average\n105 ms additional latency.\n", "versions": [{"version": "v1", "created": "Sun, 24 Nov 2019 05:15:53 GMT"}], "update_date": "2019-11-26", "authors_parsed": [["Babun", "Leonardo", ""], ["Celik", "Z. Berkay", ""], ["McDaniel", "Patrick", ""], ["Uluagac", "A. Selcuk", ""]]}, {"id": "1911.10477", "submitter": "Jiancheng Yang", "authors": "Jiancheng Yang, Xiaoyang Huang, Yi He, Jingwei Xu, Canqian Yang,\n  Guozheng Xu, Bingbing Ni", "title": "Reinventing 2D Convolutions for 3D Images", "comments": "IEEE Journal of Biomedical and Health Informatics (IEEE JBHI). Code\n  is available at https://github.com/m3dv/ACSConv", "journal-ref": "IEEE Journal of Biomedical and Health Informatics (IEEE JBHI),\n  2021", "doi": "10.1109/JBHI.2021.3049452", "report-no": null, "categories": "eess.IV cs.CV cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  There have been considerable debates over 2D and 3D representation learning\non 3D medical images. 2D approaches could benefit from large-scale 2D\npretraining, whereas they are generally weak in capturing large 3D contexts. 3D\napproaches are natively strong in 3D contexts, however few publicly available\n3D medical dataset is large and diverse enough for universal 3D pretraining.\nEven for hybrid (2D + 3D) approaches, the intrinsic disadvantages within the 2D\n/ 3D parts still exist. In this study, we bridge the gap between 2D and 3D\nconvolutions by reinventing the 2D convolutions. We propose ACS\n(axial-coronal-sagittal) convolutions to perform natively 3D representation\nlearning, while utilizing the pretrained weights on 2D datasets. In ACS\nconvolutions, 2D convolution kernels are split by channel into three parts, and\nconvoluted separately on the three views (axial, coronal and sagittal) of 3D\nrepresentations. Theoretically, ANY 2D CNN (ResNet, DenseNet, or DeepLab) is\nable to be converted into a 3D ACS CNN, with pretrained weight of a same\nparameter size. Extensive experiments on several medical benchmarks (including\nclassification, segmentation and detection tasks) validate the consistent\nsuperiority of the pretrained ACS CNNs, over the 2D / 3D CNN counterparts with\n/ without pretraining. Even without pretraining, the ACS convolution can be\nused as a plug-and-play replacement of standard 3D convolution, with smaller\nmodel size and less computation.\n", "versions": [{"version": "v1", "created": "Sun, 24 Nov 2019 09:05:06 GMT"}, {"version": "v2", "created": "Fri, 6 Mar 2020 14:52:44 GMT"}, {"version": "v3", "created": "Tue, 20 Oct 2020 13:03:06 GMT"}, {"version": "v4", "created": "Mon, 4 Jan 2021 07:24:49 GMT"}], "update_date": "2021-01-11", "authors_parsed": [["Yang", "Jiancheng", ""], ["Huang", "Xiaoyang", ""], ["He", "Yi", ""], ["Xu", "Jingwei", ""], ["Yang", "Canqian", ""], ["Xu", "Guozheng", ""], ["Ni", "Bingbing", ""]]}, {"id": "1911.10500", "submitter": "Bernhard Sch\\\"olkopf", "authors": "Bernhard Sch\\\"olkopf", "title": "Causality for Machine Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Graphical causal inference as pioneered by Judea Pearl arose from research on\nartificial intelligence (AI), and for a long time had little connection to the\nfield of machine learning.\n  This article discusses where links have been and should be established,\nintroducing key concepts along the way. It argues that the hard open problems\nof machine learning and AI are intrinsically related to causality, and explains\nhow the field is beginning to understand them.\n", "versions": [{"version": "v1", "created": "Sun, 24 Nov 2019 11:04:56 GMT"}, {"version": "v2", "created": "Mon, 23 Dec 2019 16:20:53 GMT"}], "update_date": "2019-12-24", "authors_parsed": [["Sch\u00f6lkopf", "Bernhard", ""]]}, {"id": "1911.10504", "submitter": "Ahnjae Shin", "authors": "Ahnjae Shin, Dong-Jin Shin, Sungwoo Cho, Do Yoon Kim, Eunji Jeong,\n  Gyeong-In Yu, Byung-Gon Chun", "title": "Stage-based Hyper-parameter Optimization for Deep Learning", "comments": null, "journal-ref": "Workshop on Systems for ML at NeurIPS 2019", "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  As deep learning techniques advance more than ever, hyper-parameter\noptimization is the new major workload in deep learning clusters. Although\nhyper-parameter optimization is crucial in training deep learning models for\nhigh model performance, effectively executing such a computation-heavy workload\nstill remains a challenge. We observe that numerous trials issued from existing\nhyper-parameter optimization algorithms share common hyper-parameter sequence\nprefixes, which implies that there are redundant computations from training the\nsame hyper-parameter sequence multiple times. We propose a stage-based\nexecution strategy for efficient execution of hyper-parameter optimization\nalgorithms. Our strategy removes redundancy in the training process by\nsplitting the hyper-parameter sequences of trials into homogeneous stages, and\ngenerating a tree of stages by merging the common prefixes. Our preliminary\nexperiment results show that applying stage-based execution to hyper-parameter\noptimization algorithms outperforms the original trial-based method, saving\nrequired GPU-hours and end-to-end training time by up to 6.60 times and 4.13\ntimes, respectively.\n", "versions": [{"version": "v1", "created": "Sun, 24 Nov 2019 11:24:33 GMT"}], "update_date": "2019-11-26", "authors_parsed": [["Shin", "Ahnjae", ""], ["Shin", "Dong-Jin", ""], ["Cho", "Sungwoo", ""], ["Kim", "Do Yoon", ""], ["Jeong", "Eunji", ""], ["Yu", "Gyeong-In", ""], ["Chun", "Byung-Gon", ""]]}, {"id": "1911.10506", "submitter": "Riddhish Bhalodia", "authors": "Riddhish Bhalodia, Iain Lee, Shireen Elhabian", "title": "dpVAEs: Fixing Sample Generation for Regularized VAEs", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Unsupervised representation learning via generative modeling is a staple to\nmany computer vision applications in the absence of labeled data. Variational\nAutoencoders (VAEs) are powerful generative models that learn representations\nuseful for data generation. However, due to inherent challenges in the training\nobjective, VAEs fail to learn useful representations amenable for downstream\ntasks. Regularization-based methods that attempt to improve the representation\nlearning aspect of VAEs come at a price: poor sample generation. In this paper,\nwe explore this representation-generation trade-off for regularized VAEs and\nintroduce a new family of priors, namely decoupled priors, or dpVAEs, that\ndecouple the representation space from the generation space. This decoupling\nenables the use of VAE regularizers on the representation space without\nimpacting the distribution used for sample generation, and thereby reaping the\nrepresentation learning benefits of the regularizations without sacrificing the\nsample generation. dpVAE leverages invertible networks to learn a bijective\nmapping from an arbitrarily complex representation distribution to a simple,\ntractable, generative distribution. Decoupled priors can be adapted to the\nstate-of-the-art VAE regularizers without additional hyperparameter tuning. We\nshowcase the use of dpVAEs with different regularizers. Experiments on MNIST,\nSVHN, and CelebA demonstrate, quantitatively and qualitatively, that dpVAE\nfixes sample generation for regularized VAEs.\n", "versions": [{"version": "v1", "created": "Sun, 24 Nov 2019 11:31:39 GMT"}, {"version": "v2", "created": "Sun, 22 Mar 2020 03:54:34 GMT"}], "update_date": "2020-03-24", "authors_parsed": [["Bhalodia", "Riddhish", ""], ["Lee", "Iain", ""], ["Elhabian", "Shireen", ""]]}, {"id": "1911.10516", "submitter": "Weijia Zhang", "authors": "Weijia Zhang, Hao Liu, Yanchi Liu, Jingbo Zhou, Hui Xiong", "title": "Semi-Supervised Hierarchical Recurrent Graph Neural Network for\n  City-Wide Parking Availability Prediction", "comments": "8 pages, 9 figures, AAAI-2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG eess.SP stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The ability to predict city-wide parking availability is crucial for the\nsuccessful development of Parking Guidance and Information (PGI) systems.\nIndeed, the effective prediction of city-wide parking availability can improve\nparking efficiency, help urban planning, and ultimately alleviate city\ncongestion. However, it is a non-trivial task for predicting citywide parking\navailability because of three major challenges: 1) the non-Euclidean spatial\nautocorrelation among parking lots, 2) the dynamic temporal autocorrelation\ninside of and between parking lots, and 3) the scarcity of information about\nreal-time parking availability obtained from real-time sensors (e.g., camera,\nultrasonic sensor, and GPS). To this end, we propose Semi-supervised\nHierarchical Recurrent Graph Neural Network (SHARE) for predicting city-wide\nparking availability. Specifically, we first propose a hierarchical graph\nconvolution structure to model non-Euclidean spatial autocorrelation among\nparking lots. Along this line, a contextual graph convolution block and a soft\nclustering graph convolution block are respectively proposed to capture local\nand global spatial dependencies between parking lots. Additionally, we adopt a\nrecurrent neural network to incorporate dynamic temporal dependencies of\nparking lots. Moreover, we propose a parking availability approximation module\nto estimate missing real-time parking availabilities from both spatial and\ntemporal domain. Finally, experiments on two real-world datasets demonstrate\nthe prediction performance of SHARE outperforms seven state-of-the-art\nbaselines.\n", "versions": [{"version": "v1", "created": "Sun, 24 Nov 2019 12:17:04 GMT"}], "update_date": "2019-12-02", "authors_parsed": [["Zhang", "Weijia", ""], ["Liu", "Hao", ""], ["Liu", "Yanchi", ""], ["Zhou", "Jingbo", ""], ["Xiong", "Hui", ""]]}, {"id": "1911.10521", "submitter": "Zining Liu", "authors": "Zining Liu, Chong Long, Xiaolu Lu, Zehong Hu, Jie Zhang, Yafang Wang", "title": "Which Channel to Ask My Question? Personalized Customer Service Request\n  Stream Routing using Deep Reinforcement Learning", "comments": "13 pages, 7 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI eess.SP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Customer services are critical to all companies, as they may directly connect\nto the brand reputation. Due to a great number of customers, e-commerce\ncompanies often employ multiple communication channels to answer customers'\nquestions, for example, chatbot and hotline. On one hand, each channel has\nlimited capacity to respond to customers' requests, on the other hand,\ncustomers have different preferences over these channels. The current\nproduction systems are mainly built based on business rules, which merely\nconsiders tradeoffs between resources and customers' satisfaction. To achieve\nthe optimal tradeoff between resources and customers' satisfaction, we propose\na new framework based on deep reinforcement learning, which directly takes both\nresources and user model into account. In addition to the framework, we also\npropose a new deep-reinforcement-learning based routing method-double dueling\ndeep Q-learning with prioritized experience replay (PER-DoDDQN). We evaluate\nour proposed framework and method using both synthetic and a real customer\nservice log data from a large financial technology company. We show that our\nproposed deep-reinforcement-learning based framework is superior to the\nexisting production system. Moreover, we also show our proposed PER-DoDDQN is\nbetter than all other deep Q-learning variants in practice, which provides a\nmore optimal routing plan. These observations suggest that our proposed method\ncan seek the trade-off where both channel resources and customers' satisfaction\nare optimal.\n", "versions": [{"version": "v1", "created": "Sun, 24 Nov 2019 12:57:03 GMT"}], "update_date": "2019-12-03", "authors_parsed": [["Liu", "Zining", ""], ["Long", "Chong", ""], ["Lu", "Xiaolu", ""], ["Hu", "Zehong", ""], ["Zhang", "Jie", ""], ["Wang", "Yafang", ""]]}, {"id": "1911.10522", "submitter": "Fabien Geyer", "authors": "Fabien Geyer and Steffen Bondorf", "title": "On the Robustness of Deep Learning-predicted Contention Models for\n  Network Calculus", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The network calculus (NC) analysis takes a simple model consisting of a\nnetwork of schedulers and data flows crossing them. A number of analysis\n\"building blocks\" can then be applied to capture the model without imposing\npessimistic assumptions like self-contention on tandems of servers. Yet, adding\npessimism cannot always be avoided. To compute the best bound on a single\nflow's end-to-end delay thus boils down to finding the least pessimistic\ncontention models for all tandems of schedulers in the network - and an\nexhaustive search can easily become a very resource intensive task. The\nliterature proposes a promising solution to this dilemma: a heuristic making\nuse of machine learning (ML) predictions inside the NC analysis.\n  While results of this work were promising in terms of delay bound quality and\ncomputational effort, there is little to no insight on when a prediction is\nmade or if the trained algorithm can achieve similarly striking results in\nnetworks vastly differing from its training data. In this paper, we address\nthese pending questions. We evaluate the influence of the training data and its\nfeatures on accuracy, impact and scalability. Additionally, we contribute an\nextension of the method by predicting the best $n$ contention model\nalternatives in order to achieve increased robustness for its application\noutside the training data. Our numerical evaluation shows that good accuracy\ncan still be achieved on large networks although we restrict the training to\nnetworks that are two orders of magnitude smaller.\n", "versions": [{"version": "v1", "created": "Sun, 24 Nov 2019 13:00:41 GMT"}, {"version": "v2", "created": "Fri, 17 Jul 2020 04:34:46 GMT"}], "update_date": "2020-07-20", "authors_parsed": [["Geyer", "Fabien", ""], ["Bondorf", "Steffen", ""]]}, {"id": "1911.10524", "submitter": "Zekun Yang", "authors": "Zekun Yang, Tianlin Liu", "title": "Causally Denoise Word Embeddings Using Half-Sibling Regression", "comments": "Accepted by AAAI 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Distributional representations of words, also known as word vectors, have\nbecome crucial for modern natural language processing tasks due to their wide\napplications. Recently, a growing body of word vector postprocessing algorithm\nhas emerged, aiming to render off-the-shelf word vectors even stronger. In line\nwith these investigations, we introduce a novel word vector postprocessing\nscheme under a causal inference framework. Concretely, the postprocessing\npipeline is realized by Half-Sibling Regression (HSR), which allows us to\nidentify and remove confounding noise contained in word vectors. Compared to\nprevious work, our proposed method has the advantages of interpretability and\ntransparency due to its causal inference grounding. Evaluated on a battery of\nstandard lexical-level evaluation tasks and downstream sentiment analysis\ntasks, our method reaches state-of-the-art performance.\n", "versions": [{"version": "v1", "created": "Sun, 24 Nov 2019 13:06:19 GMT"}], "update_date": "2019-11-26", "authors_parsed": [["Yang", "Zekun", ""], ["Liu", "Tianlin", ""]]}, {"id": "1911.10527", "submitter": "Gang Chen", "authors": "Gang Chen", "title": "Merging Deterministic Policy Gradient Estimations with Varied\n  Bias-Variance Tradeoff for Effective Deep Reinforcement Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep reinforcement learning (DRL) on Markov decision processes (MDPs) with\ncontinuous action spaces is often approached by directly training parametric\npolicies along the direction of estimated policy gradients (PGs). Previous\nresearch revealed that the performance of these PG algorithms depends heavily\non the bias-variance tradeoffs involved in estimating and using PGs. A notable\napproach towards balancing this tradeoff is to merge both on-policy and\noff-policy gradient estimations. However existing PG merging methods can be\nsample inefficient and are not suitable to train deterministic policies\ndirectly. To address these issues, this paper introduces elite PGs and\nstrengthens their variance reduction effect by adopting elitism and policy\nconsolidation techniques to regularize policy training based on policy\nbehavioral knowledge extracted from elite trajectories. Meanwhile, we propose a\ntwo-step method to merge elite PGs and conventional PGs as a new extension of\nthe conventional interpolation merging method. At both the theoretical and\nexperimental levels, we show that both two-step merging and interpolation\nmerging can induce varied bias-variance tradeoffs during policy training. They\nenable us to effectively use elite PGs and mitigate their performance impact on\ntrained policies. Our experiments also show that two-step merging can\noutperform interpolation merging and several state-of-the-art algorithms on six\nbenchmark control tasks.\n", "versions": [{"version": "v1", "created": "Sun, 24 Nov 2019 13:44:32 GMT"}, {"version": "v2", "created": "Wed, 29 Apr 2020 06:10:58 GMT"}, {"version": "v3", "created": "Sat, 2 May 2020 09:11:52 GMT"}], "update_date": "2020-05-05", "authors_parsed": [["Chen", "Gang", ""]]}, {"id": "1911.10538", "submitter": "Ori Nizan Mr", "authors": "Ori Nizan and Ayellet Tal", "title": "Breaking the cycle -- Colleagues are all you need", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper proposes a novel approach to performing image-to-image translation\nbetween unpaired domains. Rather than relying on a cycle constraint, our method\ntakes advantage of collaboration between various GANs. This results in a\nmulti-modal method, in which multiple optional and diverse images are produced\nfor a given image. Our model addresses some of the shortcomings of classical\nGANs: (1) It is able to remove large objects, such as glasses. (2) Since it\ndoes not need to support the cycle constraint, no irrelevant traces of the\ninput are left on the generated image. (3) It manages to translate between\ndomains that require large shape modifications. Our results are shown to\noutperform those generated by state-of-the-art methods for several challenging\napplications on commonly-used datasets, both qualitatively and quantitatively.\n", "versions": [{"version": "v1", "created": "Sun, 24 Nov 2019 14:43:45 GMT"}, {"version": "v2", "created": "Sun, 7 Jun 2020 20:23:38 GMT"}], "update_date": "2020-06-09", "authors_parsed": [["Nizan", "Ori", ""], ["Tal", "Ayellet", ""]]}, {"id": "1911.10541", "submitter": "Yuval Dagan", "authors": "Yuval Dagan and Vitaly Feldman", "title": "PAC learning with stable and private predictions", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR cs.DS stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study binary classification algorithms for which the prediction on any\npoint is not too sensitive to individual examples in the dataset. Specifically,\nwe consider the notions of uniform stability (Bousquet and Elisseeff, 2001) and\nprediction privacy (Dwork and Feldman, 2018). Previous work on these notions\nshows how they can be achieved in the standard PAC model via simple aggregation\nof models trained on disjoint subsets of data. Unfortunately, this approach\nleads to a significant overhead in terms of sample complexity. Here we\ndemonstrate several general approaches to stable and private prediction that\neither eliminate or significantly reduce the overhead. Specifically, we\ndemonstrate that for any class $C$ of VC dimension $d$ there exists a\n$\\gamma$-uniformly stable algorithm for learning $C$ with excess error $\\alpha$\nusing $\\tilde O(d/(\\alpha\\gamma) + d/\\alpha^2)$ samples. We also show that this\nbound is nearly tight. For $\\epsilon$-differentially private prediction we give\ntwo new algorithms: one using $\\tilde O(d/(\\alpha^2\\epsilon))$ samples and\nanother one using $\\tilde O(d^2/(\\alpha\\epsilon) + d/\\alpha^2)$ samples. The\nbest previously known bounds for these problems are $O(d/(\\alpha^2\\gamma))$ and\n$O(d/(\\alpha^3\\epsilon))$, respectively.\n", "versions": [{"version": "v1", "created": "Sun, 24 Nov 2019 14:48:29 GMT"}, {"version": "v2", "created": "Wed, 23 Sep 2020 09:11:58 GMT"}], "update_date": "2020-09-24", "authors_parsed": [["Dagan", "Yuval", ""], ["Feldman", "Vitaly", ""]]}, {"id": "1911.10558", "submitter": "Jinshan Zeng", "authors": "Jinshan Zeng, Minrun Wu, Shao-Bo Lin, Ding-Xuan Zhou", "title": "Fast Polynomial Kernel Classification for Massive Data", "comments": "arXiv admin note: text overlap with arXiv:1402.4735 by other authors", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG math.OC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In the era of big data, it is highly desired to develop efficient machine\nlearning algorithms to tackle massive data challenges such as storage\nbottleneck, algorithmic scalability, and interpretability. In this paper, we\ndevelop a novel efficient classification algorithm, called fast polynomial\nkernel classification (FPC), to conquer the scalability and storage challenges.\nOur main tools are a suitable selected feature mapping based on polynomial\nkernels and an alternating direction method of multipliers (ADMM) algorithm for\na related non-smooth convex optimization problem. Fast learning rates as well\nas feasibility verifications including the convergence of ADMM and the\nselection of center points are established to justify theoretical behaviors of\nFPC. Our theoretical assertions are verified by a series of simulations and\nreal data applications. The numerical results demonstrate that FPC\nsignificantly reduces the computational burden and storage memory of the\nexisting learning schemes such as support vector machines and boosting, without\nsacrificing their generalization abilities much.\n", "versions": [{"version": "v1", "created": "Sun, 24 Nov 2019 16:02:21 GMT"}, {"version": "v2", "created": "Fri, 6 Dec 2019 10:19:30 GMT"}], "update_date": "2019-12-10", "authors_parsed": [["Zeng", "Jinshan", ""], ["Wu", "Minrun", ""], ["Lin", "Shao-Bo", ""], ["Zhou", "Ding-Xuan", ""]]}, {"id": "1911.10561", "submitter": "Jian Zhang", "authors": "Jinyin Chen, Jian Zhang, Zhi Chen, Min Du and Qi Xuan", "title": "Time-aware Gradient Attack on Dynamic Network Link Prediction", "comments": "9 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In network link prediction, it is possible to hide a target link from being\npredicted with a small perturbation on network structure. This observation may\nbe exploited in many real world scenarios, for example, to preserve privacy, or\nto exploit financial security. There have been many recent studies to generate\nadversarial examples to mislead deep learning models on graph data. However,\nnone of the previous work has considered the dynamic nature of real-world\nsystems. In this work, we present the first study of adversarial attack on\ndynamic network link prediction (DNLP). The proposed attack method, namely\ntime-aware gradient attack (TGA), utilizes the gradient information generated\nby deep dynamic network embedding (DDNE) across different snapshots to rewire a\nfew links, so as to make DDNE fail to predict target links. We implement TGA in\ntwo ways: one is based on traversal search, namely TGA-Tra; and the other is\nsimplified with greedy search for efficiency, namely TGA-Gre. We conduct\ncomprehensive experiments which show the outstanding performance of TGA in\nattacking DNLP algorithms.\n", "versions": [{"version": "v1", "created": "Sun, 24 Nov 2019 16:06:45 GMT"}, {"version": "v2", "created": "Fri, 3 Apr 2020 10:23:14 GMT"}], "update_date": "2020-04-06", "authors_parsed": [["Chen", "Jinyin", ""], ["Zhang", "Jian", ""], ["Chen", "Zhi", ""], ["Du", "Min", ""], ["Xuan", "Qi", ""]]}, {"id": "1911.10563", "submitter": "Mrinank Sharma", "authors": "Mrinank Sharma, Michael Hutchinson, Siddharth Swaroop, Antti Honkela,\n  Richard E. Turner", "title": "Differentially Private Federated Variational Inference", "comments": "Privacy in Machine Learning Workshop (PriML 2019) at the 33rd\n  Conference in Neural Information and Processing Systems (NeurIPS)", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In many real-world applications of machine learning, data are distributed\nacross many clients and cannot leave the devices they are stored on.\nFurthermore, each client's data, computational resources and communication\nconstraints may be very different. This setting is known as federated learning,\nin which privacy is a key concern. Differential privacy is commonly used to\nprovide mathematical privacy guarantees. This work, to the best of our\nknowledge, is the first to consider federated, differentially private, Bayesian\nlearning. We build on Partitioned Variational Inference (PVI) which was\nrecently developed to support approximate Bayesian inference in the federated\nsetting. We modify the client-side optimisation of PVI to provide an\n(${\\epsilon}$, ${\\delta}$)-DP guarantee. We show that it is possible to learn\nmoderately private logistic regression models in the federated setting that\nachieve similar performance to models trained non-privately on centralised\ndata.\n", "versions": [{"version": "v1", "created": "Sun, 24 Nov 2019 16:15:31 GMT"}], "update_date": "2019-12-02", "authors_parsed": [["Sharma", "Mrinank", ""], ["Hutchinson", "Michael", ""], ["Swaroop", "Siddharth", ""], ["Honkela", "Antti", ""], ["Turner", "Richard E.", ""]]}, {"id": "1911.10575", "submitter": "Mohamed Zahran", "authors": "Ahmad El Sallab, Ibrahim Sobh, Mohamed Zahran, Mohamed Shawky", "title": "Unsupervised Neural Sensor Models for Synthetic LiDAR Data Augmentation", "comments": "Accepted in Machine learning for Autonomous Driving NeurIPS 2019\n  Workshop", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.IV cs.CV cs.LG", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Data scarcity is a bottleneck to machine learning-based perception modules,\nusually tackled by augmenting real data with synthetic data from simulators.\nRealistic models of the vehicle perception sensors are hard to formulate in\nclosed form, and at the same time, they require the existence of paired data to\nbe learned. In this work, we propose two unsupervised neural sensor models\nbased on unpaired domain translations with CycleGANs and Neural Style Transfer\ntechniques. We employ CARLA as the simulation environment to obtain simulated\nLiDAR point clouds, together with their annotations for data augmentation, and\nwe use KITTI dataset as the real LiDAR dataset from which we learn the\nrealistic sensor model mapping. Moreover, we provide a framework for data\naugmentation and evaluation of the developed sensor models, through extrinsic\nobject detection task evaluation using YOLO network adapted to provide oriented\nbounding boxes for LiDAR Bird-eye-View projected point clouds. Evaluation is\nperformed on unseen real LiDAR frames from KITTI dataset, with different\namounts of simulated data augmentation using the two proposed approaches,\nshowing improvement of 6% mAP for the object detection task, in favor of the\naugmenting LiDAR point clouds adapted with the proposed neural sensor models\nover the raw simulated LiDAR.\n", "versions": [{"version": "v1", "created": "Sun, 24 Nov 2019 17:29:50 GMT"}], "update_date": "2019-12-03", "authors_parsed": [["Sallab", "Ahmad El", ""], ["Sobh", "Ibrahim", ""], ["Zahran", "Mohamed", ""], ["Shawky", "Mohamed", ""]]}, {"id": "1911.10594", "submitter": "Dipan Pal", "authors": "Dipan K. Pal, Sreena Nallamothu, Marios Savvides", "title": "Towards a Hypothesis on Visual Transformation based Self-Supervision", "comments": "Draft", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose the first qualitative hypothesis characterizing the behavior of\nvisual transformation based self-supervision, called the VTSS hypothesis. Given\na dataset upon which a self-supervised task is performed while predicting\ninstantiations of a transformation, the hypothesis states that if the predicted\ninstantiations of the transformations are already present in the dataset, then\nthe representation learned will be less useful. The hypothesis was derived by\nobserving a key constraint in the application of self-supervision using a\nparticular transformation. This constraint, which we term the transformation\nconflict for this paper, forces a network learn degenerative features thereby\nreducing the usefulness of the representation. The VTSS hypothesis helps us\nidentify transformations that have the potential to be effective as a\nself-supervision task. Further, it helps to generally predict whether a\nparticular transformation based self-supervision technique would be effective\nor not for a particular dataset. We provide extensive evaluations on CIFAR 10,\nCIFAR 100, SVHN and FMNIST confirming the hypothesis and the trends it\npredicts. We also propose novel cost-effective self-supervision techniques\nbased on translation and scale, which when combined with rotation outperforms\nall transformations applied individually. Overall, this paper aims to shed\nlight on the phenomenon of visual transformation based self-supervision.\n", "versions": [{"version": "v1", "created": "Sun, 24 Nov 2019 19:27:35 GMT"}, {"version": "v2", "created": "Fri, 14 Feb 2020 03:51:46 GMT"}], "update_date": "2020-02-18", "authors_parsed": [["Pal", "Dipan K.", ""], ["Nallamothu", "Sreena", ""], ["Savvides", "Marios", ""]]}, {"id": "1911.10599", "submitter": "Erik Norlander", "authors": "Erik Norlander and Alexandros Sopasakis", "title": "Latent space conditioning for improved classification and anomaly\n  detection", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a new type of variational autoencoder to perform improved\npre-processing for clustering and anomaly detection on data with a given label.\nAnomalies however are not known or labeled. We call our method conditional\nlatent space variational autonencoder since it separates the latent space by\nconditioning on information within the data. The method fits one prior\ndistribution to each class in the dataset, effectively expanding the prior\ndistribution to include a Gaussian mixture model. Our approach is compared\nagainst the capabilities of a typical variational autoencoder by measuring\ntheir V-score during cluster formation with respect to the k-means and EM\nalgorithms.\n  For anomaly detection, we use a new metric composed of the mass-volume and\nexcess-mass curves which can work in an unsupervised setting. We compare the\nresults between established methods such as as isolation forest, local outlier\nfactor and one-class support vector machine.\n", "versions": [{"version": "v1", "created": "Sun, 24 Nov 2019 19:39:58 GMT"}, {"version": "v2", "created": "Thu, 28 Nov 2019 13:55:15 GMT"}], "update_date": "2019-12-02", "authors_parsed": [["Norlander", "Erik", ""], ["Sopasakis", "Alexandros", ""]]}, {"id": "1911.10601", "submitter": "Alexander Tschantz", "authors": "Alexander Tschantz, Manuel Baltieri, Anil. K. Seth, Christopher L.\n  Buckley", "title": "Scaling active inference", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.IT cs.SY eess.SY math.IT stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In reinforcement learning (RL), agents often operate in partially observed\nand uncertain environments. Model-based RL suggests that this is best achieved\nby learning and exploiting a probabilistic model of the world. 'Active\ninference' is an emerging normative framework in cognitive and computational\nneuroscience that offers a unifying account of how biological agents achieve\nthis. On this framework, inference, learning and action emerge from a single\nimperative to maximize the Bayesian evidence for a niched model of the world.\nHowever, implementations of this process have thus far been restricted to\nlow-dimensional and idealized situations. Here, we present a working\nimplementation of active inference that applies to high-dimensional tasks, with\nproof-of-principle results demonstrating efficient exploration and an order of\nmagnitude increase in sample efficiency over strong model-free baselines. Our\nresults demonstrate the feasibility of applying active inference at scale and\nhighlight the operational homologies between active inference and current\nmodel-based approaches to RL.\n", "versions": [{"version": "v1", "created": "Sun, 24 Nov 2019 20:03:11 GMT"}], "update_date": "2019-11-26", "authors_parsed": [["Tschantz", "Alexander", ""], ["Baltieri", "Manuel", ""], ["Seth", "Anil. K.", ""], ["Buckley", "Christopher L.", ""]]}, {"id": "1911.10606", "submitter": "Kan Li PhD", "authors": "Kan Li and Jose C. Principe", "title": "Functional Bayesian Filter", "comments": "15 pages, 8 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.SP cs.IT cs.LG math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a general nonlinear Bayesian filter for high-dimensional state\nestimation using the theory of reproducing kernel Hilbert space (RKHS).\nApplying kernel method and the representer theorem to perform linear quadratic\nestimation in a functional space, we derive a Bayesian recursive state\nestimator for a general nonlinear dynamical system in the original input space.\nUnlike existing nonlinear extensions of Kalman filter where the system dynamics\nare assumed known, the state-space representation for the Functional Bayesian\nFilter (FBF) is completely learned from measurement data in the form of an\ninfinite impulse response (IIR) filter or recurrent network in the RKHS, with\nuniversal approximation property. Using positive definite kernel function\nsatisfying Mercer's conditions to compute and evolve information quantities,\nthe FBF exploits both the statistical and time-domain information about the\nsignal, extracts higher-order moments, and preserves the properties of\ncovariances without the ill effects due to conventional arithmetic operations.\nThis novel kernel adaptive filtering algorithm is applied to recurrent network\ntraining, chaotic time-series estimation and cooperative filtering using\nGaussian and non-Gaussian noises, and inverse kinematics modeling. Simulation\nresults show FBF outperforms existing Kalman-based algorithms.\n", "versions": [{"version": "v1", "created": "Sun, 24 Nov 2019 21:00:11 GMT"}], "update_date": "2019-11-26", "authors_parsed": [["Li", "Kan", ""], ["Principe", "Jose C.", ""]]}, {"id": "1911.10608", "submitter": "Manpreet Singh Minhas", "authors": "Manpreet Singh Minhas, John Zelek", "title": "AnoNet: Weakly Supervised Anomaly Detection in Textured Surfaces", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Humans can easily detect a defect (anomaly) because it is different or\nsalient when compared to the surface it resides on. Today, manual human visual\ninspection is still the norm because it is difficult to automate anomaly\ndetection. Neural networks are a useful tool that can teach a machine to find\ndefects. However, they require a lot of training examples to learn what a\ndefect is and it is tedious and expensive to get these samples. We tackle the\nproblem of teaching a network with a low number of training samples with a\nsystem we call AnoNet. AnoNet's architecture is similar to CompactCNN with the\nexceptions that (1) it is a fully convolutional network and does not use\nstrided convolution; (2) it is shallow and compact which minimizes over-fitting\nby design; (3) the compact design constrains the size of intermediate features\nwhich allows training to be done without image downsizing; (4) the model\nfootprint is low making it suitable for edge computation; and (5) the anomaly\ncan be detected and localized despite the weak labelling. AnoNet learns to\ndetect the underlying shape of the anomalies despite the weak annotation as\nwell as preserves the spatial localization of the anomaly. Pre-seeding AnoNet\nwith an engineered filter bank initialization technique reduces the total\nsamples required for training and also achieves state-of-the-art performance.\nCompared to the CompactCNN, AnoNet achieved a massive 94% reduction of network\nparameters from 1.13 million to 64 thousand parameters. Experiments were\nconducted on four data-sets and results were compared against CompactCNN and\nDeepLabv3. AnoNet improved the performance on an average across all data-sets\nby 106% to an F1 score of 0.98 and by 13% to an AUROC value of 0.942. AnoNet\ncan learn from a limited number of images. For one of the data-sets, AnoNet\nlearnt to detect anomalies after a single pass through just 53 training images.\n", "versions": [{"version": "v1", "created": "Sun, 24 Nov 2019 21:05:35 GMT"}], "update_date": "2019-11-26", "authors_parsed": [["Minhas", "Manpreet Singh", ""], ["Zelek", "John", ""]]}, {"id": "1911.10621", "submitter": "Samet Demir", "authors": "Samet Demir, Hasan Ferit Eniser, Alper Sen", "title": "DeepSmartFuzzer: Reward Guided Test Generation For Deep Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Testing Deep Neural Network (DNN) models has become more important than ever\nwith the increasing usage of DNN models in safety-critical domains such as\nautonomous cars. The traditional approach of testing DNNs is to create a test\nset, which is a random subset of the dataset about the problem of interest.\nThis kind of approach is not enough for testing most of the real-world\nscenarios since these traditional test sets do not include corner cases, while\na corner case input is generally considered to introduce erroneous behaviors.\nRecent works on adversarial input generation, data augmentation, and\ncoverage-guided fuzzing (CGF) have provided new ways to extend traditional test\nsets. Among those, CGF aims to produce new test inputs by fuzzing existing ones\nto achieve high coverage on a test adequacy criterion (i.e. coverage\ncriterion). Given that the subject test adequacy criterion is a\nwell-established one, CGF can potentially find error inducing inputs for\ndifferent underlying reasons. In this paper, we propose a novel CGF solution\nfor structural testing of DNNs. The proposed fuzzer employs Monte Carlo Tree\nSearch to drive the coverage-guided search in the pursuit of achieving high\ncoverage. Our evaluation shows that the inputs generated by our method result\nin higher coverage than the inputs produced by the previously introduced\ncoverage-guided fuzzing techniques.\n", "versions": [{"version": "v1", "created": "Sun, 24 Nov 2019 22:18:54 GMT"}], "update_date": "2019-11-26", "authors_parsed": [["Demir", "Samet", ""], ["Eniser", "Hasan Ferit", ""], ["Sen", "Alper", ""]]}, {"id": "1911.10635", "submitter": "Kaiqing Zhang", "authors": "Kaiqing Zhang, Zhuoran Yang, and Tamer Ba\\c{s}ar", "title": "Multi-Agent Reinforcement Learning: A Selective Overview of Theories and\n  Algorithms", "comments": "Invited Chapter in Handbook on RL and Control (Springer Studies in\n  Systems, Decision and Control); Proofread version from the Publisher", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.MA stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent years have witnessed significant advances in reinforcement learning\n(RL), which has registered great success in solving various sequential\ndecision-making problems in machine learning. Most of the successful RL\napplications, e.g., the games of Go and Poker, robotics, and autonomous\ndriving, involve the participation of more than one single agent, which\nnaturally fall into the realm of multi-agent RL (MARL), a domain with a\nrelatively long history, and has recently re-emerged due to advances in\nsingle-agent RL techniques. Though empirically successful, theoretical\nfoundations for MARL are relatively lacking in the literature. In this chapter,\nwe provide a selective overview of MARL, with focus on algorithms backed by\ntheoretical analysis. More specifically, we review the theoretical results of\nMARL algorithms mainly within two representative frameworks, Markov/stochastic\ngames and extensive-form games, in accordance with the types of tasks they\naddress, i.e., fully cooperative, fully competitive, and a mix of the two. We\nalso introduce several significant but challenging applications of these\nalgorithms. Orthogonal to the existing reviews on MARL, we highlight several\nnew angles and taxonomies of MARL theory, including learning in extensive-form\ngames, decentralized MARL with networked agents, MARL in the mean-field regime,\n(non-)convergence of policy-based methods for learning in games, etc. Some of\nthe new angles extrapolate from our own research endeavors and interests. Our\noverall goal with this chapter is, beyond providing an assessment of the\ncurrent state of the field on the mark, to identify fruitful future research\ndirections on theoretical studies of MARL. We expect this chapter to serve as\ncontinuing stimulus for researchers interested in working on this exciting\nwhile challenging topic.\n", "versions": [{"version": "v1", "created": "Sun, 24 Nov 2019 22:50:32 GMT"}, {"version": "v2", "created": "Wed, 28 Apr 2021 21:33:13 GMT"}], "update_date": "2021-04-30", "authors_parsed": [["Zhang", "Kaiqing", ""], ["Yang", "Zhuoran", ""], ["Ba\u015far", "Tamer", ""]]}, {"id": "1911.10640", "submitter": "Aria Khademi", "authors": "Aria Khademi and Vasant Honavar", "title": "Algorithmic Bias in Recidivism Prediction: A Causal Perspective", "comments": "Accepted for publication at the Thirty Fourth AAAI conference on\n  Artificial Intelligence (AAAI-20)", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ME cs.AI cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  ProPublica's analysis of recidivism predictions produced by Correctional\nOffender Management Profiling for Alternative Sanctions (COMPAS) software tool\nfor the task, has shown that the predictions were racially biased against\nAfrican American defendants. We analyze the COMPAS data using a causal\nreformulation of the underlying algorithmic fairness problem. Specifically, we\nassess whether COMPAS exhibits racial bias against African American defendants\nusing FACT, a recently introduced causality grounded measure of algorithmic\nfairness. We use the Neyman-Rubin potential outcomes framework for causal\ninference from observational data to estimate FACT from COMPAS data. Our\nanalysis offers strong evidence that COMPAS exhibits racial bias against\nAfrican American defendants. We further show that the FACT estimates from\nCOMPAS data are robust in the presence of unmeasured confounding.\n", "versions": [{"version": "v1", "created": "Sun, 24 Nov 2019 23:47:50 GMT"}], "update_date": "2019-11-26", "authors_parsed": [["Khademi", "Aria", ""], ["Honavar", "Vasant", ""]]}, {"id": "1911.10641", "submitter": "Bharathan Balaji", "authors": "Bharathan Balaji, Jordan Bell-Masterson, Enes Bilgin, Andreas\n  Damianou, Pablo Moreno Garcia, Arpit Jain, Runfei Luo, Alvaro Maggiar,\n  Balakrishnan Narayanaswamy, Chun Ye", "title": "ORL: Reinforcement Learning Benchmarks for Online Stochastic\n  Optimization Problems", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI math.OC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Reinforcement Learning (RL) has achieved state-of-the-art results in domains\nsuch as robotics and games. We build on this previous work by applying RL\nalgorithms to a selection of canonical online stochastic optimization problems\nwith a range of practical applications: Bin Packing, Newsvendor, and Vehicle\nRouting. While there is a nascent literature that applies RL to these problems,\nthere are no commonly accepted benchmarks which can be used to compare proposed\napproaches rigorously in terms of performance, scale, or generalizability. This\npaper aims to fill that gap. For each problem we apply both standard approaches\nas well as newer RL algorithms and analyze results. In each case, the\nperformance of the trained RL policy is competitive with or superior to the\ncorresponding baselines, while not requiring much in the way of domain\nknowledge. This highlights the potential of RL in real-world dynamic resource\nallocation problems.\n", "versions": [{"version": "v1", "created": "Sun, 24 Nov 2019 23:49:48 GMT"}, {"version": "v2", "created": "Sun, 1 Dec 2019 23:50:12 GMT"}], "update_date": "2019-12-03", "authors_parsed": [["Balaji", "Bharathan", ""], ["Bell-Masterson", "Jordan", ""], ["Bilgin", "Enes", ""], ["Damianou", "Andreas", ""], ["Garcia", "Pablo Moreno", ""], ["Jain", "Arpit", ""], ["Luo", "Runfei", ""], ["Maggiar", "Alvaro", ""], ["Narayanaswamy", "Balakrishnan", ""], ["Ye", "Chun", ""]]}, {"id": "1911.10651", "submitter": "Ilan Price", "authors": "Ilan Price, Jared Tanner", "title": "Trajectory growth lower bounds for random sparse deep ReLU networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper considers the growth in the length of one-dimensional trajectories\nas they are passed through deep ReLU neural networks, which, among other\nthings, is one measure of the expressivity of deep networks. We generalise\nexisting results, providing an alternative, simpler method for lower bounding\nexpected trajectory growth through random networks, for a more general class of\nweights distributions, including sparsely connected networks. We illustrate\nthis approach by deriving bounds for sparse-Gaussian, sparse-uniform, and\nsparse-discrete-valued random nets. We prove that trajectory growth can remain\nexponential in depth with these new distributions, including their sparse\nvariants, with the sparsity parameter appearing in the base of the exponent.\n", "versions": [{"version": "v1", "created": "Mon, 25 Nov 2019 01:01:10 GMT"}], "update_date": "2019-11-26", "authors_parsed": [["Price", "Ilan", ""], ["Tanner", "Jared", ""]]}, {"id": "1911.10653", "submitter": "Ilianna Kollia", "authors": "James Wingate and Ilianna Kollia and Luc Bidaut and Stefanos Kollias", "title": "A Unified Deep Learning Approach for Prediction of Parkinson's Disease", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG eess.SP stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The paper presents a novel approach, based on deep learning, for diagnosis of\nParkinson's disease through medical imaging. The approach includes analysis and\nuse of the knowledge extracted by Deep Convolutional and Recurrent Neural\nNetworks (DNNs) when trained with medical images, such as Magnetic Resonance\nImages and DaTscans. Internal representations of the trained DNNs constitute\nthe extracted knowledge which is used in a transfer learning and domain\nadaptation manner, so as to create a unified framework for prediction of\nParkinson's across different medical environments. A large experimental study\nis presented illustrating the ability of the proposed approach to effectively\npredict Parkinson's, using different medical image sets from real environments.\n", "versions": [{"version": "v1", "created": "Mon, 25 Nov 2019 01:20:38 GMT"}], "update_date": "2019-11-26", "authors_parsed": [["Wingate", "James", ""], ["Kollia", "Ilianna", ""], ["Bidaut", "Luc", ""], ["Kollias", "Stefanos", ""]]}, {"id": "1911.10654", "submitter": "Md Rashidul Hasan", "authors": "Md Rashidul Hasan and Muntasir Al Kabir", "title": "Lung Cancer Detection and Classification based on Image Processing and\n  Statistical Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Lung cancer is one of the death threatening diseases among human beings.\nEarly and accurate detection of lung cancer can increase the survival rate from\nlung cancer. Computed Tomography (CT) images are commonly used for detecting\nthe lung cancer.Using a data set of thousands of high-resolution lung scans\ncollected from Kaggle competition [1], we will develop algorithms that\naccurately determine in the lungs are cancerous or not. The proposed system\npromises better result than the existing systems, which would be beneficial for\nthe radiologist for the accurate and early detection of cancer. The method has\nbeen tested on 198 slices of CT images of various stages of cancer obtained\nfrom Kaggle dataset[1] and is found satisfactory results. The accuracy of the\nproposed method in this dataset is 72.2%\n", "versions": [{"version": "v1", "created": "Mon, 25 Nov 2019 01:24:13 GMT"}], "update_date": "2019-11-26", "authors_parsed": [["Hasan", "Md Rashidul", ""], ["Kabir", "Muntasir Al", ""]]}, {"id": "1911.10658", "submitter": "Wenye Ma", "authors": "Wenye Ma", "title": "Projective Quadratic Regression for Online Learning", "comments": "AAAI 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper considers online convex optimization (OCO) problems - the\nparamount framework for online learning algorithm design. The loss function of\nlearning task in OCO setting is based on streaming data so that OCO is a\npowerful tool to model large scale applications such as online recommender\nsystems. Meanwhile, real-world data are usually of extreme high-dimensional due\nto modern feature engineering techniques so that the quadratic regression is\nimpractical. Factorization Machine as well as its variants are efficient models\nfor capturing feature interactions with low-rank matrix model but they can't\nfulfill the OCO setting due to their non-convexity. In this paper, We propose a\nprojective quadratic regression (PQR) model. First, it can capture the import\nsecond-order feature information. Second, it is a convex model, so the\nrequirements of OCO are fulfilled and the global optimal solution can be\nachieved. Moreover, existing modern online optimization methods such as Online\nGradient Descent (OGD) or Follow-The-Regularized-Leader (FTRL) can be applied\ndirectly. In addition, by choosing a proper hyper-parameter, we show that it\nhas the same order of space and time complexity as the linear model and thus\ncan handle high-dimensional data. Experimental results demonstrate the\nperformance of the proposed PQR model in terms of accuracy and efficiency by\ncomparing with the state-of-the-art methods.\n", "versions": [{"version": "v1", "created": "Mon, 25 Nov 2019 01:43:30 GMT"}], "update_date": "2019-11-26", "authors_parsed": [["Ma", "Wenye", ""]]}, {"id": "1911.10674", "submitter": "Kun Song", "authors": "Kun Song", "title": "Adaptive Nearest Neighbor: A General Framework for Distance Metric\n  Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  $K$-NN classifier is one of the most famous classification algorithms, whose\nperformance is crucially dependent on the distance metric. When we consider the\ndistance metric as a parameter of $K$-NN, learning an appropriate distance\nmetric for $K$-NN can be seen as minimizing the empirical risk of $K$-NN. In\nthis paper, we design a new type of continuous decision function of the $K$-NN\nclassification rule which can be used to construct the continuous empirical\nrisk function of $K$-NN. By minimizing this continuous empirical risk function,\nwe obtain a novel distance metric learning algorithm named as adaptive nearest\nneighbor (ANN). We have proved that the current algorithms such as the large\nmargin nearest neighbor (LMNN), neighbourhood components analysis (NCA) and the\npairwise constraint methods are special cases of the proposed ANN by setting\nthe parameter different values. Compared with the LMNN, NCA, and pairwise\nconstraint methods, our method has a broader searching space which may contain\nbetter solutions. At last, extensive experiments on various data sets are\nconducted to demonstrate the effectiveness and efficiency of the proposed\nmethod.\n", "versions": [{"version": "v1", "created": "Fri, 22 Nov 2019 14:31:25 GMT"}], "update_date": "2019-11-26", "authors_parsed": [["Song", "Kun", ""]]}, {"id": "1911.10677", "submitter": "Yu Bao", "authors": "Yu Bao, Hao Zhou, Jiangtao Feng, Mingxuan Wang, Shujian Huang, Jiajun\n  Chen, Lei LI", "title": "Non-autoregressive Transformer by Position Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Non-autoregressive models are promising on various text generation tasks.\nPrevious work hardly considers to explicitly model the positions of generated\nwords. However, position modeling is an essential problem in non-autoregressive\ntext generation. In this study, we propose PNAT, which incorporates positions\nas a latent variable into the text generative process. Experimental results\nshow that PNAT achieves top results on machine translation and paraphrase\ngeneration tasks, outperforming several strong baselines.\n", "versions": [{"version": "v1", "created": "Mon, 25 Nov 2019 03:08:42 GMT"}], "update_date": "2019-12-02", "authors_parsed": [["Bao", "Yu", ""], ["Zhou", "Hao", ""], ["Feng", "Jiangtao", ""], ["Wang", "Mingxuan", ""], ["Huang", "Shujian", ""], ["Chen", "Jiajun", ""], ["LI", "Lei", ""]]}, {"id": "1911.10684", "submitter": "Yuguang Yang", "authors": "Yuguang Yang", "title": "A Deep Reinforcement Learning Architecture for Multi-stage Optimal\n  Control", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep reinforcement learning for high dimensional, hierarchical control tasks\nusually requires the use of complex neural networks as functional\napproximators, which can lead to inefficiency, instability and even divergence\nin the training process. Here, we introduce stacked deep Q learning (SDQL), a\nflexible modularized deep reinforcement learning architecture, that can enable\nfinding of optimal control policy of control tasks consisting of multiple\nlinear stages in a stable and efficient way. SDQL exploits the linear stage\nstructure by approximating the Q function via a collection of deep Q\nsub-networks stacking along an axis marking the stage-wise progress of the\nwhole task. By back-propagating the learned state values from later stages to\nearlier stages, all sub-networks co-adapt to maximize the total reward of the\nwhole task, although each sub-network is responsible for learning optimal\ncontrol policy for its own stage. This modularized architecture offers\nconsiderable flexibility in terms of environment and policy modeling, as it\nallows choices of different state spaces, action spaces, reward structures, and\nQ networks for each stage, Further, the backward stage-wise training procedure\nof SDQL can offers additional transparency, stability, and flexibility to the\ntraining process, thus facilitating model fine-tuning and hyper-parameter\nsearch. We demonstrate that SDQL is capable of learning competitive strategies\nfor problems with characteristics of high-dimensional state space,\nheterogeneous action space(both discrete and continuous), multiple scales, and\nsparse and delayed rewards.\n", "versions": [{"version": "v1", "created": "Mon, 25 Nov 2019 03:36:47 GMT"}], "update_date": "2019-11-26", "authors_parsed": [["Yang", "Yuguang", ""]]}, {"id": "1911.10687", "submitter": "Muneki Yasuda", "authors": "Muneki Yasuda and Seishirou Ueno", "title": "Improvement of Batch Normalization in Imbalanced Data", "comments": null, "journal-ref": "Proceedings of the 2019 International Symposium on Nonlinear\n  Theory and its Applications (NOLTA2019)", "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this study, we consider classification problems based on neural networks\nin data-imbalanced environment. Learning from an imbalanced data set is one of\nthe most important and practical problems in the field of machine learning. A\nweighted loss function based on cost-sensitive approach is a well-known\neffective method for imbalanced data sets. We consider a combination of\nweighted loss function and batch normalization (BN) in this study. BN is a\npowerful standard technique in the recent developments in deep learning. A\nsimple combination of both methods leads to a size-mismatch problem due to a\nmismatch between interpretations of effective size of data set in both methods.\nWe propose a simple modification to BN to correct the size-mismatch and\ndemonstrate that this modified BN is effective in data-imbalanced environment.\n", "versions": [{"version": "v1", "created": "Mon, 25 Nov 2019 03:43:20 GMT"}], "update_date": "2019-12-02", "authors_parsed": [["Yasuda", "Muneki", ""], ["Ueno", "Seishirou", ""]]}, {"id": "1911.10688", "submitter": "Zhenyue Qin", "authors": "Zhenyue Qin and Dongwoo Kim and Tom Gedeon", "title": "Rethinking Softmax with Cross-Entropy: Neural Network Classifier as\n  Mutual Information Estimator", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Mutual information is widely applied to learn latent representations of\nobservations, whilst its implication in classification neural networks remain\nto be better explained. We show that optimising the parameters of\nclassification neural networks with softmax cross-entropy is equivalent to\nmaximising the mutual information between inputs and labels under the balanced\ndata assumption. Through experiments on synthetic and real datasets, we show\nthat softmax cross-entropy can estimate mutual information approximately. When\napplied to image classification, this relation helps approximate the point-wise\nmutual information between an input image and a label without modifying the\nnetwork structure. To this end, we propose infoCAM, informative class\nactivation map, which highlights regions of the input image that are the most\nrelevant to a given label based on differences in information. The activation\nmap helps localise the target object in an input image. Through experiments on\nthe semi-supervised object localisation task with two real-world datasets, we\nevaluate the effectiveness of our information-theoretic approach.\n", "versions": [{"version": "v1", "created": "Mon, 25 Nov 2019 03:44:34 GMT"}, {"version": "v2", "created": "Mon, 13 Jan 2020 11:46:40 GMT"}, {"version": "v3", "created": "Sun, 29 Mar 2020 12:53:51 GMT"}, {"version": "v4", "created": "Thu, 17 Sep 2020 04:47:27 GMT"}], "update_date": "2020-09-18", "authors_parsed": [["Qin", "Zhenyue", ""], ["Kim", "Dongwoo", ""], ["Gedeon", "Tom", ""]]}, {"id": "1911.10695", "submitter": "Yuzhe Yang", "authors": "Minghao Guo, Yuzhe Yang, Rui Xu, Ziwei Liu, Dahua Lin", "title": "When NAS Meets Robustness: In Search of Robust Architectures against\n  Adversarial Attacks", "comments": "CVPR 2020. First two authors contributed equally", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent advances in adversarial attacks uncover the intrinsic vulnerability of\nmodern deep neural networks. Since then, extensive efforts have been devoted to\nenhancing the robustness of deep networks via specialized learning algorithms\nand loss functions. In this work, we take an architectural perspective and\ninvestigate the patterns of network architectures that are resilient to\nadversarial attacks. To obtain the large number of networks needed for this\nstudy, we adopt one-shot neural architecture search, training a large network\nfor once and then finetuning the sub-networks sampled therefrom. The sampled\narchitectures together with the accuracies they achieve provide a rich basis\nfor our study. Our \"robust architecture Odyssey\" reveals several valuable\nobservations: 1) densely connected patterns result in improved robustness; 2)\nunder computational budget, adding convolution operations to direct connection\nedge is effective; 3) flow of solution procedure (FSP) matrix is a good\nindicator of network robustness. Based on these observations, we discover a\nfamily of robust architectures (RobNets). On various datasets, including CIFAR,\nSVHN, Tiny-ImageNet, and ImageNet, RobNets exhibit superior robustness\nperformance to other widely used architectures. Notably, RobNets substantially\nimprove the robust accuracy (~5% absolute gains) under both white-box and\nblack-box attacks, even with fewer parameter numbers. Code is available at\nhttps://github.com/gmh14/RobNets.\n", "versions": [{"version": "v1", "created": "Mon, 25 Nov 2019 04:14:02 GMT"}, {"version": "v2", "created": "Tue, 26 Nov 2019 06:07:55 GMT"}, {"version": "v3", "created": "Thu, 26 Mar 2020 01:37:40 GMT"}], "update_date": "2020-03-27", "authors_parsed": [["Guo", "Minghao", ""], ["Yang", "Yuzhe", ""], ["Xu", "Rui", ""], ["Liu", "Ziwei", ""], ["Lin", "Dahua", ""]]}, {"id": "1911.10699", "submitter": "Ruijia Wang", "authors": "Xiao Wang, Ruijia Wang, Chuan Shi, Guojie Song, Qingyong Li", "title": "Multi-Component Graph Convolutional Collaborative Filtering", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.IR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The interactions of users and items in recommender system could be naturally\nmodeled as a user-item bipartite graph. In recent years, we have witnessed an\nemerging research effort in exploring user-item graph for collaborative\nfiltering methods. Nevertheless, the formation of user-item interactions\ntypically arises from highly complex latent purchasing motivations, such as\nhigh cost performance or eye-catching appearance, which are indistinguishably\nrepresented by the edges. The existing approaches still remain the differences\nbetween various purchasing motivations unexplored, rendering the inability to\ncapture fine-grained user preference. Therefore, in this paper we propose a\nnovel Multi-Component graph convolutional Collaborative Filtering (MCCF)\napproach to distinguish the latent purchasing motivations underneath the\nobserved explicit user-item interactions. Specifically, there are two\nelaborately designed modules, decomposer and combiner, inside MCCF. The former\nfirst decomposes the edges in user-item graph to identify the latent components\nthat may cause the purchasing relationship; the latter then recombines these\nlatent components automatically to obtain unified embeddings for prediction.\nFurthermore, the sparse regularizer and weighted random sample strategy are\nutilized to alleviate the overfitting problem and accelerate the optimization.\nEmpirical results on three real datasets and a synthetic dataset not only show\nthe significant performance gains of MCCF, but also well demonstrate the\nnecessity of considering multiple components.\n", "versions": [{"version": "v1", "created": "Mon, 25 Nov 2019 04:41:43 GMT"}], "update_date": "2019-11-26", "authors_parsed": [["Wang", "Xiao", ""], ["Wang", "Ruijia", ""], ["Shi", "Chuan", ""], ["Song", "Guojie", ""], ["Li", "Qingyong", ""]]}, {"id": "1911.10708", "submitter": "Idris Abdulmumin", "authors": "Idris Abdulmumin and Bashir Shehu Galadanci", "title": "hauWE: Hausa Words Embedding for Natural Language Processing", "comments": "In Proceedings of the 2019 2nd International Conference of the IEEE\n  Nigeria Computer Chapter", "journal-ref": null, "doi": "10.1109/NigeriaComputConf45974.2019.8949674", "report-no": null, "categories": "cs.CL cs.AI cs.IR cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Words embedding (distributed word vector representations) have become an\nessential component of many natural language processing (NLP) tasks such as\nmachine translation, sentiment analysis, word analogy, named entity recognition\nand word similarity. Despite this, the only work that provides word vectors for\nHausa language is that of Bojanowski et al. [1] trained using fastText,\nconsisting of only a few words vectors. This work presents words embedding\nmodels using Word2Vec's Continuous Bag of Words (CBoW) and Skip Gram (SG)\nmodels. The models, hauWE (Hausa Words Embedding), are bigger and better than\nthe only previous model, making them more useful in NLP tasks. To compare the\nmodels, they were used to predict the 10 most similar words to 30 randomly\nselected Hausa words. hauWE CBoW's 88.7% and hauWE SG's 79.3% prediction\naccuracy greatly outperformed Bojanowski et al. [1]'s 22.3%.\n", "versions": [{"version": "v1", "created": "Mon, 25 Nov 2019 05:46:56 GMT"}], "update_date": "2020-01-08", "authors_parsed": [["Abdulmumin", "Idris", ""], ["Galadanci", "Bashir Shehu", ""]]}, {"id": "1911.10720", "submitter": "Soufiane Belharbi", "authors": "Soufiane Belharbi, Ismail Ben Ayed, Luke McCaffrey, Eric Granger", "title": "Non-parametric Uni-modality Constraints for Deep Ordinal Classification", "comments": "11 pages, 2 figures, under review", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a new constrained-optimization formulation for deep ordinal\nclassification, in which uni-modality of the label distribution is enforced\nimplicitly via a set of inequality constraints over all the pairs of adjacent\nlabels. Based on (c-1) constraints for c labels, our model is non-parametric\nand, therefore, more flexible than the existing deep ordinal classification\ntechniques. Unlike these, it does not restrict the learned representation to a\nsingle and specific parametric model (or penalty) imposed on all the labels.\nTherefore, it enables the training to explore larger spaces of solutions, while\nremoving the need for ad hoc choices and scaling up to large numbers of labels.\nIt can be used in conjunction with any standard classification loss and any\ndeep architecture. To tackle the ensuing challenging optimization problem, we\nsolve a sequence of unconstrained losses based on a powerful extension of the\nlog-barrier method.\n  This handles effectively competing constraints and accommodates standard SGD\nfor deep networks, while avoiding computationally expensive Lagrangian dual\nsteps and outperforming substantially penalty methods. Furthermore, we propose\na new performance metric for ordinal classification, as a proxy to measure\ndistribution uni-modality, referred to as the Sides Order Index (SOI). We\nreport comprehensive evaluations and comparisons to state-of-the-art methods on\nbenchmark public datasets for several ordinal classification tasks, showing the\nmerits of our approach in terms of label consistency, classification accuracy\nand scalability. Importantly, enforcing label consistency with our model does\nnot incur higher classification errors, unlike many existing ordinal\nclassification methods. A public reproducible PyTorch implementation is\nprovided.\n(https://github.com/sbelharbi/unimodal-prob-deep-oc-free-distribution)\n", "versions": [{"version": "v1", "created": "Mon, 25 Nov 2019 06:35:58 GMT"}, {"version": "v2", "created": "Tue, 10 Mar 2020 20:54:09 GMT"}, {"version": "v3", "created": "Thu, 11 Jun 2020 23:26:31 GMT"}], "update_date": "2020-06-15", "authors_parsed": [["Belharbi", "Soufiane", ""], ["Ayed", "Ismail Ben", ""], ["McCaffrey", "Luke", ""], ["Granger", "Eric", ""]]}, {"id": "1911.10728", "submitter": "Xiaojin Zhang", "authors": "Xiaojin Zhang", "title": "Automatic Ensemble Learning for Online Influence Maximization", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the problem of selecting a seed set to maximize the expected\nnumber of influenced nodes in the social network, referred to as the\n\\textit{influence maximization} (IM) problem. We assume that the topology of\nthe social network is prescribed while the influence probabilities among edges\nare unknown. In order to learn the influence probabilities and simultaneously\nmaximize the influence spread, we consider the tradeoff between exploiting the\ncurrent estimation of the influence probabilities to ensure certain influence\nspread and exploring more nodes to learn better about the influence\nprobabilities. The exploitation-exploration trade-off is the core issue in the\nmulti-armed bandit (MAB) problem. If we regard the influence spread as the\nreward, then the IM problem could be reduced to the combinatorial multi-armed\nbandits. At each round, the learner selects a limited number of seed nodes in\nthe social network, then the influence spreads over the network according to\nthe real influence probabilities. The learner could observe the activation\nstatus of the edge if and only if its start node is influenced, which is\nreferred to as the edge-level semi-bandit feedback. Two classical bandit\nalgorithms including Thompson Sampling and Epsilon Greedy are used to solve\nthis combinatorial problem. To ensure the robustness of these two algorithms,\nwe use an automatic ensemble learning strategy, which combines the exploration\nstrategy with exploitation strategy. The ensemble algorithm is self-adaptive\nregarding that the probability of each algorithm could be adjusted based on the\nhistorical performance of the algorithm. Experimental evaluation illustrates\nthe effectiveness of the automatically adjusted hybridization of exploration\nalgorithm with exploitation algorithm.\n", "versions": [{"version": "v1", "created": "Mon, 25 Nov 2019 07:00:01 GMT"}], "update_date": "2019-11-26", "authors_parsed": [["Zhang", "Xiaojin", ""]]}, {"id": "1911.10735", "submitter": "Julien Girard-Satabin", "authors": "Julien Girard-Satabin (TAU, LIST), Guillaume Charpiat (LRI, TAU),\n  Zakaria Chihani (LIST), Marc Schoenauer (TAU)", "title": "CAMUS: A Framework to Build Formal Specifications for Deep Perception\n  Systems Using Simulators", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.NE cs.PF", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The topic of provable deep neural network robustness has raised considerable\ninterest in recent years. Most research has focused on adversarial robustness,\nwhich studies the robustness of perceptive models in the neighbourhood of\nparticular samples. However, other works have proved global properties of\nsmaller neural networks. Yet, formally verifying perception remains uncharted.\nThis is due notably to the lack of relevant properties to verify, as the\ndistribution of possible inputs cannot be formally specified. We propose to\ntake advantage of the simulators often used either to train machine learning\nmodels or to check them with statistical tests, a growing trend in industry.\nOur formulation allows us to formally express and verify safety properties on\nperception units, covering all cases that could ever be generated by the\nsimulator, to the difference of statistical tests which cover only seen\nexamples. Along with this theoretical formulation , we provide a tool to\ntranslate deep learning models into standard logical formulae. As a proof of\nconcept, we train a toy example mimicking an autonomous car perceptive unit,\nand we formally verify that it will never fail to capture the relevant\ninformation in the provided inputs.\n", "versions": [{"version": "v1", "created": "Mon, 25 Nov 2019 07:28:45 GMT"}], "update_date": "2019-11-26", "authors_parsed": [["Girard-Satabin", "Julien", "", "TAU, LIST"], ["Charpiat", "Guillaume", "", "LRI, TAU"], ["Chihani", "Zakaria", "", "LIST"], ["Schoenauer", "Marc", "", "TAU"]]}, {"id": "1911.10737", "submitter": "Liangchen Liu", "authors": "Liangchen Liu, Louis Ly, Colin Macdonald, and Yen-Hsi Richard Tsai", "title": "Nearest Neighbor Sampling of Point Sets using Random Rays", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a new framework for the sampling, compression, and analysis of\ndistributions of point sets and other geometric objects embedded in Euclidean\nspaces. A set of randomly selected rays are projected onto their closest points\nin the data set, forming the ray signature. From the signature, statistical\ninformation about the data set, as well as certain geometrical information, can\nbe extracted, independent of the ray set. We present promising results from\n\"RayNN\", a neural network for the classification of point clouds based on ray\nsignatures.\n", "versions": [{"version": "v1", "created": "Mon, 25 Nov 2019 07:31:54 GMT"}, {"version": "v2", "created": "Fri, 29 Nov 2019 20:09:42 GMT"}], "update_date": "2019-12-03", "authors_parsed": [["Liu", "Liangchen", ""], ["Ly", "Louis", ""], ["Macdonald", "Colin", ""], ["Tsai", "Yen-Hsi Richard", ""]]}, {"id": "1911.10782", "submitter": "Weizhe Liu", "authors": "Weizhe Liu, Mathieu Salzmann, Pascal Fua", "title": "Estimating People Flows to Better Count Them in Crowded Scenes", "comments": "ECCV 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Modern methods for counting people in crowded scenes rely on deep networks to\nestimate people densities in individual images. As such, only very few take\nadvantage of temporal consistency in video sequences, and those that do only\nimpose weak smoothness constraints across consecutive frames.\n  In this paper, we advocate estimating people flows across image locations\nbetween consecutive images and inferring the people densities from these flows\ninstead of directly regressing. This enables us to impose much stronger\nconstraints encoding the conservation of the number of people. As a result, it\nsignificantly boosts performance without requiring a more complex architecture.\nFurthermore, it also enables us to exploit the correlation between people flow\nand optical flow to further improve the results.\n  We will demonstrate that we consistently outperform state-of-the-art methods\non five benchmark datasets.\n", "versions": [{"version": "v1", "created": "Mon, 25 Nov 2019 09:34:40 GMT"}, {"version": "v2", "created": "Wed, 18 Mar 2020 06:32:20 GMT"}, {"version": "v3", "created": "Fri, 10 Jul 2020 16:42:46 GMT"}, {"version": "v4", "created": "Wed, 15 Jul 2020 16:59:04 GMT"}], "update_date": "2020-07-16", "authors_parsed": [["Liu", "Weizhe", ""], ["Salzmann", "Mathieu", ""], ["Fua", "Pascal", ""]]}, {"id": "1911.10787", "submitter": "Zekun Yang", "authors": "Zekun Yang, Juan Feng", "title": "A Causal Inference Method for Reducing Gender Bias in Word Embedding\n  Relations", "comments": "Accepted by AAAI 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Word embedding has become essential for natural language processing as it\nboosts empirical performances of various tasks. However, recent research\ndiscovers that gender bias is incorporated in neural word embeddings, and\ndownstream tasks that rely on these biased word vectors also produce\ngender-biased results. While some word-embedding gender-debiasing methods have\nbeen developed, these methods mainly focus on reducing gender bias associated\nwith gender direction and fail to reduce the gender bias presented in word\nembedding relations. In this paper, we design a causal and simple approach for\nmitigating gender bias in word vector relation by utilizing the statistical\ndependency between gender-definition word embeddings and gender-biased word\nembeddings. Our method attains state-of-the-art results on gender-debiasing\ntasks, lexical- and sentence-level evaluation tasks, and downstream coreference\nresolution tasks.\n", "versions": [{"version": "v1", "created": "Mon, 25 Nov 2019 09:47:11 GMT"}], "update_date": "2019-11-26", "authors_parsed": [["Yang", "Zekun", ""], ["Feng", "Juan", ""]]}, {"id": "1911.10796", "submitter": "Shihua Zhang", "authors": "Chihao Zhang, Kuo Gai and Shihua Zhang", "title": "Matrix Normal PCA for Interpretable Dimension Reduction and Graphical\n  Noise Modeling", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Principal component analysis (PCA) is one of the most widely used dimension\nreduction and multivariate statistical techniques. From a probabilistic\nperspective, PCA seeks a low-dimensional representation of data in the presence\nof independent identical Gaussian noise. Probabilistic PCA (PPCA) and its\nvariants have been extensively studied for decades. Most of them assume the\nunderlying noise follows a certain independent identical distribution. However,\nthe noise in the real world is usually complicated and structured. To address\nthis challenge, some variants of PCA for data with non-IID noise have been\nproposed. However, most of the existing methods only assume that the noise is\ncorrelated in the feature space while there may exist two-way structured noise.\nTo this end, we propose a powerful and intuitive PCA method (MN-PCA) through\nmodeling the graphical noise by the matrix normal distribution, which enables\nus to explore the structure of noise in both the feature space and the sample\nspace. MN-PCA obtains a low-rank representation of data and the structure of\nnoise simultaneously. And it can be explained as approximating data over the\ngeneralized Mahalanobis distance. We develop two algorithms to solve this\nmodel: one maximizes the regularized likelihood, the other exploits the\nWasserstein distance, which is more robust. Extensive experiments on various\ndata demonstrate their effectiveness.\n", "versions": [{"version": "v1", "created": "Mon, 25 Nov 2019 09:59:33 GMT"}, {"version": "v2", "created": "Tue, 5 Jan 2021 15:01:38 GMT"}], "update_date": "2021-01-06", "authors_parsed": [["Zhang", "Chihao", ""], ["Gai", "Kuo", ""], ["Zhang", "Shihua", ""]]}, {"id": "1911.10806", "submitter": "Fan Yang", "authors": "Jin Watanabe, Takatomi Kubo, Fan Yang and Kazushi Ikeda", "title": "Detecting Unknown Behaviors by Pre-defined Behaviours: An Bayesian\n  Non-parametric Approach", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  An automatic mouse behavior recognition system can considerably reduce the\nworkload of experimenters and facilitate the analysis process. Typically,\nsupervised approaches, unsupervised approaches and semi-supervised approaches\nare applied for behavior recognition purpose under a setting which has all of\npredefined behaviors. In the real situation, however, as mouses can show\nvarious types of behaviors, besides the predefined behaviors that we want to\nanalyze, there are many undefined behaviors existing. Both supervised\napproaches and conventional semi-supervised approaches cannot identify these\nundefined behaviors. Though unsupervised approaches can detect these undefined\nbehaviors, a post-hoc labeling is needed. In this paper, we propose a\nsemi-supervised infinite Gaussian mixture model (SsIGMM), to incorporate both\nlabeled and unlabelled information in learning process while considering\nundefined behaviors. It also generates the distribution of the predefined and\nundefined behaviors by mixture Gaussians, which can be used for further\nanalysis. In our experiments, we confirmed the superiority of SsIGMM for\nsegmenting and labelling mouse-behavior videos.\n", "versions": [{"version": "v1", "created": "Mon, 25 Nov 2019 10:17:59 GMT"}, {"version": "v2", "created": "Wed, 11 Dec 2019 08:19:04 GMT"}], "update_date": "2019-12-12", "authors_parsed": [["Watanabe", "Jin", ""], ["Kubo", "Takatomi", ""], ["Yang", "Fan", ""], ["Ikeda", "Kazushi", ""]]}, {"id": "1911.10819", "submitter": "Maxim Berman", "authors": "Maxim Berman and Matthew B. Blaschko", "title": "Discriminative training of conditional random fields with probably\n  submodular constraints", "comments": "14 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Problems of segmentation, denoising, registration and 3D reconstruction are\noften addressed with the graph cut algorithm. However, solving an unconstrained\ngraph cut problem is NP-hard. For tractable optimization, pairwise potentials\nhave to fulfill the submodularity inequality. In our learning paradigm,\npairwise potentials are created as the dot product of a learned vector w with\npositive feature vectors. In order to constrain such a model to remain\ntractable, previous approaches have enforced the weight vector to be positive\nfor pairwise potentials in which the labels differ, and set pairwise potentials\nto zero in the case that the label remains the same. Such constraints are\nsufficient to guarantee that the resulting pairwise potentials satisfy the\nsubmodularity inequality. However, we show that such an approach unnecessarily\nrestricts the capacity of the learned models. Guaranteeing submodularity for\nall possible inputs, no matter how improbable, reduces inference error to\neffectively zero, but increases model error. In contrast, we relax the\nrequirement of guaranteed submodularity to solutions that are probably\napproximately submodular. We show that the conceptually simple strategy of\nenforcing submodularity on the training examples guarantees with low sample\ncomplexity that test images will also yield submodular pairwise potentials.\nResults are presented in the binary and muticlass settings, showing substantial\nimprovement from the resulting increased model capacity.\n", "versions": [{"version": "v1", "created": "Mon, 25 Nov 2019 10:38:05 GMT"}], "update_date": "2019-11-26", "authors_parsed": [["Berman", "Maxim", ""], ["Blaschko", "Matthew B.", ""]]}, {"id": "1911.10829", "submitter": "Christoph Reinders", "authors": "Christoph Reinders and Bodo Rosenhahn", "title": "Neural Random Forest Imitation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present Neural Random Forest Imitation - a novel approach for transforming\nrandom forests into neural networks. Existing methods produce very inefficient\narchitectures and do not scale. In this paper, we introduce a new method for\ngenerating data from a random forest and learning a neural network that\nimitates it. Without any additional training data, this transformation creates\nvery efficient neural networks that learn the decision boundaries of a random\nforest. The generated model is fully differentiable and can be combined with\nthe feature extraction in a single pipeline enabling further end-to-end\nprocessing. Experiments on several real-world benchmark datasets demonstrate\noutstanding performance in terms of scalability, accuracy, and learning with\nvery few training examples. Compared to state-of-the-art mappings, we\nsignificantly reduce the network size while achieving the same or even improved\naccuracy due to better generalization.\n", "versions": [{"version": "v1", "created": "Mon, 25 Nov 2019 11:04:30 GMT"}], "update_date": "2019-11-26", "authors_parsed": [["Reinders", "Christoph", ""], ["Rosenhahn", "Bodo", ""]]}, {"id": "1911.10866", "submitter": "Irina Higgins", "authors": "Christopher Grimm, Irina Higgins, Andre Barreto, Denis Teplyashin,\n  Markus Wulfmeier, Tim Hertweck, Raia Hadsell, Satinder Singh", "title": "Disentangled Cumulants Help Successor Representations Transfer to New\n  Tasks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Biological intelligence can learn to solve many diverse tasks in a data\nefficient manner by re-using basic knowledge and skills from one task to\nanother. Furthermore, many of such skills are acquired without explicit\nsupervision in an intrinsically driven fashion. This is in contrast to the\nstate-of-the-art reinforcement learning agents, which typically start learning\neach new task from scratch and struggle with knowledge transfer. In this paper\nwe propose a principled way to learn a basis set of policies, which, when\nrecombined through generalised policy improvement, come with guarantees on the\ncoverage of the final task space. In particular, we concentrate on solving\ngoal-based downstream tasks where the execution order of actions is not\nimportant. We demonstrate both theoretically and empirically that learning a\nsmall number of policies that reach intrinsically specified goal regions in a\ndisentangled latent space can be re-used to quickly achieve a high level of\nperformance on an exponentially larger number of externally specified, often\nsignificantly more complex downstream tasks. Our learning pipeline consists of\ntwo stages. First, the agent learns to perform intrinsically generated,\ngoal-based tasks in the total absence of environmental rewards. Second, the\nagent leverages this experience to quickly achieve a high level of performance\non numerous diverse externally specified tasks.\n", "versions": [{"version": "v1", "created": "Mon, 25 Nov 2019 12:31:51 GMT"}], "update_date": "2019-11-26", "authors_parsed": [["Grimm", "Christopher", ""], ["Higgins", "Irina", ""], ["Barreto", "Andre", ""], ["Teplyashin", "Denis", ""], ["Wulfmeier", "Markus", ""], ["Hertweck", "Tim", ""], ["Hadsell", "Raia", ""], ["Singh", "Satinder", ""]]}, {"id": "1911.10868", "submitter": "Marin Toromanoff", "authors": "Marin Toromanoff, Emilie Wirbel, Fabien Moutarde", "title": "End-to-End Model-Free Reinforcement Learning for Urban Driving using\n  Implicit Affordances", "comments": "Accepted at main conference of CVPR 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CV cs.RO stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Reinforcement Learning (RL) aims at learning an optimal behavior policy from\nits own experiments and not rule-based control methods. However, there is no RL\nalgorithm yet capable of handling a task as difficult as urban driving. We\npresent a novel technique, coined implicit affordances, to effectively leverage\nRL for urban driving thus including lane keeping, pedestrians and vehicles\navoidance, and traffic light detection. To our knowledge we are the first to\npresent a successful RL agent handling such a complex task especially regarding\nthe traffic light detection. Furthermore, we have demonstrated the\neffectiveness of our method by winning the Camera Only track of the CARLA\nchallenge.\n", "versions": [{"version": "v1", "created": "Mon, 25 Nov 2019 12:34:26 GMT"}, {"version": "v2", "created": "Mon, 16 Mar 2020 14:44:13 GMT"}], "update_date": "2020-03-17", "authors_parsed": [["Toromanoff", "Marin", ""], ["Wirbel", "Emilie", ""], ["Moutarde", "Fabien", ""]]}, {"id": "1911.10873", "submitter": "Marc Aubreville", "authors": "Marc Aubreville, Christof A. Bertram, Samir Jabari, Christian Marzahl,\n  Robert Klopfleisch, Andreas Maier", "title": "Learning New Tricks from Old Dogs -- Inter-Species, Inter-Tissue Domain\n  Adaptation for Mitotic Figure Assessment", "comments": "5 pages, submission to BVM 2020", "journal-ref": "Bildverarbeitung f\\\"ur die Medizin 2020. Informatik Aktuell. p.\n  1-7", "doi": "10.1007/978-3-658-29267-6_1", "report-no": null, "categories": "cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  For histopathological tumor assessment, the count of mitotic figures per area\nis an important part of prognostication. Algorithmic approaches - such as for\nmitotic figure identification - have significantly improved in recent times,\npotentially allowing for computer-augmented or fully automatic screening\nsystems in the future. This trend is further supported by whole slide scanning\nmicroscopes becoming available in many pathology labs and could soon become a\nstandard imaging tool.\n  For an application in broader fields of such algorithms, the availability of\nmitotic figure data sets of sufficient size for the respective tissue type and\nspecies is an important precondition, that is, however, rarely met. While\nalgorithmic performance climbed steadily for e.g. human mammary carcinoma,\nthanks to several challenges held in the field, for most tumor types, data sets\nare not available.\n  In this work, we assess domain transfer of mitotic figure recognition using\ndomain adversarial training on four data sets, two from dogs and two from\nhumans. We were able to show that domain adversarial training considerably\nimproves accuracy when applying mitotic figure classification learned from the\ncanine on the human data sets (up to +12.8% in accuracy) and is thus a helpful\nmethod to transfer knowledge from existing data sets to new tissue types and\nspecies.\n", "versions": [{"version": "v1", "created": "Mon, 25 Nov 2019 12:45:33 GMT"}], "update_date": "2020-02-20", "authors_parsed": [["Aubreville", "Marc", ""], ["Bertram", "Christof A.", ""], ["Jabari", "Samir", ""], ["Marzahl", "Christian", ""], ["Klopfleisch", "Robert", ""], ["Maier", "Andreas", ""]]}, {"id": "1911.10875", "submitter": "Shiliang Sun", "authors": "Ziang Dong, Liang Mao, Shiliang Sun", "title": "Adversarial Attack with Pattern Replacement", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a generative model for adversarial attack. The model generates\nsubtle but predictive patterns from the input. To perform an attack, it\nreplaces the patterns of the input with those generated based on examples from\nsome other class. We demonstrate our model by attacking CNN on MNIST.\n", "versions": [{"version": "v1", "created": "Mon, 25 Nov 2019 12:48:08 GMT"}], "update_date": "2019-12-02", "authors_parsed": [["Dong", "Ziang", ""], ["Mao", "Liang", ""], ["Sun", "Shiliang", ""]]}, {"id": "1911.10885", "submitter": "Frantzeska Lavda", "authors": "Frantzeska Lavda, Magda Gregorov\\'a and Alexandros Kalousis", "title": "Improving VAE generations of multimodal data through data-dependent\n  conditional priors", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  One of the major shortcomings of variational autoencoders is the inability to\nproduce generations from the individual modalities of data originating from\nmixture distributions. This is primarily due to the use of a simple isotropic\nGaussian as the prior for the latent code in the ancestral sampling procedure\nfor the data generations. We propose a novel formulation of variational\nautoencoders, conditional prior VAE (CP-VAE), which learns to differentiate\nbetween the individual mixture components and therefore allows for generations\nfrom the distributional data clusters. We assume a two-level generative process\nwith a continuous (Gaussian) latent variable sampled conditionally on a\ndiscrete (categorical) latent component. The new variational objective\nnaturally couples the learning of the posterior and prior conditionals, and the\nlearning of the latent categories encoding the multimodality of the original\ndata in an unsupervised manner. The data-dependent conditional priors are then\nused to sample the continuous latent code when generating new samples from the\nindividual mixture components corresponding to the multimodal structure of the\noriginal data. Our experimental results illustrate the generative performance\nof our new model comparing to multiple baselines.\n", "versions": [{"version": "v1", "created": "Mon, 25 Nov 2019 13:00:58 GMT"}], "update_date": "2019-12-02", "authors_parsed": [["Lavda", "Frantzeska", ""], ["Gregorov\u00e1", "Magda", ""], ["Kalousis", "Alexandros", ""]]}, {"id": "1911.10914", "submitter": "Patrick Putzky", "authors": "Patrick Putzky and Max Welling", "title": "Invert to Learn to Invert", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Iterative learning to infer approaches have become popular solvers for\ninverse problems. However, their memory requirements during training grow\nlinearly with model depth, limiting in practice model expressiveness. In this\nwork, we propose an iterative inverse model with constant memory that relies on\ninvertible networks to avoid storing intermediate activations. As a result, the\nproposed approach allows us to train models with 400 layers on 3D volumes in an\nMRI image reconstruction task. In experiments on a public data set, we\ndemonstrate that these deeper, and thus more expressive, networks perform\nstate-of-the-art image reconstruction.\n", "versions": [{"version": "v1", "created": "Mon, 25 Nov 2019 13:46:01 GMT"}], "update_date": "2019-11-26", "authors_parsed": [["Putzky", "Patrick", ""], ["Welling", "Max", ""]]}, {"id": "1911.10922", "submitter": "Xiaojiang Yang", "authors": "Xiaojiang Yang, Wendong Bi, Yitong Sun, Yu Cheng, Junchi Yan", "title": "Towards Better Understanding of Disentangled Representations via Mutual\n  Information", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Most existing works on disentangled representation learning are solely built\nupon an marginal independence assumption: all factors in disentangled\nrepresentations should be statistically independent. This assumption is\nnecessary but definitely not sufficient for the disentangled representations\nwithout additional inductive biases in the modeling process, which is shown\ntheoretically in recent studies. We argue in this work that disentangled\nrepresentations should be characterized by their relation with observable data.\nIn particular, we formulate such a relation through the concept of mutual\ninformation: the mutual information between each factor of the disentangled\nrepresentations and data should be invariant conditioned on values of the other\nfactors. Together with the widely accepted independence assumption, we further\nbridge it with the conditional independence of factors in representations\nconditioned on data. Moreover, we note that conditional independence of latent\nvariables has been imposed on most VAE-type models and InfoGAN due to the\nartificial choice of factorized approximate posterior $q(\\rvz|\\rvx)$ in the\nencoders. Such an arrangement of encoders introduces a crucial inductive bias\nfor disentangled representations. To demonstrate the importance of our proposed\nassumption and the related inductive bias, we show in experiments that\nviolating the assumption leads to decline of disentanglement among factors in\nthe learned representations.\n", "versions": [{"version": "v1", "created": "Mon, 25 Nov 2019 13:56:53 GMT"}, {"version": "v2", "created": "Tue, 26 Nov 2019 07:16:05 GMT"}, {"version": "v3", "created": "Wed, 1 Jul 2020 12:19:04 GMT"}], "update_date": "2020-07-02", "authors_parsed": [["Yang", "Xiaojiang", ""], ["Bi", "Wendong", ""], ["Sun", "Yitong", ""], ["Cheng", "Yu", ""], ["Yan", "Junchi", ""]]}, {"id": "1911.10924", "submitter": "Sileye Ba", "authors": "Sileye 0. Ba", "title": "Discovering topics with neural topic models built from PLSA assumptions", "comments": "10 pages, 7 figures, 3 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we present a model for unsupervised topic discovery in texts\ncorpora. The proposed model uses documents, words, and topics lookup table\nembedding as neural network model parameters to build probabilities of words\ngiven topics, and probabilities of topics given documents. These probabilities\nare used to recover by marginalization probabilities of words given documents.\nFor very large corpora where the number of documents can be in the order of\nbillions, using a neural auto-encoder based document embedding is more scalable\nthen using a lookup table embedding as classically done. We thus extended the\nlookup based document embedding model to continuous auto-encoder based model.\nOur models are trained using probabilistic latent semantic analysis (PLSA)\nassumptions. We evaluated our models on six datasets with a rich variety of\ncontents. Conducted experiments demonstrate that the proposed neural topic\nmodels are very effective in capturing relevant topics. Furthermore,\nconsidering perplexity metric, conducted evaluation benchmarks show that our\ntopic models outperform latent Dirichlet allocation (LDA) model which is\nclassically used to address topic discovery tasks.\n", "versions": [{"version": "v1", "created": "Mon, 25 Nov 2019 13:59:05 GMT"}], "update_date": "2019-11-26", "authors_parsed": [["Ba", "Sileye 0.", ""]]}, {"id": "1911.10936", "submitter": "Erhan Bayraktar", "authors": "Erhan Bayraktar, Ibrahim Ekren, Xin Zhang", "title": "Finite-Time 4-Expert Prediction Problem", "comments": "Keywords: machine learning, expert advice framework, asymptotic\n  expansion, inverse Laplace transform, regret minimization, Jacobi-theta\n  function", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.PR cs.GT cs.LG math.AP stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We explicitly solve the nonlinear PDE that is the continuous limit of dynamic\nprogramming of \\emph{expert prediction problem} in finite horizon setting with\n$N=4$ experts. The \\emph{expert prediction problem} is formulated as a zero sum\ngame between a player and an adversary. By showing that the solution is\n$\\mathcal{C}^2$, we are able to show that the strategies conjectured in\narXiv:1409.3040G form an asymptotic Nash equilibrium. We also prove the \"Finite\nvs Geometric regret\" conjecture proposed in arXiv:1409.3040G for $N=4$, and and\nshow that this conjecture in fact follows from the conjecture that the comb\nstrategies are optimal.\n", "versions": [{"version": "v1", "created": "Fri, 22 Nov 2019 03:00:39 GMT"}, {"version": "v2", "created": "Tue, 3 Dec 2019 14:22:47 GMT"}], "update_date": "2019-12-04", "authors_parsed": [["Bayraktar", "Erhan", ""], ["Ekren", "Ibrahim", ""], ["Zhang", "Xin", ""]]}, {"id": "1911.10943", "submitter": "Thiparat Chotibut", "authors": "Zuozhu Liu, Thiparat Chotibut, Christopher Hillar, Shaowei Lin", "title": "Biologically Plausible Sequence Learning with Spiking Neural Networks", "comments": "Accepted for publication in the Proceedings of the 34th AAAI\n  Conference on Artificial Intelligence (AAAI-20)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cond-mat.dis-nn cs.LG cs.NE q-bio.NC", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Motivated by the celebrated discrete-time model of nervous activity outlined\nby McCulloch and Pitts in 1943, we propose a novel continuous-time model, the\nMcCulloch-Pitts network (MPN), for sequence learning in spiking neural\nnetworks. Our model has a local learning rule, such that the synaptic weight\nupdates depend only on the information directly accessible by the synapse. By\nexploiting asymmetry in the connections between binary neurons, we show that\nMPN can be trained to robustly memorize multiple spatiotemporal patterns of\nbinary vectors, generalizing the ability of the symmetric Hopfield network to\nmemorize static spatial patterns. In addition, we demonstrate that the model\ncan efficiently learn sequences of binary pictures as well as generative models\nfor experimental neural spike-train data. Our learning rule is consistent with\nspike-timing-dependent plasticity (STDP), thus providing a theoretical ground\nfor the systematic design of biologically inspired networks with large and\nrobust long-range sequence storage capacity.\n", "versions": [{"version": "v1", "created": "Mon, 25 Nov 2019 15:11:07 GMT"}], "update_date": "2019-11-26", "authors_parsed": [["Liu", "Zuozhu", ""], ["Chotibut", "Thiparat", ""], ["Hillar", "Christopher", ""], ["Lin", "Shaowei", ""]]}, {"id": "1911.10947", "submitter": "Fangchen Liu", "authors": "Fangchen Liu, Zhan Ling, Tongzhou Mu, Hao Su", "title": "State Alignment-based Imitation Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Consider an imitation learning problem that the imitator and the expert have\ndifferent dynamics models. Most of the current imitation learning methods fail\nbecause they focus on imitating actions. We propose a novel state\nalignment-based imitation learning method to train the imitator to follow the\nstate sequences in expert demonstrations as much as possible. The state\nalignment comes from both local and global perspectives and we combine them\ninto a reinforcement learning framework by a regularized policy update\nobjective. We show the superiority of our method on standard imitation learning\nsettings and imitation learning settings where the expert and imitator have\ndifferent dynamics models.\n", "versions": [{"version": "v1", "created": "Thu, 21 Nov 2019 22:18:16 GMT"}], "update_date": "2019-11-26", "authors_parsed": [["Liu", "Fangchen", ""], ["Ling", "Zhan", ""], ["Mu", "Tongzhou", ""], ["Su", "Hao", ""]]}, {"id": "1911.10949", "submitter": "Rundi Wu", "authors": "Rundi Wu, Yixin Zhuang, Kai Xu, Hao Zhang, Baoquan Chen", "title": "PQ-NET: A Generative Part Seq2Seq Network for 3D Shapes", "comments": "Accepted to CVPR 2020. Code available at\n  https://github.com/ChrisWu1997/PQ-NET", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.GR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce PQ-NET, a deep neural network which represents and generates 3D\nshapes via sequential part assembly. The input to our network is a 3D shape\nsegmented into parts, where each part is first encoded into a feature\nrepresentation using a part autoencoder. The core component of PQ-NET is a\nsequence-to-sequence or Seq2Seq autoencoder which encodes a sequence of part\nfeatures into a latent vector of fixed size, and the decoder reconstructs the\n3D shape, one part at a time, resulting in a sequential assembly. The latent\nspace formed by the Seq2Seq encoder encodes both part structure and fine part\ngeometry. The decoder can be adapted to perform several generative tasks\nincluding shape autoencoding, interpolation, novel shape generation, and\nsingle-view 3D reconstruction, where the generated shapes are all composed of\nmeaningful parts.\n", "versions": [{"version": "v1", "created": "Mon, 25 Nov 2019 14:43:05 GMT"}, {"version": "v2", "created": "Thu, 2 Apr 2020 10:16:05 GMT"}, {"version": "v3", "created": "Fri, 24 Apr 2020 01:38:40 GMT"}], "update_date": "2020-04-27", "authors_parsed": [["Wu", "Rundi", ""], ["Zhuang", "Yixin", ""], ["Xu", "Kai", ""], ["Zhang", "Hao", ""], ["Chen", "Baoquan", ""]]}, {"id": "1911.10978", "submitter": "Brendan Odigwe", "authors": "Brendan E. Odigwe, Jesuloluwa S. Eyitayo, Celestine I. Odigwe,\n  Homayoun Valafar", "title": "Modelling of Sickle Cell Anemia Patients Response to Hydroxyurea using\n  Artificial Neural Networks", "comments": "7 Pages, 9 figures, Int'l Conf. Health Informatics and Medical\n  Systems | HIMS'19 |, Las Vegas, NV, July 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.QM cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Hydroxyurea (HU) has been shown to be effective in alleviating the symptoms\nof Sickle Cell Anemia disease. While Hydroxyurea reduces the complications\nassociated with Sickle Cell Anemia in some patients, others do not benefit from\nthis drug and experience deleterious effects since it is also a\nchemotherapeutic agent. Therefore, to whom, should the administration of HU be\nconsidered as a viable option, is the main question asked by the responsible\nphysician. We address this question by developing modeling techniques that can\npredict a patient's response to HU and therefore spare the non-responsive\npatients from the unnecessary effects of HU on the values of 22 parameters that\ncan be obtained from blood samples in 122 patients. Using this data, we\ndeveloped Deep Artificial Neural Network models that can predict with 92.6%\naccuracy, the final HbF value of a subject after undergoing HU therapy. Our\ncurrent studies are focussing on forecasting a patient's HbF response, 30 days\nahead of time.\n", "versions": [{"version": "v1", "created": "Mon, 25 Nov 2019 15:22:29 GMT"}], "update_date": "2019-12-03", "authors_parsed": [["Odigwe", "Brendan E.", ""], ["Eyitayo", "Jesuloluwa S.", ""], ["Odigwe", "Celestine I.", ""], ["Valafar", "Homayoun", ""]]}, {"id": "1911.10979", "submitter": "Yong-Goo Shin", "authors": "Yong-Goo Shin, Yoon-Jae Yeo, and Sung-Jea Ko", "title": "Simple yet Effective Way for Improving the Performance of GAN", "comments": "Accepted to IEEE transactions on neural networks and learning systems", "journal-ref": null, "doi": "10.1109/TNNLS.2020.3045000", "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In adversarial learning, discriminator often fails to guide the generator\nsuccessfully since it distinguishes between real and generated images using\nsilly or non-robust features. To alleviate this problem, this brief presents a\nsimple but effective way that improves the performance of generative\nadversarial network (GAN) without imposing the training overhead or modifying\nthe network architectures of existing methods. The proposed method employs a\nnovel cascading rejection (CR) module for discriminator, which extracts\nmultiple non-overlapped features in an iterative manner using the vector\nrejection operation. Since the extracted diverse features prevent the\ndiscriminator from concentrating on non-meaningful features, the discriminator\ncan guide the generator effectively to produce the images that are more similar\nto the real images. In addition, since the proposed CR module requires only a\nfew simple vector operations, it can be readily applied to existing frameworks\nwith marginal training overheads. Quantitative evaluations on various datasets\nincluding CIFAR-10, CelebA, CelebA-HQ, LSUN, and tiny-ImageNet confirm that the\nproposed method significantly improves the performance of GAN and conditional\nGAN in terms of Frechet inception distance (FID) indicating the diversity and\nvisual appearance of the generated images.\n", "versions": [{"version": "v1", "created": "Tue, 19 Nov 2019 10:31:19 GMT"}, {"version": "v2", "created": "Wed, 11 Dec 2019 03:50:17 GMT"}, {"version": "v3", "created": "Sun, 10 May 2020 04:33:33 GMT"}, {"version": "v4", "created": "Tue, 19 Jan 2021 16:19:15 GMT"}], "update_date": "2021-01-20", "authors_parsed": [["Shin", "Yong-Goo", ""], ["Yeo", "Yoon-Jae", ""], ["Ko", "Sung-Jea", ""]]}, {"id": "1911.10988", "submitter": "Richard Gerum", "authors": "Richard C. Gerum, Andr\\'e Erpenbeck, Patrick Krauss, Achim Schilling", "title": "Sparsity through evolutionary pruning prevents neuronal networks from\n  overfitting", "comments": null, "journal-ref": null, "doi": "10.1016/j.neunet.2020.05.007", "report-no": null, "categories": "cs.NE cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Modern Machine learning techniques take advantage of the exponentially rising\ncalculation power in new generation processor units. Thus, the number of\nparameters which are trained to resolve complex tasks was highly increased over\nthe last decades. However, still the networks fail - in contrast to our brain -\nto develop general intelligence in the sense of being able to solve several\ncomplex tasks with only one network architecture. This could be the case\nbecause the brain is not a randomly initialized neural network, which has to be\ntrained by simply investing a lot of calculation power, but has from birth some\nfixed hierarchical structure. To make progress in decoding the structural basis\nof biological neural networks we here chose a bottom-up approach, where we\nevolutionarily trained small neural networks in performing a maze task. This\nsimple maze task requires dynamical decision making with delayed rewards. We\nwere able to show that during the evolutionary optimization random severance of\nconnections lead to better generalization performance of the networks compared\nto fully connected networks. We conclude that sparsity is a central property of\nneural networks and should be considered for modern Machine learning\napproaches.\n", "versions": [{"version": "v1", "created": "Thu, 7 Nov 2019 14:13:09 GMT"}, {"version": "v2", "created": "Fri, 31 Jan 2020 15:45:19 GMT"}], "update_date": "2020-05-21", "authors_parsed": [["Gerum", "Richard C.", ""], ["Erpenbeck", "Andr\u00e9", ""], ["Krauss", "Patrick", ""], ["Schilling", "Achim", ""]]}, {"id": "1911.11000", "submitter": "Borja Rodr\\'iguez G\\'alvez", "authors": "Borja Rodr\\'iguez-G\\'alvez, Ragnar Thobaben and Mikael Skoglund", "title": "The Convex Information Bottleneck Lagrangian", "comments": "10 pages of main text, 2 page of references and 14 pages of\n  appendices with the proofs, experimental details and caveats", "journal-ref": null, "doi": "10.3390/e22010098", "report-no": null, "categories": "stat.ML cs.IT cs.LG math.IT", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  The information bottleneck (IB) problem tackles the issue of obtaining\nrelevant compressed representations $T$ of some random variable $X$ for the\ntask of predicting $Y$. It is defined as a constrained optimization problem\nwhich maximizes the information the representation has about the task,\n$I(T;Y)$, while ensuring that a certain level of compression $r$ is achieved\n(i.e., $ I(X;T) \\leq r$). For practical reasons, the problem is usually solved\nby maximizing the IB Lagrangian (i.e., $\\mathcal{L}_{\\text{IB}}(T;\\beta) =\nI(T;Y) - \\beta I(X;T)$) for many values of $\\beta \\in [0,1]$. Then, the curve\nof maximal $I(T;Y)$ for a given $I(X;T)$ is drawn and a representation with the\ndesired predictability and compression is selected. It is known when $Y$ is a\ndeterministic function of $X$, the IB curve cannot be explored and another\nLagrangian has been proposed to tackle this problem: the squared IB Lagrangian:\n$\\mathcal{L}_{\\text{sq-IB}}(T;\\beta_{\\text{sq}})=I(T;Y)-\\beta_{\\text{sq}}I(X;T)^2$.\nIn this paper, we (i) present a general family of Lagrangians which allow for\nthe exploration of the IB curve in all scenarios; (ii) provide the exact\none-to-one mapping between the Lagrange multiplier and the desired compression\nrate $r$ for known IB curve shapes; and (iii) show we can approximately obtain\na specific compression level with the convex IB Lagrangian for both known and\nunknown IB curve shapes. This eliminates the burden of solving the optimization\nproblem for many values of the Lagrange multiplier. That is, we prove that we\ncan solve the original constrained problem with a single optimization.\n", "versions": [{"version": "v1", "created": "Mon, 25 Nov 2019 15:48:28 GMT"}, {"version": "v2", "created": "Fri, 10 Jan 2020 18:57:31 GMT"}], "update_date": "2020-02-19", "authors_parsed": [["Rodr\u00edguez-G\u00e1lvez", "Borja", ""], ["Thobaben", "Ragnar", ""], ["Skoglund", "Mikael", ""]]}, {"id": "1911.11010", "submitter": "Andrey Savchenko", "authors": "Andrey V. Savchenko", "title": "Event Recognition with Automatic Album Detection based on Sequential\n  Processing, Neural Attention and Image Captioning", "comments": "11 pages, 5 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper a new formulation of event recognition task is examined: it is\nrequired to predict event categories in a gallery of images, for which albums\n(groups of photos corresponding to a single event) are unknown. We propose the\nnovel two-stage approach. At first, features are extracted in each photo using\nthe pre-trained convolutional neural network. These features are classified\nindividually. The scores of the classifier are used to group sequential photos\ninto several clusters. Finally, the features of photos in each group are\naggregated into a single descriptor using neural attention mechanism. This\nalgorithm is optionally extended to improve the accuracy for classification of\neach image in an album. In contrast to conventional fine-tuning of\nconvolutional neural networks (CNN) we proposed to use image captioning, i.e.,\ngenerative model that converts images to textual descriptions. They are one-hot\nencoded and summarized into sparse feature vector suitable for learning of\narbitrary classifier. Experimental study with Photo Event Collection and\nMulti-Label Curation of Flickr Events Dataset demonstrates that our approach is\n9-20% more accurate than event recognition on single photos. Moreover, proposed\nmethod has 13-16% lower error rate than classification of groups of photos\nobtained with hierarchical clustering. It is experimentally shown that the\nimage captions trained on Conceptual Captions dataset can be classified more\naccurately than the features from object detector, though they both are\nobviously not as rich as the CNN-based features. However, it is possible to\ncombine our approach with conventional CNNs in an ensemble to provide the\nstate-of-the-art results for several event datasets.\n", "versions": [{"version": "v1", "created": "Mon, 25 Nov 2019 15:58:18 GMT"}, {"version": "v2", "created": "Wed, 15 Jan 2020 05:44:26 GMT"}], "update_date": "2020-01-16", "authors_parsed": [["Savchenko", "Andrey V.", ""]]}, {"id": "1911.11017", "submitter": "Jiankai Sun", "authors": "Jiankai Sun, Jie Zhao, Huan Sun, and Srinivasan Parthasarathy", "title": "An End-to-End Framework for Cold Question Routing in Community Question\n  Answering Services", "comments": "arXiv admin note: text overlap with arXiv:1807.00462", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Routing newly posted questions (a.k.a cold questions) to potential answerers\nwith the suitable expertise in Community Question Answering sites (CQAs) is an\nimportant and challenging task. The existing methods either focus only on\nembedding the graph structural information and are less effective for newly\nposted questions, or adopt manually engineered feature vectors that are not as\nrepresentative as the graph embedding methods. Therefore, we propose to address\nthe challenge of leveraging heterogeneous graph and textual information for\ncold question routing by designing an end-to-end framework that jointly learns\nCQA node embeddings and finds best answerers for cold questions. We conducted\nextensive experiments to confirm the usefulness of incorporating the textual\ninformation from question tags and demonstrate that an end-2-end framework can\nachieve promising performances on routing newly posted questions asked by both\nexisting users and newly registered users.\n", "versions": [{"version": "v1", "created": "Fri, 22 Nov 2019 07:59:32 GMT"}], "update_date": "2019-11-26", "authors_parsed": [["Sun", "Jiankai", ""], ["Zhao", "Jie", ""], ["Sun", "Huan", ""], ["Parthasarathy", "Srinivasan", ""]]}, {"id": "1911.11018", "submitter": "Xiaowei Gu", "authors": "Xiaowei Gu, Plamen P Angelov and Eduardo Almeida Soares", "title": "A Self-Adaptive Synthetic Over-Sampling Technique for Imbalanced\n  Classification", "comments": "This paper has been submitted to International Journal of Intelligent\n  Systems for publication", "journal-ref": null, "doi": "10.1002/int.22230", "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Traditionally, in supervised machine learning, (a significant) part of the\navailable data (usually 50% to 80%) is used for training and the rest for\nvalidation. In many problems, however, the data is highly imbalanced in regard\nto different classes or does not have good coverage of the feasible data space\nwhich, in turn, creates problems in validation and usage phase. In this paper,\nwe propose a technique for synthesising feasible and likely data to help\nbalance the classes as well as to boost the performance in terms of confusion\nmatrix as well as overall. The idea, in a nutshell, is to synthesise data\nsamples in close vicinity to the actual data samples specifically for the less\nrepresented (minority) classes. This has also implications to the so-called\nfairness of machine learning. In this paper, we propose a specific method for\nsynthesising data in a way to balance the classes and boost the performance,\nespecially of the minority classes. It is generic and can be applied to\ndifferent base algorithms, e.g. support vector machine, k-nearest neighbour,\ndeep networks, rule-based classifiers, decision trees, etc. The results\ndemonstrated that: i) a significantly more balanced (and fair) classification\nresults can be achieved; ii) that the overall performance as well as the\nperformance per class measured by confusion matrix can be boosted. In addition,\nthis approach can be very valuable for the cases when the number of actual\navailable labelled data is small which itself is one of the problems of the\ncontemporary machine learning.\n", "versions": [{"version": "v1", "created": "Mon, 25 Nov 2019 16:08:32 GMT"}], "update_date": "2020-04-21", "authors_parsed": [["Gu", "Xiaowei", ""], ["Angelov", "Plamen P", ""], ["Soares", "Eduardo Almeida", ""]]}, {"id": "1911.11024", "submitter": "Cooper Mellema", "authors": "Cooper J. Mellema, Alex Treacher, Kevin P. Nguyen, Albert Montillo", "title": "Architectural configurations, atlas granularity and functional\n  connectivity with diagnostic value in Autism Spectrum Disorder", "comments": "Presented at ISBI 2020", "journal-ref": "ISBI 2020. Iowa City, IA, USA, April 3-7: IEEE", "doi": null, "report-no": null, "categories": "cs.LG q-bio.NC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Currently, the diagnosis of Autism Spectrum Disorder (ASD) is dependent upon\na subjective, time-consuming evaluation of behavioral tests by an expert\nclinician. Non-invasive functional MRI (fMRI) characterizes brain connectivity\nand may be used to inform diagnoses and democratize medicine. However,\nsuccessful construction of deep learning models from fMRI requires addressing\nkey choices about the model's architecture, including the number of layers and\nnumber of neurons per layer. Meanwhile, deriving functional connectivity (FC)\nfeatures from fMRI requires choosing an atlas with an appropriate level of\ngranularity. Once a model has been built, it is vital to determine which\nfeatures are predictive of ASD and if similar features are learned across atlas\ngranularity levels. To identify aptly suited architectural configurations,\nprobability distributions of the configurations of high versus low performing\nmodels are compared. To determine the effect of atlas granularity, connectivity\nfeatures are derived from atlases with 3 levels of granularity and important\nfeatures are ranked with permutation feature importance. Results show the\nhighest performing models use between 2-4 hidden layers and 16-64 neurons per\nlayer, granularity dependent. Connectivity features identified as important\nacross all 3 atlas granularity levels include FC to the supplementary motor\ngyrus and language association cortex, regions associated with deficits in\nsocial and sensory processing in ASD. Importantly, the cerebellum, often not\nincluded in functional analyses, is also identified as a region whose abnormal\nconnectivity is highly predictive of ASD. Results of this study identify\nimportant regions to include in future studies of ASD, help assist in the\nselection of network architectures, and help identify appropriate levels of\ngranularity to facilitate the development of accurate diagnostic models of ASD.\n", "versions": [{"version": "v1", "created": "Mon, 25 Nov 2019 16:15:11 GMT"}, {"version": "v2", "created": "Fri, 22 May 2020 21:05:23 GMT"}], "update_date": "2020-05-26", "authors_parsed": [["Mellema", "Cooper J.", ""], ["Treacher", "Alex", ""], ["Nguyen", "Kevin P.", ""], ["Montillo", "Albert", ""]]}, {"id": "1911.11025", "submitter": "Kory W Mathewson", "authors": "Lana Cuthbertson, Alex Kearney, Riley Dawson, Ashia Zawaduk, Eve\n  Cuthbertson, Ann Gordon-Tighe, Kory W Mathewson", "title": "Women, politics and Twitter: Using machine learning to change the\n  discourse", "comments": "8 pages, 2 figures. Presented at the NeurIPS Joint Workshop on AI for\n  Social Good at NeurIPS 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SI cs.CL cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Including diverse voices in political decision-making strengthens our\ndemocratic institutions. Within the Canadian political system, there is gender\ninequality across all levels of elected government. Online abuse, such as\nhateful tweets, leveled at women engaged in politics contributes to this\ninequity, particularly tweets focusing on their gender. In this paper, we\npresent ParityBOT: a Twitter bot which counters abusive tweets aimed at women\nin politics by sending supportive tweets about influential female leaders and\nfacts about women in public life. ParityBOT is the first artificial\nintelligence-based intervention aimed at affecting online discourse for women\nin politics for the better. The goal of this project is to: $1$) raise\nawareness of issues relating to gender inequity in politics, and $2$)\npositively influence public discourse in politics. The main contribution of\nthis paper is a scalable model to classify and respond to hateful tweets with\nquantitative and qualitative assessments. The ParityBOT abusive classification\nsystem was validated on public online harassment datasets. We conclude with\nanalysis of the impact of ParityBOT, drawing from data gathered during\ninterventions in both the $2019$ Alberta provincial and $2019$ Canadian federal\nelections.\n", "versions": [{"version": "v1", "created": "Mon, 25 Nov 2019 16:15:42 GMT"}], "update_date": "2019-11-26", "authors_parsed": [["Cuthbertson", "Lana", ""], ["Kearney", "Alex", ""], ["Dawson", "Riley", ""], ["Zawaduk", "Ashia", ""], ["Cuthbertson", "Eve", ""], ["Gordon-Tighe", "Ann", ""], ["Mathewson", "Kory W", ""]]}, {"id": "1911.11030", "submitter": "Tom Viering", "authors": "Tom J. Viering, Alexander Mey, Marco Loog", "title": "Making Learners (More) Monotone", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Learning performance can show non-monotonic behavior. That is, more data does\nnot necessarily lead to better models, even on average. We propose three\nalgorithms that take a supervised learning model and make it perform more\nmonotone. We prove consistency and monotonicity with high probability, and\nevaluate the algorithms on scenarios where non-monotone behaviour occurs. Our\nproposed algorithm $\\text{MT}_{\\text{HT}}$ makes less than $1\\%$ non-monotone\ndecisions on MNIST while staying competitive in terms of error rate compared to\nseveral baselines.\n", "versions": [{"version": "v1", "created": "Mon, 25 Nov 2019 16:35:03 GMT"}], "update_date": "2019-11-26", "authors_parsed": [["Viering", "Tom J.", ""], ["Mey", "Alexander", ""], ["Loog", "Marco", ""]]}, {"id": "1911.11033", "submitter": "Mehmet Ozgur Turkoglu", "authors": "Mehmet Ozgur Turkoglu, Stefano D'Aronco, Jan Dirk Wegner, Konrad\n  Schindler", "title": "Gating Revisited: Deep Multi-layer RNNs That Can Be Trained", "comments": "To appear in TPAMI (accepted March 2021)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a new STAckable Recurrent cell (STAR) for recurrent neural\nnetworks (RNNs), which has fewer parameters than widely used LSTM and GRU while\nbeing more robust against vanishing or exploding gradients. Stacking recurrent\nunits into deep architectures suffers from two major limitations: (i) many\nrecurrent cells (e.g., LSTMs) are costly in terms of parameters and computation\nresources; and (ii) deep RNNs are prone to vanishing or exploding gradients\nduring training. We investigate the training of multi-layer RNNs and examine\nthe magnitude of the gradients as they propagate through the network in the\n\"vertical\" direction. We show that, depending on the structure of the basic\nrecurrent unit, the gradients are systematically attenuated or amplified. Based\non our analysis we design a new type of gated cell that better preserves\ngradient magnitude. We validate our design on a large number of sequence\nmodelling tasks and demonstrate that the proposed STAR cell allows to build and\ntrain deeper recurrent architectures, ultimately leading to improved\nperformance while being computationally more efficient.\n", "versions": [{"version": "v1", "created": "Mon, 25 Nov 2019 16:35:51 GMT"}, {"version": "v2", "created": "Fri, 10 Apr 2020 08:22:12 GMT"}, {"version": "v3", "created": "Sat, 28 Nov 2020 18:07:40 GMT"}, {"version": "v4", "created": "Sat, 6 Mar 2021 12:26:10 GMT"}], "update_date": "2021-03-09", "authors_parsed": [["Turkoglu", "Mehmet Ozgur", ""], ["D'Aronco", "Stefano", ""], ["Wegner", "Jan Dirk", ""], ["Schindler", "Konrad", ""]]}, {"id": "1911.11034", "submitter": "Ram Shankar Siva Kumar", "authors": "Ram Shankar Siva Kumar (1), David O Brien (2), Kendra Albert (3),\n  Salom\\'e Vilj\\\"oen (2), Jeffrey Snover (1) ((1) Microsoft, (2) Berkman Klein\n  Center for Internet and Society at Harvard University, (3) Harvard Law\n  School)", "title": "Failure Modes in Machine Learning Systems", "comments": "12 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In the last two years, more than 200 papers have been written on how machine\nlearning (ML) systems can fail because of adversarial attacks on the algorithms\nand data; this number balloons if we were to incorporate papers covering\nnon-adversarial failure modes. The spate of papers has made it difficult for ML\npractitioners, let alone engineers, lawyers, and policymakers, to keep up with\nthe attacks against and defenses of ML systems. However, as these systems\nbecome more pervasive, the need to understand how they fail, whether by the\nhand of an adversary or due to the inherent design of a system, will only\nbecome more pressing. In order to equip software developers, security incident\nresponders, lawyers, and policy makers with a common vernacular to talk about\nthis problem, we developed a framework to classify failures into \"Intentional\nfailures\" where the failure is caused by an active adversary attempting to\nsubvert the system to attain her goals; and \"Unintentional failures\" where the\nfailure is because an ML system produces an inherently unsafe outcome. After\ndeveloping the initial version of the taxonomy last year, we worked with\nsecurity and ML teams across Microsoft, 23 external partners, standards\norganization, and governments to understand how stakeholders would use our\nframework. Throughout the paper, we attempt to highlight how machine learning\nfailure modes are meaningfully different from traditional software failures\nfrom a technology and policy perspective.\n", "versions": [{"version": "v1", "created": "Mon, 25 Nov 2019 16:37:28 GMT"}], "update_date": "2019-11-26", "authors_parsed": [["Kumar", "Ram Shankar Siva", ""], ["Brien", "David O", ""], ["Albert", "Kendra", ""], ["Vilj\u00f6en", "Salom\u00e9", ""], ["Snover", "Jeffrey", ""]]}, {"id": "1911.11049", "submitter": "Roy Mitz", "authors": "Roy Mitz, Yoel Shkolnisky", "title": "ROIPCA: An Online PCA algorithm based on rank-one updates", "comments": "16 pages, 6 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Principal components analysis (PCA) is a fundamental algorithm in data\nanalysis. Its online version is useful in many modern applications where the\ndata are too large to fit in memory, or when speed of calculation is important.\nIn this paper we propose ROIPCA, an online PCA algorithm based on rank-one\nupdates. ROIPCA is linear in both the dimension of the data and the number of\ncomponents calculated. We demonstrate its advantages over existing\nstate-of-the-art algorithms in terms of accuracy and running time.\n", "versions": [{"version": "v1", "created": "Mon, 25 Nov 2019 17:00:35 GMT"}], "update_date": "2019-11-26", "authors_parsed": [["Mitz", "Roy", ""], ["Shkolnisky", "Yoel", ""]]}, {"id": "1911.11061", "submitter": "Tommy Jones", "authors": "Tommy Jones", "title": "A Coefficient of Determination for Probabilistic Topic Models", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This research proposes a new (old) metric for evaluating goodness of fit in\ntopic models, the coefficient of determination, or $R^2$. Within the context of\ntopic modeling, $R^2$ has the same interpretation that it does when used in a\nbroader class of statistical models. Reporting $R^2$ with topic models\naddresses two current problems in topic modeling: a lack of standard\ncross-contextual evaluation metrics for topic modeling and ease of\ncommunication with lay audiences. The author proposes that $R^2$ should be\nreported as a standard metric when constructing topic models.\n", "versions": [{"version": "v1", "created": "Wed, 20 Nov 2019 00:55:30 GMT"}, {"version": "v2", "created": "Tue, 26 Nov 2019 03:07:01 GMT"}], "update_date": "2019-11-27", "authors_parsed": [["Jones", "Tommy", ""]]}, {"id": "1911.11062", "submitter": "Md Saiful Islam", "authors": "Arnab Sen Sharma, Maruf Ahmed Mridul, Md Saiful Islam", "title": "Automatic Detection of Satire in Bangla Documents: A CNN Approach Based\n  on Hybrid Feature Extraction Model", "comments": "5 pages, Conference paper", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.CL cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Widespread of satirical news in online communities is an ongoing trend. The\nnature of satires is so inherently ambiguous that sometimes it's too hard even\nfor humans to understand whether it's actually satire or not. So, research\ninterest has grown in this field. The purpose of this research is to detect\nBangla satirical news spread in online news portals as well as social media. In\nthis paper, we propose a hybrid technique for extracting features from text\ndocuments combining Word2Vec and TF-IDF. Using our proposed feature extraction\ntechnique, with standard CNN architecture we could detect whether a Bangla text\ndocument is satire or not with an accuracy of more than 96%.\n", "versions": [{"version": "v1", "created": "Tue, 19 Nov 2019 20:37:03 GMT"}], "update_date": "2019-12-02", "authors_parsed": [["Sharma", "Arnab Sen", ""], ["Mridul", "Maruf Ahmed", ""], ["Islam", "Md Saiful", ""]]}, {"id": "1911.11065", "submitter": "Siamak Shakeri", "authors": "Siamak Shakeri, Abhinav Sethy, Cheng Cheng", "title": "Knowledge Distillation in Document Retrieval", "comments": "Published at Amazon Machine Learning Conference(AMLC) 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Complex deep learning models now achieve state of the art performance for\nmany document retrieval tasks. The best models process the query or claim\njointly with the document. However for fast scalable search it is desirable to\nhave document embeddings which are independent of the claim. In this paper we\nshow that knowledge distillation can be used to encourage a model that\ngenerates claim independent document encodings to mimic the behavior of a more\ncomplex model which generates claim dependent encodings. We explore this\napproach in document retrieval for a fact extraction and verification task. We\nshow that by using the soft labels from a complex cross attention teacher\nmodel, the performance of claim independent student LSTM or CNN models is\nimproved across all the ranking metrics. The student models we use are 12x\nfaster in runtime and 20x smaller in number of parameters than the teacher\n", "versions": [{"version": "v1", "created": "Mon, 11 Nov 2019 21:02:54 GMT"}], "update_date": "2019-11-26", "authors_parsed": [["Shakeri", "Siamak", ""], ["Sethy", "Abhinav", ""], ["Cheng", "Cheng", ""]]}, {"id": "1911.11069", "submitter": "Arthi Krishna", "authors": "Arthi Krishna, Ye Jin, Christine Foster, Greg Gabel, Britt Hanley and\n  Abdou Youssef", "title": "Query Expansion for Patent Searching using Word Embedding and\n  Professional Crowdsourcing", "comments": "Presented at AAAI FSS-19: Artificial Intelligence in Government and\n  Public Sector, Arlington, Virginia, USA", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The patent examination process includes a search of previous work to verify\nthat a patent application describes a novel invention. Patent examiners\nprimarily use keyword-based searches to uncover prior art. A critical part of\nkeyword searching is query expansion, which is the process of including\nalternate terms such as synonyms and other related words, since the same\nconcepts are often described differently in the literature. Patent terminology\nis often domain specific. By curating technology-specific corpora and training\nword embedding models based on these corpora, we are able to automatically\nidentify the most relevant expansions of a given word or phrase. We compare the\nperformance of several automated query expansion techniques against expert\nspecified expansions. Furthermore, we explore a novel mechanism to extract\nrelated terms not just based on one input term but several terms in conjunction\nby computing their centroid and identifying the nearest neighbors to this\ncentroid. Highly skilled patent examiners are often the best and most reliable\nsource of identifying related terms. By designing a user interface that allows\nexaminers to interact with the word embedding suggestions, we are able to use\nthese interactions to power crowdsourced modes of related terms. Learning from\nusers allows us to overcome several challenges such as identifying words that\nare bleeding edge and have not been published in the corpus yet. This paper\nstudies the effectiveness of word embedding and crowdsourced models across 11\ndisparate technical areas.\n", "versions": [{"version": "v1", "created": "Thu, 14 Nov 2019 22:34:02 GMT"}], "update_date": "2019-11-26", "authors_parsed": [["Krishna", "Arthi", ""], ["Jin", "Ye", ""], ["Foster", "Christine", ""], ["Gabel", "Greg", ""], ["Hanley", "Britt", ""], ["Youssef", "Abdou", ""]]}, {"id": "1911.11070", "submitter": "Joanna Misztal-Radecka", "authors": "Joanna Misztal-Radecka, Dominik Rusiecki, Micha{\\l} \\.Zmuda, Artur\n  Bujak", "title": "Trend-responsive User Segmentation Enabling Traceable Publishing\n  Insights. A Case Study of a Real-world Large-scale News Recommendation System", "comments": null, "journal-ref": "7th International Workshop on News Recommendation and Analytics\n  (INRA 2019), in conjunction with RecSys 2019, September 19, 2019, Copenhagen,\n  Denmark", "doi": null, "report-no": null, "categories": "cs.IR cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  The traditional offline approaches are no longer sufficient for building\nmodern recommender systems in domains such as online news services, mainly due\nto the high dynamics of environment changes and necessity to operate on a large\nscale with high data sparsity. The ability to balance exploration with\nexploitation makes the multi-armed bandits an efficient alternative to the\nconventional methods, and a robust user segmentation plays a crucial role in\nproviding the context for such online recommendation algorithms. In this work,\nwe present an unsupervised and trend-responsive method for segmenting users\naccording to their semantic interests, which has been integrated with a\nreal-world system for large-scale news recommendations. The results of an\nonline A/B test show significant improvements compared to a global-optimization\nalgorithm on several services with different characteristics. Based on the\nexperimental results as well as the exploration of segments descriptions and\ntrend dynamics, we propose extensions to this approach that address particular\nreal-world challenges for different use-cases. Moreover, we describe a method\nof generating traceable publishing insights facilitating the creation of\ncontent that serves the diversity of all users needs.\n", "versions": [{"version": "v1", "created": "Mon, 28 Oct 2019 18:42:16 GMT"}], "update_date": "2019-11-26", "authors_parsed": [["Misztal-Radecka", "Joanna", ""], ["Rusiecki", "Dominik", ""], ["\u017bmuda", "Micha\u0142", ""], ["Bujak", "Artur", ""]]}, {"id": "1911.11071", "submitter": "Sami Khairy", "authors": "Sami Khairy, Ruslan Shaydulin, Lukasz Cincio, Yuri Alexeev, Prasanna\n  Balaprakash", "title": "Learning to Optimize Variational Quantum Circuits to Solve Combinatorial\n  Problems", "comments": "To appear in the proceedings of the Thirty-Fourth AAAI Conference on\n  Artificial Intelligence (AAAI), New York, USA, February 2020", "journal-ref": null, "doi": "10.1609/aaai.v34i03.5616", "report-no": "LA-UR-19-28945", "categories": "cs.LG quant-ph stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Quantum computing is a computational paradigm with the potential to\noutperform classical methods for a variety of problems. Proposed recently, the\nQuantum Approximate Optimization Algorithm (QAOA) is considered as one of the\nleading candidates for demonstrating quantum advantage in the near term. QAOA\nis a variational hybrid quantum-classical algorithm for approximately solving\ncombinatorial optimization problems. The quality of the solution obtained by\nQAOA for a given problem instance depends on the performance of the classical\noptimizer used to optimize the variational parameters. In this paper, we\nformulate the problem of finding optimal QAOA parameters as a learning task in\nwhich the knowledge gained from solving training instances can be leveraged to\nfind high-quality solutions for unseen test instances. To this end, we develop\ntwo machine-learning-based approaches. Our first approach adopts a\nreinforcement learning (RL) framework to learn a policy network to optimize\nQAOA circuits. Our second approach adopts a kernel density estimation (KDE)\ntechnique to learn a generative model of optimal QAOA parameters. In both\napproaches, the training procedure is performed on small-sized problem\ninstances that can be simulated on a classical computer; yet the learned RL\npolicy and the generative model can be used to efficiently solve larger\nproblems. Extensive simulations using the IBM Qiskit Aer quantum circuit\nsimulator demonstrate that our proposed RL- and KDE-based approaches reduce the\noptimality gap by factors up to 30.15 when compared with other commonly used\noff-the-shelf optimizers.\n", "versions": [{"version": "v1", "created": "Mon, 25 Nov 2019 17:23:41 GMT"}], "update_date": "2020-06-30", "authors_parsed": [["Khairy", "Sami", ""], ["Shaydulin", "Ruslan", ""], ["Cincio", "Lukasz", ""], ["Alexeev", "Yuri", ""], ["Balaprakash", "Prasanna", ""]]}, {"id": "1911.11082", "submitter": "Jia-Jie Zhu", "authors": "Jia-Jie Zhu, Krikamol Muandet, Moritz Diehl, Bernhard Sch\\\"olkopf", "title": "A New Distribution-Free Concept for Representing, Comparing, and\n  Propagating Uncertainty in Dynamical Systems with Kernel Probabilistic\n  Programming", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG cs.SY eess.SY math.OC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This work presents the concept of kernel mean embedding and kernel\nprobabilistic programming in the context of stochastic systems. We propose\nformulations to represent, compare, and propagate uncertainties for fairly\ngeneral stochastic dynamics in a distribution-free manner. The new tools enjoy\nsound theory rooted in functional analysis and wide applicability as\ndemonstrated in distinct numerical examples. The implication of this new\nconcept is a new mode of thinking about the statistical nature of uncertainty\nin dynamical systems.\n", "versions": [{"version": "v1", "created": "Mon, 25 Nov 2019 17:41:21 GMT"}, {"version": "v2", "created": "Mon, 4 May 2020 17:53:37 GMT"}], "update_date": "2020-05-05", "authors_parsed": [["Zhu", "Jia-Jie", ""], ["Muandet", "Krikamol", ""], ["Diehl", "Moritz", ""], ["Sch\u00f6lkopf", "Bernhard", ""]]}, {"id": "1911.11090", "submitter": "Thomas Elsken", "authors": "Thomas Elsken, Benedikt Staffler, Jan Hendrik Metzen, Frank Hutter", "title": "Meta-Learning of Neural Architectures for Few-Shot Learning", "comments": null, "journal-ref": "2020 IEEE/CVF Conference on Computer Vision and Pattern\n  Recognition (CVPR)", "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The recent progress in neural architecture search (NAS) has allowed scaling\nthe automated design of neural architectures to real-world domains, such as\nobject detection and semantic segmentation. However, one prerequisite for the\napplication of NAS are large amounts of labeled data and compute resources.\nThis renders its application challenging in few-shot learning scenarios, where\nmany related tasks need to be learned, each with limited amounts of data and\ncompute time. Thus, few-shot learning is typically done with a fixed neural\narchitecture. To improve upon this, we propose MetaNAS, the first method which\nfully integrates NAS with gradient-based meta-learning. MetaNAS optimizes a\nmeta-architecture along with the meta-weights during meta-training. During\nmeta-testing, architectures can be adapted to a novel task with a few steps of\nthe task optimizer, that is: task adaptation becomes computationally cheap and\nrequires only little data per task. Moreover, MetaNAS is agnostic in that it\ncan be used with arbitrary model-agnostic meta-learning algorithms and\narbitrary gradient-based NAS methods. %We present encouraging results for\nMetaNAS with a combination of DARTS and REPTILE on few-shot classification\nbenchmarks. Empirical results on standard few-shot classification benchmarks\nshow that MetaNAS with a combination of DARTS and REPTILE yields\nstate-of-the-art results.\n", "versions": [{"version": "v1", "created": "Mon, 25 Nov 2019 17:45:39 GMT"}, {"version": "v2", "created": "Tue, 26 May 2020 15:14:40 GMT"}, {"version": "v3", "created": "Mon, 14 Jun 2021 09:33:52 GMT"}], "update_date": "2021-06-15", "authors_parsed": [["Elsken", "Thomas", ""], ["Staffler", "Benedikt", ""], ["Metzen", "Jan Hendrik", ""], ["Hutter", "Frank", ""]]}, {"id": "1911.11119", "submitter": "Lingfei Wu", "authors": "Lingfei Wu, Ian En-Hsu Yen, Zhen Zhang, Kun Xu, Liang Zhao, Xi Peng,\n  Yinglong Xia and Charu Aggarwal", "title": "Scalable Global Alignment Graph Kernel Using Random Features: From Node\n  Embedding to Graph Embedding", "comments": "KDD'19, Oral Paper, Data and Code link available in the paper", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Graph kernels are widely used for measuring the similarity between graphs.\nMany existing graph kernels, which focus on local patterns within graphs rather\nthan their global properties, suffer from significant structure information\nloss when representing graphs. Some recent global graph kernels, which utilizes\nthe alignment of geometric node embeddings of graphs, yield state-of-the-art\nperformance. However, these graph kernels are not necessarily\npositive-definite. More importantly, computing the graph kernel matrix will\nhave at least quadratic {time} complexity in terms of the number and the size\nof the graphs. In this paper, we propose a new family of global alignment graph\nkernels, which take into account the global properties of graphs by using\ngeometric node embeddings and an associated node transportation based on earth\nmover's distance. Compared to existing global kernels, the proposed kernel is\npositive-definite. Our graph kernel is obtained by defining a distribution over\n\\emph{random graphs}, which can naturally yield random feature approximations.\nThe random feature approximations lead to our graph embeddings, which is named\nas \"random graph embeddings\" (RGE). In particular, RGE is shown to achieve\n\\emph{(quasi-)linear scalability} with respect to the number and the size of\nthe graphs. The experimental results on nine benchmark datasets demonstrate\nthat RGE outperforms or matches twelve state-of-the-art graph classification\nalgorithms.\n", "versions": [{"version": "v1", "created": "Mon, 25 Nov 2019 18:46:03 GMT"}], "update_date": "2019-12-02", "authors_parsed": [["Wu", "Lingfei", ""], ["Yen", "Ian En-Hsu", ""], ["Zhang", "Zhen", ""], ["Xu", "Kun", ""], ["Zhao", "Liang", ""], ["Peng", "Xi", ""], ["Xia", "Yinglong", ""], ["Aggarwal", "Charu", ""]]}, {"id": "1911.11120", "submitter": "Lingfei Wu", "authors": "Zhen Zhang, Yijian Xiang, Lingfei Wu, Bing Xue, Arye Nehorai", "title": "KerGM: Kernelized Graph Matching", "comments": "NeurIPS'19, Spotlight Paper, Data and Code link available in the\n  paper", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Graph matching plays a central role in such fields as computer vision,\npattern recognition, and bioinformatics. Graph matching problems can be cast as\ntwo types of quadratic assignment problems (QAPs): Koopmans-Beckmann's QAP or\nLawler's QAP. In our paper, we provide a unifying view for these two problems\nby introducing new rules for array operations in Hilbert spaces. Consequently,\nLawler's QAP can be considered as the Koopmans-Beckmann's alignment between two\narrays in reproducing kernel Hilbert spaces (RKHS), making it possible to\nefficiently solve the problem without computing a huge affinity matrix.\nFurthermore, we develop the entropy-regularized Frank-Wolfe (EnFW) algorithm\nfor optimizing QAPs, which has the same convergence rate as the original FW\nalgorithm while dramatically reducing the computational burden for each outer\niteration. We conduct extensive experiments to evaluate our approach, and show\nthat our algorithm significantly outperforms the state-of-the-art in both\nmatching accuracy and scalability.\n", "versions": [{"version": "v1", "created": "Mon, 25 Nov 2019 18:46:25 GMT"}], "update_date": "2019-12-02", "authors_parsed": [["Zhang", "Zhen", ""], ["Xiang", "Yijian", ""], ["Wu", "Lingfei", ""], ["Xue", "Bing", ""], ["Nehorai", "Arye", ""]]}, {"id": "1911.11121", "submitter": "Lingfei Wu", "authors": "Lingfei Wu, Ian En-Hsu Yen, Siyu Huo, Liang Zhao, Kun Xu, Liang Ma,\n  Shouling Ji and Charu Aggarwal", "title": "Efficient Global String Kernel with Random Features: Beyond Counting\n  Substructures", "comments": "KDD'19 Oral Paper, Data and Code link available in the paper", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Analysis of large-scale sequential data has been one of the most crucial\ntasks in areas such as bioinformatics, text, and audio mining. Existing string\nkernels, however, either (i) rely on local features of short substructures in\nthe string, which hardly capture long discriminative patterns, (ii) sum over\ntoo many substructures, such as all possible subsequences, which leads to\ndiagonal dominance of the kernel matrix, or (iii) rely on non-positive-definite\nsimilarity measures derived from the edit distance. Furthermore, while there\nhave been works addressing the computational challenge with respect to the\nlength of string, most of them still experience quadratic complexity in terms\nof the number of training samples when used in a kernel-based classifier. In\nthis paper, we present a new class of global string kernels that aims to (i)\ndiscover global properties hidden in the strings through global alignments,\n(ii) maintain positive-definiteness of the kernel, without introducing a\ndiagonal dominant kernel matrix, and (iii) have a training cost linear with\nrespect to not only the length of the string but also the number of training\nstring samples. To this end, the proposed kernels are explicitly defined\nthrough a series of different random feature maps, each corresponding to a\ndistribution of random strings. We show that kernels defined this way are\nalways positive-definite, and exhibit computational benefits as they always\nproduce \\emph{Random String Embeddings (RSE)} that can be directly used in any\nlinear classification models. Our extensive experiments on nine benchmark\ndatasets corroborate that RSE achieves better or comparable accuracy in\ncomparison to state-of-the-art baselines, especially with the strings of longer\nlengths. In addition, we empirically show that RSE scales linearly with the\nincrease of the number and the length of string.\n", "versions": [{"version": "v1", "created": "Mon, 25 Nov 2019 18:47:15 GMT"}], "update_date": "2019-12-02", "authors_parsed": [["Wu", "Lingfei", ""], ["Yen", "Ian En-Hsu", ""], ["Huo", "Siyu", ""], ["Zhao", "Liang", ""], ["Xu", "Kun", ""], ["Ma", "Liang", ""], ["Ji", "Shouling", ""], ["Aggarwal", "Charu", ""]]}, {"id": "1911.11122", "submitter": "Nuri Mert Vural", "authors": "N. Mert Vural, Hakan Gokcesu, Kaan Gokcesu and Suleyman S. Kozat", "title": "Minimax Optimal Algorithms for Adversarial Bandit Problem with Multiple\n  Plays", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We investigate the adversarial bandit problem with multiple plays under\nsemi-bandit feedback. We introduce a highly efficient algorithm that\nasymptotically achieves the performance of the best switching $m$-arm strategy\nwith minimax optimal regret bounds. To construct our algorithm, we introduce a\nnew expert advice algorithm for the multiple-play setting. By using our expert\nadvice algorithm, we additionally improve the best-known high-probability bound\nfor the multi-play setting by $O(\\sqrt{m})$. Our results are guaranteed to hold\nin an individual sequence manner since we have no statistical assumption on the\nbandit arm gains. Through an extensive set of experiments involving synthetic\nand real data, we demonstrate significant performance gains achieved by the\nproposed algorithm with respect to the state-of-the-art algorithms.\n", "versions": [{"version": "v1", "created": "Mon, 25 Nov 2019 18:47:44 GMT"}], "update_date": "2019-12-02", "authors_parsed": [["Vural", "N. Mert", ""], ["Gokcesu", "Hakan", ""], ["Gokcesu", "Kaan", ""], ["Kozat", "Suleyman S.", ""]]}, {"id": "1911.11132", "submitter": "Dan Hendrycks", "authors": "Dan Hendrycks and Steven Basart and Mantas Mazeika and Mohammadreza\n  Mostajabi and Jacob Steinhardt and Dawn Song", "title": "Scaling Out-of-Distribution Detection for Real-World Settings", "comments": "StreetHazards dataset and code are available at\n  https://github.com/hendrycks/anomaly-seg", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Detecting out-of-distribution examples is important for safety-critical\nmachine learning applications such as medical screening and self-driving cars.\nHowever, existing research mainly focuses on simple small-scale settings. To\nset the stage for more realistic out-of-distribution detection, we depart from\nsmall-scale settings and explore large-scale multiclass and multi-label\nsettings with high-resolution images and hundreds of classes. To make future\nwork in real-world settings possible, we also create a new benchmark for\nanomaly segmentation by introducing the Combined Anomalous Object Segmentation\nbenchmark. Our novel benchmark combines two datasets for anomaly segmentation\nthat incorporate both realism and anomaly diversity. Using both real images and\nthose from a simulated driving environment, we ensure the background context\nand a wide variety of anomalous objects are naturally integrated, unlike\nbefore. We conduct extensive experiments in these more realistic settings for\nout-of-distribution detection and find that a surprisingly simple detector\nbased on the maximum logit outperforms prior methods in all the large-scale\nmulti-class, multi-label, and segmentation tasks we consider, establishing a\nnew baseline for future work. These results, along with our new anomaly\nsegmentation benchmark, open the door to future research in out-of-distribution\ndetection.\n", "versions": [{"version": "v1", "created": "Mon, 25 Nov 2019 18:58:23 GMT"}, {"version": "v2", "created": "Mon, 7 Dec 2020 07:24:14 GMT"}], "update_date": "2020-12-08", "authors_parsed": [["Hendrycks", "Dan", ""], ["Basart", "Steven", ""], ["Mazeika", "Mantas", ""], ["Mostajabi", "Mohammadreza", ""], ["Steinhardt", "Jacob", ""], ["Song", "Dawn", ""]]}, {"id": "1911.11134", "submitter": "Utku Evci", "authors": "Utku Evci, Trevor Gale, Jacob Menick, Pablo Samuel Castro, Erich Elsen", "title": "Rigging the Lottery: Making All Tickets Winners", "comments": "Published in Proceedings of the 37th International Conference on\n  Machine Learning. Code can be found in github.com/google-research/rigl", "journal-ref": "Proceedings of the 37th International Conference on Machine\n  Learning (2020) 471-481", "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Many applications require sparse neural networks due to space or inference\ntime restrictions. There is a large body of work on training dense networks to\nyield sparse networks for inference, but this limits the size of the largest\ntrainable sparse model to that of the largest trainable dense model. In this\npaper we introduce a method to train sparse neural networks with a fixed\nparameter count and a fixed computational cost throughout training, without\nsacrificing accuracy relative to existing dense-to-sparse training methods. Our\nmethod updates the topology of the sparse network during training by using\nparameter magnitudes and infrequent gradient calculations. We show that this\napproach requires fewer floating-point operations (FLOPs) to achieve a given\nlevel of accuracy compared to prior techniques. We demonstrate state-of-the-art\nsparse training results on a variety of networks and datasets, including\nResNet-50, MobileNets on Imagenet-2012, and RNNs on WikiText-103. Finally, we\nprovide some insights into why allowing the topology to change during the\noptimization can overcome local minima encountered when the topology remains\nstatic. Code used in our work can be found in github.com/google-research/rigl.\n", "versions": [{"version": "v1", "created": "Mon, 25 Nov 2019 18:58:53 GMT"}, {"version": "v2", "created": "Sat, 25 Jul 2020 20:13:36 GMT"}, {"version": "v3", "created": "Fri, 23 Jul 2021 14:12:42 GMT"}], "update_date": "2021-07-26", "authors_parsed": [["Evci", "Utku", ""], ["Gale", "Trevor", ""], ["Menick", "Jacob", ""], ["Castro", "Pablo Samuel", ""], ["Elsen", "Erich", ""]]}, {"id": "1911.11139", "submitter": "Amin Omidvar", "authors": "Amin Omidvar, Hossein Poormodheji, Aijun An, Gordon Edall", "title": "Learning to Determine the Quality of News Headlines", "comments": "10 Pages, Accepted at the 12th International Conference on Agents and\n  Artificial Intelligence (ICAART) 2020", "journal-ref": null, "doi": "10.5220/0009367504010409", "report-no": null, "categories": "cs.IR cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Today, most newsreaders read the online version of news articles rather than\ntraditional paper-based newspapers. Also, news media publishers rely heavily on\nthe income generated from subscriptions and website visits made by newsreaders.\nThus, online user engagement is a very important issue for online newspapers.\nMuch effort has been spent on writing interesting headlines to catch the\nattention of online users. On the other hand, headlines should not be\nmisleading (e.g., clickbaits); otherwise, readers would be disappointed when\nreading the content. In this paper, we propose four indicators to determine the\nquality of published news headlines based on their click count and dwell time,\nwhich are obtained by website log analysis. Then, we use soft target\ndistribution of the calculated quality indicators to train our proposed deep\nlearning model which can predict the quality of unpublished news headlines. The\nproposed model not only processes the latent features of both headline and body\nof the article to predict its headline quality but also considers the semantic\nrelation between headline and body as well. To evaluate our model, we use a\nreal dataset from a major Canadian newspaper. Results show our proposed model\noutperforms other state-of-the-art NLP models.\n", "versions": [{"version": "v1", "created": "Tue, 26 Nov 2019 00:09:30 GMT"}, {"version": "v2", "created": "Sun, 19 Apr 2020 23:42:19 GMT"}], "update_date": "2020-04-21", "authors_parsed": [["Omidvar", "Amin", ""], ["Poormodheji", "Hossein", ""], ["An", "Aijun", ""], ["Edall", "Gordon", ""]]}, {"id": "1911.11167", "submitter": "Laixi Shi", "authors": "Laixi Shi and Yuejie Chi", "title": "Manifold Gradient Descent Solves Multi-Channel Sparse Blind\n  Deconvolution Provably and Efficiently", "comments": "accepted by IEEE Transactions on Information Theory", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.IT cs.LG eess.SP math.IT math.OC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Multi-channel sparse blind deconvolution, or convolutional sparse coding,\nrefers to the problem of learning an unknown filter by observing its circulant\nconvolutions with multiple input signals that are sparse. This problem finds\nnumerous applications in signal processing, computer vision, and inverse\nproblems. However, it is challenging to learn the filter efficiently due to the\nbilinear structure of the observations with the respect to the unknown filter\nand inputs, as well as the sparsity constraint. In this paper, we propose a\nnovel approach based on nonconvex optimization over the sphere manifold by\nminimizing a smooth surrogate of the sparsity-promoting loss function. It is\ndemonstrated that manifold gradient descent with random initializations will\nprovably recover the filter, up to scaling and shift ambiguity, as soon as the\nnumber of observations is sufficiently large under an appropriate random data\nmodel. Numerical experiments are provided to illustrate the performance of the\nproposed method with comparisons to existing ones.\n", "versions": [{"version": "v1", "created": "Mon, 25 Nov 2019 19:04:07 GMT"}, {"version": "v2", "created": "Sat, 19 Sep 2020 22:12:17 GMT"}, {"version": "v3", "created": "Tue, 6 Apr 2021 02:41:56 GMT"}], "update_date": "2021-04-07", "authors_parsed": [["Shi", "Laixi", ""], ["Chi", "Yuejie", ""]]}, {"id": "1911.11174", "submitter": "David Burth Kurka", "authors": "David Burth Kurka, Deniz G\\\"und\\\"uz", "title": "DeepJSCC-f: Deep Joint Source-Channel Coding of Images with Feedback", "comments": "IEEE Journal on Selected Areas in Information Theory (JSAIT), to\n  appear", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IT cs.LG eess.IV eess.SP math.IT stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider wireless transmission of images in the presence of channel output\nfeedback. From a Shannon theoretic perspective feedback does not improve the\nasymptotic end-to-end performance, and separate source coding followed by\ncapacity-achieving channel coding, which ignores the feedback signal, achieves\nthe optimal performance. It is well known that separation is not optimal in the\npractical finite blocklength regime; however, there are no known practical\njoint source-channel coding (JSCC) schemes that can exploit the feedback signal\nand surpass the performance of separation-based schemes. Inspired by the recent\nsuccess of deep learning methods for JSCC, we investigate how noiseless or\nnoisy channel output feedback can be incorporated into the transmission system\nto improve the reconstruction quality at the receiver. We introduce an\nautoencoder-based JSCC scheme, which we call DeepJSCC-f, that exploits the\nchannel output feedback, and provides considerable improvements in terms of the\nend-to-end reconstruction quality for fixed-length transmission, or in terms of\nthe average delay for variable-length transmission. To the best of our\nknowledge, this is the first practical JSCC scheme that can fully exploit\nchannel output feedback, demonstrating yet another setting in which modern\nmachine learning techniques can enable the design of new and efficient\ncommunication methods that surpass the performance of traditional structured\ncoding-based designs.\n", "versions": [{"version": "v1", "created": "Mon, 25 Nov 2019 19:13:53 GMT"}, {"version": "v2", "created": "Thu, 9 Apr 2020 20:27:34 GMT"}], "update_date": "2020-04-13", "authors_parsed": [["Kurka", "David Burth", ""], ["G\u00fcnd\u00fcz", "Deniz", ""]]}, {"id": "1911.11177", "submitter": "Yair Movshovitz-Attias", "authors": "Elad Eban, Yair Movshovitz-Attias, Hao Wu, Mark Sandler, Andrew Poon,\n  Yerlan Idelbayev, Miguel A. Carreira-Perpinan", "title": "Structured Multi-Hashing for Model Compression", "comments": "Elad and Yair contributed equally to the paper. They jointly proposed\n  the idea of structured-multi-hashing. Elad: Wrote most of the code and ran\n  most of the experiments Yair: Main contributor to the manuscript Hao: Coding\n  and experiments Yerlan: Coding and experiments Miguel: advised Yerlan about\n  optimization and model compression Mark:experiments Andrew: experiments", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Despite the success of deep neural networks (DNNs), state-of-the-art models\nare too large to deploy on low-resource devices or common server configurations\nin which multiple models are held in memory. Model compression methods address\nthis limitation by reducing the memory footprint, latency, or energy\nconsumption of a model with minimal impact on accuracy. We focus on the task of\nreducing the number of learnable variables in the model. In this work we\ncombine ideas from weight hashing and dimensionality reductions resulting in a\nsimple and powerful structured multi-hashing method based on matrix products\nthat allows direct control of model size of any deep network and is trained\nend-to-end. We demonstrate the strength of our approach by compressing models\nfrom the ResNet, EfficientNet, and MobileNet architecture families. Our method\nallows us to drastically decrease the number of variables while maintaining\nhigh accuracy. For instance, by applying our approach to EfficentNet-B4 (16M\nparameters) we reduce it to to the size of B0 (5M parameters), while gaining\nover 3% in accuracy over B0 baseline. On the commonly used benchmark CIFAR10 we\nreduce the ResNet32 model by 75% with no loss in quality, and are able to do a\n10x compression while still achieving above 90% accuracy.\n", "versions": [{"version": "v1", "created": "Mon, 25 Nov 2019 19:21:25 GMT"}], "update_date": "2019-11-27", "authors_parsed": [["Eban", "Elad", ""], ["Movshovitz-Attias", "Yair", ""], ["Wu", "Hao", ""], ["Sandler", "Mark", ""], ["Poon", "Andrew", ""], ["Idelbayev", "Yerlan", ""], ["Carreira-Perpinan", "Miguel A.", ""]]}, {"id": "1911.11185", "submitter": "Xiaojian Ma", "authors": "Mark Edmonds, Xiaojian Ma, Siyuan Qi, Yixin Zhu, Hongjing Lu,\n  Song-Chun Zhu", "title": "Theory-based Causal Transfer: Integrating Instance-level Induction and\n  Abstract-level Structure Learning", "comments": "Accepted to AAAI 2020 as an oral", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Learning transferable knowledge across similar but different settings is a\nfundamental component of generalized intelligence. In this paper, we approach\nthe transfer learning challenge from a causal theory perspective. Our agent is\nendowed with two basic yet general theories for transfer learning: (i) a task\nshares a common abstract structure that is invariant across domains, and (ii)\nthe behavior of specific features of the environment remain constant across\ndomains. We adopt a Bayesian perspective of causal theory induction and use\nthese theories to transfer knowledge between environments. Given these general\ntheories, the goal is to train an agent by interactively exploring the problem\nspace to (i) discover, form, and transfer useful abstract and structural\nknowledge, and (ii) induce useful knowledge from the instance-level attributes\nobserved in the environment. A hierarchy of Bayesian structures is used to\nmodel abstract-level structural causal knowledge, and an instance-level\nassociative learning scheme learns which specific objects can be used to induce\nstate changes through interaction. This model-learning scheme is then\nintegrated with a model-based planner to achieve a task in the OpenLock\nenvironment, a virtual ``escape room'' with a complex hierarchy that requires\nagents to reason about an abstract, generalized causal structure. We compare\nperformances against a set of predominate model-free reinforcement learning(RL)\nalgorithms. RL agents showed poor ability transferring learned knowledge across\ndifferent trials. Whereas the proposed model revealed similar performance\ntrends as human learners, and more importantly, demonstrated transfer behavior\nacross trials and learning situations.\n", "versions": [{"version": "v1", "created": "Mon, 25 Nov 2019 19:36:28 GMT"}], "update_date": "2019-11-27", "authors_parsed": [["Edmonds", "Mark", ""], ["Ma", "Xiaojian", ""], ["Qi", "Siyuan", ""], ["Zhu", "Yixin", ""], ["Lu", "Hongjing", ""], ["Zhu", "Song-Chun", ""]]}, {"id": "1911.11195", "submitter": "Azadeh Mozafari", "authors": "Azadeh Sadat Mozafari, Hugo Siqueira Gomes, Christian Gagne", "title": "A Novel Unsupervised Post-Processing Calibration Method for DNNS with\n  Robustness to Domain Shift", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The uncertainty estimation is critical in real-world decision making\napplications, especially when distributional shift between the training and\ntest data are prevalent. Many calibration methods in the literature have been\nproposed to improve the predictive uncertainty of DNNs which are generally not\nwell-calibrated. However, none of them is specifically designed to work\nproperly under domain shift condition. In this paper, we propose Unsupervised\nTemperature Scaling (UTS) as a robust calibration method to domain shift. It\nexploits unlabeled test samples instead of the training one to adjust the\nuncertainty prediction of deep models towards the test distribution. UTS\nutilizes a novel loss function, weighted NLL, which allows unsupervised\ncalibration. We evaluate UTS on a wide range of model-datasets to show the\npossibility of calibration without labels and demonstrate the robustness of UTS\ncompared to other methods (e.g., TS, MC-dropout, SVI, ensembles) in shifted\ndomains.\n", "versions": [{"version": "v1", "created": "Mon, 25 Nov 2019 19:59:40 GMT"}], "update_date": "2019-11-27", "authors_parsed": [["Mozafari", "Azadeh Sadat", ""], ["Gomes", "Hugo Siqueira", ""], ["Gagne", "Christian", ""]]}, {"id": "1911.11201", "submitter": "Yoolhee Kim", "authors": "Yoolhee Kim, Edward Kim, Erin Antono, Bryce Meredig, Julia Ling", "title": "Machine-learned metrics for predicting the likelihood of success in\n  materials discovery", "comments": "13 pages, 10 figures, 2 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cond-mat.mtrl-sci cs.LG physics.comp-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Materials discovery is often compared to the challenge of finding a needle in\na haystack. While much work has focused on accurately predicting the properties\nof candidate materials with machine learning (ML), which amounts to evaluating\nwhether a given candidate is a piece of straw or a needle, less attention has\nbeen paid to a critical question: Are we searching in the right haystack? We\nrefer to the haystack as the design space for a particular materials discovery\nproblem (i.e. the set of possible candidate materials to synthesize), and thus\nframe this question as one of design space selection. In this paper, we\nintroduce two metrics, the Predicted Fraction of Improved Candidates (PFIC),\nand the Cumulative Maximum Likelihood of Improvement (CMLI), which we\ndemonstrate can identify discovery-rich and discovery-poor design spaces,\nrespectively. Using CMLI and PFIC together to identify optimal design spaces\ncan significantly accelerate ML-driven materials discovery.\n", "versions": [{"version": "v1", "created": "Mon, 25 Nov 2019 20:08:35 GMT"}, {"version": "v2", "created": "Wed, 27 Nov 2019 16:46:14 GMT"}], "update_date": "2019-11-28", "authors_parsed": [["Kim", "Yoolhee", ""], ["Kim", "Edward", ""], ["Antono", "Erin", ""], ["Meredig", "Bryce", ""], ["Ling", "Julia", ""]]}, {"id": "1911.11206", "submitter": "Dave Epstein", "authors": "Dave Epstein, Boyuan Chen, Carl Vondrick", "title": "Oops! Predicting Unintentional Action in Video", "comments": "11 pages, 9 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG eess.IV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  From just a short glance at a video, we can often tell whether a person's\naction is intentional or not. Can we train a model to recognize this? We\nintroduce a dataset of in-the-wild videos of unintentional action, as well as a\nsuite of tasks for recognizing, localizing, and anticipating its onset. We\ntrain a supervised neural network as a baseline and analyze its performance\ncompared to human consistency on the tasks. We also investigate self-supervised\nrepresentations that leverage natural signals in our dataset, and show the\neffectiveness of an approach that uses the intrinsic speed of video to perform\ncompetitively with highly-supervised pretraining. However, a significant gap\nbetween machine and human performance remains. The project website is available\nat https://oops.cs.columbia.edu\n", "versions": [{"version": "v1", "created": "Mon, 25 Nov 2019 20:15:31 GMT"}], "update_date": "2019-11-27", "authors_parsed": [["Epstein", "Dave", ""], ["Chen", "Boyuan", ""], ["Vondrick", "Carl", ""]]}, {"id": "1911.11209", "submitter": "Naofumi Tomita", "authors": "Naofumi Tomita, Steven Jiang, Matthew E. Maeder and Saeed Hassanpour", "title": "Automatic Post-Stroke Lesion Segmentation on MR Images using 3D Residual\n  Convolutional Neural Network", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.IV cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we demonstrate the feasibility and performance of deep\nresidual neural networks for volumetric segmentation of irreversibly damaged\nbrain tissue lesions on T1-weighted MRI scans for chronic stroke patients. A\ntotal of 239 T1-weighted MRI scans of chronic ischemic stroke patients from a\npublic dataset were retrospectively analyzed by 3D deep convolutional\nsegmentation models with residual learning, using a novel zoom-in&out strategy.\nDice similarity coefficient (DSC), Average symmetric surface distance (ASSD),\nand Hausdorff distance (HD) of the identified lesions were measured by using\nthe manual tracing of lesions as the reference standard. Bootstrapping was\nemployed for all metrics to estimate 95% confidence intervals. The models were\nassessed on the test set of 31 scans. The average DSC was 0.64 (0.51-0.76) with\na median of 0.78. ASSD and HD were 3.6 mm (1.7-6.2 mm) and 20.4 mm (10.0-33.3\nmm), respectively. To the best of our knowledge, this performance is the\nhighest achieved on this public dataset. The latest deep learning architecture\nand techniques were applied for 3D segmentation on MRI scans and demonstrated\nto be effective for volumetric segmentation of chronic ischemic stroke lesions.\n", "versions": [{"version": "v1", "created": "Mon, 25 Nov 2019 20:20:58 GMT"}], "update_date": "2019-11-27", "authors_parsed": [["Tomita", "Naofumi", ""], ["Jiang", "Steven", ""], ["Maeder", "Matthew E.", ""], ["Hassanpour", "Saeed", ""]]}, {"id": "1911.11219", "submitter": "Chang Xiao", "authors": "Chang Xiao and Changxi Zheng", "title": "One Man's Trash is Another Man's Treasure: Resisting Adversarial\n  Examples by Adversarial Examples", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV eess.IV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Modern image classification systems are often built on deep neural networks,\nwhich suffer from adversarial examples--images with deliberately crafted,\nimperceptible noise to mislead the network's classification. To defend against\nadversarial examples, a plausible idea is to obfuscate the network's gradient\nwith respect to the input image. This general idea has inspired a long line of\ndefense methods. Yet, almost all of them have proven vulnerable. We revisit\nthis seemingly flawed idea from a radically different perspective. We embrace\nthe omnipresence of adversarial examples and the numerical procedure of\ncrafting them, and turn this harmful attacking process into a useful defense\nmechanism. Our defense method is conceptually simple: before feeding an input\nimage for classification, transform it by finding an adversarial example on a\npre-trained external model. We evaluate our method against a wide range of\npossible attacks. On both CIFAR-10 and Tiny ImageNet datasets, our method is\nsignificantly more robust than state-of-the-art methods. Particularly, in\ncomparison to adversarial training, our method offers lower training cost as\nwell as stronger robustness.\n", "versions": [{"version": "v1", "created": "Mon, 25 Nov 2019 20:33:59 GMT"}, {"version": "v2", "created": "Wed, 27 Nov 2019 21:10:06 GMT"}], "update_date": "2019-12-02", "authors_parsed": [["Xiao", "Chang", ""], ["Zheng", "Changxi", ""]]}, {"id": "1911.11230", "submitter": "Chenxi Liu", "authors": "Michelle Shu, Chenxi Liu, Weichao Qiu, Alan Yuille", "title": "Identifying Model Weakness with Adversarial Examiner", "comments": "To appear in AAAI-20", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Machine learning models are usually evaluated according to the average case\nperformance on the test set. However, this is not always ideal, because in some\nsensitive domains (e.g. autonomous driving), it is the worst case performance\nthat matters more. In this paper, we are interested in systematic exploration\nof the input data space to identify the weakness of the model to be evaluated.\nWe propose to use an adversarial examiner in the testing stage. Different from\nthe existing strategy to always give the same (distribution of) test data, the\nadversarial examiner will dynamically select the next test data to hand out\nbased on the testing history so far, with the goal being to undermine the\nmodel's performance. This sequence of test data not only helps us understand\nthe current model, but also serves as constructive feedback to help improve the\nmodel in the next iteration. We conduct experiments on ShapeNet object\nclassification. We show that our adversarial examiner can successfully put more\nemphasis on the weakness of the model, preventing performance estimates from\nbeing overly optimistic.\n", "versions": [{"version": "v1", "created": "Mon, 25 Nov 2019 21:04:49 GMT"}], "update_date": "2019-11-27", "authors_parsed": [["Shu", "Michelle", ""], ["Liu", "Chenxi", ""], ["Qiu", "Weichao", ""], ["Yuille", "Alan", ""]]}, {"id": "1911.11236", "submitter": "Bo Yang", "authors": "Qingyong Hu, Bo Yang, Linhai Xie, Stefano Rosa, Yulan Guo, Zhihua\n  Wang, Niki Trigoni, Andrew Markham", "title": "RandLA-Net: Efficient Semantic Segmentation of Large-Scale Point Clouds", "comments": "CVPR 2020 Oral. Code and data are available at:\n  https://github.com/QingyongHu/RandLA-Net", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG eess.IV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the problem of efficient semantic segmentation for large-scale 3D\npoint clouds. By relying on expensive sampling techniques or computationally\nheavy pre/post-processing steps, most existing approaches are only able to be\ntrained and operate over small-scale point clouds. In this paper, we introduce\nRandLA-Net, an efficient and lightweight neural architecture to directly infer\nper-point semantics for large-scale point clouds. The key to our approach is to\nuse random point sampling instead of more complex point selection approaches.\nAlthough remarkably computation and memory efficient, random sampling can\ndiscard key features by chance. To overcome this, we introduce a novel local\nfeature aggregation module to progressively increase the receptive field for\neach 3D point, thereby effectively preserving geometric details. Extensive\nexperiments show that our RandLA-Net can process 1 million points in a single\npass with up to 200X faster than existing approaches. Moreover, our RandLA-Net\nclearly surpasses state-of-the-art approaches for semantic segmentation on two\nlarge-scale benchmarks Semantic3D and SemanticKITTI.\n", "versions": [{"version": "v1", "created": "Mon, 25 Nov 2019 21:15:52 GMT"}, {"version": "v2", "created": "Mon, 30 Mar 2020 23:57:02 GMT"}, {"version": "v3", "created": "Fri, 1 May 2020 21:29:02 GMT"}], "update_date": "2020-05-05", "authors_parsed": [["Hu", "Qingyong", ""], ["Yang", "Bo", ""], ["Xie", "Linhai", ""], ["Rosa", "Stefano", ""], ["Guo", "Yulan", ""], ["Wang", "Zhihua", ""], ["Trigoni", "Niki", ""], ["Markham", "Andrew", ""]]}, {"id": "1911.11237", "submitter": "Didac Suris Coll-Vinent", "authors": "D\\'idac Sur\\'is, Dave Epstein, Heng Ji, Shih-Fu Chang, Carl Vondrick", "title": "Learning to Learn Words from Visual Scenes", "comments": "26 pages, 12 figures", "journal-ref": "European Conference on Computer Vision (ECCV), 2020", "doi": null, "report-no": null, "categories": "cs.CL cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Language acquisition is the process of learning words from the surrounding\nscene. We introduce a meta-learning framework that learns how to learn word\nrepresentations from unconstrained scenes. We leverage the natural\ncompositional structure of language to create training episodes that cause a\nmeta-learner to learn strong policies for language acquisition. Experiments on\ntwo datasets show that our approach is able to more rapidly acquire novel words\nas well as more robustly generalize to unseen compositions, significantly\noutperforming established baselines. A key advantage of our approach is that it\nis data efficient, allowing representations to be learned from scratch without\nlanguage pre-training. Visualizations and analysis suggest visual information\nhelps our approach learn a rich cross-modal representation from minimal\nexamples. Project webpage is available at https://expert.cs.columbia.edu/\n", "versions": [{"version": "v1", "created": "Mon, 25 Nov 2019 21:19:31 GMT"}, {"version": "v2", "created": "Mon, 16 Mar 2020 21:19:04 GMT"}, {"version": "v3", "created": "Sun, 12 Jul 2020 21:19:49 GMT"}], "update_date": "2020-07-14", "authors_parsed": [["Sur\u00eds", "D\u00eddac", ""], ["Epstein", "Dave", ""], ["Ji", "Heng", ""], ["Chang", "Shih-Fu", ""], ["Vondrick", "Carl", ""]]}, {"id": "1911.11238", "submitter": "Ganesh Sundaramoorthi", "authors": "Ganesh Sundaramoorthi, Timothy E. Wang", "title": "Translation Insensitive CNNs", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We address the problem that state-of-the-art Convolution Neural Networks\n(CNN) classifiers are not invariant to small shifts. The problem can be solved\nby the removal of sub-sampling operations such as stride and max pooling, but\nat a cost of severely degraded training and test efficiency. We present a novel\nusage of Gaussian-Hermite basis to efficiently approximate arbitrary filters\nwithin the CNN framework to obtain translation invariance. This is shown to be\ninvariant to small shifts, and preserves the efficiency of training. Further,\nto improve efficiency in memory usage as well as computational speed, we show\nthat it is still possible to sub-sample with this approach and retain a weaker\nform of invariance that we call \\emph{translation insensitivity}, which leads\nto stability with respect to shifts. We prove these claims analytically and\nempirically. Our analytic methods further provide a framework for understanding\nany architecture in terms of translation insensitivity, and provide guiding\nprinciples for design.\n", "versions": [{"version": "v1", "created": "Mon, 25 Nov 2019 21:22:06 GMT"}], "update_date": "2019-11-27", "authors_parsed": [["Sundaramoorthi", "Ganesh", ""], ["Wang", "Timothy E.", ""]]}, {"id": "1911.11250", "submitter": "Tobias Schlosser", "authors": "Tobias Schlosser, Frederik Beuth, Michael Friedrich, and Danny Kowerko", "title": "A Novel Visual Fault Detection and Classification System for\n  Semiconductor Manufacturing Using Stacked Hybrid Convolutional Neural\n  Networks", "comments": "Accepted for: 2019 IEEE 24th International Conference on Emerging\n  Technologies and Factory Automation (ETFA); the latest versions of this\n  contribution cover minor typo corrections", "journal-ref": null, "doi": "10.1109/ETFA.2019.8869311", "report-no": null, "categories": "cs.LG cs.CV eess.IV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Automated visual inspection in the semiconductor industry aims to detect and\nclassify manufacturing defects utilizing modern image processing techniques.\nWhile an earliest possible detection of defect patterns allows quality control\nand automation of manufacturing chains, manufacturers benefit from an increased\nyield and reduced manufacturing costs. Since classical image processing systems\nare limited in their ability to detect novel defect patterns, and machine\nlearning approaches often involve a tremendous amount of computational effort,\nthis contribution introduces a novel deep neural network based hybrid approach.\nUnlike classical deep neural networks, a multi-stage system allows the\ndetection and classification of the finest structures in pixel size within\nhigh-resolution imagery. Consisting of stacked hybrid convolutional neural\nnetworks (SH-CNN) and inspired by current approaches of visual attention, the\nrealized system draws the focus over the level of detail from its structures to\nmore task-relevant areas of interest. The results of our test environment show\nthat the SH-CNN outperforms current approaches of learning-based automated\nvisual inspection, whereas a distinction depending on the level of detail\nenables the elimination of defect patterns in earlier stages of the\nmanufacturing process.\n", "versions": [{"version": "v1", "created": "Mon, 25 Nov 2019 21:58:28 GMT"}, {"version": "v2", "created": "Tue, 31 Dec 2019 16:48:41 GMT"}, {"version": "v3", "created": "Sun, 26 Jan 2020 20:00:12 GMT"}, {"version": "v4", "created": "Fri, 1 Jan 2021 23:30:21 GMT"}, {"version": "v5", "created": "Thu, 18 Mar 2021 23:22:01 GMT"}], "update_date": "2021-03-22", "authors_parsed": [["Schlosser", "Tobias", ""], ["Beuth", "Frederik", ""], ["Friedrich", "Michael", ""], ["Kowerko", "Danny", ""]]}, {"id": "1911.11251", "submitter": "Tobias Schlosser", "authors": "Tobias Schlosser, Michael Friedrich, and Danny Kowerko", "title": "Hexagonal Image Processing in the Context of Machine Learning:\n  Conception of a Biologically Inspired Hexagonal Deep Learning Framework", "comments": "Accepted for: 2019 18th IEEE International Conference on Machine\n  Learning and Applications (ICMLA); the latest versions of this contribution\n  cover minor typo corrections", "journal-ref": null, "doi": "10.1109/ICMLA.2019.00300", "report-no": null, "categories": "cs.LG cs.CV eess.IV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Inspired by the human visual perception system, hexagonal image processing in\nthe context of machine learning deals with the development of image processing\nsystems that combine the advantages of evolutionary motivated structures based\non biological models. While conventional state-of-the-art image processing\nsystems of recording and output devices almost exclusively utilize square\narranged methods, their hexagonal counterparts offer a number of key advantages\nthat can benefit both researchers and users. This contribution serves as a\ngeneral application-oriented approach the synthesis of the therefore designed\nhexagonal image processing framework, called Hexnet, the processing steps of\nhexagonal image transformation, and dependent methods. The results of our\ncreated test environment show that the realized framework surpasses current\napproaches of hexagonal image processing systems, while hexagonal artificial\nneural networks can benefit from the implemented hexagonal architecture. As\nhexagonal lattice format based deep neural networks, also called H-DNN, can be\ncompared to their square counterparts by transforming classical square lattice\nbased data sets into their hexagonal representation, they can also result in a\nreduction of trainable parameters as well as result in increased training and\ntest rates.\n", "versions": [{"version": "v1", "created": "Mon, 25 Nov 2019 21:58:31 GMT"}, {"version": "v2", "created": "Tue, 31 Dec 2019 16:48:44 GMT"}, {"version": "v3", "created": "Sun, 26 Jan 2020 20:00:15 GMT"}, {"version": "v4", "created": "Tue, 24 Mar 2020 13:50:32 GMT"}, {"version": "v5", "created": "Wed, 25 Mar 2020 22:59:06 GMT"}, {"version": "v6", "created": "Fri, 1 Jan 2021 23:30:21 GMT"}, {"version": "v7", "created": "Thu, 18 Mar 2021 23:21:56 GMT"}], "update_date": "2021-03-22", "authors_parsed": [["Schlosser", "Tobias", ""], ["Friedrich", "Michael", ""], ["Kowerko", "Danny", ""]]}, {"id": "1911.11253", "submitter": "Cassidy Laidlaw", "authors": "Cassidy Laidlaw and Soheil Feizi", "title": "Playing it Safe: Adversarial Robustness with an Abstain Option", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We explore adversarial robustness in the setting in which it is acceptable\nfor a classifier to abstain---that is, output no class---on adversarial\nexamples. Adversarial examples are small perturbations of normal inputs to a\nclassifier that cause the classifier to give incorrect output; they present\nsecurity and safety challenges for machine learning systems. In many\nsafety-critical applications, it is less costly for a classifier to abstain on\nadversarial examples than to give incorrect output for them. We first introduce\na novel objective function for adversarial robustness with an abstain option\nwhich characterizes an explicit tradeoff between robustness and accuracy. We\nthen present a simple baseline in which an adversarially-trained classifier\nabstains on all inputs within a certain distance of the decision boundary,\nwhich we theoretically and experimentally evaluate. Finally, we propose\nCombined Abstention Robustness Learning (CARL), a method for jointly learning a\nclassifier and the region of the input space on which it should abstain. We\nexplore different variations of the PGD and DeepFool adversarial attacks on\nCARL in the abstain setting. Evaluating against these attacks, we demonstrate\nthat training with CARL results in a more accurate, robust, and efficient\nclassifier than the baseline.\n", "versions": [{"version": "v1", "created": "Mon, 25 Nov 2019 21:59:37 GMT"}], "update_date": "2019-11-27", "authors_parsed": [["Laidlaw", "Cassidy", ""], ["Feizi", "Soheil", ""]]}, {"id": "1911.11255", "submitter": "Rafael Henrique Santos Rocha", "authors": "Ruy Luiz Milidi\\'u and Rafael Henrique Santos Rocha", "title": "Cumulative Sum Ranking", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The goal of Ordinal Regression is to find a rule that ranks items from a\ngiven set. Several learning algorithms to solve this prediction problem build\nan ensemble of binary classifiers. Ranking by Projecting uses interdependent\nbinary perceptrons. These perceptrons share the same direction vector, but use\ndifferent bias values. Similar approaches use independent direction vectors and\nbiases. To combine the binary predictions, most of them adopt a simple counting\nheuristics. Here, we introduce a novel cumulative sum scoring function to\ncombine the binary predictions. The proposed score value aggregates the\nstrength of each one of the relevant binary classifications on how large is the\nitem's rank. We show that our modeling casts ordinal regression as a Structured\nPerceptron problem. As a consequence, we simplify its formulation and\ndescription, which results in two simple online learning algorithms. The second\nalgorithm is a Passive-Aggressive version of the first algorithm. We show that\nunder some rank separability condition both algorithms converge. Furthermore,\nwe provide mistake bounds for each one of the two online algorithms. For the\nPassive-Aggressive version, we assume the knowledge of a separation margin,\nwhat significantly improves the corresponding mistake bound. Additionally, we\nshow that Ranking by Projecting is a special case of our prediction algorithm.\nFrom a neural network architecture point of view, our empirical findings\nsuggest a layer of cusum units for ordinal regression, instead of the usual\nsoftmax layer of multiclass problems.\n", "versions": [{"version": "v1", "created": "Mon, 25 Nov 2019 22:04:19 GMT"}], "update_date": "2019-11-27", "authors_parsed": [["Milidi\u00fa", "Ruy Luiz", ""], ["Rocha", "Rafael Henrique Santos", ""]]}, {"id": "1911.11260", "submitter": "Risto Vuorio", "authors": "John Holler, Risto Vuorio, Zhiwei Qin, Xiaocheng Tang, Yan Jiao,\n  Tiancheng Jin, Satinder Singh, Chenxi Wang and Jieping Ye", "title": "Deep Reinforcement Learning for Multi-Driver Vehicle Dispatching and\n  Repositioning Problem", "comments": "ICDM 2019 Short Paper", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Order dispatching and driver repositioning (also known as fleet management)\nin the face of spatially and temporally varying supply and demand are central\nto a ride-sharing platform marketplace. Hand-crafting heuristic solutions that\naccount for the dynamics in these resource allocation problems is difficult,\nand may be better handled by an end-to-end machine learning method. Previous\nworks have explored machine learning methods to the problem from a high-level\nperspective, where the learning method is responsible for either repositioning\nthe drivers or dispatching orders, and as a further simplification, the drivers\nare considered independent agents maximizing their own reward functions. In\nthis paper we present a deep reinforcement learning approach for tackling the\nfull fleet management and dispatching problems. In addition to treating the\ndrivers as individual agents, we consider the problem from a system-centric\nperspective, where a central fleet management agent is responsible for\ndecision-making for all drivers.\n", "versions": [{"version": "v1", "created": "Mon, 25 Nov 2019 22:28:21 GMT"}], "update_date": "2019-11-27", "authors_parsed": [["Holler", "John", ""], ["Vuorio", "Risto", ""], ["Qin", "Zhiwei", ""], ["Tang", "Xiaocheng", ""], ["Jiao", "Yan", ""], ["Jin", "Tiancheng", ""], ["Singh", "Satinder", ""], ["Wang", "Chenxi", ""], ["Ye", "Jieping", ""]]}, {"id": "1911.11284", "submitter": "Ehsan Aghaei", "authors": "Ehsan Aghaei, Gursel Serpen", "title": "Host-based anomaly detection using Eigentraces feature extraction and\n  one-class classification on system call trace data", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper proposes a methodology for host-based anomaly detection using a\nsemi-supervised algorithm namely one-class classifier combined with a PCA-based\nfeature extraction technique called Eigentraces on system call trace data. The\none-class classification is based on generating a set of artificial data using\na reference distribution and combining the target class probability function\nwith artificial class density function to estimate the target class density\nfunction through the Bayes formulation. The benchmark dataset, ADFA-LD, is\nemployed for the simulation study. ADFA-LD dataset contains thousands of system\ncall traces collected during various normal and attack processes for the Linux\noperating system environment. In order to pre-process and to extract features,\nwindowing on the system call trace data followed by the principal component\nanalysis which is named as Eigentraces is implemented. The target class\nprobability function is modeled separately by Radial Basis Function neural\nnetwork and Random Forest machine learners for performance comparison purposes.\nThe simulation study showed that the proposed intrusion detection system offers\nhigh performance for detecting anomalies and normal activities with respect to\na set of well-accepted metrics including detection rate, accuracy, and missed\nand false alarm rates.\n", "versions": [{"version": "v1", "created": "Mon, 25 Nov 2019 23:55:00 GMT"}], "update_date": "2019-11-27", "authors_parsed": [["Aghaei", "Ehsan", ""], ["Serpen", "Gursel", ""]]}, {"id": "1911.11285", "submitter": "Pierre Richemond", "authors": "Pierre H. Richemond, Arinbj\\\"orn Kolbeinsson, Yike Guo", "title": "Biologically inspired architectures for sample-efficient deep\n  reinforcement learning", "comments": "Deep Reinforcement Learning Workshop, NeurIPS 2019, Vancouver, Canada", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep reinforcement learning requires a heavy price in terms of sample\nefficiency and overparameterization in the neural networks used for function\napproximation. In this work, we use tensor factorization in order to learn more\ncompact representation for reinforcement learning policies. We show empirically\nthat in the low-data regime, it is possible to learn online policies with 2 to\n10 times less total coefficients, with little to no loss of performance. We\nalso leverage progress in second order optimization, and use the theory of\nwavelet scattering to further reduce the number of learned coefficients, by\nforegoing learning the topmost convolutional layer filters altogether. We\nevaluate our results on the Atari suite against recent baseline algorithms that\nrepresent the state-of-the-art in data efficiency, and get comparable results\nwith an order of magnitude gain in weight parsimony.\n", "versions": [{"version": "v1", "created": "Mon, 25 Nov 2019 23:59:22 GMT"}], "update_date": "2019-11-27", "authors_parsed": [["Richemond", "Pierre H.", ""], ["Kolbeinsson", "Arinbj\u00f6rn", ""], ["Guo", "Yike", ""]]}, {"id": "1911.11293", "submitter": "Terrell Mundhenk", "authors": "T. Nathan Mundhenk and Barry Y. Chen and Gerald Friedland", "title": "Efficient Saliency Maps for Explainable AI", "comments": "In submission to ECCV 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG cs.PF cs.RO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We describe an explainable AI saliency map method for use with deep\nconvolutional neural networks (CNN) that is much more efficient than popular\nfine-resolution gradient methods. It is also quantitatively similar or better\nin accuracy. Our technique works by measuring information at the end of each\nnetwork scale which is then combined into a single saliency map. We describe\nhow saliency measures can be made more efficient by exploiting Saliency Map\nOrder Equivalence. We visualize individual scale/layer contributions by using a\nLayer Ordered Visualization of Information. This provides an interesting\ncomparison of scale information contributions within the network not provided\nby other saliency map methods. Using our method instead of Guided Backprop,\ncoarse-resolution class activation methods such as Grad-CAM and Grad-CAM++ seem\nto yield demonstrably superior results without sacrificing speed. This will\nmake fine-resolution saliency methods feasible on resource limited platforms\nsuch as robots, cell phones, low-cost industrial devices, astronomy and\nsatellite imagery.\n", "versions": [{"version": "v1", "created": "Tue, 26 Nov 2019 00:32:23 GMT"}, {"version": "v2", "created": "Mon, 9 Mar 2020 21:20:06 GMT"}], "update_date": "2020-03-11", "authors_parsed": [["Mundhenk", "T. Nathan", ""], ["Chen", "Barry Y.", ""], ["Friedland", "Gerald", ""]]}, {"id": "1911.11298", "submitter": "Chuxu Zhang", "authors": "Chuxu Zhang, Huaxiu Yao, Chao Huang, Meng Jiang, Zhenhui Li, Nitesh V.\n  Chawla", "title": "Few-Shot Knowledge Graph Completion", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Knowledge graphs (KGs) serve as useful resources for various natural language\nprocessing applications. Previous KG completion approaches require a large\nnumber of training instances (i.e., head-tail entity pairs) for every relation.\nThe real case is that for most of the relations, very few entity pairs are\navailable. Existing work of one-shot learning limits method generalizability\nfor few-shot scenarios and does not fully use the supervisory information;\nhowever, few-shot KG completion has not been well studied yet. In this work, we\npropose a novel few-shot relation learning model (FSRL) that aims at\ndiscovering facts of new relations with few-shot references. FSRL can\neffectively capture knowledge from heterogeneous graph structure, aggregate\nrepresentations of few-shot references, and match similar entity pairs of\nreference set for every relation. Extensive experiments on two public datasets\ndemonstrate that FSRL outperforms the state-of-the-art.\n", "versions": [{"version": "v1", "created": "Tue, 26 Nov 2019 01:01:37 GMT"}], "update_date": "2019-11-27", "authors_parsed": [["Zhang", "Chuxu", ""], ["Yao", "Huaxiu", ""], ["Huang", "Chao", ""], ["Jiang", "Meng", ""], ["Li", "Zhenhui", ""], ["Chawla", "Nitesh V.", ""]]}, {"id": "1911.11308", "submitter": "Runzhong Wang", "authors": "Runzhong Wang, Junchi Yan and Xiaokang Yang", "title": "Neural Graph Matching Network: Learning Lawler's Quadratic Assignment\n  Problem with Extension to Hypergraph and Multiple-graph Matching", "comments": "Accepted by TPAMI", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Graph matching involves combinatorial optimization based on edge-to-edge\naffinity matrix, which can be generally formulated as Lawler's Quadratic\nAssignment Problem (QAP). This paper presents a QAP network directly learning\nwith the affinity matrix (equivalently the association graph) whereby the\nmatching problem is translated into a constrained vertex classification task.\nThe association graph is learned by an embedding network for vertex\nclassification, followed by Sinkhorn normalization and a cross-entropy loss for\nend-to-end learning. We further improve the embedding model on association\ngraph by introducing Sinkhorn based matching-aware constraint, as well as dummy\nnodes to deal with unequal sizes of graphs. To our best knowledge, this is one\nof the first network to directly learn with the general Lawler's QAP. In\ncontrast, recent deep matching methods focus on the learning of node/edge\nfeatures in two graphs respectively. We also show how to extend our network to\nhypergraph matching, and matching of multiple graphs. Experimental results on\nboth synthetic graphs and real-world images show its effectiveness. For pure\nQAP tasks on synthetic data and QAPLIB benchmark, our method can perform\ncompetitively and even surpass state-of-the-art graph matching and QAP solvers\nwith notable less time cost. We provide a project homepage at\nhttp://thinklab.sjtu.edu.cn/project/NGM/index.html.\n", "versions": [{"version": "v1", "created": "Tue, 26 Nov 2019 02:06:57 GMT"}, {"version": "v2", "created": "Wed, 25 Mar 2020 17:16:22 GMT"}, {"version": "v3", "created": "Thu, 6 May 2021 17:18:34 GMT"}], "update_date": "2021-05-07", "authors_parsed": [["Wang", "Runzhong", ""], ["Yan", "Junchi", ""], ["Yang", "Xiaokang", ""]]}, {"id": "1911.11322", "submitter": "Han Shi", "authors": "Han Shi, Haozheng Fan, James T. Kwok", "title": "Effective Decoding in Graph Auto-Encoder using Triadic Closure", "comments": "Accepted by AAAI 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The (variational) graph auto-encoder and its variants have been popularly\nused for representation learning on graph-structured data. While the encoder is\noften a powerful graph convolutional network, the decoder reconstructs the\ngraph structure by only considering two nodes at a time, thus ignoring possible\ninteractions among edges. On the other hand, structured prediction, which\nconsiders the whole graph simultaneously, is computationally expensive. In this\npaper, we utilize the well-known triadic closure property which is exhibited in\nmany real-world networks. We propose the triad decoder, which considers and\npredicts the three edges involved in a local triad together. The triad decoder\ncan be readily used in any graph-based auto-encoder. In particular, we\nincorporate this to the (variational) graph auto-encoder. Experiments on link\nprediction, node clustering and graph generation show that the use of triads\nleads to more accurate prediction, clustering and better preservation of the\ngraph characteristics.\n", "versions": [{"version": "v1", "created": "Tue, 26 Nov 2019 03:56:33 GMT"}], "update_date": "2019-11-27", "authors_parsed": [["Shi", "Han", ""], ["Fan", "Haozheng", ""], ["Kwok", "James T.", ""]]}, {"id": "1911.11337", "submitter": "Xiaojin Zhang", "authors": "Xiaojin Zhang, Shuai Li, Weiwen Liu", "title": "Contextual Combinatorial Conservative Bandits", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The problem of multi-armed bandits (MAB) asks to make sequential decisions\nwhile balancing between exploitation and exploration, and have been\nsuccessfully applied to a wide range of practical scenarios. Various algorithms\nhave been designed to achieve a high reward in a long term. However, its\nshort-term performance might be rather low, which is injurious in risk\nsensitive applications. Building on previous work of conservative bandits, we\nbring up a framework of contextual combinatorial conservative bandits. An\nalgorithm is presented and a regret bound of $\\tilde O(d^2+d\\sqrt{T})$ is\nproven, where $d$ is the dimension of the feature vectors, and $T$ is the total\nnumber of time steps. We further provide an algorithm as well as regret\nanalysis for the case when the conservative reward is unknown. Experiments are\nconducted, and the results validate the effectiveness of our algorithm.\n", "versions": [{"version": "v1", "created": "Tue, 26 Nov 2019 04:42:53 GMT"}], "update_date": "2019-11-27", "authors_parsed": [["Zhang", "Xiaojin", ""], ["Li", "Shuai", ""], ["Liu", "Weiwen", ""]]}, {"id": "1911.11343", "submitter": "Alireza Shamsoshoara", "authors": "Alireza Shamsoshoara, Fatemeh Afghah, Abolfazl Razi, Sajad Mousavi,\n  Jonathan Ashdown, Kurt Turk", "title": "An Autonomous Spectrum Management Scheme for Unmanned Aerial Vehicle\n  Networks in Disaster Relief Operations", "comments": "14 pages, 14 figures, 1 table", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.NI eess.SP stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper studies the problem of spectrum shortage in an unmanned aerial\nvehicle (UAV) network during critical missions such as wildfire monitoring,\nsearch and rescue, and disaster monitoring. Such applications involve a high\ndemand for high-throughput data transmissions such as real-time video-, image-,\nand voice- streaming where the assigned spectrum to the UAV network may not be\nadequate to provide the desired Quality of Service (QoS). In these scenarios,\nthe aerial network can borrow an additional spectrum from the available\nterrestrial networks in the trade of a relaying service for them. We propose a\nspectrum sharing model in which the UAVs are grouped into two classes of\nrelaying UAVs that service the spectrum owner and the sensing UAVs that perform\nthe disaster relief mission using the obtained spectrum. The operation of the\nUAV network is managed by a hierarchical mechanism in which a central\ncontroller assigns the tasks of the UAVs based on their resources and determine\ntheir operation region based on the level of priority of impacted areas and\nthen the UAVs autonomously fine-tune their position using a model-free\nreinforcement learning algorithm to maximize the individual throughput and\nprolong their lifetime. We analyze the performance and the convergence for the\nproposed method analytically and with extensive simulations in different\nscenarios.\n", "versions": [{"version": "v1", "created": "Tue, 26 Nov 2019 05:09:39 GMT"}], "update_date": "2019-11-27", "authors_parsed": [["Shamsoshoara", "Alireza", ""], ["Afghah", "Fatemeh", ""], ["Razi", "Abolfazl", ""], ["Mousavi", "Sajad", ""], ["Ashdown", "Jonathan", ""], ["Turk", "Kurt", ""]]}, {"id": "1911.11357", "submitter": "Samaneh Azadi", "authors": "Samaneh Azadi, Michael Tschannen, Eric Tzeng, Sylvain Gelly, Trevor\n  Darrell, Mario Lucic", "title": "Semantic Bottleneck Scene Generation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Coupling the high-fidelity generation capabilities of label-conditional image\nsynthesis methods with the flexibility of unconditional generative models, we\npropose a semantic bottleneck GAN model for unconditional synthesis of complex\nscenes. We assume pixel-wise segmentation labels are available during training\nand use them to learn the scene structure. During inference, our model first\nsynthesizes a realistic segmentation layout from scratch, then synthesizes a\nrealistic scene conditioned on that layout. For the former, we use an\nunconditional progressive segmentation generation network that captures the\ndistribution of realistic semantic scene layouts. For the latter, we use a\nconditional segmentation-to-image synthesis network that captures the\ndistribution of photo-realistic images conditioned on the semantic layout. When\ntrained end-to-end, the resulting model outperforms state-of-the-art generative\nmodels in unsupervised image synthesis on two challenging domains in terms of\nthe Frechet Inception Distance and user-study evaluations. Moreover, we\ndemonstrate the generated segmentation maps can be used as additional training\ndata to strongly improve recent segmentation-to-image synthesis networks.\n", "versions": [{"version": "v1", "created": "Tue, 26 Nov 2019 06:01:09 GMT"}], "update_date": "2019-11-27", "authors_parsed": [["Azadi", "Samaneh", ""], ["Tschannen", "Michael", ""], ["Tzeng", "Eric", ""], ["Gelly", "Sylvain", ""], ["Darrell", "Trevor", ""], ["Lucic", "Mario", ""]]}, {"id": "1911.11358", "submitter": "Saurav Manchanda", "authors": "Saurav Manchanda and George Karypis", "title": "CAWA: An Attention-Network for Credit Attribution", "comments": "To appear in AAAI 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.IR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Credit attribution is the task of associating individual parts in a document\nwith their most appropriate class labels. It is an important task with\napplications to information retrieval and text summarization. When labeled\ntraining data is available, traditional approaches for sequence tagging can be\nused for credit attribution. However, generating such labeled datasets is\nexpensive and time-consuming. In this paper, we present \"Credit Attribution\nWith Attention (CAWA)\", a neural-network-based approach, that instead of using\nsentence-level labeled data, uses the set of class labels that are associated\nwith an entire document as a source of distant-supervision. CAWA combines an\nattention mechanism with a multilabel classifier into an end-to-end learning\nframework to perform credit attribution. CAWA labels the individual sentences\nfrom the input document using the resultant attention-weights. CAWA improves\nupon the state-of-the-art credit attribution approach by not constraining a\nsentence to belong to just one class, but modeling each sentence as a\ndistribution over all classes, leading to better modeling of\nsemantically-similar classes. Experiments on the credit attribution task on a\nvariety of datasets show that the sentence class labels generated by CAWA\noutperform the competing approaches. Additionally, on the multilabel text\nclassification task, CAWA performs better than the competing credit attribution\napproaches.\n", "versions": [{"version": "v1", "created": "Tue, 26 Nov 2019 06:02:33 GMT"}], "update_date": "2019-11-27", "authors_parsed": [["Manchanda", "Saurav", ""], ["Karypis", "George", ""]]}, {"id": "1911.11361", "submitter": "Yifan Wu", "authors": "Yifan Wu, George Tucker, Ofir Nachum", "title": "Behavior Regularized Offline Reinforcement Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In reinforcement learning (RL) research, it is common to assume access to\ndirect online interactions with the environment. However in many real-world\napplications, access to the environment is limited to a fixed offline dataset\nof logged experience. In such settings, standard RL algorithms have been shown\nto diverge or otherwise yield poor performance. Accordingly, recent work has\nsuggested a number of remedies to these issues. In this work, we introduce a\ngeneral framework, behavior regularized actor critic (BRAC), to empirically\nevaluate recently proposed methods as well as a number of simple baselines\nacross a variety of offline continuous control tasks. Surprisingly, we find\nthat many of the technical complexities introduced in recent methods are\nunnecessary to achieve strong performance. Additional ablations provide\ninsights into which design choices matter most in the offline RL setting.\n", "versions": [{"version": "v1", "created": "Tue, 26 Nov 2019 06:11:34 GMT"}], "update_date": "2019-11-27", "authors_parsed": [["Wu", "Yifan", ""], ["Tucker", "George", ""], ["Nachum", "Ofir", ""]]}, {"id": "1911.11363", "submitter": "Da Yu", "authors": "Da Yu, Huishuai Zhang, Wei Chen, Tie-Yan Liu, Jian Yin", "title": "Gradient Perturbation is Underrated for Differentially Private Convex\n  Optimization", "comments": "International Joint Conference on Artificial Intelligence (IJCAI)\n  2020; 7 pages, 2 figures, and 4 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Gradient perturbation, widely used for differentially private optimization,\ninjects noise at every iterative update to guarantee differential privacy.\nPrevious work first determines the noise level that can satisfy the privacy\nrequirement and then analyzes the utility of noisy gradient updates as in the\nnon-private case. In contrast, we explore how privacy noise affects\noptimization property. We show that for differentially private convex\noptimization, the utility guarantee of differentially private (stochastic)\ngradient descent is determined by an \\emph{expected curvature} rather than the\nminimum curvature. The \\emph{expected curvature}, which represents the average\ncurvature over the optimization path, is usually much larger than the minimum\ncurvature. By using the \\emph{expected curvature}, we show that gradient\nperturbation can achieve a significantly improved utility guarantee that can\ntheoretically justify the advantage of gradient perturbation over other\nperturbation methods. Finally, our extensive experiments suggest that gradient\nperturbation with the advanced composition method indeed outperforms other\nperturbation approaches by a large margin, matching our theoretical findings.\n", "versions": [{"version": "v1", "created": "Tue, 26 Nov 2019 06:18:02 GMT"}, {"version": "v2", "created": "Mon, 26 Oct 2020 09:44:57 GMT"}], "update_date": "2020-10-27", "authors_parsed": [["Yu", "Da", ""], ["Zhang", "Huishuai", ""], ["Chen", "Wei", ""], ["Liu", "Tie-Yan", ""], ["Yin", "Jian", ""]]}, {"id": "1911.11374", "submitter": "Jianwen Xie", "authors": "Jianwen Xie, Ruiqi Gao, Erik Nijkamp, Song-Chun Zhu, Ying Nian Wu", "title": "Representation Learning: A Statistical Perspective", "comments": null, "journal-ref": "Annual Review of Statistics and Its Application 2020", "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Learning representations of data is an important problem in statistics and\nmachine learning. While the origin of learning representations can be traced\nback to factor analysis and multidimensional scaling in statistics, it has\nbecome a central theme in deep learning with important applications in computer\nvision and computational neuroscience. In this article, we review recent\nadvances in learning representations from a statistical perspective. In\nparticular, we review the following two themes: (a) unsupervised learning of\nvector representations and (b) learning of both vector and matrix\nrepresentations.\n", "versions": [{"version": "v1", "created": "Tue, 26 Nov 2019 07:21:34 GMT"}], "update_date": "2019-11-27", "authors_parsed": [["Xie", "Jianwen", ""], ["Gao", "Ruiqi", ""], ["Nijkamp", "Erik", ""], ["Zhu", "Song-Chun", ""], ["Wu", "Ying Nian", ""]]}, {"id": "1911.11377", "submitter": "Robert Podschwadt", "authors": "Daniel Takabi, Robert Podschwadt, Jeff Druce, Curt Wu, Kevin Procopio", "title": "Privacy preserving Neural Network Inference on Encrypted Data with GPUs", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.CY cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Machine Learning as a Service (MLaaS) has become a growing trend in recent\nyears and several such services are currently offered. MLaaS is essentially a\nset of services that provides machine learning tools and capabilities as part\nof cloud computing services. In these settings, the cloud has pre-trained\nmodels that are deployed and large computing capacity whereas the clients can\nuse these models to make predictions without having to worry about maintaining\nthe models and the service. However, the main concern with MLaaS is the privacy\nof the client's data.\n  Although there have been several proposed approaches in the literature to run\nmachine learning models on encrypted data, the performance is still far from\nbeing satisfactory for practical use. In this paper, we aim to accelerate the\nperformance of running machine learning on encrypted data using combination of\nFully Homomorphic Encryption (FHE), Convolutional Neural Networks (CNNs) and\nGraphics Processing Units (GPUs). We use a number of optimization techniques,\nand efficient GPU-based implementation to achieve high performance. We evaluate\na CNN whose architecture is similar to AlexNet to classify homomorphically\nencrypted samples from the Cars Overhead With Context (COWC) dataset. To the\nbest of our knowledge, it is the first time such a complex network and large\ndataset is evaluated on encrypted data. Our approach achieved reasonable\nclassification accuracy of 95% for the COWC dataset. In terms of performance,\nour results show that we could achieve several thousands times speed up when we\nimplement GPU-accelerated FHE operations on encrypted floating point numbers.\n", "versions": [{"version": "v1", "created": "Tue, 26 Nov 2019 07:36:38 GMT"}], "update_date": "2019-11-27", "authors_parsed": [["Takabi", "Daniel", ""], ["Podschwadt", "Robert", ""], ["Druce", "Jeff", ""], ["Wu", "Curt", ""], ["Procopio", "Kevin", ""]]}, {"id": "1911.11378", "submitter": "Manraj Singh Grover", "authors": "Osaid Rehman Nasir, Shailesh Kumar Jha, Manraj Singh Grover, Yi Yu,\n  Ajit Kumar, Rajiv Ratn Shah", "title": "Text2FaceGAN: Face Generation from Fine Grained Textual Descriptions", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV cs.MM eess.IV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Powerful generative adversarial networks (GAN) have been developed to\nautomatically synthesize realistic images from text. However, most existing\ntasks are limited to generating simple images such as flowers from captions. In\nthis work, we extend this problem to the less addressed domain of face\ngeneration from fine-grained textual descriptions of face, e.g., \"A person has\ncurly hair, oval face, and mustache\". We are motivated by the potential of\nautomated face generation to impact and assist critical tasks such as criminal\nface reconstruction. Since current datasets for the task are either very small\nor do not contain captions, we generate captions for images in the CelebA\ndataset by creating an algorithm to automatically convert a list of attributes\nto a set of captions. We then model the highly multi-modal problem of text to\nface generation as learning the conditional distribution of faces (conditioned\non text) in same latent space. We utilize the current state-of-the-art GAN\n(DC-GAN with GAN-CLS loss) for learning conditional multi-modality. The\npresence of more fine-grained details and variable length of the captions makes\nthe problem easier for a user but more difficult to handle compared to the\nother text-to-image tasks. We flipped the labels for real and fake images and\nadded noise in discriminator. Generated images for diverse textual descriptions\nshow promising results. In the end, we show how the widely used inceptions\nscore is not a good metric to evaluate the performance of generative models\nused for synthesizing faces from text.\n", "versions": [{"version": "v1", "created": "Tue, 26 Nov 2019 07:37:47 GMT"}], "update_date": "2019-11-27", "authors_parsed": [["Nasir", "Osaid Rehman", ""], ["Jha", "Shailesh Kumar", ""], ["Grover", "Manraj Singh", ""], ["Yu", "Yi", ""], ["Kumar", "Ajit", ""], ["Shah", "Rajiv Ratn", ""]]}, {"id": "1911.11380", "submitter": "Mathis Bode", "authors": "Mathis Bode, Michael Gauding, Zeyu Lian, Dominik Denker, Marco\n  Davidovic, Konstantin Kleinheinz, Jenia Jitsev, Heinz Pitsch", "title": "Using Physics-Informed Super-Resolution Generative Adversarial Networks\n  for Subgrid Modeling in Turbulent Reactive Flows", "comments": "Submitted to Combustion Symposium 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.GR physics.comp-ph physics.flu-dyn stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Turbulence is still one of the main challenges for accurately predicting\nreactive flows. Therefore, the development of new turbulence closures which can\nbe applied to combustion problems is essential. Data-driven modeling has become\nvery popular in many fields over the last years as large, often extensively\nlabeled, datasets became available and training of large neural networks became\npossible on GPUs speeding up the learning process tremendously. However, the\nsuccessful application of deep neural networks in fluid dynamics, for example\nfor subgrid modeling in the context of large-eddy simulations (LESs), is still\nchallenging. Reasons for this are the large amount of degrees of freedom in\nrealistic flows, the high requirements with respect to accuracy and error\nrobustness, as well as open questions, such as the generalization capability of\ntrained neural networks in such high-dimensional, physics-constrained\nscenarios. This work presents a novel subgrid modeling approach based on a\ngenerative adversarial network (GAN), which is trained with unsupervised deep\nlearning (DL) using adversarial and physics-informed losses. A two-step\ntraining method is used to improve the generalization capability, especially\nextrapolation, of the network. The novel approach gives good results in a\npriori as well as a posteriori tests with decaying turbulence including\nturbulent mixing. The applicability of the network in complex combustion\nscenarios is furthermore discussed by employing it to a reactive LES of the\nSpray A case defined by the Engine Combustion Network (ECN).\n", "versions": [{"version": "v1", "created": "Tue, 26 Nov 2019 07:40:38 GMT"}], "update_date": "2019-11-27", "authors_parsed": [["Bode", "Mathis", ""], ["Gauding", "Michael", ""], ["Lian", "Zeyu", ""], ["Denker", "Dominik", ""], ["Davidovic", "Marco", ""], ["Kleinheinz", "Konstantin", ""], ["Jitsev", "Jenia", ""], ["Pitsch", "Heinz", ""]]}, {"id": "1911.11396", "submitter": "Guoxian Yu", "authors": "Shaowei Wei, Jun Wang, Guoxian Yu, Carlotta, Xiangliang Zhang", "title": "Multi-View Multiple Clusterings using Deep Matrix Factorization", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Multi-view clustering aims at integrating complementary information from\nmultiple heterogeneous views to improve clustering results. Existing multi-view\nclustering solutions can only output a single clustering of the data. Due to\ntheir multiplicity, multi-view data, can have different groupings that are\nreasonable and interesting from different perspectives. However, how to find\nmultiple, meaningful, and diverse clustering results from multi-view data is\nstill a rarely studied and challenging topic in multi-view clustering and\nmultiple clusterings. In this paper, we introduce a deep matrix factorization\nbased solution (DMClusts) to discover multiple clusterings. DMClusts gradually\nfactorizes multi-view data matrices into representational subspaces\nlayer-by-layer and generates one clustering in each layer. To enforce the\ndiversity between generated clusterings, it minimizes a new redundancy\nquantification term derived from the proximity between samples in these\nsubspaces. We further introduce an iterative optimization procedure to\nsimultaneously seek multiple clusterings with quality and diversity.\nExperimental results on benchmark datasets confirm that DMClusts outperforms\nstate-of-the-art multiple clustering solutions.\n", "versions": [{"version": "v1", "created": "Tue, 26 Nov 2019 08:31:09 GMT"}], "update_date": "2019-11-27", "authors_parsed": [["Wei", "Shaowei", ""], ["Wang", "Jun", ""], ["Yu", "Guoxian", ""], ["Carlotta", "", ""], ["Zhang", "Xiangliang", ""]]}, {"id": "1911.11397", "submitter": "Jingliang Duan", "authors": "Jingliang Duan, Zhengyu Liu, Shengbo Eben Li, Qi Sun, Zhenzhong Jia,\n  and Bo Cheng", "title": "Deep adaptive dynamic programming for nonaffine nonlinear optimal\n  control problem with state constraints", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.SY cs.LG cs.SY math.OC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper presents a constrained deep adaptive dynamic programming (CDADP)\nalgorithm to solve general nonlinear optimal control problems with known\ndynamics. Unlike previous ADP algorithms, it can directly deal with problems\nwith state constraints. Both the policy and value function are approximated by\ndeep neural networks (NNs), which directly map the system state to action and\nvalue function respectively without needing to use hand-crafted basis function.\nThe proposed algorithm considers the state constraints by transforming the\npolicy improvement process to a constrained optimization problem. Meanwhile, a\ntrust region constraint is added to prevent excessive policy update. We first\nlinearize this constrained optimization problem locally into a\nquadratically-constrained quadratic programming problem, and then obtain the\noptimal update of policy network parameters by solving its dual problem. We\nalso propose a series of recovery rules to update the policy in case the primal\nproblem is infeasible. In addition, parallel learners are employed to explore\ndifferent state spaces and then stabilize and accelerate the learning speed.\nThe vehicle control problem in path-tracking task is used to demonstrate the\neffectiveness of this proposed method.\n", "versions": [{"version": "v1", "created": "Tue, 26 Nov 2019 08:32:31 GMT"}, {"version": "v2", "created": "Tue, 8 Sep 2020 13:15:29 GMT"}], "update_date": "2020-09-09", "authors_parsed": [["Duan", "Jingliang", ""], ["Liu", "Zhengyu", ""], ["Li", "Shengbo Eben", ""], ["Sun", "Qi", ""], ["Jia", "Zhenzhong", ""], ["Cheng", "Bo", ""]]}, {"id": "1911.11430", "submitter": "Yanbei Liu", "authors": "Yanbei Liu, Xiao Wang, Shu Wu and Zhitao Xiao", "title": "Independence Promoted Graph Disentangled Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We address the problem of disentangled representation learning with\nindependent latent factors in graph convolutional networks (GCNs). The current\nmethods usually learn node representation by describing its neighborhood as a\nperceptual whole in a holistic manner while ignoring the entanglement of the\nlatent factors. However, a real-world graph is formed by the complex\ninteraction of many latent factors (e.g., the same hobby, education or work in\nsocial network). While little effort has been made toward exploring the\ndisentangled representation in GCNs. In this paper, we propose a novel\nIndependence Promoted Graph Disentangled Networks (IPGDN) to learn disentangled\nnode representation while enhancing the independence among node\nrepresentations. In particular, we firstly present disentangled representation\nlearning by neighborhood routing mechanism, and then employ the Hilbert-Schmidt\nIndependence Criterion (HSIC) to enforce independence between the latent\nrepresentations, which is effectively integrated into a graph convolutional\nframework as a regularizer at the output layer. Experimental studies on\nreal-world graphs validate our model and demonstrate that our algorithms\noutperform the state-of-the-arts by a wide margin in different network\napplications, including semi-supervised graph classification, graph clustering\nand graph visualization.\n", "versions": [{"version": "v1", "created": "Tue, 26 Nov 2019 10:01:15 GMT"}], "update_date": "2019-11-27", "authors_parsed": [["Liu", "Yanbei", ""], ["Wang", "Xiao", ""], ["Wu", "Shu", ""], ["Xiao", "Zhitao", ""]]}, {"id": "1911.11431", "submitter": "Alma Eguizabal", "authors": "Alma Eguizabal, Peter J. Schreier, J\\\"urgen Schmidt", "title": "Procrustes registration of two-dimensional statistical shape models\n  without correspondences", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Statistical shape models are a useful tool in image processing and computer\nvision. A Procrustres registration of the contours of the same shape is\ntypically perform to align the training samples to learn the statistical shape\nmodel. A Procrustes registration between two contours with known\ncorrespondences is straightforward. However, these correspondences are not\ngenerally available. Manually placed landmarks are often used for\ncorrespondence in the design of statistical shape models. However, determining\nmanual landmarks on the contours is time-consuming and often error-prone. One\nsolution to simultaneously find correspondence and registration is the\nIterative Closest Point (ICP) algorithm. However, ICP requires an initial\nposition of the contours that is close to registration, and it is not robust\nagainst outliers. We propose a new strategy, based on Dynamic Time Warping,\nthat efficiently solves the Procrustes registration problem without\ncorrespondences. We study the registration performance in a collection of\ndifferent shape data sets and show that our technique outperforms competing\ntechniques based on the ICP approach. Our strategy is applied to an ensemble of\ncontours of the same shape as an extension of the generalized Procrustes\nanalysis accounting for a lack of correspondence.\n", "versions": [{"version": "v1", "created": "Tue, 26 Nov 2019 10:01:28 GMT"}, {"version": "v2", "created": "Wed, 27 Nov 2019 09:47:38 GMT"}], "update_date": "2019-11-28", "authors_parsed": [["Eguizabal", "Alma", ""], ["Schreier", "Peter J.", ""], ["Schmidt", "J\u00fcrgen", ""]]}, {"id": "1911.11433", "submitter": "Anush Sankaran", "authors": "Ameya Prabhu, Riddhiman Dasgupta, Anush Sankaran, Srikanth\n  Tamilselvam, Senthil Mani", "title": "\"You might also like this model\": Data Driven Approach for Recommending\n  Deep Learning Models for Unknown Image Datasets", "comments": "NeurIPS 2019, New in ML Group", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV cs.IR eess.IV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  For an unknown (new) classification dataset, choosing an appropriate deep\nlearning architecture is often a recursive, time-taking, and laborious process.\nIn this research, we propose a novel technique to recommend a suitable\narchitecture from a repository of known models. Further, we predict the\nperformance accuracy of the recommended architecture on the given unknown\ndataset, without the need for training the model. We propose a model encoder\napproach to learn a fixed length representation of deep learning architectures\nalong with its hyperparameters, in an unsupervised fashion. We manually curate\na repository of image datasets with corresponding known deep learning models\nand show that the predicted accuracy is a good estimator of the actual\naccuracy. We discuss the implications of the proposed approach for three\nbenchmark images datasets and also the challenges in using the approach for\ntext modality. To further increase the reproducibility of the proposed\napproach, the entire implementation is made publicly available along with the\ntrained models.\n", "versions": [{"version": "v1", "created": "Tue, 26 Nov 2019 10:01:35 GMT"}, {"version": "v2", "created": "Wed, 20 May 2020 20:45:57 GMT"}], "update_date": "2020-05-22", "authors_parsed": [["Prabhu", "Ameya", ""], ["Dasgupta", "Riddhiman", ""], ["Sankaran", "Anush", ""], ["Tamilselvam", "Srikanth", ""], ["Mani", "Senthil", ""]]}, {"id": "1911.11444", "submitter": "Fabrizia Auletta", "authors": "Francesco De Lellis, Fabrizia Auletta, Giovanni Russo, Mario di\n  Bernardo", "title": "Control-Tutored Reinforcement Learning: an application to the Herding\n  Problem", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this extended abstract we introduce a novel control-tutored Q-learning\napproach (CTQL) as part of the ongoing effort in developing model-based and\nsafe RL for continuous state spaces. We validate our approach by applying it to\na challenging multi-agent herding control problem.\n", "versions": [{"version": "v1", "created": "Tue, 26 Nov 2019 10:40:30 GMT"}, {"version": "v2", "created": "Wed, 27 Nov 2019 11:16:25 GMT"}], "update_date": "2019-11-28", "authors_parsed": [["De Lellis", "Francesco", ""], ["Auletta", "Fabrizia", ""], ["Russo", "Giovanni", ""], ["di Bernardo", "Mario", ""]]}, {"id": "1911.11451", "submitter": "Carola Doerr", "authors": "Benjamin Doerr, Carola Doerr, Aneta Neumann, Frank Neumann, Andrew M.\n  Sutton", "title": "Optimization of Chance-Constrained Submodular Functions", "comments": "Accepted for oral presentation at AAAI 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG math.OC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Submodular optimization plays a key role in many real-world problems. In many\nreal-world scenarios, it is also necessary to handle uncertainty, and\npotentially disruptive events that violate constraints in stochastic settings\nneed to be avoided. In this paper, we investigate submodular optimization\nproblems with chance constraints. We provide a first analysis on the\napproximation behavior of popular greedy algorithms for submodular problems\nwith chance constraints. Our results show that these algorithms are highly\neffective when using surrogate functions that estimate constraint violations\nbased on Chernoff bounds. Furthermore, we investigate the behavior of the\nalgorithms on popular social network problems and show that high quality\nsolutions can still be obtained even if there are strong restrictions imposed\nby the chance constraint.\n", "versions": [{"version": "v1", "created": "Tue, 26 Nov 2019 10:59:02 GMT"}], "update_date": "2019-11-27", "authors_parsed": [["Doerr", "Benjamin", ""], ["Doerr", "Carola", ""], ["Neumann", "Aneta", ""], ["Neumann", "Frank", ""], ["Sutton", "Andrew M.", ""]]}, {"id": "1911.11455", "submitter": "Shubham Gupta", "authors": "Tony Gracious, Shubham Gupta, Arun Kanthali, Rui M. Castro, Ambedkar\n  Dukkipati", "title": "Neural Latent Space Model for Dynamic Networks and Temporal Knowledge\n  Graphs", "comments": "Accepted at AAAI-21", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Although static networks have been extensively studied in machine learning,\ndata mining, and AI communities for many decades, the study of dynamic networks\nhas recently taken center stage due to the prominence of social media and its\neffects on the dynamics of social networks. In this paper, we propose a\nstatistical model for dynamically evolving networks, together with a\nvariational inference approach. Our model, Neural Latent Space Model with\nVariational Inference, encodes edge dependencies across different time\nsnapshots. It represents nodes via latent vectors and uses interaction matrices\nto model the presence of edges. These matrices can be used to incorporate\nmultiple relations in heterogeneous networks by having a separate matrix for\neach of the relations. To capture the temporal dynamics, both node vectors and\ninteraction matrices are allowed to evolve with time. Existing network analysis\nmethods use representation learning techniques for modelling networks. These\ntechniques are different for homogeneous and heterogeneous networks because\nheterogeneous networks can have multiple types of edges and nodes as opposed to\na homogeneous network. Unlike these, we propose a unified model for homogeneous\nand heterogeneous networks in a variational inference framework. Moreover, the\nlearned node latent vectors and interaction matrices may be interpretable and\ntherefore provide insights on the mechanisms behind network evolution. We\nexperimented with a single step and multi-step link forecasting on real-world\nnetworks of homogeneous, bipartite, and heterogeneous nature, and demonstrated\nthat our model significantly outperforms existing models.\n", "versions": [{"version": "v1", "created": "Tue, 26 Nov 2019 11:13:51 GMT"}, {"version": "v2", "created": "Fri, 18 Dec 2020 12:19:27 GMT"}], "update_date": "2020-12-21", "authors_parsed": [["Gracious", "Tony", ""], ["Gupta", "Shubham", ""], ["Kanthali", "Arun", ""], ["Castro", "Rui M.", ""], ["Dukkipati", "Ambedkar", ""]]}, {"id": "1911.11471", "submitter": "Raquel P\\'erez-Arnal", "authors": "Raquel P\\'erez-Arnal, Dario Garcia-Gasulla, David Torrents, Ferran\n  Par\\'es, Ulises Cort\\'es, Jes\\'us Labarta and Eduard Ayguad\\'e", "title": "Random Forest as a Tumour Genetic Marker Extractor", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.GN cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Finding tumour genetic markers is essential to biomedicine due to their\nrelevance for cancer detection and therapy development. In this paper, we\nexplore a recently released dataset of chromosome rearrangements in 2,586\ncancer patients, where different sorts of alterations have been detected. Using\na Random Forest classifier, we evaluate the relevance of several features (some\ndirectly available in the original data, some engineered by us) related to\nchromosome rearrangements. This evaluation results in a set of potential tumour\ngenetic markers, some of which are validated in the bibliography, while others\nare potentially novel.\n", "versions": [{"version": "v1", "created": "Tue, 26 Nov 2019 11:46:07 GMT"}], "update_date": "2019-11-27", "authors_parsed": [["P\u00e9rez-Arnal", "Raquel", ""], ["Garcia-Gasulla", "Dario", ""], ["Torrents", "David", ""], ["Par\u00e9s", "Ferran", ""], ["Cort\u00e9s", "Ulises", ""], ["Labarta", "Jes\u00fas", ""], ["Ayguad\u00e9", "Eduard", ""]]}, {"id": "1911.11481", "submitter": "Alina Dubatovka", "authors": "Alina Dubatovka, Efi Kokiopoulou, Luciano Sbaiz, Andrea Gesmundo,\n  Gabor Bartok, Jesse Berent", "title": "Ranking architectures using meta-learning", "comments": "NeurIPS 2019 Meta-Learning workshop", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Neural architecture search has recently attracted lots of research efforts as\nit promises to automate the manual design of neural networks. However, it\nrequires a large amount of computing resources and in order to alleviate this,\na performance prediction network has been recently proposed that enables\nefficient architecture search by forecasting the performance of candidate\narchitectures, instead of relying on actual model training. The performance\npredictor is task-aware taking as input not only the candidate architecture but\nalso task meta-features and it has been designed to collectively learn from\nseveral tasks. In this work, we introduce a pairwise ranking loss for training\na network able to rank candidate architectures for a new unseen task\nconditioning on its task meta-features. We present experimental results,\nshowing that the ranking network is more effective in architecture search than\nthe previously proposed performance predictor.\n", "versions": [{"version": "v1", "created": "Tue, 26 Nov 2019 12:04:51 GMT"}], "update_date": "2019-11-27", "authors_parsed": [["Dubatovka", "Alina", ""], ["Kokiopoulou", "Efi", ""], ["Sbaiz", "Luciano", ""], ["Gesmundo", "Andrea", ""], ["Bartok", "Gabor", ""], ["Berent", "Jesse", ""]]}, {"id": "1911.11486", "submitter": "Yue Wang", "authors": "Yue Wang, Chenwei Zhang, Shen Wang, Philip S. Yu, Lu Bai, Lixin Cui,\n  Guandong Xu", "title": "Generative Temporal Link Prediction via Self-tokenized Sequence Modeling", "comments": "accepted by World Wide Web Journal", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.IR cs.SI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We formalize networks with evolving structures as temporal networks and\npropose a generative link prediction model, Generative Link Sequence Modeling\n(GLSM), to predict future links for temporal networks. GLSM captures the\ntemporal link formation patterns from the observed links with a sequence\nmodeling framework and has the ability to generate the emerging links by\ninferring from the probability distribution on the potential future links. To\navoid overfitting caused by treating each link as a unique token, we propose a\nself-tokenization mechanism to transform each raw link in the network to an\nabstract aggregation token automatically. The self-tokenization is seamlessly\nintegrated into the sequence modeling framework, which allows the proposed GLSM\nmodel to have the generalization capability to discover link formation patterns\nbeyond raw link sequences. We compare GLSM with the existing state-of-art\nmethods on five real-world datasets. The experimental results demonstrate that\nGLSM obtains future positive links effectively in a generative fashion while\nachieving the best performance (2-10\\% improvements on AUC) among other\nalternatives.\n", "versions": [{"version": "v1", "created": "Tue, 26 Nov 2019 12:14:01 GMT"}, {"version": "v2", "created": "Mon, 27 Apr 2020 13:17:26 GMT"}], "update_date": "2020-04-28", "authors_parsed": [["Wang", "Yue", ""], ["Zhang", "Chenwei", ""], ["Wang", "Shen", ""], ["Yu", "Philip S.", ""], ["Bai", "Lu", ""], ["Cui", "Lixin", ""], ["Xu", "Guandong", ""]]}, {"id": "1911.11496", "submitter": "Tom Hanika", "authors": "Dominik D\\\"urrschnabel and Tom Hanika and Maximilian Stubbemann", "title": "FCA2VEC: Embedding Techniques for Formal Concept Analysis", "comments": "25 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Embedding large and high dimensional data into low dimensional vector spaces\nis a necessary task to computationally cope with contemporary data sets.\nSuperseding latent semantic analysis recent approaches like word2vec or\nnode2vec are well established tools in this realm. In the present paper we add\nto this line of research by introducing fca2vec, a family of embedding\ntechniques for formal concept analysis (FCA). Our investigation contributes to\ntwo distinct lines of research. First, we enable the application of FCA notions\nto large data sets. In particular, we demonstrate how the cover relation of a\nconcept lattice can be retrieved from a computational feasible embedding.\nSecondly, we show an enhancement for the classical node2vec approach in low\ndimension. For both directions the overall constraint of FCA of explainable\nresults is preserved. We evaluate our novel procedures by computing fca2vec on\ndifferent data sets like, wiki44 (a dense part of the Wikidata knowledge\ngraph), the Mushroom data set and a publication network derived from the FCA\ncommunity.\n", "versions": [{"version": "v1", "created": "Tue, 26 Nov 2019 12:36:47 GMT"}], "update_date": "2019-11-27", "authors_parsed": [["D\u00fcrrschnabel", "Dominik", ""], ["Hanika", "Tom", ""], ["Stubbemann", "Maximilian", ""]]}, {"id": "1911.11502", "submitter": "Ya Zhao", "authors": "Ya Zhao, Rui Xu, Xinchao Wang, Peng Hou, Haihong Tang, Mingli Song", "title": "Hearing Lips: Improving Lip Reading by Distilling Speech Recognizers", "comments": "AAAI 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG eess.AS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Lip reading has witnessed unparalleled development in recent years thanks to\ndeep learning and the availability of large-scale datasets. Despite the\nencouraging results achieved, the performance of lip reading, unfortunately,\nremains inferior to the one of its counterpart speech recognition, due to the\nambiguous nature of its actuations that makes it challenging to extract\ndiscriminant features from the lip movement videos. In this paper, we propose a\nnew method, termed as Lip by Speech (LIBS), of which the goal is to strengthen\nlip reading by learning from speech recognizers. The rationale behind our\napproach is that the features extracted from speech recognizers may provide\ncomplementary and discriminant clues, which are formidable to be obtained from\nthe subtle movements of the lips, and consequently facilitate the training of\nlip readers. This is achieved, specifically, by distilling multi-granularity\nknowledge from speech recognizers to lip readers. To conduct this cross-modal\nknowledge distillation, we utilize an efficacious alignment scheme to handle\nthe inconsistent lengths of the audios and videos, as well as an innovative\nfiltering strategy to refine the speech recognizer's prediction. The proposed\nmethod achieves the new state-of-the-art performance on the CMLR and LRS2\ndatasets, outperforming the baseline by a margin of 7.66% and 2.75% in\ncharacter error rate, respectively.\n", "versions": [{"version": "v1", "created": "Tue, 26 Nov 2019 13:05:07 GMT"}], "update_date": "2019-11-27", "authors_parsed": [["Zhao", "Ya", ""], ["Xu", "Rui", ""], ["Wang", "Xinchao", ""], ["Hou", "Peng", ""], ["Tang", "Haihong", ""], ["Song", "Mingli", ""]]}, {"id": "1911.11506", "submitter": "Alejandro Moreo Fern\\'andez", "authors": "Alejandro Moreo, Andrea Esuli, Fabrizio Sebastiani", "title": "Word-Class Embeddings for Multiclass Text Classification", "comments": null, "journal-ref": "Data Mining and Knowledge Discovery, 2021", "doi": null, "report-no": null, "categories": "cs.LG cs.CL stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Pre-trained word embeddings encode general word semantics and lexical\nregularities of natural language, and have proven useful across many NLP tasks,\nincluding word sense disambiguation, machine translation, and sentiment\nanalysis, to name a few. In supervised tasks such as multiclass text\nclassification (the focus of this article) it seems appealing to enhance word\nrepresentations with ad-hoc embeddings that encode task-specific information.\nWe propose (supervised) word-class embeddings (WCEs), and show that, when\nconcatenated to (unsupervised) pre-trained word embeddings, they substantially\nfacilitate the training of deep-learning models in multiclass classification by\ntopic. We show empirical evidence that WCEs yield a consistent improvement in\nmulticlass classification accuracy, using four popular neural architectures and\nsix widely used and publicly available datasets for multiclass text\nclassification. Our code that implements WCEs is publicly available at\nhttps://github.com/AlexMoreo/word-class-embeddings\n", "versions": [{"version": "v1", "created": "Tue, 26 Nov 2019 13:11:00 GMT"}], "update_date": "2021-01-25", "authors_parsed": [["Moreo", "Alejandro", ""], ["Esuli", "Andrea", ""], ["Sebastiani", "Fabrizio", ""]]}, {"id": "1911.11525", "submitter": "Itzik Malkiel", "authors": "Itzik Malkiel, Michael Mrejen, Lior Wolf, Haim Suchowski", "title": "Spectra2pix: Generating Nanostructure Images from Spectra", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.IV cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The design of the nanostructures that are used in the field of nano-photonics\nhas remained complex, very often relying on the intuition and expertise of the\ndesigner, ultimately limiting the reach and penetration of this groundbreaking\napproach. Recently, there has been an increasing number of studies suggesting\nto apply Machine Learning techniques for the design of nanostructures. Most of\nthese studies engage Deep Learning techniques, which entails training a Deep\nNeural Network (DNN) to approximate the highly non-linear function of the\nunderlying physical process between spectra and nanostructures. At the end of\nthe training, the DNN allows an on-demand design of nanostructures, i.e. the\nmodel can infer nanostructure geometries for desired spectra. In this work, we\nintroduce spectra2pix, which is a model DNN trained to generate 2D images of\nthe designed nanostructures. Our model architecture is not limited to a closed\nset of nanostructure shapes, and can be trained for the design of any geometry.\nWe show, for the first time, a successful generalization ability by designing a\ncompletely unseen sub-family of geometries. This generalization capability\nhighlights the importance of our model architecture, and allows higher\napplicability for real-world design problems.\n", "versions": [{"version": "v1", "created": "Tue, 26 Nov 2019 13:35:45 GMT"}], "update_date": "2019-11-27", "authors_parsed": [["Malkiel", "Itzik", ""], ["Mrejen", "Michael", ""], ["Wolf", "Lior", ""], ["Suchowski", "Haim", ""]]}, {"id": "1911.11536", "submitter": "Christian Lang", "authors": "Christian Lang, Florian Steinborn, Oliver Steffens, Elmar W. Lang", "title": "Electricity Load Forecasting -- An Evaluation of Simple 1D-CNN Network\n  Structures", "comments": "Presented at the ITISE 2019 in Granada", "journal-ref": "Proceedings of Papers - ITISE 2019", "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper presents a convolutional neural network (CNN) which can be used\nfor forecasting electricity load profiles 36 hours into the future. In contrast\nto well established CNN architectures, the input data is one-dimensional. A\nparameter scanning of network parameters is conducted in order to gain\ninformation about the influence of the kernel size, number of filters, and\ndense size. The results show that a good forecast quality can already be\nachieved with basic CNN architectures.The method works not only for smooth sum\nloads of many hundred consumers, but also for the load of apartment buildings.\n", "versions": [{"version": "v1", "created": "Tue, 26 Nov 2019 13:57:45 GMT"}], "update_date": "2019-11-27", "authors_parsed": [["Lang", "Christian", ""], ["Steinborn", "Florian", ""], ["Steffens", "Oliver", ""], ["Lang", "Elmar W.", ""]]}, {"id": "1911.11542", "submitter": "Arun Venkitaraman", "authors": "Arun Venkitaraman, Saikat Chatterjee, and Bo Wahlberg", "title": "Recursive Prediction of Graph Signals with Incoming Nodes", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG eess.SP stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Kernel and linear regression have been recently explored in the prediction of\ngraph signals as the output, given arbitrary input signals that are agnostic to\nthe graph. In many real-world problems, the graph expands over time as new\nnodes get introduced. Keeping this premise in mind, we propose a method to\nrecursively obtain the optimal prediction or regression coefficients for the\nrecently propose Linear Regression over Graphs (LRG), as the graph expands with\nincoming nodes. This comes as a natural consequence of the structure C(W)= of\nthe regression problem, and obviates the need to solve a new regression problem\neach time a new node is added. Experiments with real-world graph signals show\nthat our approach results in good prediction performance which tends to be\nclose to that obtained from knowing the entire graph apriori.\n", "versions": [{"version": "v1", "created": "Tue, 26 Nov 2019 14:07:15 GMT"}], "update_date": "2019-11-27", "authors_parsed": [["Venkitaraman", "Arun", ""], ["Chatterjee", "Saikat", ""], ["Wahlberg", "Bo", ""]]}, {"id": "1911.11550", "submitter": "Bo Luo", "authors": "Bo Luo, Yu Li, Lingxiao Wei and Qiang Xu", "title": "On Functional Test Generation for Deep Neural Network IPs", "comments": null, "journal-ref": "2019 Design, Automation & Test in Europe Conference & Exhibition\n  (DATE)", "doi": null, "report-no": null, "categories": "cs.LG cs.SE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Machine learning systems based on deep neural networks (DNNs) produce\nstate-of-the-art results in many applications. Considering the large amount of\ntraining data and know-how required to generate the network, it is more\npractical to use third-party DNN intellectual property (IP) cores for many\ndesigns. No doubt to say, it is essential for DNN IP vendors to provide test\ncases for functional validation without leaking their parameters to IP users.\nTo satisfy this requirement, we propose to effectively generate test cases that\nactivate parameters as many as possible and propagate their perturbations to\noutputs. Then the functionality of DNN IPs can be validated by only checking\ntheir outputs. However, it is difficult considering large numbers of parameters\nand highly non-linearity of DNNs. In this paper, we tackle this problem by\njudiciously selecting samples from the DNN training set and applying a\ngradient-based method to generate new test cases. Experimental results\ndemonstrate the efficacy of our proposed solution.\n", "versions": [{"version": "v1", "created": "Sat, 23 Nov 2019 04:27:24 GMT"}], "update_date": "2019-11-27", "authors_parsed": [["Luo", "Bo", ""], ["Li", "Yu", ""], ["Wei", "Lingxiao", ""], ["Xu", "Qiang", ""]]}, {"id": "1911.11552", "submitter": "Heeyoul Choi", "authors": "Hyeokmin Gwon, Chungjun Lee, Rakun Keum, Heeyoul Choi", "title": "Network Intrusion Detection based on LSTM and Feature Embedding", "comments": "16 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.NI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Growing number of network devices and services have led to increasing demand\nfor protective measures as hackers launch attacks to paralyze or steal\ninformation from victim systems. Intrusion Detection System (IDS) is one of the\nessential elements of network perimeter security which detects the attacks by\ninspecting network traffic packets or operating system logs. While existing\nworks demonstrated effectiveness of various machine learning techniques, only\nfew of them utilized the time-series information of network traffic data. Also,\ncategorical information has not been included in neural network based\napproaches. In this paper, we propose network intrusion detection models based\non sequential information using long short-term memory (LSTM) network and\ncategorical information using the embedding technique. We have experimented the\nmodels with UNSW-NB15, which is a comprehensive network traffic dataset. The\nexperiment results confirm that the proposed method improve the performance,\nobserving binary classification accuracy of 99.72\\%.\n", "versions": [{"version": "v1", "created": "Tue, 26 Nov 2019 14:15:47 GMT"}], "update_date": "2019-11-27", "authors_parsed": [["Gwon", "Hyeokmin", ""], ["Lee", "Chungjun", ""], ["Keum", "Rakun", ""], ["Choi", "Heeyoul", ""]]}, {"id": "1911.11553", "submitter": "Arun Venkitaraman", "authors": "Arun Venkitaraman, H{\\aa}kan Hjalmarsson, Bo Wahlberg", "title": "Learning sparse linear dynamic networks in a hyper-parameter free\n  setting", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We address the issue of estimating the topology and dynamics of sparse linear\ndynamic networks in a hyperparameter-free setting. We propose a method to\nestimate the network dynamics in a computationally efficient and parameter\ntuning-free iterative framework known as SPICE (Sparse Iterative Covariance\nEstimation). The estimated dynamics directly reveal the underlying topology.\nOur approach does not assume that the network is undirected and is applicable\neven with varying noise levels across the modules of the network. We also do\nnot assume any explicit prior knowledge on the network dynamics. Numerical\nexperiments with realistic dynamic networks illustrate the usefulness of our\nmethod.\n", "versions": [{"version": "v1", "created": "Tue, 26 Nov 2019 14:16:41 GMT"}], "update_date": "2019-11-27", "authors_parsed": [["Venkitaraman", "Arun", ""], ["Hjalmarsson", "H\u00e5kan", ""], ["Wahlberg", "Bo", ""]]}, {"id": "1911.11554", "submitter": "Sicheng Zhao", "authors": "Sicheng Zhao, Guangzhi Wang, Shanghang Zhang, Yang Gu, Yaxian Li,\n  Zhichao Song, Pengfei Xu, Runbo Hu, Hua Chai, Kurt Keutzer", "title": "Multi-source Distilling Domain Adaptation", "comments": "Accepted by AAAI 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep neural networks suffer from performance decay when there is domain shift\nbetween the labeled source domain and unlabeled target domain, which motivates\nthe research on domain adaptation (DA). Conventional DA methods usually assume\nthat the labeled data is sampled from a single source distribution. However, in\npractice, labeled data may be collected from multiple sources, while naive\napplication of the single-source DA algorithms may lead to suboptimal\nsolutions. In this paper, we propose a novel multi-source distilling domain\nadaptation (MDDA) network, which not only considers the different distances\namong multiple sources and the target, but also investigates the different\nsimilarities of the source samples to the target ones. Specifically, the\nproposed MDDA includes four stages: (1) pre-train the source classifiers\nseparately using the training data from each source; (2) adversarially map the\ntarget into the feature space of each source respectively by minimizing the\nempirical Wasserstein distance between source and target; (3) select the source\ntraining samples that are closer to the target to fine-tune the source\nclassifiers; and (4) classify each encoded target feature by corresponding\nsource classifier, and aggregate different predictions using respective domain\nweight, which corresponds to the discrepancy between each source and target.\nExtensive experiments are conducted on public DA benchmarks, and the results\ndemonstrate that the proposed MDDA significantly outperforms the\nstate-of-the-art approaches. Our source code is released at:\nhttps://github.com/daoyuan98/MDDA.\n", "versions": [{"version": "v1", "created": "Fri, 22 Nov 2019 19:30:15 GMT"}, {"version": "v2", "created": "Fri, 7 Feb 2020 18:21:22 GMT"}], "update_date": "2020-02-10", "authors_parsed": [["Zhao", "Sicheng", ""], ["Wang", "Guangzhi", ""], ["Zhang", "Shanghang", ""], ["Gu", "Yang", ""], ["Li", "Yaxian", ""], ["Song", "Zhichao", ""], ["Xu", "Pengfei", ""], ["Hu", "Runbo", ""], ["Chai", "Hua", ""], ["Keutzer", "Kurt", ""]]}, {"id": "1911.11555", "submitter": "Zhiliang Chen", "authors": "Zhiliang Chen", "title": "Fair Multi-party Machine Learning -- a Game Theoretic approach", "comments": "Undergraduate Thesis at National University of Singapore, School of\n  Computer Science; in preparation for publication in 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.GT cs.MA", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  High performance machine learning models have become highly dependent on the\navailability of large quantity and quality of training data. To achieve this,\nvarious central agencies such as the government have suggested for different\ndata providers to pool their data together to learn a unified predictive model,\nwhich performs better. However, these providers are usually profit-driven and\nwould only agree to participate inthe data sharing process if the process is\ndeemed both profitable and fair for themselves. Due to the lack of existing\nliterature, it is unclear whether a fair and stable outcome is possible in such\ndata sharing processes. Hence, we wish to investigate the outcomes surrounding\nthese scenarios and study if data providers would even agree to collaborate in\nthe first place. Tapping on cooperative game concepts in Game Theory, we\nintroduce the data sharing process between a group of agents as a new class of\ncooperative games with modified definition of stability and fairness. Using\nthese new definitions, we then theoretically study the optimal and suboptimal\noutcomes of such data sharing processes and their sensitivity to\nperturbation.Through experiments, we present intuitive insights regarding\ntheoretical results analysed in this paper and discuss various ways in which\ndata can be valued reasonably.\n", "versions": [{"version": "v1", "created": "Fri, 22 Nov 2019 07:31:21 GMT"}], "update_date": "2019-11-27", "authors_parsed": [["Chen", "Zhiliang", ""]]}, {"id": "1911.11558", "submitter": "Shouman Das", "authors": "Rupam Acharyya, Shouman Das, Ankani Chattoraj, Md. Iftekhar Tanveer", "title": "FairyTED: A Fair Rating Predictor for TED Talk Data", "comments": "9 pages, 4 figures, 3 tables. Accepted as a conference paper to be\n  presented at AAAI 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CL stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  With the recent trend of applying machine learning in every aspect of human\nlife, it is important to incorporate fairness into the core of the predictive\nalgorithms. We address the problem of predicting the quality of public speeches\nwhile being fair with respect to sensitive attributes of the speakers, e.g.\ngender and race. We use the TED talks as an input repository of public speeches\nbecause it consists of speakers from a diverse community and has a wide\noutreach. Utilizing the theories of Causal Models, Counterfactual Fairness and\nstate-of-the-art neural language models, we propose a mathematical framework\nfor fair prediction of the public speaking quality. We employ grounded\nassumptions to construct a causal model capturing how different attributes\naffect public speaking quality. This causal model contributes in generating\ncounterfactual data to train a fair predictive model. Our framework is general\nenough to utilize any assumption within the causal model. Experimental results\nshow that while prediction accuracy is comparable to recent work on this\ndataset, our predictions are counterfactually fair with respect to a novel\nmetric when compared to true data labels. The FairyTED setup not only allows\norganizers to make informed and diverse selection of speakers from the\nunobserved counterfactual possibilities but it also ensures that viewers and\nnew users are not influenced by unfair and unbalanced ratings from arbitrary\nvisitors to the www.ted.com website when deciding to view a talk.\n", "versions": [{"version": "v1", "created": "Mon, 25 Nov 2019 09:55:52 GMT"}], "update_date": "2019-11-27", "authors_parsed": [["Acharyya", "Rupam", ""], ["Das", "Shouman", ""], ["Chattoraj", "Ankani", ""], ["Tanveer", "Md. Iftekhar", ""]]}, {"id": "1911.11559", "submitter": "Marco Fronzi Dr", "authors": "Marco Fronzi, Mutaz Abu Ghazaleh, Olexandr Isayev, David A.Winkler,\n  Joe Shapter and Michael J. Ford", "title": "Impressive computational acceleration by using machine learning for\n  2-dimensional super-lubricant materials discovery", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "physics.comp-ph cond-mat.mtrl-sci cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The screening of novel materials is an important topic in the field of\nmaterials science. Although traditional computational modeling, especially\nfirst-principles approaches, is a very useful and accurate tool to predict the\nproperties of novel materials, it still demands extensive and expensive\nstate-of-the-art computational resources. Additionally, they can be often\nextremely time consuming. We describe a time and resource-efficient machine\nlearning approach to create a large dataset of structural properties of van der\nWaals layered structures. In particular, we focus on the interlayer energy and\nthe elastic constant of layered materials composed of two different\n2-dimensional (2D) structures, that are important for novel solid lubricant and\nsuper-lubricant materials. We show that machine learning models can\nrecapitulate results of computationally expansive approaches (i.e. density\nfunctional theory) with high accuracy.\n", "versions": [{"version": "v1", "created": "Wed, 20 Nov 2019 09:59:11 GMT"}, {"version": "v2", "created": "Wed, 29 Jul 2020 08:08:49 GMT"}], "update_date": "2020-07-30", "authors_parsed": [["Fronzi", "Marco", ""], ["Ghazaleh", "Mutaz Abu", ""], ["Isayev", "Olexandr", ""], ["Winkler", "David A.", ""], ["Shapter", "Joe", ""], ["Ford", "Michael J.", ""]]}, {"id": "1911.11561", "submitter": "Yue Bai", "authors": "Yue Bai, Lichen Wang, Zhiqiang Tao, Sheng Li, Yun Fu", "title": "Correlative Channel-Aware Fusion for Multi-View Time Series\n  Classification", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Multi-view time series classification (MVTSC) aims to improve the performance\nby fusing the distinctive temporal information from multiple views. Existing\nmethods mainly focus on fusing multi-view information at an early stage, e.g.,\nby learning a common feature subspace among multiple views. However, these\nearly fusion methods may not fully exploit the unique temporal patterns of each\nview in complicated time series. Moreover, the label correlations of multiple\nviews, which are critical to boost-ing, are usually under-explored for the\nMVTSC problem. To address the aforementioned issues, we propose a Correlative\nChannel-Aware Fusion (C2AF) network. First, C2AF extracts comprehensive and\nrobust temporal patterns by a two-stream structured encoder for each view, and\ncaptures the intra-view and inter-view label correlations with a graph-based\ncorrelation matrix. Second, a channel-aware learnable fusion mechanism is\nimplemented through convolutional neural networks to further explore the global\ncorrelative patterns. These two steps are trained end-to-end in the proposed\nC2AF network. Extensive experimental results on three real-world datasets\ndemonstrate the superiority of our approach over the state-of-the-art methods.\nA detailed ablation study is also provided to show the effectiveness of each\nmodel component.\n", "versions": [{"version": "v1", "created": "Sun, 24 Nov 2019 20:22:57 GMT"}, {"version": "v2", "created": "Fri, 20 Nov 2020 23:05:52 GMT"}], "update_date": "2020-11-24", "authors_parsed": [["Bai", "Yue", ""], ["Wang", "Lichen", ""], ["Tao", "Zhiqiang", ""], ["Li", "Sheng", ""], ["Fu", "Yun", ""]]}, {"id": "1911.11573", "submitter": "Jeremy Charlier", "authors": "Jeremy Charlier", "title": "From Persistent Homology to Reinforcement Learning with Applications for\n  Retail Banking", "comments": "PhD thesis, Univ Luxembourg (2019)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The retail banking services are one of the pillars of the modern economic\ngrowth. However, the evolution of the client's habits in modern societies and\nthe recent European regulations promoting more competition mean the retail\nbanks will encounter serious challenges for the next few years, endangering\ntheir activities. They now face an impossible compromise: maximizing the\nsatisfaction of their hyper-connected clients while avoiding any risk of\ndefault and being regulatory compliant. Therefore, advanced and novel research\nconcepts are a serious game-changer to gain a competitive advantage. In this\ncontext, we investigate in this thesis different concepts bridging the gap\nbetween persistent homology, neural networks, recommender engines and\nreinforcement learning with the aim of improving the quality of the retail\nbanking services. Our contribution is threefold. First, we highlight how to\novercome insufficient financial data by generating artificial data using\ngenerative models and persistent homology. Then, we present how to perform\naccurate financial recommendations in multi-dimensions. Finally, we underline a\nreinforcement learning model-free approach to determine the optimal policy of\nmoney management based on the aggregated financial transactions of the clients.\nOur experimental data sets, extracted from well-known institutions where the\nprivacy and the confidentiality of the clients were not put at risk, support\nour contributions. In this work, we provide the motivations of our retail\nbanking research project, describe the theory employed to improve the financial\nservices quality and evaluate quantitatively and qualitatively our\nmethodologies for each of the proposed research scenarios.\n", "versions": [{"version": "v1", "created": "Sat, 23 Nov 2019 23:04:34 GMT"}], "update_date": "2019-11-27", "authors_parsed": [["Charlier", "Jeremy", ""]]}, {"id": "1911.11581", "submitter": "Hanyuan Hang", "authors": "Hanyuan Hang", "title": "Histogram Transform Ensembles for Density Estimation", "comments": "arXiv admin note: text overlap with arXiv:1905.03729", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST cs.LG stat.ML stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We investigate an algorithm named histogram transform ensembles (HTE) density\nestimator whose effectiveness is supported by both solid theoretical analysis\nand significant experimental performance. On the theoretical side, by\ndecomposing the error term into approximation error and estimation error, we\nare able to conduct the following analysis: First of all, we establish the\nuniversal consistency under $L_1(\\mu)$-norm. Secondly, under the assumption\nthat the underlying density function resides in the H\\\"{o}lder space\n$C^{0,\\alpha}$, we prove almost optimal convergence rates for both single and\nensemble density estimators under $L_1(\\mu)$-norm and $L_{\\infty}(\\mu)$-norm\nfor different tail distributions, whereas in contrast, for its subspace\n$C^{1,\\alpha}$ consisting of smoother functions, almost optimal convergence\nrates can only be established for the ensembles and the lower bound of the\nsingle estimators illustrates the benefits of ensembles over single density\nestimators. In the experiments, we first carry out simulations to illustrate\nthat histogram transform ensembles surpass single histogram transforms, which\noffers powerful evidence to support the theoretical results in the space\n$C^{1,\\alpha}$. Moreover, to further exert the experimental performances, we\npropose an adaptive version of HTE and study the parameters by generating\nseveral synthetic datasets with diversities in dimensions and distributions.\nLast but not least, real data experiments with other state-of-the-art density\nestimators demonstrate the accuracy of the adaptive HTE algorithm.\n", "versions": [{"version": "v1", "created": "Sun, 24 Nov 2019 17:24:12 GMT"}], "update_date": "2019-11-27", "authors_parsed": [["Hang", "Hanyuan", ""]]}, {"id": "1911.11592", "submitter": "Harsh Singh", "authors": "Harsh Jot Singh and Abdelhakim Senhaji Hafid", "title": "Transaction Confirmation Time Prediction in Ethereum Blockchain Using\n  Machine Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.LG cs.PF stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Blockchain offers a decentralized, immutable, transparent system of records.\nIt offers a peer-to-peer network of nodes with no centralised governing entity\nmaking it unhackable and therefore, more secure than the traditional\npaper-based or centralised system of records like banks etc. While there are\ncertain advantages to the paper-based recording approach, it does not work well\nwith digital relationships where the data is in constant flux. Unlike\ntraditional channels, governed by centralized entities, blockchain offers its\nusers a certain level of anonymity by providing capabilities to interact\nwithout disclosing their personal identities and allows them to build trust\nwithout a third-party governing entity. Due to the aforementioned\ncharacteristics of blockchain, more and more users around the globe are\ninclined towards making a digital transaction via blockchain than via\nrudimentary channels. Therefore, there is a dire need for us to gain insight on\nhow these transactions are processed by the blockchain and how much time it may\ntake for a peer to confirm a transaction and add it to the blockchain network.\nThis paper presents a novel approach that would allow one to estimate the time,\nin block time or otherwise, it would take for a mining node to accept and\nconfirm a transaction to a block using machine learning. The paper also aims to\ncompare the predictive accuracy of two machine learning regression models-\nRandom Forest Regressor and Multilayer Perceptron against previously proposed\nstatistical regression model under a set evaluation criterion. The objective is\nto determine whether machine learning offers a more accurate predictive model\nthan conventional statistical models. The proposed model results in improved\naccuracy in prediction.\n", "versions": [{"version": "v1", "created": "Mon, 25 Nov 2019 17:20:27 GMT"}], "update_date": "2019-11-27", "authors_parsed": [["Singh", "Harsh Jot", ""], ["Hafid", "Abdelhakim Senhaji", ""]]}, {"id": "1911.11596", "submitter": "Shin Nakajima", "authors": "Shin Nakajima", "title": "Distortion and Faults in Machine Learning Software", "comments": "Presented at the 9th SOFL+MSVL Workshop in Shenzhen, November 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Machine learning software, deep neural networks (DNN) software in particular,\ndiscerns valuable information from a large dataset, a set of data. Outcomes of\nsuch DNN programs are dependent on the quality of both learning programs and\ndatasets. Unfortunately, the quality of datasets is difficult to be defined,\nbecause they are just samples. The quality assurance of DNN software is\ndifficult, because resultant trained machine learning models are unknown prior\nto its development, and the validation is conducted indirectly in terms of\nprediction performance. This paper introduces a hypothesis that faults in the\nlearning programs manifest themselves as distortions in trained machine\nlearning models. Relative distortion degrees measured with appropriate observer\nfunctions may indicate that there are some hidden faults. The proposal is\ndemonstrated with example cases of the MNIST dataset.\n", "versions": [{"version": "v1", "created": "Mon, 25 Nov 2019 11:36:19 GMT"}], "update_date": "2019-11-27", "authors_parsed": [["Nakajima", "Shin", ""]]}, {"id": "1911.11607", "submitter": "Weijie J. Su", "authors": "Zhiqi Bu and Jinshuo Dong and Qi Long and Weijie J. Su", "title": "Deep Learning with Gaussian Differential Privacy", "comments": "To appear in Harvard Data Science Review", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep learning models are often trained on datasets that contain sensitive\ninformation such as individuals' shopping transactions, personal contacts, and\nmedical records. An increasingly important line of work therefore has sought to\ntrain neural networks subject to privacy constraints that are specified by\ndifferential privacy or its divergence-based relaxations. These privacy\ndefinitions, however, have weaknesses in handling certain important primitives\n(composition and subsampling), thereby giving loose or complicated privacy\nanalyses of training neural networks. In this paper, we consider a recently\nproposed privacy definition termed \\textit{$f$-differential privacy} [18] for a\nrefined privacy analysis of training neural networks. Leveraging the appealing\nproperties of $f$-differential privacy in handling composition and subsampling,\nthis paper derives analytically tractable expressions for the privacy\nguarantees of both stochastic gradient descent and Adam used in training deep\nneural networks, without the need of developing sophisticated techniques as [3]\ndid. Our results demonstrate that the $f$-differential privacy framework allows\nfor a new privacy analysis that improves on the prior analysis~[3], which in\nturn suggests tuning certain parameters of neural networks for a better\nprediction accuracy without violating the privacy budget. These theoretically\nderived improvements are confirmed by our experiments in a range of tasks in\nimage classification, text classification, and recommender systems. Python code\nto calculate the privacy cost for these experiments is publicly available in\nthe \\texttt{TensorFlow Privacy} library.\n", "versions": [{"version": "v1", "created": "Tue, 26 Nov 2019 15:08:58 GMT"}, {"version": "v2", "created": "Tue, 10 Dec 2019 03:11:37 GMT"}, {"version": "v3", "created": "Wed, 22 Jul 2020 16:09:13 GMT"}], "update_date": "2020-07-23", "authors_parsed": [["Bu", "Zhiqi", ""], ["Dong", "Jinshuo", ""], ["Long", "Qi", ""], ["Su", "Weijie J.", ""]]}, {"id": "1911.11610", "submitter": "Gautam Krishna", "authors": "Gautam Krishna, Co Tran, Mason Carnahan, Yan Han, Ahmed H Tewfik", "title": "Improving EEG based Continuous Speech Recognition", "comments": "On preparation for submission to EUSIPCO 2020. arXiv admin note: text\n  overlap with arXiv:1911.04261, arXiv:1906.08871", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.AS cs.LG cs.SD stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we introduce various techniques to improve the performance of\nelectroencephalography (EEG) features based continuous speech recognition (CSR)\nsystems. A connectionist temporal classification (CTC) based automatic speech\nrecognition (ASR) system was implemented for performing recognition. We\nintroduce techniques to initialize the weights of the recurrent layers in the\nencoder of the CTC model with more meaningful weights rather than with random\nweights and we make use of an external language model to improve the beam\nsearch during decoding time.\n  We finally study the problem of predicting articulatory features from EEG\nfeatures in this paper.\n", "versions": [{"version": "v1", "created": "Sun, 24 Nov 2019 16:00:49 GMT"}, {"version": "v2", "created": "Sat, 30 Nov 2019 04:16:39 GMT"}, {"version": "v3", "created": "Tue, 10 Dec 2019 08:37:50 GMT"}, {"version": "v4", "created": "Sun, 15 Dec 2019 06:36:00 GMT"}, {"version": "v5", "created": "Wed, 18 Dec 2019 20:44:05 GMT"}, {"version": "v6", "created": "Tue, 24 Dec 2019 04:52:49 GMT"}], "update_date": "2019-12-25", "authors_parsed": [["Krishna", "Gautam", ""], ["Tran", "Co", ""], ["Carnahan", "Mason", ""], ["Han", "Yan", ""], ["Tewfik", "Ahmed H", ""]]}, {"id": "1911.11616", "submitter": "Yantao Lu", "authors": "Yantao Lu, Yunhan Jia, Jianyu Wang, Bai Li, Weiheng Chai, Lawrence\n  Carin, Senem Velipasalar", "title": "Enhancing Cross-task Black-Box Transferability of Adversarial Examples\n  with Dispersion Reduction", "comments": "arXiv admin note: substantial text overlap with arXiv:1905.03333", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.IV cs.CR cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Neural networks are known to be vulnerable to carefully crafted adversarial\nexamples, and these malicious samples often transfer, i.e., they remain\nadversarial even against other models. Although great efforts have been delved\ninto the transferability across models, surprisingly, less attention has been\npaid to the cross-task transferability, which represents the real-world\ncybercriminal's situation, where an ensemble of different defense/detection\nmechanisms need to be evaded all at once. In this paper, we investigate the\ntransferability of adversarial examples across a wide range of real-world\ncomputer vision tasks, including image classification, object detection,\nsemantic segmentation, explicit content detection, and text detection. Our\nproposed attack minimizes the ``dispersion'' of the internal feature map, which\novercomes existing attacks' limitation of requiring task-specific loss\nfunctions and/or probing a target model. We conduct evaluation on open source\ndetection and segmentation models as well as four different computer vision\ntasks provided by Google Cloud Vision (GCV) APIs, to show how our approach\noutperforms existing attacks by degrading performance of multiple CV tasks by a\nlarge margin with only modest perturbations linf=16.\n", "versions": [{"version": "v1", "created": "Fri, 22 Nov 2019 23:08:17 GMT"}], "update_date": "2019-11-27", "authors_parsed": [["Lu", "Yantao", ""], ["Jia", "Yunhan", ""], ["Wang", "Jianyu", ""], ["Li", "Bai", ""], ["Chai", "Weiheng", ""], ["Carin", "Lawrence", ""], ["Velipasalar", "Senem", ""]]}, {"id": "1911.11622", "submitter": "Luciana Ferrer", "authors": "Luciana Ferrer and Mitchell McLaren", "title": "A discriminative condition-aware backend for speaker verification", "comments": null, "journal-ref": "Proceedings of ICASSP 2020", "doi": null, "report-no": null, "categories": "cs.LG cs.SD eess.AS stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a scoring approach for speaker verification that mimics the\nstandard PLDA-based backend process used in most current speaker verification\nsystems. However, unlike the standard backends, all parameters of the model are\njointly trained to optimize the binary cross-entropy for the speaker\nverification task. We further integrate the calibration stage inside the model,\nmaking the parameters of this stage depend on metadata vectors that represent\nthe conditions of the signals. We show that the proposed backend has excellent\nout-of-the-box calibration performance on most of our test sets, making it an\nideal approach for cases in which the test conditions are not known and\ndevelopment data is not available for training a domain-specific calibration\nmodel.\n", "versions": [{"version": "v1", "created": "Tue, 26 Nov 2019 15:14:22 GMT"}], "update_date": "2020-02-06", "authors_parsed": [["Ferrer", "Luciana", ""], ["McLaren", "Mitchell", ""]]}, {"id": "1911.11629", "submitter": "Anton Fuxjaeger", "authors": "Anton Fuxjaeger, Vaishak Belle", "title": "Logical Interpretations of Autoencoders", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The unification of low-level perception and high-level reasoning is a\nlong-standing problem in artificial intelligence, which has the potential to\nnot only bring the areas of logic and learning closer together but also\ndemonstrate how abstract concepts might emerge from sensory data. Precisely\nbecause deep learning methods dominate perception-based learning, including\nvision, speech, and linguistic grammar, there is fast-growing literature on how\nto integrate symbolic reasoning and deep learning. Broadly, efforts seem to\nfall into three camps: those focused on defining a logic whose formulas capture\ndeep learning, ones that integrate symbolic constraints in deep learning, and\nothers that allow neural computations and symbolic reasoning to co-exist\nseparately, to enjoy the strengths of both worlds. In this paper, we identify\nanother dimension to this inquiry: what do the hidden layers really capture,\nand how can we reason about that logically? In particular, we consider\nautoencoders that are widely used for dimensionality reduction and inject a\nsymbolic generative framework onto the feature layer. This allows us, among\nother things, to generate example images for a class to get a sense of what was\nlearned. Moreover, the modular structure of the proposed model makes it\npossible to learn relations over multiple images at a time, as well as handle\nnoisy labels. Our empirical evaluations show the promise of this inquiry.\n", "versions": [{"version": "v1", "created": "Tue, 26 Nov 2019 15:20:32 GMT"}], "update_date": "2019-11-27", "authors_parsed": [["Fuxjaeger", "Anton", ""], ["Belle", "Vaishak", ""]]}, {"id": "1911.11636", "submitter": "Yuwei Fan", "authors": "Yuwei Fan and Lexing Ying", "title": "Solving Traveltime Tomography with Deep Learning", "comments": "17 pages, 7 figures. arXiv admin note: text overlap with\n  arXiv:1910.04756", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.NA cs.LG cs.NA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper introduces a neural network approach for solving two-dimensional\ntraveltime tomography (TT) problems based on the eikonal equation. The\nmathematical problem of TT is to recover the slowness field of a medium based\non the boundary measurement of the traveltimes of waves going through the\nmedium. This inverse map is high-dimensional and nonlinear. For the circular\ntomography geometry, a perturbative analysis shows that the forward map can be\napproximated by a vectorized convolution operator in the angular direction.\nMotivated by this and filtered back-projection, we propose an effective neural\nnetwork architecture for the inverse map using the recently proposed BCR-Net,\nwith weights learned from training datasets. Numerical results demonstrate the\nefficiency of the proposed neural networks.\n", "versions": [{"version": "v1", "created": "Mon, 25 Nov 2019 08:50:28 GMT"}], "update_date": "2019-11-27", "authors_parsed": [["Fan", "Yuwei", ""], ["Ying", "Lexing", ""]]}, {"id": "1911.11641", "submitter": "Yonatan Bisk", "authors": "Yonatan Bisk, Rowan Zellers, Ronan Le Bras, Jianfeng Gao, Yejin Choi", "title": "PIQA: Reasoning about Physical Commonsense in Natural Language", "comments": "AAAI 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  To apply eyeshadow without a brush, should I use a cotton swab or a\ntoothpick? Questions requiring this kind of physical commonsense pose a\nchallenge to today's natural language understanding systems. While recent\npretrained models (such as BERT) have made progress on question answering over\nmore abstract domains - such as news articles and encyclopedia entries, where\ntext is plentiful - in more physical domains, text is inherently limited due to\nreporting bias. Can AI systems learn to reliably answer physical common-sense\nquestions without experiencing the physical world? In this paper, we introduce\nthe task of physical commonsense reasoning and a corresponding benchmark\ndataset Physical Interaction: Question Answering or PIQA. Though humans find\nthe dataset easy (95% accuracy), large pretrained models struggle (77%). We\nprovide analysis about the dimensions of knowledge that existing models lack,\nwhich offers significant opportunities for future research.\n", "versions": [{"version": "v1", "created": "Tue, 26 Nov 2019 15:31:46 GMT"}], "update_date": "2019-11-27", "authors_parsed": [["Bisk", "Yonatan", ""], ["Zellers", "Rowan", ""], ["Bras", "Ronan Le", ""], ["Gao", "Jianfeng", ""], ["Choi", "Yejin", ""]]}, {"id": "1911.11652", "submitter": "Alberto Torres-Barr\\'an", "authors": "Alberto Redondo, Alberto Torres-Barr\\'an, David R\\'ios Insua, Jordi\n  Domingo", "title": "Assessing Supply Chain Cyber Risks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Risk assessment is a major challenge for supply chain managers, as it\npotentially affects business factors such as service costs, supplier\ncompetition and customer expectations. The increasing interconnectivity between\norganisations has put into focus methods for supply chain cyber risk\nmanagement. We introduce a general approach to support such activity taking\ninto account various techniques of attacking an organisation and its suppliers,\nas well as the impacts of such attacks. Since data is lacking in many respects,\nwe use structured expert judgment methods to facilitate its implementation. We\ncouple a family of forecasting models to enrich risk monitoring. The approach\nmay be used to set up risk alarms, negotiate service level agreements, rank\nsuppliers and identify insurance needs, among other management possibilities.\n", "versions": [{"version": "v1", "created": "Tue, 26 Nov 2019 15:49:08 GMT"}], "update_date": "2019-11-27", "authors_parsed": [["Redondo", "Alberto", ""], ["Torres-Barr\u00e1n", "Alberto", ""], ["Insua", "David R\u00edos", ""], ["Domingo", "Jordi", ""]]}, {"id": "1911.11657", "submitter": "Gokul S Krishnan", "authors": "Gokul S Krishnan and Sowmya Kamath S", "title": "Hybrid Text Feature Modeling for Disease Group Prediction using\n  Unstructured Physician Notes", "comments": "Submitted to the International Conference on Computational Science\n  (ICCS) 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.CY cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Existing Clinical Decision Support Systems (CDSSs) largely depend on the\navailability of structured patient data and Electronic Health Records (EHRs) to\naid caregivers. However, in case of hospitals in developing countries,\nstructured patient data formats are not widely adopted, where medical\nprofessionals still rely on clinical notes in the form of unstructured text.\nSuch unstructured clinical notes recorded by medical personnel can also be a\npotential source of rich patient-specific information which can be leveraged to\nbuild CDSSs, even for hospitals in developing countries. If such unstructured\nclinical text can be used, the manual and time-consuming process of EHR\ngeneration will no longer be required, with huge person-hours and cost savings.\nIn this paper, we propose a generic ICD9 disease group prediction CDSS built on\nunstructured physician notes modeled using hybrid word embeddings. These word\nembeddings are used to train a deep neural network for effectively predicting\nICD9 disease groups. Experimental evaluation showed that the proposed approach\noutperformed the state-of-the-art disease group prediction model built on\nstructured EHRs by 15% in terms of AUROC and 40% in terms of AUPRC, thus\nproving our hypothesis and eliminating dependency on availability of structured\npatient data.\n", "versions": [{"version": "v1", "created": "Tue, 26 Nov 2019 15:55:39 GMT"}], "update_date": "2019-11-27", "authors_parsed": [["Krishnan", "Gokul S", ""], ["S", "Sowmya Kamath", ""]]}, {"id": "1911.11658", "submitter": "Victor Kristof", "authors": "Victor Kristof, Valentin Quelquejay-Lecl\\`ere, Robin Zbinden, Lucas\n  Maystre, Matthias Grossglauser, Patrick Thiran", "title": "A User Study of Perceived Carbon Footprint", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.CY cs.LG physics.soc-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a statistical model to understand people's perception of their\ncarbon footprint. Driven by the observation that few people think of CO2 impact\nin absolute terms, we design a system to probe people's perception from simple\npairwise comparisons of the relative carbon footprint of their actions. The\nformulation of the model enables us to take an active-learning approach to\nselecting the pairs of actions that are maximally informative about the model\nparameters. We define a set of 18 actions and collect a dataset of 2183\ncomparisons from 176 users on a university campus. The early results reveal\npromising directions to improve climate communication and enhance climate\nmitigation.\n", "versions": [{"version": "v1", "created": "Tue, 26 Nov 2019 15:56:46 GMT"}, {"version": "v2", "created": "Wed, 4 Dec 2019 14:56:02 GMT"}], "update_date": "2019-12-05", "authors_parsed": [["Kristof", "Victor", ""], ["Quelquejay-Lecl\u00e8re", "Valentin", ""], ["Zbinden", "Robin", ""], ["Maystre", "Lucas", ""], ["Grossglauser", "Matthias", ""], ["Thiran", "Patrick", ""]]}, {"id": "1911.11663", "submitter": "James Ritchie", "authors": "James A. Ritchie, Iain Murray", "title": "Scalable Extreme Deconvolution", "comments": "Appearing at the Second Workshop on Machine Learning and the Physical\n  Sciences (NeurIPS 2019), Vancouver, Canada", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The Extreme Deconvolution method fits a probability density to a dataset\nwhere each observation has Gaussian noise added with a known sample-specific\ncovariance, originally intended for use with astronomical datasets. The\nexisting fitting method is batch EM, which would not normally be applied to\nlarge datasets such as the Gaia catalog containing noisy observations of a\nbillion stars. We propose two minibatch variants of extreme deconvolution,\nbased on an online variation of the EM algorithm, and direct gradient-based\noptimisation of the log-likelihood, both of which can run on GPUs. We\ndemonstrate that these methods provide faster fitting, whilst being able to\nscale to much larger models for use with larger datasets.\n", "versions": [{"version": "v1", "created": "Tue, 26 Nov 2019 16:02:58 GMT"}], "update_date": "2019-11-27", "authors_parsed": [["Ritchie", "James A.", ""], ["Murray", "Iain", ""]]}, {"id": "1911.11668", "submitter": "Travis LaCroix", "authors": "Travis LaCroix", "title": "Biology and Compositionality: Empirical Considerations for\n  Emergent-Communication Protocols", "comments": "Accepted for NeurIPS 2019 workshop Emergent Communication: Towards\n  Natural Language", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CL stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Significant advances have been made in artificial systems by using biological\nsystems as a guide. However, there is often little interaction between\ncomputational models for emergent communication and biological models of the\nemergence of language. Many researchers in language origins and emergent\ncommunication take compositionality as their primary target for explaining how\nsimple communication systems can become more like natural language. However,\nthere is reason to think that compositionality is the wrong target on the\nbiological side, and so too the wrong target on the machine-learning side. As\nsuch, the purpose of this paper is to explore this claim. This has theoretical\nimplications for language origins research more generally, but the focus here\nwill be the implications for research on emergent communication in computer\nscience and machine learning---specifically regarding the types of programmes\nthat might be expected to work and those which will not. I further suggest an\nalternative approach for future research which focuses on reflexivity, rather\nthan compositionality, as a target for explaining how simple communication\nsystems may become more like natural language. I end by providing some\nreference to the language origins literature that may be of some use to\nresearchers in machine learning.\n", "versions": [{"version": "v1", "created": "Tue, 26 Nov 2019 16:07:44 GMT"}, {"version": "v2", "created": "Fri, 27 Dec 2019 19:36:13 GMT"}], "update_date": "2020-01-01", "authors_parsed": [["LaCroix", "Travis", ""]]}, {"id": "1911.11679", "submitter": "Olivier Sigaud", "authors": "Guillaume Matheron and Nicolas Perrin and Olivier Sigaud", "title": "The problem with DDPG: understanding failures in deterministic\n  environments with sparse rewards", "comments": "19 pages, submitted to ICLR 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In environments with continuous state and action spaces, state-of-the-art\nactor-critic reinforcement learning algorithms can solve very complex problems,\nyet can also fail in environments that seem trivial, but the reason for such\nfailures is still poorly understood. In this paper, we contribute a formal\nexplanation of these failures in the particular case of sparse reward and\ndeterministic environments. First, using a very elementary control problem, we\nillustrate that the learning process can get stuck into a fixed point\ncorresponding to a poor solution. Then, generalizing from the studied example,\nwe provide a detailed analysis of the underlying mechanisms which results in a\nnew understanding of one of the convergence regimes of these algorithms. The\nresulting perspective casts a new light on already existing solutions to the\nissues we have highlighted, and suggests other potential approaches.\n", "versions": [{"version": "v1", "created": "Tue, 26 Nov 2019 16:28:09 GMT"}], "update_date": "2019-11-27", "authors_parsed": [["Matheron", "Guillaume", ""], ["Perrin", "Nicolas", ""], ["Sigaud", "Olivier", ""]]}, {"id": "1911.11680", "submitter": "Xi Yin", "authors": "Xi Yin, Ying Tai, Yuge Huang, Xiaoming Liu", "title": "FAN: Feature Adaptation Network for Surveillance Face Recognition and\n  Normalization", "comments": null, "journal-ref": "ACCV2020", "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper studies face recognition (FR) and normalization in surveillance\nimagery. Surveillance FR is a challenging problem that has great values in law\nenforcement. Despite recent progress in conventional FR, less effort has been\ndevoted to surveillance FR. To bridge this gap, we propose a Feature Adaptation\nNetwork (FAN) to jointly perform surveillance FR and normalization. Our face\nnormalization mainly acts on the aspect of image resolution, closely related to\nface super-resolution. However, previous face super-resolution methods require\npaired training data with pixel-to-pixel correspondence, which is typically\nunavailable between real-world low-resolution and high-resolution faces. FAN\ncan leverage both paired and unpaired data as we disentangle the features into\nidentity and non-identity components and adapt the distribution of the identity\nfeatures, which breaks the limit of current face super-resolution methods. We\nfurther propose a random scale augmentation scheme to learn resolution robust\nidentity features, with advantages over previous fixed scale augmentation.\nExtensive experiments on LFW, WIDER FACE, QUML-SurvFace and SCface datasets\nhave shown the effectiveness of our method on surveillance FR and\nnormalization.\n", "versions": [{"version": "v1", "created": "Tue, 26 Nov 2019 16:29:27 GMT"}, {"version": "v2", "created": "Fri, 2 Oct 2020 00:32:02 GMT"}], "update_date": "2020-10-05", "authors_parsed": [["Yin", "Xi", ""], ["Tai", "Ying", ""], ["Huang", "Yuge", ""], ["Liu", "Xiaoming", ""]]}, {"id": "1911.11689", "submitter": "Kurt Stockinger", "authors": "Jonas Heitz, Kurt Stockinger", "title": "Join Query Optimization with Deep Reinforcement Learning Algorithms", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DB cs.AI cs.LG", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Join query optimization is a complex task and is central to the performance\nof query processing. In fact it belongs to the class of NP-hard problems.\nTraditional query optimizers use dynamic programming (DP) methods combined with\na set of rules and restrictions to avoid exhaustive enumeration of all possible\njoin orders. However, DP methods are very resource intensive. Moreover, given\nsimplifying assumptions of attribute independence, traditional query optimizers\nrely on erroneous cost estimations, which can lead to suboptimal query plans.\nRecent success of deep reinforcement learning (DRL) creates new opportunities\nfor the field of query optimization to tackle the above-mentioned problems. In\nthis paper, we present our DRL-based Fully Observed Optimizer (FOOP) which is a\ngeneric query optimization framework that enables plugging in different machine\nlearning algorithms. The main idea of FOOP is to use a data-adaptive learning\nquery optimizer that avoids exhaustive enumerations of join orders and is thus\nsignificantly faster than traditional approaches based on dynamic programming.\nIn particular, we evaluate various DRL-algorithms and show that Proximal Policy\nOptimization significantly outperforms Q-learning based algorithms. Finally we\ndemonstrate how ensemble learning techniques combined with DRL can further\nimprove the query optimizer.\n", "versions": [{"version": "v1", "created": "Tue, 26 Nov 2019 16:48:25 GMT"}], "update_date": "2019-11-27", "authors_parsed": [["Heitz", "Jonas", ""], ["Stockinger", "Kurt", ""]]}, {"id": "1911.11691", "submitter": "Siavash Golkar", "authors": "Siavash Golkar", "title": "Emergent Structures and Lifetime Structure Evolution in Artificial\n  Neural Networks", "comments": "Proceedings of NeurIPS workshop on Real Neurons & Hidden Units. 5\n  Pages, 6 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.NE q-bio.NC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Motivated by the flexibility of biological neural networks whose connectivity\nstructure changes significantly during their lifetime, we introduce the\nUnstructured Recursive Network (URN) and demonstrate that it can exhibit\nsimilar flexibility during training via gradient descent. We show empirically\nthat many of the different neural network structures commonly used in practice\ntoday (including fully connected, locally connected and residual networks of\ndifferent depths and widths) can emerge dynamically from the same URN. These\ndifferent structures can be derived using gradient descent on a single general\nloss function where the structure of the data and the relative strengths of\nvarious regulator terms determine the structure of the emergent network. We\nshow that this loss function and the regulators arise naturally when\nconsidering the symmetries of the network as well as the geometric properties\nof the input data.\n", "versions": [{"version": "v1", "created": "Tue, 26 Nov 2019 16:51:37 GMT"}], "update_date": "2019-11-27", "authors_parsed": [["Golkar", "Siavash", ""]]}, {"id": "1911.11699", "submitter": "Jacopo Panerati", "authors": "Rupert Mitchell, Jenny Fletcher, Jacopo Panerati, Amanda Prorok\n  (University of Cambridge)", "title": "Multi-Vehicle Mixed-Reality Reinforcement Learning for Autonomous\n  Multi-Lane Driving", "comments": "10 pages, 8 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.AI cs.LG cs.MA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Autonomous driving promises to transform road transport. Multi-vehicle and\nmulti-lane scenarios, however, present unique challenges due to constrained\nnavigation and unpredictable vehicle interactions. Learning-based\nmethods---such as deep reinforcement learning---are emerging as a promising\napproach to automatically design intelligent driving policies that can cope\nwith these challenges. Yet, the process of safely learning multi-vehicle\ndriving behaviours is hard: while collisions---and their near-avoidance---are\nessential to the learning process, directly executing immature policies on\nautonomous vehicles raises considerable safety concerns. In this article, we\npresent a safe and efficient framework that enables the learning of driving\npolicies for autonomous vehicles operating in a shared workspace, where the\nabsence of collisions cannot be guaranteed. Key to our learning procedure is a\nsim2real approach that uses real-world online policy adaptation in a\nmixed-reality setup, where other vehicles and static obstacles exist in the\nvirtual domain. This allows us to perform safe learning by simulating (and\nlearning from) collisions between the learning agent(s) and other objects in\nvirtual reality. Our results demonstrate that, after only a few runs in\nmixed-reality, collisions are significantly reduced.\n", "versions": [{"version": "v1", "created": "Tue, 26 Nov 2019 17:08:40 GMT"}, {"version": "v2", "created": "Mon, 10 Feb 2020 21:06:43 GMT"}], "update_date": "2020-02-12", "authors_parsed": [["Mitchell", "Rupert", "", "University of Cambridge"], ["Fletcher", "Jenny", "", "University of Cambridge"], ["Panerati", "Jacopo", "", "University of Cambridge"], ["Prorok", "Amanda", "", "University of Cambridge"]]}, {"id": "1911.11702", "submitter": "Miguel Fabian Romero Rondon", "authors": "Miguel Fabian Romero Rondon, Lucile Sassatelli, Ramon Aparicio Pardo,\n  Frederic Precioso", "title": "Revisiting Deep Architectures for Head Motion Prediction in 360{\\deg}\n  Videos", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG eess.IV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider predicting the user's head motion in 360-degree videos, with 2\nmodalities only: the past user's positions and the video content (not knowing\nother users' traces). We make two main contributions. First, we re-examine\nexisting deep-learning approaches for this problem and identify hidden flaws\nfrom a thorough root-cause analysis. Second, from the results of this analysis,\nwe design a new proposal establishing state-of-the-art performance. First,\nre-assessing the existing methods that use both modalities, we obtain the\nsurprising result that they all perform worse than baselines using the user's\ntrajectory only. A root-cause analysis of the metrics, datasets and neural\narchitectures shows in particular that (i) the content can inform the\nprediction for horizons longer than 2 to 3 sec. (existing methods consider\nshorter horizons), and that (ii) to compete with the baselines, it is necessary\nto have a recurrent unit dedicated to process the positions, but this is not\nsufficient. Second, from a re-examination of the problem supported with the\nconcept of Structural-RNN, we design a new deep neural architecture, named\nTRACK. TRACK achieves state-of-the-art performance on all considered datasets\nand prediction horizons, outperforming competitors by up to 20 percent on\nfocus-type videos and horizons 2-5 seconds. The entire framework (codes and\ndatasets) is online and received an ACM reproducibility badge.\n", "versions": [{"version": "v1", "created": "Tue, 26 Nov 2019 17:13:00 GMT"}, {"version": "v2", "created": "Wed, 12 Feb 2020 14:07:32 GMT"}, {"version": "v3", "created": "Wed, 14 Apr 2021 16:13:35 GMT"}], "update_date": "2021-04-15", "authors_parsed": [["Rondon", "Miguel Fabian Romero", ""], ["Sassatelli", "Lucile", ""], ["Pardo", "Ramon Aparicio", ""], ["Precioso", "Frederic", ""]]}, {"id": "1911.11717", "submitter": "Cristiano Fanelli", "authors": "Cristiano Fanelli and Jary Pomponi", "title": "DeepRICH: Learning Deeply Cherenkov Detectors", "comments": "14 pages, 9 figures, preprint", "journal-ref": "2020 Mach. Learn.: Sci. Technol. 1 015010", "doi": "10.1088/2632-2153/ab845a", "report-no": "JLAB-PHY-20-3179", "categories": "physics.data-an cs.LG hep-ex nucl-ex physics.ins-det", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Imaging Cherenkov detectors are largely used for particle identification\n(PID) in nuclear and particle physics experiments, where developing fast\nreconstruction algorithms is becoming of paramount importance to allow for near\nreal time calibration and data quality control, as well as to speed up offline\nanalysis of large amount of data. In this paper we present DeepRICH, a novel\ndeep learning algorithm for fast reconstruction which can be applied to\ndifferent imaging Cherenkov detectors. The core of our architecture is a\ngenerative model which leverages on a custom Variational Auto-encoder (VAE)\ncombined to Maximum Mean Discrepancy (MMD), with a Convolutional Neural Network\n(CNN) extracting features from the space of the latent variables for\nclassification. A thorough comparison with the simulation/reconstruction\npackage FastDIRC is discussed in the text. DeepRICH has the advantage to bypass\nlow-level details needed to build a likelihood, allowing for a sensitive\nimprovement in computation time at potentially the same reconstruction\nperformance of other established reconstruction algorithms. In the conclusions,\nwe address the implications and potentialities of this work, discussing\npossible future extensions and generalization.\n", "versions": [{"version": "v1", "created": "Tue, 26 Nov 2019 17:46:35 GMT"}, {"version": "v2", "created": "Wed, 18 Dec 2019 22:22:51 GMT"}], "update_date": "2020-05-21", "authors_parsed": [["Fanelli", "Cristiano", ""], ["Pomponi", "Jary", ""]]}, {"id": "1911.11725", "submitter": "Nino Arsov", "authors": "Nino Arsov, Goran Velinov, Aleksandar S. Dimovski, Bojana Koteska,\n  Dragan Sahpaski, Margina Kon-Popovska", "title": "Prediction of Horizontal Data Partitioning Through Query Execution Cost\n  Estimation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.DB cs.DC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The excessively increased volume of data in modern data management systems\ndemands an improved system performance, frequently provided by data\ndistribution, system scalability and performance optimization techniques.\nOptimized horizontal data partitioning has a significant influence of\ndistributed data management systems. An optimally partitioned schema found in\nthe early phase of logical database design without loading of real data in the\nsystem and its adaptation to changes of business environment are very important\nfor a successful implementation, system scalability and performance\nimprovement. In this paper we present a novel approach for finding an optimal\nhorizontally partitioned schema that manifests a minimal total execution cost\nof a given database workload. Our approach is based on a formal model that\nenables abstraction of the predicates in the workload queries, and are\nsubsequently used to define all relational fragments. This approach has\npredictive features acquired by simulation of horizontal partitioning, without\nloading any data into the partitions, but instead, altering the statistics in\nthe database catalogs. We define an optimization problem and employ a genetic\nalgorithm (GA) to find an approximately optimal horizontally partitioned\nschema. The solutions to the optimization problem are evaluated using\nPostgreSQL's query optimizer. The initial experimental evaluation of our\napproach confirms its efficiency and correctness, and the numbers imply that\nthe approach is effective in reducing the workload execution cost.\n", "versions": [{"version": "v1", "created": "Tue, 26 Nov 2019 18:02:58 GMT"}], "update_date": "2019-11-27", "authors_parsed": [["Arsov", "Nino", ""], ["Velinov", "Goran", ""], ["Dimovski", "Aleksandar S.", ""], ["Koteska", "Bojana", ""], ["Sahpaski", "Dragan", ""], ["Kon-Popovska", "Margina", ""]]}, {"id": "1911.11726", "submitter": "Nino Arsov", "authors": "Nino Arsov and Georgina Mirceva", "title": "Network Embedding: An Overview", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.SI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Networks are one of the most powerful structures for modeling problems in the\nreal world. Downstream machine learning tasks defined on networks have the\npotential to solve a variety of problems. With link prediction, for instance,\none can predict whether two persons will become friends on a social network.\nMany machine learning algorithms, however, require that each input example is a\nreal vector. Network embedding encompasses various methods for unsupervised,\nand sometimes supervised, learning of feature representations of nodes and\nlinks in a network. Typically, embedding methods are based on the assumption\nthat the similarity between nodes in the network should be reflected in the\nlearned feature representations. In this paper, we review significant\ncontributions to network embedding in the last decade. In particular, we look\nat four methods: Spectral Clustering, DeepWalk, Large-scale Information Network\nEmbedding (LINE), and node2vec. We describe each method and list its advantages\nand shortcomings. In addition, we give examples of real-world machine learning\nproblems on networks in which the embedding is critical in order to maximize\nthe predictive performance of the machine learning task. Finally, we take a\nlook at research trends and state-of-the art methods in the research on network\nembedding.\n", "versions": [{"version": "v1", "created": "Tue, 26 Nov 2019 18:03:08 GMT"}], "update_date": "2019-11-27", "authors_parsed": [["Arsov", "Nino", ""], ["Mirceva", "Georgina", ""]]}, {"id": "1911.11728", "submitter": "Sahil Bhatia", "authors": "Sahil Bhatia, Saswat Padhi, Nagarajan Natarajan, Rahul Sharma, Prateek\n  Jain", "title": "On Scaling Data-Driven Loop Invariant Inference", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.PL cs.SE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Automated synthesis of inductive invariants is an important problem in\nsoftware verification. Once all the invariants have been specified, software\nverification reduces to checking of verification conditions. Although static\nanalyses to infer invariants have been studied for over forty years, recent\nyears have seen a flurry of data-driven invariant inference techniques which\nguess invariants from examples instead of analyzing program text. However,\nthese techniques have been demonstrated to scale only to programs with a small\nnumber of variables. In this paper, we study these scalability issues and\naddress them in our tool oasis that improves the scale of data-driven invariant\ninference and outperforms state-of-the-art systems on benchmarks from the\ninvariant inference track of the Syntax Guided Synthesis competition.\n", "versions": [{"version": "v1", "created": "Tue, 26 Nov 2019 18:05:46 GMT"}, {"version": "v2", "created": "Thu, 16 Jul 2020 17:34:27 GMT"}], "update_date": "2020-07-17", "authors_parsed": [["Bhatia", "Sahil", ""], ["Padhi", "Saswat", ""], ["Natarajan", "Nagarajan", ""], ["Sharma", "Rahul", ""], ["Jain", "Prateek", ""]]}, {"id": "1911.11737", "submitter": "John Thickstun", "authors": "Harsh Verma, John Thickstun", "title": "Convolutional Composer Classification", "comments": "8 pages, published at ISMIR 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.SD eess.AS stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper investigates end-to-end learnable models for attributing composers\nto musical scores. We introduce several pooled, convolutional architectures for\nthis task and draw connections between our approach and classical learning\napproaches based on global and n-gram features. We evaluate models on a corpus\nof 2,500 scores from the KernScores collection, authored by a variety of\ncomposers spanning the Renaissance era to the early 20th century. This corpus\nhas substantial overlap with the corpora used in several previous, smaller\nstudies; we compare our results on subsets of the corpus to these previous\nworks.\n", "versions": [{"version": "v1", "created": "Tue, 26 Nov 2019 18:17:14 GMT"}], "update_date": "2019-11-27", "authors_parsed": [["Verma", "Harsh", ""], ["Thickstun", "John", ""]]}, {"id": "1911.11743", "submitter": "Vinoj Yasanga Jayasundara Magalle Hewa", "authors": "Vinoj Jayasundara, Hirunima Jayasekara, Tharaka Samarasinghe, Kasun T.\n  Hemachandra", "title": "Device-Free User Authentication, Activity Classification and Tracking\n  using Passive Wi-Fi Sensing: A Deep Learning Based Approach", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.HC eess.SP stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Privacy issues related to video camera feeds have led to a growing need for\nsuitable alternatives that provide functionalities such as user authentication,\nactivity classification and tracking in a noninvasive manner. Existing\ninfrastructure makes Wi-Fi a possible candidate, yet, utilizing traditional\nsignal processing methods to extract information necessary to fully\ncharacterize an event by sensing weak ambient Wi-Fi signals is deemed to be\nchallenging. This paper introduces a novel end to-end deep learning framework\nthat simultaneously predicts the identity, activity and the location of a user\nto create user profiles similar to the information provided through a video\ncamera. The system is fully autonomous and requires zero user intervention\nunlike systems that require user-initiated initialization, or a user held\ntransmitting device to facilitate the prediction. The system can also predict\nthe trajectory of the user by predicting the location of a user over\nconsecutive time steps. The performance of the system is evaluated through\nexperiments.\n", "versions": [{"version": "v1", "created": "Tue, 26 Nov 2019 18:27:50 GMT"}], "update_date": "2019-11-27", "authors_parsed": [["Jayasundara", "Vinoj", ""], ["Jayasekara", "Hirunima", ""], ["Samarasinghe", "Tharaka", ""], ["Hemachandra", "Kasun T.", ""]]}, {"id": "1911.11744", "submitter": "Simon Stepputtis", "authors": "Simon Stepputtis, Joseph Campbell, Mariano Phielipp, Chitta Baral,\n  Heni Ben Amor", "title": "Imitation Learning of Robot Policies by Combining Language, Vision and\n  Demonstration", "comments": "Accepted to the NeurIPS 2019 Workshop on Robot Learning: Control and\n  Interaction in the Real World, Vancouver, Canada", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.CL cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this work we propose a novel end-to-end imitation learning approach which\ncombines natural language, vision, and motion information to produce an\nabstract representation of a task, which in turn is used to synthesize specific\nmotion controllers at run-time. This multimodal approach enables generalization\nto a wide variety of environmental conditions and allows an end-user to direct\na robot policy through verbal communication. We empirically validate our\napproach with an extensive set of simulations and show that it achieves a high\ntask success rate over a variety of conditions while remaining amenable to\nprobabilistic interpretability.\n", "versions": [{"version": "v1", "created": "Tue, 26 Nov 2019 18:27:51 GMT"}], "update_date": "2019-11-27", "authors_parsed": [["Stepputtis", "Simon", ""], ["Campbell", "Joseph", ""], ["Phielipp", "Mariano", ""], ["Baral", "Chitta", ""], ["Amor", "Heni Ben", ""]]}, {"id": "1911.11746", "submitter": "Alison Jenkins", "authors": "Alison Jenkins", "title": "Defending Against Adversarial Machine Learning", "comments": "adversarial machine learning, accuracy, probability, feature mask,\n  genetic algorithm, authorship attribution system, GEFeS", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  An Adversarial System to attack and an Authorship Attribution System (AAS) to\ndefend itself against the attacks are analyzed. Defending a system against\nattacks from an adversarial machine learner can be done by randomly switching\nbetween models for the system, by detecting and reacting to changes in the\ndistribution of normal inputs, or by using other methods. Adversarial machine\nlearning is used to identify a system that is being used to map system inputs\nto outputs. Three types of machine learners are using for the model that is\nbeing attacked. The machine learners that are used to model the system being\nattacked are a Radial Basis Function Support Vector Machine, a Linear Support\nVector Machine, and a Feedforward Neural Network. The feature masks are evolved\nusing accuracy as the fitness measure. The system defends itself against\nadversarial machine learning attacks by identifying inputs that do not match\nthe probability distribution of normal inputs. The system also defends itself\nagainst adversarial attacks by randomly switching between the feature masks\nbeing used to map system inputs to outputs.\n", "versions": [{"version": "v1", "created": "Tue, 26 Nov 2019 18:28:47 GMT"}], "update_date": "2019-11-27", "authors_parsed": [["Jenkins", "Alison", ""]]}, {"id": "1911.11750", "submitter": "Nino Arsov", "authors": "Nino Arsov, Milan Dukovski, Blagoja Evkoski, Stefan Cvetkovski", "title": "A Measure of Similarity in Textual Data Using Spearman's Rank\n  Correlation Coefficient", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CL cs.IR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In the last decade, many diverse advances have occurred in the field of\ninformation extraction from data. Information extraction in its simplest form\ntakes place in computing environments, where structured data can be extracted\nthrough a series of queries. The continuous expansion of quantities of data\nhave therefore provided an opportunity for knowledge extraction (KE) from a\ntextual document (TD). A typical problem of this kind is the extraction of\ncommon characteristics and knowledge from a group of TDs, with the possibility\nto group such similar TDs in a process known as clustering. In this paper we\npresent a technique for such KE among a group of TDs related to the common\ncharacteristics and meaning of their content. Our technique is based on the\nSpearman's Rank Correlation Coefficient (SRCC), for which the conducted\nexperiments have proven to be comprehensive measure to achieve a high-quality\nKE.\n", "versions": [{"version": "v1", "created": "Tue, 26 Nov 2019 18:38:59 GMT"}], "update_date": "2019-11-27", "authors_parsed": [["Arsov", "Nino", ""], ["Dukovski", "Milan", ""], ["Evkoski", "Blagoja", ""], ["Cvetkovski", "Stefan", ""]]}, {"id": "1911.11756", "submitter": "Alexander Hanbo Li", "authors": "Alexander Hanbo Li, Abhinav Sethy", "title": "Semi-Supervised Learning for Text Classification by Layer Partitioning", "comments": "ASRU 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CL stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Most recent neural semi-supervised learning algorithms rely on adding small\nperturbation to either the input vectors or their representations. These\nmethods have been successful on computer vision tasks as the images form a\ncontinuous manifold, but are not appropriate for discrete input such as\nsentence. To adapt these methods to text input, we propose to decompose a\nneural network $M$ into two components $F$ and $U$ so that $M = U\\circ F$. The\nlayers in $F$ are then frozen and only the layers in $U$ will be updated during\nmost time of the training. In this way, $F$ serves as a feature extractor that\nmaps the input to high-level representation and adds systematical noise using\ndropout. We can then train $U$ using any state-of-the-art SSL algorithms such\nas $\\Pi$-model, temporal ensembling, mean teacher, etc. Furthermore, this\ngradually unfreezing schedule also prevents a pretrained model from\ncatastrophic forgetting. The experimental results demonstrate that our approach\nprovides improvements when compared to state of the art methods especially on\nshort texts.\n", "versions": [{"version": "v1", "created": "Tue, 26 Nov 2019 18:47:48 GMT"}], "update_date": "2019-11-27", "authors_parsed": [["Li", "Alexander Hanbo", ""], ["Sethy", "Abhinav", ""]]}, {"id": "1911.11758", "submitter": "Yuheng Li", "authors": "Yuheng Li, Krishna Kumar Singh, Utkarsh Ojha, Yong Jae Lee", "title": "MixNMatch: Multifactor Disentanglement and Encoding for Conditional\n  Image Generation", "comments": "CVPR 2020 camera ready", "journal-ref": "CVPR 2020", "doi": null, "report-no": null, "categories": "cs.CV cs.GR cs.LG eess.IV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present MixNMatch, a conditional generative model that learns to\ndisentangle and encode background, object pose, shape, and texture from real\nimages with minimal supervision, for mix-and-match image generation. We build\nupon FineGAN, an unconditional generative model, to learn the desired\ndisentanglement and image generator, and leverage adversarial joint image-code\ndistribution matching to learn the latent factor encoders. MixNMatch requires\nbounding boxes during training to model background, but requires no other\nsupervision. Through extensive experiments, we demonstrate MixNMatch's ability\nto accurately disentangle, encode, and combine multiple factors for\nmix-and-match image generation, including sketch2color, cartoon2img, and\nimg2gif applications. Our code/models/demo can be found at\nhttps://github.com/Yuheng-Li/MixNMatch\n", "versions": [{"version": "v1", "created": "Tue, 26 Nov 2019 18:49:39 GMT"}, {"version": "v2", "created": "Wed, 27 Nov 2019 06:17:57 GMT"}, {"version": "v3", "created": "Mon, 13 Apr 2020 17:56:13 GMT"}], "update_date": "2020-04-14", "authors_parsed": [["Li", "Yuheng", ""], ["Singh", "Krishna Kumar", ""], ["Ojha", "Utkarsh", ""], ["Lee", "Yong Jae", ""]]}, {"id": "1911.11759", "submitter": "Xiuye Gu", "authors": "Xiuye Gu, Weixin Luo, Michael S. Ryoo, Yong Jae Lee", "title": "Password-conditioned Anonymization and Deanonymization with Face\n  Identity Transformers", "comments": "ECCV 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG eess.IV", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Cameras are prevalent in our daily lives, and enable many useful systems\nbuilt upon computer vision technologies such as smart cameras and home robots\nfor service applications. However, there is also an increasing societal concern\nas the captured images/videos may contain privacy-sensitive information (e.g.,\nface identity). We propose a novel face identity transformer which enables\nautomated photo-realistic password-based anonymization as well as\ndeanonymization of human faces appearing in visual data. Our face identity\ntransformer is trained to (1) remove face identity information after\nanonymization, (2) make the recovery of the original face possible when given\nthe correct password, and (3) return a wrong--but photo-realistic--face given a\nwrong password. Extensive experiments show that our approach enables multimodal\npassword-conditioned face anonymizations and deanonymizations, without\nsacrificing privacy compared to existing anonymization approaches.\n", "versions": [{"version": "v1", "created": "Tue, 26 Nov 2019 18:50:53 GMT"}, {"version": "v2", "created": "Fri, 29 Nov 2019 20:42:15 GMT"}, {"version": "v3", "created": "Fri, 24 Jul 2020 13:10:01 GMT"}, {"version": "v4", "created": "Wed, 30 Sep 2020 15:52:50 GMT"}], "update_date": "2020-10-01", "authors_parsed": [["Gu", "Xiuye", ""], ["Luo", "Weixin", ""], ["Ryoo", "Michael S.", ""], ["Lee", "Yong Jae", ""]]}, {"id": "1911.11767", "submitter": "Earl Bellinger", "authors": "Earl P. Bellinger, Shashi M. Kanbur, Anupam Bhardwaj, and Marcella\n  Marconi", "title": "When a Period Is Not a Full Stop: Light Curve Structure Reveals\n  Fundamental Parameters of Cepheid and RR Lyrae Stars", "comments": "Accepted for publication in MNRAS. Source code available at\n  https://github.com/earlbellinger/Cepheid-neural-network", "journal-ref": null, "doi": "10.1093/mnras/stz3292", "report-no": null, "categories": "astro-ph.SR astro-ph.IM cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The period of pulsation and the structure of the light curve for Cepheid and\nRR Lyrae variables depend on the fundamental parameters of the star: mass,\nradius, luminosity, and effective temperature. Here we train artificial neural\nnetworks on theoretical pulsation models to predict the fundamental parameters\nof these stars based on their period and light curve structure. We find\nsignificant improvements to estimates of these parameters made using light\ncurve structure and period over estimates made using only the period. Given\nthat the models are able to reproduce most observables, we find that the\nfundamental parameters of these stars can be estimated up to 60% more\naccurately when light curve structure is taken into consideration. We quantify\nwhich aspects of light curve structure are most important in determining\nfundamental parameters, and find for example that the second Fourier amplitude\ncomponent of RR Lyrae light curves is even more important than period in\ndetermining the effective temperature of the star. We apply this analysis to\nobservations of hundreds Cepheids in the Large Magellanic Cloud and thousands\nof RR Lyrae in the Magellanic Clouds and Galactic bulge to produce catalogs of\nestimated masses, radii, luminosities, and other parameters of these stars. As\nan example application, we estimate Wesenheit indices and use those to derive\ndistance moduli to the Magellanic Clouds of $\\mu_{\\text{LMC},\\text{CEP}} =\n18.688 \\pm 0.093$, $\\mu_{\\text{LMC},\\text{RRL}} = 18.52 \\pm 0.14$, and\n$\\mu_{\\text{SMC},\\text{RRL}} = 18.88 \\pm 0.17$ mag.\n", "versions": [{"version": "v1", "created": "Mon, 25 Nov 2019 19:00:06 GMT"}], "update_date": "2020-01-08", "authors_parsed": [["Bellinger", "Earl P.", ""], ["Kanbur", "Shashi M.", ""], ["Bhardwaj", "Anupam", ""], ["Marconi", "Marcella", ""]]}, {"id": "1911.11772", "submitter": "Ali Basirat", "authors": "Ali Basirat", "title": "Shifted Randomized Singular Value Decomposition", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We extend the randomized singular value decomposition (SVD) algorithm\n\\citep{Halko2011finding} to estimate the SVD of a shifted data matrix without\nexplicitly constructing the matrix in the memory. With no loss in the accuracy\nof the original algorithm, the extended algorithm provides for a more efficient\nway of matrix factorization. The algorithm facilitates the low-rank\napproximation and principal component analysis (PCA) of off-center data\nmatrices. When applied to different types of data matrices, our experimental\nresults confirm the advantages of the extensions made to the original\nalgorithm.\n", "versions": [{"version": "v1", "created": "Tue, 26 Nov 2019 14:38:42 GMT"}, {"version": "v2", "created": "Thu, 28 Nov 2019 12:12:23 GMT"}], "update_date": "2019-12-02", "authors_parsed": [["Basirat", "Ali", ""]]}, {"id": "1911.11774", "submitter": "Chencheng Cai", "authors": "Chencheng Cai and Rong Chen and Han Xiao", "title": "Matrix Completion using Kronecker Product Approximation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG stat.ME", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A matrix completion problem is to recover the missing entries in a partially\nobserved matrix. Most of the existing matrix completion methods assume a low\nrank structure of the underlying complete matrix. In this paper, we introduce\nan alternative and more general form of the underlying complete matrix, which\nassumes a low Kronecker rank instead of a low regular rank, but includes the\nlatter as a special case. The extra flexibility allows for a much more\nparsimonious representation of the underlying matrix, but also raises the\nchallenge of determining the proper Kronecker product configuration to be used.\nWe find that the configuration can be identified using the mean squared error\ncriterion as well as a modified cross-validation criterion. We establish the\nconsistency of this procedure under suitable conditions on the signal-to-noise\nratio. A aggregation procedure is also proposed to deal with special missing\npatterns and complex underlying structures. Both numerical and empirical\nstudies are carried out to demonstrate the performance of the new method.\n", "versions": [{"version": "v1", "created": "Tue, 26 Nov 2019 16:48:31 GMT"}, {"version": "v2", "created": "Fri, 6 Dec 2019 03:04:00 GMT"}, {"version": "v3", "created": "Fri, 13 Nov 2020 18:18:31 GMT"}], "update_date": "2020-11-16", "authors_parsed": [["Cai", "Chencheng", ""], ["Chen", "Rong", ""], ["Xiao", "Han", ""]]}, {"id": "1911.11775", "submitter": "Omar Peracha", "authors": "Omar Peracha", "title": "Improving Polyphonic Music Models with Feature-Rich Encoding", "comments": "Proceedings of the 21st International Society for Music Information\n  Retrieval Conference, ISMIR 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SD cs.LG eess.AS stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  This paper explores sequential modelling of polyphonic music with deep neural\nnetworks. While recent breakthroughs have focussed on network architecture, we\ndemonstrate that the representation of the sequence can make an equally\nsignificant contribution to the performance of the model as measured by\nvalidation set loss. By extracting salient features inherent to the training\ndataset, the model can either be conditioned on these features or trained to\npredict said features as extra components of the sequences being modelled. We\nshow that training a neural network to predict a seemingly more complex\nsequence, with extra features included in the series being modelled, can\nimprove overall model performance significantly. We first introduce TonicNet, a\nGRU-based model trained to initially predict the chord at a given time-step\nbefore then predicting the notes of each voice at that time-step, in contrast\nwith the typical approach of predicting only the notes. We then evaluate\nTonicNet on the canonical JSB Chorales dataset and obtain state-of-the-art\nresults.\n", "versions": [{"version": "v1", "created": "Tue, 26 Nov 2019 18:38:30 GMT"}, {"version": "v2", "created": "Mon, 3 Aug 2020 21:54:24 GMT"}, {"version": "v3", "created": "Mon, 14 Sep 2020 22:18:36 GMT"}], "update_date": "2020-09-16", "authors_parsed": [["Peracha", "Omar", ""]]}, {"id": "1911.11776", "submitter": "Takuhiro Kaneko", "authors": "Takuhiro Kaneko, Tatsuya Harada", "title": "Noise Robust Generative Adversarial Networks", "comments": "Accepted to CVPR 2020. Project page:\n  https://takuhirok.github.io/NR-GAN/", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG eess.IV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Generative adversarial networks (GANs) are neural networks that learn data\ndistributions through adversarial training. In intensive studies, recent GANs\nhave shown promising results for reproducing training images. However, in spite\nof noise, they reproduce images with fidelity. As an alternative, we propose a\nnovel family of GANs called noise robust GANs (NR-GANs), which can learn a\nclean image generator even when training images are noisy. In particular,\nNR-GANs can solve this problem without having complete noise information (e.g.,\nthe noise distribution type, noise amount, or signal-noise relationship). To\nachieve this, we introduce a noise generator and train it along with a clean\nimage generator. However, without any constraints, there is no incentive to\ngenerate an image and noise separately. Therefore, we propose distribution and\ntransformation constraints that encourage the noise generator to capture only\nthe noise-specific components. In particular, considering such constraints\nunder different assumptions, we devise two variants of NR-GANs for\nsignal-independent noise and three variants of NR-GANs for signal-dependent\nnoise. On three benchmark datasets, we demonstrate the effectiveness of NR-GANs\nin noise robust image generation. Furthermore, we show the applicability of\nNR-GANs in image denoising. Our code is available at\nhttps://github.com/takuhirok/NR-GAN/.\n", "versions": [{"version": "v1", "created": "Tue, 26 Nov 2019 18:42:54 GMT"}, {"version": "v2", "created": "Tue, 31 Mar 2020 16:54:37 GMT"}], "update_date": "2020-04-01", "authors_parsed": [["Kaneko", "Takuhiro", ""], ["Harada", "Tatsuya", ""]]}, {"id": "1911.11779", "submitter": "Eliu Huerta", "authors": "E. A. Huerta, Gabrielle Allen, Igor Andreoni, Javier M. Antelis,\n  Etienne Bachelet, Bruce Berriman, Federica Bianco, Rahul Biswas, Matias\n  Carrasco, Kyle Chard, Minsik Cho, Philip S. Cowperthwaite, Zachariah B.\n  Etienne, Maya Fishbach, Francisco F\\\"orster, Daniel George, Tom Gibbs,\n  Matthew Graham, William Gropp, Robert Gruendl, Anushri Gupta, Roland Haas,\n  Sarah Habib, Elise Jennings, Margaret W. G. Johnson, Erik Katsavounidis,\n  Daniel S. Katz, Asad Khan, Volodymyr Kindratenko, William T. C. Kramer, Xin\n  Liu, Ashish Mahabal, Zsuzsa Marka, Kenton McHenry, Jonah Miller, Claudia\n  Moreno, Mark Neubauer, Steve Oberlin, Alexander R. Olivas, Donald Petravick,\n  Adam Rebei, Shawn Rosofsky, Milton Ruiz, Aaron Saxton, Bernard F. Schutz,\n  Alex Schwing, Ed Seidel, Stuart L. Shapiro, Hongyu Shen, Yue Shen, Leo\n  Singer, Brigitta M. Sip\\H{o}cz, Lunan Sun, John Towns, Antonios Tsokaros, Wei\n  Wei, Jack Wells, Timothy J. Williams, Jinjun Xiong and Zhizhen Zhao", "title": "Enabling real-time multi-messenger astrophysics discoveries with deep\n  learning", "comments": "Invited Expert Recommendation for Nature Reviews Physics. The art\n  work produced by E. A. Huerta and Shawn Rosofsky for this article was used by\n  Carl Conway to design the cover of the October 2019 issue of Nature Reviews\n  Physics", "journal-ref": "Nature Reviews Physics volume 1, pages 600-608 (2019)", "doi": "10.1038/s42254-019-0097-4", "report-no": null, "categories": "gr-qc astro-ph.HE astro-ph.IM cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Multi-messenger astrophysics is a fast-growing, interdisciplinary field that\ncombines data, which vary in volume and speed of data processing, from many\ndifferent instruments that probe the Universe using different cosmic\nmessengers: electromagnetic waves, cosmic rays, gravitational waves and\nneutrinos. In this Expert Recommendation, we review the key challenges of\nreal-time observations of gravitational wave sources and their electromagnetic\nand astroparticle counterparts, and make a number of recommendations to\nmaximize their potential for scientific discovery. These recommendations refer\nto the design of scalable and computationally efficient machine learning\nalgorithms; the cyber-infrastructure to numerically simulate astrophysical\nsources, and to process and interpret multi-messenger astrophysics data; the\nmanagement of gravitational wave detections to trigger real-time alerts for\nelectromagnetic and astroparticle follow-ups; a vision to harness future\ndevelopments of machine learning and cyber-infrastructure resources to cope\nwith the big-data requirements; and the need to build a community of experts to\nrealize the goals of multi-messenger astrophysics.\n", "versions": [{"version": "v1", "created": "Tue, 26 Nov 2019 19:00:01 GMT"}], "update_date": "2019-11-28", "authors_parsed": [["Huerta", "E. A.", ""], ["Allen", "Gabrielle", ""], ["Andreoni", "Igor", ""], ["Antelis", "Javier M.", ""], ["Bachelet", "Etienne", ""], ["Berriman", "Bruce", ""], ["Bianco", "Federica", ""], ["Biswas", "Rahul", ""], ["Carrasco", "Matias", ""], ["Chard", "Kyle", ""], ["Cho", "Minsik", ""], ["Cowperthwaite", "Philip S.", ""], ["Etienne", "Zachariah B.", ""], ["Fishbach", "Maya", ""], ["F\u00f6rster", "Francisco", ""], ["George", "Daniel", ""], ["Gibbs", "Tom", ""], ["Graham", "Matthew", ""], ["Gropp", "William", ""], ["Gruendl", "Robert", ""], ["Gupta", "Anushri", ""], ["Haas", "Roland", ""], ["Habib", "Sarah", ""], ["Jennings", "Elise", ""], ["Johnson", "Margaret W. G.", ""], ["Katsavounidis", "Erik", ""], ["Katz", "Daniel S.", ""], ["Khan", "Asad", ""], ["Kindratenko", "Volodymyr", ""], ["Kramer", "William T. C.", ""], ["Liu", "Xin", ""], ["Mahabal", "Ashish", ""], ["Marka", "Zsuzsa", ""], ["McHenry", "Kenton", ""], ["Miller", "Jonah", ""], ["Moreno", "Claudia", ""], ["Neubauer", "Mark", ""], ["Oberlin", "Steve", ""], ["Olivas", "Alexander R.", ""], ["Petravick", "Donald", ""], ["Rebei", "Adam", ""], ["Rosofsky", "Shawn", ""], ["Ruiz", "Milton", ""], ["Saxton", "Aaron", ""], ["Schutz", "Bernard F.", ""], ["Schwing", "Alex", ""], ["Seidel", "Ed", ""], ["Shapiro", "Stuart L.", ""], ["Shen", "Hongyu", ""], ["Shen", "Yue", ""], ["Singer", "Leo", ""], ["Sip\u0151cz", "Brigitta M.", ""], ["Sun", "Lunan", ""], ["Towns", "John", ""], ["Tsokaros", "Antonios", ""], ["Wei", "Wei", ""], ["Wells", "Jack", ""], ["Williams", "Timothy J.", ""], ["Xiong", "Jinjun", ""], ["Zhao", "Zhizhen", ""]]}, {"id": "1911.11789", "submitter": "Yawar Siddiqui", "authors": "Yawar Siddiqui, Julien Valentin, Matthias Nie{\\ss}ner", "title": "ViewAL: Active Learning with Viewpoint Entropy for Semantic Segmentation", "comments": "CVPR2020, Video: https://youtu.be/tAGdx2j-X_g", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose ViewAL, a novel active learning strategy for semantic segmentation\nthat exploits viewpoint consistency in multi-view datasets. Our core idea is\nthat inconsistencies in model predictions across viewpoints provide a very\nreliable measure of uncertainty and encourage the model to perform well\nirrespective of the viewpoint under which objects are observed. To incorporate\nthis uncertainty measure, we introduce a new viewpoint entropy formulation,\nwhich is the basis of our active learning strategy. In addition, we propose\nuncertainty computations on a superpixel level, which exploits inherently\nlocalized signal in the segmentation task, directly lowering the annotation\ncosts. This combination of viewpoint entropy and the use of superpixels allows\nto efficiently select samples that are highly informative for improving the\nnetwork. We demonstrate that our proposed active learning strategy not only\nyields the best-performing models for the same amount of required labeled data,\nbut also significantly reduces labeling effort. For instance, our method\nachieves 95% of maximum achievable network performance using only 7%, 17%, and\n24% labeled data on SceneNet-RGBD, ScanNet, and Matterport3D, respectively. On\nthese datasets, the best state-of-the-art method achieves the same performance\nwith 14%, 27% and 33% labeled data. Finally, we demonstrate that labeling using\nsuperpixels yields the same quality of ground-truth compared to labeling whole\nimages, but requires 25% less time.\n", "versions": [{"version": "v1", "created": "Tue, 26 Nov 2019 19:00:16 GMT"}, {"version": "v2", "created": "Wed, 18 Mar 2020 18:00:31 GMT"}], "update_date": "2020-03-20", "authors_parsed": [["Siddiqui", "Yawar", ""], ["Valentin", "Julien", ""], ["Nie\u00dfner", "Matthias", ""]]}, {"id": "1911.11791", "submitter": "Amir Abdi", "authors": "Amir H. Abdi, Purang Abolmaesumi, Sidney Fels", "title": "A Preliminary Study of Disentanglement With Insights on the Inadequacy\n  of Metrics", "comments": "Disentanglement Challenge - NeurIPS 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Disentangled encoding is an important step towards a better representation\nlearning. However, despite the numerous efforts, there still is no clear winner\nthat captures the independent features of the data in an unsupervised fashion.\nIn this work we empirically evaluate the performance of six unsupervised\ndisentanglement approaches on the mpi3d toy dataset curated and released for\nthe NeurIPS 2019 Disentanglement Challenge. The methods investigated in this\nwork are Beta-VAE, Factor-VAE, DIP-I-VAE, DIP-II-VAE, Info-VAE, and Beta-TCVAE.\nThe capacities of all models were progressively increased throughout the\ntraining and the hyper-parameters were kept intact across experiments. The\nmethods were evaluated based on five disentanglement metrics, namely, DCI,\nFactor-VAE, IRS, MIG, and SAP-Score. Within the limitations of this study, the\nBeta-TCVAE approach was found to outperform its alternatives with respect to\nthe normalized sum of metrics. However, a qualitative study of the encoded\nlatents reveal that there is not a consistent correlation between the reported\nmetrics and the disentanglement potential of the model.\n", "versions": [{"version": "v1", "created": "Tue, 26 Nov 2019 19:01:03 GMT"}], "update_date": "2019-11-28", "authors_parsed": [["Abdi", "Amir H.", ""], ["Abolmaesumi", "Purang", ""], ["Fels", "Sidney", ""]]}, {"id": "1911.11800", "submitter": "Vinoj Yasanga Jayasundara Magalle Hewa", "authors": "Hirunima Jayasekara, Vinoj Jayasundara, Jathushan Rajasegaran, Sandaru\n  Jayasekara, Suranga Seneviratne, Ranga Rodrigo", "title": "TimeCaps: Learning From Time Series Data with Capsule Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Capsule networks excel in understanding spatial relationships in 2D data for\nvision related tasks. Even though they are not designed to capture 1D temporal\nrelationships, with TimeCaps we demonstrate that given the ability, capsule\nnetworks excel in understanding temporal relationships. To this end, we\ngenerate capsules along the temporal and channel dimensions creating two\ntemporal feature detectors which learn contrasting relationships. TimeCaps\nsurpasses the state-of-the-art results by achieving 96.21% accuracy on\nidentifying 13 Electrocardiogram (ECG) signal beat categories, while achieving\non-par results on identifying 30 classes of short audio commands. Further, the\ninstantiation parameters inherently learnt by the capsule networks allow us to\ncompletely parameterize 1D signals which opens various possibilities in signal\nprocessing.\n", "versions": [{"version": "v1", "created": "Tue, 26 Nov 2019 19:28:57 GMT"}, {"version": "v2", "created": "Fri, 3 Jan 2020 16:58:10 GMT"}, {"version": "v3", "created": "Sat, 11 Jan 2020 12:01:24 GMT"}], "update_date": "2020-01-14", "authors_parsed": [["Jayasekara", "Hirunima", ""], ["Jayasundara", "Vinoj", ""], ["Rajasegaran", "Jathushan", ""], ["Jayasekara", "Sandaru", ""], ["Seneviratne", "Suranga", ""], ["Rodrigo", "Ranga", ""]]}, {"id": "1911.11807", "submitter": "Florian Hartmann", "authors": "Florian Hartmann, Sunah Suh, Arkadiusz Komarzewski, Tim D. Smith,\n  Ilana Segall", "title": "Federated Learning for Ranking Browser History Suggestions", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.IR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Federated Learning is a new subfield of machine learning that allows fitting\nmodels without collecting the training data itself. Instead of sharing data,\nusers collaboratively train a model by only sending weight updates to a server.\nTo improve the ranking of suggestions in the Firefox URL bar, we make use of\nFederated Learning to train a model on user interactions in a\nprivacy-preserving way. This trained model replaces a handcrafted heuristic,\nand our results show that users now type over half a character less to find\nwhat they are looking for. To be able to deploy our system to real users\nwithout degrading their experience during training, we design the optimization\nprocess to be robust. To this end, we use a variant of Rprop for optimization,\nand implement additional safeguards. By using a numerical gradient\napproximation technique, our system is able to optimize anything in Firefox\nthat is currently based on handcrafted heuristics. Our paper shows that\nFederated Learning can be used successfully to train models in\nprivacy-respecting ways.\n", "versions": [{"version": "v1", "created": "Tue, 26 Nov 2019 19:45:28 GMT"}], "update_date": "2019-11-28", "authors_parsed": [["Hartmann", "Florian", ""], ["Suh", "Sunah", ""], ["Komarzewski", "Arkadiusz", ""], ["Smith", "Tim D.", ""], ["Segall", "Ilana", ""]]}, {"id": "1911.11815", "submitter": "Xiaoyu Cao", "authors": "Minghong Fang, Xiaoyu Cao, Jinyuan Jia and Neil Zhenqiang Gong", "title": "Local Model Poisoning Attacks to Byzantine-Robust Federated Learning", "comments": "The paper was submitted to Usenix Security Symposium in February 2019\n  and will appear in Usenix Security Symposium 2020; fixing an error in Theorem\n  1", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.DC cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In federated learning, multiple client devices jointly learn a machine\nlearning model: each client device maintains a local model for its local\ntraining dataset, while a master device maintains a global model via\naggregating the local models from the client devices. The machine learning\ncommunity recently proposed several federated learning methods that were\nclaimed to be robust against Byzantine failures (e.g., system failures,\nadversarial manipulations) of certain client devices. In this work, we perform\nthe first systematic study on local model poisoning attacks to federated\nlearning. We assume an attacker has compromised some client devices, and the\nattacker manipulates the local model parameters on the compromised client\ndevices during the learning process such that the global model has a large\ntesting error rate. We formulate our attacks as optimization problems and apply\nour attacks to four recent Byzantine-robust federated learning methods. Our\nempirical results on four real-world datasets show that our attacks can\nsubstantially increase the error rates of the models learnt by the federated\nlearning methods that were claimed to be robust against Byzantine failures of\nsome client devices. We generalize two defenses for data poisoning attacks to\ndefend against our local model poisoning attacks. Our evaluation results show\nthat one defense can effectively defend against our attacks in some cases, but\nthe defenses are not effective enough in other cases, highlighting the need for\nnew defenses against our local model poisoning attacks to federated learning.\n", "versions": [{"version": "v1", "created": "Tue, 26 Nov 2019 20:10:04 GMT"}, {"version": "v2", "created": "Mon, 6 Apr 2020 20:59:34 GMT"}], "update_date": "2020-04-08", "authors_parsed": [["Fang", "Minghong", ""], ["Cao", "Xiaoyu", ""], ["Jia", "Jinyuan", ""], ["Gong", "Neil Zhenqiang", ""]]}, {"id": "1911.11838", "submitter": "He Jia", "authors": "He Jia, Santosh Vempala", "title": "Robustly Clustering a Mixture of Gaussians", "comments": "Some of our proofs were not SoS proofs. Turning them into SoS proofs\n  requires substantial changes and leads to very similar arguments (in fact\n  special cases for k=2) as those given for k-GMMs by Bakshi-Kothari\n  [arXiv2020] and Diakonikolas-Hopkins-Kane-Karmalkar [arXiv2020]. Hence we\n  withdraw the paper", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We give an efficient algorithm for robustly clustering of a mixture of two\narbitrary Gaussians, a central open problem in the theory of computationally\nefficient robust estimation, assuming only that the the means of the component\nGaussians are well-separated or their covariances are well-separated. Our\nalgorithm and analysis extend naturally to robustly clustering mixtures of\nwell-separated strongly logconcave distributions. The mean separation required\nis close to the smallest possible to guarantee that most of the measure of each\ncomponent can be separated by some hyperplane (for covariances, it is the same\ncondition in the second degree polynomial kernel). We also show that for\nGaussian mixtures, separation in total variation distance suffices to achieve\nrobust clustering. Our main tools are a new identifiability criterion based on\nisotropic position and the Fisher discriminant, and a corresponding\nSum-of-Squares convex programming relaxation, of fixed degree.\n", "versions": [{"version": "v1", "created": "Tue, 26 Nov 2019 21:16:17 GMT"}, {"version": "v2", "created": "Fri, 28 Feb 2020 16:15:16 GMT"}, {"version": "v3", "created": "Tue, 17 Mar 2020 16:16:11 GMT"}, {"version": "v4", "created": "Fri, 1 May 2020 19:04:57 GMT"}, {"version": "v5", "created": "Thu, 7 May 2020 17:56:26 GMT"}, {"version": "v6", "created": "Sun, 31 May 2020 16:06:58 GMT"}], "update_date": "2020-06-02", "authors_parsed": [["Jia", "He", ""], ["Vempala", "Santosh", ""]]}, {"id": "1911.11853", "submitter": "Antonio Ramires", "authors": "Ant\\'onio Ramires, Pritish Chandna, Xavier Favory, Emilia G\\'omez,\n  Xavier Serra", "title": "Neural Percussive Synthesis Parameterised by High-Level Timbral Features", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.AS cs.LG cs.SD stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a deep neural network-based methodology for synthesising\npercussive sounds with control over high-level timbral characteristics of the\nsounds. This approach allows for intuitive control of a synthesizer, enabling\nthe user to shape sounds without extensive knowledge of signal processing. We\nuse a feedforward convolutional neural network-based architecture, which is\nable to map input parameters to the corresponding waveform. We propose two\ndatasets to evaluate our approach on both a restrictive context, and in one\ncovering a broader spectrum of sounds. The timbral features used as parameters\nare taken from recent literature in signal processing. We also use these\nfeatures for evaluation and validation of the presented model, to ensure that\nchanging the input parameters produces a congruent waveform with the desired\ncharacteristics. Finally, we evaluate the quality of the output sound using a\nsubjective listening test. We provide sound examples and the system's source\ncode for reproducibility.\n", "versions": [{"version": "v1", "created": "Mon, 25 Nov 2019 11:26:51 GMT"}, {"version": "v2", "created": "Fri, 3 Apr 2020 10:34:14 GMT"}], "update_date": "2020-04-06", "authors_parsed": [["Ramires", "Ant\u00f3nio", ""], ["Chandna", "Pritish", ""], ["Favory", "Xavier", ""], ["G\u00f3mez", "Emilia", ""], ["Serra", "Xavier", ""]]}, {"id": "1911.11855", "submitter": "Badong Chen", "authors": "Badong Chen, Zhuang Li, Yingsong Li, Pengju Ren", "title": "Asymmetric Correntropy for Robust Adaptive Filtering", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.SP cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In recent years, correntropy has been seccessfully applied to robust adaptive\nfiltering to eliminate adverse effects of impulsive noises or outliers.\nCorrentropy is generally defined as the expectation of a Gaussian kernel\nbetween two random variables. This definition is reasonable when the error\nbetween the two random variables is symmetrically distributed around zero. For\nthe case of asymmetric error distribution, the symmetric Gaussian kernel is\nhowever inappropriate and cannot adapt to the error distribution well. To\naddress this problem, in this letter we propose a new variant of correntropy,\nnamed asymmetric correntropy, which uses an asymmetric Gaussian model as the\nkernel function. In addition, a robust adaptive filtering algorithm based on\nasymmetric correntropy is developed and its steadystate convergence performance\nis analyzed. Simulations are provided to confirm the theoretical results and\ngood performance of the proposed algorithm.\n", "versions": [{"version": "v1", "created": "Thu, 21 Nov 2019 12:02:40 GMT"}], "update_date": "2019-11-28", "authors_parsed": [["Chen", "Badong", ""], ["Li", "Zhuang", ""], ["Li", "Yingsong", ""], ["Ren", "Pengju", ""]]}, {"id": "1911.11856", "submitter": "Jonathan Kuck", "authors": "Jonathan Kuck and Tri Dao and Hamid Rezatofighi and Ashish Sabharwal\n  and Stefano Ermon", "title": "Approximating the Permanent by Sampling from Adaptive Partitions", "comments": "19 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Computing the permanent of a non-negative matrix is a core problem with\npractical applications ranging from target tracking to statistical\nthermodynamics. However, this problem is also #P-complete, which leaves little\nhope for finding an exact solution that can be computed efficiently. While the\nproblem admits a fully polynomial randomized approximation scheme, this method\nhas seen little use because it is both inefficient in practice and difficult to\nimplement. We present AdaPart, a simple and efficient method for drawing exact\nsamples from an unnormalized distribution. Using AdaPart, we show how to\nconstruct tight bounds on the permanent which hold with high probability, with\nguaranteed polynomial runtime for dense matrices. We find that AdaPart can\nprovide empirical speedups exceeding 25x over prior sampling methods on\nmatrices that are challenging for variational based approaches. Finally, in the\ncontext of multi-target tracking, exact sampling from the distribution defined\nby the matrix permanent allows us to use the optimal proposal distribution\nduring particle filtering. Using AdaPart, we show that this leads to improved\ntracking performance using an order of magnitude fewer samples.\n", "versions": [{"version": "v1", "created": "Tue, 26 Nov 2019 22:05:28 GMT"}], "update_date": "2019-11-28", "authors_parsed": [["Kuck", "Jonathan", ""], ["Dao", "Tri", ""], ["Rezatofighi", "Hamid", ""], ["Sabharwal", "Ashish", ""], ["Ermon", "Stefano", ""]]}, {"id": "1911.11879", "submitter": "Be\\~nat Mencia Uranga", "authors": "Be\\~nat Mencia Uranga and Austen Lamacraft", "title": "Schr\\\"odingeRNN: Generative Modeling of Raw Audio as a Continuously\n  Observed Quantum State", "comments": "32 pages, 20 figures, under review for MSML 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SD cond-mat.stat-mech cs.LG eess.AS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce Schr\\\"odingeRNN, a quantum inspired generative model for raw\naudio. Audio data is wave-like and is sampled from a continuous signal.\nAlthough generative modelling of raw audio has made great strides lately,\nrelational inductive biases relevant to these two characteristics are mostly\nabsent from models explored to date. Quantum Mechanics is a natural source of\nprobabilistic models of wave behaviour. Our model takes the form of a\nstochastic Schr\\\"odinger equation describing the continuous time measurement of\na quantum system, and is equivalent to the continuous Matrix Product State\n(cMPS) representation of wavefunctions in one dimensional many-body systems.\nThis constitutes a deep autoregressive architecture in which the systems state\nis a latent representation of the past observations. We test our model on\nsynthetic data sets of stationary and non-stationary signals. This is the first\ntime cMPS are used in machine learning.\n", "versions": [{"version": "v1", "created": "Tue, 26 Nov 2019 23:33:46 GMT"}], "update_date": "2019-11-28", "authors_parsed": [["Uranga", "Be\u00f1at Mencia", ""], ["Lamacraft", "Austen", ""]]}, {"id": "1911.11880", "submitter": "Junhao Wang", "authors": "Junhao Wang, Yinheng Li, Yijie Cao", "title": "Dynamic Portfolio Management with Reinforcement Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "q-fin.PM cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Dynamic Portfolio Management is a domain that concerns the continuous\nredistribution of assets within a portfolio to maximize the total return in a\ngiven period of time. With the recent advancement in machine learning and\nartificial intelligence, many efforts have been put in designing and\ndiscovering efficient algorithmic ways to manage the portfolio. This paper\npresents two different reinforcement learning agents, policy gradient\nactor-critic and evolution strategy. The performance of the two agents is\ncompared during backtesting. We also discuss the problem set up from state\nspace design, to state value function approximator and policy control design.\nWe include the short position to give the agent more flexibility during assets\nredistribution and a constant trading cost of 0.25%. The agent is able to\nachieve 5% return in 10 days daily trading despite 0.25% trading cost.\n", "versions": [{"version": "v1", "created": "Tue, 26 Nov 2019 23:41:06 GMT"}], "update_date": "2019-11-28", "authors_parsed": [["Wang", "Junhao", ""], ["Li", "Yinheng", ""], ["Cao", "Yijie", ""]]}, {"id": "1911.11881", "submitter": "Yifei Fan", "authors": "Chao Tang, Yifei Fan, Anthony Yezzi", "title": "An Adaptive View of Adversarial Robustness from Test-time Smoothing\n  Defense", "comments": "NeurIPS-2019 Workshop on Safety and Robustness in Decision Making", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The safety and robustness of learning-based decision-making systems are under\nthreats from adversarial examples, as imperceptible perturbations can mislead\nneural networks to completely different outputs. In this paper, we present an\nadaptive view of the issue via evaluating various test-time smoothing defense\nagainst white-box untargeted adversarial examples. Through controlled\nexperiments with pretrained ResNet-152 on ImageNet, we first illustrate the\nnon-monotonic relation between adversarial attacks and smoothing defenses. Then\nat the dataset level, we observe large variance among samples and show that it\nis easy to inflate accuracy (even to 100%) or build large-scale (i.e., with\nsize ~10^4) subsets on which a designated method outperforms others by a large\nmargin. Finally at the sample level, as different adversarial examples require\ndifferent degrees of defense, the potential advantages of iterative methods are\nalso discussed. We hope this paper reveal useful behaviors of test-time\ndefenses, which could help improve the evaluation process for adversarial\nrobustness in the future.\n", "versions": [{"version": "v1", "created": "Tue, 26 Nov 2019 23:45:25 GMT"}], "update_date": "2019-11-28", "authors_parsed": [["Tang", "Chao", ""], ["Fan", "Yifei", ""], ["Yezzi", "Anthony", ""]]}, {"id": "1911.11888", "submitter": "Hugh Chen", "authors": "Hugh Chen and Scott Lundberg and Su-In Lee", "title": "Explaining Models by Propagating Shapley Values of Local Components", "comments": "4 pages and references", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In healthcare, making the best possible predictions with complex models\n(e.g., neural networks, ensembles/stacks of different models) can impact\npatient welfare. In order to make these complex models explainable, we present\nDeepSHAP for mixed model types, a framework for layer wise propagation of\nShapley values that builds upon DeepLIFT (an existing approach for explaining\nneural networks). We show that in addition to being able to explain neural\nnetworks, this new framework naturally enables attributions for stacks of mixed\nmodels (e.g., neural network feature extractor into a tree model) as well as\nattributions of the loss. Finally, we theoretically justify a method for\nobtaining attributions with respect to a background distribution (under a\nShapley value framework).\n", "versions": [{"version": "v1", "created": "Wed, 27 Nov 2019 00:13:08 GMT"}], "update_date": "2019-11-28", "authors_parsed": [["Chen", "Hugh", ""], ["Lundberg", "Scott", ""], ["Lee", "Su-In", ""]]}, {"id": "1911.11897", "submitter": "Hao Tang", "authors": "Hao Tang and Hong Liu and Dan Xu and Philip H.S. Torr and Nicu Sebe", "title": "AttentionGAN: Unpaired Image-to-Image Translation using Attention-Guided\n  Generative Adversarial Networks", "comments": "An extended version of a paper published in IJCNN2019. arXiv admin\n  note: substantial text overlap with arXiv:1903.12296", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG eess.IV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  State-of-the-art methods in the unpaired image-to-image translation are\ncapable of learning a mapping from a source domain to a target domain with\nunpaired image data. Though the existing methods have achieved promising\nresults, they still produce unsatisfied artifacts, being able to convert\nlow-level information while limited in transforming high-level semantics of\ninput images. One possible reason is that generators do not have the ability to\nperceive the most discriminative semantic parts between the source and target\ndomains, thus making the generated images low quality. In this paper, we\npropose a new Attention-Guided Generative Adversarial Networks (AttentionGAN)\nfor the unpaired image-to-image translation task. AttentionGAN can identify the\nmost discriminative semantic objects and minimize changes of unwanted parts for\nsemantic manipulation problems without using extra data and models. The\nattention-guided generators in AttentionGAN are able to produce attention masks\nvia a built-in attention mechanism, and then fuse the generation output with\nthe attention masks to obtain high-quality target images. Accordingly, we also\ndesign a novel attention-guided discriminator which only considers attended\nregions. Extensive experiments are conducted on several generative tasks,\ndemonstrating that the proposed model is effective to generate sharper and more\nrealistic images compared with existing competitive models. The source code for\nthe proposed AttentionGAN is available at\nhttps://github.com/Ha0Tang/AttentionGAN.\n", "versions": [{"version": "v1", "created": "Wed, 27 Nov 2019 00:53:27 GMT"}, {"version": "v2", "created": "Tue, 10 Dec 2019 23:39:13 GMT"}, {"version": "v3", "created": "Sat, 28 Dec 2019 03:53:51 GMT"}, {"version": "v4", "created": "Wed, 12 Feb 2020 20:31:35 GMT"}], "update_date": "2020-02-14", "authors_parsed": [["Tang", "Hao", ""], ["Liu", "Hong", ""], ["Xu", "Dan", ""], ["Torr", "Philip H. S.", ""], ["Sebe", "Nicu", ""]]}, {"id": "1911.11901", "submitter": "Joseph Gatto", "authors": "Joseph Gatto, Ravi Lanka, Yumi Iwashita, Adrian Stoica", "title": "Single Sample Feature Importance: An Interpretable Algorithm for\n  Low-Level Feature Analysis", "comments": "The research was carried out at the Jet Propulsion Laboratory,\n  California Institute of Technology, under a contract with the National\n  Aeronautics and Space Administration. The work of Joseph Gatto was sponsored\n  by the JPL Summer Internship Program and the National Aeronautics and Space\n  Administration", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Have you ever wondered how your feature space is impacting the prediction of\na specific sample in your dataset? In this paper, we introduce Single Sample\nFeature Importance (SSFI), which is an interpretable feature importance\nalgorithm that allows for the identification of the most important features\nthat contribute to the prediction of a single sample. When a dataset can be\nlearned by a Random Forest classifier or regressor, SSFI shows how the Random\nForest's prediction path can be utilized for low-level feature importance\ncalculation. SSFI results in a relative ranking of features, highlighting those\nwith the greatest impact on a data point's prediction. We demonstrate these\nresults both numerically and visually on four different datasets.\n", "versions": [{"version": "v1", "created": "Wed, 27 Nov 2019 00:58:52 GMT"}], "update_date": "2019-11-28", "authors_parsed": [["Gatto", "Joseph", ""], ["Lanka", "Ravi", ""], ["Iwashita", "Yumi", ""], ["Stoica", "Adrian", ""]]}, {"id": "1911.11908", "submitter": "Gan Sun", "authors": "Gan Sun, Yang Cong, Qianqian Wang, Jun Li, Yun Fu", "title": "Lifelong Spectral Clustering", "comments": "9 pages,7 figures", "journal-ref": "AAAI 2020", "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In the past decades, spectral clustering (SC) has become one of the most\neffective clustering algorithms. However, most previous studies focus on\nspectral clustering tasks with a fixed task set, which cannot incorporate with\na new spectral clustering task without accessing to previously learned tasks.\nIn this paper, we aim to explore the problem of spectral clustering in a\nlifelong machine learning framework, i.e., Lifelong Spectral Clustering (L2SC).\nIts goal is to efficiently learn a model for a new spectral clustering task by\nselectively transferring previously accumulated experience from knowledge\nlibrary. Specifically, the knowledge library of L2SC contains two components:\n1) orthogonal basis library: capturing latent cluster centers among the\nclusters in each pair of tasks; 2) feature embedding library: embedding the\nfeature manifold information shared among multiple related tasks. As a new\nspectral clustering task arrives, L2SC firstly transfers knowledge from both\nbasis library and feature library to obtain encoding matrix, and further\nredefines the library base over time to maximize performance across all the\nclustering tasks. Meanwhile, a general online update formulation is derived to\nalternatively update the basis library and feature library. Finally, the\nempirical experiments on several real-world benchmark datasets demonstrate that\nour L2SC model can effectively improve the clustering performance when\ncomparing with other state-of-the-art spectral clustering algorithms.\n", "versions": [{"version": "v1", "created": "Wed, 27 Nov 2019 01:37:18 GMT"}, {"version": "v2", "created": "Fri, 29 Nov 2019 04:03:02 GMT"}], "update_date": "2019-12-02", "authors_parsed": [["Sun", "Gan", ""], ["Cong", "Yang", ""], ["Wang", "Qianqian", ""], ["Li", "Jun", ""], ["Fu", "Yun", ""]]}, {"id": "1911.11928", "submitter": "Yang Yu", "authors": "Rong-Jun Qin, Jing-Cheng Pang, Yang Yu", "title": "Improving Fictitious Play Reinforcement Learning with Expanding Models", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Fictitious play with reinforcement learning is a general and effective\nframework for zero-sum games. However, using the current deep neural network\nmodels, the implementation of fictitious play faces crucial challenges. Neural\nnetwork model training employs gradient descent approaches to update all\nconnection weights, and thus is easy to forget the old opponents after training\nto beat the new opponents. Existing approaches often maintain a pool of\nhistorical policy models to avoid the forgetting. However, learning to beat a\npool in stochastic games, i.e., a wide distribution over policy models, is\neither sample-consuming or insufficient to exploit all models with limited\namount of samples. In this paper, we propose a learning process with neural\nfictitious play to alleviate the above issues. We train a single model as our\npolicy model, which consists of sub-models and a selector. Everytime facing a\nnew opponent, the model is expanded by adding a new sub-model, where only the\nnew sub-model is updated instead of the whole model. At the same time, the\nselector is also updated to mix up the new sub-model with the previous ones at\nthe state-level, so that the model is maintained as a behavior strategy instead\nof a wide distribution over policy models. Experiments on Kuhn poker, a\ngrid-world Treasure Hunting game, and Mini-RTS environments show that the\nproposed approach alleviates the forgetting problem, and consequently improves\nthe learning efficiency and the robustness of neural fictitious play.\n", "versions": [{"version": "v1", "created": "Wed, 27 Nov 2019 03:14:37 GMT"}, {"version": "v2", "created": "Thu, 28 Nov 2019 04:54:29 GMT"}], "update_date": "2019-12-02", "authors_parsed": [["Qin", "Rong-Jun", ""], ["Pang", "Jing-Cheng", ""], ["Yu", "Yang", ""]]}, {"id": "1911.11932", "submitter": "Michel Kinsy", "authors": "Mihailo Isakov, Vijay Gadepally, Karen M. Gettings, Michel A. Kinsy", "title": "Survey of Attacks and Defenses on Edge-Deployed Neural Networks", "comments": null, "journal-ref": "In the 2019 IEEE High Performance Extreme Computing Conference\n  (HPEC), 2019", "doi": null, "report-no": null, "categories": "cs.CR cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep Neural Network (DNN) workloads are quickly moving from datacenters onto\nedge devices, for latency, privacy, or energy reasons. While datacenter\nnetworks can be protected using conventional cybersecurity measures, edge\nneural networks bring a host of new security challenges. Unlike classic IoT\napplications, edge neural networks are typically very compute and memory\nintensive, their execution is data-independent, and they are robust to noise\nand faults. Neural network models may be very expensive to develop, and can\npotentially reveal information about the private data they were trained on,\nrequiring special care in distribution. The hidden states and outputs of the\nnetwork can also be used in reconstructing user inputs, potentially violating\nusers' privacy. Furthermore, neural networks are vulnerable to adversarial\nattacks, which may cause misclassifications and violate the integrity of the\noutput. These properties add challenges when securing edge-deployed DNNs,\nrequiring new considerations, threat models, priorities, and approaches in\nsecurely and privately deploying DNNs to the edge. In this work, we cover the\nlandscape of attacks on, and defenses, of neural networks deployed in edge\ndevices and provide a taxonomy of attacks and defenses targeting edge DNNs.\n", "versions": [{"version": "v1", "created": "Wed, 27 Nov 2019 03:31:04 GMT"}], "update_date": "2019-11-28", "authors_parsed": [["Isakov", "Mihailo", ""], ["Gadepally", "Vijay", ""], ["Gettings", "Karen M.", ""], ["Kinsy", "Michel A.", ""]]}, {"id": "1911.11936", "submitter": "Chenghao Guo", "authors": "Chenghao Guo, Zhiyi Huang, Zhihao Gavin Tang, and Xinzhi Zhang", "title": "Generalizing Complex Hypotheses on Product Distributions: Auctions,\n  Prophet Inequalities, and Pandora's Problem", "comments": "38pages, submitted to SODA21", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.GT cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper explores a theory of generalization for learning problems on\nproduct distributions, complementing the existing learning theories in the\nsense that it does not rely on any complexity measures of the hypothesis\nclasses. The main contributions are two general sample complexity bounds: (1)\n$\\tilde{O} \\big( \\frac{nk}{\\epsilon^2} \\big)$ samples are sufficient and\nnecessary for learning an $\\epsilon$-optimal hypothesis in any problem on an\n$n$-dimensional product distribution, whose marginals have finite supports of\nsizes at most $k$; (2) $\\tilde{O} \\big( \\frac{n}{\\epsilon^2} \\big)$ samples are\nsufficient and necessary for any problem on $n$-dimensional product\ndistributions if it satisfies a notion of strong monotonicity from the\nalgorithmic game theory literature. As applications of these theories, we match\nthe optimal sample complexity for single-parameter revenue maximization (Guo et\nal., STOC 2019), improve the state-of-the-art for multi-parameter revenue\nmaximization (Gonczarowski and Weinberg, FOCS 2018) and prophet inequality\n(Correa et al., EC 2019), and provide the first and tight sample complexity\nbound for Pandora's problem.\n", "versions": [{"version": "v1", "created": "Wed, 27 Nov 2019 03:43:38 GMT"}, {"version": "v2", "created": "Sun, 26 Jul 2020 04:27:40 GMT"}], "update_date": "2020-07-28", "authors_parsed": [["Guo", "Chenghao", ""], ["Huang", "Zhiyi", ""], ["Tang", "Zhihao Gavin", ""], ["Zhang", "Xinzhi", ""]]}, {"id": "1911.11938", "submitter": "T.S. Jayram", "authors": "T.S. Jayram and Vincent Marois and Tomasz Kornuta and Vincent Albouy\n  and Emre Sevgen and Ahmet S. Ozcan", "title": "Transfer Learning in Visual and Relational Reasoning", "comments": "18 pages; more baseline comparisons; additional clarifications", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Transfer learning has become the de facto standard in computer vision and\nnatural language processing, especially where labeled data is scarce. Accuracy\ncan be significantly improved by using pre-trained models and subsequent\nfine-tuning. In visual reasoning tasks, such as image question answering,\ntransfer learning is more complex. In addition to transferring the capability\nto recognize visual features, we also expect to transfer the system's ability\nto reason. Moreover, for video data, temporal reasoning adds another dimension.\nIn this work, we formalize these unique aspects of transfer learning and\npropose a theoretical framework for visual reasoning, exemplified by the\nwell-established CLEVR and COG datasets. Furthermore, we introduce a new,\nend-to-end differentiable recurrent model (SAMNet), which shows\nstate-of-the-art accuracy and better performance in transfer learning on both\ndatasets. The improved performance of SAMNet stems from its capability to\ndecouple the abstract multi-step reasoning from the length of the sequence and\nits selective attention enabling to store only the question-relevant objects in\nthe external memory.\n", "versions": [{"version": "v1", "created": "Wed, 27 Nov 2019 03:54:15 GMT"}, {"version": "v2", "created": "Sat, 15 Feb 2020 04:26:42 GMT"}], "update_date": "2020-02-18", "authors_parsed": [["Jayram", "T. S.", ""], ["Marois", "Vincent", ""], ["Kornuta", "Tomasz", ""], ["Albouy", "Vincent", ""], ["Sevgen", "Emre", ""], ["Ozcan", "Ahmet S.", ""]]}, {"id": "1911.11943", "submitter": "Choi Sungik", "authors": "Sungik Choi, Sae-Young Chung", "title": "Novelty Detection Via Blurring", "comments": "ICLR 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV eess.IV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Conventional out-of-distribution (OOD) detection schemes based on variational\nautoencoder or Random Network Distillation (RND) have been observed to assign\nlower uncertainty to the OOD than the target distribution. In this work, we\ndiscover that such conventional novelty detection schemes are also vulnerable\nto the blurred images. Based on the observation, we construct a novel RND-based\nOOD detector, SVD-RND, that utilizes blurred images during training. Our\ndetector is simple, efficient at test time, and outperforms baseline OOD\ndetectors in various domains. Further results show that SVD-RND learns better\ntarget distribution representation than the baseline RND algorithm. Finally,\nSVD-RND combined with geometric transform achieves near-perfect detection\naccuracy on the CelebA dataset.\n", "versions": [{"version": "v1", "created": "Wed, 27 Nov 2019 04:10:18 GMT"}, {"version": "v2", "created": "Tue, 7 Jan 2020 07:36:13 GMT"}, {"version": "v3", "created": "Tue, 3 Mar 2020 06:39:00 GMT"}], "update_date": "2020-03-04", "authors_parsed": [["Choi", "Sungik", ""], ["Chung", "Sae-Young", ""]]}, {"id": "1911.11946", "submitter": "Pratik Vaishnavi", "authors": "Pratik Vaishnavi, Tianji Cong, Kevin Eykholt, Atul Prakash, Amir\n  Rahmati", "title": "Can Attention Masks Improve Adversarial Robustness?", "comments": "Version presented at AAAI-20 workshop on Engineering Dependable and\n  Secure Machine Learning Systems (EDSMLS)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.CR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep Neural Networks (DNNs) are known to be susceptible to adversarial\nexamples. Adversarial examples are maliciously crafted inputs that are designed\nto fool a model, but appear normal to human beings. Recent work has shown that\npixel discretization can be used to make classifiers for MNIST highly robust to\nadversarial examples. However, pixel discretization fails to provide\nsignificant protection on more complex datasets. In this paper, we take the\nfirst step towards reconciling these contrary findings. Focusing on the\nobservation that discrete pixelization in MNIST makes the background completely\nblack and foreground completely white, we hypothesize that the important\nproperty for increasing robustness is the elimination of image background using\nattention masks before classifying an object. To examine this hypothesis, we\ncreate foreground attention masks for two different datasets, GTSRB and\nMS-COCO. Our initial results suggest that using attention mask leads to\nimproved robustness. On the adversarially trained classifiers, we see an\nadversarial robustness increase of over 20% on MS-COCO.\n", "versions": [{"version": "v1", "created": "Wed, 27 Nov 2019 04:26:35 GMT"}, {"version": "v2", "created": "Sat, 21 Dec 2019 22:55:53 GMT"}], "update_date": "2019-12-24", "authors_parsed": [["Vaishnavi", "Pratik", ""], ["Cong", "Tianji", ""], ["Eykholt", "Kevin", ""], ["Prakash", "Atul", ""], ["Rahmati", "Amir", ""]]}, {"id": "1911.11950", "submitter": "Hung Tran-The", "authors": "Hung Tran-The, Sunil Gupta, Santu Rana, Svetha Venkatesh", "title": "Trading Convergence Rate with Computational Budget in High Dimensional\n  Bayesian Optimization", "comments": "Our accepted paper (with Supplementary Material) at AAAI 2020", "journal-ref": null, "doi": "10.1609/aaai.v34i03.5623", "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Scaling Bayesian optimisation (BO) to high-dimensional search spaces is a\nactive and open research problems particularly when no assumptions are made on\nfunction structure. The main reason is that at each iteration, BO requires to\nfind global maximisation of acquisition function, which itself is a non-convex\noptimization problem in the original search space. With growing dimensions, the\ncomputational budget for this maximisation gets increasingly short leading to\ninaccurate solution of the maximisation. This inaccuracy adversely affects both\nthe convergence and the efficiency of BO. We propose a novel approach where the\nacquisition function only requires maximisation on a discrete set of low\ndimensional subspaces embedded in the original high-dimensional search space.\nOur method is free of any low dimensional structure assumption on the function\nunlike many recent high-dimensional BO methods. Optimising acquisition function\nin low dimensional subspaces allows our method to obtain accurate solutions\nwithin limited computational budget. We show that in spite of this convenience,\nour algorithm remains convergent. In particular, cumulative regret of our\nalgorithm only grows sub-linearly with the number of iterations. More\nimportantly, as evident from our regret bounds, our algorithm provides a way to\ntrade the convergence rate with the number of subspaces used in the\noptimisation. Finally, when the number of subspaces is \"sufficiently large\",\nour algorithm's cumulative regret is at most\n$\\mathcal{O}^{*}(\\sqrt{T\\gamma_T})$ as opposed to\n$\\mathcal{O}^{*}(\\sqrt{DT\\gamma_T})$ for the GP-UCB of Srinivas et al. (2012),\nreducing a crucial factor $\\sqrt{D}$ where $D$ being the dimensional number of\ninput space.\n", "versions": [{"version": "v1", "created": "Wed, 27 Nov 2019 04:49:12 GMT"}, {"version": "v2", "created": "Fri, 28 Aug 2020 07:19:24 GMT"}], "update_date": "2020-08-31", "authors_parsed": [["Tran-The", "Hung", ""], ["Gupta", "Sunil", ""], ["Rana", "Santu", ""], ["Venkatesh", "Svetha", ""]]}, {"id": "1911.11952", "submitter": "Siamak Shakeri", "authors": "Siamak Shakeri, Abhinav Sethy", "title": "Label Dependent Deep Variational Paraphrase Generation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CL stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Generating paraphrases that are lexically similar but semantically different\nis a challenging task. Paraphrases of this form can be used to augment data\nsets for various NLP tasks such as machine reading comprehension and question\nanswering with non-trivial negative examples. In this article, we propose a\ndeep variational model to generate paraphrases conditioned on a label that\nspecifies whether the paraphrases are semantically related or not. We also\npresent new training recipes and KL regularization techniques that improve the\nperformance of variational paraphrasing models. Our proposed model demonstrates\npromising results in enhancing the generative power of the model by employing\nlabel-dependent generation on paraphrasing datasets.\n", "versions": [{"version": "v1", "created": "Wed, 27 Nov 2019 04:54:14 GMT"}], "update_date": "2019-11-28", "authors_parsed": [["Shakeri", "Siamak", ""], ["Sethy", "Abhinav", ""]]}, {"id": "1911.11960", "submitter": "Joel Ruben Antony Moniz", "authors": "Joel Ruben Antony Moniz, Eunsu Kang, Barnab\\'as P\\'oczos", "title": "LucidDream: Controlled Temporally-Consistent DeepDream on Videos", "comments": "Workshop on Machine Learning for Creativity and Design, NeurIPS 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this work, we aim to propose a set of techniques to improve the\ncontrollability and aesthetic appeal when DeepDream, which uses a pre-trained\nneural network to modify images by hallucinating objects into them, is applied\nto videos. In particular, we demonstrate a simple modification that improves\ncontrol over the class of object that DeepDream is induced to hallucinate. We\nalso show that the flickering artifacts which frequently appear when DeepDream\nis applied on videos can be mitigated by the use of an additional temporal\nconsistency loss term.\n", "versions": [{"version": "v1", "created": "Wed, 27 Nov 2019 05:29:36 GMT"}], "update_date": "2019-11-28", "authors_parsed": [["Moniz", "Joel Ruben Antony", ""], ["Kang", "Eunsu", ""], ["P\u00f3czos", "Barnab\u00e1s", ""]]}, {"id": "1911.11976", "submitter": "Faisal Hussain", "authors": "Faisal Hussain, Muhammad Basit Umair, Muhammad Ehatisham-ul-Haq, Ivan\n  Miguel Pires, T\\^ania Valente, Nuno M.Garcia and Nuno Pombo", "title": "An Efficient Machine Learning-based Elderly Fall Detection Algorithm", "comments": "6 pages, SENSORDEVICES 2018, the Ninth International Conference on\n  Sensor Device Technologies and Applications, Venice, Italy, 16-20 September\n  2018", "journal-ref": null, "doi": null, "report-no": "ISBN: 978-1-61208-660-6", "categories": "cs.LG cs.CY eess.SP stat.ML", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Falling is a commonly occurring mishap with elderly people, which may cause\nserious injuries. Thus, rapid fall detection is very important in order to\nmitigate the severe effects of fall among the elderly people. Many fall\nmonitoring systems based on the accelerometer have been proposed for the fall\ndetection. However, many of them mistakenly identify the daily life activities\nas fall or fall as daily life activity. To this aim, an efficient machine\nlearning-based fall detection algorithm has been proposed in this paper. The\nproposed algorithm detects fall with efficient sensitivity, specificity, and\naccuracy as compared to the state-of-the-art techniques. A publicly available\ndataset with a very simple and computationally efficient set of features is\nused to accurately detect the fall incident. The proposed algorithm reports and\naccuracy of 99.98% with the Support Vector Machine(SVM) classifier.\n", "versions": [{"version": "v1", "created": "Wed, 27 Nov 2019 06:26:10 GMT"}], "update_date": "2019-11-28", "authors_parsed": [["Hussain", "Faisal", ""], ["Umair", "Muhammad Basit", ""], ["Ehatisham-ul-Haq", "Muhammad", ""], ["Pires", "Ivan Miguel", ""], ["Valente", "T\u00e2nia", ""], ["Garcia", "Nuno M.", ""], ["Pombo", "Nuno", ""]]}, {"id": "1911.11983", "submitter": "Thanh Nguyen", "authors": "Thanh V. Nguyen, Raymond K. W. Wong, Chinmay Hegde", "title": "Benefits of Jointly Training Autoencoders: An Improved Neural Tangent\n  Kernel Analysis", "comments": "Added Sections 3.2 and 3.4 on inductive biases. Fixed an error in\n  deriving the neural tangent kernel in Section 3.3", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A remarkable recent discovery in machine learning has been that deep neural\nnetworks can achieve impressive performance (in terms of both lower training\nerror and higher generalization capacity) in the regime where they are\nmassively over-parameterized. Consequently, over the past year, the community\nhas devoted growing interest in analyzing optimization and generalization\nproperties of over-parameterized networks, and several breakthrough works have\nled to important theoretical progress. However, the majority of existing work\nonly applies to supervised learning scenarios and hence are limited to settings\nsuch as classification and regression. In contrast, the role of\nover-parameterization in the unsupervised setting has gained far less\nattention. In this paper, we study the gradient dynamics of two-layer\nover-parameterized autoencoders with ReLU activation. We make very few\nassumptions about the given training dataset (other than mild non-degeneracy\nconditions). Starting from a randomly initialized autoencoder network, we\nrigorously prove the linear convergence of gradient descent in two learning\nregimes, namely: (i) the weakly-trained regime where only the encoder is\ntrained, and (ii) the jointly-trained regime where both the encoder and the\ndecoder are trained. Our results indicate the considerable benefits of joint\ntraining over weak training for finding global optima, achieving a dramatic\ndecrease in the required level of over-parameterization. We also analyze the\ncase of weight-tied autoencoders (which is a commonly used architectural choice\nin practical settings) and prove that in the over-parameterized setting,\ntraining such networks from randomly initialized points leads to certain\nunexpected degeneracies.\n", "versions": [{"version": "v1", "created": "Wed, 27 Nov 2019 06:45:36 GMT"}, {"version": "v2", "created": "Mon, 2 Mar 2020 17:47:03 GMT"}], "update_date": "2020-03-03", "authors_parsed": [["Nguyen", "Thanh V.", ""], ["Wong", "Raymond K. W.", ""], ["Hegde", "Chinmay", ""]]}, {"id": "1911.11984", "submitter": "Chengyuan Deng", "authors": "Chen Wang, Chengyuan Deng, Vladimir Ivanov", "title": "SAG-VAE: End-to-end Joint Inference of Data Representations and Feature\n  Relations", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Variational Autoencoders (VAEs) are powerful in data representation\ninference, but it cannot learn relations between features with its vanilla form\nand common variations. The ability to capture relations within data can provide\nthe much needed inductive bias necessary for building more robust Machine\nLearning algorithms with more interpretable results. In this paper, inspired by\nrecent advances in relational learning using Graph Neural Networks, we propose\nthe Self-Attention Graph Variational AutoEncoder (SAG-VAE) network which can\nsimultaneously learn feature relations and data representations in an\nend-to-end manner. SAG-VAE is trained by jointly inferring the posterior\ndistribution of two types of latent variables, which denote the data\nrepresentation and a shared graph structure, respectively. Furthermore, we\nintroduce a novel self-attention graph network that improves the generative\ncapabilities of SAG-VAE by parameterizing the generative distribution allowing\nSAG-VAE to generate new data via graph convolution, while still trainable via\nbackpropagation. A learnable relational graph representation enhances SAG-VAE's\nrobustness to perturbation and noise, while also providing deeper intuition\ninto model performance. Experiments based on graphs show that SAG-VAE is\ncapable of approximately retrieving edges and links between nodes based\nentirely on feature observations. Finally, results on image data illustrate\nthat SAG-VAE is fairly robust against perturbations in image reconstruction and\nsampling.\n", "versions": [{"version": "v1", "created": "Wed, 27 Nov 2019 06:48:08 GMT"}, {"version": "v2", "created": "Thu, 20 Feb 2020 22:22:34 GMT"}, {"version": "v3", "created": "Wed, 22 Jul 2020 11:37:41 GMT"}], "update_date": "2020-07-23", "authors_parsed": [["Wang", "Chen", ""], ["Deng", "Chengyuan", ""], ["Ivanov", "Vladimir", ""]]}, {"id": "1911.11988", "submitter": "Craig Atkinson", "authors": "Craig Atkinson, Brendan McCane, Lech Szymanski, Anthony Robins", "title": "GRIm-RePR: Prioritising Generating Important Features for\n  Pseudo-Rehearsal", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Pseudo-rehearsal allows neural networks to learn a sequence of tasks without\nforgetting how to perform in earlier tasks. Preventing forgetting is achieved\nby introducing a generative network which can produce data from previously seen\ntasks so that it can be rehearsed along side learning the new task. This has\nbeen found to be effective in both supervised and reinforcement learning. Our\ncurrent work aims to further prevent forgetting by encouraging the generator to\naccurately generate features important for task retention. More specifically,\nthe generator is improved by introducing a second discriminator into the\nGenerative Adversarial Network which learns to classify between real and fake\nitems from the intermediate activation patterns that they produce when fed\nthrough a continual learning agent. Using Atari 2600 games, we experimentally\nfind that improving the generator can considerably reduce catastrophic\nforgetting compared to the standard pseudo-rehearsal methods used in deep\nreinforcement learning. Furthermore, we propose normalising the Q-values taught\nto the long-term system as we observe this substantially reduces catastrophic\nforgetting by minimising the interference between tasks' reward functions.\n", "versions": [{"version": "v1", "created": "Wed, 27 Nov 2019 07:06:03 GMT"}], "update_date": "2019-11-28", "authors_parsed": [["Atkinson", "Craig", ""], ["McCane", "Brendan", ""], ["Szymanski", "Lech", ""], ["Robins", "Anthony", ""]]}, {"id": "1911.11997", "submitter": "Haoyi Xiong", "authors": "Zhi Fengy, Haoyi Xiong, Chuanyuan Song, Sijia Yang, Baoxin Zhao,\n  Licheng Wang, Zeyu Chen, Shengwen Yang, Liping Liu, Jun Huan", "title": "SecureGBM: Secure Multi-Party Gradient Boosting", "comments": "The first two authors contributed equally to the manuscript. The\n  paper has been accepted for publication in IEEE BigData 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Federated machine learning systems have been widely used to facilitate the\njoint data analytics across the distributed datasets owned by the different\nparties that do not trust each others. In this paper, we proposed a novel\nGradient Boosting Machines (GBM) framework SecureGBM built-up with a\nmulti-party computation model based on semi-homomorphic encryption, where every\ninvolved party can jointly obtain a shared Gradient Boosting machines model\nwhile protecting their own data from the potential privacy leakage and\ninferential identification. More specific, our work focused on a specific\n\"dual--party\" secure learning scenario based on two parties -- both party own\nan unique view (i.e., attributes or features) to the sample group of samples\nwhile only one party owns the labels. In such scenario, feature and label data\nare not allowed to share with others. To achieve the above goal, we firstly\nextent -- LightGBM -- a well known implementation of tree-based GBM through\ncovering its key operations for training and inference with SEAL homomorphic\nencryption schemes. However, the performance of such re-implementation is\nsignificantly bottle-necked by the explosive inflation of the communication\npayloads, based on ciphertexts subject to the increasing length of plaintexts.\nIn this way, we then proposed to use stochastic approximation techniques to\nreduced the communication payloads while accelerating the overall training\nprocedure in a statistical manner. Our experiments using the real-world data\nshowed that SecureGBM can well secure the communication and computation of\nLightGBM training and inference procedures for the both parties while only\nlosing less than 3% AUC, using the same number of iterations for gradient\nboosting, on a wide range of benchmark datasets.\n", "versions": [{"version": "v1", "created": "Wed, 27 Nov 2019 07:42:07 GMT"}], "update_date": "2019-11-28", "authors_parsed": [["Fengy", "Zhi", ""], ["Xiong", "Haoyi", ""], ["Song", "Chuanyuan", ""], ["Yang", "Sijia", ""], ["Zhao", "Baoxin", ""], ["Wang", "Licheng", ""], ["Chen", "Zeyu", ""], ["Yang", "Shengwen", ""], ["Liu", "Liping", ""], ["Huan", "Jun", ""]]}, {"id": "1911.12008", "submitter": "Anthony Bagnall Dr", "authors": "Anthony Bagnall, James Large and Matthew Middlehurst", "title": "A tale of two toolkits, report the second: bake off redux. Chapter 1.\n  dictionary based classifiers", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Time series classification (TSC) is the problem of learning labels from time\ndependent data. One class of algorithms is derived from a bag of words\napproach. A window is run along a series, the subseries is shortened and\ndiscretised to form a word, then features are formed from the histogram of\nfrequency of occurrence of words. We call this type of approach to TSC\ndictionary based classification. We compare four dictionary based algorithms in\nthe context of a wider project to update the great time series classification\nbakeoff, a comparative study published in 2017. We experimentally characterise\nthe algorithms in terms of predictive performance, time complexity and space\ncomplexity. We find that we can improve on the previous best in terms of\naccuracy, but this comes at the cost of time and space. Alternatively, the same\nperformance can be achieved with far less cost. We review the relative merits\nof the four algorithms before suggesting a path to possible improvement.\n", "versions": [{"version": "v1", "created": "Wed, 27 Nov 2019 08:05:48 GMT"}], "update_date": "2019-11-28", "authors_parsed": [["Bagnall", "Anthony", ""], ["Large", "James", ""], ["Middlehurst", "Matthew", ""]]}, {"id": "1911.12012", "submitter": "Shilin Zhu", "authors": "Shuo Cheng, Zexiang Xu, Shilin Zhu, Zhuwen Li, Li Erran Li, Ravi\n  Ramamoorthi, Hao Su", "title": "Deep Stereo using Adaptive Thin Volume Representation with Uncertainty\n  Awareness", "comments": "Accepted to CVPR 2020 (Oral)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG cs.RO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present Uncertainty-aware Cascaded Stereo Network (UCS-Net) for 3D\nreconstruction from multiple RGB images. Multi-view stereo (MVS) aims to\nreconstruct fine-grained scene geometry from multi-view images. Previous\nlearning-based MVS methods estimate per-view depth using plane sweep volumes\nwith a fixed depth hypothesis at each plane; this generally requires densely\nsampled planes for desired accuracy, and it is very hard to achieve\nhigh-resolution depth. In contrast, we propose adaptive thin volumes (ATVs); in\nan ATV, the depth hypothesis of each plane is spatially varying, which adapts\nto the uncertainties of previous per-pixel depth predictions. Our UCS-Net has\nthree stages: the first stage processes a small standard plane sweep volume to\npredict low-resolution depth; two ATVs are then used in the following stages to\nrefine the depth with higher resolution and higher accuracy. Our ATV consists\nof only a small number of planes; yet, it efficiently partitions local depth\nranges within learned small intervals. In particular, we propose to use\nvariance-based uncertainty estimates to adaptively construct ATVs; this\ndifferentiable process introduces reasonable and fine-grained spatial\npartitioning. Our multi-stage framework progressively subdivides the vast scene\nspace with increasing depth resolution and precision, which enables scene\nreconstruction with high completeness and accuracy in a coarse-to-fine fashion.\nWe demonstrate that our method achieves superior performance compared with\nstate-of-the-art benchmarks on various challenging datasets.\n", "versions": [{"version": "v1", "created": "Wed, 27 Nov 2019 08:14:52 GMT"}, {"version": "v2", "created": "Sat, 18 Apr 2020 23:09:41 GMT"}], "update_date": "2020-04-21", "authors_parsed": [["Cheng", "Shuo", ""], ["Xu", "Zexiang", ""], ["Zhu", "Shilin", ""], ["Li", "Zhuwen", ""], ["Li", "Li Erran", ""], ["Ramamoorthi", "Ravi", ""], ["Su", "Hao", ""]]}, {"id": "1911.12036", "submitter": "Hui Tang", "authors": "Hui Tang, Kui Jia", "title": "Discriminative Adversarial Domain Adaptation", "comments": "18 pages, 10 figures, 12 tables, accepted by AAAI-20", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Given labeled instances on a source domain and unlabeled ones on a target\ndomain, unsupervised domain adaptation aims to learn a task classifier that can\nwell classify target instances. Recent advances rely on domain-adversarial\ntraining of deep networks to learn domain-invariant features. However, due to\nan issue of mode collapse induced by the separate design of task and domain\nclassifiers, these methods are limited in aligning the joint distributions of\nfeature and category across domains. To overcome it, we propose a novel\nadversarial learning method termed Discriminative Adversarial Domain Adaptation\n(DADA). Based on an integrated category and domain classifier, DADA has a novel\nadversarial objective that encourages a mutually inhibitory relation between\ncategory and domain predictions for any input instance. We show that under\npractical conditions, it defines a minimax game that can promote the joint\ndistribution alignment. Except for the traditional closed set domain\nadaptation, we also extend DADA for extremely challenging problem settings of\npartial and open set domain adaptation. Experiments show the efficacy of our\nproposed methods and we achieve the new state of the art for all the three\nsettings on benchmark datasets.\n", "versions": [{"version": "v1", "created": "Wed, 27 Nov 2019 09:19:16 GMT"}, {"version": "v2", "created": "Tue, 17 Dec 2019 03:49:04 GMT"}], "update_date": "2019-12-18", "authors_parsed": [["Tang", "Hui", ""], ["Jia", "Kui", ""]]}, {"id": "1911.12060", "submitter": "Jun Zhao", "authors": "Jun Zhao, Teng Wang, Tao Bai, Kwok-Yan Lam, Zhiying Xu, Shuyu Shi,\n  Xuebin Ren, Xinyu Yang, Yang Liu, Han Yu", "title": "Reviewing and Improving the Gaussian Mechanism for Differential Privacy", "comments": "23 Pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.AI cs.CY cs.DB cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Differential privacy provides a rigorous framework to quantify data privacy,\nand has received considerable interest recently. A randomized mechanism\nsatisfying $(\\epsilon, \\delta)$-differential privacy (DP) roughly means that,\nexcept with a small probability $\\delta$, altering a record in a dataset cannot\nchange the probability that an output is seen by more than a multiplicative\nfactor $e^{\\epsilon} $. A well-known solution to $(\\epsilon, \\delta)$-DP is the\nGaussian mechanism initiated by Dwork et al. [1] in 2006 with an improvement by\nDwork and Roth [2] in 2014, where a Gaussian noise amount $\\sqrt{2\\ln\n\\frac{2}{\\delta}} \\times \\frac{\\Delta}{\\epsilon}$ of [1] or $\\sqrt{2\\ln\n\\frac{1.25}{\\delta}} \\times \\frac{\\Delta}{\\epsilon}$ of [2] is added\nindependently to each dimension of the query result, for a query with\n$\\ell_2$-sensitivity $\\Delta$. Although both classical Gaussian mechanisms\n[1,2] assume $0 < \\epsilon \\leq 1$, our review finds that many studies in the\nliterature have used the classical Gaussian mechanisms under values of\n$\\epsilon$ and $\\delta$ where the added noise amounts of [1,2] do not achieve\n$(\\epsilon,\\delta)$-DP. We obtain such result by analyzing the optimal noise\namount $\\sigma_{DP-OPT}$ for $(\\epsilon,\\delta)$-DP and identifying $\\epsilon$\nand $\\delta$ where the noise amounts of classical mechanisms are even less than\n$\\sigma_{DP-OPT}$.\n  Since $\\sigma_{DP-OPT}$ has no closed-form expression and needs to be\napproximated in an iterative manner, we propose Gaussian mechanisms by deriving\nclosed-form upper bounds for $\\sigma_{DP-OPT}$. Our mechanisms achieve\n$(\\epsilon,\\delta)$-DP for any $\\epsilon$, while the classical mechanisms [1,2]\ndo not achieve $(\\epsilon,\\delta)$-DP for large $\\epsilon$ given $\\delta$.\nMoreover, the utilities of our mechanisms improve those of [1,2] and are close\nto that of the optimal yet more computationally expensive Gaussian mechanism.\n", "versions": [{"version": "v1", "created": "Wed, 27 Nov 2019 10:26:50 GMT"}, {"version": "v2", "created": "Sat, 7 Dec 2019 04:13:50 GMT"}], "update_date": "2019-12-10", "authors_parsed": [["Zhao", "Jun", ""], ["Wang", "Teng", ""], ["Bai", "Tao", ""], ["Lam", "Kwok-Yan", ""], ["Xu", "Zhiying", ""], ["Shi", "Shuyu", ""], ["Ren", "Xuebin", ""], ["Yang", "Xinyu", ""], ["Liu", "Yang", ""], ["Yu", "Han", ""]]}, {"id": "1911.12069", "submitter": "Davide Cozzolino", "authors": "Davide Cozzolino and Justus Thies and Andreas R\\\"ossler and Matthias\n  Nie{\\ss}ner and Luisa Verdoliva", "title": "SpoC: Spoofing Camera Fingerprints", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.CR cs.LG eess.IV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Thanks to the fast progress in synthetic media generation, creating realistic\nfalse images has become very easy. Such images can be used to wrap \"rich\" fake\nnews with enhanced credibility, spawning a new wave of high-impact, high-risk\nmisinformation campaigns. Therefore, there is a fast-growing interest in\nreliable detectors of manipulated media. The most powerful detectors, to date,\nrely on the subtle traces left by any device on all images acquired by it. In\nparticular, due to proprietary in-camera processes, like demosaicing or\ncompression, each camera model leaves trademark traces that can be exploited\nfor forensic analyses. The absence or distortion of such traces in the target\nimage is a strong hint of manipulation. In this paper, we challenge such\ndetectors to gain better insight into their vulnerabilities. This is an\nimportant study in order to build better forgery detectors able to face\nmalicious attacks. Our proposal consists of a GAN-based approach that injects\ncamera traces into synthetic images. Given a GAN-generated image, we insert the\ntraces of a specific camera model into it and deceive state-of-the-art\ndetectors into believing the image was acquired by that model. Likewise, we\ndeceive independent detectors of synthetic GAN images into believing the image\nis real. Experiments prove the effectiveness of the proposed method in a wide\narray of conditions. Moreover, no prior information on the attacked detectors\nis needed, but only sample images from the target camera.\n", "versions": [{"version": "v1", "created": "Wed, 27 Nov 2019 10:41:19 GMT"}, {"version": "v2", "created": "Thu, 22 Apr 2021 09:51:53 GMT"}], "update_date": "2021-04-23", "authors_parsed": [["Cozzolino", "Davide", ""], ["Thies", "Justus", ""], ["R\u00f6ssler", "Andreas", ""], ["Nie\u00dfner", "Matthias", ""], ["Verdoliva", "Luisa", ""]]}, {"id": "1911.12073", "submitter": "Cezary Kaliszyk", "authors": "Miroslav Ol\\v{s}\\'ak, Cezary Kaliszyk and Josef Urban", "title": "Property Invariant Embedding for Automated Reasoning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Automated reasoning and theorem proving have recently become major challenges\nfor machine learning. In other domains, representations that are able to\nabstract over unimportant transformations, such as abstraction over\ntranslations and rotations in vision, are becoming more common. Standard\nmethods of embedding mathematical formulas for learning theorem proving are\nhowever yet unable to handle many important transformations. In particular,\nembedding previously unseen labels, that often arise in definitional encodings\nand in Skolemization, has been very weak so far. Similar problems appear when\ntransferring knowledge between known symbols.\n  We propose a novel encoding of formulas that extends existing graph neural\nnetwork models. This encoding represents symbols only by nodes in the graph,\nwithout giving the network any knowledge of the original labels. We provide\nadditional links between such nodes that allow the network to recover the\nmeaning and therefore correctly embed such nodes irrespective of the given\nlabels. We test the proposed encoding in an automated theorem prover based on\nthe tableaux connection calculus, and show that it improves on the best\ncharacterizations used so far. The encoding is further evaluated on the premise\nselection task and a newly introduced symbol guessing task, and shown to\ncorrectly predict 65% of the symbol names.\n", "versions": [{"version": "v1", "created": "Wed, 27 Nov 2019 10:55:23 GMT"}], "update_date": "2019-11-28", "authors_parsed": [["Ol\u0161\u00e1k", "Miroslav", ""], ["Kaliszyk", "Cezary", ""], ["Urban", "Josef", ""]]}, {"id": "1911.12082", "submitter": "Chengyuan Wu", "authors": "Chengyuan Wu and Carol Anne Hargreaves", "title": "Topological Machine Learning for Multivariate Time Series", "comments": "18 pages, to appear in Journal of Experimental & Theoretical\n  Artificial Intelligence", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.AT cs.LG eess.SP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We develop a framework for analyzing multivariate time series using\ntopological data analysis (TDA) methods. The proposed methodology involves\nconverting the multivariate time series to point cloud data, calculating\nWasserstein distances between the persistence diagrams and using the\n$k$-nearest neighbors algorithm ($k$-NN) for supervised machine learning. Two\nmethods (symmetry-breaking and anchor points) are also introduced to enable TDA\nto better analyze data with heterogeneous features that are sensitive to\ntranslation, rotation, or choice of coordinates. We apply our methods to room\noccupancy detection based on 5 time-dependent variables (temperature, humidity,\nlight, CO2 and humidity ratio). Experimental results show that topological\nmethods are effective in predicting room occupancy during a time window. We\nalso apply our methods to an Activity Recognition dataset and obtained good\nresults.\n", "versions": [{"version": "v1", "created": "Wed, 27 Nov 2019 11:19:51 GMT"}, {"version": "v2", "created": "Wed, 6 May 2020 04:55:20 GMT"}, {"version": "v3", "created": "Sat, 26 Dec 2020 07:39:26 GMT"}], "update_date": "2020-12-29", "authors_parsed": [["Wu", "Chengyuan", ""], ["Hargreaves", "Carol Anne", ""]]}, {"id": "1911.12093", "submitter": "Ling Chen", "authors": "Weiqi Chen, Ling Chen, Yu Xie, Wei Cao, Yusong Gao, Xiaojie Feng", "title": "Multi-Range Attentive Bicomponent Graph Convolutional Network for\n  Traffic Forecasting", "comments": "Accepted by AAAI 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Traffic forecasting is of great importance to transportation management and\npublic safety, and very challenging due to the complicated spatial-temporal\ndependency and essential uncertainty brought about by the road network and\ntraffic conditions. Latest studies mainly focus on modeling the spatial\ndependency by utilizing graph convolutional networks (GCNs) throughout a fixed\nweighted graph. However, edges, i.e., the correlations between pair-wise nodes,\nare much more complicated and interact with each other. In this paper, we\npropose the Multi-Range Attentive Bicomponent GCN (MRA-BGCN), a novel deep\nlearning model for traffic forecasting. We first build the node-wise graph\naccording to the road network distance and the edge-wise graph according to\nvarious edge interaction patterns. Then, we implement the interactions of both\nnodes and edges using bicomponent graph convolution. The multi-range attention\nmechanism is introduced to aggregate information in different neighborhood\nranges and automatically learn the importance of different ranges. Extensive\nexperiments on two real-world road network traffic datasets, METR-LA and\nPEMS-BAY, show that our MRA-BGCN achieves the state-of-the-art results.\n", "versions": [{"version": "v1", "created": "Wed, 27 Nov 2019 11:48:11 GMT"}], "update_date": "2019-11-28", "authors_parsed": [["Chen", "Weiqi", ""], ["Chen", "Ling", ""], ["Xie", "Yu", ""], ["Cao", "Wei", ""], ["Gao", "Yusong", ""], ["Feng", "Xiaojie", ""]]}, {"id": "1911.12104", "submitter": "Jie Yang", "authors": "Jie Yang, Yu-Kai Wang, Xin Yao, Chin-Teng Lin", "title": "Adaptive Initialization Method for K-means Algorithm", "comments": "22 pages, 2 figures, 11 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The K-means algorithm is a widely used clustering algorithm that offers\nsimplicity and efficiency. However, the traditional K-means algorithm uses the\nrandom method to determine the initial cluster centers, which make clustering\nresults prone to local optima and then result in worse clustering performance.\nMany initialization methods have been proposed, but none of them can\ndynamically adapt to datasets with various characteristics. In our previous\nresearch, an initialization method for K-means based on hybrid distance was\nproposed, and this algorithm can adapt to datasets with different\ncharacteristics. However, it has the following drawbacks: (a) When calculating\ndensity, the threshold cannot be uniquely determined, resulting in unstable\nresults. (b) Heavily depending on adjusting the parameter, the parameter must\nbe adjusted five times to obtain better clustering results. (c) The time\ncomplexity of the algorithm is quadratic, which is difficult to apply to large\ndatasets. In the current paper, we proposed an adaptive initialization method\nfor the K-means algorithm (AIMK) to improve our previous work. AIMK can not\nonly adapt to datasets with various characteristics but also obtain better\nclustering results within two interactions. In addition, we then leverage\nrandom sampling in AIMK, which is named as AIMK-RS, to reduce the time\ncomplexity. AIMK-RS is easily applied to large and high-dimensional datasets.\nWe compared AIMK and AIMK-RS with 10 different algorithms on 16 normal and six\nextra-large datasets. The experimental results show that AIMK and AIMK-RS\noutperform the current initialization methods and several well-known clustering\nalgorithms. Furthermore, AIMK-RS can significantly reduce the complexity of\napplying it to extra-large datasets with high dimensions. The time complexity\nof AIMK-RS is O(n).\n", "versions": [{"version": "v1", "created": "Wed, 27 Nov 2019 12:27:00 GMT"}], "update_date": "2019-11-28", "authors_parsed": [["Yang", "Jie", ""], ["Wang", "Yu-Kai", ""], ["Yao", "Xin", ""], ["Lin", "Chin-Teng", ""]]}, {"id": "1911.12122", "submitter": "Dmitry Baranchuk", "authors": "Dmitry Baranchuk, Artem Babenko", "title": "Towards Similarity Graphs Constructed by Deep Reinforcement Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Similarity graphs are an active research direction for the nearest neighbor\nsearch (NNS) problem. New algorithms for similarity graph construction are\ncontinuously being proposed and analyzed by both theoreticians and\npractitioners. However, existing construction algorithms are mostly based on\nheuristics and do not explicitly maximize the target performance measure, i.e.,\nsearch recall. Therefore, at the moment it is not clear whether the performance\nof similarity graphs has plateaued or more effective graphs can be constructed\nwith more theoretically grounded methods. In this paper, we introduce a new\nprincipled algorithm, based on adjacency matrix optimization, which explicitly\nmaximizes search efficiency. Namely, we propose a probabilistic model of a\nsimilarity graph defined in terms of its edge probabilities and show how to\nlearn these probabilities from data as a reinforcement learning task. As\nconfirmed by experiments, the proposed construction method can be used to\nrefine the state-of-the-art similarity graphs, achieving higher recall rates\nfor the same number of distance computations. Furthermore, we analyze the\nlearned graphs and reveal the structural properties that are responsible for\nmore efficient search.\n", "versions": [{"version": "v1", "created": "Wed, 27 Nov 2019 13:08:30 GMT"}, {"version": "v2", "created": "Thu, 13 Feb 2020 18:59:16 GMT"}], "update_date": "2020-02-14", "authors_parsed": [["Baranchuk", "Dmitry", ""], ["Babenko", "Artem", ""]]}, {"id": "1911.12126", "submitter": "Xiangxiang Chu", "authors": "Xiangxiang Chu and Tianbao Zhou and Bo Zhang and Jixiang Li", "title": "Fair DARTS: Eliminating Unfair Advantages in Differentiable Architecture\n  Search", "comments": "Accepted to ECCV 2020, camera ready version", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Differentiable Architecture Search (DARTS) is now a widely disseminated\nweight-sharing neural architecture search method. However, it suffers from\nwell-known performance collapse due to an inevitable aggregation of skip\nconnections. In this paper, we first disclose that its root cause lies in an\nunfair advantage in exclusive competition. Through experiments, we show that if\neither of two conditions is broken, the collapse disappears. Thereby, we\npresent a novel approach called Fair DARTS where the exclusive competition is\nrelaxed to be collaborative. Specifically, we let each operation's\narchitectural weight be independent of others. Yet there is still an important\nissue of discretization discrepancy. We then propose a zero-one loss to push\narchitectural weights towards zero or one, which approximates an expected\nmulti-hot solution. Our experiments are performed on two mainstream search\nspaces, and we derive new state-of-the-art results on CIFAR-10 and ImageNet.\nOur code is available on https://github.com/xiaomi-automl/fairdarts .\n", "versions": [{"version": "v1", "created": "Wed, 27 Nov 2019 13:10:25 GMT"}, {"version": "v2", "created": "Tue, 10 Mar 2020 11:31:52 GMT"}, {"version": "v3", "created": "Wed, 15 Jul 2020 02:37:59 GMT"}, {"version": "v4", "created": "Thu, 16 Jul 2020 01:16:52 GMT"}], "update_date": "2020-07-17", "authors_parsed": [["Chu", "Xiangxiang", ""], ["Zhou", "Tianbao", ""], ["Zhang", "Bo", ""], ["Li", "Jixiang", ""]]}, {"id": "1911.12143", "submitter": "Takahiro Yabe", "authors": "Takahiro Yabe, Kota Tsubouchi, Toru Shimizu, Yoshihide Sekimoto,\n  Satish V. Ukkusuri", "title": "City2City: Translating Place Representations across Cities", "comments": "A short 4-page version of this work was accepted in ACM SIGSPATIAL\n  Conference 2019. This is the full version with details. In Proceedings of the\n  27th ACM SIGSPATIAL International Conference on Advances in Geographic\n  Information Systems. ACM", "journal-ref": null, "doi": "10.1145/3347146.3359063", "report-no": null, "categories": "cs.LG cs.CY stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Large mobility datasets collected from various sources have allowed us to\nobserve, analyze, predict and solve a wide range of important urban challenges.\nIn particular, studies have generated place representations (or embeddings)\nfrom mobility patterns in a similar manner to word embeddings to better\nunderstand the functionality of different places within a city. However,\nstudies have been limited to generating such representations of cities in an\nindividual manner and has lacked an inter-city perspective, which has made it\ndifficult to transfer the insights gained from the place representations across\ndifferent cities. In this study, we attempt to bridge this research gap by\ntreating \\textit{cities} and \\textit{languages} analogously. We apply methods\ndeveloped for unsupervised machine language translation tasks to translate\nplace representations across different cities. Real world mobility data\ncollected from mobile phone users in 2 cities in Japan are used to test our\nplace representation translation methods. Translated place representations are\nvalidated using landuse data, and results show that our methods were able to\naccurately translate place representations from one city to another.\n", "versions": [{"version": "v1", "created": "Tue, 26 Nov 2019 18:57:43 GMT"}], "update_date": "2019-11-28", "authors_parsed": [["Yabe", "Takahiro", ""], ["Tsubouchi", "Kota", ""], ["Shimizu", "Toru", ""], ["Sekimoto", "Yoshihide", ""], ["Ukkusuri", "Satish V.", ""]]}, {"id": "1911.12152", "submitter": "Manraj Singh Grover", "authors": "Baani Leen Kaur Jolly, Palash Aggrawal, Surabhi S Nath, Viresh Gupta,\n  Manraj Singh Grover, Rajiv Ratn Shah", "title": "Universal EEG Encoder for Learning Diverse Intelligent Tasks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.SP cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Brain Computer Interfaces (BCI) have become very popular with\nElectroencephalography (EEG) being one of the most commonly used signal\nacquisition techniques. A major challenge in BCI studies is the individualistic\nanalysis required for each task. Thus, task-specific feature extraction and\nclassification are performed, which fails to generalize to other tasks with\nsimilar time-series EEG input data. To this end, we design a GRU-based\nuniversal deep encoding architecture to extract meaningful features from\npublicly available datasets for five diverse EEG-based classification tasks.\nOur network can generate task and format-independent data representation and\noutperform the state of the art EEGNet architecture on most experiments. We\nalso compare our results with CNN-based, and Autoencoder networks, in turn\nperforming local, spatial, temporal and unsupervised analysis on the data.\n", "versions": [{"version": "v1", "created": "Tue, 26 Nov 2019 08:13:32 GMT"}], "update_date": "2019-11-28", "authors_parsed": [["Jolly", "Baani Leen Kaur", ""], ["Aggrawal", "Palash", ""], ["Nath", "Surabhi S", ""], ["Gupta", "Viresh", ""], ["Grover", "Manraj Singh", ""], ["Shah", "Rajiv Ratn", ""]]}, {"id": "1911.12159", "submitter": "H\\'ector Andrade-Loarca", "authors": "H\\'ector Andrade-Loarca, Gitta Kutyniok and Ozan \\\"Oktem", "title": "Shearlets as Feature Extractor for Semantic Edge Detection: The\n  Model-Based and Data-Driven Realm", "comments": "30 pages, 12 figures. To appear in Proceedings of the Royal Society.\n  Mathematical, physical and engineering sciences", "journal-ref": null, "doi": "10.1098/rspa.2019.0841", "report-no": null, "categories": "eess.IV cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Semantic edge detection has recently gained a lot of attention as an image\nprocessing task, mainly due to its wide range of real-world applications. This\nis based on the fact that edges in images contain most of the semantic\ninformation. Semantic edge detection involves two tasks, namely pure edge\ndetecion and edge classification. Those are in fact fundamentally distinct in\nterms of the level of abstraction that each task requires, which is known as\nthe distracted supervision paradox that limits the possible performance of a\nsupervised model in semantic edge detection. In this work, we will present a\nnovel hybrid method to avoid the distracted supervision paradox and achieve\nhigh-performance in semantic edge detection. Our approach is based on a\ncombination of the model-based concept of shearlets, which provides probably\noptimally sparse approximations of a model-class of images, and the data-driven\nmethod of a suitably designed convolutional neural netwok. Finally, we present\nseveral applications such as tomographic reconstruction and show that our\napproach signifiantly outperforms former methods, thereby indicating the value\nof such hybrid methods for the area in biomedical imaging.\n", "versions": [{"version": "v1", "created": "Wed, 27 Nov 2019 14:05:26 GMT"}], "update_date": "2021-04-28", "authors_parsed": [["Andrade-Loarca", "H\u00e9ctor", ""], ["Kutyniok", "Gitta", ""], ["\u00d6ktem", "Ozan", ""]]}, {"id": "1911.12161", "submitter": "David Zimmerer", "authors": "David Zimmerer, Jens Petersen, Klaus Maier-Hein", "title": "High- and Low-level image component decomposition using VAEs for\n  improved reconstruction and anomaly detection", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV eess.IV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Variational Auto-Encoders have often been used for unsupervised pretraining,\nfeature extraction and out-of-distribution and anomaly detection in the medical\nfield. However, VAEs often lack the ability to produce sharp images and learn\nhigh-level features. We propose to alleviate these issues by adding a new\nbranch to conditional hierarchical VAEs. This enforces a division between\nhigher-level and lower-level features. Despite the additional computational\noverhead compared to a normal VAE it results in sharper and better\nreconstructions and can capture the data distribution similarly well (indicated\nby a similar or slightly better OoD detection performance).\n", "versions": [{"version": "v1", "created": "Wed, 27 Nov 2019 14:08:25 GMT"}], "update_date": "2019-11-28", "authors_parsed": [["Zimmerer", "David", ""], ["Petersen", "Jens", ""], ["Maier-Hein", "Klaus", ""]]}, {"id": "1911.12178", "submitter": "Karan Singh", "authors": "Elad Hazan, Sham M. Kakade, Karan Singh", "title": "The Nonstochastic Control Problem", "comments": "To appear at Algorithmic Learning Theory (ALT) 2020; small revisions\n  from the last ver", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the problem of controlling an unknown linear dynamical system in\nthe presence of (nonstochastic) adversarial perturbations and adversarial\nconvex loss functions. In contrast to classical control, the a priori\ndetermination of an optimal controller here is hindered by the latter's\ndependence on the yet unknown perturbations and costs. Instead, we measure\nregret against an optimal linear policy in hindsight, and give the first\nefficient algorithm that guarantees a sublinear regret bound, scaling as\nT^{2/3}, in this setting.\n", "versions": [{"version": "v1", "created": "Wed, 27 Nov 2019 14:29:50 GMT"}, {"version": "v2", "created": "Mon, 20 Jan 2020 08:08:10 GMT"}], "update_date": "2020-01-22", "authors_parsed": [["Hazan", "Elad", ""], ["Kakade", "Sham M.", ""], ["Singh", "Karan", ""]]}, {"id": "1911.12199", "submitter": "Ana Lucic", "authors": "Ana Lucic, Harrie Oosterhuis, Hinda Haned, Maarten de Rijke", "title": "FOCUS: Flexible Optimizable Counterfactual Explanations for Tree\n  Ensembles", "comments": "Under review", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Model interpretability has become an important problem in machine learning\n(ML) due to the increased effect algorithmic decisions have on humans.\nCounterfactual explanations can help users understand not only why ML models\nmake certain decisions, but also give insight into how these decisions can be\nmodified. We frame the problem of finding counterfactual explanations as an\noptimization task and extend previous work that could only be applied to\ndifferentiable models. In order to accommodate non-differentiable models such\nas tree ensembles, we propose using probabilistic model approximations in the\noptimization framework. We introduce a simple approximation technique that is\neffective for finding counterfactual explanations for predictions of the\noriginal model using a range of distance metrics. We show that our\ncounterfactual examples are significantly closer to the original instances\ncompared to other methods designed for tree ensembles for four distance\nmetrics.\n", "versions": [{"version": "v1", "created": "Wed, 27 Nov 2019 14:57:11 GMT"}, {"version": "v2", "created": "Thu, 9 Jul 2020 10:07:38 GMT"}, {"version": "v3", "created": "Wed, 14 Oct 2020 07:35:36 GMT"}], "update_date": "2020-10-15", "authors_parsed": [["Lucic", "Ana", ""], ["Oosterhuis", "Harrie", ""], ["Haned", "Hinda", ""], ["de Rijke", "Maarten", ""]]}, {"id": "1911.12205", "submitter": "Junyi Gao", "authors": "Liantao Ma, Junyi Gao, Yasha Wang, Chaohe Zhang, Jiangtao Wang, Wenjie\n  Ruan, Wen Tang, Xin Gao, Xinyu Ma", "title": "AdaCare: Explainable Clinical Health Status Representation Learning via\n  Scale-Adaptive Feature Extraction and Recalibration", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep learning-based health status representation learning and clinical\nprediction have raised much research interest in recent years. Existing models\nhave shown superior performance, but there are still several major issues that\nhave not been fully taken into consideration. First, the historical variation\npattern of the biomarker in diverse time scales plays a vital role in\nindicating the health status, but it has not been explicitly extracted by\nexisting works. Second, key factors that strongly indicate the health risk are\ndifferent among patients. It is still challenging to adaptively make use of the\nfeatures for patients in diverse conditions. Third, using prediction models as\nthe black box will limit the reliability in clinical practice. However, none of\nthe existing works can provide satisfying interpretability and meanwhile\nachieve high prediction performance. In this work, we develop a general health\nstatus representation learning model, named AdaCare. It can capture the long\nand short-term variations of biomarkers as clinical features to depict the\nhealth status in multiple time scales. It also models the correlation between\nclinical features to enhance the ones which strongly indicate the health status\nand thus can maintain a state-of-the-art performance in terms of prediction\naccuracy while providing qualitative interpretability. We conduct a health risk\nprediction experiment on two real-world datasets. Experiment results indicate\nthat AdaCare outperforms state-of-the-art approaches and provides effective\ninterpretability, which is verifiable by clinical experts.\n", "versions": [{"version": "v1", "created": "Wed, 27 Nov 2019 15:02:26 GMT"}], "update_date": "2019-11-28", "authors_parsed": [["Ma", "Liantao", ""], ["Gao", "Junyi", ""], ["Wang", "Yasha", ""], ["Zhang", "Chaohe", ""], ["Wang", "Jiangtao", ""], ["Ruan", "Wenjie", ""], ["Tang", "Wen", ""], ["Gao", "Xin", ""], ["Ma", "Xinyu", ""]]}, {"id": "1911.12216", "submitter": "Junyi Gao", "authors": "Liantao Ma, Chaohe Zhang, Yasha Wang, Wenjie Ruan, Jiantao Wang, Wen\n  Tang, Xinyu Ma, Xin Gao, Junyi Gao", "title": "ConCare: Personalized Clinical Feature Embedding via Capturing the\n  Healthcare Context", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Predicting the patient's clinical outcome from the historical electronic\nmedical records (EMR) is a fundamental research problem in medical informatics.\nMost deep learning-based solutions for EMR analysis concentrate on learning the\nclinical visit embedding and exploring the relations between visits. Although\nthose works have shown superior performances in healthcare prediction, they\nfail to explore the personal characteristics during the clinical visits\nthoroughly. Moreover, existing works usually assume that the more recent record\nweights more in the prediction, but this assumption is not suitable for all\nconditions. In this paper, we propose ConCare to handle the irregular EMR data\nand extract feature interrelationship to perform individualized healthcare\nprediction. Our solution can embed the feature sequences separately by modeling\nthe time-aware distribution. ConCare further improves the multi-head\nself-attention via the cross-head decorrelation, so that the inter-dependencies\namong dynamic features and static baseline information can be effectively\ncaptured to form the personal health context. Experimental results on two\nreal-world EMR datasets demonstrate the effectiveness of ConCare. The medical\nfindings extracted by ConCare are also empirically confirmed by human experts\nand medical literature.\n", "versions": [{"version": "v1", "created": "Wed, 27 Nov 2019 15:19:15 GMT"}], "update_date": "2019-11-28", "authors_parsed": [["Ma", "Liantao", ""], ["Zhang", "Chaohe", ""], ["Wang", "Yasha", ""], ["Ruan", "Wenjie", ""], ["Wang", "Jiantao", ""], ["Tang", "Wen", ""], ["Ma", "Xinyu", ""], ["Gao", "Xin", ""], ["Gao", "Junyi", ""]]}, {"id": "1911.12224", "submitter": "Bianca Iancu", "authors": "Bianca Iancu, Gabriele Mazzola, Kyriakos Psarakis, Panagiotis Soilis", "title": "Multi-label Classification for Automatic Tag Prediction in the Context\n  of Programming Challenges", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  One of the best ways for developers to test and improve their skills in a fun\nand challenging way are programming challenges, offered by a plethora of\nwebsites. For the inexperienced ones, some of the problems might appear too\nchallenging, requiring some suggestions to implement a solution. On the other\nhand, tagging problems can be a tedious task for problem creators. In this\npaper, we focus on automating the task of tagging a programming challenge\ndescription using machine and deep learning methods. We observe that the deep\nlearning methods implemented outperform well-known IR approaches such as\ntf-idf, thus providing a starting point for further research on the task.\n", "versions": [{"version": "v1", "created": "Wed, 27 Nov 2019 15:35:25 GMT"}], "update_date": "2019-11-28", "authors_parsed": [["Iancu", "Bianca", ""], ["Mazzola", "Gabriele", ""], ["Psarakis", "Kyriakos", ""], ["Soilis", "Panagiotis", ""]]}, {"id": "1911.12239", "submitter": "Florian Jug", "authors": "Mangal Prakash, Tim-Oliver Buchholz, Manan Lalit, Pavel Tomancak,\n  Florian Jug, Alexander Krull", "title": "Leveraging Self-supervised Denoising for Image Segmentation", "comments": "accepted at ISBI 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.IV cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep learning (DL) has arguably emerged as the method of choice for the\ndetection and segmentation of biological structures in microscopy images.\nHowever, DL typically needs copious amounts of annotated training data that is\nfor biomedical projects typically not available and excessively expensive to\ngenerate. Additionally, tasks become harder in the presence of noise, requiring\neven more high-quality training data. Hence, we propose to use denoising\nnetworks to improve the performance of other DL-based image segmentation\nmethods. More specifically, we present ideas on how state-of-the-art\nself-supervised CARE networks can improve cell/nuclei segmentation in\nmicroscopy data. Using two state-of-the-art baseline methods, U-Net and\nStarDist, we show that our ideas consistently improve the quality of resulting\nsegmentations, especially when only limited training data for noisy micrographs\nare available.\n", "versions": [{"version": "v1", "created": "Wed, 27 Nov 2019 15:56:27 GMT"}, {"version": "v2", "created": "Fri, 13 Dec 2019 14:27:59 GMT"}, {"version": "v3", "created": "Thu, 19 Mar 2020 09:15:05 GMT"}], "update_date": "2020-03-20", "authors_parsed": [["Prakash", "Mangal", ""], ["Buchholz", "Tim-Oliver", ""], ["Lalit", "Manan", ""], ["Tomancak", "Pavel", ""], ["Jug", "Florian", ""], ["Krull", "Alexander", ""]]}, {"id": "1911.12247", "submitter": "Thomas Kipf", "authors": "Thomas Kipf, Elise van der Pol, Max Welling", "title": "Contrastive Learning of Structured World Models", "comments": "ICLR 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A structured understanding of our world in terms of objects, relations, and\nhierarchies is an important component of human cognition. Learning such a\nstructured world model from raw sensory data remains a challenge. As a step\ntowards this goal, we introduce Contrastively-trained Structured World Models\n(C-SWMs). C-SWMs utilize a contrastive approach for representation learning in\nenvironments with compositional structure. We structure each state embedding as\na set of object representations and their relations, modeled by a graph neural\nnetwork. This allows objects to be discovered from raw pixel observations\nwithout direct supervision as part of the learning process. We evaluate C-SWMs\non compositional environments involving multiple interacting objects that can\nbe manipulated independently by an agent, simple Atari games, and a\nmulti-object physics simulation. Our experiments demonstrate that C-SWMs can\novercome limitations of models based on pixel reconstruction and outperform\ntypical representatives of this model class in highly structured environments,\nwhile learning interpretable object-based representations.\n", "versions": [{"version": "v1", "created": "Wed, 27 Nov 2019 16:10:04 GMT"}, {"version": "v2", "created": "Sun, 5 Jan 2020 13:38:44 GMT"}], "update_date": "2020-01-07", "authors_parsed": [["Kipf", "Thomas", ""], ["van der Pol", "Elise", ""], ["Welling", "Max", ""]]}, {"id": "1911.12250", "submitter": "Edouard Leurent", "authors": "Edouard Leurent, Jean Mercat", "title": "Social Attention for Autonomous Decision-Making in Dense Traffic", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the design of learning architectures for behavioural planning in a\ndense traffic setting. Such architectures should deal with a varying number of\nnearby vehicles, be invariant to the ordering chosen to describe them, while\nstaying accurate and compact. We observe that the two most popular\nrepresentations in the literature do not fit these criteria, and perform badly\non an complex negotiation task. We propose an attention-based architecture that\nsatisfies all these properties and explicitly accounts for the existing\ninteractions between the traffic participants. We show that this architecture\nleads to significant performance gains, and is able to capture interactions\npatterns that can be visualised and qualitatively interpreted. Videos and code\nare available at https://eleurent.github.io/social-attention/.\n", "versions": [{"version": "v1", "created": "Wed, 27 Nov 2019 16:14:15 GMT"}], "update_date": "2019-11-28", "authors_parsed": [["Leurent", "Edouard", ""], ["Mercat", "Jean", ""]]}, {"id": "1911.12252", "submitter": "Tong Zhu", "authors": "Jinzhe Zeng, Liqun Cao, Mingyuan Xu, Tong Zhu, and John ZH Zhang", "title": "Neural Network Based in Silico Simulation of Combustion Reactions", "comments": "Version_01", "journal-ref": "Nat. Commun., 11, 5713 (2020)", "doi": "10.1038/s41467-020-19497-z", "report-no": null, "categories": "physics.chem-ph cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Understanding and prediction of the chemical reactions are fundamental\ndemanding in the study of many complex chemical systems. Reactive molecular\ndynamics (MD) simulation has been widely used for this purpose as it can offer\natomic details and can help us better interpret chemical reaction mechanisms.\nIn this study, two reference datasets were constructed and corresponding neural\nnetwork (NN) potentials were trained based on them. For given large-scale\nreaction systems, the NN potentials can predict the potential energy and atomic\nforces of DFT precision, while it is orders of magnitude faster than the\nconventional DFT calculation. With these two models, reactive MD simulations\nwere performed to explore the combustion mechanisms of hydrogen and methane.\nBenefit from the high efficiency of the NN model, nanosecond MD trajectories\nfor large-scale systems containing hundreds of atoms were produced and detailed\ncombustion mechanism was obtained. Through further development, the algorithms\nin this study can be used to explore and discovery reaction mechanisms of many\ncomplex reaction systems, such as combustion, synthesis, and heterogeneous\ncatalysis without any predefined reaction coordinates and elementary reaction\nsteps.\n", "versions": [{"version": "v1", "created": "Wed, 27 Nov 2019 16:22:21 GMT"}], "update_date": "2020-11-12", "authors_parsed": [["Zeng", "Jinzhe", ""], ["Cao", "Liqun", ""], ["Xu", "Mingyuan", ""], ["Zhu", "Tong", ""], ["Zhang", "John ZH", ""]]}, {"id": "1911.12253", "submitter": "Paul Samuel Ignacio", "authors": "Paul Samuel Ignacio, David Uminsky, Christopher Dunstan, Esteban\n  Escobar, Luke Trujillo", "title": "Classification of Single-lead Electrocardiograms: TDA Informed Machine\n  Learning", "comments": "\\c{opyright} 2019 IEEE. Personal use of this material is permitted.\n  Permission from IEEE must be obtained for all other uses, in any current or\n  future media, including reprinting/republishing this material for advertising\n  or promotional purposes, creating new collective works, for resale or\n  redistribution to servers or lists, or reuse of any copyrighted component of\n  this work in other works", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.QM cs.LG eess.SP math.AT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Atrial Fibrillation is a heart condition characterized by erratic heart\nrhythms caused by chaotic propagation of electrical impulses in the atria,\nleading to numerous health complications. State-of-the-art models employ\ncomplex algorithms that extract expert-informed features to improve diagnosis.\nIn this note, we demonstrate how topological features can be used to help\naccurately classify single lead electrocardiograms. Via delay embeddings, we\nmap electrocardiograms onto high-dimensional point-clouds that convert periodic\nsignals to algebraically computable topological signatures. We derive features\nfrom persistent signatures, input them to a simple machine learning algorithm,\nand benchmark its performance against winning entries in the 2017 Physionet\nComputing in Cardiology Challenge.\n", "versions": [{"version": "v1", "created": "Mon, 25 Nov 2019 05:20:48 GMT"}, {"version": "v2", "created": "Thu, 28 Nov 2019 02:12:48 GMT"}], "update_date": "2019-12-02", "authors_parsed": [["Ignacio", "Paul Samuel", ""], ["Uminsky", "David", ""], ["Dunstan", "Christopher", ""], ["Escobar", "Esteban", ""], ["Trujillo", "Luke", ""]]}, {"id": "1911.12258", "submitter": "Nuri Mert Vural", "authors": "Nuri Mert Vural, Fatih Ilhan and Suleyman S. Kozat", "title": "Stability of the Decoupled Extended Kalman Filter Learning Algorithm in\n  LSTM-Based Online Learning", "comments": "This paper was an early draft of the presented results. We have\n  written and published another paper (arXiv:1911.12258) where we have improved\n  on the material in this paper. The published paper covers most of the\n  material presented in this paper as well. Therefore, we remove this paper\n  from Arxiv and refer the interested readers to arXiv:1911.12258", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG eess.SP stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We investigate the convergence and stability properties of the decoupled\nextended Kalman filter learning algorithm (DEKF) within the long-short term\nmemory network (LSTM) based online learning framework. For this purpose, we\nmodel DEKF as a perturbed extended Kalman filter and derive sufficient\nconditions for its stability during LSTM training. We show that if the\nperturbations -- introduced due to decoupling -- stay bounded, DEKF learns LSTM\nparameters with similar convergence and stability properties of the global\nextended Kalman filter learning algorithm. We verify our results with several\nnumerical simulations and compare DEKF with other LSTM training methods. In our\nsimulations, we also observe that the well-known hyper-parameter selection\napproaches used for DEKF in the literature satisfy our conditions.\n", "versions": [{"version": "v1", "created": "Mon, 25 Nov 2019 19:34:31 GMT"}, {"version": "v2", "created": "Thu, 28 Nov 2019 08:28:41 GMT"}, {"version": "v3", "created": "Sat, 7 Mar 2020 16:06:22 GMT"}, {"version": "v4", "created": "Mon, 31 May 2021 15:32:54 GMT"}], "update_date": "2021-06-01", "authors_parsed": [["Vural", "Nuri Mert", ""], ["Ilhan", "Fatih", ""], ["Kozat", "Suleyman S.", ""]]}, {"id": "1911.12285", "submitter": "Abishek Sankararaman", "authors": "Abishek Sankararaman, Haris Vikalo, Fran\\c{c}ois Baccelli", "title": "ComHapDet: A Spatial Community Detection Algorithm for Haplotype\n  Assembly", "comments": "To Appear in BMC Genomics. Extended Abstract in ACM CNB-MAC 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SI cs.IT cs.LG math.IT q-bio.GN", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Background: Haplotypes, the ordered lists of single nucleotide variations\nthat distinguish chromosomal sequences from their homologous pairs, may reveal\nan individual's susceptibility to hereditary and complex diseases and affect\nhow our bodies respond to therapeutic drugs. Reconstructing haplotypes of an\nindividual from short sequencing reads is an NP-hard problem that becomes even\nmore challenging in the case of polyploids. While increasing lengths of\nsequencing reads and insert sizes {\\color{black} helps improve accuracy of\nreconstruction}, it also exacerbates computational complexity of the haplotype\nassembly task. This has motivated the pursuit of algorithmic frameworks capable\nof accurate yet efficient assembly of haplotypes from high-throughput\nsequencing data.\n  Results: We propose a novel graphical representation of sequencing reads and\npose the haplotype assembly problem as an instance of community detection on a\nspatial random graph. To this end, we construct a graph where each read is a\nnode with an unknown community label associating the read with the haplotype it\nsamples. Haplotype reconstruction can then be thought of as a two-step\nprocedure: first, one recovers the community labels on the nodes (i.e., the\nreads), and then uses the estimated labels to assemble the haplotypes. Based on\nthis observation, we propose ComHapDet - a novel assembly algorithm for diploid\nand ployploid haplotypes which allows both bialleleic and multi-allelic\nvariants.\n  Conclusions: Performance of the proposed algorithm is benchmarked on\nsimulated as well as experimental data obtained by sequencing Chromosome $5$ of\ntetraploid biallelic \\emph{Solanum-Tuberosum} (Potato). The results demonstrate\nthe efficacy of the proposed method and that it compares favorably with the\nexisting techniques.\n", "versions": [{"version": "v1", "created": "Wed, 27 Nov 2019 17:01:07 GMT"}], "update_date": "2019-11-28", "authors_parsed": [["Sankararaman", "Abishek", ""], ["Vikalo", "Haris", ""], ["Baccelli", "Fran\u00e7ois", ""]]}, {"id": "1911.12287", "submitter": "Giannis Daras", "authors": "Giannis Daras, Augustus Odena, Han Zhang, Alexandros G. Dimakis", "title": "Your Local GAN: Designing Two Dimensional Local Attention Mechanisms for\n  Generative Models", "comments": "Added TFRC, tensorflow-gan acknowledgements. Changed \"Ablation Study\"\n  to \"Ablation Studies\"", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce a new local sparse attention layer that preserves\ntwo-dimensional geometry and locality. We show that by just replacing the dense\nattention layer of SAGAN with our construction, we obtain very significant FID,\nInception score and pure visual improvements. FID score is improved from\n$18.65$ to $15.94$ on ImageNet, keeping all other parameters the same. The\nsparse attention patterns that we propose for our new layer are designed using\na novel information theoretic criterion that uses information flow graphs. We\nalso present a novel way to invert Generative Adversarial Networks with\nattention. Our method extracts from the attention layer of the discriminator a\nsaliency map, which we use to construct a new loss function for the inversion.\nThis allows us to visualize the newly introduced attention heads and show that\nthey indeed capture interesting aspects of two-dimensional geometry of real\nimages.\n", "versions": [{"version": "v1", "created": "Wed, 27 Nov 2019 17:03:16 GMT"}, {"version": "v2", "created": "Mon, 2 Dec 2019 18:30:38 GMT"}], "update_date": "2019-12-03", "authors_parsed": [["Daras", "Giannis", ""], ["Odena", "Augustus", ""], ["Zhang", "Han", ""], ["Dimakis", "Alexandros G.", ""]]}, {"id": "1911.12291", "submitter": "Florian Jug", "authors": "Mangal Prakash, Manan Lalit, Pavel Tomancak, Alexander Krull, Florian\n  Jug", "title": "Fully Unsupervised Probabilistic Noise2Void", "comments": "Accepted at ISBI 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.IV cs.CV cs.LG q-bio.QM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Image denoising is the first step in many biomedical image analysis pipelines\nand Deep Learning (DL) based methods are currently best performing. A new\ncategory of DL methods such as Noise2Void or Noise2Self can be used fully\nunsupervised, requiring nothing but the noisy data. However, this comes at the\nprice of reduced reconstruction quality. The recently proposed Probabilistic\nNoise2Void (PN2V) improves results, but requires an additional noise model for\nwhich calibration data needs to be acquired. Here, we present improvements to\nPN2V that (i) replace histogram based noise models by parametric noise models,\nand (ii) show how suitable noise models can be created even in the absence of\ncalibration data. This is a major step since it actually renders PN2V fully\nunsupervised. We demonstrate that all proposed improvements are not only\nacademic but indeed relevant.\n", "versions": [{"version": "v1", "created": "Wed, 27 Nov 2019 17:11:59 GMT"}, {"version": "v2", "created": "Thu, 19 Mar 2020 08:52:52 GMT"}], "update_date": "2020-03-20", "authors_parsed": [["Prakash", "Mangal", ""], ["Lalit", "Manan", ""], ["Tomancak", "Pavel", ""], ["Krull", "Alexander", ""], ["Jug", "Florian", ""]]}, {"id": "1911.12296", "submitter": "Chongwen Huang", "authors": "Chongwen Huang, Sha Hu, George C. Alexandropoulos, Alessio Zappone,\n  Chau Yuen, Rui Zhang, Marco Di Renzo, and M\\'erouane Debbah", "title": "Holographic MIMO Surfaces for 6G Wireless Networks: Opportunities,\n  Challenges, and Trends", "comments": "Accepted by IEEE Wireless Communications Magazine. 8-pages, 5-figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IT cs.LG math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Future wireless networks are expected to evolve towards an intelligent and\nsoftware reconfigurable paradigm enabling ubiquitous communications between\nhumans and mobile devices. They will be also capable of sensing, controlling,\nand optimizing the wireless environment to fulfill the visions of low-power,\nhigh-throughput, massively-connected, and low-latency communications. A key\nconceptual enabler that is recently gaining increasing popularity is the\nHolographic Multiple Input Multiple Output Surface (HMIMOS) that refers to a\nlow-cost transformative wireless planar structure comprising of sub-wavelength\nmetallic or dielectric scattering particles, which is capable of impacting\nelectromagnetic waves according to desired objectives. In this article, we\nprovide an overview of HMIMOS communications by introducing the available\nhardware architectures for reconfigurable such metasurfaces and their main\ncharacteristics, as well as highlighting the opportunities and key challenges\nin designing HMIMOS-enabled communications.\n", "versions": [{"version": "v1", "created": "Wed, 27 Nov 2019 17:19:26 GMT"}, {"version": "v2", "created": "Sun, 1 Dec 2019 16:12:15 GMT"}, {"version": "v3", "created": "Sun, 19 Apr 2020 06:25:48 GMT"}], "update_date": "2020-04-21", "authors_parsed": [["Huang", "Chongwen", ""], ["Hu", "Sha", ""], ["Alexandropoulos", "George C.", ""], ["Zappone", "Alessio", ""], ["Yuen", "Chau", ""], ["Zhang", "Rui", ""], ["Di Renzo", "Marco", ""], ["Debbah", "M\u00e9rouane", ""]]}, {"id": "1911.12322", "submitter": "Avital Shafran", "authors": "Avital Shafran, Gil Segev, Shmuel Peleg, Yedid Hoshen", "title": "Crypto-Oriented Neural Architecture Design", "comments": "Full version (shorter version published in ICASSP'21)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  As neural networks revolutionize many applications, significant privacy\nconflicts between model users and providers emerge. The cryptography community\ndeveloped a variety of techniques for secure computation to address such\nprivacy issues. As generic techniques for secure computation are typically\nprohibitively ineffective, many efforts focus on optimizing their underlying\ncryptographic tools. Differently, we propose to optimize the initial design of\ncrypto-oriented neural architectures and provide a novel Partial Activation\nlayer. The proposed layer is much faster for secure computation. Evaluating our\nmethod on three state-of-the-art architectures (SqueezeNet, ShuffleNetV2, and\nMobileNetV2) demonstrates significant improvement to the efficiency of secure\ninference on common evaluation metrics.\n", "versions": [{"version": "v1", "created": "Wed, 27 Nov 2019 17:57:42 GMT"}, {"version": "v2", "created": "Wed, 12 Aug 2020 17:48:31 GMT"}, {"version": "v3", "created": "Tue, 16 Feb 2021 06:42:31 GMT"}], "update_date": "2021-02-17", "authors_parsed": [["Shafran", "Avital", ""], ["Segev", "Gil", ""], ["Peleg", "Shmuel", ""], ["Hoshen", "Yedid", ""]]}, {"id": "1911.12360", "submitter": "Quanquan Gu", "authors": "Zixiang Chen and Yuan Cao and Difan Zou and Quanquan Gu", "title": "How Much Over-parameterization Is Sufficient to Learn Deep ReLU\n  Networks?", "comments": "26 pages, 1 figure, 1 table", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG math.OC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A recent line of research on deep learning focuses on the extremely\nover-parameterized setting, and shows that when the network width is larger\nthan a high degree polynomial of the training sample size $n$ and the inverse\nof the target error $\\epsilon^{-1}$, deep neural networks learned by\n(stochastic) gradient descent enjoy nice optimization and generalization\nguarantees. Very recently, it is shown that under certain margin assumptions on\nthe training data, a polylogarithmic width condition suffices for two-layer\nReLU networks to converge and generalize (Ji and Telgarsky, 2019). However,\nwhether deep neural networks can be learned with such a mild\nover-parameterization is still an open question. In this work, we answer this\nquestion affirmatively and establish sharper learning guarantees for deep ReLU\nnetworks trained by (stochastic) gradient descent. In specific, under certain\nassumptions made in previous work, our optimization and generalization\nguarantees hold with network width polylogarithmic in $n$ and $\\epsilon^{-1}$.\nOur results push the study of over-parameterized deep neural networks towards\nmore practical settings.\n", "versions": [{"version": "v1", "created": "Wed, 27 Nov 2019 18:59:50 GMT"}, {"version": "v2", "created": "Wed, 4 Mar 2020 05:22:34 GMT"}, {"version": "v3", "created": "Mon, 5 Oct 2020 17:41:21 GMT"}], "update_date": "2020-10-06", "authors_parsed": [["Chen", "Zixiang", ""], ["Cao", "Yuan", ""], ["Zou", "Difan", ""], ["Gu", "Quanquan", ""]]}, {"id": "1911.12377", "submitter": "Federico Landi", "authors": "Federico Landi, Lorenzo Baraldi, Marcella Cornia, Massimiliano\n  Corsini, Rita Cucchiara", "title": "Perceive, Transform, and Act: Multi-Modal Attention Networks for\n  Vision-and-Language Navigation", "comments": "A revised version of this paper is currently under consideration at\n  Computer Vision and Image Understanding", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Vision-and-Language Navigation (VLN) is a challenging task in which an agent\nneeds to follow a language-specified path to reach a target destination. In\nthis paper, we strive for the creation of an agent able to tackle three key\nissues: multi-modality, long-term dependencies, and adaptability towards\ndifferent locomotive settings. To that end, we devise \"Perceive, Transform, and\nAct\" (PTA): a fully-attentive VLN architecture that leaves the recurrent\napproach behind and the first Transformer-like architecture incorporating three\ndifferent modalities - natural language, images, and discrete actions for the\nagent control. In particular, we adopt an early fusion strategy to merge\nlingual and visual information efficiently in our encoder. We then propose to\nrefine the decoding phase with a late fusion extension between the agent's\nhistory of actions and the perception modalities. We experimentally validate\nour model on two datasets and two different action settings. PTA surpasses\nprevious state-of-the-art architectures for low-level VLN on R2R and achieves\nthe first place for both setups in the recently proposed R4R benchmark. Our\ncode is publicly available at\nhttps://github.com/aimagelab/perceive-transform-and-act.\n", "versions": [{"version": "v1", "created": "Wed, 27 Nov 2019 19:00:24 GMT"}, {"version": "v2", "created": "Mon, 20 Jul 2020 07:30:16 GMT"}], "update_date": "2020-07-21", "authors_parsed": [["Landi", "Federico", ""], ["Baraldi", "Lorenzo", ""], ["Cornia", "Marcella", ""], ["Corsini", "Massimiliano", ""], ["Cucchiara", "Rita", ""]]}, {"id": "1911.12385", "submitter": "Sachin Mehta", "authors": "Sachin Mehta and Rik Koncel-Kedziorski and Mohammad Rastegari and\n  Hannaneh Hajishirzi", "title": "DeFINE: DEep Factorized INput Token Embeddings for Neural Sequence\n  Modeling", "comments": "Accepted at ICLR 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  For sequence models with large vocabularies, a majority of network parameters\nlie in the input and output layers. In this work, we describe a new method,\nDeFINE, for learning deep token representations efficiently. Our architecture\nuses a hierarchical structure with novel skip-connections which allows for the\nuse of low dimensional input and output layers, reducing total parameters and\ntraining time while delivering similar or better performance versus existing\nmethods. DeFINE can be incorporated easily in new or existing sequence models.\nCompared to state-of-the-art methods including adaptive input representations,\nthis technique results in a 6% to 20% drop in perplexity. On WikiText-103,\nDeFINE reduces the total parameters of Transformer-XL by half with minimal\nimpact on performance. On the Penn Treebank, DeFINE improves AWD-LSTM by 4\npoints with a 17% reduction in parameters, achieving comparable performance to\nstate-of-the-art methods with fewer parameters. For machine translation, DeFINE\nimproves the efficiency of the Transformer model by about 1.4 times while\ndelivering similar performance.\n", "versions": [{"version": "v1", "created": "Wed, 27 Nov 2019 19:09:41 GMT"}, {"version": "v2", "created": "Thu, 6 Feb 2020 01:32:06 GMT"}], "update_date": "2020-02-07", "authors_parsed": [["Mehta", "Sachin", ""], ["Koncel-Kedziorski", "Rik", ""], ["Rastegari", "Mohammad", ""], ["Hajishirzi", "Hannaneh", ""]]}, {"id": "1911.12408", "submitter": "Wenxuan Wu", "authors": "Wenxuan Wu, Zhiyuan Wang, Zhuwen Li, Wei Liu, Li Fuxin", "title": "PointPWC-Net: A Coarse-to-Fine Network for Supervised and\n  Self-Supervised Scene Flow Estimation on 3D Point Clouds", "comments": "ECCV 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG eess.IV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a novel end-to-end deep scene flow model, called PointPWC-Net, on\n3D point clouds in a coarse-to-fine fashion. Flow computed at the coarse level\nis upsampled and warped to a finer level, enabling the algorithm to accommodate\nfor large motion without a prohibitive search space. We introduce novel cost\nvolume, upsampling, and warping layers to efficiently handle 3D point cloud\ndata. Unlike traditional cost volumes that require exhaustively computing all\nthe cost values on a high-dimensional grid, our point-based formulation\ndiscretizes the cost volume onto input 3D points, and a PointConv operation\nefficiently computes convolutions on the cost volume. Experiment results on\nFlyingThings3D outperform the state-of-the-art by a large margin. We further\nexplore novel self-supervised losses to train our model and achieve comparable\nresults to state-of-the-art trained with supervised loss. Without any\nfine-tuning, our method also shows great generalization ability on KITTI Scene\nFlow 2015 dataset, outperforming all previous methods.\n", "versions": [{"version": "v1", "created": "Wed, 27 Nov 2019 20:29:33 GMT"}, {"version": "v2", "created": "Fri, 31 Jul 2020 03:43:04 GMT"}], "update_date": "2020-08-03", "authors_parsed": [["Wu", "Wenxuan", ""], ["Wang", "Zhiyuan", ""], ["Li", "Zhuwen", ""], ["Liu", "Wei", ""], ["Fuxin", "Li", ""]]}, {"id": "1911.12409", "submitter": "Eli Shlizerman", "authors": "Kun Su, Xiulong Liu and Eli Shlizerman", "title": "PREDICT & CLUSTER: Unsupervised Skeleton Based Action Recognition", "comments": "See video at: https://www.youtube.com/watch?v=-dcCFUBRmwE", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG eess.IV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a novel system for unsupervised skeleton-based action recognition.\nGiven inputs of body keypoints sequences obtained during various movements, our\nsystem associates the sequences with actions. Our system is based on an\nencoder-decoder recurrent neural network, where the encoder learns a separable\nfeature representation within its hidden states formed by training the model to\nperform prediction task. We show that according to such unsupervised training\nthe decoder and the encoder self-organize their hidden states into a feature\nspace which clusters similar movements into the same cluster and distinct\nmovements into distant clusters. Current state-of-the-art methods for action\nrecognition are strongly supervised, i.e., rely on providing labels for\ntraining. Unsupervised methods have been proposed, however, they require camera\nand depth inputs (RGB+D) at each time step. In contrast, our system is fully\nunsupervised, does not require labels of actions at any stage, and can operate\nwith body keypoints input only. Furthermore, the method can perform on various\ndimensions of body keypoints (2D or 3D) and include additional cues describing\nmovements. We evaluate our system on three extensive action recognition\nbenchmarks with different number of actions and examples. Our results\noutperform prior unsupervised skeleton-based methods, unsupervised RGB+D based\nmethods on cross-view tests and while being unsupervised have similar\nperformance to supervised skeleton-based action recognition.\n", "versions": [{"version": "v1", "created": "Wed, 27 Nov 2019 20:34:54 GMT"}], "update_date": "2019-12-02", "authors_parsed": [["Su", "Kun", ""], ["Liu", "Xiulong", ""], ["Shlizerman", "Eli", ""]]}, {"id": "1911.12410", "submitter": "Shahin Khobahi", "authors": "Shahin Khobahi, Mojtaba Soltanalian", "title": "Model-Aware Deep Architectures for One-Bit Compressive Variational\n  Autoencoding", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.SP cs.IT cs.LG eess.IV math.IT stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Parameterized mathematical models play a central role in understanding and\ndesign of complex information systems. However, they often cannot take into\naccount the intricate interactions innate to such systems. On the contrary,\npurely data-driven approaches do not need explicit mathematical models for data\ngeneration and have a wider applicability at the cost of interpretability. In\nthis paper, we consider the design of a one-bit compressive variational\nautoencoder, and propose a novel hybrid model-based and data-driven methodology\nthat allows us not only to design the sensing matrix and the quantization\nthresholds for one-bit data acquisition, but also allows for learning the\nlatent-parameters of iterative optimization algorithms specifically designed\nfor the problem of one-bit sparse signal recovery. In addition, the proposed\nmethod has the ability to adaptively learn the proper quantization thresholds,\npaving the way for amplitude recovery in one-bit compressive sensing. Our\nresults demonstrate a significant improvement compared to state-of-the-art\nmodel-based algorithms.\n", "versions": [{"version": "v1", "created": "Wed, 27 Nov 2019 20:38:16 GMT"}], "update_date": "2019-12-02", "authors_parsed": [["Khobahi", "Shahin", ""], ["Soltanalian", "Mojtaba", ""]]}, {"id": "1911.12423", "submitter": "Ximeng Sun", "authors": "Ximeng Sun, Rameswar Panda, Rogerio Feris, Kate Saenko", "title": "AdaShare: Learning What To Share For Efficient Deep Multi-Task Learning", "comments": "Neurips 2020 camera-ready version", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Multi-task learning is an open and challenging problem in computer vision.\nThe typical way of conducting multi-task learning with deep neural networks is\neither through handcrafted schemes that share all initial layers and branch out\nat an adhoc point, or through separate task-specific networks with an\nadditional feature sharing/fusion mechanism. Unlike existing methods, we\npropose an adaptive sharing approach, called AdaShare, that decides what to\nshare across which tasks to achieve the best recognition accuracy, while taking\nresource efficiency into account. Specifically, our main idea is to learn the\nsharing pattern through a task-specific policy that selectively chooses which\nlayers to execute for a given task in the multi-task network. We efficiently\noptimize the task-specific policy jointly with the network weights, using\nstandard back-propagation. Experiments on several challenging and diverse\nbenchmark datasets with a variable number of tasks well demonstrate the\nefficacy of our approach over state-of-the-art methods. Project page:\nhttps://cs-people.bu.edu/sunxm/AdaShare/project.html.\n", "versions": [{"version": "v1", "created": "Wed, 27 Nov 2019 21:07:25 GMT"}, {"version": "v2", "created": "Wed, 18 Nov 2020 21:32:28 GMT"}], "update_date": "2020-11-20", "authors_parsed": [["Sun", "Ximeng", ""], ["Panda", "Rameswar", ""], ["Feris", "Rogerio", ""], ["Saenko", "Kate", ""]]}, {"id": "1911.12426", "submitter": "Adam Sandler", "authors": "Adam Sandler, Diego Klabjan, Yuan Luo", "title": "Conditional Hierarchical Bayesian Tucker Decomposition", "comments": "20 pages, added model evaluation and log-likelihood sections", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ME stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Our research focuses on studying and developing methods for reducing the\ndimensionality of large datasets, common in biomedical applications. A major\nproblem when learning information about patients based on genetic sequencing\ndata is that there are often more feature variables (genetic data) than\nobservations (patients). This makes direct supervised learning difficult. One\nway of reducing the feature space is to use latent Dirichlet allocation in\norder to group genetic variants in an unsupervised manner. Latent Dirichlet\nallocation is a common model in natural language processing, which describes a\ndocument as a mixture of topics, each with a probability of generating certain\nwords. This can be generalized as a Bayesian tensor decomposition to account\nfor multiple feature variables. While we made some progress improving and\nmodifying these methods, our significant contributions are with hierarchical\ntopic modeling. We developed distinct methods of incorporating hierarchical\ntopic modeling, based on nested Chinese restaurant processes and Pachinko\nAllocation Machine, into Bayesian tensor decompositions. We apply these models\nto predict whether or not patients have autism spectrum disorder based on\ngenetic sequencing data. We examine a dataset from National Database for Autism\nResearch consisting of paired siblings -- one with autism, and the other\nwithout -- and counts of their genetic variants. Additionally, we linked the\ngenes with their Reactome biological pathways. We combine this information into\na tensor of patients, counts of their genetic variants, and the membership of\nthese genes in pathways. Once we decompose this tensor, we use logistic\nregression on the reduced features in order to predict if patients have autism.\nWe also perform a similar analysis of a dataset of patients with one of four\ncommon types of cancer (breast, lung, prostate, and colorectal).\n", "versions": [{"version": "v1", "created": "Wed, 27 Nov 2019 21:22:04 GMT"}, {"version": "v2", "created": "Thu, 12 Dec 2019 04:18:25 GMT"}], "update_date": "2019-12-13", "authors_parsed": [["Sandler", "Adam", ""], ["Klabjan", "Diego", ""], ["Luo", "Yuan", ""]]}, {"id": "1911.12436", "submitter": "Oskar Triebe", "authors": "Oskar Triebe, Nikolay Laptev, Ram Rajagopal", "title": "AR-Net: A simple Auto-Regressive Neural Network for time-series", "comments": "Building a bridge between traditional statistical time-series models\n  and deep-learning models. Main Topics: Time-Series, Auto-Regression, Neural\n  Networks, Sparsity, Long-Range Dependencies", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we present a new framework for time-series modeling that\ncombines the best of traditional statistical models and neural networks. We\nfocus on time-series with long-range dependencies, needed for monitoring fine\ngranularity data (e.g. minutes, seconds, milliseconds), prevalent in\noperational use-cases.\n  Traditional models, such as auto-regression fitted with least squares\n(Classic-AR) can model time-series with a concise and interpretable model. When\ndealing with long-range dependencies, Classic-AR models can become intractably\nslow to fit for large data. Recently, sequence-to-sequence models, such as\nRecurrent Neural Networks, which were originally intended for natural language\nprocessing, have become popular for time-series. However, they can be overly\ncomplex for typical time-series data and lack interpretability.\n  A scalable and interpretable model is needed to bridge the statistical and\ndeep learning-based approaches. As a first step towards this goal, we propose\nmodelling AR-process dynamics using a feed-forward neural network approach,\ntermed AR-Net. We show that AR-Net is as interpretable as Classic-AR but also\nscales to long-range dependencies.\n  Our results lead to three major conclusions: First, AR-Net learns identical\nAR-coefficients as Classic-AR, thus being equally interpretable. Second, the\ncomputational complexity with respect to the order of the AR process, is linear\nfor AR-Net as compared to a quadratic for Classic-AR. This makes it possible to\nmodel long-range dependencies within fine granularity data. Third, by\nintroducing regularization, AR-Net automatically selects and learns sparse\nAR-coefficients. This eliminates the need to know the exact order of the\nAR-process and allows to learn sparse weights for a model with long-range\ndependencies.\n", "versions": [{"version": "v1", "created": "Wed, 27 Nov 2019 21:47:59 GMT"}], "update_date": "2019-12-02", "authors_parsed": [["Triebe", "Oskar", ""], ["Laptev", "Nikolay", ""], ["Rajagopal", "Ram", ""]]}, {"id": "1911.12441", "submitter": "Trent Kyono", "authors": "Trent Kyono and Mihaela van der Schaar", "title": "Improving Model Robustness Using Causal Knowledge", "comments": "14 pages, 12 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  For decades, researchers in fields, such as the natural and social sciences,\nhave been verifying causal relationships and investigating hypotheses that are\nnow well-established or understood as truth. These causal mechanisms are\nproperties of the natural world, and thus are invariant conditions regardless\nof the collection domain or environment. We show in this paper how prior\nknowledge in the form of a causal graph can be utilized to guide model\nselection, i.e., to identify from a set of trained networks the models that are\nthe most robust and invariant to unseen domains. Our method incorporates prior\nknowledge (which can be incomplete) as a Structural Causal Model (SCM) and\ncalculates a score based on the likelihood of the SCM given the target\npredictions of a candidate model and the provided input variables. We show on\nboth publicly available and synthetic datasets that our method is able to\nidentify more robust models in terms of generalizability to unseen\nout-of-distribution test examples and domains where covariates have shifted.\n", "versions": [{"version": "v1", "created": "Wed, 27 Nov 2019 21:57:00 GMT"}], "update_date": "2019-12-02", "authors_parsed": [["Kyono", "Trent", ""], ["van der Schaar", "Mihaela", ""]]}, {"id": "1911.12443", "submitter": "Aniket Pramanik", "authors": "Aniket Pramanik, Hemant Aggarwal and Mathews Jacob", "title": "Calibrationless Parallel MRI using Model based Deep Learning (C-MODL)", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG eess.SP stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce a fast model based deep learning approach for calibrationless\nparallel MRI reconstruction. The proposed scheme is a non-linear generalization\nof structured low rank (SLR) methods that self learn linear annihilation\nfilters from the same subject. It pre-learns non-linear annihilation relations\nin the Fourier domain from exemplar data. The pre-learning strategy\nsignificantly reduces the computational complexity, making the proposed scheme\nthree orders of magnitude faster than SLR schemes. The proposed framework also\nallows the use of a complementary spatial domain prior; the hybrid\nregularization scheme offers improved performance over calibrated image domain\nMoDL approach. The calibrationless strategy minimizes potential mismatches\nbetween calibration data and the main scan, while eliminating the need for a\nfully sampled calibration region.\n", "versions": [{"version": "v1", "created": "Wed, 27 Nov 2019 22:04:54 GMT"}, {"version": "v2", "created": "Tue, 21 Jan 2020 13:45:49 GMT"}], "update_date": "2020-01-22", "authors_parsed": [["Pramanik", "Aniket", ""], ["Aggarwal", "Hemant", ""], ["Jacob", "Mathews", ""]]}, {"id": "1911.12446", "submitter": "Samuel Bosch", "authors": "Samuel Bosch, Alexander Sanchez de la Cerda, Mohsen Imani, Tajana\n  Simunic Rosing and Giovanni De Micheli", "title": "QubitHD: A Stochastic Acceleration Method for HD Computing-Based Machine\n  Learning", "comments": "8 pages, 7 figures, 3 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.NE stat.ML", "license": "http://creativecommons.org/publicdomain/zero/1.0/", "abstract": "  Machine Learning algorithms based on Brain-inspired Hyperdimensional (HD)\ncomputing imitate cognition by exploiting statistical properties of\nhigh-dimensional vector spaces. It is a promising solution for achieving high\nenergy-efficiency in different machine learning tasks, such as classification,\nsemi-supervised learning and clustering. A weakness of existing HD\ncomputing-based ML algorithms is the fact that they have to be binarized for\nachieving very high energy-efficiency. At the same time, binarized models reach\nlower classification accuracies. To solve the problem of the trade-off between\nenergy-efficiency and classification accuracy, we propose the QubitHD\nalgorithm. It stochastically binarizes HD-based algorithms, while maintaining\ncomparable classification accuracies to their non-binarized counterparts. The\nFPGA implementation of QubitHD provides a 65% improvement in terms of\nenergy-efficiency, and a 95% improvement in terms of the training time, as\ncompared to state-of-the-art HD-based ML algorithms. It also outperforms\nstate-of-the-art low-cost classifiers (like Binarized Neural Networks) in terms\nof speed and energy-efficiency by an order of magnitude during training and\ninference.\n", "versions": [{"version": "v1", "created": "Wed, 27 Nov 2019 22:20:00 GMT"}, {"version": "v2", "created": "Mon, 2 Dec 2019 13:12:54 GMT"}], "update_date": "2019-12-03", "authors_parsed": [["Bosch", "Samuel", ""], ["de la Cerda", "Alexander Sanchez", ""], ["Imani", "Mohsen", ""], ["Rosing", "Tajana Simunic", ""], ["De Micheli", "Giovanni", ""]]}, {"id": "1911.12457", "submitter": "Hadis Mohseni", "authors": "Sina Hojjatinia, Sajad Hamzenejadi, and Hadis Mohseni", "title": "Android Botnet Detection using Convolutional Neural Networks", "comments": "submitted to conference", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.CR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Today, Android devices are able to provide various services. They support\napplications for different purposes such as entertainment, business, health,\neducation, and banking services. Because of the functionality and popularity of\nAndroid devices as well as the open-source policy of Android OS, they have\nbecome a suitable target for attackers. Android Botnet is one of the most\ndangerous malwares because an attacker called Botmaster can control that\nremotely to perform destructive attacks. A number of researchers have used\ndifferent well-known Machine Learning (ML) methods to recognize Android Botnets\nfrom benign applications. However, these conventional methods are not able to\ndetect new sophisticated Android Botnets. In this paper, we propose a novel\nmethod based on Android permissions and Convolutional Neural Networks (CNNs) to\nclassify Botnets and benign Android applications. Being the first developed\nmethod that uses CNNs for this aim, we also proposed a novel method to\nrepresent each application as an image which is constructed based on the\nco-occurrence of used permissions in that application. The proposed CNN is a\nbinary classifier that is trained using these images. Evaluating the proposed\nmethod on 5450 Android applications consist of Botnet and benign samples, the\nobtained results show the accuracy of 97.2% and recall of 96% which is a\npromising result just using Android permissions.\n", "versions": [{"version": "v1", "created": "Wed, 27 Nov 2019 23:03:49 GMT"}], "update_date": "2019-12-02", "authors_parsed": [["Hojjatinia", "Sina", ""], ["Hamzenejadi", "Sajad", ""], ["Mohseni", "Hadis", ""]]}, {"id": "1911.12463", "submitter": "Ke Sun", "authors": "Ke Sun and Frank Nielsen", "title": "Information-Geometric Set Embeddings (IGSE): From Sets to Probability\n  Distributions", "comments": "To be presented at Sets & Partitions (NeurIPS 2019 workshop)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This letter introduces an abstract learning problem called the \"set\nembedding\": The objective is to map sets into probability distributions so as\nto lose less information. We relate set union and intersection operations with\ncorresponding interpolations of probability distributions. We also demonstrate\na preliminary solution with experimental results on toy set embedding examples.\n", "versions": [{"version": "v1", "created": "Wed, 27 Nov 2019 23:38:17 GMT"}, {"version": "v2", "created": "Wed, 11 Dec 2019 23:03:00 GMT"}], "update_date": "2019-12-13", "authors_parsed": [["Sun", "Ke", ""], ["Nielsen", "Frank", ""]]}, {"id": "1911.12466", "submitter": "Ali Javed", "authors": "Ali Javed, Scott D. Hamshaw, Donna M. Rizzo, and Byung Suk Lee", "title": "Analysis of Hydrological and Suspended Sediment Events from Mad River\n  Watershed using Multivariate Time Series Clustering", "comments": "Corrected typo in title", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Hydrological storm events are a primary driver for transporting water quality\nconstituents such as turbidity, suspended sediments and nutrients. Analyzing\nthe concentration (C) of these water quality constituents in response to\nincreased streamflow discharge (Q), particularly when monitored at high\ntemporal resolution during a hydrological event, helps to characterize the\ndynamics and flux of such constituents. A conventional approach to storm event\nanalysis is to reduce the C-Q time series to two-dimensional (2-D) hysteresis\nloops and analyze these 2-D patterns. While effective and informative to some\nextent, this hysteresis loop approach has limitations because projecting the\nC-Q time series onto a 2-D plane obscures detail (e.g., temporal variation)\nassociated with the C-Q relationships. In this paper, we address this issue\nusing a multivariate time series clustering approach. Clustering is applied to\nsequences of river discharge and suspended sediment data (acquired through\nturbidity-based monitoring) from six watersheds located in the Lake Champlain\nBasin in the northeastern United States. While clusters of the hydrological\nstorm events using the multivariate time series approach were found to be\ncorrelated to 2-D hysteresis loop classifications and watershed locations, the\nclusters differed from the 2-D hysteresis classifications. Additionally, using\navailable meteorological data associated with storm events, we examine the\ncharacteristics of computational clusters of storm events in the study\nwatersheds and identify the features driving the clustering approach.\n", "versions": [{"version": "v1", "created": "Thu, 28 Nov 2019 00:04:21 GMT"}, {"version": "v2", "created": "Fri, 20 Mar 2020 19:15:35 GMT"}], "update_date": "2020-03-24", "authors_parsed": [["Javed", "Ali", ""], ["Hamshaw", "Scott D.", ""], ["Rizzo", "Donna M.", ""], ["Lee", "Byung Suk", ""]]}, {"id": "1911.12473", "submitter": "Dang Nguyen", "authors": "Dang Nguyen, Sunil Gupta, Santu Rana, Alistair Shilton, Svetha\n  Venkatesh", "title": "Bayesian Optimization for Categorical and Category-Specific Continuous\n  Inputs", "comments": "To appear at AAAI 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Many real-world functions are defined over both categorical and\ncategory-specific continuous variables and thus cannot be optimized by\ntraditional Bayesian optimization (BO) methods. To optimize such functions, we\npropose a new method that formulates the problem as a multi-armed bandit\nproblem, wherein each category corresponds to an arm with its reward\ndistribution centered around the optimum of the objective function in\ncontinuous variables. Our goal is to identify the best arm and the maximizer of\nthe corresponding continuous function simultaneously. Our algorithm uses a\nThompson sampling scheme that helps connecting both multi-arm bandit and BO in\na unified framework. We extend our method to batch BO to allow parallel\noptimization when multiple resources are available. We theoretically analyze\nour method for convergence and prove sub-linear regret bounds. We perform a\nvariety of experiments: optimization of several benchmark functions,\nhyper-parameter tuning of a neural network, and automatic selection of the best\nmachine learning model along with its optimal hyper-parameters (a.k.a automated\nmachine learning). Comparisons with other methods demonstrate the effectiveness\nof our proposed method.\n", "versions": [{"version": "v1", "created": "Thu, 28 Nov 2019 01:05:03 GMT"}], "update_date": "2019-12-02", "authors_parsed": [["Nguyen", "Dang", ""], ["Gupta", "Sunil", ""], ["Rana", "Santu", ""], ["Shilton", "Alistair", ""], ["Venkatesh", "Svetha", ""]]}, {"id": "1911.12476", "submitter": "Shaoli Huang", "authors": "Mingjiang Liang, Shaoli Huang, Shirui Pan, Mingming Gong and Wei Liu", "title": "Learning Multi-level Weight-centric Features for Few-shot Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Few-shot learning is currently enjoying a considerable resurgence of\ninterest, aided by the recent advance of deep learning. Contemporary approaches\nbased on weight-generation scheme delivers a straightforward and flexible\nsolution to the problem. However, they did not fully consider both the\nrepresentation power for unseen categories and weight generation capacity in\nfeature learning, making it a significant performance bottleneck. This paper\nproposes a multi-level weight-centric feature learning to give full play to\nfeature extractor's dual roles in few-shot learning. Our proposed method\nconsists of two essential techniques: a weight-centric training strategy to\nimprove the features' prototype-ability and a multi-level feature incorporating\na mid- and relation-level information. The former increases the feasibility of\nconstructing a discriminative decision boundary based on a few samples.\nSimultaneously, the latter helps improve the transferability for characterizing\nnovel classes and preserve classification capability for base classes. We\nextensively evaluate our approach to low-shot classification benchmarks.\nExperiments demonstrate our proposed method significantly outperforms its\ncounterparts in both standard and generalized settings and using different\nnetwork backbones.\n", "versions": [{"version": "v1", "created": "Thu, 28 Nov 2019 01:22:59 GMT"}, {"version": "v2", "created": "Tue, 4 May 2021 05:58:52 GMT"}], "update_date": "2021-05-05", "authors_parsed": [["Liang", "Mingjiang", ""], ["Huang", "Shaoli", ""], ["Pan", "Shirui", ""], ["Gong", "Mingming", ""], ["Liu", "Wei", ""]]}, {"id": "1911.12478", "submitter": "Benjamin Nagy", "authors": "Benjamin Nagy", "title": "Metre as a stylometric feature in Latin hexameter poetry", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG stat.AP", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  This paper demonstrates that metre is a privileged indicator of authorial\nstyle in classical Latin hexameter poetry. Using only metrical features,\npairwise classification experiments are performed between 5 first-century\nauthors (10 comparisons) using four different machine-learning models. The\nresults showed a two-label classification accuracy of at least 95% with samples\nas small as ten lines and no greater than eighty lines (up to around 500\nwords). These sample sizes are an order of magnitude smaller than those\ntypically recommended for BOW ('bag of words') or n-gram approaches, and the\nreported accuracy is outstanding. Additionally, this paper explores the\npotential for novelty (forgery) detection, or 'one-class classification'. An\nanalysis of the disputed Aldine Additamentum (Sil. Ital. Puni. 8:144-225)\nconcludes (p=0.0013) that the metrical style differs significantly from that of\nthe rest of the poem.\n", "versions": [{"version": "v1", "created": "Thu, 28 Nov 2019 01:35:51 GMT"}, {"version": "v2", "created": "Mon, 2 Dec 2019 02:20:28 GMT"}], "update_date": "2019-12-03", "authors_parsed": [["Nagy", "Benjamin", ""]]}, {"id": "1911.12481", "submitter": "Da Xu", "authors": "Da Xu, Chuanwei Ruan, Evren Korpeoglu, Sushant Kumar, Kannan Achan", "title": "Product Knowledge Graph Embedding for E-commerce", "comments": null, "journal-ref": null, "doi": "10.1145/3336191.3371778", "report-no": null, "categories": "cs.LG cs.IR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we propose a new product knowledge graph (PKG) embedding\napproach for learning the intrinsic product relations as product knowledge for\ne-commerce. We define the key entities and summarize the pivotal product\nrelations that are critical for general e-commerce applications including\nmarketing, advertisement, search ranking and recommendation. We first provide a\ncomprehensive comparison between PKG and ordinary knowledge graph (KG) and then\nillustrate why KG embedding methods are not suitable for PKG learning. We\nconstruct a self-attention-enhanced distributed representation learning model\nfor learning PKG embeddings from raw customer activity data in an end-to-end\nfashion. We design an effective multi-task learning schema to fully leverage\nthe multi-modal e-commerce data. The Poincare embedding is also employed to\nhandle complex entity structures. We use a real-world dataset from\ngrocery.walmart.com to evaluate the performances on knowledge completion,\nsearch ranking and recommendation. The proposed approach compares favourably to\nbaselines in knowledge completion and downstream tasks.\n", "versions": [{"version": "v1", "created": "Thu, 28 Nov 2019 01:53:47 GMT"}], "update_date": "2019-12-02", "authors_parsed": [["Xu", "Da", ""], ["Ruan", "Chuanwei", ""], ["Korpeoglu", "Evren", ""], ["Kumar", "Sushant", ""], ["Achan", "Kannan", ""]]}, {"id": "1911.12482", "submitter": "Basit Ayantunde", "authors": "Basit Ayantunde, Jane Odum, Fadlullah Olawumi, and Joshua Olalekan", "title": "Designing the Next Generation of Intelligent Personal Robotic Assistants\n  for the Physically Impaired", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.HC cs.CY cs.LG cs.RO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The physically impaired commonly have difficulties performing simple routine\ntasks without relying on other individuals who are not always readily available\nand thus make them strive for independence. While their impaired abilities can\nin many cases be augmented (to certain degrees) with the use of assistive\ntechnologies, there has been little attention to their applications in embodied\nAI with assistive technologies. This paper presents the modular framework,\narchitecture, and design of the mid-fidelity prototype of MARVIN: an\nartificial-intelligence-powered robotic assistant designed to help the\nphysically impaired in performing simple day-to-day tasks. The prototype\nfeatures a trivial locomotion unit and also utilizes various state-of-the-art\nneural network architectures for specific modular components of the system.\nThese components perform specialized functions, such as automatic speech\nrecognition, object detection, natural language understanding, speech\nsynthesis, etc. We also discuss the constraints, challenges encountered,\npotential future applications and improvements towards succeeding prototypes.\n", "versions": [{"version": "v1", "created": "Thu, 28 Nov 2019 02:00:20 GMT"}], "update_date": "2019-12-02", "authors_parsed": [["Ayantunde", "Basit", ""], ["Odum", "Jane", ""], ["Olawumi", "Fadlullah", ""], ["Olalekan", "Joshua", ""]]}, {"id": "1911.12486", "submitter": "Xueya Zhang", "authors": "Xueya Zhang and Tong Zhang and Wenting Zhao and Zhen Cui and Jian Yang", "title": "Dual-Attention Graph Convolutional Network", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Graph convolutional networks (GCNs) have shown the powerful ability in text\nstructure representation and effectively facilitate the task of text\nclassification. However, challenges still exist in adapting GCN on learning\ndiscriminative features from texts due to the main issue of graph variants\nincurred by the textual complexity and diversity. In this paper, we propose a\ndual-attention GCN to model the structural information of various texts as well\nas tackle the graph-invariant problem through embedding two types of attention\nmechanisms, i.e. the connection-attention and hop-attention, into the classic\nGCN. To encode various connection patterns between neighbour words,\nconnection-attention adaptively imposes different weights specified to\nneighbourhoods of each word, which captures the short-term dependencies. On the\nother hand, the hop-attention applies scaled coefficients to different scopes\nduring the graph diffusion process to make the model learn more about the\ndistribution of context, which captures long-term semantics in an adaptive way.\nExtensive experiments are conducted on five widely used datasets to evaluate\nour dual-attention GCN, and the achieved state-of-the-art performance verifies\nthe effectiveness of dual-attention mechanisms.\n", "versions": [{"version": "v1", "created": "Thu, 28 Nov 2019 02:14:57 GMT"}], "update_date": "2019-12-02", "authors_parsed": [["Zhang", "Xueya", ""], ["Zhang", "Tong", ""], ["Zhao", "Wenting", ""], ["Cui", "Zhen", ""], ["Yang", "Jian", ""]]}, {"id": "1911.12487", "submitter": "Chao Weng", "authors": "Chao Weng, Chengzhu Yu, Jia Cui, Chunlei Zhang, Dong Yu", "title": "Minimum Bayes Risk Training of RNN-Transducer for End-to-End Speech\n  Recognition", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG cs.SD eess.AS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this work, we propose minimum Bayes risk (MBR) training of RNN-Transducer\n(RNN-T) for end-to-end speech recognition. Specifically, initialized with a\nRNN-T trained model, MBR training is conducted via minimizing the expected edit\ndistance between the reference label sequence and on-the-fly generated N-best\nhypothesis. We also introduce a heuristic to incorporate an external neural\nnetwork language model (NNLM) in RNN-T beam search decoding and explore MBR\ntraining with the external NNLM. Experimental results demonstrate an MBR\ntrained model outperforms a RNN-T trained model substantially and further\nimprovements can be achieved if trained with an external NNLM. Our best MBR\ntrained system achieves absolute character error rate (CER) reductions of 1.2%\nand 0.5% on read and spontaneous Mandarin speech respectively over a strong\nconvolution and transformer based RNN-T baseline trained on ~21,000 hours of\nspeech.\n", "versions": [{"version": "v1", "created": "Thu, 28 Nov 2019 02:17:56 GMT"}], "update_date": "2019-12-02", "authors_parsed": [["Weng", "Chao", ""], ["Yu", "Chengzhu", ""], ["Cui", "Jia", ""], ["Zhang", "Chunlei", ""], ["Yu", "Dong", ""]]}, {"id": "1911.12491", "submitter": "Jangho Kim", "authors": "Jangho Kim, Yash Bhalgat, Jinwon Lee, Chirag Patel, Nojun Kwak", "title": "QKD: Quantization-aware Knowledge Distillation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Quantization and Knowledge distillation (KD) methods are widely used to\nreduce memory and power consumption of deep neural networks (DNNs), especially\nfor resource-constrained edge devices. Although their combination is quite\npromising to meet these requirements, it may not work as desired. It is mainly\nbecause the regularization effect of KD further diminishes the already reduced\nrepresentation power of a quantized model. To address this short-coming, we\npropose Quantization-aware Knowledge Distillation (QKD) wherein quantization\nand KD are care-fully coordinated in three phases. First, Self-studying (SS)\nphase fine-tunes a quantized low-precision student network without KD to obtain\na good initialization. Second, Co-studying (CS) phase tries to train a teacher\nto make it more quantizaion-friendly and powerful than a fixed teacher.\nFinally, Tutoring (TU) phase transfers knowledge from the trained teacher to\nthe student. We extensively evaluate our method on ImageNet and CIFAR-10/100\ndatasets and show an ablation study on networks with both standard and\ndepthwise-separable convolutions. The proposed QKD outperformed existing\nstate-of-the-art methods (e.g., 1.3% improvement on ResNet-18 with W4A4, 2.6%\non MobileNetV2 with W4A4). Additionally, QKD could recover the full-precision\naccuracy at as low as W3A3 quantization on ResNet and W6A6 quantization on\nMobilenetV2.\n", "versions": [{"version": "v1", "created": "Thu, 28 Nov 2019 02:27:27 GMT"}], "update_date": "2019-12-02", "authors_parsed": [["Kim", "Jangho", ""], ["Bhalgat", "Yash", ""], ["Lee", "Jinwon", ""], ["Patel", "Chirag", ""], ["Kwak", "Nojun", ""]]}, {"id": "1911.12501", "submitter": "Shaoli Huang", "authors": "Sanjeev Sharma, Shaoli Huang, and Dacheng Tao", "title": "An End-to-end Framework for Unconstrained Monocular 3D Hand Pose\n  Estimation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG eess.IV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This work addresses the challenging problem of unconstrained 3D hand pose\nestimation using monocular RGB images. Most of the existing approaches assume\nsome prior knowledge of hand (such as hand locations and side information) is\navailable for 3D hand pose estimation. This restricts their use in\nunconstrained environments. We, therefore, present an end-to-end framework that\nrobustly predicts hand prior information and accurately infers 3D hand pose by\nlearning ConvNet models while only using keypoint annotations. To achieve\nrobustness, the proposed framework uses a novel keypoint-based method to\nsimultaneously predict hand regions and side labels, unlike existing methods\nthat suffer from background color confusion caused by using segmentation or\ndetection-based technology. Moreover, inspired by the biological structure of\nthe human hand, we introduce two geometric constraints directly into the 3D\ncoordinates prediction that further improves its performance in a\nweakly-supervised training. Experimental results show that our proposed\nframework not only performs robustly on unconstrained setting, but also\noutperforms the state-of-art methods on standard benchmark datasets.\n", "versions": [{"version": "v1", "created": "Thu, 28 Nov 2019 02:55:21 GMT"}], "update_date": "2019-12-02", "authors_parsed": [["Sharma", "Sanjeev", ""], ["Huang", "Shaoli", ""], ["Tao", "Dacheng", ""]]}, {"id": "1911.12505", "submitter": "Agelos Kratimenos", "authors": "Agelos Kratimenos, Kleanthis Avramidis, Christos Garoufis, Athanasia\n  Zlatintsi, Petros Maragos", "title": "Augmentation Methods on Monophonic Audio for Instrument Classification\n  in Polyphonic Music", "comments": null, "journal-ref": null, "doi": "10.23919/Eusipco47968.2020.9287745", "report-no": null, "categories": "cs.LG cs.SD eess.AS stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Instrument classification is one of the fields in Music Information Retrieval\n(MIR) that has attracted a lot of research interest. However, the majority of\nthat is dealing with monophonic music, while efforts on polyphonic material\nmainly focus on predominant instrument recognition. In this paper, we propose\nan approach for instrument classification in polyphonic music from purely\nmonophonic data, that involves performing data augmentation by mixing different\naudio segments. A variety of data augmentation techniques focusing on different\nsonic aspects, such as overlaying audio segments of the same genre, as well as\npitch and tempo-based synchronization, are explored. We utilize Convolutional\nNeural Networks for the classification task, comparing shallow to deep network\narchitectures. We further investigate the usage of a combination of the above\nclassifiers, each trained on a single augmented dataset. An ensemble of\nVGG-like classifiers, trained on non-augmented, pitch-synchronized,\ntempo-synchronized and genre-similar excerpts, respectively, yields the best\nresults, achieving slightly above 80% in terms of label ranking average\nprecision (LRAP) in the IRMAS test set.ruments in over 2300 testing tracks.\n", "versions": [{"version": "v1", "created": "Thu, 28 Nov 2019 03:12:22 GMT"}, {"version": "v2", "created": "Tue, 3 Mar 2020 02:19:47 GMT"}], "update_date": "2021-03-03", "authors_parsed": [["Kratimenos", "Agelos", ""], ["Avramidis", "Kleanthis", ""], ["Garoufis", "Christos", ""], ["Zlatintsi", "Athanasia", ""], ["Maragos", "Petros", ""]]}, {"id": "1911.12507", "submitter": "Thuong Nguyen Canh", "authors": "Thuong, Nguyen Canh, Chien, Trinh Van", "title": "Error Resilient Deep Compressive Sensing", "comments": "4 pages, 2 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG eess.IV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Compressive sensing (CS) is an emerging sampling technology that enables\nreconstructing signals from a subset of measurements and even corrupted\nmeasurements. Deep learning-based compressive sensing (DCS) has improved CS\nperformance while maintaining a fast reconstruction but requires a training\nnetwork for each measurement rate. Also, concerning the transmission scheme of\nmeasurement lost, DCS cannot recover the original signal. Thereby, it fails to\nmaintain the error-resilient property. In this work, we proposed a robust deep\nreconstruction network to preserve the error-resilient property under the\nassumption of random measurement lost. Measurement lost layer is proposed to\nsimulate the measurement lost in an end-to-end framework.\n", "versions": [{"version": "v1", "created": "Thu, 28 Nov 2019 03:16:39 GMT"}], "update_date": "2019-12-02", "authors_parsed": [["Thuong", "", ""], ["Canh", "Nguyen", ""], ["Chien", "", ""], ["Van", "Trinh", ""]]}, {"id": "1911.12511", "submitter": "Vishal Jain", "authors": "Vishal Jain, William Fedus, Hugo Larochelle, Doina Precup, Marc G.\n  Bellemare", "title": "Algorithmic Improvements for Deep Reinforcement Learning applied to\n  Interactive Fiction", "comments": "To appear in Proceedings of the Thirty-Fourth AAAI Conference on\n  Artificial Intelligence (AAAI-20). Accepted for Oral presentation", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Text-based games are a natural challenge domain for deep reinforcement\nlearning algorithms. Their state and action spaces are combinatorially large,\ntheir reward function is sparse, and they are partially observable: the agent\nis informed of the consequences of its actions through textual feedback. In\nthis paper we emphasize this latter point and consider the design of a deep\nreinforcement learning agent that can play from feedback alone. Our design\nrecognizes and takes advantage of the structural characteristics of text-based\ngames. We first propose a contextualisation mechanism, based on accumulated\nreward, which simplifies the learning problem and mitigates partial\nobservability. We then study different methods that rely on the notion that\nmost actions are ineffectual in any given situation, following Zahavy et al.'s\nidea of an admissible action. We evaluate these techniques in a series of\ntext-based games of increasing difficulty based on the TextWorld framework, as\nwell as the iconic game Zork. Empirically, we find that these techniques\nimprove the performance of a baseline deep reinforcement learning agent applied\nto text-based games.\n", "versions": [{"version": "v1", "created": "Thu, 28 Nov 2019 03:32:31 GMT"}], "update_date": "2019-12-02", "authors_parsed": [["Jain", "Vishal", ""], ["Fedus", "William", ""], ["Larochelle", "Hugo", ""], ["Precup", "Doina", ""], ["Bellemare", "Marc G.", ""]]}, {"id": "1911.12512", "submitter": "Xinyang Jiang", "authors": "Xinyang Jiang, Yifei Gong, Xiaowei Guo, Qize Yang, Feiyue Huang,\n  Weishi Zheng, Feng Zheng, Xing Sun", "title": "Rethinking Temporal Fusion for Video-based Person Re-identification on\n  Semantic and Time Aspect", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG eess.IV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recently, the research interest of person re-identification (ReID) has\ngradually turned to video-based methods, which acquire a person representation\nby aggregating frame features of an entire video. However, existing video-based\nReID methods do not consider the semantic difference brought by the outputs of\ndifferent network stages, which potentially compromises the information\nrichness of the person features. Furthermore, traditional methods ignore\nimportant relationship among frames, which causes information redundancy in\nfusion along the time axis. To address these issues, we propose a novel general\ntemporal fusion framework to aggregate frame features on both semantic aspect\nand time aspect. As for the semantic aspect, a multi-stage fusion network is\nexplored to fuse richer frame features at multiple semantic levels, which can\neffectively reduce the information loss caused by the traditional single-stage\nfusion. While, for the time axis, the existing intra-frame attention method is\nimproved by adding a novel inter-frame attention module, which effectively\nreduces the information redundancy in temporal fusion by taking the\nrelationship among frames into consideration. The experimental results show\nthat our approach can effectively improve the video-based re-identification\naccuracy, achieving the state-of-the-art performance.\n", "versions": [{"version": "v1", "created": "Thu, 28 Nov 2019 03:35:57 GMT"}], "update_date": "2020-09-14", "authors_parsed": [["Jiang", "Xinyang", ""], ["Gong", "Yifei", ""], ["Guo", "Xiaowei", ""], ["Yang", "Qize", ""], ["Huang", "Feiyue", ""], ["Zheng", "Weishi", ""], ["Zheng", "Feng", ""], ["Sun", "Xing", ""]]}, {"id": "1911.12528", "submitter": "Istvan Fehervari", "authors": "Istvan Fehervari, Avinash Ravichandran, Srikar Appalaraju", "title": "Unbiased Evaluation of Deep Metric Learning Algorithms", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep metric learning (DML) is a popular approach for images retrieval,\nsolving verification (same or not) problems and addressing open set\nclassification. Arguably, the most common DML approach is with triplet loss,\ndespite significant advances in the area of DML. Triplet loss suffers from\nseveral issues such as collapse of the embeddings, high sensitivity to sampling\nschemes and more importantly a lack of performance when compared to more modern\nmethods. We attribute this adoption to a lack of fair comparisons between\nvarious methods and the difficulty in adopting them for novel problem\nstatements. In this paper, we perform an unbiased comparison of the most\npopular DML baseline methods under same conditions and more importantly, not\nobfuscating any hyper parameter tuning or adjustment needed to favor a\nparticular method. We find, that under equal conditions several older methods\nperform significantly better than previously believed. In fact, our unified\nimplementation of 12 recently introduced DML algorithms achieve state-of-the\nart performance on CUB200, CAR196, and Stanford Online products datasets which\nestablishes a new set of baselines for future DML research. The codebase and\nall tuned hyperparameters will be open-sourced for reproducibility and to serve\nas a source of benchmark.\n", "versions": [{"version": "v1", "created": "Thu, 28 Nov 2019 04:54:14 GMT"}], "update_date": "2019-12-02", "authors_parsed": [["Fehervari", "Istvan", ""], ["Ravichandran", "Avinash", ""], ["Appalaraju", "Srikar", ""]]}, {"id": "1911.12529", "submitter": "Hwann-Tzong Chen", "authors": "Ting-I Hsieh, Yi-Chen Lo, Hwann-Tzong Chen, Tyng-Luh Liu", "title": "One-Shot Object Detection with Co-Attention and Co-Excitation", "comments": "NeurIPS 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG eess.IV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper aims to tackle the challenging problem of one-shot object\ndetection. Given a query image patch whose class label is not included in the\ntraining data, the goal of the task is to detect all instances of the same\nclass in a target image. To this end, we develop a novel {\\em co-attention and\nco-excitation} (CoAE) framework that makes contributions in three key technical\naspects. First, we propose to use the non-local operation to explore the\nco-attention embodied in each query-target pair and yield region proposals\naccounting for the one-shot situation. Second, we formulate a\nsqueeze-and-co-excitation scheme that can adaptively emphasize correlated\nfeature channels to help uncover relevant proposals and eventually the target\nobjects. Third, we design a margin-based ranking loss for implicitly learning a\nmetric to predict the similarity of a region proposal to the underlying query,\nno matter its class label is seen or unseen in training. The resulting model is\ntherefore a two-stage detector that yields a strong baseline on both VOC and\nMS-COCO under one-shot setting of detecting objects from both seen and\nnever-seen classes. Codes are available at\nhttps://github.com/timy90022/One-Shot-Object-Detection.\n", "versions": [{"version": "v1", "created": "Thu, 28 Nov 2019 05:14:23 GMT"}], "update_date": "2019-12-02", "authors_parsed": [["Hsieh", "Ting-I", ""], ["Lo", "Yi-Chen", ""], ["Chen", "Hwann-Tzong", ""], ["Liu", "Tyng-Luh", ""]]}, {"id": "1911.12540", "submitter": "Ehsan Hoseinzade", "authors": "Ehsan Hoseinzade, Saman Haratizadeh, Arash Khoeini", "title": "U-CNNpred: A Universal CNN-based Predictor for Stock Markets", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG q-fin.CP stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The performance of financial market prediction systems depends heavily on the\nquality of features it is using. While researchers have used various techniques\nfor enhancing the stock specific features, less attention has been paid to\nextracting features that represent general mechanism of financial markets. In\nthis paper, we investigate the importance of extracting such general features\nin stock market prediction domain and show how it can improve the performance\nof financial market prediction. We present a framework called U-CNNpred, that\nuses a CNN-based structure. A base model is trained in a specially designed\nlayer-wise training procedure over a pool of historical data from many\nfinancial markets, in order to extract the common patterns from different\nmarkets. Our experiments, in which we have used hundreds of stocks in S\\&P 500\nas well as 14 famous indices around the world, show that this model can\noutperform baseline algorithms when predicting the directional movement of the\nmarkets for which it has been trained for. We also show that the base model can\nbe fine-tuned for predicting new markets and achieve a better performance\ncompared to the state of the art baseline algorithms that focus on constructing\nmarket-specific models from scratch.\n", "versions": [{"version": "v1", "created": "Thu, 28 Nov 2019 05:50:40 GMT"}], "update_date": "2019-12-02", "authors_parsed": [["Hoseinzade", "Ehsan", ""], ["Haratizadeh", "Saman", ""], ["Khoeini", "Arash", ""]]}, {"id": "1911.12543", "submitter": "Zhengbao Jiang", "authors": "Zhengbao Jiang, Frank F. Xu, Jun Araki, Graham Neubig", "title": "How Can We Know What Language Models Know?", "comments": "TACL 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent work has presented intriguing results examining the knowledge\ncontained in language models (LM) by having the LM fill in the blanks of\nprompts such as \"Obama is a _ by profession\". These prompts are usually\nmanually created, and quite possibly sub-optimal; another prompt such as \"Obama\nworked as a _\" may result in more accurately predicting the correct profession.\nBecause of this, given an inappropriate prompt, we might fail to retrieve facts\nthat the LM does know, and thus any given prompt only provides a lower bound\nestimate of the knowledge contained in an LM. In this paper, we attempt to more\naccurately estimate the knowledge contained in LMs by automatically discovering\nbetter prompts to use in this querying process. Specifically, we propose\nmining-based and paraphrasing-based methods to automatically generate\nhigh-quality and diverse prompts, as well as ensemble methods to combine\nanswers from different prompts. Extensive experiments on the LAMA benchmark for\nextracting relational knowledge from LMs demonstrate that our methods can\nimprove accuracy from 31.1% to 39.6%, providing a tighter lower bound on what\nLMs know. We have released the code and the resulting LM Prompt And Query\nArchive (LPAQA) at https://github.com/jzbjyb/LPAQA.\n", "versions": [{"version": "v1", "created": "Thu, 28 Nov 2019 05:55:42 GMT"}, {"version": "v2", "created": "Sun, 3 May 2020 20:29:05 GMT"}], "update_date": "2020-05-05", "authors_parsed": [["Jiang", "Zhengbao", ""], ["Xu", "Frank F.", ""], ["Araki", "Jun", ""], ["Neubig", "Graham", ""]]}, {"id": "1911.12544", "submitter": "Preslav Nakov", "authors": "Veselin Raychev, Preslav Nakov", "title": "Language-Independent Sentiment Analysis Using Subjectivity and\n  Positional Information", "comments": "sentiment analysis, subjectivity", "journal-ref": "RANLP-2009", "doi": null, "report-no": null, "categories": "cs.CL cs.IR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We describe a novel language-independent approach to the task of determining\nthe polarity, positive or negative, of the author's opinion on a specific topic\nin natural language text. In particular, weights are assigned to attributes,\nindividual words or word bi-grams, based on their position and on their\nlikelihood of being subjective. The subjectivity of each attribute is estimated\nin a two-step process, where first the probability of being subjective is\ncalculated for each sentence containing the attribute, and then these\nprobabilities are used to alter the attribute's weights for polarity\nclassification. The evaluation results on a standard dataset of movie reviews\nshows 89.85% classification accuracy, which rivals the best previously\npublished results for this dataset for systems that use no additional\nlinguistic information nor external resources.\n", "versions": [{"version": "v1", "created": "Thu, 28 Nov 2019 05:55:44 GMT"}], "update_date": "2019-12-02", "authors_parsed": [["Raychev", "Veselin", ""], ["Nakov", "Preslav", ""]]}, {"id": "1911.12546", "submitter": "Christopher Ren", "authors": "Christopher X. Ren, Amanda Ziemann, Alice M.S. Durieux, James Theiler", "title": "Cycle-Consistent Adversarial Networks for Realistic Pervasive Change\n  Generation in Remote Sensing Imagery", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.IV cs.CV cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  This paper introduces a new method of generating realistic pervasive changes\nin the context of evaluating the effectiveness of change detection algorithms\nin controlled settings. The method, a cycle-consistent adversarial network\n(CycleGAN), requires low quantities of training data to generate realistic\nchanges. Here we show an application of CycleGAN in creating realistic\nsnow-covered scenes of multispectral Sentinel-2 imagery, and demonstrate how\nthese images can be used as a test bed for anomalous change detection\nalgorithms.\n", "versions": [{"version": "v1", "created": "Thu, 28 Nov 2019 06:03:18 GMT"}, {"version": "v2", "created": "Sun, 8 Dec 2019 00:13:16 GMT"}, {"version": "v3", "created": "Fri, 15 May 2020 16:18:04 GMT"}], "update_date": "2020-05-18", "authors_parsed": [["Ren", "Christopher X.", ""], ["Ziemann", "Amanda", ""], ["Durieux", "Alice M. S.", ""], ["Theiler", "James", ""]]}, {"id": "1911.12548", "submitter": "Yih Sung", "authors": "Jordan Burns, David Maughan, Yih Sung", "title": "A Data Driven Approach to Learning The Hamiltonian Matrix in Quantum\n  Mechanics", "comments": "11 pages, 1 figure", "journal-ref": null, "doi": null, "report-no": null, "categories": "quant-ph cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a new machine learning technique which calculates a real-valued,\ntime independent, finite dimensional Hamiltonian matrix from only experimental\ndata. A novel cost function is given along with a proof that the cost function\nhas the theoretically correct Hamiltonian as a global minimum. We present\nresults based on data simulated on a classical computer and results based on\nsimulations of quantum systems on IBM's ibmqx2 quantum computer. We conclude\nwith a discussion on the limitations of this data driven framework, as well as\nseveral possible extensions of this work. We also note that algorithm presented\nin this article not only serves as an example of using domain knowledge to\ndesign a machine learning framework, but also as an example of using domain\nknowledge to improve the speed of such algorithm.\n", "versions": [{"version": "v1", "created": "Thu, 28 Nov 2019 06:06:01 GMT"}], "update_date": "2019-12-02", "authors_parsed": [["Burns", "Jordan", ""], ["Maughan", "David", ""], ["Sung", "Yih", ""]]}, {"id": "1911.12552", "submitter": "Ye Lin", "authors": "Ye Lin, Keren Fu, Shenggui Ling, Cheng Peng", "title": "Unsupervised Many-to-Many Image-to-Image Translation Across Multiple\n  Domains", "comments": "13 pages, 14 figures, 6 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG eess.IV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Unsupervised multi-domain image-to-image translation aims to synthesis images\namong multiple domains without labeled data, which is more general and\ncomplicated than one-to-one image mapping. However, existing methods mainly\nfocus on reducing the large costs of modeling and do not pay enough attention\nto the quality of generated images. In some target domains, their translation\nresults may not be expected or even it has model collapse. To improve the image\nquality, we propose an effective many-to-many mapping framework for\nunsupervised multi-domain image-to-image translation. There are two key aspects\nin our method. The first is a proposed many-to-many architecture with only one\ndomain-shared encoder and several domain-specialized decoders to effectively\nand simultaneously translate images across multiple domains. The second is two\nproposed constraints extended from one-to-one mappings to further help improve\nthe generation. All the evaluations demonstrate our framework is superior to\nexisting methods and provides an effective solution for multi-domain\nimage-to-image translation.\n", "versions": [{"version": "v1", "created": "Thu, 28 Nov 2019 06:39:35 GMT"}, {"version": "v2", "created": "Tue, 24 Nov 2020 02:20:43 GMT"}], "update_date": "2020-11-25", "authors_parsed": [["Lin", "Ye", ""], ["Fu", "Keren", ""], ["Ling", "Shenggui", ""], ["Peng", "Cheng", ""]]}, {"id": "1911.12553", "submitter": "Ashutosh Kumar Tiwari", "authors": "Ashutosh Kumar Tiwari and Sandeep Varma Nadimpalli", "title": "Augmented Random Search for Quadcopter Control: An alternative to\n  Reinforcement Learning", "comments": "10 pages. 11 figures, Published in International Journal of\n  Information Technology and Computer Science(IJITCS),\n  http://www.mecs-press.org/ijitcs", "journal-ref": "IJITCS Vol. 11, No. 11, Nov. 2019 , Page Range. 24-33", "doi": "10.5815/ijitcs.2019.11.03", "report-no": null, "categories": "cs.LG cs.AI cs.RO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Model-based reinforcement learning strategies are believed to exhibit more\nsignificant sample complexity than model-free strategies to control dynamical\nsystems,such as quadcopters.This belief that Model-based strategies that\ninvolve the use of well-trained neural networks for making such high-level\ndecisions always give better performance can be dispelled by making use of\nModel-free policy search methods.This paper proposes the use of a model-free\nrandom searching strategy,called Augmented Random Search(ARS),which is a better\nand faster approach of linear policy training for continuous control tasks like\ncontrolling a Quadcopters flight.The method achieves state-of-the-art accuracy\nby eliminating the use of too much data for the training of neural networks\nthat are present in the previous approaches to the task of Quadcopter\ncontrol.The paper also highlights the performance results of the searching\nstrategy used for this task in a strategically designed task environment with\nthe help of simulations.Reward collection performance over 1000 episodes and\nagents behavior in flight for augmented random search is compared with that of\nthe behavior for reinforcement learning state-of-the-art algorithm,called Deep\nDeterministic policy gradient(DDPG).Our simulations and results manifest that a\nhigh variability in performance is observed in commonly used strategies for\nsample efficiency of such tasks but the built policy network of ARS-Quad can\nreact relatively accurately to step response providing a better performing\nalternative to reinforcement learning strategies.\n", "versions": [{"version": "v1", "created": "Thu, 28 Nov 2019 06:46:06 GMT"}], "update_date": "2019-12-02", "authors_parsed": [["Tiwari", "Ashutosh Kumar", ""], ["Nadimpalli", "Sandeep Varma", ""]]}, {"id": "1911.12558", "submitter": "Hao Liao", "authors": "Hao Liao, Jiao Wu, Mingyang Zhou, Alexandre Vidmer", "title": "Addressing Time Bias in Bipartite Graph Ranking for Important Node\n  Identification", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The goal of the ranking problem in networks is to rank nodes from best to\nworst, according to a chosen criterion. In this work, we focus on ranking the\nnodes according to their quality. The problem of ranking the nodes in bipartite\nnetworks is valuable for many real-world applications. For instance,\nhigh-quality products can be promoted on an online shop or highly reputed\nrestaurants attract more people on venues review platforms. However, many\nclassical ranking algorithms share a common drawback: they tend to rank older\nmovies higher than newer movies, though some newer movies may have a high\nquality. This time bias originates from the fact that older nodes in a network\ntend to have more connections than newer ones. In the study, we develop a\nranking method using a rebalance approach to diminish the time bias of the\nrankings in bipartite graphs.\n", "versions": [{"version": "v1", "created": "Thu, 28 Nov 2019 07:07:33 GMT"}], "update_date": "2019-12-02", "authors_parsed": [["Liao", "Hao", ""], ["Wu", "Jiao", ""], ["Zhou", "Mingyang", ""], ["Vidmer", "Alexandre", ""]]}, {"id": "1911.12560", "submitter": "Jierui Lin", "authors": "Jierui Lin, Min Du, Jian Liu", "title": "Free-riders in Federated Learning: Attacks and Defenses", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Federated learning is a recently proposed paradigm that enables multiple\nclients to collaboratively train a joint model. It allows clients to train\nmodels locally, and leverages the parameter server to generate a global model\nby aggregating the locally submitted gradient updates at each round. Although\nthe incentive model for federated learning has not been fully developed, it is\nsupposed that participants are able to get rewards or the privilege to use the\nfinal global model, as a compensation for taking efforts to train the model.\nTherefore, a client who does not have any local data has the incentive to\nconstruct local gradient updates in order to deceive for rewards. In this\npaper, we are the first to propose the notion of free rider attacks, to explore\npossible ways that an attacker may construct gradient updates, without any\nlocal training data. Furthermore, we explore possible defenses that could\ndetect the proposed attacks, and propose a new high dimensional detection\nmethod called STD-DAGMM, which particularly works well for anomaly detection of\nmodel parameters. We extend the attacks and defenses to consider more free\nriders as well as differential privacy, which sheds light on and calls for\nfuture research in this field.\n", "versions": [{"version": "v1", "created": "Thu, 28 Nov 2019 07:13:48 GMT"}], "update_date": "2019-12-02", "authors_parsed": [["Lin", "Jierui", ""], ["Du", "Min", ""], ["Liu", "Jian", ""]]}, {"id": "1911.12562", "submitter": "Guozhu Meng", "authors": "Yingzhe He and Guozhu Meng and Kai Chen and Xingbo Hu and Jinwen He", "title": "Towards Security Threats of Deep Learning Systems: A Survey", "comments": "28 pages, 6 figures", "journal-ref": "IEEE Transactions on Software Engineering 2020", "doi": null, "report-no": null, "categories": "cs.CR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep learning has gained tremendous success and great popularity in the past\nfew years. However, deep learning systems are suffering several inherent\nweaknesses, which can threaten the security of learning models. Deep learning's\nwide use further magnifies the impact and consequences. To this end, lots of\nresearch has been conducted with the purpose of exhaustively identifying\nintrinsic weaknesses and subsequently proposing feasible mitigation. Yet few\nare clear about how these weaknesses are incurred and how effective these\nattack approaches are in assaulting deep learning. In order to unveil the\nsecurity weaknesses and aid in the development of a robust deep learning\nsystem, we undertake an investigation on attacks towards deep learning, and\nanalyze these attacks to conclude some findings in multiple views. In\nparticular, we focus on four types of attacks associated with security threats\nof deep learning: model extraction attack, model inversion attack, poisoning\nattack and adversarial attack. For each type of attack, we construct its\nessential workflow as well as adversary capabilities and attack goals. Pivot\nmetrics are devised for comparing the attack approaches, by which we perform\nquantitative and qualitative analyses. From the analysis, we have identified\nsignificant and indispensable factors in an attack vector, e.g., how to reduce\nqueries to target models, what distance should be used for measuring\nperturbation. We shed light on 18 findings covering these approaches' merits\nand demerits, success probability, deployment complexity and prospects.\nMoreover, we discuss other potential security weaknesses and possible\nmitigation which can inspire relevant research in this area.\n", "versions": [{"version": "v1", "created": "Thu, 28 Nov 2019 07:16:05 GMT"}, {"version": "v2", "created": "Tue, 27 Oct 2020 17:27:53 GMT"}], "update_date": "2020-10-28", "authors_parsed": [["He", "Yingzhe", ""], ["Meng", "Guozhu", ""], ["Chen", "Kai", ""], ["Hu", "Xingbo", ""], ["He", "Jinwen", ""]]}, {"id": "1911.12568", "submitter": "Ramya Korlakai Vinayak", "authors": "Ramya Korlakai Vinayak, Weihao Kong, Sham M. Kakade", "title": "Optimal Estimation of Change in a Population of Parameters", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG math.ST stat.ML stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Paired estimation of change in parameters of interest over a population plays\na central role in several application domains including those in the social\nsciences, epidemiology, medicine and biology. In these domains, the size of the\npopulation under study is often very large, however, the number of observations\navailable per individual in the population is very small (\\emph{sparse\nobservations}) which makes the problem challenging. Consider the setting with\n$N$ independent individuals, each with unknown parameters $(p_i, q_i)$ drawn\nfrom some unknown distribution on $[0, 1]^2$. We observe $X_i \\sim\n\\text{Bin}(t, p_i)$ before an event and $Y_i \\sim \\text{Bin}(t, q_i)$ after the\nevent. Provided these paired observations, $\\{(X_i, Y_i) \\}_{i=1}^N$, our goal\nis to accurately estimate the \\emph{distribution of the change in parameters},\n$\\delta_i := q_i - p_i$, over the population and properties of interest like\nthe \\emph{$\\ell_1$-magnitude of the change} with sparse observations ($t\\ll\nN$). We provide \\emph{information theoretic lower bounds} on the error in\nestimating the distribution of change and the $\\ell_1$-magnitude of change.\nFurthermore, we show that the following two step procedure achieves the optimal\nerror bounds: first, estimate the full joint distribution of the paired\nparameters using the maximum likelihood estimator (MLE) and then estimate the\ndistribution of change and the $\\ell_1$-magnitude of change using the joint\nMLE. Notably, and perhaps surprisingly, these error bounds are of the same\norder as the minimax optimal error bounds for learning the \\emph{full} joint\ndistribution itself (in Wasserstein-1 distance); in other words, estimating the\nmagnitude of the change of parameters over the population is, in a minimax\nsense, as difficult as estimating the full joint distribution itself.\n", "versions": [{"version": "v1", "created": "Thu, 28 Nov 2019 07:43:03 GMT"}], "update_date": "2019-12-02", "authors_parsed": [["Vinayak", "Ramya Korlakai", ""], ["Kong", "Weihao", ""], ["Kakade", "Sham M.", ""]]}, {"id": "1911.12574", "submitter": "Jie Wang", "authors": "Qi Zhou, Houqiang Li, Jie Wang", "title": "Deep Model-Based Reinforcement Learning via Estimated Uncertainty and\n  Conservative Policy Optimization", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Model-based reinforcement learning algorithms tend to achieve higher sample\nefficiency than model-free methods. However, due to the inevitable errors of\nlearned models, model-based methods struggle to achieve the same asymptotic\nperformance as model-free methods.\n  In this paper, We propose a Policy Optimization method with Model-Based\nUncertainty (POMBU)---a novel model-based approach---that can effectively\nimprove the asymptotic performance using the uncertainty in Q-values. We derive\nan upper bound of the uncertainty, based on which we can approximate the\nuncertainty accurately and efficiently for model-based methods. We further\npropose an uncertainty-aware policy optimization algorithm that optimizes the\npolicy conservatively to encourage performance improvement with high\nprobability. This can significantly alleviate the overfitting of policy to\ninaccurate models.\n  Experiments show POMBU can outperform existing state-of-the-art policy\noptimization algorithms in terms of sample efficiency and asymptotic\nperformance. Moreover, the experiments demonstrate the excellent robustness of\nPOMBU compared to previous model-based approaches.\n", "versions": [{"version": "v1", "created": "Thu, 28 Nov 2019 07:56:00 GMT"}], "update_date": "2019-12-02", "authors_parsed": [["Zhou", "Qi", ""], ["Li", "Houqiang", ""], ["Wang", "Jie", ""]]}, {"id": "1911.12580", "submitter": "Zheyan Shen", "authors": "Zheyan Shen, Peng Cui, Tong Zhang, Kun Kuang", "title": "Stable Learning via Sample Reweighting", "comments": "Accepted as poster paper at AAAI2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the problem of learning linear prediction models with model\nmisspecification bias. In such case, the collinearity among input variables may\ninflate the error of parameter estimation, resulting in instability of\nprediction results when training and test distributions do not match. In this\npaper we theoretically analyze this fundamental problem and propose a sample\nreweighting method that reduces collinearity among input variables. Our method\ncan be seen as a pretreatment of data to improve the condition of design\nmatrix, and it can then be combined with any standard learning method for\nparameter estimation and variable selection. Empirical studies on both\nsimulation and real datasets demonstrate the effectiveness of our method in\nterms of more stable performance across different distributed data.\n", "versions": [{"version": "v1", "created": "Thu, 28 Nov 2019 08:12:24 GMT"}], "update_date": "2019-12-02", "authors_parsed": [["Shen", "Zheyan", ""], ["Cui", "Peng", ""], ["Zhang", "Tong", ""], ["Kuang", "Kun", ""]]}, {"id": "1911.12587", "submitter": "Julia Stoyanovich", "authors": "Sebastian Schelter, Yuxuan He, Jatin Khilnani, Julia Stoyanovich", "title": "FairPrep: Promoting Data to a First-Class Citizen in Studies on\n  Fairness-Enhancing Interventions", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CY cs.DB stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The importance of incorporating ethics and legal compliance into\nmachine-assisted decision-making is broadly recognized. Further, several lines\nof recent work have argued that critical opportunities for improving data\nquality and representativeness, controlling for bias, and allowing humans to\noversee and impact computational processes are missed if we do not consider the\nlifecycle stages upstream from model training and deployment. Yet, very little\nhas been done to date to provide system-level support to data scientists who\nwish to develop and deploy responsible machine learning methods. We aim to fill\nthis gap and present FairPrep, a design and evaluation framework for\nfairness-enhancing interventions.\n  FairPrep is based on a developer-centered design, and helps data scientists\nfollow best practices in software engineering and machine learning. As part of\nour contribution, we identify shortcomings in existing empirical studies for\nanalyzing fairness-enhancing interventions. We then show how FairPrep can be\nused to measure the impact of sound best practices, such as hyperparameter\ntuning and feature scaling. In particular, our results suggest that the high\nvariability of the outcomes of fairness-enhancing interventions observed in\nprevious studies is often an artifact of a lack of hyperparameter tuning.\nFurther, we show that the choice of a data cleaning method can impact the\neffectiveness of fairness-enhancing interventions.\n", "versions": [{"version": "v1", "created": "Thu, 28 Nov 2019 08:28:46 GMT"}], "update_date": "2019-12-02", "authors_parsed": [["Schelter", "Sebastian", ""], ["He", "Yuxuan", ""], ["Khilnani", "Jatin", ""], ["Stoyanovich", "Julia", ""]]}, {"id": "1911.12593", "submitter": "Aziz Mohaisen", "authors": "David Mohaisen and Songqing Chen", "title": "Computer Systems Have 99 Problems, Let's Not Make Machine Learning\n  Another One", "comments": "5 pages; 0 figures; 0 tables. To appear in IEEE TPS 2019 (vision\n  track)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.CR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Machine learning techniques are finding many applications in computer\nsystems, including many tasks that require decision making: network\noptimization, quality of service assurance, and security. We believe machine\nlearning systems are here to stay, and to materialize on their potential we\nadvocate a fresh look at various key issues that need further attention,\nincluding security as a requirement and system complexity, and how machine\nlearning systems affect them. We also discuss reproducibility as a key\nrequirement for sustainable machine learning systems, and leads to pursuing it.\n", "versions": [{"version": "v1", "created": "Thu, 28 Nov 2019 08:43:01 GMT"}], "update_date": "2019-12-02", "authors_parsed": [["Mohaisen", "David", ""], ["Chen", "Songqing", ""]]}, {"id": "1911.12595", "submitter": "Yawei Zhao", "authors": "Yawei Zhao, Qian Zhao, Xingxing Zhang, En Zhu, Xinwang Liu, Jianping\n  Yin", "title": "Understand Dynamic Regret with Switching Cost for Online Decision Making", "comments": "Accepted by ACM Transactions on Intelligent Systems and Technology\n  (TIST)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.GT stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  As a metric to measure the performance of an online method, dynamic regret\nwith switching cost has drawn much attention for online decision making\nproblems. Although the sublinear regret has been provided in many previous\nresearches, we still have little knowledge about the relation between the\ndynamic regret and the switching cost. In the paper, we investigate the\nrelation for two classic online settings: Online Algorithms (OA) and Online\nConvex Optimization (OCO). We provide a new theoretical analysis framework,\nwhich shows an interesting observation, that is, the relation between the\nswitching cost and the dynamic regret is different for settings of OA and OCO.\nSpecifically, the switching cost has significant impact on the dynamic regret\nin the setting of OA. But, it does not have an impact on the dynamic regret in\nthe setting of OCO. Furthermore, we provide a lower bound of regret for the\nsetting of OCO, which is same with the lower bound in the case of no switching\ncost. It shows that the switching cost does not change the difficulty of online\ndecision making problems in the setting of OCO.\n", "versions": [{"version": "v1", "created": "Thu, 28 Nov 2019 08:46:39 GMT"}], "update_date": "2019-12-02", "authors_parsed": [["Zhao", "Yawei", ""], ["Zhao", "Qian", ""], ["Zhang", "Xingxing", ""], ["Zhu", "En", ""], ["Liu", "Xinwang", ""], ["Yin", "Jianping", ""]]}, {"id": "1911.12598", "submitter": "Chaoyue Niu", "authors": "Chaoyue Niu, Zhenzhe Zheng, Fan Wu, Shaojie Tang, and Guihai Chen", "title": "Online Pricing with Reserve Price Constraint for Personal Data Markets", "comments": "A short version is accepted by IEEE International Conference on Data\n  Engineering (ICDE) 2020, and the source code is available from\n  https://github.com/NiuChaoyue/Personal-Data-Pricing/", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CE cs.GT cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The society's insatiable appetites for personal data are driving the\nemergency of data markets, allowing data consumers to launch customized queries\nover the datasets collected by a data broker from data owners. In this paper,\nwe study how the data broker can maximize her cumulative revenue by posting\nreasonable prices for sequential queries. We thus propose a contextual dynamic\npricing mechanism with the reserve price constraint, which features the\nproperties of ellipsoid for efficient online optimization, and can support\nlinear and non-linear market value models with uncertainty. In particular,\nunder low uncertainty, our pricing mechanism provides a worst-case regret\nlogarithmic in the number of queries. We further extend to other similar\napplication scenarios, including hospitality service, online advertising, and\nloan application, and extensively evaluate three pricing instances of noisy\nlinear query, accommodation rental, and impression over MovieLens 20M dataset,\nAirbnb listings in U.S. major cities, and Avazu mobile ad click dataset,\nrespectively. The analysis and evaluation results reveal that our proposed\npricing mechanism incurs low practical regret, online latency, and memory\noverhead, and also demonstrate that the existence of reserve price can mitigate\nthe cold-start problem in a posted price mechanism, and thus can reduce the\ncumulative regret.\n", "versions": [{"version": "v1", "created": "Thu, 28 Nov 2019 08:55:47 GMT"}], "update_date": "2019-12-02", "authors_parsed": [["Niu", "Chaoyue", ""], ["Zheng", "Zhenzhe", ""], ["Wu", "Fan", ""], ["Tang", "Shaojie", ""], ["Chen", "Guihai", ""]]}, {"id": "1911.12603", "submitter": "Guanhua Zheng", "authors": "Guanhua Zheng, Jitao Sang, Houqiang Li, Jian Yu, and Changsheng Xu", "title": "A Generalization Theory based on Independent and Task-Identically\n  Distributed Assumption", "comments": "14 pages, 8 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Existing generalization theories analyze the generalization performance\nmainly based on the model complexity and training process. The ignorance of the\ntask properties, which results from the widely used IID assumption, makes these\ntheories fail to interpret many generalization phenomena or guide practical\nlearning tasks. In this paper, we propose a new Independent and\nTask-Identically Distributed (ITID) assumption, to consider the task properties\ninto the data generating process. The derived generalization bound based on the\nITID assumption identifies the significance of hypothesis invariance in\nguaranteeing generalization performance. Based on the new bound, we introduce a\npractical invariance enhancement algorithm from the perspective of modifying\ndata distributions. Finally, we verify the algorithm and theorems in the\ncontext of image classification task on both toy and real-world datasets. The\nexperimental results demonstrate the reasonableness of the ITID assumption and\nthe effectiveness of new generalization theory in improving practical\ngeneralization performance.\n", "versions": [{"version": "v1", "created": "Thu, 28 Nov 2019 09:06:59 GMT"}], "update_date": "2019-12-02", "authors_parsed": [["Zheng", "Guanhua", ""], ["Sang", "Jitao", ""], ["Li", "Houqiang", ""], ["Yu", "Jian", ""], ["Xu", "Changsheng", ""]]}, {"id": "1911.12607", "submitter": "Ole-Christoffer Granmo", "authors": "Adrian Phoulady, Ole-Christoffer Granmo, Saeed Rahimi Gorji, Hady\n  Ahmady Phoulady", "title": "The Weighted Tsetlin Machine: Compressed Representations with Weighted\n  Clauses", "comments": "Accepted at the Ninth International Workshop on Statistical\n  Relational AI", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The Tsetlin Machine (TM) is an interpretable mechanism for pattern\nrecognition that constructs conjunctive clauses from data. The clauses capture\nfrequent patterns with high discriminating power, providing increasing\nexpression power with each additional clause. However, the resulting accuracy\ngain comes at the cost of linear growth in computation time and memory usage.\nIn this paper, we present the Weighted Tsetlin Machine (WTM), which reduces\ncomputation time and memory usage by weighting the clauses. Real-valued\nweighting allows one clause to replace multiple, and supports fine-tuning the\nimpact of each clause. Our novel scheme simultaneously learns both the\ncomposition of the clauses and their weights. Furthermore, we increase training\nefficiency by replacing $k$ Bernoulli trials of success probability $p$ with a\nuniform sample of average size $p k$, the size drawn from a binomial\ndistribution. In our empirical evaluation, the WTM achieved the same accuracy\nas the TM on MNIST, IMDb, and Connect-4, requiring only $1/4$, $1/3$, and\n$1/50$ of the clauses, respectively. With the same number of clauses, the WTM\noutperformed the TM, obtaining peak test accuracies of respectively $98.63\\%$,\n$90.37\\%$, and $87.91\\%$. Finally, our novel sampling scheme reduced sample\ngeneration time by a factor of $7$.\n", "versions": [{"version": "v1", "created": "Thu, 28 Nov 2019 09:23:09 GMT"}, {"version": "v2", "created": "Thu, 5 Dec 2019 08:00:42 GMT"}, {"version": "v3", "created": "Mon, 13 Jan 2020 07:50:16 GMT"}, {"version": "v4", "created": "Tue, 14 Jan 2020 17:51:02 GMT"}], "update_date": "2020-01-15", "authors_parsed": [["Phoulady", "Adrian", ""], ["Granmo", "Ole-Christoffer", ""], ["Gorji", "Saeed Rahimi", ""], ["Phoulady", "Hady Ahmady", ""]]}, {"id": "1911.12617", "submitter": "Anurenjan Purushothaman", "authors": "Rohit Kumar, Anirudh Sreeram, Anurenjan Purushothaman and Sriram\n  Ganapathy", "title": "Unsupervised Neural Mask Estimator For Generalized Eigen-Value\n  Beamforming Based ASR", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.AS cs.LG cs.SD eess.SP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The state-of-art methods for acoustic beamforming in multi-channel ASR are\nbased on a neural mask estimator that predicts the presence of speech and\nnoise. These models are trained using a paired corpus of clean and noisy\nrecordings (teacher model). In this paper, we attempt to move away from the\nrequirements of having supervised clean recordings for training the mask\nestimator. The models based on signal enhancement and beamforming using\nmulti-channel linear prediction serve as the required mask estimate. In this\nway, the model training can also be carried out on real recordings of noisy\nspeech rather than simulated ones alone done in a typical teacher model.\nSeveral experiments performed on noisy and reverberant environments in the\nCHiME-3 corpus as well as the REVERB challenge corpus highlight the\neffectiveness of the proposed approach. The ASR results for the proposed\napproach provide performances that are significantly better than a teacher\nmodel trained on an out-of-domain dataset and on par with the oracle mask\nestimators trained on the in-domain dataset.\n", "versions": [{"version": "v1", "created": "Thu, 28 Nov 2019 09:53:45 GMT"}], "update_date": "2019-12-02", "authors_parsed": [["Kumar", "Rohit", ""], ["Sreeram", "Anirudh", ""], ["Purushothaman", "Anurenjan", ""], ["Ganapathy", "Sriram", ""]]}, {"id": "1911.12618", "submitter": "Jaime Ram\\'irez Castillo", "authors": "Jaime Ram\\'irez, M. Julia Flores", "title": "Machine learning for music genre: multifaceted review and\n  experimentation with audioset", "comments": null, "journal-ref": null, "doi": "10.1007/s10844-019-00582-9", "report-no": null, "categories": "cs.SD cs.IR cs.LG eess.AS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Music genre classification is one of the sub-disciplines of music information\nretrieval (MIR) with growing popularity among researchers, mainly due to the\nalready open challenges. Although research has been prolific in terms of number\nof published works, the topic still suffers from a problem in its foundations:\nthere is no clear and formal definition of what genre is. Music categorizations\nare vague and unclear, suffering from human subjectivity and lack of agreement.\nIn its first part, this paper offers a survey trying to cover the many\ndifferent aspects of the matter. Its main goal is give the reader an overview\nof the history and the current state-of-the-art, exploring techniques and\ndatasets used to the date, as well as identifying current challenges, such as\nthis ambiguity of genre definitions or the introduction of human-centric\napproaches. The paper pays special attention to new trends in machine learning\napplied to the music annotation problem. Finally, we also include a music genre\nclassification experiment that compares different machine learning models using\nAudioset.\n", "versions": [{"version": "v1", "created": "Thu, 28 Nov 2019 09:57:28 GMT"}], "update_date": "2019-12-02", "authors_parsed": [["Ram\u00edrez", "Jaime", ""], ["Flores", "M. Julia", ""]]}, {"id": "1911.12641", "submitter": "Damian Kaliroff", "authors": "Damian Kaliroff and Guy Gilboa", "title": "PhIT-Net: Photo-consistent Image Transform for Robust Illumination\n  Invariant Matching", "comments": "Modified title. Added figures in section 3 for better understanding\n  of the general concept. Added table summarizing graphs. New paper format (two\n  columns)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG eess.IV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a new and completely data-driven approach for generating a\nphoto-consistent image transform. We show that simple classical algorithms\nwhich operate in the transform domain become extremely resilient to\nillumination changes. This considerably improves matching accuracy,\noutperforming the use of state-of-the-art invariant representations as well as\nnew matching methods based on deep features. The transform is obtained by\ntraining a neural network with a specialized triplet loss, designed to\nemphasize actual scene changes while attenuating illumination changes. The\ntransform yields an illumination invariant representation, structured as an\nimage map, which is highly flexible and can be easily used for various tasks.\nWe point out that the utility of our method is not restricted to handling\nillumination invariance, and that it may be applied for generating\nrepresentations which are invariant to additional types of nuisance, undesired,\nimage variants\n", "versions": [{"version": "v1", "created": "Thu, 28 Nov 2019 10:55:55 GMT"}, {"version": "v2", "created": "Thu, 23 Apr 2020 15:20:30 GMT"}, {"version": "v3", "created": "Tue, 7 Jul 2020 12:02:28 GMT"}], "update_date": "2020-07-09", "authors_parsed": [["Kaliroff", "Damian", ""], ["Gilboa", "Guy", ""]]}, {"id": "1911.12643", "submitter": "Alexander Grebhahn", "authors": "Alexander Grebhahn (1), Norbert Siegmund (2), Sven Apel (3) ((1)\n  University of Passau, Germany, (2) Bauhaus-University Weimar, Germany, (3)\n  Saarland University, Germany)", "title": "Predicting Performance of Software Configurations: There is no Silver\n  Bullet", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SE cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Many software systems offer configuration options to tailor their\nfunctionality and non-functional properties (e.g., performance). Often, users\nare interested in the (performance-)optimal configuration, but struggle to find\nit, due to missing information on influences of individual configuration\noptions and their interactions. In the past, various supervised\nmachine-learning techniques have been used to predict the performance of all\nconfigurations and to identify the optimal one. In the literature, there is a\nlarge number of machine-learning techniques and sampling strategies to select\nfrom. It is unclear, though, to what extent they affect prediction accuracy. We\nhave conducted a comparative study regarding the mean prediction accuracy when\npredicting the performance of all configurations considering 6 machine-learning\ntechniques, 18 sampling strategies, and 6 subject software systems. We found\nthat both the learning technique and the sampling strategy have a strong\ninfluence on prediction accuracy. We further observed that some learning\ntechniques (e.g., random forests) outperform other learning techniques (e.g.,\nk-nearest neighbor) in most cases. Moreover, as the prediction accuracy\nstrongly depends on the subject system, there is no combination of a learning\ntechnique and sampling strategy that is optimal in all cases, considering the\ntradeoff between accuracy and measurement overhead, which is in line with the\nfamous no-free-lunch theorem.\n", "versions": [{"version": "v1", "created": "Thu, 28 Nov 2019 10:59:08 GMT"}], "update_date": "2019-12-02", "authors_parsed": [["Grebhahn", "Alexander", ""], ["Siegmund", "Norbert", ""], ["Apel", "Sven", ""]]}, {"id": "1911.12665", "submitter": "Jie Wang", "authors": "Taoxing Pan, Jun Liu, Jie Wang", "title": "D-SPIDER-SFO: A Decentralized Optimization Algorithm with Faster\n  Convergence Rate for Nonconvex Problems", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG math.OC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Decentralized optimization algorithms have attracted intensive interests\nrecently, as it has a balanced communication pattern, especially when solving\nlarge-scale machine learning problems. Stochastic Path Integrated Differential\nEstimator Stochastic First-Order method (SPIDER-SFO) nearly achieves the\nalgorithmic lower bound in certain regimes for nonconvex problems. However,\nwhether we can find a decentralized algorithm which achieves a similar\nconvergence rate to SPIDER-SFO is still unclear. To tackle this problem, we\npropose a decentralized variant of SPIDER-SFO, called decentralized SPIDER-SFO\n(D-SPIDER-SFO). We show that D-SPIDER-SFO achieves a similar gradient\ncomputation cost---that is, $\\mathcal{O}(\\epsilon^{-3})$ for finding an\n$\\epsilon$-approximate first-order stationary point---to its centralized\ncounterpart. To the best of our knowledge, D-SPIDER-SFO achieves the\nstate-of-the-art performance for solving nonconvex optimization problems on\ndecentralized networks in terms of the computational cost. Experiments on\ndifferent network configurations demonstrate the efficiency of the proposed\nmethod.\n", "versions": [{"version": "v1", "created": "Thu, 28 Nov 2019 12:15:00 GMT"}], "update_date": "2019-12-02", "authors_parsed": [["Pan", "Taoxing", ""], ["Liu", "Jun", ""], ["Wang", "Jie", ""]]}, {"id": "1911.12672", "submitter": "Matthew England Dr", "authors": "Dorian Florescu and Matthew England", "title": "Improved cross-validation for classifiers that make algorithmic choices\n  to minimise runtime without compromising output correctness", "comments": "16 pages. Accepted into the Proceedings of MACIS 2019. arXiv admin\n  note: text overlap with arXiv:1906.01455", "journal-ref": "Mathematical Aspects of Computer and Information Sciences (Proc.\n  MACIS '19), LNCS vol 11989, pages 169-184, Springer International, 2020", "doi": "10.1007/978-3-030-43120-4_27", "report-no": null, "categories": "cs.SC cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Our topic is the use of machine learning to improve software by making\nchoices which do not compromise the correctness of the output, but do affect\nthe time taken to produce such output. We are particularly concerned with\ncomputer algebra systems (CASs), and in particular, our experiments are for\nselecting the variable ordering to use when performing a cylindrical algebraic\ndecomposition of $n$-dimensional real space with respect to the signs of a set\nof polynomials.\n  In our prior work we explored the different ML models that could be used, and\nhow to identify suitable features of the input polynomials. In the present\npaper we both repeat our prior experiments on problems which have more\nvariables (and thus exponentially more possible orderings), and examine the\nmetric which our ML classifiers targets. The natural metric is computational\nruntime, with classifiers trained to pick the ordering which minimises this.\nHowever, this leads to the situation were models do not distinguish between any\nof the non-optimal orderings, whose runtimes may still vary dramatically. In\nthis paper we investigate a modification to the cross-validation algorithms of\nthe classifiers so that they do distinguish these cases, leading to improved\nresults.\n", "versions": [{"version": "v1", "created": "Thu, 28 Nov 2019 12:35:55 GMT"}], "update_date": "2020-04-16", "authors_parsed": [["Florescu", "Dorian", ""], ["England", "Matthew", ""]]}, {"id": "1911.12674", "submitter": "Michael G\\\"unther", "authors": "Michael G\\\"unther, Maik Thiele, Wolfgang Lehner", "title": "RETRO: Relation Retrofitting For In-Database Machine Learning on Textual\n  Data", "comments": "14 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DB cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  There are massive amounts of textual data residing in databases, valuable for\nmany machine learning (ML) tasks. Since ML techniques depend on numerical input\nrepresentations, word embeddings are increasingly utilized to convert symbolic\nrepresentations such as text into meaningful numbers. However, a naive\none-to-one mapping of each word in a database to a word embedding vector is not\nsufficient and would lead to poor accuracies in ML tasks. Thus, we argue to\nadditionally incorporate the information given by the database schema into the\nembedding, e.g. which words appear in the same column or are related to each\nother. In this paper, we propose RETRO (RElational reTROfitting), a novel\napproach to learn numerical representations of text values in databases,\ncapturing the best of both worlds, the rich information encoded by word\nembeddings and the relational information encoded by database tables. We\nformulate relation retrofitting as a learning problem and present an efficient\nalgorithm solving it. We investigate the impact of various hyperparameters on\nthe learning problem and derive good settings for all of them. Our evaluation\nshows that the proposed embeddings are ready-to-use for many ML tasks such as\nclassification and regression and even outperform state-of-the-art techniques\nin integration tasks such as null value imputation and link prediction.\n", "versions": [{"version": "v1", "created": "Thu, 28 Nov 2019 12:37:26 GMT"}, {"version": "v2", "created": "Wed, 22 Jan 2020 07:55:38 GMT"}], "update_date": "2020-01-23", "authors_parsed": [["G\u00fcnther", "Michael", ""], ["Thiele", "Maik", ""], ["Lehner", "Wolfgang", ""]]}, {"id": "1911.12675", "submitter": "Xu Shen", "authors": "Xu Shen, Xinmei Tian, Tongliang Liu, Fang Xu and Dacheng Tao", "title": "Continuous Dropout", "comments": "Accepted by TNNLS", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Dropout has been proven to be an effective algorithm for training robust deep\nnetworks because of its ability to prevent overfitting by avoiding the\nco-adaptation of feature detectors. Current explanations of dropout include\nbagging, naive Bayes, regularization, and sex in evolution. According to the\nactivation patterns of neurons in the human brain, when faced with different\nsituations, the firing rates of neurons are random and continuous, not binary\nas current dropout does. Inspired by this phenomenon, we extend the traditional\nbinary dropout to continuous dropout. On the one hand, continuous dropout is\nconsiderably closer to the activation characteristics of neurons in the human\nbrain than traditional binary dropout. On the other hand, we demonstrate that\ncontinuous dropout has the property of avoiding the co-adaptation of feature\ndetectors, which suggests that we can extract more independent feature\ndetectors for model averaging in the test stage. We introduce the proposed\ncontinuous dropout to a feedforward neural network and comprehensively compare\nit with binary dropout, adaptive dropout, and DropConnect on MNIST, CIFAR-10,\nSVHN, NORB, and ILSVRC-12. Thorough experiments demonstrate that our method\nperforms better in preventing the co-adaptation of feature detectors and\nimproves test performance. The code is available at:\nhttps://github.com/jasonustc/caffe-multigpu/tree/dropout.\n", "versions": [{"version": "v1", "created": "Thu, 28 Nov 2019 12:37:48 GMT"}], "update_date": "2019-12-02", "authors_parsed": [["Shen", "Xu", ""], ["Tian", "Xinmei", ""], ["Liu", "Tongliang", ""], ["Xu", "Fang", ""], ["Tao", "Dacheng", ""]]}, {"id": "1911.12682", "submitter": "Xu Shen", "authors": "Xu Shen, Xinmei Tian, Shaoyan Sun, Dacheng Tao", "title": "Patch Reordering: a Novel Way to Achieve Rotation and Translation\n  Invariance in Convolutional Neural Networks", "comments": "Accepted AAAI17", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG eess.IV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Convolutional Neural Networks (CNNs) have demonstrated state-of-the-art\nperformance on many visual recognition tasks. However, the combination of\nconvolution and pooling operations only shows invariance to small local\nlocation changes in meaningful objects in input. Sometimes, such networks are\ntrained using data augmentation to encode this invariance into the parameters,\nwhich restricts the capacity of the model to learn the content of these\nobjects. A more efficient use of the parameter budget is to encode rotation or\ntranslation invariance into the model architecture, which relieves the model\nfrom the need to learn them. To enable the model to focus on learning the\ncontent of objects other than their locations, we propose to conduct patch\nranking of the feature maps before feeding them into the next layer. When patch\nranking is combined with convolution and pooling operations, we obtain\nconsistent representations despite the location of meaningful objects in input.\nWe show that the patch ranking module improves the performance of the CNN on\nmany benchmark tasks, including MNIST digit recognition, large-scale image\nrecognition, and image retrieval. The code is available at\nhttps://github.com//jasonustc/caffe-multigpu/tree/TICNN .\n", "versions": [{"version": "v1", "created": "Thu, 28 Nov 2019 12:49:57 GMT"}], "update_date": "2019-12-02", "authors_parsed": [["Shen", "Xu", ""], ["Tian", "Xinmei", ""], ["Sun", "Shaoyan", ""], ["Tao", "Dacheng", ""]]}, {"id": "1911.12704", "submitter": "Claire Bowen", "authors": "Claire McKay Bowen and Joshua Snoke", "title": "Comparative Study of Differentially Private Synthetic Data Algorithms\n  from the NIST PSCR Differential Privacy Synthetic Data Challenge", "comments": "32 pages (27 main, 5 references), 3 figures, 9 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.AP cs.CR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Differentially private synthetic data generation offers a recent solution to\nrelease analytically useful data while preserving the privacy of individuals in\nthe data. In order to utilize these algorithms for public policy decisions,\npolicymakers need an accurate understanding of these algorithms' comparative\nperformance. Correspondingly, data practitioners require standard metrics for\nevaluating the analytic qualities of the synthetic data. In this paper, we\npresent an in-depth evaluation of several differentially private synthetic data\nalgorithms using actual differentially private synthetic data sets created by\ncontestants in the 2018-2019 National Institute of Standards and Technology\nPublic Safety Communications Research (NIST PSCR) Division's ``Differential\nPrivacy Synthetic Data Challenge.'' We offer analyses of these algorithms based\non both the accuracy of the data they created and their usability by potential\ndata providers. We frame the methods used in the NIST PSCR data challenge\nwithin the broader differentially private synthetic data literature. We\nimplement additional utility metrics, including two of our own, on the\ndifferentially private synthetic data and compare mechanism utility on three\ncategories. Our comparative assessment of the differentially private data\nsynthesis methods and the quality metrics shows the relative usefulness, the\ngeneral strengths and weaknesses, and offers preferred choices of algorithms\nand metrics. Finally we describe the implications of our evaluation for\npolicymakers seeking to implement differentially private synthetic data\nalgorithms on future data products.\n", "versions": [{"version": "v1", "created": "Thu, 28 Nov 2019 13:38:17 GMT"}, {"version": "v2", "created": "Tue, 23 Jun 2020 14:28:10 GMT"}, {"version": "v3", "created": "Mon, 12 Oct 2020 13:38:52 GMT"}], "update_date": "2020-10-13", "authors_parsed": [["Bowen", "Claire McKay", ""], ["Snoke", "Joshua", ""]]}, {"id": "1911.12732", "submitter": "Jun Jin", "authors": "Jun Jin, Chao Ying, Zhou Yu", "title": "Distributed estimation of principal support vector machines for\n  sufficient dimension reduction", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The principal support vector machines method (Li et al., 2011) is a powerful\ntool for sufficient dimension reduction that replaces original predictors with\ntheir low-dimensional linear combinations without loss of information. However,\nthe computational burden of the principal support vector machines method\nconstrains its use for massive data. To address this issue, we in this paper\npropose two distributed estimation algorithms for fast implementation when the\nsample size is large. Both the two distributed sufficient dimension reduction\nestimators enjoy the same statistical efficiency as merging all the data\ntogether, which provides rigorous statistical guarantees for their application\nto large scale datasets. The two distributed algorithms are further adapt to\nprincipal weighted support vector machines (Shin et al., 2016) for sufficient\ndimension reduction in binary classification. The statistical accuracy and\ncomputational complexity of our proposed methods are examined through\ncomprehensive simulation studies and a real data application with more than\n600000 samples.\n", "versions": [{"version": "v1", "created": "Thu, 28 Nov 2019 14:42:18 GMT"}], "update_date": "2019-12-02", "authors_parsed": [["Jin", "Jun", ""], ["Ying", "Chao", ""], ["Yu", "Zhou", ""]]}, {"id": "1911.12736", "submitter": "Xin Huang", "authors": "Xin Huang and Stephen G. McGill and Jonathan A. DeCastro and Luke\n  Fletcher and John J. Leonard and Brian C. Williams and Guy Rosman", "title": "DiversityGAN: Diversity-Aware Vehicle Motion Prediction via Latent\n  Semantic Sampling", "comments": "8 pages, 5 figures, 1 table", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Vehicle trajectory prediction is crucial for autonomous driving and advanced\ndriver assistant systems. While existing approaches may sample from a predicted\ndistribution of vehicle trajectories, they lack the ability to explore it -- a\nkey ability for evaluating safety from a planning and verification perspective.\nIn this work, we devise a novel approach for generating realistic and diverse\nvehicle trajectories. We extend the generative adversarial network (GAN)\nframework with a low-dimensional approximate semantic space, and shape that\nspace to capture semantics such as merging and turning. We sample from this\nspace in a way that mimics the predicted distribution, but allows us to control\ncoverage of semantically distinct outcomes. We validate our approach on a\npublicly available dataset and show results that achieve state-of-the-art\nprediction performance, while providing improved coverage of the space of\npredicted trajectory semantics.\n", "versions": [{"version": "v1", "created": "Thu, 28 Nov 2019 14:51:09 GMT"}, {"version": "v2", "created": "Sun, 22 Mar 2020 01:12:23 GMT"}], "update_date": "2020-03-24", "authors_parsed": [["Huang", "Xin", ""], ["McGill", "Stephen G.", ""], ["DeCastro", "Jonathan A.", ""], ["Fletcher", "Luke", ""], ["Leonard", "John J.", ""], ["Williams", "Brian C.", ""], ["Rosman", "Guy", ""]]}, {"id": "1911.12739", "submitter": "Mingyu Ding", "authors": "Mingyu Ding, Zhe Wang, Bolei Zhou, Jianping Shi, Zhiwu Lu, Ping Luo", "title": "Every Frame Counts: Joint Learning of Video Segmentation and Optical\n  Flow", "comments": "Published in AAAI 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG eess.IV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A major challenge for video semantic segmentation is the lack of labeled\ndata. In most benchmark datasets, only one frame of a video clip is annotated,\nwhich makes most supervised methods fail to utilize information from the rest\nof the frames. To exploit the spatio-temporal information in videos, many\nprevious works use pre-computed optical flows, which encode the temporal\nconsistency to improve the video segmentation. However, the video segmentation\nand optical flow estimation are still considered as two separate tasks. In this\npaper, we propose a novel framework for joint video semantic segmentation and\noptical flow estimation. Semantic segmentation brings semantic information to\nhandle occlusion for more robust optical flow estimation, while the\nnon-occluded optical flow provides accurate pixel-level temporal\ncorrespondences to guarantee the temporal consistency of the segmentation.\nMoreover, our framework is able to utilize both labeled and unlabeled frames in\nthe video through joint training, while no additional calculation is required\nin inference. Extensive experiments show that the proposed model makes the\nvideo semantic segmentation and optical flow estimation benefit from each other\nand outperforms existing methods under the same settings in both tasks.\n", "versions": [{"version": "v1", "created": "Thu, 28 Nov 2019 15:01:35 GMT"}], "update_date": "2019-12-02", "authors_parsed": [["Ding", "Mingyu", ""], ["Wang", "Zhe", ""], ["Zhou", "Bolei", ""], ["Shi", "Jianping", ""], ["Lu", "Zhiwu", ""], ["Luo", "Ping", ""]]}, {"id": "1911.12740", "submitter": "Sunav Choudhary", "authors": "Ramit Pahwa, Manoj Ghuhan Arivazhagan, Ankur Garg, Siddarth\n  Krishnamoorthy, Rohit Saxena, Sunav Choudhary", "title": "Data-Driven Compression of Convolutional Neural Networks", "comments": "17 pages, 10 tables, 1 figure", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Deploying trained convolutional neural networks (CNNs) to mobile devices is a\nchallenging task because of the simultaneous requirements of the deployed model\nto be fast, lightweight and accurate. Designing and training a CNN architecture\nthat does well on all three metrics is highly non-trivial and can be very\ntime-consuming if done by hand. One way to solve this problem is to compress\nthe trained CNN models before deploying to mobile devices. This work asks and\nanswers three questions on compressing CNN models automatically: a) How to\ncontrol the trade-off between speed, memory and accuracy during model\ncompression? b) In practice, a deployed model may not see all classes and/or\nmay not need to produce all class labels. Can this fact be used to improve the\ntrade-off? c) How to scale the compression algorithm to execute within a\nreasonable amount of time for many deployments? The paper demonstrates that a\nmodel compression algorithm utilizing reinforcement learning with architecture\nsearch and knowledge distillation can answer these questions in the\naffirmative. Experimental results are provided for current state-of-the-art CNN\nmodel families for image feature extraction like VGG and ResNet with CIFAR\ndatasets.\n", "versions": [{"version": "v1", "created": "Thu, 28 Nov 2019 15:03:59 GMT"}], "update_date": "2019-12-02", "authors_parsed": [["Pahwa", "Ramit", ""], ["Arivazhagan", "Manoj Ghuhan", ""], ["Garg", "Ankur", ""], ["Krishnamoorthy", "Siddarth", ""], ["Saxena", "Rohit", ""], ["Choudhary", "Sunav", ""]]}, {"id": "1911.12760", "submitter": "Vatsal Aggarwal", "authors": "Vatsal Aggarwal, Marius Cotescu, Nishant Prateek, Jaime\n  Lorenzo-Trueba, and Roberto Barra-Chicote", "title": "Using VAEs and Normalizing Flows for One-shot Text-To-Speech Synthesis\n  of Expressive Speech", "comments": "Accepted to ICASSP 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CL cs.SD eess.AS stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a Text-to-Speech method to create an unseen expressive style using\none utterance of expressive speech of around one second. Specifically, we\nenhance the disentanglement capabilities of a state-of-the-art\nsequence-to-sequence based system with a Variational AutoEncoder (VAE) and a\nHouseholder Flow. The proposed system provides a 22% KL-divergence reduction\nwhile jointly improving perceptual metrics over state-of-the-art. At synthesis\ntime we use one example of expressive style as a reference input to the encoder\nfor generating any text in the desired style. Perceptual MUSHRA evaluations\nshow that we can create a voice with a 9% relative naturalness improvement over\nstandard Neural Text-to-Speech, while also improving the perceived emotional\nintensity (59 compared to the 55 of neutral speech).\n", "versions": [{"version": "v1", "created": "Thu, 28 Nov 2019 15:57:14 GMT"}, {"version": "v2", "created": "Mon, 17 Feb 2020 13:56:04 GMT"}], "update_date": "2020-02-18", "authors_parsed": [["Aggarwal", "Vatsal", ""], ["Cotescu", "Marius", ""], ["Prateek", "Nishant", ""], ["Lorenzo-Trueba", "Jaime", ""], ["Barra-Chicote", "Roberto", ""]]}, {"id": "1911.12774", "submitter": "Harry Clifford MSci DPhil", "authors": "Adnan Akbar, Geoffroy Dubourg-Felonneau, Andrey Solovyev, John W\n  Cassidy, Nirmesh Patel, Harry W Clifford", "title": "Effective Sub-clonal Cancer Representation to Predict Tumor Evolution", "comments": "Learning Meaningful Representations of Life Workshop at NeurIPS 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.GN cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The majority of cancer treatments end in failure due to Intra-Tumor\nHeterogeneity (ITH). ITH in cancer is represented by clonal evolution where\ndifferent sub-clones compete with each other for resources under conditions of\nDarwinian natural selection. Predicting the growth of these sub-clones within a\ntumour is among the key challenges of modern cancer research. Predicting tumor\nbehavior enables the creation of risk profiles for patients and the\noptimisation of their treatment by therapeutically targeting sub-clones more\nlikely to grow. Current research efforts in this space are focused on\nmathematical modelling of population genetics to quantify the selective\nadvantage of sub-clones, thus enabling predictions of which sub-clones are more\nlikely to grow. These tumor evolution models are based on assumptions which are\nnot valid for real-world tumor micro-environment. Furthermore, these models are\noften fit on a single instance of a tumor, and hence prediction models cannot\nbe validated. This paper presents an alternative approach for predicting cancer\nevolution using a data-driven machine learning method. Our proposed method is\nbased on the intuition that if we can capture the true characteristics of\nsub-clones within a tumor and represent it in the form of features, a\nsophisticated machine learning algorithm can be trained to predict its\nbehavior. The work presented here provides a novel approach to predicting\ncancer evolution, utilizing a data-driver approach. We strongly believe that\nthe accumulation of data from microbiologists, oncologists and machine learning\nresearchers could be used to encapsulate the true essence of tumor sub-clones,\nand can play a vital role in selecting the best cancer treatments for patients.\n", "versions": [{"version": "v1", "created": "Thu, 28 Nov 2019 16:23:33 GMT"}], "update_date": "2019-12-02", "authors_parsed": [["Akbar", "Adnan", ""], ["Dubourg-Felonneau", "Geoffroy", ""], ["Solovyev", "Andrey", ""], ["Cassidy", "John W", ""], ["Patel", "Nirmesh", ""], ["Clifford", "Harry W", ""]]}, {"id": "1911.12777", "submitter": "Peeter Laud", "authors": "Peeter Laud and Alisa Pankova", "title": "Interpreting Epsilon of Differential Privacy in Terms of Advantage in\n  Guessing or Approximating Sensitive Attributes", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  There are numerous methods of achieving $\\epsilon$-differential privacy (DP).\nThe question is what is the appropriate value of $\\epsilon$, since there is no\ncommon agreement on a \"sufficiently small\" $\\epsilon$, and its goodness depends\non the query as well as the data. In this paper, we show how to compute\n$\\epsilon$ that corresponds to $\\delta$, defined as the adversary's advantage\nin probability of guessing some specific property of the output. The attacker's\ngoal can be stated as Boolean expression over guessing particular attributes,\npossibly within some precision. The attributes combined in this way should be\nindependent. We assume that both the input and the output distributions have\ncorresponding probability density functions, or probability mass functions.\n", "versions": [{"version": "v1", "created": "Thu, 28 Nov 2019 16:24:51 GMT"}], "update_date": "2019-12-02", "authors_parsed": [["Laud", "Peeter", ""], ["Pankova", "Alisa", ""]]}, {"id": "1911.12780", "submitter": "Colin Paterson", "authors": "Colin Paterson, Radu Calinescu and Chiara Picardi", "title": "Detection and Mitigation of Rare Subclasses in Deep Neural Network\n  Classifiers", "comments": "8 pages, 7 Figures, 2 Tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Regions of high-dimensional input spaces that are underrepresented in\ntraining datasets reduce machine-learnt classifier performance, and may lead to\ncorner cases and unwanted bias for classifiers used in decision making systems.\nWhen these regions belong to otherwise well-represented classes, their presence\nand negative impact are very hard to identify. We propose an approach for the\ndetection and mitigation of such rare subclasses in deep neural network\nclassifiers. The new approach is underpinned by an easy-to-compute commonality\nmetric that supports the detection of rare subclasses, and comprises methods\nfor reducing the impact of these subclasses during both model training and\nmodel exploitation. We demonstrate our approach using two well-known datasets,\nMNIST's handwritten digits and Kaggle's cats/dogs, identifying rare subclasses\nand producing models which compensate for subclass rarity. In addition we\ndemonstrate how our run-time approach increases the ability of users to\nidentify samples likely to be misclassified at run-time.\n", "versions": [{"version": "v1", "created": "Thu, 28 Nov 2019 16:41:35 GMT"}, {"version": "v2", "created": "Wed, 7 Jul 2021 15:06:42 GMT"}], "update_date": "2021-07-08", "authors_parsed": [["Paterson", "Colin", ""], ["Calinescu", "Radu", ""], ["Picardi", "Chiara", ""]]}, {"id": "1911.12796", "submitter": "Kaidi Xu", "authors": "Shaokai Ye, Kailu Wu, Mu Zhou, Yunfei Yang, Sia huat Tan, Kaidi Xu,\n  Jiebo Song, Chenglong Bao, Kaisheng Ma", "title": "Light-weight Calibrator: a Separable Component for Unsupervised Domain\n  Adaptation", "comments": "Accepted by CVPR2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG eess.IV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Existing domain adaptation methods aim at learning features that can be\ngeneralized among domains. These methods commonly require to update source\nclassifier to adapt to the target domain and do not properly handle the trade\noff between the source domain and the target domain. In this work, instead of\ntraining a classifier to adapt to the target domain, we use a separable\ncomponent called data calibrator to help the fixed source classifier recover\ndiscrimination power in the target domain, while preserving the source domain's\nperformance. When the difference between two domains is small, the source\nclassifier's representation is sufficient to perform well in the target domain\nand outperforms GAN-based methods in digits. Otherwise, the proposed method can\nleverage synthetic images generated by GANs to boost performance and achieve\nstate-of-the-art performance in digits datasets and driving scene semantic\nsegmentation. Our method empirically reveals that certain intriguing hints,\nwhich can be mitigated by adversarial attack to domain discriminators, are one\nof the sources for performance degradation under the domain shift.\n", "versions": [{"version": "v1", "created": "Thu, 28 Nov 2019 17:18:03 GMT"}, {"version": "v2", "created": "Fri, 28 Feb 2020 14:12:02 GMT"}], "update_date": "2020-03-02", "authors_parsed": [["Ye", "Shaokai", ""], ["Wu", "Kailu", ""], ["Zhou", "Mu", ""], ["Yang", "Yunfei", ""], ["Tan", "Sia huat", ""], ["Xu", "Kaidi", ""], ["Song", "Jiebo", ""], ["Bao", "Chenglong", ""], ["Ma", "Kaisheng", ""]]}, {"id": "1911.12809", "submitter": "George De Ath", "authors": "George De Ath, Richard M. Everson, Alma A. M. Rahat and Jonathan E.\n  Fieldsend", "title": "Greed is Good: Exploration and Exploitation Trade-offs in Bayesian\n  Optimisation", "comments": "Published in ACM Transactions on Evolutionary Learning and\n  Optimization (TELO). 22 pages (main paper) + 27 pages (supplementary\n  material)", "journal-ref": null, "doi": "10.1145/3425501", "report-no": null, "categories": "cs.LG cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The performance of acquisition functions for Bayesian optimisation to locate\nthe global optimum of continuous functions is investigated in terms of the\nPareto front between exploration and exploitation. We show that Expected\nImprovement (EI) and the Upper Confidence Bound (UCB) always select solutions\nto be expensively evaluated on the Pareto front, but Probability of Improvement\nis not guaranteed to do so and Weighted Expected Improvement does so only for a\nrestricted range of weights.\n  We introduce two novel $\\epsilon$-greedy acquisition functions. Extensive\nempirical evaluation of these together with random search, purely exploratory,\nand purely exploitative search on 10 benchmark problems in 1 to 10 dimensions\nshows that $\\epsilon$-greedy algorithms are generally at least as effective as\nconventional acquisition functions (e.g., EI and UCB), particularly with a\nlimited budget. In higher dimensions $\\epsilon$-greedy approaches are shown to\nhave improved performance over conventional approaches. These results are borne\nout on a real world computational fluid dynamics optimisation problem and a\nrobotics active learning problem. Our analysis and experiments suggest that the\nmost effective strategy, particularly in higher dimensions, is to be mostly\ngreedy, occasionally selecting a random exploratory solution.\n", "versions": [{"version": "v1", "created": "Thu, 28 Nov 2019 17:52:06 GMT"}, {"version": "v2", "created": "Wed, 28 Apr 2021 12:58:19 GMT"}], "update_date": "2021-04-29", "authors_parsed": [["De Ath", "George", ""], ["Everson", "Richard M.", ""], ["Rahat", "Alma A. M.", ""], ["Fieldsend", "Jonathan E.", ""]]}, {"id": "1911.12813", "submitter": "Qinghao Ye", "authors": "Qinghao Ye, Kaiyuan Hu, Yizhe Wang", "title": "Application of Time Series Analysis to Traffic Accidents in Los Angeles", "comments": "19 pages, 12 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.AP cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  With the improvements of Los Angeles in many aspects, people in mounting\nnumbers tend to live or travel to the city. The primary objective of this paper\nis to apply a set of methods for the time series analysis of traffic accidents\nin Los Angeles in the past few years. The number of traffic accidents,\ncollected from 2010 to 2019 monthly reveals that the traffic accident happens\nseasonally and increasing with fluctuation. This paper utilizes the ensemble\nmethods to combine several different methods to model the data from various\nperspectives, which can lead to better forecasting accuracy. The IMA(1, 1),\nETS(A, N, A), and two models with Fourier items are failed in independence\nassumption checking. However, the Online Gradient Descent (OGD) model generated\nby the ensemble method shows the perfect fit in the data modeling, which is the\nstate-of-the-art model among our candidate models. Therefore, it can be easier\nto accurately forecast future traffic accidents based on previous data through\nour model, which can help designers to make better plans.\n", "versions": [{"version": "v1", "created": "Thu, 28 Nov 2019 18:01:54 GMT"}], "update_date": "2019-12-02", "authors_parsed": [["Ye", "Qinghao", ""], ["Hu", "Kaiyuan", ""], ["Wang", "Yizhe", ""]]}, {"id": "1911.12815", "submitter": "Weidong Cao", "authors": "Weidong Cao, Liu Ke, Ayan Chakrabarti, Xuan Zhang", "title": "Neural Network-Inspired Analog-to-Digital Conversion to Achieve\n  Super-Resolution with Low-Precision RRAM Devices", "comments": "7 pages, ICCAD 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AR cs.ET eess.SP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent works propose neural network- (NN-) inspired analog-to-digital\nconverters (NNADCs) and demonstrate their great potentials in many emerging\napplications. These NNADCs often rely on resistive random-access memory (RRAM)\ndevices to realize the NN operations and require high-precision RRAM cells\n(6~12-bit) to achieve a moderate quantization resolution (4~8-bit). Such\noptimistic assumption of RRAM resolution, however, is not supported by\nfabrication data of RRAM arrays in large-scale production process. In this\npaper, we propose an NN-inspired super-resolution ADC based on low-precision\nRRAM devices by taking the advantage of a co-design methodology that combines a\npipelined hardware architecture with a custom NN training framework. Results\nobtained from SPICE simulations demonstrate that our method leads to robust\ndesign of a 14-bit super-resolution ADC using 3-bit RRAM devices with improved\npower and speed performance and competitive figure-of-merits (FoMs). In\naddition to the linear uniform quantization, the proposed ADC can also support\nconfigurable high-resolution nonlinear quantization with high conversion speed\nand low conversion energy, enabling future intelligent analog-to-information\ninterfaces for near-sensor analytics and processing.\n", "versions": [{"version": "v1", "created": "Thu, 28 Nov 2019 18:09:07 GMT"}], "update_date": "2019-12-02", "authors_parsed": [["Cao", "Weidong", ""], ["Ke", "Liu", ""], ["Chakrabarti", "Ayan", ""], ["Zhang", "Xuan", ""]]}, {"id": "1911.12842", "submitter": "Bhishma Dedhia", "authors": "Sarthak Consul, Bhishma Dedhia, Kumar Ashutosh and Parthasarathi\n  Khirwadkar", "title": "Analysis of Lower Bounds for Simple Policy Iteration", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG math.OC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Policy iteration is a family of algorithms that are used to find an optimal\npolicy for a given Markov Decision Problem (MDP). Simple Policy iteration (SPI)\nis a type of policy iteration where the strategy is to change the policy at\nexactly one improvable state at every step. Melekopoglou and Condon [1990]\nshowed an exponential lower bound on the number of iterations taken by SPI for\na 2 action MDP. The results have not been generalized to $k-$action MDP since.\nIn this paper, we revisit the algorithm and the analysis done by Melekopoglou\nand Condon. We generalize the previous result and prove a novel exponential\nlower bound on the number of iterations taken by policy iteration for\n$N-$state, $k-$action MDPs. We construct a family of MDPs and give an\nindex-based switching rule that yields a strong lower bound of\n$\\mathcal{O}\\big((3+k)2^{N/2-3}\\big)$.\n", "versions": [{"version": "v1", "created": "Thu, 28 Nov 2019 19:45:16 GMT"}], "update_date": "2019-12-02", "authors_parsed": [["Consul", "Sarthak", ""], ["Dedhia", "Bhishma", ""], ["Ashutosh", "Kumar", ""], ["Khirwadkar", "Parthasarathi", ""]]}, {"id": "1911.12848", "submitter": "Sonali Rajesh Shah", "authors": "Sonali Rajesh Shah (1) and Abhishek Kaushik (1) ((1) Dublin Business\n  School)", "title": "Sentiment Analysis On Indian Indigenous Languages: A Review On\n  Multilingual Opinion Mining", "comments": null, "journal-ref": null, "doi": "10.20944/preprints201911.0338.v1", "report-no": null, "categories": "cs.CL cs.IR cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  An increase in the use of smartphones has laid to the use of the internet and\nsocial media platforms. The most commonly used social media platforms are\nTwitter, Facebook, WhatsApp and Instagram. People are sharing their personal\nexperiences, reviews, feedbacks on the web. The information which is available\non the web is unstructured and enormous. Hence, there is a huge scope of\nresearch on understanding the sentiment of the data available on the web.\nSentiment Analysis (SA) can be carried out on the reviews, feedbacks,\ndiscussions available on the web. There has been extensive research carried out\non SA in the English language, but data on the web also contains different\nother languages which should be analyzed. This paper aims to analyze, review\nand discuss the approaches, algorithms, challenges faced by the researchers\nwhile carrying out the SA on Indigenous languages.\n", "versions": [{"version": "v1", "created": "Thu, 28 Nov 2019 20:00:40 GMT"}], "update_date": "2019-12-02", "authors_parsed": [["Shah", "Sonali Rajesh", ""], ["Kaushik", "Abhishek", ""]]}, {"id": "1911.12850", "submitter": "Basel Alyafi", "authors": "Basel Alyafi, Oliver Diaz, Joan C Vilanova, Javier del Riego, Robert\n  Marti", "title": "Quality analysis of DCGAN-generated mammography lesions", "comments": "Abstract accepted in the International Workshop Breast Imaging IWBI\n  (2020), 4 pages, 3 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.IV cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Medical image synthesis has gained a great focus recently, especially after\nthe introduction of Generative Adversarial Networks (GANs). GANs have been used\nwidely to provide anatomically-plausible and diverse samples for augmentation\nand other applications, including segmentation and super resolution. In our\nprevious work, Deep Convolutional GANs were used to generate synthetic\nmammogram lesions, masses mainly, that could enhance the classification\nperformance in imbalanced datasets. In this new work, a deeper investigation\nwas carried out to explore other aspects of the generated images evaluation,\ni.e., realism, feature space distribution, and observers studies. t-Stochastic\nNeighbor Embedding (t-SNE) was used to reduce the dimensionality of real and\nfake images to enable 2D visualisations. Additionally, two expert radiologists\nperformed a realism-evaluation study. Visualisations showed that the generated\nimages have a similar feature distribution of the real ones, avoiding outliers.\nMoreover, Receiver Operating Characteristic (ROC) curve showed that the\nradiologists could not, in many cases, distinguish between synthetic and real\nlesions, giving 48% and 61% accuracies in a balanced sample set.\n", "versions": [{"version": "v1", "created": "Thu, 28 Nov 2019 20:11:19 GMT"}, {"version": "v2", "created": "Thu, 6 Feb 2020 11:40:09 GMT"}], "update_date": "2020-02-07", "authors_parsed": [["Alyafi", "Basel", ""], ["Diaz", "Oliver", ""], ["Vilanova", "Joan C", ""], ["del Riego", "Javier", ""], ["Marti", "Robert", ""]]}, {"id": "1911.12851", "submitter": "Rui Silva", "authors": "Rui Silva, Miguel Vasco, Francisco S. Melo, Ana Paiva, Manuela Veloso", "title": "Playing Games in the Dark: An approach for cross-modality transfer in\n  reinforcement learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this work we explore the use of latent representations obtained from\nmultiple input sensory modalities (such as images or sounds) in allowing an\nagent to learn and exploit policies over different subsets of input modalities.\nWe propose a three-stage architecture that allows a reinforcement learning\nagent trained over a given sensory modality, to execute its task on a different\nsensory modality-for example, learning a visual policy over image inputs, and\nthen execute such policy when only sound inputs are available. We show that the\ngeneralized policies achieve better out-of-the-box performance when compared to\ndifferent baselines. Moreover, we show this holds in different OpenAI gym and\nvideo game environments, even when using different multimodal generative models\nand reinforcement learning algorithms.\n", "versions": [{"version": "v1", "created": "Thu, 28 Nov 2019 20:15:48 GMT"}], "update_date": "2019-12-02", "authors_parsed": [["Silva", "Rui", ""], ["Vasco", "Miguel", ""], ["Melo", "Francisco S.", ""], ["Paiva", "Ana", ""], ["Veloso", "Manuela", ""]]}, {"id": "1911.12864", "submitter": "Da Xu", "authors": "Da Xu, Chuanwei Ruan, Sushant Kumar, Evren Korpeoglu, Kannan Achan", "title": "Self-attention with Functional Time Representation Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Sequential modelling with self-attention has achieved cutting edge\nperformances in natural language processing. With advantages in model\nflexibility, computation complexity and interpretability, self-attention is\ngradually becoming a key component in event sequence models. However, like most\nother sequence models, self-attention does not account for the time span\nbetween events and thus captures sequential signals rather than temporal\npatterns. Without relying on recurrent network structures, self-attention\nrecognizes event orderings via positional encoding. To bridge the gap between\nmodelling time-independent and time-dependent event sequence, we introduce a\nfunctional feature map that embeds time span into high-dimensional spaces. By\nconstructing the associated translation-invariant time kernel function, we\nreveal the functional forms of the feature map under classic functional\nfunction analysis results, namely Bochner's Theorem and Mercer's Theorem. We\npropose several models to learn the functional time representation and the\ninteractions with event representation. These methods are evaluated on\nreal-world datasets under various continuous-time event sequence prediction\ntasks. The experiments reveal that the proposed methods compare favorably to\nbaseline models while also capturing useful time-event interactions.\n", "versions": [{"version": "v1", "created": "Thu, 28 Nov 2019 21:04:21 GMT"}], "update_date": "2019-12-02", "authors_parsed": [["Xu", "Da", ""], ["Ruan", "Chuanwei", ""], ["Kumar", "Sushant", ""], ["Korpeoglu", "Evren", ""], ["Achan", "Kannan", ""]]}, {"id": "1911.12868", "submitter": "Michael Smith", "authors": "Michael T. Smith, Joel Ssematimba, Mauricio A. Alvarez, Engineer\n  Bainomugisha", "title": "Machine Learning for a Low-cost Air Pollution Network", "comments": "Presented at NeurIPS 2019 Workshop on Machine Learning for the\n  Developing World", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.AP stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Data collection in economically constrained countries often necessitates\nusing approximate and biased measurements due to the low-cost of the sensors\nused. This leads to potentially invalid predictions and poor policies or\ndecision making. This is especially an issue if methods from resource-rich\nregions are applied without handling these additional constraints. In this\npaper we show, through the use of an air pollution network example, how using\nprobabilistic machine learning can mitigate some of the technical constraints.\nSpecifically we experiment with modelling the calibration for individual\nsensors as either distributions or Gaussian processes over time, and discuss\nthe wider issues around the decision process.\n", "versions": [{"version": "v1", "created": "Thu, 28 Nov 2019 21:32:59 GMT"}], "update_date": "2019-12-02", "authors_parsed": [["Smith", "Michael T.", ""], ["Ssematimba", "Joel", ""], ["Alvarez", "Mauricio A.", ""], ["Bainomugisha", "Engineer", ""]]}, {"id": "1911.12870", "submitter": "Veniamin Morgenshtern I.", "authors": "Matthias Sonntag and Veniamin I. Morgenshtern", "title": "Region segmentation via deep learning and convex optimization", "comments": "15 pages, 6 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG eess.IV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we propose a method to segment regions in three-dimensional\npoint clouds. We assume that (i) the shape and the number of regions in the\npoint cloud are not known and (ii) the point cloud may be noisy. The method\nconsists of two steps. In the first step we use a deep neural network to\npredict the probability that a pair of small patches from the point cloud\nbelongs to the same region. In the second step, we use a convex-optimization\nbased method to improve the predictions of the network by enforcing consistency\nconstraints. We evaluate the accuracy of our method on a custom dataset of\nconvex polyhedra, where the regions correspond to the faces of the polyhedra.\nThe method can be seen as a robust and flexible alternative to the famous\nregion growing segmentation algorithm. All reported results are reproducible\nand come with easy to use code that could serve as a baseline for future\nresearch.\n", "versions": [{"version": "v1", "created": "Thu, 28 Nov 2019 21:42:21 GMT"}], "update_date": "2019-12-02", "authors_parsed": [["Sonntag", "Matthias", ""], ["Morgenshtern", "Veniamin I.", ""]]}, {"id": "1911.12885", "submitter": "Shi Qiu", "authors": "Shi Qiu, Saeed Anwar and Nick Barnes", "title": "Geometric Back-projection Network for Point Cloud Classification", "comments": "14 pages, 8 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG cs.RO eess.IV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  As the basic task of point cloud analysis, classification is fundamental but\nalways challenging. To address some unsolved problems of existing methods, we\npropose a network that captures geometric features of point clouds for better\nrepresentations. To achieve this, on the one hand, we enrich the geometric\ninformation of points in low-level 3D space explicitly. On the other hand, we\napply CNN-based structures in high-level feature spaces to learn local\ngeometric context implicitly. Specifically, we leverage an idea of\nerror-correcting feedback structure to capture the local features of point\nclouds comprehensively. Furthermore, an attention module based on channel\naffinity assists the feature map to avoid possible redundancy by emphasizing\nits distinct channels. The performance on both synthetic and real-world point\nclouds datasets demonstrate the superiority and applicability of our network.\nComparing with other state-of-the-art methods, our approach balances accuracy\nand efficiency.\n", "versions": [{"version": "v1", "created": "Thu, 28 Nov 2019 22:37:06 GMT"}, {"version": "v2", "created": "Mon, 2 Dec 2019 02:54:28 GMT"}, {"version": "v3", "created": "Fri, 6 Mar 2020 06:23:35 GMT"}, {"version": "v4", "created": "Thu, 3 Sep 2020 12:29:50 GMT"}, {"version": "v5", "created": "Tue, 13 Apr 2021 05:57:13 GMT"}], "update_date": "2021-04-14", "authors_parsed": [["Qiu", "Shi", ""], ["Anwar", "Saeed", ""], ["Barnes", "Nick", ""]]}, {"id": "1911.12896", "submitter": "Michael Kamp", "authors": "Michael Kamp, Mario Boley, Michael Mock, Daniel Keren, Assaf Schuster,\n  Izchak Sharfman", "title": "Adaptive Communication Bounds for Distributed Online Learning", "comments": null, "journal-ref": "Proceedings of the 7th NIPS Workshop on Optimization for Machine\n  Learning, 2014", "doi": null, "report-no": null, "categories": "cs.DC cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We consider distributed online learning protocols that control the exchange\nof information between local learners in a round-based learning scenario. The\nlearning performance of such a protocol is intuitively optimal if approximately\nthe same loss is incurred as in a hypothetical serial setting. If a protocol\naccomplishes this, it is inherently impossible to achieve a strong\ncommunication bound at the same time. In the worst case, every input is\nessential for the learning performance, even for the serial setting, and thus\nneeds to be exchanged between the local learners. However, it is reasonable to\ndemand a bound that scales well with the hardness of the serialized prediction\nproblem, as measured by the loss received by a serial online learning\nalgorithm. We provide formal criteria based on this intuition and show that\nthey hold for a simplified version of a previously published protocol.\n", "versions": [{"version": "v1", "created": "Thu, 28 Nov 2019 23:12:34 GMT"}], "update_date": "2019-12-02", "authors_parsed": [["Kamp", "Michael", ""], ["Boley", "Mario", ""], ["Mock", "Michael", ""], ["Keren", "Daniel", ""], ["Schuster", "Assaf", ""], ["Sharfman", "Izchak", ""]]}, {"id": "1911.12899", "submitter": "Michael Kamp", "authors": "Michael Kamp, Sebastian Bothe, Mario Boley, Michael Mock", "title": "Communication-Efficient Distributed Online Learning with Kernels", "comments": null, "journal-ref": "Machine Learning and Knowledge Discovery in Databases. ECML PKDD\n  2016", "doi": null, "report-no": null, "categories": "cs.LG cs.DC stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We propose an efficient distributed online learning protocol for low-latency\nreal-time services. It extends a previously presented protocol to kernelized\nonline learners that represent their models by a support vector expansion.\nWhile such learners often achieve higher predictive performance than their\nlinear counterparts, communicating the support vector expansions becomes\ninefficient for large numbers of support vectors. The proposed extension allows\nfor a larger class of online learning algorithms---including those alleviating\nthe problem above through model compression. In addition, we characterize the\nquality of the proposed protocol by introducing a novel criterion that requires\nthe communication to be bounded by the loss suffered.\n", "versions": [{"version": "v1", "created": "Thu, 28 Nov 2019 23:22:30 GMT"}], "update_date": "2019-12-02", "authors_parsed": [["Kamp", "Michael", ""], ["Bothe", "Sebastian", ""], ["Boley", "Mario", ""], ["Mock", "Michael", ""]]}, {"id": "1911.12905", "submitter": "Piotr Mi{\\l}o\\'s", "authors": "B{\\l}a\\.zej Osi\\'nski, Adam Jakubowski, Piotr Mi{\\l}o\\'s, Pawe{\\l}\n  Zi\\k{e}cina, Christopher Galias, Silviu Homoceanu, and Henryk Michalewski", "title": "Simulation-based reinforcement learning for real-world autonomous\n  driving", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.RO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We use reinforcement learning in simulation to obtain a driving system\ncontrolling a full-size real-world vehicle. The driving policy takes RGB images\nfrom a single camera and their semantic segmentation as input. We use mostly\nsynthetic data, with labelled real-world data appearing only in the training of\nthe segmentation network.\n  Using reinforcement learning in simulation and synthetic data is motivated by\nlowering costs and engineering effort.\n  In real-world experiments we confirm that we achieved successful sim-to-real\npolicy transfer. Based on the extensive evaluation, we analyze how design\ndecisions about perception, control, and training impact the real-world\nperformance.\n", "versions": [{"version": "v1", "created": "Fri, 29 Nov 2019 00:08:58 GMT"}, {"version": "v2", "created": "Thu, 26 Dec 2019 05:25:47 GMT"}, {"version": "v3", "created": "Wed, 4 Mar 2020 14:19:18 GMT"}], "update_date": "2020-03-05", "authors_parsed": [["Osi\u0144ski", "B\u0142a\u017cej", ""], ["Jakubowski", "Adam", ""], ["Mi\u0142o\u015b", "Piotr", ""], ["Zi\u0119cina", "Pawe\u0142", ""], ["Galias", "Christopher", ""], ["Homoceanu", "Silviu", ""], ["Michalewski", "Henryk", ""]]}, {"id": "1911.12918", "submitter": "Yuxuan Zhao", "authors": "Yuxuan Zhao, Xinyan Cao, Jinlong Lin, Dunshan Yu, Xixin Cao", "title": "Multimodal Emotion Recognition Model using Physiological Signals", "comments": "10 pages, 10 figures, 6 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.SP cs.HC cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  As an important field of research in Human-Machine Interactions, emotion\nrecognition based on physiological signals has become research hotspots.\nMotivated by the outstanding performance of deep learning approaches in\nrecognition tasks, we proposed a Multimodal Emotion Recognition Model that\nconsists of a 3D convolutional neural network model, a 1D convolutional neural\nnetwork model and a biologically inspired multimodal fusion model which\nintegrates multimodal information on the decision level for emotion\nrecognition. We use this model to classify four emotional regions from the\narousal valence plane, i.e., low arousal and low valence (LALV), high arousal\nand low valence (HALV), low arousal and high valence (LAHV) and high arousal\nand high valence (HAHV) in the DEAP and AMIGOS dataset. The 3D CNN model and 1D\nCNN model are used for emotion recognition based on electroencephalogram (EEG)\nsignals and peripheral physiological signals respectively, and get the accuracy\nof 93.53% and 95.86% with the original EEG signals in these two datasets.\nCompared with the single-modal recognition, the multimodal fusion model\nimproves the accuracy of emotion recognition by 5% ~ 25%, and the fusion result\nof EEG signals (decomposed into four frequency bands) and peripheral\nphysiological signals get the accuracy of 95.77%, 97.27% and 91.07%, 99.74% in\nthese two datasets respectively. Integrated EEG signals and peripheral\nphysiological signals, this model could reach the highest accuracy about 99% in\nboth datasets which shows that our proposed method demonstrates certain\nadvantages in solving the emotion recognition tasks.\n", "versions": [{"version": "v1", "created": "Fri, 29 Nov 2019 01:35:23 GMT"}], "update_date": "2019-12-02", "authors_parsed": [["Zhao", "Yuxuan", ""], ["Cao", "Xinyan", ""], ["Lin", "Jinlong", ""], ["Yu", "Dunshan", ""], ["Cao", "Xixin", ""]]}, {"id": "1911.12919", "submitter": "Duc Le", "authors": "Van-Duc Le, Tien-Cuong Bui, Sang Kyun Cha", "title": "Spatiotemporal deep learning model for citywide air pollution\n  interpolation and prediction", "comments": "Accepted at BigComp2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG eess.SP stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Recently, air pollution is one of the most concerns for big cities.\nPredicting air quality for any regions and at any time is a critical\nrequirement of urban citizens. However, air pollution prediction for the whole\ncity is a challenging problem. The reason is, there are many spatiotemporal\nfactors affecting air pollution throughout the city. Collecting as many of them\ncould help us to forecast air pollution better. In this research, we present\nmany spatiotemporal datasets collected over Seoul city in Korea, which is\ncurrently much suffered by air pollution problem as well. These datasets\ninclude air pollution data, meteorological data, traffic volume, average\ndriving speed, and air pollution indexes of external areas which are known to\nimpact Seoul's air pollution. To the best of our knowledge, traffic volume and\naverage driving speed data are two new datasets in air pollution research. In\naddition, recent research in air pollution has tried to build models to\ninterpolate and predict air pollution in the city. Nevertheless, they mostly\nfocused on predicting air quality in discrete locations or used hand-crafted\nspatial and temporal features. In this paper, we propose the usage of\nConvolutional Long Short-Term Memory (ConvLSTM) model \\cite{b16}, a combination\nof Convolutional Neural Networks and Long Short-Term Memory, which\nautomatically manipulates both the spatial and temporal features of the data.\nSpecially, we introduce how to transform the air pollution data into sequences\nof images which leverages the using of ConvLSTM model to interpolate and\npredict air quality for the entire city at the same time. We prove that our\napproach is suitable for spatiotemporal air pollution problems and also\noutperforms other related research.\n", "versions": [{"version": "v1", "created": "Fri, 29 Nov 2019 01:40:54 GMT"}], "update_date": "2019-12-02", "authors_parsed": [["Le", "Van-Duc", ""], ["Bui", "Tien-Cuong", ""], ["Cha", "Sang Kyun", ""]]}, {"id": "1911.12922", "submitter": "Georgios Smyrnis", "authors": "Georgios Smyrnis, Petros Maragos", "title": "Tropical Polynomial Division and Neural Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG math.RA stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this work, we examine the process of Tropical Polynomial Division, a\ngeometric method which seeks to emulate the division of regular polynomials,\nwhen applied to those of the max-plus semiring. This is done via the\napproximation of the Newton Polytope of the dividend polynomial by that of the\ndivisor. This process is afterwards generalized and applied in the context of\nneural networks with ReLU activations. In particular, we make use of the\nintuition it provides, in order to minimize a two-layer fully connected\nnetwork, trained for a binary classification problem. This method is later\nevaluated on a variety of experiments, demonstrating its capability to\napproximate a network, with minimal loss in performance.\n", "versions": [{"version": "v1", "created": "Fri, 29 Nov 2019 02:10:23 GMT"}], "update_date": "2019-12-02", "authors_parsed": [["Smyrnis", "Georgios", ""], ["Maragos", "Petros", ""]]}, {"id": "1911.12926", "submitter": "Yen-Min Hsu", "authors": "Bo-Wen Chen and Yen-Min Hsu and Hung-Yi Lee", "title": "J-Net: Randomly weighted U-Net for audio source separation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SD cs.LG eess.AS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Several results in the computer vision literature have shown the potential of\nrandomly weighted neural networks. While they perform fairly well as feature\nextractors for discriminative tasks, a positive correlation exists between\ntheir performance and their fully trained counterparts. According to these\ndiscoveries, we pose two questions: what is the value of randomly weighted\nnetworks in difficult generative audio tasks such as audio source separation\nand does such positive correlation still exist when it comes to large random\nnetworks and their trained counterparts? In this paper, we demonstrate that the\npositive correlation still exists. Based on this discovery, we can try out\ndifferent architecture designs or tricks without training the whole model.\nMeanwhile, we find a surprising result that in comparison to the non-trained\nencoder (down-sample path) in Wave-U-Net, fixing the decoder (up-sample path)\nto random weights results in better performance, almost comparable to the fully\ntrained model.\n", "versions": [{"version": "v1", "created": "Fri, 29 Nov 2019 02:24:05 GMT"}], "update_date": "2019-12-02", "authors_parsed": [["Chen", "Bo-Wen", ""], ["Hsu", "Yen-Min", ""], ["Lee", "Hung-Yi", ""]]}, {"id": "1911.12927", "submitter": "Russell Tsuchida B.E.", "authors": "Russell Tsuchida, Fred Roosta, Marcus Gallagher", "title": "Richer priors for infinitely wide multi-layer perceptrons", "comments": "Pre-print", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  It is well-known that the distribution over functions induced through a\nzero-mean iid prior distribution over the parameters of a multi-layer\nperceptron (MLP) converges to a Gaussian process (GP), under mild conditions.\nWe extend this result firstly to independent priors with general zero or\nnon-zero means, and secondly to a family of partially exchangeable priors which\ngeneralise iid priors. We discuss how the second prior arises naturally when\nconsidering an equivalence class of functions in an MLP and through training\nprocesses such as stochastic gradient descent.\n  The model resulting from partially exchangeable priors is a GP, with an\nadditional level of inference in the sense that the prior and posterior\npredictive distributions require marginalisation over hyperparameters. We\nderive the kernels of the limiting GP in deep MLPs, and show empirically that\nthese kernels avoid certain pathologies present in previously studied priors.\nWe empirically evaluate our claims of convergence by measuring the maximum mean\ndiscrepancy between finite width models and limiting models. We compare the\nperformance of our new limiting model to some previously discussed models on\nsynthetic regression problems. We observe increasing ill-conditioning of the\nmarginal likelihood and hyper-posterior as the depth of the model increases,\ndrawing parallels with finite width networks which require notoriously involved\noptimisation tricks.\n", "versions": [{"version": "v1", "created": "Fri, 29 Nov 2019 02:34:35 GMT"}], "update_date": "2019-12-02", "authors_parsed": [["Tsuchida", "Russell", ""], ["Roosta", "Fred", ""], ["Gallagher", "Marcus", ""]]}, {"id": "1911.12928", "submitter": "Naoya Takahashi", "authors": "Naoya Takahashi, Mayank Kumar Singh, Sakya Basak, Parthasaarathy\n  Sudarsanam, Sriram Ganapathy, Yuki Mitsufuji", "title": "Improving Voice Separation by Incorporating End-to-end Speech\n  Recognition", "comments": "Accepted in ICASSP 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SD cs.LG eess.AS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Despite recent advances in voice separation methods, many challenges remain\nin realistic scenarios such as noisy recording and the limits of available\ndata. In this work, we propose to explicitly incorporate the phonetic and\nlinguistic nature of speech by taking a transfer learning approach using an\nend-to-end automatic speech recognition (E2EASR) system. The voice separation\nis conditioned on deep features extracted from E2EASR to cover the long-term\ndependence of phonetic aspects. Experimental results on speech separation and\nenhancement task on the AVSpeech dataset show that the proposed method\nsignificantly improves the signal-to-distortion ratio over the baseline model\nand even outperforms an audio visual model, that utilizes visual information of\nlip movements.\n", "versions": [{"version": "v1", "created": "Fri, 29 Nov 2019 02:37:17 GMT"}, {"version": "v2", "created": "Mon, 4 May 2020 00:03:27 GMT"}], "update_date": "2020-05-05", "authors_parsed": [["Takahashi", "Naoya", ""], ["Singh", "Mayank Kumar", ""], ["Basak", "Sakya", ""], ["Sudarsanam", "Parthasaarathy", ""], ["Ganapathy", "Sriram", ""], ["Mitsufuji", "Yuki", ""]]}, {"id": "1911.12950", "submitter": "Jin Chen", "authors": "Kaihua Zhang, Jin Chen, Bo Liu, Qingshan Liu", "title": "Deep Object Co-segmentation via Spatial-Semantic Network Modulation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG eess.IV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Object co-segmentation is to segment the shared objects in multiple relevant\nimages, which has numerous applications in computer vision. This paper presents\na spatial and semantic modulated deep network framework for object\nco-segmentation. A backbone network is adopted to extract multi-resolution\nimage features. With the multi-resolution features of the relevant images as\ninput, we design a spatial modulator to learn a mask for each image. The\nspatial modulator captures the correlations of image feature descriptors via\nunsupervised learning. The learned mask can roughly localize the shared\nforeground object while suppressing the background. For the semantic modulator,\nwe model it as a supervised image classification task. We propose a\nhierarchical second-order pooling module to transform the image features for\nclassification use. The outputs of the two modulators manipulate the\nmulti-resolution features by a shift-and-scale operation so that the features\nfocus on segmenting co-object regions. The proposed model is trained end-to-end\nwithout any intricate post-processing. Extensive experiments on four image\nco-segmentation benchmark datasets demonstrate the superior accuracy of the\nproposed method compared to state-of-the-art methods.\n", "versions": [{"version": "v1", "created": "Fri, 29 Nov 2019 04:40:30 GMT"}], "update_date": "2019-12-02", "authors_parsed": [["Zhang", "Kaihua", ""], ["Chen", "Jin", ""], ["Liu", "Bo", ""], ["Liu", "Qingshan", ""]]}, {"id": "1911.12965", "submitter": "Jiaqi Zhang", "authors": "Jiaqi Zhang and Beilun Wang", "title": "Sparse and Low-Rank Tensor Regression via Parallel Proximal Method", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Motivated by applications in various scientific fields having demand of\npredicting relationship between higher-order (tensor) feature and univariate\nresponse, we propose a \\underline{S}parse and \\underline{L}ow-rank\n\\underline{T}ensor \\underline{R}egression model (SLTR). This model enforces\nsparsity and low-rankness of the tensor coefficient by directly applying\n$\\ell_1$ norm and tensor nuclear norm on it respectively, such that (1) the\nstructural information of tensor is preserved and (2) the data interpretation\nis convenient. To make the solving procedure scalable and efficient, SLTR makes\nuse of the proximal gradient method to optimize two norm regularizers, which\ncan be easily implemented parallelly. Additionally, a tighter convergence rate\nis proved over three-order tensor data. We evaluate SLTR on several simulated\ndatasets and one fMRI dataset. Experiment results show that, compared with\nprevious models, SLTR is able to obtain a solution no worse than others with\nmuch less time cost.\n", "versions": [{"version": "v1", "created": "Fri, 29 Nov 2019 06:25:36 GMT"}], "update_date": "2019-12-02", "authors_parsed": [["Zhang", "Jiaqi", ""], ["Wang", "Beilun", ""]]}, {"id": "1911.12976", "submitter": "Melkior Ornik", "authors": "Melkior Ornik and Ufuk Topcu", "title": "Learning and Planning for Time-Varying MDPs Using Maximum Likelihood\n  Estimation", "comments": "To be published in Journal of Machine Learning Research", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.SY eess.SY math.OC stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  This paper proposes a formal approach to online learning and planning for\nagents operating in a priori unknown, time-varying environments. The proposed\nmethod computes the maximally likely model of the environment, given the\nobservations about the environment made by an agent earlier in the system run\nand assuming knowledge of a bound on the maximal rate of change of system\ndynamics. Such an approach generalizes the estimation method commonly used in\nlearning algorithms for unknown Markov decision processes with time-invariant\ntransition probabilities, but is also able to quickly and correctly identify\nthe system dynamics following a change. Based on the proposed method, we\ngeneralize the exploration bonuses used in learning for time-invariant Markov\ndecision processes by introducing a notion of uncertainty in a learned\ntime-varying model, and develop a control policy for time-varying Markov\ndecision processes based on the exploitation and exploration trade-off. We\ndemonstrate the proposed methods on four numerical examples: a patrolling task\nwith a change in system dynamics, a two-state MDP with periodically changing\noutcomes of actions, a wind flow estimation task, and a multi-armed bandit\nproblem with periodically changing probabilities of different rewards.\n", "versions": [{"version": "v1", "created": "Fri, 29 Nov 2019 07:02:14 GMT"}, {"version": "v2", "created": "Mon, 8 Feb 2021 17:13:14 GMT"}], "update_date": "2021-02-09", "authors_parsed": [["Ornik", "Melkior", ""], ["Topcu", "Ufuk", ""]]}, {"id": "1911.12983", "submitter": "Mohammad Mahfujur Rahman", "authors": "Mohammad Mahfujur Rahman, Clinton Fookes, Mahsa Baktashmotlagh, Sridha\n  Sridharan", "title": "Correlation-aware Adversarial Domain Adaptation and Generalization", "comments": "Preprint submitted to Pattern Recognition, Accepted in Pattern\n  Recognition", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Domain adaptation (DA) and domain generalization (DG) have emerged as a\nsolution to the domain shift problem where the distribution of the source and\ntarget data is different. The task of DG is more challenging than DA as the\ntarget data is totally unseen during the training phase in DG scenarios. The\ncurrent state-of-the-art employs adversarial techniques, however, these are\nrarely considered for the DG problem. Furthermore, these approaches do not\nconsider correlation alignment which has been proven highly beneficial for\nminimizing domain discrepancy. In this paper, we propose a correlation-aware\nadversarial DA and DG framework where the features of the source and target\ndata are minimized using correlation alignment along with adversarial learning.\nIncorporating the correlation alignment module along with adversarial learning\nhelps to achieve a more domain agnostic model due to the improved ability to\nreduce domain discrepancy with unlabeled target data more effectively.\nExperiments on benchmark datasets serve as evidence that our proposed method\nyields improved state-of-the-art performance.\n", "versions": [{"version": "v1", "created": "Fri, 29 Nov 2019 07:22:15 GMT"}], "update_date": "2019-12-02", "authors_parsed": [["Rahman", "Mohammad Mahfujur", ""], ["Fookes", "Clinton", ""], ["Baktashmotlagh", "Mahsa", ""], ["Sridharan", "Sridha", ""]]}, {"id": "1911.12986", "submitter": "Ansong Ni", "authors": "Ansong Ni, Pengcheng Yin, Graham Neubig", "title": "Merging Weak and Active Supervision for Semantic Parsing", "comments": "AAAI 2020 Main Track [Oral] (To appear)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A semantic parser maps natural language commands (NLs) from the users to\nexecutable meaning representations (MRs), which are later executed in certain\nenvironment to obtain user-desired results. The fully-supervised training of\nsuch parser requires NL/MR pairs, annotated by domain experts, which makes them\nexpensive to collect. However, weakly-supervised semantic parsers are learnt\nonly from pairs of NL and expected execution results, leaving the MRs latent.\nWhile weak supervision is cheaper to acquire, learning from this input poses\ndifficulties. It demands that parsers search a large space with a very weak\nlearning signal and it is hard to avoid spurious MRs that achieve the correct\nanswer in the wrong way. These factors lead to a performance gap between\nparsers trained in weakly- and fully-supervised setting. To bridge this gap, we\nexamine the intersection between weak supervision and active learning, which\nallows the learner to actively select examples and query for manual annotations\nas extra supervision to improve the model trained under weak supervision. We\nstudy different active learning heuristics for selecting examples to query, and\nvarious forms of extra supervision for such queries. We evaluate the\neffectiveness of our method on two different datasets. Experiments on the\nWikiSQL show that by annotating only 1.8% of examples, we improve over a\nstate-of-the-art weakly-supervised baseline by 6.4%, achieving an accuracy of\n79.0%, which is only 1.3% away from the model trained with full supervision.\nExperiments on WikiTableQuestions with human annotators show that our method\ncan improve the performance with only 100 active queries, especially for\nweakly-supervised parsers learnt from a cold start.\n", "versions": [{"version": "v1", "created": "Fri, 29 Nov 2019 07:48:19 GMT"}], "update_date": "2019-12-02", "authors_parsed": [["Ni", "Ansong", ""], ["Yin", "Pengcheng", ""], ["Neubig", "Graham", ""]]}, {"id": "1911.12990", "submitter": "Jihun Yun", "authors": "Jung Hyun Lee, Jihun Yun, Sung Ju Hwang, Eunho Yang", "title": "Semi-Relaxed Quantization with DropBits: Training Low-Bit Neural\n  Networks via Bit-wise Regularization", "comments": "19 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG eess.IV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Network quantization, which aims to reduce the bit-lengths of the network\nweights and activations, has emerged as one of the key ingredients to reduce\nthe size of neural networks for their deployments to resource-limited devices.\nIn order to overcome the nature of transforming continuous activations and\nweights to discrete ones, recent study called Relaxed Quantization (RQ)\n[Louizos et al. 2019] successfully employ the popular Gumbel-Softmax that\nallows this transformation with efficient gradient-based optimization. However,\nRQ with this Gumbel-Softmax relaxation still suffers from bias-variance\ntrade-off depending on the temperature parameter of Gumbel-Softmax. To resolve\nthe issue, we propose a novel method, Semi-Relaxed Quantization (SRQ) that uses\nmulti-class straight-through estimator to effectively reduce the bias and\nvariance, along with a new regularization technique, DropBits that replaces\ndropout regularization to randomly drop the bits instead of neurons to further\nreduce the bias of the multi-class straight-through estimator in SRQ. As a\nnatural extension of DropBits, we further introduce the way of learning\nheterogeneous quantization levels to find proper bit-length for each layer\nusing DropBits. We experimentally validate our method on various benchmark\ndatasets and network architectures, and also support the quantized lottery\nticket hypothesis: learning heterogeneous quantization levels outperforms the\ncase using the same but fixed quantization levels from scratch.\n", "versions": [{"version": "v1", "created": "Fri, 29 Nov 2019 07:58:43 GMT"}, {"version": "v2", "created": "Mon, 2 Nov 2020 07:35:34 GMT"}], "update_date": "2020-11-03", "authors_parsed": [["Lee", "Jung Hyun", ""], ["Yun", "Jihun", ""], ["Hwang", "Sung Ju", ""], ["Yang", "Eunho", ""]]}, {"id": "1911.12993", "submitter": "Sethu Hareesh Kolluru", "authors": "Sethu Hareesh Kolluru", "title": "Investigations on the inference optimization techniques and their impact\n  on multiple hardware platforms for Semantic Segmentation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG eess.IV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this work, the task of pixel-wise semantic segmentation in the context of\nself-driving with a goal to reduce the inference time is explored. Fully\nConvolutional Network (FCN-8s, FCN-16s, and FCN-32s) with a VGG16 encoder\narchitecture and skip connections is trained and validated on the Cityscapes\ndataset. Numerical investigations are carried out for several inference\noptimization techniques built into TensorFlow and TensorRT to quantify their\nimpact on the inference time and network size. Finally, the trained network is\nported on to an embedded platform (Nvidia Jetson TX1) and the inference time,\nas well as the total energy consumed for inference across hardware platforms,\nare compared.\n", "versions": [{"version": "v1", "created": "Fri, 29 Nov 2019 08:08:28 GMT"}], "update_date": "2019-12-02", "authors_parsed": [["Kolluru", "Sethu Hareesh", ""]]}, {"id": "1911.13009", "submitter": "Manuel Lopes", "authors": "Manuel Lopes, Francisco Melo", "title": "Class Teaching for Inverse Reinforcement Learners", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we propose the first machine teaching algorithm for multiple\ninverse reinforcement learners. Specifically, our contributions are: (i) we\nformally introduce the problem of teaching a sequential task to a heterogeneous\ngroup of learners; (ii) we identify conditions under which it is possible to\nconduct such teaching using the same demonstration for all learners; and (iii)\nwe propose and evaluate a simple algorithm that computes a demonstration(s)\nensuring that all agents in a heterogeneous class learn a task description that\nis compatible with the target task. Our analysis shows that, contrary to other\nteaching problems, teaching a heterogeneous class with a single demonstration\nmay not be possible as the differences between agents increase. We also\nshowcase the advantages of our proposed machine teaching approach against\nseveral possible alternatives.\n", "versions": [{"version": "v1", "created": "Fri, 29 Nov 2019 09:22:51 GMT"}], "update_date": "2019-12-02", "authors_parsed": [["Lopes", "Manuel", ""], ["Melo", "Francisco", ""]]}, {"id": "1911.13014", "submitter": "Andreas Kipf", "authors": "Andreas Kipf, Ryan Marcus, Alexander van Renen, Mihail Stoian, Alfons\n  Kemper, Tim Kraska, Thomas Neumann", "title": "SOSD: A Benchmark for Learned Indexes", "comments": "NeurIPS 2019 Workshop on Machine Learning for Systems", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DB cs.DS cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A groundswell of recent work has focused on improving data management systems\nwith learned components. Specifically, work on learned index structures has\nproposed replacing traditional index structures, such as B-trees, with learned\nmodels. Given the decades of research committed to improving index structures,\nthere is significant skepticism about whether learned indexes actually\noutperform state-of-the-art implementations of traditional structures on\nreal-world data. To answer this question, we propose a new benchmarking\nframework that comes with a variety of real-world datasets and baseline\nimplementations to compare against. We also show preliminary results for\nselected index structures, and find that learned models indeed often outperform\nstate-of-the-art implementations, and are therefore a promising direction for\nfuture research.\n", "versions": [{"version": "v1", "created": "Fri, 29 Nov 2019 09:35:04 GMT"}], "update_date": "2019-12-02", "authors_parsed": [["Kipf", "Andreas", ""], ["Marcus", "Ryan", ""], ["van Renen", "Alexander", ""], ["Stoian", "Mihail", ""], ["Kemper", "Alfons", ""], ["Kraska", "Tim", ""], ["Neumann", "Thomas", ""]]}, {"id": "1911.13018", "submitter": "Antonio Quintero-Rincon", "authors": "Antonio Quintero-Rinc\\'on, Catalina Carenzo, Joaqu\\'in Ems, Lourdes\n  Hirschson, Valeria Muro, Carlos D'Giano", "title": "Spike-and-wave epileptiform discharge pattern detection based on\n  Kendall's Tau-b coefficient", "comments": "8 pages, 3 figures. RESEARCH LETTERS/SHORT REPORTS", "journal-ref": "Applied Medical Informatics 41 (1), 1-8, 2019", "doi": null, "report-no": null, "categories": "stat.ML cs.LG eess.SP stat.AP", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Epilepsy is an important public health issue. An appropriate epileptiform\ndischarge pattern detection of this neurological disease is a typical problem\nin biomedical engineering. In this paper, a new method is proposed for\nspike-and-wave discharge pattern detection based on Kendall's Tau-b\ncoefficient. The proposed approach is demonstrated on a real dataset containing\nspike-and-wave discharge signals, where our performance is evaluated in terms\nof high Specificity, rule in (SpPIn) with 94% for patient-specific\nspike-and-wave discharge detection and 83% for a general spike-and-wave\ndischarge detection.\n", "versions": [{"version": "v1", "created": "Fri, 29 Nov 2019 09:41:45 GMT"}], "update_date": "2019-12-02", "authors_parsed": [["Quintero-Rinc\u00f3n", "Antonio", ""], ["Carenzo", "Catalina", ""], ["Ems", "Joaqu\u00edn", ""], ["Hirschson", "Lourdes", ""], ["Muro", "Valeria", ""], ["D'Giano", "Carlos", ""]]}, {"id": "1911.13019", "submitter": "Minsoo Kang", "authors": "Minsoo Kang, Jonghwan Mun, Bohyung Han", "title": "Towards Oracle Knowledge Distillation with Neural Architecture Search", "comments": "accepted by AAAI-20", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a novel framework of knowledge distillation that is capable of\nlearning powerful and efficient student models from ensemble teacher networks.\nOur approach addresses the inherent model capacity issue between teacher and\nstudent and aims to maximize benefit from teacher models during distillation by\nreducing their capacity gap. Specifically, we employ a neural architecture\nsearch technique to augment useful structures and operations, where the\nsearched network is appropriate for knowledge distillation towards student\nmodels and free from sacrificing its performance by fixing the network\ncapacity. We also introduce an oracle knowledge distillation loss to facilitate\nmodel search and distillation using an ensemble-based teacher model, where a\nstudent network is learned to imitate oracle performance of the teacher. We\nperform extensive experiments on the image classification datasets---CIFAR-100\nand TinyImageNet---using various networks. We also show that searching for a\nnew student model is effective in both accuracy and memory size and that the\nsearched models often outperform their teacher models thanks to neural\narchitecture search with oracle knowledge distillation.\n", "versions": [{"version": "v1", "created": "Fri, 29 Nov 2019 09:42:15 GMT"}], "update_date": "2019-12-02", "authors_parsed": [["Kang", "Minsoo", ""], ["Mun", "Jonghwan", ""], ["Han", "Bohyung", ""]]}, {"id": "1911.13029", "submitter": "Jiaqi Jiang", "authors": "Fufang Wen, Jiaqi Jiang and Jonathan A. Fan", "title": "Progressive-Growing of Generative Adversarial Networks for Metasurface\n  Optimization", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "physics.comp-ph cs.LG eess.IV physics.app-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Generative adversarial networks, which can generate metasurfaces based on a\ntraining set of high performance device layouts, have the potential to\nsignificantly reduce the computational cost of the metasurface design process.\nHowever, basic GAN architectures are unable to fully capture the detailed\nfeatures of topologically complex metasurfaces, and generated devices therefore\nrequire additional computationally-expensive design refinement. In this Letter,\nwe show that GANs can better learn spatially fine features from high-resolution\ntraining data by progressively growing its network architecture and training\nset. Our results indicate that with this training methodology, the best\ngenerated devices have performances that compare well with the best devices\nproduced by gradient-based topology optimization, thereby eliminating the need\nfor additional design refinement. We envision that this network training method\ncan generalize to other physical systems where device performance is strongly\ncorrelated with fine geometric structuring.\n", "versions": [{"version": "v1", "created": "Fri, 29 Nov 2019 10:05:54 GMT"}, {"version": "v2", "created": "Mon, 2 Dec 2019 07:35:41 GMT"}], "update_date": "2019-12-03", "authors_parsed": [["Wen", "Fufang", ""], ["Jiang", "Jiaqi", ""], ["Fan", "Jonathan A.", ""]]}, {"id": "1911.13034", "submitter": "Marco Forgione", "authors": "Marco Forgione, Dario Piga", "title": "Model structures and fitting criteria for system identification with\n  neural networks", "comments": "Source code generating the results of the paper available at\n  https://github.com/forgi86/sysid-neural-structures-fitting", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.SY eess.SY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper focuses on the identification of dynamical systems with\ntailor-made model structures, where neural networks are used to approximate\nuncertain components and domain knowledge is retained, if available. These\nmodel structures are fitted to measured data using different criteria including\na computationally efficient approach minimizing a regularized multi-step ahead\nsimulation error. In this approach, the neural network parameters are estimated\nalong with the initial conditions used to simulate the output signal in\nsmall-size subsequences. A regularization term is included in the fitting cost\nin order to enforce these initial conditions to be consistent with the\nestimated system dynamics. Pitfalls and limitations of naive one-step\nprediction and simulation error minimization are also discussed.\n", "versions": [{"version": "v1", "created": "Fri, 29 Nov 2019 10:14:58 GMT"}], "update_date": "2019-12-02", "authors_parsed": [["Forgione", "Marco", ""], ["Piga", "Dario", ""]]}, {"id": "1911.13036", "submitter": "Luc Giffon", "authors": "Luc Giffon (QARMA, LIS), St\\'ephane Ayache (QARMA, LIS), Thierry\n  Arti\\`eres (QARMA, ECM, LIS), Hachem Kadri (QARMA, LIS)", "title": "Deep Networks with Adaptive Nystr\\\"om Approximation", "comments": null, "journal-ref": "IJCNN 2019 - International Joint Conference on Neural Networks,\n  Jul 2019, Budapest, Hungary", "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent work has focused on combining kernel methods and deep learning to\nexploit the best of the two approaches. Here, we introduce a new architecture\nof neural networks in which we replace the top dense layers of standard\nconvolutional architectures with an approximation of a kernel function by\nrelying on the Nystr{\\\"o}m approximation. Our approach is easy and highly\nflexible. It is compatible with any kernel function and it allows exploiting\nmultiple kernels. We show that our architecture has the same performance than\nstandard architecture on datasets like SVHN and CIFAR100. One benefit of the\nmethod lies in its limited number of learnable parameters which makes it\nparticularly suited for small training set sizes, e.g. from 5 to 20 samples per\nclass.\n", "versions": [{"version": "v1", "created": "Fri, 29 Nov 2019 10:26:59 GMT"}], "update_date": "2019-12-02", "authors_parsed": [["Giffon", "Luc", "", "QARMA, LIS"], ["Ayache", "St\u00e9phane", "", "QARMA, LIS"], ["Arti\u00e8res", "Thierry", "", "QARMA, ECM, LIS"], ["Kadri", "Hachem", "", "QARMA, LIS"]]}, {"id": "1911.13042", "submitter": "Claudio Gambella", "authors": "Julien Monteil, Anton Dekusar, Claudio Gambella, Yassine Lassoued,\n  Martin Mevissen", "title": "On model selection for scalable time series forecasting in transport\n  networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The transport literature is dense regarding short-term traffic predictions,\nup to the scale of 1 hour, yet less dense for long-term traffic predictions.\nThe transport literature is also sparse when it comes to city-scale traffic\npredictions, mainly because of low data availability. In this work, we report\nan effort to investigate whether deep learning models can be useful for the\nlong-term large-scale traffic prediction task, while focusing on the\nscalability of the models. We investigate a city-scale traffic dataset with 14\nweeks of speed observations collected every 15 minutes over 1098 segments in\nthe hypercenter of Los Angeles, California. We look at a variety of\nstate-of-the-art machine learning and deep learning predictors for link-based\npredictions, and investigate how such predictors can scale up to larger areas\nwith clustering, and graph convolutional approaches. We discuss that modelling\ntemporal and spatial features into deep learning predictors can be helpful for\nlong-term predictions, while simpler, not deep learning-based predictors,\nachieve very satisfactory performance for link-based and short-term\nforecasting. The trade-off is discussed not only in terms of prediction\naccuracy vs prediction horizon but also in terms of training time and model\nsizing.\n", "versions": [{"version": "v1", "created": "Fri, 29 Nov 2019 10:36:49 GMT"}, {"version": "v2", "created": "Fri, 15 May 2020 15:01:31 GMT"}, {"version": "v3", "created": "Thu, 18 Feb 2021 16:52:51 GMT"}], "update_date": "2021-02-19", "authors_parsed": [["Monteil", "Julien", ""], ["Dekusar", "Anton", ""], ["Gambella", "Claudio", ""], ["Lassoued", "Yassine", ""], ["Mevissen", "Martin", ""]]}, {"id": "1911.13044", "submitter": "Todor Davchev", "authors": "Todor Davchev, Michael Burke, Subramanian Ramamoorthy", "title": "Learning Structured Representations of Spatial and Interactive Dynamics\n  for Trajectory Prediction in Crowded Scenes", "comments": null, "journal-ref": "IEEE Robotics and Automation Letters 2021", "doi": "10.1109/LRA.2020.3047778", "report-no": null, "categories": "cs.LG cs.CV cs.MA cs.RO stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Context plays a significant role in the generation of motion for dynamic\nagents in interactive environments. This work proposes a modular method that\nutilises a learned model of the environment for motion prediction. This\nmodularity explicitly allows for unsupervised adaptation of trajectory\nprediction models to unseen environments and new tasks by relying on unlabelled\nimage data only. We model both the spatial and dynamic aspects of a given\nenvironment alongside the per agent motions. This results in more informed\nmotion prediction and allows for performance comparable to the\nstate-of-the-art. We highlight the model's prediction capability using a\nbenchmark pedestrian prediction problem and a robot manipulation task and show\nthat we can transfer the predictor across these tasks in a completely\nunsupervised way. The proposed approach allows for robust and label efficient\nforward modelling, and relaxes the need for full model re-training in new\nenvironments.\n", "versions": [{"version": "v1", "created": "Fri, 29 Nov 2019 10:42:10 GMT"}, {"version": "v2", "created": "Mon, 2 Dec 2019 10:56:41 GMT"}, {"version": "v3", "created": "Fri, 17 Jan 2020 11:34:06 GMT"}, {"version": "v4", "created": "Sat, 16 May 2020 09:29:35 GMT"}, {"version": "v5", "created": "Sun, 16 Aug 2020 18:47:40 GMT"}, {"version": "v6", "created": "Sat, 2 Jan 2021 13:24:01 GMT"}], "update_date": "2021-01-05", "authors_parsed": [["Davchev", "Todor", ""], ["Burke", "Michael", ""], ["Ramamoorthy", "Subramanian", ""]]}, {"id": "1911.13053", "submitter": "Changlin Li", "authors": "Changlin Li, Jiefeng Peng, Liuchun Yuan, Guangrun Wang, Xiaodan Liang,\n  Liang Lin, Xiaojun Chang", "title": "Blockwisely Supervised Neural Architecture Search with Knowledge\n  Distillation", "comments": "To be appear in CVPR 2020. We achieve a state-of-the-art 78.4% top-1\n  accuracy on ImageNet in a mobile setting, which is about a 2.1% gain over\n  EfficientNet-B0", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Neural Architecture Search (NAS), aiming at automatically designing network\narchitectures by machines, is hoped and expected to bring about a new\nrevolution in machine learning. Despite these high expectation, the\neffectiveness and efficiency of existing NAS solutions are unclear, with some\nrecent works going so far as to suggest that many existing NAS solutions are no\nbetter than random architecture selection. The inefficiency of NAS solutions\nmay be attributed to inaccurate architecture evaluation. Specifically, to speed\nup NAS, recent works have proposed under-training different candidate\narchitectures in a large search space concurrently by using shared network\nparameters; however, this has resulted in incorrect architecture ratings and\nfurthered the ineffectiveness of NAS.\n  In this work, we propose to modularize the large search space of NAS into\nblocks to ensure that the potential candidate architectures are fully trained;\nthis reduces the representation shift caused by the shared parameters and leads\nto the correct rating of the candidates. Thanks to the block-wise search, we\ncan also evaluate all of the candidate architectures within a block. Moreover,\nwe find that the knowledge of a network model lies not only in the network\nparameters but also in the network architecture. Therefore, we propose to\ndistill the neural architecture (DNA) knowledge from a teacher model as the\nsupervision to guide our block-wise architecture search, which significantly\nimproves the effectiveness of NAS. Remarkably, the capacity of our searched\narchitecture has exceeded the teacher model, demonstrating the practicability\nand scalability of our method. Finally, our method achieves a state-of-the-art\n78.4\\% top-1 accuracy on ImageNet in a mobile setting, which is about a 2.1\\%\ngain over EfficientNet-B0. All of our searched models along with the evaluation\ncode are available online.\n", "versions": [{"version": "v1", "created": "Fri, 29 Nov 2019 11:00:30 GMT"}, {"version": "v2", "created": "Fri, 6 Mar 2020 06:08:31 GMT"}], "update_date": "2020-03-09", "authors_parsed": [["Li", "Changlin", ""], ["Peng", "Jiefeng", ""], ["Yuan", "Liuchun", ""], ["Wang", "Guangrun", ""], ["Liang", "Xiaodan", ""], ["Lin", "Liang", ""], ["Chang", "Xiaojun", ""]]}, {"id": "1911.13056", "submitter": "Dmitry Akimov", "authors": "Dmitry Akimov", "title": "Distributed Soft Actor-Critic with Multivariate Reward Representation\n  and Knowledge Distillation", "comments": "9 pages, 5 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we describe NeurIPS 2019 Learning to Move - Walk Around\nchallenge physics-based environment and present our solution to this\ncompetition which scored 1303.727 mean reward points and took 3rd place. Our\nmethod combines recent advances from both continuous- and discrete-action space\nreinforcement learning, such as Soft Actor-Critic and Recurrent Experience\nReplay in Distributed Reinforcement Learning. We trained our agent in two\nstages: to move somewhere at the first stage and to follow the target velocity\nfield at the second stage. We also introduce novel Q-function split technique,\nwhich we believe facilitates the task of training an agent, allows critic\npretraining and reusing it for solving harder problems, and mitigate reward\nshaping design efforts.\n", "versions": [{"version": "v1", "created": "Fri, 29 Nov 2019 11:15:26 GMT"}, {"version": "v2", "created": "Fri, 10 Apr 2020 12:16:34 GMT"}], "update_date": "2020-04-13", "authors_parsed": [["Akimov", "Dmitry", ""]]}, {"id": "1911.13060", "submitter": "Jan M\\\"uller", "authors": "Jan M\\\"uller, Reinhard Klein, Michael Weinmann", "title": "Orthogonal Wasserstein GANs", "comments": "Correction of the formatting of the appendix", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG eess.IV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Wasserstein-GANs have been introduced to address the deficiencies of\ngenerative adversarial networks (GANs) regarding the problems of vanishing\ngradients and mode collapse during the training, leading to improved\nconvergence behaviour and improved image quality. However, Wasserstein-GANs\nrequire the discriminator to be Lipschitz continuous. In current\nstate-of-the-art Wasserstein-GANs this constraint is enforced via gradient norm\nregularization. In this paper, we demonstrate that this regularization does not\nencourage a broad distribution of spectral-values in the discriminator weights,\nhence resulting in less fidelity in the learned distribution. We therefore\ninvestigate the possibility of substituting this Lipschitz constraint with an\northogonality constraint on the weight matrices. We compare three different\nweight orthogonalization techniques with regards to their convergence\nproperties, their ability to ensure the Lipschitz condition and the achieved\nquality of the learned distribution. In addition, we provide a comparison to\nWasserstein-GANs trained with current state-of-the-art methods, where we\ndemonstrate the potential of solely using orthogonality-based regularization.\nIn this context, we propose an improved training procedure for Wasserstein-GANs\nwhich utilizes orthogonalization to further increase its generalization\ncapability. Finally, we provide a novel metric to evaluate the generalization\ncapabilities of the discriminators of different Wasserstein-GANs.\n", "versions": [{"version": "v1", "created": "Fri, 29 Nov 2019 11:20:12 GMT"}, {"version": "v2", "created": "Sun, 15 Dec 2019 00:36:08 GMT"}], "update_date": "2019-12-17", "authors_parsed": [["M\u00fcller", "Jan", ""], ["Klein", "Reinhard", ""], ["Weinmann", "Michael", ""]]}, {"id": "1911.13061", "submitter": "Duncan Watson-Parris", "authors": "Duncan Watson-Parris, Samuel Sutherland, Matthew Christensen, Anthony\n  Caterini, Dino Sejdinovic, Philip Stier", "title": "Detecting anthropogenic cloud perturbations with deep learning", "comments": "Awarded Best Paper and Spotlight Oral at Climate Change: How Can AI\n  Help? (Workshop) at International Conference on Machine Learning (ICML), Long\n  Beach, California, 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "physics.ao-ph cs.CV cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  One of the most pressing questions in climate science is that of the effect\nof anthropogenic aerosol on the Earth's energy balance. Aerosols provide the\n`seeds' on which cloud droplets form, and changes in the amount of aerosol\navailable to a cloud can change its brightness and other physical properties\nsuch as optical thickness and spatial extent. Clouds play a critical role in\nmoderating global temperatures and small perturbations can lead to significant\namounts of cooling or warming. Uncertainty in this effect is so large it is not\ncurrently known if it is negligible, or provides a large enough cooling to\nlargely negate present-day warming by CO2. This work uses deep convolutional\nneural networks to look for two particular perturbations in clouds due to\nanthropogenic aerosol and assess their properties and prevalence, providing\nvaluable insights into their climatic effects.\n", "versions": [{"version": "v1", "created": "Fri, 29 Nov 2019 11:22:48 GMT"}], "update_date": "2019-12-02", "authors_parsed": [["Watson-Parris", "Duncan", ""], ["Sutherland", "Samuel", ""], ["Christensen", "Matthew", ""], ["Caterini", "Anthony", ""], ["Sejdinovic", "Dino", ""], ["Stier", "Philip", ""]]}, {"id": "1911.13068", "submitter": "Beibin Li", "authors": "Beibin Li, Nicholas Nuechterlein, Erin Barney, Caitlin Hudac, Pamela\n  Ventola, Linda Shapiro, Frederick Shic", "title": "Sparsely Grouped Input Variables for Neural Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In genomic analysis, biomarker discovery, image recognition, and other\nsystems involving machine learning, input variables can often be organized into\ndifferent groups by their source or semantic category. Eliminating some groups\nof variables can expedite the process of data acquisition and avoid\nover-fitting. Researchers have used the group lasso to ensure group sparsity in\nlinear models and have extended it to create compact neural networks in\nmeta-learning. Different from previous studies, we use multi-layer non-linear\nneural networks to find sparse groups for input variables. We propose a new\nloss function to regularize parameters for grouped input variables, design a\nnew optimization algorithm for this loss function, and test these methods in\nthree real-world settings. We achieve group sparsity for three datasets,\nmaintaining satisfying results while excluding one nucleotide position from an\nRNA splicing experiment, excluding 89.9% of stimuli from an eye-tracking\nexperiment, and excluding 60% of image rows from an experiment on the MNIST\ndataset.\n", "versions": [{"version": "v1", "created": "Fri, 29 Nov 2019 11:45:20 GMT"}], "update_date": "2019-12-02", "authors_parsed": [["Li", "Beibin", ""], ["Nuechterlein", "Nicholas", ""], ["Barney", "Erin", ""], ["Hudac", "Caitlin", ""], ["Ventola", "Pamela", ""], ["Shapiro", "Linda", ""], ["Shic", "Frederick", ""]]}, {"id": "1911.13073", "submitter": "Nupur Kumari", "authors": "Mayank Singh, Nupur Kumari, Puneet Mangla, Abhishek Sinha, Vineeth N\n  Balasubramanian, Balaji Krishnamurthy", "title": "Attributional Robustness Training using Input-Gradient Spatial Alignment", "comments": "ECCV 2020, Code at\n  https://github.com/nupurkmr9/Attributional-Robustness", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG eess.IV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Interpretability is an emerging area of research in trustworthy machine\nlearning. Safe deployment of machine learning system mandates that the\nprediction and its explanation be reliable and robust. Recently, it has been\nshown that the explanations could be manipulated easily by adding visually\nimperceptible perturbations to the input while keeping the model's prediction\nintact. In this work, we study the problem of attributional robustness (i.e.\nmodels having robust explanations) by showing an upper bound for attributional\nvulnerability in terms of spatial correlation between the input image and its\nexplanation map. We propose a training methodology that learns robust features\nby minimizing this upper bound using soft-margin triplet loss. Our methodology\nof robust attribution training (\\textit{ART}) achieves the new state-of-the-art\nattributional robustness measure by a margin of $\\approx$ 6-18 $\\%$ on several\nstandard datasets, ie. SVHN, CIFAR-10 and GTSRB. We further show the utility of\nthe proposed robust training technique (\\textit{ART}) in the downstream task of\nweakly supervised object localization by achieving the new state-of-the-art\nperformance on CUB-200 dataset.\n", "versions": [{"version": "v1", "created": "Fri, 29 Nov 2019 12:08:41 GMT"}, {"version": "v2", "created": "Wed, 4 Dec 2019 07:55:31 GMT"}, {"version": "v3", "created": "Tue, 10 Dec 2019 07:20:28 GMT"}, {"version": "v4", "created": "Sat, 18 Jul 2020 16:07:35 GMT"}], "update_date": "2020-07-21", "authors_parsed": [["Singh", "Mayank", ""], ["Kumari", "Nupur", ""], ["Mangla", "Puneet", ""], ["Sinha", "Abhishek", ""], ["Balasubramanian", "Vineeth N", ""], ["Krishnamurthy", "Balaji", ""]]}, {"id": "1911.13078", "submitter": "Francisco Nogueira Calmon Sobral", "authors": "E. V. Castelani and R. Lopes and W. V. I. Shirabayashi and F. N. C.\n  Sobral", "title": "A robust method based on LOVO functions for solving least squares\n  problems", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.OC cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  The robust adjustment of nonlinear models to data is considered in this\npaper. When data comes from real experiments, it is possible that measurement\nerrors cause the appearance of discrepant values, which should be ignored when\nadjusting models to them. This work presents a Lower Order-value Optimization\n(LOVO) version of the Levenberg-Marquardt algorithm, which is well suited to\ndeal with outliers in fitting problems. A general algorithm is presented and\nconvergence to stationary points is demonstrated. Numerical results show that\nthe algorithm is successfully able to detect and ignore outliers without too\nmany specific parameters. Parallel and distributed executions of the algorithm\nare also possible, allowing for the use of larger datasets. Comparison against\npublicly available robust algorithms shows that the present approach is able to\nfind better adjustments in well known statistical models.\n", "versions": [{"version": "v1", "created": "Fri, 29 Nov 2019 12:33:56 GMT"}], "update_date": "2019-12-02", "authors_parsed": [["Castelani", "E. V.", ""], ["Lopes", "R.", ""], ["Shirabayashi", "W. V. I.", ""], ["Sobral", "F. N. C.", ""]]}, {"id": "1911.13096", "submitter": "Rujing Yao", "authors": "Rujing Yao, Linlin Hou, Yingchun Ye, Ou Wu, Ji Zhang, Jian Wu", "title": "Method and Dataset Mining in Scientific Papers", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CL cs.IR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Literature analysis facilitates researchers better understanding the\ndevelopment of science and technology. The conventional literature analysis\nfocuses on the topics, authors, abstracts, keywords, references, etc., and\nrarely pays attention to the content of papers. In the field of machine\nlearning, the involved methods (M) and datasets (D) are key information in\npapers. The extraction and mining of M and D are useful for discipline analysis\nand algorithm recommendation. In this paper, we propose a novel entity\nrecognition model, called MDER, and constructe datasets from the papers of the\nPAKDD conferences (2009-2019). Some preliminary experiments are conducted to\nassess the extraction performance and the mining results are visualized.\n", "versions": [{"version": "v1", "created": "Fri, 29 Nov 2019 13:19:45 GMT"}], "update_date": "2019-12-02", "authors_parsed": [["Yao", "Rujing", ""], ["Hou", "Linlin", ""], ["Ye", "Yingchun", ""], ["Wu", "Ou", ""], ["Zhang", "Ji", ""], ["Wu", "Jian", ""]]}, {"id": "1911.13101", "submitter": "William Shen", "authors": "William Shen, Felipe Trevizan, Sylvie Thi\\'ebaux", "title": "Learning Domain-Independent Planning Heuristics with Hypergraph Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present the first approach capable of learning domain-independent planning\nheuristics entirely from scratch. The heuristics we learn map the hypergraph\nrepresentation of the delete-relaxation of the planning problem at hand, to a\ncost estimate that approximates that of the least-cost path from the current\nstate to the goal through the hypergraph. We generalise Graph Networks to\nobtain a new framework for learning over hypergraphs, which we specialise to\nlearn planning heuristics by training over state/value pairs obtained from\noptimal cost plans. Our experiments show that the resulting architecture,\nSTRIPS-HGNs, is capable of learning heuristics that are competitive with\nexisting delete-relaxation heuristics including LM-cut. We show that the\nheuristics we learn are able to generalise across different problems and\ndomains, including to domains that were not seen during training.\n", "versions": [{"version": "v1", "created": "Fri, 29 Nov 2019 13:24:48 GMT"}], "update_date": "2019-12-02", "authors_parsed": [["Shen", "William", ""], ["Trevizan", "Felipe", ""], ["Thi\u00e9baux", "Sylvie", ""]]}, {"id": "1911.13122", "submitter": "Solenne Gaucher", "authors": "Solenne Gaucher (LMO), Olga Klopp (CREST), Genevi\\`eve Robin (ENPC,\n  MATHERIALS)", "title": "Outliers Detection in Networks with Missing Links", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG cs.SI stat.ME", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Outliers arise in networks due to different reasons such as fraudulent\nbehavior of malicious users or default in measurement instruments and can\nsignificantly impair network analyses. In addition, real-life networks are\nlikely to be incompletely observed, with missing links due to individual\nnon-response or machine failures. Identifying outliers in the presence of\nmissing links is therefore a crucial problem in network analysis. In this work,\nwe introduce a new algorithm to detect outliers in a network that\nsimultaneously predicts the missing links. The proposed method is statistically\nsound: we prove that, under fairly general assumptions, our algorithm exactly\ndetects the outliers, and achieves the best known error for the prediction of\nmissing links with polynomial computation cost. It is also computationally\nefficient: we prove sub-linear convergence of our algorithm. We provide a\nsimulation study which demonstrates the good behavior of the algorithm in terms\nof outliers detection and prediction of the missing links. We also illustrate\nthe method with an application in epidemiology, and with the analysis of a\npolitical Twitter network. The method is freely available as an R package on\nthe Comprehensive R Archive Network.\n", "versions": [{"version": "v1", "created": "Fri, 29 Nov 2019 14:33:00 GMT"}, {"version": "v2", "created": "Tue, 1 Dec 2020 14:19:55 GMT"}], "update_date": "2020-12-02", "authors_parsed": [["Gaucher", "Solenne", "", "LMO"], ["Klopp", "Olga", "", "CREST"], ["Robin", "Genevi\u00e8ve", "", "ENPC,\n  MATHERIALS"]]}, {"id": "1911.13135", "submitter": "Gabriel Turinici", "authors": "Gabriel Turinici (CEREMADE, Universit\\'e Paris Dauphine - PSL)", "title": "Radon Sobolev Variational Auto-Encoders", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CV cs.NE", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  The quality of generative models (such as Generative adversarial networks and\nVariational Auto-Encoders) depends heavily on the choice of a good probability\ndistance. However some popular metrics like the Wasserstein or the Sliced\nWasserstein distances, the Jensen-Shannon divergence, the Kullback-Leibler\ndivergence, lack convenient properties such as (geodesic) convexity, fast\nevaluation and so on. To address these shortcomings, we introduce a class of\ndistances that have built-in convexity. We investigate the relationship with\nsome known paradigms (sliced distances - a synonym for Radon distances -,\nreproducing kernel Hilbert spaces, energy distances). The distances are shown\nto possess fast implementations and are included in an adapted Variational\nAuto-Encoder termed Radon Sobolev Variational Auto-Encoder (RS-VAE) which\nproduces high quality results on standard generative datasets.\n  Keywords: Variational Auto-Encoder; Generative model; Sobolev spaces; Radon\nSobolev Variational Auto-Encoder;\n", "versions": [{"version": "v1", "created": "Fri, 29 Nov 2019 15:02:28 GMT"}, {"version": "v2", "created": "Mon, 16 Mar 2020 17:00:16 GMT"}, {"version": "v3", "created": "Wed, 14 Apr 2021 18:08:35 GMT"}], "update_date": "2021-04-16", "authors_parsed": [["Turinici", "Gabriel", "", "CEREMADE, Universit\u00e9 Paris Dauphine - PSL"]]}, {"id": "1911.13136", "submitter": "Hector Rodriguez-Deniz", "authors": "Hector Rodriguez-Deniz, Mattias Villani and Augusto Voltes-Dorta", "title": "A Multilayered Block Network Model to Forecast Large Dynamic\n  Transportation Graphs: an Application to US Air Transport", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG stat.AP stat.ME", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Dynamic transportation networks have been analyzed for years by means of\nstatic graph-based indicators in order to study the temporal evolution of\nrelevant network components, and to reveal complex dependencies that would not\nbe easily detected by a direct inspection of the data. This paper presents a\nstate-of-the-art latent network model to forecast multilayer dynamic graphs\nthat are increasingly common in transportation and proposes a community-based\nextension to reduce the computational burden. Flexible time series analysis is\nobtained by modeling the probability of edges between vertices through latent\nGaussian processes. The models and Bayesian inference are illustrated on a\nsample of 10-year data from four major airlines within the US air\ntransportation system. Results show how the estimated latent parameters from\nthe models are related to the airline's connectivity dynamics, and their\nability to project the multilayer graph into the future for out-of-sample full\nnetwork forecasts, while stochastic blockmodeling allows for the identification\nof relevant communities. Reliable network predictions would allow policy-makers\nto better understand the dynamics of the transport system, and help in their\nplanning on e.g. route development, or the deployment of new regulations.\n", "versions": [{"version": "v1", "created": "Fri, 29 Nov 2019 15:03:05 GMT"}, {"version": "v2", "created": "Mon, 18 May 2020 07:07:09 GMT"}, {"version": "v3", "created": "Sat, 19 Jun 2021 12:44:47 GMT"}], "update_date": "2021-06-22", "authors_parsed": [["Rodriguez-Deniz", "Hector", ""], ["Villani", "Mattias", ""], ["Voltes-Dorta", "Augusto", ""]]}, {"id": "1911.13152", "submitter": "Daniel Furelos-Blanco", "authors": "Daniel Furelos-Blanco, Mark Law, Alessandra Russo, Krysia Broda and\n  Anders Jonsson", "title": "Induction of Subgoal Automata for Reinforcement Learning", "comments": "Preprint accepted for publication to the 34th AAAI Conference on\n  Artificial Intelligence (AAAI-20)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.LO stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this work we present ISA, a novel approach for learning and exploiting\nsubgoals in reinforcement learning (RL). Our method relies on inducing an\nautomaton whose transitions are subgoals expressed as propositional formulas\nover a set of observable events. A state-of-the-art inductive logic programming\nsystem is used to learn the automaton from observation traces perceived by the\nRL agent. The reinforcement learning and automaton learning processes are\ninterleaved: a new refined automaton is learned whenever the RL agent generates\na trace not recognized by the current automaton. We evaluate ISA in several\ngridworld problems and show that it performs similarly to a method for which\nautomata are given in advance. We also show that the learned automata can be\nexploited to speed up convergence through reward shaping and transfer learning\nacross multiple tasks. Finally, we analyze the running time and the number of\ntraces that ISA needs to learn an automata, and the impact that the number of\nobservable events has on the learner's performance.\n", "versions": [{"version": "v1", "created": "Fri, 29 Nov 2019 15:28:54 GMT"}], "update_date": "2019-12-02", "authors_parsed": [["Furelos-Blanco", "Daniel", ""], ["Law", "Mark", ""], ["Russo", "Alessandra", ""], ["Broda", "Krysia", ""], ["Jonsson", "Anders", ""]]}, {"id": "1911.13159", "submitter": "Leo Feng", "authors": "Leo Feng, Luisa Zintgraf, Bei Peng, Shimon Whiteson", "title": "VIABLE: Fast Adaptation via Backpropagating Learned Loss", "comments": "Published at the 3rd Workshop on Meta-Learning at NeurIPS 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In few-shot learning, typically, the loss function which is applied at test\ntime is the one we are ultimately interested in minimising, such as the\nmean-squared-error loss for a regression problem. However, given that we have\nfew samples at test time, we argue that the loss function that we are\ninterested in minimising is not necessarily the loss function most suitable for\ncomputing gradients in a few-shot setting. We propose VIABLE, a generic\nmeta-learning extension that builds on existing meta-gradient-based methods by\nlearning a differentiable loss function, replacing the pre-defined inner-loop\nloss function in performing task-specific updates. We show that learning a loss\nfunction capable of leveraging relational information between samples reduces\nunderfitting, and significantly improves performance and sample efficiency on a\nsimple regression task. Furthermore, we show VIABLE is scalable by evaluating\non the Mini-Imagenet dataset.\n", "versions": [{"version": "v1", "created": "Fri, 29 Nov 2019 15:47:09 GMT"}], "update_date": "2019-12-02", "authors_parsed": [["Feng", "Leo", ""], ["Zintgraf", "Luisa", ""], ["Peng", "Bei", ""], ["Whiteson", "Shimon", ""]]}, {"id": "1911.13162", "submitter": "Alexander Preuhs", "authors": "Alexander Preuhs, Michael Manhart, Philipp Roser, Bernhard Stimpel,\n  Christopher Syben, Marios Psychogios, Markus Kowarschik, Andreas Maier", "title": "Deep autofocus with cone-beam CT consistency constraint", "comments": "Accepted at BVM 2020, review score under Top-6 of the conference", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV eess.IV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  High quality reconstruction with interventional C-arm cone-beam computed\ntomography (CBCT) requires exact geometry information. If the geometry\ninformation is corrupted, e. g., by unexpected patient or system movement, the\nmeasured signal is misplaced in the backprojection operation. With prolonged\nacquisition times of interventional C-arm CBCT the likelihood of rigid patient\nmotion increases. To adapt the backprojection operation accordingly, a motion\nestimation strategy is necessary. Recently, a novel learning-based approach was\nproposed, capable of compensating motions within the acquisition plane. We\nextend this method by a CBCT consistency constraint, which was proven to be\nefficient for motions perpendicular to the acquisition plane. By the\nsynergistic combination of these two measures, in and out-plane motion is well\ndetectable, achieving an average artifact suppression of 93 [percent]. This\noutperforms the entropy-based state-of-the-art autofocus measure which achieves\non average an artifact suppression of 54 [percent].\n", "versions": [{"version": "v1", "created": "Fri, 29 Nov 2019 15:54:38 GMT"}, {"version": "v2", "created": "Mon, 2 Dec 2019 12:17:44 GMT"}, {"version": "v3", "created": "Wed, 4 Dec 2019 21:43:50 GMT"}], "update_date": "2019-12-06", "authors_parsed": [["Preuhs", "Alexander", ""], ["Manhart", "Michael", ""], ["Roser", "Philipp", ""], ["Stimpel", "Bernhard", ""], ["Syben", "Christopher", ""], ["Psychogios", "Marios", ""], ["Kowarschik", "Markus", ""], ["Maier", "Andreas", ""]]}, {"id": "1911.13173", "submitter": "Brendan Ruff", "authors": "Brendan Ruff and Taylor Beck and Joscha Bach", "title": "Mean Shift Rejection: Training Deep Neural Networks Without Minibatch\n  Statistics or Normalization", "comments": "under review at ECAI2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep convolutional neural networks are known to be unstable during training\nat high learning rate unless normalization techniques are employed. Normalizing\nweights or activations allows the use of higher learning rates, resulting in\nfaster convergence and higher test accuracy. Batch normalization requires\nminibatch statistics that approximate the dataset statistics but this incurs\nadditional compute and memory costs and causes a communication bottleneck for\ndistributed training. Weight normalization and initialization-only schemes do\nnot achieve comparable test accuracy.\n  We introduce a new understanding of the cause of training instability and\nprovide a technique that is independent of normalization and minibatch\nstatistics. Our approach treats training instability as a spatial common mode\nsignal which is suppressed by placing the model on a channel-wise zero-mean\nisocline that is maintained throughout training. Firstly, we apply channel-wise\nzero-mean initialization of filter kernels with overall unity kernel magnitude.\nAt each training step we modify the gradients of spatial kernels so that their\nweighted channel-wise mean is subtracted in order to maintain the common mode\nrejection condition. This prevents the onset of mean shift. This new technique\nallows direct training of the test graph so that training and test models are\nidentical. We also demonstrate that injecting random noise throughout the\nnetwork during training improves generalization. This is based on the idea\nthat, as a side effect, batch normalization performs deep data augmentation by\ninjecting minibatch noise due to the weakness of the dataset approximation.\n  Our technique achieves higher accuracy compared to batch normalization and\nfor the first time shows that minibatches and normalization are unnecessary for\nstate-of-the-art training.\n", "versions": [{"version": "v1", "created": "Fri, 29 Nov 2019 16:19:00 GMT"}], "update_date": "2019-12-02", "authors_parsed": [["Ruff", "Brendan", ""], ["Beck", "Taylor", ""], ["Bach", "Joscha", ""]]}, {"id": "1911.13178", "submitter": "Andreas Kamilaris", "authors": "Jesper Provoost, Luc Wismans, Sander Van der Drift, Andreas Kamilaris\n  and Maurice Van Keulen", "title": "Short Term Prediction of Parking Area states Using Real Time Data and\n  Machine Learning Techniques", "comments": "Proc. of Transportation Research Board 2020 Annual Meeting,\n  Washington D.C., USA, January 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG eess.SP stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Public road authorities and private mobility service providers need\ninformation derived from the current and predicted traffic states to act upon\nthe daily urban system and its spatial and temporal dynamics. In this research,\na real-time parking area state (occupancy, in- and outflux) prediction model\n(up to 60 minutes ahead) has been developed using publicly available historic\nand real time data sources. Based on a case study in a real-life scenario in\nthe city of Arnhem, a Neural Network-based approach outperforms a Random\nForest-based one on all assessed performance measures, although the differences\nare small. Both are outperforming a naive seasonal random walk model. Although\nthe performance degrades with increasing prediction horizon, the model shows a\nperformance gain of over 150% at a prediction horizon of 60 minutes compared\nwith the naive model. Furthermore, it is shown that predicting the in- and\noutflux is a far more difficult task (i.e. performance gains of 30%) which\nneeds more training data, not based exclusively on occupancy rate. However, the\nperformance of predicting in- and outflux is less sensitive to the prediction\nhorizon. In addition, it is shown that real-time information of current\noccupancy rate is the independent variable with the highest contribution to the\nperformance, although time, traffic flow and weather variables also deliver a\nsignificant contribution. During real-time deployment, the model performs three\ntimes better than the naive model on average. As a result, it can provide\nvaluable information for proactive traffic management as well as mobility\nservice providers.\n", "versions": [{"version": "v1", "created": "Fri, 29 Nov 2019 16:23:41 GMT"}], "update_date": "2019-12-02", "authors_parsed": [["Provoost", "Jesper", ""], ["Wismans", "Luc", ""], ["Van der Drift", "Sander", ""], ["Kamilaris", "Andreas", ""], ["Van Keulen", "Maurice", ""]]}, {"id": "1911.13181", "submitter": "Cheonbok  Park", "authors": "Cheonbok Park, Chunggi Lee, Hyojin Bahng, Yunwon Tae, Kihwan Kim,\n  Seungmin Jin, Sungahn Ko and Jaegul Choo", "title": "ST-GRAT: A Novel Spatio-temporal Graph Attention Network for Accurately\n  Forecasting Dynamically Changing Road Speed", "comments": "to be published in CIKM-2020", "journal-ref": null, "doi": "10.1145/3340531.3411940", "report-no": null, "categories": "cs.LG eess.SP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Predicting road traffic speed is a challenging task due to different types of\nroads, abrupt speed change and spatial dependencies between roads; it requires\nthe modeling of dynamically changing spatial dependencies among roads and\ntemporal patterns over long input sequences. This paper proposes a novel\nspatio-temporal graph attention (ST-GRAT) that effectively captures the\nspatio-temporal dynamics in road networks. The novel aspects of our approach\nmainly include spatial attention, temporal attention, and spatial sentinel\nvectors. The spatial attention takes the graph structure information (e.g.,\ndistance between roads) and dynamically adjusts spatial correlation based on\nroad states. The temporal attention is responsible for capturing traffic speed\nchanges, and the sentinel vectors allow the model to retrieve new features from\nspatially correlated nodes or preserve existing features. The experimental\nresults show that ST-GRAT outperforms existing models, especially in difficult\nconditions where traffic speeds rapidly change (e.g., rush hours). We\nadditionally provide a qualitative study to analyze when and where ST-GRAT\ntended to make accurate predictions during rush-hour times.\n", "versions": [{"version": "v1", "created": "Fri, 29 Nov 2019 16:32:51 GMT"}, {"version": "v2", "created": "Tue, 20 Oct 2020 16:03:52 GMT"}], "update_date": "2020-10-21", "authors_parsed": [["Park", "Cheonbok", ""], ["Lee", "Chunggi", ""], ["Bahng", "Hyojin", ""], ["Tae", "Yunwon", ""], ["Kim", "Kihwan", ""], ["Jin", "Seungmin", ""], ["Ko", "Sungahn", ""], ["Choo", "Jaegul", ""]]}, {"id": "1911.13202", "submitter": "Yuwei Fan", "authors": "Yuwei Fan and Lexing Ying", "title": "Solving Inverse Wave Scattering with Deep Learning", "comments": "17 pages, 11 figures. arXiv admin note: substantial text overlap with\n  arXiv:1911.11636", "journal-ref": null, "doi": null, "report-no": null, "categories": "physics.comp-ph cs.LG cs.NA math.NA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper proposes a neural network approach for solving two classical\nproblems in the two-dimensional inverse wave scattering: far field pattern\nproblem and seismic imaging. The mathematical problem of inverse wave\nscattering is to recover the scatterer field of a medium based on the boundary\nmeasurement of the scattered wave from the medium, which is high-dimensional\nand nonlinear. For the far field pattern problem under the circular\nexperimental setup, a perturbative analysis shows that the forward map can be\napproximated by a vectorized convolution operator in the angular direction.\nMotivated by this and filtered back-projection, we propose an effective neural\nnetwork architecture for the inverse map using the recently introduced BCR-Net\nalong with the standard convolution layers. Analogously for the seismic imaging\nproblem, we propose a similar neural network architecture under the rectangular\ndomain setup with a depth-dependent background velocity. Numerical results\ndemonstrate the efficiency of the proposed neural networks.\n", "versions": [{"version": "v1", "created": "Wed, 27 Nov 2019 15:13:16 GMT"}], "update_date": "2019-12-02", "authors_parsed": [["Fan", "Yuwei", ""], ["Ying", "Lexing", ""]]}, {"id": "1911.13208", "submitter": "Lei Liu", "authors": "Lei Liu", "title": "QoS-Aware Machine Learning-based Multiple Resources Scheduling for\n  Microservices in Cloud Environment", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.LG cs.OS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Microservices have been dominating in the modern cloud environment. To\nimprove cost efficiency, multiple microservices are normally co-located on a\nserver. Thus, the run-time resource scheduling becomes the pivot for QoS\ncontrol. However, the scheduling exploration space enlarges rapidly with the\nincreasing server resources - cores, cache, bandwidth, etc. - and the diversity\nof microservices. Consequently, the existing schedulers might not meet the\nrapid changes in service demands. Besides, we observe that there exist resource\ncliffs in the scheduling space. It not only impacts the exploration efficiency,\nmaking it difficult to converge to the optimal scheduling solution, but also\nresults in severe QoS fluctuation. To overcome these problems, we propose a\nnovel machine learning-based scheduling mechanism called OSML. It uses\nresources and runtime states as the input and employs two MLP models and a\nreinforcement learning model to perform scheduling space exploration. Thus,\nOSML can reach an optimal solution much faster than traditional approaches.\nMore importantly, it can automatically detect the resource cliff and avoid them\nduring exploration. To verify the effectiveness of OSML and obtain a\nwell-generalized model, we collect a dataset containing over 2-billion samples\nfrom 11 typical microservices running on real servers over 9 months. Under the\nsame QoS constraint, experimental results show that OSML outperforms the\nstate-of-the-art work, and achieves around 5 times scheduling speed.\n", "versions": [{"version": "v1", "created": "Tue, 26 Nov 2019 21:05:00 GMT"}, {"version": "v2", "created": "Mon, 2 Dec 2019 08:29:41 GMT"}], "update_date": "2019-12-03", "authors_parsed": [["Liu", "Lei", ""]]}, {"id": "1911.13211", "submitter": "Adeline Fermanian", "authors": "Adeline Fermanian", "title": "Embedding and learning with signatures", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Sequential and temporal data arise in many fields of research, such as\nquantitative finance, medicine, or computer vision. A novel approach for\nsequential learning, called the signature method and rooted in rough path\ntheory, is considered. Its basic principle is to represent multidimensional\npaths by a graded feature set of their iterated integrals, called the\nsignature. This approach relies critically on an embedding principle, which\nconsists in representing discretely sampled data as paths, i.e., functions from\n$[0,1]$ to $\\mathbb{R}^d$. After a survey of machine learning methodologies for\nsignatures, the influence of embeddings on prediction accuracy is investigated\nwith an in-depth study of three recent and challenging datasets. It is shown\nthat a specific embedding, called lead-lag, is systematically the strongest\nperformer across all datasets and algorithms considered. Moreover, an empirical\nstudy reveals that computing signatures over the whole path domain does not\nlead to a loss of local information. It is concluded that, with a good\nembedding, combining signatures with other simple algorithms achieves results\ncompetitive with state-of-the-art, domain-specific approaches.\n", "versions": [{"version": "v1", "created": "Fri, 29 Nov 2019 17:16:49 GMT"}, {"version": "v2", "created": "Thu, 9 Jul 2020 16:13:27 GMT"}, {"version": "v3", "created": "Wed, 9 Dec 2020 11:40:26 GMT"}], "update_date": "2020-12-10", "authors_parsed": [["Fermanian", "Adeline", ""]]}, {"id": "1911.13213", "submitter": "Ali Oskooei", "authors": "Ali Oskooei, Sophie Mai Chau, Jonas Weiss, Arvind Sridhar, Mar\\'ia\n  Rodr\\'iguez Mart\\'inez and Bruno Michel", "title": "DeStress: Deep Learning for Unsupervised Identification of Mental Stress\n  in Firefighters from Heart-rate Variability (HRV) Data", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG eess.SP stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this work we perform a study of various unsupervised methods to identify\nmental stress in firefighter trainees based on unlabeled heart rate variability\ndata. We collect RR interval time series data from nearly 100 firefighter\ntrainees that participated in a drill. We explore and compare three methods in\norder to perform unsupervised stress detection: 1) traditional K-Means\nclustering with engineered time and frequency domain features 2) convolutional\nautoencoders and 3) long short-term memory (LSTM) autoencoders, both trained on\nthe raw RRI measurements combined with DBSCAN clustering and\nK-Nearest-Neighbors classification. We demonstrate that K-Means combined with\nengineered features is unable to capture meaningful structure within the data.\nOn the other hand, convolutional and LSTM autoencoders tend to extract varying\nstructure from the data pointing to different clusters with different sizes of\nclusters. We attempt at identifying the true stressed and normal clusters using\nthe HRV markers of mental stress reported in the literature. We demonstrate\nthat the clusters produced by the convolutional autoencoders consistently and\nsuccessfully stratify stressed versus normal samples, as validated by several\nestablished physiological stress markers such as RMSSD, Max-HR, Mean-HR and\nLF-HF ratio.\n", "versions": [{"version": "v1", "created": "Mon, 18 Nov 2019 21:59:09 GMT"}], "update_date": "2019-12-02", "authors_parsed": [["Oskooei", "Ali", ""], ["Chau", "Sophie Mai", ""], ["Weiss", "Jonas", ""], ["Sridhar", "Arvind", ""], ["Mart\u00ednez", "Mar\u00eda Rodr\u00edguez", ""], ["Michel", "Bruno", ""]]}, {"id": "1911.13214", "submitter": "Lionel Eyraud-Dubois", "authors": "Julien Herrmann (UB, LaBRI, TADAAM), Olivier Beaumont (HiePACS, UB,\n  LaBRI), Lionel Eyraud-Dubois (HiePACS, UB, LaBRI), Julien Hermann, Alexis\n  Joly (ZENITH, LIRMM, UM), Alena Shilova (HiePACS, UB, LaBRI)", "title": "Optimal checkpointing for heterogeneous chains: how to train deep neural\n  networks with limited memory", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.DC cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper introduces a new activation checkpointing method which allows to\nsignificantly decrease memory usage when training Deep Neural Networks with the\nback-propagation algorithm. Similarly to checkpoint-ing techniques coming from\nthe literature on Automatic Differentiation, it consists in dynamically\nselecting the forward activations that are saved during the training phase, and\nthen automatically recomputing missing activations from those previously\nrecorded. We propose an original computation model that combines two types of\nactivation savings: either only storing the layer inputs, or recording the\ncomplete history of operations that produced the outputs (this uses more\nmemory, but requires fewer recomputations in the backward phase), and we\nprovide an algorithm to compute the optimal computation sequence for this\nmodel. This paper also describes a PyTorch implementation that processes the\nentire chain, dealing with any sequential DNN whose internal layers may be\narbitrarily complex and automatically executing it according to the optimal\ncheckpointing strategy computed given a memory limit. Through extensive\nexperiments, we show that our implementation consistently outperforms existing\ncheckpoint-ing approaches for a large class of networks, image sizes and batch\nsizes.\n", "versions": [{"version": "v1", "created": "Wed, 27 Nov 2019 13:05:11 GMT"}], "update_date": "2019-12-02", "authors_parsed": [["Herrmann", "Julien", "", "UB, LaBRI, TADAAM"], ["Beaumont", "Olivier", "", "HiePACS, UB,\n  LaBRI"], ["Eyraud-Dubois", "Lionel", "", "HiePACS, UB, LaBRI"], ["Hermann", "Julien", "", "ZENITH, LIRMM, UM"], ["Joly", "Alexis", "", "ZENITH, LIRMM, UM"], ["Shilova", "Alena", "", "HiePACS, UB, LaBRI"]]}, {"id": "1911.13218", "submitter": "Ahmed Hosny", "authors": "Ahmed Hosny, Michael Schwier, Christoph Berger, Evin P \\\"Ornek, Mehmet\n  Turan, Phi V Tran, Leon Weninger, Fabian Isensee, Klaus H Maier-Hein, Richard\n  McKinley, Michael T Lu, Udo Hoffmann, Bjoern Menze, Spyridon Bakas, Andriy\n  Fedorov, Hugo JWL Aerts", "title": "ModelHub.AI: Dissemination Platform for Deep Learning Models", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG eess.IV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent advances in artificial intelligence research have led to a profusion\nof studies that apply deep learning to problems in image analysis and natural\nlanguage processing among others. Additionally, the availability of open-source\ncomputational frameworks has lowered the barriers to implementing\nstate-of-the-art methods across multiple domains. Albeit leading to major\nperformance breakthroughs in some tasks, effective dissemination of deep\nlearning algorithms remains challenging, inhibiting reproducibility and\nbenchmarking studies, impeding further validation, and ultimately hindering\ntheir effectiveness in the cumulative scientific progress. In developing a\nplatform for sharing research outputs, we present ModelHub.AI\n(www.modelhub.ai), a community-driven container-based software engine and\nplatform for the structured dissemination of deep learning models. For\ncontributors, the engine controls data flow throughout the inference cycle,\nwhile the contributor-facing standard template exposes model-specific functions\nincluding inference, as well as pre- and post-processing. Python and RESTful\nApplication programming interfaces (APIs) enable users to interact with models\nhosted on ModelHub.AI and allows both researchers and developers to utilize\nmodels out-of-the-box. ModelHub.AI is domain-, data-, and framework-agnostic,\ncatering to different workflows and contributors' preferences.\n", "versions": [{"version": "v1", "created": "Tue, 26 Nov 2019 22:48:11 GMT"}], "update_date": "2019-12-02", "authors_parsed": [["Hosny", "Ahmed", ""], ["Schwier", "Michael", ""], ["Berger", "Christoph", ""], ["\u00d6rnek", "Evin P", ""], ["Turan", "Mehmet", ""], ["Tran", "Phi V", ""], ["Weninger", "Leon", ""], ["Isensee", "Fabian", ""], ["Maier-Hein", "Klaus H", ""], ["McKinley", "Richard", ""], ["Lu", "Michael T", ""], ["Hoffmann", "Udo", ""], ["Menze", "Bjoern", ""], ["Bakas", "Spyridon", ""], ["Fedorov", "Andriy", ""], ["Aerts", "Hugo JWL", ""]]}, {"id": "1911.13219", "submitter": "Sema Candemir", "authors": "Sema Candemir, Richard D. White, Mutlu Demirer, Vikash Gupta, Matthew\n  T. Bigelow, Luciano M. Prevedello, Barbaros S. Erdal", "title": "Automated Coronary Artery Atherosclerosis Detection and Weakly\n  Supervised Localization on Coronary CT Angiography with a Deep 3-Dimensional\n  Convolutional Neural Network", "comments": null, "journal-ref": null, "doi": "10.1016/j.compmedimag.2020.101721", "report-no": null, "categories": "eess.IV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a fully automated algorithm based on a deep learning framework\nenabling screening of a coronary computed tomography angiography (CCTA)\nexamination for confident detection of the presence or absence of coronary\nartery atherosclerosis. The system starts with extracting the coronary arteries\nand their branches from CCTA datasets and representing them with multi-planar\nreformatted volumes; pre-processing and augmentation techniques are then\napplied to increase the robustness and generalization ability of the system. A\n3-dimensional convolutional neural network (3D-CNN) is utilized to model\npathological changes (e.g., atherosclerotic plaques) in coronary vessels. The\nsystem learns the discriminatory features between vessels with and without\natherosclerosis. The discriminative features at the final convolutional layer\nare visualized with a saliency map approach to provide visual clues related to\natherosclerosis likelihood and location. We have evaluated the system on a\nreference dataset representing247 patients with atherosclerosis and 246\npatients free of atherosclerosis. With five-fold cross-validation,an Accuracy =\n90.9%, Positive Predictive Value = 58.8%, Sensitivity = 68.9%, Specificity of\n93.6%, and Negative Predictive Value (NPV) = 96.1% are achieved at the\nartery/branch level with threshold 0.5. The average area under the receiver\noperating characteristic curve is 0.91. The system indicates a high NPV, which\nmay be potentially useful for assisting interpreting physicians in excluding\ncoronary atherosclerosis in patients with acute chest pain.\n", "versions": [{"version": "v1", "created": "Tue, 26 Nov 2019 23:23:29 GMT"}, {"version": "v2", "created": "Mon, 9 Mar 2020 20:07:19 GMT"}, {"version": "v3", "created": "Mon, 8 Jun 2020 03:52:22 GMT"}], "update_date": "2020-06-09", "authors_parsed": [["Candemir", "Sema", ""], ["White", "Richard D.", ""], ["Demirer", "Mutlu", ""], ["Gupta", "Vikash", ""], ["Bigelow", "Matthew T.", ""], ["Prevedello", "Luciano M.", ""], ["Erdal", "Barbaros S.", ""]]}, {"id": "1911.13220", "submitter": "Daniel Mas Montserrat", "authors": "Daniel Mas Montserrat, Carlos Bustamante, Alexander Ioannidis", "title": "Class-Conditional VAE-GAN for Local-Ancestry Simulation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.GN cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Local ancestry inference (LAI) allows identification of the ancestry of all\nchromosomal segments in admixed individuals, and it is a critical step in the\nanalysis of human genomes with applications from pharmacogenomics and precision\nmedicine to genome-wide association studies. In recent years, many LAI\ntechniques have been developed in both industry and academic research. However,\nthese methods require large training data sets of human genomic sequences from\nthe ancestries of interest. Such reference data sets are usually limited,\nproprietary, protected by privacy restrictions, or otherwise not accessible to\nthe public. Techniques to generate training samples that resemble real haploid\nsequences from ancestries of interest can be useful tools in such scenarios,\nsince a generalized model can often be shared, but the unique human sample\nsequences cannot. In this work we present a class-conditional VAE-GAN to\ngenerate new human genomic sequences that can be used to train local ancestry\ninference (LAI) algorithms. We evaluate the quality of our generated data by\ncomparing the performance of a state-of-the-art LAI method when trained with\ngenerated versus real data.\n", "versions": [{"version": "v1", "created": "Wed, 27 Nov 2019 18:06:39 GMT"}], "update_date": "2019-12-02", "authors_parsed": [["Montserrat", "Daniel Mas", ""], ["Bustamante", "Carlos", ""], ["Ioannidis", "Alexander", ""]]}, {"id": "1911.13229", "submitter": "Timo Nolle", "authors": "Timo Nolle, Alexander Seeliger, Nils Thoma, Max M\\\"uhlh\\\"auser", "title": "DeepAlign: Alignment-based Process Anomaly Correction using Recurrent\n  Neural Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we propose DeepAlign, a novel approach to multi-perspective\nprocess anomaly correction, based on recurrent neural networks and\nbidirectional beam search. At the core of the DeepAlign algorithm are two\nrecurrent neural networks trained to predict the next event. One is reading\nsequences of process executions from left to right, while the other is reading\nthe sequences from right to left. By combining the predictive capabilities of\nboth neural networks, we show that it is possible to calculate sequence\nalignments, which are used to detect and correct anomalies. DeepAlign utilizes\nthe case-level and event-level attributes to closely model the decisions within\na process. We evaluate the performance of our approach on an elaborate data\ncorpus of 252 realistic synthetic event logs and compare it to three\nstate-of-the-art conformance checking methods. DeepAlign produces better\ncorrections than the rest of the field reaching an overall $F_1$ score of\n$0.9572$ across all datasets, whereas the best comparable state-of-the-art\nmethod reaches $0.6411$.\n", "versions": [{"version": "v1", "created": "Fri, 29 Nov 2019 17:34:52 GMT"}, {"version": "v2", "created": "Mon, 23 Mar 2020 20:48:29 GMT"}], "update_date": "2020-03-25", "authors_parsed": [["Nolle", "Timo", ""], ["Seeliger", "Alexander", ""], ["Thoma", "Nils", ""], ["M\u00fchlh\u00e4user", "Max", ""]]}, {"id": "1911.13232", "submitter": "Limeng Cui", "authors": "Limeng Cui, Siddharth Biswal, Lucas M. Glass, Greg Lever, Jimeng Sun,\n  Cao Xiao", "title": "CONAN: Complementary Pattern Augmentation for Rare Disease Detection", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Rare diseases affect hundreds of millions of people worldwide but are hard to\ndetect since they have extremely low prevalence rates (varying from 1/1,000 to\n1/200,000 patients) and are massively underdiagnosed. How do we reliably detect\nrare diseases with such low prevalence rates? How to further leverage patients\nwith possibly uncertain diagnosis to improve detection? In this paper, we\npropose a Complementary pattern Augmentation (CONAN) framework for rare disease\ndetection. CONAN combines ideas from both adversarial training and max-margin\nclassification. It first learns self-attentive and hierarchical embedding for\npatient pattern characterization. Then, we develop a complementary generative\nadversarial networks (GAN) model to generate candidate positive and negative\nsamples from the uncertain patients by encouraging a max-margin between\nclasses. In addition, CONAN has a disease detector that serves as the\ndiscriminator during the adversarial training for identifying rare diseases. We\nevaluated CONAN on two disease detection tasks. For low prevalence inflammatory\nbowel disease (IBD) detection, CONAN achieved .96 precision recall area under\nthe curve (PR-AUC) and 50.1% relative improvement over best baseline. For rare\ndisease idiopathic pulmonary fibrosis (IPF) detection, CONAN achieves .22\nPR-AUC with 41.3% relative improvement over the best baseline.\n", "versions": [{"version": "v1", "created": "Tue, 26 Nov 2019 22:18:40 GMT"}], "update_date": "2019-12-02", "authors_parsed": [["Cui", "Limeng", ""], ["Biswal", "Siddharth", ""], ["Glass", "Lucas M.", ""], ["Lever", "Greg", ""], ["Sun", "Jimeng", ""], ["Xiao", "Cao", ""]]}, {"id": "1911.13237", "submitter": "Tianyuan Zhang", "authors": "Tianyuan Zhang, Bichen Wu, Xin Wang, Joseph Gonzalez, Kurt Keutzer", "title": "Domain-Aware Dynamic Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV cs.DC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep neural networks with more parameters and FLOPs have higher capacity and\ngeneralize better to diverse domains. But to be deployed on edge devices, the\nmodel's complexity has to be constrained due to limited compute resource. In\nthis work, we propose a method to improve the model capacity without increasing\ninference-time complexity. Our method is based on an assumption of data\nlocality: for an edge device, within a short period of time, the input data to\nthe device are sampled from a single domain with relatively low diversity.\nTherefore, it is possible to utilize a specialized, low-complexity model to\nachieve good performance in that input domain. To leverage this, we propose\nDomain-aware Dynamic Network (DDN), which is a high-capacity dynamic network in\nwhich each layer contains multiple weights. During inference, based on the\ninput domain, DDN dynamically combines those weights into one single weight\nthat specializes in the given domain. This way, DDN can keep the inference-time\ncomplexity low but still maintain a high capacity. Experiments show that\nwithout increasing the parameters, FLOPs, and actual latency, DDN achieves up\nto 2.6\\% higher AP50 than a static network on the BDD100K object-detection\nbenchmark.\n", "versions": [{"version": "v1", "created": "Tue, 26 Nov 2019 12:00:58 GMT"}], "update_date": "2019-12-02", "authors_parsed": [["Zhang", "Tianyuan", ""], ["Wu", "Bichen", ""], ["Wang", "Xin", ""], ["Gonzalez", "Joseph", ""], ["Keutzer", "Kurt", ""]]}, {"id": "1911.13238", "submitter": "Jinle Zhu", "authors": "Jinle Zhu, Qiang Li, Li Hu, Hongyang Chen and Nirwan Ansari", "title": "Machine Learning-based Signal Detection for PMH Signals in\n  Load-modulated MIMO System", "comments": "with example", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IT cs.LG eess.SP math.IT stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Phase Modulation on the Hypersphere (PMH) is a power efficient modulation\nscheme for the \\textit{load-modulated} multiple-input multiple-output (MIMO)\ntransmitters with central power amplifiers (CPA). However, it is difficult to\nobtain the precise channel state information (CSI), and the traditional optimal\nmaximum likelihood (ML) detection scheme incurs high complexity which increases\nexponentially with the number of antennas and the number of bits carried per\nantenna in the PMH modulation. To detect the PMH signals without knowing the\nprior CSI, we first propose a signal detection scheme, termed as the\nhypersphere clustering scheme based on the expectation maximization (EM)\nalgorithm with maximum likelihood detection (HEM-ML). By leveraging machine\nlearning, the proposed detection scheme can accurately obtain information of\nthe channel from a few of the received symbols with little resource cost and\nachieve comparable detection results as that of the optimal ML detector. To\nfurther reduce the computational complexity in the ML detection in HEM-ML, we\nalso propose the second signal detection scheme, termed as the hypersphere\nclustering scheme based on the EM algorithm with KD-tree detection (HEM-KD).\nThe CSI obtained from the EM algorithm is used to build a spatial KD-tree\nreceiver codebook and the signal detection problem can be transformed into a\nnearest neighbor search (NNS) problem. The detection complexity of HEM-KD is\nsignificantly reduced without any detection performance loss as compared to\nHEM-ML. Extensive simulation results verify the effectiveness of our proposed\ndetection schemes.\n", "versions": [{"version": "v1", "created": "Sun, 24 Nov 2019 07:57:15 GMT"}], "update_date": "2019-12-02", "authors_parsed": [["Zhu", "Jinle", ""], ["Li", "Qiang", ""], ["Hu", "Li", ""], ["Chen", "Hongyang", ""], ["Ansari", "Nirwan", ""]]}, {"id": "1911.13248", "submitter": "Chee Wee Leong", "authors": "Chee Wee Leong, Katrina Roohr, Vikram Ramanarayanan, Michelle P.\n  Martin-Raugh, Harrison Kell, Rutuja Ubale, Yao Qian, Zydrune Mladineo, Laura\n  McCulla", "title": "To Trust, or Not to Trust? A Study of Human Bias in Automated Video\n  Interview Assessments", "comments": "ICCV Workshop on Interpreting and Explaining Visual Artificial\n  Intelligence Models, Seoul, South Korea, 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.HC cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Supervised systems require human labels for training. But, are humans\nthemselves always impartial during the annotation process? We examine this\nquestion in the context of automated assessment of human behavioral tasks.\nSpecifically, we investigate whether human ratings themselves can be trusted at\ntheir face value when scoring video-based structured interviews, and whether\nsuch ratings can impact machine learning models that use them as training data.\nWe present preliminary empirical evidence that indicates there might be biases\nin such annotations, most of which are visual in nature.\n", "versions": [{"version": "v1", "created": "Wed, 27 Nov 2019 05:03:04 GMT"}], "update_date": "2019-12-02", "authors_parsed": [["Leong", "Chee Wee", ""], ["Roohr", "Katrina", ""], ["Ramanarayanan", "Vikram", ""], ["Martin-Raugh", "Michelle P.", ""], ["Kell", "Harrison", ""], ["Ubale", "Rutuja", ""], ["Qian", "Yao", ""], ["Mladineo", "Zydrune", ""], ["McCulla", "Laura", ""]]}, {"id": "1911.13250", "submitter": "Anush Sankaran", "authors": "Raunak Sinha, Anush Sankaran, Mayank Vatsa, Richa Singh", "title": "AuthorGAN: Improving GAN Reproducibility using a Modular GAN Framework", "comments": "NeurIPS 2019, MLSys: Workshop on Systems for ML", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.HC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Generative models are becoming increasingly popular in the literature, with\nGenerative Adversarial Networks (GAN) being the most successful variant, yet.\nWith this increasing demand and popularity, it is becoming equally difficult\nand challenging to implement and consume GAN models. A qualitative user survey\nconducted across 47 practitioners show that expert level skill is required to\nuse GAN model for a given task, despite the presence of various open source\nlibraries. In this research, we propose a novel system called AuthorGAN, aiming\nto achieve true democratization of GAN authoring. A highly modularized library\nagnostic representation of GAN model is defined to enable interoperability of\nGAN architecture across different libraries such as Keras, Tensorflow, and\nPyTorch. An intuitive drag-and-drop based visual designer is built using\nnode-red platform to enable custom architecture designing without the need for\nwriting any code. Five different GAN models are implemented as a part of this\nframework and the performance of the different GAN models are shown using the\nbenchmark MNIST dataset.\n", "versions": [{"version": "v1", "created": "Tue, 26 Nov 2019 08:29:03 GMT"}], "update_date": "2019-12-02", "authors_parsed": [["Sinha", "Raunak", ""], ["Sankaran", "Anush", ""], ["Vatsa", "Mayank", ""], ["Singh", "Richa", ""]]}, {"id": "1911.13252", "submitter": "Julia El Zini", "authors": "Julia El Zini, Yara Rizk and Mariette Awad", "title": "An Optimized and Energy-Efficient Parallel Implementation of\n  Non-Iteratively Trained Recurrent Neural Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.DC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recurrent neural networks (RNN) have been successfully applied to various\nsequential decision-making tasks, natural language processing applications, and\ntime-series predictions. Such networks are usually trained through\nback-propagation through time (BPTT) which is prohibitively expensive,\nespecially when the length of the time dependencies and the number of hidden\nneurons increase. To reduce the training time, extreme learning machines (ELMs)\nhave been recently applied to RNN training, reaching a 99\\% speedup on some\napplications. Due to its non-iterative nature, ELM training, when parallelized,\nhas the potential to reach higher speedups than BPTT.\n  In this work, we present \\opt, an optimized parallel RNN training algorithm\nbased on ELM that takes advantage of the GPU shared memory and of parallel QR\nfactorization algorithms to efficiently reach optimal solutions. The\ntheoretical analysis of the proposed algorithm is presented on six RNN\narchitectures, including LSTM and GRU, and its performance is empirically\ntested on ten time-series prediction applications. \\opt~is shown to reach up to\n845 times speedup over its sequential counterpart and to require up to 20x less\ntime to train than parallel BPTT.\n", "versions": [{"version": "v1", "created": "Tue, 26 Nov 2019 11:30:53 GMT"}], "update_date": "2019-12-02", "authors_parsed": [["Zini", "Julia El", ""], ["Rizk", "Yara", ""], ["Awad", "Mariette", ""]]}, {"id": "1911.13254", "submitter": "Alexandre Defossez", "authors": "Alexandre D\\'efossez (FAIR, SIERRA, PSL), Nicolas Usunier (FAIR),\n  L\\'eon Bottou (FAIR), Francis Bach (DI-ENS, PSL, SIERRA)", "title": "Music Source Separation in the Waveform Domain", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SD cs.LG eess.AS stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Source separation for music is the task of isolating contributions, or stems,\nfrom different instruments recorded individually and arranged together to form\na song. Such components include voice, bass, drums and any other\naccompaniments.Contrarily to many audio synthesis tasks where the best\nperformances are achieved by models that directly generate the waveform, the\nstate-of-the-art in source separation for music is to compute masks on the\nmagnitude spectrum. In this paper, we compare two waveform domain\narchitectures. We first adapt Conv-Tasnet, initially developed for speech\nsource separation,to the task of music source separation. While Conv-Tasnet\nbeats many existing spectrogram-domain methods, it suffersfrom significant\nartifacts, as shown by human evaluations. We propose instead Demucs, a novel\nwaveform-to-waveform model,with a U-Net structure and bidirectional\nLSTM.Experiments on the MusDB dataset show that, with proper data augmentation,\nDemucs beats allexisting state-of-the-art architectures, including Conv-Tasnet,\nwith 6.3 SDR on average, (and up to 6.8 with 150 extra training songs, even\nsurpassing the IRM oracle for the bass source).Using recent development in\nmodel quantization, Demucs can be compressed down to 120MBwithout any loss of\naccuracy.We also provide human evaluations, showing that Demucs benefit from a\nlarge advantagein terms of the naturalness of the audio. However, it suffers\nfrom some bleeding,especially between the vocals and other source.\n", "versions": [{"version": "v1", "created": "Wed, 27 Nov 2019 13:50:45 GMT"}, {"version": "v2", "created": "Wed, 28 Apr 2021 14:37:48 GMT"}], "update_date": "2021-04-29", "authors_parsed": [["D\u00e9fossez", "Alexandre", "", "FAIR, SIERRA, PSL"], ["Usunier", "Nicolas", "", "FAIR"], ["Bottou", "L\u00e9on", "", "FAIR"], ["Bach", "Francis", "", "DI-ENS, PSL, SIERRA"]]}, {"id": "1911.13257", "submitter": "Md. Abu Bakr Siddique", "authors": "Mohammad Mahmudur Rahman Khan, Md. Abu Bakr Siddique, Shadman Sakib", "title": "Non-Intrusive Electrical Appliances Monitoring and Classification using\n  K-Nearest Neighbors", "comments": "To be published in the 2nd International Conference on Innovation in\n  Engineering and Technology (ICIET)", "journal-ref": "2019 2nd International Conference on Innovation in Engineering and\n  Technology (ICIET)", "doi": "10.1109/ICIET48527.2019.9290671", "report-no": null, "categories": "cs.LG eess.SP", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Non-Intrusive Load Monitoring (NILM) is the method of detecting an individual\ndevice's energy signal from an aggregated energy consumption signature [1]. As\nexisting energy meters provide very little to no information regarding the\nenergy consumption of individual appliances apart from the aggregated power\nrating, the spotting of individual appliances' energy usages by NILM will not\nonly provide consumers the feedback of appliance-specific energy usage but also\nlead to the changes of their consumption behavior which facilitate energy\nconservation. B Neenan et al. [2] have demonstrated that direct individual\nappliance-specific energy usage signals lead to consumers' behavioral changes\nwhich improves energy efficiency by as much as 15%. Upon disaggregation of an\nenergy signal, the signal needs to be classified according to the appropriate\nappliance. Hence, the goal of this paper is to disaggregate total energy\nconsumption data to individual appliance signature and then classify\nappliance-specific energy loads using a prominent supervised classification\nmethod known as K-Nearest Neighbors (KNN). To perform this operation we have\nused a publicly accessible dataset of power signals from several houses known\nas the REDD dataset. Before applying KNN, data is preprocessed for each device.\nThen KNN is applied to check whether their energy consumption signature is\nseparable or not. KNN is applied with K=5.\n", "versions": [{"version": "v1", "created": "Fri, 22 Nov 2019 06:41:03 GMT"}], "update_date": "2020-12-23", "authors_parsed": [["Khan", "Mohammad Mahmudur Rahman", ""], ["Siddique", "Md. Abu Bakr", ""], ["Sakib", "Shadman", ""]]}, {"id": "1911.13259", "submitter": "Harry Clifford MSci DPhil", "authors": "Geoffroy Dubourg-Felonneau, Yasmeen Kussad, Dominic Kirkham, John W\n  Cassidy, Nirmesh Patel, Harry W Clifford", "title": "Flatsomatic: A Method for Compression of Somatic Mutation Profiles in\n  Cancer", "comments": "Learning Meaningful Representations of Life Workshop at NeurIPS 2019.\n  arXiv admin note: substantial text overlap with arXiv:1911.09008", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.IV cs.LG q-bio.GN stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this study, we present Flatsomatic - a Variational Auto Encoder (VAE)\noptimized to compress somatic mutations that allow for unbiased data\ncompression whilst maintaining the signal. We compared two different neural\nnetwork architectures for the VAE: Multilayer Perceptron (MLP) and\nbidirectional LSTM. The somatic profiles we used to train our models consisted\nof 8,062 Pan-Cancer patients from The Cancer Genome Atlas and 989 cell lines\nfrom the COSMIC cell line project. The profiles for each patient were\nrepresented by the genomic loci where somatic mutations occurred and, to reduce\nsparsity, the locations with a frequency <5 were removed. We enhanced the VAE\nperformance by changing its evidence lower bound, and devised an F1-score based\nloss showing that it helps the VAE learn better than with binary cross-entropy.\nWe also employed beta-VAE to weight the variational regularisation term in the\nloss function and showed the best performance through a preliminary function to\nincrease the weight of the regularisation term with each epoch. We assessed the\nreconstruction ability of the VAE using the micro F1-score metric and showed\nthat our best performing model was a 2-layer deep MLP VAE. Our analysis also\nshowed that the size of the latent space did not have a significant effect on\nthe VAE learning ability. We compared the Flatsomatic embeddings created to a\nlower dimension version of the data from principal component analysis, showing\nsuperior performance of Flatsomatic, and performed K-means clustering on both\ndatasets to draw comparisons to known cancer types of each profile. Finally, we\npresent results that confirm that the Flatsomatic representations of 64\ndimensions maintain the same predictive power as the original 8,298 dimensions\nvector, through prediction of drug response.\n", "versions": [{"version": "v1", "created": "Wed, 27 Nov 2019 18:29:34 GMT"}], "update_date": "2019-12-02", "authors_parsed": [["Dubourg-Felonneau", "Geoffroy", ""], ["Kussad", "Yasmeen", ""], ["Kirkham", "Dominic", ""], ["Cassidy", "John W", ""], ["Patel", "Nirmesh", ""], ["Clifford", "Harry W", ""]]}, {"id": "1911.13263", "submitter": "Ziming Liu", "authors": "Ziming Liu, Xiaobo Liu", "title": "Multi-PCA based Fault Detection Model Combined with Prior knowledge of\n  HVAC", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG eess.SP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The traditional PCA fault detection methods completely depend on the training\ndata. The prior knowledge such as the physical principle of the system has not\nbeen taken into account. In this paper, we propose a new multi-PCA fault\ndetection model combined with prior knowledge. This new model can adapt to the\nvariable operating conditions of the central air conditioning system, and it\ncan detect small deviation faults of sensors and significantly shorten the time\ndelay of detecting drift faults. We also conducted enough ablation experiments\nto demonstrate that our model is more robust and efficient.\n", "versions": [{"version": "v1", "created": "Thu, 21 Nov 2019 16:32:14 GMT"}], "update_date": "2019-12-02", "authors_parsed": [["Liu", "Ziming", ""], ["Liu", "Xiaobo", ""]]}, {"id": "1911.13268", "submitter": "Xue Chen", "authors": "Pranjal Awasthi, Vaggos Chatziafratis, Xue Chen, Aravindan\n  Vijayaraghavan", "title": "Adversarially Robust Low Dimensional Representations", "comments": "68 pages including references", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.LG math.ST stat.ML stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Many machine learning systems are vulnerable to small perturbations made to\nthe input either at test time or at training time. This has received much\nrecent interest on the empirical front due to several applications where\nreliability and security are critical, and the emergence of paradigms such as\nlow precision machine learning. However our theoretical understanding of the\ndesign of adversarially robust algorithms for the above settings is limited.\n  In this work we focus on Principal Component Analysis (PCA), a ubiquitous\nalgorithmic primitive in machine learning. We formulate a natural robust\nvariant of PCA, where the goal is to find a low dimensional subspace to\nrepresent the given data with minimum projection error, and that is in addition\nrobust to small perturbations measured in $\\ell_q$ norm (say $q=\\infty$).\nUnlike PCA which is solvable in polynomial time, our formulation is\ncomputationally intractable to optimize as it captures the well-studied sparse\nPCA objective as a special case. We show various algorithmic and statistical\nresults including:\n  - Polynomial time algorithm that is constant factor competitive in the\nworst-case, with respect to the best subspace both in terms of the projection\nerror and the robustness criterion. We also show that our algorithmic\ntechniques can be made robust to corruptions in the training data as well, in\naddition to yielding representations that are robust at test time.\n  - We prove that our formulation (and algorithms) also enjoy significant\nstatistical benefits in terms of sample complexity over standard PCA on account\nof a ``regularization effect'', that is formalized using the well-studied\nspiked covariance model.\n  - We illustrate the broad applicability of our algorithmic techniques in\naddressing robustness to adversarial perturbations, both at training-time and\ntest-time.\n", "versions": [{"version": "v1", "created": "Fri, 29 Nov 2019 18:06:29 GMT"}, {"version": "v2", "created": "Mon, 28 Dec 2020 03:46:13 GMT"}], "update_date": "2020-12-29", "authors_parsed": [["Awasthi", "Pranjal", ""], ["Chatziafratis", "Vaggos", ""], ["Chen", "Xue", ""], ["Vijayaraghavan", "Aravindan", ""]]}, {"id": "1911.13270", "submitter": "Andrew Gambardella", "authors": "Andrew Gambardella, At{\\i}l{\\i}m G\\\"une\\c{s} Baydin, Philip H. S. Torr", "title": "Transflow Learning: Repurposing Flow Models Without Retraining", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  It is well known that deep generative models have a rich latent space, and\nthat it is possible to smoothly manipulate their outputs by traversing this\nlatent space. Recently, architectures have emerged that allow for more complex\nmanipulations, such as making an image look as though it were from a different\nclass, or painted in a certain style. These methods typically require large\namounts of training in order to learn a single class of manipulations. We\npresent Transflow Learning, a method for transforming a pre-trained generative\nmodel so that its outputs more closely resemble data that we provide\nafterwards. In contrast to previous methods, Transflow Learning does not\nrequire any training at all, and instead warps the probability distribution\nfrom which we sample latent vectors using Bayesian inference. Transflow\nLearning can be used to solve a wide variety of tasks, such as neural style\ntransfer and few-shot classification.\n", "versions": [{"version": "v1", "created": "Fri, 29 Nov 2019 18:14:53 GMT"}, {"version": "v2", "created": "Thu, 5 Dec 2019 14:09:04 GMT"}], "update_date": "2019-12-06", "authors_parsed": [["Gambardella", "Andrew", ""], ["Baydin", "At\u0131l\u0131m G\u00fcne\u015f", ""], ["Torr", "Philip H. S.", ""]]}, {"id": "1911.13271", "submitter": "Kang Yeol Kim", "authors": "Wonwoong Cho, Kangyeol Kim, Eungyeup Kim, Hyunwoo J. Kim, Jaegul Choo", "title": "Unpaired Image Translation via Adaptive Convolution-based Normalization", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG eess.IV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Disentangling content and style information of an image has played an\nimportant role in recent success in image translation. In this setting, how to\ninject given style into an input image containing its own content is an\nimportant issue, but existing methods followed relatively simple approaches,\nleaving room for improvement especially when incorporating significant style\nchanges. In response, we propose an advanced normalization technique based on\nadaptive convolution (AdaCoN), in order to properly impose style information\ninto the content of an input image. In detail, after locally standardizing the\ncontent representation in a channel-wise manner, AdaCoN performs adaptive\nconvolution where the convolution filter weights are dynamically estimated\nusing the encoded style representation. The flexibility of AdaCoN can handle\ncomplicated image translation tasks involving significant style changes. Our\nqualitative and quantitative experiments demonstrate the superiority of our\nproposed method against various existing approaches that inject the style into\nthe content.\n", "versions": [{"version": "v1", "created": "Fri, 29 Nov 2019 18:16:03 GMT"}], "update_date": "2019-12-02", "authors_parsed": [["Cho", "Wonwoong", ""], ["Kim", "Kangyeol", ""], ["Kim", "Eungyeup", ""], ["Kim", "Hyunwoo J.", ""], ["Choo", "Jaegul", ""]]}, {"id": "1911.13280", "submitter": "Kian Kenyon-Dean", "authors": "Edward Newell, Kian Kenyon-Dean, Jackie Chi Kit Cheung", "title": "Deconstructing and reconstructing word embedding algorithms", "comments": "15 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Uncontextualized word embeddings are reliable feature representations of\nwords used to obtain high quality results for various NLP applications. Given\nthe historical success of word embeddings in NLP, we propose a retrospective on\nsome of the most well-known word embedding algorithms. In this work, we\ndeconstruct Word2vec, GloVe, and others, into a common form, unveiling some of\nthe necessary and sufficient conditions required for making performant word\nembeddings. We find that each algorithm: (1) fits vector-covector dot products\nto approximate pointwise mutual information (PMI); and, (2) modulates the loss\ngradient to balance weak and strong signals. We demonstrate that these two\nalgorithmic features are sufficient conditions to construct a novel word\nembedding algorithm, Hilbert-MLE. We find that its embeddings obtain equivalent\nor better performance against other algorithms across 17 intrinsic and\nextrinsic datasets.\n", "versions": [{"version": "v1", "created": "Fri, 29 Nov 2019 18:27:36 GMT"}], "update_date": "2019-12-02", "authors_parsed": [["Newell", "Edward", ""], ["Kenyon-Dean", "Kian", ""], ["Cheung", "Jackie Chi Kit", ""]]}, {"id": "1911.13282", "submitter": "Lucien Hardy", "authors": "Lucien Hardy and Adam G. M. Lewis", "title": "Quantum Computation with Machine-Learning-Controlled Quantum Stuff", "comments": "13 pages, 3 figures, 1 table, 3 algorithms", "journal-ref": null, "doi": null, "report-no": null, "categories": "quant-ph cs.LG physics.comp-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We describe how one may go about performing quantum computation with\narbitrary \"quantum stuff\", as long as it has some basic physical properties.\nImagine a long strip of stuff, equipped with regularly spaced wires to provide\ninput settings and to read off outcomes. After showing how the corresponding\nmap from settings to outcomes can be construed as a quantum circuit, we provide\na machine learning algorithm to tomographically \"learn\" which settings\nimplement the members of a universal gate set. At optimum, arbitrary quantum\ngates, and thus arbitrary quantum programs, can be implemented using the stuff.\n", "versions": [{"version": "v1", "created": "Fri, 29 Nov 2019 18:31:22 GMT"}], "update_date": "2019-12-03", "authors_parsed": [["Hardy", "Lucien", ""], ["Lewis", "Adam G. M.", ""]]}, {"id": "1911.13288", "submitter": "Murat Ozbayoglu", "authors": "Omer Berat Sezer, Mehmet Ugur Gudelek, Ahmet Murat Ozbayoglu", "title": "Financial Time Series Forecasting with Deep Learning : A Systematic\n  Literature Review: 2005-2019", "comments": "13 figures, 13 tables, submitted to Applied Soft Computing", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG q-fin.CP stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Financial time series forecasting is, without a doubt, the top choice of\ncomputational intelligence for finance researchers from both academia and\nfinancial industry due to its broad implementation areas and substantial\nimpact. Machine Learning (ML) researchers came up with various models and a\nvast number of studies have been published accordingly. As such, a significant\namount of surveys exist covering ML for financial time series forecasting\nstudies. Lately, Deep Learning (DL) models started appearing within the field,\nwith results that significantly outperform traditional ML counterparts. Even\nthough there is a growing interest in developing models for financial time\nseries forecasting research, there is a lack of review papers that were solely\nfocused on DL for finance. Hence, our motivation in this paper is to provide a\ncomprehensive literature review on DL studies for financial time series\nforecasting implementations. We not only categorized the studies according to\ntheir intended forecasting implementation areas, such as index, forex,\ncommodity forecasting, but also grouped them based on their DL model choices,\nsuch as Convolutional Neural Networks (CNNs), Deep Belief Networks (DBNs),\nLong-Short Term Memory (LSTM). We also tried to envision the future for the\nfield by highlighting the possible setbacks and opportunities, so the\ninterested researchers can benefit.\n", "versions": [{"version": "v1", "created": "Fri, 29 Nov 2019 18:43:18 GMT"}], "update_date": "2019-12-02", "authors_parsed": [["Sezer", "Omer Berat", ""], ["Gudelek", "Mehmet Ugur", ""], ["Ozbayoglu", "Ahmet Murat", ""]]}, {"id": "1911.13299", "submitter": "Vivek Ramanujan", "authors": "Vivek Ramanujan, Mitchell Wortsman, Aniruddha Kembhavi, Ali Farhadi,\n  Mohammad Rastegari", "title": "What's Hidden in a Randomly Weighted Neural Network?", "comments": "Accepted to CVPR 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Training a neural network is synonymous with learning the values of the\nweights. By contrast, we demonstrate that randomly weighted neural networks\ncontain subnetworks which achieve impressive performance without ever training\nthe weight values. Hidden in a randomly weighted Wide ResNet-50 we show that\nthere is a subnetwork (with random weights) that is smaller than, but matches\nthe performance of a ResNet-34 trained on ImageNet. Not only do these\n\"untrained subnetworks\" exist, but we provide an algorithm to effectively find\nthem. We empirically show that as randomly weighted neural networks with fixed\nweights grow wider and deeper, an \"untrained subnetwork\" approaches a network\nwith learned weights in accuracy. Our code and pretrained models are available\nat https://github.com/allenai/hidden-networks.\n", "versions": [{"version": "v1", "created": "Fri, 29 Nov 2019 18:56:53 GMT"}, {"version": "v2", "created": "Tue, 31 Mar 2020 01:30:39 GMT"}], "update_date": "2020-04-01", "authors_parsed": [["Ramanujan", "Vivek", ""], ["Wortsman", "Mitchell", ""], ["Kembhavi", "Aniruddha", ""], ["Farhadi", "Ali", ""], ["Rastegari", "Mohammad", ""]]}]