[{"id": "1810.00004", "submitter": "Sho Yaida", "authors": "Sho Yaida", "title": "Fluctuation-dissipation relations for stochastic gradient descent", "comments": "15 pages, 6 figures; v2: final version accepted at ICLR 2019, with\n  derivations/assumptions clarified and Adam/AMSGrad experiments added", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The notion of the stationary equilibrium ensemble has played a central role\nin statistical mechanics. In machine learning as well, training serves as\ngeneralized equilibration that drives the probability distribution of model\nparameters toward stationarity. Here, we derive stationary\nfluctuation-dissipation relations that link measurable quantities and\nhyperparameters in the stochastic gradient descent algorithm. These relations\nhold exactly for any stationary state and can in particular be used to\nadaptively set training schedule. We can further use the relations to\nefficiently extract information pertaining to a loss-function landscape such as\nthe magnitudes of its Hessian and anharmonicity. Our claims are empirically\nverified.\n", "versions": [{"version": "v1", "created": "Fri, 28 Sep 2018 18:00:00 GMT"}, {"version": "v2", "created": "Fri, 21 Dec 2018 16:09:27 GMT"}], "update_date": "2018-12-24", "authors_parsed": [["Yaida", "Sho", ""]]}, {"id": "1810.00024", "submitter": "Washington Garcia", "authors": "Washington Garcia, Joseph I. Choi, Suman K. Adari, Somesh Jha, Kevin\n  R. B. Butler", "title": "Explainable Black-Box Attacks Against Model-based Authentication", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Establishing unique identities for both humans and end systems has been an\nactive research problem in the security community, giving rise to innovative\nmachine learning-based authentication techniques. Although such techniques\noffer an automated method to establish identity, they have not been vetted\nagainst sophisticated attacks that target their core machine learning\ntechnique. This paper demonstrates that mimicking the unique signatures\ngenerated by host fingerprinting and biometric authentication systems is\npossible. We expose the ineffectiveness of underlying machine learning\nclassification models by constructing a blind attack based around the query\nsynthesis framework and utilizing Explainable-AI (XAI) techniques. We launch an\nattack in under 130 queries on a state-of-the-art face authentication system,\nand under 100 queries on a host authentication system. We examine how these\nattacks can be defended against and explore their limitations. XAI provides an\neffective means for adversaries to infer decision boundaries and provides a new\nway forward in constructing attacks against systems using machine learning\nmodels for authentication.\n", "versions": [{"version": "v1", "created": "Fri, 28 Sep 2018 18:13:26 GMT"}], "update_date": "2018-10-02", "authors_parsed": [["Garcia", "Washington", ""], ["Choi", "Joseph I.", ""], ["Adari", "Suman K.", ""], ["Jha", "Somesh", ""], ["Butler", "Kevin R. B.", ""]]}, {"id": "1810.00029", "submitter": "Eduardo Laber", "authors": "Eduardo Sany Laber and Lucas Murtinho", "title": "Minimization of Gini impurity via connections with the k-means problem", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.CC cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The Gini impurity is one of the measures used to select attribute in Decision\nTrees/Random Forest construction. In this note we discuss connections between\nthe problem of computing the partition with minimum Weighted Gini impurity and\nthe $k$-means clustering problem. Based on these connections we show that the\ncomputation of the partition with minimum Weighted Gini is a NP-Complete\nproblem and we also discuss how to obtain new algorithms with provable\napproximation for the Gini Minimization problem.\n", "versions": [{"version": "v1", "created": "Fri, 28 Sep 2018 18:26:43 GMT"}], "update_date": "2018-10-02", "authors_parsed": [["Laber", "Eduardo Sany", ""], ["Murtinho", "Lucas", ""]]}, {"id": "1810.00031", "submitter": "Alejandro Noriega-Campero", "authors": "Alejandro Noriega-Campero, Michiel A. Bakker, Bernardo Garcia-Bulle,\n  Alex Pentland", "title": "Active Fairness in Algorithmic Decision Making", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.AI cs.LG stat.AP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Society increasingly relies on machine learning models for automated decision\nmaking. Yet, efficiency gains from automation have come paired with concern for\nalgorithmic discrimination that can systematize inequality. Recent work has\nproposed optimal post-processing methods that randomize classification\ndecisions for a fraction of individuals, in order to achieve fairness measures\nrelated to parity in errors and calibration. These methods, however, have\nraised concern due to the information inefficiency, intra-group unfairness, and\nPareto sub-optimality they entail. The present work proposes an alternative\nactive framework for fair classification, where, in deployment, a\ndecision-maker adaptively acquires information according to the needs of\ndifferent groups or individuals, towards balancing disparities in\nclassification performance. We propose two such methods, where information\ncollection is adapted to group- and individual-level needs respectively. We\nshow on real-world datasets that these can achieve: 1) calibration and single\nerror parity (e.g., equal opportunity); and 2) parity in both false positive\nand false negative rates (i.e., equal odds). Moreover, we show that by\nleveraging their additional degree of freedom, active approaches can\nsubstantially outperform randomization-based classifiers previously considered\noptimal, while avoiding limitations such as intra-group unfairness.\n", "versions": [{"version": "v1", "created": "Fri, 28 Sep 2018 18:28:26 GMT"}, {"version": "v2", "created": "Wed, 7 Nov 2018 16:42:51 GMT"}], "update_date": "2018-11-08", "authors_parsed": [["Noriega-Campero", "Alejandro", ""], ["Bakker", "Michiel A.", ""], ["Garcia-Bulle", "Bernardo", ""], ["Pentland", "Alex", ""]]}, {"id": "1810.00045", "submitter": "Ali Farshchian", "authors": "Ali Farshchian, Juan A. Gallego, Joseph P. Cohen, Yoshua Bengio, Lee\n  E. Miller, Sara A. Solla", "title": "Adversarial Domain Adaptation for Stable Brain-Machine Interfaces", "comments": "14 pages, 6 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG q-bio.NC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Brain-Machine Interfaces (BMIs) have recently emerged as a clinically viable\noption to restore voluntary movements after paralysis. These devices are based\non the ability to extract information about movement intent from neural signals\nrecorded using multi-electrode arrays chronically implanted in the motor\ncortices of the brain. However, the inherent loss and turnover of recorded\nneurons requires repeated recalibrations of the interface, which can\npotentially alter the day-to-day user experience. The resulting need for\ncontinued user adaptation interferes with the natural, subconscious use of the\nBMI. Here, we introduce a new computational approach that decodes movement\nintent from a low-dimensional latent representation of the neural data. We\nimplement various domain adaptation methods to stabilize the interface over\nsignificantly long times. This includes Canonical Correlation Analysis used to\nalign the latent variables across days; this method requires prior\npoint-to-point correspondence of the time series across domains. Alternatively,\nwe match the empirical probability distributions of the latent variables across\ndays through the minimization of their Kullback-Leibler divergence. These two\nmethods provide a significant and comparable improvement in the performance of\nthe interface. However, implementation of an Adversarial Domain Adaptation\nNetwork trained to match the empirical probability distribution of the\nresiduals of the reconstructed neural signals outperforms the two methods based\non latent variables, while requiring remarkably few data points to solve the\ndomain adaptation problem.\n", "versions": [{"version": "v1", "created": "Fri, 28 Sep 2018 18:56:46 GMT"}, {"version": "v2", "created": "Tue, 15 Jan 2019 17:59:26 GMT"}], "update_date": "2019-01-16", "authors_parsed": [["Farshchian", "Ali", ""], ["Gallego", "Juan A.", ""], ["Cohen", "Joseph P.", ""], ["Bengio", "Yoshua", ""], ["Miller", "Lee E.", ""], ["Solla", "Sara A.", ""]]}, {"id": "1810.00068", "submitter": "Roshan Shariff", "authors": "Roshan Shariff and Or Sheffet", "title": "Differentially Private Contextual Linear Bandits", "comments": "21 pages, 5 figures; to appear in NIPS 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the contextual linear bandit problem, a version of the standard\nstochastic multi-armed bandit (MAB) problem where a learner sequentially\nselects actions to maximize a reward which depends also on a user provided\nper-round context. Though the context is chosen arbitrarily or adversarially,\nthe reward is assumed to be a stochastic function of a feature vector that\nencodes the context and selected action. Our goal is to devise private learners\nfor the contextual linear bandit problem.\n  We first show that using the standard definition of differential privacy\nresults in linear regret. So instead, we adopt the notion of joint differential\nprivacy, where we assume that the action chosen on day $t$ is only revealed to\nuser $t$ and thus needn't be kept private that day, only on following days. We\ngive a general scheme converting the classic linear-UCB algorithm into a joint\ndifferentially private algorithm using the tree-based algorithm. We then apply\neither Gaussian noise or Wishart noise to achieve joint-differentially private\nalgorithms and bound the resulting algorithms' regrets. In addition, we give\nthe first lower bound on the additional regret any private algorithms for the\nMAB problem must incur.\n", "versions": [{"version": "v1", "created": "Fri, 28 Sep 2018 20:04:25 GMT"}], "update_date": "2018-10-02", "authors_parsed": [["Shariff", "Roshan", ""], ["Sheffet", "Or", ""]]}, {"id": "1810.00069", "submitter": "Manaar Alam", "authors": "Anirban Chakraborty and Manaar Alam and Vishal Dey and Anupam\n  Chattopadhyay and Debdeep Mukhopadhyay", "title": "Adversarial Attacks and Defences: A Survey", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep learning has emerged as a strong and efficient framework that can be\napplied to a broad spectrum of complex learning problems which were difficult\nto solve using the traditional machine learning techniques in the past. In the\nlast few years, deep learning has advanced radically in such a way that it can\nsurpass human-level performance on a number of tasks. As a consequence, deep\nlearning is being extensively used in most of the recent day-to-day\napplications. However, security of deep learning systems are vulnerable to\ncrafted adversarial examples, which may be imperceptible to the human eye, but\ncan lead the model to misclassify the output. In recent times, different types\nof adversaries based on their threat model leverage these vulnerabilities to\ncompromise a deep learning system where adversaries have high incentives.\nHence, it is extremely important to provide robustness to deep learning\nalgorithms against these adversaries. However, there are only a few strong\ncountermeasures which can be used in all types of attack scenarios to design a\nrobust deep learning system. In this paper, we attempt to provide a detailed\ndiscussion on different types of adversarial attacks with various threat models\nand also elaborate the efficiency and challenges of recent countermeasures\nagainst them.\n", "versions": [{"version": "v1", "created": "Fri, 28 Sep 2018 20:09:04 GMT"}], "update_date": "2018-10-02", "authors_parsed": [["Chakraborty", "Anirban", ""], ["Alam", "Manaar", ""], ["Dey", "Vishal", ""], ["Chattopadhyay", "Anupam", ""], ["Mukhopadhyay", "Debdeep", ""]]}, {"id": "1810.00090", "submitter": "Emanuel Onica", "authors": "Ciprian Amariei, Paul Diac, Emanuel Onica, Valentin Ro\\c{s}ca", "title": "Cell Grid Architecture for Maritime Route Prediction on AIS Data Streams", "comments": null, "journal-ref": "DEBS 2018, Proceedings of the 12th ACM International Conference on\n  Distributed and Event-based Systems, Pages 202-204", "doi": "10.1145/3210284.3220503", "report-no": null, "categories": "cs.AI cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The 2018 Grand Challenge targets the problem of accurate predictions on data\nstreams produced by automatic identification system (AIS) equipment, describing\nnaval traffic. This paper reports the technical details of a custom solution,\nwhich exposes multiple tuning parameters, making its configurability one of the\nmain strengths. Our solution employs a cell grid architecture essentially based\non a sequence of hash tables, specifically built for the targeted use case.\nThis makes it particularly effective in prediction on AIS data, obtaining a\nhigh accuracy and scalable performance results. Moreover, the architecture\nproposed accommodates also an optionally semi-supervised learning process\nbesides the basic supervised mode.\n", "versions": [{"version": "v1", "created": "Fri, 28 Sep 2018 21:42:17 GMT"}], "update_date": "2018-10-02", "authors_parsed": [["Amariei", "Ciprian", ""], ["Diac", "Paul", ""], ["Onica", "Emanuel", ""], ["Ro\u015fca", "Valentin", ""]]}, {"id": "1810.00096", "submitter": "Emanuel Onica", "authors": "Valentin Ro\\c{s}ca, Emanuel Onica, Paul Diac, Ciprian Amariei", "title": "Predicting Destinations by Nearest Neighbor Search on Training Vessel\n  Routes", "comments": null, "journal-ref": "DEBS 2018, Proceedings of the 12th ACM International Conference on\n  Distributed and Event-based Systems, Pages 224-225", "doi": "10.1145/3210284.3220509", "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The DEBS Grand Challenge 2018 is set in the context of maritime route\nprediction. Vessel routes are modeled as streams of Automatic Identification\nSystem (AIS) data points selected from real-world tracking data. The challenge\nrequires to correctly estimate the destination ports and arrival times of\nvessel trips, as early as possible. Our proposed solution partitions the\ntraining vessel routes by reported destination port and uses a nearest neighbor\nsearch to find the training routes that are closer to the query AIS point.\nParticular improvements have been included as well, such as a way to avoid\nchanging the predicted ports frequently within one query route and automating\nthe parameters tuning by the use of a genetic algorithm. This leads to\nsignificant improvements on the final score.\n", "versions": [{"version": "v1", "created": "Fri, 28 Sep 2018 21:52:56 GMT"}], "update_date": "2018-10-02", "authors_parsed": [["Ro\u015fca", "Valentin", ""], ["Onica", "Emanuel", ""], ["Diac", "Paul", ""], ["Amariei", "Ciprian", ""]]}, {"id": "1810.00110", "submitter": "Karl Ridgeway", "authors": "Karl Ridgeway and Michael C. Mozer", "title": "Open-Ended Content-Style Recombination Via Leakage Filtering", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider visual domains in which a class label specifies the content of an\nimage, and class-irrelevant properties that differentiate instances constitute\nthe style. We present a domain-independent method that permits the open-ended\nrecombination of style of one image with the content of another. Open ended\nsimply means that the method generalizes to style and content not present in\nthe training data. The method starts by constructing a content embedding using\nan existing deep metric-learning technique. This trained content encoder is\nincorporated into a variational autoencoder (VAE), paired with a to-be-trained\nstyle encoder. The VAE reconstruction loss alone is inadequate to ensure a\ndecomposition of the latent representation into style and content. Our method\nthus includes an auxiliary loss, leakage filtering, which ensures that no style\ninformation remaining in the content representation is used for reconstruction\nand vice versa. We synthesize novel images by decoding the style representation\nobtained from one image with the content representation from another. Using\nthis method for data-set augmentation, we obtain state-of-the-art performance\non few-shot learning tasks.\n", "versions": [{"version": "v1", "created": "Fri, 28 Sep 2018 22:45:40 GMT"}], "update_date": "2018-10-02", "authors_parsed": [["Ridgeway", "Karl", ""], ["Mozer", "Michael C.", ""]]}, {"id": "1810.00111", "submitter": "Riddhish Bhalodia", "authors": "Riddhish Bhalodia, Shireen Y. Elhabian, Ladislav Kavan, and Ross T.\n  Whitaker", "title": "DeepSSM: A Deep Learning Framework for Statistical Shape Modeling from\n  Raw Images", "comments": "Accepted to ShapeMI MICCAI 2018 (oral): Workshop on Shape in Medical\n  Imaging", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Statistical shape modeling is an important tool to characterize variation in\nanatomical morphology. Typical shapes of interest are measured using 3D imaging\nand a subsequent pipeline of registration, segmentation, and some extraction of\nshape features or projections onto some lower-dimensional shape space, which\nfacilitates subsequent statistical analysis. Many methods for constructing\ncompact shape representations have been proposed, but are often impractical due\nto the sequence of image preprocessing operations, which involve significant\nparameter tuning, manual delineation, and/or quality control by the users. We\npropose DeepSSM: a deep learning approach to extract a low-dimensional shape\nrepresentation directly from 3D images, requiring virtually no parameter tuning\nor user assistance. DeepSSM uses a convolutional neural network (CNN) that\nsimultaneously localizes the biological structure of interest, establishes\ncorrespondences, and projects these points onto a low-dimensional shape\nrepresentation in the form of PCA loadings within a point distribution model.\nTo overcome the challenge of the limited availability of training images, we\npresent a novel data augmentation procedure that uses existing correspondences\non a relatively small set of processed images with shape statistics to create\nplausible training samples with known shape parameters. Hence, we leverage the\nlimited CT/MRI scans (40-50) into thousands of images needed to train a CNN.\nAfter the training, the CNN automatically produces accurate low-dimensional\nshape representations for unseen images. We validate DeepSSM for three\ndifferent applications pertaining to modeling pediatric cranial CT for\ncharacterization of metopic craniosynostosis, femur CT scans identifying\nmorphologic deformities of the hip due to femoroacetabular impingement, and\nleft atrium MRI scans for atrial fibrillation recurrence prediction.\n", "versions": [{"version": "v1", "created": "Fri, 28 Sep 2018 22:53:49 GMT"}], "update_date": "2018-10-02", "authors_parsed": [["Bhalodia", "Riddhish", ""], ["Elhabian", "Shireen Y.", ""], ["Kavan", "Ladislav", ""], ["Whitaker", "Ross T.", ""]]}, {"id": "1810.00113", "submitter": "Hossein Mobahi", "authors": "Yiding Jiang, Dilip Krishnan, Hossein Mobahi, Samy Bengio", "title": "Predicting the Generalization Gap in Deep Networks with Margin\n  Distributions", "comments": "Published in ICLR 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  As shown in recent research, deep neural networks can perfectly fit randomly\nlabeled data, but with very poor accuracy on held out data. This phenomenon\nindicates that loss functions such as cross-entropy are not a reliable\nindicator of generalization. This leads to the crucial question of how\ngeneralization gap should be predicted from the training data and network\nparameters. In this paper, we propose such a measure, and conduct extensive\nempirical studies on how well it can predict the generalization gap. Our\nmeasure is based on the concept of margin distribution, which are the distances\nof training points to the decision boundary. We find that it is necessary to\nuse margin distributions at multiple layers of a deep network. On the CIFAR-10\nand the CIFAR-100 datasets, our proposed measure correlates very strongly with\nthe generalization gap. In addition, we find the following other factors to be\nof importance: normalizing margin values for scale independence, using\ncharacterizations of margin distribution rather than just the margin (closest\ndistance to decision boundary), and working in log space instead of linear\nspace (effectively using a product of margins rather than a sum). Our measure\ncan be easily applied to feedforward deep networks with any architecture and\nmay point towards new training loss functions that could enable better\ngeneralization.\n", "versions": [{"version": "v1", "created": "Fri, 28 Sep 2018 23:23:36 GMT"}, {"version": "v2", "created": "Wed, 12 Jun 2019 07:04:50 GMT"}], "update_date": "2019-06-13", "authors_parsed": [["Jiang", "Yiding", ""], ["Krishnan", "Dilip", ""], ["Mobahi", "Hossein", ""], ["Bengio", "Samy", ""]]}, {"id": "1810.00116", "submitter": "Evgeny Andriyash", "authors": "Evgeny Andriyash, Arash Vahdat and Bill Macready", "title": "Improved Gradient-Based Optimization Over Discrete Distributions", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In many applications we seek to maximize an expectation with respect to a\ndistribution over discrete variables. Estimating gradients of such objectives\nwith respect to the distribution parameters is a challenging problem. We\nanalyze existing solutions including finite-difference (FD) estimators and\ncontinuous relaxation (CR) estimators in terms of bias and variance. We show\nthat the commonly used Gumbel-Softmax estimator is biased and propose a simple\nmethod to reduce it. We also derive a simpler piece-wise linear continuous\nrelaxation that also possesses reduced bias. We demonstrate empirically that\nreduced bias leads to a better performance in variational inference and on\nbinary optimization tasks.\n", "versions": [{"version": "v1", "created": "Sat, 29 Sep 2018 00:07:28 GMT"}, {"version": "v2", "created": "Fri, 28 Dec 2018 00:19:52 GMT"}, {"version": "v3", "created": "Sat, 15 Jun 2019 23:58:32 GMT"}], "update_date": "2019-06-18", "authors_parsed": [["Andriyash", "Evgeny", ""], ["Vahdat", "Arash", ""], ["Macready", "Bill", ""]]}, {"id": "1810.00122", "submitter": "Qianxiao Li", "authors": "Yongqiang Cai, Qianxiao Li, Zuowei Shen", "title": "A Quantitative Analysis of the Effect of Batch Normalization on Gradient\n  Descent", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Despite its empirical success and recent theoretical progress, there\ngenerally lacks a quantitative analysis of the effect of batch normalization\n(BN) on the convergence and stability of gradient descent. In this paper, we\nprovide such an analysis on the simple problem of ordinary least squares (OLS).\nSince precise dynamical properties of gradient descent (GD) is completely known\nfor the OLS problem, it allows us to isolate and compare the additional effects\nof BN. More precisely, we show that unlike GD, gradient descent with BN (BNGD)\nconverges for arbitrary learning rates for the weights, and the convergence\nremains linear under mild conditions. Moreover, we quantify two different\nsources of acceleration of BNGD over GD -- one due to over-parameterization\nwhich improves the effective condition number and another due having a large\nrange of learning rates giving rise to fast descent. These phenomena set BNGD\napart from GD and could account for much of its robustness properties. These\nfindings are confirmed quantitatively by numerical experiments, which further\nshow that many of the uncovered properties of BNGD in OLS are also observed\nqualitatively in more complex supervised learning problems.\n", "versions": [{"version": "v1", "created": "Sat, 29 Sep 2018 00:50:21 GMT"}, {"version": "v2", "created": "Thu, 9 May 2019 03:04:58 GMT"}], "update_date": "2019-05-10", "authors_parsed": [["Cai", "Yongqiang", ""], ["Li", "Qianxiao", ""], ["Shen", "Zuowei", ""]]}, {"id": "1810.00123", "submitter": "Marlos C. Machado", "authors": "Jesse Farebrother, Marlos C. Machado, Michael Bowling", "title": "Generalization and Regularization in DQN", "comments": "Earlier versions of this work were presented both at the NeurIPS'18\n  Deep Reinforcement Learning Workshop and the 4th Multidisciplinary Conference\n  on Reinforcement Learning and Decision Making (RLDM'19)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep reinforcement learning algorithms have shown an impressive ability to\nlearn complex control policies in high-dimensional tasks. However, despite the\never-increasing performance on popular benchmarks, policies learned by deep\nreinforcement learning algorithms can struggle to generalize when evaluated in\nremarkably similar environments. In this paper we propose a protocol to\nevaluate generalization in reinforcement learning through different modes of\nAtari 2600 games. With that protocol we assess the generalization capabilities\nof DQN, one of the most traditional deep reinforcement learning algorithms, and\nwe provide evidence suggesting that DQN overspecializes to the training\nenvironment. We then comprehensively evaluate the impact of dropout and\n$\\ell_2$ regularization, as well as the impact of reusing learned\nrepresentations to improve the generalization capabilities of DQN. Despite\nregularization being largely underutilized in deep reinforcement learning, we\nshow that it can, in fact, help DQN learn more general features. These features\ncan be reused and fine-tuned on similar tasks, considerably improving DQN's\nsample efficiency.\n", "versions": [{"version": "v1", "created": "Sat, 29 Sep 2018 00:52:34 GMT"}, {"version": "v2", "created": "Wed, 30 Jan 2019 17:59:21 GMT"}, {"version": "v3", "created": "Fri, 17 Jan 2020 23:25:22 GMT"}], "update_date": "2020-01-22", "authors_parsed": [["Farebrother", "Jesse", ""], ["Machado", "Marlos C.", ""], ["Bowling", "Michael", ""]]}, {"id": "1810.00128", "submitter": "Jacky Chow", "authors": "Jacky C.K. Chow, Ivan Detchev, Kathleen Ang, Kristian Morin, Karthik\n  Mahadevan, Nicholas Louie", "title": "Robot Vision: Calibration of Wide-Angle Lens Cameras Using Collinearity\n  Condition and K-Nearest Neighbour Regression", "comments": "ISPRS TC I Mid-term Symposium \"Innovative Sensing - From Sensors to\n  Methods and Applications\", 10-12 October 2018. Karlsruhe, Germany", "journal-ref": "The International Archives of the Photogrammetry, Remote Sensing\n  and Spatial Information Sciences, Volume XLII-1, 2018, pp. 93-99", "doi": "10.5194/isprs-archives-XLII-1-93-2018", "report-no": null, "categories": "cs.RO cs.CV cs.LG eess.IV", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Visual perception is regularly used by humans and robots for navigation. By\neither implicitly or explicitly mapping the environment, ego-motion can be\ndetermined and a path of actions can be planned. The process of mapping and\nnavigation are delicately intertwined; therefore, improving one can often lead\nto an improvement of the other. Both processes are sensitive to the interior\norientation parameters of the camera system and mathematically modelling these\nsystematic errors can often improve the precision and accuracy of the overall\nsolution. This paper presents an automatic camera calibration method suitable\nfor any lens, without having prior knowledge about the sensor. Statistical\ninference is performed to map the environment and localize the camera\nsimultaneously. K-nearest neighbour regression is used to model the geometric\ndistortions of the images. A normal-angle lens Nikon camera and wide-angle lens\nGoPro camera were calibrated using the proposed method, as well as the\nconventional bundle adjustment with self-calibration method (for comparison).\nResults showed that the mapping error was reduced from an average of 14.9 mm to\n1.2 mm (i.e. a 92% improvement) and 66.6 mm to 1.5 mm (i.e. a 98% improvement)\nusing the proposed method for the Nikon and GoPro cameras, respectively. In\ncontrast, the conventional approach achieved an average 3D error of 0.9 mm\n(i.e. 94% improvement) and 3.3 mm (i.e. 95% improvement) for the Nikon and\nGoPro cameras, respectively. Thus, the proposed method performs well\nirrespective of the lens/sensor used: it yields results that are comparable to\nthe conventional approach for normal-angle lens cameras, and it has the\nadditional benefit of improving calibration results for wide-angle lens\ncameras.\n", "versions": [{"version": "v1", "created": "Sat, 29 Sep 2018 01:16:27 GMT"}], "update_date": "2018-10-02", "authors_parsed": [["Chow", "Jacky C. K.", ""], ["Detchev", "Ivan", ""], ["Ang", "Kathleen", ""], ["Morin", "Kristian", ""], ["Mahadevan", "Karthik", ""], ["Louie", "Nicholas", ""]]}, {"id": "1810.00138", "submitter": "Jacky Chow", "authors": "Jacky C.K. Chow, Derek Lichti, Kathleen Ang, Gregor Kuntze, Gulshan\n  Sharma, and Janet Ronsky", "title": "Modelling Errors in X-ray Fluoroscopic Imaging Systems Using\n  Photogrammetric Bundle Adjustment With a Data-Driven Self-Calibration\n  Approach", "comments": "ISPRS TC I Mid-term Symposium \"Innovative Sensing - From Sensors to\n  Methods and Applications\", 10-12 October 2018. Karlsruhe, Germany", "journal-ref": "The International Archives of the Photogrammetry, Remote Sensing\n  and Spatial Information Sciences, Volume XLII-1, 2018", "doi": "10.5194/isprs-archives-XLII-1-101-2018", "report-no": null, "categories": "eess.IV cs.CV cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  X-ray imaging is a fundamental tool of routine clinical diagnosis.\nFluoroscopic imaging can further acquire X-ray images at video frame rates,\nthus enabling non-invasive in-vivo motion studies of joints, gastrointestinal\ntract, etc. For both the qualitative and quantitative analysis of static and\ndynamic X-ray images, the data should be free of systematic biases. Besides\nprecise fabrication of hardware, software-based calibration solutions are\ncommonly used for modelling the distortions. In this primary research study, a\nrobust photogrammetric bundle adjustment was used to model the projective\ngeometry of two fluoroscopic X-ray imaging systems. However, instead of relying\non an expert photogrammetrist's knowledge and judgement to decide on a\nparametric model for describing the systematic errors, a self-tuning\ndata-driven approach is used to model the complex non-linear distortion profile\nof the sensors. Quality control from the experiment showed that 0.06 mm to 0.09\nmm 3D reconstruction accuracy was achievable post-calibration using merely 15\nX-ray images. As part of the bundle adjustment, the location of the virtual\nfluoroscopic system relative to the target field can also be spatially resected\nwith an RMSE between 3.10 mm and 3.31 mm.\n", "versions": [{"version": "v1", "created": "Sat, 29 Sep 2018 03:17:15 GMT"}, {"version": "v2", "created": "Fri, 19 Oct 2018 06:11:05 GMT"}], "update_date": "2018-10-22", "authors_parsed": [["Chow", "Jacky C. K.", ""], ["Lichti", "Derek", ""], ["Ang", "Kathleen", ""], ["Kuntze", "Gregor", ""], ["Sharma", "Gulshan", ""], ["Ronsky", "Janet", ""]]}, {"id": "1810.00139", "submitter": "Dahua Gao", "authors": "Guangming Shi, Zhongqiang Zhang, Dahua Gao, Xuemei Xie, Yihao Feng,\n  Xinrui Ma, Danhua Liu", "title": "Knowledge-guided Semantic Computing Network", "comments": "13 pages, 13 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  It is very useful to integrate human knowledge and experience into\ntraditional neural networks for faster learning speed, fewer training samples\nand better interpretability. However, due to the obscured and indescribable\nblack box model of neural networks, it is very difficult to design its\narchitecture, interpret its features and predict its performance. Inspired by\nhuman visual cognition process, we propose a knowledge-guided semantic\ncomputing network which includes two modules: a knowledge-guided semantic tree\nand a data-driven neural network. The semantic tree is pre-defined to describe\nthe spatial structural relations of different semantics, which just corresponds\nto the tree-like description of objects based on human knowledge. The object\nrecognition process through the semantic tree only needs simple forward\ncomputing without training. Besides, to enhance the recognition ability of the\nsemantic tree in aspects of the diversity, randomicity and variability, we use\nthe traditional neural network to aid the semantic tree to learn some\nindescribable features. Only in this case, the training process is needed. The\nexperimental results on MNIST and GTSRB datasets show that compared with the\ntraditional data-driven network, our proposed semantic computing network can\nachieve better performance with fewer training samples and lower computational\ncomplexity. Especially, Our model also has better adversarial robustness than\ntraditional neural network with the help of human knowledge.\n", "versions": [{"version": "v1", "created": "Sat, 29 Sep 2018 03:23:53 GMT"}], "update_date": "2018-10-02", "authors_parsed": [["Shi", "Guangming", ""], ["Zhang", "Zhongqiang", ""], ["Gao", "Dahua", ""], ["Xie", "Xuemei", ""], ["Feng", "Yihao", ""], ["Ma", "Xinrui", ""], ["Liu", "Danhua", ""]]}, {"id": "1810.00143", "submitter": "Zhiming Zhou", "authors": "Zhiming Zhou, Qingru Zhang, Guansong Lu, Hongwei Wang, Weinan Zhang,\n  Yong Yu", "title": "AdaShift: Decorrelation and Convergence of Adaptive Learning Rate\n  Methods", "comments": "Published as a conference paper at ICLR 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Adam is shown not being able to converge to the optimal solution in certain\ncases. Researchers recently propose several algorithms to avoid the issue of\nnon-convergence of Adam, but their efficiency turns out to be unsatisfactory in\npractice. In this paper, we provide new insight into the non-convergence issue\nof Adam as well as other adaptive learning rate methods. We argue that there\nexists an inappropriate correlation between gradient $g_t$ and the\nsecond-moment term $v_t$ in Adam ($t$ is the timestep), which results in that a\nlarge gradient is likely to have small step size while a small gradient may\nhave a large step size. We demonstrate that such biased step sizes are the\nfundamental cause of non-convergence of Adam, and we further prove that\ndecorrelating $v_t$ and $g_t$ will lead to unbiased step size for each\ngradient, thus solving the non-convergence problem of Adam. Finally, we propose\nAdaShift, a novel adaptive learning rate method that decorrelates $v_t$ and\n$g_t$ by temporal shifting, i.e., using temporally shifted gradient $g_{t-n}$\nto calculate $v_t$. The experiment results demonstrate that AdaShift is able to\naddress the non-convergence issue of Adam, while still maintaining a\ncompetitive performance with Adam in terms of both training speed and\ngeneralization.\n", "versions": [{"version": "v1", "created": "Sat, 29 Sep 2018 03:52:20 GMT"}, {"version": "v2", "created": "Fri, 5 Oct 2018 09:02:48 GMT"}, {"version": "v3", "created": "Wed, 9 Jan 2019 13:00:42 GMT"}, {"version": "v4", "created": "Mon, 24 Jun 2019 07:55:24 GMT"}], "update_date": "2019-06-25", "authors_parsed": [["Zhou", "Zhiming", ""], ["Zhang", "Qingru", ""], ["Lu", "Guansong", ""], ["Wang", "Hongwei", ""], ["Zhang", "Weinan", ""], ["Yu", "Yong", ""]]}, {"id": "1810.00144", "submitter": "Fuxun Yu", "authors": "Fuxun Yu, Chenchen Liu, Yanzhi Wang, Liang Zhao, Xiang Chen", "title": "Interpreting Adversarial Robustness: A View from Decision Surface in\n  Input Space", "comments": "15 pages, submitted to ICLR 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  One popular hypothesis of neural network generalization is that the flat\nlocal minima of loss surface in parameter space leads to good generalization.\nHowever, we demonstrate that loss surface in parameter space has no obvious\nrelationship with generalization, especially under adversarial settings.\nThrough visualizing decision surfaces in both parameter space and input space,\nwe instead show that the geometry property of decision surface in input space\ncorrelates well with the adversarial robustness. We then propose an adversarial\nrobustness indicator, which can evaluate a neural network's intrinsic\nrobustness property without testing its accuracy under adversarial attacks.\nGuided by it, we further propose our robust training method. Without involving\nadversarial training, our method could enhance network's intrinsic adversarial\nrobustness against various adversarial attacks.\n", "versions": [{"version": "v1", "created": "Sat, 29 Sep 2018 04:03:08 GMT"}, {"version": "v2", "created": "Fri, 12 Oct 2018 20:54:40 GMT"}], "update_date": "2018-10-16", "authors_parsed": [["Yu", "Fuxun", ""], ["Liu", "Chenchen", ""], ["Wang", "Yanzhi", ""], ["Zhao", "Liang", ""], ["Chen", "Xiang", ""]]}, {"id": "1810.00146", "submitter": "Eric Heiden", "authors": "Hejia Zhang, Eric Heiden, Stefanos Nikolaidis, Joseph J. Lim, Gaurav\n  S. Sukhatme", "title": "Auto-conditioned Recurrent Mixture Density Networks for Learning\n  Generalizable Robot Skills", "comments": "Submitted to IROS 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Personal robots assisting humans must perform complex manipulation tasks that\nare typically difficult to specify in traditional motion planning pipelines,\nwhere multiple objectives must be met and the high-level context be taken into\nconsideration. Learning from demonstration (LfD) provides a promising way to\nlearn these kind of complex manipulation skills even from non-technical users.\nHowever, it is challenging for existing LfD methods to efficiently learn skills\nthat can generalize to task specifications that are not covered by\ndemonstrations. In this paper, we introduce a state transition model (STM) that\ngenerates joint-space trajectories by imitating motions from expert behavior.\nGiven a few demonstrations, we show in real robot experiments that the learned\nSTM can quickly generalize to unseen tasks and synthesize motions having longer\ntime horizons than the expert trajectories. Compared to conventional motion\nplanners, our approach enables the robot to accomplish complex behaviors from\nhigh-level instructions without laborious hand-engineering of planning\nobjectives, while being able to adapt to changing goals during the skill\nexecution. In conjunction with a trajectory optimizer, our STM can construct a\nhigh-quality skeleton of a trajectory that can be further improved in\nsmoothness and precision. In combination with a learned inverse dynamics model,\nwe additionally present results where the STM is used as a high-level planner.\n  A video of our experiments is available at https://youtu.be/85DX9Ojq-90\n", "versions": [{"version": "v1", "created": "Sat, 29 Sep 2018 04:23:16 GMT"}, {"version": "v2", "created": "Tue, 2 Oct 2018 00:27:45 GMT"}, {"version": "v3", "created": "Wed, 20 Mar 2019 01:04:12 GMT"}], "update_date": "2019-03-21", "authors_parsed": [["Zhang", "Hejia", ""], ["Heiden", "Eric", ""], ["Nikolaidis", "Stefanos", ""], ["Lim", "Joseph J.", ""], ["Sukhatme", "Gaurav S.", ""]]}, {"id": "1810.00147", "submitter": "Tianmin Shu", "authors": "Tianmin Shu, Yuandong Tian", "title": "M$^3$RL: Mind-aware Multi-agent Management Reinforcement Learning", "comments": "ICLR 2019; 18 pages, 12 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG cs.MA stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Most of the prior work on multi-agent reinforcement learning (MARL) achieves\noptimal collaboration by directly controlling the agents to maximize a common\nreward. In this paper, we aim to address this from a different angle. In\nparticular, we consider scenarios where there are self-interested agents (i.e.,\nworker agents) which have their own minds (preferences, intentions, skills,\netc.) and can not be dictated to perform tasks they do not wish to do. For\nachieving optimal coordination among these agents, we train a super agent\n(i.e., the manager) to manage them by first inferring their minds based on both\ncurrent and past observations and then initiating contracts to assign suitable\ntasks to workers and promise to reward them with corresponding bonuses so that\nthey will agree to work together. The objective of the manager is maximizing\nthe overall productivity as well as minimizing payments made to the workers for\nad-hoc worker teaming. To train the manager, we propose Mind-aware Multi-agent\nManagement Reinforcement Learning (M^3RL), which consists of agent modeling and\npolicy learning. We have evaluated our approach in two environments, Resource\nCollection and Crafting, to simulate multi-agent management problems with\nvarious task settings and multiple designs for the worker agents. The\nexperimental results have validated the effectiveness of our approach in\nmodeling worker agents' minds online, and in achieving optimal ad-hoc teaming\nwith good generalization and fast adaptation.\n", "versions": [{"version": "v1", "created": "Sat, 29 Sep 2018 04:33:15 GMT"}, {"version": "v2", "created": "Fri, 22 Feb 2019 21:56:03 GMT"}, {"version": "v3", "created": "Thu, 7 Mar 2019 06:02:40 GMT"}], "update_date": "2019-03-08", "authors_parsed": [["Shu", "Tianmin", ""], ["Tian", "Yuandong", ""]]}, {"id": "1810.00150", "submitter": "Cheolhyoung Lee", "authors": "Cheolhyoung Lee, Kyunghyun Cho, Wanmo Kang", "title": "Directional Analysis of Stochastic Gradient Descent via von Mises-Fisher\n  Distributions in Deep learning", "comments": "11 pages (+15 pages for references and supplemental material, total\n  26 pages), 12 figures, a single table", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Although stochastic gradient descent (SGD) is a driving force behind the\nrecent success of deep learning, our understanding of its dynamics in a\nhigh-dimensional parameter space is limited. In recent years, some researchers\nhave used the stochasticity of minibatch gradients, or the signal-to-noise\nratio, to better characterize the learning dynamics of SGD. Inspired from these\nwork, we here analyze SGD from a geometrical perspective by inspecting the\nstochasticity of the norms and directions of minibatch gradients. We propose a\nmodel of the directional concentration for minibatch gradients through von\nMises-Fisher (VMF) distribution, and show that the directional uniformity of\nminibatch gradients increases over the course of SGD. We empirically verify our\nresult using deep convolutional networks and observe a higher correlation\nbetween the gradient stochasticity and the proposed directional uniformity than\nthat against the gradient norm stochasticity, suggesting that the directional\nstatistics of minibatch gradients is a major factor behind SGD.\n", "versions": [{"version": "v1", "created": "Sat, 29 Sep 2018 05:16:43 GMT"}, {"version": "v2", "created": "Wed, 28 Nov 2018 05:42:33 GMT"}], "update_date": "2018-11-29", "authors_parsed": [["Lee", "Cheolhyoung", ""], ["Cho", "Kyunghyun", ""], ["Kang", "Wanmo", ""]]}, {"id": "1810.00162", "submitter": "Evgenii Zheltonozhskii", "authors": "Chaim Baskin, Natan Liss, Yoav Chai, Evgenii Zheltonozhskii, Eli\n  Schwartz, Raja Giryes, Avi Mendelson, Alexander M. Bronstein", "title": "NICE: Noise Injection and Clamping Estimation for Neural Network\n  Quantization", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Convolutional Neural Networks (CNN) are very popular in many fields including\ncomputer vision, speech recognition, natural language processing, to name a\nfew. Though deep learning leads to groundbreaking performance in these domains,\nthe networks used are very demanding computationally and are far from real-time\neven on a GPU, which is not power efficient and therefore does not suit low\npower systems such as mobile devices. To overcome this challenge, some\nsolutions have been proposed for quantizing the weights and activations of\nthese networks, which accelerate the runtime significantly. Yet, this\nacceleration comes at the cost of a larger error. The \\uniqname method proposed\nin this work trains quantized neural networks by noise injection and a learned\nclamping, which improve the accuracy. This leads to state-of-the-art results on\nvarious regression and classification tasks, e.g., ImageNet classification with\narchitectures such as ResNet-18/34/50 with low as 3-bit weights and\nactivations. We implement the proposed solution on an FPGA to demonstrate its\napplicability for low power real-time applications. The implementation of the\npaper is available at https://github.com/Lancer555/NICE\n", "versions": [{"version": "v1", "created": "Sat, 29 Sep 2018 06:56:33 GMT"}, {"version": "v2", "created": "Tue, 2 Oct 2018 20:07:32 GMT"}], "update_date": "2018-10-04", "authors_parsed": [["Baskin", "Chaim", ""], ["Liss", "Natan", ""], ["Chai", "Yoav", ""], ["Zheltonozhskii", "Evgenii", ""], ["Schwartz", "Eli", ""], ["Giryes", "Raja", ""], ["Mendelson", "Avi", ""], ["Bronstein", "Alexander M.", ""]]}, {"id": "1810.00208", "submitter": "Ilia Shumailov", "authors": "Yiren Zhao, Ilia Shumailov, Robert Mullins, Ross Anderson", "title": "To compress or not to compress: Understanding the Interactions between\n  Adversarial Attacks and Neural Network Compression", "comments": "Presented at SysML 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.LG", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  As deep neural networks (DNNs) become widely used, pruned and quantised\nmodels are becoming ubiquitous on edge devices; such compressed DNNs are\npopular for lowering computational requirements. Meanwhile, recent studies show\nthat adversarial samples can be effective at making DNNs misclassify. We,\ntherefore, investigate the extent to which adversarial samples are transferable\nbetween uncompressed and compressed DNNs. We find that adversarial samples\nremain transferable for both pruned and quantised models. For pruning, the\nadversarial samples generated from heavily pruned models remain effective on\nuncompressed models. For quantisation, we find the transferability of\nadversarial samples is highly sensitive to integer precision.\n", "versions": [{"version": "v1", "created": "Sat, 29 Sep 2018 13:08:34 GMT"}, {"version": "v2", "created": "Thu, 16 Apr 2020 17:27:31 GMT"}], "update_date": "2020-04-17", "authors_parsed": [["Zhao", "Yiren", ""], ["Shumailov", "Ilia", ""], ["Mullins", "Robert", ""], ["Anderson", "Ross", ""]]}, {"id": "1810.00223", "submitter": "Shogo Seki", "authors": "Shogo Seki, Hirokazu Kameoka, Li Li, Tomoki Toda, Kazuya Takeda", "title": "Generalized Multichannel Variational Autoencoder for Underdetermined\n  Source Separation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG cs.SD eess.AS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper deals with a multichannel audio source separation problem under\nunderdetermined conditions. Multichannel Non-negative Matrix Factorization\n(MNMF) is one of powerful approaches, which adopts the NMF concept for source\npower spectrogram modeling. This concept is also employed in Independent\nLow-Rank Matrix Analysis (ILRMA), a special class of the MNMF framework\nformulated under determined conditions. While these methods work reasonably\nwell for particular types of sound sources, one limitation is that they can\nfail to work for sources with spectrograms that do not comply with the NMF\nmodel. To address this limitation, an extension of ILRMA called the\nMultichannel Variational Autoencoder (MVAE) method was recently proposed, where\na Conditional VAE (CVAE) is used instead of the NMF model for source power\nspectrogram modeling. This approach has shown to perform impressively in\ndetermined source separation tasks thanks to the representation power of DNNs.\nWhile the original MVAE method was formulated under determined mixing\nconditions, this paper generalizes it so that it can also deal with\nunderdetermined cases. We call the proposed framework the Generalized MVAE\n(GMVAE). The proposed method was evaluated on a underdetermined source\nseparation task of separating out three sources from two microphone inputs.\nExperimental results revealed that the GMVAE method achieved better performance\nthan the MNMF method.\n", "versions": [{"version": "v1", "created": "Sat, 29 Sep 2018 15:40:11 GMT"}], "update_date": "2018-10-02", "authors_parsed": [["Seki", "Shogo", ""], ["Kameoka", "Hirokazu", ""], ["Li", "Li", ""], ["Toda", "Tomoki", ""], ["Takeda", "Kazuya", ""]]}, {"id": "1810.00240", "submitter": "Nicolas Pr\\\"ollochs", "authors": "Nicolas Pr\\\"ollochs, Stefan Feuerriegel", "title": "Reinforcement Learning in R", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Reinforcement learning refers to a group of methods from artificial\nintelligence where an agent performs learning through trial and error. It\ndiffers from supervised learning, since reinforcement learning requires no\nexplicit labels; instead, the agent interacts continuously with its\nenvironment. That is, the agent starts in a specific state and then performs an\naction, based on which it transitions to a new state and, depending on the\noutcome, receives a reward. Different strategies (e.g. Q-learning) have been\nproposed to maximize the overall reward, resulting in a so-called policy, which\ndefines the best possible action in each state. Mathematically, this process\ncan be formalized by a Markov decision process and it has been implemented by\npackages in R; however, there is currently no package available for\nreinforcement learning. As a remedy, this paper demonstrates how to perform\nreinforcement learning in R and, for this purpose, introduces the\nReinforcementLearning package. The package provides a remarkably flexible\nframework and is easily applied to a wide range of different problems. We\ndemonstrate its use by drawing upon common examples from the literature (e.g.\nfinding optimal game strategies).\n", "versions": [{"version": "v1", "created": "Sat, 29 Sep 2018 17:25:40 GMT"}], "update_date": "2018-10-02", "authors_parsed": [["Pr\u00f6llochs", "Nicolas", ""], ["Feuerriegel", "Stefan", ""]]}, {"id": "1810.00299", "submitter": "Simon Alford", "authors": "Simon Alford, Ryan Robinett, Lauren Milechin, Jeremy Kepner", "title": "Training Behavior of Sparse Neural Network Topologies", "comments": "6 pages. Presented at the 2019 IEEE High Performance Extreme\n  Computing (HPEC) Conference. Received \"Best Paper\" award", "journal-ref": null, "doi": "10.1109/HPEC.2019.8916385", "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Improvements in the performance of deep neural networks have often come\nthrough the design of larger and more complex networks. As a result, fast\nmemory is a significant limiting factor in our ability to improve network\nperformance. One approach to overcoming this limit is the design of sparse\nneural networks, which can be both very large and efficiently trained. In this\npaper we experiment training on sparse neural network topologies. We test\npruning-based topologies, which are derived from an initially dense network\nwhose connections are pruned, as well as RadiX-Nets, a class of network\ntopologies with proven connectivity and sparsity properties. Results show that\nsparse networks obtain accuracies comparable to dense networks, but extreme\nlevels of sparsity cause instability in training, which merits further study.\n", "versions": [{"version": "v1", "created": "Sun, 30 Sep 2018 02:41:00 GMT"}, {"version": "v2", "created": "Mon, 23 Dec 2019 22:29:31 GMT"}], "update_date": "2019-12-25", "authors_parsed": [["Alford", "Simon", ""], ["Robinett", "Ryan", ""], ["Milechin", "Lauren", ""], ["Kepner", "Jeremy", ""]]}, {"id": "1810.00303", "submitter": "Fred Roosta", "authors": "Fred Roosta, Yang Liu, Peng Xu, Michael W. Mahoney", "title": "Newton-MR: Newton's Method Without Smoothness or Convexity", "comments": "57 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.OC cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Establishing global convergence of Newton-CG has long been limited to making\nstrong convexity assumptions. Hence, many Newton-type variants have been\nproposed which aim at extending Newton-CG beyond strongly convex problems.\nHowever, the analysis of almost all these non-convex methods commonly relies on\nthe Lipschitz continuity assumptions of the gradient and Hessian. Furthermore,\nthe sub-problems of many of these methods are themselves non-trivial\noptimization problems.\n  Here, we show that two simple modifications of Newton-CG result in an\nalgorithm, called Newton-MR, which offers a diverse range of algorithmic and\ntheoretical advantages. Newton-MR can be applied, beyond the traditional convex\nsettings, to invex problems. Sub-problems of Newton-MR are simple ordinary\nleast squares. Furthermore, by introducing a weaker notion of joint regularity\nof Hessian and gradient, we establish the global convergence of Newton-MR even\nin the absence of the usual smoothness assumptions. We also obtain Newton-MR's\nlocal convergence guarantee that generalizes that of Newton-CG. Specifically,\nunlike the local convergence analysis of Newton-CG, which relies on the notion\nof isolated minimum, our analysis amounts to local convergence to the set of\nminima.\n", "versions": [{"version": "v1", "created": "Sun, 30 Sep 2018 03:07:38 GMT"}, {"version": "v2", "created": "Tue, 7 May 2019 03:28:14 GMT"}], "update_date": "2019-05-08", "authors_parsed": [["Roosta", "Fred", ""], ["Liu", "Yang", ""], ["Xu", "Peng", ""], ["Mahoney", "Michael W.", ""]]}, {"id": "1810.00307", "submitter": "Sangkug Lym", "authors": "Sangkug Lym, Armand Behroozi, Wei Wen, Ge Li, Yongkee Kwon, Mattan\n  Erez", "title": "Mini-batch Serialization: CNN Training with Inter-layer Data Reuse", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AR", "license": "http://creativecommons.org/licenses/by-sa/4.0/", "abstract": "  Training convolutional neural networks (CNNs) requires intense computations\nand high memory bandwidth. We find that bandwidth today is over-provisioned\nbecause most memory accesses in CNN training can be eliminated by rearranging\ncomputation to better utilize on-chip buffers and avoid traffic resulting from\nlarge per-layer memory footprints. We introduce the MBS CNN training approach\nthat significantly reduces memory traffic by partially serializing mini-batch\nprocessing across groups of layers. This optimizes reuse within on-chip buffers\nand balances both intra-layer and inter-layer reuse. We also introduce the\nWaveCore CNN training accelerator that effectively trains CNNs in the MBS\napproach with high functional-unit utilization. Combined, WaveCore and MBS\nreduce DRAM traffic by 75%, improve performance by 53%, and save 26% system\nenergy for modern deep CNN training compared to conventional training\nmechanisms and accelerators.\n", "versions": [{"version": "v1", "created": "Sun, 30 Sep 2018 03:48:56 GMT"}, {"version": "v2", "created": "Fri, 16 Nov 2018 02:10:17 GMT"}, {"version": "v3", "created": "Mon, 15 Apr 2019 04:15:49 GMT"}, {"version": "v4", "created": "Sat, 4 May 2019 04:31:18 GMT"}], "update_date": "2019-05-07", "authors_parsed": [["Lym", "Sangkug", ""], ["Behroozi", "Armand", ""], ["Wen", "Wei", ""], ["Li", "Ge", ""], ["Kwon", "Yongkee", ""], ["Erez", "Mattan", ""]]}, {"id": "1810.00319", "submitter": "Seong Joon Oh", "authors": "Seong Joon Oh, Kevin Murphy, Jiyan Pan, Joseph Roth, Florian Schroff,\n  Andrew Gallagher", "title": "Modeling Uncertainty with Hedged Instance Embedding", "comments": "15 pages, 11 figures, updated version of ICLR'19", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Instance embeddings are an efficient and versatile image representation that\nfacilitates applications like recognition, verification, retrieval, and\nclustering. Many metric learning methods represent the input as a single point\nin the embedding space. Often the distance between points is used as a proxy\nfor match confidence. However, this can fail to represent uncertainty arising\nwhen the input is ambiguous, e.g., due to occlusion or blurriness. This work\naddresses this issue and explicitly models the uncertainty by hedging the\nlocation of each input in the embedding space. We introduce the hedged instance\nembedding (HIB) in which embeddings are modeled as random variables and the\nmodel is trained under the variational information bottleneck principle.\nEmpirical results on our new N-digit MNIST dataset show that our method leads\nto the desired behavior of hedging its bets across the embedding space upon\nencountering ambiguous inputs. This results in improved performance for image\nmatching and classification tasks, more structure in the learned embedding\nspace, and an ability to compute a per-exemplar uncertainty measure that is\ncorrelated with downstream performance.\n", "versions": [{"version": "v1", "created": "Sun, 30 Sep 2018 04:51:27 GMT"}, {"version": "v2", "created": "Thu, 11 Oct 2018 17:26:22 GMT"}, {"version": "v3", "created": "Fri, 19 Oct 2018 15:41:25 GMT"}, {"version": "v4", "created": "Fri, 21 Dec 2018 23:46:55 GMT"}, {"version": "v5", "created": "Wed, 7 Aug 2019 06:32:15 GMT"}, {"version": "v6", "created": "Tue, 27 Aug 2019 00:31:41 GMT"}], "update_date": "2019-08-28", "authors_parsed": [["Oh", "Seong Joon", ""], ["Murphy", "Kevin", ""], ["Pan", "Jiyan", ""], ["Roth", "Joseph", ""], ["Schroff", "Florian", ""], ["Gallagher", "Andrew", ""]]}, {"id": "1810.00322", "submitter": "Micha Feigin-Almon", "authors": "Micha Feigin and Daniel Freedman and Brian W. Anthony", "title": "A Deep Learning Framework for Single-Sided Sound Speed Inversion in\n  Medical Ultrasound", "comments": null, "journal-ref": "IEEE Trans Biomed Eng. 2019 Jul 25", "doi": "10.1109/TBME.2019.2931195", "report-no": null, "categories": "cs.LG eess.SP q-bio.TO stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Objective: Ultrasound elastography is gaining traction as an accessible and\nuseful diagnostic tool for such things as cancer detection and differentiation\nand thyroid disease diagnostics. Unfortunately, state of the art shear wave\nimaging techniques, essential to promote this goal, are limited to high-end\nultrasound hardware due to high power requirements; are extremely sensitive to\npatient and sonographer motion, and generally, suffer from low frame rates.\nMotivated by research and theory showing that longitudinal wave sound speed\ncarries similar diagnostic abilities to shear wave imaging, we present an\nalternative approach using single sided pressure-wave sound speed measurements\nfrom channel data.\n  Methods: In this paper, we present a single-sided sound speed inversion\nsolution using a fully convolutional deep neural network. We use simulations\nfor training, allowing the generation of limitless ground truth data.\n  Results: We show that it is possible to invert for longitudinal sound speed\nin soft tissue at high frame rates. We validate the method on simulated data.\nWe present highly encouraging results on limited real data.\n  Conclusion: Sound speed inversion on channel data has significant potential,\nmade possible in real time with deep learning technologies.\n  Significance: Specialized shear wave ultrasound systems remain inaccessible\nin many locations. longitudinal sound speed and deep learning technologies\nenable an alternative approach to diagnosis based on tissue elasticity. High\nframe rates are possible.\n", "versions": [{"version": "v1", "created": "Sun, 30 Sep 2018 06:07:00 GMT"}, {"version": "v2", "created": "Fri, 2 Nov 2018 21:26:04 GMT"}, {"version": "v3", "created": "Mon, 10 Dec 2018 07:42:12 GMT"}, {"version": "v4", "created": "Tue, 30 Jul 2019 15:05:05 GMT"}], "update_date": "2019-07-31", "authors_parsed": [["Feigin", "Micha", ""], ["Freedman", "Daniel", ""], ["Anthony", "Brian W.", ""]]}, {"id": "1810.00337", "submitter": "Xinyun Chen", "authors": "Xinyun Chen, Yuandong Tian", "title": "Learning to Perform Local Rewriting for Combinatorial Optimization", "comments": "Published in NeurIPS 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Search-based methods for hard combinatorial optimization are often guided by\nheuristics. Tuning heuristics in various conditions and situations is often\ntime-consuming. In this paper, we propose NeuRewriter that learns a policy to\npick heuristics and rewrite the local components of the current solution to\niteratively improve it until convergence. The policy factorizes into a\nregion-picking and a rule-picking component, each parameterized by a neural\nnetwork trained with actor-critic methods in reinforcement learning.\nNeuRewriter captures the general structure of combinatorial problems and shows\nstrong performance in three versatile tasks: expression simplification, online\njob scheduling and vehicle routing problems. NeuRewriter outperforms the\nexpression simplification component in Z3; outperforms DeepRM and Google\nOR-tools in online job scheduling; and outperforms recent neural baselines and\nGoogle OR-tools in vehicle routing problems.\n", "versions": [{"version": "v1", "created": "Sun, 30 Sep 2018 08:12:43 GMT"}, {"version": "v2", "created": "Tue, 2 Oct 2018 06:34:28 GMT"}, {"version": "v3", "created": "Thu, 31 Jan 2019 15:09:06 GMT"}, {"version": "v4", "created": "Fri, 24 May 2019 10:10:15 GMT"}, {"version": "v5", "created": "Wed, 30 Oct 2019 03:10:40 GMT"}], "update_date": "2019-10-31", "authors_parsed": [["Chen", "Xinyun", ""], ["Tian", "Yuandong", ""]]}, {"id": "1810.00361", "submitter": "Manuel Fritsche", "authors": "Gino Brunner, Manuel Fritsche, Oliver Richter, Roger Wattenhofer", "title": "Using State Predictions for Value Regularization in Curiosity Driven\n  Deep Reinforcement Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Learning in sparse reward settings remains a challenge in Reinforcement\nLearning, which is often addressed by using intrinsic rewards. One promising\nstrategy is inspired by human curiosity, requiring the agent to learn to\npredict the future. In this paper a curiosity-driven agent is extended to use\nthese predictions directly for training. To achieve this, the agent predicts\nthe value function of the next state at any point in time. Subsequently, the\nconsistency of this prediction with the current value function is measured,\nwhich is then used as a regularization term in the loss function of the\nalgorithm. Experiments were made on grid-world environments as well as on a 3D\nnavigation task, both with sparse rewards. In the first case the extended agent\nis able to learn significantly faster than the baselines.\n", "versions": [{"version": "v1", "created": "Sun, 30 Sep 2018 11:29:55 GMT"}], "update_date": "2018-10-02", "authors_parsed": [["Brunner", "Gino", ""], ["Fritsche", "Manuel", ""], ["Richter", "Oliver", ""], ["Wattenhofer", "Roger", ""]]}, {"id": "1810.00363", "submitter": "Alberto Bietti", "authors": "Alberto Bietti, Gr\\'egoire Mialon, Dexiong Chen, Julien Mairal", "title": "A Kernel Perspective for Regularizing Deep Neural Networks", "comments": "ICML", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a new point of view for regularizing deep neural networks by using\nthe norm of a reproducing kernel Hilbert space (RKHS). Even though this norm\ncannot be computed, it admits upper and lower approximations leading to various\npractical strategies. Specifically, this perspective (i) provides a common\numbrella for many existing regularization principles, including spectral norm\nand gradient penalties, or adversarial training, (ii) leads to new effective\nregularization penalties, and (iii) suggests hybrid strategies combining lower\nand upper bounds to get better approximations of the RKHS norm. We\nexperimentally show this approach to be effective when learning on small\ndatasets, or to obtain adversarially robust models.\n", "versions": [{"version": "v1", "created": "Sun, 30 Sep 2018 11:40:59 GMT"}, {"version": "v2", "created": "Tue, 27 Nov 2018 17:16:49 GMT"}, {"version": "v3", "created": "Thu, 24 Jan 2019 18:01:25 GMT"}, {"version": "v4", "created": "Mon, 13 May 2019 18:04:46 GMT"}], "update_date": "2019-05-15", "authors_parsed": [["Bietti", "Alberto", ""], ["Mialon", "Gr\u00e9goire", ""], ["Chen", "Dexiong", ""], ["Mairal", "Julien", ""]]}, {"id": "1810.00368", "submitter": "Matthia Sabatelli", "authors": "Matthia Sabatelli, Gilles Louppe, Pierre Geurts, Marco A. Wiering", "title": "Deep Quality-Value (DQV) Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce a novel Deep Reinforcement Learning (DRL) algorithm called Deep\nQuality-Value (DQV) Learning. DQV uses temporal-difference learning to train a\nValue neural network and uses this network for training a second Quality-value\nnetwork that learns to estimate state-action values. We first test DQV's update\nrules with Multilayer Perceptrons as function approximators on two classic RL\nproblems, and then extend DQV with the use of Deep Convolutional Neural\nNetworks, `Experience Replay' and `Target Neural Networks' for tackling four\ngames of the Atari Arcade Learning environment. Our results show that DQV\nlearns significantly faster and better than Deep Q-Learning and Double Deep\nQ-Learning, suggesting that our algorithm can potentially be a better\nperforming synchronous temporal difference algorithm than what is currently\npresent in DRL.\n", "versions": [{"version": "v1", "created": "Sun, 30 Sep 2018 12:52:31 GMT"}, {"version": "v2", "created": "Wed, 10 Oct 2018 07:47:00 GMT"}], "update_date": "2018-10-11", "authors_parsed": [["Sabatelli", "Matthia", ""], ["Louppe", "Gilles", ""], ["Geurts", "Pierre", ""], ["Wiering", "Marco A.", ""]]}, {"id": "1810.00378", "submitter": "Marcello De Bernardi", "authors": "Marcello De Bernardi, MHR Khouzani, Pasquale Malacaria", "title": "Pseudo-Random Number Generation using Generative Adversarial Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Pseudo-random number generators (PRNG) are a fundamental element of many\nsecurity algorithms. We introduce a novel approach to their implementation, by\nproposing the use of generative adversarial networks (GAN) to train a neural\nnetwork to behave as a PRNG. Furthermore, we showcase a number of interesting\nmodifications to the standard GAN architecture. The most significant is\npartially concealing the output of the GAN's generator, and training the\nadversary to discover a mapping from the overt part to the concealed part. The\ngenerator therefore learns to produce values the adversary cannot predict,\nrather than to approximate an explicit reference distribution. We demonstrate\nthat a GAN can effectively train even a small feed-forward fully connected\nneural network to produce pseudo-random number sequences with good statistical\nproperties. At best, subjected to the NIST test suite, the trained generator\npassed around 99% of test instances and 98% of overall tests, outperforming a\nnumber of standard non-cryptographic PRNGs.\n", "versions": [{"version": "v1", "created": "Sun, 30 Sep 2018 13:46:16 GMT"}], "update_date": "2018-10-02", "authors_parsed": [["De Bernardi", "Marcello", ""], ["Khouzani", "MHR", ""], ["Malacaria", "Pasquale", ""]]}, {"id": "1810.00383", "submitter": "Bo Han", "authors": "Bo Han, Ivor W. Tsang, Xiaokui Xiao, Ling Chen, Sai-fu Fung, Celina P.\n  Yu", "title": "Privacy-preserving Stochastic Gradual Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  It is challenging for stochastic optimizations to handle large-scale\nsensitive data safely. Recently, Duchi et al. proposed private sampling\nstrategy to solve privacy leakage in stochastic optimizations. However, this\nstrategy leads to robustness degeneration, since this strategy is equal to the\nnoise injection on each gradient, which adversely affects updates of the primal\nvariable. To address this challenge, we introduce a robust stochastic\noptimization under the framework of local privacy, which is called\nPrivacy-pREserving StochasTIc Gradual lEarning (PRESTIGE). PRESTIGE bridges\nprivate updates of the primal variable (by private sampling) with the gradual\ncurriculum learning (CL). Specifically, the noise injection leads to the issue\nof label noise, but the robust learning process of CL can combat with label\nnoise. Thus, PRESTIGE yields \"private but robust\" updates of the primal\nvariable on the private curriculum, namely an reordered label sequence provided\nby CL. In theory, we reveal the convergence rate and maximum complexity of\nPRESTIGE. Empirical results on six datasets show that, PRESTIGE achieves a good\ntradeoff between privacy preservation and robustness over baselines.\n", "versions": [{"version": "v1", "created": "Sun, 30 Sep 2018 14:10:11 GMT"}], "update_date": "2018-10-02", "authors_parsed": [["Han", "Bo", ""], ["Tsang", "Ivor W.", ""], ["Xiao", "Xiaokui", ""], ["Chen", "Ling", ""], ["Fung", "Sai-fu", ""], ["Yu", "Celina P.", ""]]}, {"id": "1810.00386", "submitter": "Scott Gigante", "authors": "Jay S. Stanley III, Scott Gigante, Guy Wolf, and Smita Krishnaswamy", "title": "Harmonic Alignment", "comments": "Published in SIAM Data Mining 2020. Double column, 18 pages, 4\n  figures", "journal-ref": "SIAM Data Mining 2020", "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a novel framework for combining datasets via alignment of their\nintrinsic geometry. This alignment can be used to fuse data originating from\ndisparate modalities, or to correct batch effects while preserving intrinsic\ndata structure. Importantly, we do not assume any pointwise correspondence\nbetween datasets, but instead rely on correspondence between a (possibly\nunknown) subset of data features. We leverage this assumption to construct an\nisometric alignment between the data. This alignment is obtained by relating\nthe expansion of data features in harmonics derived from diffusion operators\ndefined over each dataset. These expansions encode each feature as a function\nof the data geometry. We use this to relate the diffusion coordinates of each\ndataset through our assumption of partial feature correspondence. Then, a\nunified diffusion geometry is constructed over the aligned data, which can also\nbe used to correct the original data measurements. We demonstrate our method on\nseveral datasets, showing in particular its effectiveness in biological\napplications including fusion of single-cell RNA sequencing (scRNA-seq) and\nsingle-cell ATAC sequencing (scATAC-seq) data measured on the same population\nof cells, and removal of batch effect between biological samples.\n", "versions": [{"version": "v1", "created": "Sun, 30 Sep 2018 14:23:10 GMT"}, {"version": "v2", "created": "Thu, 24 Jan 2019 19:42:03 GMT"}, {"version": "v3", "created": "Thu, 13 Jun 2019 15:24:03 GMT"}, {"version": "v4", "created": "Thu, 30 Jan 2020 16:14:18 GMT"}], "update_date": "2020-01-31", "authors_parsed": [["Stanley", "Jay S.", "III"], ["Gigante", "Scott", ""], ["Wolf", "Guy", ""], ["Krishnaswamy", "Smita", ""]]}, {"id": "1810.00393", "submitter": "Jesse Johnson", "authors": "Jesse Johnson", "title": "Deep, Skinny Neural Networks are not Universal Approximators", "comments": "14 pages, 3 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In order to choose a neural network architecture that will be effective for a\nparticular modeling problem, one must understand the limitations imposed by\neach of the potential options. These limitations are typically described in\nterms of information theoretic bounds, or by comparing the relative complexity\nneeded to approximate example functions between different architectures. In\nthis paper, we examine the topological constraints that the architecture of a\nneural network imposes on the level sets of all the functions that it is able\nto approximate. This approach is novel for both the nature of the limitations\nand the fact that they are independent of network depth for a broad family of\nactivation functions.\n", "versions": [{"version": "v1", "created": "Sun, 30 Sep 2018 14:55:41 GMT"}], "update_date": "2018-10-02", "authors_parsed": [["Johnson", "Jesse", ""]]}, {"id": "1810.00396", "submitter": "Dmitry Podviaznikov", "authors": "Roman Khudorozhkov, Dmitry Podvyaznikov", "title": "Benchmarks of ResNet Architecture for Atrial Fibrillation Classification", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this work we apply variations of ResNet architecture to the task of atrial\nfibrillation classification. Variations differ in number of filter after first\nconvolution, ResNet block layout, number of filters in block convolutions and\nnumber of ResNet blocks between downsampling operations. We have found a range\nof model size in which models with quite different configurations show similar\nperformance. It is likely that overall number of parameters plays dominant role\nin model performance. However, configuration parameters like layout have values\nthat constantly lead to better results, which allows to suggest that these\nparameters should be defined and fixed in the first place, while others may be\nvaried in a reasonable range to satisfy any existing constraints.\n", "versions": [{"version": "v1", "created": "Sun, 30 Sep 2018 15:09:42 GMT"}], "update_date": "2018-10-02", "authors_parsed": [["Khudorozhkov", "Roman", ""], ["Podvyaznikov", "Dmitry", ""]]}, {"id": "1810.00398", "submitter": "Kapil Ahuja", "authors": "Aditya A. Shastri, Kapil Ahuja, Milind B. Ratnaparkhe, Aditya Shah,\n  Aishwary Gagrani, and Anant Lal", "title": "Vector Quantized Spectral Clustering applied to Soybean Whole Genome\n  Sequences", "comments": "10 Pages, 3 Tables, 2 Figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.QM cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We develop a Vector Quantized Spectral Clustering (VQSC) algorithm that is a\ncombination of Spectral Clustering (SC) and Vector Quantization (VQ) sampling\nfor grouping Soybean genomes. The inspiration here is to use SC for its\naccuracy and VQ to make the algorithm computationally cheap (the complexity of\nSC is cubic in-terms of the input size). Although the combination of SC and VQ\nis not new, the novelty of our work is in developing the crucial similarity\nmatrix in SC as well as use of k-medoids in VQ, both adapted for the Soybean\ngenome data. We compare our approach with commonly used techniques like UPGMA\n(Un-weighted Pair Graph Method with Arithmetic Mean) and NJ (Neighbour\nJoining). Experimental results show that our approach outperforms both these\ntechniques significantly in terms of cluster quality (up to 25% better cluster\nquality) and time complexity (order of magnitude faster).\n", "versions": [{"version": "v1", "created": "Sun, 30 Sep 2018 15:13:33 GMT"}], "update_date": "2018-10-02", "authors_parsed": [["Shastri", "Aditya A.", ""], ["Ahuja", "Kapil", ""], ["Ratnaparkhe", "Milind B.", ""], ["Shah", "Aditya", ""], ["Gagrani", "Aishwary", ""], ["Lal", "Anant", ""]]}, {"id": "1810.00421", "submitter": "Siddhartha Dhar Choudhury", "authors": "Siddhartha Dhar Choudhury, Shashank Pandey", "title": "Nth Absolute Root Mean Error", "comments": "12 pages, 13 figures", "journal-ref": null, "doi": "10.35940/ijitee.J9626.119119", "report-no": "J96260881019", "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Neural network training process takes long time when the size of training\ndata is huge, without the large set of training values the neural network is\nunable to learn features. This dilemma between time and size of data is often\nsolved using fast GPUs, but we present a better solution for a subset of those\nproblems. To reduce the time for training a regression model using neural\nnetwork we introduce a loss function called Nth Absolute Root Mean Error\n(NARME). It helps to train regression models much faster compared to other\nexisting loss functions. Experiments show that in most use cases NARME reduces\nthe required number of epochs to almost one-tenth of that required by other\ncommonly used loss functions, and also achieves great accuracy in the small\namount of time in which it was trained.\n", "versions": [{"version": "v1", "created": "Sun, 30 Sep 2018 16:59:59 GMT"}, {"version": "v2", "created": "Tue, 2 Oct 2018 13:03:22 GMT"}], "update_date": "2019-12-16", "authors_parsed": [["Choudhury", "Siddhartha Dhar", ""], ["Pandey", "Shashank", ""]]}, {"id": "1810.00424", "submitter": "Alexander Tong", "authors": "Alexander Tong, David van Dijk, Jay S. Stanley III, Matthew Amodio,\n  Kristina Yim, Rebecca Muhle, James Noonan, Guy Wolf, and Smita Krishnaswamy", "title": "Interpretable Neuron Structuring with Graph Spectral Regularization", "comments": "12 pages, 6 figures, presented at IDA 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  While neural networks are powerful approximators used to classify or embed\ndata into lower dimensional spaces, they are often regarded as black boxes with\nuninterpretable features. Here we propose Graph Spectral Regularization for\nmaking hidden layers more interpretable without significantly impacting\nperformance on the primary task. Taking inspiration from spatial organization\nand localization of neuron activations in biological networks, we use a graph\nLaplacian penalty to structure the activations within a layer. This penalty\nencourages activations to be smooth either on a predetermined graph or on a\nfeature-space graph learned from the data via co-activations of a hidden layer\nof the neural network. We show numerous uses for this additional structure\nincluding cluster indication and visualization in biological and image data\nsets.\n", "versions": [{"version": "v1", "created": "Sun, 30 Sep 2018 17:18:35 GMT"}, {"version": "v2", "created": "Tue, 2 Oct 2018 02:00:39 GMT"}, {"version": "v3", "created": "Thu, 24 Jan 2019 00:13:46 GMT"}, {"version": "v4", "created": "Mon, 27 May 2019 12:18:58 GMT"}, {"version": "v5", "created": "Fri, 14 Feb 2020 19:55:11 GMT"}], "update_date": "2020-02-18", "authors_parsed": [["Tong", "Alexander", ""], ["van Dijk", "David", ""], ["Stanley", "Jay S.", "III"], ["Amodio", "Matthew", ""], ["Yim", "Kristina", ""], ["Muhle", "Rebecca", ""], ["Noonan", "James", ""], ["Wolf", "Guy", ""], ["Krishnaswamy", "Smita", ""]]}, {"id": "1810.00428", "submitter": "Saeed Najafi", "authors": "Saeed Najafi, Colin Cherry, Grzegorz Kondrak", "title": "Efficient Sequence Labeling with Actor-Critic Training", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CL stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Neural approaches to sequence labeling often use a Conditional Random Field\n(CRF) to model their output dependencies, while Recurrent Neural Networks (RNN)\nare used for the same purpose in other tasks. We set out to establish RNNs as\nan attractive alternative to CRFs for sequence labeling. To do so, we address\none of the RNN's most prominent shortcomings, the fact that it is not exposed\nto its own errors with the maximum-likelihood training. We frame the prediction\nof the output sequence as a sequential decision-making process, where we train\nthe network with an adjusted actor-critic algorithm (AC-RNN). We\ncomprehensively compare this strategy with maximum-likelihood training for both\nRNNs and CRFs on three structured-output tasks. The proposed AC-RNN efficiently\nmatches the performance of the CRF on NER and CCG tagging, and outperforms it\non Machine Transliteration. We also show that our training strategy is\nsignificantly better than other techniques for addressing RNN's exposure bias,\nsuch as Scheduled Sampling, and Self-Critical policy training.\n", "versions": [{"version": "v1", "created": "Sun, 30 Sep 2018 17:31:52 GMT"}], "update_date": "2018-10-02", "authors_parsed": [["Najafi", "Saeed", ""], ["Cherry", "Colin", ""], ["Kondrak", "Grzegorz", ""]]}, {"id": "1810.00434", "submitter": "Huizi Mao", "authors": "Huizi Mao, Taeyoung Kong, William J. Dally", "title": "CaTDet: Cascaded Tracked Detector for Efficient Object Detection from\n  Video", "comments": "Accepted to SysML 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Detecting objects in a video is a compute-intensive task. In this paper we\npropose CaTDet, a system to speedup object detection by leveraging the temporal\ncorrelation in video. CaTDet consists of two DNN models that form a cascaded\ndetector, and an additional tracker to predict regions of interests based on\nhistoric detections. We also propose a new metric, mean Delay(mD), which is\ndesigned for latency-critical video applications. Experiments on the KITTI\ndataset show that CaTDet reduces operation count by 5.1-8.7x with the same mean\nAverage Precision(mAP) as the single-model Faster R-CNN detector and incurs\nadditional delay of 0.3 frame. On CityPersons dataset, CaTDet achieves 13.0x\nreduction in operations with 0.8% mAP loss.\n", "versions": [{"version": "v1", "created": "Sun, 30 Sep 2018 17:59:42 GMT"}, {"version": "v2", "created": "Tue, 19 Feb 2019 18:57:18 GMT"}], "update_date": "2019-02-20", "authors_parsed": [["Mao", "Huizi", ""], ["Kong", "Taeyoung", ""], ["Dally", "William J.", ""]]}, {"id": "1810.00440", "submitter": "Marton Havasi", "authors": "Marton Havasi, Robert Peharz, Jos\\'e Miguel Hern\\'andez-Lobato", "title": "Minimal Random Code Learning: Getting Bits Back from Compressed Model\n  Parameters", "comments": "Under review as a conference paper at ICLR 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  While deep neural networks are a highly successful model class, their large\nmemory footprint puts considerable strain on energy consumption, communication\nbandwidth, and storage requirements. Consequently, model size reduction has\nbecome an utmost goal in deep learning. A typical approach is to train a set of\ndeterministic weights, while applying certain techniques such as pruning and\nquantization, in order that the empirical weight distribution becomes amenable\nto Shannon-style coding schemes. However, as shown in this paper, relaxing\nweight determinism and using a full variational distribution over weights\nallows for more efficient coding schemes and consequently higher compression\nrates. In particular, following the classical bits-back argument, we encode the\nnetwork weights using a random sample, requiring only a number of bits\ncorresponding to the Kullback-Leibler divergence between the sampled\nvariational distribution and the encoding distribution. By imposing a\nconstraint on the Kullback-Leibler divergence, we are able to explicitly\ncontrol the compression rate, while optimizing the expected loss on the\ntraining set. The employed encoding scheme can be shown to be close to the\noptimal information-theoretical lower bound, with respect to the employed\nvariational family. Our method sets new state-of-the-art in neural network\ncompression, as it strictly dominates previous approaches in a Pareto sense: On\nthe benchmarks LeNet-5/MNIST and VGG-16/CIFAR-10, our approach yields the best\ntest performance for a fixed memory budget, and vice versa, it achieves the\nhighest compression rates for a fixed test performance.\n", "versions": [{"version": "v1", "created": "Sun, 30 Sep 2018 18:27:30 GMT"}], "update_date": "2018-10-02", "authors_parsed": [["Havasi", "Marton", ""], ["Peharz", "Robert", ""], ["Hern\u00e1ndez-Lobato", "Jos\u00e9 Miguel", ""]]}, {"id": "1810.00466", "submitter": "Rodrigo P\\'erez Dattari", "authors": "Rodrigo P\\'erez-Dattari, Carlos Celemin, Javier Ruiz-del-Solar and\n  Jens Kober", "title": "Interactive Learning with Corrective Feedback for Policies based on Deep\n  Neural Networks", "comments": "10 pages, 7 figures, 1 table, conference (ISER 2018)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep Reinforcement Learning (DRL) has become a powerful strategy to solve\ncomplex decision making problems based on Deep Neural Networks (DNNs). However,\nit is highly data demanding, so unfeasible in physical systems for most\napplications. In this work, we approach an alternative Interactive Machine\nLearning (IML) strategy for training DNN policies based on human corrective\nfeedback, with a method called Deep COACH (D-COACH). This approach not only\ntakes advantage of the knowledge and insights of human teachers as well as the\npower of DNNs, but also has no need of a reward function (which sometimes\nimplies the need of external perception for computing rewards). We combine Deep\nLearning with the COrrective Advice Communicated by Humans (COACH) framework,\nin which non-expert humans shape policies by correcting the agent's actions\nduring execution. The D-COACH framework has the potential to solve complex\nproblems without much data or time required. Experimental results validated the\nefficiency of the framework in three different problems (two simulated, one\nwith a real robot), with state spaces of low and high dimensions, showing the\ncapacity to successfully learn policies for continuous action spaces like in\nthe Car Racing and Cart-Pole problems faster than with DRL.\n", "versions": [{"version": "v1", "created": "Sun, 30 Sep 2018 20:59:04 GMT"}], "update_date": "2018-10-02", "authors_parsed": [["P\u00e9rez-Dattari", "Rodrigo", ""], ["Celemin", "Carlos", ""], ["Ruiz-del-Solar", "Javier", ""], ["Kober", "Jens", ""]]}, {"id": "1810.00468", "submitter": "Michalis Titsias", "authors": "Michalis K. Titsias, Sotirios Nikoloutsopoulos", "title": "Bayesian Transfer Reinforcement Learning with Prior Knowledge Rules", "comments": "11 pages, 2 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a probabilistic framework to directly insert prior knowledge in\nreinforcement learning (RL) algorithms by defining the behaviour policy as a\nBayesian posterior distribution. Such a posterior combines task specific\ninformation with prior knowledge, thus allowing to achieve transfer learning\nacross tasks. The resulting method is flexible and it can be easily\nincorporated to any standard off-policy and on-policy algorithms, such as those\nbased on temporal differences and policy gradients. We develop a specific\ninstance of this Bayesian transfer RL framework by expressing prior knowledge\nas general deterministic rules that can be useful in a large variety of tasks,\nsuch as navigation tasks. Also, we elaborate more on recent probabilistic and\nentropy-regularised RL by developing a novel temporal learning algorithm and\nshow how to combine it with Bayesian transfer RL. Finally, we demonstrate our\nmethod for solving mazes and show that significant speed ups can be obtained.\n", "versions": [{"version": "v1", "created": "Sun, 30 Sep 2018 21:12:44 GMT"}], "update_date": "2018-10-02", "authors_parsed": [["Titsias", "Michalis K.", ""], ["Nikoloutsopoulos", "Sotirios", ""]]}, {"id": "1810.00471", "submitter": "Daniel McDuff", "authors": "Daniel McDuff, Roger Cheng, Ashish Kapoor", "title": "Identifying Bias in AI using Simulation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Machine learned models exhibit bias, often because the datasets used to train\nthem are biased. This presents a serious problem for the deployment of such\ntechnology, as the resulting models might perform poorly on populations that\nare minorities within the training set and ultimately present higher risks to\nthem. We propose to use high-fidelity computer simulations to interrogate and\ndiagnose biases within ML classifiers. We present a framework that leverages\nBayesian parameter search to efficiently characterize the high dimensional\nfeature space and more quickly identify weakness in performance. We apply our\napproach to an example domain, face detection, and show that it can be used to\nhelp identify demographic biases in commercial face application programming\ninterfaces (APIs).\n", "versions": [{"version": "v1", "created": "Sun, 30 Sep 2018 21:46:58 GMT"}], "update_date": "2018-10-02", "authors_parsed": [["McDuff", "Daniel", ""], ["Cheng", "Roger", ""], ["Kapoor", "Ashish", ""]]}, {"id": "1810.00475", "submitter": "Riddhish Bhalodia", "authors": "Riddhish Bhalodia, Anupama Goparaju, Tim Sodergren, Alan Morris,\n  Evgueni Kholmovski, Nassir Marrouche, Joshua Cates, Ross Whitaker, and\n  Shireen Elhabian", "title": "Deep Learning for End-to-End Atrial Fibrillation Recurrence Estimation", "comments": "Presented at Computing in Cardiology (CinC) 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Left atrium shape has been shown to be an independent predictor of recurrence\nafter atrial fibrillation (AF) ablation. Shape-based representation is\nimperative to such an estimation process, where correspondence-based\nrepresentation offers the most flexibility and ease-of-computation for\npopulation-level shape statistics. Nonetheless, population-level shape\nrepresentations in the form of image segmentation and correspondence models\nderived from cardiac MRI require significant human resources with sufficient\nanatomy-specific expertise. In this paper, we propose a machine learning\napproach that uses deep networks to estimate AF recurrence by predicting shape\ndescriptors directly from MRI images, with NO image pre-processing involved. We\nalso propose a novel data augmentation scheme to effectively train a deep\nnetwork in a limited training data setting. We compare this new method of\nestimating shape descriptors from images with the state-of-the-art\ncorrespondence-based shape modeling that requires image segmentation and\ncorrespondence optimization. Results show that the proposed method and the\ncurrent state-of-the-art produce statistically similar outcomes on AF\nrecurrence, eliminating the need for expensive pre-processing pipelines and\nassociated human labor.\n", "versions": [{"version": "v1", "created": "Sun, 30 Sep 2018 22:10:28 GMT"}], "update_date": "2018-10-02", "authors_parsed": [["Bhalodia", "Riddhish", ""], ["Goparaju", "Anupama", ""], ["Sodergren", "Tim", ""], ["Morris", "Alan", ""], ["Kholmovski", "Evgueni", ""], ["Marrouche", "Nassir", ""], ["Cates", "Joshua", ""], ["Whitaker", "Ross", ""], ["Elhabian", "Shireen", ""]]}, {"id": "1810.00481", "submitter": "Srinivasan Arunachalam", "authors": "Srinivasan Arunachalam, Sourav Chakraborty, Troy Lee, Manaswi\n  Paraashar and Ronald de Wolf", "title": "Two new results about quantum exact learning", "comments": "v3: 21 pages. Small corrections and clarifications", "journal-ref": null, "doi": null, "report-no": null, "categories": "quant-ph cs.CC cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present two new results about exact learning by quantum computers. First,\nwe show how to exactly learn a $k$-Fourier-sparse $n$-bit Boolean function from\n$O(k^{1.5}(\\log k)^2)$ uniform quantum examples for that function. This\nimproves over the bound of $\\widetilde{\\Theta}(kn)$ uniformly random classical\nexamples (Haviv and Regev, CCC'15). Our main tool is an improvement of Chang's\nlemma for the special case of sparse functions. Second, we show that if a\nconcept class $\\mathcal{C}$ can be exactly learned using $Q$ quantum membership\nqueries, then it can also be learned using $O\\left(\\frac{Q^2}{\\log\nQ}\\log|\\mathcal{C}|\\right)$ classical membership queries. This improves the\nprevious-best simulation result (Servedio and Gortler, SICOMP'04) by a $\\log\nQ$-factor.\n", "versions": [{"version": "v1", "created": "Sun, 30 Sep 2018 22:54:58 GMT"}, {"version": "v2", "created": "Thu, 7 Mar 2019 14:24:59 GMT"}, {"version": "v3", "created": "Sun, 19 Apr 2020 15:09:26 GMT"}], "update_date": "2020-04-21", "authors_parsed": [["Arunachalam", "Srinivasan", ""], ["Chakraborty", "Sourav", ""], ["Lee", "Troy", ""], ["Paraashar", "Manaswi", ""], ["de Wolf", "Ronald", ""]]}, {"id": "1810.00482", "submitter": "Annie Xie", "authors": "Annie Xie, Avi Singh, Sergey Levine, Chelsea Finn", "title": "Few-Shot Goal Inference for Visuomotor Learning and Planning", "comments": "Videos available at https://sites.google.com/view/few-shot-goals", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CV cs.RO stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Reinforcement learning and planning methods require an objective or reward\nfunction that encodes the desired behavior. Yet, in practice, there is a wide\nrange of scenarios where an objective is difficult to provide programmatically,\nsuch as tasks with visual observations involving unknown object positions or\ndeformable objects. In these cases, prior methods use engineered\nproblem-specific solutions, e.g., by instrumenting the environment with\nadditional sensors to measure a proxy for the objective. Such solutions require\na significant engineering effort on a per-task basis, and make it impractical\nfor robots to continuously learn complex skills outside of laboratory settings.\nWe aim to find a more general and scalable solution for specifying goals for\nrobot learning in unconstrained environments. To that end, we formulate the\nfew-shot objective learning problem, where the goal is to learn a task\nobjective from only a few example images of successful end states for that\ntask. We propose a simple solution to this problem: meta-learn a classifier\nthat can recognize new goals from a few examples. We show how this approach can\nbe used with both model-free reinforcement learning and visual model-based\nplanning and show results in three domains: rope manipulation from images in\nsimulation, visual navigation in a simulated 3D environment, and object\narrangement into user-specified configurations on a real robot.\n", "versions": [{"version": "v1", "created": "Sun, 30 Sep 2018 22:57:58 GMT"}], "update_date": "2018-10-02", "authors_parsed": [["Xie", "Annie", ""], ["Singh", "Avi", ""], ["Levine", "Sergey", ""], ["Finn", "Chelsea", ""]]}, {"id": "1810.00490", "submitter": "Duc Thanh Anh Luong", "authors": "Duc Thanh Anh Luong and Varun Chandola", "title": "Learning Deep Representations from Clinical Data for Chronic Kidney\n  Disease", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the behavior of a Time-Aware Long Short-Term Memory Autoencoder, a\nstate-of-the-art method, in the context of learning latent representations from\nirregularly sampled patient data. We identify a key issue in the way such\nrecurrent neural network models are being currently used and show that the\nsolution of the issue leads to significant improvements in the learnt\nrepresentations on both synthetic and real datasets. A detailed analysis of the\nimproved methodology for representing patients suffering from Chronic Kidney\nDisease (CKD) using clinical data is provided. Experimental results show that\nthe proposed T-LSTM model is able to capture the long-term trends in the data,\nwhile effectively handling the noise in the signal. Finally, we show that by\nusing the latent representations of the CKD patients obtained from the T-LSTM\nautoencoder, one can identify unusual patient profiles from the target\npopulation.\n", "versions": [{"version": "v1", "created": "Mon, 1 Oct 2018 00:34:19 GMT"}, {"version": "v2", "created": "Sat, 9 Feb 2019 05:28:59 GMT"}], "update_date": "2019-02-12", "authors_parsed": [["Luong", "Duc Thanh Anh", ""], ["Chandola", "Varun", ""]]}, {"id": "1810.00494", "submitter": "Jinhyuk Lee", "authors": "Jinhyuk Lee, Seongjun Yun, Hyunjae Kim, Miyoung Ko, Jaewoo Kang", "title": "Ranking Paragraphs for Improving Answer Recall in Open-Domain Question\n  Answering", "comments": "EMNLP 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recently, open-domain question answering (QA) has been combined with machine\ncomprehension models to find answers in a large knowledge source. As\nopen-domain QA requires retrieving relevant documents from text corpora to\nanswer questions, its performance largely depends on the performance of\ndocument retrievers. However, since traditional information retrieval systems\nare not effective in obtaining documents with a high probability of containing\nanswers, they lower the performance of QA systems. Simply extracting more\ndocuments increases the number of irrelevant documents, which also degrades the\nperformance of QA systems. In this paper, we introduce Paragraph Ranker which\nranks paragraphs of retrieved documents for a higher answer recall with less\nnoise. We show that ranking paragraphs and aggregating answers using Paragraph\nRanker improves performance of open-domain QA pipeline on the four open-domain\nQA datasets by 7.8% on average.\n", "versions": [{"version": "v1", "created": "Mon, 1 Oct 2018 00:51:25 GMT"}], "update_date": "2018-10-02", "authors_parsed": [["Lee", "Jinhyuk", ""], ["Yun", "Seongjun", ""], ["Kim", "Hyunjae", ""], ["Ko", "Miyoung", ""], ["Kang", "Jaewoo", ""]]}, {"id": "1810.00500", "submitter": "Jong Chul Ye", "authors": "Yoseob Han and Jong Chul Ye", "title": "One Network to Solve All ROIs: Deep Learning CT for Any ROI using\n  Differentiated Backprojection", "comments": "Accepted by Medical Physics", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Computed tomography for region-of-interest (ROI) reconstruction has\nadvantages of reducing X-ray radiation dose and using a small detector.\nHowever, standard analytic reconstruction methods suffer from severe cupping\nartifacts, and existing model-based iterative reconstruction methods require\nextensive computations. Recently, we proposed a deep neural network to learn\nthe cupping artifact, but the network is not well generalized for different\nROIs due to the singularities in the corrupted images. Therefore, there is an\nincreasing demand for a neural network that works well for any ROI sizes. In\nthis paper, two types of neural networks are designed. The first type learns\nROI size-specific cupping artifacts from the analytic reconstruction images,\nwhereas the second type network is to learn to invert the finite Hilbert\ntransform from the truncated differentiated backprojection (DBP) data. Their\ngeneralizability for any ROI sizes is then examined. Experimental results show\nthat the new type of neural network significantly outperforms the existing\niterative methods for any ROI size in spite of significantly reduced run-time\ncomplexity. Since the proposed method consistently surpasses existing methods\nfor any ROIs, it can be used as a general CT reconstruction engine for many\npractical applications without compromising possible detector truncation.\n", "versions": [{"version": "v1", "created": "Mon, 1 Oct 2018 01:51:33 GMT"}, {"version": "v2", "created": "Mon, 27 May 2019 04:26:34 GMT"}], "update_date": "2019-05-28", "authors_parsed": [["Han", "Yoseob", ""], ["Ye", "Jong Chul", ""]]}, {"id": "1810.00506", "submitter": "Jagdeep Bhatia S", "authors": "Jagdeep Bhatia", "title": "Simple and Fast Algorithms for Interactive Machine Learning with Random\n  Counter-examples", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This work describes simple and efficient algorithms for interactively\nlearning non-binary concepts in the learning from random counter-examples (LRC)\nmodel. Here, learning takes place from random counter-examples that the learner\nreceives in response to their proper equivalence queries. In this context, the\nlearning time is defined as the number of counter-examples needed by the\nlearner to identify the target concept. Such learning is particularly suited\nfor online ranking, classification, clustering, etc., where machine learning\nmodels must be used before they are fully trained.\n  We provide two simple LRC algorithms, deterministic and randomized, for\nexactly learning non-binary target concepts for any concept class $H$. We show\nthat both of these algorithms have an $\\mathcal{O}(\\log{}|H|)$ asymptotically\noptimal average learning time. This solves an open problem on the existence of\nan efficient LRC randomized algorithm while simplifying and generalizing\nprevious results. We also show that the expected learning time of any arbitrary\nLRC algorithm can be upper bounded by\n$\\mathcal{O}(\\frac{1}{\\epsilon}\\log{\\frac{|H|}{\\delta}})$, where $\\epsilon$ and\n$\\delta$ are the allowed learning error and failure probability respectively.\nThis shows that LRC interactive learning is at least as efficient as\nnon-interactive Probably Approximately Correct (PAC) learning. Our simulations\nshow that in practice, these algorithms outperform their theoretical bounds.\n", "versions": [{"version": "v1", "created": "Mon, 1 Oct 2018 02:30:00 GMT"}, {"version": "v2", "created": "Sun, 29 Dec 2019 01:11:59 GMT"}], "update_date": "2020-01-01", "authors_parsed": [["Bhatia", "Jagdeep", ""]]}, {"id": "1810.00510", "submitter": "Tianmin Shu", "authors": "Tianmin Shu, Caiming Xiong, Ying Nian Wu, Song-Chun Zhu", "title": "Interactive Agent Modeling by Learning to Probe", "comments": "14 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG cs.MA stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The ability of modeling the other agents, such as understanding their\nintentions and skills, is essential to an agent's interactions with other\nagents. Conventional agent modeling relies on passive observation from\ndemonstrations. In this work, we propose an interactive agent modeling scheme\nenabled by encouraging an agent to learn to probe. In particular, the probing\nagent (i.e. a learner) learns to interact with the environment and with a\ntarget agent (i.e., a demonstrator) to maximize the change in the observed\nbehaviors of that agent. Through probing, rich behaviors can be observed and\nare used for enhancing the agent modeling to learn a more accurate mind model\nof the target agent. Our framework consists of two learning processes: i)\nimitation learning for an approximated agent model and ii) pure\ncuriosity-driven reinforcement learning for an efficient probing policy to\ndiscover new behaviors that otherwise can not be observed. We have validated\nour approach in four different tasks. The experimental results suggest that the\nagent model learned by our approach i) generalizes better in novel scenarios\nthan the ones learned by passive observation, random probing, and other\ncuriosity-driven approaches do, and ii) can be used for enhancing performance\nin multiple applications including distilling optimal planning to a policy net,\ncollaboration, and competition. A video demo is available at\nhttps://www.dropbox.com/s/8mz6rd3349tso67/Probing_Demo.mov?dl=0\n", "versions": [{"version": "v1", "created": "Mon, 1 Oct 2018 02:55:07 GMT"}], "update_date": "2018-10-02", "authors_parsed": [["Shu", "Tianmin", ""], ["Xiong", "Caiming", ""], ["Wu", "Ying Nian", ""], ["Zhu", "Song-Chun", ""]]}, {"id": "1810.00518", "submitter": "Ting-Wu Chin", "authors": "Ting-Wu Chin, Cha Zhang, Diana Marculescu", "title": "Layer-compensated Pruning for Resource-constrained Convolutional Neural\n  Networks", "comments": "11 pages, 8 figures, work in progress", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Resource-efficient convolution neural networks enable not only the\nintelligence on edge devices but also opportunities in system-level\noptimization such as scheduling. In this work, we aim to improve the\nperformance of resource-constrained filter pruning by merging two sub-problems\ncommonly considered, i.e., (i) how many filters to prune for each layer and\n(ii) which filters to prune given a per-layer pruning budget, into a global\nfilter ranking problem. Our framework entails a novel algorithm, dubbed\nlayer-compensated pruning, where meta-learning is involved to determine better\nsolutions. We show empirically that the proposed algorithm is superior to prior\nart in both effectiveness and efficiency. Specifically, we reduce the accuracy\ngap between the pruned and original networks from 0.9% to 0.7% with 8x\nreduction in time needed for meta-learning, i.e., from 1 hour down to 7\nminutes. To this end, we demonstrate the effectiveness of our algorithm using\nResNet and MobileNetV2 networks under CIFAR-10, ImageNet, and Bird-200\ndatasets.\n", "versions": [{"version": "v1", "created": "Mon, 1 Oct 2018 03:41:25 GMT"}, {"version": "v2", "created": "Thu, 18 Oct 2018 02:36:01 GMT"}], "update_date": "2018-10-19", "authors_parsed": [["Chin", "Ting-Wu", ""], ["Zhang", "Cha", ""], ["Marculescu", "Diana", ""]]}, {"id": "1810.00520", "submitter": "Rafael Menelau Oliveira E Cruz", "authors": "Rafael M. O. Cruz, Dayvid V. R. Oliveira, George D. C. Cavalcanti,\n  Robert Sabourin", "title": "FIRE-DES++: Enhanced Online Pruning of Base Classifiers for Dynamic\n  Ensemble Selection", "comments": "Article published on Pattern Recognition, 2019", "journal-ref": "Pattern Recognition, Volume 85, January 2019, Pages 149-160", "doi": "10.1016/j.patcog.2018.07.037", "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Despite being very effective in several classification tasks, Dynamic\nEnsemble Selection (DES) techniques can select classifiers that classify all\nsamples in the region of competence as being from the same class. The Frienemy\nIndecision REgion DES (FIRE-DES) tackles this problem by pre-selecting\nclassifiers that correctly classify at least one pair of samples from different\nclasses in the region of competence of the test sample. However, FIRE-DES\napplies the pre-selection for the classification of a test sample if and only\nif its region of competence is composed of samples from different classes\n(indecision region), even though this criterion is not reliable for determining\nif a test sample is located close to the borders of classes (true indecision\nregion) when the region of competence is obtained using classical nearest\nneighbors approach. Because of that, FIRE-DES mistakes noisy regions for true\nindecision regions, leading to the pre-selection of incompetent classifiers,\nand mistakes true indecision regions for safe regions, leaving samples in such\nregions without any pre-selection. To tackle these issues, we propose the\nFIRE-DES++, an enhanced FIRE-DES that removes noise and reduces the overlap of\nclasses in the validation set; and defines the region of competence using an\nequal number of samples of each class, avoiding selecting a region of\ncompetence with samples of a single class. Experiments are conducted using\nFIRE-DES++ with 8 different dynamic selection techniques on 64 classification\ndatasets. Experimental results show that FIRE-DES++ increases the\nclassification performance of all DES techniques considered in this work,\noutperforming FIRE-DES with 7 out of the 8 DES techniques, and outperforming\nstate-of-the-art DES frameworks.\n", "versions": [{"version": "v1", "created": "Mon, 1 Oct 2018 03:49:46 GMT"}, {"version": "v2", "created": "Tue, 2 Oct 2018 23:17:15 GMT"}], "update_date": "2020-03-06", "authors_parsed": [["Cruz", "Rafael M. O.", ""], ["Oliveira", "Dayvid V. R.", ""], ["Cavalcanti", "George D. C.", ""], ["Sabourin", "Robert", ""]]}, {"id": "1810.00521", "submitter": "Walid Saba", "authors": "Walid S. Saba", "title": "A Simple Machine Learning Method for Commonsense Reasoning? A Short\n  Commentary on Trinh & Le (2018)", "comments": "5 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This is a short Commentary on Trinh & Le (2018) (\"A Simple Method for\nCommonsense Reasoning\") that outlines three serious flaws in the cited paper\nand discusses why data-driven approaches cannot be considered as serious models\nfor the commonsense reasoning needed in natural language understanding in\ngeneral, and in reference resolution, in particular.\n", "versions": [{"version": "v1", "created": "Mon, 1 Oct 2018 03:58:00 GMT"}], "update_date": "2018-10-02", "authors_parsed": [["Saba", "Walid S.", ""]]}, {"id": "1810.00551", "submitter": "Hazrat Ali", "authors": "Talha Iqbal, Hazrat Ali", "title": "Generative Adversarial Network for Medical Images (MI-GAN)", "comments": "Journal of Medical Systems", "journal-ref": "Med Syst (2018) 42: 231", "doi": "10.1007/s10916-018-1072-9", "report-no": null, "categories": "cs.LG cs.CV eess.IV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep learning algorithms produces state-of-the-art results for different\nmachine learning and computer vision tasks. To perform well on a given task,\nthese algorithms require large dataset for training. However, deep learning\nalgorithms lack generalization and suffer from over-fitting whenever trained on\nsmall dataset, especially when one is dealing with medical images. For\nsupervised image analysis in medical imaging, having image data along with\ntheir corresponding annotated ground-truths is costly as well as time consuming\nsince annotations of the data is done by medical experts manually. In this\npaper, we propose a new Generative Adversarial Network for Medical Imaging\n(MI-GAN). The MI-GAN generates synthetic medical images and their segmented\nmasks, which can then be used for the application of supervised analysis of\nmedical images. Particularly, we present MI-GAN for synthesis of retinal\nimages. The proposed method generates precise segmented images better than the\nexisting techniques. The proposed model achieves a dice coefficient of 0.837 on\nSTARE dataset and 0.832 on DRIVE dataset which is state-of-the-art performance\non both the datasets.\n", "versions": [{"version": "v1", "created": "Mon, 1 Oct 2018 06:59:37 GMT"}], "update_date": "2019-04-03", "authors_parsed": [["Iqbal", "Talha", ""], ["Ali", "Hazrat", ""]]}, {"id": "1810.00553", "submitter": "Qi Deng", "authors": "Qi Deng and Yi Cheng and Guanghui Lan", "title": "Optimal Adaptive and Accelerated Stochastic Gradient Descent", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Stochastic gradient descent (\\textsc{Sgd}) methods are the most powerful\noptimization tools in training machine learning and deep learning models.\nMoreover, acceleration (a.k.a. momentum) methods and diagonal scaling (a.k.a.\nadaptive gradient) methods are the two main techniques to improve the slow\nconvergence of \\textsc{Sgd}. While empirical studies have demonstrated\npotential advantages of combining these two techniques, it remains unknown\nwhether these methods can achieve the optimal rate of convergence for\nstochastic optimization. In this paper, we present a new class of adaptive and\naccelerated stochastic gradient descent methods and show that they exhibit the\noptimal sampling and iteration complexity for stochastic optimization. More\nspecifically, we show that diagonal scaling, initially designed to improve\nvanilla stochastic gradient, can be incorporated into accelerated stochastic\ngradient descent to achieve the optimal rate of convergence for smooth\nstochastic optimization. We also show that momentum, apart from being known to\nspeed up the convergence rate of deterministic optimization, also provides us\nnew ways of designing non-uniform and aggressive moving average schemes in\nstochastic optimization. Finally, we present some heuristics that help to\nimplement adaptive accelerated stochastic gradient descent methods and to\nfurther improve their practical performance for machine learning and deep\nlearning.\n", "versions": [{"version": "v1", "created": "Mon, 1 Oct 2018 07:07:47 GMT"}], "update_date": "2018-10-02", "authors_parsed": [["Deng", "Qi", ""], ["Cheng", "Yi", ""], ["Lan", "Guanghui", ""]]}, {"id": "1810.00555", "submitter": "Theofanis Karaletsos", "authors": "Theofanis Karaletsos, Peter Dayan, Zoubin Ghahramani", "title": "Probabilistic Meta-Representations Of Neural Networks", "comments": "presented at UAI 2018 Uncertainty In Deep Learning Workshop (UDL AUG.\n  2018)", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Existing Bayesian treatments of neural networks are typically characterized\nby weak prior and approximate posterior distributions according to which all\nthe weights are drawn independently. Here, we consider a richer prior\ndistribution in which units in the network are represented by latent variables,\nand the weights between units are drawn conditionally on the values of the\ncollection of those variables. This allows rich correlations between related\nweights, and can be seen as realizing a function prior with a Bayesian\ncomplexity regularizer ensuring simple solutions. We illustrate the resulting\nmeta-representations and representations, elucidating the power of this prior.\n", "versions": [{"version": "v1", "created": "Mon, 1 Oct 2018 07:15:32 GMT"}], "update_date": "2018-10-02", "authors_parsed": [["Karaletsos", "Theofanis", ""], ["Dayan", "Peter", ""], ["Ghahramani", "Zoubin", ""]]}, {"id": "1810.00597", "submitter": "Danilo Jimenez Rezende", "authors": "Danilo Jimenez Rezende and Fabio Viola", "title": "Taming VAEs", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In spite of remarkable progress in deep latent variable generative modeling,\ntraining still remains a challenge due to a combination of optimization and\ngeneralization issues. In practice, a combination of heuristic algorithms (such\nas hand-crafted annealing of KL-terms) is often used in order to achieve the\ndesired results, but such solutions are not robust to changes in model\narchitecture or dataset. The best settings can often vary dramatically from one\nproblem to another, which requires doing expensive parameter sweeps for each\nnew case. Here we develop on the idea of training VAEs with additional\nconstraints as a way to control their behaviour. We first present a detailed\ntheoretical analysis of constrained VAEs, expanding our understanding of how\nthese models work. We then introduce and analyze a practical algorithm termed\nGeneralized ELBO with Constrained Optimization, GECO. The main advantage of\nGECO for the machine learning practitioner is a more intuitive, yet principled,\nprocess of tuning the loss. This involves defining of a set of constraints,\nwhich typically have an explicit relation to the desired model performance, in\ncontrast to tweaking abstract hyper-parameters which implicitly affect the\nmodel behavior. Encouraging experimental results in several standard datasets\nindicate that GECO is a very robust and effective tool to balance\nreconstruction and compression constraints.\n", "versions": [{"version": "v1", "created": "Mon, 1 Oct 2018 09:53:41 GMT"}], "update_date": "2018-10-02", "authors_parsed": [["Rezende", "Danilo Jimenez", ""], ["Viola", "Fabio", ""]]}, {"id": "1810.00609", "submitter": "Anbumani Subramanian", "authors": "Adithya Subramanian, Anbumani Subramanian", "title": "One-Click Annotation with Guided Hierarchical Object Detection", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV cs.HC stat.ML", "license": "http://creativecommons.org/publicdomain/zero/1.0/", "abstract": "  The increase in data collection has made data annotation an interesting and\nvaluable task in the contemporary world. This paper presents a new methodology\nfor quickly annotating data using click-supervision and hierarchical object\ndetection. The proposed work is semi-automatic in nature where the task of\nannotations is split between the human and a neural network. We show that our\nimproved method of annotation reduces the time, cost and mental stress on a\nhuman annotator. The research also highlights how our method performs better\nthan the current approach in different circumstances such as variation in\nnumber of objects, object size and different datasets. Our approach also\nproposes a new method of using object detectors making it suitable for data\nannotation task. The experiment conducted on PASCAL VOC dataset revealed that\nannotation created from our approach achieves a mAP of 0.995 and a recall of\n0.903. The Our Approach has shown an overall improvement by 8.5%, 18.6% in mean\naverage precision and recall score for KITTI and 69.6%, 36% for CITYSCAPES\ndataset. The proposed framework is 3-4 times faster as compared to the standard\nannotation method.\n", "versions": [{"version": "v1", "created": "Mon, 1 Oct 2018 10:41:35 GMT"}], "update_date": "2018-10-02", "authors_parsed": [["Subramanian", "Adithya", ""], ["Subramanian", "Anbumani", ""]]}, {"id": "1810.00619", "submitter": "Thomas Deselaers", "authors": "Victor Carbune, Thierry Coppey, Alexander Daryin, Thomas Deselaers,\n  Nikhil Sarda, Jay Yagnik", "title": "SmartChoices: Hybridizing Programming and Machine Learning", "comments": "published at the Reinforcement Learning for Real Life (RL4RealLife)\n  Workshop in the 36th International Conference on Machine Learning (ICML),\n  Long Beach, California, USA, 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.PL stat.ML", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  We present SmartChoices, an approach to making machine learning (ML) a first\nclass citizen in programming languages which we see as one way to lower the\nentrance cost to applying ML to problems in new domains. There is a growing\ndivide in approaches to building systems: on the one hand, programming\nleverages human experts to define a system while on the other hand behavior is\nlearned from data in machine learning. We propose to hybridize these two by\nproviding a 3-call API which we expose through an object called SmartChoice. We\ndescribe the SmartChoices-interface, how it can be used in programming with\nminimal code changes, and demonstrate that it is an easy to use but still\npowerful tool by demonstrating improvements over not using ML at all on three\nalgorithmic problems: binary search, QuickSort, and caches. In these three\nexamples, we replace the commonly used heuristics with an ML model entirely\nencapsulated within a SmartChoice and thus requiring minimal code changes. As\nopposed to previous work applying ML to algorithmic problems, our proposed\napproach does not require to drop existing implementations but seamlessly\nintegrates into the standard software development workflow and gives full\ncontrol to the software developer over how ML methods are applied. Our\nimplementation relies on standard Reinforcement Learning (RL) methods. To learn\nfaster, we use the heuristic function, which they are replacing, as an initial\nfunction. We show how this initial function can be used to speed up and\nstabilize learning while providing a safety net that prevents performance to\nbecome substantially worse -- allowing for a safe deployment in critical\napplications in real life.\n", "versions": [{"version": "v1", "created": "Mon, 1 Oct 2018 11:14:22 GMT"}, {"version": "v2", "created": "Thu, 28 Feb 2019 11:24:58 GMT"}, {"version": "v3", "created": "Thu, 13 Jun 2019 18:20:51 GMT"}], "update_date": "2019-06-17", "authors_parsed": [["Carbune", "Victor", ""], ["Coppey", "Thierry", ""], ["Daryin", "Alexander", ""], ["Deselaers", "Thomas", ""], ["Sarda", "Nikhil", ""], ["Yagnik", "Jay", ""]]}, {"id": "1810.00656", "submitter": "Patrick Schwab", "authors": "Patrick Schwab, Lorenz Linhardt, Walter Karlen", "title": "Perfect Match: A Simple Method for Learning Representations For\n  Counterfactual Inference With Neural Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Learning representations for counterfactual inference from observational data\nis of high practical relevance for many domains, such as healthcare, public\npolicy and economics. Counterfactual inference enables one to answer \"What\nif...?\" questions, such as \"What would be the outcome if we gave this patient\ntreatment $t_1$?\". However, current methods for training neural networks for\ncounterfactual inference on observational data are either overly complex,\nlimited to settings with only two available treatments, or both. Here, we\npresent Perfect Match (PM), a method for training neural networks for\ncounterfactual inference that is easy to implement, compatible with any\narchitecture, does not add computational complexity or hyperparameters, and\nextends to any number of treatments. PM is based on the idea of augmenting\nsamples within a minibatch with their propensity-matched nearest neighbours.\nOur experiments demonstrate that PM outperforms a number of more complex\nstate-of-the-art methods in inferring counterfactual outcomes across several\nbenchmarks, particularly in settings with many treatments.\n", "versions": [{"version": "v1", "created": "Mon, 1 Oct 2018 12:31:32 GMT"}, {"version": "v2", "created": "Wed, 3 Oct 2018 11:35:15 GMT"}, {"version": "v3", "created": "Thu, 1 Nov 2018 00:47:27 GMT"}, {"version": "v4", "created": "Sun, 3 Feb 2019 22:46:24 GMT"}, {"version": "v5", "created": "Mon, 27 May 2019 16:47:19 GMT"}], "update_date": "2019-05-28", "authors_parsed": [["Schwab", "Patrick", ""], ["Linhardt", "Lorenz", ""], ["Karlen", "Walter", ""]]}, {"id": "1810.00664", "submitter": "Omid Shahmirzadi", "authors": "Omid Shahmirzadi, Adam Lugowski and Kenneth Younge", "title": "Text Similarity in Vector Space Models: A Comparative Study", "comments": "17 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Automatic measurement of semantic text similarity is an important task in\nnatural language processing. In this paper, we evaluate the performance of\ndifferent vector space models to perform this task. We address the real-world\nproblem of modeling patent-to-patent similarity and compare TFIDF (and related\nextensions), topic models (e.g., latent semantic indexing), and neural models\n(e.g., paragraph vectors). Contrary to expectations, the added computational\ncost of text embedding methods is justified only when: 1) the target text is\ncondensed; and 2) the similarity comparison is trivial. Otherwise, TFIDF\nperforms surprisingly well in other cases: in particular for longer and more\ntechnical texts or for making finer-grained distinctions between nearest\nneighbors. Unexpectedly, extensions to the TFIDF method, such as adding noun\nphrases or calculating term weights incrementally, were not helpful in our\ncontext.\n", "versions": [{"version": "v1", "created": "Mon, 24 Sep 2018 10:54:52 GMT"}], "update_date": "2018-10-02", "authors_parsed": [["Shahmirzadi", "Omid", ""], ["Lugowski", "Adam", ""], ["Younge", "Kenneth", ""]]}, {"id": "1810.00668", "submitter": "Sudhanshu Kasewa", "authors": "Sudhanshu Kasewa and Pontus Stenetorp and Sebastian Riedel", "title": "Wronging a Right: Generating Better Errors to Improve Grammatical Error\n  Detection", "comments": "Accepted as a short paper at EMNLP 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Grammatical error correction, like other machine learning tasks, greatly\nbenefits from large quantities of high quality training data, which is\ntypically expensive to produce. While writing a program to automatically\ngenerate realistic grammatical errors would be difficult, one could learn the\ndistribution of naturallyoccurring errors and attempt to introduce them into\nother datasets. Initial work on inducing errors in this way using statistical\nmachine translation has shown promise; we investigate cheaply constructing\nsynthetic samples, given a small corpus of human-annotated data, using an\noff-the-rack attentive sequence-to-sequence model and a straight-forward\npost-processing procedure. Our approach yields error-filled artificial data\nthat helps a vanilla bi-directional LSTM to outperform the previous state of\nthe art at grammatical error detection, and a previously introduced model to\ngain further improvements of over 5% $F_{0.5}$ score. When attempting to\ndetermine if a given sentence is synthetic, a human annotator at best achieves\n39.39 $F_1$ score, indicating that our model generates mostly human-like\ninstances.\n", "versions": [{"version": "v1", "created": "Wed, 26 Sep 2018 14:25:40 GMT"}], "update_date": "2018-10-02", "authors_parsed": [["Kasewa", "Sudhanshu", ""], ["Stenetorp", "Pontus", ""], ["Riedel", "Sebastian", ""]]}, {"id": "1810.00679", "submitter": "Rasool Fakoor", "authors": "Rasool Fakoor, Amanjit Kainth, Siamak Shakeri, Christopher Winestock,\n  Abdel-rahman Mohamed, Ruhi Sarikaya", "title": "Direct optimization of F-measure for retrieval-based personal question\n  answering", "comments": "accepted at SLT2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.CL cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent advances in spoken language technologies and the introduction of many\ncustomer facing products, have given rise to a wide customer reliance on smart\npersonal assistants for many of their daily tasks. In this paper, we present a\nsystem to reduce users' cognitive load by extending personal assistants with\nlong-term personal memory where users can store and retrieve by voice,\narbitrary pieces of information. The problem is framed as a neural retrieval\nbased question answering system where answers are selected from previously\nstored user memories. We propose to directly optimize the end-to-end retrieval\nperformance, measured by the F1-score, using reinforcement learning, leading to\nbetter performance on our experimental test set(s).\n", "versions": [{"version": "v1", "created": "Fri, 28 Sep 2018 00:51:24 GMT"}], "update_date": "2018-10-02", "authors_parsed": [["Fakoor", "Rasool", ""], ["Kainth", "Amanjit", ""], ["Shakeri", "Siamak", ""], ["Winestock", "Christopher", ""], ["Mohamed", "Abdel-rahman", ""], ["Sarikaya", "Ruhi", ""]]}, {"id": "1810.00697", "submitter": "Ye Yuan", "authors": "Ye Yuan, Xiuchuan Tang, Wei Pan, Xiuting Li, Wei Zhou, Hai-Tao Zhang,\n  Han Ding, and Jorge Goncalves", "title": "Data-driven Discovery of Cyber-Physical Systems", "comments": null, "journal-ref": null, "doi": "10.1038/s41467-019-12490-1", "report-no": null, "categories": "cs.SY cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Cyber-physical systems (CPSs) embed software into the physical world. They\nappear in a wide range of applications such as smart grids, robotics,\nintelligent manufacture and medical monitoring. CPSs have proved resistant to\nmodeling due to their intrinsic complexity arising from the combination of\nphysical components and cyber components and the interaction between them. This\nstudy proposes a general framework for reverse engineering CPSs directly from\ndata. The method involves the identification of physical systems as well as the\ninference of transition logic. It has been applied successfully to a number of\nreal-world examples ranging from mechanical and electrical systems to medical\napplications. The novel framework seeks to enable researchers to make\npredictions concerning the trajectory of CPSs based on the discovered model.\nSuch information has been proven essential for the assessment of the\nperformance of CPS, the design of failure-proof CPS and the creation of design\nguidelines for new CPSs.\n", "versions": [{"version": "v1", "created": "Mon, 1 Oct 2018 13:22:41 GMT"}], "update_date": "2019-10-28", "authors_parsed": [["Yuan", "Ye", ""], ["Tang", "Xiuchuan", ""], ["Pan", "Wei", ""], ["Li", "Xiuting", ""], ["Zhou", "Wei", ""], ["Zhang", "Hai-Tao", ""], ["Ding", "Han", ""], ["Goncalves", "Jorge", ""]]}, {"id": "1810.00717", "submitter": "Seyed Amin Fadaee", "authors": "Seyed Amin Fadaee, Maryam Amir Haeri", "title": "Classification Using Link Prediction", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Link prediction in a graph is the problem of detecting the missing links that\nwould be formed in the near future. Using a graph representation of the data,\nwe can convert the problem of classification to the problem of link prediction\nwhich aims at finding the missing links between the unlabeled data (unlabeled\nnodes) and their classes. To our knowledge, despite the fact that numerous\nalgorithms use the graph representation of the data for classification, none\nare using link prediction as the heart of their classifying procedure. In this\nwork, we propose a novel algorithm called CULP (Classification Using Link\nPrediction) which uses a new structure namely Label Embedded Graph or LEG and a\nlink predictor to find the class of the unlabeled data. Different link\npredictors along with Compatibility Score - a new link predictor we proposed\nthat is designed specifically for our settings - has been used and showed\npromising results for classifying different datasets. This paper further\nimproved CULP by designing an extension called CULM which uses a majority vote\n(hence the M in the acronym) procedure with weights proportional to the\npredictions' confidences to use the predictive power of multiple link\npredictors and also exploits the low level features of the data. Extensive\nexperimental evaluations shows that both CULP and CULM are highly accurate and\ncompetitive with the cutting edge graph classifiers and general classifiers.\n", "versions": [{"version": "v1", "created": "Mon, 1 Oct 2018 14:21:33 GMT"}], "update_date": "2018-10-02", "authors_parsed": [["Fadaee", "Seyed Amin", ""], ["Haeri", "Maryam Amir", ""]]}, {"id": "1810.00737", "submitter": "Adrian Rivera Cardoso", "authors": "Adrian Rivera Cardoso, Huan Xu", "title": "Risk-Averse Stochastic Convex Bandit", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Motivated by applications in clinical trials and finance, we study the\nproblem of online convex optimization (with bandit feedback) where the decision\nmaker is risk-averse. We provide two algorithms to solve this problem. The\nfirst one is a descent-type algorithm which is easy to implement. The second\nalgorithm, which combines the ellipsoid method and a center point device,\nachieves (almost) optimal regret bounds with respect to the number of rounds.\nTo the best of our knowledge this is the first attempt to address risk-aversion\nin the online convex bandit problem.\n", "versions": [{"version": "v1", "created": "Mon, 1 Oct 2018 14:48:42 GMT"}], "update_date": "2018-10-02", "authors_parsed": [["Cardoso", "Adrian Rivera", ""], ["Xu", "Huan", ""]]}, {"id": "1810.00740", "submitter": "Chuanbiao Song", "authors": "Chuanbiao Song and Kun He and Liwei Wang and John E. Hopcroft", "title": "Improving the Generalization of Adversarial Training with Domain\n  Adaptation", "comments": "ICLR 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  By injecting adversarial examples into training data, adversarial training is\npromising for improving the robustness of deep learning models. However, most\nexisting adversarial training approaches are based on a specific type of\nadversarial attack. It may not provide sufficiently representative samples from\nthe adversarial domain, leading to a weak generalization ability on adversarial\nexamples from other attacks. Moreover, during the adversarial training,\nadversarial perturbations on inputs are usually crafted by fast single-step\nadversaries so as to scale to large datasets. This work is mainly focused on\nthe adversarial training yet efficient FGSM adversary. In this scenario, it is\ndifficult to train a model with great generalization due to the lack of\nrepresentative adversarial samples, aka the samples are unable to accurately\nreflect the adversarial domain. To alleviate this problem, we propose a novel\nAdversarial Training with Domain Adaptation (ATDA) method. Our intuition is to\nregard the adversarial training on FGSM adversary as a domain adaption task\nwith limited number of target domain samples. The main idea is to learn a\nrepresentation that is semantically meaningful and domain invariant on the\nclean domain as well as the adversarial domain. Empirical evaluations on\nFashion-MNIST, SVHN, CIFAR-10 and CIFAR-100 demonstrate that ATDA can greatly\nimprove the generalization of adversarial training and the smoothness of the\nlearned models, and outperforms state-of-the-art methods on standard benchmark\ndatasets. To show the transfer ability of our method, we also extend ATDA to\nthe adversarial training on iterative attacks such as PGD-Adversial Training\n(PAT) and the defense performance is improved considerably.\n", "versions": [{"version": "v1", "created": "Mon, 1 Oct 2018 14:52:08 GMT"}, {"version": "v2", "created": "Sat, 20 Oct 2018 09:00:02 GMT"}, {"version": "v3", "created": "Wed, 24 Oct 2018 13:29:39 GMT"}, {"version": "v4", "created": "Mon, 10 Dec 2018 08:43:35 GMT"}, {"version": "v5", "created": "Thu, 17 Jan 2019 05:13:22 GMT"}, {"version": "v6", "created": "Mon, 11 Mar 2019 11:22:56 GMT"}, {"version": "v7", "created": "Fri, 15 Mar 2019 08:37:29 GMT"}], "update_date": "2019-03-18", "authors_parsed": [["Song", "Chuanbiao", ""], ["He", "Kun", ""], ["Wang", "Liwei", ""], ["Hopcroft", "John E.", ""]]}, {"id": "1810.00746", "submitter": "Apratim Bhattacharyya", "authors": "Apratim Bhattacharyya, Mario Fritz, Bernt Schiele", "title": "Bayesian Prediction of Future Street Scenes using Synthetic Likelihoods", "comments": "To appear in ICLR 2019. arXiv admin note: text overlap with\n  arXiv:1806.06939", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  For autonomous agents to successfully operate in the real world, the ability\nto anticipate future scene states is a key competence. In real-world scenarios,\nfuture states become increasingly uncertain and multi-modal, particularly on\nlong time horizons. Dropout based Bayesian inference provides a computationally\ntractable, theoretically well grounded approach to learn likely\nhypotheses/models to deal with uncertain futures and make predictions that\ncorrespond well to observations -- are well calibrated. However, it turns out\nthat such approaches fall short to capture complex real-world scenes, even\nfalling behind in accuracy when compared to the plain deterministic approaches.\nThis is because the used log-likelihood estimate discourages diversity. In this\nwork, we propose a novel Bayesian formulation for anticipating future scene\nstates which leverages synthetic likelihoods that encourage the learning of\ndiverse models to accurately capture the multi-modal nature of future scene\nstates. We show that our approach achieves accurate state-of-the-art\npredictions and calibrated probabilities through extensive experiments for\nscene anticipation on Cityscapes dataset. Moreover, we show that our approach\ngeneralizes across diverse tasks such as digit generation and precipitation\nforecasting.\n", "versions": [{"version": "v1", "created": "Mon, 1 Oct 2018 15:02:54 GMT"}, {"version": "v2", "created": "Tue, 2 Oct 2018 14:19:54 GMT"}, {"version": "v3", "created": "Fri, 18 Jan 2019 08:09:47 GMT"}], "update_date": "2019-01-23", "authors_parsed": [["Bhattacharyya", "Apratim", ""], ["Fritz", "Mario", ""], ["Schiele", "Bernt", ""]]}, {"id": "1810.00760", "submitter": "Gary B\\'ecigneul", "authors": "Gary B\\'ecigneul, Octavian-Eugen Ganea", "title": "Riemannian Adaptive Optimization Methods", "comments": "Accepted at International Conference on Learning Representations\n  (ICLR), 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Several first order stochastic optimization methods commonly used in the\nEuclidean domain such as stochastic gradient descent (SGD), accelerated\ngradient descent or variance reduced methods have already been adapted to\ncertain Riemannian settings. However, some of the most popular of these\noptimization tools - namely Adam , Adagrad and the more recent Amsgrad - remain\nto be generalized to Riemannian manifolds. We discuss the difficulty of\ngeneralizing such adaptive schemes to the most agnostic Riemannian setting, and\nthen provide algorithms and convergence proofs for geodesically convex\nobjectives in the particular case of a product of Riemannian manifolds, in\nwhich adaptivity is implemented across manifolds in the cartesian product. Our\ngeneralization is tight in the sense that choosing the Euclidean space as\nRiemannian manifold yields the same algorithms and regret bounds as those that\nwere already known for the standard algorithms. Experimentally, we show faster\nconvergence and to a lower train loss value for Riemannian adaptive methods\nover their corresponding baselines on the realistic task of embedding the\nWordNet taxonomy in the Poincare ball.\n", "versions": [{"version": "v1", "created": "Mon, 1 Oct 2018 15:31:36 GMT"}, {"version": "v2", "created": "Mon, 18 Feb 2019 02:32:53 GMT"}], "update_date": "2019-02-19", "authors_parsed": [["B\u00e9cigneul", "Gary", ""], ["Ganea", "Octavian-Eugen", ""]]}, {"id": "1810.00782", "submitter": "Filip Ilievski", "authors": "Filip Ilievski, Eduard Hovy, Qizhe Xie, Piek Vossen", "title": "The Profiling Machine: Active Generalization over Knowledge", "comments": "AAAI2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The human mind is a powerful multifunctional knowledge storage and management\nsystem that performs generalization, type inference, anomaly detection,\nstereotyping, and other tasks. A dynamic KR system that appropriately profiles\nover sparse inputs to provide complete expectations for unknown facets can help\nwith all these tasks. In this paper, we introduce the task of profiling,\ninspired by theories and findings in social psychology about the potential of\nprofiles for reasoning and information processing. We describe two generic\nstate-of-the-art neural architectures that can be easily instantiated as\nprofiling machines to generate expectations and applied to any kind of\nknowledge to fill gaps. We evaluate these methods against Wikidata and crowd\nexpectations, and compare the results to gain insight in the nature of\nknowledge captured by various profiling methods. We make all code and data\navailable to facilitate future research.\n", "versions": [{"version": "v1", "created": "Mon, 1 Oct 2018 16:03:49 GMT"}], "update_date": "2018-10-02", "authors_parsed": [["Ilievski", "Filip", ""], ["Hovy", "Eduard", ""], ["Xie", "Qizhe", ""], ["Vossen", "Piek", ""]]}, {"id": "1810.00787", "submitter": "Veronika Rockova", "authors": "Veronika Rockova and Enakshi Saha", "title": "On Theory for BART", "comments": "22", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Ensemble learning is a statistical paradigm built on the premise that many\nweak learners can perform exceptionally well when deployed collectively. The\nBART method of Chipman et al. (2010) is a prominent example of Bayesian\nensemble learning, where each learner is a tree. Due to its impressive\nperformance, BART has received a lot of attention from practitioners. Despite\nits wide popularity, however, theoretical studies of BART have begun emerging\nonly very recently. Laying the foundations for the theoretical analysis of\nBayesian forests, Rockova and van der Pas (2017) showed optimal posterior\nconcentration under conditionally uniform tree priors. These priors deviate\nfrom the actual priors implemented in BART. Here, we study the exact BART prior\nand propose a simple modification so that it also enjoys optimality properties.\nTo this end, we dive into branching process theory. We obtain tail bounds for\nthe distribution of total progeny under heterogeneous Galton-Watson (GW)\nprocesses exploiting their connection to random walks. We conclude with a\nresult stating the optimal rate of posterior convergence for BART.\n", "versions": [{"version": "v1", "created": "Mon, 1 Oct 2018 16:18:59 GMT"}, {"version": "v2", "created": "Fri, 5 Oct 2018 17:04:10 GMT"}], "update_date": "2018-10-08", "authors_parsed": [["Rockova", "Veronika", ""], ["Saha", "Enakshi", ""]]}, {"id": "1810.00803", "submitter": "Dennis Forster", "authors": "Florian Hirschberger, Dennis Forster, J\\\"org L\\\"ucke", "title": "Large Scale Clustering with Variational EM for Gaussian Mixture Models", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  How can we efficiently find large numbers of clusters in large data sets with\nhigh-dimensional data points? Our aim is to explore the current efficiency and\nlarge-scale limits in fitting a parametric model for clustering to data\ndistributions. To do so, we combine recent lines of research which have\npreviously focused on separate specific methods for complexity reduction. We\nfirst show theoretically how the clustering objective of variational EM (which\nreduces complexity for many clusters) can be combined with coreset objectives\n(which reduce complexity for many data points). Secondly, we realize a concrete\nhighly efficient iterative procedure which combines and translates the\ntheoretical complexity gains of truncated variational EM and coresets into a\npractical algorithm. For very large scales, the high efficiency of parameter\nupdates then requires (A) highly efficient coreset construction and (B) highly\nefficient initialization procedures (seeding) in order to avoid computational\nbottlenecks. Fortunately very efficient coreset construction has become\navailable in the form of light-weight coresets, and very efficient\ninitialization has become available in the form of AFK-MC$^2$ seeding. The\nresulting algorithm features balanced computational costs across all\nconstituting components. In applications to standard large-scale benchmarks for\nclustering, we investigate the algorithm's efficiency/quality trade-off.\nCompared to the best recent approaches, we observe speedups of up to one order\nof magnitude, and up to two orders of magnitude compared to the $k$-means++\nbaseline. To demonstrate that the observed efficiency enables previously\nconsidered unfeasible applications, we cluster the entire and unscaled 80 Mio.\nTiny Images dataset into up to 32,000 clusters. To the knowledge of the\nauthors, this represents the largest scale fit of a parametric data model for\nclustering reported so far.\n", "versions": [{"version": "v1", "created": "Mon, 1 Oct 2018 16:34:51 GMT"}, {"version": "v2", "created": "Tue, 12 Feb 2019 12:09:15 GMT"}, {"version": "v3", "created": "Fri, 7 Jun 2019 16:12:38 GMT"}], "update_date": "2019-06-10", "authors_parsed": [["Hirschberger", "Florian", ""], ["Forster", "Dennis", ""], ["L\u00fccke", "J\u00f6rg", ""]]}, {"id": "1810.00821", "submitter": "Xue Bin Peng", "authors": "Xue Bin Peng, Angjoo Kanazawa, Sam Toyer, Pieter Abbeel, Sergey Levine", "title": "Variational Discriminator Bottleneck: Improving Imitation Learning,\n  Inverse RL, and GANs by Constraining Information Flow", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Adversarial learning methods have been proposed for a wide range of\napplications, but the training of adversarial models can be notoriously\nunstable. Effectively balancing the performance of the generator and\ndiscriminator is critical, since a discriminator that achieves very high\naccuracy will produce relatively uninformative gradients. In this work, we\npropose a simple and general technique to constrain information flow in the\ndiscriminator by means of an information bottleneck. By enforcing a constraint\non the mutual information between the observations and the discriminator's\ninternal representation, we can effectively modulate the discriminator's\naccuracy and maintain useful and informative gradients. We demonstrate that our\nproposed variational discriminator bottleneck (VDB) leads to significant\nimprovements across three distinct application areas for adversarial learning\nalgorithms. Our primary evaluation studies the applicability of the VDB to\nimitation learning of dynamic continuous control skills, such as running. We\nshow that our method can learn such skills directly from \\emph{raw} video\ndemonstrations, substantially outperforming prior adversarial imitation\nlearning methods. The VDB can also be combined with adversarial inverse\nreinforcement learning to learn parsimonious reward functions that can be\ntransferred and re-optimized in new settings. Finally, we demonstrate that VDB\ncan train GANs more effectively for image generation, improving upon a number\nof prior stabilization methods.\n", "versions": [{"version": "v1", "created": "Mon, 1 Oct 2018 17:02:24 GMT"}, {"version": "v2", "created": "Mon, 24 Dec 2018 07:18:08 GMT"}, {"version": "v3", "created": "Sat, 29 Dec 2018 00:03:45 GMT"}, {"version": "v4", "created": "Tue, 25 Aug 2020 02:41:11 GMT"}], "update_date": "2020-08-26", "authors_parsed": [["Peng", "Xue Bin", ""], ["Kanazawa", "Angjoo", ""], ["Toyer", "Sam", ""], ["Abbeel", "Pieter", ""], ["Levine", "Sergey", ""]]}, {"id": "1810.00825", "submitter": "Juho Lee", "authors": "Juho Lee, Yoonho Lee, Jungtaek Kim, Adam R. Kosiorek, Seungjin Choi,\n  Yee Whye Teh", "title": "Set Transformer: A Framework for Attention-based Permutation-Invariant\n  Neural Networks", "comments": "ICML 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Many machine learning tasks such as multiple instance learning, 3D shape\nrecognition, and few-shot image classification are defined on sets of\ninstances. Since solutions to such problems do not depend on the order of\nelements of the set, models used to address them should be permutation\ninvariant. We present an attention-based neural network module, the Set\nTransformer, specifically designed to model interactions among elements in the\ninput set. The model consists of an encoder and a decoder, both of which rely\non attention mechanisms. In an effort to reduce computational complexity, we\nintroduce an attention scheme inspired by inducing point methods from sparse\nGaussian process literature. It reduces the computation time of self-attention\nfrom quadratic to linear in the number of elements in the set. We show that our\nmodel is theoretically attractive and we evaluate it on a range of tasks,\ndemonstrating the state-of-the-art performance compared to recent methods for\nset-structured data.\n", "versions": [{"version": "v1", "created": "Mon, 1 Oct 2018 17:10:03 GMT"}, {"version": "v2", "created": "Thu, 24 Jan 2019 10:19:12 GMT"}, {"version": "v3", "created": "Sun, 26 May 2019 06:05:29 GMT"}], "update_date": "2019-05-28", "authors_parsed": [["Lee", "Juho", ""], ["Lee", "Yoonho", ""], ["Kim", "Jungtaek", ""], ["Kosiorek", "Adam R.", ""], ["Choi", "Seungjin", ""], ["Teh", "Yee Whye", ""]]}, {"id": "1810.00826", "submitter": "Keyulu Xu", "authors": "Keyulu Xu, Weihua Hu, Jure Leskovec, Stefanie Jegelka", "title": "How Powerful are Graph Neural Networks?", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Graph Neural Networks (GNNs) are an effective framework for representation\nlearning of graphs. GNNs follow a neighborhood aggregation scheme, where the\nrepresentation vector of a node is computed by recursively aggregating and\ntransforming representation vectors of its neighboring nodes. Many GNN variants\nhave been proposed and have achieved state-of-the-art results on both node and\ngraph classification tasks. However, despite GNNs revolutionizing graph\nrepresentation learning, there is limited understanding of their\nrepresentational properties and limitations. Here, we present a theoretical\nframework for analyzing the expressive power of GNNs to capture different graph\nstructures. Our results characterize the discriminative power of popular GNN\nvariants, such as Graph Convolutional Networks and GraphSAGE, and show that\nthey cannot learn to distinguish certain simple graph structures. We then\ndevelop a simple architecture that is provably the most expressive among the\nclass of GNNs and is as powerful as the Weisfeiler-Lehman graph isomorphism\ntest. We empirically validate our theoretical findings on a number of graph\nclassification benchmarks, and demonstrate that our model achieves\nstate-of-the-art performance.\n", "versions": [{"version": "v1", "created": "Mon, 1 Oct 2018 17:11:31 GMT"}, {"version": "v2", "created": "Wed, 26 Dec 2018 07:44:16 GMT"}, {"version": "v3", "created": "Fri, 22 Feb 2019 19:15:54 GMT"}], "update_date": "2019-02-26", "authors_parsed": [["Xu", "Keyulu", ""], ["Hu", "Weihua", ""], ["Leskovec", "Jure", ""], ["Jegelka", "Stefanie", ""]]}, {"id": "1810.00829", "submitter": "Ran Tian", "authors": "Ran Tian, Sisi Li, Nan Li, Ilya Kolmanovsky, Anouck Girard and\n  Yildiray Yildiz", "title": "Adaptive Game-Theoretic Decision Making for Autonomous Vehicle Control\n  at Roundabouts", "comments": "2018 IEEE Conference on Decision and Control (CDC)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.GT cs.LG cs.RO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we propose a decision making algorithm for autonomous vehicle\ncontrol at a roundabout intersection. The algorithm is based on a\ngame-theoretic model representing the interactions between the ego vehicle and\nan opponent vehicle, and adapts to an online estimated driver type of the\nopponent vehicle. Simulation results are reported.\n", "versions": [{"version": "v1", "created": "Mon, 1 Oct 2018 17:17:03 GMT"}], "update_date": "2018-10-02", "authors_parsed": [["Tian", "Ran", ""], ["Li", "Sisi", ""], ["Li", "Nan", ""], ["Kolmanovsky", "Ilya", ""], ["Girard", "Anouck", ""], ["Yildiz", "Yildiray", ""]]}, {"id": "1810.00839", "submitter": "Xiang Li", "authors": "Xiang Li, Qitian Chen, Xing Wang, Ning Guo, Nan Wu, Quanzheng Li", "title": "Network Modeling and Pathway Inference from Incomplete Data (\"PathInf\")", "comments": "Xiang Li, Qitian Che and Xing Wang contribute equally to this work", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this work, we developed a network inference method from incomplete data\n(\"PathInf\") , as massive and non-uniformly distributed missing values is a\ncommon challenge in practical problems. PathInf is a two-stages inference\nmodel. In the first stage, it applies a data summarization model based on\nmaximum likelihood to deal with the massive distributed missing values by\ntransforming the observation-wise items in the data into state matrix. In the\nsecond stage, transition pattern (i.e. pathway) among variables is inferred as\na graph inference problem solved by greedy algorithm with constraints. The\nproposed method was validated and compared with the state-of-art Bayesian\nnetwork method on the simulation data, and shown consistently superior\nperformance. By applying the PathInf on the lymph vascular metastasis data, we\nobtained the holistic pathways of the lymph node metastasis with novel\ndiscoveries on the jumping metastasis among nodes that are physically apart.\nThe discovery indicates the possible presence of sentinel node groups in the\nlung lymph nodes which have been previously speculated yet never found. The\npathway map can also improve the current dissection examination protocol for\nbetter individualized treatment planning, for higher diagnostic accuracy and\nreducing the patients trauma.\n", "versions": [{"version": "v1", "created": "Mon, 1 Oct 2018 17:31:34 GMT"}], "update_date": "2018-10-02", "authors_parsed": [["Li", "Xiang", ""], ["Chen", "Qitian", ""], ["Wang", "Xing", ""], ["Guo", "Ning", ""], ["Wu", "Nan", ""], ["Li", "Quanzheng", ""]]}, {"id": "1810.00845", "submitter": "Olli Saarikivi", "authors": "Roshan Dathathri, Olli Saarikivi, Hao Chen, Kim Laine, Kristin Lauter,\n  Saeed Maleki, Madanlal Musuvathi, Todd Mytkowicz", "title": "CHET: Compiler and Runtime for Homomorphic Evaluation of Tensor Programs", "comments": "Submitted to ASPLOS2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR cs.PL stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Fully Homomorphic Encryption (FHE) refers to a set of encryption schemes that\nallow computations to be applied directly on encrypted data without requiring a\nsecret key. This enables novel application scenarios where a client can safely\noffload storage and computation to a third-party cloud provider without having\nto trust the software and the hardware vendors with the decryption keys. Recent\nadvances in both FHE schemes and implementations have moved such applications\nfrom theoretical possibilities into the realm of practicalities.\n  This paper proposes a compact and well-reasoned interface called the\nHomomorphic Instruction Set Architecture (HISA) for developing FHE\napplications. Just as the hardware ISA interface enabled hardware advances to\nproceed independent of software advances in the compiler and language runtimes,\nHISA decouples compiler optimizations and runtimes for supporting FHE\napplications from advancements in the underlying FHE schemes.\n  This paper demonstrates the capabilities of HISA by building an end-to-end\nsoftware stack for evaluating neural network models on encrypted data. Our\nstack includes an end-to-end compiler, runtime, and a set of optimizations. Our\napproach shows generated code, on a set of popular neural network\narchitectures, is faster than hand-optimized implementations.\n", "versions": [{"version": "v1", "created": "Mon, 1 Oct 2018 17:38:53 GMT"}], "update_date": "2018-10-02", "authors_parsed": [["Dathathri", "Roshan", ""], ["Saarikivi", "Olli", ""], ["Chen", "Hao", ""], ["Laine", "Kim", ""], ["Lauter", "Kristin", ""], ["Maleki", "Saeed", ""], ["Musuvathi", "Madanlal", ""], ["Mytkowicz", "Todd", ""]]}, {"id": "1810.00846", "submitter": "Yu-Guan Hsieh", "authors": "Yu-Guan Hsieh, Gang Niu, Masashi Sugiyama", "title": "Classification from Positive, Unlabeled and Biased Negative Data", "comments": "In Proceedings of the 36th International Conference on Machine\n  Learning (ICML 2019)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In binary classification, there are situations where negative (N) data are\ntoo diverse to be fully labeled and we often resort to positive-unlabeled (PU)\nlearning in these scenarios. However, collecting a non-representative N set\nthat contains only a small portion of all possible N data can often be much\neasier in practice. This paper studies a novel classification framework which\nincorporates such biased N (bN) data in PU learning. We provide a method based\non empirical risk minimization to address this PUbN classification problem. Our\napproach can be regarded as a novel example-weighting algorithm, with the\nweight of each example computed through a preliminary step that draws\ninspiration from PU learning. We also derive an estimation error bound for the\nproposed method. Experimental results demonstrate the effectiveness of our\nalgorithm in not only PUbN learning scenarios but also ordinary PU learning\nscenarios on several benchmark datasets.\n", "versions": [{"version": "v1", "created": "Mon, 1 Oct 2018 17:38:58 GMT"}, {"version": "v2", "created": "Sat, 13 Jul 2019 12:16:18 GMT"}], "update_date": "2019-07-16", "authors_parsed": [["Hsieh", "Yu-Guan", ""], ["Niu", "Gang", ""], ["Sugiyama", "Masashi", ""]]}, {"id": "1810.00859", "submitter": "Liu Liu", "authors": "Liu Liu, Lei Deng, Xing Hu, Maohua Zhu, Guoqi Li, Yufei Ding, Yuan Xie", "title": "Dynamic Sparse Graph for Efficient Deep Learning", "comments": "ICLR 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose to execute deep neural networks (DNNs) with dynamic and sparse\ngraph (DSG) structure for compressive memory and accelerative execution during\nboth training and inference. The great success of DNNs motivates the pursuing\nof lightweight models for the deployment onto embedded devices. However, most\nof the previous studies optimize for inference while neglect training or even\ncomplicate it. Training is far more intractable, since (i) the neurons dominate\nthe memory cost rather than the weights in inference; (ii) the dynamic\nactivation makes previous sparse acceleration via one-off optimization on fixed\nweight invalid; (iii) batch normalization (BN) is critical for maintaining\naccuracy while its activation reorganization damages the sparsity. To address\nthese issues, DSG activates only a small amount of neurons with high\nselectivity at each iteration via a dimension-reduction search (DRS) and\nobtains the BN compatibility via a double-mask selection (DMS). Experiments\nshow significant memory saving (1.7-4.5x) and operation reduction (2.3-4.4x)\nwith little accuracy loss on various benchmarks.\n", "versions": [{"version": "v1", "created": "Mon, 1 Oct 2018 17:55:43 GMT"}, {"version": "v2", "created": "Tue, 7 May 2019 02:32:25 GMT"}], "update_date": "2019-05-08", "authors_parsed": [["Liu", "Liu", ""], ["Deng", "Lei", ""], ["Hu", "Xing", ""], ["Zhu", "Maohua", ""], ["Li", "Guoqi", ""], ["Ding", "Yufei", ""], ["Xie", "Yuan", ""]]}, {"id": "1810.00861", "submitter": "Yu Bai", "authors": "Yu Bai, Yu-Xiang Wang, Edo Liberty", "title": "ProxQuant: Quantized Neural Networks via Proximal Operators", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  To make deep neural networks feasible in resource-constrained environments\n(such as mobile devices), it is beneficial to quantize models by using\nlow-precision weights. One common technique for quantizing neural networks is\nthe straight-through gradient method, which enables back-propagation through\nthe quantization mapping. Despite its empirical success, little is understood\nabout why the straight-through gradient method works.\n  Building upon a novel observation that the straight-through gradient method\nis in fact identical to the well-known Nesterov's dual-averaging algorithm on a\nquantization constrained optimization problem, we propose a more principled\nalternative approach, called ProxQuant, that formulates quantized network\ntraining as a regularized learning problem instead and optimizes it via the\nprox-gradient method. ProxQuant does back-propagation on the underlying\nfull-precision vector and applies an efficient prox-operator in between\nstochastic gradient steps to encourage quantizedness. For quantizing ResNets\nand LSTMs, ProxQuant outperforms state-of-the-art results on binary\nquantization and is on par with state-of-the-art on multi-bit quantization. For\nbinary quantization, our analysis shows both theoretically and experimentally\nthat ProxQuant is more stable than the straight-through gradient method (i.e.\nBinaryConnect), challenging the indispensability of the straight-through\ngradient method and providing a powerful alternative.\n", "versions": [{"version": "v1", "created": "Mon, 1 Oct 2018 17:57:02 GMT"}, {"version": "v2", "created": "Mon, 8 Oct 2018 17:46:55 GMT"}, {"version": "v3", "created": "Tue, 5 Mar 2019 00:28:48 GMT"}], "update_date": "2019-03-06", "authors_parsed": [["Bai", "Yu", ""], ["Wang", "Yu-Xiang", ""], ["Liberty", "Edo", ""]]}, {"id": "1810.00867", "submitter": "Lingwei Xie", "authors": "Lingwei Xie, Song He, Shu Yang, Boyuan Feng, Kun Wan, Zhongnan Zhang,\n  Xiaochen Bo, Yufei Ding", "title": "Domain-Adversarial Multi-Task Framework for Novel Therapeutic Property\n  Prediction of Compounds", "comments": "9 pages, 6 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  With the rapid development of high-throughput technologies, parallel\nacquisition of large-scale drug-informatics data provides huge opportunities to\nimprove pharmaceutical research and development. One significant application is\nthe purpose prediction of small molecule compounds, aiming to specify\ntherapeutic properties of extensive purpose-unknown compounds and to repurpose\nnovel therapeutic properties of FDA-approved drugs. Such problem is very\nchallenging since compound attributes contain heterogeneous data with various\nfeature patterns such as drug fingerprint, drug physicochemical property, drug\nperturbation gene expression. Moreover, there is complex nonlinear dependency\namong heterogeneous data. In this paper, we propose a novel domain-adversarial\nmulti-task framework for integrating shared knowledge from multiple domains.\nThe framework utilizes the adversarial strategy to effectively learn target\nrepresentations and models their nonlinear dependency. Experiments on two\nreal-world datasets illustrate that the performance of our approach obtains an\nobvious improvement over competitive baselines. The novel therapeutic\nproperties of purpose-unknown compounds we predicted are mostly reported or\nbrought to the clinics. Furthermore, our framework can integrate various\nattributes beyond the three domains examined here and can be applied in the\nindustry for screening the purpose of huge amounts of as yet unidentified\ncompounds. Source codes of this paper are available on Github.\n", "versions": [{"version": "v1", "created": "Fri, 28 Sep 2018 23:58:23 GMT"}], "update_date": "2018-10-03", "authors_parsed": [["Xie", "Lingwei", ""], ["He", "Song", ""], ["Yang", "Shu", ""], ["Feng", "Boyuan", ""], ["Wan", "Kun", ""], ["Zhang", "Zhongnan", ""], ["Bo", "Xiaochen", ""], ["Ding", "Yufei", ""]]}, {"id": "1810.00869", "submitter": "Andrew Ross", "authors": "Andrew Slavin Ross", "title": "Training Machine Learning Models by Regularizing their Explanations", "comments": "Harvard CSE master's thesis; includes portions of arxiv:1703.03717\n  and arxiv:1711.09404", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Neural networks are among the most accurate supervised learning methods in\nuse today. However, their opacity makes them difficult to trust in critical\napplications, especially when conditions in training may differ from those in\npractice. Recent efforts to develop explanations for neural networks and\nmachine learning models more generally have produced tools to shed light on the\nimplicit rules behind predictions. These tools can help us identify when models\nare right for the wrong reasons. However, they do not always scale to\nexplaining predictions for entire datasets, are not always at the right level\nof abstraction, and most importantly cannot correct the problems they reveal.\nIn this thesis, we explore the possibility of training machine learning models\n(with a particular focus on neural networks) using explanations themselves. We\nconsider approaches where models are penalized not only for making incorrect\npredictions but also for providing explanations that are either inconsistent\nwith domain knowledge or overly complex. These methods let us train models\nwhich can not only provide more interpretable rationales for their predictions\nbut also generalize better when training data is confounded or meaningfully\ndifferent from test data (even adversarially so).\n", "versions": [{"version": "v1", "created": "Sat, 29 Sep 2018 17:43:21 GMT"}], "update_date": "2018-10-03", "authors_parsed": [["Ross", "Andrew Slavin", ""]]}, {"id": "1810.00873", "submitter": "Louis Mandel", "authors": "Guillaume Baudart, Javier Burroni, Martin Hirzel, Louis Mandel,\n  Avraham Shinnar", "title": "Compiling Stan to Generative Probabilistic Languages and Extension to\n  Deep Probabilistic Programming", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.PL stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Stan is a probabilistic programming language that is popular in the\nstatistics community, with a high-level syntax for expressing probabilistic\nmodels. Stan differs by nature from generative probabilistic programming\nlanguages like Church, Anglican, or Pyro. This paper presents a comprehensive\ncompilation scheme to compile any Stan model to a generative language and\nproves its correctness. We use our compilation scheme to build two new backends\nfor the Stanc3 compiler targeting Pyro and NumPyro. Experimental results show\nthat the NumPyro backend yields a 2.3x speedup compared to Stan in geometric\nmean over 26 benchmarks. Building on Pyro we extend Stan with support for\nexplicit variational inference guides and deep probabilistic models. That way,\nusers familiar with Stan get access to new features without having to learn a\nfundamentally new language.\n", "versions": [{"version": "v1", "created": "Sun, 30 Sep 2018 15:39:53 GMT"}, {"version": "v2", "created": "Wed, 1 Jul 2020 20:45:47 GMT"}, {"version": "v3", "created": "Mon, 3 Aug 2020 16:29:27 GMT"}, {"version": "v4", "created": "Tue, 12 Jan 2021 20:51:14 GMT"}, {"version": "v5", "created": "Sun, 11 Apr 2021 15:34:02 GMT"}], "update_date": "2021-04-13", "authors_parsed": [["Baudart", "Guillaume", ""], ["Burroni", "Javier", ""], ["Hirzel", "Martin", ""], ["Mandel", "Louis", ""], ["Shinnar", "Avraham", ""]]}, {"id": "1810.00877", "submitter": "Quan Geng", "authors": "Quan Geng, Wei Ding, Ruiqi Guo, and Sanjiv Kumar", "title": "Privacy and Utility Tradeoff in Approximate Differential Privacy", "comments": "15 pages, 3 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We characterize the minimum noise amplitude and power for noise-adding\nmechanisms in $(\\epsilon, \\delta)$-differential privacy for single real-valued\nquery function. We derive new lower bounds using the duality of linear\nprogramming, and new upper bounds by proposing a new class of\n$(\\epsilon,\\delta)$-differentially private mechanisms, the \\emph{truncated\nLaplacian} mechanisms. We show that the multiplicative gap of the lower bounds\nand upper bounds goes to zero in various high privacy regimes, proving the\ntightness of the lower and upper bounds and thus establishing the optimality of\nthe truncated Laplacian mechanism. In particular, our results close the\nprevious constant multiplicative gap in the discrete setting. Numeric\nexperiments show the improvement of the truncated Laplacian mechanism over the\noptimal Gaussian mechanism in all privacy regimes.\n", "versions": [{"version": "v1", "created": "Mon, 1 Oct 2018 17:54:17 GMT"}, {"version": "v2", "created": "Tue, 5 Feb 2019 16:41:34 GMT"}], "update_date": "2019-02-06", "authors_parsed": [["Geng", "Quan", ""], ["Ding", "Wei", ""], ["Guo", "Ruiqi", ""], ["Kumar", "Sanjiv", ""]]}, {"id": "1810.00912", "submitter": "Jianwei Yang", "authors": "Jianwei Yang, Jiasen Lu, Stefan Lee, Dhruv Batra, Devi Parikh", "title": "Visual Curiosity: Learning to Ask Questions to Learn Visual Recognition", "comments": "18 pages, 10 figures, Oral Presentation in Conference on Robot\n  Learning (CoRL) 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.AI cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In an open-world setting, it is inevitable that an intelligent agent (e.g., a\nrobot) will encounter visual objects, attributes or relationships it does not\nrecognize. In this work, we develop an agent empowered with visual curiosity,\ni.e. the ability to ask questions to an Oracle (e.g., human) about the contents\nin images (e.g., What is the object on the left side of the red cube?) and\nbuild visual recognition model based on the answers received (e.g., Cylinder).\nIn order to do this, the agent must (1) understand what it recognizes and what\nit does not, (2) formulate a valid, unambiguous and informative language query\n(a question) to ask the Oracle, (3) derive the parameters of visual classifiers\nfrom the Oracle response and (4) leverage the updated visual classifiers to ask\nmore clarified questions. Specifically, we propose a novel framework and\nformulate the learning of visual curiosity as a reinforcement learning problem.\nIn this framework, all components of our agent, visual recognition module (to\nsee), question generation policy (to ask), answer digestion module (to\nunderstand) and graph memory module (to memorize), are learned entirely\nend-to-end to maximize the reward derived from the scene graph obtained by the\nagent as a consequence of the dialog with the Oracle. Importantly, the question\ngeneration policy is disentangled from the visual recognition system and\nspecifics of the environment. Consequently, we demonstrate a sort of double\ngeneralization. Our question generation policy generalizes to new environments\nand a new pair of eyes, i.e., new visual system. Trained on a synthetic\ndataset, our results show that our agent learns new visual concepts\nsignificantly faster than several heuristic baselines, even when tested on\nsynthetic environments with novel objects, as well as in a realistic\nenvironment.\n", "versions": [{"version": "v1", "created": "Mon, 1 Oct 2018 18:37:05 GMT"}], "update_date": "2018-10-03", "authors_parsed": [["Yang", "Jianwei", ""], ["Lu", "Jiasen", ""], ["Lee", "Stefan", ""], ["Batra", "Dhruv", ""], ["Parikh", "Devi", ""]]}, {"id": "1810.00919", "submitter": "Irene Epifanio", "authors": "Jes\\'us Moliner, Irene Epifanio", "title": "Robust multivariate and functional archetypal analysis with application\n  to financial time series analysis", "comments": "Physica A: Statistical Mechanics and its Applications, 2019", "journal-ref": null, "doi": "10.1016/j.physa.2018.12.036", "report-no": null, "categories": "stat.ML cs.LG stat.AP stat.ME", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Archetypal analysis approximates data by means of mixtures of actual extreme\ncases (archetypoids) or archetypes, which are a convex combination of cases in\nthe data set. Archetypes lie on the boundary of the convex hull. This makes the\nanalysis very sensitive to outliers. A robust methodology by means of\nM-estimators for classical multivariate and functional data is proposed. This\nunsupervised methodology allows complex data to be understood even by\nnon-experts. The performance of the new procedure is assessed in a simulation\nstudy, where a comparison with a previous methodology for the multivariate case\nis also carried out, and our proposal obtains favorable results. Finally,\nrobust bivariate functional archetypoid analysis is applied to a set of\ncompanies in the S\\&P 500 described by two time series of stock quotes. A new\ngraphic representation is also proposed to visualize the results. The analysis\nshows how the information can be easily interpreted and how even non-experts\ncan gain a qualitative understanding of the data.\n", "versions": [{"version": "v1", "created": "Mon, 1 Oct 2018 18:48:26 GMT"}, {"version": "v2", "created": "Sat, 22 Dec 2018 17:18:57 GMT"}], "update_date": "2018-12-31", "authors_parsed": [["Moliner", "Jes\u00fas", ""], ["Epifanio", "Irene", ""]]}, {"id": "1810.00924", "submitter": "Matthieu Riou", "authors": "Matthieu Riou, Bassam Jabaian, St\\'ephane Huet and Fabrice Lef\\`evre", "title": "Joint On-line Learning of a Zero-shot Spoken Semantic Parser and a\n  Reinforcement Learning Dialogue Manager", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Despite many recent advances for the design of dialogue systems, a true\nbottleneck remains the acquisition of data required to train its components.\nUnlike many other language processing applications, dialogue systems require\ninteractions with users, therefore it is complex to develop them with\npre-recorded data. Building on previous works, on-line learning is pursued here\nas a most convenient way to address the issue. Data collection, annotation and\nuse in learning algorithms are performed in a single process. The main\ndifficulties are then: to bootstrap an initial basic system, and to control the\nlevel of additional cost on the user side. Considering that well-performing\nsolutions can be used directly off the shelf for speech recognition and\nsynthesis, the study is focused on learning the spoken language understanding\nand dialogue management modules only. Several variants of joint learning are\ninvestigated and tested with user trials to confirm that the overall on-line\nlearning can be obtained after only a few hundred training dialogues and can\noverstep an expert-based system.\n", "versions": [{"version": "v1", "created": "Mon, 1 Oct 2018 19:15:57 GMT"}], "update_date": "2018-10-03", "authors_parsed": [["Riou", "Matthieu", ""], ["Jabaian", "Bassam", ""], ["Huet", "St\u00e9phane", ""], ["Lef\u00e8vre", "Fabrice", ""]]}, {"id": "1810.00946", "submitter": "Makoto Onizuka", "authors": "Seiji Maekawa, Koh Takeuch, Makoto Onizuka", "title": "Non-linear Attributed Graph Clustering by Symmetric NMF with PU Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the clustering problem of attributed graphs. Our challenge is how\nwe can design an effective and efficient clustering method that precisely\ncaptures the hidden relationship between the topology and the attributes in\nreal-world graphs. We propose Non-linear Attributed Graph Clustering by\nSymmetric Non-negative Matrix Factorization with Positive Unlabeled Learning.\nThe features of our method are three holds. 1) it learns a non-linear\nprojection function between the different cluster assignments of the topology\nand the attributes of graphs so as to capture the complicated relationship\nbetween the topology and the attributes in real-world graphs, 2) it leverages\nthe positive unlabeled learning to take the effect of partially observed\npositive edges into the cluster assignment, and 3) it achieves efficient\ncomputational complexity, $O((n^2+mn)kt)$, where $n$ is the vertex size, $m$ is\nthe attribute size, $k$ is the number of clusters, and $t$ is the number of\niterations for learning the cluster assignment. We conducted experiments\nextensively for various clustering methods with various real datasets to\nvalidate that our method outperforms the former clustering methods regarding\nthe clustering quality.\n", "versions": [{"version": "v1", "created": "Fri, 21 Sep 2018 12:05:43 GMT"}], "update_date": "2018-10-03", "authors_parsed": [["Maekawa", "Seiji", ""], ["Takeuch", "Koh", ""], ["Onizuka", "Makoto", ""]]}, {"id": "1810.00950", "submitter": "Ashutosh Trivedi", "authors": "Ernst Moritz Hahn and Mateo Perez and Sven Schewe and Fabio Somenzi\n  and Ashutosh Trivedi and Dominik Wojtczak", "title": "Omega-Regular Objectives in Model-Free Reinforcement Learning", "comments": "16 pages, 3 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We provide the first solution for model-free reinforcement learning of\n{\\omega}-regular objectives for Markov decision processes (MDPs). We present a\nconstructive reduction from the almost-sure satisfaction of {\\omega}-regular\nobjectives to an almost- sure reachability problem and extend this technique to\nlearning how to control an unknown model so that the chance of satisfying the\nobjective is maximized. A key feature of our technique is the compilation of\n{\\omega}-regular properties into limit- deterministic Buechi automata instead\nof the traditional Rabin automata; this choice sidesteps difficulties that have\nmarred previous proposals. Our approach allows us to apply model-free,\noff-the-shelf reinforcement learning algorithms to compute optimal strategies\nfrom the observations of the MDP. We present an experimental evaluation of our\ntechnique on benchmark learning problems.\n", "versions": [{"version": "v1", "created": "Wed, 26 Sep 2018 18:04:56 GMT"}], "update_date": "2018-10-03", "authors_parsed": [["Hahn", "Ernst Moritz", ""], ["Perez", "Mateo", ""], ["Schewe", "Sven", ""], ["Somenzi", "Fabio", ""], ["Trivedi", "Ashutosh", ""], ["Wojtczak", "Dominik", ""]]}, {"id": "1810.00952", "submitter": "Jared Roesch", "authors": "Jared Roesch, Steven Lyubomirsky, Logan Weber, Josh Pollock, Marisa\n  Kirisame, Tianqi Chen, Zachary Tatlock", "title": "Relay: A New IR for Machine Learning Frameworks", "comments": null, "journal-ref": null, "doi": "10.1145/3211346.3211348", "report-no": null, "categories": "cs.PL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Machine learning powers diverse services in industry including search,\ntranslation, recommendation systems, and security. The scale and importance of\nthese models require that they be efficient, expressive, and portable across an\narray of heterogeneous hardware devices. These constraints are often at odds;\nin order to better accommodate them we propose a new high-level intermediate\nrepresentation (IR) called Relay. Relay is being designed as a\npurely-functional, statically-typed language with the goal of balancing\nefficient compilation, expressiveness, and portability. We discuss the goals of\nRelay and highlight its important design constraints. Our prototype is part of\nthe open source NNVM compiler framework, which powers Amazon's deep learning\nframework MxNet.\n", "versions": [{"version": "v1", "created": "Wed, 26 Sep 2018 00:09:54 GMT"}], "update_date": "2018-10-03", "authors_parsed": [["Roesch", "Jared", ""], ["Lyubomirsky", "Steven", ""], ["Weber", "Logan", ""], ["Pollock", "Josh", ""], ["Kirisame", "Marisa", ""], ["Chen", "Tianqi", ""], ["Tatlock", "Zachary", ""]]}, {"id": "1810.00953", "submitter": "Adam Oberman", "authors": "Chris Finlay, Adam Oberman, Bilal Abbasi", "title": "Improved robustness to adversarial examples using Lipschitz\n  regularization of the loss", "comments": "Merged with arXiv:1808.09540", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We augment adversarial training (AT) with worst case adversarial training\n(WCAT) which improves adversarial robustness by 11% over the current\nstate-of-the-art result in the $\\ell_2$ norm on CIFAR-10. We obtain verifiable\naverage case and worst case robustness guarantees, based on the expected and\nmaximum values of the norm of the gradient of the loss. We interpret\nadversarial training as Total Variation Regularization, which is a fundamental\ntool in mathematical image processing, and WCAT as Lipschitz regularization.\n", "versions": [{"version": "v1", "created": "Mon, 1 Oct 2018 20:02:00 GMT"}, {"version": "v2", "created": "Tue, 23 Oct 2018 16:08:46 GMT"}, {"version": "v3", "created": "Mon, 7 Jan 2019 16:01:04 GMT"}, {"version": "v4", "created": "Fri, 13 Sep 2019 14:56:57 GMT"}], "update_date": "2019-09-16", "authors_parsed": [["Finlay", "Chris", ""], ["Oberman", "Adam", ""], ["Abbasi", "Bilal", ""]]}, {"id": "1810.00956", "submitter": "Zach Wood-Doughty", "authors": "Zach Wood-Doughty, Ilya Shpitser, and Mark Dredze", "title": "Challenges of Using Text Classifiers for Causal Inference", "comments": "To appear at EMNLP 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Causal understanding is essential for many kinds of decision-making, but\ncausal inference from observational data has typically only been applied to\nstructured, low-dimensional datasets. While text classifiers produce\nlow-dimensional outputs, their use in causal inference has not previously been\nstudied. To facilitate causal analyses based on language data, we consider the\nrole that text classifiers can play in causal inference through established\nmodeling mechanisms from the causality literature on missing data and\nmeasurement error. We demonstrate how to conduct causal analyses using text\nclassifiers on simulated and Yelp data, and discuss the opportunities and\nchallenges of future work that uses text data in causal inference.\n", "versions": [{"version": "v1", "created": "Mon, 1 Oct 2018 20:08:40 GMT"}], "update_date": "2018-10-03", "authors_parsed": [["Wood-Doughty", "Zach", ""], ["Shpitser", "Ilya", ""], ["Dredze", "Mark", ""]]}, {"id": "1810.00968", "submitter": "Aysenur Bilgin", "authors": "Aysenur Bilgin (1), Laura Hollink (1), Jacco van Ossenbruggen (1),\n  Erik Tjong Kim Sang (2), Kim Smeenk (3), Frank Harbers (3), Marcel Broersma\n  (3) ((1) CWI, (2) Netherlands eScience Center, (3) University of Groningen)", "title": "Utilizing a Transparency-driven Environment toward Trusted Automatic\n  Genre Classification: A Case Study in Journalism History", "comments": "11 pages, 8 figures, IEEE eScience Conference 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  With the growing abundance of unlabeled data in real-world tasks, researchers\nhave to rely on the predictions given by black-boxed computational models.\nHowever, it is an often neglected fact that these models may be scoring high on\naccuracy for the wrong reasons. In this paper, we present a practical impact\nanalysis of enabling model transparency by various presentation forms. For this\npurpose, we developed an environment that empowers non-computer scientists to\nbecome practicing data scientists in their own research field. We demonstrate\nthe gradually increasing understanding of journalism historians through a\nreal-world use case study on automatic genre classification of newspaper\narticles. This study is a first step towards trusted usage of machine learning\npipelines in a responsible way.\n", "versions": [{"version": "v1", "created": "Mon, 1 Oct 2018 20:40:59 GMT"}], "update_date": "2018-10-03", "authors_parsed": [["Bilgin", "Aysenur", "", "CWI"], ["Hollink", "Laura", "", "CWI"], ["van Ossenbruggen", "Jacco", "", "CWI"], ["Sang", "Erik Tjong Kim", "", "Netherlands eScience Center"], ["Smeenk", "Kim", "", "University of Groningen"], ["Harbers", "Frank", "", "University of Groningen"], ["Broersma", "Marcel", "", "University of Groningen"]]}, {"id": "1810.00974", "submitter": "Wenbo Zhao", "authors": "Shahan Ali Memon, Wenbo Zhao, Bhiksha Raj, Rita Singh", "title": "Neural Regression Trees", "comments": "Accepted by The 2019 International Joint Conference on Neural\n  Networks (IJCNN). To be published on IEEE. 8 pages, 4 figures", "journal-ref": null, "doi": "10.1109/IJCNN.2019.8852133", "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Regression-via-Classification (RvC) is the process of converting a regression\nproblem to a classification one. Current approaches for RvC use ad-hoc\ndiscretization strategies and are suboptimal. We propose a neural regression\ntree model for RvC. In this model, we employ a joint optimization framework\nwhere we learn optimal discretization thresholds while simultaneously\noptimizing the features for each node in the tree. We empirically show the\nvalidity of our model by testing it on two challenging regression tasks where\nwe establish the state of the art.\n", "versions": [{"version": "v1", "created": "Mon, 1 Oct 2018 20:52:38 GMT"}, {"version": "v2", "created": "Wed, 3 Apr 2019 21:09:38 GMT"}], "update_date": "2020-02-13", "authors_parsed": [["Memon", "Shahan Ali", ""], ["Zhao", "Wenbo", ""], ["Raj", "Bhiksha", ""], ["Singh", "Rita", ""]]}, {"id": "1810.00997", "submitter": "Victor Gabillon", "authors": "Peter L. Bartlett, Victor Gabillon, Michal Valko", "title": "A simple parameter-free and adaptive approach to optimization under a\n  minimal local smoothness assumption", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the problem of optimizing a function under a \\emph{budgeted number\nof evaluations}. We only assume that the function is \\emph{locally} smooth\naround one of its global optima. The difficulty of optimization is measured in\nterms of 1) the amount of \\emph{noise} $b$ of the function evaluation and 2)\nthe local smoothness, $d$, of the function. A smaller $d$ results in smaller\noptimization error. We come with a new, simple, and parameter-free approach.\nFirst, for all values of $b$ and $d$, this approach recovers at least the\nstate-of-the-art regret guarantees. Second, our approach additionally obtains\nthese results while being \\textit{agnostic} to the values of both $b$ and $d$.\nThis leads to the first algorithm that naturally adapts to an \\textit{unknown}\nrange of noise $b$ and leads to significant improvements in a moderate and\nlow-noise regime. Third, our approach also obtains a remarkable improvement\nover the state-of-the-art SOO algorithm when the noise is very low which\nincludes the case of optimization under deterministic feedback ($b=0$). There,\nunder our minimal local smoothness assumption, this improvement is of\nexponential magnitude and holds for a class of functions that covers the vast\nmajority of functions that practitioners optimize ($d=0$). We show that our\nalgorithmic improvement is borne out in experiments as we empirically show\nfaster convergence on common benchmarks.\n", "versions": [{"version": "v1", "created": "Mon, 1 Oct 2018 22:14:43 GMT"}, {"version": "v2", "created": "Sat, 23 Feb 2019 11:13:56 GMT"}], "update_date": "2019-02-26", "authors_parsed": [["Bartlett", "Peter L.", ""], ["Gabillon", "Victor", ""], ["Valko", "Michal", ""]]}, {"id": "1810.01008", "submitter": "Martin Loncaric", "authors": "Martin Loncaric and Bowei Liu and Ryan Weber", "title": "Learning Hash Codes via Hamming Distance Targets", "comments": "8 pages, overhaul of our previous submission Convolutional Hashing\n  for Automated Scene Matching", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a powerful new loss function and training scheme for learning\nbinary hash codes with any differentiable model and similarity function. Our\nloss function improves over prior methods by using log likelihood loss on top\nof an accurate approximation for the probability that two inputs fall within a\nHamming distance target. Our novel training scheme obtains a good estimate of\nthe true gradient by better sampling inputs and evaluating loss terms between\nall pairs of inputs in each minibatch. To fully leverage the resulting hashes,\nwe use multi-indexing. We demonstrate that these techniques provide large\nimprovements to a similarity search tasks. We report the best results to date\non competitive information retrieval tasks for ImageNet and SIFT 1M, improving\nMAP from 73% to 84% and reducing query cost by a factor of 2-8, respectively.\n", "versions": [{"version": "v1", "created": "Mon, 1 Oct 2018 23:03:27 GMT"}], "update_date": "2018-10-03", "authors_parsed": [["Loncaric", "Martin", ""], ["Liu", "Bowei", ""], ["Weber", "Ryan", ""]]}, {"id": "1810.01014", "submitter": "Gilwoo Lee", "authors": "Gilwoo Lee, Brian Hou, Aditya Mandalika, Jeongseok Lee, Sanjiban\n  Choudhury, Siddhartha S. Srinivasa", "title": "Bayesian Policy Optimization for Model Uncertainty", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Addressing uncertainty is critical for autonomous systems to robustly adapt\nto the real world. We formulate the problem of model uncertainty as a\ncontinuous Bayes-Adaptive Markov Decision Process (BAMDP), where an agent\nmaintains a posterior distribution over latent model parameters given a history\nof observations and maximizes its expected long-term reward with respect to\nthis belief distribution. Our algorithm, Bayesian Policy Optimization, builds\non recent policy optimization algorithms to learn a universal policy that\nnavigates the exploration-exploitation trade-off to maximize the Bayesian value\nfunction. To address challenges from discretizing the continuous latent\nparameter space, we propose a new policy network architecture that encodes the\nbelief distribution independently from the observable state. Our method\nsignificantly outperforms algorithms that address model uncertainty without\nexplicitly reasoning about belief distributions and is competitive with\nstate-of-the-art Partially Observable Markov Decision Process solvers.\n", "versions": [{"version": "v1", "created": "Mon, 1 Oct 2018 23:39:25 GMT"}, {"version": "v2", "created": "Wed, 8 May 2019 15:04:45 GMT"}], "update_date": "2019-05-09", "authors_parsed": [["Lee", "Gilwoo", ""], ["Hou", "Brian", ""], ["Mandalika", "Aditya", ""], ["Lee", "Jeongseok", ""], ["Choudhury", "Sanjiban", ""], ["Srinivasa", "Siddhartha S.", ""]]}, {"id": "1810.01015", "submitter": "Salimeh Yasaei Sekeh", "authors": "Salimeh Yasaei Sekeh, Morteza Noshad, Kevin R. Moon, Alfred O. Hero", "title": "Convergence Rates for Empirical Estimation of Binary Classification\n  Bounds", "comments": "27 pages, 8 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IT cs.LG math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Bounding the best achievable error probability for binary classification\nproblems is relevant to many applications including machine learning, signal\nprocessing, and information theory. Many bounds on the Bayes binary\nclassification error rate depend on information divergences between the pair of\nclass distributions. Recently, the Henze-Penrose (HP) divergence has been\nproposed for bounding classification error probability. We consider the problem\nof empirically estimating the HP-divergence from random samples. We derive a\nbound on the convergence rate for the Friedman-Rafsky (FR) estimator of the\nHP-divergence, which is related to a multivariate runs statistic for testing\nbetween two distributions. The FR estimator is derived from a multicolored\nEuclidean minimal spanning tree (MST) that spans the merged samples. We obtain\na concentration inequality for the Friedman-Rafsky estimator of the\nHenze-Penrose divergence. We validate our results experimentally and illustrate\ntheir application to real datasets.\n", "versions": [{"version": "v1", "created": "Mon, 1 Oct 2018 23:53:54 GMT"}], "update_date": "2018-10-03", "authors_parsed": [["Sekeh", "Salimeh Yasaei", ""], ["Noshad", "Morteza", ""], ["Moon", "Kevin R.", ""], ["Hero", "Alfred O.", ""]]}, {"id": "1810.01018", "submitter": "Zhezhi He", "authors": "Zhezhi He, Deliang Fan", "title": "Simultaneously Optimizing Weight and Quantizer of Ternary Neural Network\n  using Truncated Gaussian Approximation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In the past years, Deep convolution neural network has achieved great success\nin many artificial intelligence applications. However, its enormous model size\nand massive computation cost have become the main obstacle for deployment of\nsuch powerful algorithm in the low power and resource-limited mobile systems.\nAs the countermeasure to this problem, deep neural networks with ternarized\nweights (i.e. -1, 0, +1) have been widely explored to greatly reduce the model\nsize and computational cost, with limited accuracy degradation. In this work,\nwe propose a novel ternarized neural network training method which\nsimultaneously optimizes both weights and quantizer during training,\ndifferentiating from prior works. Instead of fixed and uniform weight\nternarization, we are the first to incorporate the thresholds of weight\nternarization into a closed-form representation using the truncated Gaussian\napproximation, enabling simultaneous optimization of weights and quantizer\nthrough back-propagation training. With both of the first and last layer\nternarized, the experiments on the ImageNet classification task show that our\nternarized ResNet-18/34/50 only has 3.9/2.52/2.16% accuracy degradation in\ncomparison to the full-precision counterparts.\n", "versions": [{"version": "v1", "created": "Tue, 2 Oct 2018 00:04:20 GMT"}], "update_date": "2018-10-03", "authors_parsed": [["He", "Zhezhi", ""], ["Fan", "Deliang", ""]]}, {"id": "1810.01021", "submitter": "Amir Gholami", "authors": "Zhewei Yao, Amir Gholami, Daiyaan Arfeen, Richard Liaw, Joseph\n  Gonzalez, Kurt Keutzer, Michael Mahoney", "title": "Large batch size training of neural networks with adversarial training\n  and second-order information", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI math.OC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The most straightforward method to accelerate Stochastic Gradient Descent\n(SGD) computation is to distribute the randomly selected batch of inputs over\nmultiple processors. To keep the distributed processors fully utilized requires\ncommensurately growing the batch size. However, large batch training often\nleads to poorer generalization. A recently proposed solution for this problem\nis to use adaptive batch sizes in SGD. In this case, one starts with a small\nnumber of processes and scales the processes as training progresses. Two major\nchallenges with this approach are (i) that dynamically resizing the cluster can\nadd non-trivial overhead, in part since it is currently not supported, and (ii)\nthat the overall speed up is limited by the initial phase with smaller batches.\nIn this work, we address both challenges by developing a new adaptive batch\nsize framework, with autoscaling based on the Ray framework. This allows very\nefficient elastic scaling with negligible resizing overhead (0.32\\% of time for\nResNet18 ImageNet training). Furthermore, we propose a new adaptive batch size\ntraining scheme using second order methods and adversarial training. These\nenable increasing batch sizes earlier during training, which leads to better\ntraining time. We extensively evaluate our method on Cifar-10/100, SVHN,\nTinyImageNet, and ImageNet datasets, using multiple neural networks, including\nResNets and smaller networks such as SqueezeNext. Our method exceeds the\nperformance of existing solutions in terms of both accuracy and the number of\nSGD iterations (up to 1\\% and $5\\times$, respectively). Importantly, this is\nachieved without any additional hyper-parameter tuning to tailor our method in\nany of these experiments.\n", "versions": [{"version": "v1", "created": "Tue, 2 Oct 2018 00:31:46 GMT"}, {"version": "v2", "created": "Sun, 3 Feb 2019 20:56:27 GMT"}, {"version": "v3", "created": "Fri, 3 Jan 2020 00:16:36 GMT"}], "update_date": "2020-01-06", "authors_parsed": [["Yao", "Zhewei", ""], ["Gholami", "Amir", ""], ["Arfeen", "Daiyaan", ""], ["Liaw", "Richard", ""], ["Gonzalez", "Joseph", ""], ["Keutzer", "Kurt", ""], ["Mahoney", "Michael", ""]]}, {"id": "1810.01032", "submitter": "Jingkang Wang", "authors": "Jingkang Wang, Yang Liu, Bo Li", "title": "Reinforcement Learning with Perturbed Rewards", "comments": "AAAI 2020 (Spotlight)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent studies have shown that reinforcement learning (RL) models are\nvulnerable in various noisy scenarios. For instance, the observed reward\nchannel is often subject to noise in practice (e.g., when rewards are collected\nthrough sensors), and is therefore not credible. In addition, for applications\nsuch as robotics, a deep reinforcement learning (DRL) algorithm can be\nmanipulated to produce arbitrary errors by receiving corrupted rewards. In this\npaper, we consider noisy RL problems with perturbed rewards, which can be\napproximated with a confusion matrix. We develop a robust RL framework that\nenables agents to learn in noisy environments where only perturbed rewards are\nobserved. Our solution framework builds on existing RL/DRL algorithms and\nfirstly addresses the biased noisy reward setting without any assumptions on\nthe true distribution (e.g., zero-mean Gaussian noise as made in previous\nworks). The core ideas of our solution include estimating a reward confusion\nmatrix and defining a set of unbiased surrogate rewards. We prove the\nconvergence and sample complexity of our approach. Extensive experiments on\ndifferent DRL platforms show that trained policies based on our estimated\nsurrogate reward can achieve higher expected rewards, and converge faster than\nexisting baselines. For instance, the state-of-the-art PPO algorithm is able to\nobtain 84.6% and 80.8% improvements on average score for five Atari games, with\nerror rates as 10% and 30% respectively.\n", "versions": [{"version": "v1", "created": "Tue, 2 Oct 2018 01:43:45 GMT"}, {"version": "v2", "created": "Fri, 5 Oct 2018 15:47:23 GMT"}, {"version": "v3", "created": "Mon, 13 Jan 2020 22:19:26 GMT"}, {"version": "v4", "created": "Sat, 1 Feb 2020 21:15:52 GMT"}], "update_date": "2020-02-04", "authors_parsed": [["Wang", "Jingkang", ""], ["Liu", "Yang", ""], ["Li", "Bo", ""]]}, {"id": "1810.01049", "submitter": "Hu Ding", "authors": "Hu Ding and Jinhui Xu", "title": "A Unified Framework for Clustering Constrained Data without Locality\n  Property", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CG cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we consider a class of constrained clustering problems of\npoints in $\\mathbb{R}^{d}$, where $d$ could be rather high. A common feature of\nthese problems is that their optimal clusterings no longer have the locality\nproperty (due to the additional constraints), which is a key property required\nby many algorithms for their unconstrained counterparts. To overcome the\ndifficulty caused by the loss of locality, we present in this paper a unified\nframework, called {\\em Peeling-and-Enclosing (PnE)}, to iteratively solve two\nvariants of the constrained clustering problems, {\\em constrained $k$-means\nclustering} ($k$-CMeans) and {\\em constrained $k$-median clustering}\n($k$-CMedian). Our framework is based on two standalone geometric techniques,\ncalled {\\em Simplex Lemma} and {\\em Weaker Simplex Lemma}, for $k$-CMeans and\n$k$-CMedian, respectively. The simplex lemma (or weaker simplex lemma) enables\nus to efficiently approximate the mean (or median) point of an unknown set of\npoints by searching a small-size grid, independent of the dimensionality of the\nspace, in a simplex (or the surrounding region of a simplex), and thus can be\nused to handle high dimensional data. If $k$ and $\\frac{1}{\\epsilon}$ are fixed\nnumbers, our framework generates, in nearly linear time ({\\em i.e.,} $O(n(\\log\nn)^{k+1}d)$), $O((\\log n)^{k})$ $k$-tuple candidates for the $k$ mean or median\npoints, and one of them induces a $(1+\\epsilon)$-approximation for $k$-CMeans\nor $k$-CMedian, where $n$ is the number of points. Combining this unified\nframework with a problem-specific selection algorithm (which determines the\nbest $k$-tuple candidate), we obtain a $(1+\\epsilon)$-approximation for each of\nthe constrained clustering problems. We expect that our technique will be\napplicable to other constrained clustering problems without locality.\n", "versions": [{"version": "v1", "created": "Tue, 2 Oct 2018 03:18:15 GMT"}], "update_date": "2018-10-03", "authors_parsed": [["Ding", "Hu", ""], ["Xu", "Jinhui", ""]]}, {"id": "1810.01054", "submitter": "Yuanming Hu", "authors": "Yuanming Hu, Jiancheng Liu, Andrew Spielberg, Joshua B. Tenenbaum,\n  William T. Freeman, Jiajun Wu, Daniela Rus, Wojciech Matusik", "title": "ChainQueen: A Real-Time Differentiable Physical Simulator for Soft\n  Robotics", "comments": "In submission to ICRA 2019. Supplemental Video:\n  https://www.youtube.com/watch?v=4IWD4iGIsB4 Project Page:\n  https://github.com/yuanming-hu/ChainQueen", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.AI cs.GR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Physical simulators have been widely used in robot planning and control.\nAmong them, differentiable simulators are particularly favored, as they can be\nincorporated into gradient-based optimization algorithms that are efficient in\nsolving inverse problems such as optimal control and motion planning.\nSimulating deformable objects is, however, more challenging compared to rigid\nbody dynamics. The underlying physical laws of deformable objects are more\ncomplex, and the resulting systems have orders of magnitude more degrees of\nfreedom and therefore they are significantly more computationally expensive to\nsimulate. Computing gradients with respect to physical design or controller\nparameters is typically even more computationally challenging. In this paper,\nwe propose a real-time, differentiable hybrid Lagrangian-Eulerian physical\nsimulator for deformable objects, ChainQueen, based on the Moving Least Squares\nMaterial Point Method (MLS-MPM). MLS-MPM can simulate deformable objects\nincluding contact and can be seamlessly incorporated into inference, control\nand co-design systems. We demonstrate that our simulator achieves high\nprecision in both forward simulation and backward gradient computation. We have\nsuccessfully employed it in a diverse set of control tasks for soft robots,\nincluding problems with nearly 3,000 decision variables.\n", "versions": [{"version": "v1", "created": "Tue, 2 Oct 2018 03:48:42 GMT"}], "update_date": "2018-10-03", "authors_parsed": [["Hu", "Yuanming", ""], ["Liu", "Jiancheng", ""], ["Spielberg", "Andrew", ""], ["Tenenbaum", "Joshua B.", ""], ["Freeman", "William T.", ""], ["Wu", "Jiajun", ""], ["Rus", "Daniela", ""], ["Matusik", "Wojciech", ""]]}, {"id": "1810.01061", "submitter": "Diego Nascimento", "authors": "Diego Nascimento, Anderson Ara, Francisco Louzada Neto", "title": "Feature Selection Approach with Missing Values Conducted for Statistical\n  Learning: A Case Study of Entrepreneurship Survival Dataset", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this article, we investigate the features which enhanced discriminate the\nsurvival in the micro and small business (MSE) using the approach of data\nmining with feature selection. According to the complexity of the data set, we\nproposed a comparison of three data imputation methods such as mean imputation\n(MI), k-nearest neighbor (KNN) and expectation maximization (EM) using mutually\nthe selection of variables technique, whereby t-test, then through the data\nmining process using logistic regression classification methods, naive Bayes\nalgorithm, linear discriminant analysis and support vector machine hence\ncomparing their respective performances. The experimental results will be\nspread in developing a model to predict the MSE survival, providing a better\nunderstanding in the topic once it is a significant part of the Brazilian' GPA\nand macroeconomy.\n", "versions": [{"version": "v1", "created": "Tue, 2 Oct 2018 04:24:14 GMT"}], "update_date": "2018-10-03", "authors_parsed": [["Nascimento", "Diego", ""], ["Ara", "Anderson", ""], ["Neto", "Francisco Louzada", ""]]}, {"id": "1810.01064", "submitter": "Shuai Tang", "authors": "Shuai Tang, Virginia R. de Sa", "title": "Improving Sentence Representations with Consensus Maximisation", "comments": "arXiv admin note: substantial text overlap with arXiv:1805.07443", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Consensus maximisation learning can provide self-supervision when different\nviews are available of the same data. The distributional hypothesis provides\nanother form of useful self-supervision from adjacent sentences which are\nplentiful in large unlabelled corpora. Motivated by the observation that\ndifferent learning architectures tend to emphasise different aspects of\nsentence meaning, we present a new self-supervised learning framework for\nlearning sentence representations which minimises the disagreement between two\nviews of the same sentence where one view encodes the sentence with a recurrent\nneural network (RNN), and the other view encodes the same sentence with a\nsimple linear model. After learning, the individual views (networks) result in\nhigher quality sentence representations than their single-view learnt\ncounterparts (learnt using only the distributional hypothesis) as judged by\nperformance on standard downstream tasks. An ensemble of both views provides\neven better generalisation on both supervised and unsupervised downstream\ntasks. Also, importantly the ensemble of views trained with consensus\nmaximisation between the two different architectures performs better on\ndownstream tasks than an analogous ensemble made from the single-view trained\ncounterparts.\n", "versions": [{"version": "v1", "created": "Tue, 2 Oct 2018 04:51:33 GMT"}, {"version": "v2", "created": "Wed, 28 Nov 2018 01:12:24 GMT"}, {"version": "v3", "created": "Fri, 3 May 2019 18:02:53 GMT"}, {"version": "v4", "created": "Tue, 7 May 2019 01:02:40 GMT"}], "update_date": "2019-05-08", "authors_parsed": [["Tang", "Shuai", ""], ["de Sa", "Virginia R.", ""]]}, {"id": "1810.01075", "submitter": "Michael Mahoney", "authors": "Charles H. Martin and Michael W. Mahoney", "title": "Implicit Self-Regularization in Deep Neural Networks: Evidence from\n  Random Matrix Theory and Implications for Learning", "comments": "59 pages, 31 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Random Matrix Theory (RMT) is applied to analyze weight matrices of Deep\nNeural Networks (DNNs), including both production quality, pre-trained models\nsuch as AlexNet and Inception, and smaller models trained from scratch, such as\nLeNet5 and a miniature-AlexNet. Empirical and theoretical results clearly\nindicate that the DNN training process itself implicitly implements a form of\nSelf-Regularization. The empirical spectral density (ESD) of DNN layer matrices\ndisplays signatures of traditionally-regularized statistical models, even in\nthe absence of exogenously specifying traditional forms of explicit\nregularization. Building on relatively recent results in RMT, most notably its\nextension to Universality classes of Heavy-Tailed matrices, we develop a theory\nto identify 5+1 Phases of Training, corresponding to increasing amounts of\nImplicit Self-Regularization. These phases can be observed during the training\nprocess as well as in the final learned DNNs. For smaller and/or older DNNs,\nthis Implicit Self-Regularization is like traditional Tikhonov regularization,\nin that there is a \"size scale\" separating signal from noise. For\nstate-of-the-art DNNs, however, we identify a novel form of Heavy-Tailed\nSelf-Regularization, similar to the self-organization seen in the statistical\nphysics of disordered systems. This results from correlations arising at all\nsize scales, which arises implicitly due to the training process itself. This\nimplicit Self-Regularization can depend strongly on the many knobs of the\ntraining process. By exploiting the generalization gap phenomena, we\ndemonstrate that we can cause a small model to exhibit all 5+1 phases of\ntraining simply by changing the batch size. This demonstrates that---all else\nbeing equal---DNN optimization with larger batch sizes leads to less-well\nimplicitly-regularized models, and it provides an explanation for the\ngeneralization gap phenomena.\n", "versions": [{"version": "v1", "created": "Tue, 2 Oct 2018 05:27:59 GMT"}], "update_date": "2018-10-03", "authors_parsed": [["Martin", "Charles H.", ""], ["Mahoney", "Michael W.", ""]]}, {"id": "1810.01097", "submitter": "Subhadip Mukherjee", "authors": "Subhadip Mukherjee and Chandra Sekhar Seelamantula", "title": "Quantization-Aware Phase Retrieval", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We address the problem of phase retrieval (PR) from quantized measurements.\nThe goal is to reconstruct a signal from quadratic measurements encoded with a\nfinite precision, which is indeed the case in many practical applications. We\ndevelop a rank-1 projection algorithm that recovers the signal subject to\nensuring consistency with the measurement, that is, the recovered signal when\nencoded must yield the same set of measurements that one started with. The\nrank-1 projection stems from the idea of lifting, originally proposed in the\ncontext of PhaseLift. The consistency criterion is enforced using a one-sided\nquadratic cost. We also determine the probability with which different vectors\nlead to the same set of quantized measurements, which makes it impossible to\nresolve them. Naturally, this probability depends on how correlated such\nvectors are, and how coarsely/finely the measurements get quantized. The\nproposed algorithm is also capable of incorporating a sparsity constraint on\nthe signal. An analysis of the cost function reveals that it is bounded, both\nabove and below, by functions that are dependent on how well correlated the\nestimate is with the ground truth. We also derive the Cram\\'er-Rao lower bound\n(CRB) on the achievable reconstruction accuracy. A comparison with the\nstate-of-the- art algorithms shows that the proposed algorithm has a higher\nreconstruction accuracy and is about 2 to 3 dB away from the CRB. The edge, in\nterms of the reconstruction signal-to-noise ratio, over the competing\nalgorithms is higher (about 5 to 6 dB) when the quantization is coarse.\n", "versions": [{"version": "v1", "created": "Tue, 2 Oct 2018 07:23:05 GMT"}], "update_date": "2018-10-03", "authors_parsed": [["Mukherjee", "Subhadip", ""], ["Seelamantula", "Chandra Sekhar", ""]]}, {"id": "1810.01108", "submitter": "Subhajit Chaudhury", "authors": "Subhajit Chaudhury, Daiki Kimura, Asim Munawar and Ryuki Tachibana", "title": "Injective State-Image Mapping facilitates Visual Adversarial Imitation\n  Learning", "comments": "Updated the paper to match with version accepted at IEEE MMSP 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The growing use of virtual autonomous agents in applications like games and\nentertainment demands better control policies for natural-looking movements and\nactions. Unlike the conventional approach of hard-coding motion routines, we\npropose a deep learning method for obtaining control policies by directly\nmimicking raw video demonstrations. Previous methods in this domain rely on\nextracting low-dimensional features from expert videos followed by a separate\nhand-crafted reward estimation step. We propose an imitation learning framework\nthat reduces the dependence on hand-engineered reward functions by jointly\nlearning the feature extraction and reward estimation steps using Generative\nAdversarial Networks (GANs). Our main contribution in this paper is to show\nthat under injective mapping between low-level joint state (angles and\nvelocities) trajectories and corresponding raw video stream, performing\nadversarial imitation learning on video demonstrations is equivalent to\nlearning from the state trajectories. Experimental results show that the\nproposed adversarial learning method from raw videos produces a similar\nperformance to state-of-the-art imitation learning techniques while frequently\noutperforming existing hand-crafted video imitation methods. Furthermore, we\nshow that our method can learn action policies by imitating video\ndemonstrations on YouTube with similar performance to learned agents from true\nreward signals. Please see the supplementary video submission at\nhttps://ibm.biz/BdzzNA.\n", "versions": [{"version": "v1", "created": "Tue, 2 Oct 2018 08:22:41 GMT"}, {"version": "v2", "created": "Fri, 25 Oct 2019 09:32:10 GMT"}], "update_date": "2019-10-28", "authors_parsed": [["Chaudhury", "Subhajit", ""], ["Kimura", "Daiki", ""], ["Munawar", "Asim", ""], ["Tachibana", "Ryuki", ""]]}, {"id": "1810.01112", "submitter": "Per-Arne Andersen", "authors": "Per-Arne Andersen, Morten Goodwin, Ole-Christoffer Granmo", "title": "The Dreaming Variational Autoencoder for Reinforcement Learning\n  Environments", "comments": "Best Student Paper Award, Proceedings of the 38th SGAI International\n  Conference on Artificial Intelligence, Cambridge, UK, 2018, Artificial\n  Intelligence XXXV, 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Reinforcement learning has shown great potential in generalizing over raw\nsensory data using only a single neural network for value optimization. There\nare several challenges in the current state-of-the-art reinforcement learning\nalgorithms that prevent them from converging towards the global optima. It is\nlikely that the solution to these problems lies in short- and long-term\nplanning, exploration and memory management for reinforcement learning\nalgorithms. Games are often used to benchmark reinforcement learning algorithms\nas they provide a flexible, reproducible, and easy to control environment.\nRegardless, few games feature a state-space where results in exploration,\nmemory, and planning are easily perceived. This paper presents The Dreaming\nVariational Autoencoder (DVAE), a neural network based generative modeling\narchitecture for exploration in environments with sparse feedback. We further\npresent Deep Maze, a novel and flexible maze engine that challenges DVAE in\npartial and fully-observable state-spaces, long-horizon tasks, and\ndeterministic and stochastic problems. We show initial findings and encourage\nfurther work in reinforcement learning driven by generative exploration.\n", "versions": [{"version": "v1", "created": "Tue, 2 Oct 2018 08:31:39 GMT"}], "update_date": "2018-10-04", "authors_parsed": [["Andersen", "Per-Arne", ""], ["Goodwin", "Morten", ""], ["Granmo", "Ole-Christoffer", ""]]}, {"id": "1810.01118", "submitter": "Giorgio Patrini", "authors": "Giorgio Patrini, Rianne van den Berg, Patrick Forr\\'e, Marcello\n  Carioni, Samarth Bhargav, Max Welling, Tim Genewein, Frank Nielsen", "title": "Sinkhorn AutoEncoders", "comments": "Accepted for oral presentation at UAI19", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Optimal transport offers an alternative to maximum likelihood for learning\ngenerative autoencoding models. We show that minimizing the p-Wasserstein\ndistance between the generator and the true data distribution is equivalent to\nthe unconstrained min-min optimization of the p-Wasserstein distance between\nthe encoder aggregated posterior and the prior in latent space, plus a\nreconstruction error. We also identify the role of its trade-off hyperparameter\nas the capacity of the generator: its Lipschitz constant. Moreover, we prove\nthat optimizing the encoder over any class of universal approximators, such as\ndeterministic neural networks, is enough to come arbitrarily close to the\noptimum. We therefore advertise this framework, which holds for any metric\nspace and prior, as a sweet-spot of current generative autoencoding objectives.\nWe then introduce the Sinkhorn auto-encoder (SAE), which approximates and\nminimizes the p-Wasserstein distance in latent space via backprogation through\nthe Sinkhorn algorithm. SAE directly works on samples, i.e. it models the\naggregated posterior as an implicit distribution, with no need for a\nreparameterization trick for gradients estimations. SAE is thus able to work\nwith different metric spaces and priors with minimal adaptations. We\ndemonstrate the flexibility of SAE on latent spaces with different geometries\nand priors and compare with other methods on benchmark data sets.\n", "versions": [{"version": "v1", "created": "Tue, 2 Oct 2018 08:43:08 GMT"}, {"version": "v2", "created": "Wed, 3 Oct 2018 07:21:35 GMT"}, {"version": "v3", "created": "Tue, 16 Jul 2019 02:04:33 GMT"}], "update_date": "2019-07-17", "authors_parsed": [["Patrini", "Giorgio", ""], ["Berg", "Rianne van den", ""], ["Forr\u00e9", "Patrick", ""], ["Carioni", "Marcello", ""], ["Bhargav", "Samarth", ""], ["Welling", "Max", ""], ["Genewein", "Tim", ""], ["Nielsen", "Frank", ""]]}, {"id": "1810.01152", "submitter": "Pingbo Pan", "authors": "Pingbo Pan, Yan Yan, Tianbao Yang, Yi Yang", "title": "Learning Discriminators as Energy Networks in Adversarial Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.CR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a novel framework for structured prediction via adversarial\nlearning. Existing adversarial learning methods involve two separate networks,\ni.e., the structured prediction models and the discriminative models, in the\ntraining. The information captured by discriminative models complements that in\nthe structured prediction models, but few existing researches have studied on\nutilizing such information to improve structured prediction models at the\ninference stage. In this work, we propose to refine the predictions of\nstructured prediction models by effectively integrating discriminative models\ninto the prediction. Discriminative models are treated as energy-based models.\nSimilar to the adversarial learning, discriminative models are trained to\nestimate scores which measure the quality of predicted outputs, while\nstructured prediction models are trained to predict contrastive outputs with\nmaximal energy scores. In this way, the gradient vanishing problem is\nameliorated, and thus we are able to perform inference by following the ascent\ngradient directions of discriminative models to refine structured prediction\nmodels. The proposed method is able to handle a range of tasks, e.g.,\nmulti-label classification and image segmentation. Empirical results on these\ntwo tasks validate the effectiveness of our learning method.\n", "versions": [{"version": "v1", "created": "Tue, 2 Oct 2018 10:06:32 GMT"}], "update_date": "2018-10-04", "authors_parsed": [["Pan", "Pingbo", ""], ["Yan", "Yan", ""], ["Yang", "Tianbao", ""], ["Yang", "Yi", ""]]}, {"id": "1810.01163", "submitter": "Bharath Bhushan Damodaran", "authors": "Bharath Bhushan Damodaran, R\\'emi Flamary, Viven Seguy, Nicolas Courty", "title": "An Entropic Optimal Transport Loss for Learning Deep Neural Networks\n  under Label Noise in Remote Sensing Images", "comments": "Under Consideration at Computer Vision and Image Understanding", "journal-ref": "Computer Vision and Image Understanding, Volume 191, 2020, 102863,\n  ISSN 1077-3142", "doi": "10.1016/j.cviu.2019.102863", "report-no": null, "categories": "cs.CV cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep neural networks have established as a powerful tool for large scale\nsupervised classification tasks. The state-of-the-art performances of deep\nneural networks are conditioned to the availability of large number of\naccurately labeled samples. In practice, collecting large scale accurately\nlabeled datasets is a challenging and tedious task in most scenarios of remote\nsensing image analysis, thus cheap surrogate procedures are employed to label\nthe dataset. Training deep neural networks on such datasets with inaccurate\nlabels easily overfits to the noisy training labels and degrades the\nperformance of the classification tasks drastically. To mitigate this effect,\nwe propose an original solution with entropic optimal transportation. It allows\nto learn in an end-to-end fashion deep neural networks that are, to some\nextent, robust to inaccurately labeled samples. We empirically demonstrate on\nseveral remote sensing datasets, where both scene and pixel-based hyperspectral\nimages are considered for classification. Our method proves to be highly\ntolerant to significant amounts of label noise and achieves favorable results\nagainst state-of-the-art methods.\n", "versions": [{"version": "v1", "created": "Tue, 2 Oct 2018 10:31:37 GMT"}], "update_date": "2021-06-22", "authors_parsed": [["Damodaran", "Bharath Bhushan", ""], ["Flamary", "R\u00e9mi", ""], ["Seguy", "Viven", ""], ["Courty", "Nicolas", ""]]}, {"id": "1810.01176", "submitter": "Hyoungseok Kim", "authors": "Hyoungseok Kim, Jaekyeom Kim, Yeonwoo Jeong, Sergey Levine, Hyun Oh\n  Song", "title": "EMI: Exploration with Mutual Information", "comments": "Accepted and to appear at ICML 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Reinforcement learning algorithms struggle when the reward signal is very\nsparse. In these cases, naive random exploration methods essentially rely on a\nrandom walk to stumble onto a rewarding state. Recent works utilize intrinsic\nmotivation to guide the exploration via generative models, predictive forward\nmodels, or discriminative modeling of novelty. We propose EMI, which is an\nexploration method that constructs embedding representation of states and\nactions that does not rely on generative decoding of the full observation but\nextracts predictive signals that can be used to guide exploration based on\nforward prediction in the representation space. Our experiments show\ncompetitive results on challenging locomotion tasks with continuous control and\non image-based exploration tasks with discrete actions on Atari. The source\ncode is available at https://github.com/snu-mllab/EMI .\n", "versions": [{"version": "v1", "created": "Tue, 2 Oct 2018 11:33:57 GMT"}, {"version": "v2", "created": "Thu, 4 Oct 2018 15:26:16 GMT"}, {"version": "v3", "created": "Tue, 27 Nov 2018 13:50:56 GMT"}, {"version": "v4", "created": "Thu, 24 Jan 2019 01:07:50 GMT"}, {"version": "v5", "created": "Tue, 14 May 2019 07:06:05 GMT"}, {"version": "v6", "created": "Thu, 13 Jun 2019 05:41:38 GMT"}], "update_date": "2019-06-14", "authors_parsed": [["Kim", "Hyoungseok", ""], ["Kim", "Jaekyeom", ""], ["Jeong", "Yeonwoo", ""], ["Levine", "Sergey", ""], ["Song", "Hyun Oh", ""]]}, {"id": "1810.01185", "submitter": "Alexandru Constantin Serban", "authors": "Alexandru Constantin Serban, Erik Poll, Joost Visser", "title": "Adversarial Examples - A Complete Characterisation of the Phenomenon", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.CR cs.LG cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We provide a complete characterisation of the phenomenon of adversarial\nexamples - inputs intentionally crafted to fool machine learning models. We aim\nto cover all the important concerns in this field of study: (1) the conjectures\non the existence of adversarial examples, (2) the security, safety and\nrobustness implications, (3) the methods used to generate and (4) protect\nagainst adversarial examples and (5) the ability of adversarial examples to\ntransfer between different machine learning models. We provide ample background\ninformation in an effort to make this document self-contained. Therefore, this\ndocument can be used as survey, tutorial or as a catalog of attacks and\ndefences using adversarial examples.\n", "versions": [{"version": "v1", "created": "Tue, 2 Oct 2018 11:54:51 GMT"}, {"version": "v2", "created": "Sun, 17 Feb 2019 21:48:42 GMT"}], "update_date": "2019-02-19", "authors_parsed": [["Serban", "Alexandru Constantin", ""], ["Poll", "Erik", ""], ["Visser", "Joost", ""]]}, {"id": "1810.01187", "submitter": "Zixin Zhong", "authors": "Zixin Zhong, Wang Chi Cheung, Vincent Y. F. Tan", "title": "Thompson Sampling Algorithms for Cascading Bandits", "comments": "62 pages, 6 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Motivated by the pressing need for efficient optimization in online\nrecommender systems, we revisit the cascading bandit model proposed by Kveton\net al. (2015). While Thompson sampling (TS) algorithms have been shown to be\nempirically superior to Upper Confidence Bound (UCB) algorithms for cascading\nbandits, theoretical guarantees are only known for the latter. In this paper,\nwe first provide a problem-dependent upper bound on the regret of a TS\nalgorithm with Beta-Bernoulli updates; this upper bound is tighter than a\nrecent derivation under a more general setting by Huyuk and Tekin (2019). Next,\nwe design and analyze another TS algorithm with Gaussian updates, TS-Cascade.\nTS-Cascade achieves the state-of-the-art regret bound for cascading bandits.\nComplementarily, we consider a linear generalization of the cascading bandit\nmodel, which allows efficient learning in large cascading bandit problem\ninstances. We introduce and analyze a TS algorithm, which enjoys a regret bound\nthat depends on the dimension of the linear model but not the number of items.\nFinally, by using information-theoretic techniques and judiciously constructing\ncascading bandit instances, we derive a nearly matching regret lower bound for\nthe standard model. Our paper establishes the first theoretical guarantees on\nTS algorithms for stochastic combinatorial bandit problem model with partial\nfeedback. Numerical experiments demonstrate the superiority of the proposed TS\nalgorithms compared to existing UCB-based ones.\n", "versions": [{"version": "v1", "created": "Tue, 2 Oct 2018 11:55:54 GMT"}, {"version": "v2", "created": "Wed, 12 Jun 2019 13:08:10 GMT"}, {"version": "v3", "created": "Fri, 8 May 2020 16:56:18 GMT"}, {"version": "v4", "created": "Sun, 16 May 2021 03:20:10 GMT"}], "update_date": "2021-05-18", "authors_parsed": [["Zhong", "Zixin", ""], ["Cheung", "Wang Chi", ""], ["Tan", "Vincent Y. F.", ""]]}, {"id": "1810.01190", "submitter": "Yura Perov N", "authors": "Yura Perov", "title": "Inference Over Programs That Make Predictions", "comments": "The International Conference on Probabilistic Programming, 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.PL cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This abstract extends on the previous work (arXiv:1407.2646,\narXiv:1606.00075) on program induction using probabilistic programming. It\ndescribes possible further steps to extend that work, such that, ultimately,\nautomatic probabilistic program synthesis can generalise over any reasonable\nset of inputs and outputs, in particular in regard to text, image and video\ndata.\n", "versions": [{"version": "v1", "created": "Tue, 2 Oct 2018 12:00:41 GMT"}], "update_date": "2018-10-04", "authors_parsed": [["Perov", "Yura", ""]]}, {"id": "1810.01217", "submitter": "John Martin Jr", "authors": "John Martin, Jinkun Wang, Brendan Englot", "title": "Sparse Gaussian Process Temporal Difference Learning for Marine Robot\n  Navigation", "comments": "2018 Conference on Robot Learning (CoRL)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We present a method for Temporal Difference (TD) learning that addresses\nseveral challenges faced by robots learning to navigate in a marine\nenvironment. For improved data efficiency, our method reduces TD updates to\nGaussian Process regression. To make predictions amenable to online settings,\nwe introduce a sparse approximation with improved quality over current\nrejection-based sparse methods. We derive the predictive value function\nposterior and use the moments to obtain a new algorithm for model-free policy\nevaluation, SPGP-SARSA. With simple changes, we show SPGP-SARSA can be reduced\nto a model-based equivalent, SPGP-TD. We perform comprehensive simulation\nstudies and also conduct physical learning trials with an underwater robot. Our\nresults show SPGP-SARSA can outperform the state-of-the-art sparse method,\nreplicate the prediction quality of its exact counterpart, and be applied to\nsolve underwater navigation tasks.\n", "versions": [{"version": "v1", "created": "Tue, 2 Oct 2018 13:04:47 GMT"}], "update_date": "2018-10-03", "authors_parsed": [["Martin", "John", ""], ["Wang", "Jinkun", ""], ["Englot", "Brendan", ""]]}, {"id": "1810.01218", "submitter": "Yulin Shao", "authors": "Yulin Shao, Soung Chang Liew, Taotao Wang", "title": "AlphaSeq: Sequence Discovery with Deep Reinforcement Learning", "comments": "48 pages, 13 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Sequences play an important role in many applications and systems.\nDiscovering sequences with desired properties has long been an interesting\nintellectual pursuit. This paper puts forth a new paradigm, AlphaSeq, to\ndiscover desired sequences algorithmically using deep reinforcement learning\n(DRL) techniques. AlphaSeq treats the sequence discovery problem as an episodic\nsymbol-filling game, in which a player fills symbols in the vacant positions of\na sequence set sequentially during an episode of the game. Each episode ends\nwith a completely-filled sequence set, upon which a reward is given based on\nthe desirability of the sequence set. AlphaSeq models the game as a Markov\nDecision Process (MDP), and adapts the DRL framework of AlphaGo to solve the\nMDP. Sequences discovered improve progressively as AlphaSeq, starting as a\nnovice, learns to become an expert game player through many episodes of game\nplaying. Compared with traditional sequence construction by mathematical tools,\nAlphaSeq is particularly suitable for problems with complex objectives\nintractable to mathematical analysis. We demonstrate the searching capabilities\nof AlphaSeq in two applications: 1) AlphaSeq successfully rediscovers a set of\nideal complementary codes that can zero-force all potential interferences in\nmulti-carrier CDMA systems. 2) AlphaSeq discovers new sequences that triple the\nsignal-to-interference ratio -- benchmarked against the well-known Legendre\nsequence -- of a mismatched filter estimator in pulse compression radar\nsystems.\n", "versions": [{"version": "v1", "created": "Wed, 26 Sep 2018 18:30:42 GMT"}, {"version": "v2", "created": "Tue, 15 Jan 2019 21:21:05 GMT"}, {"version": "v3", "created": "Thu, 8 Aug 2019 03:28:46 GMT"}], "update_date": "2019-08-09", "authors_parsed": [["Shao", "Yulin", ""], ["Liew", "Soung Chang", ""], ["Wang", "Taotao", ""]]}, {"id": "1810.01222", "submitter": "Olivier Sigaud", "authors": "Alo\\\"is Pourchot and Olivier Sigaud", "title": "CEM-RL: Combining evolutionary and gradient-based methods for policy\n  search", "comments": "accepted at ICLR 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep neuroevolution and deep reinforcement learning (deep RL) algorithms are\ntwo popular approaches to policy search. The former is widely applicable and\nrather stable, but suffers from low sample efficiency. By contrast, the latter\nis more sample efficient, but the most sample efficient variants are also\nrather unstable and highly sensitive to hyper-parameter setting. So far, these\nfamilies of methods have mostly been compared as competing tools. However, an\nemerging approach consists in combining them so as to get the best of both\nworlds. Two previously existing combinations use either an ad hoc evolutionary\nalgorithm or a goal exploration process together with the Deep Deterministic\nPolicy Gradient (DDPG) algorithm, a sample efficient off-policy deep RL\nalgorithm. In this paper, we propose a different combination scheme using the\nsimple cross-entropy method (CEM) and Twin Delayed Deep Deterministic policy\ngradient (td3), another off-policy deep RL algorithm which improves over ddpg.\nWe evaluate the resulting method, cem-rl, on a set of benchmarks classically\nused in deep RL. We show that cem-rl benefits from several advantages over its\ncompetitors and offers a satisfactory trade-off between performance and sample\nefficiency.\n", "versions": [{"version": "v1", "created": "Tue, 2 Oct 2018 13:12:13 GMT"}, {"version": "v2", "created": "Mon, 26 Nov 2018 13:32:11 GMT"}, {"version": "v3", "created": "Mon, 11 Feb 2019 14:11:24 GMT"}], "update_date": "2019-02-12", "authors_parsed": [["Pourchot", "Alo\u00efs", ""], ["Sigaud", "Olivier", ""]]}, {"id": "1810.01240", "submitter": "Cyril Feau", "authors": "R\\'emi Sainct, Cyril Feau, Jean-Marc Martinez, Josselin Garnier", "title": "Efficient Seismic fragility curve estimation by Active Learning on\n  Support Vector Machines", "comments": "24 pages, 14 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG math.CA stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Fragility curves which express the failure probability of a structure, or\ncritical components, as function of a loading intensity measure are nowadays\nwidely used (i) in Seismic Probabilistic Risk Assessment studies, (ii) to\nevaluate impact of construction details on the structural performance of\ninstallations under seismic excitations or under other loading sources such as\nwind. To avoid the use of parametric models such as lognormal model to estimate\nfragility curves from a reduced number of numerical calculations, a methodology\nbased on Support Vector Machines coupled with an active learning algorithm is\nproposed in this paper. In practice, input excitation is reduced to some\nrelevant parameters and, given these parameters, SVMs are used for a binary\nclassification of the structural responses relative to a limit threshold of\nexceedance. Since the output is not only binary, this is a score, a\nprobabilistic interpretation of the output is exploited to estimate very\nefficiently fragility curves as score functions or as functions of classical\nseismic intensity measures.\n", "versions": [{"version": "v1", "created": "Tue, 25 Sep 2018 08:22:39 GMT"}], "update_date": "2018-10-03", "authors_parsed": [["Sainct", "R\u00e9mi", ""], ["Feau", "Cyril", ""], ["Martinez", "Jean-Marc", ""], ["Garnier", "Josselin", ""]]}, {"id": "1810.01243", "submitter": "Melpomeni Kalofonou", "authors": "Mohammed Khwaja, Melpomeni Kalofonou and Chris Toumazou", "title": "A Deep Autoencoder System for Differentiation of Cancer Types Based on\n  DNA Methylation State", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.QM cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A Deep Autoencoder based content retrieval algorithm is proposed for\nprediction and differentiation of cancer types based on the presence of\nepigenetic patterns of DNA methylation identified in genetic regions known as\nCpG islands. The developed deep learning system uses a CpG island state\nclassification sub-system to complete sets of missing/incomplete island data in\ngiven human cell lines, and is then pipelined with an intricate set of\nstatistical and signal processing methods to accurately predict the presence of\ncancer and further differentiate the type and cell of origin in the event of a\npositive result. The proposed system was trained with previously reported data\nderived from four case groups of cancer cell lines, achieving overall\nSensitivity of 88.24%, Specificity of 83.33%, Accuracy of 84.75% and Matthews\nCorrelation Coefficient of 0.687. The ability to predict and differentiate\ncancer types using epigenetic events as the identifying patterns was\ndemonstrated in previously reported data sets from breast, lung, lymphoblastic\nleukemia and urological cancer cell lines, allowing the pipelined system to be\nrobust and adjustable to other cancer cell lines or epigenetic events.\n", "versions": [{"version": "v1", "created": "Tue, 2 Oct 2018 13:44:37 GMT"}, {"version": "v2", "created": "Fri, 5 Oct 2018 14:17:49 GMT"}], "update_date": "2018-10-08", "authors_parsed": [["Khwaja", "Mohammed", ""], ["Kalofonou", "Melpomeni", ""], ["Toumazou", "Chris", ""]]}, {"id": "1810.01248", "submitter": "Xutan Peng", "authors": "Xutan Peng, Chenghua Lin, Chen Li, Zhi Cai, Jianxin Li", "title": "A Lightweight Music Texture Transfer System", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SD cs.LG cs.MM eess.AS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep learning researches on the transformation problems for image and text\nhave raised great attention. However, present methods for music feature\ntransfer using neural networks are far from practical application. In this\npaper, we initiate a novel system for transferring the texture of music, and\nrelease it as an open source project. Its core algorithm is composed of a\nconverter which represents sounds as texture spectra, a corresponding\nreconstructor and a feed-forward transfer network. We evaluate this system from\nmultiple perspectives, and experimental results reveal that it achieves\nconvincing results in both sound effects and computational performance.\n", "versions": [{"version": "v1", "created": "Thu, 27 Sep 2018 16:03:53 GMT"}, {"version": "v2", "created": "Wed, 25 Nov 2020 15:00:30 GMT"}], "update_date": "2020-11-26", "authors_parsed": [["Peng", "Xutan", ""], ["Lin", "Chenghua", ""], ["Li", "Chen", ""], ["Cai", "Zhi", ""], ["Li", "Jianxin", ""]]}, {"id": "1810.01256", "submitter": "Yang Chen", "authors": "Guanxiong Zeng, Yang Chen, Bo Cui, Shan Yu", "title": "Continual Learning of Context-dependent Processing in Neural Networks", "comments": null, "journal-ref": null, "doi": "10.1038/s42256-019-0080-x", "report-no": null, "categories": "cs.LG cs.AI cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep neural networks (DNNs) are powerful tools in learning sophisticated but\nfixed mapping rules between inputs and outputs, thereby limiting their\napplication in more complex and dynamic situations in which the mapping rules\nare not kept the same but changing according to different contexts. To lift\nsuch limits, we developed a novel approach involving a learning algorithm,\ncalled orthogonal weights modification (OWM), with the addition of a\ncontext-dependent processing (CDP) module. We demonstrated that with OWM to\novercome the problem of catastrophic forgetting, and the CDP module to learn\nhow to reuse a feature representation and a classifier for different contexts,\na single network can acquire numerous context-dependent mapping rules in an\nonline and continual manner, with as few as $\\sim$10 samples to learn each.\nThis should enable highly compact systems to gradually learn myriad\nregularities of the real world and eventually behave appropriately within it.\n", "versions": [{"version": "v1", "created": "Sat, 29 Sep 2018 09:45:08 GMT"}, {"version": "v2", "created": "Fri, 5 Oct 2018 15:36:51 GMT"}, {"version": "v3", "created": "Sun, 27 Jun 2021 13:38:39 GMT"}], "update_date": "2021-06-29", "authors_parsed": [["Zeng", "Guanxiong", ""], ["Chen", "Yang", ""], ["Cui", "Bo", ""], ["Yu", "Shan", ""]]}, {"id": "1810.01266", "submitter": "Mohit Sharma", "authors": "Arjun Sharma, Mohit Sharma, Nicholas Rhinehart, Kris M. Kitani", "title": "Directed-Info GAIL: Learning Hierarchical Policies from Unsegmented\n  Demonstrations using Directed Information", "comments": "Accepted as conference paper at ICLR'19", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The use of imitation learning to learn a single policy for a complex task\nthat has multiple modes or hierarchical structure can be challenging. In fact,\nprevious work has shown that when the modes are known, learning separate\npolicies for each mode or sub-task can greatly improve the performance of\nimitation learning. In this work, we discover the interaction between sub-tasks\nfrom their resulting state-action trajectory sequences using a directed\ngraphical model. We propose a new algorithm based on the generative adversarial\nimitation learning framework which automatically learns sub-task policies from\nunsegmented demonstrations. Our approach maximizes the directed information\nflow in the graphical model between sub-task latent variables and their\ngenerated trajectories. We also show how our approach connects with the\nexisting Options framework, which is commonly used to learn hierarchical\npolicies.\n", "versions": [{"version": "v1", "created": "Sat, 29 Sep 2018 18:40:13 GMT"}, {"version": "v2", "created": "Tue, 12 Mar 2019 02:06:19 GMT"}], "update_date": "2019-03-13", "authors_parsed": [["Sharma", "Arjun", ""], ["Sharma", "Mohit", ""], ["Rhinehart", "Nicholas", ""], ["Kitani", "Kris M.", ""]]}, {"id": "1810.01268", "submitter": "Yash Sharma", "authors": "Yash Sharma, Tien-Dung Le, Moustafa Alzantot", "title": "CAAD 2018: Generating Transferable Adversarial Examples", "comments": "1st place attack solutions and 3rd place defense in CAAD 2018\n  Competition", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep neural networks (DNNs) are vulnerable to adversarial examples,\nperturbations carefully crafted to fool the targeted DNN, in both the\nnon-targeted and targeted case. In the non-targeted case, the attacker simply\naims to induce misclassification. In the targeted case, the attacker aims to\ninduce classification to a specified target class. In addition, it has been\nobserved that strong adversarial examples can transfer to unknown models,\nyielding a serious security concern. The NIPS 2017 competition was organized to\naccelerate research in adversarial attacks and defenses, taking place in the\nrealistic setting where submitted adversarial attacks attempt to transfer to\nsubmitted defenses. The CAAD 2018 competition took place with nearly identical\nrules to the NIPS 2017 one. Given the requirement that the NIPS 2017\nsubmissions were to be open-sourced, participants in the CAAD 2018 competition\nwere able to directly build upon previous solutions, and thus improve the\nstate-of-the-art in this setting. Our team participated in the CAAD 2018\ncompetition, and won 1st place in both attack subtracks, non-targeted and\ntargeted adversarial attacks, and 3rd place in defense. We outline our\nsolutions and development results in this article. We hope our results can\ninform researchers in both generating and defending against adversarial\nexamples.\n", "versions": [{"version": "v1", "created": "Sat, 29 Sep 2018 17:57:24 GMT"}, {"version": "v2", "created": "Wed, 21 Nov 2018 08:32:51 GMT"}], "update_date": "2018-11-22", "authors_parsed": [["Sharma", "Yash", ""], ["Le", "Tien-Dung", ""], ["Alzantot", "Moustafa", ""]]}, {"id": "1810.01269", "submitter": "Adrian Wills", "authors": "Adrian Wills, Carl Jidling, Thomas Schon", "title": "A fast quasi-Newton-type method for large-scale stochastic optimisation", "comments": "arXiv admin note: substantial text overlap with arXiv:1802.04310", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.OC cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  During recent years there has been an increased interest in stochastic\nadaptations of limited memory quasi-Newton methods, which compared to pure\ngradient-based routines can improve the convergence by incorporating second\norder information. In this work we propose a direct least-squares approach\nconceptually similar to the limited memory quasi-Newton methods, but that\ncomputes the search direction in a slightly different way. This is achieved in\na fast and numerically robust manner by maintaining a Cholesky factor of low\ndimension. This is combined with a stochastic line search relying upon\nfulfilment of the Wolfe condition in a backtracking manner, where the step\nlength is adaptively modified with respect to the optimisation progress. We\nsupport our new algorithm by providing several theoretical results guaranteeing\nits performance. The performance is demonstrated on real-world benchmark\nproblems which shows improved results in comparison with already established\nmethods.\n", "versions": [{"version": "v1", "created": "Sat, 29 Sep 2018 20:59:41 GMT"}], "update_date": "2018-10-03", "authors_parsed": [["Wills", "Adrian", ""], ["Jidling", "Carl", ""], ["Schon", "Thomas", ""]]}, {"id": "1810.01270", "submitter": "Rafael Menelau Oliveira E Cruz", "authors": "Rafael M. O. Cruz, Robert Sabourin, George D. C. Cavalcanti and Tsang\n  Ing Ren", "title": "META-DES: A Dynamic Ensemble Selection Framework using Meta-Learning", "comments": "Article published on Pattern Recognition. arXiv admin note: text\n  overlap with arXiv:1509.00825", "journal-ref": "Pattern Recognition Volume 48, Issue 5, Pages 1925-1935", "doi": "10.1016/j.patcog.2014.12.003", "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Dynamic ensemble selection systems work by estimating the level of competence\nof each classifier from a pool of classifiers. Only the most competent ones are\nselected to classify a given test sample. This is achieved by defining a\ncriterion to measure the level of competence of a base classifier, such as, its\naccuracy in local regions of the feature space around the query instance.\nHowever, using only one criterion about the behavior of a base classifier is\nnot sufficient to accurately estimate its level of competence. In this paper,\nwe present a novel dynamic ensemble selection framework using meta-learning. We\npropose five distinct sets of meta-features, each one corresponding to a\ndifferent criterion to measure the level of competence of a classifier for the\nclassification of input samples. The meta-features are extracted from the\ntraining data and used to train a meta-classifier to predict whether or not a\nbase classifier is competent enough to classify an input instance. During the\ngeneralization phase, the meta-features are extracted from the query instance\nand passed down as input to the meta-classifier. The meta-classifier estimates,\nwhether a base classifier is competent enough to be added to the ensemble.\nExperiments are conducted over several small sample size classification\nproblems, i.e., problems with a high degree of uncertainty due to the lack of\ntraining data. Experimental results show the proposed meta-learning framework\ngreatly improves classification accuracy when compared against current\nstate-of-the-art dynamic ensemble selection techniques.\n", "versions": [{"version": "v1", "created": "Sun, 30 Sep 2018 00:27:49 GMT"}], "update_date": "2020-03-06", "authors_parsed": [["Cruz", "Rafael M. O.", ""], ["Sabourin", "Robert", ""], ["Cavalcanti", "George D. C.", ""], ["Ren", "Tsang Ing", ""]]}, {"id": "1810.01279", "submitter": "Xuanqing Liu", "authors": "Xuanqing Liu, Yao Li, Chongruo Wu, Cho-Jui Hsieh", "title": "Adv-BNN: Improved Adversarial Defense through Robust Bayesian Neural\n  Network", "comments": "Code will be made available at\n  https://github.com/xuanqing94/BayesianDefense", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a new algorithm to train a robust neural network against\nadversarial attacks. Our algorithm is motivated by the following two ideas.\nFirst, although recent work has demonstrated that fusing randomness can improve\nthe robustness of neural networks (Liu 2017), we noticed that adding noise\nblindly to all the layers is not the optimal way to incorporate randomness.\nInstead, we model randomness under the framework of Bayesian Neural Network\n(BNN) to formally learn the posterior distribution of models in a scalable way.\nSecond, we formulate the mini-max problem in BNN to learn the best model\ndistribution under adversarial attacks, leading to an adversarial-trained\nBayesian neural net. Experiment results demonstrate that the proposed algorithm\nachieves state-of-the-art performance under strong attacks. On CIFAR-10 with\nVGG network, our model leads to 14\\% accuracy improvement compared with\nadversarial training (Madry 2017) and random self-ensemble (Liu 2017) under PGD\nattack with $0.035$ distortion, and the gap becomes even larger on a subset of\nImageNet.\n", "versions": [{"version": "v1", "created": "Mon, 1 Oct 2018 05:23:15 GMT"}, {"version": "v2", "created": "Sat, 4 May 2019 06:39:11 GMT"}], "update_date": "2019-05-07", "authors_parsed": [["Liu", "Xuanqing", ""], ["Li", "Yao", ""], ["Wu", "Chongruo", ""], ["Hsieh", "Cho-Jui", ""]]}, {"id": "1810.01316", "submitter": "Paolo Bestagini", "authors": "Paolo Bestagini, Federico Lombardi, Maurizio Lualdi, Francesco\n  Picetti, Stefano Tubaro", "title": "Landmine Detection Using Autoencoders on Multi-polarization GPR\n  Volumetric Data", "comments": "https://github.com/polimi-ispl/landmine_detection_autoencoder", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Buried landmines and unexploded remnants of war are a constant threat for the\npopulation of many countries that have been hit by wars in the past years. The\nhuge amount of human lives lost due to this phenomenon has been a strong\nmotivation for the research community toward the development of safe and robust\ntechniques designed for landmine clearance. Nonetheless, being able to detect\nand localize buried landmines with high precision in an automatic fashion is\nstill considered a challenging task due to the many different boundary\nconditions that characterize this problem (e.g., several kinds of objects to\ndetect, different soils and meteorological conditions, etc.). In this paper, we\npropose a novel technique for buried object detection tailored to unexploded\nlandmine discovery. The proposed solution exploits a specific kind of\nconvolutional neural network (CNN) known as autoencoder to analyze volumetric\ndata acquired with ground penetrating radar (GPR) using different\npolarizations. This method works in an anomaly detection framework, indeed we\nonly train the autoencoder on GPR data acquired on landmine-free areas. The\nsystem then recognizes landmines as objects that are dissimilar to the soil\nused during the training step. Experiments conducted on real data show that the\nproposed technique requires little training and no ad-hoc data pre-processing\nto achieve accuracy higher than 93% on challenging datasets.\n", "versions": [{"version": "v1", "created": "Tue, 2 Oct 2018 15:10:31 GMT"}], "update_date": "2018-10-03", "authors_parsed": [["Bestagini", "Paolo", ""], ["Lombardi", "Federico", ""], ["Lualdi", "Maurizio", ""], ["Picetti", "Francesco", ""], ["Tubaro", "Stefano", ""]]}, {"id": "1810.01322", "submitter": "L\\'eonard Blier", "authors": "L\\'eonard Blier, Pierre Wolinski, Yann Ollivier", "title": "Learning with Random Learning Rates", "comments": "20 pages, 8 figures, code available on GitHub", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Hyperparameter tuning is a bothersome step in the training of deep learning\nmodels. One of the most sensitive hyperparameters is the learning rate of the\ngradient descent. We present the 'All Learning Rates At Once' (Alrao)\noptimization method for neural networks: each unit or feature in the network\ngets its own learning rate sampled from a random distribution spanning several\norders of magnitude. This comes at practically no computational cost. Perhaps\nsurprisingly, stochastic gradient descent (SGD) with Alrao performs close to\nSGD with an optimally tuned learning rate, for various architectures and\nproblems. Alrao could save time when testing deep learning models: a range of\nmodels could be quickly assessed with Alrao, and the most promising models\ncould then be trained more extensively. This text comes with a PyTorch\nimplementation of the method, which can be plugged on an existing PyTorch\nmodel: https://github.com/leonardblier/alrao .\n", "versions": [{"version": "v1", "created": "Tue, 2 Oct 2018 15:21:07 GMT"}, {"version": "v2", "created": "Wed, 3 Oct 2018 21:52:49 GMT"}, {"version": "v3", "created": "Tue, 29 Jan 2019 14:29:19 GMT"}], "update_date": "2019-01-30", "authors_parsed": [["Blier", "L\u00e9onard", ""], ["Wolinski", "Pierre", ""], ["Ollivier", "Yann", ""]]}, {"id": "1810.01344", "submitter": "Alban Laflaqui\\`ere Dr", "authors": "Alban Laflaqui\\`ere and Michael Garcia Ortiz", "title": "Unsupervised Emergence of Spatial Structure from Sensorimotor Prediction", "comments": "16 pages, 6 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Despite its omnipresence in robotics application, the nature of spatial\nknowledge and the mechanisms that underlie its emergence in autonomous agents\nare still poorly understood. Recent theoretical work suggests that the concept\nof space can be grounded by capturing invariants induced by the structure of\nspace in an agent's raw sensorimotor experience. Moreover, it is hypothesized\nthat capturing these invariants is beneficial for a naive agent trying to\npredict its sensorimotor experience. Under certain exploratory conditions,\nspatial representations should thus emerge as a byproduct of learning to\npredict. We propose a simple sensorimotor predictive scheme, apply it to\ndifferent agents and types of exploration, and evaluate the pertinence of this\nhypothesis. We show that a naive agent can capture the topology and metric\nregularity of its spatial configuration without any a priori knowledge, nor\nextraneous supervision.\n", "versions": [{"version": "v1", "created": "Tue, 2 Oct 2018 16:12:53 GMT"}, {"version": "v2", "created": "Tue, 27 Nov 2018 13:53:15 GMT"}], "update_date": "2018-11-28", "authors_parsed": [["Laflaqui\u00e8re", "Alban", ""], ["Ortiz", "Michael Garcia", ""]]}, {"id": "1810.01363", "submitter": "Rui Zhao", "authors": "Rui Zhao and Volker Tresp", "title": "Energy-Based Hindsight Experience Prioritization", "comments": "Published in Conference on Robot Learning (CoRL 2018) as oral\n  presentation (7%), Zurich, Switzerland", "journal-ref": "PMLR 87:113-122, 2018", "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In Hindsight Experience Replay (HER), a reinforcement learning agent is\ntrained by treating whatever it has achieved as virtual goals. However, in\nprevious work, the experience was replayed at random, without considering which\nepisode might be the most valuable for learning. In this paper, we develop an\nenergy-based framework for prioritizing hindsight experience in robotic\nmanipulation tasks. Our approach is inspired by the work-energy principle in\nphysics. We define a trajectory energy function as the sum of the transition\nenergy of the target object over the trajectory. We hypothesize that replaying\nepisodes that have high trajectory energy is more effective for reinforcement\nlearning in robotics. To verify our hypothesis, we designed a framework for\nhindsight experience prioritization based on the trajectory energy of goal\nstates. The trajectory energy function takes the potential, kinetic, and\nrotational energy into consideration. We evaluate our Energy-Based\nPrioritization (EBP) approach on four challenging robotic manipulation tasks in\nsimulation. Our empirical results show that our proposed method surpasses\nstate-of-the-art approaches in terms of both performance and sample-efficiency\non all four tasks, without increasing computational time. A video showing\nexperimental results is available at https://youtu.be/jtsF2tTeUGQ\n", "versions": [{"version": "v1", "created": "Tue, 2 Oct 2018 16:42:35 GMT"}, {"version": "v2", "created": "Wed, 3 Oct 2018 08:04:51 GMT"}, {"version": "v3", "created": "Mon, 8 Oct 2018 14:44:40 GMT"}, {"version": "v4", "created": "Wed, 20 Feb 2019 10:15:33 GMT"}, {"version": "v5", "created": "Sun, 24 May 2020 07:57:13 GMT"}], "update_date": "2020-05-26", "authors_parsed": [["Zhao", "Rui", ""], ["Tresp", "Volker", ""]]}, {"id": "1810.01365", "submitter": "Neil Houlsby", "authors": "Ting Chen, Mario Lucic, Neil Houlsby, Sylvain Gelly", "title": "On Self Modulation for Generative Adversarial Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Training Generative Adversarial Networks (GANs) is notoriously challenging.\nWe propose and study an architectural modification, self-modulation, which\nimproves GAN performance across different data sets, architectures, losses,\nregularizers, and hyperparameter settings. Intuitively, self-modulation allows\nthe intermediate feature maps of a generator to change as a function of the\ninput noise vector. While reminiscent of other conditioning techniques, it\nrequires no labeled data. In a large-scale empirical study we observe a\nrelative decrease of $5\\%-35\\%$ in FID. Furthermore, all else being equal,\nadding this modification to the generator leads to improved performance in\n$124/144$ ($86\\%$) of the studied settings. Self-modulation is a simple\narchitectural change that requires no additional parameter tuning, which\nsuggests that it can be applied readily to any GAN.\n", "versions": [{"version": "v1", "created": "Tue, 2 Oct 2018 16:50:28 GMT"}, {"version": "v2", "created": "Thu, 2 May 2019 07:20:50 GMT"}], "update_date": "2019-05-03", "authors_parsed": [["Chen", "Ting", ""], ["Lucic", "Mario", ""], ["Houlsby", "Neil", ""], ["Gelly", "Sylvain", ""]]}, {"id": "1810.01367", "submitter": "Ricky T. Q. Chen", "authors": "Will Grathwohl, Ricky T. Q. Chen, Jesse Bettencourt, Ilya Sutskever,\n  David Duvenaud", "title": "FFJORD: Free-form Continuous Dynamics for Scalable Reversible Generative\n  Models", "comments": "8 Pages, 6 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A promising class of generative models maps points from a simple distribution\nto a complex distribution through an invertible neural network.\nLikelihood-based training of these models requires restricting their\narchitectures to allow cheap computation of Jacobian determinants.\nAlternatively, the Jacobian trace can be used if the transformation is\nspecified by an ordinary differential equation. In this paper, we use\nHutchinson's trace estimator to give a scalable unbiased estimate of the\nlog-density. The result is a continuous-time invertible generative model with\nunbiased density estimation and one-pass sampling, while allowing unrestricted\nneural network architectures. We demonstrate our approach on high-dimensional\ndensity estimation, image generation, and variational inference, achieving the\nstate-of-the-art among exact likelihood methods with efficient sampling.\n", "versions": [{"version": "v1", "created": "Tue, 2 Oct 2018 16:56:37 GMT"}, {"version": "v2", "created": "Wed, 3 Oct 2018 15:28:48 GMT"}, {"version": "v3", "created": "Mon, 22 Oct 2018 17:56:45 GMT"}], "update_date": "2018-10-23", "authors_parsed": [["Grathwohl", "Will", ""], ["Chen", "Ricky T. Q.", ""], ["Bettencourt", "Jesse", ""], ["Sutskever", "Ilya", ""], ["Duvenaud", "David", ""]]}, {"id": "1810.01371", "submitter": "Rui Zhao", "authors": "Rui Zhao, Volker Tresp", "title": "Efficient Dialog Policy Learning via Positive Memory Retention", "comments": "Published in IEEE Spoken Language Technology (SLT 2018), Athens,\n  Greece", "journal-ref": null, "doi": "10.1109/SLT.2018.8639617", "report-no": null, "categories": "cs.AI cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper is concerned with the training of recurrent neural networks as\ngoal-oriented dialog agents using reinforcement learning. Training such agents\nwith policy gradients typically requires a large amount of samples. However,\nthe collection of the required data in form of conversations between chat-bots\nand human agents is time-consuming and expensive. To mitigate this problem, we\ndescribe an efficient policy gradient method using positive memory retention,\nwhich significantly increases the sample-efficiency. We show that our method is\n10 times more sample-efficient than policy gradients in extensive experiments\non a new synthetic number guessing game. Moreover, in a real-word visual object\ndiscovery game, the proposed method is twice as sample-efficient as policy\ngradients and shows state-of-the-art performance.\n", "versions": [{"version": "v1", "created": "Tue, 2 Oct 2018 17:01:28 GMT"}, {"version": "v2", "created": "Wed, 20 Feb 2019 10:26:56 GMT"}, {"version": "v3", "created": "Sun, 24 May 2020 08:08:15 GMT"}], "update_date": "2020-05-26", "authors_parsed": [["Zhao", "Rui", ""], ["Tresp", "Volker", ""]]}, {"id": "1810.01373", "submitter": "Mingjie Wang", "authors": "Mingjie Wang, Jun Zhou, Wendong Mao, Minglun Gong", "title": "Multi-scale Convolution Aggregation and Stochastic Feature Reuse for\n  DenseNets", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recently, Convolution Neural Networks (CNNs) obtained huge success in\nnumerous vision tasks. In particular, DenseNets have demonstrated that feature\nreuse via dense skip connections can effectively alleviate the difficulty of\ntraining very deep networks and that reusing features generated by the initial\nlayers in all subsequent layers has strong impact on performance. To feed even\nricher information into the network, a novel adaptive Multi-scale Convolution\nAggregation module is presented in this paper. Composed of layers for\nmulti-scale convolutions, trainable cross-scale aggregation, maxout, and\nconcatenation, this module is highly non-linear and can boost the accuracy of\nDenseNet while using much fewer parameters. In addition, due to high model\ncomplexity, the network with extremely dense feature reuse is prone to\noverfitting. To address this problem, a regularization method named Stochastic\nFeature Reuse is also presented. Through randomly dropping a set of feature\nmaps to be reused for each mini-batch during the training phase, this\nregularization method reduces training costs and prevents co-adaptation.\nExperimental results on CIFAR-10, CIFAR-100 and SVHN benchmarks demonstrated\nthe effectiveness of the proposed methods.\n", "versions": [{"version": "v1", "created": "Tue, 2 Oct 2018 17:07:35 GMT"}], "update_date": "2018-10-04", "authors_parsed": [["Wang", "Mingjie", ""], ["Zhou", "Jun", ""], ["Mao", "Wendong", ""], ["Gong", "Minglun", ""]]}, {"id": "1810.01392", "submitter": "Eric Jang", "authors": "Hyunsun Choi and Eric Jang and Alexander A. Alemi", "title": "WAIC, but Why? Generative Ensembles for Robust Anomaly Detection", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Machine learning models encounter Out-of-Distribution (OoD) errors when the\ndata seen at test time are generated from a different stochastic generator than\nthe one used to generate the training data. One proposal to scale OoD detection\nto high-dimensional data is to learn a tractable likelihood approximation of\nthe training distribution, and use it to reject unlikely inputs. However,\nlikelihood models on natural data are themselves susceptible to OoD errors, and\neven assign large likelihoods to samples from other datasets. To mitigate this\nproblem, we propose Generative Ensembles, which robustify density-based OoD\ndetection by way of estimating epistemic uncertainty of the likelihood model.\nWe present a puzzling observation in need of an explanation -- although\nlikelihood measures cannot account for the typical set of a distribution, and\ntherefore should not be suitable on their own for OoD detection, WAIC performs\nsurprisingly well in practice.\n", "versions": [{"version": "v1", "created": "Tue, 2 Oct 2018 17:32:07 GMT"}, {"version": "v2", "created": "Wed, 24 Oct 2018 19:17:06 GMT"}, {"version": "v3", "created": "Fri, 1 Feb 2019 01:04:10 GMT"}, {"version": "v4", "created": "Thu, 23 May 2019 23:48:06 GMT"}], "update_date": "2019-05-27", "authors_parsed": [["Choi", "Hyunsun", ""], ["Jang", "Eric", ""], ["Alemi", "Alexander A.", ""]]}, {"id": "1810.01395", "submitter": "Jonathan Le Roux", "authors": "Jonathan Le Roux, Gordon Wichern, Shinji Watanabe, Andy Sarroff, John\n  R. Hershey", "title": "Phasebook and Friends: Leveraging Discrete Representations for Source\n  Separation", "comments": null, "journal-ref": null, "doi": "10.1109/JSTSP.2019.2904183", "report-no": null, "categories": "cs.SD cs.CL cs.LG eess.AS stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep learning based speech enhancement and source separation systems have\nrecently reached unprecedented levels of quality, to the point that performance\nis reaching a new ceiling. Most systems rely on estimating the magnitude of a\ntarget source by estimating a real-valued mask to be applied to a\ntime-frequency representation of the mixture signal. A limiting factor in such\napproaches is a lack of phase estimation: the phase of the mixture is most\noften used when reconstructing the estimated time-domain signal. Here, we\npropose \"magbook\", \"phasebook\", and \"combook\", three new types of layers based\non discrete representations that can be used to estimate complex time-frequency\nmasks. Magbook layers extend classical sigmoidal units and a recently\nintroduced convex softmax activation for mask-based magnitude estimation.\nPhasebook layers use a similar structure to give an estimate of the phase mask\nwithout suffering from phase wrapping issues. Combook layers are an alternative\nto the magbook-phasebook combination that directly estimate complex masks. We\npresent various training and inference schemes involving these representations,\nand explain in particular how to include them in an end-to-end learning\nframework. We also present an oracle study to assess upper bounds on\nperformance for various types of masks using discrete phase representations. We\nevaluate the proposed methods on the wsj0-2mix dataset, a well-studied corpus\nfor single-channel speaker-independent speaker separation, matching the\nperformance of state-of-the-art mask-based approaches without requiring\nadditional phase reconstruction steps.\n", "versions": [{"version": "v1", "created": "Tue, 2 Oct 2018 17:36:23 GMT"}, {"version": "v2", "created": "Thu, 7 Mar 2019 16:26:58 GMT"}], "update_date": "2019-06-26", "authors_parsed": [["Roux", "Jonathan Le", ""], ["Wichern", "Gordon", ""], ["Watanabe", "Shinji", ""], ["Sarroff", "Andy", ""], ["Hershey", "John R.", ""]]}, {"id": "1810.01398", "submitter": "Sara Sabour", "authors": "Sara Sabour, William Chan, Mohammad Norouzi", "title": "Optimal Completion Distillation for Sequence Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CL stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present Optimal Completion Distillation (OCD), a training procedure for\noptimizing sequence to sequence models based on edit distance. OCD is\nefficient, has no hyper-parameters of its own, and does not require pretraining\nor joint optimization with conditional log-likelihood. Given a partial sequence\ngenerated by the model, we first identify the set of optimal suffixes that\nminimize the total edit distance, using an efficient dynamic programming\nalgorithm. Then, for each position of the generated sequence, we use a target\ndistribution that puts equal probability on the first token of all the optimal\nsuffixes. OCD achieves the state-of-the-art performance on end-to-end speech\nrecognition, on both Wall Street Journal and Librispeech datasets, achieving\n$9.3\\%$ WER and $4.5\\%$ WER respectively.\n", "versions": [{"version": "v1", "created": "Tue, 2 Oct 2018 17:44:44 GMT"}, {"version": "v2", "created": "Mon, 14 Jan 2019 21:30:20 GMT"}], "update_date": "2019-01-16", "authors_parsed": [["Sabour", "Sara", ""], ["Chan", "William", ""], ["Norouzi", "Mohammad", ""]]}, {"id": "1810.01400", "submitter": "Joseph Tassarotti", "authors": "Joseph Tassarotti, Jean-Baptiste Tristan, Michael Wick", "title": "Sketching for Latent Dirichlet-Categorical Models", "comments": "20 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent work has explored transforming data sets into smaller, approximate\nsummaries in order to scale Bayesian inference. We examine a related problem in\nwhich the parameters of a Bayesian model are very large and expensive to store\nin memory, and propose more compact representations of parameter values that\ncan be used during inference. We focus on a class of graphical models that we\nrefer to as latent Dirichlet-Categorical models, and show how a combination of\ntwo sketching algorithms known as count-min sketch and approximate counters\nprovide an efficient representation for them. We show that this sketch\ncombination -- which, despite having been used before in NLP applications, has\nnot been previously analyzed -- enjoys desirable properties. We prove that for\nthis class of models, when the sketches are used during Markov Chain Monte\nCarlo inference, the equilibrium of sketched MCMC converges to that of the\nexact chain as sketch parameters are tuned to reduce the error rate.\n", "versions": [{"version": "v1", "created": "Tue, 2 Oct 2018 17:47:04 GMT"}], "update_date": "2018-10-03", "authors_parsed": [["Tassarotti", "Joseph", ""], ["Tristan", "Jean-Baptiste", ""], ["Wick", "Michael", ""]]}, {"id": "1810.01403", "submitter": "Shubhomoy Das", "authors": "Md Rakibul Islam, Shubhomoy Das, Janardhan Rao Doppa and Sriraam\n  Natarajan", "title": "GLAD: GLocalized Anomaly Detection via Human-in-the-Loop Learning", "comments": "Presented at the ICML-2020 Workshop on Human in the Loop Learning; 8\n  pages, 8 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Human analysts that use anomaly detection systems in practice want to retain\nthe use of simple and explainable global anomaly detectors. In this paper, we\npropose a novel human-in-the-loop learning algorithm called GLAD (GLocalized\nAnomaly Detection) that supports global anomaly detectors. GLAD automatically\nlearns their local relevance to specific data instances using label feedback\nfrom human analysts. The key idea is to place a uniform prior on the relevance\nof each member of the anomaly detection ensemble over the input feature space\nvia a neural network trained on unlabeled instances. Subsequently, weights of\nthe neural network are tuned to adjust the local relevance of each ensemble\nmember using all labeled instances. GLAD also provides explanations which can\nimprove the understanding of end-users about anomalies. Our experiments on\nsynthetic and real-world data show the effectiveness of GLAD in learning the\nlocal relevance of ensemble members and discovering anomalies via label\nfeedback.\n", "versions": [{"version": "v1", "created": "Tue, 2 Oct 2018 17:54:15 GMT"}, {"version": "v2", "created": "Mon, 8 Oct 2018 04:03:00 GMT"}, {"version": "v3", "created": "Fri, 12 Oct 2018 21:04:17 GMT"}, {"version": "v4", "created": "Wed, 15 Jul 2020 19:37:15 GMT"}], "update_date": "2020-07-17", "authors_parsed": [["Islam", "Md Rakibul", ""], ["Das", "Shubhomoy", ""], ["Doppa", "Janardhan Rao", ""], ["Natarajan", "Sriraam", ""]]}, {"id": "1810.01405", "submitter": "Jayaraman J. Thiagarajan", "authors": "Uday Shankar Shanthamallu, Jayaraman J. Thiagarajan, Huan Song and\n  Andreas Spanias", "title": "GrAMME: Semi-Supervised Learning using Multi-layered Graph Attention\n  Models", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Modern data analysis pipelines are becoming increasingly complex due to the\npresence of multi-view information sources. While graphs are effective in\nmodeling complex relationships, in many scenarios a single graph is rarely\nsufficient to succinctly represent all interactions, and hence multi-layered\ngraphs have become popular. Though this leads to richer representations,\nextending solutions from the single-graph case is not straightforward.\nConsequently, there is a strong need for novel solutions to solve classical\nproblems, such as node classification, in the multi-layered case. In this\npaper, we consider the problem of semi-supervised learning with multi-layered\ngraphs. Though deep network embeddings, e.g. DeepWalk, are widely adopted for\ncommunity discovery, we argue that feature learning with random node\nattributes, using graph neural networks, can be more effective. To this end, we\npropose to use attention models for effective feature learning, and develop two\nnovel architectures, GrAMME-SG and GrAMME-Fusion, that exploit the inter-layer\ndependencies for building multi-layered graph embeddings. Using empirical\nstudies on several benchmark datasets, we evaluate the proposed approaches and\ndemonstrate significant performance improvements in comparison to\nstate-of-the-art network embedding strategies. The results also show that using\nsimple random features is an effective choice, even in cases where explicit\nnode attributes are not available.\n", "versions": [{"version": "v1", "created": "Tue, 2 Oct 2018 17:57:20 GMT"}, {"version": "v2", "created": "Wed, 27 Mar 2019 16:57:26 GMT"}], "update_date": "2019-04-02", "authors_parsed": [["Shanthamallu", "Uday Shankar", ""], ["Thiagarajan", "Jayaraman J.", ""], ["Song", "Huan", ""], ["Spanias", "Andreas", ""]]}, {"id": "1810.01406", "submitter": "Ke Li", "authors": "Ke Li, Shichong Peng, Jitendra Malik", "title": "Super-Resolution via Conditional Implicit Maximum Likelihood Estimation", "comments": "12 pages, 7 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV cs.GR cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Single-image super-resolution (SISR) is a canonical problem with diverse\napplications. Leading methods like SRGAN produce images that contain various\nartifacts, such as high-frequency noise, hallucinated colours and shape\ndistortions, which adversely affect the realism of the result. In this paper,\nwe propose an alternative approach based on an extension of the method of\nImplicit Maximum Likelihood Estimation (IMLE). We demonstrate greater\neffectiveness at noise reduction and preservation of the original colours and\nshapes, yielding more realistic super-resolved images.\n", "versions": [{"version": "v1", "created": "Tue, 2 Oct 2018 17:58:02 GMT"}], "update_date": "2018-10-03", "authors_parsed": [["Li", "Ke", ""], ["Peng", "Shichong", ""], ["Malik", "Jitendra", ""]]}, {"id": "1810.01407", "submitter": "Mohammad Mahmoody", "authors": "Saeed Mahloujifar and Mohammad Mahmoody", "title": "Can Adversarially Robust Learning Leverage Computational Hardness?", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CC cs.CR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Making learners robust to adversarial perturbation at test time (i.e.,\nevasion attacks) or training time (i.e., poisoning attacks) has emerged as a\nchallenging task. It is known that for some natural settings, sublinear\nperturbations in the training phase or the testing phase can drastically\ndecrease the quality of the predictions. These negative results, however, are\ninformation theoretic and only prove the existence of such successful\nadversarial perturbations. A natural question for these settings is whether or\nnot we can make classifiers computationally robust to polynomial-time attacks.\n  In this work, we prove strong barriers against achieving such envisioned\ncomputational robustness both for evasion and poisoning attacks. In particular,\nwe show that if the test instances come from a product distribution (e.g.,\nuniform over $\\{0,1\\}^n$ or $[0,1]^n$, or isotropic $n$-variate Gaussian) and\nthat there is an initial constant error, then there exists a polynomial-time\nattack that finds adversarial examples of Hamming distance $O(\\sqrt n)$. For\npoisoning attacks, we prove that for any learning algorithm with sample\ncomplexity $m$ and any efficiently computable \"predicate\" defining some \"bad\"\nproperty $B$ for the produced hypothesis (e.g., failing on a particular test)\nthat happens with an initial constant probability, there exist polynomial-time\nonline poisoning attacks that tamper with $O (\\sqrt m)$ many examples, replace\nthem with other correctly labeled examples, and increases the probability of\nthe bad event $B$ to $\\approx 1$.\n  Both of our poisoning and evasion attacks are black-box in how they access\ntheir corresponding components of the system (i.e., the hypothesis, the\nconcept, and the learning algorithm) and make no further assumptions about the\nclassifier or the learning algorithm producing the classifier.\n", "versions": [{"version": "v1", "created": "Tue, 2 Oct 2018 17:58:23 GMT"}, {"version": "v2", "created": "Mon, 22 Oct 2018 04:53:12 GMT"}, {"version": "v3", "created": "Tue, 6 Nov 2018 04:19:41 GMT"}], "update_date": "2018-11-07", "authors_parsed": [["Mahloujifar", "Saeed", ""], ["Mahmoody", "Mohammad", ""]]}, {"id": "1810.01414", "submitter": "Ramzan Umarov", "authors": "Ramzan Umarov, Hiroyuki Kuwahara, Yu Li, Xin Gao, Victor Solovyev", "title": "PromID: human promoter prediction by deep learning", "comments": "18 pages, 8 figures, 2 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.GN cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Computational identification of promoters is notoriously difficult as human\ngenes often have unique promoter sequences that provide regulation of\ntranscription and interaction with transcription initiation complex. While\nthere are many attempts to develop computational promoter identification\nmethods, we have no reliable tool to analyze long genomic sequences. In this\nwork we further develop our deep learning approach that was relatively\nsuccessful to discriminate short promoter and non-promoter sequences. Instead\nof focusing on the classification accuracy, in this work we predict the exact\npositions of the TSS inside the genomic sequences testing every possible\nlocation. We studied human promoters to find effective regions for\ndiscrimination and built corresponding deep learning models. These models use\nadaptively constructed negative set which iteratively improves the models\ndiscriminative ability. The developed promoter identification models\nsignificantly outperform the previously developed promoter prediction programs\nby considerably reducing the number of false positive predictions. The best\nmodel we have built has recall 0.76, precision 0.77 and MCC 0.76, while the\nnext best tool FPROM achieved precision 0.48 and MCC 0.60 for the recall of\n0.75. Our method is available at http://www.cbrc.kaust.edu.sa/PromID/.\n", "versions": [{"version": "v1", "created": "Tue, 2 Oct 2018 17:35:46 GMT"}], "update_date": "2018-10-04", "authors_parsed": [["Umarov", "Ramzan", ""], ["Kuwahara", "Hiroyuki", ""], ["Li", "Yu", ""], ["Gao", "Xin", ""], ["Solovyev", "Victor", ""]]}, {"id": "1810.01468", "submitter": "Gaurav Singh", "authors": "Gaurav Singh, James Thomas, Iain J. Marshall, John Shawe-Taylor and\n  Byron C. Wallace", "title": "Structured Multi-Label Biomedical Text Tagging via Attentive Neural Tree\n  Decoding", "comments": "Accepted for Publication in EMNLP 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a model for tagging unstructured texts with an arbitrary number of\nterms drawn from a tree-structured vocabulary (i.e., an ontology). We treat\nthis as a special case of sequence-to-sequence learning in which the decoder\nbegins at the root node of an ontological tree and recursively elects to expand\nchild nodes as a function of the input text, the current node, and the latent\ndecoder state. In our experiments the proposed method outperforms\nstate-of-the-art approaches on the important task of automatically assigning\nMeSH terms to biomedical abstracts.\n", "versions": [{"version": "v1", "created": "Tue, 2 Oct 2018 19:32:12 GMT"}], "update_date": "2018-10-04", "authors_parsed": [["Singh", "Gaurav", ""], ["Thomas", "James", ""], ["Marshall", "Iain J.", ""], ["Shawe-Taylor", "John", ""], ["Wallace", "Byron C.", ""]]}, {"id": "1810.01477", "submitter": "Houssam Nassif", "authors": "Choon Hui Teo, Houssam Nassif, Daniel Hill, Sriram Srinavasan,\n  Mitchell Goodman, Vijai Mohan, SVN Vishwanathan", "title": "Adaptive, Personalized Diversity for Visual Discovery", "comments": "Best Paper Award", "journal-ref": "Adaptive, Personalized Diversity for Visual Discovery. Teo CH,\n  Nassif H, Hill D, Srinavasan S, Goodman M, Mohan V, and Vishwanathan SVN. ACM\n  Conference on Recommender Systems (RecSys'16), Boston, pp. 35-38, 2016", "doi": "10.1145/2959100.2959171", "report-no": null, "categories": "cs.IR cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Search queries are appropriate when users have explicit intent, but they\nperform poorly when the intent is difficult to express or if the user is simply\nlooking to be inspired. Visual browsing systems allow e-commerce platforms to\naddress these scenarios while offering the user an engaging shopping\nexperience. Here we explore extensions in the direction of adaptive\npersonalization and item diversification within Stream, a new form of visual\nbrowsing and discovery by Amazon. Our system presents the user with a diverse\nset of interesting items while adapting to user interactions. Our solution\nconsists of three components (1) a Bayesian regression model for scoring the\nrelevance of items while leveraging uncertainty, (2) a submodular\ndiversification framework that re-ranks the top scoring items based on\ncategory, and (3) personalized category preferences learned from the user's\nbehavior. When tested on live traffic, our algorithms show a strong lift in\nclick-through-rate and session duration.\n", "versions": [{"version": "v1", "created": "Tue, 2 Oct 2018 19:51:46 GMT"}], "update_date": "2018-10-04", "authors_parsed": [["Teo", "Choon Hui", ""], ["Nassif", "Houssam", ""], ["Hill", "Daniel", ""], ["Srinavasan", "Sriram", ""], ["Goodman", "Mitchell", ""], ["Mohan", "Vijai", ""], ["Vishwanathan", "SVN", ""]]}, {"id": "1810.01485", "submitter": "Patrick Schwab", "authors": "Patrick Schwab, Walter Karlen", "title": "PhoneMD: Learning to Diagnose Parkinson's Disease from Smartphone Data", "comments": "AAAI Conference on Artificial Intelligence 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.NC cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Parkinson's disease is a neurodegenerative disease that can affect a person's\nmovement, speech, dexterity, and cognition. Clinicians primarily diagnose\nParkinson's disease by performing a clinical assessment of symptoms. However,\nmisdiagnoses are common. One factor that contributes to misdiagnoses is that\nthe symptoms of Parkinson's disease may not be prominent at the time the\nclinical assessment is performed. Here, we present a machine-learning approach\ntowards distinguishing between people with and without Parkinson's disease\nusing long-term data from smartphone-based walking, voice, tapping and memory\ntests. We demonstrate that our attentive deep-learning models achieve\nsignificant improvements in predictive performance over strong baselines (area\nunder the receiver operating characteristic curve = 0.85) in data from a cohort\nof 1853 participants. We also show that our models identify meaningful features\nin the input data. Our results confirm that smartphone data collected over\nextended periods of time could in the future potentially be used as a digital\nbiomarker for the diagnosis of Parkinson's disease.\n", "versions": [{"version": "v1", "created": "Mon, 1 Oct 2018 11:38:18 GMT"}, {"version": "v2", "created": "Wed, 14 Nov 2018 23:53:32 GMT"}], "update_date": "2018-11-16", "authors_parsed": [["Schwab", "Patrick", ""], ["Karlen", "Walter", ""]]}, {"id": "1810.01488", "submitter": "Maruti Mudunuru", "authors": "B. Yuan, Y. J. Tan, M. K. Mudunuru, O. E. Marcillo, A. A. Delorey, P.\n  M. Roberts, J. D. Webster, C. N. L. Gammans, S. Karra, G. D. Guthrie, and P.\n  A. Johnson", "title": "Using Machine Learning to Discern Eruption in Noisy Environments: A Case\n  Study using CO2-driven Cold-Water Geyser in Chimayo, New Mexico", "comments": "16 pages,7 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.SP cs.LG physics.data-an physics.geo-ph stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present an approach based on machine learning (ML) to distinguish eruption\nand precursory signals of Chimay\\'{o} geyser (New Mexico, USA) under noisy\nenvironments. This geyser can be considered as a natural analog of\n$\\mathrm{CO}_2$ intrusion into shallow water aquifers. By studying this geyser,\nwe can understand upwelling of $\\mathrm{CO}_2$-rich fluids from depth, which\nhas relevance to leak monitoring in a $\\mathrm{CO}_2$ sequestration project. ML\nmethods such as Random Forests (RF) are known to be robust multi-class\nclassifiers and perform well under unfavorable noisy conditions. However, the\nextent of the RF method's accuracy is poorly understood for this\n$\\mathrm{CO}_2$-driven geysering application. The current study aims to\nquantify the performance of RF-classifiers to discern the geyser state. Towards\nthis goal, we first present the data collected from the seismometer that is\ninstalled near the Chimay\\'{o} geyser. The seismic signals collected at this\nsite contain different types of noises such as daily temperature variations,\nseasonal trends, animal movement near the geyser, and human activity. First, we\nfilter the signals from these noises by combining the Butterworth-Highpass\nfilter and an Autoregressive method in a multi-level fashion. We show that by\ncombining these filtering techniques, in a hierarchical fashion, leads to\nreduction in the noise in the seismic data without removing the precursors and\neruption event signals. We then use RF on the filtered data to classify the\nstate of geyser into three classes -- remnant noise, precursor, and eruption\nstates. We show that the classification accuracy using RF on the filtered data\nis greater than 90\\%.These aspects make the proposed ML framework attractive\nfor event discrimination and signal enhancement under noisy conditions, with\nstrong potential for application to monitoring leaks in $\\mathrm{CO}_2$\nsequestration.\n", "versions": [{"version": "v1", "created": "Mon, 1 Oct 2018 15:47:34 GMT"}], "update_date": "2018-10-04", "authors_parsed": [["Yuan", "B.", ""], ["Tan", "Y. J.", ""], ["Mudunuru", "M. K.", ""], ["Marcillo", "O. E.", ""], ["Delorey", "A. A.", ""], ["Roberts", "P. M.", ""], ["Webster", "J. D.", ""], ["Gammans", "C. N. L.", ""], ["Karra", "S.", ""], ["Guthrie", "G. D.", ""], ["Johnson", "P. A.", ""]]}, {"id": "1810.01520", "submitter": "Hamed Zamani", "authors": "Hamed Zamani, Markus Schedl, Paul Lamere, Ching-Wei Chen", "title": "An Analysis of Approaches Taken in the ACM RecSys Challenge 2018 for\n  Automatic Music Playlist Continuation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.LG cs.MM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The ACM Recommender Systems Challenge 2018 focused on the task of automatic\nmusic playlist continuation, which is a form of the more general task of\nsequential recommendation. Given a playlist of arbitrary length with some\nadditional meta-data, the task was to recommend up to 500 tracks that fit the\ntarget characteristics of the original playlist. For the RecSys Challenge,\nSpotify released a dataset of one million user-generated playlists.\nParticipants could compete in two tracks, i.e., main and creative tracks.\nParticipants in the main track were only allowed to use the provided training\nset, however, in the creative track, the use of external public sources was\npermitted. In total, 113 teams submitted 1,228 runs to the main track; 33 teams\nsubmitted 239 runs to the creative track. The highest performing team in the\nmain track achieved an R-precision of 0.2241, an NDCG of 0.3946, and an average\nnumber of recommended songs clicks of 1.784. In the creative track, an\nR-precision of 0.2233, an NDCG of 0.3939, and a click rate of 1.785 was\nobtained by the best team. This article provides an overview of the challenge,\nincluding motivation, task definition, dataset description, and evaluation. We\nfurther report and analyze the results obtained by the top performing teams in\neach track and explore the approaches taken by the winners. We finally\nsummarize our key findings, discuss generalizability of approaches and results\nto domains other than music, and list the open avenues and possible future\ndirections in the area of automatic playlist continuation.\n", "versions": [{"version": "v1", "created": "Tue, 2 Oct 2018 21:19:19 GMT"}, {"version": "v2", "created": "Sat, 31 Aug 2019 22:13:33 GMT"}], "update_date": "2019-09-04", "authors_parsed": [["Zamani", "Hamed", ""], ["Schedl", "Markus", ""], ["Lamere", "Paul", ""], ["Chen", "Ching-Wei", ""]]}, {"id": "1810.01534", "submitter": "Daoud Burghal", "authors": "Daoud Burghal, Rui Wang, and Andreas F. Molisch", "title": "Band Assignment in Dual Band Systems: A Learning-based Approach", "comments": "7 pages, 2 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.SP cs.LG cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the band assignment problem in dual band systems, where the\nbase-station (BS) chooses one of the two available frequency bands\n(centimeter-wave and millimeter-wave bands) to communicate data to the mobile\nstation (MS). While the millimeter-wave band offers higher data rate when it is\navailable, there is a significant probability of outage during which the\ncommunication should be carried on the centimeter-wave band.\n  In this work, we use a machine learning framework to provide an efficient and\npractical solution to the band assignment problem. In particular, the BS trains\na Neural Network (NN) to predict the right band assignment decision using\nobserved channel information. We study the performance of the NN in two\nenvironments: (i) A stochastic channel model with correlated bands, and (ii)\nmicrocellular outdoor channels obtained by simulations with a commercial\nray-tracer. For the former case, for sake of comparison we also develop a\nthreshold based band assignment that relies on the optimal mean square error\nestimator of the best band. In addition, we study the performance of the\nNN-based solution with different NN structures and different observed\nparameters (position, field strength, etc.). We compare the achieved\nperformance to linear and logistic regression based solutions as well as the\nthreshold based solution. Under practical constraints, the learning based band\nassignment shows competitive or superior performance in both environments.\n", "versions": [{"version": "v1", "created": "Tue, 2 Oct 2018 22:05:43 GMT"}], "update_date": "2018-10-04", "authors_parsed": [["Burghal", "Daoud", ""], ["Wang", "Rui", ""], ["Molisch", "Andreas F.", ""]]}, {"id": "1810.01538", "submitter": "Andee Kaplan", "authors": "Andee Kaplan, Brenda Betancourt, and Rebecca C. Steorts", "title": "Posterior Prototyping: Bridging the Gap between Bayesian Record Linkage\n  and Regression", "comments": "23 pages, 13 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ME cs.DB cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Record linkage (entity resolution or de-deduplication) is the process of\nmerging noisy databases to remove duplicate entities. While record linkage\nremoves duplicate entities from the data, many researchers are interested in\nperforming inference, prediction or post-linkage analysis on the linked data,\nwhich we call the downstream task. Depending on the downstream task, one may\nwish to find the most representative record before performing the post-linkage\nanalysis. Motivated by the downstream task, we propose first performing record\nlinkage using a Bayesian model and then choosing representative records through\nprototyping. Given the information about the representative records, we then\nexplore two downstream tasks - linear regression and binary classification via\nlogistic regression. In addition, we explore how error propagation occurs in\nboth of these settings. We provide thorough empirical studies for our proposed\nmethodology, and conclude with a discussion of practical insights into our\nwork.\n", "versions": [{"version": "v1", "created": "Tue, 2 Oct 2018 22:55:58 GMT"}], "update_date": "2018-10-12", "authors_parsed": [["Kaplan", "Andee", ""], ["Betancourt", "Brenda", ""], ["Steorts", "Rebecca C.", ""]]}, {"id": "1810.01539", "submitter": "Lawrence Murray", "authors": "Lawrence M. Murray and Thomas B. Sch\\\"on", "title": "Automated learning with a probabilistic programming language: Birch", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This work offers a broad perspective on probabilistic modeling and inference\nin light of recent advances in probabilistic programming, in which models are\nformally expressed in Turing-complete programming languages. We consider a\ntypical workflow and how probabilistic programming languages can help to\nautomate this workflow, especially in the matching of models with inference\nmethods. We focus on two properties of a model that are critical in this\nmatching: its structure---the conditional dependencies between random\nvariables---and its form---the precise mathematical definition of those\ndependencies. While the structure and form of a probabilistic model are often\nfixed a priori, it is a curiosity of probabilistic programming that they need\nnot be, and may instead vary according to random choices made during program\nexecution. We introduce a formal description of models expressed as programs,\nand discuss some of the ways in which probabilistic programming languages can\nreveal the structure and form of these, in order to tailor inference methods.\nWe demonstrate the ideas with a new probabilistic programming language called\nBirch, with a multiple object tracking example.\n", "versions": [{"version": "v1", "created": "Tue, 2 Oct 2018 23:00:36 GMT"}, {"version": "v2", "created": "Fri, 17 Apr 2020 00:16:13 GMT"}], "update_date": "2020-04-20", "authors_parsed": [["Murray", "Lawrence M.", ""], ["Sch\u00f6n", "Thomas B.", ""]]}, {"id": "1810.01545", "submitter": "Clayton Scott", "authors": "Clayton Scott", "title": "A Generalized Neyman-Pearson Criterion for Optimal Domain Adaptation", "comments": "ALT 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In the problem of domain adaptation for binary classification, the learner is\npresented with labeled examples from a source domain, and must correctly\nclassify unlabeled examples from a target domain, which may differ from the\nsource. Previous work on this problem has assumed that the performance measure\nof interest is the expected value of some loss function. We introduce a new\nNeyman-Pearson-like criterion and argue that, for this optimality criterion,\nstronger domain adaptation results are possible than what has previously been\nestablished. In particular, we study a class of domain adaptation problems that\ngeneralizes both the covariate shift assumption and a model for\nfeature-dependent label noise, and establish optimal classification on the\ntarget domain despite not having access to labelled data from this domain.\n", "versions": [{"version": "v1", "created": "Wed, 3 Oct 2018 00:16:41 GMT"}, {"version": "v2", "created": "Wed, 27 Feb 2019 20:43:00 GMT"}], "update_date": "2019-03-01", "authors_parsed": [["Scott", "Clayton", ""]]}, {"id": "1810.01566", "submitter": "Yunzhu Li", "authors": "Yunzhu Li, Jiajun Wu, Russ Tedrake, Joshua B. Tenenbaum, Antonio\n  Torralba", "title": "Learning Particle Dynamics for Manipulating Rigid Bodies, Deformable\n  Objects, and Fluids", "comments": "Accepted to ICLR 2019. Project Page: http://dpi.csail.mit.edu Video:\n  https://www.youtube.com/watch?v=FrPpP7aW3Lg", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.RO physics.comp-ph stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Real-life control tasks involve matters of various substances---rigid or soft\nbodies, liquid, gas---each with distinct physical behaviors. This poses\nchallenges to traditional rigid-body physics engines. Particle-based simulators\nhave been developed to model the dynamics of these complex scenes; however,\nrelying on approximation techniques, their simulation often deviates from\nreal-world physics, especially in the long term. In this paper, we propose to\nlearn a particle-based simulator for complex control tasks. Combining learning\nwith particle-based systems brings in two major benefits: first, the learned\nsimulator, just like other particle-based systems, acts widely on objects of\ndifferent materials; second, the particle-based representation poses strong\ninductive bias for learning: particles of the same type have the same dynamics\nwithin. This enables the model to quickly adapt to new environments of unknown\ndynamics within a few observations. We demonstrate robots achieving complex\nmanipulation tasks using the learned simulator, such as manipulating fluids and\ndeformable foam, with experiments both in simulation and in the real world. Our\nstudy helps lay the foundation for robot learning of dynamic scenes with\nparticle-based representations.\n", "versions": [{"version": "v1", "created": "Wed, 3 Oct 2018 02:10:16 GMT"}, {"version": "v2", "created": "Thu, 18 Apr 2019 00:37:03 GMT"}], "update_date": "2019-04-19", "authors_parsed": [["Li", "Yunzhu", ""], ["Wu", "Jiajun", ""], ["Tedrake", "Russ", ""], ["Tenenbaum", "Joshua B.", ""], ["Torralba", "Antonio", ""]]}, {"id": "1810.01575", "submitter": "Omid Poursaeed", "authors": "Omid Poursaeed, Guandao Yang, Aditya Prakash, Qiuren Fang, Hanqing\n  Jiang, Bharath Hariharan, Serge Belongie", "title": "Deep Fundamental Matrix Estimation without Correspondences", "comments": "ECCV 2018, Geometry Meets Deep Learning Workshop", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.CG cs.GR cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Estimating fundamental matrices is a classic problem in computer vision.\nTraditional methods rely heavily on the correctness of estimated key-point\ncorrespondences, which can be noisy and unreliable. As a result, it is\ndifficult for these methods to handle image pairs with large occlusion or\nsignificantly different camera poses. In this paper, we propose novel neural\nnetwork architectures to estimate fundamental matrices in an end-to-end manner\nwithout relying on point correspondences. New modules and layers are introduced\nin order to preserve mathematical properties of the fundamental matrix as a\nhomogeneous rank-2 matrix with seven degrees of freedom. We analyze performance\nof the proposed models using various metrics on the KITTI dataset, and show\nthat they achieve competitive performance with traditional methods without the\nneed for extracting correspondences.\n", "versions": [{"version": "v1", "created": "Wed, 3 Oct 2018 03:59:15 GMT"}], "update_date": "2018-10-04", "authors_parsed": [["Poursaeed", "Omid", ""], ["Yang", "Guandao", ""], ["Prakash", "Aditya", ""], ["Fang", "Qiuren", ""], ["Jiang", "Hanqing", ""], ["Hariharan", "Bharath", ""], ["Belongie", "Serge", ""]]}, {"id": "1810.01586", "submitter": "Maria Vasilyeva", "authors": "Maria Vasilyeva, Aleksey Tyrylgin", "title": "Machine learning for accelerating effective property prediction for\n  poroelasticity problem in stochastic media", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.NA cs.LG physics.comp-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we consider a numerical homogenization of the poroelasticity\nproblem with stochastic properties. The proposed method based on the\nconstruction of the deep neural network (DNN) for fast calculation of the\neffective properties for a coarse grid approximation of the problem. We train\nneural networks on the set of the selected realizations of the local microscale\nstochastic fields and macroscale characteristics (permeability and elasticity\ntensors). We construct a deep learning method through convolutional neural\nnetwork (CNN) to learn a map between stochastic fields and effective\nproperties. Numerical results are presented for two and three-dimensional model\nproblems and show that proposed method provide fast and accurate effective\nproperty predictions.\n", "versions": [{"version": "v1", "created": "Wed, 3 Oct 2018 05:21:03 GMT"}], "update_date": "2018-10-04", "authors_parsed": [["Vasilyeva", "Maria", ""], ["Tyrylgin", "Aleksey", ""]]}, {"id": "1810.01588", "submitter": "Chihiro Watanabe", "authors": "Chihiro Watanabe", "title": "Interpreting Layered Neural Networks via Hierarchical Modular\n  Representation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Interpreting the prediction mechanism of complex models is currently one of\nthe most important tasks in the machine learning field, especially with layered\nneural networks, which have achieved high predictive performance with various\npractical data sets. To reveal the global structure of a trained neural network\nin an interpretable way, a series of clustering methods have been proposed,\nwhich decompose the units into clusters according to the similarity of their\ninference roles. The main problems in these studies were that (1) we have no\nprior knowledge about the optimal resolution for the decomposition, or the\nappropriate number of clusters, and (2) there was no method with which to\nacquire knowledge about whether the outputs of each cluster have a positive or\nnegative correlation with the input and output dimension values. In this paper,\nto solve these problems, we propose a method for obtaining a hierarchical\nmodular representation of a layered neural network. The application of a\nhierarchical clustering method to a trained network reveals a tree-structured\nrelationship among hidden layer units, based on their feature vectors defined\nby their correlation with the input and output dimension values.\n", "versions": [{"version": "v1", "created": "Wed, 3 Oct 2018 05:38:26 GMT"}], "update_date": "2018-10-04", "authors_parsed": [["Watanabe", "Chihiro", ""]]}, {"id": "1810.01622", "submitter": "Wendi Xu", "authors": "Wendi Xu, Ming Zhang", "title": "Theory of Generative Deep Learning : Probe Landscape of Empirical Error\n  via Norm Based Capacity Control", "comments": "2018 5th IEEE International Conference on Cloud Computing and\n  Intelligence Systems", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Despite its remarkable empirical success as a highly competitive branch of\nartificial intelligence, deep learning is often blamed for its widely known low\ninterpretation and lack of firm and rigorous mathematical foundation. However,\nmost theoretical endeavor is devoted in discriminative deep learning case,\nwhose complementary part is generative deep learning. To the best of our\nknowledge, we firstly highlight landscape of empirical error in generative case\nto complete the full picture through exquisite design of image super resolution\nunder norm based capacity control. Our theoretical advance in interpretation of\nthe training dynamic is achieved from both mathematical and biological sides.\n", "versions": [{"version": "v1", "created": "Wed, 3 Oct 2018 08:10:51 GMT"}], "update_date": "2018-10-04", "authors_parsed": [["Xu", "Wendi", ""], ["Zhang", "Ming", ""]]}, {"id": "1810.01638", "submitter": "Yibo Yang", "authors": "Huan Li, Yibo Yang, Dongmin Chen, Zhouchen Lin", "title": "Optimization Algorithm Inspired Deep Neural Network Structure Design", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep neural networks have been one of the dominant machine learning\napproaches in recent years. Several new network structures are proposed and\nhave better performance than the traditional feedforward neural network\nstructure. Representative ones include the skip connection structure in ResNet\nand the dense connection structure in DenseNet. However, it still lacks a\nunified guidance for the neural network structure design. In this paper, we\npropose the hypothesis that the neural network structure design can be inspired\nby optimization algorithms and a faster optimization algorithm may lead to a\nbetter neural network structure. Specifically, we prove that the propagation in\nthe feedforward neural network with the same linear transformation in different\nlayers is equivalent to minimizing some function using the gradient descent\nalgorithm. Based on this observation, we replace the gradient descent algorithm\nwith the heavy ball algorithm and Nesterov's accelerated gradient descent\nalgorithm, which are faster and inspire us to design new and better network\nstructures. ResNet and DenseNet can be considered as two special cases of our\nframework. Numerical experiments on CIFAR-10, CIFAR-100 and ImageNet verify the\nadvantage of our optimization algorithm inspired structures over ResNet and\nDenseNet.\n", "versions": [{"version": "v1", "created": "Wed, 3 Oct 2018 08:59:41 GMT"}], "update_date": "2018-10-04", "authors_parsed": [["Li", "Huan", ""], ["Yang", "Yibo", ""], ["Chen", "Dongmin", ""], ["Lin", "Zhouchen", ""]]}, {"id": "1810.01683", "submitter": "Ichiro Takeuchi Prof.", "authors": "Hiroki Kato, Hiroyuki Hanada, Ichiro Takeuchi", "title": "Learning sparse optimal rule fit by safe screening", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we consider linear prediction models in the form of a sparse\nlinear combination of rules, where a rule is an indicator function defined over\na hyperrectangle in the input space. Since the number of all possible rules\ngenerated from the training dataset becomes extremely large, it has been\ndifficult to consider all of them when fitting a sparse model. In this paper,\nwe propose Safe Optimal Rule Fit (SORF) as an approach to resolve this problem,\nwhich is formulated as a convex optimization problem with sparse\nregularization. The proposed SORF method utilizes the fact that the set of all\npossible rules can be represented as a tree. By extending a recently\npopularized convex optimization technique called safe screening, we develop a\nnovel method for pruning the tree such that pruned nodes are guaranteed to be\nirrelevant to the prediction model. This approach allows us to efficiently\nlearn a prediction model constructed from an exponentially large number of all\npossible rules. We demonstrate the usefulness of the proposed method by\nnumerical experiments using several benchmark datasets.\n", "versions": [{"version": "v1", "created": "Wed, 3 Oct 2018 10:55:08 GMT"}], "update_date": "2018-10-04", "authors_parsed": [["Kato", "Hiroki", ""], ["Hanada", "Hiroyuki", ""], ["Takeuchi", "Ichiro", ""]]}, {"id": "1810.01765", "submitter": "Ramy Baly", "authors": "Ramy Baly (1), Georgi Karadzhov (3), Dimitar Alexandrov (3), James\n  Glass (1), Preslav Nakov (2) ((1) MIT Computer Science and Artificial\n  Intelligence Laboratory, (2) Qatar Computing Research Institute, HBKU, Qatar,\n  (3) Sofia University, Bulgaria)", "title": "Predicting Factuality of Reporting and Bias of News Media Sources", "comments": "Fact-checking, political ideology, news media, EMNLP-2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a study on predicting the factuality of reporting and bias of news\nmedia. While previous work has focused on studying the veracity of claims or\ndocuments, here we are interested in characterizing entire news media. These\nare under-studied but arguably important research problems, both in their own\nright and as a prior for fact-checking systems. We experiment with a large list\nof news websites and with a rich set of features derived from (i) a sample of\narticles from the target news medium, (ii) its Wikipedia page, (iii) its\nTwitter account, (iv) the structure of its URL, and (v) information about the\nWeb traffic it attracts. The experimental results show sizable performance\ngains over the baselines, and confirm the importance of each feature type.\n", "versions": [{"version": "v1", "created": "Tue, 2 Oct 2018 03:27:04 GMT"}], "update_date": "2018-10-04", "authors_parsed": [["Baly", "Ramy", ""], ["Karadzhov", "Georgi", ""], ["Alexandrov", "Dimitar", ""], ["Glass", "James", ""], ["Nakov", "Preslav", ""]]}, {"id": "1810.01778", "submitter": "Juho Lee", "authors": "Juho Lee, Lancelot F. James, Seungjin Choi, Fran\\c{c}ois Caron", "title": "A Bayesian model for sparse graphs with flexible degree distribution and\n  overlapping community structure", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG cs.SI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider a non-projective class of inhomogeneous random graph models with\ninterpretable parameters and a number of interesting asymptotic properties.\nUsing the results of Bollob\\'as et al. [2007], we show that i) the class of\nmodels is sparse and ii) depending on the choice of the parameters, the model\nis either scale-free, with power-law exponent greater than 2, or with an\nasymptotic degree distribution which is power-law with exponential cut-off. We\npropose an extension of the model that can accommodate an overlapping community\nstructure. Scalable posterior inference can be performed due to the specific\nchoice of the link probability. We present experiments on five different\nreal-world networks with up to 100,000 nodes and edges, showing that the model\ncan provide a good fit to the degree distribution and recovers well the latent\ncommunity structure.\n", "versions": [{"version": "v1", "created": "Wed, 3 Oct 2018 14:47:18 GMT"}], "update_date": "2018-10-04", "authors_parsed": [["Lee", "Juho", ""], ["James", "Lancelot F.", ""], ["Choi", "Seungjin", ""], ["Caron", "Fran\u00e7ois", ""]]}, {"id": "1810.01807", "submitter": "Romain Hennequin", "authors": "Jimena Royo-Letelier, Romain Hennequin, Viet-Anh Tran, Manuel\n  Moussallam", "title": "Disambiguating Music Artists at Scale with Audio Metric Learning", "comments": "published in ISMIR 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.AI cs.LG cs.SD stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We address the problem of disambiguating large scale catalogs through the\ndefinition of an unknown artist clustering task. We explore the use of metric\nlearning techniques to learn artist embeddings directly from audio, and using a\ndedicated homonym artists dataset, we compare our method with a recent approach\nthat learn similar embeddings using artist classifiers. While both systems have\nthe ability to disambiguate unknown artists relying exclusively on audio, we\nshow that our system is more suitable in the case when enough audio data is\navailable for each artist in the train dataset. We also propose a new negative\nsampling method for metric learning that takes advantage of side information\nsuch as music genre during the learning phase and shows promising results for\nthe artist clustering task.\n", "versions": [{"version": "v1", "created": "Wed, 3 Oct 2018 15:49:43 GMT"}], "update_date": "2018-10-04", "authors_parsed": [["Royo-Letelier", "Jimena", ""], ["Hennequin", "Romain", ""], ["Tran", "Viet-Anh", ""], ["Moussallam", "Manuel", ""]]}, {"id": "1810.01811", "submitter": "Pratik Jawanpuria", "authors": "Mayank Meghwanshi, Pratik Jawanpuria, Anoop Kunchukuttan, Hiroyuki\n  Kasai, Bamdev Mishra", "title": "McTorch, a manifold optimization library for deep learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we introduce McTorch, a manifold optimization library for deep\nlearning that extends PyTorch. It aims to lower the barrier for users wishing\nto use manifold constraints in deep learning applications, i.e., when the\nparameters are constrained to lie on a manifold. Such constraints include the\npopular orthogonality and rank constraints, and have been recently used in a\nnumber of applications in deep learning. McTorch follows PyTorch's architecture\nand decouples manifold definitions and optimizers, i.e., once a new manifold is\nadded it can be used with any existing optimizer and vice-versa. McTorch is\navailable at https://github.com/mctorch .\n", "versions": [{"version": "v1", "created": "Wed, 3 Oct 2018 16:02:20 GMT"}, {"version": "v2", "created": "Thu, 4 Oct 2018 04:12:12 GMT"}], "update_date": "2018-10-05", "authors_parsed": [["Meghwanshi", "Mayank", ""], ["Jawanpuria", "Pratik", ""], ["Kunchukuttan", "Anoop", ""], ["Kasai", "Hiroyuki", ""], ["Mishra", "Bamdev", ""]]}, {"id": "1810.01835", "submitter": "Lex Fridman", "authors": "Lex Fridman", "title": "Human-Centered Autonomous Vehicle Systems: Principles of Effective\n  Shared Autonomy", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.CV cs.HC cs.LG cs.RO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Building effective, enjoyable, and safe autonomous vehicles is a lot harder\nthan has historically been considered. The reason is that, simply put, an\nautonomous vehicle must interact with human beings. This interaction is not a\nrobotics problem nor a machine learning problem nor a psychology problem nor an\neconomics problem nor a policy problem. It is all of these problems put into\none. It challenges our assumptions about the limitations of human beings at\ntheir worst and the capabilities of artificial intelligence systems at their\nbest. This work proposes a set of principles for designing and building\nautonomous vehicles in a human-centered way that does not run away from the\ncomplexity of human nature but instead embraces it. We describe our development\nof the Human-Centered Autonomous Vehicle (HCAV) as an illustrative case study\nof implementing these principles in practice.\n", "versions": [{"version": "v1", "created": "Wed, 3 Oct 2018 16:36:22 GMT"}], "update_date": "2018-10-04", "authors_parsed": [["Fridman", "Lex", ""]]}, {"id": "1810.01849", "submitter": "Sudeep Pillai", "authors": "Sudeep Pillai, Rares Ambrus, Adrien Gaidon", "title": "SuperDepth: Self-Supervised, Super-Resolved Monocular Depth Estimation", "comments": "6 pages, 5 figures, 2 tables, ICRA 2019 Submission", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.LG cs.RO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent techniques in self-supervised monocular depth estimation are\napproaching the performance of supervised methods, but operate in low\nresolution only. We show that high resolution is key towards high-fidelity\nself-supervised monocular depth prediction. Inspired by recent deep learning\nmethods for Single-Image Super-Resolution, we propose a sub-pixel convolutional\nlayer extension for depth super-resolution that accurately synthesizes\nhigh-resolution disparities from their corresponding low-resolution\nconvolutional features. In addition, we introduce a differentiable\nflip-augmentation layer that accurately fuses predictions from the image and\nits horizontally flipped version, reducing the effect of left and right shadow\nregions generated in the disparity map due to occlusions. Both contributions\nprovide significant performance gains over the state-of-the-art in\nself-supervised depth and pose estimation on the public KITTI benchmark. A\nvideo of our approach can be found at https://youtu.be/jKNgBeBMx0I.\n", "versions": [{"version": "v1", "created": "Wed, 3 Oct 2018 17:24:06 GMT"}], "update_date": "2018-10-04", "authors_parsed": [["Pillai", "Sudeep", ""], ["Ambrus", "Rares", ""], ["Gaidon", "Adrien", ""]]}, {"id": "1810.01859", "submitter": "Houssam Nassif", "authors": "Neela Sawant, Chitti Babu Namballa, Narayanan Sadagopan, and Houssam\n  Nassif", "title": "Contextual Multi-Armed Bandits for Causal Marketing", "comments": null, "journal-ref": "Sawant N, Namballa CB, Sadagopan N, and Nassif H. Contextual\n  Multi-Armed Bandits for Causal Marketing. International Conference on Machine\n  Learning (ICML'18) Workshops, Stockholm, Sweden, 2018", "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This work explores the idea of a causal contextual multi-armed bandit\napproach to automated marketing, where we estimate and optimize the causal\n(incremental) effects. Focusing on causal effect leads to better return on\ninvestment (ROI) by targeting only the persuadable customers who wouldn't have\ntaken the action organically. Our approach draws on strengths of causal\ninference, uplift modeling, and multi-armed bandits. It optimizes on causal\ntreatment effects rather than pure outcome, and incorporates counterfactual\ngeneration within data collection. Following uplift modeling results, we\noptimize over the incremental business metric. Multi-armed bandit methods allow\nus to scale to multiple treatments and to perform off-policy policy evaluation\non logged data. The Thompson sampling strategy in particular enables\nexploration of treatments on similar customer contexts and materialization of\ncounterfactual outcomes. Preliminary offline experiments on a retail Fashion\nmarketing dataset show merits of our proposal.\n", "versions": [{"version": "v1", "created": "Tue, 2 Oct 2018 20:59:07 GMT"}], "update_date": "2018-10-05", "authors_parsed": [["Sawant", "Neela", ""], ["Namballa", "Chitti Babu", ""], ["Sadagopan", "Narayanan", ""], ["Nassif", "Houssam", ""]]}, {"id": "1810.01860", "submitter": "Luke Darlow", "authors": "Luke N. Darlow, Amos J. Storkey", "title": "GINN: Geometric Illustration of Neural Networks", "comments": "8 pages, 9 figures, technical report", "journal-ref": null, "doi": null, "report-no": "EDI-INF-ANC-1901", "categories": "cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by-sa/4.0/", "abstract": "  This informal technical report details the geometric illustration of decision\nboundaries for ReLU units in a three layer fully connected neural network. The\nnetwork is designed and trained to predict pixel intensity from an (x, y) input\nlocation. The Geometric Illustration of Neural Networks (GINN) tool was built\nto visualise and track the points at which ReLU units switch from being active\nto off (or vice versa) as the network undergoes training. Several phenomenon\nwere observed and are discussed herein. This technical report is a supporting\ndocument to the blog post with online demos and is available at\nhttp://www.bayeswatch.com/2018/09/17/GINN/.\n", "versions": [{"version": "v1", "created": "Tue, 2 Oct 2018 21:28:00 GMT"}], "update_date": "2018-10-05", "authors_parsed": [["Darlow", "Luke N.", ""], ["Storkey", "Amos J.", ""]]}, {"id": "1810.01861", "submitter": "Mateusz Susik", "authors": "Marcin Mo\\.zejko, Mateusz Susik, Rafa{\\l} Karczewski", "title": "Inhibited Softmax for Uncertainty Estimation in Neural Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a new method for uncertainty estimation and out-of-distribution\ndetection in neural networks with softmax output. We extend softmax layer with\nan additional constant input. The corresponding additional output is able to\nrepresent the uncertainty of the network. The proposed method requires neither\nadditional parameters nor multiple forward passes nor input preprocessing nor\nout-of-distribution datasets. We show that our method performs comparably to\nmore computationally expensive methods and outperforms baselines on our\nexperiments from image recognition and sentiment analysis domains.\n", "versions": [{"version": "v1", "created": "Wed, 3 Oct 2018 08:18:11 GMT"}, {"version": "v2", "created": "Sun, 7 Apr 2019 08:43:59 GMT"}], "update_date": "2019-04-09", "authors_parsed": [["Mo\u017cejko", "Marcin", ""], ["Susik", "Mateusz", ""], ["Karczewski", "Rafa\u0142", ""]]}, {"id": "1810.01864", "submitter": "Aryeh Kontorovich", "authors": "Steve Hanneke, Aryeh Kontorovich, Menachem Sadigurschi", "title": "Agnostic Sample Compression for Linear Regression", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.IT math.IT math.ST stat.ML stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We obtain the first positive results for bounded sample compression in the\nagnostic regression setting. We show that for p in {1,infinity}, agnostic\nlinear regression with $\\ell_p$ loss admits a bounded sample compression\nscheme. Specifically, we exhibit efficient sample compression schemes for\nagnostic linear regression in $R^d$ of size $d+1$ under the $\\ell_1$ loss and\nsize $d+2$ under the $\\ell_\\infty$ loss. We further show that for every other\n$\\ell_p$ loss (1 < p < infinity), there does not exist an agnostic compression\nscheme of bounded size. This refines and generalizes a negative result of\nDavid, Moran, and Yehudayoff (2016) for the $\\ell_2$ loss. We close by posing a\ngeneral open question: for agnostic regression with $\\ell_1$ loss, does every\nfunction class admit a compression scheme of size equal to its\npseudo-dimension? This question generalizes Warmuth's classic sample\ncompression conjecture for realizable-case classification (Warmuth, 2003).\n", "versions": [{"version": "v1", "created": "Wed, 3 Oct 2018 11:46:59 GMT"}], "update_date": "2018-10-05", "authors_parsed": [["Hanneke", "Steve", ""], ["Kontorovich", "Aryeh", ""], ["Sadigurschi", "Menachem", ""]]}, {"id": "1810.01865", "submitter": "Federico Pittino", "authors": "Federico Pittino, Roberto Diversi, Luca Benini, Andrea Bartolini", "title": "Robust identification of thermal models for in-production\n  High-Performance-Computing clusters with machine learning-based data\n  selection", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG eess.SP stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Power and thermal management are critical components of\nHigh-Performance-Computing (HPC) systems, due to their high power density and\nlarge total power consumption. The assessment of thermal dissipation by means\nof compact models directly from the thermal response of the final device\nenables more robust and precise thermal control strategies as well as automated\ndiagnosis. However, when dealing with large scale systems \"in production\", the\naccuracy of learned thermal models depends on the dynamics of the power\nexcitation, which depends also on the executed workload, and measurement\nnonidealities, such as quantization. In this paper we show that, using an\nadvanced system identification algorithm, we are able to generate very accurate\nthermal models (average error lower than our sensors quantization step of\n1{\\deg}C) for a large scale HPC system on real workloads for very long time\nperiods. However, we also show that: 1) not all real workloads allow for the\nidentification of a good model; 2) starting from the theory of system\nidentification it is very difficult to evaluate if a trace of data leads to a\ngood estimated model. We then propose and validate a set of techniques based on\nmachine learning and deep learning algorithms for the choice of data traces to\nbe used for model identification. We also show that deep learning techniques\nare absolutely necessary to correctly choose such traces up to 96% of the\ntimes.\n", "versions": [{"version": "v1", "created": "Wed, 3 Oct 2018 12:11:20 GMT"}, {"version": "v2", "created": "Wed, 7 Nov 2018 17:09:24 GMT"}], "update_date": "2018-11-08", "authors_parsed": [["Pittino", "Federico", ""], ["Diversi", "Roberto", ""], ["Benini", "Luca", ""], ["Bartolini", "Andrea", ""]]}, {"id": "1810.01866", "submitter": "Alban Laflaqui\\`ere Dr", "authors": "Alban Laflaqui\\`ere, Alexander V. Terekhov, Bruno Gas, J.Kevin O'Regan", "title": "Learning an internal representation of the end-effector configuration\n  space", "comments": "6 pages, 3 figures, IROS 2013", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.RO stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Current machine learning techniques proposed to automatically discover a\nrobot kinematics usually rely on a priori information about the robot's\nstructure, sensors properties or end-effector position. This paper proposes a\nmethod to estimate a certain aspect of the forward kinematics model with no\nsuch information. An internal representation of the end-effector configuration\nis generated from unstructured proprioceptive and exteroceptive data flow under\nvery limited assumptions. A mapping from the proprioceptive space to this\nrepresentational space can then be used to control the robot.\n", "versions": [{"version": "v1", "created": "Wed, 3 Oct 2018 12:56:08 GMT"}], "update_date": "2018-10-05", "authors_parsed": [["Laflaqui\u00e8re", "Alban", ""], ["Terekhov", "Alexander V.", ""], ["Gas", "Bruno", ""], ["O'Regan", "J. Kevin", ""]]}, {"id": "1810.01867", "submitter": "Alban Laflaqui\\`ere Dr", "authors": "Alban Laflaqui\\`ere, Sylvain Argentieri, Olivia Breysse, St\\'ephane\n  Genet, Bruno Gas", "title": "A Non-linear Approach to Space Dimension Perception by a Naive Agent", "comments": "7 pages, 6 images, published at IROS 2012", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.RO stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Developmental Robotics offers a new approach to numerous AI features that are\noften taken as granted. Traditionally, perception is supposed to be an inherent\ncapacity of the agent. Moreover, it largely relies on models built by the\nsystem's designer. A new approach is to consider perception as an\nexperimentally acquired ability that is learned exclusively through the\nanalysis of the agent's sensorimotor flow. Previous works, based on\nH.Poincar\\'e's intuitions and the sensorimotor contingencies theory, allow a\nsimulated agent to extract the dimension of geometrical space in which it is\nimmersed without any a priori knowledge. Those results are limited to\ninfinitesimal movement's amplitude of the system. In this paper, a non-linear\ndimension estimation method is proposed to push back this limitation.\n", "versions": [{"version": "v1", "created": "Wed, 3 Oct 2018 13:09:41 GMT"}], "update_date": "2018-10-05", "authors_parsed": [["Laflaqui\u00e8re", "Alban", ""], ["Argentieri", "Sylvain", ""], ["Breysse", "Olivia", ""], ["Genet", "St\u00e9phane", ""], ["Gas", "Bruno", ""]]}, {"id": "1810.01868", "submitter": "{\\L}ukasz Maziarka", "authors": "{\\L}ukasz Maziarka, Marek \\'Smieja, Aleksandra Nowak, Jacek Tabor,\n  {\\L}ukasz Struski, Przemys{\\l}aw Spurek", "title": "Set Aggregation Network as a Trainable Pooling Layer", "comments": "ICONIP 2019", "journal-ref": "Neural Information Processing. ICONIP 2019", "doi": "10.1007/978-3-030-36711-4_35", "report-no": null, "categories": "cs.LG cs.AI cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Global pooling, such as max- or sum-pooling, is one of the key ingredients in\ndeep neural networks used for processing images, texts, graphs and other types\nof structured data. Based on the recent DeepSets architecture proposed by\nZaheer et al. (NIPS 2017), we introduce a Set Aggregation Network (SAN) as an\nalternative global pooling layer. In contrast to typical pooling operators, SAN\nallows to embed a given set of features to a vector representation of arbitrary\nsize. We show that by adjusting the size of embedding, SAN is capable of\npreserving the whole information from the input. In experiments, we demonstrate\nthat replacing global pooling layer by SAN leads to the improvement of\nclassification accuracy. Moreover, it is less prone to overfitting and can be\nused as a regularizer.\n", "versions": [{"version": "v1", "created": "Wed, 3 Oct 2018 13:20:13 GMT"}, {"version": "v2", "created": "Wed, 27 Feb 2019 08:44:25 GMT"}, {"version": "v3", "created": "Mon, 25 Nov 2019 10:25:02 GMT"}], "update_date": "2020-01-23", "authors_parsed": [["Maziarka", "\u0141ukasz", ""], ["\u015amieja", "Marek", ""], ["Nowak", "Aleksandra", ""], ["Tabor", "Jacek", ""], ["Struski", "\u0141ukasz", ""], ["Spurek", "Przemys\u0142aw", ""]]}, {"id": "1810.01869", "submitter": "David Noever", "authors": "David Noever", "title": "Machine Learning Suites for Online Toxicity Detection", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CL cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  To identify and classify toxic online commentary, the modern tools of data\nscience transform raw text into key features from which either thresholding or\nlearning algorithms can make predictions for monitoring offensive\nconversations. We systematically evaluate 62 classifiers representing 19 major\nalgorithmic families against features extracted from the Jigsaw dataset of\nWikipedia comments. We compare the classifiers based on statistically\nsignificant differences in accuracy and relative execution time. Among these\nclassifiers for identifying toxic comments, tree-based algorithms provide the\nmost transparently explainable rules and rank-order the predictive contribution\nof each feature. Among 28 features of syntax, sentiment, emotion and outlier\nword dictionaries, a simple bad word list proves most predictive of offensive\ncommentary.\n", "versions": [{"version": "v1", "created": "Wed, 3 Oct 2018 13:22:44 GMT"}], "update_date": "2018-10-05", "authors_parsed": [["Noever", "David", ""]]}, {"id": "1810.01870", "submitter": "Alban Laflaqui\\`ere Dr", "authors": "Alban Laflaqui\\`ere, Nikolas Hemion, Micha\\\"el Garcia Ortiz,\n  Jean-Christophe Baillie", "title": "Grounding Perception: A Developmental Approach to Sensorimotor\n  Contingencies", "comments": "8 pages, 4 figures, workshop at IROS 2015 conference", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.RO stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Sensorimotor contingency theory offers a promising account of the nature of\nperception, a topic rarely addressed in the robotics community. We propose a\ndevelopmental framework to address the problem of the autonomous acquisition of\nsensorimotor contingencies by a naive robot. While exploring the world, the\nrobot internally encodes contingencies as predictive models that capture the\nstructure they imply in its sensorimotor experience. Three preliminary\napplications are presented to illustrate our approach to the acquisition of\nperceptive abilities: discovering the environment, discovering objects, and\ndiscovering a visual field.\n", "versions": [{"version": "v1", "created": "Wed, 3 Oct 2018 13:31:41 GMT"}], "update_date": "2018-10-05", "authors_parsed": [["Laflaqui\u00e8re", "Alban", ""], ["Hemion", "Nikolas", ""], ["Ortiz", "Micha\u00ebl Garcia", ""], ["Baillie", "Jean-Christophe", ""]]}, {"id": "1810.01871", "submitter": "Alban Laflaqui\\`ere Dr", "authors": "Alban Laflaqui\\`ere", "title": "Grounding the Experience of a Visual Field through Sensorimotor\n  Contingencies", "comments": "23 pages, 7 figures, published in Neurocomputing", "journal-ref": "Neurocomputing, Volume 268, 13 December 2017, Pages 142-152", "doi": "10.1016/j.neucom.2016.11.085", "report-no": null, "categories": "cs.LG cs.AI cs.RO stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Artificial perception is traditionally handled by hand-designing task\nspecific algorithms. However, a truly autonomous robot should develop\nperceptive abilities on its own, by interacting with its environment, and\nadapting to new situations. The sensorimotor contingencies theory proposes to\nground the development of those perceptive abilities in the way the agent can\nactively transform its sensory inputs. We propose a sensorimotor approach,\ninspired by this theory, in which the agent explores the world and discovers\nits properties by capturing the sensorimotor regularities they induce. This\nwork presents an application of this approach to the discovery of a so-called\nvisual field as the set of regularities that a visual sensor imposes on a naive\nagent's experience. A formalism is proposed to describe how those regularities\ncan be captured in a sensorimotor predictive model. Finally, the approach is\nevaluated on a simulated system coarsely inspired from the human retina.\n", "versions": [{"version": "v1", "created": "Wed, 3 Oct 2018 13:42:43 GMT"}], "update_date": "2018-10-05", "authors_parsed": [["Laflaqui\u00e8re", "Alban", ""]]}, {"id": "1810.01872", "submitter": "Alban Laflaqui\\`ere Dr", "authors": "Alban Laflaqui\\`ere, J.Kevin O'Regan, Sylvain Argentieri, Bruno Gas,\n  Alexander V. Terekhov", "title": "Learning agent's spatial configuration from sensorimotor invariants", "comments": "26 pages, 5 images, published in Robotics and Autonomous Systems", "journal-ref": "Robotics and Autonomous Systems, Volume 71, September 2015, Pages\n  49-59", "doi": "10.1016/j.robot.2015.01.003", "report-no": null, "categories": "cs.LG cs.RO stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The design of robotic systems is largely dictated by our purely human\nintuition about how we perceive the world. This intuition has been proven\nincorrect with regard to a number of critical issues, such as visual change\nblindness. In order to develop truly autonomous robots, we must step away from\nthis intuition and let robotic agents develop their own way of perceiving. The\nrobot should start from scratch and gradually develop perceptual notions, under\nno prior assumptions, exclusively by looking into its sensorimotor experience\nand identifying repetitive patterns and invariants. One of the most fundamental\nperceptual notions, space, cannot be an exception to this requirement. In this\npaper we look into the prerequisites for the emergence of simplified spatial\nnotions on the basis of a robot's sensorimotor flow. We show that the notion of\nspace as environment-independent cannot be deduced solely from exteroceptive\ninformation, which is highly variable and is mainly determined by the contents\nof the environment. The environment-independent definition of space can be\napproached by looking into the functions that link the motor commands to\nchanges in exteroceptive inputs. In a sufficiently rich environment, the\nkernels of these functions correspond uniquely to the spatial configuration of\nthe agent's exteroceptors. We simulate a redundant robotic arm with a retina\ninstalled at its end-point and show how this agent can learn the configuration\nspace of its retina. The resulting manifold has the topology of the Cartesian\nproduct of a plane and a circle, and corresponds to the planar position and\norientation of the retina.\n", "versions": [{"version": "v1", "created": "Wed, 3 Oct 2018 13:48:43 GMT"}], "update_date": "2018-10-05", "authors_parsed": [["Laflaqui\u00e8re", "Alban", ""], ["O'Regan", "J. Kevin", ""], ["Argentieri", "Sylvain", ""], ["Gas", "Bruno", ""], ["Terekhov", "Alexander V.", ""]]}, {"id": "1810.01873", "submitter": "Mustafa Haider", "authors": "Adnan Haider and P.C. Woodland", "title": "Combining Natural Gradient with Hessian Free Methods for Sequence\n  Training", "comments": "in Proc. INTERSPEECH 2018, September 2-6, 2018, Hyderabad, India", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper presents a new optimisation approach to train Deep Neural Networks\n(DNNs) with discriminative sequence criteria. At each iteration, the method\ncombines information from the Natural Gradient (NG) direction with local\ncurvature information of the error surface that enables better paths on the\nparameter manifold to be traversed. The method is derived using an alternative\nderivation of Taylor's theorem using the concepts of manifolds, tangent vectors\nand directional derivatives from the perspective of Information Geometry. The\nefficacy of the method is shown within a Hessian Free (HF) style optimisation\nframework to sequence train both standard fully-connected DNNs and Time Delay\nNeural Networks as speech recognition acoustic models. It is shown that for the\nsame number of updates the proposed approach achieves larger reductions in the\nword error rate (WER) than both NG and HF, and also leads to a lower WER than\nstandard stochastic gradient descent. The paper also addresses the issue of\nover-fitting due to mismatch between training criterion and Word Error Rate\n(WER) that primarily arises during sequence training of ReLU-DNN models.\n", "versions": [{"version": "v1", "created": "Wed, 3 Oct 2018 13:58:12 GMT"}], "update_date": "2018-10-05", "authors_parsed": [["Haider", "Adnan", ""], ["Woodland", "P. C.", ""]]}, {"id": "1810.01875", "submitter": "Christos Louizos", "authors": "Christos Louizos, Matthias Reisser, Tijmen Blankevoort, Efstratios\n  Gavves, Max Welling", "title": "Relaxed Quantization for Discretized Neural Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Neural network quantization has become an important research area due to its\ngreat impact on deployment of large models on resource constrained devices. In\norder to train networks that can be effectively discretized without loss of\nperformance, we introduce a differentiable quantization procedure.\nDifferentiability can be achieved by transforming continuous distributions over\nthe weights and activations of the network to categorical distributions over\nthe quantization grid. These are subsequently relaxed to continuous surrogates\nthat can allow for efficient gradient-based optimization. We further show that\nstochastic rounding can be seen as a special case of the proposed approach and\nthat under this formulation the quantization grid itself can also be optimized\nwith gradient descent. We experimentally validate the performance of our method\non MNIST, CIFAR 10 and Imagenet classification.\n", "versions": [{"version": "v1", "created": "Wed, 3 Oct 2018 14:17:24 GMT"}], "update_date": "2018-10-05", "authors_parsed": [["Louizos", "Christos", ""], ["Reisser", "Matthias", ""], ["Blankevoort", "Tijmen", ""], ["Gavves", "Efstratios", ""], ["Welling", "Max", ""]]}, {"id": "1810.01876", "submitter": "Mehdi Cherti", "authors": "Bal\\'azs K\\'egl, Mehdi Cherti, Ak{\\i}n Kazak\\c{c}{\\i}", "title": "Spurious samples in deep generative models: bug or feature?", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Traditional wisdom in generative modeling literature is that spurious samples\nthat a model can generate are errors and they should be avoided. Recent\nresearch, however, has shown interest in studying or even exploiting such\nsamples instead of eliminating them. In this paper, we ask the question whether\nsuch samples can be eliminated all together without sacrificing coverage of the\ngenerating distribution. For the class of models we consider, we experimentally\ndemonstrate that this is not possible without losing the ability to model some\nof the test samples. While our results need to be confirmed on a broader set of\nmodel families, these initial findings provide partial evidence that spurious\nsamples share structural properties with the learned dataset, which, in turn,\nsuggests they are not simply errors but a feature of deep generative nets.\n", "versions": [{"version": "v1", "created": "Wed, 3 Oct 2018 16:12:26 GMT"}], "update_date": "2018-10-05", "authors_parsed": [["K\u00e9gl", "Bal\u00e1zs", ""], ["Cherti", "Mehdi", ""], ["Kazak\u00e7\u0131", "Ak\u0131n", ""]]}, {"id": "1810.01877", "submitter": "Yixi Xu", "authors": "Yixi Xu, Xiao Wang", "title": "Understanding Weight Normalized Deep Neural Networks with Rectified\n  Linear Units", "comments": null, "journal-ref": "NeurIPS 2018", "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper presents a general framework for norm-based capacity control for\n$L_{p,q}$ weight normalized deep neural networks. We establish the upper bound\non the Rademacher complexities of this family. With an $L_{p,q}$ normalization\nwhere $q\\le p^*$, and $1/p+1/p^{*}=1$, we discuss properties of a\nwidth-independent capacity control, which only depends on depth by a square\nroot term. We further analyze the approximation properties of $L_{p,q}$ weight\nnormalized deep neural networks. In particular, for an $L_{1,\\infty}$ weight\nnormalized network, the approximation error can be controlled by the $L_1$ norm\nof the output layer, and the corresponding generalization error only depends on\nthe architecture by the square root of the depth.\n", "versions": [{"version": "v1", "created": "Wed, 3 Oct 2018 16:45:04 GMT"}, {"version": "v2", "created": "Mon, 15 Oct 2018 16:17:11 GMT"}, {"version": "v3", "created": "Wed, 28 Nov 2018 02:47:36 GMT"}], "update_date": "2018-11-29", "authors_parsed": [["Xu", "Yixi", ""], ["Wang", "Xiao", ""]]}, {"id": "1810.01878", "submitter": "Rabindra Lamsal", "authors": "Rabindra Lamsal, Shubham Katiyar", "title": "Determining Optimal Number of k-Clusters based on Predefined\n  Level-of-Similarity", "comments": "2 Figures, 3 Equations", "journal-ref": null, "doi": "10.1007/s42452-020-03582-5", "report-no": null, "categories": "cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  This paper proposes a centroid-based clustering algorithm which is capable of\nclustering data-points with n-features, without having to specify the number of\nclusters to be formed. The core logic behind the algorithm is a similarity\nmeasure, which collectively decides whether to assign an incoming data-point to\na pre-existing cluster, or create a new cluster and assign the data-point to\nit. The proposed clustering algorithm is application-specific and is applicable\nwhen the need is to perform clustering analysis of a stream of data-points,\nwhere the similarity measure between an incoming data-point and the cluster to\nwhich the data-point is to be associated with, is greater than the predefined\nLevel-of-Similarity.\n", "versions": [{"version": "v1", "created": "Wed, 3 Oct 2018 16:46:25 GMT"}, {"version": "v2", "created": "Sun, 21 Jul 2019 12:47:36 GMT"}], "update_date": "2020-10-08", "authors_parsed": [["Lamsal", "Rabindra", ""], ["Katiyar", "Shubham", ""]]}, {"id": "1810.01916", "submitter": "Aydogan Ozcan", "authors": "Deniz Mengu, Yi Luo, Yair Rivenson, Aydogan Ozcan", "title": "Analysis of Diffractive Optical Neural Networks and Their Integration\n  with Electronic Neural Networks", "comments": "22 pages, 5 Figures, 4 Tables, 1 Supplementary Figure, 2\n  Supplementary Tables", "journal-ref": "IEEE Journal of Selected Topics in Quantum Electronics (2019)", "doi": "10.1109/JSTQE.2019.2921376", "report-no": null, "categories": "cs.NE cs.LG physics.optics", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Optical machine learning offers advantages in terms of power efficiency,\nscalability and computation speed. Recently, an optical machine learning method\nbased on Diffractive Deep Neural Networks (D2NNs) has been introduced to\nexecute a function as the input light diffracts through passive layers,\ndesigned by deep learning using a computer. Here we introduce improvements to\nD2NNs by changing the training loss function and reducing the impact of\nvanishing gradients in the error back-propagation step. Using five phase-only\ndiffractive layers, we numerically achieved a classification accuracy of 97.18%\nand 89.13% for optical recognition of handwritten digits and fashion products,\nrespectively; using both phase and amplitude modulation (complex-valued) at\neach layer, our inference performance improved to 97.81% and 89.32%,\nrespectively. Furthermore, we report the integration of D2NNs with electronic\nneural networks to create hybrid-classifiers that significantly reduce the\nnumber of input pixels into an electronic network using an ultra-compact\nfront-end D2NN with a layer-to-layer distance of a few wavelengths, also\nreducing the complexity of the successive electronic network. Using a 5-layer\nphase-only D2NN jointly-optimized with a single fully-connected electronic\nlayer, we achieved a classification accuracy of 98.71% and 90.04% for the\nrecognition of handwritten digits and fashion products, respectively. Moreover,\nthe input to the electronic network was compressed by >7.8 times down to 10x10\npixels. Beyond creating low-power and high-frame rate machine learning\nplatforms, D2NN-based hybrid neural networks will find applications in smart\noptical imager and sensor design.\n", "versions": [{"version": "v1", "created": "Wed, 3 Oct 2018 18:59:42 GMT"}, {"version": "v2", "created": "Thu, 11 Oct 2018 00:14:13 GMT"}, {"version": "v3", "created": "Sun, 24 Feb 2019 23:24:16 GMT"}, {"version": "v4", "created": "Sat, 8 Jun 2019 01:43:00 GMT"}], "update_date": "2019-06-11", "authors_parsed": [["Mengu", "Deniz", ""], ["Luo", "Yi", ""], ["Rivenson", "Yair", ""], ["Ozcan", "Aydogan", ""]]}, {"id": "1810.01920", "submitter": "Chaosheng Dong", "authors": "Chaosheng Dong, Yiran Chen, Bo Zeng", "title": "Generalized Inverse Optimization through Online Learning", "comments": "14 pages, 10 figures, Accepted at NIPS 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG math.OC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Inverse optimization is a powerful paradigm for learning preferences and\nrestrictions that explain the behavior of a decision maker, based on a set of\nexternal signal and the corresponding decision pairs. However, most inverse\noptimization algorithms are designed specifically in batch setting, where all\nthe data is available in advance. As a consequence, there has been rare use of\nthese methods in an online setting suitable for real-time applications. In this\npaper, we propose a general framework for inverse optimization through online\nlearning. Specifically, we develop an online learning algorithm that uses an\nimplicit update rule which can handle noisy data. Moreover, under additional\nregularity assumptions in terms of the data and the model, we prove that our\nalgorithm converges at a rate of $\\mathcal{O}(1/\\sqrt{T})$ and is statistically\nconsistent. In our experiments, we show the online learning approach can learn\nthe parameters with great accuracy and is very robust to noises, and achieves a\ndramatic improvement in computational efficacy over the batch learning\napproach.\n", "versions": [{"version": "v1", "created": "Wed, 3 Oct 2018 19:11:52 GMT"}, {"version": "v2", "created": "Fri, 2 Nov 2018 17:55:28 GMT"}], "update_date": "2018-11-05", "authors_parsed": [["Dong", "Chaosheng", ""], ["Chen", "Yiran", ""], ["Zeng", "Bo", ""]]}, {"id": "1810.01925", "submitter": "Panayotis Mertikopoulos", "authors": "Mario Bravo and David S. Leslie and Panayotis Mertikopoulos", "title": "Bandit learning in concave $N$-person games", "comments": "24 pages, 1 figure", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.GT cs.LG math.OC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper examines the long-run behavior of learning with bandit feedback in\nnon-cooperative concave games. The bandit framework accounts for extremely\nlow-information environments where the agents may not even know they are\nplaying a game; as such, the agents' most sensible choice in this setting would\nbe to employ a no-regret learning algorithm. In general, this does not mean\nthat the players' behavior stabilizes in the long run: no-regret learning may\nlead to cycles, even with perfect gradient information. However, if a standard\nmonotonicity condition is satisfied, our analysis shows that no-regret learning\nbased on mirror descent with bandit feedback converges to Nash equilibrium with\nprobability $1$. We also derive an upper bound for the convergence rate of the\nprocess that nearly matches the best attainable rate for single-agent bandit\nstochastic optimization.\n", "versions": [{"version": "v1", "created": "Wed, 3 Oct 2018 19:34:08 GMT"}], "update_date": "2018-10-05", "authors_parsed": [["Bravo", "Mario", ""], ["Leslie", "David S.", ""], ["Mertikopoulos", "Panayotis", ""]]}, {"id": "1810.01937", "submitter": "Daniel Kang", "authors": "Animesh Koratana, Daniel Kang, Peter Bailis, Matei Zaharia", "title": "LIT: Block-wise Intermediate Representation Training for Model\n  Compression", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Knowledge distillation (KD) is a popular method for reducing the\ncomputational overhead of deep network inference, in which the output of a\nteacher model is used to train a smaller, faster student model. Hint training\n(i.e., FitNets) extends KD by regressing a student model's intermediate\nrepresentation to a teacher model's intermediate representation. In this work,\nwe introduce bLock-wise Intermediate representation Training (LIT), a novel\nmodel compression technique that extends the use of intermediate\nrepresentations in deep network compression, outperforming KD and hint\ntraining. LIT has two key ideas: 1) LIT trains a student of the same width (but\nshallower depth) as the teacher by directly comparing the intermediate\nrepresentations, and 2) LIT uses the intermediate representation from the\nprevious block in the teacher model as an input to the current student block\nduring training, avoiding unstable intermediate representations in the student\nnetwork. We show that LIT provides substantial reductions in network depth\nwithout loss in accuracy -- for example, LIT can compress a ResNeXt-110 to a\nResNeXt-20 (5.5x) on CIFAR10 and a VDCNN-29 to a VDCNN-9 (3.2x) on Amazon\nReviews without loss in accuracy, outperforming KD and hint training in network\nsize for a given accuracy. We also show that applying LIT to identical\nstudent/teacher architectures increases the accuracy of the student model above\nthe teacher model, outperforming the recently-proposed Born Again Networks\nprocedure on ResNet, ResNeXt, and VDCNN. Finally, we show that LIT can\neffectively compress GAN generators, which are not supported in the KD\nframework because GANs output pixels as opposed to probabilities.\n", "versions": [{"version": "v1", "created": "Tue, 2 Oct 2018 03:27:41 GMT"}], "update_date": "2018-10-05", "authors_parsed": [["Koratana", "Animesh", ""], ["Kang", "Daniel", ""], ["Bailis", "Peter", ""], ["Zaharia", "Matei", ""]]}, {"id": "1810.01940", "submitter": "Savinay Nagendra", "authors": "Savinay Nagendra, Nikhil Podila, Rashmi Ugarakhod, Koshy George", "title": "Comparison of Reinforcement Learning algorithms applied to the Cart Pole\n  problem", "comments": null, "journal-ref": "2017 International Conference on Advances in Computing,\n  Communications and Informatics (ICACCI)", "doi": "10.1109/ICACCI.2017.8125811", "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Designing optimal controllers continues to be challenging as systems are\nbecoming complex and are inherently nonlinear. The principal advantage of\nreinforcement learning (RL) is its ability to learn from the interaction with\nthe environment and provide optimal control strategy. In this paper, RL is\nexplored in the context of control of the benchmark cartpole dynamical system\nwith no prior knowledge of the dynamics. RL algorithms such as\ntemporal-difference, policy gradient actor-critic, and value function\napproximation are compared in this context with the standard LQR solution.\nFurther, we propose a novel approach to integrate RL and swing-up controllers.\n", "versions": [{"version": "v1", "created": "Wed, 3 Oct 2018 20:10:44 GMT"}], "update_date": "2018-10-05", "authors_parsed": [["Nagendra", "Savinay", ""], ["Podila", "Nikhil", ""], ["Ugarakhod", "Rashmi", ""], ["George", "Koshy", ""]]}, {"id": "1810.01963", "submitter": "Hongzi Mao", "authors": "Hongzi Mao, Malte Schwarzkopf, Shaileshh Bojja Venkatakrishnan, Zili\n  Meng, Mohammad Alizadeh", "title": "Learning Scheduling Algorithms for Data Processing Clusters", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Efficiently scheduling data processing jobs on distributed compute clusters\nrequires complex algorithms. Current systems, however, use simple generalized\nheuristics and ignore workload characteristics, since developing and tuning a\nscheduling policy for each workload is infeasible. In this paper, we show that\nmodern machine learning techniques can generate highly-efficient policies\nautomatically. Decima uses reinforcement learning (RL) and neural networks to\nlearn workload-specific scheduling algorithms without any human instruction\nbeyond a high-level objective such as minimizing average job completion time.\nOff-the-shelf RL techniques, however, cannot handle the complexity and scale of\nthe scheduling problem. To build Decima, we had to develop new representations\nfor jobs' dependency graphs, design scalable RL models, and invent RL training\nmethods for dealing with continuous stochastic job arrivals. Our prototype\nintegration with Spark on a 25-node cluster shows that Decima improves the\naverage job completion time over hand-tuned scheduling heuristics by at least\n21%, achieving up to 2x improvement during periods of high cluster load.\n", "versions": [{"version": "v1", "created": "Wed, 3 Oct 2018 20:43:31 GMT"}, {"version": "v2", "created": "Fri, 12 Oct 2018 20:19:13 GMT"}, {"version": "v3", "created": "Tue, 26 Feb 2019 18:47:37 GMT"}, {"version": "v4", "created": "Wed, 21 Aug 2019 21:53:52 GMT"}], "update_date": "2019-08-23", "authors_parsed": [["Mao", "Hongzi", ""], ["Schwarzkopf", "Malte", ""], ["Venkatakrishnan", "Shaileshh Bojja", ""], ["Meng", "Zili", ""], ["Alizadeh", "Mohammad", ""]]}, {"id": "1810.01965", "submitter": "Seyed Mostafa Mousavi", "authors": "S. Mostafa Mousavi, Weiqiang Zhu, Yixiao Sheng, Gregory C. Beroza", "title": "CRED: A Deep Residual Network of Convolutional and Recurrent Units for\n  Earthquake Signal Detection", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Earthquake signal detection is at the core of observational seismology. A\ngood detection algorithm should be sensitive to small and weak events with a\nvariety of waveform shapes, robust to background noise and non-earthquake\nsignals, and efficient for processing large data volumes. Here, we introduce\nthe Cnn-Rnn Earthquake Detector (CRED), a detector based on deep neural\nnetworks. The network uses a combination of convolutional layers and\nbi-directional long-short-term memory units in a residual structure. It learns\nthe time-frequency characteristics of the dominant phases in an earthquake\nsignal from three component data recorded on a single station. We train the\nnetwork using 500,000 seismograms (250k associated with tectonic earthquakes\nand 250k identified as noise) recorded in Northern California and tested it\nwith an F-score of 99.95. The robustness of the trained model with respect to\nthe noise level and non-earthquake signals is shown by applying it to a set of\nsemi-synthetic signals. The model is applied to one month of continuous data\nrecorded at Central Arkansas to demonstrate its efficiency, generalization, and\nsensitivity. Our model is able to detect more than 700 microearthquakes as\nsmall as -1.3 ML induced during hydraulic fracturing far away than the training\nregion. The performance of the model is compared with STA/LTA, template\nmatching, and FAST algorithms. Our results indicate an efficient and reliable\nperformance of CRED. This framework holds great promise in lowering the\ndetection threshold while minimizing false positive detection rates.\n", "versions": [{"version": "v1", "created": "Wed, 3 Oct 2018 20:45:15 GMT"}], "update_date": "2018-10-05", "authors_parsed": [["Mousavi", "S. Mostafa", ""], ["Zhu", "Weiqiang", ""], ["Sheng", "Yixiao", ""], ["Beroza", "Gregory C.", ""]]}, {"id": "1810.01973", "submitter": "Feng Shi", "authors": "Feng Shi, Haochen Li, Yuhe Gao, Benjamin Kuschner, Song-Chun Zhu", "title": "Sparse Winograd Convolutional neural networks on small-scale systolic\n  arrays", "comments": "submitted to FPGA 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The reconfigurability, energy-efficiency, and massive parallelism on FPGAs\nmake them one of the best choices for implementing efficient deep learning\naccelerators. However, state-of-art implementations seldom consider the balance\nbetween high throughput of computation power and the ability of the memory\nsubsystem to support it. In this paper, we implement an accelerator on FPGA by\ncombining the sparse Winograd convolution, clusters of small-scale systolic\narrays, and a tailored memory layout design. We also provide an analytical\nmodel analysis for the general Winograd convolution algorithm as a design\nreference. Experimental results on VGG16 show that it achieves very high\ncomputational resource utilization, 20x ~ 30x energy efficiency, and more than\n5x speedup compared with the dense implementation.\n", "versions": [{"version": "v1", "created": "Wed, 3 Oct 2018 21:01:51 GMT"}], "update_date": "2018-10-05", "authors_parsed": [["Shi", "Feng", ""], ["Li", "Haochen", ""], ["Gao", "Yuhe", ""], ["Kuschner", "Benjamin", ""], ["Zhu", "Song-Chun", ""]]}, {"id": "1810.01989", "submitter": "Taylor T Johnson", "authors": "Weiming Xiang and Patrick Musau and Ayana A. Wild and Diego Manzanas\n  Lopez and Nathaniel Hamilton and Xiaodong Yang and Joel Rosenfeld and Taylor\n  T. Johnson", "title": "Verification for Machine Learning, Autonomy, and Neural Networks Survey", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This survey presents an overview of verification techniques for autonomous\nsystems, with a focus on safety-critical autonomous cyber-physical systems\n(CPS) and subcomponents thereof. Autonomy in CPS is enabling by recent advances\nin artificial intelligence (AI) and machine learning (ML) through approaches\nsuch as deep neural networks (DNNs), embedded in so-called learning enabled\ncomponents (LECs) that accomplish tasks from classification to control.\nRecently, the formal methods and formal verification community has developed\nmethods to characterize behaviors in these LECs with eventual goals of formally\nverifying specifications for LECs, and this article presents a survey of many\nof these recent approaches.\n", "versions": [{"version": "v1", "created": "Wed, 3 Oct 2018 22:12:05 GMT"}], "update_date": "2018-10-05", "authors_parsed": [["Xiang", "Weiming", ""], ["Musau", "Patrick", ""], ["Wild", "Ayana A.", ""], ["Lopez", "Diego Manzanas", ""], ["Hamilton", "Nathaniel", ""], ["Yang", "Xiaodong", ""], ["Rosenfeld", "Joel", ""], ["Johnson", "Taylor T.", ""]]}, {"id": "1810.01992", "submitter": "Ankuj Arora Mr", "authors": "Ankuj Arora, Humbert Fiorino, Damien Pellier, Sylvie Pesty", "title": "Action Model Acquisition using LSTM", "comments": "13 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In the field of Automated Planning and Scheduling (APS), intelligent agents\nby virtue require an action model (blueprints of actions whose interleaved\nexecutions effectuates transitions of the system state) in order to plan and\nsolve real world problems. It is, however, becoming increasingly cumbersome to\ncodify this model, and is more efficient to learn it from observed plan\nexecution sequences (training data). While the underlying objective is to\nsubsequently plan from this learnt model, most approaches fall short as\nanything less than a flawless reconstruction of the underlying model renders it\nunusable in certain domains. This work presents a novel approach using long\nshort-term memory (LSTM) techniques for the acquisition of the underlying\naction model. We use the sequence labelling capabilities of LSTMs to isolate\nfrom an exhaustive model set a model identical to the one responsible for\nproducing the training data. This isolation capability renders our approach as\nan effective one.\n", "versions": [{"version": "v1", "created": "Wed, 3 Oct 2018 22:30:44 GMT"}], "update_date": "2018-10-05", "authors_parsed": [["Arora", "Ankuj", ""], ["Fiorino", "Humbert", ""], ["Pellier", "Damien", ""], ["Pesty", "Sylvie", ""]]}, {"id": "1810.02003", "submitter": "Govind Ramnarayan", "authors": "Ran Canetti, Aloni Cohen, Nishanth Dikkala, Govind Ramnarayan, Sarah\n  Scheffler, Adam Smith", "title": "From Soft Classifiers to Hard Decisions: How fair can we be?", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CY stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A popular methodology for building binary decision-making classifiers in the\npresence of imperfect information is to first construct a non-binary \"scoring\"\nclassifier that is calibrated over all protected groups, and then to\npost-process this score to obtain a binary decision. We study the feasibility\nof achieving various fairness properties by post-processing calibrated scores,\nand then show that deferring post-processors allow for more fairness conditions\nto hold on the final decision. Specifically, we show:\n  1. There does not exist a general way to post-process a calibrated classifier\nto equalize protected groups' positive or negative predictive value (PPV or\nNPV). For certain \"nice\" calibrated classifiers, either PPV or NPV can be\nequalized when the post-processor uses different thresholds across protected\ngroups, though there exist distributions of calibrated scores for which the two\nmeasures cannot be both equalized. When the post-processing consists of a\nsingle global threshold across all groups, natural fairness properties, such as\nequalizing PPV in a nontrivial way, do not hold even for \"nice\" classifiers.\n  2. When the post-processing is allowed to `defer' on some decisions (that is,\nto avoid making a decision by handing off some examples to a separate process),\nthen for the non-deferred decisions, the resulting classifier can be made to\nequalize PPV, NPV, false positive rate (FPR) and false negative rate (FNR)\nacross the protected groups. This suggests a way to partially evade the\nimpossibility results of Chouldechova and Kleinberg et al., which preclude\nequalizing all of these measures simultaneously. We also present different\ndeferring strategies and show how they affect the fairness properties of the\noverall system.\n  We evaluate our post-processing techniques using the COMPAS data set from\n2016.\n", "versions": [{"version": "v1", "created": "Wed, 3 Oct 2018 23:16:09 GMT"}, {"version": "v2", "created": "Mon, 21 Jan 2019 16:36:11 GMT"}], "update_date": "2019-01-23", "authors_parsed": [["Canetti", "Ran", ""], ["Cohen", "Aloni", ""], ["Dikkala", "Nishanth", ""], ["Ramnarayan", "Govind", ""], ["Scheffler", "Sarah", ""], ["Smith", "Adam", ""]]}, {"id": "1810.02019", "submitter": "Ofer Meshi", "authors": "Irwan Bello, Sayali Kulkarni, Sagar Jain, Craig Boutilier, Ed Chi,\n  Elad Eban, Xiyang Luo, Alan Mackey, Ofer Meshi", "title": "Seq2Slate: Re-ranking and Slate Optimization with RNNs", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Ranking is a central task in machine learning and information retrieval. In\nthis task, it is especially important to present the user with a slate of items\nthat is appealing as a whole. This in turn requires taking into account\ninteractions between items, since intuitively, placing an item on the slate\naffects the decision of which other items should be placed alongside it. In\nthis work, we propose a sequence-to-sequence model for ranking called\nseq2slate. At each step, the model predicts the next `best' item to place on\nthe slate given the items already selected. The sequential nature of the model\nallows complex dependencies between the items to be captured directly in a\nflexible and scalable way. We show how to learn the model end-to-end from weak\nsupervision in the form of easily obtained click-through data. We further\ndemonstrate the usefulness of our approach in experiments on standard ranking\nbenchmarks as well as in a real-world recommendation system.\n", "versions": [{"version": "v1", "created": "Thu, 4 Oct 2018 01:35:14 GMT"}, {"version": "v2", "created": "Tue, 29 Jan 2019 17:38:40 GMT"}, {"version": "v3", "created": "Tue, 19 Mar 2019 18:36:25 GMT"}], "update_date": "2019-03-21", "authors_parsed": [["Bello", "Irwan", ""], ["Kulkarni", "Sayali", ""], ["Jain", "Sagar", ""], ["Boutilier", "Craig", ""], ["Chi", "Ed", ""], ["Eban", "Elad", ""], ["Luo", "Xiyang", ""], ["Mackey", "Alan", ""], ["Meshi", "Ofer", ""]]}, {"id": "1810.02020", "submitter": "Ghouthi Boukli Hacene Gbh", "authors": "Ghouthi Boukli Hacene, Vincent Gripon, Nicolas Farrugia, Matthieu\n  Arzel, Michel Jezequel", "title": "Transfer Incremental Learning using Data Augmentation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep learning-based methods have reached state of the art performances,\nrelying on large quantity of available data and computational power. Such\nmethods still remain highly inappropriate when facing a major open machine\nlearning problem, which consists of learning incrementally new classes and\nexamples over time. Combining the outstanding performances of Deep Neural\nNetworks (DNNs) with the flexibility of incremental learning techniques is a\npromising venue of research. In this contribution, we introduce Transfer\nIncremental Learning using Data Augmentation (TILDA). TILDA is based on\npre-trained DNNs as feature extractor, robust selection of feature vectors in\nsubspaces using a nearest-class-mean based technique, majority votes and data\naugmentation at both the training and the prediction stages. Experiments on\nchallenging vision datasets demonstrate the ability of the proposed method for\nlow complexity incremental learning, while achieving significantly better\naccuracy than existing incremental counterparts.\n", "versions": [{"version": "v1", "created": "Thu, 4 Oct 2018 01:38:02 GMT"}], "update_date": "2018-10-05", "authors_parsed": [["Hacene", "Ghouthi Boukli", ""], ["Gripon", "Vincent", ""], ["Farrugia", "Nicolas", ""], ["Arzel", "Matthieu", ""], ["Jezequel", "Michel", ""]]}, {"id": "1810.02022", "submitter": "Sarthak Chatterjee", "authors": "Orlando Romero, Sarthak Chatterjee, S\\'ergio Pequito", "title": "Convergence of the Expectation-Maximization Algorithm Through\n  Discrete-Time Lyapunov Stability Theory", "comments": "Preprint submitted to ACC 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.OC cs.LG cs.SY math.DS stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we propose a dynamical systems perspective of the\nExpectation-Maximization (EM) algorithm. More precisely, we can analyze the EM\nalgorithm as a nonlinear state-space dynamical system. The EM algorithm is\nwidely adopted for data clustering and density estimation in statistics,\ncontrol systems, and machine learning. This algorithm belongs to a large class\nof iterative algorithms known as proximal point methods. In particular, we\nre-interpret limit points of the EM algorithm and other local maximizers of the\nlikelihood function it seeks to optimize as equilibria in its dynamical system\nrepresentation. Furthermore, we propose to assess its convergence as asymptotic\nstability in the sense of Lyapunov. As a consequence, we proceed by leveraging\nrecent results regarding discrete-time Lyapunov stability theory in order to\nestablish asymptotic stability (and thus, convergence) in the dynamical system\nrepresentation of the EM algorithm.\n", "versions": [{"version": "v1", "created": "Thu, 4 Oct 2018 01:53:11 GMT"}], "update_date": "2018-10-05", "authors_parsed": [["Romero", "Orlando", ""], ["Chatterjee", "Sarthak", ""], ["Pequito", "S\u00e9rgio", ""]]}, {"id": "1810.02023", "submitter": "Ryan Curtin", "authors": "Ryan R. Curtin, Andrew B. Gardner, Slawomir Grzonkowski, Alexey\n  Kleymenov, Alejandro Mosquera", "title": "Detecting DGA domains with recurrent neural networks and side\n  information", "comments": "Accepted to ARES 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Modern malware typically makes use of a domain generation algorithm (DGA) to\navoid command and control domains or IPs being seized or sinkholed. This means\nthat an infected system may attempt to access many domains in an attempt to\ncontact the command and control server. Therefore, the automatic detection of\nDGA domains is an important task, both for the sake of blocking malicious\ndomains and identifying compromised hosts. However, many DGAs use English\nwordlists to generate plausibly clean-looking domain names; this makes\nautomatic detection difficult. In this work, we devise a notion of difficulty\nfor DGA families called the smashword score; this measures how much a DGA\nfamily looks like English words. We find that this measure accurately reflects\nhow much a DGA family's domains look like they are made from natural English\nwords. We then describe our new modeling approach, which is a combination of a\nnovel recurrent neural network architecture with domain registration side\ninformation. Our experiments show the model is capable of effectively\nidentifying domains generated by difficult DGA families. Our experiments also\nshow that our model outperforms existing approaches, and is able to reliably\ndetect difficult DGA families such as matsnu, suppobox, rovnix, and others. The\nmodel's performance compared to the state of the art is best for DGA families\nthat resemble English words. We believe that this model could either be used in\na standalone DGA domain detector---such as an endpoint security\napplication---or alternately the model could be used as a part of a larger\nmalware detection system.\n", "versions": [{"version": "v1", "created": "Thu, 4 Oct 2018 02:02:38 GMT"}, {"version": "v2", "created": "Fri, 21 Jun 2019 15:02:46 GMT"}], "update_date": "2019-06-24", "authors_parsed": [["Curtin", "Ryan R.", ""], ["Gardner", "Andrew B.", ""], ["Grzonkowski", "Slawomir", ""], ["Kleymenov", "Alexey", ""], ["Mosquera", "Alejandro", ""]]}, {"id": "1810.02027", "submitter": "Chieh-Fang Teng", "authors": "Chieh-Fang Teng, Ching-Chun Liao, Chun-Hsiang Chen, An-Yeu Wu", "title": "Polar Feature Based Deep Architectures for Automatic Modulation\n  Classification Considering Channel Fading", "comments": "5 pages, accepted by the 2018 Sixth IEEE Global Conference on Signal\n  and Information Processing", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.SP cs.IT cs.LG math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  To develop intelligent receivers, automatic modulation classification (AMC)\nplays an important role for better spectrum utilization. The emerging deep\nlearning (DL) technique has received much attention in AMC due to its superior\nperformance in classifying data with deep structure. In this work, a novel\npolar-based deep learning architecture with channel compensation network (CCN)\nis proposed. Our test results show that learning features from polar domain\n(r-theta) can improve recognition accuracy by 5% and reduce training overhead\nby 48%. Besides, the proposed CCN is also robust to channel fading, such as\namplitude and phase offsets, and can improve the recognition accuracy by 14%\nunder practical channel environments.\n", "versions": [{"version": "v1", "created": "Thu, 4 Oct 2018 02:19:27 GMT"}, {"version": "v2", "created": "Sun, 7 Oct 2018 08:21:09 GMT"}], "update_date": "2018-10-09", "authors_parsed": [["Teng", "Chieh-Fang", ""], ["Liao", "Ching-Chun", ""], ["Chen", "Chun-Hsiang", ""], ["Wu", "An-Yeu", ""]]}, {"id": "1810.02030", "submitter": "Chao Gao", "authors": "Chao Gao, Jiyi Liu, Yuan Yao, Weizhi Zhu", "title": "Robust Estimation and Generative Adversarial Nets", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG math.ST stat.CO stat.ME stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Robust estimation under Huber's $\\epsilon$-contamination model has become an\nimportant topic in statistics and theoretical computer science. Statistically\noptimal procedures such as Tukey's median and other estimators based on depth\nfunctions are impractical because of their computational intractability. In\nthis paper, we establish an intriguing connection between $f$-GANs and various\ndepth functions through the lens of $f$-Learning. Similar to the derivation of\n$f$-GANs, we show that these depth functions that lead to statistically optimal\nrobust estimators can all be viewed as variational lower bounds of the total\nvariation distance in the framework of $f$-Learning. This connection opens the\ndoor of computing robust estimators using tools developed for training GANs. In\nparticular, we show in both theory and experiments that some appropriate\nstructures of discriminator networks with hidden layers in GANs lead to\nstatistically optimal robust location estimators for both Gaussian distribution\nand general elliptical distributions where first moment may not exist.\n", "versions": [{"version": "v1", "created": "Thu, 4 Oct 2018 02:37:16 GMT"}, {"version": "v2", "created": "Sun, 7 Oct 2018 01:47:46 GMT"}, {"version": "v3", "created": "Mon, 25 Feb 2019 20:09:43 GMT"}], "update_date": "2019-02-27", "authors_parsed": [["Gao", "Chao", ""], ["Liu", "Jiyi", ""], ["Yao", "Yuan", ""], ["Zhu", "Weizhi", ""]]}, {"id": "1810.02032", "submitter": "Ziwei Ji", "authors": "Ziwei Ji, Matus Telgarsky", "title": "Gradient descent aligns the layers of deep linear networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG math.OC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper establishes risk convergence and asymptotic weight matrix\nalignment --- a form of implicit regularization --- of gradient flow and\ngradient descent when applied to deep linear networks on linearly separable\ndata. In more detail, for gradient flow applied to strictly decreasing loss\nfunctions (with similar results for gradient descent with particular decreasing\nstep sizes): (i) the risk converges to 0; (ii) the normalized i-th weight\nmatrix asymptotically equals its rank-1 approximation $u_iv_i^{\\top}$; (iii)\nthese rank-1 matrices are aligned across layers, meaning\n$|v_{i+1}^{\\top}u_i|\\to1$. In the case of the logistic loss (binary cross\nentropy), more can be said: the linear function induced by the network --- the\nproduct of its weight matrices --- converges to the same direction as the\nmaximum margin solution. This last property was identified in prior work, but\nonly under assumptions on gradient descent which here are implied by the\nalignment phenomenon.\n", "versions": [{"version": "v1", "created": "Thu, 4 Oct 2018 02:48:41 GMT"}, {"version": "v2", "created": "Sun, 24 Feb 2019 10:28:05 GMT"}], "update_date": "2019-02-26", "authors_parsed": [["Ji", "Ziwei", ""], ["Telgarsky", "Matus", ""]]}, {"id": "1810.02054", "submitter": "Simon Du", "authors": "Simon S. Du, Xiyu Zhai, Barnabas Poczos, Aarti Singh", "title": "Gradient Descent Provably Optimizes Over-parameterized Neural Networks", "comments": "ICLR 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG math.OC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  One of the mysteries in the success of neural networks is randomly\ninitialized first order methods like gradient descent can achieve zero training\nloss even though the objective function is non-convex and non-smooth. This\npaper demystifies this surprising phenomenon for two-layer fully connected ReLU\nactivated neural networks. For an $m$ hidden node shallow neural network with\nReLU activation and $n$ training data, we show as long as $m$ is large enough\nand no two inputs are parallel, randomly initialized gradient descent converges\nto a globally optimal solution at a linear convergence rate for the quadratic\nloss function.\n  Our analysis relies on the following observation: over-parameterization and\nrandom initialization jointly restrict every weight vector to be close to its\ninitialization for all iterations, which allows us to exploit a strong\nconvexity-like property to show that gradient descent converges at a global\nlinear rate to the global optimum. We believe these insights are also useful in\nanalyzing deep models and other first order methods.\n", "versions": [{"version": "v1", "created": "Thu, 4 Oct 2018 04:47:47 GMT"}, {"version": "v2", "created": "Tue, 5 Feb 2019 01:59:59 GMT"}], "update_date": "2019-02-06", "authors_parsed": [["Du", "Simon S.", ""], ["Zhai", "Xiyu", ""], ["Poczos", "Barnabas", ""], ["Singh", "Aarti", ""]]}, {"id": "1810.02060", "submitter": "Qihang Lin", "authors": "Hassan Rafique, Mingrui Liu, Qihang Lin, Tianbao Yang", "title": "Weakly-Convex Concave Min-Max Optimization: Provable Algorithms and\n  Applications in Machine Learning", "comments": "Published in Optimization Methods and Software:\n  https://www.tandfonline.com/doi/abs/10.1080/10556788.2021.1895152", "journal-ref": "Optimization Methods and Software (2021)", "doi": null, "report-no": null, "categories": "math.OC cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Min-max problems have broad applications in machine learning, including\nlearning with non-decomposable loss and learning with robustness to data\ndistribution. Convex-concave min-max problem is an active topic of research\nwith efficient algorithms and sound theoretical foundations developed. However,\nit remains a challenge to design provably efficient algorithms for non-convex\nmin-max problems with or without smoothness. In this paper, we study a family\nof non-convex min-max problems, whose objective function is weakly convex in\nthe variables of minimization and is concave in the variables of maximization.\nWe propose a proximally guided stochastic subgradient method and a proximally\nguided stochastic variance-reduced method for the non-smooth and smooth\ninstances, respectively, in this family of problems. We analyze the time\ncomplexities of the proposed methods for finding a nearly stationary point of\nthe outer minimization problem corresponding to the min-max problem.\n", "versions": [{"version": "v1", "created": "Thu, 4 Oct 2018 05:07:21 GMT"}, {"version": "v2", "created": "Tue, 4 Dec 2018 09:40:12 GMT"}, {"version": "v3", "created": "Fri, 1 Feb 2019 03:29:42 GMT"}, {"version": "v4", "created": "Tue, 11 May 2021 03:41:28 GMT"}], "update_date": "2021-05-12", "authors_parsed": [["Rafique", "Hassan", ""], ["Liu", "Mingrui", ""], ["Lin", "Qihang", ""], ["Yang", "Tianbao", ""]]}, {"id": "1810.02068", "submitter": "Cheng Fu", "authors": "Cheng Fu, Shilin Zhu, Hao Su, Ching-En Lee, Jishen Zhao", "title": "Towards Fast and Energy-Efficient Binarized Neural Network Inference on\n  FPGA", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.AR cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Binarized Neural Network (BNN) removes bitwidth redundancy in classical CNN\nby using a single bit (-1/+1) for network parameters and intermediate\nrepresentations, which has greatly reduced the off-chip data transfer and\nstorage overhead. However, a large amount of computation redundancy still\nexists in BNN inference. By analyzing local properties of images and the\nlearned BNN kernel weights, we observe an average of $\\sim$78% input similarity\nand $\\sim$59% weight similarity among weight kernels, measured by our proposed\nmetric in common network architectures. Thus there does exist redundancy that\ncan be exploited to further reduce the amount of on-chip computations.\n  Motivated by the observation, in this paper, we proposed two types of fast\nand energy-efficient architectures for BNN inference. We also provide analysis\nand insights to pick the better strategy of these two for different datasets\nand network models. By reusing the results from previous computation, much\ncycles for data buffer access and computations can be skipped. By experiments,\nwe demonstrate that 80% of the computation and 40% of the buffer access can be\nskipped by exploiting BNN similarity. Thus, our design can achieve 17%\nreduction in total power consumption, 54% reduction in on-chip power\nconsumption and 2.4$\\times$ maximum speedup, compared to the baseline without\napplying our reuse technique. Our design also shows 1.9$\\times$ more\narea-efficiency compared to state-of-the-art BNN inference design. We believe\nour deployment of BNN on FPGA leads to a promising future of running deep\nlearning models on mobile devices.\n", "versions": [{"version": "v1", "created": "Thu, 4 Oct 2018 06:29:59 GMT"}], "update_date": "2018-10-05", "authors_parsed": [["Fu", "Cheng", ""], ["Zhu", "Shilin", ""], ["Su", "Hao", ""], ["Lee", "Ching-En", ""], ["Zhao", "Jishen", ""]]}, {"id": "1810.02069", "submitter": "Taeyoung Kong", "authors": "Dae Hyun Kim, Taeyoung Kong, Seungbin Jeong", "title": "Finding Solutions to Generative Adversarial Privacy", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present heuristics for solving the maximin problem induced by the\ngenerative adversarial privacy setting for linear and convolutional neural\nnetwork (CNN) adversaries. In the linear adversary setting, we present a greedy\nalgorithm for approximating the optimal solution for the privatizer, which\nperforms better as the number of instances increases. We also provide an\nanalysis of the algorithm to show that it not only removes the features most\ncorrelated with the private label first, but also preserves the prediction\naccuracy of public labels that are sufficiently independent of the features\nthat are relevant to the private label. In the CNN adversary setting, we\npresent a method of hiding selected information from the adversary while\npreserving the others through alternately optimizing the goals of the\nprivatizer and the adversary using neural network backpropagation. We\nexperimentally show that our method succeeds on a fixed adversary.\n", "versions": [{"version": "v1", "created": "Thu, 4 Oct 2018 06:36:09 GMT"}], "update_date": "2018-10-05", "authors_parsed": [["Kim", "Dae Hyun", ""], ["Kong", "Taeyoung", ""], ["Jeong", "Seungbin", ""]]}, {"id": "1810.02076", "submitter": "Changhao Chen", "authors": "Changhao Chen, Yishu Miao, Chris Xiaoxuan Lu, Phil Blunsom, Andrew\n  Markham, Niki Trigoni", "title": "Transferring Physical Motion Between Domains for Neural Inertial\n  Tracking", "comments": "NIPS 2018 workshop on Modeling the Physical World: Perception,\n  Learning, and Control. A complete version will be released soon", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV cs.RO stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Inertial information processing plays a pivotal role in ego-motion awareness\nfor mobile agents, as inertial measurements are entirely egocentric and not\nenvironment dependent. However, they are affected greatly by changes in sensor\nplacement/orientation or motion dynamics, and it is infeasible to collect\nlabelled data from every domain. To overcome the challenges of domain\nadaptation on long sensory sequences, we propose a novel framework that\nextracts domain-invariant features of raw sequences from arbitrary domains, and\ntransforms to new domains without any paired data. Through the experiments, we\ndemonstrate that it is able to efficiently and effectively convert the raw\nsequence from a new unlabelled target domain into an accurate inertial\ntrajectory, benefiting from the physical motion knowledge transferred from the\nlabelled source domain. We also conduct real-world experiments to show our\nframework can reconstruct physically meaningful trajectories from raw IMU\nmeasurements obtained with a standard mobile phone in various attachments.\n", "versions": [{"version": "v1", "created": "Thu, 4 Oct 2018 07:12:47 GMT"}], "update_date": "2018-10-05", "authors_parsed": [["Chen", "Changhao", ""], ["Miao", "Yishu", ""], ["Lu", "Chris Xiaoxuan", ""], ["Blunsom", "Phil", ""], ["Markham", "Andrew", ""], ["Trigoni", "Niki", ""]]}, {"id": "1810.02080", "submitter": "Shonosuke Harada", "authors": "Shonosuke Harada, Hirotaka Akita, Masashi Tsubaki, Yukino Baba,\n  Ichigaku Takigawa, Yoshihiro Yamanishi, Hisashi Kashima", "title": "Dual Convolutional Neural Network for Graph of Graphs Link Prediction", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Graphs are general and powerful data representations which can model complex\nreal-world phenomena, ranging from chemical compounds to social networks;\nhowever, effective feature extraction from graphs is not a trivial task, and\nmuch work has been done in the field of machine learning and data mining. The\nrecent advances in graph neural networks have made automatic and flexible\nfeature extraction from graphs possible and have improved the predictive\nperformance significantly. In this paper, we go further with this line of\nresearch and address a more general problem of learning with a graph of graphs\n(GoG) consisting of an external graph and internal graphs, where each node in\nthe external graph has an internal graph structure. We propose a dual\nconvolutional neural network that extracts node representations by combining\nthe external and internal graph structures in an end-to-end manner. Experiments\non link prediction tasks using several chemical network datasets demonstrate\nthe effectiveness of the proposed method.\n", "versions": [{"version": "v1", "created": "Thu, 4 Oct 2018 07:39:31 GMT"}], "update_date": "2018-10-05", "authors_parsed": [["Harada", "Shonosuke", ""], ["Akita", "Hirotaka", ""], ["Tsubaki", "Masashi", ""], ["Baba", "Yukino", ""], ["Takigawa", "Ichigaku", ""], ["Yamanishi", "Yoshihiro", ""], ["Kashima", "Hisashi", ""]]}, {"id": "1810.02112", "submitter": "Edouard Fouch\\'e", "authors": "Edouard Fouch\\'e and Klemens B\\\"ohm", "title": "Monte Carlo Dependency Estimation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.DS stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Estimating the dependency of variables is a fundamental task in data\nanalysis. Identifying the relevant attributes in databases leads to better data\nunderstanding and also improves the performance of learning algorithms, both in\nterms of runtime and quality. In data streams, dependency monitoring provides\nkey insights into the underlying process, but is challenging. In this paper, we\npropose Monte Carlo Dependency Estimation (MCDE), a theoretical framework to\nestimate multivariate dependency in static and dynamic data. MCDE quantifies\ndependency as the average discrepancy between marginal and conditional\ndistributions via Monte Carlo simulations. Based on this framework, we present\nMann-Whitney P (MWP), a novel dependency estimator. We show that MWP satisfies\na number of desirable properties and can accommodate any kind of numerical\ndata. We demonstrate the superiority of our estimator by comparing it to the\nstate-of-the-art multivariate dependency measures.\n", "versions": [{"version": "v1", "created": "Thu, 4 Oct 2018 09:16:46 GMT"}], "update_date": "2018-10-05", "authors_parsed": [["Fouch\u00e9", "Edouard", ""], ["B\u00f6hm", "Klemens", ""]]}, {"id": "1810.02113", "submitter": "Maayan Frid-Adar", "authors": "Maayan Frid-Adar, Avi Ben-Cohen, Rula Amer, Hayit Greenspan", "title": "Improving the Segmentation of Anatomical Structures in Chest Radiographs\n  using U-Net with an ImageNet Pre-trained Encoder", "comments": "Presented at the First International Workshop on Thoracic Image\n  Analysis (TIA), MICCAI 2018", "journal-ref": null, "doi": "10.1007/978-3-030-00946-5_17", "report-no": null, "categories": "cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Accurate segmentation of anatomical structures in chest radiographs is\nessential for many computer-aided diagnosis tasks. In this paper we investigate\nthe latest fully-convolutional architectures for the task of multi-class\nsegmentation of the lungs field, heart and clavicles in a chest radiograph. In\naddition, we explore the influence of using different loss functions in the\ntraining process of a neural network for semantic segmentation. We evaluate all\nmodels on a common benchmark of 247 X-ray images from the JSRT database and\nground-truth segmentation masks from the SCR dataset. Our best performing\narchitecture, is a modified U-Net that benefits from pre-trained encoder\nweights. This model outperformed the current state-of-the-art methods tested on\nthe same benchmark, with Jaccard overlap scores of 96.1% for lung fields, 90.6%\nfor heart and 85.5% for clavicles.\n", "versions": [{"version": "v1", "created": "Thu, 4 Oct 2018 09:18:42 GMT"}], "update_date": "2018-10-05", "authors_parsed": [["Frid-Adar", "Maayan", ""], ["Ben-Cohen", "Avi", ""], ["Amer", "Rula", ""], ["Greenspan", "Hayit", ""]]}, {"id": "1810.02118", "submitter": "Dirk Surmann", "authors": "Dirk Surmann, Uwe Ligges, Claus Weihs", "title": "Infill Criterion for Multimodal Model-Based Optimisation", "comments": "14 pages, 4 figures, 3 tables, extensive appendix", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Physical systems are modelled and investigated within simulation software in\nan increasing range of applications. In reality an investigation of the system\nis often performed by empirical test scenarios which are related to typical\nsituations. Our aim is to derive a method which generates diverse test\nscenarios each representing a challenging situation for the corresponding\nphysical system.\n  From a mathematical point of view challenging test scenarios correspond to\nlocal optima. Hence, we focus to identify all local optima within mathematical\nfunctions. Due to the fact that simulation runs are usually expensive we use\nthe model-based optimisation approach with its well-known representative\nefficient global optimisation. We derive an infill criterion which focuses on\nthe identification of local optima. The criterion is checked via fifteen\ndifferent artificial functions in a computer experiment. Our new infill\ncriterion performs better in identifying local optima compared to the expected\nimprovement infill criterion and Latin Hypercube Samples.\n", "versions": [{"version": "v1", "created": "Thu, 4 Oct 2018 09:37:53 GMT"}], "update_date": "2018-10-05", "authors_parsed": [["Surmann", "Dirk", ""], ["Ligges", "Uwe", ""], ["Weihs", "Claus", ""]]}, {"id": "1810.02125", "submitter": "Adriano Koshiyama", "authors": "Adriano Soares Koshiyama, Nick Firoozye and Philip Treleaven", "title": "A Machine Learning-based Recommendation System for Swaptions Strategies", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "q-fin.PM cs.LG q-fin.GN stat.AP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Derivative traders are usually required to scan through hundreds, even\nthousands of possible trades on a daily basis. Up to now, not a single solution\nis available to aid in their job. Hence, this work aims to develop a trading\nrecommendation system, and apply this system to the so-called Mid-Curve\nCalendar Spread (MCCS), an exotic swaption-based derivatives package. In\nsummary, our trading recommendation system follows this pipeline: (i) on a\ncertain trade date, we compute metrics and sensitivities related to an MCCS;\n(ii) these metrics are feed in a model that can predict its expected return for\na given holding period; and after repeating (i) and (ii) for all trades we\n(iii) rank the trades using some dominance criteria. To suggest that such\napproach is feasible, we used a list of 35 different types of MCCS; a total of\n11 predictive models; and 4 benchmark models. Our results suggest that in\ngeneral linear regression with lasso regularisation compared favourably to\nother approaches from a predictive and interpretability perspective.\n", "versions": [{"version": "v1", "created": "Thu, 4 Oct 2018 09:55:40 GMT"}], "update_date": "2018-10-05", "authors_parsed": [["Koshiyama", "Adriano Soares", ""], ["Firoozye", "Nick", ""], ["Treleaven", "Philip", ""]]}, {"id": "1810.02176", "submitter": "James Grant", "authors": "James A. Grant, David S. Leslie, Kevin Glazebrook, Roberto Szechtman\n  and Adam N. Letchford", "title": "Adaptive Policies for Perimeter Surveillance Problems", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Maximising the detection of intrusions is a fundamental and often critical\naim of perimeter surveillance. Commonly, this requires a decision-maker to\noptimally allocate multiple searchers to segments of the perimeter. We consider\na scenario where the decision-maker may sequentially update the searchers'\nallocation, learning from the observed data to improve decisions over time. In\nthis work we propose a formal model and solution methods for this sequential\nperimeter surveillance problem. Our model is a combinatorial multi-armed bandit\n(CMAB) with Poisson rewards and a novel filtered feedback mechanism - arising\nfrom the failure to detect certain intrusions. Our solution method is an upper\nconfidence bound approach and we derive upper and lower bounds on its expected\nperformance. We prove that the gap between these bounds is of constant order,\nand demonstrate empirically that our approach is more reliable in simulated\nproblems than competing algorithms.\n", "versions": [{"version": "v1", "created": "Thu, 4 Oct 2018 12:44:34 GMT"}, {"version": "v2", "created": "Mon, 11 Nov 2019 15:44:19 GMT"}], "update_date": "2019-11-12", "authors_parsed": [["Grant", "James A.", ""], ["Leslie", "David S.", ""], ["Glazebrook", "Kevin", ""], ["Szechtman", "Roberto", ""], ["Letchford", "Adam N.", ""]]}, {"id": "1810.02180", "submitter": "Aryeh Kontorovich", "authors": "Idan Attias, Aryeh Kontorovich, Yishay Mansour", "title": "Improved Generalization Bounds for Robust Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider a model of robust learning in an adversarial environment. The\nlearner gets uncorrupted training data with access to possible corruptions that\nmay be effected by the adversary during testing. The learner's goal is to build\na robust classifier, which will be tested on future adversarial examples. The\nadversary is limited to $k$ possible corruptions for each input. We model the\nlearner-adversary interaction as a zero-sum game. This model is closely related\nto the adversarial examples model of Schmidt et al. (2018); Madry et al.\n(2017). Our main results consist of generalization bounds for the binary and\nmulticlass classification, as well as the real-valued case (regression). For\nthe binary classification setting, we both tighten the generalization bound of\nFeige, Mansour, and Schapire (2015), and are also able to handle infinite\nhypothesis classes. The sample complexity is improved from\n$O(\\frac{1}{\\epsilon^4}\\log(\\frac{|\\mathcal{H}|}{\\delta}))$ to\n$O\\big(\\frac{1}{\\epsilon^2}(\\sqrt{k\n\\mathrm{VC}(\\mathcal{H})}\\log^{\\frac{3}{2}+\\alpha}(k\\mathrm{VC}(\\mathcal{H}))+\\log(\\frac{1}{\\delta})\\big)$\nfor any $\\alpha > 0$. Additionally, we extend the algorithm and generalization\nbound from the binary to the multiclass and real-valued cases. Along the way,\nwe obtain results on fat-shattering dimension and Rademacher complexity of\n$k$-fold maxima over function classes; these may be of independent interest.\n  For binary classification, the algorithm of Feige et al. (2015) uses a regret\nminimization algorithm and an ERM oracle as a black box; we adapt it for the\nmulticlass and regression settings. The algorithm provides us with near-optimal\npolicies for the players on a given training sample.\n", "versions": [{"version": "v1", "created": "Thu, 4 Oct 2018 12:53:41 GMT"}, {"version": "v2", "created": "Sat, 2 Mar 2019 12:29:30 GMT"}, {"version": "v3", "created": "Sun, 29 Nov 2020 12:08:06 GMT"}, {"version": "v4", "created": "Mon, 22 Feb 2021 22:28:57 GMT"}], "update_date": "2021-02-24", "authors_parsed": [["Attias", "Idan", ""], ["Kontorovich", "Aryeh", ""], ["Mansour", "Yishay", ""]]}, {"id": "1810.02215", "submitter": "Jingyu He", "authors": "Jingyu He, Saar Yalov, P. Richard Hahn", "title": "XBART: Accelerated Bayesian Additive Regression Trees", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Bayesian additive regression trees (BART) (Chipman et. al., 2010) is a\npowerful predictive model that often outperforms alternative models at\nout-of-sample prediction. BART is especially well-suited to settings with\nunstructured predictor variables and substantial sources of unmeasured\nvariation as is typical in the social, behavioral and health sciences. This\npaper develops a modified version of BART that is amenable to fast posterior\nestimation. We present a stochastic hill climbing algorithm that matches the\nremarkable predictive accuracy of previous BART implementations, but is many\ntimes faster and less memory intensive. Simulation studies show that the new\nmethod is comparable in computation time and more accurate at function\nestimation than both random forests and gradient boosting.\n", "versions": [{"version": "v1", "created": "Thu, 4 Oct 2018 13:40:21 GMT"}, {"version": "v2", "created": "Mon, 25 Feb 2019 16:00:30 GMT"}, {"version": "v3", "created": "Thu, 14 Mar 2019 04:35:25 GMT"}], "update_date": "2019-03-15", "authors_parsed": [["He", "Jingyu", ""], ["Yalov", "Saar", ""], ["Hahn", "P. Richard", ""]]}, {"id": "1810.02225", "submitter": "Fan Zhang", "authors": "Fan Zhang, Miao Hu", "title": "Memristor-based Deep Convolution Neural Network: A Case Study", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.ET cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  In this paper, we firstly introduce a method to efficiently implement\nlarge-scale high-dimensional convolution with realistic memristor-based circuit\ncomponents. An experiment verified simulator is adapted for accurate prediction\nof analog crossbar behavior. An improved conversion algorithm is developed to\nconvert convolution kernels to memristor-based circuits, which minimizes the\nerror with consideration of the data and kernel patterns in CNNs. With circuit\nsimulation for all convolution layers in ResNet-20, we found that 8-bit ADC/DAC\nis necessary to preserve software level classification accuracy.\n", "versions": [{"version": "v1", "created": "Fri, 14 Sep 2018 18:47:34 GMT"}], "update_date": "2018-10-05", "authors_parsed": [["Zhang", "Fan", ""], ["Hu", "Miao", ""]]}, {"id": "1810.02229", "submitter": "Tommaso Caselli", "authors": "Tommaso Caselli", "title": "Italian Event Detection Goes Deep Learning", "comments": "to appear at CLiC-it 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  This paper reports on a set of experiments with different word embeddings to\ninitialize a state-of-the-art Bi-LSTM-CRF network for event detection and\nclassification in Italian, following the EVENTI evaluation exercise. The net-\nwork obtains a new state-of-the-art result by improving the F1 score for\ndetection of 1.3 points, and of 6.5 points for classification, by using a\nsingle step approach. The results also provide further evidence that embeddings\nhave a major impact on the performance of such architectures.\n", "versions": [{"version": "v1", "created": "Thu, 4 Oct 2018 14:09:20 GMT"}], "update_date": "2018-10-05", "authors_parsed": [["Caselli", "Tommaso", ""]]}, {"id": "1810.02244", "submitter": "Christopher Morris", "authors": "Christopher Morris, Martin Ritzert, Matthias Fey, William L. Hamilton,\n  Jan Eric Lenssen, Gaurav Rattan, Martin Grohe", "title": "Weisfeiler and Leman Go Neural: Higher-order Graph Neural Networks", "comments": "Extended version with proofs, accepted at AAAI 2019, added units of\n  measurement of QM9 dataset into appendix", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CV cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In recent years, graph neural networks (GNNs) have emerged as a powerful\nneural architecture to learn vector representations of nodes and graphs in a\nsupervised, end-to-end fashion. Up to now, GNNs have only been evaluated\nempirically---showing promising results. The following work investigates GNNs\nfrom a theoretical point of view and relates them to the $1$-dimensional\nWeisfeiler-Leman graph isomorphism heuristic ($1$-WL). We show that GNNs have\nthe same expressiveness as the $1$-WL in terms of distinguishing non-isomorphic\n(sub-)graphs. Hence, both algorithms also have the same shortcomings. Based on\nthis, we propose a generalization of GNNs, so-called $k$-dimensional GNNs\n($k$-GNNs), which can take higher-order graph structures at multiple scales\ninto account. These higher-order structures play an essential role in the\ncharacterization of social networks and molecule graphs. Our experimental\nevaluation confirms our theoretical findings as well as confirms that\nhigher-order information is useful in the task of graph classification and\nregression.\n", "versions": [{"version": "v1", "created": "Thu, 4 Oct 2018 14:31:57 GMT"}, {"version": "v2", "created": "Fri, 16 Nov 2018 12:52:37 GMT"}, {"version": "v3", "created": "Fri, 14 Feb 2020 15:55:24 GMT"}], "update_date": "2020-02-17", "authors_parsed": [["Morris", "Christopher", ""], ["Ritzert", "Martin", ""], ["Fey", "Matthias", ""], ["Hamilton", "William L.", ""], ["Lenssen", "Jan Eric", ""], ["Rattan", "Gaurav", ""], ["Grohe", "Martin", ""]]}, {"id": "1810.02252", "submitter": "Jan Van Haaren", "authors": "Lotte Bransen, Jan Van Haaren", "title": "Measuring Football Players' On-the-ball Contributions From Passes During\n  Games", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.AP cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Several performance metrics for quantifying the in-game performances of\nindividual football players have been proposed in recent years. Although the\nmajority of the on-the-ball actions during games constitutes of passes, many of\nthe currently available metrics focus on measuring the quality of shots only.\nTo help bridge this gap, we propose a novel approach to measure players'\non-the-ball contributions from passes during games. Our proposed approach\nmeasures the expected impact of each pass on the scoreline.\n", "versions": [{"version": "v1", "created": "Thu, 13 Sep 2018 20:40:22 GMT"}], "update_date": "2018-10-05", "authors_parsed": [["Bransen", "Lotte", ""], ["Van Haaren", "Jan", ""]]}, {"id": "1810.02263", "submitter": "Anas Barakat", "authors": "Anas Barakat, Pascal Bianchi", "title": "Convergence and Dynamical Behavior of the ADAM Algorithm for Non-Convex\n  Stochastic Optimization", "comments": "30 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG math.CA math.DS math.OC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Adam is a popular variant of stochastic gradient descent for finding a local\nminimizer of a function. In the constant stepsize regime, assuming that the\nobjective function is differentiable and non-convex, we establish the\nconvergence in the long run of the iterates to a stationary point under a\nstability condition. The key ingredient is the introduction of a\ncontinuous-time version of Adam, under the form of a non-autonomous ordinary\ndifferential equation. This continuous-time system is a relevant approximation\nof the Adam iterates, in the sense that the interpolated Adam process converges\nweakly towards the solution to the ODE. The existence and the uniqueness of the\nsolution are established. We further show the convergence of the solution\ntowards the critical points of the objective function and quantify its\nconvergence rate under a Lojasiewicz assumption. Then, we introduce a novel\ndecreasing stepsize version of Adam. Under mild assumptions, it is shown that\nthe iterates are almost surely bounded and converge almost surely to critical\npoints of the objective function. Finally, we analyze the fluctuations of the\nalgorithm by means of a conditional central limit theorem.\n", "versions": [{"version": "v1", "created": "Thu, 4 Oct 2018 15:01:46 GMT"}, {"version": "v2", "created": "Wed, 3 Apr 2019 23:00:29 GMT"}, {"version": "v3", "created": "Wed, 22 May 2019 14:23:23 GMT"}, {"version": "v4", "created": "Wed, 13 May 2020 18:08:49 GMT"}], "update_date": "2020-05-15", "authors_parsed": [["Barakat", "Anas", ""], ["Bianchi", "Pascal", ""]]}, {"id": "1810.02266", "submitter": "Jesse Read", "authors": "Jesse Read", "title": "Concept-drifting Data Streams are Time Series; The Case for Continuous\n  Adaptation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Learning from data streams is an increasingly important topic in data mining,\nmachine learning, and artificial intelligence in general. A major focus in the\ndata stream literature is on designing methods that can deal with concept\ndrift, a challenge where the generating distribution changes over time. A\ngeneral assumption in most of this literature is that instances are\nindependently distributed in the stream. In this work we show that, in the\ncontext of concept drift, this assumption is contradictory, and that the\npresence of concept drift necessarily implies temporal dependence; and thus\nsome form of time series. This has important implications on model design and\ndeployment. We explore and highlight the these implications, and show that\nHoeffding-tree based ensembles, which are very popular for learning in streams,\nare not naturally suited to learning \\emph{within} drift; and can perform in\nthis scenario only at significant computational cost of destructive adaptation.\nOn the other hand, we develop and parameterize gradient-descent methods and\ndemonstrate how they can perform \\emph{continuous} adaptation with no explicit\ndrift-detection mechanism, offering major advantages in terms of accuracy and\nefficiency. As a consequence of our theoretical discussion and empirical\nobservations, we outline a number of recommendations for deploying methods in\nconcept-drifting streams.\n", "versions": [{"version": "v1", "created": "Thu, 4 Oct 2018 15:04:10 GMT"}], "update_date": "2018-10-05", "authors_parsed": [["Read", "Jesse", ""]]}, {"id": "1810.02274", "submitter": "Nikolay Savinov", "authors": "Nikolay Savinov, Anton Raichuk, Rapha\\\"el Marinier, Damien Vincent,\n  Marc Pollefeys, Timothy Lillicrap, Sylvain Gelly", "title": "Episodic Curiosity through Reachability", "comments": "Accepted to ICLR 2019. Code at\n  https://github.com/google-research/episodic-curiosity/. Videos at\n  https://sites.google.com/view/episodic-curiosity/", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CV cs.RO stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Rewards are sparse in the real world and most of today's reinforcement\nlearning algorithms struggle with such sparsity. One solution to this problem\nis to allow the agent to create rewards for itself - thus making rewards dense\nand more suitable for learning. In particular, inspired by curious behaviour in\nanimals, observing something novel could be rewarded with a bonus. Such bonus\nis summed up with the real task reward - making it possible for RL algorithms\nto learn from the combined reward. We propose a new curiosity method which uses\nepisodic memory to form the novelty bonus. To determine the bonus, the current\nobservation is compared with the observations in memory. Crucially, the\ncomparison is done based on how many environment steps it takes to reach the\ncurrent observation from those in memory - which incorporates rich information\nabout environment dynamics. This allows us to overcome the known \"couch-potato\"\nissues of prior work - when the agent finds a way to instantly gratify itself\nby exploiting actions which lead to hardly predictable consequences. We test\nour approach in visually rich 3D environments in ViZDoom, DMLab and MuJoCo. In\nnavigational tasks from ViZDoom and DMLab, our agent outperforms the\nstate-of-the-art curiosity method ICM. In MuJoCo, an ant equipped with our\ncuriosity module learns locomotion out of the first-person-view curiosity only.\n", "versions": [{"version": "v1", "created": "Thu, 4 Oct 2018 15:24:06 GMT"}, {"version": "v2", "created": "Sat, 1 Dec 2018 17:39:39 GMT"}, {"version": "v3", "created": "Fri, 22 Feb 2019 17:02:58 GMT"}, {"version": "v4", "created": "Thu, 9 May 2019 13:10:33 GMT"}, {"version": "v5", "created": "Tue, 6 Aug 2019 17:54:03 GMT"}], "update_date": "2019-08-07", "authors_parsed": [["Savinov", "Nikolay", ""], ["Raichuk", "Anton", ""], ["Marinier", "Rapha\u00ebl", ""], ["Vincent", "Damien", ""], ["Pollefeys", "Marc", ""], ["Lillicrap", "Timothy", ""], ["Gelly", "Sylvain", ""]]}, {"id": "1810.02281", "submitter": "Nadav Cohen", "authors": "Sanjeev Arora, Nadav Cohen, Noah Golowich, Wei Hu", "title": "A Convergence Analysis of Gradient Descent for Deep Linear Neural\n  Networks", "comments": "Published as a conference paper at ICLR 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We analyze speed of convergence to global optimum for gradient descent\ntraining a deep linear neural network (parameterized as $x \\mapsto W_N W_{N-1}\n\\cdots W_1 x$) by minimizing the $\\ell_2$ loss over whitened data. Convergence\nat a linear rate is guaranteed when the following hold: (i) dimensions of\nhidden layers are at least the minimum of the input and output dimensions; (ii)\nweight matrices at initialization are approximately balanced; and (iii) the\ninitial loss is smaller than the loss of any rank-deficient solution. The\nassumptions on initialization (conditions (ii) and (iii)) are necessary, in the\nsense that violating any one of them may lead to convergence failure. Moreover,\nin the important case of output dimension 1, i.e. scalar regression, they are\nmet, and thus convergence to global optimum holds, with constant probability\nunder a random initialization scheme. Our results significantly extend previous\nanalyses, e.g., of deep linear residual networks (Bartlett et al., 2018).\n", "versions": [{"version": "v1", "created": "Thu, 4 Oct 2018 15:53:32 GMT"}, {"version": "v2", "created": "Tue, 27 Nov 2018 15:40:08 GMT"}, {"version": "v3", "created": "Sat, 26 Oct 2019 06:58:22 GMT"}], "update_date": "2019-10-29", "authors_parsed": [["Arora", "Sanjeev", ""], ["Cohen", "Nadav", ""], ["Golowich", "Noah", ""], ["Hu", "Wei", ""]]}, {"id": "1810.02303", "submitter": "Adrien Poulenard", "authors": "Adrien Poulenard, Maks Ovsjanikov", "title": "Multi-directional Geodesic Neural Networks via Equivariant Convolution", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.GR cs.CG cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a novel approach for performing convolution of signals on curved\nsurfaces and show its utility in a variety of geometric deep learning\napplications. Key to our construction is the notion of directional functions\ndefined on the surface, which extend the classic real-valued signals and which\ncan be naturally convolved with with real-valued template functions. As a\nresult, rather than trying to fix a canonical orientation or only keeping the\nmaximal response across all alignments of a 2D template at every point of the\nsurface, as done in previous works, we show how information across all\nrotations can be kept across different layers of the neural network. Our\nconstruction, which we call multi-directional geodesic convolution, or\ndirectional convolution for short, allows, in particular, to propagate and\nrelate directional information across layers and thus different regions on the\nshape. We first define directional convolution in the continuous setting, prove\nits key properties and then show how it can be implemented in practice, for\nshapes represented as triangle meshes. We evaluate directional convolution in a\nwide variety of learning scenarios ranging from classification of signals on\nsurfaces, to shape segmentation and shape matching, where we show a significant\nimprovement over several baselines.\n", "versions": [{"version": "v1", "created": "Mon, 1 Oct 2018 18:03:24 GMT"}], "update_date": "2018-10-05", "authors_parsed": [["Poulenard", "Adrien", ""], ["Ovsjanikov", "Maks", ""]]}, {"id": "1810.02309", "submitter": "Anna Thomas", "authors": "Anna T. Thomas and Albert Gu and Tri Dao and Atri Rudra and\n  Christopher R\\'e", "title": "Learning Compressed Transforms with Low Displacement Rank", "comments": "NeurIPS 2018. Code available at\n  https://github.com/HazyResearch/structured-nets", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The low displacement rank (LDR) framework for structured matrices represents\na matrix through two displacement operators and a low-rank residual. Existing\nuse of LDR matrices in deep learning has applied fixed displacement operators\nencoding forms of shift invariance akin to convolutions. We introduce a class\nof LDR matrices with more general displacement operators, and explicitly learn\nover both the operators and the low-rank component. This class generalizes\nseveral previous constructions while preserving compression and efficient\ncomputation. We prove bounds on the VC dimension of multi-layer neural networks\nwith structured weight matrices and show empirically that our compact\nparameterization can reduce the sample complexity of learning. When replacing\nweight layers in fully-connected, convolutional, and recurrent neural networks\nfor image classification and language modeling tasks, our new classes exceed\nthe accuracy of existing compression approaches, and on some tasks also\noutperform general unstructured layers while using more than 20x fewer\nparameters.\n", "versions": [{"version": "v1", "created": "Thu, 4 Oct 2018 16:44:16 GMT"}, {"version": "v2", "created": "Wed, 31 Oct 2018 22:02:37 GMT"}, {"version": "v3", "created": "Tue, 1 Jan 2019 16:36:35 GMT"}], "update_date": "2019-01-03", "authors_parsed": [["Thomas", "Anna T.", ""], ["Gu", "Albert", ""], ["Dao", "Tri", ""], ["Rudra", "Atri", ""], ["R\u00e9", "Christopher", ""]]}, {"id": "1810.02321", "submitter": "Hanyuan Hang", "authors": "Hanyuan Hang and Ingo Steinwart", "title": "Optimal Learning with Anisotropic Gaussian SVMs", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper investigates the nonparametric regression problem using SVMs with\nanisotropic Gaussian RBF kernels. Under the assumption that the target\nfunctions are resided in certain anisotropic Besov spaces, we establish the\nalmost optimal learning rates, more precisely, optimal up to some logarithmic\nfactor, presented by the effective smoothness. By taking the effective\nsmoothness into consideration, our almost optimal learning rates are faster\nthan those obtained with the underlying RKHSs being certain anisotropic Sobolev\nspaces. Moreover, if the target function depends only on fewer dimensions,\nfaster learning rates can be further achieved.\n", "versions": [{"version": "v1", "created": "Thu, 4 Oct 2018 17:09:42 GMT"}], "update_date": "2018-10-05", "authors_parsed": [["Hang", "Hanyuan", ""], ["Steinwart", "Ingo", ""]]}, {"id": "1810.02328", "submitter": "Gerald Friedland", "authors": "Gerald Friedland, Alfredo Metere, Mario Krell", "title": "A Practical Approach to Sizing Neural Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": "LLNL Technical Report 758456", "categories": "cs.NE cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Memorization is worst-case generalization. Based on MacKay's information\ntheoretic model of supervised machine learning, this article discusses how to\npractically estimate the maximum size of a neural network given a training data\nset. First, we present four easily applicable rules to analytically determine\nthe capacity of neural network architectures. This allows the comparison of the\nefficiency of different network architectures independently of a task. Second,\nwe introduce and experimentally validate a heuristic method to estimate the\nneural network capacity requirement for a given dataset and labeling. This\nallows an estimate of the required size of a neural network for a given\nproblem. We conclude the article with a discussion on the consequences of\nsizing the network wrongly, which includes both increased computation effort\nfor training as well as reduced generalization capability.\n", "versions": [{"version": "v1", "created": "Thu, 4 Oct 2018 17:20:39 GMT"}], "update_date": "2018-10-05", "authors_parsed": [["Friedland", "Gerald", ""], ["Metere", "Alfredo", ""], ["Krell", "Mario", ""]]}, {"id": "1810.02334", "submitter": "Kyle Hsu", "authors": "Kyle Hsu and Sergey Levine and Chelsea Finn", "title": "Unsupervised Learning via Meta-Learning", "comments": "ICLR 2019 camera-ready. 24 pages, 2 figures, links to code available\n  at https://sites.google.com/view/unsupervised-via-meta", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A central goal of unsupervised learning is to acquire representations from\nunlabeled data or experience that can be used for more effective learning of\ndownstream tasks from modest amounts of labeled data. Many prior unsupervised\nlearning works aim to do so by developing proxy objectives based on\nreconstruction, disentanglement, prediction, and other metrics. Instead, we\ndevelop an unsupervised meta-learning method that explicitly optimizes for the\nability to learn a variety of tasks from small amounts of data. To do so, we\nconstruct tasks from unlabeled data in an automatic way and run meta-learning\nover the constructed tasks. Surprisingly, we find that, when integrated with\nmeta-learning, relatively simple task construction mechanisms, such as\nclustering embeddings, lead to good performance on a variety of downstream,\nhuman-specified tasks. Our experiments across four image datasets indicate that\nour unsupervised meta-learning approach acquires a learning algorithm without\nany labeled data that is applicable to a wide range of downstream\nclassification tasks, improving upon the embedding learned by four prior\nunsupervised learning methods.\n", "versions": [{"version": "v1", "created": "Thu, 4 Oct 2018 17:29:17 GMT"}, {"version": "v2", "created": "Sat, 6 Oct 2018 23:39:52 GMT"}, {"version": "v3", "created": "Sat, 13 Oct 2018 23:57:36 GMT"}, {"version": "v4", "created": "Thu, 22 Nov 2018 20:47:45 GMT"}, {"version": "v5", "created": "Fri, 7 Dec 2018 20:38:03 GMT"}, {"version": "v6", "created": "Thu, 21 Mar 2019 23:43:47 GMT"}], "update_date": "2019-03-25", "authors_parsed": [["Hsu", "Kyle", ""], ["Levine", "Sergey", ""], ["Finn", "Chelsea", ""]]}, {"id": "1810.02338", "submitter": "Kexin Yi", "authors": "Kexin Yi, Jiajun Wu, Chuang Gan, Antonio Torralba, Pushmeet Kohli,\n  Joshua B. Tenenbaum", "title": "Neural-Symbolic VQA: Disentangling Reasoning from Vision and Language\n  Understanding", "comments": "NeurIPS 2018 (spotlight). The first two authors contributed equally\n  to this work. Project page: http://nsvqa.csail.mit.edu", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.CL cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We marry two powerful ideas: deep representation learning for visual\nrecognition and language understanding, and symbolic program execution for\nreasoning. Our neural-symbolic visual question answering (NS-VQA) system first\nrecovers a structural scene representation from the image and a program trace\nfrom the question. It then executes the program on the scene representation to\nobtain an answer. Incorporating symbolic structure as prior knowledge offers\nthree unique advantages. First, executing programs on a symbolic space is more\nrobust to long program traces; our model can solve complex reasoning tasks\nbetter, achieving an accuracy of 99.8% on the CLEVR dataset. Second, the model\nis more data- and memory-efficient: it performs well after learning on a small\nnumber of training data; it can also encode an image into a compact\nrepresentation, requiring less storage than existing methods for offline\nquestion answering. Third, symbolic program execution offers full transparency\nto the reasoning process; we are thus able to interpret and diagnose each\nexecution step.\n", "versions": [{"version": "v1", "created": "Thu, 4 Oct 2018 17:38:50 GMT"}, {"version": "v2", "created": "Mon, 14 Jan 2019 23:07:12 GMT"}], "update_date": "2019-01-16", "authors_parsed": [["Yi", "Kexin", ""], ["Wu", "Jiajun", ""], ["Gan", "Chuang", ""], ["Torralba", "Antonio", ""], ["Kohli", "Pushmeet", ""], ["Tenenbaum", "Joshua B.", ""]]}, {"id": "1810.02340", "submitter": "Namhoon Lee", "authors": "Namhoon Lee, Thalaiyasingam Ajanthan, Philip H. S. Torr", "title": "SNIP: Single-shot Network Pruning based on Connection Sensitivity", "comments": "ICLR 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Pruning large neural networks while maintaining their performance is often\ndesirable due to the reduced space and time complexity. In existing methods,\npruning is done within an iterative optimization procedure with either\nheuristically designed pruning schedules or additional hyperparameters,\nundermining their utility. In this work, we present a new approach that prunes\na given network once at initialization prior to training. To achieve this, we\nintroduce a saliency criterion based on connection sensitivity that identifies\nstructurally important connections in the network for the given task. This\neliminates the need for both pretraining and the complex pruning schedule while\nmaking it robust to architecture variations. After pruning, the sparse network\nis trained in the standard way. Our method obtains extremely sparse networks\nwith virtually the same accuracy as the reference network on the MNIST,\nCIFAR-10, and Tiny-ImageNet classification tasks and is broadly applicable to\nvarious architectures including convolutional, residual and recurrent networks.\nUnlike existing methods, our approach enables us to demonstrate that the\nretained connections are indeed relevant to the given task.\n", "versions": [{"version": "v1", "created": "Thu, 4 Oct 2018 17:39:58 GMT"}, {"version": "v2", "created": "Sat, 23 Feb 2019 07:45:29 GMT"}], "update_date": "2019-02-26", "authors_parsed": [["Lee", "Namhoon", ""], ["Ajanthan", "Thalaiyasingam", ""], ["Torr", "Philip H. S.", ""]]}, {"id": "1810.02358", "submitter": "Hyeonwoo Noh", "authors": "Hyeonwoo Noh, Taehoon Kim, Jonghwan Mun, Bohyung Han", "title": "Transfer Learning via Unsupervised Task Discovery for Visual Question\n  Answering", "comments": "CVPR 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CL cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study how to leverage off-the-shelf visual and linguistic data to cope\nwith out-of-vocabulary answers in visual question answering task. Existing\nlarge-scale visual datasets with annotations such as image class labels,\nbounding boxes and region descriptions are good sources for learning rich and\ndiverse visual concepts. However, it is not straightforward how the visual\nconcepts can be captured and transferred to visual question answering models\ndue to missing link between question dependent answering models and visual data\nwithout question. We tackle this problem in two steps: 1) learning a task\nconditional visual classifier, which is capable of solving diverse\nquestion-specific visual recognition tasks, based on unsupervised task\ndiscovery and 2) transferring the task conditional visual classifier to visual\nquestion answering models. Specifically, we employ linguistic knowledge sources\nsuch as structured lexical database (e.g. WordNet) and visual descriptions for\nunsupervised task discovery, and transfer a learned task conditional visual\nclassifier as an answering unit in a visual question answering model. We\nempirically show that the proposed algorithm generalizes to out-of-vocabulary\nanswers successfully using the knowledge transferred from the visual dataset.\n", "versions": [{"version": "v1", "created": "Wed, 3 Oct 2018 19:48:38 GMT"}, {"version": "v2", "created": "Sun, 7 Apr 2019 11:50:11 GMT"}], "update_date": "2019-04-09", "authors_parsed": [["Noh", "Hyeonwoo", ""], ["Kim", "Taehoon", ""], ["Mun", "Jonghwan", ""], ["Han", "Bohyung", ""]]}, {"id": "1810.02363", "submitter": "F\\'elix G. Harvey", "authors": "F\\'elix G. Harvey, Christopher Pal", "title": "Recurrent Transition Networks for Character Locomotion", "comments": "revision fixes: clarity issues in Section 4.4 (text and equations)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.GR cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Manually authoring transition animations for a complete locomotion system can\nbe a tedious and time-consuming task, especially for large games that allow\ncomplex and constrained locomotion movements, where the number of transitions\ngrows exponentially with the number of states. In this paper, we present a\nnovel approach, based on deep recurrent neural networks, to automatically\ngenerate such transitions given a past context of a few frames and a target\ncharacter state to reach. We present the Recurrent Transition Network (RTN),\nbased on a modified version of the Long-Short-Term-Memory (LSTM) network,\ndesigned specifically for transition generation and trained without any gait,\nphase, contact or action labels. We further propose a simple yet principled way\nto initialize the hidden states of the LSTM layer for a given sequence which\nimproves the performance and generalization to new motions. We both\nquantitatively and qualitatively evaluate our system and show that making the\nnetwork terrain-aware by adding a local terrain representation to the input\nyields better performance for rough-terrain navigation on long transitions. Our\nsystem produces realistic and fluid transitions that rival the quality of\nMotion Capture-based ground-truth motions, even before applying any\ninverse-kinematics postprocess. Direct benefits of our approach could be to\naccelerate the creation of transition variations for large coverage, or even to\nentirely replace transition nodes in an animation graph. We further explore\napplications of this model in a animation super-resolution setting where we\ntemporally decompress animations saved at 1 frame per second and show that the\nnetwork is able to reconstruct motions that are hard to distinguish from\nun-compressed locomotion sequences.\n", "versions": [{"version": "v1", "created": "Thu, 4 Oct 2018 15:12:13 GMT"}, {"version": "v2", "created": "Thu, 11 Oct 2018 14:40:10 GMT"}, {"version": "v3", "created": "Mon, 15 Oct 2018 19:44:41 GMT"}, {"version": "v4", "created": "Thu, 17 Jan 2019 21:23:44 GMT"}, {"version": "v5", "created": "Thu, 18 Mar 2021 20:00:10 GMT"}], "update_date": "2021-03-22", "authors_parsed": [["Harvey", "F\u00e9lix G.", ""], ["Pal", "Christopher", ""]]}, {"id": "1810.02406", "submitter": "Juho Piironen", "authors": "Juho Piironen, Markus Paasiniemi and Aki Vehtari", "title": "Projective Inference in High-dimensional Problems: Prediction and\n  Feature Selection", "comments": null, "journal-ref": "Electronic Journal of Statistics, 14(1):2155-2197, 2020.\n  https://projecteuclid.org/euclid.ejs/1589335310", "doi": "10.1214/20-EJS1711", "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper discusses predictive inference and feature selection for\ngeneralized linear models with scarce but high-dimensional data. We argue that\nin many cases one can benefit from a decision theoretically justified two-stage\napproach: first, construct a possibly non-sparse model that predicts well, and\nthen find a minimal subset of features that characterize the predictions. The\nmodel built in the first step is referred to as the \\emph{reference model} and\nthe operation during the latter step as predictive \\emph{projection}. The key\ncharacteristic of this approach is that it finds an excellent tradeoff between\nsparsity and predictive accuracy, and the gain comes from utilizing all\navailable information including prior and that coming from the left out\nfeatures. We review several methods that follow this principle and provide\nnovel methodological contributions. We present a new projection technique that\nunifies two existing techniques and is both accurate and fast to compute. We\nalso propose a way of evaluating the feature selection process using fast\nleave-one-out cross-validation that allows for easy and intuitive model size\nselection. Furthermore, we prove a theorem that helps to understand the\nconditions under which the projective approach could be beneficial. The\nbenefits are illustrated via several simulated and real world examples.\n", "versions": [{"version": "v1", "created": "Thu, 4 Oct 2018 19:55:58 GMT"}], "update_date": "2020-11-09", "authors_parsed": [["Piironen", "Juho", ""], ["Paasiniemi", "Markus", ""], ["Vehtari", "Aki", ""]]}, {"id": "1810.02422", "submitter": "Ryan Julian", "authors": "Zhanpeng He, Ryan Julian, Eric Heiden, Hejia Zhang, Stefan Schaal,\n  Joseph J. Lim, Gaurav Sukhatme, Karol Hausman", "title": "Simulator Predictive Control: Using Learned Task Representations and MPC\n  for Zero-Shot Generalization and Sequencing", "comments": "Presented at NeurIPS 2018 Workshop: Deep Reinforcement Learning. See\n  https://youtu.be/te4JWe7LPKw for supplemental video", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.AI cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Simulation-to-real transfer is an important strategy for making reinforcement\nlearning practical with real robots. Successful sim-to-real transfer systems\nhave difficulty producing policies which generalize across tasks, despite\ntraining for thousands of hours equivalent real robot time. To address this\nshortcoming, we present a novel approach to efficiently learning new robotic\nskills directly on a real robot, based on model-predictive control (MPC) and an\nalgorithm for learning task representations. In short, we show how to reuse the\nsimulation from the pre-training step of sim-to-real methods as a tool for\nforesight, allowing the sim-to-real policy adapt to unseen tasks. Rather than\nend-to-end learning policies for single tasks and attempting to transfer them,\nwe first use simulation to simultaneously learn (1) a continuous\nparameterization (i.e. a skill embedding or latent) of task-appropriate\nprimitive skills, and (2) a single policy for these skills which is conditioned\non this representation. We then directly transfer our multi-skill policy to a\nreal robot, and actuate the robot by choosing sequences of skill latents which\nactuate the policy, with each latent corresponding to a pre-learned primitive\nskill controller. We complete unseen tasks by choosing new sequences of skill\nlatents to control the robot using MPC, where our MPC model is composed of the\npre-trained skill policy executed in the simulation environment, run in\nparallel with the real robot. We discuss the background and principles of our\nmethod, detail its practical implementation, and evaluate its performance by\nusing our method to train a real Sawyer Robot to achieve motion tasks such as\ndrawing and block pushing.\n", "versions": [{"version": "v1", "created": "Thu, 4 Oct 2018 20:59:35 GMT"}, {"version": "v2", "created": "Tue, 13 Nov 2018 21:35:14 GMT"}, {"version": "v3", "created": "Wed, 27 Jan 2021 21:59:18 GMT"}], "update_date": "2021-01-29", "authors_parsed": [["He", "Zhanpeng", ""], ["Julian", "Ryan", ""], ["Heiden", "Eric", ""], ["Zhang", "Hejia", ""], ["Schaal", "Stefan", ""], ["Lim", "Joseph J.", ""], ["Sukhatme", "Gaurav", ""], ["Hausman", "Karol", ""]]}, {"id": "1810.02423", "submitter": "Pei Wang", "authors": "Pei Wang, Pushpi Paranamana, and Patrick Shafto", "title": "Generalizing the theory of cooperative inference", "comments": "Publish version for AISTATS 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.MA stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Cooperation information sharing is important to theories of human learning\nand has potential implications for machine learning. Prior work derived\nconditions for achieving optimal Cooperative Inference given strong, relatively\nrestrictive assumptions. We relax these assumptions by demonstrating\nconvergence for any discrete joint distribution, robustness through equivalence\nclasses and stability under perturbation, and effectiveness by deriving bounds\nfrom structural properties of the original joint distribution. We provide\ngeometric interpretations, connections to and implications for optimal\ntransport, and connections to importance sampling, and conclude by outlining\nopen questions and challenges to realizing the promise of Cooperative\nInference.\n", "versions": [{"version": "v1", "created": "Thu, 4 Oct 2018 21:04:29 GMT"}, {"version": "v2", "created": "Wed, 13 Feb 2019 21:02:30 GMT"}], "update_date": "2019-02-15", "authors_parsed": [["Wang", "Pei", ""], ["Paranamana", "Pushpi", ""], ["Shafto", "Patrick", ""]]}, {"id": "1810.02424", "submitter": "Chihuang Liu", "authors": "Chihuang Liu, Joseph JaJa", "title": "Feature Prioritization and Regularization Improve Standard Accuracy and\n  Adversarial Robustness", "comments": "IJCAI 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Adversarial training has been successfully applied to build robust models at\na certain cost. While the robustness of a model increases, the standard\nclassification accuracy declines. This phenomenon is suggested to be an\ninherent trade-off. We propose a model that employs feature prioritization by a\nnonlinear attention module and $L_2$ feature regularization to improve the\nadversarial robustness and the standard accuracy relative to adversarial\ntraining. The attention module encourages the model to rely heavily on robust\nfeatures by assigning larger weights to them while suppressing non-robust\nfeatures. The regularizer encourages the model to extract similar features for\nthe natural and adversarial images, effectively ignoring the added\nperturbation. In addition to evaluating the robustness of our model, we provide\njustification for the attention module and propose a novel experimental\nstrategy that quantitatively demonstrates that our model is almost ideally\naligned with salient data characteristics. Additional experimental results\nillustrate the power of our model relative to the state of the art methods.\n", "versions": [{"version": "v1", "created": "Thu, 4 Oct 2018 21:10:09 GMT"}, {"version": "v2", "created": "Wed, 20 Mar 2019 19:28:38 GMT"}, {"version": "v3", "created": "Mon, 12 Aug 2019 21:56:18 GMT"}], "update_date": "2019-08-14", "authors_parsed": [["Liu", "Chihuang", ""], ["JaJa", "Joseph", ""]]}, {"id": "1810.02434", "submitter": "Vaishak Belle", "authors": "Vaishak Belle", "title": "Abstracting Probabilistic Models: A Logical Perspective", "comments": "In AAAI Workshop: Statistical Relational Artificial Intelligence,\n  2020. (This is the extended version.)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Abstraction is a powerful idea widely used in science, to model, reason and\nexplain the behavior of systems in a more tractable search space, by omitting\nirrelevant details. While notions of abstraction have matured for deterministic\nsystems, the case for abstracting probabilistic models is not yet fully\nunderstood.\n  In this paper, we provide a semantical framework for analyzing such\nabstractions from first principles. We develop the framework in a general way,\nallowing for expressive languages, including logic-based ones that admit\nrelational and hierarchical constructs with stochastic primitives. We motivate\na definition of consistency between a high-level model and its low-level\ncounterpart, but also treat the case when the high-level model is missing\ncritical information present in the low-level model. We prove properties of\nabstractions, both at the level of the parameter as well as the structure of\nthe models. We conclude with some observations about how abstractions can be\nderived automatically.\n", "versions": [{"version": "v1", "created": "Thu, 4 Oct 2018 21:39:38 GMT"}, {"version": "v2", "created": "Thu, 4 Jul 2019 18:25:44 GMT"}, {"version": "v3", "created": "Mon, 13 Jan 2020 13:44:46 GMT"}], "update_date": "2020-01-14", "authors_parsed": [["Belle", "Vaishak", ""]]}, {"id": "1810.02440", "submitter": "Alessandro Achille", "authors": "Alessandro Achille, Glen Mbeng, Stefano Soatto", "title": "Dynamics and Reachability of Learning Tasks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We compute the transition probability between two learning tasks, and show\nthat it decomposes into two factors. The first depends on the geometry of the\nloss landscape of a model trained on each task, independent of any particular\nmodel used. This is related to an information theoretic distance function, but\nis insufficient to predict success in transfer learning, as nearby tasks can be\nunreachable via fine-tuning. The second factor depends on the ease of\ntraversing the path between two tasks. With this dynamic component, we derive\nstrict lower bounds on the complexity necessary to learn a task starting from\nthe solution to another, which is one of the most common forms of transfer\nlearning.\n", "versions": [{"version": "v1", "created": "Thu, 4 Oct 2018 22:14:40 GMT"}, {"version": "v2", "created": "Wed, 29 May 2019 04:49:00 GMT"}], "update_date": "2019-05-30", "authors_parsed": [["Achille", "Alessandro", ""], ["Mbeng", "Glen", ""], ["Soatto", "Stefano", ""]]}, {"id": "1810.02442", "submitter": "Hao Zhang", "authors": "Haowen Xu, Hao Zhang, Zhiting Hu, Xiaodan Liang, Ruslan Salakhutdinov,\n  Eric Xing", "title": "AutoLoss: Learning Discrete Schedules for Alternate Optimization", "comments": "19-pages manuscripts. The first two authors contributed equally", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Many machine learning problems involve iteratively and alternately optimizing\ndifferent task objectives with respect to different sets of parameters.\nAppropriately scheduling the optimization of a task objective or a set of\nparameters is usually crucial to the quality of convergence. In this paper, we\npresent AutoLoss, a meta-learning framework that automatically learns and\ndetermines the optimization schedule. AutoLoss provides a generic way to\nrepresent and learn the discrete optimization schedule from metadata, allows\nfor a dynamic and data-driven schedule in ML problems that involve alternating\nupdates of different parameters or from different loss objectives. We apply\nAutoLoss on four ML tasks: d-ary quadratic regression, classification using a\nmulti-layer perceptron (MLP), image generation using GANs, and multi-task\nneural machine translation (NMT). We show that the AutoLoss controller is able\nto capture the distribution of better optimization schedules that result in\nhigher quality of convergence on all four tasks. The trained AutoLoss\ncontroller is generalizable -- it can guide and improve the learning of a new\ntask model with different specifications, or on different datasets.\n", "versions": [{"version": "v1", "created": "Thu, 4 Oct 2018 22:21:55 GMT"}], "update_date": "2018-10-08", "authors_parsed": [["Xu", "Haowen", ""], ["Zhang", "Hao", ""], ["Hu", "Zhiting", ""], ["Liang", "Xiaodan", ""], ["Salakhutdinov", "Ruslan", ""], ["Xing", "Eric", ""]]}, {"id": "1810.02453", "submitter": "Micha{\\l} Derezi\\'nski", "authors": "Micha{\\l} Derezi\\'nski, Manfred K. Warmuth, Daniel Hsu", "title": "Correcting the bias in least squares regression with volume-rescaled\n  sampling", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Consider linear regression where the examples are generated by an unknown\ndistribution on $R^d\\times R$. Without any assumptions on the noise, the linear\nleast squares solution for any i.i.d. sample will typically be biased w.r.t.\nthe least squares optimum over the entire distribution. However, we show that\nif an i.i.d. sample of any size k is augmented by a certain small additional\nsample, then the solution of the combined sample becomes unbiased. We show this\nwhen the additional sample consists of d points drawn jointly according to the\ninput distribution that is rescaled by the squared volume spanned by the\npoints. Furthermore, we propose algorithms to sample from this volume-rescaled\ndistribution when the data distribution is only known through an i.i.d sample.\n", "versions": [{"version": "v1", "created": "Thu, 4 Oct 2018 23:09:08 GMT"}], "update_date": "2018-10-08", "authors_parsed": [["Derezi\u0144ski", "Micha\u0142", ""], ["Warmuth", "Manfred K.", ""], ["Hsu", "Daniel", ""]]}, {"id": "1810.02501", "submitter": "Gunwoong Park", "authors": "Gunwoong Park and Sion Park", "title": "High-Dimensional Poisson DAG Model Learning Using $\\ell_1$-Regularized\n  Regression", "comments": "43 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we develop a new approach to learning high-dimensional Poisson\ndirected acyclic graphical (DAG) models from only observational data without\nstrong assumptions such as faithfulness and strong sparsity. A key component of\nour method is to decouple the ordering estimation or parent search where the\nproblems can be efficiently addressed using $\\ell_1$-regularized regression and\nthe mean-variance relationship. We show that sample size $n = \\Omega( d^{2}\n\\log^{9} p)$ is sufficient for our polynomial time Mean-variance Ratio Scoring\n(MRS) algorithm to recover the true directed graph, where $p$ is the number of\nnodes and $d$ is the maximum indegree. We verify through simulations that our\nalgorithm is statistically consistent in the high-dimensional $p>n$ setting,\nand performs well compared to state-of-the-art ODS, GES, and MMHC algorithms.\nWe also demonstrate through multivariate real count data that our MRS algorithm\nis well-suited to estimating DAG models for multivariate count data in\ncomparison to other methods used for discrete data.\n", "versions": [{"version": "v1", "created": "Fri, 5 Oct 2018 03:12:27 GMT"}, {"version": "v2", "created": "Tue, 25 Dec 2018 04:58:25 GMT"}, {"version": "v3", "created": "Mon, 27 May 2019 09:58:22 GMT"}], "update_date": "2019-05-28", "authors_parsed": [["Park", "Gunwoong", ""], ["Park", "Sion", ""]]}, {"id": "1810.02513", "submitter": "Nataniel Ruiz", "authors": "Nataniel Ruiz, Samuel Schulter, Manmohan Chandraker", "title": "Learning To Simulate", "comments": "Published at International Conference on Learning Representations\n  (ICLR) 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Simulation is a useful tool in situations where training data for machine\nlearning models is costly to annotate or even hard to acquire. In this work, we\npropose a reinforcement learning-based method for automatically adjusting the\nparameters of any (non-differentiable) simulator, thereby controlling the\ndistribution of synthesized data in order to maximize the accuracy of a model\ntrained on that data. In contrast to prior art that hand-crafts these\nsimulation parameters or adjusts only parts of the available parameters, our\napproach fully controls the simulator with the actual underlying goal of\nmaximizing accuracy, rather than mimicking the real data distribution or\nrandomly generating a large volume of data. We find that our approach (i)\nquickly converges to the optimal simulation parameters in controlled\nexperiments and (ii) can indeed discover good sets of parameters for an image\nrendering simulator in actual computer vision applications.\n", "versions": [{"version": "v1", "created": "Fri, 5 Oct 2018 04:11:25 GMT"}, {"version": "v2", "created": "Tue, 14 May 2019 03:15:27 GMT"}], "update_date": "2019-05-15", "authors_parsed": [["Ruiz", "Nataniel", ""], ["Schulter", "Samuel", ""], ["Chandraker", "Manmohan", ""]]}, {"id": "1810.02518", "submitter": "arXiv Admin", "authors": "Rahul Makhijani", "title": "Social Choice Random Utility Models of Intransitive Pairwise Comparisons", "comments": "This article has been withdrawn by arXiv administrators due to an\n  irreconcilable authorship dispute", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.IR stat.AP stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  There is a growing need for discrete choice models that account for the\ncomplex nature of human choices, escaping traditional behavioral assumptions\nsuch as the transitivity of pairwise preferences. Recently, several parametric\nmodels of intransitive comparisons have been proposed, but in all cases the\nmaximum likelihood problem is non-concave, making inference difficult. In this\nwork we generalize this trend, showing that there cannot exist any parametric\nmodel with a concave log-likelihood function that can exhibit intransitive\npreferences. Given this result, we motivate a new model for analyzing\nintransitivity in pairwise comparisons, taking inspiration from the Condorcet\nmethod (majority vote) in social choice theory. The Majority Vote model we\nanalyze is defined as a voting process over independent Random Utility Models\n(RUMs). We infer a multidimensional embedding of each object or player, in\ncontrast to the traditional one-dimensional embedding used by models such as\nthe Thurstone or Bradley-Terry-Luce (BTL) models. We show that a\nthree-dimensional majority vote model is capable of modeling arbitrarily strong\nand long intransitive cycles, and can also represent arbitrary pairwise\ncomparison probabilities on any triplet. We provide experimental results that\nsubstantiate our claims regarding the effectiveness of our model in capturing\nintransitivity for various pairwise choice tasks such as predicting choices in\nrecommendation systems, winners in online video games, and elections.\n", "versions": [{"version": "v1", "created": "Fri, 5 Oct 2018 05:26:29 GMT"}, {"version": "v2", "created": "Wed, 10 Oct 2018 18:51:21 GMT"}, {"version": "v3", "created": "Thu, 11 Oct 2018 15:39:17 GMT"}], "update_date": "2018-10-12", "authors_parsed": [["Makhijani", "Rahul", ""]]}, {"id": "1810.02525", "submitter": "Peter Henderson", "authors": "Peter Henderson, Joshua Romoff, Joelle Pineau", "title": "Where Did My Optimum Go?: An Empirical Analysis of Gradient Descent\n  Optimization in Policy Gradient Methods", "comments": "Accepted at the European Workshop on Reinforcement Learning 2018\n  (EWRL14)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent analyses of certain gradient descent optimization methods have shown\nthat performance can degrade in some settings - such as with stochasticity or\nimplicit momentum. In deep reinforcement learning (Deep RL), such optimization\nmethods are often used for training neural networks via the temporal difference\nerror or policy gradient. As an agent improves over time, the optimization\ntarget changes and thus the loss landscape (and local optima) change. Due to\nthe failure modes of those methods, the ideal choice of optimizer for Deep RL\nremains unclear. As such, we provide an empirical analysis of the effects that\na wide range of gradient descent optimizers and their hyperparameters have on\npolicy gradient methods, a subset of Deep RL algorithms, for benchmark\ncontinuous control tasks. We find that adaptive optimizers have a narrow window\nof effective learning rates, diverging in other cases, and that the\neffectiveness of momentum varies depending on the properties of the\nenvironment. Our analysis suggests that there is significant interplay between\nthe dynamics of the environment and Deep RL algorithm properties which aren't\nnecessarily accounted for by traditional adaptive gradient methods. We provide\nsuggestions for optimal settings of current methods and further lines of\nresearch based on our findings.\n", "versions": [{"version": "v1", "created": "Fri, 5 Oct 2018 05:52:49 GMT"}], "update_date": "2018-10-08", "authors_parsed": [["Henderson", "Peter", ""], ["Romoff", "Joshua", ""], ["Pineau", "Joelle", ""]]}, {"id": "1810.02528", "submitter": "Cheolhyeong Kim", "authors": "Cheolhyeong Kim, Seungtae Park, Hyung Ju Hwang", "title": "Local Stability and Performance of Simple Gradient Penalty\n  mu-Wasserstein GAN", "comments": "21 pages, 39 figures, 2 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Wasserstein GAN(WGAN) is a model that minimizes the Wasserstein distance\nbetween a data distribution and sample distribution. Recent studies have\nproposed stabilizing the training process for the WGAN and implementing the\nLipschitz constraint. In this study, we prove the local stability of optimizing\nthe simple gradient penalty $\\mu$-WGAN(SGP $\\mu$-WGAN) under suitable\nassumptions regarding the equilibrium and penalty measure $\\mu$. The measure\nvalued differentiation concept is employed to deal with the derivative of the\npenalty terms, which is helpful for handling abstract singular measures with\nlower dimensional support. Based on this analysis, we claim that penalizing the\ndata manifold or sample manifold is the key to regularizing the original WGAN\nwith a gradient penalty. Experimental results obtained with unintuitive penalty\nmeasures that satisfy our assumptions are also provided to support our\ntheoretical results.\n", "versions": [{"version": "v1", "created": "Fri, 5 Oct 2018 06:03:03 GMT"}], "update_date": "2018-10-08", "authors_parsed": [["Kim", "Cheolhyeong", ""], ["Park", "Seungtae", ""], ["Hwang", "Hyung Ju", ""]]}, {"id": "1810.02541", "submitter": "Amin Babadi", "authors": "Perttu H\\\"am\\\"al\\\"ainen, Amin Babadi, Xiaoxiao Ma, Jaakko Lehtinen", "title": "PPO-CMA: Proximal Policy Optimization with Covariance Matrix Adaptation", "comments": "This paper has been accepted to IEEE International Workshop on\n  Machine Learning for Signal Processing (MLSP 2020). The arxiv version also\n  includes an appendix that covers more results", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Proximal Policy Optimization (PPO) is a highly popular model-free\nreinforcement learning (RL) approach. However, we observe that in a continuous\naction space, PPO can prematurely shrink the exploration variance, which leads\nto slow progress and may make the algorithm prone to getting stuck in local\noptima. Drawing inspiration from CMA-ES, a black-box evolutionary optimization\nmethod designed for robustness in similar situations, we propose PPO-CMA, a\nproximal policy optimization approach that adaptively expands the exploration\nvariance to speed up progress. With only minor changes to PPO, our algorithm\nconsiderably improves performance in Roboschool continuous control benchmarks.\nOur results also show that PPO-CMA, as opposed to PPO, is significantly less\nsensitive to the choice of hyperparameters, allowing one to use it in complex\nmovement optimization tasks without requiring tedious tuning.\n", "versions": [{"version": "v1", "created": "Fri, 5 Oct 2018 06:59:29 GMT"}, {"version": "v2", "created": "Mon, 8 Oct 2018 07:57:04 GMT"}, {"version": "v3", "created": "Tue, 18 Dec 2018 09:24:26 GMT"}, {"version": "v4", "created": "Wed, 16 Jan 2019 09:29:44 GMT"}, {"version": "v5", "created": "Wed, 23 Jan 2019 21:47:31 GMT"}, {"version": "v6", "created": "Fri, 24 May 2019 09:16:37 GMT"}, {"version": "v7", "created": "Tue, 27 Aug 2019 07:34:01 GMT"}, {"version": "v8", "created": "Mon, 3 Aug 2020 07:19:28 GMT"}, {"version": "v9", "created": "Tue, 3 Nov 2020 07:51:49 GMT"}], "update_date": "2020-11-04", "authors_parsed": [["H\u00e4m\u00e4l\u00e4inen", "Perttu", ""], ["Babadi", "Amin", ""], ["Ma", "Xiaoxiao", ""], ["Lehtinen", "Jaakko", ""]]}, {"id": "1810.02555", "submitter": "Mike Wu", "authors": "Mike Wu, Noah Goodman, Stefano Ermon", "title": "Differentiable Antithetic Sampling for Variance Reduction in Stochastic\n  Variational Inference", "comments": "8 pages with 7 pages appendix; AISTATS 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Stochastic optimization techniques are standard in variational inference\nalgorithms. These methods estimate gradients by approximating expectations with\nindependent Monte Carlo samples. In this paper, we explore a technique that\nuses correlated, but more representative , samples to reduce estimator\nvariance. Specifically, we show how to generate antithetic samples that match\nsample moments with the true moments of an underlying importance distribution.\nCombining a differentiable antithetic sampler with modern stochastic\nvariational inference, we showcase the effectiveness of this approach for\nlearning a deep generative model.\n", "versions": [{"version": "v1", "created": "Fri, 5 Oct 2018 07:42:15 GMT"}, {"version": "v2", "created": "Wed, 14 Aug 2019 17:24:38 GMT"}], "update_date": "2019-08-15", "authors_parsed": [["Wu", "Mike", ""], ["Goodman", "Noah", ""], ["Ermon", "Stefano", ""]]}, {"id": "1810.02565", "submitter": "Antonio Orvieto", "authors": "Antonio Orvieto and Aurelien Lucchi", "title": "Continuous-time Models for Stochastic Optimization Algorithms", "comments": "33rd Conference on Neural Information Processing Systems (NeurIPS\n  2019), Vancouver, Canada", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.OC cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose new continuous-time formulations for first-order stochastic\noptimization algorithms such as mini-batch gradient descent and\nvariance-reduced methods. We exploit these continuous-time models, together\nwith simple Lyapunov analysis as well as tools from stochastic calculus, in\norder to derive convergence bounds for various types of non-convex functions.\nGuided by such analysis, we show that the same Lyapunov arguments hold in\ndiscrete-time, leading to matching rates. In addition, we use these models and\nIto calculus to infer novel insights on the dynamics of SGD, proving that a\ndecreasing learning rate acts as time warping or, equivalently, as landscape\nstretching.\n", "versions": [{"version": "v1", "created": "Fri, 5 Oct 2018 08:15:56 GMT"}, {"version": "v2", "created": "Tue, 28 May 2019 14:22:26 GMT"}, {"version": "v3", "created": "Tue, 10 Mar 2020 22:27:25 GMT"}], "update_date": "2020-03-12", "authors_parsed": [["Orvieto", "Antonio", ""], ["Lucchi", "Aurelien", ""]]}, {"id": "1810.02567", "submitter": "Shuai Li", "authors": "Shuai Li, Tor Lattimore, Csaba Szepesv\\'ari", "title": "Online Learning to Rank with Features", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce a new model for online ranking in which the click probability\nfactors into an examination and attractiveness function and the attractiveness\nfunction is a linear function of a feature vector and an unknown parameter.\nOnly relatively mild assumptions are made on the examination function. A novel\nalgorithm for this setup is analysed, showing that the dependence on the number\nof items is replaced by a dependence on the dimension, allowing the new\nalgorithm to handle a large number of items. When reduced to the orthogonal\ncase, the regret of the algorithm improves on the state-of-the-art.\n", "versions": [{"version": "v1", "created": "Fri, 5 Oct 2018 08:39:00 GMT"}, {"version": "v2", "created": "Sat, 25 May 2019 06:12:48 GMT"}], "update_date": "2019-05-28", "authors_parsed": [["Li", "Shuai", ""], ["Lattimore", "Tor", ""], ["Szepesv\u00e1ri", "Csaba", ""]]}, {"id": "1810.02568", "submitter": "Shrikant Venkataramani", "authors": "Shrikant Venkataramani, Paris Smaragdis", "title": "End-to-end Networks for Supervised Single-channel Speech Separation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.AS cs.LG cs.SD eess.SP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The performance of single channel source separation algorithms has improved\ngreatly in recent times with the development and deployment of neural networks.\nHowever, many such networks continue to operate on the magnitude spectrogram of\na mixture, and produce an estimate of source magnitude spectrograms, to perform\nsource separation. In this paper, we interpret these steps as additional neural\nnetwork layers and propose an end-to-end source separation network that allows\nus to estimate the separated speech waveform by operating directly on the raw\nwaveform of the mixture. Furthermore, we also propose the use of masking based\nend-to-end separation networks that jointly optimize the mask and the latent\nrepresentations of the mixture waveforms. These networks show a significant\nimprovement in separation performance compared to existing architectures in our\nexperiments. To train these end-to-end models, we investigate the use of\ncomposite cost functions that are derived from objective evaluation metrics as\nmeasured on waveforms. We present subjective listening test results that\ndemonstrate the improvement attained by using masking based end-to-end networks\nand also reveal insights into the performance of these cost functions for\nend-to-end source separation.\n", "versions": [{"version": "v1", "created": "Fri, 5 Oct 2018 08:44:27 GMT"}], "update_date": "2018-10-08", "authors_parsed": [["Venkataramani", "Shrikant", ""], ["Smaragdis", "Paris", ""]]}, {"id": "1810.02653", "submitter": "Yazhan Zhang", "authors": "Yazhan Zhang, Zicheng Kan, Yu Alexander Tse, Yang Yang, Michael Yu\n  Wang", "title": "FingerVision Tactile Sensor Design and Slip Detection Using\n  Convolutional LSTM Network", "comments": "7 pages, 7 figures, submitted to ICRA2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Tactile sensing is essential to the human perception system, so as to robot.\nIn this paper, we develop a novel optical-based tactile sensor \"FingerVision\"\nwith effective signal processing algorithms. This sensor is composed of soft\nskin with embedded marker array bonded to rigid frame, and a web camera with a\nfisheye lens. While being excited with contact force, the camera tracks the\nmovements of markers and deformation field is obtained. Compared to existing\ntactile sensors, our sensor features compact footprint, high resolution, and\nease of fabrication. Besides, utilizing the deformation field estimation, we\npropose a slip classification framework based on convolution Long Short Term\nMemory (convolutional LSTM) networks. The data collection process takes\nadvantage of the human sense of slip, during which human hand holds 12 daily\nobjects, interacts with sensor skin and labels data with a slip or non-slip\nidentity based on human feeling of slip. Our slip classification framework\nperforms high accuracy of 97.62% on the test dataset. It is expected to be\ncapable of enhancing the stability of robot grasping significantly, leading to\nbetter contact force control, finer object interaction and more active sensing\nmanipulation.\n", "versions": [{"version": "v1", "created": "Fri, 5 Oct 2018 12:51:08 GMT"}], "update_date": "2018-10-08", "authors_parsed": [["Zhang", "Yazhan", ""], ["Kan", "Zicheng", ""], ["Tse", "Yu Alexander", ""], ["Yang", "Yang", ""], ["Wang", "Michael Yu", ""]]}, {"id": "1810.02658", "submitter": "Ruzhang Zhao", "authors": "Ruzhang Zhao, Pengyu Hong, Jun S Liu", "title": "IMMIGRATE: A Margin-based Feature Selection Method with Interaction\n  Terms", "comments": "R package ('Immigrate') available on CRAN", "journal-ref": "Entropy. 2020; 22(3):291", "doi": "10.3390/e22030291", "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Relief based algorithms have often been claimed to uncover feature\ninteractions. However, it is still unclear whether and how interaction terms\nwill be differentiated from marginal effects. In this paper, we propose\nIMMIGRATE algorithm by including and training weights for interaction terms.\nBesides applying the large margin principle, we focus on the robustness of the\ncontributors of margin and consider local and global information\nsimultaneously. Moreover, IMMIGRATE has been shown to enjoy attractive\nproperties, such as robustness and combination with Boosting. We evaluate our\nproposed method on several tasks, which achieves state-of-the-art results\nsignificantly.\n", "versions": [{"version": "v1", "created": "Fri, 5 Oct 2018 13:00:12 GMT"}, {"version": "v2", "created": "Tue, 22 Jan 2019 16:43:00 GMT"}, {"version": "v3", "created": "Wed, 4 Mar 2020 03:04:33 GMT"}], "update_date": "2020-03-05", "authors_parsed": [["Zhao", "Ruzhang", ""], ["Hong", "Pengyu", ""], ["Liu", "Jun S", ""]]}, {"id": "1810.02660", "submitter": "Hadrien Hendrikx", "authors": "Hadrien Hendrikx, Francis Bach and Laurent Massouli\\'e", "title": "Accelerated Decentralized Optimization with Local Updates for Smooth and\n  Strongly Convex Objectives", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.OC cs.DC cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we study the problem of minimizing a sum of smooth and\nstrongly convex functions split over the nodes of a network in a decentralized\nfashion. We propose the algorithm $ESDACD$, a decentralized accelerated\nalgorithm that only requires local synchrony. Its rate depends on the condition\nnumber $\\kappa$ of the local functions as well as the network topology and\ndelays. Under mild assumptions on the topology of the graph, $ESDACD$ takes a\ntime $O((\\tau_{\\max} +\n\\Delta_{\\max})\\sqrt{{\\kappa}/{\\gamma}}\\ln(\\epsilon^{-1}))$ to reach a precision\n$\\epsilon$ where $\\gamma$ is the spectral gap of the graph, $\\tau_{\\max}$ the\nmaximum communication delay and $\\Delta_{\\max}$ the maximum computation time.\nTherefore, it matches the rate of $SSDA$, which is optimal when $\\tau_{\\max} =\n\\Omega\\left(\\Delta_{\\max}\\right)$. Applying $ESDACD$ to quadratic local\nfunctions leads to an accelerated randomized gossip algorithm of rate $O(\n\\sqrt{\\theta_{\\rm gossip}/n})$ where $\\theta_{\\rm gossip}$ is the rate of the\nstandard randomized gossip. To the best of our knowledge, it is the first\nasynchronous gossip algorithm with a provably improved rate of convergence of\nthe second moment of the error. We illustrate these results with experiments in\nidealized settings.\n", "versions": [{"version": "v1", "created": "Fri, 5 Oct 2018 13:06:43 GMT"}, {"version": "v2", "created": "Tue, 19 Feb 2019 17:30:01 GMT"}, {"version": "v3", "created": "Fri, 22 Feb 2019 13:01:21 GMT"}], "update_date": "2019-02-25", "authors_parsed": [["Hendrikx", "Hadrien", ""], ["Bach", "Francis", ""], ["Massouli\u00e9", "Laurent", ""]]}, {"id": "1810.02677", "submitter": "Yancheng Yuan", "authors": "Defeng Sun, Kim-Chuan Toh and Yancheng Yuan", "title": "Convex Clustering: Model, Theoretical Guarantee and Efficient Algorithm", "comments": "arXiv admin note: substantial text overlap with arXiv:1802.07091", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG math.OC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Clustering is a fundamental problem in unsupervised learning. Popular methods\nlike K-means, may suffer from poor performance as they are prone to get stuck\nin its local minima. Recently, the sum-of-norms (SON) model (also known as the\nclustering path) has been proposed in Pelckmans et al. (2005), Lindsten et al.\n(2011) and Hocking et al. (2011). The perfect recovery properties of the convex\nclustering model with uniformly weighted all pairwise-differences\nregularization have been proved by Zhu et al. (2014) and Panahi et al. (2017).\nHowever, no theoretical guarantee has been established for the general weighted\nconvex clustering model, where better empirical results have been observed. In\nthe numerical optimization aspect, although algorithms like the alternating\ndirection method of multipliers (ADMM) and the alternating minimization\nalgorithm (AMA) have been proposed to solve the convex clustering model (Chi\nand Lange, 2015), it still remains very challenging to solve large-scale\nproblems. In this paper, we establish sufficient conditions for the perfect\nrecovery guarantee of the general weighted convex clustering model, which\ninclude and improve existing theoretical results as special cases. In addition,\nwe develop a semismooth Newton based augmented Lagrangian method for solving\nlarge-scale convex clustering problems. Extensive numerical experiments on both\nsimulated and real data demonstrate that our algorithm is highly efficient and\nrobust for solving large-scale problems. Moreover, the numerical results also\nshow the superior performance and scalability of our algorithm comparing to the\nexisting first-order methods. In particular, our algorithm is able to solve a\nconvex clustering problem with 200,000 points in $\\mathbb{R}^3$ in about 6\nminutes.\n", "versions": [{"version": "v1", "created": "Thu, 4 Oct 2018 14:52:42 GMT"}], "update_date": "2018-10-08", "authors_parsed": [["Sun", "Defeng", ""], ["Toh", "Kim-Chuan", ""], ["Yuan", "Yancheng", ""]]}, {"id": "1810.02678", "submitter": "Tomi Peltola", "authors": "Tomi Peltola", "title": "Local Interpretable Model-agnostic Explanations of Bayesian Predictive\n  Models via Kullback-Leibler Projections", "comments": "Extended abstract/short paper, Proceedings of the 2nd Workshop on\n  Explainable Artificial Intelligence (XAI 2018) at IJCAI/ECAI 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce a method, KL-LIME, for explaining predictions of Bayesian\npredictive models by projecting the information in the predictive distribution\nlocally to a simpler, interpretable explanation model. The proposed approach\ncombines the recent Local Interpretable Model-agnostic Explanations (LIME)\nmethod with ideas from Bayesian projection predictive variable selection\nmethods. The information theoretic basis helps in navigating the trade-off\nbetween explanation fidelity and complexity. We demonstrate the method in\nexplaining MNIST digit classifications made by a Bayesian deep convolutional\nneural network.\n", "versions": [{"version": "v1", "created": "Fri, 5 Oct 2018 13:43:08 GMT"}], "update_date": "2018-10-08", "authors_parsed": [["Peltola", "Tomi", ""]]}, {"id": "1810.02684", "submitter": "Vahid Moosavi", "authors": "Joao P. Leitao, Mohamed Zaghloul and Vahid Moosavi", "title": "Modeling overland flow from local inflows in almost no-time, using Self\n  Organizing Maps", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.CC cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Physically-based overland flow models are computationally demanding,\nhindering their use for real-time applications. Therefore, the development of\nfast (and reasonably accurate) overland flow models is needed if they are to be\nused to support flood mitigation decision making. In this study, we investigate\nthe potential of Self-Organizing Maps to rapidly generate water depth and flood\nextent results. To conduct the study, we developed a flood-simulation specific\nSOM, using cellular automata flood model results and a synthetic DEM and inflow\nhydrograph. The preliminary results showed that water depth and flood extent\nresults produced by the SOM are reasonably accurate and obtained in a very\nshort period of time. Based on this, it seems that SOMs have the potential to\nprovide critical flood information to support real-time flood mitigation\ndecisions. The findings presented would however require further investigations\nto obtain general conclusions; these further investigations may include the\nconsideration of real terrain representations, real water supply networks and\nrealistic inflows from pipe bursts.\n", "versions": [{"version": "v1", "created": "Sun, 23 Sep 2018 18:54:29 GMT"}], "update_date": "2018-10-08", "authors_parsed": [["Leitao", "Joao P.", ""], ["Zaghloul", "Mohamed", ""], ["Moosavi", "Vahid", ""]]}, {"id": "1810.02716", "submitter": "Shuaiwen Wang", "authors": "Shuaiwen Wang, Wenda Zhou, Arian Maleki, Haihao Lu, Vahab Mirrokni", "title": "Approximate Leave-One-Out for High-Dimensional Non-Differentiable\n  Learning Problems", "comments": "63 pages, 7 figures. arXiv admin note: substantial text overlap with\n  arXiv:1807.02694", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Consider the following class of learning schemes: \\begin{equation}\n\\label{eq:main-problem1}\n  \\hat{\\boldsymbol{\\beta}} := \\underset{\\boldsymbol{\\beta} \\in\n\\mathcal{C}}{\\arg\\min} \\;\\sum_{j=1}^n\n\\ell(\\boldsymbol{x}_j^\\top\\boldsymbol{\\beta}; y_j) + \\lambda\nR(\\boldsymbol{\\beta}), \\qquad \\qquad \\qquad (1) \\end{equation} where\n$\\boldsymbol{x}_i \\in \\mathbb{R}^p$ and $y_i \\in \\mathbb{R}$ denote the $i^{\\rm\nth}$ feature and response variable respectively. Let $\\ell$ and $R$ be the\nconvex loss function and regularizer, $\\boldsymbol{\\beta}$ denote the unknown\nweights, and $\\lambda$ be a regularization parameter. $\\mathcal{C} \\subset\n\\mathbb{R}^{p}$ is a closed convex set. Finding the optimal choice of $\\lambda$\nis a challenging problem in high-dimensional regimes where both $n$ and $p$ are\nlarge. We propose three frameworks to obtain a computationally efficient\napproximation of the leave-one-out cross validation (LOOCV) risk for nonsmooth\nlosses and regularizers. Our three frameworks are based on the primal, dual,\nand proximal formulations of (1). Each framework shows its strength in certain\ntypes of problems. We prove the equivalence of the three approaches under\nsmoothness conditions. This equivalence enables us to justify the accuracy of\nthe three methods under such conditions. We use our approaches to obtain a risk\nestimate for several standard problems, including generalized LASSO, nuclear\nnorm regularization, and support vector machines. We empirically demonstrate\nthe effectiveness of our results for non-differentiable cases.\n", "versions": [{"version": "v1", "created": "Thu, 4 Oct 2018 16:11:27 GMT"}], "update_date": "2018-10-08", "authors_parsed": [["Wang", "Shuaiwen", ""], ["Zhou", "Wenda", ""], ["Maleki", "Arian", ""], ["Lu", "Haihao", ""], ["Mirrokni", "Vahab", ""]]}, {"id": "1810.02757", "submitter": "Alberto Del Pia", "authors": "Alberto Del Pia, Santanu S. Dey, Robert Weismantel", "title": "Subset selection in sparse matrices", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.OC cs.CC cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In subset selection we search for the best linear predictor that involves a\nsmall subset of variables. From a computational complexity viewpoint, subset\nselection is NP-hard and few classes are known to be solvable in polynomial\ntime. Using mainly tools from discrete geometry, we show that some sparsity\nconditions on the original data matrix allow us to solve the problem in\npolynomial time.\n", "versions": [{"version": "v1", "created": "Fri, 5 Oct 2018 15:42:38 GMT"}, {"version": "v2", "created": "Thu, 6 Feb 2020 17:25:01 GMT"}], "update_date": "2020-02-07", "authors_parsed": [["Del Pia", "Alberto", ""], ["Dey", "Santanu S.", ""], ["Weismantel", "Robert", ""]]}, {"id": "1810.02762", "submitter": "Roman Nikiforov", "authors": "Roman Nikiforov", "title": "Clustering-based Anomaly Detection for microservices", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Anomaly detection is an important step in the management and monitoring of\ndata centers and cloud computing platforms. The ability to detect anomalous\nvirtual machines before real failures occur results in reduced downtime while\noperations engineers urgently recover malfunctioning virtual machines,\nefficient root cause analysis, and improved customer optics in the event said\nmalfunction lead to an outage. Virtual machines could fail at any time, whether\nin a lab or production system. If there is no anomaly detection system, and a\nvirtual machine in a lab environment fails, the QA and DEV team will have to\nswitch to another environment while the OPS team fixes the failure. The\npotential impact of failing to detect anomalous virtual machines can result in\nfinancial ramifications, both when developing new features and servicing\nexisting ones. This paper presents a model that can efficiently detect\nanomalous virtual machines both in production and testing environments.\n", "versions": [{"version": "v1", "created": "Thu, 4 Oct 2018 17:12:37 GMT"}], "update_date": "2018-10-08", "authors_parsed": [["Nikiforov", "Roman", ""]]}, {"id": "1810.02766", "submitter": "J\\\"org Wagner", "authors": "J\\\"org Wagner, Volker Fischer, Michael Herman and Sven Behnke", "title": "Hierarchical Recurrent Filtering for Fully Convolutional DenseNets", "comments": "In Proceedings of 26th European Symposium on Artificial Neural\n  Networks, Computational Intelligence and Machine Learning (ESANN), Bruges,\n  Belgium, 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Generating a robust representation of the environment is a crucial ability of\nlearning agents. Deep learning based methods have greatly improved perception\nsystems but still fail in challenging situations. These failures are often not\nsolvable on the basis of a single image. In this work, we present a\nparameter-efficient temporal filtering concept which extends an existing\nsingle-frame segmentation model to work with multiple frames. The resulting\nrecurrent architecture temporally filters representations on all abstraction\nlevels in a hierarchical manner, while decoupling temporal dependencies from\nscene representation. Using a synthetic dataset, we show the ability of our\nmodel to cope with data perturbations and highlight the importance of recurrent\nand hierarchical filtering.\n", "versions": [{"version": "v1", "created": "Fri, 5 Oct 2018 15:54:46 GMT"}, {"version": "v2", "created": "Mon, 15 Oct 2018 16:35:14 GMT"}], "update_date": "2018-10-16", "authors_parsed": [["Wagner", "J\u00f6rg", ""], ["Fischer", "Volker", ""], ["Herman", "Michael", ""], ["Behnke", "Sven", ""]]}, {"id": "1810.02789", "submitter": "Dmitry Molchanov", "authors": "Dmitry Molchanov, Valery Kharitonov, Artem Sobolev, Dmitry Vetrov", "title": "Doubly Semi-Implicit Variational Inference", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We extend the existing framework of semi-implicit variational inference\n(SIVI) and introduce doubly semi-implicit variational inference (DSIVI), a way\nto perform variational inference and learning when both the approximate\nposterior and the prior distribution are semi-implicit. In other words, DSIVI\nperforms inference in models where the prior and the posterior can be expressed\nas an intractable infinite mixture of some analytic density with a highly\nflexible implicit mixing distribution. We provide a sandwich bound on the\nevidence lower bound (ELBO) objective that can be made arbitrarily tight.\nUnlike discriminator-based and kernel-based approaches to implicit variational\ninference, DSIVI optimizes a proper lower bound on ELBO that is asymptotically\nexact. We evaluate DSIVI on a set of problems that benefit from implicit\npriors. In particular, we show that DSIVI gives rise to a simple modification\nof VampPrior, the current state-of-the-art prior for variational autoencoders,\nwhich improves its performance.\n", "versions": [{"version": "v1", "created": "Fri, 5 Oct 2018 16:54:18 GMT"}, {"version": "v2", "created": "Sat, 16 Mar 2019 13:29:11 GMT"}], "update_date": "2019-03-19", "authors_parsed": [["Molchanov", "Dmitry", ""], ["Kharitonov", "Valery", ""], ["Sobolev", "Artem", ""], ["Vetrov", "Dmitry", ""]]}, {"id": "1810.02797", "submitter": "Shiv Ram Dubey", "authors": "S H Shabbeer Basha, Soumen Ghosh, Kancharagunta Kishan Babu, Shiv Ram\n  Dubey, Viswanath Pulabaigari, Snehasis Mukherjee", "title": "RCCNet: An Efficient Convolutional Neural Network for Histological\n  Routine Colon Cancer Nuclei Classification", "comments": "Published in ICARCV 2018", "journal-ref": null, "doi": "10.1109/ICARCV.2018.8581147", "report-no": null, "categories": "cs.CV cs.AI cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Efficient and precise classification of histological cell nuclei is of utmost\nimportance due to its potential applications in the field of medical image\nanalysis. It would facilitate the medical practitioners to better understand\nand explore various factors for cancer treatment. The classification of\nhistological cell nuclei is a challenging task due to the cellular\nheterogeneity. This paper proposes an efficient Convolutional Neural Network\n(CNN) based architecture for classification of histological routine colon\ncancer nuclei named as RCCNet. The main objective of this network is to keep\nthe CNN model as simple as possible. The proposed RCCNet model consists of only\n1,512,868 learnable parameters which are significantly less compared to the\npopular CNN models such as AlexNet, CIFARVGG, GoogLeNet, and WRN. The\nexperiments are conducted over publicly available routine colon cancer\nhistological dataset \"CRCHistoPhenotypes\". The results of the proposed RCCNet\nmodel are compared with five state-of-the-art CNN models in terms of the\naccuracy, weighted average F1 score and training time. The proposed method has\nachieved a classification accuracy of 80.61% and 0.7887 weighted average F1\nscore. The proposed RCCNet is more efficient and generalized terms of the\ntraining time and data over-fitting, respectively.\n", "versions": [{"version": "v1", "created": "Sun, 30 Sep 2018 07:18:58 GMT"}, {"version": "v2", "created": "Sat, 20 Oct 2018 12:09:31 GMT"}, {"version": "v3", "created": "Sat, 8 Jun 2019 05:19:12 GMT"}], "update_date": "2019-11-19", "authors_parsed": [["Basha", "S H Shabbeer", ""], ["Ghosh", "Soumen", ""], ["Babu", "Kancharagunta Kishan", ""], ["Dubey", "Shiv Ram", ""], ["Pulabaigari", "Viswanath", ""], ["Mukherjee", "Snehasis", ""]]}, {"id": "1810.02810", "submitter": "Raef Bassily", "authors": "Raef Bassily", "title": "Linear Queries Estimation with Local Differential Privacy", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the problem of estimating a set of $d$ linear queries with respect\nto some unknown distribution $\\mathbf{p}$ over a domain $\\mathcal{J}=[J]$ based\non a sensitive data set of $n$ individuals under the constraint of local\ndifferential privacy. This problem subsumes a wide range of estimation tasks,\ne.g., distribution estimation and $d$-dimensional mean estimation. We provide\nnew algorithms for both the offline (non-adaptive) and adaptive versions of\nthis problem.\n  In the offline setting, the set of queries are fixed before the algorithm\nstarts. In the regime where $n\\lesssim d^2/\\log(J)$, our algorithms attain\n$L_2$ estimation error that is independent of $d$, and is tight up to a factor\nof $\\tilde{O}\\left(\\log^{1/4}(J)\\right)$. For the special case of distribution\nestimation, we show that projecting the output estimate of an algorithm due to\n[Acharya et al. 2018] on the probability simplex yields an $L_2$ error that\ndepends only sub-logarithmically on $J$ in the regime where $n\\lesssim\nJ^2/\\log(J)$. These results show the possibility of accurate estimation of\nlinear queries in the high-dimensional settings under the $L_2$ error\ncriterion.\n  In the adaptive setting, the queries are generated over $d$ rounds; one query\nat a time. In each round, a query can be chosen adaptively based on all the\nhistory of previous queries and answers. We give an algorithm for this problem\nwith optimal $L_{\\infty}$ estimation error (worst error in the estimated values\nfor the queries w.r.t. the data distribution). Our bound matches a lower bound\non the $L_{\\infty}$ error for the offline version of this problem [Duchi et al.\n2013].\n", "versions": [{"version": "v1", "created": "Fri, 5 Oct 2018 17:59:25 GMT"}], "update_date": "2018-10-08", "authors_parsed": [["Bassily", "Raef", ""]]}, {"id": "1810.02812", "submitter": "Tiep H. Vu", "authors": "Tiep Vu, Lam Nguyen, Vishal Monga", "title": "Classifying Multi-channel UWB SAR Imagery via Tensor Sparsity Learning\n  Techniques", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.SP cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Using low-frequency (UHF to L-band) ultra-wideband (UWB) synthetic aperture\nradar (SAR) technology for detecting buried and obscured targets, e.g. bomb or\nmine, has been successfully demonstrated recently. Despite promising recent\nprogress, a significant open challenge is to distinguish obscured targets from\nother (natural and manmade) clutter sources in the scene. The problem becomes\nexacerbated in the presence of noisy responses from rough ground surfaces. In\nthis paper, we present three novel sparsity-driven techniques, which not only\nexploit the subtle features of raw captured data but also take advantage of the\npolarization diversity and the aspect angle dependence information from\nmulti-channel SAR data. First, the traditional sparse representation-based\nclassification (SRC) is generalized to exploit shared information of classes\nand various sparsity structures of tensor coefficients for multi-channel data.\nCorresponding tensor dictionary learning models are consequently proposed to\nenhance classification accuracy. Lastly, a new tensor sparsity model is\nproposed to model responses from multiple consecutive looks of objects, which\nis a unique characteristic of the dataset we consider. Extensive experimental\nresults on a high-fidelity electromagnetic simulated dataset and radar data\ncollected from the U.S. Army Research Laboratory side-looking SAR demonstrate\nthe advantages of proposed tensor sparsity models.\n", "versions": [{"version": "v1", "created": "Thu, 4 Oct 2018 22:28:44 GMT"}], "update_date": "2018-10-09", "authors_parsed": [["Vu", "Tiep", ""], ["Nguyen", "Lam", ""], ["Monga", "Vishal", ""]]}, {"id": "1810.02814", "submitter": "Guang Cheng", "authors": "Yue Xing, Qifan Song, Guang Cheng", "title": "Statistical Optimality of Interpolated Nearest Neighbor Algorithms", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In the era of deep learning, understanding over-fitting phenomenon becomes\nincreasingly important. It is observed that carefully designed deep neural\nnetworks achieve small testing error even when the training error is close to\nzero. One possible explanation is that for many modern machine learning\nalgorithms, over-fitting can greatly reduce the estimation bias, while not\nincreasing the estimation variance too much. To illustrate the above idea, we\nprove that the proposed interpolated nearest neighbor algorithm achieves the\nminimax optimal rate in both regression and classification regimes, and observe\nthat they are empirically better than the traditional $k$ nearest neighbor\nmethod in some cases.\n", "versions": [{"version": "v1", "created": "Fri, 5 Oct 2018 03:15:16 GMT"}, {"version": "v2", "created": "Fri, 30 Nov 2018 20:17:12 GMT"}], "update_date": "2018-12-04", "authors_parsed": [["Xing", "Yue", ""], ["Song", "Qifan", ""], ["Cheng", "Guang", ""]]}, {"id": "1810.02832", "submitter": "Huaizheng Zhang", "authors": "Yong Luo, Huaizheng Zhang, Yongjie Wang, Yonggang We, Xinwen Zhang", "title": "ResumeNet: A Learning-based Framework for Automatic Resume Quality\n  Assessment", "comments": "ICDM", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recruitment of appropriate people for certain positions is critical for any\ncompanies or organizations. Manually screening to select appropriate candidates\nfrom large amounts of resumes can be exhausted and time-consuming. However,\nthere is no public tool that can be directly used for automatic resume quality\nassessment (RQA). This motivates us to develop a method for automatic RQA.\nSince there is also no public dataset for model training and evaluation, we\nbuild a dataset for RQA by collecting around 10K resumes, which are provided by\na private resume management company. By investigating the dataset, we identify\nsome factors or features that could be useful to discriminate good resumes from\nbad ones, e.g., the consistency between different parts of a resume. Then a\nneural-network model is designed to predict the quality of each resume, where\nsome text processing techniques are incorporated. To deal with the label\ndeficiency issue in the dataset, we propose several variants of the model by\neither utilizing the pair/triplet-based loss, or introducing some\nsemi-supervised learning technique to make use of the abundant unlabeled data.\nBoth the presented baseline model and its variants are general and easy to\nimplement. Various popular criteria including the receiver operating\ncharacteristic (ROC) curve, F-measure and ranking-based average precision (AP)\nare adopted for model evaluation. We compare the different variants with our\nbaseline model. Since there is no public algorithm for RQA, we further compare\nour results with those obtained from a website that can score a resume.\nExperimental results in terms of different criteria demonstrate the\neffectiveness of the proposed method. We foresee that our approach would\ntransform the way of future human resources management.\n", "versions": [{"version": "v1", "created": "Fri, 5 Oct 2018 18:02:19 GMT"}], "update_date": "2018-10-09", "authors_parsed": [["Luo", "Yong", ""], ["Zhang", "Huaizheng", ""], ["Wang", "Yongjie", ""], ["We", "Yonggang", ""], ["Zhang", "Xinwen", ""]]}, {"id": "1810.02837", "submitter": "Arun Sathanur", "authors": "Arun V Sathanur", "title": "Scaling Submodular Optimization Approaches for Control Applications in\n  Networked Systems", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Often times, in many design problems, there is a need to select a small set\nof informative or representative elements from a large ground set of entities\nin an optimal fashion. Submodular optimization that provides for a formal way\nto solve such problems, has recently received significant attention from the\ncontrols community where such subset selection problems are abound. However,\nscaling these approaches to large systems can be challenging because of the\nhigh computational complexity of the overall flow, in-part due to the\nhigh-complexity compute-oracles used to determine the objective function\nvalues. In this work, we explore a well-known paradigm, namely leader-selection\nin a multi-agent networked environment to illustrate strategies for scalable\nsubmodular optimization. We study the performance of the state-of-the-art\nstochastic and distributed greedy algorithms as well as explore techniques that\naccelerate the computation oracles within the optimization loop. We finally\npresent results combining accelerated greedy algorithms with accelerated\ncomputation oracles and demonstrate significant speedups with little loss of\noptimality when compared to the baseline ordinary greedy algorithm.\n", "versions": [{"version": "v1", "created": "Fri, 5 Oct 2018 18:12:06 GMT"}], "update_date": "2018-10-09", "authors_parsed": [["Sathanur", "Arun V", ""]]}, {"id": "1810.02840", "submitter": "Alexander Ratner", "authors": "Alexander Ratner, Braden Hancock, Jared Dunnmon, Frederic Sala,\n  Shreyash Pandey, Christopher R\\'e", "title": "Training Complex Models with Multi-Task Weak Supervision", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  As machine learning models continue to increase in complexity, collecting\nlarge hand-labeled training sets has become one of the biggest roadblocks in\npractice. Instead, weaker forms of supervision that provide noisier but cheaper\nlabels are often used. However, these weak supervision sources have diverse and\nunknown accuracies, may output correlated labels, and may label different tasks\nor apply at different levels of granularity. We propose a framework for\nintegrating and modeling such weak supervision sources by viewing them as\nlabeling different related sub-tasks of a problem, which we refer to as the\nmulti-task weak supervision setting. We show that by solving a matrix\ncompletion-style problem, we can recover the accuracies of these multi-task\nsources given their dependency structure, but without any labeled data, leading\nto higher-quality supervision for training an end model. Theoretically, we show\nthat the generalization error of models trained with this approach improves\nwith the number of unlabeled data points, and characterize the scaling with\nrespect to the task and dependency structures. On three fine-grained\nclassification problems, we show that our approach leads to average gains of\n20.2 points in accuracy over a traditional supervised approach, 6.8 points over\na majority vote baseline, and 4.1 points over a previously proposed weak\nsupervision method that models tasks separately.\n", "versions": [{"version": "v1", "created": "Fri, 5 Oct 2018 18:30:11 GMT"}, {"version": "v2", "created": "Fri, 7 Dec 2018 18:31:48 GMT"}], "update_date": "2018-12-10", "authors_parsed": [["Ratner", "Alexander", ""], ["Hancock", "Braden", ""], ["Dunnmon", "Jared", ""], ["Sala", "Frederic", ""], ["Pandey", "Shreyash", ""], ["R\u00e9", "Christopher", ""]]}, {"id": "1810.02842", "submitter": "Kuan-Jung Chiang", "authors": "Kuan-Jung Chiang, Chun-Shu Wei, Masaki Nakanishi, and Tzyy-Ping Jung", "title": "Cross-Subject Transfer Learning Improves the Practicality of Real-World\n  Applications of Brain-Computer Interfaces", "comments": "4 pages, 3 figures, 1 table. For NER'19", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.NC cs.HC cs.LG eess.SP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Steady-state visual evoked potential (SSVEP)-based brain-computer interfaces\n(BCIs) have shown its robustness in facilitating high-efficiency communication.\nState-of-the-art training-based SSVEP decoding methods such as extended\nCanonical Correlation Analysis (CCA) and Task-Related Component Analysis (TRCA)\nare the major players that elevate the efficiency of the SSVEP-based BCIs\nthrough a calibration process. However, due to notable human variability across\nindividuals and within individuals over time, calibration (training) data\ncollection is non-negligible and often laborious and time-consuming,\ndeteriorating the practicality of SSVEP BCIs in a real-world context. This\nstudy aims to develop a cross-subject transferring approach to reduce the need\nfor collecting training data from a test user with a newly proposed\nleast-squares transformation (LST) method. Study results show the capability of\nthe LST in reducing the number of training templates required for a 40-class\nSSVEP BCI. The LST method may lead to numerous real-world applications using\nnear-zero-training/plug-and-play high-speed SSVEP BCIs.\n", "versions": [{"version": "v1", "created": "Fri, 5 Oct 2018 18:33:54 GMT"}, {"version": "v2", "created": "Tue, 30 Oct 2018 22:32:08 GMT"}, {"version": "v3", "created": "Sat, 3 Nov 2018 05:16:51 GMT"}, {"version": "v4", "created": "Wed, 13 Mar 2019 21:14:29 GMT"}], "update_date": "2021-02-11", "authors_parsed": [["Chiang", "Kuan-Jung", ""], ["Wei", "Chun-Shu", ""], ["Nakanishi", "Masaki", ""], ["Jung", "Tzyy-Ping", ""]]}, {"id": "1810.02845", "submitter": "Salvator Lombardo", "authors": "Jun Han, Salvator Lombardo, Christopher Schroers, Stephan Mandt", "title": "Deep Generative Video Compression", "comments": "Accepted at NeurIPS 2019, 15 pages, 8 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG eess.IV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The usage of deep generative models for image compression has led to\nimpressive performance gains over classical codecs while neural video\ncompression is still in its infancy. Here, we propose an end-to-end, deep\ngenerative modeling approach to compress temporal sequences with a focus on\nvideo. Our approach builds upon variational autoencoder (VAE) models for\nsequential data and combines them with recent work on neural image compression.\nThe approach jointly learns to transform the original sequence into a\nlower-dimensional representation as well as to discretize and entropy code this\nrepresentation according to predictions of the sequential VAE. Rate-distortion\nevaluations on small videos from public data sets with varying complexity and\ndiversity show that our model yields competitive results when trained on\ngeneric video content. Extreme compression performance is achieved when\ntraining the model on specialized content.\n", "versions": [{"version": "v1", "created": "Fri, 5 Oct 2018 18:42:02 GMT"}, {"version": "v2", "created": "Fri, 1 Nov 2019 22:48:14 GMT"}], "update_date": "2019-11-05", "authors_parsed": [["Han", "Jun", ""], ["Lombardo", "Salvator", ""], ["Schroers", "Christopher", ""], ["Mandt", "Stephan", ""]]}, {"id": "1810.02866", "submitter": "Rozhin Eskandarpour", "authors": "Rozhin Eskandarpour, Amin Khodaei, A. Paaso, N. M. Abdullah", "title": "Artificial Intelligence Assisted Power Grid Hardening in Response to\n  Extreme Weather Events", "comments": null, "journal-ref": "2018 Grid of the Future Symposium", "doi": null, "report-no": null, "categories": "eess.SP cs.LG cs.SY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, an artificial intelligence based grid hardening model is\nproposed with the objective of improving power grid resilience in response to\nextreme weather events. At first, a machine learning model is proposed to\npredict the component states (either operational or outage) in response to the\nextreme event. Then, these predictions are fed into a hardening model, which\ndetermines strategic locations for placement of distributed generation (DG)\nunits. In contrast to existing literature in hardening and resilience\nenhancement, this paper co-optimizes grid economic and resilience objectives by\nconsidering the intricate dependencies of the two. The numerical simulations on\nthe standard IEEE 118-bus test system illustrate the merits and applicability\nof the proposed hardening model. The results indicate that the proposed\nhardening model through decentralized and distributed local energy resources\ncan produce a more robust solution that can protect the system significantly\nagainst multiple component outages due to an extreme event.\n", "versions": [{"version": "v1", "created": "Fri, 5 Oct 2018 19:54:58 GMT"}], "update_date": "2018-10-09", "authors_parsed": [["Eskandarpour", "Rozhin", ""], ["Khodaei", "Amin", ""], ["Paaso", "A.", ""], ["Abdullah", "N. M.", ""]]}, {"id": "1810.02876", "submitter": "Onur Atan", "authors": "Onur Atan, William R. Zame, Mihaela van der Schaar", "title": "Adaptive Clinical Trials: Exploiting Sequential Patient Recruitment and\n  Allocation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Randomized Controlled Trials (RCTs) are the gold standard for comparing the\neffectiveness of a new treatment to the current one (the control). Most RCTs\nallocate the patients to the treatment group and the control group by uniform\nrandomization. We show that this procedure can be highly sub-optimal (in terms\nof learning) if -- as is often the case -- patients can be recruited in cohorts\n(rather than all at once), the effects on each cohort can be observed before\nrecruiting the next cohort, and the effects are heterogeneous across\nidentifiable subgroups of patients. We formulate the patient allocation problem\nas a finite stage Markov Decision Process in which the objective is to minimize\na given weighted combination of type-I and type-II errors. Because finding the\nexact solution to this Markov Decision Process is computationally intractable,\nwe propose an algorithm -- \\textit{Knowledge Gradient for Randomized Controlled\nTrials} (RCT-KG) -- that yields an approximate solution. We illustrate our\nalgorithm on a synthetic dataset with Bernoulli outcomes and compare it with\nuniform randomization. For a given size of trial our method achieves\nsignificant reduction in error, and to achieve a prescribed level of confidence\n(in identifying whether the treatment is superior to the control), our method\nrequires many fewer patients. Our approach uses what has been learned from the\neffects on previous cohorts to recruit patients to subgroups and allocate\npatients (to treatment/control) within subgroups in a way that promotes more\nefficient learning.\n", "versions": [{"version": "v1", "created": "Fri, 5 Oct 2018 20:19:33 GMT"}, {"version": "v2", "created": "Thu, 18 Oct 2018 18:38:42 GMT"}], "update_date": "2018-10-22", "authors_parsed": [["Atan", "Onur", ""], ["Zame", "William R.", ""], ["van der Schaar", "Mihaela", ""]]}, {"id": "1810.02880", "submitter": "Jared Willard", "authors": "Xiaowei Jia, Anuj Karpatne, Jared Willard, Michael Steinbach, Jordan\n  Read, Paul C Hanson, Hilary A Dugan, Vipin Kumar", "title": "Physics Guided Recurrent Neural Networks For Modeling Dynamical Systems:\n  Application to Monitoring Water Temperature And Quality In Lakes", "comments": "3 pages, 3 figures, 8th International Workshop on Climate Informatics", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we introduce a novel framework for combining scientific\nknowledge within physics-based models and recurrent neural networks to advance\nscientific discovery in many dynamical systems. We will first describe the use\nof outputs from physics-based models in learning a hybrid-physics-data model.\nThen, we further incorporate physical knowledge in real-world dynamical systems\nas additional constraints for training recurrent neural networks. We will apply\nthis approach on modeling lake temperature and quality where we take into\naccount the physical constraints along both the depth dimension and time\ndimension. By using scientific knowledge to guide the construction and learning\nthe data-driven model, we demonstrate that this method can achieve better\nprediction accuracy as well as scientific consistency of results.\n", "versions": [{"version": "v1", "created": "Fri, 5 Oct 2018 20:40:02 GMT"}], "update_date": "2018-10-09", "authors_parsed": [["Jia", "Xiaowei", ""], ["Karpatne", "Anuj", ""], ["Willard", "Jared", ""], ["Steinbach", "Michael", ""], ["Read", "Jordan", ""], ["Hanson", "Paul C", ""], ["Dugan", "Hilary A", ""], ["Kumar", "Vipin", ""]]}, {"id": "1810.02894", "submitter": "Nathan Kallus", "authors": "Nathan Kallus, Xiaojie Mao, Angela Zhou", "title": "Interval Estimation of Individual-Level Causal Effects Under Unobserved\n  Confounding", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the problem of learning conditional average treatment effects (CATE)\nfrom observational data with unobserved confounders. The CATE function maps\nbaseline covariates to individual causal effect predictions and is key for\npersonalized assessments. Recent work has focused on how to learn CATE under\nunconfoundedness, i.e., when there are no unobserved confounders. Since CATE\nmay not be identified when unconfoundedness is violated, we develop a\nfunctional interval estimator that predicts bounds on the individual causal\neffects under realistic violations of unconfoundedness. Our estimator takes the\nform of a weighted kernel estimator with weights that vary adversarially. We\nprove that our estimator is sharp in that it converges exactly to the tightest\nbounds possible on CATE when there may be unobserved confounders. Further, we\nstudy personalized decision rules derived from our estimator and prove that\nthey achieve optimal minimax regret asymptotically. We assess our approach in a\nsimulation study as well as demonstrate its application in the case of hormone\nreplacement therapy by comparing conclusions from a real observational study\nand clinical trial.\n", "versions": [{"version": "v1", "created": "Fri, 5 Oct 2018 21:42:40 GMT"}], "update_date": "2018-10-09", "authors_parsed": [["Kallus", "Nathan", ""], ["Mao", "Xiaojie", ""], ["Zhou", "Angela", ""]]}, {"id": "1810.02897", "submitter": "Ye Zhu PhD", "authors": "Ye Zhu, Kai Ming Ting, Mark Carman, Maia Angelova", "title": "CDF Transform-and-Shift: An effective way to deal with datasets of\n  inhomogeneous cluster densities", "comments": "Pattern Recognition (2021)", "journal-ref": null, "doi": "10.1016/j.patcog.2021.107977", "report-no": null, "categories": "cs.LG cs.AI cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The problem of inhomogeneous cluster densities has been a long-standing issue\nfor distance-based and density-based algorithms in clustering and anomaly\ndetection. These algorithms implicitly assume that all clusters have\napproximately the same density. As a result, they often exhibit a bias towards\ndense clusters in the presence of sparse clusters. Many remedies have been\nsuggested; yet, we show that they are partial solutions which do not address\nthe issue satisfactorily. To match the implicit assumption, we propose to\ntransform a given dataset such that the transformed clusters have approximately\nthe same density while all regions of locally low density become globally low\ndensity -- homogenising cluster density while preserving the cluster structure\nof the dataset. We show that this can be achieved by using a new\nmulti-dimensional Cumulative Distribution Function in a transform-and-shift\nmethod. The method can be applied to every dataset, before the dataset is used\nin many existing algorithms to match their implicit assumption without\nalgorithmic modification. We show that the proposed method performs better than\nexisting remedies.\n", "versions": [{"version": "v1", "created": "Fri, 5 Oct 2018 22:32:51 GMT"}, {"version": "v2", "created": "Thu, 1 Apr 2021 08:53:59 GMT"}, {"version": "v3", "created": "Mon, 12 Apr 2021 04:27:35 GMT"}], "update_date": "2021-04-13", "authors_parsed": [["Zhu", "Ye", ""], ["Ting", "Kai Ming", ""], ["Carman", "Mark", ""], ["Angelova", "Maia", ""]]}, {"id": "1810.02906", "submitter": "Dianbin Bao", "authors": "Dianbin Bao, Kisung You and Lizhen Lin", "title": "Network Distance Based on Laplacian Flows on Graphs", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Distance plays a fundamental role in measuring similarity between objects.\nVarious visualization techniques and learning tasks in statistics and machine\nlearning such as shape matching, classification, dimension reduction and\nclustering often rely on some distance or similarity measure. It is of\ntremendous importance to have a distance that can incorporate the underlying\nstructure of the object. In this paper, we focus on proposing such a distance\nbetween network objects. Our key insight is to define a distance based on the\nlong term diffusion behavior of the whole network. We first introduce a dynamic\nsystem on graphs called Laplacian flow. Based on this Laplacian flow, a new\nversion of diffusion distance between networks is proposed. We will demonstrate\nthe utility of the distance and its advantage over various existing distances\nthrough explicit examples. The distance is also applied to subsequent learning\ntasks such as clustering network objects.\n", "versions": [{"version": "v1", "created": "Fri, 5 Oct 2018 23:15:24 GMT"}], "update_date": "2018-10-09", "authors_parsed": [["Bao", "Dianbin", ""], ["You", "Kisung", ""], ["Lin", "Lizhen", ""]]}, {"id": "1810.02909", "submitter": "Patrick Hall", "authors": "Patrick Hall", "title": "On the Art and Science of Machine Learning Explanations", "comments": "This manuscript is a preprint of the text for an invited talk at the\n  2019 KDD XAI workshop. A previous version has also appeared in the\n  proceedings of the Joint Statistical Meetings. Errata and updates available\n  here: https://github.com/jphall663/kdd_2019. Version 2 incorporated reviewer\n  feedback. Version 3 includes a minor adjustment to Figure 1. Version 4\n  corrects a minor typo", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This text discusses several popular explanatory methods that go beyond the\nerror measurements and plots traditionally used to assess machine learning\nmodels. Some of the explanatory methods are accepted tools of the trade while\nothers are rigorously derived and backed by long-standing theory. The methods,\ndecision tree surrogate models, individual conditional expectation (ICE) plots,\nlocal interpretable model-agnostic explanations (LIME), partial dependence\nplots, and Shapley explanations, vary in terms of scope, fidelity, and suitable\napplication domain. Along with descriptions of these methods, this text\npresents real-world usage recommendations supported by a use case and public,\nin-depth software examples for reproducibility.\n", "versions": [{"version": "v1", "created": "Fri, 5 Oct 2018 23:29:55 GMT"}, {"version": "v2", "created": "Tue, 28 May 2019 16:42:11 GMT"}, {"version": "v3", "created": "Fri, 2 Aug 2019 13:37:37 GMT"}, {"version": "v4", "created": "Sun, 31 May 2020 15:09:09 GMT"}], "update_date": "2020-06-02", "authors_parsed": [["Hall", "Patrick", ""]]}, {"id": "1810.02912", "submitter": "Shariq Iqbal", "authors": "Shariq Iqbal, Fei Sha", "title": "Actor-Attention-Critic for Multi-Agent Reinforcement Learning", "comments": "ICML 2019 camera ready version", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.MA stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Reinforcement learning in multi-agent scenarios is important for real-world\napplications but presents challenges beyond those seen in single-agent\nsettings. We present an actor-critic algorithm that trains decentralized\npolicies in multi-agent settings, using centrally computed critics that share\nan attention mechanism which selects relevant information for each agent at\nevery timestep. This attention mechanism enables more effective and scalable\nlearning in complex multi-agent environments, when compared to recent\napproaches. Our approach is applicable not only to cooperative settings with\nshared rewards, but also individualized reward settings, including adversarial\nsettings, as well as settings that do not provide global states, and it makes\nno assumptions about the action spaces of the agents. As such, it is flexible\nenough to be applied to most multi-agent learning problems.\n", "versions": [{"version": "v1", "created": "Fri, 5 Oct 2018 23:45:14 GMT"}, {"version": "v2", "created": "Mon, 27 May 2019 23:28:13 GMT"}], "update_date": "2019-05-29", "authors_parsed": [["Iqbal", "Shariq", ""], ["Sha", "Fei", ""]]}, {"id": "1810.02923", "submitter": "Baihan Lin", "authors": "Baihan Lin, Nikolaus Kriegeskorte", "title": "Adaptive Geo-Topological Independence Criterion", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.AI cs.LG math.ST q-bio.NC stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Testing two potentially multivariate variables for statistical dependence on\nthe basis finite samples is a fundamental statistical challenge. Here we\nexplore a family of tests that adapt to the complexity of the relationship\nbetween the variables, promising robust power across scenarios. Building on the\ndistance correlation, we introduce a family of adaptive independence criteria\nbased on nonlinear monotonic transformations of distances. We show that these\ncriteria, like the distance correlation and RKHS-based criteria, provide\ndependence indicators. We propose a class of adaptive (multi-threshold) test\nstatistics, which form the basis for permutation tests. These tests empirically\noutperform some of the established tests in average and worst-case statistical\nsensitivity across a range of univariate and multivariate relationships, offer\nuseful insights to the data and may deserve further exploration.\n", "versions": [{"version": "v1", "created": "Sat, 6 Oct 2018 02:12:21 GMT"}, {"version": "v2", "created": "Wed, 9 Oct 2019 08:21:04 GMT"}, {"version": "v3", "created": "Sun, 7 Jun 2020 07:14:42 GMT"}, {"version": "v4", "created": "Tue, 9 Jun 2020 05:18:55 GMT"}, {"version": "v5", "created": "Thu, 18 Jun 2020 01:30:58 GMT"}, {"version": "v6", "created": "Thu, 22 Oct 2020 03:44:58 GMT"}], "update_date": "2020-10-23", "authors_parsed": [["Lin", "Baihan", ""], ["Kriegeskorte", "Nikolaus", ""]]}, {"id": "1810.02927", "submitter": "Fabio Pardo", "authors": "Fabio Pardo, Vitaly Levdik, Petar Kormushev", "title": "Scaling All-Goals Updates in Reinforcement Learning Using Convolutional\n  Neural Networks", "comments": "AAAI 2020, https://sites.google.com/view/q-map-rl", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Being able to reach any desired location in the environment can be a valuable\nasset for an agent. Learning a policy to navigate between all pairs of states\nindividually is often not feasible. An all-goals updating algorithm uses each\ntransition to learn Q-values towards all goals simultaneously and off-policy.\nHowever the expensive numerous updates in parallel limited the approach to\nsmall tabular cases so far. To tackle this problem we propose to use\nconvolutional network architectures to generate Q-values and updates for a\nlarge number of goals at once. We demonstrate the accuracy and generalization\nqualities of the proposed method on randomly generated mazes and Sokoban\npuzzles. In the case of on-screen goal coordinates the resulting mapping from\nframes to distance-maps directly informs the agent about which places are\nreachable and in how many steps. As an example of application we show that\nreplacing the random actions in epsilon-greedy exploration by several actions\ntowards feasible goals generates better exploratory trajectories on Montezuma's\nRevenge and Super Mario All-Stars games.\n", "versions": [{"version": "v1", "created": "Sat, 6 Oct 2018 03:26:43 GMT"}, {"version": "v2", "created": "Tue, 4 Feb 2020 19:54:40 GMT"}], "update_date": "2020-02-06", "authors_parsed": [["Pardo", "Fabio", ""], ["Levdik", "Vitaly", ""], ["Kormushev", "Petar", ""]]}, {"id": "1810.02950", "submitter": "Saurabh Agrawal", "authors": "Saurabh Agrawal, Michael Steinbach, Daniel Boley, Snigdhansu\n  Chatterjee, Gowtham Atluri, Anh The Dang, Stefan Liess, Vipin Kumar", "title": "Mining Novel Multivariate Relationships in Time Series Data Using\n  Correlation Networks", "comments": "This is the accepted version of article submitted to IEEE\n  Transactions on Knowledge and Data Engineering 2019", "journal-ref": null, "doi": "10.1109/TKDE.2019.2911681", "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In many domains, there is significant interest in capturing novel\nrelationships between time series that represent activities recorded at\ndifferent nodes of a highly complex system. In this paper, we introduce\nmultipoles, a novel class of linear relationships between more than two time\nseries. A multipole is a set of time series that have strong linear dependence\namong themselves, with the requirement that each time series makes a\nsignificant contribution to the linear dependence. We demonstrate that most\ninteresting multipoles can be identified as cliques of negative correlations in\na correlation network. Such cliques are typically rare in a real-world\ncorrelation network, which allows us to find almost all multipoles efficiently\nusing a clique-enumeration approach. Using our proposed framework, we\ndemonstrate the utility of multipoles in discovering new physical phenomena in\ntwo scientific domains: climate science and neuroscience. In particular, we\ndiscovered several multipole relationships that are reproducible in multiple\nother independent datasets and lead to novel domain insights.\n", "versions": [{"version": "v1", "created": "Sat, 6 Oct 2018 07:46:03 GMT"}, {"version": "v2", "created": "Tue, 23 Apr 2019 08:46:48 GMT"}], "update_date": "2019-04-24", "authors_parsed": [["Agrawal", "Saurabh", ""], ["Steinbach", "Michael", ""], ["Boley", "Daniel", ""], ["Chatterjee", "Snigdhansu", ""], ["Atluri", "Gowtham", ""], ["Dang", "Anh The", ""], ["Liess", "Stefan", ""], ["Kumar", "Vipin", ""]]}, {"id": "1810.02959", "submitter": "Ryan Rossi", "authors": "Aldo G. Carranza, Ryan A. Rossi, Anup Rao, Eunyee Koh", "title": "Higher-order Spectral Clustering for Heterogeneous Graphs", "comments": null, "journal-ref": null, "doi": "10.1145/3394486.3403045", "report-no": null, "categories": "cs.SI cs.LG math.SP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Higher-order connectivity patterns such as small induced sub-graphs called\ngraphlets (network motifs) are vital to understand the important components\n(modules/functional units) governing the configuration and behavior of complex\nnetworks. Existing work in higher-order clustering has focused on simple\nhomogeneous graphs with a single node/edge type. However, heterogeneous graphs\nconsisting of nodes and edges of different types are seemingly ubiquitous in\nthe real-world. In this work, we introduce the notion of typed-graphlet that\nexplicitly captures the rich (typed) connectivity patterns in heterogeneous\nnetworks. Using typed-graphlets as a basis, we develop a general principled\nframework for higher-order clustering in heterogeneous networks. The framework\nprovides mathematical guarantees on the optimality of the higher-order\nclustering obtained. The experiments demonstrate the effectiveness of the\nframework quantitatively for three important applications including (i)\nclustering, (ii) link prediction, and (iii) graph compression. In particular,\nthe approach achieves a mean improvement of 43x over all methods and graphs for\nclustering while achieving a 18.7% and 20.8% improvement for link prediction\nand graph compression, respectively.\n", "versions": [{"version": "v1", "created": "Sat, 6 Oct 2018 08:34:07 GMT"}], "update_date": "2020-09-15", "authors_parsed": [["Carranza", "Aldo G.", ""], ["Rossi", "Ryan A.", ""], ["Rao", "Anup", ""], ["Koh", "Eunyee", ""]]}, {"id": "1810.02966", "submitter": "Abhijit Mahalunkar", "authors": "Abhijit Mahalunkar and John D. Kelleher", "title": "Understanding Recurrent Neural Architectures by Analyzing and\n  Synthesizing Long Distance Dependencies in Benchmark Sequential Datasets", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  In order to build efficient deep recurrent neural architectures, it is\nessential to analyze the complexityof long distance dependencies (LDDs) of the\ndataset being modeled. In this paper, we presentdetailed analysis of the\ndependency decay curve exhibited by various datasets. The datasets sampledfrom\na similar process (e.g. natural language, sequential MNIST, Strictlyk-Piecewise\nlanguages,etc) display variations in the properties of the dependency decay\ncurve. Our analysis reveal thefactors resulting in these variations; such as\n(i) number of unique symbols in a dataset, (ii) size ofthe dataset, (iii)\nnumber of interacting symbols within a given LDD, and (iv) the distance\nbetweenthe interacting symbols. We test these factors by generating synthesized\ndatasets of the Strictlyk-Piecewise languages. Another advantage of these\nsynthesized datasets is that they enable targetedtesting of deep recurrent\nneural architectures in terms of their ability to model LDDs with\ndifferentcharacteristics. We also demonstrate that analysing dependency decay\ncurves can inform the selectionof optimal hyper-parameters for SOTA deep\nrecurrent neural architectures. This analysis can directlycontribute to the\ndevelopment of more accurate and efficient sequential models.\n", "versions": [{"version": "v1", "created": "Sat, 6 Oct 2018 09:09:06 GMT"}, {"version": "v2", "created": "Fri, 19 Oct 2018 00:38:36 GMT"}, {"version": "v3", "created": "Wed, 5 Jun 2019 22:10:34 GMT"}, {"version": "v4", "created": "Tue, 8 Dec 2020 18:37:41 GMT"}], "update_date": "2020-12-09", "authors_parsed": [["Mahalunkar", "Abhijit", ""], ["Kelleher", "John D.", ""]]}, {"id": "1810.02976", "submitter": "Nuwan Ferdinand", "authors": "Nuwan Ferdinand and Stark Draper", "title": "Anytime Stochastic Gradient Descent: A Time to Hear from all the Workers", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.IT math.IT stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we focus on approaches to parallelizing stochastic gradient\ndescent (SGD) wherein data is farmed out to a set of workers, the results of\nwhich, after a number of updates, are then combined at a central master node.\nAlthough such synchronized SGD approaches parallelize well in idealized\ncomputing environments, they often fail to realize their promised computational\nacceleration in practical settings. One cause is slow workers, termed\nstragglers, who can cause the fusion step at the master node to stall, which\ngreatly slowing convergence. In many straggler mitigation approaches work\ncompleted by these nodes, while only partial, is discarded completely. In this\npaper, we propose an approach to parallelizing synchronous SGD that exploits\nthe work completed by all workers. The central idea is to fix the computation\ntime of each worker and then to combine distinct contributions of all workers.\nWe provide a convergence analysis and optimize the combination function. Our\nnumerical results demonstrate an improvement of several factors of magnitude in\ncomparison to existing methods.\n", "versions": [{"version": "v1", "created": "Sat, 6 Oct 2018 10:44:59 GMT"}], "update_date": "2018-10-09", "authors_parsed": [["Ferdinand", "Nuwan", ""], ["Draper", "Stark", ""]]}, {"id": "1810.02981", "submitter": "Ruslan Dautov", "authors": "Artur Kuzin, Artur Fattakhov, Ilya Kibardin, Vladimir Iglovikov,\n  Ruslan Dautov", "title": "Camera Model Identification Using Convolutional Neural Networks", "comments": "5 pages, 2 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Source camera identification is the process of determining which camera or\nmodel has been used to capture an image. In the recent years, there has been a\nrapid growth of research interest in the domain of forensics. In the current\nwork, we describe our Deep Learning approach to the camera detection task of 10\ncameras as a part of the Camera Model Identification Challenge hosted by\nKaggle.com where our team finished 2nd out of 582 teams with the accuracy on\nthe unseen data of 98%. We used aggressive data augmentations that allowed a\nmodel to stay robust against transformations. A number of experiments are\ncarried out on datasets collected by organizers and scraped from the web.\n", "versions": [{"version": "v1", "created": "Sat, 6 Oct 2018 11:11:31 GMT"}, {"version": "v2", "created": "Sun, 9 Dec 2018 07:47:43 GMT"}], "update_date": "2018-12-11", "authors_parsed": [["Kuzin", "Artur", ""], ["Fattakhov", "Artur", ""], ["Kibardin", "Ilya", ""], ["Iglovikov", "Vladimir", ""], ["Dautov", "Ruslan", ""]]}, {"id": "1810.03023", "submitter": "Devansh Arpit", "authors": "Devansh Arpit, Bhargav Kanuparthi, Giancarlo Kerg, Nan Rosemary Ke,\n  Ioannis Mitliagkas, Yoshua Bengio", "title": "h-detach: Modifying the LSTM Gradient Towards Better Optimization", "comments": "First two authors contributed equally. Published in ICLR 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recurrent neural networks are known for their notorious exploding and\nvanishing gradient problem (EVGP). This problem becomes more evident in tasks\nwhere the information needed to correctly solve them exist over long time\nscales, because EVGP prevents important gradient components from being\nback-propagated adequately over a large number of steps. We introduce a simple\nstochastic algorithm (\\textit{h}-detach) that is specific to LSTM optimization\nand targeted towards addressing this problem. Specifically, we show that when\nthe LSTM weights are large, the gradient components through the linear path\n(cell state) in the LSTM computational graph get suppressed. Based on the\nhypothesis that these components carry information about long term dependencies\n(which we show empirically), their suppression can prevent LSTMs from capturing\nthem. Our algorithm\\footnote{Our code is available at\nhttps://github.com/bhargav104/h-detach.} prevents gradients flowing through\nthis path from getting suppressed, thus allowing the LSTM to capture such\ndependencies better. We show significant improvements over vanilla LSTM\ngradient based training in terms of convergence speed, robustness to seed and\nlearning rate, and generalization using our modification of LSTM gradient on\nvarious benchmark datasets.\n", "versions": [{"version": "v1", "created": "Sat, 6 Oct 2018 16:55:46 GMT"}, {"version": "v2", "created": "Wed, 9 Jan 2019 17:12:59 GMT"}], "update_date": "2019-01-10", "authors_parsed": [["Arpit", "Devansh", ""], ["Kanuparthi", "Bhargav", ""], ["Kerg", "Giancarlo", ""], ["Ke", "Nan Rosemary", ""], ["Mitliagkas", "Ioannis", ""], ["Bengio", "Yoshua", ""]]}, {"id": "1810.03024", "submitter": "Ruihao Zhu", "authors": "Wang Chi Cheung and David Simchi-Levi and Ruihao Zhu", "title": "Learning to Optimize under Non-Stationarity", "comments": "This version fixed an error in the proof of Lemma 1 with Assumption 4\n  of arXiv:2103.05750", "journal-ref": "Proceedings of the 22nd International Conference on Artificial\n  Intelligence and Statistics (AISTATS 2019)", "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce algorithms that achieve state-of-the-art \\emph{dynamic regret}\nbounds for non-stationary linear stochastic bandit setting. It captures natural\napplications such as dynamic pricing and ads allocation in a changing\nenvironment. We show how the difficulty posed by the non-stationarity can be\novercome by a novel marriage between stochastic and adversarial bandits\nlearning algorithms. Defining $d,B_T,$ and $T$ as the problem dimension, the\n\\emph{variation budget}, and the total time horizon, respectively, our main\ncontributions are the tuned Sliding Window UCB (\\texttt{SW-UCB}) algorithm with\noptimal $\\widetilde{O}(d^{2/3}(B_T+1)^{1/3}T^{2/3})$ dynamic regret, and the\ntuning free bandit-over-bandit (\\texttt{BOB}) framework built on top of the\n\\texttt{SW-UCB} algorithm with best\n$\\widetilde{O}(d^{2/3}(B_T+1)^{1/4}T^{3/4})$ dynamic regret.\n", "versions": [{"version": "v1", "created": "Sat, 6 Oct 2018 17:04:14 GMT"}, {"version": "v2", "created": "Thu, 11 Oct 2018 15:40:52 GMT"}, {"version": "v3", "created": "Thu, 15 Nov 2018 06:13:38 GMT"}, {"version": "v4", "created": "Mon, 17 Dec 2018 02:10:34 GMT"}, {"version": "v5", "created": "Sun, 3 Mar 2019 02:16:14 GMT"}, {"version": "v6", "created": "Sat, 17 Jul 2021 17:19:12 GMT"}], "update_date": "2021-07-20", "authors_parsed": [["Cheung", "Wang Chi", ""], ["Simchi-Levi", "David", ""], ["Zhu", "Ruihao", ""]]}, {"id": "1810.03025", "submitter": "Peter Schulam", "authors": "Peter Schulam and Suchi Saria", "title": "Discretizing Logged Interaction Data Biases Learning for Decision-Making", "comments": "This is a standalone short paper describing a new type of bias that\n  can arise when learning from time series data for sequential decision-making\n  problems", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.AI cs.LG cs.SY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Time series data that are not measured at regular intervals are commonly\ndiscretized as a preprocessing step. For example, data about customer arrival\ntimes might be simplified by summing the number of arrivals within hourly\nintervals, which produces a discrete-time time series that is easier to model.\nIn this abstract, we show that discretization introduces a bias that affects\nmodels trained for decision-making. We refer to this phenomenon as\ndiscretization bias, and show that we can avoid it by using continuous-time\nmodels instead.\n", "versions": [{"version": "v1", "created": "Sat, 6 Oct 2018 17:08:47 GMT"}], "update_date": "2018-10-09", "authors_parsed": [["Schulam", "Peter", ""], ["Saria", "Suchi", ""]]}, {"id": "1810.03031", "submitter": "Erion \\c{C}ano", "authors": "Erion \\c{C}ano", "title": "Text-based Sentiment Analysis and Music Emotion Recognition", "comments": "Ph.D. Thesis", "journal-ref": null, "doi": "10.6092/polito/porto/2709436", "report-no": null, "categories": "cs.CL cs.HC cs.LG cs.SD", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Sentiment polarity of tweets, blog posts or product reviews has become highly\nattractive and is utilized in recommender systems, market predictions, business\nintelligence and more. Deep learning techniques are becoming top performers on\nanalyzing such texts. There are however several problems that need to be solved\nfor efficient use of deep neural networks on text mining and text polarity\nanalysis. First, deep neural networks need to be fed with data sets that are\nbig in size as well as properly labeled. Second, there are various\nuncertainties regarding the use of word embedding vectors: should they be\ngenerated from the same data set that is used to train the model or it is\nbetter to source them from big and popular collections? Third, to simplify\nmodel creation it is convenient to have generic neural network architectures\nthat are effective and can adapt to various texts, encapsulating much of design\ncomplexity. This thesis addresses the above problems to provide methodological\nand practical insights for utilizing neural networks on sentiment analysis of\ntexts and achieving state of the art results. Regarding the first problem, the\neffectiveness of various crowdsourcing alternatives is explored and two\nmedium-sized and emotion-labeled song data sets are created utilizing social\ntags. To address the second problem, a series of experiments with large text\ncollections of various contents and domains were conducted, trying word\nembeddings of various parameters. Regarding the third problem, a series of\nexperiments involving convolution and max-pooling neural layers were conducted.\nCombining convolutions of words, bigrams, and trigrams with regional\nmax-pooling layers in a couple of stacks produced the best results. The derived\narchitecture achieves competitive performance on sentiment polarity analysis of\nmovie, business and product reviews.\n", "versions": [{"version": "v1", "created": "Sat, 6 Oct 2018 17:42:19 GMT"}], "update_date": "2020-02-18", "authors_parsed": [["\u00c7ano", "Erion", ""]]}, {"id": "1810.03032", "submitter": "Maxim Panov", "authors": "Stanislav Tsepa and Maxim Panov", "title": "Constructing Graph Node Embeddings via Discrimination of Similarity\n  Distributions", "comments": null, "journal-ref": "In 2018 IEEE International Conference on Data Mining Workshops\n  (ICDMW), pp. 1050-1053", "doi": "10.1109/ICDMW.2018.00152", "report-no": null, "categories": "stat.ML cs.LG cs.SI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The problem of unsupervised learning node embeddings in graphs is one of the\nimportant directions in modern network science. In this work we propose a novel\nframework, which is aimed to find embeddings by \\textit{discriminating\ndistributions of similarities (DDoS)} between nodes in the graph. The general\nidea is implemented by maximizing the \\textit{earth mover distance} between\ndistributions of decoded similarities of similar and dissimilar nodes. The\nresulting algorithm generates embeddings which give a state-of-the-art\nperformance in the problem of link prediction in real-world graphs.\n", "versions": [{"version": "v1", "created": "Sat, 6 Oct 2018 17:55:26 GMT"}], "update_date": "2020-01-24", "authors_parsed": [["Tsepa", "Stanislav", ""], ["Panov", "Maxim", ""]]}, {"id": "1810.03037", "submitter": "Alon Brutzkus", "authors": "Alon Brutzkus, Amir Globerson", "title": "Why do Larger Models Generalize Better? A Theoretical Perspective via\n  the XOR Problem", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Empirical evidence suggests that neural networks with ReLU activations\ngeneralize better with over-parameterization. However, there is currently no\ntheoretical analysis that explains this observation. In this work, we provide\ntheoretical and empirical evidence that, in certain cases, overparameterized\nconvolutional networks generalize better than small networks because of an\ninterplay between weight clustering and feature exploration at initialization.\nWe demonstrate this theoretically for a 3-layer convolutional neural network\nwith max-pooling, in a novel setting which extends the XOR problem. We show\nthat this interplay implies that with overparamterization, gradient descent\nconverges to global minima with better generalization performance compared to\nglobal minima of small networks. Empirically, we demonstrate these phenomena\nfor a 3-layer convolutional neural network in the MNIST task.\n", "versions": [{"version": "v1", "created": "Sat, 6 Oct 2018 18:44:51 GMT"}, {"version": "v2", "created": "Tue, 29 Jan 2019 14:21:01 GMT"}], "update_date": "2019-01-30", "authors_parsed": [["Brutzkus", "Alon", ""], ["Globerson", "Amir", ""]]}, {"id": "1810.03044", "submitter": "Casey Bennett", "authors": "Casey C. Bennett", "title": "Artificial Intelligence for Diabetes Case Management: The Intersection\n  of Physical and Mental Health", "comments": "arXiv admin note: This version has been removed by arXiv\n  administrators due to copyright infringement", "journal-ref": "Informatics in Medicine Unlocked, 2019", "doi": "10.1016/j.imu.2019.100191", "report-no": null, "categories": "q-bio.QM cs.AI cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Diabetes is a major public health problem in the United States, affecting\nroughly 30 million people. Diabetes complications, along with the mental health\ncomorbidities that often co-occur with them, are major drivers of high\nhealthcare costs, poor outcomes, and reduced treatment adherence in diabetes.\nHere, we evaluate in a large state-wide population whether we can use\nartificial intelligence (AI) techniques to identify clusters of patient\ntrajectories within the broader diabetes population in order to create\ncost-effective, narrowly-focused case management intervention strategies to\nreduce development of complications. This approach combined data from: 1)\nclaims, 2) case management notes, and 3) social determinants of health from\n~300,000 real patients between 2014 and 2016. We categorized complications as\nfive types: Cardiovascular, Neuropathy, Opthalmic, Renal, and Other. Modeling\nwas performed combining a variety of machine learning algorithms, including\nsupervised classification, unsupervised clustering, natural language processing\nof unstructured care notes, and feature engineering. The results showed that we\ncan predict development of diabetes complications roughly 83.5% of the time\nusing claims data or social determinants of health data. They also showed we\ncan reveal meaningful clusters in the patient population related to\ncomplications and mental health that can be used to cost-effective screening\nprogram, reducing the number of patients to be screened down by 85%. This study\noutlines creation of an AI framework to develop protocols to better address\nmental health comorbidities that lead to complications development in the\ndiabetes population. Future work is described that outlines potential lines of\nresearch and the need for better addressing the 'people side' of the equation.\n", "versions": [{"version": "v1", "created": "Sat, 6 Oct 2018 19:59:56 GMT"}, {"version": "v2", "created": "Thu, 21 Mar 2019 19:12:44 GMT"}, {"version": "v3", "created": "Fri, 10 May 2019 18:59:06 GMT"}], "update_date": "2019-09-19", "authors_parsed": [["Bennett", "Casey C.", ""]]}, {"id": "1810.03048", "submitter": "Gilwoo Lee", "authors": "Gilwoo Lee, Sanjiban Choudhury, Brian Hou, Siddhartha S. Srinivasa", "title": "Bayes-CPACE: PAC Optimal Exploration in Continuous Space Bayes-Adaptive\n  Markov Decision Processes", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.RO stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present the first PAC optimal algorithm for Bayes-Adaptive Markov Decision\nProcesses (BAMDPs) in continuous state and action spaces, to the best of our\nknowledge. The BAMDP framework elegantly addresses model uncertainty by\nincorporating Bayesian belief updates into long-term expected return. However,\ncomputing an exact optimal Bayesian policy is intractable. Our key insight is\nto compute a near-optimal value function by covering the continuous\nstate-belief-action space with a finite set of representative samples and\nexploiting the Lipschitz continuity of the value function. We prove the\nnear-optimality of our algorithm and analyze a number of schemes that boost the\nalgorithm's efficiency. Finally, we empirically validate our approach on a\nnumber of discrete and continuous BAMDPs and show that the learned policy has\nconsistently competitive performance against baseline approaches.\n", "versions": [{"version": "v1", "created": "Sat, 6 Oct 2018 20:37:38 GMT"}], "update_date": "2018-10-09", "authors_parsed": [["Lee", "Gilwoo", ""], ["Choudhury", "Sanjiban", ""], ["Hou", "Brian", ""], ["Srinivasa", "Siddhartha S.", ""]]}, {"id": "1810.03051", "submitter": "Praneeth Narayanamurthy", "authors": "Praneeth Narayanamurthy and Vahid Daneshpajooh and Namrata Vaswani", "title": "Provable Subspace Tracking from Missing Data and Matrix Completion", "comments": "Writing changes; includes a detailed discussion of noise analysis;\n  contains discussion for Matrix Completion; Accepted to IEEE Transactions on\n  Signal Processing", "journal-ref": "IEEE Transactions on Signal Processing (Volume: 67 , Issue: 16 ,\n  Aug, 15 2019)", "doi": "10.1109/TSP.2019.2924595", "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the problem of subspace tracking in the presence of missing data\n(ST-miss). In recent work, we studied a related problem called robust ST. In\nthis work, we show that a simple modification of our robust ST solution also\nprovably solves ST-miss and robust ST-miss. To our knowledge, our result is the\nfirst `complete' guarantee for ST-miss. This means that we can prove that under\nassumptions on only the algorithm inputs, the output subspace estimates are\nclose to the true data subspaces at all times. Our guarantees hold under mild\nand easily interpretable assumptions, and allow the underlying subspace to\nchange with time in a piecewise constant fashion. In contrast, all existing\nguarantees for ST are partial results and assume a fixed unknown subspace.\nExtensive numerical experiments are shown to back up our theoretical claims.\nFinally, our solution can be interpreted as a provably correct mini-batch and\nmemory-efficient solution to low-rank Matrix Completion (MC).\n", "versions": [{"version": "v1", "created": "Sat, 6 Oct 2018 20:54:25 GMT"}, {"version": "v2", "created": "Thu, 30 May 2019 04:49:34 GMT"}], "update_date": "2019-08-02", "authors_parsed": [["Narayanamurthy", "Praneeth", ""], ["Daneshpajooh", "Vahid", ""], ["Vaswani", "Namrata", ""]]}, {"id": "1810.03052", "submitter": "Kenneth Blomqvist", "authors": "Kenneth Blomqvist, Samuel Kaski, Markus Heinonen", "title": "Deep convolutional Gaussian processes", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose deep convolutional Gaussian processes, a deep Gaussian process\narchitecture with convolutional structure. The model is a principled Bayesian\nframework for detecting hierarchical combinations of local features for image\nclassification. We demonstrate greatly improved image classification\nperformance compared to current Gaussian process approaches on the MNIST and\nCIFAR-10 datasets. In particular, we improve CIFAR-10 accuracy by over 10\npercentage points.\n", "versions": [{"version": "v1", "created": "Sat, 6 Oct 2018 20:58:05 GMT"}], "update_date": "2018-10-09", "authors_parsed": [["Blomqvist", "Kenneth", ""], ["Kaski", "Samuel", ""], ["Heinonen", "Markus", ""]]}, {"id": "1810.03064", "submitter": "Fei Wang", "authors": "Fei Wang, Jinsong Han, Shiyuan Zhang, Xu He, Dong Huang", "title": "CSI-Net: Unified Human Body Characterization and Pose Recognition", "comments": "14 pages, 6 figures and 10 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We build CSI-Net, a unified Deep Neural Network~(DNN), to learn the\nrepresentation of WiFi signals. Using CSI-Net, we jointly solved two body\ncharacterization problems: biometrics estimation (including body fat, muscle,\nwater, and bone rates) and person recognition. We also demonstrated the\napplication of CSI-Net on two distinctive pose recognition tasks: the hand sign\nrecognition (fine-scaled action of the hand) and falling detection\n(coarse-scaled motion of the body).\n", "versions": [{"version": "v1", "created": "Sun, 7 Oct 2018 00:51:14 GMT"}, {"version": "v2", "created": "Tue, 22 Jan 2019 18:10:23 GMT"}], "update_date": "2019-01-23", "authors_parsed": [["Wang", "Fei", ""], ["Han", "Jinsong", ""], ["Zhang", "Shiyuan", ""], ["He", "Xu", ""], ["Huang", "Dong", ""]]}, {"id": "1810.03068", "submitter": "Matthew Hirn", "authors": "Feng Gao and Guy Wolf and Matthew Hirn", "title": "Geometric Scattering for Graph Data Analysis", "comments": null, "journal-ref": "Proceedings of the 36th International Conference on Machine\n  Learning, PMLR 97:2122-2131, 2019", "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We explore the generalization of scattering transforms from traditional\n(e.g., image or audio) signals to graph data, analogous to the generalization\nof ConvNets in geometric deep learning, and the utility of extracted graph\nfeatures in graph data analysis. In particular, we focus on the capacity of\nthese features to retain informative variability and relations in the data\n(e.g., between individual graphs, or in aggregate), while relating our\nconstruction to previous theoretical results that establish the stability of\nsimilar transforms to families of graph deformations. We demonstrate the\napplication the our geometric scattering features in graph classification of\nsocial network data, and in data exploration of biochemistry data.\n", "versions": [{"version": "v1", "created": "Sun, 7 Oct 2018 01:52:15 GMT"}, {"version": "v2", "created": "Tue, 29 Jan 2019 00:19:05 GMT"}], "update_date": "2019-11-27", "authors_parsed": [["Gao", "Feng", ""], ["Wolf", "Guy", ""], ["Hirn", "Matthew", ""]]}, {"id": "1810.03076", "submitter": "Akash Patel", "authors": "Munzir Zafar, Akash Patel, Bogdan Vlahov, Nathaniel Glaser, Sergio\n  Aguillera, Seth Hutchinson", "title": "Online Center of Mass Estimation for a Humanoid Wheeled Inverted\n  Pendulum Robot", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.LG cs.SY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a novel application of robust control and online learning for the\nbalancing of a n Degree of Freedom (DoF), Wheeled Inverted Pendulum (WIP)\nhumanoid robot. Our technique condenses the inaccuracies of a mass model into a\nCenter of Mass (CoM) error, balances despite this error, and uses online\nlearning to update the mass model for a better CoM estimate. Using a simulated\nmodel of our robot, we meta-learn a set of excitory joint poses that makes our\ngradient descent algorithm quickly converge to an accurate (CoM) estimate. This\nsimulated pipeline executes in a fully online fashion, using active disturbance\nrejection to address the mass errors that result from a steadily evolving mass\nmodel. Experiments were performed on a 19 DoF WIP, in which we manually\nacquired the data for the learned set of poses and show that the mass model\nproduced by a gradient descent produces a CoM estimate that improves overall\ncontrol and efficiency. This work contributes to a greater corpus of whole body\ncontrol on the Golem Krang humanoid robot.\n", "versions": [{"version": "v1", "created": "Sun, 7 Oct 2018 02:56:37 GMT"}, {"version": "v2", "created": "Tue, 14 May 2019 23:56:44 GMT"}], "update_date": "2019-05-16", "authors_parsed": [["Zafar", "Munzir", ""], ["Patel", "Akash", ""], ["Vlahov", "Bogdan", ""], ["Glaser", "Nathaniel", ""], ["Aguillera", "Sergio", ""], ["Hutchinson", "Seth", ""]]}, {"id": "1810.03077", "submitter": "Sudharshan Suresh", "authors": "Sudharshan Suresh, Nathaniel Chodosh, Montiel Abello", "title": "DeepGeo: Photo Localization with Deep Neural Network", "comments": "7 pages, 9 figures. Pre-print after submission to conference", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we address the task of determining the geographical location of\nan image, a pertinent problem in learning and computer vision. This research\nwas inspired from playing GeoGuessr, a game that tests a humans' ability to\nlocalize themselves using just images of their surroundings. In particular, we\nwish to investigate how geographical, ecological and man-made features\ngeneralize for random location prediction. This is framed as a classification\nproblem: given images sampled from the USA, the most-probable state among 50 is\npredicted. Previous work uses models extensively trained on large, unfiltered\nonline datasets that are primed towards specific locations. To this end, we\ncreate (and open-source) the 50States10K dataset - with 0.5 million Google\nStreet View images of the country. A deep neural network based on the ResNet\narchitecture is trained, and four different strategies of incorporating\nlow-level cardinality information are presented. This model achieves an\naccuracy 20 times better than chance on a test dataset, which rises to 71.87%\nwhen taking the best of top-5 guesses. The network also beats human subjects in\n4 out of 5 rounds of GeoGuessr.\n", "versions": [{"version": "v1", "created": "Sun, 7 Oct 2018 03:10:57 GMT"}], "update_date": "2018-10-09", "authors_parsed": [["Suresh", "Sudharshan", ""], ["Chodosh", "Nathaniel", ""], ["Abello", "Montiel", ""]]}, {"id": "1810.03078", "submitter": "Yu-Zhen Janice Chen", "authors": "Xutong Liu, Yu-Zhen Janice Chen, John C.S. Lui, Konstantin Avrachenkov", "title": "Graphlet Count Estimation via Convolutional Neural Networks", "comments": "Extended Abstract Accepted by Complex Networks 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Graphlets are defined as k-node connected induced subgraph patterns. For an\nundirected graph, 3-node graphlets include close triangle and open triangle.\nWhen k = 4, there are six types of graphlets, e.g., tailed-triangle and clique\nare two possible 4-node graphlets. The number of each graphlet, called graphlet\ncount, is a signature which characterizes the local network structure of a\ngiven graph. Graphlet count plays a prominent role in network analysis of many\nfields, most notably bioinformatics and social science.\n  However, computing exact graphlet count is inherently difficult and\ncomputational expensive because the number of graphlets grows exponentially\nlarge as the graph size and/or graphlet size k grow. To deal with this\ndifficulty, many sampling methods were proposed to estimate graphlet count with\nbounded error. Nevertheless, these methods require large number of samples to\nbe statistically reliable, which is still computationally demanding. Moreover,\nthey have to repeat laborious counting procedure even if a new graph is similar\nor exactly the same as previous studied graphs.\n  Intuitively, learning from historic graphs can make estimation more accurate\nand avoid many repetitive counting to reduce computational cost. Based on this\nidea, we propose a convolutional neural network (CNN) framework and two\npreprocessing techniques to estimate graphlet count. Extensive experiments on\ntwo types of random graphs and real world biochemistry graphs show that our\nframework can offer substantial speedup on estimating graphlet count of new\ngraphs with high accuracy.\n", "versions": [{"version": "v1", "created": "Sun, 7 Oct 2018 03:31:10 GMT"}], "update_date": "2018-10-09", "authors_parsed": [["Liu", "Xutong", ""], ["Chen", "Yu-Zhen Janice", ""], ["Lui", "John C. S.", ""], ["Avrachenkov", "Konstantin", ""]]}, {"id": "1810.03105", "submitter": "Fanhua Shang", "authors": "Fanhua Shang, Licheng Jiao, Kaiwen Zhou, James Cheng, Yan Ren, Yufei\n  Jin", "title": "ASVRG: Accelerated Proximal SVRG", "comments": "32 pages, 3 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper proposes an accelerated proximal stochastic variance reduced\ngradient (ASVRG) method, in which we design a simple and effective momentum\nacceleration trick. Unlike most existing accelerated stochastic variance\nreduction methods such as Katyusha, ASVRG has only one additional variable and\none momentum parameter. Thus, ASVRG is much simpler than those methods, and has\nmuch lower per-iteration complexity. We prove that ASVRG achieves the best\nknown oracle complexities for both strongly convex and non-strongly convex\nobjectives. In addition, we extend ASVRG to mini-batch and non-smooth settings.\nWe also empirically verify our theoretical results and show that the\nperformance of ASVRG is comparable with, and sometimes even better than that of\nthe state-of-the-art stochastic methods.\n", "versions": [{"version": "v1", "created": "Sun, 7 Oct 2018 08:43:05 GMT"}, {"version": "v2", "created": "Sat, 17 Nov 2018 17:38:34 GMT"}], "update_date": "2018-11-20", "authors_parsed": [["Shang", "Fanhua", ""], ["Jiao", "Licheng", ""], ["Zhou", "Kaiwen", ""], ["Cheng", "James", ""], ["Ren", "Yan", ""], ["Jin", "Yufei", ""]]}, {"id": "1810.03115", "submitter": "Alexandre Quemy", "authors": "Alexandre Quemy", "title": "European Court of Human Right Open Data project", "comments": "Preprint submitted to Data Mining and Knowledge Discovery", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper presents thirteen datasets for binary, multiclass and multilabel\nclassification based on the European Court of Human Rights judgments since its\ncreation. The interest of such datasets is explained through the prism of the\nresearcher, the data scientist, the citizen and the legal practitioner.\nContrarily to many datasets, the creation process, from the collection of raw\ndata to the feature transformation, is provided under the form of a collection\nof fully automated and open-source scripts. It ensures reproducibility and a\nhigh level of confidence in the processed data, which is some of the most\nimportant issues in data governance nowadays. A first experimental campaign is\nperformed to study some predictability properties and to establish baseline\nresults on popular machine learning algorithms. The results are consistently\ngood across the binary datasets with an accuracy comprised between 75.86% and\n98.32% for an average accuracy of 96.45%.\n", "versions": [{"version": "v1", "created": "Sun, 7 Oct 2018 09:36:27 GMT"}, {"version": "v2", "created": "Mon, 4 Feb 2019 16:09:14 GMT"}], "update_date": "2019-02-05", "authors_parsed": [["Quemy", "Alexandre", ""]]}, {"id": "1810.03124", "submitter": "Jingchang Liu", "authors": "Jingchang Liu and Linli Xu", "title": "Accelerating Stochastic Gradient Descent Using Antithetic Sampling", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  (Mini-batch) Stochastic Gradient Descent is a popular optimization method\nwhich has been applied to many machine learning applications. But a rather high\nvariance introduced by the stochastic gradient in each step may slow down the\nconvergence. In this paper, we propose the antithetic sampling strategy to\nreduce the variance by taking advantage of the internal structure in dataset.\nUnder this new strategy, stochastic gradients in a mini-batch are no longer\nindependent but negatively correlated as much as possible, while the mini-batch\nstochastic gradient is still an unbiased estimator of full gradient. For the\nbinary classification problems, we just need to calculate the antithetic\nsamples in advance, and reuse the result in each iteration, which is practical.\nExperiments are provided to confirm the effectiveness of the proposed method.\n", "versions": [{"version": "v1", "created": "Sun, 7 Oct 2018 11:42:10 GMT"}], "update_date": "2018-10-09", "authors_parsed": [["Liu", "Jingchang", ""], ["Xu", "Linli", ""]]}, {"id": "1810.03145", "submitter": "Ruohan Wang", "authors": "Ruohan Wang and Pierluigi V. Amadori and Yiannis Demiris", "title": "Real-Time Workload Classification during Driving using HyperNetworks", "comments": "2018 IEEE/RSJ International Conference on Intelligent Robots and\n  Systems (IROS 2018)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.HC cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Classifying human cognitive states from behavioral and physiological signals\nis a challenging problem with important applications in robotics. The problem\nis challenging due to the data variability among individual users, and sensor\nartefacts. In this work, we propose an end-to-end framework for real-time\ncognitive workload classification with mixture Hyper Long Short Term Memory\nNetworks, a novel variant of HyperNetworks. Evaluating the proposed approach on\nan eye-gaze pattern dataset collected from simulated driving scenarios of\ndifferent cognitive demands, we show that the proposed framework outperforms\nprevious baseline methods and achieves 83.9\\% precision and 87.8\\% recall\nduring test. We also demonstrate the merit of our proposed architecture by\nshowing improved performance over other LSTM-based methods.\n", "versions": [{"version": "v1", "created": "Sun, 7 Oct 2018 13:57:25 GMT"}], "update_date": "2018-10-09", "authors_parsed": [["Wang", "Ruohan", ""], ["Amadori", "Pierluigi V.", ""], ["Demiris", "Yiannis", ""]]}, {"id": "1810.03155", "submitter": "JuanLuis GonzalezBello", "authors": "Juan Luis Gonzalez, Muhammad Sarmad, Hyunjoo J.Lee, Munchurl Kim", "title": "Finding Correspondences for Optical Flow and Disparity Estimations using\n  a Sub-pixel Convolution-based Encoder-Decoder Network", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep convolutional neural networks (DCNN) have recently shown promising\nresults in low-level computer vision problems such as optical flow and\ndisparity estimation, but still, have much room to further improve their\nperformance. In this paper, we propose a novel sub-pixel convolution-based\nencoder-decoder network for optical flow and disparity estimations, which can\nextend FlowNetS and DispNet by replacing the deconvolution layers with\nsup-pixel convolution blocks. By using sub-pixel refinement and estimation on\nthe decoder stages instead of deconvolution, we can significantly improve the\nestimation accuracy for optical flow and disparity, even with reduced numbers\nof parameters. We show a supervised end-to-end training of our proposed\nnetworks for optical flow and disparity estimations, and an unsupervised\nend-to-end training for monocular depth and pose estimations. In order to\nverify the effectiveness of our proposed networks, we perform intensive\nexperiments for (i) optical flow and disparity estimations, and (ii) monocular\ndepth and pose estimations. Throughout the extensive experiments, our proposed\nnetworks outperform the baselines such as FlowNetS and DispNet in terms of\nestimation accuracy and training times.\n", "versions": [{"version": "v1", "created": "Sun, 7 Oct 2018 14:41:37 GMT"}], "update_date": "2018-10-12", "authors_parsed": [["Gonzalez", "Juan Luis", ""], ["Sarmad", "Muhammad", ""], ["Lee", "Hyunjoo J.", ""], ["Kim", "Munchurl", ""]]}, {"id": "1810.03167", "submitter": "Zhiqing Sun", "authors": "Zhiqing Sun and Zhi-Hong Deng", "title": "Unsupervised Neural Word Segmentation for Chinese via Segmental Language\n  Modeling", "comments": "To appear in EMNLP 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Previous traditional approaches to unsupervised Chinese word segmentation\n(CWS) can be roughly classified into discriminative and generative models. The\nformer uses the carefully designed goodness measures for candidate\nsegmentation, while the latter focuses on finding the optimal segmentation of\nthe highest generative probability. However, while there exists a trivial way\nto extend the discriminative models into neural version by using neural\nlanguage models, those of generative ones are non-trivial. In this paper, we\npropose the segmental language models (SLMs) for CWS. Our approach explicitly\nfocuses on the segmental nature of Chinese, as well as preserves several\nproperties of language models. In SLMs, a context encoder encodes the previous\ncontext and a segment decoder generates each segment incrementally. As far as\nwe know, we are the first to propose a neural model for unsupervised CWS and\nachieve competitive performance to the state-of-the-art statistical models on\nfour different datasets from SIGHAN 2005 bakeoff.\n", "versions": [{"version": "v1", "created": "Sun, 7 Oct 2018 15:55:58 GMT"}], "update_date": "2018-10-09", "authors_parsed": [["Sun", "Zhiqing", ""], ["Deng", "Zhi-Hong", ""]]}, {"id": "1810.03197", "submitter": "Xueru Zhang", "authors": "Xueru Zhang, Mohammad Mahdi Khalili, Mingyan Liu", "title": "Recycled ADMM: Improve Privacy and Accuracy with Less Computation in\n  Distributed Algorithms", "comments": "Accepted to 56th Annual Allerton Conference on Communication,\n  Control, and Computing", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.LG math.OC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Alternating direction method of multiplier (ADMM) is a powerful method to\nsolve decentralized convex optimization problems. In distributed settings, each\nnode performs computation with its local data and the local results are\nexchanged among neighboring nodes in an iterative fashion. During this\niterative process the leakage of data privacy arises and can accumulate\nsignificantly over many iterations, making it difficult to balance the\nprivacy-utility tradeoff. In this study we propose Recycled ADMM (R-ADMM),\nwhere a linear approximation is applied to every even iteration, its solution\ndirectly calculated using only results from the previous, odd iteration. It\nturns out that under such a scheme, half of the updates incur no privacy loss\nand require much less computation compared to the conventional ADMM. We obtain\na sufficient condition for the convergence of R-ADMM and provide the privacy\nanalysis based on objective perturbation.\n", "versions": [{"version": "v1", "created": "Sun, 7 Oct 2018 18:39:41 GMT"}], "update_date": "2018-10-09", "authors_parsed": [["Zhang", "Xueru", ""], ["Khalili", "Mohammad Mahdi", ""], ["Liu", "Mingyan", ""]]}, {"id": "1810.03198", "submitter": "Jitin Kapila", "authors": "Kumarjit Pathak, Jitin Kapila", "title": "Reinforcement Evolutionary Learning Method for self-learning", "comments": "5 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.NE stat.ML", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  In statistical modelling the biggest threat is concept drift which makes the\nmodel gradually showing deteriorating performance over time. There are state of\nthe art methodologies to detect the impact of concept drift, however general\nstrategy considered to overcome the issue in performance is to rebuild or\nre-calibrate the model periodically as the variable patterns for the model\nchanges significantly due to market change or consumer behavior change etc.\nQuantitative research is the most widely spread application of data science in\nMarketing or financial domain where applicability of state of the art\nreinforcement learning for auto-learning is less explored paradigm.\nReinforcement learning is heavily dependent on having a simulated environment\nwhich is majorly available for gaming or online systems, to learn from the live\nfeedback. However, there are some research happened on the area of online\nadvertisement, pricing etc where due to the nature of the online learning\nenvironment scope of reinforcement learning is explored. Our proposed solution\nis a reinforcement learning based, true self-learning algorithm which can adapt\nto the data change or concept drift and auto learn and self-calibrate for the\nnew patterns of the data solving the problem of concept drift.\n  Keywords - Reinforcement learning, Genetic Algorithm, Q-learning,\nClassification modelling, CMA-ES, NES, Multi objective optimization, Concept\ndrift, Population stability index, Incremental learning, F1-measure, Predictive\nModelling, Self-learning, MCTS, AlphaGo, AlphaZero\n", "versions": [{"version": "v1", "created": "Sun, 7 Oct 2018 19:25:48 GMT"}], "update_date": "2018-10-09", "authors_parsed": [["Pathak", "Kumarjit", ""], ["Kapila", "Jitin", ""]]}, {"id": "1810.03218", "submitter": "Gonzalo Mu\\~noz", "authors": "Daniel Bienstock, Gonzalo Mu\\~noz, Sebastian Pokutta", "title": "Principled Deep Neural Network Training through Linear Programming", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG math.OC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep Learning has received significant attention due to its impressive\nperformance in many state-of-the-art learning tasks. Unfortunately, while very\npowerful, Deep Learning is not well understood theoretically and in particular\nonly recently results for the complexity of training deep neural networks have\nbeen obtained. In this work we show that large classes of deep neural networks\nwith various architectures (e.g., DNNs, CNNs, Binary Neural Networks, and\nResNets), activation functions (e.g., ReLUs and leaky ReLUs), and loss\nfunctions (e.g., Hinge loss, Euclidean loss, etc) can be trained to near\noptimality with desired target accuracy using linear programming in time that\nis exponential in the input data and parameter space dimension and polynomial\nin the size of the data set; improvements of the dependence in the input\ndimension are known to be unlikely assuming $P\\neq NP$, and improving the\ndependence on the parameter space dimension remains open. In particular, we\nobtain polynomial time algorithms for training for a given fixed network\narchitecture. Our work applies more broadly to empirical risk minimization\nproblems which allows us to generalize various previous results and obtain new\ncomplexity results for previously unstudied architectures in the proper\nlearning setting.\n", "versions": [{"version": "v1", "created": "Sun, 7 Oct 2018 22:15:07 GMT"}, {"version": "v2", "created": "Mon, 26 Nov 2018 21:07:59 GMT"}], "update_date": "2018-11-28", "authors_parsed": [["Bienstock", "Daniel", ""], ["Mu\u00f1oz", "Gonzalo", ""], ["Pokutta", "Sebastian", ""]]}, {"id": "1810.03222", "submitter": "Ashkan Esmaeili", "authors": "Ashkan Esmaeili, Kayhan Behdin, Sina Al-E-Mohammad, Farokh Marvasti", "title": "Recovering Quantized Data with Missing Information Using Bilinear\n  Factorization and Augmented Lagrangian Method", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we propose a novel approach in order to recover a quantized\nmatrix with missing information. We propose a regularized convex cost function\ncomposed of a log-likelihood term and a Trace norm term. The Bi-factorization\napproach and the Augmented Lagrangian Method (ALM) are applied to find the\nglobal minimizer of the cost function in order to recover the genuine data. We\nprovide mathematical convergence analysis for our proposed algorithm. In the\nNumerical Experiments Section, we show the superiority of our method in\naccuracy and also its robustness in computational complexity compared to the\nstate-of-the-art literature methods.\n", "versions": [{"version": "v1", "created": "Sun, 7 Oct 2018 23:06:52 GMT"}], "update_date": "2018-10-09", "authors_parsed": [["Esmaeili", "Ashkan", ""], ["Behdin", "Kayhan", ""], ["Al-E-Mohammad", "Sina", ""], ["Marvasti", "Farokh", ""]]}, {"id": "1810.03226", "submitter": "Eunjeong Koh", "authors": "Eunjeong Stella Koh, Shlomo Dubnov, and Dustin Wright", "title": "Rethinking Recurrent Latent Variable Model for Music Composition", "comments": "Published as a conference paper at IEEE MMSP 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SD cs.LG cs.MM eess.AS", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We present a model for capturing musical features and creating novel\nsequences of music, called the Convolutional Variational Recurrent Neural\nNetwork. To generate sequential data, the model uses an encoder-decoder\narchitecture with latent probabilistic connections to capture the hidden\nstructure of music. Using the sequence-to-sequence model, our generative model\ncan exploit samples from a prior distribution and generate a longer sequence of\nmusic. We compare the performance of our proposed model with other types of\nNeural Networks using the criteria of Information Rate that is implemented by\nVariable Markov Oracle, a method that allows statistical characterization of\nmusical information dynamics and detection of motifs in a song. Our results\nsuggest that the proposed model has a better statistical resemblance to the\nmusical structure of the training data, which improves the creation of new\nsequences of music in the style of the originals.\n", "versions": [{"version": "v1", "created": "Sun, 7 Oct 2018 23:22:56 GMT"}], "update_date": "2018-10-09", "authors_parsed": [["Koh", "Eunjeong Stella", ""], ["Dubnov", "Shlomo", ""], ["Wright", "Dustin", ""]]}, {"id": "1810.03233", "submitter": "Anit Kumar Sahu", "authors": "Anit Kumar Sahu, Manzil Zaheer and Soummya Kar", "title": "Towards Gradient Free and Projection Free Stochastic Optimization", "comments": "To appear in Proceedings of AISTATS 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.OC cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper focuses on the problem of \\emph{constrained} \\emph{stochastic}\noptimization. A zeroth order Frank-Wolfe algorithm is proposed, which in\naddition to the projection-free nature of the vanilla Frank-Wolfe algorithm\nmakes it gradient free. Under convexity and smoothness assumption, we show that\nthe proposed algorithm converges to the optimal objective function at a rate\n$O\\left(1/T^{1/3}\\right)$, where $T$ denotes the iteration count. In\nparticular, the primal sub-optimality gap is shown to have a dimension\ndependence of $O\\left(d^{1/3}\\right)$, which is the best known dimension\ndependence among all zeroth order optimization algorithms with one directional\nderivative per iteration. For non-convex functions, we obtain the\n\\emph{Frank-Wolfe} gap to be $O\\left(d^{1/3}T^{-1/4}\\right)$. Experiments on\nblack-box optimization setups demonstrate the efficacy of the proposed\nalgorithm.\n", "versions": [{"version": "v1", "created": "Mon, 8 Oct 2018 00:29:43 GMT"}, {"version": "v2", "created": "Tue, 9 Oct 2018 00:42:02 GMT"}, {"version": "v3", "created": "Mon, 18 Feb 2019 22:20:20 GMT"}], "update_date": "2019-02-20", "authors_parsed": [["Sahu", "Anit Kumar", ""], ["Zaheer", "Manzil", ""], ["Kar", "Soummya", ""]]}, {"id": "1810.03237", "submitter": "Stephen James", "authors": "Stephen James, Michael Bloesch, Andrew J. Davison", "title": "Task-Embedded Control Networks for Few-Shot Imitation Learning", "comments": "Published at the Conference on Robot Learning (CoRL) 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.AI cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Much like humans, robots should have the ability to leverage knowledge from\npreviously learned tasks in order to learn new tasks quickly in new and\nunfamiliar environments. Despite this, most robot learning approaches have\nfocused on learning a single task, from scratch, with a limited notion of\ngeneralisation, and no way of leveraging the knowledge to learn other tasks\nmore efficiently. One possible solution is meta-learning, but many of the\nrelated approaches are limited in their ability to scale to a large number of\ntasks and to learn further tasks without forgetting previously learned ones.\nWith this in mind, we introduce Task-Embedded Control Networks, which employ\nideas from metric learning in order to create a task embedding that can be used\nby a robot to learn new tasks from one or more demonstrations. In the area of\nvisually-guided manipulation, we present simulation results in which we surpass\nthe performance of a state-of-the-art method when using only visual information\nfrom each demonstration. Additionally, we demonstrate that our approach can\nalso be used in conjunction with domain randomisation to train our few-shot\nlearning ability in simulation and then deploy in the real world without any\nadditional training. Once deployed, the robot can learn new tasks from a single\nreal-world demonstration.\n", "versions": [{"version": "v1", "created": "Mon, 8 Oct 2018 00:57:24 GMT"}], "update_date": "2018-10-09", "authors_parsed": [["James", "Stephen", ""], ["Bloesch", "Michael", ""], ["Davison", "Andrew J.", ""]]}, {"id": "1810.03256", "submitter": "Kayhan Batmanghelich", "authors": "Hadi Salman and Payman Yadollahpour and Tom Fletcher and Kayhan\n  Batmanghelich", "title": "Deep Diffeomorphic Normalizing Flows", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The Normalizing Flow (NF) models a general probability density by estimating\nan invertible transformation applied on samples drawn from a known\ndistribution. We introduce a new type of NF, called Deep Diffeomorphic\nNormalizing Flow (DDNF). A diffeomorphic flow is an invertible function where\nboth the function and its inverse are smooth. We construct the flow using an\nordinary differential equation (ODE) governed by a time-varying smooth vector\nfield. We use a neural network to parametrize the smooth vector field and a\nrecursive neural network (RNN) for approximating the solution of the ODE. Each\ncell in the RNN is a residual network implementing one Euler integration step.\nThe architecture of our flow enables efficient likelihood evaluation,\nstraightforward flow inversion, and results in highly flexible density\nestimation. An end-to-end trained DDNF achieves competitive results with\nstate-of-the-art methods on a suite of density estimation and variational\ninference tasks. Finally, our method brings concepts from Riemannian geometry\nthat, we believe, can open a new research direction for neural density\nestimation.\n", "versions": [{"version": "v1", "created": "Mon, 8 Oct 2018 03:09:41 GMT"}, {"version": "v2", "created": "Thu, 22 Nov 2018 22:33:39 GMT"}], "update_date": "2018-11-26", "authors_parsed": [["Salman", "Hadi", ""], ["Yadollahpour", "Payman", ""], ["Fletcher", "Tom", ""], ["Batmanghelich", "Kayhan", ""]]}, {"id": "1810.03264", "submitter": "Wei Dai", "authors": "Wei Dai, Yi Zhou, Nanqing Dong, Hao Zhang, Eric P. Xing", "title": "Toward Understanding the Impact of Staleness in Distributed Machine\n  Learning", "comments": "19 pages, 12 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.DC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Many distributed machine learning (ML) systems adopt the non-synchronous\nexecution in order to alleviate the network communication bottleneck, resulting\nin stale parameters that do not reflect the latest updates. Despite much\ndevelopment in large-scale ML, the effects of staleness on learning are\ninconclusive as it is challenging to directly monitor or control staleness in\ncomplex distributed environments. In this work, we study the convergence\nbehaviors of a wide array of ML models and algorithms under delayed updates.\nOur extensive experiments reveal the rich diversity of the effects of staleness\non the convergence of ML algorithms and offer insights into seemingly\ncontradictory reports in the literature. The empirical findings also inspire a\nnew convergence analysis of stochastic gradient descent in non-convex\noptimization under staleness, matching the best-known convergence rate of\nO(1/\\sqrt{T}).\n", "versions": [{"version": "v1", "created": "Mon, 8 Oct 2018 03:57:39 GMT"}], "update_date": "2018-10-09", "authors_parsed": [["Dai", "Wei", ""], ["Zhou", "Yi", ""], ["Dong", "Nanqing", ""], ["Zhang", "Hao", ""], ["Xing", "Eric P.", ""]]}, {"id": "1810.03278", "submitter": "Aerin Kim", "authors": "Rohit Pandey, Yifan Chang, Cameron White, Gaurav Jagtiani, Aerin Young\n  Kim, Gil Lapid Shafriri, Sathya Singh", "title": "Optimizing Waiting Thresholds Within A State Machine", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.DC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Azure (the cloud service provided by Microsoft) is composed of physical\ncomputing units which are called nodes. These nodes are controlled by a\nsoftware component called Fabric Controller (FC), which can consider the nodes\nto be in one of many different states such as Ready, Unhealthy, Booting, etc.\nSome of these states correspond to a node being unresponsive to FCs requests.\nWhen a node goes unresponsive for more than a set threshold, FC intervenes and\nreboots the node. We minimized the downtime caused by the intervention\nthreshold when a node switches to the Unhealthy state by fitting various\nheavy-tail probability distributions. We consider using features of the node to\ncustomize the organic recovery model to the individual nodes that go unhealthy.\nThis regression approach allows us to use information about the node like\nhardware, software versions, historical performance indicators, etc. to inform\nthe organic recovery model and hence the optimal threshold. In another\ndirection, we consider generalizing this to an arbitrary number of thresholds\nwithin the node state machine (or Markov chain). When the states become\nintertwined in ways that different thresholds start affecting each other, we\ncan't simply optimize each of them in isolation. For best results, we must\nconsider this as an optimization problem in many variables (the number of\nthresholds). We no longer have a nice closed form solution for this more\ncomplex problem like we did with one threshold, but we can still use numerical\ntechniques (gradient descent) to solve it.\n", "versions": [{"version": "v1", "created": "Mon, 8 Oct 2018 06:25:38 GMT"}], "update_date": "2018-10-09", "authors_parsed": [["Pandey", "Rohit", ""], ["Chang", "Yifan", ""], ["White", "Cameron", ""], ["Jagtiani", "Gaurav", ""], ["Kim", "Aerin Young", ""], ["Shafriri", "Gil Lapid", ""], ["Singh", "Sathya", ""]]}, {"id": "1810.03292", "submitter": "Julius Adebayo", "authors": "Julius Adebayo, Justin Gilmer, Michael Muelly, Ian Goodfellow, Moritz\n  Hardt, Been Kim", "title": "Sanity Checks for Saliency Maps", "comments": "Updating Guided Backprop experiments due to bug. The results and\n  conclusions remain the same", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Saliency methods have emerged as a popular tool to highlight features in an\ninput deemed relevant for the prediction of a learned model. Several saliency\nmethods have been proposed, often guided by visual appeal on image data. In\nthis work, we propose an actionable methodology to evaluate what kinds of\nexplanations a given method can and cannot provide. We find that reliance,\nsolely, on visual assessment can be misleading. Through extensive experiments\nwe show that some existing saliency methods are independent both of the model\nand of the data generating process. Consequently, methods that fail the\nproposed tests are inadequate for tasks that are sensitive to either data or\nmodel, such as, finding outliers in the data, explaining the relationship\nbetween inputs and outputs that the model learned, and debugging the model. We\ninterpret our findings through an analogy with edge detection in images, a\ntechnique that requires neither training data nor model. Theory in the case of\na linear model and a single-layer convolutional neural network supports our\nexperimental findings.\n", "versions": [{"version": "v1", "created": "Mon, 8 Oct 2018 07:27:11 GMT"}, {"version": "v2", "created": "Sun, 28 Oct 2018 03:39:34 GMT"}, {"version": "v3", "created": "Fri, 6 Nov 2020 13:40:14 GMT"}], "update_date": "2020-11-09", "authors_parsed": [["Adebayo", "Julius", ""], ["Gilmer", "Justin", ""], ["Muelly", "Michael", ""], ["Goodfellow", "Ian", ""], ["Hardt", "Moritz", ""], ["Kim", "Been", ""]]}, {"id": "1810.03307", "submitter": "Julius Adebayo", "authors": "Julius Adebayo, Justin Gilmer, Ian Goodfellow, Been Kim", "title": "Local Explanation Methods for Deep Neural Networks Lack Sensitivity to\n  Parameter Values", "comments": "Workshop Track International Conference on Learning Representations\n  (ICLR)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Explaining the output of a complicated machine learning model like a deep\nneural network (DNN) is a central challenge in machine learning. Several\nproposed local explanation methods address this issue by identifying what\ndimensions of a single input are most responsible for a DNN's output. The goal\nof this work is to assess the sensitivity of local explanations to DNN\nparameter values. Somewhat surprisingly, we find that DNNs with\nrandomly-initialized weights produce explanations that are both visually and\nquantitatively similar to those produced by DNNs with learned weights. Our\nconjecture is that this phenomenon occurs because these explanations are\ndominated by the lower level features of a DNN, and that a DNN's architecture\nprovides a strong prior which significantly affects the representations learned\nat these lower layers. NOTE: This work is now subsumed by our recent\nmanuscript, Sanity Checks for Saliency Maps (to appear NIPS 2018), where we\nexpand on findings and address concerns raised in Sundararajan et. al. (2018).\n", "versions": [{"version": "v1", "created": "Mon, 8 Oct 2018 08:18:14 GMT"}], "update_date": "2018-10-09", "authors_parsed": [["Adebayo", "Julius", ""], ["Gilmer", "Justin", ""], ["Goodfellow", "Ian", ""], ["Kim", "Been", ""]]}, {"id": "1810.03370", "submitter": "Thiago Serra", "authors": "Thiago Serra, Srikumar Ramalingam", "title": "Empirical Bounds on Linear Regions of Deep Rectifier Networks", "comments": "AAAI 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI math.OC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We can compare the expressiveness of neural networks that use rectified\nlinear units (ReLUs) by the number of linear regions, which reflect the number\nof pieces of the piecewise linear functions modeled by such networks. However,\nenumerating these regions is prohibitive and the known analytical bounds are\nidentical for networks with same dimensions. In this work, we approximate the\nnumber of linear regions through empirical bounds based on features of the\ntrained network and probabilistic inference. Our first contribution is a method\nto sample the activation patterns defined by ReLUs using universal hash\nfunctions. This method is based on a Mixed-Integer Linear Programming (MILP)\nformulation of the network and an algorithm for probabilistic lower bounds of\nMILP solution sets that we call MIPBound, which is considerably faster than\nexact counting and reaches values in similar orders of magnitude. Our second\ncontribution is a tighter activation-based bound for the maximum number of\nlinear regions, which is particularly stronger in networks with narrow layers.\nCombined, these bounds yield a fast proxy for the number of linear regions of a\ndeep neural network.\n", "versions": [{"version": "v1", "created": "Mon, 8 Oct 2018 11:06:50 GMT"}, {"version": "v2", "created": "Fri, 25 Jan 2019 02:42:04 GMT"}, {"version": "v3", "created": "Sat, 14 Dec 2019 11:34:01 GMT"}], "update_date": "2019-12-17", "authors_parsed": [["Serra", "Thiago", ""], ["Ramalingam", "Srikumar", ""]]}, {"id": "1810.03372", "submitter": "Edo Collins", "authors": "Edo Collins, Siavash Arjomand Bigdeli, Sabine S\\\"usstrunk", "title": "Detecting Memorization in ReLU Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a new notion of `non-linearity' of a network layer with respect to\nan input batch that is based on its proximity to a linear system, which is\nreflected in the non-negative rank of the activation matrix. We measure this\nnon-linearity by applying non-negative factorization to the activation matrix.\nConsidering batches of similar samples, we find that high non-linearity in deep\nlayers is indicative of memorization. Furthermore, by applying our approach\nlayer-by-layer, we find that the mechanism for memorization consists of\ndistinct phases. We perform experiments on fully-connected and convolutional\nneural networks trained on several image and audio datasets. Our results\ndemonstrate that as an indicator for memorization, our technique can be used to\nperform early stopping.\n", "versions": [{"version": "v1", "created": "Mon, 8 Oct 2018 11:11:54 GMT"}], "update_date": "2018-10-09", "authors_parsed": [["Collins", "Edo", ""], ["Bigdeli", "Siavash Arjomand", ""], ["S\u00fcsstrunk", "Sabine", ""]]}, {"id": "1810.03377", "submitter": "Matthias Freiberger", "authors": "Matthias Freiberger, Andrew Katumba, Peter Bienstman and Joni Dambre", "title": "Training Passive Photonic Reservoirs with Integrated Optical Readout", "comments": "Accepted for publication in IEEE Transactions on Neural Networks and\n  Learning Systems (TNNLS-2017-P-8539.R1), copyright 2018 IEEE. This research\n  was funded by the EU Horizon 2020 PHRESCO Grant (Grant No. 688579) and the\n  BELSPO IAP P7-35 program Photonics@be. 11 pages, 9 figures", "journal-ref": null, "doi": "10.1109/TNNLS.2018.2874571", "report-no": null, "categories": "cs.NE cs.ET cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  As Moore's law comes to an end, neuromorphic approaches to computing are on\nthe rise. One of these, passive photonic reservoir computing, is a strong\ncandidate for computing at high bitrates (> 10 Gbps) and with low energy\nconsumption. Currently though, both benefits are limited by the necessity to\nperform training and readout operations in the electrical domain. Thus, efforts\nare currently underway in the photonic community to design an integrated\noptical readout, which allows to perform all operations in the optical domain.\nIn addition to the technological challenge of designing such a readout, new\nalgorithms have to be designed in order to train it. Foremost, suitable\nalgorithms need to be able to deal with the fact that the actual on-chip\nreservoir states are not directly observable. In this work, we investigate\nseveral options for such a training algorithm and propose a solution in which\nthe complex states of the reservoir can be observed by appropriately setting\nthe readout weights, while iterating over a predefined input sequence. We\nperform numerical simulations in order to compare our method with an ideal\nbaseline requiring full observability as well as with an established black-box\noptimization approach (CMA-ES).\n", "versions": [{"version": "v1", "created": "Mon, 8 Oct 2018 11:26:08 GMT"}], "update_date": "2018-10-09", "authors_parsed": [["Freiberger", "Matthias", ""], ["Katumba", "Andrew", ""], ["Bienstman", "Peter", ""], ["Dambre", "Joni", ""]]}, {"id": "1810.03382", "submitter": "Declan O'Regan", "authors": "Ghalib A. Bello, Timothy J.W. Dawes, Jinming Duan, Carlo Biffi,\n  Antonio de Marvao, Luke S.G.E. Howard, J. Simon R. Gibbs, Martin R. Wilkins,\n  Stuart A. Cook, Daniel Rueckert, and Declan P. O'Regan", "title": "Deep learning cardiac motion analysis for human survival prediction", "comments": null, "journal-ref": "Nature Machine Intelligence, 1, 95-104 (2019)", "doi": "10.1038/s42256-019-0019-2", "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Motion analysis is used in computer vision to understand the behaviour of\nmoving objects in sequences of images. Optimising the interpretation of dynamic\nbiological systems requires accurate and precise motion tracking as well as\nefficient representations of high-dimensional motion trajectories so that these\ncan be used for prediction tasks. Here we use image sequences of the heart,\nacquired using cardiac magnetic resonance imaging, to create time-resolved\nthree-dimensional segmentations using a fully convolutional network trained on\nanatomical shape priors. This dense motion model formed the input to a\nsupervised denoising autoencoder (4Dsurvival), which is a hybrid network\nconsisting of an autoencoder that learns a task-specific latent code\nrepresentation trained on observed outcome data, yielding a latent\nrepresentation optimised for survival prediction. To handle right-censored\nsurvival outcomes, our network used a Cox partial likelihood loss function. In\na study of 302 patients the predictive accuracy (quantified by Harrell's\nC-index) was significantly higher (p < .0001) for our model C=0.73 (95$\\%$ CI:\n0.68 - 0.78) than the human benchmark of C=0.59 (95$\\%$ CI: 0.53 - 0.65). This\nwork demonstrates how a complex computer vision task using high-dimensional\nmedical image data can efficiently predict human survival.\n", "versions": [{"version": "v1", "created": "Mon, 8 Oct 2018 11:34:38 GMT"}], "update_date": "2019-02-18", "authors_parsed": [["Bello", "Ghalib A.", ""], ["Dawes", "Timothy J. W.", ""], ["Duan", "Jinming", ""], ["Biffi", "Carlo", ""], ["de Marvao", "Antonio", ""], ["Howard", "Luke S. G. E.", ""], ["Gibbs", "J. Simon R.", ""], ["Wilkins", "Martin R.", ""], ["Cook", "Stuart A.", ""], ["Rueckert", "Daniel", ""], ["O'Regan", "Declan P.", ""]]}, {"id": "1810.03389", "submitter": "Yuan Yao", "authors": "Weizhi Zhu, Yifei Huang, Yuan Yao", "title": "Rethinking Breiman's Dilemma in Neural Networks: Phase Transitions of\n  Margin Dynamics", "comments": "36 pages", "journal-ref": "Front. Appl. Math. Stat., 30 October 2020", "doi": "10.3389/fams.2020.575073", "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Margin enlargement over training data has been an important strategy since\nperceptrons in machine learning for the purpose of boosting the robustness of\nclassifiers toward a good generalization ability. Yet Breiman (1999) showed a\ndilemma that a uniform improvement on margin distribution does NOT necessarily\nreduces generalization errors. In this paper, we revisit Breiman's dilemma in\ndeep neural networks with recently proposed spectrally normalized margins, from\na novel perspective based on phase transitions of normalized margin\ndistributions in training dynamics. Normalized margin distribution of a\nclassifier over the data, can be divided into two parts: low/small margins such\nas some negative margins for misclassified samples vs. high/large margins for\nhigh confident correctly classified samples, that often behave differently\nduring the training process. Low margins for training and test datasets are\noften effectively reduced in training, along with reductions of training and\ntest errors; while high margins may exhibit different dynamics, reflecting the\ntrade-off between expressive power of models and complexity of data. When data\ncomplexity is comparable to the model expressiveness, high margin distributions\nfor both training and test data undergo similar decrease-increase phase\ntransitions during training. In such cases, one can predict the trend of\ngeneralization or test error by margin-based generalization bounds with\nrestricted Rademacher complexities, shown in two ways in this paper with early\nstopping time exploiting such phase transitions. On the other hand,\nover-expressive models may have both low and high training margins undergoing\nuniform improvements, with a distinct phase transition in test margin dynamics.\nThis reconfirms the Breiman's dilemma associated with overparameterized neural\nnetworks where margins fail to predict overfitting.\n", "versions": [{"version": "v1", "created": "Mon, 8 Oct 2018 12:04:39 GMT"}, {"version": "v2", "created": "Thu, 18 Oct 2018 13:50:52 GMT"}, {"version": "v3", "created": "Fri, 1 Jan 2021 14:42:39 GMT"}], "update_date": "2021-01-05", "authors_parsed": [["Zhu", "Weizhi", ""], ["Huang", "Yifei", ""], ["Yao", "Yuan", ""]]}, {"id": "1810.03393", "submitter": "Ye Zhu PhD", "authors": "Ye Zhu, Kai Ming Ting, Yuan Jin, Maia Angelova", "title": "Hierarchical clustering that takes advantage of both density-peak and\n  density-connectivity", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper focuses on density-based clustering, particularly the Density Peak\n(DP) algorithm and the one based on density-connectivity DBSCAN; and proposes a\nnew method which takes advantage of the individual strengths of these two\nmethods to yield a density-based hierarchical clustering algorithm. Our\ninvestigation begins with formally defining the types of clusters DP and DBSCAN\nare designed to detect; and then identifies the kinds of distributions that DP\nand DBSCAN individually fail to detect all clusters in a dataset. These\nidentified weaknesses inspire us to formally define a new kind of clusters and\npropose a new method called DC-HDP to overcome these weaknesses to identify\nclusters with arbitrary shapes and varied densities. In addition, the new\nmethod produces a richer clustering result in terms of hierarchy or dendrogram\nfor better cluster structures understanding. Our empirical evaluation results\nshow that DC-HDP produces the best clustering results on 14 datasets in\ncomparison with 7 state-of-the-art clustering algorithms.\n", "versions": [{"version": "v1", "created": "Mon, 8 Oct 2018 12:12:42 GMT"}], "update_date": "2018-10-09", "authors_parsed": [["Zhu", "Ye", ""], ["Ting", "Kai Ming", ""], ["Jin", "Yuan", ""], ["Angelova", "Maia", ""]]}, {"id": "1810.03399", "submitter": "Benjamin Stemper", "authors": "Christian Bayer, Benjamin Stemper", "title": "Deep calibration of rough stochastic volatility models", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "q-fin.PR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Sparked by Al\\`os, Le\\'on, and Vives (2007); Fukasawa (2011, 2017); Gatheral,\nJaisson, and Rosenbaum (2018), so-called rough stochastic volatility models\nsuch as the rough Bergomi model by Bayer, Friz, and Gatheral (2016) constitute\nthe latest evolution in option price modeling. Unlike standard bivariate\ndiffusion models such as Heston (1993), these non-Markovian models with\nfractional volatility drivers allow to parsimoniously recover key stylized\nfacts of market implied volatility surfaces such as the exploding power-law\nbehaviour of the at-the-money volatility skew as time to maturity goes to zero.\nStandard model calibration routines rely on the repetitive evaluation of the\nmap from model parameters to Black-Scholes implied volatility, rendering\ncalibration of many (rough) stochastic volatility models prohibitively\nexpensive since there the map can often only be approximated by costly Monte\nCarlo (MC) simulations (Bennedsen, Lunde, & Pakkanen, 2017; McCrickerd &\nPakkanen, 2018; Bayer et al., 2016; Horvath, Jacquier, & Muguruza, 2017). As a\nremedy, we propose to combine a standard Levenberg-Marquardt calibration\nroutine with neural network regression, replacing expensive MC simulations with\ncheap forward runs of a neural network trained to approximate the implied\nvolatility map. Numerical experiments confirm the high accuracy and speed of\nour approach.\n", "versions": [{"version": "v1", "created": "Mon, 8 Oct 2018 12:22:29 GMT"}], "update_date": "2018-10-09", "authors_parsed": [["Bayer", "Christian", ""], ["Stemper", "Benjamin", ""]]}, {"id": "1810.03417", "submitter": "Arda Aytekin", "authors": "Arda Aytekin and Martin Biel and Mikael Johansson", "title": "POLO: a POLicy-based Optimization library", "comments": "25 pages, 7 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.OC cs.DC cs.LG cs.SE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present POLO --- a C++ library for large-scale parallel optimization\nresearch that emphasizes ease-of-use, flexibility and efficiency in algorithm\ndesign. It uses multiple inheritance and template programming to decompose\nalgorithms into essential policies and facilitate code reuse. With its clear\nseparation between algorithm and execution policies, it provides researchers\nwith a simple and powerful platform for prototyping ideas, evaluating them on\ndifferent parallel computing architectures and hardware platforms, and\ngenerating compact and efficient production code. A C-API is included for\ncustomization and data loading in high-level languages. POLO enables users to\nmove seamlessly from serial to multi-threaded shared-memory and multi-node\ndistributed-memory executors. We demonstrate how POLO allows users to implement\nstate-of-the-art asynchronous parallel optimization algorithms in just a few\nlines of code and report experiment results from shared and distributed-memory\ncomputing architectures. We provide both POLO and POLO.jl, a wrapper around\nPOLO written in the Julia language, at https://github.com/pologrp under the\npermissive MIT license.\n", "versions": [{"version": "v1", "created": "Mon, 8 Oct 2018 12:58:26 GMT"}], "update_date": "2018-10-09", "authors_parsed": [["Aytekin", "Arda", ""], ["Biel", "Martin", ""], ["Johansson", "Mikael", ""]]}, {"id": "1810.03419", "submitter": "Jitin Kapila", "authors": "Kumarjit Pathak, Jitin Kapila", "title": "Unique Metric for Health Analysis with Optimization of Clustering\n  Activity and Cross Comparison of Results from Different Approach", "comments": "12 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  In machine learning and data mining, Cluster analysis is one of the most\nwidely used unsupervised learning technique. Philosophy of this algorithm is to\nfind similar data items and group them together based on any distance function\nin multidimensional space. These methods are suitable for finding groups of\ndata that behave in a coherent fashion. The perspective may vary for clustering\ni.e. the way we want to find similarity, some methods are based on distance\nsuch as K-Means technique and some are probability based, like GMM.\nUnderstanding prominent segment of data is always challenging as multidimension\nspace does not allow us to have a look and feel of the distance or any visual\ncontext on the health of the clustering.\n  While explaining data using clusters, the major problem is to tell how many\ncluster are good enough to explain the data. Generally basic descriptive\nstatistics are used to estimate cluster behaviour like scree plot, dendrogram\netc. We propose a novel method to understand the cluster behaviour which can be\nused not only to find right number of clusters but can also be used to access\nthe difference of health between different clustering methods on same data. Our\ntechnique would also help to also eliminate the noisy variables and optimize\nthe clustering result.\n  keywords - Clustering, Metric, K-means, hierarchical clustering, silhoutte,\nclustering index, measures\n", "versions": [{"version": "v1", "created": "Mon, 8 Oct 2018 13:10:54 GMT"}], "update_date": "2018-10-09", "authors_parsed": [["Pathak", "Kumarjit", ""], ["Kapila", "Jitin", ""]]}, {"id": "1810.03430", "submitter": "Mohd Zeeshan Ansari", "authors": "Mohd Zeeshan Ansari, Tanvir Ahmad and Md Arshad Ali", "title": "Cross Script Hindi English NER Corpus from Wikipedia", "comments": "International Conference on Intelligent Data Communication\n  Technologies and Internet of Things (ICICI-2018)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The text generated on social media platforms is essentially a mixed lingual\ntext. The mixing of language in any form produces considerable amount of\ndifficulty in language processing systems. Moreover, the advancements in\nlanguage processing research depends upon the availability of standard corpora.\nThe development of mixed lingual Indian Named Entity Recognition (NER) systems\nare facing obstacles due to unavailability of the standard evaluation corpora.\nSuch corpora may be of mixed lingual nature in which text is written using\nmultiple languages predominantly using a single script only. The motivation of\nour work is to emphasize the automatic generation such kind of corpora in order\nto encourage mixed lingual Indian NER. The paper presents the preparation of a\nCross Script Hindi-English Corpora from Wikipedia category pages. The corpora\nis successfully annotated using standard CoNLL-2003 categories of PER, LOC,\nORG, and MISC. Its evaluation is carried out on a variety of machine learning\nalgorithms and favorable results are achieved.\n", "versions": [{"version": "v1", "created": "Mon, 8 Oct 2018 13:25:05 GMT"}], "update_date": "2018-10-09", "authors_parsed": [["Ansari", "Mohd Zeeshan", ""], ["Ahmad", "Tanvir", ""], ["Ali", "Md Arshad", ""]]}, {"id": "1810.03435", "submitter": "Ruibo Tu", "authors": "Charles Hamesse, Ruibo Tu, Paul Ackermann, Hedvig Kjellstr\\\"om, Cheng\n  Zhang", "title": "Simultaneous Measurement Imputation and Outcome Prediction for Achilles\n  Tendon Rupture Rehabilitation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.QM cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Achilles Tendon Rupture (ATR) is one of the typical soft tissue injuries.\nRehabilitation after such a musculoskeletal injury remains a prolonged process\nwith a very variable outcome. Accurately predicting rehabilitation outcome is\ncrucial for treatment decision support. However, it is challenging to train an\nautomatic method for predicting the ATR rehabilitation outcome from treatment\ndata, due to a massive amount of missing entries in the data recorded from ATR\npatients, as well as complex nonlinear relations between measurements and\noutcomes. In this work, we design an end-to-end probabilistic framework to\nimpute missing data entries and predict rehabilitation outcomes simultaneously.\nWe evaluate our model on a real-life ATR clinical cohort, comparing with\nvarious baselines. The proposed method demonstrates its clear superiority over\ntraditional methods which typically perform imputation and prediction in two\nseparate stages.\n", "versions": [{"version": "v1", "created": "Sat, 8 Sep 2018 07:25:12 GMT"}, {"version": "v2", "created": "Tue, 13 Aug 2019 09:10:16 GMT"}], "update_date": "2019-08-14", "authors_parsed": [["Hamesse", "Charles", ""], ["Tu", "Ruibo", ""], ["Ackermann", "Paul", ""], ["Kjellstr\u00f6m", "Hedvig", ""], ["Zhang", "Cheng", ""]]}, {"id": "1810.03442", "submitter": "Assya Trofimov", "authors": "Assya Trofimov, Francis Dutil, Claude Perreault, Sebastien Lemieux,\n  Yoshua Bengio and Joseph Paul Cohen", "title": "Towards the Latent Transcriptome", "comments": "7 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.GN cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this work we propose a method to compute continuous embeddings for kmers\nfrom raw RNA-seq data, without the need for alignment to a reference genome.\nThe approach uses an RNN to transform kmers of the RNA-seq reads into a 2\ndimensional representation that is used to predict abundance of each kmer. We\nreport that our model captures information of both DNA sequence similarity as\nwell as DNA sequence abundance in the embedding latent space, that we call the\nLatent Transcriptome. We confirm the quality of these vectors by comparing them\nto known gene sub-structures and report that the latent space recovers exon\ninformation from raw RNA-Seq data from acute myeloid leukemia patients.\nFurthermore we show that this latent space allows the detection of genomic\nabnormalities such as translocations as well as patient-specific mutations,\nmaking this representation space both useful for visualization as well as\nanalysis.\n", "versions": [{"version": "v1", "created": "Mon, 8 Oct 2018 14:13:22 GMT"}, {"version": "v2", "created": "Mon, 10 Dec 2018 17:46:47 GMT"}], "update_date": "2018-12-11", "authors_parsed": [["Trofimov", "Assya", ""], ["Dutil", "Francis", ""], ["Perreault", "Claude", ""], ["Lemieux", "Sebastien", ""], ["Bengio", "Yoshua", ""], ["Cohen", "Joseph Paul", ""]]}, {"id": "1810.03445", "submitter": "Zhu Gao", "authors": "Zhu Gao, Yanhui Jiang, Junhui Gao", "title": "Building a language evolution tree based on word vector combination\n  model", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we try to explore the evolution of language through case\ncalculations. First, we chose the novels of eleven British writers from 1400 to\n2005 and found the corresponding works; Then, we use the natural language\nprocessing tool to construct the corresponding eleven corpora, and calculate\nthe respective word vectors of 100 high-frequency words in eleven corpora;\nNext, for each corpus, we concatenate the 100 word vectors from beginning to\nend into one; Finally, we use the similarity comparison and hierarchical\nclustering method to generate the relationship tree between the combined eleven\nword vectors. This tree represents the relationship between eleven corpora. We\nfound that in the tree generated by clustering, the distance between the corpus\nand the year corresponding to the corpus are basically the same. This means\nthat we have discovered a specific language evolution tree. To verify the\nstability and versatility of this method, we add three other themes: Dickens's\neight works, the 19th century poets' works, and art criticism of recent 60\nyears. For these four themes, we tested different parameters such as the time\nspan of the corpus, the time interval between the corpora, the dimension of the\nword vector, and the number of high-frequency public words. The results show\nthat this is fairly stable and versatile.\n", "versions": [{"version": "v1", "created": "Thu, 4 Oct 2018 14:25:36 GMT"}], "update_date": "2018-10-09", "authors_parsed": [["Gao", "Zhu", ""], ["Jiang", "Yanhui", ""], ["Gao", "Junhui", ""]]}, {"id": "1810.03449", "submitter": "Shaobo Liu", "authors": "Shaobo Liu and Rui Cheng and Xiaoming Yu and Xueqi Cheng", "title": "Exploiting Contextual Information via Dynamic Memory Network for Event\n  Detection", "comments": "Accepted as short paper by EMNLP 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The task of event detection involves identifying and categorizing event\ntriggers. Contextual information has been shown effective on the task. However,\nexisting methods which utilize contextual information only process the context\nonce. We argue that the context can be better exploited by processing the\ncontext multiple times, allowing the model to perform complex reasoning and to\ngenerate better context representation, thus improving the overall performance.\nMeanwhile, dynamic memory network (DMN) has demonstrated promising capability\nin capturing contextual information and has been applied successfully to\nvarious tasks. In light of the multi-hop mechanism of the DMN to model the\ncontext, we propose the trigger detection dynamic memory network (TD-DMN) to\ntackle the event detection problem. We performed a five-fold cross-validation\non the ACE-2005 dataset and experimental results show that the multi-hop\nmechanism does improve the performance and the proposed model achieves best\n$F_1$ score compared to the state-of-the-art methods.\n", "versions": [{"version": "v1", "created": "Wed, 3 Oct 2018 08:43:11 GMT"}], "update_date": "2018-10-09", "authors_parsed": [["Liu", "Shaobo", ""], ["Cheng", "Rui", ""], ["Yu", "Xiaoming", ""], ["Cheng", "Xueqi", ""]]}, {"id": "1810.03459", "submitter": "Murali Karthick Baskar", "authors": "Jaejin Cho, Murali Karthick Baskar, Ruizhi Li, Matthew Wiesner, Sri\n  Harish Mallidi, Nelson Yalta, Martin Karafiat, Shinji Watanabe, Takaaki Hori", "title": "Multilingual sequence-to-sequence speech recognition: architecture,\n  transfer learning, and language modeling", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG cs.SD eess.AS", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Sequence-to-sequence (seq2seq) approach for low-resource ASR is a relatively\nnew direction in speech research. The approach benefits by performing model\ntraining without using lexicon and alignments. However, this poses a new\nproblem of requiring more data compared to conventional DNN-HMM systems. In\nthis work, we attempt to use data from 10 BABEL languages to build a\nmulti-lingual seq2seq model as a prior model, and then port them towards 4\nother BABEL languages using transfer learning approach. We also explore\ndifferent architectures for improving the prior multilingual seq2seq model. The\npaper also discusses the effect of integrating a recurrent neural network\nlanguage model (RNNLM) with a seq2seq model during decoding. Experimental\nresults show that the transfer learning approach from the multilingual model\nshows substantial gains over monolingual models across all 4 BABEL languages.\nIncorporating an RNNLM also brings significant improvements in terms of %WER,\nand achieves recognition performance comparable to the models trained with\ntwice more training data.\n", "versions": [{"version": "v1", "created": "Thu, 4 Oct 2018 08:53:42 GMT"}], "update_date": "2018-10-09", "authors_parsed": [["Cho", "Jaejin", ""], ["Baskar", "Murali Karthick", ""], ["Li", "Ruizhi", ""], ["Wiesner", "Matthew", ""], ["Mallidi", "Sri Harish", ""], ["Yalta", "Nelson", ""], ["Karafiat", "Martin", ""], ["Watanabe", "Shinji", ""], ["Hori", "Takaaki", ""]]}, {"id": "1810.03463", "submitter": "Akifumi Okuno", "authors": "Akifumi Okuno, Geewook Kim, Hidetoshi Shimodaira", "title": "Graph Embedding with Shifted Inner Product Similarity and Its Improved\n  Approximation Capability", "comments": "20 pages (with Supplementary Material), 2 figures, AISTATS2019. arXiv\n  admin note: text overlap with arXiv:1805.12332", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose shifted inner-product similarity (SIPS), which is a novel yet very\nsimple extension of the ordinary inner-product similarity (IPS) for\nneural-network based graph embedding (GE). In contrast to IPS, that is limited\nto approximating positive-definite (PD) similarities, SIPS goes beyond the\nlimitation by introducing bias terms in IPS; we theoretically prove that SIPS\nis capable of approximating not only PD but also conditionally PD (CPD)\nsimilarities with many examples such as cosine similarity, negative Poincare\ndistance and negative Wasserstein distance. Since SIPS with sufficiently large\nneural networks learns a variety of similarities, SIPS alleviates the need for\nconfiguring the similarity function of GE. Approximation error rate is also\nevaluated, and experiments on two real-world datasets demonstrate that graph\nembedding using SIPS indeed outperforms existing methods.\n", "versions": [{"version": "v1", "created": "Thu, 4 Oct 2018 18:49:03 GMT"}, {"version": "v2", "created": "Fri, 22 Feb 2019 05:39:24 GMT"}], "update_date": "2019-02-25", "authors_parsed": [["Okuno", "Akifumi", ""], ["Kim", "Geewook", ""], ["Shimodaira", "Hidetoshi", ""]]}, {"id": "1810.03466", "submitter": "Kaveh Bastani", "authors": "Kaveh Bastani, Elham Asgari, Hamed Namavari", "title": "Wide and Deep Learning for Peer-to-Peer Lending", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI q-fin.RM", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  This paper proposes a two-stage scoring approach to help lenders decide their\nfund allocations in the peer-to-peer (P2P) lending market. The existing scoring\napproaches focus on only either probability of default (PD) prediction, known\nas credit scoring, or profitability prediction, known as profit scoring, to\nidentify the best loans for investment. Credit scoring fails to deliver the\nmain need of lenders on how much profit they may obtain through their\ninvestment. On the other hand, profit scoring can satisfy that need by\npredicting the investment profitability. However, profit scoring completely\nignores the class imbalance problem where most of the past loans are\nnon-default. Consequently, ignorance of the class imbalance problem\nsignificantly affects the accuracy of profitability prediction. Our proposed\ntwo-stage scoring approach is an integration of credit scoring and profit\nscoring to address the above challenges. More specifically, stage 1 is designed\nas credit scoring to identify non-default loans while the imbalanced nature of\nloan status is considered in PD prediction. The loans identified as non-default\nare then moved to stage 2 for prediction of profitability, measured by internal\nrate of return. Wide and deep learning is used to build the predictive models\nin both stages to achieve both memorization and generalization. Extensive\nnumerical studies are conducted based on real-world data to verify the\neffectiveness of the proposed approach. The numerical studies indicate our\ntwo-stage scoring approach outperforms the existing credit scoring and profit\nscoring approaches.\n", "versions": [{"version": "v1", "created": "Fri, 5 Oct 2018 00:54:06 GMT"}, {"version": "v2", "created": "Tue, 9 Oct 2018 02:03:13 GMT"}], "update_date": "2018-10-10", "authors_parsed": [["Bastani", "Kaveh", ""], ["Asgari", "Elham", ""], ["Namavari", "Hamed", ""]]}, {"id": "1810.03479", "submitter": "Xu Han", "authors": "Xu Han, Hongsu Wang, Sanqian Zhang, Qunchao Fu, Jun S. Liu", "title": "Sentence Segmentation for Classical Chinese Based on LSTM with Radical\n  Embedding", "comments": "The Journal of China Universities of Posts and Telecommunications,\n  2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we develop a low than character feature embedding called\nradical embedding, and apply it on LSTM model for sentence segmentation of pre\nmodern Chinese texts. The datasets includes over 150 classical Chinese books\nfrom 3 different dynasties and contains different literary styles. LSTM CRF\nmodel is a state of art method for the sequence labeling problem. Our new model\nadds a component of radical embedding, which leads to improved performances.\nExperimental results based on the aforementioned Chinese books demonstrates a\nbetter accuracy than earlier methods on sentence segmentation, especial in Tang\nEpitaph texts.\n", "versions": [{"version": "v1", "created": "Fri, 5 Oct 2018 14:49:42 GMT"}], "update_date": "2020-02-20", "authors_parsed": [["Han", "Xu", ""], ["Wang", "Hongsu", ""], ["Zhang", "Sanqian", ""], ["Fu", "Qunchao", ""], ["Liu", "Jun S.", ""]]}, {"id": "1810.03487", "submitter": "Sanghyun Hong", "authors": "Sanghyun Hong, Michael Davinroy, Yi\\v{g}itcan Kaya, Stuart Nevans\n  Locke, Ian Rackow, Kevin Kulda, Dana Dachman-Soled, Tudor Dumitra\\c{s}", "title": "Security Analysis of Deep Neural Networks Operating in the Presence of\n  Cache Side-Channel Attacks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent work has introduced attacks that extract the architecture information\nof deep neural networks (DNN), as this knowledge enhances an adversary's\ncapability to conduct black-box attacks against the model. This paper presents\nthe first in-depth security analysis of DNN fingerprinting attacks that exploit\ncache side-channels. First, we define the threat model for these attacks: our\nadversary does not need the ability to query the victim model; instead, she\nruns a co-located process on the host machine victim's deep learning (DL)\nsystem is running and passively monitors the accesses of the target functions\nin the shared framework. Second, we introduce DeepRecon, an attack that\nreconstructs the architecture of the victim network by using the internal\ninformation extracted via Flush+Reload, a cache side-channel technique. Once\nthe attacker observes function invocations that map directly to architecture\nattributes of the victim network, the attacker can reconstruct the victim's\nentire network architecture. In our evaluation, we demonstrate that an attacker\ncan accurately reconstruct two complex networks (VGG19 and ResNet50) having\nobserved only one forward propagation. Based on the extracted architecture\nattributes, we also demonstrate that an attacker can build a meta-model that\naccurately fingerprints the architecture and family of the pre-trained model in\na transfer learning setting. From this meta-model, we evaluate the importance\nof the observed attributes in the fingerprinting process. Third, we propose and\nevaluate new framework-level defense techniques that obfuscate our attacker's\nobservations. Our empirical security analysis represents a step toward\nunderstanding the DNNs' vulnerability to cache side-channel attacks.\n", "versions": [{"version": "v1", "created": "Mon, 8 Oct 2018 14:21:46 GMT"}, {"version": "v2", "created": "Wed, 28 Nov 2018 05:13:52 GMT"}, {"version": "v3", "created": "Thu, 30 May 2019 02:13:40 GMT"}, {"version": "v4", "created": "Fri, 31 Jan 2020 17:12:52 GMT"}], "update_date": "2020-02-03", "authors_parsed": [["Hong", "Sanghyun", ""], ["Davinroy", "Michael", ""], ["Kaya", "Yi\u01e7itcan", ""], ["Locke", "Stuart Nevans", ""], ["Rackow", "Ian", ""], ["Kulda", "Kevin", ""], ["Dachman-Soled", "Dana", ""], ["Dumitra\u015f", "Tudor", ""]]}, {"id": "1810.03488", "submitter": "Albin Severinson", "authors": "Albin Severinson, Alexandre Graell i Amat, Eirik Rosnes, Francisco\n  Lazaro, and Gianluigi Liva", "title": "A Droplet Approach Based on Raptor Codes for Distributed Computing With\n  Straggling Servers", "comments": "Accepted at the 2018 International Symposium on Turbo Codes &\n  Iterative Information Processing, Hong Kong", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IT cs.DC cs.LG cs.PF math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a coded distributed computing scheme based on Raptor codes to\naddress the straggler problem. In particular, we consider a scheme where each\nserver computes intermediate values, referred to as droplets, that are either\nstored locally or sent over the network. Once enough droplets are collected,\nthe computation can be completed. Compared to previous schemes in the\nliterature, our proposed scheme achieves lower computational delay when the\ndecoding time is taken into account.\n", "versions": [{"version": "v1", "created": "Mon, 8 Oct 2018 14:23:27 GMT"}], "update_date": "2018-10-09", "authors_parsed": [["Severinson", "Albin", ""], ["Amat", "Alexandre Graell i", ""], ["Rosnes", "Eirik", ""], ["Lazaro", "Francisco", ""], ["Liva", "Gianluigi", ""]]}, {"id": "1810.03505", "submitter": "Luke Darlow", "authors": "Luke N. Darlow, Elliot J. Crowley, Antreas Antoniou, Amos J. Storkey", "title": "CINIC-10 is not ImageNet or CIFAR-10", "comments": "Dataset compilation, 9 pages, 11 figures, technical report", "journal-ref": null, "doi": null, "report-no": "EDI-INF-ANC-1802", "categories": "cs.CV cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by-sa/4.0/", "abstract": "  In this brief technical report we introduce the CINIC-10 dataset as a plug-in\nextended alternative for CIFAR-10. It was compiled by combining CIFAR-10 with\nimages selected and downsampled from the ImageNet database. We present the\napproach to compiling the dataset, illustrate the example images for different\nclasses, give pixel distributions for each part of the repository, and give\nsome standard benchmarks for well known models. Details for download, usage,\nand compilation can be found in the associated github repository.\n", "versions": [{"version": "v1", "created": "Tue, 2 Oct 2018 21:20:09 GMT"}], "update_date": "2018-10-09", "authors_parsed": [["Darlow", "Luke N.", ""], ["Crowley", "Elliot J.", ""], ["Antoniou", "Antreas", ""], ["Storkey", "Amos J.", ""]]}, {"id": "1810.03522", "submitter": "Vishnu Naresh Boddeti", "authors": "Zhichao Lu, Ian Whalen, Vishnu Boddeti, Yashesh Dhebar, Kalyanmoy Deb,\n  Erik Goodman and Wolfgang Banzhaf", "title": "NSGA-Net: Neural Architecture Search using Multi-Objective Genetic\n  Algorithm", "comments": "GECCO 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper introduces NSGA-Net -- an evolutionary approach for neural\narchitecture search (NAS). NSGA-Net is designed with three goals in mind: (1) a\nprocedure considering multiple and conflicting objectives, (2) an efficient\nprocedure balancing exploration and exploitation of the space of potential\nneural network architectures, and (3) a procedure finding a diverse set of\ntrade-off network architectures achieved in a single run. NSGA-Net is a\npopulation-based search algorithm that explores a space of potential neural\nnetwork architectures in three steps, namely, a population initialization step\nthat is based on prior-knowledge from hand-crafted architectures, an\nexploration step comprising crossover and mutation of architectures, and\nfinally an exploitation step that utilizes the hidden useful knowledge stored\nin the entire history of evaluated neural architectures in the form of a\nBayesian Network. Experimental results suggest that combining the dual\nobjectives of minimizing an error metric and computational complexity, as\nmeasured by FLOPs, allows NSGA-Net to find competitive neural architectures.\nMoreover, NSGA-Net achieves error rate on the CIFAR-10 dataset on par with\nother state-of-the-art NAS methods while using orders of magnitude less\ncomputational resources. These results are encouraging and shows the promise to\nfurther use of EC methods in various deep-learning paradigms.\n", "versions": [{"version": "v1", "created": "Mon, 8 Oct 2018 15:14:33 GMT"}, {"version": "v2", "created": "Thu, 18 Apr 2019 23:07:16 GMT"}], "update_date": "2019-04-22", "authors_parsed": [["Lu", "Zhichao", ""], ["Whalen", "Ian", ""], ["Boddeti", "Vishnu", ""], ["Dhebar", "Yashesh", ""], ["Deb", "Kalyanmoy", ""], ["Goodman", "Erik", ""], ["Banzhaf", "Wolfgang", ""]]}, {"id": "1810.03527", "submitter": "Jinwoong Kim", "authors": "Jinwoong Kim, Minkyu Kim, Heungseok Park, Ernar Kusdavletov, Dongjun\n  Lee, Adrian Kim, Ji-Hoon Kim, Jung-Woo Ha, Nako Sung", "title": "CHOPT : Automated Hyperparameter Optimization Framework for Cloud-Based\n  Machine Learning Platforms", "comments": "10 pages, 9 figures. arXiv admin note: text overlap with\n  arXiv:1807.01774 by other authors", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Many hyperparameter optimization (HyperOpt) methods assume restricted\ncomputing resources and mainly focus on enhancing performance. Here we propose\na novel cloud-based HyperOpt (CHOPT) framework which can efficiently utilize\nshared computing resources while supporting various HyperOpt algorithms. We\nincorporate convenient web-based user interfaces, visualization, and analysis\ntools, enabling users to easily control optimization procedures and build up\nvaluable insights with an iterative analysis procedure. Furthermore, our\nframework can be incorporated with any cloud platform, thus complementarily\nincreasing the efficiency of conventional deep learning frameworks. We\ndemonstrate applications of CHOPT with tasks such as image recognition and\nquestion-answering, showing that our framework can find hyperparameter\nconfigurations competitive with previous work. We also show CHOPT is capable of\nproviding interesting observations through its analysing tools\n", "versions": [{"version": "v1", "created": "Mon, 8 Oct 2018 15:24:23 GMT"}, {"version": "v2", "created": "Tue, 16 Oct 2018 08:06:52 GMT"}], "update_date": "2018-10-17", "authors_parsed": [["Kim", "Jinwoong", ""], ["Kim", "Minkyu", ""], ["Park", "Heungseok", ""], ["Kusdavletov", "Ernar", ""], ["Lee", "Dongjun", ""], ["Kim", "Adrian", ""], ["Kim", "Ji-Hoon", ""], ["Ha", "Jung-Woo", ""], ["Sung", "Nako", ""]]}, {"id": "1810.03530", "submitter": "Michael Kamp", "authors": "Michael Kamp and Mario Boley and Olana Missura and Thomas G\\\"artner", "title": "Effective Parallelisation for Machine Learning", "comments": "Advances in Neural Information Processing Systems, 2017", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.DC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a novel parallelisation scheme that simplifies the adaptation of\nlearning algorithms to growing amounts of data as well as growing needs for\naccurate and confident predictions in critical applications. In contrast to\nother parallelisation techniques, it can be applied to a broad class of\nlearning algorithms without further mathematical derivations and without\nwriting dedicated code, while at the same time maintaining theoretical\nperformance guarantees. Moreover, our parallelisation scheme is able to reduce\nthe runtime of many learning algorithms to polylogarithmic time on\nquasi-polynomially many processing units. This is a significant step towards a\ngeneral answer to an open question on the efficient parallelisation of machine\nlearning algorithms in the sense of Nick's Class (NC). The cost of this\nparallelisation is in the form of a larger sample complexity. Our empirical\nstudy confirms the potential of our parallelisation scheme with fixed numbers\nof processors and instances in realistic application scenarios.\n", "versions": [{"version": "v1", "created": "Mon, 8 Oct 2018 15:35:07 GMT"}], "update_date": "2018-10-09", "authors_parsed": [["Kamp", "Michael", ""], ["Boley", "Mario", ""], ["Missura", "Olana", ""], ["G\u00e4rtner", "Thomas", ""]]}, {"id": "1810.03538", "submitter": "Elias Khalil", "authors": "Elias B. Khalil, Amrita Gupta, Bistra Dilkina", "title": "Combinatorial Attacks on Binarized Neural Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Binarized Neural Networks (BNNs) have recently attracted significant interest\ndue to their computational efficiency. Concurrently, it has been shown that\nneural networks may be overly sensitive to \"attacks\" - tiny adversarial changes\nin the input - which may be detrimental to their use in safety-critical\ndomains. Designing attack algorithms that effectively fool trained models is a\nkey step towards learning robust neural networks. The discrete,\nnon-differentiable nature of BNNs, which distinguishes them from their\nfull-precision counterparts, poses a challenge to gradient-based attacks. In\nthis work, we study the problem of attacking a BNN through the lens of\ncombinatorial and integer optimization. We propose a Mixed Integer Linear\nProgramming (MILP) formulation of the problem. While exact and flexible, the\nMILP quickly becomes intractable as the network and perturbation space grow. To\naddress this issue, we propose IProp, a decomposition-based algorithm that\nsolves a sequence of much smaller MILP problems. Experimentally, we evaluate\nboth proposed methods against the standard gradient-based attack (FGSM) on\nMNIST and Fashion-MNIST, and show that IProp performs favorably compared to\nFGSM, while scaling beyond the limits of the MILP.\n", "versions": [{"version": "v1", "created": "Mon, 8 Oct 2018 15:51:23 GMT"}], "update_date": "2018-10-09", "authors_parsed": [["Khalil", "Elias B.", ""], ["Gupta", "Amrita", ""], ["Dilkina", "Bistra", ""]]}, {"id": "1810.03545", "submitter": "Guang Cheng", "authors": "Tianyang Hu, Zixiang Chen, Hanxi Sun, Jincheng Bai, Mao Ye, Guang\n  Cheng", "title": "Stein Neural Sampler", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose two novel samplers to generate high-quality samples from a given\n(un-normalized) probability density. Motivated by the success of generative\nadversarial networks, we construct our samplers using deep neural networks that\ntransform a reference distribution to the target distribution. Training schemes\nare developed to minimize two variations of the Stein discrepancy, which is\ndesigned to work with un-normalized densities. Once trained, our samplers are\nable to generate samples instantaneously. We show that the proposed methods are\ntheoretically sound and experience fewer convergence issues compared with\ntraditional sampling approaches according to our empirical studies.\n", "versions": [{"version": "v1", "created": "Mon, 8 Oct 2018 16:06:40 GMT"}, {"version": "v2", "created": "Tue, 9 Feb 2021 02:57:54 GMT"}], "update_date": "2021-02-10", "authors_parsed": [["Hu", "Tianyang", ""], ["Chen", "Zixiang", ""], ["Sun", "Hanxi", ""], ["Bai", "Jincheng", ""], ["Ye", "Mao", ""], ["Cheng", "Guang", ""]]}, {"id": "1810.03548", "submitter": "Joaquin Vanschoren", "authors": "Joaquin Vanschoren", "title": "Meta-Learning: A Survey", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Meta-learning, or learning to learn, is the science of systematically\nobserving how different machine learning approaches perform on a wide range of\nlearning tasks, and then learning from this experience, or meta-data, to learn\nnew tasks much faster than otherwise possible. Not only does this dramatically\nspeed up and improve the design of machine learning pipelines or neural\narchitectures, it also allows us to replace hand-engineered algorithms with\nnovel approaches learned in a data-driven way. In this chapter, we provide an\noverview of the state of the art in this fascinating and continuously evolving\nfield.\n", "versions": [{"version": "v1", "created": "Mon, 8 Oct 2018 16:07:11 GMT"}], "update_date": "2018-10-09", "authors_parsed": [["Vanschoren", "Joaquin", ""]]}, {"id": "1810.03552", "submitter": "Xilun Chen", "authors": "Xilun Chen, Ahmed Hassan Awadallah, Hany Hassan, Wei Wang, Claire\n  Cardie", "title": "Multi-Source Cross-Lingual Model Transfer: Learning What to Share", "comments": "ACL 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Modern NLP applications have enjoyed a great boost utilizing neural networks\nmodels. Such deep neural models, however, are not applicable to most human\nlanguages due to the lack of annotated training data for various NLP tasks.\nCross-lingual transfer learning (CLTL) is a viable method for building NLP\nmodels for a low-resource target language by leveraging labeled data from other\n(source) languages. In this work, we focus on the multilingual transfer setting\nwhere training data in multiple source languages is leveraged to further boost\ntarget language performance.\n  Unlike most existing methods that rely only on language-invariant features\nfor CLTL, our approach coherently utilizes both language-invariant and\nlanguage-specific features at instance level. Our model leverages adversarial\nnetworks to learn language-invariant features, and mixture-of-experts models to\ndynamically exploit the similarity between the target language and each\nindividual source language. This enables our model to learn effectively what to\nshare between various languages in the multilingual setup. Moreover, when\ncoupled with unsupervised multilingual embeddings, our model can operate in a\nzero-resource setting where neither target language training data nor\ncross-lingual resources are available. Our model achieves significant\nperformance gains over prior art, as shown in an extensive set of experiments\nover multiple text classification and sequence tagging tasks including a\nlarge-scale industry dataset.\n", "versions": [{"version": "v1", "created": "Mon, 8 Oct 2018 16:11:01 GMT"}, {"version": "v2", "created": "Mon, 3 Dec 2018 17:06:49 GMT"}, {"version": "v3", "created": "Wed, 5 Jun 2019 04:04:07 GMT"}], "update_date": "2019-06-06", "authors_parsed": [["Chen", "Xilun", ""], ["Awadallah", "Ahmed Hassan", ""], ["Hassan", "Hany", ""], ["Wang", "Wei", ""], ["Cardie", "Claire", ""]]}, {"id": "1810.03587", "submitter": "Chinmay Hegde", "authors": "Chinmay Hegde", "title": "Algorithmic Aspects of Inverse Problems Using Generative Models", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  The traditional approach of hand-crafting priors (such as sparsity) for\nsolving inverse problems is slowly being replaced by the use of richer learned\npriors (such as those modeled by generative adversarial networks, or GANs). In\nthis work, we study the algorithmic aspects of such a learning-based approach\nfrom a theoretical perspective. For certain generative network architectures,\nwe establish a simple non-convex algorithmic approach that (a) theoretically\nenjoys linear convergence guarantees for certain inverse problems, and (b)\nempirically improves upon conventional techniques such as back-propagation. We\nalso propose an extension of our approach that can handle model mismatch (i.e.,\nsituations where the generative network prior is not exactly applicable.)\nTogether, our contributions serve as building blocks towards a more complete\nalgorithmic understanding of generative models in inverse problems.\n", "versions": [{"version": "v1", "created": "Mon, 8 Oct 2018 17:29:47 GMT"}], "update_date": "2018-10-09", "authors_parsed": [["Hegde", "Chinmay", ""]]}, {"id": "1810.03594", "submitter": "Yawei Zhao", "authors": "Yawei Zhao and Shuang Qiu and Ji Liu", "title": "Proximal Online Gradient is Optimum for Dynamic Regret", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In online learning, the dynamic regret metric chooses the reference (optimal)\nsolution that may change over time, while the typical (static) regret metric\nassumes the reference solution to be constant over the whole time horizon. The\ndynamic regret metric is particularly interesting for applications such as\nonline recommendation (since the customers' preference always evolves over\ntime). While the online gradient method has been shown to be optimal for the\nstatic regret metric, the optimal algorithm for the dynamic regret remains\nunknown. In this paper, we show that proximal online gradient (a general\nversion of online gradient) is optimum to the dynamic regret by showing that\nthe proved lower bound matches the upper bound that slightly improves existing\nupper bound.\n", "versions": [{"version": "v1", "created": "Mon, 8 Oct 2018 17:43:50 GMT"}, {"version": "v2", "created": "Tue, 23 Oct 2018 03:53:08 GMT"}, {"version": "v3", "created": "Fri, 23 Nov 2018 15:16:34 GMT"}, {"version": "v4", "created": "Wed, 23 Jan 2019 22:04:17 GMT"}, {"version": "v5", "created": "Thu, 8 Aug 2019 22:03:37 GMT"}, {"version": "v6", "created": "Tue, 3 Sep 2019 17:37:55 GMT"}], "update_date": "2019-09-04", "authors_parsed": [["Zhao", "Yawei", ""], ["Qiu", "Shuang", ""], ["Liu", "Ji", ""]]}, {"id": "1810.03599", "submitter": "Xue Bin Peng", "authors": "Xue Bin Peng, Angjoo Kanazawa, Jitendra Malik, Pieter Abbeel, Sergey\n  Levine", "title": "SFV: Reinforcement Learning of Physical Skills from Videos", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.GR cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Data-driven character animation based on motion capture can produce highly\nnaturalistic behaviors and, when combined with physics simulation, can provide\nfor natural procedural responses to physical perturbations, environmental\nchanges, and morphological discrepancies. Motion capture remains the most\npopular source of motion data, but collecting mocap data typically requires\nheavily instrumented environments and actors. In this paper, we propose a\nmethod that enables physically simulated characters to learn skills from videos\n(SFV). Our approach, based on deep pose estimation and deep reinforcement\nlearning, allows data-driven animation to leverage the abundance of publicly\navailable video clips from the web, such as those from YouTube. This has the\npotential to enable fast and easy design of character controllers simply by\nquerying for video recordings of the desired behavior. The resulting\ncontrollers are robust to perturbations, can be adapted to new settings, can\nperform basic object interactions, and can be retargeted to new morphologies\nvia reinforcement learning. We further demonstrate that our method can predict\npotential human motions from still images, by forward simulation of learned\ncontrollers initialized from the observed pose. Our framework is able to learn\na broad range of dynamic skills, including locomotion, acrobatics, and martial\narts.\n", "versions": [{"version": "v1", "created": "Mon, 8 Oct 2018 17:55:39 GMT"}, {"version": "v2", "created": "Mon, 15 Oct 2018 17:15:34 GMT"}], "update_date": "2018-10-16", "authors_parsed": [["Peng", "Xue Bin", ""], ["Kanazawa", "Angjoo", ""], ["Malik", "Jitendra", ""], ["Abbeel", "Pieter", ""], ["Levine", "Sergey", ""]]}, {"id": "1810.03608", "submitter": "Yuan Yao", "authors": "Chendi Huang and Yuan Yao", "title": "A Unified Dynamic Approach to Sparse Model Selection", "comments": "24 pages", "journal-ref": "Proceedings of the 21st International Conference on Artificial\n  Intelligence and Statistics (AISTATS) 2018, Lanzarote, Spain. PMLR: Volume 84", "doi": null, "report-no": null, "categories": "stat.ML cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Sparse model selection is ubiquitous from linear regression to graphical\nmodels where regularization paths, as a family of estimators upon the\nregularization parameter varying, are computed when the regularization\nparameter is unknown or decided data-adaptively. Traditional computational\nmethods rely on solving a set of optimization problems where the regularization\nparameters are fixed on a grid that might be inefficient. In this paper, we\nintroduce a simple iterative regularization path, which follows the dynamics of\na sparse Mirror Descent algorithm or a generalization of Linearized Bregman\nIterations with nonlinear loss. Its performance is competitive to\n\\texttt{glmnet} with a further bias reduction. A path consistency theory is\npresented that under the Restricted Strong Convexity (RSC) and the\nIrrepresentable Condition (IRR), the path will first evolve in a subspace with\nno false positives and reach an estimator that is sign-consistent or of minimax\noptimal $\\ell_2$ error rate. Early stopping regularization is required to\nprevent overfitting. Application examples are given in sparse logistic\nregression and Ising models for NIPS coauthorship.\n", "versions": [{"version": "v1", "created": "Mon, 8 Oct 2018 13:02:02 GMT"}], "update_date": "2018-10-10", "authors_parsed": [["Huang", "Chendi", ""], ["Yao", "Yuan", ""]]}, {"id": "1810.03611", "submitter": "Marc-Etienne Brunet", "authors": "Marc-Etienne Brunet, Colleen Alkalay-Houlihan, Ashton Anderson,\n  Richard Zemel", "title": "Understanding the Origins of Bias in Word Embeddings", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CY stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The power of machine learning systems not only promises great technical\nprogress, but risks societal harm. As a recent example, researchers have shown\nthat popular word embedding algorithms exhibit stereotypical biases, such as\ngender bias. The widespread use of these algorithms in machine learning\nsystems, from automated translation services to curriculum vitae scanners, can\namplify stereotypes in important contexts. Although methods have been developed\nto measure these biases and alter word embeddings to mitigate their biased\nrepresentations, there is a lack of understanding in how word embedding bias\ndepends on the training data. In this work, we develop a technique for\nunderstanding the origins of bias in word embeddings. Given a word embedding\ntrained on a corpus, our method identifies how perturbing the corpus will\naffect the bias of the resulting embedding. This can be used to trace the\norigins of word embedding bias back to the original training documents. Using\nour method, one can investigate trends in the bias of the underlying corpus and\nidentify subsets of documents whose removal would most reduce bias. We\ndemonstrate our techniques on both a New York Times and Wikipedia corpus and\nfind that our influence function-based approximations are very accurate.\n", "versions": [{"version": "v1", "created": "Mon, 8 Oct 2018 18:00:00 GMT"}, {"version": "v2", "created": "Fri, 7 Jun 2019 18:26:54 GMT"}], "update_date": "2019-06-11", "authors_parsed": [["Brunet", "Marc-Etienne", ""], ["Alkalay-Houlihan", "Colleen", ""], ["Anderson", "Ashton", ""], ["Zemel", "Richard", ""]]}, {"id": "1810.03642", "submitter": "Luisa Zintgraf", "authors": "Luisa M Zintgraf, Kyriacos Shiarlis, Vitaly Kurin, Katja Hofmann,\n  Shimon Whiteson", "title": "Fast Context Adaptation via Meta-Learning", "comments": "Published at the International Conference on Machine Learning (ICML)\n  2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose CAVIA for meta-learning, a simple extension to MAML that is less\nprone to meta-overfitting, easier to parallelise, and more interpretable. CAVIA\npartitions the model parameters into two parts: context parameters that serve\nas additional input to the model and are adapted on individual tasks, and\nshared parameters that are meta-trained and shared across tasks. At test time,\nonly the context parameters are updated, leading to a low-dimensional task\nrepresentation. We show empirically that CAVIA outperforms MAML for regression,\nclassification, and reinforcement learning. Our experiments also highlight\nweaknesses in current benchmarks, in that the amount of adaptation needed in\nsome cases is small.\n", "versions": [{"version": "v1", "created": "Mon, 8 Oct 2018 18:11:01 GMT"}, {"version": "v2", "created": "Fri, 12 Oct 2018 13:38:19 GMT"}, {"version": "v3", "created": "Wed, 30 Jan 2019 14:06:01 GMT"}, {"version": "v4", "created": "Mon, 10 Jun 2019 17:17:53 GMT"}], "update_date": "2019-06-11", "authors_parsed": [["Zintgraf", "Luisa M", ""], ["Shiarlis", "Kyriacos", ""], ["Kurin", "Vitaly", ""], ["Hofmann", "Katja", ""], ["Whiteson", "Shimon", ""]]}, {"id": "1810.03652", "submitter": "Camila P.S. Tautenhain", "authors": "Camila P.S. Tautenhain and Mari\\'a C.V. Nascimento", "title": "An ensemble based on a bi-objective evolutionary spectral algorithm for\n  graph clustering", "comments": "Preprint accepted for publication in Expert Systems with Applications", "journal-ref": null, "doi": "10.1016/j.eswa.2019.112911", "report-no": null, "categories": "cs.SI cs.LG cs.NE physics.soc-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Graph clustering is a challenging pattern recognition problem whose goal is\nto identify vertex partitions with high intra-group connectivity. This paper\ninvestigates a bi-objective problem that maximizes the number of intra-cluster\nedges of a graph and minimizes the expected number of inter-cluster edges in a\nrandom graph with the same degree sequence as the original one. The difference\nbetween the two investigated objectives is the definition of the well-known\nmeasure of graph clustering quality: the modularity. We introduce a spectral\ndecomposition hybridized with an evolutionary heuristic, called MOSpecG, to\napproach this bi-objective problem and an ensemble strategy to consolidate the\nsolutions found by MOSpecG into a final robust partition. The results of\ncomputational experiments with real and artificial LFR networks demonstrated a\nsignificant improvement in the results and performance of the introduced method\nin regard to another bi-objective algorithm found in the literature. The\ncrossover operator based on the geometric interpretation of the modularity\nmaximization problem to match the communities of a pair of individuals was of\nutmost importance for the good performance of MOSpecG. Hybridizing spectral\ngraph theory and intelligent systems allowed us to define significantly\nhigh-quality community structures.\n", "versions": [{"version": "v1", "created": "Mon, 8 Oct 2018 18:36:19 GMT"}, {"version": "v2", "created": "Sun, 8 Sep 2019 14:50:07 GMT"}], "update_date": "2019-09-10", "authors_parsed": [["Tautenhain", "Camila P. S.", ""], ["Nascimento", "Mari\u00e1 C. V.", ""]]}, {"id": "1810.03679", "submitter": "Amit Prasad", "authors": "Amit Prasad and Ivana Dusparic", "title": "Multi-agent Deep Reinforcement Learning for Zero Energy Communities", "comments": "Accepted at ISGT Europe 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.MA stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Advances in renewable energy generation and introduction of the government\ntargets to improve energy efficiency gave rise to a concept of a Zero Energy\nBuilding (ZEB). A ZEB is a building whose net energy usage over a year is zero,\ni.e., its energy use is not larger than its overall renewables generation. A\ncollection of ZEBs forms a Zero Energy Community (ZEC). This paper addresses\nthe problem of energy sharing in such a community. This is different from\npreviously addressed energy sharing between buildings as our focus is on the\nimprovement of community energy status, while traditionally research focused on\nreducing losses due to transmission and storage, or achieving economic gains.\nWe model this problem in a multi-agent environment and propose a Deep\nReinforcement Learning (DRL) based solution. Each building is represented by an\nintelligent agent that learns over time the appropriate behaviour to share\nenergy. We have evaluated the proposed solution in a multi-agent simulation\nbuilt using osBrain. Results indicate that with time agents learn to\ncollaborate and learn a policy comparable to the optimal policy, which in turn\nimproves the ZEC's energy status. Buildings with no renewables preferred to\nrequest energy from their neighbours rather than from the supply grid.\n", "versions": [{"version": "v1", "created": "Mon, 8 Oct 2018 19:58:46 GMT"}, {"version": "v2", "created": "Thu, 27 Jun 2019 15:10:27 GMT"}], "update_date": "2019-06-28", "authors_parsed": [["Prasad", "Amit", ""], ["Dusparic", "Ivana", ""]]}, {"id": "1810.03695", "submitter": "Chen Zhong", "authors": "Chen Zhong, Ziyang Lu, M. Cenk Gursoy, Senem Velipasalar", "title": "Actor-Critic Deep Reinforcement Learning for Dynamic Multichannel Access", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IT cs.LG math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the dynamic multichannel access problem, which can be formulated\nas a partially observable Markov decision process (POMDP). We first propose a\nmodel-free actor-critic deep reinforcement learning based framework to explore\nthe sensing policy. To evaluate the performance of the proposed sensing policy\nand the framework's tolerance against uncertainty, we test the framework in\nscenarios with different channel switching patterns and consider different\nswitching probabilities. Then, we consider a time-varying environment to\nidentify the adaptive ability of the proposed framework. Additionally, we\nprovide comparisons with the Deep-Q network (DQN) based framework proposed in\n[1], in terms of both average reward and the time efficiency.\n", "versions": [{"version": "v1", "created": "Mon, 8 Oct 2018 20:59:39 GMT"}], "update_date": "2018-10-10", "authors_parsed": [["Zhong", "Chen", ""], ["Lu", "Ziyang", ""], ["Gursoy", "M. Cenk", ""], ["Velipasalar", "Senem", ""]]}, {"id": "1810.03711", "submitter": "Luigi Freda", "authors": "Luigi Freda and Mario Gianni and Fiora Pirri", "title": "A Hybrid Approach for Trajectory Control Design", "comments": "9 pages, 11 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  This work presents a methodology to design trajectory tracking feedback\ncontrol laws, which embed non-parametric statistical models, such as Gaussian\nProcesses (GPs). The aim is to minimize unmodeled dynamics such as undesired\nslippages. The proposed approach has the benefit of avoiding complex\nterramechanics analysis to directly estimate from data the robot dynamics on a\nwide class of trajectories. Experiments in both real and simulated environments\nprove that the proposed methodology is promising.\n", "versions": [{"version": "v1", "created": "Mon, 8 Oct 2018 21:40:07 GMT"}, {"version": "v2", "created": "Sat, 5 Jan 2019 10:15:13 GMT"}], "update_date": "2019-01-08", "authors_parsed": [["Freda", "Luigi", ""], ["Gianni", "Mario", ""], ["Pirri", "Fiora", ""]]}, {"id": "1810.03714", "submitter": "David Brookes", "authors": "David H. Brookes and Jennifer Listgarten", "title": "Design by adaptive sampling", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG q-bio.QM stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a probabilistic modeling framework and adaptive sampling algorithm\nwherein unsupervised generative models are combined with black box predictive\nmodels to tackle the problem of input design. In input design, one is given one\nor more stochastic \"oracle\" predictive functions, each of which maps from the\ninput design space (e.g. DNA sequences or images) to a distribution over a\nproperty of interest (e.g. protein fluorescence or image content). Given such\nstochastic oracles, the problem is to find an input that is expected to\nmaximize one or more properties, or to achieve a specified value of one or more\nproperties, or any combination thereof. We demonstrate experimentally that our\napproach substantially outperforms other recently presented methods for\ntackling a specific version of this problem, namely, maximization when the\noracle is assumed to be deterministic and unbiased. We also demonstrate that\nour method can tackle more general versions of the problem.\n", "versions": [{"version": "v1", "created": "Mon, 8 Oct 2018 21:47:11 GMT"}, {"version": "v2", "created": "Wed, 10 Oct 2018 00:30:22 GMT"}, {"version": "v3", "created": "Wed, 31 Oct 2018 23:01:28 GMT"}, {"version": "v4", "created": "Mon, 10 Feb 2020 19:42:55 GMT"}], "update_date": "2020-02-12", "authors_parsed": [["Brookes", "David H.", ""], ["Listgarten", "Jennifer", ""]]}, {"id": "1810.03728", "submitter": "Emilien Dupont", "authors": "Emilien Dupont, Suhas Suresha", "title": "Probabilistic Semantic Inpainting with Pixel Constrained CNNs", "comments": "AISTATS camera ready version", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Semantic inpainting is the task of inferring missing pixels in an image given\nsurrounding pixels and high level image semantics. Most semantic inpainting\nalgorithms are deterministic: given an image with missing regions, a single\ninpainted image is generated. However, there are often several plausible\ninpaintings for a given missing region. In this paper, we propose a method to\nperform probabilistic semantic inpainting by building a model, based on\nPixelCNNs, that learns a distribution of images conditioned on a subset of\nvisible pixels. Experiments on the MNIST and CelebA datasets show that our\nmethod produces diverse and realistic inpaintings.\n", "versions": [{"version": "v1", "created": "Mon, 8 Oct 2018 22:19:08 GMT"}, {"version": "v2", "created": "Sat, 23 Feb 2019 22:38:27 GMT"}], "update_date": "2019-02-26", "authors_parsed": [["Dupont", "Emilien", ""], ["Suresha", "Suhas", ""]]}, {"id": "1810.03730", "submitter": "Rui Zhang", "authors": "Rui Zhang, Christian Walder, Marian-Andrei Rizoiu, Lexing Xie", "title": "Efficient Non-parametric Bayesian Hawkes Processes", "comments": "IJCAI2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we develop an efficient nonparametric Bayesian estimation of\nthe kernel function of Hawkes processes. The non-parametric Bayesian approach\nis important because it provides flexible Hawkes kernels and quantifies their\nuncertainty. Our method is based on the cluster representation of Hawkes\nprocesses. Utilizing the stationarity of the Hawkes process, we efficiently\nsample random branching structures and thus, we split the Hawkes process into\nclusters of Poisson processes. We derive two algorithms -- a block Gibbs\nsampler and a maximum a posteriori estimator based on expectation maximization\n-- and we show that our methods have a linear time complexity, both\ntheoretically and empirically. On synthetic data, we show our methods to be\nable to infer flexible Hawkes triggering kernels. On two large-scale Twitter\ndiffusion datasets, we show that our methods outperform the current\nstate-of-the-art in goodness-of-fit and that the time complexity is linear in\nthe size of the dataset. We also observe that on diffusions related to online\nvideos, the learned kernels reflect the perceived longevity for different\ncontent types such as music or pets videos.\n", "versions": [{"version": "v1", "created": "Mon, 8 Oct 2018 22:21:49 GMT"}, {"version": "v2", "created": "Sat, 13 Oct 2018 00:38:46 GMT"}, {"version": "v3", "created": "Sat, 25 May 2019 05:22:56 GMT"}, {"version": "v4", "created": "Thu, 24 Jun 2021 08:05:34 GMT"}], "update_date": "2021-06-25", "authors_parsed": [["Zhang", "Rui", ""], ["Walder", "Christian", ""], ["Rizoiu", "Marian-Andrei", ""], ["Xie", "Lexing", ""]]}, {"id": "1810.03733", "submitter": "Shashanka Ubaru", "authors": "Shashanka Ubaru, Abd-Krim Seghouane, and Yousef Saad", "title": "Find the dimension that counts: Fast dimension estimation and Krylov PCA", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NA cs.LG math.NA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  High dimensional data and systems with many degrees of freedom are often\ncharacterized by covariance matrices. In this paper, we consider the problem of\nsimultaneously estimating the dimension of the principal (dominant) subspace of\nthese covariance matrices and obtaining an approximation to the subspace. This\nproblem arises in the popular principal component analysis (PCA), and in many\napplications of machine learning, data analysis, signal and image processing,\nand others. We first present a novel method for estimating the dimension of the\nprincipal subspace. We then show how this method can be coupled with a Krylov\nsubspace method to simultaneously estimate the dimension and obtain an\napproximation to the subspace. The dimension estimation is achieved at no\nadditional cost. The proposed method operates on a model selection framework,\nwhere the novel selection criterion is derived based on random matrix\nperturbation theory ideas. We present theoretical analyses which (a) show that\nthe proposed method achieves strong consistency (i.e., yields optimal solution\nas the number of data-points $n\\rightarrow \\infty$), and (b) analyze conditions\nfor exact dimension estimation in the finite $n$ case. Using recent results, we\nshow that our algorithm also yields near optimal PCA. The proposed method\navoids forming the sample covariance matrix (associated with the data)\nexplicitly and computing the complete eigen-decomposition. Therefore, the\nmethod is inexpensive, which is particularly advantageous in modern data\napplications where the covariance matrices can be very large. Numerical\nexperiments illustrate the performance of the proposed method in various\napplications.\n", "versions": [{"version": "v1", "created": "Mon, 8 Oct 2018 22:44:44 GMT"}], "update_date": "2018-10-10", "authors_parsed": [["Ubaru", "Shashanka", ""], ["Seghouane", "Abd-Krim", ""], ["Saad", "Yousef", ""]]}, {"id": "1810.03736", "submitter": "Lewis Hammond", "authors": "Lewis Hammond and Vaishak Belle", "title": "Learning Tractable Probabilistic Models for Moral Responsibility and\n  Blame", "comments": "Published in Data Mining and Knowledge Discovery (2021)", "journal-ref": null, "doi": "10.1007/s10618-020-00726-4", "report-no": null, "categories": "cs.AI cs.LG cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Moral responsibility is a major concern in autonomous systems, with\napplications ranging from self-driving cars to kidney exchanges. Although there\nhave been recent attempts to formalise responsibility and blame, among similar\nnotions, the problem of learning within these formalisms has been unaddressed.\nFrom the viewpoint of such systems, the urgent questions are: (a) How can\nmodels of moral scenarios and blameworthiness be extracted and learnt\nautomatically from data? (b) How can judgements be computed effectively and\nefficiently, given the split-second decision points faced by some systems? By\nbuilding on constrained tractable probabilistic learning, we propose and\nimplement a hybrid (between data-driven and rule-based methods) learning\nframework for inducing models of such scenarios automatically from data and\nreasoning tractably from them. We report on experiments that compare our system\nwith human judgement in three illustrative domains: lung cancer staging,\nteamwork management, and trolley problems.\n", "versions": [{"version": "v1", "created": "Mon, 8 Oct 2018 22:51:17 GMT"}, {"version": "v2", "created": "Thu, 4 Jul 2019 18:09:05 GMT"}, {"version": "v3", "created": "Sat, 30 Jan 2021 19:37:58 GMT"}], "update_date": "2021-02-02", "authors_parsed": [["Hammond", "Lewis", ""], ["Belle", "Vaishak", ""]]}, {"id": "1810.03739", "submitter": "Ting-Jui Chang", "authors": "Ting-Jui Chang, Yukun He, Peng Li", "title": "Efficient Two-Step Adversarial Defense for Deep Neural Networks", "comments": "12 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In recent years, deep neural networks have demonstrated outstanding\nperformance in many machine learning tasks. However, researchers have\ndiscovered that these state-of-the-art models are vulnerable to adversarial\nexamples: legitimate examples added by small perturbations which are\nunnoticeable to human eyes. Adversarial training, which augments the training\ndata with adversarial examples during the training process, is a well known\ndefense to improve the robustness of the model against adversarial attacks.\nHowever, this robustness is only effective to the same attack method used for\nadversarial training. Madry et al.(2017) suggest that effectiveness of\niterative multi-step adversarial attacks and particularly that projected\ngradient descent (PGD) may be considered the universal first order adversary\nand applying the adversarial training with PGD implies resistance against many\nother first order attacks. However, the computational cost of the adversarial\ntraining with PGD and other multi-step adversarial examples is much higher than\nthat of the adversarial training with other simpler attack techniques. In this\npaper, we show how strong adversarial examples can be generated only at a cost\nsimilar to that of two runs of the fast gradient sign method (FGSM), allowing\ndefense against adversarial attacks with a robustness level comparable to that\nof the adversarial training with multi-step adversarial examples. We\nempirically demonstrate the effectiveness of the proposed two-step defense\napproach against different attack methods and its improvements over existing\ndefense strategies.\n", "versions": [{"version": "v1", "created": "Mon, 8 Oct 2018 23:00:06 GMT"}], "update_date": "2018-10-10", "authors_parsed": [["Chang", "Ting-Jui", ""], ["He", "Yukun", ""], ["Li", "Peng", ""]]}, {"id": "1810.03743", "submitter": "LuoLuo Liu", "authors": "Luoluo Liu, Sang Peter Chin, Trac D. Tran", "title": "JOBS: Joint-Sparse Optimization from Bootstrap Samples", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG eess.SP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Classical signal recovery based on $\\ell_1$ minimization solves the least\nsquares problem with all available measurements via sparsity-promoting\nregularization. In practice, it is often the case that not all measurements are\navailable or required for recovery. Measurements might be corrupted/missing or\nthey arrive sequentially in streaming fashion. In this paper, we propose a\nglobal sparse recovery strategy based on subsets of measurements, named JOBS,\nin which multiple measurements vectors are generated from the original pool of\nmeasurements via bootstrapping, and then a joint-sparse constraint is enforced\nto ensure support consistency among multiple predictors. The final estimate is\nobtained by averaging over the $K$ predictors. The performance limits\nassociated with different choices of number of bootstrap samples $L$ and number\nof estimates $K$ is analyzed theoretically. Simulation results validate some of\nthe theoretical analysis, and show that the proposed method yields\nstate-of-the-art recovery performance, outperforming $\\ell_1$ minimization and\na few other existing bootstrap-based techniques in the challenging case of low\nlevels of measurements and is preferable over other bagging-based methods in\nthe streaming setting since it performs better with small $K$ and $L$ for\ndata-sets with large sizes.\n", "versions": [{"version": "v1", "created": "Mon, 8 Oct 2018 23:24:22 GMT"}, {"version": "v2", "created": "Tue, 11 Dec 2018 02:34:29 GMT"}], "update_date": "2018-12-12", "authors_parsed": [["Liu", "Luoluo", ""], ["Chin", "Sang Peter", ""], ["Tran", "Trac D.", ""]]}, {"id": "1810.03744", "submitter": "Marcelo Prates", "authors": "Felipe Zilio, Marcelo Prates, Luis Lamb", "title": "Neural Networks Models for Analyzing Magic: the Gathering Cards", "comments": "10 pages, 1 figure, 9 tables. Accepted at ICONIP 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Historically, games of all kinds have often been the subject of study in\nscientific works of Computer Science, including the field of machine learning.\nBy using machine learning techniques and applying them to a game with defined\nrules or a structured dataset, it's possible to learn and improve on the\nalready existing techniques and methods to tackle new challenges and solve\nproblems that are out of the ordinary. The already existing work on card games\ntends to focus on gameplay and card mechanics. This work aims to apply neural\nnetworks models, including Convolutional Neural Networks and Recurrent Neural\nNetworks, in order to analyze Magic: the Gathering cards, both in terms of card\ntext and illustrations; the card images and texts are used to train the\nnetworks in order to be able to classify them into multiple categories. The\nultimate goal was to develop a methodology that could generate card text\nmatching it to an input image, which was attained by relating the prediction\nvalues of the images and generated text across the different categories.\n", "versions": [{"version": "v1", "created": "Mon, 8 Oct 2018 23:25:18 GMT"}], "update_date": "2018-10-10", "authors_parsed": [["Zilio", "Felipe", ""], ["Prates", "Marcelo", ""], ["Lamb", "Luis", ""]]}, {"id": "1810.03763", "submitter": "Zhe Wang", "authors": "Zhe Wang, Yi Zhou, Yingbin Liang, Guanghui Lan", "title": "Cubic Regularization with Momentum for Nonconvex Optimization", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.OC cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Momentum is a popular technique to accelerate the convergence in practical\ntraining, and its impact on convergence guarantee has been well-studied for\nfirst-order algorithms. However, such a successful acceleration technique has\nnot yet been proposed for second-order algorithms in nonconvex optimization.In\nthis paper, we apply the momentum scheme to cubic regularized (CR) Newton's\nmethod and explore the potential for acceleration. Our numerical experiments on\nvarious nonconvex optimization problems demonstrate that the momentum scheme\ncan substantially facilitate the convergence of cubic regularization, and\nperform even better than the Nesterov's acceleration scheme for CR.\nTheoretically, we prove that CR under momentum achieves the best possible\nconvergence rate to a second-order stationary point for nonconvex optimization.\nMoreover, we study the proposed algorithm for solving problems satisfying an\nerror bound condition and establish a local quadratic convergence rate. Then,\nparticularly for finite-sum problems, we show that the proposed algorithm can\nallow computational inexactness that reduces the overall sample complexity\nwithout degrading the convergence rate.\n", "versions": [{"version": "v1", "created": "Tue, 9 Oct 2018 00:43:56 GMT"}, {"version": "v2", "created": "Thu, 27 Jun 2019 14:35:46 GMT"}], "update_date": "2019-06-28", "authors_parsed": [["Wang", "Zhe", ""], ["Zhou", "Yi", ""], ["Liang", "Yingbin", ""], ["Lan", "Guanghui", ""]]}, {"id": "1810.03764", "submitter": "Nicholas Egan", "authors": "Nicholas Egan, Jeffrey Zhang, Kevin Shen", "title": "Generalized Latent Variable Recovery for Generative Adversarial Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The Generator of a Generative Adversarial Network (GAN) is trained to\ntransform latent vectors drawn from a prior distribution into realistic looking\nphotos. These latent vectors have been shown to encode information about the\ncontent of their corresponding images. Projecting input images onto the latent\nspace of a GAN is non-trivial, but previous work has successfully performed\nthis task for latent spaces with a uniform prior. We extend these techniques to\nlatent spaces with a Gaussian prior, and demonstrate our technique's\neffectiveness.\n", "versions": [{"version": "v1", "created": "Tue, 9 Oct 2018 00:46:00 GMT"}], "update_date": "2018-10-10", "authors_parsed": [["Egan", "Nicholas", ""], ["Zhang", "Jeffrey", ""], ["Shen", "Kevin", ""]]}, {"id": "1810.03770", "submitter": "Tomoharu Iwata", "authors": "Tomoharu Iwata, Naonori Ueda", "title": "Unsupervised Object Matching for Relational Data", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose an unsupervised object matching method for relational data, which\nfinds matchings between objects in different relational datasets without\ncorrespondence information. For example, the proposed method matches documents\nin different languages in multi-lingual document-word networks without\ndictionaries nor alignment information. The proposed method assumes that each\nobject has latent vectors, and the probability of neighbor objects is modeled\nby the inner-product of the latent vectors, where the neighbors are generated\nby short random walks over the relations. The latent vectors are estimated by\nmaximizing the likelihood of the neighbors for each dataset. The estimated\nlatent vectors contain hidden structural information of each object in the\ngiven relational dataset. Then, the proposed method linearly projects the\nlatent vectors for all the datasets onto a common latent space shared across\nall datasets by matching the distributions while preserving the structural\ninformation. The projection matrix is estimated by minimizing the distance\nbetween the latent vector distributions with an orthogonality regularizer. To\nrepresent the distributions effectively, we use the kernel embedding of\ndistributions that hold high-order moment information about a distribution as\nan element in a reproducing kernel Hilbert space, which enables us to calculate\nthe distance between the distributions without density estimation. The\nstructural information encoded in the latent vectors are preserved by using the\northogonality regularizer. We demonstrate the effectiveness of the proposed\nmethod with experiments using real-world multi-lingual document-word relational\ndatasets and multiple user-item relational datasets.\n", "versions": [{"version": "v1", "created": "Tue, 9 Oct 2018 01:51:58 GMT"}, {"version": "v2", "created": "Wed, 24 Oct 2018 05:18:09 GMT"}, {"version": "v3", "created": "Thu, 27 Dec 2018 02:44:50 GMT"}], "update_date": "2018-12-31", "authors_parsed": [["Iwata", "Tomoharu", ""], ["Ueda", "Naonori", ""]]}, {"id": "1810.03773", "submitter": "Matt Olfat", "authors": "Matt Olfat, Anil Aswani", "title": "Average Margin Regularization for Classifiers", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Adversarial robustness has become an important research topic given empirical\ndemonstrations on the lack of robustness of deep neural networks.\nUnfortunately, recent theoretical results suggest that adversarial training\ninduces a strict tradeoff between classification accuracy and adversarial\nrobustness. In this paper, we propose and then study a new regularization for\nany margin classifier or deep neural network. We motivate this regularization\nby a novel generalization bound that shows a tradeoff in classifier accuracy\nbetween maximizing its margin and average margin. We thus call our approach an\naverage margin (AM) regularization, and it consists of a linear term added to\nthe objective. We theoretically show that for certain distributions AM\nregularization can both improve classifier accuracy and robustness to\nadversarial attacks. We conclude by using both synthetic and real data to\nempirically show that AM regularization can strictly improve both accuracy and\nrobustness for support vector machine's (SVM's), relative to unregularized\nclassifiers and adversarially trained classifiers.\n", "versions": [{"version": "v1", "created": "Tue, 9 Oct 2018 02:10:30 GMT"}, {"version": "v2", "created": "Sun, 14 Oct 2018 19:12:07 GMT"}, {"version": "v3", "created": "Tue, 24 Mar 2020 02:35:26 GMT"}], "update_date": "2020-03-25", "authors_parsed": [["Olfat", "Matt", ""], ["Aswani", "Anil", ""]]}, {"id": "1810.03779", "submitter": "David Ha", "authors": "David Ha", "title": "Reinforcement Learning for Improving Agent Design", "comments": "Earlier version appeared at NeurIPS 2018 Deep Reinforcement Learning\n  Workshop. Published in Artificial Life journal", "journal-ref": "Artificial Life 25 (4), 352-365, 2019", "doi": "10.1162/artl_a_00301", "report-no": null, "categories": "cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  In many reinforcement learning tasks, the goal is to learn a policy to\nmanipulate an agent, whose design is fixed, to maximize some notion of\ncumulative reward. The design of the agent's physical structure is rarely\noptimized for the task at hand. In this work, we explore the possibility of\nlearning a version of the agent's design that is better suited for its task,\njointly with the policy. We propose an alteration to the popular OpenAI Gym\nframework, where we parameterize parts of an environment, and allow an agent to\njointly learn to modify these environment parameters along with its policy. We\ndemonstrate that an agent can learn a better structure of its body that is not\nonly better suited for the task, but also facilitates policy learning. Joint\nlearning of policy and structure may even uncover design principles that are\nuseful for assisted-design applications. Videos of results at\nhttps://designrl.github.io/\n", "versions": [{"version": "v1", "created": "Tue, 9 Oct 2018 02:32:37 GMT"}, {"version": "v2", "created": "Mon, 12 Nov 2018 11:01:21 GMT"}, {"version": "v3", "created": "Mon, 2 Dec 2019 10:49:36 GMT"}], "update_date": "2019-12-03", "authors_parsed": [["Ha", "David", ""]]}, {"id": "1810.03783", "submitter": "Tao Zhuo", "authors": "Tao Zhuo, Zhiyong Cheng, Peng Zhang, Yongkang Wong, Mohan Kankanhalli", "title": "Unsupervised Online Video Object Segmentation with Motion Property\n  Understanding", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Unsupervised video object segmentation aims to automatically segment moving\nobjects over an unconstrained video without any user annotation. So far, only\nfew unsupervised online methods have been reported in literature and their\nperformance is still far from satisfactory, because the complementary\ninformation from future frames cannot be processed under online setting. To\nsolve this challenging problem, in this paper, we propose a novel Unsupervised\nOnline Video Object Segmentation (UOVOS) framework by construing the motion\nproperty to mean moving in concurrence with a generic object for segmented\nregions. By incorporating salient motion detection and object proposal, a\npixel-wise fusion strategy is developed to effectively remove detection noise\nsuch as dynamic background and stationary objects. Furthermore, by leveraging\nthe obtained segmentation from immediately preceding frames, a forward\npropagation algorithm is employed to deal with unreliable motion detection and\nobject proposals. Experimental results on several benchmark datasets\ndemonstrate the efficacy of the proposed method. Compared to the\nstate-of-the-art unsupervised online segmentation algorithms, the proposed\nmethod achieves an absolute gain of 6.2%. Moreover, our method achieves better\nperformance than the best unsupervised offline algorithm on the DAVIS-2016\nbenchmark dataset. Our code is available on the project website:\nhttps://github.com/visiontao/uovos.\n", "versions": [{"version": "v1", "created": "Tue, 9 Oct 2018 02:48:18 GMT"}, {"version": "v2", "created": "Tue, 6 Aug 2019 03:12:29 GMT"}], "update_date": "2019-08-07", "authors_parsed": [["Zhuo", "Tao", ""], ["Cheng", "Zhiyong", ""], ["Zhang", "Peng", ""], ["Wong", "Yongkang", ""], ["Kankanhalli", "Mohan", ""]]}, {"id": "1810.03785", "submitter": "Piotr A. Sok\\'o{\\l}", "authors": "Piotr A. Sokol, Il Memming Park", "title": "Information Geometry of Orthogonal Initializations and Training", "comments": "10 pages and 5 figures; 5 page appendix", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recently mean field theory has been successfully used to analyze properties\nof wide, random neural networks. It gave rise to a prescriptive theory for\ninitializing feed-forward neural networks with orthogonal weights, which\nensures that both the forward propagated activations and the backpropagated\ngradients are near $\\ell_2$ isometries and as a consequence training is orders\nof magnitude faster. Despite strong empirical performance, the mechanisms by\nwhich critical initializations confer an advantage in the optimization of deep\nneural networks are poorly understood. Here we show a novel connection between\nthe maximum curvature of the optimization landscape (gradient smoothness) as\nmeasured by the Fisher information matrix (FIM) and the spectral radius of the\ninput-output Jacobian, which partially explains why more isometric networks can\ntrain much faster. Furthermore, given that orthogonal weights are necessary to\nensure that gradient norms are approximately preserved at initialization, we\nexperimentally investigate the benefits of maintaining orthogonality throughout\ntraining, from which we conclude that manifold optimization of weights performs\nwell regardless of the smoothness of the gradients. Moreover, motivated by\nexperimental results we show that a low condition number of the FIM is not\npredictive of faster learning.\n", "versions": [{"version": "v1", "created": "Tue, 9 Oct 2018 03:00:41 GMT"}, {"version": "v2", "created": "Tue, 4 Jun 2019 17:58:13 GMT"}], "update_date": "2019-06-05", "authors_parsed": [["Sokol", "Piotr A.", ""], ["Park", "Il Memming", ""]]}, {"id": "1810.03798", "submitter": "Craig Bakker", "authors": "Craig Bakker, Michael J. Henry, and Nathan O. Hodas", "title": "The Outer Product Structure of Neural Network Derivatives", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we show that feedforward and recurrent neural networks exhibit\nan outer product derivative structure but that convolutional neural networks do\nnot. This structure makes it possible to use higher-order information without\nneeding approximations or infeasibly large amounts of memory, and it may also\nprovide insights into the geometry of neural network optima. The ability to\neasily access these derivatives also suggests a new, geometric approach to\nregularization. We then discuss how this structure could be used to improve\ntraining methods, increase network robustness and generalizability, and inform\nnetwork compression methods.\n", "versions": [{"version": "v1", "created": "Tue, 9 Oct 2018 03:37:08 GMT"}], "update_date": "2018-10-10", "authors_parsed": [["Bakker", "Craig", ""], ["Henry", "Michael J.", ""], ["Hodas", "Nathan O.", ""]]}, {"id": "1810.03805", "submitter": "Jonas Mueller", "authors": "Brandon Carter, Jonas Mueller, Siddhartha Jain, David Gifford", "title": "What made you do this? Understanding black-box decisions with sufficient\n  input subsets", "comments": "Published in AISTATS 2019; Equal contribution by first two authors", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Local explanation frameworks aim to rationalize particular decisions made by\na black-box prediction model. Existing techniques are often restricted to a\nspecific type of predictor or based on input saliency, which may be undesirably\nsensitive to factors unrelated to the model's decision making process. We\ninstead propose sufficient input subsets that identify minimal subsets of\nfeatures whose observed values alone suffice for the same decision to be\nreached, even if all other input feature values are missing. General principles\nthat globally govern a model's decision-making can also be revealed by\nsearching for clusters of such input patterns across many data points. Our\napproach is conceptually straightforward, entirely model-agnostic, simply\nimplemented using instance-wise backward selection, and able to produce more\nconcise rationales than existing techniques. We demonstrate the utility of our\ninterpretation method on various neural network models trained on text, image,\nand genomic data.\n", "versions": [{"version": "v1", "created": "Tue, 9 Oct 2018 04:22:44 GMT"}, {"version": "v2", "created": "Fri, 8 Feb 2019 19:06:28 GMT"}], "update_date": "2019-02-12", "authors_parsed": [["Carter", "Brandon", ""], ["Mueller", "Jonas", ""], ["Jain", "Siddhartha", ""], ["Gifford", "David", ""]]}, {"id": "1810.03806", "submitter": "Chenxiao Zhao", "authors": "Chenxiao Zhao, P. Thomas Fletcher, Mixue Yu, Yaxin Peng, Guixu Zhang\n  and Chaomin Shen", "title": "The Adversarial Attack and Detection under the Fisher Information Metric", "comments": "Accepted as an AAAI-2019 oral paper", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Many deep learning models are vulnerable to the adversarial attack, i.e.,\nimperceptible but intentionally-designed perturbations to the input can cause\nincorrect output of the networks. In this paper, using information geometry, we\nprovide a reasonable explanation for the vulnerability of deep learning models.\nBy considering the data space as a non-linear space with the Fisher information\nmetric induced from a neural network, we first propose an adversarial attack\nalgorithm termed one-step spectral attack (OSSA). The method is described by a\nconstrained quadratic form of the Fisher information matrix, where the optimal\nadversarial perturbation is given by the first eigenvector, and the model\nvulnerability is reflected by the eigenvalues. The larger an eigenvalue is, the\nmore vulnerable the model is to be attacked by the corresponding eigenvector.\nTaking advantage of the property, we also propose an adversarial detection\nmethod with the eigenvalues serving as characteristics. Both our attack and\ndetection algorithms are numerically optimized to work efficiently on large\ndatasets. Our evaluations show superior performance compared with other\nmethods, implying that the Fisher information is a promising approach to\ninvestigate the adversarial attacks and defenses.\n", "versions": [{"version": "v1", "created": "Tue, 9 Oct 2018 04:25:05 GMT"}, {"version": "v2", "created": "Sat, 9 Feb 2019 03:40:49 GMT"}], "update_date": "2019-02-12", "authors_parsed": [["Zhao", "Chenxiao", ""], ["Fletcher", "P. Thomas", ""], ["Yu", "Mixue", ""], ["Peng", "Yaxin", ""], ["Zhang", "Guixu", ""], ["Shen", "Chaomin", ""]]}, {"id": "1810.03814", "submitter": "Yueyong Shi", "authors": "Jian Huang, Yuling Jiao, Xiliang Lu, Yueyong Shi, Qinglong Yang", "title": "SNAP: A semismooth Newton algorithm for pathwise optimization with\n  optimal local convergence rate and oracle properties", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG math.ST stat.AP stat.CO stat.ME stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a semismooth Newton algorithm for pathwise optimization (SNAP) for\nthe LASSO and Enet in sparse, high-dimensional linear regression. SNAP is\nderived from a suitable formulation of the KKT conditions based on Newton\nderivatives. It solves the semismooth KKT equations efficiently by actively and\ncontinuously seeking the support of the regression coefficients along the\nsolution path with warm start. At each knot in the path, SNAP converges locally\nsuperlinearly for the Enet criterion and achieves an optimal local convergence\nrate for the LASSO criterion, i.e., SNAP converges in one step at the cost of\ntwo matrix-vector multiplication per iteration. Under certain regularity\nconditions on the design matrix and the minimum magnitude of the nonzero\nelements of the target regression coefficients, we show that SNAP hits a\nsolution with the same signs as the regression coefficients and achieves a\nsharp estimation error bound in finite steps with high probability. The\ncomputational complexity of SNAP is shown to be the same as that of LARS and\ncoordinate descent algorithms per iteration. Simulation studies and real data\nanalysis support our theoretical results and demonstrate that SNAP is faster\nand accurate than LARS and coordinate descent algorithms.\n", "versions": [{"version": "v1", "created": "Tue, 9 Oct 2018 04:44:42 GMT"}], "update_date": "2018-10-10", "authors_parsed": [["Huang", "Jian", ""], ["Jiao", "Yuling", ""], ["Lu", "Xiliang", ""], ["Shi", "Yueyong", ""], ["Yang", "Qinglong", ""]]}, {"id": "1810.03817", "submitter": "Shahin Shahrampour", "authors": "Shahin Shahrampour, Vahid Tarokh", "title": "Learning Bounds for Greedy Approximation with Explicit Feature Maps from\n  Multiple Kernels", "comments": "Proc. of 2018 Advances in Neural Information Processing Systems (NIPS\n  2018)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Nonlinear kernels can be approximated using finite-dimensional feature maps\nfor efficient risk minimization. Due to the inherent trade-off between the\ndimension of the (mapped) feature space and the approximation accuracy, the key\nproblem is to identify promising (explicit) features leading to a satisfactory\nout-of-sample performance. In this work, we tackle this problem by efficiently\nchoosing such features from multiple kernels in a greedy fashion. Our method\nsequentially selects these explicit features from a set of candidate features\nusing a correlation metric. We establish an out-of-sample error bound capturing\nthe trade-off between the error in terms of explicit features (approximation\nerror) and the error due to spectral properties of the best model in the\nHilbert space associated to the combined kernel (spectral error). The result\nverifies that when the (best) underlying data model is sparse enough, i.e., the\nspectral error is negligible, one can control the test error with a small\nnumber of explicit features, that can scale poly-logarithmically with data. Our\nempirical results show that given a fixed number of explicit features, the\nmethod can achieve a lower test error with a smaller time cost, compared to the\nstate-of-the-art in data-dependent random features.\n", "versions": [{"version": "v1", "created": "Tue, 9 Oct 2018 05:20:41 GMT"}], "update_date": "2018-10-10", "authors_parsed": [["Shahrampour", "Shahin", ""], ["Tarokh", "Vahid", ""]]}, {"id": "1810.03825", "submitter": "Kohei Miyaguchi", "authors": "Kohei Miyaguchi and Kenji Yamanishi", "title": "Adaptive Minimax Regret against Smooth Logarithmic Losses over\n  High-Dimensional $\\ell_1$-Balls via Envelope Complexity", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We develop a new theoretical framework, the \\emph{envelope complexity}, to\nanalyze the minimax regret with logarithmic loss functions and derive a\nBayesian predictor that adaptively achieves the minimax regret over\nhigh-dimensional $\\ell_1$-balls within a factor of two. The prior is newly\nderived for achieving the minimax regret and called the\n\\emph{spike-and-tails~(ST) prior} as it looks like. The resulting regret bound\nis so simple that it is completely determined with the smoothness of the loss\nfunction and the radius of the balls except with logarithmic factors, and it\nhas a generalized form of existing regret/risk bounds. In the preliminary\nexperiment, we confirm that the ST prior outperforms the conventional\nminimax-regret prior under non-high-dimensional asymptotics.\n", "versions": [{"version": "v1", "created": "Tue, 9 Oct 2018 06:08:27 GMT"}, {"version": "v2", "created": "Sun, 14 Oct 2018 02:16:20 GMT"}], "update_date": "2018-10-16", "authors_parsed": [["Miyaguchi", "Kohei", ""], ["Yamanishi", "Kenji", ""]]}, {"id": "1810.03842", "submitter": "Abhik Singla", "authors": "Abhik Singla, Shounak Bhattacharya, Dhaivat Dholakiya, Shalabh\n  Bhatnagar, Ashitava Ghosal, Bharadwaj Amrutur and Shishir Kolathaya", "title": "Realizing Learned Quadruped Locomotion Behaviors through Kinematic\n  Motion Primitives", "comments": "Accepted by ICRA 2019. Supplementary Video:\n  https://youtu.be/kiLKSqI4KhE", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Humans and animals are believed to use a very minimal set of trajectories to\nperform a wide variety of tasks including walking. Our main objective in this\npaper is two fold 1) Obtain an effective tool to realize these basic motion\npatterns for quadrupedal walking, called the kinematic motion primitives\n(kMPs), via trajectories learned from deep reinforcement learning (D-RL) and 2)\nRealize a set of behaviors, namely trot, walk, gallop and bound from these\nkinematic motion primitives in our custom four legged robot, called the\n`Stoch'. D-RL is a data driven approach, which has been shown to be very\neffective for realizing all kinds of robust locomotion behaviors, both in\nsimulation and in experiment. On the other hand, kMPs are known to capture the\nunderlying structure of walking and yield a set of derived behaviors. We first\ngenerate walking gaits from D-RL, which uses policy gradient based approaches.\nWe then analyze the resulting walking by using principal component analysis. We\nobserve that the kMPs extracted from PCA followed a similar pattern\nirrespective of the type of gaits generated. Leveraging on this underlying\nstructure, we then realize walking in Stoch by a straightforward reconstruction\nof joint trajectories from kMPs. This type of methodology improves the\ntransferability of these gaits to real hardware, lowers the computational\noverhead on-board, and also avoids multiple training iterations by generating a\nset of derived behaviors from a single learned gait.\n", "versions": [{"version": "v1", "created": "Tue, 9 Oct 2018 08:00:26 GMT"}, {"version": "v2", "created": "Tue, 26 Feb 2019 14:49:15 GMT"}], "update_date": "2019-02-27", "authors_parsed": [["Singla", "Abhik", ""], ["Bhattacharya", "Shounak", ""], ["Dholakiya", "Dhaivat", ""], ["Bhatnagar", "Shalabh", ""], ["Ghosal", "Ashitava", ""], ["Amrutur", "Bharadwaj", ""], ["Kolathaya", "Shishir", ""]]}, {"id": "1810.03867", "submitter": "J\\\"org Wagner", "authors": "J\\\"org Wagner, Volker Fischer, Michael Herman, Sven Behnke", "title": "Functionally Modular and Interpretable Temporal Filtering for Robust\n  Segmentation", "comments": "In Proceedings of 29th British Machine Vision Conference (BMVC),\n  Newcastle upon Tyne, UK, 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The performance of autonomous systems heavily relies on their ability to\ngenerate a robust representation of the environment. Deep neural networks have\ngreatly improved vision-based perception systems but still fail in challenging\nsituations, e.g. sensor outages or heavy weather. These failures are often\nintroduced by data-inherent perturbations, which significantly reduce the\ninformation provided to the perception system. We propose a functionally\nmodularized temporal filter, which stabilizes an abstract feature\nrepresentation of a single-frame segmentation model using information of\nprevious time steps. Our filter module splits the filter task into multiple\nless complex and more interpretable subtasks. The basic structure of the filter\nis inspired by a Bayes estimator consisting of a prediction and an update step.\nTo make the prediction more transparent, we implement it using a geometric\nprojection and estimate its parameters. This additionally enables the\ndecomposition of the filter task into static representation filtering and\nlow-dimensional motion filtering. Our model can cope with missing frames and is\ntrainable in an end-to-end fashion. Using photorealistic, synthetic video data,\nwe show the ability of the proposed architecture to overcome data-inherent\nperturbations. The experiments especially highlight advantages introduced by an\ninterpretable and explicit filter module.\n", "versions": [{"version": "v1", "created": "Tue, 9 Oct 2018 09:13:36 GMT"}, {"version": "v2", "created": "Mon, 15 Oct 2018 16:42:20 GMT"}], "update_date": "2018-10-16", "authors_parsed": [["Wagner", "J\u00f6rg", ""], ["Fischer", "Volker", ""], ["Herman", "Michael", ""], ["Behnke", "Sven", ""]]}, {"id": "1810.03880", "submitter": "Hugo Caselles-Dupr\\'e", "authors": "Hugo Caselles-Dupr\\'e, Michael Garcia-Ortiz, David Filliat", "title": "Continual State Representation Learning for Reinforcement Learning using\n  Generative Replay", "comments": "Accepted contribution to the Workshop on Continual Learning, NeurIPS\n  2018 (Neural Information Processing Systems)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the problem of building a state representation model in a\ncontinual fashion. As the environment changes, the aim is to efficiently\ncompress the sensory state's information without losing past knowledge. The\nlearned features are then fed to a Reinforcement Learning algorithm to learn a\npolicy. We propose to use Variational Auto-Encoders for state representation,\nand Generative Replay, i.e. the use of generated samples, to maintain past\nknowledge. We also provide a general and statistically sound method for\nautomatic environment change detection. Our method provides efficient state\nrepresentation as well as forward transfer, and avoids catastrophic forgetting.\nThe resulting model is capable of incrementally learning information without\nusing past data and with a bounded system size.\n", "versions": [{"version": "v1", "created": "Tue, 9 Oct 2018 09:42:53 GMT"}, {"version": "v2", "created": "Fri, 2 Nov 2018 09:49:24 GMT"}, {"version": "v3", "created": "Tue, 11 Dec 2018 13:03:34 GMT"}], "update_date": "2018-12-12", "authors_parsed": [["Caselles-Dupr\u00e9", "Hugo", ""], ["Garcia-Ortiz", "Michael", ""], ["Filliat", "David", ""]]}, {"id": "1810.03913", "submitter": "Shixia Liu", "authors": "Mengchen Liu, Shixia Liu, Hang Su, Kelei Cao, Jun Zhu", "title": "Analyzing the Noise Robustness of Deep Neural Networks", "comments": "IEEE VAST 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.HC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep neural networks (DNNs) are vulnerable to maliciously generated\nadversarial examples. These examples are intentionally designed by making\nimperceptible perturbations and often mislead a DNN into making an incorrect\nprediction. This phenomenon means that there is significant risk in applying\nDNNs to safety-critical applications, such as driverless cars. To address this\nissue, we present a visual analytics approach to explain the primary cause of\nthe wrong predictions introduced by adversarial examples. The key is to analyze\nthe datapaths of the adversarial examples and compare them with those of the\nnormal examples. A datapath is a group of critical neurons and their\nconnections. To this end, we formulate the datapath extraction as a subset\nselection problem and approximately solve it based on back-propagation. A\nmulti-level visualization consisting of a segmented DAG (layer level), an Euler\ndiagram (feature map level), and a heat map (neuron level), has been designed\nto help experts investigate datapaths from the high-level layers to the\ndetailed neuron activations. Two case studies are conducted that demonstrate\nthe promise of our approach in support of explaining the working mechanism of\nadversarial examples.\n", "versions": [{"version": "v1", "created": "Tue, 9 Oct 2018 11:13:44 GMT"}], "update_date": "2018-10-10", "authors_parsed": [["Liu", "Mengchen", ""], ["Liu", "Shixia", ""], ["Su", "Hang", ""], ["Cao", "Kelei", ""], ["Zhu", "Jun", ""]]}, {"id": "1810.03944", "submitter": "Yong Luo", "authors": "Yong Luo, Yonggang Wen, Ling-Yu Duan, and Dacheng Tao", "title": "Transfer Metric Learning: Algorithms, Applications and Outlooks", "comments": "14 pages, 5 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Distance metric learning (DML) aims to find an appropriate way to reveal the\nunderlying data relationship. It is critical in many machine learning, pattern\nrecognition and data mining algorithms, and usually require large amount of\nlabel information (such as class labels or pair/triplet constraints) to achieve\nsatisfactory performance. However, the label information may be insufficient in\nreal-world applications due to the high-labeling cost, and DML may fail in this\ncase. Transfer metric learning (TML) is able to mitigate this issue for DML in\nthe domain of interest (target domain) by leveraging knowledge/information from\nother related domains (source domains). Although achieved a certain level of\ndevelopment, TML has limited success in various aspects such as selective\ntransfer, theoretical understanding, handling complex data, big data and\nextreme cases. In this survey, we present a systematic review of the TML\nliterature. In particular, we group TML into different categories according to\ndifferent settings and metric transfer strategies, such as direct metric\napproximation, subspace approximation, distance approximation, and distribution\napproximation. A summarization and insightful discussion of the various TML\napproaches and their applications will be presented. Finally, we indicate some\nchallenges and provide possible future directions.\n", "versions": [{"version": "v1", "created": "Tue, 9 Oct 2018 12:46:20 GMT"}, {"version": "v2", "created": "Wed, 10 Oct 2018 02:18:49 GMT"}, {"version": "v3", "created": "Mon, 12 Nov 2018 06:53:11 GMT"}], "update_date": "2018-11-13", "authors_parsed": [["Luo", "Yong", ""], ["Wen", "Yonggang", ""], ["Duan", "Ling-Yu", ""], ["Tao", "Dacheng", ""]]}, {"id": "1810.03946", "submitter": "Berton Huang", "authors": "Xiaobo Huang", "title": "Convolutional Neural Networks In Convolution", "comments": "9 pages, 2 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG cs.NE", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Currently, increasingly deeper neural networks have been applied to improve\ntheir accuracy. In contrast, We propose a novel wider Convolutional Neural\nNetworks (CNN) architecture, motivated by the Multi-column Deep Neural Networks\nand the Network In Network(NIN), aiming for higher accuracy without input data\ntransmutation. In our architecture, namely \"CNN In Convolution\"(CNNIC), a small\nCNN, instead of the original generalized liner model(GLM) based filters, is\nconvoluted as kernel on the original image, serving as feature extracting layer\nof this networks. And further classifications are then carried out by a global\naverage pooling layer and a softmax layer. Dropout and orthonormal\ninitialization are applied to overcome training difficulties including slow\nconvergence and over-fitting. Persuasive classification performance is\ndemonstrated on MNIST.\n", "versions": [{"version": "v1", "created": "Tue, 9 Oct 2018 12:59:12 GMT"}], "update_date": "2018-10-10", "authors_parsed": [["Huang", "Xiaobo", ""]]}, {"id": "1810.03947", "submitter": "Pankaj Gupta", "authors": "Pankaj Gupta and Yatin Chaudhary and Florian Buettner and Hinrich\n  Sch\\\"utze", "title": "textTOvec: Deep Contextualized Neural Autoregressive Topic Models of\n  Language with Distributed Compositional Prior", "comments": "Published in #ICLR2019 International Conference on Learning\n  Representations", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.IR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We address two challenges of probabilistic topic modelling in order to better\nestimate the probability of a word in a given context, i.e., P(word|context):\n(1) No Language Structure in Context: Probabilistic topic models ignore word\norder by summarizing a given context as a \"bag-of-word\" and consequently the\nsemantics of words in the context is lost. The LSTM-LM learns a vector-space\nrepresentation of each word by accounting for word order in local collocation\npatterns and models complex characteristics of language (e.g., syntax and\nsemantics), while the TM simultaneously learns a latent representation from the\nentire document and discovers the underlying thematic structure. We unite two\ncomplementary paradigms of learning the meaning of word occurrences by\ncombining a TM (e.g., DocNADE) and a LM in a unified probabilistic framework,\nnamed as ctx-DocNADE. (2) Limited Context and/or Smaller training corpus of\ndocuments: In settings with a small number of word occurrences (i.e., lack of\ncontext) in short text or data sparsity in a corpus of few documents, the\napplication of TMs is challenging. We address this challenge by incorporating\nexternal knowledge into neural autoregressive topic models via a language\nmodelling approach: we use word embeddings as input of a LSTM-LM with the aim\nto improve the word-topic mapping on a smaller and/or short-text corpus. The\nproposed DocNADE extension is named as ctx-DocNADEe.\n  We present novel neural autoregressive topic model variants coupled with\nneural LMs and embeddings priors that consistently outperform state-of-the-art\ngenerative TMs in terms of generalization (perplexity), interpretability (topic\ncoherence) and applicability (retrieval and classification) over 6 long-text\nand 8 short-text datasets from diverse domains.\n", "versions": [{"version": "v1", "created": "Tue, 9 Oct 2018 13:04:25 GMT"}, {"version": "v2", "created": "Wed, 10 Oct 2018 11:29:00 GMT"}, {"version": "v3", "created": "Sun, 25 Nov 2018 11:40:26 GMT"}, {"version": "v4", "created": "Sat, 23 Feb 2019 14:14:05 GMT"}], "update_date": "2019-02-26", "authors_parsed": [["Gupta", "Pankaj", ""], ["Chaudhary", "Yatin", ""], ["Buettner", "Florian", ""], ["Sch\u00fctze", "Hinrich", ""]]}, {"id": "1810.03958", "submitter": "Alexander Gaunt", "authors": "Anqi Wu, Sebastian Nowozin, Edward Meeds, Richard E. Turner, Jos\\'e\n  Miguel Hern\\'andez-Lobato, Alexander L. Gaunt", "title": "Deterministic Variational Inference for Robust Bayesian Neural Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Bayesian neural networks (BNNs) hold great promise as a flexible and\nprincipled solution to deal with uncertainty when learning from finite data.\nAmong approaches to realize probabilistic inference in deep neural networks,\nvariational Bayes (VB) is theoretically grounded, generally applicable, and\ncomputationally efficient. With wide recognition of potential advantages, why\nis it that variational Bayes has seen very limited practical use for BNNs in\nreal applications? We argue that variational inference in neural networks is\nfragile: successful implementations require careful initialization and tuning\nof prior variances, as well as controlling the variance of Monte Carlo gradient\nestimates. We provide two innovations that aim to turn VB into a robust\ninference tool for Bayesian neural networks: first, we introduce a novel\ndeterministic method to approximate moments in neural networks, eliminating\ngradient variance; second, we introduce a hierarchical prior for parameters and\na novel Empirical Bayes procedure for automatically selecting prior variances.\nCombining these two innovations, the resulting method is highly efficient and\nrobust. On the application of heteroscedastic regression we demonstrate good\npredictive performance over alternative approaches.\n", "versions": [{"version": "v1", "created": "Tue, 9 Oct 2018 13:30:58 GMT"}, {"version": "v2", "created": "Thu, 7 Mar 2019 17:05:48 GMT"}], "update_date": "2019-03-08", "authors_parsed": [["Wu", "Anqi", ""], ["Nowozin", "Sebastian", ""], ["Meeds", "Edward", ""], ["Turner", "Richard E.", ""], ["Hern\u00e1ndez-Lobato", "Jos\u00e9 Miguel", ""], ["Gaunt", "Alexander L.", ""]]}, {"id": "1810.03964", "submitter": "Alhabib Abbas", "authors": "Mohammad Jubran, Alhabib Abbas, Aaron Chadha and Yiannis Andreopoulos", "title": "Rate-Accuracy Trade-Off In Video Classification With Deep Convolutional\n  Neural Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Advanced video classification systems decode video frames to derive the\nnecessary texture and motion representations for ingestion and analysis by\nspatio-temporal deep convolutional neural networks (CNNs). However, when\nconsidering visual Internet-of-Things applications, surveillance systems and\nsemantic crawlers of large video repositories, the video capture and the\nCNN-based semantic analysis parts do not tend to be co-located. This\nnecessitates the transport of compressed video over networks and incurs\nsignificant overhead in bandwidth and energy consumption, thereby significantly\nundermining the deployment potential of such systems. In this paper, we\ninvestigate the trade-off between the encoding bitrate and the achievable\naccuracy of CNN-based video classification models that directly ingest\nAVC/H.264 and HEVC encoded videos. Instead of retaining entire compressed video\nbitstreams and applying complex optical flow calculations prior to CNN\nprocessing, we only retain motion vector and select texture information at\nsignificantly-reduced bitrates and apply no additional processing prior to CNN\ningestion. Based on three CNN architectures and two action recognition\ndatasets, we achieve 11%-94% saving in bitrate with marginal effect on\nclassification accuracy. A model-based selection between multiple CNNs\nincreases these savings further, to the point where, if up to 7% loss of\naccuracy can be tolerated, video classification can take place with as little\nas 3 kbps for the transport of the required compressed video information to the\nsystem implementing the CNN models.\n", "versions": [{"version": "v1", "created": "Thu, 27 Sep 2018 14:33:43 GMT"}, {"version": "v2", "created": "Wed, 2 Jan 2019 13:08:19 GMT"}], "update_date": "2019-01-03", "authors_parsed": [["Jubran", "Mohammad", ""], ["Abbas", "Alhabib", ""], ["Chadha", "Aaron", ""], ["Andreopoulos", "Yiannis", ""]]}, {"id": "1810.03969", "submitter": "Nicolo' Savioli", "authors": "Nicol\\'o Savioli, Miguel Silva Vieira, Pablo Lamata, Giovanni Montana", "title": "A Generative Adversarial Model for Right Ventricle Segmentation", "comments": "9 pages, 8 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  The clinical management of several cardiovascular conditions, such as\npulmonary hypertension, require the assessment of the right ventricular (RV)\nfunction. This work addresses the fully automatic and robust access to one of\nthe key RV biomarkers, its ejection fraction, from the gold standard imaging\nmodality, MRI. The problem becomes the accurate segmentation of the RV blood\npool from cine MRI sequences. This work proposes a solution based on Fully\nConvolutional Neural Networks (FCNN), where our first contribution is the\noptimal combination of three concepts (the convolution Gated Recurrent Units\n(GRU), the Generative Adversarial Networks (GAN), and the L1 loss function)\nthat achieves an improvement of 0.05 and 3.49 mm in Dice Index and Hausdorff\nDistance respectively with respect to the baseline FCNN. This improvement is\nthen doubled by our second contribution, the ROI-GAN, that sets two GANs to\ncooperate working at two fields of view of the image, its full resolution and\nthe region of interest (ROI). Our rationale here is to better guide the FCNN\nlearning by combining global (full resolution) and local Region Of Interest\n(ROI) features. The study is conducted in a large in-house dataset of $\\sim$\n23.000 segmented MRI slices, and its generality is verified in a publicly\navailable dataset.\n", "versions": [{"version": "v1", "created": "Thu, 27 Sep 2018 09:52:10 GMT"}], "update_date": "2018-10-10", "authors_parsed": [["Savioli", "Nicol\u00f3", ""], ["Vieira", "Miguel Silva", ""], ["Lamata", "Pablo", ""], ["Montana", "Giovanni", ""]]}, {"id": "1810.03979", "submitter": "Lukas Cavigelli", "authors": "Lukas Cavigelli, Luca Benini", "title": "Extended Bit-Plane Compression for Convolutional Neural Network\n  Accelerators", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.AR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  After the tremendous success of convolutional neural networks in image\nclassification, object detection, speech recognition, etc., there is now rising\ndemand for deployment of these compute-intensive ML models on tightly power\nconstrained embedded and mobile systems at low cost as well as for pushing the\nthroughput in data centers. This has triggered a wave of research towards\nspecialized hardware accelerators. Their performance is often constrained by\nI/O bandwidth and the energy consumption is dominated by I/O transfers to\noff-chip memory. We introduce and evaluate a novel, hardware-friendly\ncompression scheme for the feature maps present within convolutional neural\nnetworks. We show that an average compression ratio of 4.4x relative to\nuncompressed data and a gain of 60% over existing method can be achieved for\nResNet-34 with a compression block requiring <300 bit of sequential cells and\nminimal combinational logic.\n", "versions": [{"version": "v1", "created": "Mon, 1 Oct 2018 21:02:53 GMT"}], "update_date": "2019-03-05", "authors_parsed": [["Cavigelli", "Lukas", ""], ["Benini", "Luca", ""]]}, {"id": "1810.03982", "submitter": "Reinhard Heckel", "authors": "Reinhard Heckel and Paul Hand", "title": "Deep Decoder: Concise Image Representations from Untrained\n  Non-convolutional Networks", "comments": "International Conference on Learning Representations 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep neural networks, in particular convolutional neural networks, have\nbecome highly effective tools for compressing images and solving inverse\nproblems including denoising, inpainting, and reconstruction from few and noisy\nmeasurements. This success can be attributed in part to their ability to\nrepresent and generate natural images well. Contrary to classical tools such as\nwavelets, image-generating deep neural networks have a large number of\nparameters---typically a multiple of their output dimension---and need to be\ntrained on large datasets. In this paper, we propose an untrained simple image\nmodel, called the deep decoder, which is a deep neural network that can\ngenerate natural images from very few weight parameters. The deep decoder has a\nsimple architecture with no convolutions and fewer weight parameters than the\noutput dimensionality. This underparameterization enables the deep decoder to\ncompress images into a concise set of network weights, which we show is on par\nwith wavelet-based thresholding. Further, underparameterization provides a\nbarrier to overfitting, allowing the deep decoder to have state-of-the-art\nperformance for denoising. The deep decoder is simple in the sense that each\nlayer has an identical structure that consists of only one upsampling unit,\npixel-wise linear combination of channels, ReLU activation, and channelwise\nnormalization. This simplicity makes the network amenable to theoretical\nanalysis, and it sheds light on the aspects of neural networks that enable them\nto form effective signal representations.\n", "versions": [{"version": "v1", "created": "Tue, 2 Oct 2018 20:07:07 GMT"}, {"version": "v2", "created": "Fri, 22 Feb 2019 22:13:19 GMT"}], "update_date": "2019-03-12", "authors_parsed": [["Heckel", "Reinhard", ""], ["Hand", "Paul", ""]]}, {"id": "1810.03993", "submitter": "Margaret Mitchell", "authors": "Margaret Mitchell and Simone Wu and Andrew Zaldivar and Parker Barnes\n  and Lucy Vasserman and Ben Hutchinson and Elena Spitzer and Inioluwa Deborah\n  Raji and Timnit Gebru", "title": "Model Cards for Model Reporting", "comments": null, "journal-ref": "FAT* '19: Conference on Fairness, Accountability, and\n  Transparency, January 29--31, 2019, Atlanta, GA, USA", "doi": "10.1145/3287560.3287596", "report-no": null, "categories": "cs.LG cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Trained machine learning models are increasingly used to perform high-impact\ntasks in areas such as law enforcement, medicine, education, and employment. In\norder to clarify the intended use cases of machine learning models and minimize\ntheir usage in contexts for which they are not well suited, we recommend that\nreleased models be accompanied by documentation detailing their performance\ncharacteristics. In this paper, we propose a framework that we call model\ncards, to encourage such transparent model reporting. Model cards are short\ndocuments accompanying trained machine learning models that provide benchmarked\nevaluation in a variety of conditions, such as across different cultural,\ndemographic, or phenotypic groups (e.g., race, geographic location, sex,\nFitzpatrick skin type) and intersectional groups (e.g., age and race, or sex\nand Fitzpatrick skin type) that are relevant to the intended application\ndomains. Model cards also disclose the context in which models are intended to\nbe used, details of the performance evaluation procedures, and other relevant\ninformation. While we focus primarily on human-centered machine learning models\nin the application fields of computer vision and natural language processing,\nthis framework can be used to document any trained machine learning model. To\nsolidify the concept, we provide cards for two supervised models: One trained\nto detect smiling faces in images, and one trained to detect toxic comments in\ntext. We propose model cards as a step towards the responsible democratization\nof machine learning and related AI technology, increasing transparency into how\nwell AI technology works. We hope this work encourages those releasing trained\nmachine learning models to accompany model releases with similar detailed\nevaluation numbers and other relevant documentation.\n", "versions": [{"version": "v1", "created": "Fri, 5 Oct 2018 22:33:43 GMT"}, {"version": "v2", "created": "Mon, 14 Jan 2019 20:25:27 GMT"}], "update_date": "2019-01-16", "authors_parsed": [["Mitchell", "Margaret", ""], ["Wu", "Simone", ""], ["Zaldivar", "Andrew", ""], ["Barnes", "Parker", ""], ["Vasserman", "Lucy", ""], ["Hutchinson", "Ben", ""], ["Spitzer", "Elena", ""], ["Raji", "Inioluwa Deborah", ""], ["Gebru", "Timnit", ""]]}, {"id": "1810.03999", "submitter": "Dufan Wu", "authors": "Dufan Wu, Kyungsang Kim, and Quanzheng Li", "title": "Computationally Efficient Deep Neural Network for Computed Tomography\n  Image Reconstruction", "comments": "33 pages, 14 figures, accepted by Medical Physics", "journal-ref": null, "doi": "10.1002/mp.13627", "report-no": null, "categories": "cs.CV cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep-neural-network-based image reconstruction has demonstrated promising\nperformance in medical imaging for under-sampled and low-dose scenarios.\nHowever, it requires large amount of memory and extensive time for the\ntraining. It is especially challenging to train the reconstruction networks for\nthree-dimensional computed tomography (CT) because of the high resolution of CT\nimages. The purpose of this work is to reduce the memory and time consumption\nof the training of the reconstruction networks for CT to make it practical for\ncurrent hardware, while maintaining the quality of the reconstructed images.\n  We unrolled the proximal gradient descent algorithm for iterative image\nreconstruction to finite iterations and replaced the terms related to the\npenalty function with trainable convolutional neural networks (CNN). The\nnetwork was trained greedily iteration by iteration in the image-domain on\npatches, which requires reasonable amount of memory and time on mainstream\ngraphics processing unit (GPU). To overcome the local-minimum problem caused by\ngreedy learning, we used deep UNet as the CNN and incorporated separable\nquadratic surrogate with ordered subsets for data fidelity, so that the\nsolution could escape from easy local minimums and achieve better image\nquality.\n  The proposed method achieved comparable image quality with state-of-the-art\nneural network for CT image reconstruction on 2D sparse-view and limited-angle\nproblems on the low-dose CT challenge dataset.\n", "versions": [{"version": "v1", "created": "Fri, 5 Oct 2018 18:26:39 GMT"}, {"version": "v2", "created": "Mon, 4 Mar 2019 15:50:20 GMT"}, {"version": "v3", "created": "Fri, 24 May 2019 03:25:59 GMT"}], "update_date": "2019-06-12", "authors_parsed": [["Wu", "Dufan", ""], ["Kim", "Kyungsang", ""], ["Li", "Quanzheng", ""]]}, {"id": "1810.04009", "submitter": "Gianina Alina Negoita", "authors": "Gianina Alina Negoita, James P. Vary, Glenn R. Luecke, Pieter Maris,\n  Andrey M. Shirokov, Ik Jae Shin, Youngman Kim, Esmond G. Ng, Chao Yang,\n  Matthew Lockner, and Gurpur M. Prabhu", "title": "Deep learning: Extrapolation tool for ab initio nuclear theory", "comments": "13 pages, 6 figures. Some typos were fixed, e.g., replaced MSE units\n  for the observables with observables' square units. arXiv admin note: text\n  overlap with arXiv:1803.03215", "journal-ref": "Phys. Rev. C 99, 054308 (2019)", "doi": "10.1103/PhysRevC.99.054308", "report-no": null, "categories": "nucl-th cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Ab initio approaches in nuclear theory, such as the no-core shell model\n(NCSM), have been developed for approximately solving finite nuclei with\nrealistic strong interactions. The NCSM and other approaches require an\nextrapolation of the results obtained in a finite basis space to the infinite\nbasis space limit and assessment of the uncertainty of those extrapolations.\nEach observable requires a separate extrapolation and most observables have no\nproven extrapolation method. We propose a feed-forward artificial neural\nnetwork (ANN) method as an extrapolation tool to obtain the ground state energy\nand the ground state point-proton root-mean-square (rms) radius along with\ntheir extrapolation uncertainties. The designed ANNs are sufficient to produce\nresults for these two very different observables in $^6$Li from the ab initio\nNCSM results in small basis spaces that satisfy the following theoretical\nphysics condition: independence of basis space parameters in the limit of\nextremely large matrices. Comparisons of the ANN results with other\nextrapolation methods are also provided.\n", "versions": [{"version": "v1", "created": "Sat, 6 Oct 2018 00:44:34 GMT"}, {"version": "v2", "created": "Sat, 10 Nov 2018 02:59:05 GMT"}, {"version": "v3", "created": "Mon, 20 May 2019 04:08:27 GMT"}, {"version": "v4", "created": "Thu, 6 Jun 2019 16:53:39 GMT"}], "update_date": "2019-06-07", "authors_parsed": [["Negoita", "Gianina Alina", ""], ["Vary", "James P.", ""], ["Luecke", "Glenn R.", ""], ["Maris", "Pieter", ""], ["Shirokov", "Andrey M.", ""], ["Shin", "Ik Jae", ""], ["Kim", "Youngman", ""], ["Ng", "Esmond G.", ""], ["Yang", "Chao", ""], ["Lockner", "Matthew", ""], ["Prabhu", "Gurpur M.", ""]]}, {"id": "1810.04020", "submitter": "Md Zakir Hossain", "authors": "Md. Zakir Hossain, Ferdous Sohel, Mohd Fairuz Shiratuddin, Hamid Laga", "title": "A Comprehensive Survey of Deep Learning for Image Captioning", "comments": "36 Pages, Accepted as a Journal Paper in ACM Computing Surveys\n  (October 2018)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Generating a description of an image is called image captioning. Image\ncaptioning requires to recognize the important objects, their attributes and\ntheir relationships in an image. It also needs to generate syntactically and\nsemantically correct sentences. Deep learning-based techniques are capable of\nhandling the complexities and challenges of image captioning. In this survey\npaper, we aim to present a comprehensive review of existing deep learning-based\nimage captioning techniques. We discuss the foundation of the techniques to\nanalyze their performances, strengths and limitations. We also discuss the\ndatasets and the evaluation metrics popularly used in deep learning based\nautomatic image captioning.\n", "versions": [{"version": "v1", "created": "Sat, 6 Oct 2018 16:31:52 GMT"}, {"version": "v2", "created": "Sun, 14 Oct 2018 04:55:06 GMT"}], "update_date": "2018-10-16", "authors_parsed": [["Hossain", "Md. Zakir", ""], ["Sohel", "Ferdous", ""], ["Shiratuddin", "Mohd Fairuz", ""], ["Laga", "Hamid", ""]]}, {"id": "1810.04021", "submitter": "Neslisah Torosdagli", "authors": "Neslisah Torosdagli, Denise K. Liberton, Payal Verma, Murat Sincan,\n  Janice S. Lee, and Ulas Bagci", "title": "Deep Geodesic Learning for Segmentation and Anatomical Landmarking", "comments": "14 pages, 12 Figures, IEEE Transactions on Medical Imaging 2018,\n  TMI-2018-0898.R1", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we propose a novel deep learning framework for anatomy\nsegmentation and automatic landmark- ing. Specifically, we focus on the\nchallenging problem of mandible segmentation from cone-beam computed tomography\n(CBCT) scans and identification of 9 anatomical landmarks of the mandible on\nthe geodesic space. The overall approach employs three inter-related steps. In\nstep 1, we propose a deep neu- ral network architecture with carefully designed\nregularization, and network hyper-parameters to perform image segmentation\nwithout the need for data augmentation and complex post- processing refinement.\nIn step 2, we formulate the landmark localization problem directly on the\ngeodesic space for sparsely- spaced anatomical landmarks. In step 3, we propose\nto use a long short-term memory (LSTM) network to identify closely- spaced\nlandmarks, which is rather difficult to obtain using other standard detection\nnetworks. The proposed fully automated method showed superior efficacy compared\nto the state-of-the- art mandible segmentation and landmarking approaches in\ncraniofacial anomalies and diseased states. We used a very challenging CBCT\ndataset of 50 patients with a high-degree of craniomaxillofacial (CMF)\nvariability that is realistic in clinical practice. Complementary to the\nquantitative analysis, the qualitative visual inspection was conducted for\ndistinct CBCT scans from 250 patients with high anatomical variability. We have\nalso shown feasibility of the proposed work in an independent dataset from\nMICCAI Head-Neck Challenge (2015) achieving the state-of-the-art performance.\nLastly, we present an in-depth analysis of the proposed deep networks with\nrespect to the choice of hyper-parameters such as pooling and activation\nfunctions.\n", "versions": [{"version": "v1", "created": "Sat, 6 Oct 2018 17:37:39 GMT"}], "update_date": "2018-10-10", "authors_parsed": [["Torosdagli", "Neslisah", ""], ["Liberton", "Denise K.", ""], ["Verma", "Payal", ""], ["Sincan", "Murat", ""], ["Lee", "Janice S.", ""], ["Bagci", "Ulas", ""]]}, {"id": "1810.04028", "submitter": "Hao Zhang", "authors": "Hao Zhang, Jianwei Ma", "title": "Hartley Spectral Pooling for Deep Learning", "comments": "5 pages, 6 figures, letter", "journal-ref": "CSIAM Transactions on Applied Mathematics, 2020, 1(3):518-529", "doi": "10.4208/csiam-am.2020", "report-no": null, "categories": "cs.CV cs.LG eess.SP stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In most convolution neural networks (CNNs), downsampling hidden layers is\nadopted for increasing computation efficiency and the receptive field size.\nSuch operation is commonly so-called pooling. Maximation and averaging over\nsliding windows (max/average pooling), and plain downsampling in the form of\nstrided convolution are popular pooling methods. Since the pooling is a lossy\nprocedure, a motivation of our work is to design a new pooling approach for\nless lossy in the dimensionality reduction. Inspired by the Fourier spectral\npooling(FSP) proposed by Rippel et. al. [1], we present the Hartley transform\nbased spectral pooling method in CNNs. Compared with FSP, the proposed spectral\npooling avoids the use of complex arithmetic for frequency representation and\nreduces the computation. Spectral pooling preserves more structure features for\nnetwork's discriminability than max and average pooling. We empirically show\nthat Hartley spectral pooling gives rise to the convergence of training CNNs on\nMNIST and CIFAR-10 datasets.\n", "versions": [{"version": "v1", "created": "Sun, 7 Oct 2018 06:57:01 GMT"}, {"version": "v2", "created": "Thu, 8 Oct 2020 20:05:06 GMT"}], "update_date": "2020-10-12", "authors_parsed": [["Zhang", "Hao", ""], ["Ma", "Jianwei", ""]]}, {"id": "1810.04038", "submitter": "Ming Zeng", "authors": "Ming Zeng, Haoxiang Gao, Tong Yu, Ole J. Mengshoel, Helge Langseth,\n  Ian Lane, Xiaobing Liu", "title": "Understanding and Improving Recurrent Networks for Human Activity\n  Recognition by Continuous Attention", "comments": "8 pages. published in The International Symposium on Wearable\n  Computers (ISWC) 2018", "journal-ref": "The International Symposium on Wearable Computers (ISWC) 2018", "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep neural networks, including recurrent networks, have been successfully\napplied to human activity recognition. Unfortunately, the final representation\nlearned by recurrent networks might encode some noise (irrelevant signal\ncomponents, unimportant sensor modalities, etc.). Besides, it is difficult to\ninterpret the recurrent networks to gain insight into the models' behavior. To\naddress these issues, we propose two attention models for human activity\nrecognition: temporal attention and sensor attention. These two mechanisms\nadaptively focus on important signals and sensor modalities. To further improve\nthe understandability and mean F1 score, we add continuity constraints,\nconsidering that continuous sensor signals are more robust than discrete ones.\nWe evaluate the approaches on three datasets and obtain state-of-the-art\nresults. Furthermore, qualitative analysis shows that the attention learned by\nthe models agree well with human intuition.\n", "versions": [{"version": "v1", "created": "Sun, 7 Oct 2018 21:24:19 GMT"}], "update_date": "2018-10-10", "authors_parsed": [["Zeng", "Ming", ""], ["Gao", "Haoxiang", ""], ["Yu", "Tong", ""], ["Mengshoel", "Ole J.", ""], ["Langseth", "Helge", ""], ["Lane", "Ian", ""], ["Liu", "Xiaobing", ""]]}, {"id": "1810.04040", "submitter": "Chen Zhu", "authors": "Chen Zhu, Hengshu Zhu, Hui Xiong, Chao Ma, Fang Xie, Pengliang Ding,\n  Pan Li", "title": "Person-Job Fit: Adapting the Right Talent for the Right Job with Joint\n  Representation Learning", "comments": "16 pages, 5 figures", "journal-ref": "ACM Transactions on Management Information Systems (2018)", "doi": null, "report-no": null, "categories": "cs.IR cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Person-Job Fit is the process of matching the right talent for the right job\nby identifying talent competencies that are required for the job. While many\nqualitative efforts have been made in related fields, it still lacks of\nquantitative ways of measuring talent competencies as well as the job's talent\nrequirements. To this end, in this paper, we propose a novel end-to-end\ndata-driven model based on Convolutional Neural Network (CNN), namely\nPerson-Job Fit Neural Network (PJFNN), for matching a talent qualification to\nthe requirements of a job. To be specific, PJFNN is a bipartite neural network\nwhich can effectively learn the joint representation of Person-Job fitness from\nhistorical job applications. In particular, due to the design of a hierarchical\nrepresentation structure, PJFNN can not only estimate whether a candidate fits\na job, but also identify which specific requirement items in the job posting\nare satisfied by the candidate by measuring the distances between corresponding\nlatent representations. Finally, the extensive experiments on a large-scale\nreal-world dataset clearly validate the performance of PJFNN in terms of\nPerson-Job Fit prediction. Also, we provide effective data visualization to\nshow some job and talent benchmark insights obtained by PJFNN.\n", "versions": [{"version": "v1", "created": "Mon, 8 Oct 2018 04:13:39 GMT"}], "update_date": "2018-10-10", "authors_parsed": [["Zhu", "Chen", ""], ["Zhu", "Hengshu", ""], ["Xiong", "Hui", ""], ["Ma", "Chao", ""], ["Xie", "Fang", ""], ["Ding", "Pengliang", ""], ["Li", "Pan", ""]]}, {"id": "1810.04045", "submitter": "Eric Nalisnick", "authors": "Eric Nalisnick, Jos\\'e Miguel Hern\\'andez-Lobato, Padhraic Smyth", "title": "Dropout as a Structured Shrinkage Prior", "comments": "ICML 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Dropout regularization of deep neural networks has been a mysterious yet\neffective tool to prevent overfitting. Explanations for its success range from\nthe prevention of \"co-adapted\" weights to it being a form of cheap Bayesian\ninference. We propose a novel framework for understanding multiplicative noise\nin neural networks, considering continuous distributions as well as Bernoulli\nnoise (i.e. dropout). We show that multiplicative noise induces structured\nshrinkage priors on a network's weights. We derive the equivalence through\nreparametrization properties of scale mixtures and without invoking any\napproximations. Given the equivalence, we then show that dropout's Monte Carlo\ntraining objective approximates marginal MAP estimation. We leverage these\ninsights to propose a novel shrinkage framework for resnets, terming the prior\n'automatic depth determination' as it is the natural analog of automatic\nrelevance determination for network depth. Lastly, we investigate two inference\nstrategies that improve upon the aforementioned MAP approximation in regression\nbenchmarks.\n", "versions": [{"version": "v1", "created": "Tue, 9 Oct 2018 14:44:08 GMT"}, {"version": "v2", "created": "Sun, 10 Feb 2019 14:35:37 GMT"}, {"version": "v3", "created": "Wed, 29 May 2019 14:01:20 GMT"}], "update_date": "2019-05-30", "authors_parsed": [["Nalisnick", "Eric", ""], ["Hern\u00e1ndez-Lobato", "Jos\u00e9 Miguel", ""], ["Smyth", "Padhraic", ""]]}, {"id": "1810.04058", "submitter": "Ian Xiao", "authors": "Ian Xiao", "title": "A Distributed Reinforcement Learning Solution With Knowledge Transfer\n  Capability for A Bike Rebalancing Problem", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.HC cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Rebalancing is a critical service bottleneck for many transportation\nservices, such as Citi Bike. Citi Bike relies on manual orchestrations of\nrebalancing bikes between dispatchers and field agents. Motivated by such\nproblem and the lack of smart autonomous solutions in this area, this project\nexplored a new RL architecture called Distributed RL (DiRL) with Transfer\nLearning (TL) capability. The DiRL solution is adaptive to changing traffic\ndynamics when keeping bike stock under control at the minimum cost. DiRL\nachieved a 350% improvement in bike rebalancing autonomously and TL offered a\n62.4% performance boost in managing an entire bike network. Lastly, a field\ntrip to the dispatch office of Chariot, a ride-sharing service, provided\ninsights to overcome challenges of deploying an RL solution in the real world.\n", "versions": [{"version": "v1", "created": "Tue, 9 Oct 2018 14:57:55 GMT"}], "update_date": "2018-10-10", "authors_parsed": [["Xiao", "Ian", ""]]}, {"id": "1810.04064", "submitter": "Miao Cheng", "authors": "Miao Cheng, Zunren Liu, Hongwei Zou, Ah Chung Tsoi", "title": "A Family of Maximum Margin Criterion for Adaptive Learning", "comments": "14 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.AP stat.ML", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  In recent years, pattern analysis plays an important role in data mining and\nrecognition, and many variants have been proposed to handle complicated\nscenarios. In the literature, it has been quite familiar with high\ndimensionality of data samples, but either such characteristics or large data\nhave become usual sense in real-world applications. In this work, an improved\nmaximum margin criterion (MMC) method is introduced firstly. With the new\ndefinition of MMC, several variants of MMC, including random MMC, layered MMC,\n2D^2 MMC, are designed to make adaptive learning applicable. Particularly, the\nMMC network is developed to learn deep features of images in light of simple\ndeep networks. Experimental results on a diversity of data sets demonstrate the\ndiscriminant ability of proposed MMC methods are compenent to be adopted in\ncomplicated application scenarios.\n", "versions": [{"version": "v1", "created": "Tue, 9 Oct 2018 16:45:53 GMT"}, {"version": "v2", "created": "Thu, 8 Nov 2018 02:47:47 GMT"}], "update_date": "2018-11-09", "authors_parsed": [["Cheng", "Miao", ""], ["Liu", "Zunren", ""], ["Zou", "Hongwei", ""], ["Tsoi", "Ah Chung", ""]]}, {"id": "1810.04065", "submitter": "Elvis Dohmatob", "authors": "Elvis Dohmatob", "title": "Generalized No Free Lunch Theorem for Adversarial Robustness", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  This manuscript presents some new impossibility results on adversarial\nrobustness in machine learning, a very important yet largely open problem. We\nshow that if conditioned on a class label the data distribution satisfies the\n$W_2$ Talagrand transportation-cost inequality (for example, this condition is\nsatisfied if the conditional distribution has density which is log-concave; is\nthe uniform measure on a compact Riemannian manifold with positive Ricci\ncurvature, any classifier can be adversarially fooled with high probability\nonce the perturbations are slightly greater than the natural noise level in the\nproblem. We call this result The Strong \"No Free Lunch\" Theorem as some recent\nresults (Tsipras et al. 2018, Fawzi et al. 2018, etc.) on the subject can be\nimmediately recovered as very particular cases. Our theoretical bounds are\ndemonstrated on both simulated and real data (MNIST). We conclude the\nmanuscript with some speculation on possible future research directions.\n", "versions": [{"version": "v1", "created": "Mon, 8 Oct 2018 10:13:48 GMT"}, {"version": "v2", "created": "Thu, 11 Oct 2018 18:11:23 GMT"}, {"version": "v3", "created": "Mon, 29 Oct 2018 17:13:27 GMT"}, {"version": "v4", "created": "Tue, 13 Nov 2018 09:51:02 GMT"}, {"version": "v5", "created": "Tue, 11 Dec 2018 19:11:52 GMT"}, {"version": "v6", "created": "Fri, 1 Feb 2019 05:57:34 GMT"}, {"version": "v7", "created": "Mon, 22 Apr 2019 12:43:00 GMT"}, {"version": "v8", "created": "Tue, 4 Jun 2019 04:39:09 GMT"}], "update_date": "2019-06-05", "authors_parsed": [["Dohmatob", "Elvis", ""]]}, {"id": "1810.04066", "submitter": "Pashupati Hegde", "authors": "Pashupati Hegde, Markus Heinonen, Harri L\\\"ahdesm\\\"aki, Samuel Kaski", "title": "Deep learning with differential Gaussian process flows", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We propose a novel deep learning paradigm of differential flows that learn a\nstochastic differential equation transformations of inputs prior to a standard\nclassification or regression function. The key property of differential\nGaussian processes is the warping of inputs through infinitely deep, but\ninfinitesimal, differential fields, that generalise discrete layers into a\ndynamical system. We demonstrate state-of-the-art results that exceed the\nperformance of deep Gaussian processes and neural networks\n", "versions": [{"version": "v1", "created": "Tue, 9 Oct 2018 15:15:23 GMT"}, {"version": "v2", "created": "Mon, 15 Oct 2018 11:46:33 GMT"}], "update_date": "2018-10-16", "authors_parsed": [["Hegde", "Pashupati", ""], ["Heinonen", "Markus", ""], ["L\u00e4hdesm\u00e4ki", "Harri", ""], ["Kaski", "Samuel", ""]]}, {"id": "1810.04088", "submitter": "Thomas Nedelec", "authors": "R\\'emy Degenne, Thomas Nedelec, Cl\\'ement Calauz\\`enes and Vianney\n  Perchet", "title": "Bridging the gap between regret minimization and best arm\n  identification, with application to A/B tests", "comments": null, "journal-ref": "AISTATS 2019 proceedings", "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  State of the art online learning procedures focus either on selecting the\nbest alternative (\"best arm identification\") or on minimizing the cost (the\n\"regret\"). We merge these two objectives by providing the theoretical analysis\nof cost minimizing algorithms that are also delta-PAC (with a proven guaranteed\nbound on the decision time), hence fulfilling at the same time regret\nminimization and best arm identification. This analysis sheds light on the\ncommon observation that ill-callibrated UCB-algorithms minimize regret while\nstill identifying quickly the best arm.\n  We also extend these results to the non-iid case faced by many practitioners.\nThis provides a technique to make cost versus decision time compromise when\ndoing adaptive tests with applications ranging from website A/B testing to\nclinical trials.\n", "versions": [{"version": "v1", "created": "Tue, 9 Oct 2018 15:45:10 GMT"}, {"version": "v2", "created": "Tue, 26 Feb 2019 08:14:09 GMT"}], "update_date": "2019-02-27", "authors_parsed": [["Degenne", "R\u00e9my", ""], ["Nedelec", "Thomas", ""], ["Calauz\u00e8nes", "Cl\u00e9ment", ""], ["Perchet", "Vianney", ""]]}, {"id": "1810.04100", "submitter": "Lam Nguyen", "authors": "Marten van Dijk, Lam M. Nguyen, Phuong Ha Nguyen, Dzung T. Phan", "title": "Characterization of Convex Objective Functions and Optimal Expected\n  Convergence Rates for SGD", "comments": null, "journal-ref": "Proceedings of the 36th International Conference on Machine\n  Learning, PMLR 97, 2019", "doi": null, "report-no": null, "categories": "math.OC cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study Stochastic Gradient Descent (SGD) with diminishing step sizes for\nconvex objective functions. We introduce a definitional framework and theory\nthat defines and characterizes a core property, called curvature, of convex\nobjective functions. In terms of curvature we can derive a new inequality that\ncan be used to compute an optimal sequence of diminishing step sizes by solving\na differential equation. Our exact solutions confirm known results in\nliterature and allows us to fully characterize a new regularizer with its\ncorresponding expected convergence rates.\n", "versions": [{"version": "v1", "created": "Tue, 9 Oct 2018 16:15:01 GMT"}, {"version": "v2", "created": "Tue, 14 May 2019 00:50:20 GMT"}], "update_date": "2019-05-15", "authors_parsed": [["van Dijk", "Marten", ""], ["Nguyen", "Lam M.", ""], ["Nguyen", "Phuong Ha", ""], ["Phan", "Dzung T.", ""]]}, {"id": "1810.04106", "submitter": "Fei Wang", "authors": "Fei Wang, Jinsong Han, Feng Lin, Kui Ren", "title": "WiPIN: Operation-free Passive Person Identification Using Wi-Fi Signals", "comments": "accepted by GLOBECOM 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.SP cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Wi-Fi signals-based person identification attracts increasing attention in\nthe booming Internet-of-Things era mainly due to its pervasiveness and\npassiveness. Most previous work applies gaits extracted from WiFi distortions\ncaused by the person walking to achieve the identification. However, to extract\nuseful gait, a person must walk along a pre-defined path for several meters,\nwhich requires user high collaboration and increases identification time\noverhead, thus limiting use scenarios. Moreover, gait based work has severe\nshortcoming in identification performance, especially when the user volume is\nlarge. In order to eliminate the above limitations, in this paper, we present\nan operation-free person identification system, namely WiPIN, that requires\nleast user collaboration and achieves good performance. WiPIN is based on an\nentirely new insight that Wi-Fi signals would carry person body information\nwhen propagating through the body, which is potentially discriminated for\nperson identification. Then we demonstrate the feasibility on commodity\noff-the-shelf Wi-Fi devices by well-designed signal pre-processing, feature\nextraction, and identity matching algorithms. Results show that WiPIN achieves\n92% identification accuracy over 30 users, high robustness to various\nexperimental settings, and low identifying time overhead, i.e., less than\n300ms.\n", "versions": [{"version": "v1", "created": "Sat, 6 Oct 2018 02:17:07 GMT"}, {"version": "v2", "created": "Thu, 18 Jul 2019 19:22:42 GMT"}], "update_date": "2019-07-22", "authors_parsed": [["Wang", "Fei", ""], ["Han", "Jinsong", ""], ["Lin", "Feng", ""], ["Ren", "Kui", ""]]}, {"id": "1810.04114", "submitter": "Ksenia Konyushkova", "authors": "Ksenia Konyushkova and Raphael Sznitman and Pascal Fua", "title": "Discovering General-Purpose Active Learning Strategies", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a general-purpose approach to discovering active learning (AL)\nstrategies from data. These strategies are transferable from one domain to\nanother and can be used in conjunction with many machine learning models. To\nthis end, we formalize the annotation process as a Markov decision process,\ndesign universal state and action spaces and introduce a new reward function\nthat precisely model the AL objective of minimizing the annotation cost. We\nseek to find an optimal (non-myopic) AL strategy using reinforcement learning.\nWe evaluate the learned strategies on multiple unrelated domains and show that\nthey consistently outperform state-of-the-art baselines.\n", "versions": [{"version": "v1", "created": "Tue, 9 Oct 2018 16:40:02 GMT"}, {"version": "v2", "created": "Tue, 2 Apr 2019 10:53:33 GMT"}], "update_date": "2019-04-03", "authors_parsed": [["Konyushkova", "Ksenia", ""], ["Sznitman", "Raphael", ""], ["Fua", "Pascal", ""]]}, {"id": "1810.04115", "submitter": "Nick Whiteley Prof.", "authors": "Nick Whiteley, Matt W. Jones and Aleks P.F. Domanski", "title": "The Viterbi process, decay-convexity and parallelized maximum\n  a-posteriori estimation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.PR cs.LG stat.ME stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The Viterbi process is the limiting maximum a-posteriori estimate of the\nunobserved path in a hidden Markov model as the length of the time horizon\ngrows. The existence of such a process suggests that approximate estimation\nusing optimization algorithms which process data segments in parallel may be\naccurate. For models on state-space $\\mathbb{R}^{d}$ satisfying a new\n\"decay-convexity\" condition, we develop an approach to existence of the Viterbi\nprocess via fixed points of ordinary differential equations in a certain\ninfinite dimensional Hilbert space. Bounds on the distance to the Viterbi\nprocess show that approximate estimation via parallelization can indeed be\naccurate and scaleable to high-dimensional problems because the rate of\nconvergence to the Viterbi process does not necessarily depend on $d$. The\nresults are applied to a factor model with stochastic volatility and a model of\nneural population activity.\n", "versions": [{"version": "v1", "created": "Mon, 8 Oct 2018 16:17:21 GMT"}, {"version": "v2", "created": "Thu, 11 Oct 2018 12:34:27 GMT"}, {"version": "v3", "created": "Thu, 24 Oct 2019 09:35:41 GMT"}, {"version": "v4", "created": "Wed, 18 Dec 2019 18:24:59 GMT"}], "update_date": "2019-12-19", "authors_parsed": [["Whiteley", "Nick", ""], ["Jones", "Matt W.", ""], ["Domanski", "Aleks P. F.", ""]]}, {"id": "1810.04118", "submitter": "Mehdi Mohammadi", "authors": "Mehdi Mohammadi, Ala Al-Fuqaha, Mohsen Guizani, Jun-Seok Oh", "title": "Semi-supervised Deep Reinforcement Learning in Support of IoT and Smart\n  City Services", "comments": "11 pages, 7 figures. Accepted for publication in IEEE Internet of\n  Things Journal", "journal-ref": "IEEE Internet of Things Journal, Volume 5, Issue 2, 2018", "doi": "10.1109/JIOT.2017.2712560", "report-no": null, "categories": "cs.NI cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Smart services are an important element of the smart cities and the Internet\nof Things (IoT) ecosystems where the intelligence behind the services is\nobtained and improved through the sensory data. Providing a large amount of\ntraining data is not always feasible; therefore, we need to consider\nalternative ways that incorporate unlabeled data as well. In recent years, Deep\nreinforcement learning (DRL) has gained great success in several application\ndomains. It is an applicable method for IoT and smart city scenarios where\nauto-generated data can be partially labeled by users' feedback for training\npurposes. In this paper, we propose a semi-supervised deep reinforcement\nlearning model that fits smart city applications as it consumes both labeled\nand unlabeled data to improve the performance and accuracy of the learning\nagent. The model utilizes Variational Autoencoders (VAE) as the inference\nengine for generalizing optimal policies. To the best of our knowledge, the\nproposed model is the first investigation that extends deep reinforcement\nlearning to the semi-supervised paradigm. As a case study of smart city\napplications, we focus on smart buildings and apply the proposed model to the\nproblem of indoor localization based on BLE signal strength. Indoor\nlocalization is the main component of smart city services since people spend\nsignificant time in indoor environments. Our model learns the best action\npolicies that lead to a close estimation of the target locations with an\nimprovement of 23% in terms of distance to the target and at least 67% more\nreceived rewards compared to the supervised DRL model.\n", "versions": [{"version": "v1", "created": "Tue, 9 Oct 2018 16:47:25 GMT"}], "update_date": "2018-10-10", "authors_parsed": [["Mohammadi", "Mehdi", ""], ["Al-Fuqaha", "Ala", ""], ["Guizani", "Mohsen", ""], ["Oh", "Jun-Seok", ""]]}, {"id": "1810.04122", "submitter": "Jennifer John", "authors": "Jennifer N. John, Conner Galloway, Alexander Valys", "title": "Deep Convolutional Neural Networks for Noise Detection in ECGs", "comments": "8 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.SP cs.LG cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Mobile electrocardiogram (ECG) recording technologies represent a promising\ntool to fight the ongoing epidemic of cardiovascular diseases, which are\nresponsible for more deaths globally than any other cause. While the ability to\nmonitor one's heart activity at any time in any place is a crucial advantage of\nsuch technologies, it is also the cause of a drawback: signal noise due to\nenvironmental factors can render the ECGs illegible. In this work, we develop\nconvolutional neural networks (CNNs) to automatically label ECGs for noise,\ntraining them on a novel noise-annotated dataset. By reducing distraction from\nnoisy intervals of signals, such networks have the potential to increase the\naccuracy of models for the detection of atrial fibrillation, long QT syndrome,\nand other cardiovascular conditions. Comparing several architectures, we find\nthat a 16-layer CNN adapted from the VGG16 network which generates one\nprediction per second on a 10-second input performs exceptionally well on this\ntask, with an AUC of 0.977.\n", "versions": [{"version": "v1", "created": "Fri, 5 Oct 2018 02:59:04 GMT"}], "update_date": "2018-10-10", "authors_parsed": [["John", "Jennifer N.", ""], ["Galloway", "Conner", ""], ["Valys", "Alexander", ""]]}, {"id": "1810.04133", "submitter": "Weihao Gao", "authors": "Weihao Gao, Ashok Vardhan Makkuva, Sewoong Oh, Pramod Viswanath", "title": "Learning One-hidden-layer Neural Networks under General Input\n  Distributions", "comments": "19 pages, 4 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Significant advances have been made recently on training neural networks,\nwhere the main challenge is in solving an optimization problem with abundant\ncritical points. However, existing approaches to address this issue crucially\nrely on a restrictive assumption: the training data is drawn from a Gaussian\ndistribution. In this paper, we provide a novel unified framework to design\nloss functions with desirable landscape properties for a wide range of general\ninput distributions. On these loss functions, remarkably, stochastic gradient\ndescent theoretically recovers the true parameters with global initializations\nand empirically outperforms the existing approaches. Our loss function design\nbridges the notion of score functions with the topic of neural network\noptimization. Central to our approach is the task of estimating the score\nfunction from samples, which is of basic and independent interest to\ntheoretical statistics. Traditional estimation methods (example: kernel based)\nfail right at the outset; we bring statistical methods of local likelihood to\ndesign a novel estimator of score functions, that provably adapts to the local\ngeometry of the unknown density.\n", "versions": [{"version": "v1", "created": "Tue, 9 Oct 2018 16:58:33 GMT"}, {"version": "v2", "created": "Tue, 26 Feb 2019 21:52:06 GMT"}], "update_date": "2019-02-28", "authors_parsed": [["Gao", "Weihao", ""], ["Makkuva", "Ashok Vardhan", ""], ["Oh", "Sewoong", ""], ["Viswanath", "Pramod", ""]]}, {"id": "1810.04147", "submitter": "Yogesh Balaji", "authors": "Yogesh Balaji, Hamed Hassani, Rama Chellappa and Soheil Feizi", "title": "Entropic GANs meet VAEs: A Statistical Approach to Compute Sample\n  Likelihoods in GANs", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Building on the success of deep learning, two modern approaches to learn a\nprobability model from the data are Generative Adversarial Networks (GANs) and\nVariational AutoEncoders (VAEs). VAEs consider an explicit probability model\nfor the data and compute a generative distribution by maximizing a variational\nlower-bound on the log-likelihood function. GANs, however, compute a generative\nmodel by minimizing a distance between observed and generated probability\ndistributions without considering an explicit model for the observed data. The\nlack of having explicit probability models in GANs prohibits computation of\nsample likelihoods in their frameworks and limits their use in statistical\ninference problems. In this work, we resolve this issue by constructing an\nexplicit probability model that can be used to compute sample likelihood\nstatistics in GANs. In particular, we prove that under this probability model,\na family of Wasserstein GANs with an entropy regularization can be viewed as a\ngenerative model that maximizes a variational lower-bound on average sample log\nlikelihoods, an approach that VAEs are based on. This result makes a principled\nconnection between two modern generative models, namely GANs and VAEs. In\naddition to the aforementioned theoretical results, we compute likelihood\nstatistics for GANs trained on Gaussian, MNIST, SVHN, CIFAR-10 and LSUN\ndatasets. Our numerical results validate the proposed theory.\n", "versions": [{"version": "v1", "created": "Tue, 9 Oct 2018 17:27:20 GMT"}, {"version": "v2", "created": "Wed, 5 Jun 2019 05:22:08 GMT"}], "update_date": "2019-06-06", "authors_parsed": [["Balaji", "Yogesh", ""], ["Hassani", "Hamed", ""], ["Chellappa", "Rama", ""], ["Feizi", "Soheil", ""]]}, {"id": "1810.04152", "submitter": "George Tucker", "authors": "George Tucker, Dieterich Lawson, Shixiang Gu, Chris J. Maddison", "title": "Doubly Reparameterized Gradient Estimators for Monte Carlo Objectives", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep latent variable models have become a popular model choice due to the\nscalable learning algorithms introduced by (Kingma & Welling, 2013; Rezende et\nal., 2014). These approaches maximize a variational lower bound on the\nintractable log likelihood of the observed data. Burda et al. (2015) introduced\na multi-sample variational bound, IWAE, that is at least as tight as the\nstandard variational lower bound and becomes increasingly tight as the number\nof samples increases. Counterintuitively, the typical inference network\ngradient estimator for the IWAE bound performs poorly as the number of samples\nincreases (Rainforth et al., 2018; Le et al., 2018). Roeder et al. (2017)\npropose an improved gradient estimator, however, are unable to show it is\nunbiased. We show that it is in fact biased and that the bias can be estimated\nefficiently with a second application of the reparameterization trick. The\ndoubly reparameterized gradient (DReG) estimator does not suffer as the number\nof samples increases, resolving the previously raised issues. The same idea can\nbe used to improve many recently introduced training techniques for latent\nvariable models. In particular, we show that this estimator reduces the\nvariance of the IWAE gradient, the reweighted wake-sleep update (RWS)\n(Bornschein & Bengio, 2014), and the jackknife variational inference (JVI)\ngradient (Nowozin, 2018). Finally, we show that this computationally efficient,\nunbiased drop-in gradient estimator translates to improved performance for all\nthree objectives on several modeling tasks.\n", "versions": [{"version": "v1", "created": "Tue, 9 Oct 2018 17:46:55 GMT"}, {"version": "v2", "created": "Mon, 19 Nov 2018 18:40:45 GMT"}], "update_date": "2018-11-20", "authors_parsed": [["Tucker", "George", ""], ["Lawson", "Dieterich", ""], ["Gu", "Shixiang", ""], ["Maddison", "Chris J.", ""]]}, {"id": "1810.04160", "submitter": "Myung Seok Shim", "authors": "Myung Seok Shim, Peng Li", "title": "Optimized Gated Deep Learning Architectures for Sensor Fusion", "comments": "10 pages, 5 figures. Submitted to ICLR 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Sensor fusion is a key technology that integrates various sensory inputs to\nallow for robust decision making in many applications such as autonomous\ndriving and robot control. Deep neural networks have been adopted for sensor\nfusion in a body of recent studies. Among these, the so-called netgated\narchitecture was proposed, which has demonstrated improved performances over\nthe conventional convolutional neural networks (CNN). In this paper, we address\nseveral limitations of the baseline negated architecture by proposing two\nfurther optimized architectures: a coarser-grained gated architecture employing\n(feature) group-level fusion weights and a two-stage gated architectures\nleveraging both the group-level and feature level fusion weights. Using driving\nmode prediction and human activity recognition datasets, we demonstrate the\nsignificant performance improvements brought by the proposed gated\narchitectures and also their robustness in the presence of sensor noise and\nfailures.\n", "versions": [{"version": "v1", "created": "Mon, 8 Oct 2018 18:24:12 GMT"}], "update_date": "2018-10-11", "authors_parsed": [["Shim", "Myung Seok", ""], ["Li", "Peng", ""]]}, {"id": "1810.04227", "submitter": "Chris Cantwell", "authors": "Chris D. Cantwell, Yumnah Mohamied, Konstantinos N. Tzortzis, Stef\n  Garasto, Charles Houston, Rasheda A. Chowdhury, Fu Siong Ng, Anil A. Bharath,\n  Nicholas S. Peters", "title": "Rethinking multiscale cardiac electrophysiology with machine learning\n  and predictive modelling", "comments": null, "journal-ref": null, "doi": "10.1016/j.compbiomed.2018.10.015", "report-no": null, "categories": "cs.LG math.DS q-bio.TO stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We review some of the latest approaches to analysing cardiac\nelectrophysiology data using machine learning and predictive modelling. Cardiac\narrhythmias, particularly atrial fibrillation, are a major global healthcare\nchallenge. Treatment is often through catheter ablation, which involves the\ntargeted localized destruction of regions of the myocardium responsible for\ninitiating or perpetuating the arrhythmia. Ablation targets are either\nanatomically defined, or identified based on their functional properties as\ndetermined through the analysis of contact intracardiac electrograms acquired\nwith increasing spatial density by modern electroanatomic mapping systems.\nWhile numerous quantitative approaches have been investigated over the past\ndecades for identifying these critical curative sites, few have provided a\nreliable and reproducible advance in success rates. Machine learning\ntechniques, including recent deep-learning approaches, offer a potential route\nto gaining new insight from this wealth of highly complex spatio-temporal\ninformation that existing methods struggle to analyse. Coupled with predictive\nmodelling, these techniques offer exciting opportunities to advance the field\nand produce more accurate diagnoses and robust personalised treatment. We\noutline some of these methods and illustrate their use in making predictions\nfrom the contact electrogram and augmenting predictive modelling tools, both by\nmore rapidly predicting future states of the system and by inferring the\nparameters of these models from experimental observations.\n", "versions": [{"version": "v1", "created": "Tue, 9 Oct 2018 20:09:45 GMT"}], "update_date": "2018-10-22", "authors_parsed": [["Cantwell", "Chris D.", ""], ["Mohamied", "Yumnah", ""], ["Tzortzis", "Konstantinos N.", ""], ["Garasto", "Stef", ""], ["Houston", "Charles", ""], ["Chowdhury", "Rasheda A.", ""], ["Ng", "Fu Siong", ""], ["Bharath", "Anil A.", ""], ["Peters", "Nicholas S.", ""]]}, {"id": "1810.04240", "submitter": "Kyle Julian", "authors": "Kyle D. Julian and Mykel J. Kochenderfer and Michael P. Owen", "title": "Deep Neural Network Compression for Aircraft Collision Avoidance Systems", "comments": null, "journal-ref": null, "doi": "10.2514/1.G003724", "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  One approach to designing decision making logic for an aircraft collision\navoidance system frames the problem as a Markov decision process and optimizes\nthe system using dynamic programming. The resulting collision avoidance\nstrategy can be represented as a numeric table. This methodology has been used\nin the development of the Airborne Collision Avoidance System X (ACAS X) family\nof collision avoidance systems for manned and unmanned aircraft, but the high\ndimensionality of the state space leads to very large tables. To improve\nstorage efficiency, a deep neural network is used to approximate the table.\nWith the use of an asymmetric loss function and a gradient descent algorithm,\nthe parameters for this network can be trained to provide accurate estimates of\ntable values while preserving the relative preferences of the possible\nadvisories for each state. By training multiple networks to represent\nsubtables, the network also decreases the required runtime for computing the\ncollision avoidance advisory. Simulation studies show that the network improves\nthe safety and efficiency of the collision avoidance system. Because only the\nnetwork parameters need to be stored, the required storage space is reduced by\na factor of 1000, enabling the collision avoidance system to operate using\ncurrent avionics systems.\n", "versions": [{"version": "v1", "created": "Tue, 9 Oct 2018 21:02:48 GMT"}], "update_date": "2019-03-05", "authors_parsed": [["Julian", "Kyle D.", ""], ["Kochenderfer", "Mykel J.", ""], ["Owen", "Michael P.", ""]]}, {"id": "1810.04244", "submitter": "Kyle Julian", "authors": "Kyle D. Julian and Mykel J. Kochenderfer", "title": "Distributed Wildfire Surveillance with Autonomous Aircraft using Deep\n  Reinforcement Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Teams of autonomous unmanned aircraft can be used to monitor wildfires,\nenabling firefighters to make informed decisions. However, controlling multiple\nautonomous fixed-wing aircraft to maximize forest fire coverage is a complex\nproblem. The state space is high dimensional, the fire propagates\nstochastically, the sensor information is imperfect, and the aircraft must\ncoordinate with each other to accomplish their mission. This work presents two\ndeep reinforcement learning approaches for training decentralized controllers\nthat accommodate the high dimensionality and uncertainty inherent in the\nproblem. The first approach controls the aircraft using immediate observations\nof the individual aircraft. The second approach allows aircraft to collaborate\non a map of the wildfire's state and maintain a time history of locations\nvisited, which are used as inputs to the controller. Simulation results show\nthat both approaches allow the aircraft to accurately track wildfire expansions\nand outperform an online receding horizon controller. Additional simulations\ndemonstrate that the approach scales with different numbers of aircraft and\ngeneralizes to different wildfire shapes.\n", "versions": [{"version": "v1", "created": "Tue, 9 Oct 2018 21:13:05 GMT"}], "update_date": "2018-10-12", "authors_parsed": [["Julian", "Kyle D.", ""], ["Kochenderfer", "Mykel J.", ""]]}, {"id": "1810.04246", "submitter": "Mohammed Jabi", "authors": "Mohammed Jabi, Marco Pedersoli, Amar Mitiche and Ismail Ben Ayed", "title": "Deep clustering: On the link between discriminative models and K-means", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In the context of recent deep clustering studies, discriminative models\ndominate the literature and report the most competitive performances. These\nmodels learn a deep discriminative neural network classifier in which the\nlabels are latent. Typically, they use multinomial logistic regression\nposteriors and parameter regularization, as is very common in supervised\nlearning. It is generally acknowledged that discriminative objective functions\n(e.g., those based on the mutual information or the KL divergence) are more\nflexible than generative approaches (e.g., K-means) in the sense that they make\nfewer assumptions about the data distributions and, typically, yield much\nbetter unsupervised deep learning results. On the surface, several recent\ndiscriminative models may seem unrelated to K-means. This study shows that\nthese models are, in fact, equivalent to K-means under mild conditions and\ncommon posterior models and parameter regularization. We prove that, for the\ncommonly used logistic regression posteriors, maximizing the $L_2$ regularized\nmutual information via an approximate alternating direction method (ADM) is\nequivalent to a soft and regularized K-means loss. Our theoretical analysis not\nonly connects directly several recent state-of-the-art discriminative models to\nK-means, but also leads to a new soft and regularized deep K-means algorithm,\nwhich yields competitive performance on several image clustering benchmarks.\n", "versions": [{"version": "v1", "created": "Tue, 9 Oct 2018 21:17:09 GMT"}, {"version": "v2", "created": "Sun, 15 Dec 2019 23:28:05 GMT"}], "update_date": "2019-12-17", "authors_parsed": [["Jabi", "Mohammed", ""], ["Pedersoli", "Marco", ""], ["Mitiche", "Amar", ""], ["Ayed", "Ismail Ben", ""]]}, {"id": "1810.04247", "submitter": "Ofir Lindenbaum", "authors": "Yutaro Yamada and Ofir Lindenbaum and Sahand Negahban and Yuval Kluger", "title": "Feature Selection using Stochastic Gates", "comments": "Published in ICML 2020", "journal-ref": "Proceedings of Machine Learning and Systems 2020, pages 8952--8963", "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://creativecommons.org/publicdomain/zero/1.0/", "abstract": "  Feature selection problems have been extensively studied for linear\nestimation, for instance, Lasso, but less emphasis has been placed on feature\nselection for non-linear functions. In this study, we propose a method for\nfeature selection in high-dimensional non-linear function estimation problems.\nThe new procedure is based on minimizing the $\\ell_0$ norm of the vector of\nindicator variables that represent if a feature is selected or not. Our\napproach relies on the continuous relaxation of Bernoulli distributions, which\nallows our model to learn the parameters of the approximate Bernoulli\ndistributions via gradient descent. This general framework simultaneously\nminimizes a loss function while selecting relevant features. Furthermore, we\nprovide an information-theoretic justification of incorporating Bernoulli\ndistribution into our approach and demonstrate the potential of the approach on\nsynthetic and real-life applications.\n", "versions": [{"version": "v1", "created": "Tue, 9 Oct 2018 21:17:37 GMT"}, {"version": "v2", "created": "Wed, 30 Jan 2019 01:24:37 GMT"}, {"version": "v3", "created": "Mon, 3 Jun 2019 21:53:19 GMT"}, {"version": "v4", "created": "Sun, 13 Oct 2019 15:25:53 GMT"}, {"version": "v5", "created": "Thu, 5 Dec 2019 20:17:40 GMT"}, {"version": "v6", "created": "Thu, 12 Mar 2020 22:10:57 GMT"}, {"version": "v7", "created": "Sun, 26 Jul 2020 15:45:08 GMT"}], "update_date": "2020-07-28", "authors_parsed": [["Yamada", "Yutaro", ""], ["Lindenbaum", "Ofir", ""], ["Negahban", "Sahand", ""], ["Kluger", "Yuval", ""]]}, {"id": "1810.04249", "submitter": "Raj Agrawal", "authors": "Raj Agrawal, Trevor Campbell, Jonathan H. Huggins, Tamara Broderick", "title": "Data-dependent compression of random features for large-scale kernel\n  approximation", "comments": "24 pages, 8 figures, to appear in AISTATS 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Kernel methods offer the flexibility to learn complex relationships in\nmodern, large data sets while enjoying strong theoretical guarantees on\nquality. Unfortunately, these methods typically require cubic running time in\nthe data set size, a prohibitive cost in the large-data setting. Random feature\nmaps (RFMs) and the Nystrom method both consider low-rank approximations to the\nkernel matrix as a potential solution. But, in order to achieve desirable\ntheoretical guarantees, the former may require a prohibitively large number of\nfeatures J+, and the latter may be prohibitively expensive for high-dimensional\nproblems. We propose to combine the simplicity and generality of RFMs with a\ndata-dependent feature selection scheme to achieve desirable theoretical\napproximation properties of Nystrom with just O(log J+) features. Our key\ninsight is to begin with a large set of random features, then reduce them to a\nsmall number of weighted features in a data-dependent, computationally\nefficient way, while preserving the statistical guarantees of using the\noriginal large set of features. We demonstrate the efficacy of our method with\ntheory and experiments--including on a data set with over 50 million\nobservations. In particular, we show that our method achieves small kernel\nmatrix approximation error and better test set accuracy with provably fewer\nrandom features than state-of-the-art methods.\n", "versions": [{"version": "v1", "created": "Tue, 9 Oct 2018 21:20:41 GMT"}, {"version": "v2", "created": "Thu, 28 Feb 2019 02:17:38 GMT"}], "update_date": "2019-03-01", "authors_parsed": [["Agrawal", "Raj", ""], ["Campbell", "Trevor", ""], ["Huggins", "Jonathan H.", ""], ["Broderick", "Tamara", ""]]}, {"id": "1810.04250", "submitter": "Akash Kumar", "authors": "Sourya Dipta Das and Akash Kumar", "title": "Bird Species Classification using Transfer Learning with Multistage\n  Training", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Bird species classification has received more and more attention in the field\nof computer vision, for its promising applications in biology and environmental\nstudies. Recognizing bird species is difficult due to the challenges of\ndiscriminative region localization and fine-grained feature learning. In this\npaper, we have introduced a Transfer learning based method with multistage\ntraining. We have used both Pre-Trained Mask-RCNN and an ensemble model\nconsisting of Inception Nets (InceptionV3 & InceptionResNetV2 ) to get\nlocalization and species of the bird from the images respectively. Our final\nmodel achieves an F1 score of 0.5567 or 55.67 % on the dataset provided in CVIP\n2018 Challenge.\n", "versions": [{"version": "v1", "created": "Tue, 9 Oct 2018 21:29:08 GMT"}, {"version": "v2", "created": "Thu, 11 Oct 2018 16:30:29 GMT"}], "update_date": "2018-10-12", "authors_parsed": [["Das", "Sourya Dipta", ""], ["Kumar", "Akash", ""]]}, {"id": "1810.04254", "submitter": "Tharun Kumar Reddy Medini", "authors": "Qixuan Huang, Yiqiu Wang, Tharun Medini, Anshumali Shrivastava", "title": "Extreme Classification in Log Memory", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.CC cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present Merged-Averaged Classifiers via Hashing (MACH) for\nK-classification with ultra-large values of K. Compared to traditional\none-vs-all classifiers that require O(Kd) memory and inference cost, MACH only\nneed O(d log K) (d is dimensionality )memory while only requiring O(K log K + d\nlog K) operation for inference. MACH is a generic K-classification algorithm,\nwith provably theoretical guarantees, which requires O(log K) memory without\nany assumption on the relationship between classes. MACH uses universal hashing\nto reduce classification with a large number of classes to few independent\nclassification tasks with small (constant) number of classes. We provide\ntheoretical quantification of discriminability-memory tradeoff. With MACH we\ncan train ODP dataset with 100,000 classes and 400,000 features on a single\nTitan X GPU, with the classification accuracy of 19.28%, which is the\nbest-reported accuracy on this dataset. Before this work, the best performing\nbaseline is a one-vs-all classifier that requires 40 billion parameters (160 GB\nmodel size) and achieves 9% accuracy. In contrast, MACH can achieve 9% accuracy\nwith 480x reduction in the model size (of mere 0.3GB). With MACH, we also\ndemonstrate complete training of fine-grained imagenet dataset (compressed size\n104GB), with 21,000 classes, on a single GPU. To the best of our knowledge,\nthis is the first work to demonstrate complete training of these extreme-class\ndatasets on a single Titan X.\n", "versions": [{"version": "v1", "created": "Tue, 9 Oct 2018 21:43:57 GMT"}], "update_date": "2018-10-11", "authors_parsed": [["Huang", "Qixuan", ""], ["Wang", "Yiqiu", ""], ["Medini", "Tharun", ""], ["Shrivastava", "Anshumali", ""]]}, {"id": "1810.04261", "submitter": "Ruiqi Gao", "authors": "Ying Nian Wu, Ruiqi Gao, Tian Han, Song-Chun Zhu", "title": "A Tale of Three Probabilistic Families: Discriminative, Descriptive and\n  Generative Models", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The pattern theory of Grenander is a mathematical framework where patterns\nare represented by probability models on random variables of algebraic\nstructures. In this paper, we review three families of probability models,\nnamely, the discriminative models, the descriptive models, and the generative\nmodels. A discriminative model is in the form of a classifier. It specifies the\nconditional probability of the class label given the input signal. A\ndescriptive model specifies the probability distribution of the signal, based\non an energy function defined on the signal. A generative model assumes that\nthe signal is generated by some latent variables via a transformation. We shall\nreview these models within a common framework and explore their connections. We\nshall also review the recent developments that take advantage of the high\napproximation capacities of deep neural networks.\n", "versions": [{"version": "v1", "created": "Tue, 9 Oct 2018 21:54:54 GMT"}, {"version": "v2", "created": "Tue, 4 Dec 2018 00:33:15 GMT"}], "update_date": "2018-12-05", "authors_parsed": [["Wu", "Ying Nian", ""], ["Gao", "Ruiqi", ""], ["Han", "Tian", ""], ["Zhu", "Song-Chun", ""]]}, {"id": "1810.04303", "submitter": "Erdem B{\\i}y{\\i}k", "authors": "Erdem B{\\i}y{\\i}k, Dorsa Sadigh", "title": "Batch Active Preference-Based Learning of Reward Functions", "comments": "Proceedings of the 2nd Conference on Robot Learning (CoRL), October\n  2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.RO stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Data generation and labeling are usually an expensive part of learning for\nrobotics. While active learning methods are commonly used to tackle the former\nproblem, preference-based learning is a concept that attempts to solve the\nlatter by querying users with preference questions. In this paper, we will\ndevelop a new algorithm, batch active preference-based learning, that enables\nefficient learning of reward functions using as few data samples as possible\nwhile still having short query generation times. We introduce several\napproximations to the batch active learning problem, and provide theoretical\nguarantees for the convergence of our algorithms. Finally, we present our\nexperimental results for a variety of robotics tasks in simulation. Our results\nsuggest that our batch active learning algorithm requires only a few queries\nthat are computed in a short amount of time. We then showcase our algorithm in\na study to learn human users' preferences.\n", "versions": [{"version": "v1", "created": "Wed, 10 Oct 2018 00:02:55 GMT"}], "update_date": "2018-10-11", "authors_parsed": [["B\u0131y\u0131k", "Erdem", ""], ["Sadigh", "Dorsa", ""]]}, {"id": "1810.04304", "submitter": "G Reina", "authors": "Micah J Sheller, G Anthony Reina, Brandon Edwards, Jason Martin, and\n  Spyridon Bakas", "title": "Multi-Institutional Deep Learning Modeling Without Sharing Patient Data:\n  A Feasibility Study on Brain Tumor Segmentation", "comments": "MICCAI, Brain Lesion (BrainLes) workshop, September 16, 2018,\n  Granada, Spain", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep learning models for semantic segmentation of images require large\namounts of data. In the medical imaging domain, acquiring sufficient data is a\nsignificant challenge. Labeling medical image data requires expert knowledge.\nCollaboration between institutions could address this challenge, but sharing\nmedical data to a centralized location faces various legal, privacy, technical,\nand data-ownership challenges, especially among international institutions. In\nthis study, we introduce the first use of federated learning for\nmulti-institutional collaboration, enabling deep learning modeling without\nsharing patient data. Our quantitative results demonstrate that the performance\nof federated semantic segmentation models (Dice=0.852) on multimodal brain\nscans is similar to that of models trained by sharing data (Dice=0.862). We\ncompare federated learning with two alternative collaborative learning methods\nand find that they fail to match the performance of federated learning.\n", "versions": [{"version": "v1", "created": "Wed, 10 Oct 2018 00:05:44 GMT"}, {"version": "v2", "created": "Mon, 22 Oct 2018 18:51:38 GMT"}], "update_date": "2018-10-24", "authors_parsed": [["Sheller", "Micah J", ""], ["Reina", "G Anthony", ""], ["Edwards", "Brandon", ""], ["Martin", "Jason", ""], ["Bakas", "Spyridon", ""]]}, {"id": "1810.04327", "submitter": "Takashi Ishida", "authors": "Takashi Ishida, Gang Niu, Aditya Krishna Menon, Masashi Sugiyama", "title": "Complementary-Label Learning for Arbitrary Losses and Models", "comments": "accepted to ICML 2019 (Added errata on Nov. 19, 2019)", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In contrast to the standard classification paradigm where the true class is\ngiven to each training pattern, complementary-label learning only uses training\npatterns each equipped with a complementary label, which only specifies one of\nthe classes that the pattern does not belong to. The goal of this paper is to\nderive a novel framework of complementary-label learning with an unbiased\nestimator of the classification risk, for arbitrary losses and models---all\nexisting methods have failed to achieve this goal. Not only is this beneficial\nfor the learning stage, it also makes model/hyper-parameter selection (through\ncross-validation) possible without the need of any ordinarily labeled\nvalidation data, while using any linear/non-linear models or convex/non-convex\nloss functions. We further improve the risk estimator by a non-negative\ncorrection and gradient ascent trick, and demonstrate its superiority through\nexperiments.\n", "versions": [{"version": "v1", "created": "Wed, 10 Oct 2018 01:52:43 GMT"}, {"version": "v2", "created": "Fri, 17 May 2019 12:21:06 GMT"}, {"version": "v3", "created": "Thu, 20 Jun 2019 05:55:54 GMT"}, {"version": "v4", "created": "Tue, 19 Nov 2019 00:11:04 GMT"}], "update_date": "2019-11-20", "authors_parsed": [["Ishida", "Takashi", ""], ["Niu", "Gang", ""], ["Menon", "Aditya Krishna", ""], ["Sugiyama", "Masashi", ""]]}, {"id": "1810.04329", "submitter": "Muhammad Hilman", "authors": "Muhammad H. Hilman and Maria A. Rodriguez and Rajkumar Buyya", "title": "Task Runtime Prediction in Scientific Workflows Using an Online\n  Incremental Learning Approach", "comments": "Accepted for presentation at main conference track of 11th IEEE/ACM\n  International Conference on Utility and Cloud Computing", "journal-ref": null, "doi": "10.1109/UCC.2018.00018", "report-no": null, "categories": "cs.DC cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Many algorithms in workflow scheduling and resource provisioning rely on the\nperformance estimation of tasks to produce a scheduling plan. A profiler that\nis capable of modeling the execution of tasks and predicting their runtime\naccurately, therefore, becomes an essential part of any Workflow Management\nSystem (WMS). With the emergence of multi-tenant Workflow as a Service (WaaS)\nplatforms that use clouds for deploying scientific workflows, task runtime\nprediction becomes more challenging because it requires the processing of a\nsignificant amount of data in a near real-time scenario while dealing with the\nperformance variability of cloud resources. Hence, relying on methods such as\nprofiling tasks' execution data using basic statistical description (e.g.,\nmean, standard deviation) or batch offline regression techniques to estimate\nthe runtime may not be suitable for such environments. In this paper, we\npropose an online incremental learning approach to predict the runtime of tasks\nin scientific workflows in clouds. To improve the performance of the\npredictions, we harness fine-grained resources monitoring data in the form of\ntime-series records of CPU utilization, memory usage, and I/O activities that\nare reflecting the unique characteristics of a task's execution. We compare our\nsolution to a state-of-the-art approach that exploits the resources monitoring\ndata based on regression machine learning technique. From our experiments, the\nproposed strategy improves the performance, in terms of the error, up to\n29.89%, compared to the state-of-the-art solutions.\n", "versions": [{"version": "v1", "created": "Wed, 10 Oct 2018 01:59:08 GMT"}], "update_date": "2019-03-01", "authors_parsed": [["Hilman", "Muhammad H.", ""], ["Rodriguez", "Maria A.", ""], ["Buyya", "Rajkumar", ""]]}, {"id": "1810.04336", "submitter": "Sharan Vaswani", "authors": "Mohamed Osama Ahmed, Sharan Vaswani, Mark Schmidt", "title": "Combining Bayesian Optimization and Lipschitz Optimization", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Bayesian optimization and Lipschitz optimization have developed alternative\ntechniques for optimizing black-box functions. They each exploit a different\nform of prior about the function. In this work, we explore strategies to\ncombine these techniques for better global optimization. In particular, we\npropose ways to use the Lipschitz continuity assumption within traditional BO\nalgorithms, which we call Lipschitz Bayesian optimization (LBO). This approach\ndoes not increase the asymptotic runtime and in some cases drastically improves\nthe performance (while in the worst-case the performance is similar). Indeed,\nin a particular setting, we prove that using the Lipschitz information yields\nthe same or a better bound on the regret compared to using Bayesian\noptimization on its own. Moreover, we propose a simple heuristics to estimate\nthe Lipschitz constant, and prove that a growing estimate of the Lipschitz\nconstant is in some sense ``harmless''. Our experiments on 15 datasets with 4\nacquisition functions show that in the worst case LBO performs similar to the\nunderlying BO method while in some cases it performs substantially better.\nThompson sampling in particular typically saw drastic improvements (as the\nLipschitz information corrected for its well-known ``over-exploration''\nphenomenon) and its LBO variant often outperformed other acquisition functions.\n", "versions": [{"version": "v1", "created": "Wed, 10 Oct 2018 02:26:02 GMT"}, {"version": "v2", "created": "Tue, 28 Jul 2020 16:34:33 GMT"}], "update_date": "2020-07-29", "authors_parsed": [["Ahmed", "Mohamed Osama", ""], ["Vaswani", "Sharan", ""], ["Schmidt", "Mark", ""]]}, {"id": "1810.04351", "submitter": "Jeff Calder", "authors": "Jeff Calder and Dejan Slepcev", "title": "Properly-weighted graph Laplacian for semi-supervised learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.AP cs.LG math.NA math.PR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The performance of traditional graph Laplacian methods for semi-supervised\nlearning degrades substantially as the ratio of labeled to unlabeled data\ndecreases, due to a degeneracy in the graph Laplacian. Several approaches have\nbeen proposed recently to address this, however we show that some of them\nremain ill-posed in the large-data limit.\n  In this paper, we show a way to correctly set the weights in Laplacian\nregularization so that the estimator remains well posed and stable in the\nlarge-sample limit. We prove that our semi-supervised learning algorithm\nconverges, in the infinite sample size limit, to the smooth solution of a\ncontinuum variational problem that attains the labeled values continuously. Our\nmethod is fast and easy to implement.\n", "versions": [{"version": "v1", "created": "Wed, 10 Oct 2018 03:37:29 GMT"}, {"version": "v2", "created": "Tue, 2 Apr 2019 14:09:56 GMT"}], "update_date": "2019-04-03", "authors_parsed": [["Calder", "Jeff", ""], ["Slepcev", "Dejan", ""]]}, {"id": "1810.04361", "submitter": "Shrinu Kushagra", "authors": "Shrinu Kushagra, Shai Ben-David, Ihab Ilyas", "title": "Semi-supervised clustering for de-duplication", "comments": null, "journal-ref": "Proceedings of the 22nd International Conference on Artificial\n  Intelligence and Statistics (AISTATS) 2019", "doi": null, "report-no": "PMLR 89:1659-1667, 2019", "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Data de-duplication is the task of detecting multiple records that correspond\nto the same real-world entity in a database. In this work, we view\nde-duplication as a clustering problem where the goal is to put records\ncorresponding to the same physical entity in the same cluster and putting\nrecords corresponding to different physical entities into different clusters.\n  We introduce a framework which we call promise correlation clustering. Given\na complete graph $G$ with the edges labelled $0$ and $1$, the goal is to find a\nclustering that minimizes the number of $0$ edges within a cluster plus the\nnumber of $1$ edges across different clusters (or correlation loss). The\noptimal clustering can also be viewed as a complete graph $G^*$ with edges\ncorresponding to points in the same cluster being labelled $0$ and other edges\nbeing labelled $1$. Under the promise that the edge difference between $G$ and\n$G^*$ is \"small\", we prove that finding the optimal clustering (or $G^*$) is\nstill NP-Hard. [Ashtiani et. al, 2016] introduced the framework of\nsemi-supervised clustering, where the learning algorithm has access to an\noracle, which answers whether two points belong to the same or different\nclusters. We further prove that even with access to a same-cluster oracle, the\npromise version is NP-Hard as long as the number queries to the oracle is not\ntoo large ($o(n)$ where $n$ is the number of vertices).\n  Given these negative results, we consider a restricted version of correlation\nclustering. As before, the goal is to find a clustering that minimizes the\ncorrelation loss. However, we restrict ourselves to a given class $\\mathcal F$\nof clusterings. We offer a semi-supervised algorithmic approach to solve the\nrestricted variant with success guarantees.\n", "versions": [{"version": "v1", "created": "Wed, 10 Oct 2018 04:12:50 GMT"}], "update_date": "2020-05-27", "authors_parsed": [["Kushagra", "Shrinu", ""], ["Ben-David", "Shai", ""], ["Ilyas", "Ihab", ""]]}, {"id": "1810.04374", "submitter": "Yitong Sun", "authors": "Yitong Sun, Anna Gilbert, Ambuj Tewari", "title": "On the Approximation Properties of Random ReLU Features", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the approximation properties of random ReLU features through their\nreproducing kernel Hilbert space (RKHS). We first prove a universality theorem\nfor the RKHS induced by random features whose feature maps are of the form of\nnodes in neural networks. The universality result implies that the random ReLU\nfeatures method is a universally consistent learning algorithm. We prove that\ndespite the universality of the RKHS induced by the random ReLU features,\ncomposition of functions in it generates substantially more complicated\nfunctions that are harder to approximate than those functions simply in the\nRKHS. We also prove that such composite functions can be efficiently\napproximated by multi-layer ReLU networks with bounded weights. This depth\nseparation result shows that the random ReLU features models suffer from the\nsame weakness as that of shallow models. We show in experiments that the\nperformance of random ReLU features is comparable to that of random Fourier\nfeatures and, in general, has a lower computational cost. We also demonstrate\nthat when the target function is the composite function as described in the\ndepth separation theorem, 3-layer neural networks indeed outperform both random\nReLU features and 2-layer neural networks.\n", "versions": [{"version": "v1", "created": "Wed, 10 Oct 2018 04:58:45 GMT"}, {"version": "v2", "created": "Tue, 5 Feb 2019 17:31:38 GMT"}, {"version": "v3", "created": "Fri, 16 Aug 2019 05:16:46 GMT"}], "update_date": "2019-08-19", "authors_parsed": [["Sun", "Yitong", ""], ["Gilbert", "Anna", ""], ["Tewari", "Ambuj", ""]]}, {"id": "1810.04384", "submitter": "Aydogan Ozcan", "authors": "Deniz Mengu, Yi Luo, Yair Rivenson, Xing Lin, Muhammed Veli, Aydogan\n  Ozcan", "title": "Response to Comment on \"All-optical machine learning using diffractive\n  deep neural networks\"", "comments": "Response to arXiv:1809.08360v1 [cs.LG]", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.LG physics.optics", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In their Comment, Wei et al. (arXiv:1809.08360v1 [cs.LG]) claim that our\noriginal interpretation of Diffractive Deep Neural Networks (D2NN) represent a\nmischaracterization of the system due to linearity and passivity. In this\nResponse, we detail how this mischaracterization claim is unwarranted and\noblivious to several sections detailed in our original manuscript (Science,\nDOI: 10.1126/science.aat8084) that specifically introduced and discussed\noptical nonlinearities and reconfigurability of D2NNs, as part of our proposed\nframework to enhance its performance. To further refute the mischaracterization\nclaim of Wei et al., we, once again, demonstrate the depth feature of optical\nD2NNs by showing that multiple diffractive layers operating collectively within\na D2NN present additional degrees-of-freedom compared to a single diffractive\nlayer to achieve better classification accuracy, as well as improved output\nsignal contrast and diffraction efficiency as the number of diffractive layers\nincrease, showing the deepness of a D2NN, and its inherent depth advantage for\nimproved performance. In summary, the Comment by Wei et al. does not provide an\namendment to the original teachings of our original manuscript, and all of our\nresults, core conclusions and methodology of research reported in Science (DOI:\n10.1126/science.aat8084) remain entirely valid.\n", "versions": [{"version": "v1", "created": "Wed, 10 Oct 2018 06:32:49 GMT"}], "update_date": "2018-10-11", "authors_parsed": [["Mengu", "Deniz", ""], ["Luo", "Yi", ""], ["Rivenson", "Yair", ""], ["Lin", "Xing", ""], ["Veli", "Muhammed", ""], ["Ozcan", "Aydogan", ""]]}, {"id": "1810.04416", "submitter": "Zheyang Shen", "authors": "Zheyang Shen, Markus Heinonen, Samuel Kaski", "title": "Harmonizable mixture kernels with variational Fourier features", "comments": "18 pages, 5 figures", "journal-ref": "Proceedings of Machine Learning Research (PMLR) 2019, vol. 89:\n  3273-3282", "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The expressive power of Gaussian processes depends heavily on the choice of\nkernel. In this work we propose the novel harmonizable mixture kernel (HMK), a\nfamily of expressive, interpretable, non-stationary kernels derived from\nmixture models on the generalized spectral representation. As a theoretically\nsound treatment of non-stationary kernels, HMK supports harmonizable\ncovariances, a wide subset of kernels including all stationary and many\nnon-stationary covariances. We also propose variational Fourier features, an\ninter-domain sparse GP inference framework that offers a representative set of\n'inducing frequencies'. We show that harmonizable mixture kernels interpolate\nbetween local patterns, and that variational Fourier features offers a robust\nkernel learning framework for the new kernel family.\n", "versions": [{"version": "v1", "created": "Wed, 10 Oct 2018 08:41:51 GMT"}, {"version": "v2", "created": "Thu, 11 Oct 2018 12:43:28 GMT"}, {"version": "v3", "created": "Mon, 11 Mar 2019 09:08:09 GMT"}], "update_date": "2019-10-15", "authors_parsed": [["Shen", "Zheyang", ""], ["Heinonen", "Markus", ""], ["Kaski", "Samuel", ""]]}, {"id": "1810.04433", "submitter": "Yichi Zhou", "authors": "Yichi Zhou, Tongzheng Ren, Jialian Li, Dong Yan, Jun Zhu", "title": "Lazy-CFR: fast and near optimal regret minimization for extensive games\n  with imperfect information", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Counterfactual regret minimization (CFR) is the most popular algorithm on\nsolving two-player zero-sum extensive games with imperfect information and\nachieves state-of-the-art performance in practice. However, the performance of\nCFR is not fully understood, since empirical results on the regret are much\nbetter than the upper bound proved in \\cite{zinkevich2008regret}. Another issue\nis that CFR has to traverse the whole game tree in each round, which is\ntime-consuming in large scale games. In this paper, we present a novel\ntechnique, lazy update, which can avoid traversing the whole game tree in CFR,\nas well as a novel analysis on the regret of CFR with lazy update. Our analysis\ncan also be applied to the vanilla CFR, resulting in a much tighter regret\nbound than that in \\cite{zinkevich2008regret}. Inspired by lazy update, we\nfurther present a novel CFR variant, named Lazy-CFR. Compared to traversing\n$O(|\\mathcal{I}|)$ information sets in vanilla CFR, Lazy-CFR needs only to\ntraverse $O(\\sqrt{|\\mathcal{I}|})$ information sets per round while keeping the\nregret bound almost the same, where $\\mathcal{I}$ is the class of all\ninformation sets. As a result, Lazy-CFR shows better convergence result\ncompared with vanilla CFR. Experimental results consistently show that Lazy-CFR\noutperforms the vanilla CFR significantly.\n", "versions": [{"version": "v1", "created": "Wed, 10 Oct 2018 09:24:39 GMT"}, {"version": "v2", "created": "Sun, 25 Nov 2018 05:17:34 GMT"}, {"version": "v3", "created": "Tue, 25 Dec 2018 04:54:33 GMT"}], "update_date": "2018-12-27", "authors_parsed": [["Zhou", "Yichi", ""], ["Ren", "Tongzheng", ""], ["Li", "Jialian", ""], ["Yan", "Dong", ""], ["Zhu", "Jun", ""]]}, {"id": "1810.04437", "submitter": "Giancarlo Salton", "authors": "Giancarlo D. Salton and John D. Kelleher", "title": "Persistence pays off: Paying Attention to What the LSTM Gating Mechanism\n  Persists", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Language Models (LMs) are important components in several Natural Language\nProcessing systems. Recurrent Neural Network LMs composed of LSTM units,\nespecially those augmented with an external memory, have achieved\nstate-of-the-art results. However, these models still struggle to process long\nsequences which are more likely to contain long-distance dependencies because\nof information fading and a bias towards more recent information. In this paper\nwe demonstrate an effective mechanism for retrieving information in a memory\naugmented LSTM LM based on attending to information in memory in proportion to\nthe number of timesteps the LSTM gating mechanism persisted the information.\n", "versions": [{"version": "v1", "created": "Wed, 10 Oct 2018 09:48:20 GMT"}], "update_date": "2018-10-11", "authors_parsed": [["Salton", "Giancarlo D.", ""], ["Kelleher", "John D.", ""]]}, {"id": "1810.04438", "submitter": "Rika Antonova", "authors": "Rika Antonova, Mia Kokic, Johannes A. Stork, Danica Kragic", "title": "Global Search with Bernoulli Alternation Kernel for Task-oriented\n  Grasping Informed by Simulation", "comments": "To appear in 2nd Conference on Robot Learning (CoRL) 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We develop an approach that benefits from large simulated datasets and takes\nfull advantage of the limited online data that is most relevant. We propose a\nvariant of Bayesian optimization that alternates between using informed and\nuninformed kernels. With this Bernoulli Alternation Kernel we ensure that\ndiscrepancies between simulation and reality do not hinder adapting robot\ncontrol policies online. The proposed approach is applied to a challenging\nreal-world problem of task-oriented grasping with novel objects. Our further\ncontribution is a neural network architecture and training pipeline that use\nexperience from grasping objects in simulation to learn grasp stability scores.\nWe learn task scores from a labeled dataset with a convolutional network, which\nis used to construct an informed kernel for our variant of Bayesian\noptimization. Experiments on an ABB Yumi robot with real sensor data\ndemonstrate success of our approach, despite the challenge of fulfilling task\nrequirements and high uncertainty over physical properties of objects.\n", "versions": [{"version": "v1", "created": "Wed, 10 Oct 2018 09:49:03 GMT"}], "update_date": "2018-10-11", "authors_parsed": [["Antonova", "Rika", ""], ["Kokic", "Mia", ""], ["Stork", "Johannes A.", ""], ["Kragic", "Danica", ""]]}, {"id": "1810.04468", "submitter": "David Mart\\'inez-Rubio", "authors": "David Mart\\'inez-Rubio, Varun Kanade and Patrick Rebeschini", "title": "Decentralized Cooperative Stochastic Bandits", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We study a decentralized cooperative stochastic multi-armed bandit problem\nwith $K$ arms on a network of $N$ agents. In our model, the reward distribution\nof each arm is the same for each agent and rewards are drawn independently\nacross agents and time steps. In each round, each agent chooses an arm to play\nand subsequently sends a message to her neighbors. The goal is to minimize the\noverall regret of the entire network. We design a fully decentralized algorithm\nthat uses an accelerated consensus procedure to compute (delayed) estimates of\nthe average of rewards obtained by all the agents for each arm, and then uses\nan upper confidence bound (UCB) algorithm that accounts for the delay and error\nof the estimates. We analyze the regret of our algorithm and also provide a\nlower bound. The regret is bounded by the optimal centralized regret plus a\nnatural and simple term depending on the spectral gap of the communication\nmatrix. Our algorithm is simpler to analyze than those proposed in prior work\nand it achieves better regret bounds, while requiring less information about\nthe underlying network. It also performs better empirically.\n", "versions": [{"version": "v1", "created": "Wed, 10 Oct 2018 11:46:20 GMT"}, {"version": "v2", "created": "Thu, 24 Oct 2019 13:19:01 GMT"}], "update_date": "2019-10-25", "authors_parsed": [["Mart\u00ednez-Rubio", "David", ""], ["Kanade", "Varun", ""], ["Rebeschini", "Patrick", ""]]}, {"id": "1810.04472", "submitter": "Jiawei Wang", "authors": "Jiawei Wang, Zhaoshui He, Chengjian Feng, Zhouping Zhu, Qinzhuang Lin,\n  Jun Lv, Shengli Xie", "title": "Domain Confusion with Self Ensembling for Unsupervised Adaptation", "comments": "The expression is ambiguous, which is not convenient for readers to\n  understand, and in today's view, the conclusion of the paper is of little\n  significance, so it is no longer open", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Data collection and annotation are time-consuming in machine learning,\nexpecially for large scale problem. A common approach for this problem is to\ntransfer knowledge from a related labeled domain to a target one. There are two\npopular ways to achieve this goal: adversarial learning and self training. In\nthis article, we first analyze the training unstablity problem and the mistaken\nconfusion issue in adversarial learning process. Then, inspired by domain\nconfusion and self-ensembling methods, we propose a combined model to learn\nfeature and class jointly invariant representation, namely Domain Confusion\nwith Self Ensembling (DCSE). The experiments verified that our proposed\napproach can offer better performance than empirical art in a variety of\nunsupervised domain adaptation benchmarks.\n", "versions": [{"version": "v1", "created": "Wed, 10 Oct 2018 12:09:36 GMT"}, {"version": "v2", "created": "Mon, 6 Jul 2020 11:53:19 GMT"}, {"version": "v3", "created": "Wed, 8 Jul 2020 08:48:09 GMT"}], "update_date": "2020-07-09", "authors_parsed": [["Wang", "Jiawei", ""], ["He", "Zhaoshui", ""], ["Feng", "Chengjian", ""], ["Zhu", "Zhouping", ""], ["Lin", "Qinzhuang", ""], ["Lv", "Jun", ""], ["Xie", "Shengli", ""]]}, {"id": "1810.04491", "submitter": "Prayag Tiwari Mr.", "authors": "Prayag Tiwari, Massimo Melucci", "title": "Multi-class Classification Model Inspired by Quantum Detection Theory", "comments": "Future Directions in Information Access (FDIA) 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Machine Learning has become very famous currently which assist in identifying\nthe patterns from the raw data. Technological advancement has led to\nsubstantial improvement in Machine Learning which, thus helping to improve\nprediction. Current Machine Learning models are based on Classical Theory,\nwhich can be replaced by Quantum Theory to improve the effectiveness of the\nmodel. In the previous work, we developed binary classifier inspired by Quantum\nDetection Theory. In this extended abstract, our main goal is to develop\nmulti-class classifier. We generally use the terminology multinomial\nclassification or multi-class classification when we have a classification\nproblem for classifying observations or instances into one of three or more\nclasses.\n", "versions": [{"version": "v1", "created": "Wed, 10 Oct 2018 12:56:06 GMT"}], "update_date": "2018-10-11", "authors_parsed": [["Tiwari", "Prayag", ""], ["Melucci", "Massimo", ""]]}, {"id": "1810.04502", "submitter": "Diptesh Kanojia", "authors": "Diptesh Kanojia, Nikhil Wani, Pushpak Bhattacharyya", "title": "Is your Statement Purposeless? Predicting Computer Science Graduation\n  Admission Acceptance based on Statement Of Purpose", "comments": "5 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.LG", "license": "http://creativecommons.org/licenses/by-sa/4.0/", "abstract": "  We present a quantitative, data-driven machine learning approach to mitigate\nthe problem of unpredictability of Computer Science Graduate School Admissions.\nIn this paper, we discuss the possibility of a system which may help\nprospective applicants evaluate their Statement of Purpose (SOP) based on our\nsystem output. We, then, identify feature sets which can be used to train a\npredictive model. We train a model over fifty manually verified SOPs for which\nit uses an SVM classifier and achieves the highest accuracy of 92% with 10-fold\ncross-validation. We also perform experiments to establish that Word Embedding\nbased features and Document Similarity-based features outperform other\nidentified feature combinations. We plan to deploy our application as a web\nservice and release it as a FOSS service.\n", "versions": [{"version": "v1", "created": "Tue, 9 Oct 2018 05:07:51 GMT"}], "update_date": "2018-10-11", "authors_parsed": [["Kanojia", "Diptesh", ""], ["Wani", "Nikhil", ""], ["Bhattacharyya", "Pushpak", ""]]}, {"id": "1810.04509", "submitter": "Zhi Lin Ke", "authors": "Zhi-Lin Ke, Hsiang-Yun Cheng, Chia-Lin Yang", "title": "LIRS: Enabling efficient machine learning on NVM-based storage via a\n  lightweight implementation of random shuffling", "comments": null, "journal-ref": null, "doi": "10.6342/NTU201803514", "report-no": null, "categories": "cs.PF cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Machine learning algorithms, such as Support Vector Machine (SVM) and Deep\nNeural Network (DNN), have gained a lot of interests recently. When training a\nmachine learning algorithm, randomly shuffle all the training data can improve\nthe testing accuracy and boost the convergence rate. Nevertheless, realizing\ntraining data random shuffling in a real system is not a straightforward\nprocess due to the slow random accesses in hard disk drive (HDD). To avoid\nfrequent random disk access, the effect of random shuffling is often limited in\nexisting approaches. With the emerging non-volatile memory-based storage\ndevice, such as Intel Optane SSD, which provides fast random accesses, we\npropose a lightweight implementation of random shuffling (LIRS) to randomly\nshuffle the indexes of the entire training dataset, and the selected training\ninstances are directly accessed from the storage and packed into batches.\nExperimental results show that LIRS can reduce the total training time of SVM\nand DNN by 49.9% and 43.5% on average, and improve the final testing accuracy\non DNN by 1.01%.\n", "versions": [{"version": "v1", "created": "Wed, 10 Oct 2018 13:22:47 GMT"}], "update_date": "2018-10-11", "authors_parsed": [["Ke", "Zhi-Lin", ""], ["Cheng", "Hsiang-Yun", ""], ["Yang", "Chia-Lin", ""]]}, {"id": "1810.04511", "submitter": "Lili Meng", "authors": "Lili Meng, Bo Zhao, Bo Chang, Gao Huang, Wei Sun, Frederich Tung,\n  Leonid Sigal", "title": "Interpretable Spatio-temporal Attention for Video Action Recognition", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Inspired by the observation that humans are able to process videos\nefficiently by only paying attention where and when it is needed, we propose an\ninterpretable and easy plug-in spatial-temporal attention mechanism for video\naction recognition. For spatial attention, we learn a saliency mask to allow\nthe model to focus on the most salient parts of the feature maps. For temporal\nattention, we employ a convolutional LSTM based attention mechanism to identify\nthe most relevant frames from an input video. Further, we propose a set of\nregularizers to ensure that our attention mechanism attends to coherent regions\nin space and time. Our model not only improves video action recognition\naccuracy, but also localizes discriminative regions both spatially and\ntemporally, despite being trained in a weakly-supervised manner with only\nclassification labels (no bounding box labels or time frame temporal labels).\nWe evaluate our approach on several public video action recognition datasets\nwith ablation studies. Furthermore, we quantitatively and qualitatively\nevaluate our model's ability to localize discriminative regions spatially and\ncritical frames temporally. Experimental results demonstrate the efficacy of\nour approach, showing superior or comparable accuracy with the state-of-the-art\nmethods while increasing model interpretability.\n", "versions": [{"version": "v1", "created": "Mon, 1 Oct 2018 04:23:35 GMT"}, {"version": "v2", "created": "Mon, 3 Jun 2019 03:09:50 GMT"}], "update_date": "2019-06-04", "authors_parsed": [["Meng", "Lili", ""], ["Zhao", "Bo", ""], ["Chang", "Bo", ""], ["Huang", "Gao", ""], ["Sun", "Wei", ""], ["Tung", "Frederich", ""], ["Sigal", "Leonid", ""]]}, {"id": "1810.04513", "submitter": "Jiawei Wen", "authors": "Songshan Yang, Jiawei Wen, Xiang Zhan and Daniel Kifer", "title": "ET-Lasso: A New Efficient Tuning of Lasso-type Regularization for\n  High-Dimensional Data", "comments": "Figure 1 in the real data example is changed to plot the difference\n  of true values and predicted values; added references for section 1; more\n  explanation for section 2.3", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The L1 regularization (Lasso) has proven to be a versatile tool to select\nrelevant features and estimate the model coefficients simultaneously and has\nbeen widely used in many research areas such as genomes studies, finance, and\nbiomedical imaging. Despite its popularity, it is very challenging to guarantee\nthe feature selection consistency of Lasso especially when the dimension of the\ndata is huge. One way to improve the feature selection consistency is to select\nan ideal tuning parameter. Traditional tuning criteria mainly focus on\nminimizing the estimated prediction error or maximizing the posterior model\nprobability, such as cross-validation and BIC, which may either be\ntime-consuming or fail to control the false discovery rate (FDR) when the\nnumber of features is extremely large. The other way is to introduce\npseudo-features to learn the importance of the original ones. Recently, the\nKnockoff filter is proposed to control the FDR when performing feature\nselection. However, its performance is sensitive to the choice of the expected\nFDR threshold. Motivated by these ideas, we propose a new method using\npseudo-features to obtain an ideal tuning parameter. In particular, we present\nthe Efficient Tuning of Lasso (ET-Lasso) to separate active and inactive\nfeatures by adding permuted features as pseudo-features in linear models. The\npseudo-features are constructed to be inactive by nature, which can be used to\nobtain a cutoff to select the tuning parameter that separates active and\ninactive features. Experimental studies on both simulations and real-world data\napplications are provided to show that ET-Lasso can effectively and efficiently\nselect active features under a wide range of scenarios\n", "versions": [{"version": "v1", "created": "Wed, 10 Oct 2018 13:25:03 GMT"}, {"version": "v2", "created": "Sat, 18 May 2019 04:40:08 GMT"}], "update_date": "2019-05-21", "authors_parsed": [["Yang", "Songshan", ""], ["Wen", "Jiawei", ""], ["Zhan", "Xiang", ""], ["Kifer", "Daniel", ""]]}, {"id": "1810.04520", "submitter": "Cong Luong Nguyen", "authors": "Tran The Anh, Nguyen Cong Luong, Dusit Niyato, Ying-Chang Liang, and\n  Dong In Kim", "title": "Deep Reinforcement Learning for Time Scheduling in RF-Powered\n  Backscatter Cognitive Radio Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.GT cs.NI eess.SP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In an RF-powered backscatter cognitive radio network, multiple secondary\nusers communicate with a secondary gateway by backscattering or harvesting\nenergy and actively transmitting their data depending on the primary channel\nstate. To coordinate the transmission of multiple secondary transmitters, the\nsecondary gateway needs to schedule the backscattering time, energy harvesting\ntime, and transmission time among them. However, under the dynamics of the\nprimary channel and the uncertainty of the energy state of the secondary\ntransmitters, it is challenging for the gateway to find a time scheduling\nmechanism which maximizes the total throughput. In this paper, we propose to\nuse the deep reinforcement learning algorithm to derive an optimal time\nscheduling policy for the gateway. Specifically, to deal with the problem with\nlarge state and action spaces, we adopt a Double Deep-Q Network (DDQN) that\nenables the gateway to learn the optimal policy. The simulation results clearly\nshow that the proposed deep reinforcement learning algorithm outperforms\nnon-learning schemes in terms of network throughput.\n", "versions": [{"version": "v1", "created": "Wed, 3 Oct 2018 05:30:23 GMT"}], "update_date": "2018-10-11", "authors_parsed": [["Anh", "Tran The", ""], ["Luong", "Nguyen Cong", ""], ["Niyato", "Dusit", ""], ["Liang", "Ying-Chang", ""], ["Kim", "Dong In", ""]]}, {"id": "1810.04522", "submitter": "David Pardo", "authors": "M. Shahriari, D. Pardo, A. Pic\\'on, A. Galdr\\'an, J. Del Ser, C.\n  Torres-Verd\\'in", "title": "A Deep Learning Approach to the Inversion of Borehole Resistivity\n  Measurements", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We use borehole resistivity measurements to map the electrical properties of\nthe subsurface and to increase the productivity of a reservoir. When used for\ngeosteering purposes, it becomes essential to invert them in real time. In this\nwork, we explore the possibility of using Deep Neural Network (DNN) to perform\na rapid inversion of borehole resistivity measurements. Herein, we build a DNN\nthat approximates the following inverse problem: given a set of borehole\nresistivity measurements, the DNN is designed to deliver a physically\nmeaningful and data-consistent piecewise one-dimensional layered model of the\nsurrounding subsurface. Once the DNN is built, we can perform the actual\ninversion of the field measurements in real time. We illustrate the performance\nof DNN of logging-while-drilling measurements acquired on high-angle wells via\nsynthetic data.\n", "versions": [{"version": "v1", "created": "Fri, 5 Oct 2018 13:50:19 GMT"}, {"version": "v2", "created": "Wed, 9 Jan 2019 16:49:51 GMT"}], "update_date": "2019-01-10", "authors_parsed": [["Shahriari", "M.", ""], ["Pardo", "D.", ""], ["Pic\u00f3n", "A.", ""], ["Galdr\u00e1n", "A.", ""], ["Del Ser", "J.", ""], ["Torres-Verd\u00edn", "C.", ""]]}, {"id": "1810.04534", "submitter": "Romain Couillet", "authors": "Romain Couillet and Malik Tiomoko and Steeve Zozor and Eric Moisan", "title": "Random matrix-improved estimation of covariance matrix distances", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.PR cs.LG math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Given two sets $x_1^{(1)},\\ldots,x_{n_1}^{(1)}$ and\n$x_1^{(2)},\\ldots,x_{n_2}^{(2)}\\in\\mathbb{R}^p$ (or $\\mathbb{C}^p$) of random\nvectors with zero mean and positive definite covariance matrices $C_1$ and\n$C_2\\in\\mathbb{R}^{p\\times p}$ (or $\\mathbb{C}^{p\\times p}$), respectively,\nthis article provides novel estimators for a wide range of distances between\n$C_1$ and $C_2$ (along with divergences between some zero mean and covariance\n$C_1$ or $C_2$ probability measures) of the form $\\frac1p\\sum_{i=1}^n\nf(\\lambda_i(C_1^{-1}C_2))$ (with $\\lambda_i(X)$ the eigenvalues of matrix $X$).\nThese estimators are derived using recent advances in the field of random\nmatrix theory and are asymptotically consistent as $n_1,n_2,p\\to\\infty$ with\nnon trivial ratios $p/n_1<1$ and $p/n_2<1$ (the case $p/n_2>1$ is also\ndiscussed). A first \"generic\" estimator, valid for a large set of $f$\nfunctions, is provided under the form of a complex integral. Then, for a\nselected set of $f$'s of practical interest (namely, $f(t)=t$, $f(t)=\\log(t)$,\n$f(t)=\\log(1+st)$ and $f(t)=\\log^2(t)$), a closed-form expression is provided.\nBeside theoretical findings, simulation results suggest an outstanding\nperformance advantage for the proposed estimators when compared to the\nclassical \"plug-in\" estimator $\\frac1p\\sum_{i=1}^n f(\\lambda_i(\\hat\nC_1^{-1}\\hat C_2))$ (with $\\hat\nC_a=\\frac1{n_a}\\sum_{i=1}^{n_a}x_i^{(a)}x_i^{(a){\\sf T}}$), and this even for\nvery small values of $n_1,n_2,p$.\n", "versions": [{"version": "v1", "created": "Wed, 10 Oct 2018 13:59:43 GMT"}], "update_date": "2018-10-11", "authors_parsed": [["Couillet", "Romain", ""], ["Tiomoko", "Malik", ""], ["Zozor", "Steeve", ""], ["Moisan", "Eric", ""]]}, {"id": "1810.04535", "submitter": "Rafik Hadfi Dr", "authors": "Rafik Hadfi", "title": "Investigating Enactive Learning for Autonomous Intelligent Agents", "comments": "6 pages, 5 figures, 1 table, accepted as conference paper but\n  withdrawn", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.RO stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The enactive approach to cognition is typically proposed as a viable\nalternative to traditional cognitive science. Enactive cognition displaces the\nexplanatory focus from the internal representations of the agent to the direct\nsensorimotor interaction with its environment. In this paper, we investigate\nenactive learning through means of artificial agent simulations. We compare the\nperformances of the enactive agent to an agent operating on classical\nreinforcement learning in foraging tasks within maze environments. The\ncharacteristics of the agents are analysed in terms of the accessibility of the\nenvironmental states, goals, and exploration/exploitation tradeoffs. We confirm\nthat the enactive agent can successfully interact with its environment and\nlearn to avoid unfavourable interactions using intrinsically defined goals. The\nperformance of the enactive agent is shown to be limited by the number of\naffordable actions.\n", "versions": [{"version": "v1", "created": "Tue, 9 Oct 2018 03:43:04 GMT"}], "update_date": "2018-10-11", "authors_parsed": [["Hadfi", "Rafik", ""]]}, {"id": "1810.04538", "submitter": "Lei Ma", "authors": "Lei Ma, Felix Juefei-Xu, Minhui Xue, Qiang Hu, Sen Chen, Bo Li, Yang\n  Liu, Jianjun Zhao, Jianxiong Yin, and Simon See", "title": "Secure Deep Learning Engineering: A Software Quality Assurance\n  Perspective", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SE cs.AI cs.CR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Over the past decades, deep learning (DL) systems have achieved tremendous\nsuccess and gained great popularity in various applications, such as\nintelligent machines, image processing, speech processing, and medical\ndiagnostics. Deep neural networks are the key driving force behind its recent\nsuccess, but still seem to be a magic black box lacking interpretability and\nunderstanding. This brings up many open safety and security issues with\nenormous and urgent demands on rigorous methodologies and engineering practice\nfor quality enhancement. A plethora of studies have shown that the\nstate-of-the-art DL systems suffer from defects and vulnerabilities that can\nlead to severe loss and tragedies, especially when applied to real-world\nsafety-critical applications. In this paper, we perform a large-scale study and\nconstruct a paper repository of 223 relevant works to the quality assurance,\nsecurity, and interpretation of deep learning. We, from a software quality\nassurance perspective, pinpoint challenges and future opportunities towards\nuniversal secure deep learning engineering. We hope this work and the\naccompanied paper repository can pave the path for the software engineering\ncommunity towards addressing the pressing industrial demand of secure\nintelligent applications.\n", "versions": [{"version": "v1", "created": "Wed, 10 Oct 2018 14:04:08 GMT"}], "update_date": "2018-10-11", "authors_parsed": [["Ma", "Lei", ""], ["Juefei-Xu", "Felix", ""], ["Xue", "Minhui", ""], ["Hu", "Qiang", ""], ["Chen", "Sen", ""], ["Li", "Bo", ""], ["Liu", "Yang", ""], ["Zhao", "Jianjun", ""], ["Yin", "Jianxiong", ""], ["See", "Simon", ""]]}, {"id": "1810.04559", "submitter": "Chang Su", "authors": "Su Chang, Xu Zhenzong, Gao Xuan", "title": "Improvement of K Mean Clustering Algorithm Based on Density", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The purpose of this paper is to improve the traditional K-means algorithm. In\nthe traditional K mean clustering algorithm, the initial clustering centers are\ngenerated randomly in the data set. It is easy to fall into the local minimum\nsolution when the initial cluster centers are randomly generated. The initial\nclustering center selected by K-means clustering algorithm which based on\ndensity is more representative. The experimental results show that the improved\nK clustering algorithm can eliminate the dependence on the initial cluster, and\nthe accuracy of clustering is improved.\n", "versions": [{"version": "v1", "created": "Tue, 9 Oct 2018 11:41:45 GMT"}], "update_date": "2018-10-11", "authors_parsed": [["Chang", "Su", ""], ["Zhenzong", "Xu", ""], ["Xuan", "Gao", ""]]}, {"id": "1810.04570", "submitter": "Florian Hartl", "authors": "Peter Sugimura, Florian Hartl", "title": "Building a Reproducible Machine Learning Pipeline", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.SE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Reproducibility of modeling is a problem that exists for any machine learning\npractitioner, whether in industry or academia. The consequences of an\nirreproducible model can include significant financial costs, lost time, and\neven loss of personal reputation (if results prove unable to be replicated).\nThis paper will first discuss the problems we have encountered while building a\nvariety of machine learning models, and subsequently describe the framework we\nbuilt to tackle the problem of model reproducibility. The framework is\ncomprised of four main components (data, feature, scoring, and evaluation\nlayers), which are themselves comprised of well defined transformations. This\nenables us to not only exactly replicate a model, but also to reuse the\ntransformations across different models. As a result, the platform has\ndramatically increased the speed of both offline and online experimentation\nwhile also ensuring model reproducibility.\n", "versions": [{"version": "v1", "created": "Tue, 9 Oct 2018 17:32:36 GMT"}], "update_date": "2018-10-11", "authors_parsed": [["Sugimura", "Peter", ""], ["Hartl", "Florian", ""]]}, {"id": "1810.04586", "submitter": "Yifan Wu", "authors": "Yifan Wu, George Tucker, Ofir Nachum", "title": "The Laplacian in RL: Learning Representations with Efficient\n  Approximations", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The smallest eigenvectors of the graph Laplacian are well-known to provide a\nsuccinct representation of the geometry of a weighted graph. In reinforcement\nlearning (RL), where the weighted graph may be interpreted as the state\ntransition process induced by a behavior policy acting on the environment,\napproximating the eigenvectors of the Laplacian provides a promising approach\nto state representation learning. However, existing methods for performing this\napproximation are ill-suited in general RL settings for two main reasons:\nFirst, they are computationally expensive, often requiring operations on large\nmatrices. Second, these methods lack adequate justification beyond simple,\ntabular, finite-state settings. In this paper, we present a fully general and\nscalable method for approximating the eigenvectors of the Laplacian in a\nmodel-free RL context. We systematically evaluate our approach and empirically\nshow that it generalizes beyond the tabular, finite-state setting. Even in\ntabular, finite-state settings, its ability to approximate the eigenvectors\noutperforms previous proposals. Finally, we show the potential benefits of\nusing a Laplacian representation learned using our method in goal-achieving RL\ntasks, providing evidence that our technique can be used to significantly\nimprove the performance of an RL agent.\n", "versions": [{"version": "v1", "created": "Wed, 10 Oct 2018 15:25:49 GMT"}], "update_date": "2018-10-11", "authors_parsed": [["Wu", "Yifan", ""], ["Tucker", "George", ""], ["Nachum", "Ofir", ""]]}, {"id": "1810.04622", "submitter": "Elliot J. Crowley", "authors": "Elliot J. Crowley, Jack Turner, Amos Storkey, Michael O'Boyle", "title": "A Closer Look at Structured Pruning for Neural Network Compression", "comments": "Preprint. First two authors contributed equally. Paper title has\n  changed", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.CV cs.LG", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Structured pruning is a popular method for compressing a neural network:\ngiven a large trained network, one alternates between removing channel\nconnections and fine-tuning; reducing the overall width of the network.\nHowever, the efficacy of structured pruning has largely evaded scrutiny. In\nthis paper, we examine ResNets and DenseNets obtained through structured\npruning-and-tuning and make two interesting observations: (i) reduced\nnetworks---smaller versions of the original network trained from\nscratch---consistently outperform pruned networks; (ii) if one takes the\narchitecture of a pruned network and then trains it from scratch it is\nsignificantly more competitive. Furthermore, these architectures are easy to\napproximate: we can prune once and obtain a family of new, scalable network\narchitectures that can simply be trained from scratch. Finally, we compare the\ninference speed of reduced and pruned networks on hardware, and show that\nreduced networks are significantly faster. Code is available at\nhttps://github.com/BayesWatch/pytorch-prunes.\n", "versions": [{"version": "v1", "created": "Wed, 10 Oct 2018 16:30:02 GMT"}, {"version": "v2", "created": "Tue, 29 Jan 2019 14:40:12 GMT"}, {"version": "v3", "created": "Fri, 7 Jun 2019 14:23:14 GMT"}], "update_date": "2019-06-10", "authors_parsed": [["Crowley", "Elliot J.", ""], ["Turner", "Jack", ""], ["Storkey", "Amos", ""], ["O'Boyle", "Michael", ""]]}, {"id": "1810.04632", "submitter": "Wil Ward", "authors": "Mauricio A. \\'Alvarez, Wil O. C. Ward, Cristian Guarnizo", "title": "Non-linear process convolutions for multi-output Gaussian processes", "comments": "16 pages plus 2 page supplementary. Accepted to AISTATS 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The paper introduces a non-linear version of the process convolution\nformalism for building covariance functions for multi-output Gaussian\nprocesses. The non-linearity is introduced via Volterra series, one series per\neach output. We provide closed-form expressions for the mean function and the\ncovariance function of the approximated Gaussian process at the output of the\nVolterra series. The mean function and covariance function for the joint\nGaussian process are derived using formulae for the product moments of Gaussian\nvariables. We compare the performance of the non-linear model against the\nclassical process convolution approach in one synthetic dataset and two real\ndatasets.\n", "versions": [{"version": "v1", "created": "Wed, 10 Oct 2018 16:47:35 GMT"}, {"version": "v2", "created": "Wed, 27 Feb 2019 19:23:26 GMT"}], "update_date": "2019-03-01", "authors_parsed": [["\u00c1lvarez", "Mauricio A.", ""], ["Ward", "Wil O. C.", ""], ["Guarnizo", "Cristian", ""]]}, {"id": "1810.04642", "submitter": "Indrasis Chakraborty", "authors": "Indrasis Chakraborty, Sai Pushpak Nandanoori, Soumya Kundu", "title": "Virtual Battery Parameter Identification using Transfer Learning based\n  Stacked Autoencoder", "comments": "8 pages, 6 figures, accepted to IEEE ICMLA 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent studies have shown that the aggregated dynamic flexibility of an\nensemble of thermostatic loads can be modeled in the form of a virtual battery.\nThe existing methods for computing the virtual battery parameters require the\nknowledge of the first-principle models and parameter values of the loads in\nthe ensemble. In real-world applications, however, it is likely that the only\navailable information are end-use measurements such as power consumption, room\ntemperature, device on/off status, etc., while very little about the individual\nload models and parameters are known. We propose a transfer learning based deep\nnetwork framework for calculating virtual battery state of a given ensemble of\nflexible thermostatic loads, from the available end-use measurements. This\nproposed framework extracts first order virtual battery model parameters for\nthe given ensemble. We illustrate the effectiveness of this novel framework on\ndifferent ensembles of ACs and WHs.\n", "versions": [{"version": "v1", "created": "Wed, 10 Oct 2018 17:07:53 GMT"}], "update_date": "2018-10-11", "authors_parsed": [["Chakraborty", "Indrasis", ""], ["Nandanoori", "Sai Pushpak", ""], ["Kundu", "Soumya", ""]]}, {"id": "1810.04650", "submitter": "Ozan Sener", "authors": "Ozan Sener, Vladlen Koltun", "title": "Multi-Task Learning as Multi-Objective Optimization", "comments": "In Neural Information Processing Systems (NeurIPS) 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In multi-task learning, multiple tasks are solved jointly, sharing inductive\nbias between them. Multi-task learning is inherently a multi-objective problem\nbecause different tasks may conflict, necessitating a trade-off. A common\ncompromise is to optimize a proxy objective that minimizes a weighted linear\ncombination of per-task losses. However, this workaround is only valid when the\ntasks do not compete, which is rarely the case. In this paper, we explicitly\ncast multi-task learning as multi-objective optimization, with the overall\nobjective of finding a Pareto optimal solution. To this end, we use algorithms\ndeveloped in the gradient-based multi-objective optimization literature. These\nalgorithms are not directly applicable to large-scale learning problems since\nthey scale poorly with the dimensionality of the gradients and the number of\ntasks. We therefore propose an upper bound for the multi-objective loss and\nshow that it can be optimized efficiently. We further prove that optimizing\nthis upper bound yields a Pareto optimal solution under realistic assumptions.\nWe apply our method to a variety of multi-task deep learning problems including\ndigit classification, scene understanding (joint semantic segmentation,\ninstance segmentation, and depth estimation), and multi-label classification.\nOur method produces higher-performing models than recent multi-task learning\nformulations or per-task training.\n", "versions": [{"version": "v1", "created": "Wed, 10 Oct 2018 17:18:09 GMT"}, {"version": "v2", "created": "Fri, 11 Jan 2019 12:57:32 GMT"}], "update_date": "2019-01-14", "authors_parsed": [["Sener", "Ozan", ""], ["Koltun", "Vladlen", ""]]}, {"id": "1810.04652", "submitter": "Huy Nguyen", "authors": "Eric Dodds, Huy Nguyen, Simao Herdade, Jack Culpepper, Andrew Kae,\n  Pierre Garrigues", "title": "Learning Embeddings for Product Visual Search with Triplet Loss and\n  Online Sampling", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.IR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we propose learning an embedding function for content-based\nimage retrieval within the e-commerce domain using the triplet loss and an\nonline sampling method that constructs triplets from within a minibatch. We\ncompare our method to several strong baselines as well as recent works on the\nDeepFashion and Stanford Online Product datasets. Our approach significantly\noutperforms the state-of-the-art on the DeepFashion dataset. With a\nmodification to favor sampling minibatches from a single product category, the\nsame approach demonstrates competitive results when compared to the\nstate-of-the-art for the Stanford Online Products dataset.\n", "versions": [{"version": "v1", "created": "Wed, 10 Oct 2018 17:19:08 GMT"}], "update_date": "2018-10-11", "authors_parsed": [["Dodds", "Eric", ""], ["Nguyen", "Huy", ""], ["Herdade", "Simao", ""], ["Culpepper", "Jack", ""], ["Kae", "Andrew", ""], ["Garrigues", "Pierre", ""]]}, {"id": "1810.04668", "submitter": "Margit Antal", "authors": "Margit Antal and Elod Egyed-Zsigmond", "title": "Intrusion Detection Using Mouse Dynamics", "comments": "Submitted to IET Biometrics on 23 May 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.HC cs.CR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Compared to other behavioural biometrics, mouse dynamics is a less explored\narea. General purpose data sets containing unrestricted mouse usage data are\nusually not available. The Balabit data set was released in 2016 for a data\nscience competition, which against the few subjects, can be considered the\nfirst adequate publicly available one. This paper presents a performance\nevaluation study on this data set for impostor detection. The existence of very\nshort test sessions makes this data set challenging. Raw data were segmented\ninto mouse move, point and click and drag and drop types of mouse actions, then\nseveral features were extracted. In contrast to keystroke dynamics, mouse data\nis not sensitive, therefore it is possible to collect negative mouse dynamics\ndata and to use two-class classifiers for impostor detection. Both action- and\nset of actions-based evaluations were performed. Set of actions-based\nevaluation achieves 0.92 AUC on the test part of the data set. However, the\nsame type of evaluation conducted on the training part of the data set resulted\nin maximal AUC (1) using only 13 actions. Drag and drop mouse actions proved to\nbe the best actions for impostor detection.\n", "versions": [{"version": "v1", "created": "Wed, 10 Oct 2018 18:25:02 GMT"}], "update_date": "2018-10-14", "authors_parsed": [["Antal", "Margit", ""], ["Egyed-Zsigmond", "Elod", ""]]}, {"id": "1810.04714", "submitter": "Hao-Wen Dong", "authors": "Hao-Wen Dong and Yi-Hsuan Yang", "title": "Training Generative Adversarial Networks with Binary Neurons by\n  End-to-end Backpropagation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose the BinaryGAN, a novel generative adversarial network (GAN) that\nuses binary neurons at the output layer of the generator. We employ the\nsigmoid-adjusted straight-through estimators to estimate the gradients for the\nbinary neurons and train the whole network by end-to-end backpropogation. The\nproposed model is able to directly generate binary-valued predictions at test\ntime. We implement such a model to generate binarized MNIST digits and\nexperimentally compare the performance for different types of binary neurons,\nGAN objectives and network architectures. Although the results are still\npreliminary, we show that it is possible to train a GAN that has binary neurons\nand that the use of gradient estimators can be a promising direction for\nmodeling discrete distributions with GANs. For reproducibility, the source code\nis available at https://github.com/salu133445/binarygan .\n", "versions": [{"version": "v1", "created": "Wed, 10 Oct 2018 19:13:59 GMT"}], "update_date": "2018-10-12", "authors_parsed": [["Dong", "Hao-Wen", ""], ["Yang", "Yi-Hsuan", ""]]}, {"id": "1810.04719", "submitter": "Quan Wang", "authors": "Aonan Zhang, Quan Wang, Zhenyao Zhu, John Paisley, Chong Wang", "title": "Fully Supervised Speaker Diarization", "comments": "Accepted by ICASSP 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.AS cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we propose a fully supervised speaker diarization approach,\nnamed unbounded interleaved-state recurrent neural networks (UIS-RNN). Given\nextracted speaker-discriminative embeddings (a.k.a. d-vectors) from input\nutterances, each individual speaker is modeled by a parameter-sharing RNN,\nwhile the RNN states for different speakers interleave in the time domain. This\nRNN is naturally integrated with a distance-dependent Chinese restaurant\nprocess (ddCRP) to accommodate an unknown number of speakers. Our system is\nfully supervised and is able to learn from examples where time-stamped speaker\nlabels are annotated. We achieved a 7.6% diarization error rate on NIST SRE\n2000 CALLHOME, which is better than the state-of-the-art method using spectral\nclustering. Moreover, our method decodes in an online fashion while most\nstate-of-the-art systems rely on offline clustering.\n", "versions": [{"version": "v1", "created": "Wed, 10 Oct 2018 19:21:44 GMT"}, {"version": "v2", "created": "Fri, 12 Oct 2018 13:12:36 GMT"}, {"version": "v3", "created": "Sat, 27 Oct 2018 05:44:52 GMT"}, {"version": "v4", "created": "Mon, 17 Dec 2018 23:30:02 GMT"}, {"version": "v5", "created": "Fri, 8 Feb 2019 21:52:19 GMT"}, {"version": "v6", "created": "Sun, 17 Feb 2019 20:02:52 GMT"}, {"version": "v7", "created": "Tue, 19 Feb 2019 16:30:55 GMT"}], "update_date": "2019-02-20", "authors_parsed": [["Zhang", "Aonan", ""], ["Wang", "Quan", ""], ["Zhu", "Zhenyao", ""], ["Paisley", "John", ""], ["Wang", "Chong", ""]]}, {"id": "1810.04723", "submitter": "Lam Nguyen", "authors": "Phuong Ha Nguyen, Lam M. Nguyen, Marten van Dijk", "title": "Tight Dimension Independent Lower Bound on the Expected Convergence Rate\n  for Diminishing Step Sizes in SGD", "comments": "The 33th Annual Conference on Neural Information Processing Systems\n  (NeurIPS 2019)", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.OC cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the convergence of Stochastic Gradient Descent (SGD) for strongly\nconvex objective functions. We prove for all $t$ a lower bound on the expected\nconvergence rate after the $t$-th SGD iteration; the lower bound is over all\npossible sequences of diminishing step sizes. It implies that recently proposed\nsequences of step sizes at ICML 2018 and ICML 2019 are {\\em universally} close\nto optimal in that the expected convergence rate after {\\em each} iteration is\nwithin a factor $32$ of our lower bound. This factor is independent of\ndimension $d$. We offer a framework for comparing with lower bounds in\nstate-of-the-art literature and when applied to SGD for strongly convex\nobjective functions our lower bound is a significant factor $775\\cdot d$ larger\ncompared to existing work.\n", "versions": [{"version": "v1", "created": "Wed, 10 Oct 2018 19:32:50 GMT"}, {"version": "v2", "created": "Sat, 19 Jan 2019 01:59:40 GMT"}, {"version": "v3", "created": "Sat, 25 May 2019 03:13:02 GMT"}, {"version": "v4", "created": "Fri, 8 Nov 2019 02:51:59 GMT"}], "update_date": "2019-11-11", "authors_parsed": [["Nguyen", "Phuong Ha", ""], ["Nguyen", "Lam M.", ""], ["van Dijk", "Marten", ""]]}, {"id": "1810.04738", "submitter": "David Qiu", "authors": "David Qiu and Anuran Makur and Lizhong Zheng", "title": "Probabilistic Clustering Using Maximal Matrix Norm Couplings", "comments": "Presented at 56th Annual Allerton Conference on Communication,\n  Control, and Computing, 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.IT math.IT stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we present a local information theoretic approach to\nexplicitly learn probabilistic clustering of a discrete random variable. Our\nformulation yields a convex maximization problem for which it is NP-hard to\nfind the global optimum. In order to algorithmically solve this optimization\nproblem, we propose two relaxations that are solved via gradient ascent and\nalternating maximization. Experiments on the MSR Sentence Completion Challenge,\nMovieLens 100K, and Reuters21578 datasets demonstrate that our approach is\ncompetitive with existing techniques and worthy of further investigation.\n", "versions": [{"version": "v1", "created": "Wed, 10 Oct 2018 20:26:44 GMT"}], "update_date": "2018-10-12", "authors_parsed": [["Qiu", "David", ""], ["Makur", "Anuran", ""], ["Zheng", "Lizhong", ""]]}, {"id": "1810.04754", "submitter": "Rose Yu", "authors": "Sung-En Chang, Xun Zheng, Ian E.H. Yen, Pradeep Ravikumar, Rose Yu", "title": "Efficient Tensor Decomposition with Boolean Factors", "comments": "14 pages, 3 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Tensor decomposition has been extensively used as a tool for exploratory\nanalysis. Motivated by neuroscience applications, we study tensor decomposition\nwith Boolean factors. The resulting optimization problem is challenging due to\nthe non-convex objective and the combinatorial constraints. We propose Binary\nMatching Pursuit (BMP), a novel generalization of the matching pursuit strategy\nto decompose the tensor efficiently. BMP iteratively searches for atoms in a\ngreedy fashion. The greedy atom search step is solved efficiently via a\nMAXCUT-like boolean quadratic program. We prove that BMP is guaranteed to\nconverge sublinearly to the optimal solution and recover the factors under mild\nidentifiability conditions. Experiments demonstrate the superior performance of\nour method over baselines on synthetic and real datasets. We also showcase the\napplication of BMP in quantifying neural interactions underlying\nhigh-resolution spatiotemporal ECoG recordings.\n", "versions": [{"version": "v1", "created": "Wed, 10 Oct 2018 21:41:52 GMT"}, {"version": "v2", "created": "Wed, 11 Nov 2020 22:35:27 GMT"}], "update_date": "2020-11-13", "authors_parsed": [["Chang", "Sung-En", ""], ["Zheng", "Xun", ""], ["Yen", "Ian E. H.", ""], ["Ravikumar", "Pradeep", ""], ["Yu", "Rose", ""]]}, {"id": "1810.04777", "submitter": "Runjing Liu", "authors": "Runjing Liu, Jeffrey Regier, Nilesh Tripuraneni, Michael I. Jordan,\n  and Jon McAuliffe", "title": "Rao-Blackwellized Stochastic Gradients for Discrete Distributions", "comments": "Accepted to ICML 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We wish to compute the gradient of an expectation over a finite or countably\ninfinite sample space having $K \\leq \\infty$ categories. When $K$ is indeed\ninfinite, or finite but very large, the relevant summation is intractable.\nAccordingly, various stochastic gradient estimators have been proposed. In this\npaper, we describe a technique that can be applied to reduce the variance of\nany such estimator, without changing its bias---in particular, unbiasedness is\nretained. We show that our technique is an instance of Rao-Blackwellization,\nand we demonstrate the improvement it yields on a semi-supervised\nclassification problem and a pixel attention task.\n", "versions": [{"version": "v1", "created": "Wed, 10 Oct 2018 23:17:11 GMT"}, {"version": "v2", "created": "Tue, 12 Feb 2019 07:00:13 GMT"}, {"version": "v3", "created": "Mon, 13 May 2019 17:36:37 GMT"}], "update_date": "2019-05-14", "authors_parsed": [["Liu", "Runjing", ""], ["Regier", "Jeffrey", ""], ["Tripuraneni", "Nilesh", ""], ["Jordan", "Michael I.", ""], ["McAuliffe", "Jon", ""]]}, {"id": "1810.04778", "submitter": "Susan Athey", "authors": "Zhengyuan Zhou, Susan Athey, Stefan Wager", "title": "Offline Multi-Action Policy Learning: Generalization and Optimization", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG econ.EM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In many settings, a decision-maker wishes to learn a rule, or policy, that\nmaps from observable characteristics of an individual to an action. Examples\ninclude selecting offers, prices, advertisements, or emails to send to\nconsumers, as well as the problem of determining which medication to prescribe\nto a patient. While there is a growing body of literature devoted to this\nproblem, most existing results are focused on the case where data comes from a\nrandomized experiment, and further, there are only two possible actions, such\nas giving a drug to a patient or not. In this paper, we study the offline\nmulti-action policy learning problem with observational data and where the\npolicy may need to respect budget constraints or belong to a restricted policy\nclass such as decision trees. We build on the theory of efficient\nsemi-parametric inference in order to propose and implement a policy learning\nalgorithm that achieves asymptotically minimax-optimal regret. To the best of\nour knowledge, this is the first result of this type in the multi-action setup,\nand it provides a substantial performance improvement over the existing\nlearning algorithms. We then consider additional computational challenges that\narise in implementing our method for the case where the policy is restricted to\ntake the form of a decision tree. We propose two different approaches, one\nusing a mixed integer program formulation and the other using a tree-search\nbased algorithm.\n", "versions": [{"version": "v1", "created": "Wed, 10 Oct 2018 23:34:37 GMT"}, {"version": "v2", "created": "Mon, 19 Nov 2018 16:29:24 GMT"}], "update_date": "2018-11-20", "authors_parsed": [["Zhou", "Zhengyuan", ""], ["Athey", "Susan", ""], ["Wager", "Stefan", ""]]}, {"id": "1810.04793", "submitter": "Kamran Kowsari", "authors": "Jinghe Zhang, Kamran Kowsari, James H. Harrison, Jennifer M. Lobo,\n  Laura E. Barnes", "title": "Patient2Vec: A Personalized Interpretable Deep Representation of the\n  Longitudinal Electronic Health Record", "comments": "Accepted by IEEE Access", "journal-ref": null, "doi": "10.1109/ACCESS.2018.2875677", "report-no": null, "categories": "q-bio.QM cs.AI cs.IR cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The wide implementation of electronic health record (EHR) systems facilitates\nthe collection of large-scale health data from real clinical settings. Despite\nthe significant increase in adoption of EHR systems, this data remains largely\nunexplored, but presents a rich data source for knowledge discovery from\npatient health histories in tasks such as understanding disease correlations\nand predicting health outcomes. However, the heterogeneity, sparsity, noise,\nand bias in this data present many complex challenges. This complexity makes it\ndifficult to translate potentially relevant information into machine learning\nalgorithms. In this paper, we propose a computational framework, Patient2Vec,\nto learn an interpretable deep representation of longitudinal EHR data which is\npersonalized for each patient. To evaluate this approach, we apply it to the\nprediction of future hospitalizations using real EHR data and compare its\npredictive performance with baseline methods. Patient2Vec produces a vector\nspace with meaningful structure and it achieves an AUC around 0.799\noutperforming baseline methods. In the end, the learned feature importance can\nbe visualized and interpreted at both the individual and population levels to\nbring clinical insights.\n", "versions": [{"version": "v1", "created": "Wed, 10 Oct 2018 16:41:05 GMT"}, {"version": "v2", "created": "Mon, 22 Oct 2018 15:13:16 GMT"}, {"version": "v3", "created": "Thu, 25 Oct 2018 13:38:34 GMT"}], "update_date": "2018-10-26", "authors_parsed": [["Zhang", "Jinghe", ""], ["Kowsari", "Kamran", ""], ["Harrison", "James H.", ""], ["Lobo", "Jennifer M.", ""], ["Barnes", "Laura E.", ""]]}, {"id": "1810.04824", "submitter": "Fei Tan", "authors": "Fei Tan, Zhi Wei, Jun He, Xiang Wu, Bo Peng, Haoran Liu, and Zhenyu\n  Yan", "title": "A Blended Deep Learning Approach for Predicting User Intended Actions", "comments": "10 pages, International Conference on Data Mining 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.HC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  User intended actions are widely seen in many areas. Forecasting these\nactions and taking proactive measures to optimize business outcome is a crucial\nstep towards sustaining the steady business growth. In this work, we focus on\npre- dicting attrition, which is one of typical user intended actions.\nConventional attrition predictive modeling strategies suffer a few inherent\ndrawbacks. To overcome these limitations, we propose a novel end-to-end\nlearning scheme to keep track of the evolution of attrition patterns for the\npredictive modeling. It integrates user activity logs, dynamic and static user\nprofiles based on multi-path learning. It exploits historical user records by\nestablishing a decaying multi-snapshot technique. And finally it employs the\nprecedent user intentions via guiding them to the subsequent learning\nprocedure. As a result, it addresses all disadvantages of conventional methods.\nWe evaluate our methodology on two public data repositories and one private\nuser usage dataset provided by Adobe Creative Cloud. The extensive experiments\ndemonstrate that it can offer the appealing performance in comparison with\nseveral existing approaches as rated by different popular metrics. Furthermore,\nwe introduce an advanced interpretation and visualization strategy to\neffectively characterize the periodicity of user activity logs. It can help to\npinpoint important factors that are critical to user attrition and retention\nand thus suggests actionable improvement targets for business practice. Our\nwork will provide useful insights into the prediction and elucidation of other\nuser intended actions as well.\n", "versions": [{"version": "v1", "created": "Thu, 11 Oct 2018 02:48:20 GMT"}], "update_date": "2018-10-12", "authors_parsed": [["Tan", "Fei", ""], ["Wei", "Zhi", ""], ["He", "Jun", ""], ["Wu", "Xiang", ""], ["Peng", "Bo", ""], ["Liu", "Haoran", ""], ["Yan", "Zhenyu", ""]]}, {"id": "1810.04826", "submitter": "Quan Wang", "authors": "Quan Wang, Hannah Muckenhirn, Kevin Wilson, Prashant Sridhar, Zelin\n  Wu, John Hershey, Rif A. Saurous, Ron J. Weiss, Ye Jia, Ignacio Lopez Moreno", "title": "VoiceFilter: Targeted Voice Separation by Speaker-Conditioned\n  Spectrogram Masking", "comments": "To appear in Interspeech 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.AS cs.LG eess.SP stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we present a novel system that separates the voice of a target\nspeaker from multi-speaker signals, by making use of a reference signal from\nthe target speaker. We achieve this by training two separate neural networks:\n(1) A speaker recognition network that produces speaker-discriminative\nembeddings; (2) A spectrogram masking network that takes both noisy spectrogram\nand speaker embedding as input, and produces a mask. Our system significantly\nreduces the speech recognition WER on multi-speaker signals, with minimal WER\ndegradation on single-speaker signals.\n", "versions": [{"version": "v1", "created": "Thu, 11 Oct 2018 02:57:14 GMT"}, {"version": "v2", "created": "Fri, 12 Oct 2018 13:08:42 GMT"}, {"version": "v3", "created": "Sat, 27 Oct 2018 05:36:13 GMT"}, {"version": "v4", "created": "Thu, 21 Feb 2019 15:36:55 GMT"}, {"version": "v5", "created": "Wed, 29 May 2019 14:23:02 GMT"}, {"version": "v6", "created": "Wed, 19 Jun 2019 17:10:51 GMT"}], "update_date": "2019-06-20", "authors_parsed": [["Wang", "Quan", ""], ["Muckenhirn", "Hannah", ""], ["Wilson", "Kevin", ""], ["Sridhar", "Prashant", ""], ["Wu", "Zelin", ""], ["Hershey", "John", ""], ["Saurous", "Rif A.", ""], ["Weiss", "Ron J.", ""], ["Jia", "Ye", ""], ["Moreno", "Ignacio Lopez", ""]]}, {"id": "1810.04851", "submitter": "Fang Liu", "authors": "Yinan Li, Xiao Liu, Fang Liu", "title": "PANDA: AdaPtive Noisy Data Augmentation for Regularization of Undirected\n  Graphical Models", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose an AdaPtive Noise Augmentation (PANDA) technique to regularize the\nestimation and construction of undirected graphical models. PANDA iteratively\noptimizes the objective function given the noise augmented data until\nconvergence to achieve regularization on model parameters. The augmented noises\ncan be designed to achieve various regularization effects on graph estimation,\nsuch as the bridge (including lasso and ridge), elastic net, adaptive lasso,\nand SCAD penalization; it also realizes the group lasso and fused ridge. We\nexamine the tail bound of the noise-augmented loss function and establish that\nthe noise-augmented loss function and its minimizer converge almost surely to\nthe expected penalized loss function and its minimizer, respectively. We derive\nthe asymptotic distributions for the regularized parameters through PANDA in\ngeneralized linear models, based on which, inferences for the parameters can be\nobtained simultaneously with variable selection. We show the non-inferior\nperformance of PANDA in constructing graphs of different types in simulation\nstudies and apply PANDA to an autism spectrum disorder data to construct a\nmixed-node graph. We also show that the inferences based on the asymptotic\ndistribution of regularized parameter estimates via PANDA achieve nominal or\nnear-nominal coverage and are far more efficient, compared to some existing\npost-selection procedures. Computationally, PANDA can be easily programmed in\nsoftware that implements (GLMs) without resorting to complicated optimization\ntechniques.\n", "versions": [{"version": "v1", "created": "Thu, 11 Oct 2018 05:54:44 GMT"}, {"version": "v2", "created": "Tue, 21 May 2019 22:52:51 GMT"}], "update_date": "2019-05-23", "authors_parsed": [["Li", "Yinan", ""], ["Liu", "Xiao", ""], ["Liu", "Fang", ""]]}, {"id": "1810.04859", "submitter": "Ekraam Sabir", "authors": "Dhruva Kartik, Ekraam Sabir, Urbashi Mitra and Prem Natarajan", "title": "Policy Design for Active Sequential Hypothesis Testing using Deep\n  Learning", "comments": "Accepted at 56th Annual Allerton Conference on Communication,\n  Control, and Computing", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IT cs.AI cs.LG cs.SY math.IT math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Information theory has been very successful in obtaining performance limits\nfor various problems such as communication, compression and hypothesis testing.\nLikewise, stochastic control theory provides a characterization of optimal\npolicies for Partially Observable Markov Decision Processes (POMDPs) using\ndynamic programming. However, finding optimal policies for these problems is\ncomputationally hard in general and thus, heuristic solutions are employed in\npractice. Deep learning can be used as a tool for designing better heuristics\nin such problems. In this paper, the problem of active sequential hypothesis\ntesting is considered. The goal is to design a policy that can reliably infer\nthe true hypothesis using as few samples as possible by adaptively selecting\nappropriate queries. This problem can be modeled as a POMDP and bounds on its\nvalue function exist in literature. However, optimal policies have not been\nidentified and various heuristics are used. In this paper, two new heuristics\nare proposed: one based on deep reinforcement learning and another based on a\nKL-divergence zero-sum game. These heuristics are compared with\nstate-of-the-art solutions and it is demonstrated using numerical experiments\nthat the proposed heuristics can achieve significantly better performance than\nexisting methods in some scenarios.\n", "versions": [{"version": "v1", "created": "Thu, 11 Oct 2018 06:15:05 GMT"}], "update_date": "2018-10-15", "authors_parsed": [["Kartik", "Dhruva", ""], ["Sabir", "Ekraam", ""], ["Mitra", "Urbashi", ""], ["Natarajan", "Prem", ""]]}, {"id": "1810.04863", "submitter": "Matthew J. Holland", "authors": "Matthew J. Holland", "title": "Classification using margin pursuit", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this work, we study a new approach to optimizing the margin distribution\nrealized by binary classifiers. The classical approach to this problem is\nsimply maximization of the expected margin, while more recent proposals\nconsider simultaneous variance control and proxy objectives based on robust\nlocation estimates, in the vein of keeping the margin distribution sharply\nconcentrated in a desirable region. While conceptually appealing, these new\napproaches are often computationally unwieldy, and theoretical guarantees are\nlimited. Given this context, we propose an algorithm which searches the\nhypothesis space in such a way that a pre-set \"margin level\" ends up being a\ndistribution-robust estimator of the margin location. This procedure is easily\nimplemented using gradient descent, and admits finite-sample bounds on the\nexcess risk under unbounded inputs. Empirical tests on real-world benchmark\ndata reinforce the basic principles highlighted by the theory, and are\nsuggestive of a promising new technique for classification.\n", "versions": [{"version": "v1", "created": "Thu, 11 Oct 2018 06:35:48 GMT"}], "update_date": "2018-10-12", "authors_parsed": [["Holland", "Matthew J.", ""]]}, {"id": "1810.04871", "submitter": "Homanga Bharadhwaj", "authors": "Homanga Bharadhwaj, Zihan Wang, Yoshua Bengio, Liam Paull", "title": "A Data-Efficient Framework for Training and Sim-to-Real Transfer of\n  Navigation Policies", "comments": "Under review in ICRA 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.AI cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Learning effective visuomotor policies for robots purely from data is\nchallenging, but also appealing since a learning-based system should not\nrequire manual tuning or calibration. In the case of a robot operating in a\nreal environment the training process can be costly, time-consuming, and even\ndangerous since failures are common at the start of training. For this reason,\nit is desirable to be able to leverage \\textit{simulation} and\n\\textit{off-policy} data to the extent possible to train the robot. In this\nwork, we introduce a robust framework that plans in simulation and transfers\nwell to the real environment. Our model incorporates a gradient-descent based\nplanning module, which, given the initial image and goal image, encodes the\nimages to a lower dimensional latent state and plans a trajectory to reach the\ngoal. The model, consisting of the encoder and planner modules, is trained\nthrough a meta-learning strategy in simulation first. We subsequently perform\nadversarial domain transfer on the encoder by using a bank of unlabelled but\nrandom images from the simulation and real environments to enable the encoder\nto map images from the real and simulated environments to a similarly\ndistributed latent representation. By fine tuning the entire model (encoder +\nplanner) with far fewer real world expert demonstrations, we show successful\nplanning performances in different navigation tasks.\n", "versions": [{"version": "v1", "created": "Thu, 11 Oct 2018 07:22:54 GMT"}], "update_date": "2018-10-12", "authors_parsed": [["Bharadhwaj", "Homanga", ""], ["Wang", "Zihan", ""], ["Bengio", "Yoshua", ""], ["Paull", "Liam", ""]]}, {"id": "1810.04879", "submitter": "Sao Mai Nguyen", "authors": "Maxime Devanne (LIFL), Sao Mai Nguyen (Lab-STICC, IMT Atlantique)", "title": "Generating Shared Latent Variables for Robots to Imitate Human Movements\n  and Understand their Physical Limitations", "comments": null, "journal-ref": "Computer Vision -- ECCV 2018 Workshops", "doi": "10.1007/978-3-030-11012-3_15", "report-no": null, "categories": "cs.RO cs.AI cs.CV cs.HC cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Assistive robotics and particularly robot coaches may be very helpful for\nrehabilitation healthcare. In this context, we propose a method based on\nGaussian Process Latent Variable Model (GP-LVM) to transfer knowledge between a\nphysiotherapist, a robot coach and a patient. Our model is able to map visual\nhuman body features to robot data in order to facilitate the robot learning and\nimitation. In addition , we propose to extend the model to adapt robots'\nunderstanding to patient's physical limitations during the assessment of\nrehabilitation exercises. Experimental evaluation demonstrates promising\nresults for both robot imitation and model adaptation according to the\npatients' limitations.\n", "versions": [{"version": "v1", "created": "Thu, 11 Oct 2018 08:01:08 GMT"}, {"version": "v2", "created": "Thu, 14 Feb 2019 22:09:34 GMT"}], "update_date": "2019-02-18", "authors_parsed": [["Devanne", "Maxime", "", "LIFL"], ["Nguyen", "Sao Mai", "", "Lab-STICC, IMT Atlantique"]]}, {"id": "1810.04881", "submitter": "Stefano Bromuri Dr", "authors": "R.L. Curier, T.J.A. De Jong, Katharina Strauch, Katharina Cramer,\n  Natalie Rosenski, Clara Schartner, M. Debusschere, and Hannah Ziemons, Deniz\n  Iren and Stefano Bromuri", "title": "Monitoring spatial sustainable development: Semi-automated analysis of\n  satellite and aerial images for energy transition and sustainability\n  indicators", "comments": "This document provides the reader with an overview of the various\n  datasets which will be used throughout the project. The collection of\n  satellite and aerial images as well as auxiliary information such as the\n  location of buildings and roofs which is required to train, test and validate\n  the machine learning algorithm that is being developed", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Solar panels are installed by a large and growing number of households due to\nthe convenience of having cheap and renewable energy to power house appliances.\nIn contrast to other energy sources solar installations are distributed very\ndecentralized and spread over hundred-thousands of locations. On a global level\nmore than 25% of solar photovoltaic (PV) installations were decentralized. The\neffect of the quick energy transition from a carbon based economy to a green\neconomy is though still very difficult to quantify. As a matter of fact the\nquick adoption of solar panels by households is difficult to track, with local\nregistries that miss a large number of the newly built solar panels. This makes\nthe task of assessing the impact of renewable energies an impossible task.\nAlthough models of the output of a region exist, they are often black box\nestimations. This project's aim is twofold: First automate the process to\nextract the location of solar panels from aerial or satellite images and\nsecond, produce a map of solar panels along with statistics on the number of\nsolar panels. Further, this project takes place in a wider framework which\ninvestigates how official statistics can benefit from new digital data sources.\nAt project completion, a method for detecting solar panels from aerial images\nvia machine learning will be developed and the methodology initially developed\nfor BE, DE and NL will be standardized for application to other EU countries.\nIn practice, machine learning techniques are used to identify solar panels in\nsatellite and aerial images for the province of Limburg (NL), Flanders (BE) and\nNorth Rhine-Westphalia (DE).\n", "versions": [{"version": "v1", "created": "Thu, 11 Oct 2018 08:05:29 GMT"}], "update_date": "2018-10-12", "authors_parsed": [["Curier", "R. L.", ""], ["De Jong", "T. J. A.", ""], ["Strauch", "Katharina", ""], ["Cramer", "Katharina", ""], ["Rosenski", "Natalie", ""], ["Schartner", "Clara", ""], ["Debusschere", "M.", ""], ["Ziemons", "Hannah", ""], ["Iren", "Deniz", ""], ["Bromuri", "Stefano", ""]]}, {"id": "1810.04903", "submitter": "Fatma BenSaid", "authors": "Fatma BenSaid and Adel M. Alimi", "title": "MOANOFS: Multi-Objective Automated Negotiation based Online Feature\n  Selection System for Big Data Classification", "comments": "15 pages, 8 figures, journal paper", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CV cs.MA stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Feature Selection (FS) plays an important role in learning and classification\ntasks. The object of FS is to select the relevant and non-redundant features.\nConsidering the huge amount number of features in real-world applications, FS\nmethods using batch learning technique can't resolve big data problem\nespecially when data arrive sequentially. In this paper, we propose an online\nfeature selection system which resolves this problem. More specifically, we\ntreat the problem of online supervised feature selection for binary\nclassification as a decision-making problem. A philosophical vision to this\nproblem leads to a hybridization between two important domains: feature\nselection using online learning technique (OFS) and automated negotiation (AN).\nThe proposed OFS system called MOANOFS (Multi-Objective Automated Negotiation\nbased Online Feature Selection) uses two levels of decision. In the first\nlevel, from n learners (or OFS methods), we decide which are the k trustful\nones (with high confidence or trust value). These elected k learners will\nparticipate in the second level. In this level, we integrate our proposed\nMultilateral Automated Negotiation based OFS (MANOFS) method to decide finally\nwhich is the best solution or which are relevant features. We show that MOANOFS\nsystem is applicable to different domains successfully and achieves high\naccuracy with several real-world applications.\n  Index Terms: Feature selection, online learning, multi-objective automated\nnegotiation, trust, classification, big data.\n", "versions": [{"version": "v1", "created": "Thu, 11 Oct 2018 08:41:30 GMT"}, {"version": "v2", "created": "Tue, 18 Jun 2019 15:19:17 GMT"}], "update_date": "2019-06-19", "authors_parsed": [["BenSaid", "Fatma", ""], ["Alimi", "Adel M.", ""]]}, {"id": "1810.04920", "submitter": "Aibek Alanov", "authors": "Aibek Alanov, Max Kochurov, Daniil Yashkov, Dmitry Vetrov", "title": "Pairwise Augmented GANs with Adversarial Reconstruction Loss", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a novel autoencoding model called Pairwise Augmented GANs. We\ntrain a generator and an encoder jointly and in an adversarial manner. The\ngenerator network learns to sample realistic objects. In turn, the encoder\nnetwork at the same time is trained to map the true data distribution to the\nprior in latent space. To ensure good reconstructions, we introduce an\naugmented adversarial reconstruction loss. Here we train a discriminator to\ndistinguish two types of pairs: an object with its augmentation and the one\nwith its reconstruction. We show that such adversarial loss compares objects\nbased on the content rather than on the exact match. We experimentally\ndemonstrate that our model generates samples and reconstructions of quality\ncompetitive with state-of-the-art on datasets MNIST, CIFAR10, CelebA and\nachieves good quantitative results on CIFAR10.\n", "versions": [{"version": "v1", "created": "Thu, 11 Oct 2018 09:22:36 GMT"}], "update_date": "2018-10-12", "authors_parsed": [["Alanov", "Aibek", ""], ["Kochurov", "Max", ""], ["Yashkov", "Daniil", ""], ["Vetrov", "Dmitry", ""]]}, {"id": "1810.04996", "submitter": "Junpei Komiyama", "authors": "Junpei Komiyama and Takanori Maehara", "title": "A Simple Way to Deal with Cherry-picking", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ME cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Statistical hypothesis testing serves as statistical evidence for scientific\ninnovation. However, if the reported results are intentionally biased,\nhypothesis testing no longer controls the rate of false discovery. In\nparticular, we study such selection bias in machine learning models where the\nreporter is motivated to promote an algorithmic innovation. When the number of\npossible configurations (e.g., datasets) is large, we show that the reporter\ncan falsely report an innovation even if there is no improvement at all. We\npropose a `post-reporting' solution to this issue where the bias of the\nreported results is verified by another set of results. The theoretical\nfindings are supported by experimental results with synthetic and real-world\ndatasets.\n", "versions": [{"version": "v1", "created": "Thu, 11 Oct 2018 13:06:48 GMT"}], "update_date": "2018-10-12", "authors_parsed": [["Komiyama", "Junpei", ""], ["Maehara", "Takanori", ""]]}, {"id": "1810.05017", "submitter": "Tom Paine", "authors": "Tom Le Paine, Sergio G\\'omez Colmenarejo, Ziyu Wang, Scott Reed, Yusuf\n  Aytar, Tobias Pfaff, Matt W. Hoffman, Gabriel Barth-Maron, Serkan Cabi, David\n  Budden, Nando de Freitas", "title": "One-Shot High-Fidelity Imitation: Training Large-Scale Deep Nets with RL", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CV cs.RO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Humans are experts at high-fidelity imitation -- closely mimicking a\ndemonstration, often in one attempt. Humans use this ability to quickly solve a\ntask instance, and to bootstrap learning of new tasks. Achieving these\nabilities in autonomous agents is an open problem. In this paper, we introduce\nan off-policy RL algorithm (MetaMimic) to narrow this gap. MetaMimic can learn\nboth (i) policies for high-fidelity one-shot imitation of diverse novel skills,\nand (ii) policies that enable the agent to solve tasks more efficiently than\nthe demonstrators. MetaMimic relies on the principle of storing all experiences\nin a memory and replaying these to learn massive deep neural network policies\nby off-policy RL. This paper introduces, to the best of our knowledge, the\nlargest existing neural networks for deep RL and shows that larger networks\nwith normalization are needed to achieve one-shot high-fidelity imitation on a\nchallenging manipulation task. The results also show that both types of policy\ncan be learned from vision, in spite of the task rewards being sparse, and\nwithout access to demonstrator actions.\n", "versions": [{"version": "v1", "created": "Thu, 11 Oct 2018 13:46:18 GMT"}], "update_date": "2018-10-12", "authors_parsed": [["Paine", "Tom Le", ""], ["Colmenarejo", "Sergio G\u00f3mez", ""], ["Wang", "Ziyu", ""], ["Reed", "Scott", ""], ["Aytar", "Yusuf", ""], ["Pfaff", "Tobias", ""], ["Hoffman", "Matt W.", ""], ["Barth-Maron", "Gabriel", ""], ["Cabi", "Serkan", ""], ["Budden", "David", ""], ["de Freitas", "Nando", ""]]}, {"id": "1810.05041", "submitter": "Jack Fitzsimons", "authors": "Jack Fitzsimons, AbdulRahman Al Ali, Michael Osborne and Stephen\n  Roberts", "title": "A General Framework for Fair Regression", "comments": "8 pages, 4 figures, 2 pages references", "journal-ref": null, "doi": "10.3390/e21080741", "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Fairness, through its many forms and definitions, has become an important\nissue facing the machine learning community. In this work, we consider how to\nincorporate group fairness constraints in kernel regression methods, applicable\nto Gaussian processes, support vector machines, neural network regression and\ndecision tree regression. Further, we focus on examining the effect of\nincorporating these constraints in decision tree regression, with direct\napplications to random forests and boosted trees amongst other widespread\npopular inference techniques. We show that the order of complexity of memory\nand computation is preserved for such models and tightly bound the expected\nperturbations to the model in terms of the number of leaves of the trees.\nImportantly, the approach works on trained models and hence can be easily\napplied to models in current use and group labels are only required on training\ndata.\n", "versions": [{"version": "v1", "created": "Wed, 10 Oct 2018 16:16:03 GMT"}, {"version": "v2", "created": "Sat, 2 Feb 2019 08:09:20 GMT"}], "update_date": "2019-09-04", "authors_parsed": [["Fitzsimons", "Jack", ""], ["Ali", "AbdulRahman Al", ""], ["Osborne", "Michael", ""], ["Roberts", "Stephen", ""]]}, {"id": "1810.05057", "submitter": "Alban Laflaqui\\`ere Dr", "authors": "Nicolas Le Hir, Olivier Sigaud, Alban Laflaqui\\`ere", "title": "Identification of Invariant Sensorimotor Structures as a Prerequisite\n  for the Discovery of Objects", "comments": "24 pages, 10 figures, published in Frontiers Robotics and AI", "journal-ref": "Front. Robot. AI, 25 June 2018", "doi": "10.3389/frobt.2018.00070", "report-no": null, "categories": "cs.AI cs.LG cs.RO stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Perceiving the surrounding environment in terms of objects is useful for any\ngeneral purpose intelligent agent. In this paper, we investigate a fundamental\nmechanism making object perception possible, namely the identification of\nspatio-temporally invariant structures in the sensorimotor experience of an\nagent. We take inspiration from the Sensorimotor Contingencies Theory to define\na computational model of this mechanism through a sensorimotor, unsupervised\nand predictive approach. Our model is based on processing the unsupervised\ninteraction of an artificial agent with its environment. We show how\nspatio-temporally invariant structures in the environment induce regularities\nin the sensorimotor experience of an agent, and how this agent, while building\na predictive model of its sensorimotor experience, can capture them as densely\nconnected subgraphs in a graph of sensory states connected by motor commands.\nOur approach is focused on elementary mechanisms, and is illustrated with a set\nof simple experiments in which an agent interacts with an environment. We show\nhow the agent can build an internal model of moving but spatio-temporally\ninvariant structures by performing a Spectral Clustering of the graph modeling\nits overall sensorimotor experiences. We systematically examine properties of\nthe model, shedding light more globally on the specificities of the paradigm\nwith respect to methods based on the supervised processing of collections of\nstatic images.\n", "versions": [{"version": "v1", "created": "Thu, 11 Oct 2018 14:47:38 GMT"}], "update_date": "2018-10-12", "authors_parsed": [["Hir", "Nicolas Le", ""], ["Sigaud", "Olivier", ""], ["Laflaqui\u00e8re", "Alban", ""]]}, {"id": "1810.05064", "submitter": "Dennis Rohde", "authors": "Hendrik Fichtenberger, Dennis Rohde", "title": "A Theory-Based Evaluation of Nearest Neighbor Models Put Into Practice", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In the $k$-nearest neighborhood model ($k$-NN), we are given a set of points\n$P$, and we shall answer queries $q$ by returning the $k$ nearest neighbors of\n$q$ in $P$ according to some metric. This concept is crucial in many areas of\ndata analysis and data processing, e.g., computer vision, document retrieval\nand machine learning. Many $k$-NN algorithms have been published and\nimplemented, but often the relation between parameters and accuracy of the\ncomputed $k$-NN is not explicit. We study property testing of $k$-NN graphs in\ntheory and evaluate it empirically: given a point set $P \\subset\n\\mathbb{R}^\\delta$ and a directed graph $G=(P,E)$, is $G$ a $k$-NN graph, i.e.,\nevery point $p \\in P$ has outgoing edges to its $k$ nearest neighbors, or is it\n$\\epsilon$-far from being a $k$-NN graph? Here, $\\epsilon$-far means that one\nhas to change more than an $\\epsilon$-fraction of the edges in order to make\n$G$ a $k$-NN graph. We develop a randomized algorithm with one-sided error that\ndecides this question, i.e., a property tester for the $k$-NN property, with\ncomplexity $O(\\sqrt{n} k^2 / \\epsilon^2)$ measured in terms of the number of\nvertices and edges it inspects, and we prove a lower bound of $\\Omega(\\sqrt{n /\n\\epsilon k})$. We evaluate our tester empirically on the $k$-NN models computed\nby various algorithms and show that it can be used to detect $k$-NN models with\nbad accuracy in significantly less time than the building time of the $k$-NN\nmodel.\n", "versions": [{"version": "v1", "created": "Thu, 11 Oct 2018 14:56:03 GMT"}, {"version": "v2", "created": "Thu, 22 Nov 2018 14:28:12 GMT"}, {"version": "v3", "created": "Fri, 30 Nov 2018 18:33:18 GMT"}], "update_date": "2018-12-03", "authors_parsed": [["Fichtenberger", "Hendrik", ""], ["Rohde", "Dennis", ""]]}, {"id": "1810.05065", "submitter": "Xavier Fontaine", "authors": "Xavier Fontaine, Quentin Berthet, Vianney Perchet", "title": "Regularized Contextual Bandits", "comments": "AISTATS 2019, 23 pages, 2 figures", "journal-ref": "Proceedings of Machine Learning Research, PMLR 89:2144-2153, 2019", "doi": null, "report-no": null, "categories": "stat.ML cs.LG math.OC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the stochastic contextual bandit problem with additional\nregularization. The motivation comes from problems where the policy of the\nagent must be close to some baseline policy which is known to perform well on\nthe task. To tackle this problem we use a nonparametric model and propose an\nalgorithm splitting the context space into bins, and solving simultaneously -\nand independently - regularized multi-armed bandit instances on each bin. We\nderive slow and fast rates of convergence, depending on the unknown complexity\nof the problem. We also consider a new relevant margin condition to get\nproblem-independent convergence rates, ending up in intermediate convergence\nrates interpolating between the aforementioned slow and fast rates.\n", "versions": [{"version": "v1", "created": "Thu, 11 Oct 2018 15:00:15 GMT"}, {"version": "v2", "created": "Wed, 5 Jun 2019 15:25:32 GMT"}], "update_date": "2019-06-06", "authors_parsed": [["Fontaine", "Xavier", ""], ["Berthet", "Quentin", ""], ["Perchet", "Vianney", ""]]}, {"id": "1810.05075", "submitter": "Manuel Isaac Martinez Torres", "authors": "Manuel Martinez and Rainer Stiefelhagen", "title": "Taming the Cross Entropy Loss", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present the Tamed Cross Entropy (TCE) loss function, a robust derivative\nof the standard Cross Entropy (CE) loss used in deep learning for\nclassification tasks. However, unlike other robust losses, the TCE loss is\ndesigned to exhibit the same training properties than the CE loss in noiseless\nscenarios. Therefore, the TCE loss requires no modification on the training\nregime compared to the CE loss and, in consequence, can be applied in all\napplications where the CE loss is currently used. We evaluate the TCE loss\nusing the ResNet architecture on four image datasets that we artificially\ncontaminated with various levels of label noise. The TCE loss outperforms the\nCE loss in every tested scenario.\n", "versions": [{"version": "v1", "created": "Thu, 11 Oct 2018 15:18:19 GMT"}], "update_date": "2018-10-12", "authors_parsed": [["Martinez", "Manuel", ""], ["Stiefelhagen", "Rainer", ""]]}, {"id": "1810.05094", "submitter": "David \\v{S}i\\v{s}ka", "authors": "Marc Sabate Vidales and David Siska and Lukasz Szpruch", "title": "Unbiased deep solvers for parametric PDEs", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "q-fin.CP cs.LG cs.NA math.NA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We develop several deep learning algorithms for approximating families of\nparametric PDE solutions. The proposed algorithms approximate solutions\ntogether with their gradients, which in the context of mathematical finance\nmeans that the derivative prices and hedging strategies are computed\nsimulatenously. Having approximated the gradient of the solution one can\ncombine it with a Monte-Carlo simulation to remove the bias in the deep network\napproximation of the PDE solution (derivative price). This is achieved by\nleveraging the Martingale Representation Theorem and combining the Monte Carlo\nsimulation with the neural network. The resulting algorithm is robust with\nrespect to quality of the neural network approximation and consequently can be\nused as a black-box in case only limited a priori information about the\nunderlying problem is available. We believe this is important as neural network\nbased algorithms often require fair amount of tuning to produce satisfactory\nresults. The methods are empirically shown to work for high-dimensional\nproblems (e.g. 100 dimensions). We provide diagnostics that shed light on\nappropriate network architectures.\n", "versions": [{"version": "v1", "created": "Thu, 11 Oct 2018 15:53:38 GMT"}, {"version": "v2", "created": "Wed, 24 Jul 2019 19:53:02 GMT"}, {"version": "v3", "created": "Tue, 6 Apr 2021 11:17:42 GMT"}], "update_date": "2021-04-07", "authors_parsed": [["Vidales", "Marc Sabate", ""], ["Siska", "David", ""], ["Szpruch", "Lukasz", ""]]}, {"id": "1810.05102", "submitter": "Pankaj Gupta", "authors": "Pankaj Gupta and Subburam Rajaram and Hinrich Sch\\\"utze and Bernt\n  Andrassy and Thomas Runkler", "title": "Neural Relation Extraction Within and Across Sentence Boundaries", "comments": "AAAI2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.IR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Past work in relation extraction mostly focuses on binary relation between\nentity pairs within single sentence. Recently, the NLP community has gained\ninterest in relation extraction in entity pairs spanning multiple sentences. In\nthis paper, we propose a novel architecture for this task: inter-sentential\ndependency-based neural networks (iDepNN). iDepNN models the shortest and\naugmented dependency paths via recurrent and recursive neural networks to\nextract relationships within (intra-) and across (inter-) sentence boundaries.\nCompared to SVM and neural network baselines, iDepNN is more robust to false\npositives in relationships spanning sentences.\n  We evaluate our models on four datasets from newswire (MUC6) and medical\n(BioNLP shared task) domains that achieve state-of-the-art performance and show\na better balance in precision and recall for inter-sentential relationships. We\nperform better than 11 teams participating in the BioNLP shared task 2016 and\nachieve a gain of 5.2% (0.587 vs 0.558) in F1 over the winning team. We also\nrelease the crosssentence annotations for MUC6.\n", "versions": [{"version": "v1", "created": "Thu, 11 Oct 2018 16:07:20 GMT"}, {"version": "v2", "created": "Mon, 14 Jan 2019 16:56:53 GMT"}], "update_date": "2019-01-15", "authors_parsed": [["Gupta", "Pankaj", ""], ["Rajaram", "Subburam", ""], ["Sch\u00fctze", "Hinrich", ""], ["Andrassy", "Bernt", ""], ["Runkler", "Thomas", ""]]}, {"id": "1810.05148", "submitter": "Roman Novak", "authors": "Roman Novak, Lechao Xiao, Jaehoon Lee, Yasaman Bahri, Greg Yang, Jiri\n  Hron, Daniel A. Abolafia, Jeffrey Pennington, Jascha Sohl-Dickstein", "title": "Bayesian Deep Convolutional Networks with Many Channels are Gaussian\n  Processes", "comments": "Published as a conference paper at ICLR 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.AI cs.LG cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  There is a previously identified equivalence between wide fully connected\nneural networks (FCNs) and Gaussian processes (GPs). This equivalence enables,\nfor instance, test set predictions that would have resulted from a fully\nBayesian, infinitely wide trained FCN to be computed without ever instantiating\nthe FCN, but by instead evaluating the corresponding GP. In this work, we\nderive an analogous equivalence for multi-layer convolutional neural networks\n(CNNs) both with and without pooling layers, and achieve state of the art\nresults on CIFAR10 for GPs without trainable kernels. We also introduce a Monte\nCarlo method to estimate the GP corresponding to a given neural network\narchitecture, even in cases where the analytic form has too many terms to be\ncomputationally feasible.\n  Surprisingly, in the absence of pooling layers, the GPs corresponding to CNNs\nwith and without weight sharing are identical. As a consequence, translation\nequivariance, beneficial in finite channel CNNs trained with stochastic\ngradient descent (SGD), is guaranteed to play no role in the Bayesian treatment\nof the infinite channel limit - a qualitative difference between the two\nregimes that is not present in the FCN case. We confirm experimentally, that\nwhile in some scenarios the performance of SGD-trained finite CNNs approaches\nthat of the corresponding GPs as the channel count increases, with careful\ntuning SGD-trained CNNs can significantly outperform their corresponding GPs,\nsuggesting advantages from SGD training compared to fully Bayesian parameter\nestimation.\n", "versions": [{"version": "v1", "created": "Thu, 11 Oct 2018 17:49:41 GMT"}, {"version": "v2", "created": "Tue, 8 Jan 2019 00:38:34 GMT"}, {"version": "v3", "created": "Sun, 24 Feb 2019 04:42:51 GMT"}, {"version": "v4", "created": "Fri, 21 Aug 2020 15:28:27 GMT"}], "update_date": "2020-08-24", "authors_parsed": [["Novak", "Roman", ""], ["Xiao", "Lechao", ""], ["Lee", "Jaehoon", ""], ["Bahri", "Yasaman", ""], ["Yang", "Greg", ""], ["Hron", "Jiri", ""], ["Abolafia", "Daniel A.", ""], ["Pennington", "Jeffrey", ""], ["Sohl-Dickstein", "Jascha", ""]]}, {"id": "1810.05157", "submitter": "Andreea Bobu", "authors": "Andreea Bobu, Andrea Bajcsy, Jaime F. Fisac, Anca D. Dragan", "title": "Learning under Misspecified Objective Spaces", "comments": "Conference on Robot Learning (CoRL) 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.HC cs.RO stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Learning robot objective functions from human input has become increasingly\nimportant, but state-of-the-art techniques assume that the human's desired\nobjective lies within the robot's hypothesis space. When this is not true, even\nmethods that keep track of uncertainty over the objective fail because they\nreason about which hypothesis might be correct, and not whether any of the\nhypotheses are correct. We focus specifically on learning from physical human\ncorrections during the robot's task execution, where not having a rich enough\nhypothesis space leads to the robot updating its objective in ways that the\nperson did not actually intend. We observe that such corrections appear\nirrelevant to the robot, because they are not the best way of achieving any of\nthe candidate objectives. Instead of naively trusting and learning from every\nhuman interaction, we propose robots learn conservatively by reasoning in real\ntime about how relevant the human's correction is for the robot's hypothesis\nspace. We test our inference method in an experiment with human interaction\ndata, and demonstrate that this alleviates unintended learning in an in-person\nuser study with a 7DoF robot manipulator.\n", "versions": [{"version": "v1", "created": "Thu, 11 Oct 2018 17:58:27 GMT"}, {"version": "v2", "created": "Fri, 19 Oct 2018 00:47:32 GMT"}, {"version": "v3", "created": "Thu, 25 Oct 2018 07:09:31 GMT"}, {"version": "v4", "created": "Fri, 26 Oct 2018 05:21:19 GMT"}], "update_date": "2018-10-29", "authors_parsed": [["Bobu", "Andreea", ""], ["Bajcsy", "Andrea", ""], ["Fisac", "Jaime F.", ""], ["Dragan", "Anca D.", ""]]}, {"id": "1810.05162", "submitter": "Ruizhi Deng", "authors": "Chaowei Xiao, Ruizhi Deng, Bo Li, Fisher Yu, Mingyan Liu, and Dawn\n  Song", "title": "Characterizing Adversarial Examples Based on Spatial Consistency\n  Information for Semantic Segmentation", "comments": "Accepted to ECCV 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep Neural Networks (DNNs) have been widely applied in various recognition\ntasks. However, recently DNNs have been shown to be vulnerable against\nadversarial examples, which can mislead DNNs to make arbitrary incorrect\npredictions. While adversarial examples are well studied in classification\ntasks, other learning problems may have different properties. For instance,\nsemantic segmentation requires additional components such as dilated\nconvolutions and multiscale processing. In this paper, we aim to characterize\nadversarial examples based on spatial context information in semantic\nsegmentation. We observe that spatial consistency information can be\npotentially leveraged to detect adversarial examples robustly even when a\nstrong adaptive attacker has access to the model and detection strategies. We\nalso show that adversarial examples based on attacks considered within the\npaper barely transfer among models, even though transferability is common in\nclassification. Our observations shed new light on developing adversarial\nattacks and defenses to better understand the vulnerabilities of DNNs.\n", "versions": [{"version": "v1", "created": "Thu, 11 Oct 2018 17:03:44 GMT"}], "update_date": "2018-10-15", "authors_parsed": [["Xiao", "Chaowei", ""], ["Deng", "Ruizhi", ""], ["Li", "Bo", ""], ["Yu", "Fisher", ""], ["Liu", "Mingyan", ""], ["Song", "Dawn", ""]]}, {"id": "1810.05186", "submitter": "Fanhua Shang", "authors": "Fanhua Shang, James Cheng, Yuanyuan Liu, Zhi-Quan Luo, Zhouchen Lin", "title": "Bilinear Factor Matrix Norm Minimization for Robust PCA: Algorithms and\n  Applications", "comments": "29 pages, 19 figures", "journal-ref": "IEEE Transactions on Pattern Analysis and Machine Intelligence,\n  40(9): 2066-2080, 2018", "doi": null, "report-no": null, "categories": "cs.LG cs.CV math.OC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The heavy-tailed distributions of corrupted outliers and singular values of\nall channels in low-level vision have proven effective priors for many\napplications such as background modeling, photometric stereo and image\nalignment. And they can be well modeled by a hyper-Laplacian. However, the use\nof such distributions generally leads to challenging non-convex, non-smooth and\nnon-Lipschitz problems, and makes existing algorithms very slow for large-scale\napplications. Together with the analytic solutions to lp-norm minimization with\ntwo specific values of p, i.e., p=1/2 and p=2/3, we propose two novel bilinear\nfactor matrix norm minimization models for robust principal component analysis.\nWe first define the double nuclear norm and Frobenius/nuclear hybrid norm\npenalties, and then prove that they are in essence the Schatten-1/2 and 2/3\nquasi-norms, respectively, which lead to much more tractable and scalable\nLipschitz optimization problems. Our experimental analysis shows that both our\nmethods yield more accurate solutions than original Schatten quasi-norm\nminimization, even when the number of observations is very limited. Finally, we\napply our penalties to various low-level vision problems, e.g., text removal,\nmoving object detection, image alignment and inpainting, and show that our\nmethods usually outperform the state-of-the-art methods.\n", "versions": [{"version": "v1", "created": "Thu, 11 Oct 2018 18:06:27 GMT"}], "update_date": "2018-10-15", "authors_parsed": [["Shang", "Fanhua", ""], ["Cheng", "James", ""], ["Liu", "Yuanyuan", ""], ["Luo", "Zhi-Quan", ""], ["Lin", "Zhouchen", ""]]}, {"id": "1810.05187", "submitter": "Faiz Ali Shah", "authors": "Faiz Ali Shah, Kairit Sirts, Dietmar Pfahl", "title": "The Impact of Annotation Guidelines and Annotated Data on Extracting App\n  Features from App Reviews", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Annotation guidelines used to guide the annotation of training and evaluation\ndatasets can have a considerable impact on the quality of machine learning\nmodels. In this study, we explore the effects of annotation guidelines on the\nquality of app feature extraction models. As a main result, we propose several\nchanges to the existing annotation guidelines with a goal of making the\nextracted app features more useful and informative to the app developers. We\ntest the proposed changes via simulating the application of the new annotation\nguidelines and then evaluating the performance of the supervised machine\nlearning models trained on datasets annotated with initial and simulated\nguidelines. While the overall performance of automatic app feature extraction\nremains the same as compared to the model trained on the dataset with initial\nannotations, the features extracted by the model trained on the dataset with\nsimulated new annotations are less noisy and more informative to the app\ndevelopers. Secondly, we are interested in what kind of annotated training data\nis necessary for training an automatic app feature extraction model. In\nparticular, we explore whether the training set should contain annotated app\nreviews from those apps/app categories on which the model is subsequently\nplanned to be applied, or is it sufficient to have annotated app reviews from\nany app available for training, even when these apps are from very different\ncategories compared to the test app. Our experiments show that having annotated\ntraining reviews from the test app is not necessary although including them\ninto training set helps to improve recall. Furthermore, we test whether\naugmenting the training set with annotated product reviews helps to improve the\nperformance of app feature extraction. We find that the models trained on\naugmented training set lead to improved recall but at the cost of the drop in\nprecision.\n", "versions": [{"version": "v1", "created": "Thu, 11 Oct 2018 18:07:14 GMT"}], "update_date": "2018-10-15", "authors_parsed": [["Shah", "Faiz Ali", ""], ["Sirts", "Kairit", ""], ["Pfahl", "Dietmar", ""]]}, {"id": "1810.05188", "submitter": "Young Hun Jung", "authors": "Young Hun Jung, Ambuj Tewari", "title": "Fighting Contextual Bandits with Stochastic Smoothing", "comments": "merged to a manuscript \"Online Learning via the Differential Privacy\n  Lens,\" which can be found here: arXiv:1711.10019", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce a new stochastic smoothing perspective to study adversarial\ncontextual bandit problems. We propose a general algorithm template that\nrepresents random perturbation based algorithms and identify several\nperturbation distributions that lead to strong regret bounds. Using the idea of\nsmoothness, we provide an $O(\\sqrt{T})$ zero-order bound for the vanilla\nalgorithm and an $O(L^{*2/3}_{T})$ first-order bound for the clipped version.\nThese bounds hold when the algorithms use with a variety of distributions that\nhave a bounded hazard rate. Our algorithm template includes EXP4 as a special\ncase corresponding to the Gumbel perturbation. Our regret bounds match existing\nresults for EXP4 without relying on the specific properties of the algorithm.\n", "versions": [{"version": "v1", "created": "Thu, 11 Oct 2018 18:07:43 GMT"}, {"version": "v2", "created": "Tue, 11 Jun 2019 00:52:25 GMT"}], "update_date": "2019-06-12", "authors_parsed": [["Jung", "Young Hun", ""], ["Tewari", "Ambuj", ""]]}, {"id": "1810.05193", "submitter": "Mariia Vladimirova", "authors": "Mariia Vladimirova, Jakob Verbeek, Pablo Mesejo and Julyan Arbel", "title": "Understanding Priors in Bayesian Neural Networks at the Unit Level", "comments": "10 pages, 5 figures, ICML'19 conference", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We investigate deep Bayesian neural networks with Gaussian weight priors and\na class of ReLU-like nonlinearities. Bayesian neural networks with Gaussian\npriors are well known to induce an L2, \"weight decay\", regularization. Our\nresults characterize a more intricate regularization effect at the level of the\nunit activations. Our main result establishes that the induced prior\ndistribution on the units before and after activation becomes increasingly\nheavy-tailed with the depth of the layer. We show that first layer units are\nGaussian, second layer units are sub-exponential, and units in deeper layers\nare characterized by sub-Weibull distributions. Our results provide new\ntheoretical insight on deep Bayesian neural networks, which we corroborate with\nsimulation experiments.\n", "versions": [{"version": "v1", "created": "Thu, 11 Oct 2018 18:26:50 GMT"}, {"version": "v2", "created": "Fri, 10 May 2019 15:23:50 GMT"}], "update_date": "2019-05-13", "authors_parsed": [["Vladimirova", "Mariia", ""], ["Verbeek", "Jakob", ""], ["Mesejo", "Pablo", ""], ["Arbel", "Julyan", ""]]}, {"id": "1810.05206", "submitter": "Dawei Yang", "authors": "Chaowei Xiao, Dawei Yang, Bo Li, Jia Deng, Mingyan Liu", "title": "MeshAdv: Adversarial Meshes for Visual Recognition", "comments": "Published in IEEE CVPR2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.CV cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Highly expressive models such as deep neural networks (DNNs) have been widely\napplied to various applications. However, recent studies show that DNNs are\nvulnerable to adversarial examples, which are carefully crafted inputs aiming\nto mislead the predictions. Currently, the majority of these studies have\nfocused on perturbation added to image pixels, while such manipulation is not\nphysically realistic. Some works have tried to overcome this limitation by\nattaching printable 2D patches or painting patterns onto surfaces, but can be\npotentially defended because 3D shape features are intact. In this paper, we\npropose meshAdv to generate \"adversarial 3D meshes\" from objects that have rich\nshape features but minimal textural variation. To manipulate the shape or\ntexture of the objects, we make use of a differentiable renderer to compute\naccurate shading on the shape and propagate the gradient. Extensive experiments\nshow that the generated 3D meshes are effective in attacking both classifiers\nand object detectors. We evaluate the attack under different viewpoints. In\naddition, we design a pipeline to perform black-box attack on a photorealistic\nrenderer with unknown rendering parameters.\n", "versions": [{"version": "v1", "created": "Thu, 11 Oct 2018 19:01:10 GMT"}, {"version": "v2", "created": "Sat, 29 Jun 2019 19:43:54 GMT"}], "update_date": "2019-07-02", "authors_parsed": [["Xiao", "Chaowei", ""], ["Yang", "Dawei", ""], ["Li", "Bo", ""], ["Deng", "Jia", ""], ["Liu", "Mingyan", ""]]}, {"id": "1810.05207", "submitter": "Zoltan Szabo", "authors": "Zoltan Szabo and Bharath K. Sriperumbudur", "title": "On Kernel Derivative Approximation with Random Fourier Features", "comments": "AISTATS-2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG math.PR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Random Fourier features (RFF) represent one of the most popular and\nwide-spread techniques in machine learning to scale up kernel algorithms.\nDespite the numerous successful applications of RFFs, unfortunately, quite\nlittle is understood theoretically on their optimality and limitations of their\nperformance. Only recently, precise statistical-computational trade-offs have\nbeen established for RFFs in the approximation of kernel values, kernel ridge\nregression, kernel PCA and SVM classification. Our goal is to spark the\ninvestigation of optimality of RFF-based approximations in tasks involving not\nonly function values but derivatives, which naturally lead to optimization\nproblems with kernel derivatives. Particularly, in this paper, we focus on the\napproximation quality of RFFs for kernel derivatives and prove that the\nexisting finite-sample guarantees can be improved exponentially in terms of the\ndomain where they hold, using recent tools from unbounded empirical process\ntheory. Our result implies that the same approximation guarantee is attainable\nfor kernel derivatives using RFF as achieved for kernel values.\n", "versions": [{"version": "v1", "created": "Thu, 11 Oct 2018 19:03:11 GMT"}, {"version": "v2", "created": "Sun, 21 Oct 2018 13:55:57 GMT"}, {"version": "v3", "created": "Sat, 9 Feb 2019 20:37:55 GMT"}], "update_date": "2019-02-12", "authors_parsed": [["Szabo", "Zoltan", ""], ["Sriperumbudur", "Bharath K.", ""]]}, {"id": "1810.05221", "submitter": "Gilad Katz", "authors": "Yotam Intrator, Gilad Katz, Asaf Shabtai", "title": "MDGAN: Boosting Anomaly Detection Using \\\\Multi-Discriminator Generative\n  Adversarial Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Anomaly detection is often considered a challenging field of machine learning\ndue to the difficulty of obtaining anomalous samples for training and the need\nto obtain a sufficient amount of training data. In recent years, autoencoders\nhave been shown to be effective anomaly detectors that train only on \"normal\"\ndata. Generative adversarial networks (GANs) have been used to generate\nadditional training samples for classifiers, thus making them more accurate and\nrobust. However, in anomaly detection GANs are only used to reconstruct\nexisting samples rather than to generate additional ones. This stems both from\nthe small amount and lack of diversity of anomalous data in most domains. In\nthis study we propose MDGAN, a novel GAN architecture for improving anomaly\ndetection through the generation of additional samples. Our approach uses two\ndiscriminators: a dense network for determining whether the generated samples\nare of sufficient quality (i.e., valid) and an autoencoder that serves as an\nanomaly detector. MDGAN enables us to reconcile two conflicting goals: 1)\ngenerate high-quality samples that can fool the first discriminator, and 2)\ngenerate samples that can eventually be effectively reconstructed by the second\ndiscriminator, thus improving its performance. Empirical evaluation on a\ndiverse set of datasets demonstrates the merits of our approach.\n", "versions": [{"version": "v1", "created": "Thu, 11 Oct 2018 19:45:30 GMT"}], "update_date": "2018-10-15", "authors_parsed": [["Intrator", "Yotam", ""], ["Katz", "Gilad", ""], ["Shabtai", "Asaf", ""]]}, {"id": "1810.05222", "submitter": "Michael Kuchnik", "authors": "Michael Kuchnik, Virginia Smith", "title": "Efficient Augmentation via Data Subsampling", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Data augmentation is commonly used to encode invariances in learning methods.\nHowever, this process is often performed in an inefficient manner, as\nartificial examples are created by applying a number of transformations to all\npoints in the training set. The resulting explosion of the dataset size can be\nan issue in terms of storage and training costs, as well as in selecting and\ntuning the optimal set of transformations to apply. In this work, we\ndemonstrate that it is possible to significantly reduce the number of data\npoints included in data augmentation while realizing the same accuracy and\ninvariance benefits of augmenting the entire dataset. We propose a novel set of\nsubsampling policies, based on model influence and loss, that can achieve a 90%\nreduction in augmentation set size while maintaining the accuracy gains of\nstandard data augmentation.\n", "versions": [{"version": "v1", "created": "Thu, 11 Oct 2018 19:50:08 GMT"}, {"version": "v2", "created": "Fri, 1 Mar 2019 13:23:42 GMT"}], "update_date": "2019-03-04", "authors_parsed": [["Kuchnik", "Michael", ""], ["Smith", "Virginia", ""]]}, {"id": "1810.05236", "submitter": "Luigi Nardi", "authors": "Luigi Nardi and David Koeplinger and Kunle Olukotun", "title": "Practical Design Space Exploration", "comments": "12 pages, MASCOTS 2019 conference\n  (https://sites.google.com/view/mascots-2019)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG math.OC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Multi-objective optimization is a crucial matter in computer systems design\nspace exploration because real-world applications often rely on a trade-off\nbetween several objectives. Derivatives are usually not available or\nimpractical to compute and the feasibility of an experiment can not always be\ndetermined in advance. These problems are particularly difficult when the\nfeasible region is relatively small, and it may be prohibitive to even find a\nfeasible experiment, let alone an optimal one.\n  We introduce a new methodology and corresponding software framework,\nHyperMapper 2.0, which handles multi-objective optimization, unknown\nfeasibility constraints, and categorical/ordinal variables. This new\nmethodology also supports injection of the user prior knowledge in the search\nwhen available. All of these features are common requirements in computer\nsystems but rarely exposed in existing design space exploration systems. The\nproposed methodology follows a white-box model which is simple to understand\nand interpret (unlike, for example, neural networks) and can be used by the\nuser to better understand the results of the automatic search.\n  We apply and evaluate the new methodology to the automatic static tuning of\nhardware accelerators within the recently introduced Spatial programming\nlanguage, with minimization of design run-time and compute logic under the\nconstraint of the design fitting in a target field-programmable gate array\nchip. Our results show that HyperMapper 2.0 provides better Pareto fronts\ncompared to state-of-the-art baselines, with better or competitive hypervolume\nindicator and with 8x improvement in sampling budget for most of the benchmarks\nexplored.\n", "versions": [{"version": "v1", "created": "Thu, 11 Oct 2018 20:23:57 GMT"}, {"version": "v2", "created": "Wed, 29 May 2019 21:17:47 GMT"}, {"version": "v3", "created": "Wed, 24 Jul 2019 22:33:56 GMT"}], "update_date": "2019-07-26", "authors_parsed": [["Nardi", "Luigi", ""], ["Koeplinger", "David", ""], ["Olukotun", "Kunle", ""]]}, {"id": "1810.05241", "submitter": "Eric Yuan", "authors": "Xingdi Yuan, Tong Wang, Rui Meng, Khushboo Thaker, Peter Brusilovsky,\n  Daqing He, Adam Trischler", "title": "One Size Does Not Fit All: Generating and Evaluating Variable Number of\n  Keyphrases", "comments": "ACL 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Different texts shall by nature correspond to different number of keyphrases.\nThis desideratum is largely missing from existing neural keyphrase generation\nmodels. In this study, we address this problem from both modeling and\nevaluation perspectives.\n  We first propose a recurrent generative model that generates multiple\nkeyphrases as delimiter-separated sequences. Generation diversity is further\nenhanced with two novel techniques by manipulating decoder hidden states. In\ncontrast to previous approaches, our model is capable of generating diverse\nkeyphrases and controlling number of outputs.\n  We further propose two evaluation metrics tailored towards the\nvariable-number generation. We also introduce a new dataset StackEx that\nexpands beyond the only existing genre (i.e., academic writing) in keyphrase\ngeneration tasks. With both previous and new evaluation metrics, our model\noutperforms strong baselines on all datasets.\n", "versions": [{"version": "v1", "created": "Thu, 11 Oct 2018 20:40:15 GMT"}, {"version": "v2", "created": "Tue, 10 Sep 2019 13:57:57 GMT"}, {"version": "v3", "created": "Fri, 17 Apr 2020 05:43:27 GMT"}, {"version": "v4", "created": "Tue, 12 May 2020 16:44:21 GMT"}], "update_date": "2020-05-13", "authors_parsed": [["Yuan", "Xingdi", ""], ["Wang", "Tong", ""], ["Meng", "Rui", ""], ["Thaker", "Khushboo", ""], ["Brusilovsky", "Peter", ""], ["He", "Daqing", ""], ["Trischler", "Adam", ""]]}, {"id": "1810.05246", "submitter": "Chris Donahue", "authors": "Chris Donahue, Ian Simon, Sander Dieleman", "title": "Piano Genie", "comments": "Published as a conference paper at ACM IUI 2019", "journal-ref": null, "doi": "10.1145/3301275.3302288", "report-no": null, "categories": "cs.LG cs.HC cs.SD eess.AS stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present Piano Genie, an intelligent controller which allows non-musicians\nto improvise on the piano. With Piano Genie, a user performs on a simple\ninterface with eight buttons, and their performance is decoded into the space\nof plausible piano music in real time. To learn a suitable mapping procedure\nfor this problem, we train recurrent neural network autoencoders with discrete\nbottlenecks: an encoder learns an appropriate sequence of buttons corresponding\nto a piano piece, and a decoder learns to map this sequence back to the\noriginal piece. During performance, we substitute a user's input for the\nencoder output, and play the decoder's prediction each time the user presses a\nbutton. To improve the intuitiveness of Piano Genie's performance behavior, we\nimpose musically meaningful constraints over the encoder's outputs.\n", "versions": [{"version": "v1", "created": "Thu, 11 Oct 2018 21:00:44 GMT"}, {"version": "v2", "created": "Fri, 22 Mar 2019 08:53:31 GMT"}], "update_date": "2019-03-25", "authors_parsed": [["Donahue", "Chris", ""], ["Simon", "Ian", ""], ["Dieleman", "Sander", ""]]}, {"id": "1810.05247", "submitter": "Deepjyoti Deka", "authors": "Wenting Li, Deepjyoti Deka, Michael Chertkov, Meng Wang", "title": "Real-time Faulted Line Localization and PMU Placement in Power Systems\n  through Convolutional Neural Networks", "comments": "11 pages, 8 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SY cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Diverse fault types, fast re-closures, and complicated transient states after\na fault event make real-time fault location in power grids challenging.\nExisting localization techniques in this area rely on simplistic assumptions,\nsuch as static loads, or require much higher sampling rates or total\nmeasurement availability. This paper proposes a faulted line localization\nmethod based on a Convolutional Neural Network (CNN) classifier using bus\nvoltages. Unlike prior data-driven methods, the proposed classifier is based on\nfeatures with physical interpretations that improve the robustness of the\nlocation performance. The accuracy of our CNN based localization tool is\ndemonstrably superior to other machine learning classifiers in the literature.\nTo further improve the location performance, a joint phasor measurement units\n(PMU) placement strategy is proposed and validated against other methods. A\nsignificant aspect of our methodology is that under very low observability (7%\nof buses), the algorithm is still able to localize the faulted line to a small\nneighborhood with high probability. The performance of our scheme is validated\nthrough simulations of faults of various types in the IEEE 39-bus and 68-bus\npower systems under varying uncertain conditions, system observability, and\nmeasurement quality.\n", "versions": [{"version": "v1", "created": "Thu, 11 Oct 2018 21:06:33 GMT"}, {"version": "v2", "created": "Fri, 17 May 2019 01:55:50 GMT"}], "update_date": "2019-05-20", "authors_parsed": [["Li", "Wenting", ""], ["Deka", "Deepjyoti", ""], ["Chertkov", "Michael", ""], ["Wang", "Meng", ""]]}, {"id": "1810.05270", "submitter": "Zhuang Liu", "authors": "Zhuang Liu, Mingjie Sun, Tinghui Zhou, Gao Huang, Trevor Darrell", "title": "Rethinking the Value of Network Pruning", "comments": "ICLR 2019. Significant revisions from the previous version", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Network pruning is widely used for reducing the heavy inference cost of deep\nmodels in low-resource settings. A typical pruning algorithm is a three-stage\npipeline, i.e., training (a large model), pruning and fine-tuning. During\npruning, according to a certain criterion, redundant weights are pruned and\nimportant weights are kept to best preserve the accuracy. In this work, we make\nseveral surprising observations which contradict common beliefs. For all\nstate-of-the-art structured pruning algorithms we examined, fine-tuning a\npruned model only gives comparable or worse performance than training that\nmodel with randomly initialized weights. For pruning algorithms which assume a\npredefined target network architecture, one can get rid of the full pipeline\nand directly train the target network from scratch. Our observations are\nconsistent for multiple network architectures, datasets, and tasks, which imply\nthat: 1) training a large, over-parameterized model is often not necessary to\nobtain an efficient final model, 2) learned \"important\" weights of the large\nmodel are typically not useful for the small pruned model, 3) the pruned\narchitecture itself, rather than a set of inherited \"important\" weights, is\nmore crucial to the efficiency in the final model, which suggests that in some\ncases pruning can be useful as an architecture search paradigm. Our results\nsuggest the need for more careful baseline evaluations in future research on\nstructured pruning methods. We also compare with the \"Lottery Ticket\nHypothesis\" (Frankle & Carbin 2019), and find that with optimal learning rate,\nthe \"winning ticket\" initialization as used in Frankle & Carbin (2019) does not\nbring improvement over random initialization.\n", "versions": [{"version": "v1", "created": "Thu, 11 Oct 2018 22:15:28 GMT"}, {"version": "v2", "created": "Tue, 5 Mar 2019 05:58:11 GMT"}], "update_date": "2019-03-06", "authors_parsed": [["Liu", "Zhuang", ""], ["Sun", "Mingjie", ""], ["Zhou", "Tinghui", ""], ["Huang", "Gao", ""], ["Darrell", "Trevor", ""]]}, {"id": "1810.05290", "submitter": "Young Hun Jung", "authors": "Daniel T. Zhang, Young Hun Jung, Ambuj Tewari", "title": "Online Multiclass Boosting with Bandit Feedback", "comments": "Accepted in AISTATS 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present online boosting algorithms for multiclass classification with\nbandit feedback, where the learner only receives feedback about the correctness\nof its prediction. We propose an unbiased estimate of the loss using a\nrandomized prediction, allowing the model to update its weak learners with\nlimited information. Using the unbiased estimate, we extend two full\ninformation boosting algorithms (Jung et al., 2017) to the bandit setting. We\nprove that the asymptotic error bounds of the bandit algorithms exactly match\ntheir full information counterparts. The cost of restricted feedback is\nreflected in the larger sample complexity. Experimental results also support\nour theoretical findings, and performance of the proposed models is comparable\nto that of an existing bandit boosting algorithm, which is limited to use\nbinary weak learners.\n", "versions": [{"version": "v1", "created": "Thu, 11 Oct 2018 23:47:21 GMT"}, {"version": "v2", "created": "Mon, 25 Feb 2019 05:28:45 GMT"}], "update_date": "2019-02-26", "authors_parsed": [["Zhang", "Daniel T.", ""], ["Jung", "Young Hun", ""], ["Tewari", "Ambuj", ""]]}, {"id": "1810.05291", "submitter": "Jeremy Bernstein", "authors": "Jeremy Bernstein, Jiawei Zhao, Kamyar Azizzadenesheli, Anima\n  Anandkumar", "title": "signSGD with Majority Vote is Communication Efficient And Fault Tolerant", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Training neural networks on large datasets can be accelerated by distributing\nthe workload over a network of machines. As datasets grow ever larger, networks\nof hundreds or thousands of machines become economically viable. The time cost\nof communicating gradients limits the effectiveness of using such large machine\ncounts, as may the increased chance of network faults. We explore a\nparticularly simple algorithm for robust, communication-efficient\nlearning---signSGD. Workers transmit only the sign of their gradient vector to\na server, and the overall update is decided by a majority vote. This algorithm\nuses $32\\times$ less communication per iteration than full-precision,\ndistributed SGD. Under natural conditions verified by experiment, we prove that\nsignSGD converges in the large and mini-batch settings, establishing\nconvergence for a parameter regime of Adam as a byproduct. Aggregating sign\ngradients by majority vote means that no individual worker has too much power.\nWe prove that unlike SGD, majority vote is robust when up to 50% of workers\nbehave adversarially. The class of adversaries we consider includes as special\ncases those that invert or randomise their gradient estimate. On the practical\nside, we built our distributed training system in Pytorch. Benchmarking against\nthe state of the art collective communications library (NCCL), our\nframework---with the parameter server housed entirely on one machine---led to a\n25% reduction in time for training resnet50 on Imagenet when using 15 AWS\np3.2xlarge machines.\n", "versions": [{"version": "v1", "created": "Thu, 11 Oct 2018 23:50:32 GMT"}, {"version": "v2", "created": "Fri, 19 Oct 2018 02:53:43 GMT"}, {"version": "v3", "created": "Fri, 22 Feb 2019 19:55:48 GMT"}], "update_date": "2019-02-26", "authors_parsed": [["Bernstein", "Jeremy", ""], ["Zhao", "Jiawei", ""], ["Azizzadenesheli", "Kamyar", ""], ["Anandkumar", "Anima", ""]]}, {"id": "1810.05305", "submitter": "Hunter Lang", "authors": "Hunter Lang, David Sontag, Aravindan Vijayaraghavan", "title": "Block Stability for MAP Inference", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  To understand the empirical success of approximate MAP inference, recent work\n(Lang et al., 2018) has shown that some popular approximation algorithms\nperform very well when the input instance is stable. The simplest stability\ncondition assumes that the MAP solution does not change at all when some of the\npairwise potentials are (adversarially) perturbed. Unfortunately, this strong\ncondition does not seem to be satisfied in practice. In this paper, we\nintroduce a significantly more relaxed condition that only requires blocks\n(portions) of an input instance to be stable. Under this block stability\ncondition, we prove that the pairwise LP relaxation is persistent on the stable\nblocks. We complement our theoretical results with an empirical evaluation of\nreal-world MAP inference instances from computer vision. We design an algorithm\nto find stable blocks, and find that these real instances have large stable\nregions. Our work gives a theoretical explanation for the widespread empirical\nphenomenon of persistency for this LP relaxation.\n", "versions": [{"version": "v1", "created": "Fri, 12 Oct 2018 01:17:38 GMT"}, {"version": "v2", "created": "Fri, 13 Nov 2020 00:52:41 GMT"}], "update_date": "2020-11-16", "authors_parsed": [["Lang", "Hunter", ""], ["Sontag", "David", ""], ["Vijayaraghavan", "Aravindan", ""]]}, {"id": "1810.05347", "submitter": "Xiao Li", "authors": "Xiao Li, Hanchen Xu, Jinming Zhang, Hua-hua Chang", "title": "Optimal Hierarchical Learning Path Design with Reinforcement Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CY stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  E-learning systems are capable of providing more adaptive and efficient\nlearning experiences for students than the traditional classroom setting. A key\ncomponent of such systems is the learning strategy, the algorithm that designs\nthe learning paths for students based on information such as the students'\ncurrent progresses, their skills, learning materials, and etc. In this paper,\nwe address the problem of finding the optimal learning strategy for an\nE-learning system. To this end, we first develop a model for students'\nhierarchical skills in the E-learning system. Based on the hierarchical skill\nmodel and the classical cognitive diagnosis model, we further develop a\nframework to model various proficiency levels of hierarchical skills. The\noptimal learning strategy on top of the hierarchical structure is found by\napplying a model-free reinforcement learning method, which does not require\ninformation on students' learning transition process. The effectiveness of the\nproposed framework is demonstrated via numerical experiments.\n", "versions": [{"version": "v1", "created": "Fri, 12 Oct 2018 04:03:20 GMT"}], "update_date": "2018-10-15", "authors_parsed": [["Li", "Xiao", ""], ["Xu", "Hanchen", ""], ["Zhang", "Jinming", ""], ["Chang", "Hua-hua", ""]]}, {"id": "1810.05369", "submitter": "Colin Wei", "authors": "Colin Wei, Jason D. Lee, Qiang Liu, Tengyu Ma", "title": "Regularization Matters: Generalization and Optimization of Neural Nets\n  v.s. their Induced Kernel", "comments": "version 2: title changed from originally \"On the Margin Theory of\n  Feedforward Neural Networks\". Substantial changes from old version of paper,\n  including a new lower bound on NTK sample complexity version 3: reorganized\n  NTK lower bound proof version 4: reorganized proof of optimization result", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent works have shown that on sufficiently over-parametrized neural nets,\ngradient descent with relatively large initialization optimizes a prediction\nfunction in the RKHS of the Neural Tangent Kernel (NTK). This analysis leads to\nglobal convergence results but does not work when there is a standard $\\ell_2$\nregularizer, which is useful to have in practice. We show that sample\nefficiency can indeed depend on the presence of the regularizer: we construct a\nsimple distribution in d dimensions which the optimal regularized neural net\nlearns with $O(d)$ samples but the NTK requires $\\Omega(d^2)$ samples to learn.\nTo prove this, we establish two analysis tools: i) for multi-layer feedforward\nReLU nets, we show that the global minimizer of a weakly-regularized\ncross-entropy loss is the max normalized margin solution among all neural nets,\nwhich generalizes well; ii) we develop a new technique for proving lower bounds\nfor kernel methods, which relies on showing that the kernel cannot focus on\ninformative features. Motivated by our generalization results, we study whether\nthe regularized global optimum is attainable. We prove that for infinite-width\ntwo-layer nets, noisy gradient descent optimizes the regularized neural net\nloss to a global minimum in polynomial iterations.\n", "versions": [{"version": "v1", "created": "Fri, 12 Oct 2018 06:21:22 GMT"}, {"version": "v2", "created": "Thu, 30 May 2019 09:04:32 GMT"}, {"version": "v3", "created": "Mon, 15 Jul 2019 06:33:39 GMT"}, {"version": "v4", "created": "Sat, 25 Apr 2020 06:17:48 GMT"}], "update_date": "2020-04-28", "authors_parsed": [["Wei", "Colin", ""], ["Lee", "Jason D.", ""], ["Liu", "Qiang", ""], ["Ma", "Tengyu", ""]]}, {"id": "1810.05394", "submitter": "Meenakshi Sarkar", "authors": "Meenakshi Sarkar, Debasish Ghose", "title": "Sequential Learning of Movement Prediction in Dynamic Environments using\n  LSTM Autoencoder", "comments": "4 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV cs.RO stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Predicting movement of objects while the action of learning agent interacts\nwith the dynamics of the scene still remains a key challenge in robotics. We\npropose a multi-layer Long Short Term Memory (LSTM) autoendocer network that\npredicts future frames for a robot navigating in a dynamic environment with\nmoving obstacles. The autoencoder network is composed of a state and action\nconditioned decoder network that reconstructs the future frames of video,\nconditioned on the action taken by the agent. The input image frames are first\ntransformed into low dimensional feature vectors with a pre-trained encoder\nnetwork and then reconstructed with the LSTM autoencoder network to generate\nthe future frames. A virtual environment, based on the OpenAi-Gym framework for\nrobotics, is used to gather training data and test the proposed network. The\ninitial experiments show promising results indicating that these predicted\nframes can be used by an appropriate reinforcement learning framework in future\nto navigate around dynamic obstacles.\n", "versions": [{"version": "v1", "created": "Fri, 12 Oct 2018 08:11:13 GMT"}], "update_date": "2018-10-15", "authors_parsed": [["Sarkar", "Meenakshi", ""], ["Ghose", "Debasish", ""]]}, {"id": "1810.05420", "submitter": "Florian Jug", "authors": "Tim-Oliver Buchholz, Mareike Jordan, Gaia Pigino, Florian Jug", "title": "Cryo-CARE: Content-Aware Image Restoration for Cryo-Transmission\n  Electron Microscopy Data", "comments": "This work has been submitted to the IEEE for possible publication.\n  Copyright may be transferred without notice, after which this version may no\n  longer be accessible. This version fixed flipped graph labels in Figure 5", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Multiple approaches to use deep learning for image restoration have recently\nbeen proposed. Training such approaches requires well registered pairs of high\nand low quality images. While this is easily achievable for many imaging\nmodalities, e.g. fluorescence light microscopy, for others it is not.\nCryo-transmission electron microscopy (cryo-TEM) could profoundly benefit from\nimproved denoising methods, unfortunately it is one of the latter. Here we show\nhow recent advances in network training for image restoration tasks, i.e.\ndenoising, can be applied to cryo-TEM data. We describe our proposed method and\nshow how it can be applied to single cryo-TEM projections and whole\ncryo-tomographic image volumes. Our proposed restoration method dramatically\nincreases contrast in cryo-TEM images, which improves the interpretability of\nthe acquired data. Furthermore we show that automated downstream processing on\nrestored image data, demonstrated on a dense segmentation task, leads to\nimproved results.\n", "versions": [{"version": "v1", "created": "Fri, 12 Oct 2018 09:15:06 GMT"}, {"version": "v2", "created": "Mon, 15 Oct 2018 18:49:50 GMT"}], "update_date": "2018-10-17", "authors_parsed": [["Buchholz", "Tim-Oliver", ""], ["Jordan", "Mareike", ""], ["Pigino", "Gaia", ""], ["Jug", "Florian", ""]]}, {"id": "1810.05436", "submitter": "Hosein Azarbonyad", "authors": "Hosein Azarbonyad, Mostafa Dehghani, Tom Kenter, Maarten Marx, Jaap\n  Kamps, and Maarten de Rijke", "title": "HiTR: Hierarchical Topic Model Re-estimation for Measuring Topical\n  Diversity of Documents", "comments": "IEEE Transactions on Knowledge and Data Engineering", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.IR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A high degree of topical diversity is often considered to be an important\ncharacteristic of interesting text documents. A recent proposal for measuring\ntopical diversity identifies three distributions for assessing the diversity of\ndocuments: distributions of words within documents, words within topics, and\ntopics within documents. Topic models play a central role in this approach and,\nhence, their quality is crucial to the efficacy of measuring topical diversity.\nThe quality of topic models is affected by two causes: generality and impurity\nof topics. General topics only include common information of a background\ncorpus and are assigned to most of the documents. Impure topics contain words\nthat are not related to the topic. Impurity lowers the interpretability of\ntopic models. Impure topics are likely to get assigned to documents\nerroneously. We propose a hierarchical re-estimation process aimed at removing\ngenerality and impurity. Our approach has three re-estimation components: (1)\ndocument re-estimation, which removes general words from the documents; (2)\ntopic re-estimation, which re-estimates the distribution over words of each\ntopic; and (3) topic assignment re-estimation, which re-estimates for each\ndocument its distributions over topics. For measuring topical diversity of text\ndocuments, our HiTR approach improves over the state-of-the-art measured on\nPubMed dataset.\n", "versions": [{"version": "v1", "created": "Fri, 12 Oct 2018 10:02:23 GMT"}], "update_date": "2018-10-15", "authors_parsed": [["Azarbonyad", "Hosein", ""], ["Dehghani", "Mostafa", ""], ["Kenter", "Tom", ""], ["Marx", "Maarten", ""], ["Kamps", "Jaap", ""], ["de Rijke", "Maarten", ""]]}, {"id": "1810.05440", "submitter": "Manolis Tsakiris", "authors": "Manolis C. Tsakiris, Liangzu Peng, Aldo Conca, Laurent Kneip, Yuanming\n  Shi, Hayoung Choi", "title": "An algebraic-geometric approach for linear regression without\n  correspondences", "comments": "13 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Linear regression without correspondences is the problem of performing a\nlinear regression fit to a dataset for which the correspondences between the\nindependent samples and the observations are unknown. Such a problem naturally\narises in diverse domains such as computer vision, data mining, communications\nand biology. In its simplest form, it is tantamount to solving a linear system\nof equations, for which the entries of the right hand side vector have been\npermuted. This type of data corruption renders the linear regression task\nconsiderably harder, even in the absence of other corruptions, such as noise,\noutliers or missing entries. Existing methods are either applicable only to\nnoiseless data or they are very sensitive to initialization or they work only\nfor partially shuffled data. In this paper we address these issues via an\nalgebraic geometric approach, which uses symmetric polynomials to extract\npermutation-invariant constraints that the parameters $\\xi^* \\in \\Re^n$ of the\nlinear regression model must satisfy. This naturally leads to a polynomial\nsystem of $n$ equations in $n$ unknowns, which contains $\\xi^*$ in its root\nlocus. Using the machinery of algebraic geometry we prove that as long as the\nindependent samples are generic, this polynomial system is always consistent\nwith at most $n!$ complex roots, regardless of any type of corruption inflicted\non the observations. The algorithmic implication of this fact is that one can\nalways solve this polynomial system and use its most suitable root as\ninitialization to the Expectation Maximization algorithm. To the best of our\nknowledge, the resulting method is the first working solution for small values\nof $n$ able to handle thousands of fully shuffled noisy observations in\nmilliseconds.\n", "versions": [{"version": "v1", "created": "Fri, 12 Oct 2018 10:22:05 GMT"}, {"version": "v2", "created": "Fri, 4 Oct 2019 12:16:11 GMT"}], "update_date": "2019-10-07", "authors_parsed": [["Tsakiris", "Manolis C.", ""], ["Peng", "Liangzu", ""], ["Conca", "Aldo", ""], ["Kneip", "Laurent", ""], ["Shi", "Yuanming", ""], ["Choi", "Hayoung", ""]]}, {"id": "1810.05444", "submitter": "Veronika Cheplygina", "authors": "Veronika Cheplygina", "title": "Cats or CAT scans: transfer learning from natural or medical image\n  source datasets?", "comments": "Accepted to Current Opinion in Biomedical Engineering", "journal-ref": null, "doi": "10.1016/j.cobme.2018.12.005", "report-no": null, "categories": "cs.CV cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Transfer learning is a widely used strategy in medical image analysis.\nInstead of only training a network with a limited amount of data from the\ntarget task of interest, we can first train the network with other, potentially\nlarger source datasets, creating a more robust model. The source datasets do\nnot have to be related to the target task. For a classification task in lung CT\nimages, we could use both head CT images, or images of cats, as the source.\nWhile head CT images appear more similar to lung CT images, the number and\ndiversity of cat images might lead to a better model overall. In this survey we\nreview a number of papers that have performed similar comparisons. Although the\nanswer to which strategy is best seems to be \"it depends\", we discuss a number\nof research directions we need to take as a community, to gain more\nunderstanding of this topic.\n", "versions": [{"version": "v1", "created": "Fri, 12 Oct 2018 10:35:21 GMT"}, {"version": "v2", "created": "Thu, 10 Jan 2019 08:45:08 GMT"}], "update_date": "2019-01-11", "authors_parsed": [["Cheplygina", "Veronika", ""]]}, {"id": "1810.05466", "submitter": "Lucas Deecke", "authors": "Lucas Deecke, Iain Murray, Hakan Bilen", "title": "Mode Normalization", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Normalization methods are a central building block in the deep learning\ntoolbox. They accelerate and stabilize training, while decreasing the\ndependence on manually tuned learning rate schedules. When learning from\nmulti-modal distributions, the effectiveness of batch normalization (BN),\narguably the most prominent normalization method, is reduced. As a remedy, we\npropose a more flexible approach: by extending the normalization to more than a\nsingle mean and variance, we detect modes of data on-the-fly, jointly\nnormalizing samples that share common features. We demonstrate that our method\noutperforms BN and other widely used normalization techniques in several\nexperiments, including single and multi-task datasets.\n", "versions": [{"version": "v1", "created": "Fri, 12 Oct 2018 12:10:10 GMT"}], "update_date": "2018-10-15", "authors_parsed": [["Deecke", "Lucas", ""], ["Murray", "Iain", ""], ["Bilen", "Hakan", ""]]}, {"id": "1810.05471", "submitter": "Eugene Ndiaye", "authors": "Eugene Ndiaye and Tam Le and Olivier Fercoq and Joseph Salmon and\n  Ichiro Takeuchi", "title": "Safe Grid Search with Optimal Complexity", "comments": null, "journal-ref": "International Conference on Machine Learning, 2019", "doi": null, "report-no": null, "categories": "stat.ML cs.LG math.OC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Popular machine learning estimators involve regularization parameters that\ncan be challenging to tune, and standard strategies rely on grid search for\nthis task. In this paper, we revisit the techniques of approximating the\nregularization path up to predefined tolerance $\\epsilon$ in a unified\nframework and show that its complexity is $O(1/\\sqrt[d]{\\epsilon})$ for\nuniformly convex loss of order $d \\geq 2$ and $O(1/\\sqrt{\\epsilon})$ for\nGeneralized Self-Concordant functions. This framework encompasses least-squares\nbut also logistic regression, a case that as far as we know was not handled as\nprecisely in previous works. We leverage our technique to provide refined\nbounds on the validation error as well as a practical algorithm for\nhyperparameter tuning. The latter has global convergence guarantee when\ntargeting a prescribed accuracy on the validation set. Last but not least, our\napproach helps relieving the practitioner from the (often neglected) task of\nselecting a stopping criterion when optimizing over the training set: our\nmethod automatically calibrates this criterion based on the targeted accuracy\non the validation set.\n", "versions": [{"version": "v1", "created": "Fri, 12 Oct 2018 12:16:52 GMT"}, {"version": "v2", "created": "Thu, 31 Jan 2019 11:17:35 GMT"}, {"version": "v3", "created": "Mon, 27 May 2019 04:49:13 GMT"}], "update_date": "2019-05-28", "authors_parsed": [["Ndiaye", "Eugene", ""], ["Le", "Tam", ""], ["Fercoq", "Olivier", ""], ["Salmon", "Joseph", ""], ["Takeuchi", "Ichiro", ""]]}, {"id": "1810.05497", "submitter": "Rebecca Steorts", "authors": "Rebecca C. Steorts and Anshumali Shrivastava", "title": "Probabilistic Blocking with An Application to the Syrian Conflict", "comments": "16 pages, 3 figures. arXiv admin note: substantial text overlap with\n  arXiv:1510.07714, arXiv:1710.02690", "journal-ref": "Steorts R.C., Shrivastava A. (2018) Probabilistic Blocking with an\n  Application to the Syrian Conflict. PSD (2018)", "doi": null, "report-no": null, "categories": "cs.DB cs.LG stat.AP stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Entity resolution seeks to merge databases as to remove duplicate entries\nwhere unique identifiers are typically unknown. We review modern blocking\napproaches for entity resolution, focusing on those based upon locality\nsensitive hashing (LSH). First, we introduce $k$-means locality sensitive\nhashing (KLSH), which is based upon the information retrieval literature and\nclusters similar records into blocks using a vector-space representation and\nprojections. Second, we introduce a subquadratic variant of LSH to the\nliterature, known as Densified One Permutation Hashing (DOPH). Third, we\npropose a weighted variant of DOPH. We illustrate each method on an application\nto a subset of the ongoing Syrian conflict, giving a discussion of each method.\n", "versions": [{"version": "v1", "created": "Thu, 11 Oct 2018 01:16:31 GMT"}], "update_date": "2018-10-15", "authors_parsed": [["Steorts", "Rebecca C.", ""], ["Shrivastava", "Anshumali", ""]]}, {"id": "1810.05500", "submitter": "Bastiaan Veeling", "authors": "Bastiaan S. Veeling, Rianne van den Berg, Max Welling", "title": "Predictive Uncertainty through Quantization", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  High-risk domains require reliable confidence estimates from predictive\nmodels. Deep latent variable models provide these, but suffer from the rigid\nvariational distributions used for tractable inference, which err on the side\nof overconfidence. We propose Stochastic Quantized Activation Distributions\n(SQUAD), which imposes a flexible yet tractable distribution over discretized\nlatent variables. The proposed method is scalable, self-normalizing and sample\nefficient. We demonstrate that the model fully utilizes the flexible\ndistribution, learns interesting non-linearities, and provides predictive\nuncertainty of competitive quality.\n", "versions": [{"version": "v1", "created": "Fri, 12 Oct 2018 13:37:43 GMT"}], "update_date": "2018-10-15", "authors_parsed": [["Veeling", "Bastiaan S.", ""], ["Berg", "Rianne van den", ""], ["Welling", "Max", ""]]}, {"id": "1810.05504", "submitter": "Parviz Asghari", "authors": "Parviz Asghari and Ehsan Nazerfard", "title": "Activity Recognition using Hierarchical Hidden Markov Models on\n  Streaming Sensor Data", "comments": null, "journal-ref": null, "doi": "10.1109/ISTEL.2018.8661053", "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Activity recognition from sensor data deals with various challenges, such as\noverlapping activities, activity labeling, and activity detection. Although\neach challenge in the field of recognition has great importance, the most\nimportant one refers to online activity recognition. The present study tries to\nuse online hierarchical hidden Markov model to detect an activity on the stream\nof sensor data which can predict the activity in the environment with any\nsensor event. The activity recognition samples were labeled by the statistical\nfeatures such as the duration of activity. The results of our proposed method\ntest on two different datasets of smart homes in the real world showed that one\ndataset has improved 4% and reached (59%) while the results reached 64.6% for\nthe other data by using the best methods.\n", "versions": [{"version": "v1", "created": "Thu, 4 Oct 2018 20:13:46 GMT"}], "update_date": "2019-03-13", "authors_parsed": [["Asghari", "Parviz", ""], ["Nazerfard", "Ehsan", ""]]}, {"id": "1810.05507", "submitter": "Zixing Zhang", "authors": "Zixing Zhang, Jing Han, Eduardo Coutinho, Bj\\\"orn Schuller", "title": "Dynamic Difficulty Awareness Training for Continuous Emotion Prediction", "comments": "accepted by IEEE T-MM", "journal-ref": null, "doi": "10.1109/TMM.2018.2871949", "report-no": null, "categories": "cs.LG cs.AI cs.HC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Time-continuous emotion prediction has become an increasingly compelling task\nin machine learning. Considerable efforts have been made to advance the\nperformance of these systems. Nonetheless, the main focus has been the\ndevelopment of more sophisticated models and the incorporation of different\nexpressive modalities (e. g., speech, face, and physiology). In this paper,\nmotivated by the benefit of difficulty awareness in a human learning procedure,\nwe propose a novel machine learning framework, namely, Dynamic Difficulty\nAwareness Training (DDAT), which sheds fresh light on the research -- directly\nexploiting the difficulties in learning to boost the machine learning process.\nThe DDAT framework consists of two stages: information retrieval and\ninformation exploitation. In the first stage, we make use of the reconstruction\nerror of input features or the annotation uncertainty to estimate the\ndifficulty of learning specific information. The obtained difficulty level is\nthen used in tandem with original features to update the model input in a\nsecond learning stage with the expectation that the model can learn to focus on\nhigh difficulty regions of the learning process. We perform extensive\nexperiments on a benchmark database (RECOLA) to evaluate the effectiveness of\nthe proposed framework. The experimental results show that our approach\noutperforms related baselines as well as other well-established time-continuous\nemotion prediction systems, which suggests that dynamically integrating the\ndifficulty information for neural networks can help enhance the learning\nprocess.\n", "versions": [{"version": "v1", "created": "Wed, 26 Sep 2018 07:30:52 GMT"}], "update_date": "2018-10-15", "authors_parsed": [["Zhang", "Zixing", ""], ["Han", "Jing", ""], ["Coutinho", "Eduardo", ""], ["Schuller", "Bj\u00f6rn", ""]]}, {"id": "1810.05512", "submitter": "David Leroy", "authors": "David Leroy, Alice Coucke, Thibaut Lavril, Thibault Gisselbrecht and\n  Joseph Dureau", "title": "Federated Learning for Keyword Spotting", "comments": "Accepted for publication to ICASSP 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.AS cs.CL cs.LG cs.SD stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a practical approach based on federated learning to solve\nout-of-domain issues with continuously running embedded speech-based models\nsuch as wake word detectors. We conduct an extensive empirical study of the\nfederated averaging algorithm for the \"Hey Snips\" wake word based on a\ncrowdsourced dataset that mimics a federation of wake word users. We\nempirically demonstrate that using an adaptive averaging strategy inspired from\nAdam in place of standard weighted model averaging highly reduces the number of\ncommunication rounds required to reach our target performance. The associated\nupstream communication costs per user are estimated at 8 MB, which is a\nreasonable in the context of smart home voice assistants. Additionally, the\ndataset used for these experiments is being open sourced with the aim of\nfostering further transparent research in the application of federated learning\nto speech data.\n", "versions": [{"version": "v1", "created": "Tue, 9 Oct 2018 09:41:15 GMT"}, {"version": "v2", "created": "Wed, 31 Oct 2018 10:07:18 GMT"}, {"version": "v3", "created": "Tue, 18 Dec 2018 09:31:52 GMT"}, {"version": "v4", "created": "Mon, 18 Feb 2019 18:41:00 GMT"}], "update_date": "2019-02-19", "authors_parsed": [["Leroy", "David", ""], ["Coucke", "Alice", ""], ["Lavril", "Thibaut", ""], ["Gisselbrecht", "Thibault", ""], ["Dureau", "Joseph", ""]]}, {"id": "1810.05524", "submitter": "Sara Hosseinzadeh Kassani", "authors": "Sara Hosseinzadeh Kassani, Peyman Hosseinzadeh Kassani, Seyed Esmaeel\n  Najafi", "title": "Introducing a hybrid model of DEA and data mining in evaluating\n  efficiency. Case study: Bank Branches", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The banking industry is very important for an economic cycle of each country\nand provides some quality of services for us. With the advancement in\ntechnology and rapidly increasing of the complexity of the business\nenvironment, it has become more competitive than the past so that efficiency\nanalysis in the banking industry attracts much attention in recent years. From\nmany aspects, such analyses at the branch level are more desirable. Evaluating\nthe branch performance with the purpose of eliminating deficiency can be a\ncrucial issue for branch managers to measure branch efficiency. This work not\nonly can lead to a better understanding of bank branch performance but also\ngive further information to enhance managerial decisions to recognize\nproblematic areas. To achieve this purpose, this study presents an integrated\napproach based on Data Envelopment Analysis (DEA), Clustering algorithms and\nPolynomial Pattern Classifier for constructing a classifier to identify a class\nof bank branches. First, the efficiency estimates of individual branches are\nevaluated by using the DEA approach. Next, when the range and number of classes\nwere identified by experts, the number of clusters is identified by an\nagglomerative hierarchical clustering algorithm based on some statistical\nmethods. Next, we divide our raw data into k clusters By means of\nself-organizing map (SOM) neural networks. Finally, all clusters are fed into\nthe reduced multivariate polynomial model to predict the classes of data.\n", "versions": [{"version": "v1", "created": "Wed, 10 Oct 2018 18:59:29 GMT"}], "update_date": "2018-10-15", "authors_parsed": [["Kassani", "Sara Hosseinzadeh", ""], ["Kassani", "Peyman Hosseinzadeh", ""], ["Najafi", "Seyed Esmaeel", ""]]}, {"id": "1810.05526", "submitter": "Bas van Stein", "authors": "Bas van Stein, Hao Wang, Thomas B\\\"ack", "title": "Automatic Configuration of Deep Neural Networks with EGO", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Designing the architecture for an artificial neural network is a cumbersome\ntask because of the numerous parameters to configure, including activation\nfunctions, layer types, and hyper-parameters. With the large number of\nparameters for most networks nowadays, it is intractable to find a good\nconfiguration for a given task by hand. In this paper an Efficient Global\nOptimization (EGO) algorithm is adapted to automatically optimize and configure\nconvolutional neural network architectures. A configurable neural network\narchitecture based solely on convolutional layers is proposed for the\noptimization. Without using any knowledge on the target problem and not using\nany data augmentation techniques, it is shown that on several image\nclassification tasks this approach is able to find competitive network\narchitectures in terms of prediction accuracy, compared to the best\nhand-crafted ones in literature. In addition, a very small training budget (200\nevaluations and 10 epochs in training) is spent on each optimized architectures\nin contrast to the usual long training time of hand-crafted networks. Moreover,\ninstead of the standard sequential evaluation in EGO, several candidate\narchitectures are proposed and evaluated in parallel, which saves the execution\noverheads significantly and leads to an efficient automation for deep neural\nnetwork design.\n", "versions": [{"version": "v1", "created": "Wed, 10 Oct 2018 09:06:15 GMT"}], "update_date": "2018-10-15", "authors_parsed": [["van Stein", "Bas", ""], ["Wang", "Hao", ""], ["B\u00e4ck", "Thomas", ""]]}, {"id": "1810.05533", "submitter": "Navneet Kumar", "authors": "Navneet Madhu Kumar", "title": "Empowerment-driven Exploration using Mutual Information Estimation", "comments": "Preprint. Under Development. arXiv admin note: text overlap with\n  arXiv:1807.02078 by other authors", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Exploration is a difficult challenge in reinforcement learning and is of\nprime importance in sparse reward environments. However, many of the state of\nthe art deep reinforcement learning algorithms, that rely on epsilon-greedy,\nfail on these environments. In such cases, empowerment can serve as an\nintrinsic reward signal to enable the agent to maximize the influence it has\nover the near future. We formulate empowerment as the channel capacity between\nstates and actions and is calculated by estimating the mutual information\nbetween the actions and the following states. The mutual information is\nestimated using Mutual Information Neural Estimator and a forward dynamics\nmodel. We demonstrate that an empowerment driven agent is able to improve\nsignificantly the score of a baseline DQN agent on the game of Montezuma's\nRevenge.\n", "versions": [{"version": "v1", "created": "Thu, 11 Oct 2018 06:34:18 GMT"}], "update_date": "2018-10-15", "authors_parsed": [["Kumar", "Navneet Madhu", ""]]}, {"id": "1810.05546", "submitter": "Tim Pearce", "authors": "Tim Pearce, Felix Leibfried, Alexandra Brintrup, Mohamed Zaki, Andy\n  Neely", "title": "Uncertainty in Neural Networks: Approximately Bayesian Ensembling", "comments": "Please cite as published in AISTATS 2020", "journal-ref": "The 23rd International Conference on Artificial Intelligence and\n  Statistics, AISTATS 2020", "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Understanding the uncertainty of a neural network's (NN) predictions is\nessential for many purposes. The Bayesian framework provides a principled\napproach to this, however applying it to NNs is challenging due to large\nnumbers of parameters and data. Ensembling NNs provides an easily\nimplementable, scalable method for uncertainty quantification, however, it has\nbeen criticised for not being Bayesian. This work proposes one modification to\nthe usual process that we argue does result in approximate Bayesian inference;\nregularising parameters about values drawn from a distribution which can be set\nequal to the prior. A theoretical analysis of the procedure in a simplified\nsetting suggests the recovered posterior is centred correctly but tends to have\nan underestimated marginal variance, and overestimated correlation. However,\ntwo conditions can lead to exact recovery. We argue that these conditions are\npartially present in NNs. Empirical evaluations demonstrate it has an advantage\nover standard ensembling, and is competitive with variational methods.\n", "versions": [{"version": "v1", "created": "Fri, 12 Oct 2018 14:26:34 GMT"}, {"version": "v2", "created": "Mon, 22 Oct 2018 11:07:20 GMT"}, {"version": "v3", "created": "Sun, 27 Jan 2019 13:22:11 GMT"}, {"version": "v4", "created": "Mon, 14 Oct 2019 16:14:46 GMT"}, {"version": "v5", "created": "Wed, 26 Feb 2020 12:21:59 GMT"}], "update_date": "2020-02-27", "authors_parsed": [["Pearce", "Tim", ""], ["Leibfried", "Felix", ""], ["Brintrup", "Alexandra", ""], ["Zaki", "Mohamed", ""], ["Neely", "Andy", ""]]}, {"id": "1810.05547", "submitter": "Mohammad Amin Nabian", "authors": "Mohammad Amin Nabian, Hadi Meidani", "title": "Physics-Driven Regularization of Deep Neural Networks for Enhanced\n  Engineering Design and Analysis", "comments": null, "journal-ref": "Journal of Computing and Information Science in Engineering, 20(1)\n  (2020)", "doi": "10.1115/1.4044507", "report-no": null, "categories": "cs.LG cs.CE cs.NA math.AP math.NA stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we introduce a physics-driven regularization method for\ntraining of deep neural networks (DNNs) for use in engineering design and\nanalysis problems. In particular, we focus on prediction of a physical system,\nfor which in addition to training data, partial or complete information on a\nset of governing laws is also available. These laws often appear in the form of\ndifferential equations, derived from first principles, empirically-validated\nlaws, or domain expertise, and are usually neglected in data-driven prediction\nof engineering systems. We propose a training approach that utilizes the known\ngoverning laws and regularizes data-driven DNN models by penalizing divergence\nfrom those laws. The first two numerical examples are synthetic examples, where\nwe show that in constructing a DNN model that best fits the measurements from a\nphysical system, the use of our proposed regularization results in DNNs that\nare more interpretable with smaller generalization errors, compared to other\ncommon regularization methods. The last two examples concern metamodeling for a\nrandom Burgers' system and for aerodynamic analysis of passenger vehicles,\nwhere we demonstrate that the proposed regularization provides superior\ngeneralization accuracy compared to other common alternatives.\n", "versions": [{"version": "v1", "created": "Thu, 11 Oct 2018 17:12:34 GMT"}, {"version": "v2", "created": "Tue, 15 Oct 2019 22:27:24 GMT"}], "update_date": "2019-10-17", "authors_parsed": [["Nabian", "Mohammad Amin", ""], ["Meidani", "Hadi", ""]]}, {"id": "1810.05558", "submitter": "Luigi Acerbi", "authors": "Luigi Acerbi", "title": "Variational Bayesian Monte Carlo", "comments": "In Advances in Neural Information Processing Systems 31 (NeurIPS\n  2018), pp. 8222-8232. (25 pages, 9 figures)", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG q-bio.NC q-bio.QM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Many probabilistic models of interest in scientific computing and machine\nlearning have expensive, black-box likelihoods that prevent the application of\nstandard techniques for Bayesian inference, such as MCMC, which would require\naccess to the gradient or a large number of likelihood evaluations. We\nintroduce here a novel sample-efficient inference framework, Variational\nBayesian Monte Carlo (VBMC). VBMC combines variational inference with\nGaussian-process based, active-sampling Bayesian quadrature, using the latter\nto efficiently approximate the intractable integral in the variational\nobjective. Our method produces both a nonparametric approximation of the\nposterior distribution and an approximate lower bound of the model evidence,\nuseful for model selection. We demonstrate VBMC both on several synthetic\nlikelihoods and on a neuronal model with data from real neurons. Across all\ntested problems and dimensions (up to $D = 10$), VBMC performs consistently\nwell in reconstructing the posterior and the model evidence with a limited\nbudget of likelihood evaluations, unlike other methods that work only in very\nlow dimensions. Our framework shows great promise as a novel tool for posterior\nand model inference with expensive, black-box likelihoods.\n", "versions": [{"version": "v1", "created": "Fri, 12 Oct 2018 14:50:13 GMT"}, {"version": "v2", "created": "Thu, 29 Nov 2018 12:47:30 GMT"}], "update_date": "2018-11-30", "authors_parsed": [["Acerbi", "Luigi", ""]]}, {"id": "1810.05567", "submitter": "Andr\\'e Martin", "authors": "Oleh Bodunov, Florian Schmidt, Andr\\'e Martin, Andrey Brito, Christof\n  Fetzer", "title": "Grand Challenge: Real-time Destination and ETA Prediction for Maritime\n  Traffic", "comments": null, "journal-ref": null, "doi": "10.1145/3210284.3220502", "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we present our approach for solving the DEBS Grand Challenge\n2018. The challenge asks to provide a prediction for (i) a destination and the\n(ii) arrival time of ships in a streaming-fashion using Geo-spatial data in the\nmaritime context. Novel aspects of our approach include the use of ensemble\nlearning based on Random Forest, Gradient Boosting Decision Trees (GBDT),\nXGBoost Trees and Extremely Randomized Trees (ERT) in order to provide a\nprediction for a destination while for the arrival time, we propose the use of\nFeed-forward Neural Networks. In our evaluation, we were able to achieve an\naccuracy of 97% for the port destination classification problem and 90% (in\nmins) for the ETA prediction.\n", "versions": [{"version": "v1", "created": "Fri, 12 Oct 2018 15:14:00 GMT"}], "update_date": "2018-10-15", "authors_parsed": [["Bodunov", "Oleh", ""], ["Schmidt", "Florian", ""], ["Martin", "Andr\u00e9", ""], ["Brito", "Andrey", ""], ["Fetzer", "Christof", ""]]}, {"id": "1810.05570", "submitter": "Souad Bouasker", "authors": "Souad Bouasker", "title": "Characterization and extraction of condensed representation of\n  correlated patterns based on formal concept analysis", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DB cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Correlated pattern mining has increasingly become an important task in data\nmining since these patterns allow conveying knowledge about meaningful and\nsurprising relations among data. Frequent correlated patterns were thoroughly\nstudied in the literature. In this thesis, we propose to benefit from both\nfrequent correlated as well as rare correlated patterns according to the bond\ncorrelation measure. We propose to extract a subset without information loss of\nthe sets of frequent correlated and of rare correlated patterns, this subset is\ncalled ``Condensed Representation``. In this regard, we are based on the\nnotions derived from the Formal Concept Analysis FCA, specifically the\nequivalence classes associated to a closure operator fbond dedicated to the\nbond measure, to introduce new concise representations of both frequent\ncorrelated and rare correlated patterns.\n", "versions": [{"version": "v1", "created": "Fri, 12 Oct 2018 15:16:47 GMT"}], "update_date": "2018-10-15", "authors_parsed": [["Bouasker", "Souad", ""]]}, {"id": "1810.05571", "submitter": "Karsten Maurer", "authors": "Karsten Maurer and Walter Bennette", "title": "Facility Locations Utility for Uncovering Classifier Overconfidence", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Assessing the predictive accuracy of black box classifiers is challenging in\nthe absence of labeled test datasets. In these scenarios we may need to rely on\na human oracle to evaluate individual predictions; presenting the challenge to\ncreate query algorithms to guide the search for points that provide the most\ninformation about the classifier's predictive characteristics. Previous works\nhave focused on developing utility models and query algorithms for discovering\nunknown unknowns --- misclassifications with a predictive confidence above some\narbitrary threshold. However, if misclassifications occur at the rate reflected\nby the confidence values, then these search methods reveal nothing more than a\nproper assessment of predictive certainty. We are unable to properly mitigate\nthe risks associated with model deficiency when the model's confidence in\nprediction exceeds the actual model accuracy. We propose a facility locations\nutility model and corresponding greedy query algorithm that instead searches\nfor overconfident unknown unknowns. Through robust empirical experiments we\ndemonstrate that the greedy query algorithm with the facility locations utility\nmodel consistently results in oracle queries with superior performance in\ndiscovering overconfident unknown unknowns than previous methods.\n", "versions": [{"version": "v1", "created": "Fri, 12 Oct 2018 15:19:19 GMT"}], "update_date": "2018-10-15", "authors_parsed": [["Maurer", "Karsten", ""], ["Bennette", "Walter", ""]]}, {"id": "1810.05587", "submitter": "Pablo Hernandez-Leal", "authors": "Pablo Hernandez-Leal, Bilal Kartal and Matthew E. Taylor", "title": "A Survey and Critique of Multiagent Deep Reinforcement Learning", "comments": "Under review since Oct 2018. Earlier versions of this work had the\n  title: \"Is multiagent deep reinforcement learning the answer or the question?\n  A brief survey\"", "journal-ref": null, "doi": "10.1007/s10458-019-09421-1", "report-no": null, "categories": "cs.MA cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep reinforcement learning (RL) has achieved outstanding results in recent\nyears. This has led to a dramatic increase in the number of applications and\nmethods. Recent works have explored learning beyond single-agent scenarios and\nhave considered multiagent learning (MAL) scenarios. Initial results report\nsuccesses in complex multiagent domains, although there are several challenges\nto be addressed. The primary goal of this article is to provide a clear\noverview of current multiagent deep reinforcement learning (MDRL) literature.\nAdditionally, we complement the overview with a broader analysis: (i) we\nrevisit previous key components, originally presented in MAL and RL, and\nhighlight how they have been adapted to multiagent deep reinforcement learning\nsettings. (ii) We provide general guidelines to new practitioners in the area:\ndescribing lessons learned from MDRL works, pointing to recent benchmarks, and\noutlining open avenues of research. (iii) We take a more critical tone raising\npractical challenges of MDRL (e.g., implementation and computational demands).\nWe expect this article will help unify and motivate future research to take\nadvantage of the abundant literature that exists (e.g., RL and MAL) in a joint\neffort to promote fruitful research in the multiagent community.\n", "versions": [{"version": "v1", "created": "Fri, 12 Oct 2018 15:54:05 GMT"}, {"version": "v2", "created": "Sat, 22 Jun 2019 00:54:10 GMT"}, {"version": "v3", "created": "Fri, 30 Aug 2019 19:33:23 GMT"}], "update_date": "2019-10-21", "authors_parsed": [["Hernandez-Leal", "Pablo", ""], ["Kartal", "Bilal", ""], ["Taylor", "Matthew E.", ""]]}, {"id": "1810.05593", "submitter": "Ivan Y. Tyukin", "authors": "Ivan Y. Tyukin, Alexander N. Gorban, Stephen Green, Danil Prokhorov", "title": "Fast Construction of Correcting Ensembles for Legacy Artificial\n  Intelligence Systems: Algorithms and a Case Study", "comments": null, "journal-ref": "Information Sciences, 2019", "doi": "10.1016/j.ins.2018.11.057", "report-no": null, "categories": "cs.AI cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  This paper presents a technology for simple and computationally efficient\nimprovements of a generic Artificial Intelligence (AI) system, including\nMultilayer and Deep Learning neural networks. The improvements are, in essence,\nsmall network ensembles constructed on top of the existing AI architectures.\nTheoretical foundations of the technology are based on Stochastic Separation\nTheorems and the ideas of the concentration of measure. We show that, subject\nto mild technical assumptions on statistical properties of internal signals in\nthe original AI system, the technology enables instantaneous and\ncomputationally efficient removal of spurious and systematic errors with\nprobability close to one on the datasets which are exponentially large in\ndimension. The method is illustrated with numerical examples and a case study\nof ten digits recognition from American Sign Language.\n", "versions": [{"version": "v1", "created": "Fri, 12 Oct 2018 16:14:29 GMT"}, {"version": "v2", "created": "Wed, 13 Feb 2019 08:59:55 GMT"}], "update_date": "2019-02-14", "authors_parsed": [["Tyukin", "Ivan Y.", ""], ["Gorban", "Alexander N.", ""], ["Green", "Stephen", ""], ["Prokhorov", "Danil", ""]]}, {"id": "1810.05596", "submitter": "Vincenzo Lomonaco", "authors": "Claudia Carpineti, Vincenzo Lomonaco, Luca Bedogni, Marco Di Felice,\n  Luciano Bononi", "title": "Custom Dual Transportation Mode Detection by Smartphone Devices\n  Exploiting Sensor Diversity", "comments": "Pre-print of the accepted version for the 14th Workshop on Context\n  and Activity Modeling and Recognition (IEEE COMOREA 2018), Athens, Greece,\n  March 19-23, 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Making applications aware of the mobility experienced by the user can open\nthe door to a wide range of novel services in different use-cases, from smart\nparking to vehicular traffic monitoring. In the literature, there are many\ndifferent studies demonstrating the theoretical possibility of performing\nTransportation Mode Detection (TMD) by mining smart-phones embedded sensors\ndata. However, very few of them provide details on the benchmarking process and\non how to implement the detection process in practice. In this study, we\nprovide guidelines and fundamental results that can be useful for both\nresearcher and practitioners aiming at implementing a working TMD system. These\nguidelines consist of three main contributions. First, we detail the\nconstruction of a training dataset, gathered by heterogeneous users and\nincluding five different transportation modes; the dataset is made available to\nthe research community as reference benchmark. Second, we provide an in-depth\nanalysis of the sensor-relevance for the case of Dual TDM, which is required by\nmost of mobility-aware applications. Third, we investigate the possibility to\nperform TMD of unknown users/instances not present in the training set and we\ncompare with state-of-the-art Android APIs for activity recognition.\n", "versions": [{"version": "v1", "created": "Fri, 12 Oct 2018 16:31:43 GMT"}], "update_date": "2018-10-15", "authors_parsed": [["Carpineti", "Claudia", ""], ["Lomonaco", "Vincenzo", ""], ["Bedogni", "Luca", ""], ["Di Felice", "Marco", ""], ["Bononi", "Luciano", ""]]}, {"id": "1810.05597", "submitter": "Ruiqi Gao", "authors": "Ruiqi Gao, Jianwen Xie, Song-Chun Zhu, Ying Nian Wu", "title": "Learning Grid Cells as Vector Representation of Self-Position Coupled\n  with Matrix Representation of Self-Motion", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper proposes a representational model for grid cells. In this model,\nthe 2D self-position of the agent is represented by a high-dimensional vector,\nand the 2D self-motion or displacement of the agent is represented by a matrix\nthat transforms the vector. Each component of the vector is a unit or a cell.\nThe model consists of the following three sub-models. (1) Vector-matrix\nmultiplication. The movement from the current position to the next position is\nmodeled by matrix-vector multiplication, i.e., the vector of the next position\nis obtained by multiplying the matrix of the motion to the vector of the\ncurrent position. (2) Magnified local isometry. The angle between two nearby\nvectors equals the Euclidean distance between the two corresponding positions\nmultiplied by a magnifying factor. (3) Global adjacency kernel. The inner\nproduct between two vectors measures the adjacency between the two\ncorresponding positions, which is defined by a kernel function of the Euclidean\ndistance between the two positions. Our representational model has explicit\nalgebra and geometry. It can learn hexagon patterns of grid cells, and it is\ncapable of error correction, path integral and path planning.\n", "versions": [{"version": "v1", "created": "Fri, 12 Oct 2018 16:34:07 GMT"}, {"version": "v2", "created": "Mon, 14 Jan 2019 06:17:11 GMT"}, {"version": "v3", "created": "Sat, 25 May 2019 00:22:05 GMT"}], "update_date": "2019-05-28", "authors_parsed": [["Gao", "Ruiqi", ""], ["Xie", "Jianwen", ""], ["Zhu", "Song-Chun", ""], ["Wu", "Ying Nian", ""]]}, {"id": "1810.05598", "submitter": "Thomas Kehrenberg", "authors": "Thomas Kehrenberg, Zexun Chen, Novi Quadrianto", "title": "Tuning Fairness by Balancing Target Labels", "comments": "Published in Frontiers in Artificial Intelligence, Volume 3 (2020)", "journal-ref": null, "doi": "10.3389/frai.2020.00033", "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The issue of fairness in machine learning models has recently attracted a lot\nof attention as ensuring it will ensure continued confidence of the general\npublic in the deployment of machine learning systems. We focus on mitigating\nthe harm incurred by a biased machine learning system that offers better\noutputs (e.g. loans, job interviews) for certain groups than for others. We\nshow that bias in the output can naturally be controlled in probabilistic\nmodels by introducing a latent target output. This formulation has several\nadvantages: first, it is a unified framework for several notions of group\nfairness such as Demographic Parity and Equality of Opportunity; second, it is\nexpressed as a marginalisation instead of a constrained problem; and third, it\nallows the encoding of our knowledge of what unbiased outputs should be.\nPractically, the second allows us to avoid unstable constrained optimisation\nprocedures and to reuse off-the-shelf toolboxes. The latter translates to the\nability to control the level of fairness by directly varying fairness target\nrates. In contrast, existing approaches rely on intermediate, arguably\nunintuitive, control parameters such as covariance thresholds.\n", "versions": [{"version": "v1", "created": "Fri, 12 Oct 2018 16:36:23 GMT"}, {"version": "v2", "created": "Thu, 18 Oct 2018 16:30:03 GMT"}, {"version": "v3", "created": "Wed, 10 Apr 2019 11:20:20 GMT"}, {"version": "v4", "created": "Wed, 7 Oct 2020 16:21:43 GMT"}, {"version": "v5", "created": "Tue, 23 Feb 2021 11:08:21 GMT"}], "update_date": "2021-02-24", "authors_parsed": [["Kehrenberg", "Thomas", ""], ["Chen", "Zexun", ""], ["Quadrianto", "Novi", ""]]}, {"id": "1810.05640", "submitter": "Xinshang Wang", "authors": "Wang Chi Cheung and Will Ma and David Simchi-Levi and Xinshang Wang", "title": "Inventory Balancing with Online Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study a general problem of allocating limited resources to heterogeneous\ncustomers over time under model uncertainty. Each type of customer can be\nserviced using different actions, each of which stochastically consumes some\ncombination of resources, and returns different rewards for the resources\nconsumed. We consider a general model where the resource consumption\ndistribution associated with each (customer type, action)-combination is not\nknown, but is consistent and can be learned over time. In addition, the\nsequence of customer types to arrive over time is arbitrary and completely\nunknown.\n  We overcome both the challenges of model uncertainty and customer\nheterogeneity by judiciously synthesizing two algorithmic frameworks from the\nliterature: inventory balancing, which \"reserves\" a portion of each resource\nfor high-reward customer types which could later arrive, and online learning,\nwhich shows how to \"explore\" the resource consumption distributions of each\ncustomer type under different actions. We define an auxiliary problem, which\nallows for existing competitive ratio and regret bounds to be seamlessly\nintegrated. Furthermore, we show that the performance guarantee generated by\nour framework is tight, that is, we provide an information-theoretic lower\nbound which shows that both the loss from competitive ratio and the loss for\nregret are relevant in the combined problem.\n  Finally, we demonstrate the efficacy of our algorithms on a publicly\navailable hotel data set. Our framework is highly practical in that it requires\nno historical data (no fitted customer choice models, nor forecasting of\ncustomer arrival patterns) and can be used to initialize allocation strategies\nin fast-changing environments.\n", "versions": [{"version": "v1", "created": "Thu, 11 Oct 2018 19:34:13 GMT"}], "update_date": "2018-10-16", "authors_parsed": [["Cheung", "Wang Chi", ""], ["Ma", "Will", ""], ["Simchi-Levi", "David", ""], ["Wang", "Xinshang", ""]]}, {"id": "1810.05642", "submitter": "Robert Krajewski", "authors": "Robert Krajewski, Julian Bock, Laurent Kloeker and Lutz Eckstein", "title": "The highD Dataset: A Drone Dataset of Naturalistic Vehicle Trajectories\n  on German Highways for Validation of Highly Automated Driving Systems", "comments": "IEEE International Conference on Intelligent Transportation Systems\n  (ITSC) 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.IR cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Scenario-based testing for the safety validation of highly automated vehicles\nis a promising approach that is being examined in research and industry. This\napproach heavily relies on data from real-world scenarios to derive the\nnecessary scenario information for testing. Measurement data should be\ncollected at a reasonable effort, contain naturalistic behavior of road users\nand include all data relevant for a description of the identified scenarios in\nsufficient quality. However, the current measurement methods fail to meet at\nleast one of the requirements. Thus, we propose a novel method to measure data\nfrom an aerial perspective for scenario-based validation fulfilling the\nmentioned requirements. Furthermore, we provide a large-scale naturalistic\nvehicle trajectory dataset from German highways called highD. We evaluate the\ndata in terms of quantity, variety and contained scenarios. Our dataset\nconsists of 16.5 hours of measurements from six locations with 110 000\nvehicles, a total driven distance of 45 000 km and 5600 recorded complete lane\nchanges. The highD dataset is available online at: http://www.highD-dataset.com\n", "versions": [{"version": "v1", "created": "Thu, 11 Oct 2018 22:47:33 GMT"}], "update_date": "2018-10-16", "authors_parsed": [["Krajewski", "Robert", ""], ["Bock", "Julian", ""], ["Kloeker", "Laurent", ""], ["Eckstein", "Lutz", ""]]}, {"id": "1810.05644", "submitter": "Lahiru Jayasinghe", "authors": "Lahiru Jayasinghe, Tharaka Samarasinghe, Chau Yuen, Jenny Chen Ni Low,\n  and Shuzhi Sam Ge", "title": "Temporal Convolutional Memory Networks for Remaining Useful Life\n  Estimation of Industrial Machinery", "comments": "accepted to IEEE International Conference on Industrial Technology\n  (ICIT2019)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Accurately estimating the remaining useful life (RUL) of industrial machinery\nis beneficial in many real-world applications. Estimation techniques have\nmainly utilized linear models or neural network based approaches with a focus\non short term time dependencies. This paper, introduces a system model that\nincorporates temporal convolutions with both long term and short term time\ndependencies. The proposed network learns salient features and complex temporal\nvariations in sensor values, and predicts the RUL. A data augmentation method\nis used for increased accuracy. The proposed method is compared with several\nstate-of-the-art algorithms on publicly available datasets. It demonstrates\npromising results, with superior results for datasets obtained from complex\nenvironments.\n", "versions": [{"version": "v1", "created": "Fri, 12 Oct 2018 08:00:33 GMT"}, {"version": "v2", "created": "Mon, 10 Dec 2018 10:11:11 GMT"}], "update_date": "2018-12-11", "authors_parsed": [["Jayasinghe", "Lahiru", ""], ["Samarasinghe", "Tharaka", ""], ["Yuen", "Chau", ""], ["Low", "Jenny Chen Ni", ""], ["Ge", "Shuzhi Sam", ""]]}, {"id": "1810.05665", "submitter": "Tianhang Zheng", "authors": "Tianhang Zheng, Changyou Chen, Kui Ren", "title": "Is PGD-Adversarial Training Necessary? Alternative Training via a\n  Soft-Quantization Network with Noisy-Natural Samples Only", "comments": "Further improvement", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent work on adversarial attack and defense suggests that PGD is a\nuniversal $l_\\infty$ first-order attack, and PGD adversarial training can\nsignificantly improve network robustness against a wide range of first-order\n$l_\\infty$-bounded attacks, represented as the state-of-the-art defense method.\nHowever, an obvious weakness of PGD adversarial training is its\nhighly-computational cost in generating adversarial samples, making it\ncomputationally infeasible for large and high-resolution real datasets such as\nthe ImageNet dataset. In addition, recent work also has suggested a simple\n\"close-form\" solution to a robust model on MNIST. Therefore, a natural question\nraised is that is PGD adversarial training really necessary for robust defense?\nIn this paper, we give a negative answer by proposing a training paradigm that\nis comparable to PGD adversarial training on several standard datasets, while\nonly using noisy-natural samples. Specifically, we reformulate the min-max\nobjective in PGD adversarial training by a problem to minimize the original\nnetwork loss plus $l_1$ norms of its gradients w.r.t. the inputs. For the\n$l_1$-norm loss, we propose a computationally-feasible solution by embedding a\ndifferentiable soft-quantization layer after the network input layer. We show\nformally that the soft-quantization layer trained with noisy-natural samples is\nan alternative approach to minimizing the $l_1$-gradient norms as in PGD\nadversarial training. Extensive empirical evaluations on standard datasets show\nthat our proposed models are comparable to PGD-adversarially-trained models\nunder PGD and BPDA attacks. Remarkably, our method achieves a 24X speed-up on\nMNIST while maintaining a comparable defensive ability, and for the first time\nfine-tunes a robust Imagenet model within only two days. Code is provided on\n\\url{https://github.com/tianzheng4/Noisy-Training-Soft-Quantization}\n", "versions": [{"version": "v1", "created": "Wed, 10 Oct 2018 01:06:05 GMT"}, {"version": "v2", "created": "Fri, 19 Oct 2018 17:31:50 GMT"}], "update_date": "2018-10-22", "authors_parsed": [["Zheng", "Tianhang", ""], ["Chen", "Changyou", ""], ["Ren", "Kui", ""]]}, {"id": "1810.05687", "submitter": "Yevgen Chebotar", "authors": "Yevgen Chebotar, Ankur Handa, Viktor Makoviychuk, Miles Macklin, Jan\n  Issac, Nathan Ratliff, Dieter Fox", "title": "Closing the Sim-to-Real Loop: Adapting Simulation Randomization with\n  Real World Experience", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the problem of transferring policies to the real world by\ntraining on a distribution of simulated scenarios. Rather than manually tuning\nthe randomization of simulations, we adapt the simulation parameter\ndistribution using a few real world roll-outs interleaved with policy training.\nIn doing so, we are able to change the distribution of simulations to improve\nthe policy transfer by matching the policy behavior in simulation and the real\nworld. We show that policies trained with our method are able to reliably\ntransfer to different robots in two real world tasks: swing-peg-in-hole and\nopening a cabinet drawer. The video of our experiments can be found at\nhttps://sites.google.com/view/simopt\n", "versions": [{"version": "v1", "created": "Fri, 12 Oct 2018 19:15:05 GMT"}, {"version": "v2", "created": "Sun, 21 Oct 2018 05:26:25 GMT"}, {"version": "v3", "created": "Wed, 31 Oct 2018 20:23:23 GMT"}, {"version": "v4", "created": "Tue, 5 Mar 2019 23:49:11 GMT"}], "update_date": "2019-03-07", "authors_parsed": [["Chebotar", "Yevgen", ""], ["Handa", "Ankur", ""], ["Makoviychuk", "Viktor", ""], ["Macklin", "Miles", ""], ["Issac", "Jan", ""], ["Ratliff", "Nathan", ""], ["Fox", "Dieter", ""]]}, {"id": "1810.05691", "submitter": "Erich Schubert", "authors": "Erich Schubert and Peter J. Rousseeuw", "title": "Faster k-Medoids Clustering: Improving the PAM, CLARA, and CLARANS\n  Algorithms", "comments": null, "journal-ref": null, "doi": "10.1007/978-3-030-32047-8_16", "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Clustering non-Euclidean data is difficult, and one of the most used\nalgorithms besides hierarchical clustering is the popular algorithm\nPartitioning Around Medoids (PAM), also simply referred to as k-medoids. In\nEuclidean geometry the mean-as used in k-means-is a good estimator for the\ncluster center, but this does not hold for arbitrary dissimilarities. PAM uses\nthe medoid instead, the object with the smallest dissimilarity to all others in\nthe cluster. This notion of centrality can be used with any (dis-)similarity,\nand thus is of high relevance to many domains such as biology that require the\nuse of Jaccard, Gower, or more complex distances.\n  A key issue with PAM is its high run time cost. We propose modifications to\nthe PAM algorithm to achieve an O(k)-fold speedup in the second SWAP phase of\nthe algorithm, but will still find the same results as the original PAM\nalgorithm. If we slightly relax the choice of swaps performed (at comparable\nquality), we can further accelerate the algorithm by performing up to k swaps\nin each iteration. With the substantially faster SWAP, we can now also explore\nalternative strategies for choosing the initial medoids. We also show how the\nCLARA and CLARANS algorithms benefit from these modifications. It can easily be\ncombined with earlier approaches to use PAM and CLARA on big data (some of\nwhich use PAM as a subroutine, hence can immediately benefit from these\nimprovements), where the performance with high k becomes increasingly\nimportant.\n  In experiments on real data with k=100, we observed a 200-fold speedup\ncompared to the original PAM SWAP algorithm, making PAM applicable to larger\ndata sets as long as we can afford to compute a distance matrix, and in\nparticular to higher k (at k=2, the new SWAP was only 1.5 times faster, as the\nspeedup is expected to increase with k).\n", "versions": [{"version": "v1", "created": "Fri, 12 Oct 2018 19:26:28 GMT"}, {"version": "v2", "created": "Wed, 1 May 2019 14:09:31 GMT"}, {"version": "v3", "created": "Sat, 4 May 2019 22:01:11 GMT"}, {"version": "v4", "created": "Tue, 29 Oct 2019 19:05:32 GMT"}], "update_date": "2020-02-05", "authors_parsed": [["Schubert", "Erich", ""], ["Rousseeuw", "Peter J.", ""]]}, {"id": "1810.05713", "submitter": "Sandesh Ghimire", "authors": "Sandesh Ghimire, Prashnna Kumar Gyawali, John L Sapp, Milan Horacek,\n  Linwei Wang", "title": "Improving Generalization of Sequence Encoder-Decoder Networks for\n  Inverse Imaging of Cardiac Transmembrane Potential", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Deep learning models have shown state-of-the-art performance in many inverse\nreconstruction problems. However, it is not well understood what properties of\nthe latent representation may improve the generalization ability of the\nnetwork. Furthermore, limited models have been presented for inverse\nreconstructions over time sequences. In this paper, we study the generalization\nability of a sequence encoder decoder model for solving inverse reconstructions\non time sequences. Our central hypothesis is that the generalization ability of\nthe network can be improved by 1) constrained stochasticity and 2) global\naggregation of temporal information in the latent space. First, drawing from\nanalytical learning theory, we theoretically show that a stochastic latent\nspace will lead to an improved generalization ability. Second, we consider an\nLSTM encoder-decoder architecture that compresses a global latent vector from\nall last-layer units in the LSTM encoder. This model is compared with\nalternative LSTM encoder-decoder architectures, each in deterministic and\nstochastic versions. The results demonstrate that the generalization ability of\nan inverse reconstruction network can be improved by constrained stochasticity\ncombined with global aggregation of temporal information in the latent space.\n", "versions": [{"version": "v1", "created": "Fri, 12 Oct 2018 20:42:23 GMT"}], "update_date": "2018-10-16", "authors_parsed": [["Ghimire", "Sandesh", ""], ["Gyawali", "Prashnna Kumar", ""], ["Sapp", "John L", ""], ["Horacek", "Milan", ""], ["Wang", "Linwei", ""]]}, {"id": "1810.05724", "submitter": "Andrej Junginger", "authors": "Andrej Junginger, Markus Hanselmann, Thilo Strauss, Sebastian Boblest,\n  Jens Buchner, Holger Ulmer", "title": "Unpaired High-Resolution and Scalable Style Transfer Using Generative\n  Adversarial Networks", "comments": "10 pages, 8 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Neural networks have proven their capabilities by outperforming many other\napproaches on regression or classification tasks on various kinds of data.\nOther astonishing results have been achieved using neural nets as data\ngenerators, especially in settings of generative adversarial networks (GANs).\nOne special application is the field of image domain translations. Here, the\ngoal is to take an image with a certain style (e.g. a photography) and\ntransform it into another one (e.g. a painting). If such a task is performed\nfor unpaired training examples, the corresponding GAN setting is complex, the\nneural networks are large, and this leads to a high peak memory consumption\nduring, both, training and evaluation phase. This sets a limit to the highest\nprocessable image size. We address this issue by the idea of not processing the\nwhole image at once, but to train and evaluate the domain translation on the\nlevel of overlapping image subsamples. This new approach not only enables us to\ntranslate high-resolution images that otherwise cannot be processed by the\nneural network at once, but also allows us to work with comparably small neural\nnetworks and with limited hardware resources. Additionally, the number of\nimages required for the training process is significantly reduced. We present\nhigh-quality results on images with a total resolution of up to over 50\nmegapixels and emonstrate that our method helps to preserve local image details\nwhile it also keeps global consistency.\n", "versions": [{"version": "v1", "created": "Wed, 10 Oct 2018 07:02:47 GMT"}], "update_date": "2018-10-16", "authors_parsed": [["Junginger", "Andrej", ""], ["Hanselmann", "Markus", ""], ["Strauss", "Thilo", ""], ["Boblest", "Sebastian", ""], ["Buchner", "Jens", ""], ["Ulmer", "Holger", ""]]}, {"id": "1810.05726", "submitter": "Alex Olsen", "authors": "Alex Olsen, Dmitry A. Konovalov, Bronson Philippa, Peter Ridd, Jake C.\n  Wood, Jamie Johns, Wesley Banks, Benjamin Girgenti, Owen Kenny, James\n  Whinney, Brendan Calvert, Mostafa Rahimi Azghadi and Ronald D. White", "title": "DeepWeeds: A Multiclass Weed Species Image Dataset for Deep Learning", "comments": "14 pages, 8 figures, 4 tables", "journal-ref": "Sci.Rep. 9, 2058 (2019)", "doi": "10.1038/s41598-018-38343-3", "report-no": null, "categories": "cs.CV cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Robotic weed control has seen increased research of late with its potential\nfor boosting productivity in agriculture. Majority of works focus on developing\nrobotics for croplands, ignoring the weed management problems facing rangeland\nstock farmers. Perhaps the greatest obstacle to widespread uptake of robotic\nweed control is the robust classification of weed species in their natural\nenvironment. The unparalleled successes of deep learning make it an ideal\ncandidate for recognising various weed species in the complex rangeland\nenvironment. This work contributes the first large, public, multiclass image\ndataset of weed species from the Australian rangelands; allowing for the\ndevelopment of robust classification methods to make robotic weed control\nviable. The DeepWeeds dataset consists of 17,509 labelled images of eight\nnationally significant weed species native to eight locations across northern\nAustralia. This paper presents a baseline for classification performance on the\ndataset using the benchmark deep learning models, Inception-v3 and ResNet-50.\nThese models achieved an average classification accuracy of 95.1% and 95.7%,\nrespectively. We also demonstrate real time performance of the ResNet-50\narchitecture, with an average inference time of 53.4 ms per image. These strong\nresults bode well for future field implementation of robotic weed control\nmethods in the Australian rangelands.\n", "versions": [{"version": "v1", "created": "Tue, 9 Oct 2018 05:53:26 GMT"}, {"version": "v2", "created": "Wed, 28 Nov 2018 21:49:49 GMT"}, {"version": "v3", "created": "Thu, 14 Feb 2019 11:20:57 GMT"}], "update_date": "2019-02-15", "authors_parsed": [["Olsen", "Alex", ""], ["Konovalov", "Dmitry A.", ""], ["Philippa", "Bronson", ""], ["Ridd", "Peter", ""], ["Wood", "Jake C.", ""], ["Johns", "Jamie", ""], ["Banks", "Wesley", ""], ["Girgenti", "Benjamin", ""], ["Kenny", "Owen", ""], ["Whinney", "James", ""], ["Calvert", "Brendan", ""], ["Azghadi", "Mostafa Rahimi", ""], ["White", "Ronald D.", ""]]}, {"id": "1810.05728", "submitter": "Kristjan Greenewald", "authors": "Ziv Goldfeld, Ewout van den Berg, Kristjan Greenewald, Igor Melnyk,\n  Nam Nguyen, Brian Kingsbury, Yury Polyanskiy", "title": "Estimating Information Flow in Deep Neural Networks", "comments": "Main text accepted to ICML 2019. This preprint contains the full\n  version of that paper (including omitted appendices)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the flow of information and the evolution of internal\nrepresentations during deep neural network (DNN) training, aiming to demystify\nthe compression aspect of the information bottleneck theory. The theory\nsuggests that DNN training comprises a rapid fitting phase followed by a slower\ncompression phase, in which the mutual information $I(X;T)$ between the input\n$X$ and internal representations $T$ decreases. Several papers observe\ncompression of estimated mutual information on different DNN models, but the\ntrue $I(X;T)$ over these networks is provably either constant (discrete $X$) or\ninfinite (continuous $X$). This work explains the discrepancy between theory\nand experiments, and clarifies what was actually measured by these past works.\nTo this end, we introduce an auxiliary (noisy) DNN framework for which $I(X;T)$\nis a meaningful quantity that depends on the network's parameters. This noisy\nframework is shown to be a good proxy for the original (deterministic) DNN both\nin terms of performance and the learned representations. We then develop a\nrigorous estimator for $I(X;T)$ in noisy DNNs and observe compression in\nvarious models. By relating $I(X;T)$ in the noisy DNN to an\ninformation-theoretic communication problem, we show that compression is driven\nby the progressive clustering of hidden representations of inputs from the same\nclass. Several methods to directly monitor clustering of hidden\nrepresentations, both in noisy and deterministic DNNs, are used to show that\nmeaningful clusters form in the $T$ space. Finally, we return to the estimator\nof $I(X;T)$ employed in past works, and demonstrate that while it fails to\ncapture the true (vacuous) mutual information, it does serve as a measure for\nclustering. This clarifies the past observations of compression and isolates\nthe geometric clustering of hidden representations as the true phenomenon of\ninterest.\n", "versions": [{"version": "v1", "created": "Fri, 12 Oct 2018 21:11:30 GMT"}, {"version": "v2", "created": "Tue, 16 Oct 2018 02:52:45 GMT"}, {"version": "v3", "created": "Wed, 14 Nov 2018 16:38:23 GMT"}, {"version": "v4", "created": "Thu, 30 May 2019 15:42:19 GMT"}], "update_date": "2019-05-31", "authors_parsed": [["Goldfeld", "Ziv", ""], ["Berg", "Ewout van den", ""], ["Greenewald", "Kristjan", ""], ["Melnyk", "Igor", ""], ["Nguyen", "Nam", ""], ["Kingsbury", "Brian", ""], ["Polyanskiy", "Yury", ""]]}, {"id": "1810.05729", "submitter": "Teresa Finisterra Ara\\'ujo", "authors": "Teresa Ara\\'ujo, Guilherme Aresta, Adrian Galdran, Pedro Costa, Ana\n  Maria Mendon\\c{c}a, and Aur\\'elio Campilho", "title": "UOLO - automatic object detection and segmentation in biomedical images", "comments": "Publised on DLMIA 2018. Licensed under the Creative Commons\n  CC-BY-NC-ND 4.0 license: http://creativecommons.org/licenses/by-nc-nd/4.0/", "journal-ref": "4th International Workshop, DLMIA 2018, and 8th International\n  Workshop, ML-CDS 2018, Held in Conjunction with MICCAI 2018, Granada, Spain,\n  September 20, 2018, Proceedings. 165-173", "doi": "10.1007/978-3-030-00889-5_19", "report-no": null, "categories": "cs.CV cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose UOLO, a novel framework for the simultaneous detection and\nsegmentation of structures of interest in medical images. UOLO consists of an\nobject segmentation module which intermediate abstract representations are\nprocessed and used as input for object detection. The resulting system is\noptimized simultaneously for detecting a class of objects and segmenting an\noptionally different class of structures. UOLO is trained on a set of bounding\nboxes enclosing the objects to detect, as well as pixel-wise segmentation\ninformation, when available. A new loss function is devised, taking into\naccount whether a reference segmentation is accessible for each training image,\nin order to suitably backpropagate the error. We validate UOLO on the task of\nsimultaneous optic disc (OD) detection, fovea detection, and OD segmentation\nfrom retinal images, achieving state-of-the-art performance on public datasets.\n", "versions": [{"version": "v1", "created": "Tue, 9 Oct 2018 13:53:13 GMT"}], "update_date": "2019-06-18", "authors_parsed": [["Ara\u00fajo", "Teresa", ""], ["Aresta", "Guilherme", ""], ["Galdran", "Adrian", ""], ["Costa", "Pedro", ""], ["Mendon\u00e7a", "Ana Maria", ""], ["Campilho", "Aur\u00e9lio", ""]]}, {"id": "1810.05730", "submitter": "Miao Cheng", "authors": "Miao Cheng, Ah Chung Tsoi", "title": "CRH: A Simple Benchmark Approach to Continuous Hashing", "comments": "6 pages", "journal-ref": null, "doi": "10.1109/GlobalSIP.2015.7418363", "report-no": null, "categories": "cs.CV cs.LG", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  In recent years, the distinctive advancement of handling huge data promotes\nthe evolution of ubiquitous computing and analysis technologies. With the\nconstantly upward system burden and computational complexity, adaptive coding\nhas been a fascinating topic for pattern analysis, with outstanding\nperformance. In this work, a continuous hashing method, termed continuous\nrandom hashing (CRH), is proposed to encode sequential data stream, while\nignorance of previously hashing knowledge is possible. Instead, a random\nselection idea is adopted to adaptively approximate the differential encoding\npatterns of data stream, e.g., streaming media, and iteration is avoided for\nstepwise learning. Experimental results demonstrate our method is able to\nprovide outstanding performance, as a benchmark approach to continuous hashing.\n", "versions": [{"version": "v1", "created": "Wed, 10 Oct 2018 14:18:00 GMT"}], "update_date": "2018-10-16", "authors_parsed": [["Cheng", "Miao", ""], ["Tsoi", "Ah Chung", ""]]}, {"id": "1810.05731", "submitter": "Saifuddin Hitawala", "authors": "Saifuddin Hitawala, Yao Li, Xian Wang, Dongyang Yang", "title": "Image Super-Resolution Using VDSR-ResNeXt and SRCGAN", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Over the past decade, many Super Resolution techniques have been developed\nusing deep learning. Among those, generative adversarial networks (GAN) and\nvery deep convolutional networks (VDSR) have shown promising results in terms\nof HR image quality and computational speed. In this paper, we propose two\napproaches based on these two algorithms: VDSR-ResNeXt, which is a deep\nmulti-branch convolutional network inspired by VDSR and ResNeXt; and SRCGAN,\nwhich is a conditional GAN that explicitly passes class labels as input to the\nGAN. The two methods were implemented on common SR benchmark datasets for both\nquantitative and qualitative assessment.\n", "versions": [{"version": "v1", "created": "Wed, 10 Oct 2018 19:20:15 GMT"}], "update_date": "2018-10-16", "authors_parsed": [["Hitawala", "Saifuddin", ""], ["Li", "Yao", ""], ["Wang", "Xian", ""], ["Yang", "Dongyang", ""]]}, {"id": "1810.05732", "submitter": "Amir Gholami", "authors": "Amir Gholami and Shashank Subramanian and Varun Shenoy and Naveen\n  Himthani and Xiangyu Yue and Sicheng Zhao and Peter Jin and George Biros and\n  Kurt Keutzer", "title": "A Novel Domain Adaptation Framework for Medical Image Segmentation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a segmentation framework that uses deep neural networks and\nintroduce two innovations. First, we describe a biophysics-based domain\nadaptation method. Second, we propose an automatic method to segment white and\ngray matter, and cerebrospinal fluid, in addition to tumorous tissue. Regarding\nour first innovation, we use a domain adaptation framework that combines a\nnovel multispecies biophysical tumor growth model with a generative adversarial\nmodel to create realistic looking synthetic multimodal MR images with known\nsegmentation. Regarding our second innovation, we propose an automatic approach\nto enrich available segmentation data by computing the segmentation for healthy\ntissues. This segmentation, which is done using diffeomorphic image\nregistration between the BraTS training data and a set of prelabeled atlases,\nprovides more information for training and reduces the class imbalance problem.\nOur overall approach is not specific to any particular neural network and can\nbe used in conjunction with existing solutions. We demonstrate the performance\nimprovement using a 2D U-Net for the BraTS'18 segmentation challenge. Our\nbiophysics based domain adaptation achieves better results, as compared to the\nexisting state-of-the-art GAN model used to create synthetic data for training.\n", "versions": [{"version": "v1", "created": "Thu, 11 Oct 2018 04:03:30 GMT"}], "update_date": "2018-10-16", "authors_parsed": [["Gholami", "Amir", ""], ["Subramanian", "Shashank", ""], ["Shenoy", "Varun", ""], ["Himthani", "Naveen", ""], ["Yue", "Xiangyu", ""], ["Zhao", "Sicheng", ""], ["Jin", "Peter", ""], ["Biros", "George", ""], ["Keutzer", "Kurt", ""]]}, {"id": "1810.05741", "submitter": "R\\'emi Eyraud", "authors": "Stephane Ayache and Remi Eyraud and Noe Goudian", "title": "Explaining Black Boxes on Sequential Data using Weighted Automata", "comments": "Published in the Proceedings of the International Conference in\n  Grammatical Inference, September 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Understanding how a learned black box works is of crucial interest for the\nfuture of Machine Learning. In this paper, we pioneer the question of the\nglobal interpretability of learned black box models that assign numerical\nvalues to symbolic sequential data. To tackle that task, we propose a spectral\nalgorithm for the extraction of weighted automata (WA) from such black boxes.\nThis algorithm does not require the access to a dataset or to the inner\nrepresentation of the black box: the inferred model can be obtained solely by\nquerying the black box, feeding it with inputs and analyzing its outputs.\nExperiments using Recurrent Neural Networks (RNN) trained on a wide collection\nof 48 synthetic datasets and 2 real datasets show that the obtained\napproximation is of great quality.\n", "versions": [{"version": "v1", "created": "Fri, 12 Oct 2018 21:35:23 GMT"}], "update_date": "2018-10-16", "authors_parsed": [["Ayache", "Stephane", ""], ["Eyraud", "Remi", ""], ["Goudian", "Noe", ""]]}, {"id": "1810.05749", "submitter": "Chris Zhang", "authors": "Chris Zhang, Mengye Ren, Raquel Urtasun", "title": "Graph HyperNetworks for Neural Architecture Search", "comments": "ICLR 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Neural architecture search (NAS) automatically finds the best task-specific\nneural network topology, outperforming many manual architecture designs.\nHowever, it can be prohibitively expensive as the search requires training\nthousands of different networks, while each can last for hours. In this work,\nwe propose the Graph HyperNetwork (GHN) to amortize the search cost: given an\narchitecture, it directly generates the weights by running inference on a graph\nneural network. GHNs model the topology of an architecture and therefore can\npredict network performance more accurately than regular hypernetworks and\npremature early stopping. To perform NAS, we randomly sample architectures and\nuse the validation accuracy of networks with GHN generated weights as the\nsurrogate search signal. GHNs are fast -- they can search nearly 10 times\nfaster than other random search methods on CIFAR-10 and ImageNet. GHNs can be\nfurther extended to the anytime prediction setting, where they have found\nnetworks with better speed-accuracy tradeoff than the state-of-the-art manual\ndesigns.\n", "versions": [{"version": "v1", "created": "Fri, 12 Oct 2018 22:21:05 GMT"}, {"version": "v2", "created": "Sat, 12 Jan 2019 04:03:03 GMT"}, {"version": "v3", "created": "Fri, 18 Dec 2020 18:01:04 GMT"}], "update_date": "2020-12-21", "authors_parsed": [["Zhang", "Chris", ""], ["Ren", "Mengye", ""], ["Urtasun", "Raquel", ""]]}, {"id": "1810.05751", "submitter": "Wenhao Yu", "authors": "Wenhao Yu, C. Karen Liu and Greg Turk", "title": "Policy Transfer with Strategy Optimization", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.RO stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Computer simulation provides an automatic and safe way for training robotic\ncontrol policies to achieve complex tasks such as locomotion. However, a policy\ntrained in simulation usually does not transfer directly to the real hardware\ndue to the differences between the two environments. Transfer learning using\ndomain randomization is a promising approach, but it usually assumes that the\ntarget environment is close to the distribution of the training environments,\nthus relying heavily on accurate system identification. In this paper, we\npresent a different approach that leverages domain randomization for\ntransferring control policies to unknown environments. The key idea that,\ninstead of learning a single policy in the simulation, we simultaneously learn\na family of policies that exhibit different behaviors. When tested in the\ntarget environment, we directly search for the best policy in the family based\non the task performance, without the need to identify the dynamic parameters.\nWe evaluate our method on five simulated robotic control problems with\ndifferent discrepancies in the training and testing environment and demonstrate\nthat our method can overcome larger modeling errors compared to training a\nrobust policy or an adaptive policy.\n", "versions": [{"version": "v1", "created": "Fri, 12 Oct 2018 22:53:30 GMT"}, {"version": "v2", "created": "Tue, 4 Dec 2018 16:36:47 GMT"}], "update_date": "2018-12-05", "authors_parsed": [["Yu", "Wenhao", ""], ["Liu", "C. Karen", ""], ["Turk", "Greg", ""]]}, {"id": "1810.05752", "submitter": "Jeongyeol Kwon", "authors": "Jeongyeol Kwon, Wei Qian, Constantine Caramanis, Yudong Chen, Damek\n  Davis", "title": "Global Convergence of EM Algorithm for Mixtures of Two Component Linear\n  Regression", "comments": "To appear in the proceedings of the Conference on Learning Theory\n  (COLT), 2019. This paper results from a merger of work from two groups who\n  work on the problem at the same time", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The Expectation-Maximization algorithm is perhaps the most broadly used\nalgorithm for inference of latent variable problems. A theoretical\nunderstanding of its performance, however, largely remains lacking. Recent\nresults established that EM enjoys global convergence for Gaussian Mixture\nModels. For Mixed Linear Regression, however, only local convergence results\nhave been established, and those only for the high SNR regime. We show here\nthat EM converges for mixed linear regression with two components (it is known\nthat it may fail to converge for three or more), and moreover that this\nconvergence holds for random initialization. Our analysis reveals that EM\nexhibits very different behavior in Mixed Linear Regression from its behavior\nin Gaussian Mixture Models, and hence our proofs require the development of\nseveral new ideas.\n", "versions": [{"version": "v1", "created": "Fri, 12 Oct 2018 22:59:30 GMT"}, {"version": "v2", "created": "Sat, 9 Feb 2019 22:40:37 GMT"}, {"version": "v3", "created": "Thu, 14 Feb 2019 22:29:36 GMT"}, {"version": "v4", "created": "Tue, 28 May 2019 21:29:50 GMT"}], "update_date": "2019-05-30", "authors_parsed": [["Kwon", "Jeongyeol", ""], ["Qian", "Wei", ""], ["Caramanis", "Constantine", ""], ["Chen", "Yudong", ""], ["Davis", "Damek", ""]]}, {"id": "1810.05795", "submitter": "Chun-Liang Li", "authors": "Chun-Liang Li, Manzil Zaheer, Yang Zhang, Barnabas Poczos, Ruslan\n  Salakhutdinov", "title": "Point Cloud GAN", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Generative Adversarial Networks (GAN) can achieve promising performance on\nlearning complex data distributions on different types of data. In this paper,\nwe first show a straightforward extension of existing GAN algorithm is not\napplicable to point clouds, because the constraint required for discriminators\nis undefined for set data. We propose a two fold modification to GAN algorithm\nfor learning to generate point clouds (PC-GAN). First, we combine ideas from\nhierarchical Bayesian modeling and implicit generative models by learning a\nhierarchical and interpretable sampling process. A key component of our method\nis that we train a posterior inference network for the hidden variables.\nSecond, instead of using only state-of-the-art Wasserstein GAN objective, we\npropose a sandwiching objective, which results in a tighter Wasserstein\ndistance estimate than the commonly used dual form. Thereby, PC-GAN defines a\ngeneric framework that can incorporate many existing GAN algorithms. We\nvalidate our claims on ModelNet40 benchmark dataset. Using the distance between\ngenerated point clouds and true meshes as metric, we find that PC-GAN trained\nby the sandwiching objective achieves better results on test data than the\nexisting methods. Moreover, as a byproduct, PC- GAN learns versatile latent\nrepresentations of point clouds, which can achieve competitive performance with\nother unsupervised learning algorithms on object recognition task. Lastly, we\nalso provide studies on generating unseen classes of objects and transforming\nimage to point cloud, which demonstrates the compelling generalization\ncapability and potentials of PC-GAN.\n", "versions": [{"version": "v1", "created": "Sat, 13 Oct 2018 04:14:14 GMT"}], "update_date": "2018-10-16", "authors_parsed": [["Li", "Chun-Liang", ""], ["Zaheer", "Manzil", ""], ["Zhang", "Yang", ""], ["Poczos", "Barnabas", ""], ["Salakhutdinov", "Ruslan", ""]]}, {"id": "1810.05846", "submitter": "Hans De Sterck", "authors": "Drew Mitchell, Nan Ye, Hans De Sterck", "title": "Nesterov Acceleration of Alternating Least Squares for Canonical Tensor\n  Decomposition: Momentum Step Size Selection and Restart Mechanisms", "comments": "This version: journal revision, Nov 30, 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.OC cs.LG cs.NA math.NA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present Nesterov-type acceleration techniques for Alternating Least\nSquares (ALS) methods applied to canonical tensor decomposition. While Nesterov\nacceleration turns gradient descent into an optimal first-order method for\nconvex problems by adding a momentum term with a specific weight sequence, a\ndirect application of this method and weight sequence to ALS results in erratic\nconvergence behaviour. This is so because the tensor decomposition problem is\nnon-convex and ALS is accelerated instead of gradient descent. Instead, we\nconsider various restart mechanisms and suitable choices of momentum weights\nthat enable effective acceleration. Our extensive empirical results show that\nthe Nesterov-accelerated ALS methods with restart can be dramatically more\nefficient than the stand-alone ALS or Nesterov accelerated gradient methods,\nwhen problems are ill-conditioned or accurate solutions are desired. The\nresulting methods perform competitively with or superior to existing\nacceleration methods for ALS, including ALS acceleration by NCG, NGMRES, or\nLBFGS, and additionally enjoy the benefit of being much easier to implement. We\nalso compare with Nesterov-type updates where the momentum weight is determined\nby a line search, which are equivalent or closely related to existing line\nsearch methods for ALS. On a large and ill-conditioned\n71$\\times$1000$\\times$900 tensor consisting of readings from chemical sensors\nto track hazardous gases, the restarted Nesterov-ALS method shows desirable\nrobustness properties and outperforms any of the existing methods by a large\nfactor. There is clear potential for extending our Nesterov-type acceleration\napproach to accelerating other optimization algorithms than ALS applied to\nother non-convex problems, such as Tucker tensor decomposition. Our Matlab code\nis available at\nhttps://github.com/hansdesterck/nonlinear-preconditioning-for-optimization.\n", "versions": [{"version": "v1", "created": "Sat, 13 Oct 2018 11:51:48 GMT"}, {"version": "v2", "created": "Sun, 3 Nov 2019 15:06:23 GMT"}, {"version": "v3", "created": "Sat, 30 Nov 2019 18:06:13 GMT"}], "update_date": "2019-12-03", "authors_parsed": [["Mitchell", "Drew", ""], ["Ye", "Nan", ""], ["De Sterck", "Hans", ""]]}, {"id": "1810.05868", "submitter": "Kyeong Soo (Joseph) Kim", "authors": "Kyeong Soo Kim", "title": "Hybrid Building/Floor Classification and Location Coordinates Regression\n  Using A Single-Input and Multi-Output Deep Neural Network for Large-Scale\n  Indoor Localization Based on Wi-Fi Fingerprinting", "comments": "6 pages, 4 figures, 3rd International Workshop on GPU Computing and\n  AI (GCA'18)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we propose hybrid building/floor classification and\nfloor-level two-dimensional location coordinates regression using a\nsingle-input and multi-output (SIMO) deep neural network (DNN) for large-scale\nindoor localization based on Wi-Fi fingerprinting. The proposed scheme exploits\nthe different nature of the estimation of building/floor and floor-level\nlocation coordinates and uses a different estimation framework for each task\nwith a dedicated output and hidden layers enabled by SIMO DNN architecture. We\ncarry out preliminary evaluation of the performance of the hybrid floor\nclassification and floor-level two-dimensional location coordinates regression\nusing new Wi-Fi crowdsourced fingerprinting datasets provided by Tampere\nUniversity of Technology (TUT), Finland, covering a single building with five\nfloors. Experimental results demonstrate that the proposed SIMO-DNN-based\nhybrid classification/regression scheme outperforms existing schemes in terms\nof both floor detection rate and mean positioning errors.\n", "versions": [{"version": "v1", "created": "Sat, 13 Oct 2018 14:39:20 GMT"}], "update_date": "2018-10-16", "authors_parsed": [["Kim", "Kyeong Soo", ""]]}, {"id": "1810.05893", "submitter": "Mehran Soltani", "authors": "Mehran Soltani, Vahid Pourahmadi, Ali Mirzaei, Hamid Sheikhzadeh", "title": "Deep Learning-Based Channel Estimation", "comments": "4 pages , 5 figures , Accepted for publication in the IEEE\n  Communications Letters", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IT cs.LG eess.SP math.IT stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we present a deep learning (DL) algorithm for channel\nestimation in communication systems. We consider the time-frequency response of\na fast fading communication channel as a two-dimensional image. The aim is to\nfind the unknown values of the channel response using some known values at the\npilot locations. To this end, a general pipeline using deep image processing\ntechniques, image super-resolution (SR) and image restoration (IR) is proposed.\nThis scheme considers the pilot values, altogether, as a low-resolution image\nand uses an SR network cascaded with a denoising IR network to estimate the\nchannel. Moreover, an implementation of the proposed pipeline is presented. The\nestimation error shows that the presented algorithm is comparable to the\nminimum mean square error (MMSE) with full knowledge of the channel statistics\nand it is better than ALMMSE (an approximation to linear MMSE). The results\nconfirm that this pipeline can be used efficiently in channel estimation.\n", "versions": [{"version": "v1", "created": "Sat, 13 Oct 2018 17:08:52 GMT"}, {"version": "v2", "created": "Wed, 16 Jan 2019 20:25:48 GMT"}, {"version": "v3", "created": "Sat, 16 Feb 2019 14:41:24 GMT"}, {"version": "v4", "created": "Tue, 19 Feb 2019 09:42:45 GMT"}], "update_date": "2019-02-20", "authors_parsed": [["Soltani", "Mehran", ""], ["Pourahmadi", "Vahid", ""], ["Mirzaei", "Ali", ""], ["Sheikhzadeh", "Hamid", ""]]}, {"id": "1810.05934", "submitter": "Liam Li", "authors": "Liam Li, Kevin Jamieson, Afshin Rostamizadeh, Ekaterina Gonina, Moritz\n  Hardt, Benjamin Recht, Ameet Talwalkar", "title": "A System for Massively Parallel Hyperparameter Tuning", "comments": "v2: Corrected typo in Algorithm 1 v3: Added comparison to BOHB and\n  parallel version of synchronous SHA. Add PBT to experiment in Section 4.3.1\n  v4: Added acknowledgements and slight edit to related work", "journal-ref": "Conference on Machine Learning and Systems 2020", "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Modern learning models are characterized by large hyperparameter spaces and\nlong training times. These properties, coupled with the rise of parallel\ncomputing and the growing demand to productionize machine learning workloads,\nmotivate the need to develop mature hyperparameter optimization functionality\nin distributed computing settings. We address this challenge by first\nintroducing a simple and robust hyperparameter optimization algorithm called\nASHA, which exploits parallelism and aggressive early-stopping to tackle\nlarge-scale hyperparameter optimization problems. Our extensive empirical\nresults show that ASHA outperforms existing state-of-the-art hyperparameter\noptimization methods; scales linearly with the number of workers in distributed\nsettings; and is suitable for massive parallelism, as demonstrated on a task\nwith 500 workers. We then describe several design decisions we encountered,\nalong with our associated solutions, when integrating ASHA in Determined AI's\nend-to-end production-quality machine learning system that offers\nhyperparameter tuning as a service.\n", "versions": [{"version": "v1", "created": "Sat, 13 Oct 2018 22:02:52 GMT"}, {"version": "v2", "created": "Wed, 17 Oct 2018 00:23:57 GMT"}, {"version": "v3", "created": "Thu, 29 Nov 2018 04:41:42 GMT"}, {"version": "v4", "created": "Wed, 23 Jan 2019 02:15:22 GMT"}, {"version": "v5", "created": "Mon, 16 Mar 2020 01:28:21 GMT"}], "update_date": "2020-03-17", "authors_parsed": [["Li", "Liam", ""], ["Jamieson", "Kevin", ""], ["Rostamizadeh", "Afshin", ""], ["Gonina", "Ekaterina", ""], ["Hardt", "Moritz", ""], ["Recht", "Benjamin", ""], ["Talwalkar", "Ameet", ""]]}, {"id": "1810.05986", "submitter": "Zirui Wang", "authors": "Zirui Wang", "title": "Theoretical Guarantees of Transfer Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Transfer learning has been proven effective when within-target labeled data\nis scarce. A lot of works have developed successful algorithms and empirically\nobserved positive transfer effect that improves target generalization error\nusing source knowledge. However, theoretical analysis of transfer learning is\nmore challenging due to the nature of the problem and thus is less studied. In\nthis report, we do a survey of theoretical works in transfer learning and\nsummarize key theoretical guarantees that prove the effectiveness of transfer\nlearning. The theoretical bounds are derived using model complexity and\nlearning algorithm stability. As we should see, these works exhibit a trade-off\nbetween tight bounds and restrictive assumptions. Moreover, we also prove a new\ngeneralization bound for the multi-source transfer learning problem using the\nVC-theory, which is more informative than the one proved in previous work.\n", "versions": [{"version": "v1", "created": "Sun, 14 Oct 2018 07:19:27 GMT"}, {"version": "v2", "created": "Sat, 24 Nov 2018 02:15:28 GMT"}], "update_date": "2018-11-27", "authors_parsed": [["Wang", "Zirui", ""]]}, {"id": "1810.05992", "submitter": "Satoshi Hara", "authors": "Satoshi Hara, Takanori Maehara", "title": "Convex Hull Approximation of Nearly Optimal Lasso Solutions", "comments": "14pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In an ordinary feature selection procedure, a set of important features is\nobtained by solving an optimization problem such as the Lasso regression\nproblem, and we expect that the obtained features explain the data well. In\nthis study, instead of the single optimal solution, we consider finding a set\nof diverse yet nearly optimal solutions. To this end, we formulate the problem\nas finding a small number of solutions such that the convex hull of these\nsolutions approximates the set of nearly optimal solutions. The proposed\nalgorithm consists of two steps: First, we randomly sample the extreme points\nof the set of nearly optimal solutions. Then, we select a small number of\npoints using a greedy algorithm. The experimental results indicate that the\nproposed algorithm can approximate the solution set well. The results also\nindicate that we can obtain Lasso solutions with a large diversity.\n", "versions": [{"version": "v1", "created": "Sun, 14 Oct 2018 08:10:54 GMT"}], "update_date": "2018-10-16", "authors_parsed": [["Hara", "Satoshi", ""], ["Maehara", "Takanori", ""]]}, {"id": "1810.05993", "submitter": "Boris Ivanovic", "authors": "Boris Ivanovic and Marco Pavone", "title": "The Trajectron: Probabilistic Multi-Agent Trajectory Modeling With\n  Dynamic Spatiotemporal Graphs", "comments": "IEEE/CVF International Conference on Computer Vision (ICCV) 2019 --\n  10 pages, 10 figures, 2 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.HC cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Developing safe human-robot interaction systems is a necessary step towards\nthe widespread integration of autonomous agents in society. A key component of\nsuch systems is the ability to reason about the many potential futures (e.g.\ntrajectories) of other agents in the scene. Towards this end, we present the\nTrajectron, a graph-structured model that predicts many potential future\ntrajectories of multiple agents simultaneously in both highly dynamic and\nmultimodal scenarios (i.e. where the number of agents in the scene is\ntime-varying and there are many possible highly-distinct futures for each\nagent). It combines tools from recurrent sequence modeling and variational deep\ngenerative modeling to produce a distribution of future trajectories for each\nagent in a scene. We demonstrate the performance of our model on several\ndatasets, obtaining state-of-the-art results on standard trajectory prediction\nmetrics as well as introducing a new metric for comparing models that output\ndistributions.\n", "versions": [{"version": "v1", "created": "Sun, 14 Oct 2018 08:11:03 GMT"}, {"version": "v2", "created": "Wed, 24 Apr 2019 05:56:45 GMT"}, {"version": "v3", "created": "Fri, 23 Aug 2019 23:12:48 GMT"}], "update_date": "2019-08-27", "authors_parsed": [["Ivanovic", "Boris", ""], ["Pavone", "Marco", ""]]}, {"id": "1810.05997", "submitter": "Johannes Klicpera", "authors": "Johannes Klicpera, Aleksandar Bojchevski, Stephan G\\\"unnemann", "title": "Predict then Propagate: Graph Neural Networks meet Personalized PageRank", "comments": "Published as a conference paper at ICLR 2019", "journal-ref": "International Conference on Learning Representations (ICLR), New\n  Orleans, LA, USA, 2019", "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Neural message passing algorithms for semi-supervised classification on\ngraphs have recently achieved great success. However, for classifying a node\nthese methods only consider nodes that are a few propagation steps away and the\nsize of this utilized neighborhood is hard to extend. In this paper, we use the\nrelationship between graph convolutional networks (GCN) and PageRank to derive\nan improved propagation scheme based on personalized PageRank. We utilize this\npropagation procedure to construct a simple model, personalized propagation of\nneural predictions (PPNP), and its fast approximation, APPNP. Our model's\ntraining time is on par or faster and its number of parameters on par or lower\nthan previous models. It leverages a large, adjustable neighborhood for\nclassification and can be easily combined with any neural network. We show that\nthis model outperforms several recently proposed methods for semi-supervised\nclassification in the most thorough study done so far for GCN-like models. Our\nimplementation is available online.\n", "versions": [{"version": "v1", "created": "Sun, 14 Oct 2018 08:36:54 GMT"}, {"version": "v2", "created": "Tue, 13 Nov 2018 13:50:58 GMT"}, {"version": "v3", "created": "Sat, 24 Nov 2018 11:38:20 GMT"}, {"version": "v4", "created": "Fri, 22 Feb 2019 21:09:06 GMT"}, {"version": "v5", "created": "Wed, 27 Feb 2019 10:26:24 GMT"}], "update_date": "2019-03-29", "authors_parsed": [["Klicpera", "Johannes", ""], ["Bojchevski", "Aleksandar", ""], ["G\u00fcnnemann", "Stephan", ""]]}, {"id": "1810.06021", "submitter": "Alejandro Alcalde-Barros", "authors": "Alejandro Alcalde-Barros, Diego Garc\\'ia-Gil, Salvador Garc\\'ia,\n  Francisco Herrera", "title": "DPASF: A Flink Library for Streaming Data preprocessing", "comments": "19 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DB cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Data preprocessing techniques are devoted to correct or alleviate errors in\ndata. Discretization and feature selection are two of the most extended data\npreprocessing techniques. Although we can find many proposals for static Big\nData preprocessing, there is little research devoted to the continuous Big Data\nproblem. Apache Flink is a recent and novel Big Data framework, following the\nMapReduce paradigm, focused on distributed stream and batch data processing. In\nthis paper we propose a data stream library for Big Data preprocessing, named\nDPASF, under Apache Flink. We have implemented six of the most popular data\npreprocessing algorithms, three for discretization and the rest for feature\nselection. The algorithms have been tested using two Big Data datasets.\nExperimental results show that preprocessing can not only reduce the size of\nthe data, but to maintain or even improve the original accuracy in a short\ntime. DPASF contains useful algorithms when dealing with Big Data data streams.\nThe preprocessing algorithms included in the library are able to tackle Big\nDatasets efficiently and to correct imperfections in the data.\n", "versions": [{"version": "v1", "created": "Sun, 14 Oct 2018 11:59:18 GMT"}], "update_date": "2018-10-16", "authors_parsed": [["Alcalde-Barros", "Alejandro", ""], ["Garc\u00eda-Gil", "Diego", ""], ["Garc\u00eda", "Salvador", ""], ["Herrera", "Francisco", ""]]}, {"id": "1810.06049", "submitter": "Dor Bank", "authors": "Dor Bank and Raja Giryes", "title": "An ETF view of Dropout regularization", "comments": "Accepted to BMVC 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.IT math.IT stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Dropout is a popular regularization technique in deep learning. Yet, the\nreason for its success is still not fully understood. This paper provides a new\ninterpretation of Dropout from a frame theory perspective. By drawing a\nconnection to recent developments in analog channel coding, we suggest that for\na certain family of autoencoders with a linear encoder, optimizing the encoder\nwith dropout regularization leads to an equiangular tight frame (ETF). Since\nthis optimization is non-convex, we add another regularization that promotes\nsuch structures by minimizing the cross-correlation between filters in the\nnetwork. We demonstrate its applicability in convolutional and fully connected\nlayers in both feed-forward and recurrent networks. All these results suggest\nthat there is indeed a relationship between dropout and ETF structure of the\nregularized linear operations.\n", "versions": [{"version": "v1", "created": "Sun, 14 Oct 2018 15:50:21 GMT"}, {"version": "v2", "created": "Wed, 9 Jan 2019 18:20:17 GMT"}, {"version": "v3", "created": "Fri, 8 Feb 2019 12:40:11 GMT"}, {"version": "v4", "created": "Wed, 19 Aug 2020 09:12:27 GMT"}], "update_date": "2020-08-20", "authors_parsed": [["Bank", "Dor", ""], ["Giryes", "Raja", ""]]}, {"id": "1810.06060", "submitter": "Otkrist Gupta", "authors": "Otkrist Gupta and Ramesh Raskar", "title": "Distributed learning of deep neural network over multiple agents", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In domains such as health care and finance, shortage of labeled data and\ncomputational resources is a critical issue while developing machine learning\nalgorithms. To address the issue of labeled data scarcity in training and\ndeployment of neural network-based systems, we propose a new technique to train\ndeep neural networks over several data sources. Our method allows for deep\nneural networks to be trained using data from multiple entities in a\ndistributed fashion. We evaluate our algorithm on existing datasets and show\nthat it obtains performance which is similar to a regular neural network\ntrained on a single machine. We further extend it to incorporate\nsemi-supervised learning when training with few labeled samples, and analyze\nany security concerns that may arise. Our algorithm paves the way for\ndistributed training of deep neural networks in data sensitive applications\nwhen raw data may not be shared directly.\n", "versions": [{"version": "v1", "created": "Sun, 14 Oct 2018 16:57:10 GMT"}], "update_date": "2018-10-16", "authors_parsed": [["Gupta", "Otkrist", ""], ["Raskar", "Ramesh", ""]]}, {"id": "1810.06071", "submitter": "Sarfaraz Hussein", "authors": "Ismail Irmakci, Sarfaraz Hussein, Aydogan Savran, Rita R. Kalyani,\n  David Reiter, Chee W. Chia, Kenneth W. Fishbein, Richard G. Spencer, Luigi\n  Ferrucci and Ulas Bagci", "title": "A Novel Extension to Fuzzy Connectivity for Body Composition Analysis:\n  Applications in Thigh, Brain, and Whole Body Tissue Segmentation", "comments": "In press for IEEE Transactions on Biomedical Engineering (TBME)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG q-bio.QM q-bio.TO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Magnetic resonance imaging (MRI) is the non-invasive modality of choice for\nbody tissue composition analysis due to its excellent soft tissue contrast and\nlack of ionizing radiation. However, quantification of body composition\nrequires an accurate segmentation of fat, muscle and other tissues from MR\nimages, which remains a challenging goal due to the intensity overlap between\nthem. In this study, we propose a fully automated, data-driven image\nsegmentation platform that addresses multiple difficulties in segmenting MR\nimages such as varying inhomogeneity, non-standardness, and noise, while\nproducing high-quality definition of different tissues. In contrast to most\napproaches in the literature, we perform segmentation operation by combining\nthree different MRI contrasts and a novel segmentation tool which takes into\naccount variability in the data. The proposed system, based on a novel affinity\ndefinition within the fuzzy connectivity (FC) image segmentation family,\nprevents the need for user intervention and reparametrization of the\nsegmentation algorithms. In order to make the whole system fully automated, we\nadapt an affinity propagation clustering algorithm to roughly identify tissue\nregions and image background. We perform a thorough evaluation of the proposed\nalgorithm's individual steps as well as comparison with several approaches from\nthe literature for the main application of muscle/fat separation. Furthermore,\nwhole-body tissue composition and brain tissue delineation were conducted to\nshow the generalization ability of the proposed system. This new automated\nplatform outperforms other state-of-the-art segmentation approaches both in\naccuracy and efficiency.\n", "versions": [{"version": "v1", "created": "Sun, 14 Oct 2018 17:53:44 GMT"}], "update_date": "2018-10-16", "authors_parsed": [["Irmakci", "Ismail", ""], ["Hussein", "Sarfaraz", ""], ["Savran", "Aydogan", ""], ["Kalyani", "Rita R.", ""], ["Reiter", "David", ""], ["Chia", "Chee W.", ""], ["Fishbein", "Kenneth W.", ""], ["Spencer", "Richard G.", ""], ["Ferrucci", "Luigi", ""], ["Bagci", "Ulas", ""]]}, {"id": "1810.06089", "submitter": "Edgar Dobriban", "authors": "Edgar Dobriban, Sifan Liu", "title": "Asymptotics for Sketching in Least Squares Regression", "comments": null, "journal-ref": "Updated manuscript to be consistent with version at NeurIPS 2019", "doi": null, "report-no": null, "categories": "math.ST cs.LG cs.NA math.NA stat.ME stat.ML stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider a least squares regression problem where the data has been\ngenerated from a linear model, and we are interested to learn the unknown\nregression parameters. We consider \"sketch-and-solve\" methods that randomly\nproject the data first, and do regression after. Previous works have analyzed\nthe statistical and computational performance of such methods. However, the\nexisting analysis is not fine-grained enough to show the fundamental\ndifferences between various methods, such as the Subsampled Randomized Hadamard\nTransform (SRHT) and Gaussian projections. In this paper, we make progress on\nthis problem, working in an asymptotic framework where the number of datapoints\nand dimension of features goes to infinity. We find the limits of the accuracy\nloss (for estimation and test error) incurred by popular sketching methods. We\nshow separation between different methods, so that SRHT is better than Gaussian\nprojections. Our theoretical results are verified on both real and synthetic\ndata. The analysis of SRHT relies on novel methods from random matrix theory\nthat may be of independent interest.\n", "versions": [{"version": "v1", "created": "Sun, 14 Oct 2018 19:48:05 GMT"}, {"version": "v2", "created": "Sun, 6 Oct 2019 19:25:12 GMT"}], "update_date": "2019-10-08", "authors_parsed": [["Dobriban", "Edgar", ""], ["Liu", "Sifan", ""]]}, {"id": "1810.06115", "submitter": "Yunseong Lee", "authors": "Yunseong Lee, Alberto Scolari, Byung-Gon Chun, Marco Domenico\n  Santambrogio, Markus Weimer, Matteo Interlandi", "title": "PRETZEL: Opening the Black Box of Machine Learning Prediction Serving\n  Systems", "comments": "16 pages, 14 figures, 13th USENIX Symposium on Operating Systems\n  Design and Implementation (OSDI), 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.DC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Machine Learning models are often composed of pipelines of transformations.\nWhile this design allows to efficiently execute single model components at\ntraining time, prediction serving has different requirements such as low\nlatency, high throughput and graceful performance degradation under heavy load.\nCurrent prediction serving systems consider models as black boxes, whereby\nprediction-time-specific optimizations are ignored in favor of ease of\ndeployment. In this paper, we present PRETZEL, a prediction serving system\nintroducing a novel white box architecture enabling both end-to-end and\nmulti-model optimizations. Using production-like model pipelines, our\nexperiments show that PRETZEL is able to introduce performance improvements\nover different dimensions; compared to state-of-the-art approaches PRETZEL is\non average able to reduce 99th percentile latency by 5.5x while reducing memory\nfootprint by 25x, and increasing throughput by 4.7x.\n", "versions": [{"version": "v1", "created": "Sun, 14 Oct 2018 22:21:30 GMT"}], "update_date": "2018-10-16", "authors_parsed": [["Lee", "Yunseong", ""], ["Scolari", "Alberto", ""], ["Chun", "Byung-Gon", ""], ["Santambrogio", "Marco Domenico", ""], ["Weimer", "Markus", ""], ["Interlandi", "Matteo", ""]]}, {"id": "1810.06118", "submitter": "Allon G. Percus", "authors": "Max Schwarzer, Bryce Rogan, Yadong Ruan, Zhengming Song, Diana Y. Lee,\n  Allon G. Percus, Viet T. Chau, Bryan A. Moore, Esteban Rougier, Hari S.\n  Viswanathan, Gowri Srinivasan", "title": "Learning to fail: Predicting fracture evolution in brittle material\n  models using recurrent graph convolutional neural networks", "comments": null, "journal-ref": "Computational Materials Science 162, 322-332 (2019)", "doi": "10.1016/j.commatsci.2019.02.046", "report-no": "LA-UR-18-29693", "categories": "cond-mat.mtrl-sci cs.LG physics.data-an stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a machine learning approach to address a key challenge in\nmaterials science: predicting how fractures propagate in brittle materials\nunder stress, and how these materials ultimately fail. Our methods use deep\nlearning and train on simulation data from high-fidelity models, emulating the\nresults of these models while avoiding the overwhelming computational demands\nassociated with running a statistically significant sample of simulations. We\nemploy a graph convolutional network that recognizes features of the fracturing\nmaterial and a recurrent neural network that models the evolution of these\nfeatures, along with a novel form of data augmentation that compensates for the\nmodest size of our training data. We simultaneously generate predictions for\nqualitatively distinct material properties. Results on fracture damage and\nlength are within 3% of their simulated values, and results on time to material\nfailure, which is notoriously difficult to predict even with high-fidelity\nmodels, are within approximately 15% of simulated values. Once trained, our\nneural networks generate predictions within seconds, rather than the hours\nneeded to run a single simulation.\n", "versions": [{"version": "v1", "created": "Sun, 14 Oct 2018 22:38:18 GMT"}, {"version": "v2", "created": "Fri, 1 Mar 2019 05:21:55 GMT"}, {"version": "v3", "created": "Fri, 15 Mar 2019 05:28:02 GMT"}], "update_date": "2019-03-18", "authors_parsed": [["Schwarzer", "Max", ""], ["Rogan", "Bryce", ""], ["Ruan", "Yadong", ""], ["Song", "Zhengming", ""], ["Lee", "Diana Y.", ""], ["Percus", "Allon G.", ""], ["Chau", "Viet T.", ""], ["Moore", "Bryan A.", ""], ["Rougier", "Esteban", ""], ["Viswanathan", "Hari S.", ""], ["Srinivasan", "Gowri", ""]]}, {"id": "1810.06120", "submitter": "Enzhi Li", "authors": "Yiwei Li, Enzhi Li", "title": "Variational Neural Networks: Every Layer and Neuron Can Be Unique", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The choice of activation function can significantly influence the performance\nof neural networks. The lack of guiding principles for the selection of\nactivation function is lamentable. We try to address this issue by introducing\nour variational neural networks, where the activation function is represented\nas a linear combination of possible candidate functions, and an optimal\nactivation is obtained via minimization of a loss function using gradient\ndescent method. The gradient formulae for the loss function with respect to\nthese expansion coefficients are central for the implementation of gradient\ndescent algorithm, and here we derive these gradient formulae.\n", "versions": [{"version": "v1", "created": "Sun, 14 Oct 2018 22:41:11 GMT"}], "update_date": "2018-10-16", "authors_parsed": [["Li", "Yiwei", ""], ["Li", "Enzhi", ""]]}, {"id": "1810.06175", "submitter": "Xuezhou Zhang", "authors": "Laurent Lessard, Xuezhou Zhang, Xiaojin Zhu", "title": "An Optimal Control Approach to Sequential Machine Teaching", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.SY math.OC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Given a sequential learning algorithm and a target model, sequential machine\nteaching aims to find the shortest training sequence to drive the learning\nalgorithm to the target model. We present the first principled way to find such\nshortest training sequences. Our key insight is to formulate sequential machine\nteaching as a time-optimal control problem. This allows us to solve sequential\nteaching by leveraging key theoretical and computational tools developed over\nthe past 60 years in the optimal control community. Specifically, we study the\nPontryagin Maximum Principle, which yields a necessary condition for optimality\nof a training sequence. We present analytic, structural, and numerical\nimplications of this approach on a case study with a least-squares loss\nfunction and gradient descent learner. We compute optimal training sequences\nfor this problem, and although the sequences seem circuitous, we find that they\ncan vastly outperform the best available heuristics for generating training\nsequences.\n", "versions": [{"version": "v1", "created": "Mon, 15 Oct 2018 04:18:39 GMT"}, {"version": "v2", "created": "Tue, 16 Oct 2018 04:13:27 GMT"}], "update_date": "2018-10-17", "authors_parsed": [["Lessard", "Laurent", ""], ["Zhang", "Xuezhou", ""], ["Zhu", "Xiaojin", ""]]}, {"id": "1810.06177", "submitter": "Xiangru Lian", "authors": "Xiangru Lian, Ji Liu", "title": "Revisit Batch Normalization: New Understanding from an Optimization View\n  and a Refinement via Composition Optimization", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.OC cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Batch Normalization (BN) has been used extensively in deep learning to\nachieve faster training process and better resulting models. However, whether\nBN works strongly depends on how the batches are constructed during training\nand it may not converge to a desired solution if the statistics on a batch are\nnot close to the statistics over the whole dataset. In this paper, we try to\nunderstand BN from an optimization perspective by formulating the optimization\nproblem which motivates BN. We show when BN works and when BN does not work by\nanalyzing the optimization problem. We then propose a refinement of BN based on\ncompositional optimization techniques called Full Normalization (FN) to\nalleviate the issues of BN when the batches are not constructed ideally. We\nprovide convergence analysis for FN and empirically study its effectiveness to\nrefine BN.\n", "versions": [{"version": "v1", "created": "Mon, 15 Oct 2018 04:33:53 GMT"}], "update_date": "2018-10-16", "authors_parsed": [["Lian", "Xiangru", ""], ["Liu", "Ji", ""]]}, {"id": "1810.06207", "submitter": "Matthew J. Holland", "authors": "Matthew J. Holland", "title": "Robust descent using smoothed multiplicative noise", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  To improve the off-sample generalization of classical procedures minimizing\nthe empirical risk under potentially heavy-tailed data, new robust learning\nalgorithms have been proposed in recent years, with generalized median-of-means\nstrategies being particularly salient. These procedures enjoy performance\nguarantees in the form of sharp risk bounds under weak moment assumptions on\nthe underlying loss, but typically suffer from a large computational overhead\nand substantial bias when the data happens to be sub-Gaussian, limiting their\nutility. In this work, we propose a novel robust gradient descent procedure\nwhich makes use of a smoothed multiplicative noise applied directly to\nobservations before constructing a sum of soft-truncated gradient coordinates.\nWe show that the procedure has competitive theoretical guarantees, with the\nmajor advantage of a simple implementation that does not require an iterative\nsub-routine for robustification. Empirical tests reinforce the theory, showing\nmore efficient generalization over a much wider class of data distributions.\n", "versions": [{"version": "v1", "created": "Mon, 15 Oct 2018 07:38:12 GMT"}], "update_date": "2018-10-16", "authors_parsed": [["Holland", "Matthew J.", ""]]}, {"id": "1810.06240", "submitter": "Malte Renken", "authors": "Vincent Froese, Brijnesh Jain, Rolf Niedermeier, Malte Renken", "title": "Comparing Temporal Graphs Using Dynamic Time Warping", "comments": null, "journal-ref": null, "doi": "10.1007/s13278-020-00664-5", "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Within many real-world networks the links between pairs of nodes change over\ntime. Thus, there has been a recent boom in studying temporal graphs.\nRecognizing patterns in temporal graphs requires a proximity measure to compare\ndifferent temporal graphs. To this end, we propose to study dynamic time\nwarping on temporal graphs. We define the dynamic temporal graph warping\ndistance (dtgw) to determine the dissimilarity of two temporal graphs. Our\nnovel measure is flexible and can be applied in various application domains. We\nshow that computing the dtgw-distance is a challenging (in general) NP-hard\noptimization problem and identify some polynomial-time solvable special cases.\nMoreover, we develop a quadratic programming formulation and an efficient\nheuristic. In experiments on real-word data we show that the heuristic performs\nvery well and that our dtgw-distance performs favorably in de-anonymizing\nnetworks compared to other approaches.\n", "versions": [{"version": "v1", "created": "Mon, 15 Oct 2018 09:21:36 GMT"}, {"version": "v2", "created": "Mon, 26 Aug 2019 13:39:14 GMT"}, {"version": "v3", "created": "Mon, 9 Mar 2020 08:57:12 GMT"}, {"version": "v4", "created": "Mon, 6 Jul 2020 12:41:12 GMT"}], "update_date": "2020-07-07", "authors_parsed": [["Froese", "Vincent", ""], ["Jain", "Brijnesh", ""], ["Niedermeier", "Rolf", ""], ["Renken", "Malte", ""]]}, {"id": "1810.06282", "submitter": "Aiga Suzuki", "authors": "Aiga Suzuki, Hidenori Sakanashi, Shoji Kido, Hayaru Shouno", "title": "Feature Representation Analysis of Deep Convolutional Neural Network\n  using Two-stage Feature Transfer -An Application for Diffuse Lung Disease\n  Classification-", "comments": "Preprint of the journal article to be published in IPSJ TOM-51.\n  Notice for the use of this material The copyright of this material is\n  retained by the Information Processing Society of Japan (IPSJ). This material\n  is published on this web site with the agreement of the author (s) and the\n  IPSJ", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Transfer learning is a machine learning technique designed to improve\ngeneralization performance by using pre-trained parameters obtained from other\nlearning tasks. For image recognition tasks, many previous studies have\nreported that, when transfer learning is applied to deep neural networks,\nperformance improves, despite having limited training data. This paper proposes\na two-stage feature transfer learning method focusing on the recognition of\ntextural medical images. During the proposed method, a model is successively\ntrained with massive amounts of natural images, some textural images, and the\ntarget images. We applied this method to the classification task of textural\nX-ray computed tomography images of diffuse lung diseases. In our experiment,\nthe two-stage feature transfer achieves the best performance compared to a\nfrom-scratch learning and a conventional single-stage feature transfer. We also\ninvestigated the robustness of the target dataset, based on size. Two-stage\nfeature transfer shows better robustness than the other two learning methods.\nMoreover, we analyzed the feature representations obtained from DLDs imagery\ninputs for each feature transfer models using a visualization method. We showed\nthat the two-stage feature transfer obtains both edge and textural features of\nDLDs, which does not occur in conventional single-stage feature transfer\nmodels.\n", "versions": [{"version": "v1", "created": "Mon, 15 Oct 2018 11:35:34 GMT"}], "update_date": "2018-10-16", "authors_parsed": [["Suzuki", "Aiga", ""], ["Sakanashi", "Hidenori", ""], ["Kido", "Shoji", ""], ["Shouno", "Hayaru", ""]]}, {"id": "1810.06291", "submitter": "Mastane Achab", "authors": "Mastane Achab, Anna Korba, Stephan Cl\\'emen\\c{c}on", "title": "Dimensionality Reduction and (Bucket) Ranking: a Mass Transportation\n  Approach", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Whereas most dimensionality reduction techniques (e.g. PCA, ICA, NMF) for\nmultivariate data essentially rely on linear algebra to a certain extent,\nsummarizing ranking data, viewed as realizations of a random permutation\n$\\Sigma$ on a set of items indexed by $i\\in \\{1,\\ldots,\\; n\\}$, is a great\nstatistical challenge, due to the absence of vector space structure for the set\nof permutations $\\mathfrak{S}_n$. It is the goal of this article to develop an\noriginal framework for possibly reducing the number of parameters required to\ndescribe the distribution of a statistical population composed of\nrankings/permutations, on the premise that the collection of items under study\ncan be partitioned into subsets/buckets, such that, with high probability,\nitems in a certain bucket are either all ranked higher or else all ranked lower\nthan items in another bucket. In this context, $\\Sigma$'s distribution can be\nhopefully represented in a sparse manner by a bucket distribution, i.e. a\nbucket ordering plus the ranking distributions within each bucket. More\nprecisely, we introduce a dedicated distortion measure, based on a mass\ntransportation metric, in order to quantify the accuracy of such\nrepresentations. The performance of buckets minimizing an empirical version of\nthe distortion is investigated through a rate bound analysis. Complexity\npenalization techniques are also considered to select the shape of a bucket\norder with minimum expected distortion. Beyond theoretical concepts and\nresults, numerical experiments on real ranking data are displayed in order to\nprovide empirical evidence of the relevance of the approach promoted.\n", "versions": [{"version": "v1", "created": "Mon, 15 Oct 2018 11:55:07 GMT"}, {"version": "v2", "created": "Fri, 30 Aug 2019 11:29:59 GMT"}], "update_date": "2019-09-02", "authors_parsed": [["Achab", "Mastane", ""], ["Korba", "Anna", ""], ["Cl\u00e9men\u00e7on", "Stephan", ""]]}, {"id": "1810.06305", "submitter": "Ho Chung Leon Law", "authors": "Ho Chung Leon Law, Peilin Zhao, Lucian Chan, Junzhou Huang and Dino\n  Sejdinovic", "title": "Hyperparameter Learning via Distributional Transfer", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Bayesian optimisation is a popular technique for hyperparameter learning but\ntypically requires initial exploration even in cases where similar prior tasks\nhave been solved. We propose to transfer information across tasks using learnt\nrepresentations of training datasets used in those tasks. This results in a\njoint Gaussian process model on hyperparameters and data representations.\nRepresentations make use of the framework of distribution embeddings into\nreproducing kernel Hilbert spaces. The developed method has a faster\nconvergence compared to existing baselines, in some cases requiring only a few\nevaluations of the target objective.\n", "versions": [{"version": "v1", "created": "Mon, 15 Oct 2018 12:31:20 GMT"}, {"version": "v2", "created": "Sat, 9 Mar 2019 10:04:26 GMT"}, {"version": "v3", "created": "Sun, 26 May 2019 13:48:03 GMT"}], "update_date": "2019-05-28", "authors_parsed": [["Law", "Ho Chung Leon", ""], ["Zhao", "Peilin", ""], ["Chan", "Lucian", ""], ["Huang", "Junzhou", ""], ["Sejdinovic", "Dino", ""]]}, {"id": "1810.06306", "submitter": "Dat Quoc Nguyen", "authors": "Dat Quoc Nguyen, Richard Billingsley, Lan Du, Mark Johnson", "title": "Improving Topic Models with Latent Feature Word Representations", "comments": "The published version is available at:\n  https://transacl.org/ojs/index.php/tacl/article/view/582 ; The source code is\n  available at: https://github.com/datquocnguyen/LFTM", "journal-ref": "Transactions of the Association for Computational Linguistics,\n  vol. 3, pp. 299-313, 2015", "doi": null, "report-no": null, "categories": "cs.CL cs.IR cs.LG", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Probabilistic topic models are widely used to discover latent topics in\ndocument collections, while latent feature vector representations of words have\nbeen used to obtain high performance in many NLP tasks. In this paper, we\nextend two different Dirichlet multinomial topic models by incorporating latent\nfeature vector representations of words trained on very large corpora to\nimprove the word-topic mapping learnt on a smaller corpus. Experimental results\nshow that by using information from the external corpora, our new models\nproduce significant improvements on topic coherence, document clustering and\ndocument classification tasks, especially on datasets with few or short\ndocuments.\n", "versions": [{"version": "v1", "created": "Mon, 15 Oct 2018 12:34:05 GMT"}], "update_date": "2018-10-16", "authors_parsed": [["Nguyen", "Dat Quoc", ""], ["Billingsley", "Richard", ""], ["Du", "Lan", ""], ["Johnson", "Mark", ""]]}, {"id": "1810.06313", "submitter": "Linqi Song", "authors": "Linqi Song, Christina Fragouli, Devavrat Shah", "title": "Regret vs. Bandwidth Trade-off for Recommendation Systems", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider recommendation systems that need to operate under wireless\nbandwidth constraints, measured as number of broadcast transmissions, and\ndemonstrate a (tight for some instances) tradeoff between regret and bandwidth\nfor two scenarios: the case of multi-armed bandit with context, and the case\nwhere there is a latent structure in the message space that we can exploit to\nreduce the learning phase.\n", "versions": [{"version": "v1", "created": "Mon, 15 Oct 2018 12:41:25 GMT"}], "update_date": "2018-10-16", "authors_parsed": [["Song", "Linqi", ""], ["Fragouli", "Christina", ""], ["Shah", "Devavrat", ""]]}, {"id": "1810.06323", "submitter": "Mehmet Yamac", "authors": "Aysen Degerli, Sinem Aslan, Mehmet Yamac, Bulent Sankur, Moncef\n  Gabbouj", "title": "Compressively Sensed Image Recognition", "comments": "6 pages, submitted/accepted, EUVIP 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV eess.IV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Compressive Sensing (CS) theory asserts that sparse signal reconstruction is\npossible from a small number of linear measurements. Although CS enables\nlow-cost linear sampling, it requires non-linear and costly reconstruction.\nRecent literature works show that compressive image classification is possible\nin CS domain without reconstruction of the signal. In this work, we introduce a\nDCT base method that extracts binary discriminative features directly from CS\nmeasurements. These CS measurements can be obtained by using (i) a random or a\npseudo-random measurement matrix, or (ii) a measurement matrix whose elements\nare learned from the training data to optimize the given classification task.\nWe further introduce feature fusion by concatenating Bag of Words (BoW)\nrepresentation of our binary features with one of the two state-of-the-art\nCNN-based feature vectors. We show that our fused feature outperforms the\nstate-of-the-art in both cases.\n", "versions": [{"version": "v1", "created": "Mon, 15 Oct 2018 12:55:10 GMT"}], "update_date": "2018-10-16", "authors_parsed": [["Degerli", "Aysen", ""], ["Aslan", "Sinem", ""], ["Yamac", "Mehmet", ""], ["Sankur", "Bulent", ""], ["Gabbouj", "Moncef", ""]]}, {"id": "1810.06339", "submitter": "Yuxi Li", "authors": "Yuxi Li", "title": "Deep Reinforcement Learning", "comments": "Under review for Morgan & Claypool: Synthesis Lectures in Artificial\n  Intelligence and Machine Learning", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We discuss deep reinforcement learning in an overview style. We draw a big\npicture, filled with details. We discuss six core elements, six important\nmechanisms, and twelve applications, focusing on contemporary work, and in\nhistorical contexts. We start with background of artificial intelligence,\nmachine learning, deep learning, and reinforcement learning (RL), with\nresources. Next we discuss RL core elements, including value function, policy,\nreward, model, exploration vs. exploitation, and representation. Then we\ndiscuss important mechanisms for RL, including attention and memory,\nunsupervised learning, hierarchical RL, multi-agent RL, relational RL, and\nlearning to learn. After that, we discuss RL applications, including games,\nrobotics, natural language processing (NLP), computer vision, finance, business\nmanagement, healthcare, education, energy, transportation, computer systems,\nand, science, engineering, and art. Finally we summarize briefly, discuss\nchallenges and opportunities, and close with an epilogue.\n", "versions": [{"version": "v1", "created": "Mon, 15 Oct 2018 13:20:56 GMT"}], "update_date": "2018-10-16", "authors_parsed": [["Li", "Yuxi", ""]]}, {"id": "1810.06376", "submitter": "Luwan Zhang", "authors": "Luwan Zhang and Tianrun Cai", "title": "Unsupervised Ensemble Learning via Ising Model Approximation with\n  Application to Phenotyping Prediction", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Unsupervised ensemble learning has long been an interesting yet challenging\nproblem that comes to prominence in recent years with the increasing demand of\ncrowdsourcing in various applications. In this paper, we propose a novel\nmethod-- unsupervised ensemble learning via Ising model approximation (unElisa)\nthat combines a pruning step with a predicting step. We focus on the binary\ncase and use an Ising model to characterize interactions between the ensemble\nand the underlying true classifier. The presence of an edge between an observed\nclassifier and the true classifier indicates a direct dependence whereas the\nabsence indicates the corresponding one provides no additional information and\nshall be eliminated. This observation leads to the pruning step where the key\nis to recover the neighborhood of the true classifier. We show that it can be\nrecovered successfully with exponentially decaying error in the\nhigh-dimensional setting by performing nodewise $\\ell_1$-regularized logistic\nregression. The pruned ensemble allows us to get a consistent estimate of the\nBayes classifier for predicting. We also propose an augmented version of\nmajority voting by reversing all labels given by a subgroup of the pruned\nensemble. We demonstrate the efficacy of our method through extensive numerical\nexperiments and through the application to EHR-based phenotyping prediction on\nRheumatoid Arthritis (RA) using data from Partners Healthcare System.\n", "versions": [{"version": "v1", "created": "Mon, 15 Oct 2018 14:27:38 GMT"}], "update_date": "2018-10-16", "authors_parsed": [["Zhang", "Luwan", ""], ["Cai", "Tianrun", ""]]}, {"id": "1810.06394", "submitter": "Jiechao Xiong", "authors": "Jiechao Xiong, Qing Wang, Zhuoran Yang, Peng Sun, Lei Han, Yang Zheng,\n  Haobo Fu, Tong Zhang, Ji Liu, and Han Liu", "title": "Parametrized Deep Q-Networks Learning: Reinforcement Learning with\n  Discrete-Continuous Hybrid Action Space", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Most existing deep reinforcement learning (DRL) frameworks consider either\ndiscrete action space or continuous action space solely. Motivated by\napplications in computer games, we consider the scenario with\ndiscrete-continuous hybrid action space. To handle hybrid action space,\nprevious works either approximate the hybrid space by discretization, or relax\nit into a continuous set. In this paper, we propose a parametrized deep\nQ-network (P- DQN) framework for the hybrid action space without approximation\nor relaxation. Our algorithm combines the spirits of both DQN (dealing with\ndiscrete action space) and DDPG (dealing with continuous action space) by\nseamlessly integrating them. Empirical results on a simulation example, scoring\na goal in simulated RoboCup soccer and the solo mode in game King of Glory\n(KOG) validate the efficiency and effectiveness of our method.\n", "versions": [{"version": "v1", "created": "Wed, 10 Oct 2018 07:38:44 GMT"}], "update_date": "2018-10-16", "authors_parsed": [["Xiong", "Jiechao", ""], ["Wang", "Qing", ""], ["Yang", "Zhuoran", ""], ["Sun", "Peng", ""], ["Han", "Lei", ""], ["Zheng", "Yang", ""], ["Fu", "Haobo", ""], ["Zhang", "Tong", ""], ["Liu", "Ji", ""], ["Liu", "Han", ""]]}, {"id": "1810.06397", "submitter": "Lei Wu", "authors": "Weinan E, Chao Ma, Lei Wu", "title": "A Priori Estimates of the Population Risk for Two-layer Neural Networks", "comments": "Published version", "journal-ref": "Communications in Mathematical Sciences, Volume 17(2019)", "doi": "10.4310/CMS.2019.v17.n5.a11", "report-no": null, "categories": "stat.ML cs.LG math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  New estimates for the population risk are established for two-layer neural\nnetworks. These estimates are nearly optimal in the sense that the error rates\nscale in the same way as the Monte Carlo error rates. They are equally\neffective in the over-parametrized regime when the network size is much larger\nthan the size of the dataset. These new estimates are a priori in nature in the\nsense that the bounds depend only on some norms of the underlying functions to\nbe fitted, not the parameters in the model, in contrast with most existing\nresults which are a posteriori in nature. Using these a priori estimates, we\nprovide a perspective for understanding why two-layer neural networks perform\nbetter than the related kernel methods.\n", "versions": [{"version": "v1", "created": "Mon, 15 Oct 2018 14:38:56 GMT"}, {"version": "v2", "created": "Sat, 26 Jan 2019 22:15:01 GMT"}, {"version": "v3", "created": "Thu, 20 Feb 2020 23:33:56 GMT"}], "update_date": "2020-02-24", "authors_parsed": [["E", "Weinan", ""], ["Ma", "Chao", ""], ["Wu", "Lei", ""]]}, {"id": "1810.06401", "submitter": "Weihao Gao", "authors": "Weihao Gao, Yu-Han Liu, Chong Wang, Sewoong Oh", "title": "Rate Distortion For Model Compression: From Theory To Practice", "comments": "23 pages, 12 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IT cs.LG math.IT stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The enormous size of modern deep neural networks makes it challenging to\ndeploy those models in memory and communication limited scenarios. Thus,\ncompressing a trained model without a significant loss in performance has\nbecome an increasingly important task. Tremendous advances has been made\nrecently, where the main technical building blocks are parameter pruning,\nparameter sharing (quantization), and low-rank factorization. In this paper, we\npropose principled approaches to improve upon the common heuristics used in\nthose building blocks, namely pruning and quantization.\n  We first study the fundamental limit for model compression via the rate\ndistortion theory. We bring the rate distortion function from data compression\nto model compression to quantify this fundamental limit. We prove a lower bound\nfor the rate distortion function and prove its achievability for linear models.\nAlthough this achievable compression scheme is intractable in practice, this\nanalysis motivates a novel model compression framework. This framework provides\na new objective function in model compression, which can be applied together\nwith other classes of model compressor such as pruning or quantization.\nTheoretically, we prove that the proposed scheme is optimal for compressing\none-hidden-layer ReLU neural networks. Empirically, we show that the proposed\nscheme improves upon the baseline in the compression-accuracy tradeoff.\n", "versions": [{"version": "v1", "created": "Tue, 9 Oct 2018 18:44:22 GMT"}, {"version": "v2", "created": "Wed, 23 Jan 2019 23:59:28 GMT"}], "update_date": "2019-01-25", "authors_parsed": [["Gao", "Weihao", ""], ["Liu", "Yu-Han", ""], ["Wang", "Chong", ""], ["Oh", "Sewoong", ""]]}, {"id": "1810.06443", "submitter": "Damien Pellier", "authors": "Bruno Bouzy and Marc M\\'etivier and Damien Pellier", "title": "Hedging Algorithms and Repeated Matrix Games", "comments": "12 pages, Workshop of the European Conference on Machine Learning on\n  Machine Learning and Data Mining in and around Games, 2011", "journal-ref": "Workshop of the European Conference on Machine Learning on Machine\n  Learning and Data Mining in and around Games, 2011", "doi": null, "report-no": null, "categories": "cs.LG cs.GT cs.MA stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Playing repeated matrix games (RMG) while maximizing the cumulative returns\nis a basic method to evaluate multi-agent learning (MAL) algorithms. Previous\nwork has shown that $UCB$, $M3$, $S$ or $Exp3$ algorithms have good behaviours\non average in RMG. Besides, hedging algorithms have been shown to be effective\non prediction problems. An hedging algorithm is made up with a top-level\nalgorithm and a set of basic algorithms. To make its decision, an hedging\nalgorithm uses its top-level algorithm to choose a basic algorithm, and the\nchosen algorithm makes the decision. This paper experimentally shows that\nwell-selected hedging algorithms are better on average than all previous MAL\nalgorithms on the task of playing RMG against various players. $S$ is a very\ngood top-level algorithm, and $UCB$ and $M3$ are very good basic algorithms.\nFurthermore, two-level hedging algorithms are more effective than one-level\nhedging algorithms, and three levels are not better than two levels.\n", "versions": [{"version": "v1", "created": "Mon, 15 Oct 2018 15:05:21 GMT"}], "update_date": "2018-11-02", "authors_parsed": [["Bouzy", "Bruno", ""], ["M\u00e9tivier", "Marc", ""], ["Pellier", "Damien", ""]]}, {"id": "1810.06509", "submitter": "Ching-An Cheng", "authors": "Ching-An Cheng, Xinyan Yan, Nathan Ratliff, Byron Boots", "title": "Predictor-Corrector Policy Optimization", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a predictor-corrector framework, called PicCoLO, that can\ntransform a first-order model-free reinforcement or imitation learning\nalgorithm into a new hybrid method that leverages predictive models to\naccelerate policy learning. The new \"PicCoLOed\" algorithm optimizes a policy by\nrecursively repeating two steps: In the Prediction Step, the learner uses a\nmodel to predict the unseen future gradient and then applies the predicted\nestimate to update the policy; in the Correction Step, the learner runs the\nupdated policy in the environment, receives the true gradient, and then\ncorrects the policy using the gradient error. Unlike previous algorithms,\nPicCoLO corrects for the mistakes of using imperfect predicted gradients and\nhence does not suffer from model bias. The development of PicCoLO is made\npossible by a novel reduction from predictable online learning to adversarial\nonline learning, which provides a systematic way to modify existing first-order\nalgorithms to achieve the optimal regret with respect to predictable\ninformation. We show, in both theory and simulation, that the convergence rate\nof several first-order model-free algorithms can be improved by PicCoLO.\n", "versions": [{"version": "v1", "created": "Mon, 15 Oct 2018 16:44:48 GMT"}, {"version": "v2", "created": "Fri, 24 May 2019 18:45:57 GMT"}], "update_date": "2019-05-28", "authors_parsed": [["Cheng", "Ching-An", ""], ["Yan", "Xinyan", ""], ["Ratliff", "Nathan", ""], ["Boots", "Byron", ""]]}, {"id": "1810.06519", "submitter": "Brett Israelsen", "authors": "Brett W Israelsen, Nisar R Ahmed, Eric Frew, Dale Lawrence, Brian\n  Argrow", "title": "Factorized Machine Self-Confidence for Decision-Making Agents", "comments": "title change, leaving as stand-alone tech report", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CY cs.HC cs.RO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Algorithmic assurances from advanced autonomous systems assist human users in\nunderstanding, trusting, and using such systems appropriately. Designing these\nsystems with the capacity of assessing their own capabilities is one approach\nto creating an algorithmic assurance. The idea of `machine self-confidence' is\nintroduced for autonomous systems. Using a factorization based framework for\nself-confidence assessment, one component of self-confidence, called\n`solver-quality', is discussed in the context of Markov decision processes for\nautonomous systems. Markov decision processes underlie much of the theory of\nreinforcement learning, and are commonly used for planning and decision making\nunder uncertainty in robotics and autonomous systems. A `solver quality' metric\nis formally defined in the context of decision making algorithms based on\nMarkov decision processes. A method for assessing solver quality is then\nderived, drawing inspiration from empirical hardness models. Finally, numerical\nexperiments for an unmanned autonomous vehicle navigation problem under\ndifferent solver, parameter, and environment conditions indicate that the\nself-confidence metric exhibits the desired properties. Discussion of results,\nand avenues for future investigation are included.\n", "versions": [{"version": "v1", "created": "Mon, 15 Oct 2018 17:06:38 GMT"}, {"version": "v2", "created": "Wed, 9 Jan 2019 18:31:04 GMT"}], "update_date": "2019-01-10", "authors_parsed": [["Israelsen", "Brett W", ""], ["Ahmed", "Nisar R", ""], ["Frew", "Eric", ""], ["Lawrence", "Dale", ""], ["Argrow", "Brian", ""]]}, {"id": "1810.06526", "submitter": "Youzhi Tian", "authors": "Youzhi Tian, Zhiting Hu, Zhou Yu", "title": "Structured Content Preservation for Unsupervised Text Style Transfer", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Text style transfer aims to modify the style of a sentence while keeping its\ncontent unchanged. Recent style transfer systems often fail to faithfully\npreserve the content after changing the style. This paper proposes a structured\ncontent preserving model that leverages linguistic information in the\nstructured fine-grained supervisions to better preserve the style-independent\ncontent during style transfer. In particular, we achieve the goal by devising\nrich model objectives based on both the sentence's lexical information and a\nlanguage model that conditions on content. The resulting model therefore is\nencouraged to retain the semantic meaning of the target sentences. We perform\nextensive experiments that compare our model to other existing approaches in\nthe tasks of sentiment and political slant transfer. Our model achieves\nsignificant improvement in terms of both content preservation and style\ntransfer in automatic and human evaluation.\n", "versions": [{"version": "v1", "created": "Mon, 15 Oct 2018 17:19:18 GMT"}, {"version": "v2", "created": "Wed, 31 Oct 2018 21:55:10 GMT"}], "update_date": "2018-11-02", "authors_parsed": [["Tian", "Youzhi", ""], ["Hu", "Zhiting", ""], ["Yu", "Zhou", ""]]}, {"id": "1810.06530", "submitter": "David Janz", "authors": "David Janz, Jiri Hron, Przemys{\\l}aw Mazur, Katja Hofmann, Jos\\'e\n  Miguel Hern\\'andez-Lobato, Sebastian Tschiatschek", "title": "Successor Uncertainties: Exploration and Uncertainty in Temporal\n  Difference Learning", "comments": "Camera ready version, NeurIPS 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Posterior sampling for reinforcement learning (PSRL) is an effective method\nfor balancing exploration and exploitation in reinforcement learning.\nRandomised value functions (RVF) can be viewed as a promising approach to\nscaling PSRL. However, we show that most contemporary algorithms combining RVF\nwith neural network function approximation do not possess the properties which\nmake PSRL effective, and provably fail in sparse reward problems. Moreover, we\nfind that propagation of uncertainty, a property of PSRL previously thought\nimportant for exploration, does not preclude this failure. We use these\ninsights to design Successor Uncertainties (SU), a cheap and easy to implement\nRVF algorithm that retains key properties of PSRL. SU is highly effective on\nhard tabular exploration benchmarks. Furthermore, on the Atari 2600 domain, it\nsurpasses human performance on 38 of 49 games tested (achieving a median human\nnormalised score of 2.09), and outperforms its closest RVF competitor,\nBootstrapped DQN, on 36 of those.\n", "versions": [{"version": "v1", "created": "Mon, 15 Oct 2018 17:30:53 GMT"}, {"version": "v2", "created": "Thu, 29 Nov 2018 13:38:43 GMT"}, {"version": "v3", "created": "Sat, 25 May 2019 22:57:44 GMT"}, {"version": "v4", "created": "Mon, 2 Dec 2019 16:50:39 GMT"}, {"version": "v5", "created": "Tue, 3 Dec 2019 16:30:17 GMT"}], "update_date": "2019-12-04", "authors_parsed": [["Janz", "David", ""], ["Hron", "Jiri", ""], ["Mazur", "Przemys\u0142aw", ""], ["Hofmann", "Katja", ""], ["Hern\u00e1ndez-Lobato", "Jos\u00e9 Miguel", ""], ["Tschiatschek", "Sebastian", ""]]}, {"id": "1810.06544", "submitter": "Nicholas Rhinehart", "authors": "Nicholas Rhinehart, Rowan McAllister, Sergey Levine", "title": "Deep Imitative Models for Flexible Inference, Planning, and Control", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CV cs.RO stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Imitation Learning (IL) is an appealing approach to learn desirable\nautonomous behavior. However, directing IL to achieve arbitrary goals is\ndifficult. In contrast, planning-based algorithms use dynamics models and\nreward functions to achieve goals. Yet, reward functions that evoke desirable\nbehavior are often difficult to specify. In this paper, we propose Imitative\nModels to combine the benefits of IL and goal-directed planning. Imitative\nModels are probabilistic predictive models of desirable behavior able to plan\ninterpretable expert-like trajectories to achieve specified goals. We derive\nfamilies of flexible goal objectives, including constrained goal regions,\nunconstrained goal sets, and energy-based goals. We show that our method can\nuse these objectives to successfully direct behavior. Our method substantially\noutperforms six IL approaches and a planning-based approach in a dynamic\nsimulated autonomous driving task, and is efficiently learned from expert\ndemonstrations without online data collection. We also show our approach is\nrobust to poorly specified goals, such as goals on the wrong side of the road.\n", "versions": [{"version": "v1", "created": "Mon, 15 Oct 2018 17:51:03 GMT"}, {"version": "v2", "created": "Thu, 31 Jan 2019 20:07:49 GMT"}, {"version": "v3", "created": "Tue, 4 Jun 2019 19:48:56 GMT"}, {"version": "v4", "created": "Tue, 1 Oct 2019 00:13:58 GMT"}], "update_date": "2019-10-02", "authors_parsed": [["Rhinehart", "Nicholas", ""], ["McAllister", "Rowan", ""], ["Levine", "Sergey", ""]]}, {"id": "1810.06583", "submitter": "Prasad Chalasani", "authors": "Prasad Chalasani, Jiefeng Chen, Amrita Roy Chowdhury, Somesh Jha, Xi\n  Wu", "title": "Concise Explanations of Neural Networks using Adversarial Training", "comments": "30 pages, 9 figures, 1 table", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We show new connections between adversarial learning and explainability for\ndeep neural networks (DNNs). One form of explanation of the output of a neural\nnetwork model in terms of its input features, is a vector of\nfeature-attributions. Two desirable characteristics of an attribution-based\nexplanation are: (1) $\\textit{sparseness}$: the attributions of irrelevant or\nweakly relevant features should be negligible, thus resulting in\n$\\textit{concise}$ explanations in terms of the significant features, and (2)\n$\\textit{stability}$: it should not vary significantly within a small local\nneighborhood of the input. Our first contribution is a theoretical exploration\nof how these two properties (when using attributions based on Integrated\nGradients, or IG) are related to adversarial training, for a class of 1-layer\nnetworks (which includes logistic regression models for binary and multi-class\nclassification); for these networks we show that (a) adversarial training using\nan $\\ell_\\infty$-bounded adversary produces models with sparse attribution\nvectors, and (b) natural model-training while encouraging stable explanations\n(via an extra term in the loss function), is equivalent to adversarial\ntraining. Our second contribution is an empirical verification of phenomenon\n(a), which we show, somewhat surprisingly, occurs $\\textit{not only}$\n$\\textit{in 1-layer networks}$, $\\textit{but also DNNs}$ $\\textit{trained on }$\n$\\textit{standard image datasets}$, and extends beyond IG-based attributions,\nto those based on DeepSHAP: adversarial training with $\\ell_\\infty$-bounded\nperturbations yields significantly sparser attribution vectors, with little\ndegradation in performance on natural test data, compared to natural training.\nMoreover, the sparseness of the attribution vectors is significantly better\nthan that achievable via $\\ell_1$-regularized natural training.\n", "versions": [{"version": "v1", "created": "Mon, 15 Oct 2018 18:01:06 GMT"}, {"version": "v2", "created": "Thu, 25 Oct 2018 17:59:08 GMT"}, {"version": "v3", "created": "Fri, 26 Oct 2018 18:18:48 GMT"}, {"version": "v4", "created": "Mon, 12 Nov 2018 18:59:43 GMT"}, {"version": "v5", "created": "Fri, 24 May 2019 13:28:30 GMT"}, {"version": "v6", "created": "Fri, 11 Oct 2019 14:37:10 GMT"}, {"version": "v7", "created": "Mon, 14 Oct 2019 00:54:12 GMT"}, {"version": "v8", "created": "Mon, 17 Feb 2020 00:18:51 GMT"}, {"version": "v9", "created": "Sun, 5 Jul 2020 01:06:20 GMT"}], "update_date": "2020-07-07", "authors_parsed": [["Chalasani", "Prasad", ""], ["Chen", "Jiefeng", ""], ["Chowdhury", "Amrita Roy", ""], ["Jha", "Somesh", ""], ["Wu", "Xi", ""]]}, {"id": "1810.06603", "submitter": "Marco Mart\\'inez", "authors": "Marco A. Mart\\'inez Ramirez and Joshua D. Reiss", "title": "Modeling of nonlinear audio effects with end-to-end deep neural networks", "comments": "Presented at the 2019 IEEE International Conference on Acoustics,\n  Speech, and Signal Processing (ICASSP), Brighton, UK, May 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.AS cs.LG cs.SD eess.SP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In the context of music production, distortion effects are mainly used for\naesthetic reasons and are usually applied to electric musical instruments. Most\nexisting methods for nonlinear modeling are often either simplified or\noptimized to a very specific circuit. In this work, we investigate deep\nlearning architectures for audio processing and we aim to find a general\npurpose end-to-end deep neural network to perform modeling of nonlinear audio\neffects. We show the network modeling various nonlinearities and we discuss the\ngeneralization capabilities among different instruments.\n", "versions": [{"version": "v1", "created": "Mon, 15 Oct 2018 18:30:11 GMT"}, {"version": "v2", "created": "Wed, 6 Mar 2019 12:46:48 GMT"}], "update_date": "2019-05-10", "authors_parsed": [["Ramirez", "Marco A. Mart\u00ednez", ""], ["Reiss", "Joshua D.", ""]]}, {"id": "1810.06611", "submitter": "Aydogan Ozcan", "authors": "Tairan Liu, Kevin de Haan, Yair Rivenson, Zhensong Wei, Xin Zeng, Yibo\n  Zhang, Aydogan Ozcan", "title": "Deep learning-based super-resolution in coherent imaging systems", "comments": "18 pages, 9 figures, 3 tables", "journal-ref": "Scientific Reports (2019)", "doi": "10.1038/s41598-019-40554-1", "report-no": null, "categories": "cs.CV cs.LG physics.app-ph physics.optics", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a deep learning framework based on a generative adversarial\nnetwork (GAN) to perform super-resolution in coherent imaging systems. We\ndemonstrate that this framework can enhance the resolution of both pixel\nsize-limited and diffraction-limited coherent imaging systems. We\nexperimentally validated the capabilities of this deep learning-based coherent\nimaging approach by super-resolving complex images acquired using a lensfree\non-chip holographic microscope, the resolution of which was pixel size-limited.\nUsing the same GAN-based approach, we also improved the resolution of a\nlens-based holographic imaging system that was limited in resolution by the\nnumerical aperture of its objective lens. This deep learning-based\nsuper-resolution framework can be broadly applied to enhance the\nspace-bandwidth product of coherent imaging systems using image data and\nconvolutional neural networks, and provides a rapid, non-iterative method for\nsolving inverse image reconstruction or enhancement problems in optics.\n", "versions": [{"version": "v1", "created": "Mon, 15 Oct 2018 18:55:26 GMT"}], "update_date": "2019-03-12", "authors_parsed": [["Liu", "Tairan", ""], ["de Haan", "Kevin", ""], ["Rivenson", "Yair", ""], ["Wei", "Zhensong", ""], ["Zeng", "Xin", ""], ["Zhang", "Yibo", ""], ["Ozcan", "Aydogan", ""]]}, {"id": "1810.06640", "submitter": "David Donahue", "authors": "David Donahue, Anna Rumshisky", "title": "Adversarial Text Generation Without Reinforcement Learning", "comments": "Four pages without references. ACL latex style. Four figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Generative Adversarial Networks (GANs) have experienced a recent surge in\npopularity, performing competitively in a variety of tasks, especially in\ncomputer vision. However, GAN training has shown limited success in natural\nlanguage processing. This is largely because sequences of text are discrete,\nand thus gradients cannot propagate from the discriminator to the generator.\nRecent solutions use reinforcement learning to propagate approximate gradients\nto the generator, but this is inefficient to train. We propose to utilize an\nautoencoder to learn a low-dimensional representation of sentences. A GAN is\nthen trained to generate its own vectors in this space, which decode to\nrealistic utterances. We report both random and interpolated samples from the\ngenerator. Visualization of sentence vectors indicate our model correctly\nlearns the latent space of the autoencoder. Both human ratings and BLEU scores\nshow that our model generates realistic text against competitive baselines.\n", "versions": [{"version": "v1", "created": "Thu, 11 Oct 2018 22:50:38 GMT"}, {"version": "v2", "created": "Tue, 1 Jan 2019 23:38:54 GMT"}], "update_date": "2019-01-03", "authors_parsed": [["Donahue", "David", ""], ["Rumshisky", "Anna", ""]]}, {"id": "1810.06644", "submitter": "Lin Li", "authors": "Lin Li, Yueqing Sun", "title": "An Instance Transfer based Approach Using Enhanced Recurrent Neural\n  Network for Domain Named Entity Recognition", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recently, neural networks have shown promising results for named entity\nrecognition (NER), which needs a number of labeled data to for model training.\nWhen meeting a new domain (target domain) for NER, there is no or a few labeled\ndata, which makes domain NER much more difficult. As NER has been researched\nfor a long time, some similar domain already has well labelled data (source\ndomain). Therefore, in this paper, we focus on domain NER by studying how to\nutilize the labelled data from such similar source domain for the new target\ndomain. We design a kernel function based instance transfer strategy by getting\nsimilar labelled sentences from a source domain. Moreover, we propose an\nenhanced recurrent neural network (ERNN) by adding an additional layer that\ncombines the source domain labelled data into traditional RNN structure.\nComprehensive experiments are conducted on two datasets. The comparison results\namong HMM, CRF and RNN show that RNN performs bette than others. When there is\nno labelled data in domain target, compared to directly using the source domain\nlabelled data without selecting transferred instances, our enhanced RNN\napproach gets improvement from 0.8052 to 0.9328 in terms of F1 measure.\n", "versions": [{"version": "v1", "created": "Tue, 9 Oct 2018 06:55:04 GMT"}], "update_date": "2018-10-17", "authors_parsed": [["Li", "Lin", ""], ["Sun", "Yueqing", ""]]}, {"id": "1810.06665", "submitter": "Ahmed Elnaggar", "authors": "Ahmed Elnaggar, Bernhard Waltl, Ingo Glaser, J\\\"org Landthaler, Elena\n  Scepankova and Florian Matthes", "title": "Stop Illegal Comments: A Multi-Task Deep Learning Approach", "comments": "10 pages, 4 figures, 1 table", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.CL cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep learning methods are often difficult to apply in the legal domain due to\nthe large amount of labeled data required by deep learning methods. A recent\nnew trend in the deep learning community is the application of multi-task\nmodels that enable single deep neural networks to perform more than one task at\nthe same time, for example classification and translation tasks. These powerful\nnovel models are capable of transferring knowledge among different tasks or\ntraining sets and therefore could open up the legal domain for many deep\nlearning applications. In this paper, we investigate the transfer learning\ncapabilities of such a multi-task model on a classification task on the\npublicly available Kaggle toxic comment dataset for classifying illegal\ncomments and we can report promising results.\n", "versions": [{"version": "v1", "created": "Mon, 15 Oct 2018 20:22:44 GMT"}], "update_date": "2018-10-17", "authors_parsed": [["Elnaggar", "Ahmed", ""], ["Waltl", "Bernhard", ""], ["Glaser", "Ingo", ""], ["Landthaler", "J\u00f6rg", ""], ["Scepankova", "Elena", ""], ["Matthes", "Florian", ""]]}, {"id": "1810.06667", "submitter": "Yaser Keneshloo", "authors": "Yaser Keneshloo, Naren Ramakrishnan, Chandan K. Reddy", "title": "Deep Transfer Reinforcement Learning for Text Summarization", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CL stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep neural networks are data hungry models and thus face difficulties when\nattempting to train on small text datasets. Transfer learning is a potential\nsolution but their effectiveness in the text domain is not as explored as in\nareas such as image analysis. In this paper, we study the problem of transfer\nlearning for text summarization and discuss why existing state-of-the-art\nmodels fail to generalize well on other (unseen) datasets. We propose a\nreinforcement learning framework based on a self-critic policy gradient\napproach which achieves good generalization and state-of-the-art results on a\nvariety of datasets. Through an extensive set of experiments, we also show the\nability of our proposed framework to fine-tune the text summarization model\nusing only a few training samples. To the best of our knowledge, this is the\nfirst work that studies transfer learning in text summarization and provides a\ngeneric solution that works well on unseen data.\n", "versions": [{"version": "v1", "created": "Mon, 15 Oct 2018 20:26:44 GMT"}, {"version": "v2", "created": "Thu, 24 Jan 2019 20:14:33 GMT"}], "update_date": "2019-01-28", "authors_parsed": [["Keneshloo", "Yaser", ""], ["Ramakrishnan", "Naren", ""], ["Reddy", "Chandan K.", ""]]}, {"id": "1810.06673", "submitter": "Ahmed Elnaggar", "authors": "Ahmed Elnaggar, Robin Otto and Florian Matthes", "title": "Named-Entity Linking Using Deep Learning For Legal Documents: A Transfer\n  Learning Approach", "comments": "10 pages, 2 figures, 3 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CL stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In the legal domain it is important to differentiate between words in\ngeneral, and afterwards to link the occurrences of the same entities. The topic\nto solve these challenges is called Named-Entity Linking (NEL). Current\nsupervised neural networks designed for NEL use publicly available datasets for\ntraining and testing. However, this paper focuses especially on the aspect of\napplying transfer learning approach using networks trained for NEL to legal\ndocuments. Experiments show consistent improvement in the legal datasets that\nwere created from the European Union law in the scope of this research. Using\ntransfer learning approach, we reached F1-score of 98.90\\% and 98.01\\% on the\nlegal small and large test dataset.\n", "versions": [{"version": "v1", "created": "Mon, 15 Oct 2018 20:38:00 GMT"}], "update_date": "2018-10-17", "authors_parsed": [["Elnaggar", "Ahmed", ""], ["Otto", "Robin", ""], ["Matthes", "Florian", ""]]}, {"id": "1810.06682", "submitter": "Shaojie Bai", "authors": "Shaojie Bai, J. Zico Kolter, Vladlen Koltun", "title": "Trellis Networks for Sequence Modeling", "comments": "Published at ICLR 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CL stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present trellis networks, a new architecture for sequence modeling. On the\none hand, a trellis network is a temporal convolutional network with special\nstructure, characterized by weight tying across depth and direct injection of\nthe input into deep layers. On the other hand, we show that truncated recurrent\nnetworks are equivalent to trellis networks with special sparsity structure in\ntheir weight matrices. Thus trellis networks with general weight matrices\ngeneralize truncated recurrent networks. We leverage these connections to\ndesign high-performing trellis networks that absorb structural and algorithmic\nelements from both recurrent and convolutional models. Experiments demonstrate\nthat trellis networks outperform the current state of the art methods on a\nvariety of challenging benchmarks, including word-level language modeling and\ncharacter-level language modeling tasks, and stress tests designed to evaluate\nlong-term memory retention. The code is available at\nhttps://github.com/locuslab/trellisnet .\n", "versions": [{"version": "v1", "created": "Mon, 15 Oct 2018 20:50:05 GMT"}, {"version": "v2", "created": "Mon, 11 Mar 2019 21:37:42 GMT"}], "update_date": "2019-03-13", "authors_parsed": [["Bai", "Shaojie", ""], ["Kolter", "J. Zico", ""], ["Koltun", "Vladlen", ""]]}, {"id": "1810.06684", "submitter": "Murat Firat", "authors": "Murat Firat, Guillaume Crognier, Adriana F. Gabor, C.A.J. Hurkens, and\n  Yingqian Zhang", "title": "Column generation based math-heuristic for classification trees", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper explores the use of Column Generation (CG) techniques in\nconstructing univariate binary decision trees for classification tasks. We\npropose a novel Integer Linear Programming (ILP) formulation, based on\nroot-to-leaf paths in decision trees. The model is solved via a Column\nGeneration based heuristic. To speed up the heuristic, we use a restricted\ninstance data by considering a subset of decision splits, sampled from the\nsolutions of the well-known CART algorithm. Extensive numerical experiments\nshow that our approach is competitive with the state-of-the-art ILP-based\nalgorithms. In particular, the proposed approach is capable of handling big\ndata sets with tens of thousands of data rows. Moreover, for large data sets,\nit finds solutions competitive to CART.\n", "versions": [{"version": "v1", "created": "Mon, 15 Oct 2018 20:50:39 GMT"}, {"version": "v2", "created": "Thu, 11 Jul 2019 07:04:18 GMT"}], "update_date": "2019-07-12", "authors_parsed": [["Firat", "Murat", ""], ["Crognier", "Guillaume", ""], ["Gabor", "Adriana F.", ""], ["Hurkens", "C. A. J.", ""], ["Zhang", "Yingqian", ""]]}, {"id": "1810.06695", "submitter": "Giancarlo Salton", "authors": "Giancarlo D. Salton and Robert J. Ross and John D. Kelleher", "title": "Exploring the Use of Attention within an Neural Machine Translation\n  Decoder States to Translate Idioms", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Idioms pose problems to almost all Machine Translation systems. This type of\nlanguage is very frequent in day-to-day language use and cannot be simply\nignored. The recent interest in memory augmented models in the field of\nLanguage Modelling has aided the systems to achieve good results by bridging\nlong-distance dependencies. In this paper we explore the use of such techniques\ninto a Neural Machine Translation system to help in translation of idiomatic\nlanguage.\n", "versions": [{"version": "v1", "created": "Wed, 10 Oct 2018 09:57:32 GMT"}], "update_date": "2018-10-17", "authors_parsed": [["Salton", "Giancarlo D.", ""], ["Ross", "Robert J.", ""], ["Kelleher", "John D.", ""]]}, {"id": "1810.06702", "submitter": "James Murphy", "authors": "Mauro Maggioni and James M. Murphy", "title": "Learning by Unsupervised Nonlinear Diffusion", "comments": "40 Pages, 17 Figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper proposes and analyzes a novel clustering algorithm that combines\ngraph-based diffusion geometry with techniques based on density and mode\nestimation. The proposed method is suitable for data generated from mixtures of\ndistributions with densities that are both multimodal and have nonlinear\nshapes. A crucial aspect of this algorithm is the use of time of a data-adapted\ndiffusion process as a scale parameter that is different from the local spatial\nscale parameter used in many clustering algorithms. We prove estimates for the\nbehavior of diffusion distances with respect to this time parameter under a\nflexible nonparametric data model, identifying a range of times in which the\nmesoscopic equilibria of the underlying process are revealed, corresponding to\na gap between within-cluster and between-cluster diffusion distances. These\nstructures can be missed by the top eigenvectors of the graph Laplacian,\ncommonly used in spectral clustering. This analysis is leveraged to prove\nsufficient conditions guaranteeing the accuracy of the proposed \\emph{learning\nby unsupervised nonlinear diffusion (LUND)} procedure. We implement LUND and\nconfirm its theoretical properties on illustrative datasets, demonstrating the\ntheoretical and empirical advantages over both spectral clustering and\ndensity-based clustering techniques.\n", "versions": [{"version": "v1", "created": "Mon, 15 Oct 2018 21:23:03 GMT"}, {"version": "v2", "created": "Sat, 29 Dec 2018 16:28:58 GMT"}], "update_date": "2019-01-01", "authors_parsed": [["Maggioni", "Mauro", ""], ["Murphy", "James M.", ""]]}, {"id": "1810.06721", "submitter": "Greg Wayne", "authors": "Chia-Chun Hung, Timothy Lillicrap, Josh Abramson, Yan Wu, Mehdi Mirza,\n  Federico Carnevale, Arun Ahuja, Greg Wayne", "title": "Optimizing Agent Behavior over Long Time Scales by Transporting Value", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Humans spend a remarkable fraction of waking life engaged in acts of \"mental\ntime travel\". We dwell on our actions in the past and experience satisfaction\nor regret. More than merely autobiographical storytelling, we use these event\nrecollections to change how we will act in similar scenarios in the future.\nThis process endows us with a computationally important ability to link actions\nand consequences across long spans of time, which figures prominently in\naddressing the problem of long-term temporal credit assignment; in artificial\nintelligence (AI) this is the question of how to evaluate the utility of the\nactions within a long-duration behavioral sequence leading to success or\nfailure in a task. Existing approaches to shorter-term credit assignment in AI\ncannot solve tasks with long delays between actions and consequences. Here, we\nintroduce a new paradigm for reinforcement learning where agents use recall of\nspecific memories to credit actions from the past, allowing them to solve\nproblems that are intractable for existing algorithms. This paradigm broadens\nthe scope of problems that can be investigated in AI and offers a mechanistic\naccount of behaviors that may inspire computational models in neuroscience,\npsychology, and behavioral economics.\n", "versions": [{"version": "v1", "created": "Mon, 15 Oct 2018 22:01:28 GMT"}, {"version": "v2", "created": "Fri, 21 Dec 2018 13:56:03 GMT"}], "update_date": "2018-12-24", "authors_parsed": [["Hung", "Chia-Chun", ""], ["Lillicrap", "Timothy", ""], ["Abramson", "Josh", ""], ["Wu", "Yan", ""], ["Mirza", "Mehdi", ""], ["Carnevale", "Federico", ""], ["Ahuja", "Arun", ""], ["Wayne", "Greg", ""]]}, {"id": "1810.06746", "submitter": "Winfried L\\\"otzsch", "authors": "Winfried L\\\"otzsch", "title": "Using Deep Reinforcement Learning for the Continuous Control of Robotic\n  Arms", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.RO stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep reinforcement learning enables algorithms to learn complex behavior,\ndeal with continuous action spaces and find good strategies in environments\nwith high dimensional state spaces. With deep reinforcement learning being an\nactive area of research and many concurrent inventions, we decided to focus on\na relatively simple robotic task to evaluate a set of ideas that might help to\nsolve recent reinforcement learning problems. We test a newly created\ncombination of two commonly used reinforcement learning methods, whether it is\nable to learn more effectively than a baseline. We also compare different ideas\nto preprocess information before it is fed to the reinforcement learning\nalgorithm. The goal of this strategy is to reduce training time and eventually\nhelp the algorithm to converge. The concluding evaluation proves the general\napplicability of the described concepts by testing them using a simulated\nenvironment. These concepts might be reused for future experiments.\n", "versions": [{"version": "v1", "created": "Mon, 15 Oct 2018 23:10:46 GMT"}], "update_date": "2018-10-17", "authors_parsed": [["L\u00f6tzsch", "Winfried", ""]]}, {"id": "1810.06749", "submitter": "Bastian Bohn", "authors": "Bastian Bohn and Michael Griebel and Jens Oettershagen", "title": "Optimally rotated coordinate systems for adaptive least-squares\n  regression on sparse grids", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG math.NA stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  For low-dimensional data sets with a large amount of data points, standard\nkernel methods are usually not feasible for regression anymore. Besides simple\nlinear models or involved heuristic deep learning models, grid-based\ndiscretizations of larger (kernel) model classes lead to algorithms, which\nnaturally scale linearly in the amount of data points. For moderate-dimensional\nor high-dimensional regression tasks, these grid-based discretizations suffer\nfrom the curse of dimensionality. Here, sparse grid methods have proven to\ncircumvent this problem to a large extent. In this context, space- and\ndimension-adaptive sparse grids, which can detect and exploit a given low\neffective dimensionality of nominally high-dimensional data, are particularly\nsuccessful. They nevertheless rely on an axis-aligned structure of the solution\nand exhibit issues for data with predominantly skewed and rotated coordinates.\n  In this paper we propose a preprocessing approach for these adaptive sparse\ngrid algorithms that determines an optimized, problem-dependent coordinate\nsystem and, thus, reduces the effective dimensionality of a given data set in\nthe ANOVA sense. We provide numerical examples on synthetic data as well as\nreal-world data to show how an adaptive sparse grid least squares algorithm\nbenefits from our preprocessing method.\n", "versions": [{"version": "v1", "created": "Mon, 15 Oct 2018 23:24:21 GMT"}, {"version": "v2", "created": "Thu, 28 Feb 2019 11:28:02 GMT"}], "update_date": "2019-03-01", "authors_parsed": [["Bohn", "Bastian", ""], ["Griebel", "Michael", ""], ["Oettershagen", "Jens", ""]]}, {"id": "1810.06755", "submitter": "Oliver Thomas", "authors": "Novi Quadrianto, Viktoriia Sharmanska, Oliver Thomas", "title": "Discovering Fair Representations in the Data Domain", "comments": "IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\n  2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Interpretability and fairness are critical in computer vision and machine\nlearning applications, in particular when dealing with human outcomes, e.g.\ninviting or not inviting for a job interview based on application materials\nthat may include photographs. One promising direction to achieve fairness is by\nlearning data representations that remove the semantics of protected\ncharacteristics, and are therefore able to mitigate unfair outcomes. All\navailable models however learn latent embeddings which comes at the cost of\nbeing uninterpretable. We propose to cast this problem as data-to-data\ntranslation, i.e. learning a mapping from an input domain to a fair target\ndomain, where a fairness definition is being enforced. Here the data domain can\nbe images, or any tabular data representation. This task would be\nstraightforward if we had fair target data available, but this is not the case.\nTo overcome this, we learn a highly unconstrained mapping by exploiting\nstatistics of residuals - the difference between input data and its translated\nversion - and the protected characteristics. When applied to the CelebA dataset\nof face images with gender attribute as the protected characteristic, our model\nenforces equality of opportunity by adjusting the eyes and lips regions.\nIntriguingly, on the same dataset we arrive at similar conclusions when using\nsemantic attribute representations of images for translation. On face images of\nthe recent DiF dataset, with the same gender attribute, our method adjusts nose\nregions. In the Adult income dataset, also with protected gender attribute, our\nmodel achieves equality of opportunity by, among others, obfuscating the wife\nand husband relationship. Analyzing those systematic changes will allow us to\nscrutinize the interplay of fairness criterion, chosen protected\ncharacteristics, and prediction performance.\n", "versions": [{"version": "v1", "created": "Mon, 15 Oct 2018 23:58:36 GMT"}, {"version": "v2", "created": "Thu, 11 Apr 2019 10:51:18 GMT"}], "update_date": "2019-04-12", "authors_parsed": [["Quadrianto", "Novi", ""], ["Sharmanska", "Viktoriia", ""], ["Thomas", "Oliver", ""]]}, {"id": "1810.06758", "submitter": "Samaneh Azadi", "authors": "Samaneh Azadi, Catherine Olsson, Trevor Darrell, Ian Goodfellow,\n  Augustus Odena", "title": "Discriminator Rejection Sampling", "comments": "Published as a conference paper at ICLR 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a rejection sampling scheme using the discriminator of a GAN to\napproximately correct errors in the GAN generator distribution. We show that\nunder quite strict assumptions, this will allow us to recover the data\ndistribution exactly. We then examine where those strict assumptions break down\nand design a practical algorithm - called Discriminator Rejection Sampling\n(DRS) - that can be used on real data-sets. Finally, we demonstrate the\nefficacy of DRS on a mixture of Gaussians and on the SAGAN model,\nstate-of-the-art in the image generation task at the time of developing this\nwork. On ImageNet, we train an improved baseline that increases the Inception\nScore from 52.52 to 62.36 and reduces the Frechet Inception Distance from 18.65\nto 14.79. We then use DRS to further improve on this baseline, improving the\nInception Score to 76.08 and the FID to 13.75.\n", "versions": [{"version": "v1", "created": "Tue, 16 Oct 2018 00:06:54 GMT"}, {"version": "v2", "created": "Thu, 18 Oct 2018 01:04:37 GMT"}, {"version": "v3", "created": "Tue, 26 Feb 2019 09:06:47 GMT"}], "update_date": "2019-02-27", "authors_parsed": [["Azadi", "Samaneh", ""], ["Olsson", "Catherine", ""], ["Darrell", "Trevor", ""], ["Goodfellow", "Ian", ""], ["Odena", "Augustus", ""]]}, {"id": "1810.06759", "submitter": "Harish S. Bhat", "authors": "Ramin Raziperchikolaei and Harish S. Bhat", "title": "A Block Coordinate Descent Proximal Method for Simultaneous Filtering\n  and Parameter Estimation", "comments": "18 pages, ICML 2019", "journal-ref": "PMLR 97:5380-5388, 2019", "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose and analyze a block coordinate descent proximal algorithm\n(BCD-prox) for simultaneous filtering and parameter estimation of ODE models.\nAs we show on ODE systems with up to d=40 dimensions, as compared to\nstate-of-the-art methods, BCD-prox exhibits increased robustness (to noise,\nparameter initialization, and hyperparameters), decreased training times, and\nimproved accuracy of both filtered states and estimated parameters. We show how\nBCD-prox can be used with multistep numerical discretizations, and we establish\nconvergence of BCD-prox under hypotheses that include real systems of interest.\n", "versions": [{"version": "v1", "created": "Tue, 16 Oct 2018 00:11:03 GMT"}, {"version": "v2", "created": "Fri, 24 May 2019 20:05:04 GMT"}], "update_date": "2019-05-28", "authors_parsed": [["Raziperchikolaei", "Ramin", ""], ["Bhat", "Harish S.", ""]]}, {"id": "1810.06767", "submitter": "Zhibin Liao", "authors": "Zhibin Liao, Tom Drummond, Ian Reid, and Gustavo Carneiro", "title": "Approximate Fisher Information Matrix to Characterise the Training of\n  Deep Neural Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we introduce a novel methodology for characterising the\nperformance of deep learning networks (ResNets and DenseNet) with respect to\ntraining convergence and generalisation as a function of mini-batch size and\nlearning rate for image classification. This methodology is based on novel\nmeasurements derived from the eigenvalues of the approximate Fisher information\nmatrix, which can be efficiently computed even for high capacity deep models.\nOur proposed measurements can help practitioners to monitor and control the\ntraining process (by actively tuning the mini-batch size and learning rate) to\nallow for good training convergence and generalisation. Furthermore, the\nproposed measurements also allow us to show that it is possible to optimise the\ntraining process with a new dynamic sampling training approach that\ncontinuously and automatically change the mini-batch size and learning rate\nduring the training process. Finally, we show that the proposed dynamic\nsampling training approach has a faster training time and a competitive\nclassification accuracy compared to the current state of the art.\n", "versions": [{"version": "v1", "created": "Tue, 16 Oct 2018 00:37:03 GMT"}], "update_date": "2018-10-17", "authors_parsed": [["Liao", "Zhibin", ""], ["Drummond", "Tom", ""], ["Reid", "Ian", ""], ["Carneiro", "Gustavo", ""]]}, {"id": "1810.06773", "submitter": "Xiaodong Cui", "authors": "Xiaodong Cui, Wei Zhang, Zolt\\'an T\\\"uske and Michael Picheny", "title": "Evolutionary Stochastic Gradient Descent for Optimization of Deep Neural\n  Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a population-based Evolutionary Stochastic Gradient Descent (ESGD)\nframework for optimizing deep neural networks. ESGD combines SGD and\ngradient-free evolutionary algorithms as complementary algorithms in one\nframework in which the optimization alternates between the SGD step and\nevolution step to improve the average fitness of the population. With a\nback-off strategy in the SGD step and an elitist strategy in the evolution\nstep, it guarantees that the best fitness in the population will never degrade.\nIn addition, individuals in the population optimized with various SGD-based\noptimizers using distinct hyper-parameters in the SGD step are considered as\ncompeting species in a coevolution setting such that the complementarity of the\noptimizers is also taken into account. The effectiveness of ESGD is\ndemonstrated across multiple applications including speech recognition, image\nrecognition and language modeling, using networks with a variety of deep\narchitectures.\n", "versions": [{"version": "v1", "created": "Tue, 16 Oct 2018 01:12:06 GMT"}], "update_date": "2018-10-17", "authors_parsed": [["Cui", "Xiaodong", ""], ["Zhang", "Wei", ""], ["T\u00fcske", "Zolt\u00e1n", ""], ["Picheny", "Michael", ""]]}, {"id": "1810.06784", "submitter": "Jonas Rothfuss", "authors": "Jonas Rothfuss, Dennis Lee, Ignasi Clavera, Tamim Asfour, Pieter\n  Abbeel", "title": "ProMP: Proximal Meta-Policy Search", "comments": "The first three authors contributed equally. Accepted for ICLR 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Credit assignment in Meta-reinforcement learning (Meta-RL) is still poorly\nunderstood. Existing methods either neglect credit assignment to pre-adaptation\nbehavior or implement it naively. This leads to poor sample-efficiency during\nmeta-training as well as ineffective task identification strategies. This paper\nprovides a theoretical analysis of credit assignment in gradient-based Meta-RL.\nBuilding on the gained insights we develop a novel meta-learning algorithm that\novercomes both the issue of poor credit assignment and previous difficulties in\nestimating meta-policy gradients. By controlling the statistical distance of\nboth pre-adaptation and adapted policies during meta-policy search, the\nproposed algorithm endows efficient and stable meta-learning. Our approach\nleads to superior pre-adaptation policy behavior and consistently outperforms\nprevious Meta-RL algorithms in sample-efficiency, wall-clock time, and\nasymptotic performance.\n", "versions": [{"version": "v1", "created": "Tue, 16 Oct 2018 01:43:51 GMT"}, {"version": "v2", "created": "Wed, 17 Oct 2018 18:09:00 GMT"}, {"version": "v3", "created": "Fri, 21 Dec 2018 13:10:34 GMT"}], "update_date": "2018-12-24", "authors_parsed": [["Rothfuss", "Jonas", ""], ["Lee", "Dennis", ""], ["Clavera", "Ignasi", ""], ["Asfour", "Tamim", ""], ["Abbeel", "Pieter", ""]]}, {"id": "1810.06793", "submitter": "Xiang Wang", "authors": "Rong Ge, Rohith Kuditipudi, Zhize Li, Xiang Wang", "title": "Learning Two-layer Neural Networks with Symmetric Inputs", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We give a new algorithm for learning a two-layer neural network under a\ngeneral class of input distributions. Assuming there is a ground-truth\ntwo-layer network $$ y = A \\sigma(Wx) + \\xi, $$ where $A,W$ are weight\nmatrices, $\\xi$ represents noise, and the number of neurons in the hidden layer\nis no larger than the input or output, our algorithm is guaranteed to recover\nthe parameters $A,W$ of the ground-truth network. The only requirement on the\ninput $x$ is that it is symmetric, which still allows highly complicated and\nstructured input.\n  Our algorithm is based on the method-of-moments framework and extends several\nresults in tensor decompositions. We use spectral algorithms to avoid the\ncomplicated non-convex optimization in learning neural networks. Experiments\nshow that our algorithm can robustly learn the ground-truth neural network with\na small number of samples for many symmetric input distributions.\n", "versions": [{"version": "v1", "created": "Tue, 16 Oct 2018 02:26:55 GMT"}, {"version": "v2", "created": "Sun, 3 Feb 2019 19:46:44 GMT"}], "update_date": "2019-02-05", "authors_parsed": [["Ge", "Rong", ""], ["Kuditipudi", "Rohith", ""], ["Li", "Zhize", ""], ["Wang", "Xiang", ""]]}, {"id": "1810.06801", "submitter": "Jerry Ma", "authors": "Jerry Ma and Denis Yarats", "title": "Quasi-hyperbolic momentum and Adam for deep learning", "comments": "Published as a conference paper at ICLR 2019. This version corrects\n  one typological error in the published text", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Momentum-based acceleration of stochastic gradient descent (SGD) is widely\nused in deep learning. We propose the quasi-hyperbolic momentum algorithm (QHM)\nas an extremely simple alteration of momentum SGD, averaging a plain SGD step\nwith a momentum step. We describe numerous connections to and identities with\nother algorithms, and we characterize the set of two-state optimization\nalgorithms that QHM can recover. Finally, we propose a QH variant of Adam\ncalled QHAdam, and we empirically demonstrate that our algorithms lead to\nsignificantly improved training in a variety of settings, including a new\nstate-of-the-art result on WMT16 EN-DE. We hope that these empirical results,\ncombined with the conceptual and practical simplicity of QHM and QHAdam, will\nspur interest from both practitioners and researchers. Code is immediately\navailable.\n", "versions": [{"version": "v1", "created": "Tue, 16 Oct 2018 03:58:14 GMT"}, {"version": "v2", "created": "Wed, 28 Nov 2018 20:40:01 GMT"}, {"version": "v3", "created": "Wed, 9 Jan 2019 00:50:15 GMT"}, {"version": "v4", "created": "Thu, 2 May 2019 04:57:39 GMT"}], "update_date": "2019-05-03", "authors_parsed": [["Ma", "Jerry", ""], ["Yarats", "Denis", ""]]}, {"id": "1810.06803", "submitter": "Gal Mishne", "authors": "Gal Mishne, Eric C. Chi, Ronald R. Coifman", "title": "Co-manifold learning with missing data", "comments": "16 pages, 9 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG stat.ME", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Representation learning is typically applied to only one mode of a data\nmatrix, either its rows or columns. Yet in many applications, there is an\nunderlying geometry to both the rows and the columns. We propose utilizing this\ncoupled structure to perform co-manifold learning: uncovering the underlying\ngeometry of both the rows and the columns of a given matrix, where we focus on\na missing data setting. Our unsupervised approach consists of three components.\nWe first solve a family of optimization problems to estimate a complete matrix\nat multiple scales of smoothness. We then use this collection of smooth matrix\nestimates to compute pairwise distances on the rows and columns based on a new\nmulti-scale metric that implicitly introduces a coupling between the rows and\nthe columns. Finally, we construct row and column representations from these\nmulti-scale metrics. We demonstrate that our approach outperforms competing\nmethods in both data visualization and clustering.\n", "versions": [{"version": "v1", "created": "Tue, 16 Oct 2018 04:01:45 GMT"}], "update_date": "2018-10-17", "authors_parsed": [["Mishne", "Gal", ""], ["Chi", "Eric C.", ""], ["Coifman", "Ronald R.", ""]]}, {"id": "1810.06807", "submitter": "Kartik Hegde", "authors": "Kartik Hegde, Rohit Agrawal, Yulun Yao, Christopher W. Fletcher", "title": "Morph: Flexible Acceleration for 3D CNN-based Video Understanding", "comments": "Appears in the proceedings of the 51st Annual IEEE/ACM International\n  Symposium on Microarchitecture (MICRO), 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AR cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The past several years have seen both an explosion in the use of\nConvolutional Neural Networks (CNNs) and the design of accelerators to make CNN\ninference practical. In the architecture community, the lion share of effort\nhas targeted CNN inference for image recognition. The closely related problem\nof video recognition has received far less attention as an accelerator target.\nThis is surprising, as video recognition is more computationally intensive than\nimage recognition, and video traffic is predicted to be the majority of\ninternet traffic in the coming years.\n  This paper fills the gap between algorithmic and hardware advances for video\nrecognition by providing a design space exploration and flexible architecture\nfor accelerating 3D Convolutional Neural Networks (3D CNNs) - the core kernel\nin modern video understanding. When compared to (2D) CNNs used for image\nrecognition, efficiently accelerating 3D CNNs poses a significant engineering\nchallenge due to their large (and variable over time) memory footprint and\nhigher dimensionality.\n  To address these challenges, we design a novel accelerator, called Morph,\nthat can adaptively support different spatial and temporal tiling strategies\ndepending on the needs of each layer of each target 3D CNN. We codesign a\nsoftware infrastructure alongside the Morph hardware to find good-fit\nparameters to control the hardware. Evaluated on state-of-the-art 3D CNNs,\nMorph achieves up to 3.4x (2.5x average) reduction in energy consumption and\nimproves performance/watt by up to 5.1x (4x average) compared to a baseline 3D\nCNN accelerator, with an area overhead of 5%. Morph further achieves a 15.9x\naverage energy reduction on 3D CNNs when compared to Eyeriss.\n", "versions": [{"version": "v1", "created": "Tue, 16 Oct 2018 04:49:15 GMT"}], "update_date": "2018-10-17", "authors_parsed": [["Hegde", "Kartik", ""], ["Agrawal", "Rohit", ""], ["Yao", "Yulun", ""], ["Fletcher", "Christopher W.", ""]]}, {"id": "1810.06825", "submitter": "Xu Feng", "authors": "Xu Feng, Yuyang Xie, Mingye Song, Wenjian Yu, Jie Tang", "title": "Fast Randomized PCA for Sparse Data", "comments": "16 pages, ACML2018 Accepted", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Principal component analysis (PCA) is widely used for dimension reduction and\nembedding of real data in social network analysis, information retrieval, and\nnatural language processing, etc. In this work we propose a fast randomized PCA\nalgorithm for processing large sparse data. The algorithm has similar accuracy\nto the basic randomized SVD (rPCA) algorithm (Halko et al., 2011), but is\nlargely optimized for sparse data. It also has good flexibility to trade off\nruntime against accuracy for practical usage. Experiments on real data show\nthat the proposed algorithm is up to 9.1X faster than the basic rPCA algorithm\nwithout accuracy loss, and is up to 20X faster than the svds in Matlab with\nlittle error. The algorithm computes the first 100 principal components of a\nlarge information retrieval data with 12,869,521 persons and 323,899 keywords\nin less than 400 seconds on a 24-core machine, while all conventional methods\nfail due to the out-of-memory issue.\n", "versions": [{"version": "v1", "created": "Tue, 16 Oct 2018 06:00:28 GMT"}], "update_date": "2018-10-17", "authors_parsed": [["Feng", "Xu", ""], ["Xie", "Yuyang", ""], ["Song", "Mingye", ""], ["Yu", "Wenjian", ""], ["Tang", "Jie", ""]]}, {"id": "1810.06833", "submitter": "Chao Qian", "authors": "Yibo Zhang, Chao Qian, Ke Tang", "title": "Maximizing Monotone DR-submodular Continuous Functions by\n  Derivative-free Optimization", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we study the problem of monotone (weakly) DR-submodular\ncontinuous maximization. While previous methods require the gradient\ninformation of the objective function, we propose a derivative-free algorithm\nLDGM for the first time. We define $\\beta$ and $\\alpha$ to characterize how\nclose a function is to continuous DR-submodulr and submodular, respectively.\nUnder a convex polytope constraint, we prove that LDGM can achieve a\n$(1-e^{-\\beta}-\\epsilon)$-approximation guarantee after $O(1/\\epsilon)$\niterations, which is the same as the best previous gradient-based algorithm.\nMoreover, in some special cases, a variant of LDGM can achieve a\n$((\\alpha/2)(1-e^{-\\alpha})-\\epsilon)$-approximation guarantee for (weakly)\nsubmodular functions. We also compare LDGM with the gradient-based algorithm\nFrank-Wolfe under noise, and show that LDGM can be more robust. Empirical\nresults on budget allocation verify the effectiveness of LDGM.\n", "versions": [{"version": "v1", "created": "Tue, 16 Oct 2018 06:32:34 GMT"}, {"version": "v2", "created": "Sat, 23 Feb 2019 08:23:23 GMT"}], "update_date": "2019-02-26", "authors_parsed": [["Zhang", "Yibo", ""], ["Qian", "Chao", ""], ["Tang", "Ke", ""]]}, {"id": "1810.06839", "submitter": "Alex Nowak-Vila", "authors": "Alex Nowak-Vila (SIERRA, PSL), Francis Bach (SIERRA, PSL), Alessandro\n  Rudi (SIERRA, PSL)", "title": "Sharp Analysis of Learning with Discrete Losses", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CC math.ST stat.ML stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The problem of devising learning strategies for discrete losses (e.g.,\nmultilabeling, ranking) is currently addressed with methods and theoretical\nanalyses ad-hoc for each loss. In this paper we study a least-squares framework\nto systematically design learning algorithms for discrete losses, with\nquantitative characterizations in terms of statistical and computational\ncomplexity. In particular we improve existing results by providing explicit\ndependence on the number of labels for a wide class of losses and faster\nlearning rates in conditions of low-noise. Theoretical results are complemented\nwith experiments on real datasets, showing the effectiveness of the proposed\ngeneral approach.\n", "versions": [{"version": "v1", "created": "Tue, 16 Oct 2018 06:44:42 GMT"}], "update_date": "2018-10-17", "authors_parsed": [["Nowak-Vila", "Alex", "", "SIERRA, PSL"], ["Bach", "Francis", "", "SIERRA, PSL"], ["Rudi", "Alessandro", "", "SIERRA, PSL"]]}, {"id": "1810.06860", "submitter": "Xu Feng", "authors": "Xu Feng, Wenjian Yu, Yaohang Li", "title": "Faster Matrix Completion Using Randomized SVD", "comments": "8 pages, 5 figures, ICTAI 2018 Accepted", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Matrix completion is a widely used technique for image inpainting and\npersonalized recommender system, etc. In this work, we focus on accelerating\nthe matrix completion using faster randomized singular value decomposition\n(rSVD). Firstly, two fast randomized algorithms (rSVD-PI and rSVD- BKI) are\nproposed for handling sparse matrix. They make use of an eigSVD procedure and\nseveral accelerating skills. Then, with the rSVD-BKI algorithm and a new\nsubspace recycling technique, we accelerate the singular value thresholding\n(SVT) method in [1] to realize faster matrix completion. Experiments show that\nthe proposed rSVD algorithms can be 6X faster than the basic rSVD algorithm [2]\nwhile keeping same accuracy. For image inpainting and movie-rating estimation\nproblems, the proposed accelerated SVT algorithm consumes 15X and 8X less CPU\ntime than the methods using svds and lansvd respectively, without loss of\naccuracy.\n", "versions": [{"version": "v1", "created": "Tue, 16 Oct 2018 07:57:07 GMT"}], "update_date": "2018-10-17", "authors_parsed": [["Feng", "Xu", ""], ["Yu", "Wenjian", ""], ["Li", "Yaohang", ""]]}, {"id": "1810.06870", "submitter": "Denise Ratasich", "authors": "Denise Ratasich, Faiq Khalid, Florian Geissler, Radu Grosu, Muhammad\n  Shafique, Ezio Bartocci", "title": "A Roadmap Towards Resilient Internet of Things for Cyber-Physical\n  Systems", "comments": "preprint (2018-10-29)", "journal-ref": "IEEE Access 7 (2019) 13260 - 13283", "doi": "10.1109/ACCESS.2019.2891969", "report-no": null, "categories": "cs.ET cs.LG cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The Internet of Things (IoT) is a ubiquitous system connecting many different\ndevices - the things - which can be accessed from the distance. The\ncyber-physical systems (CPS) monitor and control the things from the distance.\nAs a result, the concepts of dependability and security get deeply intertwined.\nThe increasing level of dynamicity, heterogeneity, and complexity adds to the\nsystem's vulnerability, and challenges its ability to react to faults. This\npaper summarizes state-of-the-art of existing work on anomaly detection,\nfault-tolerance and self-healing, and adds a number of other methods applicable\nto achieve resilience in an IoT. We particularly focus on non-intrusive methods\nensuring data integrity in the network. Furthermore, this paper presents the\nmain challenges in building a resilient IoT for CPS which is crucial in the era\nof smart CPS with enhanced connectivity (an excellent example of such a system\nis connected autonomous vehicles). It further summarizes our solutions,\nwork-in-progress and future work to this topic to enable \"Trustworthy IoT for\nCPS\". Finally, this framework is illustrated on a selected use case: A smart\nsensor infrastructure in the transport domain.\n", "versions": [{"version": "v1", "created": "Tue, 16 Oct 2018 08:22:58 GMT"}, {"version": "v2", "created": "Tue, 6 Nov 2018 13:25:14 GMT"}], "update_date": "2019-03-21", "authors_parsed": [["Ratasich", "Denise", ""], ["Khalid", "Faiq", ""], ["Geissler", "Florian", ""], ["Grosu", "Radu", ""], ["Shafique", "Muhammad", ""], ["Bartocci", "Ezio", ""]]}, {"id": "1810.06877", "submitter": "Kele Xu", "authors": "Kele Xu, Haibo Mi, Dawei Feng, Huaimin Wang, Chuan Chen, Zibin Zheng,\n  Xu Lan", "title": "Collaborative Deep Learning Across Multiple Data Centers", "comments": "Submitted to AAAI 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Valuable training data is often owned by independent organizations and\nlocated in multiple data centers. Most deep learning approaches require to\ncentralize the multi-datacenter data for performance purpose. In practice,\nhowever, it is often infeasible to transfer all data to a centralized data\ncenter due to not only bandwidth limitation but also the constraints of privacy\nregulations. Model averaging is a conventional choice for data parallelized\ntraining, but its ineffectiveness is claimed by previous studies as deep neural\nnetworks are often non-convex. In this paper, we argue that model averaging can\nbe effective in the decentralized environment by using two strategies, namely,\nthe cyclical learning rate and the increased number of epochs for local model\ntraining. With the two strategies, we show that model averaging can provide\ncompetitive performance in the decentralized mode compared to the\ndata-centralized one. In a practical environment with multiple data centers, we\nconduct extensive experiments using state-of-the-art deep network architectures\non different types of data. Results demonstrate the effectiveness and\nrobustness of the proposed method.\n", "versions": [{"version": "v1", "created": "Tue, 16 Oct 2018 08:33:33 GMT"}], "update_date": "2018-10-17", "authors_parsed": [["Xu", "Kele", ""], ["Mi", "Haibo", ""], ["Feng", "Dawei", ""], ["Wang", "Huaimin", ""], ["Chen", "Chuan", ""], ["Zheng", "Zibin", ""], ["Lan", "Xu", ""]]}, {"id": "1810.06891", "submitter": "Sharad Vikram", "authors": "Sharad Vikram, Matthew D. Hoffman, Matthew J. Johnson", "title": "The LORACs prior for VAEs: Letting the Trees Speak for the Data", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In variational autoencoders, the prior on the latent codes $z$ is often\ntreated as an afterthought, but the prior shapes the kind of latent\nrepresentation that the model learns. If the goal is to learn a representation\nthat is interpretable and useful, then the prior should reflect the ways in\nwhich the high-level factors that describe the data vary. The \"default\" prior\nis an isotropic normal, but if the natural factors of variation in the dataset\nexhibit discrete structure or are not independent, then the isotropic-normal\nprior will actually encourage learning representations that mask this\nstructure. To alleviate this problem, we propose using a flexible Bayesian\nnonparametric hierarchical clustering prior based on the time-marginalized\ncoalescent (TMC). To scale learning to large datasets, we develop a new\ninducing-point approximation and inference algorithm. We then apply the method\nwithout supervision to several datasets and examine the interpretability and\npractical performance of the inferred hierarchies and learned latent space.\n", "versions": [{"version": "v1", "created": "Tue, 16 Oct 2018 09:24:00 GMT"}], "update_date": "2018-10-17", "authors_parsed": [["Vikram", "Sharad", ""], ["Hoffman", "Matthew D.", ""], ["Johnson", "Matthew J.", ""]]}, {"id": "1810.06892", "submitter": "Aiga Suzuki", "authors": "Aiga Suzuki, Hayaru Shouno", "title": "A Generative Model of Textures Using Hierarchical Probabilistic\n  Principal Component Analysis", "comments": "6 pages, 9 figures; A proceeding of PDPTA'17 accepted as an oral\n  presentation", "journal-ref": "Proc. of the 2017 Intl. Conference on Parallel and Distributed\n  Processing Techniques and Applications (PDPTA'17), CSREA Press, pp.333-338,\n  (2017)", "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Modeling of textures in natural images is an important task to make a\nmicroscopic model of natural images. Portilla and Simoncelli proposed a\ngenerative texture model, which is based on the mechanism of visual systems in\nbrains, with a set of texture features and a feature matching. On the other\nhand, the texture features, used in Portillas' model, have redundancy between\nits components came from typical natural textures. In this paper, we propose a\ncontracted texture model which provides a dimension reduction for the\nPortillas' feature. This model is based on a hierarchical principal components\nanalysis using known group structure of the feature. In the experiment, we\nreveal effective dimensions to describe texture is fewer than the original\ndescription. Moreover, we also demonstrate how well the textures can be\nsynthesized from the contracted texture representations.\n", "versions": [{"version": "v1", "created": "Tue, 16 Oct 2018 09:24:19 GMT"}], "update_date": "2018-10-17", "authors_parsed": [["Suzuki", "Aiga", ""], ["Shouno", "Hayaru", ""]]}, {"id": "1810.06917", "submitter": "Fragkiskos  Malliaros", "authors": "Abdulkadir \\c{C}elikkanat, Fragkiskos D. Malliaros", "title": "TNE: A Latent Model for Representation Learning on Networks", "comments": "9 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.SI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Network representation learning (NRL) methods aim to map each vertex into a\nlow dimensional space by preserving the local and global structure of a given\nnetwork, and in recent years they have received a significant attention thanks\nto their success in several challenging problems. Although various approaches\nhave been proposed to compute node embeddings, many successful methods benefit\nfrom random walks in order to transform a given network into a collection of\nsequences of nodes and then they target to learn the representation of nodes by\npredicting the context of each vertex within the sequence. In this paper, we\nintroduce a general framework to enhance the embeddings of nodes acquired by\nmeans of the random walk-based approaches. Similar to the notion of topical\nword embeddings in NLP, the proposed method assigns each vertex to a topic with\nthe favor of various statistical models and community detection methods, and\nthen generates the enhanced community representations. We evaluate our method\non two downstream tasks: node classification and link prediction. The\nexperimental results demonstrate that the incorporation of vertex and topic\nembeddings outperform widely-known baseline NRL methods.\n", "versions": [{"version": "v1", "created": "Tue, 16 Oct 2018 10:26:47 GMT"}], "update_date": "2018-10-17", "authors_parsed": [["\u00c7elikkanat", "Abdulkadir", ""], ["Malliaros", "Fragkiskos D.", ""]]}, {"id": "1810.06933", "submitter": "Dennis Eschweiler", "authors": "Dennis Eschweiler, Thiago V. Spina, Rohan C. Choudhury, Elliot\n  Meyerowitz, Alexandre Cunha, Johannes Stegmaier", "title": "CNN-based Preprocessing to Optimize Watershed-based Cell Segmentation in\n  3D Confocal Microscopy Images", "comments": "5 pages, 4 figures, 1 table", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The quantitative analysis of cellular membranes helps understanding\ndevelopmental processes at the cellular level. Particularly 3D microscopic\nimage data offers valuable insights into cell dynamics, but error-free\nautomatic segmentation remains challenging due to the huge amount of data\ngenerated and strong variations in image intensities. In this paper, we propose\na new 3D segmentation approach which combines the discriminative power of\nconvolutional neural networks (CNNs) for preprocessing and investigates the\nperformance of three watershed-based postprocessing strategies (WS), which are\nwell suited to segment object shapes, even when supplied with vague seed and\nboundary constraints. To leverage the full potential of the watershed\nalgorithm, the multi-instance segmentation problem is initially interpreted as\nthree-class semantic segmentation problem, which in turn is well-suited for the\napplication of CNNs. Using manually annotated 3D confocal microscopy images of\nArabidopsis thaliana, we show the superior performance of the proposed method\ncompared to the state of the art.\n", "versions": [{"version": "v1", "created": "Tue, 16 Oct 2018 11:30:54 GMT"}], "update_date": "2018-10-17", "authors_parsed": [["Eschweiler", "Dennis", ""], ["Spina", "Thiago V.", ""], ["Choudhury", "Rohan C.", ""], ["Meyerowitz", "Elliot", ""], ["Cunha", "Alexandre", ""], ["Stegmaier", "Johannes", ""]]}, {"id": "1810.06943", "submitter": "Arsenii Ashukha", "authors": "Andrei Atanov, Arsenii Ashukha, Kirill Struminsky, Dmitry Vetrov, Max\n  Welling", "title": "The Deep Weight Prior", "comments": "TL;DR: The deep weight prior learns a generative model for kernels of\n  convolutional neural networks, that acts as a prior distribution while\n  training on new datasets", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Bayesian inference is known to provide a general framework for incorporating\nprior knowledge or specific properties into machine learning models via\ncarefully choosing a prior distribution. In this work, we propose a new type of\nprior distributions for convolutional neural networks, deep weight prior (DWP),\nthat exploit generative models to encourage a specific structure of trained\nconvolutional filters e.g., spatial correlations of weights. We define DWP in\nthe form of an implicit distribution and propose a method for variational\ninference with such type of implicit priors. In experiments, we show that DWP\nimproves the performance of Bayesian neural networks when training data are\nlimited, and initialization of weights with samples from DWP accelerates\ntraining of conventional convolutional neural networks.\n", "versions": [{"version": "v1", "created": "Tue, 16 Oct 2018 11:59:10 GMT"}, {"version": "v2", "created": "Thu, 8 Nov 2018 17:39:40 GMT"}, {"version": "v3", "created": "Fri, 9 Nov 2018 06:47:43 GMT"}, {"version": "v4", "created": "Wed, 14 Nov 2018 15:06:04 GMT"}, {"version": "v5", "created": "Tue, 27 Nov 2018 15:41:39 GMT"}, {"version": "v6", "created": "Mon, 18 Feb 2019 21:51:28 GMT"}], "update_date": "2019-02-20", "authors_parsed": [["Atanov", "Andrei", ""], ["Ashukha", "Arsenii", ""], ["Struminsky", "Kirill", ""], ["Vetrov", "Dmitry", ""], ["Welling", "Max", ""]]}, {"id": "1810.06979", "submitter": "Yuan Gao", "authors": "Yuan Gao (1), Fangkai Yang (2), Martin Frisk (1), Daniel Hernandez\n  (3), Christopher Peters (2) and Ginevra Castellano (1) ((1) Department of\n  Information Technology, Uppsala University, Uppsala, Sweden, (2) Department\n  of Computational Science and Technology, Royal Institute of Technology, KTH,\n  Stockholm, Sweden, (3) Department of Computer Science, University of York,\n  York, United Kingdom)", "title": "Learning Socially Appropriate Robot Approaching Behavior Toward Groups\n  using Deep Reinforcement Learning", "comments": "accepted for The 28th IEEE International Conference on Robot & Human\n  Interactive Communication (Ro-Man)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.HC cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep reinforcement learning has recently been widely applied in robotics to\nstudy tasks such as locomotion and grasping, but its application to social\nhuman-robot interaction (HRI) remains a challenge. In this paper, we present a\ndeep learning scheme that acquires a prior model of robot approaching behavior\nin simulation and applies it to real-world interaction with a physical robot\napproaching groups of humans. The scheme, which we refer to as Staged Social\nBehavior Learning (SSBL), considers different stages of learning in social\nscenarios. We learn robot approaching behaviors towards small groups in\nsimulation and evaluate the performance of the model using objective and\nsubjective measures in a perceptual study and a HRI user study with human\nparticipants. Results show that our model generates more socially appropriate\nbehavior compared to a state-of-the-art model.\n", "versions": [{"version": "v1", "created": "Tue, 16 Oct 2018 13:27:10 GMT"}, {"version": "v2", "created": "Mon, 22 Oct 2018 07:43:20 GMT"}, {"version": "v3", "created": "Mon, 12 Aug 2019 13:53:51 GMT"}], "update_date": "2019-08-13", "authors_parsed": [["Gao", "Yuan", ""], ["Yang", "Fangkai", ""], ["Frisk", "Martin", ""], ["Hernandez", "Daniel", ""], ["Peters", "Christopher", ""], ["Castellano", "Ginevra", ""]]}, {"id": "1810.06983", "submitter": "Kaspar M\\\"artens", "authors": "Kaspar M\\\"artens, Kieran R. Campbell, Christopher Yau", "title": "Decomposing feature-level variation with Covariate Gaussian Process\n  Latent Variable Models", "comments": null, "journal-ref": "Proceedings of the 36th International Conference on Machine\n  Learning (ICML 2019)", "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The interpretation of complex high-dimensional data typically requires the\nuse of dimensionality reduction techniques to extract explanatory\nlow-dimensional representations. However, in many real-world problems these\nrepresentations may not be sufficient to aid interpretation on their own, and\nit would be desirable to interpret the model in terms of the original features\nthemselves. Our goal is to characterise how feature-level variation depends on\nlatent low-dimensional representations, external covariates, and non-linear\ninteractions between the two. In this paper, we propose to achieve this through\na structured kernel decomposition in a hybrid Gaussian Process model which we\ncall the Covariate Gaussian Process Latent Variable Model (c-GPLVM). We\ndemonstrate the utility of our model on simulated examples and applications in\ndisease progression modelling from high-dimensional gene expression data in the\npresence of additional phenotypes. In each setting we show how the c-GPLVM can\nextract low-dimensional structures from high-dimensional data sets whilst\nallowing a breakdown of feature-level variability that is not present in other\ncommonly used dimensionality reduction approaches.\n", "versions": [{"version": "v1", "created": "Tue, 16 Oct 2018 13:29:56 GMT"}, {"version": "v2", "created": "Mon, 24 Jun 2019 14:03:32 GMT"}], "update_date": "2019-06-25", "authors_parsed": [["M\u00e4rtens", "Kaspar", ""], ["Campbell", "Kieran R.", ""], ["Yau", "Christopher", ""]]}, {"id": "1810.06992", "submitter": "Bruce MacLennan", "authors": "Bruce MacLennan", "title": "Topographic Representation for Quantum Machine Learning", "comments": "29 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG quant-ph stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper proposes a brain-inspired approach to quantum machine learning\nwith the goal of circumventing many of the complications of other approaches.\nThe fact that quantum processes are unitary presents both opportunities and\nchallenges. A principal opportunity is that a large number of computations can\nbe carried out in parallel in linear superposition, that is, quantum\nparallelism. The challenge is that the process is linear, and most approaches\nto machine learning depend significantly on nonlinear processes. Fortunately,\nthe situation is not hopeless, for we know that nonlinear processes can be\nembedded in unitary processes, as is familiar from the circuit model of quantum\ncomputation. This paper explores an approach to the quantum implementation of\nmachine learning involving nonlinear functions operating on information\nrepresented topographically (by computational maps), as common in neural\ncortex.\n", "versions": [{"version": "v1", "created": "Sat, 13 Oct 2018 01:54:08 GMT"}, {"version": "v2", "created": "Thu, 17 Jan 2019 17:38:12 GMT"}, {"version": "v3", "created": "Wed, 15 May 2019 01:13:20 GMT"}], "update_date": "2019-05-16", "authors_parsed": [["MacLennan", "Bruce", ""]]}, {"id": "1810.06999", "submitter": "Sai Praneeth Karimireddy", "authors": "Sai Praneeth Karimireddy, Anastasia Koloskova, Sebastian U. Stich,\n  Martin Jaggi", "title": "Efficient Greedy Coordinate Descent for Composite Problems", "comments": "44 pages, 17 figures, 3 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.OC cs.LG stat.CO stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Coordinate descent with random coordinate selection is the current state of\nthe art for many large scale optimization problems. However, greedy selection\nof the steepest coordinate on smooth problems can yield convergence rates\nindependent of the dimension $n$, and requiring upto $n$ times fewer\niterations.\n  In this paper, we consider greedy updates that are based on subgradients for\na class of non-smooth composite problems, which includes $L1$-regularized\nproblems, SVMs and related applications. For these problems we provide (i) the\nfirst linear rates of convergence independent of $n$, and show that our greedy\nupdate rule provides speedups similar to those obtained in the smooth case.\nThis was previously conjectured to be true for a stronger greedy coordinate\nselection strategy.\n  Furthermore, we show that (ii) our new selection rule can be mapped to\ninstances of maximum inner product search, allowing to leverage standard\nnearest neighbor algorithms to speed up the implementation. We demonstrate the\nvalidity of the approach through extensive numerical experiments.\n", "versions": [{"version": "v1", "created": "Tue, 16 Oct 2018 13:54:59 GMT"}], "update_date": "2018-10-17", "authors_parsed": [["Karimireddy", "Sai Praneeth", ""], ["Koloskova", "Anastasia", ""], ["Stich", "Sebastian U.", ""], ["Jaggi", "Martin", ""]]}, {"id": "1810.07052", "submitter": "Yigitcan Kaya", "authors": "Yigitcan Kaya, Sanghyun Hong, Tudor Dumitras", "title": "Shallow-Deep Networks: Understanding and Mitigating Network Overthinking", "comments": "Accepted to ICML2019. Source code here: www.shallowdeep.network", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We characterize a prevalent weakness of deep neural networks\n(DNNs)---overthinking---which occurs when a DNN can reach correct predictions\nbefore its final layer. Overthinking is computationally wasteful, and it can\nalso be destructive when, by the final layer, a correct prediction changes into\na misclassification. Understanding overthinking requires studying how each\nprediction evolves during a DNN's forward pass, which conventionally is opaque.\nFor prediction transparency, we propose the Shallow-Deep Network (SDN), a\ngeneric modification to off-the-shelf DNNs that introduces internal\nclassifiers. We apply SDN to four modern architectures, trained on three image\nclassification tasks, to characterize the overthinking problem. We show that\nSDNs can mitigate the wasteful effect of overthinking with confidence-based\nearly exits, which reduce the average inference cost by more than 50% and\npreserve the accuracy. We also find that the destructive effect occurs for 50%\nof misclassifications on natural inputs and that it can be induced,\nadversarially, with a recent backdooring attack. To mitigate this effect, we\npropose a new confusion metric to quantify the internal disagreements that will\nlikely lead to misclassifications.\n", "versions": [{"version": "v1", "created": "Tue, 16 Oct 2018 14:51:13 GMT"}, {"version": "v2", "created": "Tue, 7 May 2019 23:34:31 GMT"}, {"version": "v3", "created": "Thu, 9 May 2019 00:49:52 GMT"}], "update_date": "2019-05-10", "authors_parsed": [["Kaya", "Yigitcan", ""], ["Hong", "Sanghyun", ""], ["Dumitras", "Tudor", ""]]}, {"id": "1810.07076", "submitter": "Sashank J. Reddi", "authors": "Sashank J. Reddi, Satyen Kale, Felix Yu, Dan Holtmann-Rice, Jiecao\n  Chen, Sanjiv Kumar", "title": "Stochastic Negative Mining for Learning with Large Output Spaces", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the problem of retrieving the most relevant labels for a given\ninput when the size of the output space is very large. Retrieval methods are\nmodeled as set-valued classifiers which output a small set of classes for each\ninput, and a mistake is made if the label is not in the output set. Despite its\npractical importance, a statistically principled, yet practical solution to\nthis problem is largely missing. To this end, we first define a family of\nsurrogate losses and show that they are calibrated and convex under certain\nconditions on the loss parameters and data distribution, thereby establishing a\nstatistical and analytical basis for using these losses. Furthermore, we\nidentify a particularly intuitive class of loss functions in the aforementioned\nfamily and show that they are amenable to practical implementation in the large\noutput space setting (i.e. computation is possible without evaluating scores of\nall labels) by developing a technique called Stochastic Negative Mining. We\nalso provide generalization error bounds for the losses in the family. Finally,\nwe conduct experiments which demonstrate that Stochastic Negative Mining yields\nbenefits over commonly used negative sampling approaches.\n", "versions": [{"version": "v1", "created": "Tue, 16 Oct 2018 15:27:31 GMT"}], "update_date": "2018-10-17", "authors_parsed": [["Reddi", "Sashank J.", ""], ["Kale", "Satyen", ""], ["Yu", "Felix", ""], ["Holtmann-Rice", "Dan", ""], ["Chen", "Jiecao", ""], ["Kumar", "Sanjiv", ""]]}, {"id": "1810.07121", "submitter": "Lerrel Pinto Mr", "authors": "Pratyusha Sharma, Lekha Mohan, Lerrel Pinto, Abhinav Gupta", "title": "Multiple Interactions Made Easy (MIME): Large Scale Demonstrations Data\n  for Imitation", "comments": "10 pages, CoRL 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In recent years, we have seen an emergence of data-driven approaches in\nrobotics. However, most existing efforts and datasets are either in simulation\nor focus on a single task in isolation such as grasping, pushing or poking. In\norder to make progress and capture the space of manipulation, we would need to\ncollect a large-scale dataset of diverse tasks such as pouring, opening\nbottles, stacking objects etc. But how does one collect such a dataset? In this\npaper, we present the largest available robotic-demonstration dataset (MIME)\nthat contains 8260 human-robot demonstrations over 20 different robotic tasks\n(https://sites.google.com/view/mimedataset). These tasks range from the simple\ntask of pushing objects to the difficult task of stacking household objects.\nOur dataset consists of videos of human demonstrations and kinesthetic\ntrajectories of robot demonstrations. We also propose to use this dataset for\nthe task of mapping 3rd person video features to robot trajectories.\nFurthermore, we present two different approaches using this dataset and\nevaluate the predicted robot trajectories against ground-truth trajectories. We\nhope our dataset inspires research in multiple areas including visual\nimitation, trajectory prediction, and multi-task robotic learning.\n", "versions": [{"version": "v1", "created": "Tue, 16 Oct 2018 16:27:43 GMT"}], "update_date": "2018-10-17", "authors_parsed": [["Sharma", "Pratyusha", ""], ["Mohan", "Lekha", ""], ["Pinto", "Lerrel", ""], ["Gupta", "Abhinav", ""]]}, {"id": "1810.07128", "submitter": "Sen Na", "authors": "Sen Na, Zhuoran Yang, Zhaoran Wang, Mladen Kolar", "title": "High-dimensional Varying Index Coefficient Models via Stein's Identity", "comments": "44 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG stat.CO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the parameter estimation problem for a varying index coefficient\nmodel in high dimensions. Unlike the most existing works that iteratively\nestimate the parameters and link functions, based on the generalized Stein's\nidentity, we propose computationally efficient estimators for the\nhigh-dimensional parameters without estimating the link functions. We consider\ntwo different setups where we either estimate each sparse parameter vector\nindividually or estimate the parameters simultaneously as a sparse or low-rank\nmatrix. For all these cases, our estimators are shown to achieve optimal\nstatistical rates of convergence (up to logarithmic terms in the low-rank\nsetting). Moreover, throughout our analysis, we only require the covariate to\nsatisfy certain moment conditions, which is significantly weaker than the\nGaussian or elliptically symmetric assumptions that are commonly made in the\nexisting literature. Finally, we conduct extensive numerical experiments to\ncorroborate the theoretical results.\n", "versions": [{"version": "v1", "created": "Tue, 16 Oct 2018 16:51:28 GMT"}, {"version": "v2", "created": "Wed, 17 Oct 2018 03:00:26 GMT"}, {"version": "v3", "created": "Sun, 21 Oct 2018 21:56:15 GMT"}, {"version": "v4", "created": "Fri, 25 Oct 2019 18:33:53 GMT"}], "update_date": "2019-10-29", "authors_parsed": [["Na", "Sen", ""], ["Yang", "Zhuoran", ""], ["Wang", "Zhaoran", ""], ["Kolar", "Mladen", ""]]}, {"id": "1810.07132", "submitter": "Wei Dai", "authors": "Wei Dai, Kenji Yoshigoe, William Parsley", "title": "Improving Data Quality through Deep Learning and Statistical Models", "comments": "8 pages, 6 figures, and 3 tables", "journal-ref": "Dai, Wei, Kenji Yoshigoe, and William Parsley. \"Improving Data\n  Quality Through Deep Learning and Statistical Models.\" In Information\n  Technology-New Generations, pp. 515-522. Springer, Cham, 2018", "doi": "10.1007/978-3-319-54978-1_66", "report-no": null, "categories": "cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Traditional data quality control methods are based on users experience or\npreviously established business rules, and this limits performance in addition\nto being a very time consuming process with lower than desirable accuracy.\nUtilizing deep learning, we can leverage computing resources and advanced\ntechniques to overcome these challenges and provide greater value to users. In\nthis paper, we, the authors, first review relevant works and discuss machine\nlearning techniques, tools, and statistical quality models. Second, we offer a\ncreative data quality framework based on deep learning and statistical model\nalgorithm for identifying data quality. Third, we use data involving salary\nlevels from an open dataset published by the state of Arkansas to demonstrate\nhow to identify outlier data and how to improve data quality via deep learning.\nFinally, we discuss future work.\n", "versions": [{"version": "v1", "created": "Tue, 16 Oct 2018 16:57:07 GMT"}], "update_date": "2018-10-17", "authors_parsed": [["Dai", "Wei", ""], ["Yoshigoe", "Kenji", ""], ["Parsley", "William", ""]]}, {"id": "1810.07147", "submitter": "Sinong Geng", "authors": "Sinong Geng, Mladen Kolar and Oluwasanmi Koyejo", "title": "Joint Nonparametric Precision Matrix Estimation with Confounding", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the problem of precision matrix estimation where, due to\nextraneous confounding of the underlying precision matrix, the data are\nindependent but not identically distributed. While such confounding occurs in\nmany scientific problems, our approach is inspired by recent neuroscientific\nresearch suggesting that brain function, as measured using functional magnetic\nresonance imagine (fMRI), is susceptible to confounding by physiological noise\nsuch as breathing and subject motion. Following the scientific motivation, we\npropose a graphical model, which in turn motivates a joint nonparametric\nestimator. We provide theoretical guarantees for the consistency and the\nconvergence rate of the proposed estimator. In addition, we demonstrate that\nthe optimization of the proposed estimator can be transformed into a series of\nlinear programming problems, and thus be efficiently solved in parallel.\nEmpirical results are presented using simulated and real brain imaging data,\nwhich suggest that our approach improves precision matrix estimation, as\ncompared to baselines, when confounding is present.\n", "versions": [{"version": "v1", "created": "Tue, 16 Oct 2018 17:20:15 GMT"}, {"version": "v2", "created": "Thu, 27 Jun 2019 18:35:29 GMT"}], "update_date": "2019-07-01", "authors_parsed": [["Geng", "Sinong", ""], ["Kolar", "Mladen", ""], ["Koyejo", "Oluwasanmi", ""]]}, {"id": "1810.07151", "submitter": "Kirill Neklyudov", "authors": "Kirill Neklyudov, Evgenii Egorov, Pavel Shvechikov, Dmitry Vetrov", "title": "Metropolis-Hastings view on variational inference and adversarial\n  training", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A significant part of MCMC methods can be considered as the\nMetropolis-Hastings (MH) algorithm with different proposal distributions. From\nthis point of view, the problem of constructing a sampler can be reduced to the\nquestion - how to choose a proposal for the MH algorithm? To address this\nquestion, we propose to learn an independent sampler that maximizes the\nacceptance rate of the MH algorithm, which, as we demonstrate, is highly\nrelated to the conventional variational inference. For Bayesian inference, the\nproposed method compares favorably against alternatives to sample from the\nposterior distribution. Under the same approach, we step beyond the scope of\nclassical MCMC methods and deduce the Generative Adversarial Networks (GANs)\nframework from scratch, treating the generator as the proposal and the\ndiscriminator as the acceptance test. On real-world datasets, we improve\nFrechet Inception Distance and Inception Score, using different GANs as a\nproposal distribution for the MH algorithm. In particular, we demonstrate\nimprovements of recently proposed BigGAN model on ImageNet.\n", "versions": [{"version": "v1", "created": "Tue, 16 Oct 2018 17:26:24 GMT"}, {"version": "v2", "created": "Sun, 9 Jun 2019 14:23:34 GMT"}], "update_date": "2019-06-11", "authors_parsed": [["Neklyudov", "Kirill", ""], ["Egorov", "Evgenii", ""], ["Shvechikov", "Pavel", ""], ["Vetrov", "Dmitry", ""]]}, {"id": "1810.07155", "submitter": "Samuel Yeom", "authors": "Samuel Yeom, Anupam Datta, Matt Fredrikson", "title": "Hunting for Discriminatory Proxies in Linear Regression Models", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG math.OC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A machine learning model may exhibit discrimination when used to make\ndecisions involving people. One potential cause for such outcomes is that the\nmodel uses a statistical proxy for a protected demographic attribute. In this\npaper we formulate a definition of proxy use for the setting of linear\nregression and present algorithms for detecting proxies. Our definition follows\nrecent work on proxies in classification models, and characterizes a model's\nconstituent behavior that: 1) correlates closely with a protected random\nvariable, and 2) is causally influential in the overall behavior of the model.\nWe show that proxies in linear regression models can be efficiently identified\nby solving a second-order cone program, and further extend this result to\naccount for situations where the use of a certain input variable is justified\nas a `business necessity'. Finally, we present empirical results on two law\nenforcement datasets that exhibit varying degrees of racial disparity in\nprediction outcomes, demonstrating that proxies shed useful light on the causes\nof discriminatory behavior in models.\n", "versions": [{"version": "v1", "created": "Tue, 16 Oct 2018 17:32:27 GMT"}, {"version": "v2", "created": "Fri, 2 Nov 2018 18:12:11 GMT"}, {"version": "v3", "created": "Tue, 27 Nov 2018 21:43:47 GMT"}], "update_date": "2018-11-29", "authors_parsed": [["Yeom", "Samuel", ""], ["Datta", "Anupam", ""], ["Fredrikson", "Matt", ""]]}, {"id": "1810.07158", "submitter": "Markus Kaiser", "authors": "Markus Kaiser, Clemens Otte, Thomas Runkler, Carl Henrik Ek", "title": "Data Association with Gaussian Processes", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The data association problem is concerned with separating data coming from\ndifferent generating processes, for example when data come from different data\nsources, contain significant noise, or exhibit multimodality. We present a\nfully Bayesian approach to this problem. Our model is capable of simultaneously\nsolving the data association problem and the induced supervised learning\nproblems. Underpinning our approach is the use of Gaussian process priors to\nencode the structure of both the data and the data associations. We present an\nefficient learning scheme based on doubly stochastic variational inference and\ndiscuss how it can be applied to deep Gaussian process priors.\n", "versions": [{"version": "v1", "created": "Tue, 16 Oct 2018 17:39:12 GMT"}, {"version": "v2", "created": "Wed, 13 Feb 2019 13:39:21 GMT"}, {"version": "v3", "created": "Sun, 5 May 2019 12:46:26 GMT"}], "update_date": "2019-05-07", "authors_parsed": [["Kaiser", "Markus", ""], ["Otte", "Clemens", ""], ["Runkler", "Thomas", ""], ["Ek", "Carl Henrik", ""]]}, {"id": "1810.07167", "submitter": "Gregory Kahn", "authors": "Gregory Kahn, Adam Villaflor, Pieter Abbeel, Sergey Levine", "title": "Composable Action-Conditioned Predictors: Flexible Off-Policy Learning\n  for Robot Navigation", "comments": "Accepted to the Conference on Robot Learning (CoRL) 2018. Video at\n  https://youtu.be/lOLT7zifEkg", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A general-purpose intelligent robot must be able to learn autonomously and be\nable to accomplish multiple tasks in order to be deployed in the real world.\nHowever, standard reinforcement learning approaches learn separate\ntask-specific policies and assume the reward function for each task is known a\npriori. We propose a framework that learns event cues from off-policy data, and\ncan flexibly combine these event cues at test time to accomplish different\ntasks. These event cue labels are not assumed to be known a priori, but are\ninstead labeled using learned models, such as computer vision detectors, and\nthen `backed up' in time using an action-conditioned predictive model. We show\nthat a simulated robotic car and a real-world RC car can gather data and train\nfully autonomously without any human-provided labels beyond those needed to\ntrain the detectors, and then at test-time be able to accomplish a variety of\ndifferent tasks. Videos of the experiments and code can be found at\nhttps://github.com/gkahn13/CAPs\n", "versions": [{"version": "v1", "created": "Tue, 16 Oct 2018 17:49:43 GMT"}], "update_date": "2018-10-17", "authors_parsed": [["Kahn", "Gregory", ""], ["Villaflor", "Adam", ""], ["Abbeel", "Pieter", ""], ["Levine", "Sergey", ""]]}, {"id": "1810.07168", "submitter": "Jacques Wainer", "authors": "Jacques Wainer and Rodrigo A. Franceschinell", "title": "An empirical evaluation of imbalanced data strategies from a\n  practitioner's point of view", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This research tested the following well known strategies to deal with binary\nimbalanced data on 82 different real life data sets (sampled to imbalance rates\nof 5%, 3%, 1%, and 0.1%): class weight, SMOTE, Underbagging, and a baseline\n(just the base classifier). As base classifiers we used SVM with RBF kernel,\nrandom forests, and gradient boosting machines and we measured the quality of\nthe resulting classifier using 6 different metrics (Area under the curve,\nAccuracy, F-measure, G-mean, Matthew's correlation coefficient and Balanced\naccuracy). The best strategy strongly depends on the metric used to measure the\nquality of the classifier. For AUC and accuracy class weight and the baseline\nperform better; for F-measure and MCC, SMOTE performs better; and for G-mean\nand balanced accuracy, underbagging.\n", "versions": [{"version": "v1", "created": "Tue, 16 Oct 2018 17:50:31 GMT"}], "update_date": "2018-10-17", "authors_parsed": [["Wainer", "Jacques", ""], ["Franceschinell", "Rodrigo A.", ""]]}, {"id": "1810.07180", "submitter": "Yanjie Wang", "authors": "Yanjie Wang, Daniel Ruffinelli, Rainer Gemulla, Samuel Broscheit,\n  Christian Meilicke", "title": "On Evaluating Embedding Models for Knowledge Base Completion", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Knowledge bases contribute to many web search and mining tasks, yet they are\noften incomplete. To add missing facts to a given knowledge base, various\nembedding models have been proposed in the recent literature. Perhaps\nsurprisingly, relatively simple models with limited expressiveness often\nperformed remarkably well under today's most commonly used evaluation\nprotocols. In this paper, we explore whether recent models work well for\nknowledge base completion and argue that the current evaluation protocols are\nmore suited for question answering rather than knowledge base completion. We\nshow that when focusing on a different prediction task for evaluating knowledge\nbase completion, the performance of current embedding models is unsatisfactory\neven on datasets previously thought to be too easy. This is especially true\nwhen embedding models are compared against a simple rule-based baseline. This\nwork indicates the need for more research into the embedding models and\nevaluation protocols for knowledge base completion.\n", "versions": [{"version": "v1", "created": "Wed, 17 Oct 2018 14:09:10 GMT"}, {"version": "v2", "created": "Tue, 6 Nov 2018 13:30:39 GMT"}, {"version": "v3", "created": "Thu, 20 Dec 2018 11:28:19 GMT"}, {"version": "v4", "created": "Thu, 31 Jan 2019 19:22:59 GMT"}], "update_date": "2019-02-04", "authors_parsed": [["Wang", "Yanjie", ""], ["Ruffinelli", "Daniel", ""], ["Gemulla", "Rainer", ""], ["Broscheit", "Samuel", ""], ["Meilicke", "Christian", ""]]}, {"id": "1810.07207", "submitter": "Ryan Sweke Mr", "authors": "Ryan Sweke, Markus S. Kesselring, Evert P. L. van Nieuwenburg, Jens\n  Eisert", "title": "Reinforcement Learning Decoders for Fault-Tolerant Quantum Computation", "comments": "15 pages, 11 figures, associated code repository available at\n  https://github.com/R-Sweke/DeepQ-Decoding", "journal-ref": "Mach. Learn. Sci. Technol. 2, 025005 (2021)", "doi": "10.1088/2632-2153/abc609", "report-no": null, "categories": "quant-ph cs.AI cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Topological error correcting codes, and particularly the surface code,\ncurrently provide the most feasible roadmap towards large-scale fault-tolerant\nquantum computation. As such, obtaining fast and flexible decoding algorithms\nfor these codes, within the experimentally relevant context of faulty syndrome\nmeasurements, is of critical importance. In this work, we show that the problem\nof decoding such codes, in the full fault-tolerant setting, can be naturally\nreformulated as a process of repeated interactions between a decoding agent and\na code environment, to which the machinery of reinforcement learning can be\napplied to obtain decoding agents. As a demonstration, by using deepQ learning,\nwe obtain fast decoding agents for the surface code, for a variety of\nnoise-models.\n", "versions": [{"version": "v1", "created": "Tue, 16 Oct 2018 18:01:57 GMT"}], "update_date": "2021-01-12", "authors_parsed": [["Sweke", "Ryan", ""], ["Kesselring", "Markus S.", ""], ["van Nieuwenburg", "Evert P. L.", ""], ["Eisert", "Jens", ""]]}, {"id": "1810.07217", "submitter": "Wei-Ning Hsu", "authors": "Wei-Ning Hsu, Yu Zhang, Ron J. Weiss, Heiga Zen, Yonghui Wu, Yuxuan\n  Wang, Yuan Cao, Ye Jia, Zhifeng Chen, Jonathan Shen, Patrick Nguyen, Ruoming\n  Pang", "title": "Hierarchical Generative Modeling for Controllable Speech Synthesis", "comments": "27 pages, accepted to ICLR 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG cs.SD eess.AS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper proposes a neural sequence-to-sequence text-to-speech (TTS) model\nwhich can control latent attributes in the generated speech that are rarely\nannotated in the training data, such as speaking style, accent, background\nnoise, and recording conditions. The model is formulated as a conditional\ngenerative model based on the variational autoencoder (VAE) framework, with two\nlevels of hierarchical latent variables. The first level is a categorical\nvariable, which represents attribute groups (e.g. clean/noisy) and provides\ninterpretability. The second level, conditioned on the first, is a multivariate\nGaussian variable, which characterizes specific attribute configurations (e.g.\nnoise level, speaking rate) and enables disentangled fine-grained control over\nthese attributes. This amounts to using a Gaussian mixture model (GMM) for the\nlatent distribution. Extensive evaluation demonstrates its ability to control\nthe aforementioned attributes. In particular, we train a high-quality\ncontrollable TTS model on real found data, which is capable of inferring\nspeaker and style attributes from a noisy utterance and use it to synthesize\nclean speech with controllable speaking style.\n", "versions": [{"version": "v1", "created": "Tue, 16 Oct 2018 18:20:02 GMT"}, {"version": "v2", "created": "Thu, 27 Dec 2018 06:50:41 GMT"}], "update_date": "2018-12-31", "authors_parsed": [["Hsu", "Wei-Ning", ""], ["Zhang", "Yu", ""], ["Weiss", "Ron J.", ""], ["Zen", "Heiga", ""], ["Wu", "Yonghui", ""], ["Wang", "Yuxuan", ""], ["Cao", "Yuan", ""], ["Jia", "Ye", ""], ["Chen", "Zhifeng", ""], ["Shen", "Jonathan", ""], ["Nguyen", "Patrick", ""], ["Pang", "Ruoming", ""]]}, {"id": "1810.07218", "submitter": "Mengye Ren", "authors": "Mengye Ren, Renjie Liao, Ethan Fetaya, Richard S. Zemel", "title": "Incremental Few-Shot Learning with Attention Attractor Networks", "comments": "NeurIPS 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Machine learning classifiers are often trained to recognize a set of\npre-defined classes. However, in many applications, it is often desirable to\nhave the flexibility of learning additional concepts, with limited data and\nwithout re-training on the full training set. This paper addresses this\nproblem, incremental few-shot learning, where a regular classification network\nhas already been trained to recognize a set of base classes, and several extra\nnovel classes are being considered, each with only a few labeled examples.\nAfter learning the novel classes, the model is then evaluated on the overall\nclassification performance on both base and novel classes. To this end, we\npropose a meta-learning model, the Attention Attractor Network, which\nregularizes the learning of novel classes. In each episode, we train a set of\nnew weights to recognize novel classes until they converge, and we show that\nthe technique of recurrent back-propagation can back-propagate through the\noptimization process and facilitate the learning of these parameters. We\ndemonstrate that the learned attractor network can help recognize novel classes\nwhile remembering old classes without the need to review the original training\nset, outperforming various baselines.\n", "versions": [{"version": "v1", "created": "Tue, 16 Oct 2018 18:25:17 GMT"}, {"version": "v2", "created": "Sun, 5 May 2019 15:35:29 GMT"}, {"version": "v3", "created": "Sun, 6 Oct 2019 21:08:47 GMT"}], "update_date": "2019-10-08", "authors_parsed": [["Ren", "Mengye", ""], ["Liao", "Renjie", ""], ["Fetaya", "Ethan", ""], ["Zemel", "Richard S.", ""]]}, {"id": "1810.07225", "submitter": "Yanfu Zhang", "authors": "Yanfu Zhang, Wenshan Wang, Rogerio Bonatti, Daniel Maturana, Sebastian\n  Scherer", "title": "Integrating kinematics and environment context into deep inverse\n  reinforcement learning for predicting off-road vehicle trajectories", "comments": "CoRL 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Predicting the motion of a mobile agent from a third-person perspective is an\nimportant component for many robotics applications, such as autonomous\nnavigation and tracking. With accurate motion prediction of other agents,\nrobots can plan for more intelligent behaviors to achieve specified objectives,\ninstead of acting in a purely reactive way. Previous work addresses motion\nprediction by either only filtering kinematics, or using hand-designed and\nlearned representations of the environment. Instead of separating kinematic and\nenvironmental context, we propose a novel approach to integrate both into an\ninverse reinforcement learning (IRL) framework for trajectory prediction.\nInstead of exponentially increasing the state-space complexity with kinematics,\nwe propose a two-stage neural network architecture that considers motion and\nenvironment together to recover the reward function. The first-stage network\nlearns feature representations of the environment using low-level LiDAR\nstatistics and the second-stage network combines those learned features with\nkinematics data. We collected over 30 km of off-road driving data and validated\nexperimentally that our method can effectively extract useful environmental and\nkinematic features. We generate accurate predictions of the distribution of\nfuture trajectories of the vehicle, encoding complex behaviors such as\nmulti-modal distributions at road intersections, and even show different\npredictions at the same intersection depending on the vehicle's speed.\n", "versions": [{"version": "v1", "created": "Tue, 16 Oct 2018 18:40:34 GMT"}], "update_date": "2018-10-18", "authors_parsed": [["Zhang", "Yanfu", ""], ["Wang", "Wenshan", ""], ["Bonatti", "Rogerio", ""], ["Maturana", "Daniel", ""], ["Scherer", "Sebastian", ""]]}, {"id": "1810.07242", "submitter": "Muhammad Usama", "authors": "Muhammad Usama, Junaid Qadir, Ala Al-Fuqaha", "title": "Adversarial Attacks on Cognitive Self-Organizing Networks: The Challenge\n  and the Way Forward", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Future communications and data networks are expected to be largely cognitive\nself-organizing networks (CSON). Such networks will have the essential property\nof cognitive self-organization, which can be achieved using machine learning\ntechniques (e.g., deep learning). Despite the potential of these techniques,\nthese techniques in their current form are vulnerable to adversarial attacks\nthat can cause cascaded damages with detrimental consequences for the whole\nnetwork. In this paper, we explore the effect of adversarial attacks on CSON.\nOur experiments highlight the level of threat that CSON have to deal with in\norder to meet the challenges of next-generation networks and point out\npromising directions for future work.\n", "versions": [{"version": "v1", "created": "Wed, 26 Sep 2018 10:25:17 GMT"}], "update_date": "2018-10-18", "authors_parsed": [["Usama", "Muhammad", ""], ["Qadir", "Junaid", ""], ["Al-Fuqaha", "Ala", ""]]}, {"id": "1810.07248", "submitter": "Ali Emami", "authors": "Mahdi Ahmadi, Alireza Norouzi, S.M.Reza Soroushmehr, Nader Karimi,\n  Kayvan Najarian, Shadrokh Samavi and Ali Emami", "title": "ReDMark: Framework for Residual Diffusion Watermarking on Deep Networks", "comments": "33 pages (Single column), 10 figures, 5 tables, one appendix", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.MM cs.CR cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Due to the rapid growth of machine learning tools and specifically deep\nnetworks in various computer vision and image processing areas, application of\nConvolutional Neural Networks for watermarking have recently emerged. In this\npaper, we propose a deep end-to-end diffusion watermarking framework (ReDMark)\nwhich can be adapted for any desired transform space. The framework is composed\nof two Fully Convolutional Neural Networks with the residual structure for\nembedding and extraction. The whole deep network is trained end-to-end to\nconduct a blind secure watermarking. The framework is customizable for the\nlevel of robustness vs. imperceptibility. It is also adjustable for the\ntrade-off between capacity and robustness. The proposed framework simulates\nvarious attacks as a differentiable network layer to facilitate end-to-end\ntraining. For JPEG attack, a differentiable approximation is utilized, which\ndrastically improves the watermarking robustness to this attack. Another\nimportant characteristic of the proposed framework, which leads to improved\nsecurity and robustness, is its capability to diffuse watermark information\namong a relatively wide area of the image. Comparative results versus recent\nstate-of-the-art researches highlight the superiority of the proposed framework\nin terms of imperceptibility and robustness.\n", "versions": [{"version": "v1", "created": "Tue, 16 Oct 2018 23:07:15 GMT"}, {"version": "v2", "created": "Mon, 26 Nov 2018 09:53:39 GMT"}, {"version": "v3", "created": "Tue, 11 Dec 2018 09:32:01 GMT"}], "update_date": "2018-12-12", "authors_parsed": [["Ahmadi", "Mahdi", ""], ["Norouzi", "Alireza", ""], ["Soroushmehr", "S. M. Reza", ""], ["Karimi", "Nader", ""], ["Najarian", "Kayvan", ""], ["Samavi", "Shadrokh", ""], ["Emami", "Ali", ""]]}, {"id": "1810.07251", "submitter": "Nelly Elsayed", "authors": "Nelly Elsayed, Anthony S. Maida, Magdy Bayoumi", "title": "Reduced-Gate Convolutional LSTM Using Predictive Coding for\n  Spatiotemporal Prediction", "comments": "A novel rgcLSTM model for spatiotemporal prediction. This version\n  contains the full description and detailed empirical study of the rgcLSTM\n  architecture. 28 pages, 12 figures, 20 tables", "journal-ref": null, "doi": "10.1111/coin.12277", "report-no": "COIN12277", "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Spatiotemporal sequence prediction is an important problem in deep learning.\nWe study next-frame(s) video prediction using a deep-learning-based predictive\ncoding framework that uses convolutional, long short-term memory (convLSTM)\nmodules. We introduce a novel reduced-gate convolutional LSTM(rgcLSTM)\narchitecture that requires a significantly lower parameter budget than a\ncomparable convLSTM. By using a single multi-function gate, our reduced-gate\nmodel achieves equal or better next-frame(s) prediction accuracy than the\noriginal convolutional LSTM while using a smaller parameter budget, thereby\nreducing training time and memory requirements. We tested our reduced gate\nmodules within a predictive coding architecture on the moving MNIST and KITTI\ndatasets. We found that our reduced-gate model has a significant reduction of\napproximately 40 percent of the total number of training parameters and a 25\npercent reduction in elapsed training time in comparison with the standard\nconvolutional LSTM model. The performance accuracy of the new model was also\nimproved. This makes our model more attractive for hardware implementation,\nespecially on small devices. We also explored a space of twenty different gated\narchitectures to get insight into how our rgcLSTM fit into that space.\n", "versions": [{"version": "v1", "created": "Tue, 16 Oct 2018 19:55:51 GMT"}, {"version": "v10", "created": "Wed, 23 Oct 2019 03:30:11 GMT"}, {"version": "v11", "created": "Sun, 22 Dec 2019 21:44:41 GMT"}, {"version": "v2", "created": "Tue, 23 Oct 2018 20:36:59 GMT"}, {"version": "v3", "created": "Sun, 18 Nov 2018 06:08:08 GMT"}, {"version": "v4", "created": "Wed, 5 Dec 2018 01:52:15 GMT"}, {"version": "v5", "created": "Sun, 9 Dec 2018 03:11:44 GMT"}, {"version": "v6", "created": "Tue, 11 Dec 2018 01:57:45 GMT"}, {"version": "v7", "created": "Fri, 28 Dec 2018 01:26:57 GMT"}, {"version": "v8", "created": "Thu, 10 Jan 2019 19:05:49 GMT"}, {"version": "v9", "created": "Fri, 15 Mar 2019 19:21:00 GMT"}], "update_date": "2020-01-24", "authors_parsed": [["Elsayed", "Nelly", ""], ["Maida", "Anthony S.", ""], ["Bayoumi", "Magdy", ""]]}, {"id": "1810.07254", "submitter": "Amos Azaria", "authors": "Yitzhak Spielberg, Amos Azaria", "title": "The Concept of Criticality in Reinforcement Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.MA stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Reinforcement learning methods carry a well known bias-variance trade-off in\nn-step algorithms for optimal control. Unfortunately, this has rarely been\naddressed in current research. This trade-off principle holds independent of\nthe choice of the algorithm, such as n-step SARSA, n-step Expected SARSA or\nn-step Tree backup. A small n results in a large bias, while a large n leads to\nlarge variance. The literature offers no straightforward recipe for the best\nchoice of this value. While currently all n-step algorithms use a fixed value\nof n over the state space we extend the framework of n-step updates by allowing\neach state to have its specific n.\n  We propose a solution to this problem within the context of human aided\nreinforcement learning. Our approach is based on the observation that a human\ncan learn more efficiently if she receives input regarding the criticality of a\ngiven state and thus the amount of attention she needs to invest into the\nlearning in that state. This observation is related to the idea that each state\nof the MDP has a certain measure of criticality which indicates how much the\nchoice of the action in that state influences the return. In our algorithm the\nRL agent utilizes the criticality measure, a function provided by a human\ntrainer, in order to locally choose the best stepnumber n for the update of the\nQ function.\n", "versions": [{"version": "v1", "created": "Tue, 16 Oct 2018 20:07:06 GMT"}], "update_date": "2018-10-18", "authors_parsed": [["Spielberg", "Yitzhak", ""], ["Azaria", "Amos", ""]]}, {"id": "1810.07283", "submitter": "Min Ye", "authors": "Min Ye and Alexander Barg", "title": "Optimal locally private estimation under $\\ell_p$ loss for $1\\le p\\le 2$", "comments": "This paper generalizes the optimality results of the preprint\n  arXiv:1708.00059 from $ell_2$ to a broader class of loss functions. The new\n  approach taken here also results in a much shorter proof", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST cs.IT cs.LG math.IT stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the minimax estimation problem of a discrete distribution with\nsupport size $k$ under locally differential privacy constraints. A\nprivatization scheme is applied to each raw sample independently, and we need\nto estimate the distribution of the raw samples from the privatized samples. A\npositive number $\\epsilon$ measures the privacy level of a privatization\nscheme.\n  In our previous work (IEEE Trans. Inform. Theory, 2018), we proposed a family\nof new privatization schemes and the corresponding estimator. We also proved\nthat our scheme and estimator are order optimal in the regime $e^{\\epsilon} \\ll\nk$ under both $\\ell_2^2$ (mean square) and $\\ell_1$ loss. In this paper, we\nsharpen this result by showing asymptotic optimality of the proposed scheme\nunder the $\\ell_p^p$ loss for all $1\\le p\\le 2.$ More precisely, we show that\nfor any $p\\in[1,2]$ and any $k$ and $\\epsilon,$ the ratio between the\nworst-case $\\ell_p^p$ estimation loss of our scheme and the optimal value\napproaches $1$ as the number of samples tends to infinity. The lower bound on\nthe minimax risk of private estimation that we establish as a part of the proof\nis valid for any loss function $\\ell_p^p, p\\ge 1.$\n", "versions": [{"version": "v1", "created": "Tue, 16 Oct 2018 21:23:32 GMT"}], "update_date": "2018-10-18", "authors_parsed": [["Ye", "Min", ""], ["Barg", "Alexander", ""]]}, {"id": "1810.07286", "submitter": "Vlad Firoiu", "authors": "Vlad Firoiu, Tina Ju, Josh Tenenbaum", "title": "At Human Speed: Deep Reinforcement Learning with Action Delay", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  There has been a recent explosion in the capabilities of game-playing\nartificial intelligence. Many classes of tasks, from video games to motor\ncontrol to board games, are now solvable by fairly generic algorithms, based on\ndeep learning and reinforcement learning, that learn to play from experience\nwith minimal prior knowledge. However, these machines often do not win through\nintelligence alone -- they possess vastly superior speed and precision,\nallowing them to act in ways a human never could. To level the playing field,\nwe restrict the machine's reaction time to a human level, and find that\nstandard deep reinforcement learning methods quickly drop in performance. We\npropose a solution to the action delay problem inspired by human perception --\nto endow agents with a neural predictive model of the environment which\n\"undoes\" the delay inherent in their environment -- and demonstrate its\nefficacy against professional players in Super Smash Bros. Melee, a popular\nconsole fighting game.\n", "versions": [{"version": "v1", "created": "Tue, 16 Oct 2018 21:36:35 GMT"}], "update_date": "2018-10-18", "authors_parsed": [["Firoiu", "Vlad", ""], ["Ju", "Tina", ""], ["Tenenbaum", "Josh", ""]]}, {"id": "1810.07287", "submitter": "Karl Kumbier", "authors": "Karl Kumbier and Sumanta Basu and James B. Brown and Susan Celniker\n  and Bin Yu", "title": "Refining interaction search through signed iterative Random Forests", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Advances in supervised learning have enabled accurate prediction in\nbiological systems governed by complex interactions among biomolecules.\nHowever, state-of-the-art predictive algorithms are typically black-boxes,\nlearning statistical interactions that are difficult to translate into testable\nhypotheses. The iterative Random Forest algorithm took a step towards bridging\nthis gap by providing a computationally tractable procedure to identify the\nstable, high-order feature interactions that drive the predictive accuracy of\nRandom Forests (RF). Here we refine the interactions identified by iRF to\nexplicitly map responses as a function of interacting features. Our method,\nsigned iRF, describes subsets of rules that frequently occur on RF decision\npaths. We refer to these rule subsets as signed interactions. Signed\ninteractions share not only the same set of interacting features but also\nexhibit similar thresholding behavior, and thus describe a consistent\nfunctional relationship between interacting features and responses. We describe\nstable and predictive importance metrics to rank signed interactions. For each\nSPIM, we define null importance metrics that characterize its expected behavior\nunder known structure. We evaluate our proposed approach in biologically\ninspired simulations and two case studies: predicting enhancer activity and\nspatial gene expression patterns. In the case of enhancer activity, s-iRF\nrecovers one of the few experimentally validated high-order interactions and\nsuggests novel enhancer elements where this interaction may be active. In the\ncase of spatial gene expression patterns, s-iRF recovers all 11 reported links\nin the gap gene network. By refining the process of interaction recovery, our\napproach has the potential to guide mechanistic inquiry into systems whose\nscale and complexity is beyond human comprehension.\n", "versions": [{"version": "v1", "created": "Tue, 16 Oct 2018 21:39:41 GMT"}], "update_date": "2018-10-18", "authors_parsed": [["Kumbier", "Karl", ""], ["Basu", "Sumanta", ""], ["Brown", "James B.", ""], ["Celniker", "Susan", ""], ["Yu", "Bin", ""]]}, {"id": "1810.07288", "submitter": "Sharan Vaswani", "authors": "Sharan Vaswani, Francis Bach, Mark Schmidt", "title": "Fast and Faster Convergence of SGD for Over-Parameterized Models and an\n  Accelerated Perceptron", "comments": "AISTATS 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Modern machine learning focuses on highly expressive models that are able to\nfit or interpolate the data completely, resulting in zero training loss. For\nsuch models, we show that the stochastic gradients of common loss functions\nsatisfy a strong growth condition. Under this condition, we prove that constant\nstep-size stochastic gradient descent (SGD) with Nesterov acceleration matches\nthe convergence rate of the deterministic accelerated method for both convex\nand strongly-convex functions. We also show that this condition implies that\nSGD can find a first-order stationary point as efficiently as full gradient\ndescent in non-convex settings. Under interpolation, we further show that all\nsmooth loss functions with a finite-sum structure satisfy a weaker growth\ncondition. Given this weaker condition, we prove that SGD with a constant\nstep-size attains the deterministic convergence rate in both the\nstrongly-convex and convex settings. Under additional assumptions, the above\nresults enable us to prove an O(1/k^2) mistake bound for k iterations of a\nstochastic perceptron algorithm using the squared-hinge loss. Finally, we\nvalidate our theoretical findings with experiments on synthetic and real\ndatasets.\n", "versions": [{"version": "v1", "created": "Tue, 16 Oct 2018 21:48:11 GMT"}, {"version": "v2", "created": "Mon, 25 Feb 2019 16:27:06 GMT"}, {"version": "v3", "created": "Fri, 5 Apr 2019 18:58:38 GMT"}], "update_date": "2019-04-09", "authors_parsed": [["Vaswani", "Sharan", ""], ["Bach", "Francis", ""], ["Schmidt", "Mark", ""]]}, {"id": "1810.07291", "submitter": "Mehran Pesteie", "authors": "Mehran Pesteie, Purang Abolmaesumi, Robert Rohling", "title": "Deep Neural Maps", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce a new unsupervised representation learning and visualization\nusing deep convolutional networks and self organizing maps called Deep Neural\nMaps (DNM). DNM jointly learns an embedding of the input data and a mapping\nfrom the embedding space to a two-dimensional lattice. We compare\nvisualizations of DNM with those of t-SNE and LLE on the MNIST and COIL-20 data\nsets. Our experiments show that the DNM can learn efficient representations of\nthe input data, which reflects characteristics of each class. This is shown via\nback-projecting the neurons of the map on the data space.\n", "versions": [{"version": "v1", "created": "Tue, 16 Oct 2018 21:59:47 GMT"}], "update_date": "2018-10-18", "authors_parsed": [["Pesteie", "Mehran", ""], ["Abolmaesumi", "Purang", ""], ["Rohling", "Robert", ""]]}, {"id": "1810.07301", "submitter": "Tamar Pichkhadze", "authors": "Vikas K. Garg and Tamar Pichkhadze", "title": "Online Markov Decoding: Lower Bounds and Near-Optimal Approximation\n  Algorithms", "comments": "Added experiments, fixed typos, and polished presentation. Currently\n  under review", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We resolve the fundamental problem of online decoding with general $n^{th}$\norder ergodic Markov chain models. Specifically, we provide deterministic and\nrandomized algorithms whose performance is close to that of the optimal offline\nalgorithm even when latency is small. Our algorithms admit efficient\nimplementation via dynamic programs, and readily extend to (adversarial)\nnon-stationary or time-varying settings. We also establish lower bounds for\nonline methods under latency constraints in both deterministic and randomized\nsettings, and show that no online algorithm can perform significantly better\nthan our algorithms. Empirically, just with latency one, our algorithm\noutperforms the online step algorithm by over 30\\% in terms of decoding\nagreement with the optimal algorithm on genome sequence data.\n", "versions": [{"version": "v1", "created": "Tue, 16 Oct 2018 22:49:48 GMT"}, {"version": "v2", "created": "Thu, 30 May 2019 16:07:52 GMT"}], "update_date": "2019-05-31", "authors_parsed": [["Garg", "Vikas K.", ""], ["Pichkhadze", "Tamar", ""]]}, {"id": "1810.07307", "submitter": "Rafik Hadfi", "authors": "Rafik Hadfi", "title": "Solving Tree Problems with Category Theory", "comments": "10 pages, 4 figures, International Conference on Artificial General\n  Intelligence (AGI) 2018", "journal-ref": "Hadfi R. (2018) Solving Tree Problems with Category Theory. In:\n  Ikl\\'e M., Franz A., Rzepka R., Goertzel B. (eds) Artificial General\n  Intelligence. AGI 2018. Lecture Notes in Computer Science, vol 10999.\n  Springer, Cham", "doi": "10.1007/978-3-319-97676-1_7", "report-no": null, "categories": "cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Artificial Intelligence (AI) has long pursued models, theories, and\ntechniques to imbue machines with human-like general intelligence. Yet even the\ncurrently predominant data-driven approaches in AI seem to be lacking humans'\nunique ability to solve wide ranges of problems. This situation begs the\nquestion of the existence of principles that underlie general problem-solving\ncapabilities. We approach this question through the mathematical formulation of\nanalogies across different problems and solutions. We focus in particular on\nproblems that could be represented as tree-like structures. Most importantly,\nwe adopt a category-theoretic approach in formalising tree problems as\ncategories, and in proving the existence of equivalences across apparently\nunrelated problem domains. We prove the existence of a functor between the\ncategory of tree problems and the category of solutions. We also provide a\nweaker version of the functor by quantifying equivalences of problem categories\nusing a metric on tree problems.\n", "versions": [{"version": "v1", "created": "Tue, 16 Oct 2018 23:06:48 GMT"}], "update_date": "2018-10-18", "authors_parsed": [["Hadfi", "Rafik", ""]]}, {"id": "1810.07309", "submitter": "Jinxi Guo", "authors": "Jinxi Guo, Ning Xu, Kailun Qian, Yang Shi, Kaiyuan Xu, Yingnian Wu,\n  Abeer Alwan", "title": "Deep neural network based i-vector mapping for speaker verification\n  using short utterances", "comments": "Submitted to Speech Communication; under final review", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.AS cs.LG cs.SD stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Text-independent speaker recognition using short utterances is a highly\nchallenging task due to the large variation and content mismatch between short\nutterances. I-vector based systems have become the standard in speaker\nverification applications, but they are less effective with short utterances.\nIn this paper, we first compare two state-of-the-art universal background model\ntraining methods for i-vector modeling using full-length and short utterance\nevaluation tasks. The two methods are Gaussian mixture model (GMM) based and\ndeep neural network (DNN) based methods. The results indicate that the\nI-vector_DNN system outperforms the I-vector_GMM system under various\ndurations. However, the performances of both systems degrade significantly as\nthe duration of the utterances decreases. To address this issue, we propose two\nnovel nonlinear mapping methods which train DNN models to map the i-vectors\nextracted from short utterances to their corresponding long-utterance\ni-vectors. The mapped i-vector can restore missing information and reduce the\nvariance of the original short-utterance i-vectors. The proposed methods both\nmodel the joint representation of short and long utterance i-vectors by using\nautoencoder. Experimental results using the NIST SRE 2010 dataset show that\nboth methods provide significant improvement and result in a max of 28.43%\nrelative improvement in Equal Error Rates from a baseline system, when using\ndeep encoder with residual blocks and adding an additional phoneme vector. When\nfurther testing the best-validated models of SRE10 on the Speaker In The Wild\ndataset, the methods result in a 23.12% improvement on arbitrary-duration (1-5\ns) short-utterance conditions.\n", "versions": [{"version": "v1", "created": "Tue, 16 Oct 2018 23:16:38 GMT"}], "update_date": "2018-10-18", "authors_parsed": [["Guo", "Jinxi", ""], ["Xu", "Ning", ""], ["Qian", "Kailun", ""], ["Shi", "Yang", ""], ["Xu", "Kaiyuan", ""], ["Wu", "Yingnian", ""], ["Alwan", "Abeer", ""]]}, {"id": "1810.07310", "submitter": "Yu-Hang Tang", "authors": "Yu-Hang Tang, Wibe A. de Jong", "title": "Prediction of Atomization Energy Using Graph Kernel and Active Learning", "comments": null, "journal-ref": "J. Chem. Phys. 150(4): 044107, 2019", "doi": "10.1063/1.5078640", "report-no": null, "categories": "cs.LG cond-mat.mtrl-sci cs.CE physics.comp-ph stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Data-driven prediction of molecular properties presents unique challenges to\nthe design of machine learning methods concerning data\nstructure/dimensionality, symmetry adaption, and confidence management. In this\npaper, we present a kernel-based pipeline that can learn and predict the\natomization energy of molecules with high accuracy. The framework employs\nGaussian process regression to perform predictions based on the similarity\nbetween molecules, which is computed using the marginalized graph kernel. To\napply the marginalized graph kernel, a spatial adjacency rule is first employed\nto convert molecules into graphs whose vertices and edges are labeled by\nelements and interatomic distances, respectively. We then derive formulas for\nthe efficient evaluation of the kernel. Specific functional components for the\nmarginalized graph kernel are proposed, while the effect of the associated\nhyperparameters on accuracy and predictive confidence are examined. We show\nthat the graph kernel is particularly suitable for predicting extensive\nproperties because its convolutional structure coincides with that of the\ncovariance formula between sums of random variables. Using an active learning\nprocedure, we demonstrate that the proposed method can achieve a mean absolute\nerror of 0.62 +- 0.01 kcal/mol using as few as 2000 training samples on the QM7\ndata set.\n", "versions": [{"version": "v1", "created": "Tue, 16 Oct 2018 23:21:03 GMT"}, {"version": "v2", "created": "Thu, 18 Oct 2018 06:39:50 GMT"}, {"version": "v3", "created": "Wed, 30 Jan 2019 06:00:28 GMT"}], "update_date": "2019-01-31", "authors_parsed": [["Tang", "Yu-Hang", ""], ["de Jong", "Wibe A.", ""]]}, {"id": "1810.07320", "submitter": "Adly Templeton", "authors": "Adly Templeton, Jugal Kalita", "title": "Exploring Sentence Vector Spaces through Automatic Summarization", "comments": "Accepted for publication in ICMLA 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Given vector representations for individual words, it is necessary to compute\nvector representations of sentences for many applications in a compositional\nmanner, often using artificial neural networks.\n  Relatively little work has explored the internal structure and properties of\nsuch sentence vectors. In this paper, we explore the properties of sentence\nvectors in the context of automatic summarization. In particular, we show that\ncosine similarity between sentence vectors and document vectors is strongly\ncorrelated with sentence importance and that vector semantics can identify and\ncorrect gaps between the sentences chosen so far and the document. In addition,\nwe identify specific dimensions which are linked to effective summaries. To our\nknowledge, this is the first time specific dimensions of sentence embeddings\nhave been connected to sentence properties. We also compare the features of\ndifferent methods of sentence embeddings. Many of these insights have\napplications in uses of sentence embeddings far beyond summarization.\n", "versions": [{"version": "v1", "created": "Tue, 16 Oct 2018 23:57:37 GMT"}], "update_date": "2018-10-18", "authors_parsed": [["Templeton", "Adly", ""], ["Kalita", "Jugal", ""]]}, {"id": "1810.07321", "submitter": "Giuseppe Laurenza", "authors": "Giuseppe Laurenza, Riccardo Lazzeretti and Luca Mazzotti", "title": "Malware triage for early identification of Advanced Persistent Threat\n  activities", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In the last decade, a new class of cyber-threats has emerged. This new\ncybersecurity adversary is known with the name of \"Advanced Persistent Threat\"\n(APT) and is referred to different organizations that in the last years have\nbeen \"in the center of the eye\" due to multiple dangerous and effective attacks\ntargeting financial and politic, news headlines, embassies, critical\ninfrastructures, TV programs, etc. In order to early identify APT related\nmalware, a semi-automatic approach for malware samples analysis is needed. In\nour previous work we introduced a \"malware triage\" step for a semi-automatic\nmalware analysis architecture. This step has the duty to analyze as fast as\npossible new incoming samples and to immediately dispatch the ones that deserve\na deeper analysis, among all the malware delivered per day in the cyber-space,\nthe ones that really worth to be further examined by analysts. Our paper\nfocuses on malware developed by APTs, and we build our knowledge base, used in\nthe triage, on known APTs obtained from publicly available reports. In order to\nhave the triage as fast as possible, we only rely on static malware features,\nthat can be extracted with negligible delay, and use machine learning\ntechniques for the identification. In this work we move from multiclass\nclassification to a group of oneclass classifier, which simplify the training\nand allows higher modularity. The results of the proposed framework highlight\nhigh performances, reaching a precision of 100% and an accuracy over 95%\n", "versions": [{"version": "v1", "created": "Tue, 16 Oct 2018 12:28:55 GMT"}], "update_date": "2018-10-18", "authors_parsed": [["Laurenza", "Giuseppe", ""], ["Lazzeretti", "Riccardo", ""], ["Mazzotti", "Luca", ""]]}, {"id": "1810.07322", "submitter": "Zhuwei Qin", "authors": "Zhuwei Qin, Fuxun Yu, Chenchen Liu, Xiang Chen", "title": "Functionality-Oriented Convolutional Filter Pruning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The sophisticated structure of Convolutional Neural Network (CNN) allows for\noutstanding performance, but at the cost of intensive computation. As\nsignificant redundancies inevitably present in such a structure, many works\nhave been proposed to prune the convolutional filters for computation cost\nreduction. Although extremely effective, most works are based only on\nquantitative characteristics of the convolutional filters, and highly overlook\nthe qualitative interpretation of individual filter's specific functionality.\nIn this work, we interpreted the functionality and redundancy of the\nconvolutional filters from different perspectives, and proposed a\nfunctionality-oriented filter pruning method. With extensive experiment\nresults, we proved the convolutional filters' qualitative significance\nregardless of magnitude, demonstrated significant neural network redundancy due\nto repetitive filter functions, and analyzed the filter functionality defection\nunder inappropriate retraining process. Such an interpretable pruning approach\nnot only offers outstanding computation cost optimization over previous filter\npruning methods, but also interprets filter pruning process.\n", "versions": [{"version": "v1", "created": "Fri, 12 Oct 2018 20:39:47 GMT"}, {"version": "v2", "created": "Thu, 12 Sep 2019 03:24:06 GMT"}], "update_date": "2019-09-13", "authors_parsed": [["Qin", "Zhuwei", ""], ["Yu", "Fuxun", ""], ["Liu", "Chenchen", ""], ["Chen", "Xiang", ""]]}, {"id": "1810.07339", "submitter": "Guofu Li", "authors": "Guofu Li, Pengjia Zhu, Jin Li, Zhemin Yang, Ning Cao, and Zhiyi Chen", "title": "Security Matters: A Survey on Adversarial Machine Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Adversarial machine learning is a fast growing research area, which considers\nthe scenarios when machine learning systems may face potential adversarial\nattackers, who intentionally synthesize input data to make a well-trained model\nto make mistake. It always involves a defending side, usually a classifier, and\nan attacking side that aims to cause incorrect output. The earliest studies on\nthe adversarial examples for machine learning algorithms start from the\ninformation security area, which considers a much wider varieties of attacking\nmethods. But recent research focus that popularized by the deep learning\ncommunity places strong emphasis on how the \"imperceivable\" perturbations on\nthe normal inputs may cause dramatic mistakes by the deep learning with\nsupposed super-human accuracy. This paper serves to give a comprehensive\nintroduction to a range of aspects of the adversarial deep learning topic,\nincluding its foundations, typical attacking and defending strategies, and some\nextended studies.\n", "versions": [{"version": "v1", "created": "Tue, 16 Oct 2018 09:06:26 GMT"}, {"version": "v2", "created": "Tue, 23 Oct 2018 03:13:05 GMT"}], "update_date": "2018-10-24", "authors_parsed": [["Li", "Guofu", ""], ["Zhu", "Pengjia", ""], ["Li", "Jin", ""], ["Yang", "Zhemin", ""], ["Cao", "Ning", ""], ["Chen", "Zhiyi", ""]]}, {"id": "1810.07348", "submitter": "Andri Ashfahani", "authors": "Andri Ashfahani and Mahardhika Pratama", "title": "Autonomous Deep Learning: Continual Learning Approach for Dynamic\n  Environments", "comments": null, "journal-ref": "This paper has been published in Proceedings of the 2019 SIAM\n  International Conference on Data Mining", "doi": "10.1137/1.9781611975673.75", "report-no": null, "categories": "cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  The feasibility of deep neural networks (DNNs) to address data stream\nproblems still requires intensive study because of the static and offline\nnature of conventional deep learning approaches. A deep continual learning\nalgorithm, namely autonomous deep learning (ADL), is proposed in this paper.\nUnlike traditional deep learning methods, ADL features a flexible structure\nwhere its network structure can be constructed from scratch with the absence of\nan initial network structure via the self-constructing network structure. ADL\nspecifically addresses catastrophic forgetting by having a different-depth\nstructure which is capable of achieving a trade-off between plasticity and\nstability. Network significance (NS) formula is proposed to drive the hidden\nnodes growing and pruning mechanism. Drift detection scenario (DDS) is put\nforward to signal distributional changes in data streams which induce the\ncreation of a new hidden layer. The maximum information compression index\n(MICI) method plays an important role as a complexity reduction module\neliminating redundant layers. The efficacy of ADL is numerically validated\nunder the prequential test-then-train procedure in lifelong environments using\nnine popular data stream problems. The numerical results demonstrate that ADL\nconsistently outperforms recent continual learning methods while characterizing\nthe automatic construction of network structures.\n", "versions": [{"version": "v1", "created": "Wed, 17 Oct 2018 01:40:45 GMT"}, {"version": "v2", "created": "Wed, 29 May 2019 18:48:02 GMT"}, {"version": "v3", "created": "Tue, 8 Oct 2019 15:02:06 GMT"}, {"version": "v4", "created": "Thu, 9 Jan 2020 12:19:19 GMT"}], "update_date": "2020-01-10", "authors_parsed": [["Ashfahani", "Andri", ""], ["Pratama", "Mahardhika", ""]]}, {"id": "1810.07354", "submitter": "Aurick Qiao", "authors": "Aurick Qiao, Bryon Aragam, Bingjing Zhang, Eric P. Xing", "title": "Fault Tolerance in Iterative-Convergent Machine Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Machine learning (ML) training algorithms often possess an inherent\nself-correcting behavior due to their iterative-convergent nature. Recent\nsystems exploit this property to achieve adaptability and efficiency in\nunreliable computing environments by relaxing the consistency of execution and\nallowing calculation errors to be self-corrected during training. However, the\nbehavior of such systems are only well understood for specific types of\ncalculation errors, such as those caused by staleness, reduced precision, or\nasynchronicity, and for specific types of training algorithms, such as\nstochastic gradient descent. In this paper, we develop a general framework to\nquantify the effects of calculation errors on iterative-convergent algorithms\nand use this framework to design new strategies for checkpoint-based fault\ntolerance. Our framework yields a worst-case upper bound on the iteration cost\nof arbitrary perturbations to model parameters during training. Our system,\nSCAR, employs strategies which reduce the iteration cost upper bound due to\nperturbations incurred when recovering from checkpoints. We show that SCAR can\nreduce the iteration cost of partial failures by 78% - 95% when compared with\ntraditional checkpoint-based fault tolerance across a variety of ML models and\ntraining algorithms.\n", "versions": [{"version": "v1", "created": "Wed, 17 Oct 2018 02:19:35 GMT"}], "update_date": "2018-10-18", "authors_parsed": [["Qiao", "Aurick", ""], ["Aragam", "Bryon", ""], ["Zhang", "Bingjing", ""], ["Xing", "Eric P.", ""]]}, {"id": "1810.07362", "submitter": "Alon Gonen", "authors": "Naman Agarwal, Alon Gonen, Elad Hazan", "title": "Learning in Non-convex Games with an Optimization Oracle", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider online learning in an adversarial, non-convex setting under the\nassumption that the learner has an access to an offline optimization oracle. In\nthe general setting of prediction with expert advice, Hazan et al. (2016)\nestablished that in the optimization-oracle model, online learning requires\nexponentially more computation than statistical learning. In this paper we show\nthat by slightly strengthening the oracle model, the online and the statistical\nlearning models become computationally equivalent. Our result holds for any\nLipschitz and bounded (but not necessarily convex) function. As an application\nwe demonstrate how the offline oracle enables efficient computation of an\nequilibrium in non-convex games, that include GAN (generative adversarial\nnetworks) as a special case.\n", "versions": [{"version": "v1", "created": "Wed, 17 Oct 2018 02:46:30 GMT"}, {"version": "v2", "created": "Fri, 19 Oct 2018 23:09:47 GMT"}, {"version": "v3", "created": "Sat, 1 Dec 2018 21:16:55 GMT"}, {"version": "v4", "created": "Fri, 21 Dec 2018 23:31:49 GMT"}, {"version": "v5", "created": "Fri, 1 Feb 2019 15:10:29 GMT"}, {"version": "v6", "created": "Wed, 13 Mar 2019 12:53:17 GMT"}, {"version": "v7", "created": "Wed, 29 May 2019 01:50:48 GMT"}], "update_date": "2019-05-30", "authors_parsed": [["Agarwal", "Naman", ""], ["Gonen", "Alon", ""], ["Hazan", "Elad", ""]]}, {"id": "1810.07368", "submitter": "Hanze Dong", "authors": "Hanze Dong, Yanwei Fu, Leonid Sigal, Sung Ju Hwang, Yu-Gang Jiang,\n  Xiangyang Xue", "title": "Learning to Separate Domains in Generalized Zero-Shot and Open Set\n  Learning: a probabilistic perspective", "comments": "10 pages, 5 figures, submitted to ICLR 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper studies the problem of domain division which aims to segment\ninstances drawn from different probabilistic distributions. Such a problem\nexists in many previous recognition tasks, such as Open Set Learning (OSL) and\nGeneralized Zero-Shot Learning (G-ZSL), where the testing instances come from\neither seen or novel/unseen classes of different probabilistic distributions.\nPrevious works focused on either only calibrating the confident prediction of\nclassifiers of seen classes (W-SVM), or taking unseen classes as outliers. In\ncontrast, this paper proposes a probabilistic way of directly estimating and\nfine-tuning the decision boundary between seen and novel/unseen classes. In\nparticular, we propose a domain division algorithm of learning to split the\ntesting instances into known, unknown and uncertain domains, and then conduct\nrecognize tasks in each domain. Two statistical tools, namely, bootstrapping\nand Kolmogorov-Smirnov (K-S) Test, for the first time, are introduced to\ndiscover and fine-tune the decision boundary of each domain. Critically, the\nuncertain domain is newly introduced in our framework to adopt those instances\nwhose domain cannot be predicted confidently. Extensive experiments demonstrate\nthat our approach achieved the state-of-the-art performance on OSL and G-ZSL\nbenchmarks.\n", "versions": [{"version": "v1", "created": "Wed, 17 Oct 2018 03:11:20 GMT"}, {"version": "v2", "created": "Sun, 25 Nov 2018 05:50:07 GMT"}], "update_date": "2018-11-27", "authors_parsed": [["Dong", "Hanze", ""], ["Fu", "Yanwei", ""], ["Sigal", "Leonid", ""], ["Hwang", "Sung Ju", ""], ["Jiang", "Yu-Gang", ""], ["Xue", "Xiangyang", ""]]}, {"id": "1810.07371", "submitter": "Aniket Anand Deshmukh", "authors": "Aniket Anand Deshmukh, Srinagesh Sharma, James W. Cutler, Mark Moldwin\n  and Clayton Scott", "title": "Simple Regret Minimization for Contextual Bandits", "comments": "The first two authors contributed equally", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  There are two variants of the classical multi-armed bandit (MAB) problem that\nhave received considerable attention from machine learning researchers in\nrecent years: contextual bandits and simple regret minimization. Contextual\nbandits are a sub-class of MABs where, at every time step, the learner has\naccess to side information that is predictive of the best arm. Simple regret\nminimization assumes that the learner only incurs regret after a pure\nexploration phase. In this work, we study simple regret minimization for\ncontextual bandits. Motivated by applications where the learner has separate\ntraining and autonomous modes, we assume that the learner experiences a pure\nexploration phase, where feedback is received after every action but no regret\nis incurred, followed by a pure exploitation phase in which regret is incurred\nbut there is no feedback. We present the Contextual-Gap algorithm and establish\nperformance guarantees on the simple regret, i.e., the regret during the pure\nexploitation phase. Our experiments examine a novel application to adaptive\nsensor selection for magnetic field estimation in interplanetary spacecraft,\nand demonstrate considerable improvement over algorithms designed to minimize\nthe cumulative regret.\n", "versions": [{"version": "v1", "created": "Wed, 17 Oct 2018 03:17:26 GMT"}, {"version": "v2", "created": "Tue, 25 Feb 2020 20:13:42 GMT"}], "update_date": "2020-02-27", "authors_parsed": [["Deshmukh", "Aniket Anand", ""], ["Sharma", "Srinagesh", ""], ["Cutler", "James W.", ""], ["Moldwin", "Mark", ""], ["Scott", "Clayton", ""]]}, {"id": "1810.07377", "submitter": "Kyeong Soo (Joseph) Kim", "authors": "Zhenghang Zhong, Zhe Tang, Xiangxing Li, Tiancheng Yuan, Yang Yang,\n  Meng Wei, Yuanyuan Zhang, Renzhi Sheng, Naomi Grant, Chongfeng Ling, Xintao\n  Huan, Kyeong Soo Kim and Sanghyuk Lee", "title": "XJTLUIndoorLoc: A New Fingerprinting Database for Indoor Localization\n  and Trajectory Estimation Based on Wi-Fi RSS and Geomagnetic Field", "comments": "7 pages, 16 figures, 3rd International Workshop on GPU Computing and\n  AI (GCA'18)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG eess.SP stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we present a new location fingerprinting database comprised of\nWi-Fi received signal strength (RSS) and geomagnetic field intensity measured\nwith multiple devices at a multi-floor building in Xi'an Jiatong-Liverpool\nUniversity, Suzhou, China. We also provide preliminary results of localization\nand trajectory estimation based on convolutional neural network (CNN) and long\nshort-term memory (LSTM) network with this database. For localization, we map\nRSS data for a reference point to an image-like, two-dimensional array and then\napply CNN which is popular in image and video analysis and recognition. For\ntrajectory estimation, we use a modified random way point model to efficiently\ngenerate continuous step traces imitating human walking and train a stacked\ntwo-layer LSTM network with the generated data to remember the changing pattern\nof geomagnetic field intensity against (x,y) coordinates. Experimental results\ndemonstrate the usefulness of our new database and the feasibility of the CNN\nand LSTM-based localization and trajectory estimation with the database.\n", "versions": [{"version": "v1", "created": "Wed, 17 Oct 2018 03:47:29 GMT"}], "update_date": "2018-10-18", "authors_parsed": [["Zhong", "Zhenghang", ""], ["Tang", "Zhe", ""], ["Li", "Xiangxing", ""], ["Yuan", "Tiancheng", ""], ["Yang", "Yang", ""], ["Wei", "Meng", ""], ["Zhang", "Yuanyuan", ""], ["Sheng", "Renzhi", ""], ["Grant", "Naomi", ""], ["Ling", "Chongfeng", ""], ["Huan", "Xintao", ""], ["Kim", "Kyeong Soo", ""], ["Lee", "Sanghyuk", ""]]}, {"id": "1810.07378", "submitter": "Tianyun Zhang", "authors": "Shaokai Ye, Tianyun Zhang, Kaiqi Zhang, Jiayu Li, Kaidi Xu, Yunfei\n  Yang, Fuxun Yu, Jian Tang, Makan Fardad, Sijia Liu, Xiang Chen, Xue Lin,\n  Yanzhi Wang", "title": "Progressive Weight Pruning of Deep Neural Networks using ADMM", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep neural networks (DNNs) although achieving human-level performance in\nmany domains, have very large model size that hinders their broader\napplications on edge computing devices. Extensive research work have been\nconducted on DNN model compression or pruning. However, most of the previous\nwork took heuristic approaches. This work proposes a progressive weight pruning\napproach based on ADMM (Alternating Direction Method of Multipliers), a\npowerful technique to deal with non-convex optimization problems with\npotentially combinatorial constraints. Motivated by dynamic programming, the\nproposed method reaches extremely high pruning rate by using partial prunings\nwith moderate pruning rates. Therefore, it resolves the accuracy degradation\nand long convergence time problems when pursuing extremely high pruning ratios.\nIt achieves up to 34 times pruning rate for ImageNet dataset and 167 times\npruning rate for MNIST dataset, significantly higher than those reached by the\nliterature work. Under the same number of epochs, the proposed method also\nachieves faster convergence and higher compression rates. The codes and pruned\nDNN models are released in the link bit.ly/2zxdlss\n", "versions": [{"version": "v1", "created": "Wed, 17 Oct 2018 03:51:38 GMT"}, {"version": "v2", "created": "Sun, 4 Nov 2018 16:41:06 GMT"}], "update_date": "2018-11-06", "authors_parsed": [["Ye", "Shaokai", ""], ["Zhang", "Tianyun", ""], ["Zhang", "Kaiqi", ""], ["Li", "Jiayu", ""], ["Xu", "Kaidi", ""], ["Yang", "Yunfei", ""], ["Yu", "Fuxun", ""], ["Tang", "Jian", ""], ["Fardad", "Makan", ""], ["Liu", "Sijia", ""], ["Chen", "Xiang", ""], ["Lin", "Xue", ""], ["Wang", "Yanzhi", ""]]}, {"id": "1810.07382", "submitter": "Kamran Kowsari", "authors": "Mojtaba Heidarysafa, Kamran Kowsari, Laura E. Barnes and Donald E.\n  Brown", "title": "Analysis of Railway Accidents' Narratives Using Deep Learning", "comments": "accepted in IEEE International Conference on Machine Learning and\n  Applications (IEEE ICMLA)", "journal-ref": null, "doi": "10.1109/ICMLA.2018.00235", "report-no": null, "categories": "cs.CL cs.IR cs.LG cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Automatic understanding of domain specific texts in order to extract useful\nrelationships for later use is a non-trivial task. One such relationship would\nbe between railroad accidents' causes and their correspondent descriptions in\nreports. From 2001 to 2016 rail accidents in the U.S. cost more than $4.6B.\nRailroads involved in accidents are required to submit an accident report to\nthe Federal Railroad Administration (FRA). These reports contain a variety of\nfixed field entries including primary cause of the accidents (a coded variable\nwith 389 values) as well as a narrative field which is a short text description\nof the accident. Although these narratives provide more information than a\nfixed field entry, the terminologies used in these reports are not easy to\nunderstand by a non-expert reader. Therefore, providing an assisting method to\nfill in the primary cause from such domain specific texts(narratives) would\nhelp to label the accidents with more accuracy. Another important question for\ntransportation safety is whether the reported accident cause is consistent with\nnarrative description. To address these questions, we applied deep learning\nmethods together with powerful word embeddings such as Word2Vec and GloVe to\nclassify accident cause values for the primary cause field using the text in\nthe narratives. The results show that such approaches can both accurately\nclassify accident causes based on report narratives and find important\ninconsistencies in accident reporting.\n", "versions": [{"version": "v1", "created": "Wed, 17 Oct 2018 04:30:02 GMT"}, {"version": "v2", "created": "Mon, 17 Dec 2018 22:08:21 GMT"}, {"version": "v3", "created": "Wed, 20 May 2020 16:16:48 GMT"}], "update_date": "2020-05-21", "authors_parsed": [["Heidarysafa", "Mojtaba", ""], ["Kowsari", "Kamran", ""], ["Barnes", "Laura E.", ""], ["Brown", "Donald E.", ""]]}, {"id": "1810.07406", "submitter": "Michal Ozery-Flato", "authors": "Michal Ozery-Flato, Pierre Thodoroff, Matan Ninio, Michal Rosen-Zvi,\n  Tal El-Hay", "title": "Adversarial Balancing for Causal Inference", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Biases in observational data of treatments pose a major challenge to\nestimating expected treatment outcomes in different populations. An important\ntechnique that accounts for these biases is reweighting samples to minimize the\ndiscrepancy between treatment groups. We present a novel reweighting approach\nthat uses bi-level optimization to alternately train a discriminator to\nminimize classification error, and a balancing weights generator that uses\nexponentiated gradient descent to maximize this error. This approach borrows\nprinciples from generative adversarial networks (GANs) to exploit the power of\nclassifiers for measuring two-sample divergence. We provide theoretical results\nfor conditions in which the estimation error is bounded by two factors: (i) the\ndiscrepancy measure induced by the discriminator; and (ii) the weights\nvariability. Experimental results on several benchmarks comparing to previous\nstate-of-the-art reweighting methods demonstrate the effectiveness of this\napproach in estimating causal effects.\n", "versions": [{"version": "v1", "created": "Wed, 17 Oct 2018 07:16:20 GMT"}, {"version": "v2", "created": "Tue, 9 Apr 2019 13:33:27 GMT"}, {"version": "v3", "created": "Fri, 11 Sep 2020 15:51:32 GMT"}], "update_date": "2020-09-14", "authors_parsed": [["Ozery-Flato", "Michal", ""], ["Thodoroff", "Pierre", ""], ["Ninio", "Matan", ""], ["Rosen-Zvi", "Michal", ""], ["El-Hay", "Tal", ""]]}, {"id": "1810.07411", "submitter": "Alexander Ororbia", "authors": "Alexander Ororbia, Ankur Mali, C. Lee Giles, and Daniel Kifer", "title": "Continual Learning of Recurrent Neural Networks by Locally Aligning\n  Distributed Representations", "comments": "Important revisions made throughout (additional items/results added,\n  including a complexity analysis)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Temporal models based on recurrent neural networks have proven to be quite\npowerful in a wide variety of applications. However, training these models\noften relies on back-propagation through time, which entails unfolding the\nnetwork over many time steps, making the process of conducting credit\nassignment considerably more challenging. Furthermore, the nature of\nback-propagation itself does not permit the use of non-differentiable\nactivation functions and is inherently sequential, making parallelization of\nthe underlying training process difficult. Here, we propose the Parallel\nTemporal Neural Coding Network (P-TNCN), a biologically inspired model trained\nby the learning algorithm we call Local Representation Alignment. It aims to\nresolve the difficulties and problems that plague recurrent networks trained by\nback-propagation through time. The architecture requires neither unrolling in\ntime nor the derivatives of its internal activation functions. We compare our\nmodel and learning procedure to other back-propagation through time\nalternatives (which also tend to be computationally expensive), including\nreal-time recurrent learning, echo state networks, and unbiased online\nrecurrent optimization. We show that it outperforms these on sequence modeling\nbenchmarks such as Bouncing MNIST, a new benchmark we denote as Bouncing\nNotMNIST, and Penn Treebank. Notably, our approach can in some instances\noutperform full back-propagation through time as well as variants such as\nsparse attentive back-tracking. Significantly, the hidden unit correction phase\nof P-TNCN allows it to adapt to new datasets even if its synaptic weights are\nheld fixed (zero-shot adaptation) and facilitates retention of prior generative\nknowledge when faced with a task sequence. We present results that show the\nP-TNCN's ability to conduct zero-shot adaptation and online continual sequence\nmodeling.\n", "versions": [{"version": "v1", "created": "Wed, 17 Oct 2018 07:36:47 GMT"}, {"version": "v2", "created": "Mon, 19 Nov 2018 06:18:25 GMT"}, {"version": "v3", "created": "Mon, 10 Dec 2018 20:04:46 GMT"}, {"version": "v4", "created": "Sun, 11 Aug 2019 00:41:14 GMT"}], "update_date": "2019-08-13", "authors_parsed": [["Ororbia", "Alexander", ""], ["Mali", "Ankur", ""], ["Giles", "C. Lee", ""], ["Kifer", "Daniel", ""]]}, {"id": "1810.07435", "submitter": "Antoni Chan", "authors": "Antoni B. Chan and Janet H. Hsiao", "title": "EMHMM Simulation Study", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Eye Movement analysis with Hidden Markov Models (EMHMM) is a method for\nmodeling eye fixation sequences using hidden Markov models (HMMs). In this\nreport, we run a simulation study to investigate the estimation error for\nlearning HMMs with variational Bayesian inference, with respect to the number\nof sequences and the sequence lengths. We also relate the estimation error\nmeasured by KL divergence and L1-norm to a corresponding distortion in the\nground-truth HMM parameters.\n", "versions": [{"version": "v1", "created": "Wed, 17 Oct 2018 08:53:40 GMT"}, {"version": "v2", "created": "Tue, 25 Jun 2019 02:33:50 GMT"}], "update_date": "2019-06-26", "authors_parsed": [["Chan", "Antoni B.", ""], ["Hsiao", "Janet H.", ""]]}, {"id": "1810.07451", "submitter": "Georg Muntingh PhD", "authors": "Andrea Raffo, Oliver J.D. Barrowclough, Georg Muntingh", "title": "Reverse engineering of CAD models via clustering and approximate\n  implicitization", "comments": null, "journal-ref": null, "doi": "10.1016/j.cagd.2020.101876", "report-no": null, "categories": "math.NA cs.GR cs.LG cs.NA stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In applications like computer aided design, geometric models are often\nrepresented numerically as polynomial splines or NURBS, even when they\noriginate from primitive geometry. For purposes such as redesign and\nisogeometric analysis, it is of interest to extract information about the\nunderlying geometry through reverse engineering. In this work we develop a\nnovel method to determine these primitive shapes by combining clustering\nanalysis with approximate implicitization. The proposed method is automatic and\ncan recover algebraic hypersurfaces of any degree in any dimension. In exact\narithmetic, the algorithm returns exact results. All the required parameters,\nsuch as the implicit degree of the patches and the number of clusters of the\nmodel, are inferred using numerical approaches in order to obtain an algorithm\nthat requires as little manual input as possible. The effectiveness, efficiency\nand robustness of the method are shown both in a theoretical analysis and in\nnumerical examples implemented in Python.\n", "versions": [{"version": "v1", "created": "Wed, 17 Oct 2018 09:32:50 GMT"}, {"version": "v2", "created": "Wed, 18 Dec 2019 10:06:41 GMT"}, {"version": "v3", "created": "Sun, 19 Apr 2020 17:56:05 GMT"}], "update_date": "2021-05-14", "authors_parsed": [["Raffo", "Andrea", ""], ["Barrowclough", "Oliver J. D.", ""], ["Muntingh", "Georg", ""]]}, {"id": "1810.07468", "submitter": "Matteo Ruffini MR", "authors": "Matteo Ruffini, Guillaume Rabusseau, Borja Balle", "title": "Hierarchical Methods of Moments", "comments": "NIPS 2017", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Spectral methods of moments provide a powerful tool for learning the\nparameters of latent variable models. Despite their theoretical appeal, the\napplicability of these methods to real data is still limited due to a lack of\nrobustness to model misspecification. In this paper we present a hierarchical\napproach to methods of moments to circumvent such limitations. Our method is\nbased on replacing the tensor decomposition step used in previous algorithms\nwith approximate joint diagonalization. Experiments on topic modeling show that\nour method outperforms previous tensor decomposition methods in terms of speed\nand model quality.\n", "versions": [{"version": "v1", "created": "Wed, 17 Oct 2018 10:44:23 GMT"}], "update_date": "2018-10-18", "authors_parsed": [["Ruffini", "Matteo", ""], ["Rabusseau", "Guillaume", ""], ["Balle", "Borja", ""]]}, {"id": "1810.07481", "submitter": "Francesco Croce", "authors": "Francesco Croce (University of T\\\"ubingen), Maksym Andriushchenko\n  (Saarland University), Matthias Hein (University of T\\\"ubingen)", "title": "Provable Robustness of ReLU networks via Maximization of Linear Regions", "comments": "In AISTATS 2019. Conference version with the following modifications:\n  improved readability, comparison to Xiao et al (2018) added, section on\n  visualizations extended", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  It has been shown that neural network classifiers are not robust. This raises\nconcerns about their usage in safety-critical systems. We propose in this paper\na regularization scheme for ReLU networks which provably improves the\nrobustness of the classifier by maximizing the linear regions of the classifier\nas well as the distance to the decision boundary. Our techniques allow even to\nfind the minimal adversarial perturbation for a fraction of test points for\nlarge networks. In the experiments we show that our approach improves upon\nadversarial training both in terms of lower and upper bounds on the robustness\nand is comparable or better than the state-of-the-art in terms of test error\nand robustness.\n", "versions": [{"version": "v1", "created": "Wed, 17 Oct 2018 11:25:08 GMT"}, {"version": "v2", "created": "Fri, 8 Mar 2019 18:18:24 GMT"}], "update_date": "2019-03-11", "authors_parsed": [["Croce", "Francesco", "", "University of T\u00fcbingen"], ["Andriushchenko", "Maksym", "", "Saarland University"], ["Hein", "Matthias", "", "University of T\u00fcbingen"]]}, {"id": "1810.07483", "submitter": "Leo Pauly", "authors": "Leo Pauly, Wisdom C. Agboh, David C. Hogg, Raul Fuentes", "title": "O2A: One-shot Observational learning with Action vectors", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present O2A, a novel method for learning to perform robotic manipulation\ntasks from a single (one-shot) third-person demonstration video. To our\nknowledge, it is the first time this has been done for a single demonstration.\nThe key novelty lies in pre-training a feature extractor for creating a\nperceptual representation for actions that we call 'action vectors'. The action\nvectors are extracted using a 3D-CNN model pre-trained as an action classifier\non a generic action dataset. The distance between the action vectors from the\nobserved third-person demonstration and trial robot executions is used as a\nreward for reinforcement learning of the demonstrated task. We report on\nexperiments in simulation and on a real robot, with changes in viewpoint of\nobservation, properties of the objects involved, scene background and\nmorphology of the manipulator between the demonstration and the learning\ndomains. O2A outperforms baseline approaches under different domain shifts and\nhas comparable performance with an oracle (that uses an ideal reward function).\n", "versions": [{"version": "v1", "created": "Wed, 17 Oct 2018 11:33:11 GMT"}, {"version": "v2", "created": "Thu, 20 Jun 2019 14:40:52 GMT"}, {"version": "v3", "created": "Mon, 21 Dec 2020 13:43:15 GMT"}], "update_date": "2020-12-22", "authors_parsed": [["Pauly", "Leo", ""], ["Agboh", "Wisdom C.", ""], ["Hogg", "David C.", ""], ["Fuentes", "Raul", ""]]}, {"id": "1810.07500", "submitter": "Ivo Matteo Baltruschat", "authors": "Ivo M. Baltruschat and Leonhard Steinmeister and Harald Ittrich and\n  Gerhard Adam and Hannes Nickisch and Axel Saalbach and Jens von Berg and\n  Michael Grass and Tobias Knopp", "title": "When does Bone Suppression and Lung Field Segmentation Improve Chest\n  X-Ray Disease Classification?", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Chest radiography is the most common clinical examination type. To improve\nthe quality of patient care and to reduce workload, methods for automatic\npathology classification have been developed. In this contribution we\ninvestigate the usefulness of two advanced image pre-processing techniques,\ninitially developed for image reading by radiologists, for the performance of\nDeep Learning methods. First, we use bone suppression, an algorithm to\nartificially remove the rib cage. Secondly, we employ an automatic lung field\ndetection to crop the image to the lung area. Furthermore, we consider the\ncombination of both in the context of an ensemble approach. In a five-times\nre-sampling scheme, we use Receiver Operating Characteristic (ROC) statistics\nto evaluate the effect of the pre-processing approaches. Using a Convolutional\nNeural Network (CNN), optimized for X-ray analysis, we achieve a good\nperformance with respect to all pathologies on average. Superior results are\nobtained for selected pathologies when using pre-processing, i.e. for mass the\narea under the ROC curve increased by 9.95%. The ensemble with pre-processed\ntrained models yields the best overall results.\n", "versions": [{"version": "v1", "created": "Wed, 17 Oct 2018 12:30:08 GMT"}], "update_date": "2018-10-18", "authors_parsed": [["Baltruschat", "Ivo M.", ""], ["Steinmeister", "Leonhard", ""], ["Ittrich", "Harald", ""], ["Adam", "Gerhard", ""], ["Nickisch", "Hannes", ""], ["Saalbach", "Axel", ""], ["von Berg", "Jens", ""], ["Grass", "Michael", ""], ["Knopp", "Tobias", ""]]}, {"id": "1810.07513", "submitter": "Ahmed Elnaggar", "authors": "Ahmed Elnaggar, Christoph Gebendorfer, Ingo Glaser and Florian Matthes", "title": "Multi-Task Deep Learning for Legal Document Translation, Summarization\n  and Multi-Label Classification", "comments": "10 pages, 4 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.IR cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The digitalization of the legal domain has been ongoing for a couple of\nyears. In that process, the application of different machine learning (ML)\ntechniques is crucial. Tasks such as the classification of legal documents or\ncontract clauses as well as the translation of those are highly relevant. On\nthe other side, digitized documents are barely accessible in this field,\nparticularly in Germany. Today, deep learning (DL) is one of the hot topics\nwith many publications and various applications. Sometimes it provides results\noutperforming the human level. Hence this technique may be feasible for the\nlegal domain as well. However, DL requires thousands of samples to provide\ndecent results. A potential solution to this problem is multi-task DL to enable\ntransfer learning. This approach may be able to overcome the data scarcity\nproblem in the legal domain, specifically for the German language. We applied\nthe state of the art multi-task model on three tasks: translation,\nsummarization, and multi-label classification. The experiments were conducted\non legal document corpora utilizing several task combinations as well as\nvarious model parameters. The goal was to find the optimal configuration for\nthe tasks at hand within the legal domain. The multi-task DL approach\noutperformed the state of the art results in all three tasks. This opens a new\ndirection to integrate DL technology more efficiently in the legal domain.\n", "versions": [{"version": "v1", "created": "Tue, 16 Oct 2018 08:54:50 GMT"}], "update_date": "2018-10-18", "authors_parsed": [["Elnaggar", "Ahmed", ""], ["Gebendorfer", "Christoph", ""], ["Glaser", "Ingo", ""], ["Matthes", "Florian", ""]]}, {"id": "1810.07548", "submitter": "Chuang Ye", "authors": "Chuang Ye, M. Cenk Gursoy, and Senem Velipasalar", "title": "Deep Learning Based Power Control for Quality-Driven Wireless Video\n  Transmissions", "comments": "arXiv admin note: text overlap with arXiv:1707.08232", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.IT eess.IV math.IT stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, wireless video transmission to multiple users under total\ntransmission power and minimum required video quality constraints is studied.\nIn order to provide the desired performance levels to the end-users in\nreal-time video transmissions while using the energy resources efficiently, we\nassume that power control is employed. Due to the presence of interference,\ndetermining the optimal power control is a non-convex problem but can be solved\nvia monotonic optimization framework. However, monotonic optimization is an\niterative algorithm and can often entail considerable computational complexity,\nmaking it not suitable for real-time applications. To address this, we propose\na learning-based approach that treats the input and output of a resource\nallocation algorithm as an unknown nonlinear mapping and a deep neural network\n(DNN) is employed to learn this mapping. This learned mapping via DNN can\nprovide the optimal power level quickly for given channel conditions.\n", "versions": [{"version": "v1", "created": "Tue, 16 Oct 2018 05:14:05 GMT"}], "update_date": "2018-10-18", "authors_parsed": [["Ye", "Chuang", ""], ["Gursoy", "M. Cenk", ""], ["Velipasalar", "Senem", ""]]}, {"id": "1810.07550", "submitter": "Xi Zhu", "authors": "Junqing Qiu, Guoren Zhong, Yihua Lu, Kun Xin, Huihuan Qian, Xi Zhu", "title": "The Newton Scheme for Deep Learning", "comments": "7 pages, 10 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG physics.class-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce a neural network (NN) strictly governed by Newton's Law, with\nthe nature required basis functions derived from the fundamental classic\nmechanics. Then, by classifying the training model as a quick procedure of\n'force pattern' recognition, we developed the Newton physics-based NS scheme.\nOnce the force pattern is confirmed, the neuro network simply does the checking\nof the 'pattern stability' instead of the continuous fitting by computational\nresource consuming big data-driven processing. In the given physics's law\nsystem, once the field is confirmed, the mathematics bases for the force field\ndescription actually are not diverged but denumerable, which can save the\nfunction representations from the exhaustible available mathematics bases. In\nthis work, we endorsed Newton's Law into the deep learning technology and\nproposed Newton Scheme (NS). Under NS, the user first identifies the path\npattern, like the constant acceleration movement.The object recognition\ntechnology first loads mass information, then, the NS finds the matched\nphysical pattern and describe and predict the trajectory of the movements with\nnearly zero error. We compare the major contribution of this NS with the TCN,\nGRU and other physics inspired 'FIND-PDE' methods to demonstrate fundamental\nand extended applications of how the NS works for the free-falling, pendulum\nand curve soccer balls.The NS methodology provides more opportunity for the\nfuture deep learning advances.\n", "versions": [{"version": "v1", "created": "Tue, 16 Oct 2018 04:30:02 GMT"}], "update_date": "2018-10-18", "authors_parsed": [["Qiu", "Junqing", ""], ["Zhong", "Guoren", ""], ["Lu", "Yihua", ""], ["Xin", "Kun", ""], ["Qian", "Huihuan", ""], ["Zhu", "Xi", ""]]}, {"id": "1810.07559", "submitter": "Rodrigo de Lamare", "authors": "Y. Yu, H. Zhao and R. C. de Lamare", "title": "Study of Sparsity-Aware Subband Adaptive Filtering Algorithms with\n  Adjustable Penalties", "comments": "32 pages, 14 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.SP cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose two sparsity-aware normalized subband adaptive filter (NSAF)\nalgorithms by using the gradient descent method to minimize a combination of\nthe original NSAF cost function and the l1-norm penalty function on the filter\ncoefficients. This l1-norm penalty exploits the sparsity of a system in the\ncoefficients update formulation, thus improving the performance when\nidentifying sparse systems. Compared with prior work, the proposed algorithms\nhave lower computational complexity with comparable performance. We study and\ndevise statistical models for these sparsity-aware NSAF algorithms in the mean\nsquare sense involving their transient and steady -state behaviors. This study\nrelies on the vectorization argument and the paraunitary assumption imposed on\nthe analysis filter banks, and thus does not restrict the input signal to being\nGaussian or having another distribution. In addition, we propose to adjust\nadaptively the intensity parameter of the sparsity attraction term. Finally,\nsimulation results in sparse system identification demonstrate the\neffectiveness of our theoretical results.\n", "versions": [{"version": "v1", "created": "Tue, 16 Oct 2018 15:27:11 GMT"}], "update_date": "2018-10-18", "authors_parsed": [["Yu", "Y.", ""], ["Zhao", "H.", ""], ["de Lamare", "R. C.", ""]]}, {"id": "1810.07590", "submitter": "Damek Davis", "authors": "Damek Davis, Dmitriy Drusvyatskiy", "title": "Graphical Convergence of Subgradients in Nonconvex Optimization and\n  Learning", "comments": "36 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.OC cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We investigate the stochastic optimization problem of minimizing population\nrisk, where the loss defining the risk is assumed to be weakly convex.\nCompositions of Lipschitz convex functions with smooth maps are the primary\nexamples of such losses. We analyze the estimation quality of such nonsmooth\nand nonconvex problems by their sample average approximations. Our main results\nestablish dimension-dependent rates on subgradient estimation in full\ngenerality and dimension-independent rates when the loss is a generalized\nlinear model. As an application of the developed techniques, we analyze the\nnonsmooth landscape of a robust nonlinear regression problem.\n", "versions": [{"version": "v1", "created": "Wed, 17 Oct 2018 14:50:07 GMT"}, {"version": "v2", "created": "Mon, 17 Dec 2018 21:24:47 GMT"}], "update_date": "2018-12-19", "authors_parsed": [["Davis", "Damek", ""], ["Drusvyatskiy", "Dmitriy", ""]]}, {"id": "1810.07652", "submitter": "Mattia Antonino Di Gangi", "authors": "Mattia Antonino Di Gangi, Roberto Dess\\`i, Roldano Cattoni, Matteo\n  Negri, Marco Turchi", "title": "Fine-tuning on Clean Data for End-to-End Speech Translation: FBK @ IWSLT\n  2018", "comments": "6 pages, 2 figures, system description at the 15th International\n  Workshop on Spoken Language Translation (IWSLT) 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.AS cs.CL cs.LG cs.SD stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper describes FBK's submission to the end-to-end English-German speech\ntranslation task at IWSLT 2018. Our system relies on a state-of-the-art model\nbased on LSTMs and CNNs, where the CNNs are used to reduce the temporal\ndimension of the audio input, which is in general much higher than machine\ntranslation input. Our model was trained only on the audio-to-text parallel\ndata released for the task, and fine-tuned on cleaned subsets of the original\ntraining corpus. The addition of weight normalization and label smoothing\nimproved the baseline system by 1.0 BLEU point on our validation set. The final\nsubmission also featured checkpoint averaging within a training run and\nensemble decoding of models trained during multiple runs. On test data, our\nbest single model obtained a BLEU score of 9.7, while the ensemble obtained a\nBLEU score of 10.24.\n", "versions": [{"version": "v1", "created": "Tue, 16 Oct 2018 09:54:37 GMT"}], "update_date": "2018-10-18", "authors_parsed": [["Di Gangi", "Mattia Antonino", ""], ["Dess\u00ec", "Roberto", ""], ["Cattoni", "Roldano", ""], ["Negri", "Matteo", ""], ["Turchi", "Marco", ""]]}, {"id": "1810.07692", "submitter": "Jing Mei", "authors": "Jing Mei, Shiwan Zhao, Feng Jin, Eryu Xia, Haifeng Liu, Xiang Li", "title": "Deep Diabetologist: Learning to Prescribe Hyperglycemia Medications with\n  Hierarchical Recurrent Neural Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In healthcare, applying deep learning models to electronic health records\n(EHRs) has drawn considerable attention. EHR data consist of a sequence of\nmedical visits, i.e. a multivariate time series of diagnosis, medications,\nphysical examinations, lab tests, etc. This sequential nature makes EHR well\nmatching the power of Recurrent Neural Network (RNN). In this paper, we propose\n\"Deep Diabetologist\" - using RNNs for EHR sequential data modelling, to provide\nthe personalized hyperglycemia medication prediction for diabetic patients.\nParticularly, we develop a hierarchical RNN to capture the heterogeneous\nsequential information in the EHR data. Our experimental results demonstrate\nthe improved performance, compared with a baseline classifier using logistic\nregression. Moreover, hierarchical RNN models outperform basic ones, providing\ndeeper data insights for clinical decision support.\n", "versions": [{"version": "v1", "created": "Wed, 17 Oct 2018 00:00:10 GMT"}], "update_date": "2018-10-19", "authors_parsed": [["Mei", "Jing", ""], ["Zhao", "Shiwan", ""], ["Jin", "Feng", ""], ["Xia", "Eryu", ""], ["Liu", "Haifeng", ""], ["Li", "Xiang", ""]]}, {"id": "1810.07716", "submitter": "Dhagash Mehta", "authors": "Dhagash Mehta, Tianran Chen, Tingting Tang, Jonathan D. Hauenstein", "title": "The loss surface of deep linear networks viewed through the algebraic\n  geometry lens", "comments": "16 pages (2-columns), 5 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG math.AG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  By using the viewpoint of modern computational algebraic geometry, we explore\nproperties of the optimization landscapes of the deep linear neural network\nmodels. After clarifying on the various definitions of \"flat\" minima, we show\nthat the geometrically flat minima, which are merely artifacts of residual\ncontinuous symmetries of the deep linear networks, can be straightforwardly\nremoved by a generalized $L_2$ regularization. Then, we establish upper bounds\non the number of isolated stationary points of these networks with the help of\nalgebraic geometry. Using these upper bounds and utilizing a numerical\nalgebraic geometry method, we find all stationary points of modest depth and\nmatrix size. We show that in the presence of the non-zero regularization, deep\nlinear networks indeed possess local minima which are not the global minima.\nOur computational results clarify certain aspects of the loss surfaces of deep\nlinear networks and provide novel insights.\n", "versions": [{"version": "v1", "created": "Wed, 17 Oct 2018 18:07:44 GMT"}], "update_date": "2018-10-19", "authors_parsed": [["Mehta", "Dhagash", ""], ["Chen", "Tianran", ""], ["Tang", "Tingting", ""], ["Hauenstein", "Jonathan D.", ""]]}, {"id": "1810.07725", "submitter": "Rosana Veroneze", "authors": "Rosana Veroneze and Fernando J. Von Zuben", "title": "RIn-Close_CVC2: an even more efficient enumerative algorithm for\n  biclustering of numerical datasets", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  RIn-Close_CVC is an efficient (take polynomial time per bicluster), complete\n(find all maximal biclusters), correct (all biclusters attend the user-defined\nlevel of consistency) and non-redundant (all the obtained biclusters are\nmaximal and the same bicluster is not enumerated more than once) enumerative\nalgorithm for mining maximal biclusters with constant values on columns in\nnumerical datasets. Despite RIn-Close_CVC has all these outstanding properties,\nit has a high computational cost in terms of memory usage because it must keep\na symbol table in memory to prevent a maximal bicluster to be found more than\nonce. In this paper, we propose a new version of RIn-Close_CVC, named\nRIn-Close_CVC2, that does not use a symbol table to prevent redundant\nbiclusters, and keeps all these four properties. We also prove that these\nalgorithms actually possess these properties. Experiments are carried out with\nsynthetic and real-world datasets to compare RIn-Close_CVC and RIn-Close_CVC2\nin terms of memory usage and runtime. The experimental results show that\nRIn-Close_CVC2 brings a large reduction in memory usage and, in average,\nsignificant runtime gain when compared to its predecessor.\n", "versions": [{"version": "v1", "created": "Wed, 17 Oct 2018 18:19:39 GMT"}], "update_date": "2018-10-19", "authors_parsed": [["Veroneze", "Rosana", ""], ["Von Zuben", "Fernando J.", ""]]}, {"id": "1810.07742", "submitter": "Jianguo Chen", "authors": "Jianguo Chen, Kenli Li, Kashif Bilal, Xu Zhou, Keqin Li, and Philip S.\n  Yu", "title": "A Bi-layered Parallel Training Architecture for Large-scale\n  Convolutional Neural Networks", "comments": null, "journal-ref": "IEEE Transactions on Parallel and Distributed Systems,2019, 30(5):\n  965-976", "doi": "10.1109/TPDS.2018.2877359", "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Benefitting from large-scale training datasets and the complex training\nnetwork, Convolutional Neural Networks (CNNs) are widely applied in various\nfields with high accuracy. However, the training process of CNNs is very\ntime-consuming, where large amounts of training samples and iterative\noperations are required to obtain high-quality weight parameters. In this\npaper, we focus on the time-consuming training process of large-scale CNNs and\npropose a Bi-layered Parallel Training (BPT-CNN) architecture in distributed\ncomputing environments. BPT-CNN consists of two main components: (a) an\nouter-layer parallel training for multiple CNN subnetworks on separate data\nsubsets, and (b) an inner-layer parallel training for each subnetwork. In the\nouter-layer parallelism, we address critical issues of distributed and parallel\ncomputing, including data communication, synchronization, and workload balance.\nA heterogeneous-aware Incremental Data Partitioning and Allocation (IDPA)\nstrategy is proposed, where large-scale training datasets are partitioned and\nallocated to the computing nodes in batches according to their computing power.\nTo minimize the synchronization waiting during the global weight update\nprocess, an Asynchronous Global Weight Update (AGWU) strategy is proposed. In\nthe inner-layer parallelism, we further accelerate the training process for\neach CNN subnetwork on each computer, where computation steps of convolutional\nlayer and the local weight training are parallelized based on task-parallelism.\nWe introduce task decomposition and scheduling strategies with the objectives\nof thread-level load balancing and minimum waiting time for critical paths.\nExtensive experimental results indicate that the proposed BPT-CNN effectively\nimproves the training performance of CNNs while maintaining the accuracy.\n", "versions": [{"version": "v1", "created": "Wed, 17 Oct 2018 19:18:10 GMT"}], "update_date": "2019-11-26", "authors_parsed": [["Chen", "Jianguo", ""], ["Li", "Kenli", ""], ["Bilal", "Kashif", ""], ["Zhou", "Xu", ""], ["Li", "Keqin", ""], ["Yu", "Philip S.", ""]]}, {"id": "1810.07743", "submitter": "Kahini Wadhawan", "authors": "Payel Das, Kahini Wadhawan, Oscar Chang, Tom Sercu, Cicero Dos Santos,\n  Matthew Riemer, Vijil Chenthamarakshan, Inkit Padhi, Aleksandra Mojsilovic", "title": "PepCVAE: Semi-Supervised Targeted Design of Antimicrobial Peptide\n  Sequences", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.QM cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Given the emerging global threat of antimicrobial resistance, new methods for\nnext-generation antimicrobial design are urgently needed. We report a peptide\ngeneration framework PepCVAE, based on a semi-supervised variational\nautoencoder (VAE) model, for designing novel antimicrobial peptide (AMP)\nsequences. Our model learns a rich latent space of the biological peptide\ncontext by taking advantage of abundant, unlabeled peptide sequences. The model\nfurther learns a disentangled antimicrobial attribute space by using the\nfeedback from a jointly trained AMP classifier that uses limited labeled\ninstances. The disentangled representation allows for controllable generation\nof AMPs. Extensive analysis of the PepCVAE-generated sequences reveals superior\nperformance of our model in comparison to a plain VAE, as PepCVAE generates\nnovel AMP sequences with higher long-range diversity, while being closer to the\ntraining distribution of biological peptides. These features are highly desired\nin next-generation antimicrobial design.\n", "versions": [{"version": "v1", "created": "Wed, 17 Oct 2018 19:19:36 GMT"}, {"version": "v2", "created": "Mon, 22 Oct 2018 18:50:04 GMT"}, {"version": "v3", "created": "Tue, 13 Nov 2018 16:24:09 GMT"}], "update_date": "2018-11-14", "authors_parsed": [["Das", "Payel", ""], ["Wadhawan", "Kahini", ""], ["Chang", "Oscar", ""], ["Sercu", "Tom", ""], ["Santos", "Cicero Dos", ""], ["Riemer", "Matthew", ""], ["Chenthamarakshan", "Vijil", ""], ["Padhi", "Inkit", ""], ["Mojsilovic", "Aleksandra", ""]]}, {"id": "1810.07758", "submitter": "Hoang Anh Dau", "authors": "Hoang Anh Dau, Anthony Bagnall, Kaveh Kamgar, Chin-Chia Michael Yeh,\n  Yan Zhu, Shaghayegh Gharghabi, Chotirat Ann Ratanamahatana, Eamonn Keogh", "title": "The UCR Time Series Archive", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The UCR Time Series Archive - introduced in 2002, has become an important\nresource in the time series data mining community, with at least one thousand\npublished papers making use of at least one data set from the archive. The\noriginal incarnation of the archive had sixteen data sets but since that time,\nit has gone through periodic expansions. The last expansion took place in the\nsummer of 2015 when the archive grew from 45 to 85 data sets. This paper\nintroduces and will focus on the new data expansion from 85 to 128 data sets.\nBeyond expanding this valuable resource, this paper offers pragmatic advice to\nanyone who may wish to evaluate a new algorithm on the archive. Finally, this\npaper makes a novel and yet actionable claim: of the hundreds of papers that\nshow an improvement over the standard baseline (1-nearest neighbor\nclassification), a large fraction may be mis-attributing the reasons for their\nimprovement. Moreover, they may have been able to achieve the same improvement\nwith a much simpler modification, requiring just a single line of code.\n", "versions": [{"version": "v1", "created": "Wed, 17 Oct 2018 20:00:40 GMT"}, {"version": "v2", "created": "Mon, 9 Sep 2019 01:48:03 GMT"}], "update_date": "2019-09-10", "authors_parsed": [["Dau", "Hoang Anh", ""], ["Bagnall", "Anthony", ""], ["Kamgar", "Kaveh", ""], ["Yeh", "Chin-Chia Michael", ""], ["Zhu", "Yan", ""], ["Gharghabi", "Shaghayegh", ""], ["Ratanamahatana", "Chotirat Ann", ""], ["Keogh", "Eamonn", ""]]}, {"id": "1810.07762", "submitter": "Jianguo Chen", "authors": "Jianguo Chen, Kenli Li, Huigui Rong, Kashif Bilal, Nan Yang, Keqin Li", "title": "A Disease Diagnosis and Treatment Recommendation System Based on Big\n  Data Mining and Cloud Computing", "comments": null, "journal-ref": "Information Sciences, 2018, 435:124-149", "doi": "10.1016/j.ins.2018.01.001", "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  It is crucial to provide compatible treatment schemes for a disease according\nto various symptoms at different stages. However, most classification methods\nmight be ineffective in accurately classifying a disease that holds the\ncharacteristics of multiple treatment stages, various symptoms, and\nmulti-pathogenesis. Moreover, there are limited exchanges and cooperative\nactions in disease diagnoses and treatments between different departments and\nhospitals. Thus, when new diseases occur with atypical symptoms, inexperienced\ndoctors might have difficulty in identifying them promptly and accurately.\nTherefore, to maximize the utilization of the advanced medical technology of\ndeveloped hospitals and the rich medical knowledge of experienced doctors, a\nDisease Diagnosis and Treatment Recommendation System (DDTRS) is proposed in\nthis paper. First, to effectively identify disease symptoms more accurately, a\nDensity-Peaked Clustering Analysis (DPCA) algorithm is introduced for\ndisease-symptom clustering. In addition, association analyses on\nDisease-Diagnosis (D-D) rules and Disease-Treatment (D-T) rules are conducted\nby the Apriori algorithm separately. The appropriate diagnosis and treatment\nschemes are recommended for patients and inexperienced doctors, even if they\nare in a limited therapeutic environment. Moreover, to reach the goals of high\nperformance and low latency response, we implement a parallel solution for\nDDTRS using the Apache Spark cloud platform. Extensive experimental results\ndemonstrate that the proposed DDTRS realizes disease-symptom clustering\neffectively and derives disease treatment recommendations intelligently and\naccurately.\n", "versions": [{"version": "v1", "created": "Wed, 17 Oct 2018 20:07:08 GMT"}], "update_date": "2019-11-26", "authors_parsed": [["Chen", "Jianguo", ""], ["Li", "Kenli", ""], ["Rong", "Huigui", ""], ["Bilal", "Kashif", ""], ["Yang", "Nan", ""], ["Li", "Keqin", ""]]}, {"id": "1810.07766", "submitter": "Chen Yu", "authors": "Chen Yu, Hanlin Tang, Cedric Renggli, Simon Kassing, Ankit Singla, Dan\n  Alistarh, Ce Zhang, Ji Liu", "title": "Distributed Learning over Unreliable Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Most of today's distributed machine learning systems assume {\\em reliable\nnetworks}: whenever two machines exchange information (e.g., gradients or\nmodels), the network should guarantee the delivery of the message. At the same\ntime, recent work exhibits the impressive tolerance of machine learning\nalgorithms to errors or noise arising from relaxed communication or\nsynchronization. In this paper, we connect these two trends, and consider the\nfollowing question: {\\em Can we design machine learning systems that are\ntolerant to network unreliability during training?} With this motivation, we\nfocus on a theoretical problem of independent interest---given a standard\ndistributed parameter server architecture, if every communication between the\nworker and the server has a non-zero probability $p$ of being dropped, does\nthere exist an algorithm that still converges, and at what speed? The technical\ncontribution of this paper is a novel theoretical analysis proving that\ndistributed learning over unreliable network can achieve comparable convergence\nrate to centralized or distributed learning over reliable networks. Further, we\nprove that the influence of the packet drop rate diminishes with the growth of\nthe number of \\textcolor{black}{parameter servers}. We map this theoretical\nresult onto a real-world scenario, training deep neural networks over an\nunreliable network layer, and conduct network simulation to validate the system\nimprovement by allowing the networks to be unreliable.\n", "versions": [{"version": "v1", "created": "Wed, 17 Oct 2018 20:13:05 GMT"}, {"version": "v2", "created": "Thu, 22 Nov 2018 06:03:49 GMT"}, {"version": "v3", "created": "Wed, 6 Feb 2019 15:18:11 GMT"}, {"version": "v4", "created": "Thu, 16 May 2019 03:59:32 GMT"}], "update_date": "2019-05-17", "authors_parsed": [["Yu", "Chen", ""], ["Tang", "Hanlin", ""], ["Renggli", "Cedric", ""], ["Kassing", "Simon", ""], ["Singla", "Ankit", ""], ["Alistarh", "Dan", ""], ["Zhang", "Ce", ""], ["Liu", "Ji", ""]]}, {"id": "1810.07770", "submitter": "Chulhee Yun", "authors": "Chulhee Yun, Suvrit Sra, Ali Jadbabaie", "title": "Small ReLU networks are powerful memorizers: a tight analysis of\n  memorization capacity", "comments": "28 pages, 2 figures. NeurIPS 2019 Camera-ready version", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study finite sample expressivity, i.e., memorization power of ReLU\nnetworks. Recent results require $N$ hidden nodes to memorize/interpolate\narbitrary $N$ data points. In contrast, by exploiting depth, we show that\n3-layer ReLU networks with $\\Omega(\\sqrt{N})$ hidden nodes can perfectly\nmemorize most datasets with $N$ points. We also prove that width\n$\\Theta(\\sqrt{N})$ is necessary and sufficient for memorizing $N$ data points,\nproving tight bounds on memorization capacity. The sufficiency result can be\nextended to deeper networks; we show that an $L$-layer network with $W$\nparameters in the hidden layers can memorize $N$ data points if $W =\n\\Omega(N)$. Combined with a recent upper bound $O(WL\\log W)$ on VC dimension,\nour construction is nearly tight for any fixed $L$. Subsequently, we analyze\nmemorization capacity of residual networks under a general position assumption;\nwe prove results that substantially reduce the known requirement of $N$ hidden\nnodes. Finally, we study the dynamics of stochastic gradient descent (SGD), and\nshow that when initialized near a memorizing global minimum of the empirical\nrisk, SGD quickly finds a nearby point with much smaller empirical risk.\n", "versions": [{"version": "v1", "created": "Wed, 17 Oct 2018 20:21:43 GMT"}, {"version": "v2", "created": "Wed, 29 May 2019 00:35:32 GMT"}, {"version": "v3", "created": "Tue, 29 Oct 2019 05:22:58 GMT"}], "update_date": "2019-10-30", "authors_parsed": [["Yun", "Chulhee", ""], ["Sra", "Suvrit", ""], ["Jadbabaie", "Ali", ""]]}, {"id": "1810.07776", "submitter": "Jianguo Chen", "authors": "Jianguo Chen, Kenli Li, Huigui Rong, Kashif Bilal, Keqin Li, Philip S.\n  Yu", "title": "A Periodicity-based Parallel Time Series Prediction Algorithm in Cloud\n  Computing Environments", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In the era of big data, practical applications in various domains continually\ngenerate large-scale time-series data. Among them, some data show significant\nor potential periodicity characteristics, such as meteorological and financial\ndata. It is critical to efficiently identify the potential periodic patterns\nfrom massive time-series data and provide accurate predictions. In this paper,\na Periodicity-based Parallel Time Series Prediction (PPTSP) algorithm for\nlarge-scale time-series data is proposed and implemented in the Apache Spark\ncloud computing environment. To effectively handle the massive historical\ndatasets, a Time Series Data Compression and Abstraction (TSDCA) algorithm is\npresented, which can reduce the data scale as well as accurately extracting the\ncharacteristics. Based on this, we propose a Multi-layer Time Series Periodic\nPattern Recognition (MTSPPR) algorithm using the Fourier Spectrum Analysis\n(FSA) method. In addition, a Periodicity-based Time Series Prediction (PTSP)\nalgorithm is proposed. Data in the subsequent period are predicted based on all\nprevious period models, in which a time attenuation factor is introduced to\ncontrol the impact of different periods on the prediction results. Moreover, to\nimprove the performance of the proposed algorithms, we propose a parallel\nsolution on the Apache Spark platform, using the Streaming real-time computing\nmodule. To efficiently process the large-scale time-series datasets in\ndistributed computing environments, Distributed Streams (DStreams) and\nResilient Distributed Datasets (RDDs) are used to store and calculate these\ndatasets. Extensive experimental results show that our PPTSP algorithm has\nsignificant advantages compared with other algorithms in terms of prediction\naccuracy and performance.\n", "versions": [{"version": "v1", "created": "Wed, 17 Oct 2018 20:26:49 GMT"}], "update_date": "2018-10-19", "authors_parsed": [["Chen", "Jianguo", ""], ["Li", "Kenli", ""], ["Rong", "Huigui", ""], ["Bilal", "Kashif", ""], ["Li", "Keqin", ""], ["Yu", "Philip S.", ""]]}, {"id": "1810.07778", "submitter": "Kunkun Pang", "authors": "Kunkun Pang, Mingzhi Dong, Yang Wu, Timothy M. Hospedales", "title": "Dynamic Ensemble Active Learning: A Non-Stationary Bandit with Expert\n  Advice", "comments": "This work has been accepted at ICPR2018 and won Piero Zamperoni Best\n  Student Paper Award", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Active learning aims to reduce annotation cost by predicting which samples\nare useful for a human teacher to label. However it has become clear there is\nno best active learning algorithm. Inspired by various philosophies about what\nconstitutes a good criteria, different algorithms perform well on different\ndatasets. This has motivated research into ensembles of active learners that\nlearn what constitutes a good criteria in a given scenario, typically via\nmulti-armed bandit algorithms. Though algorithm ensembles can lead to better\nresults, they overlook the fact that not only does algorithm efficacy vary\nacross datasets, but also during a single active learning session. That is, the\nbest criteria is non-stationary. This breaks existing algorithms' guarantees\nand hampers their performance in practice. In this paper, we propose dynamic\nensemble active learning as a more general and promising research direction. We\ndevelop a dynamic ensemble active learner based on a non-stationary multi-armed\nbandit with expert advice algorithm. Our dynamic ensemble selects the right\ncriteria at each step of active learning. It has theoretical guarantees, and\nshows encouraging results on $13$ popular datasets.\n", "versions": [{"version": "v1", "created": "Sat, 29 Sep 2018 14:29:02 GMT"}], "update_date": "2018-10-19", "authors_parsed": [["Pang", "Kunkun", ""], ["Dong", "Mingzhi", ""], ["Wu", "Yang", ""], ["Hospedales", "Timothy M.", ""]]}, {"id": "1810.07785", "submitter": "Michael Chertkov", "authors": "Ryan King (NREL), Oliver Hennigh, Arvind Mohan and Michael Chertkov\n  (LANL)", "title": "From Deep to Physics-Informed Learning of Turbulence: Diagnostics", "comments": "8 pages, 3 figures", "journal-ref": "Workshop on Modeling and Decision-Making in the Spatiotemporal\n  Domain, NIPS 2018", "doi": null, "report-no": "LA-UR-18-29576", "categories": "physics.flu-dyn cs.LG nlin.CD stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We describe tests validating progress made toward acceleration and automation\nof hydrodynamic codes in the regime of developed turbulence by three Deep\nLearning (DL) Neural Network (NN) schemes trained on Direct Numerical\nSimulations of turbulence. Even the bare DL solutions, which do not take into\naccount any physics of turbulence explicitly, are impressively good overall\nwhen it comes to qualitative description of important features of turbulence.\nHowever, the early tests have also uncovered some caveats of the DL approaches.\nWe observe that the static DL scheme, implementing Convolutional GAN and\ntrained on spatial snapshots of turbulence, fails to reproduce intermittency of\nturbulent fluctuations at small scales and details of the turbulence geometry\nat large scales. We show that the dynamic NN schemes, namely LAT-NET and\nCompressed Convolutional LSTM, trained on a temporal sequence of turbulence\nsnapshots are capable to correct for the caveats of the static NN. We suggest a\npath forward towards improving reproducibility of the large-scale geometry of\nturbulence with NN.\n", "versions": [{"version": "v1", "created": "Tue, 16 Oct 2018 00:20:27 GMT"}, {"version": "v2", "created": "Wed, 5 Dec 2018 18:10:19 GMT"}], "update_date": "2018-12-06", "authors_parsed": [["King", "Ryan", "", "NREL"], ["Hennigh", "Oliver", "", "LANL"], ["Mohan", "Arvind", "", "LANL"], ["Chertkov", "Michael", "", "LANL"]]}, {"id": "1810.07791", "submitter": "Dominika Woszczyk", "authors": "Dominika Woszczyk, Gerasimos Spanakis", "title": "MaaSim: A Liveability Simulation for Improving the Quality of Life in\n  Cities", "comments": "16 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.HC cs.LG cs.NE stat.ML", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Urbanism is no longer planned on paper thanks to powerful models and 3D\nsimulation platforms. However, current work is not open to the public and lacks\nan optimisation agent that could help in decision making. This paper describes\nthe creation of an open-source simulation based on an existing Dutch\nliveability score with a built-in AI module. Features are selected using\nfeature engineering and Random Forests. Then, a modified scoring function is\nbuilt based on the former liveability classes. The score is predicted using\nRandom Forest for regression and achieved a recall of 0.83 with 10-fold\ncross-validation. Afterwards, Exploratory Factor Analysis is applied to select\nthe actions present in the model. The resulting indicators are divided into 5\ngroups, and 12 actions are generated. The performance of four optimisation\nalgorithms is compared, namely NSGA-II, PAES, SPEA2 and eps-MOEA, on three\nestablished criteria of quality: cardinality, the spread of the solutions,\nspacing, and the resulting score and number of turns. Although all four\nalgorithms show different strengths, eps-MOEA is selected to be the most\nsuitable for this problem. Ultimately, the simulation incorporates the model\nand the selected AI module in a GUI written in the Kivy framework for Python.\nTests performed on users show positive responses and encourage further\ninitiatives towards joining technology and public applications.\n", "versions": [{"version": "v1", "created": "Sat, 13 Oct 2018 15:19:41 GMT"}], "update_date": "2018-10-19", "authors_parsed": [["Woszczyk", "Dominika", ""], ["Spanakis", "Gerasimos", ""]]}, {"id": "1810.07792", "submitter": "Lucas Cassano", "authors": "Lucas Cassano, Kun Yuan, Ali H. Sayed", "title": "Multi-Agent Fully Decentralized Value Function Learning with Linear\n  Convergence Rates", "comments": "33 pages, 10 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.DC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This work develops a fully decentralized multi-agent algorithm for policy\nevaluation. The proposed scheme can be applied to two distinct scenarios. In\nthe first scenario, a collection of agents have distinct datasets gathered\nfollowing different behavior policies (none of which is required to explore the\nfull state space) in different instances of the same environment and they all\ncollaborate to evaluate a common target policy. The network approach allows for\nefficient exploration of the state space and allows all agents to converge to\nthe optimal solution even in situations where neither agent can converge on its\nown without cooperation. The second scenario is that of multi-agent games, in\nwhich the state is global and rewards are local. In this scenario, agents\ncollaborate to estimate the value function of a target team policy. The\nproposed algorithm combines off-policy learning, eligibility traces and linear\nfunction approximation. The proposed algorithm is of the variance-reduced kind\nand achieves linear convergence with $O(1)$ memory requirements. The linear\nconvergence of the algorithm is established analytically, and simulations are\nused to illustrate the effectiveness of the method.\n", "versions": [{"version": "v1", "created": "Wed, 17 Oct 2018 20:54:47 GMT"}, {"version": "v2", "created": "Tue, 4 Dec 2018 16:41:28 GMT"}, {"version": "v3", "created": "Fri, 21 Dec 2018 15:15:39 GMT"}, {"version": "v4", "created": "Wed, 31 Jul 2019 13:15:34 GMT"}, {"version": "v5", "created": "Mon, 12 Aug 2019 09:44:11 GMT"}], "update_date": "2019-08-13", "authors_parsed": [["Cassano", "Lucas", ""], ["Yuan", "Kun", ""], ["Sayed", "Ali H.", ""]]}, {"id": "1810.07793", "submitter": "Facundo Memoli", "authors": "Facundo M\\'emoli, Zane Smith, and Zhengchao Wan", "title": "The Wasserstein transform", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce the Wasserstein transform, a method for enhancing and denoising\ndatasets defined on general metric spaces. The construction draws inspiration\nfrom Optimal Transportation ideas. We establish precise connections with the\nmean shift family of algorithms and establish the stability of both our method\nand mean shift under data perturbation.\n", "versions": [{"version": "v1", "created": "Wed, 17 Oct 2018 20:58:32 GMT"}], "update_date": "2018-10-19", "authors_parsed": [["M\u00e9moli", "Facundo", ""], ["Smith", "Zane", ""], ["Wan", "Zhengchao", ""]]}, {"id": "1810.07845", "submitter": "Amir Najafi", "authors": "Amir Najafi, Saeed Ilchi, Amir H. Saberi, Seyed Abolfazl Motahari,\n  Babak H. Khalaj, Hamid R. Rabiee", "title": "On Statistical Learning of Simplices: Unmixing Problem Revisited", "comments": "32 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the sample complexity of learning a high-dimensional simplex from a\nset of points uniformly sampled from its interior. Learning of simplices is a\nlong studied problem in computer science and has applications in computational\nbiology and remote sensing, mostly under the name of `spectral unmixing'. We\ntheoretically show that a sufficient sample complexity for reliable learning of\na $K$-dimensional simplex up to a total-variation error of $\\epsilon$ is\n$O\\left(\\frac{K^2}{\\epsilon}\\log\\frac{K}{\\epsilon}\\right)$, which yields a\nsubstantial improvement over existing bounds. Based on our new theoretical\nframework, we also propose a heuristic approach for the inference of simplices.\nExperimental results on synthetic and real-world datasets demonstrate a\ncomparable performance for our method on noiseless samples, while we outperform\nthe state-of-the-art in noisy cases.\n", "versions": [{"version": "v1", "created": "Thu, 18 Oct 2018 00:20:25 GMT"}, {"version": "v2", "created": "Mon, 14 Jan 2019 19:54:20 GMT"}, {"version": "v3", "created": "Tue, 6 Aug 2019 16:35:40 GMT"}, {"version": "v4", "created": "Wed, 12 Aug 2020 23:08:46 GMT"}], "update_date": "2020-08-14", "authors_parsed": [["Najafi", "Amir", ""], ["Ilchi", "Saeed", ""], ["Saberi", "Amir H.", ""], ["Motahari", "Seyed Abolfazl", ""], ["Khalaj", "Babak H.", ""], ["Rabiee", "Hamid R.", ""]]}, {"id": "1810.07852", "submitter": "Xiangyu Guo", "authors": "Xiangyu Guo, Shi Li", "title": "Distributed $k$-Clustering for Data with Heavy Noise", "comments": "slightly improve the comm cost over the version accepted into\n  NeurIPS'18", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.DS cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we consider the $k$-center/median/means clustering with\noutliers problems (or the $(k, z)$-center/median/means problems) in the\ndistributed setting. Most previous distributed algorithms have their\ncommunication costs linearly depending on $z$, the number of outliers. Recently\nGuha et al. overcame this dependence issue by considering bi-criteria\napproximation algorithms that output solutions with $2z$ outliers. For the case\nwhere $z$ is large, the extra $z$ outliers discarded by the algorithms might be\ntoo large, considering that the data gathering process might be costly. In this\npaper, we improve the number of outliers to the best possible $(1+\\epsilon)z$,\nwhile maintaining the $O(1)$-approximation ratio and independence of\ncommunication cost on $z$. The problems we consider include the $(k, z)$-center\nproblem, and $(k, z)$-median/means problems in Euclidean metrics.\nImplementation of the our algorithm for $(k, z)$-center shows that it\noutperforms many previous algorithms, both in terms of the communication cost\nand quality of the output solution.\n", "versions": [{"version": "v1", "created": "Thu, 18 Oct 2018 01:04:14 GMT"}, {"version": "v2", "created": "Thu, 29 Nov 2018 02:41:28 GMT"}], "update_date": "2018-11-30", "authors_parsed": [["Guo", "Xiangyu", ""], ["Li", "Shi", ""]]}, {"id": "1810.07862", "submitter": "Shimin Gong", "authors": "Nguyen Cong Luong, Dinh Thai Hoang, Shimin Gong, Dusit Niyato, Ping\n  Wang, Ying-Chang Liang, Dong In Kim", "title": "Applications of Deep Reinforcement Learning in Communications and\n  Networking: A Survey", "comments": "37 pages, 13 figures, 6 tables, 174 reference papers", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper presents a comprehensive literature review on applications of deep\nreinforcement learning in communications and networking. Modern networks, e.g.,\nInternet of Things (IoT) and Unmanned Aerial Vehicle (UAV) networks, become\nmore decentralized and autonomous. In such networks, network entities need to\nmake decisions locally to maximize the network performance under uncertainty of\nnetwork environment. Reinforcement learning has been efficiently used to enable\nthe network entities to obtain the optimal policy including, e.g., decisions or\nactions, given their states when the state and action spaces are small.\nHowever, in complex and large-scale networks, the state and action spaces are\nusually large, and the reinforcement learning may not be able to find the\noptimal policy in reasonable time. Therefore, deep reinforcement learning, a\ncombination of reinforcement learning with deep learning, has been developed to\novercome the shortcomings. In this survey, we first give a tutorial of deep\nreinforcement learning from fundamental concepts to advanced models. Then, we\nreview deep reinforcement learning approaches proposed to address emerging\nissues in communications and networking. The issues include dynamic network\naccess, data rate control, wireless caching, data offloading, network security,\nand connectivity preservation which are all important to next generation\nnetworks such as 5G and beyond. Furthermore, we present applications of deep\nreinforcement learning for traffic routing, resource sharing, and data\ncollection. Finally, we highlight important challenges, open issues, and future\nresearch directions of applying deep reinforcement learning.\n", "versions": [{"version": "v1", "created": "Thu, 18 Oct 2018 01:47:19 GMT"}], "update_date": "2018-10-19", "authors_parsed": [["Luong", "Nguyen Cong", ""], ["Hoang", "Dinh Thai", ""], ["Gong", "Shimin", ""], ["Niyato", "Dusit", ""], ["Wang", "Ping", ""], ["Liang", "Ying-Chang", ""], ["Kim", "Dong In", ""]]}, {"id": "1810.07874", "submitter": "Lifang He", "authors": "Lifang He, Chun-ta Lu, Yong Chen, Jiawei Zhang, Linlin Shen, Philip S.\n  Yu, Fei Wang", "title": "A Self-Organizing Tensor Architecture for Multi-View Clustering", "comments": "2018 IEEE International Conference on Data Mining (ICDM)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In many real-world applications, data are often unlabeled and comprised of\ndifferent representations/views which often provide information complementary\nto each other. Although several multi-view clustering methods have been\nproposed, most of them routinely assume one weight for one view of features,\nand thus inter-view correlations are only considered at the view-level. These\napproaches, however, fail to explore the explicit correlations between features\nacross multiple views. In this paper, we introduce a tensor-based approach to\nincorporate the higher-order interactions among multiple views as a tensor\nstructure. Specifically, we propose a multi-linear multi-view clustering (MMC)\nmethod that can efficiently explore the full-order structural information among\nall views and reveal the underlying subspace structure embedded within the\ntensor. Extensive experiments on real-world datasets demonstrate that our\nproposed MMC algorithm clearly outperforms other related state-of-the-art\nmethods.\n", "versions": [{"version": "v1", "created": "Thu, 18 Oct 2018 02:26:28 GMT"}], "update_date": "2018-10-19", "authors_parsed": [["He", "Lifang", ""], ["Lu", "Chun-ta", ""], ["Chen", "Yong", ""], ["Zhang", "Jiawei", ""], ["Shen", "Linlin", ""], ["Yu", "Philip S.", ""], ["Wang", "Fei", ""]]}, {"id": "1810.07900", "submitter": "Kamyar Azizzadenesheli Ph.D.", "authors": "Kamyar Azizzadenesheli, Yisong Yue, Animashree Anandkumar", "title": "Policy Gradient in Partially Observable Environments: Approximation and\n  Convergence", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Policy gradient is a generic and flexible reinforcement learning approach\nthat generally enjoys simplicity in analysis, implementation, and deployment.\nIn the last few decades, this approach has been extensively advanced for fully\nobservable environments. In this paper, we generalize a variety of these\nadvances to partially observable settings, and similar to the fully observable\ncase, we keep our focus on the class of Markovian policies. We propose a series\nof technical tools, including a novel notion of advantage function, to develop\npolicy gradient algorithms and study their convergence properties in such\nenvironments. Deploying these tools, we generalize a variety of existing\ntheoretical guarantees, such as policy gradient and convergence theorems, to\npartially observable domains, those which also could be carried to more\nsettings of interest. This study also sheds light on the understanding of\npolicy gradient approaches in real-world applications which tend to be\npartially observable.\n", "versions": [{"version": "v1", "created": "Thu, 18 Oct 2018 05:25:11 GMT"}, {"version": "v2", "created": "Thu, 24 Jan 2019 23:34:04 GMT"}, {"version": "v3", "created": "Sun, 24 May 2020 21:30:54 GMT"}], "update_date": "2020-05-26", "authors_parsed": [["Azizzadenesheli", "Kamyar", ""], ["Yue", "Yisong", ""], ["Anandkumar", "Animashree", ""]]}, {"id": "1810.07911", "submitter": "Zhiding Yu", "authors": "Yang Zou, Zhiding Yu, B. V. K. Vijaya Kumar, Jinsong Wang", "title": "Domain Adaptation for Semantic Segmentation via Class-Balanced\n  Self-Training", "comments": "Accepted to ECCV 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG cs.MM", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Recent deep networks achieved state of the art performance on a variety of\nsemantic segmentation tasks. Despite such progress, these models often face\nchallenges in real world `wild tasks' where large difference between labeled\ntraining/source data and unseen test/target data exists. In particular, such\ndifference is often referred to as `domain gap', and could cause significantly\ndecreased performance which cannot be easily remedied by further increasing the\nrepresentation power. Unsupervised domain adaptation (UDA) seeks to overcome\nsuch problem without target domain labels. In this paper, we propose a novel\nUDA framework based on an iterative self-training procedure, where the problem\nis formulated as latent variable loss minimization, and can be solved by\nalternatively generating pseudo labels on target data and re-training the model\nwith these labels. On top of self-training, we also propose a novel\nclass-balanced self-training framework to avoid the gradual dominance of large\nclasses on pseudo-label generation, and introduce spatial priors to refine\ngenerated labels. Comprehensive experiments show that the proposed methods\nachieve state of the art semantic segmentation performance under multiple major\nUDA settings.\n", "versions": [{"version": "v1", "created": "Thu, 18 Oct 2018 06:20:02 GMT"}, {"version": "v2", "created": "Thu, 25 Oct 2018 09:51:52 GMT"}], "update_date": "2018-10-26", "authors_parsed": [["Zou", "Yang", ""], ["Yu", "Zhiding", ""], ["Kumar", "B. V. K. Vijaya", ""], ["Wang", "Jinsong", ""]]}, {"id": "1810.07913", "submitter": "Kean Ming Tan", "authors": "Kean Ming Tan and Qiang Sun and Daniela Witten", "title": "Robust Sparse Reduced Rank Regression in High Dimensions", "comments": "This is a replacement of a previous article titled \"Distributionally\n  Robust Reduced Rank Regression and Principal Component Analysis in High\n  Dimensions\"", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose robust sparse reduced rank regression for analyzing large and\ncomplex high-dimensional data with heavy-tailed random noise. The proposed\nmethod is based on a convex relaxation of a rank- and sparsity-constrained\nnon-convex optimization problem, which is then solved using the alternating\ndirection method of multipliers algorithm. We establish non-asymptotic\nestimation error bounds under both Frobenius and nuclear norms in the\nhigh-dimensional setting. This is a major contribution over existing results in\nreduced rank regression, which mainly focus on rank selection and prediction\nconsistency. Our theoretical results quantify the tradeoff between\nheavy-tailedness of the random noise and statistical bias. For random noise\nwith bounded $(1+\\delta)$th moment with $\\delta \\in (0,1)$, the rate of\nconvergence is a function of $\\delta$, and is slower than the sub-Gaussian-type\ndeviation bounds; for random noise with bounded second moment, we obtain a rate\nof convergence as if sub-Gaussian noise were assumed. Furthermore, the\ntransition between the two regimes is smooth. We illustrate the performance of\nthe proposed method via extensive numerical studies and a data application.\n", "versions": [{"version": "v1", "created": "Thu, 18 Oct 2018 06:21:52 GMT"}, {"version": "v2", "created": "Sun, 14 Apr 2019 19:37:42 GMT"}], "update_date": "2019-04-16", "authors_parsed": [["Tan", "Kean Ming", ""], ["Sun", "Qiang", ""], ["Witten", "Daniela", ""]]}, {"id": "1810.07924", "submitter": "Fran\\c{c}ois Bachoc", "authors": "Fran\\c{c}ois Bachoc (IMT), Fabrice Gamboa (IMT), Max Halford (IMT,\n  IRIT), Jean-Michel Loubes (IMT), Laurent Risser (IMT)", "title": "Explaining Machine Learning Models using Entropic Variable Projection", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we present a new explainability formalism designed to explain\nhow each input variable of a test set impacts the predictions of machine\nlearning models. Hence, we propose a group explainability formalism for trained\nmachine learning decision rules, based on their response to the variability of\nthe input variables distribution. In order to emphasize the impact of each\ninput variable, this formalism uses an information theory framework that\nquantifies the influence of all input-output observations based on entropic\nprojections. This is thus the first unified and model agnostic formalism\nenabling data scientists to interpret the dependence between the input\nvariables, their impact on the prediction errors, and their influence on the\noutput predictions. Convergence rates of the entropic projections are provided\nin the large sample case. Most importantly, we prove that computing an\nexplanation in our framework has a low algorithmic complexity, making it\nscalable to real-life large datasets. We illustrate our strategy by explaining\ncomplex decision rules learned by using XGBoost, Random Forest or Deep Neural\nNetwork classifiers on various datasets such as Adult income, MNIST and CelebA.\nWe finally make clear its differences with the explainability strategies\n\\textit{LIME} and \\textit{SHAP}, that are based on single observations. Results\ncan be reproduced by using the freely distributed Python toolbox\nhttps://gems-ai.com}.\n", "versions": [{"version": "v1", "created": "Thu, 18 Oct 2018 07:04:39 GMT"}, {"version": "v2", "created": "Fri, 26 Jul 2019 17:47:22 GMT"}, {"version": "v3", "created": "Tue, 4 Feb 2020 12:44:12 GMT"}, {"version": "v4", "created": "Fri, 26 Jun 2020 11:41:16 GMT"}, {"version": "v5", "created": "Wed, 2 Dec 2020 14:29:31 GMT"}], "update_date": "2020-12-03", "authors_parsed": [["Bachoc", "Fran\u00e7ois", "", "IMT"], ["Gamboa", "Fabrice", "", "IMT"], ["Halford", "Max", "", "IMT,\n  IRIT"], ["Loubes", "Jean-Michel", "", "IMT"], ["Risser", "Laurent", "", "IMT"]]}, {"id": "1810.07931", "submitter": "Sai Surya", "authors": "Sai Surya, Abhijit Mishra, Anirban Laha, Parag Jain, Karthik\n  Sankaranarayanan", "title": "Unsupervised Neural Text Simplification", "comments": "ACL 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The paper presents a first attempt towards unsupervised neural text\nsimplification that relies only on unlabeled text corpora. The core framework\nis composed of a shared encoder and a pair of attentional-decoders and gains\nknowledge of simplification through discrimination based-losses and denoising.\nThe framework is trained using unlabeled text collected from en-Wikipedia dump.\nOur analysis (both quantitative and qualitative involving human evaluators) on\na public test data shows that the proposed model can perform\ntext-simplification at both lexical and syntactic levels, competitive to\nexisting supervised methods. Addition of a few labelled pairs also improves the\nperformance further.\n", "versions": [{"version": "v1", "created": "Thu, 18 Oct 2018 07:43:12 GMT"}, {"version": "v2", "created": "Wed, 19 Dec 2018 14:28:43 GMT"}, {"version": "v3", "created": "Wed, 2 Jan 2019 03:36:48 GMT"}, {"version": "v4", "created": "Thu, 10 Jan 2019 11:43:46 GMT"}, {"version": "v5", "created": "Tue, 4 Jun 2019 13:33:50 GMT"}, {"version": "v6", "created": "Wed, 21 Aug 2019 08:45:12 GMT"}], "update_date": "2019-08-22", "authors_parsed": [["Surya", "Sai", ""], ["Mishra", "Abhijit", ""], ["Laha", "Anirban", ""], ["Jain", "Parag", ""], ["Sankaranarayanan", "Karthik", ""]]}, {"id": "1810.07954", "submitter": "Yuting Ye", "authors": "Christine Ho, Yuting Ye, Ci-Ren Jiang, Wayne Tai Lee and Haiyan Huang", "title": "HierLPR: Decision making in hierarchical multi-label classification with\n  local precision rates", "comments": "27 pages, 9 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this article we propose a novel ranking algorithm, referred to as HierLPR,\nfor the multi-label classification problem when the candidate labels follow a\nknown hierarchical structure. HierLPR is motivated by a new metric called eAUC\nthat we design to assess the ranking of classification decisions. This metric,\nassociated with the hit curve and local precision rate, emphasizes the accuracy\nof the first calls. We show that HierLPR optimizes eAUC under the tree\nconstraint and some light assumptions on the dependency between the nodes in\nthe hierarchy. We also provide a strategy to make calls for each node based on\nthe ordering produced by HierLPR, with the intent of controlling FDR or\nmaximizing F-score. The performance of our proposed methods is demonstrated on\nsynthetic datasets as well as a real example of disease diagnosis using NCBI\nGEO datasets. In these cases, HierLPR shows a favorable result over competing\nmethods in the early part of the precision-recall curve.\n", "versions": [{"version": "v1", "created": "Thu, 18 Oct 2018 08:59:04 GMT"}], "update_date": "2018-10-19", "authors_parsed": [["Ho", "Christine", ""], ["Ye", "Yuting", ""], ["Jiang", "Ci-Ren", ""], ["Lee", "Wayne Tai", ""], ["Huang", "Haiyan", ""]]}, {"id": "1810.07961", "submitter": "Pulkit Kumar", "authors": "Simmi Mourya, Sonaal Kant, Pulkit Kumar, Anubha Gupta, Ritu Gupta", "title": "LeukoNet: DCT-based CNN architecture for the classification of normal\n  versus Leukemic blasts in B-ALL Cancer", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG eess.IV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Acute lymphoblastic leukemia (ALL) constitutes approximately 25% of the\npediatric cancers. In general, the task of identifying immature leukemic blasts\nfrom normal cells under the microscope is challenging because morphologically\nthe images of the two cells appear similar. In this paper, we propose a deep\nlearning framework for classifying immature leukemic blasts and normal cells.\nThe proposed model combines the Discrete Cosine Transform (DCT) domain features\nextracted via CNN with the Optical Density (OD) space features to build a\nrobust classifier. Elaborate experiments have been conducted to validate the\nproposed LeukoNet classifier.\n", "versions": [{"version": "v1", "created": "Thu, 18 Oct 2018 09:24:14 GMT"}, {"version": "v2", "created": "Sun, 4 Nov 2018 08:05:41 GMT"}], "update_date": "2018-11-06", "authors_parsed": [["Mourya", "Simmi", ""], ["Kant", "Sonaal", ""], ["Kumar", "Pulkit", ""], ["Gupta", "Anubha", ""], ["Gupta", "Ritu", ""]]}, {"id": "1810.07973", "submitter": "Tineke Blom", "authors": "Tineke Blom, Anna Klimovskaia, Sara Magliacane, Joris M. Mooij", "title": "An Upper Bound for Random Measurement Error in Causal Discovery", "comments": "Published in Proceedings of the 34th Annual Conference on Uncertainty\n  in Artificial Intelligence (UAI-18)", "journal-ref": "Proceedings of the 34th Annual Conference on Uncertainty in\n  Artificial Intelligence, 2018", "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Causal discovery algorithms infer causal relations from data based on several\nassumptions, including notably the absence of measurement error. However, this\nassumption is most likely violated in practical applications, which may result\nin erroneous, irreproducible results. In this work we show how to obtain an\nupper bound for the variance of random measurement error from the covariance\nmatrix of measured variables and how to use this upper bound as a correction\nfor constraint-based causal discovery. We demonstrate a practical application\nof our approach on both simulated data and real-world protein signaling data.\n", "versions": [{"version": "v1", "created": "Thu, 18 Oct 2018 09:47:35 GMT"}], "update_date": "2018-10-19", "authors_parsed": [["Blom", "Tineke", ""], ["Klimovskaia", "Anna", ""], ["Magliacane", "Sara", ""], ["Mooij", "Joris M.", ""]]}, {"id": "1810.07988", "submitter": "Maurizio Pierini", "authors": "Jesus Arjona Martinez and Olmo Cerri and Maurizio Pierini and Maria\n  Spiropulu and Jean-Roch Vlimant", "title": "Pileup mitigation at the Large Hadron Collider with Graph Neural\n  Networks", "comments": "12 pages, 11 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "hep-ph cs.LG hep-ex", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  At the Large Hadron Collider, the high transverse-momentum events studied by\nexperimental collaborations occur in coincidence with parasitic low\ntransverse-momentum collisions, usually referred to as pileup. Pileup\nmitigation is a key ingredient of the online and offline event reconstruction\nas pileup affects the reconstruction accuracy of many physics observables. We\npresent a classifier based on Graph Neural Networks, trained to retain\nparticles coming from high-transverse-momentum collisions, while rejecting\nthose coming from pileup collisions. This model is designed as a refinement of\nthe PUPPI algorithm, employed in many LHC data analyses since 2015. Thanks to\nan extended basis of input information and the learning capabilities of the\nconsidered network architecture, we show an improvement in pileup-rejection\nperformances with respect to state-of-the-art solutions.\n", "versions": [{"version": "v1", "created": "Thu, 18 Oct 2018 11:00:08 GMT"}, {"version": "v2", "created": "Thu, 22 Nov 2018 17:01:52 GMT"}, {"version": "v3", "created": "Wed, 5 Dec 2018 10:32:50 GMT"}, {"version": "v4", "created": "Thu, 13 Jun 2019 16:00:47 GMT"}], "update_date": "2019-06-14", "authors_parsed": [["Martinez", "Jesus Arjona", ""], ["Cerri", "Olmo", ""], ["Pierini", "Maurizio", ""], ["Spiropulu", "Maria", ""], ["Vlimant", "Jean-Roch", ""]]}, {"id": "1810.08010", "submitter": "Benjamin Rhodes", "authors": "Benjamin Rhodes, Michael Gutmann", "title": "Variational Noise-Contrastive Estimation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Unnormalised latent variable models are a broad and flexible class of\nstatistical models. However, learning their parameters from data is\nintractable, and few estimation techniques are currently available for such\nmodels. To increase the number of techniques in our arsenal, we propose\nvariational noise-contrastive estimation (VNCE), building on NCE which is a\nmethod that only applies to unnormalised models. The core idea is to use a\nvariational lower bound to the NCE objective function, which can be optimised\nin the same fashion as the evidence lower bound (ELBO) in standard variational\ninference (VI). We prove that VNCE can be used for both parameter estimation of\nunnormalised models and posterior inference of latent variables. The developed\ntheory shows that VNCE has the same level of generality as standard VI, meaning\nthat advances made there can be directly imported to the unnormalised setting.\nWe validate VNCE on toy models and apply it to a realistic problem of\nestimating an undirected graphical model from incomplete data.\n", "versions": [{"version": "v1", "created": "Thu, 18 Oct 2018 12:32:11 GMT"}, {"version": "v2", "created": "Fri, 19 Oct 2018 08:14:56 GMT"}, {"version": "v3", "created": "Sun, 24 Feb 2019 14:07:40 GMT"}], "update_date": "2019-02-26", "authors_parsed": [["Rhodes", "Benjamin", ""], ["Gutmann", "Michael", ""]]}, {"id": "1810.08033", "submitter": "Taiji Suzuki", "authors": "Taiji Suzuki", "title": "Adaptivity of deep ReLU network for learning in Besov and mixed smooth\n  Besov spaces: optimal rate and curse of dimensionality", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep learning has shown high performances in various types of tasks from\nvisual recognition to natural language processing, which indicates superior\nflexibility and adaptivity of deep learning. To understand this phenomenon\ntheoretically, we develop a new approximation and estimation error analysis of\ndeep learning with the ReLU activation for functions in a Besov space and its\nvariant with mixed smoothness. The Besov space is a considerably general\nfunction space including the Holder space and Sobolev space, and especially can\ncapture spatial inhomogeneity of smoothness. Through the analysis in the Besov\nspace, it is shown that deep learning can achieve the minimax optimal rate and\noutperform any non-adaptive (linear) estimator such as kernel ridge regression,\nwhich shows that deep learning has higher adaptivity to the spatial\ninhomogeneity of the target function than other estimators such as linear ones.\nIn addition to this, it is shown that deep learning can avoid the curse of\ndimensionality if the target function is in a mixed smooth Besov space. We also\nshow that the dependency of the convergence rate on the dimensionality is tight\ndue to its minimax optimality. These results support high adaptivity of deep\nlearning and its superior ability as a feature extractor.\n", "versions": [{"version": "v1", "created": "Thu, 18 Oct 2018 13:17:20 GMT"}], "update_date": "2018-10-19", "authors_parsed": [["Suzuki", "Taiji", ""]]}, {"id": "1810.08047", "submitter": "Sepanta Zeighami", "authors": "Sepanta Zeighami and Raymong Chi-Wing Wong", "title": "Finding Average Regret Ratio Minimizing Set in Database", "comments": "Submitted to ICDE '19", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DB cs.IR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Selecting a certain number of data points (or records) from a database which\n\"best\" satisfy users' expectations is a very prevalent problem with many\napplications. One application is a hotel booking website showing a certain\nnumber of hotels on a single page. However, this problem is very challenging\nsince the selected points should \"collectively\" satisfy the expectation of all\nusers. Showing a certain number of data points to a single user could decrease\nthe satisfaction of a user because the user may not be able to see his/her\nfavorite point which could be found in the original database. In this paper, we\nwould like to find a set of k points such that on average, the satisfaction\n(ratio) of a user is maximized. This problem takes into account the probability\ndistribution of the users and considers the satisfaction (ratio) of all users,\nwhich is more reasonable in practice, compared with the existing studies that\nonly consider the worst-case satisfaction (ratio) of the users, which may not\nreflect the whole population and is not useful in some applications. Motivated\nby this, in this paper, we propose algorithms for this problem. Finally, we\nconducted experiments to show the effectiveness and the efficiency of the\nalgorithms.\n", "versions": [{"version": "v1", "created": "Thu, 18 Oct 2018 13:42:04 GMT"}], "update_date": "2018-10-19", "authors_parsed": [["Zeighami", "Sepanta", ""], ["Wong", "Raymong Chi-Wing", ""]]}, {"id": "1810.08061", "submitter": "Andrew Johnson", "authors": "Dan Moldovan and James M Decker and Fei Wang and Andrew A Johnson and\n  Brian K Lee and Zachary Nado and D Sculley and Tiark Rompf and Alexander B\n  Wiltschko", "title": "AutoGraph: Imperative-style Coding with Graph-based Performance", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.PL cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  There is a perceived trade-off between machine learning code that is easy to\nwrite, and machine learning code that is scalable or fast to execute. In\nmachine learning, imperative style libraries like Autograd and PyTorch are easy\nto write, but suffer from high interpretive overhead and are not easily\ndeployable in production or mobile settings. Graph-based libraries like\nTensorFlow and Theano benefit from whole-program optimization and can be\ndeployed broadly, but make expressing complex models more cumbersome. We\ndescribe how the use of staged programming in Python, via source code\ntransformation, offers a midpoint between these two library design patterns,\ncapturing the benefits of both. A key insight is to delay all type-dependent\ndecisions until runtime, via dynamic dispatch. We instantiate these principles\nin AutoGraph, a software system that improves the programming experience of the\nTensorFlow library, and demonstrate usability improvements with no loss in\nperformance compared to native TensorFlow graphs. We also show that our system\nis backend agnostic, and demonstrate targeting an alternate IR with\ncharacteristics not found in TensorFlow graphs.\n", "versions": [{"version": "v1", "created": "Tue, 16 Oct 2018 19:14:09 GMT"}, {"version": "v2", "created": "Tue, 26 Mar 2019 19:19:51 GMT"}], "update_date": "2019-03-28", "authors_parsed": [["Moldovan", "Dan", ""], ["Decker", "James M", ""], ["Wang", "Fei", ""], ["Johnson", "Andrew A", ""], ["Lee", "Brian K", ""], ["Nado", "Zachary", ""], ["Sculley", "D", ""], ["Rompf", "Tiark", ""], ["Wiltschko", "Alexander B", ""]]}, {"id": "1810.08076", "submitter": "Leonid Berov", "authors": "Leonid Berov, Kai Standvoss", "title": "Discourse Embellishment Using a Deep Encoder-Decoder Network", "comments": "Accepted at CC-NLG 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We suggest a new NLG task in the context of the discourse generation pipeline\nof computational storytelling systems. This task, textual embellishment, is\ndefined by taking a text as input and generating a semantically equivalent\noutput with increased lexical and syntactic complexity. Ideally, this would\nallow the authors of computational storytellers to implement just lightweight\nNLG systems and use a domain-independent embellishment module to translate its\noutput into more literary text. We present promising first results on this task\nusing LSTM Encoder-Decoder networks trained on the WikiLarge dataset.\nFurthermore, we introduce \"Compiled Computer Tales\", a corpus of\ncomputationally generated stories, that can be used to test the capabilities of\nembellishment algorithms.\n", "versions": [{"version": "v1", "created": "Thu, 18 Oct 2018 14:29:50 GMT"}], "update_date": "2018-10-19", "authors_parsed": [["Berov", "Leonid", ""], ["Standvoss", "Kai", ""]]}, {"id": "1810.08083", "submitter": "Simone Rossi", "authors": "Simone Rossi and Pietro Michiardi and Maurizio Filippone", "title": "Good Initializations of Variational Bayes for Deep Models", "comments": "8 pages of main paper (+3 for references and +6 of supplement\n  material)", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Stochastic variational inference is an established way to carry out\napproximate Bayesian inference for deep models. While there have been effective\nproposals for good initializations for loss minimization in deep learning, far\nless attention has been devoted to the issue of initialization of stochastic\nvariational inference. We address this by proposing a novel layer-wise\ninitialization strategy based on Bayesian linear models. The proposed method is\nextensively validated on regression and classification tasks, including\nBayesian DeepNets and ConvNets, showing faster and better convergence compared\nto alternatives inspired by the literature on initializations for loss\nminimization.\n", "versions": [{"version": "v1", "created": "Thu, 18 Oct 2018 14:35:23 GMT"}, {"version": "v2", "created": "Fri, 25 Jan 2019 09:41:07 GMT"}], "update_date": "2019-01-28", "authors_parsed": [["Rossi", "Simone", ""], ["Michiardi", "Pietro", ""], ["Filippone", "Maurizio", ""]]}, {"id": "1810.08102", "submitter": "Nicolas Perrin-Gilbert", "authors": "Thomas Pierrot and Nicolas Perrin and Olivier Sigaud", "title": "First-order and second-order variants of the gradient descent in a\n  unified framework", "comments": "13 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we provide an overview of first-order and second-order\nvariants of the gradient descent method that are commonly used in machine\nlearning. We propose a general framework in which 6 of these variants can be\ninterpreted as different instances of the same approach. They are the vanilla\ngradient descent, the classical and generalized Gauss-Newton methods, the\nnatural gradient descent method, the gradient covariance matrix approach, and\nNewton's method. Besides interpreting these methods within a single framework,\nwe explain their specificities and show under which conditions some of them\ncoincide.\n", "versions": [{"version": "v1", "created": "Thu, 18 Oct 2018 15:18:09 GMT"}, {"version": "v2", "created": "Thu, 18 Jul 2019 15:34:39 GMT"}, {"version": "v3", "created": "Tue, 13 Apr 2021 11:56:10 GMT"}], "update_date": "2021-04-14", "authors_parsed": [["Pierrot", "Thomas", ""], ["Perrin", "Nicolas", ""], ["Sigaud", "Olivier", ""]]}, {"id": "1810.08126", "submitter": "Peiye Liu", "authors": "Peiye Liu, Wu Liu, Huadong Ma, Tao Mei, Mingoo Seok", "title": "KTAN: Knowledge Transfer Adversarial Network", "comments": "8 pages, 2 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  To reduce the large computation and storage cost of a deep convolutional\nneural network, the knowledge distillation based methods have pioneered to\ntransfer the generalization ability of a large (teacher) deep network to a\nlight-weight (student) network. However, these methods mostly focus on\ntransferring the probability distribution of the softmax layer in a teacher\nnetwork and thus neglect the intermediate representations. In this paper, we\npropose a knowledge transfer adversarial network to better train a student\nnetwork. Our technique holistically considers both intermediate representations\nand probability distributions of a teacher network. To transfer the knowledge\nof intermediate representations, we set high-level teacher feature maps as a\ntarget, toward which the student feature maps are trained. Specifically, we\narrange a Teacher-to-Student layer for enabling our framework suitable for\nvarious student structures. The intermediate representation helps the student\nnetwork better understand the transferred generalization as compared to the\nprobability distribution only. Furthermore, we infuse an adversarial learning\nprocess by employing a discriminator network, which can fully exploit the\nspatial correlation of feature maps in training a student network. The\nexperimental results demonstrate that the proposed method can significantly\nimprove the performance of a student network on both image classification and\nobject detection tasks.\n", "versions": [{"version": "v1", "created": "Thu, 18 Oct 2018 15:57:02 GMT"}], "update_date": "2018-10-19", "authors_parsed": [["Liu", "Peiye", ""], ["Liu", "Wu", ""], ["Ma", "Huadong", ""], ["Mei", "Tao", ""], ["Seok", "Mingoo", ""]]}, {"id": "1810.08130", "submitter": "Morten Dahl", "authors": "Morten Dahl, Jason Mancuso, Yann Dupis, Ben Decoste, Morgan Giraud,\n  Ian Livingstone, Justin Patriquin, Gavin Uhma", "title": "Private Machine Learning in TensorFlow using Secure Computation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a framework for experimenting with secure multi-party computation\ndirectly in TensorFlow. By doing so we benefit from several properties valuable\nto both researchers and practitioners, including tight integration with\nordinary machine learning processes, existing optimizations for distributed\ncomputation in TensorFlow, high-level abstractions for expressing complex\nalgorithms and protocols, and an expanded set of familiar tooling. We give an\nopen source implementation of a state-of-the-art protocol and report on\nconcrete benchmarks using typical models from private machine learning.\n", "versions": [{"version": "v1", "created": "Thu, 18 Oct 2018 16:10:12 GMT"}, {"version": "v2", "created": "Tue, 23 Oct 2018 08:13:06 GMT"}], "update_date": "2018-10-24", "authors_parsed": [["Dahl", "Morten", ""], ["Mancuso", "Jason", ""], ["Dupis", "Yann", ""], ["Decoste", "Ben", ""], ["Giraud", "Morgan", ""], ["Livingstone", "Ian", ""], ["Patriquin", "Justin", ""], ["Uhma", "Gavin", ""]]}, {"id": "1810.08163", "submitter": "Steven Hansen", "authors": "Steven Hansen, Pablo Sprechmann, Alexander Pritzel, Andr\\'e Barreto,\n  Charles Blundell", "title": "Fast deep reinforcement learning using online adjustments from the past", "comments": "Accepted at NIPS 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose Ephemeral Value Adjusments (EVA): a means of allowing deep\nreinforcement learning agents to rapidly adapt to experience in their replay\nbuffer. EVA shifts the value predicted by a neural network with an estimate of\nthe value function found by planning over experience tuples from the replay\nbuffer near the current state. EVA combines a number of recent ideas around\ncombining episodic memory-like structures into reinforcement learning agents:\nslot-based storage, content-based retrieval, and memory-based planning. We show\nthat EVAis performant on a demonstration task and Atari games.\n", "versions": [{"version": "v1", "created": "Thu, 18 Oct 2018 17:00:20 GMT"}], "update_date": "2018-10-19", "authors_parsed": [["Hansen", "Steven", ""], ["Sprechmann", "Pablo", ""], ["Pritzel", "Alexander", ""], ["Barreto", "Andr\u00e9", ""], ["Blundell", "Charles", ""]]}, {"id": "1810.08164", "submitter": "Samarth Gupta", "authors": "Samarth Gupta, Shreyas Chaudhari, Subhojyoti Mukherjee, Gauri Joshi,\n  Osman Ya\\u{g}an", "title": "A Unified Approach to Translate Classical Bandit Algorithms to the\n  Structured Bandit Setting", "comments": null, "journal-ref": "IEEE Journal on Selected Areas of Information Theory 2020", "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider a finite-armed structured bandit problem in which mean rewards of\ndifferent arms are known functions of a common hidden parameter $\\theta^*$.\nSince we do not place any restrictions of these functions, the problem setting\nsubsumes several previously studied frameworks that assume linear or invertible\nreward functions. We propose a novel approach to gradually estimate the hidden\n$\\theta^*$ and use the estimate together with the mean reward functions to\nsubstantially reduce exploration of sub-optimal arms. This approach enables us\nto fundamentally generalize any classic bandit algorithm including UCB and\nThompson Sampling to the structured bandit setting. We prove via regret\nanalysis that our proposed UCB-C algorithm (structured bandit versions of UCB)\npulls only a subset of the sub-optimal arms $O(\\log T)$ times while the other\nsub-optimal arms (referred to as non-competitive arms) are pulled $O(1)$ times.\nAs a result, in cases where all sub-optimal arms are non-competitive, which can\nhappen in many practical scenarios, the proposed algorithms achieve bounded\nregret. We also conduct simulations on the Movielens recommendations dataset to\ndemonstrate the improvement of the proposed algorithms over existing structured\nbandit algorithms.\n", "versions": [{"version": "v1", "created": "Thu, 18 Oct 2018 17:01:00 GMT"}, {"version": "v2", "created": "Tue, 29 Jan 2019 22:31:18 GMT"}, {"version": "v3", "created": "Tue, 26 Mar 2019 14:50:05 GMT"}, {"version": "v4", "created": "Wed, 6 Nov 2019 16:18:31 GMT"}, {"version": "v5", "created": "Tue, 3 Dec 2019 23:22:38 GMT"}, {"version": "v6", "created": "Mon, 25 May 2020 18:53:55 GMT"}, {"version": "v7", "created": "Wed, 3 Feb 2021 17:46:16 GMT"}], "update_date": "2021-02-04", "authors_parsed": [["Gupta", "Samarth", ""], ["Chaudhari", "Shreyas", ""], ["Mukherjee", "Subhojyoti", ""], ["Joshi", "Gauri", ""], ["Ya\u011fan", "Osman", ""]]}, {"id": "1810.08171", "submitter": "Hongyang Zhang", "authors": "Maria-Florina Balcan and Yi Li and David P. Woodruff and Hongyang\n  Zhang", "title": "Testing Matrix Rank, Optimally", "comments": "51 pages. To appear in SODA 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We show that for the problem of testing if a matrix $A \\in F^{n \\times n}$\nhas rank at most $d$, or requires changing an $\\epsilon$-fraction of entries to\nhave rank at most $d$, there is a non-adaptive query algorithm making\n$\\widetilde{O}(d^2/\\epsilon)$ queries. Our algorithm works for any field $F$.\nThis improves upon the previous $O(d^2/\\epsilon^2)$ bound (SODA'03), and\nbypasses an $\\Omega(d^2/\\epsilon^2)$ lower bound of (KDD'14) which holds if the\nalgorithm is required to read a submatrix. Our algorithm is the first such\nalgorithm which does not read a submatrix, and instead reads a carefully\nselected non-adaptive pattern of entries in rows and columns of $A$. We\ncomplement our algorithm with a matching query complexity lower bound for\nnon-adaptive testers over any field. We also give tight bounds of\n$\\widetilde{\\Theta}(d^2)$ queries in the sensing model for which query access\ncomes in the form of $\\langle X_i, A\\rangle:=tr(X_i^\\top A)$; perhaps\nsurprisingly these bounds do not depend on $\\epsilon$.\n  We next develop a novel property testing framework for testing numerical\nproperties of a real-valued matrix $A$ more generally, which includes the\nstable rank, Schatten-$p$ norms, and SVD entropy. Specifically, we propose a\nbounded entry model, where $A$ is required to have entries bounded by $1$ in\nabsolute value. We give upper and lower bounds for a wide range of problems in\nthis model, and discuss connections to the sensing model above.\n", "versions": [{"version": "v1", "created": "Thu, 18 Oct 2018 17:24:52 GMT"}], "update_date": "2018-10-19", "authors_parsed": [["Balcan", "Maria-Florina", ""], ["Li", "Yi", ""], ["Woodruff", "David P.", ""], ["Zhang", "Hongyang", ""]]}, {"id": "1810.08178", "submitter": "Amir Erfan Eshratifar", "authors": "Amir Erfan Eshratifar, David Eigen, Massoud Pedram", "title": "Gradient Agreement as an Optimization Objective for Meta-Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper presents a novel optimization method for maximizing generalization\nover tasks in meta-learning. The goal of meta-learning is to learn a model for\nan agent adapting rapidly when presented with previously unseen tasks. Tasks\nare sampled from a specific distribution which is assumed to be similar for\nboth seen and unseen tasks. We focus on a family of meta-learning methods\nlearning initial parameters of a base model which can be fine-tuned quickly on\na new task, by few gradient steps (MAML). Our approach is based on pushing the\nparameters of the model to a direction in which tasks have more agreement upon.\nIf the gradients of a task agree with the parameters update vector, then their\ninner product will be a large positive value. As a result, given a batch of\ntasks to be optimized for, we associate a positive (negative) weight to the\nloss function of a task, if the inner product between its gradients and the\naverage of the gradients of all tasks in the batch is a positive (negative)\nvalue. Therefore, the degree of the contribution of a task to the parameter\nupdates is controlled by introducing a set of weights on the loss function of\nthe tasks. Our method can be easily integrated with the current meta-learning\nalgorithms for neural networks. Our experiments demonstrate that it yields\nmodels with better generalization compared to MAML and Reptile.\n", "versions": [{"version": "v1", "created": "Thu, 18 Oct 2018 17:38:57 GMT"}], "update_date": "2018-10-19", "authors_parsed": [["Eshratifar", "Amir Erfan", ""], ["Eigen", "David", ""], ["Pedram", "Massoud", ""]]}, {"id": "1810.08179", "submitter": "Dimitrios Giataganas", "authors": "Shotaro Shiba Funai, Dimitrios Giataganas", "title": "Thermodynamics and Feature Extraction by Machine Learning", "comments": "11 pages, double column format, 10 figures", "journal-ref": "Phys. Rev. Research 2, 033415 (2020)", "doi": "10.1103/PhysRevResearch.2.033415", "report-no": null, "categories": "cond-mat.stat-mech cond-mat.dis-nn cs.LG hep-th", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Machine learning methods are powerful in distinguishing different phases of\nmatter in an automated way and provide a new perspective on the study of\nphysical phenomena. We train a Restricted Boltzmann Machine (RBM) on data\nconstructed with spin configurations sampled from the Ising Hamiltonian at\ndifferent values of temperature and external magnetic field using Monte Carlo\nmethods. From the trained machine we obtain the flow of iterative\nreconstruction of spin state configurations to faithfully reproduce the\nobservables of the physical system. We find that the flow of the trained RBM\napproaches the spin configurations of the maximal possible specific heat which\nresemble the near criticality region of the Ising model. In the special case of\nthe vanishing magnetic field the trained RBM converges to the critical point of\nthe Renormalization Group (RG) flow of the lattice model. Our results suggest\nan alternative explanation of how the machine identifies the physical phase\ntransitions, by recognizing certain properties of the configuration like the\nmaximization of the specific heat, instead of associating directly the\nrecognition procedure with the RG flow and its fixed points. Then from the\nreconstructed data we deduce the critical exponent associated to the\nmagnetization to find satisfactory agreement with the actual physical value. We\nassume no prior knowledge about the criticality of the system and its\nHamiltonian.\n", "versions": [{"version": "v1", "created": "Thu, 18 Oct 2018 17:39:57 GMT"}], "update_date": "2020-09-23", "authors_parsed": [["Funai", "Shotaro Shiba", ""], ["Giataganas", "Dimitrios", ""]]}, {"id": "1810.08189", "submitter": "Cheng Kang Hsieh", "authors": "Cheng-Kang Hsieh, Miguel Campo, Abhinav Taliyan, Matt Nickens,\n  Mitkumar Pandya, JJ Espinoza", "title": "Convolutional Collaborative Filter Network for Video Based\n  Recommendation Systems", "comments": "8 pages, 3 figures, 1 table include ablation study. arguments /\n  results unchanged", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.IR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This analysis explores the temporal sequencing of objects in a movie trailer.\nTemporal sequencing of objects in a movie trailer (e.g., a long shot of an\nobject vs intermittent short shots) can convey information about the type of\nmovie, plot of the movie, role of the main characters, and the filmmakers\ncinematographic choices. When combined with historical customer data,\nsequencing analysis can be used to improve predictions of customer behavior.\nE.g., a customer buys tickets to a new movie and maybe the customer has seen\nmovies in the past that contained similar sequences. To explore object\nsequencing in movie trailers, we propose a video convolutional network to\ncapture actions and scenes that are predictive of customers' preferences. The\nmodel learns the specific nature of sequences for different types of objects\n(e.g., cars vs faces), and the role of sequences in predicting customer future\nbehavior. We show how such a temporal-aware model outperforms simple feature\npooling methods proposed in our previous works and, importantly, demonstrate\nthe additional model explain-ability allowed by such a model.\n", "versions": [{"version": "v1", "created": "Thu, 18 Oct 2018 17:57:58 GMT"}, {"version": "v2", "created": "Mon, 22 Oct 2018 20:43:16 GMT"}], "update_date": "2018-10-24", "authors_parsed": [["Hsieh", "Cheng-Kang", ""], ["Campo", "Miguel", ""], ["Taliyan", "Abhinav", ""], ["Nickens", "Matt", ""], ["Pandya", "Mitkumar", ""], ["Espinoza", "JJ", ""]]}, {"id": "1810.08217", "submitter": "Nils Thuerey", "authors": "Nils Thuerey, Konstantin Weissenow, Lukas Prantl, Xiangyu Hu", "title": "Deep Learning Methods for Reynolds-Averaged Navier-Stokes Simulations of\n  Airfoil Flows", "comments": "Code and data available at:\n  https://github.com/thunil/Deep-Flow-Prediction", "journal-ref": null, "doi": "10.2514/1.j058291", "report-no": null, "categories": "cs.LG physics.flu-dyn stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  With this study we investigate the accuracy of deep learning models for the\ninference of Reynolds-Averaged Navier-Stokes solutions. We focus on a\nmodernized U-net architecture, and evaluate a large number of trained neural\nnetworks with respect to their accuracy for the calculation of pressure and\nvelocity distributions. In particular, we illustrate how training data size and\nthe number of weights influence the accuracy of the solutions. With our best\nmodels we arrive at a mean relative pressure and velocity error of less than 3%\nacross a range of previously unseen airfoil shapes. In addition all source code\nis publicly available in order to ensure reproducibility and to provide a\nstarting point for researchers interested in deep learning methods for physics\nproblems. While this work focuses on RANS solutions, the neural network\narchitecture and learning setup are very generic, and applicable to a wide\nrange of PDE boundary value problems on Cartesian grids.\n", "versions": [{"version": "v1", "created": "Thu, 18 Oct 2018 18:01:01 GMT"}, {"version": "v2", "created": "Wed, 27 Feb 2019 16:52:30 GMT"}, {"version": "v3", "created": "Mon, 19 Oct 2020 10:38:43 GMT"}], "update_date": "2020-10-20", "authors_parsed": [["Thuerey", "Nils", ""], ["Weissenow", "Konstantin", ""], ["Prantl", "Lukas", ""], ["Hu", "Xiangyu", ""]]}, {"id": "1810.08223", "submitter": "Muhammad Asiful Islam", "authors": "Muhammad Asiful Islam, Ramakrishnan Srikant, Sugato Basu", "title": "Micro-Browsing Models for Search Snippets", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.IR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Click-through rate (CTR) is a key signal of relevance for search engine\nresults, both organic and sponsored. CTR of a result has two core components:\n(a) the probability of examination of a result by a user, and (b) the perceived\nrelevance of the result given that it has been examined by the user. There has\nbeen considerable work on user browsing models, to model and analyze both the\nexamination and the relevance components of CTR. In this paper, we propose a\nnovel formulation: a micro-browsing model for how users read result snippets.\nThe snippet text of a result often plays a critical role in the perceived\nrelevance of the result. We study how particular words within a line of snippet\ncan influence user behavior. We validate this new micro-browsing user model by\nconsidering the problem of predicting which snippet will yield higher CTR, and\nshow that classification accuracy is dramatically higher with our\nmicro-browsing user model. The key insight in this paper is that varying\nrelatively few words within a snippet, and even their location within a\nsnippet, can have a significant influence on the clickthrough of a snippet.\n", "versions": [{"version": "v1", "created": "Thu, 18 Oct 2018 18:13:28 GMT"}], "update_date": "2018-10-22", "authors_parsed": [["Islam", "Muhammad Asiful", ""], ["Srikant", "Ramakrishnan", ""], ["Basu", "Sugato", ""]]}, {"id": "1810.08229", "submitter": "Qiaoying Huang", "authors": "Qiaoying Huang, Dong Yang, Pengxiang Wu, Hui Qu, Jingru Yi, Dimitris\n  Metaxas", "title": "MRI Reconstruction via Cascaded Channel-wise Attention Network", "comments": "Accepted by the IEEE International Symposium on Biomedical Imaging\n  (ISBI) 2019. Code is available now", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider an MRI reconstruction problem with input of k-space data at a\nvery low undersampled rate. This can practically benefit patient due to reduced\ntime of MRI scan, but it is also challenging since quality of reconstruction\nmay be compromised. Currently, deep learning based methods dominate MRI\nreconstruction over traditional approaches such as Compressed Sensing, but they\nrarely show satisfactory performance in the case of low undersampled k-space\ndata. One explanation is that these methods treat channel-wise features\nequally, which results in degraded representation ability of the neural\nnetwork. To solve this problem, we propose a new model called MRI Cascaded\nChannel-wise Attention Network (MICCAN), highlighted by three components: (i) a\nvariant of U-net with Channel-wise Attention (UCA) module, (ii) a long skip\nconnection and (iii) a combined loss. Our model is able to attend to salient\ninformation by filtering irrelevant features and also concentrate on\nhigh-frequency information by enforcing low-frequency information bypassed to\nthe final output. We conduct both quantitative evaluation and qualitative\nanalysis of our method on a cardiac dataset. The experiment shows that our\nmethod achieves very promising results in terms of three common metrics on the\nMRI reconstruction with low undersampled k-space data.\n", "versions": [{"version": "v1", "created": "Thu, 18 Oct 2018 18:37:37 GMT"}, {"version": "v2", "created": "Tue, 9 Apr 2019 21:11:26 GMT"}], "update_date": "2019-04-11", "authors_parsed": [["Huang", "Qiaoying", ""], ["Yang", "Dong", ""], ["Wu", "Pengxiang", ""], ["Qu", "Hui", ""], ["Yi", "Jingru", ""], ["Metaxas", "Dimitris", ""]]}, {"id": "1810.08280", "submitter": "Octavian Suciu", "authors": "Octavian Suciu, Scott E. Coull, Jeffrey Johns", "title": "Exploring Adversarial Examples in Malware Detection", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The convolutional neural network (CNN) architecture is increasingly being\napplied to new domains, such as malware detection, where it is able to learn\nmalicious behavior from raw bytes extracted from executables. These\narchitectures reach impressive performance with no feature engineering effort\ninvolved, but their robustness against active attackers is yet to be\nunderstood. Such malware detectors could face a new attack vector in the form\nof adversarial interference with the classification model. Existing evasion\nattacks intended to cause misclassification on test-time instances, which have\nbeen extensively studied for image classifiers, are not applicable because of\nthe input semantics that prevents arbitrary changes to the binaries. This paper\nexplores the area of adversarial examples for malware detection. By training an\nexisting model on a production-scale dataset, we show that some previous\nattacks are less effective than initially reported, while simultaneously\nhighlighting architectural weaknesses that facilitate new attack strategies for\nmalware classification. Finally, we explore how generalizable different attack\nstrategies are, the trade-offs when aiming to increase their effectiveness, and\nthe transferability of single-step attacks.\n", "versions": [{"version": "v1", "created": "Thu, 18 Oct 2018 21:26:27 GMT"}, {"version": "v2", "created": "Wed, 20 Mar 2019 14:23:22 GMT"}, {"version": "v3", "created": "Sat, 13 Apr 2019 23:21:45 GMT"}], "update_date": "2019-04-16", "authors_parsed": [["Suciu", "Octavian", ""], ["Coull", "Scott E.", ""], ["Johns", "Jeffrey", ""]]}, {"id": "1810.08303", "submitter": "Corina P\\u{a}s\\u{a}reanu", "authors": "Corina S. Pasareanu, Divya Gopinath, Huafeng Yu", "title": "Compositional Verification for Autonomous Systems with Deep Learning\n  Components", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  As autonomy becomes prevalent in many applications, ranging from\nrecommendation systems to fully autonomous vehicles, there is an increased need\nto provide safety guarantees for such systems. The problem is difficult, as\nthese are large, complex systems which operate in uncertain environments,\nrequiring data-driven machine-learning components. However, learning techniques\nsuch as Deep Neural Networks, widely used today, are inherently unpredictable\nand lack the theoretical foundations to provide strong assurance guarantees. We\npresent a compositional approach for the scalable, formal verification of\nautonomous systems that contain Deep Neural Network components. The approach\nuses assume-guarantee reasoning whereby {\\em contracts}, encoding the\ninput-output behavior of individual components, allow the designer to model and\nincorporate the behavior of the learning-enabled components working\nside-by-side with the other components. We illustrate the approach on an\nexample taken from the autonomous vehicles domain.\n", "versions": [{"version": "v1", "created": "Thu, 18 Oct 2018 23:16:23 GMT"}], "update_date": "2018-10-22", "authors_parsed": [["Pasareanu", "Corina S.", ""], ["Gopinath", "Divya", ""], ["Yu", "Huafeng", ""]]}, {"id": "1810.08305", "submitter": "Milan Cvitkovic", "authors": "Milan Cvitkovic, Badal Singh, Anima Anandkumar", "title": "Open Vocabulary Learning on Source Code with a Graph-Structured Cache", "comments": "Published in the International Conference on Machine Learning (ICML\n  2019), 13 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Machine learning models that take computer program source code as input\ntypically use Natural Language Processing (NLP) techniques. However, a major\nchallenge is that code is written using an open, rapidly changing vocabulary\ndue to, e.g., the coinage of new variable and method names. Reasoning over such\na vocabulary is not something for which most NLP methods are designed. We\nintroduce a Graph-Structured Cache to address this problem; this cache contains\na node for each new word the model encounters with edges connecting each word\nto its occurrences in the code. We find that combining this graph-structured\ncache strategy with recent Graph-Neural-Network-based models for supervised\nlearning on code improves the models' performance on a code completion task and\na variable naming task --- with over $100\\%$ relative improvement on the latter\n--- at the cost of a moderate increase in computation time.\n", "versions": [{"version": "v1", "created": "Thu, 18 Oct 2018 23:33:11 GMT"}, {"version": "v2", "created": "Sun, 19 May 2019 22:44:00 GMT"}], "update_date": "2019-05-21", "authors_parsed": [["Cvitkovic", "Milan", ""], ["Singh", "Badal", ""], ["Anandkumar", "Anima", ""]]}, {"id": "1810.08309", "submitter": "Ian Davis", "authors": "Ian J Davis", "title": "Unsupervised Anomalous Data Space Specification", "comments": "18 Pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Computer algorithms are written with the intent that when run they perform a\nuseful function. Typically any information obtained is unknown until the\nalgorithm is run. However, if the behavior of an algorithm can be fully\ndescribed by precomputing just once how this algorithm will respond when\nexecuted on any input, this precomputed result provides a complete\nspecification for all solutions in the problem domain. We apply this idea to a\nprevious anomaly detection algorithm, and in doing so transform it from one\nthat merely detects individual anomalies when asked to discover potentially\nanomalous values, into an algorithm also capable of generating a complete\nspecification for those values it would deem to be anomalous. This\nspecification is derived by examining no more than a small training data, can\nbe obtained in very small constant time, and is inherently far more useful than\nresults obtained by repeated execution of this tool. For example, armed with\nsuch a specification one can ask how close an anomaly is to being deemed\nnormal, and can validate this answer not by exhaustively testing the algorithm\nbut by examining if the specification so generated is indeed correct. This\npowerful idea can be applied to any algorithm whose runtime behavior can be\nrecovered from its construction and so has wide applicability.\n", "versions": [{"version": "v1", "created": "Thu, 18 Oct 2018 23:43:21 GMT"}], "update_date": "2018-10-22", "authors_parsed": [["Davis", "Ian J", ""]]}, {"id": "1810.08313", "submitter": "Jianyu Wang", "authors": "Jianyu Wang, Gauri Joshi", "title": "Adaptive Communication Strategies to Achieve the Best Error-Runtime\n  Trade-off in Local-Update SGD", "comments": "Accepted to SysML 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.DC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Large-scale machine learning training, in particular distributed stochastic\ngradient descent, needs to be robust to inherent system variability such as\nnode straggling and random communication delays. This work considers a\ndistributed training framework where each worker node is allowed to perform\nlocal model updates and the resulting models are averaged periodically. We\nanalyze the true speed of error convergence with respect to wall-clock time\n(instead of the number of iterations), and analyze how it is affected by the\nfrequency of averaging. The main contribution is the design of AdaComm, an\nadaptive communication strategy that starts with infrequent averaging to save\ncommunication delay and improve convergence speed, and then increases the\ncommunication frequency in order to achieve a low error floor. Rigorous\nexperiments on training deep neural networks show that AdaComm can take $3\n\\times$ less time than fully synchronous SGD, and still reach the same final\ntraining loss.\n", "versions": [{"version": "v1", "created": "Fri, 19 Oct 2018 00:04:05 GMT"}, {"version": "v2", "created": "Thu, 7 Mar 2019 16:45:02 GMT"}], "update_date": "2019-03-08", "authors_parsed": [["Wang", "Jianyu", ""], ["Joshi", "Gauri", ""]]}, {"id": "1810.08322", "submitter": "Dae Hoon Park", "authors": "Chiu Man Ho, Dae Hoon Park, Wei Yang, Yi Chang", "title": "Sequenced-Replacement Sampling for Deep Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose sequenced-replacement sampling (SRS) for training deep neural\nnetworks. The basic idea is to assign a fixed sequence index to each sample in\nthe dataset. Once a mini-batch is randomly drawn in each training iteration, we\nrefill the original dataset by successively adding samples according to their\nsequence index. Thus we carry out replacement sampling but in a batched and\nsequenced way. In a sense, SRS could be viewed as a way of performing\n\"mini-batch augmentation\". It is particularly useful for a task where we have a\nrelatively small images-per-class such as CIFAR-100. Together with a longer\nperiod of initial large learning rate, it significantly improves the\nclassification accuracy in CIFAR-100 over the current state-of-the-art results.\nOur experiments indicate that training deeper networks with SRS is less prone\nto over-fitting. In the best case, we achieve an error rate as low as 10.10%.\n", "versions": [{"version": "v1", "created": "Fri, 19 Oct 2018 00:55:47 GMT"}], "update_date": "2018-10-22", "authors_parsed": [["Ho", "Chiu Man", ""], ["Park", "Dae Hoon", ""], ["Yang", "Wei", ""], ["Chang", "Yi", ""]]}, {"id": "1810.08323", "submitter": "Saiprasad Ravishankar", "authors": "Saiprasad Ravishankar and Brendt Wohlberg", "title": "Learning Multi-Layer Transform Models", "comments": "In Proceedings of the Annual Allerton Conference on Communication,\n  Control, and Computing, 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Learned data models based on sparsity are widely used in signal processing\nand imaging applications. A variety of methods for learning synthesis\ndictionaries, sparsifying transforms, etc., have been proposed in recent years,\noften imposing useful structures or properties on the models. In this work, we\nfocus on sparsifying transform learning, which enjoys a number of advantages.\nWe consider multi-layer or nested extensions of the transform model, and\npropose efficient learning algorithms. Numerical experiments with image data\nillustrate the behavior of the multi-layer transform learning algorithm and its\nusefulness for image denoising. Multi-layer models provide better denoising\nquality than single layer schemes.\n", "versions": [{"version": "v1", "created": "Fri, 19 Oct 2018 00:56:42 GMT"}], "update_date": "2018-10-22", "authors_parsed": [["Ravishankar", "Saiprasad", ""], ["Wohlberg", "Brendt", ""]]}, {"id": "1810.08326", "submitter": "Zhiwu Lu", "authors": "An Zhao, Mingyu Ding, Jiechao Guan, Zhiwu Lu, Tao Xiang, and Ji-Rong\n  Wen", "title": "Domain-Invariant Projection Learning for Zero-Shot Recognition", "comments": "Accepted to NIPS 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Zero-shot learning (ZSL) aims to recognize unseen object classes without any\ntraining samples, which can be regarded as a form of transfer learning from\nseen classes to unseen ones. This is made possible by learning a projection\nbetween a feature space and a semantic space (e.g. attribute space). Key to ZSL\nis thus to learn a projection function that is robust against the often large\ndomain gap between the seen and unseen classes. In this paper, we propose a\nnovel ZSL model termed domain-invariant projection learning (DIPL). Our model\nhas two novel components: (1) A domain-invariant feature self-reconstruction\ntask is introduced to the seen/unseen class data, resulting in a simple linear\nformulation that casts ZSL into a min-min optimization problem. Solving the\nproblem is non-trivial, and a novel iterative algorithm is formulated as the\nsolver, with rigorous theoretic algorithm analysis provided. (2) To further\nalign the two domains via the learned projection, shared semantic structure\namong seen and unseen classes is explored via forming superclasses in the\nsemantic space. Extensive experiments show that our model outperforms the\nstate-of-the-art alternatives by significant margins.\n", "versions": [{"version": "v1", "created": "Fri, 19 Oct 2018 01:08:05 GMT"}], "update_date": "2018-10-22", "authors_parsed": [["Zhao", "An", ""], ["Ding", "Mingyu", ""], ["Guan", "Jiechao", ""], ["Lu", "Zhiwu", ""], ["Xiang", "Tao", ""], ["Wen", "Ji-Rong", ""]]}, {"id": "1810.08329", "submitter": "Zhiwu Lu", "authors": "Aoxue Li, Zhiwu Lu, Jiechao Guan, Tao Xiang, Liwei Wang, and Ji-Rong\n  Wen", "title": "Transferrable Feature and Projection Learning with Class Hierarchy for\n  Zero-Shot Learning", "comments": "Submitted to IJCV", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Zero-shot learning (ZSL) aims to transfer knowledge from seen classes to\nunseen ones so that the latter can be recognised without any training samples.\nThis is made possible by learning a projection function between a feature space\nand a semantic space (e.g. attribute space). Considering the seen and unseen\nclasses as two domains, a big domain gap often exists which challenges ZSL.\nInspired by the fact that an unseen class is not exactly `unseen' if it belongs\nto the same superclass as a seen class, we propose a novel inductive ZSL model\nthat leverages superclasses as the bridge between seen and unseen classes to\nnarrow the domain gap. Specifically, we first build a class hierarchy of\nmultiple superclass layers and a single class layer, where the superclasses are\nautomatically generated by data-driven clustering over the semantic\nrepresentations of all seen and unseen class names. We then exploit the\nsuperclasses from the class hierarchy to tackle the domain gap challenge in two\naspects: deep feature learning and projection function learning. First, to\nnarrow the domain gap in the feature space, we integrate a recurrent neural\nnetwork (RNN) defined with the superclasses into a convolutional neural network\n(CNN), in order to enforce the superclass hierarchy. Second, to further learn a\ntransferrable projection function for ZSL, a novel projection function learning\nmethod is proposed by exploiting the superclasses to align the two domains.\nImportantly, our transferrable feature and projection learning methods can be\neasily extended to a closely related task -- few-shot learning (FSL). Extensive\nexperiments show that the proposed model significantly outperforms the\nstate-of-the-art alternatives in both ZSL and FSL tasks.\n", "versions": [{"version": "v1", "created": "Fri, 19 Oct 2018 01:21:08 GMT"}], "update_date": "2018-10-22", "authors_parsed": [["Li", "Aoxue", ""], ["Lu", "Zhiwu", ""], ["Guan", "Jiechao", ""], ["Xiang", "Tao", ""], ["Wang", "Liwei", ""], ["Wen", "Ji-Rong", ""]]}, {"id": "1810.08332", "submitter": "Zhiwu Lu", "authors": "Zhiwu Lu, Jiechao Guan, Aoxue Li, Tao Xiang, An Zhao, and Ji-Rong Wen", "title": "Zero and Few Shot Learning with Semantic Feature Synthesis and\n  Competitive Learning", "comments": "Submitted to IEEE TPAMI", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Zero-shot learning (ZSL) is made possible by learning a projection function\nbetween a feature space and a semantic space (e.g.,~an attribute space). Key to\nZSL is thus to learn a projection that is robust against the often large domain\ngap between the seen and unseen class domains. In this work, this is achieved\nby unseen class data synthesis and robust projection function learning.\nSpecifically, a novel semantic data synthesis strategy is proposed, by which\nsemantic class prototypes (e.g., attribute vectors) are used to simply perturb\nseen class data for generating unseen class ones. As in any data\nsynthesis/hallucination approach, there are ambiguities and uncertainties on\nhow well the synthesised data can capture the targeted unseen class data\ndistribution. To cope with this, the second contribution of this work is a\nnovel projection learning model termed competitive bidirectional projection\nlearning (BPL) designed to best utilise the ambiguous synthesised data.\nSpecifically, we assume that each synthesised data point can belong to any\nunseen class; and the most likely two class candidates are exploited to learn a\nrobust projection function in a competitive fashion. As a third contribution,\nwe show that the proposed ZSL model can be easily extended to few-shot learning\n(FSL) by again exploiting semantic (class prototype guided) feature synthesis\nand competitive BPL. Extensive experiments show that our model achieves the\nstate-of-the-art results on both problems.\n", "versions": [{"version": "v1", "created": "Fri, 19 Oct 2018 01:52:03 GMT"}], "update_date": "2018-10-22", "authors_parsed": [["Lu", "Zhiwu", ""], ["Guan", "Jiechao", ""], ["Li", "Aoxue", ""], ["Xiang", "Tao", ""], ["Zhao", "An", ""], ["Wen", "Ji-Rong", ""]]}, {"id": "1810.08351", "submitter": "Russell Tsuchida B.E.", "authors": "Russell Tsuchida, Fred Roosta, Marcus Gallagher", "title": "Exchangeability and Kernel Invariance in Trained MLPs", "comments": "26 pages, 16 Figures; Changed Fred (Farbod) Roosta to Fred Roosta in\n  Metadata", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In the analysis of machine learning models, it is often convenient to assume\nthat the parameters are IID. This assumption is not satisfied when the\nparameters are updated through training processes such as SGD. A relaxation of\nthe IID condition is a probabilistic symmetry known as exchangeability. We show\nthe sense in which the weights in MLPs are exchangeable. This yields the result\nthat in certain instances, the layer-wise kernel of fully-connected layers\nremains approximately constant during training. We identify a sharp change in\nthe macroscopic behavior of networks as the covariance between weights changes\nfrom zero.\n", "versions": [{"version": "v1", "created": "Fri, 19 Oct 2018 04:09:09 GMT"}, {"version": "v2", "created": "Sat, 27 Oct 2018 11:18:27 GMT"}], "update_date": "2018-10-30", "authors_parsed": [["Tsuchida", "Russell", ""], ["Roosta", "Fred", ""], ["Gallagher", "Marcus", ""]]}, {"id": "1810.08359", "submitter": "Zhongyi Hu", "authors": "Zhongyi Hu, Raymond Chiong, Ilung Pranata, Yukun Bao, Yuqing Lin", "title": "Malicious Web Domain Identification using Online Credibility and\n  Performance Data by Considering the Class Imbalance Issue", "comments": "20 pages", "journal-ref": "Industrial Management & Data Systems, 2018", "doi": "10.1108/IMDS-02-2018-0072", "report-no": null, "categories": "cs.LG cs.CR cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Purpose: Malicious web domain identification is of significant importance to\nthe security protection of Internet users. With online credibility and\nperformance data, this paper aims to investigate the use of machine learning\ntech-niques for malicious web domain identification by considering the class\nimbalance issue (i.e., there are more benign web domains than malicious ones).\nDesign/methodology/approach: We propose an integrated resampling approach to\nhandle class imbalance by combining the Synthetic Minority Over-sampling\nTEchnique (SMOTE) and Particle Swarm Optimisation (PSO), a population-based\nmeta-heuristic algorithm. We use the SMOTE for over-sampling and PSO for\nunder-sampling. Findings: By applying eight well-known machine learning\nclassifiers, the proposed integrated resampling approach is comprehensively\nexamined using several imbalanced web domain datasets with different imbalance\nratios. Com-pared to five other well-known resampling approaches, experimental\nresults confirm that the proposed approach is highly effective. Practical\nimplications: This study not only inspires the practical use of online\ncredibility and performance data for identifying malicious web domains, but\nalso provides an effective resampling approach for handling the class\nimbal-ance issue in the area of malicious web domain identification.\nOriginality/value: Online credibility and performance data is applied to build\nmalicious web domain identification models using machine learning techniques.\nAn integrated resampling approach is proposed to address the class im-balance\nissue. The performance of the proposed approach is confirmed based on\nreal-world datasets with different imbalance ratios.\n", "versions": [{"version": "v1", "created": "Fri, 19 Oct 2018 05:54:40 GMT"}], "update_date": "2018-10-22", "authors_parsed": [["Hu", "Zhongyi", ""], ["Chiong", "Raymond", ""], ["Pranata", "Ilung", ""], ["Bao", "Yukun", ""], ["Lin", "Yuqing", ""]]}, {"id": "1810.08363", "submitter": "Adi Hayat", "authors": "Adi Hayat, Mark Kliger, Shachar Fleishman, Daniel Cohen-Or", "title": "Generative Low-Shot Network Expansion", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Conventional deep learning classifiers are static in the sense that they are\ntrained on a predefined set of classes and learning to classify a novel class\ntypically requires re-training. In this work, we address the problem of\nLow-Shot network expansion learning. We introduce a learning framework which\nenables expanding a pre-trained (base) deep network to classify novel classes\nwhen the number of examples for the novel classes is particularly small. We\npresent a simple yet powerful hard distillation method where the base network\nis augmented with additional weights to classify the novel classes, while\nkeeping the weights of the base network unchanged. We show that since only a\nsmall number of weights needs to be trained, the hard distillation excels in\nlow-shot training scenarios. Furthermore, hard distillation avoids detriment to\nclassification performance on the base classes. Finally, we show that low-shot\nnetwork expansion can be done with a very small memory footprint by using a\ncompact generative model of the base classes training data with only a\nnegligible degradation relative to learning with the full training set.\n", "versions": [{"version": "v1", "created": "Fri, 19 Oct 2018 06:25:00 GMT"}], "update_date": "2018-10-22", "authors_parsed": [["Hayat", "Adi", ""], ["Kliger", "Mark", ""], ["Fleishman", "Shachar", ""], ["Cohen-Or", "Daniel", ""]]}, {"id": "1810.08379", "submitter": "Haiyue Song", "authors": "Haiyue Song, Chengwen Xu, Qiang Xu, Zhuoran Song, Naifeng Jing,\n  Xiaoyao Liang, Li Jiang", "title": "Invocation-driven Neural Approximate Computing with a\n  Multiclass-Classifier and Multiple Approximators", "comments": "Accepted by ICCAD 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Neural approximate computing gains enormous energy-efficiency at the cost of\ntolerable quality-loss. A neural approximator can map the input data to output\nwhile a classifier determines whether the input data are safe to approximate\nwith quality guarantee. However, existing works cannot maximize the invocation\nof the approximator, resulting in limited speedup and energy saving. By\nexploring the mapping space of those target functions, in this paper, we\nobserve a nonuniform distribution of the approximation error incurred by the\nsame approximator. We thus propose a novel approximate computing architecture\nwith a Multiclass-Classifier and Multiple Approximators (MCMA). These\napproximators have identical network topologies and thus can share the same\nhardware resource in a neural processing unit(NPU) clip. In the runtime, MCMA\ncan swap in the invoked approximator by merely shipping the synapse weights\nfrom the on-chip memory to the buffers near MAC within a cycle. We also propose\nefficient co-training methods for such MCMA architecture. Experimental results\nshow a more substantial invocation of MCMA as well as the gain of\nenergy-efficiency.\n", "versions": [{"version": "v1", "created": "Fri, 19 Oct 2018 07:37:31 GMT"}], "update_date": "2018-10-22", "authors_parsed": [["Song", "Haiyue", ""], ["Xu", "Chengwen", ""], ["Xu", "Qiang", ""], ["Song", "Zhuoran", ""], ["Jing", "Naifeng", ""], ["Liang", "Xiaoyao", ""], ["Jiang", "Li", ""]]}, {"id": "1810.08403", "submitter": "Lingxiao Ma", "authors": "Lingxiao Ma, Zhi Yang, Youshan Miao, Jilong Xue, Ming Wu, Lidong Zhou,\n  Yafei Dai", "title": "Towards Efficient Large-Scale Graph Neural Network Computing", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent deep learning models have moved beyond low-dimensional regular grids\nsuch as image, video, and speech, to high-dimensional graph-structured data,\nsuch as social networks, brain connections, and knowledge graphs. This\nevolution has led to large graph-based irregular and sparse models that go\nbeyond what existing deep learning frameworks are designed for. Further, these\nmodels are not easily amenable to efficient, at scale, acceleration on parallel\nhardwares (e.g. GPUs). We introduce NGra, the first parallel processing\nframework for graph-based deep neural networks (GNNs). NGra presents a new\nSAGA-NN model for expressing deep neural networks as vertex programs with each\nlayer in well-defined (Scatter, ApplyEdge, Gather, ApplyVertex) graph operation\nstages. This model not only allows GNNs to be expressed intuitively, but also\nfacilitates the mapping to an efficient dataflow representation. NGra addresses\nthe scalability challenge transparently through automatic graph partitioning\nand chunk-based stream processing out of GPU core or over multiple GPUs, which\ncarefully considers data locality, data movement, and overlapping of parallel\nprocessing and data movement. NGra further achieves efficiency through highly\noptimized Scatter/Gather operators on GPUs despite its sparsity. Our evaluation\nshows that NGra scales to large real graphs that none of the existing\nframeworks can handle directly, while achieving up to about 4 times speedup\neven at small scales over the multiple-baseline design on TensorFlow.\n", "versions": [{"version": "v1", "created": "Fri, 19 Oct 2018 08:50:58 GMT"}], "update_date": "2018-10-22", "authors_parsed": [["Ma", "Lingxiao", ""], ["Yang", "Zhi", ""], ["Miao", "Youshan", ""], ["Xue", "Jilong", ""], ["Wu", "Ming", ""], ["Zhou", "Lidong", ""], ["Dai", "Yafei", ""]]}, {"id": "1810.08452", "submitter": "Rodrigo Caye Daudt", "authors": "Rodrigo Caye Daudt, Bertrand Le Saux, Alexandre Boulch, Yann Gousseau", "title": "Multitask Learning for Large-scale Semantic Change Detection", "comments": "Preprint submitted to Computer Vision and Image Understanding", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Change detection is one of the main problems in remote sensing, and is\nessential to the accurate processing and understanding of the large scale Earth\nobservation data available through programs such as Sentinel and Landsat. Most\nof the recently proposed change detection methods bring deep learning to this\ncontext, but openly available change detection datasets are still very scarce,\nwhich limits the methods that can be proposed and tested. In this paper we\npresent the first large scale high resolution semantic change detection (HRSCD)\ndataset, which enables the usage of deep learning methods for semantic change\ndetection. The dataset contains coregistered RGB image pairs, pixel-wise change\ninformation and land cover information. We then propose several methods using\nfully convolutional neural networks to perform semantic change detection. Most\nnotably, we present a network architecture that performs change detection and\nland cover mapping simultaneously, while using the predicted land cover\ninformation to help to predict changes. We also describe a sequential training\nscheme that allows this network to be trained without setting a hyperparameter\nthat balances different loss functions and achieves the best overall results.\n", "versions": [{"version": "v1", "created": "Fri, 19 Oct 2018 12:01:51 GMT"}, {"version": "v2", "created": "Wed, 28 Aug 2019 15:29:38 GMT"}], "update_date": "2019-08-29", "authors_parsed": [["Daudt", "Rodrigo Caye", ""], ["Saux", "Bertrand Le", ""], ["Boulch", "Alexandre", ""], ["Gousseau", "Yann", ""]]}, {"id": "1810.08462", "submitter": "Rodrigo Caye Daudt", "authors": "Rodrigo Caye Daudt, Bertrand Le Saux, Alexandre Boulch", "title": "Fully Convolutional Siamese Networks for Change Detection", "comments": "To appear inProc. ICIP 2018, October 07-10, 2018, Athens, Greece", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  This paper presents three fully convolutional neural network architectures\nwhich perform change detection using a pair of coregistered images. Most\nnotably, we propose two Siamese extensions of fully convolutional networks\nwhich use heuristics about the current problem to achieve the best results in\nour tests on two open change detection datasets, using both RGB and\nmultispectral images. We show that our system is able to learn from scratch\nusing annotated change detection images. Our architectures achieve better\nperformance than previously proposed methods, while being at least 500 times\nfaster than related systems. This work is a step towards efficient processing\nof data from large scale Earth observation systems such as Copernicus or\nLandsat.\n", "versions": [{"version": "v1", "created": "Fri, 19 Oct 2018 12:27:49 GMT"}], "update_date": "2018-10-22", "authors_parsed": [["Daudt", "Rodrigo Caye", ""], ["Saux", "Bertrand Le", ""], ["Boulch", "Alexandre", ""]]}, {"id": "1810.08468", "submitter": "Rodrigo Caye Daudt", "authors": "Rodrigo Caye Daudt, Bertrand Le Saux, Alexandre Boulch, Yann Gousseau", "title": "Urban Change Detection for Multispectral Earth Observation Using\n  Convolutional Neural Networks", "comments": "To appear inProc. IGARSS 2018, July 22-27, 2018, Valencia, Spain", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  The Copernicus Sentinel-2 program now provides multispectral images at a\nglobal scale with a high revisit rate. In this paper we explore the usage of\nconvolutional neural networks for urban change detection using such\nmultispectral images. We first present the new change detection dataset that\nwas used for training the proposed networks, which will be openly available to\nserve as a benchmark. The Onera Satellite Change Detection (OSCD) dataset is\ncomposed of pairs of multispectral aerial images, and the changes were manually\nannotated at pixel level. We then propose two architectures to detect changes,\nSiamese and Early Fusion, and compare the impact of using different numbers of\nspectral channels as inputs. These architectures are trained from scratch using\nthe provided dataset.\n", "versions": [{"version": "v1", "created": "Fri, 19 Oct 2018 12:40:28 GMT"}], "update_date": "2018-10-22", "authors_parsed": [["Daudt", "Rodrigo Caye", ""], ["Saux", "Bertrand Le", ""], ["Boulch", "Alexandre", ""], ["Gousseau", "Yann", ""]]}, {"id": "1810.08498", "submitter": "Roland Molontay", "authors": "Marcell Nagy and Roland Molontay", "title": "Data-driven Analysis of Complex Networks and their Model-generated\n  Counterparts", "comments": "14 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SI cs.DM cs.LG physics.data-an physics.soc-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Data-driven analysis of complex networks has been in the focus of research\nfor decades. An important question is to discover the relation between various\nnetwork characteristics in real-world networks and how these relationships vary\nacross network domains. A related research question is to study how well the\nnetwork models can capture the observed relations between the graph metrics. In\nthis paper, we apply statistical and machine learning techniques to answer the\naforementioned questions. We study 400 real-world networks along with 2400\nnetworks generated by five frequently used network models with previously\nfitted parameters to make the generated graphs as similar to the real network\nas possible. We find that the correlation profiles of the structural measures\nsignificantly differ across network domains and the domain can be efficiently\ndetermined using a small selection of graph metrics. The goodness-of-fit of the\nnetwork models and the best performing models themselves highly depend on the\ndomains. Using machine learning techniques, it turned out to be relatively easy\nto decide if a network is real or model-generated. We also investigate what\nstructural properties make it possible to achieve a good accuracy, i.e. what\nfeatures the network models cannot capture.\n", "versions": [{"version": "v1", "created": "Fri, 19 Oct 2018 13:41:09 GMT"}, {"version": "v2", "created": "Wed, 24 Oct 2018 13:54:12 GMT"}, {"version": "v3", "created": "Thu, 25 Oct 2018 09:31:55 GMT"}], "update_date": "2018-10-26", "authors_parsed": [["Nagy", "Marcell", ""], ["Molontay", "Roland", ""]]}, {"id": "1810.08509", "submitter": "Shun Zhang", "authors": "Shun Zhang, Laixiang Liu, Zhili Chen, Hong Zhong", "title": "Probabilistic Matrix Factorization with Personalized Differential\n  Privacy", "comments": "24 pages, 12 figures, 4 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Probabilistic matrix factorization (PMF) plays a crucial role in\nrecommendation systems. It requires a large amount of user data (such as user\nshopping records and movie ratings) to predict personal preferences, and\nthereby provides users high-quality recommendation services, which expose the\nrisk of leakage of user privacy. Differential privacy, as a provable privacy\nprotection framework, has been applied widely to recommendation systems. It is\ncommon that different individuals have different levels of privacy requirements\non items. However, traditional differential privacy can only provide a uniform\nlevel of privacy protection for all users.\n  In this paper, we mainly propose a probabilistic matrix factorization\nrecommendation scheme with personalized differential privacy (PDP-PMF). It aims\nto meet users' privacy requirements specified at the item-level instead of\ngiving the same level of privacy guarantees for all. We then develop a modified\nsampling mechanism (with bounded differential privacy) for achieving PDP. We\nalso perform a theoretical analysis of the PDP-PMF scheme and demonstrate the\nprivacy of the PDP-PMF scheme. In addition, we implement the probabilistic\nmatrix factorization schemes both with traditional and with personalized\ndifferential privacy (DP-PMF, PDP-PMF) and compare them through a series of\nexperiments. The results show that the PDP-PMF scheme performs well on\nprotecting the privacy of each user and its recommendation quality is much\nbetter than the DP-PMF scheme.\n", "versions": [{"version": "v1", "created": "Fri, 19 Oct 2018 14:03:03 GMT"}], "update_date": "2018-10-22", "authors_parsed": [["Zhang", "Shun", ""], ["Liu", "Laixiang", ""], ["Chen", "Zhili", ""], ["Zhong", "Hong", ""]]}, {"id": "1810.08515", "submitter": "Mark Schutera", "authors": "Mark Schutera, Niklas Goby, Dirk Neumann, Markus Reischl", "title": "Transfer Learning versus Multi-agent Learning regarding Distributed\n  Decision-Making in Highway Traffic", "comments": "Proc. of the 10th International Workshop on Agents in Traffic and\n  Transportation (ATT 2018), co-located with ECAI/IJCAI, AAMAS and ICML 2018\n  conferences (FAIM 2018)", "journal-ref": "CEUR Workshop Proceedings 2018", "doi": null, "report-no": "CEUR-WS.org/Vol-2129", "categories": "cs.LG cs.AI cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Transportation and traffic are currently undergoing a rapid increase in terms\nof both scale and complexity. At the same time, an increasing share of traffic\nparticipants are being transformed into agents driven or supported by\nartificial intelligence resulting in mixed-intelligence traffic. This work\nexplores the implications of distributed decision-making in mixed-intelligence\ntraffic. The investigations are carried out on the basis of an online-simulated\nhighway scenario, namely the MIT \\emph{DeepTraffic} simulation. In the first\nstep traffic agents are trained by means of a deep reinforcement learning\napproach, being deployed inside an elitist evolutionary algorithm for\nhyperparameter search. The resulting architectures and training parameters are\nthen utilized in order to either train a single autonomous traffic agent and\ntransfer the learned weights onto a multi-agent scenario or else to conduct\nmulti-agent learning directly. Both learning strategies are evaluated on\ndifferent ratios of mixed-intelligence traffic. The strategies are assessed\naccording to the average speed of all agents driven by artificial intelligence.\nTraffic patterns that provoke a reduction in traffic flow are analyzed with\nrespect to the different strategies.\n", "versions": [{"version": "v1", "created": "Fri, 19 Oct 2018 14:16:25 GMT"}], "update_date": "2018-10-24", "authors_parsed": [["Schutera", "Mark", ""], ["Goby", "Niklas", ""], ["Neumann", "Dirk", ""], ["Reischl", "Markus", ""]]}, {"id": "1810.08537", "submitter": "Leo Duan", "authors": "Leo L Duan, David B Dunson", "title": "Bayesian Distance Clustering", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Model-based clustering is widely-used in a variety of application areas.\nHowever, fundamental concerns remain about robustness. In particular, results\ncan be sensitive to the choice of kernel representing the within-cluster data\ndensity. Leveraging on properties of pairwise differences between data points,\nwe propose a class of Bayesian distance clustering methods, which rely on\nmodeling the likelihood of the pairwise distances in place of the original\ndata. Although some information in the data is discarded, we gain substantial\nrobustness to modeling assumptions. The proposed approach represents an\nappealing middle ground between distance- and model-based clustering, drawing\nadvantages from each of these canonical approaches. We illustrate dramatic\ngains in the ability to infer clusters that are not well represented by the\nusual choices of kernel. A simulation study is included to assess performance\nrelative to competitors, and we apply the approach to clustering of brain\ngenome expression data.\n  Keywords: Distance-based clustering; Mixture model; Model-based clustering;\nModel misspecification; Pairwise distance matrix; Partial likelihood;\nRobustness.\n", "versions": [{"version": "v1", "created": "Fri, 19 Oct 2018 15:09:08 GMT"}, {"version": "v2", "created": "Tue, 25 Jun 2019 19:48:35 GMT"}], "update_date": "2019-06-27", "authors_parsed": [["Duan", "Leo L", ""], ["Dunson", "David B", ""]]}, {"id": "1810.08552", "submitter": "Ravi Patel", "authors": "Ravi G. Patel and Olivier Desjardins", "title": "Nonlinear integro-differential operator regression with neural networks", "comments": "5 pages, 3 figures, preprint submitted to the Journal of\n  Computational Physics", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG physics.comp-ph physics.data-an stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This note introduces a regression technique for finding a class of nonlinear\nintegro-differential operators from data. The method parametrizes the spatial\noperator with neural networks and Fourier transforms such that it can fit a\nclass of nonlinear operators without needing a library of a priori selected\noperators. We verify that this method can recover the spatial operators in the\nfractional heat equation and the Kuramoto-Sivashinsky equation from numerical\nsolutions of the equations.\n", "versions": [{"version": "v1", "created": "Fri, 19 Oct 2018 15:33:59 GMT"}], "update_date": "2018-10-22", "authors_parsed": [["Patel", "Ravi G.", ""], ["Desjardins", "Olivier", ""]]}, {"id": "1810.08553", "submitter": "Santiago Silva", "authors": "Santiago Silva, Boris Gutman, Eduardo Romero, Paul M Thompson, Andre\n  Altmann, Marco Lorenzi", "title": "Federated Learning in Distributed Medical Databases: Meta-Analysis of\n  Large-Scale Subcortical Brain Data", "comments": "Federated learning, distributed databases, PCA, SVD, meta-analysis,\n  brain disease", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG q-bio.NC q-bio.QM", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  At this moment, databanks worldwide contain brain images of previously\nunimaginable numbers. Combined with developments in data science, these massive\ndata provide the potential to better understand the genetic underpinnings of\nbrain diseases. However, different datasets, which are stored at different\ninstitutions, cannot always be shared directly due to privacy and legal\nconcerns, thus limiting the full exploitation of big data in the study of brain\ndisorders. Here we propose a federated learning framework for securely\naccessing and meta-analyzing any biomedical data without sharing individual\ninformation. We illustrate our framework by investigating brain structural\nrelationships across diseases and clinical cohorts. The framework is first\ntested on synthetic data and then applied to multi-centric, multi-database\nstudies including ADNI, PPMI, MIRIAD and UK Biobank, showing the potential of\nthe approach for further applications in distributed analysis of multi-centric\ncohorts\n", "versions": [{"version": "v1", "created": "Fri, 19 Oct 2018 15:36:35 GMT"}, {"version": "v2", "created": "Mon, 22 Oct 2018 08:40:43 GMT"}, {"version": "v3", "created": "Thu, 14 Mar 2019 16:13:30 GMT"}], "update_date": "2019-03-15", "authors_parsed": [["Silva", "Santiago", ""], ["Gutman", "Boris", ""], ["Romero", "Eduardo", ""], ["Thompson", "Paul M", ""], ["Altmann", "Andre", ""], ["Lorenzi", "Marco", ""]]}, {"id": "1810.08559", "submitter": "Alexander Wong", "authors": "Zhong Qiu Lin, Audrey G. Chung, and Alexander Wong", "title": "EdgeSpeechNets: Highly Efficient Deep Neural Networks for Speech\n  Recognition on the Edge", "comments": "4 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.AS cs.LG cs.NE cs.SD eess.SP stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Despite showing state-of-the-art performance, deep learning for speech\nrecognition remains challenging to deploy in on-device edge scenarios such as\nmobile and other consumer devices. Recently, there have been greater efforts in\nthe design of small, low-footprint deep neural networks (DNNs) that are more\nappropriate for edge devices, with much of the focus on design principles for\nhand-crafting efficient network architectures. In this study, we explore a\nhuman-machine collaborative design strategy for building low-footprint DNN\narchitectures for speech recognition through a marriage of human-driven\nprincipled network design prototyping and machine-driven design exploration.\nThe efficacy of this design strategy is demonstrated through the design of a\nfamily of highly-efficient DNNs (nicknamed EdgeSpeechNets) for\nlimited-vocabulary speech recognition. Experimental results using the Google\nSpeech Commands dataset for limited-vocabulary speech recognition showed that\nEdgeSpeechNets have higher accuracies than state-of-the-art DNNs (with the best\nEdgeSpeechNet achieving ~97% accuracy), while achieving significantly smaller\nnetwork sizes (as much as 7.8x smaller) and lower computational cost (as much\nas 36x fewer multiply-add operations, 10x lower prediction latency, and 16x\nsmaller memory footprint on a Motorola Moto E phone), making them very\nwell-suited for on-device edge voice interface applications.\n", "versions": [{"version": "v1", "created": "Thu, 18 Oct 2018 00:47:20 GMT"}, {"version": "v2", "created": "Tue, 13 Nov 2018 19:25:08 GMT"}], "update_date": "2018-11-15", "authors_parsed": [["Lin", "Zhong Qiu", ""], ["Chung", "Audrey G.", ""], ["Wong", "Alexander", ""]]}, {"id": "1810.08564", "submitter": "Mingyuan Zhou", "authors": "Quan Zhang and Mingyuan Zhou", "title": "Nonparametric Bayesian Lomax delegate racing for survival analysis with\n  competing risks", "comments": "NeurIPS 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ME cs.LG stat.AP stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose Lomax delegate racing (LDR) to explicitly model the mechanism of\nsurvival under competing risks and to interpret how the covariates accelerate\nor decelerate the time to event. LDR explains non-monotonic covariate effects\nby racing a potentially infinite number of sub-risks, and consequently relaxes\nthe ubiquitous proportional-hazards assumption which may be too restrictive.\nMoreover, LDR is naturally able to model not only censoring, but also missing\nevent times or event types. For inference, we develop a Gibbs sampler under\ndata augmentation for moderately sized data, along with a stochastic gradient\ndescent maximum a posteriori inference algorithm for big data applications.\nIllustrative experiments are provided on both synthetic and real datasets, and\ncomparison with various benchmark algorithms for survival analysis with\ncompeting risks demonstrates distinguished performance of LDR.\n", "versions": [{"version": "v1", "created": "Fri, 19 Oct 2018 15:57:22 GMT"}, {"version": "v2", "created": "Tue, 1 Jan 2019 00:48:10 GMT"}], "update_date": "2019-01-03", "authors_parsed": [["Zhang", "Quan", ""], ["Zhou", "Mingyuan", ""]]}, {"id": "1810.08575", "submitter": "Paul Christiano", "authors": "Paul Christiano, Buck Shlegeris, Dario Amodei", "title": "Supervising strong learners by amplifying weak experts", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Many real world learning tasks involve complex or hard-to-specify objectives,\nand using an easier-to-specify proxy can lead to poor performance or misaligned\nbehavior. One solution is to have humans provide a training signal by\ndemonstrating or judging performance, but this approach fails if the task is\ntoo complicated for a human to directly evaluate. We propose Iterated\nAmplification, an alternative training strategy which progressively builds up a\ntraining signal for difficult problems by combining solutions to easier\nsubproblems. Iterated Amplification is closely related to Expert Iteration\n(Anthony et al., 2017; Silver et al., 2017), except that it uses no external\nreward function. We present results in algorithmic environments, showing that\nIterated Amplification can efficiently learn complex behaviors.\n", "versions": [{"version": "v1", "created": "Fri, 19 Oct 2018 16:30:48 GMT"}], "update_date": "2018-10-22", "authors_parsed": [["Christiano", "Paul", ""], ["Shlegeris", "Buck", ""], ["Amodei", "Dario", ""]]}, {"id": "1810.08591", "submitter": "Brady Neal", "authors": "Brady Neal, Sarthak Mittal, Aristide Baratin, Vinayak Tantia, Matthew\n  Scicluna, Simon Lacoste-Julien, Ioannis Mitliagkas", "title": "A Modern Take on the Bias-Variance Tradeoff in Neural Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The bias-variance tradeoff tells us that as model complexity increases, bias\nfalls and variances increases, leading to a U-shaped test error curve. However,\nrecent empirical results with over-parameterized neural networks are marked by\na striking absence of the classic U-shaped test error curve: test error keeps\ndecreasing in wider networks. This suggests that there might not be a\nbias-variance tradeoff in neural networks with respect to network width, unlike\nwas originally claimed by, e.g., Geman et al. (1992). Motivated by the shaky\nevidence used to support this claim in neural networks, we measure bias and\nvariance in the modern setting. We find that both bias and variance can\ndecrease as the number of parameters grows. To better understand this, we\nintroduce a new decomposition of the variance to disentangle the effects of\noptimization and data sampling. We also provide theoretical analysis in a\nsimplified setting that is consistent with our empirical findings.\n", "versions": [{"version": "v1", "created": "Fri, 19 Oct 2018 17:19:38 GMT"}, {"version": "v2", "created": "Fri, 25 Jan 2019 14:55:04 GMT"}, {"version": "v3", "created": "Thu, 25 Jul 2019 15:05:50 GMT"}, {"version": "v4", "created": "Wed, 18 Dec 2019 20:35:59 GMT"}], "update_date": "2019-12-20", "authors_parsed": [["Neal", "Brady", ""], ["Mittal", "Sarthak", ""], ["Baratin", "Aristide", ""], ["Tantia", "Vinayak", ""], ["Scicluna", "Matthew", ""], ["Lacoste-Julien", "Simon", ""], ["Mitliagkas", "Ioannis", ""]]}, {"id": "1810.08597", "submitter": "Philipp Sadler", "authors": "Philipp Sadler", "title": "Detecting cities in aerial night-time images by learning structural\n  invariants using single reference augmentation", "comments": "Project in Image Classification, Winter 2018, Prof. Dr. Tatjana\n  Scheffler", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  This paper examines, if it is possible to learn structural invariants of city\nimages by using only a single reference picture when producing transformations\nalong the variants in the dataset. Previous work explored the problem of\nlearning from only a few examples and showed that data augmentation techniques\nbenefit performance and generalization for machine learning approaches. First a\nprincipal component analysis in conjunction with a Fourier transform is trained\non a single reference augmentation training dataset using the city images.\nSecondly a convolutional neural network is trained on a similar dataset with\nmore samples. The findings are that the convolutional neural network is capable\nof finding images of the same category whereas the applied principal component\nanalysis in conjunction with a Fourier transform failed to solve this task.\n", "versions": [{"version": "v1", "created": "Fri, 19 Oct 2018 17:32:07 GMT"}], "update_date": "2018-10-22", "authors_parsed": [["Sadler", "Philipp", ""]]}, {"id": "1810.08606", "submitter": "Amit Gajbhiye", "authors": "Amit Gajbhiye, Sardar Jaf, Noura Al Moubayed, A. Stephen McGough,\n  Steven Bradley", "title": "An Exploration of Dropout with RNNs for Natural Language Inference", "comments": "Accepted in International Conference on Artificial Neural Networks,\n  2018", "journal-ref": null, "doi": "10.1007/978-3-030-01424-7_16", "report-no": null, "categories": "cs.CL cs.LG", "license": "http://creativecommons.org/publicdomain/zero/1.0/", "abstract": "  Dropout is a crucial regularization technique for the Recurrent Neural\nNetwork (RNN) models of Natural Language Inference (NLI). However, dropout has\nnot been evaluated for the effectiveness at different layers and dropout rates\nin NLI models. In this paper, we propose a novel RNN model for NLI and\nempirically evaluate the effect of applying dropout at different layers in the\nmodel. We also investigate the impact of varying dropout rates at these layers.\nOur empirical evaluation on a large (Stanford Natural Language Inference\n(SNLI)) and a small (SciTail) dataset suggest that dropout at each feed-forward\nconnection severely affects the model accuracy at increasing dropout rates. We\nalso show that regularizing the embedding layer is efficient for SNLI whereas\nregularizing the recurrent layer improves the accuracy for SciTail. Our model\nachieved an accuracy 86.14% on the SNLI dataset and 77.05% on SciTail.\n", "versions": [{"version": "v1", "created": "Mon, 22 Oct 2018 17:48:21 GMT"}], "update_date": "2018-10-23", "authors_parsed": [["Gajbhiye", "Amit", ""], ["Jaf", "Sardar", ""], ["Moubayed", "Noura Al", ""], ["McGough", "A. Stephen", ""], ["Bradley", "Steven", ""]]}, {"id": "1810.08609", "submitter": "Mohendra Roy (PhD)", "authors": "Mohendra Roy, Sumon Kumar Bose, Bapi Kar, Pradeep Kumar\n  Gopalakrishnan, Arindam Basu", "title": "A Stacked Autoencoder Neural Network based Automated Feature Extraction\n  Method for Anomaly detection in On-line Condition Monitoring", "comments": "This article has been submitted to IEEE-SSCI 2018 conference", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Condition monitoring is one of the routine tasks in all major process\nindustries. The mechanical parts such as a motor, gear, bearings are the major\ncomponents of a process industry and any fault in them may cause a total\nshutdown of the whole process, which may result in serious losses. Therefore,\nit is very crucial to predict any approaching defects before its occurrence.\nSeveral methods exist for this purpose and many research are being carried out\nfor better and efficient models. However, most of them are based on the\nprocessing of raw sensor signals, which is tedious and expensive. Recently,\nthere has been an increase in the feature based condition monitoring, where\nonly the useful features are extracted from the raw signals and interpreted for\nthe prediction of the fault. Most of these are handcrafted features, where\nthese are manually obtained based on the nature of the raw data. This of course\nrequires the prior knowledge of the nature of data and related processes. This\nlimits the feature extraction process. However, recent development in the\nautoencoder based feature extraction method provides an alternative to the\ntraditional handcrafted approaches; however, they have mostly been confined in\nthe area of image and audio processing. In this work, we have developed an\nautomated feature extraction method for on-line condition monitoring based on\nthe stack of the traditional autoencoder and an on-line sequential extreme\nlearning machine(OSELM) network. The performance of this method is comparable\nto that of the traditional feature extraction approaches. The method can\nachieve 100% detection accuracy for determining the bearing health states of\nNASA bearing dataset. The simple design of this method is promising for the\neasy hardware implementation of Internet of Things(IoT) based prognostics\nsolutions.\n", "versions": [{"version": "v1", "created": "Fri, 19 Oct 2018 03:53:47 GMT"}], "update_date": "2018-10-23", "authors_parsed": [["Roy", "Mohendra", ""], ["Bose", "Sumon Kumar", ""], ["Kar", "Bapi", ""], ["Gopalakrishnan", "Pradeep Kumar", ""], ["Basu", "Arindam", ""]]}, {"id": "1810.08611", "submitter": "L\\'eopold Crestel", "authors": "L\\'eopold Crestel, Philippe Esling, Lena Heng, Stephen McAdams", "title": "A database linking piano and orchestral MIDI scores with application to\n  automatic projective orchestration", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SD cs.LG eess.AS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This article introduces the Projective Orchestral Database (POD), a\ncollection of MIDI scores composed of pairs linking piano scores to their\ncorresponding orchestrations. To the best of our knowledge, this is the first\ndatabase of its kind, which performs piano or orchestral prediction, but more\nimportantly which tries to learn the correlations between piano and orchestral\nscores. Hence, we also introduce the projective orchestration task, which\nconsists in learning how to perform the automatic orchestration of a piano\nscore. We show how this task can be addressed using learning methods and also\nprovide methodological guidelines in order to properly use this database.\n", "versions": [{"version": "v1", "created": "Fri, 19 Oct 2018 12:50:20 GMT"}], "update_date": "2018-10-23", "authors_parsed": [["Crestel", "L\u00e9opold", ""], ["Esling", "Philippe", ""], ["Heng", "Lena", ""], ["McAdams", "Stephen", ""]]}, {"id": "1810.08612", "submitter": "Denis Parkhomenko", "authors": "D.Babin, I.Mazurenko, D.Parkhomenko, A.Voloshko", "title": "CNN inference acceleration using dictionary of centroids", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://creativecommons.org/publicdomain/zero/1.0/", "abstract": "  It is well known that multiplication operations in convolutional layers of\ncommon CNNs consume a lot of time during inference stage. In this article we\npresent a flexible method to decrease both computational complexity of\nconvolutional layers in inference as well as amount of space to store them. The\nmethod is based on centroid filter quantization and outperforms approaches\nbased on tensor decomposition by a large margin. We performed comparative\nanalysis of the proposed method and series of CP tensor decomposition on\nImageNet benchmark and found that our method provide almost 2.9 times better\ncomputational gain. Despite the simplicity of our method it cannot be applied\ndirectly in inference stage in modern frameworks, but could be useful for cases\ncalculation flow could be changed, e.g. for CNN-chip designers.\n", "versions": [{"version": "v1", "created": "Fri, 19 Oct 2018 13:12:13 GMT"}], "update_date": "2018-10-23", "authors_parsed": [["Babin", "D.", ""], ["Mazurenko", "I.", ""], ["Parkhomenko", "D.", ""], ["Voloshko", "A.", ""]]}, {"id": "1810.08615", "submitter": "Ali Marjaninejad", "authors": "Ali Marjaninejad, Dar\\'io Urbina-Mel\\'endez, Brian A. Cohn, Francisco\n  J. Valero-Cuevas", "title": "Autonomous Functional Locomotion in a Tendon-Driven Limb via Limited\n  Experience", "comments": "39 pages, 6 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.LG cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Robots will become ubiquitously useful only when they can use few attempts to\nteach themselves to perform different tasks, even with complex bodies and in\ndynamical environments. Vertebrates, in fact, successfully use trial-and-error\nto learn multiple tasks in spite of their intricate tendon-driven anatomies.\nRoboticists find such tendon-driven systems particularly hard to control\nbecause they are simultaneously nonlinear, under-determined (many tendon\ntensions combine to produce few net joint torques), and over-determined (few\njoint rotations define how many tendons need to be reeled-in/payed-out). We\ndemonstrate---for the first time in simulation and in hardware---how a\nmodel-free approach allows few-shot autonomous learning to produce effective\nlocomotion in a 3-tendon/2-joint tendon-driven leg. Initially, an artificial\nneural network fed by sparsely sampled data collected using motor babbling\ncreates an inverse map from limb kinematics to motor activations, which is\nanalogous to juvenile vertebrates playing during development. Thereafter,\niterative reward-driven exploration of candidate motor activations\nsimultaneously refines the inverse map and finds a functional locomotor\nlimit-cycle autonomously. This biologically-inspired algorithm, which we call\nG2P (General to Particular), enables versatile adaptation of robots to changes\nin the target task, mechanics of their bodies, and environment. Moreover, this\nwork empowers future studies of few-shot autonomous learning in biological\nsystems, which is the foundation of their enviable functional versatility.\n", "versions": [{"version": "v1", "created": "Fri, 19 Oct 2018 16:53:01 GMT"}], "update_date": "2018-10-23", "authors_parsed": [["Marjaninejad", "Ali", ""], ["Urbina-Mel\u00e9ndez", "Dar\u00edo", ""], ["Cohn", "Brian A.", ""], ["Valero-Cuevas", "Francisco J.", ""]]}, {"id": "1810.08635", "submitter": "Jacqueline Hughes-Oliver", "authors": "Jacqueline M. Hughes-Oliver", "title": "Population and Empirical PR Curves for Assessment of Ranking Algorithms", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG stat.ME", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The ROC curve is widely used to assess the quality of\nprediction/classification/ranking algorithms, and its properties have been\nextensively studied. The precision-recall (PR) curve has become the de facto\nreplacement for the ROC curve in the presence of imbalance, namely where one\nclass is far more likely than the other class. While the PR and ROC curves tend\nto be used interchangeably, they have some very different properties.\nProperties of the PR curve are the focus of this paper. We consider: (1)\npopulation PR curves, where complete distributional assumptions are specified\nfor scores from both classes; and (2) empirical estimators of the PR curve,\nwhere we observe scores and no distributional assumptions are made. The\nproperties have direct consequence on how the PR curve should, and should not,\nbe used. For example, the empirical PR curve is not consistent when scores in\nthe class of primary interest come from discrete distributions. On the other\nhand, a normal approximation can fit quite well for points on the empirical PR\ncurve from continuously-defined scores, but convergence can be heavily\ninfluenced by the distributional setting, the amount of imbalance, and the\npoint of interest on the PR curve.\n", "versions": [{"version": "v1", "created": "Fri, 19 Oct 2018 18:29:27 GMT"}], "update_date": "2018-10-23", "authors_parsed": [["Hughes-Oliver", "Jacqueline M.", ""]]}, {"id": "1810.08640", "submitter": "Tsui-Wei Weng", "authors": "Tsui-Wei Weng, Huan Zhang, Pin-Yu Chen, Aurelie Lozano, Cho-Jui Hsieh,\n  Luca Daniel", "title": "On Extensions of CLEVER: A Neural Network Robustness Evaluation\n  Algorithm", "comments": "Accepted by GlobalSIP 2018. Tsui-Wei Weng and Huan Zhang contributed\n  equally", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  CLEVER (Cross-Lipschitz Extreme Value for nEtwork Robustness) is an Extreme\nValue Theory (EVT) based robustness score for large-scale deep neural networks\n(DNNs). In this paper, we propose two extensions on this robustness score.\nFirst, we provide a new formal robustness guarantee for classifier functions\nthat are twice differentiable. We apply extreme value theory on the new formal\nrobustness guarantee and the estimated robustness is called second-order CLEVER\nscore. Second, we discuss how to handle gradient masking, a common defensive\ntechnique, using CLEVER with Backward Pass Differentiable Approximation (BPDA).\nWith BPDA applied, CLEVER can evaluate the intrinsic robustness of neural\nnetworks of a broader class -- networks with non-differentiable input\ntransformations. We demonstrate the effectiveness of CLEVER with BPDA in\nexperiments on a 121-layer Densenet model trained on the ImageNet dataset.\n", "versions": [{"version": "v1", "created": "Fri, 19 Oct 2018 18:44:58 GMT"}], "update_date": "2018-10-23", "authors_parsed": [["Weng", "Tsui-Wei", ""], ["Zhang", "Huan", ""], ["Chen", "Pin-Yu", ""], ["Lozano", "Aurelie", ""], ["Hsieh", "Cho-Jui", ""], ["Daniel", "Luca", ""]]}, {"id": "1810.08646", "submitter": "Sumit Bam Shrestha", "authors": "Sumit Bam Shrestha and Garrick Orchard", "title": "SLAYER: Spike Layer Error Reassignment in Time", "comments": "10 pages, 2 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Configuring deep Spiking Neural Networks (SNNs) is an exciting research\navenue for low power spike event based computation. However, the spike\ngeneration function is non-differentiable and therefore not directly compatible\nwith the standard error backpropagation algorithm. In this paper, we introduce\na new general backpropagation mechanism for learning synaptic weights and\naxonal delays which overcomes the problem of non-differentiability of the spike\nfunction and uses a temporal credit assignment policy for backpropagating error\nto preceding layers. We describe and release a GPU accelerated software\nimplementation of our method which allows training both fully connected and\nconvolutional neural network (CNN) architectures. Using our software, we\ncompare our method against existing SNN based learning approaches and standard\nANN to SNN conversion techniques and show that our method achieves state of the\nart performance for an SNN on the MNIST, NMNIST, DVS Gesture, and TIDIGITS\ndatasets.\n", "versions": [{"version": "v1", "created": "Wed, 5 Sep 2018 10:10:03 GMT"}], "update_date": "2018-10-23", "authors_parsed": [["Shrestha", "Sumit Bam", ""], ["Orchard", "Garrick", ""]]}, {"id": "1810.08647", "submitter": "Natasha Jaques", "authors": "Natasha Jaques, Angeliki Lazaridou, Edward Hughes, Caglar Gulcehre,\n  Pedro A. Ortega, DJ Strouse, Joel Z. Leibo, Nando de Freitas", "title": "Social Influence as Intrinsic Motivation for Multi-Agent Deep\n  Reinforcement Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.MA stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a unified mechanism for achieving coordination and communication\nin Multi-Agent Reinforcement Learning (MARL), through rewarding agents for\nhaving causal influence over other agents' actions. Causal influence is\nassessed using counterfactual reasoning. At each timestep, an agent simulates\nalternate actions that it could have taken, and computes their effect on the\nbehavior of other agents. Actions that lead to bigger changes in other agents'\nbehavior are considered influential and are rewarded. We show that this is\nequivalent to rewarding agents for having high mutual information between their\nactions. Empirical results demonstrate that influence leads to enhanced\ncoordination and communication in challenging social dilemma environments,\ndramatically increasing the learning curves of the deep RL agents, and leading\nto more meaningful learned communication protocols. The influence rewards for\nall agents can be computed in a decentralized way by enabling agents to learn a\nmodel of other agents using deep neural networks. In contrast, key previous\nworks on emergent communication in the MARL setting were unable to learn\ndiverse policies in a decentralized manner and had to resort to centralized\ntraining. Consequently, the influence reward opens up a window of new\nopportunities for research in this area.\n", "versions": [{"version": "v1", "created": "Fri, 19 Oct 2018 19:01:15 GMT"}, {"version": "v2", "created": "Fri, 14 Dec 2018 22:44:48 GMT"}, {"version": "v3", "created": "Fri, 8 Feb 2019 23:52:07 GMT"}, {"version": "v4", "created": "Tue, 18 Jun 2019 21:39:08 GMT"}], "update_date": "2019-06-20", "authors_parsed": [["Jaques", "Natasha", ""], ["Lazaridou", "Angeliki", ""], ["Hughes", "Edward", ""], ["Gulcehre", "Caglar", ""], ["Ortega", "Pedro A.", ""], ["Strouse", "DJ", ""], ["Leibo", "Joel Z.", ""], ["de Freitas", "Nando", ""]]}, {"id": "1810.08651", "submitter": "Jessica Thompson", "authors": "Jessica A. F. Thompson, Yoshua Bengio, Elia Formisano, and Marc\n  Sch\\\"onwiesner", "title": "How can deep learning advance computational modeling of sensory\n  information processing?", "comments": "Presented at MLINI-2016 workshop, 2016 (arXiv:1701.01437)", "journal-ref": null, "doi": null, "report-no": "MLINI/2016/04", "categories": "cs.NE cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep learning, computational neuroscience, and cognitive science have\noverlapping goals related to understanding intelligence such that perception\nand behaviour can be simulated in computational systems. In neuroimaging,\nmachine learning methods have been used to test computational models of sensory\ninformation processing. Recently, these model comparison techniques have been\nused to evaluate deep neural networks (DNNs) as models of sensory information\nprocessing. However, the interpretation of such model evaluations is muddied by\nimprecise statistical conclusions. Here, we make explicit the types of\nconclusions that can be drawn from these existing model comparison techniques\nand how these conclusions change when the model in question is a DNN. We\ndiscuss how DNNs are amenable to new model comparison techniques that allow for\nstronger conclusions to be made about the computational mechanisms underlying\nsensory information processing.\n", "versions": [{"version": "v1", "created": "Tue, 25 Sep 2018 23:39:34 GMT"}], "update_date": "2018-10-23", "authors_parsed": [["Thompson", "Jessica A. F.", ""], ["Bengio", "Yoshua", ""], ["Formisano", "Elia", ""], ["Sch\u00f6nwiesner", "Marc", ""]]}, {"id": "1810.08653", "submitter": "Yonghua Yin", "authors": "Yonghua Yin", "title": "Deep Learning with the Random Neural Network and its Applications", "comments": "23 pages, 19 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The random neural network (RNN) is a mathematical model for an \"integrate and\nfire\" spiking network that closely resembles the stochastic behaviour of\nneurons in mammalian brains. Since its proposal in 1989, there have been\nnumerous investigations into the RNN's applications and learning algorithms.\nDeep learning (DL) has achieved great success in machine learning. Recently,\nthe properties of the RNN for DL have been investigated, in order to combine\ntheir power. Recent results demonstrate that the gap between RNNs and DL can be\nbridged and the DL tools based on the RNN are faster and can potentially be\nused with less energy expenditure than existing methods.\n", "versions": [{"version": "v1", "created": "Mon, 8 Oct 2018 14:47:51 GMT"}], "update_date": "2018-10-23", "authors_parsed": [["Yin", "Yonghua", ""]]}, {"id": "1810.08669", "submitter": "Giovanni Iacca Dr.", "authors": "G. Iacca, F. Neri, E. Mininno, Y. S. Ong, M. H. Lim", "title": "Ockham's Razor in Memetic Computing: Three Stage Optimal Memetic\n  Exploration", "comments": null, "journal-ref": "Information Sciences, Volume 188, pp 17-43, 2012", "doi": "10.1016/j.ins.2011.11.025", "report-no": null, "categories": "cs.LG cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Memetic Computing is a subject in computer science which considers complex\nstructures as the combination of simple agents, memes, whose evolutionary\ninteractions lead to intelligent structures capable of problem-solving. This\npaper focuses on Memetic Computing optimization algorithms and proposes a\ncounter-tendency approach for algorithmic design. Research in the field tends\nto go in the direction of improving existing algorithms by combining different\nmethods or through the formulation of more complicated structures. Contrary to\nthis trend, we instead focus on simplicity, proposing a structurally simple\nalgorithm with emphasis on processing only one solution at a time. The proposed\nalgorithm, namely Three Stage Optimal Memetic Exploration, is composed of three\nmemes; the first stochastic and with a long search radius, the second\nstochastic and with a moderate search radius and the third deterministic and\nwith a short search radius. The bottom-up combination of the three operators by\nmeans of a natural trial and error logic, generates a robust and efficient\noptimizer, capable of competing with modern complex and computationally\nexpensive algorithms. This is suggestive of the fact that complexity in\nalgorithmic structures can be unnecessary, if not detrimental, and that simple\nbottom-up approaches are likely to be competitive is here invoked as an\nextension to Memetic Computing basing on the philosophical concept of Ockham's\nRazor. An extensive experimental setup on various test problems and one digital\nsignal processing application is presented. Numerical results show that the\nproposed approach, despite its simplicity and low computational cost displays a\nvery good performance on several problems, and is competitive with\nsophisticated algorithms representing the-state-of-the-art in computational\nintelligence optimization.\n", "versions": [{"version": "v1", "created": "Fri, 5 Oct 2018 14:14:34 GMT"}], "update_date": "2018-10-23", "authors_parsed": [["Iacca", "G.", ""], ["Neri", "F.", ""], ["Mininno", "E.", ""], ["Ong", "Y. S.", ""], ["Lim", "M. H.", ""]]}, {"id": "1810.08672", "submitter": "Paul Keeler Dr", "authors": "Bart{\\l}omiej B{\\l}aszczyszyn and Paul Keeler", "title": "Determinantal thinning of point processes with network learning\n  applications", "comments": "8 pages, 6 figures. (Previous version had a typo in one of the\n  Laplace functional expressions.) All code available online:\n  https://github.com/hpaulkeeler/DetPoisson_MATLAB", "journal-ref": "Proc. of IEEE WCNC 2019", "doi": null, "report-no": null, "categories": "cs.LG math.PR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A new type of dependent thinning for point processes in continuous space is\nproposed, which leverages the advantages of determinantal point processes\ndefined on finite spaces and, as such, is particularly amenable to statistical,\nnumerical, and simulation techniques. It gives a new point process that can\nserve as a network model exhibiting repulsion. The properties and functions of\nthe new point process, such as moment measures, the Laplace functional, the\nvoid probabilities, as well as conditional (Palm) characteristics can be\nestimated accurately by simulating the underlying (non-thinned) point process,\nwhich can be taken, for example, to be Poisson. This is in contrast (and\npreference to) finite Gibbs point processes, which, instead of thinning,\nrequire weighting the Poisson realizations, involving usually intractable\nnormalizing constants. Models based on determinantal point processes are also\nwell suited for statistical (supervised) learning techniques, allowing the\nmodels to be fitted to observed network patterns with some particular geometric\nproperties. We illustrate this approach by imitating with determinantal\nthinning the well-known Mat{\\'e}rn~II hard-core thinning, as well as a\nsoft-core thinning depending on nearest-neighbour triangles. These two examples\ndemonstrate how the proposed approach can lead to new, statistically optimized,\nprobabilistic transmission scheduling schemes.\n", "versions": [{"version": "v1", "created": "Tue, 9 Oct 2018 10:19:53 GMT"}, {"version": "v2", "created": "Thu, 22 Nov 2018 19:02:45 GMT"}], "update_date": "2019-06-19", "authors_parsed": [["B\u0142aszczyszyn", "Bart\u0142omiej", ""], ["Keeler", "Paul", ""]]}, {"id": "1810.08675", "submitter": "Andrew McGough", "authors": "A. Stephen McGough and Matthew Forshaw and John Brennan and Noura Al\n  Moubayed and Stephen Bonner", "title": "Using Machine Learning to reduce the energy wasted in Volunteer\n  Computing Environments", "comments": "Accepted for publication at THE 9th international Green and\n  sustainable computing Conference, Technically Co-sponsored by IEEE Computer\n  Society & STC Sustainable Computing, October 22-24, Pittsburgh, PA, USA", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  High Throughput Computing (HTC) provides a convenient mechanism for running\nthousands of tasks. Many HTC systems exploit computers which are provisioned\nfor other purposes by utilising their idle time - volunteer computing. This has\ngreat advantages as it gives access to vast quantities of computational power\nfor little or no cost. The downside is that running tasks are sacrificed if the\ncomputer is needed for its primary use. Normally terminating the task which\nmust be restarted on a different computer - leading to wasted energy and an\nincrease in task completion time. We demonstrate, through the use of\nsimulation, how we can reduce this wasted energy by targeting tasks at\ncomputers less likely to be needed for primary use, predicting this idle time\nthrough machine learning. By combining two machine learning approaches, namely\nRandom Forest and MultiLayer Perceptron, we save 51.4% of the energy without\nsignificantly affecting the time to complete tasks.\n", "versions": [{"version": "v1", "created": "Fri, 19 Oct 2018 20:17:41 GMT"}], "update_date": "2018-10-23", "authors_parsed": [["McGough", "A. Stephen", ""], ["Forshaw", "Matthew", ""], ["Brennan", "John", ""], ["Moubayed", "Noura Al", ""], ["Bonner", "Stephen", ""]]}, {"id": "1810.08676", "submitter": "Kommy Weldemariam Dr", "authors": "Skyler Speakman, Srihari Sridharan, Sekou Remy, Komminist Weldemariam,\n  Edward McFowland", "title": "Subset Scanning Over Neural Network Activations", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  This work views neural networks as data generating systems and applies\nanomalous pattern detection techniques on that data in order to detect when a\nnetwork is processing an anomalous input. Detecting anomalies is a critical\ncomponent for multiple machine learning problems including detecting\nadversarial noise. More broadly, this work is a step towards giving neural\nnetworks the ability to recognize an out-of-distribution sample. This is the\nfirst work to introduce \"Subset Scanning\" methods from the anomalous pattern\ndetection domain to the task of detecting anomalous input of neural networks.\nSubset scanning treats the detection problem as a search for the most anomalous\nsubset of node activations (i.e., highest scoring subset according to\nnon-parametric scan statistics). Mathematical properties of these scoring\nfunctions allow the search to be completed in log-linear rather than\nexponential time while still guaranteeing the most anomalous subset of nodes in\nthe network is identified for a given input. Quantitative results for detecting\nand characterizing adversarial noise are provided for CIFAR-10 images on a\nsimple convolutional neural network. We observe an \"interference\" pattern where\nanomalous activations in shallow layers suppress the activation structure of\nthe original image in deeper layers.\n", "versions": [{"version": "v1", "created": "Fri, 19 Oct 2018 20:22:53 GMT"}], "update_date": "2018-10-23", "authors_parsed": [["Speakman", "Skyler", ""], ["Sridharan", "Srihari", ""], ["Remy", "Sekou", ""], ["Weldemariam", "Komminist", ""], ["McFowland", "Edward", ""]]}, {"id": "1810.08678", "submitter": "Zhenpeng Zhou", "authors": "Zhenpeng Zhou, Steven Kearnes, Li Li, Richard N. Zare, and Patrick\n  Riley", "title": "Optimization of Molecules via Deep Reinforcement Learning", "comments": null, "journal-ref": null, "doi": "10.1038/s41598-019-47148-x", "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a framework, which we call Molecule Deep $Q$-Networks (MolDQN),\nfor molecule optimization by combining domain knowledge of chemistry and\nstate-of-the-art reinforcement learning techniques (double $Q$-learning and\nrandomized value functions). We directly define modifications on molecules,\nthereby ensuring 100\\% chemical validity. Further, we operate without\npre-training on any dataset to avoid possible bias from the choice of that set.\nInspired by problems faced during medicinal chemistry lead optimization, we\nextend our model with multi-objective reinforcement learning, which maximizes\ndrug-likeness while maintaining similarity to the original molecule. We further\nshow the path through chemical space to achieve optimization for a molecule to\nunderstand how the model works.\n", "versions": [{"version": "v1", "created": "Fri, 19 Oct 2018 20:23:44 GMT"}, {"version": "v2", "created": "Tue, 23 Oct 2018 05:28:46 GMT"}, {"version": "v3", "created": "Fri, 1 Mar 2019 01:46:11 GMT"}], "update_date": "2020-06-22", "authors_parsed": [["Zhou", "Zhenpeng", ""], ["Kearnes", "Steven", ""], ["Li", "Li", ""], ["Zare", "Richard N.", ""], ["Riley", "Patrick", ""]]}, {"id": "1810.08683", "submitter": "Michele Donini", "authors": "Luca Oneto, Michele Donini, Amon Elders, Massimiliano Pontil", "title": "Taking Advantage of Multitask Learning for Fair Classification", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://creativecommons.org/licenses/by-sa/4.0/", "abstract": "  A central goal of algorithmic fairness is to reduce bias in automated\ndecision making. An unavoidable tension exists between accuracy gains obtained\nby using sensitive information (e.g., gender or ethnic group) as part of a\nstatistical model, and any commitment to protect these characteristics. Often,\ndue to biases present in the data, using the sensitive information in the\nfunctional form of a classifier improves classification accuracy. In this paper\nwe show how it is possible to get the best of both worlds: optimize model\naccuracy and fairness without explicitly using the sensitive feature in the\nfunctional form of the model, thereby treating different individuals equally.\nOur method is based on two key ideas. On the one hand, we propose to use\nMultitask Learning (MTL), enhanced with fairness constraints, to jointly learn\ngroup specific classifiers that leverage information between sensitive groups.\nOn the other hand, since learning group specific models might not be permitted,\nwe propose to first predict the sensitive features by any learning method and\nthen to use the predicted sensitive feature to train MTL with fairness\nconstraints. This enables us to tackle fairness with a three-pronged approach,\nthat is, by increasing accuracy on each group, enforcing measures of fairness\nduring training, and protecting sensitive information during testing.\nExperimental results on two real datasets support our proposal, showing\nsubstantial improvements in both accuracy and fairness.\n", "versions": [{"version": "v1", "created": "Fri, 19 Oct 2018 20:34:46 GMT"}, {"version": "v2", "created": "Fri, 31 Jan 2020 08:03:05 GMT"}], "update_date": "2020-02-03", "authors_parsed": [["Oneto", "Luca", ""], ["Donini", "Michele", ""], ["Elders", "Amon", ""], ["Pontil", "Massimiliano", ""]]}, {"id": "1810.08691", "submitter": "Dawei Liang", "authors": "Dawei Liang, Edison Thomaz", "title": "Audio-Based Activities of Daily Living (ADL) Recognition with\n  Large-Scale Acoustic Embeddings from Online Videos", "comments": "18 pages,7 figures; new version: results updates", "journal-ref": "ACM IMWUT 3(1) 2019 Article 17", "doi": "10.1145/3314404", "report-no": null, "categories": "cs.HC cs.LG cs.SD eess.AS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Over the years, activity sensing and recognition has been shown to play a key\nenabling role in a wide range of applications, from sustainability and\nhuman-computer interaction to health care. While many recognition tasks have\ntraditionally employed inertial sensors, acoustic-based methods offer the\nbenefit of capturing rich contextual information, which can be useful when\ndiscriminating complex activities. Given the emergence of deep learning\ntechniques and leveraging new, large-scaled multi-media datasets, this paper\nrevisits the opportunity of training audio-based classifiers without the\nonerous and time-consuming task of annotating audio data. We propose a\nframework for audio-based activity recognition that makes use of millions of\nembedding features from public online video sound clips. Based on the\ncombination of oversampling and deep learning approaches, our framework does\nnot require further feature processing or outliers filtering as in prior work.\nWe evaluated our approach in the context of Activities of Daily Living (ADL) by\nrecognizing 15 everyday activities with 14 participants in their own homes,\nachieving 64.2% and 83.6% averaged within-subject accuracy in terms of top-1\nand top-3 classification respectively. Individual class performance was also\nexamined in the paper to further study the co-occurrence characteristics of the\nactivities and the robustness of the framework.\n", "versions": [{"version": "v1", "created": "Fri, 19 Oct 2018 21:19:16 GMT"}, {"version": "v2", "created": "Sun, 18 Nov 2018 09:08:24 GMT"}], "update_date": "2019-04-09", "authors_parsed": [["Liang", "Dawei", ""], ["Thomaz", "Edison", ""]]}, {"id": "1810.08700", "submitter": "Bj\\\"orn L\\\"utjens", "authors": "Bj\\\"orn L\\\"utjens, Michael Everett, Jonathan P. How", "title": "Safe Reinforcement Learning with Model Uncertainty Estimates", "comments": "ICRA 2019; Presented at IROS 2018 Workshop on Machine Learning in\n  Robot Motion Planning", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Many current autonomous systems are being designed with a strong reliance on\nblack box predictions from deep neural networks (DNNs). However, DNNs tend to\nbe overconfident in predictions on unseen data and can give unpredictable\nresults for far-from-distribution test data. The importance of predictions that\nare robust to this distributional shift is evident for safety-critical\napplications, such as collision avoidance around pedestrians. Measures of model\nuncertainty can be used to identify unseen data, but the state-of-the-art\nextraction methods such as Bayesian neural networks are mostly intractable to\ncompute. This paper uses MC-Dropout and Bootstrapping to give computationally\ntractable and parallelizable uncertainty estimates. The methods are embedded in\na Safe Reinforcement Learning framework to form uncertainty-aware navigation\naround pedestrians. The result is a collision avoidance policy that knows what\nit does not know and cautiously avoids pedestrians that exhibit unseen\nbehavior. The policy is demonstrated in simulation to be more robust to novel\nobservations and take safer actions than an uncertainty-unaware baseline.\n", "versions": [{"version": "v1", "created": "Fri, 19 Oct 2018 22:04:59 GMT"}, {"version": "v2", "created": "Fri, 1 Mar 2019 05:03:11 GMT"}], "update_date": "2019-03-04", "authors_parsed": [["L\u00fctjens", "Bj\u00f6rn", ""], ["Everett", "Michael", ""], ["How", "Jonathan P.", ""]]}, {"id": "1810.08723", "submitter": "Ewout van den Berg", "authors": "Ewout van den Berg", "title": "The Ocean Tensor Package", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.MS cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Matrix and tensor operations form the basis of a wide range of fields and\napplications, and in many cases constitute a substantial part of the overall\ncomputational complexity. The ability of general-purpose GPUs to speed up many\nof these operations and enable others has resulted in a widespread adaptation\nof these devices. In order for tensor operations to take full advantage of the\ncomputational power, specialized software is required, and currently there\nexist several packages (predominantly in the area of deep learning) that\nincorporate tensor operations on both CPU and GPU. Nevertheless, a stand-alone\nframework that supports general tensor operations is still missing. In this\npaper we fill this gap and propose the Ocean Tensor Library: a modular\ntensor-support package that is designed to serve as a foundational layer for\napplications that require dense tensor operations on a variety of device types.\nThe API is carefully designed to be powerful, extensible, and at the same time\neasy to use. The package is available as open source.\n", "versions": [{"version": "v1", "created": "Sat, 20 Oct 2018 00:56:12 GMT"}], "update_date": "2018-10-23", "authors_parsed": [["Berg", "Ewout van den", ""]]}, {"id": "1810.08726", "submitter": "Yong Liu Stephen", "authors": "Yong Liu, Min Wu, Chenghao Liu, Xiao-Li Li, Jie Zheng", "title": "SL$^2$MF: Predicting Synthetic Lethality in Human Cancers via Logistic\n  Matrix Factorization", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG q-bio.QM stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Synthetic lethality (SL) is a promising concept for novel discovery of\nanti-cancer drug targets. However, wet-lab experiments for detecting SLs are\nfaced with various challenges, such as high cost, low consistency across\nplatforms or cell lines. Therefore, computational prediction methods are needed\nto address these issues. This paper proposes a novel SL prediction method,\nnamed SL2MF, which employs logistic matrix factorization to learn latent\nrepresentations of genes from the observed SL data. The probability that two\ngenes are likely to form SL is modeled by the linear combination of gene latent\nvectors. As known SL pairs are more trustworthy than unknown pairs, we design\nimportance weighting schemes to assign higher importance weights for known SL\npairs and lower importance weights for unknown pairs in SL2MF. Moreover, we\nalso incorporate biological knowledge about genes from protein-protein\ninteraction (PPI) data and Gene Ontology (GO). In particular, we calculate the\nsimilarity between genes based on their GO annotations and topological\nproperties in the PPI network. Extensive experiments on the SL interaction data\nfrom SynLethDB database have been conducted to demonstrate the effectiveness of\nSL2MF.\n", "versions": [{"version": "v1", "created": "Sat, 20 Oct 2018 01:33:07 GMT"}], "update_date": "2018-10-23", "authors_parsed": [["Liu", "Yong", ""], ["Wu", "Min", ""], ["Liu", "Chenghao", ""], ["Li", "Xiao-Li", ""], ["Zheng", "Jie", ""]]}, {"id": "1810.08727", "submitter": "Paul Grigas", "authors": "Robert M. Freund, Paul Grigas, Rahul Mazumder", "title": "Condition Number Analysis of Logistic Regression, and its Implications\n  for Standard First-Order Solution Methods", "comments": "38 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.OC cs.LG stat.CO stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Logistic regression is one of the most popular methods in binary\nclassification, wherein estimation of model parameters is carried out by\nsolving the maximum likelihood (ML) optimization problem, and the ML estimator\nis defined to be the optimal solution of this problem. It is well known that\nthe ML estimator exists when the data is non-separable, but fails to exist when\nthe data is separable. First-order methods are the algorithms of choice for\nsolving large-scale instances of the logistic regression problem. In this\npaper, we introduce a pair of condition numbers that measure the degree of\nnon-separability or separability of a given dataset in the setting of binary\nclassification, and we study how these condition numbers relate to and inform\nthe properties and the convergence guarantees of first-order methods. When the\ntraining data is non-separable, we show that the degree of non-separability\nnaturally enters the analysis and informs the properties and convergence\nguarantees of two standard first-order methods: steepest descent (for any given\nnorm) and stochastic gradient descent. Expanding on the work of Bach, we also\nshow how the degree of non-separability enters into the analysis of linear\nconvergence of steepest descent (without needing strong convexity), as well as\nthe adaptive convergence of stochastic gradient descent. When the training data\nis separable, first-order methods rather curiously have good empirical success,\nwhich is not well understood in theory. In the case of separable data, we\ndemonstrate how the degree of separability enters into the analysis of $\\ell_2$\nsteepest descent and stochastic gradient descent for delivering\napproximate-maximum-margin solutions with associated computational guarantees\nas well. This suggests that first-order methods can lead to statistically\nmeaningful solutions in the separable case, even though the ML solution does\nnot exist.\n", "versions": [{"version": "v1", "created": "Sat, 20 Oct 2018 01:37:20 GMT"}], "update_date": "2018-10-23", "authors_parsed": [["Freund", "Robert M.", ""], ["Grigas", "Paul", ""], ["Mazumder", "Rahul", ""]]}, {"id": "1810.08732", "submitter": "Eda Okur", "authors": "Eda Okur and Hakan Demir and Arzucan \\\"Ozg\\\"ur", "title": "Named Entity Recognition on Twitter for Turkish using Semi-supervised\n  Learning with Word Embeddings", "comments": "Proceedings of the Tenth International Conference on Language\n  Resources and Evaluation (LREC 2016)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recently, due to the increasing popularity of social media, the necessity for\nextracting information from informal text types, such as microblog texts, has\ngained significant attention. In this study, we focused on the Named Entity\nRecognition (NER) problem on informal text types for Turkish. We utilized a\nsemi-supervised learning approach based on neural networks. We applied a fast\nunsupervised method for learning continuous representations of words in vector\nspace. We made use of these obtained word embeddings, together with language\nindependent features that are engineered to work better on informal text types,\nfor generating a Turkish NER system on microblog texts. We evaluated our\nTurkish NER system on Twitter messages and achieved better F-score performances\nthan the published results of previously proposed NER systems on Turkish\ntweets. Since we did not employ any language dependent features, we believe\nthat our method can be easily adapted to microblog texts in other\nmorphologically rich languages.\n", "versions": [{"version": "v1", "created": "Sat, 20 Oct 2018 02:00:35 GMT"}], "update_date": "2018-10-23", "authors_parsed": [["Okur", "Eda", ""], ["Demir", "Hakan", ""], ["\u00d6zg\u00fcr", "Arzucan", ""]]}, {"id": "1810.08743", "submitter": "Christopher Jung", "authors": "Christopher Jung, Sampath Kannan, Neil Lutz", "title": "Quantifying the Burden of Exploration and the Unfairness of Free Riding", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.MA stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the multi-armed bandit setting with a twist. Rather than having\njust one decision maker deciding which arm to pull in each round, we have $n$\ndifferent decision makers (agents). In the simple stochastic setting, we show\nthat a \"free-riding\" agent observing another \"self-reliant\" agent can achieve\njust $O(1)$ regret, as opposed to the regret lower bound of $\\Omega (\\log t)$\nwhen one decision maker is playing in isolation. This result holds whenever the\nself-reliant agent's strategy satisfies either one of two assumptions: (1) each\narm is pulled at least $\\gamma \\ln t$ times in expectation for a constant\n$\\gamma$ that we compute, or (2) the self-reliant agent achieves $o(t)$\nrealized regret with high probability. Both of these assumptions are satisfied\nby standard zero-regret algorithms. Under the second assumption, we further\nshow that the free rider only needs to observe the number of times each arm is\npulled by the self-reliant agent, and not the rewards realized.\n  In the linear contextual setting, each arm has a distribution over parameter\nvectors, each agent has a context vector, and the reward realized when an agent\npulls an arm is the inner product of that agent's context vector with a\nparameter vector sampled from the pulled arm's distribution. We show that the\nfree rider can achieve $O(1)$ regret in this setting whenever the free rider's\ncontext is a small (in $L_2$-norm) linear combination of other agents' contexts\nand all other agents pull each arm $\\Omega (\\log t)$ times with high\nprobability. Again, this condition on the self-reliant players is satisfied by\nstandard zero-regret algorithms like UCB. We also prove a number of lower\nbounds.\n", "versions": [{"version": "v1", "created": "Sat, 20 Oct 2018 03:08:52 GMT"}, {"version": "v2", "created": "Wed, 23 Jan 2019 22:22:35 GMT"}, {"version": "v3", "created": "Wed, 17 Jul 2019 01:16:56 GMT"}, {"version": "v4", "created": "Tue, 22 Sep 2020 17:29:49 GMT"}], "update_date": "2020-09-23", "authors_parsed": [["Jung", "Christopher", ""], ["Kannan", "Sampath", ""], ["Lutz", "Neil", ""]]}, {"id": "1810.08744", "submitter": "Mark Hamilton", "authors": "Mark Hamilton, Sudarshan Raghunathan, Ilya Matiach, Andrew\n  Schonhoffer, Anand Raman, Eli Barzilay, Karthik Rajendran, Dalitso Banda,\n  Casey Jisoo Hong, Manon Knoertzer, Ben Brodsky, Minsoo Thigpen, Janhavi\n  Suresh Mahajan, Courtney Cochrane, Abhiram Eswaran, Ari Green", "title": "MMLSpark: Unifying Machine Learning Ecosystems at Massive Scales", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.DC stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We introduce Microsoft Machine Learning for Apache Spark (MMLSpark), an\necosystem of enhancements that expand the Apache Spark distributed computing\nlibrary to tackle problems in Deep Learning, Micro-Service Orchestration,\nGradient Boosting, Model Interpretability, and other areas of modern\ncomputation. Furthermore, we present a novel system called Spark Serving that\nallows users to run any Apache Spark program as a distributed, sub-millisecond\nlatency web service backed by their existing Spark Cluster. All MMLSpark\ncontributions have the same API to enable simple composition across frameworks\nand usage across batch, streaming, and RESTful web serving scenarios on static,\nelastic, or serverless clusters. We showcase MMLSpark by creating a method for\ndeep object detection capable of learning without human labeled data and\ndemonstrate its effectiveness for Snow Leopard conservation.\n", "versions": [{"version": "v1", "created": "Sat, 20 Oct 2018 03:12:59 GMT"}, {"version": "v2", "created": "Fri, 21 Jun 2019 15:39:52 GMT"}], "update_date": "2019-06-24", "authors_parsed": [["Hamilton", "Mark", ""], ["Raghunathan", "Sudarshan", ""], ["Matiach", "Ilya", ""], ["Schonhoffer", "Andrew", ""], ["Raman", "Anand", ""], ["Barzilay", "Eli", ""], ["Rajendran", "Karthik", ""], ["Banda", "Dalitso", ""], ["Hong", "Casey Jisoo", ""], ["Knoertzer", "Manon", ""], ["Brodsky", "Ben", ""], ["Thigpen", "Minsoo", ""], ["Mahajan", "Janhavi Suresh", ""], ["Cochrane", "Courtney", ""], ["Eswaran", "Abhiram", ""], ["Green", "Ari", ""]]}, {"id": "1810.08749", "submitter": "Borzou Alipourfard", "authors": "Borzou Alipourfard and Jean X. Gao", "title": "Renormalized Normalized Maximum Likelihood and Three-Part Code Criteria\n  For Learning Gaussian Networks", "comments": "This work has been submitted to a journal for possible publication.\n  Copyright may be transferred without notice, after which this version may no\n  longer be accessible", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Score based learning (SBL) is a promising approach for learning Bayesian\nnetworks in the discrete domain. However, when employing SBL in the continuous\ndomain, one is either forced to move the problem to the discrete domain or use\nmetrics such as BIC/AIC, and these approaches are often lacking. Discretization\ncan have an undesired impact on the accuracy of the results, and BIC/AIC can\nfall short of achieving the desired accuracy. In this paper, we introduce two\nnew scoring metrics for scoring Bayesian networks in the continuous domain: the\nthree-part minimum description length and the renormalized normalized maximum\nlikelihood metric. We rely on the minimum description length principle in\nformulating these metrics. The metrics proposed are free of hyperparameters,\ndecomposable, and are asymptotically consistent. We evaluate our solution by\nstudying the convergence rate of the learned graph to the generating network\nand, also, the structural hamming distance of the learned graph to the\ngenerating network. Our evaluations show that the proposed metrics outperform\ntheir competitors, the BIC/AIC metrics. Furthermore, using the proposed RNML\nmetric, SBL will have the fastest rate of convergence with the smallest\nstructural hamming distance to the generating network.\n", "versions": [{"version": "v1", "created": "Sat, 20 Oct 2018 03:46:41 GMT"}, {"version": "v2", "created": "Sat, 26 Dec 2020 13:13:15 GMT"}], "update_date": "2020-12-29", "authors_parsed": [["Alipourfard", "Borzou", ""], ["Gao", "Jean X.", ""]]}, {"id": "1810.08750", "submitter": "Hongseok Namkoong", "authors": "John Duchi, Hongseok Namkoong", "title": "Learning Models with Uniform Performance via Distributionally Robust\n  Optimization", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A common goal in statistics and machine learning is to learn models that can\nperform well against distributional shifts, such as latent heterogeneous\nsubpopulations, unknown covariate shifts, or unmodeled temporal effects. We\ndevelop and analyze a distributionally robust stochastic optimization (DRO)\nframework that learns a model providing good performance against perturbations\nto the data-generating distribution. We give a convex formulation for the\nproblem, providing several convergence guarantees. We prove finite-sample\nminimax upper and lower bounds, showing that distributional robustness\nsometimes comes at a cost in convergence rates. We give limit theorems for the\nlearned parameters, where we fully specify the limiting distribution so that\nconfidence intervals can be computed. On real tasks including generalizing to\nunknown subpopulations, fine-grained recognition, and providing good tail\nperformance, the distributionally robust approach often exhibits improved\nperformance.\n", "versions": [{"version": "v1", "created": "Sat, 20 Oct 2018 03:50:29 GMT"}, {"version": "v2", "created": "Tue, 20 Nov 2018 20:59:12 GMT"}, {"version": "v3", "created": "Thu, 25 Apr 2019 02:39:04 GMT"}, {"version": "v4", "created": "Fri, 15 Nov 2019 05:24:31 GMT"}, {"version": "v5", "created": "Mon, 6 Jul 2020 16:58:54 GMT"}, {"version": "v6", "created": "Sat, 18 Jul 2020 01:20:20 GMT"}], "update_date": "2020-07-21", "authors_parsed": [["Duchi", "John", ""], ["Namkoong", "Hongseok", ""]]}, {"id": "1810.08754", "submitter": "Yuwei Fan", "authors": "Yuwei Fan and Cindy Orozco Bohorquez and Lexing Ying", "title": "BCR-Net: a neural network based on the nonstandard wavelet form", "comments": "17 pages and 9 figures", "journal-ref": null, "doi": "10.1016/j.jcp.2019.02.002", "report-no": null, "categories": "math.NA cs.LG eess.SP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper proposes a novel neural network architecture inspired by the\nnonstandard form proposed by Beylkin, Coifman, and Rokhlin in [Communications\non Pure and Applied Mathematics, 44(2), 141-183]. The nonstandard form is a\nhighly effective wavelet-based compression scheme for linear integral\noperators. In this work, we first represent the matrix-vector product algorithm\nof the nonstandard form as a linear neural network where every scale of the\nmultiresolution computation is carried out by a locally connected linear\nsub-network. In order to address nonlinear problems, we propose an extension,\ncalled BCR-Net, by replacing each linear sub-network with a deeper and more\npowerful nonlinear one. Numerical results demonstrate the efficiency of the new\narchitecture by approximating nonlinear maps that arise in homogenization\ntheory and stochastic computation.\n", "versions": [{"version": "v1", "created": "Sat, 20 Oct 2018 05:57:38 GMT"}], "update_date": "2019-03-27", "authors_parsed": [["Fan", "Yuwei", ""], ["Bohorquez", "Cindy Orozco", ""], ["Ying", "Lexing", ""]]}, {"id": "1810.08765", "submitter": "Wen-Hao Chen", "authors": "Wen-Hao Chen, Chin-Chi Hsu, Yi-An Lai, Vincent Liu, Mi-Yen Yeh,\n  Shou-De Lin", "title": "Attribute-aware Collaborative Filtering: Survey and Classification", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Attribute-aware CF models aims at rating prediction given not only the\nhistorical rating from users to items, but also the information associated with\nusers (e.g. age), items (e.g. price), or even ratings (e.g. rating time). This\npaper surveys works in the past decade developing attribute-aware CF systems,\nand discovered that mathematically they can be classified into four different\ncategories. We provide the readers not only the high level mathematical\ninterpretation of the existing works in this area but also the mathematical\ninsight for each category of models. Finally we provide in-depth experiment\nresults comparing the effectiveness of the major works in each category.\n", "versions": [{"version": "v1", "created": "Sat, 20 Oct 2018 07:29:52 GMT"}], "update_date": "2018-10-23", "authors_parsed": [["Chen", "Wen-Hao", ""], ["Hsu", "Chin-Chi", ""], ["Lai", "Yi-An", ""], ["Liu", "Vincent", ""], ["Yeh", "Mi-Yen", ""], ["Lin", "Shou-De", ""]]}, {"id": "1810.08802", "submitter": "Mehdi Drissi", "authors": "Mehdi Drissi, Olivia Watkins, Jugal Kalita", "title": "Hierarchical Text Generation using an Outline", "comments": "8 pages, Accepted to International Conference on Natural Language\n  Processing", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Many challenges in natural language processing require generating text,\nincluding language translation, dialogue generation, and speech recognition.\nFor all of these problems, text generation becomes more difficult as the text\nbecomes longer. Current language models often struggle to keep track of\ncoherence for long pieces of text. Here, we attempt to have the model construct\nand use an outline of the text it generates to keep it focused. We find that\nthe usage of an outline improves perplexity. We do not find that using the\noutline improves human evaluation over a simpler baseline, revealing a\ndiscrepancy in perplexity and human perception. Similarly, hierarchical\ngeneration is not found to improve human evaluation scores.\n", "versions": [{"version": "v1", "created": "Sat, 20 Oct 2018 13:27:04 GMT"}], "update_date": "2018-10-23", "authors_parsed": [["Drissi", "Mehdi", ""], ["Watkins", "Olivia", ""], ["Kalita", "Jugal", ""]]}, {"id": "1810.08810", "submitter": "Aaron Roth", "authors": "Alexandra Chouldechova, Aaron Roth", "title": "The Frontiers of Fairness in Machine Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.DS cs.GT stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The last few years have seen an explosion of academic and popular interest in\nalgorithmic fairness. Despite this interest and the volume and velocity of work\nthat has been produced recently, the fundamental science of fairness in machine\nlearning is still in a nascent state. In March 2018, we convened a group of\nexperts as part of a CCC visioning workshop to assess the state of the field,\nand distill the most promising research directions going forward. This report\nsummarizes the findings of that workshop. Along the way, it surveys recent\ntheoretical work in the field and points towards promising directions for\nresearch.\n", "versions": [{"version": "v1", "created": "Sat, 20 Oct 2018 14:24:05 GMT"}], "update_date": "2018-10-23", "authors_parsed": [["Chouldechova", "Alexandra", ""], ["Roth", "Aaron", ""]]}, {"id": "1810.08851", "submitter": "Jing Li", "authors": "Jing Li, Rafal K. Mantiuk, Junle Wang, Suiyi Ling, Patrick Le Callet", "title": "Hybrid-MST: A Hybrid Active Sampling Strategy for Pairwise Preference\n  Aggregation", "comments": "NIPS 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we present a hybrid active sampling strategy for pairwise\npreference aggregation, which aims at recovering the underlying rating of the\ntest candidates from sparse and noisy pairwise labelling. Our method employs\nBayesian optimization framework and Bradley-Terry model to construct the\nutility function, then to obtain the Expected Information Gain (EIG) of each\npair. For computational efficiency, Gaussian-Hermite quadrature is used for\nestimation of EIG. In this work, a hybrid active sampling strategy is proposed,\neither using Global Maximum (GM) EIG sampling or Minimum Spanning Tree (MST)\nsampling in each trial, which is determined by the test budget. The proposed\nmethod has been validated on both simulated and real-world datasets, where it\nshows higher preference aggregation ability than the state-of-the-art methods.\n", "versions": [{"version": "v1", "created": "Sat, 20 Oct 2018 21:31:12 GMT"}], "update_date": "2018-10-23", "authors_parsed": [["Li", "Jing", ""], ["Mantiuk", "Rafal K.", ""], ["Wang", "Junle", ""], ["Ling", "Suiyi", ""], ["Callet", "Patrick Le", ""]]}, {"id": "1810.08867", "submitter": "Alireza Rezaei", "authors": "Shayan Oveis Gharan, Alireza Rezaei", "title": "A Polynomial Time MCMC Method for Sampling from Continuous DPPs", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.DS stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the Gibbs sampling algorithm for continuous determinantal point\nprocesses. We show that, given a warm start, the Gibbs sampler generates a\nrandom sample from a continuous $k$-DPP defined on a $d$-dimensional domain by\nonly taking $\\text{poly}(k)$ number of steps. As an application, we design an\nalgorithm to generate random samples from $k$-DPPs defined by a spherical\nGaussian kernel on a unit sphere in $d$-dimensions, $\\mathbb{S}^{d-1}$ in time\npolynomial in $k,d$.\n", "versions": [{"version": "v1", "created": "Sat, 20 Oct 2018 23:29:40 GMT"}], "update_date": "2018-10-23", "authors_parsed": [["Gharan", "Shayan Oveis", ""], ["Rezaei", "Alireza", ""]]}, {"id": "1810.08869", "submitter": "Ryan Kim", "authors": "Biresh Kumar Joardar, Ryan Gary Kim, Janardhan Rao Doppa, Partha\n  Pratim Pande, Diana Marculescu, and Radu Marculescu", "title": "Learning-based Application-Agnostic 3D NoC Design for Heterogeneous\n  Manycore Systems", "comments": "Published in IEEE Transactions on Computers", "journal-ref": "IEEE Transactions on Computers, vol. 68, no. 6, June 2019", "doi": "10.1109/TC.2018.2889053", "report-no": null, "categories": "cs.DC cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The rising use of deep learning and other big-data algorithms has led to an\nincreasing demand for hardware platforms that are computationally powerful, yet\nenergy-efficient. Due to the amount of data parallelism in these algorithms,\nhigh-performance 3D manycore platforms that incorporate both CPUs and GPUs\npresent a promising direction. However, as systems use heterogeneity (e.g., a\ncombination of CPUs, GPUs, and accelerators) to improve performance and\nefficiency, it becomes more pertinent to address the distinct and likely\nconflicting communication requirements (e.g., CPU memory access latency or GPU\nnetwork throughput) that arise from such heterogeneity. Unfortunately, it is\ndifficult to quickly explore the hardware design space and choose appropriate\ntradeoffs between these heterogeneous requirements. To address these\nchallenges, we propose the design of a 3D Network-on-Chip (NoC) for\nheterogeneous manycore platforms that considers the appropriate design\nobjectives for a 3D heterogeneous system and explores various tradeoffs using\nan efficient ML-based multi-objective optimization technique. The proposed\ndesign space exploration considers the various requirements of its\nheterogeneous components and generates a set of 3D NoC architectures that\nefficiently trades off these design objectives. Our findings show that by\njointly considering these requirements (latency, throughput, temperature, and\nenergy), we can achieve 9.6% better Energy-Delay Product on average at nearly\niso-temperature conditions when compared to a thermally-optimized design for 3D\nheterogeneous NoCs. More importantly, our results suggest that our 3D NoCs\noptimized for a few applications can be generalized for unknown applications as\nwell. Our results show that these generalized 3D NoCs only incur a 1.8%\n(36-tile system) and 1.1% (64-tile system) average performance loss compared to\napplication-specific NoCs.\n", "versions": [{"version": "v1", "created": "Sat, 20 Oct 2018 23:46:14 GMT"}, {"version": "v2", "created": "Sat, 5 Oct 2019 15:06:54 GMT"}], "update_date": "2019-10-08", "authors_parsed": [["Joardar", "Biresh Kumar", ""], ["Kim", "Ryan Gary", ""], ["Doppa", "Janardhan Rao", ""], ["Pande", "Partha Pratim", ""], ["Marculescu", "Diana", ""], ["Marculescu", "Radu", ""]]}, {"id": "1810.08875", "submitter": "Masun Nabhan Homsi", "authors": "Philip Warrick and Masun Nabhan Homsi", "title": "Sleep Arousal Detection from Polysomnography using the Scattering\n  Transform and Recurrent Neural Networks", "comments": "Computing in Cardiology 2018, 4 pages and 5 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG eess.SP stat.ML", "license": "http://creativecommons.org/publicdomain/zero/1.0/", "abstract": "  Sleep disorders are implicated in a growing number of health problems. In\nthis paper, we present a signal-processing/machine learning approach to\ndetecting arousals in the multi-channel polysomnographic recordings of the\nPhysionet/CinC Challenge2018 dataset.\n  Methods: Our network architecture consists of two components. Inputs were\npresented to a Scattering Transform (ST) representation layer which fed a\nrecurrent neural network for sequence learning using three layers of Long\nShort-Term Memory (LSTM). The STs were calculated for each signal with\ndownsampling parameters chosen to give approximately 1 s time resolution,\nresulting in an eighteen-fold data reduction. The LSTM layers then operated at\nthis downsampled rate.\n  Results: The proposed approach detected arousal regions on the 10% random\nsample of the hidden test set with an AUROC of 88.0% and an AUPRC of 42.1%.\n", "versions": [{"version": "v1", "created": "Sun, 21 Oct 2018 00:42:58 GMT"}], "update_date": "2018-10-23", "authors_parsed": [["Warrick", "Philip", ""], ["Homsi", "Masun Nabhan", ""]]}, {"id": "1810.08899", "submitter": "Jie Ren", "authors": "Qing Qin, Jie Ren, Jialong Yu, Ling Gao, Hai Wang, Jie Zheng, Yansong\n  Feng, Jianbin Fang, Zheng Wang", "title": "To Compress, or Not to Compress: Characterizing Deep Learning Model\n  Compression for Embedded Inference", "comments": "8 pages, To appear in ISPA 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.DC cs.PF stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The recent advances in deep neural networks (DNNs) make them attractive for\nembedded systems. However, it can take a long time for DNNs to make an\ninference on resource-constrained computing devices. Model compression\ntechniques can address the computation issue of deep inference on embedded\ndevices. This technique is highly attractive, as it does not rely on\nspecialized hardware, or computation-offloading that is often infeasible due to\nprivacy concerns or high latency. However, it remains unclear how model\ncompression techniques perform across a wide range of DNNs. To design efficient\nembedded deep learning solutions, we need to understand their behaviors. This\nwork develops a quantitative approach to characterize model compression\ntechniques on a representative embedded deep learning architecture, the NVIDIA\nJetson Tx2. We perform extensive experiments by considering 11 influential\nneural network architectures from the image classification and the natural\nlanguage processing domains. We experimentally show that how two mainstream\ncompression techniques, data quantization and pruning, perform on these network\narchitectures and the implications of compression techniques to the model\nstorage size, inference time, energy consumption and performance metrics. We\ndemonstrate that there are opportunities to achieve fast deep inference on\nembedded systems, but one must carefully choose the compression settings. Our\nresults provide insights on when and how to apply model compression techniques\nand guidelines for designing efficient embedded deep learning systems.\n", "versions": [{"version": "v1", "created": "Sun, 21 Oct 2018 05:09:45 GMT"}], "update_date": "2018-10-23", "authors_parsed": [["Qin", "Qing", ""], ["Ren", "Jie", ""], ["Yu", "Jialong", ""], ["Gao", "Ling", ""], ["Wang", "Hai", ""], ["Zheng", "Jie", ""], ["Feng", "Yansong", ""], ["Fang", "Jianbin", ""], ["Wang", "Zheng", ""]]}, {"id": "1810.08907", "submitter": "Bin Shi", "authors": "Bin Shi, Simon S. Du, Michael I. Jordan, Weijie J. Su", "title": "Understanding the Acceleration Phenomenon via High-Resolution\n  Differential Equations", "comments": "82 pages, 11 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.OC cs.LG math.CA math.NA stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Gradient-based optimization algorithms can be studied from the perspective of\nlimiting ordinary differential equations (ODEs). Motivated by the fact that\nexisting ODEs do not distinguish between two fundamentally different\nalgorithms---Nesterov's accelerated gradient method for strongly convex\nfunctions (NAG-SC) and Polyak's heavy-ball method---we study an alternative\nlimiting process that yields high-resolution ODEs. We show that these ODEs\npermit a general Lyapunov function framework for the analysis of convergence in\nboth continuous and discrete time. We also show that these ODEs are more\naccurate surrogates for the underlying algorithms; in particular, they not only\ndistinguish between NAG-SC and Polyak's heavy-ball method, but they allow the\nidentification of a term that we refer to as \"gradient correction\" that is\npresent in NAG-SC but not in the heavy-ball method and is responsible for the\nqualitative difference in convergence of the two methods. We also use the\nhigh-resolution ODE framework to study Nesterov's accelerated gradient method\nfor (non-strongly) convex functions, uncovering a hitherto unknown\nresult---that NAG-C minimizes the squared gradient norm at an inverse cubic\nrate. Finally, by modifying the high-resolution ODE of NAG-C, we obtain a\nfamily of new optimization methods that are shown to maintain the accelerated\nconvergence rates of NAG-C for smooth convex functions.\n", "versions": [{"version": "v1", "created": "Sun, 21 Oct 2018 07:34:09 GMT"}, {"version": "v2", "created": "Sat, 27 Oct 2018 05:26:04 GMT"}, {"version": "v3", "created": "Thu, 1 Nov 2018 19:10:45 GMT"}], "update_date": "2018-11-05", "authors_parsed": [["Shi", "Bin", ""], ["Du", "Simon S.", ""], ["Jordan", "Michael I.", ""], ["Su", "Weijie J.", ""]]}, {"id": "1810.08921", "submitter": "Maximilian Stark", "authors": "Maximilian Stark, Jan Lewandowsky, Souradip Saha, Gerhard Bauch", "title": "Decoding of Non-Binary LDPC Codes Using the Information Bottleneck\n  Method", "comments": "This paper has been presented at IEEE International Conference on\n  Communications (ICC'19) in Shanghai", "journal-ref": null, "doi": "10.1109/ICC.2019.8761712", "report-no": null, "categories": "cs.IT cs.LG math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recently, a novel lookup table based decoding method for binary low-density\nparity-check codes has attracted considerable attention. In this approach,\nmutual-information maximizing lookup tables replace the conventional operations\nof the variable nodes and the check nodes in message passing decoding.\nMoreover, the exchanged messages are represented by integers with very small\nbit width. A machine learning framework termed the information bottleneck\nmethod is used to design the corresponding lookup tables. In this paper, we\nextend this decoding principle from binary to non-binary codes. This is not a\nstraightforward extension, but requires a more sophisticated lookup table\ndesign to cope with the arithmetic in higher order Galois fields. Provided bit\nerror rate simulations show that our proposed scheme outperforms the log-max\ndecoding algorithm and operates close to sum-product decoding.\n", "versions": [{"version": "v1", "created": "Sun, 21 Oct 2018 09:49:13 GMT"}, {"version": "v2", "created": "Sat, 23 Feb 2019 18:15:45 GMT"}, {"version": "v3", "created": "Wed, 23 Oct 2019 07:31:03 GMT"}], "update_date": "2019-10-24", "authors_parsed": [["Stark", "Maximilian", ""], ["Lewandowsky", "Jan", ""], ["Saha", "Souradip", ""], ["Bauch", "Gerhard", ""]]}, {"id": "1810.08923", "submitter": "Ehsan Hoseinzade", "authors": "Ehsan Hoseinzade, Saman Haratizadeh", "title": "CNNPred: CNN-based stock market prediction using several data sources", "comments": "39 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CE cs.NE q-fin.CP stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Feature extraction from financial data is one of the most important problems\nin market prediction domain for which many approaches have been suggested.\nAmong other modern tools, convolutional neural networks (CNN) have recently\nbeen applied for automatic feature selection and market prediction. However, in\nexperiments reported so far, less attention has been paid to the correlation\namong different markets as a possible source of information for extracting\nfeatures. In this paper, we suggest a CNN-based framework with specially\ndesigned CNNs, that can be applied on a collection of data from a variety of\nsources, including different markets, in order to extract features for\npredicting the future of those markets. The suggested framework has been\napplied for predicting the next day's direction of movement for the indices of\nS&P 500, NASDAQ, DJI, NYSE, and RUSSELL markets based on various sets of\ninitial features. The evaluations show a significant improvement in\nprediction's performance compared to the state of the art baseline algorithms.\n", "versions": [{"version": "v1", "created": "Sun, 21 Oct 2018 10:34:56 GMT"}], "update_date": "2018-10-23", "authors_parsed": [["Hoseinzade", "Ehsan", ""], ["Haratizadeh", "Saman", ""]]}, {"id": "1810.08926", "submitter": "Adish Singla", "authors": "Luis Haug, Sebastian Tschiatschek, Adish Singla", "title": "Teaching Inverse Reinforcement Learners via Features and Demonstrations", "comments": "NeurIPS'2018 (extended version)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Learning near-optimal behaviour from an expert's demonstrations typically\nrelies on the assumption that the learner knows the features that the true\nreward function depends on. In this paper, we study the problem of learning\nfrom demonstrations in the setting where this is not the case, i.e., where\nthere is a mismatch between the worldviews of the learner and the expert. We\nintroduce a natural quantity, the teaching risk, which measures the potential\nsuboptimality of policies that look optimal to the learner in this setting. We\nshow that bounds on the teaching risk guarantee that the learner is able to\nfind a near-optimal policy using standard algorithms based on inverse\nreinforcement learning. Based on these findings, we suggest a teaching scheme\nin which the expert can decrease the teaching risk by updating the learner's\nworldview, and thus ultimately enable her to find a near-optimal policy.\n", "versions": [{"version": "v1", "created": "Sun, 21 Oct 2018 10:44:22 GMT"}, {"version": "v2", "created": "Tue, 23 Oct 2018 21:37:28 GMT"}, {"version": "v3", "created": "Thu, 29 Nov 2018 17:17:31 GMT"}, {"version": "v4", "created": "Wed, 27 Mar 2019 11:14:44 GMT"}], "update_date": "2019-03-28", "authors_parsed": [["Haug", "Luis", ""], ["Tschiatschek", "Sebastian", ""], ["Singla", "Adish", ""]]}, {"id": "1810.08940", "submitter": "Hyeryung Jang", "authors": "Hyeryung Jang and Osvaldo Simeone", "title": "Training Dynamic Exponential Family Models with Causal and Lateral\n  Dependencies for Generalized Neuromorphic Computing", "comments": "Published in IEEE ICASSP 2019. Author's Accepted Manuscript", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.IT eess.SP math.IT stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Neuromorphic hardware platforms, such as Intel's Loihi chip, support the\nimplementation of Spiking Neural Networks (SNNs) as an energy-efficient\nalternative to Artificial Neural Networks (ANNs). SNNs are networks of neurons\nwith internal analogue dynamics that communicate by means of binary time\nseries. In this work, a probabilistic model is introduced for a generalized\nset-up in which the synaptic time series can take values in an arbitrary\nalphabet and are characterized by both causal and instantaneous statistical\ndependencies. The model, which can be considered as an extension of exponential\nfamily harmoniums to time series, is introduced by means of a hybrid\ndirected-undirected graphical representation. Furthermore, distributed learning\nrules are derived for Maximum Likelihood and Bayesian criteria under the\nassumption of fully observed time series in the training set.\n", "versions": [{"version": "v1", "created": "Sun, 21 Oct 2018 13:27:55 GMT"}, {"version": "v2", "created": "Tue, 23 Oct 2018 11:06:37 GMT"}, {"version": "v3", "created": "Wed, 18 Dec 2019 14:43:42 GMT"}], "update_date": "2019-12-19", "authors_parsed": [["Jang", "Hyeryung", ""], ["Simeone", "Osvaldo", ""]]}, {"id": "1810.08955", "submitter": "Jiawen Liu", "authors": "Jiawen Liu, Dong Li, Gokcen Kestor, Jeffrey Vetter", "title": "Runtime Concurrency Control and Operation Scheduling for High\n  Performance Neural Network Training", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Training neural network often uses a machine learning framework such as\nTensorFlow and Caffe2. These frameworks employ a dataflow model where the NN\ntraining is modeled as a directed graph composed of a set of nodes. Operations\nin neural network training are typically implemented by the frameworks as\nprimitives and represented as nodes in the dataflow graph. Training NN models\nin a dataflow-based machine learning framework involves a large number of\nfine-grained operations. Those operations have diverse memory access patterns\nand computation intensity. How to manage and schedule those operations is\nchallenging, because we have to decide the number of threads to run each\noperation (concurrency control) and schedule those operations for good hardware\nutilization and system throughput.\n  In this paper, we extend an existing runtime system (the TensorFlow runtime)\nto enable automatic concurrency control and scheduling of operations. We\nexplore performance modeling to predict the performance of operations with\nvarious thread-level parallelism. Our performance model is highly accurate and\nlightweight. Leveraging the performance model, our runtime system employs a set\nof scheduling strategies that co-run operations to improve hardware utilization\nand system throughput. Our runtime system demonstrates a big performance\nbenefit. Comparing with using the recommended configurations for concurrency\ncontrol and operation scheduling in TensorFlow, our approach achieves 33%\nperformance (execution time) improvement on average (up to 49%) for three\nneural network models, and achieves high performance closing to the optimal one\nmanually obtained by the user.\n", "versions": [{"version": "v1", "created": "Sun, 21 Oct 2018 14:18:03 GMT"}, {"version": "v2", "created": "Tue, 19 Feb 2019 01:15:36 GMT"}], "update_date": "2019-02-20", "authors_parsed": [["Liu", "Jiawen", ""], ["Li", "Dong", ""], ["Kestor", "Gokcen", ""], ["Vetter", "Jeffrey", ""]]}, {"id": "1810.08985", "submitter": "Abhishek Dubey", "authors": "Sanchita Basak, Saptarshi Sengupta, Abhishek Dubey", "title": "Mechanisms for Integrated Feature Normalization and Remaining Useful\n  Life Estimation Using LSTMs Applied to Hard-Disks", "comments": "9 pages, 13 figures, 2 tables", "journal-ref": "Proceedings of IEEE Smartcomp 2019", "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  With emerging smart communities, improving overall system availability is\nbecoming a major concern. In order to improve the reliability of the components\nin a system we propose an inference model to predict Remaining Useful Life\n(RUL) of those components. In this paper we work with components of backend\ndata servers such as hard disks, that are subject to degradation. A Deep\nLong-Short Term Memory (LSTM) Network is used as the backbone of this fast,\ndata-driven decision framework and dynamically captures the pattern of the\nincoming data. In the article, we discuss the architecture of the neural\nnetwork and describe the mechanisms to choose the various hyper-parameters.\nFurther, we describe the challenges faced in extracting effective training sets\nfrom highly unorganized and class-imbalanced big data and establish methods for\nonline predictions with extensive data pre-processing, feature extraction and\nvalidation through online simulation sets with unknown remaining useful lives\nof the hard disks. Our algorithm performs especially well in predicting RUL\nnear the critical zone of a device approaching failure. With the proposed\napproach we are able to predict whether a disk is going to fail in next ten\ndays with an average precision of 0.8435. We also show that the architecture\ntrained on a particular model can be used to predict RUL for devices in\ndifferent models from same manufacturer through transfer learning.\n", "versions": [{"version": "v1", "created": "Sun, 21 Oct 2018 16:24:46 GMT"}, {"version": "v2", "created": "Tue, 12 Feb 2019 08:57:58 GMT"}, {"version": "v3", "created": "Mon, 17 Jun 2019 00:41:38 GMT"}], "update_date": "2019-06-18", "authors_parsed": [["Basak", "Sanchita", ""], ["Sengupta", "Saptarshi", ""], ["Dubey", "Abhishek", ""]]}, {"id": "1810.09006", "submitter": "Anru R. Zhang", "authors": "Anru R. Zhang and Yuchen Zhou", "title": "On the Non-asymptotic and Sharp Lower Tail Bounds of Random Variables", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.PR cs.LG math.ST stat.TH", "license": "http://creativecommons.org/licenses/by-sa/4.0/", "abstract": "  The non-asymptotic tail bounds of random variables play crucial roles in\nprobability, statistics, and machine learning. Despite much success in\ndeveloping upper bounds on tail probability in literature, the lower bounds on\ntail probabilities are relatively fewer. In this paper, we introduce systematic\nand user-friendly schemes for developing non-asymptotic lower bounds of tail\nprobabilities. In addition, we develop sharp lower tail bounds for the sum of\nindependent sub-Gaussian and sub-exponential random variables, which match the\nclassic Hoeffding-type and Bernstein-type concentration inequalities,\nrespectively. We also provide non-asymptotic matching upper and lower tail\nbounds for a suite of distributions, including gamma, beta, (regular, weighted,\nand noncentral) chi-square, binomial, Poisson, Irwin-Hall, etc. We apply the\nresult to establish the matching upper and lower bounds for extreme value\nexpectation of the sum of independent sub-Gaussian and sub-exponential random\nvariables. A statistical application of signal identification from sparse\nheterogeneous mixtures is finally considered.\n", "versions": [{"version": "v1", "created": "Sun, 21 Oct 2018 18:47:38 GMT"}, {"version": "v2", "created": "Fri, 4 Jan 2019 17:40:08 GMT"}, {"version": "v3", "created": "Sat, 5 Sep 2020 02:12:17 GMT"}], "update_date": "2020-09-08", "authors_parsed": [["Zhang", "Anru R.", ""], ["Zhou", "Yuchen", ""]]}, {"id": "1810.09026", "submitter": "Marc Lanctot", "authors": "Sriram Srinivasan, Marc Lanctot, Vinicius Zambaldi, Julien Perolat,\n  Karl Tuyls, Remi Munos, Michael Bowling", "title": "Actor-Critic Policy Optimization in Partially Observable Multiagent\n  Environments", "comments": "NeurIPS 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.GT cs.MA stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Optimization of parameterized policies for reinforcement learning (RL) is an\nimportant and challenging problem in artificial intelligence. Among the most\ncommon approaches are algorithms based on gradient ascent of a score function\nrepresenting discounted return. In this paper, we examine the role of these\npolicy gradient and actor-critic algorithms in partially-observable multiagent\nenvironments. We show several candidate policy update rules and relate them to\na foundation of regret minimization and multiagent learning techniques for the\none-shot and tabular cases, leading to previously unknown convergence\nguarantees. We apply our method to model-free multiagent reinforcement learning\nin adversarial sequential decision problems (zero-sum imperfect information\ngames), using RL-style function approximation. We evaluate on commonly used\nbenchmark Poker domains, showing performance against fixed policies and\nempirical convergence to approximate Nash equilibria in self-play with rates\nsimilar to or better than a baseline model-free algorithm for zero sum games,\nwithout any domain-specific state space reductions.\n", "versions": [{"version": "v1", "created": "Sun, 21 Oct 2018 21:01:49 GMT"}, {"version": "v2", "created": "Wed, 7 Nov 2018 04:41:14 GMT"}, {"version": "v3", "created": "Tue, 27 Nov 2018 23:16:33 GMT"}, {"version": "v4", "created": "Sat, 19 Oct 2019 15:23:13 GMT"}, {"version": "v5", "created": "Fri, 12 Jun 2020 04:32:01 GMT"}], "update_date": "2020-06-15", "authors_parsed": [["Srinivasan", "Sriram", ""], ["Lanctot", "Marc", ""], ["Zambaldi", "Vinicius", ""], ["Perolat", "Julien", ""], ["Tuyls", "Karl", ""], ["Munos", "Remi", ""], ["Bowling", "Michael", ""]]}, {"id": "1810.09028", "submitter": "Michael Schaarschmidt", "authors": "Michael Schaarschmidt, Sven Mika, Kai Fricke, Eiko Yoneki", "title": "RLgraph: Modular Computation Graphs for Deep Reinforcement Learning", "comments": "SysML 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Reinforcement learning (RL) tasks are challenging to implement, execute and\ntest due to algorithmic instability, hyper-parameter sensitivity, and\nheterogeneous distributed communication patterns. We argue for the separation\nof logical component composition, backend graph definition, and distributed\nexecution. To this end, we introduce RLgraph, a library for designing and\nexecuting reinforcement learning tasks in both static graph and define-by-run\nparadigms. The resulting implementations are robust, incrementally testable,\nand yield high performance across different deep learning frameworks and\ndistributed backends.\n", "versions": [{"version": "v1", "created": "Sun, 21 Oct 2018 21:12:06 GMT"}, {"version": "v2", "created": "Thu, 28 Feb 2019 19:32:08 GMT"}], "update_date": "2019-03-04", "authors_parsed": [["Schaarschmidt", "Michael", ""], ["Mika", "Sven", ""], ["Fricke", "Kai", ""], ["Yoneki", "Eiko", ""]]}, {"id": "1810.09038", "submitter": "Kenji Kawaguchi", "authors": "Kenji Kawaguchi, Yoshua Bengio", "title": "Depth with Nonlinearity Creates No Bad Local Minima in ResNets", "comments": null, "journal-ref": "Neural Networks, volume 118, pages 167-174 (2019)", "doi": "10.1016/j.neunet.2019.06.009", "report-no": null, "categories": "stat.ML cs.AI cs.LG math.OC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we prove that depth with nonlinearity creates no bad local\nminima in a type of arbitrarily deep ResNets with arbitrary nonlinear\nactivation functions, in the sense that the values of all local minima are no\nworse than the global minimum value of corresponding classical machine-learning\nmodels, and are guaranteed to further improve via residual representations. As\na result, this paper provides an affirmative answer to an open question stated\nin a paper in the conference on Neural Information Processing Systems 2018.\nThis paper advances the optimization theory of deep learning only for ResNets\nand not for other network architectures.\n", "versions": [{"version": "v1", "created": "Sun, 21 Oct 2018 22:38:32 GMT"}, {"version": "v2", "created": "Wed, 19 Jun 2019 16:50:26 GMT"}, {"version": "v3", "created": "Tue, 9 Jul 2019 14:59:54 GMT"}], "update_date": "2019-07-10", "authors_parsed": [["Kawaguchi", "Kenji", ""], ["Bengio", "Yoshua", ""]]}, {"id": "1810.09043", "submitter": "Nikhil Galagali", "authors": "Nikhil Galagali and Minnan Xu-Wilson", "title": "Patient Subtyping with Disease Progression and Irregular Observation\n  Trajectories", "comments": "Machine Learning for Health (ML4H) Workshop at NeurIPS 2018\n  arXiv:1811.07216", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Patient subtyping based on temporal observations can lead to significantly\nnuanced subtyping that acknowledges the dynamic characteristics of diseases.\nExisting methods for subtyping trajectories treat the evolution of clinical\nobservations as a homogeneous process or employ data available at regular\nintervals. In reality, diseases may have transient underlying states and a\nstate-dependent observation pattern. In our paper, we present an approach to\nsubtype irregular patient data while acknowledging the underlying progression\nof disease states. Our approach consists of two components: a probabilistic\nmodel to determine the likelihood of a patient's observation trajectory and a\nmixture model to measure similarity between asynchronous patient trajectories.\nWe demonstrate our model by discovering subtypes of progression to hemodynamic\ninstability (requiring cardiovascular intervention) in a patient cohort from a\nmulti-institution ICU dataset. We find three primary patterns: two of which\nshow classic signs of decompensation (rising heart rate with dropping blood\npressure), with one of these showing a faster course of decompensation than the\nother. The third pattern has transient period of low heart rate and blood\npressure. We also show that our model results in a 13% reduction in average\ncross-entropy error compared to a model with no state progression when\nforecasting vital signs.\n", "versions": [{"version": "v1", "created": "Sun, 21 Oct 2018 23:46:38 GMT"}, {"version": "v2", "created": "Thu, 1 Nov 2018 15:59:49 GMT"}, {"version": "v3", "created": "Thu, 22 Nov 2018 18:45:08 GMT"}, {"version": "v4", "created": "Wed, 28 Nov 2018 22:06:14 GMT"}], "update_date": "2018-11-30", "authors_parsed": [["Galagali", "Nikhil", ""], ["Xu-Wilson", "Minnan", ""]]}, {"id": "1810.09071", "submitter": "Kar-Ann Toh", "authors": "Kar-Ann Toh", "title": "Learning from the Kernel and the Range Space", "comments": "Camera-ready finalized on 22 April 2018, paper presented on 07 June\n  2018 in the 17th IEEE/ACIS International Conference on Computer and\n  Information Science (ICIS) 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this article, a novel approach to learning a complex function which can be\nwritten as the system of linear equations is introduced. This learning is\ngrounded upon the observation that solving the system of linear equations by a\nmanipulation in the kernel and the range space boils down to an estimation\nbased on the least squares error approximation. The learning approach is\napplied to learn a deep feedforward network with full weight connections. The\nnumerical experiments on network learning of synthetic and benchmark data not\nonly show feasibility of the proposed learning approach but also provide\ninsights into the mechanism of data representation.\n", "versions": [{"version": "v1", "created": "Mon, 22 Oct 2018 03:35:32 GMT"}], "update_date": "2018-10-23", "authors_parsed": [["Toh", "Kar-Ann", ""]]}, {"id": "1810.09078", "submitter": "Siddhardha Balemarthy", "authors": "Siddhardha Balemarthy, Atul Sajjanhar, James Xi Zheng", "title": "Our Practice Of Using Machine Learning To Recognize Species By Voice", "comments": "16 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SD cs.LG eess.AS stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  As the technology is advancing, audio recognition in machine learning is\nimproved as well. Research in audio recognition has traditionally focused on\nspeech. Living creatures (especially the small ones) are part of the whole\necosystem, monitoring as well as maintaining them are important tasks. Species\nsuch as animals and birds are tending to change their activities as well as\ntheir habitats due to the adverse effects on the environment or due to other\nnatural or man-made calamities. For those in far deserted areas, we will not\nhave any idea about their existence until we can continuously monitor them.\nContinuous monitoring will take a lot of hard work and labor. If there is no\ncontinuous monitoring, then there might be instances where endangered species\nmay encounter dangerous situations. The best way to monitor those species are\nthrough audio recognition. Classifying sound can be a difficult task even for\nhumans. Powerful audio signals and their processing techniques make it possible\nto detect audio of various species. There might be many ways wherein audio\nrecognition can be done. We can train machines either by pre-recorded audio\nfiles or by recording them live and detecting them. The audio of species can be\ndetected by removing all the background noise and echoes. Smallest sound is\nconsidered as a syllable. Extracting various syllables is the process we are\nfocusing on which is known as audio recognition in terms of Machine Learning\n(ML).\n", "versions": [{"version": "v1", "created": "Mon, 22 Oct 2018 04:23:17 GMT"}], "update_date": "2018-10-23", "authors_parsed": [["Balemarthy", "Siddhardha", ""], ["Sajjanhar", "Atul", ""], ["Zheng", "James Xi", ""]]}, {"id": "1810.09079", "submitter": "Tianyi Lin", "authors": "Tianyi Lin, Zhiyue Hu and Xin Guo", "title": "Sparsemax and Relaxed Wasserstein for Topic Sparsity", "comments": "10 Pages. To appear in WSDM 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.IR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Topic sparsity refers to the observation that individual documents usually\nfocus on several salient topics instead of covering a wide variety of topics,\nand a real topic adopts a narrow range of terms instead of a wide coverage of\nthe vocabulary. Understanding this topic sparsity is especially important for\nanalyzing user-generated web content and social media, which are featured in\nthe form of extremely short posts and discussions. As topic sparsity of\nindividual documents in online social media increases, so does the difficulty\nof analyzing the online text sources using traditional methods.\n  In this paper, we propose two novel neural models by providing sparse\nposterior distributions over topics based on the Gaussian sparsemax\nconstruction, enabling efficient training by stochastic backpropagation. We\nconstruct an inference network conditioned on the input data and infer the\nvariational distribution with the relaxed Wasserstein (RW) divergence. Unlike\nexisting works based on Gaussian softmax construction and Kullback-Leibler (KL)\ndivergence, our approaches can identify latent topic sparsity with training\nstability, predictive performance, and topic coherence. Experiments on\ndifferent genres of large text corpora have demonstrated the effectiveness of\nour models as they outperform both probabilistic and neural methods.\n", "versions": [{"version": "v1", "created": "Mon, 22 Oct 2018 04:23:44 GMT"}, {"version": "v2", "created": "Wed, 28 Nov 2018 10:22:18 GMT"}], "update_date": "2018-11-29", "authors_parsed": [["Lin", "Tianyi", ""], ["Hu", "Zhiyue", ""], ["Guo", "Xin", ""]]}, {"id": "1810.09092", "submitter": "Xuezhou Zhang", "authors": "Xuezhou Zhang, Sarah Tan, Paul Koch, Yin Lou, Urszula Chajewska, Rich\n  Caruana", "title": "Axiomatic Interpretability for Multiclass Additive Models", "comments": "KDD 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Generalized additive models (GAMs) are favored in many regression and binary\nclassification problems because they are able to fit complex, nonlinear\nfunctions while still remaining interpretable. In the first part of this paper,\nwe generalize a state-of-the-art GAM learning algorithm based on boosted trees\nto the multiclass setting, and show that this multiclass algorithm outperforms\nexisting GAM learning algorithms and sometimes matches the performance of full\ncomplexity models such as gradient boosted trees.\n  In the second part, we turn our attention to the interpretability of GAMs in\nthe multiclass setting. Surprisingly, the natural interpretability of GAMs\nbreaks down when there are more than two classes. Naive interpretation of\nmulticlass GAMs can lead to false conclusions. Inspired by binary GAMs, we\nidentify two axioms that any additive model must satisfy in order to not be\nvisually misleading. We then develop a technique called Additive\nPost-Processing for Interpretability (API), that provably transforms a\npre-trained additive model to satisfy the interpretability axioms without\nsacrificing accuracy. The technique works not just on models trained with our\nlearning algorithm, but on any multiclass additive model, including multiclass\nlinear and logistic regression. We demonstrate the effectiveness of API on a\n12-class infant mortality dataset.\n", "versions": [{"version": "v1", "created": "Mon, 22 Oct 2018 05:40:05 GMT"}, {"version": "v2", "created": "Thu, 30 May 2019 23:11:55 GMT"}], "update_date": "2019-06-03", "authors_parsed": [["Zhang", "Xuezhou", ""], ["Tan", "Sarah", ""], ["Koch", "Paul", ""], ["Lou", "Yin", ""], ["Chajewska", "Urszula", ""], ["Caruana", "Rich", ""]]}, {"id": "1810.09098", "submitter": "Christopher Aicher", "authors": "Christopher Aicher, Yi-An Ma, Nicholas J. Foti, and Emily B. Fox", "title": "Stochastic Gradient MCMC for State Space Models", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG stat.CO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  State space models (SSMs) are a flexible approach to modeling complex time\nseries. However, inference in SSMs is often computationally prohibitive for\nlong time series. Stochastic gradient MCMC (SGMCMC) is a popular method for\nscalable Bayesian inference for large independent data. Unfortunately when\napplied to dependent data, such as in SSMs, SGMCMC's stochastic gradient\nestimates are biased as they break crucial temporal dependencies. To alleviate\nthis, we propose stochastic gradient estimators that control this bias by\nperforming additional computation in a `buffer' to reduce breaking\ndependencies. Furthermore, we derive error bounds for this bias and show a\ngeometric decay under mild conditions. Using these estimators, we develop novel\nSGMCMC samplers for discrete, continuous and mixed-type SSMs with analytic\nmessage passing. Our experiments on real and synthetic data demonstrate the\neffectiveness of our SGMCMC algorithms compared to batch MCMC, allowing us to\nscale inference to long time series with millions of time points.\n", "versions": [{"version": "v1", "created": "Mon, 22 Oct 2018 05:53:22 GMT"}, {"version": "v2", "created": "Tue, 9 Jul 2019 18:09:39 GMT"}], "update_date": "2019-07-11", "authors_parsed": [["Aicher", "Christopher", ""], ["Ma", "Yi-An", ""], ["Foti", "Nicholas J.", ""], ["Fox", "Emily B.", ""]]}, {"id": "1810.09102", "submitter": "Xiaohan Chen", "authors": "Nitin Bansal, Xiaohan Chen, Zhangyang Wang", "title": "Can We Gain More from Orthogonality Regularizations in Training Deep\n  CNNs?", "comments": "11 pages, 1 figure, 2 tables. Accepted in NIPS 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper seeks to answer the question: as the (near-) orthogonality of\nweights is found to be a favorable property for training deep convolutional\nneural networks, how can we enforce it in more effective and easy-to-use ways?\nWe develop novel orthogonality regularizations on training deep CNNs, utilizing\nvarious advanced analytical tools such as mutual coherence and restricted\nisometry property. These plug-and-play regularizations can be conveniently\nincorporated into training almost any CNN without extra hassle. We then\nbenchmark their effects on state-of-the-art models: ResNet, WideResNet, and\nResNeXt, on several most popular computer vision datasets: CIFAR-10, CIFAR-100,\nSVHN and ImageNet. We observe consistent performance gains after applying those\nproposed regularizations, in terms of both the final accuracies achieved, and\nfaster and more stable convergences. We have made our codes and pre-trained\nmodels publicly available:\nhttps://github.com/nbansal90/Can-we-Gain-More-from-Orthogonality.\n", "versions": [{"version": "v1", "created": "Mon, 22 Oct 2018 06:22:54 GMT"}], "update_date": "2018-10-23", "authors_parsed": [["Bansal", "Nitin", ""], ["Chen", "Xiaohan", ""], ["Wang", "Zhangyang", ""]]}, {"id": "1810.09103", "submitter": "Sungsu Lim", "authors": "Sungsu Lim, Ajin Joseph, Lei Le, Yangchen Pan, Martha White", "title": "Actor-Expert: A Framework for using Q-learning in Continuous Action\n  Spaces", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Q-learning can be difficult to use in continuous action spaces, because an\noptimization has to be solved to find the maximal action for the action-values.\nA common strategy has been to restrict the functional form of the action-values\nto be concave in the actions, to simplify the optimization. Such restrictions,\nhowever, can prevent learning accurate action-values. In this work, we propose\na new policy search objective that facilitates using Q-learning and a framework\nto optimize this objective, called Actor-Expert. The Expert uses Q-learning to\nupdate the action-values towards optimal action-values. The Actor learns the\nmaximal actions over time for these changing action-values. We develop a Cross\nEntropy Method (CEM) for the Actor, where such a global optimization approach\nfacilitates use of generically parameterized action-values. This method - which\nwe call Conditional CEM - iteratively concentrates density around maximal\nactions, conditioned on state. We prove that this algorithm tracks the expected\nCEM update, over states with changing action-values. We demonstrate in a toy\nenvironment that previous methods that restrict the action-value\nparameterization fail whereas Actor-Expert with a more general action-value\nparameterization succeeds. Finally, we demonstrate that Actor-Expert performs\nas well as or better than competitors on four benchmark continuous-action\nenvironments.\n", "versions": [{"version": "v1", "created": "Mon, 22 Oct 2018 06:35:03 GMT"}, {"version": "v2", "created": "Sun, 28 Apr 2019 17:34:35 GMT"}], "update_date": "2019-04-30", "authors_parsed": [["Lim", "Sungsu", ""], ["Joseph", "Ajin", ""], ["Le", "Lei", ""], ["Pan", "Yangchen", ""], ["White", "Martha", ""]]}, {"id": "1810.09104", "submitter": "Xiao Yan", "authors": "Xiao Yan, Xinyan Dai, Jie Liu, Kaiwen Zhou, James Cheng", "title": "Norm-Range Partition: A Universal Catalyst for LSH based Maximum Inner\n  Product Search (MIPS)", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recently, locality sensitive hashing (LSH) was shown to be effective for MIPS\nand several algorithms including $L_2$-ALSH, Sign-ALSH and Simple-LSH have been\nproposed. In this paper, we introduce the norm-range partition technique, which\npartitions the original dataset into sub-datasets containing items with similar\n2-norms and builds hash index independently for each sub-dataset. We prove that\nnorm-range partition reduces the query processing complexity for all existing\nLSH based MIPS algorithms under mild conditions. The key to performance\nimprovement is that norm-range partition allows to use smaller normalization\nfactor most sub-datasets. For efficient query processing, we also formulate a\nunified framework to rank the buckets from the hash indexes of different\nsub-datasets. Experiments on real datasets show that norm-range partition\nsignificantly reduces the number of probed for LSH based MIPS algorithms when\nachieving the same recall.\n", "versions": [{"version": "v1", "created": "Mon, 22 Oct 2018 06:36:23 GMT"}, {"version": "v2", "created": "Mon, 5 Nov 2018 12:49:32 GMT"}], "update_date": "2018-11-06", "authors_parsed": [["Yan", "Xiao", ""], ["Dai", "Xinyan", ""], ["Liu", "Jie", ""], ["Zhou", "Kaiwen", ""], ["Cheng", "James", ""]]}, {"id": "1810.09113", "submitter": "Frank Nielsen", "authors": "Frank Nielsen and Richard Nock", "title": "The Bregman chord divergence", "comments": "10 pages", "journal-ref": "GSI 2019: Geometric Science of Information pp 299-308", "doi": "10.1007/978-3-030-26980-7_31", "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Distances are fundamental primitives whose choice significantly impacts the\nperformances of algorithms in machine learning and signal processing. However\nselecting the most appropriate distance for a given task is an endeavor.\nInstead of testing one by one the entries of an ever-expanding dictionary of\n{\\em ad hoc} distances, one rather prefers to consider parametric classes of\ndistances that are exhaustively characterized by axioms derived from first\nprinciples. Bregman divergences are such a class. However fine-tuning a Bregman\ndivergence is delicate since it requires to smoothly adjust a functional\ngenerator. In this work, we propose an extension of Bregman divergences called\nthe Bregman chord divergences. This new class of distances does not require\ngradient calculations, uses two scalar parameters that can be easily tailored\nin applications, and generalizes asymptotically Bregman divergences.\n", "versions": [{"version": "v1", "created": "Mon, 22 Oct 2018 07:11:11 GMT"}], "update_date": "2020-10-01", "authors_parsed": [["Nielsen", "Frank", ""], ["Nock", "Richard", ""]]}, {"id": "1810.09126", "submitter": "L.A. Prashanth", "authors": "Prashanth L.A., Michael Fu", "title": "Risk-Sensitive Reinforcement Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG math.OC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The classic objective in a reinforcement learning (RL) problem is to find a\npolicy that minimizes, in expectation, a long-run objective such as the\ninfinite-horizon cumulative discounted or long-run average cost. In many\npractical applications, optimizing the expected value alone is not sufficient,\nand it may be necessary to include a risk measure in the optimization process,\neither in the objective or as a constraint. Various risk measures have been\nproposed in the literature, e.g., variance, exponential utility, percentile\nperformance, chance constraints, value at risk (quantile), conditional\nvalue-at-risk, coherent risk measure, prospect theory and its later\nenhancement, cumulative prospect theory. In this article, we focus on the\ncombination of risk criteria and reinforcement learning in a constrained\noptimization framework, i.e., a setting where the goal to find a policy that\noptimizes the usual objective of infinite-horizon discounted/average cost,\nwhile ensuring that an explicit risk constraint is satisfied. We introduce the\nrisk-constrained RL framework, cover popular risk measures based on variance,\nconditional value-at-risk, and chance constraints, and present a template for a\nrisk-sensitive RL algorithm. Next, we study risk-sensitive RL with the\nobjective of minimizing risk in an unconstrained framework, and cover\ncumulative prospect theory and coherent risk measures as special cases. We\nsurvey some of the recent work on this topic, covering problems encompassing\ndiscounted cost, average cost, and stochastic shortest path settings, together\nwith the aforementioned risk measures, in constrained as well as unconstrained\nframeworks. This non-exhaustive survey is aimed at giving a flavor of the\nchallenges involved in solving risk-sensitive RL problems, and outlining some\npotential future research directions.\n", "versions": [{"version": "v1", "created": "Mon, 22 Oct 2018 08:01:18 GMT"}, {"version": "v2", "created": "Sat, 24 Apr 2021 19:56:37 GMT"}], "update_date": "2021-04-27", "authors_parsed": [["A.", "Prashanth L.", ""], ["Fu", "Michael", ""]]}, {"id": "1810.09133", "submitter": "Yuma Koizumi Dr.", "authors": "Yuma Koizumi, Shoichiro Saito, Hisashi Uematsum Yuta Kawachi, Noboru\n  Harada", "title": "Unsupervised Detection of Anomalous Sound based on Deep Learning and the\n  Neyman-Pearson Lemma", "comments": "IEEE/ACM Transactions on Audio, Speech, and Language Processing, 2018", "journal-ref": null, "doi": "10.1109/TASLP.2018.2877258", "report-no": null, "categories": "stat.ML cs.LG cs.SD eess.AS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper proposes a novel optimization principle and its implementation for\nunsupervised anomaly detection in sound (ADS) using an autoencoder (AE). The\ngoal of unsupervised-ADS is to detect unknown anomalous sound without training\ndata of anomalous sound. Use of an AE as a normal model is a state-of-the-art\ntechnique for unsupervised-ADS. To decrease the false positive rate (FPR), the\nAE is trained to minimize the reconstruction error of normal sounds and the\nanomaly score is calculated as the reconstruction error of the observed sound.\nUnfortunately, since this training procedure does not take into account the\nanomaly score for anomalous sounds, the true positive rate (TPR) does not\nnecessarily increase. In this study, we define an objective function based on\nthe Neyman-Pearson lemma by considering ADS as a statistical hypothesis test.\nThe proposed objective function trains the AE to maximize the TPR under an\narbitrary low FPR condition. To calculate the TPR in the objective function, we\nconsider that the set of anomalous sounds is the complementary set of normal\nsounds and simulate anomalous sounds by using a rejection sampling algorithm.\nThrough experiments using synthetic data, we found that the proposed method\nimproved the performance measures of ADS under low FPR conditions. In addition,\nwe confirmed that the proposed method could detect anomalous sounds in real\nenvironments.\n", "versions": [{"version": "v1", "created": "Mon, 22 Oct 2018 08:20:59 GMT"}], "update_date": "2018-10-23", "authors_parsed": [["Koizumi", "Yuma", ""], ["Saito", "Shoichiro", ""], ["Kawachi", "Hisashi Uematsum Yuta", ""], ["Harada", "Noboru", ""]]}, {"id": "1810.09136", "submitter": "Eric Nalisnick", "authors": "Eric Nalisnick, Akihiro Matsukawa, Yee Whye Teh, Dilan Gorur, Balaji\n  Lakshminarayanan", "title": "Do Deep Generative Models Know What They Don't Know?", "comments": "ICLR 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A neural network deployed in the wild may be asked to make predictions for\ninputs that were drawn from a different distribution than that of the training\ndata. A plethora of work has demonstrated that it is easy to find or synthesize\ninputs for which a neural network is highly confident yet wrong. Generative\nmodels are widely viewed to be robust to such mistaken confidence as modeling\nthe density of the input features can be used to detect novel,\nout-of-distribution inputs. In this paper we challenge this assumption. We find\nthat the density learned by flow-based models, VAEs, and PixelCNNs cannot\ndistinguish images of common objects such as dogs, trucks, and horses (i.e.\nCIFAR-10) from those of house numbers (i.e. SVHN), assigning a higher\nlikelihood to the latter when the model is trained on the former. Moreover, we\nfind evidence of this phenomenon when pairing several popular image data sets:\nFashionMNIST vs MNIST, CelebA vs SVHN, ImageNet vs CIFAR-10 / CIFAR-100 / SVHN.\nTo investigate this curious behavior, we focus analysis on flow-based\ngenerative models in particular since they are trained and evaluated via the\nexact marginal likelihood. We find such behavior persists even when we restrict\nthe flows to constant-volume transformations. These transformations admit some\ntheoretical analysis, and we show that the difference in likelihoods can be\nexplained by the location and variances of the data and the model curvature.\nOur results caution against using the density estimates from deep generative\nmodels to identify inputs similar to the training distribution until their\nbehavior for out-of-distribution inputs is better understood.\n", "versions": [{"version": "v1", "created": "Mon, 22 Oct 2018 08:32:02 GMT"}, {"version": "v2", "created": "Wed, 5 Dec 2018 19:52:27 GMT"}, {"version": "v3", "created": "Sun, 24 Feb 2019 11:57:32 GMT"}], "update_date": "2019-02-26", "authors_parsed": [["Nalisnick", "Eric", ""], ["Matsukawa", "Akihiro", ""], ["Teh", "Yee Whye", ""], ["Gorur", "Dilan", ""], ["Lakshminarayanan", "Balaji", ""]]}, {"id": "1810.09137", "submitter": "Yuma Koizumi Dr.", "authors": "Yuma Koizumi, Kenta Niwa, Yusuke Hioka, Kazunori Kobayashi, Yoichi\n  Haneda", "title": "DNN-based Source Enhancement to Increase Objective Sound Quality\n  Assessment Score", "comments": null, "journal-ref": "IEEE/ACM Transactions on Audio, Speech, and Language Processing,\n  Vol.26, Issue.10, 2018", "doi": "10.1109/TASLP.2018.2842156", "report-no": null, "categories": "stat.ML cs.LG cs.SD eess.AS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a training method for deep neural network (DNN)-based source\nenhancement to increase objective sound quality assessment (OSQA) scores such\nas the perceptual evaluation of speech quality (PESQ). In many conventional\nstudies, DNNs have been used as a mapping function to estimate time-frequency\nmasks and trained to minimize an analytically tractable objective function such\nas the mean squared error (MSE). Since OSQA scores have been used widely for\nsound-quality evaluation, constructing DNNs to increase OSQA scores would be\nbetter than using the minimum-MSE to create high-quality output signals.\nHowever, since most OSQA scores are not analytically tractable, \\textit{i.e.},\nthey are black boxes, the gradient of the objective function cannot be\ncalculated by simply applying back-propagation. To calculate the gradient of\nthe OSQA-based objective function, we formulated a DNN optimization scheme on\nthe basis of \\textit{black-box optimization}, which is used for training a\ncomputer that plays a game. For a black-box-optimization scheme, we adopt the\npolicy gradient method for calculating the gradient on the basis of a sampling\nalgorithm. To simulate output signals using the sampling algorithm, DNNs are\nused to estimate the probability density function of the output signals that\nmaximize OSQA scores. The OSQA scores are calculated from the simulated output\nsignals, and the DNNs are trained to increase the probability of generating the\nsimulated output signals that achieve high OSQA scores. Through several\nexperiments, we found that OSQA scores significantly increased by applying the\nproposed method, even though the MSE was not minimized.\n", "versions": [{"version": "v1", "created": "Mon, 22 Oct 2018 08:34:04 GMT"}], "update_date": "2018-10-23", "authors_parsed": [["Koizumi", "Yuma", ""], ["Niwa", "Kenta", ""], ["Hioka", "Yusuke", ""], ["Kobayashi", "Kazunori", ""], ["Haneda", "Yoichi", ""]]}, {"id": "1810.09155", "submitter": "Edouard Pineau", "authors": "Nathan de Lara and Edouard Pineau", "title": "A Simple Baseline Algorithm for Graph Classification", "comments": "Relational Representation Learning, NIPS 2018 Workshop", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Graph classification has recently received a lot of attention from various\nfields of machine learning e.g. kernel methods, sequential modeling or graph\nembedding. All these approaches offer promising results with different\nrespective strengths and weaknesses. However, most of them rely on complex\nmathematics and require heavy computational power to achieve their best\nperformance. We propose a simple and fast algorithm based on the spectral\ndecomposition of graph Laplacian to perform graph classification and get a\nfirst reference score for a dataset. We show that this method obtains\ncompetitive results compared to state-of-the-art algorithms.\n", "versions": [{"version": "v1", "created": "Mon, 22 Oct 2018 09:47:38 GMT"}, {"version": "v2", "created": "Mon, 12 Nov 2018 15:47:10 GMT"}], "update_date": "2018-11-13", "authors_parsed": [["de Lara", "Nathan", ""], ["Pineau", "Edouard", ""]]}, {"id": "1810.09166", "submitter": "Evgeniy Ozhegov M.", "authors": "Evgeniy M. Ozhegov, Daria Teterina", "title": "Ensemble Method for Censored Demand Prediction", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Many economic applications including optimal pricing and inventory management\nrequires prediction of demand based on sales data and estimation of sales\nreaction to a price change. There is a wide range of econometric approaches\nwhich are used to correct a bias in estimates of demand parameters on censored\nsales data. These approaches can also be applied to various classes of machine\nlearning models to reduce the prediction error of sales volume. In this study\nwe construct two ensemble models for demand prediction with and without\naccounting for demand censorship. Accounting for sales censorship is based on\nthe idea of censored quantile regression method where the model estimation is\nsplitted on two separate parts: a) prediction of zero sales by classification\nmodel; and b) prediction of non-zero sales by regression model. Models with and\nwithout accounting for censorship are based on the predictions aggregations of\nLeast squares, Ridge and Lasso regressions and Random Forest model. Having\nestimated the predictive properties of both models, we empirically test the\nbest predictive power of the model that takes into account the censored nature\nof demand. We also show that machine learning method with censorship accounting\nprovide bias corrected estimates of demand sensitivity for price change similar\nto econometric models.\n", "versions": [{"version": "v1", "created": "Mon, 22 Oct 2018 10:20:55 GMT"}], "update_date": "2018-10-23", "authors_parsed": [["Ozhegov", "Evgeniy M.", ""], ["Teterina", "Daria", ""]]}, {"id": "1810.09176", "submitter": "Megha Khosla", "authors": "Megha Khosla, Jurek Leonhardt, Wolfgang Nejdl, Avishek Anand", "title": "Node Representation Learning for Directed Graphs", "comments": "Accepted in ECML-PKDD 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SI cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a novel approach for learning node representations in directed\ngraphs, which maintains separate views or embedding spaces for the two distinct\nnode roles induced by the directionality of the edges. We argue that the\nprevious approaches either fail to encode the edge directionality or their\nencodings cannot be generalized across tasks. With our simple \\emph{alternating\nrandom walk} strategy, we generate role specific vertex neighborhoods and train\nnode embeddings in their corresponding source/target roles while fully\nexploiting the semantics of directed graphs. We also unearth the limitations of\nevaluations on directed graphs in previous works and propose a clear strategy\nfor evaluating link prediction and graph reconstruction in directed graphs. We\nconduct extensive experiments to showcase our effectiveness on several\nreal-world datasets on link prediction, node classification and graph\nreconstruction tasks. We show that the embeddings from our approach are indeed\nrobust, generalizable and well performing across multiple kinds of tasks and\ngraphs. We show that we consistently outperform all baselines for node\nclassification task. In addition to providing a theoretical interpretation of\nour method we also show that we are considerably more robust than the other\ndirected graph approaches.\n", "versions": [{"version": "v1", "created": "Mon, 22 Oct 2018 11:04:00 GMT"}, {"version": "v2", "created": "Thu, 29 Nov 2018 11:50:24 GMT"}, {"version": "v3", "created": "Sat, 2 Feb 2019 10:53:18 GMT"}, {"version": "v4", "created": "Fri, 28 Jun 2019 11:32:13 GMT"}], "update_date": "2019-07-01", "authors_parsed": [["Khosla", "Megha", ""], ["Leonhardt", "Jurek", ""], ["Nejdl", "Wolfgang", ""], ["Anand", "Avishek", ""]]}, {"id": "1810.09177", "submitter": "Hao Ren", "authors": "Hao Ren, Hong Lu", "title": "Compositional coding capsule network with k-means routing for text\n  classification", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.IR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Text classification is a challenging problem which aims to identify the\ncategory of texts. Recently, Capsule Networks (CapsNets) are proposed for image\nclassification. It has been shown that CapsNets have several advantages over\nConvolutional Neural Networks (CNNs), while, their validity in the domain of\ntext has less been explored. An effective method named deep compositional code\nlearning has been proposed lately. This method can save many parameters about\nword embeddings without any significant sacrifices in performance. In this\npaper, we introduce the Compositional Coding (CC) mechanism between capsules,\nand we propose a new routing algorithm, which is based on k-means clustering\ntheory. Experiments conducted on eight challenging text classification datasets\nshow the proposed method achieves competitive accuracy compared to the\nstate-of-the-art approach with significantly fewer parameters.\n", "versions": [{"version": "v1", "created": "Mon, 22 Oct 2018 11:04:27 GMT"}, {"version": "v2", "created": "Tue, 23 Oct 2018 07:34:04 GMT"}, {"version": "v3", "created": "Mon, 29 Oct 2018 14:29:24 GMT"}], "update_date": "2018-10-30", "authors_parsed": [["Ren", "Hao", ""], ["Lu", "Hong", ""]]}, {"id": "1810.09184", "submitter": "Peter Bloem", "authors": "Peter Bloem", "title": "Learning sparse transformations through backpropagation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Many transformations in deep learning architectures are sparsely connected.\nWhen such transformations cannot be designed by hand, they can be learned, even\nthrough plain backpropagation, for instance in attention mechanisms. However,\nduring learning, such sparse structures are often represented in a dense form,\nas we do not know beforehand which elements will eventually become non-zero. We\nintroduce the adaptive, sparse hyperlayer, a method for learning a sparse\ntransformation, paramatrized sparsely: as index-tuples with associated values.\nTo overcome the lack of gradients from such a discrete structure, we introduce\na method of randomly sampling connections, and backpropagating over the\nrandomly wired computation graph. To show that this approach allows us to train\na model to competitive performance on real data, we use it to build two\narchitectures. First, an attention mechanism for visual classification. Second,\nwe implement a method for differentiable sorting: specifically, learning to\nsort unlabeled MNIST digits, given only the correct order.\n", "versions": [{"version": "v1", "created": "Mon, 22 Oct 2018 11:34:32 GMT"}], "update_date": "2018-10-23", "authors_parsed": [["Bloem", "Peter", ""]]}, {"id": "1810.09202", "submitter": "Zongqing Lu", "authors": "Jiechuan Jiang, Chen Dun, Tiejun Huang, and Zongqing Lu", "title": "Graph Convolutional Reinforcement Learning", "comments": "ICLR'20", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.MA stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Learning to cooperate is crucially important in multi-agent environments. The\nkey is to understand the mutual interplay between agents. However, multi-agent\nenvironments are highly dynamic, where agents keep moving and their neighbors\nchange quickly. This makes it hard to learn abstract representations of mutual\ninterplay between agents. To tackle these difficulties, we propose graph\nconvolutional reinforcement learning, where graph convolution adapts to the\ndynamics of the underlying graph of the multi-agent environment, and relation\nkernels capture the interplay between agents by their relation representations.\nLatent features produced by convolutional layers from gradually increased\nreceptive fields are exploited to learn cooperation, and cooperation is further\nimproved by temporal relation regularization for consistency. Empirically, we\nshow that our method substantially outperforms existing methods in a variety of\ncooperative scenarios.\n", "versions": [{"version": "v1", "created": "Mon, 22 Oct 2018 12:17:40 GMT"}, {"version": "v2", "created": "Tue, 22 Jan 2019 12:42:24 GMT"}, {"version": "v3", "created": "Thu, 26 Sep 2019 05:21:13 GMT"}, {"version": "v4", "created": "Tue, 4 Feb 2020 03:22:09 GMT"}, {"version": "v5", "created": "Tue, 11 Feb 2020 13:46:23 GMT"}], "update_date": "2020-02-12", "authors_parsed": [["Jiang", "Jiechuan", ""], ["Dun", "Chen", ""], ["Huang", "Tiejun", ""], ["Lu", "Zongqing", ""]]}, {"id": "1810.09225", "submitter": "Xiao Zhang", "authors": "Xiao Zhang, David Evans", "title": "Cost-Sensitive Robustness against Adversarial Examples", "comments": "ICLR final version", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Several recent works have developed methods for training classifiers that are\ncertifiably robust against norm-bounded adversarial perturbations. These\nmethods assume that all the adversarial transformations are equally important,\nwhich is seldom the case in real-world applications. We advocate for\ncost-sensitive robustness as the criteria for measuring the classifier's\nperformance for tasks where some adversarial transformation are more important\nthan others. We encode the potential harm of each adversarial transformation in\na cost matrix, and propose a general objective function to adapt the robust\ntraining method of Wong & Kolter (2018) to optimize for cost-sensitive\nrobustness. Our experiments on simple MNIST and CIFAR10 models with a variety\nof cost matrices show that the proposed approach can produce models with\nsubstantially reduced cost-sensitive robust error, while maintaining\nclassification accuracy.\n", "versions": [{"version": "v1", "created": "Mon, 22 Oct 2018 12:55:48 GMT"}, {"version": "v2", "created": "Tue, 5 Mar 2019 15:43:25 GMT"}], "update_date": "2019-03-06", "authors_parsed": [["Zhang", "Xiao", ""], ["Evans", "David", ""]]}, {"id": "1810.09227", "submitter": "Brandon Malone", "authors": "Brandon Malone and Alberto Garc\\'ia-Dur\\'an and Mathias Niepert", "title": "Knowledge Graph Completion to Predict Polypharmacy Side Effects", "comments": "13th International Conference on Data Integration in the Life\n  Sciences (DILS2018)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DB cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The polypharmacy side effect prediction problem considers cases in which two\ndrugs taken individually do not result in a particular side effect; however,\nwhen the two drugs are taken in combination, the side effect manifests. In this\nwork, we demonstrate that multi-relational knowledge graph completion achieves\nstate-of-the-art results on the polypharmacy side effect prediction problem.\nEmpirical results show that our approach is particularly effective when the\nprotein targets of the drugs are well-characterized. In contrast to prior work,\nour approach provides more interpretable predictions and hypotheses for wet lab\nvalidation.\n", "versions": [{"version": "v1", "created": "Mon, 22 Oct 2018 12:59:51 GMT"}], "update_date": "2018-10-23", "authors_parsed": [["Malone", "Brandon", ""], ["Garc\u00eda-Dur\u00e1n", "Alberto", ""], ["Niepert", "Mathias", ""]]}, {"id": "1810.09230", "submitter": "Abdullah Al-Dujaili", "authors": "Gili Rusak, Abdullah Al-Dujaili, Una-May O'Reilly", "title": "AST-Based Deep Learning for Detecting Malicious PowerShell", "comments": "To appear at ACM CCS 2018 Poster Session", "journal-ref": null, "doi": "10.1145/3243734.3278496", "report-no": null, "categories": "cs.SE cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  With the celebrated success of deep learning, some attempts to develop\neffective methods for detecting malicious PowerShell programs employ neural\nnets in a traditional natural language processing setup while others employ\nconvolutional neural nets to detect obfuscated malicious commands at a\ncharacter level. While these representations may express salient PowerShell\nproperties, our hypothesis is that tools from static program analysis will be\nmore effective. We propose a hybrid approach combining traditional program\nanalysis (in the form of abstract syntax trees) and deep learning. This poster\npresents preliminary results of a fundamental step in our approach: learning\nembeddings for nodes of PowerShell ASTs. We classify malicious scripts by\nfamily type and explore embedded program vector representations.\n", "versions": [{"version": "v1", "created": "Wed, 3 Oct 2018 16:03:53 GMT"}], "update_date": "2018-10-23", "authors_parsed": [["Rusak", "Gili", ""], ["Al-Dujaili", "Abdullah", ""], ["O'Reilly", "Una-May", ""]]}, {"id": "1810.09233", "submitter": "Haowen Fang", "authors": "Haowem Fang, Amar Shrestha, De Ma, Qinru Qiu", "title": "Scalable NoC-based Neuromorphic Hardware Learning and Inference", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.ET cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Bio-inspired neuromorphic hardware is a research direction to approach\nbrain's computational power and energy efficiency. Spiking neural networks\n(SNN) encode information as sparsely distributed spike trains and employ\nspike-timing-dependent plasticity (STDP) mechanism for learning. Existing\nhardware implementations of SNN are limited in scale or do not have in-hardware\nlearning capability. In this work, we propose a low-cost scalable\nNetwork-on-Chip (NoC) based SNN hardware architecture with fully distributed\nin-hardware STDP learning capability. All hardware neurons work in parallel and\ncommunicate through the NoC. This enables chip-level interconnection,\nscalability and reconfigurability necessary for deploying different\napplications. The hardware is applied to learn MNIST digits as an evaluation of\nits learning capability. We explore the design space to study the trade-offs\nbetween speed, area and energy. How to use this procedure to find optimal\narchitecture configuration is also discussed.\n", "versions": [{"version": "v1", "created": "Tue, 18 Sep 2018 16:41:57 GMT"}], "update_date": "2018-10-23", "authors_parsed": [["Fang", "Haowem", ""], ["Shrestha", "Amar", ""], ["Ma", "De", ""], ["Qiu", "Qinru", ""]]}, {"id": "1810.09253", "submitter": "Mingjun Zhong", "authors": "Hong Tang, Huaming Chen, Ting Li, Mingjun Zhong", "title": "Classification of normal/abnormal heart sound recordings based on\n  multi-domain features and back propagation neural network", "comments": "4 pages", "journal-ref": "2016 Computing in Cardiology Conference (CinC), IEEE, Vancouver,\n  BC, 2016, pp. 593-596", "doi": "10.23919/CIC.2016.7868812", "report-no": null, "categories": "eess.SP cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper aims to classify a single PCG recording as normal or abnormal for\ncomputer-aided diagnosis. The proposed framework for this challenge has four\nsteps: preprocessing, feature extraction, training and validation. In the\npreprocessing step, a recording is segmented into four states, i.e., the first\nheart sound, systolic interval, the second heart sound, and diastolic interval\nby the Springer Segmentation algorithm. In the feature extraction step, the\nauthors extract 324 features from multi-domains to perform classification. A\nback propagation neural network is used as predication model. The optimal\nthreshold for distinguishing normal and abnormal is determined by the\nstatistics of model output for both normal and abnormal. The performance of the\nproposed predictor tested by the six training sets is sensitivity 0.812 and\nspecificity 0.860 (overall accuracy is 0.836). However, the performance reduces\nto sensitivity 0.807 and specificity 0.829 (overall accuracy is 0.818) for the\nhidden test set.\n", "versions": [{"version": "v1", "created": "Wed, 17 Oct 2018 21:17:48 GMT"}], "update_date": "2018-10-23", "authors_parsed": [["Tang", "Hong", ""], ["Chen", "Huaming", ""], ["Li", "Ting", ""], ["Zhong", "Mingjun", ""]]}, {"id": "1810.09261", "submitter": "Francisco Ruiz", "authors": "Francisco J. R. Ruiz, Isabel Valera, Lennart Svensson, Fernando\n  Perez-Cruz", "title": "Infinite Factorial Finite State Machine for Blind Multiuser Channel\n  Estimation", "comments": "15 pages, 15 figures", "journal-ref": "IEEE Transactions on Cognitive Communications and Networking, June\n  2018, Vol 2, Issue 2, pages 177-191", "doi": "10.1109/TCCN.2018.2790976", "report-no": null, "categories": "eess.SP cs.IT cs.LG math.IT stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  New communication standards need to deal with machine-to-machine\ncommunications, in which users may start or stop transmitting at any time in an\nasynchronous manner. Thus, the number of users is an unknown and time-varying\nparameter that needs to be accurately estimated in order to properly recover\nthe symbols transmitted by all users in the system. In this paper, we address\nthe problem of joint channel parameter and data estimation in a multiuser\ncommunication channel in which the number of transmitters is not known. For\nthat purpose, we develop the infinite factorial finite state machine model, a\nBayesian nonparametric model based on the Markov Indian buffet that allows for\nan unbounded number of transmitters with arbitrary channel length. We propose\nan inference algorithm that makes use of slice sampling and particle Gibbs with\nancestor sampling. Our approach is fully blind as it does not require a prior\nchannel estimation step, prior knowledge of the number of transmitters, or any\nsignaling information. Our experimental results, loosely based on the LTE\nrandom access channel, show that the proposed approach can effectively recover\nthe data-generating process for a wide range of scenarios, with varying number\nof transmitters, number of receivers, constellation order, channel length, and\nsignal-to-noise ratio.\n", "versions": [{"version": "v1", "created": "Thu, 18 Oct 2018 20:26:17 GMT"}], "update_date": "2018-10-23", "authors_parsed": [["Ruiz", "Francisco J. R.", ""], ["Valera", "Isabel", ""], ["Svensson", "Lennart", ""], ["Perez-Cruz", "Fernando", ""]]}, {"id": "1810.09270", "submitter": "Rui Zhu", "authors": "Rui Zhu and Di Niu", "title": "A Model Parallel Proximal Stochastic Gradient Algorithm for Partially\n  Asynchronous Systems", "comments": "arXiv admin note: substantial text overlap with arXiv:1802.08880", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Large models are prevalent in modern machine learning scenarios, including\ndeep learning, recommender systems, etc., which can have millions or even\nbillions of parameters. Parallel algorithms have become an essential solution\ntechnique to many large-scale machine learning jobs. In this paper, we propose\na model parallel proximal stochastic gradient algorithm, AsyB-ProxSGD, to deal\nwith large models using model parallel blockwise updates while in the meantime\nhandling a large amount of training data using proximal stochastic gradient\ndescent (ProxSGD). In our algorithm, worker nodes communicate with the\nparameter servers asynchronously, and each worker performs proximal stochastic\ngradient for only one block of model parameters during each iteration. Our\nproposed algorithm generalizes ProxSGD to the asynchronous and model parallel\nsetting. We prove that AsyB-ProxSGD achieves a convergence rate of\n$O(1/\\sqrt{K})$ to stationary points for nonconvex problems under\n\\emph{constant} minibatch sizes, where $K$ is the total number of block\nupdates. This rate matches the best-known rates of convergence for a wide range\nof gradient-like algorithms. Furthermore, we show that when the number of\nworkers is bounded by $O(K^{1/4})$, we can expect AsyB-ProxSGD to achieve\nlinear speedup as the number of workers increases. We implement the proposed\nalgorithm on MXNet and demonstrate its convergence behavior and near-linear\nspeedup on a real-world dataset involving both a large model size and large\namounts of data.\n", "versions": [{"version": "v1", "created": "Fri, 19 Oct 2018 17:22:30 GMT"}], "update_date": "2018-10-23", "authors_parsed": [["Zhu", "Rui", ""], ["Niu", "Di", ""]]}, {"id": "1810.09274", "submitter": "Randall Balestriero", "authors": "Randall Balestriero, Richard G. Baraniuk", "title": "From Hard to Soft: Understanding Deep Network Nonlinearities via Vector\n  Quantization and Statistical Inference", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Nonlinearity is crucial to the performance of a deep (neural) network (DN).\nTo date there has been little progress understanding the menagerie of available\nnonlinearities, but recently progress has been made on understanding the r\\^ole\nplayed by piecewise affine and convex nonlinearities like the ReLU and absolute\nvalue activation functions and max-pooling. In particular, DN layers\nconstructed from these operations can be interpreted as {\\em max-affine spline\noperators} (MASOs) that have an elegant link to vector quantization (VQ) and\n$K$-means. While this is good theoretical progress, the entire MASO approach is\npredicated on the requirement that the nonlinearities be piecewise affine and\nconvex, which precludes important activation functions like the sigmoid,\nhyperbolic tangent, and softmax. {\\em This paper extends the MASO framework to\nthese and an infinitely large class of new nonlinearities by linking\ndeterministic MASOs with probabilistic Gaussian Mixture Models (GMMs).} We show\nthat, under a GMM, piecewise affine, convex nonlinearities like ReLU, absolute\nvalue, and max-pooling can be interpreted as solutions to certain natural\n\"hard\" VQ inference problems, while sigmoid, hyperbolic tangent, and softmax\ncan be interpreted as solutions to corresponding \"soft\" VQ inference problems.\nWe further extend the framework by hybridizing the hard and soft VQ\noptimizations to create a $\\beta$-VQ inference that interpolates between hard,\nsoft, and linear VQ inference. A prime example of a $\\beta$-VQ DN nonlinearity\nis the {\\em swish} nonlinearity, which offers state-of-the-art performance in a\nrange of computer vision tasks but was developed ad hoc by experimentation.\nFinally, we validate with experiments an important assertion of our theory,\nnamely that DN performance can be significantly improved by enforcing\northogonality in its linear filters.\n", "versions": [{"version": "v1", "created": "Mon, 22 Oct 2018 13:39:44 GMT"}], "update_date": "2018-10-23", "authors_parsed": [["Balestriero", "Randall", ""], ["Baraniuk", "Richard G.", ""]]}, {"id": "1810.09284", "submitter": "Tiago de Souza Farias", "authors": "Tiago de Souza Farias, Jonas Maziero", "title": "Gradient target propagation", "comments": "12 pages, 4 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We report a learning rule for neural networks that computes how much each\nneuron should contribute to minimize a giving cost function via the estimation\nof its target value. By theoretical analysis, we show that this learning rule\ncontains backpropagation, Hebian learning, and additional terms. We also give a\ngeneral technique for weights initialization. Our results are at least as good\nas those obtained with backpropagation. The neural networks are trained and\ntested in three problems: MNIST, MNIST-Fashion, and CIFAR-10 datasets. The\nassociated code is available at https://github.com/tiago939/target.\n", "versions": [{"version": "v1", "created": "Fri, 19 Oct 2018 15:56:00 GMT"}, {"version": "v2", "created": "Tue, 30 Oct 2018 18:03:54 GMT"}, {"version": "v3", "created": "Thu, 1 Nov 2018 17:11:14 GMT"}], "update_date": "2018-11-02", "authors_parsed": [["Farias", "Tiago de Souza", ""], ["Maziero", "Jonas", ""]]}, {"id": "1810.09302", "submitter": "Qingyu Chen", "authors": "Qingyu Chen, Yifan Peng, and Zhiyong Lu", "title": "BioSentVec: creating sentence embeddings for biomedical texts", "comments": "5 pages, 3 tables and 2 figures accepted by The Seventh IEEE\n  International Conference on Healthcare Informatics (ICHI 2019)", "journal-ref": null, "doi": "10.1109/ICHI.2019.8904728", "report-no": null, "categories": "cs.CL cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Sentence embeddings have become an essential part of today's natural language\nprocessing (NLP) systems, especially together advanced deep learning methods.\nAlthough pre-trained sentence encoders are available in the general domain,\nnone exists for biomedical texts to date. In this work, we introduce\nBioSentVec: the first open set of sentence embeddings trained with over 30\nmillion documents from both scholarly articles in PubMed and clinical notes in\nthe MIMIC-III Clinical Database. We evaluate BioSentVec embeddings in two\nsentence pair similarity tasks in different text genres. Our benchmarking\nresults demonstrate that the BioSentVec embeddings can better capture sentence\nsemantics compared to the other competitive alternatives and achieve\nstate-of-the-art performance in both tasks. We expect BioSentVec to facilitate\nthe research and development in biomedical text mining and to complement the\nexisting resources in biomedical word embeddings. BioSentVec is publicly\navailable at https://github.com/ncbi-nlp/BioSentVec\n", "versions": [{"version": "v1", "created": "Mon, 22 Oct 2018 14:10:01 GMT"}, {"version": "v2", "created": "Fri, 26 Oct 2018 15:04:19 GMT"}, {"version": "v3", "created": "Wed, 15 May 2019 04:41:06 GMT"}, {"version": "v4", "created": "Tue, 18 Jun 2019 13:46:32 GMT"}, {"version": "v5", "created": "Wed, 19 Jun 2019 00:33:32 GMT"}, {"version": "v6", "created": "Fri, 24 Jan 2020 21:48:13 GMT"}], "update_date": "2020-01-28", "authors_parsed": [["Chen", "Qingyu", ""], ["Peng", "Yifan", ""], ["Lu", "Zhiyong", ""]]}, {"id": "1810.09305", "submitter": "Mahnaz Koupaee", "authors": "Mahnaz Koupaee, William Yang Wang", "title": "WikiHow: A Large Scale Text Summarization Dataset", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.IR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Sequence-to-sequence models have recently gained the state of the art\nperformance in summarization. However, not too many large-scale high-quality\ndatasets are available and almost all the available ones are mainly news\narticles with specific writing style. Moreover, abstractive human-style systems\ninvolving description of the content at a deeper level require data with higher\nlevels of abstraction. In this paper, we present WikiHow, a dataset of more\nthan 230,000 article and summary pairs extracted and constructed from an online\nknowledge base written by different human authors. The articles span a wide\nrange of topics and therefore represent high diversity styles. We evaluate the\nperformance of the existing methods on WikiHow to present its challenges and\nset some baselines to further improve it.\n", "versions": [{"version": "v1", "created": "Thu, 18 Oct 2018 05:29:41 GMT"}], "update_date": "2018-10-23", "authors_parsed": [["Koupaee", "Mahnaz", ""], ["Wang", "William Yang", ""]]}, {"id": "1810.09309", "submitter": "Jiali Yao", "authors": "Jiali Yao, Raphael Shu, Xinjian Li, Katsutoshi Ohtsuki, Hideki\n  Nakayama", "title": "Real-time Neural-based Input Method", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The input method is an essential service on every mobile and desktop devices\nthat provides text suggestions. It converts sequential keyboard inputs to the\ncharacters in its target language, which is indispensable for Japanese and\nChinese users. Due to critical resource constraints and limited network\nbandwidth of the target devices, applying neural models to input method is not\nwell explored. In this work, we apply a LSTM-based language model to input\nmethod and evaluate its performance for both prediction and conversion tasks\nwith Japanese BCCWJ corpus. We articulate the bottleneck to be the slow softmax\ncomputation during conversion. To solve the issue, we propose incremental\nsoftmax approximation approach, which computes softmax with a selected subset\nvocabulary and fix the stale probabilities when the vocabulary is updated in\nfuture steps. We refer to this method as incremental selective softmax. The\nresults show a two order speedup for the softmax computation when converting\nJapanese input sequences with a large vocabulary, reaching real-time speed on\ncommodity CPU. We also exploit the model compressing potential to achieve a 92%\nmodel size reduction without losing accuracy.\n", "versions": [{"version": "v1", "created": "Fri, 19 Oct 2018 12:57:37 GMT"}], "update_date": "2018-10-23", "authors_parsed": [["Yao", "Jiali", ""], ["Shu", "Raphael", ""], ["Li", "Xinjian", ""], ["Ohtsuki", "Katsutoshi", ""], ["Nakayama", "Hideki", ""]]}, {"id": "1810.09311", "submitter": "Alejandro Moreo Fern\\'andez", "authors": "Alejandro Moreo, Andrea Esuli, Fabrizio Sebastiani", "title": "Revisiting Distributional Correspondence Indexing: A Python\n  Reimplementation and New Experiments", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper introduces PyDCI, a new implementation of Distributional\nCorrespondence Indexing (DCI) written in Python. DCI is a transfer learning\nmethod for cross-domain and cross-lingual text classification for which we had\nprovided an implementation (here called JaDCI) built on top of JaTeCS, a Java\nframework for text classification. PyDCI is a stand-alone version of DCI that\nexploits scikit-learn and the SciPy stack. We here report on new experiments\nthat we have carried out in order to test PyDCI, and in which we use as\nbaselines new high-performing methods that have appeared after DCI was\noriginally proposed. These experiments show that, thanks to a few subtle ways\nin which we have improved DCI, PyDCI outperforms both JaDCI and the\nabove-mentioned high-performing methods, and delivers the best known results on\nthe two popular benchmarks on which we had tested DCI, i.e.,\nMultiDomainSentiment (a.k.a. MDS -- for cross-domain adaptation) and\nWebis-CLS-10 (for cross-lingual adaptation). PyDCI, together with the code\nallowing to replicate our experiments, is available at\nhttps://github.com/AlexMoreo/pydci .\n", "versions": [{"version": "v1", "created": "Fri, 19 Oct 2018 07:27:24 GMT"}], "update_date": "2018-10-23", "authors_parsed": [["Moreo", "Alejandro", ""], ["Esuli", "Andrea", ""], ["Sebastiani", "Fabrizio", ""]]}, {"id": "1810.09312", "submitter": "Mahnaz Koupaee", "authors": "Mahnaz Koupaee, William Yang Wang", "title": "Analyzing and Interpreting Convolutional Neural Networks in NLP", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Convolutional neural networks have been successfully applied to various NLP\ntasks. However, it is not obvious whether they model different linguistic\npatterns such as negation, intensification, and clause compositionality to help\nthe decision-making process. In this paper, we apply visualization techniques\nto observe how the model can capture different linguistic features and how\nthese features can affect the performance of the model. Later on, we try to\nidentify the model errors and their sources. We believe that interpreting CNNs\nis the first step to understand the underlying semantic features which can\nraise awareness to further improve the performance and explainability of CNN\nmodels.\n", "versions": [{"version": "v1", "created": "Thu, 18 Oct 2018 05:18:04 GMT"}], "update_date": "2018-10-23", "authors_parsed": [["Koupaee", "Mahnaz", ""], ["Wang", "William Yang", ""]]}, {"id": "1810.09343", "submitter": "Michael Fink", "authors": "Michael Fink, Thomas Layer, Georg Mackenbrock, and Michael Sprinzl", "title": "Baseline Detection in Historical Documents using Convolutional U-Nets", "comments": "6 pages, accepted to DAS 2018", "journal-ref": "Proc. of the 13th IAPR Int. Workshop on Document Analysis Systems\n  (DAS 2018), IEEE Computer Society, pp. 37-42, 2018", "doi": "10.1109/DAS.2018.34", "report-no": null, "categories": "cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Baseline detection is still a challenging task for heterogeneous collections\nof historical documents. We present a novel approach to baseline extraction in\nsuch settings, turning out the winning entry to the ICDAR 2017 Competition on\nBaseline detection (cBAD). It utilizes deep convolutional nets (CNNs) for both,\nthe actual extraction of baselines, as well as for a simple form of layout\nanalysis in a pre-processing step. To the best of our knowledge it is the first\nCNN-based system for baseline extraction applying a U-net architecture and\nsliding window detection, profiting from a high local accuracy of the candidate\nlines extracted. Final baseline post-processing complements our approach,\ncompensating for inaccuracies mainly due to missing context information during\nsliding window detection. We experimentally evaluate the components of our\nsystem individually on the cBAD dataset. Moreover, we investigate how it\ngeneralizes to different data by means of the dataset used for the baseline\nextraction task of the ICDAR 2017 Competition on Layout Analysis for\nChallenging Medieval Manuscripts (HisDoc). A comparison with the results\nreported for HisDoc shows that it also outperforms the contestants of the\nlatter.\n", "versions": [{"version": "v1", "created": "Mon, 22 Oct 2018 15:06:57 GMT"}], "update_date": "2018-10-23", "authors_parsed": [["Fink", "Michael", ""], ["Layer", "Thomas", ""], ["Mackenbrock", "Georg", ""], ["Sprinzl", "Michael", ""]]}, {"id": "1810.09346", "submitter": "Alon Resler", "authors": "Alon Resler, Yishay Mansour", "title": "Adversarial Online Learning with noise", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present and study models of adversarial online learning where the feedback\nobserved by the learner is noisy, and the feedback is either full information\nfeedback or bandit feedback. Specifically, we consider binary losses xored with\nthe noise, which is a Bernoulli random variable. We consider both a constant\nnoise rate and a variable noise rate. Our main results are tight regret bounds\nfor learning with noise in the adversarial online learning model.\n", "versions": [{"version": "v1", "created": "Mon, 22 Oct 2018 15:10:41 GMT"}, {"version": "v2", "created": "Wed, 24 Oct 2018 11:59:42 GMT"}, {"version": "v3", "created": "Sun, 4 Nov 2018 10:49:09 GMT"}], "update_date": "2018-11-06", "authors_parsed": [["Resler", "Alon", ""], ["Mansour", "Yishay", ""]]}, {"id": "1810.09352", "submitter": "Riccardo Guidotti", "authors": "Riccardo Guidotti, Salvatore Ruggieri", "title": "On The Stability of Interpretable Models", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Interpretable classification models are built with the purpose of providing a\ncomprehensible description of the decision logic to an external oversight\nagent. When considered in isolation, a decision tree, a set of classification\nrules, or a linear model, are widely recognized as human-interpretable.\nHowever, such models are generated as part of a larger analytical process. Bias\nin data collection and preparation, or in model's construction may severely\naffect the accountability of the design process. We conduct an experimental\nstudy of the stability of interpretable models with respect to feature\nselection, instance selection, and model selection. Our conclusions should\nraise awareness and attention of the scientific community on the need of a\nstability impact assessment of interpretable models.\n", "versions": [{"version": "v1", "created": "Mon, 22 Oct 2018 15:16:53 GMT"}, {"version": "v2", "created": "Fri, 15 Mar 2019 08:45:23 GMT"}], "update_date": "2019-03-18", "authors_parsed": [["Guidotti", "Riccardo", ""], ["Ruggieri", "Salvatore", ""]]}, {"id": "1810.09361", "submitter": "Conrad Sanderson", "authors": "Shikhar Bhardwaj and Ryan R. Curtin and Marcus Edel and Yannis\n  Mentekidis and Conrad Sanderson", "title": "ensmallen: a flexible C++ library for efficient function optimization", "comments": "Workshop on Systems for ML and Open Source Software at NIPS /\n  NeurIPS, 2018", "journal-ref": null, "doi": "10.5281/zenodo.2008650", "report-no": null, "categories": "cs.MS cs.LG math.OC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present ensmallen, a fast and flexible C++ library for mathematical\noptimization of arbitrary user-supplied functions, which can be applied to many\nmachine learning problems. Several types of optimizations are supported,\nincluding differentiable, separable, constrained, and categorical objective\nfunctions. The library provides many pre-built optimizers (including numerous\nvariants of SGD and Quasi-Newton optimizers) as well as a flexible framework\nfor implementing new optimizers and objective functions. Implementation of a\nnew optimizer requires only one method and a new objective function requires\ntypically one or two C++ functions. This can aid in the quick implementation\nand prototyping of new machine learning algorithms. Due to the use of C++\ntemplate metaprogramming, ensmallen is able to support compiler optimizations\nthat provide fast runtimes. Empirical comparisons show that ensmallen is able\nto outperform other optimization frameworks (like Julia and SciPy), sometimes\nby large margins. The library is distributed under the BSD license and is ready\nfor use in production environments.\n", "versions": [{"version": "v1", "created": "Mon, 22 Oct 2018 15:26:35 GMT"}, {"version": "v2", "created": "Mon, 10 Dec 2018 04:37:09 GMT"}], "update_date": "2018-12-11", "authors_parsed": [["Bhardwaj", "Shikhar", ""], ["Curtin", "Ryan R.", ""], ["Edel", "Marcus", ""], ["Mentekidis", "Yannis", ""], ["Sanderson", "Conrad", ""]]}, {"id": "1810.09365", "submitter": "Guillaume Devineau", "authors": "Guillaume Devineau, Philip Polack, Florent Altch\\'e, Fabien Moutarde", "title": "Coupled Longitudinal and Lateral Control of a Vehicle using Deep\n  Learning", "comments": "Published in the IEEE 2018 International Conference on Intelligent\n  Transportation Systems (ITSC 2018)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.RO cs.SY stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper explores the capability of deep neural networks to capture key\ncharacteristics of vehicle dynamics, and their ability to perform coupled\nlongitudinal and lateral control of a vehicle. To this extent, two different\nartificial neural networks are trained to compute vehicle controls\ncorresponding to a reference trajectory, using a dataset based on high-fidelity\nsimulations of vehicle dynamics. In this study, control inputs are chosen as\nthe steering angle of the front wheels, and the applied torque on each wheel.\nThe performance of both models, namely a Multi-Layer Perceptron (MLP) and a\nConvolutional Neural Network (CNN), is evaluated based on their ability to\ndrive the vehicle on a challenging test track, shifting between long straight\nlines and tight curves. A comparison to conventional decoupled controllers on\nthe same track is also provided.\n", "versions": [{"version": "v1", "created": "Mon, 22 Oct 2018 15:35:12 GMT"}], "update_date": "2018-10-23", "authors_parsed": [["Devineau", "Guillaume", ""], ["Polack", "Philip", ""], ["Altch\u00e9", "Florent", ""], ["Moutarde", "Fabien", ""]]}, {"id": "1810.09381", "submitter": "Eldar Insafutdinov", "authors": "Eldar Insafutdinov and Alexey Dosovitskiy", "title": "Unsupervised Learning of Shape and Pose with Differentiable Point Clouds", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We address the problem of learning accurate 3D shape and camera pose from a\ncollection of unlabeled category-specific images. We train a convolutional\nnetwork to predict both the shape and the pose from a single image by\nminimizing the reprojection error: given several views of an object, the\nprojections of the predicted shapes to the predicted camera poses should match\nthe provided views. To deal with pose ambiguity, we introduce an ensemble of\npose predictors which we then distill to a single \"student\" model. To allow for\nefficient learning of high-fidelity shapes, we represent the shapes by point\nclouds and devise a formulation allowing for differentiable projection of\nthese. Our experiments show that the distilled ensemble of pose predictors\nlearns to estimate the pose accurately, while the point cloud representation\nallows to predict detailed shape models. The supplementary video can be found\nat https://www.youtube.com/watch?v=LuIGovKeo60\n", "versions": [{"version": "v1", "created": "Mon, 22 Oct 2018 16:01:20 GMT"}], "update_date": "2018-10-23", "authors_parsed": [["Insafutdinov", "Eldar", ""], ["Dosovitskiy", "Alexey", ""]]}, {"id": "1810.09390", "submitter": "Joseph C. Lam", "authors": "Juliette Achdou, Joseph C. Lam, Alexandra Carpentier and Gilles\n  Blanchard", "title": "A minimax near-optimal algorithm for adaptive rejection sampling", "comments": "32 pages, 4 figures. Submitted to ALT 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Rejection Sampling is a fundamental Monte-Carlo method. It is used to sample\nfrom distributions admitting a probability density function which can be\nevaluated exactly at any given point, albeit at a high computational cost.\nHowever, without proper tuning, this technique implies a high rejection rate.\nSeveral methods have been explored to cope with this problem, based on the\nprinciple of adaptively estimating the density by a simpler function, using the\ninformation of the previous samples. Most of them either rely on strong\nassumptions on the form of the density, or do not offer any theoretical\nperformance guarantee. We give the first theoretical lower bound for the\nproblem of adaptive rejection sampling and introduce a new algorithm which\nguarantees a near-optimal rejection rate in a minimax sense.\n", "versions": [{"version": "v1", "created": "Mon, 22 Oct 2018 16:22:43 GMT"}], "update_date": "2018-10-23", "authors_parsed": [["Achdou", "Juliette", ""], ["Lam", "Joseph C.", ""], ["Carpentier", "Alexandra", ""], ["Blanchard", "Gilles", ""]]}, {"id": "1810.09391", "submitter": "Constantine Dovrolis", "authors": "Constantine Dovrolis", "title": "A neuro-inspired architecture for unsupervised continual learning based\n  on online clustering and hierarchical predictive coding", "comments": "Under peer-review", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI q-bio.NC stat.ML", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  We propose that the Continual Learning desiderata can be achieved through a\nneuro-inspired architecture, grounded on Mountcastle's cortical column\nhypothesis. The proposed architecture involves a single module, called\nSelf-Taught Associative Memory (STAM), which models the function of a cortical\ncolumn. STAMs are repeated in multi-level hierarchies involving feedforward,\nlateral and feedback connections. STAM networks learn in an unsupervised\nmanner, based on a combination of online clustering and hierarchical predictive\ncoding. This short paper only presents the architecture and its connections\nwith neuroscience. A mathematical formulation and experimental results will be\npresented in an extended version of this paper.\n", "versions": [{"version": "v1", "created": "Mon, 22 Oct 2018 16:27:21 GMT"}], "update_date": "2018-10-23", "authors_parsed": [["Dovrolis", "Constantine", ""]]}, {"id": "1810.09401", "submitter": "Hamid Dadkhahi", "authors": "Hamid Dadkhahi and Sahand Negahban", "title": "Alternating Linear Bandits for Online Matrix-Factorization\n  Recommendation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the problem of online collaborative filtering in the online\nsetting, where items are recommended to the users over time. At each time step,\nthe user (selected by the environment) consumes an item (selected by the agent)\nand provides a rating of the selected item. In this paper, we propose a novel\nalgorithm for online matrix factorization recommendation that combines linear\nbandits and alternating least squares. In this formulation, the bandit feedback\nis equal to the difference between the ratings of the best and selected items.\nWe evaluate the performance of the proposed algorithm over time using both\ncumulative regret and average cumulative NDCG. Simulation results over three\nsynthetic datasets as well as three real-world datasets for online\ncollaborative filtering indicate the superior performance of the proposed\nalgorithm over two state-of-the-art online algorithms.\n", "versions": [{"version": "v1", "created": "Mon, 22 Oct 2018 16:52:57 GMT"}], "update_date": "2018-10-23", "authors_parsed": [["Dadkhahi", "Hamid", ""], ["Negahban", "Sahand", ""]]}, {"id": "1810.09409", "submitter": "Matthias Meyer", "authors": "Matthias Meyer, Timo Farei-Campagna, Akos Pasztor, Reto Da Forno,\n  Tonio Gsell, J\\'erome Faillettaz, Andreas Vieli, Samuel Weber, Jan Beutel,\n  Lothar Thiele", "title": "Event-triggered Natural Hazard Monitoring with Convolutional Neural\n  Networks on the Edge", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.NI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In natural hazard warning systems fast decision making is vital to avoid\ncatastrophes. Decision making at the edge of a wireless sensor network promises\nfast response times but is limited by the availability of energy, data transfer\nspeed, processing and memory constraints. In this work we present a realization\nof a wireless sensor network for hazard monitoring based on an array of\nevent-triggered single-channel micro-seismic sensors with advanced signal\nprocessing and characterization capabilities based on a novel co-detection\ntechnique. On the one hand we leverage an ultra-low power, threshold-triggering\ncircuit paired with on-demand digital signal acquisition capable of extracting\nrelevant information exactly and efficiently at times when it matters most and\nconsequentially not wasting precious resources when nothing can be observed. On\nthe other hand we utilize machine-learning-based classification implemented on\nlow-power, off-the-shelf microcontrollers to avoid false positive warnings and\nto actively identify humans in hazard zones. The sensors' response time and\nmemory requirement is substantially improved by quantizing and pipelining the\ninference of a convolutional neural network. In this way, convolutional neural\nnetworks that would not run unmodified on a memory constrained device can be\nexecuted in real-time and at scale on low-power embedded devices. A field study\nwith our system is running on the rockfall scarp of the Matterhorn H\\\"ornligrat\nat 3500 m a.s.l. since 08/2018.\n", "versions": [{"version": "v1", "created": "Mon, 22 Oct 2018 17:24:31 GMT"}, {"version": "v2", "created": "Fri, 1 Mar 2019 10:11:47 GMT"}], "update_date": "2019-03-04", "authors_parsed": [["Meyer", "Matthias", ""], ["Farei-Campagna", "Timo", ""], ["Pasztor", "Akos", ""], ["Da Forno", "Reto", ""], ["Gsell", "Tonio", ""], ["Faillettaz", "J\u00e9rome", ""], ["Vieli", "Andreas", ""], ["Weber", "Samuel", ""], ["Beutel", "Jan", ""], ["Thiele", "Lothar", ""]]}, {"id": "1810.09414", "submitter": "Rodrigo Collazo", "authors": "Rodrigo A. Collazo, Jim Q. Smith", "title": "Properties of an N Time-Slice Dynamic Chain Event Graph", "comments": "38 pages, 9 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A Dynamic Chain Event Graph (DCEG) provides a rich tree-based framework for\nmodelling a dynamic process with highly asymmetric developments. An N\nTime-Slice DCEG (NT-DCEG) is a useful subclass of the DCEG class that exhibits\na specific type of periodicity in its supporting tree graph and embodies a\ntime-homogeneity assumption. Here some desired properties of an NT-DCEG is\nexplored. In particular, we prove that the class of NT-DCEGs contains all\ndiscrete N time-slice Dynamic Bayesian Networks as special cases. We also\ndevelop a method to distributively construct an NT-DCEG model. By exploiting\nthe topology of an NT-DCEG graph, we show how to construct intrinsic random\nvariables which exhibit context-specific independences that can then be checked\nby domain experts. We also show how an NT-DCEG can be used to depict various\nstructural and Granger causal hypotheses about a given process. Our methods are\nillustrated throughout using examples of dynamic multivariate processes\ndescribing inmate radicalisation in a prison.\n", "versions": [{"version": "v1", "created": "Mon, 22 Oct 2018 17:35:33 GMT"}], "update_date": "2018-10-23", "authors_parsed": [["Collazo", "Rodrigo A.", ""], ["Smith", "Jim Q.", ""]]}, {"id": "1810.09418", "submitter": "Andrea Schioppa", "authors": "Andrea Schioppa", "title": "Optimality of the final model found via Stochastic Gradient Descent", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG math.OC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study convergence properties of Stochastic Gradient Descent (SGD) for\nconvex objectives without assumptions on smoothness or strict convexity. We\nconsider the question of establishing that with high probability the objective\nevaluated at the candidate minimizer returned by SGD is close to the minimal\nvalue of the objective. We compare this result concerning the final candidate\nminimzer (i.e. the final model parameters learned after all gradient steps) to\nthe online learning techniques of [Zin03] that take a rolling average of the\nmodel parameters at the different steps of SGD.\n", "versions": [{"version": "v1", "created": "Mon, 22 Oct 2018 17:36:20 GMT"}], "update_date": "2018-10-23", "authors_parsed": [["Schioppa", "Andrea", ""]]}, {"id": "1810.09425", "submitter": "Jakub Mare\\v{c}ek", "authors": "Philipp Haehnel, Jakub Marecek, Julien Monteil, and Fearghal O'Donncha", "title": "Using Deep Learning to Extend the Range of Air-Pollution Monitoring and\n  Forecasting", "comments": "14 pages, 10 figures", "journal-ref": "Journal of Computational Physics, 2020", "doi": "10.1016/j.jcp.2020.109278", "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Across numerous applications, forecasting relies on numerical solvers for\npartial differential equations (PDEs). Although the use of deep-learning\ntechniques has been proposed, actual applications have been restricted by the\nfact the training data are obtained using traditional PDE solvers. Thereby, the\nuses of deep-learning techniques were limited to domains, where the PDE solver\nwas applicable.\n  We demonstrate a deep-learning framework for air-pollution monitoring and\nforecasting that provides the ability to train across different model domains,\nas well as a reduction in the run-time by two orders of magnitude. It presents\na first-of-a-kind implementation that combines deep-learning and\ndomain-decomposition techniques to allow model deployments extend beyond the\ndomain(s) on which the it has been trained.\n", "versions": [{"version": "v1", "created": "Mon, 22 Oct 2018 17:46:23 GMT"}, {"version": "v2", "created": "Sun, 29 Sep 2019 12:47:19 GMT"}, {"version": "v3", "created": "Sun, 26 Jan 2020 23:55:43 GMT"}], "update_date": "2020-01-28", "authors_parsed": [["Haehnel", "Philipp", ""], ["Marecek", "Jakub", ""], ["Monteil", "Julien", ""], ["O'Donncha", "Fearghal", ""]]}, {"id": "1810.09433", "submitter": "Ehsan Hajiramezanali", "authors": "Ehsan Hajiramezanali, Siamak Zamani Dadaneh, Alireza Karbalayghareh,\n  Mingyuan Zhou, and Xiaoning Qian", "title": "Bayesian multi-domain learning for cancer subtype discovery from\n  next-generation sequencing count data", "comments": "32nd Conference on Neural Information Processing Systems (NIPS 2018)", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG q-bio.GN stat.AP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Precision medicine aims for personalized prognosis and therapeutics by\nutilizing recent genome-scale high-throughput profiling techniques, including\nnext-generation sequencing (NGS). However, translating NGS data faces several\nchallenges. First, NGS count data are often overdispersed, requiring\nappropriate modeling. Second, compared to the number of involved molecules and\nsystem complexity, the number of available samples for studying complex\ndisease, such as cancer, is often limited, especially considering disease\nheterogeneity. The key question is whether we may integrate available data from\nall different sources or domains to achieve reproducible disease prognosis\nbased on NGS count data. In this paper, we develop a Bayesian Multi-Domain\nLearning (BMDL) model that derives domain-dependent latent representations of\noverdispersed count data based on hierarchical negative binomial factorization\nfor accurate cancer subtyping even if the number of samples for a specific\ncancer type is small. Experimental results from both our simulated and NGS\ndatasets from The Cancer Genome Atlas (TCGA) demonstrate the promising\npotential of BMDL for effective multi-domain learning without \"negative\ntransfer\" effects often seen in existing multi-task learning and transfer\nlearning methods.\n", "versions": [{"version": "v1", "created": "Mon, 22 Oct 2018 17:58:56 GMT"}], "update_date": "2018-10-23", "authors_parsed": [["Hajiramezanali", "Ehsan", ""], ["Dadaneh", "Siamak Zamani", ""], ["Karbalayghareh", "Alireza", ""], ["Zhou", "Mingyuan", ""], ["Qian", "Xiaoning", ""]]}, {"id": "1810.09440", "submitter": "Karim Pichara Baksai", "authors": "Carlos Aguirre and Karim Pichara and Ignacio Becker", "title": "Deep multi-survey classification of variable stars", "comments": "Accepted for publication in Monthly Notices of the Royal Astronomical\n  Society", "journal-ref": null, "doi": "10.1093/mnras/sty2836", "report-no": null, "categories": "astro-ph.IM cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  During the last decade, a considerable amount of effort has been made to\nclassify variable stars using different machine learning techniques. Typically,\nlight curves are represented as vectors of statistical descriptors or features\nthat are used to train various algorithms. These features demand big\ncomputational powers that can last from hours to days, making impossible to\ncreate scalable and efficient ways of automatically classifying variable stars.\nAlso, light curves from different surveys cannot be integrated and analyzed\ntogether when using features, because of observational differences. For\nexample, having variations in cadence and filters, feature distributions become\nbiased and require expensive data-calibration models. The vast amount of data\nthat will be generated soon make necessary to develop scalable machine learning\narchitectures without expensive integration techniques. Convolutional Neural\nNetworks have shown impressing results in raw image classification and\nrepresentation within the machine learning literature. In this work, we present\na novel Deep Learning model for light curve classification, mainly based on\nconvolutional units. Our architecture receives as input the differences between\ntime and magnitude of light curves. It captures the essential classification\npatterns regardless of cadence and filter. In addition, we introduce a novel\ndata augmentation schema for unevenly sampled time series. We test our method\nusing three different surveys: OGLE-III; Corot; and VVV, which differ in\nfilters, cadence, and area of the sky. We show that besides the benefit of\nscalability, our model obtains state of the art levels accuracy in light curve\nclassification benchmarks.\n", "versions": [{"version": "v1", "created": "Sun, 21 Oct 2018 14:22:31 GMT"}], "update_date": "2018-10-31", "authors_parsed": [["Aguirre", "Carlos", ""], ["Pichara", "Karim", ""], ["Becker", "Ignacio", ""]]}, {"id": "1810.09447", "submitter": "Babak Barazandeh", "authors": "Babak Barazandeh, Mohammadhussein Rafieisakhaei, Sunwook Kim, Zhenyu\n  (James) Kong, Maury A. Nussbaum", "title": "A Method for Robust Online Classification using Dictionary Learning:\n  Development and Assessment for Monitoring Manual Material Handling Activities\n  Using Wearable Sensors", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG stat.ME", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Classification methods based on sparse estimation have drawn much attention\nrecently, due to their effectiveness in processing high-dimensional data such\nas images. In this paper, a method to improve the performance of a sparse\nrepresentation classification (SRC) approach is proposed; it is then applied to\nthe problem of online process monitoring of human workers, specifically manual\nmaterial handling (MMH) operations monitored using wearable sensors (involving\n111 sensor channels). Our proposed method optimizes the design matrix (aka\ndictionary) in the linear model used for SRC, minimizing its ill-posedness to\nachieve a sparse solution. This procedure is based on the idea of dictionary\nlearning (DL): we optimize the design matrix formed by training datasets to\nminimize both redundancy and coherency as well as reducing the size of these\ndatasets. Use of such optimized training data can subsequently improve\nclassification accuracy and help decrease the computational time needed for the\nSRC; it is thus more applicable for online process monitoring. Performance of\nthe proposed methodology is demonstrated using wearable sensor data obtained\nfrom manual material handling experiments, and is found to be superior to those\nof benchmark methods in terms of accuracy, while also requiring computational\ntime appropriate for MMH online monitoring.\n", "versions": [{"version": "v1", "created": "Mon, 22 Oct 2018 03:13:48 GMT"}], "update_date": "2018-10-24", "authors_parsed": [["Barazandeh", "Babak", "", "James"], ["Rafieisakhaei", "Mohammadhussein", "", "James"], ["Kim", "Sunwook", "", "James"], ["Zhenyu", "", "", "James"], ["Kong", "", ""], ["Nussbaum", "Maury A.", ""]]}, {"id": "1810.09487", "submitter": "Philipp Tschandl MD PhD", "authors": "Philipp Tschandl, Giuseppe Argenziano, Majid Razmara, Jordan Yap", "title": "Diagnostic Accuracy of Content Based Dermatoscopic Image Retrieval with\n  Deep Classification Features", "comments": null, "journal-ref": "Tschandl P, Argenziano G, Razmara M, Yap J. Diagnostic Accuracy of\n  Content Based Dermatoscopic Image Retrieval with Deep Classification\n  Features. Br J Dermatol 2018 Sep 12. doi: 10.1111/bjd.17189", "doi": "10.1111/bjd.17189", "report-no": null, "categories": "cs.CV cs.HC cs.LG", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Background: Automated classification of medical images through neural\nnetworks can reach high accuracy rates but lack interpretability.\n  Objectives: To compare the diagnostic accuracy obtained by using content\nbased image retrieval (CBIR) to retrieve visually similar dermatoscopic images\nwith corresponding disease labels against predictions made by a neural network.\n  Methods: A neural network was trained to predict disease classes on\ndermatoscopic images from three retrospectively collected image datasets\ncontaining 888, 2750 and 16691 images respectively. Diagnosis predictions were\nmade based on the most commonly occurring diagnosis in visually similar images,\nor based on the top-1 class prediction of the softmax output from the network.\nOutcome measures were area under the ROC curve for predicting a malignant\nlesion (AUC), multiclass-accuracy and mean average precision (mAP), measured on\nunseen test images of the corresponding dataset.\n  Results: In all three datasets the skin cancer predictions from CBIR\n(evaluating the 16 most similar images) showed AUC values similar to softmax\npredictions (0.842, 0.806 and 0.852 versus 0.830, 0.810 and 0.847 respectively;\np-value>0.99 for all). Similarly, the multiclass-accuracy of CBIR was\ncomparable to softmax predictions. Networks trained for detecting only 3\nclasses performed better on a dataset with 8 classes when using CBIR as\ncompared to softmax predictions (mAP 0.184 vs. 0.368 and 0.198 vs. 0.403\nrespectively).\n  Conclusions: Presenting visually similar images based on features from a\nneural network shows comparable accuracy to the softmax probability-based\ndiagnoses of convolutional neural networks. CBIR may be more helpful than a\nsoftmax classifier in improving diagnostic accuracy of clinicians in a routine\nclinical setting.\n", "versions": [{"version": "v1", "created": "Mon, 22 Oct 2018 18:20:01 GMT"}], "update_date": "2018-10-24", "authors_parsed": [["Tschandl", "Philipp", ""], ["Argenziano", "Giuseppe", ""], ["Razmara", "Majid", ""], ["Yap", "Jordan", ""]]}, {"id": "1810.09502", "submitter": "Antreas Antoniou Mr", "authors": "Antreas Antoniou, Harrison Edwards and Amos Storkey", "title": "How to train your MAML", "comments": "Published in ICLR 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The field of few-shot learning has recently seen substantial advancements.\nMost of these advancements came from casting few-shot learning as a\nmeta-learning problem. Model Agnostic Meta Learning or MAML is currently one of\nthe best approaches for few-shot learning via meta-learning. MAML is simple,\nelegant and very powerful, however, it has a variety of issues, such as being\nvery sensitive to neural network architectures, often leading to instability\nduring training, requiring arduous hyperparameter searches to stabilize\ntraining and achieve high generalization and being very computationally\nexpensive at both training and inference times. In this paper, we propose\nvarious modifications to MAML that not only stabilize the system, but also\nsubstantially improve the generalization performance, convergence speed and\ncomputational overhead of MAML, which we call MAML++.\n", "versions": [{"version": "v1", "created": "Mon, 22 Oct 2018 18:48:16 GMT"}, {"version": "v2", "created": "Mon, 25 Feb 2019 06:13:09 GMT"}, {"version": "v3", "created": "Tue, 5 Mar 2019 23:11:02 GMT"}], "update_date": "2019-03-07", "authors_parsed": [["Antoniou", "Antreas", ""], ["Edwards", "Harrison", ""], ["Storkey", "Amos", ""]]}, {"id": "1810.09519", "submitter": "Justin Khim", "authors": "Justin Khim and Po-Ling Loh", "title": "Adversarial Risk Bounds via Function Transformation", "comments": "43 pages, 3 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We derive bounds for a notion of adversarial risk, designed to characterize\nthe robustness of linear and neural network classifiers to adversarial\nperturbations. Specifically, we introduce a new class of function\ntransformations with the property that the risk of the transformed functions\nupper-bounds the adversarial risk of the original functions. This reduces the\nproblem of deriving bounds on the adversarial risk to the problem of deriving\nrisk bounds using standard learning-theoretic techniques. We then derive bounds\non the Rademacher complexities of the transformed function classes, obtaining\nerror rates on the same order as the generalization error of the original\nfunction classes. We also discuss extensions of our theory to multiclass\nclassification and regression. Finally, we provide two algorithms for\noptimizing the adversarial risk bounds in the linear case, and discuss\nconnections to regularization and distributional robustness.\n", "versions": [{"version": "v1", "created": "Mon, 22 Oct 2018 19:51:20 GMT"}, {"version": "v2", "created": "Tue, 1 Jan 2019 22:29:27 GMT"}], "update_date": "2019-01-03", "authors_parsed": [["Khim", "Justin", ""], ["Loh", "Po-Ling", ""]]}, {"id": "1810.09520", "submitter": "Matthieu Gilson", "authors": "Matthieu Gilson and Jean-Pascal Pfister", "title": "Propagation of spiking moments in linear Hawkes networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.NC cs.LG", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  The present paper provides exact mathematical expressions for the high-order\nmoments of spiking activity in a recurrently-connected network of linear Hawkes\nprocesses. It extends previous studies that have explored the case of a\n(linear) Hawkes network driven by deterministic intensity functions to the case\nof a stimulation by external inputs (rate functions or spike trains) with\narbitrary correlation structure. Our approach describes the spatio-temporal\nfiltering induced by the afferent and recurrent connectivities (with arbitrary\nsynaptic response kernels) using operators acting on the input moments. This\nalgebraic viewpoint provides intuition about how the network ingredients shape\nthe input-output mapping for moments, as well as cumulants. We also show using\nnumerical simulation that our results hold for neurons with refractoriness\nimplemented by self-inhibition, provided the corresponding negative feedback\nfor each neuron only mildly alters its mean firing probability.\n", "versions": [{"version": "v1", "created": "Tue, 18 Sep 2018 17:03:49 GMT"}, {"version": "v2", "created": "Thu, 12 Sep 2019 14:57:48 GMT"}, {"version": "v3", "created": "Mon, 16 Dec 2019 16:12:09 GMT"}], "update_date": "2019-12-17", "authors_parsed": [["Gilson", "Matthieu", ""], ["Pfister", "Jean-Pascal", ""]]}, {"id": "1810.09536", "submitter": "Yikang Shen", "authors": "Yikang Shen, Shawn Tan, Alessandro Sordoni and Aaron Courville", "title": "Ordered Neurons: Integrating Tree Structures into Recurrent Neural\n  Networks", "comments": "Published as a conference paper at ICLR 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Natural language is hierarchically structured: smaller units (e.g., phrases)\nare nested within larger units (e.g., clauses). When a larger constituent ends,\nall of the smaller constituents that are nested within it must also be closed.\nWhile the standard LSTM architecture allows different neurons to track\ninformation at different time scales, it does not have an explicit bias towards\nmodeling a hierarchy of constituents. This paper proposes to add such an\ninductive bias by ordering the neurons; a vector of master input and forget\ngates ensures that when a given neuron is updated, all the neurons that follow\nit in the ordering are also updated. Our novel recurrent architecture, ordered\nneurons LSTM (ON-LSTM), achieves good performance on four different tasks:\nlanguage modeling, unsupervised parsing, targeted syntactic evaluation, and\nlogical inference.\n", "versions": [{"version": "v1", "created": "Mon, 22 Oct 2018 20:37:46 GMT"}, {"version": "v2", "created": "Wed, 21 Nov 2018 18:11:47 GMT"}, {"version": "v3", "created": "Mon, 26 Nov 2018 20:38:05 GMT"}, {"version": "v4", "created": "Wed, 24 Apr 2019 15:38:54 GMT"}, {"version": "v5", "created": "Tue, 30 Apr 2019 14:57:34 GMT"}, {"version": "v6", "created": "Wed, 8 May 2019 15:06:14 GMT"}], "update_date": "2019-05-09", "authors_parsed": [["Shen", "Yikang", ""], ["Tan", "Shawn", ""], ["Sordoni", "Alessandro", ""], ["Courville", "Aaron", ""]]}, {"id": "1810.09538", "submitter": "Eli Bingham", "authors": "Eli Bingham, Jonathan P. Chen, Martin Jankowiak, Fritz Obermeyer,\n  Neeraj Pradhan, Theofanis Karaletsos, Rohit Singh, Paul Szerlip, Paul\n  Horsfall, Noah D. Goodman", "title": "Pyro: Deep Universal Probabilistic Programming", "comments": "Submitted to JMLR MLOSS track", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.PL stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Pyro is a probabilistic programming language built on Python as a platform\nfor developing advanced probabilistic models in AI research. To scale to large\ndatasets and high-dimensional models, Pyro uses stochastic variational\ninference algorithms and probability distributions built on top of PyTorch, a\nmodern GPU-accelerated deep learning framework. To accommodate complex or\nmodel-specific algorithmic behavior, Pyro leverages Poutine, a library of\ncomposable building blocks for modifying the behavior of probabilistic\nprograms.\n", "versions": [{"version": "v1", "created": "Thu, 18 Oct 2018 19:28:32 GMT"}], "update_date": "2018-10-24", "authors_parsed": [["Bingham", "Eli", ""], ["Chen", "Jonathan P.", ""], ["Jankowiak", "Martin", ""], ["Obermeyer", "Fritz", ""], ["Pradhan", "Neeraj", ""], ["Karaletsos", "Theofanis", ""], ["Singh", "Rohit", ""], ["Szerlip", "Paul", ""], ["Horsfall", "Paul", ""], ["Goodman", "Noah D.", ""]]}, {"id": "1810.09549", "submitter": "Benjamin Day", "authors": "Conor Sheehan, Ben Day, Pietro Li\\`o", "title": "Introducing Curvature to the Label Space", "comments": "Under review as a workshop paper at MetaLearn, NIPS 2018, 4 pages, 2\n  figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  One-hot encoding is a labelling system that embeds classes as standard basis\nvectors in a label space. Despite seeing near-universal use in supervised\ncategorical classification tasks, the scheme is problematic in its geometric\nimplication that, as all classes are equally distant, all classes are equally\ndifferent. This is inconsistent with most, if not all, real-world tasks due to\nthe prevalence of ancestral and convergent relationships generating a varying\ndegree of morphological similarity across classes. We address this issue by\nintroducing curvature to the label-space using a metric tensor as a\nself-regulating method that better represents these relationships as a bolt-on,\nlearning-algorithm agnostic solution. We propose both general constraints and\nspecific statistical parameterizations of the metric and identify a direction\nfor future research using autoencoder-based parameterizations.\n", "versions": [{"version": "v1", "created": "Mon, 22 Oct 2018 20:57:42 GMT"}], "update_date": "2018-10-24", "authors_parsed": [["Sheehan", "Conor", ""], ["Day", "Ben", ""], ["Li\u00f2", "Pietro", ""]]}, {"id": "1810.09558", "submitter": "Houssam Nassif", "authors": "Daniel N Hill, Houssam Nassif, Yi Liu, Anand Iyer, S V N Vishwanathan", "title": "An Efficient Bandit Algorithm for Realtime Multivariate Optimization", "comments": "KDD'17 Audience Appreciation Award", "journal-ref": "Daniel N. Hill, Houssam Nassif, Yi Liu, Anand Iyer, and S. V. N.\n  Vishwanathan. 2017. An Efficient Bandit Algorithm for Realtime Multivariate\n  Optimization. In Proceedings of KDD'17, Halifax, NS, Canada, pp. 1813-1821,\n  2017", "doi": "10.1145/3097983.3098184", "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Optimization is commonly employed to determine the content of web pages, such\nas to maximize conversions on landing pages or click-through rates on search\nengine result pages. Often the layout of these pages can be decoupled into\nseveral separate decisions. For example, the composition of a landing page may\ninvolve deciding which image to show, which wording to use, what color\nbackground to display, etc. Such optimization is a combinatorial problem over\nan exponentially large decision space. Randomized experiments do not scale well\nto this setting, and therefore, in practice, one is typically limited to\noptimizing a single aspect of a web page at a time. This represents a missed\nopportunity in both the speed of experimentation and the exploitation of\npossible interactions between layout decisions.\n  Here we focus on multivariate optimization of interactive web pages. We\nformulate an approach where the possible interactions between different\ncomponents of the page are modeled explicitly. We apply bandit methodology to\nexplore the layout space efficiently and use hill-climbing to select optimal\ncontent in realtime. Our algorithm also extends to contextualization and\npersonalization of layout selection. Simulation results show the suitability of\nour approach to large decision spaces with strong interactions between content.\nWe further apply our algorithm to optimize a message that promotes adoption of\nan Amazon service. After only a single week of online optimization, we saw a\n21% conversion increase compared to the median layout. Our technique is\ncurrently being deployed to optimize content across several locations at\nAmazon.com.\n", "versions": [{"version": "v1", "created": "Mon, 22 Oct 2018 21:09:38 GMT"}], "update_date": "2018-10-24", "authors_parsed": [["Hill", "Daniel N", ""], ["Nassif", "Houssam", ""], ["Liu", "Yi", ""], ["Iyer", "Anand", ""], ["Vishwanathan", "S V N", ""]]}, {"id": "1810.09568", "submitter": "Shane Barratt", "authors": "Shane Barratt, Mykel Kochenderfer, and Stephen Boyd", "title": "Learning Probabilistic Trajectory Models of Aircraft in Terminal\n  Airspace from Position Data", "comments": "IEEE Transactions on Intelligent Transportation Systems", "journal-ref": null, "doi": "10.1109/TITS.2018.2877572", "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Models for predicting aircraft motion are an important component of modern\naeronautical systems. These models help aircraft plan collision avoidance\nmaneuvers and help conduct offline performance and safety analyses. In this\narticle, we develop a method for learning a probabilistic generative model of\naircraft motion in terminal airspace, the controlled airspace surrounding a\ngiven airport. The method fits the model based on a historical dataset of\nradar-based position measurements of aircraft landings and takeoffs at that\nairport. We find that the model generates realistic trajectories, provides\naccurate predictions, and captures the statistical properties of aircraft\ntrajectories. Furthermore, the model trains quickly, is compact, and allows for\nefficient real-time inference.\n", "versions": [{"version": "v1", "created": "Mon, 22 Oct 2018 21:41:11 GMT"}], "update_date": "2018-10-24", "authors_parsed": [["Barratt", "Shane", ""], ["Kochenderfer", "Mykel", ""], ["Boyd", "Stephen", ""]]}, {"id": "1810.09569", "submitter": "Adel Javanmard", "authors": "Ery Arias-Castro, Adel Javanmard, Bruno Pelletier", "title": "Perturbation Bounds for Procrustes, Classical Scaling, and\n  Trilateration, with Applications to Manifold Learning", "comments": "33 pages, 6 Figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.NA math.NA stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  One of the common tasks in unsupervised learning is dimensionality reduction,\nwhere the goal is to find meaningful low-dimensional structures hidden in\nhigh-dimensional data. Sometimes referred to as manifold learning, this problem\nis closely related to the problem of localization, which aims at embedding a\nweighted graph into a low-dimensional Euclidean space. Several methods have\nbeen proposed for localization, and also manifold learning. Nonetheless, the\nrobustness property of most of them is little understood. In this paper, we\nobtain perturbation bounds for classical scaling and trilateration, which are\nthen applied to derive performance bounds for Isomap, Landmark Isomap, and\nMaximum Variance Unfolding. A new perturbation bound for procrustes analysis\nplays a key role.\n", "versions": [{"version": "v1", "created": "Mon, 22 Oct 2018 21:43:33 GMT"}, {"version": "v2", "created": "Thu, 24 Oct 2019 20:41:02 GMT"}], "update_date": "2019-10-28", "authors_parsed": [["Arias-Castro", "Ery", ""], ["Javanmard", "Adel", ""], ["Pelletier", "Bruno", ""]]}, {"id": "1810.09583", "submitter": "Jie Ding", "authors": "Jie Ding, Vahid Tarokh, and Yuhong Yang", "title": "Model Selection Techniques -- An Overview", "comments": "accepted by IEEE SIGNAL PROCESSING MAGAZINE", "journal-ref": null, "doi": "10.1109/MSP.2018.2867638", "report-no": null, "categories": "stat.ML cs.IT cs.LG econ.EM math.IT physics.app-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In the era of big data, analysts usually explore various statistical models\nor machine learning methods for observed data in order to facilitate scientific\ndiscoveries or gain predictive power. Whatever data and fitting procedures are\nemployed, a crucial step is to select the most appropriate model or method from\na set of candidates. Model selection is a key ingredient in data analysis for\nreliable and reproducible statistical inference or prediction, and thus central\nto scientific studies in fields such as ecology, economics, engineering,\nfinance, political science, biology, and epidemiology. There has been a long\nhistory of model selection techniques that arise from researches in statistics,\ninformation theory, and signal processing. A considerable number of methods\nhave been proposed, following different philosophies and exhibiting varying\nperformances. The purpose of this article is to bring a comprehensive overview\nof them, in terms of their motivation, large sample performance, and\napplicability. We provide integrated and practically relevant discussions on\ntheoretical properties of state-of- the-art model selection approaches. We also\nshare our thoughts on some controversial views on the practice of model\nselection.\n", "versions": [{"version": "v1", "created": "Mon, 22 Oct 2018 22:33:44 GMT"}], "update_date": "2018-10-24", "authors_parsed": [["Ding", "Jie", ""], ["Tarokh", "Vahid", ""], ["Yang", "Yuhong", ""]]}, {"id": "1810.09591", "submitter": "Malay Haldar", "authors": "Malay Haldar, Mustafa Abdool, Prashant Ramanathan, Tao Xu, Shulin\n  Yang, Huizhong Duan, Qing Zhang, Nick Barrow-Williams, Bradley C. Turnbull,\n  Brendan M. Collins and Thomas Legrand", "title": "Applying Deep Learning To Airbnb Search", "comments": "8 pages", "journal-ref": null, "doi": "10.1145/3292500.3330658", "report-no": null, "categories": "cs.LG cs.AI cs.IR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The application to search ranking is one of the biggest machine learning\nsuccess stories at Airbnb. Much of the initial gains were driven by a gradient\nboosted decision tree model. The gains, however, plateaued over time. This\npaper discusses the work done in applying neural networks in an attempt to\nbreak out of that plateau. We present our perspective not with the intention of\npushing the frontier of new modeling techniques. Instead, ours is a story of\nthe elements we found useful in applying neural networks to a real life\nproduct. Deep learning was steep learning for us. To other teams embarking on\nsimilar journeys, we hope an account of our struggles and triumphs will provide\nsome useful pointers. Bon voyage!\n", "versions": [{"version": "v1", "created": "Mon, 22 Oct 2018 23:11:01 GMT"}, {"version": "v2", "created": "Wed, 24 Oct 2018 18:28:03 GMT"}], "update_date": "2020-02-13", "authors_parsed": [["Haldar", "Malay", ""], ["Abdool", "Mustafa", ""], ["Ramanathan", "Prashant", ""], ["Xu", "Tao", ""], ["Yang", "Shulin", ""], ["Duan", "Huizhong", ""], ["Zhang", "Qing", ""], ["Barrow-Williams", "Nick", ""], ["Turnbull", "Bradley C.", ""], ["Collins", "Brendan M.", ""], ["Legrand", "Thomas", ""]]}, {"id": "1810.09593", "submitter": "Edward Choi", "authors": "Edward Choi, Cao Xiao, Walter F. Stewart, Jimeng Sun", "title": "MiME: Multilevel Medical Embedding of Electronic Health Records for\n  Predictive Healthcare", "comments": "Accepted at NIPS 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CL stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep learning models exhibit state-of-the-art performance for many predictive\nhealthcare tasks using electronic health records (EHR) data, but these models\ntypically require training data volume that exceeds the capacity of most\nhealthcare systems. External resources such as medical ontologies are used to\nbridge the data volume constraint, but this approach is often not directly\napplicable or useful because of inconsistencies with terminology. To solve the\ndata insufficiency challenge, we leverage the inherent multilevel structure of\nEHR data and, in particular, the encoded relationships among medical codes. We\npropose Multilevel Medical Embedding (MiME) which learns the multilevel\nembedding of EHR data while jointly performing auxiliary prediction tasks that\nrely on this inherent EHR structure without the need for external labels. We\nconducted two prediction tasks, heart failure prediction and sequential disease\nprediction, where MiME outperformed baseline methods in diverse evaluation\nsettings. In particular, MiME consistently outperformed all baselines when\npredicting heart failure on datasets of different volumes, especially\ndemonstrating the greatest performance improvement (15% relative gain in PR-AUC\nover the best baseline) on the smallest dataset, demonstrating its ability to\neffectively model the multilevel structure of EHR data.\n", "versions": [{"version": "v1", "created": "Mon, 22 Oct 2018 23:19:43 GMT"}], "update_date": "2018-10-24", "authors_parsed": [["Choi", "Edward", ""], ["Xiao", "Cao", ""], ["Stewart", "Walter F.", ""], ["Sun", "Jimeng", ""]]}, {"id": "1810.09597", "submitter": "Setu Shah", "authors": "Setu Shah and Xiao Luo", "title": "Biomedical Document Clustering and Visualization based on the Concepts\n  of Diseases", "comments": "KDD 2017's Data Driven Discovery Workshop", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Document clustering is a text mining technique used to provide better\ndocument search and browsing in digital libraries or online corpora. A lot of\nresearch has been done on biomedical document clustering that is based on using\nexisting ontology. But, associations and co-occurrences of the medical concepts\nare not well represented by using ontology. In this research, a vector\nrepresentation of concepts of diseases and similarity measurement between\nconcepts are proposed. They identify the closest concepts of diseases in the\ncontext of a corpus. Each document is represented by using the vector space\nmodel. A weight scheme is proposed to consider both local content and\nassociations between concepts. A Self-Organizing Map is used as document\nclustering algorithm. The vector projection and visualization features of SOM\nenable visualization and analysis of the clusters distributions and\nrelationships on the two dimensional space. The experimental results show that\nthe proposed document clustering framework generates meaningful clusters and\nfacilitate visualization of the clusters based on the concepts of diseases.\n", "versions": [{"version": "v1", "created": "Mon, 22 Oct 2018 23:37:31 GMT"}], "update_date": "2018-10-24", "authors_parsed": [["Shah", "Setu", ""], ["Luo", "Xiao", ""]]}, {"id": "1810.09619", "submitter": "Yiwen Guo", "authors": "Yiwen Guo, Chao Zhang, Changshui Zhang and Yurong Chen", "title": "Sparse DNNs with Improved Adversarial Robustness", "comments": "l1 regularization on weights --> l1 regularization on activations", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR cs.CV cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep neural networks (DNNs) are computationally/memory-intensive and\nvulnerable to adversarial attacks, making them prohibitive in some real-world\napplications. By converting dense models into sparse ones, pruning appears to\nbe a promising solution to reducing the computation/memory cost. This paper\nstudies classification models, especially DNN-based ones, to demonstrate that\nthere exists intrinsic relationships between their sparsity and adversarial\nrobustness. Our analyses reveal, both theoretically and empirically, that\nnonlinear DNN-based classifiers behave differently under $l_2$ attacks from\nsome linear ones. We further demonstrate that an appropriately higher model\nsparsity implies better robustness of nonlinear DNNs, whereas over-sparsified\nmodels can be more difficult to resist adversarial examples.\n", "versions": [{"version": "v1", "created": "Tue, 23 Oct 2018 01:05:41 GMT"}, {"version": "v2", "created": "Wed, 6 Nov 2019 01:32:50 GMT"}], "update_date": "2019-11-07", "authors_parsed": [["Guo", "Yiwen", ""], ["Zhang", "Chao", ""], ["Zhang", "Changshui", ""], ["Chen", "Yurong", ""]]}, {"id": "1810.09620", "submitter": "Derek Doran", "authors": "Giuseppe Nebbione, Derek Doran, Srikanth Nadella, Brandon Minnery", "title": "Deep Neural Ranking for Crowdsourced Geopolitical Event Forecasting", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  There are many examples of 'wisdom of the crowd' effects in which the large\nnumber of participants imparts confidence in the collective judgment of the\ncrowd. But how do we form an aggregated judgment when the size of the crowd is\nlimited? Whose judgments do we include, and whose do we accord the most weight?\nThis paper considers this problem in the context of geopolitical event\nforecasting, where volunteer analysts are queried to give their expertise,\nconfidence, and predictions about the outcome of an event. We develop a\nforecast aggregation model that integrates topical information about a\nquestion, meta-data about a pair of forecasters, and their predictions in a\ndeep siamese neural network that decides which forecasters' predictions are\nmore likely to be close to the correct response. A ranking of the forecasters\nis induced from a tournament of pair-wise forecaster comparisons, with the\nranking used to create an aggregate forecast. Preliminary results find the\naggregate prediction of the best forecasters ranked by our deep siamese network\nmodel consistently beats typical aggregation techniques by Brier score.\n", "versions": [{"version": "v1", "created": "Tue, 23 Oct 2018 01:08:25 GMT"}], "update_date": "2018-10-24", "authors_parsed": [["Nebbione", "Giuseppe", ""], ["Doran", "Derek", ""], ["Nadella", "Srikanth", ""], ["Minnery", "Brandon", ""]]}, {"id": "1810.09630", "submitter": "Bo Dai", "authors": "Bo Dai, Sanja Fidler, Dahua Lin", "title": "A Neural Compositional Paradigm for Image Captioning", "comments": "32nd Conference on Neural Information Processing Systems (NIPS 2018),\n  Montr\\'eal, Canada", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Mainstream captioning models often follow a sequential structure to generate\ncaptions, leading to issues such as introduction of irrelevant semantics, lack\nof diversity in the generated captions, and inadequate generalization\nperformance. In this paper, we present an alternative paradigm for image\ncaptioning, which factorizes the captioning procedure into two stages: (1)\nextracting an explicit semantic representation from the given image; and (2)\nconstructing the caption based on a recursive compositional procedure in a\nbottom-up manner. Compared to conventional ones, our paradigm better preserves\nthe semantic content through an explicit factorization of semantics and syntax.\nBy using the compositional generation procedure, caption construction follows a\nrecursive structure, which naturally fits the properties of human language.\nMoreover, the proposed compositional procedure requires less data to train,\ngeneralizes better, and yields more diverse captions.\n", "versions": [{"version": "v1", "created": "Tue, 23 Oct 2018 02:16:12 GMT"}], "update_date": "2018-10-24", "authors_parsed": [["Dai", "Bo", ""], ["Fidler", "Sanja", ""], ["Lin", "Dahua", ""]]}, {"id": "1810.09650", "submitter": "Jingkang Wang", "authors": "Jingkang Wang, Ruoxi Jia, Gerald Friedland, Bo Li, Costas Spanos", "title": "One Bit Matters: Understanding Adversarial Examples as the Abuse of\n  Redundancy", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR cs.CV cs.IT math.IT stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Despite the great success achieved in machine learning (ML), adversarial\nexamples have caused concerns with regards to its trustworthiness: A small\nperturbation of an input results in an arbitrary failure of an otherwise\nseemingly well-trained ML model. While studies are being conducted to discover\nthe intrinsic properties of adversarial examples, such as their transferability\nand universality, there is insufficient theoretic analysis to help understand\nthe phenomenon in a way that can influence the design process of ML\nexperiments. In this paper, we deduce an information-theoretic model which\nexplains adversarial attacks as the abuse of feature redundancies in ML\nalgorithms. We prove that feature redundancy is a necessary condition for the\nexistence of adversarial examples. Our model helps to explain some major\nquestions raised in many anecdotal studies on adversarial examples. Our theory\nis backed up by empirical measurements of the information content of benign and\nadversarial examples on both image and text datasets. Our measurements show\nthat typical adversarial examples introduce just enough redundancy to overflow\nthe decision making of an ML model trained on corresponding benign examples. We\nconclude with actionable recommendations to improve the robustness of machine\nlearners against adversarial examples.\n", "versions": [{"version": "v1", "created": "Tue, 23 Oct 2018 04:23:25 GMT"}], "update_date": "2018-10-24", "authors_parsed": [["Wang", "Jingkang", ""], ["Jia", "Ruoxi", ""], ["Friedland", "Gerald", ""], ["Li", "Bo", ""], ["Spanos", "Costas", ""]]}, {"id": "1810.09656", "submitter": "Ermo Wei", "authors": "Ermo Wei and Drew Wicke and Sean Luke", "title": "Hierarchical Approaches for Reinforcement Learning in Parameterized\n  Action Space", "comments": "Accepted in AAAI 18 Spring Symposium", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We explore Deep Reinforcement Learning in a parameterized action space.\nSpecifically, we investigate how to achieve sample-efficient end-to-end\ntraining in these tasks. We propose a new compact architecture for the tasks\nwhere the parameter policy is conditioned on the output of the discrete action\npolicy. We also propose two new methods based on the state-of-the-art\nalgorithms Trust Region Policy Optimization (TRPO) and Stochastic Value\nGradient (SVG) to train such an architecture. We demonstrate that these methods\noutperform the state of the art method, Parameterized Action DDPG, on test\ndomains.\n", "versions": [{"version": "v1", "created": "Tue, 23 Oct 2018 04:52:53 GMT"}], "update_date": "2018-10-24", "authors_parsed": [["Wei", "Ermo", ""], ["Wicke", "Drew", ""], ["Luke", "Sean", ""]]}, {"id": "1810.09665", "submitter": "Stefano Spigler", "authors": "Stefano Spigler, Mario Geiger, St\\'ephane d'Ascoli, Levent Sagun,\n  Giulio Biroli and Matthieu Wyart", "title": "A jamming transition from under- to over-parametrization affects loss\n  landscape and generalization", "comments": "arXiv admin note: text overlap with arXiv:1809.09349", "journal-ref": null, "doi": "10.1088/1751-8121/ab4c8b", "report-no": null, "categories": "cs.LG cond-mat.dis-nn stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We argue that in fully-connected networks a phase transition delimits the\nover- and under-parametrized regimes where fitting can or cannot be achieved.\nUnder some general conditions, we show that this transition is sharp for the\nhinge loss. In the whole over-parametrized regime, poor minima of the loss are\nnot encountered during training since the number of constraints to satisfy is\ntoo small to hamper minimization. Our findings support a link between this\ntransition and the generalization properties of the network: as we increase the\nnumber of parameters of a given model, starting from an under-parametrized\nnetwork, we observe that the generalization error displays three phases: (i)\ninitial decay, (ii) increase until the transition point --- where it displays a\ncusp --- and (iii) slow decay toward a constant for the rest of the\nover-parametrized regime. Thereby we identify the region where the classical\nphenomenon of over-fitting takes place, and the region where the model keeps\nimproving, in line with previous empirical observations for modern neural\nnetworks.\n", "versions": [{"version": "v1", "created": "Mon, 22 Oct 2018 09:49:32 GMT"}, {"version": "v2", "created": "Thu, 29 Nov 2018 09:22:15 GMT"}, {"version": "v3", "created": "Tue, 5 Feb 2019 13:29:18 GMT"}, {"version": "v4", "created": "Mon, 18 Feb 2019 09:19:24 GMT"}, {"version": "v5", "created": "Tue, 18 Jun 2019 09:51:38 GMT"}], "update_date": "2020-01-08", "authors_parsed": [["Spigler", "Stefano", ""], ["Geiger", "Mario", ""], ["d'Ascoli", "St\u00e9phane", ""], ["Sagun", "Levent", ""], ["Biroli", "Giulio", ""], ["Wyart", "Matthieu", ""]]}, {"id": "1810.09666", "submitter": "Anshuka Rangi", "authors": "Anshuka Rangi and Massimo Franceschetti", "title": "Online learning with feedback graphs and switching costs", "comments": "Published in Proceedings of the 22nd International Conference on\n  Artificial Intelligence and Statistics (AISTATS) 2019. PMLR: Volume 89", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study online learning when partial feedback information is provided\nfollowing every action of the learning process, and the learner incurs\nswitching costs for changing his actions. In this setting, the feedback\ninformation system can be represented by a graph, and previous works studied\nthe expected regret of the learner in the case of a clique (Expert setup), or\ndisconnected single loops (Multi-Armed Bandits (MAB)). This work provides a\nlower bound on the expected regret in the Partial Information (PI) setting,\nnamely for general feedback graphs --excluding the clique. Additionally, it\nshows that all algorithms that are optimal without switching costs are\nnecessarily sub-optimal in the presence of switching costs, which motivates the\nneed to design new algorithms. We propose two new algorithms: Threshold Based\nEXP3 and EXP3. SC. For the two special cases of symmetric PI setting and MAB,\nthe expected regret of both of these algorithms is order optimal in the\nduration of the learning process. Additionally, Threshold Based EXP3 is order\noptimal in the switching cost, whereas EXP3. SC is not. Finally, empirical\nevaluations show that Threshold Based EXP3 outperforms the previously proposed\norder-optimal algorithms EXP3 SET in the presence of switching costs, and Batch\nEXP3 in the MAB setting with switching costs.\n", "versions": [{"version": "v1", "created": "Tue, 23 Oct 2018 05:34:19 GMT"}, {"version": "v2", "created": "Mon, 20 May 2019 15:16:46 GMT"}], "update_date": "2019-05-21", "authors_parsed": [["Rangi", "Anshuka", ""], ["Franceschetti", "Massimo", ""]]}, {"id": "1810.09675", "submitter": "Yuehaw Khoo", "authors": "Yuehaw Khoo and Lexing Ying", "title": "SwitchNet: a neural network model for forward and inverse scattering\n  problems", "comments": "19 pages, 7 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.NA cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a novel neural network architecture, SwitchNet, for solving the\nwave equation based inverse scattering problems via providing maps between the\nscatterers and the scattered field (and vice versa). The main difficulty of\nusing a neural network for this problem is that a scatterer has a global impact\non the scattered wave field, rendering typical convolutional neural network\nwith local connections inapplicable. While it is possible to deal with such a\nproblem using a fully connected network, the number of parameters grows\nquadratically with the size of the input and output data. By leveraging the\ninherent low-rank structure of the scattering problems and introducing a novel\nswitching layer with sparse connections, the SwitchNet architecture uses much\nfewer parameters and facilitates the training process. Numerical experiments\nshow promising accuracy in learning the forward and inverse maps between the\nscatterers and the scattered wave field.\n", "versions": [{"version": "v1", "created": "Tue, 23 Oct 2018 06:15:33 GMT"}], "update_date": "2018-10-29", "authors_parsed": [["Khoo", "Yuehaw", ""], ["Ying", "Lexing", ""]]}, {"id": "1810.09683", "submitter": "Giuseppe Antonio Di Luna", "authors": "Roberto Baldoni, Giuseppe Antonio Di Luna, Luca Massarelli, Fabio\n  Petroni, Leonardo Querzoni", "title": "Unsupervised Features Extraction for Binary Similarity Using Graph\n  Embedding Neural Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we consider the binary similarity problem that consists in\ndetermining if two binary functions are similar only considering their compiled\nform. This problem is know to be crucial in several application scenarios, such\nas copyright disputes, malware analysis, vulnerability detection, etc. The\ncurrent state-of-the-art solutions in this field work by creating an embedding\nmodel that maps binary functions into vectors in $\\mathbb{R}^{n}$. Such\nembedding model captures syntactic and semantic similarity between binaries,\ni.e., similar binary functions are mapped to points that are close in the\nvector space. This strategy has many advantages, one of them is the possibility\nto precompute embeddings of several binary functions, and then compare them\nwith simple geometric operations (e.g., dot product). In [32] functions are\nfirst transformed in Annotated Control Flow Graphs (ACFGs) constituted by\nmanually engineered features and then graphs are embedded into vectors using a\ndeep neural network architecture. In this paper we propose and test several\nways to compute annotated control flow graphs that use unsupervised approaches\nfor feature learning, without incurring a human bias. Our methods are inspired\nafter techniques used in the natural language processing community (e.g., we\nuse word2vec to encode assembly instructions). We show that our approach is\nindeed successful, and it leads to better performance than previous\nstate-of-the-art solutions. Furthermore, we report on a qualitative analysis of\nfunctions embeddings. We found interesting cases in which embeddings are\nclustered according to the semantic of the original binary function.\n", "versions": [{"version": "v1", "created": "Tue, 23 Oct 2018 06:45:54 GMT"}, {"version": "v2", "created": "Tue, 13 Nov 2018 13:26:55 GMT"}], "update_date": "2018-11-14", "authors_parsed": [["Baldoni", "Roberto", ""], ["Di Luna", "Giuseppe Antonio", ""], ["Massarelli", "Luca", ""], ["Petroni", "Fabio", ""], ["Querzoni", "Leonardo", ""]]}, {"id": "1810.09712", "submitter": "Tomoharu Iwata", "authors": "Tomoharu Iwata, Takuma Otsuka, Hitoshi Shimizu, Hiroshi Sawada,\n  Futoshi Naya, Naonori Ueda", "title": "Finding Appropriate Traffic Regulations via Graph Convolutional Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "physics.soc-ph cs.AI cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Appropriate traffic regulations, e.g. planned road closure, are important in\ncongested events. Crowd simulators have been used to find appropriate\nregulations by simulating multiple scenarios with different regulations.\nHowever, this approach requires multiple simulation runs, which are\ntime-consuming. In this paper, we propose a method to learn a function that\noutputs regulation effects given the current traffic situation as inputs. If\nthe function is learned using the training data of many simulation runs in\nadvance, we can obtain an appropriate regulation efficiently by bypassing\nsimulations for the current situation. We use the graph convolutional networks\nfor modeling the function, which enable us to find regulations even for unseen\nareas. With the proposed method, we construct a graph for each area, where a\nnode represents a road, and an edge represents the road connection. By running\ncrowd simulations with various regulations on various areas, we generate\ntraffic situations and regulation effects. The graph convolutional networks are\ntrained to output the regulation effects given the graph with the traffic\nsituation information as inputs. With experiments using real-world road\nnetworks and a crowd simulator, we demonstrate that the proposed method can\nfind a road to close that reduces the average time needed to reach the\ndestination.\n", "versions": [{"version": "v1", "created": "Tue, 23 Oct 2018 08:19:33 GMT"}], "update_date": "2018-10-24", "authors_parsed": [["Iwata", "Tomoharu", ""], ["Otsuka", "Takuma", ""], ["Shimizu", "Hitoshi", ""], ["Sawada", "Hiroshi", ""], ["Naya", "Futoshi", ""], ["Ueda", "Naonori", ""]]}, {"id": "1810.09717", "submitter": "Jakub Bednarek", "authors": "Jakub Bednarek, Karol Piaskowski, Krzysztof Krawiec", "title": "Ain't Nobody Got Time For Coding: Structure-Aware Program Synthesis From\n  Natural Language", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.PL stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Program synthesis from natural language (NL) is practical for humans and,\nonce technically feasible, would significantly facilitate software development\nand revolutionize end-user programming. We present SAPS, an end-to-end neural\nnetwork capable of mapping relatively complex, multi-sentence NL specifications\nto snippets of executable code. The proposed architecture relies exclusively on\nneural components, and is trained on abstract syntax trees, combined with a\npretrained word embedding and a bi-directional multi-layer LSTM for processing\nof word sequences. The decoder features a doubly-recurrent LSTM, for which we\npropose novel signal propagation schemes and soft attention mechanism. When\napplied to a large dataset of problems proposed in a previous study, SAPS\nperforms on par with or better than the method proposed there, producing\ncorrect programs in over 92% of cases. In contrast to other methods, it does\nnot require post-processing of the resulting programs, and uses a\nfixed-dimensional latent representation as the only interface between the NL\nanalyzer and the source code generator.\n", "versions": [{"version": "v1", "created": "Tue, 23 Oct 2018 08:29:11 GMT"}, {"version": "v2", "created": "Mon, 18 Feb 2019 07:17:09 GMT"}], "update_date": "2019-02-19", "authors_parsed": [["Bednarek", "Jakub", ""], ["Piaskowski", "Karol", ""], ["Krawiec", "Krzysztof", ""]]}, {"id": "1810.09733", "submitter": "Maria Cristina Heredia G\\'omez", "authors": "M. Cristina Heredia-G\\'omez, Salvador Garc\\'ia, Pedro Antonio\n  Guti\\'errez, Francisco Herrera", "title": "OCAPIS: R package for Ordinal Classification And Preprocessing In Scala", "comments": "16 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Ordinal Data are those where a natural order exist between the labels. The\nclassification and pre-processing of this type of data is attracting more and\nmore interest in the area of machine learning, due to its presence in many\ncommon problems. Traditionally, ordinal classification problems have been\napproached as nominal problems. However, that implies not taking into account\ntheir natural order constraints. In this paper, an innovative R package named\nocapis (Ordinal Classification and Preprocessing In Scala) is introduced.\nImplemented mainly in Scala and available through Github, this library includes\nfour learners and two pre-processing algorithms for ordinal and monotonic data.\nMain features of the package and examples of installation and use are explained\nthroughout this manuscript.\n", "versions": [{"version": "v1", "created": "Tue, 23 Oct 2018 09:12:34 GMT"}, {"version": "v2", "created": "Thu, 14 Feb 2019 16:12:02 GMT"}, {"version": "v3", "created": "Sun, 17 Mar 2019 10:27:33 GMT"}], "update_date": "2019-03-19", "authors_parsed": [["Heredia-G\u00f3mez", "M. Cristina", ""], ["Garc\u00eda", "Salvador", ""], ["Guti\u00e9rrez", "Pedro Antonio", ""], ["Herrera", "Francisco", ""]]}, {"id": "1810.09746", "submitter": "Stephan Sloth Lorenzen", "authors": "Stephan Sloth Lorenzen and Christian Igel and Yevgeny Seldin", "title": "On PAC-Bayesian Bounds for Random Forests", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Existing guarantees in terms of rigorous upper bounds on the generalization\nerror for the original random forest algorithm, one of the most frequently used\nmachine learning methods, are unsatisfying. We discuss and evaluate various\nPAC-Bayesian approaches to derive such bounds. The bounds do not require\nadditional hold-out data, because the out-of-bag samples from the bagging in\nthe training process can be exploited. A random forest predicts by taking a\nmajority vote of an ensemble of decision trees. The first approach is to bound\nthe error of the vote by twice the error of the corresponding Gibbs classifier\n(classifying with a single member of the ensemble selected at random). However,\nthis approach does not take into account the effect of averaging out of errors\nof individual classifiers when taking the majority vote. This effect provides a\nsignificant boost in performance when the errors are independent or negatively\ncorrelated, but when the correlations are strong the advantage from taking the\nmajority vote is small. The second approach based on PAC-Bayesian C-bounds\ntakes dependencies between ensemble members into account, but it requires\nestimating correlations between the errors of the individual classifiers. When\nthe correlations are high or the estimation is poor, the bounds degrade. In our\nexperiments, we compute generalization bounds for random forests on various\nbenchmark data sets. Because the individual decision trees already perform\nwell, their predictions are highly correlated and the C-bounds do not lead to\nsatisfactory results. For the same reason, the bounds based on the analysis of\nGibbs classifiers are typically superior and often reasonably tight. Bounds\nbased on a validation set coming at the cost of a smaller training set gave\nbetter performance guarantees, but worse performance in most experiments.\n", "versions": [{"version": "v1", "created": "Tue, 23 Oct 2018 09:44:40 GMT"}, {"version": "v2", "created": "Wed, 6 Mar 2019 10:38:24 GMT"}], "update_date": "2019-03-07", "authors_parsed": [["Lorenzen", "Stephan Sloth", ""], ["Igel", "Christian", ""], ["Seldin", "Yevgeny", ""]]}, {"id": "1810.09785", "submitter": "Alexandre Defossez", "authors": "Alexandre D\\'efossez (FAIR, PSL, SIERRA), Neil Zeghidour (PSL, FAIR,\n  LSCP), Nicolas Usunier (FAIR), L\\'eon Bottou (FAIR), Francis Bach (DI-ENS,\n  PSL, SIERRA)", "title": "SING: Symbol-to-Instrument Neural Generator", "comments": null, "journal-ref": "Conference on Neural Information Processing Systems (NIPS), Dec\n  2018, Montr{\\'e}al, Canada", "doi": null, "report-no": null, "categories": "cs.SD cs.LG eess.AS stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent progress in deep learning for audio synthesis opens the way to models\nthat directly produce the waveform, shifting away from the traditional paradigm\nof relying on vocoders or MIDI synthesizers for speech or music generation.\nDespite their successes, current state-of-the-art neural audio synthesizers\nsuch as WaveNet and SampleRNN suffer from prohibitive training and inference\ntimes because they are based on autoregressive models that generate audio\nsamples one at a time at a rate of 16kHz. In this work, we study the more\ncomputationally efficient alternative of generating the waveform frame-by-frame\nwith large strides. We present SING, a lightweight neural audio synthesizer for\nthe original task of generating musical notes given desired instrument, pitch\nand velocity. Our model is trained end-to-end to generate notes from nearly\n1000 instruments with a single decoder, thanks to a new loss function that\nminimizes the distances between the log spectrograms of the generated and\ntarget waveforms. On the generalization task of synthesizing notes for pairs of\npitch and instrument not seen during training, SING produces audio with\nsignificantly improved perceptual quality compared to a state-of-the-art\nautoencoder based on WaveNet as measured by a Mean Opinion Score (MOS), and is\nabout 32 times faster for training and 2, 500 times faster for inference.\n", "versions": [{"version": "v1", "created": "Tue, 23 Oct 2018 11:27:06 GMT"}], "update_date": "2018-10-24", "authors_parsed": [["D\u00e9fossez", "Alexandre", "", "FAIR, PSL, SIERRA"], ["Zeghidour", "Neil", "", "PSL, FAIR,\n  LSCP"], ["Usunier", "Nicolas", "", "FAIR"], ["Bottou", "L\u00e9on", "", "FAIR"], ["Bach", "Francis", "", "DI-ENS,\n  PSL, SIERRA"]]}, {"id": "1810.09807", "submitter": "Hong Chen", "authors": "Hong Chen, Zhenhua Fan, Hao Lu, Alan L. Yuille and Shu Rong", "title": "PreCo: A Large-scale Dataset in Preschool Vocabulary for Coreference\n  Resolution", "comments": "EMNLP 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce PreCo, a large-scale English dataset for coreference resolution.\nThe dataset is designed to embody the core challenges in coreference, such as\nentity representation, by alleviating the challenge of low overlap between\ntraining and test sets and enabling separated analysis of mention detection and\nmention clustering. To strengthen the training-test overlap, we collect a large\ncorpus of about 38K documents and 12.4M words which are mostly from the\nvocabulary of English-speaking preschoolers. Experiments show that with higher\ntraining-test overlap, error analysis on PreCo is more efficient than the one\non OntoNotes, a popular existing dataset. Furthermore, we annotate singleton\nmentions making it possible for the first time to quantify the influence that a\nmention detector makes on coreference resolution performance. The dataset is\nfreely available at https://preschool-lab.github.io/PreCo/.\n", "versions": [{"version": "v1", "created": "Tue, 23 Oct 2018 12:09:37 GMT"}], "update_date": "2018-10-24", "authors_parsed": [["Chen", "Hong", ""], ["Fan", "Zhenhua", ""], ["Lu", "Hao", ""], ["Yuille", "Alan L.", ""], ["Rong", "Shu", ""]]}, {"id": "1810.09828", "submitter": "Emil Iacob", "authors": "Duleep Rathgamage Don and Ionut E. Iacob", "title": "DCSVM: Fast Multi-class Classification using Support Vector Machines", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present DCSVM, an efficient algorithm for multi-class classification using\nSupport Vector Machines. DCSVM is a divide and conquer algorithm which relies\non data sparsity in high dimensional space and performs a smart partitioning of\nthe whole training data set into disjoint subsets that are easily separable. A\nsingle prediction performed between two partitions eliminates at once one or\nmore classes in one partition, leaving only a reduced number of candidate\nclasses for subsequent steps. The algorithm continues recursively, reducing the\nnumber of classes at each step, until a final binary decision is made between\nthe last two classes left in the competition. In the best case scenario, our\nalgorithm makes a final decision between $k$ classes in $O(\\log k)$ decision\nsteps and in the worst case scenario DCSVM makes a final decision in $k-1$\nsteps, which is not worse than the existent techniques.\n", "versions": [{"version": "v1", "created": "Tue, 23 Oct 2018 13:07:48 GMT"}], "update_date": "2018-10-24", "authors_parsed": [["Don", "Duleep Rathgamage", ""], ["Iacob", "Ionut E.", ""]]}, {"id": "1810.09845", "submitter": "Bhairav Mehta", "authors": "Bhairav Mehta, Adithya Ramanathan", "title": "A Scalable, Flexible Augmentation of the Student Education Process", "comments": "Accepted to NIPS 2018 AI for Social Good Workshop", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a novel intelligent tutoring system which builds upon\nwell-established hypotheses in educational psychology and incorporates them\ninside of a scalable software architecture. Specifically, we build upon the\nknown benefits of knowledge vocalization, parallel learning, and immediate\nfeedback in the context of student learning. We show that open-source data\ncombined with state-of-the-art techniques in deep learning and natural language\nprocessing can apply the benefits of these three factors at scale, while still\noperating at the granularity of individual student needs and recommendations.\nAdditionally, we allow teachers to retain full control of the outputs of the\nalgorithms, and provide student statistics to help better guide classroom\ndiscussions towards topics that would benefit from more in-person review and\ncoverage. Our experiments and pilot programs show promising results, and cement\nour hypothesis that the system is flexible enough to serve a wide variety of\npurposes in both classroom and classroom-free settings.\n", "versions": [{"version": "v1", "created": "Wed, 17 Oct 2018 04:47:52 GMT"}, {"version": "v2", "created": "Sun, 29 Nov 2020 21:51:25 GMT"}], "update_date": "2020-12-01", "authors_parsed": [["Mehta", "Bhairav", ""], ["Ramanathan", "Adithya", ""]]}, {"id": "1810.09854", "submitter": "Lukas Mauch", "authors": "Lukas Mauch and Bin Yang", "title": "Deep Neural Network inference with reduced word length", "comments": "submitted to ICASSP 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep neural networks (DNN) are powerful models for many pattern recognition\ntasks, yet their high computational complexity and memory requirement limit\nthem to applications on high-performance computing platforms. In this paper, we\npropose a new method to evaluate DNNs trained with 32bit floating point\n(float32) accuracy using only low precision integer arithmetics in combination\nwith binary shift and clipping operations. Because hardware implementation of\nthese operations is much simpler than high precision floating point\ncalculation, our method can be used for an efficient DNN inference on dedicated\nhardware. In experiments on MNIST, we demonstrate that DNNs trained with\nfloat32 can be evaluated using a combination of 2bit integer arithmetics and a\nfew float32 calculations in each layer or only 3bit integer arithmetics in\ncombination with binary shift and clipping without significant performance\ndegradation.\n", "versions": [{"version": "v1", "created": "Tue, 23 Oct 2018 13:48:53 GMT"}], "update_date": "2018-10-24", "authors_parsed": [["Mauch", "Lukas", ""], ["Yang", "Bin", ""]]}, {"id": "1810.09868", "submitter": "Keno Fischer", "authors": "Keno Fischer, Elliot Saba", "title": "Automatic Full Compilation of Julia Programs and ML Models to Cloud TPUs", "comments": "Submitted to SysML 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.PL cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Google's Cloud TPUs are a promising new hardware architecture for machine\nlearning workloads. They have powered many of Google's milestone machine\nlearning achievements in recent years. Google has now made TPUs available for\ngeneral use on their cloud platform and as of very recently has opened them up\nfurther to allow use by non-TensorFlow frontends. We describe a method and\nimplementation for offloading suitable sections of Julia programs to TPUs via\nthis new API and the Google XLA compiler. Our method is able to completely fuse\nthe forward pass of a VGG19 model expressed as a Julia program into a single\nTPU executable to be offloaded to the device. Our method composes well with\nexisting compiler-based automatic differentiation techniques on Julia code, and\nwe are thus able to also automatically obtain the VGG19 backwards pass and\nsimilarly offload it to the TPU. Targeting TPUs using our compiler, we are able\nto evaluate the VGG19 forward pass on a batch of 100 images in 0.23s which\ncompares favorably to the 52.4s required for the original model on the CPU. Our\nimplementation is less than 1000 lines of Julia, with no TPU specific changes\nmade to the core Julia compiler or any other Julia packages.\n", "versions": [{"version": "v1", "created": "Tue, 23 Oct 2018 14:02:11 GMT"}], "update_date": "2018-10-24", "authors_parsed": [["Fischer", "Keno", ""], ["Saba", "Elliot", ""]]}, {"id": "1810.09878", "submitter": "Tara Salman", "authors": "Deval Bhamare, Tara Salman, Mohammed Samaka, Aiman Erbad, Raj Jain", "title": "Feasibility of Supervised Machine Learning for Cloud Security", "comments": null, "journal-ref": "2016 International Conference on Information Science and Security\n  (ICISS)", "doi": "10.1109/ICISSEC.2016.7885853", "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Cloud computing is gaining significant attention, however, security is the\nbiggest hurdle in its wide acceptance. Users of cloud services are under\nconstant fear of data loss, security threats and availability issues. Recently,\nlearning-based methods for security applications are gaining popularity in the\nliterature with the advents in machine learning techniques. However, the major\nchallenge in these methods is obtaining real-time and unbiased datasets. Many\ndatasets are internal and cannot be shared due to privacy issues or may lack\ncertain statistical characteristics. As a result of this, researchers prefer to\ngenerate datasets for training and testing purpose in the simulated or closed\nexperimental environments which may lack comprehensiveness. Machine learning\nmodels trained with such a single dataset generally result in a semantic gap\nbetween results and their application. There is a dearth of research work which\ndemonstrates the effectiveness of these models across multiple datasets\nobtained in different environments. We argue that it is necessary to test the\nrobustness of the machine learning models, especially in diversified operating\nconditions, which are prevalent in cloud scenarios. In this work, we use the\nUNSW dataset to train the supervised machine learning models. We then test\nthese models with ISOT dataset. We present our results and argue that more\nresearch in the field of machine learning is still required for its\napplicability to the cloud security.\n", "versions": [{"version": "v1", "created": "Tue, 23 Oct 2018 14:23:43 GMT"}], "update_date": "2018-10-24", "authors_parsed": [["Bhamare", "Deval", ""], ["Salman", "Tara", ""], ["Samaka", "Mohammed", ""], ["Erbad", "Aiman", ""], ["Jain", "Raj", ""]]}, {"id": "1810.09899", "submitter": "Traiko Dinev", "authors": "Traiko Dinev and Michael U. Gutmann", "title": "Dynamic Likelihood-free Inference via Ratio Estimation (DIRE)", "comments": "For a demo, see https://traiko.com/pages/research/lfire/", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG stat.CO stat.ME", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Parametric statistical models that are implicitly defined in terms of a\nstochastic data generating process are used in a wide range of scientific\ndisciplines because they enable accurate modeling. However, learning the\nparameters from observed data is generally very difficult because their\nlikelihood function is typically intractable. Likelihood-free Bayesian\ninference methods have been proposed which include the frameworks of\napproximate Bayesian computation (ABC), synthetic likelihood, and its recent\ngeneralization that performs likelihood-free inference by ratio estimation\n(LFIRE). A major difficulty in all these methods is choosing summary statistics\nthat reduce the dimensionality of the data to facilitate inference. While\nseveral methods for choosing summary statistics have been proposed for ABC, the\nliterature for synthetic likelihood and LFIRE is very thin to date. We here\naddress this gap in the literature, focusing on the important special case of\ntime-series models. We show that convolutional neural networks trained to\npredict the input parameters from the data provide suitable summary statistics\nfor LFIRE. On a wide range of time-series models, a single neural network\narchitecture produced equally or more accurate posteriors than alternative\nmethods.\n", "versions": [{"version": "v1", "created": "Tue, 23 Oct 2018 15:02:47 GMT"}], "update_date": "2018-10-24", "authors_parsed": [["Dinev", "Traiko", ""], ["Gutmann", "Michael U.", ""]]}, {"id": "1810.09912", "submitter": "Steven Kleinegesse", "authors": "Steven Kleinegesse and Michael Gutmann", "title": "Efficient Bayesian Experimental Design for Implicit Models", "comments": "Added references and fixed typos. Results and figures remain\n  unchanged", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG stat.CO stat.ME", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Bayesian experimental design involves the optimal allocation of resources in\nan experiment, with the aim of optimising cost and performance. For implicit\nmodels, where the likelihood is intractable but sampling from the model is\npossible, this task is particularly difficult and therefore largely unexplored.\nThis is mainly due to technical difficulties associated with approximating\nposterior distributions and utility functions. We devise a novel experimental\ndesign framework for implicit models that improves upon previous work in two\nways. First, we use the mutual information between parameters and data as the\nutility function, which has previously not been feasible. We achieve this by\nutilising Likelihood-Free Inference by Ratio Estimation (LFIRE) to approximate\nposterior distributions, instead of the traditional approximate Bayesian\ncomputation or synthetic likelihood methods. Secondly, we use Bayesian\noptimisation in order to solve the optimal design problem, as opposed to the\ntypically used grid search or sampling-based methods. We find that this\nincreases efficiency and allows us to consider higher design dimensions.\n", "versions": [{"version": "v1", "created": "Tue, 23 Oct 2018 15:24:29 GMT"}, {"version": "v2", "created": "Sat, 23 Feb 2019 13:48:19 GMT"}], "update_date": "2019-02-26", "authors_parsed": [["Kleinegesse", "Steven", ""], ["Gutmann", "Michael", ""]]}, {"id": "1810.09920", "submitter": "Alexander Lin", "authors": "Alexander Lin, Yingzhuo Zhang, Jeremy Heng, Stephen A. Allsop, Kay M.\n  Tye, Pierre E. Jacob, and Demba Ba", "title": "Clustering Time Series with Nonlinear Dynamics: A Bayesian\n  Non-Parametric and Particle-Based Approach", "comments": null, "journal-ref": "International Conference on Artificial Intelligence and Statistics\n  (AISTATS 2019)", "doi": null, "report-no": null, "categories": "stat.ML cs.LG q-bio.NC stat.CO", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We propose a general statistical framework for clustering multiple time\nseries that exhibit nonlinear dynamics into an a-priori-unknown number of\nsub-groups. Our motivation comes from neuroscience, where an important problem\nis to identify, within a large assembly of neurons, subsets that respond\nsimilarly to a stimulus or contingency. Upon modeling the multiple time series\nas the output of a Dirichlet process mixture of nonlinear state-space models,\nwe derive a Metropolis-within-Gibbs algorithm for full Bayesian inference that\nalternates between sampling cluster assignments and sampling parameter values\nthat form the basis of the clustering. The Metropolis step employs recent\ninnovations in particle-based methods. We apply the framework to clustering\ntime series acquired from the prefrontal cortex of mice in an experiment\ndesigned to characterize the neural underpinnings of fear.\n", "versions": [{"version": "v1", "created": "Tue, 23 Oct 2018 15:40:25 GMT"}, {"version": "v2", "created": "Wed, 24 Oct 2018 18:44:19 GMT"}, {"version": "v3", "created": "Tue, 26 Feb 2019 21:28:11 GMT"}, {"version": "v4", "created": "Mon, 4 Mar 2019 18:40:29 GMT"}], "update_date": "2019-03-05", "authors_parsed": [["Lin", "Alexander", ""], ["Zhang", "Yingzhuo", ""], ["Heng", "Jeremy", ""], ["Allsop", "Stephen A.", ""], ["Tye", "Kay M.", ""], ["Jacob", "Pierre E.", ""], ["Ba", "Demba", ""]]}, {"id": "1810.09923", "submitter": "Pawel Gomoluch", "authors": "Pawel Gomoluch, Dalal Alrajeh, Alessandra Russo", "title": "Learning Classical Planning Strategies with Policy Gradient", "comments": "Accepted for ICAPS 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A common paradigm in classical planning is heuristic forward search. Forward\nsearch planners often rely on simple best-first search which remains fixed\nthroughout the search process. In this paper, we introduce a novel search\nframework capable of alternating between several forward search approaches\nwhile solving a particular planning problem. Selection of the approach is\nperformed using a trainable stochastic policy, mapping the state of the search\nto a probability distribution over the approaches. This enables using policy\ngradient to learn search strategies tailored to a specific distributions of\nplanning problems and a selected performance metric, e.g. the IPC score. We\ninstantiate the framework by constructing a policy space consisting of five\nsearch approaches and a two-dimensional representation of the planner's state.\nThen, we train the system on randomly generated problems from five IPC domains\nusing three different performance metrics. Our experimental results show that\nthe learner is able to discover domain-specific search strategies, improving\nthe planner's performance relative to the baselines of plain best-first search\nand a uniform policy.\n", "versions": [{"version": "v1", "created": "Tue, 23 Oct 2018 15:44:44 GMT"}, {"version": "v2", "created": "Thu, 11 Apr 2019 16:15:22 GMT"}], "update_date": "2019-04-12", "authors_parsed": [["Gomoluch", "Pawel", ""], ["Alrajeh", "Dalal", ""], ["Russo", "Alessandra", ""]]}, {"id": "1810.09936", "submitter": "Fuli Feng", "authors": "Fuli Feng, Huimin Chen, Xiangnan He, Ji Ding, Maosong Sun, Tat-Seng\n  Chua", "title": "Enhancing Stock Movement Prediction with Adversarial Training", "comments": "IJCAI 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-fin.TR cs.CE cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper contributes a new machine learning solution for stock movement\nprediction, which aims to predict whether the price of a stock will be up or\ndown in the near future. The key novelty is that we propose to employ\nadversarial training to improve the generalization of a neural network\nprediction model. The rationality of adversarial training here is that the\ninput features to stock prediction are typically based on stock price, which is\nessentially a stochastic variable and continuously changed with time by nature.\nAs such, normal training with static price-based features (e.g. the close\nprice) can easily overfit the data, being insufficient to obtain reliable\nmodels. To address this problem, we propose to add perturbations to simulate\nthe stochasticity of price variable, and train the model to work well under\nsmall yet intentional perturbations. Extensive experiments on two real-world\nstock data show that our method outperforms the state-of-the-art solution with\n3.11% relative improvements on average w.r.t. accuracy, validating the\nusefulness of adversarial training for stock prediction task.\n", "versions": [{"version": "v1", "created": "Sat, 13 Oct 2018 07:27:19 GMT"}, {"version": "v2", "created": "Sat, 1 Jun 2019 11:43:26 GMT"}], "update_date": "2019-06-04", "authors_parsed": [["Feng", "Fuli", ""], ["Chen", "Huimin", ""], ["He", "Xiangnan", ""], ["Ding", "Ji", ""], ["Sun", "Maosong", ""], ["Chua", "Tat-Seng", ""]]}, {"id": "1810.09942", "submitter": "Brandon Schoenfeld", "authors": "Brandon Schoenfeld, Christophe Giraud-Carrier, Mason Poggemann, Jarom\n  Christensen, Kevin Seppi", "title": "Preprocessor Selection for Machine Learning Pipelines", "comments": "Accepted at the ICML 2018 AutoML Workshop", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Much of the work in metalearning has focused on classifier selection,\ncombined more recently with hyperparameter optimization, with little concern\nfor data preprocessing. Yet, it is generally well accepted that machine\nlearning applications require not only model building, but also data\npreprocessing. In other words, practical solutions consist of pipelines of\nmachine learning operators rather than single algorithms. Interestingly, our\nexperiments suggest that, on average, data preprocessing hinders accuracy,\nwhile the best performing pipelines do actually make use of preprocessors.\nHere, we conduct an extensive empirical study over a wide range of learning\nalgorithms and preprocessors, and use metalearning to determine when one should\nmake use of preprocessors in ML pipeline design.\n", "versions": [{"version": "v1", "created": "Tue, 23 Oct 2018 16:14:11 GMT"}], "update_date": "2018-10-24", "authors_parsed": [["Schoenfeld", "Brandon", ""], ["Giraud-Carrier", "Christophe", ""], ["Poggemann", "Mason", ""], ["Christensen", "Jarom", ""], ["Seppi", "Kevin", ""]]}, {"id": "1810.09944", "submitter": "Monika Sharma", "authors": "Monika Sharma, Tristan Glatard, Eric Gelinas, Mariam Tagmouti,\n  Brigitte Jaumard", "title": "Data models for service failure prediction in supply-chain networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We aim to predict and explain service failures in supply-chain networks, more\nprecisely among last-mile pickup and delivery services to customers. We analyze\na dataset of 500,000 services using (1) supervised classification with Random\nForests, and (2) Association Rules. Our classifier reaches an average\nsensitivity of 0.7 and an average specificity of 0.7 for the 5 studied types of\nfailure. Association Rules reassert the importance of confirmation calls to\nprevent failures due to customers not at home, show the importance of the time\nwindow size, slack time, and geographical location of the customer for the\nother failure types, and highlight the effect of the retailer company on\nseveral failure types. To reduce the occurrence of service failures, our data\nmodels could be coupled to optimizers, or used to define counter-measures to be\ntaken by human dispatchers.\n", "versions": [{"version": "v1", "created": "Sat, 20 Oct 2018 22:50:01 GMT"}], "update_date": "2018-10-24", "authors_parsed": [["Sharma", "Monika", ""], ["Glatard", "Tristan", ""], ["Gelinas", "Eric", ""], ["Tagmouti", "Mariam", ""], ["Jaumard", "Brigitte", ""]]}, {"id": "1810.09945", "submitter": "Wojciech Samek", "authors": "Armin W. Thomas, Hauke R. Heekeren, Klaus-Robert M\\\"uller, Wojciech\n  Samek", "title": "Analyzing Neuroimaging Data Through Recurrent Deep Learning Models", "comments": "36 pages, 9 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV cs.NE q-bio.NC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The application of deep learning (DL) models to neuroimaging data poses\nseveral challenges, due to the high dimensionality, low sample size and complex\ntemporo-spatial dependency structure of these datasets. Even further, DL models\nact as as black-box models, impeding insight into the association of cognitive\nstate and brain activity. To approach these challenges, we introduce the\nDeepLight framework, which utilizes long short-term memory (LSTM) based DL\nmodels to analyze whole-brain functional Magnetic Resonance Imaging (fMRI)\ndata. To decode a cognitive state (e.g., seeing the image of a house),\nDeepLight separates the fMRI volume into a sequence of axial brain slices,\nwhich is then sequentially processed by an LSTM. To maintain interpretability,\nDeepLight adapts the layer-wise relevance propagation (LRP) technique. Thereby,\ndecomposing its decoding decision into the contributions of the single input\nvoxels to this decision. Importantly, the decomposition is performed on the\nlevel of single fMRI volumes, enabling DeepLight to study the associations\nbetween cognitive state and brain activity on several levels of data\ngranularity, from the level of the group down to the level of single time\npoints. To demonstrate the versatility of DeepLight, we apply it to a large\nfMRI dataset of the Human Connectome Project. We show that DeepLight\noutperforms conventional approaches of uni- and multivariate fMRI analysis in\ndecoding the cognitive states and in identifying the physiologically\nappropriate brain regions associated with these states. We further demonstrate\nDeepLight's ability to study the fine-grained temporo-spatial variability of\nbrain activity over sequences of single fMRI samples.\n", "versions": [{"version": "v1", "created": "Tue, 23 Oct 2018 16:23:27 GMT"}, {"version": "v2", "created": "Fri, 5 Apr 2019 07:31:32 GMT"}], "update_date": "2019-04-08", "authors_parsed": [["Thomas", "Armin W.", ""], ["Heekeren", "Hauke R.", ""], ["M\u00fcller", "Klaus-Robert", ""], ["Samek", "Wojciech", ""]]}, {"id": "1810.09957", "submitter": "Hanjoo Kim", "authors": "Hanjoo Kim, Minkyu Kim, Dongjoo Seo, Jinwoong Kim, Heungseok Park,\n  Soeun Park, Hyunwoo Jo, KyungHyun Kim, Youngil Yang, Youngkwan Kim, Nako\n  Sung, Jung-Woo Ha", "title": "NSML: Meet the MLaaS platform with a real-world case study", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The boom of deep learning induced many industries and academies to introduce\nmachine learning based approaches into their concern, competitively. However,\nexisting machine learning frameworks are limited to sufficiently fulfill the\ncollaboration and management for both data and models. We proposed NSML, a\nmachine learning as a service (MLaaS) platform, to meet these demands. NSML\nhelps machine learning work be easily launched on a NSML cluster and provides a\ncollaborative environment which can afford development at enterprise scale.\nFinally, NSML users can deploy their own commercial services with NSML cluster.\nIn addition, NSML furnishes convenient visualization tools which assist the\nusers in analyzing their work. To verify the usefulness and accessibility of\nNSML, we performed some experiments with common examples. Furthermore, we\nexamined the collaborative advantages of NSML through three competitions with\nreal-world use cases.\n", "versions": [{"version": "v1", "created": "Mon, 8 Oct 2018 04:30:44 GMT"}], "update_date": "2018-10-24", "authors_parsed": [["Kim", "Hanjoo", ""], ["Kim", "Minkyu", ""], ["Seo", "Dongjoo", ""], ["Kim", "Jinwoong", ""], ["Park", "Heungseok", ""], ["Park", "Soeun", ""], ["Jo", "Hyunwoo", ""], ["Kim", "KyungHyun", ""], ["Yang", "Youngil", ""], ["Kim", "Youngkwan", ""], ["Sung", "Nako", ""], ["Ha", "Jung-Woo", ""]]}, {"id": "1810.09958", "submitter": "Jason Knight", "authors": "Matthew Sotoudeh, Anand Venkat, Michael Anderson, Evangelos Georganas,\n  Alexander Heinecke, Jason Knight", "title": "ISA Mapper: A Compute and Hardware Agnostic Deep Learning Compiler", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Domain specific accelerators present new challenges and opportunities for\ncode generation onto novel instruction sets, communication fabrics, and memory\narchitectures.\n  In this paper we introduce an intermediate representation (IR) which enables\nboth deep learning computational kernels and hardware capabilities to be\ndescribed in the same IR. We then formulate and apply instruction mapping to\ndetermine the possible ways a computation can be performed on a hardware\nsystem. Next, our scheduler chooses a specific mapping and determines the data\nmovement and computation order. In order to manage the large search space of\nmappings and schedules, we developed a flexible framework that allows\nheuristics, cost models, and potentially machine learning to facilitate this\nsearch problem.\n  With this system, we demonstrate the automated extraction of matrix\nmultiplication kernels out of recent deep learning kernels such as\ndepthwise-separable convolution. In addition, we demonstrate two to five times\nbetter performance on DeepBench sized GEMMs and GRU RNN execution when compared\nto state-of-the-art (SOTA) implementations on new hardware and up to 85% of the\nperformance for SOTA implementations on existing hardware.\n", "versions": [{"version": "v1", "created": "Fri, 12 Oct 2018 23:54:00 GMT"}], "update_date": "2018-10-24", "authors_parsed": [["Sotoudeh", "Matthew", ""], ["Venkat", "Anand", ""], ["Anderson", "Michael", ""], ["Georganas", "Evangelos", ""], ["Heinecke", "Alexander", ""], ["Knight", "Jason", ""]]}, {"id": "1810.09965", "submitter": "Avraam Tsantekidis", "authors": "Avraam Tsantekidis, Nikolaos Passalis, Anastasios Tefas, Juho\n  Kanniainen, Moncef Gabbouj, Alexandros Iosifidis", "title": "Using Deep Learning for price prediction by exploiting stationary limit\n  order book features", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG q-fin.ST stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The recent surge in Deep Learning (DL) research of the past decade has\nsuccessfully provided solutions to many difficult problems. The field of\nquantitative analysis has been slowly adapting the new methods to its problems,\nbut due to problems such as the non-stationary nature of financial data,\nsignificant challenges must be overcome before DL is fully utilized. In this\nwork a new method to construct stationary features, that allows DL models to be\napplied effectively, is proposed. These features are thoroughly tested on the\ntask of predicting mid price movements of the Limit Order Book. Several DL\nmodels are evaluated, such as recurrent Long Short Term Memory (LSTM) networks\nand Convolutional Neural Networks (CNN). Finally a novel model that combines\nthe ability of CNNs to extract useful features and the ability of LSTMs' to\nanalyze time series, is proposed and evaluated. The combined model is able to\noutperform the individual LSTM and CNN models in the prediction horizons that\nare tested.\n", "versions": [{"version": "v1", "created": "Tue, 23 Oct 2018 16:53:03 GMT"}], "update_date": "2018-10-24", "authors_parsed": [["Tsantekidis", "Avraam", ""], ["Passalis", "Nikolaos", ""], ["Tefas", "Anastasios", ""], ["Kanniainen", "Juho", ""], ["Gabbouj", "Moncef", ""], ["Iosifidis", "Alexandros", ""]]}, {"id": "1810.09967", "submitter": "Brett Daley", "authors": "Brett Daley and Christopher Amato", "title": "Reconciling $\\lambda$-Returns with Experience Replay", "comments": "NeurIPS 2019 (Camera-Ready) Code available:\n  https://github.com/brett-daley/dqn-lambda", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Modern deep reinforcement learning methods have departed from the incremental\nlearning required for eligibility traces, rendering the implementation of the\n$\\lambda$-return difficult in this context. In particular, off-policy methods\nthat utilize experience replay remain problematic because their random sampling\nof minibatches is not conducive to the efficient calculation of\n$\\lambda$-returns. Yet replay-based methods are often the most sample\nefficient, and incorporating $\\lambda$-returns into them is a viable way to\nachieve new state-of-the-art performance. Towards this, we propose the first\nmethod to enable practical use of $\\lambda$-returns in arbitrary replay-based\nmethods without relying on other forms of decorrelation such as asynchronous\ngradient updates. By promoting short sequences of past transitions into a small\ncache within the replay memory, adjacent $\\lambda$-returns can be efficiently\nprecomputed by sharing Q-values. Computation is not wasted on experiences that\nare never sampled, and stored $\\lambda$-returns behave as stable\ntemporal-difference (TD) targets that replace the target network. Additionally,\nour method grants the unique ability to observe TD errors prior to sampling;\nfor the first time, transitions can be prioritized by their true significance\nrather than by a proxy to it. Furthermore, we propose the novel use of the TD\nerror to dynamically select $\\lambda$-values that facilitate faster learning.\nWe show that these innovations can enhance the performance of DQN when playing\nAtari 2600 games, even under partial observability. While our work specifically\nfocuses on $\\lambda$-returns, these ideas are applicable to any multi-step\nreturn estimator.\n", "versions": [{"version": "v1", "created": "Tue, 23 Oct 2018 16:55:28 GMT"}, {"version": "v2", "created": "Tue, 12 Nov 2019 02:38:07 GMT"}, {"version": "v3", "created": "Mon, 13 Jan 2020 19:05:20 GMT"}], "update_date": "2020-01-15", "authors_parsed": [["Daley", "Brett", ""], ["Amato", "Christopher", ""]]}, {"id": "1810.09977", "submitter": "Bleema Rosenfeld", "authors": "Bleema Rosenfeld, Osvaldo Simeone and Bipin Rajendran", "title": "Learning First-to-Spike Policies for Neuromorphic Control Using Policy\n  Gradients", "comments": "Submitted for conference publication", "journal-ref": null, "doi": "10.1109/SPAWC.2019.8815546", "report-no": null, "categories": "cs.LG eess.SP stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Artificial Neural Networks (ANNs) are currently being used as function\napproximators in many state-of-the-art Reinforcement Learning (RL) algorithms.\nSpiking Neural Networks (SNNs) have been shown to drastically reduce the energy\nconsumption of ANNs by encoding information in sparse temporal binary spike\nstreams, hence emulating the communication mechanism of biological neurons. Due\nto their low energy consumption, SNNs are considered to be important candidates\nas co-processors to be implemented in mobile devices. In this work, the use of\nSNNs as stochastic policies is explored under an energy-efficient\nfirst-to-spike action rule, whereby the action taken by the RL agent is\ndetermined by the occurrence of the first spike among the output neurons. A\npolicy gradient-based algorithm is derived considering a Generalized Linear\nModel (GLM) for spiking neurons. Experimental results demonstrate the\ncapability of online trained SNNs as stochastic policies to gracefully trade\nenergy consumption, as measured by the number of spikes, and control\nperformance. Significant gains are shown as compared to the standard approach\nof converting an offline trained ANN into an SNN.\n", "versions": [{"version": "v1", "created": "Tue, 23 Oct 2018 17:13:21 GMT"}, {"version": "v2", "created": "Thu, 25 Oct 2018 18:29:37 GMT"}, {"version": "v3", "created": "Thu, 28 Feb 2019 17:00:29 GMT"}], "update_date": "2020-01-23", "authors_parsed": [["Rosenfeld", "Bleema", ""], ["Simeone", "Osvaldo", ""], ["Rajendran", "Bipin", ""]]}, {"id": "1810.10002", "submitter": "Kristen Masada", "authors": "Kristen Masada, Razvan Bunescu", "title": "Chord Recognition in Symbolic Music: A Segmental CRF Model,\n  Segment-Level Features, and Comparative Evaluations on Classical and Popular\n  Music", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SD cs.LG eess.AS stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We present a new approach to harmonic analysis that is trained to segment\nmusic into a sequence of chord spans tagged with chord labels. Formulated as a\nsemi-Markov Conditional Random Field (semi-CRF), this joint segmentation and\nlabeling approach enables the use of a rich set of segment-level features, such\nas segment purity and chord coverage, that capture the extent to which the\nevents in an entire segment of music are compatible with a candidate chord\nlabel. The new chord recognition model is evaluated extensively on three\ncorpora of classical music and a newly created corpus of rock music.\nExperimental results show that the semi-CRF model performs substantially better\nthan previous approaches when trained on a sufficient number of labeled\nexamples and remains competitive when the amount of training data is limited.\n", "versions": [{"version": "v1", "created": "Mon, 22 Oct 2018 22:55:17 GMT"}, {"version": "v2", "created": "Fri, 26 Oct 2018 02:05:13 GMT"}], "update_date": "2018-10-29", "authors_parsed": [["Masada", "Kristen", ""], ["Bunescu", "Razvan", ""]]}, {"id": "1810.10004", "submitter": "Pavlos Fafalios", "authors": "Nilamadhaba Mohapatra, Vasileios Iosifidis, Asif Ekbal, Stefan Dietze,\n  Pavlos Fafalios", "title": "Time-Aware and Corpus-Specific Entity Relatedness", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Entity relatedness has emerged as an important feature in a plethora of\napplications such as information retrieval, entity recommendation and entity\nlinking. Given an entity, for instance a person or an organization, entity\nrelatedness measures can be exploited for generating a list of highly-related\nentities. However, the relation of an entity to some other entity depends on\nseveral factors, with time and context being two of the most important ones\n(where, in our case, context is determined by a particular corpus). For\nexample, the entities related to the International Monetary Fund are different\nnow compared to some years ago, while these entities also may highly differ in\nthe context of a USA news portal compared to a Greek news portal. In this\npaper, we propose a simple but flexible model for entity relatedness which\nconsiders time and entity aware word embeddings by exploiting the underlying\ncorpus. The proposed model does not require external knowledge and is language\nindependent, which makes it widely useful in a variety of applications.\n", "versions": [{"version": "v1", "created": "Tue, 23 Oct 2018 11:17:45 GMT"}], "update_date": "2018-10-25", "authors_parsed": [["Mohapatra", "Nilamadhaba", ""], ["Iosifidis", "Vasileios", ""], ["Ekbal", "Asif", ""], ["Dietze", "Stefan", ""], ["Fafalios", "Pavlos", ""]]}, {"id": "1810.10031", "submitter": "Mohammad Hashemi", "authors": "Mohammad Hashemi, Greg Cusack, Eric Keller", "title": "Stochastic Substitute Training: A Gray-box Approach to Craft Adversarial\n  Examples Against Gradient Obfuscation Defenses", "comments": "Accepted by AISec '18: 11th ACM Workshop on Artificial Intelligence\n  and Security. Source code at https://github.com/S-Mohammad-Hashemi/SST", "journal-ref": null, "doi": "10.1145/3270101.3270111", "report-no": null, "categories": "cs.LG cs.AI cs.CR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  It has been shown that adversaries can craft example inputs to neural\nnetworks which are similar to legitimate inputs but have been created to\npurposely cause the neural network to misclassify the input. These adversarial\nexamples are crafted, for example, by calculating gradients of a carefully\ndefined loss function with respect to the input. As a countermeasure, some\nresearchers have tried to design robust models by blocking or obfuscating\ngradients, even in white-box settings. Another line of research proposes\nintroducing a separate detector to attempt to detect adversarial examples. This\napproach also makes use of gradient obfuscation techniques, for example, to\nprevent the adversary from trying to fool the detector. In this paper, we\nintroduce stochastic substitute training, a gray-box approach that can craft\nadversarial examples for defenses which obfuscate gradients. For those defenses\nthat have tried to make models more robust, with our technique, an adversary\ncan craft adversarial examples with no knowledge of the defense. For defenses\nthat attempt to detect the adversarial examples, with our technique, an\nadversary only needs very limited information about the defense to craft\nadversarial examples. We demonstrate our technique by applying it against two\ndefenses which make models more robust and two defenses which detect\nadversarial examples.\n", "versions": [{"version": "v1", "created": "Tue, 23 Oct 2018 18:14:47 GMT"}], "update_date": "2018-10-25", "authors_parsed": [["Hashemi", "Mohammad", ""], ["Cusack", "Greg", ""], ["Keller", "Eric", ""]]}, {"id": "1810.10032", "submitter": "Jose Maria Almira", "authors": "J. M. Almira, P.E. Lopez-de-Teruel, D.J. Romero-Lopez, F. Voigtlaender", "title": "Negative results for approximation using single layer and multilayer\n  feedforward neural networks", "comments": "12 pages, submitted to a Journal", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We prove a negative result for the approximation of functions defined on\ncompact subsets of $\\mathbb{R}^d$ (where $d \\geq 2$) using feedforward neural\nnetworks with one hidden layer and arbitrary continuous activation function. In\na nutshell, this result claims the existence of target functions that are as\ndifficult to approximate using these neural networks as one may want. We also\ndemonstrate an analogous result (for general $d \\in \\mathbb{N}$) for neural\nnetworks with an \\emph{arbitrary} number of hidden layers, for activation\nfunctions that are either rational functions or continuous splines with\nfinitely many pieces.\n", "versions": [{"version": "v1", "created": "Tue, 23 Oct 2018 18:15:50 GMT"}, {"version": "v2", "created": "Wed, 31 Oct 2018 08:56:16 GMT"}, {"version": "v3", "created": "Thu, 16 Jan 2020 19:37:20 GMT"}, {"version": "v4", "created": "Tue, 25 Aug 2020 07:45:04 GMT"}], "update_date": "2020-08-26", "authors_parsed": [["Almira", "J. M.", ""], ["Lopez-de-Teruel", "P. E.", ""], ["Romero-Lopez", "D. J.", ""], ["Voigtlaender", "F.", ""]]}, {"id": "1810.10042", "submitter": "Natalia Ares", "authors": "D.T. Lennon, H. Moon, L.C. Camenzind, Liuqi Yu, D.M. Zumb\\\"uhl, G.A.D.\n  Briggs, M.A. Osborne, E.A. Laird and N. Ares", "title": "Efficiently measuring a quantum device using machine learning", "comments": null, "journal-ref": null, "doi": "10.1038/s41534-019-0193-4", "report-no": null, "categories": "quant-ph cond-mat.mes-hall cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Scalable quantum technologies will present challenges for characterizing and\ntuning quantum devices. This is a time-consuming activity, and as the size of\nquantum systems increases, this task will become intractable without the aid of\nautomation. We present measurements on a quantum dot device performed by a\nmachine learning algorithm. The algorithm selects the most informative\nmeasurements to perform next using information theory and a probabilistic\ndeep-generative model, the latter capable of generating multiple\nfull-resolution reconstructions from scattered partial measurements. We\ndemonstrate, for two different measurement configurations, that the algorithm\noutperforms standard grid scan techniques, reducing the number of measurements\nrequired by up to 4 times and the measurement time by 3.7 times. Our\ncontribution goes beyond the use of machine learning for data search and\nanalysis, and instead presents the use of algorithms to automate measurement.\nThis work lays the foundation for automated control of large quantum circuits.\n", "versions": [{"version": "v1", "created": "Tue, 23 Oct 2018 18:38:01 GMT"}], "update_date": "2019-12-03", "authors_parsed": [["Lennon", "D. T.", ""], ["Moon", "H.", ""], ["Camenzind", "L. C.", ""], ["Yu", "Liuqi", ""], ["Zumb\u00fchl", "D. M.", ""], ["Briggs", "G. A. D.", ""], ["Osborne", "M. A.", ""], ["Laird", "E. A.", ""], ["Ares", "N.", ""]]}, {"id": "1810.10053", "submitter": "Hermina Petric Maretic", "authors": "Hermina Petric Maretic and Pascal Frossard", "title": "Graph Laplacian mixture model", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.SI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Graph learning methods have recently been receiving increasing interest as\nmeans to infer structure in datasets. Most of the recent approaches focus on\ndifferent relationships between a graph and data sample distributions, mostly\nin settings where all available data relate to the same graph. This is,\nhowever, not always the case, as data is often available in mixed form,\nyielding the need for methods that are able to cope with mixture data and learn\nmultiple graphs. We propose a novel generative model that represents a\ncollection of distinct data which naturally live on different graphs. We assume\nthe mapping of data to graphs is not known and investigate the problem of\njointly clustering a set of data and learning a graph for each of the clusters.\nExperiments demonstrate promising performance in data clustering and multiple\ngraph inference, and show desirable properties in terms of interpretability and\ncoping with high dimensionality on weather and traffic data, as well as digit\nclassification.\n", "versions": [{"version": "v1", "created": "Tue, 23 Oct 2018 19:03:06 GMT"}, {"version": "v2", "created": "Fri, 20 Mar 2020 17:36:19 GMT"}], "update_date": "2020-03-23", "authors_parsed": [["Maretic", "Hermina Petric", ""], ["Frossard", "Pascal", ""]]}, {"id": "1810.10065", "submitter": "Jonathan Kadmon", "authors": "Jonathan Kadmon and Surya Ganguli", "title": "Statistical mechanics of low-rank tensor decomposition", "comments": "27 pages, 3 figures", "journal-ref": null, "doi": "10.1088/1742-5468/ab3216", "report-no": null, "categories": "stat.ML cs.LG q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Often, large, high dimensional datasets collected across multiple modalities\ncan be organized as a higher order tensor. Low-rank tensor decomposition then\narises as a powerful and widely used tool to discover simple low dimensional\nstructures underlying such data. However, we currently lack a theoretical\nunderstanding of the algorithmic behavior of low-rank tensor decompositions. We\nderive Bayesian approximate message passing (AMP) algorithms for recovering\narbitrarily shaped low-rank tensors buried within noise, and we employ dynamic\nmean field theory to precisely characterize their performance. Our theory\nreveals the existence of phase transitions between easy, hard and impossible\ninference regimes, and displays an excellent match with simulations. Moreover,\nit reveals several qualitative surprises compared to the behavior of symmetric,\ncubic tensor decomposition. Finally, we compare our AMP algorithm to the most\ncommonly used algorithm, alternating least squares (ALS), and demonstrate that\nAMP significantly outperforms ALS in the presence of noise.\n", "versions": [{"version": "v1", "created": "Tue, 23 Oct 2018 19:36:28 GMT"}], "update_date": "2020-01-29", "authors_parsed": [["Kadmon", "Jonathan", ""], ["Ganguli", "Surya", ""]]}, {"id": "1810.10076", "submitter": "Navoneel Chakrabarty", "authors": "Navoneel Chakrabarty and Sanket Biswas", "title": "A Statistical Approach to Adult Census Income Level Prediction", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  The prominent inequality of wealth and income is a huge concern especially in\nthe United States. The likelihood of diminishing poverty is one valid reason to\nreduce the world's surging level of economic inequality. The principle of\nuniversal moral equality ensures sustainable development and improve the\neconomic stability of a nation. Governments in different countries have been\ntrying their best to address this problem and provide an optimal solution. This\nstudy aims to show the usage of machine learning and data mining techniques in\nproviding a solution to the income equality problem. The UCI Adult Dataset has\nbeen used for the purpose. Classification has been done to predict whether a\nperson's yearly income in US falls in the income category of either greater\nthan 50K Dollars or less equal to 50K Dollars category based on a certain set\nof attributes. The Gradient Boosting Classifier Model was deployed which\nclocked the highest accuracy of 88.16%, eventually breaking the benchmark\naccuracy of existing works.\n", "versions": [{"version": "v1", "created": "Tue, 23 Oct 2018 20:21:31 GMT"}], "update_date": "2018-10-25", "authors_parsed": [["Chakrabarty", "Navoneel", ""], ["Biswas", "Sanket", ""]]}, {"id": "1810.10078", "submitter": "Zhaoqiang Liu", "authors": "Zhaoqiang Liu", "title": "Model Selection for Nonnegative Matrix Factorization by Support Union\n  Recovery", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG cs.NA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Nonnegative matrix factorization (NMF) has been widely used in machine\nlearning and signal processing because of its non-subtractive, part-based\nproperty which enhances interpretability. It is often assumed that the latent\ndimensionality (or the number of components) is given. Despite the large amount\nof algorithms designed for NMF, there is little literature about automatic\nmodel selection for NMF with theoretical guarantees. In this paper, we propose\nan algorithm that first calculates an empirical second-order moment from the\nempirical fourth-order cumulant tensor, and then estimates the latent\ndimensionality by recovering the support union (the index set of non-zero rows)\nof a matrix related to the empirical second-order moment. By assuming a\ngenerative model of the data with additional mild conditions, our algorithm\nprovably detects the true latent dimensionality. We show on synthetic examples\nthat our proposed algorithm is able to find an approximately correct number of\ncomponents.\n", "versions": [{"version": "v1", "created": "Tue, 23 Oct 2018 20:31:14 GMT"}], "update_date": "2018-10-25", "authors_parsed": [["Liu", "Zhaoqiang", ""]]}, {"id": "1810.10082", "submitter": "Alnur Ali", "authors": "Alnur Ali, J. Zico Kolter, Ryan J. Tibshirani", "title": "A Continuous-Time View of Early Stopping for Least Squares", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the statistical properties of the iterates generated by gradient\ndescent, applied to the fundamental problem of least squares regression. We\ntake a continuous-time view, i.e., consider infinitesimal step sizes in\ngradient descent, in which case the iterates form a trajectory called gradient\nflow. Our primary focus is to compare the risk of gradient flow to that of\nridge regression. Under the calibration $t=1/\\lambda$---where $t$ is the time\nparameter in gradient flow, and $\\lambda$ the tuning parameter in ridge\nregression---we prove that the risk of gradient flow is no less than 1.69 times\nthat of ridge, along the entire path (for all $t \\geq 0$). This holds in finite\nsamples with very weak assumptions on the data model (in particular, with no\nassumptions on the features $X$). We prove that the same relative risk bound\nholds for prediction risk, in an average sense over the underlying signal\n$\\beta_0$. Finally, we examine limiting risk expressions (under standard\nMarchenko-Pastur asymptotics), and give supporting numerical experiments.\n", "versions": [{"version": "v1", "created": "Tue, 23 Oct 2018 20:44:16 GMT"}, {"version": "v2", "created": "Wed, 9 Jan 2019 20:32:30 GMT"}, {"version": "v3", "created": "Mon, 11 Feb 2019 15:44:57 GMT"}, {"version": "v4", "created": "Sat, 23 Feb 2019 20:08:39 GMT"}], "update_date": "2019-02-26", "authors_parsed": [["Ali", "Alnur", ""], ["Kolter", "J. Zico", ""], ["Tibshirani", "Ryan J.", ""]]}, {"id": "1810.10085", "submitter": "Ehsan Kazemi Dr", "authors": "Ehsan Kazemi, Liqiang Wang", "title": "A Proximal Zeroth-Order Algorithm for Nonconvex Nonsmooth Problems", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.OC cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we focus on solving an important class of nonconvex\noptimization problems which includes many problems for example signal\nprocessing over a networked multi-agent system and distributed learning over\nnetworks. Motivated by many applications in which the local objective function\nis the sum of smooth but possibly nonconvex part, and non-smooth but convex\npart subject to a linear equality constraint, this paper proposes a proximal\nzeroth-order primal dual algorithm (PZO-PDA) that accounts for the information\nstructure of the problem. This algorithm only utilize the zeroth-order\ninformation (i.e., the functional values) of smooth functions, yet the\nflexibility is achieved for applications that only noisy information of the\nobjective function is accessible, where classical methods cannot be applied. We\nprove convergence and rate of convergence for PZO-PDA. Numerical experiments\nare provided to validate the theoretical results.\n", "versions": [{"version": "v1", "created": "Wed, 17 Oct 2018 18:28:51 GMT"}], "update_date": "2018-10-25", "authors_parsed": [["Kazemi", "Ehsan", ""], ["Wang", "Liqiang", ""]]}, {"id": "1810.10096", "submitter": "Jacob Rafati", "authors": "Jacob Rafati and David C. Noelle", "title": "Learning Representations in Model-Free Hierarchical Reinforcement\n  Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG math.OC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Common approaches to Reinforcement Learning (RL) are seriously challenged by\nlarge-scale applications involving huge state spaces and sparse delayed reward\nfeedback. Hierarchical Reinforcement Learning (HRL) methods attempt to address\nthis scalability issue by learning action selection policies at multiple levels\nof temporal abstraction. Abstraction can be had by identifying a relatively\nsmall set of states that are likely to be useful as subgoals, in concert with\nthe learning of corresponding skill policies to achieve those subgoals. Many\napproaches to subgoal discovery in HRL depend on the analysis of a model of the\nenvironment, but the need to learn such a model introduces its own problems of\nscale. Once subgoals are identified, skills may be learned through intrinsic\nmotivation, introducing an internal reward signal marking subgoal attainment.\nIn this paper, we present a novel model-free method for subgoal discovery using\nincremental unsupervised learning over a small memory of the most recent\nexperiences (trajectories) of the agent. When combined with an intrinsic\nmotivation learning mechanism, this method learns both subgoals and skills,\nbased on experiences in the environment. Thus, we offer an original approach to\nHRL that does not require the acquisition of a model of the environment,\nsuitable for large-scale applications. We demonstrate the efficiency of our\nmethod on two RL problems with sparse delayed feedback: a variant of the rooms\nenvironment and the first screen of the ATARI 2600 Montezuma's Revenge game.\n", "versions": [{"version": "v1", "created": "Tue, 23 Oct 2018 21:24:06 GMT"}, {"version": "v2", "created": "Thu, 25 Oct 2018 21:19:51 GMT"}, {"version": "v3", "created": "Fri, 12 Apr 2019 16:37:31 GMT"}], "update_date": "2019-04-15", "authors_parsed": [["Rafati", "Jacob", ""], ["Noelle", "David C.", ""]]}, {"id": "1810.10098", "submitter": "David Reiman", "authors": "David M. Reiman, Brett E. G\\\"ohre", "title": "Deblending galaxy superpositions with branched generative adversarial\n  networks", "comments": "14 pages, 6 figures, accepted for publication in MNRAS", "journal-ref": null, "doi": "10.1093/mnras/stz575", "report-no": null, "categories": "astro-ph.IM astro-ph.GA cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Near-future large galaxy surveys will encounter blended galaxy images at a\nfraction of up to 50% in the densest regions of the universe. Current\ndeblending techniques may segment the foreground galaxy while leaving missing\npixel intensities in the background galaxy flux. The problem is compounded by\nthe diffuse nature of galaxies in their outer regions, making segmentation\nsignificantly more difficult than in traditional object segmentation\napplications. We propose a novel branched generative adversarial network (GAN)\nto deblend overlapping galaxies, where the two branches produce images of the\ntwo deblended galaxies. We show that generative models are a powerful engine\nfor deblending given their innate ability to infill missing pixel values\noccluded by the superposition. We maintain high peak signal-to-noise ratio and\nstructural similarity scores with respect to ground truth images upon\ndeblending. Our model also predicts near-instantaneously, making it a natural\nchoice for the immense quantities of data soon to be created by large surveys\nsuch as LSST, Euclid and WFIRST.\n", "versions": [{"version": "v1", "created": "Tue, 23 Oct 2018 21:28:53 GMT"}, {"version": "v2", "created": "Sat, 29 Dec 2018 17:41:25 GMT"}, {"version": "v3", "created": "Sat, 2 Feb 2019 03:58:38 GMT"}, {"version": "v4", "created": "Fri, 8 Mar 2019 20:29:44 GMT"}], "update_date": "2019-03-12", "authors_parsed": [["Reiman", "David M.", ""], ["G\u00f6hre", "Brett E.", ""]]}, {"id": "1810.10107", "submitter": "Abubakar Abid", "authors": "Abubakar Abid, James Zou", "title": "Autowarp: Learning a Warping Distance from Unlabeled Time Series Using\n  Sequence Autoencoders", "comments": "Accepted at NIPS 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Measuring similarities between unlabeled time series trajectories is an\nimportant problem in domains as diverse as medicine, astronomy, finance, and\ncomputer vision. It is often unclear what is the appropriate metric to use\nbecause of the complex nature of noise in the trajectories (e.g. different\nsampling rates or outliers). Domain experts typically hand-craft or manually\nselect a specific metric, such as dynamic time warping (DTW), to apply on their\ndata. In this paper, we propose Autowarp, an end-to-end algorithm that\noptimizes and learns a good metric given unlabeled trajectories. We define a\nflexible and differentiable family of warping metrics, which encompasses common\nmetrics such as DTW, Euclidean, and edit distance. Autowarp then leverages the\nrepresentation power of sequence autoencoders to optimize for a member of this\nwarping distance family. The output is a metric which is easy to interpret and\ncan be robustly learned from relatively few trajectories. In systematic\nexperiments across different domains, we show that Autowarp often outperforms\nhand-crafted trajectory similarity metrics.\n", "versions": [{"version": "v1", "created": "Tue, 23 Oct 2018 22:04:16 GMT"}], "update_date": "2018-10-25", "authors_parsed": [["Abid", "Abubakar", ""], ["Zou", "James", ""]]}, {"id": "1810.10108", "submitter": "Thanh Dung Le", "authors": "Mehdi Ahmadi, Timothy Nest, Mostafa Abdelnaim, Thanh-Dung Le", "title": "Reproducing AmbientGAN: Generative models from lossy measurements", "comments": "This work was submitted as final project for the course IFT6135:\n  Representation Learning - A Deep Learning Course, University of Montreal,\n  Winter 2018", "journal-ref": "ICLR 2018 Reproducibility Challenge", "doi": null, "report-no": null, "categories": "eess.SP cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  In recent years, Generative Adversarial Networks (GANs) have shown\nsubstantial progress in modeling complex distributions of data. These networks\nhave received tremendous attention since they can generate implicit\nprobabilistic models that produce realistic data using a stochastic procedure.\nWhile such models have proven highly effective in diverse scenarios, they\nrequire a large set of fully-observed training samples. In many applications\naccess to such samples are difficult or even impractical and only noisy or\npartial observations of the desired distribution is available. Recent research\nhas tried to address the problem of incompletely observed samples to recover\nthe distribution of the data. \\citep{zhu2017unpaired} and\n\\citep{yeh2016semantic} proposed methods to solve ill-posed inverse problem\nusing cycle-consistency and latent-space mappings in adversarial networks,\nrespectively. \\citep{bora2017compressed} and \\citep{kabkab2018task} have\napplied similar adversarial approaches to the problem of compressed sensing. In\nthis work, we focus on a new variant of GAN models called AmbientGAN, which\nincorporates a measurement process (e.g. adding noise, data removal and\nprojection) into the GAN training. While in the standard GAN, the discriminator\ndistinguishes a generated image from a real image, in AmbientGAN model the\ndiscriminator has to separate a real measurement from a simulated measurement\nof a generated image. The results shown by \\citep{bora2018ambientgan} are quite\npromising for the problem of incomplete data, and have potentially important\nimplications for generative approaches to compressed sensing and ill-posed\nproblems.\n", "versions": [{"version": "v1", "created": "Tue, 23 Oct 2018 22:10:51 GMT"}], "update_date": "2018-10-25", "authors_parsed": [["Ahmadi", "Mehdi", ""], ["Nest", "Timothy", ""], ["Abdelnaim", "Mostafa", ""], ["Le", "Thanh-Dung", ""]]}, {"id": "1810.10118", "submitter": "Rajiv Khanna", "authors": "Rajiv Khanna, Been Kim, Joydeep Ghosh, Oluwasanmi Koyejo", "title": "Interpreting Black Box Predictions using Fisher Kernels", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Research in both machine learning and psychology suggests that salient\nexamples can help humans to interpret learning models. To this end, we take a\nnovel look at black box interpretation of test predictions in terms of training\nexamples. Our goal is to ask `which training examples are most responsible for\na given set of predictions'? To answer this question, we make use of Fisher\nkernels as the defining feature embedding of each data point, combined with\nSequential Bayesian Quadrature (SBQ) for efficient selection of examples. In\ncontrast to prior work, our method is able to seamlessly handle any sized\nsubset of test predictions in a principled way. We theoretically analyze our\napproach, providing novel convergence bounds for SBQ over discrete candidate\natoms. Our approach recovers the application of influence functions for\ninterpretability as a special case yielding novel insights from this\nconnection. We also present applications of the proposed approach to three use\ncases: cleaning training data, fixing mislabeled examples and data\nsummarization.\n", "versions": [{"version": "v1", "created": "Tue, 23 Oct 2018 22:41:41 GMT"}], "update_date": "2018-10-25", "authors_parsed": [["Khanna", "Rajiv", ""], ["Kim", "Been", ""], ["Ghosh", "Joydeep", ""], ["Koyejo", "Oluwasanmi", ""]]}, {"id": "1810.10122", "submitter": "Hongteng Xu", "authors": "Hongteng Xu", "title": "PoPPy: A Point Process Toolbox Based on PyTorch", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  PoPPy is a Point Process toolbox based on PyTorch, which achieves flexible\ndesigning and efficient learning of point process models. It can be used for\ninterpretable sequential data modeling and analysis, e.g., Granger causality\nanalysis of multi-variate point processes, point process-based simulation and\nprediction of event sequences. In practice, the key points of point\nprocess-based sequential data modeling include: 1) How to design intensity\nfunctions to describe the mechanism behind observed data? 2) How to learn the\nproposed intensity functions from observed data? The goal of PoPPy is providing\na user-friendly solution to the key points above and achieving large-scale\npoint process-based sequential data analysis, simulation and prediction.\n", "versions": [{"version": "v1", "created": "Tue, 23 Oct 2018 23:04:13 GMT"}, {"version": "v2", "created": "Thu, 25 Oct 2018 05:41:20 GMT"}, {"version": "v3", "created": "Fri, 11 Oct 2019 16:54:25 GMT"}], "update_date": "2019-10-14", "authors_parsed": [["Xu", "Hongteng", ""]]}, {"id": "1810.10126", "submitter": "Yang Li", "authors": "Yang Li, Lukasz Kaiser, Samy Bengio, Si Si", "title": "Area Attention", "comments": "@InProceedings{pmlr-v97-li19e, title = {Area Attention}, author =\n  {Li, Yang and Kaiser, Lukasz and Bengio, Samy and Si, Si}, booktitle =\n  {Proceedings of the 36th International Conference on Machine Learning}, pages\n  = {3846--3855}, year = {2019}, volume = {97}, series = {Proceedings of\n  Machine Learning Research}, publisher = {PMLR} }", "journal-ref": "ICML 2019", "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CL stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Existing attention mechanisms are trained to attend to individual items in a\ncollection (the memory) with a predefined, fixed granularity, e.g., a word\ntoken or an image grid. We propose area attention: a way to attend to areas in\nthe memory, where each area contains a group of items that are structurally\nadjacent, e.g., spatially for a 2D memory such as images, or temporally for a\n1D memory such as natural language sentences. Importantly, the shape and the\nsize of an area are dynamically determined via learning, which enables a model\nto attend to information with varying granularity. Area attention can easily\nwork with existing model architectures such as multi-head attention for\nsimultaneously attending to multiple areas in the memory. We evaluate area\nattention on two tasks: neural machine translation (both character and\ntoken-level) and image captioning, and improve upon strong (state-of-the-art)\nbaselines in all the cases. These improvements are obtainable with a basic form\nof area attention that is parameter free.\n", "versions": [{"version": "v1", "created": "Tue, 23 Oct 2018 23:14:27 GMT"}, {"version": "v2", "created": "Tue, 30 Oct 2018 22:01:08 GMT"}, {"version": "v3", "created": "Tue, 27 Nov 2018 01:31:26 GMT"}, {"version": "v4", "created": "Tue, 5 Feb 2019 19:58:57 GMT"}, {"version": "v5", "created": "Thu, 23 May 2019 23:34:46 GMT"}, {"version": "v6", "created": "Wed, 5 Jun 2019 22:07:12 GMT"}, {"version": "v7", "created": "Thu, 7 May 2020 21:55:04 GMT"}], "update_date": "2020-05-11", "authors_parsed": [["Li", "Yang", ""], ["Kaiser", "Lukasz", ""], ["Bengio", "Samy", ""], ["Si", "Si", ""]]}, {"id": "1810.10132", "submitter": "Gautam Goel", "authors": "Gautam Goel, Adam Wierman", "title": "Smoothed Online Optimization for Regression and Control", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.DS math.OC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider Online Convex Optimization (OCO) in the setting where the costs\nare $m$-strongly convex and the online learner pays a switching cost for\nchanging decisions between rounds. We show that the recently proposed Online\nBalanced Descent (OBD) algorithm is constant competitive in this setting, with\ncompetitive ratio $3 + O(1/m)$, irrespective of the ambient dimension.\nAdditionally, we show that when the sequence of cost functions is\n$\\epsilon$-smooth, OBD has near-optimal dynamic regret and maintains strong\nper-round accuracy. We demonstrate the generality of our approach by showing\nthat the OBD framework can be used to construct competitive algorithms for a\nvariety of online problems across learning and control, including online\nvariants of ridge regression, logistic regression, maximum likelihood\nestimation, and LQR control.\n", "versions": [{"version": "v1", "created": "Tue, 23 Oct 2018 23:57:40 GMT"}, {"version": "v2", "created": "Thu, 4 Apr 2019 05:30:46 GMT"}], "update_date": "2019-04-05", "authors_parsed": [["Goel", "Gautam", ""], ["Wierman", "Adam", ""]]}, {"id": "1810.10134", "submitter": "Huu Le", "authors": "Huu Le, Anders Eriksson, Thanh-Toan Do, Michael Milford", "title": "A Binary Optimization Approach for Constrained K-Means Clustering", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  K-Means clustering still plays an important role in many computer vision\nproblems. While the conventional Lloyd method, which alternates between\ncentroid update and cluster assignment, is primarily used in practice, it may\nconverge to a solution with empty clusters. Furthermore, some applications may\nrequire the clusters to satisfy a specific set of constraints, e.g., cluster\nsizes, must-link/cannot-link. Several methods have been introduced to solve\nconstrained K-Means clustering. Due to the non-convex nature of K-Means,\nhowever, existing approaches may result in sub-optimal solutions that poorly\napproximate the true clusters. In this work, we provide a new perspective to\ntackle this problem. Particularly, we reconsider constrained K-Means as a\nBinary Optimization Problem and propose a novel optimization scheme to search\nfor feasible solutions in the binary domain. This approach allows us to solve\nconstrained K-Means where multiple types of constraints can be simultaneously\nenforced. Experimental results on synthetic and real datasets show that our\nmethod provides better clustering accuracy with faster runtime compared to\nseveral commonly used techniques.\n", "versions": [{"version": "v1", "created": "Wed, 24 Oct 2018 00:11:33 GMT"}, {"version": "v2", "created": "Mon, 29 Oct 2018 05:51:09 GMT"}], "update_date": "2018-10-30", "authors_parsed": [["Le", "Huu", ""], ["Eriksson", "Anders", ""], ["Do", "Thanh-Toan", ""], ["Milford", "Michael", ""]]}, {"id": "1810.10147", "submitter": "Hao Zhu", "authors": "Xu Han, Hao Zhu, Pengfei Yu, Ziyun Wang, Yuan Yao, Zhiyuan Liu,\n  Maosong Sun", "title": "FewRel: A Large-Scale Supervised Few-Shot Relation Classification\n  Dataset with State-of-the-Art Evaluation", "comments": "EMNLP 2018. The first four authors contribute equally. The order is\n  determined by dice rolling. Visit our website http://zhuhao.me/fewrel", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CL stat.ML", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  We present a Few-Shot Relation Classification Dataset (FewRel), consisting of\n70, 000 sentences on 100 relations derived from Wikipedia and annotated by\ncrowdworkers. The relation of each sentence is first recognized by distant\nsupervision methods, and then filtered by crowdworkers. We adapt the most\nrecent state-of-the-art few-shot learning methods for relation classification\nand conduct a thorough evaluation of these methods. Empirical results show that\neven the most competitive few-shot learning models struggle on this task,\nespecially as compared with humans. We also show that a range of different\nreasoning skills are needed to solve our task. These results indicate that\nfew-shot relation classification remains an open problem and still requires\nfurther research. Our detailed analysis points multiple directions for future\nresearch. All details and resources about the dataset and baselines are\nreleased on http://zhuhao.me/fewrel.\n", "versions": [{"version": "v1", "created": "Wed, 24 Oct 2018 01:18:08 GMT"}, {"version": "v2", "created": "Fri, 26 Oct 2018 21:41:46 GMT"}], "update_date": "2018-10-30", "authors_parsed": [["Han", "Xu", ""], ["Zhu", "Hao", ""], ["Yu", "Pengfei", ""], ["Wang", "Ziyun", ""], ["Yao", "Yuan", ""], ["Liu", "Zhiyuan", ""], ["Sun", "Maosong", ""]]}, {"id": "1810.10158", "submitter": "Haihao Lu", "authors": "Haihao Lu and Rahul Mazumder", "title": "Randomized Gradient Boosting Machine", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG math.OC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Gradient Boosting Machine (GBM) introduced by Friedman is a powerful\nsupervised learning algorithm that is very widely used in practice---it\nroutinely features as a leading algorithm in machine learning competitions such\nas Kaggle and the KDDCup. In spite of the usefulness of GBM in practice, our\ncurrent theoretical understanding of this method is rather limited. In this\nwork, we propose Randomized Gradient Boosting Machine (RGBM) which leads to\nsubstantial computational gains compared to GBM, by using a randomization\nscheme to reduce search in the space of weak-learners. We derive novel\ncomputational guarantees for RGBM. We also provide a principled guideline\ntowards better step-size selection in RGBM that does not require a line search.\nOur proposed framework is inspired by a special variant of coordinate descent\nthat combines the benefits of randomized coordinate descent and greedy\ncoordinate descent; and may be of independent interest as an optimization\nalgorithm. As a special case, our results for RGBM lead to superior\ncomputational guarantees for GBM. Our computational guarantees depend upon a\ncurious geometric quantity that we call Minimal Cosine Angle, which relates to\nthe density of weak-learners in the prediction space. On a series of numerical\nexperiments on real datasets, we demonstrate the effectiveness of RGBM over GBM\nin terms of obtaining a model with good training and/or testing data fidelity\nwith a fraction of the computational cost.\n", "versions": [{"version": "v1", "created": "Wed, 24 Oct 2018 02:50:45 GMT"}, {"version": "v2", "created": "Sun, 28 Oct 2018 18:12:47 GMT"}, {"version": "v3", "created": "Tue, 8 Sep 2020 02:09:40 GMT"}, {"version": "v4", "created": "Wed, 16 Sep 2020 01:00:08 GMT"}], "update_date": "2020-09-17", "authors_parsed": [["Lu", "Haihao", ""], ["Mazumder", "Rahul", ""]]}, {"id": "1810.10161", "submitter": "Yuxiu Hua", "authors": "Yuxiu Hua, Zhifeng Zhao, Rongpeng Li, Xianfu Chen, Zhiming Liu,\n  Honggang Zhang", "title": "Deep Learning with Long Short-Term Memory for Time Series Prediction", "comments": "9 pages, 5 figures, 14 references", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.LG", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Time series prediction can be generalized as a process that extracts useful\ninformation from historical records and then determines future values. Learning\nlong-range dependencies that are embedded in time series is often an obstacle\nfor most algorithms, whereas Long Short-Term Memory (LSTM) solutions, as a\nspecific kind of scheme in deep learning, promise to effectively overcome the\nproblem. In this article, we first give a brief introduction to the structure\nand forward propagation mechanism of the LSTM model. Then, aiming at reducing\nthe considerable computing cost of LSTM, we put forward the Random Connectivity\nLSTM (RCLSTM) model and test it by predicting traffic and user mobility in\ntelecommunication networks. Compared to LSTM, RCLSTM is formed via stochastic\nconnectivity between neurons, which achieves a significant breakthrough in the\narchitecture formation of neural networks. In this way, the RCLSTM model\nexhibits a certain level of sparsity, which leads to an appealing decrease in\nthe computational complexity and makes the RCLSTM model become more applicable\nin latency-stringent application scenarios. In the field of telecommunication\nnetworks, the prediction of traffic series and mobility traces could directly\nbenefit from this improvement as we further demonstrate that the prediction\naccuracy of RCLSTM is comparable to that of the conventional LSTM no matter how\nwe change the number of training samples or the length of input sequences.\n", "versions": [{"version": "v1", "created": "Wed, 24 Oct 2018 03:06:38 GMT"}], "update_date": "2018-10-25", "authors_parsed": [["Hua", "Yuxiu", ""], ["Zhao", "Zhifeng", ""], ["Li", "Rongpeng", ""], ["Chen", "Xianfu", ""], ["Liu", "Zhiming", ""], ["Zhang", "Honggang", ""]]}, {"id": "1810.10167", "submitter": "Qiong Wu Ms", "authors": "Hao Wang, Fan Zhang, Qiong Wu, Yaohua Hu, Yuanming Shi", "title": "Nonconvex and Nonsmooth Sparse Optimization via Adaptively Iterative\n  Reweighted Methods", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IT cs.LG math.IT math.OC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a general formulation of nonconvex and nonsmooth sparse\noptimization problems with a convexset constraint, which takes into account\nmost existing types of nonconvex sparsity-inducing terms. It thus brings strong\napplicability to a wide range of applications. We further design a general\nalgorithmic framework of adaptively iterative reweighted algorithms for solving\nthe nonconvex and nonsmooth sparse optimization problems. This is achieved by\nsolving a sequence of weighted convex penalty subproblems with adaptively\nupdated weights. The first-order optimality condition is then derived and the\nglobal convergence results are provided under loose assumptions. This makes our\ntheoretical results a practical tool for analyzing a family of various\niteratively reweighted algorithms. In particular, for the iteratively reweighed\n$\\ell_1$-algorithm, global convergence analysis is provided for cases with\ndiminishing relaxation parameter. For the iteratively reweighed\n$\\ell_2$-algorithm, adaptively decreasing relaxation parameter is applicable\nand the existence of the cluster point to the algorithm is established. The\neffectiveness and efficiency of our proposed formulation and the algorithms are\ndemonstrated in numerical experiments in various sparse optimization problems.\n", "versions": [{"version": "v1", "created": "Wed, 24 Oct 2018 03:23:42 GMT"}], "update_date": "2018-10-25", "authors_parsed": [["Wang", "Hao", ""], ["Zhang", "Fan", ""], ["Wu", "Qiong", ""], ["Hu", "Yaohua", ""], ["Shi", "Yuanming", ""]]}, {"id": "1810.10172", "submitter": "Qiang Sun", "authors": "Xiucai Ding and Qiang Sun", "title": "Modified Multidimensional Scaling and High Dimensional Clustering", "comments": "There are critical errors in the proofs", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ME cs.LG math.ST stat.ML stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Multidimensional scaling is an important dimension reduction tool in\nstatistics and machine learning. Yet few theoretical results characterizing its\nstatistical performance exist, not to mention any in high dimensions. By\nconsidering a unified framework that includes low, moderate and high\ndimensions, we study multidimensional scaling in the setting of clustering\nnoisy data. Our results suggest that, the classical multidimensional scaling\ncan be modified to further improve the quality of embedded samples, especially\nwhen the noise level increases. To this end, we propose {\\it modified\nmultidimensional scaling} which applies a nonlinear transformation to the\nsample eigenvalues. The nonlinear transformation depends on the dimensionality,\nsample size and moment of noise. We show that modified multidimensional scaling\nfollowed by various clustering algorithms can achieve exact recovery, i.e., all\nthe cluster labels can be recovered correctly with probability tending to one.\nNumerical simulations and two real data applications lend strong support to our\nproposed methodology.\n", "versions": [{"version": "v1", "created": "Wed, 24 Oct 2018 03:51:26 GMT"}, {"version": "v2", "created": "Thu, 3 Jan 2019 23:53:54 GMT"}, {"version": "v3", "created": "Sun, 13 Sep 2020 03:20:14 GMT"}, {"version": "v4", "created": "Tue, 15 Sep 2020 01:03:53 GMT"}], "update_date": "2020-09-16", "authors_parsed": [["Ding", "Xiucai", ""], ["Sun", "Qiang", ""]]}, {"id": "1810.10176", "submitter": "Tolgahan Cakaloglu Ph.D.c", "authors": "Tolgahan Cakaloglu, Christian Szegedy, Xiaowei Xu", "title": "Text Embeddings for Retrieval From a Large Knowledge Base", "comments": "12 pages, 7 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Text embedding representing natural language documents in a semantic vector\nspace can be used for document retrieval using nearest neighbor lookup. In\norder to study the feasibility of neural models specialized for retrieval in a\nsemantically meaningful way, we suggest the use of the Stanford Question\nAnswering Dataset (SQuAD) in an open-domain question answering context, where\nthe first task is to find paragraphs useful for answering a given question.\nFirst, we compare the quality of various text-embedding methods on the\nperformance of retrieval and give an extensive empirical comparison on the\nperformance of various non-augmented base embedding with, and without IDF\nweighting. Our main results are that by training deep residual neural models,\nspecifically for retrieval purposes, can yield significant gains when it is\nused to augment existing embeddings. We also establish that deeper models are\nsuperior to this task. The best base baseline embeddings augmented by our\nlearned neural approach improves the top-1 paragraph recall of the system by\n14%.\n", "versions": [{"version": "v1", "created": "Wed, 24 Oct 2018 03:57:11 GMT"}, {"version": "v2", "created": "Thu, 2 May 2019 17:19:08 GMT"}], "update_date": "2019-05-03", "authors_parsed": [["Cakaloglu", "Tolgahan", ""], ["Szegedy", "Christian", ""], ["Xu", "Xiaowei", ""]]}, {"id": "1810.10191", "submitter": "Michelle A. Lee", "authors": "Michelle A. Lee, Yuke Zhu, Krishnan Srinivasan, Parth Shah, Silvio\n  Savarese, Li Fei-Fei, Animesh Garg, Jeannette Bohg", "title": "Making Sense of Vision and Touch: Self-Supervised Learning of Multimodal\n  Representations for Contact-Rich Tasks", "comments": "ICRA 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Contact-rich manipulation tasks in unstructured environments often require\nboth haptic and visual feedback. However, it is non-trivial to manually design\na robot controller that combines modalities with very different\ncharacteristics. While deep reinforcement learning has shown success in\nlearning control policies for high-dimensional inputs, these algorithms are\ngenerally intractable to deploy on real robots due to sample complexity. We use\nself-supervision to learn a compact and multimodal representation of our\nsensory inputs, which can then be used to improve the sample efficiency of our\npolicy learning. We evaluate our method on a peg insertion task, generalizing\nover different geometry, configurations, and clearances, while being robust to\nexternal perturbations. Results for simulated and real robot experiments are\npresented.\n", "versions": [{"version": "v1", "created": "Wed, 24 Oct 2018 05:21:22 GMT"}, {"version": "v2", "created": "Fri, 8 Mar 2019 03:52:36 GMT"}], "update_date": "2019-03-11", "authors_parsed": [["Lee", "Michelle A.", ""], ["Zhu", "Yuke", ""], ["Srinivasan", "Krishnan", ""], ["Shah", "Parth", ""], ["Savarese", "Silvio", ""], ["Fei-Fei", "Li", ""], ["Garg", "Animesh", ""], ["Bohg", "Jeannette", ""]]}, {"id": "1810.10222", "submitter": "Marcin Kardas", "authors": "Piotr Czapla, Jeremy Howard, Marcin Kardas", "title": "Universal Language Model Fine-Tuning with Subword Tokenization for\n  Polish", "comments": "PolEval 2018 Workshop", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Universal Language Model for Fine-tuning [arXiv:1801.06146] (ULMFiT) is one\nof the first NLP methods for efficient inductive transfer learning.\nUnsupervised pretraining results in improvements on many NLP tasks for English.\nIn this paper, we describe a new method that uses subword tokenization to adapt\nULMFiT to languages with high inflection. Our approach results in a new\nstate-of-the-art for the Polish language, taking first place in Task 3 of\nPolEval'18. After further training, our final model outperformed the second\nbest model by 35%. We have open-sourced our pretrained models and code.\n", "versions": [{"version": "v1", "created": "Wed, 24 Oct 2018 07:34:45 GMT"}], "update_date": "2018-10-25", "authors_parsed": [["Czapla", "Piotr", ""], ["Howard", "Jeremy", ""], ["Kardas", "Marcin", ""]]}, {"id": "1810.10226", "submitter": "Hanbing Zhan", "authors": "Zhou Zhao, Hanbing Zhan, Lingtao Meng, Jun Xiao, Jun Yu, Min Yang, Fei\n  Wu, Deng Cai", "title": "Textually Guided Ranking Network for Attentional Image Retweet Modeling", "comments": "12 pages, 9 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.LG cs.MM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Retweet prediction is a challenging problem in social media sites (SMS). In\nthis paper, we study the problem of image retweet prediction in social media,\nwhich predicts the image sharing behavior that the user reposts the image\ntweets from their followees. Unlike previous studies, we learn user preference\nranking model from their past retweeted image tweets in SMS. We first propose\nheterogeneous image retweet modeling network (IRM) that exploits users' past\nretweeted image tweets with associated contexts, their following relations in\nSMS and preference of their followees. We then develop a novel attentional\nmulti-faceted ranking network learning framework with textually guided\nmulti-modal neural networks for the proposed heterogenous IRM network to learn\nthe joint image tweet representations and user preference representations for\nprediction task. The extensive experiments on a large-scale dataset from\nTwitter site shows that our method achieves better performance than other\nstate-of-the-art solutions to the problem.\n", "versions": [{"version": "v1", "created": "Wed, 24 Oct 2018 07:43:20 GMT"}], "update_date": "2018-10-25", "authors_parsed": [["Zhao", "Zhou", ""], ["Zhan", "Hanbing", ""], ["Meng", "Lingtao", ""], ["Xiao", "Jun", ""], ["Yu", "Jun", ""], ["Yang", "Min", ""], ["Wu", "Fei", ""], ["Cai", "Deng", ""]]}, {"id": "1810.10237", "submitter": "Zhengchao Zhang", "authors": "Zhengchao Zhang, Meng Li, Xi Lin, Yinhai Wang, Fang He", "title": "Multistep Speed Prediction on Traffic Networks: A Graph Convolutional\n  Sequence-to-Sequence Learning Approach with Attention Mechanism", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Multistep traffic forecasting on road networks is a crucial task in\nsuccessful intelligent transportation system applications. To capture the\ncomplex non-stationary temporal dynamics and spatial dependency in multistep\ntraffic-condition prediction, we propose a novel deep learning framework named\nattention graph convolutional sequence-to-sequence model (AGC-Seq2Seq). In the\nproposed deep learning framework, spatial and temporal dependencies are modeled\nthrough the Seq2Seq model and graph convolution network separately, and the\nattention mechanism along with a newly designed training method based on the\nSeq2Seq architecture is proposed to overcome the difficulty in multistep\nprediction and further capture the temporal heterogeneity of traffic pattern.\nWe conduct numerical tests to compare AGC-Seq2Seq with other benchmark models\nusing a real-world dataset. The results indicate that our model yields the best\nprediction performance in terms of various prediction error measures.\nFurthermore, the variation of spatiotemporal correlation of traffic conditions\nunder different perdition steps and road segments is revealed through\nsensitivity analyses.\n", "versions": [{"version": "v1", "created": "Wed, 24 Oct 2018 08:22:01 GMT"}], "update_date": "2018-10-30", "authors_parsed": [["Zhang", "Zhengchao", ""], ["Li", "Meng", ""], ["Lin", "Xi", ""], ["Wang", "Yinhai", ""], ["He", "Fang", ""]]}, {"id": "1810.10274", "submitter": "Jordi Pons M.Sc.", "authors": "Jordi Pons, Joan Serr\\`a, Xavier Serra", "title": "Training neural audio classifiers with few data", "comments": "Code: https://github.com/jordipons/neural-classifiers-with-few-audio/", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SD cs.AI cs.LG eess.AS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We investigate supervised learning strategies that improve the training of\nneural network audio classifiers on small annotated collections. In particular,\nwe study whether (i) a naive regularization of the solution space, (ii)\nprototypical networks, (iii) transfer learning, or (iv) their combination, can\nfoster deep learning models to better leverage a small amount of training\nexamples. To this end, we evaluate (i-iv) for the tasks of acoustic event\nrecognition and acoustic scene classification, considering from 1 to 100\nlabeled examples per class. Results indicate that transfer learning is a\npowerful strategy in such scenarios, but prototypical networks show promising\nresults when one does not count with external or validation data.\n", "versions": [{"version": "v1", "created": "Wed, 24 Oct 2018 09:59:17 GMT"}, {"version": "v2", "created": "Sun, 28 Oct 2018 21:03:52 GMT"}, {"version": "v3", "created": "Sat, 3 Nov 2018 16:42:07 GMT"}], "update_date": "2018-11-07", "authors_parsed": [["Pons", "Jordi", ""], ["Serr\u00e0", "Joan", ""], ["Serra", "Xavier", ""]]}, {"id": "1810.10307", "submitter": "Jinjin Chi", "authors": "Jinjin Chi, Jihong Ouyang, Changchun Li, Xueyang Dong, Ximing Li,\n  Xinhua Wang", "title": "Topic representation: finding more representative words in topic models", "comments": "The paper has been submitted to Pattern Recognition Letters and is\n  being reviewed", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The top word list, i.e., the top-M words with highest marginal probability in\na given topic, is the standard topic representation in topic models. Most of\nrecent automatical topic labeling algorithms and popular topic quality metrics\nare based on it. However, we find, empirically, words in this type of top word\nlist are not always representative. The objective of this paper is to find more\nrepresentative top word lists for topics. To achieve this, we rerank the words\nin a given topic by further considering marginal probability on words over\nevery other topic. The reranking list of top-M words is used to be a novel\ntopic representation for topic models. We investigate three reranking\nmethodologies, using (1) standard deviation weight, (2) standard deviation\nweight with topic size and (3) Chi Square \\c{hi}2statistic selection.\nExperimental results on real world collections indicate that our\nrepresentations can extract more representative words for topics, agreeing with\nhuman judgements.\n", "versions": [{"version": "v1", "created": "Tue, 23 Oct 2018 04:33:49 GMT"}], "update_date": "2018-10-25", "authors_parsed": [["Chi", "Jinjin", ""], ["Ouyang", "Jihong", ""], ["Li", "Changchun", ""], ["Dong", "Xueyang", ""], ["Li", "Ximing", ""], ["Wang", "Xinhua", ""]]}, {"id": "1810.10321", "submitter": "Aadirupa Saha", "authors": "Aadirupa Saha and Aditya Gopalan", "title": "Active Ranking with Subset-wise Preferences", "comments": "In 22nd International Conference on Artificial Intelligence and\n  Statistics (AISTATS), 2019. (44 pages, 8 figures). arXiv admin note: text\n  overlap with arXiv:1808.04008", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the problem of probably approximately correct (PAC) ranking $n$\nitems by adaptively eliciting subset-wise preference feedback. At each round,\nthe learner chooses a subset of $k$ items and observes stochastic feedback\nindicating preference information of the winner (most preferred) item of the\nchosen subset drawn according to a Plackett-Luce (PL) subset choice model\nunknown a priori. The objective is to identify an $\\epsilon$-optimal ranking of\nthe $n$ items with probability at least $1 - \\delta$. When the feedback in each\nsubset round is a single Plackett-Luce-sampled item, we show $(\\epsilon,\n\\delta)$-PAC algorithms with a sample complexity of\n$O\\left(\\frac{n}{\\epsilon^2} \\ln \\frac{n}{\\delta} \\right)$ rounds, which we\nestablish as being order-optimal by exhibiting a matching sample complexity\nlower bound of $\\Omega\\left(\\frac{n}{\\epsilon^2} \\ln \\frac{n}{\\delta}\n\\right)$---this shows that there is essentially no improvement possible from\nthe pairwise comparisons setting ($k = 2$). When, however, it is possible to\nelicit top-$m$ ($\\leq k$) ranking feedback according to the PL model from each\nadaptively chosen subset of size $k$, we show that an $(\\epsilon, \\delta)$-PAC\nranking sample complexity of $O\\left(\\frac{n}{m \\epsilon^2} \\ln\n\\frac{n}{\\delta} \\right)$ is achievable with explicit algorithms, which\nrepresents an $m$-wise reduction in sample complexity compared to the pairwise\ncase. This again turns out to be order-wise unimprovable across the class of\nsymmetric ranking algorithms. Our algorithms rely on a novel {pivot trick} to\nmaintain only $n$ itemwise score estimates, unlike $O(n^2)$ pairwise score\nestimates that has been used in prior work. We report results of numerical\nexperiments that corroborate our findings.\n", "versions": [{"version": "v1", "created": "Tue, 23 Oct 2018 17:31:52 GMT"}, {"version": "v2", "created": "Fri, 1 Mar 2019 21:45:38 GMT"}], "update_date": "2019-03-06", "authors_parsed": [["Saha", "Aadirupa", ""], ["Gopalan", "Aditya", ""]]}, {"id": "1810.10323", "submitter": "Dong Kyun Shin", "authors": "Dong Kyun Shin, Minhaz Uddin Ahmed and Phill Kyu Rhee", "title": "Incremental Deep Learning for Robust Object Detection in Unknown\n  Cluttered Environments", "comments": "14 pages, 17 figures", "journal-ref": null, "doi": "10.1109/ACCESS.2018.2875720", "report-no": null, "categories": "cs.CV cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Object detection in streaming images is a major step in different\ndetection-based applications, such as object tracking, action recognition,\nrobot navigation, and visual surveillance applications. In mostcases, image\nquality is noisy and biased, and as a result, the data distributions are\ndisturbed and imbalanced. Most object detection approaches, such as the faster\nregion-based convolutional neural network (Faster RCNN), Single Shot Multibox\nDetector with 300x300 inputs (SSD300), and You Only Look Once version 2\n(YOLOv2), rely on simple sampling without considering distortions and noise\nunder real-world changing environments, despite poor object labeling. In this\npaper, we propose an Incremental active semi-supervised learning (IASSL)\ntechnology for unseen object detection. It combines batch-based active learning\n(AL) and bin-based semi-supervised learning (SSL) to leverage the strong points\nof AL's exploration and SSL's exploitation capabilities. A collaborative\nsampling method is also adopted to measure the uncertainty and diversity of AL\nand the confidence in SSL. Batch-based AL allows us to select more informative,\nconfident, and representative samples with low cost. Bin-based SSL divides\nstreaming image samples into several bins, and each bin repeatedly transfers\nthe discriminative knowledge of convolutional neural network (CNN) deep\nlearning to the next bin until the performance criterion is reached. IASSL can\novercome noisy and biased labels in unknown, cluttered data distributions. We\nobtain superior performance, compared to state-of-the-art technologies such as\nFaster RCNN, SSD300, and YOLOv2.\n", "versions": [{"version": "v1", "created": "Sat, 13 Oct 2018 17:10:41 GMT"}], "update_date": "2018-10-25", "authors_parsed": [["Shin", "Dong Kyun", ""], ["Ahmed", "Minhaz Uddin", ""], ["Rhee", "Phill Kyu", ""]]}, {"id": "1810.10325", "submitter": "Sebastian Niehaus", "authors": "Jonas Koenig, Simon Malberg, Martin Martens, Sebastian Niehaus, Artus\n  Krohn-Grimberghe, Arunselvan Ramaswamy", "title": "Multi-Stage Reinforcement Learning For Object Detection", "comments": "Accepted for the Computer Vision Conference (CVC) 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a reinforcement learning approach for detecting objects within an\nimage. Our approach performs a step-wise deformation of a bounding box with the\ngoal of tightly framing the object. It uses a hierarchical tree-like\nrepresentation of predefined region candidates, which the agent can zoom in on.\nThis reduces the number of region candidates that must be evaluated so that the\nagent can afford to compute new feature maps before each step to enhance\ndetection quality. We compare an approach that is based purely on zoom actions\nwith one that is extended by a second refinement stage to fine-tune the\nbounding box after each zoom step. We also improve the fitting ability by\nallowing for different aspect ratios of the bounding box. Finally, we propose\ndifferent reward functions to lead to a better guidance of the agent while\nfollowing its search trajectories. Experiments indicate that each of these\nextensions leads to more correct detections. The best performing approach\ncomprises a zoom stage and a refinement stage, uses aspect-ratio modifying\nactions and is trained using a combination of three different reward metrics.\n", "versions": [{"version": "v1", "created": "Mon, 15 Oct 2018 21:41:57 GMT"}, {"version": "v2", "created": "Fri, 26 Oct 2018 11:11:02 GMT"}], "update_date": "2018-10-29", "authors_parsed": [["Koenig", "Jonas", ""], ["Malberg", "Simon", ""], ["Martens", "Martin", ""], ["Niehaus", "Sebastian", ""], ["Krohn-Grimberghe", "Artus", ""], ["Ramaswamy", "Arunselvan", ""]]}, {"id": "1810.10326", "submitter": "Lisa Graziani", "authors": "Lisa Graziani, Stefano Melacci, Marco Gori", "title": "Coherence Constraints in Facial Expression Recognition", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recognizing facial expressions from static images or video sequences is a\nwidely studied but still challenging problem. The recent progresses obtained by\ndeep neural architectures, or by ensembles of heterogeneous models, have shown\nthat integrating multiple input representations leads to state-of-the-art\nresults. In particular, the appearance and the shape of the input face, or the\nrepresentations of some face parts, are commonly used to boost the quality of\nthe recognizer. This paper investigates the application of Convolutional Neural\nNetworks (CNNs) with the aim of building a versatile recognizer of expressions\nin static images that can be further applied to video sequences. We first study\nthe importance of different face parts in the recognition task, focussing on\nappearance and shape-related features. Then we cast the learning problem in the\nSemi-Supervised setting, exploiting video data, where only a few frames are\nsupervised. The unsupervised portion of the training data is used to enforce\nthree types of coherence, namely temporal coherence, coherence among the\npredictions on the face parts and coherence between appearance and shape-based\nrepresentation. Our experimental analysis shows that coherence constraints can\nimprove the quality of the expression recognizer, thus offering a suitable\nbasis to profitably exploit unsupervised video sequences. Finally we present\nsome examples with occlusions where the shape-based predictor performs better\nthan the appearance one.\n", "versions": [{"version": "v1", "created": "Wed, 17 Oct 2018 07:51:46 GMT"}], "update_date": "2018-10-25", "authors_parsed": [["Graziani", "Lisa", ""], ["Melacci", "Stefano", ""], ["Gori", "Marco", ""]]}, {"id": "1810.10327", "submitter": "Ha Young Kim", "authors": "Ba Rom Kang and Ha Young Kim", "title": "BshapeNet: Object Detection and Instance Segmentation with Bounding\n  Shape Masks", "comments": "10 pages,6 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent object detectors use four-coordinate bounding box (bbox) regression to\npredict object locations. Providing additional information indicating the\nobject positions and coordinates will improve detection performance. Thus, we\npropose two types of masks: a bbox mask and a bounding shape (bshape) mask, to\nrepresent the object's bbox and boundary shape, respectively. For each of these\ntypes, we consider two variants: the Thick model and the Scored model, both of\nwhich have the same morphology but differ in ways to make their boundaries\nthicker. To evaluate the proposed masks, we design extended frameworks by\nadding a bshape mask (or a bbox mask) branch to a Faster R-CNN framework, and\ncall this BshapeNet (or BboxNet). Further, we propose BshapeNet+, a network\nthat combines a bshape mask branch with a Mask R-CNN to improve instance\nsegmentation as well as detection. Among our proposed models, BshapeNet+\ndemonstrates the best performance in both tasks and achieves highly competitive\nresults with state of the art (SOTA) models. Particularly, it improves the\ndetection results over Faster R-CNN+RoIAlign (37.3% and 28.9%) with a detection\nAP of 42.4% and 32.3% on MS COCO test-dev and Cityscapes val, respectively.\nFurthermore, for small objects, it achieves 24.9% AP on COCO test-dev, a\nsignificant improvement over previous SOTA models. For instance segmentation,\nit is substantially superior to Mask R-CNN on both test datasets.\n", "versions": [{"version": "v1", "created": "Mon, 15 Oct 2018 10:12:45 GMT"}, {"version": "v2", "created": "Fri, 22 Mar 2019 19:04:05 GMT"}, {"version": "v3", "created": "Wed, 31 Jul 2019 11:19:23 GMT"}], "update_date": "2019-08-01", "authors_parsed": [["Kang", "Ba Rom", ""], ["Kim", "Ha Young", ""]]}, {"id": "1810.10328", "submitter": "Niall Twomey", "authors": "Rafael Poyiadzi and Raul Santos-Rodriguez and Niall Twomey", "title": "Label Propagation for Learning with Label Proportions", "comments": "Accepted to MLSP 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Learning with Label Proportions (LLP) is the problem of recovering the\nunderlying true labels given a dataset when the data is presented in the form\nof bags. This paradigm is particularly suitable in contexts where providing\nindividual labels is expensive and label aggregates are more easily obtained.\nIn the healthcare domain, it is a burden for a patient to keep a detailed diary\nof their daily routines, but often they will be amenable to provide higher\nlevel summaries of daily behavior. We present a novel and efficient graph-based\nalgorithm that encourages local smoothness and exploits the global structure of\nthe data, while preserving the `mass' of each bag.\n", "versions": [{"version": "v1", "created": "Wed, 24 Oct 2018 12:24:59 GMT"}], "update_date": "2018-10-25", "authors_parsed": [["Poyiadzi", "Rafael", ""], ["Santos-Rodriguez", "Raul", ""], ["Twomey", "Niall", ""]]}, {"id": "1810.10329", "submitter": "Nick Pears", "authors": "Rohan Watkins, Nick Pears and Suresh Manandhar", "title": "Vehicle classification using ResNets, localisation and\n  spatially-weighted pooling", "comments": "15 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We investigate whether ResNet architectures can outperform more traditional\nConvolutional Neural Networks on the task of fine-grained vehicle\nclassification. We train and test ResNet-18, ResNet-34 and ResNet-50 on the\nComprehensive Cars dataset without pre-training on other datasets. We then\nmodify the networks to use Spatially Weighted Pooling. Finally, we add a\nlocalisation step before the classification process, using a network based on\nResNet-50. We find that using Spatially Weighted Pooling and localisation both\nimprove classification accuracy of ResNet50. Spatially Weighted Pooling\nincreases accuracy by 1.5 percent points and localisation increases accuracy by\n3.4 percent points. Using both increases accuracy by 3.7 percent points giving\na top-1 accuracy of 96.351\\% on the Comprehensive Cars dataset. Our method\nachieves higher accuracy than a range of methods including those that use\ntraditional CNNs. However, our method does not perform quite as well as\npre-trained networks that use Spatially Weighted Pooling.\n", "versions": [{"version": "v1", "created": "Mon, 15 Oct 2018 13:28:19 GMT"}], "update_date": "2018-10-25", "authors_parsed": [["Watkins", "Rohan", ""], ["Pears", "Nick", ""], ["Manandhar", "Suresh", ""]]}, {"id": "1810.10330", "submitter": "Joao Reis", "authors": "Joao Reis and Gil Gon\\c{c}alves", "title": "Hyper-Process Model: A Zero-Shot Learning algorithm for Regression\n  Problems based on Shape Analysis", "comments": "36 pages, 4 figures, 2 tables, submitted to JMLR", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Zero-shot learning (ZSL) can be defined by correctly solving a task where no\ntraining data is available, based on previous acquired knowledge from\ndifferent, but related tasks. So far, this area has mostly drawn the attention\nfrom computer vision community where a new unseen image needs to be correctly\nclassified, assuming the target class was not used in the training procedure.\nApart from image classification, only a couple of generic methods were proposed\nthat are applicable to both classification and regression. These learn the\nrelation among model coefficients so new ones can be predicted according to\nprovided conditions. So far, up to our knowledge, no methods exist that are\napplicable only to regression, and take advantage from such setting. Therefore,\nthe present work proposes a novel algorithm for regression problems that uses\ndata drawn from trained models, instead of model coefficients. In this case, a\nshape analyses on the data is performed to create a statistical shape model and\ngenerate new shapes to train new models. The proposed algorithm is tested in a\ntheoretical setting using the beta distribution where main problem to solve is\nto estimate a function that predicts curves, based on already learned\ndifferent, but related ones.\n", "versions": [{"version": "v1", "created": "Tue, 16 Oct 2018 11:35:16 GMT"}], "update_date": "2018-10-25", "authors_parsed": [["Reis", "Joao", ""], ["Gon\u00e7alves", "Gil", ""]]}, {"id": "1810.10333", "submitter": "Adityanarayanan Radhakrishnan", "authors": "Adityanarayanan Radhakrishnan, Karren Yang, Mikhail Belkin, Caroline\n  Uhler", "title": "Memorization in Overparameterized Autoencoders", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The ability of deep neural networks to generalize well in the\noverparameterized regime has become a subject of significant research interest.\nWe show that overparameterized autoencoders exhibit memorization, a form of\ninductive bias that constrains the functions learned through the optimization\nprocess to concentrate around the training examples, although the network could\nin principle represent a much larger function class. In particular, we prove\nthat single-layer fully-connected autoencoders project data onto the\n(nonlinear) span of the training examples. In addition, we show that deep\nfully-connected autoencoders learn a map that is locally contractive at the\ntraining examples, and hence iterating the autoencoder results in convergence\nto the training examples. Finally, we prove that depth is necessary and provide\nempirical evidence that it is also sufficient for memorization in convolutional\nautoencoders. Understanding this inductive bias may shed light on the\ngeneralization properties of overparametrized deep neural networks that are\ncurrently unexplained by classical statistical theory.\n", "versions": [{"version": "v1", "created": "Tue, 16 Oct 2018 17:02:54 GMT"}, {"version": "v2", "created": "Fri, 1 Feb 2019 17:56:43 GMT"}, {"version": "v3", "created": "Tue, 3 Sep 2019 22:37:13 GMT"}], "update_date": "2019-09-05", "authors_parsed": [["Radhakrishnan", "Adityanarayanan", ""], ["Yang", "Karren", ""], ["Belkin", "Mikhail", ""], ["Uhler", "Caroline", ""]]}, {"id": "1810.10337", "submitter": "Robert Jasper", "authors": "Nicole Nichols and Robert Jasper", "title": "Projecting Trouble: Light Based Adversarial Attacks on Deep Learning\n  Classifiers", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This work demonstrates a physical attack on a deep learning image\nclassification system using projected light onto a physical scene. Prior work\nis dominated by techniques for creating adversarial examples which directly\nmanipulate the digital input of the classifier. Such an attack is limited to\nscenarios where the adversary can directly update the inputs to the classifier.\nThis could happen by intercepting and modifying the inputs to an online API\nsuch as Clarifai or Cloud Vision. Such limitations have led to a vein of\nresearch around physical attacks where objects are constructed to be inherently\nadversarial or adversarial modifications are added to cause misclassification.\nOur work differs from other physical attacks in that we can cause\nmisclassification dynamically without altering physical objects in a permanent\nway.\n  We construct an experimental setup which includes a light projection source,\nan object for classification, and a camera to capture the scene. Experiments\nare conducted against 2D and 3D objects from CIFAR-10. Initial tests show\nprojected light patterns selected via differential evolution could degrade\nclassification from 98% to 22% and 89% to 43% probability for 2D and 3D targets\nrespectively. Subsequent experiments explore sensitivity to physical setup and\ncompare two additional baseline conditions for all 10 CIFAR classes. Some\nphysical targets are more susceptible to perturbation. Simple attacks show near\nequivalent success, and 6 of the 10 classes were disrupted by light.\n", "versions": [{"version": "v1", "created": "Tue, 16 Oct 2018 17:47:07 GMT"}], "update_date": "2018-10-25", "authors_parsed": [["Nichols", "Nicole", ""], ["Jasper", "Robert", ""]]}, {"id": "1810.10338", "submitter": "Thomas Lampert", "authors": "Thomas Lampert, Odyss\\'ee Merveille, Jessica Schmitz, Germain\n  Forestier, Friedrich Feuerhake, C\\'edric Wemmert", "title": "Strategies for Training Stain Invariant CNNs", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  An important part of Digital Pathology is the analysis of multiple digitised\nwhole slide images from differently stained tissue sections. It is common\npractice to mount consecutive sections containing corresponding microscopic\nstructures on glass slides, and to stain them differently to highlight specific\ntissue components. These multiple staining modalities result in very different\nimages but include a significant amount of consistent image information. Deep\nlearning approaches have recently been proposed to analyse these images in\norder to automatically identify objects of interest for pathologists. These\nsupervised approaches require a vast amount of annotations, which are difficult\nand expensive to acquire---a problem that is multiplied with multiple\nstainings. This article presents several training strategies that make progress\ntowards stain invariant networks. By training the network on one commonly used\nstaining modality and applying it to images that include corresponding but\ndifferently stained tissue structures, the presented unsupervised strategies\ndemonstrate significant improvements over standard training strategies.\n", "versions": [{"version": "v1", "created": "Wed, 17 Oct 2018 09:41:23 GMT"}, {"version": "v2", "created": "Sat, 3 Nov 2018 23:13:02 GMT"}], "update_date": "2018-11-06", "authors_parsed": [["Lampert", "Thomas", ""], ["Merveille", "Odyss\u00e9e", ""], ["Schmitz", "Jessica", ""], ["Forestier", "Germain", ""], ["Feuerhake", "Friedrich", ""], ["Wemmert", "C\u00e9dric", ""]]}, {"id": "1810.10342", "submitter": "Lily Peng", "authors": "Avinash Varadarajan, Pinal Bavishi, Paisan Raumviboonsuk, Peranut\n  Chotcomwongse, Subhashini Venugopalan, Arunachalam Narayanaswamy, Jorge\n  Cuadros, Kuniyoshi Kanai, George Bresnick, Mongkol Tadarati, Sukhum\n  Silpa-archa, Jirawut Limwattanayingyong, Variya Nganthavee, Joe Ledsam,\n  Pearse A Keane, Greg S Corrado, Lily Peng, Dale R Webster", "title": "Predicting optical coherence tomography-derived diabetic macular edema\n  grades from fundus photographs using deep learning", "comments": null, "journal-ref": "Nature Communications (2020)", "doi": "10.1038/s41467-019-13922-8", "report-no": null, "categories": "cs.CV cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Diabetic eye disease is one of the fastest growing causes of preventable\nblindness. With the advent of anti-VEGF (vascular endothelial growth factor)\ntherapies, it has become increasingly important to detect center-involved\ndiabetic macular edema (ci-DME). However, center-involved diabetic macular\nedema is diagnosed using optical coherence tomography (OCT), which is not\ngenerally available at screening sites because of cost and workflow\nconstraints. Instead, screening programs rely on the detection of hard exudates\nin color fundus photographs as a proxy for DME, often resulting in high false\npositive or false negative calls. To improve the accuracy of DME screening, we\ntrained a deep learning model to use color fundus photographs to predict\nci-DME. Our model had an ROC-AUC of 0.89 (95% CI: 0.87-0.91), which corresponds\nto a sensitivity of 85% at a specificity of 80%. In comparison, three retinal\nspecialists had similar sensitivities (82-85%), but only half the specificity\n(45-50%, p<0.001 for each comparison with model). The positive predictive value\n(PPV) of the model was 61% (95% CI: 56-66%), approximately double the 36-38% by\nthe retinal specialists. In addition to predicting ci-DME, our model was able\nto detect the presence of intraretinal fluid with an AUC of 0.81 (95% CI:\n0.81-0.86) and subretinal fluid with an AUC of 0.88 (95% CI: 0.85-0.91). The\nability of deep learning algorithms to make clinically relevant predictions\nthat generally require sophisticated 3D-imaging equipment from simple 2D images\nhas broad relevance to many other applications in medical imaging.\n", "versions": [{"version": "v1", "created": "Thu, 18 Oct 2018 23:22:33 GMT"}, {"version": "v2", "created": "Mon, 19 Nov 2018 01:46:59 GMT"}, {"version": "v3", "created": "Sat, 9 Feb 2019 17:50:50 GMT"}, {"version": "v4", "created": "Wed, 31 Jul 2019 23:39:59 GMT"}], "update_date": "2020-06-03", "authors_parsed": [["Varadarajan", "Avinash", ""], ["Bavishi", "Pinal", ""], ["Raumviboonsuk", "Paisan", ""], ["Chotcomwongse", "Peranut", ""], ["Venugopalan", "Subhashini", ""], ["Narayanaswamy", "Arunachalam", ""], ["Cuadros", "Jorge", ""], ["Kanai", "Kuniyoshi", ""], ["Bresnick", "George", ""], ["Tadarati", "Mongkol", ""], ["Silpa-archa", "Sukhum", ""], ["Limwattanayingyong", "Jirawut", ""], ["Nganthavee", "Variya", ""], ["Ledsam", "Joe", ""], ["Keane", "Pearse A", ""], ["Corrado", "Greg S", ""], ["Peng", "Lily", ""], ["Webster", "Dale R", ""]]}, {"id": "1810.10348", "submitter": "Amirreza Rezvantalab", "authors": "Amirreza Rezvantalab, Habib Safigholi, Somayeh Karimijeshni", "title": "Dermatologist Level Dermoscopy Skin Cancer Classification Using\n  Different Deep Learning Convolutional Neural Networks Algorithms", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, the effectiveness and capability of convolutional neural\nnetworks have been studied in the classification of 8 skin diseases. Different\npre-trained state-of-the-art architectures (DenseNet 201, ResNet 152, Inception\nv3, InceptionResNet v2) were used and applied on 10135 dermoscopy skin images\nin total (HAM10000: 10015, PH2: 120). The utilized dataset includes 8\ndiagnostic categories - melanoma, melanocytic nevi, basal cell carcinoma,\nbenign keratosis, actinic keratosis and intraepithelial carcinoma,\ndermatofibroma, vascular lesions, and atypical nevi. The aim is to compare the\nability of deep learning with the performance of highly trained dermatologists.\nOverall, the mean results show that all deep learning models outperformed\ndermatologists (at least 11%). The best ROC AUC values for melanoma and basal\ncell carcinoma are 94.40% (ResNet 152) and 99.30% (DenseNet 201) versus 82.26%\nand 88.82% of dermatologists, respectively. Also, DenseNet 201 had the highest\nmacro and micro averaged AUC values for overall classification (98.16%, 98.79%,\nrespectively).\n", "versions": [{"version": "v1", "created": "Sun, 21 Oct 2018 23:27:59 GMT"}], "update_date": "2018-10-25", "authors_parsed": [["Rezvantalab", "Amirreza", ""], ["Safigholi", "Habib", ""], ["Karimijeshni", "Somayeh", ""]]}, {"id": "1810.10350", "submitter": "Michelle Kuchera", "authors": "Michelle P. Kuchera, Raghuram Ramanujan, Jack Z. Taylor, Ryan R.\n  Strauss, Daniel Bazin, Joshua Bradt, Ruiming Chen", "title": "Machine Learning Methods for Track Classification in the AT-TPC", "comments": null, "journal-ref": "NIMA 940 (2019) 56-167, ISSN 0168-9002", "doi": "10.1016/j.nima.2019.05.097", "report-no": "NIMA-D-18-01137", "categories": "cs.CV cs.LG nucl-ex", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We evaluate machine learning methods for event classification in the\nActive-Target Time Projection Chamber detector at the National Superconducting\nCyclotron Laboratory (NSCL) at Michigan State University. An automated method\nto single out the desired reaction product would result in more accurate\nphysics results as well as a faster analysis process. Binary and multi-class\nclassification methods were tested on data produced by the $^{46}$Ar(p,p)\nexperiment run at the NSCL in September 2015. We found a Convolutional Neural\nNetwork to be the most successful classifier of proton scattering events for\ntransfer learning. Results from this investigation and recommendations for\nevent classification in future experiments are presented.\n", "versions": [{"version": "v1", "created": "Sun, 21 Oct 2018 18:52:01 GMT"}, {"version": "v2", "created": "Fri, 22 Feb 2019 01:57:47 GMT"}, {"version": "v3", "created": "Tue, 30 Apr 2019 01:54:11 GMT"}], "update_date": "2019-07-17", "authors_parsed": [["Kuchera", "Michelle P.", ""], ["Ramanujan", "Raghuram", ""], ["Taylor", "Jack Z.", ""], ["Strauss", "Ryan R.", ""], ["Bazin", "Daniel", ""], ["Bradt", "Joshua", ""], ["Chen", "Ruiming", ""]]}, {"id": "1810.10358", "submitter": "Lin Zhang", "authors": "Lin Zhang, Valery Vishnevskiy, Andras Jakab, Orcun Goksel", "title": "Implicit Modeling with Uncertainty Estimation for Intravoxel Incoherent\n  Motion Imaging", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Intravoxel incoherent motion (IVIM) imaging allows contrast-agent free in\nvivo perfusion quantification with magnetic resonance imaging (MRI). However,\nits use is limited by typically low accuracy due to low signal-to-noise ratio\n(SNR) at large gradient encoding magnitudes as well as dephasing artefacts\ncaused by subject motion, which is particularly challenging in fetal MRI. To\nmitigate this problem, we propose an implicit IVIM signal acquisition model\nwith which we learn full posterior distribution of perfusion parameters using\nartificial neural networks. This posterior then encapsulates the uncertainty of\nthe inferred parameter estimates, which we validate herein via numerical\nexperiments with rejection-based Bayesian sampling. Compared to\nstate-of-the-art IVIM estimation method of segmented least-squares fitting, our\nproposed approach improves parameter estimation accuracy by 65% on synthetic\nanisotropic perfusion data. On paired rescans of in vivo fetal MRI, our method\nincreases repeatability of parameter estimation in placenta by 46%.\n", "versions": [{"version": "v1", "created": "Mon, 22 Oct 2018 14:22:10 GMT"}], "update_date": "2018-10-25", "authors_parsed": [["Zhang", "Lin", ""], ["Vishnevskiy", "Valery", ""], ["Jakab", "Andras", ""], ["Goksel", "Orcun", ""]]}, {"id": "1810.10363", "submitter": "Yang Xi", "authors": "Tianlun Zhang, Xi Yang", "title": "G-SMOTE: A GMM-based synthetic minority oversampling technique for\n  imbalanced learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Imbalanced Learning is an important learning algorithm for the classification\nmodels, which have enjoyed much popularity on many applications. Typically,\nimbalanced learning algorithms can be partitioned into two types, i.e., data\nlevel approaches and algorithm level approaches. In this paper, the focus is to\ndevelop a robust synthetic minority oversampling technique which falls the\numbrella of data level approaches. On one hand, we proposed a method to\ngenerate synthetic samples in a high dimensional feature space, instead of a\nlinear sampling space. On the other hand, in the proposed imbalanced learning\nframework, Gaussian Mixture Model is employed to distinguish the outliers from\nminority class instances and filter out the synthetic majority class instances.\nLast and more importantly, an adaptive optimization method is proposed to\noptimize these parameters in sampling process. By doing so, an effectiveness\nand efficiency imbalanced learning framework is developed.\n", "versions": [{"version": "v1", "created": "Wed, 24 Oct 2018 12:46:25 GMT"}], "update_date": "2018-10-25", "authors_parsed": [["Zhang", "Tianlun", ""], ["Yang", "Xi", ""]]}, {"id": "1810.10368", "submitter": "Vincent Fortuin", "authors": "Vincent Fortuin, Gideon Dresdner, Heiko Strathmann, Gunnar R\\\"atsch", "title": "Scalable Gaussian Processes on Discrete Domains", "comments": "Published at IEEE Access", "journal-ref": null, "doi": "10.1109/ACCESS.2021.3082761", "report-no": null, "categories": "stat.ML cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Kernel methods on discrete domains have shown great promise for many\nchallenging data types, for instance, biological sequence data and molecular\nstructure data. Scalable kernel methods like Support Vector Machines may offer\ngood predictive performances but do not intrinsically provide uncertainty\nestimates. In contrast, probabilistic kernel methods like Gaussian Processes\noffer uncertainty estimates in addition to good predictive performance but fall\nshort in terms of scalability. While the scalability of Gaussian processes can\nbe improved using sparse inducing point approximations, the selection of these\ninducing points remains challenging. We explore different techniques for\nselecting inducing points on discrete domains, including greedy selection,\ndeterminantal point processes, and simulated annealing. We find that simulated\nannealing, which can select inducing points that are not in the training set,\ncan perform competitively with support vector machines and full Gaussian\nprocesses on synthetic data, as well as on challenging real-world DNA sequence\ndata.\n", "versions": [{"version": "v1", "created": "Wed, 24 Oct 2018 12:55:00 GMT"}, {"version": "v2", "created": "Wed, 30 Jan 2019 10:11:50 GMT"}, {"version": "v3", "created": "Wed, 26 May 2021 16:57:43 GMT"}], "update_date": "2021-05-27", "authors_parsed": [["Fortuin", "Vincent", ""], ["Dresdner", "Gideon", ""], ["Strathmann", "Heiko", ""], ["R\u00e4tsch", "Gunnar", ""]]}, {"id": "1810.10369", "submitter": "Vahid Behzadan", "authors": "Vahid Behzadan and Arslan Munir", "title": "The Faults in Our Pi Stars: Security Issues and Open Challenges in Deep\n  Reinforcement Learning", "comments": "arXiv admin note: text overlap with arXiv:1807.06064,\n  arXiv:1712.03632, arXiv:1803.02811, arXiv:1710.00814 by other authors", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Since the inception of Deep Reinforcement Learning (DRL) algorithms, there\nhas been a growing interest in both research and industrial communities in the\npromising potentials of this paradigm. The list of current and envisioned\napplications of deep RL ranges from autonomous navigation and robotics to\ncontrol applications in the critical infrastructure, air traffic control,\ndefense technologies, and cybersecurity. While the landscape of opportunities\nand the advantages of deep RL algorithms are justifiably vast, the security\nrisks and issues in such algorithms remain largely unexplored. To facilitate\nand motivate further research on these critical challenges, this paper presents\na foundational treatment of the security problem in DRL. We formulate the\nsecurity requirements of DRL, and provide a high-level threat model through the\nclassification and identification of vulnerabilities, attack vectors, and\nadversarial capabilities. Furthermore, we present a review of current\nliterature on security of deep RL from both offensive and defensive\nperspectives. Lastly, we enumerate critical research venues and open problems\nin mitigation and prevention of intentional attacks against deep RL as a\nroadmap for further research in this area.\n", "versions": [{"version": "v1", "created": "Tue, 23 Oct 2018 07:05:17 GMT"}], "update_date": "2018-10-25", "authors_parsed": [["Behzadan", "Vahid", ""], ["Munir", "Arslan", ""]]}, {"id": "1810.10380", "submitter": "Anna Veronika Dorogush", "authors": "Anna Veronika Dorogush, Vasily Ershov, Dmitriy Kruchinin", "title": "Why every GBDT speed benchmark is wrong", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This article provides a comprehensive study of different ways to make speed\nbenchmarks of gradient boosted decision trees algorithm. We show main problems\nof several straight forward ways to make benchmarks, explain, why a speed\nbenchmarking is a challenging task and provide a set of reasonable requirements\nfor a benchmark to be fair and useful.\n", "versions": [{"version": "v1", "created": "Wed, 24 Oct 2018 13:09:03 GMT"}], "update_date": "2018-10-25", "authors_parsed": [["Dorogush", "Anna Veronika", ""], ["Ershov", "Vasily", ""], ["Kruchinin", "Dmitriy", ""]]}, {"id": "1810.10395", "submitter": "Gerasimos Spanakis", "authors": "Ajkel Mino, Gerasimos Spanakis", "title": "LoGAN: Generating Logos with a Generative Adversarial Neural Network\n  Conditioned on color", "comments": "6 page, ICMLA18", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Designing a logo is a long, complicated, and expensive process for any\ndesigner. However, recent advancements in generative algorithms provide models\nthat could offer a possible solution. Logos are multi-modal, have very few\ncategorical properties, and do not have a continuous latent space. Yet,\nconditional generative adversarial networks can be used to generate logos that\ncould help designers in their creative process. We propose LoGAN: an improved\nauxiliary classifier Wasserstein generative adversarial neural network (with\ngradient penalty) that is able to generate logos conditioned on twelve\ndifferent colors. In 768 generated instances (12 classes and 64 logos per\nclass), when looking at the most prominent color, the conditional generation\npart of the model has an overall precision and recall of 0.8 and 0.7\nrespectively. LoGAN's results offer a first glance at how artificial\nintelligence can be used to assist designers in their creative process and open\npromising future directions, such as including more descriptive labels which\nwill provide a more exhaustive and easy-to-use system.\n", "versions": [{"version": "v1", "created": "Tue, 23 Oct 2018 10:22:17 GMT"}], "update_date": "2018-10-25", "authors_parsed": [["Mino", "Ajkel", ""], ["Spanakis", "Gerasimos", ""]]}, {"id": "1810.10425", "submitter": "Gaetano Manzo", "authors": "Gaetano Manzo, Juan Sebastian Ot\\'alora Montenegro, and Gianluca Rizzo", "title": "A Deep Learning Mechanism for Efficient Information Dissemination in\n  Vehicular Floating Content", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Handling the tremendous amount of network data, produced by the explosive\ngrowth of mobile traffic volume, is becoming of main priority to achieve\ndesired performance targets efficiently. Opportunistic communication such as\nFloatingContent (FC), can be used to offload part of the cellular traffic\nvolume to vehicular-to-vehicular communication (V2V), leaving the\ninfrastructure the task of coordinating the communication. Existing FC\ndimensioning approaches have limitations, mainly due to unrealistic assumptions\nand on a coarse partitioning of users, which results in over-dimensioning.\nShaping the opportunistic communication area is a crucial task to achieve\ndesired application performance efficiently. In this work, we propose a\nsolution for this open challenge. In particular, the broadcasting areas called\nAnchor Zone (AZ), are selected via a deep learning approach to minimize\ncommunication resources achieving desired message availability. No assumption\nrequired to fit the classifier in both synthetic and real mobility. A numerical\nstudy is made to validate the effectiveness and efficiency of the proposed\nmethod. The predicted AZ configuration can achieve an accuracy of 89.7%within\n98% of confidence level. By cause of the learning approach, the method performs\neven better in real scenarios, saving up to 27% of resources compared to\nprevious work analytically modelled\n", "versions": [{"version": "v1", "created": "Wed, 24 Oct 2018 14:36:54 GMT"}], "update_date": "2018-10-25", "authors_parsed": [["Manzo", "Gaetano", ""], ["Montenegro", "Juan Sebastian Ot\u00e1lora", ""], ["Rizzo", "Gianluca", ""]]}, {"id": "1810.10460", "submitter": "Elliot J. Crowley", "authors": "Jack Turner, Elliot J. Crowley, Valentin Radu, Jos\\'e Cano, Amos\n  Storkey, Michael O'Boyle", "title": "Distilling with Performance Enhanced Students", "comments": "Preprint. Paper title has changed", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG cs.PF", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  The task of accelerating large neural networks on general purpose hardware\nhas, in recent years, prompted the use of channel pruning to reduce network\nsize. However, the efficacy of pruning based approaches has since been called\ninto question. In this paper, we turn to distillation for model\ncompression---specifically, attention transfer---and develop a simple method\nfor discovering performance enhanced student networks. We combine channel\nsaliency metrics with empirical observations of runtime performance to design\nmore accurate networks for a given latency budget. We apply our methodology to\nresidual and densely-connected networks, and show that we are able to find\nresource-efficient student networks on different hardware platforms while\nmaintaining very high accuracy. These performance-enhanced student networks\nachieve up to 10% boosts in top-1 ImageNet accuracy over their channel-pruned\ncounterparts for the same inference time.\n", "versions": [{"version": "v1", "created": "Wed, 24 Oct 2018 15:45:36 GMT"}, {"version": "v2", "created": "Thu, 7 Mar 2019 16:19:50 GMT"}], "update_date": "2019-03-08", "authors_parsed": [["Turner", "Jack", ""], ["Crowley", "Elliot J.", ""], ["Radu", "Valentin", ""], ["Cano", "Jos\u00e9", ""], ["Storkey", "Amos", ""], ["O'Boyle", "Michael", ""]]}, {"id": "1810.10469", "submitter": "Tommy Tram", "authors": "Tommy Tram, Anton Jansson, Robin Gr\\\"onberg, Mohammad Ali, Jonas\n  Sj\\\"oberg", "title": "Learning Negotiating Behavior Between Cars in Intersections using Deep\n  Q-Learning", "comments": "6 pages, 7 figures, Accepted to IEEE International Conference on\n  Intelligent Transportation Systems (ITSC) 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.GT stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper concerns automated vehicles negotiating with other vehicles,\ntypically human driven, in crossings with the goal to find a decision algorithm\nby learning typical behaviors of other vehicles. The vehicle observes distance\nand speed of vehicles on the intersecting road and use a policy that adapts its\nspeed along its pre-defined trajectory to pass the crossing efficiently. Deep\nQ-learning is used on simulated traffic with different predefined driver\nbehaviors and intentions. The results show a policy that is able to cross the\nintersection avoiding collision with other vehicles 98% of the time, while at\nthe same time not being too passive. Moreover, inferring information over time\nis important to distinguish between different intentions and is shown by\ncomparing the collision rate between a Deep Recurrent Q-Network at 0.85% and a\nDeep Q-learning at 1.75%.\n", "versions": [{"version": "v1", "created": "Wed, 24 Oct 2018 16:06:33 GMT"}], "update_date": "2018-10-25", "authors_parsed": [["Tram", "Tommy", ""], ["Jansson", "Anton", ""], ["Gr\u00f6nberg", "Robin", ""], ["Ali", "Mohammad", ""], ["Sj\u00f6berg", "Jonas", ""]]}, {"id": "1810.10482", "submitter": "Rajat Sen", "authors": "Rajat Sen, Kirthevasan Kandasamy and Sanjay Shakkottai", "title": "Noisy Blackbox Optimization with Multi-Fidelity Queries: A Tree Search\n  Approach", "comments": "18 pages, 9 Figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the problem of black-box optimization of a noisy function in the\npresence of low-cost approximations or fidelities, which is motivated by\nproblems like hyper-parameter tuning. In hyper-parameter tuning evaluating the\nblack-box function at a point involves training a learning algorithm on a large\ndata-set at a particular hyper-parameter and evaluating the validation error.\nEven a single such evaluation can be prohibitively expensive. Therefore, it is\nbeneficial to use low-cost approximations, like training the learning algorithm\non a sub-sampled version of the whole data-set. These low-cost\napproximations/fidelities can however provide a biased and noisy estimate of\nthe function value. In this work, we incorporate the multi-fidelity setup in\nthe powerful framework of noisy black-box optimization through tree-like\nhierarchical partitions. We propose a multi-fidelity bandit based tree-search\nalgorithm for the problem and provide simple regret bounds for our algorithm.\nFinally, we validate the performance of our algorithm on real and synthetic\ndatasets, where it outperforms several benchmarks.\n", "versions": [{"version": "v1", "created": "Wed, 24 Oct 2018 16:38:07 GMT"}], "update_date": "2018-10-25", "authors_parsed": [["Sen", "Rajat", ""], ["Kandasamy", "Kirthevasan", ""], ["Shakkottai", "Sanjay", ""]]}, {"id": "1810.10489", "submitter": "Ahmed Alaa", "authors": "Ahmed M. Alaa and Mihaela van der Schaar", "title": "Forecasting Individualized Disease Trajectories using Interpretable Deep\n  Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Disease progression models are instrumental in predicting individual-level\nhealth trajectories and understanding disease dynamics. Existing models are\ncapable of providing either accurate predictions of patients prognoses or\nclinically interpretable representations of disease pathophysiology, but not\nboth. In this paper, we develop the phased attentive state space (PASS) model\nof disease progression, a deep probabilistic model that captures complex\nrepresentations for disease progression while maintaining clinical\ninterpretability. Unlike Markovian state space models which assume memoryless\ndynamics, PASS uses an attention mechanism to induce \"memoryful\" state\ntransitions, whereby repeatedly updated attention weights are used to focus on\npast state realizations that best predict future states. This gives rise to\ncomplex, non-stationary state dynamics that remain interpretable through the\ngenerated attention weights, which designate the relationships between the\nrealized state variables for individual patients. PASS uses phased LSTM units\n(with time gates controlled by parametrized oscillations) to generate the\nattention weights in continuous time, which enables handling\nirregularly-sampled and potentially missing medical observations. Experiments\non data from a realworld cohort of patients show that PASS successfully\nbalances the tradeoff between accuracy and interpretability: it demonstrates\nsuperior predictive accuracy and learns insightful individual-level\nrepresentations of disease progression.\n", "versions": [{"version": "v1", "created": "Wed, 24 Oct 2018 16:51:35 GMT"}], "update_date": "2018-10-25", "authors_parsed": [["Alaa", "Ahmed M.", ""], ["van der Schaar", "Mihaela", ""]]}, {"id": "1810.10510", "submitter": "Ignacio Rocco", "authors": "Ignacio Rocco, Mircea Cimpoi, Relja Arandjelovi\\'c, Akihiko Torii,\n  Tomas Pajdla, Josef Sivic", "title": "Neighbourhood Consensus Networks", "comments": "In Proceedings of the 32nd Conference on Neural Information\n  Processing Systems (NeurIPS 2018)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We address the problem of finding reliable dense correspondences between a\npair of images. This is a challenging task due to strong appearance differences\nbetween the corresponding scene elements and ambiguities generated by\nrepetitive patterns. The contributions of this work are threefold. First,\ninspired by the classic idea of disambiguating feature matches using semi-local\nconstraints, we develop an end-to-end trainable convolutional neural network\narchitecture that identifies sets of spatially consistent matches by analyzing\nneighbourhood consensus patterns in the 4D space of all possible\ncorrespondences between a pair of images without the need for a global\ngeometric model. Second, we demonstrate that the model can be trained\neffectively from weak supervision in the form of matching and non-matching\nimage pairs without the need for costly manual annotation of point to point\ncorrespondences. Third, we show the proposed neighbourhood consensus network\ncan be applied to a range of matching tasks including both category- and\ninstance-level matching, obtaining the state-of-the-art results on the PF\nPascal dataset and the InLoc indoor visual localization benchmark.\n", "versions": [{"version": "v1", "created": "Wed, 24 Oct 2018 17:45:17 GMT"}, {"version": "v2", "created": "Thu, 29 Nov 2018 07:35:45 GMT"}], "update_date": "2018-11-30", "authors_parsed": [["Rocco", "Ignacio", ""], ["Cimpoi", "Mircea", ""], ["Arandjelovi\u0107", "Relja", ""], ["Torii", "Akihiko", ""], ["Pajdla", "Tomas", ""], ["Sivic", "Josef", ""]]}, {"id": "1810.10525", "submitter": "Max Tegmark", "authors": "Tailin Wu (MIT), Max Tegmark (MIT)", "title": "Toward an AI Physicist for Unsupervised Learning", "comments": "Replaced to match accepted PRE version. Added references, improved\n  discussion. 22 pages, 7 figs", "journal-ref": "Phys. Rev. E 100, 033311 (2019)", "doi": "10.1103/PhysRevE.100.033311", "report-no": null, "categories": "physics.comp-ph cond-mat.dis-nn cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We investigate opportunities and challenges for improving unsupervised\nmachine learning using four common strategies with a long history in physics:\ndivide-and-conquer, Occam's razor, unification and lifelong learning. Instead\nof using one model to learn everything, we propose a novel paradigm centered\naround the learning and manipulation of *theories*, which parsimoniously\npredict both aspects of the future (from past observations) and the domain in\nwhich these predictions are accurate. Specifically, we propose a novel\ngeneralized-mean-loss to encourage each theory to specialize in its\ncomparatively advantageous domain, and a differentiable description length\nobjective to downweight bad data and \"snap\" learned theories into simple\nsymbolic formulas. Theories are stored in a \"theory hub\", which continuously\nunifies learned theories and can propose theories when encountering new\nenvironments. We test our implementation, the toy \"AI Physicist\" learning\nagent, on a suite of increasingly complex physics environments. From\nunsupervised observation of trajectories through worlds involving random\ncombinations of gravity, electromagnetism, harmonic motion and elastic bounces,\nour agent typically learns faster and produces mean-squared prediction errors\nabout a billion times smaller than a standard feedforward neural net of\ncomparable complexity, typically recovering integer and rational theory\nparameters exactly. Our agent successfully identifies domains with different\nlaws of motion also for a nonlinear chaotic double pendulum in a piecewise\nconstant force field.\n", "versions": [{"version": "v1", "created": "Wed, 24 Oct 2018 17:59:57 GMT"}, {"version": "v2", "created": "Mon, 5 Nov 2018 18:32:14 GMT"}, {"version": "v3", "created": "Sun, 21 Apr 2019 02:35:10 GMT"}, {"version": "v4", "created": "Mon, 2 Sep 2019 01:18:25 GMT"}], "update_date": "2019-09-25", "authors_parsed": [["Wu", "Tailin", "", "MIT"], ["Tegmark", "Max", "", "MIT"]]}, {"id": "1810.10531", "submitter": "Andrew Saxe", "authors": "Andrew M. Saxe, James L. McClelland, and Surya Ganguli", "title": "A mathematical theory of semantic development in deep neural networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI q-bio.NC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  An extensive body of empirical research has revealed remarkable regularities\nin the acquisition, organization, deployment, and neural representation of\nhuman semantic knowledge, thereby raising a fundamental conceptual question:\nwhat are the theoretical principles governing the ability of neural networks to\nacquire, organize, and deploy abstract knowledge by integrating across many\nindividual experiences? We address this question by mathematically analyzing\nthe nonlinear dynamics of learning in deep linear networks. We find exact\nsolutions to this learning dynamics that yield a conceptual explanation for the\nprevalence of many disparate phenomena in semantic cognition, including the\nhierarchical differentiation of concepts through rapid developmental\ntransitions, the ubiquity of semantic illusions between such transitions, the\nemergence of item typicality and category coherence as factors controlling the\nspeed of semantic processing, changing patterns of inductive projection over\ndevelopment, and the conservation of semantic similarity in neural\nrepresentations across species. Thus, surprisingly, our simple neural model\nqualitatively recapitulates many diverse regularities underlying semantic\ndevelopment, while providing analytic insight into how the statistical\nstructure of an environment can interact with nonlinear deep learning dynamics\nto give rise to these regularities.\n", "versions": [{"version": "v1", "created": "Tue, 23 Oct 2018 22:20:27 GMT"}], "update_date": "2018-10-26", "authors_parsed": [["Saxe", "Andrew M.", ""], ["McClelland", "James L.", ""], ["Ganguli", "Surya", ""]]}, {"id": "1810.10533", "submitter": "Hari Prasanna Das", "authors": "Hari Prasanna Das, Ioannis C. Konstantakopoulos, Aummul Baneen\n  Manasawala, Tanya Veeravalli, Huihan Liu and Costas J. Spanos", "title": "Segmentation Analysis in Human Centric Cyber-Physical Systems using\n  Graphical Lasso", "comments": "arXiv admin note: substantial text overlap with arXiv:1809.05142", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.AP stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A generalized gamification framework is introduced as a form of smart\ninfrastructure with potential to improve sustainability and energy efficiency\nby leveraging humans-in-the-loop strategy. The proposed framework enables a\nHuman-Centric Cyber-Physical System using an interface to allow building\nmanagers to interact with occupants. The interface is designed for occupant\nengagement-integration supporting learning of their preferences over resources\nin addition to understanding how preferences change as a function of external\nstimuli such as physical control, time or incentives. Towards intelligent and\nautonomous incentive design, a noble statistical learning algorithm performing\noccupants energy usage behavior segmentation is proposed. We apply the proposed\nalgorithm, Graphical Lasso, on energy resource usage data by the occupants to\nobtain feature correlations--dependencies. Segmentation analysis results in\ncharacteristic clusters demonstrating different energy usage behaviors. The\nfeatures--factors characterizing human decision-making are made explainable.\n", "versions": [{"version": "v1", "created": "Wed, 24 Oct 2018 11:08:13 GMT"}, {"version": "v2", "created": "Thu, 17 Jan 2019 02:14:17 GMT"}], "update_date": "2019-01-21", "authors_parsed": [["Das", "Hari Prasanna", ""], ["Konstantakopoulos", "Ioannis C.", ""], ["Manasawala", "Aummul Baneen", ""], ["Veeravalli", "Tanya", ""], ["Liu", "Huihan", ""], ["Spanos", "Costas J.", ""]]}, {"id": "1810.10535", "submitter": "WaiChing Sun", "authors": "Kun Wang, WaiChing Sun", "title": "Meta-modeling game for deriving theoretical-consistent,\n  micro-structural-based traction-separation laws via deep reinforcement\n  learning", "comments": null, "journal-ref": null, "doi": "10.1016/j.cma.2018.11.026", "report-no": null, "categories": "cs.LG physics.comp-ph physics.geo-ph stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  This paper presents a new meta-modeling framework to employ deep\nreinforcement learning (DRL) to generate mechanical constitutive models for\ninterfaces. The constitutive models are conceptualized as information flow in\ndirected graphs. The process of writing constitutive models are simplified as a\nsequence of forming graph edges with the goal of maximizing the model score (a\nfunction of accuracy, robustness and forward prediction quality). Thus\nmeta-modeling can be formulated as a Markov decision process with well-defined\nstates, actions, rules, objective functions, and rewards. By using neural\nnetworks to estimate policies and state values, the computer agent is able to\nefficiently self-improve the constitutive model it generated through\nself-playing, in the same way AlphaGo Zero (the algorithm that outplayed the\nworld champion in the game of Go)improves its gameplay. Our numerical examples\nshow that this automated meta-modeling framework not only produces models which\noutperform existing cohesive models on benchmark traction-separation data but\nis also capable of detecting hidden mechanisms among micro-structural features\nand incorporating them in constitutive models to improve the forward prediction\naccuracy, which are difficult tasks to do manually.\n", "versions": [{"version": "v1", "created": "Wed, 24 Oct 2018 23:21:55 GMT"}], "update_date": "2019-01-30", "authors_parsed": [["Wang", "Kun", ""], ["Sun", "WaiChing", ""]]}, {"id": "1810.10551", "submitter": "V\\'it R\\r{u}\\v{z}i\\v{c}ka", "authors": "V\\'it R\\r{u}\\v{z}i\\v{c}ka and Franz Franchetti", "title": "Fast and accurate object detection in high resolution 4K and 8K video\n  using GPUs", "comments": "6 pages, 12 figures, Best Paper Finalist at IEEE High Performance\n  Extreme Computing Conference (HPEC) 2018; copyright 2018 IEEE; (DOI will be\n  filled when known)", "journal-ref": "2018 IEEE High Performance extreme Computing Conference (HPEC)", "doi": "10.1109/HPEC.2018.8547574", "report-no": null, "categories": "cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Machine learning has celebrated a lot of achievements on computer vision\ntasks such as object detection, but the traditionally used models work with\nrelatively low resolution images. The resolution of recording devices is\ngradually increasing and there is a rising need for new methods of processing\nhigh resolution data. We propose an attention pipeline method which uses two\nstaged evaluation of each image or video frame under rough and refined\nresolution to limit the total number of necessary evaluations. For both stages,\nwe make use of the fast object detection model YOLO v2. We have implemented our\nmodel in code, which distributes the work across GPUs. We maintain high\naccuracy while reaching the average performance of 3-6 fps on 4K video and 2\nfps on 8K video.\n", "versions": [{"version": "v1", "created": "Wed, 24 Oct 2018 18:00:06 GMT"}], "update_date": "2019-02-01", "authors_parsed": [["R\u016f\u017ei\u010dka", "V\u00edt", ""], ["Franchetti", "Franz", ""]]}, {"id": "1810.10581", "submitter": "Abhik Singla", "authors": "Abhik Singla, Partha Pratim Roy and Debi Prosad Dogra", "title": "Visual Rendering of Shapes on 2D Display Devices Guided by Hand Gestures", "comments": "Submitted to Elsevier Displays Journal, 32 pages, 18 figures, 7\n  tables", "journal-ref": null, "doi": "10.1016/j.displa.2019.03.001", "report-no": null, "categories": "cs.HC cs.CV cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Designing of touchless user interface is gaining popularity in various\ncontexts. Using such interfaces, users can interact with electronic devices\neven when the hands are dirty or non-conductive. Also, user with partial\nphysical disability can interact with electronic devices using such systems.\nResearch in this direction has got major boost because of the emergence of\nlow-cost sensors such as Leap Motion, Kinect or RealSense devices. In this\npaper, we propose a Leap Motion controller-based methodology to facilitate\nrendering of 2D and 3D shapes on display devices. The proposed method tracks\nfinger movements while users perform natural gestures within the field of view\nof the sensor. In the next phase, trajectories are analyzed to extract extended\nNpen++ features in 3D. These features represent finger movements during the\ngestures and they are fed to unidirectional left-to-right Hidden Markov Model\n(HMM) for training. A one-to-one mapping between gestures and shapes is\nproposed. Finally, shapes corresponding to these gestures are rendered over the\ndisplay using MuPad interface. We have created a dataset of 5400 samples\nrecorded by 10 volunteers. Our dataset contains 18 geometric and 18\nnon-geometric shapes such as \"circle\", \"rectangle\", \"flower\", \"cone\", \"sphere\"\netc. The proposed methodology achieves an accuracy of 92.87% when evaluated\nusing 5-fold cross validation method. Our experiments revel that the extended\n3D features perform better than existing 3D features in the context of shape\nrepresentation and classification. The method can be used for developing useful\nHCI applications for smart display devices.\n", "versions": [{"version": "v1", "created": "Mon, 22 Oct 2018 16:59:52 GMT"}], "update_date": "2019-04-05", "authors_parsed": [["Singla", "Abhik", ""], ["Roy", "Partha Pratim", ""], ["Dogra", "Debi Prosad", ""]]}, {"id": "1810.10593", "submitter": "Adam Gleave", "authors": "Aaron Tucker and Adam Gleave and Stuart Russell", "title": "Inverse reinforcement learning for video games", "comments": "10 pages, 4 figures. Submitted to NIPS Deep RL Workshop", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep reinforcement learning achieves superhuman performance in a range of\nvideo game environments, but requires that a designer manually specify a reward\nfunction. It is often easier to provide demonstrations of a target behavior\nthan to design a reward function describing that behavior. Inverse\nreinforcement learning (IRL) algorithms can infer a reward from demonstrations\nin low-dimensional continuous control environments, but there has been little\nwork on applying IRL to high-dimensional video games. In our CNN-AIRL baseline,\nwe modify the state-of-the-art adversarial IRL (AIRL) algorithm to use CNNs for\nthe generator and discriminator. To stabilize training, we normalize the reward\nand increase the size of the discriminator training dataset. We additionally\nlearn a low-dimensional state representation using a novel autoencoder\narchitecture tuned for video game environments. This embedding is used as input\nto the reward network, improving the sample efficiency of expert\ndemonstrations. Our method achieves high-level performance on the simple\nCatcher video game, substantially outperforming the CNN-AIRL baseline. We also\nscore points on the Enduro Atari racing game, but do not match expert\nperformance, highlighting the need for further work.\n", "versions": [{"version": "v1", "created": "Wed, 24 Oct 2018 20:00:50 GMT"}], "update_date": "2018-10-26", "authors_parsed": [["Tucker", "Aaron", ""], ["Gleave", "Adam", ""], ["Russell", "Stuart", ""]]}, {"id": "1810.10602", "submitter": "Giovanni Catania", "authors": "Alfredo Braunstein, Giovanni Catania, Luca Dall'Asta", "title": "Loop corrections in spin models through density consistency", "comments": "12 pages, 3 figures, 1 table", "journal-ref": "Phys. Rev. Lett. 123, 020604 (2019)", "doi": "10.1103/PhysRevLett.123.020604", "report-no": null, "categories": "cond-mat.stat-mech cond-mat.dis-nn cs.LG physics.comp-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Computing marginal distributions of discrete or semidiscrete Markov random\nfields (MRFs) is a fundamental, generally intractable problem with a vast\nnumber of applications in virtually all fields of science. We present a new\nfamily of computational schemes to approximately calculate the marginals of\ndiscrete MRFs. This method shares some desirable properties with belief\npropagation, in particular, providing exact marginals on acyclic graphs, but it\ndiffers with the latter in that it includes some loop corrections; i.e., it\ntakes into account correlations coming from all cycles in the factor graph. It\nis also similar to the adaptive Thouless-Anderson-Palmer method, but it differs\nwith the latter in that the consistency is not on the first two moments of the\ndistribution but rather on the value of its density on a subset of values. The\nresults on finite-dimensional Isinglike models show a significant improvement\nwith respect to the Bethe-Peierls (tree) approximation in all cases and with\nrespect to the plaquette cluster variational method approximation in many\ncases. In particular, for the critical inverse temperature $\\beta_{c}$ of the\nhomogeneous hypercubic lattice, the expansion of $\\left(d\\beta_{c}\\right)^{-1}$\naround $d=\\infty$ of the proposed scheme is exact up to the $d^{-4}$ order,\nwhereas the two latter are exact only up to the $d^{-2}$ order.\n", "versions": [{"version": "v1", "created": "Wed, 24 Oct 2018 20:17:43 GMT"}, {"version": "v2", "created": "Mon, 10 Dec 2018 16:46:17 GMT"}, {"version": "v3", "created": "Tue, 7 May 2019 14:57:20 GMT"}, {"version": "v4", "created": "Tue, 23 Jul 2019 13:29:53 GMT"}], "update_date": "2019-07-24", "authors_parsed": [["Braunstein", "Alfredo", ""], ["Catania", "Giovanni", ""], ["Dall'Asta", "Luca", ""]]}, {"id": "1810.10612", "submitter": "Frantzeska Lavda", "authors": "Frantzeska Lavda, Jason Ramapuram, Magda Gregorova, Alexandros\n  Kalousis", "title": "Continual Classification Learning Using Generative Models", "comments": "5 pages, 4 figures, under review in Continual learning Workshop NIPS\n  2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Continual learning is the ability to sequentially learn over time by\naccommodating knowledge while retaining previously learned experiences. Neural\nnetworks can learn multiple tasks when trained on them jointly, but cannot\nmaintain performance on previously learned tasks when tasks are presented one\nat a time. This problem is called catastrophic forgetting. In this work, we\npropose a classification model that learns continuously from sequentially\nobserved tasks, while preventing catastrophic forgetting. We build on the\nlifelong generative capabilities of [10] and extend it to the classification\nsetting by deriving a new variational bound on the joint log likelihood, $\\log\np(x; y)$.\n", "versions": [{"version": "v1", "created": "Wed, 24 Oct 2018 20:41:13 GMT"}], "update_date": "2018-10-26", "authors_parsed": [["Lavda", "Frantzeska", ""], ["Ramapuram", "Jason", ""], ["Gregorova", "Magda", ""], ["Kalousis", "Alexandros", ""]]}, {"id": "1810.10625", "submitter": "Soorya Gopalakrishnan", "authors": "Soorya Gopalakrishnan, Zhinus Marzi, Metehan Cekic, Upamanyu Madhow,\n  Ramtin Pedarsani", "title": "Robust Adversarial Learning via Sparsifying Front Ends", "comments": "16 pages, 12 figures, 6 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.IT cs.LG math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  It is by now well-known that small adversarial perturbations can induce\nclassification errors in deep neural networks. In this paper, we take a\nbottom-up signal processing perspective to this problem and show that a\nsystematic exploitation of sparsity in natural data is a promising tool for\ndefense. For linear classifiers, we show that a sparsifying front end is\nprovably effective against $\\ell_{\\infty}$-bounded attacks, reducing output\ndistortion due to the attack by a factor of roughly $K/N$ where $N$ is the data\ndimension and $K$ is the sparsity level. We then extend this concept to deep\nnetworks, showing that a \"locally linear\" model can be used to develop a\ntheoretical foundation for crafting attacks and defenses. We also devise\nattacks based on the locally linear model that outperform the well-known FGSM\nattack. We supplement our theoretical results with experiments on the MNIST and\nCIFAR-10 datasets, showing the efficacy of the proposed sparsity-based defense\nschemes.\n", "versions": [{"version": "v1", "created": "Wed, 24 Oct 2018 21:17:23 GMT"}, {"version": "v2", "created": "Fri, 22 Mar 2019 18:14:10 GMT"}, {"version": "v3", "created": "Tue, 25 May 2021 07:00:56 GMT"}], "update_date": "2021-05-26", "authors_parsed": [["Gopalakrishnan", "Soorya", ""], ["Marzi", "Zhinus", ""], ["Cekic", "Metehan", ""], ["Madhow", "Upamanyu", ""], ["Pedarsani", "Ramtin", ""]]}, {"id": "1810.10627", "submitter": "Yao Ma", "authors": "Yao Ma, Ziyi Guo, Zhaochun Ren, Eric Zhao, Jiliang Tang and Dawei Yin", "title": "Streaming Graph Neural Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Graphs are essential representations of many real-world data such as social\nnetworks. Recent years have witnessed the increasing efforts made to extend the\nneural network models to graph-structured data. These methods, which are\nusually known as the graph neural networks, have been applied to advance many\ngraphs related tasks such as reasoning dynamics of the physical system, graph\nclassification, and node classification. Most of the existing graph neural\nnetwork models have been designed for static graphs, while many real-world\ngraphs are inherently dynamic. For example, social networks are naturally\nevolving as new users joining and new relations being created. Current graph\nneural network models cannot utilize the dynamic information in dynamic graphs.\nHowever, the dynamic information has been proven to enhance the performance of\nmany graph analytic tasks such as community detection and link prediction.\nHence, it is necessary to design dedicated graph neural networks for dynamic\ngraphs. In this paper, we propose DGNN, a new {\\bf D}ynamic {\\bf G}raph {\\bf\nN}eural {\\bf N}etwork model, which can model the dynamic information as the\ngraph evolving. In particular, the proposed framework can keep updating node\ninformation by capturing the sequential information of edges (interactions),\nthe time intervals between edges and information propagation coherently.\nExperimental results on various dynamic graphs demonstrate the effectiveness of\nthe proposed framework.\n", "versions": [{"version": "v1", "created": "Wed, 24 Oct 2018 21:20:05 GMT"}, {"version": "v2", "created": "Tue, 6 Nov 2018 07:22:16 GMT"}], "update_date": "2018-11-07", "authors_parsed": [["Ma", "Yao", ""], ["Guo", "Ziyi", ""], ["Ren", "Zhaochun", ""], ["Zhao", "Eric", ""], ["Tang", "Jiliang", ""], ["Yin", "Dawei", ""]]}, {"id": "1810.10637", "submitter": "Ruihao Zhu", "authors": "Ruihao Zhu, Eytan Modiano", "title": "Learning to Route Efficiently with End-to-End Feedback: The Value of\n  Networked Structure", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce efficient algorithms which achieve nearly optimal regrets for\nthe problem of stochastic online shortest path routing with end-to-end\nfeedback. The setting is a natural application of the combinatorial stochastic\nbandits problem, a special case of the linear stochastic bandits problem. We\nshow how the difficulties posed by the large scale action set can be overcome\nby the networked structure of the action set. Our approach presents a novel\nconnection between bandit learning and shortest path algorithms. Our main\ncontribution is an adaptive exploration algorithm with nearly optimal\ninstance-dependent regret for any directed acyclic network. We then modify it\nso that nearly optimal worst case regret is achieved simultaneously. Driven by\nthe carefully designed Top-Two Comparison (TTC) technique, the algorithms are\nefficiently implementable. We further conduct extensive numerical experiments\nto show that our proposed algorithms not only achieve superior regret\nperformances, but also reduce the runtime drastically.\n", "versions": [{"version": "v1", "created": "Wed, 24 Oct 2018 21:47:19 GMT"}, {"version": "v2", "created": "Wed, 19 Dec 2018 02:19:20 GMT"}], "update_date": "2018-12-20", "authors_parsed": [["Zhu", "Ruihao", ""], ["Modiano", "Eytan", ""]]}, {"id": "1810.10654", "submitter": "Lerrel Pinto Mr", "authors": "Lerrel Pinto, Aditya Mandalika, Brian Hou, Siddhartha Srinivasa", "title": "Sample-Efficient Learning of Nonprehensile Manipulation Policies via\n  Physics-Based Informed State Distributions", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper proposes a sample-efficient yet simple approach to learning\nclosed-loop policies for nonprehensile manipulation. Although reinforcement\nlearning (RL) can learn closed-loop policies without requiring access to\nunderlying physics models, it suffers from poor sample complexity on\nchallenging tasks. To overcome this problem, we leverage rearrangement planning\nto provide an informative physics-based prior on the environment's optimal\nstate-visitation distribution. Specifically, we present a new technique,\nLearning with Planned Episodic Resets (LeaPER), that resets the environment's\nstate to one informed by the prior during the learning phase. We experimentally\nshow that LeaPER significantly outperforms traditional RL approaches by a\nfactor of up to 5X on simulated rearrangement. Further, we relax dynamics from\nquasi-static to welded contacts to illustrate that LeaPER is robust to the use\nof simpler physics models. Finally, LeaPER's closed-loop policies significantly\nimprove task success rates relative to both open-loop controls with a planned\npath or simple feedback controllers that track open-loop trajectories. We\ndemonstrate the performance and behavior of LeaPER on a physical 7-DOF\nmanipulator in https://youtu.be/feS-zFq6J1c.\n", "versions": [{"version": "v1", "created": "Wed, 24 Oct 2018 23:49:58 GMT"}], "update_date": "2018-10-26", "authors_parsed": [["Pinto", "Lerrel", ""], ["Mandalika", "Aditya", ""], ["Hou", "Brian", ""], ["Srinivasa", "Siddhartha", ""]]}, {"id": "1810.10659", "submitter": "Zhuwen Li", "authors": "Zhuwen Li, Qifeng Chen and Vladlen Koltun", "title": "Combinatorial Optimization with Graph Convolutional Networks and Guided\n  Tree Search", "comments": "To appear in NIPS 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a learning-based approach to computing solutions for certain\nNP-hard problems. Our approach combines deep learning techniques with useful\nalgorithmic elements from classic heuristics. The central component is a graph\nconvolutional network that is trained to estimate the likelihood, for each\nvertex in a graph, of whether this vertex is part of the optimal solution. The\nnetwork is designed and trained to synthesize a diverse set of solutions, which\nenables rapid exploration of the solution space via tree search. The presented\napproach is evaluated on four canonical NP-hard problems and five datasets,\nwhich include benchmark satisfiability problems and real social network graphs\nwith up to a hundred thousand nodes. Experimental results demonstrate that the\npresented approach substantially outperforms recent deep learning work, and\nperforms on par with highly optimized state-of-the-art heuristic solvers for\nsome NP-hard problems. Experiments indicate that our approach generalizes\nacross datasets, and scales to graphs that are orders of magnitude larger than\nthose used during training.\n", "versions": [{"version": "v1", "created": "Thu, 25 Oct 2018 00:12:44 GMT"}], "update_date": "2018-10-26", "authors_parsed": [["Li", "Zhuwen", ""], ["Chen", "Qifeng", ""], ["Koltun", "Vladlen", ""]]}, {"id": "1810.10664", "submitter": "Pratik Shah", "authors": "Gregory Yauney, Aman Rana, Lawrence C. Wong, Perikumar Javia, Ali\n  Muftu and Pratik Shah", "title": "Automated Process Incorporating Machine Learning Segmentation and\n  Correlation of Oral Diseases with Systemic Health", "comments": "Submitted to IEEE Journal of Biomedical and Health Informatics, 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG q-bio.QM stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Imaging fluorescent disease biomarkers in tissues and skin is a non-invasive\nmethod to screen for health conditions. We report an automated process that\ncombines intraoral fluorescent porphyrin biomarker imaging, clinical\nexaminations and machine learning for correlation of systemic health conditions\nwith periodontal disease. 1215 intraoral fluorescent images, from 284\nconsenting adults aged 18-90, were analyzed using a machine learning classifier\nthat can segment periodontal inflammation. The classifier achieved an AUC of\n0.677 with precision and recall of 0.271 and 0.429, respectively, indicating a\nlearned association between disease signatures in collected images. Periodontal\ndiseases were more prevalent among males (p=0.0012) and older subjects\n(p=0.0224) in the screened population. Physicians independently examined the\ncollected images, assigning localized modified gingival indices (MGIs). MGIs\nand periodontal disease were then cross-correlated with responses to a medical\nhistory questionnaire, blood pressure and body mass index measurements, and\noptic nerve, tympanic membrane, neurological, and cardiac rhythm imaging\nexaminations. Gingivitis and early periodontal disease were associated with\nsubjects diagnosed with optic nerve abnormalities (p <0.0001) in their retinal\nscans. We also report significant co-occurrences of periodontal disease in\nsubjects reporting swollen joints (p=0.0422) and a family history of eye\ndisease (p=0.0337). These results indicate cross-correlation of poor\nperiodontal health with systemic health outcomes and stress the importance of\noral health screenings at the primary care level. Our screening process and\nanalysis method, using images and machine learning, can be generalized for\nautomated diagnoses and systemic health screenings for other diseases.\n", "versions": [{"version": "v1", "created": "Thu, 25 Oct 2018 00:42:20 GMT"}], "update_date": "2018-10-26", "authors_parsed": [["Yauney", "Gregory", ""], ["Rana", "Aman", ""], ["Wong", "Lawrence C.", ""], ["Javia", "Perikumar", ""], ["Muftu", "Ali", ""], ["Shah", "Pratik", ""]]}, {"id": "1810.10667", "submitter": "Amirreza Shaban", "authors": "Amirreza Shaban, Ching-An Cheng, Nathan Hatch, Byron Boots", "title": "Truncated Back-propagation for Bilevel Optimization", "comments": null, "journal-ref": "The International Conference on Artificial Intelligence and\n  Statistics (AISTATS) 2019", "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Bilevel optimization has been recently revisited for designing and analyzing\nalgorithms in hyperparameter tuning and meta learning tasks. However, due to\nits nested structure, evaluating exact gradients for high-dimensional problems\nis computationally challenging. One heuristic to circumvent this difficulty is\nto use the approximate gradient given by performing truncated back-propagation\nthrough the iterative optimization procedure that solves the lower-level\nproblem. Although promising empirical performance has been reported, its\ntheoretical properties are still unclear. In this paper, we analyze the\nproperties of this family of approximate gradients and establish sufficient\nconditions for convergence. We validate this on several hyperparameter tuning\nand meta learning tasks. We find that optimization with the approximate\ngradient computed using few-step back-propagation often performs comparably to\noptimization with the exact gradient, while requiring far less memory and half\nthe computation time.\n", "versions": [{"version": "v1", "created": "Thu, 25 Oct 2018 00:49:36 GMT"}, {"version": "v2", "created": "Fri, 5 Apr 2019 19:49:06 GMT"}], "update_date": "2019-04-09", "authors_parsed": [["Shaban", "Amirreza", ""], ["Cheng", "Ching-An", ""], ["Hatch", "Nathan", ""], ["Boots", "Byron", ""]]}, {"id": "1810.10690", "submitter": "Zhe Wang", "authors": "Zhe Wang, Kaiyi Ji, Yi Zhou, Yingbin Liang, Vahid Tarokh", "title": "SpiderBoost and Momentum: Faster Stochastic Variance Reduction\n  Algorithms", "comments": "Appear in NeurIPS 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.OC cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  SARAH and SPIDER are two recently developed stochastic variance-reduced\nalgorithms, and SPIDER has been shown to achieve a near-optimal first-order\noracle complexity in smooth nonconvex optimization. However, SPIDER uses an\naccuracy-dependent stepsize that slows down the convergence in practice, and\ncannot handle objective functions that involve nonsmooth regularizers. In this\npaper, we propose SpiderBoost as an improved scheme, which allows to use a much\nlarger constant-level stepsize while maintaining the same near-optimal oracle\ncomplexity, and can be extended with proximal mapping to handle composite\noptimization (which is nonsmooth and nonconvex) with provable convergence\nguarantee. In particular, we show that proximal SpiderBoost achieves an oracle\ncomplexity of $\\mathcal{O}(\\min\\{n^{1/2}\\epsilon^{-2},\\epsilon^{-3}\\})$ in\ncomposite nonconvex optimization, improving the state-of-the-art result by a\nfactor of $\\mathcal{O}(\\min\\{n^{1/6},\\epsilon^{-1/3}\\})$. We further develop a\nnovel momentum scheme to accelerate SpiderBoost for composite optimization,\nwhich achieves the near-optimal oracle complexity in theory and substantial\nimprovement in experiments.\n", "versions": [{"version": "v1", "created": "Thu, 25 Oct 2018 02:18:03 GMT"}, {"version": "v2", "created": "Tue, 27 Nov 2018 02:38:05 GMT"}, {"version": "v3", "created": "Fri, 15 May 2020 19:12:01 GMT"}], "update_date": "2020-05-19", "authors_parsed": [["Wang", "Zhe", ""], ["Ji", "Kaiyi", ""], ["Zhou", "Yi", ""], ["Liang", "Yingbin", ""], ["Tarokh", "Vahid", ""]]}, {"id": "1810.10695", "submitter": "Xiuyuan Cheng", "authors": "Xiuyuan Cheng, Gal Mishne", "title": "Spectral Embedding Norm: Looking Deep into the Spectrum of the Graph\n  Laplacian", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG math.SP stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The extraction of clusters from a dataset which includes multiple clusters\nand a significant background component is a non-trivial task of practical\nimportance. In image analysis this manifests for example in anomaly detection\nand target detection. The traditional spectral clustering algorithm, which\nrelies on the leading $K$ eigenvectors to detect $K$ clusters, fails in such\ncases. In this paper we propose the {\\it spectral embedding norm} which sums\nthe squared values of the first $I$ normalized eigenvectors, where $I$ can be\nsignificantly larger than $K$. We prove that this quantity can be used to\nseparate clusters from the background in unbalanced settings, including extreme\ncases such as outlier detection. The performance of the algorithm is not\nsensitive to the choice of $I$, and we demonstrate its application on synthetic\nand real-world remote sensing and neuroimaging datasets.\n", "versions": [{"version": "v1", "created": "Thu, 25 Oct 2018 02:51:54 GMT"}, {"version": "v2", "created": "Thu, 22 Aug 2019 19:38:40 GMT"}], "update_date": "2019-08-26", "authors_parsed": [["Cheng", "Xiuyuan", ""], ["Mishne", "Gal", ""]]}, {"id": "1810.10702", "submitter": "Yu Bai", "authors": "Yu Bai, Qijia Jiang, Ju Sun", "title": "Subgradient Descent Learns Orthogonal Dictionaries", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.IT math.IT math.OC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper concerns dictionary learning, i.e., sparse coding, a fundamental\nrepresentation learning problem. We show that a subgradient descent algorithm,\nwith random initialization, can provably recover orthogonal dictionaries on a\nnatural nonsmooth, nonconvex $\\ell_1$ minimization formulation of the problem,\nunder mild statistical assumptions on the data. This is in contrast to previous\nprovable methods that require either expensive computation or delicate\ninitialization schemes. Our analysis develops several tools for characterizing\nlandscapes of nonsmooth functions, which might be of independent interest for\nprovable training of deep networks with nonsmooth activations (e.g., ReLU),\namong numerous other applications. Preliminary experiments corroborate our\nanalysis and show that our algorithm works well empirically in recovering\northogonal dictionaries.\n", "versions": [{"version": "v1", "created": "Thu, 25 Oct 2018 03:07:58 GMT"}, {"version": "v2", "created": "Mon, 1 Jul 2019 05:26:18 GMT"}], "update_date": "2019-07-02", "authors_parsed": [["Bai", "Yu", ""], ["Jiang", "Qijia", ""], ["Sun", "Ju", ""]]}, {"id": "1810.10703", "submitter": "Pramod Kaushik Mudrakarta", "authors": "Pramod Kaushik Mudrakarta, Mark Sandler, Andrey Zhmoginov, Andrew\n  Howard", "title": "K for the Price of 1: Parameter-efficient Multi-task and Transfer\n  Learning", "comments": "published at ICLR 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce a novel method that enables parameter-efficient transfer and\nmulti-task learning with deep neural networks. The basic approach is to learn a\nmodel patch - a small set of parameters - that will specialize to each task,\ninstead of fine-tuning the last layer or the entire network. For instance, we\nshow that learning a set of scales and biases is sufficient to convert a\npretrained network to perform well on qualitatively different problems (e.g.\nconverting a Single Shot MultiBox Detection (SSD) model into a 1000-class image\nclassification model while reusing 98% of parameters of the SSD feature\nextractor). Similarly, we show that re-learning existing low-parameter layers\n(such as depth-wise convolutions) while keeping the rest of the network frozen\nalso improves transfer-learning accuracy significantly. Our approach allows\nboth simultaneous (multi-task) as well as sequential transfer learning. In\nseveral multi-task learning problems, despite using much fewer parameters than\ntraditional logits-only fine-tuning, we match single-task performance.\n", "versions": [{"version": "v1", "created": "Thu, 25 Oct 2018 03:12:37 GMT"}, {"version": "v2", "created": "Sun, 24 Feb 2019 02:03:00 GMT"}], "update_date": "2019-02-26", "authors_parsed": [["Mudrakarta", "Pramod Kaushik", ""], ["Sandler", "Mark", ""], ["Zhmoginov", "Andrey", ""], ["Howard", "Andrew", ""]]}, {"id": "1810.10708", "submitter": "Bo-Jian Hou", "authors": "Bo-Jian Hou and Zhi-Hua Zhou", "title": "Learning with Interpretable Structure from Gated RNN", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The interpretability of deep learning models has raised extended attention\nthese years. It will be beneficial if we can learn an interpretable structure\nfrom deep learning models. In this paper, we focus on Recurrent Neural\nNetworks~(RNNs) especially gated RNNs whose inner mechanism is still not\nclearly understood. We find that Finite State Automaton~(FSA) that processes\nsequential data has more interpretable inner mechanism according to the\ndefinition of interpretability and can be learned from RNNs as the\ninterpretable structure. We propose two methods to learn FSA from RNN based on\ntwo different clustering methods. With the learned FSA and via experiments on\nartificial and real datasets, we find that FSA is more trustable than the RNN\nfrom which it learned, which gives FSA a chance to substitute RNNs in\napplications involving humans' lives or dangerous facilities. Besides, we\nanalyze how the number of gates affects the performance of RNN. Our result\nsuggests that gate in RNN is important but the less the better, which could be\na guidance to design other RNNs. Finally, we observe that the FSA learned from\nRNN gives semantic aggregated states and its transition graph shows us a very\ninteresting vision of how RNNs intrinsically handle text classification tasks.\n", "versions": [{"version": "v1", "created": "Thu, 25 Oct 2018 03:42:08 GMT"}, {"version": "v2", "created": "Tue, 14 Jan 2020 12:07:02 GMT"}], "update_date": "2020-01-15", "authors_parsed": [["Hou", "Bo-Jian", ""], ["Zhou", "Zhi-Hua", ""]]}, {"id": "1810.10727", "submitter": "Yusuke Kida", "authors": "Yusuke Kida, Dung Tran, Motoi Omachi, Toru Taniguchi, Yuya Fujita", "title": "Speaker Selective Beamformer with Keyword Mask Estimation", "comments": "Accepted by SLT2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.AS cs.LG cs.SD", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper addresses the problem of automatic speech recognition (ASR) of a\ntarget speaker in background speech. The novelty of our approach is that we\nfocus on a wakeup keyword, which is usually used for activating ASR systems\nlike smart speakers. The proposed method firstly utilizes a DNN-based mask\nestimator to separate the mixture signal into the keyword signal uttered by the\ntarget speaker and the remaining background speech. Then the separated signals\nare used for calculating a beamforming filter to enhance the subsequent\nutterances from the target speaker. Experimental evaluations show that the\ntrained DNN-based mask can selectively separate the keyword and background\nspeech from the mixture signal. The effectiveness of the proposed method is\nalso verified with Japanese ASR experiments, and we confirm that the character\nerror rates are significantly improved by the proposed method for both\nsimulated and real recorded test sets.\n", "versions": [{"version": "v1", "created": "Thu, 25 Oct 2018 05:45:06 GMT"}, {"version": "v2", "created": "Wed, 7 Nov 2018 09:07:26 GMT"}], "update_date": "2018-11-08", "authors_parsed": [["Kida", "Yusuke", ""], ["Tran", "Dung", ""], ["Omachi", "Motoi", ""], ["Taniguchi", "Toru", ""], ["Fujita", "Yuya", ""]]}, {"id": "1810.10731", "submitter": "Ram Shankar Siva Kumar", "authors": "Ram Shankar Siva Kumar, David R. O'Brien, Kendra Albert, Salome\n  Vilojen", "title": "Law and Adversarial Machine Learning", "comments": "Minor edits. Corrected typos, Added references. 4 pages, submitted to\n  NIPS 2018 Workshop on Security in Machine Learning", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR cs.CY stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  When machine learning systems fail because of adversarial manipulation, how\nshould society expect the law to respond? Through scenarios grounded in\nadversarial ML literature, we explore how some aspects of computer crime,\ncopyright, and tort law interface with perturbation, poisoning, model stealing\nand model inversion attacks to show how some attacks are more likely to result\nin liability than others. We end with a call for action to ML researchers to\ninvest in transparent benchmarks of attacks and defenses; architect ML systems\nwith forensics in mind and finally, think more about adversarial machine\nlearning in the context of civil liberties. The paper is targeted towards ML\nresearchers who have no legal background.\n", "versions": [{"version": "v1", "created": "Thu, 25 Oct 2018 06:17:34 GMT"}, {"version": "v2", "created": "Fri, 26 Oct 2018 02:45:10 GMT"}, {"version": "v3", "created": "Wed, 5 Dec 2018 02:02:46 GMT"}], "update_date": "2018-12-06", "authors_parsed": [["Kumar", "Ram Shankar Siva", ""], ["O'Brien", "David R.", ""], ["Albert", "Kendra", ""], ["Vilojen", "Salome", ""]]}, {"id": "1810.10751", "submitter": "Xiaoyun Wang", "authors": "Xiaoyun Wang, Minhao Cheng, Joe Eaton, Cho-Jui Hsieh, Felix Wu", "title": "Attack Graph Convolutional Networks by Adding Fake Nodes", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR cs.SI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we study the robustness of graph convolutional networks\n(GCNs). Previous work have shown that GCNs are vulnerable to adversarial\nperturbation on adjacency or feature matrices of existing nodes; however, such\nattacks are usually unrealistic in real applications. For instance, in social\nnetwork applications, the attacker will need to hack into either the client or\nserver to change existing links or features. In this paper, we propose a new\ntype of \"fake node attacks\" to attack GCNs by adding malicious fake nodes. This\nis much more realistic than previous attacks; in social network applications,\nthe attacker only needs to register a set of fake accounts and link to existing\nones. To conduct fake node attacks, a greedy algorithm is proposed to generate\nedges of malicious nodes and their corresponding features aiming to minimize\nthe classification accuracy on the target nodes. In addition, we introduce a\ndiscriminator to classify malicious nodes from real nodes, and propose a\nGreedy-GAN attack to simultaneously update the discriminator and the attacker,\nto make malicious nodes indistinguishable from the real ones. Our non-targeted\nattack decreases the accuracy of GCN down to 0.03, and our targeted attack\nreaches a success rate of 78% on a group of 100 nodes, and 90% on average for\nattacking a single target node.\n", "versions": [{"version": "v1", "created": "Thu, 25 Oct 2018 07:49:09 GMT"}, {"version": "v2", "created": "Fri, 26 Oct 2018 06:59:12 GMT"}, {"version": "v3", "created": "Mon, 11 Nov 2019 17:16:47 GMT"}, {"version": "v4", "created": "Thu, 3 Sep 2020 20:31:16 GMT"}], "update_date": "2020-09-07", "authors_parsed": [["Wang", "Xiaoyun", ""], ["Cheng", "Minhao", ""], ["Eaton", "Joe", ""], ["Hsieh", "Cho-Jui", ""], ["Wu", "Felix", ""]]}, {"id": "1810.10770", "submitter": "Frank Nielsen", "authors": "Erika Gomes-Gon\\c{c}alves, Henryk Gzyl and Frank Nielsen", "title": "Geometry and clustering with metrics derived from separable Bregman\n  divergences", "comments": "23 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Separable Bregman divergences induce Riemannian metric spaces that are\nisometric to the Euclidean space after monotone embeddings. We investigate\nfixed rate quantization and its codebook Voronoi diagrams, and report on\nexperimental performances of partition-based, hierarchical, and soft clustering\nalgorithms with respect to these Riemann-Bregman distances.\n", "versions": [{"version": "v1", "created": "Thu, 25 Oct 2018 08:41:24 GMT"}], "update_date": "2018-10-26", "authors_parsed": [["Gomes-Gon\u00e7alves", "Erika", ""], ["Gzyl", "Henryk", ""], ["Nielsen", "Frank", ""]]}, {"id": "1810.10775", "submitter": "Ilija Bogunovic", "authors": "Ilija Bogunovic and Jonathan Scarlett and Stefanie Jegelka and Volkan\n  Cevher", "title": "Adversarially Robust Optimization with Gaussian Processes", "comments": "Corrected typos", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we consider the problem of Gaussian process (GP) optimization\nwith an added robustness requirement: The returned point may be perturbed by an\nadversary, and we require the function value to remain as high as possible even\nafter this perturbation. This problem is motivated by settings in which the\nunderlying functions during optimization and implementation stages are\ndifferent, or when one is interested in finding an entire region of good inputs\nrather than only a single point. We show that standard GP optimization\nalgorithms do not exhibit the desired robustness properties, and provide a\nnovel confidence-bound based algorithm StableOpt for this purpose. We\nrigorously establish the required number of samples for StableOpt to find a\nnear-optimal point, and we complement this guarantee with an\nalgorithm-independent lower bound. We experimentally demonstrate several\npotential applications of interest using real-world data sets, and we show that\nStableOpt consistently succeeds in finding a stable maximizer where several\nbaseline methods fail.\n", "versions": [{"version": "v1", "created": "Thu, 25 Oct 2018 08:47:46 GMT"}, {"version": "v2", "created": "Thu, 1 Nov 2018 20:37:11 GMT"}], "update_date": "2018-11-05", "authors_parsed": [["Bogunovic", "Ilija", ""], ["Scarlett", "Jonathan", ""], ["Jegelka", "Stefanie", ""], ["Cevher", "Volkan", ""]]}, {"id": "1810.10777", "submitter": "Vidyadhar Upadhya", "authors": "Vidyadhar Upadhya, P.S. Sastry", "title": "Efficient Learning of Restricted Boltzmann Machines Using Covariance\n  Estimates", "comments": "Proceedings of Asian Conference on Machine Learning 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Learning RBMs using standard algorithms such as CD(k) involves gradient\ndescent on the negative log-likelihood. One of the terms in the gradient, which\ninvolves expectation w.r.t. the model distribution, is intractable and is\nobtained through an MCMC estimate. In this work we show that the Hessian of the\nlog-likelihood can be written in terms of covariances of hidden and visible\nunits and hence, all elements of the Hessian can also be estimated using the\nsame MCMC samples with small extra computational costs. Since inverting the\nHessian may be computationally expensive, we propose an algorithm that uses\ninverse of the diagonal approximation of the Hessian, instead. This essentially\nresults in parameter-specific adaptive learning rates for the gradient descent\nprocess and improves the efficiency of learning RBMs compared to the standard\nmethods. Specifically we show that using the inverse of diagonal approximation\nof Hessian in the stochastic DC (difference of convex functions) program\napproach results in very efficient learning of RBMs.\n", "versions": [{"version": "v1", "created": "Thu, 25 Oct 2018 08:51:19 GMT"}, {"version": "v2", "created": "Tue, 1 Oct 2019 04:58:01 GMT"}], "update_date": "2019-10-02", "authors_parsed": [["Upadhya", "Vidyadhar", ""], ["Sastry", "P. S.", ""]]}, {"id": "1810.10798", "submitter": "Anastasia Borovykh", "authors": "Anastasia Borovykh", "title": "A Gaussian Process perspective on Convolutional Neural Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we cast the well-known convolutional neural network in a\nGaussian process perspective. In this way we hope to gain additional insights\ninto the performance of convolutional networks, in particular understand under\nwhat circumstances they tend to perform well and what assumptions are\nimplicitly made in the network. While for fully-connected networks the\nproperties of convergence to Gaussian processes have been studied extensively,\nlittle is known about situations in which the output from a convolutional\nnetwork approaches a multivariate normal distribution.\n", "versions": [{"version": "v1", "created": "Thu, 25 Oct 2018 09:18:20 GMT"}, {"version": "v2", "created": "Wed, 9 Jan 2019 15:29:23 GMT"}], "update_date": "2019-01-10", "authors_parsed": [["Borovykh", "Anastasia", ""]]}, {"id": "1810.10802", "submitter": "Lei Yu", "authors": "Lei Yu", "title": "Tackling Sequence to Sequence Mapping Problems with Neural Networks", "comments": "PhD thesis", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In Natural Language Processing (NLP), it is important to detect the\nrelationship between two sequences or to generate a sequence of tokens given\nanother observed sequence. We call the type of problems on modelling sequence\npairs as sequence to sequence (seq2seq) mapping problems. A lot of research has\nbeen devoted to finding ways of tackling these problems, with traditional\napproaches relying on a combination of hand-crafted features, alignment models,\nsegmentation heuristics, and external linguistic resources. Although great\nprogress has been made, these traditional approaches suffer from various\ndrawbacks, such as complicated pipeline, laborious feature engineering, and the\ndifficulty for domain adaptation. Recently, neural networks emerged as a\npromising solution to many problems in NLP, speech recognition, and computer\nvision. Neural models are powerful because they can be trained end to end,\ngeneralise well to unseen examples, and the same framework can be easily\nadapted to a new domain.\n  The aim of this thesis is to advance the state-of-the-art in seq2seq mapping\nproblems with neural networks. We explore solutions from three major aspects:\ninvestigating neural models for representing sequences, modelling interactions\nbetween sequences, and using unpaired data to boost the performance of neural\nmodels. For each aspect, we propose novel models and evaluate their efficacy on\nvarious tasks of seq2seq mapping.\n", "versions": [{"version": "v1", "created": "Thu, 25 Oct 2018 09:24:13 GMT"}], "update_date": "2018-10-26", "authors_parsed": [["Yu", "Lei", ""]]}, {"id": "1810.10815", "submitter": "Lijun Zhang", "authors": "Lijun Zhang, Shiyin Lu, Zhi-Hua Zhou", "title": "Adaptive Online Learning in Dynamic Environments", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we study online convex optimization in dynamic environments,\nand aim to bound the dynamic regret with respect to any sequence of\ncomparators. Existing work have shown that online gradient descent enjoys an\n$O(\\sqrt{T}(1+P_T))$ dynamic regret, where $T$ is the number of iterations and\n$P_T$ is the path-length of the comparator sequence. However, this result is\nunsatisfactory, as there exists a large gap from the $\\Omega(\\sqrt{T(1+P_T)})$\nlower bound established in our paper. To address this limitation, we develop a\nnovel online method, namely adaptive learning for dynamic environment (Ader),\nwhich achieves an optimal $O(\\sqrt{T(1+P_T)})$ dynamic regret. The basic idea\nis to maintain a set of experts, each attaining an optimal dynamic regret for a\nspecific path-length, and combines them with an expert-tracking algorithm.\nFurthermore, we propose an improved Ader based on the surrogate loss, and in\nthis way the number of gradient evaluations per round is reduced from $O(\\log\nT)$ to $1$. Finally, we extend Ader to the setting that a sequence of dynamical\nmodels is available to characterize the comparators.\n", "versions": [{"version": "v1", "created": "Thu, 25 Oct 2018 10:13:04 GMT"}], "update_date": "2018-10-26", "authors_parsed": [["Zhang", "Lijun", ""], ["Lu", "Shiyin", ""], ["Zhou", "Zhi-Hua", ""]]}, {"id": "1810.10866", "submitter": "Yunsheng Bai", "authors": "Yunsheng Bai, Hao Ding, Yizhou Sun, Wei Wang", "title": "Convolutional Set Matching for Graph Similarity", "comments": "NIPS 2018 Workshop: Relational Representation Learning. Note:\n  Substantial text overlap with arXiv:1809.04440", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce GSimCNN (Graph Similarity Computation via Convolutional Neural\nNetworks) for predicting the similarity score between two graphs. As the core\noperation of graph similarity search, pairwise graph similarity computation is\na challenging problem due to the NP-hard nature of computing many graph\ndistance/similarity metrics. We demonstrate our model using the Graph Edit\nDistance (GED) as the example metric. Experiments on three real graph datasets\ndemonstrate that our model achieves the state-of-the-art performance on graph\nsimilarity search.\n", "versions": [{"version": "v1", "created": "Tue, 23 Oct 2018 19:22:48 GMT"}, {"version": "v2", "created": "Wed, 7 Nov 2018 22:33:48 GMT"}, {"version": "v3", "created": "Tue, 13 Nov 2018 17:04:14 GMT"}], "update_date": "2018-11-15", "authors_parsed": [["Bai", "Yunsheng", ""], ["Ding", "Hao", ""], ["Sun", "Yizhou", ""], ["Wang", "Wei", ""]]}, {"id": "1810.10889", "submitter": "Jason Deglint", "authors": "Jason L. Deglint, Chao Jin, Alexander Wong", "title": "Investigating the Automatic Classification of Algae Using Fusion of\n  Spectral and Morphological Characteristics of Algae via Deep Residual\n  Learning", "comments": "19 pages, 8 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG q-bio.QM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Under the impact of global climate changes and human activities, harmful\nalgae blooms in surface waters have become a growing concern due to negative\nimpacts on water related industries. Therefore, reliable and cost effective\nmethods of quantifying the type and concentration of threshold levels of algae\ncells has become critical for ensuring successful water management. In this\nwork, we present SAMSON, an innovative system to automatically classify\nmultiple types of algae from different phyla groups by combining standard\nmorphological features with their multi-wavelength signals. Two phyla with\nfocused investigation in this study are the Cyanophyta phylum (blue-green\nalgae), and the Chlorophyta phylum (green algae). We use a custom-designed\nmicroscopy imaging system which is configured to image water samples at two\nfluorescent wavelengths and seven absorption wavelengths using\ndiscrete-wavelength high-powered light emitting diodes (LEDs). Powered by\ncomputer vision and machine learning, we investigate the possibility and\neffectiveness of automatic classification using a deep residual convolutional\nneural network. More specifically, a classification accuracy of 96% was\nachieved in an experiment conducted with six different algae types. This high\nlevel of accuracy was achieved using a deep residual convolutional neural\nnetwork that learns the optimal combination of spectral and morphological\nfeatures. These findings elude to the possibility of leveraging a unique\nfingerprint of algae cell (i.e. spectral wavelengths and morphological\nfeatures) to automatically distinguish different algae types. Our work herein\ndemonstrates that, when coupled with multi-band fluorescence microscopy,\nmachine learning algorithms can potentially be used as a robust and\ncost-effective tool for identifying and enumerating algae cells.\n", "versions": [{"version": "v1", "created": "Thu, 25 Oct 2018 14:23:23 GMT"}], "update_date": "2018-10-26", "authors_parsed": [["Deglint", "Jason L.", ""], ["Jin", "Chao", ""], ["Wong", "Alexander", ""]]}, {"id": "1810.10895", "submitter": "Xiaotian Yu", "authors": "Han Shao, Xiaotian Yu, Irwin King and Michael R. Lyu", "title": "Almost Optimal Algorithms for Linear Stochastic Bandits with\n  Heavy-Tailed Payoffs", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In linear stochastic bandits, it is commonly assumed that payoffs are with\nsub-Gaussian noises. In this paper, under a weaker assumption on noises, we\nstudy the problem of \\underline{lin}ear stochastic {\\underline b}andits with\nh{\\underline e}avy-{\\underline t}ailed payoffs (LinBET), where the\ndistributions have finite moments of order $1+\\epsilon$, for some $\\epsilon\\in\n(0,1]$. We rigorously analyze the regret lower bound of LinBET as\n$\\Omega(T^{\\frac{1}{1+\\epsilon}})$, implying that finite moments of order 2\n(i.e., finite variances) yield the bound of $\\Omega(\\sqrt{T})$, with $T$ being\nthe total number of rounds to play bandits. The provided lower bound also\nindicates that the state-of-the-art algorithms for LinBET are far from optimal.\nBy adopting median of means with a well-designed allocation of decisions and\ntruncation based on historical information, we develop two novel bandit\nalgorithms, where the regret upper bounds match the lower bound up to\npolylogarithmic factors. To the best of our knowledge, we are the first to\nsolve LinBET optimally in the sense of the polynomial order on $T$. Our\nproposed algorithms are evaluated based on synthetic datasets, and outperform\nthe state-of-the-art results.\n", "versions": [{"version": "v1", "created": "Thu, 25 Oct 2018 14:29:02 GMT"}, {"version": "v2", "created": "Sun, 11 Nov 2018 13:47:50 GMT"}], "update_date": "2018-11-13", "authors_parsed": [["Shao", "Han", ""], ["Yu", "Xiaotian", ""], ["King", "Irwin", ""], ["Lyu", "Michael R.", ""]]}, {"id": "1810.10902", "submitter": "Loren Lugosch", "authors": "Loren Lugosch, Warren J. Gross", "title": "Learning from the Syndrome", "comments": "Accepted to Asilomar 2018 - special session on \"Machine Learning for\n  Wireless Systems\"", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IT cs.LG eess.SP math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we introduce the syndrome loss, an alternative loss function\nfor neural error-correcting decoders based on a relaxation of the syndrome. The\nsyndrome loss penalizes the decoder for producing outputs that do not\ncorrespond to valid codewords. We show that training with the syndrome loss\nyields decoders with consistently lower frame error rate for a number of short\nblock codes, at little additional cost during training and no additional cost\nduring inference. The proposed method does not depend on knowledge of the\ntransmitted codeword, making it a promising tool for online adaptation to\nchanging channel conditions.\n", "versions": [{"version": "v1", "created": "Tue, 23 Oct 2018 00:24:10 GMT"}], "update_date": "2018-10-26", "authors_parsed": [["Lugosch", "Loren", ""], ["Gross", "Warren J.", ""]]}, {"id": "1810.10927", "submitter": "Ekaterina Lobacheva Ms", "authors": "Nadezhda Chirkova, Ekaterina Lobacheva, Dmitry Vetrov", "title": "Bayesian Compression for Natural Language Processing", "comments": "Published in EMNLP 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In natural language processing, a lot of the tasks are successfully solved\nwith recurrent neural networks, but such models have a huge number of\nparameters. The majority of these parameters are often concentrated in the\nembedding layer, which size grows proportionally to the vocabulary length. We\npropose a Bayesian sparsification technique for RNNs which allows compressing\nthe RNN dozens or hundreds of times without time-consuming hyperparameters\ntuning. We also generalize the model for vocabulary sparsification to filter\nout unnecessary words and compress the RNN even further. We show that the\nchoice of the kept words is interpretable. Code is available on github:\nhttps://github.com/tipt0p/SparseBayesianRNN\n", "versions": [{"version": "v1", "created": "Thu, 25 Oct 2018 15:27:23 GMT"}, {"version": "v2", "created": "Wed, 12 Dec 2018 17:18:13 GMT"}], "update_date": "2018-12-13", "authors_parsed": [["Chirkova", "Nadezhda", ""], ["Lobacheva", "Ekaterina", ""], ["Vetrov", "Dmitry", ""]]}, {"id": "1810.10929", "submitter": "Han Jindong", "authors": "Mingtao Dong and Jindong Han", "title": "HAR-Net:Fusing Deep Representation and Hand-crafted Features for Human\n  Activity Recognition", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Wearable computing and context awareness are the focuses of study in the\nfield of artificial intelligence recently. One of the most appealing as well as\nchallenging applications is the Human Activity Recognition (HAR) utilizing\nsmart phones. Conventional HAR based on Support Vector Machine relies on\nsubjective manually extracted features. This approach is time and energy\nconsuming as well as immature in prediction due to the partial view toward\nwhich features to be extracted by human. With the rise of deep learning,\nartificial intelligence has been making progress toward being a mature\ntechnology. This paper proposes a new approach based on deep learning and\ntraditional feature engineering called HAR-Net to address the issue related to\nHAR. The study used the data collected by gyroscopes and acceleration sensors\nin android smart phones. The raw sensor data was put into the HAR-Net proposed.\nThe HAR-Net fusing the hand-crafted features and high-level features extracted\nfrom convolutional network to make prediction. The performance of the proposed\nmethod was proved to be 0.9% higher than the original MC-SVM approach. The\nexperimental results on the UCI dataset demonstrate that fusing the two kinds\nof features can make up for the shortage of traditional feature engineering and\ndeep learning techniques.\n", "versions": [{"version": "v1", "created": "Thu, 25 Oct 2018 15:30:07 GMT"}], "update_date": "2018-10-26", "authors_parsed": [["Dong", "Mingtao", ""], ["Han", "Jindong", ""]]}, {"id": "1810.10938", "submitter": "Han-Hsuan Lin", "authors": "Kai-Min Chung and Han-Hsuan Lin", "title": "Sample Efficient Algorithms for Learning Quantum Channels in PAC Model\n  and the Approximate State Discrimination Problem", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "quant-ph cs.CC cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We generalize the PAC (probably approximately correct) learning model to the\nquantum world by generalizing the concepts from classical functions to quantum\nprocesses, defining the problem of \\emph{PAC learning quantum process}, and\nstudy its sample complexity. In the problem of PAC learning quantum process, we\nwant to learn an $\\epsilon$-approximate of an unknown quantum process $c^*$\nfrom a known finite concept class $C$ with probability $1-\\delta$ using samples\n$\\{(x_1,c^*(x_1)),(x_2,c^*(x_2)),\\dots\\}$, where $\\{x_1,x_2, \\dots\\}$ are\ncomputational basis states sampled from an unknown distribution $D$ and\n$\\{c^*(x_1),c^*(x_2),\\dots\\}$ are the (possibly mixed) quantum states outputted\nby $c^*$. The special case of PAC-learning quantum process under constant input\nreduces to a natural problem which we named as approximate state\ndiscrimination, where we are given copies of an unknown quantum state $c^*$\nfrom an known finite set $C$, and we want to learn with probability $1-\\delta$\nan $\\epsilon$-approximate of $c^*$ with as few copies of $c^*$ as possible. We\nshow that the problem of PAC learning quantum process can be solved with\n$$O\\left(\\frac{\\log|C| + \\log(1/ \\delta)} { \\epsilon^2}\\right)$$ samples when\nthe outputs are pure states and $$O\\left(\\frac{\\log^3 |C|(\\log |C|+\\log(1/\n\\delta))} { \\epsilon^2}\\right)$$ samples if the outputs can be mixed. Some\nimplications of our results are that we can PAC-learn a polynomial sized\nquantum circuit in polynomial samples and approximate state discrimination can\nbe solved in polynomial samples even when concept class size $|C|$ is\nexponential in the number of qubits, an exponentially improvement over a full\nstate tomography.\n", "versions": [{"version": "v1", "created": "Thu, 25 Oct 2018 15:50:57 GMT"}, {"version": "v2", "created": "Sun, 3 Nov 2019 16:42:35 GMT"}, {"version": "v3", "created": "Wed, 19 May 2021 02:40:11 GMT"}], "update_date": "2021-05-20", "authors_parsed": [["Chung", "Kai-Min", ""], ["Lin", "Han-Hsuan", ""]]}, {"id": "1810.10939", "submitter": "Bogdan Kulynych", "authors": "Bogdan Kulynych, Jamie Hayes, Nikita Samarin, Carmela Troncoso", "title": "Evading classifiers in discrete domains with provable optimality\n  guarantees", "comments": "NeurIPS 2018 Workshop on Security in Machine Learning", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Machine-learning models for security-critical applications such as bot,\nmalware, or spam detection, operate in constrained discrete domains. These\napplications would benefit from having provable guarantees against adversarial\nexamples. The existing literature on provable adversarial robustness of models,\nhowever, exclusively focuses on robustness to gradient-based attacks in domains\nsuch as images. These attacks model the adversarial cost, e.g., amount of\ndistortion applied to an image, as a $p$-norm. We argue that this approach is\nnot well-suited to model adversarial costs in constrained domains where not all\nexamples are feasible.\n  We introduce a graphical framework that (1) generalizes existing attacks in\ndiscrete domains, (2) can accommodate complex cost functions beyond $p$-norms,\nincluding financial cost incurred when attacking a classifier, and (3)\nefficiently produces valid adversarial examples with guarantees of minimal\nadversarial cost. These guarantees directly translate into a notion of\nadversarial robustness that takes into account domain constraints and the\nadversary's capabilities. We show how our framework can be used to evaluate\nsecurity by crafting adversarial examples that evade a Twitter-bot detection\nclassifier with provably minimal number of changes; and to build privacy\ndefenses by crafting adversarial examples that evade a privacy-invasive\nwebsite-fingerprinting classifier.\n", "versions": [{"version": "v1", "created": "Thu, 25 Oct 2018 15:53:19 GMT"}, {"version": "v2", "created": "Thu, 22 Nov 2018 14:26:22 GMT"}, {"version": "v3", "created": "Mon, 1 Jul 2019 15:10:25 GMT"}], "update_date": "2019-07-02", "authors_parsed": [["Kulynych", "Bogdan", ""], ["Hayes", "Jamie", ""], ["Samarin", "Nikita", ""], ["Troncoso", "Carmela", ""]]}, {"id": "1810.10942", "submitter": "Nicolas Pr\\\"ollochs", "authors": "Bernhard Lutz, Nicolas Pr\\\"ollochs, Dirk Neumann", "title": "Understanding the Role of Two-Sided Argumentation in Online Consumer\n  Reviews: A Language-Based Perspective", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  This paper examines the effect of two-sided argumentation on the perceived\nhelpfulness of online consumer reviews. In contrast to previous works, our\nanalysis thereby sheds light on the reception of reviews from a language-based\nperspective. For this purpose, we propose an intriguing text analysis approach\nbased on distributed text representations and multi-instance learning to\noperationalize the two-sidedness of argumentation in review texts. A subsequent\nempirical analysis using a large corpus of Amazon reviews suggests that\ntwo-sided argumentation in reviews significantly increases their helpfulness.\nWe find this effect to be stronger for positive reviews than for negative\nreviews, whereas a higher degree of emotional language weakens the effect. Our\nfindings have immediate implications for retailer platforms, which can utilize\nour results to optimize their customer feedback system and to present more\nuseful product reviews.\n", "versions": [{"version": "v1", "created": "Thu, 25 Oct 2018 15:57:45 GMT"}, {"version": "v2", "created": "Mon, 24 Dec 2018 23:21:24 GMT"}], "update_date": "2018-12-27", "authors_parsed": [["Lutz", "Bernhard", ""], ["Pr\u00f6llochs", "Nicolas", ""], ["Neumann", "Dirk", ""]]}, {"id": "1810.10948", "submitter": "Jianlin Su", "authors": "Jianlin Su", "title": "Training Generative Adversarial Networks Via Turing Test", "comments": "fix some clerical errors, add some experimental data", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  In this article, we introduce a new mode for training Generative Adversarial\nNetworks (GANs). Rather than minimizing the distance of evidence distribution\n$\\tilde{p}(x)$ and the generative distribution $q(x)$, we minimize the distance\nof $\\tilde{p}(x_r)q(x_f)$ and $\\tilde{p}(x_f)q(x_r)$. This adversarial pattern\ncan be interpreted as a Turing test in GANs. It allows us to use information of\nreal samples during training generator and accelerates the whole training\nprocedure. We even find that just proportionally increasing the size of\ndiscriminator and generator, it succeeds on 256x256 resolution without\nadjusting hyperparameters carefully.\n", "versions": [{"version": "v1", "created": "Thu, 25 Oct 2018 16:08:02 GMT"}, {"version": "v2", "created": "Sat, 27 Oct 2018 08:49:53 GMT"}], "update_date": "2018-10-30", "authors_parsed": [["Su", "Jianlin", ""]]}, {"id": "1810.10952", "submitter": "Yuankai Wu", "authors": "Yuankai Wu, Huachun Tan, Bin Ran", "title": "Differential Variable Speed Limits Control for Freeway Recurrent\n  Bottlenecks via Deep Reinforcement learning", "comments": "24 pages, 7 figures, 1 table", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Variable speed limits (VSL) control is a flexible way to improve traffic\ncondition,increase safety and reduce emission. There is an emerging trend of\nusing reinforcement learning technique for VSL control and recent studies have\nshown promising results. Currently, deep learning is enabling reinforcement\nlearning to develope autonomous control agents for problems that were\npreviously intractable. In this paper, we propose a more effective deep\nreinforcement learning (DRL) model for differential variable speed limits\n(DVSL) control, in which the dynamic and different speed limits among lanes can\nbe imposed. The proposed DRL models use a novel actor-critic architecture which\ncan learn a large number of discrete speed limits in a continues action space.\nDifferent reward signals, e.g. total travel time, bottleneck speed, emergency\nbraking, and vehicular emission are used to train the DVSL controller, and\ncomparison between these reward signals are conducted. We test proposed DRL\nbaased DVSL controllers on a simulated freeway recurrent bottleneck. Results\nshow that the efficiency, safety and emissions can be improved by the proposed\nmethod. We also show some interesting findings through the visulization of the\ncontrol policies generated from DRL models.\n", "versions": [{"version": "v1", "created": "Thu, 25 Oct 2018 16:11:29 GMT"}], "update_date": "2018-10-26", "authors_parsed": [["Wu", "Yuankai", ""], ["Tan", "Huachun", ""], ["Ran", "Bin", ""]]}, {"id": "1810.10956", "submitter": "Tiago Carvalho", "authors": "Kemilly Dearo Garcia, Tiago Carvalho, Jo\\~ao Mendes-Moreira, Jo\\~ao\n  M.P. Cardoso and Andr\\'e C.P.L.F. de Carvalho", "title": "A Preliminary Study on Hyperparameter Configuration for Human Activity\n  Recognition", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Human activity recognition (HAR) is a classification task that aims to\nclassify human activities or predict human behavior by means of features\nextracted from sensors data. Typical HAR systems use wearable sensors and/or\nhandheld and mobile devices with built-in sensing capabilities. Due to the\nwidespread use of smartphones and to the inclusion of various sensors in all\ncontemporary smartphones (e.g., accelerometers and gyroscopes), they are\ncommonly used for extracting and collecting data from sensors and even for\nimplementing HAR systems. When using mobile devices, e.g., smartphones, HAR\nsystems need to deal with several constraints regarding battery, computation\nand memory. These constraints enforce the need of a system capable of managing\nits resources and maintain acceptable levels of classification accuracy.\nMoreover, several factors can influence activity recognition, such as\nclassification models, sensors availability and size of data window for feature\nextraction, making stable accuracy a difficult task. In this paper, we present\na semi-supervised classifier and a study regarding the influence of\nhyperparameter configuration in classification accuracy, depending on the user\nand the activities performed by each user. This study focuses on sensing data\nprovided by the PAMAP2 dataset. Experimental results show that it is possible\nto maintain classification accuracy by adjusting hyperparameters, like window\nsize and windows overlap factor, depending on user and activity performed.\nThese experiments motivate the development of a system able to automatically\nadapt hyperparameter settings for the activity performed by each user.\n", "versions": [{"version": "v1", "created": "Thu, 25 Oct 2018 16:26:30 GMT"}], "update_date": "2018-10-26", "authors_parsed": [["Garcia", "Kemilly Dearo", ""], ["Carvalho", "Tiago", ""], ["Mendes-Moreira", "Jo\u00e3o", ""], ["Cardoso", "Jo\u00e3o M. P.", ""], ["de Carvalho", "Andr\u00e9 C. P. L. F.", ""]]}, {"id": "1810.10958", "submitter": "Iqbal H. Sarker", "authors": "Iqbal H. Sarker", "title": "SilentPhone: Inferring User Unavailability based Opportune Moments to\n  Minimize Call Interruptions", "comments": "EAI Endorsed Transactions on Mobile Communications and Applications,\n  2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The increasing popularity of cell phones has made them the most personal and\nubiquitous communication devices nowadays. Typically, the ringing notifications\nof mobile phones are used to inform the users about the incoming calls.\nHowever, the notifications of inappropriate incoming calls sometimes cause\ninterruptions not only for the users but also the surrounding people. In this\npaper, we present a data-driven approach to infer the opportune moments for\nsuch phone call interruptions based on user's unavailability, i.e., when a user\nis unable to answer the incoming phone calls, by analyzing individual's past\nphone log data, and to discover the corresponding phone silent mode configuring\nrules for the purpose of minimizing call interruptions in an automated\nintelligent system. Experiments on the real mobile phone datasets show that our\napproach is able to identify the opportune moments for call interruptions and\ngenerates corresponding silent mode configuring rules by capturing the dominant\nbehavior of individual users' at various times-of-the-day and days-of-the week.\n", "versions": [{"version": "v1", "created": "Mon, 15 Oct 2018 14:56:02 GMT"}], "update_date": "2018-10-26", "authors_parsed": [["Sarker", "Iqbal H.", ""]]}, {"id": "1810.10962", "submitter": "Lei Deng", "authors": "Zhaodong Chen, Lei Deng, Guoqi Li, Jiawei Sun, Xing Hu, Xin Ma, Yuan\n  Xie", "title": "Batch Normalization Sampling", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep Neural Networks (DNNs) thrive in recent years in which Batch\nNormalization (BN) plays an indispensable role. However, it has been observed\nthat BN is costly due to the reduction operations. In this paper, we propose\nalleviating this problem through sampling only a small fraction of data for\nnormalization at each iteration. Specifically, we model it as a statistical\nsampling problem and identify that by sampling less correlated data, we can\nlargely reduce the requirement of the number of data for statistics estimation\nin BN, which directly simplifies the reduction operations. Based on this\nconclusion, we propose two sampling strategies, \"Batch Sampling\" (randomly\nselect several samples from each batch) and \"Feature Sampling\" (randomly select\na small patch from each feature map of all samples), that take both\ncomputational efficiency and sample correlation into consideration.\nFurthermore, we introduce an extremely simple variant of BN, termed as Virtual\nDataset Normalization (VDN), that can normalize the activations well with few\nsynthetical random samples. All the proposed methods are evaluated on various\ndatasets and networks, where an overall training speedup by up to 20% on GPU is\npractically achieved without the support of any specialized libraries, and the\nloss on accuracy and convergence rate are negligible. Finally, we extend our\nwork to the \"micro-batch normalization\" problem and yield comparable\nperformance with existing approaches at the case of tiny batch size.\n", "versions": [{"version": "v1", "created": "Thu, 25 Oct 2018 16:31:49 GMT"}, {"version": "v2", "created": "Fri, 2 Nov 2018 01:54:47 GMT"}], "update_date": "2018-11-05", "authors_parsed": [["Chen", "Zhaodong", ""], ["Deng", "Lei", ""], ["Li", "Guoqi", ""], ["Sun", "Jiawei", ""], ["Hu", "Xing", ""], ["Ma", "Xin", ""], ["Xie", "Yuan", ""]]}, {"id": "1810.10964", "submitter": "Iman Sajedian", "authors": "Iman Sajedian, Trevon Badloe, Junsuk Rho", "title": "Finding the best design parameters for optical nanostructures using\n  reinforcement learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.IV cs.LG physics.optics", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recently, a novel machine learning model has emerged in the field of\nreinforcement learning known as deep Q-learning. This model is capable of\nfinding the best possible solution in systems consisting of millions of\nchoices, without ever experiencing it before, and has been used to beat the\nbest human minds at complex games such as, Go and chess, which both have a huge\nnumber of possible decisions and outcomes for each move. With a human-level\nintelligence, it has been solved the problems that no other machine learning\nmodel could do before. Here, we show the steps needed for implementing this\nmodel on an optical problem. We investigated the colour generation by\ndielectric nanostructures and show that this model can find geometrical\nproperties that can generate a much deeper red, green and blue colours compared\nto the ones found by human researchers. This technique can easily be extended\nto predict and find the best design parameters for other optical structures.\n", "versions": [{"version": "v1", "created": "Thu, 18 Oct 2018 03:44:39 GMT"}], "update_date": "2018-10-26", "authors_parsed": [["Sajedian", "Iman", ""], ["Badloe", "Trevon", ""], ["Rho", "Junsuk", ""]]}, {"id": "1810.10974", "submitter": "Isaak Kavasidis", "authors": "Simone Palazzo, Concetto Spampinato, Isaak Kavasidis, Daniela\n  Giordano, Joseph Schmidt, Mubarak Shah", "title": "Decoding Brain Representations by Multimodal Learning of Neural Activity\n  and Visual Features", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This work presents a novel method of exploring human brain-visual\nrepresentations, with a view towards replicating these processes in machines.\nThe core idea is to learn plausible computational and biological\nrepresentations by correlating human neural activity and natural images. Thus,\nwe first propose a model, EEG-ChannelNet, to learn a brain manifold for EEG\nclassification. After verifying that visual information can be extracted from\nEEG data, we introduce a multimodal approach that uses deep image and EEG\nencoders, trained in a siamese configuration, for learning a joint manifold\nthat maximizes a compatibility measure between visual features and brain\nrepresentations. We then carry out image classification and saliency detection\non the learned manifold. Performance analyses show that our approach\nsatisfactorily decodes visual information from neural signals. This, in turn,\ncan be used to effectively supervise the training of deep learning models, as\ndemonstrated by the high performance of image classification and saliency\ndetection on out-of-training classes. The obtained results show that the\nlearned brain-visual features lead to improved performance and simultaneously\nbring deep models more in line with cognitive neuroscience work related to\nvisual perception and attention.\n", "versions": [{"version": "v1", "created": "Thu, 25 Oct 2018 16:52:20 GMT"}, {"version": "v2", "created": "Sat, 18 Apr 2020 17:49:41 GMT"}], "update_date": "2020-04-21", "authors_parsed": [["Palazzo", "Simone", ""], ["Spampinato", "Concetto", ""], ["Kavasidis", "Isaak", ""], ["Giordano", "Daniela", ""], ["Schmidt", "Joseph", ""], ["Shah", "Mubarak", ""]]}, {"id": "1810.10977", "submitter": "Erva Ulu", "authors": "Yining Wang and Erva Ulu and Aarti Singh and Levent Burak Kara", "title": "Efficient Load Sampling for Worst-Case Structural Analysis Under Force\n  Location Uncertainty", "comments": "Proceedings of the ASME 2018 International Design Engineering\n  Technical Conferences & Computers and Information in Engineering Conference\n  (IDETC/CIE 2018) (In Print)", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.CG cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  An important task in structural design is to quantify the structural\nperformance of an object under the external forces it may experience during its\nuse. The problem proves to be computationally very challenging as the external\nforces' contact locations and magnitudes may exhibit significant variations. We\npresent an efficient analysis approach to determine the most critical force\ncontact location in such problems with force location uncertainty. Given an\ninput 3D model and regions on its boundary where arbitrary normal forces may\nmake contact, our algorithm predicts the worst-case force configuration\nresponsible for creating the highest stress within the object. Our approach\nuses a computationally tractable experimental design method to select number of\nsample force locations based on geometry only, without inspecting the stress\nresponse that requires computationally expensive finite-element analysis. Then,\nwe construct a simple regression model on these samples and corresponding\nmaximum stresses. Combined with a simple ranking based post-processing step,\nour method provides a practical solution to worst-case structural analysis\nproblem. The results indicate that our approach achieves significant\nimprovements over the existing work and brute force approaches. We demonstrate\nthat further speed- up can be obtained when small amount of an error tolerance\nin maximum stress is allowed.\n", "versions": [{"version": "v1", "created": "Thu, 25 Oct 2018 16:55:23 GMT"}], "update_date": "2018-10-26", "authors_parsed": [["Wang", "Yining", ""], ["Ulu", "Erva", ""], ["Singh", "Aarti", ""], ["Kara", "Levent Burak", ""]]}, {"id": "1810.10999", "submitter": "Matthew MacKay", "authors": "Matthew MacKay, Paul Vicol, Jimmy Ba, Roger Grosse", "title": "Reversible Recurrent Neural Networks", "comments": "Published as a conference paper at NIPS 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recurrent neural networks (RNNs) provide state-of-the-art performance in\nprocessing sequential data but are memory intensive to train, limiting the\nflexibility of RNN models which can be trained. Reversible RNNs---RNNs for\nwhich the hidden-to-hidden transition can be reversed---offer a path to reduce\nthe memory requirements of training, as hidden states need not be stored and\ninstead can be recomputed during backpropagation. We first show that perfectly\nreversible RNNs, which require no storage of the hidden activations, are\nfundamentally limited because they cannot forget information from their hidden\nstate. We then provide a scheme for storing a small number of bits in order to\nallow perfect reversal with forgetting. Our method achieves comparable\nperformance to traditional models while reducing the activation memory cost by\na factor of 10--15. We extend our technique to attention-based\nsequence-to-sequence models, where it maintains performance while reducing\nactivation memory cost by a factor of 5--10 in the encoder, and a factor of\n10--15 in the decoder.\n", "versions": [{"version": "v1", "created": "Thu, 25 Oct 2018 17:44:45 GMT"}], "update_date": "2018-10-26", "authors_parsed": [["MacKay", "Matthew", ""], ["Vicol", "Paul", ""], ["Ba", "Jimmy", ""], ["Grosse", "Roger", ""]]}, {"id": "1810.11043", "submitter": "Tianhe Yu", "authors": "Tianhe Yu, Pieter Abbeel, Sergey Levine, Chelsea Finn", "title": "One-Shot Hierarchical Imitation Learning of Compound Visuomotor Tasks", "comments": "Video results available at https://sites.google.com/view/one-shot-hil", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CV cs.RO stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the problem of learning multi-stage vision-based tasks on a real\nrobot from a single video of a human performing the task, while leveraging\ndemonstration data of subtasks with other objects. This problem presents a\nnumber of major challenges. Video demonstrations without teleoperation are easy\nfor humans to provide, but do not provide any direct supervision. Learning\npolicies from raw pixels enables full generality but calls for large function\napproximators with many parameters to be learned. Finally, compound tasks can\nrequire impractical amounts of demonstration data, when treated as a monolithic\nskill. To address these challenges, we propose a method that learns both how to\nlearn primitive behaviors from video demonstrations and how to dynamically\ncompose these behaviors to perform multi-stage tasks by \"watching\" a human\ndemonstrator. Our results on a simulated Sawyer robot and real PR2 robot\nillustrate our method for learning a variety of order fulfillment and kitchen\nserving tasks with novel objects and raw pixel inputs.\n", "versions": [{"version": "v1", "created": "Thu, 25 Oct 2018 18:05:08 GMT"}], "update_date": "2018-10-29", "authors_parsed": [["Yu", "Tianhe", ""], ["Abbeel", "Pieter", ""], ["Levine", "Sergey", ""], ["Finn", "Chelsea", ""]]}, {"id": "1810.11059", "submitter": "Ayush Sekhari", "authors": "Dylan J. Foster, Ayush Sekhari, Karthik Sridharan", "title": "Uniform Convergence of Gradients for Non-Convex Learning and\n  Optimization", "comments": "To appear in Neural Information Processing Systems (NIPS) 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG math.OC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We investigate 1) the rate at which refined properties of the empirical\nrisk---in particular, gradients---converge to their population counterparts in\nstandard non-convex learning tasks, and 2) the consequences of this convergence\nfor optimization. Our analysis follows the tradition of norm-based capacity\ncontrol. We propose vector-valued Rademacher complexities as a simple,\ncomposable, and user-friendly tool to derive dimension-free uniform convergence\nbounds for gradients in non-convex learning problems. As an application of our\ntechniques, we give a new analysis of batch gradient descent methods for\nnon-convex generalized linear models and non-convex robust regression, showing\nhow to use any algorithm that finds approximate stationary points to obtain\noptimal sample complexity, even when dimension is high or possibly infinite and\nmultiple passes over the dataset are allowed.\n  Moving to non-smooth models we show----in contrast to the smooth case---that\neven for a single ReLU it is not possible to obtain dimension-independent\nconvergence rates for gradients in the worst case. On the positive side, it is\nstill possible to obtain dimension-independent rates under a new type of\ndistributional assumption.\n", "versions": [{"version": "v1", "created": "Thu, 25 Oct 2018 18:31:44 GMT"}, {"version": "v2", "created": "Sun, 11 Nov 2018 05:42:58 GMT"}], "update_date": "2018-11-13", "authors_parsed": [["Foster", "Dylan J.", ""], ["Sekhari", "Ayush", ""], ["Sridharan", "Karthik", ""]]}, {"id": "1810.11066", "submitter": "Meghan Cowan", "authors": "Meghan Cowan, Thierry Moreau, Tianqi Chen, Luis Ceze", "title": "Automating Generation of Low Precision Deep Learning Operators", "comments": "10 pages, 11 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  State of the art deep learning models have made steady progress in the fields\nof computer vision and natural language processing, at the expense of growing\nmodel sizes and computational complexity. Deploying these models on low power\nand mobile devices poses a challenge due to their limited compute capabilities\nand strict energy budgets. One solution that has generated significant research\ninterest is deploying highly quantized models that operate on low precision\ninputs and weights less than eight bits, trading off accuracy for performance.\nThese models have a significantly reduced memory footprint (up to 32x\nreduction) and can replace multiply-accumulates with bitwise operations during\ncompute intensive convolution and fully connected layers.\n  Most deep learning frameworks rely on highly engineered linear algebra\nlibraries such as ATLAS or Intel's MKL to implement efficient deep learning\noperators. To date, none of the popular deep learning directly support low\nprecision operators, partly due to a lack of optimized low precision libraries.\nIn this paper we introduce a work flow to quickly generate high performance low\nprecision deep learning operators for arbitrary precision that target multiple\nCPU architectures and include optimizations such as memory tiling and\nvectorization. We present an extensive case study on low power ARM Cortex-A53\nCPU, and show how we can generate 1-bit, 2-bit convolutions with speedups up to\n16x over an optimized 16-bit integer baseline and 2.3x better than handwritten\nimplementations.\n", "versions": [{"version": "v1", "created": "Thu, 25 Oct 2018 18:52:48 GMT"}], "update_date": "2018-10-29", "authors_parsed": [["Cowan", "Meghan", ""], ["Moreau", "Thierry", ""], ["Chen", "Tianqi", ""], ["Ceze", "Luis", ""]]}, {"id": "1810.11071", "submitter": "Hamideh Hajiabadi", "authors": "Hamideh Hajiabadi, Reza Monsefi, Hadi Sadoghi Yazdi", "title": "RELF: Robust Regression Extended with Ensemble Loss Function", "comments": "18 Pages, 7 figures, Accepted in Applied Intelligence- Springer The\n  International Journal of Research on Intelligent Systems for Real Life\n  Complex Problems", "journal-ref": null, "doi": "10.1007/s10489-018-1341-9", "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Ensemble techniques are powerful approaches that combine several weak\nlearners to build a stronger one. As a meta-learning framework, ensemble\ntechniques can easily be applied to many machine learning methods. Inspired by\nensemble techniques, in this paper we propose an ensemble loss functions\napplied to a simple regressor. We then propose a half-quadratic learning\nalgorithm in order to find the parameter of the regressor and the optimal\nweights associated with each loss function. Moreover, we show that our proposed\nloss function is robust in noisy environments. For a particular class of loss\nfunctions, we show that our proposed ensemble loss function is Bayes consistent\nand robust. Experimental evaluations on several datasets demonstrate that our\nproposed ensemble loss function significantly improves the performance of a\nsimple regressor in comparison with state-of-the-art methods.\n", "versions": [{"version": "v1", "created": "Thu, 25 Oct 2018 19:05:16 GMT"}], "update_date": "2018-10-29", "authors_parsed": [["Hajiabadi", "Hamideh", ""], ["Monsefi", "Reza", ""], ["Yazdi", "Hadi Sadoghi", ""]]}, {"id": "1810.11098", "submitter": "Ming Yu", "authors": "Ming Yu, Zhuoran Yang, Tuo Zhao, Mladen Kolar, Zhaoran Wang", "title": "Provable Gaussian Embedding with One Observation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The success of machine learning methods heavily relies on having an\nappropriate representation for data at hand. Traditionally, machine learning\napproaches relied on user-defined heuristics to extract features encoding\nstructural information about data. However, recently there has been a surge in\napproaches that learn how to encode the data automatically in a low dimensional\nspace. Exponential family embedding provides a probabilistic framework for\nlearning low-dimensional representation for various types of high-dimensional\ndata. Though successful in practice, theoretical underpinnings for exponential\nfamily embeddings have not been established. In this paper, we study the\nGaussian embedding model and develop the first theoretical results for\nexponential family embedding models. First, we show that, under mild condition,\nthe embedding structure can be learned from one observation by leveraging the\nparameter sharing between different contexts even though the data are dependent\nwith each other. Second, we study properties of two algorithms used for\nlearning the embedding structure and establish convergence results for each of\nthem. The first algorithm is based on a convex relaxation, while the other\nsolved the non-convex formulation of the problem directly. Experiments\ndemonstrate the effectiveness of our approach.\n", "versions": [{"version": "v1", "created": "Thu, 25 Oct 2018 20:34:37 GMT"}], "update_date": "2018-10-29", "authors_parsed": [["Yu", "Ming", ""], ["Yang", "Zhuoran", ""], ["Zhao", "Tuo", ""], ["Kolar", "Mladen", ""], ["Wang", "Zhaoran", ""]]}, {"id": "1810.11155", "submitter": "Bayan Saparbayeva", "authors": "Bayan Saparbayeva, Michael Minyi Zhang, Lizhen Lin", "title": "Communication Efficient Parallel Algorithms for Optimization on\n  Manifolds", "comments": "15 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The last decade has witnessed an explosion in the development of models,\ntheory and computational algorithms for \"big data\" analysis. In particular,\ndistributed computing has served as a natural and dominating paradigm for\nstatistical inference. However, the existing literature on parallel inference\nalmost exclusively focuses on Euclidean data and parameters. While this\nassumption is valid for many applications, it is increasingly more common to\nencounter problems where the data or the parameters lie on a non-Euclidean\nspace, like a manifold for example. Our work aims to fill a critical gap in the\nliterature by generalizing parallel inference algorithms to optimization on\nmanifolds. We show that our proposed algorithm is both communication efficient\nand carries theoretical convergence guarantees. In addition, we demonstrate the\nperformance of our algorithm to the estimation of Fr\\'echet means on simulated\nspherical data and the low-rank matrix completion problem over Grassmann\nmanifolds applied to the Netflix prize data set.\n", "versions": [{"version": "v1", "created": "Fri, 26 Oct 2018 01:05:40 GMT"}, {"version": "v2", "created": "Mon, 29 Oct 2018 04:18:34 GMT"}, {"version": "v3", "created": "Thu, 1 Nov 2018 16:45:30 GMT"}], "update_date": "2018-11-02", "authors_parsed": [["Saparbayeva", "Bayan", ""], ["Zhang", "Michael Minyi", ""], ["Lin", "Lizhen", ""]]}, {"id": "1810.11158", "submitter": "Bolton Bailey", "authors": "Bolton Bailey, Matus Telgarsky", "title": "Size-Noise Tradeoffs in Generative Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper investigates the ability of generative networks to convert their\ninput noise distributions into other distributions. Firstly, we demonstrate a\nconstruction that allows ReLU networks to increase the dimensionality of their\nnoise distribution by implementing a \"space-filling\" function based on iterated\ntent maps. We show this construction is optimal by analyzing the number of\naffine pieces in functions computed by multivariate ReLU networks. Secondly, we\nprovide efficient ways (using polylog $(1/\\epsilon)$ nodes) for networks to\npass between univariate uniform and normal distributions, using a Taylor series\napproximation and a binary search gadget for computing function inverses.\nLastly, we indicate how high dimensional distributions can be efficiently\ntransformed into low dimensional distributions.\n", "versions": [{"version": "v1", "created": "Fri, 26 Oct 2018 01:26:30 GMT"}], "update_date": "2018-10-29", "authors_parsed": [["Bailey", "Bolton", ""], ["Telgarsky", "Matus", ""]]}, {"id": "1810.11165", "submitter": "Tharindu Adikari", "authors": "Tharindu Adikari, Stark C. Draper", "title": "Efficient learning of neighbor representations for boundary trees and\n  forests", "comments": "9 pages, 2 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce a semiparametric approach to neighbor-based classification. We\nbuild off the recently proposed Boundary Trees algorithm by Mathy et al.(2015)\nwhich enables fast neighbor-based classification, regression and retrieval in\nlarge datasets. While boundary trees use an Euclidean measure of similarity,\nthe Differentiable Boundary Tree algorithm by Zoran et al.(2017) was introduced\nto learn low-dimensional representations of complex input data, on which\nsemantic similarity can be calculated to train boundary trees. As is pointed\nout by its authors, the differentiable boundary tree approach contains a few\nlimitations that prevents it from scaling to large datasets. In this paper, we\nintroduce Differentiable Boundary Sets, an algorithm that overcomes the\ncomputational issues of the differentiable boundary tree scheme and also\nimproves its classification accuracy and data representability. Our algorithm\nis efficiently implementable with existing tools and offers a significant\nreduction in training time. We test and compare the algorithms on the well\nknown MNIST handwritten digits dataset and the newer Fashion-MNIST dataset by\nXiao et al.(2017).\n", "versions": [{"version": "v1", "created": "Fri, 26 Oct 2018 02:01:30 GMT"}], "update_date": "2018-10-29", "authors_parsed": [["Adikari", "Tharindu", ""], ["Draper", "Stark C.", ""]]}, {"id": "1810.11177", "submitter": "Zi Wang", "authors": "Victoria Xia and Zi Wang and Leslie Pack Kaelbling", "title": "Learning sparse relational transition models", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.RO stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a representation for describing transition models in complex\nuncertain domains using relational rules. For any action, a rule selects a set\nof relevant objects and computes a distribution over properties of just those\nobjects in the resulting state given their properties in the previous state. An\niterative greedy algorithm is used to construct a set of deictic references\nthat determine which objects are relevant in any given state. Feed-forward\nneural networks are used to learn the transition distribution on the relevant\nobjects' properties. This strategy is demonstrated to be both more versatile\nand more sample efficient than learning a monolithic transition model in a\nsimulated domain in which a robot pushes stacks of objects on a cluttered\ntable.\n", "versions": [{"version": "v1", "created": "Fri, 26 Oct 2018 03:45:22 GMT"}], "update_date": "2018-10-29", "authors_parsed": [["Xia", "Victoria", ""], ["Wang", "Zi", ""], ["Kaelbling", "Leslie Pack", ""]]}, {"id": "1810.11178", "submitter": "Richard Bean", "authors": "Richard Bean, Hina Khan", "title": "Using solar and load predictions in battery scheduling at the\n  residential level", "comments": "This paper was presented at the 8th Solar Integration Workshop and\n  published in the workshop's proceedings", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SY cs.LG math.OC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Smart solar inverters can be used to store, monitor and manage a home's solar\nenergy. We describe a smart solar inverter system with battery which can either\noperate in an automatic mode or receive commands over a network to charge and\ndischarge at a given rate. In order to make battery storage financially viable\nand advantageous to the consumers, effective battery scheduling algorithms can\nbe employed. Particularly, when time-of-use tariffs are in effect in the region\nof the inverter, it is possible in some cases to schedule the battery to save\nmoney for the individual customer, compared to the \"automatic\" mode. Hence,\nthis paper presents and evaluates the performance of a novel battery scheduling\nalgorithm for residential consumers of solar energy. The proposed battery\nscheduling algorithm optimizes the cost of electricity over next 24 hours for\nresidential consumers. The cost minimization is realized by controlling the\ncharging/discharging of battery storage system based on the predictions for\nload and solar power generation values. The scheduling problem is formulated as\na linear programming problem. We performed computer simulations over 83\ninverters using several months of hourly load and PV data. The simulation\nresults indicate that key factors affecting the viability of optimization are\nthe tariffs and the PV to Load ratio at each inverter. Depending on the tariff,\nsavings of between 1% and 10% can be expected over the automatic approach. The\nprediction approach used in this paper is also shown to out-perform basic\n\"persistence\" forecasting approaches. We have also examined the approaches for\nimproving the prediction accuracy and optimization effectiveness.\n", "versions": [{"version": "v1", "created": "Fri, 26 Oct 2018 03:49:25 GMT"}], "update_date": "2018-10-29", "authors_parsed": [["Bean", "Richard", ""], ["Khan", "Hina", ""]]}, {"id": "1810.11181", "submitter": "Abhishek Das", "authors": "Abhishek Das, Georgia Gkioxari, Stefan Lee, Devi Parikh, Dhruv Batra", "title": "Neural Modular Control for Embodied Question Answering", "comments": "10 pages, 3 figures, 2 tables. Published at CoRL 2018. Webpage:\n  https://embodiedqa.org/", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.CL cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a modular approach for learning policies for navigation over long\nplanning horizons from language input. Our hierarchical policy operates at\nmultiple timescales, where the higher-level master policy proposes subgoals to\nbe executed by specialized sub-policies. Our choice of subgoals is\ncompositional and semantic, i.e. they can be sequentially combined in arbitrary\norderings, and assume human-interpretable descriptions (e.g. 'exit room', 'find\nkitchen', 'find refrigerator', etc.).\n  We use imitation learning to warm-start policies at each level of the\nhierarchy, dramatically increasing sample efficiency, followed by reinforcement\nlearning. Independent reinforcement learning at each level of hierarchy enables\nsub-policies to adapt to consequences of their actions and recover from errors.\nSubsequent joint hierarchical training enables the master policy to adapt to\nthe sub-policies.\n  On the challenging EQA (Das et al., 2018) benchmark in House3D (Wu et al.,\n2018), requiring navigating diverse realistic indoor environments, our approach\noutperforms prior work by a significant margin, both in terms of navigation and\nquestion answering.\n", "versions": [{"version": "v1", "created": "Fri, 26 Oct 2018 03:58:26 GMT"}, {"version": "v2", "created": "Thu, 2 May 2019 23:41:47 GMT"}], "update_date": "2019-05-06", "authors_parsed": [["Das", "Abhishek", ""], ["Gkioxari", "Georgia", ""], ["Lee", "Stefan", ""], ["Parikh", "Devi", ""], ["Batra", "Dhruv", ""]]}, {"id": "1810.11187", "submitter": "Abhishek Das", "authors": "Abhishek Das, Th\\'eophile Gervet, Joshua Romoff, Dhruv Batra, Devi\n  Parikh, Michael Rabbat, Joelle Pineau", "title": "TarMAC: Targeted Multi-Agent Communication", "comments": "ICML 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.MA stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a targeted communication architecture for multi-agent\nreinforcement learning, where agents learn both what messages to send and whom\nto address them to while performing cooperative tasks in partially-observable\nenvironments. This targeting behavior is learnt solely from downstream\ntask-specific reward without any communication supervision. We additionally\naugment this with a multi-round communication approach where agents coordinate\nvia multiple rounds of communication before taking actions in the environment.\nWe evaluate our approach on a diverse set of cooperative multi-agent tasks, of\nvarying difficulties, with varying number of agents, in a variety of\nenvironments ranging from 2D grid layouts of shapes and simulated traffic\njunctions to 3D indoor environments, and demonstrate the benefits of targeted\nand multi-round communication. Moreover, we show that the targeted\ncommunication strategies learned by agents are interpretable and intuitive.\nFinally, we show that our architecture can be easily extended to mixed and\ncompetitive environments, leading to improved performance and sample complexity\nover recent state-of-the-art approaches.\n", "versions": [{"version": "v1", "created": "Fri, 26 Oct 2018 04:22:58 GMT"}, {"version": "v2", "created": "Sat, 22 Feb 2020 04:37:13 GMT"}], "update_date": "2020-02-25", "authors_parsed": [["Das", "Abhishek", ""], ["Gervet", "Th\u00e9ophile", ""], ["Romoff", "Joshua", ""], ["Batra", "Dhruv", ""], ["Parikh", "Devi", ""], ["Rabbat", "Michael", ""], ["Pineau", "Joelle", ""]]}, {"id": "1810.11197", "submitter": "Amichai Painsky", "authors": "Amichai Painsky and Saharon Rosset", "title": "Lossless (and Lossy) Compression of Random Forests", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Ensemble methods are among the state-of-the-art predictive modeling\napproaches. Applied to modern big data, these methods often require a large\nnumber of sub-learners, where the complexity of each learner typically grows\nwith the size of the dataset. This phenomenon results in an increasing demand\nfor storage space, which may be very costly. This problem mostly manifests in a\nsubscriber based environment, where a user-specific ensemble needs to be stored\non a personal device with strict storage limitations (such as a cellular\ndevice). In this work we introduce a novel method for lossless compression of\ntree-based ensemble methods, focusing on random forests. Our suggested method\nis based on probabilistic modeling of the ensemble's trees, followed by model\nclustering via Bregman divergence. This allows us to find a minimal set of\nmodels that provides an accurate description of the trees, and at the same time\nis small enough to store and maintain. Our compression scheme demonstrates high\ncompression rates on a variety of modern datasets. Importantly, our scheme\nenables predictions from the compressed format and a perfect reconstruction of\nthe original ensemble. In addition, we introduce a theoretically sound lossy\ncompression scheme, which allows us to control the trade-off between the\ndistortion and the coding rate.\n", "versions": [{"version": "v1", "created": "Fri, 26 Oct 2018 06:08:05 GMT"}], "update_date": "2018-10-29", "authors_parsed": [["Painsky", "Amichai", ""], ["Rosset", "Saharon", ""]]}, {"id": "1810.11203", "submitter": "Asma Nouira", "authors": "Asma Nouira (ICMPE), Nataliya Sokolovska (Sorbonne Universit\\'e),\n  Jean-Claude Crivello (ICMPE)", "title": "CrystalGAN: Learning to Discover Crystallographic Structures with\n  Generative Adversarial Networks", "comments": null, "journal-ref": "AAAI Spring Symposium: Combining Machine Learning with Knowledge\n  Engineering 2019", "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Our main motivation is to propose an efficient approach to generate novel\nmulti-element stable chemical compounds that can be used in real world\napplications. This task can be formulated as a combinatorial problem, and it\ntakes many hours of human experts to construct, and to evaluate new data.\nUnsupervised learning methods such as Generative Adversarial Networks (GANs)\ncan be efficiently used to produce new data. Cross-domain Generative\nAdversarial Networks were reported to achieve exciting results in image\nprocessing applications. However, in the domain of materials science, there is\na need to synthesize data with higher order complexity compared to observed\nsamples, and the state-of-the-art cross-domain GANs can not be adapted\ndirectly. In this contribution, we propose a novel GAN called CrystalGAN which\ngenerates new chemically stable crystallographic structures with increased\ndomain complexity. We introduce an original architecture, we provide the\ncorresponding loss functions, and we show that the CrystalGAN generates very\nreasonable data. We illustrate the efficiency of the proposed method on a real\noriginal problem of novel hydrides discovery that can be further used in\ndevelopment of hydrogen storage materials.\n", "versions": [{"version": "v1", "created": "Fri, 26 Oct 2018 06:50:04 GMT"}, {"version": "v2", "created": "Tue, 6 Nov 2018 20:06:31 GMT"}, {"version": "v3", "created": "Sat, 25 May 2019 10:30:49 GMT"}], "update_date": "2019-05-28", "authors_parsed": [["Nouira", "Asma", "", "ICMPE"], ["Sokolovska", "Nataliya", "", "Sorbonne Universit\u00e9"], ["Crivello", "Jean-Claude", "", "ICMPE"]]}, {"id": "1810.11205", "submitter": "Max-Heinrich Laves", "authors": "Max-Heinrich Laves, L\\\"uder A. Kahrs, and Tobias Ortmaier", "title": "Deep learning based 2.5D flow field estimation for maximum intensity\n  projections of 4D optical coherence tomography", "comments": "Accepted for SPIE Medical Imaging 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In microsurgery, lasers have emerged as precise tools for bone ablation. A\nchallenge is automatic control of laser bone ablation with 4D optical coherence\ntomography (OCT). OCT as high resolution imaging modality provides volumetric\nimages of tissue and foresees information of bone position and orientation\n(pose) as well as thickness. However, existing approaches for OCT based laser\nablation control rely on external tracking systems or invasively ablated\nartificial landmarks for tracking the pose of the OCT probe relative to the\ntissue. This can be superseded by estimating the scene flow caused by relative\nmovement between OCT-based laser ablation system and patient.\n  Therefore, this paper deals with 2.5D scene flow estimation of volumetric OCT\nimages for application in laser ablation. We present a semi-supervised\nconvolutional neural network based tracking scheme for subsequent 3D OCT\nvolumes and apply it to a realistic semi-synthetic data set of ex vivo human\ntemporal bone specimen. The scene flow is estimated in a two-stage approach. In\nthe first stage, 2D lateral scene flow is computed on census-transformed\nen-face arguments-of-maximum intensity projections. Subsequent to this, the\nprojections are warped by predicted lateral flow and 1D depth flow is\nestimated. The neural network is trained semi-supervised by combining error to\nground truth and the reconstruction error of warped images with assumptions of\nspatial flow smoothness. Quantitative evaluation reveals a mean endpoint error\nof $ (4.7\\pm{}3.5) $ voxel or $ 27.5 \\pm 20.5 \\mu\\mathrm{m} $ for scene flow\nestimation caused by simulated relative movement between the OCT probe and\nbone. The scene flow estimation for 4D OCT enables its use for markerless\ntracking of mastoid bone structures for image guidance in general, and\nautomated laser ablation control.\n", "versions": [{"version": "v1", "created": "Fri, 26 Oct 2018 07:10:51 GMT"}, {"version": "v2", "created": "Tue, 19 Feb 2019 00:35:59 GMT"}], "update_date": "2019-02-20", "authors_parsed": [["Laves", "Max-Heinrich", ""], ["Kahrs", "L\u00fcder A.", ""], ["Ortmaier", "Tobias", ""]]}, {"id": "1810.11209", "submitter": "Mingyuan Zhou", "authors": "Dandan Guo, Bo Chen, Hao Zhang, Mingyuan Zhou", "title": "Deep Poisson gamma dynamical systems", "comments": "NeurIPS 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG stat.CO stat.ME", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We develop deep Poisson-gamma dynamical systems (DPGDS) to model sequentially\nobserved multivariate count data, improving previously proposed models by not\nonly mining deep hierarchical latent structure from the data, but also\ncapturing both first-order and long-range temporal dependencies. Using\nsophisticated but simple-to-implement data augmentation techniques, we derived\nclosed-form Gibbs sampling update equations by first backward and upward\npropagating auxiliary latent counts, and then forward and downward sampling\nlatent variables. Moreover, we develop stochastic gradient MCMC inference that\nis scalable to very long multivariate count time series. Experiments on both\nsynthetic and a variety of real-world data demonstrate that the proposed model\nnot only has excellent predictive performance, but also provides highly\ninterpretable multilayer latent structure to represent hierarchical and\ntemporal information propagation.\n", "versions": [{"version": "v1", "created": "Fri, 26 Oct 2018 07:28:20 GMT"}, {"version": "v2", "created": "Tue, 1 Jan 2019 01:01:02 GMT"}], "update_date": "2019-01-03", "authors_parsed": [["Guo", "Dandan", ""], ["Chen", "Bo", ""], ["Zhang", "Hao", ""], ["Zhou", "Mingyuan", ""]]}, {"id": "1810.11227", "submitter": "Chenguang Lu", "authors": "Chenguang Lu", "title": "From the EM Algorithm to the CM-EM Algorithm for Global Convergence of\n  Mixture Models", "comments": "17 pages, 5 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The Expectation-Maximization (EM) algorithm for mixture models often results\nin slow or invalid convergence. The popular convergence proof affirms that the\nlikelihood increases with Q; Q is increasing in the M -step and non-decreasing\nin the E-step. The author found that (1) Q may and should decrease in some\nE-steps; (2) The Shannon channel from the E-step is improper and hence the\nexpectation is improper. The author proposed the CM-EM algorithm (CM means\nChannel's Matching), which adds a step to optimize the mixture ratios for the\nproper Shannon channel and maximizes G, average log-normalized-likelihood, in\nthe M-step. Neal and Hinton's Maximization-Maximization (MM) algorithm use F\ninstead of Q to speed the convergence. Maximizing G is similar to maximizing F.\nThe new convergence proof is similar to Beal's proof with the variational\nmethod. It first proves that the minimum relative entropy equals the minimum\nR-G (R is mutual information), then uses variational and iterative methods that\nShannon et al. use for rate-distortion functions to prove the global\nconvergence. Some examples show that Q and F should and may decrease in some\nE-steps. For the same example, the EM, MM, and CM-EM algorithms need about 36,\n18, and 9 iterations respectively.\n", "versions": [{"version": "v1", "created": "Fri, 26 Oct 2018 08:44:50 GMT"}], "update_date": "2018-10-29", "authors_parsed": [["Lu", "Chenguang", ""]]}, {"id": "1810.11295", "submitter": "Bhaskar Das", "authors": "Bhaskar Das, Jalal Almhana", "title": "Real-time Context-aware Learning System for IoT Applications", "comments": "34 pages, 12 figures, Journal article", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CY stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a real-time context-aware learning system along with the\narchitecture that runs on the mobile devices, provide services to the user and\nmanage the IoT devices. In this system, an application running on mobile\ndevices collected data from the sensors, learned about the user-defined\ncontext, made predictions in real-time and manage IoT devices accordingly.\nHowever, the computational power of the mobile devices makes it challenging to\nrun machine learning algorithms with acceptable accuracy. To solve this issue,\nsome authors have run machine learning algorithms on the server and transmitted\nthe results to the mobile devices. Although the context-aware predictions made\nby the server are more accurate than their mobile counterpart, it heavily\ndepends on the network connection for the delivery of the results to the\ndevices, which negatively affects real-time context-learning. Therefore, in\nthis work, we describe a context-learning algorithm for mobile devices which is\nless demanding on the computational resources and maintains the accuracy of the\nprediction by updating itself from the learning parameters obtained from the\nserver periodically. Experimental results show that the proposed light-weight\ncontext-learning algorithm can achieve mean accuracy up to 97.51% while mean\nexecution time requires only 11ms.\n", "versions": [{"version": "v1", "created": "Fri, 26 Oct 2018 12:50:56 GMT"}], "update_date": "2018-10-29", "authors_parsed": [["Das", "Bhaskar", ""], ["Almhana", "Jalal", ""]]}, {"id": "1810.11317", "submitter": "Tanujit Chakraborty", "authors": "Tanujit Chakraborty and Ashis Kumar Chakraborty", "title": "Superensemble Classifier for Improving Predictions in Imbalanced\n  Datasets", "comments": "arXiv admin note: text overlap with arXiv:1805.12381", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Learning from an imbalanced dataset is a tricky proposition. Because these\ndatasets are biased towards one class, most existing classifiers tend not to\nperform well on minority class examples. Conventional classifiers usually aim\nto optimize the overall accuracy without considering the relative distribution\nof each class. This article presents a superensemble classifier, to tackle and\nimprove predictions in imbalanced classification problems, that maps Hellinger\ndistance decision trees (HDDT) into radial basis function network (RBFN)\nframework. Regularity conditions for universal consistency and the idea of\nparameter optimization of the proposed model are provided. The proposed\ndistribution-free model can be applied for feature selection cum imbalanced\nclassification problems. We have also provided enough numerical evidence using\nvarious real-life data sets to assess the performance of the proposed model.\nIts effectiveness and competitiveness with respect to different\nstate-of-the-art models are shown.\n", "versions": [{"version": "v1", "created": "Thu, 25 Oct 2018 15:02:24 GMT"}], "update_date": "2018-10-29", "authors_parsed": [["Chakraborty", "Tanujit", ""], ["Chakraborty", "Ashis Kumar", ""]]}, {"id": "1810.11333", "submitter": "Alessia Amelio Dr.", "authors": "Radmila Jankovi\\'c, Alessia Amelio", "title": "Comparing Multilayer Perceptron and Multiple Regression Models for\n  Predicting Energy Use in the Balkans", "comments": "In proceedings of 4th Virtual International Conference on Science,\n  Technology and Management in Energy (eNergetics 2018)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Global demographic and economic changes have a critical impact on the total\nenergy consumption, which is why demographic and economic parameters have to be\ntaken into account when making predictions about the energy consumption. This\nresearch is based on the application of a multiple linear regression model and\na neural network model, in particular multilayer perceptron, for predicting the\nenergy consumption. Data from five Balkan countries has been considered in the\nanalysis for the period 1995-2014. Gross domestic product, total number of\npopulation, and CO2 emission were taken as predictor variables, while the\nenergy consumption was used as the dependent variable. The analyses showed that\nCO2 emissions have the highest impact on the energy consumption, followed by\nthe gross domestic product, while the population number has the lowest impact.\nThe results from both analyses are then used for making predictions on the same\ndata, after which the obtained values were compared with the real values. It\nwas observed that the multilayer perceptron model predicts better the energy\nconsumption than the regression model.\n", "versions": [{"version": "v1", "created": "Fri, 26 Oct 2018 14:02:28 GMT"}], "update_date": "2018-10-29", "authors_parsed": [["Jankovi\u0107", "Radmila", ""], ["Amelio", "Alessia", ""]]}, {"id": "1810.11344", "submitter": "Ji Xu", "authors": "Ji Xu and Daniel Hsu and Arian Maleki", "title": "Benefits of over-parameterization with EM", "comments": "Accepted at NIPS 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Expectation Maximization (EM) is among the most popular algorithms for\nmaximum likelihood estimation, but it is generally only guaranteed to find its\nstationary points of the log-likelihood objective. The goal of this article is\nto present theoretical and empirical evidence that over-parameterization can\nhelp EM avoid spurious local optima in the log-likelihood. We consider the\nproblem of estimating the mean vectors of a Gaussian mixture model in a\nscenario where the mixing weights are known. Our study shows that the global\nbehavior of EM, when one uses an over-parameterized model in which the mixing\nweights are treated as unknown, is better than that when one uses the (correct)\nmodel with the mixing weights fixed to the known values. For symmetric\nGaussians mixtures with two components, we prove that introducing the\n(statistically redundant) weight parameters enables EM to find the global\nmaximizer of the log-likelihood starting from almost any initial mean\nparameters, whereas EM without this over-parameterization may very often fail.\nFor other Gaussian mixtures, we provide empirical evidence that shows similar\nbehavior. Our results corroborate the value of over-parameterization in solving\nnon-convex optimization problems, previously observed in other domains.\n", "versions": [{"version": "v1", "created": "Fri, 26 Oct 2018 14:22:20 GMT"}], "update_date": "2018-10-29", "authors_parsed": [["Xu", "Ji", ""], ["Hsu", "Daniel", ""], ["Maleki", "Arian", ""]]}, {"id": "1810.11347", "submitter": "Niklas Wolf Andreas Gebauer", "authors": "Niklas W. A. Gebauer, Michael Gastegger, Kristof T. Sch\\\"utt", "title": "Generating equilibrium molecules with deep neural networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG physics.chem-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Discovery of atomistic systems with desirable properties is a major challenge\nin chemistry and material science. Here we introduce a novel, autoregressive,\nconvolutional deep neural network architecture that generates molecular\nequilibrium structures by sequentially placing atoms in three-dimensional\nspace. The model estimates the joint probability over molecular configurations\nwith tractable conditional probabilities which only depend on distances between\natoms and their nuclear charges. It combines concepts from state-of-the-art\natomistic neural networks with auto-regressive generative models for images and\nspeech. We demonstrate that the architecture is capable of generating molecules\nclose to equilibrium for constitutional isomers of C$_7$O$_2$H$_{10}$.\n", "versions": [{"version": "v1", "created": "Fri, 26 Oct 2018 14:34:33 GMT"}], "update_date": "2018-10-29", "authors_parsed": [["Gebauer", "Niklas W. A.", ""], ["Gastegger", "Michael", ""], ["Sch\u00fctt", "Kristof T.", ""]]}, {"id": "1810.11363", "submitter": "Anna Veronika Dorogush", "authors": "Anna Veronika Dorogush, Vasily Ershov, Andrey Gulin", "title": "CatBoost: gradient boosting with categorical features support", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.MS stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we present CatBoost, a new open-sourced gradient boosting\nlibrary that successfully handles categorical features and outperforms existing\npublicly available implementations of gradient boosting in terms of quality on\na set of popular publicly available datasets. The library has a GPU\nimplementation of learning algorithm and a CPU implementation of scoring\nalgorithm, which are significantly faster than other gradient boosting\nlibraries on ensembles of similar sizes.\n", "versions": [{"version": "v1", "created": "Wed, 24 Oct 2018 13:08:24 GMT"}], "update_date": "2018-10-29", "authors_parsed": [["Dorogush", "Anna Veronika", ""], ["Ershov", "Vasily", ""], ["Gulin", "Andrey", ""]]}, {"id": "1810.11367", "submitter": "Eytan Adar", "authors": "Xin Rong, Joshua Luckson, Eytan Adar", "title": "LAMVI-2: A Visual Tool for Comparing and Tuning Word Embedding Models", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.HC cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Tuning machine learning models, particularly deep learning architectures, is\na complex process. Automated hyperparameter tuning algorithms often depend on\nspecific optimization metrics. However, in many situations, a developer trades\none metric against another: accuracy versus overfitting, precision versus\nrecall, smaller models and accuracy, etc. With deep learning, not only are the\nmodel's representations opaque, the model's behavior when parameters \"knobs\"\nare changed may also be unpredictable. Thus, picking the \"best\" model often\nrequires time-consuming model comparison. In this work, we introduce LAMVI-2, a\nvisual analytics system to support a developer in comparing hyperparameter\nsettings and outcomes. By focusing on word-embedding models (\"deep learning for\ntext\") we integrate views to compare both high-level statistics as well as\ninternal model behaviors (e.g., comparing word 'distances'). We demonstrate how\ndevelopers can work with LAMVI-2 to more quickly and accurately narrow down an\nappropriate and effective application-specific model.\n", "versions": [{"version": "v1", "created": "Mon, 22 Oct 2018 20:05:42 GMT"}], "update_date": "2018-10-29", "authors_parsed": [["Rong", "Xin", ""], ["Luckson", "Joshua", ""], ["Adar", "Eytan", ""]]}, {"id": "1810.11378", "submitter": "Jaime Roquero Gimenez", "authors": "Jaime Roquero Gimenez, James Zou", "title": "Improving the Stability of the Knockoff Procedure: Multiple Simultaneous\n  Knockoffs and Entropy Maximization", "comments": "Accepted at AISTATS 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The Model-X knockoff procedure has recently emerged as a powerful approach\nfor feature selection with statistical guarantees. The advantage of knockoff is\nthat if we have a good model of the features X, then we can identify salient\nfeatures without knowing anything about how the outcome Y depends on X. An\nimportant drawback of knockoffs is its instability: running the procedure twice\ncan result in very different selected features, potentially leading to\ndifferent conclusions. Addressing this instability is critical for obtaining\nreproducible and robust results. Here we present a generalization of the\nknockoff procedure that we call simultaneous multi-knockoffs. We show that\nmulti-knockoff guarantees false discovery rate (FDR) control, and is\nsubstantially more stable and powerful compared to the standard (single)\nknockoff. Moreover we propose a new algorithm based on entropy maximization for\ngenerating Gaussian multi-knockoffs. We validate the improved stability and\npower of multi-knockoffs in systematic experiments. We also illustrate how\nmulti-knockoffs can improve the accuracy of detecting genetic mutations that\nare causally linked to phenotypes.\n", "versions": [{"version": "v1", "created": "Fri, 26 Oct 2018 15:21:50 GMT"}, {"version": "v2", "created": "Wed, 29 May 2019 01:43:59 GMT"}], "update_date": "2019-05-30", "authors_parsed": [["Gimenez", "Jaime Roquero", ""], ["Zou", "James", ""]]}, {"id": "1810.11383", "submitter": "Milan Cvitkovic", "authors": "Milan Cvitkovic", "title": "Some Requests for Machine Learning Research from the East African Tech\n  Scene", "comments": "Presented at NIPS 2018 Workshop on Machine Learning for the\n  Developing World", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CY stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Based on 46 in-depth interviews with scientists, engineers, and CEOs, this\ndocument presents a list of concrete machine research problems, progress on\nwhich would directly benefit tech ventures in East Africa.\n", "versions": [{"version": "v1", "created": "Thu, 25 Oct 2018 02:53:14 GMT"}, {"version": "v2", "created": "Thu, 8 Nov 2018 01:03:50 GMT"}], "update_date": "2018-11-09", "authors_parsed": [["Cvitkovic", "Milan", ""]]}, {"id": "1810.11388", "submitter": "Muhammad Burhan Hafez", "authors": "Muhammad Burhan Hafez, Cornelius Weber, Matthias Kerzel, Stefan\n  Wermter", "title": "Deep Intrinsically Motivated Continuous Actor-Critic for Efficient\n  Robotic Visuomotor Skill Learning", "comments": null, "journal-ref": "Paladyn, Journal of Behavioral Robotics, Volume 10, Issue 1, Pages\n  14-29, 2019", "doi": "10.1515/pjbr-2019-0005", "report-no": null, "categories": "cs.LG cs.AI cs.RO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we present a new intrinsically motivated actor-critic\nalgorithm for learning continuous motor skills directly from raw visual input.\nOur neural architecture is composed of a critic and an actor network. Both\nnetworks receive the hidden representation of a deep convolutional autoencoder\nwhich is trained to reconstruct the visual input, while the centre-most hidden\nrepresentation is also optimized to estimate the state value. Separately, an\nensemble of predictive world models generates, based on its learning progress,\nan intrinsic reward signal which is combined with the extrinsic reward to guide\nthe exploration of the actor-critic learner. Our approach is more\ndata-efficient and inherently more stable than the existing actor-critic\nmethods for continuous control from pixel data. We evaluate our algorithm for\nthe task of learning robotic reaching and grasping skills on a realistic\nphysics simulator and on a humanoid robot. The results show that the control\npolicies learned with our approach can achieve better performance than the\ncompared state-of-the-art and baseline algorithms in both dense-reward and\nchallenging sparse-reward settings.\n", "versions": [{"version": "v1", "created": "Fri, 26 Oct 2018 15:32:32 GMT"}, {"version": "v2", "created": "Mon, 18 Feb 2019 10:54:46 GMT"}], "update_date": "2019-02-19", "authors_parsed": [["Hafez", "Muhammad Burhan", ""], ["Weber", "Cornelius", ""], ["Kerzel", "Matthias", ""], ["Wermter", "Stefan", ""]]}, {"id": "1810.11393", "submitter": "Jo\\~ao Sacramento", "authors": "Jo\\~ao Sacramento, Rui Ponte Costa, Yoshua Bengio, Walter Senn", "title": "Dendritic cortical microcircuits approximate the backpropagation\n  algorithm", "comments": "To appear in Advances in Neural Information Processing Systems 31\n  (NIPS 2018). 12 pages, 3 figures, 9 pages of supplementary material (2\n  supplementary figures)", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.NC cs.LG cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep learning has seen remarkable developments over the last years, many of\nthem inspired by neuroscience. However, the main learning mechanism behind\nthese advances - error backpropagation - appears to be at odds with\nneurobiology. Here, we introduce a multilayer neuronal network model with\nsimplified dendritic compartments in which error-driven synaptic plasticity\nadapts the network towards a global desired output. In contrast to previous\nwork our model does not require separate phases and synaptic learning is driven\nby local dendritic prediction errors continuously in time. Such errors\noriginate at apical dendrites and occur due to a mismatch between predictive\ninput from lateral interneurons and activity from actual top-down feedback.\nThrough the use of simple dendritic compartments and different cell-types our\nmodel can represent both error and normal activity within a pyramidal neuron.\nWe demonstrate the learning capabilities of the model in regression and\nclassification tasks, and show analytically that it approximates the error\nbackpropagation algorithm. Moreover, our framework is consistent with recent\nobservations of learning between brain areas and the architecture of cortical\nmicrocircuits. Overall, we introduce a novel view of learning on dendritic\ncortical circuits and on how the brain may solve the long-standing synaptic\ncredit assignment problem.\n", "versions": [{"version": "v1", "created": "Fri, 26 Oct 2018 15:40:58 GMT"}], "update_date": "2018-10-29", "authors_parsed": [["Sacramento", "Jo\u00e3o", ""], ["Costa", "Rui Ponte", ""], ["Bengio", "Yoshua", ""], ["Senn", "Walter", ""]]}, {"id": "1810.11414", "submitter": "Durmus Sahin", "authors": "Durmus Ozkan Sahin, Oguz Emre Kural, Erdal Kilic, Armagan Karabina", "title": "A Text Classification Application: Poet Detection from Poetry", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.CL cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  With the widespread use of the internet, the size of the text data increases\nday by day. Poems can be given as an example of the growing text. In this\nstudy, we aim to classify poetry according to poet. Firstly, data set\nconsisting of three different poetry of poets written in English have been\nconstructed. Then, text categorization techniques are implemented on it.\nChi-Square technique are used for feature selection. In addition, five\ndifferent classification algorithms are tried. These algorithms are Sequential\nminimal optimization, Naive Bayes, C4.5 decision tree, Random Forest and\nk-nearest neighbors. Although each classifier showed very different results,\nover the 70% classification success rate was taken by sequential minimal\noptimization technique.\n", "versions": [{"version": "v1", "created": "Wed, 24 Oct 2018 17:44:57 GMT"}], "update_date": "2018-10-29", "authors_parsed": [["Sahin", "Durmus Ozkan", ""], ["Kural", "Oguz Emre", ""], ["Kilic", "Erdal", ""], ["Karabina", "Armagan", ""]]}, {"id": "1810.11428", "submitter": "Matthias Bauer", "authors": "Matthias Bauer and Andriy Mnih", "title": "Resampled Priors for Variational Autoencoders", "comments": null, "journal-ref": "Proceedings of the 22nd International Conference on Artificial\n  Intelligence and Statistics (AISTATS) 2019", "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose Learned Accept/Reject Sampling (LARS), a method for constructing\nricher priors using rejection sampling with a learned acceptance function. This\nwork is motivated by recent analyses of the VAE objective, which pointed out\nthat commonly used simple priors can lead to underfitting. As the distribution\ninduced by LARS involves an intractable normalizing constant, we show how to\nestimate it and its gradients efficiently. We demonstrate that LARS priors\nimprove VAE performance on several standard datasets both when they are learned\njointly with the rest of the model and when they are fitted to a pretrained\nmodel. Finally, we show that LARS can be combined with existing methods for\ndefining flexible priors for an additional boost in performance.\n", "versions": [{"version": "v1", "created": "Fri, 26 Oct 2018 17:17:48 GMT"}, {"version": "v2", "created": "Fri, 26 Apr 2019 09:35:33 GMT"}], "update_date": "2019-04-29", "authors_parsed": [["Bauer", "Matthias", ""], ["Mnih", "Andriy", ""]]}, {"id": "1810.11447", "submitter": "Karren Yang", "authors": "Karren D. Yang and Caroline Uhler", "title": "Scalable Unbalanced Optimal Transport using Generative Adversarial\n  Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Generative adversarial networks (GANs) are an expressive class of neural\ngenerative models with tremendous success in modeling high-dimensional\ncontinuous measures. In this paper, we present a scalable method for unbalanced\noptimal transport (OT) based on the generative-adversarial framework. We\nformulate unbalanced OT as a problem of simultaneously learning a transport map\nand a scaling factor that push a source measure to a target measure in a\ncost-optimal manner. In addition, we propose an algorithm for solving this\nproblem based on stochastic alternating gradient updates, similar in practice\nto GANs. We also provide theoretical justification for this formulation,\nshowing that it is closely related to an existing static formulation by Liero\net al. (2018), and perform numerical experiments demonstrating how this\nmethodology can be applied to population modeling.\n", "versions": [{"version": "v1", "created": "Fri, 26 Oct 2018 17:53:08 GMT"}, {"version": "v2", "created": "Sun, 4 Aug 2019 00:26:49 GMT"}], "update_date": "2019-08-06", "authors_parsed": [["Yang", "Karren D.", ""], ["Uhler", "Caroline", ""]]}, {"id": "1810.11479", "submitter": "Changjian Shui", "authors": "Changjian Shui, Ihsen Hedhli, Christian Gagn\\'e", "title": "Accumulating Knowledge for Lifelong Online Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Lifelong learning can be viewed as a continuous transfer learning procedure\nover consecutive tasks, where learning a given task depends on accumulated\nknowledge --- the so-called knowledge base. Most published work on lifelong\nlearning makes a batch processing of each task, implying that a data collection\nstep is required beforehand. We are proposing a new framework, lifelong online\nlearning, in which the learning procedure for each task is interactive. This is\ndone through a computationally efficient algorithm where the predicted result\nfor a given task is made by combining two intermediate predictions: by using\nonly the information from the current task and by relying on the accumulated\nknowledge. In this work, two challenges are tackled: making no assumption on\nthe task generation distribution, and processing with a possibly unknown number\nof instances for each task. We are providing a theoretical analysis of this\nalgorithm, with a cumulative error upper bound for each task. We find that\nunder some mild conditions, the algorithm can still benefit from a small\ncumulative error even when facing few interactions. Moreover, we provide\nexperimental results on both synthetic and real datasets that validate the\ncorrect behavior and practical usefulness of the proposed algorithm.\n", "versions": [{"version": "v1", "created": "Fri, 26 Oct 2018 18:18:36 GMT"}], "update_date": "2018-10-30", "authors_parsed": [["Shui", "Changjian", ""], ["Hedhli", "Ihsen", ""], ["Gagn\u00e9", "Christian", ""]]}, {"id": "1810.11491", "submitter": "Alexander Fabisch", "authors": "Alexander Fabisch", "title": "Empirical Evaluation of Contextual Policy Search with a Comparison-based\n  Surrogate Model and Active Covariance Matrix Adaptation", "comments": "Supplementary material for poster paper accepted at GECCO 2019;\n  https://doi.org/10.1145/3319619.3321935", "journal-ref": null, "doi": "10.1145/3319619.3321935", "report-no": null, "categories": "cs.LG cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Contextual policy search (CPS) is a class of multi-task reinforcement\nlearning algorithms that is particularly useful for robotic applications. A\nrecent state-of-the-art method is Contextual Covariance Matrix Adaptation\nEvolution Strategies (C-CMA-ES). It is based on the standard black-box\noptimization algorithm CMA-ES. There are two useful extensions of CMA-ES that\nwe will transfer to C-CMA-ES and evaluate empirically: ACM-ES, which uses a\ncomparison-based surrogate model, and aCMA-ES, which uses an active update of\nthe covariance matrix. We will show that improvements with these methods can be\nimpressive in terms of sample-efficiency, although this is not relevant any\nmore for the robotic domain.\n", "versions": [{"version": "v1", "created": "Fri, 26 Oct 2018 18:35:27 GMT"}, {"version": "v2", "created": "Sun, 14 Apr 2019 21:20:16 GMT"}], "update_date": "2019-04-16", "authors_parsed": [["Fabisch", "Alexander", ""]]}, {"id": "1810.11497", "submitter": "Sanchit Agarwal", "authors": "Sanchit Agarwal, Rahul Goel, Tagyoung Chung, Abhishek Sethi, Arindam\n  Mandal, Spyros Matsoukas", "title": "Parsing Coordination for Spoken Language Understanding", "comments": "The paper was published in SLT 2018 conference", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Typical spoken language understanding systems provide narrow semantic parses\nusing a domain-specific ontology. The parses contain intents and slots that are\ndirectly consumed by downstream domain applications. In this work we discuss\nexpanding such systems to handle compound entities and intents by introducing a\ndomain-agnostic shallow parser that handles linguistic coordination. We show\nthat our model for parsing coordination learns domain-independent and\nslot-independent features and is able to segment conjunct boundaries of many\ndifferent phrasal categories. We also show that using adversarial training can\nbe effective for improving generalization across different slot types for\ncoordination parsing.\n", "versions": [{"version": "v1", "created": "Fri, 26 Oct 2018 18:44:52 GMT"}], "update_date": "2018-10-30", "authors_parsed": [["Agarwal", "Sanchit", ""], ["Goel", "Rahul", ""], ["Chung", "Tagyoung", ""], ["Sethi", "Abhishek", ""], ["Mandal", "Arindam", ""], ["Matsoukas", "Spyros", ""]]}, {"id": "1810.11499", "submitter": "Parinaz Farajiparvar", "authors": "Parinaz Farajiparvar, Ahmad Beirami, Matthew Nokleby", "title": "Information Bottleneck Methods for Distributed Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IT cs.LG math.IT", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We study a distributed learning problem in which Alice sends a compressed\ndistillation of a set of training data to Bob, who uses the distilled version\nto best solve an associated learning problem. We formalize this as a\nrate-distortion problem in which the training set is the source and Bob's\ncross-entropy loss is the distortion measure. We consider this problem for\nunsupervised learning for batch and sequential data. In the batch data, this\nproblem is equivalent to the information bottleneck (IB), and we show that\nreduced-complexity versions of standard IB methods solve the associated\nrate-distortion problem. For the streaming data, we present a new algorithm,\nwhich may be of independent interest, that solves the rate-distortion problem\nfor Gaussian sources. Furthermore, to improve the results of the iterative\nalgorithm for sequential data we introduce a two-pass version of this\nalgorithm. Finally, we show the dependency of the rate on the number of samples\n$k$ required for Gaussian sources to ensure cross-entropy loss that scales\noptimally with the growth of the training set.\n", "versions": [{"version": "v1", "created": "Fri, 26 Oct 2018 18:48:24 GMT"}], "update_date": "2018-10-30", "authors_parsed": [["Farajiparvar", "Parinaz", ""], ["Beirami", "Ahmad", ""], ["Nokleby", "Matthew", ""]]}, {"id": "1810.11505", "submitter": "Ming Jin", "authors": "Ming Jin and Javad Lavaei", "title": "Stability-certified reinforcement learning: A control-theoretic\n  perspective", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SY cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We investigate the important problem of certifying stability of reinforcement\nlearning policies when interconnected with nonlinear dynamical systems. We show\nthat by regulating the input-output gradients of policies, strong guarantees of\nrobust stability can be obtained based on a proposed semidefinite programming\nfeasibility problem. The method is able to certify a large set of stabilizing\ncontrollers by exploiting problem-specific structures; furthermore, we analyze\nand establish its (non)conservatism. Empirical evaluations on two decentralized\ncontrol tasks, namely multi-flight formation and power system frequency\nregulation, demonstrate that the reinforcement learning agents can have high\nperformance within the stability-certified parameter space, and also exhibit\nstable learning behaviors in the long run.\n", "versions": [{"version": "v1", "created": "Fri, 26 Oct 2018 18:57:35 GMT"}], "update_date": "2018-10-30", "authors_parsed": [["Jin", "Ming", ""], ["Lavaei", "Javad", ""]]}, {"id": "1810.11507", "submitter": "Majid Jahani", "authors": "Majid Jahani, Xi He, Chenxin Ma, Aryan Mokhtari, Dheevatsa Mudigere,\n  Alejandro Ribeiro, and Martin Tak\\'a\\v{c}", "title": "Efficient Distributed Hessian Free Algorithm for Large-scale Empirical\n  Risk Minimization via Accumulating Sample Strategy", "comments": "Updated numerical results", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we propose a Distributed Accumulated Newton Conjugate gradiEnt\n(DANCE) method in which sample size is gradually increasing to quickly obtain a\nsolution whose empirical loss is under satisfactory statistical accuracy. Our\nproposed method is multistage in which the solution of a stage serves as a warm\nstart for the next stage which contains more samples (including the samples in\nthe previous stage). The proposed multistage algorithm reduces the number of\npasses over data to achieve the statistical accuracy of the full training set.\nMoreover, our algorithm in nature is easy to be distributed and shares the\nstrong scaling property indicating that acceleration is always expected by\nusing more computing nodes. Various iteration complexity results regarding\ndescent direction computation, communication efficiency and stopping criteria\nare analyzed under convex setting. Our numerical results illustrate that the\nproposed method outperforms other comparable methods for solving learning\nproblems including neural networks.\n", "versions": [{"version": "v1", "created": "Fri, 26 Oct 2018 19:06:36 GMT"}, {"version": "v2", "created": "Tue, 10 Mar 2020 02:41:37 GMT"}], "update_date": "2020-03-11", "authors_parsed": [["Jahani", "Majid", ""], ["He", "Xi", ""], ["Ma", "Chenxin", ""], ["Mokhtari", "Aryan", ""], ["Mudigere", "Dheevatsa", ""], ["Ribeiro", "Alejandro", ""], ["Tak\u00e1\u010d", "Martin", ""]]}, {"id": "1810.11514", "submitter": "Alessandro Tibo", "authors": "Alessandro Tibo, Manfred Jaeger, Paolo Frasconi", "title": "Learning and Interpreting Multi-Multi-Instance Learning Networks", "comments": "JMLR", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce an extension of the multi-instance learning problem where\nexamples are organized as nested bags of instances (e.g., a document could be\nrepresented as a bag of sentences, which in turn are bags of words). This\nframework can be useful in various scenarios, such as text and image\nclassification, but also supervised learning over graphs. As a further\nadvantage, multi-multi instance learning enables a particular way of\ninterpreting predictions and the decision function. Our approach is based on a\nspecial neural network layer, called bag-layer, whose units aggregate bags of\ninputs of arbitrary size. We prove theoretically that the associated class of\nfunctions contains all Boolean functions over sets of sets of instances and we\nprovide empirical evidence that functions of this kind can be actually learned\non semi-synthetic datasets. We finally present experiments on text\nclassification, on citation graphs, and social graph data, which show that our\nmodel obtains competitive results with respect to accuracy when compared to\nother approaches such as convolutional networks on graphs, while at the same\ntime it supports a general approach to interpret the learnt model, as well as\nexplain individual predictions.\n", "versions": [{"version": "v1", "created": "Fri, 26 Oct 2018 19:46:12 GMT"}, {"version": "v2", "created": "Fri, 30 Nov 2018 17:11:46 GMT"}, {"version": "v3", "created": "Wed, 13 May 2020 13:40:14 GMT"}, {"version": "v4", "created": "Sat, 3 Oct 2020 14:48:07 GMT"}], "update_date": "2020-10-06", "authors_parsed": [["Tibo", "Alessandro", ""], ["Jaeger", "Manfred", ""], ["Frasconi", "Paolo", ""]]}, {"id": "1810.11520", "submitter": "Jaehoon Oh", "authors": "Jaehoon Oh, Duyeon Kim, and Se-Young Yun", "title": "Spectrogram-channels u-net: a source separation model viewing each\n  channel as the spectrogram of each source", "comments": "3 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SD cs.LG eess.AS eess.SP stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Sound source separation has attracted attention from Music Information\nRetrieval(MIR) researchers, since it is related to many MIR tasks such as\nautomatic lyric transcription, singer identification, and voice conversion. In\nthis paper, we propose an intuitive spectrogram-based model for source\nseparation by adapting U-Net. We call it Spectrogram-Channels U-Net, which\nmeans each channel of the output corresponds to the spectrogram of separated\nsource itself. The proposed model can be used for not only singing voice\nseparation but also multi-instrument separation by changing only the number of\noutput channels. In addition, we propose a loss function that balances volumes\nbetween different sources. Finally, we yield performance that is\nstate-of-the-art on both separation tasks.\n", "versions": [{"version": "v1", "created": "Fri, 26 Oct 2018 20:23:17 GMT"}, {"version": "v2", "created": "Tue, 30 Oct 2018 15:08:52 GMT"}], "update_date": "2018-10-31", "authors_parsed": [["Oh", "Jaehoon", ""], ["Kim", "Duyeon", ""], ["Yun", "Se-Young", ""]]}, {"id": "1810.11521", "submitter": "William Severa", "authors": "William Severa, Craig M. Vineyard, Ryan Dellana, Stephen J. Verzi,\n  James B. Aimone", "title": "Whetstone: A Method for Training Deep Artificial Neural Networks for\n  Binary Communication", "comments": null, "journal-ref": null, "doi": "10.1038/s42256-018-0015-y", "report-no": null, "categories": "cs.NE cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper presents a new technique for training networks for low-precision\ncommunication. Targeting minimal communication between nodes not only enables\nthe use of emerging spiking neuromorphic platforms, but may additionally\nstreamline processing conventionally. Low-power and embedded neuromorphic\nprocessors potentially offer dramatic performance-per-Watt improvements over\ntraditional von Neumann processors, however programming these brain-inspired\nplatforms generally requires platform-specific expertise which limits their\napplicability. To date, the majority of artificial neural networks have not\noperated using discrete spike-like communication.\n  We present a method for training deep spiking neural networks using an\niterative modification of the backpropagation optimization algorithm. This\nmethod, which we call Whetstone, effectively and reliably configures a network\nfor a spiking hardware target with little, if any, loss in performance.\nWhetstone networks use single time step binary communication and do not require\na rate code or other spike-based coding scheme, thus producing networks\ncomparable in timing and size to conventional ANNs, albeit with binarized\ncommunication. We demonstrate Whetstone on a number of image classification\nnetworks, describing how the sharpening process interacts with different\ntraining optimizers and changes the distribution of activity within the\nnetwork. We further note that Whetstone is compatible with several\nnon-classification neural network applications, such as autoencoders and\nsemantic segmentation. Whetstone is widely extendable and currently implemented\nusing custom activation functions within the Keras wrapper to the popular\nTensorFlow machine learning framework.\n", "versions": [{"version": "v1", "created": "Fri, 26 Oct 2018 20:24:02 GMT"}], "update_date": "2019-01-29", "authors_parsed": [["Severa", "William", ""], ["Vineyard", "Craig M.", ""], ["Dellana", "Ryan", ""], ["Verzi", "Stephen J.", ""], ["Aimone", "James B.", ""]]}, {"id": "1810.11530", "submitter": "Pascal Lamblin", "authors": "Bart van Merri\\\"enboer, Olivier Breuleux, Arnaud Bergeron, Pascal\n  Lamblin", "title": "Automatic differentiation in ML: Where we are and where we should be\n  going", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.PL stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We review the current state of automatic differentiation (AD) for array\nprogramming in machine learning (ML), including the different approaches such\nas operator overloading (OO) and source transformation (ST) used for AD,\ngraph-based intermediate representations for programs, and source languages.\nBased on these insights, we introduce a new graph-based intermediate\nrepresentation (IR) which specifically aims to efficiently support\nfully-general AD for array programming. Unlike existing dataflow programming\nrepresentations in ML frameworks, our IR naturally supports function calls,\nhigher-order functions and recursion, making ML models easier to implement. The\nability to represent closures allows us to perform AD using ST without a tape,\nmaking the resulting derivative (adjoint) program amenable to ahead-of-time\noptimization using tools from functional language compilers, and enabling\nhigher-order derivatives. Lastly, we introduce a proof of concept compiler\ntoolchain called Myia which uses a subset of Python as a front end.\n", "versions": [{"version": "v1", "created": "Fri, 26 Oct 2018 21:09:07 GMT"}, {"version": "v2", "created": "Wed, 2 Jan 2019 21:16:54 GMT"}], "update_date": "2019-01-04", "authors_parsed": [["van Merri\u00ebnboer", "Bart", ""], ["Breuleux", "Olivier", ""], ["Bergeron", "Arnaud", ""], ["Lamblin", "Pascal", ""]]}, {"id": "1810.11536", "submitter": "Zhihao Zhu", "authors": "Zhihao Zhu, Zhan Xue, Zejian Yuan", "title": "Automatic Graphics Program Generation using Attention-Based Hierarchical\n  Decoder", "comments": "Asian Conference on Computer Vision", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.GR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent progress on deep learning has made it possible to automatically\ntransform the screenshot of Graphic User Interface (GUI) into code by using the\nencoder-decoder framework. While the commonly adopted image encoder (e.g., CNN\nnetwork), might be capable of extracting image features to the desired level,\ninterpreting these abstract image features into hundreds of tokens of code puts\na particular challenge on the decoding power of the RNN-based code generator.\nConsidering the code used for describing GUI is usually hierarchically\nstructured, we propose a new attention-based hierarchical code generation\nmodel, which can describe GUI images in a finer level of details, while also\nbeing able to generate hierarchically structured code in consistency with the\nhierarchical layout of the graphic elements in the GUI. Our model follows the\nencoder-decoder framework, all the components of which can be trained jointly\nin an end-to-end manner. The experimental results show that our method\noutperforms other current state-of-the-art methods on both a publicly available\nGUI-code dataset as well as a dataset established by our own.\n", "versions": [{"version": "v1", "created": "Fri, 26 Oct 2018 21:28:10 GMT"}], "update_date": "2018-10-30", "authors_parsed": [["Zhu", "Zhihao", ""], ["Xue", "Zhan", ""], ["Yuan", "Zejian", ""]]}, {"id": "1810.11544", "submitter": "Anton Osokin", "authors": "Kirill Struminsky, Simon Lacoste-Julien, Anton Osokin", "title": "Quantifying Learning Guarantees for Convex but Inconsistent Surrogates", "comments": "Appears in: Advances in Neural Information Processing Systems 31\n  (NeurIPS 2018). 18 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study consistency properties of machine learning methods based on\nminimizing convex surrogates. We extend the recent framework of Osokin et al.\n(2017) for the quantitative analysis of consistency properties to the case of\ninconsistent surrogates. Our key technical contribution consists in a new lower\nbound on the calibration function for the quadratic surrogate, which is\nnon-trivial (not always zero) for inconsistent cases. The new bound allows to\nquantify the level of inconsistency of the setting and shows how learning with\ninconsistent surrogates can have guarantees on sample complexity and\noptimization difficulty. We apply our theory to two concrete cases: multi-class\nclassification with the tree-structured loss and ranking with the mean average\nprecision loss. The results show the approximation-computation trade-offs\ncaused by inconsistent surrogates and their potential benefits.\n", "versions": [{"version": "v1", "created": "Fri, 26 Oct 2018 22:10:48 GMT"}, {"version": "v2", "created": "Wed, 9 Jan 2019 08:47:58 GMT"}], "update_date": "2019-01-10", "authors_parsed": [["Struminsky", "Kirill", ""], ["Lacoste-Julien", "Simon", ""], ["Osokin", "Anton", ""]]}, {"id": "1810.11546", "submitter": "Mohammad Malekzadeh", "authors": "Mohammad Malekzadeh, Richard G. Clegg, Andrea Cavallaro, Hamed Haddadi", "title": "Mobile Sensor Data Anonymization", "comments": "10 pages", "journal-ref": null, "doi": "10.1145/3302505.3310068", "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Motion sensors such as accelerometers and gyroscopes measure the instant\nacceleration and rotation of a device, in three dimensions. Raw data streams\nfrom motion sensors embedded in portable and wearable devices may reveal\nprivate information about users without their awareness. For example, motion\ndata might disclose the weight or gender of a user, or enable their\nre-identification. To address this problem, we propose an on-device\ntransformation of sensor data to be shared for specific applications, such as\nmonitoring selected daily activities, without revealing information that\nenables user identification. We formulate the anonymization problem using an\ninformation-theoretic approach and propose a new multi-objective loss function\nfor training deep autoencoders. This loss function helps minimizing\nuser-identity information as well as data distortion to preserve the\napplication-specific utility. The training process regulates the encoder to\ndisregard user-identifiable patterns and tunes the decoder to shape the output\nindependently of users in the training set. The trained autoencoder can be\ndeployed on a mobile or wearable device to anonymize sensor data even for users\nwho are not included in the training dataset. Data from 24 users transformed by\nthe proposed anonymizing autoencoder lead to a promising trade-off between\nutility and privacy, with an accuracy for activity recognition above 92% and an\naccuracy for user identification below 7%.\n", "versions": [{"version": "v1", "created": "Fri, 26 Oct 2018 22:26:31 GMT"}, {"version": "v2", "created": "Mon, 19 Nov 2018 16:08:44 GMT"}, {"version": "v3", "created": "Mon, 18 Feb 2019 23:58:38 GMT"}], "update_date": "2019-02-20", "authors_parsed": [["Malekzadeh", "Mohammad", ""], ["Clegg", "Richard G.", ""], ["Cavallaro", "Andrea", ""], ["Haddadi", "Hamed", ""]]}, {"id": "1810.11558", "submitter": "Humberto Gonzalez", "authors": "Qingzhu Gao, Humberto Gonzalez, and Parvez Ahammad", "title": "MCA-based Rule Mining Enables Interpretable Inference in Clinical\n  Psychiatry", "comments": null, "journal-ref": null, "doi": "10.1007/978-3-030-24409-5_3", "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Development of interpretable machine learning models for clinical healthcare\napplications has the potential of changing the way we understand, treat, and\nultimately cure, diseases and disorders in many areas of medicine. These models\ncan serve not only as sources of predictions and estimates, but also as\ndiscovery tools for clinicians and researchers to reveal new knowledge from the\ndata. High dimensionality of patient information (e.g., phenotype, genotype,\nand medical history), lack of objective measurements, and the heterogeneity in\npatient populations often create significant challenges in developing\ninterpretable machine learning models for clinical psychiatry in practice. In\nthis paper we take a step towards the development of such interpretable models.\nFirst, by developing a novel categorical rule mining method based on\nMultivariate Correspondence Analysis (MCA) capable of handling datasets with\nlarge numbers of features, and second, by applying this method to build\ntransdiagnostic Bayesian Rule List models to screen for psychiatric disorders\nusing the Consortium for Neuropsychiatric Phenomics dataset. We show that our\nmethod is not only at least 100 times faster than state-of-the-art rule mining\ntechniques for datasets with 50 features, but also provides interpretability\nand comparable prediction accuracy across several benchmark datasets.\n", "versions": [{"version": "v1", "created": "Fri, 26 Oct 2018 23:51:08 GMT"}, {"version": "v2", "created": "Sun, 16 Dec 2018 22:44:07 GMT"}], "update_date": "2019-08-06", "authors_parsed": [["Gao", "Qingzhu", ""], ["Gonzalez", "Humberto", ""], ["Ahammad", "Parvez", ""]]}, {"id": "1810.11562", "submitter": "Henry Kvinge", "authors": "Henry Kvinge, Elin Farnell, Michael Kirby, Chris Peterson", "title": "Monitoring the shape of weather, soundscapes, and dynamical systems: a\n  new statistic for dimension-driven data analysis on large data sets", "comments": "Accepted to the 2018 IEEE International Conference on BIG DATA, 9\n  pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV physics.data-an stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Dimensionality-reduction methods are a fundamental tool in the analysis of\nlarge data sets. These algorithms work on the assumption that the \"intrinsic\ndimension\" of the data is generally much smaller than the ambient dimension in\nwhich it is collected. Alongside their usual purpose of mapping data into a\nsmaller dimension with minimal information loss, dimensionality-reduction\ntechniques implicitly or explicitly provide information about the dimension of\nthe data set.\n  In this paper, we propose a new statistic that we call the $\\kappa$-profile\nfor analysis of large data sets. The $\\kappa$-profile arises from a\ndimensionality-reduction optimization problem: namely that of finding a\nprojection into $k$-dimensions that optimally preserves the secants between\npoints in the data set. From this optimal projection we extract $\\kappa,$ the\nnorm of the shortest projected secant from among the set of all normalized\nsecants. This $\\kappa$ can be computed for any $k$; thus the tuple of $\\kappa$\nvalues (indexed by dimension) becomes a $\\kappa$-profile. Algorithms such as\nthe Secant-Avoidance Projection algorithm and the Hierarchical Secant-Avoidance\nProjection algorithm, provide a computationally feasible means of estimating\nthe $\\kappa$-profile for large data sets, and thus a method of understanding\nand monitoring their behavior. As we demonstrate in this paper, the\n$\\kappa$-profile serves as a useful statistic in several representative\nsettings: weather data, soundscape data, and dynamical systems data.\n", "versions": [{"version": "v1", "created": "Sat, 27 Oct 2018 00:15:34 GMT"}], "update_date": "2018-10-30", "authors_parsed": [["Kvinge", "Henry", ""], ["Farnell", "Elin", ""], ["Kirby", "Michael", ""], ["Peterson", "Chris", ""]]}, {"id": "1810.11571", "submitter": "Puning Zhao", "authors": "Puning Zhao and Lifeng Lai", "title": "Analysis of KNN Information Estimators for Smooth Distributions", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.IT cs.LG math.IT math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  KSG mutual information estimator, which is based on the distances of each\nsample to its k-th nearest neighbor, is widely used to estimate mutual\ninformation between two continuous random variables. Existing work has analyzed\nthe convergence rate of this estimator for random variables whose densities are\nbounded away from zero in its support. In practice, however, KSG estimator also\nperforms well for a much broader class of distributions, including not only\nthose with bounded support and densities bounded away from zero, but also those\nwith bounded support but densities approaching zero, and those with unbounded\nsupport. In this paper, we analyze the convergence rate of the error of KSG\nestimator for smooth distributions, whose support of density can be both\nbounded and unbounded. As KSG mutual information estimator can be viewed as an\nadaptive recombination of KL entropy estimators, in our analysis, we also\nprovide convergence analysis of KL entropy estimator for a broad class of\ndistributions.\n", "versions": [{"version": "v1", "created": "Sat, 27 Oct 2018 00:56:28 GMT"}, {"version": "v2", "created": "Fri, 26 Apr 2019 06:55:13 GMT"}, {"version": "v3", "created": "Thu, 24 Oct 2019 22:28:40 GMT"}], "update_date": "2019-10-28", "authors_parsed": [["Zhao", "Puning", ""], ["Lai", "Lifeng", ""]]}, {"id": "1810.11573", "submitter": "Fuad Noman", "authors": "Fuad Noman, Chee-Ming Ting, Sh-Hussain Salleh, and Hernando Ombao", "title": "Short-segment heart sound classification using an ensemble of deep\n  convolutional neural networks", "comments": "8 pages, 1 figure, conference", "journal-ref": null, "doi": "10.1109/ICASSP.2019.8682668", "report-no": null, "categories": "cs.SD cs.LG eess.AS eess.SP stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper proposes a framework based on deep convolutional neural networks\n(CNNs) for automatic heart sound classification using short-segments of\nindividual heart beats. We design a 1D-CNN that directly learns features from\nraw heart-sound signals, and a 2D-CNN that takes inputs of two- dimensional\ntime-frequency feature maps based on Mel-frequency cepstral coefficients\n(MFCC). We further develop a time-frequency CNN ensemble (TF-ECNN) combining\nthe 1D-CNN and 2D-CNN based on score-level fusion of the class probabilities.\nOn the large PhysioNet CinC challenge 2016 database, the proposed CNN models\noutperformed traditional classifiers based on support vector machine and hidden\nMarkov models with various hand-crafted time- and frequency-domain features.\nBest classification scores with 89.22% accuracy and 89.94% sensitivity were\nachieved by the ECNN, and 91.55% specificity and 88.82% modified accuracy by\nthe 2D-CNN alone on the test set.\n", "versions": [{"version": "v1", "created": "Sat, 27 Oct 2018 01:32:27 GMT"}], "update_date": "2020-04-27", "authors_parsed": [["Noman", "Fuad", ""], ["Ting", "Chee-Ming", ""], ["Salleh", "Sh-Hussain", ""], ["Ombao", "Hernando", ""]]}, {"id": "1810.11580", "submitter": "Guanhong Tao", "authors": "Guanhong Tao, Shiqing Ma, Yingqi Liu, Xiangyu Zhang", "title": "Attacks Meet Interpretability: Attribute-steered Detection of\n  Adversarial Samples", "comments": "Accepted to NIPS 2018 Spotlight", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Adversarial sample attacks perturb benign inputs to induce DNN misbehaviors.\nRecent research has demonstrated the widespread presence and the devastating\nconsequences of such attacks. Existing defense techniques either assume prior\nknowledge of specific attacks or may not work well on complex models due to\ntheir underlying assumptions. We argue that adversarial sample attacks are\ndeeply entangled with interpretability of DNN models: while classification\nresults on benign inputs can be reasoned based on the human perceptible\nfeatures/attributes, results on adversarial samples can hardly be explained.\nTherefore, we propose a novel adversarial sample detection technique for face\nrecognition models, based on interpretability. It features a novel\nbi-directional correspondence inference between attributes and internal neurons\nto identify neurons critical for individual attributes. The activation values\nof critical neurons are enhanced to amplify the reasoning part of the\ncomputation and the values of other neurons are weakened to suppress the\nuninterpretable part. The classification results after such transformation are\ncompared with those of the original model to detect adversaries. Results show\nthat our technique can achieve 94% detection accuracy for 7 different kinds of\nattacks with 9.91% false positives on benign inputs. In contrast, a\nstate-of-the-art feature squeezing technique can only achieve 55% accuracy with\n23.3% false positives.\n", "versions": [{"version": "v1", "created": "Sat, 27 Oct 2018 02:32:32 GMT"}], "update_date": "2018-10-30", "authors_parsed": [["Tao", "Guanhong", ""], ["Ma", "Shiqing", ""], ["Liu", "Yingqi", ""], ["Zhang", "Xiangyu", ""]]}, {"id": "1810.11581", "submitter": "Kar-Ann Toh", "authors": "Kar-Ann Toh, Zhiping Lin, Zhengguo Li, Beomseok Oh and Lei Sun", "title": "Gradient-Free Learning Based on the Kernel and the Range Space", "comments": "The idea of kernel and range projection was first introduced in the\n  IEEE/ACIS ICIS conference which was held in Singapore in June 2018. This\n  article presents a full development of the method supported by extensive\n  numerical results", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this article, we show that solving the system of linear equations by\nmanipulating the kernel and the range space is equivalent to solving the\nproblem of least squares error approximation. This establishes the ground for a\ngradient-free learning search when the system can be expressed in the form of a\nlinear matrix equation. When the nonlinear activation function is invertible,\nthe learning problem of a fully-connected multilayer feedforward neural network\ncan be easily adapted for this novel learning framework. By a series of kernel\nand range space manipulations, it turns out that such a network learning boils\ndown to solving a set of cross-coupling equations. By having the weights\nrandomly initialized, the equations can be decoupled and the network solution\nshows relatively good learning capability for real world data sets of small to\nmoderate dimensions. Based on the structural information of the matrix\nequation, the network representation is found to be dependent on the number of\ndata samples and the output dimension.\n", "versions": [{"version": "v1", "created": "Sat, 27 Oct 2018 02:49:37 GMT"}], "update_date": "2018-10-30", "authors_parsed": [["Toh", "Kar-Ann", ""], ["Lin", "Zhiping", ""], ["Li", "Zhengguo", ""], ["Oh", "Beomseok", ""], ["Sun", "Lei", ""]]}, {"id": "1810.11583", "submitter": "Matthew Riemer", "authors": "Matthew Riemer, Miao Liu, Gerald Tesauro", "title": "Learning Abstract Options", "comments": "NeurIPS 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Building systems that autonomously create temporal abstractions from data is\na key challenge in scaling learning and planning in reinforcement learning. One\npopular approach for addressing this challenge is the options framework (Sutton\net al., 1999). However, only recently in (Bacon et al., 2017) was a policy\ngradient theorem derived for online learning of general purpose options in an\nend to end fashion. In this work, we extend previous work on this topic that\nonly focuses on learning a two-level hierarchy including options and primitive\nactions to enable learning simultaneously at multiple resolutions in time. We\nachieve this by considering an arbitrarily deep hierarchy of options where high\nlevel temporally extended options are composed of lower level options with\nfiner resolutions in time. We extend results from (Bacon et al., 2017) and\nderive policy gradient theorems for a deep hierarchy of options. Our proposed\nhierarchical option-critic architecture is capable of learning internal\npolicies, termination conditions, and hierarchical compositions over options\nwithout the need for any intrinsic rewards or subgoals. Our empirical results\nin both discrete and continuous environments demonstrate the efficiency of our\nframework.\n", "versions": [{"version": "v1", "created": "Sat, 27 Oct 2018 02:54:59 GMT"}, {"version": "v2", "created": "Tue, 6 Nov 2018 17:43:42 GMT"}, {"version": "v3", "created": "Sat, 1 Dec 2018 23:36:25 GMT"}, {"version": "v4", "created": "Tue, 31 Dec 2019 17:25:40 GMT"}], "update_date": "2020-01-01", "authors_parsed": [["Riemer", "Matthew", ""], ["Liu", "Miao", ""], ["Tesauro", "Gerald", ""]]}, {"id": "1810.11586", "submitter": "Azadeh Mozafari", "authors": "Azadeh Sadat Mozafari, Hugo Siqueira Gomes, Wilson Le\\~ao, Steeven\n  Janny, Christian Gagn\\'e", "title": "Attended Temperature Scaling: A Practical Approach for Calibrating Deep\n  Neural Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recently, Deep Neural Networks (DNNs) have been achieving impressive results\non wide range of tasks. However, they suffer from being well-calibrated. In\ndecision-making applications, such as autonomous driving or medical diagnosing,\nthe confidence of deep networks plays an important role to bring the trust and\nreliability to the system. To calibrate the deep networks' confidence, many\nprobabilistic and measure-based approaches are proposed. Temperature Scaling\n(TS) is a state-of-the-art among measure-based calibration methods which has\nlow time and memory complexity as well as effectiveness. In this paper, we\nstudy TS and show it does not work properly when the validation set that TS\nuses for calibration has small size or contains noisy-labeled samples. TS also\ncannot calibrate highly accurate networks as well as non-highly accurate ones.\nAccordingly, we propose Attended Temperature Scaling (ATS) which preserves the\nadvantages of TS while improves calibration in aforementioned challenging\nsituations. We provide theoretical justifications for ATS and assess its\neffectiveness on wide range of deep models and datasets. We also compare the\ncalibration results of TS and ATS on skin lesion detection application as a\npractical problem where well-calibrated system can play important role in\nmaking a decision.\n", "versions": [{"version": "v1", "created": "Sat, 27 Oct 2018 03:03:57 GMT"}, {"version": "v2", "created": "Mon, 25 Mar 2019 01:22:46 GMT"}, {"version": "v3", "created": "Wed, 8 May 2019 18:51:05 GMT"}], "update_date": "2019-05-10", "authors_parsed": [["Mozafari", "Azadeh Sadat", ""], ["Gomes", "Hugo Siqueira", ""], ["Le\u00e3o", "Wilson", ""], ["Janny", "Steeven", ""], ["Gagn\u00e9", "Christian", ""]]}, {"id": "1810.11598", "submitter": "Ting Chen", "authors": "Ting Chen and Xiaohua Zhai and Neil Houlsby", "title": "Self-Supervised GAN to Counter Forgetting", "comments": "NeurIPS'18 Continual Learning workshop", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  GANs involve training two networks in an adversarial game, where each\nnetwork's task depends on its adversary. Recently, several works have framed\nGAN training as an online or continual learning problem. We focus on the\ndiscriminator, which must perform classification under an (adversarially)\nshifting data distribution. When trained on sequential tasks, neural networks\nexhibit \\emph{forgetting}. For GANs, discriminator forgetting leads to training\ninstability. To counter forgetting, we encourage the discriminator to maintain\nuseful representations by adding a self-supervision. Conditional GANs have a\nsimilar effect using labels. However, our self-supervised GAN does not require\nlabels, and closes the performance gap between conditional and unconditional\nmodels. We show that, in doing so, the self-supervised discriminator learns\nbetter representations than regular GANs.\n", "versions": [{"version": "v1", "created": "Sat, 27 Oct 2018 04:49:25 GMT"}, {"version": "v2", "created": "Thu, 29 Nov 2018 23:00:39 GMT"}], "update_date": "2018-12-06", "authors_parsed": [["Chen", "Ting", ""], ["Zhai", "Xiaohua", ""], ["Houlsby", "Neil", ""]]}, {"id": "1810.11612", "submitter": "Genta Indra Winata", "authors": "Genta Indra Winata, Masayu Leylia Khodra", "title": "Handling Imbalanced Dataset in Multi-label Text Categorization using\n  Bagging and Adaptive Boosting", "comments": "Accepted in the 2015 International Conference on Electrical\n  Engineering and Informatics (ICEEI), Best Student Paper Award", "journal-ref": null, "doi": "10.1109/ICEEI.2015.7352552", "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Imbalanced dataset is occurred due to uneven distribution of data available\nin the real world such as disposition of complaints on government offices in\nBandung. Consequently, multi-label text categorization algorithms may not\nproduce the best performance because classifiers tend to be weighed down by the\nmajority of the data and ignore the minority. In this paper, Bagging and\nAdaptive Boosting algorithms are employed to handle the issue and improve the\nperformance of text categorization. The result is evaluated with four\nevaluation metrics such as hamming loss, subset accuracy, example-based\naccuracy and micro-averaged f-measure. Bagging ML-LP with SMO weak classifier\nis the best performer in terms of subset accuracy and example-based accuracy.\nBagging ML-BR with SMO weak classifier has the best micro-averaged f-measure\namong all. In other hand, AdaBoost MH with J48 weak classifier has the lowest\nhamming loss value. Thus, both algorithms have high potential in boosting the\nperformance of text categorization, but only for certain weak classifiers.\nHowever, bagging has more potential than adaptive boosting in increasing the\naccuracy of minority labels.\n", "versions": [{"version": "v1", "created": "Sat, 27 Oct 2018 07:27:18 GMT"}, {"version": "v2", "created": "Mon, 10 Jun 2019 17:00:25 GMT"}, {"version": "v3", "created": "Tue, 11 Jun 2019 04:18:26 GMT"}], "update_date": "2019-06-12", "authors_parsed": [["Winata", "Genta Indra", ""], ["Khodra", "Masayu Leylia", ""]]}, {"id": "1810.11614", "submitter": "Siwei Yu", "authors": "Siwei Yu, Jianwei Ma, Wenlong Wang", "title": "Deep learning for denoising", "comments": "59 pages, 27 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "physics.geo-ph cs.LG eess.SP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Compared with traditional seismic noise attenuation algorithms that depend on\nsignal models and their corresponding prior assumptions, removing noise with a\ndeep neural network is trained based on a large training set, where the inputs\nare the raw datasets and the corresponding outputs are the desired clean data.\nAfter the completion of training, the deep learning method achieves adaptive\ndenoising with no requirements of (i) accurate modelings of the signal and\nnoise, or (ii) optimal parameters tuning. We call this intelligent denoising.\nWe use a convolutional neural network as the basic tool for deep learning. In\nrandom and linear noise attenuation, the training set is generated with\nartificially added noise. In the multiple attenuation step, the training set is\ngenerated with acoustic wave equation. Stochastic gradient descent is used to\nsolve the optimal parameters for the convolutional neural network. The runtime\nof deep learning on a graphics processing unit for denoising has the same order\nas the $f-x$ deconvolution method. Synthetic and field results show the\npotential applications of deep learning in automatic attenuation of random\nnoise (with unknown variance), linear noise, and multiples.\n", "versions": [{"version": "v1", "created": "Sat, 27 Oct 2018 07:39:09 GMT"}, {"version": "v2", "created": "Sat, 20 Jul 2019 02:20:39 GMT"}], "update_date": "2019-07-23", "authors_parsed": [["Yu", "Siwei", ""], ["Ma", "Jianwei", ""], ["Wang", "Wenlong", ""]]}, {"id": "1810.11624", "submitter": "David Guijo-Rubio", "authors": "David Guijo-Rubio, Antonio Manuel Dur\\'an-Rosal, Pedro Antonio\n  Guti\\'errez, Alicia Troncoso and C\\'esar Herv\\'as-Mart\\'inez", "title": "Time series clustering based on the characterisation of segment\n  typologies", "comments": "13 pages, 7 figures, 4 tables, 57 refs", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Time series clustering is the process of grouping time series with respect to\ntheir similarity or characteristics. Previous approaches usually combine a\nspecific distance measure for time series and a standard clustering method.\nHowever, these approaches do not take the similarity of the different\nsubsequences of each time series into account, which can be used to better\ncompare the time series objects of the dataset. In this paper, we propose a\nnovel technique of time series clustering based on two clustering stages. In a\nfirst step, a least squares polynomial segmentation procedure is applied to\neach time series, which is based on a growing window technique that returns\ndifferent-length segments. Then, all the segments are projected into same\ndimensional space, based on the coefficients of the model that approximates the\nsegment and a set of statistical features. After mapping, a first hierarchical\nclustering phase is applied to all mapped segments, returning groups of\nsegments for each time series. These clusters are used to represent all time\nseries in the same dimensional space, after defining another specific mapping\nprocess. In a second and final clustering stage, all the time series objects\nare grouped. We consider internal clustering quality to automatically adjust\nthe main parameter of the algorithm, which is an error threshold for the\nsegmenta- tion. The results obtained on 84 datasets from the UCR Time Series\nClassification Archive have been compared against two state-of-the-art methods,\nshowing that the performance of this methodology is very promising.\n", "versions": [{"version": "v1", "created": "Sat, 27 Oct 2018 10:01:46 GMT"}], "update_date": "2018-10-30", "authors_parsed": [["Guijo-Rubio", "David", ""], ["Dur\u00e1n-Rosal", "Antonio Manuel", ""], ["Guti\u00e9rrez", "Pedro Antonio", ""], ["Troncoso", "Alicia", ""], ["Herv\u00e1s-Mart\u00ednez", "C\u00e9sar", ""]]}, {"id": "1810.11630", "submitter": "Wittawat Jitkrittum", "authors": "Wittawat Jitkrittum, Heishiro Kanagawa, Patsorn Sangkloy, James Hays,\n  Bernhard Sch\\\"olkopf, Arthur Gretton", "title": "Informative Features for Model Comparison", "comments": "Accepted to NIPS 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Given two candidate models, and a set of target observations, we address the\nproblem of measuring the relative goodness of fit of the two models. We propose\ntwo new statistical tests which are nonparametric, computationally efficient\n(runtime complexity is linear in the sample size), and interpretable. As a\nunique advantage, our tests can produce a set of examples (informative\nfeatures) indicating the regions in the data domain where one model fits\nsignificantly better than the other. In a real-world problem of comparing GAN\nmodels, the test power of our new test matches that of the state-of-the-art\ntest of relative goodness of fit, while being one order of magnitude faster.\n", "versions": [{"version": "v1", "created": "Sat, 27 Oct 2018 10:55:34 GMT"}], "update_date": "2018-10-30", "authors_parsed": [["Jitkrittum", "Wittawat", ""], ["Kanagawa", "Heishiro", ""], ["Sangkloy", "Patsorn", ""], ["Hays", "James", ""], ["Sch\u00f6lkopf", "Bernhard", ""], ["Gretton", "Arthur", ""]]}, {"id": "1810.11646", "submitter": "Nathan Kallus", "authors": "Nathan Kallus, Aahlad Manas Puli, Uri Shalit", "title": "Removing Hidden Confounding by Experimental Grounding", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Observational data is increasingly used as a means for making\nindividual-level causal predictions and intervention recommendations. The\nforemost challenge of causal inference from observational data is hidden\nconfounding, whose presence cannot be tested in data and can invalidate any\ncausal conclusion. Experimental data does not suffer from confounding but is\nusually limited in both scope and scale. We introduce a novel method of using\nlimited experimental data to correct the hidden confounding in causal effect\nmodels trained on larger observational data, even if the observational data\ndoes not fully overlap with the experimental data. Our method makes strictly\nweaker assumptions than existing approaches, and we prove conditions under\nwhich it yields a consistent estimator. We demonstrate our method's efficacy\nusing real-world data from a large educational experiment.\n", "versions": [{"version": "v1", "created": "Sat, 27 Oct 2018 13:59:05 GMT"}], "update_date": "2018-10-30", "authors_parsed": [["Kallus", "Nathan", ""], ["Puli", "Aahlad Manas", ""], ["Shalit", "Uri", ""]]}, {"id": "1810.11649", "submitter": "Viraj Prabhu", "authors": "Utsav Garg, Viraj Prabhu, Deshraj Yadav, Ram Ramrakhya, Harsh Agrawal,\n  Dhruv Batra", "title": "Fabrik: An Online Collaborative Neural Network Editor", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present Fabrik, an online neural network editor that provides tools to\nvisualize, edit, and share neural networks from within a browser. Fabrik\nprovides a simple and intuitive GUI to import neural networks written in\npopular deep learning frameworks such as Caffe, Keras, and TensorFlow, and\nallows users to interact with, build, and edit models via simple drag and drop.\nFabrik is designed to be framework agnostic and support high interoperability,\nand can be used to export models back to any supported framework. Finally, it\nprovides powerful collaborative features to enable users to iterate over model\ndesign remotely and at scale.\n", "versions": [{"version": "v1", "created": "Sat, 27 Oct 2018 14:23:38 GMT"}], "update_date": "2018-10-30", "authors_parsed": [["Garg", "Utsav", ""], ["Prabhu", "Viraj", ""], ["Yadav", "Deshraj", ""], ["Ramrakhya", "Ram", ""], ["Agrawal", "Harsh", ""], ["Batra", "Dhruv", ""]]}, {"id": "1810.11650", "submitter": "Marcel Crasmaru", "authors": "Marcel Crasmaru", "title": "On the Equivalence of Convolutional and Hadamard Networks using DFT", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.OC cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we introduce activation functions that move the entire\ncomputation of Convolutional Networks into the frequency domain, where they are\nactually Hadamard Networks. To achieve this result we employ the properties of\nDiscrete Fourier Transform. We present some implementation details and\nexperimental results, as well as some insights into why convolutional networks\nperform well in learning use cases.\n", "versions": [{"version": "v1", "created": "Sat, 27 Oct 2018 14:29:52 GMT"}], "update_date": "2018-10-30", "authors_parsed": [["Crasmaru", "Marcel", ""]]}, {"id": "1810.11665", "submitter": "Joberto Martins Prof. Dr.", "authors": "Joberto S. B. Martins", "title": "Towards Smart City Innovation Under the Perspective of Software-Defined\n  Networking, Artificial Intelligence and Big Data", "comments": "8 pages", "journal-ref": "RTIC - Revista de Tecnologia da Informacao e Comunicacao, Vol.8,\n  No.2, October 2018", "doi": "10.5281/zenodo.1467770", "report-no": null, "categories": "cs.NI cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Smart city projects address many of the current problems afflicting high\npopulated areas and cities and, as such, are a target for government,\ninstitutions and private organizations that plan to explore its foreseen\nadvantages. In technical terms, smart city projects present a complex set of\nrequirements including a large number users with highly different and\nheterogeneous requirements. In this scenario, this paper proposes and analyses\nthe impact and perspectives on adopting software-defined networking and\nartificial intelligence as innovative approaches for smart city project\ndevelopment and deployment. Big data is also considered as an inherent element\nof most smart city project that must be tackled. A framework layered view is\nproposed with a discussion about software-defined networking and machine\nlearning impacts on innovation followed by a use case that demonstrates the\npotential benefits of cognitive learning for smart cities. It is argued that\nthe complexity of smart city projects do require new innovative approaches that\npotentially result in more efficient and intelligent systems.\n", "versions": [{"version": "v1", "created": "Sat, 27 Oct 2018 15:39:18 GMT"}], "update_date": "2018-10-30", "authors_parsed": [["Martins", "Joberto S. B.", ""]]}, {"id": "1810.11671", "submitter": "Marek Wydmuch", "authors": "Marek Wydmuch, Kalina Jasinska, Mikhail Kuznetsov, R\\'obert\n  Busa-Fekete, Krzysztof Dembczy\\'nski", "title": "A no-regret generalization of hierarchical softmax to extreme\n  multi-label classification", "comments": "Accepted at NIPS 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Extreme multi-label classification (XMLC) is a problem of tagging an instance\nwith a small subset of relevant labels chosen from an extremely large pool of\npossible labels. Large label spaces can be efficiently handled by organizing\nlabels as a tree, like in the hierarchical softmax (HSM) approach commonly used\nfor multi-class problems. In this paper, we investigate probabilistic label\ntrees (PLTs) that have been recently devised for tackling XMLC problems. We\nshow that PLTs are a no-regret multi-label generalization of HSM when\nprecision@k is used as a model evaluation metric. Critically, we prove that\npick-one-label heuristic - a reduction technique from multi-label to\nmulti-class that is routinely used along with HSM - is not consistent in\ngeneral. We also show that our implementation of PLTs, referred to as\nextremeText (XT), obtains significantly better results than HSM with the\npick-one-label heuristic and XML-CNN, a deep network specifically designed for\nXMLC problems. Moreover, XT is competitive to many state-of-the-art approaches\nin terms of statistical performance, model size and prediction time which makes\nit amenable to deploy in an online system.\n", "versions": [{"version": "v1", "created": "Sat, 27 Oct 2018 16:27:18 GMT"}], "update_date": "2018-10-30", "authors_parsed": [["Wydmuch", "Marek", ""], ["Jasinska", "Kalina", ""], ["Kuznetsov", "Mikhail", ""], ["Busa-Fekete", "R\u00f3bert", ""], ["Dembczy\u0144ski", "Krzysztof", ""]]}, {"id": "1810.11677", "submitter": "Pradeep Kr. Banerjee", "authors": "Pradeep Kr. Banerjee, Guido Mont\\'ufar", "title": "The Variational Deficiency Bottleneck", "comments": "8 pages, 4 figures, International Joint Conference on Neural Networks\n  (IJCNN) 2020", "journal-ref": null, "doi": "10.1109/IJCNN48605.2020.9206900", "report-no": null, "categories": "cs.IT cs.LG math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce a bottleneck method for learning data representations based on\ninformation deficiency, rather than the more traditional information\nsufficiency. A variational upper bound allows us to implement this method\nefficiently. The bound itself is bounded above by the variational information\nbottleneck objective, and the two methods coincide in the regime of single-shot\nMonte Carlo approximations. The notion of deficiency provides a principled way\nof approximating complicated channels by relatively simpler ones. We show that\nthe deficiency of one channel with respect to another has an operational\ninterpretation in terms of the optimal risk gap of decision problems, capturing\nclassification as a special case. Experiments demonstrate that the deficiency\nbottleneck can provide advantages in terms of minimal sufficiency as measured\nby information bottleneck curves, while retaining robust test performance in\nclassification tasks.\n", "versions": [{"version": "v1", "created": "Sat, 27 Oct 2018 16:58:01 GMT"}, {"version": "v2", "created": "Sat, 21 Mar 2020 22:46:25 GMT"}, {"version": "v3", "created": "Wed, 4 Nov 2020 12:00:59 GMT"}], "update_date": "2020-11-05", "authors_parsed": [["Banerjee", "Pradeep Kr.", ""], ["Mont\u00fafar", "Guido", ""]]}, {"id": "1810.11693", "submitter": "Dilin Wang", "authors": "Qiang Liu and Dilin Wang", "title": "Stein Variational Gradient Descent as Moment Matching", "comments": "Conference on Neural Information Processing Systems (NIPS) 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Stein variational gradient descent (SVGD) is a non-parametric inference\nalgorithm that evolves a set of particles to fit a given distribution of\ninterest. We analyze the non-asymptotic properties of SVGD, showing that there\nexists a set of functions, which we call the Stein matching set, whose\nexpectations are exactly estimated by any set of particles that satisfies the\nfixed point equation of SVGD. This set is the image of Stein operator applied\non the feature maps of the positive definite kernel used in SVGD. Our results\nprovide a theoretical framework for analyzing the properties of SVGD with\ndifferent kernels, shedding insight into optimal kernel choice. In particular,\nwe show that SVGD with linear kernels yields exact estimation of means and\nvariances on Gaussian distributions, while random Fourier features enable\nprobabilistic bounds for distributional approximation. Our results offer a\nrefreshing view of the classical inference problem as fitting Stein's identity\nor solving the Stein equation, which may motivate more efficient algorithms.\n", "versions": [{"version": "v1", "created": "Sat, 27 Oct 2018 19:23:50 GMT"}], "update_date": "2018-10-30", "authors_parsed": [["Liu", "Qiang", ""], ["Wang", "Dilin", ""]]}, {"id": "1810.11698", "submitter": "Myriam Tami", "authors": "Myriam Tami, Marianne Clausel, Emilie Devijver, Adrien Dulac, Eric\n  Gaussier, Stefan Janaqi, Meriam Chebre", "title": "Uncertain Trees: Dealing with Uncertain Inputs in Regression Trees", "comments": "9 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Tree-based ensemble methods, as Random Forests and Gradient Boosted Trees,\nhave been successfully used for regression in many applications and research\nstudies. Furthermore, these methods have been extended in order to deal with\nuncertainty in the output variable, using for example a quantile loss in Random\nForests (Meinshausen, 2006). To the best of our knowledge, no extension has\nbeen provided yet for dealing with uncertainties in the input variables, even\nthough such uncertainties are common in practical situations. We propose here\nsuch an extension by showing how standard regression trees optimizing a\nquadratic loss can be adapted and learned while taking into account the\nuncertainties in the inputs. By doing so, one no longer assumes that an\nobservation lies into a single region of the regression tree, but rather that\nit belongs to each region with a certain probability. Experiments conducted on\nseveral data sets illustrate the good behavior of the proposed extension.\n", "versions": [{"version": "v1", "created": "Sat, 27 Oct 2018 20:03:45 GMT"}, {"version": "v2", "created": "Sun, 18 Nov 2018 14:04:14 GMT"}], "update_date": "2018-11-20", "authors_parsed": [["Tami", "Myriam", ""], ["Clausel", "Marianne", ""], ["Devijver", "Emilie", ""], ["Dulac", "Adrien", ""], ["Gaussier", "Eric", ""], ["Janaqi", "Stefan", ""], ["Chebre", "Meriam", ""]]}, {"id": "1810.11701", "submitter": "Dongchi Yu", "authors": "Dongchi Yu, Lu Wang", "title": "Hull Form Optimization with Principal Component Analysis and Deep Neural\n  Network", "comments": "20 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Designing and modifying complex hull forms for optimal vessel performances\nhave been a major challenge for naval architects. In the present study,\nPrincipal Component Analysis (PCA) is introduced to compress the geometric\nrepresentation of a group of existing vessels, and the resulting principal\nscores are manipulated to generate a large number of derived hull forms, which\nare evaluated computationally for their calm-water performances. The results\nare subsequently used to train a Deep Neural Network (DNN) to accurately\nestablish the relation between different hull forms and their associated\nperformances. Then, based on the fast, parallel DNN-based hull-form evaluation,\nthe large-scale search for optimal hull forms is performed.\n", "versions": [{"version": "v1", "created": "Sat, 27 Oct 2018 20:37:47 GMT"}], "update_date": "2018-10-30", "authors_parsed": [["Yu", "Dongchi", ""], ["Wang", "Lu", ""]]}, {"id": "1810.11702", "submitter": "Christian Schroeder de Witt", "authors": "Christian A. Schroeder de Witt, Jakob N. Foerster, Gregory Farquhar,\n  Philip H. S. Torr, Wendelin Boehmer, Shimon Whiteson", "title": "Multi-Agent Common Knowledge Reinforcement Learning", "comments": "Advances in Neural Information Processing Systems, 9924-9935", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.MA cs.AI cs.GT cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Cooperative multi-agent reinforcement learning often requires decentralised\npolicies, which severely limit the agents' ability to coordinate their\nbehaviour. In this paper, we show that common knowledge between agents allows\nfor complex decentralised coordination. Common knowledge arises naturally in a\nlarge number of decentralised cooperative multi-agent tasks, for example, when\nagents can reconstruct parts of each others' observations. Since agents an\nindependently agree on their common knowledge, they can execute complex\ncoordinated policies that condition on this knowledge in a fully decentralised\nfashion. We propose multi-agent common knowledge reinforcement learning\n(MACKRL), a novel stochastic actor-critic algorithm that learns a hierarchical\npolicy tree. Higher levels in the hierarchy coordinate groups of agents by\nconditioning on their common knowledge, or delegate to lower levels with\nsmaller subgroups but potentially richer common knowledge. The entire policy\ntree can be executed in a fully decentralised fashion. As the lowest policy\ntree level consists of independent policies for each agent, MACKRL reduces to\nindependently learnt decentralised policies as a special case. We demonstrate\nthat our method can exploit common knowledge for superior performance on\ncomplex decentralised coordination tasks, including a stochastic matrix game\nand challenging problems in StarCraft II unit micromanagement.\n", "versions": [{"version": "v1", "created": "Sat, 27 Oct 2018 20:45:19 GMT"}, {"version": "v2", "created": "Mon, 5 Nov 2018 14:53:34 GMT"}, {"version": "v3", "created": "Wed, 15 May 2019 13:05:30 GMT"}, {"version": "v4", "created": "Sun, 23 Jun 2019 16:45:17 GMT"}, {"version": "v5", "created": "Tue, 1 Oct 2019 11:13:59 GMT"}, {"version": "v6", "created": "Sun, 10 Nov 2019 13:35:42 GMT"}, {"version": "v7", "created": "Tue, 3 Dec 2019 11:03:40 GMT"}, {"version": "v8", "created": "Sat, 11 Jan 2020 22:42:13 GMT"}], "update_date": "2020-01-14", "authors_parsed": [["de Witt", "Christian A. Schroeder", ""], ["Foerster", "Jakob N.", ""], ["Farquhar", "Gregory", ""], ["Torr", "Philip H. S.", ""], ["Boehmer", "Wendelin", ""], ["Whiteson", "Shimon", ""]]}, {"id": "1810.11711", "submitter": "Chandler Zuo", "authors": "Chandler Zuo", "title": "Regularization Effect of Fast Gradient Sign Method and its\n  Generalization", "comments": "15 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Fast Gradient Sign Method (FGSM) is a popular method to generate adversarial\nexamples that make neural network models robust against perturbations. Despite\nits empirical success, its theoretical property is not well understood. This\npaper develops theory to explain the regularization effect of Generalized FGSM,\na class of methods to generate adversarial examples. Motivated from the\nrelationship between FGSM and LASSO penalty, the asymptotic properties of\nGeneralized FGSM are derived in the Generalized Linear Model setting, which is\nessentially the 1-layer neural network setting with certain activation\nfunctions. In such simple neural network models, I prove that Generalized FGSM\nestimation is root n-consistent and weakly oracle under proper conditions. The\nasymptotic results are also highly similar to penalized likelihood estimation.\nNevertheless, Generalized FGSM introduces additional bias when data sampling is\nnot sign neutral, a concept I introduce to describe the balance-ness of the\nnoise signs. Although the theory in this paper is developed under simple neural\nnetwork settings, I argue that it may give insights and justification for FGSM\nin deep neural network settings as well.\n", "versions": [{"version": "v1", "created": "Sat, 27 Oct 2018 21:22:06 GMT"}, {"version": "v2", "created": "Tue, 30 Oct 2018 04:44:50 GMT"}], "update_date": "2018-10-31", "authors_parsed": [["Zuo", "Chandler", ""]]}, {"id": "1810.11714", "submitter": "Andrew Hundt", "authors": "Andrew Hundt, Varun Jain, Chia-Hung Lin, Chris Paxton, Gregory D.\n  Hager", "title": "The CoSTAR Block Stacking Dataset: Learning with Workspace Constraints", "comments": "This is a major revision refocusing the topic towards the JHU CoSTAR\n  Block Stacking Dataset, workspace constraints, and a comparison of HyperTrees\n  with hand-designed algorithms. 12 pages, 10 figures, and 3 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.AI cs.CV cs.LG cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A robot can now grasp an object more effectively than ever before, but once\nit has the object what happens next? We show that a mild relaxation of the task\nand workspace constraints implicit in existing object grasping datasets can\ncause neural network based grasping algorithms to fail on even a simple block\nstacking task when executed under more realistic circumstances.\n  To address this, we introduce the JHU CoSTAR Block Stacking Dataset (BSD),\nwhere a robot interacts with 5.1 cm colored blocks to complete an\norder-fulfillment style block stacking task. It contains dynamic scenes and\nreal time-series data in a less constrained environment than comparable\ndatasets. There are nearly 12,000 stacking attempts and over 2 million frames\nof real data. We discuss the ways in which this dataset provides a valuable\nresource for a broad range of other topics of investigation.\n  We find that hand-designed neural networks that work on prior datasets do not\ngeneralize to this task. Thus, to establish a baseline for this dataset, we\ndemonstrate an automated search of neural network based models using a novel\nmultiple-input HyperTree MetaModel, and find a final model which makes\nreasonable 3D pose predictions for grasping and stacking on our dataset.\n  The CoSTAR BSD, code, and instructions are available at\nhttps://sites.google.com/site/costardataset.\n", "versions": [{"version": "v1", "created": "Sat, 27 Oct 2018 21:26:42 GMT"}, {"version": "v2", "created": "Tue, 12 Mar 2019 23:17:17 GMT"}], "update_date": "2019-03-14", "authors_parsed": [["Hundt", "Andrew", ""], ["Jain", "Varun", ""], ["Lin", "Chia-Hung", ""], ["Paxton", "Chris", ""], ["Hager", "Gregory D.", ""]]}, {"id": "1810.11726", "submitter": "Dhagash Mehta", "authors": "Timothy E. Wang, Yiming Gu, Dhagash Mehta, Xiaojun Zhao, Edgar A.\n  Bernal", "title": "Towards Robust Deep Neural Networks", "comments": "Added further discussions, and supplementary material", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cond-mat.stat-mech cs.LG math.OC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We investigate the topics of sensitivity and robustness in feedforward and\nconvolutional neural networks. Combining energy landscape techniques developed\nin computational chemistry with tools drawn from formal methods, we produce\nempirical evidence indicating that networks corresponding to lower-lying minima\nin the optimization landscape of the learning objective tend to be more robust.\nThe robustness estimate used is the inverse of a proposed sensitivity measure,\nwhich we define as the volume of an over-approximation of the reachable set of\nnetwork outputs under all additive $l_{\\infty}$-bounded perturbations on the\ninput data. We present a novel loss function which includes a sensitivity term\nin addition to the traditional task-oriented and regularization terms. In our\nexperiments on standard machine learning and computer vision datasets, we show\nthat the proposed loss function leads to networks which reliably optimize the\nrobustness measure as well as other related metrics of adversarial robustness\nwithout significant degradation in the classification error. Experimental\nresults indicate that the proposed method outperforms state-of-the-art\nsensitivity-based learning approaches with regards to robustness to adversarial\nattacks. We also show that although the introduced framework does not\nexplicitly enforce an adversarial loss, it achieves competitive overall\nperformance relative to methods that do.\n", "versions": [{"version": "v1", "created": "Sat, 27 Oct 2018 22:38:33 GMT"}, {"version": "v2", "created": "Tue, 4 Dec 2018 20:55:32 GMT"}], "update_date": "2018-12-06", "authors_parsed": [["Wang", "Timothy E.", ""], ["Gu", "Yiming", ""], ["Mehta", "Dhagash", ""], ["Zhao", "Xiaojun", ""], ["Bernal", "Edgar A.", ""]]}, {"id": "1810.11730", "submitter": "Hang Gao", "authors": "Hang Gao, Zheng Shou, Alireza Zareian, Hanwang Zhang, Shih-Fu Chang", "title": "Low-shot Learning via Covariance-Preserving Adversarial Augmentation\n  Networks", "comments": null, "journal-ref": "In Advances in Neural Information Processing Systems, pp. 981-991.\n  2018", "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep neural networks suffer from over-fitting and catastrophic forgetting\nwhen trained with small data. One natural remedy for this problem is data\naugmentation, which has been recently shown to be effective. However, previous\nworks either assume that intra-class variances can always be generalized to new\nclasses, or employ naive generation methods to hallucinate finite examples\nwithout modeling their latent distributions. In this work, we propose\nCovariance-Preserving Adversarial Augmentation Networks to overcome existing\nlimits of low-shot learning. Specifically, a novel Generative Adversarial\nNetwork is designed to model the latent distribution of each novel class given\nits related base counterparts. Since direct estimation of novel classes can be\ninductively biased, we explicitly preserve covariance information as the\n`variability' of base examples during the generation process. Empirical results\nshow that our model can generate realistic yet diverse examples, leading to\nsubstantial improvements on the ImageNet benchmark over the state of the art.\n", "versions": [{"version": "v1", "created": "Sat, 27 Oct 2018 23:09:10 GMT"}, {"version": "v2", "created": "Tue, 30 Oct 2018 20:13:47 GMT"}, {"version": "v3", "created": "Thu, 13 Dec 2018 16:42:32 GMT"}], "update_date": "2018-12-14", "authors_parsed": [["Gao", "Hang", ""], ["Shou", "Zheng", ""], ["Zareian", "Alireza", ""], ["Zhang", "Hanwang", ""], ["Chang", "Shih-Fu", ""]]}, {"id": "1810.11738", "submitter": "Francesco Paolo Casale", "authors": "Francesco Paolo Casale, Adrian V Dalca, Luca Saglietti, Jennifer\n  Listgarten, Nicolo Fusi", "title": "Gaussian Process Prior Variational Autoencoders", "comments": "Accepted at 32nd Conference on Neural Information Processing Systems\n  (NIPS 2018), Montr\\'eal, Canada", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Variational autoencoders (VAE) are a powerful and widely-used class of models\nto learn complex data distributions in an unsupervised fashion. One important\nlimitation of VAEs is the prior assumption that latent sample representations\nare independent and identically distributed. However, for many important\ndatasets, such as time-series of images, this assumption is too strong:\naccounting for covariances between samples, such as those in time, can yield to\na more appropriate model specification and improve performance in downstream\ntasks. In this work, we introduce a new model, the Gaussian Process (GP) Prior\nVariational Autoencoder (GPPVAE), to specifically address this issue. The\nGPPVAE aims to combine the power of VAEs with the ability to model correlations\nafforded by GP priors. To achieve efficient inference in this new class of\nmodels, we leverage structure in the covariance matrix, and introduce a new\nstochastic backpropagation strategy that allows for computing stochastic\ngradients in a distributed and low-memory fashion. We show that our method\noutperforms conditional VAEs (CVAEs) and an adaptation of standard VAEs in two\nimage data applications.\n", "versions": [{"version": "v1", "created": "Sun, 28 Oct 2018 00:57:23 GMT"}, {"version": "v2", "created": "Mon, 26 Nov 2018 05:00:52 GMT"}], "update_date": "2018-11-27", "authors_parsed": [["Casale", "Francesco Paolo", ""], ["Dalca", "Adrian V", ""], ["Saglietti", "Luca", ""], ["Listgarten", "Jennifer", ""], ["Fusi", "Nicolo", ""]]}, {"id": "1810.11740", "submitter": "Farzan Farnia", "authors": "Farzan Farnia, David Tse", "title": "A Convex Duality Framework for GANs", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Generative adversarial network (GAN) is a minimax game between a generator\nmimicking the true model and a discriminator distinguishing the samples\nproduced by the generator from the real training samples. Given an\nunconstrained discriminator able to approximate any function, this game reduces\nto finding the generative model minimizing a divergence measure, e.g. the\nJensen-Shannon (JS) divergence, to the data distribution. However, in practice\nthe discriminator is constrained to be in a smaller class $\\mathcal{F}$ such as\nneural nets. Then, a natural question is how the divergence minimization\ninterpretation changes as we constrain $\\mathcal{F}$. In this work, we address\nthis question by developing a convex duality framework for analyzing GANs. For\na convex set $\\mathcal{F}$, this duality framework interprets the original GAN\nformulation as finding the generative model with minimum JS-divergence to the\ndistributions penalized to match the moments of the data distribution, with the\nmoments specified by the discriminators in $\\mathcal{F}$. We show that this\ninterpretation more generally holds for f-GAN and Wasserstein GAN. As a\nbyproduct, we apply the duality framework to a hybrid of f-divergence and\nWasserstein distance. Unlike the f-divergence, we prove that the proposed\nhybrid divergence changes continuously with the generative model, which\nsuggests regularizing the discriminator's Lipschitz constant in f-GAN and\nvanilla GAN. We numerically evaluate the power of the suggested regularization\nschemes for improving GAN's training performance.\n", "versions": [{"version": "v1", "created": "Sun, 28 Oct 2018 01:15:20 GMT"}], "update_date": "2018-10-30", "authors_parsed": [["Farnia", "Farzan", ""], ["Tse", "David", ""]]}, {"id": "1810.11748", "submitter": "Sosuke Kobayashi", "authors": "Riku Arakawa and Sosuke Kobayashi and Yuya Unno and Yuta Tsuboi and\n  Shin-ichi Maeda", "title": "DQN-TAMER: Human-in-the-Loop Reinforcement Learning with Intractable\n  Feedback", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.HC cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Exploration has been one of the greatest challenges in reinforcement learning\n(RL), which is a large obstacle in the application of RL to robotics. Even with\nstate-of-the-art RL algorithms, building a well-learned agent often requires\ntoo many trials, mainly due to the difficulty of matching its actions with\nrewards in the distant future. A remedy for this is to train an agent with\nreal-time feedback from a human observer who immediately gives rewards for some\nactions. This study tackles a series of challenges for introducing such a\nhuman-in-the-loop RL scheme. The first contribution of this work is our\nexperiments with a precisely modeled human observer: binary, delay,\nstochasticity, unsustainability, and natural reaction. We also propose an RL\nmethod called DQN-TAMER, which efficiently uses both human feedback and distant\nrewards. We find that DQN-TAMER agents outperform their baselines in Maze and\nTaxi simulated environments. Furthermore, we demonstrate a real-world\nhuman-in-the-loop RL application where a camera automatically recognizes a\nuser's facial expressions as feedback to the agent while the agent explores a\nmaze.\n", "versions": [{"version": "v1", "created": "Sun, 28 Oct 2018 02:18:40 GMT"}], "update_date": "2018-10-30", "authors_parsed": [["Arakawa", "Riku", ""], ["Kobayashi", "Sosuke", ""], ["Unno", "Yuya", ""], ["Tsuboi", "Yuta", ""], ["Maeda", "Shin-ichi", ""]]}, {"id": "1810.11750", "submitter": "Liwei Wang", "authors": "Liwei Wang, Lunjia Hu, Jiayuan Gu, Yue Wu, Zhiqiang Hu, Kun He and\n  John Hopcroft", "title": "Towards Understanding Learning Representations: To What Extent Do\n  Different Neural Networks Learn the Same Representation", "comments": "17 pages, 6 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  It is widely believed that learning good representations is one of the main\nreasons for the success of deep neural networks. Although highly intuitive,\nthere is a lack of theory and systematic approach quantitatively characterizing\nwhat representations do deep neural networks learn. In this work, we move a\ntiny step towards a theory and better understanding of the representations.\nSpecifically, we study a simpler problem: How similar are the representations\nlearned by two networks with identical architecture but trained from different\ninitializations. We develop a rigorous theory based on the neuron activation\nsubspace match model. The theory gives a complete characterization of the\nstructure of neuron activation subspace matches, where the core concepts are\nmaximum match and simple match which describe the overall and the finest\nsimilarity between sets of neurons in two networks respectively. We also\npropose efficient algorithms to find the maximum match and simple matches.\nFinally, we conduct extensive experiments using our algorithms. Experimental\nresults suggest that, surprisingly, representations learned by the same\nconvolutional layers of networks trained from different initializations are not\nas similar as prevalently expected, at least in terms of subspace match.\n", "versions": [{"version": "v1", "created": "Sun, 28 Oct 2018 02:27:31 GMT"}, {"version": "v2", "created": "Wed, 28 Nov 2018 21:14:59 GMT"}], "update_date": "2018-11-30", "authors_parsed": [["Wang", "Liwei", ""], ["Hu", "Lunjia", ""], ["Gu", "Jiayuan", ""], ["Wu", "Yue", ""], ["Hu", "Zhiqiang", ""], ["He", "Kun", ""], ["Hopcroft", "John", ""]]}, {"id": "1810.11754", "submitter": "Yi Hao", "authors": "Yi Hao, Alon Orlitsky, Venkatadheeraj Pichapati", "title": "On Learning Markov Chains", "comments": "To appear at NIPS 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The problem of estimating an unknown discrete distribution from its samples\nis a fundamental tenet of statistical learning. Over the past decade, it\nattracted significant research effort and has been solved for a variety of\ndivergence measures. Surprisingly, an equally important problem, estimating an\nunknown Markov chain from its samples, is still far from understood. We\nconsider two problems related to the min-max risk (expected loss) of estimating\nan unknown $k$-state Markov chain from its $n$ sequential samples: predicting\nthe conditional distribution of the next sample with respect to the\nKL-divergence, and estimating the transition matrix with respect to a natural\nloss induced by KL or a more general $f$-divergence measure.\n  For the first measure, we determine the min-max prediction risk to within a\nlinear factor in the alphabet size, showing it is $\\Omega(k\\log\\log n\\ / n)$\nand $\\mathcal{O}(k^2\\log\\log n\\ / n)$. For the second, if the transition\nprobabilities can be arbitrarily small, then only trivial uniform risk upper\nbounds can be derived. We therefore consider transition probabilities that are\nbounded away from zero, and resolve the problem for essentially all\nsufficiently smooth $f$-divergences, including KL-, $L_2$-, Chi-squared,\nHellinger, and Alpha-divergences.\n", "versions": [{"version": "v1", "created": "Sun, 28 Oct 2018 03:20:20 GMT"}], "update_date": "2018-10-30", "authors_parsed": [["Hao", "Yi", ""], ["Orlitsky", "Alon", ""], ["Pichapati", "Venkatadheeraj", ""]]}, {"id": "1810.11755", "submitter": "Anji Liu", "authors": "Anji Liu, Jianshu Chen, Mingze Yu, Yu Zhai, Xuewen Zhou, Ji Liu", "title": "Watch the Unobserved: A Simple Approach to Parallelizing Monte Carlo\n  Tree Search", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Monte Carlo Tree Search (MCTS) algorithms have achieved great success on many\nchallenging benchmarks (e.g., Computer Go). However, they generally require a\nlarge number of rollouts, making their applications costly. Furthermore, it is\nalso extremely challenging to parallelize MCTS due to its inherent sequential\nnature: each rollout heavily relies on the statistics (e.g., node visitation\ncounts) estimated from previous simulations to achieve an effective\nexploration-exploitation tradeoff. In spite of these difficulties, we develop\nan algorithm, WU-UCT, to effectively parallelize MCTS, which achieves linear\nspeedup and exhibits only limited performance loss with an increasing number of\nworkers. The key idea in WU-UCT is a set of statistics that we introduce to\ntrack the number of on-going yet incomplete simulation queries (named as\nunobserved samples). These statistics are used to modify the UCT tree policy in\nthe selection steps in a principled manner to retain effective\nexploration-exploitation tradeoff when we parallelize the most time-consuming\nexpansion and simulation steps. Experiments on a proprietary benchmark and the\nAtari Game benchmark demonstrate the linear speedup and the superior\nperformance of WU-UCT comparing to existing techniques.\n", "versions": [{"version": "v1", "created": "Sun, 28 Oct 2018 03:24:01 GMT"}, {"version": "v2", "created": "Tue, 5 Feb 2019 16:42:24 GMT"}, {"version": "v3", "created": "Thu, 26 Sep 2019 21:10:56 GMT"}, {"version": "v4", "created": "Tue, 11 Feb 2020 03:48:32 GMT"}, {"version": "v5", "created": "Tue, 25 Feb 2020 22:03:23 GMT"}], "update_date": "2020-02-27", "authors_parsed": [["Liu", "Anji", ""], ["Chen", "Jianshu", ""], ["Yu", "Mingze", ""], ["Zhai", "Yu", ""], ["Zhou", "Xuewen", ""], ["Liu", "Ji", ""]]}, {"id": "1810.11758", "submitter": "Hao-Hsuan Chang", "authors": "Hao-Hsuan Chang, Hao Song, Yang Yi, Jianzhong Zhang, Haibo He, Lingjia\n  Liu", "title": "Distributive Dynamic Spectrum Access through Deep Reinforcement\n  Learning: A Reservoir Computing Based Approach", "comments": "This work is accepted in IEEE IoT Journal 2018", "journal-ref": null, "doi": "10.1109/JIOT.2018.2872441", "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Dynamic spectrum access (DSA) is regarded as an effective and efficient\ntechnology to share radio spectrum among different networks. As a secondary\nuser (SU), a DSA device will face two critical problems: avoiding causing\nharmful interference to primary users (PUs), and conducting effective\ninterference coordination with other secondary users. These two problems become\neven more challenging for a distributed DSA network where there is no\ncentralized controllers for SUs. In this paper, we investigate communication\nstrategies of a distributive DSA network under the presence of spectrum sensing\nerrors. To be specific, we apply the powerful machine learning tool, deep\nreinforcement learning (DRL), for SUs to learn \"appropriate\" spectrum access\nstrategies in a distributed fashion assuming NO knowledge of the underlying\nsystem statistics. Furthermore, a special type of recurrent neural network\n(RNN), called the reservoir computing (RC), is utilized to realize DRL by\ntaking advantage of the underlying temporal correlation of the DSA network.\nUsing the introduced machine learning-based strategy, SUs could make spectrum\naccess decisions distributedly relying only on their own current and past\nspectrum sensing outcomes. Through extensive experiments, our results suggest\nthat the RC-based spectrum access strategy can help the SU to significantly\nreduce the chances of collision with PUs and other SUs. We also show that our\nscheme outperforms the myopic method which assumes the knowledge of system\nstatistics, and converges faster than the Q-learning method when the number of\nchannels is large.\n", "versions": [{"version": "v1", "created": "Sun, 28 Oct 2018 04:02:27 GMT"}], "update_date": "2018-10-30", "authors_parsed": [["Chang", "Hao-Hsuan", ""], ["Song", "Hao", ""], ["Yi", "Yang", ""], ["Zhang", "Jianzhong", ""], ["He", "Haibo", ""], ["Liu", "Lingjia", ""]]}, {"id": "1810.11760", "submitter": "Luis Lamb", "authors": "Felipe Grando, Lisando Z. Granville and Luis C. Lamb", "title": "Machine Learning in Network Centrality Measures: Tutorial and Outlook", "comments": "7 tables, 9 figures, version accepted at ACM Computing Surveys.\n  https://doi.org/10.1145/3237192", "journal-ref": "ACM Comput. Surv. 51, 5, Article 102 (October 2018), 32 pages", "doi": "10.1145/3237192", "report-no": null, "categories": "cs.LG cs.NE cs.NI cs.SI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Complex networks are ubiquitous to several Computer Science domains.\nCentrality measures are an important analysis mechanism to uncover vital\nelements of complex networks. However, these metrics have high computational\ncosts and requirements that hinder their applications in large real-world\nnetworks. In this tutorial, we explain how the use of neural network learning\nalgorithms can render the application of the metrics in complex networks of\narbitrary size. Moreover, the tutorial describes how to identify the best\nconfiguration for neural network training and learning such for tasks, besides\npresenting an easy way to generate and acquire training data. We do so by means\nof a general methodology, using complex network models adaptable to any\napplication. We show that a regression model generated by the neural network\nsuccessfully approximates the metric values and therefore are a robust,\neffective alternative in real-world applications. The methodology and proposed\nmachine learning model use only a fraction of time with respect to other\napproximation algorithms, which is crucial in complex network applications.\n", "versions": [{"version": "v1", "created": "Sun, 28 Oct 2018 04:51:08 GMT"}], "update_date": "2018-10-30", "authors_parsed": [["Grando", "Felipe", ""], ["Granville", "Lisando Z.", ""], ["Lamb", "Luis C.", ""]]}, {"id": "1810.11764", "submitter": "Enzo Tartaglione", "authors": "Enzo Tartaglione, Skjalg Leps{\\o}y, Attilio Fiandrotti, Gianluca\n  Francini", "title": "Learning Sparse Neural Networks via Sensitivity-Driven Regularization", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cond-mat.dis-nn stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The ever-increasing number of parameters in deep neural networks poses\nchallenges for memory-limited applications. Regularize-and-prune methods aim at\nmeeting these challenges by sparsifying the network weights. In this context we\nquantify the output sensitivity to the parameters (i.e. their relevance to the\nnetwork output) and introduce a regularization term that gradually lowers the\nabsolute value of parameters with low sensitivity. Thus, a very large fraction\nof the parameters approach zero and are eventually set to zero by simple\nthresholding. Our method surpasses most of the recent techniques both in terms\nof sparsity and error rates. In some cases, the method reaches twice the\nsparsity obtained by other techniques at equal error rates.\n", "versions": [{"version": "v1", "created": "Sun, 28 Oct 2018 06:15:51 GMT"}], "update_date": "2018-10-30", "authors_parsed": [["Tartaglione", "Enzo", ""], ["Leps\u00f8y", "Skjalg", ""], ["Fiandrotti", "Attilio", ""], ["Francini", "Gianluca", ""]]}, {"id": "1810.11772", "submitter": "Huda Ibeid", "authors": "Huda Ibeid, Siping Meng, Oliver Dobon, Luke Olson, William Gropp", "title": "Learning with Analytical Models", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.PF cs.DC cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  To understand and predict the performance of scientific applications, several\nanalytical and machine learning approaches have been proposed, each having its\nadvantages and disadvantages. In this paper, we propose and validate a hybrid\napproach for performance modeling and prediction, which combines analytical and\nmachine learning models. The proposed hybrid model aims to minimize prediction\ncost while providing reasonable prediction accuracy. Our validation results\nshow that the hybrid model is able to learn and correct the analytical models\nto better match the actual performance. Furthermore, the proposed hybrid model\nimproves the prediction accuracy in comparison to pure machine learning\ntechniques while using small training datasets, thus making it suitable for\nhardware and workload changes.\n", "versions": [{"version": "v1", "created": "Sun, 28 Oct 2018 07:19:23 GMT"}, {"version": "v2", "created": "Tue, 26 Feb 2019 00:20:20 GMT"}], "update_date": "2019-02-27", "authors_parsed": [["Ibeid", "Huda", ""], ["Meng", "Siping", ""], ["Dobon", "Oliver", ""], ["Olson", "Luke", ""], ["Gropp", "William", ""]]}, {"id": "1810.11776", "submitter": "Niklas Pfister", "authors": "Niklas Pfister, Stefan Bauer and Jonas Peters", "title": "Learning stable and predictive structures in kinetic systems: Benefits\n  of a causal approach", "comments": null, "journal-ref": null, "doi": "10.1073/pnas.1905688116", "report-no": null, "categories": "stat.ML cs.LG stat.AP stat.ME", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Learning kinetic systems from data is one of the core challenges in many\nfields. Identifying stable models is essential for the generalization\ncapabilities of data-driven inference. We introduce a computationally efficient\nframework, called CausalKinetiX, that identifies structure from discrete time,\nnoisy observations, generated from heterogeneous experiments. The algorithm\nassumes the existence of an underlying, invariant kinetic model, a key\ncriterion for reproducible research. Results on both simulated and real-world\nexamples suggest that learning the structure of kinetic systems benefits from a\ncausal perspective. The identified variables and models allow for a concise\ndescription of the dynamics across multiple experimental settings and can be\nused for prediction in unseen experiments. We observe significant improvements\ncompared to well established approaches focusing solely on predictive\nperformance, especially for out-of-sample generalization.\n", "versions": [{"version": "v1", "created": "Sun, 28 Oct 2018 07:47:54 GMT"}, {"version": "v2", "created": "Thu, 28 Nov 2019 12:07:30 GMT"}], "update_date": "2019-12-02", "authors_parsed": [["Pfister", "Niklas", ""], ["Bauer", "Stefan", ""], ["Peters", "Jonas", ""]]}, {"id": "1810.11783", "submitter": "Huan Zhang", "authors": "Huan Zhang, Pengchuan Zhang, Cho-Jui Hsieh", "title": "RecurJac: An Efficient Recursive Algorithm for Bounding Jacobian Matrix\n  of Neural Networks and Its Applications", "comments": "Work done during internship at Microsoft Research", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.AI cs.LG math.OC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The Jacobian matrix (or the gradient for single-output networks) is directly\nrelated to many important properties of neural networks, such as the function\nlandscape, stationary points, (local) Lipschitz constants and robustness to\nadversarial attacks. In this paper, we propose a recursive algorithm, RecurJac,\nto compute both upper and lower bounds for each element in the Jacobian matrix\nof a neural network with respect to network's input, and the network can\ncontain a wide range of activation functions. As a byproduct, we can\nefficiently obtain a (local) Lipschitz constant, which plays a crucial role in\nneural network robustness verification, as well as the training stability of\nGANs. Experiments show that (local) Lipschitz constants produced by our method\nis of better quality than previous approaches, thus providing better robustness\nverification results. Our algorithm has polynomial time complexity, and its\ncomputation time is reasonable even for relatively large networks.\nAdditionally, we use our bounds of Jacobian matrix to characterize the\nlandscape of the neural network, for example, to determine whether there exist\nstationary points in a local neighborhood. Source code available at\n\\url{http://github.com/huanzhang12/RecurJac-Jacobian-bounds}.\n", "versions": [{"version": "v1", "created": "Sun, 28 Oct 2018 09:25:08 GMT"}, {"version": "v2", "created": "Wed, 27 Feb 2019 07:01:58 GMT"}], "update_date": "2019-02-28", "authors_parsed": [["Zhang", "Huan", ""], ["Zhang", "Pengchuan", ""], ["Hsieh", "Cho-Jui", ""]]}, {"id": "1810.11787", "submitter": "Karanbir Chahal", "authors": "Karanbir Chahal, Manraj Singh Grover, Kuntal Dey", "title": "A Hitchhiker's Guide On Distributed Training of Deep Neural Networks", "comments": "14 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.DC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep learning has led to tremendous advancements in the field of Artificial\nIntelligence. One caveat however is the substantial amount of compute needed to\ntrain these deep learning models. Training a benchmark dataset like ImageNet on\na single machine with a modern GPU can take upto a week, distributing training\non multiple machines has been observed to drastically bring this time down.\nRecent work has brought down ImageNet training time to a time as low as 4\nminutes by using a cluster of 2048 GPUs. This paper surveys the various\nalgorithms and techniques used to distribute training and presents the current\nstate of the art for a modern distributed training framework. More\nspecifically, we explore the synchronous and asynchronous variants of\ndistributed Stochastic Gradient Descent, various All Reduce gradient\naggregation strategies and best practices for obtaining higher throughout and\nlower latency over a cluster such as mixed precision training, large batch\ntraining and gradient compression.\n", "versions": [{"version": "v1", "created": "Sun, 28 Oct 2018 09:37:47 GMT"}], "update_date": "2018-10-30", "authors_parsed": [["Chahal", "Karanbir", ""], ["Grover", "Manraj Singh", ""], ["Dey", "Kuntal", ""]]}, {"id": "1810.11793", "submitter": "Hiromu Yakura", "authors": "Hiromu Yakura, Jun Sakuma", "title": "Robust Audio Adversarial Example for a Physical Attack", "comments": "Accepted to IJCAI 2019", "journal-ref": null, "doi": "10.24963/ijcai.2019/741", "report-no": null, "categories": "cs.LG cs.CR cs.SD eess.AS stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a method to generate audio adversarial examples that can attack a\nstate-of-the-art speech recognition model in the physical world. Previous work\nassumes that generated adversarial examples are directly fed to the recognition\nmodel, and is not able to perform such a physical attack because of\nreverberation and noise from playback environments. In contrast, our method\nobtains robust adversarial examples by simulating transformations caused by\nplayback or recording in the physical world and incorporating the\ntransformations into the generation process. Evaluation and a listening\nexperiment demonstrated that our adversarial examples are able to attack\nwithout being noticed by humans. This result suggests that audio adversarial\nexamples generated by the proposed method may become a real threat.\n", "versions": [{"version": "v1", "created": "Sun, 28 Oct 2018 10:50:24 GMT"}, {"version": "v2", "created": "Fri, 9 Nov 2018 23:18:45 GMT"}, {"version": "v3", "created": "Mon, 4 Mar 2019 08:40:25 GMT"}, {"version": "v4", "created": "Mon, 19 Aug 2019 02:22:51 GMT"}], "update_date": "2019-08-20", "authors_parsed": [["Yakura", "Hiromu", ""], ["Sakuma", "Jun", ""]]}, {"id": "1810.11829", "submitter": "Thodoris Lykouris", "authors": "Avrim Blum, Suriya Gunasekar, Thodoris Lykouris, Nathan Srebro", "title": "On preserving non-discrimination when combining expert advice", "comments": "Appeared in NIPS 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.DS stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the interplay between sequential decision making and avoiding\ndiscrimination against protected groups, when examples arrive online and do not\nfollow distributional assumptions. We consider the most basic extension of\nclassical online learning: \"Given a class of predictors that are individually\nnon-discriminatory with respect to a particular metric, how can we combine them\nto perform as well as the best predictor, while preserving non-discrimination?\"\nSurprisingly we show that this task is unachievable for the prevalent notion of\n\"equalized odds\" that requires equal false negative rates and equal false\npositive rates across groups. On the positive side, for another notion of\nnon-discrimination, \"equalized error rates\", we show that running separate\ninstances of the classical multiplicative weights algorithm for each group\nachieves this guarantee. Interestingly, even for this notion, we show that\nalgorithms with stronger performance guarantees than multiplicative weights\ncannot preserve non-discrimination.\n", "versions": [{"version": "v1", "created": "Sun, 28 Oct 2018 16:28:30 GMT"}, {"version": "v2", "created": "Fri, 29 Mar 2019 21:37:00 GMT"}], "update_date": "2019-04-02", "authors_parsed": [["Blum", "Avrim", ""], ["Gunasekar", "Suriya", ""], ["Lykouris", "Thodoris", ""], ["Srebro", "Nathan", ""]]}, {"id": "1810.11832", "submitter": "Luis Remis", "authors": "Luis Remis, Vishakha Gupta-Cledat, Christina Strong, Ragaad Altarawneh", "title": "VDMS: Efficient Big-Visual-Data Access for Machine Learning Workloads", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DB cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce the Visual Data Management System (VDMS), which enables faster\naccess to big-visual-data and adds support to visual analytics. This is\nachieved by searching for relevant visual data via metadata stored as a graph,\nand enabling faster access to visual data through new machine-friendly storage\nformats. VDMS differs from existing large scale photo serving, video streaming,\nand textual big-data management systems due to its primary focus on supporting\nmachine learning and data analytics pipelines that use visual data (images,\nvideos, and feature vectors), treating these as first class entities. We\ndescribe how to use VDMS via its user friendly interface and how it enables\nrich and efficient vision analytics through a machine learning pipeline for\nprocessing medical images. We show the improved performance of 2x in complex\nqueries over a comparable set-up.\n", "versions": [{"version": "v1", "created": "Sun, 28 Oct 2018 16:41:22 GMT"}, {"version": "v2", "created": "Sat, 1 Dec 2018 18:38:44 GMT"}, {"version": "v3", "created": "Tue, 11 Dec 2018 15:42:14 GMT"}], "update_date": "2018-12-12", "authors_parsed": [["Remis", "Luis", ""], ["Gupta-Cledat", "Vishakha", ""], ["Strong", "Christina", ""], ["Altarawneh", "Ragaad", ""]]}, {"id": "1810.11843", "submitter": "Stephen Pasteris", "authors": "Stephen Pasteris, Fabio Vitale, Kevin Chan, Shiqiang Wang, Mark\n  Herbster", "title": "MaxHedge: Maximising a Maximum Online", "comments": "Published in AISTATS 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce a new online learning framework where, at each trial, the\nlearner is required to select a subset of actions from a given known action\nset. Each action is associated with an energy value, a reward and a cost. The\nsum of the energies of the actions selected cannot exceed a given energy\nbudget. The goal is to maximise the cumulative profit, where the profit\nobtained on a single trial is defined as the difference between the maximum\nreward among the selected actions and the sum of their costs. Action energy\nvalues and the budget are known and fixed. All rewards and costs associated\nwith each action change over time and are revealed at each trial only after the\nlearner's selection of actions. Our framework encompasses several online\nlearning problems where the environment changes over time; and the solution\ntrades-off between minimising the costs and maximising the maximum reward of\nthe selected subset of actions, while being constrained to an action energy\nbudget. The algorithm that we propose is efficient and general in that it may\nbe specialised to multiple natural online combinatorial problems.\n", "versions": [{"version": "v1", "created": "Sun, 28 Oct 2018 17:38:32 GMT"}, {"version": "v2", "created": "Sun, 30 Jun 2019 13:22:38 GMT"}], "update_date": "2019-07-02", "authors_parsed": [["Pasteris", "Stephen", ""], ["Vitale", "Fabio", ""], ["Chan", "Kevin", ""], ["Wang", "Shiqiang", ""], ["Herbster", "Mark", ""]]}, {"id": "1810.11846", "submitter": "Jean-Marc Valin", "authors": "Jean-Marc Valin, Jan Skoglund", "title": "LPCNet: Improving Neural Speech Synthesis Through Linear Prediction", "comments": "ICASSP 2019, 5 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.AS cs.LG cs.SD", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Neural speech synthesis models have recently demonstrated the ability to\nsynthesize high quality speech for text-to-speech and compression applications.\nThese new models often require powerful GPUs to achieve real-time operation, so\nbeing able to reduce their complexity would open the way for many new\napplications. We propose LPCNet, a WaveRNN variant that combines linear\nprediction with recurrent neural networks to significantly improve the\nefficiency of speech synthesis. We demonstrate that LPCNet can achieve\nsignificantly higher quality than WaveRNN for the same network size and that\nhigh quality LPCNet speech synthesis is achievable with a complexity under 3\nGFLOPS. This makes it easier to deploy neural synthesis applications on\nlower-power devices, such as embedded systems and mobile phones.\n", "versions": [{"version": "v1", "created": "Sun, 28 Oct 2018 17:59:57 GMT"}, {"version": "v2", "created": "Tue, 19 Feb 2019 05:08:46 GMT"}], "update_date": "2019-02-20", "authors_parsed": [["Valin", "Jean-Marc", ""], ["Skoglund", "Jan", ""]]}, {"id": "1810.11857", "submitter": "Wenbo Ren", "authors": "Wenbo Ren, Jia Liu, Ness Shroff", "title": "Exploring $k$ out of Top $\\rho$ Fraction of Arms in Stochastic Bandits", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper studies the problem of identifying any $k$ distinct arms among the\ntop $\\rho$ fraction (e.g., top 5\\%) of arms from a finite or infinite set with\na probably approximately correct (PAC) tolerance $\\epsilon$. We consider two\ncases: (i) when the threshold of the top arms' expected rewards is known and\n(ii) when it is unknown. We prove lower bounds for the four variants (finite or\ninfinite arms, and known or unknown threshold), and propose algorithms for\neach. Two of these algorithms are shown to be sample complexity optimal (up to\nconstant factors) and the other two are optimal up to a log factor. Results in\nthis paper provide up to $\\rho n/k$ reductions compared with the\n\"$k$-exploration\" algorithms that focus on finding the (PAC) best $k$ arms out\nof $n$ arms. We also numerically show improvements over the state-of-the-art.\n", "versions": [{"version": "v1", "created": "Sun, 28 Oct 2018 18:40:16 GMT"}, {"version": "v2", "created": "Thu, 19 Nov 2020 06:24:53 GMT"}], "update_date": "2020-11-20", "authors_parsed": [["Ren", "Wenbo", ""], ["Liu", "Jia", ""], ["Shroff", "Ness", ""]]}, {"id": "1810.11861", "submitter": "Andrew Wilson", "authors": "William Herlands, Daniel B. Neill, Hannes Nickisch, Andrew Gordon\n  Wilson", "title": "Change Surfaces for Expressive Multidimensional Changepoints and\n  Counterfactual Prediction", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.AI cs.LG stat.ME", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Identifying changes in model parameters is fundamental in machine learning\nand statistics. However, standard changepoint models are limited in\nexpressiveness, often addressing unidimensional problems and assuming\ninstantaneous changes. We introduce change surfaces as a multidimensional and\nhighly expressive generalization of changepoints. We provide a model-agnostic\nformalization of change surfaces, illustrating how they can provide variable,\nheterogeneous, and non-monotonic rates of change across multiple dimensions.\nAdditionally, we show how change surfaces can be used for counterfactual\nprediction. As a concrete instantiation of the change surface framework, we\ndevelop Gaussian Process Change Surfaces (GPCS). We demonstrate counterfactual\nprediction with Bayesian posterior mean and credible sets, as well as massive\nscalability by introducing novel methods for additive non-separable kernels.\nUsing two large spatio-temporal datasets we employ GPCS to discover and\ncharacterize complex changes that can provide scientific and policy relevant\ninsights. Specifically, we analyze twentieth century measles incidence across\nthe United States and discover previously unknown heterogeneous changes after\nthe introduction of the measles vaccine. Additionally, we apply the model to\nrequests for lead testing kits in New York City, discovering distinct spatial\nand demographic patterns.\n", "versions": [{"version": "v1", "created": "Sun, 28 Oct 2018 19:08:18 GMT"}, {"version": "v2", "created": "Tue, 30 Oct 2018 11:56:42 GMT"}], "update_date": "2018-10-31", "authors_parsed": [["Herlands", "William", ""], ["Neill", "Daniel B.", ""], ["Nickisch", "Hannes", ""], ["Wilson", "Andrew Gordon", ""]]}, {"id": "1810.11867", "submitter": "Erik Lindgren", "authors": "Erik M. Lindgren, Murat Kocaoglu, Alexandros G. Dimakis, Sriram\n  Vishwanath", "title": "Experimental Design for Cost-Aware Learning of Causal Graphs", "comments": "In NIPS 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.DM stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the minimum cost intervention design problem: Given the essential\ngraph of a causal graph and a cost to intervene on a variable, identify the set\nof interventions with minimum total cost that can learn any causal graph with\nthe given essential graph. We first show that this problem is NP-hard. We then\nprove that we can achieve a constant factor approximation to this problem with\na greedy algorithm. We then constrain the sparsity of each intervention. We\ndevelop an algorithm that returns an intervention design that is nearly optimal\nin terms of size for sparse graphs with sparse interventions and we discuss how\nto use it when there are costs on the vertices.\n", "versions": [{"version": "v1", "created": "Sun, 28 Oct 2018 19:28:59 GMT"}], "update_date": "2018-10-30", "authors_parsed": [["Lindgren", "Erik M.", ""], ["Kocaoglu", "Murat", ""], ["Dimakis", "Alexandros G.", ""], ["Vishwanath", "Sriram", ""]]}, {"id": "1810.11874", "submitter": "Yanyao Shen", "authors": "Yanyao Shen and Sujay Sanghavi", "title": "Learning with Bad Training Data via Iterative Trimmed Loss Minimization", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we study a simple and generic framework to tackle the problem\nof learning model parameters when a fraction of the training samples are\ncorrupted. We first make a simple observation: in a variety of such settings,\nthe evolution of training accuracy (as a function of training epochs) is\ndifferent for clean and bad samples. Based on this we propose to iteratively\nminimize the trimmed loss, by alternating between (a) selecting samples with\nlowest current loss, and (b) retraining a model on only these samples. We prove\nthat this process recovers the ground truth (with linear convergence rate) in\ngeneralized linear models with standard statistical assumptions.\nExperimentally, we demonstrate its effectiveness in three settings: (a) deep\nimage classifiers with errors only in labels, (b) generative adversarial\nnetworks with bad training images, and (c) deep image classifiers with\nadversarial (image, label) pairs (i.e., backdoor attacks). For the well-studied\nsetting of random label noise, our algorithm achieves state-of-the-art\nperformance without having access to any a-priori guaranteed clean samples.\n", "versions": [{"version": "v1", "created": "Sun, 28 Oct 2018 20:10:22 GMT"}, {"version": "v2", "created": "Mon, 18 Feb 2019 22:35:31 GMT"}], "update_date": "2019-02-20", "authors_parsed": [["Shen", "Yanyao", ""], ["Sanghavi", "Sujay", ""]]}, {"id": "1810.11890", "submitter": "Linfeng Zhang", "authors": "Linfeng Zhang, De-Ye Lin, Han Wang, Roberto Car, Weinan E", "title": "Active Learning of Uniformly Accurate Inter-atomic Potentials for\n  Materials Simulation", "comments": null, "journal-ref": "Phys. Rev. Materials 3, 023804 (2019)", "doi": "10.1103/PhysRevMaterials.3.023804", "report-no": null, "categories": "physics.comp-ph cond-mat.mtrl-sci cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  An active learning procedure called Deep Potential Generator (DP-GEN) is\nproposed for the construction of accurate and transferable machine\nlearning-based models of the potential energy surface (PES) for the molecular\nmodeling of materials. This procedure consists of three main components:\nexploration, generation of accurate reference data, and training. Application\nto the sample systems of Al, Mg and Al-Mg alloys demonstrates that DP-GEN can\nproduce uniformly accurate PES models with a minimal number of reference data.\n", "versions": [{"version": "v1", "created": "Sun, 28 Oct 2018 21:45:27 GMT"}, {"version": "v2", "created": "Wed, 6 Feb 2019 05:26:08 GMT"}], "update_date": "2019-03-06", "authors_parsed": [["Zhang", "Linfeng", ""], ["Lin", "De-Ye", ""], ["Wang", "Han", ""], ["Car", "Roberto", ""], ["E", "Weinan", ""]]}, {"id": "1810.11893", "submitter": "Ulrich Paquet", "authors": "Ulrich Paquet and Marco Fraccaro", "title": "An Efficient Implementation of Riemannian Manifold Hamiltonian Monte\n  Carlo for Gaussian Process Models", "comments": "Technical report accompanying arXiv:1604.01972, \"An Adaptive\n  Resample-Move Algorithm for Estimating Normalizing Constants\" (2016)", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This technical report presents pseudo-code for a Riemannian manifold\nHamiltonian Monte Carlo (RMHMC) method to efficiently simulate samples from\n$N$-dimensional posterior distributions $p(x|y)$, where $x \\in R^N$ is drawn\nfrom a Gaussian Process (GP) prior, and observations $y_n$ are independent\ngiven $x_n$. Sufficient technical and algorithmic details are provided for the\nimplementation of RMHMC for distributions arising from GP priors.\n", "versions": [{"version": "v1", "created": "Sun, 28 Oct 2018 22:10:26 GMT"}], "update_date": "2018-10-30", "authors_parsed": [["Paquet", "Ulrich", ""], ["Fraccaro", "Marco", ""]]}, {"id": "1810.11896", "submitter": "Nima Anari", "authors": "Nima Anari, Constantinos Daskalakis, Wolfgang Maass, Christos H.\n  Papadimitriou, Amin Saberi, Santosh Vempala", "title": "Smoothed Analysis of Discrete Tensor Decomposition and Assemblies of\n  Neurons", "comments": "To appear in NIPS 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.LG cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We analyze linear independence of rank one tensors produced by tensor powers\nof randomly perturbed vectors. This enables efficient decomposition of sums of\nhigh-order tensors. Our analysis builds upon [BCMV14] but allows for a wider\nrange of perturbation models, including discrete ones. We give an application\nto recovering assemblies of neurons.\n  Assemblies are large sets of neurons representing specific memories or\nconcepts. The size of the intersection of two assemblies has been shown in\nexperiments to represent the extent to which these memories co-occur or these\nconcepts are related; the phenomenon is called association of assemblies. This\nsuggests that an animal's memory is a complex web of associations, and poses\nthe problem of recovering this representation from cognitive data. Motivated by\nthis problem, we study the following more general question: Can we reconstruct\nthe Venn diagram of a family of sets, given the sizes of their $\\ell$-wise\nintersections? We show that as long as the family of sets is randomly\nperturbed, it is enough for the number of measurements to be polynomially\nlarger than the number of nonempty regions of the Venn diagram to fully\nreconstruct the diagram.\n", "versions": [{"version": "v1", "created": "Sun, 28 Oct 2018 22:15:48 GMT"}], "update_date": "2018-10-30", "authors_parsed": [["Anari", "Nima", ""], ["Daskalakis", "Constantinos", ""], ["Maass", "Wolfgang", ""], ["Papadimitriou", "Christos H.", ""], ["Saberi", "Amin", ""], ["Vempala", "Santosh", ""]]}, {"id": "1810.11899", "submitter": "Hongkuan Zhou", "authors": "Hanqing Zeng, Hongkuan Zhou, Ajitesh Srivastava, Rajgopal Kannan,\n  Viktor Prasanna", "title": "Accurate, Efficient and Scalable Graph Embedding", "comments": "10 pages. 2019 IEEE International Parallel and Distributed Processing\n  Symposium (IPDPS)", "journal-ref": null, "doi": "10.1109/IPDPS.2019.00056", "report-no": null, "categories": "cs.LG cs.PF stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The Graph Convolutional Network (GCN) model and its variants are powerful\ngraph embedding tools for facilitating classification and clustering on graphs.\nHowever, a major challenge is to reduce the complexity of layered GCNs and make\nthem parallelizable and scalable on very large graphs -- state-of the art\ntechniques are unable to achieve scalability without losing accuracy and\nefficiency. In this paper, we propose novel parallelization techniques for\ngraph sampling-based GCNs that achieve superior scalable performance on very\nlarge graphs without compromising accuracy. Specifically, our GCN guarantees\nwork-efficient training and produces order of magnitude savings in computation\nand communication. To scale GCN training on tightly-coupled shared memory\nsystems, we develop parallelization strategies for the key steps in training:\nFor the graph sampling step, we exploit parallelism within and across multiple\nsampling instances, and devise an efficient data structure for concurrent\naccesses that provides theoretical guarantee of near-linear speedup with number\nof processing units. For the feature propagation step within the sampled graph,\nwe improve cache utilization and reduce DRAM communication by data\npartitioning. We prove that our partitioning strategy is a 2-approximation for\nminimizing the communication time compared to the optimal strategy. We\ndemonstrate that our parallel graph embedding outperforms state-of-the-art\nmethods in scalability (with respect to number of processors, graph size and\nGCN model size), efficiency and accuracy on several large datasets. On a\n40-core Xeon platform, our parallel training achieves $64\\times$ speedup (with\nAVX) in the sampling step and $25\\times$ speedup in the feature propagation\nstep, compared to the serial implementation, resulting in a net speedup of\n$21\\times$.\n", "versions": [{"version": "v1", "created": "Sun, 28 Oct 2018 22:44:51 GMT"}, {"version": "v2", "created": "Tue, 30 Oct 2018 04:49:54 GMT"}, {"version": "v3", "created": "Wed, 5 Aug 2020 17:51:08 GMT"}], "update_date": "2020-08-06", "authors_parsed": [["Zeng", "Hanqing", ""], ["Zhou", "Hongkuan", ""], ["Srivastava", "Ajitesh", ""], ["Kannan", "Rajgopal", ""], ["Prasanna", "Viktor", ""]]}, {"id": "1810.11905", "submitter": "Shanshan Wu", "authors": "Shanshan Wu, Sujay Sanghavi, Alexandros G. Dimakis", "title": "Sparse Logistic Regression Learns All Discrete Pairwise Graphical Models", "comments": "30 pages, 3 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.DS math.ST stat.ML stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We characterize the effectiveness of a classical algorithm for recovering the\nMarkov graph of a general discrete pairwise graphical model from i.i.d.\nsamples. The algorithm is (appropriately regularized) maximum conditional\nlog-likelihood, which involves solving a convex program for each node; for\nIsing models this is $\\ell_1$-constrained logistic regression, while for more\ngeneral alphabets an $\\ell_{2,1}$ group-norm constraint needs to be used. We\nshow that this algorithm can recover any arbitrary discrete pairwise graphical\nmodel, and also characterize its sample complexity as a function of model\nwidth, alphabet size, edge parameter accuracy, and the number of variables. We\nshow that along every one of these axes, it matches or improves on all existing\nresults and algorithms for this problem. Our analysis applies a sharp\ngeneralization error bound for logistic regression when the weight vector has\nan $\\ell_1$ constraint (or $\\ell_{2,1}$ constraint) and the sample vector has\nan $\\ell_{\\infty}$ constraint (or $\\ell_{2, \\infty}$ constraint). We also show\nthat the proposed convex programs can be efficiently solved in $\\tilde{O}(n^2)$\nrunning time (where $n$ is the number of variables) under the same statistical\nguarantees. We provide experimental results to support our analysis.\n", "versions": [{"version": "v1", "created": "Sun, 28 Oct 2018 23:40:42 GMT"}, {"version": "v2", "created": "Sun, 3 Feb 2019 03:40:47 GMT"}, {"version": "v3", "created": "Tue, 18 Jun 2019 20:53:05 GMT"}], "update_date": "2019-06-20", "authors_parsed": [["Wu", "Shanshan", ""], ["Sanghavi", "Sujay", ""], ["Dimakis", "Alexandros G.", ""]]}, {"id": "1810.11906", "submitter": "Mark Hamilton", "authors": "Mark Hamilton", "title": "Semi-Supervised Translation with MMD Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CL stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  This work aims to improve semi-supervised learning in a neural network\narchitecture by introducing a hybrid supervised and unsupervised cost function.\nThe unsupervised component is trained using a differentiable estimator of the\nMaximum Mean Discrepancy (MMD) distance between the network output and the\ntarget dataset. We introduce the notion of an $n$-channel network and several\nmethods to improve performance of these nets based on supervised\npre-initialization, and multi-scale kernels. This work investigates the\neffectiveness of these methods on language translation where very few quality\ntranslations are known \\textit{a priori}. We also present a thorough\ninvestigation of the hyper-parameter space of this method on both synthetic\ndata.\n", "versions": [{"version": "v1", "created": "Sun, 28 Oct 2018 23:40:54 GMT"}], "update_date": "2018-10-30", "authors_parsed": [["Hamilton", "Mark", ""]]}, {"id": "1810.11908", "submitter": "Tatsuro Kawamoto", "authors": "Tatsuro Kawamoto, Masashi Tsubaki, Tomoyuki Obuchi", "title": "Mean-field theory of graph neural networks in graph partitioning", "comments": "16 pages, 6 figures, Thirty-second Conference on Neural Information\n  Processing Systems (NIPS2018)", "journal-ref": null, "doi": "10.1088/1742-5468/ab3456", "report-no": null, "categories": "cs.LG cs.SI physics.soc-ph stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A theoretical performance analysis of the graph neural network (GNN) is\npresented. For classification tasks, the neural network approach has the\nadvantage in terms of flexibility that it can be employed in a data-driven\nmanner, whereas Bayesian inference requires the assumption of a specific model.\nA fundamental question is then whether GNN has a high accuracy in addition to\nthis flexibility. Moreover, whether the achieved performance is predominately a\nresult of the backpropagation or the architecture itself is a matter of\nconsiderable interest. To gain a better insight into these questions, a\nmean-field theory of a minimal GNN architecture is developed for the graph\npartitioning problem. This demonstrates a good agreement with numerical\nexperiments.\n", "versions": [{"version": "v1", "created": "Mon, 29 Oct 2018 00:09:48 GMT"}], "update_date": "2020-01-29", "authors_parsed": [["Kawamoto", "Tatsuro", ""], ["Tsubaki", "Masashi", ""], ["Obuchi", "Tomoyuki", ""]]}, {"id": "1810.11910", "submitter": "Matthew Riemer", "authors": "Matthew Riemer, Ignacio Cases, Robert Ajemian, Miao Liu, Irina Rish,\n  Yuhai Tu, Gerald Tesauro", "title": "Learning to Learn without Forgetting by Maximizing Transfer and\n  Minimizing Interference", "comments": "ICLR 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Lack of performance when it comes to continual learning over non-stationary\ndistributions of data remains a major challenge in scaling neural network\nlearning to more human realistic settings. In this work we propose a new\nconceptualization of the continual learning problem in terms of a temporally\nsymmetric trade-off between transfer and interference that can be optimized by\nenforcing gradient alignment across examples. We then propose a new algorithm,\nMeta-Experience Replay (MER), that directly exploits this view by combining\nexperience replay with optimization based meta-learning. This method learns\nparameters that make interference based on future gradients less likely and\ntransfer based on future gradients more likely. We conduct experiments across\ncontinual lifelong supervised learning benchmarks and non-stationary\nreinforcement learning environments demonstrating that our approach\nconsistently outperforms recently proposed baselines for continual learning.\nOur experiments show that the gap between the performance of MER and baseline\nalgorithms grows both as the environment gets more non-stationary and as the\nfraction of the total experiences stored gets smaller.\n", "versions": [{"version": "v1", "created": "Mon, 29 Oct 2018 00:13:50 GMT"}, {"version": "v2", "created": "Sun, 2 Dec 2018 19:23:28 GMT"}, {"version": "v3", "created": "Fri, 3 May 2019 03:32:40 GMT"}], "update_date": "2019-05-06", "authors_parsed": [["Riemer", "Matthew", ""], ["Cases", "Ignacio", ""], ["Ajemian", "Robert", ""], ["Liu", "Miao", ""], ["Rish", "Irina", ""], ["Tu", "Yuhai", ""], ["Tesauro", "Gerald", ""]]}, {"id": "1810.11911", "submitter": "Viet Huynh", "authors": "Nhat Ho, Viet Huynh, Dinh Phung, Michael I. Jordan", "title": "Probabilistic Multilevel Clustering via Composite Transportation\n  Distance", "comments": "25 pages, 3 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We propose a novel probabilistic approach to multilevel clustering problems\nbased on composite transportation distance, which is a variant of\ntransportation distance where the underlying metric is Kullback-Leibler\ndivergence. Our method involves solving a joint optimization problem over\nspaces of probability measures to simultaneously discover grouping structures\nwithin groups and among groups. By exploiting the connection of our method to\nthe problem of finding composite transportation barycenters, we develop fast\nand efficient optimization algorithms even for potentially large-scale\nmultilevel datasets. Finally, we present experimental results with both\nsynthetic and real data to demonstrate the efficiency and scalability of the\nproposed approach.\n", "versions": [{"version": "v1", "created": "Mon, 29 Oct 2018 00:26:29 GMT"}], "update_date": "2018-10-30", "authors_parsed": [["Ho", "Nhat", ""], ["Huynh", "Viet", ""], ["Phung", "Dinh", ""], ["Jordan", "Michael I.", ""]]}, {"id": "1810.11914", "submitter": "Dong Yin", "authors": "Dong Yin and Kannan Ramchandran and Peter Bartlett", "title": "Rademacher Complexity for Adversarially Robust Generalization", "comments": "ICML 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Many machine learning models are vulnerable to adversarial attacks; for\nexample, adding adversarial perturbations that are imperceptible to humans can\noften make machine learning models produce wrong predictions with high\nconfidence. Moreover, although we may obtain robust models on the training\ndataset via adversarial training, in some problems the learned models cannot\ngeneralize well to the test data. In this paper, we focus on $\\ell_\\infty$\nattacks, and study the adversarially robust generalization problem through the\nlens of Rademacher complexity. For binary linear classifiers, we prove tight\nbounds for the adversarial Rademacher complexity, and show that the adversarial\nRademacher complexity is never smaller than its natural counterpart, and it has\nan unavoidable dimension dependence, unless the weight vector has bounded\n$\\ell_1$ norm. The results also extend to multi-class linear classifiers. For\n(nonlinear) neural networks, we show that the dimension dependence in the\nadversarial Rademacher complexity also exists. We further consider a surrogate\nadversarial loss for one-hidden layer ReLU network and prove margin bounds for\nthis setting. Our results indicate that having $\\ell_1$ norm constraints on the\nweight matrices might be a potential way to improve generalization in the\nadversarial setting. We demonstrate experimental results that validate our\ntheoretical findings.\n", "versions": [{"version": "v1", "created": "Mon, 29 Oct 2018 00:51:08 GMT"}, {"version": "v2", "created": "Wed, 7 Nov 2018 06:40:59 GMT"}, {"version": "v3", "created": "Fri, 25 Jan 2019 07:03:12 GMT"}, {"version": "v4", "created": "Wed, 29 Jul 2020 04:23:34 GMT"}], "update_date": "2020-07-30", "authors_parsed": [["Yin", "Dong", ""], ["Ramchandran", "Kannan", ""], ["Bartlett", "Peter", ""]]}, {"id": "1810.11921", "submitter": "Weiping Song", "authors": "Weiping Song, Chence Shi, Zhiping Xiao, Zhijian Duan, Yewen Xu, Ming\n  Zhang, Jian Tang", "title": "AutoInt: Automatic Feature Interaction Learning via Self-Attentive\n  Neural Networks", "comments": "Accepted at CIKM2019", "journal-ref": null, "doi": "10.1145/3357384.3357925", "report-no": null, "categories": "cs.IR cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Click-through rate (CTR) prediction, which aims to predict the probability of\na user clicking on an ad or an item, is critical to many online applications\nsuch as online advertising and recommender systems. The problem is very\nchallenging since (1) the input features (e.g., the user id, user age, item id,\nitem category) are usually sparse and high-dimensional, and (2) an effective\nprediction relies on high-order combinatorial features (\\textit{a.k.a.} cross\nfeatures), which are very time-consuming to hand-craft by domain experts and\nare impossible to be enumerated. Therefore, there have been efforts in finding\nlow-dimensional representations of the sparse and high-dimensional raw features\nand their meaningful combinations. In this paper, we propose an effective and\nefficient method called the \\emph{AutoInt} to automatically learn the\nhigh-order feature interactions of input features. Our proposed algorithm is\nvery general, which can be applied to both numerical and categorical input\nfeatures. Specifically, we map both the numerical and categorical features into\nthe same low-dimensional space. Afterwards, a multi-head self-attentive neural\nnetwork with residual connections is proposed to explicitly model the feature\ninteractions in the low-dimensional space. With different layers of the\nmulti-head self-attentive neural networks, different orders of feature\ncombinations of input features can be modeled. The whole model can be\nefficiently fit on large-scale raw data in an end-to-end fashion. Experimental\nresults on four real-world datasets show that our proposed approach not only\noutperforms existing state-of-the-art approaches for prediction but also offers\ngood explainability. Code is available at:\n\\url{https://github.com/DeepGraphLearning/RecommenderSystems}.\n", "versions": [{"version": "v1", "created": "Mon, 29 Oct 2018 01:56:25 GMT"}, {"version": "v2", "created": "Fri, 23 Aug 2019 19:51:41 GMT"}], "update_date": "2019-08-27", "authors_parsed": [["Song", "Weiping", ""], ["Shi", "Chence", ""], ["Xiao", "Zhiping", ""], ["Duan", "Zhijian", ""], ["Xu", "Yewen", ""], ["Zhang", "Ming", ""], ["Tang", "Jian", ""]]}, {"id": "1810.11922", "submitter": "Min-Hsiu Hsieh", "authors": "Yuxuan Du and Min-Hsiu Hsieh and Tongliang Liu and Dacheng Tao", "title": "The Expressive Power of Parameterized Quantum Circuits", "comments": "Comments welcomed!", "journal-ref": "Phys. Rev. Research 2, 033125 (2020)", "doi": "10.1103/PhysRevResearch.2.033125", "report-no": null, "categories": "quant-ph cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Parameterized quantum circuits (PQCs) have been broadly used as a hybrid\nquantum-classical machine learning scheme to accomplish generative tasks.\nHowever, whether PQCs have better expressive power than classical generative\nneural networks, such as restricted or deep Boltzmann machines, remains an open\nissue. In this paper, we prove that PQCs with a simple structure already\noutperform any classical neural network for generative tasks, unless the\npolynomial hierarchy collapses. Our proof builds on known results from tensor\nnetworks and quantum circuits (in particular, instantaneous quantum polynomial\ncircuits). In addition, PQCs equipped with ancillary qubits for post-selection\nhave even stronger expressive power than those without post-selection. We\nemploy them as an application for Bayesian learning, since it is possible to\nlearn prior probabilities rather than assuming they are known. We expect that\nit will find many more applications in semi-supervised learning where prior\ndistributions are normally assumed to be unknown. Lastly, we conduct several\nnumerical experiments using the Rigetti Forest platform to demonstrate the\nperformance of the proposed Bayesian quantum circuit.\n", "versions": [{"version": "v1", "created": "Mon, 29 Oct 2018 02:32:40 GMT"}], "update_date": "2020-07-29", "authors_parsed": [["Du", "Yuxuan", ""], ["Hsieh", "Min-Hsiu", ""], ["Liu", "Tongliang", ""], ["Tao", "Dacheng", ""]]}, {"id": "1810.11943", "submitter": "Dilin Wang", "authors": "Dilin Wang, Hao Liu, Qiang Liu", "title": "Variational Inference with Tail-adaptive f-Divergence", "comments": "NeurIPS 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Variational inference with {\\alpha}-divergences has been widely used in\nmodern probabilistic machine learning. Compared to Kullback-Leibler (KL)\ndivergence, a major advantage of using {\\alpha}-divergences (with positive\n{\\alpha} values) is their mass-covering property. However, estimating and\noptimizing {\\alpha}-divergences require to use importance sampling, which could\nhave extremely large or infinite variances due to heavy tails of importance\nweights. In this paper, we propose a new class of tail-adaptive f-divergences\nthat adaptively change the convex function f with the tail of the importance\nweights, in a way that theoretically guarantees finite moments, while\nsimultaneously achieving mass-covering properties. We test our methods on\nBayesian neural networks, as well as deep reinforcement learning in which our\nmethod is applied to improve a recent soft actor-critic (SAC) algorithm. Our\nresults show that our approach yields significant advantages compared with\nexisting methods based on classical KL and {\\alpha}-divergences.\n", "versions": [{"version": "v1", "created": "Mon, 29 Oct 2018 03:52:53 GMT"}, {"version": "v2", "created": "Sat, 12 Jan 2019 02:56:59 GMT"}, {"version": "v3", "created": "Mon, 9 Sep 2019 17:26:00 GMT"}], "update_date": "2019-09-10", "authors_parsed": [["Wang", "Dilin", ""], ["Liu", "Hao", ""], ["Liu", "Qiang", ""]]}, {"id": "1810.11953", "submitter": "Stephan Rabanser", "authors": "Stephan Rabanser, Stephan G\\\"unnemann, Zachary C. Lipton", "title": "Failing Loudly: An Empirical Study of Methods for Detecting Dataset\n  Shift", "comments": "Advances in Neural Information Processing Systems (NeurIPS) 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We might hope that when faced with unexpected inputs, well-designed software\nsystems would fire off warnings. Machine learning (ML) systems, however, which\ndepend strongly on properties of their inputs (e.g. the i.i.d. assumption),\ntend to fail silently. This paper explores the problem of building ML systems\nthat fail loudly, investigating methods for detecting dataset shift,\nidentifying exemplars that most typify the shift, and quantifying shift\nmalignancy. We focus on several datasets and various perturbations to both\ncovariates and label distributions with varying magnitudes and fractions of\ndata affected. Interestingly, we show that across the dataset shifts that we\nexplore, a two-sample-testing-based approach, using pre-trained classifiers for\ndimensionality reduction, performs best. Moreover, we demonstrate that\ndomain-discriminating approaches tend to be helpful for characterizing shifts\nqualitatively and determining if they are harmful.\n", "versions": [{"version": "v1", "created": "Mon, 29 Oct 2018 04:50:18 GMT"}, {"version": "v2", "created": "Thu, 24 Jan 2019 11:03:45 GMT"}, {"version": "v3", "created": "Wed, 28 Aug 2019 09:47:56 GMT"}, {"version": "v4", "created": "Mon, 28 Oct 2019 14:56:15 GMT"}], "update_date": "2019-10-29", "authors_parsed": [["Rabanser", "Stephan", ""], ["G\u00fcnnemann", "Stephan", ""], ["Lipton", "Zachary C.", ""]]}, {"id": "1810.11956", "submitter": "Sebastien Blandin", "authors": "Marc Jourdan, Sebastien Blandin, Laura Wynter, Pralhad Deshpande", "title": "Characterizing Entities in the Bitcoin Blockchain", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Bitcoin has created a new exchange paradigm within which financial\ntransactions can be trusted without an intermediary. This premise of a free\ndecentralized transactional network however requires, in its current\nimplementation, unrestricted access to the ledger for peer-based transaction\nverification. A number of studies have shown that, in this pseudonymous\ncontext, identities can be leaked based on transaction features or off-network\ninformation. In this work, we analyze the information revealed by the pattern\nof transactions in the neighborhood of a given entity transaction. By\ndefinition, these features which pertain to an extended network are not\ndirectly controllable by the entity, but might enable leakage of information\nabout transacting entities. We define a number of new features relevant to\nentity characterization on the Bitcoin Blockchain and study their efficacy in\npractice. We show that even a weak attacker with shallow data mining knowledge\nis able to leverage these features to characterize the entity properties.\n", "versions": [{"version": "v1", "created": "Mon, 29 Oct 2018 05:05:00 GMT"}], "update_date": "2018-10-30", "authors_parsed": [["Jourdan", "Marc", ""], ["Blandin", "Sebastien", ""], ["Wynter", "Laura", ""], ["Deshpande", "Pralhad", ""]]}, {"id": "1810.11959", "submitter": "Geraci Joseph", "authors": "Siddhant Jain, Jalal Ziauddin, Paul Leonchyk, Joseph Geraci", "title": "An Amalgamation of Classical and Quantum Machine Learning For the\n  Classification of Adenocarcinoma and Squamous Cell Carcinoma Patients", "comments": "19 pages, 8 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG quant-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The ability to accurately classify disease subtypes is of vital importance,\nespecially in oncology where this capability could have a life saving impact.\nHere we report a classification between two subtypes of non-small cell lung\ncancer, namely Adeno- carcinoma vs Squamous cell carcinoma. The data consists\nof approximately 20,000 gene expression values for each of 104 patients. The\ndata was curated from [1] [2]. We used an amalgamation of classical and and\nquantum machine learning models to successfully classify these patients. We\nutilized feature selection methods based on univariate statistics in addition\nto XGBoost [3]. A novel and proprietary data representation method developed by\none of the authors called QCrush was also used as it was designed to\nincorporate a maximal amount of information under the size constraints of the\nD-Wave quantum annealing computer. The machine learning was performed by a\nQuantum Boltzmann Machine. This paper will report our results, the various\nclassical methods, and the quantum machine learning approach we utilized.\n", "versions": [{"version": "v1", "created": "Mon, 29 Oct 2018 05:22:51 GMT"}], "update_date": "2018-10-30", "authors_parsed": [["Jain", "Siddhant", ""], ["Ziauddin", "Jalal", ""], ["Leonchyk", "Paul", ""], ["Geraci", "Joseph", ""]]}, {"id": "1810.11971", "submitter": "Yucen Luo", "authors": "Yucen Luo, Tian Tian, Jiaxin Shi, Jun Zhu, Bo Zhang", "title": "Semi-crowdsourced Clustering with Deep Generative Models", "comments": "32nd Conference on Neural Information Processing Systems (NIPS 2018)", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the semi-supervised clustering problem where crowdsourcing\nprovides noisy information about the pairwise comparisons on a small subset of\ndata, i.e., whether a sample pair is in the same cluster. We propose a new\napproach that includes a deep generative model (DGM) to characterize low-level\nfeatures of the data, and a statistical relational model for noisy pairwise\nannotations on its subset. The two parts share the latent variables. To make\nthe model automatically trade-off between its complexity and fitting data, we\nalso develop its fully Bayesian variant. The challenge of inference is\naddressed by fast (natural-gradient) stochastic variational inference\nalgorithms, where we effectively combine variational message passing for the\nrelational part and amortized learning of the DGM under a unified framework.\nEmpirical results on synthetic and real-world datasets show that our model\noutperforms previous crowdsourced clustering methods.\n", "versions": [{"version": "v1", "created": "Mon, 29 Oct 2018 06:24:24 GMT"}], "update_date": "2018-10-30", "authors_parsed": [["Luo", "Yucen", ""], ["Tian", "Tian", ""], ["Shi", "Jiaxin", ""], ["Zhu", "Jun", ""], ["Zhang", "Bo", ""]]}, {"id": "1810.11975", "submitter": "Anirban Laha", "authors": "Anirban Laha, Saneem A. Chemmengath, Priyanka Agrawal, Mitesh M.\n  Khapra, Karthik Sankaranarayanan, Harish G. Ramaswamy", "title": "On Controllable Sparse Alternatives to Softmax", "comments": "To appear in NIPS 2018, Total 16 pages including appendix", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CL stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Converting an n-dimensional vector to a probability distribution over n\nobjects is a commonly used component in many machine learning tasks like\nmulticlass classification, multilabel classification, attention mechanisms etc.\nFor this, several probability mapping functions have been proposed and employed\nin literature such as softmax, sum-normalization, spherical softmax, and\nsparsemax, but there is very little understanding in terms how they relate with\neach other. Further, none of the above formulations offer an explicit control\nover the degree of sparsity. To address this, we develop a unified framework\nthat encompasses all these formulations as special cases. This framework\nensures simple closed-form solutions and existence of sub-gradients suitable\nfor learning via backpropagation. Within this framework, we propose two novel\nsparse formulations, sparsegen-lin and sparsehourglass, that seek to provide a\ncontrol over the degree of desired sparsity. We further develop novel convex\nloss functions that help induce the behavior of aforementioned formulations in\nthe multilabel classification setting, showing improved performance. We also\ndemonstrate empirically that the proposed formulations, when used to compute\nattention weights, achieve better or comparable performance on standard seq2seq\ntasks like neural machine translation and abstractive summarization.\n", "versions": [{"version": "v1", "created": "Mon, 29 Oct 2018 06:46:37 GMT"}, {"version": "v2", "created": "Tue, 30 Oct 2018 19:02:13 GMT"}], "update_date": "2018-11-01", "authors_parsed": [["Laha", "Anirban", ""], ["Chemmengath", "Saneem A.", ""], ["Agrawal", "Priyanka", ""], ["Khapra", "Mitesh M.", ""], ["Sankaranarayanan", "Karthik", ""], ["Ramaswamy", "Harish G.", ""]]}, {"id": "1810.11977", "submitter": "Haibin Chang", "authors": "Haibin Chang and Dongxiao Zhang", "title": "Identification of physical processes via combined data-driven and\n  data-assimilation methods", "comments": null, "journal-ref": "Journal of Computational Physics. 2019, 393, 337-350", "doi": "10.1016/j.jcp.2019.05.008", "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  With the advent of modern data collection and storage technologies,\ndata-driven approaches have been developed for discovering the governing\npartial differential equations (PDE) of physical problems. However, in the\nextant works the model parameters in the equations are either assumed to be\nknown or have a linear dependency. Therefore, most of the realistic physical\nprocesses cannot be identified with the current data-driven PDE discovery\napproaches. In this study, an innovative framework is developed that combines\ndata-driven and data-assimilation methods for simultaneously identifying\nphysical processes and inferring model parameters. Spatiotemporal measurement\ndata are first divided into a training data set and a testing data set. Using\nthe training data set, a data-driven method is developed to learn the governing\nequation of the considered physical problem by identifying the occurred (or\ndominated) processes and selecting the proper empirical model. Through\nintroducing a prediction error of the learned governing equation for the\ntesting data set, a data-assimilation method is devised to estimate the\nuncertain model parameters of the selected empirical model. For the contaminant\ntransport problem investigated, the results demonstrate that the proposed\nmethod can adequately identify the considered physical processes via\nconcurrently discovering the corresponding governing equations and inferring\nuncertain parameters of nonlinear models, even in the presence of measurement\nerrors. This work helps to broaden the applicable area of the research of data\ndriven discovery of governing equations of physical problems.\n", "versions": [{"version": "v1", "created": "Mon, 29 Oct 2018 07:12:01 GMT"}], "update_date": "2019-05-28", "authors_parsed": [["Chang", "Haibin", ""], ["Zhang", "Dongxiao", ""]]}, {"id": "1810.12026", "submitter": "Sergei Grudinin", "authors": "Guillaume Pag\\`es (NANO-D), Sergei Grudinin (NANO-D)", "title": "DeepSymmetry : Using 3D convolutional networks for identification of\n  tandem repeats and internal symmetries in protein structures", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.QM cs.LG physics.bio-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Motivation: Thanks to the recent advances in structural biology, nowadays\nthree-dimensional structures of various proteins are solved on a routine basis.\nA large portion of these contain structural repetitions or internal symmetries.\nTo understand the evolution mechanisms of these proteins and how structural\nrepetitions affect the protein function, we need to be able to detect such\nproteins very robustly. As deep learning is particularly suited to deal with\nspatially organized data, we applied it to the detection of proteins with\nstructural repetitions. Results: We present DeepSymmetry, a versatile method\nbased on three-dimensional (3D) convolutional networks that detects structural\nrepetitions in proteins and their density maps. Our method is designed to\nidentify tandem repeat proteins, proteins with internal symmetries, symmetries\nin the raw density maps, their symmetry order, and also the corresponding\nsymmetry axes. Detection of symmetry axes is based on learning six-dimensional\nVeronese mappings of 3D vectors, and the median angular error of axis\ndetermination is less than one degree. We demonstrate the capabilities of our\nmethod on benchmarks with tandem repeated proteins and also with symmetrical\nassemblies. For example, we have discovered over 10,000 putative tandem repeat\nproteins that are not currently present in the RepeatsDB database.\nAvailability: The method is available at\nhttps://team.inria.fr/nano-d/software/deepsymmetry. It consists of a C++\nexecutable that transforms molecular structures into volumetric density maps,\nand a Python code based on the TensorFlow framework for applying the\nDeepSymmetry model to these maps.\n", "versions": [{"version": "v1", "created": "Mon, 29 Oct 2018 09:38:51 GMT"}], "update_date": "2018-10-30", "authors_parsed": [["Pag\u00e8s", "Guillaume", "", "NANO-D"], ["Grudinin", "Sergei", "", "NANO-D"]]}, {"id": "1810.12034", "submitter": "Anders Arpteg", "authors": "Anders Arpteg, Bj\\\"orn Brinne, Luka Crnkovic-Friis, Jan Bosch", "title": "Software Engineering Challenges of Deep Learning", "comments": "44th Euromicro Conference on Software Engineering and Advanced\n  Applications, IEEE, 2018", "journal-ref": null, "doi": "10.1109/SEAA.2018.00018", "report-no": null, "categories": "cs.SE cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Surprisingly promising results have been achieved by deep learning (DL)\nsystems in recent years. Many of these achievements have been reached in\nacademic settings, or by large technology companies with highly skilled\nresearch groups and advanced supporting infrastructure. For companies without\nlarge research groups or advanced infrastructure, building high-quality\nproduction-ready systems with DL components has proven challenging. There is a\nclear lack of well-functioning tools and best practices for building DL\nsystems. It is the goal of this research to identify what the main challenges\nare, by applying an interpretive research approach in close collaboration with\ncompanies of varying size and type.\n  A set of seven projects have been selected to describe the potential with\nthis new technology and to identify associated main challenges. A set of 12\nmain challenges has been identified and categorized into the three areas of\ndevelopment, production, and organizational challenges. Furthermore, a mapping\nbetween the challenges and the projects is defined, together with selected\nmotivating descriptions of how and why the challenges apply to specific\nprojects.\n  Compared to other areas such as software engineering or database\ntechnologies, it is clear that DL is still rather immature and in need of\nfurther work to facilitate development of high-quality systems. The challenges\nidentified in this paper can be used to guide future research by the software\nengineering and DL communities. Together, we could enable a large number of\ncompanies to start taking advantage of the high potential of the DL technology.\n", "versions": [{"version": "v1", "created": "Mon, 29 Oct 2018 10:05:37 GMT"}], "update_date": "2018-10-30", "authors_parsed": [["Arpteg", "Anders", ""], ["Brinne", "Bj\u00f6rn", ""], ["Crnkovic-Friis", "Luka", ""], ["Bosch", "Jan", ""]]}, {"id": "1810.12042", "submitter": "Marius Mosbach", "authors": "Marius Mosbach, Maksym Andriushchenko, Thomas Trost, Matthias Hein,\n  Dietrich Klakow", "title": "Logit Pairing Methods Can Fool Gradient-Based Attacks", "comments": "Accepted to NeurIPS 2018 Workshop on Security in Machine Learning", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recently, Kannan et al. [2018] proposed several logit regularization methods\nto improve the adversarial robustness of classifiers. We show that the\ncomputationally fast methods they propose - Clean Logit Pairing (CLP) and Logit\nSqueezing (LSQ) - just make the gradient-based optimization problem of crafting\nadversarial examples harder without providing actual robustness. We find that\nAdversarial Logit Pairing (ALP) may indeed provide robustness against\nadversarial examples, especially when combined with adversarial training, and\nwe examine it in a variety of settings. However, the increase in adversarial\naccuracy is much smaller than previously claimed. Finally, our results suggest\nthat the evaluation against an iterative PGD attack relies heavily on the\nparameters used and may result in false conclusions regarding robustness of a\nmodel.\n", "versions": [{"version": "v1", "created": "Mon, 29 Oct 2018 10:30:20 GMT"}, {"version": "v2", "created": "Thu, 29 Nov 2018 16:08:33 GMT"}, {"version": "v3", "created": "Tue, 12 Mar 2019 08:13:30 GMT"}], "update_date": "2019-03-13", "authors_parsed": [["Mosbach", "Marius", ""], ["Andriushchenko", "Maksym", ""], ["Trost", "Thomas", ""], ["Hein", "Matthias", ""], ["Klakow", "Dietrich", ""]]}, {"id": "1810.12065", "submitter": "Zeyuan Allen-Zhu", "authors": "Zeyuan Allen-Zhu, Yuanzhi Li, Zhao Song", "title": "On the Convergence Rate of Training Recurrent Neural Networks", "comments": "V2/V3/V4 polish writing", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.DS cs.NE math.OC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  How can local-search methods such as stochastic gradient descent (SGD) avoid\nbad local minima in training multi-layer neural networks? Why can they fit\nrandom labels even given non-convex and non-smooth architectures? Most existing\ntheory only covers networks with one hidden layer, so can we go deeper?\n  In this paper, we focus on recurrent neural networks (RNNs) which are\nmulti-layer networks widely used in natural language processing. They are\nharder to analyze than feedforward neural networks, because the $\\textit{same}$\nrecurrent unit is repeatedly applied across the entire time horizon of length\n$L$, which is analogous to feedforward networks of depth $L$. We show when the\nnumber of neurons is sufficiently large, meaning polynomial in the training\ndata size and in $L$, then SGD is capable of minimizing the regression loss in\nthe linear convergence rate. This gives theoretical evidence of how RNNs can\nmemorize data.\n  More importantly, in this paper we build general toolkits to analyze\nmulti-layer networks with ReLU activations. For instance, we prove why ReLU\nactivations can prevent exponential gradient explosion or vanishing, and build\na perturbation theory to analyze first-order approximation of multi-layer\nnetworks.\n", "versions": [{"version": "v1", "created": "Mon, 29 Oct 2018 11:45:02 GMT"}, {"version": "v2", "created": "Fri, 9 Nov 2018 15:25:15 GMT"}, {"version": "v3", "created": "Thu, 29 Nov 2018 11:47:47 GMT"}, {"version": "v4", "created": "Mon, 27 May 2019 10:08:59 GMT"}], "update_date": "2019-05-28", "authors_parsed": [["Allen-Zhu", "Zeyuan", ""], ["Li", "Yuanzhi", ""], ["Song", "Zhao", ""]]}, {"id": "1810.12069", "submitter": "Timoth\\'ee Lesort", "authors": "Timoth\\'ee Lesort, Alexander Gepperth, Andrei Stoian, David Filliat", "title": "Marginal Replay vs Conditional Replay for Continual Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a new replay-based method of continual classification learning\nthat we term \"conditional replay\" which generates samples and labels together\nby sampling from a distribution conditioned on the class. We compare\nconditional replay to another\n  replay-based continual learning paradigm (which we term \"marginal replay\")\nthat generates samples independently of their class and assigns labels in a\nseparate step.\n  The main improvement in conditional replay is that labels for generated\nsamples need not be inferred, which reduces the margin for error in complex\ncontinual classification learning tasks. We demonstrate the effectiveness of\nthis approach using novel and standard benchmarks constructed from MNIST and\nFashionMNIST data, and compare to the regularization-based \\textit{elastic\nweight consolidation} (EWC) method.\n", "versions": [{"version": "v1", "created": "Mon, 29 Oct 2018 12:17:48 GMT"}, {"version": "v2", "created": "Mon, 26 Nov 2018 13:23:15 GMT"}, {"version": "v3", "created": "Thu, 13 Dec 2018 20:22:15 GMT"}, {"version": "v4", "created": "Sat, 29 Dec 2018 10:35:42 GMT"}, {"version": "v5", "created": "Wed, 23 Jan 2019 14:49:00 GMT"}, {"version": "v6", "created": "Mon, 1 Jul 2019 14:12:50 GMT"}], "update_date": "2019-07-02", "authors_parsed": [["Lesort", "Timoth\u00e9e", ""], ["Gepperth", "Alexander", ""], ["Stoian", "Andrei", ""], ["Filliat", "David", ""]]}, {"id": "1810.12081", "submitter": "Lijun Wu", "authors": "Lijun Wu, Fei Tian, Yingce Xia, Yang Fan, Tao Qin, Jianhuang Lai,\n  Tie-Yan Liu", "title": "Learning to Teach with Dynamic Loss Functions", "comments": "NIPS 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Teaching is critical to human society: it is with teaching that prospective\nstudents are educated and human civilization can be inherited and advanced. A\ngood teacher not only provides his/her students with qualified teaching\nmaterials (e.g., textbooks), but also sets up appropriate learning objectives\n(e.g., course projects and exams) considering different situations of a\nstudent. When it comes to artificial intelligence, treating machine learning\nmodels as students, the loss functions that are optimized act as perfect\ncounterparts of the learning objective set by the teacher. In this work, we\nexplore the possibility of imitating human teaching behaviors by dynamically\nand automatically outputting appropriate loss functions to train machine\nlearning models. Different from typical learning settings in which the loss\nfunction of a machine learning model is predefined and fixed, in our framework,\nthe loss function of a machine learning model (we call it student) is defined\nby another machine learning model (we call it teacher). The ultimate goal of\nteacher model is cultivating the student to have better performance measured on\ndevelopment dataset. Towards that end, similar to human teaching, the teacher,\na parametric model, dynamically outputs different loss functions that will be\nused and optimized by its student model at different training stages. We\ndevelop an efficient learning method for the teacher model that makes gradient\nbased optimization possible, exempt of the ineffective solutions such as policy\noptimization. We name our method as \"learning to teach with dynamic loss\nfunctions\" (L2T-DLF for short). Extensive experiments on real world tasks\nincluding image classification and neural machine translation demonstrate that\nour method significantly improves the quality of various student models.\n", "versions": [{"version": "v1", "created": "Mon, 29 Oct 2018 13:03:38 GMT"}], "update_date": "2018-10-30", "authors_parsed": [["Wu", "Lijun", ""], ["Tian", "Fei", ""], ["Xia", "Yingce", ""], ["Fan", "Yang", ""], ["Qin", "Tao", ""], ["Lai", "Jianhuang", ""], ["Liu", "Tie-Yan", ""]]}, {"id": "1810.12085", "submitter": "Emily Alsentzer", "authors": "Emily Alsentzer and Anne Kim", "title": "Extractive Summarization of EHR Discharge Notes", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.CL cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Patient summarization is essential for clinicians to provide coordinated care\nand practice effective communication. Automated summarization has the potential\nto save time, standardize notes, aid clinical decision making, and reduce\nmedical errors. Here we provide an upper bound on extractive summarization of\ndischarge notes and develop an LSTM model to sequentially label topics of\nhistory of present illness notes. We achieve an F1 score of 0.876, which\nindicates that this model can be employed to create a dataset for evaluation of\nextractive summarization methods.\n", "versions": [{"version": "v1", "created": "Fri, 26 Oct 2018 16:36:27 GMT"}], "update_date": "2018-10-30", "authors_parsed": [["Alsentzer", "Emily", ""], ["Kim", "Anne", ""]]}, {"id": "1810.12091", "submitter": "Shelan Jeawak", "authors": "Shelan S. Jeawak, Christopher B. Jones, and Steven Schockaert", "title": "Embedding Geographic Locations for Modelling the Natural Environment\n  using Flickr Tags and Structured Data", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.CL cs.CV cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Meta-data from photo-sharing websites such as Flickr can be used to obtain\nrich bag-of-words descriptions of geographic locations, which have proven\nvaluable, among others, for modelling and predicting ecological features. One\nimportant insight from previous work is that the descriptions obtained from\nFlickr tend to be complementary to the structured information that is available\nfrom traditional scientific resources. To better integrate these two diverse\nsources of information, in this paper we consider a method for learning vector\nspace embeddings of geographic locations. We show experimentally that this\nmethod improves on existing approaches, especially in cases where structured\ninformation is available.\n", "versions": [{"version": "v1", "created": "Fri, 12 Oct 2018 12:22:34 GMT"}], "update_date": "2018-10-30", "authors_parsed": [["Jeawak", "Shelan S.", ""], ["Jones", "Christopher B.", ""], ["Schockaert", "Steven", ""]]}, {"id": "1810.12116", "submitter": "Wenyuan Liu", "authors": "Wenyuan Liu, Stanis{\\l}aw Saganowski, Przemys{\\l}aw Kazienko and Siew\n  Ann Cheong", "title": "Using Machine Learning to Predict the Evolution of Physics Research", "comments": "24 pages, 10 figures, 4 tables, supplementary information is included", "journal-ref": null, "doi": "10.3390/e21121152", "report-no": null, "categories": "physics.soc-ph cs.LG cs.SI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The advancement of science as outlined by Popper and Kuhn is largely\nqualitative, but with bibliometric data it is possible and desirable to develop\na quantitative picture of scientific progress. Furthermore it is also important\nto allocate finite resources to research topics that have growth potential, to\naccelerate the process from scientific breakthroughs to technological\ninnovations. In this paper, we address this problem of quantitative knowledge\nevolution by analysing the APS publication data set from 1981 to 2010. We build\nthe bibliographic coupling and co-citation networks, use the Louvain method to\ndetect topical clusters (TCs) in each year, measure the similarity of TCs in\nconsecutive years, and visualize the results as alluvial diagrams. Having the\npredictive features describing a given TC and its known evolution in the next\nyear, we can train a machine learning model to predict future changes of TCs,\ni.e., their continuing, dissolving, merging and splitting. We found the number\nof papers from certain journals, the degree, closeness, and betweenness to be\nthe most predictive features. Additionally, betweenness increases significantly\nfor merging events, and decreases significantly for splitting events. Our\nresults represent a first step from a descriptive understanding of the Science\nof Science (SciSci), towards one that is ultimately prescriptive.\n", "versions": [{"version": "v1", "created": "Mon, 29 Oct 2018 13:36:04 GMT"}], "update_date": "2019-12-06", "authors_parsed": [["Liu", "Wenyuan", ""], ["Saganowski", "Stanis\u0142aw", ""], ["Kazienko", "Przemys\u0142aw", ""], ["Cheong", "Siew Ann", ""]]}, {"id": "1810.12118", "submitter": "Jiamou Liu", "authors": "Helen Jiahe Zhao and Jiamou Liu", "title": "Finding Answers from the Word of God: Domain Adaptation for Neural\n  Networks in Biblical Question Answering", "comments": "The paper has been accepted at IJCNN 2018", "journal-ref": null, "doi": "10.1109/IJCNN.2018.8489756", "report-no": null, "categories": "cs.IR cs.AI cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Question answering (QA) has significantly benefitted from deep learning\ntechniques in recent years. However, domain-specific QA remains a challenge due\nto the significant amount of data required to train a neural network. This\npaper studies the answer sentence selection task in the Bible domain and answer\nquestions by selecting relevant verses from the Bible. For this purpose, we\ncreate a new dataset BibleQA based on bible trivia questions and propose three\nneural network models for our task. We pre-train our models on a large-scale QA\ndataset, SQuAD, and investigate the effect of transferring weights on model\naccuracy. Furthermore, we also measure the model accuracies with different\nanswer context lengths and different Bible translations. We affirm that\ntransfer learning has a noticeable improvement in the model accuracy. We\nachieve relatively good results with shorter context lengths, whereas longer\ncontext lengths decreased model accuracy. We also find that using a more modern\nBible translation in the dataset has a positive effect on the task.\n", "versions": [{"version": "v1", "created": "Fri, 26 Oct 2018 12:34:21 GMT"}], "update_date": "2018-10-30", "authors_parsed": [["Zhao", "Helen Jiahe", ""], ["Liu", "Jiamou", ""]]}, {"id": "1810.12125", "submitter": "Boyi Hou", "authors": "Boyi Hou, Qun Chen, Yanyan Wang, Youcef Nafa, Zhanhuai Li", "title": "Gradual Machine Learning for Entity Resolution", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DB cs.AI cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Usually considered as a classification problem, entity resolution (ER) can be\nvery challenging on real data due to the prevalence of dirty values. The\nstate-of-the-art solutions for ER were built on a variety of learning models\n(most notably deep neural networks), which require lots of accurately labeled\ntraining data. Unfortunately, high-quality labeled data usually require\nexpensive manual work, and are therefore not readily available in many real\nscenarios. In this paper, we propose a novel learning paradigm for ER, called\ngradual machine learning, which aims to enable effective machine labeling\nwithout the requirement for manual labeling effort. It begins with some easy\ninstances in a task, which can be automatically labeled by the machine with\nhigh accuracy, and then gradually labels more challenging instances by\niterative factor graph inference. In gradual machine learning, the hard\ninstances in a task are gradually labeled in small stages based on the\nestimated evidential certainty provided by the labeled easier instances. Our\nextensive experiments on real data have shown that the performance of the\nproposed approach is considerably better than its unsupervised alternatives,\nand highly competitive compared to the state-of-the-art supervised techniques.\nUsing ER as a test case, we demonstrate that gradual machine learning is a\npromising paradigm potentially applicable to other challenging classification\ntasks requiring extensive labeling effort.\n", "versions": [{"version": "v1", "created": "Mon, 29 Oct 2018 13:47:52 GMT"}, {"version": "v2", "created": "Wed, 12 Dec 2018 11:58:22 GMT"}, {"version": "v3", "created": "Wed, 24 Apr 2019 08:40:51 GMT"}, {"version": "v4", "created": "Fri, 14 Jun 2019 01:12:48 GMT"}], "update_date": "2019-06-17", "authors_parsed": [["Hou", "Boyi", ""], ["Chen", "Qun", ""], ["Wang", "Yanyan", ""], ["Nafa", "Youcef", ""], ["Li", "Zhanhuai", ""]]}, {"id": "1810.12136", "submitter": "St\\'ephane Mallat", "authors": "St\\'ephane Mallat, Sixin Zhang, Gaspar Rochette", "title": "Phase Harmonic Correlations and Convolutional Neural Networks", "comments": "26 pages, 8 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.SP cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A major issue in harmonic analysis is to capture the phase dependence of\nfrequency representations, which carries important signal properties. It seems\nthat convolutional neural networks have found a way. Over time-series and\nimages, convolutional networks often learn a first layer of filters which are\nwell localized in the frequency domain, with different phases. We show that a\nrectifier then acts as a filter on the phase of the resulting coefficients. It\ncomputes signal descriptors which are local in space, frequency and phase. The\nnon-linear phase filter becomes a multiplicative operator over phase harmonics\ncomputed with a Fourier transform along the phase. We prove that it defines a\nbi-Lipschitz and invertible representation. The correlations of phase harmonics\ncoefficients characterise coherent structures from their phase dependence\nacross frequencies. For wavelet filters, we show numerically that signals\nhaving sparse wavelet coefficients can be recovered from few phase harmonic\ncorrelations, which provide a compressive representation\n", "versions": [{"version": "v1", "created": "Mon, 29 Oct 2018 14:12:09 GMT"}, {"version": "v2", "created": "Sat, 29 Jun 2019 14:02:45 GMT"}], "update_date": "2019-07-02", "authors_parsed": [["Mallat", "St\u00e9phane", ""], ["Zhang", "Sixin", ""], ["Rochette", "Gaspar", ""]]}, {"id": "1810.12138", "submitter": "Andr\\'es Marafioti MSc", "authors": "Andr\\'es Marafioti, Nathana\\\"el Perraudin, Nicki Holighaus, and Piotr\n  Majdak", "title": "A context encoder for audio inpainting", "comments": "Published in IEEE TASLP", "journal-ref": null, "doi": "10.1109/TASLP.2019.2947232", "report-no": null, "categories": "cs.SD cs.LG eess.AS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the ability of deep neural networks (DNNs) to restore missing audio\ncontent based on its context, i.e., inpaint audio gaps. We focus on a condition\nwhich has not received much attention yet: gaps in the range of tens of\nmilliseconds. We propose a DNN structure that is provided with the signal\nsurrounding the gap in the form of time-frequency (TF) coefficients. Two DNNs\nwith either complex-valued TF coefficient output or magnitude TF coefficient\noutput were studied by separately training them on inpainting two types of\naudio signals (music and musical instruments) having 64-ms long gaps. The\nmagnitude DNN outperformed the complex-valued DNN in terms of signal-to-noise\nratios and objective difference grades. Although, for instruments, a reference\ninpainting obtained through linear predictive coding performed better in both\nmetrics, it performed worse than the magnitude DNN for music. This demonstrates\nthe potential of the magnitude DNN, in particular for inpainting signals that\nare more complex than single instrument sounds.\n", "versions": [{"version": "v1", "created": "Mon, 29 Oct 2018 14:15:30 GMT"}, {"version": "v2", "created": "Thu, 10 Oct 2019 12:50:22 GMT"}], "update_date": "2020-05-12", "authors_parsed": [["Marafioti", "Andr\u00e9s", ""], ["Perraudin", "Nathana\u00ebl", ""], ["Holighaus", "Nicki", ""], ["Majdak", "Piotr", ""]]}, {"id": "1810.12153", "submitter": "Matthew Matlock", "authors": "Matthew K. Matlock, Arghya Datta, Na Le Dang, Kevin Jiang, S. Joshua\n  Swamidass", "title": "Deep learning long-range information in undirected graphs with wave\n  networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Graph algorithms are key tools in many fields of science and technology. Some\nof these algorithms depend on propagating information between distant nodes in\na graph. Recently, there have been a number of deep learning architectures\nproposed to learn on undirected graphs. However, most of these architectures\naggregate information in the local neighborhood of a node, and therefore they\nmay not be capable of efficiently propagating long-range information. To solve\nthis problem we examine a recently proposed architecture, wave, which\npropagates information back and forth across an undirected graph in waves of\nnonlinear computation. We compare wave to graph convolution, an architecture\nbased on local aggregation, and find that wave learns three different\ngraph-based tasks with greater efficiency and accuracy. These three tasks\ninclude (1) labeling a path connecting two nodes in a graph, (2) solving a maze\npresented as an image, and (3) computing voltages in a circuit. These tasks\nrange from trivial to very difficult, but wave can extrapolate from small\ntraining examples to much larger testing examples. These results show that wave\nmay be able to efficiently solve a wide range of problems that require\nlong-range information propagation across undirected graphs. An implementation\nof the wave network, and example code for the maze problem are included in the\ntflon deep learning toolkit (https://bitbucket.org/mkmatlock/tflon).\n", "versions": [{"version": "v1", "created": "Mon, 29 Oct 2018 14:35:40 GMT"}], "update_date": "2018-10-30", "authors_parsed": [["Matlock", "Matthew K.", ""], ["Datta", "Arghya", ""], ["Dang", "Na Le", ""], ["Jiang", "Kevin", ""], ["Swamidass", "S. Joshua", ""]]}, {"id": "1810.12154", "submitter": "Chieh-Fang Teng", "authors": "Chieh-Fang Teng, Chen-Hsi Wu, Kuan-Shiuan Ho, An-Yeu Wu", "title": "Low-complexity Recurrent Neural Network-based Polar Decoder with Weight\n  Quantization Mechanism", "comments": "5 pages, accepted by the 2019 International Conference on Acoustics,\n  Speech, and Signal Processing (ICASSP)", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.SP cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Polar codes have drawn much attention and been adopted in 5G New Radio (NR)\ndue to their capacity-achieving performance. Recently, as the emerging deep\nlearning (DL) technique has breakthrough achievements in many fields, neural\nnetwork decoder was proposed to obtain faster convergence and better\nperformance than belief propagation (BP) decoding. However, neural networks are\nmemory-intensive and hinder the deployment of DL in communication systems. In\nthis work, a low-complexity recurrent neural network (RNN) polar decoder with\ncodebook-based weight quantization is proposed. Our test results show that we\ncan effectively reduce the memory overhead by 98% and alleviate computational\ncomplexity with slight performance loss.\n", "versions": [{"version": "v1", "created": "Mon, 29 Oct 2018 14:37:02 GMT"}, {"version": "v2", "created": "Sat, 2 Feb 2019 04:27:51 GMT"}], "update_date": "2019-02-05", "authors_parsed": [["Teng", "Chieh-Fang", ""], ["Wu", "Chen-Hsi", ""], ["Ho", "Kuan-Shiuan", ""], ["Wu", "An-Yeu", ""]]}, {"id": "1810.12161", "submitter": "Faicel Chamroukhi", "authors": "Faicel Chamroukhi and Bao-Tuyen Huynh", "title": "Regularized Maximum Likelihood Estimation and Feature Selection in\n  Mixtures-of-Experts Models", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG stat.CO stat.ME", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Mixture of Experts (MoE) are successful models for modeling heterogeneous\ndata in many statistical learning problems including regression, clustering and\nclassification. Generally fitted by maximum likelihood estimation via the\nwell-known EM algorithm, their application to high-dimensional problems is\nstill therefore challenging. We consider the problem of fitting and feature\nselection in MoE models, and propose a regularized maximum likelihood\nestimation approach that encourages sparse solutions for heterogeneous\nregression data models with potentially high-dimensional predictors. Unlike\nstate-of-the art regularized MLE for MoE, the proposed modelings do not require\nan approximate of the penalty function. We develop two hybrid EM algorithms: an\nExpectation-Majorization-Maximization (EM/MM) algorithm, and an EM algorithm\nwith coordinate ascent algorithm. The proposed algorithms allow to\nautomatically obtaining sparse solutions without thresholding, and avoid matrix\ninversion by allowing univariate parameter updates. An experimental study shows\nthe good performance of the algorithms in terms of recovering the actual sparse\nsolutions, parameter estimation, and clustering of heterogeneous regression\ndata.\n", "versions": [{"version": "v1", "created": "Mon, 29 Oct 2018 14:42:04 GMT"}], "update_date": "2018-10-30", "authors_parsed": [["Chamroukhi", "Faicel", ""], ["Huynh", "Bao-Tuyen", ""]]}, {"id": "1810.12162", "submitter": "Pranav Shyam", "authors": "Pranav Shyam, Wojciech Ja\\'skowski, Faustino Gomez", "title": "Model-Based Active Exploration", "comments": "ICML 2019. Code: https://github.com/nnaisense/max", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.IT cs.NE math.IT stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Efficient exploration is an unsolved problem in Reinforcement Learning which\nis usually addressed by reactively rewarding the agent for fortuitously\nencountering novel situations. This paper introduces an efficient active\nexploration algorithm, Model-Based Active eXploration (MAX), which uses an\nensemble of forward models to plan to observe novel events. This is carried out\nby optimizing agent behaviour with respect to a measure of novelty derived from\nthe Bayesian perspective of exploration, which is estimated using the\ndisagreement between the futures predicted by the ensemble members. We show\nempirically that in semi-random discrete environments where directed\nexploration is critical to make progress, MAX is at least an order of magnitude\nmore efficient than strong baselines. MAX scales to high-dimensional continuous\nenvironments where it builds task-agnostic models that can be used for any\ndownstream task.\n", "versions": [{"version": "v1", "created": "Mon, 29 Oct 2018 14:43:48 GMT"}, {"version": "v2", "created": "Wed, 28 Nov 2018 11:22:22 GMT"}, {"version": "v3", "created": "Thu, 7 Feb 2019 18:00:02 GMT"}, {"version": "v4", "created": "Mon, 13 May 2019 20:58:53 GMT"}, {"version": "v5", "created": "Thu, 13 Jun 2019 19:33:27 GMT"}], "update_date": "2019-06-17", "authors_parsed": [["Shyam", "Pranav", ""], ["Ja\u015bkowski", "Wojciech", ""], ["Gomez", "Faustino", ""]]}, {"id": "1810.12165", "submitter": "Luana Ruiz", "authors": "Luana Ruiz, Fernando Gama, Antonio G. Marques, Alejandro Ribeiro", "title": "Median activation functions for graph neural networks", "comments": "Submitted to ICASSP 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Graph neural networks (GNNs) have been shown to replicate convolutional\nneural networks' (CNNs) superior performance in many problems involving graphs.\nBy replacing regular convolutions with linear shift-invariant graph filters\n(LSI-GFs), GNNs take into account the (irregular) structure of the graph and\nprovide meaningful representations of network data. However, LSI-GFs fail to\nencode local nonlinear graph signal behavior, and so do regular activation\nfunctions, which are nonlinear but pointwise. To address this issue, we propose\nmedian activation functions with support on graph neighborhoods instead of\nindividual nodes. A GNN architecture with a trainable multirresolution version\nof this activation function is then tested on synthetic and real-word datasets,\nwhere we show that median activation functions can improve GNN capacity with\nmarginal increase in complexity.\n", "versions": [{"version": "v1", "created": "Mon, 29 Oct 2018 14:53:56 GMT"}, {"version": "v2", "created": "Mon, 11 Feb 2019 18:45:56 GMT"}], "update_date": "2019-02-12", "authors_parsed": [["Ruiz", "Luana", ""], ["Gama", "Fernando", ""], ["Marques", "Antonio G.", ""], ["Ribeiro", "Alejandro", ""]]}, {"id": "1810.12169", "submitter": "Marie Szafranski", "authors": "Florent Guinot (LaMME), Marie Szafranski (LaMME), Julien Chiquet\n  (MIA-Paris), Anouk Zancarini, Christine Le Signor, Christophe Mougel (IGEPP),\n  Christophe Ambroise (LaMME)", "title": "Fast Computation of Genome-Metagenome Interaction Effects", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.AP cs.LG math.ST stat.ME stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Motivation. Association studies have been widely used to search for\nassociations between common genetic variants observations and a given\nphenotype. However, it is now generally accepted that genes and environment\nmust be examined jointly when estimating phenotypic variance. In this work we\nconsider two types of biological markers: genotypic markers, which characterize\nan observation in terms of inherited genetic information, and metagenomic\nmarker which are related to the environment. Both types of markers are\navailable in their millions and can be used to characterize any observation\nuniquely. Objective. Our focus is on detecting interactions between groups of\ngenetic and metagenomic markers in order to gain a better understanding of the\ncomplex relationship between environment and genome in the expression of a\ngiven phenotype. Contributions. We propose a novel approach for efficiently\ndetecting interactions between complementary datasets in a high-dimensional\nsetting with a reduced computational cost. The method, named SICOMORE, reduces\nthe dimension of the search space by selecting a subset of supervariables in\nthe two complementary datasets. These supervariables are given by a weighted\ngroup structure defined on sets of variables at different scales. A Lasso\nselection is then applied on each type of supervariable to obtain a subset of\npotential interactions that will be explored via linear model testing. Results.\nWe compare SICOMORE with other approaches in simulations, with varying sample\nsizes, noise, and numbers of true interactions. SICOMORE exhibits convincing\nresults in terms of recall, as well as competitive performances with respect to\nrunning time. The method is also used to detect interaction between genomic\nmarkers in Medicago truncatula and metagenomic markers in its rhizosphere\nbacterial community. Software availability. A R package is available, along\nwith its documentation and associated scripts, allowing the reader to reproduce\nthe results presented in the paper.\n", "versions": [{"version": "v1", "created": "Mon, 29 Oct 2018 14:57:02 GMT"}, {"version": "v2", "created": "Wed, 10 Jun 2020 15:41:15 GMT"}, {"version": "v3", "created": "Thu, 18 Jun 2020 16:19:38 GMT"}], "update_date": "2020-06-19", "authors_parsed": [["Guinot", "Florent", "", "LaMME"], ["Szafranski", "Marie", "", "LaMME"], ["Chiquet", "Julien", "", "MIA-Paris"], ["Zancarini", "Anouk", "", "IGEPP"], ["Signor", "Christine Le", "", "IGEPP"], ["Mougel", "Christophe", "", "IGEPP"], ["Ambroise", "Christophe", "", "LaMME"]]}, {"id": "1810.12170", "submitter": "Uri Alon", "authors": "Uri Alon, Golan Pundak, Tara N. Sainath", "title": "Contextual Speech Recognition with Difficult Negative Training Examples", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.AS cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Improving the representation of contextual information is key to unlocking\nthe potential of end-to-end (E2E) automatic speech recognition (ASR). In this\nwork, we present a novel and simple approach for training an ASR context\nmechanism with difficult negative examples. The main idea is to focus on proper\nnouns (e.g., unique entities such as names of people and places) in the\nreference transcript, and use phonetically similar phrases as negative\nexamples, encouraging the neural model to learn more discriminative\nrepresentations. We apply our approach to an end-to-end contextual ASR model\nthat jointly learns to transcribe and select the correct context items, and\nshow that our proposed method gives up to $53.1\\%$ relative improvement in word\nerror rate (WER) across several benchmarks.\n", "versions": [{"version": "v1", "created": "Mon, 29 Oct 2018 14:57:58 GMT"}], "update_date": "2018-10-30", "authors_parsed": [["Alon", "Uri", ""], ["Pundak", "Golan", ""], ["Sainath", "Tara N.", ""]]}, {"id": "1810.12176", "submitter": "Matthew Willetts", "authors": "Matthew Willetts, Aiden Doherty, Stephen Roberts and Chris Holmes", "title": "Semi-unsupervised Learning of Human Activity using Deep Generative\n  Models", "comments": "4 pages, 2 figures, conference workshop pre-print Machine Learning\n  for Health (ML4H) Workshop at NeurIPS 2018 arXiv:1811.07216", "journal-ref": null, "doi": null, "report-no": "ML4H/2018/94", "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce 'semi-unsupervised learning', a problem regime related to\ntransfer learning and zero-shot learning where, in the training data, some\nclasses are sparsely labelled and others entirely unlabelled. Models able to\nlearn from training data of this type are potentially of great use as many\nreal-world datasets are like this. Here we demonstrate a new deep generative\nmodel for classification in this regime. Our model, a Gaussian mixture deep\ngenerative model, demonstrates superior semi-unsupervised classification\nperformance on MNIST to model M2 from Kingma and Welling (2014). We apply the\nmodel to human accelerometer data, performing activity classification and\nstructure discovery on windows of time series data.\n", "versions": [{"version": "v1", "created": "Mon, 29 Oct 2018 15:06:43 GMT"}, {"version": "v2", "created": "Tue, 11 Dec 2018 12:48:45 GMT"}], "update_date": "2018-12-12", "authors_parsed": [["Willetts", "Matthew", ""], ["Doherty", "Aiden", ""], ["Roberts", "Stephen", ""], ["Holmes", "Chris", ""]]}, {"id": "1810.12177", "submitter": "Sebastien Marmin", "authors": "S\\'ebastien Marmin, Maurizio Filippone", "title": "Variational Calibration of Computer Models", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG stat.AP stat.ME", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Bayesian calibration of black-box computer models offers an established\nframework to obtain a posterior distribution over model parameters. Traditional\nBayesian calibration involves the emulation of the computer model and an\nadditive model discrepancy term using Gaussian processes; inference is then\ncarried out using MCMC. These choices pose computational and statistical\nchallenges and limitations, which we overcome by proposing the use of\napproximate Deep Gaussian processes and variational inference techniques. The\nresult is a practical and scalable framework for calibration, which obtains\ncompetitive performance compared to the state-of-the-art.\n", "versions": [{"version": "v1", "created": "Mon, 29 Oct 2018 15:07:07 GMT"}], "update_date": "2018-10-30", "authors_parsed": [["Marmin", "S\u00e9bastien", ""], ["Filippone", "Maurizio", ""]]}, {"id": "1810.12186", "submitter": "Nathanael Perraudin N. P.", "authors": "Nathana\\\"el Perraudin, Micha\\\"el Defferrard, Tomasz Kacprzak, Raphael\n  Sgier", "title": "DeepSphere: Efficient spherical Convolutional Neural Network with\n  HEALPix sampling for cosmological applications", "comments": "arXiv admin note: text overlap with arXiv:astro-ph/0409513 by other\n  authors", "journal-ref": null, "doi": "10.1016/j.ascom.2019.03.004", "report-no": null, "categories": "astro-ph.CO astro-ph.IM cs.AI cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Convolutional Neural Networks (CNNs) are a cornerstone of the Deep Learning\ntoolbox and have led to many breakthroughs in Artificial Intelligence. These\nnetworks have mostly been developed for regular Euclidean domains such as those\nsupporting images, audio, or video. Because of their success, CNN-based methods\nare becoming increasingly popular in Cosmology. Cosmological data often comes\nas spherical maps, which make the use of the traditional CNNs more complicated.\nThe commonly used pixelization scheme for spherical maps is the Hierarchical\nEqual Area isoLatitude Pixelisation (HEALPix). We present a spherical CNN for\nanalysis of full and partial HEALPix maps, which we call DeepSphere. The\nspherical CNN is constructed by representing the sphere as a graph. Graphs are\nversatile data structures that can act as a discrete representation of a\ncontinuous manifold. Using the graph-based representation, we define many of\nthe standard CNN operations, such as convolution and pooling. With filters\nrestricted to being radial, our convolutions are equivariant to rotation on the\nsphere, and DeepSphere can be made invariant or equivariant to rotation. This\nway, DeepSphere is a special case of a graph CNN, tailored to the HEALPix\nsampling of the sphere. This approach is computationally more efficient than\nusing spherical harmonics to perform convolutions. We demonstrate the method on\na classification problem of weak lensing mass maps from two cosmological models\nand compare the performance of the CNN with that of two baseline classifiers.\nThe results show that the performance of DeepSphere is always superior or equal\nto both of these baselines. For high noise levels and for data covering only a\nsmaller fraction of the sphere, DeepSphere achieves typically 10% better\nclassification accuracy than those baselines. Finally, we show how learned\nfilters can be visualized to introspect the neural network.\n", "versions": [{"version": "v1", "created": "Mon, 29 Oct 2018 15:23:18 GMT"}, {"version": "v2", "created": "Tue, 26 Mar 2019 17:11:17 GMT"}], "update_date": "2021-01-05", "authors_parsed": [["Perraudin", "Nathana\u00ebl", ""], ["Defferrard", "Micha\u00ebl", ""], ["Kacprzak", "Tomasz", ""], ["Sgier", "Raphael", ""]]}, {"id": "1810.12187", "submitter": "Jordi Pons M.Sc.", "authors": "Francesc Llu\\'is, Jordi Pons, Xavier Serra", "title": "End-to-end music source separation: is it possible in the waveform\n  domain?", "comments": "In proceedings of INTERSPEECH 2019. Code:\n  https://github.com/francesclluis/source-separation-wavenet and demo:\n  http://jordipons.me/apps/end-to-end-music-source-separation/", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SD cs.LG eess.AS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Most of the currently successful source separation techniques use the\nmagnitude spectrogram as input, and are therefore by default omitting part of\nthe signal: the phase. To avoid omitting potentially useful information, we\nstudy the viability of using end-to-end models for music source separation ---\nwhich take into account all the information available in the raw audio signal,\nincluding the phase. Although during the last decades end-to-end music source\nseparation has been considered almost unattainable, our results confirm that\nwaveform-based models can perform similarly (if not better) than a\nspectrogram-based deep learning model. Namely: a Wavenet-based model we propose\nand Wave-U-Net can outperform DeepConvSep, a recent spectrogram-based deep\nlearning model.\n", "versions": [{"version": "v1", "created": "Mon, 29 Oct 2018 15:24:34 GMT"}, {"version": "v2", "created": "Fri, 28 Jun 2019 09:41:08 GMT"}], "update_date": "2019-07-01", "authors_parsed": [["Llu\u00eds", "Francesc", ""], ["Pons", "Jordi", ""], ["Serra", "Xavier", ""]]}, {"id": "1810.12188", "submitter": "Kwang-Sung Jun", "authors": "Kwang-Sung Jun, Lihong Li, Yuzhe Ma, Xiaojin Zhu", "title": "Adversarial Attacks on Stochastic Bandits", "comments": "accepted to NIPS", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study adversarial attacks that manipulate the reward signals to control\nthe actions chosen by a stochastic multi-armed bandit algorithm. We propose the\nfirst attack against two popular bandit algorithms: $\\epsilon$-greedy and UCB,\n\\emph{without} knowledge of the mean rewards. The attacker is able to spend\nonly logarithmic effort, multiplied by a problem-specific parameter that\nbecomes smaller as the bandit problem gets easier to attack. The result means\nthe attacker can easily hijack the behavior of the bandit algorithm to promote\nor obstruct certain actions, say, a particular medical treatment. As bandits\nare seeing increasingly wide use in practice, our study exposes a significant\nsecurity threat.\n", "versions": [{"version": "v1", "created": "Mon, 29 Oct 2018 15:28:20 GMT"}], "update_date": "2018-10-30", "authors_parsed": [["Jun", "Kwang-Sung", ""], ["Li", "Lihong", ""], ["Ma", "Yuzhe", ""], ["Zhu", "Xiaojin", ""]]}, {"id": "1810.12210", "submitter": "Yanzhao Wu", "authors": "Yanzhao Wu, Ling Liu, Calton Pu, Wenqi Cao, Semih Sahin, Wenqi Wei, Qi\n  Zhang", "title": "A Comparative Measurement Study of Deep Learning as a Service Framework", "comments": "To appear on IEEE Transactions on Services Computing. The benchmark\n  tool used in this study is GTDLBench (https://git-disl.github.io/GTDLBench/)", "journal-ref": null, "doi": "10.1109/TSC.2019.2928551", "report-no": null, "categories": "cs.PF cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Big data powered Deep Learning (DL) and its applications have blossomed in\nrecent years, fueled by three technological trends: a large amount of digitized\ndata openly accessible, a growing number of DL software frameworks in open\nsource and commercial markets, and a selection of affordable parallel computing\nhardware devices. However, no single DL framework, to date, dominates in terms\nof performance and accuracy even for baseline classification tasks on standard\ndatasets, making the selection of a DL framework an overwhelming task. This\npaper takes a holistic approach to conduct empirical comparison and analysis of\nfour representative DL frameworks with three unique contributions. First, given\na selection of CPU-GPU configurations, we show that for a specific DL\nframework, different configurations of its hyper-parameters may have a\nsignificant impact on both performance and accuracy of DL applications. Second,\nto the best of our knowledge, this study is the first to identify the\nopportunities for improving the training time performance and the accuracy of\nDL frameworks by configuring parallel computing libraries and tuning individual\nand multiple hyper-parameters. Third, we also conduct a comparative measurement\nstudy on the resource consumption patterns of four DL frameworks and their\nperformance and accuracy implications, including CPU and memory usage, and\ntheir correlations to varying settings of hyper-parameters under different\nconfiguration combinations of hardware, parallel computing libraries. We argue\nthat this measurement study provides in-depth empirical comparison and analysis\nof four representative DL frameworks, and offers practical guidance for service\nproviders to deploying and delivering DL as a Service (DLaaS) and for\napplication developers and DLaaS consumers to select the right DL frameworks\nfor the right DL workloads.\n", "versions": [{"version": "v1", "created": "Mon, 29 Oct 2018 16:03:41 GMT"}, {"version": "v2", "created": "Sun, 18 Aug 2019 18:24:19 GMT"}], "update_date": "2019-08-20", "authors_parsed": [["Wu", "Yanzhao", ""], ["Liu", "Ling", ""], ["Pu", "Calton", ""], ["Cao", "Wenqi", ""], ["Sahin", "Semih", ""], ["Wei", "Wenqi", ""], ["Zhang", "Qi", ""]]}, {"id": "1810.12228", "submitter": "Pei Cao", "authors": "Pei Cao, Qi Shuai and Jiong Tang", "title": "Leveraging Gaussian Process and Voting-Empowered Many-Objective\n  Evaluation for Fault Identification", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CE cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Using piezoelectric impedance/admittance sensing for structural health\nmonitoring is promising, owing to the simplicity in circuitry design as well as\nthe high-frequency interrogation capability. The actual identification of fault\nlocation and severity using impedance/admittance measurements, nevertheless,\nremains to be an extremely challenging task. A first-principle based structural\nmodel using finite element discretization requires high dimensionality to\ncharacterize the high-frequency response. As such, direct inversion using the\nsensitivity matrix usually yields an under-determined problem. Alternatively,\nthe identification problem may be cast into an optimization framework in which\nfault parameters are identified through repeated forward finite element\nanalysis which however is oftentimes computationally prohibitive. This paper\npresents an efficient data-assisted optimization approach for fault\nidentification without using finite element model iteratively. We formulate a\nmany-objective optimization problem to identify fault parameters, where\nresponse surfaces of impedance measurements are constructed through Gaussian\nprocess-based calibration. To balance between solution diversity and\nconvergence, an -dominance enabled many-objective simulated annealing algorithm\nis established. As multiple solutions are expected, a voting score calculation\nprocedure is developed to further identify those solutions that yield better\nimplications regarding structural health condition. The effectiveness of the\nproposed approach is demonstrated by systematic numerical and experimental case\nstudies.\n", "versions": [{"version": "v1", "created": "Mon, 29 Oct 2018 16:15:45 GMT"}], "update_date": "2018-10-30", "authors_parsed": [["Cao", "Pei", ""], ["Shuai", "Qi", ""], ["Tang", "Jiong", ""]]}, {"id": "1810.12233", "submitter": "Charlie Rogers-Smith", "authors": "Charlie Rogers-Smith, Henri Pesonen and Samuel Kaski", "title": "Approximate Bayesian Computation via Population Monte Carlo and\n  Classification", "comments": "18 pages, 5 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Approximate Bayesian computation (ABC) methods can be used to sample from\nposterior distributions when the likelihood function is unavailable or\nintractable, as is often the case in biological systems. ABC methods suffer\nfrom inefficient particle proposals in high dimensions, and subjectivity in the\nchoice of summary statistics, discrepancy measure, and error tolerance.\nSequential Monte Carlo (SMC) methods have been combined with ABC to improve the\nefficiency of particle proposals, but suffer from subjectivity and require many\nsimulations from the likelihood function. Likelihood-Free Inference by Ratio\nEstimation (LFIRE) leverages classification to estimate the posterior density\ndirectly but does not explore the parameter space efficiently. This work\nproposes a classification approach that approximates population Monte Carlo\n(PMC), where model class probabilities from classification are used to update\nparticle weights. This approach, called Classification-PMC, blends adaptive\nproposals and classification, efficiently producing samples from the posterior\nwithout subjectivity. We show through a simulation study that\nClassification-PMC outperforms two state-of-the-art methods: ratio estimation\nand SMC ABC when it is computationally difficult to simulate from the\nlikelihood.\n", "versions": [{"version": "v1", "created": "Mon, 29 Oct 2018 16:22:17 GMT"}, {"version": "v2", "created": "Sat, 30 Nov 2019 14:07:59 GMT"}], "update_date": "2019-12-03", "authors_parsed": [["Rogers-Smith", "Charlie", ""], ["Pesonen", "Henri", ""], ["Kaski", "Samuel", ""]]}, {"id": "1810.12247", "submitter": "Curtis Hawthorne", "authors": "Curtis Hawthorne, Andriy Stasyuk, Adam Roberts, Ian Simon, Cheng-Zhi\n  Anna Huang, Sander Dieleman, Erich Elsen, Jesse Engel, Douglas Eck", "title": "Enabling Factorized Piano Music Modeling and Generation with the MAESTRO\n  Dataset", "comments": "Examples available at https://goo.gl/magenta/maestro-examples", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SD cs.LG eess.AS stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Generating musical audio directly with neural networks is notoriously\ndifficult because it requires coherently modeling structure at many different\ntimescales. Fortunately, most music is also highly structured and can be\nrepresented as discrete note events played on musical instruments. Herein, we\nshow that by using notes as an intermediate representation, we can train a\nsuite of models capable of transcribing, composing, and synthesizing audio\nwaveforms with coherent musical structure on timescales spanning six orders of\nmagnitude (~0.1 ms to ~100 s), a process we call Wave2Midi2Wave. This large\nadvance in the state of the art is enabled by our release of the new MAESTRO\n(MIDI and Audio Edited for Synchronous TRacks and Organization) dataset,\ncomposed of over 172 hours of virtuosic piano performances captured with fine\nalignment (~3 ms) between note labels and audio waveforms. The networks and the\ndataset together present a promising approach toward creating new expressive\nand interpretable neural models of music.\n", "versions": [{"version": "v1", "created": "Mon, 29 Oct 2018 16:48:53 GMT"}, {"version": "v2", "created": "Tue, 30 Oct 2018 18:54:40 GMT"}, {"version": "v3", "created": "Wed, 14 Nov 2018 19:43:32 GMT"}, {"version": "v4", "created": "Sat, 12 Jan 2019 01:27:00 GMT"}, {"version": "v5", "created": "Thu, 17 Jan 2019 19:45:00 GMT"}], "update_date": "2019-01-21", "authors_parsed": [["Hawthorne", "Curtis", ""], ["Stasyuk", "Andriy", ""], ["Roberts", "Adam", ""], ["Simon", "Ian", ""], ["Huang", "Cheng-Zhi Anna", ""], ["Dieleman", "Sander", ""], ["Elsen", "Erich", ""], ["Engel", "Jesse", ""], ["Eck", "Douglas", ""]]}, {"id": "1810.12263", "submitter": "David Reeb", "authors": "David Reeb, Andreas Doerr, Sebastian Gerwinn, Barbara Rakitsch", "title": "Learning Gaussian Processes by Minimizing PAC-Bayesian Generalization\n  Bounds", "comments": "11 pages main text, 12 pages appendix. v2: minor changes, new NeurIPS\n  style file. Final camera-ready version submitted to NeurIPS 2018", "journal-ref": "Advances in Neural Information Processing Systems 31 (Proceedings\n  of the NeurIPS Conference 2018),\n  https://papers.nips.cc/paper/7594-learning-gaussian-processes-by-minimizing-pac-bayesian-generalization-bounds", "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Gaussian Processes (GPs) are a generic modelling tool for supervised\nlearning. While they have been successfully applied on large datasets, their\nuse in safety-critical applications is hindered by the lack of good performance\nguarantees. To this end, we propose a method to learn GPs and their sparse\napproximations by directly optimizing a PAC-Bayesian bound on their\ngeneralization performance, instead of maximizing the marginal likelihood.\nBesides its theoretical appeal, we find in our evaluation that our learning\nmethod is robust and yields significantly better generalization guarantees than\nother common GP approaches on several regression benchmark datasets.\n", "versions": [{"version": "v1", "created": "Mon, 29 Oct 2018 17:21:50 GMT"}, {"version": "v2", "created": "Fri, 28 Dec 2018 11:48:46 GMT"}], "update_date": "2019-08-27", "authors_parsed": [["Reeb", "David", ""], ["Doerr", "Andreas", ""], ["Gerwinn", "Sebastian", ""], ["Rakitsch", "Barbara", ""]]}, {"id": "1810.12272", "submitter": "Dimitrios Diochnos", "authors": "Dimitrios I. Diochnos, Saeed Mahloujifar, Mohammad Mahmoody", "title": "Adversarial Risk and Robustness: General Definitions and Implications\n  for the Uniform Distribution", "comments": "Full version of a work with the same title that will appear in NIPS\n  2018, 31 pages containing 5 figures, 1 table, 2 algorithms", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CC cs.CR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study adversarial perturbations when the instances are uniformly\ndistributed over $\\{0,1\\}^n$. We study both \"inherent\" bounds that apply to any\nproblem and any classifier for such a problem as well as bounds that apply to\nspecific problems and specific hypothesis classes.\n  As the current literature contains multiple definitions of adversarial risk\nand robustness, we start by giving a taxonomy for these definitions based on\ntheir goals, we identify one of them as the one guaranteeing misclassification\nby pushing the instances to the error region. We then study some classic\nalgorithms for learning monotone conjunctions and compare their adversarial\nrisk and robustness under different definitions by attacking the hypotheses\nusing instances drawn from the uniform distribution. We observe that sometimes\nthese definitions lead to significantly different bounds. Thus, this study\nadvocates for the use of the error-region definition, even though other\ndefinitions, in other contexts, may coincide with the error-region definition.\n  Using the error-region definition of adversarial perturbations, we then study\ninherent bounds on risk and robustness of any classifier for any classification\nproblem whose instances are uniformly distributed over $\\{0,1\\}^n$. Using the\nisoperimetric inequality for the Boolean hypercube, we show that for initial\nerror $0.01$, there always exists an adversarial perturbation that changes\n$O(\\sqrt{n})$ bits of the instances to increase the risk to $0.5$, making\nclassifier's decisions meaningless. Furthermore, by also using the central\nlimit theorem we show that when $n\\to \\infty$, at most $c \\cdot \\sqrt{n}$ bits\nof perturbations, for a universal constant $c< 1.17$, suffice for increasing\nthe risk to $0.5$, and the same $c \\cdot \\sqrt{n} $ bits of perturbations on\naverage suffice to increase the risk to $1$, hence bounding the robustness by\n$c \\cdot \\sqrt{n}$.\n", "versions": [{"version": "v1", "created": "Mon, 29 Oct 2018 17:41:29 GMT"}], "update_date": "2018-10-30", "authors_parsed": [["Diochnos", "Dimitrios I.", ""], ["Mahloujifar", "Saeed", ""], ["Mahmoody", "Mohammad", ""]]}, {"id": "1810.12273", "submitter": "James Vuckovic", "authors": "James Vuckovic", "title": "Kalman Gradient Descent: Adaptive Variance Reduction in Stochastic\n  Optimization", "comments": "25 pages, 5 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG math.OC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce Kalman Gradient Descent, a stochastic optimization algorithm\nthat uses Kalman filtering to adaptively reduce gradient variance in stochastic\ngradient descent by filtering the gradient estimates. We present both a\ntheoretical analysis of convergence in a non-convex setting and experimental\nresults which demonstrate improved performance on a variety of machine learning\nareas including neural networks and black box variational inference. We also\npresent a distributed version of our algorithm that enables large-dimensional\noptimization, and we extend our algorithm to SGD with momentum and RMSProp.\n", "versions": [{"version": "v1", "created": "Mon, 29 Oct 2018 17:42:39 GMT"}], "update_date": "2018-10-30", "authors_parsed": [["Vuckovic", "James", ""]]}, {"id": "1810.12278", "submitter": "Ethan Rudd", "authors": "Richard Harang and Ethan M. Rudd", "title": "Towards Principled Uncertainty Estimation for Deep Neural Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  When the cost of misclassifying a sample is high, it is useful to have an\naccurate estimate of uncertainty in the prediction for that sample. There are\nalso multiple types of uncertainty which are best estimated in different ways,\nfor example, uncertainty that is intrinsic to the training set may be\nwell-handled by a Bayesian approach, while uncertainty introduced by shifts\nbetween training and query distributions may be better-addressed by\ndensity/support estimation. In this paper, we examine three types of\nuncertainty: model capacity uncertainty, intrinsic data uncertainty, and open\nset uncertainty, and review techniques that have been derived to address each\none. We then introduce a unified hierarchical model, which combines methods\nfrom Bayesian inference, invertible latent density inference, and\ndiscriminative classification in a single end-to-end deep neural network\ntopology to yield efficient per-sample uncertainty estimation in a detection\ncontext. This approach addresses all three uncertainty types and can readily\naccommodate prior/base rates for binary detection. We then discuss how to\nextend this model to a more generic multiclass recognition context.\n", "versions": [{"version": "v1", "created": "Mon, 29 Oct 2018 17:46:55 GMT"}, {"version": "v2", "created": "Thu, 14 Mar 2019 23:37:03 GMT"}], "update_date": "2019-03-18", "authors_parsed": [["Harang", "Richard", ""], ["Rudd", "Ethan M.", ""]]}, {"id": "1810.12281", "submitter": "Guodong Zhang", "authors": "Guodong Zhang, Chaoqi Wang, Bowen Xu, Roger Grosse", "title": "Three Mechanisms of Weight Decay Regularization", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Weight decay is one of the standard tricks in the neural network toolbox, but\nthe reasons for its regularization effect are poorly understood, and recent\nresults have cast doubt on the traditional interpretation in terms of $L_2$\nregularization. Literal weight decay has been shown to outperform $L_2$\nregularization for optimizers for which they differ. We empirically investigate\nweight decay for three optimization algorithms (SGD, Adam, and K-FAC) and a\nvariety of network architectures. We identify three distinct mechanisms by\nwhich weight decay exerts a regularization effect, depending on the particular\noptimization algorithm and architecture: (1) increasing the effective learning\nrate, (2) approximately regularizing the input-output Jacobian norm, and (3)\nreducing the effective damping coefficient for second-order optimization. Our\nresults provide insight into how to improve the regularization of neural\nnetworks.\n", "versions": [{"version": "v1", "created": "Mon, 29 Oct 2018 17:51:25 GMT"}], "update_date": "2018-10-30", "authors_parsed": [["Zhang", "Guodong", ""], ["Wang", "Chaoqi", ""], ["Xu", "Bowen", ""], ["Grosse", "Roger", ""]]}, {"id": "1810.12282", "submitter": "Katelyn Gao", "authors": "Charles Packer, Katelyn Gao, Jernej Kos, Philipp Kr\\\"ahenb\\\"uhl,\n  Vladlen Koltun, Dawn Song", "title": "Assessing Generalization in Deep Reinforcement Learning", "comments": "17 pages, 6 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep reinforcement learning (RL) has achieved breakthrough results on many\ntasks, but agents often fail to generalize beyond the environment they were\ntrained in. As a result, deep RL algorithms that promote generalization are\nreceiving increasing attention. However, works in this area use a wide variety\nof tasks and experimental setups for evaluation. The literature lacks a\ncontrolled assessment of the merits of different generalization schemes. Our\naim is to catalyze community-wide progress on generalization in deep RL. To\nthis end, we present a benchmark and experimental protocol, and conduct a\nsystematic empirical study. Our framework contains a diverse set of\nenvironments, our methodology covers both in-distribution and\nout-of-distribution generalization, and our evaluation includes deep RL\nalgorithms that specifically tackle generalization. Our key finding is that\n`vanilla' deep RL algorithms generalize better than specialized schemes that\nwere proposed specifically to tackle generalization.\n", "versions": [{"version": "v1", "created": "Mon, 29 Oct 2018 17:51:46 GMT"}, {"version": "v2", "created": "Fri, 15 Mar 2019 17:58:23 GMT"}], "update_date": "2019-03-18", "authors_parsed": [["Packer", "Charles", ""], ["Gao", "Katelyn", ""], ["Kos", "Jernej", ""], ["Kr\u00e4henb\u00fchl", "Philipp", ""], ["Koltun", "Vladlen", ""], ["Song", "Dawn", ""]]}, {"id": "1810.12283", "submitter": "David Eriksson", "authors": "David Eriksson, Kun Dong, Eric Hans Lee, David Bindel, Andrew Gordon\n  Wilson", "title": "Scaling Gaussian Process Regression with Derivatives", "comments": "Appears at Advances in Neural Information Processing Systems 32\n  (NIPS), 2018", "journal-ref": "Advances in Neural Information Processing Systems 32 (NIPS), 2018", "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Gaussian processes (GPs) with derivatives are useful in many applications,\nincluding Bayesian optimization, implicit surface reconstruction, and terrain\nreconstruction. Fitting a GP to function values and derivatives at $n$ points\nin $d$ dimensions requires linear solves and log determinants with an ${n(d+1)\n\\times n(d+1)}$ positive definite matrix -- leading to prohibitive\n$\\mathcal{O}(n^3d^3)$ computations for standard direct methods. We propose\niterative solvers using fast $\\mathcal{O}(nd)$ matrix-vector multiplications\n(MVMs), together with pivoted Cholesky preconditioning that cuts the iterations\nto convergence by several orders of magnitude, allowing for fast kernel\nlearning and prediction. Our approaches, together with dimensionality\nreduction, enables Bayesian optimization with derivatives to scale to\nhigh-dimensional problems and large evaluation budgets.\n", "versions": [{"version": "v1", "created": "Mon, 29 Oct 2018 17:51:54 GMT"}], "update_date": "2018-10-30", "authors_parsed": [["Eriksson", "David", ""], ["Dong", "Kun", ""], ["Lee", "Eric Hans", ""], ["Bindel", "David", ""], ["Wilson", "Andrew Gordon", ""]]}, {"id": "1810.12361", "submitter": "Murat A. Erdogdu", "authors": "Murat A. Erdogdu, Lester Mackey, Ohad Shamir", "title": "Global Non-convex Optimization with Discretized Diffusions", "comments": "19 pages, NeurIPS 2018 camera ready version", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG stat.CO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  An Euler discretization of the Langevin diffusion is known to converge to the\nglobal minimizers of certain convex and non-convex optimization problems. We\nshow that this property holds for any suitably smooth diffusion and that\ndifferent diffusions are suitable for optimizing different classes of convex\nand non-convex functions. This allows us to design diffusions suitable for\nglobally optimizing convex and non-convex functions not covered by the existing\nLangevin theory. Our non-asymptotic analysis delivers computable optimization\nand integration error bounds based on easily accessed properties of the\nobjective and chosen diffusion. Central to our approach are new explicit Stein\nfactor bounds on the solutions of Poisson equations. We complement these\nresults with improved optimization guarantees for targets other than the\nstandard Gibbs measure.\n", "versions": [{"version": "v1", "created": "Mon, 29 Oct 2018 19:09:23 GMT"}, {"version": "v2", "created": "Fri, 27 Dec 2019 08:28:28 GMT"}], "update_date": "2019-12-30", "authors_parsed": [["Erdogdu", "Murat A.", ""], ["Mackey", "Lester", ""], ["Shamir", "Ohad", ""]]}, {"id": "1810.12369", "submitter": "Siddarth Srinivasan", "authors": "Siddarth Srinivasan, Carlton Downey, Byron Boots", "title": "Learning and Inference in Hilbert Space with Quantum Graphical Models", "comments": "13 pages total, 9 pages content, 3 pages appendix; NIPS 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG quant-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Quantum Graphical Models (QGMs) generalize classical graphical models by\nadopting the formalism for reasoning about uncertainty from quantum mechanics.\nUnlike classical graphical models, QGMs represent uncertainty with density\nmatrices in complex Hilbert spaces. Hilbert space embeddings (HSEs) also\ngeneralize Bayesian inference in Hilbert spaces. We investigate the link\nbetween QGMs and HSEs and show that the sum rule and Bayes rule for QGMs are\nequivalent to the kernel sum rule in HSEs and a special case of Nadaraya-Watson\nkernel regression, respectively. We show that these operations can be\nkernelized, and use these insights to propose a Hilbert Space Embedding of\nHidden Quantum Markov Models (HSE-HQMM) to model dynamics. We present\nexperimental results showing that HSE-HQMMs are competitive with\nstate-of-the-art models like LSTMs and PSRNNs on several datasets, while also\nproviding a nonparametric method for maintaining a probability distribution\nover continuous-valued features.\n", "versions": [{"version": "v1", "created": "Mon, 29 Oct 2018 19:22:49 GMT"}], "update_date": "2018-10-31", "authors_parsed": [["Srinivasan", "Siddarth", ""], ["Downey", "Carlton", ""], ["Boots", "Byron", ""]]}, {"id": "1810.12380", "submitter": "Diego Chialva", "authors": "Diego Chialva and Ann Dooms", "title": "Conditionals in Homomorphic Encryption and Machine Learning Applications", "comments": "14 pages, 1 figure, corrected typos, added introductory pedagogical\n  section on polynomial approximation", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Homomorphic encryption aims at allowing computations on encrypted data\nwithout decryption other than that of the final result. This could provide an\nelegant solution to the issue of privacy preservation in data-based\napplications, such as those using machine learning, but several open issues\nhamper this plan. In this work we assess the possibility for homomorphic\nencryption to fully implement its program without relying on other techniques,\nsuch as multiparty computation (SMPC), which may be impossible in many use\ncases (for instance due to the high level of communication required). We\nproceed in two steps: i) on the basis of the structured program theorem\n(Bohm-Jacopini theorem) we identify the relevant minimal set of operations\nhomomorphic encryption must be able to perform to implement any algorithm; and\nii) we analyse the possibility to solve -- and propose an implementation for --\nthe most fundamentally relevant issue as it emerges from our analysis, that is,\nthe implementation of conditionals (requiring comparison and selection/jump\noperations). We show how this issue clashes with the fundamental requirements\nof homomorphic encryption and could represent a drawback for its use as a\ncomplete solution for privacy preservation in data-based applications, in\nparticular machine learning ones. Our approach for comparisons is novel and\nentirely embedded in homomorphic encryption, while previous studies relied on\nother techniques, such as SMPC, demanding high level of communication among\nparties, and decryption of intermediate results from data-owners. Our protocol\nis also provably safe (sharing the same safety as the homomorphic encryption\nschemes), differently from other techniques such as\nOrder-Preserving/Revealing-Encryption (OPE/ORE).\n", "versions": [{"version": "v1", "created": "Mon, 29 Oct 2018 19:44:23 GMT"}, {"version": "v2", "created": "Thu, 9 May 2019 19:02:20 GMT"}], "update_date": "2019-05-13", "authors_parsed": [["Chialva", "Diego", ""], ["Dooms", "Ann", ""]]}, {"id": "1810.12387", "submitter": "Hao Zhu", "authors": "Yihong Gu, Jun Yan, Hao Zhu, Zhiyuan Liu, Ruobing Xie, Maosong Sun,\n  Fen Lin, Leyu Lin", "title": "Language Modeling with Sparse Product of Sememe Experts", "comments": "EMNLP 2018. The first three authors contribute equally", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Most language modeling methods rely on large-scale data to statistically\nlearn the sequential patterns of words. In this paper, we argue that words are\natomic language units but not necessarily atomic semantic units. Inspired by\nHowNet, we use sememes, the minimum semantic units in human languages, to\nrepresent the implicit semantics behind words for language modeling, named\nSememe-Driven Language Model (SDLM). More specifically, to predict the next\nword, SDLM first estimates the sememe distribution gave textual context.\nAfterward, it regards each sememe as a distinct semantic expert, and these\nexperts jointly identify the most probable senses and the corresponding word.\nIn this way, SDLM enables language models to work beyond word-level\nmanipulation to fine-grained sememe-level semantics and offers us more powerful\ntools to fine-tune language models and improve the interpretability as well as\nthe robustness of language models. Experiments on language modeling and the\ndownstream application of headline gener- ation demonstrate the significant\neffect of SDLM. Source code and data used in the experiments can be accessed at\nhttps:// github.com/thunlp/SDLM-pytorch.\n", "versions": [{"version": "v1", "created": "Mon, 29 Oct 2018 20:13:05 GMT"}], "update_date": "2018-10-31", "authors_parsed": [["Gu", "Yihong", ""], ["Yan", "Jun", ""], ["Zhu", "Hao", ""], ["Liu", "Zhiyuan", ""], ["Xie", "Ruobing", ""], ["Sun", "Maosong", ""], ["Lin", "Fen", ""], ["Lin", "Leyu", ""]]}, {"id": "1810.12399", "submitter": "Jinsong Wu", "authors": "Rachad Atat, Lingjia Liu, Jinsong Wu, Guangyu Li, Chunxuan Ye, Yang Yi", "title": "Big Data Meet Cyber-Physical Systems: A Panoramic Survey", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  The world is witnessing an unprecedented growth of cyber-physical systems\n(CPS), which are foreseen to revolutionize our world {via} creating new\nservices and applications in a variety of sectors such as environmental\nmonitoring, mobile-health systems, intelligent transportation systems and so\non. The {information and communication technology }(ICT) sector is experiencing\na significant growth in { data} traffic, driven by the widespread usage of\nsmartphones, tablets and video streaming, along with the significant growth of\nsensors deployments that are anticipated in the near future. {It} is expected\nto outstandingly increase the growth rate of raw sensed data. In this paper, we\npresent the CPS taxonomy {via} providing a broad overview of data collection,\nstorage, access, processing and analysis. Compared with other survey papers,\nthis is the first panoramic survey on big data for CPS, where our objective is\nto provide a panoramic summary of different CPS aspects. Furthermore, CPS\n{require} cybersecurity to protect {them} against malicious attacks and\nunauthorized intrusion, which {become} a challenge with the enormous amount of\ndata that is continuously being generated in the network. {Thus, we also}\nprovide an overview of the different security solutions proposed for CPS big\ndata storage, access and analytics. We also discuss big data meeting green\nchallenges in the contexts of CPS.\n", "versions": [{"version": "v1", "created": "Mon, 29 Oct 2018 20:41:47 GMT"}], "update_date": "2018-10-31", "authors_parsed": [["Atat", "Rachad", ""], ["Liu", "Lingjia", ""], ["Wu", "Jinsong", ""], ["Li", "Guangyu", ""], ["Ye", "Chunxuan", ""], ["Yi", "Yang", ""]]}, {"id": "1810.12406", "submitter": "Patrick Chen", "authors": "Patrick H. Chen, Si Si, Sanjiv Kumar, Yang Li, Cho-Jui Hsieh", "title": "Learning to Screen for Fast Softmax Inference on Large Vocabulary Neural\n  Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CL stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Neural language models have been widely used in various NLP tasks, including\nmachine translation, next word prediction and conversational agents. However,\nit is challenging to deploy these models on mobile devices due to their slow\nprediction speed, where the bottleneck is to compute top candidates in the\nsoftmax layer. In this paper, we introduce a novel softmax layer approximation\nalgorithm by exploiting the clustering structure of context vectors. Our\nalgorithm uses a light-weight screening model to predict a much smaller set of\ncandidate words based on the given context, and then conducts an exact softmax\nonly within that subset. Training such a procedure end-to-end is challenging as\ntraditional clustering methods are discrete and non-differentiable, and thus\nunable to be used with back-propagation in the training process. Using the\nGumbel softmax, we are able to train the screening model end-to-end on the\ntraining set to exploit data distribution. The algorithm achieves an order of\nmagnitude faster inference than the original softmax layer for predicting\ntop-$k$ words in various tasks such as beam search in machine translation or\nnext words prediction. For example, for machine translation task on German to\nEnglish dataset with around 25K vocabulary, we can achieve 20.4 times speed up\nwith 98.9\\% precision@1 and 99.3\\% precision@5 with the original softmax layer\nprediction, while state-of-the-art ~\\citep{MSRprediction} only achieves 6.7x\nspeedup with 98.7\\% precision@1 and 98.1\\% precision@5 for the same task.\n", "versions": [{"version": "v1", "created": "Mon, 29 Oct 2018 20:59:56 GMT"}], "update_date": "2018-10-31", "authors_parsed": [["Chen", "Patrick H.", ""], ["Si", "Si", ""], ["Kumar", "Sanjiv", ""], ["Li", "Yang", ""], ["Hsieh", "Cho-Jui", ""]]}, {"id": "1810.12411", "submitter": "Sergiy Bokhnyak", "authors": "Heng xin Fun, Sergiy V Bokhnyak, Francesco Saverio Zuppichini", "title": "Counting in Language with RNNs", "comments": "Withdrawing due to lack of key acknowledgements and follow up work", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we examine a possible reason for the LSTM outperforming the GRU\non language modeling and more specifically machine translation. We hypothesize\nthat this has to do with counting. This is a consistent theme across the\nliterature of long term dependence, counting, and language modeling for RNNs.\nUsing the simplified forms of language -- Context-Free and Context-Sensitive\nLanguages -- we show how exactly the LSTM performs its counting based on their\ncell states during inference and why the GRU cannot perform as well.\n", "versions": [{"version": "v1", "created": "Mon, 29 Oct 2018 21:11:07 GMT"}, {"version": "v2", "created": "Wed, 31 Oct 2018 14:07:15 GMT"}], "update_date": "2018-11-01", "authors_parsed": [["Fun", "Heng xin", ""], ["Bokhnyak", "Sergiy V", ""], ["Zuppichini", "Francesco Saverio", ""]]}, {"id": "1810.12418", "submitter": "Xi Liu", "authors": "Ping-Chun Hsieh, Xi Liu, Anirban Bhattacharya, P. R. Kumar", "title": "Stay With Me: Lifetime Maximization Through Heteroscedastic Linear\n  Bandits With Reneging", "comments": "To appear in ICML 2019. More rounds of experiments are performed\n  before being taken average of compared to versions before", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Sequential decision making for lifetime maximization is a critical problem in\nmany real-world applications, such as medical treatment and portfolio\nselection. In these applications, a \"reneging\" phenomenon, where participants\nmay disengage from future interactions after observing an unsatisfiable\noutcome, is rather prevalent. To address the above issue, this paper proposes a\nmodel of heteroscedastic linear bandits with reneging, which allows each\nparticipant to have a distinct \"satisfaction level,\" with any interaction\noutcome falling short of that level resulting in that participant reneging.\nMoreover, it allows the variance of the outcome to be context-dependent. Based\non this model, we develop a UCB-type policy, namely HR-UCB, and prove that it\nachieves $\\mathcal{O}\\big(\\sqrt{{T}(\\log({T}))^{3}}\\big)$ regret. Finally, we\nvalidate the performance of HR-UCB via simulations.\n", "versions": [{"version": "v1", "created": "Mon, 29 Oct 2018 21:36:21 GMT"}, {"version": "v2", "created": "Wed, 31 Oct 2018 15:08:36 GMT"}, {"version": "v3", "created": "Tue, 14 May 2019 06:38:50 GMT"}, {"version": "v4", "created": "Wed, 15 May 2019 06:23:38 GMT"}], "update_date": "2019-05-16", "authors_parsed": [["Hsieh", "Ping-Chun", ""], ["Liu", "Xi", ""], ["Bhattacharya", "Anirban", ""], ["Kumar", "P. R.", ""]]}, {"id": "1810.12429", "submitter": "Ziyang Tang", "authors": "Qiang Liu, Lihong Li, Ziyang Tang, Dengyong Zhou", "title": "Breaking the Curse of Horizon: Infinite-Horizon Off-Policy Estimation", "comments": "21 pages, 5 figures, NIPS 2018 (spotlight)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.SY stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the off-policy estimation problem of estimating the expected\nreward of a target policy using samples collected by a different behavior\npolicy. Importance sampling (IS) has been a key technique to derive (nearly)\nunbiased estimators, but is known to suffer from an excessively high variance\nin long-horizon problems. In the extreme case of in infinite-horizon problems,\nthe variance of an IS-based estimator may even be unbounded. In this paper, we\npropose a new off-policy estimation method that applies IS directly on the\nstationary state-visitation distributions to avoid the exploding variance issue\nfaced by existing estimators.Our key contribution is a novel approach to\nestimating the density ratio of two stationary distributions, with trajectories\nsampled from only the behavior distribution. We develop a mini-max loss\nfunction for the estimation problem, and derive a closed-form solution for the\ncase of RKHS. We support our method with both theoretical and empirical\nanalyses.\n", "versions": [{"version": "v1", "created": "Mon, 29 Oct 2018 22:03:58 GMT"}], "update_date": "2018-10-31", "authors_parsed": [["Liu", "Qiang", ""], ["Li", "Lihong", ""], ["Tang", "Ziyang", ""], ["Zhou", "Dengyong", ""]]}, {"id": "1810.12448", "submitter": "Onur Tasar", "authors": "Onur Tasar, Yuliya Tarabalka, Pierre Alliez", "title": "Incremental Learning for Semantic Segmentation of Large-Scale Remote\n  Sensing Data", "comments": null, "journal-ref": "IEEE JOURNAL OF SELECTED TOPICS IN APPLIED EARTH OBSERVATIONS AND\n  REMOTE SENSING, 12, 2019, 3524-3537", "doi": "10.1109/JSTARS.2019.2925416", "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In spite of remarkable success of the convolutional neural networks on\nsemantic segmentation, they suffer from catastrophic forgetting: a significant\nperformance drop for the already learned classes when new classes are added on\nthe data, having no annotations for the old classes. We propose an incremental\nlearning methodology, enabling to learn segmenting new classes without\nhindering dense labeling abilities for the previous classes, although the\nentire previous data are not accessible. The key points of the proposed\napproach are adapting the network to learn new as well as old classes on the\nnew training data, and allowing it to remember the previously learned\ninformation for the old classes. For adaptation, we keep a frozen copy of the\npreviously trained network, which is used as a memory for the updated network\nin absence of annotations for the former classes. The updated network minimizes\na loss function, which balances the discrepancy between outputs for the\nprevious classes from the memory and updated networks, and the\nmis-classification rate between outputs for the new classes from the updated\nnetwork and the new ground-truth. For remembering, we either regularly feed\nsamples from the stored, little fraction of the previous data or use the memory\nnetwork, depending on whether the new data are collected from completely\ndifferent geographic areas or from the same city. Our experimental results\nprove that it is possible to add new classes to the network, while maintaining\nits performance for the previous classes, despite the whole previous training\ndata are not available.\n", "versions": [{"version": "v1", "created": "Mon, 29 Oct 2018 22:51:52 GMT"}], "update_date": "2019-11-28", "authors_parsed": [["Tasar", "Onur", ""], ["Tarabalka", "Yuliya", ""], ["Alliez", "Pierre", ""]]}, {"id": "1810.12456", "submitter": "Shuai Tang", "authors": "Shuai Tang, Paul Smolensky, Virginia R. de Sa", "title": "A Simple Recurrent Unit with Reduced Tensor Product Representations", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.LG cs.SC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  idely used recurrent units, including Long-short Term Memory (LSTM) and the\nGated Recurrent Unit (GRU), perform well on natural language tasks, but their\nability to learn structured representations is still questionable. Exploiting\nreduced Tensor Product Representations (TPRs) --- distributed representations\nof symbolic structure in which vector-embedded symbols are bound to\nvector-embedded structural positions --- we propose the TPRU, a simple\nrecurrent unit that, at each time step, explicitly executes structural-role\nbinding and unbinding operations to incorporate structural information into\nlearning. A gradient analysis of our proposed TPRU is conducted to support our\nmodel design, and its performance on multiple datasets shows the effectiveness\nof our design choices. Furthermore, observations on a linguistically grounded\nstudy demonstrate the interpretability of our TPRU.\n", "versions": [{"version": "v1", "created": "Mon, 29 Oct 2018 23:31:39 GMT"}, {"version": "v2", "created": "Sat, 3 Nov 2018 23:18:56 GMT"}, {"version": "v3", "created": "Mon, 26 Nov 2018 06:05:25 GMT"}, {"version": "v4", "created": "Thu, 31 Jan 2019 17:02:40 GMT"}, {"version": "v5", "created": "Mon, 27 May 2019 04:50:59 GMT"}, {"version": "v6", "created": "Tue, 5 Nov 2019 10:38:38 GMT"}], "update_date": "2019-11-06", "authors_parsed": [["Tang", "Shuai", ""], ["Smolensky", "Paul", ""], ["de Sa", "Virginia R.", ""]]}, {"id": "1810.12457", "submitter": "Milind Rao", "authors": "Milind Rao, Stefano Rini, Andrea Goldsmith", "title": "Distributed Convex Optimization With Limited Communications", "comments": "Extended version of submission to IEEE ICASSP 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.LG cs.MA eess.SP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, a distributed convex optimization algorithm, termed\n\\emph{distributed coordinate dual averaging} (DCDA) algorithm, is proposed. The\nDCDA algorithm addresses the scenario of a large distributed optimization\nproblem with limited communication among nodes in the network. Currently known\ndistributed subgradient methods, such as the distributed dual averaging or the\ndistributed alternating direction method of multipliers algorithms, assume that\nnodes can exchange messages of large cardinality. Such network communication\ncapabilities are not valid in many scenarios of practical relevance. In the\nDCDA algorithm, on the other hand, communication of each coordinate of the\noptimization variable is restricted over time. For the proposed algorithm, we\nbound the rate of convergence under different communication protocols and\nnetwork architectures. We also consider the extensions to the case of imperfect\ngradient knowledge and the case in which transmitted messages are corrupted by\nadditive noise or are quantized. Relevant numerical simulations are also\nprovided.\n", "versions": [{"version": "v1", "created": "Mon, 29 Oct 2018 23:42:37 GMT"}], "update_date": "2018-10-31", "authors_parsed": [["Rao", "Milind", ""], ["Rini", "Stefano", ""], ["Goldsmith", "Andrea", ""]]}, {"id": "1810.12460", "submitter": "Ashkan Esmaeili", "authors": "Ashkan Esmaeili, Farokh Marvasti", "title": "A Novel Approach to Quantized Matrix Completion Using Huber Loss Measure", "comments": null, "journal-ref": null, "doi": "10.1109/LSP.2019.2891134", "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we introduce a novel and robust approach to Quantized Matrix\nCompletion (QMC). First, we propose a rank minimization problem with\nconstraints induced by quantization bounds. Next, we form an unconstrained\noptimization problem by regularizing the rank function with Huber loss. Huber\nloss is leveraged to control the violation from quantization bounds due to two\nproperties: 1- It is differentiable, 2- It is less sensitive to outliers than\nthe quadratic loss. A Smooth Rank Approximation is utilized to endorse lower\nrank on the genuine data matrix. Thus, an unconstrained optimization problem\nwith differentiable objective function is obtained allowing us to advantage\nfrom Gradient Descent (GD) technique. Novel and firm theoretical analysis on\nproblem model and convergence of our algorithm to the global solution are\nprovided. Another contribution of our work is that our method does not require\nprojections or initial rank estimation unlike the state- of-the-art. In the\nNumerical Experiments Section, the noticeable outperformance of our proposed\nmethod in learning accuracy and computational complexity compared to those of\nthe state-of- the-art literature methods is illustrated as the main\ncontribution.\n", "versions": [{"version": "v1", "created": "Mon, 29 Oct 2018 23:44:29 GMT"}], "update_date": "2019-02-20", "authors_parsed": [["Esmaeili", "Ashkan", ""], ["Marvasti", "Farokh", ""]]}, {"id": "1810.12464", "submitter": "Rasool Fakoor", "authors": "Thomas Powers, Rasool Fakoor, Siamak Shakeri, Abhinav Sethy, Amanjit\n  Kainth, Abdel-rahman Mohamed, Ruhi Sarikaya", "title": "Differentiable Greedy Networks", "comments": "Work in progress and under review", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Optimal selection of a subset of items from a given set is a hard problem\nthat requires combinatorial optimization. In this paper, we propose a subset\nselection algorithm that is trainable with gradient-based methods yet achieves\nnear-optimal performance via submodular optimization. We focus on the task of\nidentifying a relevant set of sentences for claim verification in the context\nof the FEVER task. Conventional methods for this task look at sentences on\ntheir individual merit and thus do not optimize the informativeness of\nsentences as a set. We show that our proposed method which builds on the idea\nof unfolding a greedy algorithm into a computational graph allows both\ninterpretability and gradient-based training. The proposed differentiable\ngreedy network (DGN) outperforms discrete optimization algorithms as well as\nother baseline methods in terms of precision and recall.\n", "versions": [{"version": "v1", "created": "Tue, 30 Oct 2018 00:24:22 GMT"}], "update_date": "2018-10-31", "authors_parsed": [["Powers", "Thomas", ""], ["Fakoor", "Rasool", ""], ["Shakeri", "Siamak", ""], ["Sethy", "Abhinav", ""], ["Kainth", "Amanjit", ""], ["Mohamed", "Abdel-rahman", ""], ["Sarikaya", "Ruhi", ""]]}, {"id": "1810.12473", "submitter": "Roberto Souza", "authors": "Roberto Souza, Richard Frayne", "title": "A Hybrid Frequency-domain/Image-domain Deep Network for Magnetic\n  Resonance Image Reconstruction", "comments": "8 pages, 7 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.IV cs.LG eess.SP stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Decreasing magnetic resonance (MR) image acquisition times can potentially\nreduce procedural cost and make MR examinations more accessible. Compressed\nsensing (CS)-based image reconstruction methods, for example, decrease MR\nacquisition time by reconstructing high-quality images from data that were\noriginally sampled at rates inferior to the Nyquist-Shannon sampling theorem.\nIn this work we propose a hybrid architecture that works both in the k-space\n(or frequency-domain) and the image (or spatial) domains. Our network is\ncomposed of a complex-valued residual U-net in the k-space domain, an inverse\nFast Fourier Transform (iFFT) operation, and a real-valued U-net in the image\ndomain. Our experiments demonstrated, using MR raw k-space data, that the\nproposed hybrid approach can potentially improve CS reconstruction compared to\ndeep-learning networks that operate only in the image domain. In this study we\ncompare our method with four previously published deep neural networks and\nexamine their ability to reconstruct images that are subsequently used to\ngenerate regional volume estimates. We evaluated undersampling ratios of 75%\nand 80%. Our technique was ranked second in the quantitative analysis, but\nqualitative analysis indicated that our reconstruction performed the best in\nhard to reconstruct regions, such as the cerebellum. All images reconstructed\nwith our method were successfully post-processed, and showed good volumetry\nagreement compared with the fully sampled reconstruction measures.\n", "versions": [{"version": "v1", "created": "Tue, 30 Oct 2018 01:10:19 GMT"}], "update_date": "2018-10-31", "authors_parsed": [["Souza", "Roberto", ""], ["Frayne", "Richard", ""]]}, {"id": "1810.12482", "submitter": "Tomas Geffner", "authors": "Tomas Geffner, Justin Domke", "title": "Using Large Ensembles of Control Variates for Variational Inference", "comments": "Neural Information Processing Systems (NIPS 2018)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Variational inference is increasingly being addressed with stochastic\noptimization. In this setting, the gradient's variance plays a crucial role in\nthe optimization procedure, since high variance gradients lead to poor\nconvergence. A popular approach used to reduce gradient's variance involves the\nuse of control variates. Despite the good results obtained, control variates\ndeveloped for variational inference are typically looked at in isolation. In\nthis paper we clarify the large number of control variates that are available\nby giving a systematic view of how they are derived. We also present a Bayesian\nrisk minimization framework in which the quality of a procedure for combining\ncontrol variates is quantified by its effect on optimization convergence rates,\nwhich leads to a very simple combination rule. Results show that combining a\nlarge number of control variates this way significantly improves the\nconvergence of inference over using the typical gradient estimators or a\nreduced number of control variates.\n", "versions": [{"version": "v1", "created": "Tue, 30 Oct 2018 01:48:19 GMT"}, {"version": "v2", "created": "Thu, 22 Oct 2020 11:03:48 GMT"}], "update_date": "2020-10-23", "authors_parsed": [["Geffner", "Tomas", ""], ["Domke", "Justin", ""]]}, {"id": "1810.12488", "submitter": "Yen-Chang Hsu", "authors": "Yen-Chang Hsu, Yen-Cheng Liu, Anita Ramasamy, and Zsolt Kira", "title": "Re-evaluating Continual Learning Scenarios: A Categorization and Case\n  for Strong Baselines", "comments": "Continual Learning Workshop, 32nd Conference on Neural Information\n  Processing Systems (NIPS 2018)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Continual learning has received a great deal of attention recently with\nseveral approaches being proposed. However, evaluations involve a diverse set\nof scenarios making meaningful comparison difficult. This work provides a\nsystematic categorization of the scenarios and evaluates them within a\nconsistent framework including strong baselines and state-of-the-art methods.\nThe results provide an understanding of the relative difficulty of the\nscenarios and that simple baselines (Adagrad, L2 regularization, and naive\nrehearsal strategies) can surprisingly achieve similar performance to current\nmainstream methods. We conclude with several suggestions for creating harder\nevaluation scenarios and future research directions. The code is available at\nhttps://github.com/GT-RIPL/Continual-Learning-Benchmark\n", "versions": [{"version": "v1", "created": "Tue, 30 Oct 2018 02:08:35 GMT"}, {"version": "v2", "created": "Thu, 8 Nov 2018 16:50:11 GMT"}, {"version": "v3", "created": "Mon, 10 Dec 2018 03:51:28 GMT"}, {"version": "v4", "created": "Wed, 23 Jan 2019 16:58:13 GMT"}], "update_date": "2019-01-24", "authors_parsed": [["Hsu", "Yen-Chang", ""], ["Liu", "Yen-Cheng", ""], ["Ramasamy", "Anita", ""], ["Kira", "Zsolt", ""]]}, {"id": "1810.12506", "submitter": "Yeping Hu", "authors": "Yeping Hu, Wei Zhan, Masayoshi Tomizuka", "title": "A Framework for Probabilistic Generic Traffic Scene Prediction", "comments": "2018 IEEE 21st International Conference on Intelligent Transportation\n  Systems (ITSC)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.RO stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In a given scenario, simultaneously and accurately predicting every possible\ninteraction of traffic participants is an important capability for autonomous\nvehicles. The majority of current researches focused on the prediction of an\nsingle entity without incorporating the environment information. Although some\napproaches aimed to predict multiple vehicles, they either predicted each\nvehicle independently with no considerations on possible interaction with\nsurrounding entities or generated discretized joint motions which cannot be\ndirectly used in decision making and motion planning for autonomous vehicle. In\nthis paper, we present a probabilistic framework that is able to jointly\npredict continuous motions for multiple interacting road participants under any\ndriving scenarios and is capable of forecasting the duration of each\ninteraction, which can enhance the prediction performance and efficiency. The\nproposed traffic scene prediction framework contains two hierarchical modules:\nthe upper module and the lower module. The upper module forecasts the intention\nof the predicted vehicle, while the lower module predicts motions for\ninteracting scene entities. An exemplar real-world scenario is used to\nimplement and examine the proposed framework.\n", "versions": [{"version": "v1", "created": "Tue, 30 Oct 2018 03:04:45 GMT"}], "update_date": "2018-10-31", "authors_parsed": [["Hu", "Yeping", ""], ["Zhan", "Wei", ""], ["Tomizuka", "Masayoshi", ""]]}, {"id": "1810.12513", "submitter": "Shin Ando Ph. D.", "authors": "Shin Ando", "title": "Weak-supervision for Deep Representation Learning under Class Imbalance", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Class imbalance is a pervasive issue among classification models including\ndeep learning, whose capacity to extract task-specific features is affected in\nimbalanced settings. However, the challenges of handling imbalance among a\nlarge number of classes, commonly addressed by deep learning, have not received\na significant amount of attention in previous studies. In this paper, we\npropose an extension of the deep over-sampling framework, to exploit\nautomatically-generated abstract-labels, i.e., a type of side-information used\nin weak-label learning, to enhance deep representation learning against class\nimbalance. We attempt to exploit the labels to guide the deep representation of\ninstances towards different subspaces, to induce a soft-separation of inherent\nsubtasks of the classification problem. Our empirical study shows that the\nproposed framework achieves a substantial improvement on image classification\nbenchmarks with imbalanced among large and small numbers of classes.\n", "versions": [{"version": "v1", "created": "Tue, 30 Oct 2018 03:37:09 GMT"}], "update_date": "2018-10-31", "authors_parsed": [["Ando", "Shin", ""]]}, {"id": "1810.12521", "submitter": "Yi Zhu", "authors": "Yi Zhu and Jia Xue and Shawn Newsam", "title": "Gated Transfer Network for Transfer Learning", "comments": "Accepted at ACCV 2018. Camera ready", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.LG cs.MM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep neural networks have led to a series of breakthroughs in computer vision\ngiven sufficient annotated training datasets. For novel tasks with limited\nlabeled data, the prevalent approach is to transfer the knowledge learned in\nthe pre-trained models to the new tasks by fine-tuning. Classic model\nfine-tuning utilizes the fact that well trained neural networks appear to learn\ncross domain features. These features are treated equally during transfer\nlearning. In this paper, we explore the impact of feature selection in model\nfine-tuning by introducing a transfer module, which assigns weights to features\nextracted from pre-trained models. The proposed transfer module proves the\nimportance of feature selection for transferring models from source to target\ndomains. It is shown to significantly improve upon fine-tuning results with\nonly marginal extra computational cost. We also incorporate an auxiliary\nclassifier as an extra regularizer to avoid over-fitting. Finally, we build a\nGated Transfer Network (GTN) based on our transfer module and achieve\nstate-of-the-art results on six different tasks.\n", "versions": [{"version": "v1", "created": "Tue, 30 Oct 2018 04:31:48 GMT"}], "update_date": "2018-10-31", "authors_parsed": [["Zhu", "Yi", ""], ["Xue", "Jia", ""], ["Newsam", "Shawn", ""]]}, {"id": "1810.12544", "submitter": "Dong Huang", "authors": "Dong Huang, Chang-Dong Wang, Hongxing Peng, Jianhuang Lai, Chee-Keong\n  Kwoh", "title": "Enhanced Ensemble Clustering via Fast Propagation of Cluster-wise\n  Similarities", "comments": "To appear in IEEE Transactions on Systems, Man, and Cybernetics:\n  Systems. The MATLAB source code of this work is available at:\n  http://www.researchgate.net/publication/328581758", "journal-ref": null, "doi": "10.1109/TSMC.2018.2876202", "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Ensemble clustering has been a popular research topic in data mining and\nmachine learning. Despite its significant progress in recent years, there are\nstill two challenging issues in the current ensemble clustering research.\nFirst, most of the existing algorithms tend to investigate the ensemble\ninformation at the object-level, yet often lack the ability to explore the rich\ninformation at higher levels of granularity. Second, they mostly focus on the\ndirect connections (e.g., direct intersection or pair-wise co-occurrence) in\nthe multiple base clusterings, but generally neglect the multi-scale indirect\nrelationship hidden in them. To address these two issues, this paper presents a\nnovel ensemble clustering approach based on fast propagation of cluster-wise\nsimilarities via random walks. We first construct a cluster similarity graph\nwith the base clusters treated as graph nodes and the cluster-wise Jaccard\ncoefficient exploited to compute the initial edge weights. Upon the constructed\ngraph, a transition probability matrix is defined, based on which the random\nwalk process is conducted to propagate the graph structural information.\nSpecifically, by investigating the propagating trajectories starting from\ndifferent nodes, a new cluster-wise similarity matrix can be derived by\nconsidering the trajectory relationship. Then, the newly obtained cluster-wise\nsimilarity matrix is mapped from the cluster-level to the object-level to\nachieve an enhanced co-association (ECA) matrix, which is able to\nsimultaneously capture the object-wise co-occurrence relationship as well as\nthe multi-scale cluster-wise relationship in ensembles. Finally, two novel\nconsensus functions are proposed to obtain the consensus clustering result.\nExtensive experiments on a variety of real-world datasets have demonstrated the\neffectiveness and efficiency of our approach.\n", "versions": [{"version": "v1", "created": "Tue, 30 Oct 2018 06:34:50 GMT"}], "update_date": "2018-10-31", "authors_parsed": [["Huang", "Dong", ""], ["Wang", "Chang-Dong", ""], ["Peng", "Hongxing", ""], ["Lai", "Jianhuang", ""], ["Kwoh", "Chee-Keong", ""]]}, {"id": "1810.12558", "submitter": "Mahammad Humayoo", "authors": "Mahammad Humayoo and Xueqi Cheng", "title": "Relative Importance Sampling For Off-Policy Actor-Critic in Deep\n  Reinforcement Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Off-policy learning is more unstable compared to on-policy learning in\nreinforcement learning (RL). One reason for the instability of off-policy\nlearning is a discrepancy between the target ($\\pi$) and behavior (b) policy\ndistributions. The discrepancy between $\\pi$ and b distributions can be\nalleviated by employing a smooth variant of the importance sampling (IS), such\nas the relative importance sampling (RIS). RIS has parameter $\\beta\\in[0, 1]$\nwhich controls smoothness. To cope with instability, we present the first\nrelative importance sampling-off-policy actor-critic (RIS-Off-PAC) model-free\nalgorithms in RL. In our method, the network yields a target policy (the\nactor), a value function (the critic) assessing the current policy ($\\pi$)\nusing samples drawn from behavior policy. We use action value generated from\nthe behavior policy in reward function to train our algorithm rather than from\nthe target policy. We also use deep neural networks to train both actor and\ncritic. We evaluated our algorithm on a number of Open AI Gym benchmark\nproblems and demonstrate better or comparable performance to several\nstate-of-the-art RL baselines.\n", "versions": [{"version": "v1", "created": "Tue, 30 Oct 2018 07:41:08 GMT"}, {"version": "v2", "created": "Tue, 15 Jan 2019 07:13:50 GMT"}, {"version": "v3", "created": "Wed, 8 May 2019 00:27:31 GMT"}, {"version": "v4", "created": "Thu, 11 Jul 2019 02:42:41 GMT"}, {"version": "v5", "created": "Tue, 16 Jul 2019 01:35:44 GMT"}, {"version": "v6", "created": "Fri, 19 Jul 2019 03:08:45 GMT"}], "update_date": "2019-07-22", "authors_parsed": [["Humayoo", "Mahammad", ""], ["Cheng", "Xueqi", ""]]}, {"id": "1810.12563", "submitter": "Haowen Luo", "authors": "Haowen Luo", "title": "Shorten Spatial-spectral RNN with Parallel-GRU for Hyperspectral Image\n  Classification", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Convolutional neural networks (CNNs) attained a good performance in\nhyperspectral sensing image (HSI) classification, but CNNs consider spectra as\norderless vectors. Therefore, considering the spectra as sequences, recurrent\nneural networks (RNNs) have been applied in HSI classification, for RNNs is\nskilled at dealing with sequential data. However, for a long-sequence task,\nRNNs is difficult for training and not as effective as we expected. Besides,\nspatial contextual features are not considered in RNNs. In this study, we\npropose a Shorten Spatial-spectral RNN with Parallel-GRU (St-SS-pGRU) for HSI\nclassification. A shorten RNN is more efficient and easier for training than\nband-by-band RNN. By combining converlusion layer, the St-SSpGRU model\nconsiders not only spectral but also spatial feature, which results in a better\nperformance. An architecture named parallel-GRU is also proposed and applied in\nSt-SS-pGRU. With this architecture, the model gets a better performance and is\nmore robust.\n", "versions": [{"version": "v1", "created": "Tue, 30 Oct 2018 07:57:27 GMT"}], "update_date": "2018-10-31", "authors_parsed": [["Luo", "Haowen", ""]]}, {"id": "1810.12575", "submitter": "Tobias Pl\\\"otz", "authors": "Tobias Pl\\\"otz and Stefan Roth", "title": "Neural Nearest Neighbors Networks", "comments": "to appear at NIPS*2018, code available at\n  https://github.com/visinf/n3net/", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Non-local methods exploiting the self-similarity of natural signals have been\nwell studied, for example in image analysis and restoration. Existing\napproaches, however, rely on k-nearest neighbors (KNN) matching in a fixed\nfeature space. The main hurdle in optimizing this feature space w.r.t.\napplication performance is the non-differentiability of the KNN selection rule.\nTo overcome this, we propose a continuous deterministic relaxation of KNN\nselection that maintains differentiability w.r.t. pairwise distances, but\nretains the original KNN as the limit of a temperature parameter approaching\nzero. To exploit our relaxation, we propose the neural nearest neighbors block\n(N3 block), a novel non-local processing layer that leverages the principle of\nself-similarity and can be used as building block in modern neural network\narchitectures. We show its effectiveness for the set reasoning task of\ncorrespondence classification as well as for image restoration, including image\ndenoising and single image super-resolution, where we outperform strong\nconvolutional neural network (CNN) baselines and recent non-local models that\nrely on KNN selection in hand-chosen features spaces.\n", "versions": [{"version": "v1", "created": "Tue, 30 Oct 2018 08:32:47 GMT"}], "update_date": "2018-10-31", "authors_parsed": [["Pl\u00f6tz", "Tobias", ""], ["Roth", "Stefan", ""]]}, {"id": "1810.12576", "submitter": "Alexander Matyasko", "authors": "Alexander Matyasko, Lap-Pui Chau", "title": "Improved Network Robustness with Adversary Critic", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://creativecommons.org/publicdomain/zero/1.0/", "abstract": "  Ideally, what confuses neural network should be confusing to humans. However,\nrecent experiments have shown that small, imperceptible perturbations can\nchange the network prediction. To address this gap in perception, we propose a\nnovel approach for learning robust classifier. Our main idea is: adversarial\nexamples for the robust classifier should be indistinguishable from the regular\ndata of the adversarial target. We formulate a problem of learning robust\nclassifier in the framework of Generative Adversarial Networks (GAN), where the\nadversarial attack on classifier acts as a generator, and the critic network\nlearns to distinguish between regular and adversarial images. The classifier\ncost is augmented with the objective that its adversarial examples should\nconfuse the adversary critic. To improve the stability of the adversarial\nmapping, we introduce adversarial cycle-consistency constraint which ensures\nthat the adversarial mapping of the adversarial examples is close to the\noriginal. In the experiments, we show the effectiveness of our defense. Our\nmethod surpasses in terms of robustness networks trained with adversarial\ntraining. Additionally, we verify in the experiments with human annotators on\nMTurk that adversarial examples are indeed visually confusing. Codes for the\nproject are available at https://github.com/aam-at/adversary_critic.\n", "versions": [{"version": "v1", "created": "Tue, 30 Oct 2018 08:33:46 GMT"}], "update_date": "2018-10-31", "authors_parsed": [["Matyasko", "Alexander", ""], ["Chau", "Lap-Pui", ""]]}, {"id": "1810.12582", "submitter": "Lingbing Guo", "authors": "Lingbing Guo, Qingheng Zhang, Weiyi Ge, Wei Hu, and Yuzhong Qu", "title": "DSKG: A Deep Sequential Model for Knowledge Graph Completion", "comments": "CCKS (China Conference on Knowledge Graph and Semantic Computing)\n  Best English Paper Award 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Knowledge graph (KG) completion aims to fill the missing facts in a KG, where\na fact is represented as a triple in the form of $(subject, relation, object)$.\nCurrent KG completion models compel two-thirds of a triple provided (e.g.,\n$subject$ and $relation$) to predict the remaining one. In this paper, we\npropose a new model, which uses a KG-specific multi-layer recurrent neural\nnetwork (RNN) to model triples in a KG as sequences. It outperformed several\nstate-of-the-art KG completion models on the conventional entity prediction\ntask for many evaluation metrics, based on two benchmark datasets and a more\ndifficult dataset. Furthermore, our model is enabled by the sequential\ncharacteristic and thus capable of predicting the whole triples only given one\nentity. Our experiments demonstrated that our model achieved promising\nperformance on this new triple prediction task.\n", "versions": [{"version": "v1", "created": "Tue, 30 Oct 2018 08:45:01 GMT"}, {"version": "v2", "created": "Sun, 30 Dec 2018 09:51:05 GMT"}], "update_date": "2019-01-01", "authors_parsed": [["Guo", "Lingbing", ""], ["Zhang", "Qingheng", ""], ["Ge", "Weiyi", ""], ["Hu", "Wei", ""], ["Qu", "Yuzhong", ""]]}, {"id": "1810.12611", "submitter": "Asifullah Khan", "authors": "Aqsa Saeed Qureshi, Asifullah Khan", "title": "Adaptive Transfer Learning in Deep Neural Networks: Wind Power\n  Prediction using Knowledge Transfer from Region to Region and Between\n  Different Task Domains", "comments": "28 pages, 21 figures, and 11 tables", "journal-ref": null, "doi": "10.1111/coin.12236", "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Transfer Learning (TL) in Deep Neural Networks is gaining importance because\nin most of the applications, the labeling of data is costly and time-consuming.\nAdditionally, TL also provides an effective weight initialization strategy for\nDeep Neural Networks . This paper introduces the idea of Adaptive Transfer\nLearning in Deep Neural Networks (ATL-DNN) for wind power prediction.\nSpecifically, we show in case of wind power prediction that adaptive TL of Deep\nNeural Networks system can be adaptively modified as regards training on a\ndifferent wind farm is concerned. The proposed ATL-DNN technique is tested for\nshort-term wind power prediction, where continuously arriving information has\nto be exploited. Adaptive TL not only helps in providing good weight\ninitialization, but is also helpful to utilize the incoming data for effective\nlearning. Additionally, the proposed ATL-DNN technique is shown to transfer\nknowledge between different task domains (wind power to wind speed prediction)\nand from one region to another region. The simulation results show that the\nproposed ATL-DNN technique achieves average values of 0.0637,0.0986, and 0.0984\nfor the Mean-Absolute-Error, Root-Mean-Squared-Error, and\nStandard-Deviation-Error, respectively.\n", "versions": [{"version": "v1", "created": "Tue, 30 Oct 2018 09:47:32 GMT"}, {"version": "v2", "created": "Thu, 20 Dec 2018 11:27:20 GMT"}], "update_date": "2019-08-20", "authors_parsed": [["Qureshi", "Aqsa Saeed", ""], ["Khan", "Asifullah", ""]]}, {"id": "1810.12613", "submitter": "Bhalaji Nagarajan Mr", "authors": "Bhalaji Nagarajan, V Ramana Murthy Oruganti", "title": "Deep Learning as Feature Encoding for Emotion Recognition", "comments": "Issues pertaining with experimental results reported in paper", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Deep learning is popular as an end-to-end framework extracting the prominent\nfeatures and performing the classification also. In this paper, we extensively\ninvestigate deep networks as an alternate to feature encoding technique of low\nlevel descriptors for emotion recognition on the benchmark EmoDB dataset.\nFusion performance with such obtained encoded features with other available\nfeatures is also investigated. Highest performance to date in the literature is\nobserved.\n", "versions": [{"version": "v1", "created": "Tue, 30 Oct 2018 09:53:28 GMT"}, {"version": "v2", "created": "Wed, 14 Nov 2018 10:57:31 GMT"}], "update_date": "2018-11-15", "authors_parsed": [["Nagarajan", "Bhalaji", ""], ["Oruganti", "V Ramana Murthy", ""]]}, {"id": "1810.12656", "submitter": "Li-Wei Chen", "authors": "Li-Wei Chen, Hung-Yi Lee, Yu Tsao", "title": "Generative Adversarial Networks for Unpaired Voice Transformation on\n  Impaired Speech", "comments": "Published as a conference paper at INTERSPEECH 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.AS cs.LG cs.SD", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper focuses on using voice conversion (VC) to improve the speech\nintelligibility of surgical patients who have had parts of their articulators\nremoved. Due to the difficulty of data collection, VC without parallel data is\nhighly desired. Although techniques for unparallel VC, for example, CycleGAN,\nhave been developed, they usually focus on transforming the speaker identity,\nand directly transforming the speech of one speaker to that of another speaker\nand as such do not address the task here. In this paper, we propose a new\napproach for unparallel VC. The proposed approach transforms impaired speech to\nnormal speech while preserving the linguistic content and speaker\ncharacteristics. To our knowledge, this is the first end-to-end GAN-based\nunsupervised VC model applied to impaired speech. The experimental results show\nthat the proposed approach outperforms CycleGAN.\n", "versions": [{"version": "v1", "created": "Tue, 30 Oct 2018 11:11:14 GMT"}, {"version": "v2", "created": "Mon, 12 Nov 2018 19:09:47 GMT"}, {"version": "v3", "created": "Thu, 22 Aug 2019 19:17:23 GMT"}], "update_date": "2019-08-26", "authors_parsed": [["Chen", "Li-Wei", ""], ["Lee", "Hung-Yi", ""], ["Tsao", "Yu", ""]]}, {"id": "1810.12679", "submitter": "Pablo A. Alvarado", "authors": "Pablo A. Alvarado, Mauricio A. \\'Alvarez, Dan Stowell", "title": "Sparse Gaussian Process Audio Source Separation Using Spectrum Priors in\n  the Time-Domain", "comments": "Paper submitted to the 44th International Conference on Acoustics,\n  Speech, and Signal Processing, ICASSP 2019. To be held in Brighton, United\n  Kingdom, between May 12 and May 17, 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.AS cs.LG cs.SD eess.SP stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Gaussian process (GP) audio source separation is a time-domain approach that\ncircumvents the inherent phase approximation issue of spectrogram based\nmethods. Furthermore, through its kernel, GPs elegantly incorporate prior\nknowledge about the sources into the separation model. Despite these compelling\nadvantages, the computational complexity of GP inference scales cubically with\nthe number of audio samples. As a result, source separation GP models have been\nrestricted to the analysis of short audio frames. We introduce an efficient\napplication of GPs to time-domain audio source separation, without compromising\nperformance. For this purpose, we used GP regression, together with spectral\nmixture kernels, and variational sparse GPs. We compared our method with\nLD-PSDTF (positive semi-definite tensor factorization), KL-NMF\n(Kullback-Leibler non-negative matrix factorization), and IS-NMF (Itakura-Saito\nNMF). Results show that the proposed method outperforms these techniques.\n", "versions": [{"version": "v1", "created": "Tue, 30 Oct 2018 11:46:35 GMT"}, {"version": "v2", "created": "Mon, 5 Nov 2018 09:49:35 GMT"}, {"version": "v3", "created": "Wed, 21 Nov 2018 12:18:46 GMT"}], "update_date": "2018-11-22", "authors_parsed": [["Alvarado", "Pablo A.", ""], ["\u00c1lvarez", "Mauricio A.", ""], ["Stowell", "Dan", ""]]}, {"id": "1810.12683", "submitter": "Emilie Morvant", "authors": "Ga\\\"el Letarte, Emilie Morvant (LHC), Pascal Germain (MODAL)", "title": "Pseudo-Bayesian Learning with Kernel Fourier Transform as Prior", "comments": "Published at AISTATS 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We revisit Rahimi and Recht (2007)'s kernel random Fourier features (RFF)\nmethod through the lens of the PAC-Bayesian theory. While the primary goal of\nRFF is to approximate a kernel, we look at the Fourier transform as a prior\ndistribution over trigonometric hypotheses. It naturally suggests learning a\nposterior on these hypotheses. We derive generalization bounds that are\noptimized by learning a pseudo-posterior obtained from a closed-form\nexpression. Based on this study, we consider two learning strategies: The first\none finds a compact landmarks-based representation of the data where each\nlandmark is given by a distribution-tailored similarity measure, while the\nsecond one provides a PAC-Bayesian justification to the kernel alignment method\nof Sinha and Duchi (2016).\n", "versions": [{"version": "v1", "created": "Tue, 30 Oct 2018 11:55:06 GMT"}, {"version": "v2", "created": "Wed, 27 Mar 2019 14:05:25 GMT"}], "update_date": "2019-03-28", "authors_parsed": [["Letarte", "Ga\u00ebl", "", "LHC"], ["Morvant", "Emilie", "", "LHC"], ["Germain", "Pascal", "", "MODAL"]]}, {"id": "1810.12692", "submitter": "Iqbal H. Sarker", "authors": "Iqbal H. Sarker", "title": "Research Issues in Mining User Behavioral Rules for Context-Aware\n  Intelligent Mobile Applications", "comments": "12 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Context-awareness in smart mobile applications is a growing area of study,\nbecause of it's intelligence in the applications. In order to build\ncontext-aware intelligent applications, mining contextual behavioral rules of\nindividual smartphone users utilizing their phone log data is the key. However,\nto mine these rules, a number of issues, such as the quality of smartphone\ndata, understanding the relevancy of contexts, discretization of continuous\ncontextual data, discovery of useful behavioral rules of individuals and their\nordering, knowledge-based interactive post-mining for semantic understanding,\nand dynamic updating and management of rules according to their present\nbehavior, are investigated. In this paper, we briefly discuss these issues and\ntheir potential solution directions for mining individuals' behavioral rules,\nfor the purpose of building various context-aware intelligent mobile\napplications. We also summarize a number of real-life rule-based applications\nthat intelligently assist individual smartphone users according to their\nbehavioral rules in their daily activities.\n", "versions": [{"version": "v1", "created": "Tue, 30 Oct 2018 12:10:43 GMT"}], "update_date": "2018-10-31", "authors_parsed": [["Sarker", "Iqbal H.", ""]]}, {"id": "1810.12698", "submitter": "Vaidheeswaran Archana", "authors": "Muru Selvakumar, Suriyadeepan Ramamoorthy, Vaidheeswaran Archana,\n  Malaikannan Sankarasubbu", "title": "Compositional Attention Networks for Interpretability in Natural\n  Language Question Answering", "comments": "8 pages,10 figures, 1 table", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CL stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  MAC Net is a compositional attention network designed for Visual Question\nAnswering. We propose a modified MAC net architecture for Natural Language\nQuestion Answering. Question Answering typically requires Language\nUnderstanding and multi-step Reasoning. MAC net's unique architecture - the\nseparation between memory and control, facilitates data-driven iterative\nreasoning. This makes it an ideal candidate for solving tasks that involve\nlogical reasoning. Our experiments with 20 bAbI tasks demonstrate the value of\nMAC net as a data-efficient and interpretable architecture for Natural Language\nQuestion Answering. The transparent nature of MAC net provides a highly\ngranular view of the reasoning steps taken by the network in answering a query.\n", "versions": [{"version": "v1", "created": "Tue, 30 Oct 2018 12:23:35 GMT"}], "update_date": "2018-10-31", "authors_parsed": [["Selvakumar", "Muru", ""], ["Ramamoorthy", "Suriyadeepan", ""], ["Archana", "Vaidheeswaran", ""], ["Sankarasubbu", "Malaikannan", ""]]}, {"id": "1810.12715", "submitter": "Sven Gowal", "authors": "Sven Gowal, Krishnamurthy Dvijotham, Robert Stanforth, Rudy Bunel,\n  Chongli Qin, Jonathan Uesato, Relja Arandjelovic, Timothy Mann, Pushmeet\n  Kohli", "title": "On the Effectiveness of Interval Bound Propagation for Training\n  Verifiably Robust Models", "comments": "[v2] Best paper at NeurIPS SECML 2018 Workshop [v4] Accepted at ICCV\n  2019 under the title \"Scalable Verified Training for Provably Robust Image\n  Classification\"", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent work has shown that it is possible to train deep neural networks that\nare provably robust to norm-bounded adversarial perturbations. Most of these\nmethods are based on minimizing an upper bound on the worst-case loss over all\npossible adversarial perturbations. While these techniques show promise, they\noften result in difficult optimization procedures that remain hard to scale to\nlarger networks. Through a comprehensive analysis, we show how a simple\nbounding technique, interval bound propagation (IBP), can be exploited to train\nlarge provably robust neural networks that beat the state-of-the-art in\nverified accuracy. While the upper bound computed by IBP can be quite weak for\ngeneral networks, we demonstrate that an appropriate loss and clever\nhyper-parameter schedule allow the network to adapt such that the IBP bound is\ntight. This results in a fast and stable learning algorithm that outperforms\nmore sophisticated methods and achieves state-of-the-art results on MNIST,\nCIFAR-10 and SVHN. It also allows us to train the largest model to be verified\nbeyond vacuous bounds on a downscaled version of ImageNet.\n", "versions": [{"version": "v1", "created": "Tue, 30 Oct 2018 13:12:47 GMT"}, {"version": "v2", "created": "Mon, 5 Nov 2018 11:48:21 GMT"}, {"version": "v3", "created": "Mon, 28 Jan 2019 16:53:04 GMT"}, {"version": "v4", "created": "Thu, 29 Aug 2019 12:23:52 GMT"}], "update_date": "2019-08-30", "authors_parsed": [["Gowal", "Sven", ""], ["Dvijotham", "Krishnamurthy", ""], ["Stanforth", "Robert", ""], ["Bunel", "Rudy", ""], ["Qin", "Chongli", ""], ["Uesato", "Jonathan", ""], ["Arandjelovic", "Relja", ""], ["Mann", "Timothy", ""], ["Kohli", "Pushmeet", ""]]}, {"id": "1810.12722", "submitter": "Thomas Niesler", "authors": "Lerato Lerato and Thomas Niesler", "title": "Feature Trajectory Dynamic Time Warping for Clustering of Speech\n  Segments", "comments": "10 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SD cs.LG eess.AS stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Dynamic time warping (DTW) can be used to compute the similarity between two\nsequences of generally differing length. We propose a modification to DTW that\nperforms individual and independent pairwise alignment of feature trajectories.\nThe modified technique, termed feature trajectory dynamic time warping (FTDTW),\nis applied as a similarity measure in the agglomerative hierarchical clustering\nof speech segments. Experiments using MFCC and PLP parametrisations extracted\nfrom TIMIT and from the Spoken Arabic Digit Dataset (SADD) show consistent and\nstatistically significant improvements in the quality of the resulting clusters\nin terms of F-measure and normalised mutual information (NMI).\n", "versions": [{"version": "v1", "created": "Tue, 30 Oct 2018 13:30:19 GMT"}], "update_date": "2018-10-31", "authors_parsed": [["Lerato", "Lerato", ""], ["Niesler", "Thomas", ""]]}, {"id": "1810.12730", "submitter": "Fuming Fang", "authors": "Fuming Fang, Xin Wang, Junichi Yamagishi, Isao Echizen", "title": "Audiovisual speaker conversion: jointly and simultaneously transforming\n  facial expression and acoustic characteristics", "comments": "Submitted to ICASSP 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.AS cs.CL cs.LG cs.SD stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  An audiovisual speaker conversion method is presented for simultaneously\ntransforming the facial expressions and voice of a source speaker into those of\na target speaker. Transforming the facial and acoustic features together makes\nit possible for the converted voice and facial expressions to be highly\ncorrelated and for the generated target speaker to appear and sound natural. It\nuses three neural networks: a conversion network that fuses and transforms the\nfacial and acoustic features, a waveform generation network that produces the\nwaveform from both the converted facial and acoustic features, and an image\nreconstruction network that outputs an RGB facial image also based on both the\nconverted features. The results of experiments using an emotional audiovisual\ndatabase showed that the proposed method achieved significantly higher\nnaturalness compared with one that separately transformed acoustic and facial\nfeatures.\n", "versions": [{"version": "v1", "created": "Mon, 29 Oct 2018 15:20:32 GMT"}, {"version": "v2", "created": "Sat, 1 Dec 2018 15:36:52 GMT"}], "update_date": "2018-12-04", "authors_parsed": [["Fang", "Fuming", ""], ["Wang", "Xin", ""], ["Yamagishi", "Junichi", ""], ["Echizen", "Isao", ""]]}, {"id": "1810.12735", "submitter": "Alice Coucke", "authors": "Alaa Saade, Alice Coucke, Alexandre Caulier, Joseph Dureau, Adrien\n  Ball, Th\\'eodore Bluche, David Leroy, Cl\\'ement Doumouro, Thibault\n  Gisselbrecht, Francesco Caltagirone, Thibaut Lavril, Ma\\\"el Primet", "title": "Spoken Language Understanding on the Edge", "comments": "arXiv admin note: text overlap with arXiv:1805.10190", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG cs.SD eess.AS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the problem of performing Spoken Language Understanding (SLU) on\nsmall devices typical of IoT applications. Our contributions are twofold.\nFirst, we outline the design of an embedded, private-by-design SLU system and\nshow that it has performance on par with cloud-based commercial solutions.\nSecond, we release the datasets used in our experiments in the interest of\nreproducibility and in the hope that they can prove useful to the SLU\ncommunity.\n", "versions": [{"version": "v1", "created": "Tue, 30 Oct 2018 13:49:37 GMT"}, {"version": "v2", "created": "Wed, 2 Oct 2019 15:03:22 GMT"}], "update_date": "2019-10-04", "authors_parsed": [["Saade", "Alaa", ""], ["Coucke", "Alice", ""], ["Caulier", "Alexandre", ""], ["Dureau", "Joseph", ""], ["Ball", "Adrien", ""], ["Bluche", "Th\u00e9odore", ""], ["Leroy", "David", ""], ["Doumouro", "Cl\u00e9ment", ""], ["Gisselbrecht", "Thibault", ""], ["Caltagirone", "Francesco", ""], ["Lavril", "Thibaut", ""], ["Primet", "Ma\u00ebl", ""]]}, {"id": "1810.12743", "submitter": "Loc Tran H", "authors": "Loc Hoang Tran, Trang Hoang, Bui Hoang Nam Huynh", "title": "Hypergraph based semi-supervised learning algorithms applied to speech\n  recognition problem: a novel approach", "comments": "11 pages, 1 figure, 2 tables. arXiv admin note: substantial text\n  overlap with arXiv:1212.0388", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG cs.SD eess.AS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Most network-based speech recognition methods are based on the assumption\nthat the labels of two adjacent speech samples in the network are likely to be\nthe same. However, assuming the pairwise relationship between speech samples is\nnot complete. The information a group of speech samples that show very similar\npatterns and tend to have similar labels is missed. The natural way overcoming\nthe information loss of the above assumption is to represent the feature data\nof speech samples as the hypergraph. Thus, in this paper, the three\nun-normalized, random walk, and symmetric normalized hypergraph Laplacian based\nsemi-supervised learning methods applied to hypergraph constructed from the\nfeature data of speech samples in order to predict the labels of speech samples\nare introduced. Experiment results show that the sensitivity performance\nmeasures of these three hypergraph Laplacian based semi-supervised learning\nmethods are greater than the sensitivity performance measures of the Hidden\nMarkov Model method (the current state of the art method applied to speech\nrecognition problem) and graph based semi-supervised learning methods (i.e. the\ncurrent state of the art network-based method for classification problems)\napplied to network created from the feature data of speech samples.\n", "versions": [{"version": "v1", "created": "Sun, 28 Oct 2018 13:37:14 GMT"}], "update_date": "2018-10-31", "authors_parsed": [["Tran", "Loc Hoang", ""], ["Hoang", "Trang", ""], ["Huynh", "Bui Hoang Nam", ""]]}, {"id": "1810.12744", "submitter": "Thomas Niesler", "authors": "Lerato Lerato and Thomas Niesler", "title": "Cluster Size Management in Multi-Stage Agglomerative Hierarchical\n  Clustering of Acoustic Speech Segments", "comments": "12 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Agglomerative hierarchical clustering (AHC) requires only the similarity\nbetween objects to be known. This is attractive when clustering signals of\nvarying length, such as speech, which are not readily represented in\nfixed-dimensional vector space. However, AHC is characterised by $O(N^2)$ space\nand time complexity, making it infeasible for partitioning large datasets. This\nhas recently been addressed by an approach based on the iterative re-clustering\nof independent subsets of the larger dataset. We show that, due to its\niterative nature, this procedure can sometimes lead to unchecked growth of\nindividual subsets, thereby compromising its effectiveness. We propose the\nintegration of a simple space management strategy into the iterative process,\nand show experimentally that this leads to no loss in performance in terms of\nF-measure while guaranteeing that a threshold space complexity is not breached.\n", "versions": [{"version": "v1", "created": "Tue, 30 Oct 2018 14:00:59 GMT"}], "update_date": "2018-10-31", "authors_parsed": [["Lerato", "Lerato", ""], ["Niesler", "Thomas", ""]]}, {"id": "1810.12750", "submitter": "Vincent Dutordoir", "authors": "Vincent Dutordoir, Hugh Salimbeni, Marc Deisenroth, James Hensman", "title": "Gaussian Process Conditional Density Estimation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Conditional Density Estimation (CDE) models deal with estimating conditional\ndistributions. The conditions imposed on the distribution are the inputs of the\nmodel. CDE is a challenging task as there is a fundamental trade-off between\nmodel complexity, representational capacity and overfitting. In this work, we\npropose to extend the model's input with latent variables and use Gaussian\nprocesses (GP) to map this augmented input onto samples from the conditional\ndistribution. Our Bayesian approach allows for the modeling of small datasets,\nbut we also provide the machinery for it to be applied to big data using\nstochastic variational inference. Our approach can be used to model densities\neven in sparse data regions, and allows for sharing learned structure between\nconditions. We illustrate the effectiveness and wide-reaching applicability of\nour model on a variety of real-world problems, such as spatio-temporal density\nestimation of taxi drop-offs, non-Gaussian noise modeling, and few-shot\nlearning on omniglot images.\n", "versions": [{"version": "v1", "created": "Tue, 30 Oct 2018 14:05:54 GMT"}], "update_date": "2018-10-31", "authors_parsed": [["Dutordoir", "Vincent", ""], ["Salimbeni", "Hugh", ""], ["Deisenroth", "Marc", ""], ["Hensman", "James", ""]]}, {"id": "1810.12751", "submitter": "Yuqi Yu", "authors": "Yuqi Yu, Hanbing Yan, Hongchao Guan and Hao Zhou", "title": "DeepHTTP: Semantics-Structure Model with Attention for Anomalous HTTP\n  Traffic Detection and Pattern Mining", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In the Internet age, cyber-attacks occur frequently with complex types.\nTraffic generated by access activities can record website status and user\nrequest information, which brings a great opportunity for network attack\ndetection. Among diverse network protocols, Hypertext Transfer Protocol (HTTP)\nis widely used in government, organizations and enterprises. In this work, we\npropose DeepHTTP, a semantics structure integration model utilizing\nBidirectional Long Short-Term Memory (Bi-LSTM) with attention mechanism to\nmodel HTTP traffic as a natural language sequence. In addition to extracting\ntraffic content information, we integrate structural information to enhance the\ngeneralization capabilities of the model. Moreover, the application of\nattention mechanism can assist in discovering critical parts of anomalous\ntraffic and further mining attack patterns. Additionally, we demonstrate how to\nincrementally update the data set and retrain model so that it can be adapted\nto new anomalous traffic. Extensive experimental evaluations over large traffic\ndata have illustrated that DeepHTTP has outstanding performance in traffic\ndetection and pattern discovery.\n", "versions": [{"version": "v1", "created": "Tue, 30 Oct 2018 14:07:48 GMT"}], "update_date": "2018-11-01", "authors_parsed": [["Yu", "Yuqi", ""], ["Yan", "Hanbing", ""], ["Guan", "Hongchao", ""], ["Zhou", "Hao", ""]]}, {"id": "1810.12752", "submitter": "Guoqiang Zhong", "authors": "Guoqiang Zhong, Xin Lin, Kang Chen, Qingyang Li, and Kaizhu Huang", "title": "Long Short-Term Attention", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CL cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Attention is an important cognition process of humans, which helps humans\nconcentrate on critical information during their perception and learning.\nHowever, although many machine learning models can remember information of\ndata, they have no the attention mechanism. For example, the long short-term\nmemory (LSTM) network is able to remember sequential information, but it cannot\npay special attention to part of the sequences. In this paper, we present a\nnovel model called long short-term attention (LSTA), which seamlessly\nintegrates the attention mechanism into the inner cell of LSTM. More than\nprocessing long short term dependencies, LSTA can focus on important\ninformation of the sequences with the attention mechanism. Extensive\nexperiments demonstrate that LSTA outperforms LSTM and related models on the\nsequence learning tasks.\n", "versions": [{"version": "v1", "created": "Tue, 30 Oct 2018 14:08:30 GMT"}, {"version": "v2", "created": "Thu, 5 Sep 2019 02:44:15 GMT"}], "update_date": "2019-09-06", "authors_parsed": [["Zhong", "Guoqiang", ""], ["Lin", "Xin", ""], ["Chen", "Kang", ""], ["Li", "Qingyang", ""], ["Huang", "Kaizhu", ""]]}, {"id": "1810.12754", "submitter": "Guoqiang Zhong", "authors": "Guoqiang Zhong, Guohua Yue and Xiao Ling", "title": "Recurrent Attention Unit", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CL cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recurrent Neural Network (RNN) has been successfully applied in many sequence\nlearning problems. Such as handwriting recognition, image description, natural\nlanguage processing and video motion analysis. After years of development,\nresearchers have improved the internal structure of the RNN and introduced many\nvariants. Among others, Gated Recurrent Unit (GRU) is one of the most widely\nused RNN model. However, GRU lacks the capability of adaptively paying\nattention to certain regions or locations, so that it may cause information\nredundancy or loss during leaning. In this paper, we propose a RNN model,\ncalled Recurrent Attention Unit (RAU), which seamlessly integrates the\nattention mechanism into the interior of GRU by adding an attention gate. The\nattention gate can enhance GRU's ability to remember long-term memory and help\nmemory cells quickly discard unimportant content. RAU is capable of extracting\ninformation from the sequential data by adaptively selecting a sequence of\nregions or locations and pay more attention to the selected regions during\nlearning. Extensive experiments on image classification, sentiment\nclassification and language modeling show that RAU consistently outperforms GRU\nand other baseline methods.\n", "versions": [{"version": "v1", "created": "Tue, 30 Oct 2018 14:09:19 GMT"}], "update_date": "2018-11-01", "authors_parsed": [["Zhong", "Guoqiang", ""], ["Yue", "Guohua", ""], ["Ling", "Xiao", ""]]}, {"id": "1810.12757", "submitter": "Gil Keren", "authors": "Gil Keren, Jing Han, Bj\\\"orn Schuller", "title": "Scaling Speech Enhancement in Unseen Environments with Noise Embeddings", "comments": null, "journal-ref": "The Fifth CHiME Challenge Workshop, 2018", "doi": null, "report-no": null, "categories": "eess.AS cs.LG cs.SD stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We address the problem of speech enhancement generalisation to unseen\nenvironments by performing two manipulations. First, we embed an additional\nrecording from the environment alone, and use this embedding to alter\nactivations in the main enhancement subnetwork. Second, we scale the number of\nnoise environments present at training time to 16,784 different environments.\nExperiment results show that both manipulations reduce word error rates of a\npretrained speech recognition system and improve enhancement quality according\nto a number of performance measures. Specifically, our best model reduces the\nword error rate from 34.04% on noisy speech to 15.46% on the enhanced speech.\nEnhanced audio samples can be found in\nhttps://speechenhancement.page.link/samples.\n", "versions": [{"version": "v1", "created": "Fri, 26 Oct 2018 13:05:54 GMT"}], "update_date": "2018-10-31", "authors_parsed": [["Keren", "Gil", ""], ["Han", "Jing", ""], ["Schuller", "Bj\u00f6rn", ""]]}, {"id": "1810.12758", "submitter": "Cheng Qian", "authors": "Cheng Qian, Nicholas D. Sidiropoulos, Magda Amiridi, Amin Emad", "title": "From Gene Expression to Drug Response: A Collaborative Filtering\n  Approach", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.QM cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Predicting the response of cancer cells to drugs is an important problem in\npharmacogenomics. Recent efforts in generation of large scale datasets\nprofiling gene expression and drug sensitivity in cell lines have provided a\nunique opportunity to study this problem. However, one major challenge is the\nsmall number of samples (cell lines) compared to the number of features (genes)\neven in these large datasets. We propose a collaborative filtering (CF) like\nalgorithm for modeling gene-drug relationship to identify patients most likely\nto benefit from a treatment. Due to the correlation of gene expressions in\ndifferent cell lines, the gene expression matrix is approximately low-rank,\nwhich suggests that drug responses could be estimated from a reduced dimension\nlatent space of the gene expression. Towards this end, we propose a joint\nlow-rank matrix factorization and latent linear regression approach.\nExperiments with data from the Genomics of Drug Sensitivity in Cancer database\nare included to show that the proposed method can predict drug-gene\nassociations better than the state-of-the-art methods.\n", "versions": [{"version": "v1", "created": "Mon, 29 Oct 2018 13:25:35 GMT"}, {"version": "v2", "created": "Wed, 31 Oct 2018 03:05:47 GMT"}], "update_date": "2018-11-01", "authors_parsed": [["Qian", "Cheng", ""], ["Sidiropoulos", "Nicholas D.", ""], ["Amiridi", "Magda", ""], ["Emad", "Amin", ""]]}, {"id": "1810.12770", "submitter": "Supriyo Mandal", "authors": "Supriyo Mandal and Abyayananda Maiti", "title": "Explicit Feedbacks Meet with Implicit Feedbacks : A Combined Approach\n  for Recommendation System", "comments": "12 pages. Accepted in Complex Networks, 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recommender systems recommend items more accurately by analyzing users'\npotential interest on different brands' items. In conjunction with users'\nrating similarity, the presence of users' implicit feedbacks like clicking\nitems, viewing items specifications, watching videos etc. have been proved to\nbe helpful for learning users' embedding, that helps better rating prediction\nof users. Most existing recommender systems focus on modeling of ratings and\nimplicit feedbacks ignoring users' explicit feedbacks. Explicit feedbacks can\nbe used to validate the reliability of the particular users and can be used to\nlearn about the users' characteristic. Users' characteristic mean what type of\nreviewers they are. In this paper, we explore three different models for\nrecommendation with more accuracy focusing on users' explicit feedbacks and\nimplicit feedbacks. First one is RHC-PMF that predicts users' rating more\naccurately based on user's three explicit feedbacks (rating, helpfulness score\nand centrality) and second one is RV-PMF, where user's implicit feedback (view\nrelationship) is considered. Last one is RHCV-PMF, where both type of feedbacks\nare considered. In this model users' explicit feedbacks' similarity indicate\nthe similarity of their reliability and characteristic and implicit feedback's\nsimilarity indicates their preference similarity. Extensive experiments on real\nworld dataset, i.e. Amazon.com online review dataset shows that our models\nperform better compare to base-line models in term of users' rating prediction.\nRHCV-PMF model also performs better rating prediction compare to baseline\nmodels for cold start users and cold start items.\n", "versions": [{"version": "v1", "created": "Mon, 29 Oct 2018 06:03:29 GMT"}], "update_date": "2018-10-31", "authors_parsed": [["Mandal", "Supriyo", ""], ["Maiti", "Abyayananda", ""]]}, {"id": "1810.12778", "submitter": "Dong Li", "authors": "Dong Li, Dongbin Zhao, Qichao Zhang, Yaran Chen", "title": "Reinforcement Learning and Deep Learning based Lateral Control for\n  Autonomous Driving", "comments": "14 pages, 12 figures, accepted to IEEE Computational Intelligence\n  Magazine", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper investigates the vision-based autonomous driving with deep\nlearning and reinforcement learning methods. Different from the end-to-end\nlearning method, our method breaks the vision-based lateral control system down\ninto a perception module and a control module. The perception module which is\nbased on a multi-task learning neural network first takes a driver-view image\nas its input and predicts the track features. The control module which is based\non reinforcement learning then makes a control decision based on these\nfeatures. In order to improve the data efficiency, we propose visual TORCS\n(VTORCS), a deep reinforcement learning environment which is based on the open\nracing car simulator (TORCS). By means of the provided functions, one can train\nan agent with the input of an image or various physical sensor measurement, or\nevaluate the perception algorithm on this simulator. The trained reinforcement\nlearning controller outperforms the linear quadratic regulator (LQR) controller\nand model predictive control (MPC) controller on different tracks. The\nexperiments demonstrate that the perception module shows promising performance\nand the controller is capable of controlling the vehicle drive well along the\ntrack center with visual input.\n", "versions": [{"version": "v1", "created": "Tue, 30 Oct 2018 14:43:36 GMT"}], "update_date": "2018-10-31", "authors_parsed": [["Li", "Dong", ""], ["Zhao", "Dongbin", ""], ["Zhang", "Qichao", ""], ["Chen", "Yaran", ""]]}, {"id": "1810.12780", "submitter": "Di Jin", "authors": "Di Jin, Peter Szolovits", "title": "Advancing PICO Element Detection in Biomedical Text via Deep Neural\n  Networks", "comments": "Machine Learning for Health (ML4H) at NeurIPS 2019 - Extended\n  Abstract", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In evidence-based medicine (EBM), defining a clinical question in terms of\nthe specific patient problem aids the physicians to efficiently identify\nappropriate resources and search for the best available evidence for medical\ntreatment. In order to formulate a well-defined, focused clinical question, a\nframework called PICO is widely used, which identifies the sentences in a given\nmedical text that belong to the four components typically reported in clinical\ntrials: Participants/Problem (P), Intervention (I), Comparison (C) and Outcome\n(O). In this work, we propose a novel deep learning model for recognizing PICO\nelements in biomedical abstracts. Based on the previous state-of-the-art\nbidirectional long-short term memory (biLSTM) plus conditional random field\n(CRF) architecture, we add another layer of biLSTM upon the sentence\nrepresentation vectors so that the contextual information from surrounding\nsentences can be gathered to help infer the interpretation of the current one.\nIn addition, we propose two methods to further generalize and improve the\nmodel: adversarial training and unsupervised pre-training over large corpora.\nWe tested our proposed approach over two benchmark datasets. One is the\nPubMed-PICO dataset, where our best results outperform the previous best by\n5.5%, 7.9%, and 5.8% for P, I, and O elements in terms of F1 score,\nrespectively. And for the other dataset named NICTA-PIBOSO, the improvements\nfor P/I/O elements are 2.4%, 13.6%, and 1.0% in F1 score, respectively.\nOverall, our proposed deep learning model can obtain unprecedented PICO element\ndetection accuracy while avoiding the need for any manual feature selection.\n", "versions": [{"version": "v1", "created": "Tue, 30 Oct 2018 14:44:24 GMT"}, {"version": "v2", "created": "Thu, 29 Nov 2018 02:38:02 GMT"}, {"version": "v3", "created": "Sat, 5 Oct 2019 17:26:41 GMT"}, {"version": "v4", "created": "Sun, 10 Nov 2019 07:57:16 GMT"}], "update_date": "2019-11-12", "authors_parsed": [["Jin", "Di", ""], ["Szolovits", "Peter", ""]]}, {"id": "1810.12782", "submitter": "Hao Zhou", "authors": "Hao Zhou, Ke Chen", "title": "Transferable Positive/Negative Speech Emotion Recognition via Class-wise\n  Adversarial Domain Adaptation", "comments": "5 pages, 3 figures, accepted to ICASSP 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Speech emotion recognition plays an important role in building more\nintelligent and human-like agents. Due to the difficulty of collecting speech\nemotional data, an increasingly popular solution is leveraging a related and\nrich source corpus to help address the target corpus. However, domain shift\nbetween the corpora poses a serious challenge, making domain shift adaptation\ndifficult to function even on the recognition of positive/negative emotions. In\nthis work, we propose class-wise adversarial domain adaptation to address this\nchallenge by reducing the shift for all classes between different corpora.\nExperiments on the well-known corpora EMODB and Aibo demonstrate that our\nmethod is effective even when only a very limited number of target labeled\nexamples are provided.\n", "versions": [{"version": "v1", "created": "Tue, 30 Oct 2018 14:47:51 GMT"}, {"version": "v2", "created": "Thu, 14 Feb 2019 11:55:23 GMT"}], "update_date": "2019-02-15", "authors_parsed": [["Zhou", "Hao", ""], ["Chen", "Ke", ""]]}, {"id": "1810.12794", "submitter": "Tomohiro Nishiyama", "authors": "Tomohiro Nishiyama", "title": "Divergence Network: Graphical calculation method of divergence functions", "comments": "17 pages, 22 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.IT math.IT math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we introduce directed networks called `divergence network' in\norder to perform graphical calculation of divergence functions. By using the\ndivergence networks, we can easily understand the geometric meaning of\ncalculation results and grasp relations among divergence functions intuitively.\n", "versions": [{"version": "v1", "created": "Tue, 30 Oct 2018 17:02:55 GMT"}, {"version": "v2", "created": "Thu, 1 Nov 2018 13:18:18 GMT"}], "update_date": "2018-11-02", "authors_parsed": [["Nishiyama", "Tomohiro", ""]]}, {"id": "1810.12805", "submitter": "Tristan Milne", "authors": "Tristan Milne", "title": "Piecewise Strong Convexity of Neural Networks", "comments": "16 pages, 2 figures. NeurIPS2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the loss surface of a feed-forward neural network with ReLU\nnon-linearities, regularized with weight decay. We show that the regularized\nloss function is piecewise strongly convex on an important open set which\ncontains, under some conditions, all of its global minimizers. This is used to\nprove that local minima of the regularized loss function in this set are\nisolated, and that every differentiable critical point in this set is a local\nminimum, partially addressing an open problem given at the Conference on\nLearning Theory (COLT) 2015; our result is also applied to linear neural\nnetworks to show that with weight decay regularization, there are no non-zero\ncritical points in a norm ball obtaining training error below a given\nthreshold. We also include an experimental section where we validate our\ntheoretical work and show that the regularized loss function is almost always\npiecewise strongly convex when restricted to stochastic gradient descent\ntrajectories for three standard image classification problems.\n", "versions": [{"version": "v1", "created": "Tue, 30 Oct 2018 15:17:56 GMT"}, {"version": "v2", "created": "Mon, 27 May 2019 01:27:52 GMT"}, {"version": "v3", "created": "Mon, 9 Dec 2019 18:22:39 GMT"}], "update_date": "2019-12-10", "authors_parsed": [["Milne", "Tristan", ""]]}, {"id": "1810.12823", "submitter": "Dongsoo Lee", "authors": "Dongsoo Lee, Parichay Kapoor, Byeongwook Kim", "title": "DeepTwist: Learning Model Compression via Occasional Weight Distortion", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Model compression has been introduced to reduce the required hardware\nresources while maintaining the model accuracy. Lots of techniques for model\ncompression, such as pruning, quantization, and low-rank approximation, have\nbeen suggested along with different inference implementation characteristics.\nAdopting model compression is, however, still challenging because the design\ncomplexity of model compression is rapidly increasing due to additional\nhyper-parameters and computation overhead in order to achieve a high\ncompression ratio. In this paper, we propose a simple and efficient model\ncompression framework called DeepTwist which distorts weights in an occasional\nmanner without modifying the underlying training algorithms. The ideas of\ndesigning weight distortion functions are intuitive and straightforward given\nformats of compressed weights. We show that our proposed framework improves\ncompression rate significantly for pruning, quantization, and low-rank\napproximation techniques while the efforts of additional retraining and/or\nhyper-parameter search are highly reduced. Regularization effects of DeepTwist\nare also reported.\n", "versions": [{"version": "v1", "created": "Tue, 30 Oct 2018 15:48:30 GMT"}], "update_date": "2018-10-31", "authors_parsed": [["Lee", "Dongsoo", ""], ["Kapoor", "Parichay", ""], ["Kim", "Byeongwook", ""]]}, {"id": "1810.12856", "submitter": "Alex Sun", "authors": "Alexander Y. Sun", "title": "Discovering state-parameter mappings in subsurface models using\n  generative adversarial networks", "comments": null, "journal-ref": null, "doi": "10.1029/2018GL080404", "report-no": null, "categories": "physics.data-an cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A fundamental problem in geophysical modeling is related to the\nidentification and approximation of causal structures among physical processes.\nHowever, resolving the bidirectional mappings between physical parameters and\nmodel state variables (i.e., solving the forward and inverse problems) is\nchallenging, especially when parameter dimensionality is high. Deep learning\nhas opened a new door toward knowledge representation and complex pattern\nidentification. In particular, the recently introduced generative adversarial\nnetworks (GANs) hold strong promises in learning cross-domain mappings for\nimage translation. This study presents a state-parameter identification GAN\n(SPID-GAN) for simultaneously learning bidirectional mappings between a\nhigh-dimensional parameter space and the corresponding model state space.\nSPID-GAN is demonstrated using a series of representative problems from\nsubsurface flow modeling. Results show that SPID-GAN achieves satisfactory\nperformance in identifying the bidirectional state-parameter mappings,\nproviding a new deep-learning-based, knowledge representation paradigm for a\nwide array of complex geophysical problems.\n", "versions": [{"version": "v1", "created": "Tue, 30 Oct 2018 16:55:37 GMT"}], "update_date": "2018-10-31", "authors_parsed": [["Sun", "Alexander Y.", ""]]}, {"id": "1810.12881", "submitter": "Mingjie Sun", "authors": "Mingjie Sun, Jian Tang, Huichen Li, Bo Li, Chaowei Xiao, Yao Chen,\n  Dawn Song", "title": "Data Poisoning Attack against Unsupervised Node Embedding Methods", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR cs.SI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Unsupervised node embedding methods (e.g., DeepWalk, LINE, and node2vec) have\nattracted growing interests given their simplicity and effectiveness. However,\nalthough these methods have been proved effective in a variety of applications,\nnone of the existing work has analyzed the robustness of them. This could be\nvery risky if these methods are attacked by an adversarial party. In this\npaper, we take the task of link prediction as an example, which is one of the\nmost fundamental problems for graph analysis, and introduce a data positioning\nattack to node embedding methods. We give a complete characterization of\nattacker's utilities and present efficient solutions to adversarial attacks for\ntwo popular node embedding methods: DeepWalk and LINE. We evaluate our proposed\nattack model on multiple real-world graphs. Experimental results show that our\nproposed model can significantly affect the results of link prediction by\nslightly changing the graph structures (e.g., adding or removing a few edges).\nWe also show that our proposed model is very general and can be transferable\nacross different embedding methods. Finally, we conduct a case study on a\ncoauthor network to better understand our attack method.\n", "versions": [{"version": "v1", "created": "Tue, 30 Oct 2018 17:25:30 GMT"}, {"version": "v2", "created": "Thu, 1 Nov 2018 04:09:57 GMT"}], "update_date": "2018-11-02", "authors_parsed": [["Sun", "Mingjie", ""], ["Tang", "Jian", ""], ["Li", "Huichen", ""], ["Li", "Bo", ""], ["Xiao", "Chaowei", ""], ["Chen", "Yao", ""], ["Song", "Dawn", ""]]}, {"id": "1810.12894", "submitter": "Yuri Burda", "authors": "Yuri Burda, Harrison Edwards, Amos Storkey, Oleg Klimov", "title": "Exploration by Random Network Distillation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce an exploration bonus for deep reinforcement learning methods\nthat is easy to implement and adds minimal overhead to the computation\nperformed. The bonus is the error of a neural network predicting features of\nthe observations given by a fixed randomly initialized neural network. We also\nintroduce a method to flexibly combine intrinsic and extrinsic rewards. We find\nthat the random network distillation (RND) bonus combined with this increased\nflexibility enables significant progress on several hard exploration Atari\ngames. In particular we establish state of the art performance on Montezuma's\nRevenge, a game famously difficult for deep reinforcement learning methods. To\nthe best of our knowledge, this is the first method that achieves better than\naverage human performance on this game without using demonstrations or having\naccess to the underlying state of the game, and occasionally completes the\nfirst level.\n", "versions": [{"version": "v1", "created": "Tue, 30 Oct 2018 17:44:42 GMT"}], "update_date": "2018-10-31", "authors_parsed": [["Burda", "Yuri", ""], ["Edwards", "Harrison", ""], ["Storkey", "Amos", ""], ["Klimov", "Oleg", ""]]}, {"id": "1810.12897", "submitter": "Sumit Bhatia", "authors": "Sumit Bhatia and Deepak P", "title": "Topic-Specific Sentiment Analysis Can Help Identify Political Ideology", "comments": "Presented at EMNLP Workshop on Computational Approaches to\n  Subjectivity, Sentiment & Social Media Analysis, 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.IR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Ideological leanings of an individual can often be gauged by the sentiment\none expresses about different issues. We propose a simple framework that\nrepresents a political ideology as a distribution of sentiment polarities\ntowards a set of topics. This representation can then be used to detect\nideological leanings of documents (speeches, news articles, etc.) based on the\nsentiments expressed towards different topics. Experiments performed using a\nwidely used dataset show the promise of our proposed approach that achieves\ncomparable performance to other methods despite being much simpler and more\ninterpretable.\n", "versions": [{"version": "v1", "created": "Tue, 30 Oct 2018 17:49:46 GMT"}], "update_date": "2018-10-31", "authors_parsed": [["Bhatia", "Sumit", ""], ["P", "Deepak", ""]]}, {"id": "1810.12910", "submitter": "Muhammad Abdullah Hanif", "authors": "Muhammad Abdullah Hanif, Rachmad Vidya Wicaksana Putra, Muhammad\n  Tanvir, Rehan Hafiz, Semeen Rehman, Muhammad Shafique", "title": "MPNA: A Massively-Parallel Neural Array Accelerator with Dataflow\n  Optimization for Convolutional Neural Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.AR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The state-of-the-art accelerators for Convolutional Neural Networks (CNNs)\ntypically focus on accelerating only the convolutional layers, but do not\nprioritize the fully-connected layers much. Hence, they lack a synergistic\noptimization of the hardware architecture and diverse dataflows for the\ncomplete CNN design, which can provide a higher potential for\nperformance/energy efficiency. Towards this, we propose a novel\nMassively-Parallel Neural Array (MPNA) accelerator that integrates two\nheterogeneous systolic arrays and respective highly-optimized dataflow patterns\nto jointly accelerate both the convolutional (CONV) and the fully-connected\n(FC) layers. Besides fully-exploiting the available off-chip memory bandwidth,\nthese optimized dataflows enable high data-reuse of all the data types (i.e.,\nweights, input and output activations), and thereby enable our MPNA to achieve\nhigh energy savings. We synthesized our MPNA architecture using the ASIC design\nflow for a 28nm technology, and performed functional and timing validation\nusing multiple real-world complex CNNs. MPNA achieves 149.7GOPS/W at 280MHz and\nconsumes 239mW. Experimental results show that our MPNA architecture provides\n1.7x overall performance improvement compared to state-of-the-art accelerator,\nand 51% energy saving compared to the baseline architecture.\n", "versions": [{"version": "v1", "created": "Tue, 30 Oct 2018 17:20:24 GMT"}], "update_date": "2018-11-01", "authors_parsed": [["Hanif", "Muhammad Abdullah", ""], ["Putra", "Rachmad Vidya Wicaksana", ""], ["Tanvir", "Muhammad", ""], ["Hafiz", "Rehan", ""], ["Rehman", "Semeen", ""], ["Shafique", "Muhammad", ""]]}, {"id": "1810.12997", "submitter": "Andreas B\\\"armann", "authors": "Andreas B\\\"armann and Alexander Martin and Sebastian Pokutta and Oskar\n  Schneider", "title": "An Online-Learning Approach to Inverse Optimization", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.OC cs.AI cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we demonstrate how to learn the objective function of a\ndecision-maker while only observing the problem input data and the\ndecision-maker's corresponding decisions over multiple rounds. We present exact\nalgorithms for this online version of inverse optimization which converge at a\nrate of $ \\mathcal{O}(1/\\sqrt{T}) $ in the number of observations~$T$ and\ncompare their further properties. Especially, they all allow taking decisions\nwhich are essentially as good as those of the observed decision-maker already\nafter relatively few iterations, but are suited best for different settings\neach. Our approach is based on online learning and works for linear objectives\nover arbitrary feasible sets for which we have a linear optimization oracle. As\nsuch, it generalizes previous approaches based on KKT-system decomposition and\ndualization. We also introduce several generalizations, such as the approximate\nlearning of non-linear objective functions, dynamically changing as well as\nparameterized objectives and the case of suboptimal observed decisions. When\napplied to the stochastic offline case, our algorithms are able to give\nguarantees on the quality of the learned objectives in expectation. Finally, we\nshow the effectiveness and possible applications of our methods in indicative\ncomputational experiments.\n", "versions": [{"version": "v1", "created": "Tue, 30 Oct 2018 20:43:04 GMT"}, {"version": "v2", "created": "Sun, 29 Mar 2020 02:08:41 GMT"}], "update_date": "2020-03-31", "authors_parsed": [["B\u00e4rmann", "Andreas", ""], ["Martin", "Alexander", ""], ["Pokutta", "Sebastian", ""], ["Schneider", "Oskar", ""]]}, {"id": "1810.13024", "submitter": "Qiujia Li", "authors": "Qiujia Li, Preben Ness, Anton Ragni and Mark Gales", "title": "Bi-Directional Lattice Recurrent Neural Networks for Confidence\n  Estimation", "comments": "Accepted by ICASSP 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.AS cs.CL cs.LG cs.SD", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The standard approach to mitigate errors made by an automatic speech\nrecognition system is to use confidence scores associated with each predicted\nword. In the simplest case, these scores are word posterior probabilities\nwhilst more complex schemes utilise bi-directional recurrent neural network\n(BiRNN) models. A number of upstream and downstream applications, however, rely\non confidence scores assigned not only to 1-best hypotheses but to all words\nfound in confusion networks or lattices. These include but are not limited to\nspeaker adaptation, semi-supervised training and information retrieval.\nAlthough word posteriors could be used in those applications as confidence\nscores, they are known to have reliability issues. To make improved confidence\nscores more generally available, this paper shows how BiRNNs can be extended\nfrom 1-best sequences to confusion network and lattice structures. Experiments\nare conducted using one of the Cambridge University submissions to the IARPA\nOpenKWS 2016 competition. The results show that confusion network and\nlattice-based BiRNNs can provide a significant improvement in confidence\nestimation.\n", "versions": [{"version": "v1", "created": "Tue, 30 Oct 2018 22:39:02 GMT"}, {"version": "v2", "created": "Mon, 18 Feb 2019 17:04:05 GMT"}], "update_date": "2019-02-19", "authors_parsed": [["Li", "Qiujia", ""], ["Ness", "Preben", ""], ["Ragni", "Anton", ""], ["Gales", "Mark", ""]]}, {"id": "1810.13025", "submitter": "Qiujia Li", "authors": "Anton Ragni, Qiujia Li, Mark Gales and Yu Wang", "title": "Confidence Estimation and Deletion Prediction Using Bidirectional\n  Recurrent Neural Networks", "comments": "Accepted as a conference paper at 2018 IEEE Workshop on Spoken\n  Language Technology (SLT 2018)", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.AS cs.CL cs.LG cs.SD", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The standard approach to assess reliability of automatic speech\ntranscriptions is through the use of confidence scores. If accurate, these\nscores provide a flexible mechanism to flag transcription errors for upstream\nand downstream applications. One challenging type of errors that recognisers\nmake are deletions. These errors are not accounted for by the standard\nconfidence estimation schemes and are hard to rectify in the upstream and\ndownstream processing. High deletion rates are prominent in limited resource\nand highly mismatched training/testing conditions studied under IARPA Babel and\nMaterial programs. This paper looks at the use of bidirectional recurrent\nneural networks to yield confidence estimates in predicted as well as deleted\nwords. Several simple schemes are examined for combination. To assess\nusefulness of this approach, the combined confidence score is examined for\nuntranscribed data selection that favours transcriptions with lower deletion\nerrors. Experiments are conducted using IARPA Babel/Material program languages.\n", "versions": [{"version": "v1", "created": "Tue, 30 Oct 2018 22:39:54 GMT"}], "update_date": "2018-11-01", "authors_parsed": [["Ragni", "Anton", ""], ["Li", "Qiujia", ""], ["Gales", "Mark", ""], ["Wang", "Yu", ""]]}, {"id": "1810.13043", "submitter": "Lars Lorch", "authors": "Lars Lorch, Abir De, Samir Bhatt, William Trouleau, Utkarsh Upadhyay,\n  Manuel Gomez-Rodriguez", "title": "Stochastic Optimal Control of Epidemic Processes in Networks", "comments": "Machine Learning for Health (ML4H) Workshop at NeurIPS 2018\n  arXiv:1811.07216", "journal-ref": null, "doi": null, "report-no": "ML4H/2018/65", "categories": "math.OC cs.LG cs.SI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We approach the development of models and control strategies of\nsusceptible-infected-susceptible (SIS) epidemic processes from the perspective\nof marked temporal point processes and stochastic optimal control of stochastic\ndifferential equations (SDEs) with jumps. In contrast to previous work, this\nnovel perspective is particularly well-suited to make use of fine-grained data\nabout disease outbreaks and lets us overcome the shortcomings of current\ncontrol strategies. Our control strategy resorts to treatment intensities to\ndetermine who to treat and when to do so to minimize the amount of infected\nindividuals over time. Preliminary experiments with synthetic data show that\nour control strategy consistently outperforms several alternatives. Looking\ninto the future, we believe our methodology provides a promising step towards\nthe development of practical data-driven control strategies of epidemic\nprocesses.\n", "versions": [{"version": "v1", "created": "Tue, 30 Oct 2018 15:43:36 GMT"}, {"version": "v2", "created": "Fri, 23 Nov 2018 04:33:39 GMT"}, {"version": "v3", "created": "Wed, 28 Nov 2018 02:03:57 GMT"}, {"version": "v4", "created": "Fri, 30 Nov 2018 23:10:45 GMT"}], "update_date": "2018-12-04", "authors_parsed": [["Lorch", "Lars", ""], ["De", "Abir", ""], ["Bhatt", "Samir", ""], ["Trouleau", "William", ""], ["Upadhyay", "Utkarsh", ""], ["Gomez-Rodriguez", "Manuel", ""]]}, {"id": "1810.13044", "submitter": "Imtiaz Ziko", "authors": "Imtiaz Masud Ziko, Eric Granger and Ismail Ben Ayed", "title": "Scalable Laplacian K-modes", "comments": "13 pages, 11 figures. Accepted in NIPS 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We advocate Laplacian K-modes for joint clustering and density mode finding,\nand propose a concave-convex relaxation of the problem, which yields a parallel\nalgorithm that scales up to large datasets and high dimensions. We optimize a\ntight bound (auxiliary function) of our relaxation, which, at each iteration,\namounts to computing an independent update for each cluster-assignment\nvariable, with guaranteed convergence. Therefore, our bound optimizer can be\ntrivially distributed for large-scale data sets. Furthermore, we show that the\ndensity modes can be obtained as byproducts of the assignment variables via\nsimple maximum-value operations whose additional computational cost is linear\nin the number of data points. Our formulation does not need storing a full\naffinity matrix and computing its eigenvalue decomposition, neither does it\nperform expensive projection steps and Lagrangian-dual inner iterates for the\nsimplex constraints of each point. Furthermore, unlike mean-shift, our\ndensity-mode estimation does not require inner-loop gradient-ascent iterates.\nIt has a complexity independent of feature-space dimension, yields modes that\nare valid data points in the input set and is applicable to discrete domains as\nwell as arbitrary kernels. We report comprehensive experiments over various\ndata sets, which show that our algorithm yields very competitive performances\nin term of optimization quality (i.e., the value of the discrete-variable\nobjective at convergence) and clustering accuracy.\n", "versions": [{"version": "v1", "created": "Wed, 31 Oct 2018 00:01:31 GMT"}, {"version": "v2", "created": "Tue, 20 Nov 2018 19:30:18 GMT"}], "update_date": "2018-11-22", "authors_parsed": [["Ziko", "Imtiaz Masud", ""], ["Granger", "Eric", ""], ["Ayed", "Ismail Ben", ""]]}, {"id": "1810.13069", "submitter": "Yining Wang", "authors": "Xi Chen, Yining Wang, Yuan Zhou", "title": "Dynamic Assortment Optimization with Changing Contextual Information", "comments": "4 pages, 4 figures. Minor revision and polishing of presentation", "journal-ref": null, "doi": null, "report-no": null, "categories": "econ.EM cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we study the dynamic assortment optimization problem under a\nfinite selling season of length $T$. At each time period, the seller offers an\narriving customer an assortment of substitutable products under a cardinality\nconstraint, and the customer makes the purchase among offered products\naccording to a discrete choice model. Most existing work associates each\nproduct with a real-valued fixed mean utility and assumes a multinomial logit\nchoice (MNL) model. In many practical applications, feature/contexutal\ninformation of products is readily available. In this paper, we incorporate the\nfeature information by assuming a linear relationship between the mean utility\nand the feature. In addition, we allow the feature information of products to\nchange over time so that the underlying choice model can also be\nnon-stationary. To solve the dynamic assortment optimization under this\nchanging contextual MNL model, we need to simultaneously learn the underlying\nunknown coefficient and makes the decision on the assortment. To this end, we\ndevelop an upper confidence bound (UCB) based policy and establish the regret\nbound on the order of $\\widetilde O(d\\sqrt{T})$, where $d$ is the dimension of\nthe feature and $\\widetilde O$ suppresses logarithmic dependence. We further\nestablished the lower bound $\\Omega(d\\sqrt{T}/K)$ where $K$ is the cardinality\nconstraint of an offered assortment, which is usually small. When $K$ is a\nconstant, our policy is optimal up to logarithmic factors. In the exploitation\nphase of the UCB algorithm, we need to solve a combinatorial optimization for\nassortment optimization based on the learned information. We further develop an\napproximation algorithm and an efficient greedy heuristic. The effectiveness of\nthe proposed policy is further demonstrated by our numerical studies.\n", "versions": [{"version": "v1", "created": "Wed, 31 Oct 2018 01:52:59 GMT"}, {"version": "v2", "created": "Fri, 18 Jan 2019 03:30:01 GMT"}], "update_date": "2019-01-21", "authors_parsed": [["Chen", "Xi", ""], ["Wang", "Yining", ""], ["Zhou", "Yuan", ""]]}, {"id": "1810.13084", "submitter": "Nicolas Loizou", "authors": "Nicolas Loizou, Michael Rabbat, Peter Richt\\'arik", "title": "Provably Accelerated Randomized Gossip Algorithms", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.OC cs.DC cs.LG cs.MA cs.SY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this work we present novel provably accelerated gossip algorithms for\nsolving the average consensus problem. The proposed protocols are inspired from\nthe recently developed accelerated variants of the randomized Kaczmarz method -\na popular method for solving linear systems. In each gossip iteration all nodes\nof the network update their values but only a pair of them exchange their\nprivate information. Numerical experiments on popular wireless sensor networks\nshowing the benefits of our protocols are also presented.\n", "versions": [{"version": "v1", "created": "Wed, 31 Oct 2018 02:59:02 GMT"}], "update_date": "2018-11-01", "authors_parsed": [["Loizou", "Nicolas", ""], ["Rabbat", "Michael", ""], ["Richt\u00e1rik", "Peter", ""]]}, {"id": "1810.13088", "submitter": "Yan Yin", "authors": "Yan Yin, Ramon Prieto, Bin Wang, Jianwei Zhou, Yiwei Gu, Yang Liu, Hui\n  Lin", "title": "Attention-based sequence-to-sequence model for speech recognition:\n  development of state-of-the-art system on LibriSpeech and its application to\n  non-native English", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG cs.SD eess.AS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent research has shown that attention-based sequence-to-sequence models\nsuch as Listen, Attend, and Spell (LAS) yield comparable results to\nstate-of-the-art ASR systems on various tasks. In this paper, we describe the\ndevelopment of such a system and demonstrate its performance on two tasks:\nfirst we achieve a new state-of-the-art word error rate of 3.43% on the test\nclean subset of LibriSpeech English data; second on non-native English speech,\nincluding both read speech and spontaneous speech, we obtain very competitive\nresults compared to a conventional system built with the most updated Kaldi\nrecipe.\n", "versions": [{"version": "v1", "created": "Wed, 31 Oct 2018 03:10:37 GMT"}, {"version": "v2", "created": "Mon, 5 Nov 2018 19:08:34 GMT"}], "update_date": "2018-11-07", "authors_parsed": [["Yin", "Yan", ""], ["Prieto", "Ramon", ""], ["Wang", "Bin", ""], ["Zhou", "Jianwei", ""], ["Gu", "Yiwei", ""], ["Liu", "Yang", ""], ["Lin", "Hui", ""]]}, {"id": "1810.13098", "submitter": "Chao Li", "authors": "Chao Li, Zhun Sun, Jinshi Yu, Ming Hou and Qibin Zhao", "title": "Low-Rank Embedding of Kernels in Convolutional Neural Networks under\n  Random Shuffling", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Although the convolutional neural networks (CNNs) have become popular for\nvarious image processing and computer vision task recently, it remains a\nchallenging problem to reduce the storage cost of the parameters for\nresource-limited platforms. In the previous studies, tensor decomposition (TD)\nhas achieved promising compression performance by embedding the kernel of a\nconvolutional layer into a low-rank subspace. However the employment of TD is\nnaively on the kernel or its specified variants. Unlike the conventional\napproaches, this paper shows that the kernel can be embedded into more general\nor even random low-rank subspaces. We demonstrate this by compressing the\nconvolutional layers via randomly-shuffled tensor decomposition (RsTD) for a\nstandard classification task using CIFAR-10. In addition, we analyze how the\nspatial similarity of the training data influences the low-rank structure of\nthe kernels. The experimental results show that the CNN can be significantly\ncompressed even if the kernels are randomly shuffled. Furthermore, the\nRsTD-based method yields more stable classification accuracy than the\nconventional TD-based methods in a large range of compression ratios.\n", "versions": [{"version": "v1", "created": "Wed, 31 Oct 2018 04:05:54 GMT"}], "update_date": "2018-11-01", "authors_parsed": [["Li", "Chao", ""], ["Sun", "Zhun", ""], ["Yu", "Jinshi", ""], ["Hou", "Ming", ""], ["Zhao", "Qibin", ""]]}, {"id": "1810.13103", "submitter": "Zhongdao Wang", "authors": "Zhongdao Wang, Liang Zheng, Shengjin Wang", "title": "Query Adaptive Late Fusion for Image Retrieval", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Feature fusion is a commonly used strategy in image retrieval tasks, which\naggregates the matching responses of multiple visual features. Feasible sets of\nfeatures can be either descriptors (SIFT, HSV) for an entire image or the same\ndescriptor for different local parts (face, body). Ideally, the to-be-fused\nheterogeneous features are pre-assumed to be discriminative and complementary\nto each other. However, the effectiveness of different features varies\ndramatically according to different queries. That is to say, for some queries,\na feature may be neither discriminative nor complementary to existing ones,\nwhile for other queries, the feature suffices. As a result, it is important to\nestimate the effectiveness of features in a query-adaptive manner. To this end,\nthis article proposes a new late fusion scheme at the score level. We base our\nmethod on the observation that the sorted score curves contain patterns that\ndescribe their effectiveness. For example, an \"L\"-shaped curve indicates that\nthe feature is discriminative while a gradually descending curve suggests a bad\nfeature. As such, this paper introduces a query-adaptive late fusion pipeline.\nIn the hand-crafted version, it can be an unsupervised approach to tasks like\nparticular object retrieval. In the learning version, it can also be applied to\nsupervised tasks like person recognition and pedestrian retrieval, based on a\ntrainable neural module. Extensive experiments are conducted on two object\nretrieval datasets and one person recognition dataset. We show that our method\nis able to highlight the good features and suppress the bad ones, is resilient\nto distractor features, and achieves very competitive retrieval accuracy\ncompared with the state of the art. In an additional person re-identification\ndataset, the application scope and limitation of the proposed method are\nstudied.\n", "versions": [{"version": "v1", "created": "Wed, 31 Oct 2018 04:51:16 GMT"}], "update_date": "2018-11-01", "authors_parsed": [["Wang", "Zhongdao", ""], ["Zheng", "Liang", ""], ["Wang", "Shengjin", ""]]}, {"id": "1810.13104", "submitter": "Ertu\\u{g} Karamatl{\\i}", "authors": "Ertu\\u{g} Karamatl{\\i}, Ali Taylan Cemgil, Serap K{\\i}rb{\\i}z", "title": "Audio Source Separation Using Variational Autoencoders and Weak Class\n  Supervision", "comments": "Accepted version", "journal-ref": "IEEE Signal Processing Letters 26 (2019) 1349-1353", "doi": "10.1109/LSP.2019.2929440", "report-no": null, "categories": "cs.SD cs.LG eess.AS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we propose a source separation method that is trained by\nobserving the mixtures and the class labels of the sources present in the\nmixture without any access to isolated sources. Since our method does not\nrequire source class labels for every time-frequency bin but only a single\nlabel for each source constituting the mixture signal, we call this scenario as\nweak class supervision. We associate a variational autoencoder (VAE) with each\nsource class within a non-negative (compositional) model. Each VAE provides a\nprior model to identify the signal from its associated class in a sound\nmixture. After training the model on mixtures, we obtain a generative model for\neach source class and demonstrate our method on one-second mixtures of\nutterances of digits from 0 to 9. We show that the separation performance\nobtained by source class supervision is as good as the performance obtained by\nsource signal supervision.\n", "versions": [{"version": "v1", "created": "Wed, 31 Oct 2018 04:52:42 GMT"}, {"version": "v2", "created": "Mon, 5 Nov 2018 09:15:41 GMT"}, {"version": "v3", "created": "Sun, 4 Aug 2019 14:09:15 GMT"}], "update_date": "2019-08-06", "authors_parsed": [["Karamatl\u0131", "Ertu\u011f", ""], ["Cemgil", "Ali Taylan", ""], ["K\u0131rb\u0131z", "Serap", ""]]}, {"id": "1810.13105", "submitter": "Jennifer Jang", "authors": "Jennifer Jang, Heinrich Jiang", "title": "DBSCAN++: Towards fast and scalable density clustering", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  DBSCAN is a classical density-based clustering procedure with tremendous\npractical relevance. However, DBSCAN implicitly needs to compute the empirical\ndensity for each sample point, leading to a quadratic worst-case time\ncomplexity, which is too slow on large datasets. We propose DBSCAN++, a simple\nmodification of DBSCAN which only requires computing the densities for a chosen\nsubset of points. We show empirically that, compared to traditional DBSCAN,\nDBSCAN++ can provide not only competitive performance but also added robustness\nin the bandwidth hyperparameter while taking a fraction of the runtime. We also\npresent statistical consistency guarantees showing the trade-off between\ncomputational cost and estimation rates. Surprisingly, up to a certain point,\nwe can enjoy the same estimation rates while lowering computational cost,\nshowing that DBSCAN++ is a sub-quadratic algorithm that attains minimax optimal\nrates for level-set estimation, a quality that may be of independent interest.\n", "versions": [{"version": "v1", "created": "Wed, 31 Oct 2018 04:52:46 GMT"}, {"version": "v2", "created": "Fri, 25 Jan 2019 14:54:17 GMT"}, {"version": "v3", "created": "Fri, 17 May 2019 18:14:00 GMT"}], "update_date": "2019-05-21", "authors_parsed": [["Jang", "Jennifer", ""], ["Jiang", "Heinrich", ""]]}, {"id": "1810.13107", "submitter": "Andros Tjandra", "authors": "Andros Tjandra, Sakriani Sakti, Satoshi Nakamura", "title": "End-to-End Feedback Loss in Speech Chain Framework via Straight-Through\n  Estimator", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG cs.SD eess.AS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The speech chain mechanism integrates automatic speech recognition (ASR) and\ntext-to-speech synthesis (TTS) modules into a single cycle during training. In\nour previous work, we applied a speech chain mechanism as a semi-supervised\nlearning. It provides the ability for ASR and TTS to assist each other when\nthey receive unpaired data and let them infer the missing pair and optimize the\nmodel with reconstruction loss. If we only have speech without transcription,\nASR generates the most likely transcription from the speech data, and then TTS\nuses the generated transcription to reconstruct the original speech features.\nHowever, in previous papers, we just limited our back-propagation to the\nclosest module, which is the TTS part. One reason is that back-propagating the\nerror through the ASR is challenging due to the output of the ASR are discrete\ntokens, creating non-differentiability between the TTS and ASR. In this paper,\nwe address this problem and describe how to thoroughly train a speech chain\nend-to-end for reconstruction loss using a straight-through estimator (ST).\nExperimental results revealed that, with sampling from ST-Gumbel-Softmax, we\nwere able to update ASR parameters and improve the ASR performances by 11\\%\nrelative CER reduction compared to the baseline.\n", "versions": [{"version": "v1", "created": "Wed, 31 Oct 2018 05:05:37 GMT"}], "update_date": "2018-11-01", "authors_parsed": [["Tjandra", "Andros", ""], ["Sakti", "Sakriani", ""], ["Nakamura", "Satoshi", ""]]}, {"id": "1810.13108", "submitter": "Andr\\'e Ricardo Belotto Da Silva", "authors": "Andr\\'e Belotto da Silva and Maxime Gazeau", "title": "A general system of differential equations to model first order adaptive\n  algorithms", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG math.CA math.DS math.OC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  First order optimization algorithms play a major role in large scale machine\nlearning. A new class of methods, called adaptive algorithms, were recently\nintroduced to adjust iteratively the learning rate for each coordinate. Despite\ngreat practical success in deep learning, their behavior and performance on\nmore general loss functions are not well understood. In this paper, we derive a\nnon-autonomous system of differential equations, which is the continuous time\nlimit of adaptive optimization methods. We prove global well-posedness of the\nsystem and we investigate the numerical time convergence of its forward Euler\napproximation. We study, furthermore, the convergence of its trajectories and\ngive conditions under which the differential system, underlying all adaptive\nalgorithms, is suitable for optimization. We discuss convergence to a critical\npoint in the non-convex case and give conditions for the dynamics to avoid\nsaddle points and local maxima. For convex and deterministic loss function, we\nintroduce a suitable Lyapunov functional which allow us to study its rate of\nconvergence. Several other properties of both the continuous and discrete\nsystems are briefly discussed. The differential system studied in the paper is\ngeneral enough to encompass many other classical algorithms (such as Heavy ball\nand Nesterov's accelerated method) and allow us to recover several known\nresults for these algorithms.\n", "versions": [{"version": "v1", "created": "Wed, 31 Oct 2018 05:12:11 GMT"}, {"version": "v2", "created": "Mon, 30 Sep 2019 14:21:22 GMT"}], "update_date": "2019-10-01", "authors_parsed": [["da Silva", "Andr\u00e9 Belotto", ""], ["Gazeau", "Maxime", ""]]}, {"id": "1810.13118", "submitter": "Cem Keskin", "authors": "Cem Keskin and Shahram Izadi", "title": "SplineNets: Continuous Neural Decision Graphs", "comments": "Accepted to NIPS 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present SplineNets, a practical and novel approach for using conditioning\nin convolutional neural networks (CNNs). SplineNets are continuous\ngeneralizations of neural decision graphs, and they can dramatically reduce\nruntime complexity and computation costs of CNNs, while maintaining or even\nincreasing accuracy. Functions of SplineNets are both dynamic (i.e.,\nconditioned on the input) and hierarchical (i.e., conditioned on the\ncomputational path). SplineNets employ a unified loss function with a desired\nlevel of smoothness over both the network and decision parameters, while\nallowing for sparse activation of a subset of nodes for individual samples. In\nparticular, we embed infinitely many function weights (e.g. filters) on smooth,\nlow dimensional manifolds parameterized by compact B-splines, which are indexed\nby a position parameter. Instead of sampling from a categorical distribution to\npick a branch, samples choose a continuous position to pick a function weight.\nWe further show that by maximizing the mutual information between spline\npositions and class labels, the network can be optimally utilized and\nspecialized for classification tasks. Experiments show that our approach can\nsignificantly increase the accuracy of ResNets with negligible cost in speed,\nmatching the precision of a 110 level ResNet with a 32 level SplineNet.\n", "versions": [{"version": "v1", "created": "Wed, 31 Oct 2018 06:20:24 GMT"}], "update_date": "2018-11-01", "authors_parsed": [["Keskin", "Cem", ""], ["Izadi", "Shahram", ""]]}, {"id": "1810.13135", "submitter": "Naima Chouikhi", "authors": "Naima Chouikhi and Adel M. Alimi", "title": "Adaptive Extreme Learning Machine for Recurrent Beta-basis Function\n  Neural Network Training", "comments": "14 pages and 5 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Beta Basis Function Neural Network (BBFNN) is a special kind of kernel basis\nneural networks. It is a feedforward network typified by the use of beta\nfunction as a hidden activation function. Beta is a flexible transfer function\nrepresenting richer forms than the common existing functions. As in every\nnetwork, the architecture setting as well as the learning method are two main\ngauntlets faced by BBFNN. In this paper, new architecture and training\nalgorithm are proposed for the BBFNN. An Extreme Learning Machine (ELM) is used\nas a training approach of BBFNN with the aim of quickening the training\nprocess. The peculiarity of ELM is permitting a certain decrement of the\ncomputing time and complexity regarding the already used BBFNN learning\nalgorithms such as backpropagation, OLS, etc. For the architectural design, a\nrecurrent structure is added to the common BBFNN architecture in order to make\nit more able to deal with complex, non linear and time varying problems.\nThroughout this paper, the conceived recurrent ELM-trained BBFNN is tested on a\nnumber of tasks related to time series prediction, classification and\nregression. Experimental results show noticeable achievements of the proposed\nnetwork compared to common feedforward and recurrent networks trained by ELM\nand using hyperbolic tangent as activation function. These achievements are in\nterms of accuracy and robustness against data breakdowns such as noise signals.\n", "versions": [{"version": "v1", "created": "Wed, 31 Oct 2018 07:31:08 GMT"}], "update_date": "2018-11-01", "authors_parsed": [["Chouikhi", "Naima", ""], ["Alimi", "Adel M.", ""]]}, {"id": "1810.13155", "submitter": "Guoqiang Zhong", "authors": "Guoqiang Zhong, Wencong Jiao and Wei Gao", "title": "Structure Learning of Deep Neural Networks with Q-Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recently, with convolutional neural networks gaining significant achievements\nin many challenging machine learning fields, hand-crafted neural networks no\nlonger satisfy our requirements as designing a network will cost a lot, and\nautomatically generating architectures has attracted increasingly more\nattention and focus. Some research on auto-generated networks has achieved\npromising results. However, they mainly aim at picking a series of single\nlayers such as convolution or pooling layers one by one. There are many elegant\nand creative designs in the carefully hand-crafted neural networks, such as\nInception-block in GoogLeNet, residual block in residual network and dense\nblock in dense convolutional network. Based on reinforcement learning and\ntaking advantages of the superiority of these networks, we propose a novel\nautomatic process to design a multi-block neural network, whose architecture\ncontains multiple types of blocks mentioned above, with the purpose to do\nstructure learning of deep neural networks and explore the possibility whether\ndifferent blocks can be composed together to form a well-behaved neural\nnetwork. The optimal network is created by the Q-learning agent who is trained\nto sequentially pick different types of blocks. To verify the validity of our\nproposed method, we use the auto-generated multi-block neural network to\nconduct experiments on image benchmark datasets MNIST, SVHN and CIFAR-10 image\nclassification task with restricted computational resources. The results\ndemonstrate that our method is very effective, achieving comparable or better\nperformance than hand-crafted networks and advanced auto-generated neural\nnetworks.\n", "versions": [{"version": "v1", "created": "Wed, 31 Oct 2018 08:39:22 GMT"}], "update_date": "2018-11-01", "authors_parsed": [["Zhong", "Guoqiang", ""], ["Jiao", "Wencong", ""], ["Gao", "Wei", ""]]}, {"id": "1810.13163", "submitter": "Peter Bloem", "authors": "Peter Bloem, Steven de Rooij", "title": "A tutorial on MDL hypothesis testing for graph analysis", "comments": "arXiv admin note: text overlap with arXiv:1701.02026", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  This document provides a tutorial description of the use of the MDL principle\nin complex graph analysis. We give a brief summary of the preliminary subjects,\nand describe the basic principle, using the example of analysing the size of\nthe largest clique in a graph. We also provide a discussion of how to interpret\nthe results of such an analysis, making note of several common pitfalls.\n", "versions": [{"version": "v1", "created": "Wed, 31 Oct 2018 08:58:15 GMT"}], "update_date": "2018-11-01", "authors_parsed": [["Bloem", "Peter", ""], ["de Rooij", "Steven", ""]]}, {"id": "1810.13166", "submitter": "Natalia D\\'iaz-Rodr\\'iguez", "authors": "Natalia D\\'iaz-Rodr\\'iguez and Vincenzo Lomonaco and David Filliat and\n  Davide Maltoni", "title": "Don't forget, there is more than forgetting: new metrics for Continual\n  Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.CV cs.LG cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Continual learning consists of algorithms that learn from a stream of\ndata/tasks continuously and adaptively thought time, enabling the incremental\ndevelopment of ever more complex knowledge and skills. The lack of consensus in\nevaluating continual learning algorithms and the almost exclusive focus on\nforgetting motivate us to propose a more comprehensive set of implementation\nindependent metrics accounting for several factors we believe have practical\nimplications worth considering in the deployment of real AI systems that learn\ncontinually: accuracy or performance over time, backward and forward knowledge\ntransfer, memory overhead as well as computational efficiency. Drawing\ninspiration from the standard Multi-Attribute Value Theory (MAVT) we further\npropose to fuse these metrics into a single score for ranking purposes and we\nevaluate our proposal with five continual learning strategies on the iCIFAR-100\ncontinual learning benchmark.\n", "versions": [{"version": "v1", "created": "Wed, 31 Oct 2018 09:15:02 GMT"}], "update_date": "2018-11-01", "authors_parsed": [["D\u00edaz-Rodr\u00edguez", "Natalia", ""], ["Lomonaco", "Vincenzo", ""], ["Filliat", "David", ""], ["Maltoni", "Davide", ""]]}, {"id": "1810.13192", "submitter": "Qiang Hu", "authors": "Qiang Hu and Hao Zhang", "title": "Nearly-tight bounds on linear regions of piecewise linear neural\n  networks", "comments": "Counting linear regions of neural networks", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  The developments of deep neural networks (DNN) in recent years have ushered a\nbrand new era of artificial intelligence. DNNs are proved to be excellent in\nsolving very complex problems, e.g., visual recognition and text understanding,\nto the extent of competing with or even surpassing people. Despite inspiring\nand encouraging success of DNNs, thorough theoretical analyses still lack to\nunravel the mystery of their magics. The design of DNN structure is dominated\nby empirical results in terms of network depth, number of neurons and\nactivations. A few of remarkable works published recently in an attempt to\ninterpret DNNs have established the first glimpses of their internal\nmechanisms. Nevertheless, research on exploring how DNNs operate is still at\nthe initial stage with plenty of room for refinement. In this paper, we extend\nprecedent research on neural networks with piecewise linear activations (PLNN)\nconcerning linear regions bounds. We present (i) the exact maximal number of\nlinear regions for single layer PLNNs; (ii) a upper bound for multi-layer\nPLNNs; and (iii) a tighter upper bound for the maximal number of liner regions\non rectifier networks. The derived bounds also indirectly explain why deep\nmodels are more powerful than shallow counterparts, and how non-linearity of\nactivation functions impacts on expressiveness of networks.\n", "versions": [{"version": "v1", "created": "Wed, 31 Oct 2018 10:08:40 GMT"}, {"version": "v2", "created": "Thu, 1 Nov 2018 12:25:27 GMT"}, {"version": "v3", "created": "Wed, 12 Dec 2018 12:25:51 GMT"}, {"version": "v4", "created": "Wed, 26 Dec 2018 14:55:57 GMT"}], "update_date": "2018-12-27", "authors_parsed": [["Hu", "Qiang", ""], ["Zhang", "Hao", ""]]}, {"id": "1810.13205", "submitter": "Chen Chen", "authors": "Chen Chen, Wenjia Bai, Daniel Rueckert", "title": "Multi-Task Learning for Left Atrial Segmentation on GE-MRI", "comments": "STACOM 2018 Workshop, MICCAI 2018", "journal-ref": "Statistical Atlases and Computational Models of the Heart. Atrial\n  Segmentation and LV Quantification Challenges, 9th International Workshop,\n  STACOM 2018, pp.292-301", "doi": "10.1007/978-3-030-12029-0_32", "report-no": null, "categories": "cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Segmentation of the left atrium (LA) is crucial for assessing its anatomy in\nboth pre-operative atrial fibrillation (AF) ablation planning and\npost-operative follow-up studies. In this paper, we present a fully automated\nframework for left atrial segmentation in gadolinium-enhanced magnetic\nresonance images (GE-MRI) based on deep learning. We propose a fully\nconvolutional neural network and explore the benefits of multi-task learning\nfor performing both atrial segmentation and pre/post ablation classification.\nOur results show that, by sharing features between related tasks, the network\ncan gain additional anatomical information and achieve more accurate atrial\nsegmentation, leading to a mean Dice score of 0.901 on a test set of 20 3D MRI\nimages. Code of our proposed algorithm is available at\nhttps://github.com/cherise215/atria_segmentation_2018/.\n", "versions": [{"version": "v1", "created": "Wed, 31 Oct 2018 10:47:06 GMT"}], "update_date": "2019-02-28", "authors_parsed": [["Chen", "Chen", ""], ["Bai", "Wenjia", ""], ["Rueckert", "Daniel", ""]]}, {"id": "1810.13243", "submitter": "Akhilesh Gotmare", "authors": "Akhilesh Gotmare, Nitish Shirish Keskar, Caiming Xiong and Richard\n  Socher", "title": "A Closer Look at Deep Learning Heuristics: Learning rate restarts,\n  Warmup and Distillation", "comments": "We use empirical tools of mode connectivity and SVCCA to investigate\n  neural network training heuristics of learning rate restarts, warmup and\n  knowledge distillation. arXiv admin note: text overlap with arXiv:1806.06977", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The convergence rate and final performance of common deep learning models\nhave significantly benefited from heuristics such as learning rate schedules,\nknowledge distillation, skip connections, and normalization layers. In the\nabsence of theoretical underpinnings, controlled experiments aimed at\nexplaining these strategies can aid our understanding of deep learning\nlandscapes and the training dynamics. Existing approaches for empirical\nanalysis rely on tools of linear interpolation and visualizations with\ndimensionality reduction, each with their limitations. Instead, we revisit such\nanalysis of heuristics through the lens of recently proposed methods for loss\nsurface and representation analysis, viz., mode connectivity and canonical\ncorrelation analysis (CCA), and hypothesize reasons for the success of the\nheuristics. In particular, we explore knowledge distillation and learning rate\nheuristics of (cosine) restarts and warmup using mode connectivity and CCA. Our\nempirical analysis suggests that: (a) the reasons often quoted for the success\nof cosine annealing are not evidenced in practice; (b) that the effect of\nlearning rate warmup is to prevent the deeper layers from creating training\ninstability; and (c) that the latent knowledge shared by the teacher is\nprimarily disbursed to the deeper layers.\n", "versions": [{"version": "v1", "created": "Mon, 29 Oct 2018 19:36:07 GMT"}], "update_date": "2018-11-01", "authors_parsed": [["Gotmare", "Akhilesh", ""], ["Keskar", "Nitish Shirish", ""], ["Xiong", "Caiming", ""], ["Socher", "Richard", ""]]}, {"id": "1810.13247", "submitter": "Nghia (Andy) Nguyen", "authors": "Mei Lin, Vanya Jaitly, Iris Wang, Zhihong Hu, Lei Chen, Md. Amer\n  Wahed, Zeyad Kanaan, Adan Rios, Andy N.D. Nguyen", "title": "Application of Deep Learning on Predicting Prognosis of Acute Myeloid\n  Leukemia with Cytogenetics, Age, and Mutations", "comments": "11 pages, 1 table, 1 figure. arXiv admin note: substantial text\n  overlap with arXiv:1801.01019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG q-bio.QM stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We explore how Deep Learning (DL) can be utilized to predict prognosis of\nacute myeloid leukemia (AML). Out of TCGA (The Cancer Genome Atlas) database,\n94 AML cases are used in this study. Input data include age, 10 common\ncytogenetic and 23 most common mutation results; output is the prognosis\n(diagnosis to death, DTD). In our DL network, autoencoders are stacked to form\na hierarchical DL model from which raw data are compressed and organized and\nhigh-level features are extracted. The network is written in R language and is\ndesigned to predict prognosis of AML for a given case (DTD of more than or less\nthan 730 days). The DL network achieves an excellent accuracy of 83% in\npredicting prognosis. As a proof-of-concept study, our preliminary results\ndemonstrate a practical application of DL in future practice of prognostic\nprediction using next-gen sequencing (NGS) data.\n", "versions": [{"version": "v1", "created": "Tue, 30 Oct 2018 15:03:35 GMT"}], "update_date": "2018-11-01", "authors_parsed": [["Lin", "Mei", ""], ["Jaitly", "Vanya", ""], ["Wang", "Iris", ""], ["Hu", "Zhihong", ""], ["Chen", "Lei", ""], ["Wahed", "Md. Amer", ""], ["Kanaan", "Zeyad", ""], ["Rios", "Adan", ""], ["Nguyen", "Andy N. D.", ""]]}, {"id": "1810.13258", "submitter": "Luigi Carratino", "authors": "Alessandro Rudi, Daniele Calandriello, Luigi Carratino, Lorenzo\n  Rosasco", "title": "On Fast Leverage Score Sampling and Optimal Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.DS cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Leverage score sampling provides an appealing way to perform approximate\ncomputations for large matrices. Indeed, it allows to derive faithful\napproximations with a complexity adapted to the problem at hand. Yet,\nperforming leverage scores sampling is a challenge in its own right requiring\nfurther approximations. In this paper, we study the problem of leverage score\nsampling for positive definite matrices defined by a kernel. Our contribution\nis twofold. First we provide a novel algorithm for leverage score sampling and\nsecond, we exploit the proposed method in statistical learning by deriving a\nnovel solver for kernel ridge regression. Our main technical contribution is\nshowing that the proposed algorithms are currently the most efficient and\naccurate for these problems.\n", "versions": [{"version": "v1", "created": "Wed, 31 Oct 2018 12:54:56 GMT"}, {"version": "v2", "created": "Thu, 24 Jan 2019 11:08:26 GMT"}], "update_date": "2019-01-25", "authors_parsed": [["Rudi", "Alessandro", ""], ["Calandriello", "Daniele", ""], ["Carratino", "Luigi", ""], ["Rosasco", "Lorenzo", ""]]}, {"id": "1810.13259", "submitter": "Amichai Painsky", "authors": "Amichai Painsky, Meir Feder, Naftali Tishby", "title": "Non-linear Canonical Correlation Analysis: A Compressed Representation\n  Approach", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Canonical Correlation Analysis (CCA) is a linear representation learning\nmethod that seeks maximally correlated variables in multi-view data. Non-linear\nCCA extends this notion to a broader family of transformations, which are more\npowerful in many real-world applications. Given the joint probability, the\nAlternating Conditional Expectation (ACE) algorithm provides an optimal\nsolution to the non-linear CCA problem. However, it suffers from limited\nperformance and an increasing computational burden when only a finite number of\nsamples is available. In this work we introduce an information-theoretic\ncompressed representation framework for the non-linear CCA problem (CRCCA),\nwhich extends the classical ACE approach. Our suggested framework seeks compact\nrepresentations of the data that allow a maximal level of correlation. This way\nwe control the trade-off between the flexibility and the complexity of the\nmodel. CRCCA provides theoretical bounds and optimality conditions, as we\nestablish fundamental connections to rate-distortion theory, the information\nbottleneck and remote source coding. In addition, it allows a soft\ndimensionality reduction, as the compression level is determined by the mutual\ninformation between the original noisy data and the extracted signals. Finally,\nwe introduce a simple implementation of the CRCCA framework, based on lattice\nquantization.\n", "versions": [{"version": "v1", "created": "Wed, 31 Oct 2018 12:57:35 GMT"}, {"version": "v2", "created": "Mon, 10 Feb 2020 08:46:32 GMT"}], "update_date": "2020-02-11", "authors_parsed": [["Painsky", "Amichai", ""], ["Feder", "Meir", ""], ["Tishby", "Naftali", ""]]}, {"id": "1810.13273", "submitter": "Alexandre Boulch", "authors": "Alexandre Boulch and No\\\"elie Cherrier and Thibaut Castaings", "title": "Ionospheric activity prediction using convolutional recurrent neural\n  networks", "comments": "Under submission at IEEE Transactions on Big Data", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The ionosphere electromagnetic activity is a major factor of the quality of\nsatellite telecommunications, Global Navigation Satellite Systems (GNSS) and\nother vital space applications. Being able to forecast globally the Total\nElectron Content (TEC) would enable a better anticipation of potential\nperformance degradations. A few studies have proposed models able to predict\nthe TEC locally, but not worldwide for most of them. Thanks to a large record\nof past TEC maps publicly available, we propose a method based on Deep Neural\nNetworks (DNN) to forecast a sequence of global TEC maps consecutive to an\ninput sequence of TEC maps, without introducing any prior knowledge other than\nEarth rotation periodicity. By combining several state-of-the-art\narchitectures, the proposed approach is competitive with previous works on TEC\nforecasting while predicting the TEC globally.\n", "versions": [{"version": "v1", "created": "Wed, 31 Oct 2018 13:25:17 GMT"}, {"version": "v2", "created": "Tue, 6 Nov 2018 12:14:15 GMT"}], "update_date": "2018-11-07", "authors_parsed": [["Boulch", "Alexandre", ""], ["Cherrier", "No\u00eblie", ""], ["Castaings", "Thibaut", ""]]}, {"id": "1810.13278", "submitter": "Vajira Thambawita", "authors": "Vajira Thambawita, Debesh Jha, Michael Riegler, P{\\aa}l Halvorsen,\n  Hugo Lewi Hammer, H{\\aa}vard D. Johansen, Dag Johansen", "title": "The Medico-Task 2018: Disease Detection in the Gastrointestinal Tract\n  using Global Features and Deep Learning", "comments": "2 pages + 1 page for references, 1 figure, Conference paper", "journal-ref": "MediaEval 2018", "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we present our approach for the 2018 Medico Task classifying\ndiseases in the gastrointestinal tract. We have proposed a system based on\nglobal features and deep neural networks. The best approach combines two neural\nnetworks, and the reproducible experimental results signify the efficiency of\nthe proposed model with an accuracy rate of 95.80%, a precision of 95.87%, and\nan F1-score of 95.80%.\n", "versions": [{"version": "v1", "created": "Wed, 31 Oct 2018 13:35:23 GMT"}], "update_date": "2018-11-01", "authors_parsed": [["Thambawita", "Vajira", ""], ["Jha", "Debesh", ""], ["Riegler", "Michael", ""], ["Halvorsen", "P\u00e5l", ""], ["Hammer", "Hugo Lewi", ""], ["Johansen", "H\u00e5vard D.", ""], ["Johansen", "Dag", ""]]}, {"id": "1810.13292", "submitter": "Duc Tam Nguyen", "authors": "Duc Tam Nguyen, Zhongyu Lou, Michael Klar, Thomas Brox", "title": "Anomaly Detection With Multiple-Hypotheses Predictions", "comments": "In proceedings of the 36th International Conference on Machine\n  Learning (ICML), Long Beach, California, PMLR 97, 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.LG cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In one-class-learning tasks, only the normal case (foreground) can be modeled\nwith data, whereas the variation of all possible anomalies is too erratic to be\ndescribed by samples. Thus, due to the lack of representative data, the\nwide-spread discriminative approaches cannot cover such learning tasks, and\nrather generative models, which attempt to learn the input density of the\nforeground, are used. However, generative models suffer from a large input\ndimensionality (as in images) and are typically inefficient learners. We\npropose to learn the data distribution of the foreground more efficiently with\na multi-hypotheses autoencoder. Moreover, the model is criticized by a\ndiscriminator, which prevents artificial data modes not supported by data, and\nenforces diversity across hypotheses. Our multiple-hypothesesbased anomaly\ndetection framework allows the reliable identification of out-of-distribution\nsamples. For anomaly detection on CIFAR-10, it yields up to 3.9% points\nimprovement over previously reported results. On a real anomaly detection task,\nthe approach reduces the error of the baseline models from 6.8% to 1.5%.\n", "versions": [{"version": "v1", "created": "Wed, 31 Oct 2018 14:05:44 GMT"}, {"version": "v2", "created": "Mon, 26 Nov 2018 12:36:22 GMT"}, {"version": "v3", "created": "Tue, 27 Nov 2018 06:13:45 GMT"}, {"version": "v4", "created": "Mon, 28 Jan 2019 15:05:09 GMT"}, {"version": "v5", "created": "Fri, 31 May 2019 12:25:42 GMT"}], "update_date": "2019-06-03", "authors_parsed": [["Nguyen", "Duc Tam", ""], ["Lou", "Zhongyu", ""], ["Klar", "Michael", ""], ["Brox", "Thomas", ""]]}, {"id": "1810.13296", "submitter": "Xiaoyu Lu", "authors": "Xiaoyu Lu, Tom Rainforth, Yuan Zhou, Jan-Willem van de Meent, Yee Whye\n  Teh", "title": "On Exploration, Exploitation and Learning in Adaptive Importance\n  Sampling", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study adaptive importance sampling (AIS) as an online learning problem and\nargue for the importance of the trade-off between exploration and exploitation\nin this adaptation. Borrowing ideas from the bandits literature, we propose\nDaisee, a partition-based AIS algorithm. We further introduce a notion of\nregret for AIS and show that Daisee has $\\mathcal{O}(\\sqrt{T}(\\log\nT)^{\\frac{3}{4}})$ cumulative pseudo-regret, where $T$ is the number of\niterations. We then extend Daisee to adaptively learn a hierarchical\npartitioning of the sample space for more efficient sampling and confirm the\nperformance of both algorithms empirically.\n", "versions": [{"version": "v1", "created": "Wed, 31 Oct 2018 14:13:55 GMT"}], "update_date": "2018-11-01", "authors_parsed": [["Lu", "Xiaoyu", ""], ["Rainforth", "Tom", ""], ["Zhou", "Yuan", ""], ["van de Meent", "Jan-Willem", ""], ["Teh", "Yee Whye", ""]]}, {"id": "1810.13306", "submitter": "Quanming Yao", "authors": "Quanming Yao, Mengshuo Wang, Yuqiang Chen, Wenyuan Dai, Yu-Feng Li,\n  Wei-Wei Tu, Qiang Yang, Yang Yu", "title": "Taking Human out of Learning Applications: A Survey on Automated Machine\n  Learning", "comments": "This is a preliminary and will be kept updated", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Machine learning techniques have deeply rooted in our everyday life. However,\nsince it is knowledge- and labor-intensive to pursue good learning performance,\nhuman experts are heavily involved in every aspect of machine learning. In\norder to make machine learning techniques easier to apply and reduce the demand\nfor experienced human experts, automated machine learning (AutoML) has emerged\nas a hot topic with both industrial and academic interest. In this paper, we\nprovide an up to date survey on AutoML. First, we introduce and define the\nAutoML problem, with inspiration from both realms of automation and machine\nlearning. Then, we propose a general AutoML framework that not only covers most\nexisting approaches to date but also can guide the design for new methods.\nSubsequently, we categorize and review the existing works from two aspects,\ni.e., the problem setup and the employed techniques. Finally, we provide a\ndetailed analysis of AutoML approaches and explain the reasons underneath their\nsuccessful applications. We hope this survey can serve as not only an\ninsightful guideline for AutoML beginners but also an inspiration for future\nresearch.\n", "versions": [{"version": "v1", "created": "Wed, 31 Oct 2018 14:35:38 GMT"}, {"version": "v2", "created": "Mon, 24 Dec 2018 11:29:43 GMT"}, {"version": "v3", "created": "Thu, 17 Jan 2019 10:47:18 GMT"}, {"version": "v4", "created": "Mon, 16 Dec 2019 05:36:13 GMT"}], "update_date": "2019-12-17", "authors_parsed": [["Yao", "Quanming", ""], ["Wang", "Mengshuo", ""], ["Chen", "Yuqiang", ""], ["Dai", "Wenyuan", ""], ["Li", "Yu-Feng", ""], ["Tu", "Wei-Wei", ""], ["Yang", "Qiang", ""], ["Yu", "Yang", ""]]}, {"id": "1810.13317", "submitter": "Abdi-Hakin Dirie", "authors": "Abdi-Hakin Dirie, Abubakar Abid, James Zou", "title": "Contrastive Multivariate Singular Spectrum Analysis", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce Contrastive Multivariate Singular Spectrum Analysis, a novel\nunsupervised method for dimensionality reduction and signal decomposition of\ntime series data. By utilizing an appropriate background dataset, the method\ntransforms a target time series dataset in a way that evinces the sub-signals\nthat are enhanced in the target dataset, as opposed to only those that account\nfor the greatest variance. This shifts the goal from finding signals that\nexplain the most variance to signals that matter the most to the analyst. We\ndemonstrate our method on an illustrative synthetic example, as well as show\nthe utility of our method in the downstream clustering of electrocardiogram\nsignals from the public MHEALTH dataset.\n", "versions": [{"version": "v1", "created": "Wed, 31 Oct 2018 14:50:01 GMT"}], "update_date": "2018-11-01", "authors_parsed": [["Dirie", "Abdi-Hakin", ""], ["Abid", "Abubakar", ""], ["Zou", "James", ""]]}, {"id": "1810.13329", "submitter": "Doyun Kim", "authors": "Doyun Kim, Han Young Yim, Sanghyuck Ha, Changgwun Lee, and Inyup Kang", "title": "Convolutional Neural Network Quantization using Generalized Gamma\n  Distribution", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  As edge applications using convolutional neural networks (CNN) models grow,\nit is becoming necessary to introduce dedicated hardware accelerators in which\nnetwork parameters and feature-map data are represented with limited precision.\nIn this paper we propose a novel quantization algorithm for energy-efficient\ndeployment of the hardware accelerators. For weights and biases, the optimal\nbit length of the fractional part is determined so that the quantization error\nis minimized over their distribution. For feature-map data, meanwhile, their\nsample distribution is well approximated with the generalized gamma\ndistribution (GGD), and accordingly the optimal quantization step size can be\nobtained through the asymptotical closed form solution of GGD. The proposed\nquantization algorithm has a higher signal-to-quantization-noise ratio (SQNR)\nthan other quantization schemes previously proposed for CNNs, and even can be\nmore improved by tuning the quantization parameters, resulting in efficient\nimplementation of the hardware accelerators for CNNs in terms of power\nconsumption and memory bandwidth.\n", "versions": [{"version": "v1", "created": "Wed, 31 Oct 2018 15:17:05 GMT"}], "update_date": "2018-11-01", "authors_parsed": [["Kim", "Doyun", ""], ["Yim", "Han Young", ""], ["Ha", "Sanghyuck", ""], ["Lee", "Changgwun", ""], ["Kang", "Inyup", ""]]}, {"id": "1810.13333", "submitter": "Micha\\\"el Perrot", "authors": "Micha\\\"el Perrot, Ulrike von Luxburg", "title": "Boosting for Comparison-Based Learning", "comments": "This is the extended version (38 pages) of a paper accepted to the\n  International Joint Conference on Artificial Intelligence (IJCAI) 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the problem of classification in a comparison-based setting:\ngiven a set of objects, we only have access to triplet comparisons of the form\n\"object $x_i$ is closer to object $x_j$ than to object $x_k$.\" In this paper we\nintroduce TripletBoost, a new method that can learn a classifier just from such\ntriplet comparisons. The main idea is to aggregate the triplets information\ninto weak classifiers, which can subsequently be boosted to a strong\nclassifier. Our method has two main advantages: (i) it is applicable to data\nfrom any metric space, and (ii) it can deal with large scale problems using\nonly passively obtained and noisy triplets. We derive theoretical\ngeneralization guarantees and a lower bound on the number of necessary\ntriplets, and we empirically show that our method is both competitive with\nstate of the art approaches and resistant to noise.\n", "versions": [{"version": "v1", "created": "Wed, 31 Oct 2018 15:26:12 GMT"}, {"version": "v2", "created": "Wed, 29 May 2019 17:17:05 GMT"}], "update_date": "2019-05-30", "authors_parsed": [["Perrot", "Micha\u00ebl", ""], ["von Luxburg", "Ulrike", ""]]}, {"id": "1810.13337", "submitter": "Pengcheng Yin", "authors": "Pengcheng Yin, Graham Neubig, Miltiadis Allamanis, Marc Brockschmidt,\n  Alexander L. Gaunt", "title": "Learning to Represent Edits", "comments": "ICLR 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.SE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce the problem of learning distributed representations of edits. By\ncombining a \"neural editor\" with an \"edit encoder\", our models learn to\nrepresent the salient information of an edit and can be used to apply edits to\nnew inputs. We experiment on natural language and source code edit data. Our\nevaluation yields promising results that suggest that our neural network models\nlearn to capture the structure and semantics of edits. We hope that this\ninteresting task and data source will inspire other researchers to work further\non this problem.\n", "versions": [{"version": "v1", "created": "Wed, 31 Oct 2018 15:29:30 GMT"}, {"version": "v2", "created": "Fri, 22 Feb 2019 05:16:03 GMT"}], "update_date": "2019-02-25", "authors_parsed": [["Yin", "Pengcheng", ""], ["Neubig", "Graham", ""], ["Allamanis", "Miltiadis", ""], ["Brockschmidt", "Marc", ""], ["Gaunt", "Alexander L.", ""]]}, {"id": "1810.13348", "submitter": "Keyang Xu", "authors": "Keyang Xu, Mike Lam, Jingzhi Pang, Xin Gao, Charlotte Band, Piyush\n  Mathur MD, Frank Papay MD, Ashish K. Khanna MD, Jacek B. Cywinski MD, Kamal\n  Maheshwari MD, Pengtao Xie, Eric Xing", "title": "Multimodal Machine Learning for Automated ICD Coding", "comments": "Machine Learning for Healthcare 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This study presents a multimodal machine learning model to predict ICD-10\ndiagnostic codes. We developed separate machine learning models that can handle\ndata from different modalities, including unstructured text, semi-structured\ntext and structured tabular data. We further employed an ensemble method to\nintegrate all modality-specific models to generate ICD-10 codes. Key evidence\nwas also extracted to make our prediction more convincing and explainable. We\nused the Medical Information Mart for Intensive Care III (MIMIC -III) dataset\nto validate our approach. For ICD code prediction, our best-performing model\n(micro-F1 = 0.7633, micro-AUC = 0.9541) significantly outperforms other\nbaseline models including TF-IDF (micro-F1 = 0.6721, micro-AUC = 0.7879) and\nText-CNN model (micro-F1 = 0.6569, micro-AUC = 0.9235). For interpretability,\nour approach achieves a Jaccard Similarity Coefficient (JSC) of 0.1806 on text\ndata and 0.3105 on tabular data, where well-trained physicians achieve 0.2780\nand 0.5002 respectively.\n", "versions": [{"version": "v1", "created": "Wed, 31 Oct 2018 15:39:32 GMT"}, {"version": "v2", "created": "Thu, 25 Jul 2019 08:44:55 GMT"}, {"version": "v3", "created": "Tue, 6 Aug 2019 07:58:41 GMT"}], "update_date": "2019-08-07", "authors_parsed": [["Xu", "Keyang", ""], ["Lam", "Mike", ""], ["Pang", "Jingzhi", ""], ["Gao", "Xin", ""], ["Band", "Charlotte", ""], ["MD", "Piyush Mathur", ""], ["MD", "Frank Papay", ""], ["MD", "Ashish K. Khanna", ""], ["MD", "Jacek B. Cywinski", ""], ["MD", "Kamal Maheshwari", ""], ["Xie", "Pengtao", ""], ["Xing", "Eric", ""]]}, {"id": "1810.13373", "submitter": "David Barrett", "authors": "David G.T. Barrett, Ari S. Morcos and Jakob H. Macke", "title": "Analyzing biological and artificial neural networks: challenges with\n  opportunities for synergy?", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.NC cs.AI cs.CV cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep neural networks (DNNs) transform stimuli across multiple processing\nstages to produce representations that can be used to solve complex tasks, such\nas object recognition in images. However, a full understanding of how they\nachieve this remains elusive. The complexity of biological neural networks\nsubstantially exceeds the complexity of DNNs, making it even more challenging\nto understand the representations that they learn. Thus, both machine learning\nand computational neuroscience are faced with a shared challenge: how can we\nanalyze their representations in order to understand how they solve complex\ntasks?\n  We review how data-analysis concepts and techniques developed by\ncomputational neuroscientists can be useful for analyzing representations in\nDNNs, and in turn, how recently developed techniques for analysis of DNNs can\nbe useful for understanding representations in biological neural networks. We\nexplore opportunities for synergy between the two fields, such as the use of\nDNNs as in-silico model systems for neuroscience, and how this synergy can lead\nto new hypotheses about the operating principles of biological neural networks.\n", "versions": [{"version": "v1", "created": "Wed, 31 Oct 2018 16:09:44 GMT"}], "update_date": "2018-11-01", "authors_parsed": [["Barrett", "David G. T.", ""], ["Morcos", "Ari S.", ""], ["Macke", "Jakob H.", ""]]}, {"id": "1810.13395", "submitter": "Chaoyue Liu", "authors": "Chaoyue Liu, Mikhail Belkin", "title": "Accelerating SGD with momentum for over-parameterized learning", "comments": "new version", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Nesterov SGD is widely used for training modern neural networks and other\nmachine learning models. Yet, its advantages over SGD have not been\ntheoretically clarified. Indeed, as we show in our paper, both theoretically\nand empirically, Nesterov SGD with any parameter selection does not in general\nprovide acceleration over ordinary SGD. Furthermore, Nesterov SGD may diverge\nfor step sizes that ensure convergence of ordinary SGD. This is in contrast to\nthe classical results in the deterministic scenario, where the same step size\nensures accelerated convergence of the Nesterov's method over optimal gradient\ndescent.\n  To address the non-acceleration issue, we introduce a compensation term to\nNesterov SGD. The resulting algorithm, which we call MaSS, converges for same\nstep sizes as SGD. We prove that MaSS obtains an accelerated convergence rates\nover SGD for any mini-batch size in the linear setting. For full batch, the\nconvergence rate of MaSS matches the well-known accelerated rate of the\nNesterov's method.\n  We also analyze the practically important question of the dependence of the\nconvergence rate and optimal hyper-parameters on the mini-batch size,\ndemonstrating three distinct regimes: linear scaling, diminishing returns and\nsaturation.\n  Experimental evaluation of MaSS for several standard architectures of deep\nnetworks, including ResNet and convolutional networks, shows improved\nperformance over SGD, Nesterov SGD and Adam.\n", "versions": [{"version": "v1", "created": "Wed, 31 Oct 2018 16:44:05 GMT"}, {"version": "v2", "created": "Mon, 5 Nov 2018 21:30:32 GMT"}, {"version": "v3", "created": "Thu, 14 Feb 2019 16:58:03 GMT"}, {"version": "v4", "created": "Mon, 18 Feb 2019 18:53:41 GMT"}, {"version": "v5", "created": "Fri, 27 Sep 2019 17:38:08 GMT"}], "update_date": "2019-09-30", "authors_parsed": [["Liu", "Chaoyue", ""], ["Belkin", "Mikhail", ""]]}, {"id": "1810.13400", "submitter": "Brandon Amos", "authors": "Brandon Amos, Ivan Dario Jimenez Rodriguez, Jacob Sacks, Byron Boots,\n  J. Zico Kolter", "title": "Differentiable MPC for End-to-end Planning and Control", "comments": "NeurIPS 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI math.OC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present foundations for using Model Predictive Control (MPC) as a\ndifferentiable policy class for reinforcement learning in continuous state and\naction spaces. This provides one way of leveraging and combining the advantages\nof model-free and model-based approaches. Specifically, we differentiate\nthrough MPC by using the KKT conditions of the convex approximation at a fixed\npoint of the controller. Using this strategy, we are able to learn the cost and\ndynamics of a controller via end-to-end learning. Our experiments focus on\nimitation learning in the pendulum and cartpole domains, where we learn the\ncost and dynamics terms of an MPC policy class. We show that our MPC policies\nare significantly more data-efficient than a generic neural network and that\nour method is superior to traditional system identification in a setting where\nthe expert is unrealizable.\n", "versions": [{"version": "v1", "created": "Wed, 31 Oct 2018 16:46:38 GMT"}, {"version": "v2", "created": "Thu, 10 Jan 2019 18:58:30 GMT"}, {"version": "v3", "created": "Mon, 14 Oct 2019 17:49:37 GMT"}], "update_date": "2019-10-15", "authors_parsed": [["Amos", "Brandon", ""], ["Rodriguez", "Ivan Dario Jimenez", ""], ["Sacks", "Jacob", ""], ["Boots", "Byron", ""], ["Kolter", "J. Zico", ""]]}, {"id": "1810.13404", "submitter": "Philipp Seeb\\\"ock", "authors": "Philipp Seeb\\\"ock, Sebastian M. Waldstein, Sophie Klimscha, Hrvoje\n  Bogunovic, Thomas Schlegl, Bianca S. Gerendas, Ren\\'e Donner, Ursula\n  Schmidt-Erfurth, Georg Langs", "title": "Unsupervised Identification of Disease Marker Candidates in Retinal OCT\n  Imaging Data", "comments": "Accepted for publication in IEEE Transactions on Medical Imaging,\n  2018", "journal-ref": null, "doi": "10.1109/TMI.2018.2877080", "report-no": null, "categories": "cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The identification and quantification of markers in medical images is\ncritical for diagnosis, prognosis, and disease management. Supervised machine\nlearning enables the detection and exploitation of findings that are known a\npriori after annotation of training examples by experts. However, supervision\ndoes not scale well, due to the amount of necessary training examples, and the\nlimitation of the marker vocabulary to known entities. In this proof-of-concept\nstudy, we propose unsupervised identification of anomalies as candidates for\nmarkers in retinal Optical Coherence Tomography (OCT) imaging data without a\nconstraint to a priori definitions. We identify and categorize marker\ncandidates occurring frequently in the data, and demonstrate that these markers\nshow predictive value in the task of detecting disease. A careful qualitative\nanalysis of the identified data driven markers reveals how their quantifiable\noccurrence aligns with our current understanding of disease course, in early-\nand late age-related macular degeneration (AMD) patients. A multi-scale deep\ndenoising autoencoder is trained on healthy images, and a one-class support\nvector machine identifies anomalies in new data. Clustering in the anomalies\nidentifies stable categories. Using these markers to classify healthy-, early\nAMD- and late AMD cases yields an accuracy of 81.40%. In a second binary\nclassification experiment on a publicly available data set (healthy vs.\nintermediate AMD) the model achieves an area under the ROC curve of 0.944.\n", "versions": [{"version": "v1", "created": "Wed, 31 Oct 2018 16:55:46 GMT"}], "update_date": "2018-11-01", "authors_parsed": [["Seeb\u00f6ck", "Philipp", ""], ["Waldstein", "Sebastian M.", ""], ["Klimscha", "Sophie", ""], ["Bogunovic", "Hrvoje", ""], ["Schlegl", "Thomas", ""], ["Gerendas", "Bianca S.", ""], ["Donner", "Ren\u00e9", ""], ["Schmidt-Erfurth", "Ursula", ""], ["Langs", "Georg", ""]]}, {"id": "1810.13407", "submitter": "Hao Tang", "authors": "Hao Tang and James Glass", "title": "On The Inductive Bias of Words in Acoustics-to-Word Models", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.AS cs.CL cs.LG cs.SD", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Acoustics-to-word models are end-to-end speech recognizers that use words as\ntargets without relying on pronunciation dictionaries or graphemes. These\nmodels are notoriously difficult to train due to the lack of linguistic\nknowledge. It is also unclear how the amount of training data impacts the\noptimization and generalization of such models. In this work, we study the\noptimization and generalization of acoustics-to-word models under different\namounts of training data. In addition, we study three types of inductive bias,\nleveraging a pronunciation dictionary, word boundary annotations, and\nconstraints on word durations. We find that constraining word durations leads\nto the most improvement. Finally, we analyze the word embedding space learned\nby the model, and find that the space has a structure dominated by the\npronunciation of words. This suggests that the contexts of words, instead of\ntheir phonetic structure, should be the future focus of inductive bias in\nacoustics-to-word models.\n", "versions": [{"version": "v1", "created": "Wed, 31 Oct 2018 17:07:14 GMT"}, {"version": "v2", "created": "Mon, 12 Nov 2018 20:51:27 GMT"}], "update_date": "2018-11-14", "authors_parsed": [["Tang", "Hao", ""], ["Glass", "James", ""]]}, {"id": "1810.13425", "submitter": "Jayaraman J. Thiagarajan", "authors": "Jayaraman J. Thiagarajan, Irene Kim, Rushil Anirudh, Peer-Timo Bremer", "title": "Understanding Deep Neural Networks through Input Uncertainties", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Techniques for understanding the functioning of complex machine learning\nmodels are becoming increasingly popular, not only to improve the validation\nprocess, but also to extract new insights about the data via exploratory\nanalysis. Though a large class of such tools currently exists, most assume that\npredictions are point estimates and use a sensitivity analysis of these\nestimates to interpret the model. Using lightweight probabilistic networks we\nshow how including prediction uncertainties in the sensitivity analysis leads\nto: (i) more robust and generalizable models; and (ii) a new approach for model\ninterpretation through uncertainty decomposition. In particular, we introduce a\nnew regularization that takes both the mean and variance of a prediction into\naccount and demonstrate that the resulting networks provide improved\ngeneralization to unseen data. Furthermore, we propose a new technique to\nexplain prediction uncertainties through uncertainties in the input domain,\nthus providing new ways to validate and interpret deep learning models.\n", "versions": [{"version": "v1", "created": "Wed, 31 Oct 2018 17:36:31 GMT"}, {"version": "v2", "created": "Thu, 1 Nov 2018 02:56:55 GMT"}], "update_date": "2018-11-02", "authors_parsed": [["Thiagarajan", "Jayaraman J.", ""], ["Kim", "Irene", ""], ["Anirudh", "Rushil", ""], ["Bremer", "Peer-Timo", ""]]}, {"id": "1810.13427", "submitter": "Jayaraman J. Thiagarajan", "authors": "Jayaraman J. Thiagarajan, Rushil Anirudh, Rahul Sridhar and Peer-Timo\n  Bremer", "title": "Unsupervised Dimension Selection using a Blue Noise Spectrum", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Unsupervised dimension selection is an important problem that seeks to reduce\ndimensionality of data, while preserving the most useful characteristics. While\ndimensionality reduction is commonly utilized to construct low-dimensional\nembeddings, they produce feature spaces that are hard to interpret. Further, in\napplications such as sensor design, one needs to perform reduction directly in\nthe input domain, instead of constructing transformed spaces. Consequently,\ndimension selection (DS) aims to solve the combinatorial problem of identifying\nthe top-$k$ dimensions, which is required for effective experiment design,\nreducing data while keeping it interpretable, and designing better sensing\nmechanisms. In this paper, we develop a novel approach for DS based on graph\nsignal analysis to measure feature influence. By analyzing synthetic graph\nsignals with a blue noise spectrum, we show that we can measure the importance\nof each dimension. Using experiments in supervised learning and image masking,\nwe demonstrate the superiority of the proposed approach over existing\ntechniques in capturing crucial characteristics of high dimensional spaces,\nusing only a small subset of the original features.\n", "versions": [{"version": "v1", "created": "Wed, 31 Oct 2018 17:40:40 GMT"}], "update_date": "2018-11-01", "authors_parsed": [["Thiagarajan", "Jayaraman J.", ""], ["Anirudh", "Rushil", ""], ["Sridhar", "Rahul", ""], ["Bremer", "Peer-Timo", ""]]}, {"id": "1810.13431", "submitter": "Rihui Ou", "authors": "Rihui Ou, Deborshee Sen, Alexander L Young, David B Dunson", "title": "Targeted stochastic gradient Markov chain Monte Carlo for hidden Markov\n  models with rare latent states", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Markov chain Monte Carlo (MCMC) algorithms for hidden Markov models often\nrely on the forward-backward sampler. This makes them computationally slow as\nthe length of the time series increases, motivating the recent development of\nsub-sampling-based approaches. These approximate the full posterior by using\nsmall random subsequences of the data at each MCMC iteration within stochastic\ngradient MCMC. In the presence of imbalanced data resulting from rare latent\nstates, subsequences often exclude rare latent state data, leading to\ninaccurate inference and prediction/detection of rare events. We propose a\ntargeted sub-sampling (TASS) approach that over-samples observations\ncorresponding to rare latent states when calculating the stochastic gradient of\nparameters associated with them. TASS uses an initial clustering of the data to\nconstruct subsequence weights that reduce the variance in gradient estimation.\nThis leads to improved sampling efficiency, in particular in settings where the\nrare latent states correspond to extreme observations. We demonstrate\nsubstantial gains in predictive and inferential accuracy on real and synthetic\nexamples.\n", "versions": [{"version": "v1", "created": "Wed, 31 Oct 2018 17:44:20 GMT"}, {"version": "v2", "created": "Thu, 27 May 2021 18:04:44 GMT"}], "update_date": "2021-05-31", "authors_parsed": [["Ou", "Rihui", ""], ["Sen", "Deborshee", ""], ["Young", "Alexander L", ""], ["Dunson", "David B", ""]]}, {"id": "1810.13444", "submitter": "John Dabiri", "authors": "Kristy L. Schlueter-Kuck and John O. Dabiri", "title": "Model parameter estimation using coherent structure coloring", "comments": "Accepted in the Journal of Fluid Mechanics", "journal-ref": null, "doi": "10.1017/jfm.2018.898", "report-no": null, "categories": "physics.flu-dyn cs.LG physics.ao-ph physics.data-an stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Lagrangian data assimilation is a complex problem in oceanic and atmospheric\nmodeling. Tracking drifters in large-scale geophysical flows can involve\nuncertainty in drifter location, complex inertial effects, and other factors\nwhich make comparing them to simulated Lagrangian trajectories from numerical\nmodels extremely challenging. Temporal and spatial discretization, factors\nnecessary in modeling large scale flows, also contribute to separation between\nreal and simulated drifter trajectories. The chaotic advection inherent in\nthese turbulent flows tends to separate even closely spaced tracer particles,\nmaking error metrics based solely on drifter displacements unsuitable for\nestimating model parameters. We propose to instead use error in the coherent\nstructure coloring (CSC) field to assess model skill. The CSC field provides a\nspatial representation of the underlying coherent patterns in the flow, and we\nshow that it is a more robust metric for assessing model accuracy. Through the\nuse of two test cases, one considering spatial uncertainty in particle\ninitialization, and one examining the influence of stochastic error along a\ntrajectory and temporal discretization, we show that error in the coherent\nstructure coloring field can be used to accurately determine single or multiple\nsimultaneously unknown model parameters, whereas a conventional error metric\nbased on error in drifter displacement fails. Because the CSC field enhances\nthe difference in error between correct and incorrect model parameters, error\nminima in model parameter sweeps become more distinct. The effectiveness and\nrobustness of this method for single and multi-parameter estimation in\nanalytical flows suggests that Lagrangian data assimilation for real oceanic\nand atmospheric models would benefit from a similar approach.\n", "versions": [{"version": "v1", "created": "Wed, 31 Oct 2018 17:57:26 GMT"}], "update_date": "2019-01-30", "authors_parsed": [["Schlueter-Kuck", "Kristy L.", ""], ["Dabiri", "John O.", ""]]}]